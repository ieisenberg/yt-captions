[
  {
    "start": "0",
    "end": "15000"
  },
  {
    "text": "hello everyone uh welcome to our cook on talk",
    "start": "3919",
    "end": "9440"
  },
  {
    "text": "today we'll be talking about uh how we've been working at cern",
    "start": "9440",
    "end": "14920"
  },
  {
    "text": "for speeding up analysis pipelines using remote container images my name is ricardo",
    "start": "14920",
    "end": "21520"
  },
  {
    "start": "15000",
    "end": "265000"
  },
  {
    "text": "rocha i work at cern in the sun cloud team i'm a computing engineer",
    "start": "21520",
    "end": "28720"
  },
  {
    "text": "and speed is three days i work in the same club as well as a computing engineer focusing on containers",
    "start": "28720",
    "end": "36239"
  },
  {
    "text": "so today we'll be covering this topic uh i will start by giving a very brief introduction to cern",
    "start": "36239",
    "end": "42719"
  },
  {
    "text": "and what we do here so cern is the european organization for",
    "start": "42719",
    "end": "48000"
  },
  {
    "text": "nuclear research we focus on doing fundamental research and trying to",
    "start": "48000",
    "end": "53440"
  },
  {
    "text": "answer big questions about the origins of the universe and",
    "start": "53440",
    "end": "59280"
  },
  {
    "text": "how matter how matter is constituted so",
    "start": "59280",
    "end": "66400"
  },
  {
    "text": "for to answer all these questions we basically built very large machines the largest machine",
    "start": "66400",
    "end": "73040"
  },
  {
    "text": "that we have today is the large hyphen collider which is here in the map it's a particle accelerator that is 27",
    "start": "73040",
    "end": "78799"
  },
  {
    "text": "kilometers in circumference where we inject proton beams one clockwise the other one",
    "start": "78799",
    "end": "84159"
  },
  {
    "text": "counterclockwise and we accelerate them to very close to the speed of light and uh to very",
    "start": "84159",
    "end": "90079"
  },
  {
    "text": "high energies uh we try them to make them collide uh at very specific points where we",
    "start": "90079",
    "end": "96479"
  },
  {
    "text": "built this massive detectors that allows us to get a sneak peak into",
    "start": "96479",
    "end": "102640"
  },
  {
    "text": "the collisions to have an idea of the size you have the geneva airport on the bottom right cern is actually a",
    "start": "102640",
    "end": "110320"
  },
  {
    "text": "split or the accelerator is split between the the swiss and french border close to the",
    "start": "110320",
    "end": "115600"
  },
  {
    "text": "european alps uh if we look a bit down into the",
    "start": "115600",
    "end": "120640"
  },
  {
    "text": "what the actual accelerator looks like it's a hundred meters in the ground in the",
    "start": "120640",
    "end": "125680"
  },
  {
    "text": "in a tunnel we see here the magnets and the in the middle we have the beams circulating and to achieve these higher",
    "start": "125680",
    "end": "132879"
  },
  {
    "text": "energies we actually have to cool them down to very close to absolute zero",
    "start": "132879",
    "end": "137920"
  },
  {
    "text": "then we have this big experiments that i mentioned these are in large caverns also underground this is",
    "start": "137920",
    "end": "144720"
  },
  {
    "text": "the compact muon solar solenoid cms the cavern is 40 meters by",
    "start": "144720",
    "end": "150080"
  },
  {
    "text": "40 meters it's fully filled with detector the detector weighs 14 tons and you can see the size",
    "start": "150080",
    "end": "156319"
  },
  {
    "text": "of the person for an idea of the scale it acts like a gigantic camera taking 40",
    "start": "156319",
    "end": "161920"
  },
  {
    "text": "million pictures a second and then the result of this uh",
    "start": "161920",
    "end": "171120"
  },
  {
    "text": "collection is just a very large amount of data that we have to store and eventually analyze",
    "start": "171120",
    "end": "176959"
  },
  {
    "text": "uh this analysis has many steps but the the final step will be the end user analysis",
    "start": "176959",
    "end": "182560"
  },
  {
    "text": "where we generate plots like the one we see here which showed the peak",
    "start": "182560",
    "end": "187840"
  },
  {
    "text": "that gave us the higgs discovery back in 2012 and that led to the nobel prize in 2013.",
    "start": "187840",
    "end": "198879"
  },
  {
    "text": "so here to process all this data we need a large amount of computing resources we have our own",
    "start": "198879",
    "end": "204560"
  },
  {
    "text": "data center on premises that gives us something like 300 000 cores but we actually need more",
    "start": "204560",
    "end": "210000"
  },
  {
    "text": "capacity so over the last uh 20 years or so we've built this very large uh",
    "start": "210000",
    "end": "216319"
  },
  {
    "text": "grid computing infrastructure where we connected more than 200 sites around the world",
    "start": "216319",
    "end": "221599"
  },
  {
    "text": "and uh this acts like a giant supercomputer for our physicists at any moment you will see",
    "start": "221599",
    "end": "227599"
  },
  {
    "text": "something like 400 000 jobs running in this infrastructure and we have we",
    "start": "227599",
    "end": "233200"
  },
  {
    "text": "more than double the capacity we have on premises to close very close to 1 million cars these days",
    "start": "233200",
    "end": "240959"
  },
  {
    "text": "this is a one crucial part of our system to analyze the data and this",
    "start": "240959",
    "end": "247680"
  },
  {
    "text": "shows also how important it is to optimize the software distribution which is why we are doing this talk",
    "start": "247680",
    "end": "254319"
  },
  {
    "text": "today and how to describe to you how we used to do it and how we are",
    "start": "254319",
    "end": "259600"
  },
  {
    "text": "now doing it using containerized infrastructure infrastructures",
    "start": "259600",
    "end": "265280"
  },
  {
    "start": "265000",
    "end": "335000"
  },
  {
    "text": "so if we look a bit at what we used to do and we still do actually this is the",
    "start": "265280",
    "end": "271360"
  },
  {
    "text": "main way of distributing software in the in the grid we use this system called",
    "start": "271360",
    "end": "277120"
  },
  {
    "text": "cern vmfs it's a very scalable system to",
    "start": "277120",
    "end": "282880"
  },
  {
    "text": "distribute software in the grid and across all the sites it acts like a hierarchical",
    "start": "282880",
    "end": "288639"
  },
  {
    "text": "read-only file system where cern is the what we call the stratum zero or the top",
    "start": "288639",
    "end": "293919"
  },
  {
    "text": "of the hierarchy where we push all the software the experiments will do their releases and push software here",
    "start": "293919",
    "end": "299199"
  },
  {
    "text": "and then at each side we run this uh caches which are exposed to the users as",
    "start": "299199",
    "end": "304960"
  },
  {
    "text": "a read-only posix file systems in user space and we do very aggressive caching at this sites to optimize both the",
    "start": "304960",
    "end": "312080"
  },
  {
    "text": "network uh usage uh to towards these sites but also to speed up",
    "start": "312080",
    "end": "317520"
  },
  {
    "text": "the the start of the jobs uh making sure that only the data that is actually needed is is pushed to the to",
    "start": "317520",
    "end": "324080"
  },
  {
    "text": "the different sites on request this has been a very successful system and we",
    "start": "324080",
    "end": "330479"
  },
  {
    "text": "we use it intensively so when we start uh looking at containers it's kind of",
    "start": "330479",
    "end": "336720"
  },
  {
    "start": "335000",
    "end": "354000"
  },
  {
    "text": "very important to to make sure that we achieve the same efficiency so this was the big question",
    "start": "336720",
    "end": "342000"
  },
  {
    "text": "when people started containerizing their workloads and thinking about using containers we started thinking how can we rely",
    "start": "342000",
    "end": "350160"
  },
  {
    "text": "on something similar uh to to do the same for containers so there's a couple more questions that",
    "start": "350160",
    "end": "355759"
  },
  {
    "text": "come uh more detailed questions that come with this so if we think that",
    "start": "355759",
    "end": "361039"
  },
  {
    "text": "software packaging in container images it's pretty important how to speed up container creation if you",
    "start": "361039",
    "end": "366720"
  },
  {
    "text": "think that uh to start a container you need to pull the image uh and you consider that some of",
    "start": "366720",
    "end": "373039"
  },
  {
    "text": "our users have images that are uh several gigabytes or even tens of gigabytes uh this can take uh uh quite a while",
    "start": "373039",
    "end": "380080"
  },
  {
    "text": "especially if you if you have large clusters where we might you might need to pull these images",
    "start": "380080",
    "end": "387280"
  },
  {
    "text": "in in many different instances at the same time this puts not only slows down the job start but",
    "start": "387280",
    "end": "393840"
  },
  {
    "text": "also puts a lot of loading in our system so how can we reduce and optimize network usage",
    "start": "393840",
    "end": "400319"
  },
  {
    "text": "um we knew how to do this already with something like caching with cpmfs",
    "start": "400319",
    "end": "405360"
  },
  {
    "text": "and then if you think of cluster auto scaling which is something that we try to explore as much as possible we have to think",
    "start": "405360",
    "end": "413360"
  },
  {
    "text": "if if we are handling huge images and we are constantly dropping and creating new nodes",
    "start": "413360",
    "end": "419039"
  },
  {
    "text": "then we'll be on this cycle of having to pull new images constantly because the nodes",
    "start": "419039",
    "end": "424720"
  },
  {
    "text": "are are just fresh so all of this is quite important and this is what triggered all",
    "start": "424720",
    "end": "430639"
  },
  {
    "text": "all the work that we're describing today so there's some history on on before what we will present here",
    "start": "430639",
    "end": "438560"
  },
  {
    "start": "431000",
    "end": "474000"
  },
  {
    "text": "so back in 2016 16 at fast a system called slacker was presented",
    "start": "438560",
    "end": "444960"
  },
  {
    "text": "that allowed fast distribution of uh docker containers and introduced this",
    "start": "444960",
    "end": "450479"
  },
  {
    "text": "idea of laser loading of docker container images uh the cvmfs team took this idea and implemented the",
    "start": "450479",
    "end": "456960"
  },
  {
    "text": "docker cvm fest graph graph dyra this worked very well while we were using docker but when",
    "start": "456960",
    "end": "463759"
  },
  {
    "text": "the components started being split then we couldn't use the graph driver any",
    "start": "463759",
    "end": "469599"
  },
  {
    "text": "longer and we had to look at other runtimes that were appearing",
    "start": "469599",
    "end": "474879"
  },
  {
    "start": "474000",
    "end": "501000"
  },
  {
    "text": "so with this i will pass to spirus that will focus on describing how lazy lazy",
    "start": "474879",
    "end": "480800"
  },
  {
    "text": "pulling is working",
    "start": "480800",
    "end": "493120"
  },
  {
    "text": "thank you ricardo i think i managed to share my screen uh so yeah i will be talking now about",
    "start": "493120",
    "end": "499680"
  },
  {
    "text": "uh lazy pulling um building on the history that ricardo already mentioned",
    "start": "499680",
    "end": "506000"
  },
  {
    "text": "there is some ongoing work work already the cvmfs developers",
    "start": "506000",
    "end": "513599"
  },
  {
    "text": "have already started implementing a container d remote sound software based on",
    "start": "513599",
    "end": "519839"
  },
  {
    "text": "and this is still work in progress but in this presentation i will focus on",
    "start": "519839",
    "end": "526560"
  },
  {
    "text": "another implementation that started by the container the authors based on a strategy set and we",
    "start": "526560",
    "end": "533519"
  },
  {
    "text": "will also do a demo with a distributed hierarchy of container registries",
    "start": "533519",
    "end": "540399"
  },
  {
    "text": "so what is a remote snapshotter and what is star gz",
    "start": "540399",
    "end": "545519"
  },
  {
    "text": "back in 2019 um the every group of the contender the",
    "start": "546000",
    "end": "551839"
  },
  {
    "text": "authors had some brainstorm sessions to implement remote snapshotting and they came up",
    "start": "551839",
    "end": "558399"
  },
  {
    "text": "with uh with an api based on a",
    "start": "558399",
    "end": "563519"
  },
  {
    "text": "grpc api for a plugable remote snapshotters and the first implementation came from",
    "start": "563519",
    "end": "570640"
  },
  {
    "text": "ntt and the kohito konag and the hiroshida that was based on estradized estradiol",
    "start": "570640",
    "end": "577839"
  },
  {
    "text": "stands for seekable target and it's extending the properties of",
    "start": "577839",
    "end": "585760"
  },
  {
    "text": "turbos that make up container images so a very interesting um",
    "start": "585760",
    "end": "592800"
  },
  {
    "text": "property that terribles have is that if you concatenate or append many terribles and",
    "start": "592800",
    "end": "600640"
  },
  {
    "text": "one after the other there's still a validable so based on this idea",
    "start": "600640",
    "end": "605840"
  },
  {
    "text": "[Music] some developers at google to improve",
    "start": "605840",
    "end": "611040"
  },
  {
    "text": "the performance of a golden golang build system proposed the cfs and",
    "start": "611040",
    "end": "618320"
  },
  {
    "text": "implement it a proposed estrogen protocol",
    "start": "618320",
    "end": "623440"
  },
  {
    "text": "and so what this snapshot does it indexes all the files in all the layers and it creates a see",
    "start": "623440",
    "end": "630959"
  },
  {
    "text": "something similar to the manifest of a container image to where all these files exist in every",
    "start": "630959",
    "end": "637680"
  },
  {
    "text": "layer and then it mounts it is a fuse mount for every every layer from the container registry",
    "start": "637680",
    "end": "644320"
  },
  {
    "text": "and to the host leveraging uh remote um leveraging uh range queries uh arranged",
    "start": "644320",
    "end": "651920"
  },
  {
    "text": "hdb queries registry and as i mentioned that this is a jbc plugin",
    "start": "651920",
    "end": "657600"
  },
  {
    "text": "i configured them and in every node and container d communicates to it",
    "start": "657600",
    "end": "663200"
  },
  {
    "text": "via socket so this is more like a visual representation of it and so on the left side we have",
    "start": "663200",
    "end": "670399"
  },
  {
    "text": "the container registry on the right side a node that pulls images so on the left you can see that we have",
    "start": "670399",
    "end": "678399"
  },
  {
    "text": "the hierarchy that under v2 in the register path we have",
    "start": "678480",
    "end": "684079"
  },
  {
    "text": "every layer as a blob and on the right side we can see that we have container d",
    "start": "684079",
    "end": "689600"
  },
  {
    "text": "communicating with the snapshotter and the samsung creates a fuse mount um",
    "start": "689600",
    "end": "695200"
  },
  {
    "text": "for every for every layer and then it creates an an overlay file system where the root",
    "start": "695200",
    "end": "700480"
  },
  {
    "text": "effects of the image is where the container starts",
    "start": "700480",
    "end": "705680"
  },
  {
    "start": "704000",
    "end": "860000"
  },
  {
    "text": "and to demonstrate how this works we run some experiments with a very big",
    "start": "706320",
    "end": "712240"
  },
  {
    "text": "image produced by the atlas experiment called athena and athena is um",
    "start": "712240",
    "end": "719920"
  },
  {
    "text": "this this athena is a full release that is made up of uh 17 17.2 gigabytes",
    "start": "720000",
    "end": "727920"
  },
  {
    "text": "uncompressed and the 5.4 gigabytes compressed and below you can see",
    "start": "727920",
    "end": "736320"
  },
  {
    "text": "an optimized image for start digit that turns into a file",
    "start": "736320",
    "end": "743040"
  },
  {
    "text": "a turns every file into another turbo so as you can see the size increases a",
    "start": "743040",
    "end": "750399"
  },
  {
    "text": "bit because we have the additional size of the header of every turbo",
    "start": "750399",
    "end": "756560"
  },
  {
    "text": "so for the for this experiment we run a simple workload uh to analyze an event",
    "start": "756560",
    "end": "763519"
  },
  {
    "text": "uh an lh event so here in the first row we have uh the native execution with uh just",
    "start": "763519",
    "end": "770399"
  },
  {
    "text": "the native continuity overlayfest implementation and we can see the pulling time is uh",
    "start": "770399",
    "end": "778560"
  },
  {
    "text": "an optimistic three point three minutes uh three and a half minutes uh time while",
    "start": "778560",
    "end": "784880"
  },
  {
    "text": "in strategy is a flat 15 to 17 seconds",
    "start": "784880",
    "end": "790560"
  },
  {
    "text": "and then you can also see that most more importantly for network ingress and in the case of the",
    "start": "790560",
    "end": "798000"
  },
  {
    "text": "native implementation of container d we pull almost 6 gigabytes of data",
    "start": "798000",
    "end": "803440"
  },
  {
    "text": "while we start design we pull exactly the files that we need and we have less than one gigabyte and",
    "start": "803440",
    "end": "811440"
  },
  {
    "text": "a very big benefit of that is that um of the implementation of the snapshotter",
    "start": "811440",
    "end": "816480"
  },
  {
    "text": "is that while we lazy pull all the files that on the time that we need",
    "start": "816480",
    "end": "822480"
  },
  {
    "text": "we don't lose a lot of performance so the the execution time and of the",
    "start": "822480",
    "end": "828800"
  },
  {
    "text": "workload with the strategy set is just one minute uh slower than the native one so if we add",
    "start": "828800",
    "end": "835760"
  },
  {
    "text": "up the pulling time uh executing with a strategy zed it's faster so to summarize we have like",
    "start": "835760",
    "end": "843600"
  },
  {
    "text": "very very fast startup time low network traffic and the memory consumption for the snapshot",
    "start": "843600",
    "end": "849120"
  },
  {
    "text": "is a little concerning but something we can investigate and the drawback is that to build this",
    "start": "849120",
    "end": "855920"
  },
  {
    "text": "optimized image you need a lot of time in this case it was 45 minutes",
    "start": "855920",
    "end": "861760"
  },
  {
    "start": "860000",
    "end": "1023000"
  },
  {
    "text": "and to demonstrate this um like more in practice i will do a quick demo",
    "start": "861760",
    "end": "868959"
  },
  {
    "text": "and so here i have one container that runs the container d and the stamp setter and then auxiliary",
    "start": "869519",
    "end": "874720"
  },
  {
    "text": "center set container so we will see um",
    "start": "874720",
    "end": "881120"
  },
  {
    "text": "an example image that i have",
    "start": "882240",
    "end": "886880"
  },
  {
    "text": "so this is a docker file that pull that base is on python 3.9 and that's a",
    "start": "890800",
    "end": "896560"
  },
  {
    "text": "simple hello pie file that just prints hello and i will just go and build it but i have",
    "start": "896560",
    "end": "903600"
  },
  {
    "text": "it already built and then i can assume that i can push",
    "start": "903600",
    "end": "908720"
  },
  {
    "text": "to registry and what i will show you in in the other screen is that i can just",
    "start": "908720",
    "end": "915440"
  },
  {
    "text": "optimize it and then try to lazy pull it so in in this case i have already",
    "start": "915440",
    "end": "921760"
  },
  {
    "text": "optimized it but uh so now i will just try to pull the image",
    "start": "921760",
    "end": "927120"
  },
  {
    "text": "but not the full image and just do a few months a day that i described",
    "start": "927120",
    "end": "934320"
  },
  {
    "text": "and here you can see that it downloads the manifest of the image and the index",
    "start": "935040",
    "end": "941279"
  },
  {
    "text": "of all the files and in just uh in a flat time of six seconds sometimes it's five",
    "start": "941279",
    "end": "947519"
  },
  {
    "text": "but it's much faster than a normal image and then they will also go ahead and",
    "start": "947519",
    "end": "954240"
  },
  {
    "text": "download the massive image of the described and you will see that the cooling time is just a little",
    "start": "954240",
    "end": "960399"
  },
  {
    "text": "more uh than the standard than a simple python image and while it's downloading",
    "start": "960399",
    "end": "968560"
  },
  {
    "text": "i will also show you that i have docker stats running to monitor the traffic",
    "start": "968560",
    "end": "974320"
  },
  {
    "text": "of container d so here you can see that",
    "start": "974320",
    "end": "980800"
  },
  {
    "text": "the i o of them the container d demo container was only 30 megabytes",
    "start": "980800",
    "end": "987360"
  },
  {
    "text": "and here you can see that in 16 seconds it managed to download the image finally",
    "start": "987360",
    "end": "993839"
  },
  {
    "text": "i would like to show you that this is the original image built from",
    "start": "993839",
    "end": "999839"
  },
  {
    "text": "atlas and it has 14 layers and this is the optimized image that they created again comprised by 14",
    "start": "999839",
    "end": "1005680"
  },
  {
    "text": "layers but now you can see that the signatures of the layers are",
    "start": "1005680",
    "end": "1011120"
  },
  {
    "text": "different back to ricardo to talk to you about",
    "start": "1011120",
    "end": "1017360"
  },
  {
    "text": "the demo that i described about hierarchical registries",
    "start": "1017759",
    "end": "1024400"
  },
  {
    "text": "okay thanks beerus i'll just hide here my bar",
    "start": "1024400",
    "end": "1031360"
  },
  {
    "text": "so uh spearows explained um all the points can you hear me spirus",
    "start": "1031360",
    "end": "1037600"
  },
  {
    "text": "explained all the all the points of uh why we are doing this lazy pulling uh by showing uh",
    "start": "1037600",
    "end": "1043360"
  },
  {
    "text": "an example with uh with a couple of images uh well uh what we'll try to explain now",
    "start": "1043360",
    "end": "1050160"
  },
  {
    "text": "is how we are deploying this uh as in our infrastructure so uh coming back",
    "start": "1050160",
    "end": "1056880"
  },
  {
    "text": "to [Music] coming back to uh the initial slide that i showed",
    "start": "1056880",
    "end": "1062480"
  },
  {
    "start": "1059000",
    "end": "1093000"
  },
  {
    "text": "which was uh how we are doing today the software distribution we rely on certain vmfs so",
    "start": "1062480",
    "end": "1069120"
  },
  {
    "text": "this is a system that we are uh very happy with it works very well so",
    "start": "1069120",
    "end": "1076320"
  },
  {
    "text": "one option is to rely on on the implementation of a remote snapshot of",
    "start": "1076320",
    "end": "1081520"
  },
  {
    "text": "relying on this system and this is something that is happening as we mentioned earlier",
    "start": "1081520",
    "end": "1086960"
  },
  {
    "text": "and something that can work very well what we will try also to demo today is uh something that",
    "start": "1086960",
    "end": "1093280"
  },
  {
    "text": "could be more generic which is to rely on the a couple of registries uh distributed registry so",
    "start": "1093280",
    "end": "1100240"
  },
  {
    "text": "instead of just relying on the file system and http caches really relying on the implementation of the container",
    "start": "1100240",
    "end": "1106240"
  },
  {
    "text": "registries the implementation is up to",
    "start": "1106240",
    "end": "1111280"
  },
  {
    "text": "to to you uh which one to choose in in the demo today i will be using harper",
    "start": "1111280",
    "end": "1116400"
  },
  {
    "text": "which is also something we deploy here at cern and the the way it works is very similar to",
    "start": "1116400",
    "end": "1122000"
  },
  {
    "text": "what we saw for cvmfs which is a hierarchical model with cern being at the top of the",
    "start": "1122000",
    "end": "1128240"
  },
  {
    "text": "hierarchy where we push the images and then at each side",
    "start": "1128240",
    "end": "1133360"
  },
  {
    "text": "we can run another registry that can be configured as a proxy cache so that",
    "start": "1133360",
    "end": "1139280"
  },
  {
    "text": "if people pull the image it will first cache it and the second poll will be much faster or just configured with replication by",
    "start": "1139280",
    "end": "1146000"
  },
  {
    "text": "using some pattern to decide which which images and tags should be pushed along to the sites it's very important",
    "start": "1146000",
    "end": "1153600"
  },
  {
    "text": "that it has proper star gz support and estrogen as spirit showed",
    "start": "1153600",
    "end": "1159120"
  },
  {
    "text": "for performance and also one benefit of using this is that any oci artifact if if you have an oci",
    "start": "1159120",
    "end": "1165919"
  },
  {
    "text": "uh registry it can be pushed it's not only docker images you can use to to push home charts or ml",
    "start": "1165919",
    "end": "1172400"
  },
  {
    "text": "artifacts containing model data or weights uh so in the in the picture on the right",
    "start": "1172400",
    "end": "1179120"
  },
  {
    "text": "you see what we'll try to do in the level which is we have cern with the registry and then we have two regions deployed in",
    "start": "1179120",
    "end": "1186480"
  },
  {
    "text": "this case in the google cloud uh we have a cluster running on us central sea",
    "start": "1186480",
    "end": "1192080"
  },
  {
    "text": "and a cluster running in the netherlands so we have two clusters in different continents and then each one has its own register",
    "start": "1192080",
    "end": "1198880"
  },
  {
    "text": "so this is the hardware registry running on the u.s central this is the harbor registry on the netherlands and each one has a",
    "start": "1198880",
    "end": "1205200"
  },
  {
    "text": "cluster running with five nodes that will try to run some some user analysis",
    "start": "1205200",
    "end": "1210400"
  },
  {
    "text": "and they will use their local registries that then can can point to the top so i will now jump to the demo",
    "start": "1210400",
    "end": "1218400"
  },
  {
    "start": "1216000",
    "end": "1308000"
  },
  {
    "text": "and uh here is the deployment of my two harbor uh instances the one on the left is the",
    "start": "1218400",
    "end": "1223760"
  },
  {
    "text": "one we have in the netherlands uh this one and the one on the right is the one we have in the u.s central region",
    "start": "1223760",
    "end": "1230720"
  },
  {
    "text": "so i'll just browse through you can see here they are very they are exactly the same",
    "start": "1230720",
    "end": "1236480"
  },
  {
    "text": "configuration and this is the the way we will deploy so that all the sites feel kind of the same and",
    "start": "1236480",
    "end": "1242720"
  },
  {
    "text": "then you can have multiple projects in this case i have a cern cache which is a proxy cache and it's linked to the",
    "start": "1242720",
    "end": "1248720"
  },
  {
    "text": "cern registry so whenever you pull from from this prefix it will just pull the",
    "start": "1248720",
    "end": "1253840"
  },
  {
    "text": "image from the from the certain cache and then you have docker io just for convenience as another cache and then we have this",
    "start": "1253840",
    "end": "1260960"
  },
  {
    "text": "star gz that is configured as a replicated instance so we have a configure that it should replicate",
    "start": "1260960",
    "end": "1266559"
  },
  {
    "text": "everything that is in this uh in this uh prefix satsang including the",
    "start": "1266559",
    "end": "1272240"
  },
  {
    "text": "athena image so the way this works for the proxy caches is that you define two registries",
    "start": "1272240",
    "end": "1278159"
  },
  {
    "text": "and it controls the health and then for the replicated one we just define replication rules and you can see",
    "start": "1278159",
    "end": "1284240"
  },
  {
    "text": "here that uh we just we had here a successful replication a previous one",
    "start": "1284240",
    "end": "1290159"
  },
  {
    "text": "was not successful you can decide to trigger this manually or you can decide to to make it scheduled like every hour or",
    "start": "1290159",
    "end": "1296400"
  },
  {
    "text": "every couple of minutes this this is the way we structure so",
    "start": "1296400",
    "end": "1302320"
  },
  {
    "text": "after this uh this overview i will try to submit um",
    "start": "1302320",
    "end": "1307919"
  },
  {
    "text": "a workload so the workload is uh is uh very similar uh to to what our",
    "start": "1307919",
    "end": "1315600"
  },
  {
    "start": "1308000",
    "end": "1505000"
  },
  {
    "text": "our users do just in this case i will be using argo workflows which is kind of a",
    "start": "1315600",
    "end": "1321360"
  },
  {
    "text": "new tool that most users are not using but what this will do is it will submit",
    "start": "1321360",
    "end": "1326960"
  },
  {
    "text": "the same workload to two different clusters to the two different clusters but on the left one",
    "start": "1326960",
    "end": "1332000"
  },
  {
    "text": "in the netherlands i'm using es rgz deployments so you can see here",
    "start": "1332000",
    "end": "1339760"
  },
  {
    "text": "the workload already starting and on the right i'm doing the same in u.s central but using uh a",
    "start": "1339760",
    "end": "1346240"
  },
  {
    "text": "normal uh non-starchy set image and you can see that on the left we already started the",
    "start": "1346240",
    "end": "1351520"
  },
  {
    "text": "workflow while on the right is still in the first step of preparing it because it has to download",
    "start": "1351520",
    "end": "1356640"
  },
  {
    "text": "every step downloads the same image the same athena image and it takes quite a bit longer so we",
    "start": "1356640",
    "end": "1361840"
  },
  {
    "text": "can see that in the netherlands we our our workflow is already going uh pretty fast",
    "start": "1361840",
    "end": "1367760"
  },
  {
    "text": "and uh executing some steps each each what we do here is we parallelize the",
    "start": "1367760",
    "end": "1372960"
  },
  {
    "text": "job into 20 different parallel jobs and each job has three steps",
    "start": "1372960",
    "end": "1378240"
  },
  {
    "text": "one for staging in one for processing and eventually we'll have staging out when when the processing",
    "start": "1378240",
    "end": "1383919"
  },
  {
    "text": "stops while we see this uh this job with star gz going really fast and some",
    "start": "1383919",
    "end": "1391679"
  },
  {
    "text": "of the jobs even already pushing data out the netherlands the one in u.s central which is using",
    "start": "1391679",
    "end": "1398640"
  },
  {
    "text": "the normal images is just starting to launch its job so it's way behind",
    "start": "1398640",
    "end": "1404559"
  },
  {
    "text": "and we can see here that uh in just a couple of seconds or or so we'll be using we'll we'll be",
    "start": "1404559",
    "end": "1411039"
  },
  {
    "text": "having this workflow completed so this is this is uh kind of critical for us you can see the",
    "start": "1411039",
    "end": "1417600"
  },
  {
    "text": "benefit when you start paralyzing uh the job and especially as i mentioned when you have uh",
    "start": "1417600",
    "end": "1424000"
  },
  {
    "text": "like uh enabled cluster auto scaling and some nodes might come and go it's really really important that you",
    "start": "1424000",
    "end": "1430480"
  },
  {
    "text": "don't have to pull them at the full image every time if your job is just using a small",
    "start": "1430480",
    "end": "1436000"
  },
  {
    "text": "fraction of the image which is the case here the images are 18 gigabytes but its job is is just pulling",
    "start": "1436000",
    "end": "1442000"
  },
  {
    "text": "a very small fraction so we can see here that uh our u.s central the non-star gz is uh",
    "start": "1442000",
    "end": "1449919"
  },
  {
    "text": "is still behind but moving this one is almost finished so if we do it leave it",
    "start": "1449919",
    "end": "1455919"
  },
  {
    "text": "a couple more seconds we might even be able to see it finishing",
    "start": "1455919",
    "end": "1461840"
  },
  {
    "text": "so i'll just give it a couple seconds uh one one thing that",
    "start": "1462480",
    "end": "1468880"
  },
  {
    "text": "i will also want to show you is that in this case for every node it's pulling the image once so it's",
    "start": "1468880",
    "end": "1474720"
  },
  {
    "text": "putting a lot of stress on the on the storage where the container images are are being",
    "start": "1474720",
    "end": "1480080"
  },
  {
    "text": "put so in this in our case we have our hardware instance that is backed by a gcs bucket so we are",
    "start": "1480080",
    "end": "1487440"
  },
  {
    "text": "actually putting load on the gcs bucket so our our uh optimized uh",
    "start": "1487440",
    "end": "1492960"
  },
  {
    "text": "srgz based workflow is already finished this one is uh almost like halfway let's say so it's",
    "start": "1492960",
    "end": "1499440"
  },
  {
    "text": "it's it's a significant advantage if if you start scaling out so the last bit",
    "start": "1499440",
    "end": "1504960"
  },
  {
    "text": "i would like to show you uh is this uh this traffic that i mentioned so",
    "start": "1504960",
    "end": "1510159"
  },
  {
    "start": "1505000",
    "end": "1574000"
  },
  {
    "text": "again on the left you have the the netherlands west 4 european region",
    "start": "1510159",
    "end": "1516880"
  },
  {
    "text": "i'll just refresh here the data but i'll try to show you hopefully we'll see some data about",
    "start": "1516880",
    "end": "1524879"
  },
  {
    "text": "the traffic being pushed put or the load being put on the gcs pocket",
    "start": "1526000",
    "end": "1532400"
  },
  {
    "text": "so there we go so in this case we see here the bucket is us central um it's loading here",
    "start": "1532400",
    "end": "1541520"
  },
  {
    "text": "and we can see the network traffic sent because it's serving the data and we see here the equivalent",
    "start": "1541520",
    "end": "1548880"
  },
  {
    "text": "on the on the netherlands region so you can see here that we picked that",
    "start": "1548880",
    "end": "1554080"
  },
  {
    "text": "several tens of megabytes per second something like 80 megabytes while here",
    "start": "1554080",
    "end": "1559760"
  },
  {
    "text": "uh this hardly has a peak because we physically downloaded very little data",
    "start": "1559760",
    "end": "1565360"
  },
  {
    "text": "in this case for this end user analysis there was a very very small fraction of the image being used",
    "start": "1565360",
    "end": "1571039"
  },
  {
    "text": "so that's it for the demo and i will pass back to spiros for for",
    "start": "1571039",
    "end": "1576960"
  },
  {
    "start": "1574000",
    "end": "1655000"
  },
  {
    "text": "the rest of the talk",
    "start": "1576960",
    "end": "1585840"
  },
  {
    "text": "okay uh thanks to cardo um so the status uh the current status",
    "start": "1588320",
    "end": "1595200"
  },
  {
    "text": "of the snapshotter is that although it's in its first stages is",
    "start": "1595200",
    "end": "1600480"
  },
  {
    "text": "very much very much functional and we can achieve super fast container",
    "start": "1600480",
    "end": "1607120"
  },
  {
    "text": "startup times we can dramatically reduce the natural usage as a regard showed and also the",
    "start": "1607120",
    "end": "1614720"
  },
  {
    "text": "constitution in case that you use the public cloud and as we saw in the",
    "start": "1614720",
    "end": "1622720"
  },
  {
    "text": "example that we did with athena the cpu overhead is very little and overall there is a big gain",
    "start": "1622720",
    "end": "1630960"
  },
  {
    "text": "cpu wise and also network wise and just limitation that we found in our",
    "start": "1631440",
    "end": "1639120"
  },
  {
    "text": "own github registry that we used before starting",
    "start": "1639120",
    "end": "1645070"
  },
  {
    "text": "[Music] leveraging harbor is that there is a strong requirement for strategizing",
    "start": "1645070",
    "end": "1651360"
  },
  {
    "text": "support http range queries and in our case it's not supported",
    "start": "1651360",
    "end": "1656480"
  },
  {
    "start": "1655000",
    "end": "1743000"
  },
  {
    "text": "improvements that we would like to see we would like to see for starting zed is the speed up of image optimization",
    "start": "1656720",
    "end": "1664880"
  },
  {
    "text": "and in case of athena i took 45 minutes in other images it might take",
    "start": "1664880",
    "end": "1670240"
  },
  {
    "text": "even longer additionally what would be very important for us is to be able to",
    "start": "1670240",
    "end": "1676960"
  },
  {
    "text": "create optimized images that are based on already optimized images so just",
    "start": "1676960",
    "end": "1683919"
  },
  {
    "text": "optimizing uh install dz the additional layers and finally",
    "start": "1683919",
    "end": "1690480"
  },
  {
    "text": "what we would like to see also is that being able to optimize images with some existing",
    "start": "1690480",
    "end": "1696080"
  },
  {
    "text": "data so instead of cramming data inside the image maybe we could just mount them and if we",
    "start": "1696080",
    "end": "1701760"
  },
  {
    "text": "have workloads um that we expect to have and we have a sample workload we can",
    "start": "1701760",
    "end": "1707440"
  },
  {
    "text": "optimize the image with the same workload and then um have an image which is very much well",
    "start": "1707440",
    "end": "1713919"
  },
  {
    "text": "prepared for for the actual workloads some small issues that we found",
    "start": "1713919",
    "end": "1719360"
  },
  {
    "text": "uh is that container d doesn't gracefully fall back to the standard",
    "start": "1719360",
    "end": "1724640"
  },
  {
    "text": "uh snapshotting if the remote sensor is down whichever snapshot or that is and i",
    "start": "1724640",
    "end": "1730880"
  },
  {
    "text": "would also like to do some further investigations in the hub in our hardware configuration because",
    "start": "1730880",
    "end": "1736320"
  },
  {
    "text": "we hit some limitations with flash layers and the snare shutter was not behaving in the way we would like um",
    "start": "1736320",
    "end": "1744559"
  },
  {
    "start": "1743000",
    "end": "1802000"
  },
  {
    "text": "i also would like to thank the team from ntt here and kohi uh",
    "start": "1744559",
    "end": "1750720"
  },
  {
    "text": "siemens team for the cern cloud team and all the participants that made",
    "start": "1750720",
    "end": "1756559"
  },
  {
    "text": "this possible cartoon do you want to say some closing remarks as well",
    "start": "1756559",
    "end": "1763120"
  },
  {
    "text": "no again yeah thanks uh everyone also for watching and thanks to for everyone to that has been working on",
    "start": "1763120",
    "end": "1769919"
  },
  {
    "text": "this this is uh one of the key points that will help us uh",
    "start": "1769919",
    "end": "1775120"
  },
  {
    "text": "making the best use of containers also on the grid not just at the local sites so",
    "start": "1775120",
    "end": "1780480"
  },
  {
    "text": "yeah i would also highlight that this is the work of",
    "start": "1780480",
    "end": "1785520"
  },
  {
    "text": "a lot of people uh we had a workshop in may last year that kind of triggered a lot of this here at",
    "start": "1785520",
    "end": "1792399"
  },
  {
    "text": "cern with people from from different companies around the world so yeah we look forward to continuing",
    "start": "1792399",
    "end": "1798720"
  },
  {
    "text": "improving the system and thank you very much",
    "start": "1798720",
    "end": "1803919"
  }
]
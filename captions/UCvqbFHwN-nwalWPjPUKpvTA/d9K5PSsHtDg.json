[
  {
    "text": "hi my name is Susan Woo Thanks for",
    "start": "160",
    "end": "2240"
  },
  {
    "text": "staying back on Friday to hear from us",
    "start": "2240",
    "end": "5279"
  },
  {
    "text": "Um I'm Susan Woo I'm out in the pro I'm",
    "start": "5279",
    "end": "8160"
  },
  {
    "text": "a product manager in Google Cloud I",
    "start": "8160",
    "end": "10880"
  },
  {
    "text": "focus on cloud networking GKE networking",
    "start": "10880",
    "end": "14400"
  },
  {
    "text": "network security We all wear a lot of",
    "start": "14400",
    "end": "16720"
  },
  {
    "text": "hats here at Google Thank you So with me",
    "start": "16720",
    "end": "19600"
  },
  {
    "text": "I have my panel a steam panel Uh we're",
    "start": "19600",
    "end": "22240"
  },
  {
    "text": "talking about extending Kubernetes for",
    "start": "22240",
    "end": "24320"
  },
  {
    "text": "AI So come on up",
    "start": "24320",
    "end": "28439"
  },
  {
    "text": "Thank you very much We have no uh",
    "start": "30560",
    "end": "32640"
  },
  {
    "text": "walk-on music Thank you",
    "start": "32640",
    "end": "36800"
  },
  {
    "text": "So with that I'm going to let the",
    "start": "36800",
    "end": "38160"
  },
  {
    "text": "panelists introduce themselves They're",
    "start": "38160",
    "end": "40000"
  },
  {
    "text": "all miked up and ready Cool Thank you Um",
    "start": "40000",
    "end": "43840"
  },
  {
    "text": "yeah hi my name is co-founder and CTO of",
    "start": "43840",
    "end": "46719"
  },
  {
    "text": "Weeb8 Uh Weeb8 is a vector database",
    "start": "46719",
    "end": "49039"
  },
  {
    "text": "company or actually it's more of a of an",
    "start": "49039",
    "end": "51280"
  },
  {
    "text": "AI data platform these days but it",
    "start": "51280",
    "end": "53760"
  },
  {
    "text": "started out as a as a vector database",
    "start": "53760",
    "end": "55440"
  },
  {
    "text": "company And of course we run a lot of AI",
    "start": "55440",
    "end": "58000"
  },
  {
    "text": "workloads uh on Kubernetes",
    "start": "58000",
    "end": "61680"
  },
  {
    "text": "Hi Uh I'm the only one who wasn't miked",
    "start": "61680",
    "end": "63920"
  },
  {
    "text": "up We ran out of packs Uh but my name's",
    "start": "63920",
    "end": "66320"
  },
  {
    "text": "Lucy I'm a engineer at Uber where I work",
    "start": "66320",
    "end": "68720"
  },
  {
    "text": "on our platforms Uh we have a quite",
    "start": "68720",
    "end": "71920"
  },
  {
    "text": "substantial presence on Kubernetes We're",
    "start": "71920",
    "end": "73840"
  },
  {
    "text": "one of the biggest end user deployments",
    "start": "73840",
    "end": "75360"
  },
  {
    "text": "in the world which uh I'm sure we can",
    "start": "75360",
    "end": "77119"
  },
  {
    "text": "get into later And then we run a mix of",
    "start": "77119",
    "end": "79680"
  },
  {
    "text": "a IML workloads both for training and",
    "start": "79680",
    "end": "82320"
  },
  {
    "text": "for inference uh across non-critical",
    "start": "82320",
    "end": "84640"
  },
  {
    "text": "stuff but also in the core trip flow of",
    "start": "84640",
    "end": "86560"
  },
  {
    "text": "Uber",
    "start": "86560",
    "end": "88159"
  },
  {
    "text": "Good morning everyone My name is Andrea",
    "start": "88159",
    "end": "90880"
  },
  {
    "text": "I work for a company called Overstory We",
    "start": "90880",
    "end": "93759"
  },
  {
    "text": "do vegetation management using satellite",
    "start": "93759",
    "end": "95840"
  },
  {
    "text": "images Basically we use satellite images",
    "start": "95840",
    "end": "98000"
  },
  {
    "text": "to prevent wildfires And uh yeah I'm",
    "start": "98000",
    "end": "101040"
  },
  {
    "text": "here today to talk about how we use",
    "start": "101040",
    "end": "102560"
  },
  {
    "text": "Kubernetes in the cloud in Google Cloud",
    "start": "102560",
    "end": "105040"
  },
  {
    "text": "to yeah make sure all our clients get",
    "start": "105040",
    "end": "107040"
  },
  {
    "text": "their risk assessment on time using our",
    "start": "107040",
    "end": "109520"
  },
  {
    "text": "platform Um I'm Tim Wickberg I'm the",
    "start": "109520",
    "end": "113360"
  },
  {
    "text": "chief technical officer for Skidmd uh",
    "start": "113360",
    "end": "115600"
  },
  {
    "text": "were the principal slurm developers um",
    "start": "115600",
    "end": "118079"
  },
  {
    "text": "also now the developers of slinky which",
    "start": "118079",
    "end": "120000"
  },
  {
    "text": "is meant to be our set of integrations",
    "start": "120000",
    "end": "122000"
  },
  {
    "text": "for bringing slurm scheduling",
    "start": "122000",
    "end": "124159"
  },
  {
    "text": "wherewithal into the kubernetes stack",
    "start": "124159",
    "end": "127200"
  },
  {
    "text": "Okay Uh I got a couple of prepared",
    "start": "127200",
    "end": "129440"
  },
  {
    "text": "questions but I at some point I'll I'll",
    "start": "129440",
    "end": "131599"
  },
  {
    "text": "have folks come on to the microphone and",
    "start": "131599",
    "end": "133599"
  },
  {
    "text": "you can ask your questions directly Uh",
    "start": "133599",
    "end": "136239"
  },
  {
    "text": "so starting with Lucy you know for",
    "start": "136239",
    "end": "138480"
  },
  {
    "text": "platform engineers or infrastructure",
    "start": "138480",
    "end": "140760"
  },
  {
    "text": "engineers do do you typically provide",
    "start": "140760",
    "end": "143120"
  },
  {
    "text": "Kubernetes clusters for sort of",
    "start": "143120",
    "end": "145599"
  },
  {
    "text": "conventional uh microservices",
    "start": "145599",
    "end": "147760"
  },
  {
    "text": "orchestration or do you have dedicated",
    "start": "147760",
    "end": "149520"
  },
  {
    "text": "teams for a IML workloads so um our",
    "start": "149520",
    "end": "154160"
  },
  {
    "text": "approach is that we don't bad time for a",
    "start": "154160",
    "end": "157239"
  },
  {
    "text": "cough our approach is that we don't uh",
    "start": "157239",
    "end": "160160"
  },
  {
    "text": "directly offer what I would call maybe",
    "start": "160160",
    "end": "162319"
  },
  {
    "text": "Kubernetes as a service uh our worry is",
    "start": "162319",
    "end": "164879"
  },
  {
    "text": "that it's very expansive and it's very",
    "start": "164879",
    "end": "167519"
  },
  {
    "text": "powerful but at the same time it leaves",
    "start": "167519",
    "end": "169360"
  },
  {
    "text": "you with uh very little guard rails to",
    "start": "169360",
    "end": "171680"
  },
  {
    "text": "uh do things uh maybe the way we want We",
    "start": "171680",
    "end": "174239"
  },
  {
    "text": "want you to make do rollouts and",
    "start": "174239",
    "end": "175840"
  },
  {
    "text": "deployments in a safe way Uh we want you",
    "start": "175840",
    "end": "177760"
  },
  {
    "text": "to do them within at least some",
    "start": "177760",
    "end": "178879"
  },
  {
    "text": "safeguards that we as a company have So",
    "start": "178879",
    "end": "180959"
  },
  {
    "text": "we run a stateless compute platform that",
    "start": "180959",
    "end": "183440"
  },
  {
    "text": "uh users actually deploy their services",
    "start": "183440",
    "end": "184879"
  },
  {
    "text": "through and that gives them a lot of",
    "start": "184879",
    "end": "185920"
  },
  {
    "text": "stuff for free safe rollouts safe",
    "start": "185920",
    "end": "187760"
  },
  {
    "text": "deployment safe CD Uh our a IML",
    "start": "187760",
    "end": "190480"
  },
  {
    "text": "workloads are then actually built on top",
    "start": "190480",
    "end": "192000"
  },
  {
    "text": "of that uh there's a whole team of",
    "start": "192000",
    "end": "193920"
  },
  {
    "text": "engineers who build uh the platform for",
    "start": "193920",
    "end": "197040"
  },
  {
    "text": "uh folks to deploy things like pipelines",
    "start": "197040",
    "end": "199519"
  },
  {
    "text": "and uh training jobs and etc uh that is",
    "start": "199519",
    "end": "202560"
  },
  {
    "text": "then also uh wrapped in a little bit",
    "start": "202560",
    "end": "204959"
  },
  {
    "text": "more opinionation in that uh you have to",
    "start": "204959",
    "end": "207040"
  },
  {
    "text": "get your data source from certain places",
    "start": "207040",
    "end": "208879"
  },
  {
    "text": "etc Uh I'd say I think we have so I work",
    "start": "208879",
    "end": "212959"
  },
  {
    "text": "in Denmark and in our office we do",
    "start": "212959",
    "end": "214640"
  },
  {
    "text": "nothing but build platforms and we have",
    "start": "214640",
    "end": "216920"
  },
  {
    "text": "about 140 people in that office plus",
    "start": "216920",
    "end": "220239"
  },
  {
    "text": "probably like maybe another 20 plus",
    "start": "220239",
    "end": "222400"
  },
  {
    "text": "working on a IML in the US uh plus",
    "start": "222400",
    "end": "225200"
  },
  {
    "text": "another maybe 10 plus in the U 10 plus",
    "start": "225200",
    "end": "227760"
  },
  {
    "text": "scattered around the world as well Uh",
    "start": "227760",
    "end": "230000"
  },
  {
    "text": "but yeah it's a pretty substantial",
    "start": "230000",
    "end": "231440"
  },
  {
    "text": "presence of engineers just working on uh",
    "start": "231440",
    "end": "233599"
  },
  {
    "text": "these uh internal developer platforms Uh",
    "start": "233599",
    "end": "236080"
  },
  {
    "text": "do other folks want to weigh in",
    "start": "236080",
    "end": "238319"
  },
  {
    "text": "yeah I'd be be happy to go because",
    "start": "238319",
    "end": "240000"
  },
  {
    "text": "there's a nice contrast I think like 140",
    "start": "240000",
    "end": "242319"
  },
  {
    "text": "people that's more than our entire",
    "start": "242319",
    "end": "243680"
  },
  {
    "text": "company Um we do we do have a platform",
    "start": "243680",
    "end": "248000"
  },
  {
    "text": "team as well but from our perspective",
    "start": "248000",
    "end": "249680"
  },
  {
    "text": "the platform team is more about",
    "start": "249680",
    "end": "251439"
  },
  {
    "text": "provisioning the WV8 database for our",
    "start": "251439",
    "end": "253840"
  },
  {
    "text": "customers So it's essentially you could",
    "start": "253840",
    "end": "255040"
  },
  {
    "text": "say the platform team is what runs our",
    "start": "255040",
    "end": "257040"
  },
  {
    "text": "SAS So in in that sense um it's not so",
    "start": "257040",
    "end": "261600"
  },
  {
    "text": "much an internal team catering to",
    "start": "261600",
    "end": "263199"
  },
  {
    "text": "different teams with different workloads",
    "start": "263199",
    "end": "264880"
  },
  {
    "text": "but it's very much a a specialized uh",
    "start": "264880",
    "end": "267759"
  },
  {
    "text": "platform team that really just and it's",
    "start": "267759",
    "end": "270320"
  },
  {
    "text": "a bit oversimplified in saying it just",
    "start": "270320",
    "end": "271919"
  },
  {
    "text": "runs the we the WV8 database because of",
    "start": "271919",
    "end": "274800"
  },
  {
    "text": "course there's so many other things that",
    "start": "274800",
    "end": "275919"
  },
  {
    "text": "come with it be it observability and",
    "start": "275919",
    "end": "277919"
  },
  {
    "text": "then if we're talking AI and GPUs",
    "start": "277919",
    "end": "279680"
  },
  {
    "text": "there's different observability loads um",
    "start": "279680",
    "end": "282240"
  },
  {
    "text": "as well um but it's it it gives the team",
    "start": "282240",
    "end": "285520"
  },
  {
    "text": "much more of a focus compared to just",
    "start": "285520",
    "end": "287840"
  },
  {
    "text": "any AI workload popping up anywhere in",
    "start": "287840",
    "end": "290160"
  },
  {
    "text": "the company",
    "start": "290160",
    "end": "292639"
  },
  {
    "text": "Anybody else yeah just wanted to add",
    "start": "292639",
    "end": "294560"
  },
  {
    "text": "it's actually very interesting It's a",
    "start": "294560",
    "end": "295919"
  },
  {
    "text": "point that I've been hearing about more",
    "start": "295919",
    "end": "297840"
  },
  {
    "text": "and more over the last couple of days",
    "start": "297840",
    "end": "299360"
  },
  {
    "text": "that the concept of like platform",
    "start": "299360",
    "end": "301199"
  },
  {
    "text": "engineering and platform team changes a",
    "start": "301199",
    "end": "302960"
  },
  {
    "text": "lot So of course like platform",
    "start": "302960",
    "end": "304320"
  },
  {
    "text": "engineering in Uber is different the one",
    "start": "304320",
    "end": "306479"
  },
  {
    "text": "in weate and it's different the one that",
    "start": "306479",
    "end": "308160"
  },
  {
    "text": "we have at overstore which is a much",
    "start": "308160",
    "end": "309759"
  },
  {
    "text": "smaller startup and so it's also you",
    "start": "309759",
    "end": "312000"
  },
  {
    "text": "know the task of the company and the",
    "start": "312000",
    "end": "313360"
  },
  {
    "text": "team to adapt to you know what are the",
    "start": "313360",
    "end": "315759"
  },
  {
    "text": "use cases of the business to build a",
    "start": "315759",
    "end": "317520"
  },
  {
    "text": "platform team that fits the company uh",
    "start": "317520",
    "end": "319919"
  },
  {
    "text": "rather than a company that fits the",
    "start": "319919",
    "end": "321120"
  },
  {
    "text": "platform team that doesn't really work",
    "start": "321120",
    "end": "322560"
  },
  {
    "text": "right Tim did you want uh no I guess I",
    "start": "322560",
    "end": "326080"
  },
  {
    "text": "don't have much to contribute there I",
    "start": "326080",
    "end": "327360"
  },
  {
    "text": "guess we're we're a tooling vendor at at",
    "start": "327360",
    "end": "329600"
  },
  {
    "text": "our heart so we don't actually have our",
    "start": "329600",
    "end": "330960"
  },
  {
    "text": "own platforms to maintain fortunately",
    "start": "330960",
    "end": "332800"
  },
  {
    "text": "Definitely",
    "start": "332800",
    "end": "335120"
  },
  {
    "text": "Actually we're talking about",
    "start": "335120",
    "end": "336440"
  },
  {
    "text": "customization extending Kubernetes So uh",
    "start": "336440",
    "end": "339680"
  },
  {
    "text": "maybe starting with Andrea What kind of",
    "start": "339680",
    "end": "341440"
  },
  {
    "text": "customizations have you seen uh you know",
    "start": "341440",
    "end": "343680"
  },
  {
    "text": "that people have been doing and if you",
    "start": "343680",
    "end": "345919"
  },
  {
    "text": "have any adjacent projects that you've",
    "start": "345919",
    "end": "348160"
  },
  {
    "text": "seen people bring in to Kubernetes uh",
    "start": "348160",
    "end": "350639"
  },
  {
    "text": "feel free to talk about that as well as",
    "start": "350639",
    "end": "352560"
  },
  {
    "text": "they build out the data pipeline Yeah",
    "start": "352560",
    "end": "355039"
  },
  {
    "text": "absolutely So as I was mentioning before",
    "start": "355039",
    "end": "357199"
  },
  {
    "text": "what we do over story is uh uh",
    "start": "357199",
    "end": "359600"
  },
  {
    "text": "vegetation management So basically what",
    "start": "359600",
    "end": "361600"
  },
  {
    "text": "we do is that we get satellite images",
    "start": "361600",
    "end": "364400"
  },
  {
    "text": "from satellite provider like Airbus or",
    "start": "364400",
    "end": "367440"
  },
  {
    "text": "MAC or Maxer and so on and basically we",
    "start": "367440",
    "end": "371199"
  },
  {
    "text": "merge that information with information",
    "start": "371199",
    "end": "373600"
  },
  {
    "text": "that we get from utility provider",
    "start": "373600",
    "end": "376080"
  },
  {
    "text": "basically the folks that bring energy",
    "start": "376080",
    "end": "378160"
  },
  {
    "text": "and electricity to your homes So we",
    "start": "378160",
    "end": "380720"
  },
  {
    "text": "combine these two types of data and we",
    "start": "380720",
    "end": "383199"
  },
  {
    "text": "create a risk profile The idea is that",
    "start": "383199",
    "end": "385520"
  },
  {
    "text": "from satellite images we can look at",
    "start": "385520",
    "end": "387919"
  },
  {
    "text": "where high tension power lines are going",
    "start": "387919",
    "end": "390880"
  },
  {
    "text": "through So where they go through a",
    "start": "390880",
    "end": "392240"
  },
  {
    "text": "forest or through cities and whenever",
    "start": "392240",
    "end": "394240"
  },
  {
    "text": "the vegetation gets too close to the",
    "start": "394240",
    "end": "396080"
  },
  {
    "text": "power line we can notify the energy",
    "start": "396080",
    "end": "398240"
  },
  {
    "text": "provider so they can go and trim the",
    "start": "398240",
    "end": "399840"
  },
  {
    "text": "vegetation before a wildfire spreads out",
    "start": "399840",
    "end": "403120"
  },
  {
    "text": "Wildfire are massively you know",
    "start": "403120",
    "end": "404720"
  },
  {
    "text": "destructive event They bring a lot of uh",
    "start": "404720",
    "end": "407280"
  },
  {
    "text": "damage to our community to people's life",
    "start": "407280",
    "end": "409440"
  },
  {
    "text": "and businesses And so we are working",
    "start": "409440",
    "end": "412000"
  },
  {
    "text": "towards preventing them that rather than",
    "start": "412000",
    "end": "414560"
  },
  {
    "text": "reacting to them Yeah thank you We kind",
    "start": "414560",
    "end": "417120"
  },
  {
    "text": "of need that in the US Yeah the US is",
    "start": "417120",
    "end": "420080"
  },
  {
    "text": "indeed like a a big you know many",
    "start": "420080",
    "end": "422080"
  },
  {
    "text": "companies in the US are customers of us",
    "start": "422080",
    "end": "424000"
  },
  {
    "text": "just because it's the the land is very",
    "start": "424000",
    "end": "426080"
  },
  {
    "text": "vast",
    "start": "426080",
    "end": "428319"
  },
  {
    "text": "One thing that uh uh I wanted to add",
    "start": "428319",
    "end": "430639"
  },
  {
    "text": "that I will talk more about this right",
    "start": "430639",
    "end": "432240"
  },
  {
    "text": "after lunch I have a session dedicated",
    "start": "432240",
    "end": "434000"
  },
  {
    "text": "to how we do and that we try to handle",
    "start": "434000",
    "end": "436800"
  },
  {
    "text": "these problems at over story So in case",
    "start": "436800",
    "end": "438800"
  },
  {
    "text": "you're interested I have a talk later",
    "start": "438800",
    "end": "440319"
  },
  {
    "text": "today right after lunch uh at level zero",
    "start": "440319",
    "end": "443039"
  },
  {
    "text": "room J um where I will talk specifically",
    "start": "443039",
    "end": "445919"
  },
  {
    "text": "on how we tackle these problems But just",
    "start": "445919",
    "end": "447919"
  },
  {
    "text": "to give you like a brief intro or I",
    "start": "447919",
    "end": "450319"
  },
  {
    "text": "guess you can call it spoiler Uh we use",
    "start": "450319",
    "end": "452960"
  },
  {
    "text": "uh Google cloud specifically we use",
    "start": "452960",
    "end": "455360"
  },
  {
    "text": "combination of uh GKE and Google Cloud",
    "start": "455360",
    "end": "458240"
  },
  {
    "text": "Run GKE has been extremely useful for",
    "start": "458240",
    "end": "460800"
  },
  {
    "text": "our type of use cases Satellite images",
    "start": "460800",
    "end": "463440"
  },
  {
    "text": "come in all kind of shapes and forms and",
    "start": "463440",
    "end": "465520"
  },
  {
    "text": "resolution We use resolutions up to 15",
    "start": "465520",
    "end": "468240"
  },
  {
    "text": "cm So that's very high resolution high",
    "start": "468240",
    "end": "470960"
  },
  {
    "text": "imagery and the flexibility that we get",
    "start": "470960",
    "end": "473599"
  },
  {
    "text": "with Kubernetes and having the",
    "start": "473599",
    "end": "475199"
  },
  {
    "text": "possibility of having workloads that use",
    "start": "475199",
    "end": "477280"
  },
  {
    "text": "one CPU and 2 gigs of memory or 72 CPUs",
    "start": "477280",
    "end": "481120"
  },
  {
    "text": "and 450 gigs of memory It's it's very",
    "start": "481120",
    "end": "484240"
  },
  {
    "text": "important for us On top of it one of our",
    "start": "484240",
    "end": "487599"
  },
  {
    "text": "open source project that we use is",
    "start": "487599",
    "end": "489120"
  },
  {
    "text": "called Daxter This is the tool that we",
    "start": "489120",
    "end": "490960"
  },
  {
    "text": "use for our data data workflow engine uh",
    "start": "490960",
    "end": "494960"
  },
  {
    "text": "it's a open source project that works",
    "start": "494960",
    "end": "496960"
  },
  {
    "text": "really well in the cloud in my opinion I",
    "start": "496960",
    "end": "498800"
  },
  {
    "text": "am uh an open source contributor of the",
    "start": "498800",
    "end": "500639"
  },
  {
    "text": "project I've been working with it for",
    "start": "500639",
    "end": "502160"
  },
  {
    "text": "quite some years since version you know",
    "start": "502160",
    "end": "504319"
  },
  {
    "text": "0 something and yeah it has been really",
    "start": "504319",
    "end": "507120"
  },
  {
    "text": "exciting to see this project grow uh add",
    "start": "507120",
    "end": "509680"
  },
  {
    "text": "more integrations with Google cloud as",
    "start": "509680",
    "end": "511360"
  },
  {
    "text": "well and with kubernetes especially",
    "start": "511360",
    "end": "514240"
  },
  {
    "text": "well this is great thank you for a nice",
    "start": "514240",
    "end": "516399"
  },
  {
    "text": "plug for both GKE and cloud run but this",
    "start": "516399",
    "end": "518800"
  },
  {
    "text": "is definitely uh not only uh you know we",
    "start": "518800",
    "end": "521760"
  },
  {
    "text": "have other uh upstream Kubernetes at",
    "start": "521760",
    "end": "524080"
  },
  {
    "text": "Uber and other forms of Kubernetes so",
    "start": "524080",
    "end": "526959"
  },
  {
    "text": "it's not really a vendor pitch or",
    "start": "526959",
    "end": "528480"
  },
  {
    "text": "anything like that but thank you Um so",
    "start": "528480",
    "end": "530880"
  },
  {
    "text": "we we talked a lot about uh you know",
    "start": "530880",
    "end": "532959"
  },
  {
    "text": "kind of workload placement and uh",
    "start": "532959",
    "end": "535200"
  },
  {
    "text": "dynamic resource allocation in this",
    "start": "535200",
    "end": "537360"
  },
  {
    "text": "conference So um you know so especially",
    "start": "537360",
    "end": "540160"
  },
  {
    "text": "the DRRA is a beta feature in Kubernetes",
    "start": "540160",
    "end": "543839"
  },
  {
    "text": "So what are some of the advancements",
    "start": "543839",
    "end": "545839"
  },
  {
    "text": "that you're seeing um in um you know",
    "start": "545839",
    "end": "548720"
  },
  {
    "text": "resource allocation or workload",
    "start": "548720",
    "end": "550720"
  },
  {
    "text": "placements i'm gonna start with Tim on",
    "start": "550720",
    "end": "552720"
  },
  {
    "text": "that one Uh yeah Yeah No I've I've",
    "start": "552720",
    "end": "555279"
  },
  {
    "text": "probably been at a half a dozen talks on",
    "start": "555279",
    "end": "557680"
  },
  {
    "text": "DRRA uh in the past couple days at least",
    "start": "557680",
    "end": "560320"
  },
  {
    "text": "Um I think DRRA does start introducing a",
    "start": "560320",
    "end": "563200"
  },
  {
    "text": "lot of really interesting capabilities",
    "start": "563200",
    "end": "564720"
  },
  {
    "text": "to make sure that you can start doing",
    "start": "564720",
    "end": "567839"
  },
  {
    "text": "very very fine grained allocation of",
    "start": "567839",
    "end": "569800"
  },
  {
    "text": "resources Um alongside that one of the",
    "start": "569800",
    "end": "573279"
  },
  {
    "text": "things that I'm here pushing for this",
    "start": "573279",
    "end": "574880"
  },
  {
    "text": "week is is being able to do a very",
    "start": "574880",
    "end": "577120"
  },
  {
    "text": "similar set of management tricks to CPUs",
    "start": "577120",
    "end": "580480"
  },
  {
    "text": "Um and then building off of that",
    "start": "580480",
    "end": "582800"
  },
  {
    "text": "combination of fine grain resource",
    "start": "582800",
    "end": "584399"
  },
  {
    "text": "management to start talking about",
    "start": "584399",
    "end": "586880"
  },
  {
    "text": "copying that same pattern across",
    "start": "586880",
    "end": "588800"
  },
  {
    "text": "multiple nodes Um and maybe that there",
    "start": "588800",
    "end": "591120"
  },
  {
    "text": "are some missing primitives to to better",
    "start": "591120",
    "end": "592959"
  },
  {
    "text": "help enable multi-node AI training",
    "start": "592959",
    "end": "595120"
  },
  {
    "text": "workloads um with a very long toward",
    "start": "595120",
    "end": "598160"
  },
  {
    "text": "strategy towards being able to natively",
    "start": "598160",
    "end": "601200"
  },
  {
    "text": "process training um which is is",
    "start": "601200",
    "end": "604399"
  },
  {
    "text": "generally being done on just slurm on",
    "start": "604399",
    "end": "606480"
  },
  {
    "text": "bare metal today u but maybe it can be",
    "start": "606480",
    "end": "608800"
  },
  {
    "text": "done on kubernetes on bare metal with",
    "start": "608800",
    "end": "611680"
  },
  {
    "text": "slurm providing our our scheduling",
    "start": "611680",
    "end": "613600"
  },
  {
    "text": "expertise into the mix Yeah Um if you",
    "start": "613600",
    "end": "617839"
  },
  {
    "text": "think uh a dozen uh talks on is bad you",
    "start": "617839",
    "end": "620480"
  },
  {
    "text": "should try being an upstream contributor",
    "start": "620480",
    "end": "621920"
  },
  {
    "text": "I've been on a dozen pull requests about",
    "start": "621920",
    "end": "623360"
  },
  {
    "text": "DRA in the last month But uh no so uh I",
    "start": "623360",
    "end": "628160"
  },
  {
    "text": "think I'm going to talk about something",
    "start": "628160",
    "end": "629279"
  },
  {
    "text": "that isn't the RA for once because I'm",
    "start": "629279",
    "end": "630560"
  },
  {
    "text": "sure you've all heard a lot about this",
    "start": "630560",
    "end": "632880"
  },
  {
    "text": "Uh one of the other things that's",
    "start": "632880",
    "end": "634560"
  },
  {
    "text": "changing a lot especially in the node",
    "start": "634560",
    "end": "635680"
  },
  {
    "text": "integration of Kubernetes and uh this",
    "start": "635680",
    "end": "637680"
  },
  {
    "text": "was not this has not been pre-arranged",
    "start": "637680",
    "end": "638959"
  },
  {
    "text": "but shameless plug at the same time as",
    "start": "638959",
    "end": "640320"
  },
  {
    "text": "your talk unfortunately I am having a",
    "start": "640320",
    "end": "641839"
  },
  {
    "text": "talk on what I'm about to talk about So",
    "start": "641839",
    "end": "645000"
  },
  {
    "text": "uh what a lot in uh the latest release",
    "start": "645000",
    "end": "648640"
  },
  {
    "text": "of Kubernetes there's now support for in",
    "start": "648640",
    "end": "650800"
  },
  {
    "text": "place pod vertical scaling Now what does",
    "start": "650800",
    "end": "653680"
  },
  {
    "text": "that mean that means you can change the",
    "start": "653680",
    "end": "655360"
  },
  {
    "text": "CPU and memory requests and limits of a",
    "start": "655360",
    "end": "658079"
  },
  {
    "text": "pod without stopping the application You",
    "start": "658079",
    "end": "661279"
  },
  {
    "text": "can change it even after your pod has",
    "start": "661279",
    "end": "663120"
  },
  {
    "text": "started running That is particularly",
    "start": "663120",
    "end": "665600"
  },
  {
    "text": "cool for both aim a IML for training You",
    "start": "665600",
    "end": "668320"
  },
  {
    "text": "don't have to disrupt your application",
    "start": "668320",
    "end": "670399"
  },
  {
    "text": "Uh and it's also cool for batch jobs and",
    "start": "670399",
    "end": "672560"
  },
  {
    "text": "all sorts of things in between Uh also",
    "start": "672560",
    "end": "675040"
  },
  {
    "text": "what's changing is there's uh if I was",
    "start": "675040",
    "end": "677760"
  },
  {
    "text": "to make take it to a bit more of a wider",
    "start": "677760",
    "end": "679600"
  },
  {
    "text": "angle there's definitely a lot more of a",
    "start": "679600",
    "end": "682000"
  },
  {
    "text": "push that pods are less cattle and more",
    "start": "682000",
    "end": "684399"
  },
  {
    "text": "pets especially nowadays with more",
    "start": "684399",
    "end": "686880"
  },
  {
    "text": "advanced workloads where maybe in the",
    "start": "686880",
    "end": "689200"
  },
  {
    "text": "past the project has not been the best",
    "start": "689200",
    "end": "690959"
  },
  {
    "text": "for them I know racm uh we very much",
    "start": "690959",
    "end": "694240"
  },
  {
    "text": "hear the uh sentiment across the project",
    "start": "694240",
    "end": "697360"
  },
  {
    "text": "about the fact that there could be",
    "start": "697360",
    "end": "698720"
  },
  {
    "text": "better integration there and we we'll",
    "start": "698720",
    "end": "700160"
  },
  {
    "text": "we'll try and do more there at least in",
    "start": "700160",
    "end": "701839"
  },
  {
    "text": "my opinion we will um and then uh what",
    "start": "701839",
    "end": "705120"
  },
  {
    "text": "was the other thing yes and uh the other",
    "start": "705120",
    "end": "707040"
  },
  {
    "text": "change that's coming that is also quite",
    "start": "707040",
    "end": "708399"
  },
  {
    "text": "useful here is pod level resources you",
    "start": "708399",
    "end": "711519"
  },
  {
    "text": "can share your resources among multiple",
    "start": "711519",
    "end": "713839"
  },
  {
    "text": "containers in the same pod uh which",
    "start": "713839",
    "end": "716160"
  },
  {
    "text": "before of course you had to define your",
    "start": "716160",
    "end": "717519"
  },
  {
    "text": "resources at a per container level that",
    "start": "717519",
    "end": "720320"
  },
  {
    "text": "is quite useful you can uh balance",
    "start": "720320",
    "end": "722560"
  },
  {
    "text": "resources across a single C group across",
    "start": "722560",
    "end": "724720"
  },
  {
    "text": "multiple containers that are part of the",
    "start": "724720",
    "end": "726240"
  },
  {
    "text": "same training workload Obviously that's",
    "start": "726240",
    "end": "728560"
  },
  {
    "text": "not everything Uh I think that for",
    "start": "728560",
    "end": "730480"
  },
  {
    "text": "example we need to think a lot more",
    "start": "730480",
    "end": "732000"
  },
  {
    "text": "maybe in the project about in if I'm",
    "start": "732000",
    "end": "733839"
  },
  {
    "text": "thinking a IML maybe multiode inference",
    "start": "733839",
    "end": "736079"
  },
  {
    "text": "it's not particularly the funnest thing",
    "start": "736079",
    "end": "737920"
  },
  {
    "text": "in Kubernetes to do today especially if",
    "start": "737920",
    "end": "740240"
  },
  {
    "text": "you have multiple pods that you have to",
    "start": "740240",
    "end": "742320"
  },
  {
    "text": "uh kind of keep together kind of related",
    "start": "742320",
    "end": "744959"
  },
  {
    "text": "but Kubernetes doesn't really treat them",
    "start": "744959",
    "end": "746240"
  },
  {
    "text": "in a related way Um but yeah there's a",
    "start": "746240",
    "end": "748880"
  },
  {
    "text": "there's a lot coming I think in uh in",
    "start": "748880",
    "end": "750480"
  },
  {
    "text": "advancements 2K itself on this Uh Lucy",
    "start": "750480",
    "end": "753760"
  },
  {
    "text": "are you doing a talk in the afternoon at",
    "start": "753760",
    "end": "756079"
  },
  {
    "text": "the same time as Andrea's talk so make",
    "start": "756079",
    "end": "759360"
  },
  {
    "text": "your choice",
    "start": "759360",
    "end": "762399"
  },
  {
    "text": "Um so actually um we talked a lot about",
    "start": "762399",
    "end": "764800"
  },
  {
    "text": "running Kubernetes for AI You know at",
    "start": "764800",
    "end": "767519"
  },
  {
    "text": "can you talk about some of the",
    "start": "767519",
    "end": "768720"
  },
  {
    "text": "characteristics is it kind of like a",
    "start": "768720",
    "end": "770720"
  },
  {
    "text": "constant volume or is it very bursty and",
    "start": "770720",
    "end": "774000"
  },
  {
    "text": "how does multi-tenency play into this",
    "start": "774000",
    "end": "776560"
  },
  {
    "text": "picture yeah Yeah So we definitely see",
    "start": "776560",
    "end": "780160"
  },
  {
    "text": "both May maybe just to to quickly start",
    "start": "780160",
    "end": "782160"
  },
  {
    "text": "with what Lucy just said about the",
    "start": "782160",
    "end": "784240"
  },
  {
    "text": "ability to change pods um that are",
    "start": "784240",
    "end": "787680"
  },
  {
    "text": "already running Um that is sort of the",
    "start": "787680",
    "end": "789680"
  },
  {
    "text": "first category of three categories that",
    "start": "789680",
    "end": "791600"
  },
  {
    "text": "we see because VV8 is a database",
    "start": "791600",
    "end": "793120"
  },
  {
    "text": "Database is a stateful load Stateful",
    "start": "793120",
    "end": "795040"
  },
  {
    "text": "loads on Kubernetes is something that",
    "start": "795040",
    "end": "796959"
  },
  {
    "text": "five years ago people would have said",
    "start": "796959",
    "end": "798399"
  },
  {
    "text": "you're crazy Um I'm sure these days a",
    "start": "798399",
    "end": "801040"
  },
  {
    "text": "lot of people still think so but it's",
    "start": "801040",
    "end": "802320"
  },
  {
    "text": "it's fewer and more and more people are",
    "start": "802320",
    "end": "803839"
  },
  {
    "text": "are doing it just because the the",
    "start": "803839",
    "end": "805120"
  },
  {
    "text": "flexibility in general gives us so much",
    "start": "805120",
    "end": "807120"
  },
  {
    "text": "value Um but yeah stateful load and then",
    "start": "807120",
    "end": "810240"
  },
  {
    "text": "specifically for vector databases you",
    "start": "810240",
    "end": "813200"
  },
  {
    "text": "can almost think of them as in-memory",
    "start": "813200",
    "end": "814880"
  },
  {
    "text": "databases for for many cases and that",
    "start": "814880",
    "end": "816880"
  },
  {
    "text": "that just you're essentially bound by",
    "start": "816880",
    "end": "819440"
  },
  {
    "text": "whatever throughput you have from your",
    "start": "819440",
    "end": "821040"
  },
  {
    "text": "disk at startup time to just load that",
    "start": "821040",
    "end": "822959"
  },
  {
    "text": "all back into memory and as as uh loads",
    "start": "822959",
    "end": "825120"
  },
  {
    "text": "grow there's only so much that you can",
    "start": "825120",
    "end": "826959"
  },
  {
    "text": "scale horizontally So the ability to to",
    "start": "826959",
    "end": "829839"
  },
  {
    "text": "basically vertically change a pot that",
    "start": "829839",
    "end": "832240"
  },
  {
    "text": "is that is a way of bursting I would say",
    "start": "832240",
    "end": "835839"
  },
  {
    "text": "um just the workload growing and",
    "start": "835839",
    "end": "837680"
  },
  {
    "text": "shrinking and then of course in a",
    "start": "837680",
    "end": "838800"
  },
  {
    "text": "multi-tenant environment if you have so",
    "start": "838800",
    "end": "840399"
  },
  {
    "text": "much physical uh infrastructure so many",
    "start": "840399",
    "end": "842720"
  },
  {
    "text": "nodes you can share that across these if",
    "start": "842720",
    "end": "845920"
  },
  {
    "text": "if we can share that more dynamically",
    "start": "845920",
    "end": "847440"
  },
  {
    "text": "without introducing a restart that's",
    "start": "847440",
    "end": "849040"
  },
  {
    "text": "going to be a gamecher for for databases",
    "start": "849040",
    "end": "852160"
  },
  {
    "text": "the other two categories that we have is",
    "start": "852160",
    "end": "854079"
  },
  {
    "text": "more thinking of probably when people",
    "start": "854079",
    "end": "855760"
  },
  {
    "text": "think of AI workloads they think more of",
    "start": "855760",
    "end": "857600"
  },
  {
    "text": "of GPUs and uh there we have we have two",
    "start": "857600",
    "end": "862079"
  },
  {
    "text": "one is um the embedding creation so we",
    "start": "862079",
    "end": "866079"
  },
  {
    "text": "being a vector database you can think of",
    "start": "866079",
    "end": "867440"
  },
  {
    "text": "this very roughly as you have any kind",
    "start": "867440",
    "end": "869040"
  },
  {
    "text": "of multimodal data you throw it into a",
    "start": "869040",
    "end": "871120"
  },
  {
    "text": "model that model spits out vector",
    "start": "871120",
    "end": "872959"
  },
  {
    "text": "embeddings and those vector embeddings",
    "start": "872959",
    "end": "874560"
  },
  {
    "text": "are what's actually indexed in the",
    "start": "874560",
    "end": "876079"
  },
  {
    "text": "database so what that means is even if",
    "start": "876079",
    "end": "878639"
  },
  {
    "text": "that indexation part is CPUbased you",
    "start": "878639",
    "end": "882560"
  },
  {
    "text": "still need the model to to create those",
    "start": "882560",
    "end": "884399"
  },
  {
    "text": "vector embeddings and you need them um",
    "start": "884399",
    "end": "886560"
  },
  {
    "text": "you need a lot them at ingest time",
    "start": "886560",
    "end": "888560"
  },
  {
    "text": "because most people do bulk ingests and",
    "start": "888560",
    "end": "890720"
  },
  {
    "text": "then updates Um but you also need them",
    "start": "890720",
    "end": "893199"
  },
  {
    "text": "at query time because at query time um",
    "start": "893199",
    "end": "895360"
  },
  {
    "text": "same thing you query in some kind of",
    "start": "895360",
    "end": "897199"
  },
  {
    "text": "modality typically text can also be",
    "start": "897199",
    "end": "899279"
  },
  {
    "text": "images can be sound that needs to be",
    "start": "899279",
    "end": "901440"
  },
  {
    "text": "translated into this essentially array",
    "start": "901440",
    "end": "903680"
  },
  {
    "text": "of of numbers again and for this uh",
    "start": "903680",
    "end": "906880"
  },
  {
    "text": "we're running uh what we call the the8",
    "start": "906880",
    "end": "909760"
  },
  {
    "text": "embedding service which is essentially",
    "start": "909760",
    "end": "911600"
  },
  {
    "text": "just this it's a media to vector uh",
    "start": "911600",
    "end": "914399"
  },
  {
    "text": "service and that runs on Kubernetes in",
    "start": "914399",
    "end": "917760"
  },
  {
    "text": "um sort of various pods that have GPUs",
    "start": "917760",
    "end": "921040"
  },
  {
    "text": "attached to",
    "start": "921040",
    "end": "922160"
  },
  {
    "text": "And there we're controlling the",
    "start": "922160",
    "end": "924440"
  },
  {
    "text": "burstiness through multi-tenency So this",
    "start": "924440",
    "end": "926720"
  },
  {
    "text": "is a multi-tenant service Um and of",
    "start": "926720",
    "end": "930320"
  },
  {
    "text": "course you still have peaks around",
    "start": "930320",
    "end": "932480"
  },
  {
    "text": "specific hours or so So one of our our",
    "start": "932480",
    "end": "934800"
  },
  {
    "text": "customers is an email client for example",
    "start": "934800",
    "end": "936560"
  },
  {
    "text": "So there's very clear distribution of",
    "start": "936560",
    "end": "938639"
  },
  {
    "text": "Monday morning 9:00 a.m you get so many",
    "start": "938639",
    "end": "940800"
  },
  {
    "text": "emails Um and and that is something that",
    "start": "940800",
    "end": "943920"
  },
  {
    "text": "you can plan for and you can you can",
    "start": "943920",
    "end": "945600"
  },
  {
    "text": "sort of scale dynamically But then we",
    "start": "945600",
    "end": "948320"
  },
  {
    "text": "also have and that's the third bucket",
    "start": "948320",
    "end": "950639"
  },
  {
    "text": "extremely unpredictable and bursty loads",
    "start": "950639",
    "end": "953519"
  },
  {
    "text": "where for example um one thing that we",
    "start": "953519",
    "end": "955519"
  },
  {
    "text": "just recently introduced is called the",
    "start": "955519",
    "end": "956959"
  },
  {
    "text": "transformation agent and that's",
    "start": "956959",
    "end": "958639"
  },
  {
    "text": "essentially a AI agent that runs on your",
    "start": "958639",
    "end": "961920"
  },
  {
    "text": "data and you can essentially kick a",
    "start": "961920",
    "end": "963759"
  },
  {
    "text": "transformation off with a single prompt",
    "start": "963759",
    "end": "965600"
  },
  {
    "text": "So you would say like take every single",
    "start": "965600",
    "end": "967759"
  },
  {
    "text": "object that's in my database translate",
    "start": "967759",
    "end": "970000"
  },
  {
    "text": "it to Spanish and write it back into the",
    "start": "970000",
    "end": "972240"
  },
  {
    "text": "database And that is extremely bursty",
    "start": "972240",
    "end": "974800"
  },
  {
    "text": "because you could have could have",
    "start": "974800",
    "end": "975920"
  },
  {
    "text": "billions of objects and and all of a",
    "start": "975920",
    "end": "978079"
  },
  {
    "text": "sudden all these translations are",
    "start": "978079",
    "end": "979440"
  },
  {
    "text": "essentially LLM model calls And uh what",
    "start": "979440",
    "end": "982079"
  },
  {
    "text": "we're doing for that that is essentially",
    "start": "982079",
    "end": "984000"
  },
  {
    "text": "the category we said like we don't want",
    "start": "984000",
    "end": "985600"
  },
  {
    "text": "to self-host this and we're we're um",
    "start": "985600",
    "end": "988480"
  },
  {
    "text": "using a third party provider uh modal in",
    "start": "988480",
    "end": "991199"
  },
  {
    "text": "this case um who from what I understand",
    "start": "991199",
    "end": "993680"
  },
  {
    "text": "do not run on kubernetes themselves",
    "start": "993680",
    "end": "995680"
  },
  {
    "text": "because it is so bursty because they",
    "start": "995680",
    "end": "997360"
  },
  {
    "text": "they really charge for CPU minutes which",
    "start": "997360",
    "end": "999839"
  },
  {
    "text": "is something that is great for us as a",
    "start": "999839",
    "end": "1001759"
  },
  {
    "text": "as a customer but quite a quite a bit of",
    "start": "1001759",
    "end": "1004880"
  },
  {
    "text": "a challenge from an infrastructure",
    "start": "1004880",
    "end": "1006320"
  },
  {
    "text": "perspective I think I think Andrea you",
    "start": "1006320",
    "end": "1008639"
  },
  {
    "text": "have a lot of data that you're",
    "start": "1008639",
    "end": "1009920"
  },
  {
    "text": "manipulating as well do Do you want to",
    "start": "1009920",
    "end": "1011600"
  },
  {
    "text": "add anything here yeah exactly as I was",
    "start": "1011600",
    "end": "1013759"
  },
  {
    "text": "saying like satellite images they take a",
    "start": "1013759",
    "end": "1015680"
  },
  {
    "text": "lot of space as you can imagine So we",
    "start": "1015680",
    "end": "1018079"
  },
  {
    "text": "use very large amount of stoages and",
    "start": "1018079",
    "end": "1020000"
  },
  {
    "text": "this is this is why I'm also interested",
    "start": "1020000",
    "end": "1021759"
  },
  {
    "text": "very much into um the array right the",
    "start": "1021759",
    "end": "1024798"
  },
  {
    "text": "dynamic resource allocation because our",
    "start": "1024799",
    "end": "1027839"
  },
  {
    "text": "pipelines they always look the same more",
    "start": "1027839",
    "end": "1029678"
  },
  {
    "text": "or less whe there are a lot of choices",
    "start": "1029679",
    "end": "1031280"
  },
  {
    "text": "to be made but depending on the input",
    "start": "1031280",
    "end": "1033438"
  },
  {
    "text": "that we get the pipeline might take a",
    "start": "1033439",
    "end": "1035839"
  },
  {
    "text": "lot of resources or less resources and",
    "start": "1035839",
    "end": "1038640"
  },
  {
    "text": "when you run like workflow workload that",
    "start": "1038640",
    "end": "1040798"
  },
  {
    "text": "are a little bit more stateful that",
    "start": "1040799",
    "end": "1042720"
  },
  {
    "text": "becomes a problem you don't want your",
    "start": "1042720",
    "end": "1044480"
  },
  {
    "text": "pipeline to go out of memory after",
    "start": "1044480",
    "end": "1046400"
  },
  {
    "text": "processing in you know 12 hours and you",
    "start": "1046400",
    "end": "1048480"
  },
  {
    "text": "have no checkpointing and all of a",
    "start": "1048480",
    "end": "1049919"
  },
  {
    "text": "sudden you need to redo everything from",
    "start": "1049919",
    "end": "1051760"
  },
  {
    "text": "scratch So I'm very much looking forward",
    "start": "1051760",
    "end": "1053520"
  },
  {
    "text": "to the you know new changes and new",
    "start": "1053520",
    "end": "1055440"
  },
  {
    "text": "features that will happen over the",
    "start": "1055440",
    "end": "1056960"
  },
  {
    "text": "course of the next months and years in",
    "start": "1056960",
    "end": "1058720"
  },
  {
    "text": "that regard",
    "start": "1058720",
    "end": "1060160"
  },
  {
    "text": "One of the things that at least I'm",
    "start": "1060160",
    "end": "1061840"
  },
  {
    "text": "trying to get us in a better state about",
    "start": "1061840",
    "end": "1063679"
  },
  {
    "text": "is being is having more checkpointing",
    "start": "1063679",
    "end": "1065600"
  },
  {
    "text": "and being more disruption tolerant when",
    "start": "1065600",
    "end": "1067200"
  },
  {
    "text": "doing training in batch because GPUs are",
    "start": "1067200",
    "end": "1071360"
  },
  {
    "text": "well this is going to be a real shocker",
    "start": "1071360",
    "end": "1072640"
  },
  {
    "text": "here but GPUs are really expensive Um",
    "start": "1072640",
    "end": "1076160"
  },
  {
    "text": "and uh it's not it's unlike CPUs where",
    "start": "1076160",
    "end": "1079120"
  },
  {
    "text": "oh you know just we can have a safety",
    "start": "1079120",
    "end": "1080880"
  },
  {
    "text": "buffer it's fine it's going to cost the",
    "start": "1080880",
    "end": "1082320"
  },
  {
    "text": "company some money but it's worth it",
    "start": "1082320",
    "end": "1083760"
  },
  {
    "text": "With GPUs ideally I want to be using all",
    "start": "1083760",
    "end": "1087120"
  },
  {
    "text": "of them all of the time to do at least",
    "start": "1087120",
    "end": "1089280"
  },
  {
    "text": "something and to extract value from them",
    "start": "1089280",
    "end": "1091440"
  },
  {
    "text": "because getting because they are worth",
    "start": "1091440",
    "end": "1093039"
  },
  {
    "text": "their weight in gold Um so obviously",
    "start": "1093039",
    "end": "1097039"
  },
  {
    "text": "that's we're never going to get to 100%",
    "start": "1097039",
    "end": "1098799"
  },
  {
    "text": "utilization 100% of the time But how do",
    "start": "1098799",
    "end": "1100320"
  },
  {
    "text": "we get how can we even get close well",
    "start": "1100320",
    "end": "1102640"
  },
  {
    "text": "one of the ways we can do that at least",
    "start": "1102640",
    "end": "1104480"
  },
  {
    "text": "is uh there we will only be use",
    "start": "1104480",
    "end": "1107120"
  },
  {
    "text": "fundamentally a load load follows a a",
    "start": "1107120",
    "end": "1110160"
  },
  {
    "text": "peak and valley right and uh when we are",
    "start": "1110160",
    "end": "1112880"
  },
  {
    "text": "down in this valley when we have a less",
    "start": "1112880",
    "end": "1114640"
  },
  {
    "text": "load because people are sleeping etc",
    "start": "1114640",
    "end": "1117360"
  },
  {
    "text": "Well really we shouldn't just leave in",
    "start": "1117360",
    "end": "1119120"
  },
  {
    "text": "my in my opinion we shouldn't leave",
    "start": "1119120",
    "end": "1120240"
  },
  {
    "text": "these GPUs idle We should we should uh",
    "start": "1120240",
    "end": "1123039"
  },
  {
    "text": "we should reuse them on a workload that",
    "start": "1123039",
    "end": "1125919"
  },
  {
    "text": "is more disruption tolerant Um that is",
    "start": "1125919",
    "end": "1129039"
  },
  {
    "text": "more disruption tolerant but we can very",
    "start": "1129039",
    "end": "1131039"
  },
  {
    "text": "quickly take the GPUs back if we",
    "start": "1131039",
    "end": "1133120"
  },
  {
    "text": "suddenly have a spike in a spike of",
    "start": "1133120",
    "end": "1135280"
  },
  {
    "text": "traffic a capacity crunch something bad",
    "start": "1135280",
    "end": "1137760"
  },
  {
    "text": "happening right uh we are not yet there",
    "start": "1137760",
    "end": "1141200"
  },
  {
    "text": "yet We're working a lot on this project",
    "start": "1141200",
    "end": "1143919"
  },
  {
    "text": "uh within Uber that I won't go into",
    "start": "1143919",
    "end": "1145440"
  },
  {
    "text": "specific details of because I did this",
    "start": "1145440",
    "end": "1147520"
  },
  {
    "text": "crazy thing where I signed an NDA for",
    "start": "1147520",
    "end": "1149039"
  },
  {
    "text": "money from them Um but we are trying to",
    "start": "1149039",
    "end": "1152480"
  },
  {
    "text": "at least get into a position where we",
    "start": "1152480",
    "end": "1154880"
  },
  {
    "text": "can uh maximize the potential use cases",
    "start": "1154880",
    "end": "1158080"
  },
  {
    "text": "that our GPUs could be used for so that",
    "start": "1158080",
    "end": "1160559"
  },
  {
    "text": "if we have a disruption tolerant",
    "start": "1160559",
    "end": "1162240"
  },
  {
    "text": "workload we can opportunistically eat",
    "start": "1162240",
    "end": "1165039"
  },
  {
    "text": "the idle capacity rather than buy more",
    "start": "1165039",
    "end": "1167600"
  },
  {
    "text": "devices because yeah they're really",
    "start": "1167600",
    "end": "1169360"
  },
  {
    "text": "expensive Yeah So this morning's keynote",
    "start": "1169360",
    "end": "1172080"
  },
  {
    "text": "talked about the inference gateway So",
    "start": "1172080",
    "end": "1174160"
  },
  {
    "text": "you can kind of low balance the requests",
    "start": "1174160",
    "end": "1176320"
  },
  {
    "text": "to the available endpoints Uh so now I I",
    "start": "1176320",
    "end": "1179280"
  },
  {
    "text": "have do have a couple questions for the",
    "start": "1179280",
    "end": "1180799"
  },
  {
    "text": "panelists but if folks can go to the",
    "start": "1180799",
    "end": "1182880"
  },
  {
    "text": "microphone you can ask individual",
    "start": "1182880",
    "end": "1185160"
  },
  {
    "text": "questions Thank you for being the first",
    "start": "1185160",
    "end": "1188480"
  },
  {
    "text": "No problem Um yes question about GPU",
    "start": "1188480",
    "end": "1191120"
  },
  {
    "text": "management Um I think I think I already",
    "start": "1191120",
    "end": "1193280"
  },
  {
    "text": "partly know the answer from Lucy but be",
    "start": "1193280",
    "end": "1195120"
  },
  {
    "text": "interested in the rest of the panel Um",
    "start": "1195120",
    "end": "1197280"
  },
  {
    "text": "so do you work with a fixed pool of GPUs",
    "start": "1197280",
    "end": "1199919"
  },
  {
    "text": "or do you use the autoscaler to get them",
    "start": "1199919",
    "end": "1202160"
  },
  {
    "text": "on demand and why so at our scale we",
    "start": "1202160",
    "end": "1205520"
  },
  {
    "text": "can't the question I think was do we",
    "start": "1205520",
    "end": "1207360"
  },
  {
    "text": "work with a fixed pool of GPUs or do we",
    "start": "1207360",
    "end": "1209200"
  },
  {
    "text": "like use autoscaling with a cloud",
    "start": "1209200",
    "end": "1210720"
  },
  {
    "text": "provider or something right i I see a",
    "start": "1210720",
    "end": "1212320"
  },
  {
    "text": "head nodding so I'm going to assume",
    "start": "1212320",
    "end": "1213280"
  },
  {
    "text": "that's the question So the problem we",
    "start": "1213280",
    "end": "1216000"
  },
  {
    "text": "have is that our at our scale uh if we",
    "start": "1216000",
    "end": "1218880"
  },
  {
    "text": "ask a cloud provider to hold capacity in",
    "start": "1218880",
    "end": "1220799"
  },
  {
    "text": "reserve and give us like a quot uh they",
    "start": "1220799",
    "end": "1222960"
  },
  {
    "text": "say we are not holding an entire data",
    "start": "1222960",
    "end": "1224720"
  },
  {
    "text": "center hall in free in free capacity for",
    "start": "1224720",
    "end": "1226960"
  },
  {
    "text": "you So our GPU pool is fixed It's a mix",
    "start": "1226960",
    "end": "1230240"
  },
  {
    "text": "of uh onrem GPUs In fact we still have",
    "start": "1230240",
    "end": "1233120"
  },
  {
    "text": "some quite old ones because they're",
    "start": "1233120",
    "end": "1234720"
  },
  {
    "text": "expensive now So why not keep them and",
    "start": "1234720",
    "end": "1236799"
  },
  {
    "text": "keep using them uh we also have some in",
    "start": "1236799",
    "end": "1239679"
  },
  {
    "text": "uh cloud providers OCI GCP Um but yeah",
    "start": "1239679",
    "end": "1242960"
  },
  {
    "text": "it's a fix it's a fixed amount",
    "start": "1242960",
    "end": "1244480"
  },
  {
    "text": "fundamentally and it's uh because of how",
    "start": "1244480",
    "end": "1247600"
  },
  {
    "text": "expensive they are actually if you want",
    "start": "1247600",
    "end": "1249039"
  },
  {
    "text": "like more GPUs and you want them outside",
    "start": "1249039",
    "end": "1251520"
  },
  {
    "text": "of the shared pool that is a",
    "start": "1251520",
    "end": "1254360"
  },
  {
    "text": "process because that's a lot of money",
    "start": "1254360",
    "end": "1258400"
  },
  {
    "text": "I just wanted to say at at scale all",
    "start": "1258400",
    "end": "1260720"
  },
  {
    "text": "resources end up being finite at some",
    "start": "1260720",
    "end": "1262799"
  },
  {
    "text": "point Um I I think historically the",
    "start": "1262799",
    "end": "1265679"
  },
  {
    "text": "cloud providers have have done a great",
    "start": "1265679",
    "end": "1267280"
  },
  {
    "text": "job",
    "start": "1267280",
    "end": "1268120"
  },
  {
    "text": "of pretending they're infinite and and a",
    "start": "1268120",
    "end": "1271280"
  },
  {
    "text": "lot of workloads been built around this",
    "start": "1271280",
    "end": "1272880"
  },
  {
    "text": "idea that they can ephemerally always",
    "start": "1272880",
    "end": "1274720"
  },
  {
    "text": "pull in resources But what you're seeing",
    "start": "1274720",
    "end": "1277600"
  },
  {
    "text": "out of especially a IML workloads is oh",
    "start": "1277600",
    "end": "1281280"
  },
  {
    "text": "we do need to queue up work that can't",
    "start": "1281280",
    "end": "1283760"
  },
  {
    "text": "instantaneously run How do we start",
    "start": "1283760",
    "end": "1286320"
  },
  {
    "text": "talking about deferring work how do we",
    "start": "1286320",
    "end": "1288400"
  },
  {
    "text": "prioritize work how do we preempt work",
    "start": "1288400",
    "end": "1291280"
  },
  {
    "text": "efficiently and especially in respect to",
    "start": "1291280",
    "end": "1293640"
  },
  {
    "text": "keeping system utilization high uh",
    "start": "1293640",
    "end": "1296640"
  },
  {
    "text": "because idling those GPUs is quite",
    "start": "1296640",
    "end": "1298640"
  },
  {
    "text": "expensive Yeah And yeah at at just",
    "start": "1298640",
    "end": "1301039"
  },
  {
    "text": "reiterating that at scale cloud",
    "start": "1301039",
    "end": "1302799"
  },
  {
    "text": "flexibility just disappears It's not",
    "start": "1302799",
    "end": "1305039"
  },
  {
    "text": "real Yeah Yeah We found a similar thing",
    "start": "1305039",
    "end": "1307520"
  },
  {
    "text": "We used to use the autoscaler very",
    "start": "1307520",
    "end": "1309120"
  },
  {
    "text": "flexibly and then in the last year or so",
    "start": "1309120",
    "end": "1311360"
  },
  {
    "text": "the autoscaling latency is about three",
    "start": "1311360",
    "end": "1313360"
  },
  {
    "text": "months",
    "start": "1313360",
    "end": "1315039"
  },
  {
    "text": "Yeah Yeah that sounds like a three",
    "start": "1315039",
    "end": "1316240"
  },
  {
    "text": "months sounds like about the lead time",
    "start": "1316240",
    "end": "1317840"
  },
  {
    "text": "uh on this stuff if not more Thanks",
    "start": "1317840",
    "end": "1322159"
  },
  {
    "text": "Thanks Thanks for a question Are there",
    "start": "1322159",
    "end": "1324240"
  },
  {
    "text": "any other questions from the audience",
    "start": "1324240",
    "end": "1327919"
  },
  {
    "text": "there's no line",
    "start": "1327919",
    "end": "1330480"
  },
  {
    "text": "That must mean that we were really good",
    "start": "1330480",
    "end": "1331919"
  },
  {
    "text": "at answering everyone's questions Have a",
    "start": "1331919",
    "end": "1333679"
  },
  {
    "text": "question for you actually Lucy Um so",
    "start": "1333679",
    "end": "1335919"
  },
  {
    "text": "it's uh a lot of times it's like you",
    "start": "1335919",
    "end": "1338080"
  },
  {
    "text": "said it's a very finite resource and so",
    "start": "1338080",
    "end": "1341039"
  },
  {
    "text": "how do you make your compute choices i",
    "start": "1341039",
    "end": "1343200"
  },
  {
    "text": "know that some people are making compute",
    "start": "1343200",
    "end": "1344720"
  },
  {
    "text": "choices using different variations for",
    "start": "1344720",
    "end": "1347120"
  },
  {
    "text": "specialized compute How do you do that",
    "start": "1347120",
    "end": "1349360"
  },
  {
    "text": "or how do you choose workloads to go on",
    "start": "1349360",
    "end": "1351679"
  },
  {
    "text": "which type of commute comput uh so we",
    "start": "1351679",
    "end": "1354640"
  },
  {
    "text": "have a right now it's a bit less mixing",
    "start": "1354640",
    "end": "1357840"
  },
  {
    "text": "in in my opinion should be but uh",
    "start": "1357840",
    "end": "1360120"
  },
  {
    "text": "fundamentally uh we have uh and actually",
    "start": "1360120",
    "end": "1363039"
  },
  {
    "text": "I'll tailor this to a IML uh when you",
    "start": "1363039",
    "end": "1365520"
  },
  {
    "text": "create a service as Uber that needs a",
    "start": "1365520",
    "end": "1368240"
  },
  {
    "text": "certain that needs to do use GPUs you",
    "start": "1368240",
    "end": "1371120"
  },
  {
    "text": "specify what GPUs you actually need with",
    "start": "1371120",
    "end": "1374320"
  },
  {
    "text": "gating that it has to be done by someone",
    "start": "1374320",
    "end": "1376000"
  },
  {
    "text": "who knows what they're doing you can't",
    "start": "1376000",
    "end": "1377280"
  },
  {
    "text": "just be like a random engineer in an",
    "start": "1377280",
    "end": "1378960"
  },
  {
    "text": "office who's got no affiliation with the",
    "start": "1378960",
    "end": "1381440"
  },
  {
    "text": "a IML folks who just goes I would like",
    "start": "1381440",
    "end": "1383600"
  },
  {
    "text": "100 uh H100s now um they that is then",
    "start": "1383600",
    "end": "1387919"
  },
  {
    "text": "placed onto a machine uh typically on",
    "start": "1387919",
    "end": "1390559"
  },
  {
    "text": "prem uh where those G where those GPUs",
    "start": "1390559",
    "end": "1393360"
  },
  {
    "text": "are available and then ECAC there",
    "start": "1393360",
    "end": "1395520"
  },
  {
    "text": "outside of that um we're trying to get",
    "start": "1395520",
    "end": "1398640"
  },
  {
    "text": "better at collocation because we don't",
    "start": "1398640",
    "end": "1401360"
  },
  {
    "text": "want fundament fundamentally uh we we",
    "start": "1401360",
    "end": "1404559"
  },
  {
    "text": "we've at least found that uh collocation",
    "start": "1404559",
    "end": "1406880"
  },
  {
    "text": "first off allows us to do more resource",
    "start": "1406880",
    "end": "1409120"
  },
  {
    "text": "overcommitting um and it and it but the",
    "start": "1409120",
    "end": "1412720"
  },
  {
    "text": "challenge there really is uh noisy is",
    "start": "1412720",
    "end": "1414960"
  },
  {
    "text": "noisy neighbors isolation there's no",
    "start": "1414960",
    "end": "1417360"
  },
  {
    "text": "magic bullet here it is a really tough",
    "start": "1417360",
    "end": "1419760"
  },
  {
    "text": "problem um yes I'd uh sorry any",
    "start": "1419760",
    "end": "1425760"
  },
  {
    "text": "uh no I think you covered it uh how many",
    "start": "1425760",
    "end": "1427679"
  },
  {
    "text": "cores you run on kubernetes out in Uber",
    "start": "1427679",
    "end": "1430880"
  },
  {
    "text": "okay so on kubernetes uh okay so at Uber",
    "start": "1430880",
    "end": "1434559"
  },
  {
    "text": "we measure things in TPU cores because",
    "start": "1434559",
    "end": "1436320"
  },
  {
    "text": "it's like it's a roughly good metric if",
    "start": "1436320",
    "end": "1438480"
  },
  {
    "text": "you measured in hosts like a host could",
    "start": "1438480",
    "end": "1440240"
  },
  {
    "text": "be small big you know it's not it's",
    "start": "1440240",
    "end": "1442000"
  },
  {
    "text": "useful CPU cores has its downsides but",
    "start": "1442000",
    "end": "1445039"
  },
  {
    "text": "it's a good enough metric I'd say right",
    "start": "1445039",
    "end": "1447760"
  },
  {
    "text": "now I think we have about 4 million CPU",
    "start": "1447760",
    "end": "1450159"
  },
  {
    "text": "cores on Kubernetes and it's going to be",
    "start": "1450159",
    "end": "1453039"
  },
  {
    "text": "more like 8 to 10 million within like",
    "start": "1453039",
    "end": "1455440"
  },
  {
    "text": "two years so it's a lot I think we're",
    "start": "1455440",
    "end": "1458720"
  },
  {
    "text": "the biggest end user in the world only",
    "start": "1458720",
    "end": "1461120"
  },
  {
    "text": "evidence for that is I have yet to meet",
    "start": "1461120",
    "end": "1462880"
  },
  {
    "text": "someone who's got more if you are an end",
    "start": "1462880",
    "end": "1465200"
  },
  {
    "text": "user in this room and have more please",
    "start": "1465200",
    "end": "1467360"
  },
  {
    "text": "let me know Uh but yeah uh one question",
    "start": "1467360",
    "end": "1470880"
  },
  {
    "text": "out in the audience Anyone using uh GPUs",
    "start": "1470880",
    "end": "1474080"
  },
  {
    "text": "and anyone running TPUs kind of",
    "start": "1474080",
    "end": "1476480"
  },
  {
    "text": "interested in",
    "start": "1476480",
    "end": "1477559"
  },
  {
    "text": "that GPUs we got a few Okay Uh do do any",
    "start": "1477559",
    "end": "1483120"
  },
  {
    "text": "folks out there running GPUs like at the",
    "start": "1483120",
    "end": "1485279"
  },
  {
    "text": "edge just checking if there's any folks",
    "start": "1485279",
    "end": "1488400"
  },
  {
    "text": "Ah",
    "start": "1488400",
    "end": "1489400"
  },
  {
    "text": "okay Okay Um I I think uh are there any",
    "start": "1489400",
    "end": "1493120"
  },
  {
    "text": "more questions feel free to go to",
    "start": "1493120",
    "end": "1494559"
  },
  {
    "text": "microphones If not uh the panelists will",
    "start": "1494559",
    "end": "1497120"
  },
  {
    "text": "stick around for individual",
    "start": "1497120",
    "end": "1498919"
  },
  {
    "text": "questions Uh there's",
    "start": "1498919",
    "end": "1502559"
  },
  {
    "text": "somebody Okay Well thank you very much",
    "start": "1502600",
    "end": "1505039"
  },
  {
    "text": "We'll be we'll stick around for",
    "start": "1505039",
    "end": "1506559"
  },
  {
    "text": "individual questions Thank you Thanks",
    "start": "1506559",
    "end": "1511520"
  }
]
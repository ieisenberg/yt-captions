[
  {
    "text": "So today we're going to talk about automated multi- region Disaster Recovery in cuas for",
    "start": "40",
    "end": "6560"
  },
  {
    "text": "postgress uh the agenda super high level problem space and solution I'm going to",
    "start": "6560",
    "end": "12719"
  },
  {
    "text": "be a troublemaker talking about problem space and uh Shivani here is going to",
    "start": "12719",
    "end": "20240"
  },
  {
    "text": "talk about the solution so I'm Sergey I'm from prona uh I'm doing products",
    "start": "20240",
    "end": "26920"
  },
  {
    "text": "there Shivani is a product leader at a lle and Yan here as well as software",
    "start": "26920",
    "end": "32800"
  },
  {
    "text": "engineer at AAL so we're going to talk a lot of fun things today so problem space",
    "start": "32800",
    "end": "39040"
  },
  {
    "text": "the agenda for problem space is quick recap of why you would want to have",
    "start": "39040",
    "end": "44520"
  },
  {
    "text": "Disaster Recovery then quick jump in into pogress on cubanet and we're going",
    "start": "44520",
    "end": "50480"
  },
  {
    "text": "to talk about disaster recovery for pogress on cubanes and what problems it",
    "start": "50480",
    "end": "56039"
  },
  {
    "text": "brings and then Shivani and Yan are going to talk talk about the",
    "start": "56039",
    "end": "61399"
  },
  {
    "text": "solution so Disaster Recovery well everyone knows what it is I hope so it's",
    "start": "61399",
    "end": "68040"
  },
  {
    "text": "a plan right how you want to protect your it systems from data loss in case",
    "start": "68040",
    "end": "73920"
  },
  {
    "text": "of databases or from uh business failures and so on right and you want to do it quickly and there are usually two",
    "start": "73920",
    "end": "80720"
  },
  {
    "text": "drivers for Disaster Recovery first one is business continuity which is",
    "start": "80720",
    "end": "87360"
  },
  {
    "text": "basically boiling down to SLA requirements okay you need to recover your business within 5 minutes within 24",
    "start": "87360",
    "end": "94360"
  },
  {
    "text": "hours or whatever and the second driver is compliance and standards which is kind",
    "start": "94360",
    "end": "100600"
  },
  {
    "text": "of um dull and sad one because it's usually on the paper you might not",
    "start": "100600",
    "end": "106159"
  },
  {
    "text": "really have real disaster recovery but you sign it off your legal team signs it off everything is great but it's not",
    "start": "106159",
    "end": "112600"
  },
  {
    "text": "real Disaster Recovery usually so in a nutshell disaster recovery for databases looks like this",
    "start": "112600",
    "end": "119200"
  },
  {
    "text": "you have site a with the database and you have application and developers",
    "start": "119200",
    "end": "125079"
  },
  {
    "text": "everything is working everyone is happy business is happy now something goes south database fails or the whole site",
    "start": "125079",
    "end": "132360"
  },
  {
    "text": "goes down the developers are unhappy application is not working business is",
    "start": "132360",
    "end": "138680"
  },
  {
    "text": "losing money what do you do you have side B which is a disaster recovery site",
    "start": "138680",
    "end": "144239"
  },
  {
    "text": "and you recover your data everyone is happy right now so this is dis disaster",
    "start": "144239",
    "end": "149800"
  },
  {
    "text": "recovery in few seconds so a quick recap on pogress and",
    "start": "149800",
    "end": "158400"
  },
  {
    "text": "operators so again I hope everyone here is aware how databases and operators",
    "start": "158400",
    "end": "164760"
  },
  {
    "text": "work with kuet but in a nutshell um operators for databases they",
    "start": "164760",
    "end": "171080"
  },
  {
    "text": "provide you a simple way to upos skate kuet Primitives and database",
    "start": "171080",
    "end": "177200"
  },
  {
    "text": "configuration overall so you don't don't don't need to be an expert in a way of",
    "start": "177200",
    "end": "183080"
  },
  {
    "text": "configuring databases or qas itself you just have a dream or you just need a",
    "start": "183080",
    "end": "188640"
  },
  {
    "text": "database and you describe this database in a quite long yaml manifest and then",
    "start": "188640",
    "end": "196159"
  },
  {
    "text": "the magic is happening on kubernetes your database appears you can connect to it you can use it that's how operators",
    "start": "196159",
    "end": "202159"
  },
  {
    "text": "work right and the more on it operators provide you not only with day one where",
    "start": "202159",
    "end": "208840"
  },
  {
    "text": "you can deploy databases but they also give you a way to manage database day two operations backup scaling whatever",
    "start": "208840",
    "end": "216040"
  },
  {
    "text": "you want so this is the magic of kuet operators and again there is an example",
    "start": "216040",
    "end": "222319"
  },
  {
    "text": "of how peronna operator looks like you just specify a number of replicas you",
    "start": "222319",
    "end": "227599"
  },
  {
    "text": "specify the configuration the version of pogress and that's it you have a working database up and running in",
    "start": "227599",
    "end": "234319"
  },
  {
    "text": "seconds so if we talk about Disaster Recovery through per Coral operators uh",
    "start": "234319",
    "end": "241560"
  },
  {
    "text": "there are a couple of ways how you can do it so we have two kubernetes clusters they can be different regions in",
    "start": "241560",
    "end": "247159"
  },
  {
    "text": "different countries whatever and the basic or the simplest way to do Disaster",
    "start": "247159",
    "end": "253079"
  },
  {
    "text": "Recovery is through backups so you have an operator running on site a in one kubernetes cluster and",
    "start": "253079",
    "end": "260280"
  },
  {
    "text": "you have an operator running in site B in another kubernetes cluster and PG backrest that we use in our operator",
    "start": "260280",
    "end": "267199"
  },
  {
    "text": "uploads your backups to some object storage can be GCS S3 whatever and then if you",
    "start": "267199",
    "end": "274919"
  },
  {
    "text": "have a failure on your site a you can recover to side B by restoring from",
    "start": "274919",
    "end": "280080"
  },
  {
    "text": "backups of course it is suboptimal because well it might take some time and",
    "start": "280080",
    "end": "286680"
  },
  {
    "text": "well if your slas allow you some companies some customers that we have",
    "start": "286680",
    "end": "291800"
  },
  {
    "text": "they tell hey we cave for if our database is down for 24 hours for some",
    "start": "291800",
    "end": "297880"
  },
  {
    "text": "it works right so it can be one way and there is",
    "start": "297880",
    "end": "303560"
  },
  {
    "text": "obviously a better way so you have again two kuas clusters region a region B site",
    "start": "303560",
    "end": "309320"
  },
  {
    "text": "a site B but instead of using backups what you can do is you can have a streaming replication that way all your",
    "start": "309320",
    "end": "317160"
  },
  {
    "text": "data is synchronized between two q&as clusters between two postgress clusters in different",
    "start": "317160",
    "end": "323199"
  },
  {
    "text": "regions um live right and besides streaming replication what you can also",
    "start": "323199",
    "end": "329840"
  },
  {
    "text": "do you can do this replication through an object storage where your backups are",
    "start": "329840",
    "end": "337080"
  },
  {
    "text": "uploaded to the same S3 bucket or GCS or Asia whatever and then right ahead logs",
    "start": "337080",
    "end": "343039"
  },
  {
    "text": "are streamed directly to BG BG back rest in region",
    "start": "343039",
    "end": "348680"
  },
  {
    "text": "B that way you have real time replication to region B so this is like",
    "start": "348680",
    "end": "355400"
  },
  {
    "text": "how you can set up disaster recovery and that works great but what are the problems that you're going to face so",
    "start": "355400",
    "end": "362199"
  },
  {
    "text": "automated failover is problem number one right so again this is our ideal setup",
    "start": "362199",
    "end": "368639"
  },
  {
    "text": "you have database database is running developers applications are happy and",
    "start": "368639",
    "end": "374680"
  },
  {
    "text": "you have Disaster Recovery in place replication is there now your site or origion",
    "start": "374680",
    "end": "381440"
  },
  {
    "text": "fails and what you do is you need to switch the traffic you need to switch",
    "start": "381440",
    "end": "388440"
  },
  {
    "text": "the application to start using the database in region B the way you do it",
    "start": "388440",
    "end": "393479"
  },
  {
    "text": "right now within our operator is you need to do two steps first you need to",
    "start": "393479",
    "end": "399360"
  },
  {
    "text": "tell the operator in region B that it is now primary and it's a simple change it's just couple of lines in the",
    "start": "399360",
    "end": "406039"
  },
  {
    "text": "Manifest okay now it's primary grade but also you need to switch the traffic for your application to this region that's",
    "start": "406039",
    "end": "412560"
  },
  {
    "text": "another manual step and these steps they can be automated and you can write some",
    "start": "412560",
    "end": "418080"
  },
  {
    "text": "scripts but it's not the job of the operator to do so it should be some third party agent but that's just the",
    "start": "418080",
    "end": "425520"
  },
  {
    "text": "beginning of the problem the next problem would be when your main region goes up so now you need to think okay",
    "start": "425520",
    "end": "433520"
  },
  {
    "text": "how do I sync the data back because now all your new date is in",
    "start": "433520",
    "end": "439120"
  },
  {
    "text": "region B in your disaster recovery so you need to synchronize the data back and well that is the real problem",
    "start": "439120",
    "end": "446360"
  },
  {
    "text": "because you have a lot of manual steps now to perform and uh there are certain myths about",
    "start": "446360",
    "end": "452639"
  },
  {
    "text": "disaster recovery and automation around it like myth number one is disaster is a",
    "start": "452639",
    "end": "460720"
  },
  {
    "text": "rare thing clouds never fail or my data center is super solid I have backup power whatever well it's wrong you can",
    "start": "460720",
    "end": "468400"
  },
  {
    "text": "look at how Amazon regions are failing Asia regions gcp whatever and on pram",
    "start": "468400",
    "end": "474240"
  },
  {
    "text": "data center failed more often than you can imagine right and the when when this",
    "start": "474240",
    "end": "480479"
  },
  {
    "text": "happens again depending in your um slas",
    "start": "480479",
    "end": "485639"
  },
  {
    "text": "you need to switch as fast as possible and that's the problem sometimes because",
    "start": "485639",
    "end": "491680"
  },
  {
    "text": "we trust humans a lot right and uh when someone is doing something manually",
    "start": "491680",
    "end": "498199"
  },
  {
    "text": "there is a lot of room for mistake and that is why the automation for Disaster",
    "start": "498199",
    "end": "504479"
  },
  {
    "text": "Recovery is really really needed so as I said I'm introduce the problem and now",
    "start": "504479",
    "end": "510919"
  },
  {
    "text": "Shani is going to talk about the solution thank you Ser I actually have my mic so yeah so you know we met Sergey",
    "start": "510919",
    "end": "518760"
  },
  {
    "text": "a few months ago at actually cubec con um in EU and he mentioned the problem to",
    "start": "518760",
    "end": "524800"
  },
  {
    "text": "us we started collaborating with his team to find a solution and build a",
    "start": "524800",
    "end": "530279"
  },
  {
    "text": "solution because the company I work at is in the business of building multicluster control planes so we",
    "start": "530279",
    "end": "536880"
  },
  {
    "text": "automatically have this sort of uh View and topology of multiple kubernetes",
    "start": "536880",
    "end": "542160"
  },
  {
    "text": "clusters so this sort of problem is sort of uh you know in our alley in some",
    "start": "542160",
    "end": "547959"
  },
  {
    "text": "sense uh so the way I'm going to describe the solution we built is first",
    "start": "547959",
    "end": "553360"
  },
  {
    "text": "I will go over what a multicluster control plane is what its core capabilities are that can be leveraged",
    "start": "553360",
    "end": "560680"
  },
  {
    "text": "for building something like a Dr automation solution um then I we will go through",
    "start": "560680",
    "end": "567079"
  },
  {
    "text": "what a Dr orchestration workflow look looks like and what additional things we",
    "start": "567079",
    "end": "572480"
  },
  {
    "text": "had to build over and above our core uh control plane capabilities in order to",
    "start": "572480",
    "end": "578079"
  },
  {
    "text": "automate this whole workflow that Ser just described uh we I'll also share a demo",
    "start": "578079",
    "end": "584680"
  },
  {
    "text": "which uh will'll show all this in action we've put together the demo uh with otal",
    "start": "584680",
    "end": "590000"
  },
  {
    "text": "Nova which is the product uh my team works on and uh we use per perona post",
    "start": "590000",
    "end": "596120"
  },
  {
    "text": "SQL operator to do all the deployment and and the setup of the two sites so",
    "start": "596120",
    "end": "601600"
  },
  {
    "text": "Yan in is my teammate he did all the engineering work and I will be talking",
    "start": "601600",
    "end": "606800"
  },
  {
    "text": "about it I'm a product manager all right so what is a",
    "start": "606800",
    "end": "612519"
  },
  {
    "text": "multicluster control plane it is basically a kubernetes management cluster which has other workload",
    "start": "612519",
    "end": "619480"
  },
  {
    "text": "clusters attached to it the control plane itself does not run any workloads",
    "start": "619480",
    "end": "625240"
  },
  {
    "text": "those all run on the workload clusters so its main job you number one thing such a control plane does is to deploy",
    "start": "625240",
    "end": "632760"
  },
  {
    "text": "workloads to one or more clusters and as a result of this because it's in the",
    "start": "632760",
    "end": "638160"
  },
  {
    "text": "path of all the workloads being deployed it has this aggregate view of workload",
    "start": "638160",
    "end": "643519"
  },
  {
    "text": "topologies which in turn enables it to orchestrate things about workloads",
    "start": "643519",
    "end": "650079"
  },
  {
    "text": "spread across clusters so this is sort of like the secret power it has which",
    "start": "650079",
    "end": "656800"
  },
  {
    "text": "enables it to do things like this there are handful of products in this space",
    "start": "656800",
    "end": "661959"
  },
  {
    "text": "there's kada there's admirality and of course AAL NOA uh there's a couple more",
    "start": "661959",
    "end": "668959"
  },
  {
    "text": "um Red Hat ACM and uh Cube fed I will be using otal Nova in the rest of the",
    "start": "668959",
    "end": "675720"
  },
  {
    "text": "discussion because obviously that's what we are most familiar",
    "start": "675720",
    "end": "681079"
  },
  {
    "text": "with so the way this sort of control plane um schedules the workloads is it",
    "start": "682399",
    "end": "689079"
  },
  {
    "text": "decouples the placement from the workload definition itself so you take",
    "start": "689079",
    "end": "694120"
  },
  {
    "text": "your application manifest and you deploy it onto the control plane as though it were going to run there but in reality",
    "start": "694120",
    "end": "700839"
  },
  {
    "text": "it doesn't run on the control plane what the control plane does it it has all these scheduled policies which have been",
    "start": "700839",
    "end": "707760"
  },
  {
    "text": "defined and you can have default policies too you don't have to define a policy per workload it has these",
    "start": "707760",
    "end": "713240"
  },
  {
    "text": "scheduled policies it tries to match the incoming application manifest with a",
    "start": "713240",
    "end": "720120"
  },
  {
    "text": "schedule policy and then accordingly spreads the workload onto one or more",
    "start": "720120",
    "end": "725399"
  },
  {
    "text": "clusters so this is essentially what the basic structure of a scheduled policy",
    "start": "725399",
    "end": "731120"
  },
  {
    "text": "looks like it it has a couple of ways to select the resources and then match them",
    "start": "731120",
    "end": "736839"
  },
  {
    "text": "to one or more clusters so the namespace selector and the resource selector are ways to narrow down the",
    "start": "736839",
    "end": "743120"
  },
  {
    "text": "resources uh and the cluster selector is to select the target clusters and if you",
    "start": "743120",
    "end": "749560"
  },
  {
    "text": "do not specify a cluster selector that's fine um Noah will make a capacity based",
    "start": "749560",
    "end": "755959"
  },
  {
    "text": "decision to place it on any of the work uh workload clusters that it's managing",
    "start": "755959",
    "end": "762000"
  },
  {
    "text": "similarly if you specify more than one it'll again make a capacity based",
    "start": "762000",
    "end": "767480"
  },
  {
    "text": "decision so the next thing that you can specify in a scheduled policy and this",
    "start": "767480",
    "end": "773279"
  },
  {
    "text": "is actually very very core to being able to do something like a Dr or a ha set",
    "start": "773279",
    "end": "778839"
  },
  {
    "text": "set up this is spread specification essentially what it says is take my",
    "start": "778839",
    "end": "784440"
  },
  {
    "text": "workload definition and clone it onto all the uh selected workload clusters",
    "start": "784440",
    "end": "791360"
  },
  {
    "text": "and this has two modes there is a divide mode which is more like you know splitting your workload so say you",
    "start": "791360",
    "end": "798240"
  },
  {
    "text": "deploy a replica set which has 10 replicas and you say you select two",
    "start": "798240",
    "end": "803560"
  },
  {
    "text": "clusters and the percentages you allocated are 50/50 it'll put five on one and five on the other then there is",
    "start": "803560",
    "end": "811519"
  },
  {
    "text": "also duplicate mode which does exactly as it sounds like it takes your definition and puts it on all the uh",
    "start": "811519",
    "end": "818680"
  },
  {
    "text": "selected clusters so basically we're going to use duplicate mode for RDR setup so that way you know all your",
    "start": "818680",
    "end": "825800"
  },
  {
    "text": "configuration Secrets everything is the same across your sites it's never going to drift so that's something which uh is",
    "start": "825800",
    "end": "834240"
  },
  {
    "text": "very helpful in maintaining a uh Dr or ha kind of",
    "start": "834240",
    "end": "839880"
  },
  {
    "text": "uh deployment okay so that was the basics",
    "start": "839880",
    "end": "845240"
  },
  {
    "text": "of the control plan itself now let's look at what a Dr workflow typically",
    "start": "845240",
    "end": "851519"
  },
  {
    "text": "looks like I might have oversimplified it I'm sure I have but essentially these",
    "start": "851519",
    "end": "856600"
  },
  {
    "text": "are the sort of stages that come to mind when people think of disaster recovery",
    "start": "856600",
    "end": "861720"
  },
  {
    "text": "so obviously it begins with the setup of the database on multiple kubernetes clusters we'll assume we are all",
    "start": "861720",
    "end": "868079"
  },
  {
    "text": "deploying on kubernetes and these clusters need to be in you know different Cloud regions or maybe even",
    "start": "868079",
    "end": "875440"
  },
  {
    "text": "better in different clouds or different centers if you're data centers if you're on Prem um so the challenge I think I've",
    "start": "875440",
    "end": "883360"
  },
  {
    "text": "already alluded to this so by now it's probably um sort of obvious is to get",
    "start": "883360",
    "end": "888560"
  },
  {
    "text": "the setup right if you try to do it manually it's it's a pretty error prone",
    "start": "888560",
    "end": "894360"
  },
  {
    "text": "uh exercise you may not have the same S3 secret for your replication bucket on",
    "start": "894360",
    "end": "899639"
  },
  {
    "text": "both your primary and standby you may not have the same TLS Secrets your configs may not be same so using this",
    "start": "899639",
    "end": "907680"
  },
  {
    "text": "sort of control plane for which uh you know we have the spread scheduling",
    "start": "907680",
    "end": "912720"
  },
  {
    "text": "capability with duplication is is the answer to this first",
    "start": "912720",
    "end": "918040"
  },
  {
    "text": "part the next is obviously data replication we're not out with stateless workloads here we are talking about a",
    "start": "918040",
    "end": "924320"
  },
  {
    "text": "stateful workload like a database so your data has to be there on the other",
    "start": "924320",
    "end": "930600"
  },
  {
    "text": "site a priori you cannot start accessing data from your uh primary site which has",
    "start": "930600",
    "end": "936839"
  },
  {
    "text": "gone down because of the disaster so you need to have some form of data application Ser already described the",
    "start": "936839",
    "end": "943639"
  },
  {
    "text": "couple of ways in which you can do this uh you know depending on your RTO you can primarily go with the backup restore",
    "start": "943639",
    "end": "950959"
  },
  {
    "text": "method you know if you want tighter RTO you can RPO sorry I should say if you're",
    "start": "950959",
    "end": "957000"
  },
  {
    "text": "on tighter RPO you can go go with the uh streaming replication kind of method but",
    "start": "957000",
    "end": "962199"
  },
  {
    "text": "this is basically postrest native uh uh Technologies so which brings us to",
    "start": "962199",
    "end": "969440"
  },
  {
    "text": "failure detection so let's say uh you know your disaster has happened how do",
    "start": "969440",
    "end": "975040"
  },
  {
    "text": "you detect it how do you trigger the workflow to do the disaster recovery so",
    "start": "975040",
    "end": "980839"
  },
  {
    "text": "this is very dependent on business requirements and what monitoring tools you use um how long you want to tolerate",
    "start": "980839",
    "end": "988600"
  },
  {
    "text": "the failure before you actually trigger disaster recovery so you know we want to be able to do this part in a flexible",
    "start": "988600",
    "end": "995560"
  },
  {
    "text": "way and same thing for failover you know every organization has their own runbook for the series of steps they want to",
    "start": "995560",
    "end": "1002040"
  },
  {
    "text": "follow when a disaster happens maybe it's not all automatic maybe you want to",
    "start": "1002040",
    "end": "1007440"
  },
  {
    "text": "send an email to someone who has the authority to say yeah let's switch to the standby and you want to wait for",
    "start": "1007440",
    "end": "1013360"
  },
  {
    "text": "their response so you know you can build in a whole sort of workflow in order to do this right so this needs to be",
    "start": "1013360",
    "end": "1020440"
  },
  {
    "text": "flexible as well uh so we are going to do uh basically view these as pluggable",
    "start": "1020440",
    "end": "1026678"
  },
  {
    "text": "components in our architecture I won't talk about fail back because it's very similar to fail over so you know we",
    "start": "1026679",
    "end": "1034280"
  },
  {
    "text": "limited to fail over since this is a short talk uh so here is what we've come up",
    "start": "1034280",
    "end": "1040880"
  },
  {
    "text": "with as our Dr orchestration architecture right so we have the Nova control plane which is the central uh",
    "start": "1040880",
    "end": "1047400"
  },
  {
    "text": "scheduler as we have already looked at so it's going to take care of spreading the workload in an identical way on both",
    "start": "1047400",
    "end": "1054600"
  },
  {
    "text": "the Clusters next we have added a failure web hook which you integrate with your monitoring tool so you",
    "start": "1054600",
    "end": "1060679"
  },
  {
    "text": "basically register it as alert receiver we've also got a failover controller which is going to run a job which you",
    "start": "1060679",
    "end": "1068679"
  },
  {
    "text": "will provide to it as a Docker image and this job basically is the series of steps that capture or encapsulate your",
    "start": "1068679",
    "end": "1076240"
  },
  {
    "text": "run book so you can do whatever ever you want in that script or job that you register with the failover controller so",
    "start": "1076240",
    "end": "1083200"
  },
  {
    "text": "it's basically these one two three steps right Define your schedule policy register Nova web hook with your",
    "start": "1083200",
    "end": "1089679"
  },
  {
    "text": "monitoring tool and Define this job for your actual",
    "start": "1089679",
    "end": "1094760"
  },
  {
    "text": "failover all right so with that let's look at a demo uh the demo layout is",
    "start": "1094760",
    "end": "1100679"
  },
  {
    "text": "going to look something like this I have four kubernetes clusters one of them is running the Nova control plane there are",
    "start": "1100679",
    "end": "1108400"
  },
  {
    "text": "three workload clusters registered with it these three are all in different AWS regions which is what you would want in",
    "start": "1108400",
    "end": "1116159"
  },
  {
    "text": "reality uh the two of them cluster one and cluster two are running per Kona database the first one in primary mode",
    "start": "1116159",
    "end": "1123400"
  },
  {
    "text": "the second one in standby mode they're replicating data via the means of a S3 bucket and the third cluster is running",
    "start": "1123400",
    "end": "1130880"
  },
  {
    "text": "an ha proxy which is how the clients are communicating with the database so the H",
    "start": "1130880",
    "end": "1137400"
  },
  {
    "text": "proxy either goes to one or two and the client is sort of insulated from this fact and seamlessly can be redirected to",
    "start": "1137400",
    "end": "1144480"
  },
  {
    "text": "the correct cluster the failover job that I registered with Nova control plane is as described by Sergey the",
    "start": "1144480",
    "end": "1151720"
  },
  {
    "text": "minimal steps needed are to at least switch the workload cluster to from standby mode to primary mode as well as",
    "start": "1151720",
    "end": "1159400"
  },
  {
    "text": "to reconfigure the ha proxy to go to the second cluster so now we're going to see",
    "start": "1159400",
    "end": "1164520"
  },
  {
    "text": "the demo as I said this is the record demo so I'll try to keep Pace with",
    "start": "1164520",
    "end": "1171720"
  },
  {
    "text": "what's going on so we first going to get the kubernetes um I apologize for the font can anyone at the back see anything",
    "start": "1171720",
    "end": "1179799"
  },
  {
    "text": "at all you can perfect so first we're going to get the",
    "start": "1179799",
    "end": "1185120"
  },
  {
    "text": "kubernetes Clusters that are registered as workload clusters so this command is going against the U Nova control plane",
    "start": "1185120",
    "end": "1193000"
  },
  {
    "text": "that's our default Cube context so there are three clusters uh now we are going",
    "start": "1193000",
    "end": "1198480"
  },
  {
    "text": "to deploy the perona operator on cluster",
    "start": "1198480",
    "end": "1203919"
  },
  {
    "text": "one and two so this is the operator manifest we've added a label to it to",
    "start": "1203919",
    "end": "1210159"
  },
  {
    "text": "all our uh objects to say p cluster all this will be used for matching the",
    "start": "1210159",
    "end": "1216080"
  },
  {
    "text": "schedule policy the schedule policy that will get matched will put it on cluster",
    "start": "1216080",
    "end": "1222480"
  },
  {
    "text": "one and two so this is where the duplicate mechanism comes in so this",
    "start": "1222480",
    "end": "1227760"
  },
  {
    "text": "will make sure both of them have the same same configuration same everything um all right so let's look at",
    "start": "1227760",
    "end": "1235440"
  },
  {
    "text": "the schedule policies we have we have four of them registered this particular manifest will match the first one which",
    "start": "1235440",
    "end": "1242640"
  },
  {
    "text": "said P equal cluster all let's deploy the operator so the operator is getting",
    "start": "1242640",
    "end": "1249240"
  },
  {
    "text": "deployed on the first two clusters um now we are going to go ahead",
    "start": "1249240",
    "end": "1255400"
  },
  {
    "text": "and deploy the S3 so we're just checking whether",
    "start": "1255400",
    "end": "1262679"
  },
  {
    "text": "the operator was deployed on both of them all these commands that you're seeing are going against the Nova control plane okay so it says 2 over one",
    "start": "1262679",
    "end": "1271200"
  },
  {
    "text": "this is how we show when something is duplicated to multiple clusters so we're going to do the same thing with the S3",
    "start": "1271200",
    "end": "1278000"
  },
  {
    "text": "secret because we want to make sure that it's always the same on both this is also going to use the duplicate spread",
    "start": "1278000",
    "end": "1284880"
  },
  {
    "text": "policy let's deploy the S3 Secret",
    "start": "1284880",
    "end": "1290039"
  },
  {
    "text": "okay so the secret is created now we're going to go ahead and create actual database resource custom resource this",
    "start": "1292799",
    "end": "1300240"
  },
  {
    "text": "will be picked by the operator which will launch all the uh database processes and do everything so this is",
    "start": "1300240",
    "end": "1307000"
  },
  {
    "text": "going to use the secret for the backup that we just deployed right so let's go ahead and",
    "start": "1307000",
    "end": "1314320"
  },
  {
    "text": "create the first database custom resource so we applying the",
    "start": "1314320",
    "end": "1319480"
  },
  {
    "text": "Manifest cluster one this will put it on cluster uh the AWS region one",
    "start": "1319480",
    "end": "1327080"
  },
  {
    "text": "cluster let's see if it's coming up all right so it's initializing the",
    "start": "1327080",
    "end": "1333760"
  },
  {
    "text": "operator is doing its thing now let's go ahead and create a",
    "start": "1333760",
    "end": "1340559"
  },
  {
    "text": "second database okay so the only difference in this one from the first one that we",
    "start": "1340559",
    "end": "1347320"
  },
  {
    "text": "created is that this has standby and able to true that's how uh the operator",
    "start": "1347320",
    "end": "1354960"
  },
  {
    "text": "determines that this one is the standby and also notice this is using the same secret resource so there's no scope for",
    "start": "1354960",
    "end": "1365200"
  },
  {
    "text": "mismatch so let's go ahead and deploy the second",
    "start": "1365200",
    "end": "1371919"
  },
  {
    "text": "database okay let's check what's going on with",
    "start": "1371919",
    "end": "1378000"
  },
  {
    "text": "with both of them so these two are using a different",
    "start": "1378000",
    "end": "1383679"
  },
  {
    "text": "schedule policy because they are targeted only to one cluster each they're not using the duplicate spread",
    "start": "1383679",
    "end": "1389880"
  },
  {
    "text": "one Okay so we've got both the perona database uh postest databases coming up",
    "start": "1389880",
    "end": "1395360"
  },
  {
    "text": "let's now go ahead and start a client a pql client this is a simple client which",
    "start": "1395360",
    "end": "1400679"
  },
  {
    "text": "is going to insert into some dummy table and then right after inserting it's going to do a count so when on the",
    "start": "1400679",
    "end": "1406840"
  },
  {
    "text": "output terminal of the this uh client you'll basically see a row count getting printed which is getting incremented if",
    "start": "1406840",
    "end": "1413919"
  },
  {
    "text": "the client is working properly what we're going to do is simulate a region failure a disaster by removing the",
    "start": "1413919",
    "end": "1421080"
  },
  {
    "text": "primary KU primary cluster so we'll kill the kubernetes cluster there the client",
    "start": "1421080",
    "end": "1427320"
  },
  {
    "text": "will have a minor glitch which you will notice shortly in the meantime on the",
    "start": "1427320",
    "end": "1432840"
  },
  {
    "text": "right what you're seeing is the actual recovery job which is now starting to run so what the recovery job will do is",
    "start": "1432840",
    "end": "1441520"
  },
  {
    "text": "it'll switch the standby it'll change the Manifest of database 2 to change the",
    "start": "1441520",
    "end": "1446840"
  },
  {
    "text": "standby flag to false and then apply it and it'll also do the same with the",
    "start": "1446840",
    "end": "1452840"
  },
  {
    "text": "primary just in case the primary comes back you don't want it to continue thinking it's the primary so just for an",
    "start": "1452840",
    "end": "1458840"
  },
  {
    "text": "added safety we switch that to standby it also reconfigures the ha proxy so",
    "start": "1458840",
    "end": "1465080"
  },
  {
    "text": "here's the client failing for a brief moment if we didn't have Dr automated",
    "start": "1465080",
    "end": "1471240"
  },
  {
    "text": "this client would continue failing and some until someone came and manually did something right but now with this whole",
    "start": "1471240",
    "end": "1478679"
  },
  {
    "text": "thing automated as you see this client is back in business already so it's kind",
    "start": "1478679",
    "end": "1485480"
  },
  {
    "text": "of like you know things just self-healed so um yeah so that's",
    "start": "1485480",
    "end": "1492480"
  },
  {
    "text": "basically what the demo is about I mean the rest of it we're just checking the recovery job just to make sure if it's",
    "start": "1492480",
    "end": "1499039"
  },
  {
    "text": "done completing and things like that um all right so let me switch back",
    "start": "1499039",
    "end": "1506159"
  },
  {
    "text": "from the demo um so just some takeaways obviously",
    "start": "1506159",
    "end": "1511960"
  },
  {
    "text": "to survive widespread outages you need to make sure your database is deployed in multiple clusters in different",
    "start": "1511960",
    "end": "1518279"
  },
  {
    "text": "regions naturally use of kubernetes along with operators makes Dr setup",
    "start": "1518279",
    "end": "1524640"
  },
  {
    "text": "easier as well as opens up opportunity ities for Automation and automation of",
    "start": "1524640",
    "end": "1531159"
  },
  {
    "text": "recovery can be done in a simple low friction way using a multicluster control plane such as",
    "start": "1531159",
    "end": "1538039"
  },
  {
    "text": "Nova this is how the future work we want to make uh everything doable we are",
    "start": "1538039",
    "end": "1543559"
  },
  {
    "text": "manifest so we want to come up with crd based definitions for failure detection and failover uh we want to make the",
    "start": "1543559",
    "end": "1550200"
  },
  {
    "text": "control plane itself Deployable in highly available mode so that it's not a single point of failure",
    "start": "1550200",
    "end": "1556440"
  },
  {
    "text": "itself right um so that's basically it here are just",
    "start": "1556440",
    "end": "1561799"
  },
  {
    "text": "some resources for you to learn more if you're interested um you know the link",
    "start": "1561799",
    "end": "1567559"
  },
  {
    "text": "to the perona operators is there you can go uh uh do a free trial of Nova we have",
    "start": "1567559",
    "end": "1574039"
  },
  {
    "text": "the full featured version available for up to six",
    "start": "1574039",
    "end": "1579200"
  },
  {
    "text": "clusters um thank you hopefully this was useful and you know feel free to provide",
    "start": "1579440",
    "end": "1585440"
  },
  {
    "text": "us feedback [Applause]",
    "start": "1585440",
    "end": "1591559"
  },
  {
    "text": "okay great thanks everyone we have about a 15minute break if anyone has questions for them um well we can take a few",
    "start": "1591559",
    "end": "1599039"
  },
  {
    "text": "questions oh no yeah sorry question sorry two questions primarily",
    "start": "1599039",
    "end": "1606360"
  },
  {
    "text": "one is uh RPO in case of I mean what's your how do we address RPO in in the",
    "start": "1606360",
    "end": "1612840"
  },
  {
    "text": "case of uh automated failover uh between two regions and the",
    "start": "1612840",
    "end": "1618080"
  },
  {
    "text": "other one was I'm curious to understand why you you are not using applications",
    "start": "1618080",
    "end": "1624520"
  },
  {
    "text": "in the same uh local kubernetes cluster from what I can see you're actually",
    "start": "1624520",
    "end": "1630120"
  },
  {
    "text": "using ha proxy and applications might be even in different regions so how do you",
    "start": "1630120",
    "end": "1636159"
  },
  {
    "text": "address for example lency in that case so these are the two",
    "start": "1636159",
    "end": "1641320"
  },
  {
    "text": "questions um I guess um and serge feel free to jump in um for RPO uh you know",
    "start": "1641320",
    "end": "1648520"
  },
  {
    "text": "if you want tighter rpu you probably want to use uh streaming replication and maybe you can add steps to your um",
    "start": "1648520",
    "end": "1657000"
  },
  {
    "text": "failover routine before you actually switch to the standby to make sure that you've caught up to a",
    "start": "1657000",
    "end": "1663559"
  },
  {
    "text": "certain uh checkpoint or something before you actually switch that if",
    "start": "1663559",
    "end": "1668720"
  },
  {
    "text": "you're using back backups that your backup has caught up um but you know you",
    "start": "1668720",
    "end": "1674320"
  },
  {
    "text": "can only recover data until the point of the failure right right there is um if",
    "start": "1674320",
    "end": "1679919"
  },
  {
    "text": "something was still in cash and didn't get written to disk I guess that's that's lost um I don't know if that",
    "start": "1679919",
    "end": "1687799"
  },
  {
    "text": "addresses your question yeah probably with streaming replication probably synchronous replication to the other",
    "start": "1687799",
    "end": "1694159"
  },
  {
    "text": "region but in that case there's latency yes so that's why I think you know in any case this would provide",
    "start": "1694159",
    "end": "1701679"
  },
  {
    "text": "probably the automatic failover expects some data loss you know yeah it can happen yeah definitely so",
    "start": "1701679",
    "end": "1708720"
  },
  {
    "text": "sometimes maybe organizations might prefer maybe to delay the fail over and",
    "start": "1708720",
    "end": "1714519"
  },
  {
    "text": "do it manually just avoid data data you know and if that's an option",
    "start": "1714519",
    "end": "1720399"
  },
  {
    "text": "basically yeah it it can be an option well if you need a manual failover",
    "start": "1720399",
    "end": "1725919"
  },
  {
    "text": "probably you would not use this one right cuz Okay I don't I I just going to",
    "start": "1725919",
    "end": "1731440"
  },
  {
    "text": "fail over manually cuz I need to sync all the data and make sure that data consistency is there but that that one",
    "start": "1731440",
    "end": "1737720"
  },
  {
    "text": "is useful for some other organizations that can be losing some of it like a",
    "start": "1737720",
    "end": "1742960"
  },
  {
    "text": "couple of transactions or something there are also ways how you can address or minimize the lag obviously right and",
    "start": "1742960",
    "end": "1751399"
  },
  {
    "text": "ensure that all the data is written but that might impact the performance for",
    "start": "1751399",
    "end": "1758760"
  },
  {
    "text": "sure go ahead uh thank you very much for your presentation multicluster is is a",
    "start": "1758760",
    "end": "1764760"
  },
  {
    "text": "thing that I'm stuck on so I'm interested in this some learning a lot here um could you just for my education",
    "start": "1764760",
    "end": "1771600"
  },
  {
    "text": "tell me is Nova orchestrator is that actually a cluster in itself with just a control plane node or is it a Docker",
    "start": "1771600",
    "end": "1778640"
  },
  {
    "text": "container and the Nova agents are those like stateful sets running in master",
    "start": "1778640",
    "end": "1786080"
  },
  {
    "text": "nodes just just a sound bite on the architecture for how that works yeah I I I'll try but my team might want to jump",
    "start": "1786080",
    "end": "1792840"
  },
  {
    "text": "in too um so Nova itself is a you know kubernetes API server with a bunch of",
    "start": "1792840",
    "end": "1799799"
  },
  {
    "text": "controllers backing it that's a cluster it is a cluster but yeah you do not need to dedicate a",
    "start": "1799799",
    "end": "1806519"
  },
  {
    "text": "whole cluster to it you could share it with other things and the Nova agents",
    "start": "1806519",
    "end": "1812200"
  },
  {
    "text": "are um additional controllers just running on the workload",
    "start": "1812200",
    "end": "1817440"
  },
  {
    "text": "clusters are they running on the masters of each of the Clusters is that how that works they they're running on the",
    "start": "1817440",
    "end": "1823720"
  },
  {
    "text": "workload clusters I'll ask you later thank you very much it was very good",
    "start": "1823720",
    "end": "1829240"
  },
  {
    "text": "uh if you can give some insight as to what kind of minimum U uh RPO can be",
    "start": "1830279",
    "end": "1835679"
  },
  {
    "text": "achieved with NOA controller so the rpu is really dependent on the underlying postest",
    "start": "1835679",
    "end": "1841919"
  },
  {
    "text": "replication like I mentioned we Nova itself is not doing the replication",
    "start": "1841919",
    "end": "1847519"
  },
  {
    "text": "it'll just help you set it up by configuring your S3 bucket your making sure both sides have the same TLS or S3",
    "start": "1847519",
    "end": "1854320"
  },
  {
    "text": "secrets and stuff like that but the RPO the recovery Point objective itself will",
    "start": "1854320",
    "end": "1861120"
  },
  {
    "text": "depend on your application Nova can help with RTO the recovery time objective but",
    "start": "1861120",
    "end": "1867200"
  },
  {
    "text": "it cannot help with RPO so yeah RPO is mostly on database you can achieve zero",
    "start": "1867200",
    "end": "1873200"
  },
  {
    "text": "seconds but with certain sacrifices right but it depends a lot on your",
    "start": "1873200",
    "end": "1880720"
  },
  {
    "text": "workloads on how you use the data how you connect it and so",
    "start": "1880720",
    "end": "1886159"
  },
  {
    "text": "on hello uh I wanted to ask you because the script you showed seem rather manual",
    "start": "1886159",
    "end": "1894360"
  },
  {
    "text": "I mean that was uh fail over and I guess that you need to do some manual steps if",
    "start": "1894360",
    "end": "1900159"
  },
  {
    "text": "you would like to fail over back you know whenu switch from primary to",
    "start": "1900159",
    "end": "1905240"
  },
  {
    "text": "replica and then back something like this so maybe I wanted to ask you if there is some additional tooling to",
    "start": "1905240",
    "end": "1911480"
  },
  {
    "text": "automate this process even further that you developed uh let's say to have some",
    "start": "1911480",
    "end": "1916919"
  },
  {
    "text": "kind of of experience like we do have on RDS or something like this so we don't",
    "start": "1916919",
    "end": "1922240"
  },
  {
    "text": "need to bother which one of this primary and it just can switch uh to the secondary and back without any any",
    "start": "1922240",
    "end": "1929240"
  },
  {
    "text": "hustle yeah so what we showed is just sort of like uh a simple workflow of a",
    "start": "1929240",
    "end": "1935799"
  },
  {
    "text": "simplistic scenario and it can always be enhanced with more pieces to the",
    "start": "1935799",
    "end": "1941919"
  },
  {
    "text": "workflow I from what I understand uh what you're saying is that you want to switch to the standby but once the",
    "start": "1941919",
    "end": "1948600"
  },
  {
    "text": "primary is back up you want it to automatically switch back so yeah that can always be built uh this can always",
    "start": "1948600",
    "end": "1955799"
  },
  {
    "text": "be enhanced to do",
    "start": "1955799",
    "end": "1958840"
  },
  {
    "text": "that not yet we haven't built the fail back yet",
    "start": "1963320",
    "end": "1969559"
  },
  {
    "text": "but last question for you here so between the two methods of replication you talked about the streaming",
    "start": "1969559",
    "end": "1976039"
  },
  {
    "text": "replication and the Object Store replication do you have data um on how",
    "start": "1976039",
    "end": "1981200"
  },
  {
    "text": "fast it replicates let's say the primaries in the east region and the backup is in the west region how quickly",
    "start": "1981200",
    "end": "1987240"
  },
  {
    "text": "it replicates between the two methods it depends mostly on your networking and",
    "start": "1987240",
    "end": "1993120"
  },
  {
    "text": "the amounts of data right but uh again with streaming replication you CCH",
    "start": "1993120",
    "end": "1999559"
  },
  {
    "text": "almost like zero lck Z second lack so all the transaction would be see simultaneously but that would imply some",
    "start": "1999559",
    "end": "2007960"
  },
  {
    "text": "sacrifices again in performance",
    "start": "2007960",
    "end": "2011840"
  }
]
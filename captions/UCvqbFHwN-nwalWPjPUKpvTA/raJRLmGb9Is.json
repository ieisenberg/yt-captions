[
  {
    "start": "0",
    "end": "139000"
  },
  {
    "text": "all right welcome for our first talk of the morning here we've got a great talk",
    "start": "0",
    "end": "7200"
  },
  {
    "text": "by Rob and Laura from data dog and they're on the infrastructure team there and they're gonna talk a bit about the",
    "start": "7200",
    "end": "14070"
  },
  {
    "text": "Ottawa capability of kubernetes give him a big welcome hi folks",
    "start": "14070",
    "end": "26730"
  },
  {
    "text": "my name is Rob ball I work on the infrastructure team at beta dog as an engineering manager hi i'm long beyond I",
    "start": "26730",
    "end": "32730"
  },
  {
    "text": "awoke on the same infrastructure team and we focus on communities clusters so if you don't know data everything okay",
    "start": "32730",
    "end": "42690"
  },
  {
    "text": "of course know",
    "start": "42690",
    "end": "51980"
  },
  {
    "text": "well do W we don't the dead a dog whereas s based company and we do monitoring so we do infrastructure",
    "start": "61390",
    "end": "67630"
  },
  {
    "text": "monitoring a p.m. and logs and we had a large customer base and repossess a lot of data points every day we are you have",
    "start": "67630",
    "end": "73900"
  },
  {
    "text": "a few actual figures on the left-hand side of the slide and on the infrastructure chain were actually",
    "start": "73900",
    "end": "79750"
  },
  {
    "text": "focused on the infrastructure that is powering the product and we're talking about tens of thousands of hosts and",
    "start": "79750",
    "end": "85560"
  },
  {
    "text": "tens of commuters clusters of very different size between 50 and shree",
    "start": "85560",
    "end": "90580"
  },
  {
    "text": "thousand nodes for the bigger one and to give you an idea about half of them are pretty small so in the 50-100 node range",
    "start": "90580",
    "end": "97360"
  },
  {
    "text": "and the other odd is pretty big between 1500 and 2000 also with multi-cloud and",
    "start": "97360",
    "end": "102729"
  },
  {
    "text": "we're growing pretty fast which comes with quite a bit of challenges and so a",
    "start": "102729",
    "end": "107830"
  },
  {
    "text": "lot of times we have to understand what's happening why we have issues and we need to debug deeply what's happening",
    "start": "107830",
    "end": "113460"
  },
  {
    "text": "and to do that we're actually using other drugs this is what the talk is gonna be about so first to understand",
    "start": "113460",
    "end": "121720"
  },
  {
    "text": "what benefit we're getting out of our logs I think we need to dig in a little bit for some background on the kubernetes api so let's do that",
    "start": "121720",
    "end": "130170"
  },
  {
    "text": "kubernetes api is the set of REST API is provided by the API server it's backed by a database called that CD and there's",
    "start": "130230",
    "end": "136180"
  },
  {
    "text": "a lot of clients so let's look at what those clients look like first we've got the kubernetes control plan so a bunch of built-in controllers and the",
    "start": "136180",
    "end": "142060"
  },
  {
    "start": "139000",
    "end": "139000"
  },
  {
    "text": "scheduler that's in charge of scheduling workloads on two on two nodes and then some node daemons like the cubelet that",
    "start": "142060",
    "end": "147370"
  },
  {
    "text": "powers most of the kubernetes functionality and cube proxy which does some networking things and probably a",
    "start": "147370",
    "end": "152470"
  },
  {
    "text": "bunch of other no demons like monitoring demon or CNI or CSI or things like that",
    "start": "152470",
    "end": "157959"
  },
  {
    "text": "and they've got some cluster services of dns and ingress controller is autoscale",
    "start": "157959",
    "end": "163930"
  },
  {
    "text": "or external DNS certificate manager probably a bunch of other kubernetes native applications that you've written in-house and then finally users so",
    "start": "163930",
    "end": "171700"
  },
  {
    "text": "that's might be tools that are using acute control or users that are doing this in an interactive way",
    "start": "171700",
    "end": "177070"
  },
  {
    "text": "so get kind of a complex graph a lot of different things all reaching the API server and",
    "start": "177070",
    "end": "182140"
  },
  {
    "text": "do it that the API server is even calling itself so this can be tricky to debug issues and this you know sort of a",
    "start": "182140",
    "end": "187960"
  },
  {
    "text": "lot of complexity here in this graph there's even a little bit of hidden complexity in queue control in the way",
    "start": "187960",
    "end": "193600"
  },
  {
    "text": "that it works so let's take a quick look there as well looking at the simplest case here write a simple get ball and",
    "start": "193600",
    "end": "201100"
  },
  {
    "text": "what we see by using a hyper Basit e level on cube control we can actually see every API call that it's that it's",
    "start": "201100",
    "end": "206920"
  },
  {
    "text": "generating so there's some important details exposed here you see what API server we're reaching the API version of",
    "start": "206920",
    "end": "213340"
  },
  {
    "text": "the objects we're looking at what namespace those objects are in as well as the resource type and in this case",
    "start": "213340",
    "end": "218530"
  },
  {
    "text": "since we're just friendly we're getting a single resource the resource name as well with some more complex different",
    "start": "218530",
    "end": "225070"
  },
  {
    "start": "222000",
    "end": "222000"
  },
  {
    "text": "types of API calls when we do different operations so in this case when we do a list it's actually very similar to the",
    "start": "225070",
    "end": "230260"
  },
  {
    "text": "get but we're missing the resource name and so we can see how that URL translates it's very similar except missing the resource name at the end and",
    "start": "230260",
    "end": "236560"
  },
  {
    "text": "then keep control also does automatic pagination and so you can see that it's limiting to 500 resources so if you have",
    "start": "236560",
    "end": "242230"
  },
  {
    "text": "a lot of resources that are being returned you might actually see multiple API calls for this one operation with",
    "start": "242230",
    "end": "249010"
  },
  {
    "text": "some more get examples if you enable watch that actually results in two different API calls first the same get",
    "start": "249010",
    "end": "255489"
  },
  {
    "text": "that we saw before there returns the list of objects and then a subsequent get that's actually a watch with a",
    "start": "255489",
    "end": "261190"
  },
  {
    "text": "resource version so we take the resource version from the first list and we look for what this is going to return as all",
    "start": "261190",
    "end": "266710"
  },
  {
    "text": "of the changes that have happened since that first representation we received",
    "start": "266710",
    "end": "271710"
  },
  {
    "start": "271000",
    "end": "271000"
  },
  {
    "text": "described is also an interesting use case so when we look at keep control describe there's actually a couple different API calls here the first is",
    "start": "271770",
    "end": "278860"
  },
  {
    "text": "what you might expect we get the resource we understand the whole representation of it the second one is a little bit surprising where we're",
    "start": "278860",
    "end": "284950"
  },
  {
    "text": "looking at it get on events and so this is filtered using the involved object of the event and so the described is",
    "start": "284950",
    "end": "290740"
  },
  {
    "text": "actually looking at multiple different types of resources and then stitching them together on the client side and so",
    "start": "290740",
    "end": "296560"
  },
  {
    "text": "again so you know a lot of different API calls all coming from what looks like a simple operation there's also some",
    "start": "296560",
    "end": "302169"
  },
  {
    "text": "different patterns for mutating requests so when we do a delete this is actually three different API calls first it's a delete and then it's two subsequent gets",
    "start": "302169",
    "end": "309040"
  },
  {
    "text": "first and normal get and get with a watch and what's happening here is this is providing the user like a synchronous interaction so first we",
    "start": "309040",
    "end": "317300"
  },
  {
    "text": "delete the resource and then those two subsequent gets are scoped by some metadata on the object so we're not",
    "start": "317300",
    "end": "322430"
  },
  {
    "text": "getting 404 is when we try to get the object when it's in the path instead we're watching for updates on that object and we'll know when they light",
    "start": "322430",
    "end": "328100"
  },
  {
    "text": "when the delete is eventually completed and then there's some higher-level operations that we might want to look at",
    "start": "328100",
    "end": "333740"
  },
  {
    "text": "as well so like keep control create where we're doing a lot on the client side keep control is actually generating",
    "start": "333740",
    "end": "339919"
  },
  {
    "text": "the payload based on some minimal data that we're passing it in this case just the image we're building up a whole",
    "start": "339919",
    "end": "345470"
  },
  {
    "text": "payload based on the spec that we know for deployment and then using a post request for this and keep control scale",
    "start": "345470",
    "end": "352520"
  },
  {
    "text": "does a similar thing where we're doing an update in place so we first get the representation of the object that we",
    "start": "352520",
    "end": "357530"
  },
  {
    "text": "want to scale and then it generates a minimal request body and uses a patch API call so why do we go through all of",
    "start": "357530",
    "end": "364520"
  },
  {
    "text": "this to understand and I talked about Auto at low and slow they're trying to demonstrate the complexity in the",
    "start": "364520",
    "end": "369680"
  },
  {
    "text": "kubernetes api there's a lot of different components making calls to kubernetes api and they're doing a whole",
    "start": "369680",
    "end": "376039"
  },
  {
    "text": "variety of different API calls that may not be obvious from the surface these simple user operations translate to a",
    "start": "376039",
    "end": "381710"
  },
  {
    "text": "lot of different calls and so how can we help you know with audit log self understand what's actually going on so",
    "start": "381710",
    "end": "391389"
  },
  {
    "text": "other clothes are actually logs that are going to give you information about all",
    "start": "391389",
    "end": "396500"
  },
  {
    "text": "the API calls make sure you've made to your cluster so just to give you a quick definition it's like a rich structured JSON log output",
    "start": "396500",
    "end": "404720"
  },
  {
    "text": "pattern API server when you get the API call with additional metadata you can",
    "start": "404720",
    "end": "410660"
  },
  {
    "text": "configure the velocity and what's important is logging can happen a different stage of the request",
    "start": "410660",
    "end": "417080"
  },
  {
    "text": "processing and to give you an idea when a client is doing a request to the API server so they are room with a one on",
    "start": "417080",
    "end": "423380"
  },
  {
    "text": "top of it the API server is going to process this request and it's going to answer and when the answer is so when",
    "start": "423380",
    "end": "432080"
  },
  {
    "text": "the API server receive the request it can log an object at state request received with all the information from",
    "start": "432080",
    "end": "437750"
  },
  {
    "text": "the request and if you look at state streets of the final the answer the API server is going to look",
    "start": "437750",
    "end": "444080"
  },
  {
    "text": "at state response completes for a normal operation and respond started for watch because when you do a watch it's",
    "start": "444080",
    "end": "449810"
  },
  {
    "text": "actually a long live connection to the place every winner gets ultimate education to the objects we you're watching",
    "start": "449810",
    "end": "455710"
  },
  {
    "text": "so other clocks contain a lot of very interesting information and you have a few example of error and we're going to",
    "start": "455710",
    "end": "462080"
  },
  {
    "text": "dive into that so let's get back to the first gate example Rob game earlier when",
    "start": "462080",
    "end": "467720"
  },
  {
    "text": "we're just getting a part so you have the cube CTL come on at the top and the resulting API call and do what you see",
    "start": "467720",
    "end": "475400"
  },
  {
    "text": "at the bottom and on the left hand side is the audit log so of course I'm assuming most of you can't read it because it's very small but we're going",
    "start": "475400",
    "end": "481580"
  },
  {
    "text": "to dive into the different part of it so the first thing you get is what happens",
    "start": "481580",
    "end": "487100"
  },
  {
    "start": "484000",
    "end": "484000"
  },
  {
    "text": "so which resource was targeted so you can see on the first line the URI so",
    "start": "487100",
    "end": "492169"
  },
  {
    "text": "it's exactly what we got under arrest call and and then you have the verb that was used and in that case it's gets and",
    "start": "492169",
    "end": "499450"
  },
  {
    "text": "the data is very structured so the URI is passed so you can get a lot of informational happens so for instance",
    "start": "499450",
    "end": "506060"
  },
  {
    "text": "you have the API version the name spare that was used the resource you were getting and in the name of it and",
    "start": "506060",
    "end": "511460"
  },
  {
    "text": "finally you get the status code which is here 200 which means things are working fine another information you get in the",
    "start": "511460",
    "end": "519409"
  },
  {
    "text": "audit logs is who did the query so in this example here I was doing the query so you have my username and also the API",
    "start": "519409",
    "end": "527000"
  },
  {
    "text": "server it is going to add additional rich information which is the group you are part of which is interesting because",
    "start": "527000",
    "end": "532190"
  },
  {
    "text": "then you can see why request succeed or wait failed what's interesting is in",
    "start": "532190",
    "end": "538100"
  },
  {
    "start": "537000",
    "end": "537000"
  },
  {
    "text": "very recent version of kubernetes you can also see the reason why you call was",
    "start": "538100",
    "end": "543440"
  },
  {
    "text": "authorized so yeah this authorization block where you can see that Michael was loads",
    "start": "543440",
    "end": "548810"
  },
  {
    "text": "because my user was part of a group that's bound to a role with the proper permission and so that's why I can",
    "start": "548810",
    "end": "555170"
  },
  {
    "text": "actually do the get call you also have additional information so you can know",
    "start": "555170",
    "end": "561350"
  },
  {
    "text": "exactly when the request was made and also when it was finished if you're looking at this stage response comp list",
    "start": "561350",
    "end": "567800"
  },
  {
    "text": "I was showing earlier and by using the difference you can actually add the latency of the call so processing this get worried",
    "start": "567800",
    "end": "573760"
  },
  {
    "text": "actually took 14 milliseconds an additional piece of information you get is where the cargo is made from from",
    "start": "573760",
    "end": "579850"
  },
  {
    "text": "which IP address which can help you troubleshoot issues of where things were coming from let's look at another gate",
    "start": "579850",
    "end": "587230"
  },
  {
    "start": "586000",
    "end": "586000"
  },
  {
    "text": "code so you remember from earlier Rob was in an example of a get pod which is a global list of all the pods in the",
    "start": "587230",
    "end": "593800"
  },
  {
    "text": "namespace and you can see there that it's very similar except the verb is not",
    "start": "593800",
    "end": "599260"
  },
  {
    "text": "get this time so the API server is clever enough to transform the HTTP method into a via that makes sense",
    "start": "599260",
    "end": "605440"
  },
  {
    "text": "based on context so here it's not a get call it's actually a list call on the namespace which gives you all the above",
    "start": "605440",
    "end": "612610"
  },
  {
    "text": "permissions you need if you want to allow gate and disallow list for instance and and so yeah the gate is",
    "start": "612610",
    "end": "619089"
  },
  {
    "text": "mapped to different verbs we also showed watched before so when you do a watch",
    "start": "619089",
    "end": "625480"
  },
  {
    "start": "621000",
    "end": "621000"
  },
  {
    "text": "usually what happens is you first do a first list where you get all the information and then you you do the",
    "start": "625480",
    "end": "632200"
  },
  {
    "text": "watch itself and you can see on this example on the left hand side the first list call and then the watch call so I",
    "start": "632200",
    "end": "639670"
  },
  {
    "text": "like it just a few thing there so both of them are get calls by dam up to",
    "start": "639670",
    "end": "644770"
  },
  {
    "text": "different verbs once again list on the left-hand side and watch on the right-hand side and they appear at",
    "start": "644770",
    "end": "651070"
  },
  {
    "text": "different stages the list call is the call that terminates immediately so it's captured at response complete and the",
    "start": "651070",
    "end": "657880"
  },
  {
    "text": "word code is actually long lasting calls words captured as respond started and of course the watch go is starting after the list go because the fan first does",
    "start": "657880",
    "end": "664900"
  },
  {
    "text": "the least than the watch if we look at the create call so the call where work",
    "start": "664900",
    "end": "671050"
  },
  {
    "start": "668000",
    "end": "668000"
  },
  {
    "text": "was creating a deployment earlier we can see exactly the same type of information this time the verb is create so it once",
    "start": "671050",
    "end": "677350"
  },
  {
    "text": "again it's not the first verb and there's actually additional information in there which is the request object so",
    "start": "677350",
    "end": "684250"
  },
  {
    "text": "depending on the velocity you configure you can get different types of information and in that case we actually capture the request object and if we",
    "start": "684250",
    "end": "691630"
  },
  {
    "text": "zoom on the request object we can actually see the full spec of the deployment that was created so early",
    "start": "691630",
    "end": "699310"
  },
  {
    "text": "locks contain a lot of very interesting information the API server is adding very interesting metadata so I hope we",
    "start": "699310",
    "end": "705430"
  },
  {
    "text": "convinced you that a lot of things we can get out of them and now let's see how we can get them so let's look at how",
    "start": "705430",
    "end": "713050"
  },
  {
    "start": "711000",
    "end": "711000"
  },
  {
    "text": "you configure your kubernetes control plan to output audit logs in the most",
    "start": "713050",
    "end": "718180"
  },
  {
    "start": "718000",
    "end": "718000"
  },
  {
    "text": "basic configuration it's just two flags on your API server the first is a path to the file that you want them output to",
    "start": "718180",
    "end": "724060"
  },
  {
    "text": "and the second is the path to the audit policy file which is the description of how you want the API server to perform",
    "start": "724060",
    "end": "731290"
  },
  {
    "text": "auditing there's some advanced options that you can set here there's some stuff around rotation and alternative backends",
    "start": "731290",
    "end": "736960"
  },
  {
    "text": "like the web hook back end which will output to a web hook instead of to a local file and then there's some options",
    "start": "736960",
    "end": "742780"
  },
  {
    "text": "around async async' batching so this is a way that not output an audit record",
    "start": "742780",
    "end": "748090"
  },
  {
    "text": "for every API call synchronously with that API call but instead batch them up for performance reasons so one thing to",
    "start": "748090",
    "end": "755920"
  },
  {
    "text": "be aware of here is that there are some security implications so if you enable audit logs and for an exposed API server",
    "start": "755920",
    "end": "762970"
  },
  {
    "text": "and you start getting a lot of unauthenticated calls to that API server you're getting audit records for every one of them and so you're opening",
    "start": "762970",
    "end": "769150"
  },
  {
    "text": "yourself up to potential denial service there so just be careful about where you're exposing that API server when you",
    "start": "769150",
    "end": "774700"
  },
  {
    "text": "have these enabled the policy file is really where all the magic happens though so let's take a look at that that",
    "start": "774700",
    "end": "780310"
  },
  {
    "text": "policy is basically a list of rules in each of those rules is describing the operations that we want the API server",
    "start": "780310",
    "end": "785950"
  },
  {
    "text": "to generate audit records for and what those audit records should look like so the first section of each of these is a",
    "start": "785950",
    "end": "793030"
  },
  {
    "text": "description of what resources based on the API group and the resource type we want to match and what verbs we perform",
    "start": "793030",
    "end": "799630"
  },
  {
    "text": "on those resources it probably looks familiar to you if you've ever looked at kubernetes our back rules it's very",
    "start": "799630",
    "end": "806050"
  },
  {
    "text": "similar way to describe resources so in this case you can see we're just we're describing pod resources in the core",
    "start": "806050",
    "end": "812350"
  },
  {
    "text": "group and all mutating operations on them so create update delete as well as patch will all generate audit records",
    "start": "812350",
    "end": "818890"
  },
  {
    "text": "and in the second part of this rule is describing the level and stage for matching API calls so that's basically",
    "start": "818890",
    "end": "825250"
  },
  {
    "text": "telling you when to log at what point in the request lifecycle to log and what to log so here we're configuring the",
    "start": "825250",
    "end": "832279"
  },
  {
    "text": "request response level and that level is gonna log everything about the initial request including the request body as",
    "start": "832279",
    "end": "839000"
  },
  {
    "text": "well as the response in the response body so you're gonna get a lot of information there there's a few gotchas",
    "start": "839000",
    "end": "844430"
  },
  {
    "text": "to be aware of when you're writing these policies though when you're writing these the set of rules they're evaluated",
    "start": "844430",
    "end": "850190"
  },
  {
    "start": "847000",
    "end": "847000"
  },
  {
    "text": "in order top down in that file and so we have to be really careful about setting very broad rules at the top of the file",
    "start": "850190",
    "end": "855440"
  },
  {
    "text": "because once it matches once it's not going to match a second time request",
    "start": "855440",
    "end": "860720"
  },
  {
    "text": "level will include request metadata full request body and request response as the response body as well and so that can be",
    "start": "860720",
    "end": "867800"
  },
  {
    "text": "really powerful you can understand everything that's going on in those API that the full lifecycle but you need to",
    "start": "867800",
    "end": "872959"
  },
  {
    "text": "be really careful about them for large large payloads so if you're doing things like the logs API call you maybe end up",
    "start": "872959",
    "end": "879019"
  },
  {
    "text": "logging all of your logs into your audit logs in addition to that you need to be careful about some security sensitive",
    "start": "879019",
    "end": "885589"
  },
  {
    "text": "endpoints so token review you're gonna end up with your with your tokens logged out here other logs as well and finally",
    "start": "885589",
    "end": "892819"
  },
  {
    "text": "the API group when when you leave that empty that references the kubernetes core API group so that's not gonna match",
    "start": "892819",
    "end": "898069"
  },
  {
    "text": "any third party or custom API services that you have so make sure if you want them to generate audit records there",
    "start": "898069",
    "end": "903680"
  },
  {
    "text": "that you're explicitly putting them into your policy files I want to provide some recommendations for you to go write your",
    "start": "903680",
    "end": "909980"
  },
  {
    "start": "908000",
    "end": "908000"
  },
  {
    "text": "own policy files so our first one is to ignore the request receive stage it's typically redundant where we don't need",
    "start": "909980",
    "end": "917600"
  },
  {
    "text": "to log at both the time that we received the request and the time that we send the response we're getting much the same",
    "start": "917600",
    "end": "922939"
  },
  {
    "text": "data we want to use at least the metadata level for almost everything so",
    "start": "922939",
    "end": "928220"
  },
  {
    "text": "we want to ignore potentially health and metrics endpoints but for everything else that gives you a really good a really good way to understand all the",
    "start": "928220",
    "end": "934670"
  },
  {
    "text": "operations happening in your cluster and use request and request response level for critical resources and verbs this",
    "start": "934670",
    "end": "941420"
  },
  {
    "text": "can be super valuable for doing retroactive debugging and understanding the state of your cluster and how you got there",
    "start": "941420",
    "end": "946790"
  },
  {
    "text": "just again be careful for those larger sensitive request payloads or responsibilities you don't want to have",
    "start": "946790",
    "end": "953000"
  },
  {
    "text": "that stuff end up in your audit logs inadvertently there's some great links here we'll publish the slides later that",
    "start": "953000",
    "end": "958339"
  },
  {
    "text": "you can check them out or vacuum fishin on the audit policy as well as a pretty complete example coming from gke",
    "start": "958339",
    "end": "965959"
  },
  {
    "text": "so some quick takeaway is getting audit logs is pretty simple you set two flags on your API server and you're getting",
    "start": "965959",
    "end": "971399"
  },
  {
    "text": "them out to a file and then it's up to you to collect them and put them somewhere but getting the policies right is harder you're gonna get a huge volume",
    "start": "971399",
    "end": "977579"
  },
  {
    "text": "of logs so be prepared don't overwhelm downstream systems that are processing your logs from your cluster and it",
    "start": "977579",
    "end": "982649"
  },
  {
    "text": "requires a good solution to analyze them and be able to do some interesting operations that understand them so let's",
    "start": "982649",
    "end": "988439"
  },
  {
    "text": "take a minute and look at what audit logs look like on a real large cluster yes now that we're able to capture audit",
    "start": "988439",
    "end": "995550"
  },
  {
    "text": "log and we know what's in ZL it's let's look at what we can take out of them so the way we approach it is we took one of",
    "start": "995550",
    "end": "1001819"
  },
  {
    "text": "our larger cluster cluster with I think 2500 nodes and we looked at what was",
    "start": "1001819",
    "end": "1006889"
  },
  {
    "text": "happening on this cluster so this is like a very simple graph showing the number of Cole we're getting on this",
    "start": "1006889",
    "end": "1012709"
  },
  {
    "text": "cluster on the API server and as you can see we're getting about 900 calls per second which is quite a lot and the",
    "start": "1012709",
    "end": "1019459"
  },
  {
    "text": "first thing we wanted to do is say well who is actually making this call so we",
    "start": "1019459",
    "end": "1026298"
  },
  {
    "start": "1025000",
    "end": "1025000"
  },
  {
    "text": "grouped all the call by the user that was making the call and looked at the top 25 users and you can see they're the",
    "start": "1026299",
    "end": "1032990"
  },
  {
    "text": "first the first five so the first one is the API server making call to itself to verify things usually and the two",
    "start": "1032990",
    "end": "1040220"
  },
  {
    "text": "following ones are to proxy and local volunteer vision er which are two daemon sets running on every node so the first",
    "start": "1040220",
    "end": "1046579"
  },
  {
    "text": "one you're probably familiar with its listing and watching endpoints and services to make sure that you can do",
    "start": "1046579",
    "end": "1051590"
  },
  {
    "text": "client-side balancing on your hosts and the second one we use to provide local volumes to our applications and so this",
    "start": "1051590",
    "end": "1058279"
  },
  {
    "text": "one is actually updating the local volume and getting person volume information and the fourth one is the",
    "start": "1058279",
    "end": "1065720"
  },
  {
    "text": "cron job controller which is in this case very dependent on this tip and this cluster it's because we have a lot of",
    "start": "1065720",
    "end": "1071179"
  },
  {
    "text": "cron jobs of course the cron job is very active and the fifth one we also wanted to mention because it's spinnaker so",
    "start": "1071179",
    "end": "1077029"
  },
  {
    "text": "spinnaker is a tool we use to deploy it to our cluster and spinnaker is doing a lot of queries because it needs to",
    "start": "1077029",
    "end": "1082730"
  },
  {
    "text": "maintain a cache of everything that's in the cluster so it's doing a lot of lists and get calls on the cluster and that's",
    "start": "1082730",
    "end": "1088070"
  },
  {
    "text": "why it's so high so if you do the some of these and you're gonna notice that we're not",
    "start": "1088070",
    "end": "1093560"
  },
  {
    "text": "getting anywhere close to the 900 queries I was mentioning before I mean",
    "start": "1093560",
    "end": "1098690"
  },
  {
    "text": "well the total was 900 queries per seconds and we look at the top 25 they",
    "start": "1098690",
    "end": "1103850"
  },
  {
    "text": "only account for about 150 queries so what's happening to the 85 80 percent of",
    "start": "1103850",
    "end": "1109820"
  },
  {
    "text": "the other calls so maybe grouping by user wasn't such a great idea",
    "start": "1109820",
    "end": "1115250"
  },
  {
    "text": "so let's now group by groups ok so instead of grouping by users now grouping by the group the main group",
    "start": "1115250",
    "end": "1121850"
  },
  {
    "start": "1116000",
    "end": "1116000"
  },
  {
    "text": "used by the better calls and while we notice that the main one like by far is",
    "start": "1121850",
    "end": "1127220"
  },
  {
    "text": "the system note group and the reason that then showed before is because each",
    "start": "1127220",
    "end": "1132470"
  },
  {
    "text": "node has a different user to connect with the API server but they share the same you know the same the same group",
    "start": "1132470",
    "end": "1137780"
  },
  {
    "text": "and they're not making that many calls they are making a call about one call every three seconds but we have a lot of",
    "start": "1137780",
    "end": "1144830"
  },
  {
    "text": "notes so it makes a lot of queries so let's yet the DDF what's this book on so",
    "start": "1144830",
    "end": "1153020"
  },
  {
    "text": "here what we did is we actually took all the call by the system notes group so",
    "start": "1153020",
    "end": "1158210"
  },
  {
    "text": "from the cubelets basically and we're looking at the resources that are targeted and the main three resources",
    "start": "1158210",
    "end": "1163820"
  },
  {
    "text": "targeted are nodes so note actually you can form more than 50% of the total",
    "start": "1163820",
    "end": "1169010"
  },
  {
    "text": "queries on the cluster and then config maps and then secrets so we've wanted to know why we were",
    "start": "1169010",
    "end": "1177050"
  },
  {
    "text": "getting so many calls by the cubit to the nodes resources and so what we did",
    "start": "1177050",
    "end": "1182960"
  },
  {
    "start": "1182000",
    "end": "1182000"
  },
  {
    "text": "is we actually zoomed on a single cubelets and we looked at the call of a single qubit all the time so here are a",
    "start": "1182960",
    "end": "1189080"
  },
  {
    "text": "few minutes of logs from a single qubit and all the API call it mate and",
    "start": "1189080",
    "end": "1194240"
  },
  {
    "text": "individual it works and you can see that this cubelets is making two calls every 10 second one gets on its own node",
    "start": "1194240",
    "end": "1201650"
  },
  {
    "text": "object and one touch to update its condition so to tell the cluster well I'm still doing fine every since my aim",
    "start": "1201650",
    "end": "1208550"
  },
  {
    "text": "is the set of my conditions and here is my status and you actually have on the right hand side the detailed attach call",
    "start": "1208550",
    "end": "1214940"
  },
  {
    "text": "which is just a very simple call on the under not object to day the status and",
    "start": "1214940",
    "end": "1220960"
  },
  {
    "text": "it's interesting that it's acting every 10 seconds and it's actually a flag and configure on your cubelets and the",
    "start": "1220960",
    "end": "1227330"
  },
  {
    "text": "default is 10 second and that's why it's 10 seconds so we did the same for config",
    "start": "1227330",
    "end": "1232490"
  },
  {
    "start": "1230000",
    "end": "1230000"
  },
  {
    "text": "Maps and so the first thing we did is we'll say ok let's look at the single cubelet and what it's doing and config",
    "start": "1232490",
    "end": "1238820"
  },
  {
    "text": "maps and so it's only doing gates so it's different from earlier and there is",
    "start": "1238820",
    "end": "1243890"
  },
  {
    "text": "some kind of regularity but it is not as regular as was before so what we did next one the standings is",
    "start": "1243890",
    "end": "1249470"
  },
  {
    "text": "we actually looked at the actual resource that was retrieved by the cubelets and here it's different color",
    "start": "1249470",
    "end": "1256280"
  },
  {
    "start": "1254000",
    "end": "1254000"
  },
  {
    "text": "is a different company and if you look at any single config map in single color you're going to see that regular calls",
    "start": "1256280",
    "end": "1262580"
  },
  {
    "text": "are made for this config map and when happens is when you actually mount a volume-based using a config map the",
    "start": "1262580",
    "end": "1268700"
  },
  {
    "text": "cubit is actually going to synchronize it every few minutes and it's very regular and if you have butts with a lot",
    "start": "1268700",
    "end": "1274190"
  },
  {
    "text": "of config maps on a lot of butts it's actually going to be pretty intense on the API server because all these calls are gets it's actually exactly the",
    "start": "1274190",
    "end": "1281840"
  },
  {
    "text": "same secrets and we don't use community secrets at all except we use seven seconds so we have service account",
    "start": "1281840",
    "end": "1287630"
  },
  {
    "text": "tokens that are represented our secrets and downloaded to by the cubit to the nodes so so far we've looked at calls",
    "start": "1287630",
    "end": "1296360"
  },
  {
    "text": "and ways to filter them and aggregate them to make sense out of them but",
    "start": "1296360",
    "end": "1301430"
  },
  {
    "text": "what's interesting too is we can also look at the timing of the queries because as I was saying before we had we",
    "start": "1301430",
    "end": "1308090"
  },
  {
    "text": "have the information of when they request started and when it's finished so we can compute latency and on this",
    "start": "1308090",
    "end": "1313850"
  },
  {
    "start": "1313000",
    "end": "1313000"
  },
  {
    "text": "graph here what we did is we plotted latency for list calls by resource ok",
    "start": "1313850",
    "end": "1319460"
  },
  {
    "text": "over time and so you can see that difference resource and enlisting different resources is very different in",
    "start": "1319460",
    "end": "1325130"
  },
  {
    "text": "terms of timing so some resources are very fast to list some resources are slower so of course the more resources",
    "start": "1325130",
    "end": "1330350"
  },
  {
    "text": "you have a forgiving type the longer the collagen lasts but also you're going to see that it's very interestingly you we",
    "start": "1330350",
    "end": "1337220"
  },
  {
    "text": "have spikes and you can see spikes for instance here on the endpoint resource",
    "start": "1337220",
    "end": "1342470"
  },
  {
    "text": "and we looked into that and when is well q proxy is happy is watching and",
    "start": "1342470",
    "end": "1348340"
  },
  {
    "text": "bunch of course but sometimes we restart API servers and when we start API",
    "start": "1348340",
    "end": "1354100"
  },
  {
    "text": "service all the Q proxies that are connected to this API server are reconnecting to another API server and",
    "start": "1354100",
    "end": "1360429"
  },
  {
    "text": "what happens is when you have hundreds up to proxy during the first initial list to start the watch well it's of",
    "start": "1360429",
    "end": "1367090"
  },
  {
    "text": "course very heavy on the API server and that's why these calls are pretty long",
    "start": "1367090",
    "end": "1372779"
  },
  {
    "text": "another interesting thing we can do with latency is compare closer to make sure that all our close you are behaving",
    "start": "1372779",
    "end": "1378369"
  },
  {
    "start": "1373000",
    "end": "1373000"
  },
  {
    "text": "properly so in this example here what we're graphing is a single gate call on",
    "start": "1378369",
    "end": "1383740"
  },
  {
    "text": "the pod objects across different clusters and you can see that depending on the cluster these calls are very",
    "start": "1383740",
    "end": "1389289"
  },
  {
    "text": "different in terms of latency and we actually looked at all this cluster in detail and it turned out smaller cluster",
    "start": "1389289",
    "end": "1395860"
  },
  {
    "text": "are much faster and the main reason is has special get bigger number the load",
    "start": "1395860",
    "end": "1401080"
  },
  {
    "text": "on the API server is much much more heavy and of course it's slower quick",
    "start": "1401080",
    "end": "1408100"
  },
  {
    "start": "1407000",
    "end": "1407000"
  },
  {
    "text": "takeaways the biggest uses of your control plane and of your API server are going to be the components running on",
    "start": "1408100",
    "end": "1413950"
  },
  {
    "text": "each node so the cubelet and the daemon set such as to proxy for instance and there's actually a lot of effort",
    "start": "1413950",
    "end": "1420759"
  },
  {
    "text": "upstream to optimize it and to make sure that the Cuba is going to be more efficient in terms of calls just to",
    "start": "1420759",
    "end": "1426610"
  },
  {
    "text": "enable us to have bigger clusters because of course it's it's very intense if you had daemon sets that connect to",
    "start": "1426610",
    "end": "1434379"
  },
  {
    "text": "the API server that do API call be very careful because if they do operation that are intense on the API server like",
    "start": "1434379",
    "end": "1440529"
  },
  {
    "text": "least code for instance you can easily deduce your API server and it's actually things that happened quite a few times",
    "start": "1440529",
    "end": "1446499"
  },
  {
    "text": "and in our case the structure of the audit logs is very powerful",
    "start": "1446499",
    "end": "1451869"
  },
  {
    "text": "it's the JSON is very structured so you can filter and you can group which allows you to do slice and dice and very",
    "start": "1451869",
    "end": "1458139"
  },
  {
    "text": "easily go from a macro view to a very detailed view and that's very powerful reminder again they are very verbose so",
    "start": "1458139",
    "end": "1465850"
  },
  {
    "text": "be careful like on this example cursor we're about hundred blocks per second so that's that's quite a lot",
    "start": "1465850",
    "end": "1473700"
  },
  {
    "text": "so let's see how we can use audit logs to understand the internals of kubernetes and the way that we'll look",
    "start": "1474500",
    "end": "1479880"
  },
  {
    "text": "at this is by looking at a really simple operation right we're gonna create a deployment and this is about as minimal as we can make it it's just a single",
    "start": "1479880",
    "end": "1486630"
  },
  {
    "start": "1480000",
    "end": "1480000"
  },
  {
    "text": "container in this pot in every pod we're doing two replicas and just the required",
    "start": "1486630",
    "end": "1491700"
  },
  {
    "text": "labels so we're not adding anything fancy to this what happens when we submit it so we're looking at the kind",
    "start": "1491700",
    "end": "1497220"
  },
  {
    "start": "1496000",
    "end": "1496000"
  },
  {
    "text": "of kubernetes 101 view right now we did a lot of filtering to remove noise so we can see just the relevant audit calls",
    "start": "1497220",
    "end": "1503310"
  },
  {
    "text": "here and this starts with you know the sort of sequence of deploying submitting",
    "start": "1503310",
    "end": "1509370"
  },
  {
    "text": "the deployment and everything that happens until the pods are created and assigned to a node so we can see first that the user creates the deployment and",
    "start": "1509370",
    "end": "1515790"
  },
  {
    "text": "that's followed by the deployment controller reacting to that and creating the replica set and similarly the",
    "start": "1515790",
    "end": "1521610"
  },
  {
    "text": "replica set controller reacts to that creation by creating the pods associated with it and then the scheduler",
    "start": "1521610",
    "end": "1528120"
  },
  {
    "text": "eventually binds the pods to a node finally the node updates the status of those pods to container creating so",
    "start": "1528120",
    "end": "1534600"
  },
  {
    "text": "indicating that the scheduling decision is like accepted and everything's moving forward we can take a deeper look at one",
    "start": "1534600",
    "end": "1540390"
  },
  {
    "text": "of the audit records to tell us a little bit more about what's happening here so the one I'm choosing here is the is the",
    "start": "1540390",
    "end": "1545400"
  },
  {
    "text": "bind call the scheduler binding pods to nodes the call is performed by the scheduler we can see up at the top here",
    "start": "1545400",
    "end": "1551610"
  },
  {
    "text": "that it uses a create method it's a 201 so it's successful and then the object",
    "start": "1551610",
    "end": "1556890"
  },
  {
    "text": "reference audit record is pointing at the pod that's it's being referenced here and a sub resource called binding",
    "start": "1556890",
    "end": "1562710"
  },
  {
    "text": "so I actually discovered that binding is a resource while creating this talk finally you can see the target below",
    "start": "1562710",
    "end": "1568950"
  },
  {
    "text": "which is the node that the pot is being scheduled onto so we get a sort of whole view of what this operation looks like",
    "start": "1568950",
    "end": "1574970"
  },
  {
    "text": "the more advanced view of this whole lifecycle is actually a little bit more complex like I mentioned we did a lot of",
    "start": "1574970",
    "end": "1580470"
  },
  {
    "text": "filtering so this is what it looks like this is the full timeline of operations from everything from what we just talked",
    "start": "1580470",
    "end": "1587340"
  },
  {
    "text": "about all the way until the pods are actually running and it happens across about three seconds on this cluster for",
    "start": "1587340",
    "end": "1592560"
  },
  {
    "text": "this pod that first section on the left that you're looking at is the graph that we looked at on the last slide except",
    "start": "1592560",
    "end": "1598350"
  },
  {
    "text": "what you're seeing is in reality we only showed you ten audit events there is actually a total of 30 so we filtered out all of",
    "start": "1598350",
    "end": "1604610"
  },
  {
    "text": "the event creation all the API server calls to validate policies like quotas they get in list operations from each of",
    "start": "1604610",
    "end": "1611330"
  },
  {
    "text": "these components before they perform their mutations so there's a lot of different things going on there as well as the node workflow so everything that",
    "start": "1611330",
    "end": "1617330"
  },
  {
    "text": "happens once it goes from container creating to actually running on the node that node workflow is represented by",
    "start": "1617330",
    "end": "1623840"
  },
  {
    "text": "what's in the middle there and that's a sequence of events being published by the cubelet on the node as it goes through the lifecycle of the pod going",
    "start": "1623840",
    "end": "1630889"
  },
  {
    "text": "from container creating to being updated through all of the events that happen there and this is a great way to get an",
    "start": "1630889",
    "end": "1636019"
  },
  {
    "text": "idea of what's actually happening on the node this is the primary way that all this information for what the cubelet is actually doing is surfaced finally at",
    "start": "1636019",
    "end": "1643850"
  },
  {
    "text": "the end we see the resulting status updates so first the node updates the status of the containers and then all these",
    "start": "1643850",
    "end": "1650419"
  },
  {
    "text": "controllers in the kubernetes core are updating their the status of the the objects of the replicas setting of the",
    "start": "1650419",
    "end": "1656659"
  },
  {
    "text": "deployment as that cascades to the whole graph so let's take a closer look at that middle section the otic records for",
    "start": "1656659",
    "end": "1662450"
  },
  {
    "text": "the node workflow we can see the audit logs here and they're kind of reversed a little bit because you can see they're",
    "start": "1662450",
    "end": "1667789"
  },
  {
    "start": "1663000",
    "end": "1663000"
  },
  {
    "text": "in chronological order and by the time stamps on the left and those first calls are a get call to understand the full",
    "start": "1667789",
    "end": "1674440"
  },
  {
    "text": "resource for the pod updating the container creating which we already talked about and then a get for the",
    "start": "1674440",
    "end": "1680990"
  },
  {
    "text": "service account token because all of our pods have service accounts followed by a mountain valium event so this is one of",
    "start": "1680990",
    "end": "1688009"
  },
  {
    "text": "those node lifecycle events as it's preparing a volume that's going to get the service account token mounted a couple of events related to pulling the",
    "start": "1688009",
    "end": "1695389"
  },
  {
    "text": "image success of the image poll and the container being created and then finally one for starting the container and then",
    "start": "1695389",
    "end": "1703009"
  },
  {
    "text": "another final operation where we get the pod and then we update its status to running after this some other",
    "start": "1703009",
    "end": "1708320"
  },
  {
    "text": "controllers will takeover and cascade that status update through all the",
    "start": "1708320",
    "end": "1713350"
  },
  {
    "text": "Associated objects so some takeaways here there's a lot of interactions between all the different components",
    "start": "1713350",
    "end": "1719480"
  },
  {
    "text": "here a lot of different controllers and we can use audit logs to give us a really good understanding of it to sequence everything and understand how",
    "start": "1719480",
    "end": "1725809"
  },
  {
    "text": "they're all interacting the events can be really spiky and they generate a lot of logs but events in kubernetes by",
    "start": "1725809",
    "end": "1732080"
  },
  {
    "text": "default have only a one TTL which means they get purged from the data store after an hour and you can't",
    "start": "1732080",
    "end": "1737179"
  },
  {
    "text": "see them anymore so when you're doing describe on your resources you're only seeing the view for the last hour if",
    "start": "1737179",
    "end": "1742249"
  },
  {
    "text": "you're archiving your audit logs though you keep those events for as long as you're keeping your logs so you have that really nice retroactive view to",
    "start": "1742249",
    "end": "1748580"
  },
  {
    "text": "understand what was going on so now let's try to use audit logs to identify some problems in a kubernetes cluster up",
    "start": "1748580",
    "end": "1755690"
  },
  {
    "text": "to now we've seen how it can use other folks to have a macro view of what's happening on your treasure and drill down and the way that can be very",
    "start": "1755690",
    "end": "1762529"
  },
  {
    "text": "helpful in understanding the low-level interaction between controllers and we learned a lot by actually looking at",
    "start": "1762529",
    "end": "1768289"
  },
  {
    "text": "that we're now going to look at how we can use audit logs to troubleshoot problems so all these logs help you answer",
    "start": "1768289",
    "end": "1776090"
  },
  {
    "start": "1775000",
    "end": "1775000"
  },
  {
    "text": "questions such as why was resource deleted which is a question that's happened that we got quite a few times",
    "start": "1776090",
    "end": "1782299"
  },
  {
    "text": "and sometimes it's because another person has deleted it and nobody knew or it because the controller authority did",
    "start": "1782299",
    "end": "1788599"
  },
  {
    "text": "because it was garbage collected because the underling and underlying node was gone or it's because the HPA decided",
    "start": "1788599",
    "end": "1794779"
  },
  {
    "text": "that the load was low enough so it can it could delete one so all the traffic",
    "start": "1794779",
    "end": "1800269"
  },
  {
    "text": "will reduce information and one of the most interesting thing we've used audit",
    "start": "1800269",
    "end": "1805369"
  },
  {
    "text": "logs for is to debug performance regression or improve performances because as I was saying like all these",
    "start": "1805369",
    "end": "1810379"
  },
  {
    "text": "components may go to the API server and your API servers can become slow as you have do a lot of heavy queries and so",
    "start": "1810379",
    "end": "1816919"
  },
  {
    "text": "understanding which applications are doing heavy query is actually very powerful and also you can actually look",
    "start": "1816919",
    "end": "1822559"
  },
  {
    "text": "at the status codes because its nature tip it's an HTTP call and all the rest API calls are HTTP calls and you get a",
    "start": "1822559",
    "end": "1829340"
  },
  {
    "text": "status code and to be honest when we started this talk we didn't figure that we were going to find anything very",
    "start": "1829340",
    "end": "1834979"
  },
  {
    "start": "1831000",
    "end": "1831000"
  },
  {
    "text": "interesting there it turns out we were very wrong and so that's why we have to",
    "start": "1834979",
    "end": "1840169"
  },
  {
    "text": "have a full section on this so well of course the first thing is if you if you graph all these blogs by status codes",
    "start": "1840169",
    "end": "1846259"
  },
  {
    "text": "you can see a lot of 200 and 201 which make complete sand and that's good but also you can see 401 for instance and",
    "start": "1846259",
    "end": "1852399"
  },
  {
    "text": "actually when you dive into 400 so errors you can see a variety of",
    "start": "1852399",
    "end": "1857989"
  },
  {
    "text": "different errors and like that's where it I mean this is a live huge prediction question we should I get these errors",
    "start": "1857989",
    "end": "1864940"
  },
  {
    "text": "so first well before one that's a lot of inertia icicle that's weird",
    "start": "1864940",
    "end": "1870430"
  },
  {
    "text": "and so with what trying to understand what was happening because of course all our users log before they connect and",
    "start": "1870430",
    "end": "1875920"
  },
  {
    "text": "all the controllers and all the applications you see this count token so this should never happen so we slice and dice we drill down and",
    "start": "1875920",
    "end": "1883840"
  },
  {
    "text": "finally what we found out is that all these for one was actually actually coming to for single IPS and what had",
    "start": "1883840",
    "end": "1890890"
  },
  {
    "text": "happened is for cubelets had experts at three gates and we're actually trying to",
    "start": "1890890",
    "end": "1896110"
  },
  {
    "text": "connect and do their things and they were getting for once and the reason we missed them is because they'd been",
    "start": "1896110",
    "end": "1901630"
  },
  {
    "text": "removed from the cluster so they were not part of the presser anymore but the qubit was still trying to do things so",
    "start": "1901630",
    "end": "1907270"
  },
  {
    "text": "while we did the talk and we fixed it well forestry was kind of a weird so why",
    "start": "1907270",
    "end": "1913810"
  },
  {
    "text": "are we getting forbidden I mean it I mean it would happen from time to time but it shouldn't be that regular and so",
    "start": "1913810",
    "end": "1919870"
  },
  {
    "text": "it turns out when we plotted it by user we we found a single trap status account which is tragic which we use for some",
    "start": "1919870",
    "end": "1926500"
  },
  {
    "text": "ingress that was getting forestries and my first feeling was well this is probably about a by configuration so",
    "start": "1926500",
    "end": "1932950"
  },
  {
    "text": "let's look at what's actually failing and what was fairly was a least secret",
    "start": "1932950",
    "end": "1938890"
  },
  {
    "text": "school and I'm like that's weird I mean we don't use committed secrets and there's no reason for traffic to do",
    "start": "1938890",
    "end": "1944740"
  },
  {
    "text": "that and of course traffic doesn't have the proper a back policy to do it because it doesn't need it",
    "start": "1944740",
    "end": "1949810"
  },
  {
    "text": "it turns out it's actually built into the code and it's doing it so yeah traffic is gonna list all your secrets",
    "start": "1949810",
    "end": "1956520"
  },
  {
    "text": "unless you forbid it the last one was probably the weirdest",
    "start": "1956520",
    "end": "1962790"
  },
  {
    "text": "we were getting for 22 which are invalid HTTP queries and once again this was",
    "start": "1962790",
    "end": "1968470"
  },
  {
    "text": "very weird so the first thing we did is look at which user were actually getting",
    "start": "1968470",
    "end": "1973570"
  },
  {
    "text": "this for 22 and it tell that it's a built in controller from kubernetes so how like wow this is very like a",
    "start": "1973570",
    "end": "1981070"
  },
  {
    "text": "built-in controller should never create invalid queries I mean it's a built-in controller why would that happen and so",
    "start": "1981070",
    "end": "1987940"
  },
  {
    "text": "we dive deeper and we looked at the at the cogut was actually failing and what getting in for 22 and it was the patch",
    "start": "1987940",
    "end": "1994390"
  },
  {
    "start": "1988000",
    "end": "1988000"
  },
  {
    "text": "and the pod object so if you look at the job patch at the at the bottom of the slide you can see that the garbage controller is",
    "start": "1994390",
    "end": "2000380"
  },
  {
    "text": "trying to remove the owner reference to make the pod open from what it was controlled by enter well that's where",
    "start": "2000380",
    "end": "2007820"
  },
  {
    "text": "this is a very simple patch code there's no way it should trigger for 22 so what",
    "start": "2007820",
    "end": "2013850"
  },
  {
    "start": "2013000",
    "end": "2013000"
  },
  {
    "text": "was happening was actually pretty complex is these spots were evicted okay",
    "start": "2013850",
    "end": "2019550"
  },
  {
    "text": "so they had been evicted for reasons from from nodes and they were controlled by a replica set controller which had",
    "start": "2019550",
    "end": "2025460"
  },
  {
    "text": "been deleted and so what should have happened is sponge would have been often by the garbage controller and the way",
    "start": "2025460",
    "end": "2030950"
  },
  {
    "text": "the garbage control is opening this bus is actually removing the owner reference and but it was failing so well we had",
    "start": "2030950",
    "end": "2038300"
  },
  {
    "text": "this replica set that was terminating and it had been terminating for two months as of this morning I think it's still the case and so the root cause is",
    "start": "2038300",
    "end": "2047210"
  },
  {
    "text": "we use mutating webhooks to help application developers and by providing",
    "start": "2047210",
    "end": "2052760"
  },
  {
    "text": "them with sended and Brendon environment variables DNS configurations and we configured these web hooks to a both on",
    "start": "2052760",
    "end": "2059510"
  },
  {
    "text": "the create call a crate operation and update operation and so they actually applied to touch and things like these",
    "start": "2059510",
    "end": "2066440"
  },
  {
    "text": "calls are actually modifying immutable field immutable fields and of course the",
    "start": "2066440",
    "end": "2071480"
  },
  {
    "text": "API server is failing when you get a call that is trying to modify an immutable field and that's what the garbage collector wasn't able to garbage",
    "start": "2071480",
    "end": "2077690"
  },
  {
    "text": "collector cuts so and takeaways while looking at and using other clocks for",
    "start": "2077690",
    "end": "2083658"
  },
  {
    "text": "debugging is very helpful and like just writing this talk we found three different problem that we fixed so that",
    "start": "2083659",
    "end": "2089270"
  },
  {
    "text": "was interesting and let's conclude so we",
    "start": "2089270",
    "end": "2094970"
  },
  {
    "start": "2093000",
    "end": "2093000"
  },
  {
    "text": "hope that with this talk you guys learned that all in logs can be incredibly valuable we take advantage of them all the time and they've been",
    "start": "2094970",
    "end": "2100720"
  },
  {
    "text": "instrumental in us understanding our kubernetes clusters the low-level details and detecting misconfigurations",
    "start": "2100720",
    "end": "2106750"
  },
  {
    "text": "troubleshooting issues it's it's really been super valuable for us you know taking advantage of them does require a",
    "start": "2106750",
    "end": "2113049"
  },
  {
    "text": "little bit of effort the policy is a little bit complicated and they're hard to get right and they do require a little an advanced tool train to figure",
    "start": "2113049",
    "end": "2119710"
  },
  {
    "text": "it out but they can be super valuable I hope you all go enable audit logs in your clusters if you aren't already and",
    "start": "2119710",
    "end": "2124839"
  },
  {
    "text": "walk away with some value from this and that's all you can find us at the booth",
    "start": "2124839",
    "end": "2129940"
  },
  {
    "text": "later where we'll be around at the data dog booth or reach out to us on Twitter or email if you're interested and we're always hiring so this is interesting",
    "start": "2129940",
    "end": "2136569"
  },
  {
    "text": "come find us [Applause]",
    "start": "2136569",
    "end": "2141790"
  }
]
[
  {
    "text": "hello welcome to the talk",
    "start": "1199",
    "end": "3360"
  },
  {
    "text": "we'll do an intro and a deep dive into",
    "start": "3360",
    "end": "5279"
  },
  {
    "text": "what rook is",
    "start": "5279",
    "end": "6560"
  },
  {
    "text": "uh but basically rook is a kubernetes",
    "start": "6560",
    "end": "8880"
  },
  {
    "text": "storage platform",
    "start": "8880",
    "end": "11040"
  },
  {
    "text": "i am travis nielsen i'm from red hat my",
    "start": "11040",
    "end": "13519"
  },
  {
    "text": "colleague satoru",
    "start": "13519",
    "end": "15599"
  },
  {
    "text": "from saibusu will also be talking with",
    "start": "15599",
    "end": "17760"
  },
  {
    "text": "us",
    "start": "17760",
    "end": "18800"
  },
  {
    "text": "but today i want to talk about",
    "start": "18800",
    "end": "20720"
  },
  {
    "text": "first of all what are kubernetes storage",
    "start": "20720",
    "end": "23119"
  },
  {
    "text": "challenges that everyone has",
    "start": "23119",
    "end": "25519"
  },
  {
    "text": "then let's get into what is rook what is",
    "start": "25519",
    "end": "28240"
  },
  {
    "text": "ceph how they work together",
    "start": "28240",
    "end": "30640"
  },
  {
    "text": "and then we'll get into some features",
    "start": "30640",
    "end": "33200"
  },
  {
    "text": "and what features are have all his work",
    "start": "33200",
    "end": "35440"
  },
  {
    "text": "always had",
    "start": "35440",
    "end": "36559"
  },
  {
    "text": "and what features are in our latest",
    "start": "36559",
    "end": "38559"
  },
  {
    "text": "release 1.8",
    "start": "38559",
    "end": "40640"
  },
  {
    "text": "zotero will then show a demo of what",
    "start": "40640",
    "end": "43120"
  },
  {
    "text": "it's like to use rook",
    "start": "43120",
    "end": "44640"
  },
  {
    "text": "and at the end we'll be happy to take",
    "start": "44640",
    "end": "46320"
  },
  {
    "text": "your questions",
    "start": "46320",
    "end": "47520"
  },
  {
    "text": "so during this presentation",
    "start": "47520",
    "end": "49760"
  },
  {
    "text": "you can type your questions",
    "start": "49760",
    "end": "52160"
  },
  {
    "text": "in the chat or you can save them to the",
    "start": "52160",
    "end": "54320"
  },
  {
    "text": "end",
    "start": "54320",
    "end": "55760"
  },
  {
    "text": "so what are your kubernetes storage",
    "start": "55760",
    "end": "57440"
  },
  {
    "text": "challenges",
    "start": "57440",
    "end": "58399"
  },
  {
    "text": "everyone who adds kubernetes really",
    "start": "58399",
    "end": "60239"
  },
  {
    "text": "needs to have applications that store",
    "start": "60239",
    "end": "62640"
  },
  {
    "text": "things",
    "start": "62640",
    "end": "63920"
  },
  {
    "text": "kubernetes is a is a platform to manage",
    "start": "63920",
    "end": "66159"
  },
  {
    "text": "distributed applications",
    "start": "66159",
    "end": "68240"
  },
  {
    "text": "now these applications are traditionally",
    "start": "68240",
    "end": "70560"
  },
  {
    "text": "stateless or they don't need to store",
    "start": "70560",
    "end": "72400"
  },
  {
    "text": "anything",
    "start": "72400",
    "end": "73680"
  },
  {
    "text": "so you're relying on some external",
    "start": "73680",
    "end": "75520"
  },
  {
    "text": "storage to serve what's backing your",
    "start": "75520",
    "end": "79040"
  },
  {
    "text": "your applications so these applications",
    "start": "79040",
    "end": "81600"
  },
  {
    "text": "if they have storage that's outside",
    "start": "81600",
    "end": "83200"
  },
  {
    "text": "kubernetes it's difficult to make them",
    "start": "83200",
    "end": "85200"
  },
  {
    "text": "portable",
    "start": "85200",
    "end": "86799"
  },
  {
    "text": "it's a it's a burden to deploy because",
    "start": "86799",
    "end": "89119"
  },
  {
    "text": "the storage may be different everywhere",
    "start": "89119",
    "end": "91119"
  },
  {
    "text": "you deploy",
    "start": "91119",
    "end": "92640"
  },
  {
    "text": "and then at the end of the day who is",
    "start": "92640",
    "end": "94560"
  },
  {
    "text": "managing the storage",
    "start": "94560",
    "end": "96560"
  },
  {
    "text": "do you rely on a cloud provider that",
    "start": "96560",
    "end": "99360"
  },
  {
    "text": "manages this",
    "start": "99360",
    "end": "100880"
  },
  {
    "text": "manages that storage and if so",
    "start": "100880",
    "end": "103119"
  },
  {
    "text": "you may run into vendor lock-in",
    "start": "103119",
    "end": "104560"
  },
  {
    "text": "challenges where",
    "start": "104560",
    "end": "106159"
  },
  {
    "text": "you don't want to be tied to any",
    "start": "106159",
    "end": "108240"
  },
  {
    "text": "particular storage platform",
    "start": "108240",
    "end": "111280"
  },
  {
    "text": "so here's where rook came in we were",
    "start": "111280",
    "end": "113200"
  },
  {
    "text": "looking at kubernetes and we thought hey",
    "start": "113200",
    "end": "115840"
  },
  {
    "text": "how do we bring storage to kubernetes in",
    "start": "115840",
    "end": "118159"
  },
  {
    "text": "a way that's natively built in to",
    "start": "118159",
    "end": "120960"
  },
  {
    "text": "kubernetes and works well with",
    "start": "120960",
    "end": "122320"
  },
  {
    "text": "kubernetes",
    "start": "122320",
    "end": "124079"
  },
  {
    "text": "so rook it creates and provides a data",
    "start": "124079",
    "end": "127280"
  },
  {
    "text": "platform inside your same kubernetes",
    "start": "127280",
    "end": "129520"
  },
  {
    "text": "cluster where you're running other",
    "start": "129520",
    "end": "130959"
  },
  {
    "text": "applications",
    "start": "130959",
    "end": "132640"
  },
  {
    "text": "you will then consume the rook storage",
    "start": "132640",
    "end": "135120"
  },
  {
    "text": "just like any other",
    "start": "135120",
    "end": "136560"
  },
  {
    "text": "storage using storage classes and pvcs",
    "start": "136560",
    "end": "141520"
  },
  {
    "text": "the way rook is implemented is with an",
    "start": "141520",
    "end": "143920"
  },
  {
    "text": "operator kubernetes operator and custom",
    "start": "143920",
    "end": "146879"
  },
  {
    "text": "resource definitions",
    "start": "146879",
    "end": "148640"
  },
  {
    "text": "so using the custom resource definitions",
    "start": "148640",
    "end": "150560"
  },
  {
    "text": "you can tell rook how you want the",
    "start": "150560",
    "end": "152400"
  },
  {
    "text": "storage configured",
    "start": "152400",
    "end": "154480"
  },
  {
    "text": "but at the end of the day the power that",
    "start": "154480",
    "end": "157040"
  },
  {
    "text": "rook provides is",
    "start": "157040",
    "end": "158640"
  },
  {
    "text": "automating",
    "start": "158640",
    "end": "159840"
  },
  {
    "text": "the storage platform deploying it for",
    "start": "159840",
    "end": "162000"
  },
  {
    "text": "you configuring it for you",
    "start": "162000",
    "end": "164080"
  },
  {
    "text": "managing upgrades for you so you don't",
    "start": "164080",
    "end": "167040"
  },
  {
    "text": "have to know all the details of how the",
    "start": "167040",
    "end": "168720"
  },
  {
    "text": "storage platform works",
    "start": "168720",
    "end": "170959"
  },
  {
    "text": "now rook is open source it's",
    "start": "170959",
    "end": "173920"
  },
  {
    "text": "based on apache 2 io license so it's",
    "start": "173920",
    "end": "176480"
  },
  {
    "text": "very flexible to allow you to deploy in",
    "start": "176480",
    "end": "178560"
  },
  {
    "text": "your environments",
    "start": "178560",
    "end": "181360"
  },
  {
    "text": "i just want to stop for a moment and say",
    "start": "181760",
    "end": "183120"
  },
  {
    "text": "happy fifth birthday to rook",
    "start": "183120",
    "end": "185760"
  },
  {
    "text": "in kubecon seattle",
    "start": "185760",
    "end": "188000"
  },
  {
    "text": "five years ago we first went public and",
    "start": "188000",
    "end": "190400"
  },
  {
    "text": "open sourced rook first excited for all",
    "start": "190400",
    "end": "192879"
  },
  {
    "text": "the community support and the growth",
    "start": "192879",
    "end": "194560"
  },
  {
    "text": "that we've had over the past five years",
    "start": "194560",
    "end": "196560"
  },
  {
    "text": "to help it be production ready and",
    "start": "196560",
    "end": "199120"
  },
  {
    "text": "deployed in many production environments",
    "start": "199120",
    "end": "202159"
  },
  {
    "text": "so let's get into what is ceph",
    "start": "202159",
    "end": "204560"
  },
  {
    "text": "so ceph is a storage is the storage",
    "start": "204560",
    "end": "207120"
  },
  {
    "text": "platform that rook deploys",
    "start": "207120",
    "end": "209440"
  },
  {
    "text": "sephi is also open source and it",
    "start": "209440",
    "end": "212319"
  },
  {
    "text": "provides three types of storage it",
    "start": "212319",
    "end": "214400"
  },
  {
    "text": "provides",
    "start": "214400",
    "end": "215599"
  },
  {
    "text": "block storage shared file system",
    "start": "215599",
    "end": "218560"
  },
  {
    "text": "and object which is fs3 compliant",
    "start": "218560",
    "end": "222480"
  },
  {
    "text": "ceph favors data consistency so you",
    "start": "222480",
    "end": "225040"
  },
  {
    "text": "never have to worry about if your data",
    "start": "225040",
    "end": "226640"
  },
  {
    "text": "is safe",
    "start": "226640",
    "end": "228560"
  },
  {
    "text": "and",
    "start": "228560",
    "end": "229680"
  },
  {
    "text": "seth has been around for almost 10 years",
    "start": "229680",
    "end": "231519"
  },
  {
    "text": "now in production environments it was",
    "start": "231519",
    "end": "233360"
  },
  {
    "text": "first released in july of 2012.",
    "start": "233360",
    "end": "237040"
  },
  {
    "text": "and you can refer to the website ceph.io",
    "start": "237040",
    "end": "239519"
  },
  {
    "text": "for more information",
    "start": "239519",
    "end": "241920"
  },
  {
    "text": "so architecturally",
    "start": "241920",
    "end": "244000"
  },
  {
    "text": "rook really",
    "start": "244000",
    "end": "245439"
  },
  {
    "text": "has three layers to consider",
    "start": "245439",
    "end": "247840"
  },
  {
    "text": "so that the top layer",
    "start": "247840",
    "end": "249519"
  },
  {
    "text": "rook owns",
    "start": "249519",
    "end": "251040"
  },
  {
    "text": "the management layer so we rook deploys",
    "start": "251040",
    "end": "254799"
  },
  {
    "text": "the operator and manages the storage",
    "start": "254799",
    "end": "257359"
  },
  {
    "text": "platform",
    "start": "257359",
    "end": "258880"
  },
  {
    "text": "rook deploys a csi driver so the csi",
    "start": "258880",
    "end": "262560"
  },
  {
    "text": "driver now is the second layer",
    "start": "262560",
    "end": "265199"
  },
  {
    "text": "that csi driver dynamically provisions",
    "start": "265199",
    "end": "268320"
  },
  {
    "text": "and then mounts the storage to your",
    "start": "268320",
    "end": "269840"
  },
  {
    "text": "application pods",
    "start": "269840",
    "end": "272800"
  },
  {
    "text": "and then the third layer",
    "start": "272880",
    "end": "274960"
  },
  {
    "text": "is ceph so seth is the actual data layer",
    "start": "274960",
    "end": "278240"
  },
  {
    "text": "anytime your pod is reading and writing",
    "start": "278240",
    "end": "280320"
  },
  {
    "text": "data to the cluster it will go directly",
    "start": "280320",
    "end": "283120"
  },
  {
    "text": "to ceph",
    "start": "283120",
    "end": "284320"
  },
  {
    "text": "for that storage and rook is not",
    "start": "284320",
    "end": "286639"
  },
  {
    "text": "involved in the data layer rook is",
    "start": "286639",
    "end": "288479"
  },
  {
    "text": "really only the management layer",
    "start": "288479",
    "end": "290720"
  },
  {
    "text": "so i've got some diagrams now that will",
    "start": "290720",
    "end": "292560"
  },
  {
    "text": "help us see these different layers and",
    "start": "292560",
    "end": "294479"
  },
  {
    "text": "how they're separated in a few different",
    "start": "294479",
    "end": "296880"
  },
  {
    "text": "ways",
    "start": "296880",
    "end": "298639"
  },
  {
    "text": "so first the rook management layer",
    "start": "298639",
    "end": "300880"
  },
  {
    "text": "so rook owns the deployment of all the",
    "start": "300880",
    "end": "304160"
  },
  {
    "text": "the pods and the services and the",
    "start": "304160",
    "end": "306240"
  },
  {
    "text": "endpoints",
    "start": "306240",
    "end": "307360"
  },
  {
    "text": "and all of the resources to make up the",
    "start": "307360",
    "end": "309680"
  },
  {
    "text": "ceph cluster to provide that data",
    "start": "309680",
    "end": "311759"
  },
  {
    "text": "platform",
    "start": "311759",
    "end": "313120"
  },
  {
    "text": "so this is a diagram of pods that might",
    "start": "313120",
    "end": "315840"
  },
  {
    "text": "be running on three different nodes",
    "start": "315840",
    "end": "318000"
  },
  {
    "text": "so the pods in blue are",
    "start": "318000",
    "end": "320560"
  },
  {
    "text": "the rook pods so the rook operator",
    "start": "320560",
    "end": "323120"
  },
  {
    "text": "and a rook discovery daemon",
    "start": "323120",
    "end": "325600"
  },
  {
    "text": "so they provide management",
    "start": "325600",
    "end": "328400"
  },
  {
    "text": "the green pods then are the csi driver",
    "start": "328400",
    "end": "331280"
  },
  {
    "text": "the csi driver the csi provisioner the",
    "start": "331280",
    "end": "333840"
  },
  {
    "text": "rbd plug-in which is for block storage",
    "start": "333840",
    "end": "336000"
  },
  {
    "text": "and this ffs plugin which is for the",
    "start": "336000",
    "end": "338080"
  },
  {
    "text": "shared file system storage",
    "start": "338080",
    "end": "341039"
  },
  {
    "text": "and then each of the red pods",
    "start": "341039",
    "end": "344160"
  },
  {
    "text": "is a seth daemon so the ceph",
    "start": "344160",
    "end": "347120"
  },
  {
    "text": "pods are the ones that actually provide",
    "start": "347120",
    "end": "348639"
  },
  {
    "text": "that data layer and there are a number",
    "start": "348639",
    "end": "350479"
  },
  {
    "text": "of different",
    "start": "350479",
    "end": "351680"
  },
  {
    "text": "daemons that ceph provides in that in",
    "start": "351680",
    "end": "354400"
  },
  {
    "text": "that data layer the mons and osds",
    "start": "354400",
    "end": "357039"
  },
  {
    "text": "the manager",
    "start": "357039",
    "end": "358880"
  },
  {
    "text": "and so on",
    "start": "358880",
    "end": "360319"
  },
  {
    "text": "we won't get into exactly what all those",
    "start": "360319",
    "end": "362160"
  },
  {
    "text": "seth demons are but",
    "start": "362160",
    "end": "364319"
  },
  {
    "text": "so here we see that rook is really",
    "start": "364319",
    "end": "366880"
  },
  {
    "text": "managing the deployment of these pods",
    "start": "366880",
    "end": "369680"
  },
  {
    "text": "and deciding how to configure the ceph",
    "start": "369680",
    "end": "372319"
  },
  {
    "text": "demons",
    "start": "372319",
    "end": "374639"
  },
  {
    "text": "so at the second layer so if we look at",
    "start": "374639",
    "end": "377280"
  },
  {
    "text": "after",
    "start": "377280",
    "end": "378240"
  },
  {
    "text": "rook and sapphire deployed now how do",
    "start": "378240",
    "end": "381039"
  },
  {
    "text": "you attach your storage your application",
    "start": "381039",
    "end": "383440"
  },
  {
    "text": "pods to consume that storage or you need",
    "start": "383440",
    "end": "385600"
  },
  {
    "text": "to first provision that storage",
    "start": "385600",
    "end": "388080"
  },
  {
    "text": "so the csi driver",
    "start": "388080",
    "end": "390400"
  },
  {
    "text": "will take your application and your",
    "start": "390400",
    "end": "392639"
  },
  {
    "text": "application has a volume claim or a pvc",
    "start": "392639",
    "end": "397120"
  },
  {
    "text": "that",
    "start": "397120",
    "end": "398560"
  },
  {
    "text": "that pvc",
    "start": "398560",
    "end": "400000"
  },
  {
    "text": "will consume the storage from a storage",
    "start": "400000",
    "end": "402000"
  },
  {
    "text": "class which is a ceph",
    "start": "402000",
    "end": "404400"
  },
  {
    "text": "rbd",
    "start": "404400",
    "end": "405520"
  },
  {
    "text": "for a block storage or set fs storage",
    "start": "405520",
    "end": "408720"
  },
  {
    "text": "class for shared storage",
    "start": "408720",
    "end": "411280"
  },
  {
    "text": "csi driver will provision the storage",
    "start": "411280",
    "end": "413680"
  },
  {
    "text": "either for that block or that file",
    "start": "413680",
    "end": "415280"
  },
  {
    "text": "system storage",
    "start": "415280",
    "end": "416720"
  },
  {
    "text": "now on the right hand side with these",
    "start": "416720",
    "end": "418880"
  },
  {
    "text": "purple",
    "start": "418880",
    "end": "420880"
  },
  {
    "text": "boxes we see this is with an object",
    "start": "420880",
    "end": "424000"
  },
  {
    "text": "storage so an s3 interface provides",
    "start": "424000",
    "end": "427360"
  },
  {
    "text": "access to object storage",
    "start": "427360",
    "end": "429280"
  },
  {
    "text": "and we provision that in a similar",
    "start": "429280",
    "end": "431919"
  },
  {
    "text": "pattern to pvcs with what we call a",
    "start": "431919",
    "end": "434479"
  },
  {
    "text": "bucket claim so",
    "start": "434479",
    "end": "437199"
  },
  {
    "text": "an object bucket is of course something",
    "start": "437199",
    "end": "439440"
  },
  {
    "text": "that's backing the storage is backing an",
    "start": "439440",
    "end": "441360"
  },
  {
    "text": "s3 endpoint",
    "start": "441360",
    "end": "443440"
  },
  {
    "text": "and that endpoint comes from a storage",
    "start": "443440",
    "end": "445919"
  },
  {
    "text": "class which declares where in ceph",
    "start": "445919",
    "end": "449120"
  },
  {
    "text": "to configure that storage",
    "start": "449120",
    "end": "451840"
  },
  {
    "text": "now at the third layer",
    "start": "451840",
    "end": "453599"
  },
  {
    "text": "after",
    "start": "453599",
    "end": "454639"
  },
  {
    "text": "the data the storage is already",
    "start": "454639",
    "end": "456560"
  },
  {
    "text": "provisioned how does the application",
    "start": "456560",
    "end": "458960"
  },
  {
    "text": "write to the",
    "start": "458960",
    "end": "460880"
  },
  {
    "text": "the",
    "start": "460880",
    "end": "461680"
  },
  {
    "text": "data layer",
    "start": "461680",
    "end": "463360"
  },
  {
    "text": "so seth",
    "start": "463360",
    "end": "464879"
  },
  {
    "text": "has a driver that after it's mounted",
    "start": "464879",
    "end": "467280"
  },
  {
    "text": "this rbd kernel driver for block storage",
    "start": "467280",
    "end": "469759"
  },
  {
    "text": "it will write to the ceph cluster",
    "start": "469759",
    "end": "472800"
  },
  {
    "text": "if you have a shared file system the set",
    "start": "472800",
    "end": "474879"
  },
  {
    "text": "ffs kernel driver will write to the ceph",
    "start": "474879",
    "end": "477120"
  },
  {
    "text": "cluster and it will manage the",
    "start": "477120",
    "end": "479360"
  },
  {
    "text": "communication between all of those",
    "start": "479360",
    "end": "480800"
  },
  {
    "text": "different ceph pods",
    "start": "480800",
    "end": "483120"
  },
  {
    "text": "or if you have an s3 client the s3",
    "start": "483120",
    "end": "485440"
  },
  {
    "text": "client will connect to the ceph rdw",
    "start": "485440",
    "end": "487840"
  },
  {
    "text": "daemon",
    "start": "487840",
    "end": "488720"
  },
  {
    "text": "to read and write that object storage",
    "start": "488720",
    "end": "490960"
  },
  {
    "text": "right to the buckets",
    "start": "490960",
    "end": "492960"
  },
  {
    "text": "so you'll see that in this diagram when",
    "start": "492960",
    "end": "494720"
  },
  {
    "text": "your applications are reading and",
    "start": "494720",
    "end": "496240"
  },
  {
    "text": "writing data",
    "start": "496240",
    "end": "497680"
  },
  {
    "text": "rook is not directly in this path rook",
    "start": "497680",
    "end": "500319"
  },
  {
    "text": "is only",
    "start": "500319",
    "end": "501520"
  },
  {
    "text": "in the management layer when you set up",
    "start": "501520",
    "end": "504400"
  },
  {
    "text": "or provision the storage",
    "start": "504400",
    "end": "506800"
  },
  {
    "text": "let's get into some of the key features",
    "start": "506800",
    "end": "508720"
  },
  {
    "text": "that rook has always had or had for a",
    "start": "508720",
    "end": "511039"
  },
  {
    "text": "long time from the start",
    "start": "511039",
    "end": "512640"
  },
  {
    "text": "so first of all",
    "start": "512640",
    "end": "514399"
  },
  {
    "text": "seth",
    "start": "514399",
    "end": "515839"
  },
  {
    "text": "deploying seth is simple with we've",
    "start": "515839",
    "end": "517760"
  },
  {
    "text": "tried to make it as easy as we can that",
    "start": "517760",
    "end": "519518"
  },
  {
    "text": "was one of the goals of the brook",
    "start": "519519",
    "end": "520880"
  },
  {
    "text": "project from the start",
    "start": "520880",
    "end": "522880"
  },
  {
    "text": "we provide several manifests for",
    "start": "522880",
    "end": "525440"
  },
  {
    "text": "installing",
    "start": "525440",
    "end": "526880"
  },
  {
    "text": "seth in a default configuration",
    "start": "526880",
    "end": "529200"
  },
  {
    "text": "and you can change those settings for",
    "start": "529200",
    "end": "530880"
  },
  {
    "text": "more complex configurations",
    "start": "530880",
    "end": "533200"
  },
  {
    "text": "but at the end of the day",
    "start": "533200",
    "end": "535200"
  },
  {
    "text": "we've made ceph simple to install",
    "start": "535200",
    "end": "538240"
  },
  {
    "text": "here we show several cube cuddle",
    "start": "538240",
    "end": "540080"
  },
  {
    "text": "commands of what you need to create if",
    "start": "540080",
    "end": "541920"
  },
  {
    "text": "you're creating these manifests directly",
    "start": "541920",
    "end": "544080"
  },
  {
    "text": "and we also have",
    "start": "544080",
    "end": "545680"
  },
  {
    "text": "two helm charts that will help you",
    "start": "545680",
    "end": "547200"
  },
  {
    "text": "install the operator",
    "start": "547200",
    "end": "548800"
  },
  {
    "text": "and create the ceph cluster as well",
    "start": "548800",
    "end": "552399"
  },
  {
    "text": "we have a csi driver the csi driver as",
    "start": "552399",
    "end": "555600"
  },
  {
    "text": "has already been mentioned it",
    "start": "555600",
    "end": "557040"
  },
  {
    "text": "dynamically provisions the file in block",
    "start": "557040",
    "end": "558880"
  },
  {
    "text": "storage",
    "start": "558880",
    "end": "559920"
  },
  {
    "text": "it allows you to expand volumes",
    "start": "559920",
    "end": "562399"
  },
  {
    "text": "it will",
    "start": "562399",
    "end": "563519"
  },
  {
    "text": "it also implements snapshots and cloning",
    "start": "563519",
    "end": "566720"
  },
  {
    "text": "so you can have some of the backup",
    "start": "566720",
    "end": "568880"
  },
  {
    "text": "functionality",
    "start": "568880",
    "end": "570240"
  },
  {
    "text": "all right so what environments can you",
    "start": "570240",
    "end": "571920"
  },
  {
    "text": "run rook in the rook primarily is run",
    "start": "571920",
    "end": "575920"
  },
  {
    "text": "in production environments in",
    "start": "575920",
    "end": "577600"
  },
  {
    "text": "two types you have bare metal",
    "start": "577600",
    "end": "579440"
  },
  {
    "text": "environments where you have your own",
    "start": "579440",
    "end": "581760"
  },
  {
    "text": "hardware your or your own virtual",
    "start": "581760",
    "end": "584320"
  },
  {
    "text": "environments and you get to install",
    "start": "584320",
    "end": "587279"
  },
  {
    "text": "rook this is the this is the main",
    "start": "587279",
    "end": "589360"
  },
  {
    "text": "scenario where we expected rook to be",
    "start": "589360",
    "end": "591279"
  },
  {
    "text": "used where there is no cloud provider",
    "start": "591279",
    "end": "594000"
  },
  {
    "text": "storage",
    "start": "594000",
    "end": "595040"
  },
  {
    "text": "that you can",
    "start": "595040",
    "end": "596560"
  },
  {
    "text": "back your storage with",
    "start": "596560",
    "end": "598640"
  },
  {
    "text": "and back your applications with",
    "start": "598640",
    "end": "600720"
  },
  {
    "text": "um so the second environment though",
    "start": "600720",
    "end": "603040"
  },
  {
    "text": "that is commonly run is in cloud",
    "start": "603040",
    "end": "604800"
  },
  {
    "text": "providers where even though cloud",
    "start": "604800",
    "end": "607120"
  },
  {
    "text": "providers",
    "start": "607120",
    "end": "608560"
  },
  {
    "text": "have storage that you can build on",
    "start": "608560",
    "end": "611920"
  },
  {
    "text": "rook",
    "start": "611920",
    "end": "612720"
  },
  {
    "text": "has several benefits with ceph",
    "start": "612720",
    "end": "615600"
  },
  {
    "text": "that overcome some limitations that",
    "start": "615600",
    "end": "617360"
  },
  {
    "text": "cloud providers have",
    "start": "617360",
    "end": "619200"
  },
  {
    "text": "so in that cloud environment what rook",
    "start": "619200",
    "end": "621360"
  },
  {
    "text": "does is it allows you to have storage",
    "start": "621360",
    "end": "623680"
  },
  {
    "text": "that spans availability zones",
    "start": "623680",
    "end": "626079"
  },
  {
    "text": "you can have faster failover times where",
    "start": "626079",
    "end": "628079"
  },
  {
    "text": "it's seconds instead of minutes for your",
    "start": "628079",
    "end": "630160"
  },
  {
    "text": "pods to",
    "start": "630160",
    "end": "631760"
  },
  {
    "text": "to fail over",
    "start": "631760",
    "end": "633760"
  },
  {
    "text": "you can have a greater number of pvs per",
    "start": "633760",
    "end": "635360"
  },
  {
    "text": "node as many as 30. you can use storage",
    "start": "635360",
    "end": "638240"
  },
  {
    "text": "with better performance to cost ratio",
    "start": "638240",
    "end": "642160"
  },
  {
    "text": "and also",
    "start": "642160",
    "end": "643920"
  },
  {
    "text": "rook really gives you a consistent",
    "start": "643920",
    "end": "645279"
  },
  {
    "text": "platform no matter where you're",
    "start": "645279",
    "end": "647200"
  },
  {
    "text": "installing whether you're deploying an",
    "start": "647200",
    "end": "648800"
  },
  {
    "text": "aws or azure or google cloud or or any",
    "start": "648800",
    "end": "652560"
  },
  {
    "text": "environment",
    "start": "652560",
    "end": "654160"
  },
  {
    "text": "this is it's a consistent storage",
    "start": "654160",
    "end": "656079"
  },
  {
    "text": "platform everywhere",
    "start": "656079",
    "end": "659040"
  },
  {
    "text": "when you're running in these cloud",
    "start": "659120",
    "end": "660320"
  },
  {
    "text": "environments seth will use pvcs as the",
    "start": "660320",
    "end": "663600"
  },
  {
    "text": "underlying storage so you can connect",
    "start": "663600",
    "end": "666640"
  },
  {
    "text": "seth",
    "start": "666640",
    "end": "667680"
  },
  {
    "text": "to the underlying storage platform in a",
    "start": "667680",
    "end": "670480"
  },
  {
    "text": "consistent way with your other",
    "start": "670480",
    "end": "672079"
  },
  {
    "text": "kubernetes applications as well no",
    "start": "672079",
    "end": "674240"
  },
  {
    "text": "there's no need for direct access to",
    "start": "674240",
    "end": "675680"
  },
  {
    "text": "local devices when you're running in the",
    "start": "675680",
    "end": "677440"
  },
  {
    "text": "cloud or mount them in advance it's all",
    "start": "677440",
    "end": "680480"
  },
  {
    "text": "dynamically provisioned",
    "start": "680480",
    "end": "682560"
  },
  {
    "text": "another aspect of rook is",
    "start": "682560",
    "end": "684560"
  },
  {
    "text": "you can configure it for any cluster",
    "start": "684560",
    "end": "686079"
  },
  {
    "text": "topology whether you have just a flat",
    "start": "686079",
    "end": "689279"
  },
  {
    "text": "level of nodes",
    "start": "689279",
    "end": "692240"
  },
  {
    "text": "staff will divide",
    "start": "692240",
    "end": "693920"
  },
  {
    "text": "the storage across the nodes",
    "start": "693920",
    "end": "696800"
  },
  {
    "text": "in an available way to keep the data",
    "start": "696800",
    "end": "698880"
  },
  {
    "text": "highly available and durable",
    "start": "698880",
    "end": "702240"
  },
  {
    "text": "or if you have multiple racks or zones",
    "start": "702240",
    "end": "705680"
  },
  {
    "text": "or any other complex topology",
    "start": "705680",
    "end": "708000"
  },
  {
    "text": "seth and rook will work well in those",
    "start": "708000",
    "end": "709920"
  },
  {
    "text": "environments to spread your data",
    "start": "709920",
    "end": "712720"
  },
  {
    "text": "across the appropriate",
    "start": "712720",
    "end": "715519"
  },
  {
    "text": "data zones",
    "start": "715519",
    "end": "717120"
  },
  {
    "text": "so that you can",
    "start": "717120",
    "end": "718880"
  },
  {
    "text": "rely on your data being spread across",
    "start": "718880",
    "end": "721360"
  },
  {
    "text": "failure domains",
    "start": "721360",
    "end": "723279"
  },
  {
    "text": "right now when it's time to update rook",
    "start": "723279",
    "end": "725120"
  },
  {
    "text": "or ceph",
    "start": "725120",
    "end": "726399"
  },
  {
    "text": "there's a way where rook handles",
    "start": "726399",
    "end": "728079"
  },
  {
    "text": "everything you tell rook what version",
    "start": "728079",
    "end": "729920"
  },
  {
    "text": "you want to run and rook will upgrade",
    "start": "729920",
    "end": "732480"
  },
  {
    "text": "all of the rook the airbrush operator",
    "start": "732480",
    "end": "735120"
  },
  {
    "text": "and the rook demons rick will also",
    "start": "735120",
    "end": "737279"
  },
  {
    "text": "update the ceph demons all of the mons",
    "start": "737279",
    "end": "740079"
  },
  {
    "text": "and osd's",
    "start": "740079",
    "end": "741519"
  },
  {
    "text": "in a rolling fashion so that your",
    "start": "741519",
    "end": "744399"
  },
  {
    "text": "storage will remain active and available",
    "start": "744399",
    "end": "747680"
  },
  {
    "text": "and online during the upgrades as well",
    "start": "747680",
    "end": "751120"
  },
  {
    "text": "another feature rick has is let's say",
    "start": "751120",
    "end": "753440"
  },
  {
    "text": "you already have",
    "start": "753440",
    "end": "754720"
  },
  {
    "text": "a ceph cluster running outside of",
    "start": "754720",
    "end": "756240"
  },
  {
    "text": "kubernetes so using the csi driver and",
    "start": "756240",
    "end": "759279"
  },
  {
    "text": "the brook operator",
    "start": "759279",
    "end": "760959"
  },
  {
    "text": "rook makes it simple to connect your csi",
    "start": "760959",
    "end": "763440"
  },
  {
    "text": "driver",
    "start": "763440",
    "end": "764399"
  },
  {
    "text": "to that external ceph cluster",
    "start": "764399",
    "end": "767600"
  },
  {
    "text": "no need to run sap cluster inside",
    "start": "767600",
    "end": "770000"
  },
  {
    "text": "kubernetes if you",
    "start": "770000",
    "end": "771600"
  },
  {
    "text": "if you want to run",
    "start": "771600",
    "end": "773360"
  },
  {
    "text": "and connect to your existing set cluster",
    "start": "773360",
    "end": "776560"
  },
  {
    "text": "now if you want to",
    "start": "776560",
    "end": "778079"
  },
  {
    "text": "have access to",
    "start": "778079",
    "end": "779839"
  },
  {
    "text": "object storage with an s3 endpoint",
    "start": "779839",
    "end": "783279"
  },
  {
    "text": "you can provision object buckets so this",
    "start": "783279",
    "end": "785120"
  },
  {
    "text": "is done with an object bucket claim this",
    "start": "785120",
    "end": "787680"
  },
  {
    "text": "is a very similar pattern to using a pvc",
    "start": "787680",
    "end": "790480"
  },
  {
    "text": "where",
    "start": "790480",
    "end": "791279"
  },
  {
    "text": "rick will create a bucket when requested",
    "start": "791279",
    "end": "793839"
  },
  {
    "text": "give that",
    "start": "793839",
    "end": "795120"
  },
  {
    "text": "application access to the bucket with a",
    "start": "795120",
    "end": "797360"
  },
  {
    "text": "secret",
    "start": "797360",
    "end": "798639"
  },
  {
    "text": "and then",
    "start": "798639",
    "end": "800480"
  },
  {
    "text": "you can have your provision your buckets",
    "start": "800480",
    "end": "802399"
  },
  {
    "text": "dynamically",
    "start": "802399",
    "end": "803519"
  },
  {
    "text": "this is very similar to the new",
    "start": "803519",
    "end": "806079"
  },
  {
    "text": "container object storage interface or",
    "start": "806079",
    "end": "807920"
  },
  {
    "text": "kazi",
    "start": "807920",
    "end": "809360"
  },
  {
    "text": "which is coming soon and we will be",
    "start": "809360",
    "end": "811279"
  },
  {
    "text": "implementing that in rook as well when",
    "start": "811279",
    "end": "813279"
  },
  {
    "text": "qazi is available",
    "start": "813279",
    "end": "815440"
  },
  {
    "text": "so let's talk about some rook 1.8",
    "start": "815440",
    "end": "817680"
  },
  {
    "text": "features",
    "start": "817680",
    "end": "818800"
  },
  {
    "text": "that are in their latest release what",
    "start": "818800",
    "end": "820639"
  },
  {
    "text": "rook 1.8 is was just released as of",
    "start": "820639",
    "end": "824399"
  },
  {
    "text": "kubecon we're expecting to have it out",
    "start": "824399",
    "end": "826320"
  },
  {
    "text": "this just a few days before kubecon",
    "start": "826320",
    "end": "828720"
  },
  {
    "text": "china",
    "start": "828720",
    "end": "830880"
  },
  {
    "text": "so some of the features we have there",
    "start": "830880",
    "end": "832240"
  },
  {
    "text": "first object bucket notifications",
    "start": "832240",
    "end": "834800"
  },
  {
    "text": "notifications can be sent to",
    "start": "834800",
    "end": "838160"
  },
  {
    "text": "a configurable endpoint where the",
    "start": "838160",
    "end": "840240"
  },
  {
    "text": "notifications can be based on a put or a",
    "start": "840240",
    "end": "842480"
  },
  {
    "text": "get or a copy or a delete of different",
    "start": "842480",
    "end": "845600"
  },
  {
    "text": "actions to the s3 store",
    "start": "845600",
    "end": "848079"
  },
  {
    "text": "you can specify filters for those",
    "start": "848079",
    "end": "850480"
  },
  {
    "text": "notifications whether it's object names",
    "start": "850480",
    "end": "852720"
  },
  {
    "text": "suffixes",
    "start": "852720",
    "end": "854399"
  },
  {
    "text": "or regular expressions or you can filter",
    "start": "854399",
    "end": "856560"
  },
  {
    "text": "on the metadata of those objects",
    "start": "856560",
    "end": "859600"
  },
  {
    "text": "and you can send it to an endpoint such",
    "start": "859600",
    "end": "861600"
  },
  {
    "text": "as http kafka or amqp",
    "start": "861600",
    "end": "865279"
  },
  {
    "text": "another feature",
    "start": "865279",
    "end": "866480"
  },
  {
    "text": "disaster recovery for applications the",
    "start": "866480",
    "end": "869040"
  },
  {
    "text": "dr is very important where applications",
    "start": "869040",
    "end": "872160"
  },
  {
    "text": "need to",
    "start": "872160",
    "end": "873360"
  },
  {
    "text": "span across",
    "start": "873360",
    "end": "875040"
  },
  {
    "text": "clusters across kubernetes clusters",
    "start": "875040",
    "end": "877199"
  },
  {
    "text": "let's say you have a whole site go down",
    "start": "877199",
    "end": "878959"
  },
  {
    "text": "your application needs to continue",
    "start": "878959",
    "end": "880880"
  },
  {
    "text": "running in the other site",
    "start": "880880",
    "end": "883440"
  },
  {
    "text": "so the csi driver supports mirroring the",
    "start": "883440",
    "end": "886639"
  },
  {
    "text": "data with ceph across the clusters",
    "start": "886639",
    "end": "889600"
  },
  {
    "text": "and we provide tools and documentation",
    "start": "889600",
    "end": "891760"
  },
  {
    "text": "to support your applications in that",
    "start": "891760",
    "end": "893600"
  },
  {
    "text": "failover",
    "start": "893600",
    "end": "895120"
  },
  {
    "text": "a couple of network enhancements in the",
    "start": "895120",
    "end": "897199"
  },
  {
    "text": "latest release so encrypted connections",
    "start": "897199",
    "end": "899519"
  },
  {
    "text": "across the wire",
    "start": "899519",
    "end": "901199"
  },
  {
    "text": "where",
    "start": "901199",
    "end": "902240"
  },
  {
    "text": "you know any data that's transferred",
    "start": "902240",
    "end": "904160"
  },
  {
    "text": "across the wire will be encrypted with",
    "start": "904160",
    "end": "906160"
  },
  {
    "text": "seps",
    "start": "906160",
    "end": "907440"
  },
  {
    "text": "suffix",
    "start": "907440",
    "end": "908880"
  },
  {
    "text": "encryption at rest was already has",
    "start": "908880",
    "end": "910560"
  },
  {
    "text": "already been available for a number of",
    "start": "910560",
    "end": "912160"
  },
  {
    "text": "releases",
    "start": "912160",
    "end": "914639"
  },
  {
    "text": "you can also compress the data across",
    "start": "914639",
    "end": "916720"
  },
  {
    "text": "the network",
    "start": "916720",
    "end": "918480"
  },
  {
    "text": "to reduce that",
    "start": "918480",
    "end": "921199"
  },
  {
    "text": "that throughput that's required across",
    "start": "921199",
    "end": "923040"
  },
  {
    "text": "across the wire if you have compressible",
    "start": "923040",
    "end": "924959"
  },
  {
    "text": "data this does require an experimental",
    "start": "924959",
    "end": "928560"
  },
  {
    "text": "version of ceph seth quincy which will",
    "start": "928560",
    "end": "931519"
  },
  {
    "text": "be coming out in early",
    "start": "931519",
    "end": "933920"
  },
  {
    "text": "2022.",
    "start": "933920",
    "end": "935759"
  },
  {
    "text": "multis networking the multis is a",
    "start": "935759",
    "end": "938320"
  },
  {
    "text": "network plug-in that provides more",
    "start": "938320",
    "end": "940399"
  },
  {
    "text": "flexibility for",
    "start": "940399",
    "end": "942160"
  },
  {
    "text": "different connections",
    "start": "942160",
    "end": "943920"
  },
  {
    "text": "so work will fully support multis and",
    "start": "943920",
    "end": "946480"
  },
  {
    "text": "1.8",
    "start": "946480",
    "end": "947680"
  },
  {
    "text": "the csi driver primarily needed an",
    "start": "947680",
    "end": "950160"
  },
  {
    "text": "update to require that",
    "start": "950160",
    "end": "952839"
  },
  {
    "text": "multi-support little tool that we've",
    "start": "952839",
    "end": "955440"
  },
  {
    "text": "released is the crew a group plugin so",
    "start": "955440",
    "end": "958320"
  },
  {
    "text": "perhaps you've seen other crew plug-ins",
    "start": "958320",
    "end": "960399"
  },
  {
    "text": "really it's for making tube cuddle",
    "start": "960399",
    "end": "962880"
  },
  {
    "text": "commands",
    "start": "962880",
    "end": "964079"
  },
  {
    "text": "extend extendable",
    "start": "964079",
    "end": "966320"
  },
  {
    "text": "so for example you can say cube cuddle",
    "start": "966320",
    "end": "969519"
  },
  {
    "text": "rook stuff",
    "start": "969519",
    "end": "970880"
  },
  {
    "text": "sap status and you'll see the stuff",
    "start": "970880",
    "end": "973360"
  },
  {
    "text": "status as if you're running in the rook",
    "start": "973360",
    "end": "975120"
  },
  {
    "text": "toolbox",
    "start": "975120",
    "end": "976320"
  },
  {
    "text": "but it's it's much simpler and shorter",
    "start": "976320",
    "end": "978320"
  },
  {
    "text": "to type out",
    "start": "978320",
    "end": "979680"
  },
  {
    "text": "that's just a convenience tool but we",
    "start": "979680",
    "end": "981680"
  },
  {
    "text": "are really excited about it",
    "start": "981680",
    "end": "983920"
  },
  {
    "text": "in 1.8",
    "start": "983920",
    "end": "985279"
  },
  {
    "text": "a few important notes if you're already",
    "start": "985279",
    "end": "987040"
  },
  {
    "text": "a rook user and and are considering",
    "start": "987040",
    "end": "989440"
  },
  {
    "text": "upgrading to 1.8",
    "start": "989440",
    "end": "991440"
  },
  {
    "text": "we do require kubernetes 1.16 or newer",
    "start": "991440",
    "end": "994880"
  },
  {
    "text": "older versions are not supported due to",
    "start": "994880",
    "end": "997199"
  },
  {
    "text": "old crd versions",
    "start": "997199",
    "end": "1000000"
  },
  {
    "text": "the ceph versions supported are octopus",
    "start": "1000000",
    "end": "1002240"
  },
  {
    "text": "and pacific with quincy as experimental",
    "start": "1002240",
    "end": "1004880"
  },
  {
    "text": "coming out early next year",
    "start": "1004880",
    "end": "1007680"
  },
  {
    "text": "but the support for ceph nautilus was",
    "start": "1007680",
    "end": "1010399"
  },
  {
    "text": "removed",
    "start": "1010399",
    "end": "1012399"
  },
  {
    "text": "and finally if you've been using work",
    "start": "1012399",
    "end": "1014480"
  },
  {
    "text": "for a really long time before the csi",
    "start": "1014480",
    "end": "1016639"
  },
  {
    "text": "driver",
    "start": "1016639",
    "end": "1017600"
  },
  {
    "text": "the flex driver support is was removed",
    "start": "1017600",
    "end": "1020320"
  },
  {
    "text": "in 1.8",
    "start": "1020320",
    "end": "1022079"
  },
  {
    "text": "and we'll we have a tool that will help",
    "start": "1022079",
    "end": "1023759"
  },
  {
    "text": "you convert your volumes to csi",
    "start": "1023759",
    "end": "1027760"
  },
  {
    "text": "and now we turn the time over to zotero",
    "start": "1027760",
    "end": "1030000"
  },
  {
    "text": "for a demo",
    "start": "1030000",
    "end": "1032558"
  },
  {
    "text": "i have a demo to create a simple look",
    "start": "1032640",
    "end": "1036000"
  },
  {
    "text": "safe cluster",
    "start": "1036000",
    "end": "1038959"
  },
  {
    "text": "i will use js2 softwares",
    "start": "1038959",
    "end": "1043839"
  },
  {
    "text": "there are two types of ruxic clusters",
    "start": "1044160",
    "end": "1047520"
  },
  {
    "text": "the first one is host-based cluster",
    "start": "1047520",
    "end": "1051120"
  },
  {
    "text": "and the second one is ppg based cluster",
    "start": "1051120",
    "end": "1056400"
  },
  {
    "text": "host-based cluster is suitable for",
    "start": "1056720",
    "end": "1059360"
  },
  {
    "text": "simple cluster",
    "start": "1059360",
    "end": "1061120"
  },
  {
    "text": "especially if",
    "start": "1061120",
    "end": "1062720"
  },
  {
    "text": "you use or all nodes and all devices for",
    "start": "1062720",
    "end": "1066799"
  },
  {
    "text": "rook sequencer",
    "start": "1066799",
    "end": "1069760"
  },
  {
    "text": "but sequester cluster results get",
    "start": "1069760",
    "end": "1072320"
  },
  {
    "text": "complicated if",
    "start": "1072320",
    "end": "1074640"
  },
  {
    "text": "not all nodes and devices are used",
    "start": "1074640",
    "end": "1079520"
  },
  {
    "text": "at first you should",
    "start": "1079520",
    "end": "1081679"
  },
  {
    "text": "list all nodes and all devices for",
    "start": "1081679",
    "end": "1085440"
  },
  {
    "text": "classes",
    "start": "1085440",
    "end": "1087120"
  },
  {
    "text": "used for clusters",
    "start": "1087120",
    "end": "1090320"
  },
  {
    "text": "as for pvc-based cluster you are free",
    "start": "1090320",
    "end": "1093679"
  },
  {
    "text": "from describing hardware configurations",
    "start": "1093679",
    "end": "1096960"
  },
  {
    "text": "like this",
    "start": "1096960",
    "end": "1098400"
  },
  {
    "text": "and then you should",
    "start": "1098400",
    "end": "1101280"
  },
  {
    "text": "you should specify only to field",
    "start": "1101280",
    "end": "1104080"
  },
  {
    "text": "the count field and the volume claim",
    "start": "1104080",
    "end": "1106320"
  },
  {
    "text": "templates feed",
    "start": "1106320",
    "end": "1108480"
  },
  {
    "text": "count field means number of ost and",
    "start": "1108480",
    "end": "1112559"
  },
  {
    "text": "volume claim templates field",
    "start": "1112559",
    "end": "1115039"
  },
  {
    "text": "is used for template or pvc",
    "start": "1115039",
    "end": "1118799"
  },
  {
    "text": "used for osds",
    "start": "1118799",
    "end": "1122400"
  },
  {
    "text": "pbc-based cluster is very easy to expand",
    "start": "1122400",
    "end": "1126720"
  },
  {
    "text": "you just need to increase the count",
    "start": "1126720",
    "end": "1129120"
  },
  {
    "text": "field",
    "start": "1129120",
    "end": "1130559"
  },
  {
    "text": "if you increase this field from 1 to 2",
    "start": "1130559",
    "end": "1134799"
  },
  {
    "text": "the number of ost is also increased to",
    "start": "1134799",
    "end": "1138720"
  },
  {
    "text": "2.",
    "start": "1138720",
    "end": "1141039"
  },
  {
    "text": "so let's create a",
    "start": "1142400",
    "end": "1144559"
  },
  {
    "text": "simple pvc based cluster",
    "start": "1144559",
    "end": "1148080"
  },
  {
    "text": "i",
    "start": "1148080",
    "end": "1148840"
  },
  {
    "text": "used uh one kubernetes cluster",
    "start": "1148840",
    "end": "1152720"
  },
  {
    "text": "consists of",
    "start": "1152720",
    "end": "1154160"
  },
  {
    "text": "one node",
    "start": "1154160",
    "end": "1155919"
  },
  {
    "text": "this node has",
    "start": "1155919",
    "end": "1157919"
  },
  {
    "text": "two local empty block devices",
    "start": "1157919",
    "end": "1160960"
  },
  {
    "text": "and the corresponding past and boring",
    "start": "1160960",
    "end": "1166159"
  },
  {
    "text": "this demo",
    "start": "1166400",
    "end": "1167679"
  },
  {
    "text": "consists of three steps",
    "start": "1167679",
    "end": "1170240"
  },
  {
    "text": "and you can get the all script and all",
    "start": "1170240",
    "end": "1174240"
  },
  {
    "text": "manifest from",
    "start": "1174240",
    "end": "1176400"
  },
  {
    "text": "this project",
    "start": "1176400",
    "end": "1179840"
  },
  {
    "text": "so let's create a rook safeguard",
    "start": "1181360",
    "end": "1184240"
  },
  {
    "text": "look operator as a step one",
    "start": "1184240",
    "end": "1188400"
  },
  {
    "text": "so copy ctrl",
    "start": "1189280",
    "end": "1191440"
  },
  {
    "text": "hardware and",
    "start": "1191440",
    "end": "1193280"
  },
  {
    "text": "operate the dmo",
    "start": "1193280",
    "end": "1196080"
  },
  {
    "text": "so the",
    "start": "1196080",
    "end": "1197200"
  },
  {
    "text": "operator is created",
    "start": "1197200",
    "end": "1199440"
  },
  {
    "text": "operator is created and",
    "start": "1199440",
    "end": "1202640"
  },
  {
    "text": "our rook safeglass",
    "start": "1202640",
    "end": "1204400"
  },
  {
    "text": "rook safe name space",
    "start": "1204400",
    "end": "1206320"
  },
  {
    "text": "get bot",
    "start": "1206320",
    "end": "1208320"
  },
  {
    "text": "okay the rooks operator cross operator",
    "start": "1208320",
    "end": "1211919"
  },
  {
    "text": "port is already already running",
    "start": "1211919",
    "end": "1216559"
  },
  {
    "text": "so this second step is create a",
    "start": "1216799",
    "end": "1220480"
  },
  {
    "text": "rook safe cluster",
    "start": "1220480",
    "end": "1223280"
  },
  {
    "text": "the manifest is",
    "start": "1223280",
    "end": "1225280"
  },
  {
    "text": "on in the cluster on pbc.yamo",
    "start": "1225280",
    "end": "1230679"
  },
  {
    "text": "yes it's a",
    "start": "1231039",
    "end": "1233679"
  },
  {
    "text": "cluster custom resource and it means",
    "start": "1233679",
    "end": "1237679"
  },
  {
    "text": "number monitor port is one",
    "start": "1237679",
    "end": "1240640"
  },
  {
    "text": "and the number of ost is also one",
    "start": "1240640",
    "end": "1245120"
  },
  {
    "text": "so",
    "start": "1245120",
    "end": "1246159"
  },
  {
    "text": "let's apply this manifest",
    "start": "1246159",
    "end": "1250400"
  },
  {
    "text": "right here",
    "start": "1251600",
    "end": "1254400"
  },
  {
    "text": "there",
    "start": "1255200",
    "end": "1257280"
  },
  {
    "text": "no no",
    "start": "1257280",
    "end": "1259679"
  },
  {
    "text": "okay",
    "start": "1260080",
    "end": "1261120"
  },
  {
    "text": "so let's see the progress of creating",
    "start": "1261120",
    "end": "1265039"
  },
  {
    "text": "this",
    "start": "1265039",
    "end": "1267039"
  },
  {
    "text": "creating root safe cluster get code",
    "start": "1267039",
    "end": "1272080"
  },
  {
    "text": "so rook safe operator is already exist",
    "start": "1272559",
    "end": "1276320"
  },
  {
    "text": "and the g supports",
    "start": "1276320",
    "end": "1279280"
  },
  {
    "text": "this port for",
    "start": "1279280",
    "end": "1282159"
  },
  {
    "text": "safe gsi drivers",
    "start": "1282159",
    "end": "1285520"
  },
  {
    "text": "and now safe monitor port is learning",
    "start": "1285520",
    "end": "1289520"
  },
  {
    "text": "and the second and the next step is",
    "start": "1289520",
    "end": "1293200"
  },
  {
    "text": "create a manager port",
    "start": "1293200",
    "end": "1296000"
  },
  {
    "text": "and the third step is looks creating",
    "start": "1296000",
    "end": "1298880"
  },
  {
    "text": "root safe opera uh looks ost look safe",
    "start": "1298880",
    "end": "1302640"
  },
  {
    "text": "osd prepare port",
    "start": "1302640",
    "end": "1305440"
  },
  {
    "text": "it's to initialize",
    "start": "1305440",
    "end": "1308159"
  },
  {
    "text": "initialize",
    "start": "1308159",
    "end": "1309679"
  },
  {
    "text": "data structure on top of",
    "start": "1309679",
    "end": "1312640"
  },
  {
    "text": "our",
    "start": "1312640",
    "end": "1313520"
  },
  {
    "text": "local block device",
    "start": "1313520",
    "end": "1316159"
  },
  {
    "text": "and the last",
    "start": "1316159",
    "end": "1317600"
  },
  {
    "text": "rook safe osd port is created",
    "start": "1317600",
    "end": "1320799"
  },
  {
    "text": "it's to manage ost ports",
    "start": "1320799",
    "end": "1324960"
  },
  {
    "text": "so",
    "start": "1325840",
    "end": "1328080"
  },
  {
    "text": "get pvc",
    "start": "1329440",
    "end": "1331120"
  },
  {
    "text": "okay so this uh",
    "start": "1331120",
    "end": "1334000"
  },
  {
    "text": "this part um past and volume claim is",
    "start": "1334000",
    "end": "1336799"
  },
  {
    "text": "created by rook",
    "start": "1336799",
    "end": "1339360"
  },
  {
    "text": "and it's bound to local rusd to",
    "start": "1339360",
    "end": "1343600"
  },
  {
    "text": "to past and boring it's",
    "start": "1343600",
    "end": "1347760"
  },
  {
    "text": "it's corresponding to",
    "start": "1347760",
    "end": "1350640"
  },
  {
    "text": "uh one loops",
    "start": "1350640",
    "end": "1352559"
  },
  {
    "text": "on local osd",
    "start": "1352559",
    "end": "1354960"
  },
  {
    "text": "and this bbc is consumed by",
    "start": "1354960",
    "end": "1358960"
  },
  {
    "text": "this oyster pot",
    "start": "1358960",
    "end": "1362240"
  },
  {
    "text": "so let's confirm the",
    "start": "1362320",
    "end": "1366000"
  },
  {
    "text": "status of",
    "start": "1366000",
    "end": "1367760"
  },
  {
    "text": "on safe cluster",
    "start": "1367760",
    "end": "1371280"
  },
  {
    "text": "tools apply",
    "start": "1372840",
    "end": "1375679"
  },
  {
    "text": "another toolbox bolt",
    "start": "1375679",
    "end": "1378400"
  },
  {
    "text": "okay",
    "start": "1378400",
    "end": "1380559"
  },
  {
    "text": "on the road",
    "start": "1380559",
    "end": "1382559"
  },
  {
    "text": "save",
    "start": "1382559",
    "end": "1384640"
  },
  {
    "text": "exact",
    "start": "1384640",
    "end": "1385919"
  },
  {
    "text": "setups",
    "start": "1385919",
    "end": "1388919"
  },
  {
    "text": "so say hi whom s command is",
    "start": "1389280",
    "end": "1392400"
  },
  {
    "text": "to",
    "start": "1392400",
    "end": "1393840"
  },
  {
    "text": "uh",
    "start": "1393840",
    "end": "1394640"
  },
  {
    "text": "to see the status of our",
    "start": "1394640",
    "end": "1398559"
  },
  {
    "text": "safe cluster",
    "start": "1398559",
    "end": "1401440"
  },
  {
    "text": "okay the safe cluster is actually",
    "start": "1401679",
    "end": "1404640"
  },
  {
    "text": "created and the",
    "start": "1404640",
    "end": "1406960"
  },
  {
    "text": "monitor number monitor is one",
    "start": "1406960",
    "end": "1409760"
  },
  {
    "text": "the number of manager is one and",
    "start": "1409760",
    "end": "1413440"
  },
  {
    "text": "zero there is one waste",
    "start": "1413440",
    "end": "1416720"
  },
  {
    "text": "okay",
    "start": "1416720",
    "end": "1419039"
  },
  {
    "text": "so the third and the last step is expand",
    "start": "1419440",
    "end": "1423360"
  },
  {
    "text": "this cluster",
    "start": "1423360",
    "end": "1425679"
  },
  {
    "text": "so it's very easy as said",
    "start": "1425679",
    "end": "1428880"
  },
  {
    "text": "before through",
    "start": "1428880",
    "end": "1432400"
  },
  {
    "text": "so it's by editing",
    "start": "1433120",
    "end": "1437039"
  },
  {
    "text": "self cluster grocery source",
    "start": "1439120",
    "end": "1443360"
  },
  {
    "text": "[Music]",
    "start": "1446290",
    "end": "1448159"
  },
  {
    "text": "okay so it means number of ost",
    "start": "1448159",
    "end": "1451840"
  },
  {
    "text": "so let's increase this to two",
    "start": "1451840",
    "end": "1456000"
  },
  {
    "text": "and",
    "start": "1456000",
    "end": "1456960"
  },
  {
    "text": "let's confirm",
    "start": "1456960",
    "end": "1460240"
  },
  {
    "text": "self get port",
    "start": "1461120",
    "end": "1463919"
  },
  {
    "text": "okay",
    "start": "1463919",
    "end": "1465520"
  },
  {
    "text": "so the next the second um looks a",
    "start": "1465520",
    "end": "1469840"
  },
  {
    "text": "prepair port will be created soon",
    "start": "1469840",
    "end": "1474480"
  },
  {
    "text": "so wait for a while",
    "start": "1475200",
    "end": "1478799"
  },
  {
    "text": "okay the ost prepare port is created",
    "start": "1480720",
    "end": "1485039"
  },
  {
    "text": "and it's running",
    "start": "1485039",
    "end": "1486960"
  },
  {
    "text": "uh",
    "start": "1486960",
    "end": "1488080"
  },
  {
    "text": "now creating the second osd data",
    "start": "1488080",
    "end": "1491279"
  },
  {
    "text": "structure",
    "start": "1491279",
    "end": "1492720"
  },
  {
    "text": "and now osd port is created",
    "start": "1492720",
    "end": "1496000"
  },
  {
    "text": "and running",
    "start": "1496000",
    "end": "1498080"
  },
  {
    "text": "okay so let's confirm to",
    "start": "1498080",
    "end": "1501279"
  },
  {
    "text": "let's run the",
    "start": "1501279",
    "end": "1504240"
  },
  {
    "text": "safe iphone s again",
    "start": "1504240",
    "end": "1508400"
  },
  {
    "text": "okay the number of ost",
    "start": "1508720",
    "end": "1511360"
  },
  {
    "text": "uh",
    "start": "1511360",
    "end": "1512720"
  },
  {
    "text": "number of ost",
    "start": "1512720",
    "end": "1514799"
  },
  {
    "text": "is now two",
    "start": "1514799",
    "end": "1516720"
  },
  {
    "text": "okay so",
    "start": "1516720",
    "end": "1518240"
  },
  {
    "text": "it means uh",
    "start": "1518240",
    "end": "1520080"
  },
  {
    "text": "this cluster is expanded correctly",
    "start": "1520080",
    "end": "1524880"
  },
  {
    "text": "there are advanced configurations about",
    "start": "1526480",
    "end": "1529600"
  },
  {
    "text": "um bbg base cluster",
    "start": "1529600",
    "end": "1532640"
  },
  {
    "text": "the first one is create position volumes",
    "start": "1532640",
    "end": "1535679"
  },
  {
    "text": "or ost on demand",
    "start": "1535679",
    "end": "1538559"
  },
  {
    "text": "in this demo i prepared",
    "start": "1538559",
    "end": "1541360"
  },
  {
    "text": "the two",
    "start": "1541360",
    "end": "1544159"
  },
  {
    "text": "two",
    "start": "1544159",
    "end": "1545039"
  },
  {
    "text": "positive volume beforehand",
    "start": "1545039",
    "end": "1548000"
  },
  {
    "text": "but if you use csi drivers with dynamic",
    "start": "1548000",
    "end": "1552000"
  },
  {
    "text": "volume",
    "start": "1552000",
    "end": "1552960"
  },
  {
    "text": "provisioning",
    "start": "1552960",
    "end": "1554559"
  },
  {
    "text": "you can omit this step on this work",
    "start": "1554559",
    "end": "1558799"
  },
  {
    "text": "and the second",
    "start": "1558799",
    "end": "1560480"
  },
  {
    "text": "second configuration is even ost",
    "start": "1560480",
    "end": "1563120"
  },
  {
    "text": "splitting among all nodes",
    "start": "1563120",
    "end": "1566400"
  },
  {
    "text": "to use",
    "start": "1566400",
    "end": "1567919"
  },
  {
    "text": "this feature",
    "start": "1567919",
    "end": "1569279"
  },
  {
    "text": "you can use topology's topology spread",
    "start": "1569279",
    "end": "1572320"
  },
  {
    "text": "constraint feature in kubernetes",
    "start": "1572320",
    "end": "1576480"
  },
  {
    "text": "if you are interested in",
    "start": "1576480",
    "end": "1579200"
  },
  {
    "text": "these configurations please refer to",
    "start": "1579200",
    "end": "1582799"
  },
  {
    "text": "this blog post",
    "start": "1582799",
    "end": "1585200"
  },
  {
    "text": "all right thank you so teru for that",
    "start": "1585200",
    "end": "1586480"
  },
  {
    "text": "demo",
    "start": "1586480",
    "end": "1588240"
  },
  {
    "text": "and thank you for joining us today to",
    "start": "1588240",
    "end": "1589760"
  },
  {
    "text": "learn about rook",
    "start": "1589760",
    "end": "1591200"
  },
  {
    "text": "here's our here are a few links to our",
    "start": "1591200",
    "end": "1592720"
  },
  {
    "text": "website our documentation",
    "start": "1592720",
    "end": "1594799"
  },
  {
    "text": "come join our slack ask questions",
    "start": "1594799",
    "end": "1597360"
  },
  {
    "text": "we like to build the community",
    "start": "1597360",
    "end": "1599600"
  },
  {
    "text": "in an open way",
    "start": "1599600",
    "end": "1601440"
  },
  {
    "text": "we do take contributions we're excited",
    "start": "1601440",
    "end": "1603200"
  },
  {
    "text": "to",
    "start": "1603200",
    "end": "1603919"
  },
  {
    "text": "to have you join the community",
    "start": "1603919",
    "end": "1606880"
  },
  {
    "text": "now we'd like to take your questions",
    "start": "1606880",
    "end": "1610320"
  }
]
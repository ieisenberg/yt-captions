[
  {
    "text": "so ju just before we kick off the session uh just would like to Quick raise of hands how many of you are",
    "start": "240",
    "end": "7000"
  },
  {
    "text": "currently using spark operator on kubernetes",
    "start": "7000",
    "end": "11320"
  },
  {
    "text": "today that's not a bad number that's good but we're going to cover bit of",
    "start": "12679",
    "end": "17880"
  },
  {
    "text": "basics of the spark and then spark operator um so I think you should be okay right so with the my name is vuntu",
    "start": "17880",
    "end": "27240"
  },
  {
    "text": "I'm a principal open source specialist sess working with AWS and I'm also a",
    "start": "27240",
    "end": "32800"
  },
  {
    "text": "qflow spar operator maintainer and in my day-to-day job I work with uh data and ml platforms and",
    "start": "32800",
    "end": "41600"
  },
  {
    "text": "building these platforms highly scalable on kubernetes yeah uh that's me with me uh",
    "start": "41600",
    "end": "49280"
  },
  {
    "text": "my co-presenter uh Sharon do you want to introduce yourself uh hello everyone uh thanks thanks for attending our talk my",
    "start": "49280",
    "end": "56000"
  },
  {
    "text": "name is tan I lead the solutions engineering team at Apple I'm one of the early contributors of the spark operator",
    "start": "56000",
    "end": "62719"
  },
  {
    "text": "project and also a maintainer glad to be here today thanks Shon right um so this",
    "start": "62719",
    "end": "70880"
  },
  {
    "text": "is elevating Q FL par operator so we're going to talk about some of the best prct best practices and enhancements in",
    "start": "70880",
    "end": "77840"
  },
  {
    "text": "today's session so with the um we're going to touch upon some of",
    "start": "77840",
    "end": "83360"
  },
  {
    "text": "the basics of uh Apache spark and and how spark operator is evolved and we",
    "start": "83360",
    "end": "89560"
  },
  {
    "text": "will also talk about the migration of spark operator from Google to qlow",
    "start": "89560",
    "end": "94640"
  },
  {
    "text": "community which a qlow or and since we migrated to Q spark operator we added a lot of enhancements",
    "start": "94640",
    "end": "101560"
  },
  {
    "text": "and features then we'll touch upon all the enhancements and features and we will discuss some of the best practices",
    "start": "101560",
    "end": "107600"
  },
  {
    "text": "of running spark operator on kubernetes in any platform and finally uh we discuss some",
    "start": "107600",
    "end": "114119"
  },
  {
    "text": "of the CU flow Community how you can join and become part of the community to",
    "start": "114119",
    "end": "120240"
  },
  {
    "text": "work with the spark operator right so before I give an",
    "start": "120240",
    "end": "126600"
  },
  {
    "text": "introduction to spark operator I want to touch upon Apache spark itself right so most of you are familiar with Apache",
    "start": "126600",
    "end": "133480"
  },
  {
    "text": "spark Apache spark is very popular and distributed data processing framework",
    "start": "133480",
    "end": "139440"
  },
  {
    "text": "which is used for both batch processing streaming and even machine learning worklet today right in Apache spark in",
    "start": "139440",
    "end": "147280"
  },
  {
    "text": "2018 uh in version 2.3 that is one Apaches spark added a support for",
    "start": "147280",
    "end": "153200"
  },
  {
    "text": "running on kubernetes uh in addition to um Hado and you know",
    "start": "153200",
    "end": "160280"
  },
  {
    "text": "msos so that's when things have changed a lot of customers and organizations",
    "start": "160280",
    "end": "166760"
  },
  {
    "text": "started to run the spark on kuties So within the same year in",
    "start": "166760",
    "end": "172080"
  },
  {
    "text": "2018 uh the same contributors also started building the spark operator and",
    "start": "172080",
    "end": "177760"
  },
  {
    "text": "they buil and some of the Google folks have built the Google Cloud I think they are from Google Cloud platform and they",
    "start": "177760",
    "end": "184480"
  },
  {
    "text": "built this Google spark operator and they open sourced in 2018 but since then",
    "start": "184480",
    "end": "190480"
  },
  {
    "text": "that's been used by a lot of organizations as you see I think 40 companies as part the adopter page",
    "start": "190480",
    "end": "197440"
  },
  {
    "text": "there's a lot of starts on the repo and and most importantly spark operator it",
    "start": "197440",
    "end": "203040"
  },
  {
    "text": "actually simplifies the the the life cycle of the spark job execution on kubernetes itself right it manages the",
    "start": "203040",
    "end": "210239"
  },
  {
    "text": "automation of the Spock job uh and ensures the life cycle of it and retrice",
    "start": "210239",
    "end": "215879"
  },
  {
    "text": "when the Spock job fails and it has all the capabilities in terms of the metrics",
    "start": "215879",
    "end": "222120"
  },
  {
    "text": "uh and in overall uh it simplifies the Journey of the spark running on",
    "start": "222120",
    "end": "228840"
  },
  {
    "text": "kubernetes right so let me touch about um bit about how spark operator um the",
    "start": "229760",
    "end": "237519"
  },
  {
    "text": "migrated to Q flow right so in I think in last year and in cucon uh myself and",
    "start": "237519",
    "end": "243400"
  },
  {
    "text": "Sharon from Apple and marsan from Google and few other folks got together um and",
    "start": "243400",
    "end": "248879"
  },
  {
    "text": "we talked about you know Google spark operators has being there a lot of customers are using but it was suffering",
    "start": "248879",
    "end": "254439"
  },
  {
    "text": "from some of the maintenance issues from the last 2 to three years um we spoke to some of those maintenance from Google",
    "start": "254439",
    "end": "260560"
  },
  {
    "text": "and discussed about you know the options and they were ready to donate that",
    "start": "260560",
    "end": "266960"
  },
  {
    "text": "project to you know the bigger communities like Apachi as well as C flow so we submitted that spip proposal",
    "start": "266960",
    "end": "275440"
  },
  {
    "text": "to both Apachi Apachi as well as qlow uh unfortunately it was not accepted under",
    "start": "275440",
    "end": "281840"
  },
  {
    "text": "Apachi but it was accepted by the qlow community so that was an issue what you're seeing um and with",
    "start": "281840",
    "end": "291520"
  },
  {
    "text": "that and I think few months of the work uh we managed to migrate that the reaper",
    "start": "291880",
    "end": "297639"
  },
  {
    "text": "from Google Cloud platform to qf flow community and so we announced a Blog and",
    "start": "297639",
    "end": "302720"
  },
  {
    "text": "blog has uh pretty much all the details and with the QR code if you look at it",
    "start": "302720",
    "end": "307919"
  },
  {
    "text": "but um with the people like Sharon Andre and a lot of other people came to came",
    "start": "307919",
    "end": "314320"
  },
  {
    "text": "along and tried to migrate the whole repo and and build a community around",
    "start": "314320",
    "end": "320520"
  },
  {
    "text": "it so with that I would like to touch upon what you see on the slide is a",
    "start": "320759",
    "end": "326680"
  },
  {
    "text": "simple spark operator manifest like if you want to run Spock job on kubernetes",
    "start": "326680",
    "end": "332840"
  },
  {
    "text": "so with Spock submit you might have to create uh the large Json file with all",
    "start": "332840",
    "end": "338120"
  },
  {
    "text": "the configurations but with spark operator you'll be writing a simple yaml file you just Define the kind as a spark",
    "start": "338120",
    "end": "344960"
  },
  {
    "text": "application and the driver spe and executive spec that's the minimum spec that you need to run the job just run C",
    "start": "344960",
    "end": "351360"
  },
  {
    "text": "CTL apply that goes to kubernetes API and creates all the driver and executive",
    "start": "351360",
    "end": "356800"
  },
  {
    "text": "parts and runs a job and it manages a life cycle by the spark operator",
    "start": "356800",
    "end": "363319"
  },
  {
    "text": "itself but then moving on to uh some of the internals of the spark operator right so we talked about okay so what a",
    "start": "363319",
    "end": "370680"
  },
  {
    "text": "spark operator does internally there are four components within the spark operator as you see there one of them is",
    "start": "370680",
    "end": "376800"
  },
  {
    "text": "a controller which is like heart of the spark operator so when user the Manifest",
    "start": "376800",
    "end": "381880"
  },
  {
    "text": "that we have seen from the previous slide submits using CBE CDL apply and",
    "start": "381880",
    "end": "387120"
  },
  {
    "text": "that manifest will be submitted to the API server kubernetes API server that is",
    "start": "387120",
    "end": "392199"
  },
  {
    "text": "when the spark operative controller comes into the picture and start watching for the spark application custom resources and when when it finds",
    "start": "392199",
    "end": "399639"
  },
  {
    "text": "one and then it validates a spec and identifies if the spec is valid and once",
    "start": "399639",
    "end": "405400"
  },
  {
    "text": "it validates it sends back to the second component of the spark operator which is a submission Runner and submission run",
    "start": "405400",
    "end": "412520"
  },
  {
    "text": "runner is like a crucial component what it does is converts that Spar application into a spar sub submit",
    "start": "412520",
    "end": "419840"
  },
  {
    "text": "command which is a native way of sub submitting Spar jobs to kubernetes once a job is submitted and then you have",
    "start": "419840",
    "end": "426840"
  },
  {
    "text": "Spar pod monitor which is another component it keeps watching for the status of the driver and executors and",
    "start": "426840",
    "end": "433840"
  },
  {
    "text": "Reporting back to the controller on the latest status and finally the the fourth",
    "start": "433840",
    "end": "439759"
  },
  {
    "text": "component is a mutating admission web Hub this is um it's crucial until this",
    "start": "439759",
    "end": "445560"
  },
  {
    "text": "point but we're going to talk about the feature which is po templates that comes in later but mutating admission V hook",
    "start": "445560",
    "end": "451759"
  },
  {
    "text": "runs along with the spark operator this ensures that all your volumes are attached and ready before the spark job",
    "start": "451759",
    "end": "458639"
  },
  {
    "text": "is started so it takes care of a lot of other things like adding labels note selectors stains and config Max",
    "start": "458639",
    "end": "464879"
  },
  {
    "text": "creations and so on so that's pretty much all the key components of the spark",
    "start": "464879",
    "end": "470240"
  },
  {
    "text": "operator internals but in summary uh you know when you submit a spark job and",
    "start": "470240",
    "end": "476240"
  },
  {
    "text": "Spark operator takes care of the whole life cycle and it provides a feature such as retrying when something fails",
    "start": "476240",
    "end": "483759"
  },
  {
    "text": "and it also provides some metrics that we will discuss in the latest slides so with that I'll hand over to",
    "start": "483759",
    "end": "490479"
  },
  {
    "text": "Sharon who's going to talk about new features and enhancements that we added to spark operators since we migrated to",
    "start": "490479",
    "end": "496120"
  },
  {
    "text": "qf flow thank you all right thanks V uh I'll be going over uh some of the highlights uh some recent contributions",
    "start": "496120",
    "end": "503319"
  },
  {
    "text": "from the community uh major features and enhancements uh that the community did ever since the uh migration of the",
    "start": "503319",
    "end": "509159"
  },
  {
    "text": "project to cube flow uh to start off I'll be covering the documentation website and the container registry",
    "start": "509159",
    "end": "514800"
  },
  {
    "text": "migration to CU flow uh then I'll spend a few minutes on the uh on the major rewrite of the project using a framework",
    "start": "514800",
    "end": "521518"
  },
  {
    "text": "called controller R time and after that uh let's also talk about two primary ways of customizing the behaviors of",
    "start": "521519",
    "end": "528480"
  },
  {
    "text": "spark applications uh the first way is to to use uh what's called po template which is a feature that's made available",
    "start": "528480",
    "end": "535320"
  },
  {
    "text": "in Pache spark itself since spark 3.0 uh that allows uh users to customize uh uh",
    "start": "535320",
    "end": "542079"
  },
  {
    "text": "properties and Fs of spark pods and another way is to uh uh Infuse some",
    "start": "542079",
    "end": "547399"
  },
  {
    "text": "patch scheduling capabilities using a another open source project called patch unicorn and after that uh let's uh go",
    "start": "547399",
    "end": "554079"
  },
  {
    "text": "over uh best practices in the areas of uh security uh multi tendency uh metrics",
    "start": "554079",
    "end": "559320"
  },
  {
    "text": "and monitoring so first off uh some Logistics and uh since the project is",
    "start": "559320",
    "end": "566680"
  },
  {
    "text": "now under cuute flow we migrated the container registry uh from the uh their original home of Google container",
    "start": "566680",
    "end": "573040"
  },
  {
    "text": "registry or GCR to cube flow uh and in the past uh Docker images for spark operator live under GCR and the project",
    "start": "573040",
    "end": "581079"
  },
  {
    "text": "maintainer had to manually generate those images and push those to GCR and now uh new images uh completely um live",
    "start": "581079",
    "end": "588800"
  },
  {
    "text": "under qflow dockerhub U organization and images are automatically generated and",
    "start": "588800",
    "end": "594360"
  },
  {
    "text": "pushed uh using an automated pipeline upon each operator release and uh We've",
    "start": "594360",
    "end": "600200"
  },
  {
    "text": "also included a screenshot of the uh the new operator documentation website you",
    "start": "600200",
    "end": "605279"
  },
  {
    "text": "can see that it's now hosted under uh Q flow official website and uh sitting",
    "start": "605279",
    "end": "610320"
  },
  {
    "text": "alongside other qlow components like model registry qflow pipelines and so",
    "start": "610320",
    "end": "617120"
  },
  {
    "text": "on uh next let's talk about uh this major refactoring of operator using",
    "start": "617560",
    "end": "622959"
  },
  {
    "text": "controller round time and this is a major refactoring uh or I would say a complete rewrite uh and and uh I've",
    "start": "622959",
    "end": "629959"
  },
  {
    "text": "provided a link to the uh PR if you are interested in reviewing the code in more detail but before talking about this uh",
    "start": "629959",
    "end": "636680"
  },
  {
    "text": "refactoring itself uh some historical background uh originally when the operator was first created years ago uh",
    "start": "636680",
    "end": "643720"
  },
  {
    "text": "the original implementation was uh uh created based on client go which is",
    "start": "643720",
    "end": "648839"
  },
  {
    "text": "still to this day the official goand SDK for kubernetes this is a powerful piece",
    "start": "648839",
    "end": "654200"
  },
  {
    "text": "of software uh it allows de a developer to U do basically anything that's possible within a kubernetes environment",
    "start": "654200",
    "end": "661519"
  },
  {
    "text": "uh it's it's a great tool but when it comes to writing a custom controller or an operator it's not very convenient",
    "start": "661519",
    "end": "667360"
  },
  {
    "text": "because uh lots of the operations that are essential U for for an operator need",
    "start": "667360",
    "end": "672639"
  },
  {
    "text": "to be manually handled and among those operations include uh crowd operations",
    "start": "672639",
    "end": "677720"
  },
  {
    "text": "on crd objects in our case this is operations on spark application crd objects and also management of uh uh",
    "start": "677720",
    "end": "685480"
  },
  {
    "text": "informers uh works and lists and uh in case you are not familiar uh these are",
    "start": "685480",
    "end": "691000"
  },
  {
    "text": "critical mechanisms uh in any operator implementation and in former is a uh is",
    "start": "691000",
    "end": "696079"
  },
  {
    "text": "a mechanism that allows an operator uh to be informed of any changes and",
    "start": "696079",
    "end": "701200"
  },
  {
    "text": "actions uh uh that are happening to the uh crd objects that are of interest and",
    "start": "701200",
    "end": "707519"
  },
  {
    "text": "so that the operator can take actions accordingly based on the custom logic that the developer has uh",
    "start": "707519",
    "end": "713320"
  },
  {
    "text": "implemented and a work CU is also essential as the name suggests it's a a",
    "start": "713320",
    "end": "718880"
  },
  {
    "text": "queue uh that hosts uh that includes um that that basically cues up all the events that are happening to the CD",
    "start": "718880",
    "end": "725600"
  },
  {
    "text": "objects in the cluster and the operator will be uh basically doing deqing operation on the work queue and",
    "start": "725600",
    "end": "732399"
  },
  {
    "text": "processes those um items in the in the queue in athly fashion and the listers",
    "start": "732399",
    "end": "738399"
  },
  {
    "text": "allows an operator to list um uh all the objects in the cor cluster and also",
    "start": "738399",
    "end": "745079"
  },
  {
    "text": "allows for support of Uh custom labels and notations and so on or filtering by",
    "start": "745079",
    "end": "751240"
  },
  {
    "text": "name spaces and that's straightforward uh so a good thing about control around",
    "start": "751240",
    "end": "756360"
  },
  {
    "text": "time is that it offers a higher level abstraction compared to client goal so that developers don't have to uh spend",
    "start": "756360",
    "end": "761720"
  },
  {
    "text": "time writing those um basic Primitives and uh all of these features that I talked about just now are provided by",
    "start": "761720",
    "end": "769000"
  },
  {
    "text": "controller WR time out of the box and what's even better is that there's another open source project",
    "start": "769000",
    "end": "774399"
  },
  {
    "text": "called CU Builder which is U hosted under comm's special interest groups uh GitHub org and uh CU provides a a more",
    "start": "774399",
    "end": "782920"
  },
  {
    "text": "convenient way of using controller around time it provides lots of code generation and Scaffolding capabilities",
    "start": "782920",
    "end": "788199"
  },
  {
    "text": "so that a developer can quickly get up to speed running and writing a a new operator and what this PR uh uh did was",
    "start": "788199",
    "end": "795959"
  },
  {
    "text": "uh to use cuer to generate uh the new project structure and uh porting over the existing uh logic uh for handling",
    "start": "795959",
    "end": "803199"
  },
  {
    "text": "spark applications to the new product structure and uh this is a major",
    "start": "803199",
    "end": "808800"
  },
  {
    "text": "highlight of the recent release major release that the community did for version2.0 uh and the author came from",
    "start": "808800",
    "end": "817199"
  },
  {
    "text": "Alibaba and uh this author is now also eliminated as one of the maintainers of the uh",
    "start": "817199",
    "end": "824480"
  },
  {
    "text": "project uh next up let's talk about uh a uh feature that's available in Apache",
    "start": "824720",
    "end": "830199"
  },
  {
    "text": "spark itself called po template and uh also just like previously before talking",
    "start": "830199",
    "end": "836199"
  },
  {
    "text": "about the feature itself some uh background and since the uh initial creation of the operator project uh it",
    "start": "836199",
    "end": "843120"
  },
  {
    "text": "relied heavily on what's called a web hook for customizing spark Poots and these customization operations are um",
    "start": "843120",
    "end": "850680"
  },
  {
    "text": "common place and it's it's commonly needed for many um use cases and those",
    "start": "850680",
    "end": "856040"
  },
  {
    "text": "include adding volumes uh mounting volumes config Ms unit containers and so on and web Hook was a uh was an",
    "start": "856040",
    "end": "864079"
  },
  {
    "text": "effective mechanism for handling these responsibilities uh but uh it proves to be quite tricky uh to automate and",
    "start": "864079",
    "end": "871600"
  },
  {
    "text": "maintain uh especially in a production environment uh because a web hook this web hook uh that the operator is",
    "start": "871600",
    "end": "878120"
  },
  {
    "text": "embedded with uh is a is a HTTP service and uh because of that it needs a uh a",
    "start": "878120",
    "end": "884040"
  },
  {
    "text": "dedicated kuet secret which needs to be generated with a one-time coronus job uh",
    "start": "884040",
    "end": "889399"
  },
  {
    "text": "upon the initial deployment of the operator and also uh it needs to be refreshed upon each redeployment of the",
    "start": "889399",
    "end": "896199"
  },
  {
    "text": "operator and uh and also that one time this job needs to be uh cleaned up upon",
    "start": "896199",
    "end": "901240"
  },
  {
    "text": "completion uh so all of these um um details require some special handling and automation uh it's a uh some extra",
    "start": "901240",
    "end": "908839"
  },
  {
    "text": "work especially in production and ever since spark 3.0 added the P template support uh it's uh",
    "start": "908839",
    "end": "916240"
  },
  {
    "text": "it has become the uh standard way of uh customizing spark pods uh basically taking over all the responsibilities",
    "start": "916240",
    "end": "922519"
  },
  {
    "text": "that the operator web hook uh has been uh responsible for in the past uh and",
    "start": "922519",
    "end": "928079"
  },
  {
    "text": "part template provides a much lighter weight option uh while um avoiding all",
    "start": "928079",
    "end": "933279"
  },
  {
    "text": "the hassles of Maintenance and operations uh that that were present with the web",
    "start": "933279",
    "end": "940560"
  },
  {
    "text": "hook and uh another highlight in version 2.0 uh is uh the added support for",
    "start": "942319",
    "end": "948040"
  },
  {
    "text": "Apache unicorn uh in case you're not familiar aache unicorn is another open source project that provides a special",
    "start": "948040",
    "end": "955399"
  },
  {
    "text": "sketching capabilities uh that's geared toward batch oriented workloads uh batch workloads differ from online uh or U",
    "start": "955399",
    "end": "962360"
  },
  {
    "text": "long running web services type of workloads in a number of significant ways uh for example many of them have",
    "start": "962360",
    "end": "968600"
  },
  {
    "text": "requirements for U quota enforcement or um application ordering or G gading and",
    "start": "968600",
    "end": "976680"
  },
  {
    "text": "uh a good thing about Apache unicorn is that it doesn't require much extra work to be integrated with any um any",
    "start": "976680",
    "end": "984279"
  },
  {
    "text": "framework uh and Spark operator was already working well with the pat uniform um to take advantage of its",
    "start": "984279",
    "end": "990240"
  },
  {
    "text": "capabilities for handling cues resource quotas and application ordering and but",
    "start": "990240",
    "end": "997040"
  },
  {
    "text": "the significance of this uh recent contribution uh is to add the support for Gans gading and a few words about G gading uh",
    "start": "997040",
    "end": "1004600"
  },
  {
    "text": "it's a common requirement for batch workloads especially for machine learning workloads uh because uh those",
    "start": "1004600",
    "end": "1010000"
  },
  {
    "text": "type of workloads require that uh a certain uh group of workers uh to be scheduled uh to be considered as a",
    "start": "1010000",
    "end": "1016680"
  },
  {
    "text": "single unit uh during scheduling time time and sketching should only happen for this gain of workers uh if the",
    "start": "1016680",
    "end": "1025000"
  },
  {
    "text": "resources in the cluster can be um there's sufficient resources in the environment to meet uh the uh to meet",
    "start": "1025000",
    "end": "1031438"
  },
  {
    "text": "the requirements for the entire G as opposed to one single worker within that G and um Apache unicorn has a unique way",
    "start": "1031439",
    "end": "1040918"
  },
  {
    "text": "of uh implementing G schuling the way it does it is uh through this mechanism called placeholder pods so what that",
    "start": "1040919",
    "end": "1047520"
  },
  {
    "text": "does is that unicorn uses um uh some fake pods that we call placeholder pods to reserve resources for real pods uh",
    "start": "1047520",
    "end": "1055080"
  },
  {
    "text": "before the real pods are um generated uh in the first place and those placeholder",
    "start": "1055080",
    "end": "1060320"
  },
  {
    "text": "paths will be reserving resources and uh try to test Waters to see whether the environment has sufficient resources to",
    "start": "1060320",
    "end": "1066840"
  },
  {
    "text": "meet the Gan requirements and uh a key uh requirement uh in this uh uh G sking um",
    "start": "1066840",
    "end": "1073520"
  },
  {
    "text": "implementation for unicorn uh is that the placeholder PS need to be of identical resource requ request compared",
    "start": "1073520",
    "end": "1079720"
  },
  {
    "text": "to the real pods that will be replacing those um fake fake pods um in the future",
    "start": "1079720",
    "end": "1086480"
  },
  {
    "text": "and if the resource request between the uh Place pods and real pods if there's",
    "start": "1086480",
    "end": "1091960"
  },
  {
    "text": "any discrepancy between them there can be sttle bugs that may occur uh so there there has to be an exact match uh this",
    "start": "1091960",
    "end": "1098520"
  },
  {
    "text": "PR basically added the calculation Logic for uh placeholder po uh resource request and for Apache spark it's a bit",
    "start": "1098520",
    "end": "1105480"
  },
  {
    "text": "involved because lots of the um logic needs to be implemented uh for to take",
    "start": "1105480",
    "end": "1110600"
  },
  {
    "text": "into consideration for uh multiple resource factors not only the resources needed for the spark driver and the",
    "start": "1110600",
    "end": "1117039"
  },
  {
    "text": "executors themselves but also overhead memory uh and offhe memory uh",
    "start": "1117039",
    "end": "1123280"
  },
  {
    "text": "Etc and also this contribution uh has a nice enhancement to allow uh unicorn to",
    "start": "1123280",
    "end": "1130320"
  },
  {
    "text": "be used as the U uh badge scheduler without unicorn's own animation controller uh to be uh enabled so",
    "start": "1130320",
    "end": "1137159"
  },
  {
    "text": "unicorn has its own animation weap hook uh that's a separate component uh some um community members have found that to",
    "start": "1137159",
    "end": "1143440"
  },
  {
    "text": "be challenging to deal with uh and uh now that's no longer needed you can run uniform Sketcher itself without its uh",
    "start": "1143440",
    "end": "1151120"
  },
  {
    "text": "animation controller and uh have that integrated with spark operator while still having spark applications uh be",
    "start": "1151120",
    "end": "1158080"
  },
  {
    "text": "able to take advantage of all the uh capabilities that apach unicorn has to",
    "start": "1158080",
    "end": "1163519"
  },
  {
    "text": "offer and uh uh the community is also heavily invested in security uh security",
    "start": "1163960",
    "end": "1170720"
  },
  {
    "text": "uh is critical for any production or Enterprise environments uh there's a mult multiple recent contributions in",
    "start": "1170720",
    "end": "1177679"
  },
  {
    "text": "this area I won't I won't go into details for any of these um but uh just want to highlight that a general idea is",
    "start": "1177679",
    "end": "1185000"
  },
  {
    "text": "that we want to the community wants to uh tighten the security posture of the",
    "start": "1185000",
    "end": "1190120"
  },
  {
    "text": "operator as much as possible to make it the suitable for Enterprise deployments and uh permissions should only be",
    "start": "1190120",
    "end": "1196600"
  },
  {
    "text": "granted uh to to any of the operator uh when they are absolutely needed for",
    "start": "1196600",
    "end": "1202120"
  },
  {
    "text": "certain functionalities and there has to be a justification instead of opening up the wi permissions for",
    "start": "1202120",
    "end": "1209600"
  },
  {
    "text": "everything uh and now uh let's uh move on to uh some best practices discussion",
    "start": "1210320",
    "end": "1215480"
  },
  {
    "text": "um so to to start off uh there's some considerations uh to deal with the multitenancy",
    "start": "1215480",
    "end": "1221440"
  },
  {
    "text": "and uh if you are a user of spark operator you might uh be aware of this uh flag in the operator Helm chart uh",
    "start": "1221440",
    "end": "1229120"
  },
  {
    "text": "called the spark. jum namespaces this is a flag that allows a user to configure",
    "start": "1229120",
    "end": "1234520"
  },
  {
    "text": "the list of namespaces that this operator deployment is monitoring uh if you leave that out uh on field to be",
    "start": "1234520",
    "end": "1241159"
  },
  {
    "text": "empty then this operator deployment will be uh by default monitoring all the name spaces uh and uh all the applications in",
    "start": "1241159",
    "end": "1248799"
  },
  {
    "text": "the entire cluster uh that may be uh an acceptable uh deployment situation um",
    "start": "1248799",
    "end": "1254480"
  },
  {
    "text": "but uh in a large busy cluster that has uh let's say over a thousand nodes and",
    "start": "1254480",
    "end": "1260240"
  },
  {
    "text": "with the busy tenants it might not be a good solution so there's some additional considerations to be U to be taken into",
    "start": "1260240",
    "end": "1267799"
  },
  {
    "text": "account and uh a general recommendation is that you should consider having multiple operator uh uh instances in a",
    "start": "1267799",
    "end": "1274600"
  },
  {
    "text": "single cluster in a multi-tenant environment this is to allow for better tenant isolation because different",
    "start": "1274600",
    "end": "1280600"
  },
  {
    "text": "tenants have different traffic uh patterns and different uh tolerance um for example uh some tenants might have",
    "start": "1280600",
    "end": "1288320"
  },
  {
    "text": "uh a a stronger requirements for application startup latency and some other tenants may be more lenient in",
    "start": "1288320",
    "end": "1294480"
  },
  {
    "text": "those um regards so uh by having multiple spark operator deployments you can assign different tenants different",
    "start": "1294480",
    "end": "1301320"
  },
  {
    "text": "teams within the uh same comp cluster to be to be uh to be managed by different",
    "start": "1301320",
    "end": "1306559"
  },
  {
    "text": "operator instances for example we can have operator deployment number one managing uh tenants one and two and the",
    "start": "1306559",
    "end": "1312880"
  },
  {
    "text": "rest of the tenants to be managed by another uh Spar operator uh instance that also gives you flexibility with the",
    "start": "1312880",
    "end": "1319880"
  },
  {
    "text": "resource configurations because uh some some busier tenants might justify uh",
    "start": "1319880",
    "end": "1325360"
  },
  {
    "text": "putting uh allocating additional resources to the to that operator deployment managing those busier tenants",
    "start": "1325360",
    "end": "1331240"
  },
  {
    "text": "U maybe they can use U more memory or more CPUs and related to that uh um uh Point",
    "start": "1331240",
    "end": "1339480"
  },
  {
    "text": "there's also a concern for performance improvements uh especially in a in a busy cluster and uh control one time",
    "start": "1339480",
    "end": "1345799"
  },
  {
    "text": "provides a feature called rate limiter out of the box and that's provided and exposed via these two flags in the",
    "start": "1345799",
    "end": "1352600"
  },
  {
    "text": "operator hel chart and those two uh parameters are called uh bucket QPS and",
    "start": "1352600",
    "end": "1357880"
  },
  {
    "text": "bucket size respectively uh so what that what that does is that it provides a way",
    "start": "1357880",
    "end": "1363600"
  },
  {
    "text": "for uh to control the inflow and outflow of incoming requests uh for new applications so each uh spark",
    "start": "1363600",
    "end": "1369880"
  },
  {
    "text": "application crd object is one single request a bucket size uh of 500 is",
    "start": "1369880",
    "end": "1375480"
  },
  {
    "text": "picked uh as a default and what that means is that um the operator will be able to hold 500 applications in the in",
    "start": "1375480",
    "end": "1383039"
  },
  {
    "text": "the bucket in the rate limiter uh simultaneously and uh if there's more incoming applications um those will be",
    "start": "1383039",
    "end": "1390480"
  },
  {
    "text": "on hold until the the bucket is freed up so that they can be admitted and",
    "start": "1390480",
    "end": "1395919"
  },
  {
    "text": "processed and bucket QPS is another another parameter that controls the outflow uh how how quickly the operator",
    "start": "1395919",
    "end": "1402320"
  },
  {
    "text": "Can U simultaneously process those application uh requests and uh these numbers are just",
    "start": "1402320",
    "end": "1410000"
  },
  {
    "text": "provided there as default as a general guidance but it it might make sense for",
    "start": "1410000",
    "end": "1415799"
  },
  {
    "text": "your own deployments and uh your traffic characteristics to experiment with the",
    "start": "1415799",
    "end": "1421240"
  },
  {
    "text": "these numbers to arrive that the ideal um performance requirements that that",
    "start": "1421240",
    "end": "1427080"
  },
  {
    "text": "you may need all right now I'll pass it back to VRA to talk about the metrics and the rapidity sure thanks Shon right",
    "start": "1427080",
    "end": "1435840"
  },
  {
    "text": "um and I think the going back to the point I would like to mention so if you are already using spark operator with",
    "start": "1435840",
    "end": "1442120"
  },
  {
    "text": "the old configurations and um you might not see this performance improvements that QPS and bucket size uh which is",
    "start": "1442120",
    "end": "1448919"
  },
  {
    "text": "recently added into the helm chart at the latest versions of 202 um so we have we are in the process",
    "start": "1448919",
    "end": "1455320"
  },
  {
    "text": "of running the benchmarks yet so we're still thinking this might be more performant than the previous one but we",
    "start": "1455320",
    "end": "1460360"
  },
  {
    "text": "don't have the stats yet um but this uh you can adjust according to your",
    "start": "1460360",
    "end": "1465760"
  },
  {
    "text": "workload how you are running um uh like shadon said you can have multiple",
    "start": "1465760",
    "end": "1471600"
  },
  {
    "text": "operators and have different settings and until and find The Sweet Spot what works for you right before you get with",
    "start": "1471600",
    "end": "1478919"
  },
  {
    "text": "that right so I think the most important thing is now when you run Spock applications on kubernetes and",
    "start": "1479399",
    "end": "1486039"
  },
  {
    "text": "observability is a big factor right and your data teams and they run the job and they they say hey I submitted a job I",
    "start": "1486039",
    "end": "1493240"
  },
  {
    "text": "don't know what happened you know I I don't see a way that my job is running or not so so um the job submission can",
    "start": "1493240",
    "end": "1500120"
  },
  {
    "text": "happen from airflow or various other job schedulers um with that um but there",
    "start": "1500120",
    "end": "1506080"
  },
  {
    "text": "levels of observability so let's start with spark operator observability right so spark operator itself running within",
    "start": "1506080",
    "end": "1511799"
  },
  {
    "text": "kubernetes we really want to see what spark operator gives whether how many spark applications are running uh how",
    "start": "1511799",
    "end": "1517320"
  },
  {
    "text": "many jobs are completed and what is the latency in terms of processing these jobs so um we added this feature to the",
    "start": "1517320",
    "end": "1524399"
  },
  {
    "text": "helm chart and as you see um the small snippet of the code uh you just enable there and and Spark operator um exposes",
    "start": "1524399",
    "end": "1532919"
  },
  {
    "text": "these metrics to Prometheus so you can use grafana to visualize this metrix and look at the latency and other things and",
    "start": "1532919",
    "end": "1539919"
  },
  {
    "text": "then you can go back and verify if you can adjust your QPS and you can adjust your bucket size that can meet with the",
    "start": "1539919",
    "end": "1546399"
  },
  {
    "text": "latency right so it's all about how quickly your Spock jobs are being processed and this will help you with",
    "start": "1546399",
    "end": "1552440"
  },
  {
    "text": "The Spar operator metrix itself now moving on to the",
    "start": "1552440",
    "end": "1559159"
  },
  {
    "text": "the next topic which is about uh Spar driver and executor metrics itself right so now these uh the data teams who are",
    "start": "1559159",
    "end": "1567279"
  },
  {
    "text": "running the spark jobs they really want to see uh how how much memory and CPU usage uh memory usage CPU usage and even",
    "start": "1567279",
    "end": "1574200"
  },
  {
    "text": "jvm usage and how the shuffle is performing Network bandwidth all sorts of metrics that Apache spark exposes uh",
    "start": "1574200",
    "end": "1582000"
  },
  {
    "text": "that you can expose us metrics of Prometheus with a simple configuration what you see there previously with spark",
    "start": "1582000",
    "end": "1589000"
  },
  {
    "text": "operator there is a concept called jmx exporter there's a additional jar file that you need to use to export those",
    "start": "1589000",
    "end": "1594880"
  },
  {
    "text": "metrics and you don't have to do that anymore so this is a built-in feature within Apache Spark It's called",
    "start": "1594880",
    "end": "1600640"
  },
  {
    "text": "promethee seret class and with that class it handles those metrics and exposes those driver and executor",
    "start": "1600640",
    "end": "1607159"
  },
  {
    "text": "metrics to Prometheus and there's a lot of Open Source dashboards with grafana you can visualize those metric and take",
    "start": "1607159",
    "end": "1613480"
  },
  {
    "text": "a look at how your driver and execut is performing um that gives you that",
    "start": "1613480",
    "end": "1618559"
  },
  {
    "text": "overall visualization of the individual jobs but then spark history server right",
    "start": "1618559",
    "end": "1625840"
  },
  {
    "text": "traditionally all the data Engineers are relied on Spar history server uh they want to see how their job is performing",
    "start": "1625840",
    "end": "1632000"
  },
  {
    "text": "whether they can optimize the Spock job itself to make it faster the one way to do it looking at a SP hisry server it'll",
    "start": "1632000",
    "end": "1638600"
  },
  {
    "text": "it will give the entire dag and how long each stage took Sometimes some of the stages might take a longer so they can",
    "start": "1638600",
    "end": "1645480"
  },
  {
    "text": "go back and change the code and modify it so how do they get the spark server logs but with the Hadoop and other you",
    "start": "1645480",
    "end": "1652679"
  },
  {
    "text": "know the traditionally with Hadoop clusters and you have other ways of getting The Spar history server but with",
    "start": "1652679",
    "end": "1657960"
  },
  {
    "text": "the kubernetes you have to run a dedicated Spar history server Helm chart right and that Spar history Ser Helm CH",
    "start": "1657960",
    "end": "1664919"
  },
  {
    "text": "needs to point to the data where these metrics are stored so with these four",
    "start": "1664919",
    "end": "1670360"
  },
  {
    "text": "lines of code uh not a code this configuration that goes into individual",
    "start": "1670360",
    "end": "1675480"
  },
  {
    "text": "spark job um that basically oses your sparkk history server metrics to AR",
    "start": "1675480",
    "end": "1681720"
  },
  {
    "text": "rights to an external storage um this example I'm using S3 but you can write",
    "start": "1681720",
    "end": "1687480"
  },
  {
    "text": "to any storage system that can be any cloud provider object storage or even",
    "start": "1687480",
    "end": "1692720"
  },
  {
    "text": "you know uh uh the any other file systems so once these logs are return to",
    "start": "1692720",
    "end": "1698039"
  },
  {
    "text": "that specific storage and Spark server will be pointed to that storage so that you can visualize all the jobs that were",
    "start": "1698039",
    "end": "1705039"
  },
  {
    "text": "executed even before I mean the this will give you an option where even if a cluster goes down these metrics are",
    "start": "1705039",
    "end": "1711880"
  },
  {
    "text": "available for all your data Engineers to look into it so that's the three levels of the",
    "start": "1711880",
    "end": "1717720"
  },
  {
    "text": "observability that we have um but that's",
    "start": "1717720",
    "end": "1722880"
  },
  {
    "text": "with that um we moving on to yeah the final slide and I think we",
    "start": "1722880",
    "end": "1729279"
  },
  {
    "text": "are in time right so um if you are already using spark operator and what we",
    "start": "1729279",
    "end": "1736720"
  },
  {
    "text": "heard from a lot of the folks are they foged the spark operator and started to build their own features and using in",
    "start": "1736720",
    "end": "1743559"
  },
  {
    "text": "their organization it's just because they've raised the PRS in the past but their PRS were not merged into the",
    "start": "1743559",
    "end": "1749080"
  },
  {
    "text": "Google Cloud as spark Operator just because of the maintenance issues but then now it's moved to the qow spark",
    "start": "1749080",
    "end": "1754720"
  },
  {
    "text": "operator we have a lot of contributors and maintainers now and they're actively working on it as you can see the",
    "start": "1754720",
    "end": "1760120"
  },
  {
    "text": "enhancements and features that we added I think in April uh within a short span of time we have Rewritten the whole",
    "start": "1760120",
    "end": "1766840"
  },
  {
    "text": "spark operator and continuously adding the new features and so I would urge everyone who is already using it bring",
    "start": "1766840",
    "end": "1774360"
  },
  {
    "text": "your changes and raise a PR raise an issue and make this better and join the",
    "start": "1774360",
    "end": "1779640"
  },
  {
    "text": "community so we also created uh new spark operator Channel under slack",
    "start": "1779640",
    "end": "1786480"
  },
  {
    "text": "Channel under cncf so you can join there and you know raise your questions or",
    "start": "1786480",
    "end": "1791519"
  },
  {
    "text": "anything that you want to contribute um and there's two QR codes one goes to the spark operator and",
    "start": "1791519",
    "end": "1797039"
  },
  {
    "text": "another one for SL channel so uh with that Sharon do you want to add anything yeah I just want to say that this is a",
    "start": "1797039",
    "end": "1803760"
  },
  {
    "text": "Community Driven effort and lots of the actually all of the uh PRS that",
    "start": "1803760",
    "end": "1809880"
  },
  {
    "text": "enhancements features that I presented today were contributed by community members many of them have become a",
    "start": "1809880",
    "end": "1815840"
  },
  {
    "text": "maintainers uh since their initial contributions and any contribution is a contribution uh feel free to start any",
    "start": "1815840",
    "end": "1821880"
  },
  {
    "text": "um discussions on on the slack Channel or contribute to the documentation or um participate on discussions",
    "start": "1821880",
    "end": "1828480"
  },
  {
    "text": "um so um yeah we welcome new contributors at any time look forward to",
    "start": "1828480",
    "end": "1833519"
  },
  {
    "text": "seeing you in the community yeah thank you very much and if anyone has any questions please come",
    "start": "1833519",
    "end": "1839080"
  },
  {
    "text": "to the mic and I think we have four minutes before the session ends yeah",
    "start": "1839080",
    "end": "1846840"
  },
  {
    "text": "thanks thank you uh just a quick question I'm a big",
    "start": "1848640",
    "end": "1855240"
  },
  {
    "text": "supporter of uh CU flow used in Capital One used it in Freddy MAAC but the",
    "start": "1855240",
    "end": "1861440"
  },
  {
    "text": "challenge always has been with the pr merges when we submit it to Google it",
    "start": "1861440",
    "end": "1866720"
  },
  {
    "text": "was a nightmare it's glad I'm glad to hear that now it's under the cncf libr",
    "start": "1866720",
    "end": "1872279"
  },
  {
    "text": "uh umbrella um there are a lot of Enterprise type of",
    "start": "1872279",
    "end": "1878960"
  },
  {
    "text": "challenges that cves that were not uh easy to resolve uh have we done anything",
    "start": "1878960",
    "end": "1885840"
  },
  {
    "text": "in in that aspect to be um have some sort of um Cadence on",
    "start": "1885840",
    "end": "1892200"
  },
  {
    "text": "taking care of the security uh vulnerabilities and stuff like that right um I'll reiterate the",
    "start": "1892200",
    "end": "1900000"
  },
  {
    "text": "question so so you're talking about specifically the container images and CVS right so yes okay so there are the",
    "start": "1900000",
    "end": "1907120"
  },
  {
    "text": "two aspects here one is the image uh the spark operator itself runs um and the",
    "start": "1907120",
    "end": "1912919"
  },
  {
    "text": "image that the the data teams brings to run the spark job uh Spock operator I",
    "start": "1912919",
    "end": "1919039"
  },
  {
    "text": "think we've um we've done some optimization since we migrated um but",
    "start": "1919039",
    "end": "1925440"
  },
  {
    "text": "there still we haven't done any of the cve checks further uh that is something",
    "start": "1925440",
    "end": "1930679"
  },
  {
    "text": "it's in the pipeline we contined to improve that um and reduce that but it's",
    "start": "1930679",
    "end": "1936200"
  },
  {
    "text": "it's a big challenge because of all the dependencies and to reduce that uh what we're trying to do is to add some more",
    "start": "1936200",
    "end": "1944360"
  },
  {
    "text": "barriers and layers of the security to reduce that impact for the spark operator itself um yeah that that's but",
    "start": "1944360",
    "end": "1952639"
  },
  {
    "text": "within the community qlo is providing the um um like the KE Community itself",
    "start": "1952639",
    "end": "1959159"
  },
  {
    "text": "is providing the governance for the spark operator project um but uh our",
    "start": "1959159",
    "end": "1964960"
  },
  {
    "text": "contributors are working independently to make sure that every single PR is much so if there is an open PR I think",
    "start": "1964960",
    "end": "1970760"
  },
  {
    "text": "we have really active contributors uh looking to merge those PRS you want to",
    "start": "1970760",
    "end": "1976000"
  },
  {
    "text": "add anything yeah just to add to the uh security vulnerability discussion because spark operator uses Pache spark",
    "start": "1976000",
    "end": "1982480"
  },
  {
    "text": "uh spark submit uh command behind the scenes so many of the vulnerabilities that are present in spark itself will",
    "start": "1982480",
    "end": "1989279"
  },
  {
    "text": "show up in the uh vulnerability report of the operator and uh I would uh",
    "start": "1989279",
    "end": "1994799"
  },
  {
    "text": "encourage uh the uh anyone who's concerned about those uh vulnerabilities to First Look at whether those are",
    "start": "1994799",
    "end": "2001080"
  },
  {
    "text": "really applicable because uh uh first of all not all of them not all of them are critical um severity and even the",
    "start": "2001080",
    "end": "2008039"
  },
  {
    "text": "critical ones not all of them are applicable to any environment or use",
    "start": "2008039",
    "end": "2013120"
  },
  {
    "text": "case uh and uh yeah it needs to be looked that on a case-by Case basis and some vulnerabilities are easier to fix",
    "start": "2013120",
    "end": "2019720"
  },
  {
    "text": "for example we can up upgrade the the goldland version uh but some others are um harder to fix um but yeah as I was",
    "start": "2019720",
    "end": "2026519"
  },
  {
    "text": "saying earlier we welcome contributions yeah I'll take one more question one minute left",
    "start": "2026519",
    "end": "2032240"
  },
  {
    "text": "so uh thank you so much for your talk I'm y spark uh yra Team from Bloomberg",
    "start": "2032240",
    "end": "2037559"
  },
  {
    "text": "and we have our own spark operator deploying our clusters we are very interested in converging to open source",
    "start": "2037559",
    "end": "2044440"
  },
  {
    "text": "operators and follow the best practice one of our pinpoint right now for in",
    "start": "2044440",
    "end": "2049560"
  },
  {
    "text": "platform is multi-tenant resource management and gun scheduling uh we",
    "start": "2049560",
    "end": "2055040"
  },
  {
    "text": "observe that if users schedule multi uh spark applications uh uh drivers might",
    "start": "2055040",
    "end": "2061560"
  },
  {
    "text": "eat have all resources and all drivers will keep requesting executors but stock",
    "start": "2061560",
    "end": "2067320"
  },
  {
    "text": "because of of uh limit resources uh you mentioned that your scheduler could do a",
    "start": "2067320",
    "end": "2072800"
  },
  {
    "text": "precalculation to Res Reserve uh resources uh I want to ask how do you",
    "start": "2072800",
    "end": "2078760"
  },
  {
    "text": "handle the scenarios for uh spark applications with uh exor Dynamic",
    "start": "2078760",
    "end": "2084839"
  },
  {
    "text": "allocation mode yeah that's a good question so Dynamic allocation uh because of the",
    "start": "2084839",
    "end": "2091040"
  },
  {
    "text": "nature of How It's implemented uh the not all the executors are requested up front at the beginning of the execution",
    "start": "2091040",
    "end": "2097320"
  },
  {
    "text": "and number of executors may change throughout the course of execution uh",
    "start": "2097320",
    "end": "2102800"
  },
  {
    "text": "and uh yeah in that case uh gas sking is still possible but uh uh yeah you might want to uh do gas sking based on let's",
    "start": "2102800",
    "end": "2109960"
  },
  {
    "text": "say the initial or minimum executors uh in the dynamic alocation uh configuration um and uh just go with",
    "start": "2109960",
    "end": "2117280"
  },
  {
    "text": "that uh otherwise uh because the number keeps changing you have to go for uh one a single number to to start",
    "start": "2117280",
    "end": "2125320"
  },
  {
    "text": "with question uh do you do you have support for the new spark connect feature in your",
    "start": "2126200",
    "end": "2134320"
  },
  {
    "text": "operator yeah that's a good one uh the it has been brought up by the community uh in the uh in our I think monthly",
    "start": "2134320",
    "end": "2141359"
  },
  {
    "text": "community meeting uh and it's on the road map uh and uh I believe someone in the community is looking to that uh yeah",
    "start": "2141359",
    "end": "2148760"
  },
  {
    "text": "that's a great area for next major contribution actually so uh you're encouraged to join the community meeting",
    "start": "2148760",
    "end": "2155119"
  },
  {
    "text": "and uh bring up that topic wonderful thank thank you y thank you very much",
    "start": "2155119",
    "end": "2160560"
  },
  {
    "text": "thank you thank you",
    "start": "2160560",
    "end": "2164599"
  }
]
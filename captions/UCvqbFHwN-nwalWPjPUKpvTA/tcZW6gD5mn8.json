[
  {
    "start": "0",
    "end": "57000"
  },
  {
    "text": "morning everyone welcome to my session I'm Shane from eBay and today I'm gonna talk about how we're on high performance",
    "start": "30",
    "end": "6210"
  },
  {
    "text": "wore clothes at scale with kubernetes and you're gonna hear lots of best",
    "start": "6210",
    "end": "11250"
  },
  {
    "text": "practices and lessons learned for our performance and scalability",
    "start": "11250",
    "end": "16619"
  },
  {
    "text": "here's agenda first I'm gonna give a very quick intro on ebay SKU Banaras deployments after that I'm gonna walk",
    "start": "16619",
    "end": "23460"
  },
  {
    "text": "through the way we build and manage kubernetes clusters with a fleet management system based on Q&A series in",
    "start": "23460",
    "end": "29039"
  },
  {
    "text": "operators and after building these clusters I'm gonna talk about control",
    "start": "29039",
    "end": "34260"
  },
  {
    "text": "and performance how do we turn the control plan to make them you know be",
    "start": "34260",
    "end": "39329"
  },
  {
    "text": "able to run thousands of nodes with heavy workloads and and eventually I'm gonna touch base on the data and data",
    "start": "39329",
    "end": "45660"
  },
  {
    "text": "plan and user space basically how we build containers how we write the prospects and how we do performance",
    "start": "45660",
    "end": "52680"
  },
  {
    "text": "tuning at different layers to around those workloads first things first",
    "start": "52680",
    "end": "59149"
  },
  {
    "start": "57000",
    "end": "57000"
  },
  {
    "text": "eBay started Cuban area since 2015 we run an internal distribution named",
    "start": "59149",
    "end": "64290"
  },
  {
    "text": "tested IO and was in the past few years we moved lots of workloads from BAM",
    "start": "64290",
    "end": "71610"
  },
  {
    "text": "arrows and VMs into containers and as of now we have 50 plus clusters and we run",
    "start": "71610",
    "end": "78630"
  },
  {
    "text": "multiple V pcs for different environments we have those flat flat",
    "start": "78630",
    "end": "83820"
  },
  {
    "text": "netbook and overlay network based on ovn and we have multiple 2000 plus size",
    "start": "83820",
    "end": "89189"
  },
  {
    "text": "clusters was heavy workloads running on them and in total and we are growing",
    "start": "89189",
    "end": "94829"
  },
  {
    "text": "like for daily basis but I just took that like two weeks ago that we have",
    "start": "94829",
    "end": "100670"
  },
  {
    "text": "160,000 pause running on about like 24,000 hosts most of them are bare",
    "start": "100670",
    "end": "106530"
  },
  {
    "text": "metals we only run BAM bottles for production and there are so many different production will close Ronnie",
    "start": "106530",
    "end": "111869"
  },
  {
    "text": "on there they're like web front-ends databases search engines and even Hadoop so we are also running only edge we",
    "start": "111869",
    "end": "121320"
  },
  {
    "text": "pretty much runs on so many edge locations so that we can get closer to the eBay end users we are doing some",
    "start": "121320",
    "end": "128220"
  },
  {
    "text": "sort of edge proxy software load balancer on the edges and we pretty much handle",
    "start": "128220",
    "end": "133680"
  },
  {
    "text": "SSO termination from the edge and we do some caching and this is a significant",
    "start": "133680",
    "end": "140549"
  },
  {
    "text": "boost for our user experience from Europe and APEC and we are rapidly growing our footprint on the edge as",
    "start": "140549",
    "end": "146040"
  },
  {
    "text": "well so our goal is to unify a base fleet on kubernetes and we are trying",
    "start": "146040",
    "end": "151980"
  },
  {
    "text": "our best to get there as early as possible so now after getting some idea on ebay skew Banaras footprints you",
    "start": "151980",
    "end": "158609"
  },
  {
    "text": "might wonder how did we get there and the short answer is we use cube annuities itself to make it all happen",
    "start": "158609",
    "end": "164030"
  },
  {
    "text": "so as most of you know that Cuban Aries is a declarative API centric and",
    "start": "164030",
    "end": "170010"
  },
  {
    "text": "portable system it can be used to do so many different things in different ways we use it to build our private cloud",
    "start": "170010",
    "end": "176220"
  },
  {
    "text": "that runs Cuban Aries and that's our fleet management system like any other kubernetes services it runs with an iPad",
    "start": "176220",
    "end": "183180"
  },
  {
    "text": "server it we run it city on Twitter to do some sort of its city cluster management and once you have the API",
    "start": "183180",
    "end": "189209"
  },
  {
    "text": "server you pretty much will model your data center that's the most fun part so",
    "start": "189209",
    "end": "195170"
  },
  {
    "text": "we pretty much model every bits from the data center from racks to switches from subnets and even routers and we pretty",
    "start": "195170",
    "end": "202199"
  },
  {
    "text": "much models everything from the infrastructure layer and we have to pretty much model the software bits we",
    "start": "202199",
    "end": "209519"
  },
  {
    "text": "do our model for operating system we do os fees so that it's easily modeled and",
    "start": "209519",
    "end": "214620"
  },
  {
    "text": "the whole operating systems would bring this track by committee my ID and then we have a compute nodes that's a",
    "start": "214620",
    "end": "220500"
  },
  {
    "text": "provision hosts and we use salt to deploy kubernetes so we model salt master we automate the part to deploy a",
    "start": "220500",
    "end": "226889"
  },
  {
    "text": "salt master to deploy kubernetes and once you have all those models you have to write a lot of controllers to do",
    "start": "226889",
    "end": "233400"
  },
  {
    "text": "things for you so first is supervision so you pretty much create compute nodes with",
    "start": "233400",
    "end": "240659"
  },
  {
    "text": "kubernetes so we support multiple providers we do OpenStack at the very early stages because eBay used to be a",
    "start": "240659",
    "end": "246510"
  },
  {
    "text": "super big OpenStack shop and we support DCP as well but in order to scale and",
    "start": "246510",
    "end": "252750"
  },
  {
    "text": "write high-performance workloads we want to do bare models and we don't want to have all those OpenStack components we",
    "start": "252750",
    "end": "258989"
  },
  {
    "text": "used to do ironic but we see many issues with expanding especially on RabbitMQ so we decided let's use our own",
    "start": "258989",
    "end": "266130"
  },
  {
    "text": "primero provisioning was easy stuff like kickstart we use kickstart and Foreman and we write our own bare metal",
    "start": "266130",
    "end": "272220"
  },
  {
    "text": "provisioning system and that's completely based on cuban ADC RTS and it's gonna call for me an API to do",
    "start": "272220",
    "end": "278520"
  },
  {
    "text": "provisioning is completely declarative and it's also acting as a provider for",
    "start": "278520",
    "end": "284100"
  },
  {
    "text": "our fleet management system and and then you need to install a salt master we",
    "start": "284100",
    "end": "290040"
  },
  {
    "text": "pretty much can install salt master and pull a salt fee from get based on the",
    "start": "290040",
    "end": "295590"
  },
  {
    "text": "commit ID and then build a kubernetes cluster yeah of course you pretty much have to do salt minions as well because",
    "start": "295590",
    "end": "302880"
  },
  {
    "text": "you are running South High States to deploy kubernetes so we actually",
    "start": "302880",
    "end": "309330"
  },
  {
    "text": "implemented so many similar as cuban aires implementations like salt",
    "start": "309330",
    "end": "314940"
  },
  {
    "text": "deployments and node pools those are just like deployments is managing replica status and pots and we",
    "start": "314940",
    "end": "322140"
  },
  {
    "text": "actually support transactions schedulers and roaring updates we do rolling updates for OS upgrade for cuban areas",
    "start": "322140",
    "end": "329070"
  },
  {
    "text": "releases and you know some specific workflows can even plug their workflows",
    "start": "329070",
    "end": "334710"
  },
  {
    "text": "specific logic into our rolling update strategy and we do that for our search",
    "start": "334710",
    "end": "340500"
  },
  {
    "text": "engine use cases too so after introducing those concepts let's take an",
    "start": "340500",
    "end": "345870"
  },
  {
    "start": "342000",
    "end": "342000"
  },
  {
    "text": "architectural view this is a single aziz view and we normally have one fleet management system managing one ebay",
    "start": "345870",
    "end": "352110"
  },
  {
    "text": "availability zone to make itself content so this is our AZ control plan basically",
    "start": "352110",
    "end": "357810"
  },
  {
    "text": "so let's see how it works so first you have api server you have controllers basically we pack all those",
    "start": "357810",
    "end": "364740"
  },
  {
    "text": "controllers we call them test master and we have to pre create a few objects so",
    "start": "364740",
    "end": "371370"
  },
  {
    "text": "OS image i'm gonna mention that later but we use OS tree to build our own version of operating system we leverage",
    "start": "371370",
    "end": "378600"
  },
  {
    "text": "our pmos tree and project atomic and this operating system can be built from",
    "start": "378600",
    "end": "384120"
  },
  {
    "text": "spec and this operating system object in our api server contains the OS tree URL",
    "start": "384120",
    "end": "392220"
  },
  {
    "text": "the camera ID for this operating system footprint and we create something called",
    "start": "392220",
    "end": "397560"
  },
  {
    "text": "compute flavors and it will pretty much cover the the way you want to provision your",
    "start": "397560",
    "end": "403349"
  },
  {
    "text": "bare metal so for example you have three disks you want to pretty much do some LVM some software raid MDM and you can",
    "start": "403349",
    "end": "411179"
  },
  {
    "text": "all put them into specs and we are going to automatically generate the kickstart file based on that so now you have",
    "start": "411179",
    "end": "417599"
  },
  {
    "text": "predefined those models let's say we have a new rax coming into our data center so after you rock n roll you have",
    "start": "417599",
    "end": "424379"
  },
  {
    "text": "all the cabling done and you power them all right so all the assets by default gets into a pixie image that net boots",
    "start": "424379",
    "end": "431459"
  },
  {
    "text": "and cell richards yourself to ebay CMDB it pretty much populates all those rocky",
    "start": "431459",
    "end": "437759"
  },
  {
    "text": "information asset details like serial numbers and long IPS and all kinds of",
    "start": "437759",
    "end": "442829"
  },
  {
    "text": "stuff and that's when our controller we have an auto discovery controller that kicks in we call it rack controller we",
    "start": "442829",
    "end": "449819"
  },
  {
    "text": "populates everything based on the unit of rack and it pretty much create the switches the subnets the racks and even",
    "start": "449819",
    "end": "456509"
  },
  {
    "text": "the routes for the whole infrastructure layer and once you have those assets",
    "start": "456509",
    "end": "462659"
  },
  {
    "text": "sitting there ready to be consumed for our homegrown provisioning system we are",
    "start": "462659",
    "end": "468299"
  },
  {
    "text": "going to create compute nodes so compute nodes can be provisioned by different",
    "start": "468299",
    "end": "473459"
  },
  {
    "text": "providers just like any other orchestration systems so I'm just giving",
    "start": "473459",
    "end": "479249"
  },
  {
    "text": "an example of how do we do that it was our homegrown provisioning system so once you create compute node our",
    "start": "479249",
    "end": "486179"
  },
  {
    "text": "scheduler what we can asset and it's gonna create the noting foreman and we",
    "start": "486179",
    "end": "491789"
  },
  {
    "text": "are gonna automatically generate the partitioning templates for the specific node based on the partitioning table you",
    "start": "491789",
    "end": "498059"
  },
  {
    "text": "want to do and then you know it's gonna interact with Foreman and we do lots of controllers like IP location we do",
    "start": "498059",
    "end": "506089"
  },
  {
    "text": "provisioning we do DNS and you know CMDB registration all kinds of stuff and they",
    "start": "506089",
    "end": "512578"
  },
  {
    "text": "are working with orders and they are subscribed to either notations or finalizes to complete the complex flow",
    "start": "512579",
    "end": "519659"
  },
  {
    "text": "of provisioning once you have the computers provision you're gonna have you can deploy your communities clusters",
    "start": "519659",
    "end": "525749"
  },
  {
    "text": "so we use salt to the preliminaries you can just go to get we have our salt",
    "start": "525749",
    "end": "531329"
  },
  {
    "text": "state report you manage kubernetes you take a committee you put that into the salt appointment object which will pretty much create the",
    "start": "531329",
    "end": "539100"
  },
  {
    "text": "salt master for you and we are going to run salt minion on those compute nodes",
    "start": "539100",
    "end": "544320"
  },
  {
    "text": "based on their different roles some of them are masters some of them are notes and that's how we build a cuban aires",
    "start": "544320",
    "end": "551790"
  },
  {
    "text": "cluster and there's also those other controllers that we do to do scheduling transactions and rolling updates so I",
    "start": "551790",
    "end": "560130"
  },
  {
    "text": "won't go further to the implementation details but I'm gonna have a separate",
    "start": "560130",
    "end": "565380"
  },
  {
    "text": "session to deep dive into this in the upcoming Shanghai cucum but to summarize",
    "start": "565380",
    "end": "571700"
  },
  {
    "text": "this is an important piece of running our high-performance fleet because with",
    "start": "571700",
    "end": "577350"
  },
  {
    "text": "our fleet management system we model a base data center we have lots of controllers doing different things and we pretty much have every bit in get",
    "start": "577350",
    "end": "585060"
  },
  {
    "text": "what is this mean is that so if you from from the ground up so you have operating",
    "start": "585060",
    "end": "590070"
  },
  {
    "text": "system we built it with OS 3 and we have it modeled in a PS server with CRTs and",
    "start": "590070",
    "end": "597300"
  },
  {
    "text": "we use salt to manage host config as well as during kubernetes so the salt",
    "start": "597300",
    "end": "603240"
  },
  {
    "text": "isn't it and you can get a commit ID imbued a cluster and and moving forward",
    "start": "603240",
    "end": "609360"
  },
  {
    "text": "you have like fleet so which does provisioning setting up cluster lifecycle management remediation and",
    "start": "609360",
    "end": "615210"
  },
  {
    "text": "those are all CR DS that you check in to get so which makes us think of like get",
    "start": "615210",
    "end": "620370"
  },
  {
    "text": "ops which is like a natural choice for us and and then you're gonna have some sort of PR driven operations and",
    "start": "620370",
    "end": "626910"
  },
  {
    "text": "everything to be decorative this is the beauty of this whole system and that's what empower us to viewed consistent",
    "start": "626910",
    "end": "635130"
  },
  {
    "text": "kubernetes clusters across award and having the capability to really scale",
    "start": "635130",
    "end": "641130"
  },
  {
    "text": "our clusters for high performance workload ok now we have lots of clusters",
    "start": "641130",
    "end": "647130"
  },
  {
    "start": "644000",
    "end": "644000"
  },
  {
    "text": "built out there but how do they perform so let's take a quick look at the eBay's",
    "start": "647130",
    "end": "653820"
  },
  {
    "text": "cuban aries control plan config we run five masters active active and they are",
    "start": "653820",
    "end": "658950"
  },
  {
    "text": "making one each CD cluster and each node is running API server talking to its",
    "start": "658950",
    "end": "664709"
  },
  {
    "text": "local it city we of course controller manager scheduler running on the same note and we're",
    "start": "664709",
    "end": "669949"
  },
  {
    "text": "running a Dom manager and all of those control plan bits are managed by salt",
    "start": "669949",
    "end": "675139"
  },
  {
    "text": "because they are static pots and for the notes we're running Cuba in queue proxy with a lot of demons as managing like",
    "start": "675139",
    "end": "681860"
  },
  {
    "text": "storage networking and monitoring and this all worked fine but what if you are",
    "start": "681860",
    "end": "688759"
  },
  {
    "text": "running like thousands of nodes of a hundred thousand pots you see issues right so the typical issues you are",
    "start": "688759",
    "end": "695749"
  },
  {
    "text": "seeing is heavy lessening and watching and it maps to different layers and most critical part is is city and API server",
    "start": "695749",
    "end": "702559"
  },
  {
    "text": "so you're gonna see a lot of high memory usage from the HDD you have very",
    "start": "702559",
    "end": "707839"
  },
  {
    "text": "frequent leader election changes and you are gonna have very slow scheduling as",
    "start": "707839",
    "end": "713119"
  },
  {
    "text": "well as delayed controller sync and of course API server also is gonna suffer",
    "start": "713119",
    "end": "718129"
  },
  {
    "text": "and it's going to have like frequent restarts and crashes so how do we do",
    "start": "718129",
    "end": "723439"
  },
  {
    "start": "723000",
    "end": "723000"
  },
  {
    "text": "performance turning for this most of the work here is done by one of our team members her name is England and the idea",
    "start": "723439",
    "end": "729470"
  },
  {
    "text": "is to use cube mark to get to know the clusters limit you really need to know your limit right so cube mark is a tool",
    "start": "729470",
    "end": "736399"
  },
  {
    "text": "is an upstream to that simulates like thousands of nodes and it might not be",
    "start": "736399",
    "end": "742819"
  },
  {
    "text": "able to run your pots but you can really test your performance of the control plan and then you our test case is",
    "start": "742819",
    "end": "749449"
  },
  {
    "text": "simple we're gonna create and delete like 10,000 pots at the same time and see how it performs and this is pretty",
    "start": "749449",
    "end": "756949"
  },
  {
    "text": "much how what we get so I'm gonna talk about it from two different layers first",
    "start": "756949",
    "end": "762410"
  },
  {
    "text": "is a server side so API server and HCD are the most critical part so first",
    "start": "762410",
    "end": "768439"
  },
  {
    "text": "things that we found is that you need to evenly distribute the load to the five master notes that I've been talking",
    "start": "768439",
    "end": "775279"
  },
  {
    "text": "about right so one issue we found specifically interesting is that some of our heavy controllers for example",
    "start": "775279",
    "end": "782029"
  },
  {
    "text": "provisioning controllers from test master it creates one clanked and it has",
    "start": "782029",
    "end": "787490"
  },
  {
    "text": "a session stickiness to one api server and this kind of controller if it always",
    "start": "787490",
    "end": "792589"
  },
  {
    "text": "like DDoS the api server you're pretty much lost of one api server and you have a flat peon control plan so you can",
    "start": "792589",
    "end": "799970"
  },
  {
    "text": "solve that from two different layers first is that you do some sort of load balancing from the API server but this wouldn't solve our",
    "start": "799970",
    "end": "806060"
  },
  {
    "text": "issues that that I just mentioned you also need to enhance your clients so that they can do some sort of auto",
    "start": "806060",
    "end": "812089"
  },
  {
    "text": "balancing form itself so that it can do like multiple clients and then it can be smart about talking to API servers I'm",
    "start": "812089",
    "end": "818029"
  },
  {
    "text": "gonna mention more about it later but next its its city so our practices",
    "start": "818029",
    "end": "825170"
  },
  {
    "text": "that always have dedicated SSDs for HDD so that you have guaranteed I ops I think this is rather obvious but the",
    "start": "825170",
    "end": "832790"
  },
  {
    "text": "other one is sometimes you want to split the city some of the folks yesterday also mention like if ingress can service",
    "start": "832790",
    "end": "839389"
  },
  {
    "text": "controller is underperforming you can split that specific piece for in service",
    "start": "839389",
    "end": "844699"
  },
  {
    "text": "controller but for us we we sometimes we need to split the events outsides of the",
    "start": "844699",
    "end": "850550"
  },
  {
    "text": "man its city and we sometimes do like a separate disk for its city snapshots",
    "start": "850550",
    "end": "855949"
  },
  {
    "text": "because snapshot is also heavy we wants to do backup our HDD backup happens I think every half an hour so we always",
    "start": "855949",
    "end": "863000"
  },
  {
    "text": "are you know very concerned about losing data and the snapshotting also has some",
    "start": "863000",
    "end": "868639"
  },
  {
    "text": "impact so you always want to be careful about a city and the next one is there",
    "start": "868639",
    "end": "874790"
  },
  {
    "text": "just a few configs that most of the folks working with api server well will",
    "start": "874790",
    "end": "879980"
  },
  {
    "text": "change that so pretty much you want to uh pre your limits and you putting the",
    "start": "879980",
    "end": "885019"
  },
  {
    "text": "max requesting flights or max mutating requesting flight and then you always",
    "start": "885019",
    "end": "890689"
  },
  {
    "text": "want to do some sort of really limiting so you pretty much don't know like some controllers is doing some super nasty",
    "start": "890689",
    "end": "896899"
  },
  {
    "text": "stuff and some people are doing like tens of thousands of deployments and and you you pretty much don't want them to",
    "start": "896899",
    "end": "902750"
  },
  {
    "text": "DDoS your API server and that's pretty much the server sites attorney and from",
    "start": "902750",
    "end": "909079"
  },
  {
    "text": "the client side it's always about writing good controllers first example is about the list options and resource",
    "start": "909079",
    "end": "915920"
  },
  {
    "text": "versions so so many of you might know that if you put the resource version equals to zero it gets the API servers",
    "start": "915920",
    "end": "922550"
  },
  {
    "text": "cache but if you put that into Neal it goes into the HDD so we always want to",
    "start": "922550",
    "end": "927980"
  },
  {
    "text": "pretty much avoid directly hitting it city for some some of the cases really",
    "start": "927980",
    "end": "933110"
  },
  {
    "text": "need to do that like for example controller restarts you want to reconcile and do stuff like that you don't want to be",
    "start": "933110",
    "end": "939230"
  },
  {
    "text": "behind but when you are actively running always avoid that and use as many",
    "start": "939230",
    "end": "945800"
  },
  {
    "text": "informers as possible this is also like a pretty common you know performance",
    "start": "945800",
    "end": "952030"
  },
  {
    "text": "concerned about writing controllers when you are able to do informers don't do",
    "start": "952030",
    "end": "959510"
  },
  {
    "text": "listings and we actually when we are building our complex fleet management",
    "start": "959510",
    "end": "964730"
  },
  {
    "text": "system we have actually so complex objects and we have a lot of you know",
    "start": "964730",
    "end": "971240"
  },
  {
    "text": "API calls and interactions with the API server so we build some sort of metrics",
    "start": "971240",
    "end": "977660"
  },
  {
    "text": "collecting function very simple before you make the API call and after you make it makes the API call you collect the",
    "start": "977660",
    "end": "983420"
  },
  {
    "text": "time you spend for each API call you are going against the API server and of course you have namespaces and the type",
    "start": "983420",
    "end": "990260"
  },
  {
    "text": "of API calls you are getting like get listening so you get an idea of how your",
    "start": "990260",
    "end": "995900"
  },
  {
    "text": "controller is doing and how they are performing so that's very important for you to measure the performance and",
    "start": "995900",
    "end": "1002320"
  },
  {
    "text": "enhance your performance so the last part I am just quickly goes through",
    "start": "1002320",
    "end": "1007480"
  },
  {
    "text": "because that's already fixed in the upstream so sometimes you have some sort of leftover parts so they are doing",
    "start": "1007480",
    "end": "1013960"
  },
  {
    "text": "they're in terminating some of the hardware failed and in the earlier versions of Cuban Ares scheduler is",
    "start": "1013960",
    "end": "1020260"
  },
  {
    "text": "using mutex instead of RW mutex so it's one part can slow down your whole",
    "start": "1020260",
    "end": "1025390"
  },
  {
    "text": "cluster but that's fixed later as I mentioned so basically we you always",
    "start": "1025390",
    "end": "1031240"
  },
  {
    "text": "need to manage your lifecycle of the cluster so our fleet management also",
    "start": "1031240",
    "end": "1036370"
  },
  {
    "text": "does that it does remediation interacting with our brick fixed system",
    "start": "1036370",
    "end": "1041530"
  },
  {
    "text": "we can take down the bad nose send them into break fix cling up from the",
    "start": "1041530",
    "end": "1047290"
  },
  {
    "text": "kubernetes clusters and then remember we have this node poo and deployment concept and we are going to replace with",
    "start": "1047290",
    "end": "1053830"
  },
  {
    "text": "a spare asset and match it as it is and add it back into the cluster to complete",
    "start": "1053830",
    "end": "1060100"
  },
  {
    "text": "the story of remediation so now we are moving to the data plan because we are",
    "start": "1060100",
    "end": "1065410"
  },
  {
    "text": "mostly done with a control plan so we're gonna talk about how we run those high-performance will close some",
    "start": "1065410",
    "end": "1072100"
  },
  {
    "text": "of our best practices so first thing is you're gonna build containers for them so some obvious principle is that you",
    "start": "1072100",
    "end": "1080080"
  },
  {
    "start": "1073000",
    "end": "1073000"
  },
  {
    "text": "always try to do the containers as a native container but sometimes somewhat",
    "start": "1080080",
    "end": "1085600"
  },
  {
    "text": "close doesn't like it so we have a lot of heavy workloads they still want to run some init system this is like a",
    "start": "1085600",
    "end": "1093039"
  },
  {
    "text": "classic PID discussion that has been going on for a while so can you run",
    "start": "1093039",
    "end": "1098289"
  },
  {
    "text": "system D the answer is yes but it's a little bit too much in order to run system D inside a container for your pit",
    "start": "1098289",
    "end": "1106090"
  },
  {
    "text": "one you need to do some cleanup from your container you need to amount um I think a C group FS as read-only and then",
    "start": "1106090",
    "end": "1113950"
  },
  {
    "text": "you need to make some temp FS we do that with empty door and okay now you have it",
    "start": "1113950",
    "end": "1119890"
  },
  {
    "text": "running but is it that's it no it's actually we see lots of other issues like somebody actually captures some",
    "start": "1119890",
    "end": "1127390"
  },
  {
    "text": "darker image from a Hadoop server and they think they can just write like but",
    "start": "1127390",
    "end": "1132730"
  },
  {
    "text": "later we found out because this is a heavy high-priority project we give them all the permissions we can get and then",
    "start": "1132730",
    "end": "1138820"
  },
  {
    "text": "you know they pretty much limit the system configs and I'm gonna talk about",
    "start": "1138820",
    "end": "1145510"
  },
  {
    "text": "that later but for this specific case CentOS 7 has a system D that has hard core at 65 K you limit so any like",
    "start": "1145510",
    "end": "1152980"
  },
  {
    "text": "Hadoop jobs as containers spin off they cannot reach the 100 K limit they want so we have to pretty much patch it and",
    "start": "1152980",
    "end": "1159429"
  },
  {
    "text": "compile a new system D and put on to that all they have to upgrade that container image the actually alternative",
    "start": "1159429",
    "end": "1166360"
  },
  {
    "text": "is to use some smaller in a system like supervisor D or you are your own init system but with the new features coming",
    "start": "1166360",
    "end": "1172510"
  },
  {
    "text": "up there is a share pit namespace and which allows you to manage those processes and you have your post",
    "start": "1172510",
    "end": "1178480"
  },
  {
    "text": "container acting as a pit one so maybe you don't even need init system later the next one is you have to be super",
    "start": "1178480",
    "end": "1186039"
  },
  {
    "text": "careful about the capabilities you give so it's a security thing but it's also",
    "start": "1186039",
    "end": "1192360"
  },
  {
    "text": "performance thing because the same container I just mentioned it imagine",
    "start": "1192360",
    "end": "1198100"
  },
  {
    "text": "that it took from a bare marrow host it turn D and it has all those capabilities",
    "start": "1198100",
    "end": "1204340"
  },
  {
    "text": "that you give and it completely mess up your hosts and it's so hard to",
    "start": "1204340",
    "end": "1210460"
  },
  {
    "text": "troubleshoot because from the host you don't actually see anything and then the",
    "start": "1210460",
    "end": "1216100"
  },
  {
    "text": "last one I want to mention is the containers resource limit awareness so for some of the legacy systems they want",
    "start": "1216100",
    "end": "1222610"
  },
  {
    "text": "to do a lot of things from the containers they do opt on top check the memory and see things around to run some",
    "start": "1222610",
    "end": "1229240"
  },
  {
    "text": "jobs some scripts but most of you know that from containers you see most of the",
    "start": "1229240",
    "end": "1234370"
  },
  {
    "text": "things from the host well of course you can pass a lot of information to the containers by download AP is by EMV s",
    "start": "1234370",
    "end": "1241150"
  },
  {
    "text": "but there's some solution that Kinetico has they use it to manage our X DS it's",
    "start": "1241150",
    "end": "1246520"
  },
  {
    "text": "called Erik CFS it actually do a custom proc file system that overrides a few",
    "start": "1246520",
    "end": "1253390"
  },
  {
    "text": "things like app time memory and CPU but only does CPU set well it's quite",
    "start": "1253390",
    "end": "1258490"
  },
  {
    "text": "obvious CPU share is hard to like simulate and custom into the containers",
    "start": "1258490",
    "end": "1263710"
  },
  {
    "text": "and then the next one is writing good prospects we actually use a lot of",
    "start": "1263710",
    "end": "1270250"
  },
  {
    "start": "1264000",
    "end": "1264000"
  },
  {
    "text": "download api's pod presets basically a lot of capabilities of cuban aries to",
    "start": "1270250",
    "end": "1275380"
  },
  {
    "text": "make it you know easy and make them make all those paths good cuban eighties",
    "start": "1275380",
    "end": "1281170"
  },
  {
    "text": "citizens and there are lots of interesting features of cuban aids where you can do to match whatever you run",
    "start": "1281170",
    "end": "1287860"
  },
  {
    "text": "with OpenStack or VM work for example like over-commitment everybody wants to",
    "start": "1287860",
    "end": "1293800"
  },
  {
    "text": "do over commitment from vm work but in containers you pretty much has a better",
    "start": "1293800",
    "end": "1299620"
  },
  {
    "text": "way so you can manage the over commitment ratio by yourself by declare",
    "start": "1299620",
    "end": "1304780"
  },
  {
    "text": "your birth small pots like you put on like a request and limit based on a ratio and then you can tolerate the",
    "start": "1304780",
    "end": "1311020"
  },
  {
    "text": "hosts over commitment by yourself you make the call and then there's a lot you run a lot of props so written is prop",
    "start": "1311020",
    "end": "1319120"
  },
  {
    "text": "and liveness prop is a super powerful tool for example rhiness prop the",
    "start": "1319120",
    "end": "1324190"
  },
  {
    "text": "typical use cases to enable/disable web traffic and liveness prop you can use on",
    "start": "1324190",
    "end": "1329650"
  },
  {
    "text": "trick to do some self triggered restarts and I just want to quickly go through them",
    "start": "1329650",
    "end": "1335740"
  },
  {
    "text": "but I want I do want to mention some performance bits of the pass back one thing is for stateless applications many",
    "start": "1335740",
    "end": "1342880"
  },
  {
    "text": "of our city's applications they want some sort of a thermo drives and it seems that's the only option right now",
    "start": "1342880",
    "end": "1350020"
  },
  {
    "text": "is to use MTR backed by hard drives well it's not a perfect one because you're",
    "start": "1350020",
    "end": "1355450"
  },
  {
    "text": "gonna see lots of issues like applications just dump their data into MDR they don't really care and then you",
    "start": "1355450",
    "end": "1362230"
  },
  {
    "text": "ended up adding size limits into the empty doors but so as to evict them once",
    "start": "1362230",
    "end": "1367930"
  },
  {
    "text": "they are reaching their limits right but the implementation is cubelet is gonna",
    "start": "1367930",
    "end": "1373720"
  },
  {
    "text": "do some sort of D you against that folder like every 20 seconds and when you have lots of them you can I have",
    "start": "1373720",
    "end": "1379990"
  },
  {
    "text": "some performance overhead so for that we are actively looking at the upstream CSI",
    "start": "1379990",
    "end": "1385270"
  },
  {
    "text": "inline volume support not just for the kind of a formal support but also we want to unify our flavors to run you",
    "start": "1385270",
    "end": "1393130"
  },
  {
    "text": "know the local storage specifically we if you look at and compare stateless",
    "start": "1393130",
    "end": "1399460"
  },
  {
    "text": "applications versus versus stateful applications we actually have stateful says running with high performance local",
    "start": "1399460",
    "end": "1406450"
  },
  {
    "text": "volumes if both of them can be backed by the same you know i/o vm BG it's much",
    "start": "1406450",
    "end": "1412900"
  },
  {
    "text": "easier for us to manage okay now we have built up ads we need to run them at the",
    "start": "1412900",
    "end": "1418930"
  },
  {
    "start": "1414000",
    "end": "1414000"
  },
  {
    "text": "hosts runtime so host runtime performance most of the bits are from the kernel we can spend another day",
    "start": "1418930",
    "end": "1425230"
  },
  {
    "text": "talking about the kernel but basically a few basics we want to make sure that our",
    "start": "1425230",
    "end": "1431200"
  },
  {
    "text": "we share so first is that you want to unify the platform and manage as less kernels as possible why is that you have",
    "start": "1431200",
    "end": "1438190"
  },
  {
    "text": "lots of drivers to certify you have you know if you're managing so many different kernels and I for example eBay",
    "start": "1438190",
    "end": "1443860"
  },
  {
    "text": "is managing ODM custom hardware's we have lots of like GPU use case many",
    "start": "1443860",
    "end": "1449230"
  },
  {
    "text": "adding kernels adding a lot of maintenance cost and now let's say you",
    "start": "1449230",
    "end": "1454510"
  },
  {
    "text": "decide on running one kernel you're trying to run the latest so the upcoming 4:19 kernel seems to be very interesting",
    "start": "1454510",
    "end": "1462310"
  },
  {
    "text": "it brought in a patch for a network packet patching and that should improve network through",
    "start": "1462310",
    "end": "1467750"
  },
  {
    "text": "by like over 30% so we are also looking at it so the next one for host on time",
    "start": "1467750",
    "end": "1472790"
  },
  {
    "text": "turning is about CPU and power so we always want to push your server to the limit when it runs high performance will",
    "start": "1472790",
    "end": "1479630"
  },
  {
    "text": "close so we want to make sure that it running on the performance mode instead of power saving mode so you pretty much",
    "start": "1479630",
    "end": "1486620"
  },
  {
    "text": "flipped like P State and you always want to make sure that there's many odd not",
    "start": "1486620",
    "end": "1492050"
  },
  {
    "text": "any other services of the system like canonical has like own the amount that's",
    "start": "1492050",
    "end": "1497120"
  },
  {
    "text": "reverting your changes and we found it interesting that there's a maxi state we",
    "start": "1497120",
    "end": "1503270"
  },
  {
    "text": "always wanted to set it as zero but it's not absolutely true that zero gets you",
    "start": "1503270",
    "end": "1509090"
  },
  {
    "text": "more performance because you always think about some use cases that's super heavy and then they need to use a lot of",
    "start": "1509090",
    "end": "1515360"
  },
  {
    "text": "turbo from the CPU so basically what we found is that setting it to zero is",
    "start": "1515360",
    "end": "1520640"
  },
  {
    "text": "actually way less comfy performing as sitting into the default nine for maxi",
    "start": "1520640",
    "end": "1525680"
  },
  {
    "text": "state when it comes to the turbo use case and then the memory there's a like",
    "start": "1525680",
    "end": "1530870"
  },
  {
    "text": "very common ones about THP like many of the database folks will warn you that HP",
    "start": "1530870",
    "end": "1537470"
  },
  {
    "text": "is gonna buggy but what we found is we actually get a lot of benefits from THP especially for our search engine use",
    "start": "1537470",
    "end": "1543830"
  },
  {
    "text": "cases so it's pretty much like walk low specific you always have to identify by",
    "start": "1543830",
    "end": "1549380"
  },
  {
    "text": "ourself and I do want to mention about the swap because you know swap is one",
    "start": "1549380",
    "end": "1556070"
  },
  {
    "text": "feature that we want to avoid for Cuban Ares one lesson learn is that we have a small noisy daemon set that actually had",
    "start": "1556070",
    "end": "1563810"
  },
  {
    "text": "runs on a box that has swept and it has some sort of memory leak and once it reached to over 60% it actually wakes up",
    "start": "1563810",
    "end": "1571700"
  },
  {
    "text": "the swap and then case web de slows down the whole host so what we ended up doing is so you're gonna we ended up you know",
    "start": "1571700",
    "end": "1579110"
  },
  {
    "text": "overriding memories wepner's and d for it to zero for everything unless you put a specific connotation so try to avoid",
    "start": "1579110",
    "end": "1586150"
  },
  {
    "text": "swap because it kind of mess up with c group and of course we're gonna talk",
    "start": "1586150",
    "end": "1592070"
  },
  {
    "text": "about like io scheduler cfq or dead lying and I won't go further into that but one",
    "start": "1592070",
    "end": "1597970"
  },
  {
    "text": "thing we found is that we default to cfq because we found some issues with deadlines when we are doing it city",
    "start": "1597970",
    "end": "1603220"
  },
  {
    "text": "backups but it's basically your choice I do want to talk about our storage classes because we have many layers for",
    "start": "1603220",
    "end": "1610239"
  },
  {
    "text": "storage class we have hot tears and standard tears we pretty much runs local",
    "start": "1610239",
    "end": "1617019"
  },
  {
    "text": "volumes for most of the high-performing ones and we run our own version now but we are trying to switch to the upstream",
    "start": "1617019",
    "end": "1624460"
  },
  {
    "text": "dynamically local volume solutions from CSI and we run stand around cinders so",
    "start": "1624460",
    "end": "1629769"
  },
  {
    "text": "that we can get the set volume money to bare metal without going through the hypervisors and viens stuff Nova from",
    "start": "1629769",
    "end": "1636879"
  },
  {
    "text": "you know OpenStack and there are lots of system configs I just want to highlight",
    "start": "1636879",
    "end": "1642009"
  },
  {
    "text": "two one is unique you want to limit your stuff like you there are lots of heavy",
    "start": "1642009",
    "end": "1647259"
  },
  {
    "text": "workloads you want to limit the kind of resource they are taking so that the hosts sit down don't get bumped up and then you want to increase a few things",
    "start": "1647259",
    "end": "1654519"
  },
  {
    "text": "for example max map count for elastic search so you always have to find a",
    "start": "1654519",
    "end": "1660070"
  },
  {
    "text": "balance between some workloads that's overusing some others are or not but",
    "start": "1660070",
    "end": "1665710"
  },
  {
    "text": "some of the things we are trying to do is first is the CPU set and Numa so this is a feature we want to do and then",
    "start": "1665710",
    "end": "1672909"
  },
  {
    "text": "block IO C group obviously we want to do some better resource management and isolations and OS query as well as we",
    "start": "1672909",
    "end": "1681100"
  },
  {
    "text": "are doing some software-defined storage ok last part is networking performance",
    "start": "1681100",
    "end": "1687809"
  },
  {
    "start": "1684000",
    "end": "1684000"
  },
  {
    "text": "I'm not too much of a networking guy so I don't have too much details here but",
    "start": "1687809",
    "end": "1694090"
  },
  {
    "text": "luckily we don't have too much time left either so we do RPS and RFS we set that",
    "start": "1694090",
    "end": "1702460"
  },
  {
    "text": "into the vs devices and this is super helpful which gets us to the similar as",
    "start": "1702460",
    "end": "1708309"
  },
  {
    "text": "BAM arrow through boots we do IP VLAN for high performance work clothes for standard ones we use obvious and obvious",
    "start": "1708309",
    "end": "1715080"
  },
  {
    "text": "but some search engine will close we run IPV line and we of course we are",
    "start": "1715080",
    "end": "1721480"
  },
  {
    "text": "trying to kill proxy with IP vs mode and there's a PBR that we are using for",
    "start": "1721480",
    "end": "1727240"
  },
  {
    "text": "search engines and like our edge computing so bbr is good",
    "start": "1727240",
    "end": "1733570"
  },
  {
    "text": "for consistent rates so consider if you have such kind of use case and then the",
    "start": "1733570",
    "end": "1739570"
  },
  {
    "text": "last one is the TC if you can fix how we do some like traffic controls fq cuddles and tcp slow-start",
    "start": "1739570",
    "end": "1745809"
  },
  {
    "text": "so i won't go further into that because we don't have enough time left but we do want to do IP VLAN and eb PF and we are",
    "start": "1745809",
    "end": "1754179"
  },
  {
    "text": "actively thinking about the solutions to network us the last part is sometimes",
    "start": "1754179",
    "end": "1760299"
  },
  {
    "start": "1758000",
    "end": "1758000"
  },
  {
    "text": "you want to isolate your workloads you see so many different configs there is",
    "start": "1760299",
    "end": "1765730"
  },
  {
    "text": "mentioned you profile them and you want to isolate them so how do you do that so",
    "start": "1765730",
    "end": "1771809"
  },
  {
    "text": "stopping one workload to step into each other you pretty much can do like no schedule you do is tense and toleration",
    "start": "1771809",
    "end": "1778990"
  },
  {
    "text": "but there is no schedule and no execution so what we found is that no execution is actually too aggressive",
    "start": "1778990",
    "end": "1785590"
  },
  {
    "text": "it actually evict some of the no selecting parts which we actively use for like volume recycle so you don't",
    "start": "1785590",
    "end": "1792159"
  },
  {
    "text": "want you go with no execute we do know it no schedule and you always want to",
    "start": "1792159",
    "end": "1797679"
  },
  {
    "text": "monitor your performance there's a lots of tools I listed here and there you need to do a loss of benchmarking and",
    "start": "1797679",
    "end": "1804309"
  },
  {
    "text": "burning tests and more importantly if you can automate that part we actually are actively working on integrating all",
    "start": "1804309",
    "end": "1810909"
  },
  {
    "text": "those performance bits for specific use cases into our OS image CI CD as well as our certification flow for new hardware",
    "start": "1810909",
    "end": "1817860"
  },
  {
    "text": "so that's pretty much it lots of contents I might have run a little bit",
    "start": "1817860",
    "end": "1824289"
  },
  {
    "text": "to rush for some of the stuff if you miss anything you can find the slides",
    "start": "1824289",
    "end": "1829450"
  },
  {
    "text": "online I'm not sure how much time we have for Q&A but time is yours thank you",
    "start": "1829450",
    "end": "1836080"
  },
  {
    "text": "[Applause]",
    "start": "1836080",
    "end": "1840460"
  },
  {
    "text": "yeah we have like three minutes we only have one microphone so if anyone does have a question shout it out or I can",
    "start": "1842280",
    "end": "1849429"
  },
  {
    "text": "run to you and then run back the one",
    "start": "1849429",
    "end": "1855280"
  },
  {
    "text": "right at the back you want to try shouting",
    "start": "1855280",
    "end": "1858809"
  },
  {
    "text": "where's the where's the where's the question there hey a really cool",
    "start": "1867630",
    "end": "1880440"
  },
  {
    "text": "presentation I want to ask like how do you manage your to upgrade your kubernetes clusters and how that does",
    "start": "1880440",
    "end": "1886350"
  },
  {
    "text": "interfere with the applications that you have installed on kubernetes",
    "start": "1886350",
    "end": "1891260"
  },
  {
    "text": "[Laughter] you're gonna have to ask him in the",
    "start": "1903550",
    "end": "1909789"
  },
  {
    "text": "hallway because he didn't hear the question I I think we're out of time now thank you very much yeah if you can find",
    "start": "1909789",
    "end": "1918159"
  },
  {
    "text": "me from the hallway for any questions",
    "start": "1918159",
    "end": "1921509"
  }
]
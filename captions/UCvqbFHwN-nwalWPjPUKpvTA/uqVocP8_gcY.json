[
  {
    "text": "all right uh hey everyone welcome to the",
    "start": "120",
    "end": "2399"
  },
  {
    "text": "learning session here I'm today I'm",
    "start": "2399",
    "end": "4560"
  },
  {
    "text": "going to share how we use decentralized",
    "start": "4560",
    "end": "7080"
  },
  {
    "text": "file system to optimize your ML",
    "start": "7080",
    "end": "9719"
  },
  {
    "text": "workloads on",
    "start": "9719",
    "end": "11000"
  },
  {
    "text": "communties so my name is Sean I'm a",
    "start": "11000",
    "end": "13200"
  },
  {
    "text": "software engineer from",
    "start": "13200",
    "end": "15119"
  },
  {
    "text": "luxu so first we're going to talk about",
    "start": "15119",
    "end": "17840"
  },
  {
    "text": "the benefits that uh the file system",
    "start": "17840",
    "end": "20640"
  },
  {
    "text": "brings and what is the current solution",
    "start": "20640",
    "end": "23880"
  },
  {
    "text": "we have and a new design that we came up",
    "start": "23880",
    "end": "26039"
  },
  {
    "text": "with and it's implementation and finally",
    "start": "26039",
    "end": "29519"
  },
  {
    "text": "some Ben mark on the new",
    "start": "29519",
    "end": "32439"
  },
  {
    "text": "implementation so first the the most",
    "start": "32440",
    "end": "35960"
  },
  {
    "text": "important advantage that this file",
    "start": "35960",
    "end": "38440"
  },
  {
    "text": "system brings is the data",
    "start": "38440",
    "end": "40520"
  },
  {
    "text": "locality and there are two main benefits",
    "start": "40520",
    "end": "46039"
  },
  {
    "text": "brings the first is performance gain by",
    "start": "46039",
    "end": "48800"
  },
  {
    "text": "bringing your data from remote storage",
    "start": "48800",
    "end": "51800"
  },
  {
    "text": "to your Computing node you have faster",
    "start": "51800",
    "end": "54399"
  },
  {
    "text": "access to your data compared to remote",
    "start": "54399",
    "end": "56039"
  },
  {
    "text": "storage like S3 or AER therefore less",
    "start": "56039",
    "end": "60199"
  },
  {
    "text": "time will be spent on your data",
    "start": "60199",
    "end": "62000"
  },
  {
    "text": "intensive",
    "start": "62000",
    "end": "63600"
  },
  {
    "text": "applications it is it is also very",
    "start": "63600",
    "end": "66280"
  },
  {
    "text": "cost-saving because few API cost will be",
    "start": "66280",
    "end": "69000"
  },
  {
    "text": "made to the cloud storage both data and",
    "start": "69000",
    "end": "72360"
  },
  {
    "text": "metadata plus because because of the",
    "start": "72360",
    "end": "75119"
  },
  {
    "text": "performance gain you have a higher",
    "start": "75119",
    "end": "77439"
  },
  {
    "text": "utilization of your GPU resulting in",
    "start": "77439",
    "end": "80119"
  },
  {
    "text": "less GPU time faster training and uh",
    "start": "80119",
    "end": "84600"
  },
  {
    "text": "that's we we all know GPU cost a lot of",
    "start": "84600",
    "end": "88840"
  },
  {
    "text": "Fortune now the the existing solution we",
    "start": "88840",
    "end": "91960"
  },
  {
    "text": "have which is our alio",
    "start": "91960",
    "end": "94680"
  },
  {
    "text": "2.x we follow a traditional distributed",
    "start": "94680",
    "end": "97880"
  },
  {
    "text": "system where there's centralized master",
    "start": "97880",
    "end": "100880"
  },
  {
    "text": "or Masters because we want High",
    "start": "100880",
    "end": "103600"
  },
  {
    "text": "availability so there will be a all",
    "start": "103600",
    "end": "107119"
  },
  {
    "text": "number of Master",
    "start": "107119",
    "end": "108840"
  },
  {
    "text": "nodes",
    "start": "108840",
    "end": "110880"
  },
  {
    "text": "and but the high availability is just",
    "start": "110880",
    "end": "115520"
  },
  {
    "text": "theoretically because we all know no no",
    "start": "115520",
    "end": "119079"
  },
  {
    "text": "Inc will get maintenance and there will",
    "start": "119079",
    "end": "121680"
  },
  {
    "text": "be fail overs on the moners during those",
    "start": "121680",
    "end": "125759"
  },
  {
    "text": "times the system is still now serving",
    "start": "125759",
    "end": "129360"
  },
  {
    "text": "data so here Masters are single point of",
    "start": "129360",
    "end": "133840"
  },
  {
    "text": "failure and also because the data now is",
    "start": "133840",
    "end": "137920"
  },
  {
    "text": "there there's tons of data out",
    "start": "137920",
    "end": "140560"
  },
  {
    "text": "there it's pretty typical to see a",
    "start": "140560",
    "end": "143319"
  },
  {
    "text": "training needs billions of files so that",
    "start": "143319",
    "end": "147080"
  },
  {
    "text": "number of files makes the master the",
    "start": "147080",
    "end": "148840"
  },
  {
    "text": "botton neck of overall performance",
    "start": "148840",
    "end": "151440"
  },
  {
    "text": "because of the the lot lot of metadata",
    "start": "151440",
    "end": "154360"
  },
  {
    "text": "operations so we really need a system",
    "start": "154360",
    "end": "157480"
  },
  {
    "text": "that can have a that that has a better",
    "start": "157480",
    "end": "160280"
  },
  {
    "text": "Rel reliability availability and",
    "start": "160280",
    "end": "164200"
  },
  {
    "text": "scalability which is why we came up with",
    "start": "164200",
    "end": "167159"
  },
  {
    "text": "this",
    "start": "167159",
    "end": "168440"
  },
  {
    "text": "decentralized file system using",
    "start": "168440",
    "end": "170879"
  },
  {
    "text": "consistent hashing for caching so here",
    "start": "170879",
    "end": "173959"
  },
  {
    "text": "we completely removed the master nodes",
    "start": "173959",
    "end": "177519"
  },
  {
    "text": "and instead instead of using Master to",
    "start": "177519",
    "end": "180599"
  },
  {
    "text": "determine where the cach goes we use",
    "start": "180599",
    "end": "183519"
  },
  {
    "text": "consistent hashing on the client side to",
    "start": "183519",
    "end": "186000"
  },
  {
    "text": "decide where the data and and metadata",
    "start": "186000",
    "end": "188640"
  },
  {
    "text": "goes on which worker so now because of",
    "start": "188640",
    "end": "191959"
  },
  {
    "text": "we because of the musters are removed",
    "start": "191959",
    "end": "195879"
  },
  {
    "text": "now there's no single point of failure",
    "start": "195879",
    "end": "198599"
  },
  {
    "text": "and no more performance botton that",
    "start": "198599",
    "end": "199959"
  },
  {
    "text": "going to master and here if there's any",
    "start": "199959",
    "end": "203360"
  },
  {
    "text": "worker for any reason it's down the",
    "start": "203360",
    "end": "205680"
  },
  {
    "text": "client will directly talk to your Source",
    "start": "205680",
    "end": "209200"
  },
  {
    "text": "data source",
    "start": "209200",
    "end": "211680"
  },
  {
    "text": "so in Alex 23 uh in Al 3xx we implement",
    "start": "214720",
    "end": "220120"
  },
  {
    "text": "this consistent hashing algorithm for",
    "start": "220120",
    "end": "222080"
  },
  {
    "text": "caching data so now we have a much",
    "start": "222080",
    "end": "224480"
  },
  {
    "text": "higher scalability one one worker is",
    "start": "224480",
    "end": "227400"
  },
  {
    "text": "able to support 30 to 50 million files",
    "start": "227400",
    "end": "231280"
  },
  {
    "text": "so with a 50 worker system we can easily",
    "start": "231280",
    "end": "235040"
  },
  {
    "text": "cash billions of files it also has a",
    "start": "235040",
    "end": "237920"
  },
  {
    "text": "higher availability we can have we can",
    "start": "237920",
    "end": "240319"
  },
  {
    "text": "guarantee a 99 99.99% off time and",
    "start": "240319",
    "end": "244079"
  },
  {
    "text": "there's no single point of failure we",
    "start": "244079",
    "end": "246239"
  },
  {
    "text": "also have Cloud native CES operator for",
    "start": "246239",
    "end": "248879"
  },
  {
    "text": "deployment and management on",
    "start": "248879",
    "end": "252560"
  },
  {
    "text": "kues so we did a endtoend",
    "start": "253200",
    "end": "256400"
  },
  {
    "text": "CV training with pytorch on a subset of",
    "start": "256400",
    "end": "261199"
  },
  {
    "text": "image",
    "start": "261199",
    "end": "262079"
  },
  {
    "text": "net so by reading the data from",
    "start": "262080",
    "end": "266160"
  },
  {
    "text": "alio we reduce the data loader time",
    "start": "266160",
    "end": "268880"
  },
  {
    "text": "percentage from from 82% to only 1% and",
    "start": "268880",
    "end": "273039"
  },
  {
    "text": "we increase GPU utilization rate from",
    "start": "273039",
    "end": "275880"
  },
  {
    "text": "17% to",
    "start": "275880",
    "end": "278639"
  },
  {
    "text": "93% this is a huge",
    "start": "278639",
    "end": "282560"
  },
  {
    "text": "Improvement and we will have more we",
    "start": "283520",
    "end": "287160"
  },
  {
    "text": "will share more details about our",
    "start": "287160",
    "end": "289520"
  },
  {
    "text": "journey on the data locality on Thursday",
    "start": "289520",
    "end": "293000"
  },
  {
    "text": "we also have a talk at 4",
    "start": "293000",
    "end": "295000"
  },
  {
    "text": "pm thank you so much",
    "start": "295000",
    "end": "299320"
  }
]
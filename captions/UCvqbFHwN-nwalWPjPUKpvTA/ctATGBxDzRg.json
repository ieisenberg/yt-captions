[
  {
    "start": "0",
    "end": "41000"
  },
  {
    "text": "[Applause] thank you so much for the introduction",
    "start": "660",
    "end": "6509"
  },
  {
    "text": "and welcome to our talk tale of two worlds so what we're going to be talking about today is basically here at cube",
    "start": "6509",
    "end": "12960"
  },
  {
    "text": "con I guess most of us we have experience with some kind of model deployments and we're actually going to",
    "start": "12960",
    "end": "18420"
  },
  {
    "text": "talk about the similarities to deploying machine learning models which might be something new for some of us at least so",
    "start": "18420",
    "end": "25260"
  },
  {
    "text": "with me here is the Vincent yeah I'm a physicist I'm a technical product",
    "start": "25260",
    "end": "30990"
  },
  {
    "text": "manager for FM I have a background in as a civil engineer and software architect",
    "start": "30990",
    "end": "37050"
  },
  {
    "text": "the cloud architects in the past years and I'm here with a York yeah so I'm the",
    "start": "37050",
    "end": "42719"
  },
  {
    "start": "41000",
    "end": "70000"
  },
  {
    "text": "head of engineering and machine learning over at Arango DB and prior to that I actually built a lot of machine learning",
    "start": "42719",
    "end": "48420"
  },
  {
    "text": "infrastructure both satsuki which is like a healthcare I based start-up in",
    "start": "48420",
    "end": "53670"
  },
  {
    "text": "San Francisco and also at mesosphere so I actually I had to deal with a lot of those problems and you're also going to",
    "start": "53670",
    "end": "60210"
  },
  {
    "text": "see later where kind of connection comes back to working on it at a database company and still talking about machine",
    "start": "60210",
    "end": "66479"
  },
  {
    "text": "learning infrastructure but let's actually dive into the topic who of you knows kind of this reference tale of two",
    "start": "66479",
    "end": "73409"
  },
  {
    "start": "70000",
    "end": "108000"
  },
  {
    "text": "worlds or Tale of Two Cities actually actually works a little better in America because it's like it's a famous",
    "start": "73409",
    "end": "80159"
  },
  {
    "text": "book Charles Dickens Tale of Two Cities and I often feel reminded to like so starting word since starting words like",
    "start": "80159",
    "end": "86460"
  },
  {
    "text": "it's the best of times it's the worst of times and that's actually how I often feel in computing because I feel we have",
    "start": "86460",
    "end": "92939"
  },
  {
    "text": "so much cool stuff achieved and there's still like so many annoying parts which don't make it perfect so this is why I",
    "start": "92939",
    "end": "100409"
  },
  {
    "text": "felt so reminded of this book often when working with a Thai tea or even being at Q con talking about some of the",
    "start": "100409",
    "end": "106799"
  },
  {
    "text": "challenges but the two worlds we actually want to talk about today is a world of micro services and the world of",
    "start": "106799",
    "end": "113130"
  },
  {
    "start": "108000",
    "end": "120000"
  },
  {
    "text": "machine learning models which might seem very different at first but we're going to see that's actually not that",
    "start": "113130",
    "end": "119310"
  },
  {
    "text": "different after all so Vincent is actually the expert from micro services so that's why I would",
    "start": "119310",
    "end": "126060"
  },
  {
    "start": "120000",
    "end": "267000"
  },
  {
    "text": "just hand over to him now yes thank you so I will start off with this this first",
    "start": "126060",
    "end": "131640"
  },
  {
    "text": "world micro-services assuming a bit that most of you already know debt and deploy",
    "start": "131640",
    "end": "138430"
  },
  {
    "text": "services on a daily basis in in this world so and I think of the layer over",
    "start": "138430",
    "end": "147280"
  },
  {
    "text": "the years the cease of promises in challenges arising in this one and especially towards deploying and",
    "start": "147280",
    "end": "152980"
  },
  {
    "text": "releasing new services first we actually want to make our development teams",
    "start": "152980",
    "end": "158140"
  },
  {
    "text": "independent and in their own control of driving their services into the into production we encourage them to do more",
    "start": "158140",
    "end": "165220"
  },
  {
    "text": "frequent deployments because we think that we can develop faster while doing that what are they are there and we",
    "start": "165220",
    "end": "171430"
  },
  {
    "text": "don't want to have more frequent incidents by doing that so we need some things around that that can actually",
    "start": "171430",
    "end": "177660"
  },
  {
    "text": "help us in in this and other stuff is actually we see also that we want to",
    "start": "177660",
    "end": "183400"
  },
  {
    "text": "enable experimentation so that we that we can actually measure that the things we are deploying into production is",
    "start": "183400",
    "end": "189760"
  },
  {
    "text": "actually yeah the things that we expect and so what I want to go through is a",
    "start": "189760",
    "end": "195760"
  },
  {
    "text": "couple of those patterns that you that you see in this world and the first one I think is my familiar blue green and",
    "start": "195760",
    "end": "203140"
  },
  {
    "text": "maybe some hands of people are deploying into production with Bluegreen deployments that's quite some there yeah",
    "start": "203140",
    "end": "212110"
  },
  {
    "text": "there where we push another version of an application next to the current one and make sure it's healthy and as soon",
    "start": "212110",
    "end": "219250"
  },
  {
    "text": "as it's healthy we swap over the traffic to the to the new application if you",
    "start": "219250",
    "end": "225250"
  },
  {
    "text": "look at a bit an evolvement of that we have the declarer releasing",
    "start": "225250",
    "end": "231000"
  },
  {
    "text": "maybe some hands or people are doing canary releasing into production okay no",
    "start": "231000",
    "end": "236910"
  },
  {
    "text": "son I know very actually set to send the next version of the application also to",
    "start": "236910",
    "end": "245600"
  },
  {
    "text": "you set the next version of the application also also to the current one and you direct only a small amount of",
    "start": "245600",
    "end": "252960"
  },
  {
    "text": "traffic which is the canary to this new version and you keep track of itself and",
    "start": "252960",
    "end": "258329"
  },
  {
    "text": "if the metrics are aligning up and as soon as it does you're actually gradually moving into the new version",
    "start": "258330",
    "end": "266510"
  },
  {
    "text": "and the last one yeah this is like we'll see like a sort of only grill where we",
    "start": "266510",
    "end": "272820"
  },
  {
    "start": "267000",
    "end": "329000"
  },
  {
    "text": "actually want to know that every deployment becomes an experiment and with this we have patterned like a be",
    "start": "272820",
    "end": "280770"
  },
  {
    "text": "testing a shadow deployments I wondering how much of you are doing this see okay",
    "start": "280770",
    "end": "287930"
  },
  {
    "text": "okay good yeah we're actually you're yeah you're experimenting that the new",
    "start": "287930",
    "end": "294210"
  },
  {
    "text": "version should behave and is indeed better than the current version and you",
    "start": "294210",
    "end": "299880"
  },
  {
    "text": "put it next to that and you look at all the metrics that comes with that and that's on not only the metrics of Alf or",
    "start": "299880",
    "end": "307010"
  },
  {
    "text": "but also he spawns the guys but also business metrics saying hey I assume",
    "start": "307010",
    "end": "312210"
  },
  {
    "text": "this this deployment drives my conversion are better and that are the",
    "start": "312210",
    "end": "317310"
  },
  {
    "text": "things that you can test on and I click",
    "start": "317310",
    "end": "323730"
  },
  {
    "text": "further",
    "start": "323730",
    "end": "325970"
  },
  {
    "start": "329000",
    "end": "393000"
  },
  {
    "text": "like that and we found as a company that",
    "start": "329620",
    "end": "334790"
  },
  {
    "text": "did this almost 5 years and a friend we actually make a distinction between deploying code into production and",
    "start": "334790",
    "end": "341330"
  },
  {
    "text": "releasing code towards our customers you believe that deployment is something technical you put your code in there",
    "start": "341330",
    "end": "347360"
  },
  {
    "text": "make sure it's healthy and that is ready to receive traffic and releasing we",
    "start": "347360",
    "end": "353690"
  },
  {
    "text": "saying releasing actually the act to get the code in the ends of the customers and and give you value and that's",
    "start": "353690",
    "end": "360920"
  },
  {
    "text": "something that we already started five years ago at that time on the maysa marathon",
    "start": "360920",
    "end": "368710"
  },
  {
    "text": "orchestration and we're using H a proxy for four out into traffic and in 2016",
    "start": "368710",
    "end": "376030"
  },
  {
    "text": "with the developments we see around kubernetes we added the community support to this as well and now AQ Khan",
    "start": "376030",
    "end": "383420"
  },
  {
    "text": "2019 we also introducing SEO as part of like the the way of handling the",
    "start": "383420",
    "end": "389690"
  },
  {
    "text": "networks are we building on top of sto at now as well and if you look at the",
    "start": "389690",
    "end": "395150"
  },
  {
    "start": "393000",
    "end": "431000"
  },
  {
    "text": "FEM stack we actually standing under the shoulders of giants so we were",
    "start": "395150",
    "end": "400490"
  },
  {
    "text": "leveraging the technology that is available to us and that goes from the",
    "start": "400490",
    "end": "405910"
  },
  {
    "text": "three major cloud providers but also to the orchestrators like Mesa Spheeris",
    "start": "405910",
    "end": "412520"
  },
  {
    "text": "with DCOs and mesas Marathon fqb net is",
    "start": "412520",
    "end": "417710"
  },
  {
    "text": "the orchestrator and for the networking using HD poxy and now also sto and for",
    "start": "417710",
    "end": "423890"
  },
  {
    "text": "all the metric related stuff we can integrate with Prometheus and an elastic search so let's go to the other world",
    "start": "423890",
    "end": "433310"
  },
  {
    "start": "431000",
    "end": "524000"
  },
  {
    "text": "yeah and that actually brings us to the next Roland's it's actually machine learning models and those challenges",
    "start": "433310",
    "end": "438860"
  },
  {
    "text": "they might actually look different at the beginning so but at cords actually the same we want to productionize our",
    "start": "438860",
    "end": "445820"
  },
  {
    "text": "code we want to productionize our services so we now just train the model and we actually have to get value out of",
    "start": "445820",
    "end": "451520"
  },
  {
    "text": "that so we have to deploy it to production which also is called often serving in the machine learning world",
    "start": "451520",
    "end": "457409"
  },
  {
    "text": "and the challenges that not only happens once we're actually also going to retrain because we have received more",
    "start": "457409",
    "end": "463289"
  },
  {
    "text": "training data our data scientist have come up with a new cool model so we kind",
    "start": "463289",
    "end": "468509"
  },
  {
    "text": "of have updated our model and we need to redeploy that and overtime we also we",
    "start": "468509",
    "end": "473610"
  },
  {
    "text": "end up actually with a large number of models because we might have different models optimized for different",
    "start": "473610",
    "end": "479330"
  },
  {
    "text": "environments one model might work super great on a like a smart phone another",
    "start": "479330",
    "end": "485819"
  },
  {
    "text": "might just work really well if we have like a large big server farm with like TP used or CPUs so the challenge and how",
    "start": "485819",
    "end": "493979"
  },
  {
    "text": "we can actually make those decisions which model or which models we want to deploy is usually based on metadata and",
    "start": "493979",
    "end": "500610"
  },
  {
    "text": "policies and the other thing as you mentioned testing like cannery deployments a big challenge in machine",
    "start": "500610",
    "end": "507089"
  },
  {
    "text": "learning is also that testing is really hard we cannot have like unit tests because it's kind of like it's a",
    "start": "507089",
    "end": "512638"
  },
  {
    "text": "probabilistic outcome for example classification so a really good pattern is actually to just expose it to live",
    "start": "512639",
    "end": "519419"
  },
  {
    "text": "traffic and compare it to others so actually testing was live production data but let's just step back why is",
    "start": "519419",
    "end": "526380"
  },
  {
    "start": "524000",
    "end": "549000"
  },
  {
    "text": "machine learning becoming so successful in recent years we actually have large amounts of data we have large amounts of",
    "start": "526380",
    "end": "532589"
  },
  {
    "text": "computer vailable and actually also new techniques and like neural networks or related machine learning algorithms and",
    "start": "532589",
    "end": "539339"
  },
  {
    "text": "that's actually turning our data scientists into superheroes because they can come up with really cool use cases",
    "start": "539339",
    "end": "544829"
  },
  {
    "text": "from self-driving cars drug discovery and other things what do we want our",
    "start": "544829",
    "end": "550380"
  },
  {
    "start": "549000",
    "end": "576000"
  },
  {
    "text": "data scientists to be doing they actually they want to focus on riding those really cool models for drug",
    "start": "550380",
    "end": "555689"
  },
  {
    "text": "discovery for self-driving cars and basically they would just love to have",
    "start": "555689",
    "end": "560850"
  },
  {
    "text": "to cycle get some pre clean data right intelligent models train those models and then they",
    "start": "560850",
    "end": "568110"
  },
  {
    "text": "are actually done they're just going to deploy them and they can start over with the next super villain or is the next",
    "start": "568110",
    "end": "573779"
  },
  {
    "text": "cool project they want to tackle in reality unfortunately it looks a bit different so this is a slide from Google",
    "start": "573779",
    "end": "581220"
  },
  {
    "text": "and actually only this small black box here in the middle is the actual ML code we have to do a lot",
    "start": "581220",
    "end": "587910"
  },
  {
    "text": "of stuff around that like serving infrastructure configuration data cleansing data preparation monitoring",
    "start": "587910",
    "end": "594120"
  },
  {
    "text": "and so on and so on so actually this is a lot of work and many of us are probably doing around services as well",
    "start": "594120",
    "end": "600240"
  },
  {
    "text": "but that's actually distracting those data scientists and what we typically end up building in the end is like a",
    "start": "600240",
    "end": "606509"
  },
  {
    "start": "603000",
    "end": "630000"
  },
  {
    "text": "complete pipeline from data cleaning towards the model engineering so the parts the data scientists actually",
    "start": "606509",
    "end": "612839"
  },
  {
    "text": "graded then model training which involves a large number of resources keeping track of all our models we have",
    "start": "612839",
    "end": "620309"
  },
  {
    "text": "trained especially like model training if we're training a model if we train for different hyper parameters this",
    "start": "620309",
    "end": "627389"
  },
  {
    "text": "might not result in one model but actually a large number and then actually getting production value out of",
    "start": "627389",
    "end": "632850"
  },
  {
    "start": "630000",
    "end": "641000"
  },
  {
    "text": "that is in model serving and actually model serving is a part we're going to talk most about today so one example of",
    "start": "632850",
    "end": "640499"
  },
  {
    "text": "that of such pipeline is tensorflow extended this is kind of the ecosystem",
    "start": "640499",
    "end": "646769"
  },
  {
    "start": "641000",
    "end": "669000"
  },
  {
    "text": "around z tensorflow project and machine learning and it's kind of like matching what we described before so we have a",
    "start": "646769",
    "end": "652949"
  },
  {
    "text": "lot of data preparation part here like schema generation example generation transformations then we have our trainer",
    "start": "652949",
    "end": "659759"
  },
  {
    "text": "here we have an evaluator which is actually evaluating how good our metrics are and then we kind of deploy them and",
    "start": "659759",
    "end": "665879"
  },
  {
    "text": "push them into the serving player down here and if we look back so this",
    "start": "665879",
    "end": "672449"
  },
  {
    "text": "actually is this can't all be managed by the data scientist so if we actually look back how this labor can be divided",
    "start": "672449",
    "end": "678059"
  },
  {
    "text": "by different superheroes I mean superheroes say I'll also need sidekicks to actually be efficient so actually the",
    "start": "678059",
    "end": "684179"
  },
  {
    "text": "stack of this prior picture typically is kind of split up between different personalities in a company to actually",
    "start": "684179",
    "end": "690449"
  },
  {
    "text": "be efficient and as mentioned kind of see part of the stack we want to focus on today's kind of see serving",
    "start": "690449",
    "end": "696540"
  },
  {
    "text": "infrastructure and kind of see model monitoring so basically how can we decide what models to deploy and how to",
    "start": "696540",
    "end": "703769"
  },
  {
    "text": "deploy models into production and that's already pretty challenging by itself I",
    "start": "703769",
    "end": "709009"
  },
  {
    "text": "typically when I work with companies before this is often an aspect which is just forgotten because everyone is kind",
    "start": "709009",
    "end": "716160"
  },
  {
    "text": "of focusing on this data scientist spective Chris we need just great models but actually the hard part is later on",
    "start": "716160",
    "end": "722180"
  },
  {
    "text": "production izing that model getting value out of that so for example the first questions are like which model to",
    "start": "722180",
    "end": "728149"
  },
  {
    "text": "deploy if I have a large set of different models because even my production data patterns might be",
    "start": "728149",
    "end": "734029"
  },
  {
    "text": "slightly different from the training data I had earlier so I should keep metrics around and just see whether I",
    "start": "734029",
    "end": "739250"
  },
  {
    "text": "really get what I expected then updating models without impacting those users who might use the hot dog",
    "start": "739250",
    "end": "746060"
  },
  {
    "text": "Pizza app or cat or doc app I just exposed to the Internet they don't want any downtime they want those",
    "start": "746060",
    "end": "751639"
  },
  {
    "text": "classifications immediately so how can I actually update those models without resulting into downtime how can i deploy",
    "start": "751639",
    "end": "758690"
  },
  {
    "text": "to different environments as mentioned there are different servers there might be different geographical regions so for",
    "start": "758690",
    "end": "765500"
  },
  {
    "text": "example it's the health care startup I worked at it's a lot of choices depends on whether we use pH I free so patient",
    "start": "765500",
    "end": "772940"
  },
  {
    "text": "related data or not because that really restricts in which environments you can deploy based on data privacy issues and",
    "start": "772940",
    "end": "779870"
  },
  {
    "text": "then as mentioned like testing models it's also really hard part I might not really know whether my model works good",
    "start": "779870",
    "end": "786740"
  },
  {
    "text": "with production data even though the test accuracy was splendid it might",
    "start": "786740",
    "end": "792589"
  },
  {
    "text": "actually just fail in production and another interesting pattern here is that",
    "start": "792589",
    "end": "797839"
  },
  {
    "text": "often we are also not just deploying a single machine learning model but we actually deploy three or four ends and",
    "start": "797839",
    "end": "803690"
  },
  {
    "text": "we take like a majority vote based on whatever is those different models output so we kind of take ensemble",
    "start": "803690",
    "end": "809779"
  },
  {
    "text": "decisions because we actually get value out of multiple different models so the question is kind of like how can we",
    "start": "809779",
    "end": "815660"
  },
  {
    "text": "deploy that and how can we kind of aggregate that all together and if we actually look at that this is very",
    "start": "815660",
    "end": "821660"
  },
  {
    "start": "818000",
    "end": "875000"
  },
  {
    "text": "similar to the slide we saw before about microservices we want to update a model we can do that in like an a/b style",
    "start": "821660",
    "end": "828199"
  },
  {
    "text": "where we have model version 1 and then we have model version 2 and we just switch traffic over we might want to",
    "start": "828199",
    "end": "834199"
  },
  {
    "text": "test models where we slowly expose 5% of the traffic to model B and keep the rest",
    "start": "834199",
    "end": "840199"
  },
  {
    "text": "at the other model and we just compare like how has a different distribution patterns in the classifications or also",
    "start": "840199",
    "end": "848389"
  },
  {
    "text": "we might do like more calm ensemble or testing of models where we kind of shadow deploy a model and we",
    "start": "848389",
    "end": "855140"
  },
  {
    "text": "still route traffic to it but we kind of like ignores the output so imagines it's",
    "start": "855140",
    "end": "860450"
  },
  {
    "text": "load-balanced if there's a request coming in from for like a hotdog or pizza picture classification and it's",
    "start": "860450",
    "end": "866150"
  },
  {
    "text": "just routing to both models but at first we just kind of ignore the output of model two but just kind of keep see",
    "start": "866150",
    "end": "872300"
  },
  {
    "text": "metrics around so we can compare it later on and so this is very similar to",
    "start": "872300",
    "end": "879140"
  },
  {
    "text": "Z micro-service picture we saw earlier and now the question is just how do I",
    "start": "879140",
    "end": "884570"
  },
  {
    "start": "882000",
    "end": "895000"
  },
  {
    "text": "choose those models like which of those models should I choose here which should I deploy up here because I still",
    "start": "884570",
    "end": "890900"
  },
  {
    "text": "probably have a larger set of models and I can deploy to production anyhow so this leads us to this challenge of",
    "start": "890900",
    "end": "897680"
  },
  {
    "start": "895000",
    "end": "998000"
  },
  {
    "text": "metadata and this is actually tying back to why I'm still so interested in that field because this keeping track of",
    "start": "897680",
    "end": "903920"
  },
  {
    "text": "metadata is super challenging but also super interesting because it really gives me value out of this entire ml",
    "start": "903920",
    "end": "909740"
  },
  {
    "text": "pipeline so what we see up here this is again like tensorflow extended so the different components and each of those",
    "start": "909740",
    "end": "916280"
  },
  {
    "text": "components actually is producing metadata so we know for example where our datasets are we know which",
    "start": "916280",
    "end": "922250"
  },
  {
    "text": "transformations have been done to our data set we know what training and test",
    "start": "922250",
    "end": "927740"
  },
  {
    "text": "accuracy we had when training our model and then also from serving we might get some statistics and it's actually really",
    "start": "927740",
    "end": "934520"
  },
  {
    "text": "crucial that I have like a common metadata store where I keep track of all of that so first of all probably we all",
    "start": "934520",
    "end": "940910"
  },
  {
    "text": "think about like accuracy so how accurate is my model but another important factor to decide whether we",
    "start": "940910",
    "end": "947840"
  },
  {
    "text": "want to deploy it or not typically its latency how long does it takes a model to make a decision because that also",
    "start": "947840",
    "end": "954080"
  },
  {
    "text": "varies quite a lot between different models and can also even vary between different environments do I have TP use",
    "start": "954080",
    "end": "959750"
  },
  {
    "text": "available do I only have a smartphone available this probably is going to impact the choice of model I want to",
    "start": "959750",
    "end": "965720"
  },
  {
    "text": "deploy and it's mentioned like data privacy is another interesting aspect where I just need kind of like a common",
    "start": "965720",
    "end": "972440"
  },
  {
    "text": "view across that pipeline so for example for us it was always really important to figure out for all those models being",
    "start": "972440",
    "end": "979640"
  },
  {
    "text": "deployed in production and being used right now which data sets have been so for example if we had to filter out a",
    "start": "979640",
    "end": "986510"
  },
  {
    "text": "specific doctor in the training set data we had to be able to identify all the",
    "start": "986510",
    "end": "991820"
  },
  {
    "text": "models being running in production for which that data has been used and so if",
    "start": "991820",
    "end": "998780"
  },
  {
    "start": "998000",
    "end": "1046000"
  },
  {
    "text": "we actually look at that let's ending up in a lot of unstructured data we have some kind of description a document like",
    "start": "998780",
    "end": "1004750"
  },
  {
    "text": "description of a data set we have a document description of our pre-processing steps of our features and",
    "start": "1004750",
    "end": "1011020"
  },
  {
    "text": "so on and so on so actually we have a connection of unstructured data describing each of those entities and",
    "start": "1011020",
    "end": "1017200"
  },
  {
    "text": "then they are just related by edges by actually a graph and so if we look at",
    "start": "1017200",
    "end": "1022510"
  },
  {
    "text": "that tree I mentioned earlier we have to figure out those models being served in production figure out all models which",
    "start": "1022510",
    "end": "1029350"
  },
  {
    "text": "have contributions from my data says it's actually it's a graph traversal find all those models which are kind of",
    "start": "1029350",
    "end": "1035350"
  },
  {
    "text": "related through those arches with that model we are using in production there",
    "start": "1035350",
    "end": "1041410"
  },
  {
    "text": "and that for example enabled us to really easily identify all those models and this is tying back to why I still",
    "start": "1041410",
    "end": "1048580"
  },
  {
    "start": "1046000",
    "end": "1084000"
  },
  {
    "text": "care as I currently work at a Rango DB which is like a multi model database so",
    "start": "1048580",
    "end": "1053590"
  },
  {
    "text": "we actually can both treat those document stories it's unstructured data but also evaluates the connections",
    "start": "1053590",
    "end": "1061180"
  },
  {
    "text": "between them really well because it's actually this native native model model",
    "start": "1061180",
    "end": "1066220"
  },
  {
    "text": "it actually allows me to both have a document store plus a graph store in like a single database core and it also",
    "start": "1066220",
    "end": "1073300"
  },
  {
    "text": "can scale to multiple nodes so this graphs are not restricted to a single node because often our graphs gets",
    "start": "1073300",
    "end": "1079810"
  },
  {
    "text": "rather large because a lot of models a lot of data sets and so on and so on and",
    "start": "1079810",
    "end": "1084840"
  },
  {
    "text": "yeah this actually allowed us to decide which models we wanted to deploy into production and this also helps us to",
    "start": "1084840",
    "end": "1092620"
  },
  {
    "text": "kind of connect those both worlds together soon in the end it's not two worlds it's actually one world as we're",
    "start": "1092620",
    "end": "1098110"
  },
  {
    "start": "1094000",
    "end": "1102000"
  },
  {
    "text": "just talking about the deployments of models and services together and with",
    "start": "1098110",
    "end": "1103480"
  },
  {
    "start": "1102000",
    "end": "1139000"
  },
  {
    "text": "that I would actually hand back to you for the demo yeah thank you",
    "start": "1103480",
    "end": "1108580"
  },
  {
    "text": "so whatever demo is actually how how does does one world works",
    "start": "1108580",
    "end": "1113970"
  },
  {
    "text": "for that I want to start off with doing and canary release of a service which we",
    "start": "1113970",
    "end": "1119970"
  },
  {
    "text": "have created for this demo and in this actually and in this demo we have this this one we have this one service",
    "start": "1119970",
    "end": "1126809"
  },
  {
    "text": "running on fee one and it has in catalog and the sheriff is that I'm showing is",
    "start": "1126809",
    "end": "1132690"
  },
  {
    "text": "some called smart Kong it's it's actually the OL session listening of Q",
    "start": "1132690",
    "end": "1137700"
  },
  {
    "text": "con whatever show in a minute and what I want to do is actually make it a bit smarter because one of our business",
    "start": "1137700",
    "end": "1143129"
  },
  {
    "start": "1139000",
    "end": "1175000"
  },
  {
    "text": "metrics in that in that service is that we want to drive on people favor favoriting sessions and so what I want",
    "start": "1143129",
    "end": "1153360"
  },
  {
    "text": "to do is actually do an air release of a new version of the service which has something tied to that which is in",
    "start": "1153360",
    "end": "1159539"
  },
  {
    "text": "discovery service which is a smart model trained actually with the sole purpose",
    "start": "1159539",
    "end": "1166200"
  },
  {
    "text": "to to you know to match more and better sessions to people so that we can have",
    "start": "1166200",
    "end": "1172710"
  },
  {
    "text": "more favorites for application our motivation was actually if you first",
    "start": "1172710",
    "end": "1178169"
  },
  {
    "start": "1175000",
    "end": "1202000"
  },
  {
    "text": "time I looked at scat and especially like a lot of newcomers I was actually sitting on the plane next to someone who",
    "start": "1178169",
    "end": "1183299"
  },
  {
    "text": "was like okay which sessions should I go to and I feel over time koukin has become so large that's actually a really",
    "start": "1183299",
    "end": "1190379"
  },
  {
    "text": "hard problem and this is why we were discussing like what demo use case should we take it was kind of like okay",
    "start": "1190379",
    "end": "1195840"
  },
  {
    "text": "how can we recommend sessions to people and that was kind of the idea here yeah",
    "start": "1195840",
    "end": "1201389"
  },
  {
    "text": "exactly so the this is the way how the canary release is going to work and I actually want to demonstrate it to you",
    "start": "1201389",
    "end": "1207409"
  },
  {
    "start": "1202000",
    "end": "1576000"
  },
  {
    "text": "and bear with me that the that the conference VP hold up but",
    "start": "1207409",
    "end": "1213510"
  },
  {
    "text": "here's the application called smart con and as you can see there's a lot of sessions over there and we have",
    "start": "1213510",
    "end": "1220560"
  },
  {
    "text": "different sections of the schedule in sessions and you can put and those ones",
    "start": "1220560",
    "end": "1226380"
  },
  {
    "text": "you can actually favorite over here and it's kind of nice it's deployed on cube Nettie's and we have built a nice graph",
    "start": "1226380",
    "end": "1236310"
  },
  {
    "text": "on a desktop that show all kind of information like the incoming requests the success rates and it's actually",
    "start": "1236310",
    "end": "1243420"
  },
  {
    "text": "getting all this data out of sto we're constantly and over here we also have a",
    "start": "1243420",
    "end": "1249180"
  },
  {
    "text": "custom metrics inserted here which is the the number favorites per minute and",
    "start": "1249180",
    "end": "1254760"
  },
  {
    "text": "later on you can also see the number of favorites per model so what I will do is",
    "start": "1254760",
    "end": "1260130"
  },
  {
    "text": "actually starting canary release using using femp and for that I'm going into my terminal",
    "start": "1260130",
    "end": "1270880"
  },
  {
    "text": "I do FEM CTO create canary release and in that canary release I pointed towards",
    "start": "1270880",
    "end": "1277750"
  },
  {
    "text": "and yama fell like like you know everything Cuban it is Robles llamo I've heard a couple of times during this",
    "start": "1277750",
    "end": "1283750"
  },
  {
    "text": "conference and yeah this is also the case so what we now are doing is",
    "start": "1283750",
    "end": "1289720"
  },
  {
    "text": "actually running this release and I want to say looking at the service and it",
    "start": "1289720",
    "end": "1299080"
  },
  {
    "text": "will actually show me that the service is now from version one as a rate of 100 and version 2 as a rate of zero and well",
    "start": "1299080",
    "end": "1307450"
  },
  {
    "text": "it's actually going to slide those rates over to the other version we actually",
    "start": "1307450",
    "end": "1314380"
  },
  {
    "text": "made some sort of error in this this part so as in Canaries release you do as",
    "start": "1314380",
    "end": "1319660"
  },
  {
    "text": "as long as it doesn't work it should fall back so let's wait into it moving",
    "start": "1319660",
    "end": "1330640"
  },
  {
    "text": "traffic so me more I can actually show",
    "start": "1330640",
    "end": "1336430"
  },
  {
    "text": "you a bit how the llamo looks like the llamo what you're actually giving to ven",
    "start": "1336430",
    "end": "1342730"
  },
  {
    "text": "is see it over here it's the families",
    "start": "1342730",
    "end": "1347890"
  },
  {
    "text": "and the families will actually give it some actually give it some farro use we",
    "start": "1347890",
    "end": "1355240"
  },
  {
    "text": "say average services we actually want to release what is the destination so if",
    "start": "1355240",
    "end": "1360280"
  },
  {
    "text": "you are familiar with sto and destination should sound familiar and we give it to which subset it has to go and",
    "start": "1360280",
    "end": "1366790"
  },
  {
    "text": "some some parameters like in which period and what are the steps it has to",
    "start": "1366790",
    "end": "1372010"
  },
  {
    "text": "involve and we have baked in a couple of release policies with the event and this is in health Dave canary release oh well",
    "start": "1372010",
    "end": "1378610"
  },
  {
    "text": "it's moving those traffic it constantly looking at a health we also have a time-based way of doing that so it goes",
    "start": "1378610",
    "end": "1385690"
  },
  {
    "text": "regardless over time but you can also put in your custom metrics so as things",
    "start": "1385690",
    "end": "1391330"
  },
  {
    "text": "that are important for you like it resonates or it's Bonus Time if I quickly come over",
    "start": "1391330",
    "end": "1398900"
  },
  {
    "text": "here we see there is an a problem in our service and if we look at that it",
    "start": "1398900",
    "end": "1405470"
  },
  {
    "text": "automatically switched back to 100 again so this means there was a problem with",
    "start": "1405470",
    "end": "1413960"
  },
  {
    "text": "our service that we're deploying and the canary actually died so we we stopped",
    "start": "1413960",
    "end": "1419660"
  },
  {
    "text": "the release switch back towards the previous version and gave us time to actually fix this forward so what I",
    "start": "1419660",
    "end": "1427820"
  },
  {
    "text": "going to do isn't say slash fix and what",
    "start": "1427820",
    "end": "1436430"
  },
  {
    "text": "I doing with fix is I I create a new deployment of a service the problem is",
    "start": "1436430",
    "end": "1441800"
  },
  {
    "text": "that it couldn't reach the end point of the discovery service and what it does",
    "start": "1441800",
    "end": "1449420"
  },
  {
    "text": "it now should be correctly although I",
    "start": "1449420",
    "end": "1456380"
  },
  {
    "text": "see my my health dropping there as well",
    "start": "1456380",
    "end": "1461020"
  },
  {
    "text": "and it quickly go to this",
    "start": "1463660",
    "end": "1467950"
  },
  {
    "text": "okay quickly fixes live demos didn't ya",
    "start": "1477470",
    "end": "1490759"
  },
  {
    "text": "choose the demo gods last night I I did a couple of sessions probably it works",
    "start": "1490759",
    "end": "1496370"
  },
  {
    "text": "differently over in Barcelona so when we",
    "start": "1496370",
    "end": "1501950"
  },
  {
    "text": "first checked the deployment deployment",
    "start": "1501950",
    "end": "1508009"
  },
  {
    "text": "is fixed now I actually have to update",
    "start": "1508009",
    "end": "1516289"
  },
  {
    "text": "the servers to the right traffic",
    "start": "1516289",
    "end": "1523299"
  },
  {
    "text": "let me see oh yeah okay it's fixed",
    "start": "1525400",
    "end": "1529780"
  },
  {
    "text": "yeah I see that my fix is probably at least the other version already okay so",
    "start": "1531490",
    "end": "1538400"
  },
  {
    "text": "as you see my my new version of the service is released and it's actually",
    "start": "1538400",
    "end": "1544670"
  },
  {
    "text": "getting favorites for our new model I see it already going to version 2 of the",
    "start": "1544670",
    "end": "1550700"
  },
  {
    "text": "models I have to take this as well",
    "start": "1550700",
    "end": "1558100"
  },
  {
    "text": "let me switch back to the slide to actually to go to show what's the second",
    "start": "1564670",
    "end": "1570080"
  },
  {
    "text": "part so moving to we're now at at this",
    "start": "1570080",
    "end": "1578270"
  },
  {
    "start": "1576000",
    "end": "1649000"
  },
  {
    "text": "situation where we have the the application getting all the session from",
    "start": "1578270",
    "end": "1584480"
  },
  {
    "text": "the catalog and it will get the discovery part from the from our model",
    "start": "1584480",
    "end": "1590350"
  },
  {
    "text": "to show it a bit in the user interface there's now section called discover and",
    "start": "1590350",
    "end": "1598220"
  },
  {
    "text": "if I go there you see it has less less",
    "start": "1598220",
    "end": "1603500"
  },
  {
    "text": "sessions to show and it will match up towards my my profile at least that's my",
    "start": "1603500",
    "end": "1609559"
  },
  {
    "text": "assumption whatever look into into qivana I actually see that model one",
    "start": "1609559",
    "end": "1620500"
  },
  {
    "text": "over here doesn't provide me the expected amount of favorites per minute",
    "start": "1620500",
    "end": "1627290"
  },
  {
    "text": "so I'll see okay I need to to update this to a better version of my model and",
    "start": "1627290",
    "end": "1634550"
  },
  {
    "text": "for that I actually going to launch an experiment search this slide",
    "start": "1634550",
    "end": "1646809"
  },
  {
    "text": "and this is experiment actually we treat the model the same as a service and we're going to have some traffic from",
    "start": "1648090",
    "end": "1658749"
  },
  {
    "start": "1649000",
    "end": "1800000"
  },
  {
    "text": "from model version one to mold version two and while we're doing that we're",
    "start": "1658749",
    "end": "1663940"
  },
  {
    "text": "actually going to look on a what what are the metrics that we expect for that in this case is the favorites that one",
    "start": "1663940",
    "end": "1670929"
  },
  {
    "text": "should actually go go up so basically how many of those recommendations you",
    "start": "1670929",
    "end": "1677619"
  },
  {
    "text": "got you would actually see as a favorite and add to your program to add to your schedule right yeah exactly exactly",
    "start": "1677619",
    "end": "1683609"
  },
  {
    "text": "because that's our business brain so the more favorites the better and that's",
    "start": "1683609",
    "end": "1689019"
  },
  {
    "text": "what we want to test so I started having a 50% of my traffic",
    "start": "1689019",
    "end": "1696700"
  },
  {
    "text": "towards the experiment and while doing that I'm actually testing if we getting",
    "start": "1696700",
    "end": "1702369"
  },
  {
    "text": "more favorites out of that model and as",
    "start": "1702369",
    "end": "1708129"
  },
  {
    "text": "we now should show in Havana this should become more favorites into my graphs so",
    "start": "1708129",
    "end": "1719919"
  },
  {
    "text": "we have to weigh down a bit and what we",
    "start": "1719919",
    "end": "1725080"
  },
  {
    "text": "do with experiments is quite nicely we can actually if you have a new website",
    "start": "1725080",
    "end": "1731940"
  },
  {
    "text": "and we held traffic to us the websites we place them as they come in into an",
    "start": "1732629",
    "end": "1737710"
  },
  {
    "text": "embark it so we say is 50% of the people coming in to the website we place it into the experiment and we're going to",
    "start": "1737710",
    "end": "1744609"
  },
  {
    "text": "monitor yeah if that that part goes towards the target that",
    "start": "1744609",
    "end": "1750049"
  },
  {
    "text": "we expect and we should see now sorry ah",
    "start": "1750049",
    "end": "1759100"
  },
  {
    "text": "okay great thank you you saved it as you",
    "start": "1759100",
    "end": "1764179"
  },
  {
    "text": "can see now we get more favorites on the model two version of the model and it",
    "start": "1764179",
    "end": "1774650"
  },
  {
    "text": "also increase our favorites per minute so this indicates that this version of the model performs better and better",
    "start": "1774650",
    "end": "1781490"
  },
  {
    "text": "than as we expect and it actually won the experiment and that's what we don't",
    "start": "1781490",
    "end": "1787820"
  },
  {
    "text": "then release automatically in production",
    "start": "1787820",
    "end": "1792070"
  },
  {
    "start": "1800000",
    "end": "1891000"
  },
  {
    "text": "so like your mentioned we also we have",
    "start": "1800350",
    "end": "1806720"
  },
  {
    "text": "also some other scenarios if you look at machine learning models so what we can",
    "start": "1806720",
    "end": "1812270"
  },
  {
    "text": "do as well is yeah put them into segments like if you look at if you ever",
    "start": "1812270",
    "end": "1819710"
  },
  {
    "text": "get the cumference example again not all the not all the",
    "start": "1819710",
    "end": "1825919"
  },
  {
    "text": "people here are our developers or so it could be that there are people here with",
    "start": "1825919",
    "end": "1832220"
  },
  {
    "text": "other interest interests so those are models that actually trained differently or also just like based on location",
    "start": "1832220",
    "end": "1839840"
  },
  {
    "text": "right people here in Barcelona might have different of who are here at coupon itself might have different preferences",
    "start": "1839840",
    "end": "1845179"
  },
  {
    "text": "and someone just filling out scat for the videos he want you to want to watch later exactly so we can annotate the",
    "start": "1845179",
    "end": "1851960"
  },
  {
    "text": "request with which rolled the person is in and we can route the traffic towards the model that's actually connected to",
    "start": "1851960",
    "end": "1859340"
  },
  {
    "text": "that this is a way we can actually help as well and the other one is actually",
    "start": "1859340",
    "end": "1866150"
  },
  {
    "text": "using shadow traffic so meaning that we don't expose the end user towards the the new model but on the background we",
    "start": "1866150",
    "end": "1874220"
  },
  {
    "text": "actually look at things like performance and that the outcome of the of the",
    "start": "1874220",
    "end": "1879299"
  },
  {
    "text": "results that model gave us are correct until we actually give traffic towards to work it until you use that result",
    "start": "1879299",
    "end": "1886740"
  },
  {
    "text": "right yeah exactly cool and yeah that's actually kind of",
    "start": "1886740",
    "end": "1894029"
  },
  {
    "start": "1891000",
    "end": "1979000"
  },
  {
    "text": "combining those two worlds of those micro services and data services so what I personally feel we actually invested",
    "start": "1894029",
    "end": "1900809"
  },
  {
    "text": "so much and came up with so many good tools around building and deploying",
    "start": "1900809",
    "end": "1906360"
  },
  {
    "text": "micro services that we should actually just consider reusing them also for machine learning even though it's not",
    "start": "1906360",
    "end": "1912869"
  },
  {
    "text": "exactly the same there's actually enough overlap that it's worse to kind of like reuse a lot of those tools and we don't",
    "start": "1912869",
    "end": "1920220"
  },
  {
    "text": "have to reinvent the wheel all the time because we already have a lot of great stuff out there and this also applies to",
    "start": "1920220",
    "end": "1927360"
  },
  {
    "text": "data science that's a large part I believe we have like two minutes or so for questions - yeah any questions from",
    "start": "1927360",
    "end": "1935039"
  },
  {
    "text": "the audience if you want to talk with us",
    "start": "1935039",
    "end": "1947159"
  },
  {
    "text": "we we are here you can find us at the mesosphere stands also like to invite",
    "start": "1947159",
    "end": "1952980"
  },
  {
    "text": "you to take a look at our source code event and if you are interested in",
    "start": "1952980",
    "end": "1959869"
  },
  {
    "text": "running it with SEO we have an preview available and if you don't like to see",
    "start": "1959869",
    "end": "1966690"
  },
  {
    "text": "the code for the demo there's also the repository on github thank you",
    "start": "1966690",
    "end": "1975379"
  },
  {
    "text": "you",
    "start": "1977880",
    "end": "1979940"
  }
]
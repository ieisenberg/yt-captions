[
  {
    "text": "hi everyone thank you very much for joining us today uh especially in person i know it's been uh somewhere like the",
    "start": "80",
    "end": "6480"
  },
  {
    "text": "weird the last years have been a bit weird so at least from my point not sure if",
    "start": "6480",
    "end": "11599"
  },
  {
    "text": "you can relate this this is like i haven't seen this many people in like the last two or three years so it's a",
    "start": "11599",
    "end": "17359"
  },
  {
    "text": "bit different uh so thank you very much for being here thank you very much for",
    "start": "17359",
    "end": "22800"
  },
  {
    "text": "the people that are uh virtually attending um [Music] my name is madalina i'll be one of your",
    "start": "22800",
    "end": "30080"
  },
  {
    "text": "co-hosts today i am a software engineer in intel's resource management space in ireland",
    "start": "30080",
    "end": "36800"
  },
  {
    "text": "i have a web service and distributed systems background but i recently moved",
    "start": "36800",
    "end": "42079"
  },
  {
    "text": "into the cloud native and kubernetes space i won't be giving this presentation alone i'm here with my",
    "start": "42079",
    "end": "48559"
  },
  {
    "text": "teammate denisio and he's going to say a couple of words about himself",
    "start": "48559",
    "end": "53520"
  },
  {
    "text": "hello my name is denis otogashes or",
    "start": "55360",
    "end": "60399"
  },
  {
    "text": "ice mandolin i am also a cloud native engineer at intel",
    "start": "60399",
    "end": "66960"
  },
  {
    "text": "my background is science then a couple years ago um i got uh",
    "start": "66960",
    "end": "74400"
  },
  {
    "text": "opportunities to fast track and get a degree on the soft development and and",
    "start": "74400",
    "end": "80320"
  },
  {
    "text": "then so i end up on this huge incred incredible company that intel so",
    "start": "80320",
    "end": "86960"
  },
  {
    "text": "we both are based in ireland we work on the team on the resource management team",
    "start": "86960",
    "end": "92560"
  },
  {
    "text": "and in this team um we have so many different projects but",
    "start": "92560",
    "end": "98799"
  },
  {
    "text": "each one then with your challenge it's your the challenges and so on but um",
    "start": "98799",
    "end": "104159"
  },
  {
    "text": "we we always looking on different ways to make an improvement",
    "start": "104159",
    "end": "110000"
  },
  {
    "text": "kind of different innovations related but with the mindset what was talked on",
    "start": "110000",
    "end": "116159"
  },
  {
    "text": "this morning uh relate to sustainability so as i said we",
    "start": "116159",
    "end": "123040"
  },
  {
    "text": "we have a dual school projects and uh yeah i hope you enjoy so madeline and i is a first time um",
    "start": "123040",
    "end": "130319"
  },
  {
    "text": "community uh cubicon so um it's really great to be here and",
    "start": "130319",
    "end": "136239"
  },
  {
    "text": "yeah um today because of you and thank you give you",
    "start": "136239",
    "end": "141280"
  },
  {
    "text": "this opportunity we're going to talk about one of those projects that is related on the",
    "start": "141280",
    "end": "147200"
  },
  {
    "text": "um you know this math scheduling and and then",
    "start": "147200",
    "end": "153040"
  },
  {
    "text": "we follow up the presentation that so i stopped to talk and",
    "start": "153040",
    "end": "158400"
  },
  {
    "text": "head back to mata thank you so i",
    "start": "158400",
    "end": "163920"
  },
  {
    "text": "um so the name of our talk is working your cluster smarter scheduling decisions for",
    "start": "164560",
    "end": "170080"
  },
  {
    "text": "your workload the aim of it is to show you how you can leverage telemetry from your own cluster to make better",
    "start": "170080",
    "end": "176160"
  },
  {
    "text": "scheduling decisions we're going to start off with why",
    "start": "176160",
    "end": "182480"
  },
  {
    "text": "resource dates and scheduling matter how would they how would you go around combining them and what's the what are",
    "start": "182480",
    "end": "189040"
  },
  {
    "text": "the benefits of doing so we're going to touch on one of our projects which is called telemetry aware scheduling it's",
    "start": "189040",
    "end": "195280"
  },
  {
    "text": "an open source project then you spoke a bit about it we're going to look at a high-level intro system design and then",
    "start": "195280",
    "end": "202400"
  },
  {
    "text": "the basic building blocks we're going to see telemetry aware scheduling or tas it's a bit of a mouthful",
    "start": "202400",
    "end": "208799"
  },
  {
    "text": "and in a quick demo and we're going to conclude the session with a bit of q a",
    "start": "208799",
    "end": "216239"
  },
  {
    "text": "so i'm guessing most of you here today run your workloads on clusters whether they are on premise or via or or hosted",
    "start": "217040",
    "end": "225280"
  },
  {
    "text": "by a cloud provider um especially if you work with big clusters you have a large number of nodes and",
    "start": "225280",
    "end": "232400"
  },
  {
    "text": "with that comes the problem how do you deal with uh failures because it's the",
    "start": "232400",
    "end": "237760"
  },
  {
    "text": "more hosts you actually have in a cluster the harder it gets for you to pinpoint with like accurate precision",
    "start": "237760",
    "end": "244159"
  },
  {
    "text": "when a host or a node can become unhealthy so when you design a system or even",
    "start": "244159",
    "end": "249439"
  },
  {
    "text": "think of a system you look at how will i deal with these fail failure scenarios",
    "start": "249439",
    "end": "254799"
  },
  {
    "text": "some ideas that will come to mind is whenever you want to schedule a workload you can avoid scheduling to an unhealthy",
    "start": "254799",
    "end": "262160"
  },
  {
    "text": "node or once you know that a node becomes unhealthy you migrate your workloads away",
    "start": "262160",
    "end": "269440"
  },
  {
    "text": "one level going above this that you can think about is i know my workload so i know what i want to do and then i know",
    "start": "269440",
    "end": "276160"
  },
  {
    "text": "my cluster i know my hardware configurations what if i take the metrics of interest like temperature or",
    "start": "276160",
    "end": "283120"
  },
  {
    "text": "power or load and i make a ranking of my nodes and i pick the best outcome",
    "start": "283120",
    "end": "289680"
  },
  {
    "text": "especially if you're in kubernetes you don't want to also reinvent the wheel so you're going to think of how can i make",
    "start": "289680",
    "end": "295280"
  },
  {
    "text": "my system work but out of the box tools like like the kubernetes the scheduler or the gpu aware scheduler",
    "start": "295280",
    "end": "303759"
  },
  {
    "text": "so the next topic that i want to talk about is at least in how we thought about",
    "start": "305120",
    "end": "312240"
  },
  {
    "text": "handling telemetry and smarter scheduling decisions and this is where i'm going to talk a bit about one of our",
    "start": "312240",
    "end": "318160"
  },
  {
    "text": "projects it's called telemetry aware scheduler as i said before it's an open source project and as the name says and i guess",
    "start": "318160",
    "end": "325360"
  },
  {
    "text": "you already thought about it it uses telemetry to help make scheduling and scheduling decisions",
    "start": "325360",
    "end": "331360"
  },
  {
    "text": "it's an extender of the kubernetes scheduler and that comes with a couple of perks the first",
    "start": "331360",
    "end": "337759"
  },
  {
    "text": "thing you think of is because it's an extender i have the capability of filtering",
    "start": "337759",
    "end": "343199"
  },
  {
    "text": "and uh scoring nodes and then the spice that i think comes a bit above is i can",
    "start": "343199",
    "end": "349120"
  },
  {
    "text": "also utilize node affinity rules via fixed and also custom labels and we're going to look at this in a bit",
    "start": "349120",
    "end": "357039"
  },
  {
    "text": "when you're talking about scheduling at least in kubernetes and with a default scheduler one way you can actually touch",
    "start": "357039",
    "end": "363440"
  },
  {
    "text": "upon a recommended pods like a pause recommended schedule is via policies",
    "start": "363440",
    "end": "371039"
  },
  {
    "text": "that is pretty much how you would tell the scheduler how to react what actions are taken and when",
    "start": "371039",
    "end": "377520"
  },
  {
    "text": "in our specific case we work with something called telemetry where uh telemetry we're scheduling policies and",
    "start": "377520",
    "end": "382800"
  },
  {
    "text": "we're gonna look at examples and these this policy is structurally based on",
    "start": "382800",
    "end": "389120"
  },
  {
    "text": "rules which in turns are based on metrics that actually come from your own cluster",
    "start": "389120",
    "end": "395120"
  },
  {
    "text": "if you have more complex scenarios we also have a capability in telemetry or",
    "start": "395120",
    "end": "400800"
  },
  {
    "text": "scheduler or tis that we support multimetric rules so you can build rules",
    "start": "400800",
    "end": "405840"
  },
  {
    "text": "that contain multiple metrics and you can link them together with operators such as any off or all of",
    "start": "405840",
    "end": "413840"
  },
  {
    "text": "so to set telemetry we're scheduling up you don't need much the first component that you need is a",
    "start": "421440",
    "end": "427199"
  },
  {
    "text": "metrics pipeline because we're talking about telemetry and i i'm going to talk about the first part i'm going to talk about",
    "start": "427199",
    "end": "433280"
  },
  {
    "text": "is in the top left corner so the metrics pipeline you need that because you need to expose collect store and then make",
    "start": "433280",
    "end": "440400"
  },
  {
    "text": "metrics available to the kubernetes custom metrics api in our specific case we're using the prometheus node exporter",
    "start": "440400",
    "end": "448000"
  },
  {
    "text": "to make telemetry available to us we use prometheus for collection",
    "start": "448000",
    "end": "453199"
  },
  {
    "text": "and storage and we use the adapter to make our metrics ready making them ready for the custom metrics",
    "start": "453199",
    "end": "459440"
  },
  {
    "text": "api the second part that i want to talk about is the actual telemetry aware scheduler it",
    "start": "459440",
    "end": "465039"
  },
  {
    "text": "works together with the default scheduler so every time the default scheduler actually wants to make a",
    "start": "465039",
    "end": "470319"
  },
  {
    "text": "decision it reaches out to tas if the workload has a policy that ts",
    "start": "470319",
    "end": "476479"
  },
  {
    "text": "recognizes it just returns like a suggested outcome of that pod placement",
    "start": "476479",
    "end": "482080"
  },
  {
    "text": "to the default scheduler the last piece of the puzzle is the actual telemetry aware policy",
    "start": "482080",
    "end": "488240"
  },
  {
    "text": "and as i said this part this is harshly how you control the actions it's a custom resource known by the telemetry",
    "start": "488240",
    "end": "494400"
  },
  {
    "text": "aware scheduler and um you the way you actually work with it is",
    "start": "494400",
    "end": "500400"
  },
  {
    "text": "in your in a high level workload type like a deployment you would just add a label saying which policy you want to link it",
    "start": "500400",
    "end": "506960"
  },
  {
    "text": "to but don't be afraid we're going to show you examples as i said before structurally this policy has a couple of rules and tas",
    "start": "506960",
    "end": "514640"
  },
  {
    "text": "itself supports uh four types and i'm going to ask denise to come along and show you what are these four types and",
    "start": "514640",
    "end": "521919"
  },
  {
    "text": "how they behave and how do they actually look like",
    "start": "521919",
    "end": "526000"
  },
  {
    "text": "thank you madalina so thank you for a nice intro on that so i'm going to talk about the a little",
    "start": "528240",
    "end": "535120"
  },
  {
    "text": "bit money structure the other another piece of the building block that is the js pulse",
    "start": "535120",
    "end": "540800"
  },
  {
    "text": "so the ts policy composed of four strategies okay um",
    "start": "540800",
    "end": "546640"
  },
  {
    "text": "the two fourth strategies are directly related about the the the schedule the",
    "start": "546640",
    "end": "551760"
  },
  {
    "text": "native schedule the full scatter uh which telemetry was getting working like a",
    "start": "551760",
    "end": "557600"
  },
  {
    "text": "standard the two less the two less strategies are more uh communicating",
    "start": "557600",
    "end": "563279"
  },
  {
    "text": "director of the the difference via the northern finnish rules",
    "start": "563279",
    "end": "569040"
  },
  {
    "text": "so you can go yeah thank you so we got to take a look on the first strategy",
    "start": "569040",
    "end": "575839"
  },
  {
    "text": "don't schedule each one of those strategies are composed for the action so",
    "start": "575839",
    "end": "582160"
  },
  {
    "text": "and the metric name and the target val and the operator so",
    "start": "582160",
    "end": "588080"
  },
  {
    "text": "we say that the the strategy is broken or",
    "start": "588080",
    "end": "594000"
  },
  {
    "text": "uh in case of down schedule when the the metric rules are broken so what that means so",
    "start": "594000",
    "end": "599920"
  },
  {
    "text": "in this case we have the health metric uh metric like that example so if you know",
    "start": "599920",
    "end": "605600"
  },
  {
    "text": "closely you define you have that metric and if that method is at that current state have that value that is equal to 1",
    "start": "605600",
    "end": "612880"
  },
  {
    "text": "in this case so that node particularly going to be pulled out from the scattering process",
    "start": "612880",
    "end": "620160"
  },
  {
    "text": "so that's the equivalent of the filtering process on the the default scheduling and",
    "start": "620160",
    "end": "625920"
  },
  {
    "text": "now the second the second strategy is categorically started so",
    "start": "625920",
    "end": "631279"
  },
  {
    "text": "it's the one that actually gives a kind of priority or those nodes that have",
    "start": "631279",
    "end": "636720"
  },
  {
    "text": "been uh available with information to the cluster so once that is you only",
    "start": "636720",
    "end": "642880"
  },
  {
    "text": "have those up suitable nodes which one that you think that will be uh",
    "start": "642880",
    "end": "648480"
  },
  {
    "text": "more adequate so they can't get a kind of the prior priority uh in front of the",
    "start": "648480",
    "end": "654399"
  },
  {
    "text": "other so that's you can define only these strategies using another metric method",
    "start": "654399",
    "end": "660240"
  },
  {
    "text": "in this case there's a temperature that is a good opportunity to know to save if you consider temperatures are",
    "start": "660240",
    "end": "667120"
  },
  {
    "text": "power related so so in these examples that we have",
    "start": "667120",
    "end": "672240"
  },
  {
    "text": "that strategy is just saying that okay nodes with that metric temperature the lowest",
    "start": "672240",
    "end": "678399"
  },
  {
    "text": "really going to have the high priority so now uh move on for them",
    "start": "678399",
    "end": "684160"
  },
  {
    "text": "now we are looking on the disk schedule strategy the schedule strategy is",
    "start": "684160",
    "end": "689279"
  },
  {
    "text": "from that on the telemeter where scheduling use",
    "start": "689279",
    "end": "694320"
  },
  {
    "text": "the node affinity rules so it doesn't communicate directly with the default schedule in this case you have any other",
    "start": "694320",
    "end": "701120"
  },
  {
    "text": "parameter files you have no way to link it using the node affinity uh rules",
    "start": "701120",
    "end": "706240"
  },
  {
    "text": "so if you have an apart that eventually break those rules the pod",
    "start": "706240",
    "end": "712720"
  },
  {
    "text": "going to be uh sorry the node that have the method is being uh broken",
    "start": "712720",
    "end": "718639"
  },
  {
    "text": "going to be labeled so uh it is in this case the heart code labels it just won't receive a let me",
    "start": "718639",
    "end": "725600"
  },
  {
    "text": "say violating so once that label is present on the node",
    "start": "725600",
    "end": "730880"
  },
  {
    "text": "we can use the other components uh external components in this case we use a",
    "start": "730880",
    "end": "736240"
  },
  {
    "text": "cabinet scheduler that identifies that the node there is one nodes that broken the node",
    "start": "736240",
    "end": "743040"
  },
  {
    "text": "definitive rules and proceeding that way you can go uh to infect the party risk and so on so",
    "start": "743040",
    "end": "750399"
  },
  {
    "text": "the last strategies that one recent future added to",
    "start": "750399",
    "end": "756880"
  },
  {
    "text": "the to our application that is a labeling",
    "start": "756880",
    "end": "762320"
  },
  {
    "text": "basically uh it's worked like a discarded strategy but the main difference here is",
    "start": "762320",
    "end": "767519"
  },
  {
    "text": "that you can customize the user can customize the type of the label that",
    "start": "767519",
    "end": "773360"
  },
  {
    "text": "you want a node receive if you break that rules so uh",
    "start": "773360",
    "end": "779040"
  },
  {
    "text": "you can think like that that you are transferring information uh",
    "start": "779040",
    "end": "784240"
  },
  {
    "text": "some metric to the north so why this is important this kind of flexibility um",
    "start": "784240",
    "end": "791519"
  },
  {
    "text": "that that would come from one the collaboration across our our",
    "start": "791519",
    "end": "796720"
  },
  {
    "text": "company so we developed together with the attenuation that where they are interesting use case relatable gpu so",
    "start": "796720",
    "end": "804800"
  },
  {
    "text": "which they they have also gpos scheduling that another open source project that is we",
    "start": "804800",
    "end": "811440"
  },
  {
    "text": "work together with telemeter west scan so let's let's imagine uh sorry there's",
    "start": "811440",
    "end": "818560"
  },
  {
    "text": "that kind of fault here now the last image we have across and this cluster have a node and this",
    "start": "818560",
    "end": "824639"
  },
  {
    "text": "node have attached supposed to gpus now",
    "start": "824639",
    "end": "830240"
  },
  {
    "text": "imagine that we have you're able to write a telemeter with the policy",
    "start": "830240",
    "end": "835279"
  },
  {
    "text": "that tell you that if your metric is related like",
    "start": "835279",
    "end": "841040"
  },
  {
    "text": "might say power consumption break the rules so if you have one gpu that break the hose and you have a",
    "start": "841040",
    "end": "847760"
  },
  {
    "text": "workload that tells you that one part per request one gpu",
    "start": "847760",
    "end": "853600"
  },
  {
    "text": "you have one people that have a problematic concern a lot of power",
    "start": "853600",
    "end": "859680"
  },
  {
    "text": "but the other gpu is working fine if you use this schedule",
    "start": "859680",
    "end": "865360"
  },
  {
    "text": "that node that have those distributes going to mark as a violator and",
    "start": "865360",
    "end": "871040"
  },
  {
    "text": "all the parts going to be discovered and evicted so that's not a",
    "start": "871040",
    "end": "877760"
  },
  {
    "text": "a suitable situation so and we we create this new feature that are",
    "start": "877760",
    "end": "883600"
  },
  {
    "text": "customized in the label that way we can transfer the information just tell and label the node that have those two",
    "start": "883600",
    "end": "890160"
  },
  {
    "text": "gpus which one gpu will have a high power consumer they say",
    "start": "890160",
    "end": "895440"
  },
  {
    "text": "you can write a kind of the label let's say disable card gpu one or something like that and then once that is you have",
    "start": "895440",
    "end": "903120"
  },
  {
    "text": "that information on that node gpu always kind of kick off and do the",
    "start": "903120",
    "end": "908320"
  },
  {
    "text": "business there and make it ready for for the kubernetes to",
    "start": "908320",
    "end": "914880"
  },
  {
    "text": "discuss just that part that use that gpu that has high power consumption that",
    "start": "914880",
    "end": "921680"
  },
  {
    "text": "that's uh yeah i think that's enough we can go for the demo",
    "start": "921680",
    "end": "926800"
  },
  {
    "text": "but we we have to make a kind of deployment those are the three files that we use",
    "start": "926800",
    "end": "933759"
  },
  {
    "text": "normally used when we work with the discarder community schedule so",
    "start": "933759",
    "end": "939360"
  },
  {
    "text": "you can see on the board there all the sections that you are related so you you you have the uh",
    "start": "939360",
    "end": "946720"
  },
  {
    "text": "the deployment file in this case we have an application simple nginx and uh we're",
    "start": "946720",
    "end": "951920"
  },
  {
    "text": "going to deploy five cops or that fight parts and you have that the link",
    "start": "951920",
    "end": "958079"
  },
  {
    "text": "to the telemetry so you identify that each one of those parts are going to be",
    "start": "958079",
    "end": "963199"
  },
  {
    "text": "associated to a policy related gs and the other section it says where they",
    "start": "963199",
    "end": "969120"
  },
  {
    "text": "know the fins who's coming out because we have a uh in all gis policy discovery",
    "start": "969120",
    "end": "975839"
  },
  {
    "text": "uh sorry the labeling strategy strategy and the final one the",
    "start": "975839",
    "end": "981199"
  },
  {
    "text": "simple pulse for the combination of the scheduler that just tell you to invict the party that",
    "start": "981199",
    "end": "987120"
  },
  {
    "text": "violating all the finished rules so um so",
    "start": "987120",
    "end": "993040"
  },
  {
    "text": "apologize if some demo effect happen here even if it's a recorder but okay",
    "start": "993120",
    "end": "999759"
  },
  {
    "text": "let's start here um this example here we have a closer that",
    "start": "999759",
    "end": "1006560"
  },
  {
    "text": "composes the three workers under one control brand they normally stand so the only the work on those received parts",
    "start": "1006560",
    "end": "1013279"
  },
  {
    "text": "so we have the the right side is you have the metrics associated to each one of the workers",
    "start": "1013279",
    "end": "1020079"
  },
  {
    "text": "and on the further right you have the excuse me the labels",
    "start": "1020079",
    "end": "1027360"
  },
  {
    "text": "the labels associate for each one of those notes now",
    "start": "1027360",
    "end": "1033038"
  },
  {
    "text": "on the top panel is where the you're going to observe the all the resources being called uh during the",
    "start": "1033039",
    "end": "1039839"
  },
  {
    "text": "demo so like the pods that have been deploying and all all the [Music]",
    "start": "1039839",
    "end": "1045199"
  },
  {
    "text": "all the operations that happen and that the middle is where you have the information they show the events which",
    "start": "1045199",
    "end": "1051200"
  },
  {
    "text": "you want those steps on the bottom and eventually you don't see part of the logs",
    "start": "1051200",
    "end": "1056480"
  },
  {
    "text": "so we already have deployed the telemetry we're scheduling under the policy the",
    "start": "1056480",
    "end": "1061520"
  },
  {
    "text": "police again has been shown on the left side so it composed for this number",
    "start": "1061520",
    "end": "1068080"
  },
  {
    "text": "three uh strategy again down schedule standalone and labeling so each one again have your own",
    "start": "1068080",
    "end": "1075360"
  },
  {
    "text": "metric rules so um",
    "start": "1075360",
    "end": "1080480"
  },
  {
    "text": "again don't schedule you're going to tell the chairs that to future not evaluate their result",
    "start": "1080480",
    "end": "1087520"
  },
  {
    "text": "we can see that working on trees that have that help northern health matter the health metric",
    "start": "1087520",
    "end": "1094400"
  },
  {
    "text": "name that is equal to one that's the method that that current state is showing",
    "start": "1094400",
    "end": "1099520"
  },
  {
    "text": "so you look around the on the telematics policy you have that that",
    "start": "1099520",
    "end": "1106799"
  },
  {
    "text": "that exactly that value should not be that in that case that node will be put out on the in the schedule process",
    "start": "1106799",
    "end": "1114000"
  },
  {
    "text": "so um therefore we'll have three results filter out",
    "start": "1114000",
    "end": "1120000"
  },
  {
    "text": "um it's okay so the next the next one",
    "start": "1121440",
    "end": "1126880"
  },
  {
    "text": "is um excuse me",
    "start": "1126880",
    "end": "1133280"
  },
  {
    "text": "uh they schedule a method strategy so as i mentioned before this",
    "start": "1133280",
    "end": "1138640"
  },
  {
    "text": "is based on the priority and the metric used here that simply temperatures",
    "start": "1138640",
    "end": "1144240"
  },
  {
    "text": "and gone selected between those nodes the the works that have lowest temperature they want to be",
    "start": "1144240",
    "end": "1150720"
  },
  {
    "text": "with the going to receive majority of the pods in this case",
    "start": "1150720",
    "end": "1157600"
  },
  {
    "text": "uh we only have five so they all then gone to land and the node that have the",
    "start": "1157600",
    "end": "1162880"
  },
  {
    "text": "highest priority the lowest temperature that the work they would choose so they deployed our demo and we can see",
    "start": "1162880",
    "end": "1170480"
  },
  {
    "text": "that the container created and so on and that you have all the file being up running on the work too",
    "start": "1170480",
    "end": "1177280"
  },
  {
    "text": "here which in example all the the logs so the logs on the chairs which are the",
    "start": "1177280",
    "end": "1183360"
  },
  {
    "text": "steps each step did that happen um i think it's a pretty clear debt so",
    "start": "1183360",
    "end": "1188880"
  },
  {
    "text": "in that fine what the police the strategy police you know the filtering part and then go to",
    "start": "1188880",
    "end": "1195280"
  },
  {
    "text": "uh select what nodes are available that doesn't break the don't scan the rule",
    "start": "1195280",
    "end": "1201360"
  },
  {
    "text": "and then go to the prioritization part that is basically going to relate to the scheduling method strategy",
    "start": "1201360",
    "end": "1207919"
  },
  {
    "text": "and give the rank and select based on this rank sent back to the full",
    "start": "1207919",
    "end": "1213280"
  },
  {
    "text": "schedule okay what should they have the hyper arts and that way we go okay",
    "start": "1213280",
    "end": "1218799"
  },
  {
    "text": "now um",
    "start": "1218799",
    "end": "1223279"
  },
  {
    "text": "we have now five parts running on the walk too so there is reason to to think that okay so",
    "start": "1223919",
    "end": "1231440"
  },
  {
    "text": "we have one method that's related on the memory use so",
    "start": "1231440",
    "end": "1236720"
  },
  {
    "text": "what we expected that the value matrix for them the the the nodes that have",
    "start": "1236720",
    "end": "1242240"
  },
  {
    "text": "their map should increase in case on the on the walker two",
    "start": "1242240",
    "end": "1247840"
  },
  {
    "text": "because we uh we spent yeah we have more positive than that so we do a little bit of the push",
    "start": "1247840",
    "end": "1254640"
  },
  {
    "text": "that in order just to go above the threshold uh related the labeling strategy",
    "start": "1254640",
    "end": "1261440"
  },
  {
    "text": "so we saw just saw that the labeling happening there oh sorry",
    "start": "1261440",
    "end": "1267679"
  },
  {
    "text": "so the labeling happened in that and then we take a look on the logs and it's just",
    "start": "1267679",
    "end": "1272799"
  },
  {
    "text": "saying that okay the metric provider on the walker tube just crossed over the threshold and for",
    "start": "1272799",
    "end": "1279840"
  },
  {
    "text": "the label strategy break the dead and then uh",
    "start": "1279840",
    "end": "1285280"
  },
  {
    "text": "here's going to write off the label that have been described on the policy to the",
    "start": "1285280",
    "end": "1290480"
  },
  {
    "text": "to the node that broken that rules so just continue that and that's that's",
    "start": "1290480",
    "end": "1296799"
  },
  {
    "text": "what is actually just describing on the log",
    "start": "1296799",
    "end": "1302600"
  },
  {
    "text": "okay so that that's what is at the moment so um",
    "start": "1308720",
    "end": "1315440"
  },
  {
    "text": "we have what we have now two nodes that are not able to receive so one",
    "start": "1315679",
    "end": "1320960"
  },
  {
    "text": "because the breaker they don't scatter us and uh the other one that's because then they",
    "start": "1320960",
    "end": "1327440"
  },
  {
    "text": "are finished rules and you know able to receive a lot so what we expected just one left and if",
    "start": "1327440",
    "end": "1333840"
  },
  {
    "text": "we increase the number of the parts to be deploying on the uh in the closets or just not",
    "start": "1333840",
    "end": "1340240"
  },
  {
    "text": "upstairs and they should end up as just show that on the walker",
    "start": "1340240",
    "end": "1347600"
  },
  {
    "text": "on the or on the first one so and yeah so that again so let's just",
    "start": "1347600",
    "end": "1353039"
  },
  {
    "text": "show the process how this one and you have the label on the work and we",
    "start": "1353039",
    "end": "1359600"
  },
  {
    "text": "get what respect than that um we still have parts on the work truth so",
    "start": "1359600",
    "end": "1366799"
  },
  {
    "text": "they most likely are not happening that's a little dependent situation and depend on your",
    "start": "1366799",
    "end": "1372240"
  },
  {
    "text": "policy but we we would like to move as that migrate from the more suitable",
    "start": "1372240",
    "end": "1377919"
  },
  {
    "text": "nodes so gs as i mentioned we mentioned before that is not capable to evict the parts",
    "start": "1377919",
    "end": "1383919"
  },
  {
    "text": "of in this case we we have to call the help and help it on the",
    "start": "1383919",
    "end": "1390240"
  },
  {
    "text": "kubernetes schedule and uh once that we have the pulse the config configuration deployed we just deployed the",
    "start": "1390240",
    "end": "1396480"
  },
  {
    "text": "application and you see immediately that this community schedule",
    "start": "1396480",
    "end": "1402720"
  },
  {
    "text": "going to look at and see there are what's uh",
    "start": "1402720",
    "end": "1408080"
  },
  {
    "text": "parts associated on the nodes that break their finished rules and then immediately",
    "start": "1408080",
    "end": "1415360"
  },
  {
    "text": "evicted that so the cabinet schedule work on the cycle so once that you probably immediately do those checks and",
    "start": "1415360",
    "end": "1422640"
  },
  {
    "text": "then yeah so going to put the other parts on the queue",
    "start": "1422640",
    "end": "1428400"
  },
  {
    "text": "in the comments on the cycle to defer scatter and find a better",
    "start": "1428400",
    "end": "1433440"
  },
  {
    "text": "better node available that is work now we don't have any more uh",
    "start": "1433440",
    "end": "1440799"
  },
  {
    "text": "parts running on the orchestra again so no pods so memory should go",
    "start": "1440799",
    "end": "1446880"
  },
  {
    "text": "down the memory using something else so that matters associated should at least go to back on the same levels",
    "start": "1446880",
    "end": "1454480"
  },
  {
    "text": "and when that happen okay uh we don't have a delivering strategy",
    "start": "1454480",
    "end": "1461360"
  },
  {
    "text": "rules and a broken anymore so we expected the label to be removed and that's what happened",
    "start": "1461360",
    "end": "1467120"
  },
  {
    "text": "once that happened uh work to working on you is again background alive",
    "start": "1467120",
    "end": "1474240"
  },
  {
    "text": "so right to receive the parts again but the work now have a 10 points of the same story",
    "start": "1474240",
    "end": "1481919"
  },
  {
    "text": "memory use going to increase so as inspected break the rules because above the",
    "start": "1481919",
    "end": "1487919"
  },
  {
    "text": "threshold on the level stretch uh yes write the labels on that nodes",
    "start": "1487919",
    "end": "1493360"
  },
  {
    "text": "and once the label is there remember the kubernetes scattering now is up running",
    "start": "1493360",
    "end": "1499679"
  },
  {
    "text": "on the cluster they're going to look on the node list and you see there is one node that breaking the affinity rules",
    "start": "1499679",
    "end": "1506159"
  },
  {
    "text": "and the one is started in vector all the parts on that and that",
    "start": "1506159",
    "end": "1511440"
  },
  {
    "text": "node and we scatter to the work that are available",
    "start": "1511440",
    "end": "1517440"
  },
  {
    "text": "and in the class at the moment okay so yeah",
    "start": "1517440",
    "end": "1523600"
  },
  {
    "text": "that's it so",
    "start": "1523600",
    "end": "1527320"
  },
  {
    "text": "[Applause]",
    "start": "1529730",
    "end": "1538369"
  },
  {
    "text": "okay so before we conclude this session just wanted to give give out a bit more",
    "start": "1540960",
    "end": "1546559"
  },
  {
    "text": "details so as i said telemetry aware scheduler is an open source project and",
    "start": "1546559",
    "end": "1551600"
  },
  {
    "text": "above you can find the link to our public repo if you're interested you can",
    "start": "1551600",
    "end": "1556720"
  },
  {
    "text": "look look at the repo push pr's or issues if you see anything that you would want to work on",
    "start": "1556720",
    "end": "1563760"
  },
  {
    "text": "or fix if you're also if you're interested about features you can reach out to us via",
    "start": "1563760",
    "end": "1569600"
  },
  {
    "text": "the kubernetes slack room or emails we have our emails in the bottom right you can also find us in our booth so feel",
    "start": "1569600",
    "end": "1575279"
  },
  {
    "text": "free to stop by and talk to us if you're um interested about learning a bit more",
    "start": "1575279",
    "end": "1580880"
  },
  {
    "text": "like architecture wise a bit more details you have links to 12 hour white papers so feel free to check them out if",
    "start": "1580880",
    "end": "1587120"
  },
  {
    "text": "you want more details architecturally this is it in terms of presentation thank you very much for for your",
    "start": "1587120",
    "end": "1593840"
  },
  {
    "text": "attention and i'm going to open it up for questions if you have any",
    "start": "1593840",
    "end": "1599039"
  },
  {
    "text": "thank you",
    "start": "1599039",
    "end": "1601440"
  },
  {
    "text": "hello i'm here over here i'm sorry the no problem",
    "start": "1606880",
    "end": "1614240"
  },
  {
    "text": "what you show us scheduler has now a dependency with the",
    "start": "1614799",
    "end": "1620880"
  },
  {
    "text": "metrics pipeline if the matrix pipeline fails will",
    "start": "1620880",
    "end": "1626559"
  },
  {
    "text": "scheduling be blocked or is it able to still scale ignoring the telemetry of our scheduling",
    "start": "1626559",
    "end": "1634799"
  },
  {
    "text": "i mean we now have a dependency of the metrics pipeline is it a hard dependency is it",
    "start": "1635279",
    "end": "1642240"
  },
  {
    "text": "optional i don't know i i would say it might not able to react",
    "start": "1642240",
    "end": "1648559"
  },
  {
    "text": "as fast so you might need to wait a bit until the matrix come comes back online but i think i need to test a bit more",
    "start": "1648559",
    "end": "1654399"
  },
  {
    "text": "the scenario i think this this is my opinion so i think you need to wait until it comes back",
    "start": "1654399",
    "end": "1660640"
  },
  {
    "text": "oh okay and do you want to add more details to this okay sorry can you come actually can you come",
    "start": "1662000",
    "end": "1669840"
  },
  {
    "text": "to us once we finish and we can talk about this work because i can't hear you",
    "start": "1669840",
    "end": "1674960"
  },
  {
    "text": "okay i need to know where to look okay or us to look yeah i was going to ask what happens",
    "start": "1674960",
    "end": "1682320"
  },
  {
    "text": "when the telemetry scheduling you have configured for for a deployment",
    "start": "1682320",
    "end": "1688960"
  },
  {
    "text": "or whatever doesn't find any suitable node but you still have available",
    "start": "1688960",
    "end": "1694840"
  },
  {
    "text": "nodes what happens in this scenario",
    "start": "1694840",
    "end": "1699760"
  },
  {
    "text": "so i think it will just look continuously for nodes so if something happens and maybe your node comes back",
    "start": "1700320",
    "end": "1706159"
  },
  {
    "text": "online it might just like continuously look for nodes if if it wasn't maybe you might need to",
    "start": "1706159",
    "end": "1712399"
  },
  {
    "text": "go back and alter your policies at least that's that's what i think it would do",
    "start": "1712399",
    "end": "1719880"
  },
  {
    "text": "tasc yeah so with tas you would get a suggestion of a placement so maybe when",
    "start": "1724320",
    "end": "1731039"
  },
  {
    "text": "that's not running you would just default to whatever the default scheduler wants to do and your policies",
    "start": "1731039",
    "end": "1736480"
  },
  {
    "text": "might not actually the ts policies might not work okay",
    "start": "1736480",
    "end": "1741520"
  },
  {
    "text": "any high so so the metrics uh pipeline it generates",
    "start": "1741520",
    "end": "1748080"
  },
  {
    "text": "new metrics or you also work with default metrics and the telemetry policy can also be applied on the default",
    "start": "1748080",
    "end": "1754720"
  },
  {
    "text": "metrics from the nodes or any custom metrics that are generated like",
    "start": "1754720",
    "end": "1760000"
  },
  {
    "text": "via script or manually can you okay yeah",
    "start": "1760000",
    "end": "1765360"
  },
  {
    "text": "so you hear me so basically you can use uh",
    "start": "1765360",
    "end": "1770640"
  },
  {
    "text": "any metrics because it depends on your exporter so in this example we use node",
    "start": "1770640",
    "end": "1776000"
  },
  {
    "text": "export for the primitives you can you can use also qb metrics api as well so",
    "start": "1776000",
    "end": "1782080"
  },
  {
    "text": "is is up to you to select what type what type of the method you are interested so",
    "start": "1782080",
    "end": "1788320"
  },
  {
    "text": "collected also can be used as also okay thank you so i'm going to read out a question",
    "start": "1788320",
    "end": "1796240"
  },
  {
    "text": "from the online users does tis work well with topology spread",
    "start": "1796240",
    "end": "1801440"
  },
  {
    "text": "constraints to ensure an even distribution of application pods",
    "start": "1801440",
    "end": "1808039"
  },
  {
    "text": "so they even distribute distribution on the deployment i assume",
    "start": "1812640",
    "end": "1819840"
  },
  {
    "text": "i guess they're asking yeah deployment or stateful set or",
    "start": "1819840",
    "end": "1824960"
  },
  {
    "text": "um yeah i can't i can't",
    "start": "1826080",
    "end": "1831200"
  },
  {
    "text": "yeah we have to think about that this is a good question um yeah maybe maybe follow up in slack afterwards yeah with",
    "start": "1831200",
    "end": "1837120"
  },
  {
    "text": "you again whoever wrote can ping us on slack yeah with the question yeah sure we'll try our best answer okay thank you",
    "start": "1837120",
    "end": "1844799"
  },
  {
    "text": "we got a couple more minutes in the room uh i think he was first",
    "start": "1844799",
    "end": "1851840"
  },
  {
    "text": "uh hello i have a small question so what will happen after our port is scheduled so",
    "start": "1853919",
    "end": "1860000"
  },
  {
    "text": "when it's uh during uh scheduling the port is placed one of the nodes and metric",
    "start": "1860000",
    "end": "1865600"
  },
  {
    "text": "changes will it port will be rescheduled during execution or it's ignored during",
    "start": "1865600",
    "end": "1870720"
  },
  {
    "text": "execution so your question is to know what happened",
    "start": "1870720",
    "end": "1877360"
  },
  {
    "text": "on the pod after the discovery uh yes true so actually default scheduler usually check this rules once you decide",
    "start": "1877360",
    "end": "1884480"
  },
  {
    "text": "whether to schedule port and it ignores changes further so in this case a metric is always changing and during execution it changed",
    "start": "1884480",
    "end": "1892240"
  },
  {
    "text": "what will happen okay i think there is a time related on that",
    "start": "1892240",
    "end": "1898559"
  },
  {
    "text": "so it depends on the how how how the process it takes and",
    "start": "1898559",
    "end": "1905200"
  },
  {
    "text": "if eventually yeah if you get that time where the deposit has",
    "start": "1905200",
    "end": "1910399"
  },
  {
    "text": "been discharged and this guy definitely started getting on that it might have that kind of conflict yeah",
    "start": "1910399",
    "end": "1916880"
  },
  {
    "text": "it's something that we haven't fought because we basically use this schedule just from the distance",
    "start": "1916880",
    "end": "1922720"
  },
  {
    "text": "in terms of to show the defectiveness of the of the application so but yeah we",
    "start": "1922720",
    "end": "1930320"
  },
  {
    "text": "is thank you we'll take a look at that as well okay i think i think we have time for",
    "start": "1930320",
    "end": "1936000"
  },
  {
    "text": "one more and hello so my question is is this",
    "start": "1936000",
    "end": "1941360"
  },
  {
    "text": "scheduler going to respect the pdb constraints that we have for a report",
    "start": "1941360",
    "end": "1946480"
  },
  {
    "text": "for the deployment can you repeat that can you repeat the question yeah is this a scheduler going",
    "start": "1946480",
    "end": "1952399"
  },
  {
    "text": "to respect the restrictions set by a pdb by a disruption budget",
    "start": "1952399",
    "end": "1958399"
  },
  {
    "text": "how is that going how i mean how is this going to work together with a pdb set for a for about for a deployment or a",
    "start": "1958399",
    "end": "1964240"
  },
  {
    "text": "pod i don't think we tested that approach i",
    "start": "1964240",
    "end": "1969760"
  },
  {
    "text": "don't know what the pdp is done i think we need to look a bit more into this because i don't think i understand",
    "start": "1969760",
    "end": "1975760"
  },
  {
    "text": "what are at least i'm i'm not able to understand what you're asking me sorry sorry i mean a pub disruption budget",
    "start": "1975760",
    "end": "1981679"
  },
  {
    "text": "it's a configuration or a policy that you define in kubernetes in order to for uh to restrict how kubernetes a big spot",
    "start": "1981679",
    "end": "1989760"
  },
  {
    "text": "bots from a node or the number of or the minimum number of pots that you have to run for a certain application",
    "start": "1989760",
    "end": "1996399"
  },
  {
    "text": "so i'm asking that because if the scheduler is going to move bots around it could actually",
    "start": "1996399",
    "end": "2001760"
  },
  {
    "text": "violate the restrictions set by the pdb or the constraints",
    "start": "2001760",
    "end": "2008960"
  },
  {
    "text": "does that make sense not quite i think i need to follow up sorry please",
    "start": "2010000",
    "end": "2015760"
  },
  {
    "text": "thank you okay well thank you very much and that's",
    "start": "2015760",
    "end": "2020799"
  },
  {
    "text": "we're at time thank you thank you",
    "start": "2020799",
    "end": "2025799"
  }
]
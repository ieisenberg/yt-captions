[
  {
    "text": "okay I think we can we can start um so let me introduce myself I'm my",
    "start": "179",
    "end": "7440"
  },
  {
    "text": "name is Mikhail I'm a software engineer working for Google in the GK batch team",
    "start": "7440",
    "end": "12540"
  },
  {
    "text": "and today I'm going to co-present with Vanessa from Lawrence Livermore National Laboratory who unfortunately cannot be",
    "start": "12540",
    "end": "21119"
  },
  {
    "text": "with me on the stage but um I will play her part and she will be",
    "start": "21119",
    "end": "27240"
  },
  {
    "text": "later for your questions on the slack so let me begin with a little bit of",
    "start": "27240",
    "end": "33540"
  },
  {
    "text": "History like all of you now like kubernetes was built originally with um",
    "start": "33540",
    "end": "39180"
  },
  {
    "text": "with the focus on Long running and stateless applications and naturally there was a lot of feature gaps in the",
    "start": "39180",
    "end": "47219"
  },
  {
    "text": "early job API to run batch workloads and but over the years",
    "start": "47219",
    "end": "54719"
  },
  {
    "text": "users who wanted to use batch were still very determined to run batch on",
    "start": "54719",
    "end": "60300"
  },
  {
    "text": "kubernetes even at the cost of worker runs of or re-implementing features",
    "start": "60300",
    "end": "65760"
  },
  {
    "text": "which should have been provided by the call kubernetes but this leads to a lot of fragmentation",
    "start": "65760",
    "end": "73380"
  },
  {
    "text": "in the in the ecosystem of batch so um we would like to improve the situation",
    "start": "73380",
    "end": "80220"
  },
  {
    "text": "and reduce the fragmentation so that's why we started the batch working group initiative and we work under its",
    "start": "80220",
    "end": "87900"
  },
  {
    "text": "umbrella to bring all the necessary features and Primitives to the Core kubernetes",
    "start": "87900",
    "end": "94619"
  },
  {
    "text": "so we believe that this will improve workload profitability between different",
    "start": "94619",
    "end": "99659"
  },
  {
    "text": "Frameworks and between different Cloud providers and also this will allow",
    "start": "99659",
    "end": "105119"
  },
  {
    "text": "framework developers to focus on the value added rather than the implementation of the core functionality",
    "start": "105119",
    "end": "113040"
  },
  {
    "text": "okay so let's take a look at what has been done on that front so here you can see on the left the list",
    "start": "113040",
    "end": "121140"
  },
  {
    "text": "of problems and on the right the list of new features that address these problems in the recent releases of kubernetes",
    "start": "121140",
    "end": "128759"
  },
  {
    "text": "so the list and go passes many areas you can see for example improved handling of",
    "start": "128759",
    "end": "135840"
  },
  {
    "text": "periodic jobs or the job suspense field which is a stepping stone for job",
    "start": "135840",
    "end": "141599"
  },
  {
    "text": "queuing something that Aldo talked at length but in this talk I would like to focus",
    "start": "141599",
    "end": "147239"
  },
  {
    "text": "on two features that is index job and portfolio policy",
    "start": "147239",
    "end": "152340"
  },
  {
    "text": "um so let me first introduce index job by the use case of processing a large data set so if we have a large data set",
    "start": "152340",
    "end": "159720"
  },
  {
    "text": "we naturally want to split it into smaller chunks and process the data set in parallel by multiple workers in the",
    "start": "159720",
    "end": "168060"
  },
  {
    "text": "world of kubernetes represented by parts but the problem in the early API and",
    "start": "168060",
    "end": "175319"
  },
  {
    "text": "like the recommended approach was to create and maintain your own queue of",
    "start": "175319",
    "end": "180599"
  },
  {
    "text": "tasks however if the data set isn't changing that we can do have a simpler",
    "start": "180599",
    "end": "185819"
  },
  {
    "text": "solution and just assign the specific check of the data set based on the worker index and this is",
    "start": "185819",
    "end": "192180"
  },
  {
    "text": "essentially what the index job gives us so we simply set the completion completion mode as shown in the yaml on",
    "start": "192180",
    "end": "200220"
  },
  {
    "text": "the right as indexed and then the um environment variable is in which the",
    "start": "200220",
    "end": "207120"
  },
  {
    "text": "index is injected into the worker process which can be then used by the worker to load a specific chunk of the",
    "start": "207120",
    "end": "213659"
  },
  {
    "text": "data set to so that makes it simple and also if we add another requirement",
    "start": "213659",
    "end": "222299"
  },
  {
    "text": "and that the pots need to communicate well while processing the data set and",
    "start": "222299",
    "end": "227400"
  },
  {
    "text": "then index drop also makes it simpler because if you create the index drop as shown on",
    "start": "227400",
    "end": "234000"
  },
  {
    "text": "the left and then match it with the Headless Service as shown in in the",
    "start": "234000",
    "end": "239040"
  },
  {
    "text": "middle in the arm then all the parts will have the stable DNS names and predictable up front",
    "start": "239040",
    "end": "245879"
  },
  {
    "text": "and so this the DNS names will include the job named the worker index and the",
    "start": "245879",
    "end": "251340"
  },
  {
    "text": "service name and this makes it convenient to to set up distributed",
    "start": "251340",
    "end": "258079"
  },
  {
    "text": "network of pods um and yeah in the use cases as we are",
    "start": "258079",
    "end": "264180"
  },
  {
    "text": "about to see um okay so important part of the talk is",
    "start": "264180",
    "end": "270660"
  },
  {
    "text": "to I would like to present selection of use cases where the index job feature",
    "start": "270660",
    "end": "276180"
  },
  {
    "text": "Finds Its use a deepmind and here I want to say big thanks to George and Lena for",
    "start": "276180",
    "end": "282900"
  },
  {
    "text": "sharing the insights and job should also be available on slack at the end of the",
    "start": "282900",
    "end": "288840"
  },
  {
    "text": "session if you have some questions so the use case the first use case that",
    "start": "288840",
    "end": "294180"
  },
  {
    "text": "I want to present is we want to train a machine learning model and we want to train it on a large data",
    "start": "294180",
    "end": "301740"
  },
  {
    "text": "set and in order to make the training fast we need to check the data set across many devices while the devices",
    "start": "301740",
    "end": "309540"
  },
  {
    "text": "are split between multiple nodes and each node also can have multiple devices",
    "start": "309540",
    "end": "314600"
  },
  {
    "text": "and inside the devices are typically GPU or TPU",
    "start": "314600",
    "end": "321540"
  },
  {
    "text": "so let's take a look how index drop can be helpful here so in the first step we create",
    "start": "321540",
    "end": "328020"
  },
  {
    "text": "um one pod per node and here one part",
    "start": "328020",
    "end": "333600"
  },
  {
    "text": "with the zero index is a distinguished pod called coordinator",
    "start": "333600",
    "end": "338660"
  },
  {
    "text": "so because as I said before it has a stable DNS name predictable front while",
    "start": "338660",
    "end": "345419"
  },
  {
    "text": "creating the other reports we can make it makes it easy so other pods",
    "start": "345419",
    "end": "351600"
  },
  {
    "text": "register their presence at the at the start of of the system and then the",
    "start": "351600",
    "end": "357479"
  },
  {
    "text": "coordinator can set up the distributed environment so in particular it will await for all",
    "start": "357479",
    "end": "364020"
  },
  {
    "text": "the pods to be ready and all the communications channel to be established between the parts",
    "start": "364020",
    "end": "371100"
  },
  {
    "text": "um so what once we have that all the Bots can load the chart of the big data",
    "start": "371100",
    "end": "376979"
  },
  {
    "text": "set and split into um into smaller mini batches corresponding",
    "start": "376979",
    "end": "382380"
  },
  {
    "text": "loaded on the particular devices and along with the data we also load the",
    "start": "382380",
    "end": "389400"
  },
  {
    "text": "model and here we on the devices and we here we have the simplifying assumption that the model gets fit into memory of a",
    "start": "389400",
    "end": "397259"
  },
  {
    "text": "single device and in practice this is might be more complex than in this case",
    "start": "397259",
    "end": "402560"
  },
  {
    "text": "once we have that uh the devices trained on the low that mini",
    "start": "402560",
    "end": "410400"
  },
  {
    "text": "batches of the data and the communication channels are used to exchange partial results of the training",
    "start": "410400",
    "end": "416220"
  },
  {
    "text": "of the on the smaller parts of chunks of the data set so that once the results",
    "start": "416220",
    "end": "422220"
  },
  {
    "text": "access changed we obtain a single model that is trained on the entire data set",
    "start": "422220",
    "end": "430460"
  },
  {
    "text": "um if you are interested then I would also like to refer you to some code",
    "start": "431220",
    "end": "437039"
  },
  {
    "text": "samples inspired by this use case and that I prepared both for pythons and Jax",
    "start": "437039",
    "end": "443340"
  },
  {
    "text": "ml libraries um okay so in the next use case",
    "start": "443340",
    "end": "449699"
  },
  {
    "text": "we want to simulate an agent in a virtual reality or environment",
    "start": "449699",
    "end": "455400"
  },
  {
    "text": "for the purpose of reinforcement learning so in this setup the agent",
    "start": "455400",
    "end": "461720"
  },
  {
    "text": "performs different actions on the environment and also it can observe the",
    "start": "461720",
    "end": "467940"
  },
  {
    "text": "environment to update its knowledge of the world and for some achievements in the environment it collects Rewards",
    "start": "467940",
    "end": "475580"
  },
  {
    "text": "so the assumption is that by correlating the actions with the",
    "start": "475580",
    "end": "480740"
  },
  {
    "text": "rewards we can make the new generation of the agent that is more likely to",
    "start": "480740",
    "end": "485819"
  },
  {
    "text": "repeat the actions that led to Rewards however in practice we don't want to run",
    "start": "485819",
    "end": "493560"
  },
  {
    "text": "just a single simulation but we want to run money and the reasons include for example just",
    "start": "493560",
    "end": "499440"
  },
  {
    "text": "that we want to collect more data so that we can make some of the less likely trajectories",
    "start": "499440",
    "end": "505819"
  },
  {
    "text": "also to be explored we also want to account for like",
    "start": "505819",
    "end": "511339"
  },
  {
    "text": "variation in the initial conditions or we also want to test agent for with",
    "start": "511339",
    "end": "516899"
  },
  {
    "text": "different Tendencies for exploration versus execution um so again let's take a look at how we",
    "start": "516899",
    "end": "524039"
  },
  {
    "text": "can set up this with index drop so the assumption is that we have the agents",
    "start": "524039",
    "end": "529380"
  },
  {
    "text": "and environments containerized then here we have two index jobs the one will",
    "start": "529380",
    "end": "535260"
  },
  {
    "text": "represent multiple players and the other multiple environments and then by using again the feature of",
    "start": "535260",
    "end": "543180"
  },
  {
    "text": "stable and predictable DNS names the agents can connect easily to the",
    "start": "543180",
    "end": "548660"
  },
  {
    "text": "environment with the same index and create the communication channel",
    "start": "548660",
    "end": "554040"
  },
  {
    "text": "that will be used for for the simulation so once we have that the simulation can",
    "start": "554040",
    "end": "560640"
  },
  {
    "text": "start and actions observations rewards can be passed",
    "start": "560640",
    "end": "565980"
  },
  {
    "text": "over the course of the simulation and this is nicely abstracted out by the open source Library by deepmind",
    "start": "565980",
    "end": "574920"
  },
  {
    "text": "and if you are interested I would also like to refer you to the code samples that I prepared for the simple catch",
    "start": "574920",
    "end": "583860"
  },
  {
    "text": "game so what you can see on the GIF on the right is an example for the",
    "start": "583860",
    "end": "589380"
  },
  {
    "text": "trajectory in this game played for a single index",
    "start": "589380",
    "end": "594560"
  },
  {
    "text": "okay so I would like to conclude this part by saying that while you can think of many workarounds and they will work",
    "start": "594660",
    "end": "602100"
  },
  {
    "text": "to some extent so this is also similar to um what was what happened here so prior",
    "start": "602100",
    "end": "609360"
  },
  {
    "text": "to index job deepmind actually use stateful sets but there were some problems with them so one I mean the",
    "start": "609360",
    "end": "617220"
  },
  {
    "text": "root cause was actually the lack of the notion of completion that is characteristic to all batch workloads",
    "start": "617220",
    "end": "624779"
  },
  {
    "text": "and because of the lack of denotion of completion parts so for example in this use case of the",
    "start": "624779",
    "end": "631680"
  },
  {
    "text": "simulation some simulation can end earlier but the pots would still continue running consuming resources and",
    "start": "631680",
    "end": "637920"
  },
  {
    "text": "also you would need to have some custom code to detect when the simulation is over and also there was no like",
    "start": "637920",
    "end": "645180"
  },
  {
    "text": "um Native handsome to to limit the number of failures in case of a software",
    "start": "645180",
    "end": "652800"
  },
  {
    "text": "back let's say so index drops nicely nicely fits this this use case",
    "start": "652800",
    "end": "660920"
  },
  {
    "text": "um okay and now is the second part of the talk when I will",
    "start": "661380",
    "end": "666800"
  },
  {
    "text": "Vanessa will play about I will play Vanessa stock when she talks about flux",
    "start": "666800",
    "end": "672480"
  },
  {
    "text": "operator I will also make it clear that she will",
    "start": "672480",
    "end": "678300"
  },
  {
    "text": "be or already is even at cncf slack channel so if you think of some",
    "start": "678300",
    "end": "683880"
  },
  {
    "text": "questions that you want to Target to Vanessa or or George then you will you",
    "start": "683880",
    "end": "689880"
  },
  {
    "text": "should be able to find them on slack after the session bye fellow kubernetes I'm Vanessa socket",
    "start": "689880",
    "end": "696300"
  },
  {
    "text": "and I'm going to be talking about an example use case for index jobs a project called the flux operator that",
    "start": "696300",
    "end": "702360"
  },
  {
    "text": "we've been working on at Lawrence Livermore National Lab let's get started once upon a time there was a resource",
    "start": "702360",
    "end": "710100"
  },
  {
    "text": "manager named flux framework and flux lived in HPC land along with the other",
    "start": "710100",
    "end": "715740"
  },
  {
    "text": "resource managers a few container Technologies and of course assisted men",
    "start": "715740",
    "end": "720839"
  },
  {
    "text": "are too and such a really great at a lot of things that you see in this table but a specialty Flex was great at full",
    "start": "720839",
    "end": "727620"
  },
  {
    "text": "hierarchical and graph based Resource Management oh hi there little friend you",
    "start": "727620",
    "end": "733079"
  },
  {
    "text": "have a question what does graph-based resource management mean that is a good question so let's say that we have a",
    "start": "733079",
    "end": "739620"
  },
  {
    "text": "resource allocation with four nodes doesn't matter if this is on HPC or on a kubernetes cluster we could",
    "start": "739620",
    "end": "745500"
  },
  {
    "text": "theoretically install clocks and start what's called a flux instance now the flux instance can actually see the",
    "start": "745500",
    "end": "751500"
  },
  {
    "text": "resources that are available to it and then if we were to create a job launch a job the really cool part of that is that",
    "start": "751500",
    "end": "758459"
  },
  {
    "text": "flux is going to create instances of itself to run on the sub resources and",
    "start": "758459",
    "end": "763500"
  },
  {
    "text": "if you're looking at this and you're like hmm I don't know this looks a little bit coffee you were totally right",
    "start": "763500",
    "end": "768779"
  },
  {
    "text": "we're looking at different depths of a graph where each depth knows about and validates its own resources",
    "start": "768779",
    "end": "775860"
  },
  {
    "text": "so this means that flux is really good at portability you can run it on a",
    "start": "775860",
    "end": "781560"
  },
  {
    "text": "cluster you can run it alongside luster you can run it on a share you can really",
    "start": "781560",
    "end": "787139"
  },
  {
    "text": "run it like anywhere you can run it in a container using fluoxetate total",
    "start": "787139",
    "end": "792959"
  },
  {
    "text": "no-brainer flux is also really good at co-scheduling because it's able to know",
    "start": "792959",
    "end": "798779"
  },
  {
    "text": "the node topology so let's say that you have a workflow that requires gpus to communicate flux can schedule them to be",
    "start": "798779",
    "end": "805320"
  },
  {
    "text": "physically close together flux is also really good at jobs coordination so here",
    "start": "805320",
    "end": "810899"
  },
  {
    "text": "we have the mumi workflow and movie was incredibly heterogeneous in terms of the different needs for the workflow",
    "start": "810899",
    "end": "816899"
  },
  {
    "text": "components flux was able to intelligently schedule them so that those components best match the",
    "start": "816899",
    "end": "822300"
  },
  {
    "text": "resources they needed across a very large set of resources",
    "start": "822300",
    "end": "827660"
  },
  {
    "text": "hang it out over here at HPC it's a cloud land where we have",
    "start": "828360",
    "end": "833940"
  },
  {
    "text": "Technologies like kubernetes and in between them is the fog of War if you've",
    "start": "833940",
    "end": "839880"
  },
  {
    "text": "ever played like a strategy game and in this fog of war the idea is that there's something that needs to be uncovered and",
    "start": "839880",
    "end": "846240"
  },
  {
    "text": "we need to go on a journey and so last year in the lab this is exactly what we",
    "start": "846240",
    "end": "851279"
  },
  {
    "text": "decided to do we said the space between HPC and Cloud",
    "start": "851279",
    "end": "858300"
  },
  {
    "text": "so in this space one of the early projects to emerge is the flux operator and this is going to be what I'm talking",
    "start": "858300",
    "end": "863760"
  },
  {
    "text": "about today okay let's get started on today's Journey starting with a stop at",
    "start": "863760",
    "end": "870300"
  },
  {
    "text": "definition island so probably most of you know what an operator is it is a controller for a",
    "start": "870300",
    "end": "875880"
  },
  {
    "text": "kubernetes cluster to manage objects so the flux operator is a controller that allows us to set up that flux instance",
    "start": "875880",
    "end": "882839"
  },
  {
    "text": "to run across spots and specifically this part here we have a special term",
    "start": "882839",
    "end": "889199"
  },
  {
    "text": "for it we call it a mini cluster and no I don't mean a cluster for ants I",
    "start": "889199",
    "end": "895199"
  },
  {
    "text": "actually mean a set of duplicate pods created by the index job here is where the index drop comes in I in kubernetes",
    "start": "895199",
    "end": "901860"
  },
  {
    "text": "configured to run a flux instance it's really cool conceptually because it's like you have an entire cluster in",
    "start": "901860",
    "end": "909300"
  },
  {
    "text": "the cloud an HPC cluster for you to control so let's say that we start with the kubernetes cluster of size nine we could",
    "start": "909300",
    "end": "916560"
  },
  {
    "text": "theoretically create a mini cluster also of size 9 to maximally maximally utilize",
    "start": "916560",
    "end": "922079"
  },
  {
    "text": "our resources and index zero if that brought that job is called the broker orchestrating the",
    "start": "922079",
    "end": "929339"
  },
  {
    "text": "job the way the pods communicate is via tree based overlay Network",
    "start": "929339",
    "end": "934560"
  },
  {
    "text": "and it has kind of all the niceties that you'd expect so batch jobs queuing",
    "start": "934560",
    "end": "940079"
  },
  {
    "text": "Etc okay basic question how do I submit a job",
    "start": "940079",
    "end": "948120"
  },
  {
    "text": "well if you come visit us in HPC land we're going to give you a command line thing if you're off to Cloudland",
    "start": "948120",
    "end": "953279"
  },
  {
    "text": "somebody's gonna hand you a yaml file so it'll like start off we figured okay we'll just Define what the needs of a",
    "start": "953279",
    "end": "958860"
  },
  {
    "text": "job in a mini cluster.yaml file this is our custom resource definition or crd so",
    "start": "958860",
    "end": "964740"
  },
  {
    "text": "basically you define your job in this file you give it to the flux offer and it's going to create you a mini cluster and",
    "start": "964740",
    "end": "971100"
  },
  {
    "text": "then your job is going to complete run and everything cleans up yay okay I'm ready to make a mini",
    "start": "971100",
    "end": "976680"
  },
  {
    "text": "cluster the next stop in our journey is going to be to experiment Empire where we ask empirical questions like",
    "start": "976680",
    "end": "984000"
  },
  {
    "text": "how well does this work again so we decided we wanted to compare it to",
    "start": "984000",
    "end": "989760"
  },
  {
    "text": "the MPI operator which is another operator in the space that is very similar in nature this started as a part",
    "start": "989760",
    "end": "994980"
  },
  {
    "text": "of the kubeflow project defines an MPI job as its custom resource it has a slightly different design it uses a",
    "start": "994980",
    "end": "1000920"
  },
  {
    "text": "launcher node to coordinate workers via SSH like the flux operator it also uses a dedicated host name and a service for",
    "start": "1000920",
    "end": "1007399"
  },
  {
    "text": "workers and we had to use a modified version to scale to over 100 MPI ranks check out the paper right there if you",
    "start": "1007399",
    "end": "1015259"
  },
  {
    "text": "want to learn more about that okay so like how do they compare so we decided to run an experiment that",
    "start": "1015259",
    "end": "1021980"
  },
  {
    "text": "looked at lamps a molecular simulation on an unoptimized containers this is what that experiment looked like so we",
    "start": "1021980",
    "end": "1028160"
  },
  {
    "text": "needed to use a 65 node cluster to account for that extra launcher node but then we want to test on size of",
    "start": "1028160",
    "end": "1034160"
  },
  {
    "text": "basically 64 down to eight of a mini cluster or just sort of an index job and",
    "start": "1034160",
    "end": "1039860"
  },
  {
    "text": "you can also see the corresponding number of ranks which are the MPI processes okay so we're gonna create that cluster",
    "start": "1039860",
    "end": "1047000"
  },
  {
    "text": "and then for each of the operators we're going to launch a job or create the mini cluster across each of those different sizes we're going to record diamonds and",
    "start": "1047000",
    "end": "1054200"
  },
  {
    "text": "we're going to save the outfits show me the results apparently our sun",
    "start": "1054200",
    "end": "1060200"
  },
  {
    "text": "god at the empirical experiment island is angry right away is on God through the results okay some God has questions",
    "start": "1060200",
    "end": "1066919"
  },
  {
    "text": "if the block the operator mini cluster is created via an index job how well does that scale",
    "start": "1066919",
    "end": "1072260"
  },
  {
    "text": "well here you're looking at mini cluster creation and deletion times so this includes the entire bringing up and then",
    "start": "1072260",
    "end": "1078440"
  },
  {
    "text": "bringing down of the pods but does not include lamps and as we move across the x-axis we move from size eight to size",
    "start": "1078440",
    "end": "1085340"
  },
  {
    "text": "64 so the cluster gets bigger and the really cool part is that this scales really nicely like the index job is",
    "start": "1085340",
    "end": "1091760"
  },
  {
    "text": "doing a great job okay so next question from the Sun God if the flux and MPI operator have",
    "start": "1091760",
    "end": "1098179"
  },
  {
    "text": "different designs like how efficient is each operator setup so because we are comparing apples and oranges here we",
    "start": "1098179",
    "end": "1105260"
  },
  {
    "text": "need to look at them separately starting with the MPI operator here's the end to end time so this is the",
    "start": "1105260",
    "end": "1110840"
  },
  {
    "text": "notification of the job through the timestamp when it's completed this I must note is when the pods are ready to",
    "start": "1110840",
    "end": "1117200"
  },
  {
    "text": "go there's absolutely no waiting for pods here and it does not include the lamps run and what you see is that",
    "start": "1117200",
    "end": "1122900"
  },
  {
    "text": "there's a two-fold increase in time from 5 8 to size 64. now the similar thing we",
    "start": "1122900",
    "end": "1129679"
  },
  {
    "text": "could compare to influx is a flux start this is from like when the broker comes to life through when he shuts down or",
    "start": "1129679",
    "end": "1136460"
  },
  {
    "text": "when it shuts down so this I need to point out that this includes the broker waiting for all the other pods we don't",
    "start": "1136460",
    "end": "1142220"
  },
  {
    "text": "know when the broker is going to come up relative to the other pots it also does not include the lamps from",
    "start": "1142220",
    "end": "1148280"
  },
  {
    "text": "looks pretty okay to me okay so when you remove the setup let's",
    "start": "1148280",
    "end": "1154340"
  },
  {
    "text": "compare finally Apples to Apples how do the run times of these things compare so specifically we're going to look at",
    "start": "1154340",
    "end": "1161660"
  },
  {
    "text": "flux submit versus MPI run this is like if you logged into an HPC Center and you like wanted to run this with blocks",
    "start": "1161660",
    "end": "1167539"
  },
  {
    "text": "directly or with MPI run that's the command you would type and this does include the lamp strung",
    "start": "1167539",
    "end": "1173299"
  },
  {
    "text": "this is like the direct wrapper to Lamps as close as we can get without being inside lamps and I want to point out",
    "start": "1173299",
    "end": "1178940"
  },
  {
    "text": "that for these experiments so we can't really generalize to like everything but for these experiments we did note that",
    "start": "1178940",
    "end": "1185179"
  },
  {
    "text": "the flux operator is consistently faster we think it might be related to the bootstrap or other MPI variables but the",
    "start": "1185179",
    "end": "1192380"
  },
  {
    "text": "difference is like really insignificant okay so when we peel back another layer",
    "start": "1192380",
    "end": "1198500"
  },
  {
    "text": "of the onion and we look just at the lamps time reported by lamps so no wrappers we again see the differences",
    "start": "1198500",
    "end": "1205580"
  },
  {
    "text": "get even smaller but if you kind of visually look at the medians they're about 10 percent lower per flux and we",
    "start": "1205580",
    "end": "1211700"
  },
  {
    "text": "think that like for larger workflows this could potentially translate to cost savings",
    "start": "1211700",
    "end": "1218380"
  },
  {
    "text": "what did we learn well we learned that the index job does allow the mini cluster pods to scale really nicely very",
    "start": "1218600",
    "end": "1226039"
  },
  {
    "text": "happy about that we think that flux is 0mq bootstrap might be related to why",
    "start": "1226039",
    "end": "1231260"
  },
  {
    "text": "it's a little bit faster because the MPI operator uses an SSH based bootstrap",
    "start": "1231260",
    "end": "1236660"
  },
  {
    "text": "more work of course is needed to investigate the performance like folks lamps is not it",
    "start": "1236660",
    "end": "1242660"
  },
  {
    "text": "and this might be the most important point of the entire talk so listen up the architecture of the flux operator",
    "start": "1242660",
    "end": "1250460"
  },
  {
    "text": "allows for multiple jobs to be run on the mini cluster so we avoid the",
    "start": "1250460",
    "end": "1256039"
  },
  {
    "text": "infamous SCD API server bottlenecks and it enables High throughput and finally we want to point out that",
    "start": "1256039",
    "end": "1262340"
  },
  {
    "text": "the MCI operator does require that extra laundry node and it could also benefit from using an index job they seem pretty",
    "start": "1262340",
    "end": "1268280"
  },
  {
    "text": "great to me alrighty we've learned so much at the experiment Empire the flex operator has",
    "start": "1268280",
    "end": "1273620"
  },
  {
    "text": "promised yay but I have some questions I hope you do",
    "start": "1273620",
    "end": "1278840"
  },
  {
    "text": "too we need to take a quick stop at the reality Republic so this question how do I submit a job",
    "start": "1278840",
    "end": "1286280"
  },
  {
    "text": "did you really think to run these experiments we applied like a yaml file like a thousand times do you think",
    "start": "1286280",
    "end": "1291559"
  },
  {
    "text": "that's how I want to spend my work day absolutely not we actually ran these",
    "start": "1291559",
    "end": "1296720"
  },
  {
    "text": "experiments using a tool called flux cloud in flux Cloud you define your experiments in a yellow file yeah I know",
    "start": "1296720",
    "end": "1303860"
  },
  {
    "text": "we can't escape the yaml it's everywhere so you still use it here and then there's just three commands so up",
    "start": "1303860",
    "end": "1310159"
  },
  {
    "text": "applying down to bring everything up run your experiments and then bring everything down so you can kind of like",
    "start": "1310159",
    "end": "1315200"
  },
  {
    "text": "watch work on other things watch your containers logs and have a sandwich have an avocado it's super easy",
    "start": "1315200",
    "end": "1322039"
  },
  {
    "text": "and then when you're done all of your config files data and output are saved for reproducibility",
    "start": "1322039",
    "end": "1329779"
  },
  {
    "text": "everyone take a breath our vision for converge Computing is not",
    "start": "1329799",
    "end": "1334940"
  },
  {
    "text": "applying a billion yaml files it is a comfortable intuitive user interface",
    "start": "1334940",
    "end": "1340700"
  },
  {
    "text": "okay so one really awesome thing about being in reality Republic is we know that reality is informed by Vision so as",
    "start": "1340700",
    "end": "1349100"
  },
  {
    "text": "we're here let's take a ride on the Visionary vehicle we're going to jump on and ask this question how could we",
    "start": "1349100",
    "end": "1355760"
  },
  {
    "text": "submit jobs so I played a fiendish trick on you I didn't tell you that if you don't give a",
    "start": "1355760",
    "end": "1362720"
  },
  {
    "text": "command to the flux operator mini cluster crd the flux operator will actually bring up an interactive",
    "start": "1362720",
    "end": "1369080"
  },
  {
    "text": "interface for you to submit jobs for you to monitor your jobs in a table or check",
    "start": "1369080",
    "end": "1374840"
  },
  {
    "text": "output logs and it also serves a restful API that can be interacted with via SDK",
    "start": "1374840",
    "end": "1380659"
  },
  {
    "text": "and so that is closer to our vision for this future of converged Computing and we also are thinking about some of these",
    "start": "1380659",
    "end": "1386840"
  },
  {
    "text": "other things coming soon to a theater or kubernetes cluster near you so keep the",
    "start": "1386840",
    "end": "1392600"
  },
  {
    "text": "watch out alrighty we're coming in for landing on the Visionary vehicle and we drop down",
    "start": "1392600",
    "end": "1398780"
  },
  {
    "text": "in the collaboration coast and we're met by our friend ly and so one point I really want to",
    "start": "1398780",
    "end": "1404960"
  },
  {
    "text": "impress is that in order to make progress in this converged Computing space it is absolutely essential that we",
    "start": "1404960",
    "end": "1410480"
  },
  {
    "text": "work together and share our ideas and to kick us off on that thread I'm going to share with you some of the design tips",
    "start": "1410480",
    "end": "1416360"
  },
  {
    "text": "that I learned when designing the flux operator okay problem I have a resource",
    "start": "1416360",
    "end": "1422539"
  },
  {
    "text": "manager that communicates via a network is an index job and it's plus a headless",
    "start": "1422539",
    "end": "1429559"
  },
  {
    "text": "Service as a nice solution with fully qualified domain names problem I need specialized logic to",
    "start": "1429559",
    "end": "1436580"
  },
  {
    "text": "generate something you you could run it via an entry point if it's just like a one-time thing you can",
    "start": "1436580",
    "end": "1443000"
  },
  {
    "text": "create an isolated pod to run before the next job and run it that way or you could use a knit containers",
    "start": "1443000",
    "end": "1448400"
  },
  {
    "text": "problem my workers are specialized like they are there's they're not they're special snowflakes that I can't use the",
    "start": "1448400",
    "end": "1454640"
  },
  {
    "text": "next job okay you can use logic that distinguishes",
    "start": "1454640",
    "end": "1459860"
  },
  {
    "text": "based on the index this is exactly what we do for the broker and a cool suggestion is maybe the jobs",
    "start": "1459860",
    "end": "1465799"
  },
  {
    "text": "API could allow us to Define groups with custom logic good work problem I need",
    "start": "1465799",
    "end": "1472640"
  },
  {
    "text": "multi-dependency it's okay so I don't have a great solution for this one but what we're doing is we're starting the",
    "start": "1472640",
    "end": "1477740"
  },
  {
    "text": "container as root getting everything set up and then we're actually running the jobs as a user",
    "start": "1477740",
    "end": "1483380"
  },
  {
    "text": "so this is just the start of mapping out this converged Computing space what's so exciting is that there's more projects",
    "start": "1483380",
    "end": "1489080"
  },
  {
    "text": "to be covered and worked on and we need your help we want you to get involved so please come and find us on GitHub under",
    "start": "1489080",
    "end": "1496039"
  },
  {
    "text": "flux framework the operator project is also there too Lux cloud is under the converged Computing organization and to",
    "start": "1496039",
    "end": "1503120"
  },
  {
    "text": "learn more about Fox check out fluxframework.org and that is how to reach me or any of my",
    "start": "1503120",
    "end": "1510140"
  },
  {
    "text": "clones here apparently via email and I am vsoc on all the social media places thank you to these Cloud providers for",
    "start": "1510140",
    "end": "1517220"
  },
  {
    "text": "supporting us on our adventures and thank you for having me a coupon I had a",
    "start": "1517220",
    "end": "1522679"
  },
  {
    "text": "blast me how back to you",
    "start": "1522679",
    "end": "1527140"
  },
  {
    "text": "thank you Vanessa hold on hold on I mean",
    "start": "1527779",
    "end": "1534100"
  },
  {
    "text": "yes but we there is one more part of the talk um",
    "start": "1534500",
    "end": "1540260"
  },
  {
    "text": "uh okay so I would also like to present the portfolio policy which is the recent",
    "start": "1540260",
    "end": "1546740"
  },
  {
    "text": "feature in job controller currently in beta so if you have some ideas",
    "start": "1546740",
    "end": "1552380"
  },
  {
    "text": "suggestions then also we will welcome your input so let me introduce it by",
    "start": "1552380",
    "end": "1559659"
  },
  {
    "text": "again the use case so here we want to run a batch workload a large comprising",
    "start": "1559659",
    "end": "1567740"
  },
  {
    "text": "hundreds or thousands of of pods and when running such a workload many",
    "start": "1567740",
    "end": "1574279"
  },
  {
    "text": "things can go wrong wrong like pods are pretty much ephemeral so the nodes can",
    "start": "1574279",
    "end": "1579980"
  },
  {
    "text": "go down and or there might be a higher priority workload that would evict your",
    "start": "1579980",
    "end": "1586340"
  },
  {
    "text": "reports so to some extent and this was already addressed in the early job API by the",
    "start": "1586340",
    "end": "1593480"
  },
  {
    "text": "back of limit where you could specify the number of retrace however we if in",
    "start": "1593480",
    "end": "1599059"
  },
  {
    "text": "many use cases like this one it is really not sufficient because there is a",
    "start": "1599059",
    "end": "1604520"
  },
  {
    "text": "trade-off when setting it up so if you set the backup limit to low then you",
    "start": "1604520",
    "end": "1610460"
  },
  {
    "text": "risk that you file the job in case of disruptions such as node going down and so on but if you on the other hand set",
    "start": "1610460",
    "end": "1617360"
  },
  {
    "text": "the back of limit to high then you in case of a software bug uh risked like many unnecessary haters",
    "start": "1617360",
    "end": "1624799"
  },
  {
    "text": "of the board in case of software bugs that translates into costs",
    "start": "1624799",
    "end": "1629840"
  },
  {
    "text": "okay so it sounds simple what we would like to do ideally is to just restart for free in case of disruption",
    "start": "1629840",
    "end": "1636919"
  },
  {
    "text": "or terminate or fail the entire job in case we fed the port fail due to a",
    "start": "1636919",
    "end": "1643100"
  },
  {
    "text": "software back but how to tell a difference so one strategy you can think of and this strategy was implemented by",
    "start": "1643100",
    "end": "1649940"
  },
  {
    "text": "a couple of Frameworks including tensorflow job in kubeflow is to use exit codes so that's natural we have it",
    "start": "1649940",
    "end": "1656600"
  },
  {
    "text": "in status Etc but the problem is that it's not a full solution again because the sum of the exit codes like 137 for C",
    "start": "1656600",
    "end": "1664700"
  },
  {
    "text": "kill are ambiguous so this exit code would be said both in case of disruptions because",
    "start": "1664700",
    "end": "1670100"
  },
  {
    "text": "your grace will now shut down note was going down but it will also be set in if",
    "start": "1670100",
    "end": "1675799"
  },
  {
    "text": "your part has memory leak and exceeded memory limits and was home killed",
    "start": "1675799",
    "end": "1681740"
  },
  {
    "text": "so the solution that we propose is based on the pod conditions",
    "start": "1681740",
    "end": "1688100"
  },
  {
    "text": "in combination with exit codes actually so pod conversations are like in status",
    "start": "1688100",
    "end": "1694279"
  },
  {
    "text": "you have a list of conditions and as an important part so here is an",
    "start": "1694279",
    "end": "1701120"
  },
  {
    "text": "example was an example of the pot condition but as an important part of this effort we reviewed places in the",
    "start": "1701120",
    "end": "1709659"
  },
  {
    "text": "code of kubernetes which evicted pod classified which of them corresponds to",
    "start": "1709659",
    "end": "1716080"
  },
  {
    "text": "disruptions and we modified the displaces of the kubernetes to add the condition that indicates that the pot",
    "start": "1716080",
    "end": "1723380"
  },
  {
    "text": "was disrupted and the name of the condition is then disruption Target",
    "start": "1723380",
    "end": "1729740"
  },
  {
    "text": "so let's take a look so first of all such a pod could be disrupted by the control plane components so for example",
    "start": "1729740",
    "end": "1737500"
  },
  {
    "text": "by scheduler in case of preemption by a higher priority workload another couple",
    "start": "1737500",
    "end": "1743779"
  },
  {
    "text": "of cases but also we modified the code of kublet in some scenarios like for",
    "start": "1743779",
    "end": "1749299"
  },
  {
    "text": "example Grace will now shut down due to note restart um",
    "start": "1749299",
    "end": "1754760"
  },
  {
    "text": "but we are aware that this doesn't cover all the cases there might be some third-party controllers that have their",
    "start": "1754760",
    "end": "1761659"
  },
  {
    "text": "own reasons for evicting about Etc so like a core part of the design is",
    "start": "1761659",
    "end": "1768020"
  },
  {
    "text": "to allow custom conditions that then users can use in the portfolio policy to",
    "start": "1768020",
    "end": "1774679"
  },
  {
    "text": "handle a failed spot also there is a Reddit at work for bringing in more built-in conditions but",
    "start": "1774679",
    "end": "1782840"
  },
  {
    "text": "that's ongoing um so let's take a look an example at example a portfolio policy so popular",
    "start": "1782840",
    "end": "1789679"
  },
  {
    "text": "policy is just a list of rules and each rule specifies an action of how to",
    "start": "1789679",
    "end": "1795200"
  },
  {
    "text": "handle a failed how to handle a failed spot in case of a match and the match is",
    "start": "1795200",
    "end": "1801620"
  },
  {
    "text": "again based on exit code Airport conditions so in the first rule here the user wants to fail the entire job in",
    "start": "1801620",
    "end": "1809179"
  },
  {
    "text": "case of configuration issues and the configurations these issues are annotated by the custom config issue",
    "start": "1809179",
    "end": "1817340"
  },
  {
    "text": "a condition that is added in case of like unreservable container image or",
    "start": "1817340",
    "end": "1823000"
  },
  {
    "text": "invalid config map configuration in the second rule the user wants to",
    "start": "1823000",
    "end": "1828080"
  },
  {
    "text": "just ignore and restart the Freeport that failed due to these options and for this purpose the built-in disruption",
    "start": "1828080",
    "end": "1836240"
  },
  {
    "text": "Target condition is used and in the next two rules the user just wants to mimic the convention of handling failed pods",
    "start": "1836240",
    "end": "1844100"
  },
  {
    "text": "by TF job and that is based on the exit codes",
    "start": "1844100",
    "end": "1849520"
  },
  {
    "text": "okay here I will also want to thank say a big thanks to Fox from rescale who",
    "start": "1849559",
    "end": "1856159"
  },
  {
    "text": "also were nice enough to share with us the results of the testing of the",
    "start": "1856159",
    "end": "1862760"
  },
  {
    "text": "portfolio policy so in this setup they had also large embarrassingly parallel",
    "start": "1862760",
    "end": "1868100"
  },
  {
    "text": "jobs and they face a very similar problem with just inflexibility of setting the",
    "start": "1868100",
    "end": "1873380"
  },
  {
    "text": "back of limit but with the use of portfolio policy and like in the CM they",
    "start": "1873380",
    "end": "1879080"
  },
  {
    "text": "are able to prevent job failures while keeping the time much shorter",
    "start": "1879080",
    "end": "1885559"
  },
  {
    "text": "okay so in summary what we what we went through today we learned about the index",
    "start": "1885559",
    "end": "1891980"
  },
  {
    "text": "drop use cases like for machine learning for reinforcement learning or setting up",
    "start": "1891980",
    "end": "1898120"
  },
  {
    "text": "HPC environment that Vanessa talked about flux operator there are export",
    "start": "1898120",
    "end": "1903980"
  },
  {
    "text": "examples that for the use cases inspired by the use cases which I like you to",
    "start": "1903980",
    "end": "1911120"
  },
  {
    "text": "take a look at and also you can take a look at the flux operator code",
    "start": "1911120",
    "end": "1916580"
  },
  {
    "text": "um and finally we looked at the new feature of interest that is portfolio policy but the list of new features is",
    "start": "1916580",
    "end": "1922700"
  },
  {
    "text": "doesn't end here so there is a lot of things and new features that we are",
    "start": "1922700",
    "end": "1927860"
  },
  {
    "text": "currently working on just to name some elastic index job or job set so if you",
    "start": "1927860",
    "end": "1934100"
  },
  {
    "text": "want to get involved and participate in the discussions and then batch working",
    "start": "1934100",
    "end": "1940399"
  },
  {
    "text": "group is the good place to to come in I would also like to recommend you to",
    "start": "1940399",
    "end": "1947899"
  },
  {
    "text": "watch Once available the Swati and Aldo talk about bad working group but",
    "start": "1947899",
    "end": "1954440"
  },
  {
    "text": "essentially if you have any topic related to what or you want to present something discuss ask then",
    "start": "1954440",
    "end": "1962000"
  },
  {
    "text": "come and join and with that I'm ready for questions and there will also be",
    "start": "1962000",
    "end": "1967880"
  },
  {
    "text": "Vanessa and George ready for your questions on slack so thank you [Applause]",
    "start": "1967880",
    "end": "1979660"
  }
]
[
  {
    "text": "hi everyone I'm Zara um I'm giving a a",
    "start": "160",
    "end": "3840"
  },
  {
    "text": "brief overview this is AIM MLOps for",
    "start": "3840",
    "end": "6319"
  },
  {
    "text": "busy people um just introducing some of",
    "start": "6319",
    "end": "9920"
  },
  {
    "text": "the uh open source tools that we can use",
    "start": "9920",
    "end": "12080"
  },
  {
    "text": "to implement cloudnative AI and ML um a",
    "start": "12080",
    "end": "15920"
  },
  {
    "text": "bit about me i describe myself as like",
    "start": "15920",
    "end": "17760"
  },
  {
    "text": "four parts like math and data i'm more",
    "start": "17760",
    "end": "20080"
  },
  {
    "text": "of a math data person three parts",
    "start": "20080",
    "end": "22080"
  },
  {
    "text": "security and two parts engineering just",
    "start": "22080",
    "end": "24240"
  },
  {
    "text": "nine parts trying to be helpful for",
    "start": "24240",
    "end": "25840"
  },
  {
    "text": "everyone um I am a senior security data",
    "start": "25840",
    "end": "29359"
  },
  {
    "text": "scientist at Digital Ocean um I'm also",
    "start": "29359",
    "end": "32078"
  },
  {
    "text": "adjunct faculty at the University of",
    "start": "32079",
    "end": "33840"
  },
  {
    "text": "Arizona in Tucson and I am the founder",
    "start": "33840",
    "end": "36880"
  },
  {
    "text": "and director of research and development",
    "start": "36880",
    "end": "38239"
  },
  {
    "text": "for a small organization called Z",
    "start": "38239",
    "end": "39760"
  },
  {
    "text": "Collelective um and this talk is um on",
    "start": "39760",
    "end": "43760"
  },
  {
    "text": "behalf of me and not Digital Ocean or",
    "start": "43760",
    "end": "45440"
  },
  {
    "text": "the University of Arizona",
    "start": "45440",
    "end": "48360"
  },
  {
    "text": "so this this whole thing came together",
    "start": "48360",
    "end": "51920"
  },
  {
    "text": "um really because I found that it was",
    "start": "51920",
    "end": "53760"
  },
  {
    "text": "quite difficult to kind of uh talk",
    "start": "53760",
    "end": "56399"
  },
  {
    "text": "across disciplines from the data science",
    "start": "56399",
    "end": "58399"
  },
  {
    "text": "discipline to the software engineering",
    "start": "58399",
    "end": "61280"
  },
  {
    "text": "discipline um so I just wanted to be",
    "start": "61280",
    "end": "63440"
  },
  {
    "text": "able to kind of build empathy between",
    "start": "63440",
    "end": "65198"
  },
  {
    "text": "you know both domains um and help kind",
    "start": "65199",
    "end": "67760"
  },
  {
    "text": "of create a common understanding for",
    "start": "67760",
    "end": "69520"
  },
  {
    "text": "what we really need for model",
    "start": "69520",
    "end": "71520"
  },
  {
    "text": "development and evaluation and",
    "start": "71520",
    "end": "73520"
  },
  {
    "text": "deployment and serving um and then also",
    "start": "73520",
    "end": "77119"
  },
  {
    "text": "just kind of give a an overview a survey",
    "start": "77119",
    "end": "79680"
  },
  {
    "text": "of all the like open source tools that",
    "start": "79680",
    "end": "81680"
  },
  {
    "text": "I've used um in my own journey where I",
    "start": "81680",
    "end": "85200"
  },
  {
    "text": "had to learn to productionize my own",
    "start": "85200",
    "end": "87680"
  },
  {
    "text": "work um so I'm actually trained as a",
    "start": "87680",
    "end": "89520"
  },
  {
    "text": "data scientist primarily and then ended",
    "start": "89520",
    "end": "91840"
  },
  {
    "text": "up uh kind of doing ML engineering um",
    "start": "91840",
    "end": "94680"
  },
  {
    "text": "unwittingly and you know just finding",
    "start": "94680",
    "end": "98479"
  },
  {
    "text": "ways of um creating that common language",
    "start": "98479",
    "end": "101840"
  },
  {
    "text": "that we can communicate a little bit",
    "start": "101840",
    "end": "103280"
  },
  {
    "text": "better between all these different",
    "start": "103280",
    "end": "104640"
  },
  {
    "text": "domains and if you are perhaps like a a",
    "start": "104640",
    "end": "107200"
  },
  {
    "text": "a engineering manager or if you are an",
    "start": "107200",
    "end": "110320"
  },
  {
    "text": "IT director or in a leadership role just",
    "start": "110320",
    "end": "112159"
  },
  {
    "text": "sort of understanding what all these",
    "start": "112159",
    "end": "113920"
  },
  {
    "text": "different disciplines are and who's",
    "start": "113920",
    "end": "115759"
  },
  {
    "text": "actually skilled at what and what we're",
    "start": "115759",
    "end": "117439"
  },
  {
    "text": "all kind being asked to",
    "start": "117439",
    "end": "119479"
  },
  {
    "text": "do so let's just uh level set with what",
    "start": "119479",
    "end": "123680"
  },
  {
    "text": "is MLOps um if you are well can I get a",
    "start": "123680",
    "end": "126719"
  },
  {
    "text": "quick raise of hands like who's on the",
    "start": "126719",
    "end": "128160"
  },
  {
    "text": "data science side of the house any like",
    "start": "128160",
    "end": "130479"
  },
  {
    "text": "straight up data scientists",
    "start": "130479",
    "end": "132200"
  },
  {
    "text": "here no okay all right cool um well then",
    "start": "132200",
    "end": "137599"
  },
  {
    "text": "I I I think we're all going to learn a",
    "start": "137599",
    "end": "139040"
  },
  {
    "text": "lot about data science and and the whole",
    "start": "139040",
    "end": "140400"
  },
  {
    "text": "like ML discipline the ML life cycle so",
    "start": "140400",
    "end": "143640"
  },
  {
    "text": "MLOps if you're all software folk then",
    "start": "143640",
    "end": "146720"
  },
  {
    "text": "you you're very familiar with DevOps but",
    "start": "146720",
    "end": "148560"
  },
  {
    "text": "MLOps is the standardization and",
    "start": "148560",
    "end": "150640"
  },
  {
    "text": "streamlining of the machine learning",
    "start": "150640",
    "end": "152800"
  },
  {
    "text": "life cycle um so we need to distinguish",
    "start": "152800",
    "end": "157680"
  },
  {
    "text": "the different families of ML and AI just",
    "start": "157680",
    "end": "160239"
  },
  {
    "text": "to kind",
    "start": "160239",
    "end": "161480"
  },
  {
    "text": "of set an understanding that this world",
    "start": "161480",
    "end": "164400"
  },
  {
    "text": "is a lot more than just generative",
    "start": "164400",
    "end": "166000"
  },
  {
    "text": "language models and that's really",
    "start": "166000",
    "end": "168319"
  },
  {
    "text": "important for a lot of our production um",
    "start": "168319",
    "end": "170959"
  },
  {
    "text": "considerations so if we look at the",
    "start": "170959",
    "end": "172959"
  },
  {
    "text": "larger ML and AI landscape you know we",
    "start": "172959",
    "end": "175599"
  },
  {
    "text": "we talk about AI as this kind of I mean",
    "start": "175599",
    "end": "178080"
  },
  {
    "text": "if you asked two years ago what AI was",
    "start": "178080",
    "end": "180239"
  },
  {
    "text": "people would have said deep learning and",
    "start": "180239",
    "end": "181680"
  },
  {
    "text": "that's no longer the case now AI",
    "start": "181680",
    "end": "183360"
  },
  {
    "text": "specifically means generative language",
    "start": "183360",
    "end": "185120"
  },
  {
    "text": "models but you know uh there's more to",
    "start": "185120",
    "end": "187920"
  },
  {
    "text": "it than that so we have artificial",
    "start": "187920",
    "end": "189840"
  },
  {
    "text": "intelligence we have machine learning",
    "start": "189840",
    "end": "191599"
  },
  {
    "text": "within machine learning we have",
    "start": "191599",
    "end": "192879"
  },
  {
    "text": "statistical machine learning kind of",
    "start": "192879",
    "end": "194239"
  },
  {
    "text": "traditional machine learning we have",
    "start": "194239",
    "end": "196159"
  },
  {
    "text": "deep learning and reinforcement learning",
    "start": "196159",
    "end": "198560"
  },
  {
    "text": "so those are kind of they're related but",
    "start": "198560",
    "end": "200239"
  },
  {
    "text": "separate because their architectures are",
    "start": "200239",
    "end": "201680"
  },
  {
    "text": "quite different within deep learning we",
    "start": "201680",
    "end": "203840"
  },
  {
    "text": "have these architectures called encoders",
    "start": "203840",
    "end": "206239"
  },
  {
    "text": "and decoders within that we have",
    "start": "206239",
    "end": "208400"
  },
  {
    "text": "transformer architectures and then",
    "start": "208400",
    "end": "210879"
  },
  {
    "text": "that's where we get into generative AI",
    "start": "210879",
    "end": "212480"
  },
  {
    "text": "and generative language models so you",
    "start": "212480",
    "end": "213840"
  },
  {
    "text": "see there's a lot more to it uh to AI",
    "start": "213840",
    "end": "217120"
  },
  {
    "text": "world than just you know your your GPT",
    "start": "217120",
    "end": "220360"
  },
  {
    "text": "models so with that in mind we're going",
    "start": "220360",
    "end": "223120"
  },
  {
    "text": "to be going over kind of like the",
    "start": "223120",
    "end": "225200"
  },
  {
    "text": "broadest level applications we can um I",
    "start": "225200",
    "end": "228319"
  },
  {
    "text": "actually teach a four-part lecture",
    "start": "228319",
    "end": "230319"
  },
  {
    "text": "series on ML and AI ops at the",
    "start": "230319",
    "end": "232560"
  },
  {
    "text": "University of Arizona so um I have links",
    "start": "232560",
    "end": "234879"
  },
  {
    "text": "to that at the end of this presentation",
    "start": "234879",
    "end": "236400"
  },
  {
    "text": "if you want to watch four hours of this",
    "start": "236400",
    "end": "238239"
  },
  {
    "text": "talk uh you're welcome to do so um so",
    "start": "238239",
    "end": "241680"
  },
  {
    "text": "let's talk about experimental versus",
    "start": "241680",
    "end": "243760"
  },
  {
    "text": "production ML and AI so if no one here",
    "start": "243760",
    "end": "248239"
  },
  {
    "text": "uh works in data science or if if you're",
    "start": "248239",
    "end": "250400"
  },
  {
    "text": "not like you know creating novel",
    "start": "250400",
    "end": "252799"
  },
  {
    "text": "architectures on your own then um you",
    "start": "252799",
    "end": "255439"
  },
  {
    "text": "will be probably a little bit shocked to",
    "start": "255439",
    "end": "257280"
  },
  {
    "text": "know what the what the data science",
    "start": "257280",
    "end": "259280"
  },
  {
    "text": "workflow is like outside of production",
    "start": "259280",
    "end": "261680"
  },
  {
    "text": "world we do this in very ad hoc fashions",
    "start": "261680",
    "end": "266160"
  },
  {
    "text": "most of our workflows are in Jupyter",
    "start": "266160",
    "end": "268560"
  },
  {
    "text": "notebooks um and just show of hands is",
    "start": "268560",
    "end": "272080"
  },
  {
    "text": "anyone familiar with Jupyter notebooks",
    "start": "272080",
    "end": "274240"
  },
  {
    "text": "yeah great okay cool so it's sort of",
    "start": "274240",
    "end": "276000"
  },
  {
    "text": "like procedural programming right you",
    "start": "276000",
    "end": "277520"
  },
  {
    "text": "evaluate everything in a cell um and all",
    "start": "277520",
    "end": "280000"
  },
  {
    "text": "of this just like lives in memory and",
    "start": "280000",
    "end": "282080"
  },
  {
    "text": "the data science workflow that a lot of",
    "start": "282080",
    "end": "284320"
  },
  {
    "text": "us learn you know kind of coming up in",
    "start": "284320",
    "end": "286160"
  },
  {
    "text": "the field we uh um everything is just",
    "start": "286160",
    "end": "291360"
  },
  {
    "text": "local our our virtual environments all",
    "start": "291360",
    "end": "293360"
  },
  {
    "text": "of our all of our data we read in CSVs",
    "start": "293360",
    "end": "295919"
  },
  {
    "text": "um our helper functions they just exist",
    "start": "295919",
    "end": "298720"
  },
  {
    "text": "locally in our notebooks um we actually",
    "start": "298720",
    "end": "301360"
  },
  {
    "text": "train the models i mean sometimes the",
    "start": "301360",
    "end": "302880"
  },
  {
    "text": "models are trained locally um obviously",
    "start": "302880",
    "end": "305440"
  },
  {
    "text": "a lot of them are are are trained in",
    "start": "305440",
    "end": "307039"
  },
  {
    "text": "cloud um cloud environments um we track",
    "start": "307039",
    "end": "309759"
  },
  {
    "text": "metrics locally uh we have all of our",
    "start": "309759",
    "end": "312800"
  },
  {
    "text": "results persisted locally so all of this",
    "start": "312800",
    "end": "315440"
  },
  {
    "text": "happens kind of in a notebook and uh",
    "start": "315440",
    "end": "318400"
  },
  {
    "text": "actually like version control source",
    "start": "318400",
    "end": "320160"
  },
  {
    "text": "control is very rarely used um we're",
    "start": "320160",
    "end": "323120"
  },
  {
    "text": "usually working with a small number of",
    "start": "323120",
    "end": "324639"
  },
  {
    "text": "people uh maybe just an individual or a",
    "start": "324639",
    "end": "328160"
  },
  {
    "text": "small team you know and I I have I have",
    "start": "328160",
    "end": "331840"
  },
  {
    "text": "some collaborators who will literally",
    "start": "331840",
    "end": "333600"
  },
  {
    "text": "just email me a notebook instead of you",
    "start": "333600",
    "end": "336400"
  },
  {
    "text": "know uh committing it to a repo um a lot",
    "start": "336400",
    "end": "339280"
  },
  {
    "text": "of this is ad hoc um sometimes we're",
    "start": "339280",
    "end": "342000"
  },
  {
    "text": "working with historical data or static",
    "start": "342000",
    "end": "344280"
  },
  {
    "text": "data um there's not always a",
    "start": "344280",
    "end": "347199"
  },
  {
    "text": "consideration for what like online",
    "start": "347199",
    "end": "349600"
  },
  {
    "text": "inferencing requirements are going to be",
    "start": "349600",
    "end": "352720"
  },
  {
    "text": "um data management can be a little bit",
    "start": "352720",
    "end": "354880"
  },
  {
    "text": "spotty because sometimes we just drop",
    "start": "354880",
    "end": "356960"
  },
  {
    "text": "missing data that's a very common",
    "start": "356960",
    "end": "358479"
  },
  {
    "text": "practice um that doesn't work quite so",
    "start": "358479",
    "end": "360880"
  },
  {
    "text": "well in production world um and there's",
    "start": "360880",
    "end": "363840"
  },
  {
    "text": "a lot of manual tuning manual um",
    "start": "363840",
    "end": "366319"
  },
  {
    "text": "hyperparameter tuning and again results",
    "start": "366319",
    "end": "369440"
  },
  {
    "text": "are often just persisted to disk so",
    "start": "369440",
    "end": "372639"
  },
  {
    "text": "going from our experimental ML and AI",
    "start": "372639",
    "end": "375600"
  },
  {
    "text": "setup working as an individual kind of",
    "start": "375600",
    "end": "377680"
  },
  {
    "text": "workshopping your models and",
    "start": "377680",
    "end": "379039"
  },
  {
    "text": "workshopping um your your tasks and",
    "start": "379039",
    "end": "381520"
  },
  {
    "text": "improving your your models based off the",
    "start": "381520",
    "end": "383039"
  },
  {
    "text": "task to production ML and AI where we",
    "start": "383039",
    "end": "386160"
  },
  {
    "text": "have distributed workflows you know we",
    "start": "386160",
    "end": "388400"
  },
  {
    "text": "need to start utilizing artifact and",
    "start": "388400",
    "end": "390400"
  },
  {
    "text": "feature stores um you know our model",
    "start": "390400",
    "end": "393120"
  },
  {
    "text": "needs to be deployed in an appropriate",
    "start": "393120",
    "end": "395600"
  },
  {
    "text": "manner for the application again if it's",
    "start": "395600",
    "end": "397680"
  },
  {
    "text": "online inferencing or batch inferencing",
    "start": "397680",
    "end": "400560"
  },
  {
    "text": "um then our data and our model lineage",
    "start": "400560",
    "end": "404479"
  },
  {
    "text": "need to be tracked right we need to have",
    "start": "404479",
    "end": "406080"
  },
  {
    "text": "data versioning we need to have model",
    "start": "406080",
    "end": "407680"
  },
  {
    "text": "versioning um and then we also have to",
    "start": "407680",
    "end": "409840"
  },
  {
    "text": "have feedback loops you know human",
    "start": "409840",
    "end": "411440"
  },
  {
    "text": "feedback and um human feedback and also",
    "start": "411440",
    "end": "413759"
  },
  {
    "text": "model feedback um drift detection all of",
    "start": "413759",
    "end": "416080"
  },
  {
    "text": "these things so going from you know my",
    "start": "416080",
    "end": "419280"
  },
  {
    "text": "my my notebook that's on my on my local",
    "start": "419280",
    "end": "421840"
  },
  {
    "text": "disc to this is quite the process um and",
    "start": "421840",
    "end": "426400"
  },
  {
    "text": "uh oh I'm sorry yeah um data cataloging",
    "start": "426400",
    "end": "429360"
  },
  {
    "text": "i think I touched on all of this but",
    "start": "429360",
    "end": "431440"
  },
  {
    "text": "yeah moving from local ML uh and AI",
    "start": "431440",
    "end": "434000"
  },
  {
    "text": "experimentation to a mature production",
    "start": "434000",
    "end": "435759"
  },
  {
    "text": "environment is complicated um and so",
    "start": "435759",
    "end": "438479"
  },
  {
    "text": "we're going to break that down step by",
    "start": "438479",
    "end": "439680"
  },
  {
    "text": "step in the ML life cycle it's going to",
    "start": "439680",
    "end": "442240"
  },
  {
    "text": "hopefully help us establish some clarity",
    "start": "442240",
    "end": "444319"
  },
  {
    "text": "and make this whole process a lot more",
    "start": "444319",
    "end": "445919"
  },
  {
    "text": "manageable um and yay for open source",
    "start": "445919",
    "end": "448160"
  },
  {
    "text": "tools that make this a lot more",
    "start": "448160",
    "end": "449520"
  },
  {
    "text": "efficient and scalable and",
    "start": "449520",
    "end": "452440"
  },
  {
    "text": "cost-effective okay so let's talk about",
    "start": "452440",
    "end": "454319"
  },
  {
    "text": "the ML life cycle the stages and what I",
    "start": "454319",
    "end": "457919"
  },
  {
    "text": "think the the appropriate like developer",
    "start": "457919",
    "end": "460479"
  },
  {
    "text": "roles are and personas are in the ML",
    "start": "460479",
    "end": "462400"
  },
  {
    "text": "life cycle um so",
    "start": "462400",
    "end": "466319"
  },
  {
    "text": "uh we think about this in terms of you",
    "start": "466319",
    "end": "468880"
  },
  {
    "text": "know a handful of steps it always starts",
    "start": "468880",
    "end": "470639"
  },
  {
    "text": "with a research question or a business",
    "start": "470639",
    "end": "472240"
  },
  {
    "text": "need right so what are we trying to",
    "start": "472240",
    "end": "474000"
  },
  {
    "text": "classify what are we what do we need to",
    "start": "474000",
    "end": "476160"
  },
  {
    "text": "predict um you know what text do we need",
    "start": "476160",
    "end": "478800"
  },
  {
    "text": "to generate for example um we go onto",
    "start": "478800",
    "end": "481520"
  },
  {
    "text": "our data collection and preparation",
    "start": "481520",
    "end": "483199"
  },
  {
    "text": "stages which is cleaning pre-processing",
    "start": "483199",
    "end": "485520"
  },
  {
    "text": "pipelining lots of tasks with that then",
    "start": "485520",
    "end": "487840"
  },
  {
    "text": "from there we go into experimentation",
    "start": "487840",
    "end": "489440"
  },
  {
    "text": "and valuation that's where we're",
    "start": "489440",
    "end": "490639"
  },
  {
    "text": "actually building our models",
    "start": "490639",
    "end": "492000"
  },
  {
    "text": "establishing the model architecture",
    "start": "492000",
    "end": "494080"
  },
  {
    "text": "doing our training doing our testing",
    "start": "494080",
    "end": "496080"
  },
  {
    "text": "recording our valuation metrics and then",
    "start": "496080",
    "end": "498960"
  },
  {
    "text": "we go to model deployment where we're",
    "start": "498960",
    "end": "500800"
  },
  {
    "text": "actually deploying that model in some",
    "start": "500800",
    "end": "502319"
  },
  {
    "text": "production system um that's also where",
    "start": "502319",
    "end": "504639"
  },
  {
    "text": "we're going to determine how often our",
    "start": "504639",
    "end": "505919"
  },
  {
    "text": "model needs to be retrained um and then",
    "start": "505919",
    "end": "508400"
  },
  {
    "text": "we get into serving and inferencing so",
    "start": "508400",
    "end": "510160"
  },
  {
    "text": "that's using the model's learned weights",
    "start": "510160",
    "end": "512880"
  },
  {
    "text": "right or the model's parameters um to",
    "start": "512880",
    "end": "515360"
  },
  {
    "text": "predict some the class of some incoming",
    "start": "515360",
    "end": "518479"
  },
  {
    "text": "data we're going to start using our",
    "start": "518479",
    "end": "519760"
  },
  {
    "text": "model on unseen data then we have",
    "start": "519760",
    "end": "521839"
  },
  {
    "text": "monitoring and maintenance uh which has",
    "start": "521839",
    "end": "524080"
  },
  {
    "text": "some specific um uh requirements in",
    "start": "524080",
    "end": "527600"
  },
  {
    "text": "machine learning world that are a little",
    "start": "527600",
    "end": "529200"
  },
  {
    "text": "bit separate from software um I guess",
    "start": "529200",
    "end": "531680"
  },
  {
    "text": "traditional software engineering world",
    "start": "531680",
    "end": "533279"
  },
  {
    "text": "um we need to detect and model monitor",
    "start": "533279",
    "end": "535760"
  },
  {
    "text": "the model's performance detect drift",
    "start": "535760",
    "end": "537680"
  },
  {
    "text": "things like that so as far as the rules",
    "start": "537680",
    "end": "540720"
  },
  {
    "text": "the personas behind these stages um",
    "start": "540720",
    "end": "543680"
  },
  {
    "text": "research questions business needs um",
    "start": "543680",
    "end": "545600"
  },
  {
    "text": "those are really driven by domain",
    "start": "545600",
    "end": "547440"
  },
  {
    "text": "experts uh machine learning uh data",
    "start": "547440",
    "end": "550480"
  },
  {
    "text": "scientists and and um machine learning",
    "start": "550480",
    "end": "553200"
  },
  {
    "text": "specialists are not are not domain",
    "start": "553200",
    "end": "554720"
  },
  {
    "text": "experts in everything we really need our",
    "start": "554720",
    "end": "557200"
  },
  {
    "text": "domain experts in order to create",
    "start": "557200",
    "end": "559160"
  },
  {
    "text": "meaningful and effective models",
    "start": "559160",
    "end": "562560"
  },
  {
    "text": "data collection and pre-processing",
    "start": "562560",
    "end": "564000"
  },
  {
    "text": "that's really a combination a",
    "start": "564000",
    "end": "565839"
  },
  {
    "text": "collaboration between data engineers and",
    "start": "565839",
    "end": "568000"
  },
  {
    "text": "data scientists uh data scientists need",
    "start": "568000",
    "end": "569920"
  },
  {
    "text": "to be able to articulate what data we",
    "start": "569920",
    "end": "572000"
  },
  {
    "text": "need and where what kinds of transforms",
    "start": "572000",
    "end": "574399"
  },
  {
    "text": "need to happen uh where this data comes",
    "start": "574399",
    "end": "576480"
  },
  {
    "text": "from and then we need our data engineers",
    "start": "576480",
    "end": "578320"
  },
  {
    "text": "to help us facilitate that help",
    "start": "578320",
    "end": "580880"
  },
  {
    "text": "coordinate that um and do that in a sane",
    "start": "580880",
    "end": "582959"
  },
  {
    "text": "way our experimentation evaluation phase",
    "start": "582959",
    "end": "586800"
  },
  {
    "text": "that's where like data scientists are",
    "start": "586800",
    "end": "588320"
  },
  {
    "text": "actually trained like that's that's the",
    "start": "588320",
    "end": "590000"
  },
  {
    "text": "majority of of where we work that's",
    "start": "590000",
    "end": "592240"
  },
  {
    "text": "where we like to work I think um that's",
    "start": "592240",
    "end": "594560"
  },
  {
    "text": "where we start reading a bunch of math",
    "start": "594560",
    "end": "596160"
  },
  {
    "text": "papers and then um you know and and",
    "start": "596160",
    "end": "598560"
  },
  {
    "text": "making sense of them the model",
    "start": "598560",
    "end": "600399"
  },
  {
    "text": "deployment piece is you know ML",
    "start": "600399",
    "end": "603040"
  },
  {
    "text": "engineering this is our software",
    "start": "603040",
    "end": "604399"
  },
  {
    "text": "engineering our SRRES we're getting a",
    "start": "604399",
    "end": "606480"
  },
  {
    "text": "little bit more into traditional",
    "start": "606480",
    "end": "608959"
  },
  {
    "text": "software engineering roles model serving",
    "start": "608959",
    "end": "611600"
  },
  {
    "text": "and inferencing again software engineers",
    "start": "611600",
    "end": "613279"
  },
  {
    "text": "and SRRES and then our monitoring",
    "start": "613279",
    "end": "615120"
  },
  {
    "text": "maintenance that's a combination of our",
    "start": "615120",
    "end": "616800"
  },
  {
    "text": "observability teams and our data",
    "start": "616800",
    "end": "619200"
  },
  {
    "text": "scientists because again we have some",
    "start": "619200",
    "end": "620880"
  },
  {
    "text": "unique requirements for monitoring um",
    "start": "620880",
    "end": "623600"
  },
  {
    "text": "and we need to work with our our",
    "start": "623600",
    "end": "626160"
  },
  {
    "text": "observability teams on",
    "start": "626160",
    "end": "627880"
  },
  {
    "text": "that okay so now we're going to we're",
    "start": "627880",
    "end": "630959"
  },
  {
    "text": "going to skip the research question and",
    "start": "630959",
    "end": "632160"
  },
  {
    "text": "business need that's around like you",
    "start": "632160",
    "end": "633920"
  },
  {
    "text": "know defining hypotheses things like",
    "start": "633920",
    "end": "635600"
  },
  {
    "text": "that um we're going to get straight into",
    "start": "635600",
    "end": "637600"
  },
  {
    "text": "the you know the more taskbased uh",
    "start": "637600",
    "end": "640880"
  },
  {
    "text": "stages of the life cycle so data",
    "start": "640880",
    "end": "643440"
  },
  {
    "text": "collection and and pre-processing um",
    "start": "643440",
    "end": "645519"
  },
  {
    "text": "there's a few like key stages in this um",
    "start": "645519",
    "end": "649440"
  },
  {
    "text": "we are doing our data pipelining our",
    "start": "649440",
    "end": "652320"
  },
  {
    "text": "ETLs we'll talk about that a little bit",
    "start": "652320",
    "end": "653920"
  },
  {
    "text": "more uh pre-processing and cleaning our",
    "start": "653920",
    "end": "656399"
  },
  {
    "text": "feature engineering where we're actually",
    "start": "656399",
    "end": "658480"
  },
  {
    "text": "defining what the inputs of the model",
    "start": "658480",
    "end": "660399"
  },
  {
    "text": "need to be and then we're doing some",
    "start": "660399",
    "end": "662560"
  },
  {
    "text": "data cataloging and data management",
    "start": "662560",
    "end": "665040"
  },
  {
    "text": "we're excluding a really key phase for",
    "start": "665040",
    "end": "666560"
  },
  {
    "text": "like the data science process here which",
    "start": "666560",
    "end": "668000"
  },
  {
    "text": "is um exploratory data analysis i'm",
    "start": "668000",
    "end": "670320"
  },
  {
    "text": "leaving that out because that's usually",
    "start": "670320",
    "end": "671519"
  },
  {
    "text": "just done kind of in an ad hoc manner or",
    "start": "671519",
    "end": "673680"
  },
  {
    "text": "locally that's like notebook world so we",
    "start": "673680",
    "end": "675920"
  },
  {
    "text": "don't necessarily need that for our",
    "start": "675920",
    "end": "677920"
  },
  {
    "text": "MLOps",
    "start": "677920",
    "end": "679320"
  },
  {
    "text": "pipelines so with data pipelining there",
    "start": "679320",
    "end": "682079"
  },
  {
    "text": "are I mean there's a a lot of really",
    "start": "682079",
    "end": "684000"
  },
  {
    "text": "really great open source tools here um",
    "start": "684000",
    "end": "686560"
  },
  {
    "text": "I'm going to focus on Apache Airflow",
    "start": "686560",
    "end": "688959"
  },
  {
    "text": "because I it's really widely used um and",
    "start": "688959",
    "end": "692560"
  },
  {
    "text": "uh it has a lot of features that just",
    "start": "692560",
    "end": "695680"
  },
  {
    "text": "make pipelining uh a lot more sane um",
    "start": "695680",
    "end": "699839"
  },
  {
    "text": "for you know for non-data engineers I",
    "start": "699839",
    "end": "702480"
  },
  {
    "text": "would say",
    "start": "702480",
    "end": "704120"
  },
  {
    "text": "so extract transform load or ETL or",
    "start": "704120",
    "end": "707600"
  },
  {
    "text": "extract load transform is ELT um are two",
    "start": "707600",
    "end": "710959"
  },
  {
    "text": "like approaches to taking our data from",
    "start": "710959",
    "end": "713680"
  },
  {
    "text": "maybe production databases or other",
    "start": "713680",
    "end": "716320"
  },
  {
    "text": "locations um and then getting them into",
    "start": "716320",
    "end": "718399"
  },
  {
    "text": "for example a warehouse um so extract",
    "start": "718399",
    "end": "721120"
  },
  {
    "text": "transform load is uh I'm sorry uh yeah",
    "start": "721120",
    "end": "724160"
  },
  {
    "text": "extract transform load is the current",
    "start": "724160",
    "end": "727440"
  },
  {
    "text": "favorite of the two approaches is where",
    "start": "727440",
    "end": "729600"
  },
  {
    "text": "you're going to pull your data do some",
    "start": "729600",
    "end": "731440"
  },
  {
    "text": "transformations on it once it hits the",
    "start": "731440",
    "end": "732959"
  },
  {
    "text": "warehouse it's already in the state that",
    "start": "732959",
    "end": "734399"
  },
  {
    "text": "it needs to be in um Apache Airflow",
    "start": "734399",
    "end": "736720"
  },
  {
    "text": "helps us do that it's one of the key um",
    "start": "736720",
    "end": "739839"
  },
  {
    "text": "key functionality of Apache Airflow",
    "start": "739839",
    "end": "742320"
  },
  {
    "text": "there's also scheduling and",
    "start": "742320",
    "end": "743519"
  },
  {
    "text": "orchestration of your data pipelines and",
    "start": "743519",
    "end": "745519"
  },
  {
    "text": "workflows you can define you know uh uh",
    "start": "745519",
    "end": "748480"
  },
  {
    "text": "you can define periods for where your um",
    "start": "748480",
    "end": "752720"
  },
  {
    "text": "uh your pipelines are going to go query",
    "start": "752720",
    "end": "755360"
  },
  {
    "text": "maybe a production database and get that",
    "start": "755360",
    "end": "757760"
  },
  {
    "text": "data back into your warehouse um you can",
    "start": "757760",
    "end": "760959"
  },
  {
    "text": "also represent your data tasks as a",
    "start": "760959",
    "end": "763760"
  },
  {
    "text": "directed as graph or a DAG so we have a",
    "start": "763760",
    "end": "766800"
  },
  {
    "text": "handful of tasks maybe we need to pull",
    "start": "766800",
    "end": "768399"
  },
  {
    "text": "this data from our production database",
    "start": "768399",
    "end": "770320"
  },
  {
    "text": "we need to uh we need to standardize",
    "start": "770320",
    "end": "773440"
  },
  {
    "text": "some datetime features or some datetime",
    "start": "773440",
    "end": "775760"
  },
  {
    "text": "columns we need to do some string",
    "start": "775760",
    "end": "777920"
  },
  {
    "text": "processing on some textual columns and",
    "start": "777920",
    "end": "780399"
  },
  {
    "text": "then all of that gets into our warehouse",
    "start": "780399",
    "end": "782720"
  },
  {
    "text": "down the line um there's also dbt so dbt",
    "start": "782720",
    "end": "787519"
  },
  {
    "text": "is very SQL SQL world friendly um you're",
    "start": "787519",
    "end": "791360"
  },
  {
    "text": "going to define your transforms as like",
    "start": "791360",
    "end": "793440"
  },
  {
    "text": "select statements which is really nice",
    "start": "793440",
    "end": "795200"
  },
  {
    "text": "um and then those select statements get",
    "start": "795200",
    "end": "797360"
  },
  {
    "text": "persisted into your warehouse or",
    "start": "797360",
    "end": "799440"
  },
  {
    "text": "whatever centralized uh data repository",
    "start": "799440",
    "end": "801600"
  },
  {
    "text": "you have um it also uh so that's the ETL",
    "start": "801600",
    "end": "805200"
  },
  {
    "text": "step and it also lets you represent your",
    "start": "805200",
    "end": "807279"
  },
  {
    "text": "transforms as a",
    "start": "807279",
    "end": "810200"
  },
  {
    "text": "DAG so next we have our pre-processing",
    "start": "810200",
    "end": "812720"
  },
  {
    "text": "and cleaning it's a really critical step",
    "start": "812720",
    "end": "814320"
  },
  {
    "text": "and it's really important to think about",
    "start": "814320",
    "end": "815680"
  },
  {
    "text": "pre-processing cleaning and feature",
    "start": "815680",
    "end": "817040"
  },
  {
    "text": "engineering in our MLOps life cycle",
    "start": "817040",
    "end": "819680"
  },
  {
    "text": "because those always come back to bite",
    "start": "819680",
    "end": "821839"
  },
  {
    "text": "us at inference time so uh we have a a",
    "start": "821839",
    "end": "824720"
  },
  {
    "text": "handful of tools for data validation i'm",
    "start": "824720",
    "end": "827040"
  },
  {
    "text": "going to look at s or we'll look at",
    "start": "827040",
    "end": "829000"
  },
  {
    "text": "serabus for a second so it's really just",
    "start": "829000",
    "end": "831600"
  },
  {
    "text": "a it's python heavy uh data validation",
    "start": "831600",
    "end": "835680"
  },
  {
    "text": "you can do extensive checks for your",
    "start": "835680",
    "end": "837600"
  },
  {
    "text": "data normalization you can do um uh",
    "start": "837600",
    "end": "840880"
  },
  {
    "text": "static typing yay uh you can check for",
    "start": "840880",
    "end": "844560"
  },
  {
    "text": "that keys exist in your data structures",
    "start": "844560",
    "end": "846720"
  },
  {
    "text": "all of these things",
    "start": "846720",
    "end": "849040"
  },
  {
    "text": "and then our feature engineering um",
    "start": "849040",
    "end": "851279"
  },
  {
    "text": "which is a critical stage in MLOps",
    "start": "851279",
    "end": "854240"
  },
  {
    "text": "because we need to make sure that our",
    "start": "854240",
    "end": "856000"
  },
  {
    "text": "features um are going to be available",
    "start": "856000",
    "end": "858480"
  },
  {
    "text": "both at training time and also at",
    "start": "858480",
    "end": "860000"
  },
  {
    "text": "inference time right but if we're",
    "start": "860000",
    "end": "861440"
  },
  {
    "text": "training on this uh infrastructure over",
    "start": "861440",
    "end": "864720"
  },
  {
    "text": "here but our inference server lives over",
    "start": "864720",
    "end": "866320"
  },
  {
    "text": "there we need to make sure that they can",
    "start": "866320",
    "end": "867680"
  },
  {
    "text": "both access the same features right so",
    "start": "867680",
    "end": "869839"
  },
  {
    "text": "we need to make sure that the data",
    "start": "869839",
    "end": "870959"
  },
  {
    "text": "that's coming in will have the same",
    "start": "870959",
    "end": "872480"
  },
  {
    "text": "pre-processing steps they'll be",
    "start": "872480",
    "end": "874079"
  },
  {
    "text": "transformed into the features so that it",
    "start": "874079",
    "end": "875920"
  },
  {
    "text": "can actually work at inference time so",
    "start": "875920",
    "end": "878320"
  },
  {
    "text": "uh feature store that's really common",
    "start": "878320",
    "end": "879920"
  },
  {
    "text": "and really popular in the MLOps world is",
    "start": "879920",
    "end": "882480"
  },
  {
    "text": "feast and this lets us use both online",
    "start": "882480",
    "end": "886399"
  },
  {
    "text": "feature stores and offline feature",
    "start": "886399",
    "end": "888240"
  },
  {
    "text": "stores so your offline feature store is",
    "start": "888240",
    "end": "890079"
  },
  {
    "text": "going to be you know historical feature",
    "start": "890079",
    "end": "891839"
  },
  {
    "text": "extraction that you're using in training",
    "start": "891839",
    "end": "893760"
  },
  {
    "text": "um and then your online feature store",
    "start": "893760",
    "end": "895360"
  },
  {
    "text": "will serve your features at inference",
    "start": "895360",
    "end": "897760"
  },
  {
    "text": "time with low latency um feast is not",
    "start": "897760",
    "end": "901160"
  },
  {
    "text": "ETL it's not data orchestration it's",
    "start": "901160",
    "end": "903839"
  },
  {
    "text": "really just your feature store so now we",
    "start": "903839",
    "end": "906160"
  },
  {
    "text": "have this this new element of MLOps",
    "start": "906160",
    "end": "908320"
  },
  {
    "text": "right so we have this uh new new new uh",
    "start": "908320",
    "end": "912800"
  },
  {
    "text": "um infrastructure that we need to",
    "start": "912800",
    "end": "914399"
  },
  {
    "text": "consider right so now we have not just",
    "start": "914399",
    "end": "916639"
  },
  {
    "text": "like our our application that we're",
    "start": "916639",
    "end": "918959"
  },
  {
    "text": "writing um but we also now have an you",
    "start": "918959",
    "end": "921360"
  },
  {
    "text": "know offline feature store and an online",
    "start": "921360",
    "end": "923279"
  },
  {
    "text": "feature store and we need to make sure",
    "start": "923279",
    "end": "924480"
  },
  {
    "text": "that those are incorporated into our",
    "start": "924480",
    "end": "926160"
  },
  {
    "text": "architecture for end toend",
    "start": "926160",
    "end": "928360"
  },
  {
    "text": "MLOps another great tool for feature",
    "start": "928360",
    "end": "931199"
  },
  {
    "text": "stores is just using Reddus um you know",
    "start": "931199",
    "end": "934160"
  },
  {
    "text": "it's just in-memory database you can use",
    "start": "934160",
    "end": "936160"
  },
  {
    "text": "key value pairs um extremely low latency",
    "start": "936160",
    "end": "939120"
  },
  {
    "text": "right um you can use reddus as a feature",
    "start": "939120",
    "end": "941600"
  },
  {
    "text": "story for certain cases and I encourage",
    "start": "941600",
    "end": "944639"
  },
  {
    "text": "you uh to think through like when when",
    "start": "944639",
    "end": "947839"
  },
  {
    "text": "and where you can use Reddus as opposed",
    "start": "947839",
    "end": "949680"
  },
  {
    "text": "to you know spinning up new",
    "start": "949680",
    "end": "951600"
  },
  {
    "text": "infrastructure that maybe um your",
    "start": "951600",
    "end": "953839"
  },
  {
    "text": "organization does not currently have um",
    "start": "953839",
    "end": "956000"
  },
  {
    "text": "in place so another another key part is",
    "start": "956000",
    "end": "960320"
  },
  {
    "text": "data cataloging um it takes forever",
    "start": "960320",
    "end": "963600"
  },
  {
    "text": "getting a solid data cataloging team or",
    "start": "963600",
    "end": "966480"
  },
  {
    "text": "like effort going in your organization",
    "start": "966480",
    "end": "968959"
  },
  {
    "text": "is is really really difficult but it's",
    "start": "968959",
    "end": "971279"
  },
  {
    "text": "so worth it um uh open metadata is a",
    "start": "971279",
    "end": "975199"
  },
  {
    "text": "great data cataloging tool it helps you",
    "start": "975199",
    "end": "977440"
  },
  {
    "text": "with discovery uh with data lineage you",
    "start": "977440",
    "end": "980480"
  },
  {
    "text": "can have notes about what your ETLs",
    "start": "980480",
    "end": "982560"
  },
  {
    "text": "really mean uh why did you do these",
    "start": "982560",
    "end": "984720"
  },
  {
    "text": "particular transforms um you can do data",
    "start": "984720",
    "end": "987279"
  },
  {
    "text": "quality checks it helps you have a",
    "start": "987279",
    "end": "989600"
  },
  {
    "text": "collaborative approach for your you know",
    "start": "989600",
    "end": "992079"
  },
  {
    "text": "for your data warehouse um all of the",
    "start": "992079",
    "end": "994800"
  },
  {
    "text": "different data engineers or domain",
    "start": "994800",
    "end": "996880"
  },
  {
    "text": "experts who are helping you define",
    "start": "996880",
    "end": "998560"
  },
  {
    "text": "what's in your warehouse can all make",
    "start": "998560",
    "end": "1000399"
  },
  {
    "text": "annotations and it just makes life so",
    "start": "1000399",
    "end": "1002320"
  },
  {
    "text": "much easier um and you can also have",
    "start": "1002320",
    "end": "1004639"
  },
  {
    "text": "some data governance features in open",
    "start": "1004639",
    "end": "1008519"
  },
  {
    "text": "metadata as far as data stores um I",
    "start": "1008519",
    "end": "1012160"
  },
  {
    "text": "think we've all at this point probably",
    "start": "1012160",
    "end": "1013440"
  },
  {
    "text": "heard about vector databases right um",
    "start": "1013440",
    "end": "1015680"
  },
  {
    "text": "Milvis is a very common vector database",
    "start": "1015680",
    "end": "1018079"
  },
  {
    "text": "and um just show of hands really quickly",
    "start": "1018079",
    "end": "1021079"
  },
  {
    "text": "um who who who feels like you have a",
    "start": "1021079",
    "end": "1024640"
  },
  {
    "text": "good handle on why vector databases are",
    "start": "1024640",
    "end": "1027280"
  },
  {
    "text": "needed right now in the ML AI ops world",
    "start": "1027280",
    "end": "1030959"
  },
  {
    "text": "yeah we got a decent handle on vector",
    "start": "1030959",
    "end": "1033000"
  },
  {
    "text": "databases okay so the way that we",
    "start": "1033000",
    "end": "1036720"
  },
  {
    "text": "transform our data in machine learning",
    "start": "1036720",
    "end": "1038558"
  },
  {
    "text": "world is we we turn data into a um a",
    "start": "1038559",
    "end": "1043839"
  },
  {
    "text": "long representation a long vector if you",
    "start": "1043839",
    "end": "1046319"
  },
  {
    "text": "will of of numbers and that that that",
    "start": "1046319",
    "end": "1049039"
  },
  {
    "text": "long vector of numbers is going to have",
    "start": "1049039",
    "end": "1051679"
  },
  {
    "text": "encoded in it information about that",
    "start": "1051679",
    "end": "1054640"
  },
  {
    "text": "data in relation to the rest of the data",
    "start": "1054640",
    "end": "1057120"
  },
  {
    "text": "set that we're working with so if it's",
    "start": "1057120",
    "end": "1058640"
  },
  {
    "text": "textual data we have these embedding",
    "start": "1058640",
    "end": "1060480"
  },
  {
    "text": "models that will take a sentence for",
    "start": "1060480",
    "end": "1062480"
  },
  {
    "text": "example and turn it into a long string",
    "start": "1062480",
    "end": "1063919"
  },
  {
    "text": "of numbers that gets encoded as a vector",
    "start": "1063919",
    "end": "1066480"
  },
  {
    "text": "right so that's persisted as a vector",
    "start": "1066480",
    "end": "1068320"
  },
  {
    "text": "once we have vector databases and we're",
    "start": "1068320",
    "end": "1070240"
  },
  {
    "text": "we are saving all of our vectors um as",
    "start": "1070240",
    "end": "1074640"
  },
  {
    "text": "uh as for example the value of an index",
    "start": "1074640",
    "end": "1077200"
  },
  {
    "text": "key then we can do nice transformations",
    "start": "1077200",
    "end": "1079600"
  },
  {
    "text": "on them we can do really quick",
    "start": "1079600",
    "end": "1081679"
  },
  {
    "text": "similarity searches across those vector",
    "start": "1081679",
    "end": "1084000"
  },
  {
    "text": "databases are going to have a lot of",
    "start": "1084000",
    "end": "1085360"
  },
  {
    "text": "those algorithms already built in that",
    "start": "1085360",
    "end": "1086960"
  },
  {
    "text": "let us do comparisons against vectors so",
    "start": "1086960",
    "end": "1090559"
  },
  {
    "text": "they're really worth taking a look at",
    "start": "1090559",
    "end": "1092320"
  },
  {
    "text": "milv is really easy to get started with",
    "start": "1092320",
    "end": "1094559"
  },
  {
    "text": "um I really like it it's getting really",
    "start": "1094559",
    "end": "1096400"
  },
  {
    "text": "popular because of that there's sort of",
    "start": "1096400",
    "end": "1098240"
  },
  {
    "text": "a light there's a light flavor there's a",
    "start": "1098240",
    "end": "1100160"
  },
  {
    "text": "standalone flavor there's a distributed",
    "start": "1100160",
    "end": "1101760"
  },
  {
    "text": "flavor of Milvvis um it lets you it's",
    "start": "1101760",
    "end": "1104559"
  },
  {
    "text": "it's used very commonly in rag in graph",
    "start": "1104559",
    "end": "1106880"
  },
  {
    "text": "rag image search multimodal search",
    "start": "1106880",
    "end": "1109360"
  },
  {
    "text": "hybrid search all of these things um and",
    "start": "1109360",
    "end": "1111840"
  },
  {
    "text": "so uh we can uh discover for example the",
    "start": "1111840",
    "end": "1116080"
  },
  {
    "text": "nearest that we we use ANN we use KN&N",
    "start": "1116080",
    "end": "1119120"
  },
  {
    "text": "for all of our vector search algorithms",
    "start": "1119120",
    "end": "1120880"
  },
  {
    "text": "there's a the um the FIC vector search",
    "start": "1120880",
    "end": "1123600"
  },
  {
    "text": "algorithm all of those are natively",
    "start": "1123600",
    "end": "1125360"
  },
  {
    "text": "implemented in in",
    "start": "1125360",
    "end": "1126919"
  },
  {
    "text": "MILV so key considerations for um for",
    "start": "1126919",
    "end": "1131200"
  },
  {
    "text": "MLOps for data collection and",
    "start": "1131200",
    "end": "1132600"
  },
  {
    "text": "pre-processing are queries and",
    "start": "1132600",
    "end": "1134400"
  },
  {
    "text": "transforms have to be repeatable um",
    "start": "1134400",
    "end": "1136799"
  },
  {
    "text": "which is not always something that data",
    "start": "1136799",
    "end": "1138000"
  },
  {
    "text": "scientists keep in mind when they're",
    "start": "1138000",
    "end": "1139200"
  },
  {
    "text": "building their experiments um data",
    "start": "1139200",
    "end": "1140960"
  },
  {
    "text": "really should be managed by a team",
    "start": "1140960",
    "end": "1142400"
  },
  {
    "text": "including data scientists and data",
    "start": "1142400",
    "end": "1143840"
  },
  {
    "text": "engineers your ETL pipelines should be",
    "start": "1143840",
    "end": "1146240"
  },
  {
    "text": "managed in source control ideally um and",
    "start": "1146240",
    "end": "1149440"
  },
  {
    "text": "the choice of the data pipeline tool is",
    "start": "1149440",
    "end": "1151200"
  },
  {
    "text": "likely going to be an organizational",
    "start": "1151200",
    "end": "1152400"
  },
  {
    "text": "decision that's not really going to be",
    "start": "1152400",
    "end": "1153840"
  },
  {
    "text": "up to you you you know you as a data",
    "start": "1153840",
    "end": "1155600"
  },
  {
    "text": "scientist or as an individual engineer",
    "start": "1155600",
    "end": "1157360"
  },
  {
    "text": "unless you're on a very very small team",
    "start": "1157360",
    "end": "1158880"
  },
  {
    "text": "and a very small organization um and",
    "start": "1158880",
    "end": "1160880"
  },
  {
    "text": "data cataloging is very timeconuming but",
    "start": "1160880",
    "end": "1163039"
  },
  {
    "text": "very very well worth the effort",
    "start": "1163039",
    "end": "1166160"
  },
  {
    "text": "so next is our experimentation and",
    "start": "1166160",
    "end": "1167840"
  },
  {
    "text": "evaluation stage and we have a few tasks",
    "start": "1167840",
    "end": "1171600"
  },
  {
    "text": "here this is really the core like data",
    "start": "1171600",
    "end": "1173919"
  },
  {
    "text": "science discipline I think um where",
    "start": "1173919",
    "end": "1175840"
  },
  {
    "text": "we're selecting our model uh for the",
    "start": "1175840",
    "end": "1178240"
  },
  {
    "text": "task that we have to achieve um we're",
    "start": "1178240",
    "end": "1180559"
  },
  {
    "text": "making our model architectural decisions",
    "start": "1180559",
    "end": "1183200"
  },
  {
    "text": "uh we're building out our model we're",
    "start": "1183200",
    "end": "1185120"
  },
  {
    "text": "choosing a library if it's you know",
    "start": "1185120",
    "end": "1186880"
  },
  {
    "text": "tensorflow or caris or pytorch um we're",
    "start": "1186880",
    "end": "1189280"
  },
  {
    "text": "defining our input and output dimensions",
    "start": "1189280",
    "end": "1191760"
  },
  {
    "text": "um and then training it we have to",
    "start": "1191760",
    "end": "1193440"
  },
  {
    "text": "determine our hardware requirements",
    "start": "1193440",
    "end": "1195039"
  },
  {
    "text": "persist our model weights and our",
    "start": "1195039",
    "end": "1196440"
  },
  {
    "text": "parameters testing and evaluation is",
    "start": "1196440",
    "end": "1199200"
  },
  {
    "text": "where we start to define our metrics",
    "start": "1199200",
    "end": "1201200"
  },
  {
    "text": "right so we we need to be able to say",
    "start": "1201200",
    "end": "1202720"
  },
  {
    "text": "how well our model is working there are",
    "start": "1202720",
    "end": "1204640"
  },
  {
    "text": "specific metrics that go along with",
    "start": "1204640",
    "end": "1207039"
  },
  {
    "text": "certain tasks right so if you're using",
    "start": "1207039",
    "end": "1209120"
  },
  {
    "text": "if you're doing an information retrieval",
    "start": "1209120",
    "end": "1210720"
  },
  {
    "text": "model that's going to have its own set",
    "start": "1210720",
    "end": "1212000"
  },
  {
    "text": "of metrics and like a a classification",
    "start": "1212000",
    "end": "1214320"
  },
  {
    "text": "problem will have its own set of metrics",
    "start": "1214320",
    "end": "1215679"
  },
  {
    "text": "so we have to make sure that we define",
    "start": "1215679",
    "end": "1216960"
  },
  {
    "text": "those and then we're going to tune our",
    "start": "1216960",
    "end": "1218720"
  },
  {
    "text": "model's hyperparameters or in LLM world",
    "start": "1218720",
    "end": "1221600"
  },
  {
    "text": "we'll call this like fine-tuning right",
    "start": "1221600",
    "end": "1223760"
  },
  {
    "text": "um and so we're just going to see if our",
    "start": "1223760",
    "end": "1225200"
  },
  {
    "text": "model can be improved through for",
    "start": "1225200",
    "end": "1226880"
  },
  {
    "text": "example prompt engineering or through",
    "start": "1226880",
    "end": "1229440"
  },
  {
    "text": "fine-tuning or you know uh performance",
    "start": "1229440",
    "end": "1231679"
  },
  {
    "text": "improvements um uh but in like more",
    "start": "1231679",
    "end": "1235360"
  },
  {
    "text": "broadly this would be you know can we uh",
    "start": "1235360",
    "end": "1238480"
  },
  {
    "text": "change an optimizer or can we uh change",
    "start": "1238480",
    "end": "1242240"
  },
  {
    "text": "the number of epochs for example for",
    "start": "1242240",
    "end": "1245320"
  },
  {
    "text": "training so all of this is our",
    "start": "1245320",
    "end": "1247679"
  },
  {
    "text": "hypothesis testing tuning evaluation",
    "start": "1247679",
    "end": "1250080"
  },
  {
    "text": "metrics all these things um without",
    "start": "1250080",
    "end": "1252400"
  },
  {
    "text": "MLOps tooling data scientists we we",
    "start": "1252400",
    "end": "1255360"
  },
  {
    "text": "literally record this manually like",
    "start": "1255360",
    "end": "1256880"
  },
  {
    "text": "we'll have a spreadsheet and then you",
    "start": "1256880",
    "end": "1258799"
  },
  {
    "text": "log your hyperparameter and what that",
    "start": "1258799",
    "end": "1260640"
  },
  {
    "text": "value was and what the metric was",
    "start": "1260640",
    "end": "1262320"
  },
  {
    "text": "downstream and it's it's so timeconuming",
    "start": "1262320",
    "end": "1265200"
  },
  {
    "text": "um or you'll put it in a slide deck um",
    "start": "1265200",
    "end": "1267600"
  },
  {
    "text": "and it's it's it's terrible but if we",
    "start": "1267600",
    "end": "1269679"
  },
  {
    "text": "have experiment management and",
    "start": "1269679",
    "end": "1271240"
  },
  {
    "text": "cataloging then a lot of that is",
    "start": "1271240",
    "end": "1273280"
  },
  {
    "text": "automated for us so that's a huge",
    "start": "1273280",
    "end": "1275039"
  },
  {
    "text": "time-saving piece for um for us as data",
    "start": "1275039",
    "end": "1277760"
  },
  {
    "text": "scientists and I'm going to start",
    "start": "1277760",
    "end": "1279280"
  },
  {
    "text": "calling out MLflow uh MLflow is like",
    "start": "1279280",
    "end": "1282400"
  },
  {
    "text": "it's my favorite um and because it does",
    "start": "1282400",
    "end": "1285520"
  },
  {
    "text": "so many parts of the MLOps life cycle um",
    "start": "1285520",
    "end": "1289280"
  },
  {
    "text": "for us so this is a screenshot of MLflow",
    "start": "1289280",
    "end": "1293280"
  },
  {
    "text": "where you can see um some experiment",
    "start": "1293280",
    "end": "1295200"
  },
  {
    "text": "management so you launch your MLflow",
    "start": "1295200",
    "end": "1297840"
  },
  {
    "text": "tracking server and then you just uh log",
    "start": "1297840",
    "end": "1301039"
  },
  {
    "text": "your experimental designs um you can",
    "start": "1301039",
    "end": "1303440"
  },
  {
    "text": "have uh different parameters that you",
    "start": "1303440",
    "end": "1306000"
  },
  {
    "text": "log you can log different metrics um you",
    "start": "1306000",
    "end": "1309120"
  },
  {
    "text": "can even log your input and output",
    "start": "1309120",
    "end": "1310640"
  },
  {
    "text": "dimensions all of these",
    "start": "1310640",
    "end": "1312440"
  },
  {
    "text": "things so another wonderful benefit of",
    "start": "1312440",
    "end": "1316320"
  },
  {
    "text": "some of our experiment tracking and",
    "start": "1316320",
    "end": "1317760"
  },
  {
    "text": "management tooling is that it helps us",
    "start": "1317760",
    "end": "1319440"
  },
  {
    "text": "go from experimentation to production um",
    "start": "1319440",
    "end": "1322320"
  },
  {
    "text": "to deployment rather um a lot more",
    "start": "1322320",
    "end": "1325919"
  },
  {
    "text": "easily than we could without them so our",
    "start": "1325919",
    "end": "1328240"
  },
  {
    "text": "tooling makes a huge difference in this",
    "start": "1328240",
    "end": "1329679"
  },
  {
    "text": "case um experiment good experiment",
    "start": "1329679",
    "end": "1332159"
  },
  {
    "text": "management tooling is going to help us",
    "start": "1332159",
    "end": "1333280"
  },
  {
    "text": "do model versioning data versioning even",
    "start": "1333280",
    "end": "1336000"
  },
  {
    "text": "and model artifact storage so this is",
    "start": "1336000",
    "end": "1338960"
  },
  {
    "text": "another bit of MLOps that's unique so we",
    "start": "1338960",
    "end": "1341840"
  },
  {
    "text": "need to start storing different kinds of",
    "start": "1341840",
    "end": "1343520"
  },
  {
    "text": "artifacts to serve our model um so",
    "start": "1343520",
    "end": "1348640"
  },
  {
    "text": "here's MLflow again we have our um our",
    "start": "1348640",
    "end": "1353280"
  },
  {
    "text": "model validation so you can um validate",
    "start": "1353280",
    "end": "1355840"
  },
  {
    "text": "your model before deployment we have our",
    "start": "1355840",
    "end": "1358320"
  },
  {
    "text": "model sche model model schema is",
    "start": "1358320",
    "end": "1360240"
  },
  {
    "text": "automatically logged kind of in the in",
    "start": "1360240",
    "end": "1362880"
  },
  {
    "text": "the middle bit right there um our",
    "start": "1362880",
    "end": "1365600"
  },
  {
    "text": "dependencies are actually defined for us",
    "start": "1365600",
    "end": "1368480"
  },
  {
    "text": "as part of um MLflow's API and our",
    "start": "1368480",
    "end": "1372159"
  },
  {
    "text": "environments are are are preset um we",
    "start": "1372159",
    "end": "1376720"
  },
  {
    "text": "also have model registries so the model",
    "start": "1376720",
    "end": "1378799"
  },
  {
    "text": "itself that like binary file or pickle",
    "start": "1378799",
    "end": "1381039"
  },
  {
    "text": "file or whatever you're going to use um",
    "start": "1381039",
    "end": "1382880"
  },
  {
    "text": "is also persisted in a model registry",
    "start": "1382880",
    "end": "1385280"
  },
  {
    "text": "and that can be on the same server as",
    "start": "1385280",
    "end": "1387440"
  },
  {
    "text": "your MLflow tracking server or that",
    "start": "1387440",
    "end": "1389280"
  },
  {
    "text": "could be",
    "start": "1389280",
    "end": "1390760"
  },
  {
    "text": "remote so our model deployment uh we",
    "start": "1390760",
    "end": "1393679"
  },
  {
    "text": "have some key tasks again defining the",
    "start": "1393679",
    "end": "1396000"
  },
  {
    "text": "environment um defining our signature",
    "start": "1396000",
    "end": "1398320"
  },
  {
    "text": "model signature uh establishing",
    "start": "1398320",
    "end": "1400640"
  },
  {
    "text": "versioning having our CI/CD checks and",
    "start": "1400640",
    "end": "1403880"
  },
  {
    "text": "retraining so this gets into this",
    "start": "1403880",
    "end": "1406480"
  },
  {
    "text": "concept of model ops so in model ops we",
    "start": "1406480",
    "end": "1409600"
  },
  {
    "text": "have our model artifacts we'll discuss",
    "start": "1409600",
    "end": "1411280"
  },
  {
    "text": "what those are we have our deployment",
    "start": "1411280",
    "end": "1413400"
  },
  {
    "text": "considerations and those combined leads",
    "start": "1413400",
    "end": "1416799"
  },
  {
    "text": "us to ensuring that our trained model",
    "start": "1416799",
    "end": "1418559"
  },
  {
    "text": "artifacts are persisted and updated and",
    "start": "1418559",
    "end": "1420640"
  },
  {
    "text": "available for other",
    "start": "1420640",
    "end": "1422919"
  },
  {
    "text": "services so more artifacts to consider",
    "start": "1422919",
    "end": "1426720"
  },
  {
    "text": "for our MLOps deployment we have our",
    "start": "1426720",
    "end": "1429120"
  },
  {
    "text": "training checkpoints right if you have a",
    "start": "1429120",
    "end": "1430720"
  },
  {
    "text": "long training job you don't want it to",
    "start": "1430720",
    "end": "1432000"
  },
  {
    "text": "just you know wink out of existence",
    "start": "1432000",
    "end": "1434000"
  },
  {
    "text": "because you had you know um uh some",
    "start": "1434000",
    "end": "1436400"
  },
  {
    "text": "server crash somewhere so we have model",
    "start": "1436400",
    "end": "1438320"
  },
  {
    "text": "training checkpoints that are serialized",
    "start": "1438320",
    "end": "1439919"
  },
  {
    "text": "to disk and also persisted in some",
    "start": "1439919",
    "end": "1441440"
  },
  {
    "text": "additional remote storage the train",
    "start": "1441440",
    "end": "1443200"
  },
  {
    "text": "model itself um that's going to be again",
    "start": "1443200",
    "end": "1445280"
  },
  {
    "text": "your job lib file your pickle file",
    "start": "1445280",
    "end": "1447280"
  },
  {
    "text": "binary whatever it is and that will be",
    "start": "1447280",
    "end": "1449520"
  },
  {
    "text": "um could be serialized to disk could be",
    "start": "1449520",
    "end": "1451520"
  },
  {
    "text": "persisted in a location that's",
    "start": "1451520",
    "end": "1452799"
  },
  {
    "text": "accessible to the inference server um",
    "start": "1452799",
    "end": "1454799"
  },
  {
    "text": "there's and and you also want to have",
    "start": "1454799",
    "end": "1457039"
  },
  {
    "text": "your your model signing uh your train",
    "start": "1457039",
    "end": "1460240"
  },
  {
    "text": "model hyperparameters those are going to",
    "start": "1460240",
    "end": "1462000"
  },
  {
    "text": "be recorded to an audit table your",
    "start": "1462000",
    "end": "1463840"
  },
  {
    "text": "training data catalog that's maybe a",
    "start": "1463840",
    "end": "1465760"
  },
  {
    "text": "hash of your training data descriptive",
    "start": "1465760",
    "end": "1467760"
  },
  {
    "text": "statistics of your data things like that",
    "start": "1467760",
    "end": "1469520"
  },
  {
    "text": "and then your training evaluation",
    "start": "1469520",
    "end": "1470799"
  },
  {
    "text": "metrics and feature importances those",
    "start": "1470799",
    "end": "1472640"
  },
  {
    "text": "are also recorded to audit tables so",
    "start": "1472640",
    "end": "1474559"
  },
  {
    "text": "we're we're starting to get into um uh",
    "start": "1474559",
    "end": "1477840"
  },
  {
    "text": "you know a lot of unique concerns for",
    "start": "1477840",
    "end": "1480720"
  },
  {
    "text": "MLOps which I think is it's it's really",
    "start": "1480720",
    "end": "1482720"
  },
  {
    "text": "key though to make sure we have",
    "start": "1482720",
    "end": "1483840"
  },
  {
    "text": "reproducibility that we have",
    "start": "1483840",
    "end": "1485279"
  },
  {
    "text": "observability all the way through our",
    "start": "1485279",
    "end": "1487919"
  },
  {
    "text": "our",
    "start": "1487919",
    "end": "1489240"
  },
  {
    "text": "architecture so model deployment",
    "start": "1489240",
    "end": "1491279"
  },
  {
    "text": "considerations um uh we need our CI/CD",
    "start": "1491279",
    "end": "1496240"
  },
  {
    "text": "pipelines we need to understand how",
    "start": "1496240",
    "end": "1498080"
  },
  {
    "text": "often we want our model to be retrained",
    "start": "1498080",
    "end": "1499760"
  },
  {
    "text": "that's going to be based off the data",
    "start": "1499760",
    "end": "1500880"
  },
  {
    "text": "and the problem that we're addressing",
    "start": "1500880",
    "end": "1502720"
  },
  {
    "text": "how are you going to track your model",
    "start": "1502720",
    "end": "1504240"
  },
  {
    "text": "through version control um and is your",
    "start": "1504240",
    "end": "1506799"
  },
  {
    "text": "training service going to need to have",
    "start": "1506799",
    "end": "1508080"
  },
  {
    "text": "other persistence requirements um are",
    "start": "1508080",
    "end": "1510000"
  },
  {
    "text": "you gonna have sidecars um are you going",
    "start": "1510000",
    "end": "1511679"
  },
  {
    "text": "to have temporary data stores between",
    "start": "1511679",
    "end": "1513039"
  },
  {
    "text": "model training runs um I am running out",
    "start": "1513039",
    "end": "1516480"
  },
  {
    "text": "of time a little bit so I'm going to fly",
    "start": "1516480",
    "end": "1518640"
  },
  {
    "text": "through this but we have um CI/CD",
    "start": "1518640",
    "end": "1521039"
  },
  {
    "text": "tooling um specific to MLOps and also",
    "start": "1521039",
    "end": "1524159"
  },
  {
    "text": "not we have kit ops GitHub actions",
    "start": "1524159",
    "end": "1526960"
  },
  {
    "text": "Jenkins and harness uh GitHub actions I",
    "start": "1526960",
    "end": "1529919"
  },
  {
    "text": "think we're most of us are pretty",
    "start": "1529919",
    "end": "1531279"
  },
  {
    "text": "familiar with um that's going you in",
    "start": "1531279",
    "end": "1533840"
  },
  {
    "text": "GitHub actions you can define all kinds",
    "start": "1533840",
    "end": "1535760"
  },
  {
    "text": "of different um uh tasks you can have",
    "start": "1535760",
    "end": "1538720"
  },
  {
    "text": "your data prep-processing model training",
    "start": "1538720",
    "end": "1540720"
  },
  {
    "text": "and validation schedules um you can have",
    "start": "1540720",
    "end": "1543840"
  },
  {
    "text": "monitoring alerts in GitHub actions you",
    "start": "1543840",
    "end": "1546080"
  },
  {
    "text": "can define workflows in YAML and you're",
    "start": "1546080",
    "end": "1547919"
  },
  {
    "text": "going to automate packaging and",
    "start": "1547919",
    "end": "1549120"
  },
  {
    "text": "deployment of your models into your",
    "start": "1549120",
    "end": "1550400"
  },
  {
    "text": "production",
    "start": "1550400",
    "end": "1551320"
  },
  {
    "text": "environment um model version control",
    "start": "1551320",
    "end": "1554480"
  },
  {
    "text": "again MLflow it handles model version",
    "start": "1554480",
    "end": "1557039"
  },
  {
    "text": "control for us we can both do versions",
    "start": "1557039",
    "end": "1558640"
  },
  {
    "text": "and also aliases so you can have tags um",
    "start": "1558640",
    "end": "1561919"
  },
  {
    "text": "for your model to say okay this is the",
    "start": "1561919",
    "end": "1563440"
  },
  {
    "text": "one that this is the model we're going",
    "start": "1563440",
    "end": "1564559"
  },
  {
    "text": "to promote based off of our",
    "start": "1564559",
    "end": "1566600"
  },
  {
    "text": "metrics um so again our those key",
    "start": "1566600",
    "end": "1569919"
  },
  {
    "text": "considerations for deployment your data",
    "start": "1569919",
    "end": "1572400"
  },
  {
    "text": "and your model artifacts that are",
    "start": "1572400",
    "end": "1573760"
  },
  {
    "text": "created during training need to be",
    "start": "1573760",
    "end": "1574880"
  },
  {
    "text": "available at inference time um we need",
    "start": "1574880",
    "end": "1577600"
  },
  {
    "text": "to persist a record of our training data",
    "start": "1577600",
    "end": "1580400"
  },
  {
    "text": "uh we have different hardware",
    "start": "1580400",
    "end": "1582480"
  },
  {
    "text": "requirements for training we need to",
    "start": "1582480",
    "end": "1584400"
  },
  {
    "text": "understand if we need sidecars and if so",
    "start": "1584400",
    "end": "1586400"
  },
  {
    "text": "are sidecars allowed in your cluster um",
    "start": "1586400",
    "end": "1588960"
  },
  {
    "text": "your container resource constraints",
    "start": "1588960",
    "end": "1590640"
  },
  {
    "text": "might need to be disabled for massive",
    "start": "1590640",
    "end": "1592400"
  },
  {
    "text": "training jobs um and there's so many",
    "start": "1592400",
    "end": "1594720"
  },
  {
    "text": "audit tables there's just the most audit",
    "start": "1594720",
    "end": "1596559"
  },
  {
    "text": "tables um but you know you need to",
    "start": "1596559",
    "end": "1599039"
  },
  {
    "text": "record the model version your evaluation",
    "start": "1599039",
    "end": "1600720"
  },
  {
    "text": "results future importances your data",
    "start": "1600720",
    "end": "1602320"
  },
  {
    "text": "catalog a hash of your data um and",
    "start": "1602320",
    "end": "1605600"
  },
  {
    "text": "signing your model so serving and",
    "start": "1605600",
    "end": "1608400"
  },
  {
    "text": "inferencing we have our key tasks which",
    "start": "1608400",
    "end": "1610799"
  },
  {
    "text": "is just um you know online inferencing",
    "start": "1610799",
    "end": "1614720"
  },
  {
    "text": "batch inferencing and then one-off",
    "start": "1614720",
    "end": "1616720"
  },
  {
    "text": "inferencing think if you're doing",
    "start": "1616720",
    "end": "1617600"
  },
  {
    "text": "one-off inferencing do you really need a",
    "start": "1617600",
    "end": "1619039"
  },
  {
    "text": "whole MLOps pipeline it's something to",
    "start": "1619039",
    "end": "1620559"
  },
  {
    "text": "keep in mind um if it's online that's",
    "start": "1620559",
    "end": "1622960"
  },
  {
    "text": "kind of streaming data uh if it's batch",
    "start": "1622960",
    "end": "1625279"
  },
  {
    "text": "maybe that's just a a chron job so if",
    "start": "1625279",
    "end": "1627120"
  },
  {
    "text": "it's a batch processing job batch",
    "start": "1627120",
    "end": "1628799"
  },
  {
    "text": "inferencing job then you know maybe you",
    "start": "1628799",
    "end": "1630960"
  },
  {
    "text": "define something that runs once day um",
    "start": "1630960",
    "end": "1634080"
  },
  {
    "text": "you need to make sure that your features",
    "start": "1634080",
    "end": "1635520"
  },
  {
    "text": "and your other data transformations are",
    "start": "1635520",
    "end": "1637039"
  },
  {
    "text": "available at inference time uh and all",
    "start": "1637039",
    "end": "1640000"
  },
  {
    "text": "of this is done through an API endpoint",
    "start": "1640000",
    "end": "1642400"
  },
  {
    "text": "um for your for your calling services",
    "start": "1642400",
    "end": "1645880"
  },
  {
    "text": "um again uh MLflow I love it it handles",
    "start": "1645880",
    "end": "1650559"
  },
  {
    "text": "so much of this for us um so we have uh",
    "start": "1650559",
    "end": "1654960"
  },
  {
    "text": "MLflow will let us create our our Docker",
    "start": "1654960",
    "end": "1657840"
  },
  {
    "text": "containers uh we can have multiple",
    "start": "1657840",
    "end": "1659440"
  },
  {
    "text": "deployment targets to um you know to",
    "start": "1659440",
    "end": "1662400"
  },
  {
    "text": "different cloud services or even locally",
    "start": "1662400",
    "end": "1664799"
  },
  {
    "text": "um and it'll have your your inference",
    "start": "1664799",
    "end": "1666880"
  },
  {
    "text": "server will be provided with a REST API",
    "start": "1666880",
    "end": "1669679"
  },
  {
    "text": "um it wouldn't be CubeCon if we didn't",
    "start": "1669679",
    "end": "1671760"
  },
  {
    "text": "talk about CubeFlow and Kerve but there",
    "start": "1671760",
    "end": "1673679"
  },
  {
    "text": "is a whole there's a ton of content",
    "start": "1673679",
    "end": "1675520"
  },
  {
    "text": "happening around this i encourage you to",
    "start": "1675520",
    "end": "1678159"
  },
  {
    "text": "check it out on YouTube later um and",
    "start": "1678159",
    "end": "1681520"
  },
  {
    "text": "yeah so our key considerations for",
    "start": "1681520",
    "end": "1683520"
  },
  {
    "text": "serving and inferencing you know we're",
    "start": "1683520",
    "end": "1685200"
  },
  {
    "text": "going to have different requirements for",
    "start": "1685200",
    "end": "1686240"
  },
  {
    "text": "streaming batch and one-off LLMs have a",
    "start": "1686240",
    "end": "1688640"
  },
  {
    "text": "completely different requirements from",
    "start": "1688640",
    "end": "1690000"
  },
  {
    "text": "traditional ML again I have this",
    "start": "1690000",
    "end": "1691520"
  },
  {
    "text": "four-part lecture series that you can",
    "start": "1691520",
    "end": "1692960"
  },
  {
    "text": "watch on YouTube if you'd like to um",
    "start": "1692960",
    "end": "1694640"
  },
  {
    "text": "that talks a lot more about that um",
    "start": "1694640",
    "end": "1696799"
  },
  {
    "text": "endpoint availability is going to be our",
    "start": "1696799",
    "end": "1698159"
  },
  {
    "text": "top concern for inferencing um but we",
    "start": "1698159",
    "end": "1700159"
  },
  {
    "text": "also need to think about bam bandwidth",
    "start": "1700159",
    "end": "1701600"
  },
  {
    "text": "and latency um for our inference server",
    "start": "1701600",
    "end": "1705039"
  },
  {
    "text": "the cost for that can be really",
    "start": "1705039",
    "end": "1706399"
  },
  {
    "text": "unpredictable because bandwidth is",
    "start": "1706399",
    "end": "1709159"
  },
  {
    "text": "unpredictable um monitoring and",
    "start": "1709159",
    "end": "1711360"
  },
  {
    "text": "maintenance uh we don't have much time",
    "start": "1711360",
    "end": "1713520"
  },
  {
    "text": "but evidently AI is amazing tool you",
    "start": "1713520",
    "end": "1715520"
  },
  {
    "text": "should use evidently AI for your",
    "start": "1715520",
    "end": "1716720"
  },
  {
    "text": "monitoring and maintenance um anomaly",
    "start": "1716720",
    "end": "1719360"
  },
  {
    "text": "detection is great if you're too busy",
    "start": "1719360",
    "end": "1721039"
  },
  {
    "text": "for all of this uh here's what you",
    "start": "1721039",
    "end": "1723120"
  },
  {
    "text": "should do use Airflow for data pipelines",
    "start": "1723120",
    "end": "1725279"
  },
  {
    "text": "MLflow for your evaluation KSERF for uh",
    "start": "1725279",
    "end": "1729679"
  },
  {
    "text": "for serving add in some Prometheus add",
    "start": "1729679",
    "end": "1732559"
  },
  {
    "text": "in some evidently you'll have a nice",
    "start": "1732559",
    "end": "1734240"
  },
  {
    "text": "time if you're too busy for all of that",
    "start": "1734240",
    "end": "1736480"
  },
  {
    "text": "use MLflow GitHub actions evidently AI",
    "start": "1736480",
    "end": "1739840"
  },
  {
    "text": "and if you're really not that busy do",
    "start": "1739840",
    "end": "1741840"
  },
  {
    "text": "the whole thing do DBT and Airflow use",
    "start": "1741840",
    "end": "1744399"
  },
  {
    "text": "Milvvis as your vector database feast",
    "start": "1744399",
    "end": "1746559"
  },
  {
    "text": "for feature stores experiment tracking",
    "start": "1746559",
    "end": "1748480"
  },
  {
    "text": "through MLflow",
    "start": "1748480",
    "end": "1750159"
  },
  {
    "text": "um deploy through MLflow and GitHub",
    "start": "1750159",
    "end": "1751679"
  },
  {
    "text": "actions serve through KSER observability",
    "start": "1751679",
    "end": "1754080"
  },
  {
    "text": "through Prometheus and evidently AI do",
    "start": "1754080",
    "end": "1756399"
  },
  {
    "text": "some custom alerting that's me thank you",
    "start": "1756399",
    "end": "1758480"
  },
  {
    "text": "so much",
    "start": "1758480",
    "end": "1761640"
  }
]
[
  {
    "text": "hello everybody uh we're gonna get starting our next session so hi everybody my name is danielle i'm cncf",
    "start": "10080",
    "end": "16800"
  },
  {
    "text": "ambassador i'm so happy to be here as a moderate this session today",
    "start": "16800",
    "end": "22080"
  },
  {
    "text": "so i'm really happy i mean uh back to the return i mean in person event",
    "start": "22080",
    "end": "27199"
  },
  {
    "text": "since pandemi so today uh we're gonna talk a little bit about next session as you can see",
    "start": "27199",
    "end": "33920"
  },
  {
    "text": "the kubernetes evangelion auto scary cater so please welcome our next great speaker",
    "start": "33920",
    "end": "40079"
  },
  {
    "text": "uh jorge from uh dark planner i'm sorry my bad pronunciation spanish",
    "start": "40079",
    "end": "45600"
  },
  {
    "text": "and there's v-neck from the red head and the principal software engineer and a please welcome",
    "start": "45600",
    "end": "54038"
  },
  {
    "text": "okay okay first of all thanks to all for staying",
    "start": "58320",
    "end": "64158"
  },
  {
    "text": "here we will try to teach us to be funny and just share the knowledge we are gonna",
    "start": "64159",
    "end": "70080"
  },
  {
    "text": "talk about kubernetes event drive and auto scaling aka keda",
    "start": "70080",
    "end": "75360"
  },
  {
    "text": "and first of all who am i i'm jorge dorado i'm an experiment of planner tech",
    "start": "75360",
    "end": "80560"
  },
  {
    "text": "i'm one of kedah maintainer board and also microsoft mvp in developer",
    "start": "80560",
    "end": "85920"
  },
  {
    "text": "technologies and you can see my social media networks there yes if you want to",
    "start": "85920",
    "end": "91600"
  },
  {
    "text": "write me make me any question you want no problem at all and now my",
    "start": "91600",
    "end": "97360"
  },
  {
    "text": "fault spinyek will introduce pizza hey my name is vinayak robotic i know the name is pretty hard to pronounce but",
    "start": "97360",
    "end": "104079"
  },
  {
    "text": "both guys did a pretty good job so that's fine i'm from czech republic i'm a software internet third hat and i'm",
    "start": "104079",
    "end": "110640"
  },
  {
    "text": "working on openshift serverless which is native stuff and i'm also kidding maintainer",
    "start": "110640",
    "end": "116000"
  },
  {
    "text": "and yeah we can go ahead so today we will talk about kedar so this is the agenda",
    "start": "116000",
    "end": "121520"
  },
  {
    "text": "and we can start so basically what is kedar what is the project what is the main goal of the project",
    "start": "121520",
    "end": "127840"
  },
  {
    "text": "if there is just one sentence one thing that you need to know after this presentation is that we",
    "start": "127840",
    "end": "132879"
  },
  {
    "text": "are really trying to make kubernetes even driven auto scaling that simple so",
    "start": "132879",
    "end": "138400"
  },
  {
    "text": "probably maybe we can finish the presentation what do you think okay we have a lot of attendees please work a",
    "start": "138400",
    "end": "144640"
  },
  {
    "text": "bit more they want to learn a bit more let's continue i don't know let's try to do it okay okay okay so i'll try",
    "start": "144640",
    "end": "150800"
  },
  {
    "text": "something so what is the use case so let's say that you have very simple",
    "start": "150800",
    "end": "156080"
  },
  {
    "text": "application it's a consumer application that consume messages from some external service",
    "start": "156080",
    "end": "161200"
  },
  {
    "text": "let's say you have a kafka consumer application that consume messages from kafka topic",
    "start": "161200",
    "end": "166640"
  },
  {
    "text": "and you would like to auto scale this application so how you can do that",
    "start": "166640",
    "end": "171680"
  },
  {
    "text": "on kubernetes you have hpa right but with hpa the options are you can scale",
    "start": "171680",
    "end": "177200"
  },
  {
    "text": "the application based on cpu or scaled application based on memory but",
    "start": "177200",
    "end": "182800"
  },
  {
    "text": "now it is even driven world right everything is 7-driven so this might not be the best solution how",
    "start": "182800",
    "end": "188640"
  },
  {
    "text": "to drive the auto scaling because the cpu or memory usage might not correlate with the needs for for the auto scaling",
    "start": "188640",
    "end": "195760"
  },
  {
    "text": "so here comes kedah for the rescue so basically this is the example application just",
    "start": "195760",
    "end": "201280"
  },
  {
    "text": "redesigned to use scada you don't have to change the application you don't have to change the deployment you just plug",
    "start": "201280",
    "end": "206560"
  },
  {
    "text": "it in and cada will scrape metrics from the external service so in this case it is the kafka topic and based on the",
    "start": "206560",
    "end": "212799"
  },
  {
    "text": "number of unprocessed messages it will automatically scare our application and if there are no messages it can also",
    "start": "212799",
    "end": "218959"
  },
  {
    "text": "scale down to zero this is something that hpa cannot do there is like a alpha version that already in the kubernetes",
    "start": "218959",
    "end": "225920"
  },
  {
    "text": "but but currently you can do that with hpa so this is the main goal of of the project",
    "start": "225920",
    "end": "232560"
  },
  {
    "text": "and basically this is just a quote from one of the users that he mentioned because there were ways how to do the",
    "start": "232560",
    "end": "238720"
  },
  {
    "text": "auto scaling based on custom metrics but the the stuff to actually",
    "start": "238720",
    "end": "244319"
  },
  {
    "text": "actually do that and to configure the custom metrics is very very complex",
    "start": "244319",
    "end": "249360"
  },
  {
    "text": "and we just try to do the same way but very easily yeah and",
    "start": "249360",
    "end": "255439"
  },
  {
    "text": "we can imagine the common scenario before keda i guess that",
    "start": "255439",
    "end": "260959"
  },
  {
    "text": "you have been working with kubernetes and probably in some scenarios where you",
    "start": "260959",
    "end": "266160"
  },
  {
    "text": "need a higher scale based on for instance h3ometrics aws matrix whatever not",
    "start": "266160",
    "end": "272320"
  },
  {
    "text": "important as you could know or if you don't know i should explain it to you no problem in",
    "start": "272320",
    "end": "277680"
  },
  {
    "text": "kubernetes we have three different api metrics ipm one is a metric",
    "start": "277680",
    "end": "283199"
  },
  {
    "text": "that is already locked by the normal metric server the second one is custom matrix",
    "start": "283199",
    "end": "289040"
  },
  {
    "text": "third one is external metrics usually adapters like monitor",
    "start": "289040",
    "end": "294960"
  },
  {
    "text": "from infuse or others blocks customers what's the problem imagine that you are starting your",
    "start": "294960",
    "end": "300960"
  },
  {
    "text": "project you are okay i have a rabbit that's all let's install directly the",
    "start": "300960",
    "end": "306080"
  },
  {
    "text": "rabbit adapter yeah for scaling based on what's the problem imagine that oh but i",
    "start": "306080",
    "end": "311360"
  },
  {
    "text": "would like to get some metrics for it from insurmountable or from another provider",
    "start": "311360",
    "end": "317039"
  },
  {
    "text": "monitoring system the problem is that you cannot because the ap the custom metrics api is already low but your",
    "start": "317039",
    "end": "323520"
  },
  {
    "text": "rabbits so you have two options move all your things to prometheus scrap scraping the",
    "start": "323520",
    "end": "329919"
  },
  {
    "text": "metrics from different sources and just use it for the same",
    "start": "329919",
    "end": "335440"
  },
  {
    "text": "and with that change you could use the normal approach of deployment plus hpa",
    "start": "335440",
    "end": "340720"
  },
  {
    "text": "okay what can i solve why kedah is useful at least in my opinion",
    "start": "340720",
    "end": "346720"
  },
  {
    "text": "who could imagine that i don't get a useful okay the point is that we have more or",
    "start": "346720",
    "end": "352240"
  },
  {
    "text": "less the same scenario here we have the deployment but we replaced the hpa with the scale audio",
    "start": "352240",
    "end": "358400"
  },
  {
    "text": "the scale object is just a crd that get a register in kubernetes api apis",
    "start": "358400",
    "end": "364720"
  },
  {
    "text": "which don't worry we will see one example of them but basically it's another object that",
    "start": "364720",
    "end": "370880"
  },
  {
    "text": "says to kera how we want to scale our application so kera will read this scale",
    "start": "370880",
    "end": "376960"
  },
  {
    "text": "object and internally we'll prepare all the needed things just for",
    "start": "376960",
    "end": "382160"
  },
  {
    "text": "expose those metrics in a single network circuit so get a wheel lock external metrics api",
    "start": "382160",
    "end": "388960"
  },
  {
    "text": "for serving the metrics but with keva we could serve all the different upstream",
    "start": "388960",
    "end": "394080"
  },
  {
    "text": "we could have a scalar based on service paths and other based on prometheus kafka and a lot of different scalers",
    "start": "394080",
    "end": "400319"
  },
  {
    "text": "that get a support just for giving some highlights about",
    "start": "400319",
    "end": "407039"
  },
  {
    "text": "kela maybe in the other side no problem the only intention of cada is",
    "start": "407039",
    "end": "413680"
  },
  {
    "text": "make the autoscaling simple we don't want to manage any other thing than outer skin the scope is really limited",
    "start": "413680",
    "end": "422880"
  },
  {
    "text": "keva started as a partnership between red hat and microsoft",
    "start": "422880",
    "end": "428479"
  },
  {
    "text": "three years ago could be yeah more or less three years ago right now is a project of cncf because",
    "start": "428479",
    "end": "435199"
  },
  {
    "text": "kedah was donated to cncf and right now it's a science incubation incubation yeah",
    "start": "435199",
    "end": "442880"
  },
  {
    "text": "it was a it was donated two years ago and after version 2.0 now right now it's",
    "start": "443840",
    "end": "450960"
  },
  {
    "text": "an incubating project and currently the current version is 2.7",
    "start": "450960",
    "end": "457120"
  },
  {
    "text": "and usually we release new versions every three months every three months just for",
    "start": "457120",
    "end": "462560"
  },
  {
    "text": "giving some highlights about uh how keller works and",
    "start": "462560",
    "end": "467759"
  },
  {
    "text": "is get a project done by a group of friends of course i expect that i",
    "start": "467759",
    "end": "472800"
  },
  {
    "text": "consider you as a friend i will think about it oh my god oh you are praising my heart",
    "start": "472800",
    "end": "478319"
  },
  {
    "text": "but apart from us you can see we have more or less a bit less than 5 000 stars",
    "start": "478319",
    "end": "486479"
  },
  {
    "text": "on github more than 190 different contributors and several users and inside our",
    "start": "486479",
    "end": "494400"
  },
  {
    "text": "contributors there are it's not a small companies maybe the smallest companies there is mine",
    "start": "494400",
    "end": "500479"
  },
  {
    "text": "but others are smallest companies like red hat microsoft and abn super small",
    "start": "500479",
    "end": "506080"
  },
  {
    "text": "who knows about this right and also our users are quite different",
    "start": "506080",
    "end": "512320"
  },
  {
    "text": "and we are super proud about them if you use kedah don't worry you can be listed we",
    "start": "512320",
    "end": "518240"
  },
  {
    "text": "will be proud of you also and yes we're going",
    "start": "518240",
    "end": "523599"
  },
  {
    "text": "the extension in the bottom you can see that dot sh a community you can see all the",
    "start": "523599",
    "end": "529519"
  },
  {
    "text": "information about the community about how we manage the project because we try to be",
    "start": "529519",
    "end": "535360"
  },
  {
    "text": "closest as possible to community because it's a community project not a business project from a company",
    "start": "535360",
    "end": "540480"
  },
  {
    "text": "and every two weeks we have our open meetup with all interested people",
    "start": "540480",
    "end": "547680"
  },
  {
    "text": "okay so let's talk about um the concepts and architecture how can i design and how what is actually doing so as we",
    "start": "547680",
    "end": "553760"
  },
  {
    "text": "mentioned we are auto scaling deployments kubernetes deployments you can also spawn kubernetes jobs based on",
    "start": "553760",
    "end": "559680"
  },
  {
    "text": "the events uh and also you can target a custom resource if the custom resource",
    "start": "559680",
    "end": "565519"
  },
  {
    "text": "implements specific thing but you can also target your custom resources so for example argo rollout",
    "start": "565519",
    "end": "570720"
  },
  {
    "text": "uh as we said before we have",
    "start": "570720",
    "end": "577319"
  },
  {
    "text": "it was you we have 50 plus scalers so different services aws azure rabbit kafka you name",
    "start": "578240",
    "end": "585680"
  },
  {
    "text": "it and basically the main concept is really with scale based on the events in the",
    "start": "585680",
    "end": "590800"
  },
  {
    "text": "target system uh important aspect is that itself does not manipulate the data you need to handle",
    "start": "590800",
    "end": "597680"
  },
  {
    "text": "the data transfer to your application we just do the scaling okay so uh this is like let's say the",
    "start": "597680",
    "end": "604720"
  },
  {
    "text": "architecture so there are two main components there is operator that monitors the custom",
    "start": "604720",
    "end": "609920"
  },
  {
    "text": "resources and then we have the metrics server which provides the metrics to the hpa so",
    "start": "609920",
    "end": "617760"
  },
  {
    "text": "under the hood kedar for each skill object cada creates hpa that does the scaling from zero to n and operator does",
    "start": "617760",
    "end": "624880"
  },
  {
    "text": "the scaling from one from no from one to n and operator does the",
    "start": "624880",
    "end": "629920"
  },
  {
    "text": "scaling from zero to one so that way we can achieve the full scalability",
    "start": "629920",
    "end": "635360"
  },
  {
    "text": "okay so this is the example of uh scale object as you can see it's pretty simple we just need to tell it what workload",
    "start": "635360",
    "end": "642560"
  },
  {
    "text": "you you would like to you would like to scale this is the lagdos scale target then you define the minimum maximum",
    "start": "642560",
    "end": "649200"
  },
  {
    "text": "replicas and then there is a trigger section and in the trigger section you can you can specify multiple triggers in",
    "start": "649200",
    "end": "655200"
  },
  {
    "text": "this case it is just a kafka so you specify okay this is my kafka broker this is the consumer group this is the",
    "start": "655200",
    "end": "660480"
  },
  {
    "text": "topic and the lag so based on the based on the lag it will it will automatically scan my application there are multiple",
    "start": "660480",
    "end": "666399"
  },
  {
    "text": "additional options but this is just the highlight how you can how you can do that",
    "start": "666399",
    "end": "671920"
  },
  {
    "text": "and this is skill job example so this is the other crd so for for spawning new",
    "start": "672320",
    "end": "677440"
  },
  {
    "text": "communities super fast okay okay so",
    "start": "677440",
    "end": "682959"
  },
  {
    "text": "basically it's a very similar thing here here you put your standard kubernetes job specification",
    "start": "682959",
    "end": "689600"
  },
  {
    "text": "and based on the evidence on the system it creates a new new kubernetes job so it's very good for batch processing and",
    "start": "689600",
    "end": "696800"
  },
  {
    "text": "especially for processing of long running executions because if you would like to if you would like",
    "start": "696800",
    "end": "702399"
  },
  {
    "text": "to scale your application that um handles some long process the hpa thing might not be might not be ideal because",
    "start": "702399",
    "end": "709120"
  },
  {
    "text": "you know once you process the messages from the system and the processing starts the metrics are already already down so",
    "start": "709120",
    "end": "715279"
  },
  {
    "text": "hpa might scale down your application in the middle of processing but if you scale jobs you can just spawn a new new",
    "start": "715279",
    "end": "720880"
  },
  {
    "text": "jobs to do the processing all right yeah some advanced features",
    "start": "720880",
    "end": "726800"
  },
  {
    "text": "so basically we said or again i can say",
    "start": "726800",
    "end": "732399"
  },
  {
    "text": "right now we try to don't reinvent the wheel what that means",
    "start": "732399",
    "end": "737600"
  },
  {
    "text": "if kubernetes already has a super good piece of software of software name hpa",
    "start": "737600",
    "end": "742720"
  },
  {
    "text": "controller we just try to reuse it i mean we can expose the metric and then",
    "start": "742720",
    "end": "749120"
  },
  {
    "text": "configure the hpa to request this metric but why couldn't we extend that",
    "start": "749120",
    "end": "755760"
  },
  {
    "text": "functionality in get catastrophe why not so because we can",
    "start": "755760",
    "end": "762240"
  },
  {
    "text": "because we can implement some other features like a fallback mechanism what is a format",
    "start": "762240",
    "end": "768800"
  },
  {
    "text": "imagine that your kaka broker your promise your server whatever is done",
    "start": "768800",
    "end": "774000"
  },
  {
    "text": "it's done so you cannot reach that what do you want in that case you can specify using the dci feature",
    "start": "774000",
    "end": "781839"
  },
  {
    "text": "set in the fallback replicas okay if in case of any upstream is available for",
    "start": "781839",
    "end": "788880"
  },
  {
    "text": "five times in a row just scale to or not the scale do just consider that scaling",
    "start": "788880",
    "end": "795360"
  },
  {
    "text": "that figure as a requirement of into the set replica for",
    "start": "795360",
    "end": "800800"
  },
  {
    "text": "instance if you have more than one trigger and only one phase that trigger will request that amount of replicas and the",
    "start": "800800",
    "end": "807519"
  },
  {
    "text": "other trigger could expose the other value so the hpa will proceed if there",
    "start": "807519",
    "end": "814959"
  },
  {
    "text": "another important thing is that i hope that you don't need to customize the hpr the hpa behavior because it's a",
    "start": "815200",
    "end": "822320"
  },
  {
    "text": "pain but maybe you need to do it because one",
    "start": "822320",
    "end": "829079"
  },
  {
    "text": "specifying those values in a section in the schedule and get away with that faster the xpa but you can do it if you",
    "start": "830639",
    "end": "838480"
  },
  {
    "text": "need to customize because you need to scale down a scale out or feeling faster or slower you can do it so it's a good",
    "start": "838480",
    "end": "845680"
  },
  {
    "text": "thing one point super nice and trust me i have been on call today",
    "start": "845680",
    "end": "852240"
  },
  {
    "text": "and this feature thank you so trust me it's a super good knife the possibility the capability of",
    "start": "852240",
    "end": "859199"
  },
  {
    "text": "pausing the auto scaling what that means imagine that you are under maintenance and you need to scale to zero",
    "start": "859199",
    "end": "865680"
  },
  {
    "text": "in other mechanisms or with other tools you need to barely remove the hpa because if you would",
    "start": "865680",
    "end": "871279"
  },
  {
    "text": "simply scan to zero your deployment the hpa will scale up and we'll scale out",
    "start": "871279",
    "end": "876720"
  },
  {
    "text": "the deployment again with this feature you can just add in an annotation in your state object don't worry we will",
    "start": "876720",
    "end": "883440"
  },
  {
    "text": "see how to do it in the demo you can say okay never mind i want to have",
    "start": "883440",
    "end": "889199"
  },
  {
    "text": "this fit a lot of instances and i take the rings because i know what i'm doing it's hard way for doing maintenance or",
    "start": "889199",
    "end": "896079"
  },
  {
    "text": "just for dealing with problems so for me it's one of the the best features that we have",
    "start": "896079",
    "end": "902800"
  },
  {
    "text": "uh obviously kedah as majority of software nowadays expose prometheus",
    "start": "902800",
    "end": "908399"
  },
  {
    "text": "metrics because if you don't do it you are doing the things really wrong in my opinion at",
    "start": "908399",
    "end": "914240"
  },
  {
    "text": "least inside kubernetes and right now we have more than 50",
    "start": "914240",
    "end": "919279"
  },
  {
    "text": "scalers but the most important thing the scalers are not opinionated scalers that that means that they don't have any",
    "start": "919279",
    "end": "926240"
  },
  {
    "text": "logic they just go to the upstream and request the metric if you need to do any logic",
    "start": "926240",
    "end": "932240"
  },
  {
    "text": "based on the metric just no i would like to have that metric plus one",
    "start": "932240",
    "end": "937759"
  },
  {
    "text": "well whatever not important the target but you can have more advances scenarios cannot",
    "start": "937759",
    "end": "944160"
  },
  {
    "text": "support being extended implementing your own grpc server implementing the external",
    "start": "944160",
    "end": "951199"
  },
  {
    "text": "scalar interface or if you are more comfortable with the rest api you can",
    "start": "951199",
    "end": "957440"
  },
  {
    "text": "just use the matrix matrix apis trader and just implement your own",
    "start": "957440",
    "end": "963839"
  },
  {
    "text": "api rest api and just expose the value that you want and get the value from your work you can",
    "start": "963839",
    "end": "970560"
  },
  {
    "text": "do it so you can extend kedah easily to fulfill your requirements",
    "start": "970560",
    "end": "975920"
  },
  {
    "text": "one example one sample of these extensions is the",
    "start": "975920",
    "end": "981839"
  },
  {
    "text": "http app we tried it's not the objective of this meeting but just for me",
    "start": "981839",
    "end": "988720"
  },
  {
    "text": "oh my god oh yeah i always break the microphones sorry you speak a lot probably",
    "start": "988720",
    "end": "994560"
  },
  {
    "text": "yeah sorry let me handle that okay nice sorry",
    "start": "994560",
    "end": "1001360"
  },
  {
    "text": "er http atom is just a an external metric server that we use for extending",
    "start": "1001360",
    "end": "1007360"
  },
  {
    "text": "a and scaling base of ntl and http it's in beta i guess but it's an example so",
    "start": "1007360",
    "end": "1013839"
  },
  {
    "text": "there is an example of external metric implemented inside cada and",
    "start": "1013839",
    "end": "1019120"
  },
  {
    "text": "in the last line don't worry this slides will be served so you don't need",
    "start": "1019120",
    "end": "1024319"
  },
  {
    "text": "to just copy in your blog your blog don't worry is the link to the",
    "start": "1024319",
    "end": "1030640"
  },
  {
    "text": "it's to the scale object definition just for watching all the all the capabilities inside the scale object",
    "start": "1030640",
    "end": "1038160"
  },
  {
    "text": "and what about anti-authentication this is important topic in my opinion is",
    "start": "1038160",
    "end": "1043918"
  },
  {
    "text": "one of the most important things in kera because keda usually needs",
    "start": "1043919",
    "end": "1050559"
  },
  {
    "text": "based on the work that keda does usually needs high privilege on different systems get a needs to the permission",
    "start": "1050559",
    "end": "1058320"
  },
  {
    "text": "for listing kafka brokers for listing messages so it needs",
    "start": "1058320",
    "end": "1064240"
  },
  {
    "text": "some privilege that are quite risky if there are not good manners so for for solving that first of all",
    "start": "1064240",
    "end": "1071600"
  },
  {
    "text": "keda allows to reduce the credentials i mean you don't need to just copy and",
    "start": "1071600",
    "end": "1076799"
  },
  {
    "text": "paste potential every player and every place that you are there you can specify together okay just go to the warlord and",
    "start": "1076799",
    "end": "1084400"
  },
  {
    "text": "take this environment variable where it's already the the secret",
    "start": "1084400",
    "end": "1090639"
  },
  {
    "text": "music as well yeah i can dance no problem at all and",
    "start": "1091360",
    "end": "1097039"
  },
  {
    "text": "how can how can do that or how can go farther and reuse more queda has another",
    "start": "1097039",
    "end": "1102320"
  },
  {
    "text": "two theories another custom resources one is trigger authentication and the other is cluster trigger authentication",
    "start": "1102320",
    "end": "1109280"
  },
  {
    "text": "you could imagine the difference one is name spaces and the other is just a cluster scope",
    "start": "1109280",
    "end": "1114799"
  },
  {
    "text": "applied and basically using them we can extend even more the security capabilities why",
    "start": "1114799",
    "end": "1121760"
  },
  {
    "text": "because we can use we can specify some secret from okay took the secret from",
    "start": "1121760",
    "end": "1127919"
  },
  {
    "text": "the deployment or from that secret but also from from both identities i don't know if you",
    "start": "1127919",
    "end": "1134880"
  },
  {
    "text": "know what are both identities basically port identities is a mechanism from several cloud providers",
    "start": "1134880",
    "end": "1141440"
  },
  {
    "text": "for using even emma system managed identities in the in their site so it's",
    "start": "1141440",
    "end": "1146799"
  },
  {
    "text": "the most secure thing it's like a system managed identities in azure or",
    "start": "1146799",
    "end": "1152799"
  },
  {
    "text": "aam in aws so it's the most secure option but if you don't if you don't use",
    "start": "1152799",
    "end": "1158400"
  },
  {
    "text": "them you can use hasik or bolt directly integrated inside kera not using any other integration that can go to",
    "start": "1158400",
    "end": "1165840"
  },
  {
    "text": "hashicorp vault and just read from them and also from azure keyboard",
    "start": "1165840",
    "end": "1171039"
  },
  {
    "text": "yeah just to add that to this the cluster authentication is good because for example you have an administrator",
    "start": "1171039",
    "end": "1176640"
  },
  {
    "text": "who has some credentials and they don't want to share it with the developers so he can you know define the cluster to go",
    "start": "1176640",
    "end": "1182160"
  },
  {
    "text": "to authentication object and the developer just reference in the scaled object to this static notification",
    "start": "1182160",
    "end": "1187600"
  },
  {
    "text": "object so we can do this stuff as well okay um just for",
    "start": "1187600",
    "end": "1194880"
  },
  {
    "text": "showing some five highlights so i will i will maybe show the character it will show the parameters because i don't like",
    "start": "1194880",
    "end": "1200640"
  },
  {
    "text": "it yeah right yeah sure yeah so again this is like this is like the scale object so as you can see again very",
    "start": "1200640",
    "end": "1206000"
  },
  {
    "text": "simple just the skill target if you don't specify the api or kind it's automatically deployment but you",
    "start": "1206000",
    "end": "1212000"
  },
  {
    "text": "can define as i said before you can use the custom resources for example as a route so then you specify the api api",
    "start": "1212000",
    "end": "1219760"
  },
  {
    "text": "and api version of kind then the minimum maximum replicas and the trigger section so you see it's just a couple of lines",
    "start": "1219760",
    "end": "1226960"
  },
  {
    "text": "and you can explain the stuff you catch me drinking yeah i know",
    "start": "1226960",
    "end": "1233520"
  },
  {
    "text": "we need to prepare better for the next time yeah okay in this side is the common hpa nothing",
    "start": "1233520",
    "end": "1240159"
  },
  {
    "text": "new under the sun under the sky the common hpa but it seems or they seem quite similar the",
    "start": "1240159",
    "end": "1246960"
  },
  {
    "text": "problem is that for using this side for using this apa you need to do this also in the adapter",
    "start": "1246960",
    "end": "1253360"
  },
  {
    "text": "i mean you need to configure the adapter just for renaming the metrics and exposing them in the name space you will",
    "start": "1253360",
    "end": "1260559"
  },
  {
    "text": "need them so the hpa is quite similar but the work and then the under the hood is higher",
    "start": "1260559",
    "end": "1267600"
  },
  {
    "text": "it's really higher with kedah you don't need to do this to do this you only need to spawn kedah in the cluster install",
    "start": "1267600",
    "end": "1274240"
  },
  {
    "text": "them and that's all yeah so if for example you would like to scale your one deployment you need to define the rules",
    "start": "1274240",
    "end": "1281120"
  },
  {
    "text": "if you would like to add another deployment or auto scale it you will need to again reconfigure the whole",
    "start": "1281120",
    "end": "1286799"
  },
  {
    "text": "adapter it is not like the crd thingy okay and what about now yeah demo time",
    "start": "1286799",
    "end": "1291919"
  },
  {
    "text": "so yeah talk is cheap yeah right i can talk maybe and you can",
    "start": "1291919",
    "end": "1300200"
  },
  {
    "text": "so as you can see this is like the no they cannot see it oh they don't see why",
    "start": "1305200",
    "end": "1311519"
  },
  {
    "text": "okay i don't know so this is the deployment right yeah okay",
    "start": "1312720",
    "end": "1318159"
  },
  {
    "text": "yeah i can do it don't worry okay yeah basically just for improving the demo i will do it there just for not making a",
    "start": "1318159",
    "end": "1324960"
  },
  {
    "text": "bit bully them all always presenting there you can see there i for just for",
    "start": "1324960",
    "end": "1330799"
  },
  {
    "text": "improving the process we have in we start in a scenario i have already installed cada",
    "start": "1330799",
    "end": "1336799"
  },
  {
    "text": "cada is already installing the cluster and i already installed a helm chart a head to answer obviously help chart a",
    "start": "1336799",
    "end": "1343440"
  },
  {
    "text": "rabbit q i install a rabbit server just for using rabbit scalar sample but",
    "start": "1343440",
    "end": "1350640"
  },
  {
    "text": "you can after the demo i will show you the where you can download the whole",
    "start": "1350640",
    "end": "1355760"
  },
  {
    "text": "sample but basically we have already deployed",
    "start": "1355760",
    "end": "1361840"
  },
  {
    "text": "this file in the cluster this file just has a secret with the secret of the for connecting",
    "start": "1362080",
    "end": "1367840"
  },
  {
    "text": "rabbit host has a super simple deployment with a mistake the annotation is not",
    "start": "1367840",
    "end": "1373760"
  },
  {
    "text": "there but ignore it it's just a sample like a rabbit customer don't worry eat the cues",
    "start": "1373760",
    "end": "1380240"
  },
  {
    "text": "messages from the queue and do absolutely nothing with them but the most important thing please",
    "start": "1380240",
    "end": "1386240"
  },
  {
    "text": "scroll below is this this is the scale object in this",
    "start": "1386240",
    "end": "1391840"
  },
  {
    "text": "skill object we are basically specifying the steady scalar charger drive basically",
    "start": "1391840",
    "end": "1399679"
  },
  {
    "text": "what what we want to scale nothing important these values are for",
    "start": "1399679",
    "end": "1404799"
  },
  {
    "text": "just for improving the speed of the demo and the max replica count we want to have 30",
    "start": "1404799",
    "end": "1410960"
  },
  {
    "text": "replicas at maximum and the triggers this is the place where we are we are going to introduce the",
    "start": "1410960",
    "end": "1417840"
  },
  {
    "text": "different scalars the different rules that we want to use just for scaling",
    "start": "1417840",
    "end": "1423440"
  },
  {
    "text": "in this case important is an array so you don't need to scale based on only one you can specify all of you want",
    "start": "1423440",
    "end": "1431200"
  },
  {
    "text": "without any limit without any limit yeah",
    "start": "1431200",
    "end": "1436400"
  },
  {
    "text": "just double checking and the trigger authentication why trigger authentication just for",
    "start": "1436400",
    "end": "1442400"
  },
  {
    "text": "specifying where are where is the connection string from",
    "start": "1442400",
    "end": "1447760"
  },
  {
    "text": "for their rabbit server and we define the trigger authentication and we have specified it inside the trigger",
    "start": "1447760",
    "end": "1455120"
  },
  {
    "text": "just for saying this trigger should use this authentication so go there and take the parameters the secret",
    "start": "1455120",
    "end": "1462159"
  },
  {
    "text": "parameters from there",
    "start": "1462159",
    "end": "1465279"
  },
  {
    "text": "and just for doing the things totally transparent i will deploy this job this",
    "start": "1469279",
    "end": "1475039"
  },
  {
    "text": "job is super simple just for enqueuing it generates the load basically",
    "start": "1475039",
    "end": "1482720"
  },
  {
    "text": "you should mirror the screen right you should yeah but as you can see i'm not the best with mac",
    "start": "1483840",
    "end": "1489919"
  },
  {
    "text": "os okay you are microsoft fanboy right yeah",
    "start": "1489919",
    "end": "1496080"
  },
  {
    "text": "my bosses are more microsoft haters yeah that's good",
    "start": "1501520",
    "end": "1508240"
  },
  {
    "text": "you have a typo over there thanks",
    "start": "1508559",
    "end": "1515840"
  },
  {
    "text": "yeah that's good nice i can hold it oh thanks",
    "start": "1517440",
    "end": "1525679"
  },
  {
    "text": "so jorge just created the the publisher job which is the stuff for generating the load",
    "start": "1525679",
    "end": "1531919"
  },
  {
    "text": "as you can see he can pre and right now we are going to watch that is what's cube ctl yeah yeah",
    "start": "1531919",
    "end": "1539600"
  },
  {
    "text": "thanks for watching watching the consumer application so he's watching the workloads as you can see it's already auto scale down to zero i don't",
    "start": "1539600",
    "end": "1546480"
  },
  {
    "text": "know why i know because yeah i make up a joke for him it's a trap okay i added the",
    "start": "1546480",
    "end": "1552960"
  },
  {
    "text": "annotation that i explained it during the during the presentation just for pausing the",
    "start": "1552960",
    "end": "1560080"
  },
  {
    "text": "autoscaling and sewing so we need so",
    "start": "1560080",
    "end": "1565919"
  },
  {
    "text": "okay sorry i will remove it locally because otherwise it could be a pain",
    "start": "1565919",
    "end": "1571520"
  },
  {
    "text": "best demo ever as you can see the annotation is there",
    "start": "1571520",
    "end": "1579279"
  },
  {
    "text": "is this so i will try to remove it oh my god",
    "start": "1579279",
    "end": "1584480"
  },
  {
    "text": "sorry nice",
    "start": "1584480",
    "end": "1588080"
  },
  {
    "text": "okay no problem and [Music] now automatically",
    "start": "1589840",
    "end": "1596080"
  },
  {
    "text": "the autoscaling has started one instance because we were in a zero scenario we",
    "start": "1596080",
    "end": "1602720"
  },
  {
    "text": "were just scaled to zero so remember the operator has increased from zero to one",
    "start": "1602720",
    "end": "1608559"
  },
  {
    "text": "and now the hpa will take care we take the control and we'll scale this",
    "start": "1608559",
    "end": "1613600"
  },
  {
    "text": "workload so in a few moments we could see that okay right now we have four instances",
    "start": "1613600",
    "end": "1622240"
  },
  {
    "text": "yeah because we are generating the load so we are generating messaging to the rabbitmq and the application is probably processing",
    "start": "1622240",
    "end": "1628640"
  },
  {
    "text": "them and it will be scroll down to zero right after a couple of yeah after we will reach 30 instances and",
    "start": "1628640",
    "end": "1635279"
  },
  {
    "text": "suddenly we will scale to zero again okay",
    "start": "1635279",
    "end": "1640399"
  },
  {
    "text": "so maybe in the meantime we can check the additional stuff right because we don't",
    "start": "1640399",
    "end": "1646240"
  },
  {
    "text": "have too much time yeah in the meantime oh my god",
    "start": "1646240",
    "end": "1652200"
  },
  {
    "text": "this is the url basically this url this demo is there it's a public demo that we have",
    "start": "1654080",
    "end": "1660960"
  },
  {
    "text": "we use a rabbit and if you go there you will see step by step how to reproduce",
    "start": "1660960",
    "end": "1668080"
  },
  {
    "text": "this demo just for try in your under infrastructure you could try it in mini cube in local cluster never mind no",
    "start": "1668080",
    "end": "1675360"
  },
  {
    "text": "problem that's why we try to use rabbit they don't pay us for using rabbit trust",
    "start": "1675360",
    "end": "1681039"
  },
  {
    "text": "me or at least not to me no but basically that's the the url you can",
    "start": "1681039",
    "end": "1687360"
  },
  {
    "text": "find it in github slash catacore slash rabbit",
    "start": "1687360",
    "end": "1693679"
  },
  {
    "text": "okay no the scream is not mirrored so can you move the slides here yes for",
    "start": "1693679",
    "end": "1700000"
  },
  {
    "text": "sure as you can see already autoscale down to zero so it is pretty simple and maybe we can go further right yeah",
    "start": "1700000",
    "end": "1709120"
  },
  {
    "text": "so i'm gonna go to the slides that sounds easier than it is",
    "start": "1709679",
    "end": "1717679"
  },
  {
    "text": "bye",
    "start": "1720559",
    "end": "1723559"
  },
  {
    "text": "okay presentation you don't need to do the presentation right nice okay",
    "start": "1727679",
    "end": "1733600"
  },
  {
    "text": "again no no no no we are bored about you",
    "start": "1733600",
    "end": "1741600"
  },
  {
    "text": "i will say that this is yeah awesome so what about the future of the project",
    "start": "1745600",
    "end": "1751279"
  },
  {
    "text": "because you know we can already auto scale the stuff but still we would like to stay focused on one thing",
    "start": "1751279",
    "end": "1758080"
  },
  {
    "text": "uh so there are several things that we would like to improve so one of them is caching the actual metric values in the",
    "start": "1758080",
    "end": "1764480"
  },
  {
    "text": "inductor so then you can save basically the traffic to your to your external service so for example to",
    "start": "1764480",
    "end": "1770640"
  },
  {
    "text": "do kafka broker or then maybe we can do some nice analysis on the on the",
    "start": "1770640",
    "end": "1775760"
  },
  {
    "text": "values and maybe do some predictions maybe plug some aiml stuff into and monitor",
    "start": "1775760",
    "end": "1781200"
  },
  {
    "text": "monitor the basically the metric values and then based on that maybe start scaling a",
    "start": "1781200",
    "end": "1786640"
  },
  {
    "text": "little bit faster a little bit in advance uh another another thing because",
    "start": "1786640",
    "end": "1792080"
  },
  {
    "text": "as said at the beginning though there is the limitation that there could be only one extension point for metric server in the",
    "start": "1792080",
    "end": "1799120"
  },
  {
    "text": "kubernetes cluster so that means that you can have only one installation perform cluster so we will need to somehow solve this so",
    "start": "1799120",
    "end": "1806080"
  },
  {
    "text": "this is another like a big thing that we would like to do another cool thing is cloud events",
    "start": "1806080",
    "end": "1811120"
  },
  {
    "text": "because cloud events are everywhere right now so we would like to you know maybe expose some cloud events and do",
    "start": "1811120",
    "end": "1816240"
  },
  {
    "text": "some cool stuff so then you can and you can integrate uh integrate basically uh carry out with your",
    "start": "1816240",
    "end": "1822399"
  },
  {
    "text": "portfolio and maybe you know based on the code events based on the statistics about scaling you can do some additional",
    "start": "1822399",
    "end": "1828399"
  },
  {
    "text": "stuff um yeah and that's probably it",
    "start": "1828399",
    "end": "1834399"
  },
  {
    "text": "so do you have anything else yeah i have noticed that i don't know when we delete",
    "start": "1834399",
    "end": "1839760"
  },
  {
    "text": "the one of important features that supports arm architecture yeah in the",
    "start": "1839760",
    "end": "1845279"
  },
  {
    "text": "latest version it's not critical but if you are on aws and you are using graviton nodes you",
    "start": "1845279",
    "end": "1851679"
  },
  {
    "text": "could use also there so do you have any question",
    "start": "1851679",
    "end": "1856880"
  },
  {
    "text": "yeah so you know that so we have five minutes so we have",
    "start": "1856880",
    "end": "1863279"
  },
  {
    "text": "we have five million and we have a bunch of t-shirts here so if you have any questions and good questions yeah",
    "start": "1863279",
    "end": "1869279"
  },
  {
    "text": "t-shirt bad questions go out that is a regular one so yeah just uh bearing in",
    "start": "1869279",
    "end": "1875360"
  },
  {
    "text": "mind so we have a one virtual question we're gonna maybe address that first okay so can you scale a part according",
    "start": "1875360",
    "end": "1882320"
  },
  {
    "text": "to the load of the difference path uh you you need to you need to somehow",
    "start": "1882320",
    "end": "1889679"
  },
  {
    "text": "get the metrics from the different ports so once you expose the metrics from the referring port maybe from through",
    "start": "1889679",
    "end": "1895360"
  },
  {
    "text": "prometheus then you can scrape the parameters scale scrape the metrics from the portfolios so basically",
    "start": "1895360",
    "end": "1902559"
  },
  {
    "text": "to do the scaling we always need to have the basically the source so yeah this is doable i suppose",
    "start": "1902559",
    "end": "1908399"
  },
  {
    "text": "cool yeah thanks for the answering and questions okay",
    "start": "1908399",
    "end": "1913440"
  },
  {
    "text": "yeah i'm gonna do prosperous",
    "start": "1913440",
    "end": "1917840"
  },
  {
    "text": "i think the start at the start you mentioned you can create multiple scaled objects for the",
    "start": "1918559",
    "end": "1924399"
  },
  {
    "text": "same deployment nope no there could be only one scale object per deployment okay but you can specify multiple",
    "start": "1924399",
    "end": "1930880"
  },
  {
    "text": "triggers in one skill object so if there could be like a trigger for kafka for prometheus for rabbit",
    "start": "1930880",
    "end": "1936880"
  },
  {
    "text": "or cpu targeting the same uh same deployment and then hpa works this way that basically it",
    "start": "1936880",
    "end": "1944080"
  },
  {
    "text": "selects the the greatest value to drive the scaling so basically so so it takes by greater greater value there's no like",
    "start": "1944080",
    "end": "1950399"
  },
  {
    "text": "exactly five between them so i can for example do something like uh scale by",
    "start": "1950399",
    "end": "1956000"
  },
  {
    "text": "metrics and then say uh wednesday i have an event at 4 pm i",
    "start": "1956000",
    "end": "1961039"
  },
  {
    "text": "want to scale it way up and it will not fight yeah okay very interesting thank",
    "start": "1961039",
    "end": "1966080"
  },
  {
    "text": "you but there must be always only scale object targeting the deployment you cannot combine skill objects and your",
    "start": "1966080",
    "end": "1971760"
  },
  {
    "text": "hpas it could be only one one object so if you know it but it manages yeah yeah",
    "start": "1971760",
    "end": "1977760"
  },
  {
    "text": "thank you thank you so much and i'm gonna go to back there",
    "start": "1977760",
    "end": "1984158"
  },
  {
    "text": "go for it thank you um how does it work for example i mean in",
    "start": "1984320",
    "end": "1990880"
  },
  {
    "text": "this scenario that you are upgrading an application so you are triggering triggering a",
    "start": "1990880",
    "end": "1997120"
  },
  {
    "text": "kubernetes deployment and is a scale to zero what happened",
    "start": "1997120",
    "end": "2003279"
  },
  {
    "text": "nothing because uh because if you update the deployment uh cadaver",
    "start": "2003279",
    "end": "2009200"
  },
  {
    "text": "after a few seconds it will notice that the deployment has changed like the the replica number doesn't uh equal what is",
    "start": "2009200",
    "end": "2016159"
  },
  {
    "text": "basically provided by the metric server so it will again scale through what should we do but that does that's the",
    "start": "2016159",
    "end": "2021519"
  },
  {
    "text": "thing i'm wondering for example if you have a scale to zero and then you are constantly checking for example the",
    "start": "2021519",
    "end": "2026880"
  },
  {
    "text": "number of messages in rabbit and q and then you upgrade the version of that application",
    "start": "2026880",
    "end": "2033679"
  },
  {
    "text": "there's no no no no okay and monitor all the time the app",
    "start": "2033679",
    "end": "2039200"
  },
  {
    "text": "stream so if you don't have any messages in the queue will scale your deployment into zero and",
    "start": "2039200",
    "end": "2044880"
  },
  {
    "text": "cannot still be monitoring the the queue yeah when there is any message in the queue will be keda",
    "start": "2044880",
    "end": "2051520"
  },
  {
    "text": "put a scale again into one and then you don't need to do any more more than",
    "start": "2051520",
    "end": "2056720"
  },
  {
    "text": "deploy the same object once at the beginning and because you are always targeting the same deployment it doesn't mean that it",
    "start": "2056720",
    "end": "2062800"
  },
  {
    "text": "was changing the version was changed but it's still still the same deployment so it doesn't care like so",
    "start": "2062800",
    "end": "2068398"
  },
  {
    "text": "it should work okay thank you thank you so i think that we have one",
    "start": "2068399",
    "end": "2073679"
  },
  {
    "text": "last question there don't worry you can meet us after the meeting yeah your question directly to",
    "start": "2073679",
    "end": "2080240"
  },
  {
    "text": "us don't worry if you don't have time we will be here",
    "start": "2080240",
    "end": "2086320"
  },
  {
    "text": "hey uh so does you know i'm thinking specifically around kafka but it probably applies",
    "start": "2086320",
    "end": "2092158"
  },
  {
    "text": "elsewhere um does kida support like partition level um",
    "start": "2092159",
    "end": "2097760"
  },
  {
    "text": "scaling uh no itself does not scale kafka it scales just the consumer application but for",
    "start": "2097760",
    "end": "2103599"
  },
  {
    "text": "example if you are consuming uh messages from kafka it doesn't make sense to scale out the number of consumers that",
    "start": "2103599",
    "end": "2110480"
  },
  {
    "text": "is larger than the partition so yeah it's kept so basically it will scale only to the maximum number of partitions",
    "start": "2110480",
    "end": "2115920"
  },
  {
    "text": "you can rewrite this so we can there is an optional value i would like to scale to more consumers but it doesn't make",
    "start": "2115920",
    "end": "2121040"
  },
  {
    "text": "sense but yeah this is covered okay cool thanks maybe you can do another question there",
    "start": "2121040",
    "end": "2126960"
  },
  {
    "text": "was one a day okay",
    "start": "2126960",
    "end": "2131838"
  },
  {
    "text": "hi hi i saw in the demo that you were like you put 18 replicas and then he went up",
    "start": "2132320",
    "end": "2137760"
  },
  {
    "text": "super fast do you have like throttling because this is the stuff that you define on the",
    "start": "2137760",
    "end": "2142880"
  },
  {
    "text": "hpl level so this is like the scale it's called scaling behavior so then you can define like the older options this is",
    "start": "2142880",
    "end": "2149760"
  },
  {
    "text": "everything that's provided by hp8 can be like fast um can also be by external services",
    "start": "2149760",
    "end": "2156400"
  },
  {
    "text": "my limit can be based on the metric of external service i'm not sure i get the question sorry in",
    "start": "2156400",
    "end": "2162079"
  },
  {
    "text": "case like i am i don't know putting in a amazon limit i am using a delay services i am",
    "start": "2162079",
    "end": "2168720"
  },
  {
    "text": "putting like a batch of bots running i don't wanna get the limit of throttling of eight or less could i put like a",
    "start": "2168720",
    "end": "2174960"
  },
  {
    "text": "limit on that based on that limit by checking one metric from aws",
    "start": "2174960",
    "end": "2181040"
  },
  {
    "text": "and to see if i reach in the limit of the throttling or not i don't know if is playing well maybe we can discuss",
    "start": "2181040",
    "end": "2187119"
  },
  {
    "text": "this offline because i'm not sure okay i got properly or do i understand okay yeah thank you so much yeah so",
    "start": "2187119",
    "end": "2193520"
  },
  {
    "text": "thank you so a great presentation demo today and thanks for attending so enjoy",
    "start": "2193520",
    "end": "2198640"
  },
  {
    "text": "the rest of the cube call and officials yeah",
    "start": "2198640",
    "end": "2206039"
  }
]
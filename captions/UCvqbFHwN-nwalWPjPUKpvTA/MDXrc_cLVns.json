[
  {
    "text": "hello everyone uh I'm Aaron and this is",
    "start": "160",
    "end": "3560"
  },
  {
    "text": "my colleague Co and we're here to talk",
    "start": "3560",
    "end": "5920"
  },
  {
    "text": "about scaling a g Ops platform at",
    "start": "5920",
    "end": "9240"
  },
  {
    "text": "aob so uh first I want to give a little",
    "start": "9240",
    "end": "12000"
  },
  {
    "text": "bit of background on us what we work on",
    "start": "12000",
    "end": "14320"
  },
  {
    "text": "our journey so far how we dealt with the",
    "start": "14320",
    "end": "17199"
  },
  {
    "text": "rapid adoption of our platform and we",
    "start": "17199",
    "end": "19359"
  },
  {
    "text": "want to leave you with some lessons and",
    "start": "19359",
    "end": "20840"
  },
  {
    "text": "recommendations so that you don't make",
    "start": "20840",
    "end": "22439"
  },
  {
    "text": "the same mistakes we did uh and we'll",
    "start": "22439",
    "end": "24640"
  },
  {
    "text": "try to leave some time at the end for",
    "start": "24640",
    "end": "27199"
  },
  {
    "text": "Q&A okay so I'm Aon like I mentioned",
    "start": "27199",
    "end": "30840"
  },
  {
    "text": "earlier uh I'm an architect on developer",
    "start": "30840",
    "end": "33320"
  },
  {
    "text": "platforms at Adobe my GitHub is jvk uh",
    "start": "33320",
    "end": "37440"
  },
  {
    "text": "and developer platforms is an or at",
    "start": "37440",
    "end": "39160"
  },
  {
    "text": "Adobe that provides internal tooling for",
    "start": "39160",
    "end": "41160"
  },
  {
    "text": "our",
    "start": "41160",
    "end": "41840"
  },
  {
    "text": "developers uh I've been at Adobe for",
    "start": "41840",
    "end": "43879"
  },
  {
    "text": "about four years uh and I work on",
    "start": "43879",
    "end": "46079"
  },
  {
    "text": "helping design and build out this",
    "start": "46079",
    "end": "47559"
  },
  {
    "text": "platform and I'm hi I'm Co I've been",
    "start": "47559",
    "end": "50399"
  },
  {
    "text": "with Adobe for almost 12 years now uh I",
    "start": "50399",
    "end": "53199"
  },
  {
    "text": "worked at a bunch of startups before",
    "start": "53199",
    "end": "54640"
  },
  {
    "text": "this and I've been a devops engineer uh",
    "start": "54640",
    "end": "57120"
  },
  {
    "text": "before I was called that uh for well",
    "start": "57120",
    "end": "58879"
  },
  {
    "text": "over 20 years and I focus more on the",
    "start": "58879",
    "end": "61399"
  },
  {
    "text": "infrastructure and deployment side of",
    "start": "61399",
    "end": "62760"
  },
  {
    "text": "things uh and help run our cic",
    "start": "62760",
    "end": "65640"
  },
  {
    "text": "platform cool so what do we do so Flex",
    "start": "65640",
    "end": "69320"
  },
  {
    "text": "is our giops platform on top of which",
    "start": "69320",
    "end": "71360"
  },
  {
    "text": "we've implemented a cicd solution that",
    "start": "71360",
    "end": "73799"
  },
  {
    "text": "we've rolled out to Adobe some of us in",
    "start": "73799",
    "end": "75720"
  },
  {
    "text": "the room May recognize Flex from past",
    "start": "75720",
    "end": "77479"
  },
  {
    "text": "Adobe project this is a different Flex",
    "start": "77479",
    "end": "79840"
  },
  {
    "text": "completely unrelated to that uh it's",
    "start": "79840",
    "end": "82320"
  },
  {
    "text": "built on our and popular Open Source",
    "start": "82320",
    "end": "84200"
  },
  {
    "text": "Products you might have heard of uh many",
    "start": "84200",
    "end": "85880"
  },
  {
    "text": "of which are cncf so uh for example Argo",
    "start": "85880",
    "end": "89400"
  },
  {
    "text": "CD kubernetes backstage and so on uh and",
    "start": "89400",
    "end": "92880"
  },
  {
    "text": "worth noting it's G Ops based from top",
    "start": "92880",
    "end": "94799"
  },
  {
    "text": "to bottom uh to give an idea of the",
    "start": "94799",
    "end": "97479"
  },
  {
    "text": "scale we're dealing with We sync to over",
    "start": "97479",
    "end": "99280"
  },
  {
    "text": "300 kubernetes clusters in counting uh",
    "start": "99280",
    "end": "102399"
  },
  {
    "text": "our largest Argo CD instance syncs over",
    "start": "102399",
    "end": "105280"
  },
  {
    "text": "12,000 applications and it's responsible",
    "start": "105280",
    "end": "107840"
  },
  {
    "text": "for syncing over 600,000 kubernetes",
    "start": "107840",
    "end": "110880"
  },
  {
    "text": "resources and at the time of writing",
    "start": "110880",
    "end": "112880"
  },
  {
    "text": "this was roughly accurate but it's",
    "start": "112880",
    "end": "114280"
  },
  {
    "text": "probably much more",
    "start": "114280",
    "end": "116600"
  },
  {
    "text": "now so uh let's zoom in on what makes up",
    "start": "116600",
    "end": "120399"
  },
  {
    "text": "Flex so Flex provides a paved path to",
    "start": "120399",
    "end": "123119"
  },
  {
    "text": "help users get from an empty GitHub repo",
    "start": "123119",
    "end": "125640"
  },
  {
    "text": "to a solution running in production and",
    "start": "125640",
    "end": "128160"
  },
  {
    "text": "by pave path I mean specifically we",
    "start": "128160",
    "end": "130000"
  },
  {
    "text": "provide developers with shared",
    "start": "130000",
    "end": "131480"
  },
  {
    "text": "standardized secured templates and these",
    "start": "131480",
    "end": "134480"
  },
  {
    "text": "templates include Advanced deployment",
    "start": "134480",
    "end": "136519"
  },
  {
    "text": "strategies like Canary and Blu green uh",
    "start": "136519",
    "end": "138840"
  },
  {
    "text": "as well as a standardized set of build",
    "start": "138840",
    "end": "140360"
  },
  {
    "text": "and deploy",
    "start": "140360",
    "end": "141480"
  },
  {
    "text": "pipelines uh we try to keep them open to",
    "start": "141480",
    "end": "144080"
  },
  {
    "text": "customization and extension and we ALS",
    "start": "144080",
    "end": "146959"
  },
  {
    "text": "we also provide g off Spas tooling to",
    "start": "146959",
    "end": "148840"
  },
  {
    "text": "help users provision infrastructure",
    "start": "148840",
    "end": "150599"
  },
  {
    "text": "across various Adobe services so for",
    "start": "150599",
    "end": "153440"
  },
  {
    "text": "example uh artifactory repos for helmet",
    "start": "153440",
    "end": "155959"
  },
  {
    "text": "Docker uh the build and deploy",
    "start": "155959",
    "end": "157640"
  },
  {
    "text": "infrastructure itself policies and so",
    "start": "157640",
    "end": "161720"
  },
  {
    "text": "on so here is a rough overview of some",
    "start": "161760",
    "end": "165120"
  },
  {
    "text": "of the notable points in our journey",
    "start": "165120",
    "end": "166280"
  },
  {
    "text": "rolling out Flex uh we chose Argo CD",
    "start": "166280",
    "end": "169080"
  },
  {
    "text": "applications to represent our go our",
    "start": "169080",
    "end": "170920"
  },
  {
    "text": "growth uh it's not a perfect metric but",
    "start": "170920",
    "end": "173239"
  },
  {
    "text": "it's a good enough heuristic uh so we",
    "start": "173239",
    "end": "175640"
  },
  {
    "text": "started with like a with a lighthouse",
    "start": "175640",
    "end": "177599"
  },
  {
    "text": "phase uh and then shortly after after",
    "start": "177599",
    "end": "180040"
  },
  {
    "text": "our go live date uh we saw a rapid",
    "start": "180040",
    "end": "182159"
  },
  {
    "text": "uptick in client adoption uh this",
    "start": "182159",
    "end": "184480"
  },
  {
    "text": "resulted in our fair share of production",
    "start": "184480",
    "end": "186720"
  },
  {
    "text": "outages uh to which we responded by",
    "start": "186720",
    "end": "189400"
  },
  {
    "text": "forming a stability tiger team uh to",
    "start": "189400",
    "end": "192280"
  },
  {
    "text": "address the stability and scalability",
    "start": "192280",
    "end": "193760"
  },
  {
    "text": "scalability",
    "start": "193760",
    "end": "195000"
  },
  {
    "text": "issues uh we we considered these to be",
    "start": "195000",
    "end": "197879"
  },
  {
    "text": "roughly the phases of our Evolution",
    "start": "197879",
    "end": "199480"
  },
  {
    "text": "around that time uh and this vertical",
    "start": "199480",
    "end": "201879"
  },
  {
    "text": "scaling improvements phase worked great",
    "start": "201879",
    "end": "204519"
  },
  {
    "text": "until we of course hit the limits of our",
    "start": "204519",
    "end": "206519"
  },
  {
    "text": "vertical scaling for this we needed to",
    "start": "206519",
    "end": "209920"
  },
  {
    "text": "re architecture",
    "start": "209920",
    "end": "211720"
  },
  {
    "text": "our uh we we needed to re architecture",
    "start": "211720",
    "end": "214360"
  },
  {
    "text": "the platform which we'll get to in a few",
    "start": "214360",
    "end": "216799"
  },
  {
    "text": "slides uh and now we're here um we're",
    "start": "216799",
    "end": "219239"
  },
  {
    "text": "doing great now but obviously the",
    "start": "219239",
    "end": "222480"
  },
  {
    "text": "journey here has been rough and now I'm",
    "start": "222480",
    "end": "226120"
  },
  {
    "text": "going to hand it over to co to go into",
    "start": "226120",
    "end": "228319"
  },
  {
    "text": "more detail about how we responded to",
    "start": "228319",
    "end": "229840"
  },
  {
    "text": "this growth uh thanks Ain so as I",
    "start": "229840",
    "end": "232560"
  },
  {
    "text": "mentioned on the previous slide we",
    "start": "232560",
    "end": "234079"
  },
  {
    "text": "needed to quickly address uh our",
    "start": "234079",
    "end": "236040"
  },
  {
    "text": "stability and stability issues uh so we",
    "start": "236040",
    "end": "238400"
  },
  {
    "text": "start out by first uh uh tuning and",
    "start": "238400",
    "end": "240680"
  },
  {
    "text": "scaling our existing infrastructure so",
    "start": "240680",
    "end": "243360"
  },
  {
    "text": "in our environment we are running Argo",
    "start": "243360",
    "end": "245040"
  },
  {
    "text": "CD and workflows uh so most of our",
    "start": "245040",
    "end": "247040"
  },
  {
    "text": "example Solutions here will be more",
    "start": "247040",
    "end": "248720"
  },
  {
    "text": "specific to them but the general",
    "start": "248720",
    "end": "250799"
  },
  {
    "text": "concepts uh should still apply to other",
    "start": "250799",
    "end": "253040"
  },
  {
    "text": "giops",
    "start": "253040",
    "end": "253920"
  },
  {
    "text": "engines uh one major issue that we had",
    "start": "253920",
    "end": "256519"
  },
  {
    "text": "was that our giops engine was under",
    "start": "256519",
    "end": "258320"
  },
  {
    "text": "really heavy load and we needed to scale",
    "start": "258320",
    "end": "260320"
  },
  {
    "text": "up with within our existing uh cluster",
    "start": "260320",
    "end": "263160"
  },
  {
    "text": "so our Solutions here were to scale up",
    "start": "263160",
    "end": "265040"
  },
  {
    "text": "replica accounts for various components",
    "start": "265040",
    "end": "267360"
  },
  {
    "text": "uh such as Argo CD application",
    "start": "267360",
    "end": "269039"
  },
  {
    "text": "controller and and repo server uh this",
    "start": "269039",
    "end": "271360"
  },
  {
    "text": "is a quick and easy way to gain",
    "start": "271360",
    "end": "272680"
  },
  {
    "text": "additional performance uh from your",
    "start": "272680",
    "end": "274000"
  },
  {
    "text": "engine to start uh when increasing the",
    "start": "274000",
    "end": "277759"
  },
  {
    "text": "replica counts uh for the application",
    "start": "277759",
    "end": "279680"
  },
  {
    "text": "controller um just keep in mind uh that",
    "start": "279680",
    "end": "281720"
  },
  {
    "text": "it will depend on the size and number of",
    "start": "281720",
    "end": "284080"
  },
  {
    "text": "remote clusters that you'll be managing",
    "start": "284080",
    "end": "286759"
  },
  {
    "text": "uh as well as the total number of",
    "start": "286759",
    "end": "288400"
  },
  {
    "text": "resources that you are managing on each",
    "start": "288400",
    "end": "290600"
  },
  {
    "text": "of",
    "start": "290600",
    "end": "291520"
  },
  {
    "text": "them we also tuned processing settings",
    "start": "291520",
    "end": "294560"
  },
  {
    "text": "such as the status and operation",
    "start": "294560",
    "end": "296240"
  },
  {
    "text": "processors uh increased QPS and burst",
    "start": "296240",
    "end": "298800"
  },
  {
    "text": "settings for the kubernetes API client",
    "start": "298800",
    "end": "301800"
  },
  {
    "text": "side rate limit this helped uh speed up",
    "start": "301800",
    "end": "305080"
  },
  {
    "text": "the AP syncing and Reconciliation times",
    "start": "305080",
    "end": "308199"
  },
  {
    "text": "we also set uh pod anti-an rules to",
    "start": "308199",
    "end": "310919"
  },
  {
    "text": "reduce any Noisy Neighbor issues for ARG",
    "start": "310919",
    "end": "313160"
  },
  {
    "text": "CD specifically uh this is important for",
    "start": "313160",
    "end": "316080"
  },
  {
    "text": "the application controller uh when it's",
    "start": "316080",
    "end": "317840"
  },
  {
    "text": "under really heavy load as well as uh if",
    "start": "317840",
    "end": "319720"
  },
  {
    "text": "your cluster is shared with 10m",
    "start": "319720",
    "end": "321240"
  },
  {
    "text": "workloads as those workloads can",
    "start": "321240",
    "end": "323280"
  },
  {
    "text": "sometimes be really",
    "start": "323280",
    "end": "324479"
  },
  {
    "text": "unpredictable so try to spread out your",
    "start": "324479",
    "end": "326880"
  },
  {
    "text": "workload to multiple worker those uh as",
    "start": "326880",
    "end": "328800"
  },
  {
    "text": "much as possible",
    "start": "328800",
    "end": "331280"
  },
  {
    "text": "another problem that we ran into is that",
    "start": "331280",
    "end": "333160"
  },
  {
    "text": "our giops engine was performing really",
    "start": "333160",
    "end": "335039"
  },
  {
    "text": "poorly due to some unnecessary work that",
    "start": "335039",
    "end": "337000"
  },
  {
    "text": "was being performed by it so we tackled",
    "start": "337000",
    "end": "339560"
  },
  {
    "text": "this by reducing the number of",
    "start": "339560",
    "end": "341440"
  },
  {
    "text": "kubernetes resources that it was",
    "start": "341440",
    "end": "342840"
  },
  {
    "text": "managing by specifying resource",
    "start": "342840",
    "end": "344960"
  },
  {
    "text": "inclusions and exclusions the important",
    "start": "344960",
    "end": "347720"
  },
  {
    "text": "Point here is to exclude things that you",
    "start": "347720",
    "end": "349759"
  },
  {
    "text": "really don't want your engine to manage",
    "start": "349759",
    "end": "351280"
  },
  {
    "text": "uh for example C9 resources like uh",
    "start": "351280",
    "end": "354280"
  },
  {
    "text": "associated with cium or end",
    "start": "354280",
    "end": "356600"
  },
  {
    "text": "points Argo CD also keeps all resources",
    "start": "356600",
    "end": "359800"
  },
  {
    "text": "that is managing in memory so it's",
    "start": "359800",
    "end": "361240"
  },
  {
    "text": "really best to exclude anything that you",
    "start": "361240",
    "end": "363199"
  },
  {
    "text": "don't need on Argo workflows we also did",
    "start": "363199",
    "end": "366199"
  },
  {
    "text": "something similar by excluding no events",
    "start": "366199",
    "end": "368639"
  },
  {
    "text": "uh that was not needed in our",
    "start": "368639",
    "end": "371479"
  },
  {
    "text": "environment another problem that we ran",
    "start": "371479",
    "end": "373440"
  },
  {
    "text": "into was that the number of times that",
    "start": "373440",
    "end": "375720"
  },
  {
    "text": "the getop engine was performing uh self",
    "start": "375720",
    "end": "377680"
  },
  {
    "text": "healing actions this is partly due to",
    "start": "377680",
    "end": "380080"
  },
  {
    "text": "some misconfigured problematic",
    "start": "380080",
    "end": "381599"
  },
  {
    "text": "applications which I'll cover a little",
    "start": "381599",
    "end": "383240"
  },
  {
    "text": "bit more in the later",
    "start": "383240",
    "end": "384800"
  },
  {
    "text": "slide uh our so our get Ops engine was",
    "start": "384800",
    "end": "387680"
  },
  {
    "text": "performing extremely frequent self",
    "start": "387680",
    "end": "389599"
  },
  {
    "text": "healing and spending reconciliation",
    "start": "389599",
    "end": "391840"
  },
  {
    "text": "Cycles on unnecessary resources as an",
    "start": "391840",
    "end": "394960"
  },
  {
    "text": "example if you have self healing turned",
    "start": "394960",
    "end": "397039"
  },
  {
    "text": "on in AR CD the default time out here is",
    "start": "397039",
    "end": "399479"
  },
  {
    "text": "5 Seconds we've tuned that up all the",
    "start": "399479",
    "end": "401520"
  },
  {
    "text": "way to 10 minutes uh as I've shown here",
    "start": "401520",
    "end": "404440"
  },
  {
    "text": "uh and we also disabled the health",
    "start": "404440",
    "end": "406599"
  },
  {
    "text": "status persistence which reduces the",
    "start": "406599",
    "end": "408840"
  },
  {
    "text": "number of application crd updates and",
    "start": "408840",
    "end": "410840"
  },
  {
    "text": "the data volume on the C's backing store",
    "start": "410840",
    "end": "413039"
  },
  {
    "text": "which is at CD it also improves",
    "start": "413039",
    "end": "415360"
  },
  {
    "text": "application controller",
    "start": "415360",
    "end": "418000"
  },
  {
    "text": "performance we also EXP sless in our G",
    "start": "418000",
    "end": "420440"
  },
  {
    "text": "up engine as well as uh sless in our",
    "start": "420440",
    "end": "422879"
  },
  {
    "text": "cluster performance and for that we",
    "start": "422879",
    "end": "425960"
  },
  {
    "text": "actually tackled that by tuning",
    "start": "425960",
    "end": "427599"
  },
  {
    "text": "parallelism and compression settings so",
    "start": "427599",
    "end": "429960"
  },
  {
    "text": "for example for the AO CD repo server it",
    "start": "429960",
    "end": "432919"
  },
  {
    "text": "actually helped to reduce the",
    "start": "432919",
    "end": "434039"
  },
  {
    "text": "parallelism there and to to scale up the",
    "start": "434039",
    "end": "436879"
  },
  {
    "text": "processing with additional replicas",
    "start": "436879",
    "end": "438479"
  },
  {
    "text": "instead of additional parm uh settings",
    "start": "438479",
    "end": "441400"
  },
  {
    "text": "in to high a setting there actually slow",
    "start": "441400",
    "end": "443199"
  },
  {
    "text": "down the processing for the repo",
    "start": "443199",
    "end": "445240"
  },
  {
    "text": "server we also limited the parallelism",
    "start": "445240",
    "end": "448199"
  },
  {
    "text": "settings in the ARG work workflows as",
    "start": "448199",
    "end": "450360"
  },
  {
    "text": "tenants were able to spin up an",
    "start": "450360",
    "end": "451960"
  },
  {
    "text": "extremely large number of PODS and",
    "start": "451960",
    "end": "453400"
  },
  {
    "text": "workflows in parallel without setting",
    "start": "453400",
    "end": "456039"
  },
  {
    "text": "those we also enabled compression",
    "start": "456039",
    "end": "458280"
  },
  {
    "text": "settings that help helped the Argo CD UI",
    "start": "458280",
    "end": "461120"
  },
  {
    "text": "performance as well as help reduce R",
    "start": "461120",
    "end": "463080"
  },
  {
    "text": "databas",
    "start": "463080",
    "end": "465440"
  },
  {
    "text": "sizes at the same time as limiting some",
    "start": "465440",
    "end": "467720"
  },
  {
    "text": "settings like parallelism there were",
    "start": "467720",
    "end": "469680"
  },
  {
    "text": "various limits that we actually needed",
    "start": "469680",
    "end": "470879"
  },
  {
    "text": "to increase in order to gain more",
    "start": "470879",
    "end": "472599"
  },
  {
    "text": "performance from a system we were",
    "start": "472599",
    "end": "475520"
  },
  {
    "text": "hitting various timeouts on our system",
    "start": "475520",
    "end": "477520"
  },
  {
    "text": "we were and we were getting frequent",
    "start": "477520",
    "end": "478759"
  },
  {
    "text": "restarts and H evictions of some of our",
    "start": "478759",
    "end": "481759"
  },
  {
    "text": "components so the solution to the",
    "start": "481759",
    "end": "483639"
  },
  {
    "text": "resource were to set proper resource",
    "start": "483639",
    "end": "485720"
  },
  {
    "text": "requests if you are using a CD in",
    "start": "485720",
    "end": "488199"
  },
  {
    "text": "workflows for example like out of the",
    "start": "488199",
    "end": "490240"
  },
  {
    "text": "box they are really they're just not set",
    "start": "490240",
    "end": "492120"
  },
  {
    "text": "at all so you'll just want to make sure",
    "start": "492120",
    "end": "494440"
  },
  {
    "text": "that they're set appropriately uh set",
    "start": "494440",
    "end": "496400"
  },
  {
    "text": "for all components and increase them as",
    "start": "496400",
    "end": "498280"
  },
  {
    "text": "required for your",
    "start": "498280",
    "end": "499800"
  },
  {
    "text": "environment another example if you're",
    "start": "499800",
    "end": "501759"
  },
  {
    "text": "running lots of services like we are is",
    "start": "501759",
    "end": "504000"
  },
  {
    "text": "that you may need to increase your grpc",
    "start": "504000",
    "end": "505800"
  },
  {
    "text": "payload Max size without the setting you",
    "start": "505800",
    "end": "508520"
  },
  {
    "text": "might have uh trouble uh getting back",
    "start": "508520",
    "end": "510680"
  },
  {
    "text": "results from Argo CD applic uh server if",
    "start": "510680",
    "end": "513800"
  },
  {
    "text": "the application count is too",
    "start": "513800",
    "end": "515919"
  },
  {
    "text": "high uh another thing that we did was to",
    "start": "515919",
    "end": "518279"
  },
  {
    "text": "fix replication settings uh for example",
    "start": "518279",
    "end": "521159"
  },
  {
    "text": "Argo CD uses redus as the caching engine",
    "start": "521159",
    "end": "523959"
  },
  {
    "text": "and some of the settings there need to",
    "start": "523959",
    "end": "525200"
  },
  {
    "text": "be tuned in order to ensure that the r",
    "start": "525200",
    "end": "527560"
  },
  {
    "text": "application work properly with larger",
    "start": "527560",
    "end": "529360"
  },
  {
    "text": "database",
    "start": "529360",
    "end": "530320"
  },
  {
    "text": "sizes the screenshot here shows uh the",
    "start": "530320",
    "end": "533160"
  },
  {
    "text": "settings that we tune uh so we increase",
    "start": "533160",
    "end": "534839"
  },
  {
    "text": "the client uput buffer limit and the Min",
    "start": "534839",
    "end": "536920"
  },
  {
    "text": "replicas the",
    "start": "536920",
    "end": "538120"
  },
  {
    "text": "right another thing that we did was that",
    "start": "538120",
    "end": "540440"
  },
  {
    "text": "we set uh set or increase timeouts as",
    "start": "540440",
    "end": "543360"
  },
  {
    "text": "required so for example uh what we did",
    "start": "543360",
    "end": "546560"
  },
  {
    "text": "was for repo server we set timeouts",
    "start": "546560",
    "end": "549000"
  },
  {
    "text": "there and increased reconciliation",
    "start": "549000",
    "end": "551360"
  },
  {
    "text": "timeouts um if you happen to be hitting",
    "start": "551360",
    "end": "554760"
  },
  {
    "text": "those we also had some problematic",
    "start": "554760",
    "end": "557160"
  },
  {
    "text": "workloads running on our system which",
    "start": "557160",
    "end": "558880"
  },
  {
    "text": "was causing disproportionate workload on",
    "start": "558880",
    "end": "561240"
  },
  {
    "text": "our system which we needed to",
    "start": "561240",
    "end": "563839"
  },
  {
    "text": "address so you'll want to make sure to",
    "start": "563839",
    "end": "566440"
  },
  {
    "text": "fix or remove any kind of problematic",
    "start": "566440",
    "end": "568560"
  },
  {
    "text": "resource they have",
    "start": "568560",
    "end": "570240"
  },
  {
    "text": "for example um flapping applications",
    "start": "570240",
    "end": "573600"
  },
  {
    "text": "they're especially really bad as they",
    "start": "573600",
    "end": "575600"
  },
  {
    "text": "cause significant load on the",
    "start": "575600",
    "end": "576800"
  },
  {
    "text": "application controller and can starve",
    "start": "576800",
    "end": "578399"
  },
  {
    "text": "resources for your other healthy apps",
    "start": "578399",
    "end": "581160"
  },
  {
    "text": "and the flapping app in case you're not",
    "start": "581160",
    "end": "582600"
  },
  {
    "text": "familiar with them is an application",
    "start": "582600",
    "end": "584240"
  },
  {
    "text": "that is for example a flipping State",
    "start": "584240",
    "end": "586000"
  },
  {
    "text": "back and forth really really rapidly for",
    "start": "586000",
    "end": "588480"
  },
  {
    "text": "example if it's uh going in and out of",
    "start": "588480",
    "end": "590480"
  },
  {
    "text": "sync in and out of sync really rapidly",
    "start": "590480",
    "end": "592760"
  },
  {
    "text": "within seconds so how do we detect those",
    "start": "592760",
    "end": "596160"
  },
  {
    "text": "in Argo CD uh the simplest way is to",
    "start": "596160",
    "end": "598839"
  },
  {
    "text": "watch the I for go apps going in the out",
    "start": "598839",
    "end": "601320"
  },
  {
    "text": "sync frequently for example with the",
    "start": "601320",
    "end": "604000"
  },
  {
    "text": "default self heel settings you'll see",
    "start": "604000",
    "end": "605519"
  },
  {
    "text": "apps going in the out sync every 5",
    "start": "605519",
    "end": "607200"
  },
  {
    "text": "seconds or",
    "start": "607200",
    "end": "608600"
  },
  {
    "text": "so you can also locate logs uh for",
    "start": "608600",
    "end": "611279"
  },
  {
    "text": "example if you see the application",
    "start": "611279",
    "end": "613120"
  },
  {
    "text": "status changing several times a minute",
    "start": "613120",
    "end": "614839"
  },
  {
    "text": "you probably have a flapping",
    "start": "614839",
    "end": "616920"
  },
  {
    "text": "app and an example of a flapping app",
    "start": "616920",
    "end": "619399"
  },
  {
    "text": "manifest diff is shown here uh here",
    "start": "619399",
    "end": "621839"
  },
  {
    "text": "there's another process adding in debug",
    "start": "621839",
    "end": "623760"
  },
  {
    "text": "lines shown on the left in red uh and",
    "start": "623760",
    "end": "626640"
  },
  {
    "text": "then on the right the application uh or",
    "start": "626640",
    "end": "629320"
  },
  {
    "text": "C the application sync is is trying to",
    "start": "629320",
    "end": "631320"
  },
  {
    "text": "remove them and it keeps FL flipping",
    "start": "631320",
    "end": "633480"
  },
  {
    "text": "back and forth and it just goes in the N",
    "start": "633480",
    "end": "636200"
  },
  {
    "text": "Sync and uh another thing that you want",
    "start": "636200",
    "end": "638680"
  },
  {
    "text": "to watch out for uh is that uh to make",
    "start": "638680",
    "end": "641240"
  },
  {
    "text": "sure that you're cleaning up any unused",
    "start": "641240",
    "end": "643240"
  },
  {
    "text": "or test applications it's it's a little",
    "start": "643240",
    "end": "645079"
  },
  {
    "text": "bit self-explanatory but uh it's",
    "start": "645079",
    "end": "646800"
  },
  {
    "text": "important to Just note uh because they",
    "start": "646800",
    "end": "649079"
  },
  {
    "text": "tend to be the applications that your",
    "start": "649079",
    "end": "650760"
  },
  {
    "text": "developers are probably ignoring they",
    "start": "650760",
    "end": "653000"
  },
  {
    "text": "set up once and forgot about it right um",
    "start": "653000",
    "end": "655800"
  },
  {
    "text": "in addition uh uh you want to watch out",
    "start": "655800",
    "end": "658079"
  },
  {
    "text": "for any kind of large gate repos uh that",
    "start": "658079",
    "end": "660959"
  },
  {
    "text": "you you are managing with your G Ops",
    "start": "660959",
    "end": "662880"
  },
  {
    "text": "engine uh they might require special",
    "start": "662880",
    "end": "664800"
  },
  {
    "text": "tuning uh for Argo CD specifically you",
    "start": "664800",
    "end": "667480"
  },
  {
    "text": "want to watch out for mon repos which",
    "start": "667480",
    "end": "669279"
  },
  {
    "text": "ago C defines as any any one git repo",
    "start": "669279",
    "end": "672519"
  },
  {
    "text": "that manages over 50 Aro C",
    "start": "672519",
    "end": "676120"
  },
  {
    "text": "applications another problem that we had",
    "start": "676200",
    "end": "678279"
  },
  {
    "text": "was that was that our SD database which",
    "start": "678279",
    "end": "680320"
  },
  {
    "text": "again is the backing store for",
    "start": "680320",
    "end": "681880"
  },
  {
    "text": "kubernetes uh that was growing very very",
    "start": "681880",
    "end": "684120"
  },
  {
    "text": "rapidly and we needed a way to reduce",
    "start": "684120",
    "end": "685920"
  },
  {
    "text": "the database size and to keep it in",
    "start": "685920",
    "end": "687839"
  },
  {
    "text": "check so here the database uh size is",
    "start": "687839",
    "end": "691240"
  },
  {
    "text": "really actually very important because",
    "start": "691240",
    "end": "692959"
  },
  {
    "text": "it's recommended to stay under the 8 gig",
    "start": "692959",
    "end": "695680"
  },
  {
    "text": "limit and to do this the best way that",
    "start": "695680",
    "end": "698560"
  },
  {
    "text": "we found was to Archive any kind of old",
    "start": "698560",
    "end": "700800"
  },
  {
    "text": "data when at all possible so we're",
    "start": "700800",
    "end": "703680"
  },
  {
    "text": "running Argo workflows and specifically",
    "start": "703680",
    "end": "705399"
  },
  {
    "text": "for that there's a feature that you can",
    "start": "705399",
    "end": "707320"
  },
  {
    "text": "turn on called archive workflows and",
    "start": "707320",
    "end": "710120"
  },
  {
    "text": "that helps reduce the number of ponds",
    "start": "710120",
    "end": "711959"
  },
  {
    "text": "and workflow events that are stored in N",
    "start": "711959",
    "end": "715000"
  },
  {
    "text": "CD you'll also want to increase the",
    "start": "715000",
    "end": "717920"
  },
  {
    "text": "frequency of any cleanup process CES uh",
    "start": "717920",
    "end": "720240"
  },
  {
    "text": "and another example for workflows is to",
    "start": "720240",
    "end": "722279"
  },
  {
    "text": "reduce the active deadline seconds and",
    "start": "722279",
    "end": "724639"
  },
  {
    "text": "TTL strategy to delete completed",
    "start": "724639",
    "end": "726880"
  },
  {
    "text": "workflows after a set",
    "start": "726880",
    "end": "729040"
  },
  {
    "text": "time and another yet exam yet another",
    "start": "729040",
    "end": "731839"
  },
  {
    "text": "example is to enable pod GC and that",
    "start": "731839",
    "end": "734600"
  },
  {
    "text": "setting will delete any completed",
    "start": "734600",
    "end": "738240"
  },
  {
    "text": "pods so now I'll cover some additional",
    "start": "739240",
    "end": "741680"
  },
  {
    "text": "General tips uh so first uh make sure",
    "start": "741680",
    "end": "745160"
  },
  {
    "text": "you use an Informer cache where possible",
    "start": "745160",
    "end": "748120"
  },
  {
    "text": "uh in our case uh we switched from using",
    "start": "748120",
    "end": "750760"
  },
  {
    "text": "the kubernetes apis to ARG CD apis as it",
    "start": "750760",
    "end": "753639"
  },
  {
    "text": "gave us an informa cach for free and we",
    "start": "753639",
    "end": "756040"
  },
  {
    "text": "didn't need to maintain our own this was",
    "start": "756040",
    "end": "758920"
  },
  {
    "text": "actually a resolution to one of our big",
    "start": "758920",
    "end": "760839"
  },
  {
    "text": "big production averages that we had",
    "start": "760839",
    "end": "763320"
  },
  {
    "text": "um and then ensure your kues cluster is",
    "start": "763320",
    "end": "766839"
  },
  {
    "text": "is healthy uh and tuned correctly uh and",
    "start": "766839",
    "end": "769199"
  },
  {
    "text": "this this by itself can be a whole talk",
    "start": "769199",
    "end": "771360"
  },
  {
    "text": "by itself so I'm just going to touch on",
    "start": "771360",
    "end": "772959"
  },
  {
    "text": "some of the basics here uh so make sure",
    "start": "772959",
    "end": "775440"
  },
  {
    "text": "you're monitoring your API server and SD",
    "start": "775440",
    "end": "778120"
  },
  {
    "text": "performance make sure you're monitoring",
    "start": "778120",
    "end": "780000"
  },
  {
    "text": "your SE database size that's a big",
    "start": "780000",
    "end": "781920"
  },
  {
    "text": "problem that we had uh monitor the APF Q",
    "start": "781920",
    "end": "785519"
  },
  {
    "text": "uh and ensure things aren't falling into",
    "start": "785519",
    "end": "787160"
  },
  {
    "text": "that",
    "start": "787160",
    "end": "788279"
  },
  {
    "text": "queue uh performs any kind of cni tuning",
    "start": "788279",
    "end": "790959"
  },
  {
    "text": "as",
    "start": "790959",
    "end": "791760"
  },
  {
    "text": "required and ensure that you have enough",
    "start": "791760",
    "end": "794079"
  },
  {
    "text": "IP space for a cluster as well as for",
    "start": "794079",
    "end": "796079"
  },
  {
    "text": "all of your pods and now I'll hand back",
    "start": "796079",
    "end": "798320"
  },
  {
    "text": "to Aon to talk about some additional",
    "start": "798320",
    "end": "799839"
  },
  {
    "text": "scaling efforts that we",
    "start": "799839",
    "end": "801920"
  },
  {
    "text": "took cool thank you so vertically",
    "start": "801920",
    "end": "805399"
  },
  {
    "text": "scaling has gone a long way in terms of",
    "start": "805399",
    "end": "807360"
  },
  {
    "text": "helping our stability and scalability",
    "start": "807360",
    "end": "810000"
  },
  {
    "text": "uh for example we went from struggling",
    "start": "810000",
    "end": "811639"
  },
  {
    "text": "with 2,000 Argo CD applications to",
    "start": "811639",
    "end": "814120"
  },
  {
    "text": "comfortably handling",
    "start": "814120",
    "end": "815600"
  },
  {
    "text": "12,000 but like any vertical scaling",
    "start": "815600",
    "end": "817880"
  },
  {
    "text": "we're Bound by physical limitations like",
    "start": "817880",
    "end": "819760"
  },
  {
    "text": "the maximum size of the ETD database or",
    "start": "819760",
    "end": "822839"
  },
  {
    "text": "the resources available on a single node",
    "start": "822839",
    "end": "824639"
  },
  {
    "text": "to allocate to the Pod and so on to",
    "start": "824639",
    "end": "827000"
  },
  {
    "text": "address that we needed to come up with a",
    "start": "827000",
    "end": "828839"
  },
  {
    "text": "horizontal scaling",
    "start": "828839",
    "end": "830639"
  },
  {
    "text": "strategy the problem is at the time of",
    "start": "830639",
    "end": "833160"
  },
  {
    "text": "design our platform was already in",
    "start": "833160",
    "end": "834959"
  },
  {
    "text": "active use so we needed to be conscious",
    "start": "834959",
    "end": "837240"
  },
  {
    "text": "of our impact uh to any production",
    "start": "837240",
    "end": "839519"
  },
  {
    "text": "workloads so that meant Zero downtime",
    "start": "839519",
    "end": "841560"
  },
  {
    "text": "cut over to any new architecture uh and",
    "start": "841560",
    "end": "844040"
  },
  {
    "text": "we also needed an architecture that was",
    "start": "844040",
    "end": "845800"
  },
  {
    "text": "easy to understand communicate and",
    "start": "845800",
    "end": "847560"
  },
  {
    "text": "Implement you know so that we could",
    "start": "847560",
    "end": "849040"
  },
  {
    "text": "reach quick alignment and begin work",
    "start": "849040",
    "end": "851279"
  },
  {
    "text": "immediately we also had a tight deadline",
    "start": "851279",
    "end": "853360"
  },
  {
    "text": "of course who doesn't uh and an analogy",
    "start": "853360",
    "end": "855959"
  },
  {
    "text": "I liked is it's comparable to refueling",
    "start": "855959",
    "end": "859040"
  },
  {
    "text": "mid-flight so uh here's a simplified",
    "start": "859040",
    "end": "861560"
  },
  {
    "text": "version of the flex architecture from",
    "start": "861560",
    "end": "863079"
  },
  {
    "text": "our previous slide uh and this is what",
    "start": "863079",
    "end": "865199"
  },
  {
    "text": "we needed to horizontally scale so the",
    "start": "865199",
    "end": "867399"
  },
  {
    "text": "first step was to determine what makes",
    "start": "867399",
    "end": "868759"
  },
  {
    "text": "up an installation of flex uh for us",
    "start": "868759",
    "end": "871480"
  },
  {
    "text": "this was just the entire kubernetes",
    "start": "871480",
    "end": "873120"
  },
  {
    "text": "cluster and all the flex related",
    "start": "873120",
    "end": "874880"
  },
  {
    "text": "components running in running in it so",
    "start": "874880",
    "end": "878560"
  },
  {
    "text": "we plan the plan was to horizontally",
    "start": "878560",
    "end": "880639"
  },
  {
    "text": "scale Flex by scaling the number of",
    "start": "880639",
    "end": "883399"
  },
  {
    "text": "clusters um we called each one of these",
    "start": "883399",
    "end": "885519"
  },
  {
    "text": "clusters running flex components Flex",
    "start": "885519",
    "end": "888000"
  },
  {
    "text": "boxes uh and we built a tooling to",
    "start": "888000",
    "end": "891000"
  },
  {
    "text": "automate the creation of additional Flex",
    "start": "891000",
    "end": "892800"
  },
  {
    "text": "boxes like this uh we then used it to",
    "start": "892800",
    "end": "896480"
  },
  {
    "text": "create an additional installation of",
    "start": "896480",
    "end": "897920"
  },
  {
    "text": "flex uh in this example uh labeled",
    "start": "897920",
    "end": "900600"
  },
  {
    "text": "flexbox 2 here which again is just an",
    "start": "900600",
    "end": "904000"
  },
  {
    "text": "additional Flex cluster the next problem",
    "start": "904000",
    "end": "906600"
  },
  {
    "text": "is on its own it doesn't really do",
    "start": "906600",
    "end": "908079"
  },
  {
    "text": "anything yet uh so in order to actually",
    "start": "908079",
    "end": "910360"
  },
  {
    "text": "make use of it uh we added a component",
    "start": "910360",
    "end": "912839"
  },
  {
    "text": "for routing traffic from GitHub in order",
    "start": "912839",
    "end": "915199"
  },
  {
    "text": "to load balance across the different",
    "start": "915199",
    "end": "917000"
  },
  {
    "text": "Flex",
    "start": "917000",
    "end": "918160"
  },
  {
    "text": "boxes uh so this would act like a a load",
    "start": "918160",
    "end": "920720"
  },
  {
    "text": "balancer to use a traditional networking",
    "start": "920720",
    "end": "923240"
  },
  {
    "text": "analy uh and in the diagram you can",
    "start": "923240",
    "end": "925600"
  },
  {
    "text": "think of the GitHub events as our",
    "start": "925600",
    "end": "926880"
  },
  {
    "text": "incoming traffic uh and the redirection",
    "start": "926880",
    "end": "930920"
  },
  {
    "text": "component here is the is the load balcer",
    "start": "930920",
    "end": "934079"
  },
  {
    "text": "uh so the next problem is this does help",
    "start": "934079",
    "end": "937000"
  },
  {
    "text": "stop things from getting worse but we",
    "start": "937000",
    "end": "939040"
  },
  {
    "text": "still had the issue of the overloaded",
    "start": "939040",
    "end": "940560"
  },
  {
    "text": "flexbox one from before this right so",
    "start": "940560",
    "end": "944079"
  },
  {
    "text": "from that for that we built tooling to",
    "start": "944079",
    "end": "946040"
  },
  {
    "text": "redistribute existing load from flexbox",
    "start": "946040",
    "end": "948480"
  },
  {
    "text": "one onto flexbox 2 and this tooling",
    "start": "948480",
    "end": "951160"
  },
  {
    "text": "would essentially uh seamlessly move",
    "start": "951160",
    "end": "953600"
  },
  {
    "text": "client workloads between Flex boxes",
    "start": "953600",
    "end": "955560"
  },
  {
    "text": "without downtime to their",
    "start": "955560",
    "end": "957240"
  },
  {
    "text": "services uh and while most of this seems",
    "start": "957240",
    "end": "959480"
  },
  {
    "text": "like a relatively drastic re",
    "start": "959480",
    "end": "960839"
  },
  {
    "text": "architecture we were able to do this",
    "start": "960839",
    "end": "962399"
  },
  {
    "text": "with minimal client impact clients would",
    "start": "962399",
    "end": "964800"
  },
  {
    "text": "continue to use a single end point for",
    "start": "964800",
    "end": "966959"
  },
  {
    "text": "accessing their Argo CD or Argo",
    "start": "966959",
    "end": "968480"
  },
  {
    "text": "workflows instance ass associated with",
    "start": "968480",
    "end": "970839"
  },
  {
    "text": "their uh respective",
    "start": "970839",
    "end": "972759"
  },
  {
    "text": "flexbox and this has been working great",
    "start": "972759",
    "end": "974720"
  },
  {
    "text": "for us so far so now I'll talk about",
    "start": "974720",
    "end": "977880"
  },
  {
    "text": "lessons we learned from our experience",
    "start": "977880",
    "end": "979399"
  },
  {
    "text": "and some",
    "start": "979399",
    "end": "981040"
  },
  {
    "text": "recommendations so first plan for",
    "start": "981040",
    "end": "984319"
  },
  {
    "text": "horizontal scaling in multiple instances",
    "start": "984319",
    "end": "987120"
  },
  {
    "text": "this will simplify things in the long",
    "start": "987120",
    "end": "988480"
  },
  {
    "text": "run uh if horizontal scaling is planned",
    "start": "988480",
    "end": "990759"
  },
  {
    "text": "for up front you can defer some of the",
    "start": "990759",
    "end": "992279"
  },
  {
    "text": "vertical scaling uh the trade-off is",
    "start": "992279",
    "end": "994839"
  },
  {
    "text": "some increased infrastructure cost but",
    "start": "994839",
    "end": "996720"
  },
  {
    "text": "but this can save developer time and",
    "start": "996720",
    "end": "998680"
  },
  {
    "text": "build up some operational experience uh",
    "start": "998680",
    "end": "1001319"
  },
  {
    "text": "and it's worth mentioning even if you",
    "start": "1001319",
    "end": "1002560"
  },
  {
    "text": "don't think you'll need it do it",
    "start": "1002560",
    "end": "1004680"
  },
  {
    "text": "anyway uh plan a sharding strategy for",
    "start": "1004680",
    "end": "1008079"
  },
  {
    "text": "example sharding by some function like",
    "start": "1008079",
    "end": "1010240"
  },
  {
    "text": "class of workload or business unit can",
    "start": "1010240",
    "end": "1011800"
  },
  {
    "text": "help you distribute load",
    "start": "1011800",
    "end": "1014279"
  },
  {
    "text": "evenly uh make sure you can create",
    "start": "1014279",
    "end": "1016880"
  },
  {
    "text": "additional instances to be used for",
    "start": "1016880",
    "end": "1018880"
  },
  {
    "text": "horizontal scaling uh we didn't do this",
    "start": "1018880",
    "end": "1021240"
  },
  {
    "text": "up front and we wish we had for us",
    "start": "1021240",
    "end": "1023360"
  },
  {
    "text": "additional instances came in the form of",
    "start": "1023360",
    "end": "1025038"
  },
  {
    "text": "what we call Flex boxes this will vary",
    "start": "1025039",
    "end": "1027079"
  },
  {
    "text": "from platform to platform design what",
    "start": "1027079",
    "end": "1029319"
  },
  {
    "text": "works best for your",
    "start": "1029319",
    "end": "1030640"
  },
  {
    "text": "platform plan for redistributing your",
    "start": "1030640",
    "end": "1033520"
  },
  {
    "text": "workloads sharding is hard to get right",
    "start": "1033520",
    "end": "1036000"
  },
  {
    "text": "the first time and so our relocation",
    "start": "1036000",
    "end": "1037480"
  },
  {
    "text": "tooling has been invaluable to us and",
    "start": "1037480",
    "end": "1041240"
  },
  {
    "text": "another thing to consider is to divide",
    "start": "1041240",
    "end": "1042678"
  },
  {
    "text": "any intensive workloads that you might",
    "start": "1042679",
    "end": "1044400"
  },
  {
    "text": "have into separate closers if they rely",
    "start": "1044400",
    "end": "1046839"
  },
  {
    "text": "on the same control plane bottlenecks",
    "start": "1046839",
    "end": "1048438"
  },
  {
    "text": "they'll affect each other's performance",
    "start": "1048439",
    "end": "1050919"
  },
  {
    "text": "as an example if you're running both AR",
    "start": "1050919",
    "end": "1052960"
  },
  {
    "text": "and work clothes like we are try to run",
    "start": "1052960",
    "end": "1054799"
  },
  {
    "text": "them on different kubernetes clusters if",
    "start": "1054799",
    "end": "1056520"
  },
  {
    "text": "that all",
    "start": "1056520",
    "end": "1057640"
  },
  {
    "text": "possible AR so AR CD consists of long L",
    "start": "1057640",
    "end": "1060960"
  },
  {
    "text": "workflows and also generates a large",
    "start": "1060960",
    "end": "1062760"
  },
  {
    "text": "number of events and it really works",
    "start": "1062760",
    "end": "1064640"
  },
  {
    "text": "best when it's on its own",
    "start": "1064640",
    "end": "1066440"
  },
  {
    "text": "cluster if you're running lots of",
    "start": "1066440",
    "end": "1068400"
  },
  {
    "text": "workflows workflows like we are Aro",
    "start": "1068400",
    "end": "1071240"
  },
  {
    "text": "workflows can cause lots of SCD churn as",
    "start": "1071240",
    "end": "1074039"
  },
  {
    "text": "workflows consists of many crds as well",
    "start": "1074039",
    "end": "1076080"
  },
  {
    "text": "as many pods spinning up and down and",
    "start": "1076080",
    "end": "1077880"
  },
  {
    "text": "usually consists of many shortlived",
    "start": "1077880",
    "end": "1080280"
  },
  {
    "text": "workflows this type of workflow is the",
    "start": "1080280",
    "end": "1082679"
  },
  {
    "text": "exact opposite of rcd so it's really",
    "start": "1082679",
    "end": "1084679"
  },
  {
    "text": "best to keep them separate if at all",
    "start": "1084679",
    "end": "1086640"
  },
  {
    "text": "possible we unfortunately did not uh",
    "start": "1086640",
    "end": "1089120"
  },
  {
    "text": "split them and it actually forced us to",
    "start": "1089120",
    "end": "1090679"
  },
  {
    "text": "do additional tuning for both CD and",
    "start": "1090679",
    "end": "1093120"
  },
  {
    "text": "workflows and due to the volume of",
    "start": "1093120",
    "end": "1095159"
  },
  {
    "text": "workflows that we were running we were",
    "start": "1095159",
    "end": "1096559"
  },
  {
    "text": "hitting database limits for SD which is",
    "start": "1096559",
    "end": "1098559"
  },
  {
    "text": "why I kept talking about it and uh this",
    "start": "1098559",
    "end": "1100720"
  },
  {
    "text": "limited the number of Argo CD",
    "start": "1100720",
    "end": "1102559"
  },
  {
    "text": "applications that we can support on a",
    "start": "1102559",
    "end": "1103760"
  },
  {
    "text": "single",
    "start": "1103760",
    "end": "1105600"
  },
  {
    "text": "cluster when to start tuning for scale",
    "start": "1105600",
    "end": "1109159"
  },
  {
    "text": "so we started seeing issues with a",
    "start": "1109159",
    "end": "1111720"
  },
  {
    "text": "couple hundred tennis Services",
    "start": "1111720",
    "end": "1113440"
  },
  {
    "text": "running and depending on your",
    "start": "1113440",
    "end": "1115120"
  },
  {
    "text": "architecture or platform you might start",
    "start": "1115120",
    "end": "1116760"
  },
  {
    "text": "to see slow downs even earlier so it's",
    "start": "1116760",
    "end": "1118679"
  },
  {
    "text": "really never too early to start",
    "start": "1118679",
    "end": "1120919"
  },
  {
    "text": "tuning also the exact number obviously",
    "start": "1120919",
    "end": "1123679"
  },
  {
    "text": "depend on your get Ops engine platform",
    "start": "1123679",
    "end": "1125400"
  },
  {
    "text": "of course and in Argo CD in particular",
    "start": "1125400",
    "end": "1128520"
  },
  {
    "text": "the number of Argo CD applications to",
    "start": "1128520",
    "end": "1130280"
  },
  {
    "text": "watch for are about 1500 to two uh 2,000",
    "start": "1130280",
    "end": "1133039"
  },
  {
    "text": "or so orac City",
    "start": "1133039",
    "end": "1134799"
  },
  {
    "text": "applications and also each orac City",
    "start": "1134799",
    "end": "1137120"
  },
  {
    "text": "application can only target one remote",
    "start": "1137120",
    "end": "1138799"
  },
  {
    "text": "cluster so you might hit this number",
    "start": "1138799",
    "end": "1140600"
  },
  {
    "text": "fast way faster than anything and this",
    "start": "1140600",
    "end": "1142760"
  },
  {
    "text": "also applies even if you use application",
    "start": "1142760",
    "end": "1146760"
  },
  {
    "text": "sets and if again if you're struggling",
    "start": "1146919",
    "end": "1149280"
  },
  {
    "text": "to scale your get op solution you should",
    "start": "1149280",
    "end": "1151400"
  },
  {
    "text": "definitely follow some of the tips that",
    "start": "1151400",
    "end": "1152600"
  },
  {
    "text": "we gave in this talk in addition",
    "start": "1152600",
    "end": "1155480"
  },
  {
    "text": "understand your bottle necks and make",
    "start": "1155480",
    "end": "1156840"
  },
  {
    "text": "sure they're popularly",
    "start": "1156840",
    "end": "1158640"
  },
  {
    "text": "monitored understand the knobs that you",
    "start": "1158640",
    "end": "1160679"
  },
  {
    "text": "can turn in your system and finally",
    "start": "1160679",
    "end": "1163480"
  },
  {
    "text": "we've also done some other talks on this",
    "start": "1163480",
    "end": "1165080"
  },
  {
    "text": "topic uh so be sure to check them out",
    "start": "1165080",
    "end": "1167039"
  },
  {
    "text": "and I've linked one of those here um the",
    "start": "1167039",
    "end": "1169240"
  },
  {
    "text": "QR code",
    "start": "1169240",
    "end": "1171000"
  },
  {
    "text": "here and that conclud our talk thank you",
    "start": "1171000",
    "end": "1173440"
  },
  {
    "text": "everyone for listening and we'll open up",
    "start": "1173440",
    "end": "1175039"
  },
  {
    "text": "for Q&A",
    "start": "1175039",
    "end": "1177679"
  },
  {
    "text": "now all right who has",
    "start": "1179600",
    "end": "1182080"
  },
  {
    "text": "questions question first of all thank",
    "start": "1182080",
    "end": "1185360"
  },
  {
    "text": "you so much for for this and your",
    "start": "1185360",
    "end": "1187240"
  },
  {
    "text": "previous talks that saved the day for us",
    "start": "1187240",
    "end": "1189960"
  },
  {
    "text": "um we follow some of that advice and",
    "start": "1189960",
    "end": "1191880"
  },
  {
    "text": "we're able to get",
    "start": "1191880",
    "end": "1193360"
  },
  {
    "text": "4,000 smoothly",
    "start": "1193360",
    "end": "1197360"
  },
  {
    "text": "things that we looked at was uh Auto",
    "start": "1198840",
    "end": "1200799"
  },
  {
    "text": "scaling rep server and when we did we",
    "start": "1200799",
    "end": "1203520"
  },
  {
    "text": "started to experience timeouts during",
    "start": "1203520",
    "end": "1206280"
  },
  {
    "text": "Auto scaling EV so we're just running",
    "start": "1206280",
    "end": "1208600"
  },
  {
    "text": "probably over",
    "start": "1208600",
    "end": "1210960"
  },
  {
    "text": "static is there any way we can get to",
    "start": "1210960",
    "end": "1214280"
  },
  {
    "text": "auto scal",
    "start": "1214280",
    "end": "1216280"
  },
  {
    "text": "without so actually that's a great",
    "start": "1216280",
    "end": "1218559"
  },
  {
    "text": "question and that's actually something",
    "start": "1218559",
    "end": "1219799"
  },
  {
    "text": "we've hit as well I mean we we're also",
    "start": "1219799",
    "end": "1221880"
  },
  {
    "text": "running a static number of repo servers",
    "start": "1221880",
    "end": "1224360"
  },
  {
    "text": "uh we found that um you know keeping",
    "start": "1224360",
    "end": "1226400"
  },
  {
    "text": "them smaller limiting the parallelism",
    "start": "1226400",
    "end": "1228400"
  },
  {
    "text": "actually was really important so I I",
    "start": "1228400",
    "end": "1230559"
  },
  {
    "text": "touched that here and I I covered the",
    "start": "1230559",
    "end": "1232480"
  },
  {
    "text": "exact setting so definitely check that",
    "start": "1232480",
    "end": "1234440"
  },
  {
    "text": "out um I'd highly recommend limiting the",
    "start": "1234440",
    "end": "1236880"
  },
  {
    "text": "parallelism and just scaling up the uh",
    "start": "1236880",
    "end": "1239559"
  },
  {
    "text": "repo server account uh we actually",
    "start": "1239559",
    "end": "1241919"
  },
  {
    "text": "didn't Autos scale either uh we we kept",
    "start": "1241919",
    "end": "1244640"
  },
  {
    "text": "it at a static count uh and in our in",
    "start": "1244640",
    "end": "1246960"
  },
  {
    "text": "our case uh we're not we're adding a lot",
    "start": "1246960",
    "end": "1249280"
  },
  {
    "text": "of vations but we're not deleting that",
    "start": "1249280",
    "end": "1251159"
  },
  {
    "text": "many all that frequently so we found",
    "start": "1251159",
    "end": "1253240"
  },
  {
    "text": "that just you know manually managing",
    "start": "1253240",
    "end": "1255080"
  },
  {
    "text": "them has helped a lot um in terms of uh",
    "start": "1255080",
    "end": "1259120"
  },
  {
    "text": "uh actually like doing a Dynamic Auto",
    "start": "1259120",
    "end": "1261440"
  },
  {
    "text": "scaling on repo server I think you know",
    "start": "1261440",
    "end": "1264039"
  },
  {
    "text": "depending on you know how you have it",
    "start": "1264039",
    "end": "1265480"
  },
  {
    "text": "tuned it might not work as well because",
    "start": "1265480",
    "end": "1267440"
  },
  {
    "text": "uh you",
    "start": "1267440",
    "end": "1268919"
  },
  {
    "text": "know the repo server tends to you know",
    "start": "1268919",
    "end": "1271520"
  },
  {
    "text": "maintain like state right so by trying",
    "start": "1271520",
    "end": "1275200"
  },
  {
    "text": "to you know scale down too much uh you",
    "start": "1275200",
    "end": "1278720"
  },
  {
    "text": "might end up you know having negative",
    "start": "1278720",
    "end": "1280520"
  },
  {
    "text": "impact and you know having like issues",
    "start": "1280520",
    "end": "1282360"
  },
  {
    "text": "with the reconciliation and uh um you",
    "start": "1282360",
    "end": "1286320"
  },
  {
    "text": "know having issues with the uh Rec with",
    "start": "1286320",
    "end": "1289039"
  },
  {
    "text": "your with your G uh with your git server",
    "start": "1289039",
    "end": "1291000"
  },
  {
    "text": "and things like that so um we personally",
    "start": "1291000",
    "end": "1292880"
  },
  {
    "text": "have it set to a static number and we",
    "start": "1292880",
    "end": "1294520"
  },
  {
    "text": "just you know you gradually you know",
    "start": "1294520",
    "end": "1296640"
  },
  {
    "text": "monitor it and gradually increase it as",
    "start": "1296640",
    "end": "1298279"
  },
  {
    "text": "a unit so um I guess that that's been",
    "start": "1298279",
    "end": "1301880"
  },
  {
    "text": "working for the environment so far right",
    "start": "1301880",
    "end": "1303279"
  },
  {
    "text": "so I mean I think that that's that's",
    "start": "1303279",
    "end": "1304880"
  },
  {
    "text": "what I would uh recommend sticking to if",
    "start": "1304880",
    "end": "1307360"
  },
  {
    "text": "possible um unless there's like a cost",
    "start": "1307360",
    "end": "1309880"
  },
  {
    "text": "consideration",
    "start": "1309880",
    "end": "1311919"
  },
  {
    "text": "so",
    "start": "1311919",
    "end": "1313640"
  },
  {
    "text": "yes do you use the Argo CD UI",
    "start": "1313640",
    "end": "1318880"
  },
  {
    "text": "or not you do do that how much that on",
    "start": "1318880",
    "end": "1322440"
  },
  {
    "text": "your",
    "start": "1322440",
    "end": "1325240"
  },
  {
    "text": "scalings",
    "start": "1325240",
    "end": "1328039"
  },
  {
    "text": "related uh so we we actually ex we do",
    "start": "1328039",
    "end": "1331240"
  },
  {
    "text": "use the UI pretty heavily we expose it",
    "start": "1331240",
    "end": "1333720"
  },
  {
    "text": "to clients so they actually look at it",
    "start": "1333720",
    "end": "1336279"
  },
  {
    "text": "um it is not a huge impact because if I",
    "start": "1336279",
    "end": "1340080"
  },
  {
    "text": "remember correctly the the state for the",
    "start": "1340080",
    "end": "1341720"
  },
  {
    "text": "UI is managed separately from the state",
    "start": "1341720",
    "end": "1344520"
  },
  {
    "text": "of the actual resource tree uh so it's",
    "start": "1344520",
    "end": "1348320"
  },
  {
    "text": "been pretty okay for us um when it comes",
    "start": "1348320",
    "end": "1350480"
  },
  {
    "text": "to",
    "start": "1350480",
    "end": "1351279"
  },
  {
    "text": "like uh performance bottlenecks for that",
    "start": "1351279",
    "end": "1354960"
  },
  {
    "text": "like sometimes yeah we'll see the UI",
    "start": "1354960",
    "end": "1357480"
  },
  {
    "text": "kind of is a bit slow to update but uh",
    "start": "1357480",
    "end": "1360799"
  },
  {
    "text": "as far as I remember it it doesn't",
    "start": "1360799",
    "end": "1362279"
  },
  {
    "text": "really impact the the performance of the",
    "start": "1362279",
    "end": "1364159"
  },
  {
    "text": "actual uh controllers and and yeah to to",
    "start": "1364159",
    "end": "1367320"
  },
  {
    "text": "add to that um yeah uh depending on how",
    "start": "1367320",
    "end": "1370559"
  },
  {
    "text": "many applications you're running as like",
    "start": "1370559",
    "end": "1372320"
  },
  {
    "text": "an admin for example you might see UI",
    "start": "1372320",
    "end": "1374600"
  },
  {
    "text": "slowness issues but our clients that",
    "start": "1374600",
    "end": "1377240"
  },
  {
    "text": "have a more limited set of CD",
    "start": "1377240",
    "end": "1379840"
  },
  {
    "text": "applications that they're seeing they",
    "start": "1379840",
    "end": "1382400"
  },
  {
    "text": "won't see that issue as much because we",
    "start": "1382400",
    "end": "1384880"
  },
  {
    "text": "you know with we're limiting that with",
    "start": "1384880",
    "end": "1386279"
  },
  {
    "text": "rback right uh and yeah again as Aon",
    "start": "1386279",
    "end": "1389039"
  },
  {
    "text": "said the I think the controller is",
    "start": "1389039",
    "end": "1391279"
  },
  {
    "text": "separate from the the UI part of things",
    "start": "1391279",
    "end": "1393240"
  },
  {
    "text": "so even if the UI appears so that",
    "start": "1393240",
    "end": "1395279"
  },
  {
    "text": "doesn't mean that you're you know the",
    "start": "1395279",
    "end": "1397400"
  },
  {
    "text": "the reconciliation and you know that",
    "start": "1397400",
    "end": "1399159"
  },
  {
    "text": "stuff is still not happening right",
    "start": "1399159",
    "end": "1402880"
  },
  {
    "text": "so yes I think a lot of strg with",
    "start": "1403919",
    "end": "1410440"
  },
  {
    "text": "uh got it so uh the question is like",
    "start": "1431880",
    "end": "1434799"
  },
  {
    "text": "about a general way to find your",
    "start": "1434799",
    "end": "1436480"
  },
  {
    "text": "performance bottleneck yeah so so I",
    "start": "1436480",
    "end": "1439240"
  },
  {
    "text": "would say um obviously start off by just",
    "start": "1439240",
    "end": "1443240"
  },
  {
    "text": "uh doing a breakdown of what your",
    "start": "1443240",
    "end": "1445279"
  },
  {
    "text": "bottlenecks are and making sure they're",
    "start": "1445279",
    "end": "1446600"
  },
  {
    "text": "all monitored and obviously that's not",
    "start": "1446600",
    "end": "1448600"
  },
  {
    "text": "always going to catch everything right",
    "start": "1448600",
    "end": "1450120"
  },
  {
    "text": "away um for the instances where there's",
    "start": "1450120",
    "end": "1454440"
  },
  {
    "text": "a bottleneck that you didn't uh notice",
    "start": "1454440",
    "end": "1457320"
  },
  {
    "text": "you are just going to have to you know",
    "start": "1457320",
    "end": "1460400"
  },
  {
    "text": "go through the standard troubleshooting",
    "start": "1460400",
    "end": "1462080"
  },
  {
    "text": "process uh and when you reach something",
    "start": "1462080",
    "end": "1463720"
  },
  {
    "text": "that you can horizontally scale like",
    "start": "1463720",
    "end": "1465279"
  },
  {
    "text": "let's say you're running into uh repo",
    "start": "1465279",
    "end": "1467600"
  },
  {
    "text": "server timeouts um you probably want to",
    "start": "1467600",
    "end": "1470600"
  },
  {
    "text": "from there just try horizontally scaling",
    "start": "1470600",
    "end": "1473120"
  },
  {
    "text": "it or vertically scaling it um and then",
    "start": "1473120",
    "end": "1476120"
  },
  {
    "text": "when you are not in like an emergency",
    "start": "1476120",
    "end": "1479520"
  },
  {
    "text": "situation where it's like affecting your",
    "start": "1479520",
    "end": "1481080"
  },
  {
    "text": "actual production environment you can",
    "start": "1481080",
    "end": "1482399"
  },
  {
    "text": "work on like uh benchmarking figuring",
    "start": "1482399",
    "end": "1485679"
  },
  {
    "text": "out where where the ball neck there is",
    "start": "1485679",
    "end": "1487440"
  },
  {
    "text": "like what causes",
    "start": "1487440",
    "end": "1488679"
  },
  {
    "text": "it uh yeah it's a yeah it's like a it's",
    "start": "1488679",
    "end": "1492679"
  },
  {
    "text": "a general uh troubleshooting process",
    "start": "1492679",
    "end": "1495240"
  },
  {
    "text": "that you get better with over time with",
    "start": "1495240",
    "end": "1497120"
  },
  {
    "text": "practice and yeah just to step back uh",
    "start": "1497120",
    "end": "1499880"
  },
  {
    "text": "you know obviously make sure all your",
    "start": "1499880",
    "end": "1501080"
  },
  {
    "text": "components are monitor right so for",
    "start": "1501080",
    "end": "1502600"
  },
  {
    "text": "example Argo CD uh there are some open",
    "start": "1502600",
    "end": "1505840"
  },
  {
    "text": "source uh grafana um dashboards and",
    "start": "1505840",
    "end": "1509159"
  },
  {
    "text": "things like that that you can download",
    "start": "1509159",
    "end": "1510399"
  },
  {
    "text": "and you know start you know that's a",
    "start": "1510399",
    "end": "1512440"
  },
  {
    "text": "great starting point uh that's what we",
    "start": "1512440",
    "end": "1513960"
  },
  {
    "text": "started with uh make sure your",
    "start": "1513960",
    "end": "1515960"
  },
  {
    "text": "kubernetes uh you know the cluster",
    "start": "1515960",
    "end": "1517320"
  },
  {
    "text": "itself is monitored uh just make sure",
    "start": "1517320",
    "end": "1519039"
  },
  {
    "text": "the API server performance is is doing",
    "start": "1519039",
    "end": "1522039"
  },
  {
    "text": "okay like you know check the latency and",
    "start": "1522039",
    "end": "1523679"
  },
  {
    "text": "things like that if you're seeing like",
    "start": "1523679",
    "end": "1525399"
  },
  {
    "text": "huge latency spikes or like 60-sec",
    "start": "1525399",
    "end": "1527600"
  },
  {
    "text": "timeouts in your request and things",
    "start": "1527600",
    "end": "1529200"
  },
  {
    "text": "things like that I mean that's where you",
    "start": "1529200",
    "end": "1530720"
  },
  {
    "text": "you'd want to start looking so yeah",
    "start": "1530720",
    "end": "1532240"
  },
  {
    "text": "that's actually a good call you got a",
    "start": "1532240",
    "end": "1533320"
  },
  {
    "text": "bunch of Prometheus metrics for free",
    "start": "1533320",
    "end": "1534880"
  },
  {
    "text": "from Argo CD and uh ETD so those are",
    "start": "1534880",
    "end": "1537960"
  },
  {
    "text": "great lists to",
    "start": "1537960",
    "end": "1539440"
  },
  {
    "text": "start",
    "start": "1539440",
    "end": "1542440"
  },
  {
    "text": "youland one metric that's a I'd say the",
    "start": "1543880",
    "end": "1547360"
  },
  {
    "text": "kuet server L API server latency like",
    "start": "1547360",
    "end": "1549799"
  },
  {
    "text": "the requests right that's a big one",
    "start": "1549799",
    "end": "1552480"
  },
  {
    "text": "because we were we were definitely",
    "start": "1552480",
    "end": "1553720"
  },
  {
    "text": "hitting like those 60c timeouts and",
    "start": "1553720",
    "end": "1555399"
  },
  {
    "text": "things like that um yeah just watch for",
    "start": "1555399",
    "end": "1557919"
  },
  {
    "text": "those and and you can see some of those",
    "start": "1557919",
    "end": "1559640"
  },
  {
    "text": "in on the on the client side as well",
    "start": "1559640",
    "end": "1562000"
  },
  {
    "text": "right or on the AR CD side just watch",
    "start": "1562000",
    "end": "1564360"
  },
  {
    "text": "your server logs you know control logs",
    "start": "1564360",
    "end": "1567000"
  },
  {
    "text": "repo server logs things like that um as",
    "start": "1567000",
    "end": "1569520"
  },
  {
    "text": "well yeah uh that's that's like the",
    "start": "1569520",
    "end": "1571600"
  },
  {
    "text": "general story for a lot of um kubernetes",
    "start": "1571600",
    "end": "1573919"
  },
  {
    "text": "Native products is like they they pretty",
    "start": "1573919",
    "end": "1575799"
  },
  {
    "text": "heavily utilize the the API server so",
    "start": "1575799",
    "end": "1579760"
  },
  {
    "text": "that's probably going to be like the",
    "start": "1579760",
    "end": "1580960"
  },
  {
    "text": "number one place you need to keep your",
    "start": "1580960",
    "end": "1582039"
  },
  {
    "text": "monit",
    "start": "1582039",
    "end": "1585039"
  }
]
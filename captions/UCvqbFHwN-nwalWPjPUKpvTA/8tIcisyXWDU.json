[
  {
    "start": "0",
    "end": "31000"
  },
  {
    "text": "I'm about to tell you a story of three engineers a DevOps application and data",
    "start": "110",
    "end": "5750"
  },
  {
    "text": "all three of them of different needs and different views and why can I tell you",
    "start": "5750",
    "end": "10920"
  },
  {
    "text": "their story because I had the unique opportunity to play all three of them hello my name is Lauren Beavis and I",
    "start": "10920",
    "end": "18570"
  },
  {
    "text": "walk for Iguazu I'm what I tend to call myself a Joker engineer and as you can",
    "start": "18570",
    "end": "25140"
  },
  {
    "text": "see I'm really into Legos but this is as far as they go down this presentation",
    "start": "25140",
    "end": "30980"
  },
  {
    "text": "for for the past decade or so or bigger out of all this change romantically since its first released back in Apple",
    "start": "30980",
    "end": "37770"
  },
  {
    "start": "31000",
    "end": "185000"
  },
  {
    "text": "to 2006 Hadoop really defined the big data era this world today's network was",
    "start": "37770",
    "end": "43590"
  },
  {
    "text": "slow memory was expensive and we needed something to to process our ever-growing",
    "start": "43590",
    "end": "51149"
  },
  {
    "text": "data we believe that by bringing the compute closer to the data we will solve",
    "start": "51149",
    "end": "57870"
  },
  {
    "text": "all of our problem we remodel our application into MapReduce pipeline and",
    "start": "57870",
    "end": "63149"
  },
  {
    "text": "it actually worked and it was fairly easy to deploy these scenarios our big",
    "start": "63149",
    "end": "70080"
  },
  {
    "text": "data world is grown our software needed a lot more than just MapReduce our user demand a lot more analytics memory",
    "start": "70080",
    "end": "77580"
  },
  {
    "text": "became slightly cheaper so we had the idea of loading everything into memory",
    "start": "77580",
    "end": "83250"
  },
  {
    "text": "and try to compute it as much as possible in there we worship the RDD that spark brought us we even started",
    "start": "83250",
    "end": "91740"
  },
  {
    "text": "storing some of our data in on a loop no sequel data source like Redis or",
    "start": "91740",
    "end": "97320"
  },
  {
    "text": "Cassandra or maybe elasticsearch but we needed a lot more we place Kafka",
    "start": "97320",
    "end": "105270"
  },
  {
    "text": "rabbitmq right next to our API application flow was reading in growing",
    "start": "105270",
    "end": "110369"
  },
  {
    "text": "amount of data we needed a method to process all those incoming events we built event process pipeline with spouts",
    "start": "110369",
    "end": "118979"
  },
  {
    "text": "and bolts we added fleeing and even toned back to spark and got our notion",
    "start": "118979",
    "end": "125490"
  },
  {
    "text": "of swimming with micro batching overall all those frameworks were basically a",
    "start": "125490",
    "end": "131730"
  },
  {
    "text": "way a way of bringing more and more into our Big Data world now that we were",
    "start": "131730",
    "end": "137430"
  },
  {
    "text": "so good at collecting data we need to figure out what its mean Presta was",
    "start": "137430",
    "end": "143760"
  },
  {
    "text": "added to the mixture and with its current solution we turned to machine learning later adopted deep learning and",
    "start": "143760",
    "end": "152180"
  },
  {
    "text": "in these days it seems like many companies when I attend sure floater the",
    "start": "152180",
    "end": "157680"
  },
  {
    "text": "ever-growing technology map and deploying this infrastructure became real hard work a lot of companies",
    "start": "157680",
    "end": "165569"
  },
  {
    "text": "actually based our offering and how well they can actually deploy this detector",
    "start": "165569",
    "end": "170730"
  },
  {
    "text": "Paula this technology map into your organization even where I work at Iguazu",
    "start": "170730",
    "end": "175830"
  },
  {
    "text": "we provide Hadoop compliant api's because we deal with companies that are",
    "start": "175830",
    "end": "180840"
  },
  {
    "text": "required Big Data solution the so called",
    "start": "180840",
    "end": "186360"
  },
  {
    "start": "185000",
    "end": "296000"
  },
  {
    "text": "cloud era didn't change much of what we knew even the major cloud provider had",
    "start": "186360",
    "end": "191549"
  },
  {
    "text": "some alignment with a duplicate system major cloud provider have a dupe",
    "start": "191549",
    "end": "196590"
  },
  {
    "text": "integrated with your services most of an implementation of a dupe compliant api's",
    "start": "196590",
    "end": "202190"
  },
  {
    "text": "if we'll take care for example we take Amazon the leading cloud provider we",
    "start": "202190",
    "end": "208410"
  },
  {
    "text": "have s3 working as a dupe compliant a file system EMR which is elastic Amazon",
    "start": "208410",
    "end": "215820"
  },
  {
    "text": "Elastic MapReduce runs of course spark HBase and yarn and later on they added",
    "start": "215820",
    "end": "221940"
  },
  {
    "text": "of course other capabilities we see and of course you if you have tension flow",
    "start": "221940",
    "end": "228480"
  },
  {
    "text": "Amazon has a pre-configure am i running for you on AWS and we started streaming",
    "start": "228480",
    "end": "236400"
  },
  {
    "text": "stuff through kinases but as you can see nothing really change the hard work of",
    "start": "236400",
    "end": "241950"
  },
  {
    "text": "actually deploying all those tangled technology map replaced by the actual",
    "start": "241950",
    "end": "247470"
  },
  {
    "text": "weaselly of choosing which server less data service you're going to choose and trying to figure out what your invoiced",
    "start": "247470",
    "end": "254609"
  },
  {
    "text": "by the end of the month going to be and no one actually can",
    "start": "254609",
    "end": "260709"
  },
  {
    "text": "the cloud products to the server lacera our data was in the cloud we didn't have",
    "start": "260709",
    "end": "266889"
  },
  {
    "text": "to worry where it was it was simply there or occasionally wasn't and there",
    "start": "266889",
    "end": "275680"
  },
  {
    "text": "were the real major leap was the application less code this is when",
    "start": "275680",
    "end": "280720"
  },
  {
    "text": "lambda was introduced we were promised a simpler to process incoming events we",
    "start": "280720",
    "end": "287380"
  },
  {
    "text": "just code well if you're familiar with lambda this is the promise we got we",
    "start": "287380",
    "end": "293590"
  },
  {
    "text": "actually got something else so let's do",
    "start": "293590",
    "end": "299350"
  },
  {
    "start": "296000",
    "end": "398000"
  },
  {
    "text": "a short recap our data flow has obviously evolved we added so many big",
    "start": "299350",
    "end": "304750"
  },
  {
    "text": "data framework so to our toolbox these frameworks were scheduled with different schedulers spark for example was using",
    "start": "304750",
    "end": "312430"
  },
  {
    "text": "yawn some of them were using mezzos and application sometimes is something",
    "start": "312430",
    "end": "318400"
  },
  {
    "text": "completely else and now with the",
    "start": "318400",
    "end": "323590"
  },
  {
    "text": "introduction of new architecture new analytic tools we need to rethink our ecosystem look it back there are three",
    "start": "323590",
    "end": "331449"
  },
  {
    "text": "engineers we need to really understand their current needs application",
    "start": "331449",
    "end": "336669"
  },
  {
    "text": "engineers want one want what every application engineer wants they want agile development they want to release",
    "start": "336669",
    "end": "343030"
  },
  {
    "text": "as frequent as possible and get the use of feedback as soon as possible data",
    "start": "343030",
    "end": "348820"
  },
  {
    "text": "engineers pretty simple they simply want stuff to keep working they don't care how but keep it working and I have their",
    "start": "348820",
    "end": "356110"
  },
  {
    "text": "data available and the data in a DevOps engineers one their tools to keep work",
    "start": "356110",
    "end": "362349"
  },
  {
    "text": "that the the tools to keep working but have less maintenance they want an",
    "start": "362349",
    "end": "368800"
  },
  {
    "text": "easier way to manage all those services in application and frameworks and they will not manage multiple clusters with",
    "start": "368800",
    "end": "376840"
  },
  {
    "text": "multiple scheduler we we must consolidate thanks to the container",
    "start": "376840",
    "end": "382750"
  },
  {
    "text": "revolution we have an easier way to deploy these scenarios a new ecosystem to walk with our combined toolbox to run",
    "start": "382750",
    "end": "390550"
  },
  {
    "text": "on a single scheduler and since well-read cube con I'm suggesting communities",
    "start": "390550",
    "end": "398139"
  },
  {
    "start": "398000",
    "end": "559000"
  },
  {
    "text": "so let's first review our data we had a guava look at our data as an structures",
    "start": "398139",
    "end": "404690"
  },
  {
    "text": "object store structure store and streaming this is basically how we look",
    "start": "404690",
    "end": "409729"
  },
  {
    "text": "at it at a throughout even if it's cloud or even if you're on Prem this is your",
    "start": "409729",
    "end": "417229"
  },
  {
    "text": "data decoupling the data from our entire system require a shift or in the current mind sent aleko system shall grow from a",
    "start": "417229",
    "end": "424880"
  },
  {
    "text": "dupe mindset of distributing the data itself to distributing its access when",
    "start": "424880",
    "end": "432110"
  },
  {
    "text": "you run in the cloud it allows you to access your data in a distributed fashion think of s3 or dynamo DB or key",
    "start": "432110",
    "end": "440240"
  },
  {
    "text": "Nessus you don't have to worry whether the data is you simply access it from anywhere in any and even if you don't",
    "start": "440240",
    "end": "448669"
  },
  {
    "text": "run in the cloud you can access your data using some services like looks to the fests for objects if you keep your",
    "start": "448669",
    "end": "456320"
  },
  {
    "text": "data in Cassandra you can access it without much problem and your Kafka",
    "start": "456320",
    "end": "461690"
  },
  {
    "text": "cluster can be accessed from anywhere this is what people are actually referring to as cloud native",
    "start": "461690",
    "end": "467600"
  },
  {
    "text": "these are resilient and always accessible data services in between wave",
    "start": "467600",
    "end": "474650"
  },
  {
    "text": "the orchestration kubernetes will schedule application analytics tools of frameworks and manage our entire",
    "start": "474650",
    "end": "481430"
  },
  {
    "text": "configuration when we align everything to a single unified orchestration we",
    "start": "481430",
    "end": "487130"
  },
  {
    "text": "need to adapt the application layer we require the utmost level to be a great",
    "start": "487130",
    "end": "492530"
  },
  {
    "text": "upgraded we can simply run anything on top of our Orchestrator this furthermore",
    "start": "492530",
    "end": "497990"
  },
  {
    "text": "can application must be cloud native they have to use every tool kubernetes has to offer",
    "start": "497990",
    "end": "504039"
  },
  {
    "text": "besides our application big error frameworks we can have leveraged several experiments we can now have our function",
    "start": "504039",
    "end": "510410"
  },
  {
    "text": "service our very own lambda",
    "start": "510410",
    "end": "514779"
  },
  {
    "text": "our big data pipeline massive Ovilus as well and actually it's already has it's",
    "start": "517690",
    "end": "523659"
  },
  {
    "text": "no longer pipeline it's a living system our system and services are constantly",
    "start": "523660",
    "end": "529240"
  },
  {
    "text": "processing in and analyzing data accessing the data simultaneously running function micro services analytic",
    "start": "529240",
    "end": "537490"
  },
  {
    "text": "tools we have daddy data coming in or pulled out for my IT devices external",
    "start": "537490",
    "end": "543910"
  },
  {
    "text": "sources dashboard and many more the entire layer around our data runs on a",
    "start": "543910",
    "end": "549910"
  },
  {
    "text": "unified orchestration data is being accessed from anywhere at any time",
    "start": "549910",
    "end": "556770"
  },
  {
    "start": "559000",
    "end": "708000"
  },
  {
    "text": "another evolution we see when moving to kubernetes is using several aspera mocks",
    "start": "560340",
    "end": "565900"
  },
  {
    "text": "like I've mentioned before the cube lists open fast nucleo this is of course",
    "start": "565900",
    "end": "572650"
  },
  {
    "text": "a blessed move we now know no longer need to worry how to build docker we",
    "start": "572650",
    "end": "579040"
  },
  {
    "text": "don't no longer need to understand how to deploy it how to run it on kubernetes we simply write a code and the function",
    "start": "579040",
    "end": "588090"
  },
  {
    "text": "frameworks will simply deploy it for us it will compile us the code and everything will simply run in you know",
    "start": "588090",
    "end": "595420"
  },
  {
    "text": "in our infrastructure another good benefits a function is",
    "start": "595420",
    "end": "600480"
  },
  {
    "text": "basically you don't have to bind to any specific language your entire stack and",
    "start": "600480",
    "end": "607000"
  },
  {
    "text": "can be polyglot and it's already has but",
    "start": "607000",
    "end": "612010"
  },
  {
    "text": "using several as frameworks is the way but comes with a great price usually it",
    "start": "612010",
    "end": "617110"
  },
  {
    "text": "it comes with the slow performance so slow development cycle and we're almost",
    "start": "617110",
    "end": "622390"
  },
  {
    "text": "limited to HTTP endpoints not really our very own lambda look at all those",
    "start": "622390",
    "end": "631230"
  },
  {
    "text": "several as false we'd aguado decided to build a real real",
    "start": "631230",
    "end": "636490"
  },
  {
    "text": "time service platform nucleo nucleus",
    "start": "636490",
    "end": "642010"
  },
  {
    "text": "platform can have any event source not just HTTP they can be of course combined",
    "start": "642010",
    "end": "649690"
  },
  {
    "text": "you can listen some honestly - Kafka - HTTP - kinases with",
    "start": "649690",
    "end": "655549"
  },
  {
    "text": "the same function code that you wrote this allows you a better debugging",
    "start": "655549",
    "end": "662119"
  },
  {
    "text": "testing and execute execution cycle since we all also run everywhere god not",
    "start": "662119",
    "end": "668209"
  },
  {
    "text": "just kubernetes you can deploy and test everywhere your sole focus is on writing",
    "start": "668209",
    "end": "675679"
  },
  {
    "text": "the code and the rest is taken care of we even provide you with building",
    "start": "675679",
    "end": "682579"
  },
  {
    "text": "metrics and logging this was open-source",
    "start": "682579",
    "end": "690319"
  },
  {
    "text": "recently and you should definitely check it out we also provide now with a",
    "start": "690319",
    "end": "696439"
  },
  {
    "text": "hackathon we should definitely check it out the prize is a very ironed",
    "start": "696439",
    "end": "703009"
  },
  {
    "text": "drone so now you're probably saying okay",
    "start": "703009",
    "end": "712009"
  },
  {
    "start": "708000",
    "end": "838000"
  },
  {
    "text": "I listen to your talk and everything containerized I'm using function I'm",
    "start": "712009",
    "end": "717379"
  },
  {
    "text": "using micro services my Sparky's containerized great but now I have",
    "start": "717379",
    "end": "724869"
  },
  {
    "text": "thousands of containers running on micros traitor and each one of them is",
    "start": "724869",
    "end": "731389"
  },
  {
    "text": "gonna open a connection to my data service it's gonna create a huge load on our system and you're actually right and",
    "start": "731389",
    "end": "740079"
  },
  {
    "text": "when I said we need a cloud native for amongst an application it meant that",
    "start": "740079",
    "end": "745100"
  },
  {
    "text": "some frameworks need to evolve as well at laguardia we are dealing with very",
    "start": "745100",
    "end": "750649"
  },
  {
    "text": "large color clusters and needed a way to optimize data access we build a solution",
    "start": "750649",
    "end": "755989"
  },
  {
    "text": "around shell memory which brings the data directly to our application memory",
    "start": "755989",
    "end": "761059"
  },
  {
    "text": "the solution works closely with kubernetes to allow shared connection fast data access and fast connection",
    "start": "761059",
    "end": "768769"
  },
  {
    "text": "initialization let's take for example spark we created a data frame",
    "start": "768769",
    "end": "777909"
  },
  {
    "text": "implementation that reads from a shared memory populated by our v3l daemon",
    "start": "777909",
    "end": "783009"
  },
  {
    "text": "running on each of the nodes this demon is the sole owner of the",
    "start": "783009",
    "end": "788480"
  },
  {
    "text": "outgoing TCP or are they make connection to the data service now if you are not",
    "start": "788480",
    "end": "796130"
  },
  {
    "text": "running with something native liditz we support like new Cleo spark Hadoop and others we can we also have you this same",
    "start": "796130",
    "end": "805339"
  },
  {
    "text": "solution available as a fuse mount which you can use a flex mount a flex volume",
    "start": "805339",
    "end": "810709"
  },
  {
    "text": "to using kubernetes and read directly video application now",
    "start": "810709",
    "end": "816560"
  },
  {
    "text": "just like with nuclear this entire walk was open-source and you can check out",
    "start": "816560",
    "end": "822050"
  },
  {
    "text": "the solution and work some ways how to to leverage it with your data services",
    "start": "822050",
    "end": "828070"
  },
  {
    "text": "we do hope that other data services will hope will offer such acceleration in the",
    "start": "828070",
    "end": "833930"
  },
  {
    "text": "near future we've talked a lot at how we",
    "start": "833930",
    "end": "841700"
  },
  {
    "start": "838000",
    "end": "912000"
  },
  {
    "text": "need to look at our data application of frameworks which new firm works we need",
    "start": "841700",
    "end": "847640"
  },
  {
    "text": "to add now let's look at our deployments",
    "start": "847640",
    "end": "853149"
  },
  {
    "text": "I'll assume that DevOps had for a minute but remember how hard it was to deploy",
    "start": "853180",
    "end": "858620"
  },
  {
    "text": "and manage a complete clusters let's look at a spark example every aspect of",
    "start": "858620",
    "end": "865370"
  },
  {
    "text": "the system is managed by kubernetes deployment services and even the",
    "start": "865370",
    "end": "870920"
  },
  {
    "text": "configuration itself and config map is not just for flat configuration startup",
    "start": "870920",
    "end": "877880"
  },
  {
    "text": "scripts are easily managing config Maps I know and I will later on demonstrate your IRA can leverage a lot of the tool",
    "start": "877880",
    "end": "884360"
  },
  {
    "text": "in kubernetes has to offer to manage your entire deployments and how much",
    "start": "884360",
    "end": "891079"
  },
  {
    "text": "simpler is using helm versus chef or puppet you don't have to use another language",
    "start": "891079",
    "end": "896510"
  },
  {
    "text": "Yamma which you have to use already because you're unique using kubernetes is being utilized by helm to basically",
    "start": "896510",
    "end": "904370"
  },
  {
    "text": "now describe your deployments",
    "start": "904370",
    "end": "909459"
  },
  {
    "start": "912000",
    "end": "976000"
  },
  {
    "text": "another demo done I'll demonstrate is how our current pipeline looks like you",
    "start": "914020",
    "end": "920750"
  },
  {
    "text": "know plan like I said a current pipeline is a living system the data is simultaneously being accessed for",
    "start": "920750",
    "end": "927260"
  },
  {
    "text": "multiple location at once so I'm taking a real example from one of our customers",
    "start": "927260",
    "end": "933910"
  },
  {
    "text": "this is an IOT automobile company they have their cars",
    "start": "933910",
    "end": "939050"
  },
  {
    "text": "sending information constantly where the driver is some metrics of the cars and",
    "start": "939050",
    "end": "944900"
  },
  {
    "text": "so on and everything is being processed in real time and injected to our data",
    "start": "944900",
    "end": "951440"
  },
  {
    "text": "services and simultaneously there are dashboard showing where the data where",
    "start": "951440",
    "end": "958610"
  },
  {
    "text": "the driver is what are the alerts for that driver and there are also data",
    "start": "958610",
    "end": "964750"
  },
  {
    "text": "engineers trying to run analytics on the same data that just came in everything",
    "start": "964750",
    "end": "971450"
  },
  {
    "text": "is being processed simultaneously so",
    "start": "971450",
    "end": "977540"
  },
  {
    "start": "976000",
    "end": "1238000"
  },
  {
    "text": "let's jump into the demo",
    "start": "977540",
    "end": "981009"
  },
  {
    "text": "okay so what I have here is a completely new kubernetes cluster running in in one",
    "start": "987720",
    "end": "996390"
  },
  {
    "text": "of our data centers I'll help you you",
    "start": "996390",
    "end": "1002000"
  },
  {
    "text": "can see it properly so the first thing",
    "start": "1002000",
    "end": "1007850"
  },
  {
    "text": "I'm gonna do is create a new name space for all for this nuke customer and since",
    "start": "1007850",
    "end": "1016010"
  },
  {
    "text": "I can't show okay I see what I'm typing",
    "start": "1016010",
    "end": "1020590"
  },
  {
    "text": "and of course I'm gonna make a mistake",
    "start": "1022930",
    "end": "1027850"
  },
  {
    "text": "great so we have a new namespace to facilitate this new customer now let's",
    "start": "1032079",
    "end": "1042470"
  },
  {
    "text": "create something that allows that new customer to access its its new namespace",
    "start": "1042470",
    "end": "1048890"
  },
  {
    "text": "I'm gonna do something that it's not something you should do I'm gonna",
    "start": "1048890",
    "end": "1054500"
  },
  {
    "text": "provide it with the option to be a cluster admin usually we provide the",
    "start": "1054500",
    "end": "1060080"
  },
  {
    "text": "option with a friend grade binding but just for the sake of the demo we create",
    "start": "1060080",
    "end": "1066080"
  },
  {
    "text": "a new role binding and now we'll do helm",
    "start": "1066080",
    "end": "1075950"
  },
  {
    "text": "install of our with herald demon okay so",
    "start": "1075950",
    "end": "1082910"
  },
  {
    "text": "what about it's all in the namespace of you cube Khan I'm using the vio demon",
    "start": "1082910",
    "end": "1090170"
  },
  {
    "text": "chart which is available for you to use and pointing to one of our data services",
    "start": "1090170",
    "end": "1098559"
  },
  {
    "text": "once I hit you immediately see it's being deployed and in a few seconds its",
    "start": "1098890",
    "end": "1105860"
  },
  {
    "text": "operational now we're gonna show you",
    "start": "1105860",
    "end": "1111290"
  },
  {
    "text": "what I meant when I used that config Maps Judd not just config maps you can",
    "start": "1111290",
    "end": "1117800"
  },
  {
    "text": "do a lot more",
    "start": "1117800",
    "end": "1120490"
  },
  {
    "text": "can I'm simply gonna describe one of the config naps that I'm using",
    "start": "1127610",
    "end": "1133059"
  },
  {
    "text": "can see Oh second",
    "start": "1137020",
    "end": "1144559"
  },
  {
    "text": "I forgot to update my contacts",
    "start": "1145639",
    "end": "1149799"
  },
  {
    "text": "okay so I'll move just I can see as well",
    "start": "1153120",
    "end": "1158870"
  },
  {
    "text": "what do we have here is raw configuration as a JSON file being saved",
    "start": "1159110",
    "end": "1165720"
  },
  {
    "text": "directly as a config map it's not the usual way to use a config map because",
    "start": "1165720",
    "end": "1173640"
  },
  {
    "text": "usually people tend to use it as a map a key value or simply place it as a file and then map it to the container and I",
    "start": "1173640",
    "end": "1182400"
  },
  {
    "text": "don't think that I I really love doing its the initialization script I also",
    "start": "1182400",
    "end": "1187590"
  },
  {
    "text": "place in a config map it's allowed me to better control which which parameters",
    "start": "1187590",
    "end": "1193830"
  },
  {
    "text": "I'm doing initialization and not by overriding all kind of VM else files now",
    "start": "1193830",
    "end": "1206340"
  },
  {
    "text": "let's add spark again like we did with",
    "start": "1206340",
    "end": "1212790"
  },
  {
    "text": "the vitriol daemon it will simply run in a matter of seconds right very simple",
    "start": "1212790",
    "end": "1219950"
  },
  {
    "text": "now what I'm about to show you is nucleus function service",
    "start": "1219950",
    "end": "1228140"
  },
  {
    "start": "1238000",
    "end": "1363000"
  },
  {
    "text": "okay we have we have a plague a playground for you to actually deploy functions do it'll be simpler to find",
    "start": "1239929",
    "end": "1251360"
  },
  {
    "text": "the mouse I can deploy any pre-loaded",
    "start": "1251360",
    "end": "1257960"
  },
  {
    "text": "function or of course provide with me with my own hit deploy and we'll simply ship to the to the cloud in this case",
    "start": "1257960",
    "end": "1265940"
  },
  {
    "text": "our kubernetes cluster but this is not how you usually want to do stuff you don't want to open another IDE or",
    "start": "1265940",
    "end": "1273049"
  },
  {
    "text": "another another tool you simply want to use either cube CTL or other",
    "start": "1273049",
    "end": "1278990"
  },
  {
    "text": "command-line tools to do it the automation for you so of course we do",
    "start": "1278990",
    "end": "1284029"
  },
  {
    "text": "have an automation tool for you which is our",
    "start": "1284029",
    "end": "1289389"
  },
  {
    "text": "and now I'm going to deploy a function just like you seen in the present in the",
    "start": "1299260",
    "end": "1306190"
  },
  {
    "text": "UI I'm going to deploy a function using",
    "start": "1306190",
    "end": "1311799"
  },
  {
    "text": "our new CTL command line two",
    "start": "1311799",
    "end": "1315600"
  },
  {
    "text": "okay it will build take the code will into",
    "start": "1324730",
    "end": "1332859"
  },
  {
    "text": "container do all kind of tests for it and ship it to a registry that we define",
    "start": "1332859",
    "end": "1339669"
  },
  {
    "text": "entropy running in our communities cluster now I also deploy au weeks a UI",
    "start": "1339669",
    "end": "1350739"
  },
  {
    "text": "for our demo and while we are looking at",
    "start": "1350739",
    "end": "1359169"
  },
  {
    "text": "that deploying",
    "start": "1359169",
    "end": "1362190"
  },
  {
    "start": "1363000",
    "end": "1478000"
  },
  {
    "text": "there's a simple map currently there's no data because we didn't scream anything we just launched the",
    "start": "1364190",
    "end": "1369800"
  },
  {
    "text": "application where well there's a dashboard waiting for data to be streaming so lets streaming some data",
    "start": "1369800",
    "end": "1380050"
  },
  {
    "text": "okay that's it it's just a streaming but the real real",
    "start": "1389100",
    "end": "1400620"
  },
  {
    "text": "issue here is that you will count now the function that I'd recently deployed start to receive the events and",
    "start": "1400620",
    "end": "1407610"
  },
  {
    "text": "populates all the real-time data on the map this is of course with a lot of",
    "start": "1407610",
    "end": "1414360"
  },
  {
    "text": "drivers being hammered into the system but as you can see everything is constantly live during during the",
    "start": "1414360",
    "end": "1422340"
  },
  {
    "text": "presentation now now I have two acts 2 2",
    "start": "1422340",
    "end": "1429870"
  },
  {
    "text": "way of accessing the data one is the function the other is the dashboard and I mentioned also that data engineers",
    "start": "1429870",
    "end": "1436259"
  },
  {
    "text": "might wanna use let's say Zeppelin to run small jobs",
    "start": "1436259",
    "end": "1442429"
  },
  {
    "text": "so let's use a plane and we'll create a",
    "start": "1449360",
    "end": "1455850"
  },
  {
    "text": "simple",
    "start": "1455850",
    "end": "1458299"
  },
  {
    "text": "second",
    "start": "1463690",
    "end": "1466679"
  },
  {
    "text": "it's called cube con and now we'll do a simple spark job just",
    "start": "1474390",
    "end": "1483860"
  },
  {
    "start": "1478000",
    "end": "1544000"
  },
  {
    "text": "just to show you how I can access the data simultaneously as it is it coming",
    "start": "1483860",
    "end": "1489710"
  },
  {
    "text": "in from the function",
    "start": "1489710",
    "end": "1493090"
  },
  {
    "text": "okay have a very very simple job run",
    "start": "1498960",
    "end": "1505080"
  },
  {
    "text": "some analytics and show the results this of course are called styles of spark so it might take a few more",
    "start": "1505080",
    "end": "1512990"
  },
  {
    "text": "seconds but still the data is coming in",
    "start": "1512990",
    "end": "1520050"
  },
  {
    "text": "it's been constantly processed by the function constantly being read by the dashboard and also by spiral job this is",
    "start": "1520050",
    "end": "1528660"
  },
  {
    "text": "what I meant a living system everything is constantly being accessed and we have",
    "start": "1528660",
    "end": "1537120"
  },
  {
    "text": "the help the output of single driver that fits the criteria now during the",
    "start": "1537120",
    "end": "1546900"
  },
  {
    "text": "talk I said it's gonna be easier to run with kubernetes we have much easier",
    "start": "1546900",
    "end": "1553320"
  },
  {
    "text": "deployment and no one actually stopped me and said this is not easier you",
    "start": "1553320",
    "end": "1559950"
  },
  {
    "text": "actually keep running cube city l and you're using new CTL and you're still",
    "start": "1559950",
    "end": "1565590"
  },
  {
    "text": "editing yeah Mel's and init scripts anything and stuff like that and too bad no one interrupted but",
    "start": "1565590",
    "end": "1574280"
  },
  {
    "text": "actually yeah this is not the way to do it this is not the way to deploy this is",
    "start": "1574280",
    "end": "1579440"
  },
  {
    "text": "mimicking the old way of doing bad stuff on your deployments so what you should",
    "start": "1579440",
    "end": "1586740"
  },
  {
    "text": "be doing let's kill the current application I",
    "start": "1586740",
    "end": "1597380"
  },
  {
    "text": "will help to kill everything okay I'm simply going to remove spark demon the",
    "start": "1597980",
    "end": "1608429"
  },
  {
    "text": "function everything that we just installed and I'm about to show you how",
    "start": "1608429",
    "end": "1614039"
  },
  {
    "text": "to really do it",
    "start": "1614039",
    "end": "1616879"
  },
  {
    "text": "nobody kiss right",
    "start": "1621610",
    "end": "1625239"
  },
  {
    "text": "so when I said that we should leverage our tools in the in our toolbox helm is",
    "start": "1631880",
    "end": "1636950"
  },
  {
    "text": "not just for presenting how easy to install with Elm is how to install a complete application with the helm so as",
    "start": "1636950",
    "end": "1645289"
  },
  {
    "text": "a cluster is shutting down what I'm about sure is that nucleo provide you",
    "start": "1645289",
    "end": "1651590"
  },
  {
    "text": "with the Yama Yama is something that is common to communities this is a native",
    "start": "1651590",
    "end": "1657950"
  },
  {
    "text": "vml - kubernetes meaning you can edit it and really pull out the function over and over again through your functions so",
    "start": "1657950",
    "end": "1667900"
  },
  {
    "text": "taking some time but meaning that you can take that yeah Mel and use it in",
    "start": "1667900",
    "end": "1674720"
  },
  {
    "text": "helm using all the templates that help",
    "start": "1674720",
    "end": "1681710"
  },
  {
    "text": "provide and now you can launch everything with a second a single",
    "start": "1681710",
    "end": "1686929"
  },
  {
    "text": "command instead of all the stuff that I just typed in which is I have to stress out it this is the wrong way of using",
    "start": "1686929",
    "end": "1693980"
  },
  {
    "text": "kubernetes okay I hope I went took pictures but this is actually the wrong",
    "start": "1693980",
    "end": "1702020"
  },
  {
    "text": "way of using it so now let's let's see",
    "start": "1702020",
    "end": "1706780"
  },
  {
    "text": "the human doesn't want to die",
    "start": "1707650",
    "end": "1711640"
  },
  {
    "text": "we'll kill it",
    "start": "1713850",
    "end": "1716929"
  },
  {
    "text": "okay so we have a clean cluster and now this is the way to do everything that I",
    "start": "1730270",
    "end": "1736940"
  },
  {
    "text": "just mentioned including the the roll binding including everything that I just",
    "start": "1736940",
    "end": "1742790"
  },
  {
    "text": "mentioned name spacing and everything in a single command this is the proper way",
    "start": "1742790",
    "end": "1748160"
  },
  {
    "text": "this is something that if you're being around the talks of helm and how to use",
    "start": "1748160",
    "end": "1753230"
  },
  {
    "text": "communities in a single command we're",
    "start": "1753230",
    "end": "1760340"
  },
  {
    "text": "gonna deploy our function our demon spark Zeppelin everything did I just",
    "start": "1760340",
    "end": "1772370"
  },
  {
    "text": "show you in like five minutes of work now is a five second a work until",
    "start": "1772370",
    "end": "1779330"
  },
  {
    "text": "everything is running including the new function including spark including",
    "start": "1779330",
    "end": "1784880"
  },
  {
    "text": "Zeppelin and our enhanced demon",
    "start": "1784880",
    "end": "1790690"
  },
  {
    "start": "1801000",
    "end": "2084000"
  },
  {
    "text": "so few tips and lesson learned we we're",
    "start": "1801990",
    "end": "1807000"
  },
  {
    "text": "the guado had along the way the first and foremost rule and I can't stress how",
    "start": "1807000",
    "end": "1814049"
  },
  {
    "text": "important is it should really read the menu and I'm neglecting the effort you",
    "start": "1814049",
    "end": "1821700"
  },
  {
    "text": "should definitely read the manual I've seen too many hacks people are trying to do with kubernetes and and the manual is",
    "start": "1821700",
    "end": "1829940"
  },
  {
    "text": "very comprehensive very easy to follow it's it's sometimes how to follow",
    "start": "1829940",
    "end": "1835740"
  },
  {
    "text": "because it's length but it's not something that you say oh it's very very difficult simply do a copy-paste of",
    "start": "1835740",
    "end": "1842669"
  },
  {
    "text": "commands a lot of the times second is the community community has a great",
    "start": "1842669",
    "end": "1850140"
  },
  {
    "text": "community is not limited to just get up you can find the slack channel you can fight the group's everything within the",
    "start": "1850140",
    "end": "1857279"
  },
  {
    "text": "community is helpful but it come with a special note like when it is the",
    "start": "1857279",
    "end": "1864330"
  },
  {
    "text": "community is young so sometimes you might get help that gonna contradict the",
    "start": "1864330",
    "end": "1872130"
  },
  {
    "text": "manual try to recheck everything that you are getting help to know the tools",
    "start": "1872130",
    "end": "1879149"
  },
  {
    "text": "that kubernetes has to provide during the development of many scenarios for",
    "start": "1879149",
    "end": "1884220"
  },
  {
    "text": "our customers you don't know how much I want how many times I use port forwarding just to check if the pods is",
    "start": "1884220",
    "end": "1890610"
  },
  {
    "text": "doing what I expect it to do the logging collect everything that you have using",
    "start": "1890610",
    "end": "1896669"
  },
  {
    "text": "cube CTL cube CTL is a great tool you should really understand every other option that has available also one of",
    "start": "1896669",
    "end": "1904380"
  },
  {
    "text": "the faults that most people are having in cube CTL is when or not to use the -",
    "start": "1904380",
    "end": "1909630"
  },
  {
    "text": "oh the output because the output of the amyl allows you a lot of times to understand what happened to the service",
    "start": "1909630",
    "end": "1915659"
  },
  {
    "text": "or what happened to the deployment and not all commands except the - all flag",
    "start": "1915659",
    "end": "1921740"
  },
  {
    "text": "and like I showed you always navigate with helm or other solution that you",
    "start": "1921740",
    "end": "1927659"
  },
  {
    "text": "choose with but stick to it helm has great great options great into that",
    "start": "1927659",
    "end": "1935640"
  },
  {
    "text": "great understanding of kubernetes and as you can see once you really understand",
    "start": "1935640",
    "end": "1941010"
  },
  {
    "text": "how to use it our entire application stack was being has been deployed with a single helm command and doing a pretty",
    "start": "1941010",
    "end": "1948960"
  },
  {
    "text": "good handle it's even easier and like I think that Kelsey mentioned don't ever",
    "start": "1948960",
    "end": "1954870"
  },
  {
    "text": "do coop CTL edit don't ever do SSH into our cube CTL exact to edit your",
    "start": "1954870",
    "end": "1963530"
  },
  {
    "text": "containers simply use helm another tip",
    "start": "1963530",
    "end": "1969390"
  },
  {
    "text": "that we when you deal with large cluster and many applications sharing the same",
    "start": "1969390",
    "end": "1975750"
  },
  {
    "text": "cluster is they're not the overused in out port not both it's great when we're",
    "start": "1975750",
    "end": "1980790"
  },
  {
    "text": "doing debugging it really it's great because you now know where to access but",
    "start": "1980790",
    "end": "1985980"
  },
  {
    "text": "if you stick with static node a node ports its meaning that your start having",
    "start": "1985980",
    "end": "1991260"
  },
  {
    "text": "to manage all those node ports use load balancers there are great options within",
    "start": "1991260",
    "end": "1996450"
  },
  {
    "text": "kubernetes now the sixth item might look trivial but configuration must go into",
    "start": "1996450",
    "end": "2003860"
  },
  {
    "text": "config Maps don't try to force them in into all kind of solution that I've seen",
    "start": "2003860",
    "end": "2009740"
  },
  {
    "text": "is loading files from the House passed but someone has to populate that file which everything goes to a config map",
    "start": "2009740",
    "end": "2017390"
  },
  {
    "text": "which very very easy in a specific case",
    "start": "2017390",
    "end": "2022429"
  },
  {
    "text": "to a config map is dealing with the amyl Yamal is very very tricky syntax so when",
    "start": "2022429",
    "end": "2031760"
  },
  {
    "text": "you try to override the command is sometimes end up with resulted you didn't expect so",
    "start": "2031760",
    "end": "2037820"
  },
  {
    "text": "like I've showed you place init script and call them instead of trying to do",
    "start": "2037820",
    "end": "2043400"
  },
  {
    "text": "some wizard deal with the ammo and the last it's not really related just for",
    "start": "2043400",
    "end": "2050060"
  },
  {
    "text": "kubernetes for any deployment large clusters you should really collect operational data and not just collect it",
    "start": "2050060",
    "end": "2057440"
  },
  {
    "text": "if you just collect it you're done nothing with it it doesn't mean anything you can simply shut it down you have to",
    "start": "2057440",
    "end": "2064368"
  },
  {
    "text": "collect it you have to understand it we are big data engineers so we need to understand big data means and if the data is",
    "start": "2064369",
    "end": "2071929"
  },
  {
    "text": "meaningless shut it down thank you if you have any questions",
    "start": "2071929",
    "end": "2079960"
  },
  {
    "text": "[Applause]",
    "start": "2079960",
    "end": "2085848"
  }
]
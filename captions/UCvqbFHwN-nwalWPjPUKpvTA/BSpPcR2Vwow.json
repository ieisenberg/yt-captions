[
  {
    "start": "0",
    "end": "70000"
  },
  {
    "text": "hi i'm amy and i work at google on the",
    "start": "240",
    "end": "2560"
  },
  {
    "text": "cloud platform",
    "start": "2560",
    "end": "4720"
  },
  {
    "text": "in this talk i'll first discuss what",
    "start": "4720",
    "end": "6399"
  },
  {
    "text": "kinds of issues come up when you move",
    "start": "6399",
    "end": "7759"
  },
  {
    "text": "your machine learning workflow from",
    "start": "7759",
    "end": "9120"
  },
  {
    "text": "development to production",
    "start": "9120",
    "end": "10240"
  },
  {
    "text": "and what approaches and design patterns",
    "start": "10240",
    "end": "11840"
  },
  {
    "text": "can help then i'll discuss how kubeflow",
    "start": "11840",
    "end": "14320"
  },
  {
    "text": "pipelines operationalize as many of",
    "start": "14320",
    "end": "15839"
  },
  {
    "text": "these useful patterns",
    "start": "15839",
    "end": "17600"
  },
  {
    "text": "and finally i'll show a couple of",
    "start": "17600",
    "end": "18800"
  },
  {
    "text": "example pipelines that show some of",
    "start": "18800",
    "end": "20320"
  },
  {
    "text": "these patterns in action",
    "start": "20320",
    "end": "23119"
  },
  {
    "text": "so launching the first proof-of-concept",
    "start": "23119",
    "end": "25199"
  },
  {
    "text": "version of a machine learning system",
    "start": "25199",
    "end": "26800"
  },
  {
    "text": "is usually fairly easy but when you try",
    "start": "26800",
    "end": "30080"
  },
  {
    "text": "to productionize and scale out",
    "start": "30080",
    "end": "31920"
  },
  {
    "text": "typically what was built as the",
    "start": "31920",
    "end": "33200"
  },
  {
    "text": "prototype is only a small piece of what",
    "start": "33200",
    "end": "35040"
  },
  {
    "text": "you need to pay attention to",
    "start": "35040",
    "end": "36640"
  },
  {
    "text": "and it can be hard to scale out and keep",
    "start": "36640",
    "end": "38239"
  },
  {
    "text": "your system operating continuously",
    "start": "38239",
    "end": "41280"
  },
  {
    "text": "i should add that i'm using",
    "start": "41280",
    "end": "42320"
  },
  {
    "text": "productionize to indicate making a",
    "start": "42320",
    "end": "43920"
  },
  {
    "text": "system more robust",
    "start": "43920",
    "end": "45039"
  },
  {
    "text": "that doesn't necessarily mean that it",
    "start": "45039",
    "end": "47039"
  },
  {
    "text": "needs to be external phasing",
    "start": "47039",
    "end": "50399"
  },
  {
    "text": "so many of you have probably seen this",
    "start": "50559",
    "end": "51920"
  },
  {
    "text": "graphic before but",
    "start": "51920",
    "end": "53760"
  },
  {
    "text": "i like it so i included it again this is",
    "start": "53760",
    "end": "56320"
  },
  {
    "text": "the common perception when thinking",
    "start": "56320",
    "end": "57840"
  },
  {
    "text": "about a machine learning application",
    "start": "57840",
    "end": "59760"
  },
  {
    "text": "many of us anticipate that the main",
    "start": "59760",
    "end": "61440"
  },
  {
    "text": "challenge is going to be getting the",
    "start": "61440",
    "end": "62719"
  },
  {
    "text": "models working properly and accurately",
    "start": "62719",
    "end": "65600"
  },
  {
    "text": "but the reality is that building the",
    "start": "65600",
    "end": "67200"
  },
  {
    "text": "model is only a small part of what you",
    "start": "67200",
    "end": "68880"
  },
  {
    "text": "need to be paying attention to",
    "start": "68880",
    "end": "72000"
  },
  {
    "start": "70000",
    "end": "130000"
  },
  {
    "text": "so why do things become so much harder",
    "start": "72000",
    "end": "73680"
  },
  {
    "text": "when moving to production",
    "start": "73680",
    "end": "75360"
  },
  {
    "text": "here's an incomplete list of some of the",
    "start": "75360",
    "end": "77040"
  },
  {
    "text": "reasons these are things we hear from",
    "start": "77040",
    "end": "78720"
  },
  {
    "text": "customers",
    "start": "78720",
    "end": "80400"
  },
  {
    "text": "first data cleaning and processing",
    "start": "80400",
    "end": "82080"
  },
  {
    "text": "becomes very hard at scale",
    "start": "82080",
    "end": "84320"
  },
  {
    "text": "dealing with data cleaning it getting it",
    "start": "84320",
    "end": "86000"
  },
  {
    "text": "to where it needs to be feature",
    "start": "86000",
    "end": "87280"
  },
  {
    "text": "engineering et cetera is a large part of",
    "start": "87280",
    "end": "89280"
  },
  {
    "text": "the overall effort required to put an",
    "start": "89280",
    "end": "91439"
  },
  {
    "text": "ml system into production it can also be",
    "start": "91439",
    "end": "94320"
  },
  {
    "text": "hard to scale out training and serving",
    "start": "94320",
    "end": "95920"
  },
  {
    "text": "infrastructure to make sure that your",
    "start": "95920",
    "end": "97439"
  },
  {
    "text": "system has sufficient resources when it",
    "start": "97439",
    "end": "99040"
  },
  {
    "text": "needs them and then it can scale back",
    "start": "99040",
    "end": "100960"
  },
  {
    "text": "down when they're not required",
    "start": "100960",
    "end": "103200"
  },
  {
    "text": "another set of problems can arise from",
    "start": "103200",
    "end": "104799"
  },
  {
    "text": "issues like model or data drift",
    "start": "104799",
    "end": "106880"
  },
  {
    "text": "or training serving sku your production",
    "start": "106880",
    "end": "109360"
  },
  {
    "text": "infrastructure needs to be able to",
    "start": "109360",
    "end": "110799"
  },
  {
    "text": "detect and handle situations where a",
    "start": "110799",
    "end": "112560"
  },
  {
    "text": "model is no longer sufficiently accurate",
    "start": "112560",
    "end": "114720"
  },
  {
    "text": "or new data might indicate model",
    "start": "114720",
    "end": "116240"
  },
  {
    "text": "retraining is necessary",
    "start": "116240",
    "end": "117840"
  },
  {
    "text": "or online prediction data is not",
    "start": "117840",
    "end": "119600"
  },
  {
    "text": "consistent with the feature engineering",
    "start": "119600",
    "end": "121040"
  },
  {
    "text": "done for model training",
    "start": "121040",
    "end": "123280"
  },
  {
    "text": "in a production environment access",
    "start": "123280",
    "end": "124960"
  },
  {
    "text": "control and security become more",
    "start": "124960",
    "end": "126320"
  },
  {
    "text": "important as well",
    "start": "126320",
    "end": "128640"
  },
  {
    "text": "and of course lots more",
    "start": "128640",
    "end": "131840"
  },
  {
    "text": "so let's look at some patterns and",
    "start": "131840",
    "end": "133040"
  },
  {
    "text": "practices that can help address these",
    "start": "133040",
    "end": "134720"
  },
  {
    "text": "problems",
    "start": "134720",
    "end": "135680"
  },
  {
    "text": "here's a high level and incomplete list",
    "start": "135680",
    "end": "139280"
  },
  {
    "text": "first formalize your machine learning",
    "start": "139280",
    "end": "140879"
  },
  {
    "text": "workflows for production move away from",
    "start": "140879",
    "end": "143120"
  },
  {
    "text": "stitched together notebooks or",
    "start": "143120",
    "end": "144400"
  },
  {
    "text": "monolithic scripts",
    "start": "144400",
    "end": "146239"
  },
  {
    "text": "the suggestion will probably come as no",
    "start": "146239",
    "end": "147840"
  },
  {
    "text": "surprise given that i love this talk",
    "start": "147840",
    "end": "150319"
  },
  {
    "text": "equally important your machine learning",
    "start": "150319",
    "end": "151840"
  },
  {
    "text": "workflows should behave in the same way",
    "start": "151840",
    "end": "153440"
  },
  {
    "text": "across environments",
    "start": "153440",
    "end": "154879"
  },
  {
    "text": "workflow execution should also support",
    "start": "154879",
    "end": "156800"
  },
  {
    "text": "burstability that is scale out resources",
    "start": "156800",
    "end": "158959"
  },
  {
    "text": "when needed and scale down when they're",
    "start": "158959",
    "end": "160560"
  },
  {
    "text": "not",
    "start": "160560",
    "end": "162080"
  },
  {
    "text": "designing for composability modularity",
    "start": "162080",
    "end": "164239"
  },
  {
    "text": "and reuse of workflow building blocks",
    "start": "164239",
    "end": "166080"
  },
  {
    "text": "will ensure that you can reliably",
    "start": "166080",
    "end": "167599"
  },
  {
    "text": "reproduce and re-run your workflows",
    "start": "167599",
    "end": "170000"
  },
  {
    "text": "and similarly your infrastructure should",
    "start": "170000",
    "end": "171840"
  },
  {
    "text": "support workflow monitoring versioning",
    "start": "171840",
    "end": "173599"
  },
  {
    "text": "and caching",
    "start": "173599",
    "end": "174640"
  },
  {
    "text": "this typically requires making ml",
    "start": "174640",
    "end": "176800"
  },
  {
    "text": "workflow metadata explicit",
    "start": "176800",
    "end": "179680"
  },
  {
    "text": "the data scientists on your team will",
    "start": "179680",
    "end": "181440"
  },
  {
    "text": "probably be prototyping a notebooks",
    "start": "181440",
    "end": "183599"
  },
  {
    "text": "you need well-defined processes to",
    "start": "183599",
    "end": "185200"
  },
  {
    "text": "capture that work and move it out of",
    "start": "185200",
    "end": "186560"
  },
  {
    "text": "notebooks for production use",
    "start": "186560",
    "end": "189280"
  },
  {
    "text": "mechanisms for supporting collaboration",
    "start": "189280",
    "end": "191200"
  },
  {
    "text": "and role-based access control also",
    "start": "191200",
    "end": "192959"
  },
  {
    "text": "become important",
    "start": "192959",
    "end": "194480"
  },
  {
    "text": "informal methods of providing team",
    "start": "194480",
    "end": "196319"
  },
  {
    "text": "members access to your notebooks etc",
    "start": "196319",
    "end": "198319"
  },
  {
    "text": "won't scale anymore",
    "start": "198319",
    "end": "201200"
  },
  {
    "start": "200000",
    "end": "271000"
  },
  {
    "text": "so that was a useful list but how to",
    "start": "201200",
    "end": "203040"
  },
  {
    "text": "operationalize these patterns and",
    "start": "203040",
    "end": "204400"
  },
  {
    "text": "actually use them",
    "start": "204400",
    "end": "205760"
  },
  {
    "text": "this is where kubeflow pipelines comes",
    "start": "205760",
    "end": "207440"
  },
  {
    "text": "in i'll briefly introduce it and then",
    "start": "207440",
    "end": "209760"
  },
  {
    "text": "talk about how its features and",
    "start": "209760",
    "end": "210959"
  },
  {
    "text": "capabilities support",
    "start": "210959",
    "end": "212000"
  },
  {
    "text": "these patterns and practices then i'll",
    "start": "212000",
    "end": "214080"
  },
  {
    "text": "show a couple of examples",
    "start": "214080",
    "end": "217120"
  },
  {
    "text": "keep flow pipelines as part of the",
    "start": "217360",
    "end": "218640"
  },
  {
    "text": "keepflow project which features in many",
    "start": "218640",
    "end": "220560"
  },
  {
    "text": "of today's talks",
    "start": "220560",
    "end": "221920"
  },
  {
    "text": "it has the goal to make it easy for",
    "start": "221920",
    "end": "223440"
  },
  {
    "text": "everyone to develop deploy and manage",
    "start": "223440",
    "end": "225599"
  },
  {
    "text": "portable",
    "start": "225599",
    "end": "226159"
  },
  {
    "text": "scalable ml everywhere kubeflow",
    "start": "226159",
    "end": "228959"
  },
  {
    "text": "pipelines",
    "start": "228959",
    "end": "229840"
  },
  {
    "text": "which you'll often hear abbreviated as",
    "start": "229840",
    "end": "231440"
  },
  {
    "text": "kfp is a platform for building and",
    "start": "231440",
    "end": "233840"
  },
  {
    "text": "deploying machine learning workflows",
    "start": "233840",
    "end": "235840"
  },
  {
    "text": "it runs on a kubernetes cluster and its",
    "start": "235840",
    "end": "237920"
  },
  {
    "text": "pipeline steps are container based",
    "start": "237920",
    "end": "240080"
  },
  {
    "text": "it can be installed with the rest of",
    "start": "240080",
    "end": "241439"
  },
  {
    "text": "kubeflow or in so-called standalone mode",
    "start": "241439",
    "end": "243599"
  },
  {
    "text": "without the other parts of queue flow",
    "start": "243599",
    "end": "245680"
  },
  {
    "text": "for the examples i'll show later i'll be",
    "start": "245680",
    "end": "247519"
  },
  {
    "text": "using a standalone installation",
    "start": "247519",
    "end": "249439"
  },
  {
    "text": "installed on a gke cluster where gke is",
    "start": "249439",
    "end": "252480"
  },
  {
    "text": "google's hosted kubernetes",
    "start": "252480",
    "end": "255200"
  },
  {
    "text": "hubflow pipelines has a python sdk and",
    "start": "255200",
    "end": "257440"
  },
  {
    "text": "an interactive ui",
    "start": "257440",
    "end": "259040"
  },
  {
    "text": "you'll see both in the examples coming",
    "start": "259040",
    "end": "260639"
  },
  {
    "text": "up",
    "start": "260639",
    "end": "262799"
  },
  {
    "text": "qlow pipeline supports two python sdks",
    "start": "262880",
    "end": "265280"
  },
  {
    "text": "kfp",
    "start": "265280",
    "end": "265919"
  },
  {
    "text": "and tfx in the examples i'll show for",
    "start": "265919",
    "end": "268479"
  },
  {
    "text": "this talk i'll be using the kfp",
    "start": "268479",
    "end": "270320"
  },
  {
    "text": "sdk so back to this question how can",
    "start": "270320",
    "end": "274479"
  },
  {
    "text": "kubeflow pipelines play a part in",
    "start": "274479",
    "end": "276160"
  },
  {
    "text": "operationalizing helpful mlaps design",
    "start": "276160",
    "end": "278240"
  },
  {
    "text": "patterns and practices",
    "start": "278240",
    "end": "280960"
  },
  {
    "text": "first of course q flow pipelines lets",
    "start": "280960",
    "end": "283520"
  },
  {
    "text": "you formalize and automate your machine",
    "start": "283520",
    "end": "285600"
  },
  {
    "text": "learning workflows",
    "start": "285600",
    "end": "287040"
  },
  {
    "text": "you can think of a pipeline's platform",
    "start": "287040",
    "end": "288720"
  },
  {
    "text": "as the backbone of production ml systems",
    "start": "288720",
    "end": "291680"
  },
  {
    "text": "a typical workflow might look like the",
    "start": "291680",
    "end": "293199"
  },
  {
    "text": "one on this slide with experimentation",
    "start": "293199",
    "end": "295199"
  },
  {
    "text": "and prototyping",
    "start": "295199",
    "end": "296000"
  },
  {
    "text": "stages as well as automation of model",
    "start": "296000",
    "end": "298400"
  },
  {
    "text": "eval and",
    "start": "298400",
    "end": "299600"
  },
  {
    "text": "model deployment monitoring and",
    "start": "299600",
    "end": "301039"
  },
  {
    "text": "retraining",
    "start": "301039",
    "end": "302639"
  },
  {
    "text": "by specifying a workflow as a pipeline",
    "start": "302639",
    "end": "304639"
  },
  {
    "text": "rather than building monolithic scripts",
    "start": "304639",
    "end": "306320"
  },
  {
    "text": "or running a series of notebook cells",
    "start": "306320",
    "end": "308479"
  },
  {
    "text": "we can automate track and reproduce the",
    "start": "308479",
    "end": "310560"
  },
  {
    "text": "workflow more easily debug",
    "start": "310560",
    "end": "312080"
  },
  {
    "text": "problems and reuse some parts of a",
    "start": "312080",
    "end": "314160"
  },
  {
    "text": "workflow elsewhere",
    "start": "314160",
    "end": "316560"
  },
  {
    "text": "more is needed though than just workflow",
    "start": "316560",
    "end": "318960"
  },
  {
    "text": "orchestration infrastructure",
    "start": "318960",
    "end": "322319"
  },
  {
    "text": "explicit use of pipeline metadata is",
    "start": "322400",
    "end": "324639"
  },
  {
    "text": "another key to effective ml ops",
    "start": "324639",
    "end": "327280"
  },
  {
    "text": "once we can treat workflow artifacts",
    "start": "327280",
    "end": "329360"
  },
  {
    "text": "things like models and data sets",
    "start": "329360",
    "end": "331360"
  },
  {
    "text": "as first-class citizens with defined",
    "start": "331360",
    "end": "333440"
  },
  {
    "text": "schemas",
    "start": "333440",
    "end": "334400"
  },
  {
    "text": "we can automatically track and reason",
    "start": "334400",
    "end": "336240"
  },
  {
    "text": "about their use cubeflow pipelines",
    "start": "336240",
    "end": "338880"
  },
  {
    "text": "automatically logs to a metadata server",
    "start": "338880",
    "end": "341039"
  },
  {
    "text": "during pipeline execution and this in",
    "start": "341039",
    "end": "343360"
  },
  {
    "text": "turn enables automatic lineage tracking",
    "start": "343360",
    "end": "345759"
  },
  {
    "text": "and supports features like reproduction",
    "start": "345759",
    "end": "347520"
  },
  {
    "text": "of previous pipeline runs",
    "start": "347520",
    "end": "349039"
  },
  {
    "text": "and comparisons across fronts",
    "start": "349039",
    "end": "353120"
  },
  {
    "text": "an ml workflow should also be",
    "start": "353120",
    "end": "354639"
  },
  {
    "text": "reproducible and portable so that it",
    "start": "354639",
    "end": "356479"
  },
  {
    "text": "runs the same way in",
    "start": "356479",
    "end": "357680"
  },
  {
    "text": "different environments here are some of",
    "start": "357680",
    "end": "360479"
  },
  {
    "text": "the ways that kfp helps support that",
    "start": "360479",
    "end": "363199"
  },
  {
    "text": "qflo pipeline steps are container-based",
    "start": "363199",
    "end": "365199"
  },
  {
    "text": "so they'll run the same anywhere",
    "start": "365199",
    "end": "367120"
  },
  {
    "text": "similarly kubeflow pipelines can be",
    "start": "367120",
    "end": "369039"
  },
  {
    "text": "installed anywhere that a kubernetes",
    "start": "369039",
    "end": "370800"
  },
  {
    "text": "cluster can be set up",
    "start": "370800",
    "end": "372240"
  },
  {
    "text": "so this lets keep flow pipelines",
    "start": "372240",
    "end": "373840"
  },
  {
    "text": "leverage kubernetes auto scaling",
    "start": "373840",
    "end": "376240"
  },
  {
    "text": "allows pipeline tasks to create and",
    "start": "376240",
    "end": "378560"
  },
  {
    "text": "manage kubernetes resources",
    "start": "378560",
    "end": "380639"
  },
  {
    "text": "and i'll show an example pipeline that",
    "start": "380639",
    "end": "382240"
  },
  {
    "text": "that takes advantage of that",
    "start": "382240",
    "end": "384160"
  },
  {
    "text": "in just a few moments kfp also allows",
    "start": "384160",
    "end": "387440"
  },
  {
    "text": "pipelines to be versioned so it's clear",
    "start": "387440",
    "end": "389440"
  },
  {
    "text": "which version of a given pipeline",
    "start": "389440",
    "end": "391280"
  },
  {
    "text": "was run when and it automatically logs",
    "start": "391280",
    "end": "393600"
  },
  {
    "text": "metadata and tracks pipeline artifacts",
    "start": "393600",
    "end": "395520"
  },
  {
    "text": "during execution",
    "start": "395520",
    "end": "397759"
  },
  {
    "text": "with kfp it's also straightforward to",
    "start": "397759",
    "end": "399520"
  },
  {
    "text": "clone a pipeline and run it again",
    "start": "399520",
    "end": "401199"
  },
  {
    "text": "or to retry a pipeline kfp supports step",
    "start": "401199",
    "end": "404400"
  },
  {
    "text": "level caching as well",
    "start": "404400",
    "end": "406000"
  },
  {
    "text": "which makes it really straightforward to",
    "start": "406000",
    "end": "407440"
  },
  {
    "text": "experiment with different pipeline",
    "start": "407440",
    "end": "409039"
  },
  {
    "text": "variants or to debug",
    "start": "409039",
    "end": "412240"
  },
  {
    "text": "support for modular design and",
    "start": "413520",
    "end": "415280"
  },
  {
    "text": "composable pipeline building blocks",
    "start": "415280",
    "end": "417039"
  },
  {
    "text": "is also important so that the pipeline",
    "start": "417039",
    "end": "418880"
  },
  {
    "text": "steps can be plug and play support",
    "start": "418880",
    "end": "420639"
  },
  {
    "text": "easier debugging and can be reused and",
    "start": "420639",
    "end": "422800"
  },
  {
    "text": "shared",
    "start": "422800",
    "end": "424319"
  },
  {
    "text": "qflo pipelines allows users to share",
    "start": "424319",
    "end": "426479"
  },
  {
    "text": "components",
    "start": "426479",
    "end": "428080"
  },
  {
    "text": "by components i mean specification of",
    "start": "428080",
    "end": "429680"
  },
  {
    "text": "pipeline steps as well as pipeline",
    "start": "429680",
    "end": "431919"
  },
  {
    "text": "definitions",
    "start": "431919",
    "end": "433039"
  },
  {
    "text": "components can be compiled to yaml",
    "start": "433039",
    "end": "434880"
  },
  {
    "text": "format put under version control and",
    "start": "434880",
    "end": "436720"
  },
  {
    "text": "loaded from their source urls",
    "start": "436720",
    "end": "438560"
  },
  {
    "text": "as i'll show in one of the examples",
    "start": "438560",
    "end": "441759"
  },
  {
    "text": "the kfp sdk also makes it easy to create",
    "start": "441759",
    "end": "444160"
  },
  {
    "text": "pipeline components without needing to",
    "start": "444160",
    "end": "445919"
  },
  {
    "text": "directly use docker",
    "start": "445919",
    "end": "447520"
  },
  {
    "text": "which can be helpful often for data",
    "start": "447520",
    "end": "449440"
  },
  {
    "text": "science teams particularly in the",
    "start": "449440",
    "end": "450880"
  },
  {
    "text": "prototyping phase",
    "start": "450880",
    "end": "452319"
  },
  {
    "text": "i'll show that in an example as well",
    "start": "452319",
    "end": "455520"
  },
  {
    "text": "and while i won't have time to show it",
    "start": "455520",
    "end": "456960"
  },
  {
    "text": "in this talk there's now multi-user",
    "start": "456960",
    "end": "458720"
  },
  {
    "text": "support for kfp when you install it as",
    "start": "458720",
    "end": "460639"
  },
  {
    "text": "part of kubeflow",
    "start": "460639",
    "end": "464879"
  },
  {
    "text": "given that pipeline components are",
    "start": "464879",
    "end": "466479"
  },
  {
    "text": "composable and reusable the next step is",
    "start": "466479",
    "end": "468560"
  },
  {
    "text": "to provide pre-built",
    "start": "468560",
    "end": "469520"
  },
  {
    "text": "building blocks to guide construction of",
    "start": "469520",
    "end": "471280"
  },
  {
    "text": "canonical ml workflows",
    "start": "471280",
    "end": "473039"
  },
  {
    "text": "and reduce the need to build your",
    "start": "473039",
    "end": "475039"
  },
  {
    "text": "workflows from scratch",
    "start": "475039",
    "end": "477280"
  },
  {
    "text": "the tensorflow extended project provides",
    "start": "477280",
    "end": "479360"
  },
  {
    "text": "a number of such components in libraries",
    "start": "479360",
    "end": "481440"
  },
  {
    "text": "and i'll show an example that uses one",
    "start": "481440",
    "end": "484080"
  },
  {
    "text": "in addition",
    "start": "484080",
    "end": "485039"
  },
  {
    "text": "pipeline steps can call out to any",
    "start": "485039",
    "end": "486879"
  },
  {
    "text": "service so we can provide pre-built",
    "start": "486879",
    "end": "488720"
  },
  {
    "text": "components that wrap ml services",
    "start": "488720",
    "end": "491039"
  },
  {
    "text": "there are many sets in the kfp repo and",
    "start": "491039",
    "end": "493440"
  },
  {
    "text": "more being added all the time",
    "start": "493440",
    "end": "496800"
  },
  {
    "text": "it's also important to support processes",
    "start": "497120",
    "end": "498879"
  },
  {
    "text": "for moving from notebook prototyping and",
    "start": "498879",
    "end": "500800"
  },
  {
    "text": "experimentation to production",
    "start": "500800",
    "end": "503120"
  },
  {
    "text": "part of this is the ability to easily",
    "start": "503120",
    "end": "505120"
  },
  {
    "text": "create and run pipelines from a notebook",
    "start": "505120",
    "end": "507680"
  },
  {
    "text": "and one of the examples i'll show how",
    "start": "507680",
    "end": "509280"
  },
  {
    "text": "straightforward it is to do this",
    "start": "509280",
    "end": "511919"
  },
  {
    "text": "there of course more aspects to",
    "start": "511919",
    "end": "513919"
  },
  {
    "text": "converting from notebooks than just",
    "start": "513919",
    "end": "515279"
  },
  {
    "text": "using the sdk in a notebook",
    "start": "515279",
    "end": "517440"
  },
  {
    "text": "for example see the kale talk in this",
    "start": "517440",
    "end": "519360"
  },
  {
    "text": "session",
    "start": "519360",
    "end": "521839"
  },
  {
    "text": "another ml ops pattern relates to",
    "start": "522560",
    "end": "524320"
  },
  {
    "text": "supporting tooling around managing",
    "start": "524320",
    "end": "525839"
  },
  {
    "text": "pipeline runs",
    "start": "525839",
    "end": "527440"
  },
  {
    "text": "one important category is making sense",
    "start": "527440",
    "end": "529519"
  },
  {
    "text": "of execution results",
    "start": "529519",
    "end": "531279"
  },
  {
    "text": "this includes the ability to organize",
    "start": "531279",
    "end": "532959"
  },
  {
    "text": "pipeline runs into semantic groupings",
    "start": "532959",
    "end": "535040"
  },
  {
    "text": "kfp calls them experiments and to easily",
    "start": "535040",
    "end": "537920"
  },
  {
    "text": "compare and visualize results across",
    "start": "537920",
    "end": "539760"
  },
  {
    "text": "runs",
    "start": "539760",
    "end": "541600"
  },
  {
    "text": "kfp components can be designed to output",
    "start": "541600",
    "end": "543760"
  },
  {
    "text": "metadata that renders as visualizations",
    "start": "543760",
    "end": "545760"
  },
  {
    "text": "in the dashboard",
    "start": "545760",
    "end": "547120"
  },
  {
    "text": "and you can spin up a tensorboard server",
    "start": "547120",
    "end": "549040"
  },
  {
    "text": "on right on the cluster by including a",
    "start": "549040",
    "end": "550800"
  },
  {
    "text": "pre-built component",
    "start": "550800",
    "end": "552080"
  },
  {
    "text": "pre-built pipeline step when you build",
    "start": "552080",
    "end": "553920"
  },
  {
    "text": "your pipeline i'll show that in one of",
    "start": "553920",
    "end": "555839"
  },
  {
    "text": "my examples",
    "start": "555839",
    "end": "557760"
  },
  {
    "text": "another important tooling category is",
    "start": "557760",
    "end": "559600"
  },
  {
    "text": "cicd for example when pipelining",
    "start": "559600",
    "end": "562560"
  },
  {
    "text": "and components are changed new versions",
    "start": "562560",
    "end": "565040"
  },
  {
    "text": "are automatically built",
    "start": "565040",
    "end": "566080"
  },
  {
    "text": "and tests are run i won't have time to",
    "start": "566080",
    "end": "569120"
  },
  {
    "text": "cover that in this talk but there are",
    "start": "569120",
    "end": "570320"
  },
  {
    "text": "some",
    "start": "570320",
    "end": "570640"
  },
  {
    "text": "examples online and another talk in this",
    "start": "570640",
    "end": "572560"
  },
  {
    "text": "session we'll delve into this in more",
    "start": "572560",
    "end": "574480"
  },
  {
    "text": "detail i believe",
    "start": "574480",
    "end": "577839"
  },
  {
    "start": "577000",
    "end": "871000"
  },
  {
    "text": "so now let's take a brief look at a",
    "start": "578560",
    "end": "580160"
  },
  {
    "text": "couple of kfp pipelines that support",
    "start": "580160",
    "end": "582000"
  },
  {
    "text": "some of the design patterns i've been",
    "start": "582000",
    "end": "583440"
  },
  {
    "text": "showing",
    "start": "583440",
    "end": "584880"
  },
  {
    "text": "both of these examples use the same data",
    "start": "584880",
    "end": "586959"
  },
  {
    "text": "set which is a log",
    "start": "586959",
    "end": "588560"
  },
  {
    "text": "of a few years worth of london bike",
    "start": "588560",
    "end": "590800"
  },
  {
    "text": "rental data",
    "start": "590800",
    "end": "591920"
  },
  {
    "text": "combined with information about the",
    "start": "591920",
    "end": "593360"
  },
  {
    "text": "local weather on each day",
    "start": "593360",
    "end": "595600"
  },
  {
    "text": "the machine learning task in both cases",
    "start": "595600",
    "end": "597440"
  },
  {
    "text": "will be to train a keras model to",
    "start": "597440",
    "end": "599200"
  },
  {
    "text": "predict",
    "start": "599200",
    "end": "600080"
  },
  {
    "text": "rental duration the model details aren't",
    "start": "600080",
    "end": "602640"
  },
  {
    "text": "important for this talk though",
    "start": "602640",
    "end": "605360"
  },
  {
    "text": "for both example pipelines i'll be using",
    "start": "605360",
    "end": "607120"
  },
  {
    "text": "a so-called standalone installation of",
    "start": "607120",
    "end": "608959"
  },
  {
    "text": "kubeflow pipelines",
    "start": "608959",
    "end": "610320"
  },
  {
    "text": "running on a gke cluster where gke is",
    "start": "610320",
    "end": "613920"
  },
  {
    "text": "google's hosted kubernetes",
    "start": "613920",
    "end": "616640"
  },
  {
    "text": "i'll first show an example that",
    "start": "616640",
    "end": "617839"
  },
  {
    "text": "highlights some of the ways that a",
    "start": "617839",
    "end": "619040"
  },
  {
    "text": "kubeflow pipeline can leverage its",
    "start": "619040",
    "end": "620720"
  },
  {
    "text": "underlying kubernetes cluster",
    "start": "620720",
    "end": "622800"
  },
  {
    "text": "this pipeline uses the keras tuner to do",
    "start": "622800",
    "end": "624959"
  },
  {
    "text": "hyper-parameter tuning",
    "start": "624959",
    "end": "626480"
  },
  {
    "text": "and uses the tuner's distributed mode to",
    "start": "626480",
    "end": "628640"
  },
  {
    "text": "let the workers run concurrently on the",
    "start": "628640",
    "end": "630240"
  },
  {
    "text": "cluster",
    "start": "630240",
    "end": "631120"
  },
  {
    "text": "setting up each tuner worker as a",
    "start": "631120",
    "end": "632800"
  },
  {
    "text": "kubernetes job and of course the cluster",
    "start": "632800",
    "end": "635040"
  },
  {
    "text": "will auto scale as needed to support the",
    "start": "635040",
    "end": "636959"
  },
  {
    "text": "number of",
    "start": "636959",
    "end": "637519"
  },
  {
    "text": "tuner workers specified so this is what",
    "start": "637519",
    "end": "640959"
  },
  {
    "text": "the graph for the",
    "start": "640959",
    "end": "641839"
  },
  {
    "text": "this pipeline looks like pipeline's",
    "start": "641839",
    "end": "643920"
  },
  {
    "text": "using a pre-built component",
    "start": "643920",
    "end": "645680"
  },
  {
    "text": "to spin up a tensorboard server on the",
    "start": "645680",
    "end": "648399"
  },
  {
    "text": "same cluster",
    "start": "648399",
    "end": "649440"
  },
  {
    "text": "and then the k-tune step launches the",
    "start": "649440",
    "end": "651279"
  },
  {
    "text": "tuner workers and",
    "start": "651279",
    "end": "653360"
  },
  {
    "text": "controller as kubernetes jobs to do the",
    "start": "653360",
    "end": "655200"
  },
  {
    "text": "hyper-parameter search",
    "start": "655200",
    "end": "656720"
  },
  {
    "text": "and when they're all finished returns",
    "start": "656720",
    "end": "658480"
  },
  {
    "text": "the n-best parameter sets",
    "start": "658480",
    "end": "660959"
  },
  {
    "text": "once the tuning search is completed the",
    "start": "660959",
    "end": "662880"
  },
  {
    "text": "pipeline trains end full models using",
    "start": "662880",
    "end": "664959"
  },
  {
    "text": "the best parameter sets",
    "start": "664959",
    "end": "666640"
  },
  {
    "text": "change them in parallel using the keep",
    "start": "666640",
    "end": "668640"
  },
  {
    "text": "flow pipeline's loop structure",
    "start": "668640",
    "end": "671120"
  },
  {
    "text": "and while they're training we can use",
    "start": "671120",
    "end": "673680"
  },
  {
    "text": "the tensorboard server to monitor the",
    "start": "673680",
    "end": "675440"
  },
  {
    "text": "training runs",
    "start": "675440",
    "end": "676800"
  },
  {
    "text": "after training each full model is",
    "start": "676800",
    "end": "678560"
  },
  {
    "text": "evaluated and if it is",
    "start": "678560",
    "end": "680320"
  },
  {
    "text": "of sufficient accuracy and it's a",
    "start": "680320",
    "end": "682959"
  },
  {
    "text": "condition check here it's deployed",
    "start": "682959",
    "end": "685920"
  },
  {
    "text": "the models are deployed using tensorflow",
    "start": "685920",
    "end": "687839"
  },
  {
    "text": "serving where the tf serving services",
    "start": "687839",
    "end": "689920"
  },
  {
    "text": "are also spun up on the same cluster",
    "start": "689920",
    "end": "692320"
  },
  {
    "text": "so we're using the kubernetes cluster",
    "start": "692320",
    "end": "693760"
  },
  {
    "text": "not only to run the pipeline",
    "start": "693760",
    "end": "695519"
  },
  {
    "text": "but to launch jobs to perform a",
    "start": "695519",
    "end": "697120"
  },
  {
    "text": "distributed hyperparameter search",
    "start": "697120",
    "end": "699760"
  },
  {
    "text": "to use tensorflow serving to serve",
    "start": "699760",
    "end": "701440"
  },
  {
    "text": "models and to run a tensorboard server",
    "start": "701440",
    "end": "704160"
  },
  {
    "text": "and of course the cluster will auto",
    "start": "704160",
    "end": "705600"
  },
  {
    "text": "scale when we need it to if we want to",
    "start": "705600",
    "end": "707680"
  },
  {
    "text": "use more keras tuner workers or train",
    "start": "707680",
    "end": "709839"
  },
  {
    "text": "more models concurrently",
    "start": "709839",
    "end": "712320"
  },
  {
    "text": "so now let's see what it looks like to",
    "start": "712320",
    "end": "713680"
  },
  {
    "text": "upload and run a new version of the",
    "start": "713680",
    "end": "715519"
  },
  {
    "text": "pipeline",
    "start": "715519",
    "end": "717600"
  },
  {
    "text": "i'll click on upload version to upload a",
    "start": "717600",
    "end": "719760"
  },
  {
    "text": "compiled pipeline archive file",
    "start": "719760",
    "end": "722320"
  },
  {
    "text": "in the next example we'll see what the",
    "start": "722320",
    "end": "723920"
  },
  {
    "text": "pipeline specification looks like",
    "start": "723920",
    "end": "726800"
  },
  {
    "text": "by uploading new versions of a given",
    "start": "726800",
    "end": "728720"
  },
  {
    "text": "pipeline rather than just creating a new",
    "start": "728720",
    "end": "730480"
  },
  {
    "text": "pipeline",
    "start": "730480",
    "end": "731440"
  },
  {
    "text": "it lets me track and group related",
    "start": "731440",
    "end": "733040"
  },
  {
    "text": "pipelines in their runs",
    "start": "733040",
    "end": "734800"
  },
  {
    "text": "then i'll click create experiment to run",
    "start": "734800",
    "end": "736639"
  },
  {
    "text": "this pipeline under the grouping of a",
    "start": "736639",
    "end": "738320"
  },
  {
    "text": "given experiment",
    "start": "738320",
    "end": "739600"
  },
  {
    "text": "so this lets me semantically organize",
    "start": "739600",
    "end": "741680"
  },
  {
    "text": "the pipeline runs then",
    "start": "741680",
    "end": "744240"
  },
  {
    "text": "in the start or run page i'll enter the",
    "start": "744240",
    "end": "746000"
  },
  {
    "text": "pipeline run parameters",
    "start": "746000",
    "end": "748000"
  },
  {
    "text": "some have default values i'll keep and",
    "start": "748000",
    "end": "750000"
  },
  {
    "text": "others i will change",
    "start": "750000",
    "end": "751760"
  },
  {
    "text": "while i'm not showing it here i can also",
    "start": "751760",
    "end": "753600"
  },
  {
    "text": "clone or retry an existing pipeline run",
    "start": "753600",
    "end": "757839"
  },
  {
    "text": "thing i'll do is specify to train full",
    "start": "757839",
    "end": "760079"
  },
  {
    "text": "models using the best three parameter",
    "start": "760079",
    "end": "762240"
  },
  {
    "text": "sets returned from the keras tuner",
    "start": "762240",
    "end": "764240"
  },
  {
    "text": "the default is to train the best two",
    "start": "764240",
    "end": "766320"
  },
  {
    "text": "which gives the pipeline graph shown in",
    "start": "766320",
    "end": "768240"
  },
  {
    "text": "the top image",
    "start": "768240",
    "end": "769120"
  },
  {
    "text": "and when i change it to three i'll get",
    "start": "769120",
    "end": "770720"
  },
  {
    "text": "the pipeline graph shown in the bottom",
    "start": "770720",
    "end": "772240"
  },
  {
    "text": "image",
    "start": "772240",
    "end": "773440"
  },
  {
    "text": "this is made possible by using the",
    "start": "773440",
    "end": "775040"
  },
  {
    "text": "pipeline so-called parallel 4",
    "start": "775040",
    "end": "777760"
  },
  {
    "text": "construct to launch n training jobs in",
    "start": "777760",
    "end": "780880"
  },
  {
    "text": "parallel",
    "start": "780880",
    "end": "782320"
  },
  {
    "text": "because i've configured my cluster to",
    "start": "782320",
    "end": "783839"
  },
  {
    "text": "support auto scaling i can change both",
    "start": "783839",
    "end": "786160"
  },
  {
    "text": "the number of keras tuner workers",
    "start": "786160",
    "end": "788160"
  },
  {
    "text": "or the number of concurrent training",
    "start": "788160",
    "end": "789680"
  },
  {
    "text": "jobs and let the cluster scale out when",
    "start": "789680",
    "end": "791920"
  },
  {
    "text": "it needs to",
    "start": "791920",
    "end": "794560"
  },
  {
    "text": "next i'll start the run note that one of",
    "start": "795120",
    "end": "797200"
  },
  {
    "text": "the steps is configuring a tensorboard",
    "start": "797200",
    "end": "799279"
  },
  {
    "text": "server that will run on the cluster",
    "start": "799279",
    "end": "801680"
  },
  {
    "text": "the k-tune step manages and coordinates",
    "start": "801680",
    "end": "804560"
  },
  {
    "text": "the keras tuner workers which are",
    "start": "804560",
    "end": "806320"
  },
  {
    "text": "kubernetes jobs",
    "start": "806320",
    "end": "808720"
  },
  {
    "text": "while the tuner workers are running we",
    "start": "808720",
    "end": "810480"
  },
  {
    "text": "can see them in the gke dashboard",
    "start": "810480",
    "end": "814079"
  },
  {
    "text": "the k-tune step waits for the workers to",
    "start": "814079",
    "end": "816160"
  },
  {
    "text": "complete all their trials",
    "start": "816160",
    "end": "817760"
  },
  {
    "text": "and outputs the top and best results and",
    "start": "817760",
    "end": "820800"
  },
  {
    "text": "in this case we requested the top three",
    "start": "820800",
    "end": "823440"
  },
  {
    "text": "then a full training job is launched for",
    "start": "823440",
    "end": "825440"
  },
  {
    "text": "each of the best parameter sets",
    "start": "825440",
    "end": "829600"
  },
  {
    "text": "while the trending jobs are running or",
    "start": "829600",
    "end": "831440"
  },
  {
    "text": "after they've completed",
    "start": "831440",
    "end": "832639"
  },
  {
    "text": "we can launch the created tensorboard",
    "start": "832639",
    "end": "834560"
  },
  {
    "text": "server which we've configured to include",
    "start": "834560",
    "end": "836720"
  },
  {
    "text": "all three of the full training runs this",
    "start": "836720",
    "end": "839680"
  },
  {
    "text": "lets us monitor model graph and metrics",
    "start": "839680",
    "end": "841839"
  },
  {
    "text": "data",
    "start": "841839",
    "end": "842320"
  },
  {
    "text": "and and lots more",
    "start": "842320",
    "end": "845279"
  },
  {
    "text": "it looks like set zero of the three",
    "start": "846160",
    "end": "848079"
  },
  {
    "text": "parameter sets is the best one",
    "start": "848079",
    "end": "850959"
  },
  {
    "text": "and it looks like perhaps we overtrain",
    "start": "850959",
    "end": "852639"
  },
  {
    "text": "the models as well",
    "start": "852639",
    "end": "855279"
  },
  {
    "text": "we can look at the outputs of the k-tune",
    "start": "855279",
    "end": "857360"
  },
  {
    "text": "step and the pipeline graph",
    "start": "857360",
    "end": "859680"
  },
  {
    "text": "to see which parameter set was used and",
    "start": "859680",
    "end": "862480"
  },
  {
    "text": "this information has been preserved in",
    "start": "862480",
    "end": "864480"
  },
  {
    "text": "google cloud storage as well",
    "start": "864480",
    "end": "871839"
  },
  {
    "start": "871000",
    "end": "1191000"
  },
  {
    "text": "for my second example i'll walk through",
    "start": "872240",
    "end": "874160"
  },
  {
    "text": "parts of this notebook",
    "start": "874160",
    "end": "875519"
  },
  {
    "text": "this example builds on the training and",
    "start": "875519",
    "end": "877360"
  },
  {
    "text": "serving components used in the first",
    "start": "877360",
    "end": "879040"
  },
  {
    "text": "example",
    "start": "879040",
    "end": "879600"
  },
  {
    "text": "and add some additional ones it shows",
    "start": "879600",
    "end": "882000"
  },
  {
    "text": "how to use the tfx tensorflow validation",
    "start": "882000",
    "end": "884480"
  },
  {
    "text": "libraries",
    "start": "884480",
    "end": "885920"
  },
  {
    "text": "often abbreviated as tftv to detect data",
    "start": "885920",
    "end": "889440"
  },
  {
    "text": "drift",
    "start": "889440",
    "end": "889920"
  },
  {
    "text": "between different versions of a data set",
    "start": "889920",
    "end": "892160"
  },
  {
    "text": "if drift is over a given threshold the",
    "start": "892160",
    "end": "894079"
  },
  {
    "text": "model is retrained",
    "start": "894079",
    "end": "896160"
  },
  {
    "text": "this is a two-step process first",
    "start": "896160",
    "end": "898079"
  },
  {
    "text": "statistical information needs to be",
    "start": "898079",
    "end": "899680"
  },
  {
    "text": "generated for both the old and new data",
    "start": "899680",
    "end": "901360"
  },
  {
    "text": "set",
    "start": "901360",
    "end": "901760"
  },
  {
    "text": "then the stats need to be analyzed we'll",
    "start": "901760",
    "end": "904160"
  },
  {
    "text": "build these in the notebook as two",
    "start": "904160",
    "end": "905440"
  },
  {
    "text": "different pipeline components",
    "start": "905440",
    "end": "907199"
  },
  {
    "text": "both using the tftb library then we'll",
    "start": "907199",
    "end": "910000"
  },
  {
    "text": "build a new pipeline that uses these",
    "start": "910000",
    "end": "911600"
  },
  {
    "text": "components plus the training and serving",
    "start": "911600",
    "end": "913519"
  },
  {
    "text": "components from the previous example",
    "start": "913519",
    "end": "916240"
  },
  {
    "text": "while i won't have time to cover it the",
    "start": "916240",
    "end": "917680"
  },
  {
    "text": "notebook also shows how to set up event",
    "start": "917680",
    "end": "919600"
  },
  {
    "text": "triggered pipeline runs",
    "start": "919600",
    "end": "921440"
  },
  {
    "text": "i'll share a link to the notebook at the",
    "start": "921440",
    "end": "922800"
  },
  {
    "text": "end of this talk",
    "start": "922800",
    "end": "925519"
  },
  {
    "text": "i've done some setup already so let's",
    "start": "925680",
    "end": "927519"
  },
  {
    "text": "skip to building the new components",
    "start": "927519",
    "end": "929519"
  },
  {
    "text": "i'm going to create python function",
    "start": "929519",
    "end": "930880"
  },
  {
    "text": "based components i'll define a function",
    "start": "930880",
    "end": "932720"
  },
  {
    "text": "that implements each pipeline step",
    "start": "932720",
    "end": "934320"
  },
  {
    "text": "then convert it to a component the first",
    "start": "934320",
    "end": "936800"
  },
  {
    "text": "function generates the stats for a data",
    "start": "936800",
    "end": "938639"
  },
  {
    "text": "set",
    "start": "938639",
    "end": "939279"
  },
  {
    "text": "the function returns a string that holds",
    "start": "939279",
    "end": "941040"
  },
  {
    "text": "the path to the generated stats info",
    "start": "941040",
    "end": "943360"
  },
  {
    "text": "when the function is compiled to a",
    "start": "943360",
    "end": "944720"
  },
  {
    "text": "component it will have an output called",
    "start": "944720",
    "end": "946240"
  },
  {
    "text": "statspath",
    "start": "946240",
    "end": "947199"
  },
  {
    "text": "that other components can consume as",
    "start": "947199",
    "end": "948880"
  },
  {
    "text": "input we'll see this in a minute",
    "start": "948880",
    "end": "950880"
  },
  {
    "text": "the given dataset is large it can be",
    "start": "950880",
    "end": "952560"
  },
  {
    "text": "hard to do this analysis",
    "start": "952560",
    "end": "954079"
  },
  {
    "text": "in memory the function allows the option",
    "start": "954079",
    "end": "956000"
  },
  {
    "text": "to launch the analysis",
    "start": "956000",
    "end": "957199"
  },
  {
    "text": "as a cloud dataflow job dataflow is",
    "start": "957199",
    "end": "959519"
  },
  {
    "text": "google's hosted apache beam",
    "start": "959519",
    "end": "961199"
  },
  {
    "text": "if it needs to scale out this is a good",
    "start": "961199",
    "end": "963279"
  },
  {
    "text": "example of using pipelines to",
    "start": "963279",
    "end": "964639"
  },
  {
    "text": "orchestrate calls to other cloud",
    "start": "964639",
    "end": "966079"
  },
  {
    "text": "services",
    "start": "966079",
    "end": "967519"
  },
  {
    "text": "now i'll convert this function to a",
    "start": "967519",
    "end": "968880"
  },
  {
    "text": "pipeline component when i do this",
    "start": "968880",
    "end": "970720"
  },
  {
    "text": "i need to specify the base container",
    "start": "970720",
    "end": "972480"
  },
  {
    "text": "image to use",
    "start": "972480",
    "end": "973920"
  },
  {
    "text": "default is a python 3.7 image but i'll",
    "start": "973920",
    "end": "976800"
  },
  {
    "text": "use one that already installs the tftv",
    "start": "976800",
    "end": "978720"
  },
  {
    "text": "libraries to save time",
    "start": "978720",
    "end": "980639"
  },
  {
    "text": "as part of the process i'm generating a",
    "start": "980639",
    "end": "982399"
  },
  {
    "text": "component yaml file",
    "start": "982399",
    "end": "983920"
  },
  {
    "text": "this can be put under version control",
    "start": "983920",
    "end": "985680"
  },
  {
    "text": "and shared with others",
    "start": "985680",
    "end": "988639"
  },
  {
    "text": "now i'll do the same for the second new",
    "start": "988959",
    "end": "990639"
  },
  {
    "text": "component it also uses the tfdv library",
    "start": "990639",
    "end": "993920"
  },
  {
    "text": "compares two stats files it returns a",
    "start": "993920",
    "end": "996480"
  },
  {
    "text": "value indicating whether there was an",
    "start": "996480",
    "end": "998399"
  },
  {
    "text": "anomaly over the given threshold",
    "start": "998399",
    "end": "1002160"
  },
  {
    "text": "now that i have two new components i'll",
    "start": "1002800",
    "end": "1004880"
  },
  {
    "text": "build a pipeline that uses them",
    "start": "1004880",
    "end": "1006639"
  },
  {
    "text": "using the kfp sdk in addition to the new",
    "start": "1006639",
    "end": "1010079"
  },
  {
    "text": "components",
    "start": "1010079",
    "end": "1011120"
  },
  {
    "text": "i'm defining pipeline ops from four",
    "start": "1011120",
    "end": "1013600"
  },
  {
    "text": "pre-built components",
    "start": "1013600",
    "end": "1015120"
  },
  {
    "text": "the tensorboard component i mentioned",
    "start": "1015120",
    "end": "1016880"
  },
  {
    "text": "earlier that spins up a tensorboard",
    "start": "1016880",
    "end": "1019040"
  },
  {
    "text": "server on the cluster",
    "start": "1019040",
    "end": "1020560"
  },
  {
    "text": "and the training serving and model eval",
    "start": "1020560",
    "end": "1023040"
  },
  {
    "text": "components from the previous example",
    "start": "1023040",
    "end": "1025839"
  },
  {
    "text": "these are all checked into github and i",
    "start": "1025839",
    "end": "1027918"
  },
  {
    "text": "can load them from their urls",
    "start": "1027919",
    "end": "1030160"
  },
  {
    "text": "note that i need to use the raw urls",
    "start": "1030160",
    "end": "1034240"
  },
  {
    "text": "we'll use the tftv op twice for both the",
    "start": "1035439",
    "end": "1038160"
  },
  {
    "text": "training and test data set",
    "start": "1038160",
    "end": "1040000"
  },
  {
    "text": "then the tftv drip drift step takes as",
    "start": "1040000",
    "end": "1043038"
  },
  {
    "text": "input the stats generated by the tftp",
    "start": "1043039",
    "end": "1045438"
  },
  {
    "text": "step run on the training data if",
    "start": "1045439",
    "end": "1048000"
  },
  {
    "text": "sufficient drift is detected",
    "start": "1048000",
    "end": "1049679"
  },
  {
    "text": "this is the conditional expression we'll",
    "start": "1049679",
    "end": "1052000"
  },
  {
    "text": "retrain the model on the new data",
    "start": "1052000",
    "end": "1054160"
  },
  {
    "text": "then a model eval step determines",
    "start": "1054160",
    "end": "1056559"
  },
  {
    "text": "whether the accuracy of the new model is",
    "start": "1056559",
    "end": "1058240"
  },
  {
    "text": "sufficiently good",
    "start": "1058240",
    "end": "1059440"
  },
  {
    "text": "and if it is that's the second",
    "start": "1059440",
    "end": "1061120"
  },
  {
    "text": "conditional the model is deployed using",
    "start": "1061120",
    "end": "1063600"
  },
  {
    "text": "tensorflow serving",
    "start": "1063600",
    "end": "1065280"
  },
  {
    "text": "the last line of this pipeline",
    "start": "1065280",
    "end": "1066720"
  },
  {
    "text": "definition indicates that the training",
    "start": "1066720",
    "end": "1068480"
  },
  {
    "text": "step should run on a gpu-enabled node in",
    "start": "1068480",
    "end": "1071039"
  },
  {
    "text": "your cluster",
    "start": "1071039",
    "end": "1073679"
  },
  {
    "text": "now we're ready to compile and run the",
    "start": "1074160",
    "end": "1075760"
  },
  {
    "text": "pipeline after we compile it",
    "start": "1075760",
    "end": "1077840"
  },
  {
    "text": "we need to instantiate a client object",
    "start": "1077840",
    "end": "1080080"
  },
  {
    "text": "using the url of the kfp installation",
    "start": "1080080",
    "end": "1083120"
  },
  {
    "text": "then we'll first create an experiment",
    "start": "1083120",
    "end": "1084799"
  },
  {
    "text": "under which to run the pipeline",
    "start": "1084799",
    "end": "1087200"
  },
  {
    "text": "next we'll upload the pipeline get its",
    "start": "1087200",
    "end": "1089919"
  },
  {
    "text": "id and then launch a pipeline run",
    "start": "1089919",
    "end": "1092400"
  },
  {
    "text": "you can also combine the upload and run",
    "start": "1092400",
    "end": "1094960"
  },
  {
    "text": "as a single call if you like",
    "start": "1094960",
    "end": "1097600"
  },
  {
    "text": "when we run the pipeline we can pass it",
    "start": "1097600",
    "end": "1099520"
  },
  {
    "text": "the input arguments to use",
    "start": "1099520",
    "end": "1101679"
  },
  {
    "text": "once the run is launched we can view it",
    "start": "1101679",
    "end": "1103520"
  },
  {
    "text": "in the kubeflow pipelines dashboard",
    "start": "1103520",
    "end": "1107200"
  },
  {
    "text": "then several hours later the result",
    "start": "1107360",
    "end": "1110320"
  },
  {
    "text": "looks like this",
    "start": "1110320",
    "end": "1111520"
  },
  {
    "text": "in the case where we do detect drift",
    "start": "1111520",
    "end": "1113440"
  },
  {
    "text": "between the old new data sets",
    "start": "1113440",
    "end": "1115280"
  },
  {
    "text": "and decide to retrain the model in the",
    "start": "1115280",
    "end": "1117760"
  },
  {
    "text": "serving step",
    "start": "1117760",
    "end": "1118480"
  },
  {
    "text": "you can see a listing of the yaml used",
    "start": "1118480",
    "end": "1120400"
  },
  {
    "text": "to spawn off the tf serving",
    "start": "1120400",
    "end": "1122000"
  },
  {
    "text": "deployment service",
    "start": "1122000",
    "end": "1125039"
  },
  {
    "text": "so in this talk i discussed some of the",
    "start": "1130160",
    "end": "1132400"
  },
  {
    "text": "problems that can arise when you're",
    "start": "1132400",
    "end": "1133840"
  },
  {
    "text": "trying to move a machine learning",
    "start": "1133840",
    "end": "1135039"
  },
  {
    "text": "workflow from development to production",
    "start": "1135039",
    "end": "1138160"
  },
  {
    "text": "i showed some mlaps patterns that can",
    "start": "1138160",
    "end": "1140080"
  },
  {
    "text": "help and talked about how kubeflow",
    "start": "1140080",
    "end": "1142160"
  },
  {
    "text": "pipelines",
    "start": "1142160",
    "end": "1143200"
  },
  {
    "text": "helps operationalize these patterns and",
    "start": "1143200",
    "end": "1145120"
  },
  {
    "text": "practices",
    "start": "1145120",
    "end": "1147280"
  },
  {
    "text": "you can think of the capabilities",
    "start": "1147280",
    "end": "1148960"
  },
  {
    "text": "provided by kubeflow pipelines is",
    "start": "1148960",
    "end": "1150799"
  },
  {
    "text": "largely falling into three buckets",
    "start": "1150799",
    "end": "1153600"
  },
  {
    "text": "ml workflow orchestration share reuse",
    "start": "1153600",
    "end": "1157120"
  },
  {
    "text": "and compose",
    "start": "1157120",
    "end": "1158160"
  },
  {
    "text": "components and pipelines and then run",
    "start": "1158160",
    "end": "1160400"
  },
  {
    "text": "them across multiple clouds",
    "start": "1160400",
    "end": "1162000"
  },
  {
    "text": "on-prem anywhere that",
    "start": "1162000",
    "end": "1165039"
  },
  {
    "text": "kubernetes itself runs and",
    "start": "1165039",
    "end": "1168160"
  },
  {
    "text": "rapid reliable experimentation including",
    "start": "1168160",
    "end": "1170799"
  },
  {
    "text": "metadata tracking",
    "start": "1170799",
    "end": "1172000"
  },
  {
    "text": "and parallel experiments",
    "start": "1172000",
    "end": "1175440"
  },
  {
    "text": "so no matter which machine learning",
    "start": "1175440",
    "end": "1177360"
  },
  {
    "text": "framework we're using",
    "start": "1177360",
    "end": "1178559"
  },
  {
    "text": "these concepts are critical for mlaps",
    "start": "1178559",
    "end": "1183039"
  },
  {
    "text": "so thanks very much for your time here",
    "start": "1185039",
    "end": "1187520"
  },
  {
    "text": "are the links to the code for the two",
    "start": "1187520",
    "end": "1189280"
  },
  {
    "text": "examples i showed",
    "start": "1189280",
    "end": "1193360"
  }
]
[
  {
    "start": "0",
    "end": "27000"
  },
  {
    "text": "so again my name is john scarbeck and",
    "start": "80",
    "end": "1839"
  },
  {
    "text": "i'm going to have a conversation with",
    "start": "1839",
    "end": "3040"
  },
  {
    "text": "you all regarding how gitlab.com has",
    "start": "3040",
    "end": "6160"
  },
  {
    "text": "added additional clusters to their",
    "start": "6160",
    "end": "7919"
  },
  {
    "text": "infrastructure to reduce overall cloud",
    "start": "7919",
    "end": "10080"
  },
  {
    "text": "costs",
    "start": "10080",
    "end": "11519"
  },
  {
    "text": "so i am john scarbeck i'm a site",
    "start": "11519",
    "end": "13759"
  },
  {
    "text": "reliability engineer for get lab",
    "start": "13759",
    "end": "16880"
  },
  {
    "text": "specifically on the delivery team i've",
    "start": "16880",
    "end": "19359"
  },
  {
    "text": "been with gaylab for about three years",
    "start": "19359",
    "end": "21600"
  },
  {
    "text": "and as you can see from this image i'm",
    "start": "21600",
    "end": "23359"
  },
  {
    "text": "also a beekeeper sometimes",
    "start": "23359",
    "end": "27519"
  },
  {
    "start": "27000",
    "end": "51000"
  },
  {
    "text": "in this conversation i'm going to talk a",
    "start": "28240",
    "end": "30000"
  },
  {
    "text": "little bit about how gitlab.com got",
    "start": "30000",
    "end": "32160"
  },
  {
    "text": "started with kubernetes",
    "start": "32160",
    "end": "34000"
  },
  {
    "text": "um i'm going to talk a little bit about",
    "start": "34000",
    "end": "35920"
  },
  {
    "text": "how",
    "start": "35920",
    "end": "37360"
  },
  {
    "text": "one of the problems that we encountered",
    "start": "37360",
    "end": "38960"
  },
  {
    "text": "with cloud costs and how we got set up",
    "start": "38960",
    "end": "41760"
  },
  {
    "text": "initially",
    "start": "41760",
    "end": "42879"
  },
  {
    "text": "i will then dive into the solution that",
    "start": "42879",
    "end": "44879"
  },
  {
    "text": "we chose to go about solving that",
    "start": "44879",
    "end": "46800"
  },
  {
    "text": "problem and some of the wins that we got",
    "start": "46800",
    "end": "49120"
  },
  {
    "text": "with the solution that we had chosen",
    "start": "49120",
    "end": "52640"
  },
  {
    "start": "51000",
    "end": "135000"
  },
  {
    "text": "so firstly what is gitlab.com",
    "start": "52640",
    "end": "55920"
  },
  {
    "text": "we are",
    "start": "55920",
    "end": "57280"
  },
  {
    "text": "the get lab product itself at sas scale",
    "start": "57280",
    "end": "60559"
  },
  {
    "text": "so you know we're serving roughly 2",
    "start": "60559",
    "end": "62239"
  },
  {
    "text": "million plus customers at this moment",
    "start": "62239",
    "end": "65518"
  },
  {
    "text": "it took us a while to",
    "start": "65519",
    "end": "67600"
  },
  {
    "text": "get started in kubernetes land",
    "start": "67600",
    "end": "70320"
  },
  {
    "text": "we've got a large infrastructure we've",
    "start": "70320",
    "end": "72159"
  },
  {
    "text": "had to scale out quite vastly over the",
    "start": "72159",
    "end": "74240"
  },
  {
    "text": "course of time",
    "start": "74240",
    "end": "76159"
  },
  {
    "text": "and in doing so our infrastructure team",
    "start": "76159",
    "end": "78000"
  },
  {
    "text": "has had to break up parts of our",
    "start": "78000",
    "end": "80240"
  },
  {
    "text": "infrastructure into smaller chunks in",
    "start": "80240",
    "end": "82240"
  },
  {
    "text": "order to be",
    "start": "82240",
    "end": "83680"
  },
  {
    "text": "make it a little easier for us to fully",
    "start": "83680",
    "end": "85840"
  },
  {
    "text": "manage that large infrastructure at the",
    "start": "85840",
    "end": "88159"
  },
  {
    "text": "scale that we operate",
    "start": "88159",
    "end": "90720"
  },
  {
    "text": "at the same time we've also had customer",
    "start": "90720",
    "end": "93520"
  },
  {
    "text": "demand to create a helm chart that would",
    "start": "93520",
    "end": "96240"
  },
  {
    "text": "enable us to",
    "start": "96240",
    "end": "98000"
  },
  {
    "text": "or enable customers rather to install an",
    "start": "98000",
    "end": "100240"
  },
  {
    "text": "entire gitlab application on premise",
    "start": "100240",
    "end": "103600"
  },
  {
    "text": "inside of their existing kubernetes",
    "start": "103600",
    "end": "105360"
  },
  {
    "text": "clusters",
    "start": "105360",
    "end": "106560"
  },
  {
    "text": "so with those two building blocks in",
    "start": "106560",
    "end": "109200"
  },
  {
    "text": "place we've been able to get our feet",
    "start": "109200",
    "end": "111920"
  },
  {
    "text": "wet within kubernetes",
    "start": "111920",
    "end": "115840"
  },
  {
    "text": "and at this point we now have today we",
    "start": "115840",
    "end": "118320"
  },
  {
    "text": "have a hybrid architecture both virtual",
    "start": "118320",
    "end": "120240"
  },
  {
    "text": "machines that are still managed via",
    "start": "120240",
    "end": "121840"
  },
  {
    "text": "terraform and chef",
    "start": "121840",
    "end": "123360"
  },
  {
    "text": "and we now have about 90 of our front",
    "start": "123360",
    "end": "125759"
  },
  {
    "text": "end workloads are inside of kubernetes",
    "start": "125759",
    "end": "128080"
  },
  {
    "text": "at this point",
    "start": "128080",
    "end": "129280"
  },
  {
    "text": "would have done a few more services but",
    "start": "129280",
    "end": "131520"
  },
  {
    "text": "i decided to stress myself out and do a",
    "start": "131520",
    "end": "133599"
  },
  {
    "text": "talk so here i am",
    "start": "133599",
    "end": "136959"
  },
  {
    "start": "135000",
    "end": "221000"
  },
  {
    "text": "so when it came to getting started",
    "start": "136959",
    "end": "140879"
  },
  {
    "text": "with kubernetes our infrastructure team",
    "start": "140879",
    "end": "143440"
  },
  {
    "text": "needed a way to",
    "start": "143440",
    "end": "144959"
  },
  {
    "text": "simply",
    "start": "144959",
    "end": "146080"
  },
  {
    "text": "or create a cluster very quickly without",
    "start": "146080",
    "end": "148800"
  },
  {
    "text": "having to work terribly hard",
    "start": "148800",
    "end": "151120"
  },
  {
    "text": "we did not want to go the route of using",
    "start": "151120",
    "end": "153200"
  },
  {
    "text": "our existing infrastructure management",
    "start": "153200",
    "end": "155680"
  },
  {
    "text": "practices to build clusters",
    "start": "155680",
    "end": "158560"
  },
  {
    "text": "manage the upgrades and figure out how",
    "start": "158560",
    "end": "160959"
  },
  {
    "text": "to troubleshoot them and such",
    "start": "160959",
    "end": "163519"
  },
  {
    "text": "we wanted to do something very quickly",
    "start": "163519",
    "end": "165280"
  },
  {
    "text": "we wanted to get customer workloads",
    "start": "165280",
    "end": "167040"
  },
  {
    "text": "inside of kubernetes as quickly as",
    "start": "167040",
    "end": "168800"
  },
  {
    "text": "possible so with that",
    "start": "168800",
    "end": "171519"
  },
  {
    "text": "we use google's cloud platform as our",
    "start": "171519",
    "end": "174160"
  },
  {
    "text": "infrastructure provider",
    "start": "174160",
    "end": "176400"
  },
  {
    "text": "so it was very natural for us to go down",
    "start": "176400",
    "end": "178400"
  },
  {
    "text": "the route of checking out google",
    "start": "178400",
    "end": "179840"
  },
  {
    "text": "kubernetes engine or gke",
    "start": "179840",
    "end": "183120"
  },
  {
    "text": "in doing so this allowed us to focus our",
    "start": "183120",
    "end": "185360"
  },
  {
    "text": "efforts where we deemed things more",
    "start": "185360",
    "end": "187040"
  },
  {
    "text": "important to us",
    "start": "187040",
    "end": "188480"
  },
  {
    "text": "that included items such as making sure",
    "start": "188480",
    "end": "190480"
  },
  {
    "text": "we know how to manage and deploy our",
    "start": "190480",
    "end": "193040"
  },
  {
    "text": "actual configurations for those clusters",
    "start": "193040",
    "end": "196480"
  },
  {
    "text": "integrating those clusters with our",
    "start": "196480",
    "end": "198400"
  },
  {
    "text": "existing infrastructure making sure the",
    "start": "198400",
    "end": "200239"
  },
  {
    "text": "applications interoperate very well",
    "start": "200239",
    "end": "202319"
  },
  {
    "text": "between our virtual machines and our",
    "start": "202319",
    "end": "204000"
  },
  {
    "text": "clusters that we deployed",
    "start": "204000",
    "end": "206319"
  },
  {
    "text": "in our observability stack we want to",
    "start": "206319",
    "end": "207920"
  },
  {
    "text": "make sure that as we migrate things",
    "start": "207920",
    "end": "209840"
  },
  {
    "text": "between virtual machines and kubernetes",
    "start": "209840",
    "end": "212080"
  },
  {
    "text": "that we could still",
    "start": "212080",
    "end": "214560"
  },
  {
    "text": "view the metrics of those applications",
    "start": "214560",
    "end": "217200"
  },
  {
    "text": "as",
    "start": "217200",
    "end": "218159"
  },
  {
    "text": "as we focus on its migrations",
    "start": "218159",
    "end": "221760"
  },
  {
    "start": "221000",
    "end": "334000"
  },
  {
    "text": "so with all this is in place we're able",
    "start": "222720",
    "end": "225599"
  },
  {
    "text": "to now",
    "start": "225599",
    "end": "227760"
  },
  {
    "text": "migrate our first component which in",
    "start": "227760",
    "end": "229440"
  },
  {
    "text": "this case was the",
    "start": "229440",
    "end": "231280"
  },
  {
    "text": "get lab container or the container",
    "start": "231280",
    "end": "233040"
  },
  {
    "text": "registry of gitlab",
    "start": "233040",
    "end": "235200"
  },
  {
    "text": "this is a relatively lightweight doling",
    "start": "235200",
    "end": "237760"
  },
  {
    "text": "application there's not a lot of",
    "start": "237760",
    "end": "239439"
  },
  {
    "text": "dependencies between",
    "start": "239439",
    "end": "241439"
  },
  {
    "text": "that and other services within our stack",
    "start": "241439",
    "end": "245040"
  },
  {
    "text": "it moves it does not move a lot of data",
    "start": "245040",
    "end": "247599"
  },
  {
    "text": "but it does",
    "start": "247599",
    "end": "248959"
  },
  {
    "text": "serve a lot of traffic for customers",
    "start": "248959",
    "end": "252000"
  },
  {
    "text": "i think our own ci is probably the",
    "start": "252000",
    "end": "254239"
  },
  {
    "text": "heaviest hitter of our container",
    "start": "254239",
    "end": "255760"
  },
  {
    "text": "registry at this point",
    "start": "255760",
    "end": "258320"
  },
  {
    "text": "but in doing so this was a perfect",
    "start": "258320",
    "end": "260400"
  },
  {
    "text": "application it's stateless",
    "start": "260400",
    "end": "262320"
  },
  {
    "text": "so it was able to get us",
    "start": "262320",
    "end": "264160"
  },
  {
    "text": "get our feet wet in the kubernetes",
    "start": "264160",
    "end": "266960"
  },
  {
    "text": "we are able to figure out how the best",
    "start": "266960",
    "end": "269520"
  },
  {
    "text": "way to migrate our applications inside",
    "start": "269520",
    "end": "271520"
  },
  {
    "text": "of our particular stack and how we",
    "start": "271520",
    "end": "273440"
  },
  {
    "text": "operate",
    "start": "273440",
    "end": "274720"
  },
  {
    "text": "we could test and validate the changes",
    "start": "274720",
    "end": "277120"
  },
  {
    "text": "that we make inside of our",
    "start": "277120",
    "end": "278160"
  },
  {
    "text": "infrastructure make sure they're",
    "start": "278160",
    "end": "279360"
  },
  {
    "text": "interoperable between our various",
    "start": "279360",
    "end": "281600"
  },
  {
    "text": "infrastructure technologies",
    "start": "281600",
    "end": "283680"
  },
  {
    "text": "meaning kubernetes under virtual",
    "start": "283680",
    "end": "285120"
  },
  {
    "text": "machines",
    "start": "285120",
    "end": "286400"
  },
  {
    "text": "and we could also dig a little bit into",
    "start": "286400",
    "end": "288560"
  },
  {
    "text": "the future and determine what we need to",
    "start": "288560",
    "end": "290160"
  },
  {
    "text": "do",
    "start": "290160",
    "end": "291919"
  },
  {
    "text": "with future migrations we could set",
    "start": "291919",
    "end": "294160"
  },
  {
    "text": "expectations for how we expect",
    "start": "294160",
    "end": "296560"
  },
  {
    "text": "objects to work or services to work when",
    "start": "296560",
    "end": "298639"
  },
  {
    "text": "they get migrated into kubernetes",
    "start": "298639",
    "end": "301280"
  },
  {
    "text": "we are still building our knowledge",
    "start": "301280",
    "end": "303440"
  },
  {
    "text": "within kubernetes itself and how we",
    "start": "303440",
    "end": "305440"
  },
  {
    "text": "expect the future applications to work",
    "start": "305440",
    "end": "307919"
  },
  {
    "text": "within kubernetes",
    "start": "307919",
    "end": "309840"
  },
  {
    "text": "and then share the knowledge across the",
    "start": "309840",
    "end": "311520"
  },
  {
    "text": "rest of our infrastructure team over the",
    "start": "311520",
    "end": "313360"
  },
  {
    "text": "course of time as we expand more",
    "start": "313360",
    "end": "315199"
  },
  {
    "text": "services into kubernetes",
    "start": "315199",
    "end": "318240"
  },
  {
    "text": "so one of the things that we thought",
    "start": "318240",
    "end": "320240"
  },
  {
    "text": "ahead when it came time to touching one",
    "start": "320240",
    "end": "322720"
  },
  {
    "text": "of the next front-end services",
    "start": "322720",
    "end": "324800"
  },
  {
    "text": "was the investigation and the",
    "start": "324800",
    "end": "326240"
  },
  {
    "text": "expectations we set for ourselves with",
    "start": "326240",
    "end": "328160"
  },
  {
    "text": "that migration and one of the problems",
    "start": "328160",
    "end": "330000"
  },
  {
    "text": "that we encountered",
    "start": "330000",
    "end": "331759"
  },
  {
    "text": "was going to be the heart of this talk",
    "start": "331759",
    "end": "333919"
  },
  {
    "text": "which is something we learned about",
    "start": "333919",
    "end": "336400"
  },
  {
    "start": "334000",
    "end": "475000"
  },
  {
    "text": "cloud costs and when you set up a",
    "start": "336400",
    "end": "339120"
  },
  {
    "text": "regional cluster",
    "start": "339120",
    "end": "341280"
  },
  {
    "text": "so",
    "start": "341280",
    "end": "342160"
  },
  {
    "text": "when we got started with kubernetes we",
    "start": "342160",
    "end": "344400"
  },
  {
    "text": "went the route of using gke and used",
    "start": "344400",
    "end": "346720"
  },
  {
    "text": "their",
    "start": "346720",
    "end": "348080"
  },
  {
    "text": "recommendations",
    "start": "348080",
    "end": "349759"
  },
  {
    "text": "for setting up production-worthy",
    "start": "349759",
    "end": "351199"
  },
  {
    "text": "clusters so related with the regional",
    "start": "351199",
    "end": "352800"
  },
  {
    "text": "cluster",
    "start": "352800",
    "end": "353919"
  },
  {
    "text": "that was deployed",
    "start": "353919",
    "end": "355440"
  },
  {
    "text": "using all the zones inside that region",
    "start": "355440",
    "end": "358720"
  },
  {
    "text": "so in this diagram here i'm showcasing",
    "start": "358720",
    "end": "361199"
  },
  {
    "text": "the fact that we've got the network",
    "start": "361199",
    "end": "363039"
  },
  {
    "text": "traffic happening",
    "start": "363039",
    "end": "364800"
  },
  {
    "text": "inside of our front end stack so",
    "start": "364800",
    "end": "368560"
  },
  {
    "text": "when you operate inside of a single",
    "start": "369360",
    "end": "370800"
  },
  {
    "text": "cluster and you're",
    "start": "370800",
    "end": "372639"
  },
  {
    "text": "you've got a web service deployed you're",
    "start": "372639",
    "end": "374160"
  },
  {
    "text": "technically deploying a few objects one",
    "start": "374160",
    "end": "376000"
  },
  {
    "text": "is the web service itself",
    "start": "376000",
    "end": "378000"
  },
  {
    "text": "along with all the web service pods and",
    "start": "378000",
    "end": "379919"
  },
  {
    "text": "the services associated with those and",
    "start": "379919",
    "end": "382080"
  },
  {
    "text": "you're also deploying the nginx ingress",
    "start": "382080",
    "end": "384000"
  },
  {
    "text": "controller in our case or you might have",
    "start": "384000",
    "end": "386319"
  },
  {
    "text": "a",
    "start": "386319",
    "end": "387039"
  },
  {
    "text": "configuration for the existing",
    "start": "387039",
    "end": "388479"
  },
  {
    "text": "controller",
    "start": "388479",
    "end": "389919"
  },
  {
    "text": "because we're using a google cloud as",
    "start": "389919",
    "end": "391840"
  },
  {
    "text": "our provider we get an a low bouncer of",
    "start": "391840",
    "end": "394400"
  },
  {
    "text": "some type in this case we utilize an",
    "start": "394400",
    "end": "395840"
  },
  {
    "text": "internal load bouncer",
    "start": "395840",
    "end": "397680"
  },
  {
    "text": "so with this client requests end up",
    "start": "397680",
    "end": "400160"
  },
  {
    "text": "going from our front door which we",
    "start": "400160",
    "end": "402319"
  },
  {
    "text": "utilize aj proxy for and those requests",
    "start": "402319",
    "end": "404560"
  },
  {
    "text": "are going to go through and route into",
    "start": "404560",
    "end": "406560"
  },
  {
    "text": "the load bouncer which then get uh sent",
    "start": "406560",
    "end": "409440"
  },
  {
    "text": "to the nginx ingress controllers",
    "start": "409440",
    "end": "412479"
  },
  {
    "text": "at this point we've got two potential",
    "start": "412479",
    "end": "414319"
  },
  {
    "text": "paths in which network traffic can take",
    "start": "414319",
    "end": "417199"
  },
  {
    "text": "one of them being a very nice low",
    "start": "417199",
    "end": "419440"
  },
  {
    "text": "latency low cost path the one being kind",
    "start": "419440",
    "end": "422240"
  },
  {
    "text": "of a heavyweight path",
    "start": "422240",
    "end": "425759"
  },
  {
    "text": "because a regional cluster is set up in",
    "start": "426319",
    "end": "428880"
  },
  {
    "text": "a way in which you have web service pods",
    "start": "428880",
    "end": "432639"
  },
  {
    "text": "the knowledge of those web service pods",
    "start": "432639",
    "end": "434960"
  },
  {
    "text": "across the entire cluster the nginx",
    "start": "434960",
    "end": "437039"
  },
  {
    "text": "ingress controllers know about all those",
    "start": "437039",
    "end": "439280"
  },
  {
    "text": "pods",
    "start": "439280",
    "end": "440639"
  },
  {
    "text": "because of this when a request comes",
    "start": "440639",
    "end": "442240"
  },
  {
    "text": "into an ingress control located say in",
    "start": "442240",
    "end": "444400"
  },
  {
    "text": "zone b",
    "start": "444400",
    "end": "445440"
  },
  {
    "text": "if that request lands on a web service",
    "start": "445440",
    "end": "447919"
  },
  {
    "text": "pod located in zone c two potentially",
    "start": "447919",
    "end": "451919"
  },
  {
    "text": "bad things can happen one you have",
    "start": "451919",
    "end": "453520"
  },
  {
    "text": "additional network latency because",
    "start": "453520",
    "end": "455599"
  },
  {
    "text": "you've egressed traffic from one zone to",
    "start": "455599",
    "end": "458880"
  },
  {
    "text": "another it may be minor but it might be",
    "start": "458880",
    "end": "461759"
  },
  {
    "text": "something to keep in mind on another is",
    "start": "461759",
    "end": "464720"
  },
  {
    "text": "the cost of the network egress from one",
    "start": "464720",
    "end": "467120"
  },
  {
    "text": "zone to another",
    "start": "467120",
    "end": "468639"
  },
  {
    "text": "and this is where",
    "start": "468639",
    "end": "470960"
  },
  {
    "text": "we at gitlab.com had a problem to solve",
    "start": "470960",
    "end": "474639"
  },
  {
    "text": "so let's dive a little bit into the",
    "start": "474639",
    "end": "477039"
  },
  {
    "text": "costs associated with this",
    "start": "477039",
    "end": "480000"
  },
  {
    "text": "so all cloud providers have this problem",
    "start": "480000",
    "end": "482000"
  },
  {
    "text": "where network egress is a little bit",
    "start": "482000",
    "end": "484160"
  },
  {
    "text": "costly but",
    "start": "484160",
    "end": "485360"
  },
  {
    "text": "so insert your favorite cloud providers",
    "start": "485360",
    "end": "487919"
  },
  {
    "text": "pricing calculator and such here but",
    "start": "487919",
    "end": "490479"
  },
  {
    "text": "for google you know they charge one",
    "start": "490479",
    "end": "492240"
  },
  {
    "text": "penny per gigabyte for traffic that",
    "start": "492240",
    "end": "494080"
  },
  {
    "text": "egresses out of zones so prior to us",
    "start": "494080",
    "end": "496639"
  },
  {
    "text": "remembering the next big service we were",
    "start": "496639",
    "end": "498000"
  },
  {
    "text": "just doing some napkin math 500",
    "start": "498000",
    "end": "499840"
  },
  {
    "text": "terabytes of data moving across zones",
    "start": "499840",
    "end": "502319"
  },
  {
    "text": "is gonna cost you over five thousand",
    "start": "502319",
    "end": "503840"
  },
  {
    "text": "dollars a month",
    "start": "503840",
    "end": "507120"
  },
  {
    "text": "for gitlab.com and the amount of data",
    "start": "507120",
    "end": "509440"
  },
  {
    "text": "that we move we're moving petabytes of",
    "start": "509440",
    "end": "511440"
  },
  {
    "text": "data across an entire month",
    "start": "511440",
    "end": "513680"
  },
  {
    "text": "and assuming a",
    "start": "513680",
    "end": "515200"
  },
  {
    "text": "regional cluster with three zones you're",
    "start": "515200",
    "end": "518000"
  },
  {
    "text": "going to",
    "start": "518000",
    "end": "519200"
  },
  {
    "text": "subject approximately two-thirds of that",
    "start": "519200",
    "end": "521518"
  },
  {
    "text": "traffic",
    "start": "521519",
    "end": "522479"
  },
  {
    "text": "potentially crossing those zonal",
    "start": "522479",
    "end": "524080"
  },
  {
    "text": "boundaries",
    "start": "524080",
    "end": "525279"
  },
  {
    "text": "and that's going to get quite expensive",
    "start": "525279",
    "end": "527440"
  },
  {
    "text": "and this goes a little bit into how",
    "start": "527440",
    "end": "529120"
  },
  {
    "text": "difficult it is to predict your cloud",
    "start": "529120",
    "end": "531279"
  },
  {
    "text": "bill and estimate your potential cloud",
    "start": "531279",
    "end": "533600"
  },
  {
    "text": "costs",
    "start": "533600",
    "end": "535519"
  },
  {
    "text": "you know how much a kubernetes cluster",
    "start": "535519",
    "end": "537760"
  },
  {
    "text": "is going to cost because they tell you",
    "start": "537760",
    "end": "539360"
  },
  {
    "text": "it's going to cost x amount per hour",
    "start": "539360",
    "end": "541600"
  },
  {
    "text": "we know the nodes that back or",
    "start": "541600",
    "end": "543040"
  },
  {
    "text": "creminates clusters you can kind of",
    "start": "543040",
    "end": "544720"
  },
  {
    "text": "predict how much",
    "start": "544720",
    "end": "546800"
  },
  {
    "text": "the instances are going to cost you over",
    "start": "546800",
    "end": "548800"
  },
  {
    "text": "the course a month",
    "start": "548800",
    "end": "550120"
  },
  {
    "text": "gitlab.com is a very network",
    "start": "550120",
    "end": "553200"
  },
  {
    "text": "data-driven workload we're subject to",
    "start": "553200",
    "end": "555600"
  },
  {
    "text": "what our customers send to us and the",
    "start": "555600",
    "end": "557600"
  },
  {
    "text": "data that they're requesting from us",
    "start": "557600",
    "end": "560240"
  },
  {
    "text": "so",
    "start": "560240",
    "end": "561040"
  },
  {
    "text": "knowing the costs associated with",
    "start": "561040",
    "end": "562959"
  },
  {
    "text": "network egress is a little bit harder to",
    "start": "562959",
    "end": "564640"
  },
  {
    "text": "predict and it's kind of a surprising",
    "start": "564640",
    "end": "566800"
  },
  {
    "text": "cost to be added if you're unaware of it",
    "start": "566800",
    "end": "570560"
  },
  {
    "start": "570000",
    "end": "630000"
  },
  {
    "text": "now keep in mind that",
    "start": "570800",
    "end": "572880"
  },
  {
    "text": "crossing zonal boundaries",
    "start": "572880",
    "end": "575440"
  },
  {
    "text": "or egressing zones is not avoidable",
    "start": "575440",
    "end": "578240"
  },
  {
    "text": "everywhere so in this diagram i'm",
    "start": "578240",
    "end": "579600"
  },
  {
    "text": "showing that web service pods eventually",
    "start": "579600",
    "end": "581440"
  },
  {
    "text": "a talk to a database or file server to",
    "start": "581440",
    "end": "583279"
  },
  {
    "text": "retrieve the data that they're",
    "start": "583279",
    "end": "584640"
  },
  {
    "text": "requesting",
    "start": "584640",
    "end": "586240"
  },
  {
    "text": "but this is a cost that we just kind of",
    "start": "586240",
    "end": "588399"
  },
  {
    "text": "have to succumb to it's something that",
    "start": "588399",
    "end": "590640"
  },
  {
    "text": "we are willing to take because of the",
    "start": "590640",
    "end": "592240"
  },
  {
    "text": "way that we've engineered our lower end",
    "start": "592240",
    "end": "594640"
  },
  {
    "text": "infrastructure",
    "start": "594640",
    "end": "596240"
  },
  {
    "text": "to be as redundant as possible",
    "start": "596240",
    "end": "598720"
  },
  {
    "text": "however the nginx ingers controllers",
    "start": "598720",
    "end": "601440"
  },
  {
    "text": "they're not really doing a lot of work",
    "start": "601440",
    "end": "603200"
  },
  {
    "text": "here they're simply proxying the data",
    "start": "603200",
    "end": "605120"
  },
  {
    "text": "they might be doing a little buffering",
    "start": "605120",
    "end": "606640"
  },
  {
    "text": "but the important part is that they're",
    "start": "606640",
    "end": "608240"
  },
  {
    "text": "taking the traffic",
    "start": "608240",
    "end": "610079"
  },
  {
    "text": "from the nginx ingers controllers and",
    "start": "610079",
    "end": "612079"
  },
  {
    "text": "kind of proxying it across all these web",
    "start": "612079",
    "end": "614160"
  },
  {
    "text": "service pods",
    "start": "614160",
    "end": "615600"
  },
  {
    "text": "realistically they don't need to know",
    "start": "615600",
    "end": "617680"
  },
  {
    "text": "about all of those web service pods but",
    "start": "617680",
    "end": "619920"
  },
  {
    "text": "they just need to know how to route the",
    "start": "619920",
    "end": "621680"
  },
  {
    "text": "traffic to ones that are closest to them",
    "start": "621680",
    "end": "623519"
  },
  {
    "text": "so if we could solve for that problem",
    "start": "623519",
    "end": "625519"
  },
  {
    "text": "we've got some sort of improvement",
    "start": "625519",
    "end": "627279"
  },
  {
    "text": "specifically to our cloud bill",
    "start": "627279",
    "end": "630079"
  },
  {
    "start": "630000",
    "end": "741000"
  },
  {
    "text": "so as my talk",
    "start": "630079",
    "end": "633200"
  },
  {
    "text": "title suggests we decided to add a few",
    "start": "633200",
    "end": "635839"
  },
  {
    "text": "more clusters",
    "start": "635839",
    "end": "637680"
  },
  {
    "text": "so given a region that has three zones",
    "start": "637680",
    "end": "640160"
  },
  {
    "text": "we simply created a cluster per zone so",
    "start": "640160",
    "end": "643519"
  },
  {
    "text": "now when traffic comes in through rha",
    "start": "643519",
    "end": "645920"
  },
  {
    "text": "proxy front end and you know they're",
    "start": "645920",
    "end": "647440"
  },
  {
    "text": "spread across all of our zones as well",
    "start": "647440",
    "end": "649760"
  },
  {
    "text": "if your client request went through zone",
    "start": "649760",
    "end": "651760"
  },
  {
    "text": "b in aj proxy you're going to get",
    "start": "651760",
    "end": "654000"
  },
  {
    "text": "favored to a cluster that is also",
    "start": "654000",
    "end": "656079"
  },
  {
    "text": "located in zone b",
    "start": "656079",
    "end": "658720"
  },
  {
    "text": "this means that the nginx ingress",
    "start": "658720",
    "end": "660320"
  },
  {
    "text": "controller that's also located inside",
    "start": "660320",
    "end": "662240"
  },
  {
    "text": "that cluster only knows about the web",
    "start": "662240",
    "end": "664160"
  },
  {
    "text": "service pods that are located in that",
    "start": "664160",
    "end": "666079"
  },
  {
    "text": "cluster so therefore that traffic stays",
    "start": "666079",
    "end": "668720"
  },
  {
    "text": "inside of that zone for the time being",
    "start": "668720",
    "end": "671360"
  },
  {
    "text": "with this aspect we've completely",
    "start": "671360",
    "end": "673200"
  },
  {
    "text": "eliminated the fact that an engine's",
    "start": "673200",
    "end": "675360"
  },
  {
    "text": "ingress is going to route your traffic",
    "start": "675360",
    "end": "677040"
  },
  {
    "text": "to an awkward zone which may incur some",
    "start": "677040",
    "end": "679279"
  },
  {
    "text": "additional costs whether that be the",
    "start": "679279",
    "end": "680720"
  },
  {
    "text": "network or the um",
    "start": "680720",
    "end": "682880"
  },
  {
    "text": "cloud bill network egress cost",
    "start": "682880",
    "end": "686720"
  },
  {
    "text": "but again like",
    "start": "686959",
    "end": "688640"
  },
  {
    "text": "underneath the web service pods when",
    "start": "688640",
    "end": "690240"
  },
  {
    "text": "they go reach out the file service",
    "start": "690240",
    "end": "691680"
  },
  {
    "text": "they'll still potentially cross a zonal",
    "start": "691680",
    "end": "694079"
  },
  {
    "text": "boundary and again like i mentioned",
    "start": "694079",
    "end": "695839"
  },
  {
    "text": "before this will be a cost that we have",
    "start": "695839",
    "end": "697200"
  },
  {
    "text": "to",
    "start": "697200",
    "end": "698320"
  },
  {
    "text": "absorb",
    "start": "698320",
    "end": "700240"
  },
  {
    "text": "and there's a few benefits um to having",
    "start": "700240",
    "end": "703360"
  },
  {
    "text": "multiple clusters as well",
    "start": "703360",
    "end": "706000"
  },
  {
    "text": "we've you've got the potential we have a",
    "start": "706000",
    "end": "708240"
  },
  {
    "text": "situation for",
    "start": "708240",
    "end": "710959"
  },
  {
    "text": "cluster upgrades you could spread them",
    "start": "710959",
    "end": "712800"
  },
  {
    "text": "out over the course of time so instead",
    "start": "712800",
    "end": "714480"
  },
  {
    "text": "of having a single cluster that gets",
    "start": "714480",
    "end": "716079"
  },
  {
    "text": "upgraded you have multiple clusters and",
    "start": "716079",
    "end": "718399"
  },
  {
    "text": "you know should an upgrade fail you got",
    "start": "718399",
    "end": "720560"
  },
  {
    "text": "the ability to spread or remove a",
    "start": "720560",
    "end": "722880"
  },
  {
    "text": "cluster from rotation to fix it h.a prox",
    "start": "722880",
    "end": "726320"
  },
  {
    "text": "in our case has knowledge of all of our",
    "start": "726320",
    "end": "728560"
  },
  {
    "text": "clusters so when we take one down for",
    "start": "728560",
    "end": "730639"
  },
  {
    "text": "maintenance or we need to perform some",
    "start": "730639",
    "end": "732320"
  },
  {
    "text": "sort of",
    "start": "732320",
    "end": "734639"
  },
  {
    "text": "maintenance procedure we have the",
    "start": "735040",
    "end": "736320"
  },
  {
    "text": "ability to ship that traffic over to",
    "start": "736320",
    "end": "737760"
  },
  {
    "text": "other clusters as necessary",
    "start": "737760",
    "end": "741200"
  },
  {
    "start": "741000",
    "end": "811000"
  },
  {
    "text": "so what other options are available if a",
    "start": "741920",
    "end": "744160"
  },
  {
    "text": "multi-cluster configuration may not be",
    "start": "744160",
    "end": "746160"
  },
  {
    "text": "available for everyone",
    "start": "746160",
    "end": "748160"
  },
  {
    "text": "one is a service mesh",
    "start": "748160",
    "end": "750240"
  },
  {
    "text": "today gitlab.com does not use a service",
    "start": "750240",
    "end": "752639"
  },
  {
    "text": "mesh this gitlab product does not use a",
    "start": "752639",
    "end": "754880"
  },
  {
    "text": "service mesh",
    "start": "754880",
    "end": "756560"
  },
  {
    "text": "and this would have been a lot of work",
    "start": "756560",
    "end": "757920"
  },
  {
    "text": "for us to try to figure out how to",
    "start": "757920",
    "end": "759120"
  },
  {
    "text": "implement uh it would have been a",
    "start": "759120",
    "end": "760399"
  },
  {
    "text": "combination of figuring out which",
    "start": "760399",
    "end": "762320"
  },
  {
    "text": "service mesh would have worked for us",
    "start": "762320",
    "end": "764320"
  },
  {
    "text": "uh learning how to use it configure it",
    "start": "764320",
    "end": "766639"
  },
  {
    "text": "build up the observability tooling and",
    "start": "766639",
    "end": "768399"
  },
  {
    "text": "all that stuff",
    "start": "768399",
    "end": "770000"
  },
  {
    "text": "so in this case it was just a solution",
    "start": "770000",
    "end": "771680"
  },
  {
    "text": "that we didn't want to go down",
    "start": "771680",
    "end": "773760"
  },
  {
    "text": "another option would have been modifying",
    "start": "773760",
    "end": "776639"
  },
  {
    "text": "our regional cluster configuration",
    "start": "776639",
    "end": "778399"
  },
  {
    "text": "there's many ways",
    "start": "778399",
    "end": "780240"
  },
  {
    "text": "to configure a",
    "start": "780240",
    "end": "782560"
  },
  {
    "text": "managed cluster inside of google",
    "start": "782560",
    "end": "785279"
  },
  {
    "text": "but we saw the benefits of having",
    "start": "785279",
    "end": "787760"
  },
  {
    "text": "more clusters greater than a single",
    "start": "787760",
    "end": "789760"
  },
  {
    "text": "cluster so we decided to just go down",
    "start": "789760",
    "end": "791839"
  },
  {
    "text": "that route",
    "start": "791839",
    "end": "792880"
  },
  {
    "text": "and then today there's more features",
    "start": "792880",
    "end": "794480"
  },
  {
    "text": "available than there were",
    "start": "794480",
    "end": "796399"
  },
  {
    "text": "in prior when we first started looking",
    "start": "796399",
    "end": "798480"
  },
  {
    "text": "into this so kubernetes kubernetes has a",
    "start": "798480",
    "end": "802160"
  },
  {
    "text": "feature called topology aware hints",
    "start": "802160",
    "end": "806000"
  },
  {
    "text": "something that was not available back",
    "start": "806160",
    "end": "807600"
  },
  {
    "text": "then i'm no clue what this does but it",
    "start": "807600",
    "end": "809200"
  },
  {
    "text": "might be worth checking out",
    "start": "809200",
    "end": "812160"
  },
  {
    "start": "811000",
    "end": "884000"
  },
  {
    "text": "um",
    "start": "812399",
    "end": "813279"
  },
  {
    "text": "so could you consider this configuration",
    "start": "813279",
    "end": "816480"
  },
  {
    "text": "more complex um",
    "start": "816480",
    "end": "818800"
  },
  {
    "text": "this is something that you could go both",
    "start": "818800",
    "end": "820399"
  },
  {
    "text": "ways with it's more complex than the",
    "start": "820399",
    "end": "822480"
  },
  {
    "text": "fact that you do have more kubernetes",
    "start": "822480",
    "end": "824399"
  },
  {
    "text": "clusters",
    "start": "824399",
    "end": "825440"
  },
  {
    "text": "but if you think about",
    "start": "825440",
    "end": "827440"
  },
  {
    "text": "a very well-balanced workload and the",
    "start": "827440",
    "end": "830320"
  },
  {
    "text": "configurations associated with it you're",
    "start": "830320",
    "end": "832720"
  },
  {
    "text": "not necessarily adding more complexity",
    "start": "832720",
    "end": "835040"
  },
  {
    "text": "for your infrastructure teams",
    "start": "835040",
    "end": "837760"
  },
  {
    "text": "the amount of nodes that are going to be",
    "start": "837760",
    "end": "839199"
  },
  {
    "text": "running those same workloads is going to",
    "start": "839199",
    "end": "840800"
  },
  {
    "text": "be roughly equivalent",
    "start": "840800",
    "end": "843839"
  },
  {
    "text": "the cluster configurations and the",
    "start": "844240",
    "end": "846639"
  },
  {
    "text": "workloads that are defined they're",
    "start": "846639",
    "end": "848480"
  },
  {
    "text": "roughly or they're pretty much identical",
    "start": "848480",
    "end": "851440"
  },
  {
    "text": "you're starting to lean away from having",
    "start": "851440",
    "end": "853600"
  },
  {
    "text": "clusters treated as pets but you're",
    "start": "853600",
    "end": "855519"
  },
  {
    "text": "leaning towards the cluster of clusters",
    "start": "855519",
    "end": "857600"
  },
  {
    "text": "as cattle",
    "start": "857600",
    "end": "858880"
  },
  {
    "text": "methodology here",
    "start": "858880",
    "end": "861600"
  },
  {
    "text": "i think the",
    "start": "861600",
    "end": "863120"
  },
  {
    "text": "most",
    "start": "863120",
    "end": "864240"
  },
  {
    "text": "strategic part that we had at gitlab was",
    "start": "864240",
    "end": "866560"
  },
  {
    "text": "determining how we identify our clusters",
    "start": "866560",
    "end": "868560"
  },
  {
    "text": "would that be a name or adding some sort",
    "start": "868560",
    "end": "871040"
  },
  {
    "text": "of location tag to figure out how we",
    "start": "871040",
    "end": "873279"
  },
  {
    "text": "want to observe and monitor our clusters",
    "start": "873279",
    "end": "875519"
  },
  {
    "text": "appropriately",
    "start": "875519",
    "end": "877839"
  },
  {
    "text": "and then of course simplifies the cloud",
    "start": "877839",
    "end": "880000"
  },
  {
    "text": "bill you know by lowering the",
    "start": "880000",
    "end": "882360"
  },
  {
    "text": "costs um",
    "start": "882360",
    "end": "885360"
  },
  {
    "start": "884000",
    "end": "950000"
  },
  {
    "text": "so some bonus things i want to touch on",
    "start": "885360",
    "end": "887279"
  },
  {
    "text": "that we got out of having this",
    "start": "887279",
    "end": "888560"
  },
  {
    "text": "configuration",
    "start": "888560",
    "end": "891040"
  },
  {
    "text": "one is a fun way to mitigate incidents",
    "start": "891040",
    "end": "893600"
  },
  {
    "text": "so this chart is showing our nat port",
    "start": "893600",
    "end": "895760"
  },
  {
    "text": "usage over the course of time when we",
    "start": "895760",
    "end": "898160"
  },
  {
    "text": "first created our additional clusters we",
    "start": "898160",
    "end": "900639"
  },
  {
    "text": "were",
    "start": "900639",
    "end": "901680"
  },
  {
    "text": "asking all of our clusters to deploy new",
    "start": "901680",
    "end": "904320"
  },
  {
    "text": "code at the same time",
    "start": "904320",
    "end": "906240"
  },
  {
    "text": "this had the down effect of after a",
    "start": "906240",
    "end": "909040"
  },
  {
    "text": "period of time where we had grown into",
    "start": "909040",
    "end": "911199"
  },
  {
    "text": "kubernetes and started pushing more",
    "start": "911199",
    "end": "912720"
  },
  {
    "text": "stuff into kubernetes we ran into a",
    "start": "912720",
    "end": "915199"
  },
  {
    "text": "situation where every time we deployed",
    "start": "915199",
    "end": "916800"
  },
  {
    "text": "all the kubernetes nodes wanted to pull",
    "start": "916800",
    "end": "918720"
  },
  {
    "text": "down",
    "start": "918720",
    "end": "919920"
  },
  {
    "text": "the new image that we wanted to run all",
    "start": "919920",
    "end": "921519"
  },
  {
    "text": "the same time",
    "start": "921519",
    "end": "923120"
  },
  {
    "text": "this was kind of bad and results in you",
    "start": "923120",
    "end": "925920"
  },
  {
    "text": "know nat port exhaustion for us in this",
    "start": "925920",
    "end": "927920"
  },
  {
    "text": "particular use case for us to mitigate",
    "start": "927920",
    "end": "930000"
  },
  {
    "text": "this all we had to do was simply modify",
    "start": "930000",
    "end": "932079"
  },
  {
    "text": "our ci pipelines to change how many",
    "start": "932079",
    "end": "934399"
  },
  {
    "text": "clusters we deploy at a time so instead",
    "start": "934399",
    "end": "936480"
  },
  {
    "text": "of deploying in parallel it was deployed",
    "start": "936480",
    "end": "938639"
  },
  {
    "text": "to one cluster at a time to give our",
    "start": "938639",
    "end": "940480"
  },
  {
    "text": "infrastructure engineers time to fix",
    "start": "940480",
    "end": "942399"
  },
  {
    "text": "that problem",
    "start": "942399",
    "end": "943680"
  },
  {
    "text": "and then move forward we could revert",
    "start": "943680",
    "end": "945199"
  },
  {
    "text": "that change and",
    "start": "945199",
    "end": "946880"
  },
  {
    "text": "deploy to as many clusters as we want to",
    "start": "946880",
    "end": "950800"
  },
  {
    "start": "950000",
    "end": "1015000"
  },
  {
    "text": "another one that i want to highlight and",
    "start": "951360",
    "end": "952880"
  },
  {
    "text": "this is something that we use very",
    "start": "952880",
    "end": "954560"
  },
  {
    "text": "heavily right now is the ability to test",
    "start": "954560",
    "end": "957440"
  },
  {
    "text": "cluster configurations so this is a",
    "start": "957440",
    "end": "959600"
  },
  {
    "text": "chart showcasing pod counts over the",
    "start": "959600",
    "end": "961600"
  },
  {
    "text": "course of a few days",
    "start": "961600",
    "end": "963279"
  },
  {
    "text": "you can see right in the middle of the",
    "start": "963279",
    "end": "964399"
  },
  {
    "text": "chart that we made some sort of change",
    "start": "964399",
    "end": "966320"
  },
  {
    "text": "where we're using far fewer pods than uh",
    "start": "966320",
    "end": "969040"
  },
  {
    "text": "than two of our",
    "start": "969040",
    "end": "970560"
  },
  {
    "text": "two of our other clusters so we've",
    "start": "970560",
    "end": "972720"
  },
  {
    "text": "effectively created a control and a test",
    "start": "972720",
    "end": "975040"
  },
  {
    "text": "set of clusters where the controls are",
    "start": "975040",
    "end": "977040"
  },
  {
    "text": "the two clusters that we did not touch",
    "start": "977040",
    "end": "978720"
  },
  {
    "text": "at all we've got our test cluster where",
    "start": "978720",
    "end": "980959"
  },
  {
    "text": "we deployed some sort of change to",
    "start": "980959",
    "end": "982959"
  },
  {
    "text": "figure out whether or not we want to see",
    "start": "982959",
    "end": "984399"
  },
  {
    "text": "positive or negative feedback here and",
    "start": "984399",
    "end": "986639"
  },
  {
    "text": "this could be anything whether it be the",
    "start": "986639",
    "end": "988399"
  },
  {
    "text": "way that you deploy the workload the",
    "start": "988399",
    "end": "990399"
  },
  {
    "text": "horizontal pod auto scaler configuration",
    "start": "990399",
    "end": "993519"
  },
  {
    "text": "it may be changing the application and",
    "start": "993519",
    "end": "995120"
  },
  {
    "text": "the way it behaves in itself but here we",
    "start": "995120",
    "end": "997279"
  },
  {
    "text": "have the ability to compare",
    "start": "997279",
    "end": "999360"
  },
  {
    "text": "with those workloads that we see in",
    "start": "999360",
    "end": "1001120"
  },
  {
    "text": "production how well",
    "start": "1001120",
    "end": "1003440"
  },
  {
    "text": "the the cluster is behaving",
    "start": "1003440",
    "end": "1006639"
  },
  {
    "text": "so in this particular case we are trying",
    "start": "1006639",
    "end": "1008639"
  },
  {
    "text": "to gain more efficiency by lowering how",
    "start": "1008639",
    "end": "1010480"
  },
  {
    "text": "many pods that we were running",
    "start": "1010480",
    "end": "1012639"
  },
  {
    "text": "for this particular workload",
    "start": "1012639",
    "end": "1016000"
  },
  {
    "start": "1015000",
    "end": "1062000"
  },
  {
    "text": "and the last thing i want to highlight",
    "start": "1016240",
    "end": "1018160"
  },
  {
    "text": "is maintenance procedures so we have the",
    "start": "1018160",
    "end": "1020720"
  },
  {
    "text": "ability to remove traffic going into",
    "start": "1020720",
    "end": "1023360"
  },
  {
    "text": "entire clusters as a whole",
    "start": "1023360",
    "end": "1025360"
  },
  {
    "text": "so this is a showcase of web requests",
    "start": "1025360",
    "end": "1028000"
  },
  {
    "text": "coming in through all three of these uh",
    "start": "1028000",
    "end": "1030079"
  },
  {
    "text": "clusters in this one region",
    "start": "1030079",
    "end": "1032959"
  },
  {
    "text": "so we had found an interesting bug on",
    "start": "1032959",
    "end": "1035760"
  },
  {
    "text": "our helm chart and if we were to deploy",
    "start": "1035760",
    "end": "1038558"
  },
  {
    "text": "a fix for the home chart",
    "start": "1038559",
    "end": "1041120"
  },
  {
    "text": "it would have been incident inducing so",
    "start": "1041120",
    "end": "1043280"
  },
  {
    "text": "in order to do that we just created a",
    "start": "1043280",
    "end": "1045038"
  },
  {
    "text": "maintenance procedure where we pulled",
    "start": "1045039",
    "end": "1046558"
  },
  {
    "text": "traffic from that cluster entirely",
    "start": "1046559",
    "end": "1048640"
  },
  {
    "text": "deployed the fix",
    "start": "1048640",
    "end": "1050320"
  },
  {
    "text": "validated the fix was in place and um",
    "start": "1050320",
    "end": "1054400"
  },
  {
    "text": "and put traffic back into it and",
    "start": "1054400",
    "end": "1056000"
  },
  {
    "text": "repeated that process for",
    "start": "1056000",
    "end": "1058000"
  },
  {
    "text": "all of our clusters",
    "start": "1058000",
    "end": "1060880"
  },
  {
    "start": "1062000",
    "end": "1129000"
  },
  {
    "text": "so to wrap up um i think one thing that",
    "start": "1062559",
    "end": "1066000"
  },
  {
    "text": "would be interesting to keep in mind is",
    "start": "1066000",
    "end": "1067520"
  },
  {
    "text": "determining whether or not this is a",
    "start": "1067520",
    "end": "1068880"
  },
  {
    "text": "problem for you",
    "start": "1068880",
    "end": "1070000"
  },
  {
    "text": "this was going to be a problem for us",
    "start": "1070000",
    "end": "1071440"
  },
  {
    "text": "because we did start off using original",
    "start": "1071440",
    "end": "1073520"
  },
  {
    "text": "cluster",
    "start": "1073520",
    "end": "1074720"
  },
  {
    "text": "and not knowing that network egress was",
    "start": "1074720",
    "end": "1077760"
  },
  {
    "text": "going to be a problem between zones",
    "start": "1077760",
    "end": "1079919"
  },
  {
    "text": "within a cluster was something that was",
    "start": "1079919",
    "end": "1081919"
  },
  {
    "text": "not immediately prevalent to us",
    "start": "1081919",
    "end": "1085200"
  },
  {
    "text": "keep in mind that the solution that we",
    "start": "1085200",
    "end": "1086720"
  },
  {
    "text": "chose may not be for everyone",
    "start": "1086720",
    "end": "1088720"
  },
  {
    "text": "we want the route of having multiple",
    "start": "1088720",
    "end": "1090960"
  },
  {
    "text": "clusters because at the time that we did",
    "start": "1090960",
    "end": "1092640"
  },
  {
    "text": "this we didn't have a lot of stuff",
    "start": "1092640",
    "end": "1094559"
  },
  {
    "text": "inside of kubernetes as a whole",
    "start": "1094559",
    "end": "1096720"
  },
  {
    "text": "it was easier for us to deploy more",
    "start": "1096720",
    "end": "1098880"
  },
  {
    "text": "clusters than it was to look at other",
    "start": "1098880",
    "end": "1100640"
  },
  {
    "text": "solutions",
    "start": "1100640",
    "end": "1102720"
  },
  {
    "text": "and also conserve this is a problem with",
    "start": "1102720",
    "end": "1104640"
  },
  {
    "text": "other workloads outside of kubernetes",
    "start": "1104640",
    "end": "1107039"
  },
  {
    "text": "like i mentioned we've got this problem",
    "start": "1107039",
    "end": "1108559"
  },
  {
    "text": "between",
    "start": "1108559",
    "end": "1109919"
  },
  {
    "text": "our web service layer and talking to our",
    "start": "1109919",
    "end": "1112480"
  },
  {
    "text": "file servers and such",
    "start": "1112480",
    "end": "1114320"
  },
  {
    "text": "so this could be",
    "start": "1114320",
    "end": "1115679"
  },
  {
    "text": "problems elsewhere within your stack",
    "start": "1115679",
    "end": "1118400"
  },
  {
    "text": "so",
    "start": "1118400",
    "end": "1119840"
  },
  {
    "text": "i spoke really fast because this is my",
    "start": "1119840",
    "end": "1122559"
  },
  {
    "text": "first time so my apologies so i've got",
    "start": "1122559",
    "end": "1124799"
  },
  {
    "text": "plenty of times for question",
    "start": "1124799",
    "end": "1128760"
  }
]
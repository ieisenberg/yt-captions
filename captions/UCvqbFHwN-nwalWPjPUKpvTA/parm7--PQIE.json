[
  {
    "start": "0",
    "end": "38000"
  },
  {
    "text": "hi everyone my name is lyron cohen and today i will talk about some of the different solutions",
    "start": "560",
    "end": "6560"
  },
  {
    "text": "for achieving highly available long-term scalable prometheus",
    "start": "6560",
    "end": "12480"
  },
  {
    "text": "a little bit about myself before we start i have been a devops and site reliability engineer for the past seven",
    "start": "12480",
    "end": "19439"
  },
  {
    "text": "years before my current job as an sre at riskyfied i was a devops consultant in multiple",
    "start": "19439",
    "end": "26480"
  },
  {
    "text": "companies and when i'm not working or studying i enjoy traveling diving and basically anything water",
    "start": "26480",
    "end": "33040"
  },
  {
    "text": "related as you can probably tell by my happy face in this photo",
    "start": "33040",
    "end": "38640"
  },
  {
    "start": "38000",
    "end": "238000"
  },
  {
    "text": "so before we will dive into the different solutions we decided to check let's briefly talk about the issues we",
    "start": "38640",
    "end": "44719"
  },
  {
    "text": "had so what we started with was an architecture used by a lot of people",
    "start": "44719",
    "end": "50559"
  },
  {
    "text": "and companies two prometheus servers that scrapes matrix from the same targets",
    "start": "50559",
    "end": "55920"
  },
  {
    "text": "both monitor the same sets of jobs for high availability where each prometheus has its own local",
    "start": "55920",
    "end": "61760"
  },
  {
    "text": "disk for durability we're running on aws so in our case it's ebs what are the issues with this",
    "start": "61760",
    "end": "70840"
  },
  {
    "text": "architecture well it's not scalable it's not really highly available",
    "start": "70840",
    "end": "76560"
  },
  {
    "text": "if one prometheus is going down or in the process of rolling update there will be gaps in the data we will",
    "start": "76560",
    "end": "82720"
  },
  {
    "text": "see for example in grafana so we can't really load balance between the different instances",
    "start": "82720",
    "end": "88960"
  },
  {
    "text": "there is no centralization no global view of data if for example we want to query multiple",
    "start": "88960",
    "end": "94799"
  },
  {
    "text": "clusters we can't and there is no long term storage of data we can configure a retention of",
    "start": "94799",
    "end": "101680"
  },
  {
    "text": "multiple years as an example this way so we knew we needed a solution for all",
    "start": "101680",
    "end": "106960"
  },
  {
    "text": "of these issues and we knew that there are some tools that can help us eventually we were left with three",
    "start": "106960",
    "end": "113439"
  },
  {
    "text": "potential tools we decided we wanted to choose from number three cortex and tongues it's",
    "start": "113439",
    "end": "120799"
  },
  {
    "text": "important to note that i'm not representing any of these projects i'm not part of the maintainers of none of them",
    "start": "120799",
    "end": "127600"
  },
  {
    "text": "we simply wanted to examine their different architectures to understand what each tool can offer",
    "start": "127600",
    "end": "133520"
  },
  {
    "text": "what are the advantages and disadvantages of each soul and how they differ from each other why",
    "start": "133520",
    "end": "139599"
  },
  {
    "text": "did we want to know this all these projects have some similarities they are all written in go",
    "start": "139599",
    "end": "146959"
  },
  {
    "text": "open source projects that are compatible with prometheus and they all offer us a solution that",
    "start": "146959",
    "end": "153200"
  },
  {
    "text": "can suit the issues we just talked about all these projects offers a long-term",
    "start": "153200",
    "end": "158319"
  },
  {
    "text": "storage for our metrics a global view of data they are horizontally scalable",
    "start": "158319",
    "end": "164560"
  },
  {
    "text": "and making sure our metrics are highly available and durable all these solutions provide replication",
    "start": "164560",
    "end": "170560"
  },
  {
    "text": "of time series data across regions and or availability zones",
    "start": "170560",
    "end": "176160"
  },
  {
    "text": "so it sounds like all of these tools are doing pretty much the same things how can we compare them",
    "start": "176160",
    "end": "183760"
  },
  {
    "text": "well we decided to focus on different aspects that can be categorized according to four general categories",
    "start": "183760",
    "end": "190560"
  },
  {
    "text": "performance high availability cost and operational complexity i will start",
    "start": "190560",
    "end": "197200"
  },
  {
    "text": "by reviewing each one of the architectures so we can understand what are the pros and cons of each",
    "start": "197200",
    "end": "203280"
  },
  {
    "text": "and be able to compare all of them by the end eventually i will tell you what we chose",
    "start": "203280",
    "end": "208799"
  },
  {
    "text": "to use but please remember that our choice was made before some new features were added to this project one last note",
    "start": "208799",
    "end": "217280"
  },
  {
    "text": "i will focus only on the right path and the read or query path of the architectures and will not show",
    "start": "217280",
    "end": "223920"
  },
  {
    "text": "all of the components such as the components that help us run rules over samples",
    "start": "223920",
    "end": "229040"
  },
  {
    "text": "and integrate with the alert manager this is to help us main focus on the main",
    "start": "229040",
    "end": "235360"
  },
  {
    "text": "differences between these projects so let's start by talking about m3",
    "start": "235360",
    "end": "243200"
  },
  {
    "start": "238000",
    "end": "603000"
  },
  {
    "text": "so m3 was originally developed by the observability team at uber with the goal of providing teams with",
    "start": "243200",
    "end": "249519"
  },
  {
    "text": "highly available and centralized metrics platform it's an open source project under the",
    "start": "249519",
    "end": "254879"
  },
  {
    "text": "apache tool license the foundation of the platform is m3db a",
    "start": "254879",
    "end": "260320"
  },
  {
    "text": "distributed time series database or ksdb that has a built-in replication of time",
    "start": "260320",
    "end": "266479"
  },
  {
    "text": "series data points across nodes on different availability zones and or regions",
    "start": "266479",
    "end": "272320"
  },
  {
    "text": "m3 is based on a push-based model meaning the prometheus from servers use",
    "start": "272320",
    "end": "278240"
  },
  {
    "text": "remote right api to push data to m3 so let's start by understanding",
    "start": "278240",
    "end": "283919"
  },
  {
    "text": "how the right path works first of all prometheus scrapes metrics as we know",
    "start": "283919",
    "end": "290240"
  },
  {
    "text": "then the m3 coordinator which can be deployed as a sidecar alongside prometheus gets promethia's remote write",
    "start": "290240",
    "end": "297520"
  },
  {
    "text": "request it can also get prometheus remote read request as we will see in a moment",
    "start": "297520",
    "end": "302800"
  },
  {
    "text": "as its name implies it's responsible for coordinating rights and routes in amp3d once matrix gets to",
    "start": "302800",
    "end": "310400"
  },
  {
    "text": "m3db writes are compressed in memory and eventually flash to the disk",
    "start": "310400",
    "end": "316240"
  },
  {
    "text": "the duration the data will remain in memory depends on the configured block size",
    "start": "316240",
    "end": "321440"
  },
  {
    "text": "which is the duration of time dictating how long new writes will be compressed in memory before being flushed to the",
    "start": "321440",
    "end": "328479"
  },
  {
    "text": "disk for example block size can be set to 2 hours there is also xcd which stores the",
    "start": "328479",
    "end": "335280"
  },
  {
    "text": "metadata used by each of the components it means that the m3 coordinator and",
    "start": "335280",
    "end": "340320"
  },
  {
    "text": "m3db relies on lcd as a source of truth for clustering management",
    "start": "340320",
    "end": "346400"
  },
  {
    "text": "basically we can start by writing only the m3 coordinator and m3db with xcd you can also add another component",
    "start": "346400",
    "end": "354320"
  },
  {
    "text": "the m3 aggregator that runs a dedicated metrics aggregator and provides stream",
    "start": "354320",
    "end": "359759"
  },
  {
    "text": "based down sampling before metrics are stored in m3db based on dynamic rules stored in",
    "start": "359759",
    "end": "366479"
  },
  {
    "text": "activity so this is the right path what about the read path well",
    "start": "366479",
    "end": "372880"
  },
  {
    "text": "under it path grafana or other api client sends its query to amp's required this",
    "start": "372880",
    "end": "379360"
  },
  {
    "text": "component is responsible for exposing the metrics and metadata of the time series stored",
    "start": "379360",
    "end": "385120"
  },
  {
    "text": "in m3db so for writes to m3db we use a dedicated deployment of m3 coordinator instances",
    "start": "385120",
    "end": "393039"
  },
  {
    "text": "and then for queries we can use a dedicated deployment of m3 query instances note that it's also",
    "start": "393039",
    "end": "399520"
  },
  {
    "text": "possible to use just the m3 coordinator if we don't mind the degree path",
    "start": "399520",
    "end": "405120"
  },
  {
    "text": "and the right path won't be isolated in order to support efficient rates m3db",
    "start": "405120",
    "end": "411840"
  },
  {
    "text": "implements various catching policies that determine which fast blocks are kept in memory and",
    "start": "411840",
    "end": "418479"
  },
  {
    "text": "which are not so that's another thing that improved performance and as we saw previously xcd stores the",
    "start": "418479",
    "end": "425840"
  },
  {
    "text": "metadata used by each of the components so what are the advantages of m3",
    "start": "425840",
    "end": "433360"
  },
  {
    "text": "first of all data resides within the cluster on disk and replicated between",
    "start": "433360",
    "end": "438400"
  },
  {
    "text": "availability zones and or regions there is no use of cloud storage service",
    "start": "438400",
    "end": "443840"
  },
  {
    "text": "such as s3 or google code storage which means that a bandwidth costs are",
    "start": "443840",
    "end": "449599"
  },
  {
    "text": "relatively low so if you're running things both on prem and on cloud",
    "start": "449599",
    "end": "454639"
  },
  {
    "text": "it might be a good idea for you to use m3 since cloud bandwidth cost might be high when moving data between",
    "start": "454639",
    "end": "461039"
  },
  {
    "text": "the cloud and on-prem data centers and b it means lower latency which of",
    "start": "461039",
    "end": "466319"
  },
  {
    "text": "course means a better performance fetching data from an object store like amazon s3",
    "start": "466319",
    "end": "472160"
  },
  {
    "text": "might be slower than using local disk it's also a push-based model system",
    "start": "472160",
    "end": "477199"
  },
  {
    "text": "prometheus uses remote right api to send data to m3 which also have some advantages in",
    "start": "477199",
    "end": "483759"
  },
  {
    "text": "particular in use cases where you have ephemeral cluster or in terms of availability",
    "start": "483759",
    "end": "489840"
  },
  {
    "text": "if the prometheus server becomes unavailable all data up to that point is still available for queries",
    "start": "489840",
    "end": "497360"
  },
  {
    "text": "there are a few components as you saw which might make it easier to deploy so",
    "start": "497360",
    "end": "503840"
  },
  {
    "text": "any terms of caching queries there are various caching policies you can implement in order to support",
    "start": "503840",
    "end": "509840"
  },
  {
    "text": "efficient trees so we can see how the m3 solution is really focused on being a",
    "start": "509840",
    "end": "516719"
  },
  {
    "text": "system that can manage huge amounts of data even petabytes of metrics with the primary concern",
    "start": "516719",
    "end": "522800"
  },
  {
    "text": "to scale monitoring horizontally in a cost effective nature but the m3 solution also has some cons",
    "start": "522800",
    "end": "531920"
  },
  {
    "text": "m3db might be complex to operate after all it's another database in your",
    "start": "531920",
    "end": "537120"
  },
  {
    "text": "infrastructure that you need to take care of and learn how to bootstrap and recover i will mention that there is",
    "start": "537120",
    "end": "544560"
  },
  {
    "text": "a m3db operator that aims to automate everyday tasks around managing m3bb",
    "start": "544560",
    "end": "551600"
  },
  {
    "text": "but it doesn't automate every single edge case i will also mention that i found the m3",
    "start": "551600",
    "end": "557120"
  },
  {
    "text": "official documentation lacking and it might be harder to understand deploy and debug it as a result",
    "start": "557120",
    "end": "565200"
  },
  {
    "text": "second thing to consider is that m3 requires external dependency at cd so",
    "start": "565200",
    "end": "571519"
  },
  {
    "text": "it's eventually one more cluster you need to take care of and lastly the push-based model also",
    "start": "571519",
    "end": "577680"
  },
  {
    "text": "have some disadvantages it might be more complex than a pool-based system like thanos",
    "start": "577680",
    "end": "583760"
  },
  {
    "text": "we will discuss about it later on and shipping samples from prometheus over the network immediately as they are",
    "start": "583760",
    "end": "590480"
  },
  {
    "text": "scraped is not very efficient so after understanding some of the advantages and",
    "start": "590480",
    "end": "596959"
  },
  {
    "text": "disadvantages of m3 let's talk about other solution to our",
    "start": "596959",
    "end": "602000"
  },
  {
    "text": "issues cortex cortex is in cncf",
    "start": "602000",
    "end": "607839"
  },
  {
    "start": "603000",
    "end": "1041000"
  },
  {
    "text": "incubating project and another solution for horizontally scalable highly available long-term prometheus",
    "start": "607839",
    "end": "615040"
  },
  {
    "text": "its initial focus was mainly on scalability and high performance and later on in",
    "start": "615040",
    "end": "620160"
  },
  {
    "text": "collaboration with thanos team the cortex team also added other focuses to the cortex architecture",
    "start": "620160",
    "end": "627519"
  },
  {
    "text": "when talking about cortex we can separate our discussion into two chunk storage the storage that cortex",
    "start": "627519",
    "end": "633680"
  },
  {
    "text": "started with and block storage the support for which was added recently with the help of the thanos project",
    "start": "633680",
    "end": "640079"
  },
  {
    "text": "during their collaboration most of the cortex architecture is quite the same on",
    "start": "640079",
    "end": "645519"
  },
  {
    "text": "these two use cases but there are differences regarding the pros and cons and what we can get",
    "start": "645519",
    "end": "651839"
  },
  {
    "text": "let's start by talking but taking a look at the cortex architecture in case chunk storage is in use",
    "start": "651839",
    "end": "660079"
  },
  {
    "text": "cortex like m3 also uses push-based model which means that widgets server use",
    "start": "660079",
    "end": "666640"
  },
  {
    "text": "remote right api to push data to cortex so when talking about the right path",
    "start": "666640",
    "end": "672480"
  },
  {
    "text": "prometheus servers scrape samples from various targets and use prometheus remote right api to",
    "start": "672480",
    "end": "679279"
  },
  {
    "text": "push data to the distributors the distributors are responsible for validating the samples",
    "start": "679279",
    "end": "685760"
  },
  {
    "text": "they get and can also deduplicate incoming samples from multiple ha replicas of the same prometheus",
    "start": "685760",
    "end": "692480"
  },
  {
    "text": "servers in order to coordinate which replica is currently elected as the leader",
    "start": "692480",
    "end": "698160"
  },
  {
    "text": "the only replica the distributor will accept samples from it's needed to have a key value store",
    "start": "698160",
    "end": "703760"
  },
  {
    "text": "where the data about the elected replica is saved and it can be console or at cd",
    "start": "703760",
    "end": "710160"
  },
  {
    "text": "then the valid samples are split into batches and sent to multiple ingestors in",
    "start": "710160",
    "end": "715200"
  },
  {
    "text": "parallel on the right path the ingestor will be responsible for writing incoming series",
    "start": "715200",
    "end": "721519"
  },
  {
    "text": "to a long-term story the incoming series are kept in memory for a while and periodically flushed to",
    "start": "721519",
    "end": "728160"
  },
  {
    "text": "the storage there are different solutions to prevent data loss of in-memory series that have",
    "start": "728160",
    "end": "733440"
  },
  {
    "text": "not yet been flushed to the long-term storage by using multiple replicas of each time",
    "start": "733440",
    "end": "738880"
  },
  {
    "text": "series in the ingesters and or by using right headlog which is used to write to a persistent disk",
    "start": "738880",
    "end": "745200"
  },
  {
    "text": "all incoming serious samples until they are flashed to the long term storage",
    "start": "745200",
    "end": "750800"
  },
  {
    "text": "so the ingestors will batch and compress samples in memory and will periodically flush them out to",
    "start": "750800",
    "end": "756720"
  },
  {
    "text": "the long long-term storage so when talking about chunk storage each single time series",
    "start": "756720",
    "end": "762639"
  },
  {
    "text": "is stored in a separate object called chunk that contains the samples for a given period",
    "start": "762639",
    "end": "768560"
  },
  {
    "text": "defaults to 12 hours the chunks are indexed by time range and labels in",
    "start": "768560",
    "end": "774160"
  },
  {
    "text": "order to provide a fast lookup across chunks the index will be kept in a key",
    "start": "774160",
    "end": "779519"
  },
  {
    "text": "value store amazon dynamodb google big table or apache cassandra",
    "start": "779519",
    "end": "785120"
  },
  {
    "text": "and the chunks will be kept in object store such as amazon s3 dynamodb google cloud storage or",
    "start": "785120",
    "end": "791920"
  },
  {
    "text": "microsoft azure storage note that for example if we are talking about aws",
    "start": "791920",
    "end": "798480"
  },
  {
    "text": "you can store the chunks in s3 and index in dynamodb or put everything in",
    "start": "798480",
    "end": "803839"
  },
  {
    "text": "dynamodb using just s3 is not an option unless you use the block storage engine",
    "start": "803839",
    "end": "810800"
  },
  {
    "text": "that we will discuss in a moment so we talked about the right path but again what about the read path",
    "start": "810800",
    "end": "819519"
  },
  {
    "text": "when we query data we can do so by sending the query directly to the query or to the query front end the query",
    "start": "819760",
    "end": "827360"
  },
  {
    "text": "frontend is used to accelerate the read path it can optionally split the query and",
    "start": "827360",
    "end": "832480"
  },
  {
    "text": "serve it from the cache the query front-end stores the query into in-memory queue",
    "start": "832480",
    "end": "838160"
  },
  {
    "text": "and then the query or component picks it up and executes it the query are fetch samples",
    "start": "838160",
    "end": "844800"
  },
  {
    "text": "from the in-memory series samples in the investors and the long-term storage",
    "start": "844800",
    "end": "850000"
  },
  {
    "text": "while executing query because the ingesters hold the in-memory series that have not yet been flushed",
    "start": "850000",
    "end": "857279"
  },
  {
    "text": "finally courier sends results back to the query front-end which then forwards it to the client the",
    "start": "857279",
    "end": "864399"
  },
  {
    "text": "query front-end is an important component thanos also added to their architecture lately",
    "start": "864399",
    "end": "870079"
  },
  {
    "text": "because of some important features splitting the query frontend split queries of",
    "start": "870079",
    "end": "875440"
  },
  {
    "text": "multiple days into multiple single day queries it gives us the ability to execute",
    "start": "875440",
    "end": "880800"
  },
  {
    "text": "queries in parallel on downstream queries which means a faster query execution and b it",
    "start": "880800",
    "end": "887600"
  },
  {
    "text": "prevents out of memory issues when executing large multi-day queries",
    "start": "887600",
    "end": "892800"
  },
  {
    "text": "it also provides caching it supports caching query results using memcache strategies or an",
    "start": "892800",
    "end": "899040"
  },
  {
    "text": "in-memory cache in queueing it has a queuing mechanism that is used for different purposes",
    "start": "899040",
    "end": "905920"
  },
  {
    "text": "including retry on failure of large queries in case of om errors in the query",
    "start": "905920",
    "end": "912320"
  },
  {
    "text": "in addition to the cache that the query frontend uses in order to keep the results of a world query",
    "start": "912320",
    "end": "917839"
  },
  {
    "text": "i want us to notice that there are additional caching layers the chan cache that stores recent",
    "start": "917839",
    "end": "924160"
  },
  {
    "text": "immutable compressed chunks and is used by queries to reduce load on the chunk store",
    "start": "924160",
    "end": "930240"
  },
  {
    "text": "and the index cache index rate cache that stores entire rows from the index",
    "start": "930240",
    "end": "935920"
  },
  {
    "text": "and is used by queries to reduce slowly on the index and the index right cache that is used",
    "start": "935920",
    "end": "942639"
  },
  {
    "text": "for deduplication and reducing load on the database by avoiding rewriting index and chunk",
    "start": "942639",
    "end": "948959"
  },
  {
    "text": "data that has already been stored so after going over the chunk storage",
    "start": "948959",
    "end": "954320"
  },
  {
    "text": "architecture let's talk about block storage a block storage architecture is actually",
    "start": "954320",
    "end": "961680"
  },
  {
    "text": "based on thanos architecture the block storage itself is based on prometheus dsdb",
    "start": "961680",
    "end": "968079"
  },
  {
    "text": "it stores each tenant's time series into their own psdb the in-memory samples in the ingestors",
    "start": "968079",
    "end": "975279"
  },
  {
    "text": "will be flashed when a new tsdb block is created in default to two hours",
    "start": "975279",
    "end": "980720"
  },
  {
    "text": "block range periods to an object store such as amazon s3 google cloud storage etc",
    "start": "980720",
    "end": "987920"
  },
  {
    "text": "in this architecture there are two additional components that are based on thanos components",
    "start": "987920",
    "end": "993199"
  },
  {
    "text": "as we will see soon first the store gathway that query blocks from the object store",
    "start": "993199",
    "end": "1000079"
  },
  {
    "text": "and is used by the querier at query time it also uses index cache ton cache and",
    "start": "1000079",
    "end": "1005600"
  },
  {
    "text": "metadata cache in order to speed up queries and reduce the number of api calls",
    "start": "1005600",
    "end": "1011360"
  },
  {
    "text": "to object storage and there is also the compactor which is responsible for reducing the",
    "start": "1011360",
    "end": "1017440"
  },
  {
    "text": "number of blocks stored in the long term storage by merging and duplicating smaller blocks into larger",
    "start": "1017440",
    "end": "1024319"
  },
  {
    "text": "ones and by that also making them query more efficiently there are additional components options",
    "start": "1024319",
    "end": "1031038"
  },
  {
    "text": "and abilities i didn't talk about but looking at the cortex architecture we can point already points",
    "start": "1031039",
    "end": "1037600"
  },
  {
    "text": "some of the advantages cortex gives us it gives us the ability to use chunk",
    "start": "1037600",
    "end": "1044319"
  },
  {
    "start": "1041000",
    "end": "1165000"
  },
  {
    "text": "storage in case we are putting performance at the top of our priorities",
    "start": "1044319",
    "end": "1049440"
  },
  {
    "text": "chunk storage is faster than block storage we can also decide to use block storage",
    "start": "1049440",
    "end": "1055120"
  },
  {
    "text": "when we are putting simplicity and cost reduction at the top of our priorities clock",
    "start": "1055120",
    "end": "1060720"
  },
  {
    "text": "storage is eventually cheaper than chunk storage for example s3 costs",
    "start": "1060720",
    "end": "1066559"
  },
  {
    "text": "are lower than dynamodb costs plus it's much more simple to use only s3 bucket",
    "start": "1066559",
    "end": "1072559"
  },
  {
    "text": "than to use and take care of an extra dynamodb table cortex also gives us lots of",
    "start": "1072559",
    "end": "1079280"
  },
  {
    "text": "caching layers which can improve performance significantly",
    "start": "1079280",
    "end": "1084799"
  },
  {
    "text": "there is also the query front end which allows query parallelization and results caching which also have",
    "start": "1084799",
    "end": "1092880"
  },
  {
    "text": "which also have a great impact on performance and the push-based model that cortex is",
    "start": "1092880",
    "end": "1099120"
  },
  {
    "text": "based on also offers multiple benefits in terms of performance prometheus push",
    "start": "1099120",
    "end": "1105919"
  },
  {
    "text": "data to cortex so if the cluster you are collecting the matrix from and the",
    "start": "1105919",
    "end": "1111120"
  },
  {
    "text": "cluster where the query is are far away geographically keeping all the data in cortex",
    "start": "1111120",
    "end": "1116799"
  },
  {
    "text": "will decrease query latency there won't be any gaps in the graphs caused by",
    "start": "1116799",
    "end": "1122240"
  },
  {
    "text": "prometheus restart because the pushes happen as soon as the data is scraped even if one of the leafs of prometheus",
    "start": "1122240",
    "end": "1128640"
  },
  {
    "text": "server is down you will not see gaps in the data and again in terms of availability",
    "start": "1128640",
    "end": "1134480"
  },
  {
    "text": "when an edge location becomes unavailable all data up to date point is still available",
    "start": "1134480",
    "end": "1139520"
  },
  {
    "text": "centrally also it's a great option if you don't want to enable ingest to your clusters",
    "start": "1139520",
    "end": "1145840"
  },
  {
    "text": "and basically it offers all the advantages of the push-based system we talked about earlier when we talked",
    "start": "1145840",
    "end": "1152559"
  },
  {
    "text": "about m3 so we can really see how cortex has been designed",
    "start": "1152559",
    "end": "1157600"
  },
  {
    "text": "with focus on high performance of long-term storage but there are some disadvantages as well",
    "start": "1157600",
    "end": "1166240"
  },
  {
    "text": "some people might find it more complex system than others because it includes relatively large",
    "start": "1166240",
    "end": "1172000"
  },
  {
    "text": "number of components the cortex team did added the ability to run cortex as a single binary",
    "start": "1172000",
    "end": "1178720"
  },
  {
    "text": "which means a single deployment which makes things easier but in production systems it's",
    "start": "1178720",
    "end": "1184240"
  },
  {
    "text": "recommended to deploy as multiple independent microservices so you can tune and configure the",
    "start": "1184240",
    "end": "1190559"
  },
  {
    "text": "different components secondly in order to use all of its",
    "start": "1190559",
    "end": "1195760"
  },
  {
    "text": "features such as the duplicating you rely on external dependencies such as at cd or console eventually",
    "start": "1195760",
    "end": "1204000"
  },
  {
    "text": "those are more moving parts to deploy operate and monitor the push-based model",
    "start": "1204000",
    "end": "1210400"
  },
  {
    "text": "that we mentioned already also have some cons as we mentioned before",
    "start": "1210400",
    "end": "1215440"
  },
  {
    "text": "extra complexity and resources you need to manage separate cortex cluster and storage on",
    "start": "1215440",
    "end": "1221360"
  },
  {
    "text": "top of your prometheus deployment if your network has momentary issues and",
    "start": "1221360",
    "end": "1226400"
  },
  {
    "text": "the e-memory buffer of prometheus cannot hold more data you might end up losing some of the data",
    "start": "1226400",
    "end": "1232960"
  },
  {
    "text": "and shipping metrics over the network immediately as they are scraped to a remote storage is not so",
    "start": "1232960",
    "end": "1238720"
  },
  {
    "text": "efficient and might cause data loss if the network is flaking",
    "start": "1238720",
    "end": "1244640"
  },
  {
    "text": "lastly the different storage types have some trade-offs as well chunk storage gives us great performance",
    "start": "1244640",
    "end": "1251600"
  },
  {
    "text": "but is expensive when comparing to the block storage and it's an additional resources that",
    "start": "1251600",
    "end": "1257360"
  },
  {
    "text": "need to be taken care of block storage is cheaper and simpler but",
    "start": "1257360",
    "end": "1262799"
  },
  {
    "text": "its performance is lower so we saw that cortex can offer us multiple ways to deploy it",
    "start": "1262799",
    "end": "1269200"
  },
  {
    "text": "each has its own trade-offs as i mentioned before the cortex team worked closely with the",
    "start": "1269200",
    "end": "1275200"
  },
  {
    "text": "palestine so both cortex and thanos added components and abilities that eventually improved",
    "start": "1275200",
    "end": "1281919"
  },
  {
    "text": "their solution and added more options and abilities",
    "start": "1281919",
    "end": "1287600"
  },
  {
    "start": "1287000",
    "end": "1555000"
  },
  {
    "text": "so let's see what thanos architecture looks like and how their collaboration with cortex bettered it tennis is also a cncf",
    "start": "1287919",
    "end": "1297120"
  },
  {
    "text": "incubating project and is a solution for highly available prometheus with long-term storage its initial focus",
    "start": "1297120",
    "end": "1304640"
  },
  {
    "text": "was on operational simplicity and cost-effectiveness but as cortex added new capabilities",
    "start": "1304640",
    "end": "1311039"
  },
  {
    "text": "that were inspired from thanos thanos also added improvements that were inspired from cortex",
    "start": "1311039",
    "end": "1318640"
  },
  {
    "text": "contrary to cortex thanos originally used a pool based model architecture that means",
    "start": "1318640",
    "end": "1326400"
  },
  {
    "text": "that thanos pulls out serious front parties at query time",
    "start": "1326400",
    "end": "1332320"
  },
  {
    "text": "later on inspired by the cortex push-based model the thanos team added support for",
    "start": "1332320",
    "end": "1338000"
  },
  {
    "text": "push-based model as well let's take a look at a sinus pool based model",
    "start": "1338000",
    "end": "1343360"
  },
  {
    "text": "starting again with your ipad in thanos there is a thunderside card to transit",
    "start": "1343360",
    "end": "1348960"
  },
  {
    "text": "in the same pod as the prometheus server its purpose is to upload data tsdb",
    "start": "1348960",
    "end": "1354880"
  },
  {
    "text": "blocks and to an object storage such as iws s3 google cloud storage or microsoft",
    "start": "1354880",
    "end": "1362720"
  },
  {
    "text": "azure storage and to give other tennis components access to this",
    "start": "1362720",
    "end": "1368080"
  },
  {
    "text": "time series data in prometheus as we will see when we will talk about the query path",
    "start": "1368080",
    "end": "1374880"
  },
  {
    "text": "sidecar uploads the tsdb blocks to an object storage as prometheus produces them every two",
    "start": "1374880",
    "end": "1381120"
  },
  {
    "text": "hours this gives us the ability to configure prometheus servers to run with relatively low tension",
    "start": "1381120",
    "end": "1388960"
  },
  {
    "text": "notice that using this model means prometheus cannot be fully stateless",
    "start": "1388960",
    "end": "1394400"
  },
  {
    "text": "if it crashes or restarts the last two hours of metrics will be lost",
    "start": "1394400",
    "end": "1399840"
  },
  {
    "text": "so persistent disk for prometheus is still needed using prometheus remote right api gets",
    "start": "1399840",
    "end": "1405919"
  },
  {
    "text": "you closer to stateless prometheus but it still won't be fully stateless",
    "start": "1405919",
    "end": "1411360"
  },
  {
    "text": "so it is still always recommended to have a persistent disk",
    "start": "1411360",
    "end": "1416400"
  },
  {
    "text": "we can see how the right path here is super easy you can actually only add the channel sidecar to your prometheus pods",
    "start": "1416400",
    "end": "1423440"
  },
  {
    "text": "and configure your object storage in order to save long-term data what's great about thanos is that",
    "start": "1423440",
    "end": "1430159"
  },
  {
    "text": "features can be deployed independently of each other you can start",
    "start": "1430159",
    "end": "1435679"
  },
  {
    "text": "by only deploying a side car and gradually add other components to use and deploy",
    "start": "1435679",
    "end": "1441520"
  },
  {
    "text": "other features now let's talk about the query path",
    "start": "1441520",
    "end": "1446799"
  },
  {
    "text": "graffana or other api client sends its query to the thanos query component then the query",
    "start": "1446799",
    "end": "1453919"
  },
  {
    "text": "component aggregates and it duplicates data from the underlying components",
    "start": "1453919",
    "end": "1459279"
  },
  {
    "text": "it query recent metrics from the thanos sidecar which exposes prometheus metrics and",
    "start": "1459279",
    "end": "1465360"
  },
  {
    "text": "older metrics from the store gateway the stargateway query metrics from the object store",
    "start": "1465360",
    "end": "1471360"
  },
  {
    "text": "and also supports an index cache and experimental caching budget with chunks and metadata caching using",
    "start": "1471360",
    "end": "1477840"
  },
  {
    "text": "memcached or in-memory cache to speed up loading of chunks from tsdb blocks",
    "start": "1477840",
    "end": "1484240"
  },
  {
    "text": "there is also the compactor that scans the object storage and is responsible for",
    "start": "1484240",
    "end": "1490080"
  },
  {
    "text": "contacting data and down sampling blocks in order to speed up queries as for the",
    "start": "1490080",
    "end": "1495679"
  },
  {
    "text": "other projects there are other components such as ruler that we want focus on",
    "start": "1495679",
    "end": "1501600"
  },
  {
    "text": "so as the sun the thanos and cortex team started to collaborate it has been decided to add optional",
    "start": "1501600",
    "end": "1508640"
  },
  {
    "text": "multiple components as well the query front-end that can be put in",
    "start": "1508640",
    "end": "1514960"
  },
  {
    "text": "front of thanos queries to improve the read path in order to have some important features like",
    "start": "1514960",
    "end": "1520880"
  },
  {
    "text": "splitting and results caching it is based on the cortex query front-end component",
    "start": "1520880",
    "end": "1526880"
  },
  {
    "text": "that we mentioned before note that at the moment only range queries can be",
    "start": "1526880",
    "end": "1532000"
  },
  {
    "text": "splitted and cached those are the only queries that the query that the thanos query front end can",
    "start": "1532000",
    "end": "1538720"
  },
  {
    "text": "process at the moment thanos team also added the option to use a push-based model",
    "start": "1538720",
    "end": "1545520"
  },
  {
    "text": "by adding a component named receiver which receives data from prometheus remote right and",
    "start": "1545520",
    "end": "1552400"
  },
  {
    "text": "uploads it to an object storage so again we can point to some of the",
    "start": "1552400",
    "end": "1558640"
  },
  {
    "text": "advantages planners offer us by looking at its architecture",
    "start": "1558640",
    "end": "1564720"
  },
  {
    "text": "first its architecture is relatively simple we can gradually install its components",
    "start": "1564720",
    "end": "1571440"
  },
  {
    "text": "storing long-term data in a block storage gives us as we mentioned regarding cortex",
    "start": "1571440",
    "end": "1576799"
  },
  {
    "text": "simplicity and cost reduction we talked about the pros and cons of a push-based model",
    "start": "1576799",
    "end": "1583520"
  },
  {
    "text": "before and the same applies here we also have the option of using the pool based model",
    "start": "1583520",
    "end": "1589679"
  },
  {
    "text": "which is the classic one when talking about funnels the pool based model gives us simplicity",
    "start": "1589679",
    "end": "1595919"
  },
  {
    "text": "and it makes the right path more efficient because it ships full compressed blocks every two hours by default",
    "start": "1595919",
    "end": "1602640"
  },
  {
    "text": "which can also prevent data lost in case of network issues that last more than few minutes and lastly",
    "start": "1602640",
    "end": "1609679"
  },
  {
    "text": "it its recently added query front end can improve performance",
    "start": "1609679",
    "end": "1614799"
  },
  {
    "text": "looking at these advantages we can see how in thanos case its main focus is indeed on operational",
    "start": "1614799",
    "end": "1621039"
  },
  {
    "text": "simplicity and cost effectiveness but again there are some disadvantages",
    "start": "1621039",
    "end": "1628640"
  },
  {
    "start": "1624000",
    "end": "1687000"
  },
  {
    "text": "the block storage is slower than the alternative storage solution that cortex and m3 offers",
    "start": "1628640",
    "end": "1636000"
  },
  {
    "text": "the same cons of the push-based model that we talked about also apply here but there are also",
    "start": "1636000",
    "end": "1643120"
  },
  {
    "text": "trade-offs when we talk about pool based model it means that the data from the last two",
    "start": "1643120",
    "end": "1649679"
  },
  {
    "text": "hours is less durable samples aren't being saved immediately through remote storage",
    "start": "1649679",
    "end": "1654960"
  },
  {
    "text": "which means we cannot access data from the last two hours if there are network issues and we can",
    "start": "1654960",
    "end": "1660880"
  },
  {
    "text": "even lose it if prometheus goes down it might also have worse latency for the",
    "start": "1660880",
    "end": "1666480"
  },
  {
    "text": "query path if the cluster you are collecting the metrics from meaning where the prometheus servers are",
    "start": "1666480",
    "end": "1673679"
  },
  {
    "text": "and the cluster where the query is located are distanced geographically and there is not as much",
    "start": "1673679",
    "end": "1680720"
  },
  {
    "text": "caching query front-end only caches range queries as we mentioned before",
    "start": "1680720",
    "end": "1687679"
  },
  {
    "start": "1687000",
    "end": "1741000"
  },
  {
    "text": "so now after going over the architectures of each solution let's see how the four categories i",
    "start": "1688559",
    "end": "1695120"
  },
  {
    "text": "mentioned in the beginning are satisfied or not our four categories were performance",
    "start": "1695120",
    "end": "1702399"
  },
  {
    "text": "high availability operational complexity and cost this is a summary of all that we talked",
    "start": "1702399",
    "end": "1709200"
  },
  {
    "text": "about and based on this comparison comparison we can see the trade-offs that each",
    "start": "1709200",
    "end": "1714720"
  },
  {
    "text": "solution offer us there are other aspects that can be compared that we didn't talk about",
    "start": "1714720",
    "end": "1721440"
  },
  {
    "text": "but the bottom line is that i think all of these solutions are great i'm pretty positive you will",
    "start": "1721440",
    "end": "1727840"
  },
  {
    "text": "be satisfied with with whichever solution you choose but there are some differences that",
    "start": "1727840",
    "end": "1734480"
  },
  {
    "text": "might make one of these tools and better match with your needs and architecture",
    "start": "1734480",
    "end": "1741600"
  },
  {
    "start": "1741000",
    "end": "1832000"
  },
  {
    "text": "there are also other aspects according to which we can compare the solutions",
    "start": "1742320",
    "end": "1747679"
  },
  {
    "text": "for example from ql compatibility according to chromelab's latest test",
    "start": "1747679",
    "end": "1754000"
  },
  {
    "text": "this is the chrome ql compatibility of m3 tunnels and cortex official documentation",
    "start": "1754000",
    "end": "1762720"
  },
  {
    "text": "as i said i do find m3 official dogs lacking and they also mentioned in the official",
    "start": "1762720",
    "end": "1768960"
  },
  {
    "text": "docks that additional work is still needed i personally enjoyed cortex to",
    "start": "1768960",
    "end": "1774640"
  },
  {
    "text": "fermentation the dust but thanos also has grey ducks",
    "start": "1774640",
    "end": "1779840"
  },
  {
    "text": "we're talking about installation via hound charts you can find helm charts for all of",
    "start": "1779840",
    "end": "1785039"
  },
  {
    "text": "these tools but take note that cortex does mention that their official hound shot still needs work that the m3",
    "start": "1785039",
    "end": "1793440"
  },
  {
    "text": "offers only a home chart for the m3db operator and the sanos does not have",
    "start": "1793440",
    "end": "1800960"
  },
  {
    "text": "an official hunter but does have multiple community home charts options",
    "start": "1800960",
    "end": "1808399"
  },
  {
    "text": "if you are using the q prometheus stack helm chart the prometheus community chart that many",
    "start": "1808399",
    "end": "1814480"
  },
  {
    "text": "use including us by the way to install prometheus operator prometheus rafana alert manager and more",
    "start": "1814480",
    "end": "1822720"
  },
  {
    "text": "you already have built-in integration with thanos and you can configure the",
    "start": "1822720",
    "end": "1828880"
  },
  {
    "text": "standard sidecar very easily so at this point i'm quite sure you're",
    "start": "1828880",
    "end": "1835919"
  },
  {
    "start": "1832000",
    "end": "1880000"
  },
  {
    "text": "asking yourself okay so what did you choose we eventually decided to go with thanos",
    "start": "1835919",
    "end": "1844640"
  },
  {
    "text": "we wanted to keep it simple fast offers a good enough performance for our use",
    "start": "1844640",
    "end": "1849679"
  },
  {
    "text": "case its costs are relatively low the cube prometheus stock helm chart",
    "start": "1849679",
    "end": "1855200"
  },
  {
    "text": "which we use has ability and support to install the standard sidecar so it's hot the thanos answered our",
    "start": "1855200",
    "end": "1862000"
  },
  {
    "text": "needs best then again all of these solutions have",
    "start": "1862000",
    "end": "1867120"
  },
  {
    "text": "pros and cons the best way for you to choose one is simply to decide on your priorities",
    "start": "1867120",
    "end": "1874000"
  },
  {
    "text": "and that's it thank you for your time and i'm available for questions",
    "start": "1874000",
    "end": "1879840"
  }
]
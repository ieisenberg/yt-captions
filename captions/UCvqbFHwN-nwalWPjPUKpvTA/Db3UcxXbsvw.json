[
  {
    "text": "uh we will be talking about Project Era and uh let's start with interactions okay I'm gonna introduce myself I'm",
    "start": "10200",
    "end": "17820"
  },
  {
    "text": "Jorge turado the first one obviously doesn't match with my face I'm SRI",
    "start": "17820",
    "end": "24180"
  },
  {
    "text": "expert at a little the international Hub AKA smart group I'm Keda maintainer and",
    "start": "24180",
    "end": "31260"
  },
  {
    "text": "also I'm cncf Ambassador and Microsoft MVP in developer Technologies and Azure",
    "start": "31260",
    "end": "37380"
  },
  {
    "text": "and you have there my connection or my my handle for Twitter GitHub and Linkedin you can send a fire request or",
    "start": "37380",
    "end": "45780"
  },
  {
    "text": "write me whatever you want and the state is yours thank you so my name is robotic",
    "start": "45780",
    "end": "50820"
  },
  {
    "text": "I'm from Czech Republic I'm engineer working at redhead in openg serverless",
    "start": "50820",
    "end": "56340"
  },
  {
    "text": "team and a long time kind of maintainer I'm also acted in a native community so I'm a",
    "start": "56340",
    "end": "62640"
  },
  {
    "text": "member of the creative DLC and let's start it right so uh we will quickly tell you what what",
    "start": "62640",
    "end": "71159"
  },
  {
    "text": "is Keda we will describe some new features that we have some best practices and it will see a demo hopefully and before we start actually I",
    "start": "71159",
    "end": "78600"
  },
  {
    "text": "would like to ask you a question so who knows Keda in this in his room can you please raise your hand",
    "start": "78600",
    "end": "83780"
  },
  {
    "text": "users are you interested on being listed so uh and who are the users of kid",
    "start": "83780",
    "end": "89939"
  },
  {
    "text": "actually from Israel okay that's less and is there anybody who is considering using Keda",
    "start": "89939",
    "end": "96119"
  },
  {
    "text": "okay cool I will ask after the presentation did a great job",
    "start": "96119",
    "end": "101700"
  },
  {
    "text": "so what is so let's describe this on a problem so we have an application this",
    "start": "101700",
    "end": "107400"
  },
  {
    "text": "application is some consumer of some data so in this case it could be like a rabbit mqmq consumer it consume messages",
    "start": "107400",
    "end": "114479"
  },
  {
    "text": "from an epidemq and I have a problem I would like to Auto scale this application because the",
    "start": "114479",
    "end": "120420"
  },
  {
    "text": "application is not doing well with during my setup so what are my options",
    "start": "120420",
    "end": "125939"
  },
  {
    "text": "if you use kubernetes there is HPA right so you can Auto scale the kubernetes deployment with HPA but this has",
    "start": "125939",
    "end": "134700"
  },
  {
    "text": "some kind of problem in this car in this setup because if you would like to Auto scale our application",
    "start": "134700",
    "end": "140480"
  },
  {
    "text": "based on CPU or memory which are the only metrics that HPA provides this might not correlate with the actual",
    "start": "140480",
    "end": "147660"
  },
  {
    "text": "needs for our application because our application is consuming messages from some external service in this case from the rabbit so we would like to Auto",
    "start": "147660",
    "end": "153480"
  },
  {
    "text": "scale this application based on the based on some metrics from this external service",
    "start": "153480",
    "end": "158640"
  },
  {
    "text": "so let's let's see the solution the solution is very simple you plug",
    "start": "158640",
    "end": "163860"
  },
  {
    "text": "together in this in this in the setup and what kind of does it just creates metrics from the external endpoint from",
    "start": "163860",
    "end": "170099"
  },
  {
    "text": "the rapidm queue and based on those metrics the decision on on actual Auto scaling the this this application",
    "start": "170099",
    "end": "176940"
  },
  {
    "text": "deployment let's see this in action yeah because torque is cheap let's start with",
    "start": "176940",
    "end": "182580"
  },
  {
    "text": "a demo okay well you already still see we still see",
    "start": "182580",
    "end": "188580"
  },
  {
    "text": "like that oh okay I need to stop the presentation yeah that's it",
    "start": "188580",
    "end": "193980"
  },
  {
    "text": "okay I'm not gonna invest so much time here because basically it's an application",
    "start": "193980",
    "end": "200159"
  },
  {
    "text": "that consumes some messages from from a rabbit and I'm going to deploy an SQL",
    "start": "200159",
    "end": "206340"
  },
  {
    "text": "object we see which is the grappler on top of the HPA that Keda uses so let's",
    "start": "206340",
    "end": "211800"
  },
  {
    "text": "do it Cube CTL apply minus f",
    "start": "211800",
    "end": "218640"
  },
  {
    "text": "simple demo and let's deploy the consumer the publisher sorry so if I go",
    "start": "218640",
    "end": "225599"
  },
  {
    "text": "to that namespace suddenly my deployment is growing now it",
    "start": "225599",
    "end": "230819"
  },
  {
    "text": "has one port but now has four ports and we are not gonna",
    "start": "230819",
    "end": "238680"
  },
  {
    "text": "wait until the demo ends because you can see that it's working I have published some messages and my warlock has a scale",
    "start": "238680",
    "end": "245819"
  },
  {
    "text": "out just for consuming it don't worry in the final demo we go deeper and we check those different things but it's just",
    "start": "245819",
    "end": "253379"
  },
  {
    "text": "like okay I'm gonna tell you about Keda we are gonna talk about that uh speak about Keda works this is the demo for an",
    "start": "253379",
    "end": "261720"
  },
  {
    "text": "ensuring that we are not gonna lie okay okay that works so maybe we can finish it all right now right that's it",
    "start": "261720",
    "end": "269220"
  },
  {
    "text": "thank you thank you for your time now let's continue okay so let's",
    "start": "269220",
    "end": "275280"
  },
  {
    "text": "continue sorry I will keep you a little longer so as you know so Keda is a project that aims kubernetes and Driven",
    "start": "275280",
    "end": "281880"
  },
  {
    "text": "Auto scaling that simple so this is like the our motto and we try to stick to it uh it allows you to Auto scale your",
    "start": "281880",
    "end": "288900"
  },
  {
    "text": "applications your deployments your workloads your kubernetes jobs based on some events happening externally so not",
    "start": "288900",
    "end": "295259"
  },
  {
    "text": "just CPU or memory which is building kubernetes uh to achieve the capabilities we have 60 plus integrated",
    "start": "295259",
    "end": "302220"
  },
  {
    "text": "triggers or event sources so basically those those components are talking to this external Services",
    "start": "302220",
    "end": "309560"
  },
  {
    "text": "Etc this is our web page and this is the community slide so do you want to carry it as a ambassador",
    "start": "310560",
    "end": "317100"
  },
  {
    "text": "give me my opportunities please okay basically Community is more than a small",
    "start": "317100",
    "end": "323580"
  },
  {
    "text": "project and who anyone knows about it we have several big companies like Microsoft Red",
    "start": "323580",
    "end": "331020"
  },
  {
    "text": "Hat spark group Reddit IBM contributing with the code but also use it together",
    "start": "331020",
    "end": "338240"
  },
  {
    "text": "that's the list of listed users who are using Keda on production and there are",
    "start": "338240",
    "end": "344820"
  },
  {
    "text": "really huge really huge names like FedEx there are big players here and first of",
    "start": "344820",
    "end": "352740"
  },
  {
    "text": "all before continuing now we are trying to understand better the user requirements and that's why we are",
    "start": "352740",
    "end": "360000"
  },
  {
    "text": "asking for your help with a super small survey about how you use or you want to",
    "start": "360000",
    "end": "365699"
  },
  {
    "text": "use Keda and if you can take a picture don't worry because at the end of the of",
    "start": "365699",
    "end": "370979"
  },
  {
    "text": "the session we will place again but we wanted to introduce this survey thank you so so let's go and see some details",
    "start": "370979",
    "end": "379800"
  },
  {
    "text": "so for those of you who don't know like how can I works I will just briefly explain the architecture so there are",
    "start": "379800",
    "end": "387720"
  },
  {
    "text": "actually two main components one is Cuda controller or the operator and a matrix adapter so imagine that I would like to",
    "start": "387720",
    "end": "394139"
  },
  {
    "text": "Auto scale my application so what I do I will I will create a scaled object which is the custom resource that we provide",
    "start": "394139",
    "end": "399419"
  },
  {
    "text": "and the character controller basically is watching for those skill objects or skill jobs and based on that it connects",
    "start": "399419",
    "end": "406259"
  },
  {
    "text": "to the external service so for example the rabbit Revit instant and it creates HPA",
    "start": "406259",
    "end": "411960"
  },
  {
    "text": "and then it provides a metrics to The Matrix adapter that is been used by the HPA actually to do the decision because",
    "start": "411960",
    "end": "418380"
  },
  {
    "text": "HPA can use some external Matrix except the CPU or memory but you need to find a",
    "start": "418380",
    "end": "423600"
  },
  {
    "text": "way how to provide provide those kind of metrics and it's uh it's kind of tricky to do that like it's very easy but we",
    "start": "423600",
    "end": "429720"
  },
  {
    "text": "try to solve this issue and also HPA doesn't allow you to scale down to zero so you cannot scale your workloads to",
    "start": "429720",
    "end": "436740"
  },
  {
    "text": "zero replicas so that's why we basically work around it by leveraging this capabilities to the",
    "start": "436740",
    "end": "443639"
  },
  {
    "text": "operator so look at operator scales from zero to one and then the HPA takes over and it basically",
    "start": "443639",
    "end": "449880"
  },
  {
    "text": "basically scales from one to whatever replicas I have defined in my scaled object so this is this is very simple no",
    "start": "449880",
    "end": "457080"
  },
  {
    "text": "no big no big deal we have some admission better books also and we have some other stuff but this is like the",
    "start": "457080",
    "end": "462180"
  },
  {
    "text": "main Concepts so basically there are two main components the operator and the Matrix adapter and they are doing most",
    "start": "462180",
    "end": "467699"
  },
  {
    "text": "of the job so and this is the example of scale objects are one of our custom resources",
    "start": "467699",
    "end": "473520"
  },
  {
    "text": "so with scaled object you can you can Target your your deployment or stateful set or any custom resource that expose",
    "start": "473520",
    "end": "480060"
  },
  {
    "text": "uh skill sub resource you can if you have your own custom resource and you would like to Auto scale it you just",
    "start": "480060",
    "end": "486120"
  },
  {
    "text": "need to provide this this endpoint it's very simple and then we can Target it together or with HPA actually",
    "start": "486120",
    "end": "491880"
  },
  {
    "text": "so if we look at the scaled object we see that we are referencing the deployment example deployment the",
    "start": "491880",
    "end": "496979"
  },
  {
    "text": "sculptor skill Target ref then there is minimum maximum replicas and then the",
    "start": "496979",
    "end": "503400"
  },
  {
    "text": "trigger section so in the trigger section we actually specify the the credentials or not credentials but the",
    "start": "503400",
    "end": "509400"
  },
  {
    "text": "metadata for connecting to the external service and there could be multiple multiple triggers specified for single",
    "start": "509400",
    "end": "515700"
  },
  {
    "text": "single scaled object we have another optional options but this is like the",
    "start": "515700",
    "end": "520919"
  },
  {
    "text": "very very specific one for just for purposes and this is a scale job this is our",
    "start": "520919",
    "end": "527640"
  },
  {
    "text": "second main customer resource and this is this one is for scheduling kubernetes",
    "start": "527640",
    "end": "532980"
  },
  {
    "text": "jobs because if you look at this skill job it's very similar to the to the scaled object it also has like the",
    "start": "532980",
    "end": "538019"
  },
  {
    "text": "trigger section but instead of referencing an existing deployment you can put a vol J uh",
    "start": "538019",
    "end": "544380"
  },
  {
    "text": "kubernetes job so spec in into this interest field and you can you can basically schedule new new",
    "start": "544380",
    "end": "551040"
  },
  {
    "text": "kubernetes jobs based on the evidence in the in the webmq this is in particular useful for processing of long running",
    "start": "551040",
    "end": "557160"
  },
  {
    "text": "executions because imagine that you are for example our consumer application is consuming those messages from rabbit and",
    "start": "557160",
    "end": "563339"
  },
  {
    "text": "based on this message it is doing some some expensive calculation which may take hours",
    "start": "563339",
    "end": "568880"
  },
  {
    "text": "then the HPA style of Auto scaling is not ideal because once we consume the",
    "start": "568880",
    "end": "574500"
  },
  {
    "text": "message and the workload starts processing those messages the metrics are going down so basically it will it",
    "start": "574500",
    "end": "580380"
  },
  {
    "text": "will be scale scaling the the workload in the in the process of execution so if",
    "start": "580380",
    "end": "585660"
  },
  {
    "text": "you want to keep really long running jobs the scale job is the is the right option because you know you can you can",
    "start": "585660",
    "end": "590940"
  },
  {
    "text": "run the very long workloads in the as a kubernetes jobs based based on those based on those events yeah you could",
    "start": "590940",
    "end": "597420"
  },
  {
    "text": "imagine for instance go back please you could imagine this this scale of the use case for instance is Imagine do you use",
    "start": "597420",
    "end": "604200"
  },
  {
    "text": "GitHub GitHub azure devops kind of CI system imagine that suddenly the HPA",
    "start": "604200",
    "end": "610019"
  },
  {
    "text": "controller decides that the port that is running your specific pipeline should be",
    "start": "610019",
    "end": "615240"
  },
  {
    "text": "evicted and remove it so your pipeline will die and will fail and it's horrible because white has failed has failed due",
    "start": "615240",
    "end": "622680"
  },
  {
    "text": "to the HPA controller this kind of tooling this this specific tool like",
    "start": "622680",
    "end": "627899"
  },
  {
    "text": "scale job is for that because this ensures that the work started by the pot",
    "start": "627899",
    "end": "633000"
  },
  {
    "text": "and and it's important in those cases as the CI processes or long-term processes",
    "start": "633000",
    "end": "639120"
  },
  {
    "text": "in general yeah so these are our main two customer resources we have also other custom resources for securing the",
    "start": "639120",
    "end": "646140"
  },
  {
    "text": "credentials or for credentials and Link because obviously you don't want to put your credentials directly into skill object but you might want to reference",
    "start": "646140",
    "end": "652140"
  },
  {
    "text": "them from a secret or from a world so we have a special special customer service for this okay so this was like the Cada",
    "start": "652140",
    "end": "660899"
  },
  {
    "text": "in five minutes I would say introduction six minutes so okay speed",
    "start": "660899",
    "end": "667160"
  },
  {
    "text": "so now let's talk about some new features so we'll go through some architectural changes that we've done",
    "start": "667160",
    "end": "673260"
  },
  {
    "text": "recently we'll talk about certificate management about web hooks about metrics",
    "start": "673260",
    "end": "678540"
  },
  {
    "text": "and other other cool stuff so let me start with the",
    "start": "678540",
    "end": "684180"
  },
  {
    "text": "okay let's just go I don't know so first the old architecture then the",
    "start": "684180",
    "end": "690720"
  },
  {
    "text": "transition and at the end the new architecture he just changed the slides so basically this is the old old",
    "start": "690720",
    "end": "697019"
  },
  {
    "text": "architecture uh if you recall from my like interaction in the beginning so we have the main two components controller",
    "start": "697019",
    "end": "702779"
  },
  {
    "text": "Matrix adapter and they are responsible for the for the scaling of workloads uh",
    "start": "702779",
    "end": "708180"
  },
  {
    "text": "originally basically what we did we open a connection to the external service so the external trigger Source could be",
    "start": "708180",
    "end": "713279"
  },
  {
    "text": "like the rabbitmq and we opened the connection both from the controller from the operator and move from the metrics",
    "start": "713279",
    "end": "719940"
  },
  {
    "text": "adapter so basically we have two connections uh and basically it was independent on each other we changed",
    "start": "719940",
    "end": "726300"
  },
  {
    "text": "this architecture a little bit so voila yeah we we just open one",
    "start": "726300",
    "end": "731640"
  },
  {
    "text": "collection from the from the controller and we moved a majority of the logic from The Matrix adapter so this Matrix",
    "start": "731640",
    "end": "737940"
  },
  {
    "text": "adapter is really just the let's say proxy to talk to kubernetes and we we do",
    "start": "737940",
    "end": "743880"
  },
  {
    "text": "majorities of the stuff from the from the cad operator why we did it uh because we wanted to do that",
    "start": "743880",
    "end": "751019"
  },
  {
    "text": "and we can do it well well we will We Will We also talk about this in detail",
    "start": "751019",
    "end": "756899"
  },
  {
    "text": "more later but maybe a couple of examples so for example we reduce the number of open connections you know so",
    "start": "756899",
    "end": "763320"
  },
  {
    "text": "imagine that you have a large cluster and a lot of a lot of deployments that are he was in Prometheus and there are",
    "start": "763320",
    "end": "771120"
  },
  {
    "text": "scraping metrics from Prometheus so our scale objects are pretty metrics from families with this change we just reduce",
    "start": "771120",
    "end": "776579"
  },
  {
    "text": "the number of connections by half so which could be which could be a lot so we'll use so we are using the load on",
    "start": "776579",
    "end": "782160"
  },
  {
    "text": "the external service and second of all uh because operator you does the scaling from zero",
    "start": "782160",
    "end": "788220"
  },
  {
    "text": "to one but the HPA does the rest of the scaling and we don't we don't we don't have any power to change the actual the",
    "start": "788220",
    "end": "793380"
  },
  {
    "text": "scaling behavior let's say or imagine that you have two scalars two triggers defined in a scaled object in this case",
    "start": "793380",
    "end": "800399"
  },
  {
    "text": "what HPA does it asks for metrics for each trigger and then does the scaling",
    "start": "800399",
    "end": "806160"
  },
  {
    "text": "position based on the let's say largest number so whichever metric reports largest number then is the final final",
    "start": "806160",
    "end": "812459"
  },
  {
    "text": "replica count so imagine you have a for example Prometheus trigger specified and rapidmq sticker specified the default",
    "start": "812459",
    "end": "818760"
  },
  {
    "text": "behavior that the larger number wins we have no power to actually change it but with this with this change when we are",
    "start": "818760",
    "end": "824940"
  },
  {
    "text": "in power of of all the uh let's say the Matrix Loop then we can we can modify",
    "start": "824940",
    "end": "831060"
  },
  {
    "text": "those metrics a little bit before we are actually sending them to a matrix adapter we are using grpc so it should be relatively fast so we are we would",
    "start": "831060",
    "end": "839700"
  },
  {
    "text": "like to add new capabilities for example that you would like to specify in case you have multiple triggers you would",
    "start": "839700",
    "end": "845100"
  },
  {
    "text": "like to specify okay not use like the highest number but maybe average or minimum or whatever or maybe some more",
    "start": "845100",
    "end": "850860"
  },
  {
    "text": "complex logic into into evaluation of of the of the target scale another cool",
    "start": "850860",
    "end": "856019"
  },
  {
    "text": "stuff is is caching of of those metrics but I will I will talk about it so later on",
    "start": "856019",
    "end": "861240"
  },
  {
    "text": "it's my turn yeah nice they are bored yeah sorry for them okay",
    "start": "861240",
    "end": "866820"
  },
  {
    "text": "if you are if if you are not bored maybe the the certificate management is not the most the most interesting and",
    "start": "866820",
    "end": "872700"
  },
  {
    "text": "enjoyable topic around the world but I will try to do it at least funny okay and due to this change that we have done",
    "start": "872700",
    "end": "880139"
  },
  {
    "text": "in the architecture we need we discovered the strong requirement of encrypting every internal traffic inside",
    "start": "880139",
    "end": "887040"
  },
  {
    "text": "the cluster from Canada for the Keda components why because otherwise anyone",
    "start": "887040",
    "end": "892320"
  },
  {
    "text": "can put another application that's a man in the middle and suddenly your AWS",
    "start": "892320",
    "end": "897720"
  },
  {
    "text": "Azure or ggp Bill grows and grows and grows and why because you are scaling",
    "start": "897720",
    "end": "903779"
  },
  {
    "text": "out more than expected or less than expected so we need to introduce a trust",
    "start": "903779",
    "end": "909959"
  },
  {
    "text": "a trustable way for communicating and that's why we introduce a mechanisms for",
    "start": "909959",
    "end": "915420"
  },
  {
    "text": "automatically generating TLS certificate self-signed obviously we are not a trust",
    "start": "915420",
    "end": "921899"
  },
  {
    "text": "the ca but we support the capability of providing your own search certificate",
    "start": "921899",
    "end": "927480"
  },
  {
    "text": "with your own CA however you have generated them but you can use it not only for common for",
    "start": "927480",
    "end": "934680"
  },
  {
    "text": "communicating different Keta components also for the communication between Keda and the cluster because the cluster",
    "start": "934680",
    "end": "941339"
  },
  {
    "text": "needs to ask okay that this metric hi what value has this metric so for that",
    "start": "941339",
    "end": "947519"
  },
  {
    "text": "communication we also use that CA so we we have been in Greece the security",
    "start": "947519",
    "end": "955019"
  },
  {
    "text": "but it requires to manage the certificate if you are lazy like I am it's true that operator can Dash it",
    "start": "955019",
    "end": "963240"
  },
  {
    "text": "alone but obviously if your Enterprise security agreement and your Enterprise",
    "start": "963240",
    "end": "969079"
  },
  {
    "text": "policies requires to use your own CA it's doable and it's supported okay and",
    "start": "969079",
    "end": "975480"
  },
  {
    "text": "talking about Cas because the certificates around internet well",
    "start": "975480",
    "end": "980579"
  },
  {
    "text": "okay if you are using your own CA it's really common that okay I'm using TLs",
    "start": "980579",
    "end": "987240"
  },
  {
    "text": "but the rabbit the server the Prometheus or rabbit server is using my own",
    "start": "987240",
    "end": "992519"
  },
  {
    "text": "certificate so the standard libraries in any language write an error if the certificate is not",
    "start": "992519",
    "end": "1000259"
  },
  {
    "text": "in the trusted CA store from the container an error will be right so in Canada we",
    "start": "1000259",
    "end": "1006320"
  },
  {
    "text": "have at the support for providing your own Cas in this way you can use your own",
    "start": "1006320",
    "end": "1012440"
  },
  {
    "text": "CA in a full validated communication and encrypted way in the scalars which is",
    "start": "1012440",
    "end": "1017720"
  },
  {
    "text": "another improvement from security point of view I'm the last but not the least",
    "start": "1017720",
    "end": "1024678"
  },
  {
    "text": "point about certificate is that we have made optionally or settable the minimum",
    "start": "1024679",
    "end": "1030620"
  },
  {
    "text": "TLS version so nowadays latest versions of Keda ensures that your encrypted",
    "start": "1030620",
    "end": "1036798"
  },
  {
    "text": "Communications is using at least TLS 1.2 which is the minimum secure TLS",
    "start": "1036799",
    "end": "1043459"
  },
  {
    "text": "encryption protocol that exists you can use your own is an option you",
    "start": "1043459",
    "end": "1049160"
  },
  {
    "text": "can modify but at least you are safe we are moving forward we are designing the",
    "start": "1049160",
    "end": "1055820"
  },
  {
    "text": "roadmap for making Keda safe safe as default in case of not configuring",
    "start": "1055820",
    "end": "1061640"
  },
  {
    "text": "anything Keda will be safe and will fulfill all security requirements because",
    "start": "1061640",
    "end": "1067880"
  },
  {
    "text": "is not interesting it's not necessary and if we can do it why should we",
    "start": "1067880",
    "end": "1072980"
  },
  {
    "text": "delegate or why should we enforce you to doing to do these boring stuffs",
    "start": "1072980",
    "end": "1079960"
  },
  {
    "text": "or web hooks validation one really common Topic in GitHub",
    "start": "1081799",
    "end": "1087860"
  },
  {
    "text": "repository in the issues are things that for me ASA Academy as a person really",
    "start": "1087860",
    "end": "1096620"
  },
  {
    "text": "focus on auto scaling sounds super clear but my experience is that it's not",
    "start": "1096620",
    "end": "1102860"
  },
  {
    "text": "obvious it's not obvious at all how many of you knows that I need to a",
    "start": "1102860",
    "end": "1108620"
  },
  {
    "text": "world in kubernetes not important deployment stateful set custom resources whatever how many how much of you know",
    "start": "1108620",
    "end": "1115820"
  },
  {
    "text": "that you can only have one HPA per world you can have multiple but if you have",
    "start": "1115820",
    "end": "1122179"
  },
  {
    "text": "more if you can if you have multiple it won't work correctly because those two hpas will live I think exactly if you",
    "start": "1122179",
    "end": "1128900"
  },
  {
    "text": "want to escape for instance not in queda in kubernetes in general if you want to Scale based on met on CPU and memory you",
    "start": "1128900",
    "end": "1137179"
  },
  {
    "text": "should mix both metrics in the same HPA if U.S pound if you deploy two HPA the",
    "start": "1137179",
    "end": "1143360"
  },
  {
    "text": "behavior will be crazy and those things cool Sim obvious but they are not",
    "start": "1143360",
    "end": "1149960"
  },
  {
    "text": "obvious at all another feature that we have introduced is a validation a validating workbooks for those things",
    "start": "1149960",
    "end": "1156200"
  },
  {
    "text": "the validation workbooks will block any SQL object that try to scale or that try",
    "start": "1156200",
    "end": "1162380"
  },
  {
    "text": "to control a world that is already controlled by another scale object or by",
    "start": "1162380",
    "end": "1167480"
  },
  {
    "text": "another xpa and also sorry",
    "start": "1167480",
    "end": "1172460"
  },
  {
    "text": "the same validation where post validating web hooks will check obviously apart from that if you are",
    "start": "1172760",
    "end": "1179000"
  },
  {
    "text": "going if you want to use CPU or memory scalars you need to have those values in the",
    "start": "1179000",
    "end": "1186559"
  },
  {
    "text": "request of the pot if you don't have then Define the HPA will do nothing",
    "start": "1186559",
    "end": "1191720"
  },
  {
    "text": "nothing at all so why why wait until that scenario if we can catch during the",
    "start": "1191720",
    "end": "1199700"
  },
  {
    "text": "deployment thanks to this validation cool",
    "start": "1199700",
    "end": "1206200"
  },
  {
    "text": "too much slides yeah it's my moment okay",
    "start": "1206480",
    "end": "1211940"
  },
  {
    "text": "we have been working also in the observability because okay I have saw you okay that works it's not",
    "start": "1211940",
    "end": "1219500"
  },
  {
    "text": "a joke we don't record the demo it's a live demo okay that works but",
    "start": "1219500",
    "end": "1224720"
  },
  {
    "text": "how can I check it what can I do if Kerala is failing how could I notice",
    "start": "1224720",
    "end": "1229940"
  },
  {
    "text": "that Keda is failing okay in in for during the last year we have been",
    "start": "1229940",
    "end": "1235700"
  },
  {
    "text": "working hard also in the observability of Keda we have added some Prometheus",
    "start": "1235700",
    "end": "1242360"
  },
  {
    "text": "metric",
    "start": "1242360",
    "end": "1244780"
  },
  {
    "text": "come here we have we have added a lot of metrics because we think and we are not the",
    "start": "1252400",
    "end": "1260299"
  },
  {
    "text": "owner of the truth that's why we did we prepare the survey we attend GitHub",
    "start": "1260299",
    "end": "1267140"
  },
  {
    "text": "issues it's like discussions because we want feedback but we have added these",
    "start": "1267140",
    "end": "1272419"
  },
  {
    "text": "metrics just for ensuring that Keta works and those are available just",
    "start": "1272419",
    "end": "1277880"
  },
  {
    "text": "scrapping them from the server cool let's move forward so these were some these were some new",
    "start": "1277880",
    "end": "1284900"
  },
  {
    "text": "features that we introduced recently and let's talk about some best practices just real quick and then let's go to",
    "start": "1284900",
    "end": "1290240"
  },
  {
    "text": "limo so think properly because you will be doing the demo right so polling interval this is uh interesting",
    "start": "1290240",
    "end": "1297559"
  },
  {
    "text": "interesting stuff so this is like an option in scale object and the pulling interval is because if",
    "start": "1297559",
    "end": "1304340"
  },
  {
    "text": "you recall there are those two components operator a matrix server the pulling interval is only for the operator so it tells how how like what",
    "start": "1304340",
    "end": "1312020"
  },
  {
    "text": "is the frequency of the checks from from cadot to the external service so let's say I would like to check my my webmq",
    "start": "1312020",
    "end": "1318320"
  },
  {
    "text": "queue like uh every 15 seconds so this is what the polling interval is for but it is only for zero to one scaling it is",
    "start": "1318320",
    "end": "1326179"
  },
  {
    "text": "not uh it is not related to the relevance to the HPA or so to the one to",
    "start": "1326179",
    "end": "1331700"
  },
  {
    "text": "end scaling because as I told you before like the HPA requested some metrics on",
    "start": "1331700",
    "end": "1336980"
  },
  {
    "text": "its own so and this by default is 15 seconds there is an option for it and but this option needs to be needs to be",
    "start": "1336980",
    "end": "1343100"
  },
  {
    "text": "set on the on the kubernetes platform so if you are not managing the Platformers your own you",
    "start": "1343100",
    "end": "1348440"
  },
  {
    "text": "cannot change this this period so it means that if you for example would like to make the auto scaling let's say",
    "start": "1348440",
    "end": "1354919"
  },
  {
    "text": "quicker so we would like to scale faster so you would like to decrease this this limit you have no option if you don't",
    "start": "1354919",
    "end": "1360260"
  },
  {
    "text": "manage the manager cluster so how you can how you can bypass this so that's why we did the move from like",
    "start": "1360260",
    "end": "1367280"
  },
  {
    "text": "let's say the architectural change so now we are in a full control of the of the metrics flowing into the system so",
    "start": "1367280",
    "end": "1374059"
  },
  {
    "text": "we have a new feature which is called Matrix caching and basically it means if you enable this setting you can enable",
    "start": "1374059",
    "end": "1379880"
  },
  {
    "text": "it pair each trigger so it means that uh the the only only request for a metric",
    "start": "1379880",
    "end": "1385640"
  },
  {
    "text": "is coming uh during the polling interval and then we are caching the metrics in the operator and when HPA requests those",
    "start": "1385640",
    "end": "1392480"
  },
  {
    "text": "metrics for example if every 15 seconds but we are have we have the polling interval set for one minute so we only",
    "start": "1392480",
    "end": "1398780"
  },
  {
    "text": "query the metrics to the external system every minute and uh the cache is being hit in this case and we we are also",
    "start": "1398780",
    "end": "1406280"
  },
  {
    "text": "saving saving like the threat default traffic so it's useful to think about these options if you are designing your",
    "start": "1406280",
    "end": "1412039"
  },
  {
    "text": "your your your solution because for example some solutions don't require that that fast",
    "start": "1412039",
    "end": "1417980"
  },
  {
    "text": "uh fast or I could say startup startup time for scaling there might be some delay so you might want to extend these",
    "start": "1417980",
    "end": "1424340"
  },
  {
    "text": "options maybe other other workloads require like let's say uh higher frequency so we want you would like to",
    "start": "1424340",
    "end": "1430520"
  },
  {
    "text": "really tweak this this kind of settings uh then uh there is a another another",
    "start": "1430520",
    "end": "1436580"
  },
  {
    "text": "cool recommendation which is called HPA scaling Behavior there's it's a like a advanced field in the in the HPA",
    "start": "1436580",
    "end": "1443120"
  },
  {
    "text": "settings so it is HPA building building stuff and there are two two options there is a stabilization window which is",
    "start": "1443120",
    "end": "1449059"
  },
  {
    "text": "good if you want to prevent like flapping or the number of of replicas so let's say my Matrix reports for example",
    "start": "1449059",
    "end": "1456260"
  },
  {
    "text": "scale to one replica then to 10 110 you would like to avoid every situation so you can you can you can you can specify",
    "start": "1456260",
    "end": "1462860"
  },
  {
    "text": "the stabilization window and it prevents this kind of behavior it makes the scaling smooth also you can Define the",
    "start": "1462860",
    "end": "1468620"
  },
  {
    "text": "scaling policies both for scaling out and in and basically you you can you can",
    "start": "1468620",
    "end": "1474679"
  },
  {
    "text": "modify the algorithm to scale maybe a little bit faster or slower so increasing or decreasing the number of replicas so I definitely recommend you",
    "start": "1474679",
    "end": "1482120"
  },
  {
    "text": "using these settings in your in your environment and this is uh interesting topic and I",
    "start": "1482120",
    "end": "1487700"
  },
  {
    "text": "would like you to talk about this is this is another interesting topic and maybe it's not about practice we didn't",
    "start": "1487700",
    "end": "1494780"
  },
  {
    "text": "know the best place to put or to explain this but but it's important because",
    "start": "1494780",
    "end": "1499840"
  },
  {
    "text": "we have introduced support for for float numbers but if you don't know I can tell",
    "start": "1499840",
    "end": "1506539"
  },
  {
    "text": "you kubernetes doesn't support flows floats float number they are not supported at all kubernetes change the",
    "start": "1506539",
    "end": "1514100"
  },
  {
    "text": "scale if you want to say 1.5 kubernetes will use 100 Milli in general milligors",
    "start": "1514100",
    "end": "1521539"
  },
  {
    "text": "melee whatever but the the the the scale is changed and",
    "start": "1521539",
    "end": "1528320"
  },
  {
    "text": "that's why you could see in your HPA something weird like four thousand eight hundred M five what",
    "start": "1528320",
    "end": "1537740"
  },
  {
    "text": "that means that means four point eight slash Five",
    "start": "1537740",
    "end": "1543440"
  },
  {
    "text": "why are we explain this because we have noticed in our issues and in our community channels that there are a lot",
    "start": "1543440",
    "end": "1550159"
  },
  {
    "text": "of questions about this and this is due to this not limitation due to this",
    "start": "1550159",
    "end": "1555980"
  },
  {
    "text": "design in kubernetes but due to this the support for floating numbers as a",
    "start": "1555980",
    "end": "1562340"
  },
  {
    "text": "value for instance you will say I want to Scale based on or the the value that",
    "start": "1562340",
    "end": "1567380"
  },
  {
    "text": "I want to read is 0.5 potatoes per replica and why per replica because",
    "start": "1567380",
    "end": "1574460"
  },
  {
    "text": "there is another important topic that we have support and we want to explain an isometric type and this is not part of",
    "start": "1574460",
    "end": "1582320"
  },
  {
    "text": "Canada itself because this this is extremely related with the HPA you will see this in the HPA",
    "start": "1582320",
    "end": "1589760"
  },
  {
    "text": "directly not in Canada the metric types do you know the metric",
    "start": "1589760",
    "end": "1595279"
  },
  {
    "text": "types in kubernetes which kind of metric types do you have a buy bubble in kubernetes in general",
    "start": "1595279",
    "end": "1602860"
  },
  {
    "text": "never not nobody knows okay don't worry me neither",
    "start": "1603320",
    "end": "1608840"
  },
  {
    "text": "that's why I grow them we have the average type which is the most obvious",
    "start": "1608840",
    "end": "1614240"
  },
  {
    "text": "it's like okay my boat can process five messages at once in parallel so I want",
    "start": "1614240",
    "end": "1621980"
  },
  {
    "text": "to have five message in average purpose so if I have the messages",
    "start": "1621980",
    "end": "1627919"
  },
  {
    "text": "I will have two parts easy to understand the second one is value value is a cast",
    "start": "1627919",
    "end": "1633980"
  },
  {
    "text": "not a custom it's another formula like three three four I don't remember the",
    "start": "1633980",
    "end": "1640940"
  },
  {
    "text": "value as last 20 I don't remember but you have the link to the documentation",
    "start": "1640940",
    "end": "1646279"
  },
  {
    "text": "where it's properly explained the specific formula but you have another way to calculate because maybe you're",
    "start": "1646279",
    "end": "1652400"
  },
  {
    "text": "warlord needs other scaling weight than just the average and",
    "start": "1652400",
    "end": "1657500"
  },
  {
    "text": "if you are using CPU or memory you probably recognize utilization because is the",
    "start": "1657500",
    "end": "1665600"
  },
  {
    "text": "metric is the common metric for CPU and memory for instance if you see the percentage in the HPA is because you are",
    "start": "1665600",
    "end": "1672440"
  },
  {
    "text": "using utilization if you will be using any other you will not be the percentage so this is not",
    "start": "1672440",
    "end": "1679820"
  },
  {
    "text": "part of us best practices but it's important to share this knowledge because you will you can't face with",
    "start": "1679820",
    "end": "1686779"
  },
  {
    "text": "this values metric types and it's important to know how it works because",
    "start": "1686779",
    "end": "1692059"
  },
  {
    "text": "it's part of the internal working way of kubernetes Ankara exactly",
    "start": "1692059",
    "end": "1698000"
  },
  {
    "text": "awesome so I have to do the another demon oh",
    "start": "1698000",
    "end": "1703760"
  },
  {
    "text": "yes I don't earn enough oh sorry",
    "start": "1703760",
    "end": "1710679"
  },
  {
    "text": "go ahead oh no word sir okay now I'm",
    "start": "1712880",
    "end": "1717919"
  },
  {
    "text": "going a bit deeper in the air process we have a deployment they are really normal",
    "start": "1717919",
    "end": "1724279"
  },
  {
    "text": "deployment you can find this example in in kedar Rapids",
    "start": "1724279",
    "end": "1730419"
  },
  {
    "text": "organization in GitHub and I have the scale object as being a",
    "start": "1730419",
    "end": "1736220"
  },
  {
    "text": "class explained but I have another important point he has his plane we have other crds in",
    "start": "1736220",
    "end": "1743240"
  },
  {
    "text": "this case the other crd is trigger Authentication what are we doing with that trigger",
    "start": "1743240",
    "end": "1749000"
  },
  {
    "text": "Authentication we are using a 90 a native integration",
    "start": "1749000",
    "end": "1754820"
  },
  {
    "text": "in this case with Acer keyboard for pulling the secret so the connection",
    "start": "1754820",
    "end": "1760340"
  },
  {
    "text": "string to that rabbit isn't in the cluster is on demand pull from Keda and",
    "start": "1760340",
    "end": "1767480"
  },
  {
    "text": "how can we connect with that with that Azure keyboard we are using managed",
    "start": "1767480",
    "end": "1772940"
  },
  {
    "text": "identities if you don't know what our manager identities yeah they are known as Rod identity Federation in Azure and",
    "start": "1772940",
    "end": "1781220"
  },
  {
    "text": "gcp and eam role assumption could be in AWS is the most secure way that you can",
    "start": "1781220",
    "end": "1788960"
  },
  {
    "text": "use to connect through the cloud provider infrastructure because because it generates it generates",
    "start": "1788960",
    "end": "1796700"
  },
  {
    "text": "a single token based on the identity speed up which is speed up okay no",
    "start": "1796700",
    "end": "1802820"
  },
  {
    "text": "problem at all okay so yeah this is the rabbit if you check rabbit",
    "start": "1802820",
    "end": "1809779"
  },
  {
    "text": "is not secure because I have generated my own self self signed certificate so if I as I",
    "start": "1809779",
    "end": "1816980"
  },
  {
    "text": "have explained it but five minutes nice sorry but in this case",
    "start": "1816980",
    "end": "1824899"
  },
  {
    "text": "I have the secret with the CI the C8 is registered in queda so Keda Trust on DCA",
    "start": "1824899",
    "end": "1831500"
  },
  {
    "text": "and obviously when I run the sediment sample in this case",
    "start": "1831500",
    "end": "1837740"
  },
  {
    "text": "I'm gonna publish to the other queue",
    "start": "1837740",
    "end": "1842240"
  },
  {
    "text": "I can see that the scaling start again now from zero to one and I",
    "start": "1844279",
    "end": "1852860"
  },
  {
    "text": "can I can keep it keep it there for the future but we have a bit rush I will jump to the",
    "start": "1852860",
    "end": "1860360"
  },
  {
    "text": "next one how can I check I show you that we expose metric we want to expose",
    "start": "1860360",
    "end": "1866299"
  },
  {
    "text": "metric to monitor how Keda is working because it's important it's critical if",
    "start": "1866299",
    "end": "1871520"
  },
  {
    "text": "you need to answer and your Port is down because queda hasn't scale your world you are failing in production and that's",
    "start": "1871520",
    "end": "1879080"
  },
  {
    "text": "not acceptable we need to figure out how to do it and in this case we expose my drink this dashboard is a",
    "start": "1879080",
    "end": "1886820"
  },
  {
    "text": "totally demo dashboard let me put 30 minutes but these are a sample about the",
    "start": "1886820",
    "end": "1892700"
  },
  {
    "text": "metrics that you could use those are there you only need to scrape them using",
    "start": "1892700",
    "end": "1897740"
  },
  {
    "text": "Prometheus and explore them use them in your alerts in your monitor dashboards wherever you want",
    "start": "1897740",
    "end": "1904159"
  },
  {
    "text": "cool maybe let's go back to the presentation yeah",
    "start": "1904159",
    "end": "1908559"
  },
  {
    "text": "this is just the future future topic we don't have time so this is just the list maybe you can read it later on but",
    "start": "1914059",
    "end": "1919279"
  },
  {
    "text": "basically this is like a related to our architectural changes so this is what what's coming and this is the end of the session so",
    "start": "1919279",
    "end": "1926539"
  },
  {
    "text": "please if you are Qatar users please please take your time to to fill this Philly survey because it will help you",
    "start": "1926539",
    "end": "1932240"
  },
  {
    "text": "help us to prioritize what are the like the features that we would like to see in the in the in the cadan to improve",
    "start": "1932240",
    "end": "1938659"
  },
  {
    "text": "and there is also the QR code for the session feedback so please if you have any questions feel free to ask them now",
    "start": "1938659",
    "end": "1944360"
  },
  {
    "text": "and sorry for speeding up the end of the demo sorry my fault yeah one microphone",
    "start": "1944360",
    "end": "1949700"
  },
  {
    "text": "here can we have a mic",
    "start": "1949700",
    "end": "1954460"
  },
  {
    "text": "in here hi thanks",
    "start": "1958940",
    "end": "1966399"
  },
  {
    "text": "so anybody has a question in the meantime so this okay",
    "start": "1966799",
    "end": "1972320"
  },
  {
    "text": "okay hello good um so you mentioned about the validating webhook stuff",
    "start": "1972320",
    "end": "1978620"
  },
  {
    "text": "um what happens if you deploy your so if I'm deploying everything with a Helm chart with flux or whatever and everything deposit once and it's",
    "start": "1978620",
    "end": "1985159"
  },
  {
    "text": "checking the deployment for CPU and RAM being there yeah what happens if the uh the cata resource um is deployed",
    "start": "1985159",
    "end": "1992539"
  },
  {
    "text": "slightly before the deployment does it fail um it failed yeah okay yeah but in general Helm first deploy is found the",
    "start": "1992539",
    "end": "1999200"
  },
  {
    "text": "deployed and then spawn the scale object because they are Customs here this yeah",
    "start": "1999200",
    "end": "2005080"
  },
  {
    "text": "but if if you have any Edge case that is not supported you could use a web hooks",
    "start": "2005080",
    "end": "2010419"
  },
  {
    "text": "web host no sorry a Helm hooks for slowing the slowing the the scale object",
    "start": "2010419",
    "end": "2016179"
  },
  {
    "text": "deployment or deploy in the cluster anybody any other question okay",
    "start": "2016179",
    "end": "2023399"
  },
  {
    "text": "well I go next until the mission was there regarding the Prometheus metrics",
    "start": "2026140",
    "end": "2032700"
  },
  {
    "text": "Thank you regarding the Prometheus metrics uh you show the dashboard do you have a",
    "start": "2032700",
    "end": "2038380"
  },
  {
    "text": "community dashboard that is available we have a dashboard in the repository that",
    "start": "2038380",
    "end": "2045600"
  },
  {
    "text": "I created this dashboard for this demo but it's based on this dashboard so you",
    "start": "2045600",
    "end": "2050919"
  },
  {
    "text": "have the starting point and you can iterate from that starting point but we plan to extend this season all right",
    "start": "2050919",
    "end": "2056740"
  },
  {
    "text": "thanks",
    "start": "2056740",
    "end": "2058980"
  }
]
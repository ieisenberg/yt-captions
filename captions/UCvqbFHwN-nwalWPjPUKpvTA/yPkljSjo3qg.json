[
  {
    "text": "I'm Abit I'm a tech lead manager at Nvidia hey uh this is arit I'm a senior",
    "start": "160",
    "end": "7680"
  },
  {
    "text": "s engineer at Nvidia so by a show of hands how many of you manage GPU",
    "start": "7680",
    "end": "14599"
  },
  {
    "text": "plers oh wow and that's a lot and how many gpus or how many nodes in your",
    "start": "14599",
    "end": "20560"
  },
  {
    "text": "cluster 10 20 30 5050",
    "start": "20560",
    "end": "27800"
  },
  {
    "text": "100 okay 500",
    "start": "27800",
    "end": "31960"
  },
  {
    "text": "1,000 5,000 10,000 more than 10,000 oh nice nice you",
    "start": "33440",
    "end": "42160"
  },
  {
    "text": "in right talk we go all right yeah all right so",
    "start": "42160",
    "end": "50360"
  },
  {
    "text": "um in this talk we'll go over uh the motivation for resiliency understanding",
    "start": "50360",
    "end": "55960"
  },
  {
    "text": "some of the characteristics of AI workloads we'll see where failures come from uh we'll look into AI",
    "start": "55960",
    "end": "62239"
  },
  {
    "text": "infrastructure components and bring up and validation then we'll talk about uh fall tolerance and it building blocks",
    "start": "62239",
    "end": "68960"
  },
  {
    "text": "and then the four pillars of fall horns are monitoring propagation recovery and uh remediation and then we'll see",
    "start": "68960",
    "end": "75360"
  },
  {
    "text": "where's their scope for enhancement as a community so why do we need fonns in AI",
    "start": "75360",
    "end": "81720"
  },
  {
    "text": "workloads inherently AI Hardware is complex here you see the schematic of uh",
    "start": "81720",
    "end": "88600"
  },
  {
    "text": "uh djx h100 200 uh system in addition to",
    "start": "88600",
    "end": "93880"
  },
  {
    "text": "the typical components in a CPU server like you know the CPU socks dam and vme",
    "start": "93880",
    "end": "99840"
  },
  {
    "text": "drives and fans there are a few additional components um these two are the 400 gig",
    "start": "99840",
    "end": "107240"
  },
  {
    "text": "ethernet cards that are used to connect to your uh high performance parallel file system like cluster and you have",
    "start": "107240",
    "end": "114159"
  },
  {
    "text": "the eight infinity band cards which are connected to the backend Network they",
    "start": "114159",
    "end": "119479"
  },
  {
    "text": "connect to the gpus um you know could be h100 200 and then those all the gpus",
    "start": "119479",
    "end": "126560"
  },
  {
    "text": "inside a server are connected to each other via the NV switch over a 900 GB",
    "start": "126560",
    "end": "132560"
  },
  {
    "text": "GPU to GPU interconnect yeah it's 900 gbes and um the second dimension so on",
    "start": "132560",
    "end": "140680"
  },
  {
    "text": "one side we have complex hardware and the second dimension is very large scale um you can imagine a single training job",
    "start": "140680",
    "end": "148280"
  },
  {
    "text": "being run at this scale uses up all the nodes in your data center all the gpus",
    "start": "148280",
    "end": "153680"
  },
  {
    "text": "all the infinite band connections and everything um here's a topology for a 1,000 GPU uh rail optimized fabric by",
    "start": "153680",
    "end": "162599"
  },
  {
    "text": "rail optimized it means you want to minimize the number of collisions that can happen and so it creates a two-",
    "start": "162599",
    "end": "169080"
  },
  {
    "text": "layer topology uh at 32k scale again you can you know Drive some of that through a",
    "start": "169080",
    "end": "174480"
  },
  {
    "text": "two layer topology but depending on your how your back end is connected could be two or three layers",
    "start": "174480",
    "end": "180599"
  },
  {
    "text": "and the scale keeps growing there are already 100K plus GPU clusters in production and 200 and 300K GPU clusters",
    "start": "180599",
    "end": "188519"
  },
  {
    "text": "are being built uh when you combine the effect of complex Hardware with scale",
    "start": "188519",
    "end": "194360"
  },
  {
    "text": "the combined effect is synergistic so it's compounding rather than",
    "start": "194360",
    "end": "200760"
  },
  {
    "text": "additive uh at a scale of course we want to run you know training of billions and trillions of parameter models uh the GPU",
    "start": "200760",
    "end": "208760"
  },
  {
    "text": "server is a very sophisticated high performance piece of equipment but it comes with its own complexity there are",
    "start": "208760",
    "end": "215360"
  },
  {
    "text": "several sources of failure like power uh CPU GPU the memory network cables",
    "start": "215360",
    "end": "224439"
  },
  {
    "text": "software and then data center components like uh the network design and the",
    "start": "224439",
    "end": "229599"
  },
  {
    "text": "cooling design um moreover some components may not fail completely they might just run in a degraded State",
    "start": "229599",
    "end": "236120"
  },
  {
    "text": "making it harder to detect um failures in llm training are",
    "start": "236120",
    "end": "242959"
  },
  {
    "text": "catastrophic because the training workload is a tightly coupled synchronous workload which means it is",
    "start": "242959",
    "end": "249680"
  },
  {
    "text": "at the intersection of distributed systems which expect failures and HBC",
    "start": "249680",
    "end": "255040"
  },
  {
    "text": "systems which cannot tolerate failures uh moreover users expect a fire",
    "start": "255040",
    "end": "260479"
  },
  {
    "text": "and forget experience where they just want to submit their job and walk away and then be notified after the job",
    "start": "260479",
    "end": "267120"
  },
  {
    "text": "completes so let's take a step back back and understand the characteristics of AI",
    "start": "267120",
    "end": "272880"
  },
  {
    "text": "workloads uh pre-training or training is uh one of the large scale workloads",
    "start": "272880",
    "end": "279160"
  },
  {
    "text": "that's running um on these clusters it's a long running and synchronous workload",
    "start": "279160",
    "end": "284919"
  },
  {
    "text": "requires High storage throughput for data read and write uh there's also a very high amount of traffic over the",
    "start": "284919",
    "end": "290919"
  },
  {
    "text": "back end nodes and uh it's a large scale multi- Noe multi-gpu workload and a",
    "start": "290919",
    "end": "297680"
  },
  {
    "text": "single training job is usually run Within in the entire data center fine-tuning is a a smaller form of",
    "start": "297680",
    "end": "306000"
  },
  {
    "text": "training which which is a a short running synchronous workload less than 24 hours uh there's of course High uh",
    "start": "306000",
    "end": "313759"
  },
  {
    "text": "traffic over the back end with frequent small rides but the scale of the job is smaller with 8 to 32",
    "start": "313759",
    "end": "320560"
  },
  {
    "text": "gpus and then there is the inference when you run your models in production this is a request response type of",
    "start": "320560",
    "end": "327360"
  },
  {
    "text": "workload um which has batch input and streaming output it is very sensitive to",
    "start": "327360",
    "end": "332440"
  },
  {
    "text": "front-end Network latencies employees load balancing and autoscaling uh many concurrent instances of uh the model can",
    "start": "332440",
    "end": "340360"
  },
  {
    "text": "be deployed for inference in parallel and the blast radius for failures is limited to individual",
    "start": "340360",
    "end": "347160"
  },
  {
    "text": "instances uh in addition um simulation is another workload that runs on AI",
    "start": "347160",
    "end": "353160"
  },
  {
    "text": "clusters is not a um you know it uses the same infrastructure but um it's it's",
    "start": "353160",
    "end": "359479"
  },
  {
    "text": "a a long running medium scale workload with high storage requirements uh running at medium scale and the",
    "start": "359479",
    "end": "366880"
  },
  {
    "text": "interesting part here is that the gpus run in a mixed mode which is Graphics some gpus run in a graphics mode and",
    "start": "366880",
    "end": "373560"
  },
  {
    "text": "some gpus run in compute mode so let's try to now that we understand the",
    "start": "373560",
    "end": "380240"
  },
  {
    "text": "complexity and the scale and the characteristics of AI WorkSource let's see where do the failures come from so",
    "start": "380240",
    "end": "386880"
  },
  {
    "text": "the hard failures which usually require a not reboot or an RMA um can be",
    "start": "386880",
    "end": "392520"
  },
  {
    "text": "categorized like this like some most of the failures some of them come from the network fabric itself the NV link errors",
    "start": "392520",
    "end": "400440"
  },
  {
    "text": "the uh external switches um GPU errors like ECC uncorrectable errors uh The",
    "start": "400440",
    "end": "407039"
  },
  {
    "text": "Disappearing GPU like GPU falling off the bus or could be kernel driver bugs that wet the application system errors",
    "start": "407039",
    "end": "414639"
  },
  {
    "text": "like pcie related you have seen nvme errors um all kinds of errors on the system itself and intermittent storage",
    "start": "414639",
    "end": "422000"
  },
  {
    "text": "errors also transient failures failures are recoverable either either by",
    "start": "422000",
    "end": "429680"
  },
  {
    "text": "resetting the hardware component or uh simply by rebooting the node typically",
    "start": "429680",
    "end": "435720"
  },
  {
    "text": "Network link flap or bandwidth degradation is one of those uh thermal slowdowns in gpus Cuda errors or nans",
    "start": "435720",
    "end": "444080"
  },
  {
    "text": "can be uh sources of them remote storage performance degradation uh can also be a",
    "start": "444080",
    "end": "449879"
  },
  {
    "text": "source of transient failures and then of course application failures like out of memory or application crash due to bugs",
    "start": "449879",
    "end": "456319"
  },
  {
    "text": "in the application itself there are other failures that cannot directly be categorized into each",
    "start": "456319",
    "end": "462479"
  },
  {
    "text": "either of these we have seen a single faulty fan on a node in a 400 node",
    "start": "462479",
    "end": "468800"
  },
  {
    "text": "cluster was causing heat to build up within that enclosure that uh slowed",
    "start": "468800",
    "end": "474960"
  },
  {
    "text": "down the training on all the nodes we've seen another issue with where a routine",
    "start": "474960",
    "end": "481800"
  },
  {
    "text": "firmware upgrade in the IB switch in the data center caused huge performance",
    "start": "481800",
    "end": "486919"
  },
  {
    "text": "degradation for multi- node training and that was done over the weekend so Monday",
    "start": "486919",
    "end": "492440"
  },
  {
    "text": "morning developers or researchers come in and suddenly the cluster is unusable meta has done some work on um",
    "start": "492440",
    "end": "501360"
  },
  {
    "text": "identifying the um failures and classifying them and they have published",
    "start": "501360",
    "end": "506840"
  },
  {
    "text": "bunch of this work of uh noted The Source below so while resiliency for AI",
    "start": "506840",
    "end": "513880"
  },
  {
    "text": "is you know is a multi-layer and is applicable in every layer of the stack",
    "start": "513880",
    "end": "519760"
  },
  {
    "text": "from application software to libraries to Frameworks lower level libraries system software kernel uh kernel drivers",
    "start": "519760",
    "end": "527560"
  },
  {
    "text": "and even the hardware the focus of this talk is on the kubernetes",
    "start": "527560",
    "end": "533160"
  },
  {
    "text": "infrastructure now uh we'll look into details of the AI infrastructure and its components hey uh so we go over the AI",
    "start": "533160",
    "end": "542160"
  },
  {
    "text": "infrastructure the the goal here is that you should be able to avoid failure at at first place uh prevent them because",
    "start": "542160",
    "end": "549560"
  },
  {
    "text": "the cost of detecting at later stages increases and then later on we will go into when failures happen when the job",
    "start": "549560",
    "end": "555120"
  },
  {
    "text": "is earning what to do okay to do that uh let's first go into what are the",
    "start": "555120",
    "end": "560680"
  },
  {
    "text": "components of the AI infrastructure stack uh the there are three main",
    "start": "560680",
    "end": "565839"
  },
  {
    "text": "component the first is the compute in compute we have GP operator scheduler and MPI operator GPU operator is is a",
    "start": "565839",
    "end": "575000"
  },
  {
    "text": "component which automates the provisioning of a software which enables the cuet to see the GPU by deploying our",
    "start": "575000",
    "end": "582120"
  },
  {
    "text": "device plugin it also uh enables bunch of other component for GPU management",
    "start": "582120",
    "end": "587839"
  },
  {
    "text": "and health monitoring uh the second is Schuler we need a Schuler with gang scheduling to",
    "start": "587839",
    "end": "593240"
  },
  {
    "text": "enable the multi-node job it should also have abilities like preemption and priority for the efficient U I ization",
    "start": "593240",
    "end": "599880"
  },
  {
    "text": "of resources uh MPI operator it enables a multi-node job and makes it easy to",
    "start": "599880",
    "end": "605800"
  },
  {
    "text": "run the all all red style multinode training it configures the Pod injects",
    "start": "605800",
    "end": "611200"
  },
  {
    "text": "the environment variable and manages a life cycle of the multinode job the next",
    "start": "611200",
    "end": "616640"
  },
  {
    "text": "is the network uh the network has two component Network operator and Ingress",
    "start": "616640",
    "end": "622560"
  },
  {
    "text": "Network operator manages the life cycle of RDMA IB interfaces it uh it enables a",
    "start": "622560",
    "end": "629760"
  },
  {
    "text": "device plugin which exposes them to the Cub so when you do describe node that's",
    "start": "629760",
    "end": "635079"
  },
  {
    "text": "that's how you see all the Nicks as well as the gpus the Ingress is responsible for enabling the users to do exec and",
    "start": "635079",
    "end": "642560"
  },
  {
    "text": "attach into their jobs the exec and attach is important functionality as machine learning researchers want to",
    "start": "642560",
    "end": "648399"
  },
  {
    "text": "look into uh look into the jobs and do a debugging the other piece of the picture",
    "start": "648399",
    "end": "654880"
  },
  {
    "text": "is storage there are three kinds of storage that we usually need one is the node local scratch space it's used for",
    "start": "654880",
    "end": "661959"
  },
  {
    "text": "storing the Emeral uh computation or the transient data sets the second is your",
    "start": "661959",
    "end": "668000"
  },
  {
    "text": "fast parallel remote storage something like Lusher where you can store your training code and data sets uh it needs",
    "start": "668000",
    "end": "674680"
  },
  {
    "text": "it's useful when you share this data set with your colleagues but also needs to have a ways you prevent the unauthorized",
    "start": "674680",
    "end": "681959"
  },
  {
    "text": "access the third is the object store which is useful for storing the checkpoint the checkpoints are useful",
    "start": "681959",
    "end": "687639"
  },
  {
    "text": "when you restart the job or during the inference and the last is observability",
    "start": "687639",
    "end": "695120"
  },
  {
    "text": "for monitoring you need a Prometheus grafana and a logging stack like gry log",
    "start": "695120",
    "end": "700440"
  },
  {
    "text": "uh we might also need something like job metric aggregator which can export the job metrics so that end user can see",
    "start": "700440",
    "end": "707760"
  },
  {
    "text": "those and determine the quality of the training and the last is you need a node problem detector which runs the plugins",
    "start": "707760",
    "end": "715480"
  },
  {
    "text": "uh and which runs the plugin and can determine the infrastructure problem s in the system like colel issues and all",
    "start": "715480",
    "end": "721600"
  },
  {
    "text": "of that okay so now we know what it takes to build the the the AI stack or",
    "start": "721600",
    "end": "728399"
  },
  {
    "text": "the components of AI stack and you have maybe a cluster ready so we want to now validate that cluster so how are we",
    "start": "728399",
    "end": "735120"
  },
  {
    "text": "going to do that the first is a software checks we have to ensure that the all the driver and libraries are compatible",
    "start": "735120",
    "end": "741600"
  },
  {
    "text": "with each other I can give an example the network operator and GP operator has to work together to enable the the RDMA",
    "start": "741600",
    "end": "748920"
  },
  {
    "text": "and if they are not incompatible you might see the degraded performance or maybe the multi node will not even work",
    "start": "748920",
    "end": "755120"
  },
  {
    "text": "uh tools like Argo can help you to bring the cluster in a consistent State and",
    "start": "755120",
    "end": "761320"
  },
  {
    "text": "make sure there's a predictable software running in the cluster okay now the software stack is okay now we have to do",
    "start": "761320",
    "end": "768199"
  },
  {
    "text": "test so you do a burn in test or you do a GPU burn in test and you can do an IB burning test and do them together to",
    "start": "768199",
    "end": "774920"
  },
  {
    "text": "make sure that devices are behaving as expected",
    "start": "774920",
    "end": "780040"
  },
  {
    "text": "uh next is you me menure that the performance is okay so we usually run",
    "start": "780040",
    "end": "786440"
  },
  {
    "text": "the heavy nickel test it can consist of uh GPU computation and all R style",
    "start": "786440",
    "end": "791760"
  },
  {
    "text": "communication and you to ensure that the bandwidth reported by those nickel test are within the tolerable limits the",
    "start": "791760",
    "end": "798880"
  },
  {
    "text": "other piece of picture which we often ignore is your control plane robustness you might want to run a small uh a large",
    "start": "798880",
    "end": "806760"
  },
  {
    "text": "number of small jobs to make sure your control plan is robust enough uh then",
    "start": "806760",
    "end": "812880"
  },
  {
    "text": "once we have reach that stage you want to have an end to end check which is a typical Megatron job or an llm job which",
    "start": "812880",
    "end": "818920"
  },
  {
    "text": "touches your storage computer network all parts of a system and then uh the",
    "start": "818920",
    "end": "824240"
  },
  {
    "text": "last which is tuning it's very close to my heart too uh so so you have to do the",
    "start": "824240",
    "end": "831279"
  },
  {
    "text": "system tuning to get a maximum performance out of your existing system sometime you have to do over tuning like",
    "start": "831279",
    "end": "836360"
  },
  {
    "text": "setting the VM Max thread or FS I ify settings which ensures that your system",
    "start": "836360",
    "end": "842199"
  },
  {
    "text": "can give you best performance for that workloads the other is the ks client",
    "start": "842199",
    "end": "847360"
  },
  {
    "text": "tuning by default if your systems is have using the cube config client they have a low value of QPS and burst and if",
    "start": "847360",
    "end": "855560"
  },
  {
    "text": "you do not tune them your your system component uh will do the self throttling",
    "start": "855560",
    "end": "861399"
  },
  {
    "text": "and you might see a slowness in in in them okay now we have validated the",
    "start": "861399",
    "end": "868639"
  },
  {
    "text": "cluster uh let's start run a job but you might",
    "start": "868639",
    "end": "873759"
  },
  {
    "text": "run into issues where job start running and immediately goes bad so how do we prevent that we do that by running",
    "start": "873759",
    "end": "880600"
  },
  {
    "text": "pre-flight checks they usually run as in form of inet containers uh you will do the you can do the pre-flight check by",
    "start": "880600",
    "end": "887240"
  },
  {
    "text": "running the network storage and compute test in the compute test you run the GPU test and check the heal temperature and",
    "start": "887240",
    "end": "893360"
  },
  {
    "text": "memory you might check for the ECC error for the network test you run a collective communication ation test",
    "start": "893360",
    "end": "899519"
  },
  {
    "text": "which is typically a nickel test and ensure that the bandwidth reported by these nickel tests are within the",
    "start": "899519",
    "end": "904639"
  },
  {
    "text": "tolerable limit third is a storage test you might want to make sure that you have the the persistent storage which",
    "start": "904639",
    "end": "911320"
  },
  {
    "text": "will be attached to your job you have access to that and you're able to read right into",
    "start": "911320",
    "end": "916480"
  },
  {
    "text": "that okay so now we have covered the part of the cluster how to validate and",
    "start": "916480",
    "end": "922040"
  },
  {
    "text": "how to run a PreFlight job now if a job is running and then it gets some issue",
    "start": "922040",
    "end": "928720"
  },
  {
    "text": "happen how do we get there so enter the the fall tolerance so first we're going to",
    "start": "928720",
    "end": "934240"
  },
  {
    "text": "talk about the building blocks of fall tolerance the mechanisms of the building blocks there are four building blocks",
    "start": "934240",
    "end": "941199"
  },
  {
    "text": "let's go over them one by one the first is monitoring monitoring is defined as",
    "start": "941199",
    "end": "947279"
  },
  {
    "text": "methods and processing of detecting fault and performance uh it you measure you can",
    "start": "947279",
    "end": "953800"
  },
  {
    "text": "measure a goodput degradation goodput is defined as a useful computation versus a",
    "start": "953800",
    "end": "959399"
  },
  {
    "text": "total elapse time the another word that is used is uh mfu uh as a synonym to",
    "start": "959399",
    "end": "966240"
  },
  {
    "text": "determine whether there's a degradation in the performance the next is propagation once",
    "start": "966240",
    "end": "972399"
  },
  {
    "text": "you detect the error you have to Upstream it to higher layers and that that mechanism is called propagation so",
    "start": "972399",
    "end": "978839"
  },
  {
    "text": "that higher layer can take action it should ideally contain error message and error code uh next is recovery recovery",
    "start": "978839",
    "end": "985600"
  },
  {
    "text": "are the steps such that entity that controls the job to determine the course of action depending on what error is",
    "start": "985600",
    "end": "992279"
  },
  {
    "text": "there it can range from you know restarting the job to just maybe killing the job and the last building blocks is",
    "start": "992279",
    "end": "997800"
  },
  {
    "text": "remediation which is the process of evaluating the fault and taking action to fix that fault is called",
    "start": "997800",
    "end": "1004519"
  },
  {
    "text": "remediation now we know what are the building blocks let's go how we can uh",
    "start": "1004519",
    "end": "1010319"
  },
  {
    "text": "Implement what are techniques for them so for monitoring we use typically use",
    "start": "1010319",
    "end": "1015639"
  },
  {
    "text": "heartbeats to detect the status of our critical components you can also pole devices for any potential issues and you",
    "start": "1015639",
    "end": "1023120"
  },
  {
    "text": "can use Watch Dogs to watch over logs and determine if there are issues uh for propagation we rely on events labels",
    "start": "1023120",
    "end": "1031360"
  },
  {
    "text": "condition or even crash dumps for process level monitoring uh then there is recovery so",
    "start": "1031360",
    "end": "1038400"
  },
  {
    "text": "recovery you can do fast restart local rank restart node swap uh and or H",
    "start": "1038400",
    "end": "1044120"
  },
  {
    "text": "spares these are various strategies by which you can recover a job and the last",
    "start": "1044120",
    "end": "1049600"
  },
  {
    "text": "is remediation uh you can do like node reboot or system update or GPU link",
    "start": "1049600",
    "end": "1055760"
  },
  {
    "text": "reset or sometime even manual interventions so these are the techniques in next couple of sections we",
    "start": "1055760",
    "end": "1061559"
  },
  {
    "text": "are going to go deep dive into each of these building blocks okay where are these technique",
    "start": "1061559",
    "end": "1067960"
  },
  {
    "text": "can be implemented so so monitoring can be implemented and you can have a node level fault aggregation which can look",
    "start": "1067960",
    "end": "1074200"
  },
  {
    "text": "over all monitoring component giv you an outcome whether a node is healthy or unhealthy uh it can be in node problem",
    "start": "1074200",
    "end": "1079440"
  },
  {
    "text": "detector in form of the plugins it can be in G GPU device plug-in you can also have your per rank monitor which",
    "start": "1079440",
    "end": "1087240"
  },
  {
    "text": "monitors the rank of your training job a propagation uh lives in prop in",
    "start": "1087240",
    "end": "1093919"
  },
  {
    "text": "form of node condition or pod condition or in Prometheus metrix uh recovery can be implemented in",
    "start": "1093919",
    "end": "1101480"
  },
  {
    "text": "MPI operator job controller and Schuler Schuler can be tuned to not consider unhealthy node for scheduling",
    "start": "1101480",
    "end": "1108880"
  },
  {
    "text": "and Remediation can be in form of remediation operator or a node node life cycle management",
    "start": "1108880",
    "end": "1115200"
  },
  {
    "text": "component okay now we know what how and where of the building blocks of fall",
    "start": "1115200",
    "end": "1120520"
  },
  {
    "text": "tolerance let's Deep dive into each one of them starting with monitoring so monitoring can typically",
    "start": "1120520",
    "end": "1128799"
  },
  {
    "text": "be implemented using the four broad or five technique first is nvml nvml is a c",
    "start": "1128799",
    "end": "1136080"
  },
  {
    "text": "based API for monitoring and managing the ious status of Nvidia device GPU it",
    "start": "1136080",
    "end": "1142000"
  },
  {
    "text": "has Python and pearl binding available as well it can integrate with your training",
    "start": "1142000",
    "end": "1147880"
  },
  {
    "text": "code uh dcgm exporter it exports the the GPU metrix uh the dcgm is actually a set",
    "start": "1147880",
    "end": "1155120"
  },
  {
    "text": "of tools for GPU monitoring and Diagnostic and it it integrates with kubernetes via dcgm exporter which",
    "start": "1155120",
    "end": "1162280"
  },
  {
    "text": "exports the metric which can be leveraged kernel logs uh is a reliable mechanism to detect the xid SX ID error",
    "start": "1162280",
    "end": "1170559"
  },
  {
    "text": "because GPU driver inherently logs into the in there uh and then there is for",
    "start": "1170559",
    "end": "1176200"
  },
  {
    "text": "networking issues you can rely on the RDMA counters which lies in the CFS and determine whether there are link flaps",
    "start": "1176200",
    "end": "1182320"
  },
  {
    "text": "or things like that uh you can have ml specific job processes and you can rely",
    "start": "1182320",
    "end": "1188039"
  },
  {
    "text": "on failure message and exit code paring to determine that what fault has",
    "start": "1188039",
    "end": "1193120"
  },
  {
    "text": "occurred okay let's go deep into each of these uh the first is the MML the nvml",
    "start": "1193120",
    "end": "1200080"
  },
  {
    "text": "can help you get the the ECC error count which indicates that there's a data corruption or not uh it also tells you",
    "start": "1200080",
    "end": "1206039"
  },
  {
    "text": "about GP utilization low GP utilization while the job is ongoing the sign of a",
    "start": "1206039",
    "end": "1211559"
  },
  {
    "text": "let's say task hang and if you want to debug more you can find out the active compute processes running on this uh",
    "start": "1211559",
    "end": "1217760"
  },
  {
    "text": "running on the GPU uh temperature and fan fan speed can be uh can be used to",
    "start": "1217760",
    "end": "1223880"
  },
  {
    "text": "leverage to reason the GPU performance degradation and and other identification details can be useful in",
    "start": "1223880",
    "end": "1230960"
  },
  {
    "text": "remediation uh this is a nvml sample code it's a simple Library you just input in uh you just import the library",
    "start": "1230960",
    "end": "1238159"
  },
  {
    "text": "go over each devices and get the respective fan speed name temperature or power",
    "start": "1238159",
    "end": "1244320"
  },
  {
    "text": "usage okay let jump into dcgm so dcgm exporter can export a lot of metrics",
    "start": "1244320",
    "end": "1250280"
  },
  {
    "text": "including xid or ECC error this SL presents metrics specifically related to",
    "start": "1250280",
    "end": "1255440"
  },
  {
    "text": "the clock throttle reasons uh the clock throttling can lead lead to degraded performance and often can explain the",
    "start": "1255440",
    "end": "1261240"
  },
  {
    "text": "straggler Behavior Uh the software thermal or Hardware thermal are indicator of temperature being too high",
    "start": "1261240",
    "end": "1268039"
  },
  {
    "text": "display clocks determine the speed of rendering or display related task and",
    "start": "1268039",
    "end": "1273240"
  },
  {
    "text": "clock setting determine the the processor speed now let's figure out how to find",
    "start": "1273240",
    "end": "1280320"
  },
  {
    "text": "xid or SX ID error you can typically set up a Watch Dog on kernel logs and you can find that signature string",
    "start": "1280320",
    "end": "1286600"
  },
  {
    "text": "determining whether the xid error has occurred or not the why we use Cal logs because it's a",
    "start": "1286600",
    "end": "1293240"
  },
  {
    "text": "most reliable mechanism to detect xid and SX ID given the epimeral nature of",
    "start": "1293240",
    "end": "1298600"
  },
  {
    "text": "these events the the error reported from NV switch it it is logged as SX ID and",
    "start": "1298600",
    "end": "1304640"
  },
  {
    "text": "error reported by GPU driver is log as an xid uh you uh okay so moving on uh the",
    "start": "1304640",
    "end": "1314400"
  },
  {
    "text": "kernel locks can also help you determine the IB related or network related issue ues so you can determine the IB link",
    "start": "1314400",
    "end": "1321520"
  },
  {
    "text": "flaps uh and uh from the Cal logs by searching for those particular strings",
    "start": "1321520",
    "end": "1326919"
  },
  {
    "text": "and they can often explain the behavior of a nickel timeouts or issues like that the ethernet link flap can also be",
    "start": "1326919",
    "end": "1333520"
  },
  {
    "text": "determined using D messages and these link flap can also be the root cause of your mysterious application",
    "start": "1333520",
    "end": "1341840"
  },
  {
    "text": "failures uh the other is the the RDMA counters uh they can be used to determine the the network issues for",
    "start": "1343000",
    "end": "1349520"
  },
  {
    "text": "example packet sequence count or local act timeout error they indicate that there's a issue with the note toote",
    "start": "1349520",
    "end": "1354960"
  },
  {
    "text": "communication link flap counter tell us how many times the RDMA interface has flapped uh this link down and Link",
    "start": "1354960",
    "end": "1361600"
  },
  {
    "text": "recovery are the counter to determine how many time the IB link has flapped they can often explain your nickel",
    "start": "1361600",
    "end": "1366720"
  },
  {
    "text": "timeout and transcent application failure we are often sometime in those situations where the application fail",
    "start": "1366720",
    "end": "1372559"
  },
  {
    "text": "when we look at a system uh it it seems fine and that's when these come handy",
    "start": "1372559",
    "end": "1377640"
  },
  {
    "text": "because uh a link flapped it means that at time of application failure the link has flapped",
    "start": "1377640",
    "end": "1383159"
  },
  {
    "text": "but when you look at it it seems fine okay now let's go into the",
    "start": "1383159",
    "end": "1388880"
  },
  {
    "text": "troubleshooting test uh so one is we use nickel test the you can you can conduct",
    "start": "1388880",
    "end": "1395400"
  },
  {
    "text": "a pairwise nickel test and by running a test in pods the nickel test status and",
    "start": "1395400",
    "end": "1400600"
  },
  {
    "text": "reported bandwidth they can indicate that whether there's an issue with application or there's an issue with",
    "start": "1400600",
    "end": "1406159"
  },
  {
    "text": "underlying Hardware uh if teal test passes that means that your application might be having some issues but if",
    "start": "1406159",
    "end": "1411640"
  },
  {
    "text": "there's issue with the hardware you might need to do further debugging you have to start probably from foundation",
    "start": "1411640",
    "end": "1416760"
  },
  {
    "text": "and you have to work your way up you first want to check the device status using typical commands like ibv device",
    "start": "1416760",
    "end": "1422159"
  },
  {
    "text": "device info or MSD status or IB stat depending on the type of your network setup and environment uh once you know",
    "start": "1422159",
    "end": "1429840"
  },
  {
    "text": "your device it is okay you might want to do some ping test and and then you can further do the bandwidth test uh if P",
    "start": "1429840",
    "end": "1436960"
  },
  {
    "text": "ping tests are okay the bandd test can help you determine whether there's a degradation in bandwidth in your system or not uh sometime it is also important",
    "start": "1436960",
    "end": "1444640"
  },
  {
    "text": "to look into start from the lower Hardware level and you can use commands",
    "start": "1444640",
    "end": "1450200"
  },
  {
    "text": "like M mlx link or mlx config which can tell you about the state of the link in the device configuration",
    "start": "1450200",
    "end": "1456440"
  },
  {
    "text": "respectively uh if the device status is up and and ping test fail uh that means",
    "start": "1456440",
    "end": "1464159"
  },
  {
    "text": "that there can be an issue with your network control plane management software or sometime we have seen issues where",
    "start": "1464159",
    "end": "1472080"
  },
  {
    "text": "the device status is down it would have it pointed us to a cni issue or the",
    "start": "1472080",
    "end": "1477559"
  },
  {
    "text": "issue with the deployment of your network operator components okay now this covered",
    "start": "1477559",
    "end": "1483760"
  },
  {
    "text": "monitoring like you we discussed about how we figured out xid error clock",
    "start": "1483760",
    "end": "1489240"
  },
  {
    "text": "throttle error which tells the degradation uh we we talked about the network or IB link error now let's talk",
    "start": "1489240",
    "end": "1495480"
  },
  {
    "text": "about propagation prop so once error are detected they need to be propagated to",
    "start": "1495480",
    "end": "1500799"
  },
  {
    "text": "the higher layer up the error signal which is typical in form of let's say a",
    "start": "1500799",
    "end": "1505840"
  },
  {
    "text": "pulling device or kernel xid can be sent to a node fault aggregator which can also listen to let's say dcgm Matrix the",
    "start": "1505840",
    "end": "1513080"
  },
  {
    "text": "node faal aggregator can translate this signal into a node condition as well as a pod condition why pod condition",
    "start": "1513080",
    "end": "1519799"
  },
  {
    "text": "because the job controller only monitors PS it does not monitor nodes the SP condition can be taken as a input by MPI",
    "start": "1519799",
    "end": "1526480"
  },
  {
    "text": "operator and can further be taken as input by job controller who can take a recovery action as well as as well as up",
    "start": "1526480",
    "end": "1536440"
  },
  {
    "text": "as well as translate that message into a job status your note condition will be",
    "start": "1536440",
    "end": "1541679"
  },
  {
    "text": "an input to your remediation operator which can send that input further to your Hardware provider who can uh who",
    "start": "1541679",
    "end": "1549799"
  },
  {
    "text": "can use this message to to determine the long-term patterns of the failure and can take uh corrective",
    "start": "1549799",
    "end": "1556399"
  },
  {
    "text": "action uh scheduler can also use this message uh the the node condition",
    "start": "1556399",
    "end": "1561480"
  },
  {
    "text": "message to reject the node from further scheduling until the remediation is done on that particular",
    "start": "1561480",
    "end": "1567360"
  },
  {
    "text": "node uh here you see a typical status of a job after it is recued so it indicates",
    "start": "1567360",
    "end": "1574039"
  },
  {
    "text": "that we the the controller has detected the error and restarted it that's why it",
    "start": "1574039",
    "end": "1579360"
  },
  {
    "text": "moved from running to cued and then back to running and cute indicates the the error that has",
    "start": "1579360",
    "end": "1585240"
  },
  {
    "text": "occurred okay so now from monitoring to prop ation now let's go over the recovery strategies okay thanks harit so",
    "start": "1585240",
    "end": "1594080"
  },
  {
    "text": "recovery is all about you know getting your job back up and running and making",
    "start": "1594080",
    "end": "1599440"
  },
  {
    "text": "progress so there are a few options available this is more in the application and your job life cycle so",
    "start": "1599440",
    "end": "1606360"
  },
  {
    "text": "there are a few op options available depending on what caused the error in the first place and how many resources",
    "start": "1606360",
    "end": "1611679"
  },
  {
    "text": "you have in a cluster a job workload can be recovered either within the job itself if if the application has the",
    "start": "1611679",
    "end": "1618799"
  },
  {
    "text": "ability to do that or you can do a cluster wide restart and there are a bunch of options for each of these and",
    "start": "1618799",
    "end": "1625080"
  },
  {
    "text": "we'll go through them the quickest form of recovery is an inprocess recovery",
    "start": "1625080",
    "end": "1630279"
  },
  {
    "text": "where if your process crashes or dies you just restart it locally um maybe you",
    "start": "1630279",
    "end": "1635480"
  },
  {
    "text": "have a monitor running of course this depends on um what kind of Errors cause",
    "start": "1635480",
    "end": "1640600"
  },
  {
    "text": "the process to die in the first place so things like link flaps or GPU Cuda errors uh you could use this strategy",
    "start": "1640600",
    "end": "1648480"
  },
  {
    "text": "um this strategy can sometimes take a time take some time for the uh new",
    "start": "1648480",
    "end": "1653799"
  },
  {
    "text": "thread to start because of loading the libraries and loading the GPU memory and all that so you might want to optimize",
    "start": "1653799",
    "end": "1661080"
  },
  {
    "text": "it by running a you know background process that just sleeps waiting for the main process to die and when the main",
    "start": "1661080",
    "end": "1667279"
  },
  {
    "text": "process dies it just uh recovers and uh continues the",
    "start": "1667279",
    "end": "1672519"
  },
  {
    "text": "work um if the application is able to support it and if the failure is not",
    "start": "1672519",
    "end": "1678600"
  },
  {
    "text": "transient then you might have to move to a different node uh one way to do that",
    "start": "1678600",
    "end": "1683799"
  },
  {
    "text": "is if you don't have additional uh capacity in the cluster the application can just run on the healthy noes and uh",
    "start": "1683799",
    "end": "1691720"
  },
  {
    "text": "exclude the note where the failure happened uh this of course means that",
    "start": "1691720",
    "end": "1697200"
  },
  {
    "text": "you have loss in capacity in the application and so your performance may not be as much as it was earlier but the",
    "start": "1697200",
    "end": "1703880"
  },
  {
    "text": "restart on the healthy nodes means that your pro your application can make progress",
    "start": "1703880",
    "end": "1709159"
  },
  {
    "text": "uh there might be some additional requirements from the DL layers or Frameworks like uh flexible checkpoints",
    "start": "1709159",
    "end": "1716399"
  },
  {
    "text": "to work on different uh sizes of the uh Hardware resources available and say a",
    "start": "1716399",
    "end": "1722760"
  },
  {
    "text": "compilation cach depending on what Frameworks you're using the other way if you your",
    "start": "1722760",
    "end": "1728480"
  },
  {
    "text": "application can support it is to start with a hot spare the spare nodes are just idle capacity that you keep on",
    "start": "1728480",
    "end": "1734559"
  },
  {
    "text": "standby in case you know one of the nodes where you're running the job fails you just migrate over to the spare",
    "start": "1734559",
    "end": "1740960"
  },
  {
    "text": "capacity and abandon the node that you were running on uh warm sparing minimizes restart time or also locks up",
    "start": "1740960",
    "end": "1748799"
  },
  {
    "text": "capacity that could be used for other kind of workloads now if it is not possible to",
    "start": "1748799",
    "end": "1754279"
  },
  {
    "text": "restart your application uh within the job itself it calls for a cluster level",
    "start": "1754279",
    "end": "1759840"
  },
  {
    "text": "restart for that you can imagine a workflow where the fault detection um",
    "start": "1759840",
    "end": "1765159"
  },
  {
    "text": "happens and the monitoring components bubble up the error propagate it using",
    "start": "1765159",
    "end": "1770720"
  },
  {
    "text": "node condition updates or P condition updates to the API server and into your",
    "start": "1770720",
    "end": "1776480"
  },
  {
    "text": "MP operator and job controller once the job controll gets it it can um you know",
    "start": "1776480",
    "end": "1781919"
  },
  {
    "text": "trigger either restart or just kill the job if there's just too many of your",
    "start": "1781919",
    "end": "1787720"
  },
  {
    "text": "resources are failed it's also possible sometimes that your application will notice errors before the monitoring",
    "start": "1787720",
    "end": "1794120"
  },
  {
    "text": "components can notice and in that case various exit codes can be used to uh",
    "start": "1794120",
    "end": "1799519"
  },
  {
    "text": "send a message to the job controller that it needs to be restarted a knif job of uh restart of",
    "start": "1799519",
    "end": "1806000"
  },
  {
    "text": "course is the simplest to implement if a job fails and it exits with a non-zero error code you just restart it but",
    "start": "1806000",
    "end": "1812720"
  },
  {
    "text": "depending on the type of cluster you have uh it can lead to some negative effects where if you have a multi-user",
    "start": "1812720",
    "end": "1819480"
  },
  {
    "text": "multi-tenant cluster then the newly scheduled job can be at the end of the",
    "start": "1819480",
    "end": "1824880"
  },
  {
    "text": "queue or have a higher startup time depending on what nodes gets selected uh you there are some optimizations",
    "start": "1824880",
    "end": "1831320"
  },
  {
    "text": "possible to reduce the Q time it could you know uh be restarted with a higher priority and to reduce the startup time",
    "start": "1831320",
    "end": "1838919"
  },
  {
    "text": "you could choose to use a bunch of the healthy notes from the previous run that are available in the",
    "start": "1838919",
    "end": "1845519"
  },
  {
    "text": "cluster of course it's also possible to start with A reduced World size uh but",
    "start": "1845519",
    "end": "1851640"
  },
  {
    "text": "then in this case you'll have to adjust the application parameters to make sure that the application understands that",
    "start": "1851640",
    "end": "1857279"
  },
  {
    "text": "the fuel resour es this time uh when it's starting the workload the next is to start with warm",
    "start": "1857279",
    "end": "1864080"
  },
  {
    "text": "spares if you have enough capacity in your cluster uh you keep some nodes idle",
    "start": "1864080",
    "end": "1869559"
  },
  {
    "text": "and then if one of the node fails with a non-transient error then you can move",
    "start": "1869559",
    "end": "1875240"
  },
  {
    "text": "the workload over to the U standby or the warm nodes uh this way uh the",
    "start": "1875240",
    "end": "1881600"
  },
  {
    "text": "application can run with expected capacity however some capacity in your",
    "start": "1881600",
    "end": "1887039"
  },
  {
    "text": "cluster overall is lost to standby nodes which are just sitting there idle and you don't want to probably do that in",
    "start": "1887039",
    "end": "1893159"
  },
  {
    "text": "the next slide we'll see how to optimize that so if your scheduler can support",
    "start": "1893159",
    "end": "1898440"
  },
  {
    "text": "preemption uh you might want you might run lower priority applications on those spare nodes and then when the main job",
    "start": "1898440",
    "end": "1906120"
  },
  {
    "text": "runs into error you can preempt an existing workload uh low priority",
    "start": "1906120",
    "end": "1911200"
  },
  {
    "text": "workload could be something like a fine tuning or data parallel job that is",
    "start": "1911200",
    "end": "1917120"
  },
  {
    "text": "running and can be preempted and you can move the application over to that node",
    "start": "1917120",
    "end": "1922200"
  },
  {
    "text": "and therefore you know keep the utilization high once you've figured out that hey so",
    "start": "1922200",
    "end": "1930720"
  },
  {
    "text": "one node has to be cordoned off then you'll need to run some tests on it to make sure that it is in a healthy State",
    "start": "1930720",
    "end": "1938279"
  },
  {
    "text": "and for that typically you would go through a no life cycle kind of workflow where uh it's required to run some tests",
    "start": "1938279",
    "end": "1946120"
  },
  {
    "text": "um on the Node which will try to detect and attribute the error to a subsystem",
    "start": "1946120",
    "end": "1952519"
  },
  {
    "text": "uh test should be run to make sure that the um IB links the gpus and memory and",
    "start": "1952519",
    "end": "1958720"
  },
  {
    "text": "all of those are tested but not in isolation because typically a failure in one subsystem can cause uh the other",
    "start": "1958720",
    "end": "1965039"
  },
  {
    "text": "subsystem to fail so typically you want to run test that exercise the entire node and all of the components in it if",
    "start": "1965039",
    "end": "1972240"
  },
  {
    "text": "those tests succeed you could move that node back into production if not a reboot could be used",
    "start": "1972240",
    "end": "1978399"
  },
  {
    "text": "if that also doesn't work then you might have to move the node into um RMA or",
    "start": "1978399",
    "end": "1983880"
  },
  {
    "text": "some manual intervention might be required here are some of",
    "start": "1983880",
    "end": "1988960"
  },
  {
    "text": "the uh some of the um typical errors that we see and uh what you can do with",
    "start": "1988960",
    "end": "1994720"
  },
  {
    "text": "it uh lost GPU or falling off the bus is a very common error and sometimes cual",
    "start": "1994720",
    "end": "2001480"
  },
  {
    "text": "can report GPU as missing for a benign exidy error um it is advisable to check",
    "start": "2001480",
    "end": "2008159"
  },
  {
    "text": "nvml uh if the gpus actually has an error and is missing in case it does then a node",
    "start": "2008159",
    "end": "2015399"
  },
  {
    "text": "reboot can help if that also doesn't work it might be required to replace the GPU uh if your gpus or Nicks are",
    "start": "2015399",
    "end": "2022360"
  },
  {
    "text": "overheating most likely it is due to uh bad fans or improper Cooling and you",
    "start": "2022360",
    "end": "2028240"
  },
  {
    "text": "might need a nor RMA uh link CLA can happen temporarily or permanently you might have to check",
    "start": "2028240",
    "end": "2035120"
  },
  {
    "text": "the uh NX it's themselves they also can sometimes uh behave differently when",
    "start": "2035120",
    "end": "2040519"
  },
  {
    "text": "they're overheated the switches uh in your data center and a node reboot might",
    "start": "2040519",
    "end": "2046480"
  },
  {
    "text": "help as well sometimes your CSI Parts lose connection to the remote storage so",
    "start": "2046480",
    "end": "2053040"
  },
  {
    "text": "checking the status and resetting them will also help the uh we have Nvidia has",
    "start": "2053040",
    "end": "2058679"
  },
  {
    "text": "given a bunch of guidelines and a a nice flow chart for debute debugging and uh",
    "start": "2058679",
    "end": "2065200"
  },
  {
    "text": "I've listed the link here so with that we'll talk about enhancements yeah here",
    "start": "2065200",
    "end": "2071638"
  },
  {
    "text": "we come to the last part so these are the few few things we observed as a gap",
    "start": "2071639",
    "end": "2076878"
  },
  {
    "text": "in ecosystem first is that we are in a situation where we have to scale to 100,000 gpus which means that to 10 to",
    "start": "2076879",
    "end": "2084520"
  },
  {
    "text": "15,000 work on nodes today cubet Max supports is around 5,000 nodes so we",
    "start": "2084520",
    "end": "2089960"
  },
  {
    "text": "might have to start thinking about scale from the point of view ofcd API server",
    "start": "2089960",
    "end": "2095240"
  },
  {
    "text": "the scale need to be T through with this new uh training Paradigm uh the kest",
    "start": "2095240",
    "end": "2100800"
  },
  {
    "text": "schuer is not natively for gang scheduling so we might need preemption and priority uh in build and we we",
    "start": "2100800",
    "end": "2109079"
  },
  {
    "text": "there's a lack of standardized error code which can help the job controllers and application writer to uh to",
    "start": "2109079",
    "end": "2116359"
  },
  {
    "text": "communicate via a common understanding and help distinguish between infrastructure and application error so",
    "start": "2116359",
    "end": "2122200"
  },
  {
    "text": "with this slide ends uh any questions or you can scan the the QR code to give us",
    "start": "2122200",
    "end": "2128160"
  },
  {
    "text": "feedback for this session thank you thank [Applause]",
    "start": "2128160",
    "end": "2136920"
  },
  {
    "text": "you sure so um do you have any recommendations for checkpointing",
    "start": "2136920",
    "end": "2143680"
  },
  {
    "text": "strategies yeah so for checkpointing it's a very um framework um specific",
    "start": "2143680",
    "end": "2151560"
  },
  {
    "text": "strategies uh we have collaborated with various companies across the industry",
    "start": "2151560",
    "end": "2157160"
  },
  {
    "text": "and working with the Frameworks like pyts Jacks and other Frameworks to uh",
    "start": "2157160",
    "end": "2163480"
  },
  {
    "text": "help with um making checkpointing faster uh so things like asynchronous",
    "start": "2163480",
    "end": "2168880"
  },
  {
    "text": "checkpointing inmemory checkpointing and very fast recovery strategies is something that's work in progress",
    "start": "2168880",
    "end": "2175240"
  },
  {
    "text": "available um there's also a gap in ecosystem today there's no way infra can tell the application to do the",
    "start": "2175240",
    "end": "2182240"
  },
  {
    "text": "checkpoint yeah yeah yeah one thing you might want to do is in the slide where the job control sending a signal to the",
    "start": "2182240",
    "end": "2189319"
  },
  {
    "text": "application to die it might one of the steps the application can do is hey do",
    "start": "2189319",
    "end": "2194560"
  },
  {
    "text": "just in time checkpoints before it dies so that next time you have very little amount of work that is actually lost",
    "start": "2194560",
    "end": "2201000"
  },
  {
    "text": "after you restore thank you um so what is the main",
    "start": "2201000",
    "end": "2206880"
  },
  {
    "text": "difference between remediation and Recovery looks like very similar so remediation is on the Node side where",
    "start": "2206880",
    "end": "2214760"
  },
  {
    "text": "you want to test run test on the Node and figure out what components have failed and then take corrective actions",
    "start": "2214760",
    "end": "2221960"
  },
  {
    "text": "recovery is on the job and application side where you want to figure out what's the fastest way to restart the job or",
    "start": "2221960",
    "end": "2229680"
  },
  {
    "text": "remove the uh faulty nodes from your working set and continue your job with",
    "start": "2229680",
    "end": "2236200"
  },
  {
    "text": "um the healthy nodes that you have in your cluster or in your data center so so basically difference in scope",
    "start": "2236200",
    "end": "2242119"
  },
  {
    "text": "difference in scope and also different layers",
    "start": "2242119",
    "end": "2247040"
  },
  {
    "text": "give it a minute I I'm sure you guys are aware of Lollipop right inside of",
    "start": "2256520",
    "end": "2262760"
  },
  {
    "text": "Nvidia uh Aaron Ericson's project to build",
    "start": "2262760",
    "end": "2268000"
  },
  {
    "text": "autonomous AI observability agents mhm yeah do do you do you use that source",
    "start": "2268000",
    "end": "2274440"
  },
  {
    "text": "for um some of the yeah we have not used that in our okay",
    "start": "2274440",
    "end": "2280079"
  },
  {
    "text": "maybe that's a use case I know it started with primarily slurm clusters",
    "start": "2280079",
    "end": "2285319"
  },
  {
    "text": "okay but I think there's isn't there some project now going on too with um ex",
    "start": "2285319",
    "end": "2291040"
  },
  {
    "text": "expanding those things into kubernetes right okay so might be we can look might be interesting I think the time is up we",
    "start": "2291040",
    "end": "2298200"
  },
  {
    "text": "we can discuss outside here as well it's fine we can take one more question that yeah sure go oh hi this is W from like B",
    "start": "2298200",
    "end": "2307560"
  },
  {
    "text": "like previously like you mentioned like I think somewh from Nidia mentioned like you just released the HCC like",
    "start": "2307560",
    "end": "2314440"
  },
  {
    "text": "confidential container uh so I was wondering like if we open HCC mode uh",
    "start": "2314440",
    "end": "2320599"
  },
  {
    "text": "are the monitoring still work and um it all the like special registers still",
    "start": "2320599",
    "end": "2326480"
  },
  {
    "text": "open to the like VMS all like partially are down like so nvml should still be",
    "start": "2326480",
    "end": "2332480"
  },
  {
    "text": "able to give you the information that's required so it's still through exactly the same process yes yes it is still the",
    "start": "2332480",
    "end": "2338640"
  },
  {
    "text": "same process uh confidential compute encrypts the data in the memory not the",
    "start": "2338640",
    "end": "2344119"
  },
  {
    "text": "U monitoring aspects of the GPU yeah thank you thank you thank",
    "start": "2344119",
    "end": "2350839"
  },
  {
    "text": "you all right thank you thank you everybody",
    "start": "2353720",
    "end": "2359079"
  }
]
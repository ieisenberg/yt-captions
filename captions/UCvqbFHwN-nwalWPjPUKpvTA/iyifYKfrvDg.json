[
  {
    "text": "hey everyone my name is Son Panda so",
    "start": "160",
    "end": "2960"
  },
  {
    "text": "let's start welcome to Qflow Summit this",
    "start": "2960",
    "end": "6720"
  },
  {
    "text": "is empowering ML workloads with Qflow",
    "start": "6720",
    "end": "10000"
  },
  {
    "text": "Jax distributed training and LLM hyper",
    "start": "10000",
    "end": "13440"
  },
  {
    "text": "parameter",
    "start": "13440",
    "end": "14599"
  },
  {
    "text": "optimization so I am Sundep Panda i work",
    "start": "14599",
    "end": "18800"
  },
  {
    "text": "as a member of technical staff at",
    "start": "18800",
    "end": "20439"
  },
  {
    "text": "DevZero i am also a CNCF ambassador and",
    "start": "20439",
    "end": "23519"
  },
  {
    "text": "member of Kubernetes and Cubeflow my",
    "start": "23519",
    "end": "26400"
  },
  {
    "text": "co-speaker Helen unfortunately could not",
    "start": "26400",
    "end": "28800"
  },
  {
    "text": "be with us here today but she has sent",
    "start": "28800",
    "end": "31359"
  },
  {
    "text": "in a recording of her part of the",
    "start": "31359",
    "end": "33280"
  },
  {
    "text": "session so we'll play it",
    "start": "33280",
    "end": "35239"
  },
  {
    "text": "shortly so here's what we'll be",
    "start": "35239",
    "end": "37760"
  },
  {
    "text": "discussing today first Helen will be",
    "start": "37760",
    "end": "40079"
  },
  {
    "text": "sharing LLM hyperarameter optimization",
    "start": "40079",
    "end": "43440"
  },
  {
    "text": "the motivation behind her work some",
    "start": "43440",
    "end": "45920"
  },
  {
    "text": "existing work and design of the tune API",
    "start": "45920",
    "end": "48160"
  },
  {
    "text": "and then she will go through a quick",
    "start": "48160",
    "end": "49520"
  },
  {
    "text": "demo and after that we will see how we",
    "start": "49520",
    "end": "52239"
  },
  {
    "text": "can perform Jax distributed training on",
    "start": "52239",
    "end": "54719"
  },
  {
    "text": "Kubernetes using the cubeflow training",
    "start": "54719",
    "end": "56760"
  },
  {
    "text": "operator we'll learn when to use Jax and",
    "start": "56760",
    "end": "60160"
  },
  {
    "text": "we'll have a look at the Jax job API",
    "start": "60160",
    "end": "62840"
  },
  {
    "text": "configuration and we'll learn something",
    "start": "62840",
    "end": "65040"
  },
  {
    "text": "about SPDM programming with Jax we'll",
    "start": "65040",
    "end": "68000"
  },
  {
    "text": "run a quick demo and I'll share with you",
    "start": "68000",
    "end": "70000"
  },
  {
    "text": "how you can get involved in the cubeflow",
    "start": "70000",
    "end": "72720"
  },
  {
    "text": "community as well so uh over to Helen",
    "start": "72720",
    "end": "76479"
  },
  {
    "text": "for now",
    "start": "76479",
    "end": "79719"
  },
  {
    "text": "hello everyone i'm Helen unfortunately I",
    "start": "85119",
    "end": "88479"
  },
  {
    "text": "couldn't join the conference in person",
    "start": "88479",
    "end": "91200"
  },
  {
    "text": "and I'd like to thank my co-speaker",
    "start": "91200",
    "end": "93680"
  },
  {
    "text": "Senipan for playing this video last",
    "start": "93680",
    "end": "96720"
  },
  {
    "text": "summer I participated in Google Summer",
    "start": "96720",
    "end": "99200"
  },
  {
    "text": "of Code where I was fortunate to",
    "start": "99200",
    "end": "101759"
  },
  {
    "text": "contribute to Coupeflow with the help of",
    "start": "101759",
    "end": "104560"
  },
  {
    "text": "my mentors especially Angie I developed",
    "start": "104560",
    "end": "107520"
  },
  {
    "text": "an API for optimizing hyperparameters of",
    "start": "107520",
    "end": "110960"
  },
  {
    "text": "large language models in Tatik today I'm",
    "start": "110960",
    "end": "114479"
  },
  {
    "text": "excited to share my work with all of you",
    "start": "114479",
    "end": "116880"
  },
  {
    "text": "and I look forward to your feedback and",
    "start": "116880",
    "end": "119799"
  },
  {
    "text": "suggestions before we dive in since the",
    "start": "119799",
    "end": "122479"
  },
  {
    "text": "demo will take about 10 minutes to",
    "start": "122479",
    "end": "124799"
  },
  {
    "text": "complete so let me start it quickly so",
    "start": "124799",
    "end": "127840"
  },
  {
    "text": "we won't have to wait okay let's start",
    "start": "127840",
    "end": "130560"
  },
  {
    "text": "with the background of this project",
    "start": "130560",
    "end": "133920"
  },
  {
    "text": "captive already have a tune API in its",
    "start": "133920",
    "end": "136800"
  },
  {
    "text": "Python",
    "start": "136800",
    "end": "137959"
  },
  {
    "text": "SDK uh and it can optimize",
    "start": "137959",
    "end": "140920"
  },
  {
    "text": "hyperparameters in userdefined objective",
    "start": "140920",
    "end": "143760"
  },
  {
    "text": "function here is a used example of the",
    "start": "143760",
    "end": "147120"
  },
  {
    "text": "previous tune API but with the growing",
    "start": "147120",
    "end": "150640"
  },
  {
    "text": "importance of large language models we",
    "start": "150640",
    "end": "153200"
  },
  {
    "text": "saw the need to expand this tune API to",
    "start": "153200",
    "end": "156640"
  },
  {
    "text": "also support hyperparameter optimization",
    "start": "156640",
    "end": "159680"
  },
  {
    "text": "in large language models this would",
    "start": "159680",
    "end": "162319"
  },
  {
    "text": "simplify the process by abstracting away",
    "start": "162319",
    "end": "165360"
  },
  {
    "text": "the complexity of Kubernetes",
    "start": "165360",
    "end": "168040"
  },
  {
    "text": "infrastructure and allows data",
    "start": "168040",
    "end": "170400"
  },
  {
    "text": "scientists to focus more on improving",
    "start": "170400",
    "end": "172879"
  },
  {
    "text": "their models rather than system",
    "start": "172879",
    "end": "175280"
  },
  {
    "text": "configuration",
    "start": "175280",
    "end": "178280"
  },
  {
    "text": "we had a good starting point thanks to",
    "start": "178319",
    "end": "180800"
  },
  {
    "text": "the existing train API in the trainer",
    "start": "180800",
    "end": "183920"
  },
  {
    "text": "SDK which simplifies the sorry which",
    "start": "183920",
    "end": "187200"
  },
  {
    "text": "simplify the finetuning of large",
    "start": "187200",
    "end": "189519"
  },
  {
    "text": "language models using distributed pytor",
    "start": "189519",
    "end": "192239"
  },
  {
    "text": "job workers as you can see in this",
    "start": "192239",
    "end": "195480"
  },
  {
    "text": "figure the users need to input",
    "start": "195480",
    "end": "198959"
  },
  {
    "text": "parameters like model data set and the",
    "start": "198959",
    "end": "202000"
  },
  {
    "text": "trainer parameters then the train API",
    "start": "202000",
    "end": "204640"
  },
  {
    "text": "use pytor job for distributed training",
    "start": "204640",
    "end": "208000"
  },
  {
    "text": "and the storage initializer downloads",
    "start": "208000",
    "end": "210799"
  },
  {
    "text": "models and data sets from external",
    "start": "210799",
    "end": "213360"
  },
  {
    "text": "platforms like hacking phase and s3 and",
    "start": "213360",
    "end": "217200"
  },
  {
    "text": "shared them across all the workers to",
    "start": "217200",
    "end": "219840"
  },
  {
    "text": "avoid redundant downloads so instead of",
    "start": "219840",
    "end": "223200"
  },
  {
    "text": "starting from scratch we reused the key",
    "start": "223200",
    "end": "225599"
  },
  {
    "text": "components such as storage initializer",
    "start": "225599",
    "end": "228799"
  },
  {
    "text": "and the pipel from train API to enhance",
    "start": "228799",
    "end": "232720"
  },
  {
    "text": "the tune",
    "start": "232720",
    "end": "234599"
  },
  {
    "text": "API here is the design of the new tune",
    "start": "234599",
    "end": "238080"
  },
  {
    "text": "API first user need to provide inputs",
    "start": "238080",
    "end": "242000"
  },
  {
    "text": "like model data set trainer parameters",
    "start": "242000",
    "end": "245840"
  },
  {
    "text": "objective metric and goal search",
    "start": "245840",
    "end": "248519"
  },
  {
    "text": "algorithm resources per trial and other",
    "start": "248519",
    "end": "251599"
  },
  {
    "text": "settings then the API will create an",
    "start": "251599",
    "end": "255000"
  },
  {
    "text": "experiment which contains multiple",
    "start": "255000",
    "end": "257519"
  },
  {
    "text": "trials each corresponding to a ptor job",
    "start": "257519",
    "end": "261759"
  },
  {
    "text": "this tri runs with different",
    "start": "261759",
    "end": "264360"
  },
  {
    "text": "hyperparameter values generated by the",
    "start": "264360",
    "end": "267040"
  },
  {
    "text": "suggestion service and uh after",
    "start": "267040",
    "end": "270759"
  },
  {
    "text": "execution the results are collected and",
    "start": "270759",
    "end": "274400"
  },
  {
    "text": "the best hyperparameter set is",
    "start": "274400",
    "end": "277800"
  },
  {
    "text": "identified and with the integration of",
    "start": "277800",
    "end": "280400"
  },
  {
    "text": "storage initializer and the pytor job it",
    "start": "280400",
    "end": "283840"
  },
  {
    "text": "allows users to download models and data",
    "start": "283840",
    "end": "286720"
  },
  {
    "text": "sets from external platforms and also",
    "start": "286720",
    "end": "289600"
  },
  {
    "text": "perform distributed training across",
    "start": "289600",
    "end": "292000"
  },
  {
    "text": "multiple nodes by leveraging these",
    "start": "292000",
    "end": "294800"
  },
  {
    "text": "existing components we can scale and",
    "start": "294800",
    "end": "298000"
  },
  {
    "text": "speed up the training process of large",
    "start": "298000",
    "end": "300639"
  },
  {
    "text": "language",
    "start": "300639",
    "end": "302680"
  },
  {
    "text": "models so now users have two options one",
    "start": "302680",
    "end": "306880"
  },
  {
    "text": "option is to optimize hyperparameters in",
    "start": "306880",
    "end": "310080"
  },
  {
    "text": "their defined objective function and",
    "start": "310080",
    "end": "312960"
  },
  {
    "text": "another option is to optimize",
    "start": "312960",
    "end": "315400"
  },
  {
    "text": "hyperparameters of large language models",
    "start": "315400",
    "end": "318720"
  },
  {
    "text": "with models and data sets from external",
    "start": "318720",
    "end": "321680"
  },
  {
    "text": "platforms",
    "start": "321680",
    "end": "324240"
  },
  {
    "text": "we aim to make the experience consistent",
    "start": "324240",
    "end": "327520"
  },
  {
    "text": "between using train API for ALM fine",
    "start": "327520",
    "end": "331360"
  },
  {
    "text": "tooling and the tune API for",
    "start": "331360",
    "end": "333720"
  },
  {
    "text": "hyperparameter optimization here are two",
    "start": "333720",
    "end": "337080"
  },
  {
    "text": "examples one using the train API for",
    "start": "337080",
    "end": "340479"
  },
  {
    "text": "bird finetuning and the other using the",
    "start": "340479",
    "end": "343199"
  },
  {
    "text": "tune API for bird hyperparameter",
    "start": "343199",
    "end": "346120"
  },
  {
    "text": "optimization we can see that the input",
    "start": "346120",
    "end": "349199"
  },
  {
    "text": "parameters are nearly identical model",
    "start": "349199",
    "end": "352320"
  },
  {
    "text": "and the data set parameters remain the",
    "start": "352320",
    "end": "354800"
  },
  {
    "text": "same and the trainer parameters in the",
    "start": "354800",
    "end": "359360"
  },
  {
    "text": "tune API uh includes the search space",
    "start": "359360",
    "end": "363520"
  },
  {
    "text": "for hyperparameters that we want to",
    "start": "363520",
    "end": "366280"
  },
  {
    "text": "optimize and also we need to include",
    "start": "366280",
    "end": "369120"
  },
  {
    "text": "some specific optimization settings in",
    "start": "369120",
    "end": "372080"
  },
  {
    "text": "the tune API such as the objective",
    "start": "372080",
    "end": "375360"
  },
  {
    "text": "matrix name and the objective type and",
    "start": "375360",
    "end": "378960"
  },
  {
    "text": "another small difference is the resource",
    "start": "378960",
    "end": "381560"
  },
  {
    "text": "configuration in the tune API we use",
    "start": "381560",
    "end": "384400"
  },
  {
    "text": "resources per trial to define resources",
    "start": "384400",
    "end": "387520"
  },
  {
    "text": "and we created a new class trainer",
    "start": "387520",
    "end": "390160"
  },
  {
    "text": "resources for distributed training which",
    "start": "390160",
    "end": "393199"
  },
  {
    "text": "also contain long workers long process",
    "start": "393199",
    "end": "396479"
  },
  {
    "text": "per worker and resource per worker which",
    "start": "396479",
    "end": "400400"
  },
  {
    "text": "are the same parameters we used to",
    "start": "400400",
    "end": "403280"
  },
  {
    "text": "define resources in the train API but we",
    "start": "403280",
    "end": "406319"
  },
  {
    "text": "defined a new class for for it",
    "start": "406319",
    "end": "410240"
  },
  {
    "text": "next let's look at the demo before using",
    "start": "410240",
    "end": "413199"
  },
  {
    "text": "this API we need to set up the cluster",
    "start": "413199",
    "end": "416319"
  },
  {
    "text": "install the trainer and the cat control",
    "start": "416319",
    "end": "419280"
  },
  {
    "text": "planes and install CIP SDK with the",
    "start": "419280",
    "end": "422560"
  },
  {
    "text": "required extras for the detailed",
    "start": "422560",
    "end": "425280"
  },
  {
    "text": "instruction you can refer to this user",
    "start": "425280",
    "end": "427680"
  },
  {
    "text": "guide since I've already completed these",
    "start": "427680",
    "end": "430639"
  },
  {
    "text": "steps so we can jump right into the",
    "start": "430639",
    "end": "434840"
  },
  {
    "text": "demo here is the demo code first we",
    "start": "434840",
    "end": "438479"
  },
  {
    "text": "import the necessary modules then we use",
    "start": "438479",
    "end": "442400"
  },
  {
    "text": "a bird model from the hugging face and",
    "start": "442400",
    "end": "445599"
  },
  {
    "text": "the Yelp data set for the experiment to",
    "start": "445599",
    "end": "449440"
  },
  {
    "text": "speed up i only use eight example eight",
    "start": "449440",
    "end": "452240"
  },
  {
    "text": "samples from the Yelp data set then we",
    "start": "452240",
    "end": "455520"
  },
  {
    "text": "define the trainer parameters which",
    "start": "455520",
    "end": "458880"
  },
  {
    "text": "specify that we want to optimize the",
    "start": "458880",
    "end": "461759"
  },
  {
    "text": "nering rate and are in the laurel config",
    "start": "461759",
    "end": "465759"
  },
  {
    "text": "and we want to minimize the train loss",
    "start": "465759",
    "end": "468960"
  },
  {
    "text": "and use random algorithm and we set the",
    "start": "468960",
    "end": "472960"
  },
  {
    "text": "max trial count and parallel trial count",
    "start": "472960",
    "end": "475759"
  },
  {
    "text": "to one since I'm running this experiment",
    "start": "475759",
    "end": "478960"
  },
  {
    "text": "on my local machine with only one uh",
    "start": "478960",
    "end": "481440"
  },
  {
    "text": "with only a single node so here I set",
    "start": "481440",
    "end": "484400"
  },
  {
    "text": "the num workers and nonprocess per",
    "start": "484400",
    "end": "486800"
  },
  {
    "text": "worker to one and use one CPU and 10 GB",
    "start": "486800",
    "end": "491599"
  },
  {
    "text": "of memory for the",
    "start": "491599",
    "end": "494440"
  },
  {
    "text": "experiment and I guess we have to wait a",
    "start": "494440",
    "end": "497599"
  },
  {
    "text": "few minutes for the experiment to",
    "start": "497599",
    "end": "499919"
  },
  {
    "text": "complete",
    "start": "499919",
    "end": "502919"
  },
  {
    "text": "okay the experiment is succeeded and we",
    "start": "506000",
    "end": "509680"
  },
  {
    "text": "can see the values of the matrix which",
    "start": "509680",
    "end": "512479"
  },
  {
    "text": "is train loss here and we can also say",
    "start": "512479",
    "end": "515919"
  },
  {
    "text": "the best hyperparameter values of",
    "start": "515919",
    "end": "519039"
  },
  {
    "text": "learning rate and R we can also check",
    "start": "519039",
    "end": "522080"
  },
  {
    "text": "the results in captive UI so here is our",
    "start": "522080",
    "end": "526600"
  },
  {
    "text": "experiment we can enter it and we can",
    "start": "526600",
    "end": "529760"
  },
  {
    "text": "see the results of this experiment and",
    "start": "529760",
    "end": "533519"
  },
  {
    "text": "also the trials in the experiment we can",
    "start": "533519",
    "end": "537440"
  },
  {
    "text": "since there is only one trial in this",
    "start": "537440",
    "end": "539519"
  },
  {
    "text": "experiment we can enter it and here it",
    "start": "539519",
    "end": "543760"
  },
  {
    "text": "show that the trial has succeeded and",
    "start": "543760",
    "end": "546080"
  },
  {
    "text": "the corresponding pytor job is also",
    "start": "546080",
    "end": "548720"
  },
  {
    "text": "successfully completed we can also check",
    "start": "548720",
    "end": "551600"
  },
  {
    "text": "the logs of the trial and the yama file",
    "start": "551600",
    "end": "556640"
  },
  {
    "text": "here",
    "start": "556640",
    "end": "558080"
  },
  {
    "text": "so this is the demo of the of this",
    "start": "558080",
    "end": "562600"
  },
  {
    "text": "API here is a quick summary of this",
    "start": "562600",
    "end": "566160"
  },
  {
    "text": "project so I divide uh divided my",
    "start": "566160",
    "end": "569440"
  },
  {
    "text": "project into three stages preparation",
    "start": "569440",
    "end": "572720"
  },
  {
    "text": "development and the wrap-up and I have",
    "start": "572720",
    "end": "575800"
  },
  {
    "text": "created five PRs for this API including",
    "start": "575800",
    "end": "579920"
  },
  {
    "text": "the proposal the API implementation and",
    "start": "579920",
    "end": "583760"
  },
  {
    "text": "adding unit uh test and end to end test",
    "start": "583760",
    "end": "586720"
  },
  {
    "text": "for this API and I also contributed to",
    "start": "586720",
    "end": "590880"
  },
  {
    "text": "bug fixes and new features in for the",
    "start": "590880",
    "end": "594160"
  },
  {
    "text": "cat and the trainer",
    "start": "594160",
    "end": "597440"
  },
  {
    "text": "uh throughout the journey I learned a",
    "start": "597440",
    "end": "599440"
  },
  {
    "text": "lot uh with the help of my mentors as",
    "start": "599440",
    "end": "602560"
  },
  {
    "text": "well as the supportive community and it",
    "start": "602560",
    "end": "606160"
  },
  {
    "text": "has strengthened my passion for",
    "start": "606160",
    "end": "608080"
  },
  {
    "text": "open-source",
    "start": "608080",
    "end": "610880"
  },
  {
    "text": "contribution thanks for your time and I",
    "start": "611000",
    "end": "614079"
  },
  {
    "text": "will hand it over back to Sanipan",
    "start": "614079",
    "end": "618920"
  },
  {
    "text": "so up next we'll be discussing uh how we",
    "start": "629240",
    "end": "633200"
  },
  {
    "text": "can perform JAX distributed training on",
    "start": "633200",
    "end": "635279"
  },
  {
    "text": "Kubernetes using the keepflow training",
    "start": "635279",
    "end": "637560"
  },
  {
    "text": "operator uh so first let's have a quick",
    "start": "637560",
    "end": "640880"
  },
  {
    "text": "look at at what is Jax so Jax is a high",
    "start": "640880",
    "end": "644560"
  },
  {
    "text": "performance numerical computing",
    "start": "644560",
    "end": "646240"
  },
  {
    "text": "framework which was initially developed",
    "start": "646240",
    "end": "648720"
  },
  {
    "text": "by Google research some of its key",
    "start": "648720",
    "end": "651360"
  },
  {
    "text": "features include numpy like API with",
    "start": "651360",
    "end": "654000"
  },
  {
    "text": "automatic",
    "start": "654000",
    "end": "655160"
  },
  {
    "text": "differentiation just in time compilation",
    "start": "655160",
    "end": "657680"
  },
  {
    "text": "with XLA inbuilt support for GPU and TPU",
    "start": "657680",
    "end": "661240"
  },
  {
    "text": "acceleration and SPDM programming for",
    "start": "661240",
    "end": "664720"
  },
  {
    "text": "distributed",
    "start": "664720",
    "end": "666440"
  },
  {
    "text": "computing so Jax has a huge ecosystem of",
    "start": "666440",
    "end": "669279"
  },
  {
    "text": "libraries like Flax Optax Haiku orax",
    "start": "669279",
    "end": "672800"
  },
  {
    "text": "which maintains Jack's functional",
    "start": "672800",
    "end": "675279"
  },
  {
    "text": "programming paradigm so all of these",
    "start": "675279",
    "end": "677519"
  },
  {
    "text": "should work seamlessly with the Jax",
    "start": "677519",
    "end": "680279"
  },
  {
    "text": "job so when we should use Jax for",
    "start": "680279",
    "end": "682880"
  },
  {
    "text": "distributed training we we should use it",
    "start": "682880",
    "end": "685519"
  },
  {
    "text": "for high performance computing because",
    "start": "685519",
    "end": "687839"
  },
  {
    "text": "it's very much efficient on CPUs GPUs",
    "start": "687839",
    "end": "690720"
  },
  {
    "text": "and TPUs we can use it for research",
    "start": "690720",
    "end": "693200"
  },
  {
    "text": "applications for physics simulations",
    "start": "693200",
    "end": "696560"
  },
  {
    "text": "scientific computing we can use it for",
    "start": "696560",
    "end": "699279"
  },
  {
    "text": "reinforcement learning at scale and",
    "start": "699279",
    "end": "701519"
  },
  {
    "text": "large scale model training on GPUs and",
    "start": "701519",
    "end": "704320"
  },
  {
    "text": "TPU clusters",
    "start": "704320",
    "end": "707320"
  },
  {
    "text": "so if we try to run Jax natively on",
    "start": "707320",
    "end": "710959"
  },
  {
    "text": "Kubernetes we have some challenges like",
    "start": "710959",
    "end": "714160"
  },
  {
    "text": "uh distributed coordination and setting",
    "start": "714160",
    "end": "716320"
  },
  {
    "text": "up the port configuration for",
    "start": "716320",
    "end": "717920"
  },
  {
    "text": "distributed training setting up the",
    "start": "717920",
    "end": "720000"
  },
  {
    "text": "environment variables that are required",
    "start": "720000",
    "end": "722160"
  },
  {
    "text": "for jacks and worker discovery and life",
    "start": "722160",
    "end": "725360"
  },
  {
    "text": "cycle management and resource allocation",
    "start": "725360",
    "end": "728000"
  },
  {
    "text": "and here's where the training operator",
    "start": "728000",
    "end": "731440"
  },
  {
    "text": "of Kilo comes in so with the use of Jax",
    "start": "731440",
    "end": "735200"
  },
  {
    "text": "job we have a simplified deployment",
    "start": "735200",
    "end": "736880"
  },
  {
    "text": "model and we have automatic coordination",
    "start": "736880",
    "end": "739360"
  },
  {
    "text": "between workers and service management",
    "start": "739360",
    "end": "741920"
  },
  {
    "text": "and we also have support for failure",
    "start": "741920",
    "end": "743680"
  },
  {
    "text": "handling status tracking and consistent",
    "start": "743680",
    "end": "746560"
  },
  {
    "text": "API along with other uh ML jobs like",
    "start": "746560",
    "end": "751600"
  },
  {
    "text": "PyTorch job XG boost job tensorflow job",
    "start": "751600",
    "end": "755519"
  },
  {
    "text": "of the training",
    "start": "755519",
    "end": "758120"
  },
  {
    "text": "operator so if we have a look at the Jax",
    "start": "758120",
    "end": "761200"
  },
  {
    "text": "job CRD API we can see that we can",
    "start": "761200",
    "end": "764160"
  },
  {
    "text": "configure the resource management like",
    "start": "764160",
    "end": "766560"
  },
  {
    "text": "run policy clean port policy and suspend",
    "start": "766560",
    "end": "769360"
  },
  {
    "text": "and some worker configuration like we",
    "start": "769360",
    "end": "772000"
  },
  {
    "text": "can set up the number of worker",
    "start": "772000",
    "end": "774120"
  },
  {
    "text": "replicas and the coordinator",
    "start": "774120",
    "end": "778160"
  },
  {
    "text": "port so let's have a look at the overall",
    "start": "779959",
    "end": "783040"
  },
  {
    "text": "Jack job architecture so the training",
    "start": "783040",
    "end": "785600"
  },
  {
    "text": "operator manages the Jack job life cycle",
    "start": "785600",
    "end": "788480"
  },
  {
    "text": "it creates and monitors the worker ports",
    "start": "788480",
    "end": "790880"
  },
  {
    "text": "and automatically configures the",
    "start": "790880",
    "end": "792800"
  },
  {
    "text": "environment variables required for",
    "start": "792800",
    "end": "794320"
  },
  {
    "text": "distributed training like Jax",
    "start": "794320",
    "end": "796240"
  },
  {
    "text": "coordinator address number of processes",
    "start": "796240",
    "end": "798959"
  },
  {
    "text": "process ID and it also handles the",
    "start": "798959",
    "end": "800800"
  },
  {
    "text": "portuling and life cycle",
    "start": "800800",
    "end": "804120"
  },
  {
    "text": "management so Jax uses something called",
    "start": "804120",
    "end": "806959"
  },
  {
    "text": "the single program multiple data",
    "start": "806959",
    "end": "808560"
  },
  {
    "text": "programming model so the same code runs",
    "start": "808560",
    "end": "811360"
  },
  {
    "text": "across all devices operating on",
    "start": "811360",
    "end": "813200"
  },
  {
    "text": "different data so here in this code",
    "start": "813200",
    "end": "816000"
  },
  {
    "text": "snippet we can see that the there is a",
    "start": "816000",
    "end": "819519"
  },
  {
    "text": "function called pmap which transforms",
    "start": "819519",
    "end": "821839"
  },
  {
    "text": "functions to run in parallel across",
    "start": "821839",
    "end": "823600"
  },
  {
    "text": "devices and it's great for data",
    "start": "823600",
    "end": "825760"
  },
  {
    "text": "parallelism in training neural",
    "start": "825760",
    "end": "829000"
  },
  {
    "text": "networks so let's have a quick look at",
    "start": "829000",
    "end": "832399"
  },
  {
    "text": "how you can run jax",
    "start": "832399",
    "end": "834200"
  },
  {
    "text": "job so the first process will be to have",
    "start": "834200",
    "end": "837360"
  },
  {
    "text": "a kubernetes cluster ready here we are",
    "start": "837360",
    "end": "839360"
  },
  {
    "text": "using kind for that",
    "start": "839360",
    "end": "841920"
  },
  {
    "text": "the next step will be to install the",
    "start": "841920",
    "end": "844000"
  },
  {
    "text": "training operator control plane and",
    "start": "844000",
    "end": "846720"
  },
  {
    "text": "after here we are using the version",
    "start": "846720",
    "end": "849240"
  },
  {
    "text": "1.9.0 of the Qflow training operator",
    "start": "849240",
    "end": "852720"
  },
  {
    "text": "which has the Jax job",
    "start": "852720",
    "end": "855880"
  },
  {
    "text": "CRD here and we can check that the",
    "start": "855880",
    "end": "860480"
  },
  {
    "text": "training operator port is running and we",
    "start": "860480",
    "end": "862320"
  },
  {
    "text": "have the Jax job CRD installed",
    "start": "862320",
    "end": "866600"
  },
  {
    "text": "so here's the example Jack job we'll be",
    "start": "867920",
    "end": "870639"
  },
  {
    "text": "using for this training so we have kind",
    "start": "870639",
    "end": "873120"
  },
  {
    "text": "jax job defined with two worker replicas",
    "start": "873120",
    "end": "875880"
  },
  {
    "text": "and we are using the following image for",
    "start": "875880",
    "end": "878959"
  },
  {
    "text": "the distributed",
    "start": "878959",
    "end": "880920"
  },
  {
    "text": "training if we have a look at the",
    "start": "880920",
    "end": "882959"
  },
  {
    "text": "container used for running this training",
    "start": "882959",
    "end": "884880"
  },
  {
    "text": "job we can see that we have Python",
    "start": "884880",
    "end": "887120"
  },
  {
    "text": "installed along with Jax and all these",
    "start": "887120",
    "end": "889040"
  },
  {
    "text": "required dependencies and we have",
    "start": "889040",
    "end": "892240"
  },
  {
    "text": "installed glue which is a communication",
    "start": "892240",
    "end": "894480"
  },
  {
    "text": "library for a multi-machine model",
    "start": "894480",
    "end": "898120"
  },
  {
    "text": "training and we are just applying this",
    "start": "898120",
    "end": "900720"
  },
  {
    "text": "SPD classifier from Jax to demonstrate",
    "start": "900720",
    "end": "904959"
  },
  {
    "text": "the distributed",
    "start": "904959",
    "end": "907920"
  },
  {
    "text": "training so here we are deploying the",
    "start": "909000",
    "end": "911519"
  },
  {
    "text": "Jax job and we can see that Jax job is",
    "start": "911519",
    "end": "914000"
  },
  {
    "text": "created and we see that we have two",
    "start": "914000",
    "end": "916560"
  },
  {
    "text": "worker replicas as defined in the Jax",
    "start": "916560",
    "end": "918639"
  },
  {
    "text": "job",
    "start": "918639",
    "end": "919399"
  },
  {
    "text": "API uh if we have a quick look at the",
    "start": "919399",
    "end": "923360"
  },
  {
    "text": "Python code snippet used for running",
    "start": "923360",
    "end": "925199"
  },
  {
    "text": "this Jack job we can see that uh here we",
    "start": "925199",
    "end": "929120"
  },
  {
    "text": "are",
    "start": "929120",
    "end": "930680"
  },
  {
    "text": "uh setting up uh the model training so",
    "start": "930680",
    "end": "935199"
  },
  {
    "text": "that uh we can use the",
    "start": "935199",
    "end": "938920"
  },
  {
    "text": "uh course of CPU as multiple",
    "start": "938920",
    "end": "943240"
  },
  {
    "text": "devices for the Jack's job and here we",
    "start": "943240",
    "end": "947120"
  },
  {
    "text": "are setting up glue for the collective",
    "start": "947120",
    "end": "949120"
  },
  {
    "text": "CPU",
    "start": "949120",
    "end": "950040"
  },
  {
    "text": "operations and we get the process ID",
    "start": "950040",
    "end": "953279"
  },
  {
    "text": "number of process and coordinator",
    "start": "953279",
    "end": "955360"
  },
  {
    "text": "address from the ports automatically",
    "start": "955360",
    "end": "957680"
  },
  {
    "text": "using the cubeflow training operator and",
    "start": "957680",
    "end": "959839"
  },
  {
    "text": "after that we initialize the JAX",
    "start": "959839",
    "end": "961839"
  },
  {
    "text": "distributed system by calling the",
    "start": "961839",
    "end": "965160"
  },
  {
    "text": "JAX.istributed.initialize API",
    "start": "965160",
    "end": "969160"
  },
  {
    "text": "so if we have a look at one of the",
    "start": "972000",
    "end": "974320"
  },
  {
    "text": "worker replicas for the logs of the",
    "start": "974320",
    "end": "976800"
  },
  {
    "text": "training we can see that the data set is",
    "start": "976800",
    "end": "979759"
  },
  {
    "text": "downloaded and we have a total of two",
    "start": "979759",
    "end": "983360"
  },
  {
    "text": "jacks processes because we specified two",
    "start": "983360",
    "end": "985680"
  },
  {
    "text": "worker replicas and we have two eight",
    "start": "985680",
    "end": "988720"
  },
  {
    "text": "local JAX devices because my uh CPU has",
    "start": "988720",
    "end": "992160"
  },
  {
    "text": "eight cores and we have a total of 16 uh",
    "start": "992160",
    "end": "997839"
  },
  {
    "text": "J",
    "start": "997839",
    "end": "998759"
  },
  {
    "text": "devices among which the distributed",
    "start": "998759",
    "end": "1001040"
  },
  {
    "text": "training takes place because uh uh we",
    "start": "1001040",
    "end": "1005519"
  },
  {
    "text": "updated the configuration to use the CPU",
    "start": "1005519",
    "end": "1007759"
  },
  {
    "text": "course as multiple",
    "start": "1007759",
    "end": "1010800"
  },
  {
    "text": "machines we can also monitor the JX job",
    "start": "1013240",
    "end": "1017320"
  },
  {
    "text": "and to see the its current status",
    "start": "1017320",
    "end": "1021000"
  },
  {
    "text": "and here's the example output uh when",
    "start": "1021000",
    "end": "1024079"
  },
  {
    "text": "the Jack job is successfully completed",
    "start": "1024079",
    "end": "1026079"
  },
  {
    "text": "so here you can see the jack job is",
    "start": "1026079",
    "end": "1028319"
  },
  {
    "text": "created and then it's it in running",
    "start": "1028319",
    "end": "1030480"
  },
  {
    "text": "state and after that it's successfully",
    "start": "1030480",
    "end": "1035199"
  },
  {
    "text": "completed uh so if we look at some of",
    "start": "1035400",
    "end": "1038880"
  },
  {
    "text": "our key take a from this demo we can see",
    "start": "1038880",
    "end": "1041678"
  },
  {
    "text": "that you can use a sim simple EML",
    "start": "1041679",
    "end": "1043918"
  },
  {
    "text": "configuration for setting up the",
    "start": "1043919",
    "end": "1045360"
  },
  {
    "text": "distributed training and it",
    "start": "1045360",
    "end": "1047360"
  },
  {
    "text": "automatically sets up the worker",
    "start": "1047360",
    "end": "1049559"
  },
  {
    "text": "coordination and we also get a native",
    "start": "1049559",
    "end": "1052160"
  },
  {
    "text": "coordinative support and we can achieve",
    "start": "1052160",
    "end": "1054960"
  },
  {
    "text": "linear scaling with by just adding",
    "start": "1054960",
    "end": "1057520"
  },
  {
    "text": "additional",
    "start": "1057520",
    "end": "1060160"
  },
  {
    "text": "workers so for future developments we",
    "start": "1061160",
    "end": "1063840"
  },
  {
    "text": "are looking forward to adding support",
    "start": "1063840",
    "end": "1065360"
  },
  {
    "text": "for Jax as a training runtime in the",
    "start": "1065360",
    "end": "1067120"
  },
  {
    "text": "cube trainer you can go and check out",
    "start": "1067120",
    "end": "1069919"
  },
  {
    "text": "the following resources if you would",
    "start": "1069919",
    "end": "1071360"
  },
  {
    "text": "like to learn more about Jack's",
    "start": "1071360",
    "end": "1074440"
  },
  {
    "text": "job and if you have any questions you",
    "start": "1074440",
    "end": "1077200"
  },
  {
    "text": "can join the Qflow trainer channel on",
    "start": "1077200",
    "end": "1080240"
  },
  {
    "text": "CNCF Slack and you are also welcome to",
    "start": "1080240",
    "end": "1083440"
  },
  {
    "text": "participate in the AutoML and training",
    "start": "1083440",
    "end": "1085440"
  },
  {
    "text": "group meetings",
    "start": "1085440",
    "end": "1087280"
  },
  {
    "text": "and you can also uh participate in in",
    "start": "1087280",
    "end": "1091039"
  },
  {
    "text": "the Google summer of code program which",
    "start": "1091039",
    "end": "1092799"
  },
  {
    "text": "is a mentorship program and we have the",
    "start": "1092799",
    "end": "1095280"
  },
  {
    "text": "following projects open in cubeflow and",
    "start": "1095280",
    "end": "1097919"
  },
  {
    "text": "you will have the opportunity to work",
    "start": "1097919",
    "end": "1099960"
  },
  {
    "text": "alongside other cubeflow contributors",
    "start": "1099960",
    "end": "1102640"
  },
  {
    "text": "and work under the mentorship of the",
    "start": "1102640",
    "end": "1104880"
  },
  {
    "text": "amazing cubeflow",
    "start": "1104880",
    "end": "1107000"
  },
  {
    "text": "maintainers",
    "start": "1107000",
    "end": "1109000"
  },
  {
    "text": "uh so thank you so much uh for this",
    "start": "1109000",
    "end": "1112080"
  },
  {
    "text": "opportunity if you have any questions",
    "start": "1112080",
    "end": "1114320"
  },
  {
    "text": "you can reach out and you can scan this",
    "start": "1114320",
    "end": "1116880"
  },
  {
    "text": "QR code to share your feedback and have",
    "start": "1116880",
    "end": "1120160"
  },
  {
    "text": "a look at the resources and links that",
    "start": "1120160",
    "end": "1122320"
  },
  {
    "text": "were presented in this slide so thank",
    "start": "1122320",
    "end": "1124480"
  },
  {
    "text": "you",
    "start": "1124480",
    "end": "1127480"
  },
  {
    "text": "thank you for this great presentation we",
    "start": "1130480",
    "end": "1131919"
  },
  {
    "text": "have time for questions anyone have any",
    "start": "1131919",
    "end": "1134320"
  },
  {
    "text": "questions",
    "start": "1134320",
    "end": "1137320"
  },
  {
    "text": "all right I think it's a great",
    "start": "1141919",
    "end": "1142960"
  },
  {
    "text": "presentation just to remind QFlow is the",
    "start": "1142960",
    "end": "1145440"
  },
  {
    "text": "member of will participate in Google SR",
    "start": "1145440",
    "end": "1147679"
  },
  {
    "text": "of code",
    "start": "1147679",
    "end": "1148600"
  },
  {
    "text": "2025 right 2025 so it's a great",
    "start": "1148600",
    "end": "1151760"
  },
  {
    "text": "opportunity as you can see to be",
    "start": "1151760",
    "end": "1153200"
  },
  {
    "text": "involved so this is two amazing uh PC",
    "start": "1153200",
    "end": "1156799"
  },
  {
    "text": "that you saw that's actually students",
    "start": "1156799",
    "end": "1158760"
  },
  {
    "text": "contributed and we see more and more",
    "start": "1158760",
    "end": "1161280"
  },
  {
    "text": "kind of engagement from the community uh",
    "start": "1161280",
    "end": "1163919"
  },
  {
    "text": "so please let let know like all of the",
    "start": "1163919",
    "end": "1166240"
  },
  {
    "text": "students you know like that Qflow is",
    "start": "1166240",
    "end": "1167600"
  },
  {
    "text": "participating and if you want to get",
    "start": "1167600",
    "end": "1168640"
  },
  {
    "text": "involved uh feel free to check out the",
    "start": "1168640",
    "end": "1170240"
  },
  {
    "text": "website thanks for this great",
    "start": "1170240",
    "end": "1171760"
  },
  {
    "text": "presentation",
    "start": "1171760",
    "end": "1174230"
  },
  {
    "text": "[Applause]",
    "start": "1174230",
    "end": "1180710"
  }
]
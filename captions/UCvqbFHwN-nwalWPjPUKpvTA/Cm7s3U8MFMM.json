[
  {
    "text": "good morning just give it a couple more minutes or a",
    "start": "170000",
    "end": "175519"
  },
  {
    "text": "few more minutes some more people to join",
    "start": "175519",
    "end": "185840"
  },
  {
    "text": "okay pasted the link to the name so to place that yourself as an attendee",
    "start": "235840",
    "end": "241840"
  },
  {
    "text": "all right so it's 802 almost 803 so",
    "start": "277919",
    "end": "283280"
  },
  {
    "text": "thank you everyone for joining so um",
    "start": "283280",
    "end": "288560"
  },
  {
    "text": "today we have uh seldom core and the project and clyde is here and thank you",
    "start": "289520",
    "end": "296080"
  },
  {
    "text": "for uh deciding to uh [Music] show us the the project and what it's",
    "start": "296080",
    "end": "302400"
  },
  {
    "text": "all about hey enough excited to learn about it um i think this is probably the first uh",
    "start": "302400",
    "end": "311120"
  },
  {
    "text": "ai machine learning type of project that has presented presented instagram time so we're pretty excited",
    "start": "311120",
    "end": "317039"
  },
  {
    "text": "about it um yeah so um go ahead and take it away",
    "start": "317039",
    "end": "326400"
  },
  {
    "text": "all right cool yeah great i'll uh share my screen if i can let's see cool",
    "start": "326400",
    "end": "332639"
  },
  {
    "text": "let me see if i can move this cool can you see that yeah all right cool",
    "start": "332639",
    "end": "340320"
  },
  {
    "text": "so great to see you so i'm uh clive i'm cto of selden um so i'm just going to give you introduction to some of the projects",
    "start": "340320",
    "end": "346160"
  },
  {
    "text": "that we work on and yeah be good to get your feedback and see how it connects to the things that you're interested in",
    "start": "346160",
    "end": "352479"
  },
  {
    "text": "would be an interesting thing for me um so i'm just going to go through some sort of rationales of what selling's trying to do so set the sort of",
    "start": "352479",
    "end": "359039"
  },
  {
    "text": "landscape um so one of the things is uh this paper from google from 2015 uh",
    "start": "359039",
    "end": "366800"
  },
  {
    "text": "which is really setting the scene for what we were trying to do um was they're saying you know when you do ml code you know the data scientists",
    "start": "366800",
    "end": "373759"
  },
  {
    "text": "sometimes think or even the whole organization thinks it's just you just got to work your little algorithm and that's it but actually there's a",
    "start": "373759",
    "end": "380080"
  },
  {
    "text": "whole set of other things surrounding it and this was a paper by google from their own internal analysis which",
    "start": "380080",
    "end": "385840"
  },
  {
    "text": "some of you might know it's got quite a lot of uh fame afterwards um where the size of the boxes are the",
    "start": "385840",
    "end": "391759"
  },
  {
    "text": "amount of code they had to write for these other things surrounding the ml code so there's a lot of technical debt that",
    "start": "391759",
    "end": "397199"
  },
  {
    "text": "gets created in organization and we'll sell them that was sort of inspired us to start doing what we're doing is that",
    "start": "397199",
    "end": "404240"
  },
  {
    "text": "we wanted to solve those parts of the technical debt in terms of serving infrastructure analysis tools and",
    "start": "404240",
    "end": "412000"
  },
  {
    "text": "the monitoring of your machine learning et cetera has really helped our organizations in that area we've seen a trend in recent years that",
    "start": "412000",
    "end": "418560"
  },
  {
    "text": "the organizations are looking for best to breed and parts for the whole ml",
    "start": "418560",
    "end": "423680"
  },
  {
    "text": "life cycle you know from initial data um analysis and um through to the training and then the",
    "start": "423680",
    "end": "429680"
  },
  {
    "text": "serving and um so that's really the direction we see that's taking obviously also with the cloud native world and",
    "start": "429680",
    "end": "435759"
  },
  {
    "text": "tools fitting into that and we'll discuss that a little bit um so that's one of the rationales for",
    "start": "435759",
    "end": "440800"
  },
  {
    "text": "seldom to help organizations in that area for these these things with their ml codes so their data scientists can focus on that part uh the core you know",
    "start": "440800",
    "end": "448400"
  },
  {
    "text": "uh code part um so another way of looking at what we do and so the issues",
    "start": "448400",
    "end": "454160"
  },
  {
    "text": "uh that we find uh in organizations is one you have the data scientists on one side and they've got their own set of",
    "start": "454160",
    "end": "459280"
  },
  {
    "text": "tools that they know a lot about you know obviously all the training tools and tensorflow and video spark etc and then",
    "start": "459280",
    "end": "466319"
  },
  {
    "text": "you on the other side you've got the devops who've got their own tools in the cloud native world and all the tools they work out well and",
    "start": "466319",
    "end": "472240"
  },
  {
    "text": "there really is sort of quite a hard divide between the two the data scientists don't really care sometimes too much about the devops what",
    "start": "472240",
    "end": "478639"
  },
  {
    "text": "the devops are doing and the devops are scared about the machine learning and all this stuff which they don't really",
    "start": "478639",
    "end": "483680"
  },
  {
    "text": "understand it's not so simple as a normal app they're going to just deploy onto their kubernetes cluster",
    "start": "483680",
    "end": "488960"
  },
  {
    "text": "and so you really get this um issue of of of these two teams working together and",
    "start": "488960",
    "end": "494000"
  },
  {
    "text": "that's also what we're trying to help trying to put some devops into data science and data science help them move their stuff",
    "start": "494000",
    "end": "499120"
  },
  {
    "text": "out so they can get it into production to really speed up that time to get those uh machine learning",
    "start": "499120",
    "end": "504560"
  },
  {
    "text": "projects from just being a project out into production and making a difference for um companies and organizations",
    "start": "504560",
    "end": "510720"
  },
  {
    "text": "so that's that's that's another rash now this one obviously should make a lot of sense to you guys and this is you know we're saying nothing",
    "start": "510720",
    "end": "516959"
  },
  {
    "text": "new that you know a person as a data scientist they've got tool kits they want to really deploy their model scale and update it",
    "start": "516959",
    "end": "523440"
  },
  {
    "text": "you know onto a compute cluster with cpus gpus and tpus and obviously we all know about the um",
    "start": "523440",
    "end": "528640"
  },
  {
    "text": "sort of stack that's been built up over the years from the container runtimes then obviously kubernetes is coming in to orchestrate",
    "start": "528640",
    "end": "534480"
  },
  {
    "text": "uh more complex projects on top of those container runtimes and then projects such as istio for the service meshes",
    "start": "534480",
    "end": "540240"
  },
  {
    "text": "it's about you to do all the things that that allows you to do in terms of handling that sort of network management",
    "start": "540240",
    "end": "546160"
  },
  {
    "text": "and then interesting projects like k native and other ones to really build on top of that for serverless",
    "start": "546160",
    "end": "551200"
  },
  {
    "text": "and there's there's that sort of gap in between that and what the data scientists need to do and",
    "start": "551200",
    "end": "557040"
  },
  {
    "text": "so really uh the issue is if you wanted to use that stack um you've got all those things that i",
    "start": "557040",
    "end": "563040"
  },
  {
    "text": "think we all know about it but data scientists are probably less interested in so i'm not going to go through it the big list",
    "start": "563040",
    "end": "568080"
  },
  {
    "text": "doesn't think it will all be um familiar as well some sort of communities",
    "start": "568080",
    "end": "573279"
  },
  {
    "text": "i'm like aficionados uh but here but um you know it's quite a challenge for people to do that as a data scientist",
    "start": "573279",
    "end": "579760"
  },
  {
    "text": "or some companies to get all these things when they're trying to get their machine learning out of the stack so really so to sell them what we're",
    "start": "579760",
    "end": "586080"
  },
  {
    "text": "trying to do here is with our project seldom core and care serving uh just building this stack and to bridge that gap it's about data",
    "start": "586080",
    "end": "592399"
  },
  {
    "text": "scientists it's a sort of focused tool which is sort of cloud-native and allows them to get their machine",
    "start": "592399",
    "end": "597760"
  },
  {
    "text": "learning into production so that's that's another question now for us and then",
    "start": "597760",
    "end": "603120"
  },
  {
    "text": "one of the last things is also very important to us is it's the whole um so ethical side so obviously there's a",
    "start": "603120",
    "end": "608560"
  },
  {
    "text": "lot of interest in society of how ai is going to be used when it's put into production um and so that has built up a lot of",
    "start": "608560",
    "end": "615279"
  },
  {
    "text": "momentum and it's obviously key to for all the projects and companies that started to use ai and",
    "start": "615279",
    "end": "620560"
  },
  {
    "text": "apply it to their customer bases and then there's now beginning to be a lot of regulation in certain areas you know",
    "start": "620560",
    "end": "625600"
  },
  {
    "text": "so gdpr in in europe and another another regulations coming in which needs to be",
    "start": "625600",
    "end": "631120"
  },
  {
    "text": "applied and trying to build up some sort of rules for how ai can be applied but there's really still there's",
    "start": "631120",
    "end": "637120"
  },
  {
    "text": "still a space of how that is actually going to be how companies need to apply those regulations and what is the best practice when you",
    "start": "637120",
    "end": "643360"
  },
  {
    "text": "actually put your machine learning in production how do you know that it's actually um not harming your user base and you",
    "start": "643360",
    "end": "648560"
  },
  {
    "text": "know it's really doing what it says and can be audited et cetera and so there's a gap there and that's also what we're trying to fill with some of the tech",
    "start": "648560",
    "end": "655279"
  },
  {
    "text": "so this is so this space is really emerging you know from how society is reacting at the base to",
    "start": "655279",
    "end": "661120"
  },
  {
    "text": "ai as as it affects them more and then in the middle layer of companies and um",
    "start": "661120",
    "end": "666560"
  },
  {
    "text": "regulations being applied and how that's working i think that's still being worked out you know how that's going to apply and",
    "start": "666560",
    "end": "671760"
  },
  {
    "text": "then the tools at the top but it's a space that we're in and we're trying to also help out help out",
    "start": "671760",
    "end": "677120"
  },
  {
    "text": "there and then finally i just wanted to bring up one more academic side is that um",
    "start": "677120",
    "end": "682560"
  },
  {
    "text": "there's some really big conferences every year on machine learning one of the biggest is icml um and the first time this is the first",
    "start": "682560",
    "end": "687839"
  },
  {
    "text": "time they had like a um workshop icml on challenges in deploying and",
    "start": "687839",
    "end": "693040"
  },
  {
    "text": "monitoring machine learning systems so it's really being viewed also in the academic world what are the challenges",
    "start": "693040",
    "end": "699519"
  },
  {
    "text": "when you try to put machine learning into production and we actually were lucky enough to get two talks into that workshop or one on",
    "start": "699519",
    "end": "705200"
  },
  {
    "text": "serverless inferencing on kubernetes uh by myself and then there was another talk on of the work we're doing in alibi",
    "start": "705200",
    "end": "710320"
  },
  {
    "text": "for um some monitoring explainability of models in production and there's a lot of research areas that are being applied in",
    "start": "710320",
    "end": "716720"
  },
  {
    "text": "this area what are the challenges when you're actually deploying the machine learning model so just wanted to sort of highlight that as a",
    "start": "716720",
    "end": "722320"
  },
  {
    "text": "an emerging area that's coming also from academia with a lot of research being done um so okay that's so that's the",
    "start": "722320",
    "end": "728079"
  },
  {
    "text": "background so i hope you understand what we're trying to solve and sell them and what's projects that we actually um",
    "start": "728079",
    "end": "733839"
  },
  {
    "text": "work on to help to achieve some of those uh goals this is our stack of projects that we",
    "start": "733839",
    "end": "739200"
  },
  {
    "text": "work on um starting in the layer in the middle so this is all open source in the middle um so the sultan core which",
    "start": "739200",
    "end": "744959"
  },
  {
    "text": "probably the most mature project will be for five years maybe i can't remember now but it's got a lot of traction",
    "start": "744959",
    "end": "750079"
  },
  {
    "text": "that's going to into more detail that's providing like a abstraction a custom resource allow you to define",
    "start": "750079",
    "end": "756240"
  },
  {
    "text": "how you want to put your machine learning model and or whole inference graph out into production managing it updating it",
    "start": "756240",
    "end": "761920"
  },
  {
    "text": "scaling etc and then more recently with in the last year or so we've been working with a group of companies on cash serving",
    "start": "761920",
    "end": "767839"
  },
  {
    "text": "which is building very similar aims it was building on the stack of k-natives so looking at serverless",
    "start": "767839",
    "end": "773279"
  },
  {
    "text": "how can serverless help uh in the area of machine learning deployment um so that's sort of the middle layer",
    "start": "773279",
    "end": "779440"
  },
  {
    "text": "and then at the bottom there which feeds into that middle layer a suite of projects that we've been working on to focus on some of the",
    "start": "779440",
    "end": "786560"
  },
  {
    "text": "um things you need to do once you've put your model out which is obviously the core concern for i'm a company but creating a data",
    "start": "786560",
    "end": "793200"
  },
  {
    "text": "science model and putting it out there then the things that surround it so things like explanations um you know why is the",
    "start": "793200",
    "end": "799600"
  },
  {
    "text": "actual model giving the response it it's actually given and try to understand that uh for various",
    "start": "799600",
    "end": "805040"
  },
  {
    "text": "stakeholders the customers be auditors or the actual data scientists themselves who want to understand how",
    "start": "805040",
    "end": "810079"
  },
  {
    "text": "the model is behaving so i'll discuss a little bit about that and then we have another project called alibi detect uh which is uh",
    "start": "810079",
    "end": "816399"
  },
  {
    "text": "focusing on the ways you need to monitor models when you put them into production so things like drift detection outlet",
    "start": "816399",
    "end": "821680"
  },
  {
    "text": "detection um there's like adversarial detection and stuff like that and these feed this is also open source you can find them",
    "start": "821680",
    "end": "827920"
  },
  {
    "text": "i'll give links to them um on github and these feed into",
    "start": "827920",
    "end": "833440"
  },
  {
    "text": "and then these projects above to actually allow you to actually deploy those models on kinetics and add these techniques surrounding your model",
    "start": "833440",
    "end": "840560"
  },
  {
    "text": "and then at the top obviously it's a company we need to make money we have um a project which is our",
    "start": "840560",
    "end": "845600"
  },
  {
    "text": "core enterprise project which is bringing this all together for companies to provide a full enterprise stack uh for",
    "start": "845600",
    "end": "851360"
  },
  {
    "text": "machine learning bringing all this open source or like an open call company and feeding it in and then providing a full solution so",
    "start": "851360",
    "end": "856720"
  },
  {
    "text": "companies can scale uh and manage their models i'll give a quick glimpse of that at the end obviously i'll focus more on the",
    "start": "856720",
    "end": "863279"
  },
  {
    "text": "open source so going into a bit more detail on some of those projects so we have",
    "start": "863279",
    "end": "868320"
  },
  {
    "text": "seldom core so what is that trying to do that's basically allowing you to build up a whole graph of containerized components",
    "start": "868320",
    "end": "874800"
  },
  {
    "text": "that are doing inference and put them together allow them to be reusable in different projects and then",
    "start": "874800",
    "end": "880720"
  },
  {
    "text": "manage that for you so that graph is um defined by a custom resource so we have our own",
    "start": "880720",
    "end": "886720"
  },
  {
    "text": "operator that's running that and you define by that custom resource the various components",
    "start": "886720",
    "end": "892160"
  },
  {
    "text": "uh various customizations you want you know in terms of what customizations and what the model is um what type of model",
    "start": "892160",
    "end": "898800"
  },
  {
    "text": "it is and and how you want it to actually connect together so you might define just a single model in your inference graph or you might",
    "start": "898800",
    "end": "905040"
  },
  {
    "text": "have much more complex things so we have customers for instance doing large inference cars with",
    "start": "905040",
    "end": "910399"
  },
  {
    "text": "things like multi-arm bandits which which decide in real time based on the input traffic which of the underlying models",
    "start": "910399",
    "end": "916639"
  },
  {
    "text": "this particular request will go to so you might add that in with a suite of different models and then you might tie in further things earlier in the",
    "start": "916639",
    "end": "923040"
  },
  {
    "text": "um inference chain uh maybe some feature transformation that needs to be done before the actual the request gets the",
    "start": "923040",
    "end": "929199"
  },
  {
    "text": "model maybe some transformations that need to be done after the request has come back from the model and then adding an avid other things",
    "start": "929199",
    "end": "934959"
  },
  {
    "text": "like i discussed like outline detection and explanation so you basically allow you to define this whole graph in",
    "start": "934959",
    "end": "941040"
  },
  {
    "text": "uh yamalotsi yum or json as a custom resource and then deploy it and then manage it and update it so that really",
    "start": "941040",
    "end": "946880"
  },
  {
    "text": "handles the core thinking of what data scientists want to do deploy scale and update their model and they do that by updating that custom",
    "start": "946880",
    "end": "954320"
  },
  {
    "text": "resource um with the various definitions then then the next question i suppose is how",
    "start": "954320",
    "end": "960560"
  },
  {
    "text": "do they get the core components of to actually derive these sort of containerized boxes in their inference",
    "start": "960560",
    "end": "966160"
  },
  {
    "text": "graph and there's really two ways that we provide one is out of the box machine learning service all they need to do is okay",
    "start": "966160",
    "end": "972480"
  },
  {
    "text": "here's my artifact on s3 or google storage and then we'll fire up a say tensorflow serving",
    "start": "972480",
    "end": "979920"
  },
  {
    "text": "or a triton server you know for that artifact and manage it and um tie it all into the inference",
    "start": "979920",
    "end": "985440"
  },
  {
    "text": "graph so that the actual api can be used through that that's one way that's very popular that's obviously the most",
    "start": "985440",
    "end": "990560"
  },
  {
    "text": "simplest way that they they can use uh sell them once they've trained a model and got that artifact onto some",
    "start": "990560",
    "end": "995759"
  },
  {
    "text": "location either on the cluster as i say or in the cloud in some bucket then the other way which is surprisingly",
    "start": "995759",
    "end": "1001279"
  },
  {
    "text": "actually quite popular as well um with lots of organizations is if we have we have um particular language sdks so",
    "start": "1001279",
    "end": "1007600"
  },
  {
    "text": "in different languages if you have custom code and what we allow is the data scientist just to focus on the prediction codes",
    "start": "1007600",
    "end": "1014800"
  },
  {
    "text": "say in python we have a python wrapper as we call it and they can just focus on the predict call of the python wrapper and maybe some other stuff to",
    "start": "1014800",
    "end": "1021199"
  },
  {
    "text": "set up their model at the start and then we'll manage that in terms of wrapping it up into a um it's a micro",
    "start": "1021199",
    "end": "1026400"
  },
  {
    "text": "service allow them to um and containerized add in the metrics uh tracing and other other parts and so it",
    "start": "1026400",
    "end": "1033360"
  },
  {
    "text": "can easily be slotted in here as part of that inference graph and that's actually quite popular with a lot of our customers who have like custom",
    "start": "1033360",
    "end": "1039520"
  },
  {
    "text": "code in different languages we have people using java some people using r there's actually a talk at the last kubecon europe",
    "start": "1039520",
    "end": "1046079"
  },
  {
    "text": "about uh guys from nasdaq um using seldom core and they've got some models in r so with various language",
    "start": "1046079",
    "end": "1052640"
  },
  {
    "text": "wrappers and uh that allow you to wrap up your code uh so allow the data science just to focus on the machine learning code and then",
    "start": "1052640",
    "end": "1058400"
  },
  {
    "text": "put it into the graph i have a question so yeah uh",
    "start": "1058400",
    "end": "1065760"
  },
  {
    "text": "you mentioned the models on the right side um and they can be like uh artifacts in s3 but once those models",
    "start": "1065760",
    "end": "1072720"
  },
  {
    "text": "are created the models are created they are they loaded on on into memory or some other place where the influence",
    "start": "1072720",
    "end": "1080080"
  },
  {
    "text": "actually can happen faster or is it is it still in s3 or is it still",
    "start": "1080080",
    "end": "1085600"
  },
  {
    "text": "or like maybe ebs storage or maybe typically some of these models may",
    "start": "1085600",
    "end": "1092080"
  },
  {
    "text": "be kind of kind of large right so yeah absolutely that is a quite a good point so what",
    "start": "1092080",
    "end": "1097919"
  },
  {
    "text": "what we allow them to what we like people to do is define a uh location where it's from actually s3 and",
    "start": "1097919",
    "end": "1102960"
  },
  {
    "text": "then the actual model server will download the model from s3 onto the local volume",
    "start": "1102960",
    "end": "1108080"
  },
  {
    "text": "and then run it in memory so there is still work to be done in terms of very large organizations that",
    "start": "1108080",
    "end": "1113679"
  },
  {
    "text": "maybe have lots of um using the same model from different locations how you can use caching and",
    "start": "1113679",
    "end": "1118799"
  },
  {
    "text": "we're looking into that sort of caching layer that's that sits between um so s3 and the actual local model server",
    "start": "1118799",
    "end": "1125520"
  },
  {
    "text": "which will have the model in memory um but at present we provide um sort of uh standard downloaders like",
    "start": "1125520",
    "end": "1131280"
  },
  {
    "text": "a in a container that runs once the model server starts up it has the inner containers given the location",
    "start": "1131280",
    "end": "1137200"
  },
  {
    "text": "of the model and it understands how to talk to s3 or gcs et cetera and then it downloads it",
    "start": "1137200",
    "end": "1142240"
  },
  {
    "text": "locally and then the server starts in the main pod and reads from that",
    "start": "1142240",
    "end": "1148080"
  },
  {
    "text": "local volume and reads the model into uh yeah okay got it cool thank you cool",
    "start": "1148080",
    "end": "1155520"
  },
  {
    "text": "and so one other thing we add as part of what we do is is a service orchestrator so obviously you",
    "start": "1155520",
    "end": "1161440"
  },
  {
    "text": "just define this graph and you don't need to decide how how this graph connects together we so you can that's one way",
    "start": "1161440",
    "end": "1167360"
  },
  {
    "text": "you can define how the graph connects together but but will manage the sort of request and response flow",
    "start": "1167360",
    "end": "1172720"
  },
  {
    "text": "uh so through the graph so we add in a component which you don't see here which is a surface orchestrator which is going to",
    "start": "1172720",
    "end": "1177760"
  },
  {
    "text": "take the request and manage that flow it's going to say okay first i need to call say the feature transformer and then once the response comes back to",
    "start": "1177760",
    "end": "1184160"
  },
  {
    "text": "that they've defined this to go to a multi-arm bandit and i'll send the response to that and then the multi-magnet says okay i want to send to",
    "start": "1184160",
    "end": "1190720"
  },
  {
    "text": "say model a and in this case i'll send the model the request to model a the model a",
    "start": "1190720",
    "end": "1195919"
  },
  {
    "text": "response and it will send it back for out the graph so that's an extra component or sidecar",
    "start": "1195919",
    "end": "1201440"
  },
  {
    "text": "that we add in uh to the grass but apart from that they've got complete flexibility so they can define parts of these to be in certain",
    "start": "1201440",
    "end": "1208159"
  },
  {
    "text": "pods that scale it in a sort of different way so they say the feature transformations could have like hpa",
    "start": "1208159",
    "end": "1213440"
  },
  {
    "text": "uh the scales in one way and and the models can be on like another uh pod that is going to scale on us so",
    "start": "1213440",
    "end": "1220320"
  },
  {
    "text": "different metrics you've got a lot of flexibility in how you define it as well i mean then in terms of how",
    "start": "1220320",
    "end": "1226400"
  },
  {
    "text": "people use it so in terms of what we've done in terms of our life cycle we've focused initially",
    "start": "1226400",
    "end": "1231600"
  },
  {
    "text": "more on so rpc use cases a real time machine learning inference and that's probably how most of our customers um",
    "start": "1231600",
    "end": "1238240"
  },
  {
    "text": "come to us and use us at present but also what we're seeing is customers do want like a unified solution so once",
    "start": "1238240",
    "end": "1244159"
  },
  {
    "text": "they've created their model they don't just want to expose it via rpc they want to also send",
    "start": "1244159",
    "end": "1249360"
  },
  {
    "text": "us a batch request to it or or use their streaming but i say kafka k native",
    "start": "1249360",
    "end": "1254799"
  },
  {
    "text": "um and all and send that so we allow them to do all free basically um and it's very easy to use the same",
    "start": "1254799",
    "end": "1261120"
  },
  {
    "text": "components and irrespective of how they're going to sort of consume that model in their organization",
    "start": "1261120",
    "end": "1268320"
  },
  {
    "text": "so let's seldom core and i'll just go on if there's no questions sorry",
    "start": "1269760",
    "end": "1277039"
  },
  {
    "text": "i don't know if you can hear me though oh sorry it's a bit it's been low your volume but yeah i can hear you mentioned something about",
    "start": "1277039",
    "end": "1283039"
  },
  {
    "text": "containerization of their model initially is that part of what you provide as well or do they they",
    "start": "1283039",
    "end": "1288960"
  },
  {
    "text": "are assumed to have used s2i or whatever when they yeah so um also a good",
    "start": "1288960",
    "end": "1295360"
  },
  {
    "text": "question so we provided our docs as examples of how to use s2i and we we have actually sy",
    "start": "1295360",
    "end": "1301919"
  },
  {
    "text": "builder to allow them to easily use stoi that brings in the appropriate uh sort of dependencies say in python and stuff to",
    "start": "1301919",
    "end": "1307760"
  },
  {
    "text": "actually wrap the model easily but we also provide them um docs for how they can just use a standard uh so docker file to actually",
    "start": "1307760",
    "end": "1313840"
  },
  {
    "text": "uh create their model and we have people using different methods obviously not everybody wants to use this s2i this you know some people like it some people",
    "start": "1313840",
    "end": "1319919"
  },
  {
    "text": "don't and there's obviously many ways of building their containers we want to be quite agnostic to that so yeah it's not like a unified",
    "start": "1319919",
    "end": "1326320"
  },
  {
    "text": "solution that's that we provide them with different sort of resources to really um create their container in the way",
    "start": "1326320",
    "end": "1332559"
  },
  {
    "text": "that they want to okay i was just trying to figure out the scope of it okay great",
    "start": "1332559",
    "end": "1338720"
  },
  {
    "text": "okay cool uh that's sold and cool so as i said there's another area that we",
    "start": "1338720",
    "end": "1344000"
  },
  {
    "text": "work on which is uh sort of looking at things you need to surround your model with and that's two projects that we work on um",
    "start": "1344000",
    "end": "1350720"
  },
  {
    "text": "um one is added by explaining one alibi detects alibaba explains looking at explanations uh so looking at um once",
    "start": "1350720",
    "end": "1357679"
  },
  {
    "text": "your model is out there how you how if you get a particular prediction back why did the model give",
    "start": "1357679",
    "end": "1363200"
  },
  {
    "text": "the actual predict prediction we have different techniques for this both black box and white bug so black box has advantage it just purely treats the",
    "start": "1363200",
    "end": "1370320"
  },
  {
    "text": "model as it says as a black box and you just um talk to the model over an api so so the",
    "start": "1370320",
    "end": "1375679"
  },
  {
    "text": "big advantage of that is you don't you don't care how it was created what technique it could be like a",
    "start": "1375679",
    "end": "1380960"
  },
  {
    "text": "deep neural network it could be like a tree based model it could be just a sort of simple linear regression it",
    "start": "1380960",
    "end": "1386480"
  },
  {
    "text": "doesn't matter because all the techniques do is just query the model many many times normally by changing",
    "start": "1386480",
    "end": "1391760"
  },
  {
    "text": "some of the inputs from the um like initial input and trying to understand how the model is actually",
    "start": "1391760",
    "end": "1397039"
  },
  {
    "text": "responding to those slight slight changes in the input and from that it builds up a picture of how of what the model is taking into",
    "start": "1397039",
    "end": "1403600"
  },
  {
    "text": "consideration and then it can give like a human understandable response and that has a lot of interest and",
    "start": "1403600",
    "end": "1410000"
  },
  {
    "text": "especially in organizations who want to keep it quite separate so the team that they built the model they can keep it completely separate",
    "start": "1410000",
    "end": "1415919"
  },
  {
    "text": "from the team that needs to explain it it is obviously also more challenging though because it's treating as i said",
    "start": "1415919",
    "end": "1421520"
  },
  {
    "text": "purely as a black box so you're just talking over an api to it so we also have white box explanations which is",
    "start": "1421520",
    "end": "1426960"
  },
  {
    "text": "focused on if you know how the model was created so you actually have access to the model weights you know if it's in your",
    "start": "1426960",
    "end": "1432880"
  },
  {
    "text": "network you have access to the keras uh saved model then you can load that saved kos model and then you can look at",
    "start": "1432880",
    "end": "1438320"
  },
  {
    "text": "the weights and you can do analysis of that again probably um doing various techniques to actually",
    "start": "1438320",
    "end": "1443679"
  },
  {
    "text": "understand how it's working or if you've got like a tree based model you can actually load that tree based model and try to understand it and give an explanation",
    "start": "1443679",
    "end": "1450000"
  },
  {
    "text": "for this partic particular prediction so each of each has that both their pros and cons and there's not like a single way to do it",
    "start": "1450000",
    "end": "1457200"
  },
  {
    "text": "and also just to quickly jump into the alibi uh project uh just to illustrate the",
    "start": "1457200",
    "end": "1462559"
  },
  {
    "text": "sort of different ways of looking at it that we have a large number of different state-of-the-art techniques and",
    "start": "1462559",
    "end": "1467840"
  },
  {
    "text": "and the key thing is those techniques give different ways of viewing those exclamations also they have",
    "start": "1467840",
    "end": "1472960"
  },
  {
    "text": "different focuses on the type of input data so it could be that some techniques work with classification actually most of",
    "start": "1472960",
    "end": "1478159"
  },
  {
    "text": "them here work with classification but some are more focused on regression and also some are more focused on certain types of input data so if your",
    "start": "1478159",
    "end": "1484400"
  },
  {
    "text": "data is just tabular um then fine and also if it has some categorical variables you know is it",
    "start": "1484400",
    "end": "1489679"
  },
  {
    "text": "um some work better or worse with that somewhat focused more text someone",
    "start": "1489679",
    "end": "1495440"
  },
  {
    "text": "images um and other features like that so there's not really one uh way of solving the explanation",
    "start": "1495440",
    "end": "1502159"
  },
  {
    "text": "question in terms of machine learning models and also the way these give these models give their responses",
    "start": "1502159",
    "end": "1507440"
  },
  {
    "text": "is also um quite different and so some are suited more for data scientists uh where say some likes of",
    "start": "1507440",
    "end": "1512960"
  },
  {
    "text": "counterfactuals may be suited more for the actual customers so for example counterfactuals would tell you",
    "start": "1512960",
    "end": "1518480"
  },
  {
    "text": "what do you need to change so if you have like a loan system say that's all rejected your loan it's like automated system and if you",
    "start": "1518480",
    "end": "1524480"
  },
  {
    "text": "use the counter factual um explanation technique then it could tell you what do you as a customer need",
    "start": "1524480",
    "end": "1529919"
  },
  {
    "text": "to change for this system to change its mind and actually give you the actual loan and so it's easier to understand that way whereas other",
    "start": "1529919",
    "end": "1536080"
  },
  {
    "text": "techniques might help the actual data scientists understand what features are being taken into account in terms of how the models so they all",
    "start": "1536080",
    "end": "1542400"
  },
  {
    "text": "have their pros and cons um and we need to work with the organization uh concerned into which one",
    "start": "1542400",
    "end": "1548159"
  },
  {
    "text": "would be most appropriate for the actual models being put out um this is also quite an active research",
    "start": "1548159",
    "end": "1554559"
  },
  {
    "text": "area in which we and also the other challenges that's also quite complex so you need to train some of these on",
    "start": "1554559",
    "end": "1560000"
  },
  {
    "text": "the actual training data and so even though some of them are black box so they don't care about what technique you use to train",
    "start": "1560000",
    "end": "1566799"
  },
  {
    "text": "your model some of them need to understand the training data so if they're going to actually uh sort of perturb the input",
    "start": "1566799",
    "end": "1572960"
  },
  {
    "text": "then they need to know say if it's an age if this feature is an age then it only makes sense to sort of perturb it between say",
    "start": "1572960",
    "end": "1578960"
  },
  {
    "text": "1 and 110 or something there's no point putting in the value of 1000 and seeing how the model behaves because it's going to give you",
    "start": "1578960",
    "end": "1584640"
  },
  {
    "text": "strange results so there's certain you know things you need to look at in terms of that",
    "start": "1584640",
    "end": "1591120"
  },
  {
    "text": "so yeah this is very interesting so um do you actually integrate with some",
    "start": "1591120",
    "end": "1598000"
  },
  {
    "text": "other graphing tools i would imagine like some people want to understand you know so about how these models",
    "start": "1598000",
    "end": "1605039"
  },
  {
    "text": "actually behave so for example like something like tableau right so people want to",
    "start": "1605039",
    "end": "1610240"
  },
  {
    "text": "see how people are using the model or or how or how it's um",
    "start": "1610240",
    "end": "1617679"
  },
  {
    "text": "making its decisions right so oh yeah i'm absolutely i think there's quite a",
    "start": "1617679",
    "end": "1622720"
  },
  {
    "text": "challenge there i mean it's one of the large challenges inside explanations is really how you show that data to the user",
    "start": "1622720",
    "end": "1628960"
  },
  {
    "text": "and how how you tie it back into into the how come the actual model is being used actually maybe i can quickly sort of dip",
    "start": "1628960",
    "end": "1635279"
  },
  {
    "text": "into our enterprise body just to show you the explanations in action hopefully i can just give a quick demo so this is one model this is our",
    "start": "1635279",
    "end": "1641360"
  },
  {
    "text": "like our top level viewing panel of cell deploy which shows the different models you've got running",
    "start": "1641360",
    "end": "1646559"
  },
  {
    "text": "i'm not going to go into too much detail here we'll see if we're we're focusing more on the open source but this will help hopefully answer your",
    "start": "1646559",
    "end": "1652799"
  },
  {
    "text": "question so i've got one model here which is a sort of incomes or loan categorization",
    "start": "1652799",
    "end": "1658080"
  },
  {
    "text": "model uh which is based on making predictions uh based on sort of demographic features is actually",
    "start": "1658080",
    "end": "1663120"
  },
  {
    "text": "a standard sort of data set we have it's actually taken from the u.s census",
    "start": "1663120",
    "end": "1669360"
  },
  {
    "text": "in 1996 um open data set so we've got various demographic teachers",
    "start": "1669360",
    "end": "1674720"
  },
  {
    "text": "features and it will predict whether the person is going to have high or low income um so we can take a particular example",
    "start": "1674720",
    "end": "1681360"
  },
  {
    "text": "uh send it to the models it's like a binary classifier saying this person uh 86 chance of",
    "start": "1681360",
    "end": "1687440"
  },
  {
    "text": "having low income and because we've added an explainer um to this model it can basically",
    "start": "1687440",
    "end": "1694000"
  },
  {
    "text": "try to investigate that model and and understand why so this is using a technique called anchors so we've got the core demographic",
    "start": "1694000",
    "end": "1700000"
  },
  {
    "text": "features here and basically this is um showing that this model is quite focused on two it's saying",
    "start": "1700000",
    "end": "1706320"
  },
  {
    "text": "maltoset separation sexy or female so say 95 of the time if you just had those two",
    "start": "1706320",
    "end": "1711840"
  },
  {
    "text": "features the model would particularly low incomes obviously this is key because this is saying well is this acceptable to put this model out",
    "start": "1711840",
    "end": "1717840"
  },
  {
    "text": "because it looks like it's quite biased in terms of gender and so it may be that you this is",
    "start": "1717840",
    "end": "1722960"
  },
  {
    "text": "completely unacceptable but it's more like you need to get more or maybe that you need to get more data for uh various sections of your model so i",
    "start": "1722960",
    "end": "1729360"
  },
  {
    "text": "mean this technique anchors which is the technique i'm showing here really gives you the core anchors that the model is using uh you can set a",
    "start": "1729360",
    "end": "1735919"
  },
  {
    "text": "threshold in this case it's 90 so it tries to look for features obviously there's a lot of features here you know there's",
    "start": "1735919",
    "end": "1741520"
  },
  {
    "text": "features on what is white colored uh the race and other things where they are united states their age and other things like that",
    "start": "1741520",
    "end": "1747840"
  },
  {
    "text": "and it's trying to find core features that um from that initial request that we're trying",
    "start": "1747840",
    "end": "1753760"
  },
  {
    "text": "to explain that really made the model go in one direction and here it seems to be mostly amount of status",
    "start": "1753760",
    "end": "1760240"
  },
  {
    "text": "but because you set the the confidence to be at least 90 of the time it should be true this answer this explanation then they tried",
    "start": "1760240",
    "end": "1767120"
  },
  {
    "text": "to it went further tried to find one more feature which in this case was the gender feature",
    "start": "1767120",
    "end": "1773200"
  },
  {
    "text": "is the underlying model here is it you know random forest is it linear regression how do we see",
    "start": "1773520",
    "end": "1778640"
  },
  {
    "text": "that yeah this yeah this model is actually just a very simple i think it's um linear regression and this technique",
    "start": "1778640",
    "end": "1785279"
  },
  {
    "text": "is black box so it doesn't actually as i say depend on the actual underlying uh model but it's a very simple model just to",
    "start": "1785279",
    "end": "1790880"
  },
  {
    "text": "illustrate that it's quite biased and actually this data set um from",
    "start": "1790880",
    "end": "1796000"
  },
  {
    "text": "the census data is actually very um so unbalanced there's actually only um one percent of people who have high income so most",
    "start": "1796000",
    "end": "1802399"
  },
  {
    "text": "people have low income in the data center it produces very biased values this is why we're using it as an illustration of the",
    "start": "1802399",
    "end": "1809200"
  },
  {
    "text": "things you need to do to of how you can use explanations and it can help you understand your model more and then obviously",
    "start": "1809200",
    "end": "1815120"
  },
  {
    "text": "get early indicators of some of these things okay so like if you have linear regression and you are asking for a year",
    "start": "1815120",
    "end": "1820640"
  },
  {
    "text": "that's outside the model it might tell you look this is outside the range and so for",
    "start": "1820640",
    "end": "1825679"
  },
  {
    "text": "the linear regression is invalid or something like that um yeah i suppose that's i mean that's",
    "start": "1825679",
    "end": "1831760"
  },
  {
    "text": "slightly related actually this technique is actually needs to have access to the training data so it can",
    "start": "1831760",
    "end": "1837120"
  },
  {
    "text": "understand the range of i think this is the i'm not sure which one is the h thing but it needs to understand that if",
    "start": "1837120",
    "end": "1843440"
  },
  {
    "text": "it say in what it was doing it would probably send several hundred requests to the model it would probably change this feature a",
    "start": "1843440",
    "end": "1849440"
  },
  {
    "text": "little bit 65 you know 55 and stuff so he needs to know that there's no point doing 600 because",
    "start": "1849440",
    "end": "1854559"
  },
  {
    "text": "that's going to give you know strange results it won't help the explanation so it it sort of understands those aspects of the",
    "start": "1854559",
    "end": "1860720"
  },
  {
    "text": "actual training data and then it fires off lots of requests to get this answer okay so it's not really rule",
    "start": "1860720",
    "end": "1866240"
  },
  {
    "text": "based of uh oh you're doing linear regression in the wrong way or something it's not going to tell you yeah no it's not like that it's really",
    "start": "1866240",
    "end": "1872480"
  },
  {
    "text": "just i say treating the model as a black box and trying to understand uh by um uh understanding how the model",
    "start": "1872480",
    "end": "1879519"
  },
  {
    "text": "is behaving just around this particular value so it's changing features and seeing if the model changes its opinion",
    "start": "1879519",
    "end": "1885840"
  },
  {
    "text": "and um what are the core things that make it focus on that result very cool yeah yeah yeah it's it's",
    "start": "1885840",
    "end": "1893039"
  },
  {
    "text": "called set of techniques and so here down here we just give access to the actual training data sets you can see",
    "start": "1893039",
    "end": "1898960"
  },
  {
    "text": "examples which actually fit that explanation and then there should also be some examples which don't fit that so these",
    "start": "1898960",
    "end": "1905120"
  },
  {
    "text": "are people who have those features separated and female but have high income and so you can see okay maybe i",
    "start": "1905120",
    "end": "1911039"
  },
  {
    "text": "need to expand out my training set by getting more of these um you know to sort of label these and stuff and you know it just helps the",
    "start": "1911039",
    "end": "1917440"
  },
  {
    "text": "data scientists this technique is obviously as i said you need to be very understanding of the actual stakeholder",
    "start": "1917440",
    "end": "1922960"
  },
  {
    "text": "that needs to look at this if she gave this to a customer that would probably be very confusing to them so this is a technique that's probably more focused on the data",
    "start": "1922960",
    "end": "1929279"
  },
  {
    "text": "scientists or maybe the auditor as opposed to some of the other techniques",
    "start": "1929279",
    "end": "1935840"
  },
  {
    "text": "yeah this is one comment i think this is a great feature i mean some of the the things that i've been hearing about",
    "start": "1935919",
    "end": "1942080"
  },
  {
    "text": "some of the models is that they're biased and this is a great way to see that you know they're biased",
    "start": "1942080",
    "end": "1949840"
  },
  {
    "text": "and then maybe telling some of the data scientists that they need to change their models",
    "start": "1949840",
    "end": "1955120"
  },
  {
    "text": "right or they need to in a certain way so they they are less biased like yeah",
    "start": "1955120",
    "end": "1960799"
  },
  {
    "text": "absolutely so it can be used at various different stages of the machine life cycle so it can be using sort of development and",
    "start": "1960799",
    "end": "1966320"
  },
  {
    "text": "sort of so auditing but also obviously in production as well that you know you might get a request maybe this has gone live",
    "start": "1966320",
    "end": "1971679"
  },
  {
    "text": "and someone's saying hey what was i you know rejected uh you know for a loan and then we say oh look this is these are the reasons the",
    "start": "1971679",
    "end": "1977760"
  },
  {
    "text": "model is looking at you know and so you know you can get early with the early warning of that",
    "start": "1977760",
    "end": "1983039"
  },
  {
    "text": "i'll just show you one more this is like a different model this is the sort of text-based explanations this is a model that",
    "start": "1983039",
    "end": "1988320"
  },
  {
    "text": "takes um as a movie reviews and tries to decide whether it's",
    "start": "1988320",
    "end": "1995279"
  },
  {
    "text": "a positive one or a negative sentiment so hopefully i can find an example",
    "start": "1995279",
    "end": "2000640"
  },
  {
    "text": "and i'll predict and then i'll explain that example um and we can have a look at it so this is",
    "start": "2000640",
    "end": "2005840"
  },
  {
    "text": "a movie review it's a visually exquisite but narratively opaque and emotionally vapid experience of style of mystification",
    "start": "2005840",
    "end": "2011600"
  },
  {
    "text": "so obviously that's some negative and um so what this explanation here in the",
    "start": "2011600",
    "end": "2017200"
  },
  {
    "text": "text thing is saying what are the words that the model was looking at to really make this sort of negative and obviously it's",
    "start": "2017200",
    "end": "2022559"
  },
  {
    "text": "highlighting these two emotionally rapid as the two core things so it shows like another angle that you",
    "start": "2022559",
    "end": "2029279"
  },
  {
    "text": "need to have different explanation techniques for different types of data and and how those work for different types of data should be different so",
    "start": "2029279",
    "end": "2035360"
  },
  {
    "text": "you know obviously this is different you know to the tabular case and it's sort of highlighting things in like a different way but it's actually",
    "start": "2035360",
    "end": "2041440"
  },
  {
    "text": "using the same sort of technique but for text-based data rather than um sort of tabulators",
    "start": "2041440",
    "end": "2046960"
  },
  {
    "text": "this is anchor text as it's called anchor tabular technique",
    "start": "2046960",
    "end": "2052878"
  },
  {
    "text": "uh cool so yeah so that's alibi explain and then we also have alibi detect which is looking at um so",
    "start": "2054240",
    "end": "2060158"
  },
  {
    "text": "more the monitoring side so looking at outliers obviously because you don't want to actually give um responses from your",
    "start": "2060159",
    "end": "2065520"
  },
  {
    "text": "model if it's a outlier because because it's quite like the model is going to give a very strange results if you have an outlier",
    "start": "2065520",
    "end": "2071520"
  },
  {
    "text": "you know you should probably throw that result away from the model then other things like um adversarial",
    "start": "2071520",
    "end": "2076878"
  },
  {
    "text": "attack detectors and the source area that we do research on obviously it's quite niche uh",
    "start": "2076879",
    "end": "2082079"
  },
  {
    "text": "um there's you know obviously particular areas it's important for um this is an example taken you know",
    "start": "2082079",
    "end": "2088079"
  },
  {
    "text": "from sort of um a traffic sign detector so this is a classic one you know where you've got a stop sign here and",
    "start": "2088079",
    "end": "2094240"
  },
  {
    "text": "the model's saying stop great but if you just attack it in certain ways by adding a few pixels it still pretty much looks like a stop",
    "start": "2094240",
    "end": "2100480"
  },
  {
    "text": "sign to us but actually the model gives a completely different answer and the same for these other traffic signs",
    "start": "2100480",
    "end": "2107119"
  },
  {
    "text": "um i always wondered what stop sign was blue i think it's it's like taken from a german data",
    "start": "2107119",
    "end": "2112400"
  },
  {
    "text": "search and i'm sure maybe stop signs of blue in germany i'm not sure um the use of",
    "start": "2112400",
    "end": "2120240"
  },
  {
    "text": "their enjoyment yeah that's true yeah yeah so so that's uh we do that we also",
    "start": "2120240",
    "end": "2127280"
  },
  {
    "text": "look at things like drift detectors which tell you when do i need to retrain my models it's the input distribution the model saying completely different to what it",
    "start": "2127280",
    "end": "2134000"
  },
  {
    "text": "was trained on because again it's probably going to be giving bad answers you probably need to retrain it on on the new type of data and it's the",
    "start": "2134000",
    "end": "2140320"
  },
  {
    "text": "same sort of thing so this is the alibi detector github repo and again we there's a suite of different uh techniques again",
    "start": "2140320",
    "end": "2146720"
  },
  {
    "text": "based on some of the different um sort of uh modalities and sort of decision points yet is it is your data tabular image time",
    "start": "2146720",
    "end": "2153520"
  },
  {
    "text": "series text does it have categorical features you know do you want to do online outlet detection or do you want to have",
    "start": "2153520",
    "end": "2159440"
  },
  {
    "text": "outliers at the particular feature level you know so for like a so image the feature level will be sort of the level of pixels rather than the whole image",
    "start": "2159440",
    "end": "2166240"
  },
  {
    "text": "as you need to make decisions based on that and similar for the other sort of things adversarial detection and uh",
    "start": "2166240",
    "end": "2172720"
  },
  {
    "text": "sort of drift detection that's obviously the key is that we we do this data science then we bring it",
    "start": "2172720",
    "end": "2177920"
  },
  {
    "text": "back into seldom course you can then deploy your model using cell and core and then you can add these explainers etc",
    "start": "2177920",
    "end": "2185440"
  },
  {
    "text": "explain this out by the textures to your model to give the things surrounding it and that's obviously the goal to allow we're gonna allow those",
    "start": "2185440",
    "end": "2191599"
  },
  {
    "text": "organizations to do that um so cool so i'll go on to another project we work on which is care serving",
    "start": "2191599",
    "end": "2196720"
  },
  {
    "text": "so this is like focused on using some of the things from say k native so we're focusing on scale to zero",
    "start": "2196720",
    "end": "2202320"
  },
  {
    "text": "because obviously you know things like uh gpus and other aspects of machine learning influence are quite costly if you if",
    "start": "2202320",
    "end": "2208240"
  },
  {
    "text": "it's if you've got the model it's not being used wouldn't it be great just to get rid of the infrastructure from your kubernetes cluster so i mean it's really",
    "start": "2208240",
    "end": "2214160"
  },
  {
    "text": "great stuff to do in k native and so this is building on top of that and everything is we're looking at gpu auto scaling in this project because",
    "start": "2214160",
    "end": "2220720"
  },
  {
    "text": "actually gpu auto scanning is quite a challenge i think i'll talk about it in the next slide just how that",
    "start": "2220720",
    "end": "2226400"
  },
  {
    "text": "how canadian solves that and also what we're trying to do we actually founded this project with some very large partners google",
    "start": "2226400",
    "end": "2232640"
  },
  {
    "text": "bloomberg microsoft and ibm and we're trying to really create some standards for machine learning inference",
    "start": "2232640",
    "end": "2237760"
  },
  {
    "text": "and feed them across the whole industry so one thing we've done is is created like a standard protocol from machine",
    "start": "2237760",
    "end": "2242880"
  },
  {
    "text": "learning inference and we're starting to get people from these organizations to actually buy into actually using it",
    "start": "2242880",
    "end": "2248880"
  },
  {
    "text": "so obviously that takes time as all standards do but it's it's an interesting direction as",
    "start": "2248880",
    "end": "2254400"
  },
  {
    "text": "part of what the project was created for um so this project is part of key flow so key flows unless you've heard of it",
    "start": "2254400",
    "end": "2260000"
  },
  {
    "text": "it's like a sort of ecosystem of machine learning projects right from some data analysis training at scale and some",
    "start": "2260000",
    "end": "2267520"
  },
  {
    "text": "hyper parameter optimization and serving and so this part of that so it's like a great um sort of location to join",
    "start": "2267520",
    "end": "2273839"
  },
  {
    "text": "together with these other projects in this ecosystem to work on machine learning on top of kubernetes",
    "start": "2273839",
    "end": "2280079"
  },
  {
    "text": "so just focusing one thing in care serving that we solve so one thing that's really difficult is",
    "start": "2280079",
    "end": "2285599"
  },
  {
    "text": "gpu autoscaling why it's difficult because when you've got gpu some models using gpus you've",
    "start": "2285599",
    "end": "2290880"
  },
  {
    "text": "got various metrics you'll have metrics from the actual server using the cpu and you'll have metrics from",
    "start": "2290880",
    "end": "2296560"
  },
  {
    "text": "the actual gpu itself and also those gpu metrics are sometimes hard to uh get from your kubernetes cluster and",
    "start": "2296560",
    "end": "2302960"
  },
  {
    "text": "it's also then harder to combine all those into a single rule if you want to do auto scaling you know if you want to say okay my cpu or my",
    "start": "2302960",
    "end": "2309200"
  },
  {
    "text": "server gets over this amount am my gpu stats say this then i scale up",
    "start": "2309200",
    "end": "2315440"
  },
  {
    "text": "and it's actually quite hard for people to do so after luckily we can simplify that by using the ideas from k",
    "start": "2315440",
    "end": "2321920"
  },
  {
    "text": "native which just are gonna basically look at the number of in-flight requests going to your actual pods in this case",
    "start": "2321920",
    "end": "2328880"
  },
  {
    "text": "machine learning about ck native is quite so generic so all you have to do is say what for these pods",
    "start": "2328880",
    "end": "2335040"
  },
  {
    "text": "um what is the amount of um concurrent requests they can manage maybe this model server can handle 10",
    "start": "2335040",
    "end": "2340079"
  },
  {
    "text": "requests or maybe it's just one and so basically k native takes that into account it actually uses um various site cards and stuff it",
    "start": "2340079",
    "end": "2347040"
  },
  {
    "text": "puts in like you proxies to understand how many requests are in flight and then from that",
    "start": "2347040",
    "end": "2352240"
  },
  {
    "text": "it can take those stats from that and how many requests are coming in uh to actually decide she likes should i",
    "start": "2352240",
    "end": "2357359"
  },
  {
    "text": "scale up or should i scale down and so it makes it much easier for the actual user in terms of machine learning",
    "start": "2357359",
    "end": "2362880"
  },
  {
    "text": "who sits at the top who just wants to have their thing scale automatically not really to do much all they need to do is say how many requests can i",
    "start": "2362880",
    "end": "2369440"
  },
  {
    "text": "serve my actual model server server at the same time and it really solves that obviously there's some other great",
    "start": "2369440",
    "end": "2374720"
  },
  {
    "text": "things in k native if there's a burst of requests then they get stored in a component called the activator before they get",
    "start": "2374720",
    "end": "2380320"
  },
  {
    "text": "pushed on to the actual replicas when they've scaled up so you don't get like too many requests hitting your mod at the same",
    "start": "2380320",
    "end": "2386000"
  },
  {
    "text": "time so it's really interesting and we're trying to build on top of that technology um for machine learning",
    "start": "2386000",
    "end": "2392079"
  },
  {
    "text": "inference the question here is um so when it comes to handling many many requests",
    "start": "2392079",
    "end": "2400160"
  },
  {
    "text": "we're talking about millions millions of requests so so the standard practice is to keep uh",
    "start": "2400160",
    "end": "2407920"
  },
  {
    "text": "share storage you know for these for these spots or you know so they can they can actually do the",
    "start": "2407920",
    "end": "2413680"
  },
  {
    "text": "serving from that storage i mean if you if you have a really big model",
    "start": "2413680",
    "end": "2419760"
  },
  {
    "text": "because spinning up uh pots for every single request and then creating a you know models storage for",
    "start": "2419760",
    "end": "2426480"
  },
  {
    "text": "the model you know every for every single pod and we take a lot of time right so yeah absolutely and that's a",
    "start": "2426480",
    "end": "2432880"
  },
  {
    "text": "very good point you've actually uh i don't think i have it on these uh slides but um i gave a talk at the um icml on just on",
    "start": "2432880",
    "end": "2440720"
  },
  {
    "text": "kf serving and so one of the slides was the challenges presently with with using it and that is exactly what",
    "start": "2440720",
    "end": "2446240"
  },
  {
    "text": "you said the challenges are that once you scale up you've got that big lag times you've got all your requests waiting for this replica to start",
    "start": "2446240",
    "end": "2453200"
  },
  {
    "text": "and so yeah and that is a clear challenge and actually even some people if um so at the moment the way to solve",
    "start": "2453200",
    "end": "2459119"
  },
  {
    "text": "that is is to um uh well there's not really many ways that president of to solve",
    "start": "2459119",
    "end": "2464800"
  },
  {
    "text": "that but one is to have your model locally so it doesn't have to be downloaded so we should get rid of some of the network time but",
    "start": "2464800",
    "end": "2470240"
  },
  {
    "text": "even then you're still going to have time for the model server to start up or the other thing the other thing",
    "start": "2470240",
    "end": "2475520"
  },
  {
    "text": "people do is just to get rid of the scale to zero and just say okay i want to have at least a certain number of",
    "start": "2475520",
    "end": "2481040"
  },
  {
    "text": "replicas but then that's obviously getting rid of the whole point of okay native so yeah it's definitely an open challenge",
    "start": "2481040",
    "end": "2486720"
  },
  {
    "text": "um and that is something we're actually looking at as part of cash serving or so with the k-native community you know",
    "start": "2486720",
    "end": "2492400"
  },
  {
    "text": "how can that be solved yeah got it thank you yes you put your your",
    "start": "2492400",
    "end": "2497839"
  },
  {
    "text": "finger on the one of the key points uh cool um so yeah so i i've showed you some",
    "start": "2497839",
    "end": "2504160"
  },
  {
    "text": "deploy which is our sort of closed source architecture that's really bringing everything together so it's it's it's",
    "start": "2504160",
    "end": "2509920"
  },
  {
    "text": "it's allowing you to use core and care serving and alibi explainer detect and tying it all up with standard components",
    "start": "2509920",
    "end": "2516640"
  },
  {
    "text": "uh things like uh you know so things like githubs which were like a big believer in and say which if you don't know i'm sure",
    "start": "2516640",
    "end": "2522800"
  },
  {
    "text": "you do that everything gets stolen to source control before it's put into the cluster so you've got your sort of clarity of representations you",
    "start": "2522800",
    "end": "2528560"
  },
  {
    "text": "know as you define a model and deploy it's pushed out to github bucket comes back on using things like",
    "start": "2528560",
    "end": "2534160"
  },
  {
    "text": "argo cd which really allows you to give that full audit trail stuff like that and we",
    "start": "2534160",
    "end": "2539280"
  },
  {
    "text": "tie it together with um you know metrics and elastic stack and and off levels with decks and key cloaks",
    "start": "2539280",
    "end": "2545440"
  },
  {
    "text": "tying into ldap and enterprise api so that's how we tie everything together for like uh enterprise customers and obviously",
    "start": "2545440",
    "end": "2552160"
  },
  {
    "text": "that's quite key so like you know in terms of um some of the models i've got like a model running here um",
    "start": "2552160",
    "end": "2558000"
  },
  {
    "text": "where you get all the stats but the key thing is just to highlight the githubs you've got that full um you can",
    "start": "2558000",
    "end": "2563520"
  },
  {
    "text": "go to uh see what all the actual actions you've done on the model because it's all stored in in github",
    "start": "2563520",
    "end": "2569440"
  },
  {
    "text": "every everything you did so with all the canaries you created or other ways to update it and you can see what's the difference between that and",
    "start": "2569440",
    "end": "2576160"
  },
  {
    "text": "any um documentation and obviously if you feel there's a mistake you can go back to a particular",
    "start": "2576160",
    "end": "2581280"
  },
  {
    "text": "point in this little chain of your github repo and just restore to that state if you wish",
    "start": "2581280",
    "end": "2587200"
  },
  {
    "text": "so it really allows to do that so yeah that's what we're really doing um cool so that's the enterprise product i",
    "start": "2587200",
    "end": "2593280"
  },
  {
    "text": "don't that's pretty much my last slide i just wanted to finish on some uh things for the future and things which may interest you i'm not sure but",
    "start": "2593280",
    "end": "2599520"
  },
  {
    "text": "um so some things which have come yeah last night sorry the one that had our going",
    "start": "2599520",
    "end": "2604839"
  },
  {
    "text": "yep someone is already using tecton you know instead of argo can they should they just use and they",
    "start": "2604839",
    "end": "2611599"
  },
  {
    "text": "wanted to use selden would they have argo and selden on their system or like can you replace",
    "start": "2611599",
    "end": "2616960"
  },
  {
    "text": "argo in that picture with tacton yeah this is actually something slightly different this is i'm like another",
    "start": "2616960",
    "end": "2623440"
  },
  {
    "text": "project in like the argo ecosystem called argo cd so it's it it's all about sort of um",
    "start": "2623440",
    "end": "2629839"
  },
  {
    "text": "um git ops and sort of syncing things from a source control onto the cluster okay okay i got it yeah yeah thank you",
    "start": "2629839",
    "end": "2637520"
  },
  {
    "text": "it's but it is actually confusing because like actually when i created this slide i couldn't find but there wasn't any logo for argo cd so",
    "start": "2637520",
    "end": "2644640"
  },
  {
    "text": "i just stole the actual argo logos this is why like exactly what you said happens people",
    "start": "2644640",
    "end": "2649760"
  },
  {
    "text": "think it's just argo yeah okay all right thanks i think the argo cd people need to get a logo",
    "start": "2649760",
    "end": "2656240"
  },
  {
    "text": "um so yeah some final um points some things we're looking at so so gpu sharing is comes up quite a lot",
    "start": "2656240",
    "end": "2662800"
  },
  {
    "text": "in terms of you know because you've got these very costly um gpus and you might have say with some of our",
    "start": "2662800",
    "end": "2668160"
  },
  {
    "text": "partners like um from bloomberg and kfc we've got thousands of models which are say very slightly different",
    "start": "2668160",
    "end": "2674160"
  },
  {
    "text": "and they all um skype learn model sales or something and they and what they need to do is really share",
    "start": "2674160",
    "end": "2679359"
  },
  {
    "text": "on a single server or those models to so decrease cost and also some of them might not be used to be used very much",
    "start": "2679359",
    "end": "2685440"
  },
  {
    "text": "so that's a definitely a challenge and actually part of the care of survey project we're looking at extension of that project to do so",
    "start": "2685440",
    "end": "2691359"
  },
  {
    "text": "multi-modal serving is what we call it to allow you to have multiple models on a server and so pack them in",
    "start": "2691359",
    "end": "2696640"
  },
  {
    "text": "to one server and also there's other things we're looking at like volcano which has a gpu scheduler to allow you",
    "start": "2696640",
    "end": "2702480"
  },
  {
    "text": "to share gpus and stuff so it's very early stages and i think the actual volcano gpu schedule is also",
    "start": "2702480",
    "end": "2708000"
  },
  {
    "text": "very much in alpha there's interesting stuff there that are coming back from our customers that we need to look at um stuff like",
    "start": "2708000",
    "end": "2714480"
  },
  {
    "text": "edge i'm sorry as like a company and also the code that you've seen we're not really sort of edge focused at the moment but that's",
    "start": "2714480",
    "end": "2720000"
  },
  {
    "text": "definitely uh which obviously we all know is growing and um be great to get your feedback of what you're seeing",
    "start": "2720000",
    "end": "2725839"
  },
  {
    "text": "from other people who probably presented because i saw you had some cube edge presenting some weeks ago so interesting to get",
    "start": "2725839",
    "end": "2731599"
  },
  {
    "text": "your feedback on that point actually rather than me i think we've certainly seen customers um in that area definitely",
    "start": "2731599",
    "end": "2738079"
  },
  {
    "text": "um and so general model optimization is something we're looking at into the future so you know",
    "start": "2738079",
    "end": "2743440"
  },
  {
    "text": "so customers will sometimes want to just give us the model it could be just a tensorflow model but then we can do various optimizations optimize",
    "start": "2743440",
    "end": "2749760"
  },
  {
    "text": "it for various endpoints it could be for edge you know sort of and or other ways of optimizing the models you know",
    "start": "2749760",
    "end": "2755359"
  },
  {
    "text": "perhaps take a skype in their model and turn it into one that can be run on a cheaper you and stuff so there's lots of interesting stuff",
    "start": "2755359",
    "end": "2760880"
  },
  {
    "text": "there that we're looking at and then just one uh final thing is to shout out about care serving and sort of general",
    "start": "2760880",
    "end": "2766720"
  },
  {
    "text": "machine learning data plan we're doing so as you said we've created a general machine learning protocol",
    "start": "2766720",
    "end": "2773119"
  },
  {
    "text": "uh which was is then going to be supported by their various people in the industry supported by nvidia triton infant server",
    "start": "2773119",
    "end": "2779599"
  },
  {
    "text": "present seldom self care serving and and then hopefully in the near future torch server facebook doing some work",
    "start": "2779599",
    "end": "2785040"
  },
  {
    "text": "there so that's an interesting development of cool so hopefully i haven't taken up too much time it's",
    "start": "2785040",
    "end": "2790480"
  },
  {
    "text": "probably longer than i thought but they're happy to open up a discussion or any points",
    "start": "2790480",
    "end": "2797119"
  },
  {
    "text": "thank you for the presentation it's very interesting um space and then",
    "start": "2800160",
    "end": "2807440"
  },
  {
    "text": "yeah in you know i think a lot a lot of people",
    "start": "2807440",
    "end": "2812640"
  },
  {
    "text": "are moving more towards um you know having more of a cicd type of system where",
    "start": "2812640",
    "end": "2821440"
  },
  {
    "text": "you can have like um you know have the data scientists create",
    "start": "2821440",
    "end": "2827359"
  },
  {
    "text": "some of these models and have some of the the cluster operators so the devops uh",
    "start": "2827359",
    "end": "2834800"
  },
  {
    "text": "uh people in an organization handle some of the serving parts so i think this kind of fits them",
    "start": "2834800",
    "end": "2841599"
  },
  {
    "text": "in there to to fill that gap like yeah absolutely yeah thanks yeah i think",
    "start": "2841599",
    "end": "2848240"
  },
  {
    "text": "it is quite a big need definitely as hopefully like the slides at the start showed",
    "start": "2848240",
    "end": "2853359"
  },
  {
    "text": "um so yeah definitely so what question did i have that i is a",
    "start": "2853359",
    "end": "2859280"
  },
  {
    "text": "seldom team um looking at maybe having one of their projects join the cncf for being part of the cncf",
    "start": "2859280",
    "end": "2868000"
  },
  {
    "text": "uh uh yeah i'm certainly we are thinking about it um in terms of several projects but we can't say which but yeah",
    "start": "2868000",
    "end": "2874720"
  },
  {
    "text": "we're certainly in talks with cncf and the guys lfai um so yeah um i think that's probably",
    "start": "2874720",
    "end": "2881200"
  },
  {
    "text": "interaction we'll probably think about some of the projects definitely",
    "start": "2881200",
    "end": "2887280"
  },
  {
    "text": "great anybody has any questions that don't want to be the only ones to ask",
    "start": "2887280",
    "end": "2892559"
  },
  {
    "text": "most of the questions i guess i had a question about the kf serving it's part of kubeflow",
    "start": "2892559",
    "end": "2899040"
  },
  {
    "text": "yeah uh components that are also part of coke flow or is that",
    "start": "2899040",
    "end": "2904480"
  },
  {
    "text": "that is i i somehow had the idea that all of seldon was in kubo but i guess that's not",
    "start": "2904480",
    "end": "2910160"
  },
  {
    "text": "that's are all the open source parts i guess that's not right yeah yeah so seldom is like",
    "start": "2910160",
    "end": "2915920"
  },
  {
    "text": "separate from kubeflow but we have integrations in queue flow so if people want to use seldom core in queue",
    "start": "2915920",
    "end": "2922400"
  },
  {
    "text": "flow they can and also the the project kfc is actually in keyflops yes it is a bit confusing",
    "start": "2922400",
    "end": "2929440"
  },
  {
    "text": "so uh i'm so careful serving as part of the keyflow so domain and that project is inside um keyflow",
    "start": "2929440",
    "end": "2935359"
  },
  {
    "text": "for serving so it's all both for the two projects one is outside but you can use it and one's inside",
    "start": "2935359",
    "end": "2941200"
  },
  {
    "text": "being developed on there so if uh seldom became part of cncf then",
    "start": "2941200",
    "end": "2947440"
  },
  {
    "text": "kubeflow might do that separately and they just interact together that would be the way to do that",
    "start": "2947440",
    "end": "2952480"
  },
  {
    "text": "um yeah i suppose it's quite separate i suppose kevlar because it's so under uh so",
    "start": "2952480",
    "end": "2958800"
  },
  {
    "text": "google i think probably it's up to them i think there's actually an open discussion in in queue club of how the individual",
    "start": "2958800",
    "end": "2965520"
  },
  {
    "text": "projects were what the governance would be whether individual projects could then move into cncf",
    "start": "2965520",
    "end": "2971040"
  },
  {
    "text": "or lfai or however i think google is interested in keeping it",
    "start": "2971040",
    "end": "2976240"
  },
  {
    "text": "together at the moment okay thanks",
    "start": "2976240",
    "end": "2984640"
  },
  {
    "text": "yeah we i think uh with cube edges there's also a good fit there uh you can maybe",
    "start": "2984640",
    "end": "2992160"
  },
  {
    "text": "edge can be used to you know manage some of these workloads and then you know some of them",
    "start": "2992160",
    "end": "2999599"
  },
  {
    "text": "can be used maybe to send the these um workloads or or the the models and the",
    "start": "2999599",
    "end": "3007359"
  },
  {
    "text": "the serving mechanism over to the ah right where maybe you want to have faster response",
    "start": "3007359",
    "end": "3013119"
  },
  {
    "text": "time and i've seen some of the use cases where you know you you do some of that",
    "start": "3013119",
    "end": "3019200"
  },
  {
    "text": "inference on say stop sign or or maybe license plates and uh",
    "start": "3019359",
    "end": "3027040"
  },
  {
    "text": "for example right so yeah yeah absolutely i mean it's not a um i",
    "start": "3027040",
    "end": "3033119"
  },
  {
    "text": "know too much about cube edge but it's something this part of our research path to see how we can",
    "start": "3033119",
    "end": "3038240"
  },
  {
    "text": "get closer to those guys and see how we can collaborate",
    "start": "3038240",
    "end": "3043200"
  },
  {
    "text": "any other comments questions",
    "start": "3047839",
    "end": "3055839"
  },
  {
    "text": "once twice got some people on the call that are very quiet",
    "start": "3057599",
    "end": "3069838"
  },
  {
    "text": "okay well thank you very much uh okay thank you thanks for all the",
    "start": "3070319",
    "end": "3077680"
  },
  {
    "text": "insights and yeah let's keep in touch absolutely",
    "start": "3077680",
    "end": "3083280"
  },
  {
    "text": "absolutely yeah thanks for having me here i appreciate it alright thank you all",
    "start": "3083280",
    "end": "3097838"
  },
  {
    "text": "you",
    "start": "4037039",
    "end": "4039119"
  }
]
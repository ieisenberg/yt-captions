[
  {
    "text": "all right hello everyone hope you guys are enjoying your first full day at uh cucon North America 2023 uh my name is",
    "start": "719",
    "end": "7799"
  },
  {
    "text": "Mal olssen um we're all here today to talk about um how to build realtime",
    "start": "7799",
    "end": "13960"
  },
  {
    "text": "highly performing applications and how you can do that with reddis um sort of",
    "start": "13960",
    "end": "19199"
  },
  {
    "text": "I'm hoping you guys all at least know what reddis is does anyone here not know what reddis",
    "start": "19199",
    "end": "24720"
  },
  {
    "text": "is good uh I will not be explaining it at all so",
    "start": "24720",
    "end": "31199"
  },
  {
    "text": "none of the basics we're only here for advanced stuff um yeah so I'm here to talk kind",
    "start": "31199",
    "end": "37000"
  },
  {
    "text": "of about um sort of the talk about some basic concepts in caching and how you can extend those with res and then some",
    "start": "37000",
    "end": "43200"
  },
  {
    "text": "of the more advanced patterns we see uh that I've seen people used um so I said",
    "start": "43200",
    "end": "48640"
  },
  {
    "text": "my name is mine I am a principal engineer at AWS uh and I'm also one of the open source reddits",
    "start": "48640",
    "end": "55000"
  },
  {
    "text": "maintainers so I want to start off this talk by sort of just you know a little bit of a warning which is that a lot of",
    "start": "55000",
    "end": "61039"
  },
  {
    "text": "people these days kind of view uh like latency as like the new outage like a lot of people hear this quote where if",
    "start": "61039",
    "end": "67640"
  },
  {
    "text": "someone sees your application being slow that's like the number one reason for people to not come back um but that",
    "start": "67640",
    "end": "73880"
  },
  {
    "text": "doesn't necessarily mean you should put a cach there which is what we see a lot of people do and that doesn't always work great so before you know anyone",
    "start": "73880",
    "end": "81320"
  },
  {
    "text": "tries to like suggest putting a cash in application you should really make sure like the data is cachable and that you",
    "start": "81320",
    "end": "87400"
  },
  {
    "text": "know you can identify that piece of information with the key and then you're doing a lot of frequent lookups on that",
    "start": "87400",
    "end": "93040"
  },
  {
    "text": "key you're not you know constantly you know updating that data and you need to reest it",
    "start": "93040",
    "end": "99520"
  },
  {
    "text": "um so that's the first thing the second thing is make sure that you're actually like experiencing the problem on the",
    "start": "99520",
    "end": "105640"
  },
  {
    "text": "read path we see a lot of people trying to figure out how to put caches in the right path and they generally don't work out super well you can do something you",
    "start": "105640",
    "end": "112640"
  },
  {
    "text": "can like buffer data but that's not quite caching we see people start losing data like don't don't do that",
    "start": "112640",
    "end": "118719"
  },
  {
    "text": "either um um the other good reason to start adding caches when you start hitting scaling limits you usually want",
    "start": "118719",
    "end": "123759"
  },
  {
    "text": "to start rethinking how your architecture work if that's the problem you're having it's probably not caching",
    "start": "123759",
    "end": "129440"
  },
  {
    "text": "um and also tolerate eventual consistency so many people just think like oh we can just put a cache in front of our like user apis and then it works",
    "start": "129440",
    "end": "136480"
  },
  {
    "text": "and it doesn't so those are sort of like you know I'm going to talk more about you know making sure you're following",
    "start": "136480",
    "end": "142640"
  },
  {
    "text": "these in a bit but let's di in and just kind of go over the basics and talk about how R fits into this",
    "start": "142640",
    "end": "148400"
  },
  {
    "text": "picture so most people when they use caching they start with uh what's called lazy loading",
    "start": "148400",
    "end": "154080"
  },
  {
    "text": "and read through the idea being that you have a query in a backend database and you want to identify that piece of",
    "start": "154080",
    "end": "160760"
  },
  {
    "text": "information uh you check you first check to see if it's in Cache like redus and if it's not you go and check it from the",
    "start": "160760",
    "end": "166440"
  },
  {
    "text": "backend database and then pull the data back through right so how does this data eventually get invalidated which is to",
    "start": "166440",
    "end": "173080"
  },
  {
    "text": "say how does it no longer become the most upto-date source of Truth you you typically set a TTL on this so res has",
    "start": "173080",
    "end": "179280"
  },
  {
    "text": "obviously they have support for ttls but so do all the other major caching",
    "start": "179280",
    "end": "184560"
  },
  {
    "text": "engines so one thing I want to highlight here is that there's an independence of the read and the right path this is",
    "start": "184560",
    "end": "191319"
  },
  {
    "text": "often important for microservice architectures because they follow command query responsibility segregation",
    "start": "191319",
    "end": "196879"
  },
  {
    "text": "which is you want to have independent wrs and reads so that they can scale independently so if you're just doing",
    "start": "196879",
    "end": "202680"
  },
  {
    "text": "Lazy loading everything is on the read path which is great so what are some R specific things",
    "start": "202680",
    "end": "210040"
  },
  {
    "text": "you can use to make that read path better so the most common thing we see people do is what's called a refresh a",
    "start": "210040",
    "end": "216280"
  },
  {
    "text": "head pattern with Reddit the idea being that you can listen to keyspace notifications in redus which is a pubsub",
    "start": "216280",
    "end": "224120"
  },
  {
    "text": "notification mechanism that's best effort and it will notify you when a key gets deleted people use this in a way",
    "start": "224120",
    "end": "231640"
  },
  {
    "text": "that when the key gets deleted they'll know the key name and from that they'll be able to refresh the data back from",
    "start": "231640",
    "end": "236959"
  },
  {
    "text": "the backend database this this helps with tail latency as you no longer have that first",
    "start": "236959",
    "end": "243120"
  },
  {
    "text": "cash Miss on the lazy loading the other thing we see people which is kind of",
    "start": "243120",
    "end": "248640"
  },
  {
    "text": "starting to become more popular now which is client assisted sorry server assisted client site caching so",
    "start": "248640",
    "end": "255239"
  },
  {
    "text": "traditional client side caching usually involves keeping sort of track of ttls on the client um but now we support the",
    "start": "255239",
    "end": "262400"
  },
  {
    "text": "ability for res to directly invalidate uh the records that the client has read so the way it works is",
    "start": "262400",
    "end": "269000"
  },
  {
    "text": "the client op in to client side caching every time it gets a value Reddit will keep track of that and when that value",
    "start": "269000",
    "end": "275680"
  },
  {
    "text": "is no longer up to date it will send a notification to the client and the client can kick it out there's some",
    "start": "275680",
    "end": "281000"
  },
  {
    "text": "popular clients like lettuce which does this automatically but most clients support all the fundamentals uh to support this",
    "start": "281000",
    "end": "288560"
  },
  {
    "text": "already so last thing that I'm going to call like uh caching fundamentals is how",
    "start": "288560",
    "end": "295320"
  },
  {
    "text": "to do invalidations so invalidations is is the path where we are proactively kicking",
    "start": "295320",
    "end": "301360"
  },
  {
    "text": "stuff out of the cach right so this is done in usually one of two ways through a right through",
    "start": "301360",
    "end": "306639"
  },
  {
    "text": "caching pattern where we basically go to the database reput everything uh back in the cache or we just kick it out and let",
    "start": "306639",
    "end": "313639"
  },
  {
    "text": "lazy loading take its uh place and repopulate the cache the Highlight I",
    "start": "313639",
    "end": "319160"
  },
  {
    "text": "want to make here is that now we have to make changes on both the read and the right path again as we talked about we",
    "start": "319160",
    "end": "324440"
  },
  {
    "text": "like to have those separate so now these two uh systems might be built by different teams and now they have to",
    "start": "324440",
    "end": "330039"
  },
  {
    "text": "coordinate to make sure the cache is staying coherent so that's kind of the S like if",
    "start": "330039",
    "end": "337000"
  },
  {
    "text": "you if you can do all that you're doing caching more or less right but there's nothing reddish interesting or too",
    "start": "337000",
    "end": "342360"
  },
  {
    "text": "interesting in that so what most people really want to be using with redus is using all the advanced data structures",
    "start": "342360",
    "end": "347600"
  },
  {
    "text": "we had everything we talked about so far is just using the string data type and R strings are just binary Blobs of data",
    "start": "347600",
    "end": "354120"
  },
  {
    "text": "you can stick compressed blobs in them Json blobs SQL like result set blobs whatever you want strings are great for",
    "start": "354120",
    "end": "360720"
  },
  {
    "text": "that but the other big data structures that redus uses for caching are the hash which is basically a subkey value pair",
    "start": "360720",
    "end": "368319"
  },
  {
    "text": "people use this to sort of store like sub piece of information or they might store like a",
    "start": "368319",
    "end": "373639"
  },
  {
    "text": "large block of uh text as different components and then you can fetch pieces of them",
    "start": "373639",
    "end": "379560"
  },
  {
    "text": "individually the next data structure is the set which people use a lot for like fraud detection you might put Bad actors",
    "start": "379560",
    "end": "386120"
  },
  {
    "text": "in The set and say hey is this user in this or are they not and most might also do stuff like hey is this user alloud",
    "start": "386120",
    "end": "392039"
  },
  {
    "text": "listed you can do a very quick check to see if that the user is in the set or",
    "start": "392039",
    "end": "397400"
  },
  {
    "text": "not the next data structure is what we call the sorted set which is kind of just a fancy way of saying it's an",
    "start": "397400",
    "end": "402960"
  },
  {
    "text": "ordered set based on a number so this allows you to rank um the elements in a",
    "start": "402960",
    "end": "408720"
  },
  {
    "text": "set a more practical example is what we typically call a leaderboard which",
    "start": "408720",
    "end": "414280"
  },
  {
    "text": "is uh when you have a ranking of items which is we also see use this it's it's",
    "start": "414280",
    "end": "420080"
  },
  {
    "text": "common in like the gaming context like hey who has the highest score but much more practically it's used a lot to say",
    "start": "420080",
    "end": "425319"
  },
  {
    "text": "like hey what are the top 10 products that are being sold in the store today and the score would be how many times",
    "start": "425319",
    "end": "431479"
  },
  {
    "text": "it's sold and the member or the key name is the uh actual product being sold um",
    "start": "431479",
    "end": "437400"
  },
  {
    "text": "I'm not going to touch too much into geospatial but that's kind of like a sword set but instead of using a score",
    "start": "437400",
    "end": "442680"
  },
  {
    "text": "it uses what's called a GEOS hash which allows you do pretty efficient queries on like the nearest and neighbors to an",
    "start": "442680",
    "end": "450400"
  },
  {
    "text": "element uh what's great about this is res is also completely open source so there's also a bunch of Open Source um",
    "start": "450400",
    "end": "456199"
  },
  {
    "text": "extensions to Res called modules which add even more data structures so what are all these data",
    "start": "456199",
    "end": "462240"
  },
  {
    "text": "structures that have in common that make them good for cing because res has other data structures it also has the list in the stream data",
    "start": "462240",
    "end": "468440"
  },
  {
    "text": "types this is great because these are all um what I like to call um declarative they have declarative apis",
    "start": "468440",
    "end": "475639"
  },
  {
    "text": "which is to say hey we're setting the value to be something this is good because you often need to keep your cash",
    "start": "475639",
    "end": "481280"
  },
  {
    "text": "consistent with your backend database you don't want to have to worry about cases where if you send uh a API twice",
    "start": "481280",
    "end": "489159"
  },
  {
    "text": "it gives you a different result right because you're usually like committing the transaction and then updating the cash and you're kind of okay if you",
    "start": "489159",
    "end": "495680"
  },
  {
    "text": "don't upate update the cache but you're really concerned if you like update it twice to be more concrete so when you're",
    "start": "495680",
    "end": "501759"
  },
  {
    "text": "putting something in a set you can only put something in a set once if you try to put some the same thing in the set",
    "start": "501759",
    "end": "506879"
  },
  {
    "text": "twice you'll get the same output um this property is called item potency which is really great for caching so let's walk",
    "start": "506879",
    "end": "515360"
  },
  {
    "text": "through a little bit like what what these actually might look like in like real workloads so I'm going to talk a",
    "start": "515360",
    "end": "521240"
  },
  {
    "text": "lot about this like this relational table for a little bit which is just like hey we have this idea where someone's ordering products um there's",
    "start": "521240",
    "end": "528320"
  },
  {
    "text": "an order ID there's some product Ida that uh defines what product we're ordering and some customer is buying",
    "start": "528320",
    "end": "535959"
  },
  {
    "text": "that so when you're trying to think about caching with redus you should think a lot about the use cases um like",
    "start": "535959",
    "end": "542200"
  },
  {
    "text": "how how do you want to access this data so let's say we have an example where we want to see if a user has bought a given",
    "start": "542200",
    "end": "549480"
  },
  {
    "text": "item before so we can use a set for that right we can say hey is this in the set or not so we can see we can sort of like",
    "start": "549480",
    "end": "556600"
  },
  {
    "text": "reimagine the data from this relational table into a Redd set um we're following all Redd's like best practices where you",
    "start": "556600",
    "end": "562440"
  },
  {
    "text": "kind of have a common prefix for all the same data and then we're using like the right data type",
    "start": "562440",
    "end": "569959"
  },
  {
    "text": "so when we look at this like how would we actually construct this set because all of the the mechanisms we have so far",
    "start": "569959",
    "end": "575640"
  },
  {
    "text": "don't allow us to do this we can't lazy load this information every time we request it we don't want to pull it",
    "start": "575640",
    "end": "580880"
  },
  {
    "text": "through like do a complex query on the relational table maybe we could do something like right through every time",
    "start": "580880",
    "end": "586959"
  },
  {
    "text": "the the the product gets ordered we put in the cache but then we have problems if like the cache becomes inconsistent",
    "start": "586959",
    "end": "592519"
  },
  {
    "text": "how do we like refresh the data back so I just want to think about that for a",
    "start": "592519",
    "end": "597880"
  },
  {
    "text": "second so so let's talk about one other case which",
    "start": "597880",
    "end": "604800"
  },
  {
    "text": "is um the the benefit we had in that previous example is like that all the",
    "start": "604800",
    "end": "610160"
  },
  {
    "text": "data was kind of still there and if we tried to add something multiple times we'd like we'd have this it pocy",
    "start": "610160",
    "end": "615640"
  },
  {
    "text": "protecting us so on the other big use case I want",
    "start": "615640",
    "end": "620920"
  },
  {
    "text": "to talk about is the leaderboard case so let's say we want to say what are the top uh items ordered for a given C",
    "start": "620920",
    "end": "629120"
  },
  {
    "text": "category and so we have like um a couple of items in this case this is all in a",
    "start": "629120",
    "end": "634200"
  },
  {
    "text": "single key not multiple keys and we can see how many of each item has been",
    "start": "634200",
    "end": "640200"
  },
  {
    "text": "purchased so we still don't we still have the same problems as the set case where if we want to we can't lazy load",
    "start": "640200",
    "end": "646639"
  },
  {
    "text": "this information if we want to write through it we don't have the item pocy protection because if we want to say like increment the item by one we don't",
    "start": "646639",
    "end": "654240"
  },
  {
    "text": "have the protection because if we accidentally send the command twice it will get uh it will become incoherent with the back",
    "start": "654240",
    "end": "661120"
  },
  {
    "text": "end so sort of just to reate like we do we have an ability to do an item poent",
    "start": "661120",
    "end": "666240"
  },
  {
    "text": "ad so in R sord sets can have an item Point add with a z ad which set sets a",
    "start": "666240",
    "end": "671639"
  },
  {
    "text": "specific subkey um sorry the specific score of a member to a specific value so like we",
    "start": "671639",
    "end": "677600"
  },
  {
    "text": "would like to be able to do that but we we don't really have a a good mechanism for doing that um if if there was some",
    "start": "677600",
    "end": "684160"
  },
  {
    "text": "way we could sort of keep track of how many of the increments that we were doing we'd be able to sort of solve this",
    "start": "684160",
    "end": "689360"
  },
  {
    "text": "problem because we were able to turn a non itm ponent operation into an item ponent",
    "start": "689360",
    "end": "696240"
  },
  {
    "text": "operation so the metap point that I was trying to kind of get at was this sounds a lot like what the database is really",
    "start": "696240",
    "end": "701920"
  },
  {
    "text": "doing already so the database's job is basically to keep track of all the transactions and make sure they get applied in order",
    "start": "701920",
    "end": "708600"
  },
  {
    "text": "consistently so it would be really nice instead of what we're currently doing of like trying to keep the two databases",
    "start": "708600",
    "end": "715200"
  },
  {
    "text": "and the cache in sync we could just listen to what the database was doing and every time it updates a record it",
    "start": "715200",
    "end": "720920"
  },
  {
    "text": "would just go and let the cache know directly and we don't have to worry about it because it's already maintaining logs",
    "start": "720920",
    "end": "727320"
  },
  {
    "text": "like basically all major databases use a right Ahad log to keep track of updates",
    "start": "727320",
    "end": "733720"
  },
  {
    "text": "so thank God for open source there's already project that basically does all of this right we don't want to have to",
    "start": "733720",
    "end": "739199"
  },
  {
    "text": "think about how to manage the different logs from the different databases so as an open source project called deum that",
    "start": "739199",
    "end": "744519"
  },
  {
    "text": "kind of does all of this for us so deum is Like Glue code deum knows how to",
    "start": "744519",
    "end": "750519"
  },
  {
    "text": "listen to all the different databases and it knows how to basically push out notifications about the updates from",
    "start": "750519",
    "end": "756279"
  },
  {
    "text": "that database um the the most quintessential use case is it's usually pushing these into a cka topic um but",
    "start": "756279",
    "end": "763440"
  },
  {
    "text": "this slide had rst on it so I want to use that instead these are a little bit less common but you can use all this",
    "start": "763440",
    "end": "769880"
  },
  {
    "text": "stuff and the great thing about uh deum being open source is it basically supports most major databases including",
    "start": "769880",
    "end": "776519"
  },
  {
    "text": "including Cloud dative ones like FAS so what does uh deum basically do it's",
    "start": "776519",
    "end": "783560"
  },
  {
    "text": "listening in on the updates and produces update records like this so the core pieces of information",
    "start": "783560",
    "end": "790480"
  },
  {
    "text": "here is that there's a schema so it kind of tells you on every update sort what schema looks like you can turn this off",
    "start": "790480",
    "end": "796320"
  },
  {
    "text": "but it's important to make sure like the schema is not changing beneath you um and then you get basically a pre-image",
    "start": "796320",
    "end": "802079"
  },
  {
    "text": "and a post image so in this case this is a create uh record so there's no before",
    "start": "802079",
    "end": "808519"
  },
  {
    "text": "image if there was there would be um if this was an update there would be a before image but there's an after image which",
    "start": "808519",
    "end": "813680"
  },
  {
    "text": "is this is what the database looks like after the update and what's really important here is we have transaction",
    "start": "813680",
    "end": "818839"
  },
  {
    "text": "IDs so we know basically where we are in the Stream and we could know if we've",
    "start": "818839",
    "end": "823920"
  },
  {
    "text": "already applied we've updated the cache with this information or not um for most",
    "start": "823920",
    "end": "829399"
  },
  {
    "text": "uh databases that end up being charted like by test we also get great information like Shard IDs so that we can actually fan out and use multiple",
    "start": "829399",
    "end": "836240"
  },
  {
    "text": "devium processes to read a bunch of data data um so I've been talking mostly",
    "start": "836240",
    "end": "842720"
  },
  {
    "text": "about materialization of data into a cache but this is also a great tool for doing invalidations as well instead of",
    "start": "842720",
    "end": "849560"
  },
  {
    "text": "having to go and update the right path you can just go and listen into the database and see when your data is no longer relevant and just kick it out and",
    "start": "849560",
    "end": "856279"
  },
  {
    "text": "then lazy load it back",
    "start": "856279",
    "end": "859320"
  },
  {
    "text": "through okay so I would like to spend a few minutes and show you kind of like uh you know how this all works in practice",
    "start": "862199",
    "end": "870680"
  },
  {
    "text": "so let's hope everything works because I uh I originally had a online demo but",
    "start": "870680",
    "end": "877560"
  },
  {
    "text": "I everyone was telling me that uh the internet sucks so I am doing this all",
    "start": "877560",
    "end": "884440"
  },
  {
    "text": "offline um what do I want to show first um",
    "start": "884440",
    "end": "889560"
  },
  {
    "text": "so deum pretty straightforward everyone can see this right yeah",
    "start": "889560",
    "end": "894920"
  },
  {
    "text": "cool so we have a very simple configuration that's saying hey we we're using a syn type which is basically what",
    "start": "894920",
    "end": "900800"
  },
  {
    "text": "we're dumping data into uh we're just using renis we're dumping it all in and we have a source configuration which is",
    "start": "900800",
    "end": "907240"
  },
  {
    "text": "where we're pulling data out of in this case it's a mySQL database a very insecure",
    "start": "907240",
    "end": "913160"
  },
  {
    "text": "password um most people probably won't use deum server they'll use the normal deum which um is more natively connected",
    "start": "913160",
    "end": "920040"
  },
  {
    "text": "directly with Kafka but for this demo I just I'm going to use uh deum server itself which is like the core piece of",
    "start": "920040",
    "end": "927600"
  },
  {
    "text": "deum so I don't have tobm running right now I just have a mySQL database and a rtic instance running uh",
    "start": "927600",
    "end": "936680"
  },
  {
    "text": "so so we have this exact same table we started earlier and I have should have R",
    "start": "936680",
    "end": "942680"
  },
  {
    "text": "here and there's basically nothing here there's the CDC location which I'll talk about in a little bit but right now",
    "start": "942680",
    "end": "947920"
  },
  {
    "text": "nothing else is going on so to start off I'm going to apply that chain stream file we just had and",
    "start": "947920",
    "end": "954920"
  },
  {
    "text": "deum is now going to kick up and start running and the other thing I need to do",
    "start": "954920",
    "end": "960000"
  },
  {
    "text": "is actually start pulling the data so This Is Us consuming it doesn't matter",
    "start": "960000",
    "end": "965120"
  },
  {
    "text": "what you can you don't need to read all this it's a lot of information but this is the you know we're pulling these streams and doing something with it so",
    "start": "965120",
    "end": "971880"
  },
  {
    "text": "we had that uh stream we're looking at and now we can see we actually have data so this data was all pulled from the",
    "start": "971880",
    "end": "977160"
  },
  {
    "text": "back end and put into our database",
    "start": "977160",
    "end": "982240"
  },
  {
    "text": "and I always get the casing wrong I get this command wrong so we can see we can",
    "start": "982240",
    "end": "987600"
  },
  {
    "text": "basically do the command do is like hey what are the top products that we've ordered but this isn't super interesting",
    "start": "987600",
    "end": "993319"
  },
  {
    "text": "let's actually put some load on this so now not only are we",
    "start": "993319",
    "end": "998720"
  },
  {
    "text": "materializing we're also generating random data and just kind of filling this up so we're now like throwing",
    "start": "998720",
    "end": "1003920"
  },
  {
    "text": "random data at this and we can go and validate that this is actually staying in sync let's",
    "start": "1003920",
    "end": "1011279"
  },
  {
    "text": "go grab some random product ID and go and validate that this does",
    "start": "1011279",
    "end": "1017279"
  },
  {
    "text": "actually work oh because this is in rdus that doesn't",
    "start": "1017279",
    "end": "1022800"
  },
  {
    "text": "make sense this is where I want to put this so we have four items and we can do",
    "start": "1022800",
    "end": "1031000"
  },
  {
    "text": "this I promise this works um so that's because you know there's",
    "start": "1031160",
    "end": "1036880"
  },
  {
    "text": "records ongoing I got a little bit unlucky and one other great property about this is if we want uh I'm going to",
    "start": "1036880",
    "end": "1043720"
  },
  {
    "text": "throw Mar up on here so this is basically everything that's running on res of the time you can all these",
    "start": "1043720",
    "end": "1048760"
  },
  {
    "text": "commands we were talking about",
    "start": "1048760",
    "end": "1054360"
  },
  {
    "text": "and where's",
    "start": "1054360",
    "end": "1057720"
  },
  {
    "text": "R if we go and just delete",
    "start": "1059440",
    "end": "1064159"
  },
  {
    "text": "everything it will go and start refilling everything that happened a little bit faster than I was hoping um",
    "start": "1067400",
    "end": "1073240"
  },
  {
    "text": "but I deleted everything and we can show that eventually it all gets repopulated because it was able to go back to the beginning of the Stream and re resume",
    "start": "1073240",
    "end": "1080159"
  },
  {
    "text": "everything um so there's a lot of glue code in this file but there's really not that much actual code that we need to",
    "start": "1080159",
    "end": "1085520"
  },
  {
    "text": "write so in this case we talked a little bit how we're generating these CDC events and all we're doing is going and",
    "start": "1085520",
    "end": "1091679"
  },
  {
    "text": "uh parsing these messages that were generated we're checking to see the operation that it was um in this case we",
    "start": "1091679",
    "end": "1097039"
  },
  {
    "text": "talked about C being the create event um my SQL specifically also has an R event which is a read event which is from a",
    "start": "1097039",
    "end": "1104480"
  },
  {
    "text": "snapshot and so this is hey when we're loading it back from a snapshot this is because the way deum works is it",
    "start": "1104480",
    "end": "1110400"
  },
  {
    "text": "goes and takes a full snapshot of the data set and then starts listening to ongoing changes so you can turn this on on a running database uh or you know set",
    "start": "1110400",
    "end": "1118280"
  },
  {
    "text": "it up before you start the database and it will work the same this also means that if you somehow get a corruption inside your database and like your cache",
    "start": "1118280",
    "end": "1125240"
  },
  {
    "text": "becomes incoherent you're able to basically restart the bzm it'll take a new snapshot and catch all the way back",
    "start": "1125240",
    "end": "1132440"
  },
  {
    "text": "up and so here's like kind of all the important code I a little bit smaller",
    "start": "1132440",
    "end": "1137600"
  },
  {
    "text": "which is that hey when we got a new record for the first time we'll call sad on it which is set ad and we'll put it",
    "start": "1137600",
    "end": "1142880"
  },
  {
    "text": "in and if we uh have duplicate records they'll be kind of handled",
    "start": "1142880",
    "end": "1147919"
  },
  {
    "text": "gracefully and then the Z incr by case is when we're incr incre incrementing the sorted Set uh score by one I",
    "start": "1147919",
    "end": "1155919"
  },
  {
    "text": "mentioned a little bit about transaction IDs so you can also do that with Lis scripts you can basically every time you update it you can pass in hey this is",
    "start": "1155919",
    "end": "1162720"
  },
  {
    "text": "the transaction ID I expect you to see is it the one you have if it is update the transaction ID",
    "start": "1162720",
    "end": "1170240"
  },
  {
    "text": "cool so back to the",
    "start": "1170559",
    "end": "1175279"
  },
  {
    "text": "slides oh no that's fine",
    "start": "1177080",
    "end": "1183120"
  },
  {
    "text": "okay so I it's worth saying now that this is sort of like a generic mechanism you can use like you don't have to be",
    "start": "1183120",
    "end": "1189320"
  },
  {
    "text": "consuming from the database stream you could also uh put this as a as a right ahead before the database as well which",
    "start": "1189320",
    "end": "1195360"
  },
  {
    "text": "is a common pattern to sort of like allow you to batch rights into your backend database while still making sure",
    "start": "1195360",
    "end": "1200600"
  },
  {
    "text": "that the data has been durably stored but the benefit of this is you do",
    "start": "1200600",
    "end": "1205760"
  },
  {
    "text": "have those decoupled reads and wrs and so the applications can more or less uh iterate independently and you have a",
    "start": "1205760",
    "end": "1211120"
  },
  {
    "text": "great way to scale the back end because then all you really need working worry about is how do you scale deum so that",
    "start": "1211120",
    "end": "1216440"
  },
  {
    "text": "it's pulling datas uniformly across a bunch of database instances another common use case we've",
    "start": "1216440",
    "end": "1222520"
  },
  {
    "text": "been seeing a lot is a lot of people are starting to invest more in data analytics because gen I hear it's a",
    "start": "1222520",
    "end": "1227640"
  },
  {
    "text": "thing needs lots of data so people are using that to sort of push all of their data um out of their database into",
    "start": "1227640",
    "end": "1235039"
  },
  {
    "text": "analytic warehouses other places so that they can do machine learning so the other great thing about",
    "start": "1235039",
    "end": "1242720"
  },
  {
    "text": "doing this strategy with redis is that it works well with how res does high availability so there's kind of two main",
    "start": "1242720",
    "end": "1249159"
  },
  {
    "text": "ways to do high availability with caching the first is you do M multiwriter so when you have a write you",
    "start": "1249159",
    "end": "1255039"
  },
  {
    "text": "you say you have like three backend nodes for caching you write to all three and you basically respond back when like",
    "start": "1255039",
    "end": "1260600"
  },
  {
    "text": "two have Ren successfully this means that there's often very subtle uh incoherencies",
    "start": "1260600",
    "end": "1265840"
  },
  {
    "text": "between individual nodes in the cache whereas res takes a different approach whereas you only write to the",
    "start": "1265840",
    "end": "1272320"
  },
  {
    "text": "primary and the primary directly replicates Verbatim what it has to the replica this means that that's the CDC",
    "start": "1272320",
    "end": "1278360"
  },
  {
    "text": "location that I kind of briefly talked about earlier you're able to store where the cache is in the cgc Stream that's",
    "start": "1278360",
    "end": "1284240"
  },
  {
    "text": "being produced by cesium so that when a replica uh when the primary fails and",
    "start": "1284240",
    "end": "1289559"
  },
  {
    "text": "replica takes over it knows where it is in the Stream and can resume from that point",
    "start": "1289559",
    "end": "1295278"
  },
  {
    "text": "on cool so this isn't the Panacea as I said at the beginning there's always",
    "start": "1297440",
    "end": "1302880"
  },
  {
    "text": "trade-offs to everything we're building the main downside is even though deum has really matured as a as a open source",
    "start": "1302880",
    "end": "1308320"
  },
  {
    "text": "project in the last couple of years there's still a lot of assembly required to kind of hook everything up and then",
    "start": "1308320",
    "end": "1313760"
  },
  {
    "text": "make sure everything's working as expected I sort of glossed over some details with vest we have to handle like",
    "start": "1313760",
    "end": "1319720"
  },
  {
    "text": "Shard movements we have to handle transactions if you send multiple stuff",
    "start": "1319720",
    "end": "1325039"
  },
  {
    "text": "sorry multiple different updates together in a transaction you sort of handle those as a",
    "start": "1325039",
    "end": "1330120"
  },
  {
    "text": "block so there's a lot of little stuff you can still kind of get wrong um and still requires quite a bit of you know",
    "start": "1330120",
    "end": "1336440"
  },
  {
    "text": "tribal knowledge to begin getting right but if you kind of build up that expertise you can sort of apply it uh generically across a bunch of different",
    "start": "1336440",
    "end": "1343760"
  },
  {
    "text": "applications the other downside is if you still have a very right heavy application you're going to generate a lot of unnecessary data and do a lot of",
    "start": "1343760",
    "end": "1350919"
  },
  {
    "text": "cash updates for no reason the other big issue we've often seen is you know you don't use you",
    "start": "1350919",
    "end": "1358159"
  },
  {
    "text": "usually have a very small set of data which is your working set in caching so if you have like 200 gigabytes maybe",
    "start": "1358159",
    "end": "1364080"
  },
  {
    "text": "someone's only operating on 10 gigabytes there's no real good way to like shrink this data set down and only care about",
    "start": "1364080",
    "end": "1369840"
  },
  {
    "text": "what's hot because everything is based on the previous updates it's hard to know you know what's the hot uh 10% of",
    "start": "1369840",
    "end": "1376840"
  },
  {
    "text": "data without really like having deep understanding of your data and sort of proactively working on",
    "start": "1376840",
    "end": "1382679"
  },
  {
    "text": "it uh another downside we hear a lot is people often say like oh it would be really nice if I could replicate a view",
    "start": "1382679",
    "end": "1388440"
  },
  {
    "text": "of my database which is say hey like I want to create a virtual View and replicate that but deum only operates on",
    "start": "1388440",
    "end": "1395240"
  },
  {
    "text": "real updates so there's no good way to do that without also materializing like uh another read replica somewhere which",
    "start": "1395240",
    "end": "1402440"
  },
  {
    "text": "there's ways to do that it's just not fully flushed out at the moment the other main down we've seen is",
    "start": "1402440",
    "end": "1408520"
  },
  {
    "text": "that when you do have data failures and you need to like restart the stream you can't lazy load stuff in so you kind of",
    "start": "1408520",
    "end": "1414000"
  },
  {
    "text": "tend to take a major outage while restoring data so that's sort of the end of the um",
    "start": "1414000",
    "end": "1423760"
  },
  {
    "text": "Advanced use case section and now I want to talk a little bit about the best practices that I've seen uh people employ as uh as I've worked with folks",
    "start": "1423760",
    "end": "1432600"
  },
  {
    "text": "that are using redus specifically in Cloud native environments so we see a lot of people",
    "start": "1432600",
    "end": "1439440"
  },
  {
    "text": "running managed reddis I am from AWS I do work on the managed Redd service but",
    "start": "1439440",
    "end": "1445080"
  },
  {
    "text": "um Redd still works pretty well uh in kubernetes deployments and it's fairly Cloud native the best way to run redus",
    "start": "1445080",
    "end": "1451559"
  },
  {
    "text": "in the um in like a kubernetes cluster is with cluster mode a big gap we used to hear a lot was",
    "start": "1451559",
    "end": "1457679"
  },
  {
    "text": "with the dynamic IPS of PODS uh cluster mode would get kind of confused and IPS would be assigned to multiple nodes but",
    "start": "1457679",
    "end": "1464200"
  },
  {
    "text": "that's mostly been fixed with Reds 7 so if that detergent in the past it's working a lot better now and we are",
    "start": "1464200",
    "end": "1470799"
  },
  {
    "text": "still and we being the community working to try to make um res cluster better uh",
    "start": "1470799",
    "end": "1476279"
  },
  {
    "text": "with this new initiative we're calling cluster V2 which should make it a lot easier to scale in and out uh adding new shards",
    "start": "1476279",
    "end": "1483960"
  },
  {
    "text": "removing charts Etc so the next thing I want to talk",
    "start": "1483960",
    "end": "1490559"
  },
  {
    "text": "about is sort of monitoring so you know as this theme of",
    "start": "1490559",
    "end": "1495760"
  },
  {
    "text": "hey make sure you're doing caching right it's very important to monitor Cash's behavior um because if you start having",
    "start": "1495760",
    "end": "1501720"
  },
  {
    "text": "problems they tend to escalate very quickly um it doesn't res does not have built-in support for integration with",
    "start": "1501720",
    "end": "1508000"
  },
  {
    "text": "Telemetry or metrics but it does there's a lot of other open source projects that allow you to um kind of bridge that crap",
    "start": "1508000",
    "end": "1516399"
  },
  {
    "text": "um the main one I recommend is using res exporter for Prometheus you can configure the exporter to provide the",
    "start": "1516399",
    "end": "1522799"
  },
  {
    "text": "data from R info um in a format that Prometheus likes and you can adjust it all this is a graphon dashboard that I",
    "start": "1522799",
    "end": "1530120"
  },
  {
    "text": "was showing last year um to several Folks at Cube cone I assume everyone here is fairly",
    "start": "1530120",
    "end": "1536480"
  },
  {
    "text": "well versed and how to measure cash performance but the big thing you want to be watching for is Cash hit rate",
    "start": "1536480",
    "end": "1542240"
  },
  {
    "text": "which is easy to do and usage the next thing I want to talk a little about is a lot of people ask me",
    "start": "1542240",
    "end": "1548480"
  },
  {
    "text": "why can't they measure latency here so re recently added support to measure like what's the end dead lency time",
    "start": "1548480",
    "end": "1554120"
  },
  {
    "text": "within a given command with like p50 P99 and I want to talk a little bit about that so this is a graph of what Red's",
    "start": "1554120",
    "end": "1562919"
  },
  {
    "text": "response latency looks like from the client side at different throughputs um you really can't quite see at the bottom",
    "start": "1562919",
    "end": "1568600"
  },
  {
    "text": "but the bottom is a scale of basically zero requests per second to um 160,000",
    "start": "1568600",
    "end": "1574320"
  },
  {
    "text": "is requests per second and the vertical axis is the latency time you can kind of",
    "start": "1574320",
    "end": "1579640"
  },
  {
    "text": "see that the latency stays pretty flat so the bottom line is the the p50 and average the maroonish color and it stays",
    "start": "1579640",
    "end": "1586559"
  },
  {
    "text": "pretty flat until it gets to about 160 requests per second and then sort of vertically shoots up it doesn't stop at",
    "start": "1586559",
    "end": "1592240"
  },
  {
    "text": "that line it just we can't measure it anymore because we're like the ly jumps to",
    "start": "1592240",
    "end": "1597640"
  },
  {
    "text": "infinity and this is because ly and high performance systems um grows to the",
    "start": "1597640",
    "end": "1603440"
  },
  {
    "text": "square of the number of commands that get queued up so redus tends to start seeing latency increases around 95% of",
    "start": "1603440",
    "end": "1610039"
  },
  {
    "text": "Max throughput and then scales basically with a square as you approach um that",
    "start": "1610039",
    "end": "1617279"
  },
  {
    "text": "the 100% limit so you really have no room to scale for latency spikes which is just to say you really need to",
    "start": "1617279",
    "end": "1623679"
  },
  {
    "text": "understand the limits of your system because if you're waiting for latency to spike you're kind of already too late to respond to the",
    "start": "1623679",
    "end": "1630559"
  },
  {
    "text": "crisis and this is because um R is what uh caching and distributed caching in general including rest are what called",
    "start": "1630559",
    "end": "1637320"
  },
  {
    "text": "what what are called metastable systems um there's a bunch of good writing on this Mark Brooker who's also an engineer",
    "start": "1637320",
    "end": "1644000"
  },
  {
    "text": "at ads has written well about this which is this idea that um",
    "start": "1644000",
    "end": "1649520"
  },
  {
    "text": "caches tend to be stable until they aren't so as your this graph just shows like kind of a high level of good put is",
    "start": "1649600",
    "end": "1656240"
  },
  {
    "text": "the number of successful cash hits but once you kind of exceed an offered load which is the number of requests you're",
    "start": "1656240",
    "end": "1661279"
  },
  {
    "text": "sending the system the number of successful request drops off and once it gets to this dropped off State it often",
    "start": "1661279",
    "end": "1667320"
  },
  {
    "text": "can't get back to the good State once you start seeing errors in your cash you'll often start doing retrives or",
    "start": "1667320",
    "end": "1674440"
  },
  {
    "text": "you'll start Hing a Cold Cash I haven't talked much about ad ads",
    "start": "1674440",
    "end": "1679600"
  },
  {
    "text": "this talk but one thing ads does really well is po post-mortems of issues um a",
    "start": "1679600",
    "end": "1684960"
  },
  {
    "text": "couple years ago there was a major Kinesis event and this was purely because of cold caches right so Kinesis",
    "start": "1684960",
    "end": "1691039"
  },
  {
    "text": "was expecting like when it got a new piece of information it would put it to the cach and then put it in a queue and then once it got to the am of the queue",
    "start": "1691039",
    "end": "1697279"
  },
  {
    "text": "it would go back and check the cash but if the cash became cold you would put something in the cache put",
    "start": "1697279",
    "end": "1703399"
  },
  {
    "text": "something in the queue it would get processed a while later and when it got processed the the cach would be cold and",
    "start": "1703399",
    "end": "1708840"
  },
  {
    "text": "you would not be able to process it quickly and so Kines just kind of kept getting further and further",
    "start": "1708840",
    "end": "1714760"
  },
  {
    "text": "behind which is all a very long verbose way of me saying you should really be",
    "start": "1714760",
    "end": "1720519"
  },
  {
    "text": "testing your failure modes of your caches um there's a couple of recommendations we normally give to our",
    "start": "1720519",
    "end": "1727519"
  },
  {
    "text": "uh customers at ABS as well as open source users make sure you're testing individual node",
    "start": "1727519",
    "end": "1733200"
  },
  {
    "text": "failures this is very easy in kubernetes just kill pods randomly make sure everything still good and stable you",
    "start": "1733200",
    "end": "1739399"
  },
  {
    "text": "should also be testing High load scenarios what a lot of people are doing is just testing um like failures but you",
    "start": "1739399",
    "end": "1746000"
  },
  {
    "text": "know that case where we have hide lency is also a big problem um there's an open source project or an open source",
    "start": "1746000",
    "end": "1752720"
  },
  {
    "text": "module the plugin for R is called Rus fault injection which allows you to artificially increase",
    "start": "1752720",
    "end": "1759600"
  },
  {
    "text": "latency uh the other big thing that I would strongly recommend is try to avoid multi- node dependencies because they",
    "start": "1759600",
    "end": "1766440"
  },
  {
    "text": "can exasperate failures so we've seen a lot of this with like Feast uh and other types of um",
    "start": "1766440",
    "end": "1773000"
  },
  {
    "text": "feature storage which people use they have an offline primary store and then online cache of features and the way it",
    "start": "1773000",
    "end": "1778880"
  },
  {
    "text": "works is they sort of fan out and request a lot of data at once but the lency of that request becomes the tail",
    "start": "1778880",
    "end": "1784080"
  },
  {
    "text": "so the slowest node in the cluster becomes the the latency of the entire request so although sometimes it's",
    "start": "1784080",
    "end": "1790039"
  },
  {
    "text": "unavoidable it can cause high latency and then lastly you should be",
    "start": "1790039",
    "end": "1795080"
  },
  {
    "text": "doing um like you should be ially doing what I did in the demo which is just flushing all the data and making sure",
    "start": "1795080",
    "end": "1800399"
  },
  {
    "text": "everything comes back up you might want not want to do this on a prod cluster if anything I would tell you not to do on a",
    "start": "1800399",
    "end": "1805720"
  },
  {
    "text": "prod cluster but um you should be testing it and you should understand what happens um so",
    "start": "1805720",
    "end": "1811760"
  },
  {
    "text": "that when when something does happen you're you're prepared for it um so that's everything I had today",
    "start": "1811760",
    "end": "1818840"
  },
  {
    "text": "I'm so happy I'm almost perfectly on time um you can follow me on Twitter if he wants or what's formally known as",
    "start": "1818840",
    "end": "1825120"
  },
  {
    "text": "Twitter all all the code was posted here if you can please take some time to up",
    "start": "1825120",
    "end": "1830480"
  },
  {
    "text": "scan the QR code and give feedback it's really important for the organizers here to really understand like what you guys",
    "start": "1830480",
    "end": "1836120"
  },
  {
    "text": "want if like this was completely wrong do the feedback tell them that it's all wrong or if you want something else if",
    "start": "1836120",
    "end": "1842360"
  },
  {
    "text": "you want more gen gen talks um scan the code um so I've been",
    "start": "1842360",
    "end": "1848519"
  },
  {
    "text": "told if you have questions well you can do that now for a little bit if you do have a question you should go up and ask",
    "start": "1848519",
    "end": "1853640"
  },
  {
    "text": "it in the microphone or if you want to go to the",
    "start": "1853640",
    "end": "1859159"
  },
  {
    "text": "bar crawl you can go to that too hey uh thanks for the sharing I do",
    "start": "1859159",
    "end": "1865200"
  },
  {
    "text": "have two questions so first onat is regarding uh performance do you",
    "start": "1865200",
    "end": "1870720"
  },
  {
    "text": "recommend putting your uh the computation POD at the same Noe as the Reddit",
    "start": "1870720",
    "end": "1877399"
  },
  {
    "text": "pod H so I typically recommend not to do that cuz you can sort of get in the",
    "start": "1877399",
    "end": "1882840"
  },
  {
    "text": "situation where like if they don't if you end up scaling them independently you'll have inconsistent cash performance and you know a lot of stuff",
    "start": "1882840",
    "end": "1890039"
  },
  {
    "text": "works small at scale if you like collocate them and once like they sort of split um you start seeing weird",
    "start": "1890039",
    "end": "1896960"
  },
  {
    "text": "performance patterns so I normally Say by default don't like keep them away from each other um so that you can make",
    "start": "1896960",
    "end": "1903760"
  },
  {
    "text": "sure it still works as expected um for that like non-uniform access um but",
    "start": "1903760",
    "end": "1909279"
  },
  {
    "text": "there's plenty of people who definitely do side pods of R and they scale them together and if you're going to do that that's fine like just make sure you",
    "start": "1909279",
    "end": "1914960"
  },
  {
    "text": "don't run into situations you have that mismatch okay",
    "start": "1914960",
    "end": "1919840"
  },
  {
    "text": "thanks uh hi thanks for the talk uh I'm an SRE who has recently inherited a",
    "start": "1921720",
    "end": "1926840"
  },
  {
    "text": "whole bunch of huge redis nodes and we're we're working through a lot of tech debt to get up to date working on getting to redis 6 excited for red7",
    "start": "1926840",
    "end": "1934760"
  },
  {
    "text": "thank you for the work you've done on that um my question is one of the things that we have found with our choreographies is what one of the one of",
    "start": "1934760",
    "end": "1942240"
  },
  {
    "text": "the hardest things to deal with from coming from kind of the kubernetes world we have a control plane right M um uh",
    "start": "1942240",
    "end": "1949440"
  },
  {
    "text": "will some of the things that that are coming up with cluster V2 help with the fact that reddis is a little different you know reddis is a cluster of",
    "start": "1949440",
    "end": "1956600"
  },
  {
    "text": "peers yeah so I didn't I didn't want to spend too much time talking about that but that that is sort of the idea is we",
    "start": "1956600",
    "end": "1962000"
  },
  {
    "text": "really want to give a control plane into red cluster so you can instead of saying like so normally you have to basically",
    "start": "1962000",
    "end": "1967720"
  },
  {
    "text": "add a here like you know reard the data over set it slots and we really want to get to the point where we can say like",
    "start": "1967720",
    "end": "1973080"
  },
  {
    "text": "hey I want seven shards with like even like slot distribution and like there",
    "start": "1973080",
    "end": "1978240"
  },
  {
    "text": "will be some operations that it will in itself just be able to scale out it'll add the shards over they'll happen automatically and you don't have to go",
    "start": "1978240",
    "end": "1983960"
  },
  {
    "text": "manually do all that so that is a stated goal um I didn't link it but if you if",
    "start": "1983960",
    "end": "1989840"
  },
  {
    "text": "you reach out I can like share the issue with you if you want to add your input into that because like this is kind of what information we want or if there's",
    "start": "1989840",
    "end": "1996200"
  },
  {
    "text": "anything specifically painful you're seeing but yeah we are hoping to solve those types of problems absolutely yeah",
    "start": "1996200",
    "end": "2001240"
  },
  {
    "text": "thank you so much MH",
    "start": "2001240",
    "end": "2008960"
  },
  {
    "text": "cool well if anyone else has any questions I'll be up here I'll chill out there's there's not I think that there",
    "start": "2009840",
    "end": "2015039"
  },
  {
    "text": "might be beer in the main hall but I'll I'll be here for a little bit anyways cool and thank you all for",
    "start": "2015039",
    "end": "2021720"
  },
  {
    "text": "coming",
    "start": "2024440",
    "end": "2027440"
  }
]
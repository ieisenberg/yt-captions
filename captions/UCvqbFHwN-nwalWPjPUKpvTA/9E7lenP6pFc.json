[
  {
    "text": "all right um hi everyone thank you for joining um my name is s kelal I'm a",
    "start": "1439",
    "end": "6600"
  },
  {
    "text": "software engineer at data bricks we have worked on various key areas to scale and manage our communities platform today",
    "start": "6600",
    "end": "13719"
  },
  {
    "text": "I'm going to talk about how we build an automated way to manage the life cycle of our kuties clusters in a multicloud",
    "start": "13719",
    "end": "19400"
  },
  {
    "text": "environment and this was instrumental to uh meet the growing demand of compute that we have seen at data",
    "start": "19400",
    "end": "26599"
  },
  {
    "text": "brakes for those who are not very familiar with what data break does uh datab aims to simplify data management",
    "start": "26599",
    "end": "32960"
  },
  {
    "text": "by providing a comprehensive collaborative and scalable platform for data and AI so as you can see in all",
    "start": "32960",
    "end": "38800"
  },
  {
    "text": "these bubbles we have we have different solutions that are catered towards different personas who wants to leverage",
    "start": "38800",
    "end": "44680"
  },
  {
    "text": "data and AI capabilities uh be a data engineer data scientist machine learning engineer gen engineer or uh data uh",
    "start": "44680",
    "end": "52640"
  },
  {
    "text": "analyst uh we have one platform where they can come in and uh get lever get",
    "start": "52640",
    "end": "57800"
  },
  {
    "text": "insights from the data a lot of these products that we I",
    "start": "57800",
    "end": "63120"
  },
  {
    "text": "discussed before uh are actually powered by our serverless architecture by serverless I mean that like we manage",
    "start": "63120",
    "end": "69479"
  },
  {
    "text": "the compute for our customers so so that our customers don't have to worry or like deal with uh managing uh or setting",
    "start": "69479",
    "end": "77040"
  },
  {
    "text": "up their accounts themselves uh and they can get a very serverless experience um",
    "start": "77040",
    "end": "82240"
  },
  {
    "text": "let's like dive deep into how the servance architecture looks like so we have our database customer who wants to",
    "start": "82240",
    "end": "88439"
  },
  {
    "text": "leverage some of our product the request actually comes to our control plan service here our control",
    "start": "88439",
    "end": "95119"
  },
  {
    "text": "plan service our control plan cluster actually hosts a bunch of community services as you can see our frontend",
    "start": "95119",
    "end": "101079"
  },
  {
    "text": "facing service is the web application Service uh and then we have a couple of other services like DB SQL for our SQL",
    "start": "101079",
    "end": "108200"
  },
  {
    "text": "product Mosaic Mosaic AI for our AI uh product uh the request from the control",
    "start": "108200",
    "end": "115040"
  },
  {
    "text": "plane Service uh gets routed to our data plane data plane is uh the place where",
    "start": "115040",
    "end": "120479"
  },
  {
    "text": "we we basically schedule all our customer workloads uh who wants to run their data and AI tasks um data plane uh",
    "start": "120479",
    "end": "129000"
  },
  {
    "text": "think of data plane as like a large Fleet of pubis clusters where we host all our customer workloads so uh this all these workloads",
    "start": "129000",
    "end": "137120"
  },
  {
    "text": "uh talk to the customers account where the customers store their data in either of the three clouds S3 ADLs or gcp and",
    "start": "137120",
    "end": "145959"
  },
  {
    "text": "um uh they basically run uh and like all the task uh get the data and run the",
    "start": "145959",
    "end": "151280"
  },
  {
    "text": "task on top of that on top of the Clusters all as you can see that like",
    "start": "151280",
    "end": "156519"
  },
  {
    "text": "all our cluster our clusters are actually at the core of all databas tasks and uh over the recent past we",
    "start": "156519",
    "end": "164840"
  },
  {
    "text": "have seen tremendous growth in our serverless compute um we manage over thousand CU",
    "start": "164840",
    "end": "170400"
  },
  {
    "text": "clusters today and all the growth we have seen uh the all these clusters are created in the last three years only we",
    "start": "170400",
    "end": "177519"
  },
  {
    "text": "are present in all three clouds a Azure and gcp and we are deployed in more than",
    "start": "177519",
    "end": "184120"
  },
  {
    "text": "60 regions as of today so in order to scale our serverless compute we really need to",
    "start": "184120",
    "end": "190159"
  },
  {
    "text": "scale our cluster management so by cluster management what I mean is uh these operations the first",
    "start": "190159",
    "end": "197519"
  },
  {
    "text": "is the provisioning and deising of our commum clusters it should uh be multicloud it should be scalable and",
    "start": "197519",
    "end": "204120"
  },
  {
    "text": "reliable and the second operation that we do very commonly is upgrades where uh",
    "start": "204120",
    "end": "210120"
  },
  {
    "text": "we actually support two kind of upgrades uh the first is uh supporting cluster rotations where we bring in a new",
    "start": "210120",
    "end": "216439"
  },
  {
    "text": "cluster all together with the new configuration and then we retire the old clusters this kind of upgrades are",
    "start": "216439",
    "end": "222239"
  },
  {
    "text": "necessary when we want to do any major infrastructure changes like doing updating the network of the Clusters or",
    "start": "222239",
    "end": "228879"
  },
  {
    "text": "doing any major kubernetes version upgrades and the second kind of upgrade is in place upgrades uh where we update",
    "start": "228879",
    "end": "235360"
  },
  {
    "text": "the nodes of the Clusters as well as a cubis control plane there is a similar talk given by my colleague in the Next",
    "start": "235360",
    "end": "241799"
  },
  {
    "text": "Room uh who's going to focus more on the inl upgrades for my talk I'm mostly going to Pro focus on how we scaled",
    "start": "241799",
    "end": "249079"
  },
  {
    "text": "provisioning and deprovision of clusters and the upgrades which required cluster",
    "start": "249079",
    "end": "254239"
  },
  {
    "text": "rotations so let's try to understand what cluster provisioning exactly entails here uh so our goal is to",
    "start": "254239",
    "end": "260720"
  },
  {
    "text": "provide a ready to use clusters for our customers by ready to use I mean that like our customers do not have to our",
    "start": "260720",
    "end": "267759"
  },
  {
    "text": "customers are nothing but our product teams who who wants to like run uh the",
    "start": "267759",
    "end": "273080"
  },
  {
    "text": "run different uh uh uh different kind of tasks on top of the on top of the",
    "start": "273080",
    "end": "278360"
  },
  {
    "text": "cluster that they are creating uh so by by ready to use",
    "start": "278360",
    "end": "284039"
  },
  {
    "text": "cluster I mean that they don't uh need to worry about like provisioning lowlevel Cloud specific details or worry",
    "start": "284039",
    "end": "290000"
  },
  {
    "text": "about multicloud heterogeneity we will take care of everything and hide uh",
    "start": "290000",
    "end": "295120"
  },
  {
    "text": "everything from them and create all the resources that are necessary for them to use it so let's try to understand like",
    "start": "295120",
    "end": "301360"
  },
  {
    "text": "what are all the resources that we do in cluster provisioning so we have to create the network where the cluster is",
    "start": "301360",
    "end": "306759"
  },
  {
    "text": "going to be created like the VPC or the vet and the subnets of the cluster then we create the actual base cluster in the",
    "start": "306759",
    "end": "313479"
  },
  {
    "text": "cloud we actually use cloud manage communties for this AKs eks and gcp you are probably all familiar with this and",
    "start": "313479",
    "end": "320840"
  },
  {
    "text": "then you create the not pools on top of the cluster and then we create a couple of cloud resources like the IM roles who",
    "start": "320840",
    "end": "328400"
  },
  {
    "text": "uh were uh who basically the IM rules are created to give access to our clusters whoever wants to give get",
    "start": "328400",
    "end": "335240"
  },
  {
    "text": "access and then the event Hub and kesis stream uh to store the logs and stream the logs there are a couple of cloud",
    "start": "335240",
    "end": "342120"
  },
  {
    "text": "resources that we create which I have not mentioned here um uh and then we also do a couple of",
    "start": "342120",
    "end": "347759"
  },
  {
    "text": "infra setup um like uh setting up the monitoring logging rback uh creating",
    "start": "347759",
    "end": "354680"
  },
  {
    "text": "kubernetes Secrets uh that are commonly used by all the workloads that are r on",
    "start": "354680",
    "end": "359720"
  },
  {
    "text": "top of the cluster and some of the essential infrastructure services like uh one of the commonly used",
    "start": "359720",
    "end": "365400"
  },
  {
    "text": "infrastructure services like the SE manager which basically manages and issues TLS certificates uh that that for",
    "start": "365400",
    "end": "373440"
  },
  {
    "text": "anyone who wants to create the TLs certificates and then there is like Ingress proxy which manages the Ingress",
    "start": "373440",
    "end": "379199"
  },
  {
    "text": "traffic that is coming into the cluster so yeah there are couple of other infrastru services which I'm not",
    "start": "379199",
    "end": "384680"
  },
  {
    "text": "mentioned here uh um but yeah this is like these are all the things that we need to provision uh to make the cluster",
    "start": "384680",
    "end": "390880"
  },
  {
    "text": "ready to use so we had a framework before but uh",
    "start": "390880",
    "end": "397560"
  },
  {
    "text": "we ran into a lot of challenges using that framework what it was was like a",
    "start": "397560",
    "end": "402759"
  },
  {
    "text": "single python script with many many steps into it and they were stitched together as a spica",
    "start": "402759",
    "end": "407800"
  },
  {
    "text": "pipeline um so what the problems we had with this is that it required manual retries if anything goes wrong in any of",
    "start": "407800",
    "end": "413720"
  },
  {
    "text": "the steps in the middle and sometimes those manual recruit R are very expensive because the steps are not buil",
    "start": "413720",
    "end": "420879"
  },
  {
    "text": "with item potency in mind we also did not have very good monitoring coverage as this was like an",
    "start": "420879",
    "end": "427120"
  },
  {
    "text": "offline pipeline running uh we exposed a lot of lowlevel cloud specific",
    "start": "427120",
    "end": "433680"
  },
  {
    "text": "details and uh the way we did configuration management was not ideal we basically had one configuration file",
    "start": "433680",
    "end": "440479"
  },
  {
    "text": "to read and write input and output and we merged this configuration file into a",
    "start": "440479",
    "end": "446000"
  },
  {
    "text": "code repo so for any service who wants to discover the Clusters they have to bind it in their service binary and",
    "start": "446000",
    "end": "452879"
  },
  {
    "text": "deploy their service to discover any configurations and we had a problem of leaky abstraction here as well where our",
    "start": "452879",
    "end": "460319"
  },
  {
    "text": "Engineers needed to write raw kubernetes templates or terraform or cloud formation templates uh to create",
    "start": "460319",
    "end": "466440"
  },
  {
    "text": "resources or cluster resources and it was also very hard to tell whether a terraform template and a",
    "start": "466440",
    "end": "472479"
  },
  {
    "text": "cloud formation template was representing the same resource in two different clouds so overall all these problem",
    "start": "472479",
    "end": "479720"
  },
  {
    "text": "actually caused our cluster creation and like all the cluster crud timeline to take weeks so we had to come with",
    "start": "479720",
    "end": "486800"
  },
  {
    "text": "something better we actually build a completely new cluster life cycle framework and we",
    "start": "486800",
    "end": "492960"
  },
  {
    "text": "look towards kubernetes for inspiration so the high level idea was to use kubernetes to manage clusters life",
    "start": "492960",
    "end": "500000"
  },
  {
    "text": "cycle uh basically using kubernetes operator pattern so in this what we get",
    "start": "500000",
    "end": "505080"
  },
  {
    "text": "is our declarative configuration for kubernetes clusters by modeling it as a custom resource definition and then we",
    "start": "505080",
    "end": "512279"
  },
  {
    "text": "get continuous reconciliation uh from the current state to the desired State as uh the operator pattern provides that",
    "start": "512279",
    "end": "519760"
  },
  {
    "text": "and uh the biggest Advantage here is that like we get a we get to write a single crd for managing all the",
    "start": "519760",
    "end": "525480"
  },
  {
    "text": "configuration of the cluster in all clouds so let's understand how the exact",
    "start": "525480",
    "end": "530920"
  },
  {
    "text": "end to end workflow looks like here so we have this top level database",
    "start": "530920",
    "end": "536160"
  },
  {
    "text": "kubernetes uh cluster custom resource where we represent the desired state of",
    "start": "536160",
    "end": "541240"
  },
  {
    "text": "the cluster here uh uh we have the metad of the cluster which is just the name of",
    "start": "541240",
    "end": "546480"
  },
  {
    "text": "the cluster and the spec of the cluster which represents where we want to create the cluster the cloud and the region and",
    "start": "546480",
    "end": "553160"
  },
  {
    "text": "some of the cluster configurations like the node pools that we want to create on top of the cluster some of the other things which are not represented here",
    "start": "553160",
    "end": "559240"
  },
  {
    "text": "are like uh Network Etc and then this C is actually get",
    "start": "559240",
    "end": "564399"
  },
  {
    "text": "applied to our management cluster so think of management cluster is another kubernetes cluster which manages all the",
    "start": "564399",
    "end": "571320"
  },
  {
    "text": "other kubernetes clusters life cycle so it basically deploys a couple of",
    "start": "571320",
    "end": "577200"
  },
  {
    "text": "kubernetes operators which are collectively known as kubernetes as a service which interacts with our cloud",
    "start": "577200",
    "end": "582720"
  },
  {
    "text": "provider apis uh like AKs eks and GK to cre the Clusters created deleted and",
    "start": "582720",
    "end": "589640"
  },
  {
    "text": "updated and once that happens uh we update uh the status into the custom",
    "start": "589640",
    "end": "596079"
  },
  {
    "text": "resource object so in this case you can see the status uh present some of the runtime state of the cluster like the",
    "start": "596079",
    "end": "601920"
  },
  {
    "text": "cube API URL uh the cube version that we are using uh the vet uh the network that",
    "start": "601920",
    "end": "607800"
  },
  {
    "text": "the cluster is using subnets the node pool statuses Etc so let's dive deep into and zoom",
    "start": "607800",
    "end": "615920"
  },
  {
    "text": "into what the kubernetes service looks like exactly for our end user so any",
    "start": "615920",
    "end": "623360"
  },
  {
    "text": "databas engineer who wants to create a kubernetes cluster uh they would come uh",
    "start": "623360",
    "end": "628720"
  },
  {
    "text": "interact with with a cicd job which only exposes only some of the user facing",
    "start": "628720",
    "end": "634320"
  },
  {
    "text": "Fields like where do they want to create the cluster and what kind of clusters they want and the cicd job basically",
    "start": "634320",
    "end": "640279"
  },
  {
    "text": "creates uh the top level uh database cluster custom resource object which basically have uh the desired spec like",
    "start": "640279",
    "end": "648160"
  },
  {
    "text": "the node pools that we want to create uh the network that we want to use for the cluster Etc and this gets applied to our",
    "start": "648160",
    "end": "655399"
  },
  {
    "text": "management cluster as you can see the management cluster is running a couple of is operators or controllers like I'm",
    "start": "655399",
    "end": "661920"
  },
  {
    "text": "going to use this synonymously but like controllers and operators are meaning the same so our top level com controller",
    "start": "661920",
    "end": "669120"
  },
  {
    "text": "is the cast controller which basically uh orchestrates the life cycle of the",
    "start": "669120",
    "end": "674760"
  },
  {
    "text": "cluster um it does that by creating custom resources for all the other",
    "start": "674760",
    "end": "680120"
  },
  {
    "text": "controllers which execute different parts of the provisioning um and uh it re it",
    "start": "680120",
    "end": "687160"
  },
  {
    "text": "basically monitors the status of those Uh custom resources and reads that and updates its own status so the first one",
    "start": "687160",
    "end": "694880"
  },
  {
    "text": "it interacts with on the right is the cluster API controller so cluster API controller under the hood is adopted",
    "start": "694880",
    "end": "701079"
  },
  {
    "text": "from an open source project cluster API which is created by the kubernetes group",
    "start": "701079",
    "end": "706639"
  },
  {
    "text": "and uh what it provides US is an abstract interface for how to automate managing cluster life cycle using kuber",
    "start": "706639",
    "end": "712639"
  },
  {
    "text": "style patterns and apis and it also ensures that like we get a consistent and repeatable cluster",
    "start": "712639",
    "end": "719360"
  },
  {
    "text": "deployments across a wide variety of infrastructure environments so cluster API controller is essentially doing the",
    "start": "719360",
    "end": "726839"
  },
  {
    "text": "orchestration work here uh it requires an infrastructure provider to implement the provisioning of underlying resources",
    "start": "726839",
    "end": "733399"
  },
  {
    "text": "and all the infrastructure providers are the bottom three controllers here uh which is the cap Z for the Azure",
    "start": "733399",
    "end": "741000"
  },
  {
    "text": "controller which interacts with Azure Cloud Cap a which interacts with AWS and",
    "start": "741000",
    "end": "746040"
  },
  {
    "text": "capg which interacts with gcp and uh it these are the controllers which actually takes care of doing the crud of the",
    "start": "746040",
    "end": "753199"
  },
  {
    "text": "resources in the cloud so as you can see that like end to end our customer exper our database Engineers experience is",
    "start": "753199",
    "end": "760120"
  },
  {
    "text": "just that they have to Define some of the input fields and everything is taken care of them uh in a cloud agnostic",
    "start": "760120",
    "end": "767600"
  },
  {
    "text": "way so let's try to evaluate what improvements we have made with this",
    "start": "767600",
    "end": "772720"
  },
  {
    "text": "solution so here uh I'm going to represent uh the old python script run in in red and and cuberes as a service",
    "start": "772720",
    "end": "780360"
  },
  {
    "text": "operator in blue so earlier we required uh manual",
    "start": "780360",
    "end": "785480"
  },
  {
    "text": "retries with this we basically build it with continuous reconciliation towards desired State as kubernetes operators",
    "start": "785480",
    "end": "791959"
  },
  {
    "text": "provide us eared item potency now we our operations invoked by the controller is",
    "start": "791959",
    "end": "798920"
  },
  {
    "text": "actually item poent uh as they are uh they are basically needed to be importent uh because they need to run",
    "start": "798920",
    "end": "807120"
  },
  {
    "text": "continuously we had incomplete monitor ing before but uh with this service running as an online service we were",
    "start": "807120",
    "end": "812800"
  },
  {
    "text": "able to enable Rich monitoring and uh logging",
    "start": "812800",
    "end": "817880"
  },
  {
    "text": "capabilities earlier we exposed lowle Cloud specific details but uh with this",
    "start": "817880",
    "end": "823040"
  },
  {
    "text": "we abstracted out majority of the cloud specific details by offering a consistent interface across all",
    "start": "823040",
    "end": "830639"
  },
  {
    "text": "environments so yes we improved a lot of things but uh have we solved all the",
    "start": "830839",
    "end": "836000"
  },
  {
    "text": "problems here um let's try to see how our and cluster",
    "start": "836000",
    "end": "841800"
  },
  {
    "text": "provision priv looks like now so it still has a couple of steps which are stretch together as spica pipeline we",
    "start": "841800",
    "end": "848480"
  },
  {
    "text": "did resolve uh the base kubernetes cluster provisioning and all the details of that very well like the uh CL class",
    "start": "848480",
    "end": "855560"
  },
  {
    "text": "cluster is taking care of that but there are things which happens before the provisioning and after the provisioning",
    "start": "855560",
    "end": "860839"
  },
  {
    "text": "which are running into the same problem like we need to get the network to create the cluster and then after the",
    "start": "860839",
    "end": "866160"
  },
  {
    "text": "cluster is created we need to configure the cluster deploy in services on top of them and publish the cluster so that our",
    "start": "866160",
    "end": "872639"
  },
  {
    "text": "control plane Services can discover the cluster and run customer workloads there so it has the same problems of uh uh not",
    "start": "872639",
    "end": "879959"
  },
  {
    "text": "being reliable which are all the steps which are before and after the cluster provisioning it had the problem of",
    "start": "879959",
    "end": "886360"
  },
  {
    "text": "scalability it was hard to create multiple clusters across different clouds and regions at one go what our",
    "start": "886360",
    "end": "892720"
  },
  {
    "text": "Engineers needed to do was to run multiple runs of this uh Pipeline and uh it used to take uh a lot of time to do",
    "start": "892720",
    "end": "899959"
  },
  {
    "text": "that and the upgrades that require cluster rotations where we bring up a whole set of clusters and retire old",
    "start": "899959",
    "end": "905839"
  },
  {
    "text": "clusters it required us to run um multiple runs of the pipeline to create new clusters and then delete all the",
    "start": "905839",
    "end": "913560"
  },
  {
    "text": "Clusters the end to end latency we did not solve uh from the first uh framework",
    "start": "913560",
    "end": "919680"
  },
  {
    "text": "uh it was still very high because of the way we managed uh the configurations of the Clusters the configurations of the",
    "start": "919680",
    "end": "926120"
  },
  {
    "text": "Clusters were still merged into a codee repo and uh it was uh basically anyone",
    "start": "926120",
    "end": "932040"
  },
  {
    "text": "who wants to discover the Clusters and use those clusters they had to go with uh their service deployment to get this",
    "start": "932040",
    "end": "939240"
  },
  {
    "text": "configurations into their service binary to discover that and sometimes it could take a week depending upon the frequency",
    "start": "939240",
    "end": "945560"
  },
  {
    "text": "on which the service deployments used to happen so how do you how do you solve",
    "start": "945560",
    "end": "952199"
  },
  {
    "text": "these problems we basically came up with a another level of abstraction on top of",
    "start": "952199",
    "end": "959279"
  },
  {
    "text": "our C abstraction what we created is like a cluster set life cycle manager service",
    "start": "959279",
    "end": "966199"
  },
  {
    "text": "which manages our clusters in the unit of cluster set here we basically have",
    "start": "966199",
    "end": "972240"
  },
  {
    "text": "all clusters in the set with have which has that have the same configurations and uh what CSM does uh",
    "start": "972240",
    "end": "980519"
  },
  {
    "text": "the this life cycle meure does is that like it basically orchestrates and cares out all the steps that are present in",
    "start": "980519",
    "end": "985880"
  },
  {
    "text": "the Spiner pipeline in a much more efficient and reliable way and this is deployed as kubernetes",
    "start": "985880",
    "end": "992639"
  },
  {
    "text": "operator as well so let's try to see how this",
    "start": "992639",
    "end": "998160"
  },
  {
    "text": "interface exactly looks like so the cluster Set uh this is",
    "start": "998160",
    "end": "1004360"
  },
  {
    "text": "basically representation of the desired spec for the cluster set here we basically in the metadata we specify",
    "start": "1004360",
    "end": "1010440"
  },
  {
    "text": "what where we want to create the Clusters in the Set uh the location can",
    "start": "1010440",
    "end": "1015480"
  },
  {
    "text": "have the environment the cloud and the region where you want to create the cluster and then we have what kind of",
    "start": "1015480",
    "end": "1020639"
  },
  {
    "text": "cluster we want to create in this case we are creating model serving cluster uh the type of cluster determines what kind",
    "start": "1020639",
    "end": "1027160"
  },
  {
    "text": "of resources and notps that are going to be provisioned for that cluster and then we have the spec of the",
    "start": "1027160",
    "end": "1033918"
  },
  {
    "text": "cluster which basically has the number of has a count field which represents",
    "start": "1033919",
    "end": "1039079"
  },
  {
    "text": "how many clusters we want to create in the set what kind of features should have should be present for this cluster",
    "start": "1039079",
    "end": "1044480"
  },
  {
    "text": "set like one example is private connectivity so by private connectivity I mean is that like uh we want to have",
    "start": "1044480",
    "end": "1052200"
  },
  {
    "text": "the Ingress and the egress traffic from the cluster to be completely going through our private network instead of",
    "start": "1052200",
    "end": "1057720"
  },
  {
    "text": "our public network and this will in order to enable this feature it will require provisioning some Resource as",
    "start": "1057720",
    "end": "1064120"
  },
  {
    "text": "well and then now we create the node pools for the cluster we have all the infra Services represented here and the",
    "start": "1064120",
    "end": "1071960"
  },
  {
    "text": "upgrade strategy so upgrade strategy here essentially I'm going to talk more about the upgrade strategy in some later",
    "start": "1071960",
    "end": "1078240"
  },
  {
    "text": "slides but basically this determines how to upgrade the Clusters and then um in the status once",
    "start": "1078240",
    "end": "1086480"
  },
  {
    "text": "the Clusters are clusters in the set are created uh the Clusters status is captured in the status field uh where we",
    "start": "1086480",
    "end": "1093400"
  },
  {
    "text": "have all the Clusters in represented by their name and for each of the cluster",
    "start": "1093400",
    "end": "1098840"
  },
  {
    "text": "we have the metadata field and the spec field which essentially uh copied from the cluster set spec and metadata and",
    "start": "1098840",
    "end": "1106520"
  },
  {
    "text": "then uh we have the status field for each of the cluster which represents what the state kind state of the cluster is uh whether it could whether it is in",
    "start": "1106520",
    "end": "1114039"
  },
  {
    "text": "creating State Ready state or it is in deletion State and the network that is",
    "start": "1114039",
    "end": "1119159"
  },
  {
    "text": "being used by the cluster what are the infrastr infra Services status that the cluster is actually uh",
    "start": "1119159",
    "end": "1125960"
  },
  {
    "text": "deploying so let's try to understand how the how it works end to end uh how it",
    "start": "1125960",
    "end": "1132559"
  },
  {
    "text": "create and provision all the Clusters in the sent end to end so here uh as as you",
    "start": "1132559",
    "end": "1138919"
  },
  {
    "text": "can see on the top left we have our databas engineer uh interacting with the",
    "start": "1138919",
    "end": "1144120"
  },
  {
    "text": "configuration uh service so for the database engineer just needs to give",
    "start": "1144120",
    "end": "1150320"
  },
  {
    "text": "some input Fields like where do they want to create clusters how many clusters do they want to create in the",
    "start": "1150320",
    "end": "1155440"
  },
  {
    "text": "Set uh and then we manage a bunch of configurations internally which is",
    "start": "1155440",
    "end": "1160559"
  },
  {
    "text": "completely controlled by the by our compute infr team uh like uh the kind of",
    "start": "1160559",
    "end": "1166440"
  },
  {
    "text": "uh uh not pool that you want to create in the class the ver the kubernetes version that you want to create um the",
    "start": "1166440",
    "end": "1173080"
  },
  {
    "text": "kind of uh resources that needs to be created for a particular kind of cluster so all these configurations are managed",
    "start": "1173080",
    "end": "1179880"
  },
  {
    "text": "internally and these two configurations are combined through our cluster set",
    "start": "1179880",
    "end": "1185320"
  },
  {
    "text": "config generator logic and uh we basically create this top level cluster set specs which are the desired specs by",
    "start": "1185320",
    "end": "1192520"
  },
  {
    "text": "each location um and then this uh desired specs are getting applied gets applied",
    "start": "1192520",
    "end": "1200039"
  },
  {
    "text": "to our cluster set life cycle man service which basically uh host two top",
    "start": "1200039",
    "end": "1205520"
  },
  {
    "text": "level controllers uh the first one is the cluster set controller which basically manages the life cycle uh",
    "start": "1205520",
    "end": "1213240"
  },
  {
    "text": "which basically manages uh the top level operations like adding clusters to the set removing clusters from the set and",
    "start": "1213240",
    "end": "1219520"
  },
  {
    "text": "upgrading the Clusters within the set and it interacts with uh the cluster controller which is the main Orchestra",
    "start": "1219520",
    "end": "1226039"
  },
  {
    "text": "where the main orchestration logic lives which uh carries out interacting with different systems and life and",
    "start": "1226039",
    "end": "1232919"
  },
  {
    "text": "controllers to carry out the provisioning and de provisioning of the resources so as you can see here it uh",
    "start": "1232919",
    "end": "1238760"
  },
  {
    "text": "interacts with uh the cast controller which we had seen before uh it creates the custom resource for the cast",
    "start": "1238760",
    "end": "1245360"
  },
  {
    "text": "controller and the cast controller takes care of creating the best cues cluster in in the different clouds it interacts",
    "start": "1245360",
    "end": "1251919"
  },
  {
    "text": "it also interacts with different cloud provider apis to create different resources and uh it uh creates other",
    "start": "1251919",
    "end": "1259120"
  },
  {
    "text": "custom resources for other controllers that needs to create different kind of resources like for example private",
    "start": "1259120",
    "end": "1264960"
  },
  {
    "text": "connectivity networks Etc so once all this provisioning is done uh it goes and",
    "start": "1264960",
    "end": "1270919"
  },
  {
    "text": "talk to the release system to get all the important essential infrastructure services to be deployed on top of the",
    "start": "1270919",
    "end": "1277279"
  },
  {
    "text": "cluster so once we once it orchestrates and gets done with everything it updates the status and we say that the cluster",
    "start": "1277279",
    "end": "1284000"
  },
  {
    "text": "is ready to use and anyone who wants to use the cluster can make RPC calls to this life cycle manual service to get",
    "start": "1284000",
    "end": "1289919"
  },
  {
    "text": "the Clusters uh discovered so um as you can see that",
    "start": "1289919",
    "end": "1296799"
  },
  {
    "text": "like if you look at the overall picture here like for our end user they just needed to specify only a few input",
    "start": "1296799",
    "end": "1301919"
  },
  {
    "text": "fields and everything is orchestrated and automated for",
    "start": "1301919",
    "end": "1306840"
  },
  {
    "text": "them so in this case U let's try to see how the cluster Discovery happens uh so",
    "start": "1307480",
    "end": "1312840"
  },
  {
    "text": "for cluster Discovery what we did was uh that like we basically ran a background job which can publish the cluster status",
    "start": "1312840",
    "end": "1319799"
  },
  {
    "text": "by reading uh the status from the life cycle manager service and Publishing it as a config map to each of the control",
    "start": "1319799",
    "end": "1326559"
  },
  {
    "text": "plan Services who wants to discover those clusters and we did that uh by publishing it as a config map and uh we",
    "start": "1326559",
    "end": "1333400"
  },
  {
    "text": "were able to actually run this uh very frequently and uh it also did not",
    "start": "1333400",
    "end": "1338840"
  },
  {
    "text": "require us to do any service deployments all the cluster Discovery was dynamic in nature here and we achieved like uh a",
    "start": "1338840",
    "end": "1347240"
  },
  {
    "text": "discovery within an hour with this method so now that we understand how the",
    "start": "1347240",
    "end": "1355080"
  },
  {
    "text": "cluster provisioning and cluster Discovery Works let's try to Deep dive into how uh we how it helped us to do an",
    "start": "1355080",
    "end": "1362919"
  },
  {
    "text": "automated way of doing upgrades that require cluster rotations so for cluster rotation",
    "start": "1362919",
    "end": "1369480"
  },
  {
    "text": "upgrades we basically have these four major steps um the first is to create a",
    "start": "1369480",
    "end": "1374600"
  },
  {
    "text": "new batch of clusters with new configurations the second is to drain the workloads from the old clusters to",
    "start": "1374600",
    "end": "1380720"
  },
  {
    "text": "the new clusters and the third is to delete the old batch of clusters and then we repeat the steps from 1 to three",
    "start": "1380720",
    "end": "1386799"
  },
  {
    "text": "to get all the Clusters upgraded within the set so how it works is that uh for the",
    "start": "1386799",
    "end": "1393320"
  },
  {
    "text": "end databas engineer who wants to upgrade a cluster they just create a",
    "start": "1393320",
    "end": "1398840"
  },
  {
    "text": "updated spec of the cluster set here they are trying to upgrade Aus version",
    "start": "1398840",
    "end": "1404200"
  },
  {
    "text": "for the Clusters um and the upgrade strategy they are using is a cluster rotation with the max surge of",
    "start": "1404200",
    "end": "1410960"
  },
  {
    "text": "three by Max surge I mean that we will upgrade the Clusters with a Max batch size of three uh and we'll create like",
    "start": "1410960",
    "end": "1418320"
  },
  {
    "text": "three clusters at a time and upgrade them not more than that so this updated spec gets applied to the CSM the cluster",
    "start": "1418320",
    "end": "1426279"
  },
  {
    "text": "set life cycle manager service which basically orchestrates all the steps that we had seen before creates the",
    "start": "1426279",
    "end": "1432000"
  },
  {
    "text": "cluster creates three new clusters and once all the Clusters are created it publishes those clusters to our control",
    "start": "1432000",
    "end": "1438679"
  },
  {
    "text": "plane Service uh which wants to leverage those clusters and discover them to run",
    "start": "1438679",
    "end": "1443960"
  },
  {
    "text": "the our actual customers data and AI tasks so the control pin service has",
    "start": "1443960",
    "end": "1450320"
  },
  {
    "text": "both uh the knowledge of the old clusters and the new clusters it drains the workloads from the old clusters to",
    "start": "1450320",
    "end": "1458000"
  },
  {
    "text": "the new clusters and once all the trining has happened we delete uh the life cycle",
    "start": "1458000",
    "end": "1463760"
  },
  {
    "text": "service deletes the cluster delet the old clusters and this process repeats until all the upgrades has happened",
    "start": "1463760",
    "end": "1469320"
  },
  {
    "text": "within the cluster so to Deep dive into how exactly",
    "start": "1469320",
    "end": "1476880"
  },
  {
    "text": "the state machine looks like for the upgrades um as you can see like let's",
    "start": "1476880",
    "end": "1482480"
  },
  {
    "text": "try to understand that here uh so the top box is our life cycle manag service which carries out the life cycle",
    "start": "1482480",
    "end": "1488559"
  },
  {
    "text": "management of our clusters here we are representing going to represent the uh new clusters in green and the old",
    "start": "1488559",
    "end": "1495080"
  },
  {
    "text": "clusters in blue we also call this as our blue green blue green upgrade as well the bottom panel is the uh",
    "start": "1495080",
    "end": "1503480"
  },
  {
    "text": "serverless product service which actually wants to discover uh the cluster and manage the cluster to run",
    "start": "1503480",
    "end": "1509240"
  },
  {
    "text": "the customers data and AI workloads so when the Clusters are getting created uh it the the first dat",
    "start": "1509240",
    "end": "1516600"
  },
  {
    "text": "is creating when we start provisioning different resources on the cluster and when all the resources are provisioned",
    "start": "1516600",
    "end": "1522520"
  },
  {
    "text": "we say that the cluster is ready and then we start deleting the old",
    "start": "1522520",
    "end": "1527960"
  },
  {
    "text": "clusters the first state we say is that schedule we scheduled the cluster for deletion this is an indication that like",
    "start": "1527960",
    "end": "1534039"
  },
  {
    "text": "the old cluster should start deletion we publish these clusters as config map to",
    "start": "1534039",
    "end": "1540360"
  },
  {
    "text": "the control plane service who wants to discover these clusters the control plane service when they discover this",
    "start": "1540360",
    "end": "1546840"
  },
  {
    "text": "cluster they activate the new clusters and they start draining the old",
    "start": "1546840",
    "end": "1551919"
  },
  {
    "text": "clusters and once uh the drain has completely happened uh they retire the",
    "start": "1551919",
    "end": "1557919"
  },
  {
    "text": "old clusters and uh after the cluster is retired the control plane service basically sends a RPC call to uh confirm",
    "start": "1557919",
    "end": "1566080"
  },
  {
    "text": "that you can like confirm the life cycle manager that like it's okay to delete the cluster and uh on receiving on receiving",
    "start": "1566080",
    "end": "1574159"
  },
  {
    "text": "of this RPC call uh the life cycle me service changes the life cycle state of the cluster to deletion confirmed where",
    "start": "1574159",
    "end": "1581080"
  },
  {
    "text": "it actually starts uh to tear down the cluster resources and can and once the cluster",
    "start": "1581080",
    "end": "1586960"
  },
  {
    "text": "is completely deleted we say that the cluster is in a deleted State and this",
    "start": "1586960",
    "end": "1592039"
  },
  {
    "text": "basically continues for each of the Clusters in the set and this is how we automated uh the entire end to end uh",
    "start": "1592039",
    "end": "1599679"
  },
  {
    "text": "upgrade process uh without any human interaction in this place so let's try to see how this one",
    "start": "1599679",
    "end": "1607760"
  },
  {
    "text": "fars with uh uh with the previous previous challenges that we have seen",
    "start": "1607760",
    "end": "1613799"
  },
  {
    "text": "before u in terms of scalability uh it's definitely scal available now because we are able to",
    "start": "1613799",
    "end": "1619880"
  },
  {
    "text": "create multiple clusters across different regions and clouds at one go and our upgrades are completely",
    "start": "1619880",
    "end": "1625840"
  },
  {
    "text": "automated uh with our end user just needed to needing to update uh and",
    "start": "1625840",
    "end": "1631120"
  },
  {
    "text": "Supply the updated spec in terms of reliability uh yeah we are able to",
    "start": "1631120",
    "end": "1637399"
  },
  {
    "text": "achieve much better reliability as we are able to run this as a kuber style operator uh which gives us item poent",
    "start": "1637399",
    "end": "1644640"
  },
  {
    "text": "item potency and um automatic retrive is by uh from the",
    "start": "1644640",
    "end": "1650559"
  },
  {
    "text": "get-go and in terms of end to end latency uh we are able to achieve a",
    "start": "1650559",
    "end": "1655760"
  },
  {
    "text": "dynamic discovery of clusters uh which allowed us to have uh the the discovery",
    "start": "1655760",
    "end": "1661159"
  },
  {
    "text": "of clusters to be within one",
    "start": "1661159",
    "end": "1664880"
  },
  {
    "text": "hour that's all I have for today uh I'm happy to answer any questions if you have uh anything that is top of your",
    "start": "1666960",
    "end": "1673559"
  },
  {
    "text": "mind",
    "start": "1673559",
    "end": "1676559"
  },
  {
    "text": "you can ask questions yeah yeah it's it's very interesting",
    "start": "1687039",
    "end": "1693399"
  },
  {
    "text": "because like we just finished deploying something very similar down to the name",
    "start": "1693399",
    "end": "1698799"
  },
  {
    "text": "of the crds um I was wondering how you did endle like different workloads",
    "start": "1698799",
    "end": "1705320"
  },
  {
    "text": "talking to each other within the cluster so when you're tearing down down and like moving workloads you need them to",
    "start": "1705320",
    "end": "1711559"
  },
  {
    "text": "still talk to each other did you merge the meshes in ISO how did you hand all",
    "start": "1711559",
    "end": "1717200"
  },
  {
    "text": "that so you basically are you asking that like how the how the customers workloads which are running on the",
    "start": "1717200",
    "end": "1723360"
  },
  {
    "text": "cluster how did they discover that like uh where to run is that what you're",
    "start": "1723360",
    "end": "1729519"
  },
  {
    "text": "asking well uh do you have communication between Services staying within the",
    "start": "1729519",
    "end": "1735440"
  },
  {
    "text": "cluster you always go through routing EXP internally that is where like got it so",
    "start": "1735440",
    "end": "1742399"
  },
  {
    "text": "in this case I'm specifically talking about uh the data plane clusters uh where we run uh yeah we run a bunch of",
    "start": "1742399",
    "end": "1750120"
  },
  {
    "text": "uh Services demon side Services plus also a bunch of uh customer workloads who are running their data and AI tasks",
    "start": "1750120",
    "end": "1757120"
  },
  {
    "text": "so they they can just so when we uh when we bring up the new",
    "start": "1757120",
    "end": "1762399"
  },
  {
    "text": "cluster uh we basically we uh we stop",
    "start": "1762399",
    "end": "1767640"
  },
  {
    "text": "scheduling any of the new uh customer workloads or services on the new cluster",
    "start": "1767640",
    "end": "1773840"
  },
  {
    "text": "uh on on the old clusters and then we slow we basically migrate all the workloads from the old cluster to the",
    "start": "1773840",
    "end": "1779440"
  },
  {
    "text": "new cluster so the services internally did not have to communicate uh they can uh they can just",
    "start": "1779440",
    "end": "1787120"
  },
  {
    "text": "uh uh as the new services are coming in uh there's like a proxy layer which",
    "start": "1787120",
    "end": "1793080"
  },
  {
    "text": "handles the traffic routing between the old cluster and the new cluster",
    "start": "1793080",
    "end": "1798159"
  },
  {
    "text": "okay thanks yeah hey uh this is really cool also",
    "start": "1798159",
    "end": "1804159"
  },
  {
    "text": "we've been implementing something like this for the last two or three years and finally got it reliable over the last year and it's really interesting to see",
    "start": "1804159",
    "end": "1809559"
  },
  {
    "text": "how other people arrive at the same solution uh one of the big pain points for us though and I think our workload is much different is um Auto scaling and",
    "start": "1809559",
    "end": "1816360"
  },
  {
    "text": "so our old clusters are autoscaled um to handle the load that they're currently under and we would run into trouble you",
    "start": "1816360",
    "end": "1822200"
  },
  {
    "text": "know shifting in our case shifting traffic to a new cluster that was under provision um in your case are you relying strictly on the draining to get",
    "start": "1822200",
    "end": "1828440"
  },
  {
    "text": "that new cluster scaled up to whatever capacity it needs before you start tearing down the old um like are are you Auto do you have",
    "start": "1828440",
    "end": "1835679"
  },
  {
    "text": "Auto scaling enabled on the old cluster um and if so um are you just relying on the workloads being drained and migrated",
    "start": "1835679",
    "end": "1842799"
  },
  {
    "text": "to the new cluster to scale out the new cluster to the appropriate capacity so we we do have Autos scaling enabled but",
    "start": "1842799",
    "end": "1848279"
  },
  {
    "text": "uh the auto scaling is enabled on the Node level not at the cluster level uh",
    "start": "1848279",
    "end": "1853360"
  },
  {
    "text": "so by by that I mean is that like within the cluster if we want to scale if we want to",
    "start": "1853360",
    "end": "1859200"
  },
  {
    "text": "have more customer workloads we will be able to scale the nodes but uh in order",
    "start": "1859200",
    "end": "1864799"
  },
  {
    "text": "to so we are currently working on autoscaling feature on at the cluster level as well where uh if if we are",
    "start": "1864799",
    "end": "1872559"
  },
  {
    "text": "running out of capacity where uh like we have exhausted all the nodes onto a particular cluster and we want to bring",
    "start": "1872559",
    "end": "1878880"
  },
  {
    "text": "up new kubernetes clusters to host new customer workloads uh those are actually not autoscaled uh we creep a warm pool",
    "start": "1878880",
    "end": "1886240"
  },
  {
    "text": "of those clusters uh without any nodes in them and then when we want to",
    "start": "1886240",
    "end": "1891880"
  },
  {
    "text": "leverage those clusters uh we get those clusters in uh uh we basically schedule",
    "start": "1891880",
    "end": "1898320"
  },
  {
    "text": "work customer workloads on top of those clusters so that we can scale the nodes but the auto scaling is not enabled for",
    "start": "1898320",
    "end": "1906360"
  },
  {
    "text": "uh for where we scale up the Clusters automatically we someone has to some",
    "start": "1906360",
    "end": "1911880"
  },
  {
    "text": "some engineer has to manually go and like create new clusters or basically do this operation of scaling up the cluster",
    "start": "1911880",
    "end": "1918600"
  },
  {
    "text": "set by creating by increasing the count of the cluster set and that takes care of creating new clusters yeah it's",
    "start": "1918600",
    "end": "1924639"
  },
  {
    "text": "something we spend a lot of time on synchronizing scaling specs between clusters before flipping trafficing what not all right cool thank you yeah thanks",
    "start": "1924639",
    "end": "1930960"
  },
  {
    "text": "for asking uh I have one question where you are saying that uh you are creating and",
    "start": "1930960",
    "end": "1937480"
  },
  {
    "text": "managing this cluster using a concept of cluster set so that cluster set itself is a controller and it which runs on one",
    "start": "1937480",
    "end": "1944320"
  },
  {
    "text": "of the cluster I think earlier in the one of the first design you mentioned that it's called the management cluster right right so my question is that how",
    "start": "1944320",
    "end": "1952159"
  },
  {
    "text": "do you create and manage the management cluster a yes question where do you run it B and uh what happens in case there",
    "start": "1952159",
    "end": "1961159"
  },
  {
    "text": "are an issue with the management cluster itself which has the control running and how do you detect that yeah that's",
    "start": "1961159",
    "end": "1967120"
  },
  {
    "text": "that's a very good question uh so the we create the management so we don't have",
    "start": "1967120",
    "end": "1972519"
  },
  {
    "text": "the same tooling uh to create the management cluster uh it's basically a chicken and neck problem right like how",
    "start": "1972519",
    "end": "1978320"
  },
  {
    "text": "do you create the management cluster uh in an auto in an automated way so management cluster is not created in an",
    "start": "1978320",
    "end": "1984440"
  },
  {
    "text": "automated way we as it does not need to be does not need to have the same uh uh",
    "start": "1984440",
    "end": "1990880"
  },
  {
    "text": "same uh scaling and automated operations that needed to be done within the management cluster itself so it is being",
    "start": "1990880",
    "end": "1997960"
  },
  {
    "text": "brought up uh using uh a stitch together uh uh like python script like that we",
    "start": "1997960",
    "end": "2003960"
  },
  {
    "text": "had before uh and uh we basically use homr kuties to create this management",
    "start": "2003960",
    "end": "2009080"
  },
  {
    "text": "cluster um and it is uh run uh in all three different clouds in different uh",
    "start": "2009080",
    "end": "2014399"
  },
  {
    "text": "So currently our management cluster is uh is a central cluster which is run as",
    "start": "2014399",
    "end": "2019559"
  },
  {
    "text": "one cluster per Cloud but we trying to get to a place where like we can run management clusters in all the regions",
    "start": "2019559",
    "end": "2025559"
  },
  {
    "text": "so that we can get more highly available uh things uh in place uh and if",
    "start": "2025559",
    "end": "2031320"
  },
  {
    "text": "management cluster goes down it's not the end of the world uh because like um",
    "start": "2031320",
    "end": "2037240"
  },
  {
    "text": "at the end of the day what what happens is that like uh uh we uh the cluster",
    "start": "2037240",
    "end": "2043039"
  },
  {
    "text": "operations are not that high QPS operations right like uh we we do do capacity map planning and like create",
    "start": "2043039",
    "end": "2050158"
  },
  {
    "text": "one of clusters and if the management cluster is down for a few hours uh we",
    "start": "2050159",
    "end": "2055720"
  },
  {
    "text": "are just not able to create new clusters or delete new clusters uh but uh like we",
    "start": "2055720",
    "end": "2062720"
  },
  {
    "text": "have enough pool of clusters to be leveraged from if I can add uh to that question so",
    "start": "2062720",
    "end": "2070560"
  },
  {
    "text": "what kind of Technology you are using under the H for example are using goang to build this operator or cloud",
    "start": "2070560",
    "end": "2076040"
  },
  {
    "text": "formation versus terraform in order to manage the cloud resources yeah we use go level communities",
    "start": "2076040",
    "end": "2082839"
  },
  {
    "text": "operators thank you yeah a question uh how do you manage",
    "start": "2082839",
    "end": "2089000"
  },
  {
    "text": "system resources uh system add-ons like core DNS for example if you need to",
    "start": "2089000",
    "end": "2095960"
  },
  {
    "text": "change cache settings or like Q proxy configuration like enable disable metrix",
    "start": "2095960",
    "end": "2103440"
  },
  {
    "text": "yeah that's a good question uh so what do we do for that is that like so we also have a couple of other operators",
    "start": "2103440",
    "end": "2109560"
  },
  {
    "text": "running in our management cluster and uh those operators are responsible so",
    "start": "2109560",
    "end": "2114880"
  },
  {
    "text": "they're also managed by submitting custom resources for those services so",
    "start": "2114880",
    "end": "2120320"
  },
  {
    "text": "if so code DNS and some of the other services they are deployed as uh think of them getting deployed as uh",
    "start": "2120320",
    "end": "2127960"
  },
  {
    "text": "infrastructure service which has uh which is basically taken care of by our cicd pipeline we have a very robust uh",
    "start": "2127960",
    "end": "2135920"
  },
  {
    "text": "release pipeline through which we deploy and upgrade uh services and uh under the",
    "start": "2135920",
    "end": "2141920"
  },
  {
    "text": "hood some of the services are running are run as cuties operators uh where we basically create custom resources and uh",
    "start": "2141920",
    "end": "2148680"
  },
  {
    "text": "we update custom resources to manage those thank",
    "start": "2148680",
    "end": "2154280"
  },
  {
    "text": "you um just a quick question thank thanks for the talk yeah say hi yeah uh",
    "start": "2155040",
    "end": "2161079"
  },
  {
    "text": "can you talk about some of the preps and the post steps you mentioned about the network provisioning and and whatnot and",
    "start": "2161079",
    "end": "2166839"
  },
  {
    "text": "how you were able to tackle that in your new approach right",
    "start": "2166839",
    "end": "2173560"
  },
  {
    "text": "so what specifically do you want to know about the preps and post steps exactly uh yeah um like for example the",
    "start": "2173560",
    "end": "2181200"
  },
  {
    "text": "provisioning of the network um that's the pre essential step for your building up the new cluster are the new clusters",
    "start": "2181200",
    "end": "2187400"
  },
  {
    "text": "coming up on the same VPC or same network right so uh yeah so for cluster",
    "start": "2187400",
    "end": "2194720"
  },
  {
    "text": "uh we for a cluster to run we basically have to know where it should run like which particular uh network uh VPC or",
    "start": "2194720",
    "end": "2202839"
  },
  {
    "text": "subnet it should use we we have uh multiple clusters to be created in the same VPC but uh they are not never",
    "start": "2202839",
    "end": "2210119"
  },
  {
    "text": "created in the same subnets uh and we have a very complex Network architecture",
    "start": "2210119",
    "end": "2215280"
  },
  {
    "text": "uh used that we use to uh uh to create the network um and um like uh the",
    "start": "2215280",
    "end": "2223599"
  },
  {
    "text": "network is actually provisioned uh using other uh operate other controller",
    "start": "2223599",
    "end": "2228800"
  },
  {
    "text": "service which takes care of creating the network creating uh the like so some of",
    "start": "2228800",
    "end": "2234560"
  },
  {
    "text": "the network resources are pre-provisioned but some of them are actually provision at the time of cluster is getting provisioned some some",
    "start": "2234560",
    "end": "2240920"
  },
  {
    "text": "of them are like uh which requires where we can't pre-provision them as as they cost a lot of money for us like n",
    "start": "2240920",
    "end": "2246400"
  },
  {
    "text": "gateways uh eips and all those things uh so we create them uh we create them at",
    "start": "2246400",
    "end": "2253319"
  },
  {
    "text": "the time when we are provisioning the cluster from the cluster set life cycle manager service by and they it interacts",
    "start": "2253319",
    "end": "2258760"
  },
  {
    "text": "with uh the network controller service to create get those resources created",
    "start": "2258760",
    "end": "2264839"
  },
  {
    "text": "okay yeah thanks",
    "start": "2264839",
    "end": "2268359"
  },
  {
    "text": "I don't know if you can hear me there we go um one more question so I don't know when you started this but just given you",
    "start": "2277599",
    "end": "2283920"
  },
  {
    "text": "know the number of vendors are out here different people who are thinking about this problem would you do it the same way if you started it today or have you",
    "start": "2283920",
    "end": "2290960"
  },
  {
    "text": "thought about other technologies that you would potentially make use of yes that's a really good question uh",
    "start": "2290960",
    "end": "2297400"
  },
  {
    "text": "so um yeah if uh there there a couple of things we can improve on what uh we have",
    "start": "2297400",
    "end": "2304560"
  },
  {
    "text": "already built like for example the way we SP up the management cluster uh we uh",
    "start": "2304560",
    "end": "2310720"
  },
  {
    "text": "basically created a central centralized cluster for that to man uh to manage uh",
    "start": "2310720",
    "end": "2316560"
  },
  {
    "text": "it is not very highly available so if we had to redo again we will basically create uh it in a in a more Regional way",
    "start": "2316560",
    "end": "2323720"
  },
  {
    "text": "and create a better automation for doing that uh and uh we also took very",
    "start": "2323720",
    "end": "2330200"
  },
  {
    "text": "incremental step here like we first took an approach to just automate the life cycle management of the base cuber disc",
    "start": "2330200",
    "end": "2336720"
  },
  {
    "text": "clusters that interact with Cloud managed communities clusters uh and then we basically build another layer of",
    "start": "2336720",
    "end": "2342920"
  },
  {
    "text": "abstraction on top of that if we had to redo again we'll basically have more cleaner abstraction for doing all the",
    "start": "2342920",
    "end": "2349920"
  },
  {
    "text": "resource provisioning from the GetGo using this approach are there any other vendors",
    "start": "2349920",
    "end": "2356240"
  },
  {
    "text": "that you would consider I mean did you like would you think of a cross plane or radius or any other in that space um so",
    "start": "2356240",
    "end": "2364400"
  },
  {
    "text": "I would say that like uh data bricks has a very complex architecture we are deployed in multiple clouds multiple",
    "start": "2364400",
    "end": "2370560"
  },
  {
    "text": "regions we have very complex networking um and uh we explored a few",
    "start": "2370560",
    "end": "2375680"
  },
  {
    "text": "vendors but uh it would not meet all the demands and uh we want to move fast as",
    "start": "2375680",
    "end": "2381079"
  },
  {
    "text": "well so we want to have things you our own control um uh so yeah that is like",
    "start": "2381079",
    "end": "2387640"
  },
  {
    "text": "one of the primary reason we have we we basically take automation very seriously and uh we do try to automate a bunch of",
    "start": "2387640",
    "end": "2394160"
  },
  {
    "text": "things uh and uh we invest a lot into this uh however we basically use a lot of",
    "start": "2394160",
    "end": "2400079"
  },
  {
    "text": "Open Source uh stuff uh and we leverage a lot of them uh to to build uh to",
    "start": "2400079",
    "end": "2406839"
  },
  {
    "text": "basically incorporate in our uh in our development uh but uh are do you have",
    "start": "2406839",
    "end": "2413480"
  },
  {
    "text": "any specific uh thing that you have in mind uh no it's just something that's right now in the back of my head um that",
    "start": "2413480",
    "end": "2419880"
  },
  {
    "text": "we're thinking through the ones that I mentioned are some of those that seem like they're in the same space but I'm wondering if you know of any others okay",
    "start": "2419880",
    "end": "2426560"
  },
  {
    "text": "I'm happy to talk more about like if you have any more ideas about this cool thanks",
    "start": "2426560",
    "end": "2432400"
  },
  {
    "text": "yeah I think we are over time I'm happy to answer any questions offline as well I'll be outside um I'm going to leave uh",
    "start": "2432400",
    "end": "2441920"
  },
  {
    "text": "my LinkedIn uh link as well as uh we are hiring actively at data brakes so if you",
    "start": "2441920",
    "end": "2447040"
  },
  {
    "text": "have uh if you are looking for jobs uh I linked my open like our open positions",
    "start": "2447040",
    "end": "2453280"
  },
  {
    "text": "here thank you everyone",
    "start": "2453280",
    "end": "2457599"
  },
  {
    "text": "[Applause]",
    "start": "2458420",
    "end": "2461119"
  }
]
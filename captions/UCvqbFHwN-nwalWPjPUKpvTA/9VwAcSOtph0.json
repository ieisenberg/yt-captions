[
  {
    "text": "all right thank you my name is Daniel",
    "start": "480",
    "end": "2760"
  },
  {
    "text": "Milroy and I'm a computer scientist at",
    "start": "2760",
    "end": "5339"
  },
  {
    "text": "the Center for Applied scientific",
    "start": "5339",
    "end": "6660"
  },
  {
    "text": "Computing at the Lawrence Livermore",
    "start": "6660",
    "end": "8099"
  },
  {
    "text": "National Laboratory and I'm going to be",
    "start": "8099",
    "end": "10559"
  },
  {
    "text": "speaking on behalf of my collaborators",
    "start": "10559",
    "end": "12000"
  },
  {
    "text": "at the laboratory and also uh Claudia",
    "start": "12000",
    "end": "14280"
  },
  {
    "text": "masale who could not be here today from",
    "start": "14280",
    "end": "16500"
  },
  {
    "text": "the IBM TJ Watson Research Center",
    "start": "16500",
    "end": "20520"
  },
  {
    "text": "so I'll be talking about fluence",
    "start": "20520",
    "end": "22039"
  },
  {
    "text": "approaching a converged Computing",
    "start": "22039",
    "end": "24060"
  },
  {
    "text": "environment",
    "start": "24060",
    "end": "25140"
  },
  {
    "text": "so to give everyone a little bit of a",
    "start": "25140",
    "end": "26880"
  },
  {
    "text": "background on what I'm talking about",
    "start": "26880",
    "end": "28380"
  },
  {
    "text": "here I want to give an example of a",
    "start": "28380",
    "end": "30660"
  },
  {
    "text": "pre-exist scale scientific workflow that",
    "start": "30660",
    "end": "33120"
  },
  {
    "text": "really strained the capabilities of",
    "start": "33120",
    "end": "34800"
  },
  {
    "text": "traditional HPC resource managers and",
    "start": "34800",
    "end": "36899"
  },
  {
    "text": "schedulers so this is the multi-scale",
    "start": "36899",
    "end": "39719"
  },
  {
    "text": "machine learned modeling infrastructure",
    "start": "39719",
    "end": "41520"
  },
  {
    "text": "also known as mumi which won the sc19",
    "start": "41520",
    "end": "44700"
  },
  {
    "text": "best paper award and this features",
    "start": "44700",
    "end": "46920"
  },
  {
    "text": "message passing interface or MPI based",
    "start": "46920",
    "end": "49620"
  },
  {
    "text": "simulation it coupled with in-situ",
    "start": "49620",
    "end": "52260"
  },
  {
    "text": "analysis and machine learning as well",
    "start": "52260",
    "end": "55980"
  },
  {
    "text": "so there are three primary areas that",
    "start": "55980",
    "end": "58199"
  },
  {
    "text": "really text or strain the capabilities",
    "start": "58199",
    "end": "61140"
  },
  {
    "text": "of resource managers and schedules and",
    "start": "61140",
    "end": "63000"
  },
  {
    "text": "the first is the co-scheduling challenge",
    "start": "63000",
    "end": "64500"
  },
  {
    "text": "so the coarse grain component of this",
    "start": "64500",
    "end": "67140"
  },
  {
    "text": "particular workflow and I'm just kind of",
    "start": "67140",
    "end": "68640"
  },
  {
    "text": "going to over provide a brief overview",
    "start": "68640",
    "end": "70740"
  },
  {
    "text": "view of this because it's very complex",
    "start": "70740",
    "end": "73220"
  },
  {
    "text": "required the analysis be bound to cores",
    "start": "73220",
    "end": "76560"
  },
  {
    "text": "that were nearest PCI Express buses on",
    "start": "76560",
    "end": "79140"
  },
  {
    "text": "node because those particular cores",
    "start": "79140",
    "end": "81420"
  },
  {
    "text": "needed to communicate and exchange data",
    "start": "81420",
    "end": "83159"
  },
  {
    "text": "data with the gpus on the nodes so we",
    "start": "83159",
    "end": "85439"
  },
  {
    "text": "need to exploit very fine-grained node",
    "start": "85439",
    "end": "87840"
  },
  {
    "text": "local topology information the second",
    "start": "87840",
    "end": "90299"
  },
  {
    "text": "was the jobs communication and",
    "start": "90299",
    "end": "92520"
  },
  {
    "text": "coordination challenge so this",
    "start": "92520",
    "end": "93960"
  },
  {
    "text": "particular workflow consisted of",
    "start": "93960",
    "end": "95520"
  },
  {
    "text": "approximately 36 000 individual",
    "start": "95520",
    "end": "97920"
  },
  {
    "text": "concurrent tasks using 176 000 CPU cores",
    "start": "97920",
    "end": "102420"
  },
  {
    "text": "and over 16 000 gpus on the Lawrence",
    "start": "102420",
    "end": "105720"
  },
  {
    "text": "Livermore National Laboratory Sierra",
    "start": "105720",
    "end": "107840"
  },
  {
    "text": "pre-exascale cluster so the coordination",
    "start": "107840",
    "end": "110399"
  },
  {
    "text": "between a lot of these tasks was very",
    "start": "110399",
    "end": "112020"
  },
  {
    "text": "very difficult using traditional",
    "start": "112020",
    "end": "113460"
  },
  {
    "text": "workload managers and schedulers finally",
    "start": "113460",
    "end": "115920"
  },
  {
    "text": "the portability challenge so given all",
    "start": "115920",
    "end": "118259"
  },
  {
    "text": "this coordination and given the",
    "start": "118259",
    "end": "119820"
  },
  {
    "text": "difficulty of actually adapting this",
    "start": "119820",
    "end": "121439"
  },
  {
    "text": "workflow to a particular resource",
    "start": "121439",
    "end": "123479"
  },
  {
    "text": "manager and schedule reporting that",
    "start": "123479",
    "end": "124920"
  },
  {
    "text": "between different resource managers and",
    "start": "124920",
    "end": "126780"
  },
  {
    "text": "schedulers is tremendously difficult",
    "start": "126780",
    "end": "130739"
  },
  {
    "text": "so in terms of Next Generation what",
    "start": "130739",
    "end": "132959"
  },
  {
    "text": "we're going to from here is we're",
    "start": "132959",
    "end": "134640"
  },
  {
    "text": "starting to see cross-cluster scientific",
    "start": "134640",
    "end": "136560"
  },
  {
    "text": "workflows which are demanding",
    "start": "136560",
    "end": "137940"
  },
  {
    "text": "portability as well as integration with",
    "start": "137940",
    "end": "139920"
  },
  {
    "text": "the cloud so this diagram is an",
    "start": "139920",
    "end": "142620"
  },
  {
    "text": "architectural diagram of the American",
    "start": "142620",
    "end": "144360"
  },
  {
    "text": "Heart Association molecular screening",
    "start": "144360",
    "end": "146400"
  },
  {
    "text": "workflow which was the e-science 22 best",
    "start": "146400",
    "end": "148620"
  },
  {
    "text": "paper and this combines more traditional",
    "start": "148620",
    "end": "151200"
  },
  {
    "text": "MPI based simulation analysis with",
    "start": "151200",
    "end": "153480"
  },
  {
    "text": "machine learning and now containerized",
    "start": "153480",
    "end": "155459"
  },
  {
    "text": "components as well so when I mentioned",
    "start": "155459",
    "end": "157319"
  },
  {
    "text": "that this is a cross cluster workflow it",
    "start": "157319",
    "end": "159720"
  },
  {
    "text": "features one component that runs on a",
    "start": "159720",
    "end": "162360"
  },
  {
    "text": "dedicated CPU cluster one component that",
    "start": "162360",
    "end": "165540"
  },
  {
    "text": "runs on a CPU and GPU cluster and then a",
    "start": "165540",
    "end": "168060"
  },
  {
    "text": "kubernetes cluster that provides a",
    "start": "168060",
    "end": "169800"
  },
  {
    "text": "message queuing glue between these two",
    "start": "169800",
    "end": "171900"
  },
  {
    "text": "clusters so we're seeing on this",
    "start": "171900",
    "end": "174480"
  },
  {
    "text": "particular pattern at the laboratory and",
    "start": "174480",
    "end": "176519"
  },
  {
    "text": "Beyond there are other examples at the",
    "start": "176519",
    "end": "178140"
  },
  {
    "text": "laboratory such as traditional combining",
    "start": "178140",
    "end": "180599"
  },
  {
    "text": "traditional HPC simulations with AI and",
    "start": "180599",
    "end": "183900"
  },
  {
    "text": "machine learned surrogate models as well",
    "start": "183900",
    "end": "186900"
  },
  {
    "text": "as potentially orchestrated databases so",
    "start": "186900",
    "end": "189900"
  },
  {
    "text": "despite there being examples already at",
    "start": "189900",
    "end": "191879"
  },
  {
    "text": "the laboratory we anticipate that",
    "start": "191879",
    "end": "194340"
  },
  {
    "text": "they're going to be many many more in",
    "start": "194340",
    "end": "195900"
  },
  {
    "text": "the future a recent survey indicated",
    "start": "195900",
    "end": "197700"
  },
  {
    "text": "that up to 73 percent of the laboratory",
    "start": "197700",
    "end": "200280"
  },
  {
    "text": "workflows are interested in Cloud",
    "start": "200280",
    "end": "201900"
  },
  {
    "text": "integration",
    "start": "201900",
    "end": "204060"
  },
  {
    "text": "so I mentioned that uh that many of",
    "start": "204060",
    "end": "206340"
  },
  {
    "text": "these complex workflows challenge the",
    "start": "206340",
    "end": "208319"
  },
  {
    "text": "capabilities of traditional HPC resource",
    "start": "208319",
    "end": "210959"
  },
  {
    "text": "managers and schedulers and this is",
    "start": "210959",
    "end": "212640"
  },
  {
    "text": "where the flux framework comes in so",
    "start": "212640",
    "end": "215040"
  },
  {
    "text": "flux is a hierarchical combines",
    "start": "215040",
    "end": "216780"
  },
  {
    "text": "hierarchical management with graph based",
    "start": "216780",
    "end": "219239"
  },
  {
    "text": "scheduling which addresses many of the",
    "start": "219239",
    "end": "221099"
  },
  {
    "text": "challenges that I brought up in the",
    "start": "221099",
    "end": "222540"
  },
  {
    "text": "first two slides so the first the first",
    "start": "222540",
    "end": "225000"
  },
  {
    "text": "way it accomplishes this is to enable",
    "start": "225000",
    "end": "227220"
  },
  {
    "text": "full workflow support and it does this",
    "start": "227220",
    "end": "230099"
  },
  {
    "text": "via hierarchical resource subdivision so",
    "start": "230099",
    "end": "232500"
  },
  {
    "text": "flux can actually instantiate itself",
    "start": "232500",
    "end": "234420"
  },
  {
    "text": "inside of itself essentially add",
    "start": "234420",
    "end": "236400"
  },
  {
    "text": "infinitum and this allows for",
    "start": "236400",
    "end": "237959"
  },
  {
    "text": "specialization each at each level so at",
    "start": "237959",
    "end": "240540"
  },
  {
    "text": "each level in a nested flux hierarchy",
    "start": "240540",
    "end": "242760"
  },
  {
    "text": "you can change the scheduling algorithms",
    "start": "242760",
    "end": "244500"
  },
  {
    "text": "and use divide and conquer approaches",
    "start": "244500",
    "end": "246659"
  },
  {
    "text": "the second point is that flux can",
    "start": "246659",
    "end": "249239"
  },
  {
    "text": "actually manage resources basically",
    "start": "249239",
    "end": "250860"
  },
  {
    "text": "anywhere from bare metal resources to",
    "start": "250860",
    "end": "252900"
  },
  {
    "text": "Virtual machines in the cloud Etc",
    "start": "252900",
    "end": "255480"
  },
  {
    "text": "another huge Advantage is that workflows",
    "start": "255480",
    "end": "258299"
  },
  {
    "text": "really only need to program to flux I",
    "start": "258299",
    "end": "260100"
  },
  {
    "text": "mentioned the portability challenge",
    "start": "260100",
    "end": "261299"
  },
  {
    "text": "before well flux can actually",
    "start": "261299",
    "end": "263340"
  },
  {
    "text": "instantiate itself underneath external",
    "start": "263340",
    "end": "265860"
  },
  {
    "text": "resource managers like slurm and lsf",
    "start": "265860",
    "end": "268620"
  },
  {
    "text": "finally you see the direct graph diagram",
    "start": "268620",
    "end": "271380"
  },
  {
    "text": "at the bottom well the directed graphs",
    "start": "271380",
    "end": "273780"
  },
  {
    "text": "are used as a resource model to express",
    "start": "273780",
    "end": "275520"
  },
  {
    "text": "complex or potentially complex and",
    "start": "275520",
    "end": "277979"
  },
  {
    "text": "changing resources finally flux the flux",
    "start": "277979",
    "end": "281160"
  },
  {
    "text": "framework provides rich and well-defined",
    "start": "281160",
    "end": "282960"
  },
  {
    "text": "interfaces this facilitates",
    "start": "282960",
    "end": "284880"
  },
  {
    "text": "communication and coordination between",
    "start": "284880",
    "end": "286800"
  },
  {
    "text": "different tasks in a workflow flux",
    "start": "286800",
    "end": "289440"
  },
  {
    "text": "framework provides CLI python C C plus",
    "start": "289440",
    "end": "292740"
  },
  {
    "text": "plus bindings rust and we're working on",
    "start": "292740",
    "end": "295560"
  },
  {
    "text": "go bindings as well",
    "start": "295560",
    "end": "299060"
  },
  {
    "text": "so given the emphasis and MPI and",
    "start": "299220",
    "end": "301500"
  },
  {
    "text": "traditional HPC work workloads we want",
    "start": "301500",
    "end": "304500"
  },
  {
    "text": "to actually declaratively create kind of",
    "start": "304500",
    "end": "306240"
  },
  {
    "text": "an HPC Cloud slice and this is really",
    "start": "306240",
    "end": "308520"
  },
  {
    "text": "complicated and requires a couple of",
    "start": "308520",
    "end": "310380"
  },
  {
    "text": "things the first is scalable MPI",
    "start": "310380",
    "end": "312900"
  },
  {
    "text": "bootstrapping and also fine or high",
    "start": "312900",
    "end": "316080"
  },
  {
    "text": "quality pod placement and I'll talk",
    "start": "316080",
    "end": "317639"
  },
  {
    "text": "about what that means in just a minute",
    "start": "317639",
    "end": "319139"
  },
  {
    "text": "but basically the idea is that you have",
    "start": "319139",
    "end": "321180"
  },
  {
    "text": "more complexity than you do in a kind of",
    "start": "321180",
    "end": "323400"
  },
  {
    "text": "bare bones or bare metal HPC",
    "start": "323400",
    "end": "325820"
  },
  {
    "text": "environments you have mapping of MPI",
    "start": "325820",
    "end": "328259"
  },
  {
    "text": "ranks to pods mapping of PODS to",
    "start": "328259",
    "end": "330060"
  },
  {
    "text": "underlying physical infrastructure",
    "start": "330060",
    "end": "333000"
  },
  {
    "text": "so the first thing that we did to now",
    "start": "333000",
    "end": "334800"
  },
  {
    "text": "enable this uh this this capability was",
    "start": "334800",
    "end": "337560"
  },
  {
    "text": "to allow declarative MPI to scale three",
    "start": "337560",
    "end": "340259"
  },
  {
    "text": "orders of magnitude higher than it did",
    "start": "340259",
    "end": "342060"
  },
  {
    "text": "in our tests so we use the kubeflow MPI",
    "start": "342060",
    "end": "345300"
  },
  {
    "text": "operator which initially in our tests",
    "start": "345300",
    "end": "347039"
  },
  {
    "text": "only scaled to about 80 ranks",
    "start": "347039",
    "end": "349620"
  },
  {
    "text": "um so we identified and fixed some race",
    "start": "349620",
    "end": "351780"
  },
  {
    "text": "conditions in the process or the flow",
    "start": "351780",
    "end": "353880"
  },
  {
    "text": "diagram to to the left one of which was",
    "start": "353880",
    "end": "357660"
  },
  {
    "text": "that the launcher didn't wait for",
    "start": "357660",
    "end": "358979"
  },
  {
    "text": "workers to be ready the second was that",
    "start": "358979",
    "end": "361560"
  },
  {
    "text": "workers would actually report a state",
    "start": "361560",
    "end": "363479"
  },
  {
    "text": "transition to ready before SSH was",
    "start": "363479",
    "end": "366000"
  },
  {
    "text": "available which caused failures upon MPI",
    "start": "366000",
    "end": "368280"
  },
  {
    "text": "bootstrap we also fixed a DNS flood that",
    "start": "368280",
    "end": "371940"
  },
  {
    "text": "would cause overload of core DNS",
    "start": "371940",
    "end": "374460"
  },
  {
    "text": "so this fixed MPI operator we tested it",
    "start": "374460",
    "end": "376919"
  },
  {
    "text": "with just MPI in it and hello world and",
    "start": "376919",
    "end": "379919"
  },
  {
    "text": "got that to run up to 16 384 MPI ranks",
    "start": "379919",
    "end": "383819"
  },
  {
    "text": "on eks",
    "start": "383819",
    "end": "385919"
  },
  {
    "text": "so the second component of this is",
    "start": "385919",
    "end": "387900"
  },
  {
    "text": "fluence which used to be known as",
    "start": "387900",
    "end": "389160"
  },
  {
    "text": "kubeflux which brings HPC grade",
    "start": "389160",
    "end": "391620"
  },
  {
    "text": "scheduling and improved performance to",
    "start": "391620",
    "end": "393479"
  },
  {
    "text": "kubernetes It's featured as part of the",
    "start": "393479",
    "end": "396060"
  },
  {
    "text": "kubernetes plug-in schedule framework so",
    "start": "396060",
    "end": "399840"
  },
  {
    "text": "fluent supports CPU memory and GPU",
    "start": "399840",
    "end": "402300"
  },
  {
    "text": "resource requests it allows for Zone",
    "start": "402300",
    "end": "404580"
  },
  {
    "text": "awareness via locality information",
    "start": "404580",
    "end": "406080"
  },
  {
    "text": "that's actually embedded into the",
    "start": "406080",
    "end": "407940"
  },
  {
    "text": "function or scheduler component resource",
    "start": "407940",
    "end": "410340"
  },
  {
    "text": "graph we tested this using Department of",
    "start": "410340",
    "end": "413699"
  },
  {
    "text": "energy Coral 2 exascale pre-exascale",
    "start": "413699",
    "end": "416340"
  },
  {
    "text": "benchmarks such as AMG lamps and qmc",
    "start": "416340",
    "end": "419940"
  },
  {
    "text": "pack we found that optimized AMG ran",
    "start": "419940",
    "end": "423600"
  },
  {
    "text": "well in IBM cloud and AWS and we've got",
    "start": "423600",
    "end": "426419"
  },
  {
    "text": "lamps which is latency sensitive to",
    "start": "426419",
    "end": "428460"
  },
  {
    "text": "strong scale in eks up to 3008 ranks",
    "start": "428460",
    "end": "433380"
  },
  {
    "text": "so fluence actually accelerates Coral",
    "start": "433380",
    "end": "436080"
  },
  {
    "text": "two benchmarks in openshift on IBM Cloud",
    "start": "436080",
    "end": "438539"
  },
  {
    "text": "so this is a rocks cluster I'm going to",
    "start": "438539",
    "end": "440880"
  },
  {
    "text": "provide a little bit of overview of",
    "start": "440880",
    "end": "442139"
  },
  {
    "text": "these performance results you can see",
    "start": "442139",
    "end": "443699"
  },
  {
    "text": "qmc pack is the rightmost plot and lamps",
    "start": "443699",
    "end": "446340"
  },
  {
    "text": "or sorry the leftmost plot lamps is the",
    "start": "446340",
    "end": "448560"
  },
  {
    "text": "rightmost plot these sets of box plots",
    "start": "448560",
    "end": "451440"
  },
  {
    "text": "in these sets of box plots the blue",
    "start": "451440",
    "end": "453240"
  },
  {
    "text": "indicates default Cube scheduler and",
    "start": "453240",
    "end": "455580"
  },
  {
    "text": "orange is fluent so you notice right",
    "start": "455580",
    "end": "458039"
  },
  {
    "text": "away that depending on the rank size the",
    "start": "458039",
    "end": "461039"
  },
  {
    "text": "variability is much higher with a",
    "start": "461039",
    "end": "463259"
  },
  {
    "text": "default scheduler than fluent and also",
    "start": "463259",
    "end": "465120"
  },
  {
    "text": "the run times are higher so Coupe",
    "start": "465120",
    "end": "467580"
  },
  {
    "text": "schedule part of the reason is that",
    "start": "467580",
    "end": "468720"
  },
  {
    "text": "Coupe schedule is unable to pack to end",
    "start": "468720",
    "end": "471240"
  },
  {
    "text": "single nodes so even when limiting or or",
    "start": "471240",
    "end": "474060"
  },
  {
    "text": "modifying affinity and anti-affinity",
    "start": "474060",
    "end": "476460"
  },
  {
    "text": "Coupe scheduler was not able to able to",
    "start": "476460",
    "end": "479580"
  },
  {
    "text": "perform as desired",
    "start": "479580",
    "end": "482759"
  },
  {
    "text": "we also compared multi-app simulated",
    "start": "482759",
    "end": "485400"
  },
  {
    "text": "workflow performance which was scheduled",
    "start": "485400",
    "end": "487259"
  },
  {
    "text": "by fluence versus Coupe scheduler so we",
    "start": "487259",
    "end": "489479"
  },
  {
    "text": "simulated workflows by taking the three",
    "start": "489479",
    "end": "492680"
  },
  {
    "text": "Coral two benchmarks and running them",
    "start": "492680",
    "end": "494940"
  },
  {
    "text": "simultaneously on within a single",
    "start": "494940",
    "end": "497340"
  },
  {
    "text": "availability zone of an IBM eks cluster",
    "start": "497340",
    "end": "499979"
  },
  {
    "text": "and this heat map represents pod",
    "start": "499979",
    "end": "501960"
  },
  {
    "text": "placement so at the top we have Coop",
    "start": "501960",
    "end": "503819"
  },
  {
    "text": "scheduler those are the top 40 jobs and",
    "start": "503819",
    "end": "506039"
  },
  {
    "text": "the bottom 40 jobs are actually fluent",
    "start": "506039",
    "end": "508139"
  },
  {
    "text": "so along the horizontal axis are the",
    "start": "508139",
    "end": "510479"
  },
  {
    "text": "unique node IDs and again vertical",
    "start": "510479",
    "end": "512180"
  },
  {
    "text": "accesses job IDs and the color indicates",
    "start": "512180",
    "end": "515520"
  },
  {
    "text": "the number of PODS that were actually",
    "start": "515520",
    "end": "517260"
  },
  {
    "text": "mapped to each individual node",
    "start": "517260",
    "end": "519719"
  },
  {
    "text": "when we saw what a pathological mapping",
    "start": "519719",
    "end": "521700"
  },
  {
    "text": "Behavior due to the random tie breaking",
    "start": "521700",
    "end": "523800"
  },
  {
    "text": "of the coop scheduler which resulted",
    "start": "523800",
    "end": "525720"
  },
  {
    "text": "resulted in artificial resource",
    "start": "525720",
    "end": "527640"
  },
  {
    "text": "starvation and delayed execution for",
    "start": "527640",
    "end": "529800"
  },
  {
    "text": "some of the constituents of the workflow",
    "start": "529800",
    "end": "531660"
  },
  {
    "text": "so you can see this represented in two",
    "start": "531660",
    "end": "534000"
  },
  {
    "text": "buck plots to to my right the first is",
    "start": "534000",
    "end": "537600"
  },
  {
    "text": "AMG where you can see that that is",
    "start": "537600",
    "end": "539899"
  },
  {
    "text": "heavily skewed distribution for the",
    "start": "539899",
    "end": "542399"
  },
  {
    "text": "default scheduler which you can't really",
    "start": "542399",
    "end": "543899"
  },
  {
    "text": "see the color there but you can take my",
    "start": "543899",
    "end": "545700"
  },
  {
    "text": "word for it that the one that is skewed",
    "start": "545700",
    "end": "548040"
  },
  {
    "text": "is Coupe scheduler and and qmc pack you",
    "start": "548040",
    "end": "550620"
  },
  {
    "text": "see similar Behavior so in general we",
    "start": "550620",
    "end": "553140"
  },
  {
    "text": "saw the fluent scheduled workflows run",
    "start": "553140",
    "end": "554940"
  },
  {
    "text": "up to three times faster you can take a",
    "start": "554940",
    "end": "557519"
  },
  {
    "text": "look at this this will be published in",
    "start": "557519",
    "end": "559380"
  },
  {
    "text": "the Canon P22 workshop at sc22 so",
    "start": "559380",
    "end": "562680"
  },
  {
    "text": "finally I want to talk really briefly",
    "start": "562680",
    "end": "564000"
  },
  {
    "text": "about our latest work which is actually",
    "start": "564000",
    "end": "565740"
  },
  {
    "text": "to replace the MPI operator using the",
    "start": "565740",
    "end": "568080"
  },
  {
    "text": "flux operator this is going to enable",
    "start": "568080",
    "end": "570240"
  },
  {
    "text": "both HPC grade pod scheduling and also",
    "start": "570240",
    "end": "573420"
  },
  {
    "text": "hierarchical Management in kubernetes",
    "start": "573420",
    "end": "576180"
  },
  {
    "text": "the idea behind this is to bootstrap the",
    "start": "576180",
    "end": "578580"
  },
  {
    "text": "flux tree base overlay Network across",
    "start": "578580",
    "end": "580800"
  },
  {
    "text": "pods such that complex scientific",
    "start": "580800",
    "end": "582660"
  },
  {
    "text": "workflows can run and make use of the",
    "start": "582660",
    "end": "585300"
  },
  {
    "text": "hierarchical resource subdivision and",
    "start": "585300",
    "end": "587399"
  },
  {
    "text": "scheduling capabilities that they use on",
    "start": "587399",
    "end": "589440"
  },
  {
    "text": "bare metal so the first first thing that",
    "start": "589440",
    "end": "591899"
  },
  {
    "text": "we're going to start working on is",
    "start": "591899",
    "end": "593100"
  },
  {
    "text": "porting the American Heart Association",
    "start": "593100",
    "end": "595200"
  },
  {
    "text": "molecular screening workflow to",
    "start": "595200",
    "end": "596880"
  },
  {
    "text": "kubernetes",
    "start": "596880",
    "end": "598620"
  },
  {
    "text": "so thank you very much I have some links",
    "start": "598620",
    "end": "601380"
  },
  {
    "text": "to the uh to the software available on",
    "start": "601380",
    "end": "603720"
  },
  {
    "text": "GitHub and let me know if you have any",
    "start": "603720",
    "end": "605519"
  },
  {
    "text": "questions",
    "start": "605519",
    "end": "607760"
  },
  {
    "text": "[Applause]",
    "start": "609170",
    "end": "611640"
  },
  {
    "text": "questions",
    "start": "611640",
    "end": "614300"
  },
  {
    "text": "oh that's really interesting thank you",
    "start": "623519",
    "end": "625560"
  },
  {
    "text": "for that uh I guess one thing I'm",
    "start": "625560",
    "end": "627540"
  },
  {
    "text": "wondering about is this is mostly",
    "start": "627540",
    "end": "629940"
  },
  {
    "text": "Outsider looking in but I have",
    "start": "629940",
    "end": "633480"
  },
  {
    "text": "have there been talks in the doe about",
    "start": "633480",
    "end": "635519"
  },
  {
    "text": "like converging on these different like",
    "start": "635519",
    "end": "637200"
  },
  {
    "text": "science like scientific workflow of our",
    "start": "637200",
    "end": "639300"
  },
  {
    "text": "presentations like I know it seems like",
    "start": "639300",
    "end": "641399"
  },
  {
    "text": "every every lab kind of has their own",
    "start": "641399",
    "end": "644120"
  },
  {
    "text": "and uh I know the bioinformatics",
    "start": "644120",
    "end": "647040"
  },
  {
    "text": "community has a bunch of their own too",
    "start": "647040",
    "end": "648779"
  },
  {
    "text": "and I guess I'm just curious if I'm I",
    "start": "648779",
    "end": "652380"
  },
  {
    "text": "just want to know your thoughts on that",
    "start": "652380",
    "end": "654000"
  },
  {
    "text": "so you're talking about kind of",
    "start": "654000",
    "end": "655800"
  },
  {
    "text": "standardizing workflow components or",
    "start": "655800",
    "end": "657779"
  },
  {
    "text": "standardizing workable architectures",
    "start": "657779",
    "end": "659600"
  },
  {
    "text": "yeah among the doe yeah um there are",
    "start": "659600",
    "end": "663779"
  },
  {
    "text": "there's an EXO Works project that's part",
    "start": "663779",
    "end": "665820"
  },
  {
    "text": "of the exascale Computing project I'm",
    "start": "665820",
    "end": "667860"
  },
  {
    "text": "not part of that but I believe there are",
    "start": "667860",
    "end": "669959"
  },
  {
    "text": "several members of the Lawrence",
    "start": "669959",
    "end": "671279"
  },
  {
    "text": "Livermore laboratory that are working on",
    "start": "671279",
    "end": "672899"
  },
  {
    "text": "that I believe Dan Laney is one of them",
    "start": "672899",
    "end": "674579"
  },
  {
    "text": "so I'm not an expert on that particular",
    "start": "674579",
    "end": "676860"
  },
  {
    "text": "portion but I know their efforts",
    "start": "676860",
    "end": "678899"
  },
  {
    "text": "underway to do so",
    "start": "678899",
    "end": "681740"
  },
  {
    "text": "yeah hi",
    "start": "694680",
    "end": "696240"
  },
  {
    "text": "how are you dealing with the concept of",
    "start": "696240",
    "end": "698279"
  },
  {
    "text": "like users within your MPI operator",
    "start": "698279",
    "end": "701579"
  },
  {
    "text": "replacement yeah so this is this is",
    "start": "701579",
    "end": "704339"
  },
  {
    "text": "something that we haven't really gotten",
    "start": "704339",
    "end": "705600"
  },
  {
    "text": "into yet the multi-user cluster is going",
    "start": "705600",
    "end": "708300"
  },
  {
    "text": "to be a little bit complex",
    "start": "708300",
    "end": "710220"
  },
  {
    "text": "um at this point we're basically just",
    "start": "710220",
    "end": "712320"
  },
  {
    "text": "assuming that all everyone is the same",
    "start": "712320",
    "end": "714000"
  },
  {
    "text": "user but once we have",
    "start": "714000",
    "end": "716459"
  },
  {
    "text": "once we allow there to be multiple users",
    "start": "716459",
    "end": "718500"
  },
  {
    "text": "we're going to have to contend with a",
    "start": "718500",
    "end": "720240"
  },
  {
    "text": "lot of the problems that you work with",
    "start": "720240",
    "end": "721560"
  },
  {
    "text": "like fairness and that sort of thing so",
    "start": "721560",
    "end": "723720"
  },
  {
    "text": "we haven't we haven't worked on that yet",
    "start": "723720",
    "end": "725100"
  },
  {
    "text": "but that's upcoming",
    "start": "725100",
    "end": "728000"
  },
  {
    "text": "hi um maybe we can take this offline but",
    "start": "730860",
    "end": "733440"
  },
  {
    "text": "I was wondering why uh you're well doing",
    "start": "733440",
    "end": "737700"
  },
  {
    "text": "these improvements to MP operator or",
    "start": "737700",
    "end": "739920"
  },
  {
    "text": "even now thinking of forking if I",
    "start": "739920",
    "end": "741959"
  },
  {
    "text": "understand correctly why not bring this",
    "start": "741959",
    "end": "744360"
  },
  {
    "text": "uh changes to the existing API operator",
    "start": "744360",
    "end": "747480"
  },
  {
    "text": "in keep flow yeah they're um I think",
    "start": "747480",
    "end": "750720"
  },
  {
    "text": "there were some complexities with the um",
    "start": "750720",
    "end": "753720"
  },
  {
    "text": "the license agreement",
    "start": "753720",
    "end": "755820"
  },
  {
    "text": "with the MPI operator so I think it is",
    "start": "755820",
    "end": "757920"
  },
  {
    "text": "possible to do so but it is rather",
    "start": "757920",
    "end": "759540"
  },
  {
    "text": "complex given the uh constraints based",
    "start": "759540",
    "end": "762180"
  },
  {
    "text": "on our various organizations",
    "start": "762180",
    "end": "764279"
  },
  {
    "text": "so yeah that would be desired definitely",
    "start": "764279",
    "end": "767579"
  },
  {
    "text": "and if those were to be resolved you",
    "start": "767579",
    "end": "771120"
  },
  {
    "text": "would be willing to do it absolutely",
    "start": "771120",
    "end": "772500"
  },
  {
    "text": "yeah",
    "start": "772500",
    "end": "774800"
  },
  {
    "text": "and I think it's more of a level of",
    "start": "775680",
    "end": "777540"
  },
  {
    "text": "amount of time in order to resolve it",
    "start": "777540",
    "end": "779760"
  },
  {
    "text": "not that not whether it can be",
    "start": "779760",
    "end": "783440"
  },
  {
    "text": "in the case where we tested it on on",
    "start": "787440",
    "end": "790019"
  },
  {
    "text": "awsck yes did you use any auto scaling",
    "start": "790019",
    "end": "792480"
  },
  {
    "text": "there I'm sorry I didn't hear that did",
    "start": "792480",
    "end": "795060"
  },
  {
    "text": "you use any form of Auto scaling no no",
    "start": "795060",
    "end": "798000"
  },
  {
    "text": "not yet but this is something that we",
    "start": "798000",
    "end": "799620"
  },
  {
    "text": "want to integrate in the future so I",
    "start": "799620",
    "end": "801300"
  },
  {
    "text": "mentioned that um the flux framework",
    "start": "801300",
    "end": "803760"
  },
  {
    "text": "scheduler uh is is we work on elasticity",
    "start": "803760",
    "end": "806880"
  },
  {
    "text": "in it so we want to actually integrate",
    "start": "806880",
    "end": "808680"
  },
  {
    "text": "that into fluence and allow the",
    "start": "808680",
    "end": "810660"
  },
  {
    "text": "allocations to change shape over time so",
    "start": "810660",
    "end": "813540"
  },
  {
    "text": "yeah that that is definitely something",
    "start": "813540",
    "end": "814920"
  },
  {
    "text": "we're working on",
    "start": "814920",
    "end": "817639"
  },
  {
    "text": "um",
    "start": "823139",
    "end": "824399"
  },
  {
    "text": "any more questions",
    "start": "824399",
    "end": "827240"
  },
  {
    "text": "I got one",
    "start": "828060",
    "end": "829920"
  },
  {
    "text": "um so with your comparison with Cube",
    "start": "829920",
    "end": "832320"
  },
  {
    "text": "scheduler like it's clearly it shows",
    "start": "832320",
    "end": "834480"
  },
  {
    "text": "that Cube schedule is",
    "start": "834480",
    "end": "836300"
  },
  {
    "text": "optimized for service type workers tries",
    "start": "836300",
    "end": "838680"
  },
  {
    "text": "to spread Etc did you try at least to",
    "start": "838680",
    "end": "841200"
  },
  {
    "text": "tune it other than using uh potent",
    "start": "841200",
    "end": "843839"
  },
  {
    "text": "Affinity Etc but the configuration",
    "start": "843839",
    "end": "846000"
  },
  {
    "text": "itself right like changing the weights",
    "start": "846000",
    "end": "848639"
  },
  {
    "text": "of these like you know",
    "start": "848639",
    "end": "850920"
  },
  {
    "text": "um various features that they have",
    "start": "850920",
    "end": "852899"
  },
  {
    "text": "inside yeah that that would be a",
    "start": "852899",
    "end": "854820"
  },
  {
    "text": "question a question for Claudia she did",
    "start": "854820",
    "end": "856620"
  },
  {
    "text": "that work primarily I believe so um I",
    "start": "856620",
    "end": "858959"
  },
  {
    "text": "believe she also tried skew too but I",
    "start": "858959",
    "end": "861120"
  },
  {
    "text": "don't want to speak for her too much",
    "start": "861120",
    "end": "862380"
  },
  {
    "text": "because I didn't run that so the answer",
    "start": "862380",
    "end": "864300"
  },
  {
    "text": "is I think so with caveat I'm not sure",
    "start": "864300",
    "end": "868579"
  },
  {
    "text": "[Applause]",
    "start": "870830",
    "end": "874940"
  }
]
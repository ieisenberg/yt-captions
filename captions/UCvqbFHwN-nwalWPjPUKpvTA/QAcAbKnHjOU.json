[
  {
    "text": "welcome to the closing keynote of the company scheduling deep dive actually so",
    "start": "89",
    "end": "7410"
  },
  {
    "text": "my name is Bobby Solomon I work at Google I am the lead or one of the two",
    "start": "7410",
    "end": "13710"
  },
  {
    "text": "leads of scheduling before kubernetes I used to work on Borg and about two years",
    "start": "13710",
    "end": "21240"
  },
  {
    "text": "ago I started working on kubernetes and I've been leading Sookie scheduling for",
    "start": "21240",
    "end": "26609"
  },
  {
    "text": "the past one year or so so most of these deep dives are meant to be like he won a",
    "start": "26609",
    "end": "33950"
  },
  {
    "text": "as a result I didn't add a lot of slides to my deck so I'm gonna go through them",
    "start": "33950",
    "end": "39180"
  },
  {
    "text": "hopefully in about half of the time slot that it'd be happenin will open up to questions that you may have to get us",
    "start": "39180",
    "end": "46680"
  },
  {
    "text": "started I would like to very quickly tell you what kubernetes scheduler is so",
    "start": "46680",
    "end": "52199"
  },
  {
    "text": "basically kubernetes the scheduler is a component and kubernetes ecosystem that",
    "start": "52199",
    "end": "58050"
  },
  {
    "text": "is responsible for finding nodes for running the for running pods in the cluster kubernetes is scheduler unlike",
    "start": "58050",
    "end": "66150"
  },
  {
    "text": "some other cluster management networks or crisis management systems it is not",
    "start": "66150",
    "end": "71580"
  },
  {
    "text": "responsible for life cycle management of pods it never creates any pods and it kills",
    "start": "71580",
    "end": "78990"
  },
  {
    "text": "pod in very few circumstances actually this is kind of a new feature in kubernetes which is essentially",
    "start": "78990",
    "end": "85650"
  },
  {
    "text": "preemption i'm gonna talk about that a little bit later kubernetes the scheduler is a feature-rich scheduler it",
    "start": "85650",
    "end": "92369"
  },
  {
    "text": "supports many features among the notable ones I can point out node resource",
    "start": "92369",
    "end": "98939"
  },
  {
    "text": "checks or when it when it schedules parts it is it has a capability of",
    "start": "98939",
    "end": "104340"
  },
  {
    "text": "spreading parts of a collection among nodes of a cluster for example if you have a replica set it puts replicas of a",
    "start": "104340",
    "end": "112100"
  },
  {
    "text": "replica set in different nodes or in different failure domains of the zones",
    "start": "112100",
    "end": "117149"
  },
  {
    "text": "regions etc it supports trains and Toleration if you're not familiar with",
    "start": "117149",
    "end": "123000"
  },
  {
    "text": "these things on toleration as a feature in kubernetes where you can label some of the nodes with a special label let's",
    "start": "123000",
    "end": "130020"
  },
  {
    "text": "say which is called taint and those stains cause pods to not get",
    "start": "130020",
    "end": "135540"
  },
  {
    "text": "scheduled on those notes unless they have a corresponding toleration for those things",
    "start": "135540",
    "end": "142230"
  },
  {
    "text": "it supports no affinity basically you can in your pod spec you can specify",
    "start": "142230",
    "end": "148080"
  },
  {
    "text": "what kind of nodes or what specific nodes in the cluster you want this part to be scheduled on it supports inter pod",
    "start": "148080",
    "end": "155519"
  },
  {
    "text": "affinity which essentially means where you want your pods to be scheduled close",
    "start": "155519",
    "end": "160920"
  },
  {
    "text": "to some other pods in the cluster this is useful for example in case you want to run let's say a cache server next to",
    "start": "160920",
    "end": "168060"
  },
  {
    "text": "a web server and stuff like that also similar to inter pod affinity it",
    "start": "168060",
    "end": "173879"
  },
  {
    "text": "supports inter pod anti affinity entire vanity is useful for a case that for example you don't wanna on to pause next",
    "start": "173879",
    "end": "181440"
  },
  {
    "text": "to one another let's say you don't wanna run multiple web servers on the same",
    "start": "181440",
    "end": "186480"
  },
  {
    "text": "node you can you can do that by having anti affinity kubernetes scheduler",
    "start": "186480",
    "end": "192950"
  },
  {
    "text": "supports checking node conditions in kubernetes nodes can have certain",
    "start": "192950",
    "end": "198540"
  },
  {
    "text": "conditions for example if a node is on their memory pressure it gets this memory pressure condition or if there is",
    "start": "198540",
    "end": "204599"
  },
  {
    "text": "a PID pressure it gets that condition so the scheduler tries to avoid those nodes",
    "start": "204599",
    "end": "210720"
  },
  {
    "text": "which have issues or under certain",
    "start": "210720",
    "end": "215840"
  },
  {
    "text": "restrictions other than some of these for elect filters kubernetes the",
    "start": "215840",
    "end": "221940"
  },
  {
    "text": "scheduler has some preference as well that sometimes in the code be I recall",
    "start": "221940",
    "end": "227579"
  },
  {
    "text": "them priority functions basically these are these are preferences for scheduling",
    "start": "227579",
    "end": "233099"
  },
  {
    "text": "for example kubernetes scheduler can prefer choosing nodes which have lower",
    "start": "233099",
    "end": "238230"
  },
  {
    "text": "resource utilization or higher resource utilization deported and depending on",
    "start": "238230",
    "end": "243480"
  },
  {
    "text": "the config that you give to the scheduler this is useful for the case for example if you want to spread your",
    "start": "243480",
    "end": "249470"
  },
  {
    "text": "pods among different nodes in a cluster to hide them to achieve higher availability you can specify like choose",
    "start": "249470",
    "end": "256650"
  },
  {
    "text": "nodes with lower resource utilization or if you want to reduce the cost you don't care as much about availability you can",
    "start": "256650",
    "end": "263550"
  },
  {
    "text": "ask the scheduler to put as many parts as pass but viewers on fewer notes so in that",
    "start": "263550",
    "end": "269460"
  },
  {
    "text": "case you want to use like choose the highest choose notes with highest resource utilization you also have a",
    "start": "269460",
    "end": "277380"
  },
  {
    "text": "number of other preference for example the scheduler can put your pods on notes",
    "start": "277380",
    "end": "283590"
  },
  {
    "text": "that already have images that those parts require to reduce the amount of",
    "start": "283590",
    "end": "288900"
  },
  {
    "text": "network usage in your cluster so with",
    "start": "288900",
    "end": "294150"
  },
  {
    "text": "that I'm gonna talk about what are the recent developments in the world of scheduling in kubernetes one of the",
    "start": "294150",
    "end": "300780"
  },
  {
    "text": "areas of our focus have been performance so we wanted to improve performance of the scheduler as a part of that effort",
    "start": "300780",
    "end": "308040"
  },
  {
    "text": "and other than some of these algorithm algorithmic improvements we have done",
    "start": "308040",
    "end": "314000"
  },
  {
    "text": "we've added a new feature to the kubernetes schedule that they never had before",
    "start": "314000",
    "end": "319140"
  },
  {
    "text": "Borg and many other similar schedulers usually had this feature where once the",
    "start": "319140",
    "end": "325980"
  },
  {
    "text": "scheduler finds a certain number of nodes feasible in the cluster it picks one of those nodes and doesn't continue",
    "start": "325980",
    "end": "333000"
  },
  {
    "text": "scanning all the nodes in the cluster but kubernetes the scheduler didn't have this feature basically in a let's say in",
    "start": "333000",
    "end": "338670"
  },
  {
    "text": "a 5,000 cluster it would scan all the nodes for every single pod all the time",
    "start": "338670",
    "end": "344640"
  },
  {
    "text": "and as a result of course performance would drop but in large clusters like a",
    "start": "344640",
    "end": "350430"
  },
  {
    "text": "cluster of five thousand nodes we don't really need to scan all the nodes every time for example the cost the scheduler",
    "start": "350430",
    "end": "356880"
  },
  {
    "text": "can say ok I have already found 500 feasible nodes let's pick one of them",
    "start": "356880",
    "end": "361890"
  },
  {
    "text": "and move on so this feature basically helps you configure that so there is a",
    "start": "361890",
    "end": "368780"
  },
  {
    "text": "flag or a configuration parameter that you can specify what percentage of the",
    "start": "368780",
    "end": "374340"
  },
  {
    "text": "node the scheduler should find before it stops looking for more as you can see",
    "start": "374340",
    "end": "382050"
  },
  {
    "text": "here this has a relatively significant performance impact if you scan all the",
    "start": "382050",
    "end": "390240"
  },
  {
    "text": "nodes in a cluster on the very left side of this graph you see that the throughput of this of the scheduler is a",
    "start": "390240",
    "end": "397080"
  },
  {
    "text": "in a $5000 cereza but five parts per second but as you reduce",
    "start": "397080",
    "end": "402930"
  },
  {
    "text": "this percentage all the way to like five percent it can reach 290 parts over than",
    "start": "402930",
    "end": "409020"
  },
  {
    "text": "90 parts for 91 parts per second five percent in a five thousand note cluster",
    "start": "409020",
    "end": "414660"
  },
  {
    "text": "is still significant so basically it stops scanning for more nodes once it",
    "start": "414660",
    "end": "419850"
  },
  {
    "text": "finds 250 parts in that cluster by default this flag is set to fifty fifty",
    "start": "419850",
    "end": "426000"
  },
  {
    "text": "percent basically which is still high in large clusters it's still very high but",
    "start": "426000",
    "end": "431310"
  },
  {
    "text": "you can modify that if you run large development deployments we also have a",
    "start": "431310",
    "end": "436530"
  },
  {
    "text": "plan to make this semi-automatic basic you can you can still specify it if you",
    "start": "436530",
    "end": "442530"
  },
  {
    "text": "want but based on a cluster size it's automatically adjusted in the next",
    "start": "442530",
    "end": "448650"
  },
  {
    "text": "version or maybe do the version after that another area that really required",
    "start": "448650",
    "end": "454770"
  },
  {
    "text": "performance improvement is inter pod affinity and anti affinity all of those",
    "start": "454770",
    "end": "460830"
  },
  {
    "text": "folks who have tried to schedule the kubernetes in the past and have used inter pod affinity know that it was a",
    "start": "460830",
    "end": "468300"
  },
  {
    "text": "very very slow feature actually it was three orders of magnitude slower than",
    "start": "468300",
    "end": "473640"
  },
  {
    "text": "other features other scheduling features so it was so bad that we had to go and",
    "start": "473640",
    "end": "480150"
  },
  {
    "text": "mention in the documents that don't use this feature if you run any cluster of more than a couple hundred nodes or so",
    "start": "480150",
    "end": "486320"
  },
  {
    "text": "but we've had a kind of a breakthrough in improving performance of this feature",
    "start": "486320",
    "end": "493310"
  },
  {
    "text": "and from like six hundred millisecond for a single part in a 1,000 note",
    "start": "493310",
    "end": "498960"
  },
  {
    "text": "coaster we'd we reduced the time to five milliseconds this it's about 120 X",
    "start": "498960",
    "end": "505860"
  },
  {
    "text": "performance improvement so you can now actually use this feature more or less",
    "start": "505860",
    "end": "511290"
  },
  {
    "text": "similar to any other scheduling feature it's still slower about like maybe eight times slower than other features but",
    "start": "511290",
    "end": "516539"
  },
  {
    "text": "it's no longer like three orders of magnitude slower so it's usable in",
    "start": "516540",
    "end": "521669"
  },
  {
    "text": "clusters of multiple thousands of notes and one other feature is priority and",
    "start": "521670",
    "end": "529050"
  },
  {
    "text": "preemption kubernetes didn't have this feature at all in the past basically you couldn't specify",
    "start": "529050",
    "end": "534149"
  },
  {
    "text": "importance of your parts about with priority and preemption you can do so in",
    "start": "534149",
    "end": "539279"
  },
  {
    "text": "the past if your cluster was full and let's say autoscaler was not allowed to",
    "start": "539279",
    "end": "545820"
  },
  {
    "text": "add more nodes to the cluster or you had a cluster which was on-premise so you couldn't add more nodes to the cluster",
    "start": "545820",
    "end": "550980"
  },
  {
    "text": "and your cluster was full a new pod probably the important part was created",
    "start": "550980",
    "end": "557149"
  },
  {
    "text": "the pod couldn't be scheduled because kubernetes didn't have any notion of",
    "start": "557149",
    "end": "562649"
  },
  {
    "text": "importance but with priority you can provide that basically the higher the priority the more important your pod",
    "start": "562649",
    "end": "569700"
  },
  {
    "text": "will be now if let's say the cluster is full and a new pod or high-priority pod",
    "start": "569700",
    "end": "575190"
  },
  {
    "text": "is created the scheduler looks for pods with lower priority and if it finds them",
    "start": "575190",
    "end": "580649"
  },
  {
    "text": "somewhere in your cluster it removes those if it can schedule this high-priority pod so it deletes these",
    "start": "580649",
    "end": "587310"
  },
  {
    "text": "like low priority pods and schedules the high priority pod that's pretty much all",
    "start": "587310",
    "end": "595350"
  },
  {
    "text": "about the recent developments I would like to point out the plant features that we are targeting for for the",
    "start": "595350",
    "end": "603029"
  },
  {
    "text": "scheduler one is gang scheduling this is essentially a feature that tells the",
    "start": "603029",
    "end": "609240"
  },
  {
    "text": "scheduler either schedule all the pods or none of them well a kind of like an",
    "start": "609240",
    "end": "615660"
  },
  {
    "text": "expansion of this is to schedule at least the number of parts in a group or none of them why is this feature",
    "start": "615660",
    "end": "621870"
  },
  {
    "text": "important so some workloads are designed",
    "start": "621870",
    "end": "627480"
  },
  {
    "text": "to provide like sort of interdependency among pods so basically pods create input for one",
    "start": "627480",
    "end": "633779"
  },
  {
    "text": "another some ml workloads are examples of that or some MapReduce workloads are",
    "start": "633779",
    "end": "639390"
  },
  {
    "text": "examples of that what happens is that if you schedule instead of all of them like",
    "start": "639390",
    "end": "644970"
  },
  {
    "text": "half of them or a portion of them they will not progress so they basically get",
    "start": "644970",
    "end": "651540"
  },
  {
    "text": "to stock and whatever stay they are and if there is schedule they are just using",
    "start": "651540",
    "end": "656760"
  },
  {
    "text": "your cluster resources without making any progress so in those cases is better not to schedule any of them so gang",
    "start": "656760",
    "end": "663690"
  },
  {
    "text": "scheduling helps with that it has a lot of in batch processing and as I said in",
    "start": "663690",
    "end": "669630"
  },
  {
    "text": "machine learning as well we have a an incubator project called qubit Klaus is",
    "start": "669630",
    "end": "678330"
  },
  {
    "text": "actually leading that effort classes the other of segi scheduling lead he's",
    "start": "678330",
    "end": "684240"
  },
  {
    "text": "leading that effort and we have a proof of concept and cube batch we plan to",
    "start": "684240",
    "end": "690450"
  },
  {
    "text": "make it a standard feature in kubernetes is scheduler and party scheduling",
    "start": "690450",
    "end": "698160"
  },
  {
    "text": "policies so in a multi-tenant cluster some users can put certain scheduling",
    "start": "698160",
    "end": "704460"
  },
  {
    "text": "requirements on under pods preventing other users from scheduling their part or causing bad scheduling behavior in",
    "start": "704460",
    "end": "712860"
  },
  {
    "text": "your cluster for example if someone puts a very broad anti affinity on their pods",
    "start": "712860",
    "end": "719630"
  },
  {
    "text": "let's say anti affinity to almost any other part in the cluster or in anti",
    "start": "719630",
    "end": "726030"
  },
  {
    "text": "affinity to any other part in the same zone and they get lucky let's say that",
    "start": "726030",
    "end": "731760"
  },
  {
    "text": "their puzzle is created first in that zone and is scheduled in that zone that",
    "start": "731760",
    "end": "736920"
  },
  {
    "text": "part will prevent any other part in a cluster from getting scheduled there this is this is an example of a problem",
    "start": "736920",
    "end": "745380"
  },
  {
    "text": "in patanti affinity there are problems with toleration for example we use",
    "start": "745380",
    "end": "750690"
  },
  {
    "text": "taints and toleration for different applications one of them is that you for",
    "start": "750690",
    "end": "756450"
  },
  {
    "text": "example have expensive resources in your clusters let's say nodes with GPU or TPU",
    "start": "756450",
    "end": "762720"
  },
  {
    "text": "you go and take those nodes with let's say GPU and keep you taint to prevent pods that don't need those",
    "start": "762720",
    "end": "769350"
  },
  {
    "text": "resources from getting rescheduled there but if anybody is allowed to put",
    "start": "769350",
    "end": "774870"
  },
  {
    "text": "tolerate any kind of toleration on their part then a malicious user or now or an",
    "start": "774870",
    "end": "780210"
  },
  {
    "text": "uninformed user could put those toleration zhan their parts causing parts that don't require those resources",
    "start": "780210",
    "end": "786030"
  },
  {
    "text": "to get scheduled on those nodes so we think we need to have a way to to give",
    "start": "786030",
    "end": "794840"
  },
  {
    "text": "admin a mechanism to prevent these scenarios as a result we are designing party",
    "start": "794840",
    "end": "801680"
  },
  {
    "text": "scheduling policies these policies there are a few items here there are examples",
    "start": "801680",
    "end": "807230"
  },
  {
    "text": "of such policies for example you can specify what is the maximum priority in a namespace that users can use or what",
    "start": "807230",
    "end": "815180"
  },
  {
    "text": "kind of toleration z' are allowed or what kind of pot enter infinity is allowed you can also enforce some sort of node",
    "start": "815180",
    "end": "823550"
  },
  {
    "text": "affinity and anti affinity some users who run security sensitive applications know that they want to put some of the",
    "start": "823550",
    "end": "832010"
  },
  {
    "text": "nodes of the cluster for certain application in the cluster and not share",
    "start": "832010",
    "end": "837080"
  },
  {
    "text": "those nodes with any other work loading in the cluster so with party scheduling",
    "start": "837080",
    "end": "842510"
  },
  {
    "text": "policies you can enforce that all the parts that are created for example from such-and-such namespace get this",
    "start": "842510",
    "end": "848900"
  },
  {
    "text": "particular node affinity and all the pods all other parts cannot be scheduled on these certain a number of nodes or",
    "start": "848900",
    "end": "856400"
  },
  {
    "text": "group of nodes that are designed or that are dedicated to running security",
    "start": "856400",
    "end": "861710"
  },
  {
    "text": "sensitive applications another example in case that you run a cluster with",
    "start": "861710",
    "end": "868700"
  },
  {
    "text": "multiple scheduler is to enforce one type of scheduler or one of the schedulers in your cluster to schedule",
    "start": "868700",
    "end": "875420"
  },
  {
    "text": "some of the parts created in certain namespaces there is then the best",
    "start": "875420",
    "end": "884410"
  },
  {
    "text": "framework ever the scheduling front work so so on top of being the best framework",
    "start": "884410",
    "end": "894140"
  },
  {
    "text": "ever in the history of mankind the scheduling framework provides a certain",
    "start": "894140",
    "end": "900050"
  },
  {
    "text": "number of features so it's essentially a it provides a pair born of scheduling",
    "start": "900050",
    "end": "906140"
  },
  {
    "text": "which includes scheduling queue and a cache and some event handlers for",
    "start": "906140",
    "end": "912860"
  },
  {
    "text": "updating that cache and then the rest of the features of the scheduler become plug-ins for the scheduling framework so",
    "start": "912860",
    "end": "920510"
  },
  {
    "text": "essentially all these filters that we sometimes refer to as predicates and all the priority functions used for scoring",
    "start": "920510",
    "end": "927350"
  },
  {
    "text": "nodes although has become plug-ins for this scheduler also we add a",
    "start": "927350",
    "end": "933170"
  },
  {
    "text": "a number of extension points to provide even more flexibility for for you to",
    "start": "933170",
    "end": "939889"
  },
  {
    "text": "customize the scheduler if you need we we got a lot of feedback from our users",
    "start": "939889",
    "end": "945800"
  },
  {
    "text": "that many of them require make sometimes small changes to this scheduler to do",
    "start": "945800",
    "end": "952579"
  },
  {
    "text": "things slightly differently but there was no way of doing it in the past so the scheduling framework is an effort",
    "start": "952579",
    "end": "958670"
  },
  {
    "text": "towards a direction of making kubernetes customizing the scheduler easier and",
    "start": "958670",
    "end": "965389"
  },
  {
    "text": "maintaining it also easier so hopefully with this way this framework merging new",
    "start": "965389",
    "end": "971209"
  },
  {
    "text": "changes from upstream to your customized scheduled scheduler will be very easy it",
    "start": "971209",
    "end": "978290"
  },
  {
    "text": "also provides modularity so we can wholly debug our schedule is more easily",
    "start": "978290",
    "end": "984790"
  },
  {
    "text": "another effort which doesn't have a timeline at the moment at least is the",
    "start": "985149",
    "end": "991820"
  },
  {
    "text": "scheduler this is another incubator and siggy scheduling these scheduler",
    "start": "991820",
    "end": "997990"
  },
  {
    "text": "responsibilities essentially undoing what the scheduler does so as clusters",
    "start": "997990",
    "end": "1004990"
  },
  {
    "text": "run certain things in a cluster change for example we know we talked about",
    "start": "1004990",
    "end": "1010500"
  },
  {
    "text": "balancing resources in a cluster so the scheduler can try to balance amount of",
    "start": "1010500",
    "end": "1016329"
  },
  {
    "text": "resource usage in different nodes but after pods are terminated those balance",
    "start": "1016329",
    "end": "1022420"
  },
  {
    "text": "will change right the balance will change or I don't know maybe at the time",
    "start": "1022420",
    "end": "1028089"
  },
  {
    "text": "that the scheduler was the scheduling replicas of a replica said it couldn't put each replicas on a different node",
    "start": "1028089",
    "end": "1035620"
  },
  {
    "text": "because some of the notes didn't have enough resources so it had to put multiple of those replicas on a single",
    "start": "1035620",
    "end": "1041319"
  },
  {
    "text": "node but as time has passed some other nodes are available so some of these",
    "start": "1041319",
    "end": "1046839"
  },
  {
    "text": "replicas can be moved to other nodes so the scheduler essentially tries to remove some of the parts from the",
    "start": "1046839",
    "end": "1053260"
  },
  {
    "text": "cluster that violate some of the scheduling or they are not satisfying",
    "start": "1053260",
    "end": "1059020"
  },
  {
    "text": "all the preferences for scheduling with the hope that they can be moved to better nodes after getting",
    "start": "1059020",
    "end": "1065950"
  },
  {
    "text": "de scheduled as I said it's already available as an incubator and it",
    "start": "1065950",
    "end": "1072370"
  },
  {
    "text": "actually kind of works it's not feature-rich at the moment but we're",
    "start": "1072370",
    "end": "1078400"
  },
  {
    "text": "hoping that we can add more features and a more simulation to it in the near",
    "start": "1078400",
    "end": "1083980"
  },
  {
    "text": "future and finally Poseidon Poseidon is",
    "start": "1083980",
    "end": "1089260"
  },
  {
    "text": "a firmament based scheduler firmament as a scheduler came out of a research",
    "start": "1089260",
    "end": "1096190"
  },
  {
    "text": "project in Cambridge and Poseidon is sort of like a bridge between kubernetes",
    "start": "1096190",
    "end": "1103720"
  },
  {
    "text": "api to that firmament engine it achieves higher scheduling throughput in certain",
    "start": "1103720",
    "end": "1111040"
  },
  {
    "text": "scenarios so if you have like simple pods and your cluster basically parts that",
    "start": "1111040",
    "end": "1117370"
  },
  {
    "text": "don't use some of the more sophisticated features of the scheduler such as an affinity an anti affinity firmament can",
    "start": "1117370",
    "end": "1124960"
  },
  {
    "text": "achieve high rescheduling throughput we haven't tested it very electorally",
    "start": "1124960",
    "end": "1133360"
  },
  {
    "text": "in all scenarios but the the algorithmic latency of firmament is lower than our",
    "start": "1133360",
    "end": "1142380"
  },
  {
    "text": "standard scheduler and how much performance improvement we can get",
    "start": "1142380",
    "end": "1148120"
  },
  {
    "text": "end-to-end and in real class resistant not very well known but we're hoping",
    "start": "1148120",
    "end": "1154480"
  },
  {
    "text": "that we can we can achieve better performance at the end with a scheduler for batch and gang scheduling it's also",
    "start": "1154480",
    "end": "1163480"
  },
  {
    "text": "available as an incubator if you want to give it a spin feel free to try it you know with that",
    "start": "1163480",
    "end": "1170370"
  },
  {
    "text": "we can talk about other questions or comments that you have yes I actually",
    "start": "1170370",
    "end": "1178210"
  },
  {
    "text": "should probably give you the microphone",
    "start": "1178210",
    "end": "1182610"
  },
  {
    "text": "[Music] hi my first questions about some of the",
    "start": "1184490",
    "end": "1191780"
  },
  {
    "text": "limitations of kubernetes is stated in the documentation is five thousand nodes hundred parts per node yes",
    "start": "1191780",
    "end": "1199460"
  },
  {
    "text": "three hundred containers per node how much of that is schedulers limitation",
    "start": "1199460",
    "end": "1205540"
  },
  {
    "text": "good question yeah so the scheduler you know if you need higher throughputs you",
    "start": "1205540",
    "end": "1213020"
  },
  {
    "text": "know I saw you this slides that for example right now with default configuration of the scheduler in a five",
    "start": "1213020",
    "end": "1220520"
  },
  {
    "text": "thousand dollar cluster we can achieve about like fifty to fifty-five almost",
    "start": "1220520",
    "end": "1226100"
  },
  {
    "text": "fifty five pots per second right so if you want to have a two hundred parts per second throughput of the scheduling and",
    "start": "1226100",
    "end": "1233150"
  },
  {
    "text": "you push your cluster to five thousand nodes you will not get it if you don't care about the scheduling performance",
    "start": "1233150",
    "end": "1239450"
  },
  {
    "text": "schedule is not a bottleneck so it's basically down to how much throughput",
    "start": "1239450",
    "end": "1245390"
  },
  {
    "text": "you really need and I was I was just wondering about the pit pressure you",
    "start": "1245390",
    "end": "1251030"
  },
  {
    "text": "were talking about so I 100 pots for no either you have really small notes or really huge containers with lots of",
    "start": "1251030",
    "end": "1258110"
  },
  {
    "text": "processes is that like that 100 pots per node or 300 containers for node it's",
    "start": "1258110",
    "end": "1264440"
  },
  {
    "text": "kind of I don't understand what that assumption comes from I was wondering if I don't know either I'm not an expert",
    "start": "1264440",
    "end": "1271760"
  },
  {
    "text": "about like node I know about the scheduling site which is this like the",
    "start": "1271760",
    "end": "1278090"
  },
  {
    "text": "110 is not a requirement or restriction from the scheduler it's something I know",
    "start": "1278090",
    "end": "1283910"
  },
  {
    "text": "we should probably ask that question from the folks in a node yes you have an answer to that question or",
    "start": "1283910",
    "end": "1291820"
  },
  {
    "text": "[Music]",
    "start": "1299710",
    "end": "1302909"
  },
  {
    "text": "yeah I think I may have been the person who put that number on a piece of paper",
    "start": "1304870",
    "end": "1310570"
  },
  {
    "text": "somewhere but basically you have nodes of a certain size particularly relating",
    "start": "1310570",
    "end": "1316000"
  },
  {
    "text": "to memory usually and to have useful containers then usually need a certain amount of memory and if you take them",
    "start": "1316000",
    "end": "1322960"
  },
  {
    "text": "the amount of RAM and you know typical big servers and the typical sizes of containers you you end up in there sort",
    "start": "1322960",
    "end": "1329020"
  },
  {
    "text": "of around about a hundred container 100 pods range so I'm sure there are exceptions there's a six scalability has",
    "start": "1329020",
    "end": "1336700"
  },
  {
    "text": "a document which describes exactly where a lot of these limits are derived from but I don't think it's got anything to",
    "start": "1336700",
    "end": "1343270"
  },
  {
    "text": "do with scheduling it's got to do with available resources on typical nodes yeah thank you",
    "start": "1343270",
    "end": "1350040"
  },
  {
    "text": "there's a question I had a question about pod scheduling policies I think",
    "start": "1350040",
    "end": "1356590"
  },
  {
    "text": "they're a really great idea I think there's been something that's been lacking for a while but - particularly around preventing people",
    "start": "1356590",
    "end": "1362080"
  },
  {
    "text": "that can create pods from creating pods on master nodes masters registers nodes you can just kind of tolerate the taint",
    "start": "1362080",
    "end": "1367390"
  },
  {
    "text": "and get out there we actually wrote something to do something like this to",
    "start": "1367390",
    "end": "1372490"
  },
  {
    "text": "apply scheduling data to pods as they're created so we target labels and then we",
    "start": "1372490",
    "end": "1377740"
  },
  {
    "text": "say if you've got these labels we actually put affinity or toleration x' or anything on them right so I think",
    "start": "1377740",
    "end": "1384250"
  },
  {
    "text": "that's that was really useful my question is where are you doing this and can I I mean our projects great it's open source I love it you but it uses",
    "start": "1384250",
    "end": "1390640"
  },
  {
    "text": "initializers and it's another thing you have to run so where do you plan on applying pod security policy is it",
    "start": "1390640",
    "end": "1396400"
  },
  {
    "text": "actually the scheduler modifying the pod specs after they're created that's a good question so we are still designing",
    "start": "1396400",
    "end": "1402580"
  },
  {
    "text": "this feature but the latest development and this is that we are gonna have to places to enforce these policies one is",
    "start": "1402580",
    "end": "1408820"
  },
  {
    "text": "at the admission time and the other one is at the runtime basically dynamically the reason that the scheduler needs to",
    "start": "1408820",
    "end": "1414940"
  },
  {
    "text": "be involved is that sometimes they note that is eventually chosen for running the part should be should be evaluated",
    "start": "1414940",
    "end": "1421660"
  },
  {
    "text": "against those scheduling policies at the admission time when a pod is created it",
    "start": "1421660",
    "end": "1427060"
  },
  {
    "text": "doesn't have a note associated with it but the scheduler is the only component that eventually picks a note and after",
    "start": "1427060",
    "end": "1433720"
  },
  {
    "text": "it picks a note for the part it can it can evaluate that note against the policies and if the note violates those",
    "start": "1433720",
    "end": "1440080"
  },
  {
    "text": "policies it can go and ask for and we can go and scan for another node in the cluster I may be out of date but as far",
    "start": "1440080",
    "end": "1457390"
  },
  {
    "text": "as I remember you have like in Copernicus there are like two scheduler one for team onset and for what there",
    "start": "1457390",
    "end": "1464410"
  },
  {
    "text": "was it's been converged now yes there's 12 I think okay",
    "start": "1464410",
    "end": "1470740"
  },
  {
    "text": "we have only one schedule okay that's mr. Sarnowski but you're right demons",
    "start": "1470740",
    "end": "1476559"
  },
  {
    "text": "are now scheduled by the default of schedule is what so yeah so actually",
    "start": "1476559",
    "end": "1502740"
  },
  {
    "text": "demon said controller still creates demons at pod and it adds some of those",
    "start": "1502740",
    "end": "1508360"
  },
  {
    "text": "toleration by default so that the default schedule actually takes care of",
    "start": "1508360",
    "end": "1514929"
  },
  {
    "text": "those things one follow-up on the demon set schedule eNOS I wanted to ask our",
    "start": "1514929",
    "end": "1525940"
  },
  {
    "text": "demon sets still broken like I do",
    "start": "1525940",
    "end": "1532840"
  },
  {
    "text": "remember we had some issues with admission for demon sets I don't I",
    "start": "1532840",
    "end": "1539740"
  },
  {
    "text": "wanted to know if these were fixed or not for example we had some issues with",
    "start": "1539740",
    "end": "1546330"
  },
  {
    "text": "but the not obeyed into not selectors and stuff like that I want to know if it",
    "start": "1546330",
    "end": "1554140"
  },
  {
    "text": "was fixed or not I am not aware of any broken thinking demon sets but hey I'm",
    "start": "1554140",
    "end": "1575770"
  },
  {
    "text": "Tomas I maintain one of the maintenance for the diamond set so the thing is when",
    "start": "1575770",
    "end": "1583660"
  },
  {
    "text": "to switch to the new scheduler oh maybe back to the problem the problem usually is you have some admission that",
    "start": "1583660",
    "end": "1590410"
  },
  {
    "text": "modifies the pots and the demon said controller schedules all it now doesn't",
    "start": "1590410",
    "end": "1596890"
  },
  {
    "text": "schedule them entirely but it chooses the note either way and it does that",
    "start": "1596890",
    "end": "1601960"
  },
  {
    "text": "before the your admission modifies the pot so if you like change the note",
    "start": "1601960",
    "end": "1607150"
  },
  {
    "text": "selector it doesn't see that so the way",
    "start": "1607150",
    "end": "1612429"
  },
  {
    "text": "it used to be it scheduled the pot to denote anyways even your admission",
    "start": "1612429",
    "end": "1618910"
  },
  {
    "text": "modified a note select and not to match that note so cubelet fell to that port",
    "start": "1618910",
    "end": "1624760"
  },
  {
    "text": "and then one set has just recreated it and it was folly fighting all over so if",
    "start": "1624760",
    "end": "1629890"
  },
  {
    "text": "you are running like an old version of cube update and basically you're saying",
    "start": "1629890",
    "end": "1637870"
  },
  {
    "text": "that after we switch to the default scheduler for scheduling demons and this problems will go away well it will stay",
    "start": "1637870",
    "end": "1645010"
  },
  {
    "text": "in pending so I say yeah if you have very restrictive node selected that right it's a lit after admission or like",
    "start": "1645010",
    "end": "1652840"
  },
  {
    "text": "during the admission you can have like thousands put in pending but at least",
    "start": "1652840",
    "end": "1657940"
  },
  {
    "text": "now it doesn't go into hot loop and doesn't just delete the port and create it again queue but failed it and it was",
    "start": "1657940",
    "end": "1665350"
  },
  {
    "text": "really bad now it basically just have a big queue and the purple solution is not",
    "start": "1665350",
    "end": "1671230"
  },
  {
    "text": "so simple and we are kind of working on it but it will be few releases at least",
    "start": "1671230",
    "end": "1678059"
  },
  {
    "text": "all right thank you when you talked about the D scheduling",
    "start": "1678059",
    "end": "1685380"
  },
  {
    "text": "helping with node anti affinity does that mean if there's no I'm sorry yeah",
    "start": "1685380",
    "end": "1693930"
  },
  {
    "text": "does that imply that if I have anti affinity to you you make a scheduling decision put me on a node then a Nestle",
    "start": "1693930",
    "end": "1702060"
  },
  {
    "text": "another scheduling decision will allow you to be on that node yeah scheduling me off so now actually the scheduler",
    "start": "1702060",
    "end": "1710430"
  },
  {
    "text": "never violates those like and if you have and required anti affinity the",
    "start": "1710430",
    "end": "1715860"
  },
  {
    "text": "scheduler will not ever put you only two parts that violate that anti affinity on",
    "start": "1715860",
    "end": "1721830"
  },
  {
    "text": "the same node for example but there are certain things can change in the cluster for example let's say that you add new",
    "start": "1721830",
    "end": "1729300"
  },
  {
    "text": "labels to your parts after they are scheduled or you add new labels to some",
    "start": "1729300",
    "end": "1735210"
  },
  {
    "text": "of the nodes in the cluster that are already running some parts and those labels cause after the after all these",
    "start": "1735210",
    "end": "1742320"
  },
  {
    "text": "positive schedule caused the violation of some of the anti affinity rules so basically this is a run time check the",
    "start": "1742320",
    "end": "1749280"
  },
  {
    "text": "schedule does the run time check if after addition of those labels some of these rules are violated in the schedule",
    "start": "1749280",
    "end": "1756270"
  },
  {
    "text": "removes those those parts but or sometimes you may have preferred anti",
    "start": "1756270",
    "end": "1762270"
  },
  {
    "text": "affinity so preferred anti affinity may not be satisfied at the time that you is",
    "start": "1762270",
    "end": "1767400"
  },
  {
    "text": "scheduling the parts right so and then later on the scheduler finds out that there are better opportunities for",
    "start": "1767400",
    "end": "1773220"
  },
  {
    "text": "moving some of these parts around so that those preferences satisfied then it removes the parts questions so ok you",
    "start": "1773220",
    "end": "1787820"
  },
  {
    "text": "decide a question about the scoring changes so first did you look at",
    "start": "1787850",
    "end": "1793800"
  },
  {
    "text": "efficiency like sorry efficiency of packing like when you toggled how many",
    "start": "1793800",
    "end": "1799650"
  },
  {
    "text": "you were actually scoring like was there actually a you know just scoring fewer really meaningfully",
    "start": "1799650",
    "end": "1804870"
  },
  {
    "text": "actually impacts how well you end up packing the cluster so I believe you are",
    "start": "1804870",
    "end": "1810210"
  },
  {
    "text": "talking about this number of number of nodes that you are considering we don't but the scheduler now has a",
    "start": "1810210",
    "end": "1817620"
  },
  {
    "text": "more advanced iterator for nodes so it tries to basically instead of just",
    "start": "1817620",
    "end": "1825260"
  },
  {
    "text": "looking in an array of nodes and going from beginning to the end it goes",
    "start": "1825260",
    "end": "1830909"
  },
  {
    "text": "through like noticing different figures failure domains and basically different zones and it also continues from the",
    "start": "1830909",
    "end": "1839340"
  },
  {
    "text": "point that it like basically left off when app uses scheduling cycle so it",
    "start": "1839340",
    "end": "1847019"
  },
  {
    "text": "tries to tries to satisfy some of these",
    "start": "1847019",
    "end": "1852179"
  },
  {
    "text": "preferences but of course when you when you reduce that percentage to lower",
    "start": "1852179",
    "end": "1857669"
  },
  {
    "text": "values you will you may see some compromises in terms of the scheduling",
    "start": "1857669",
    "end": "1862980"
  },
  {
    "text": "preference right and then the other questions you mentioned and I know I've read about it but I haven't bothered to",
    "start": "1862980",
    "end": "1868590"
  },
  {
    "text": "look at how it does it the preference to schedule to a pod that already has the image what does it use to determine that",
    "start": "1868590",
    "end": "1875600"
  },
  {
    "text": "what is the what what what is the use you said yeah like what's the heuristic",
    "start": "1875600",
    "end": "1881519"
  },
  {
    "text": "that he uses to determine that the pod already has the image so pods are actually cubelets report the images that",
    "start": "1881519",
    "end": "1889049"
  },
  {
    "text": "exists on the notes so the scheduler knows about the existence of those images it's not here is it really",
    "start": "1889049",
    "end": "1897138"
  },
  {
    "text": "hi I wanted to ask about a new feature about eviction now you mentioned you",
    "start": "1901980",
    "end": "1907360"
  },
  {
    "text": "have three priorities high medium and low now priorities are user definable so you can you can add as many as I want a",
    "start": "1907360",
    "end": "1914190"
  },
  {
    "text": "float integer they are integers they are integers but you know it can be negative minus two",
    "start": "1914190",
    "end": "1920830"
  },
  {
    "text": "billion two billion hopefully that's like good enough French for everybody",
    "start": "1920830",
    "end": "1926790"
  },
  {
    "text": "this mm probably isn't necessarily your problem but I guess something that we",
    "start": "1929220",
    "end": "1934810"
  },
  {
    "text": "frequently run into is when we have you know a massive failure notes of our massive amount of rescheduling in a",
    "start": "1934810",
    "end": "1940630"
  },
  {
    "text": "cluster it can kind of overwhelm the Kubla and container engine like trying",
    "start": "1940630",
    "end": "1946450"
  },
  {
    "text": "to put you know 50 60 pods on one node at a time I guess maybe like again it when I say",
    "start": "1946450",
    "end": "1952990"
  },
  {
    "text": "it it sounds like this is really a node problem that a schedule of a problem but I don't know if there's been discussion about who should be responsible for sort",
    "start": "1952990",
    "end": "1958570"
  },
  {
    "text": "of fixing that problem so we have we have an actually a feature to limit the",
    "start": "1958570",
    "end": "1963940"
  },
  {
    "text": "number of pots on a on a particular node so there is a max pot per node which can",
    "start": "1963940",
    "end": "1969550"
  },
  {
    "text": "be changed if you if you want fewer pots on a particular node but not the problem",
    "start": "1969550",
    "end": "1974830"
  },
  {
    "text": "you're talking about is a little bit more than this probably if you I guess",
    "start": "1974830",
    "end": "1980410"
  },
  {
    "text": "this is actually mmm this should be addressed at different levels I guess",
    "start": "1980410",
    "end": "1986080"
  },
  {
    "text": "then the scheduler mm-hmm but I would like to understand the situation a little bit better that causes this to",
    "start": "1986080",
    "end": "1993010"
  },
  {
    "text": "start actually so you see that there are a lot of failures in your clusters",
    "start": "1993010",
    "end": "1998320"
  },
  {
    "text": "because of yeah like let's say you know we're have a multi zone cluster and we",
    "start": "1998320",
    "end": "2004800"
  },
  {
    "text": "have like a stateful application and we use preferred zone anti affinity right",
    "start": "2004800",
    "end": "2009960"
  },
  {
    "text": "and so just so that we're not stuck in a state where we don't have at least a little bit of resiliency for that data",
    "start": "2009960",
    "end": "2015540"
  },
  {
    "text": "will often reschedule into another zone like will autoscaler zone to provide the",
    "start": "2015540",
    "end": "2020610"
  },
  {
    "text": "additional capacity and reschedule those pods from like the third zone unto those and it could be thousands and thousands",
    "start": "2020610",
    "end": "2026610"
  },
  {
    "text": "of pods right and like the problem is that it's it's not that so like let's say I",
    "start": "2026610",
    "end": "2032430"
  },
  {
    "text": "add you know 50 new nodes to his own and I have to schedule a thousand pods like",
    "start": "2032430",
    "end": "2037530"
  },
  {
    "text": "it's not that there's not enough capacity at a steady state it's that the",
    "start": "2037530",
    "end": "2042570"
  },
  {
    "text": "container engines and the couplet like really are not very good at starting up a huge number of processes in parallel",
    "start": "2042570",
    "end": "2050370"
  },
  {
    "text": "and so this is basically a burst of pods all getting you scheduled on a on a",
    "start": "2050370",
    "end": "2056940"
  },
  {
    "text": "single now again there's a kid well you know this is kind of like an oxymoron to",
    "start": "2056940",
    "end": "2062490"
  },
  {
    "text": "scheduling throughput right so if you want to improve scheduling throughput scenarios like this could become more",
    "start": "2062490",
    "end": "2069600"
  },
  {
    "text": "common I guess this should be addressed at like cubelets I'd probably or maybe we can",
    "start": "2069600",
    "end": "2077070"
  },
  {
    "text": "somehow rate limit the number of path creation yeah but I think in the end",
    "start": "2077070",
    "end": "2082620"
  },
  {
    "text": "it's just a battle royale between you and the Kubla team to basically figure who's gonna make this thing not doctor right side all right but but thanks for",
    "start": "2082620",
    "end": "2089970"
  },
  {
    "text": "the feedback sure",
    "start": "2089970",
    "end": "2092630"
  },
  {
    "text": "faster nodes yeah so I have a question",
    "start": "2096500",
    "end": "2107150"
  },
  {
    "text": "about the sort of future landscape of schedulers so there's a couple in Aikido right now do you see a world where",
    "start": "2107150",
    "end": "2113750"
  },
  {
    "text": "there's a year or two down the line where there's one scheduler to rule a model or do you see that there's gonna",
    "start": "2113750",
    "end": "2119960"
  },
  {
    "text": "be a multiple schedulers in the long term and in that world what's the compatibility story gonna be",
    "start": "2119960",
    "end": "2125420"
  },
  {
    "text": "like yeah that's a good question actually from the very beginning we've decided we've tried to make kubernetes",
    "start": "2125420",
    "end": "2132109"
  },
  {
    "text": "motto a scheduler friendly and we are we're gonna do that but the reality is",
    "start": "2132109",
    "end": "2139099"
  },
  {
    "text": "that in a cluster which is under a high churn multiple schedules are going to",
    "start": "2139099",
    "end": "2145970"
  },
  {
    "text": "compete against one another unless you have very clear partitioning among the",
    "start": "2145970",
    "end": "2151040"
  },
  {
    "text": "nodes or very clear partitioning among the parts you know because positing kubernetes can have a scheduler name and",
    "start": "2151040",
    "end": "2157400"
  },
  {
    "text": "you can basically direct them to one schedule or the other so and then they",
    "start": "2157400",
    "end": "2163010"
  },
  {
    "text": "can also have no affinity so that for example the scheduler knows what group of nodes it wants to schedule them on if",
    "start": "2163010",
    "end": "2170720"
  },
  {
    "text": "you follow those practices and the possibility of Contin to scheduler",
    "start": "2170720",
    "end": "2176000"
  },
  {
    "text": "competing with one other and one another well reduce but otherwise there will be a lot of competition between two",
    "start": "2176000",
    "end": "2182329"
  },
  {
    "text": "schedulers and sometimes you may see your pods getting rejected by cubelet because two schedules will leave that",
    "start": "2182329",
    "end": "2187520"
  },
  {
    "text": "there are available resources on that note both of them schedule their own pods on that now then what one of them",
    "start": "2187520",
    "end": "2193460"
  },
  {
    "text": "gets rejected so we are going to keep having kubernetes multiple scheduler",
    "start": "2193460",
    "end": "2200990"
  },
  {
    "text": "friendly but for standard components we believe that we should probably go with",
    "start": "2200990",
    "end": "2206420"
  },
  {
    "text": "a single scheduler that supports multiple features so for one of the",
    "start": "2206420",
    "end": "2211609"
  },
  {
    "text": "incubator schedulers to get so to graduate it out would it need full compatibility with the default",
    "start": "2211609",
    "end": "2217130"
  },
  {
    "text": "schedulers behavior in terms of you know affinity and all the other things that it salts or supports or do you see a",
    "start": "2217130",
    "end": "2222920"
  },
  {
    "text": "world where it could graduate out with an own sort of sort of limitation so those those features that we support in",
    "start": "2222920",
    "end": "2230210"
  },
  {
    "text": "defaulted scheduler are part of kubernetes api so definitely any other scheduler that wants to be in standard",
    "start": "2230210",
    "end": "2238160"
  },
  {
    "text": "has to support kubernetes api as well and yes there should be compatibility so",
    "start": "2238160",
    "end": "2249050"
  },
  {
    "text": "I'm interested in the kind of memory usage behavior of the core services and",
    "start": "2249050",
    "end": "2255950"
  },
  {
    "text": "so how does scheduling how does the scheduler memory usage behave with lots",
    "start": "2255950",
    "end": "2262070"
  },
  {
    "text": "of nodes lots of pods because these are scenarios that I haven't tested yet yeah so of course especially especially when",
    "start": "2262070",
    "end": "2270680"
  },
  {
    "text": "the number of nodes grow in a cluster and also number of particle in a cluster the scheduling memory footprint is going",
    "start": "2270680",
    "end": "2276680"
  },
  {
    "text": "to go up as well and depending on what feature is actually using and with your part memory footprint could could be",
    "start": "2276680",
    "end": "2284510"
  },
  {
    "text": "different but we have our scalability tests that actually emit some of just",
    "start": "2284510",
    "end": "2291020"
  },
  {
    "text": "data as well I believe for scheduling",
    "start": "2291020",
    "end": "2296480"
  },
  {
    "text": "like a hundred fifty thousand powers in a fighter and a five thousand node cluster the scheduler memory footprint",
    "start": "2296480",
    "end": "2302570"
  },
  {
    "text": "could be a few gigabytes so it's it's",
    "start": "2302570",
    "end": "2307940"
  },
  {
    "text": "doing a lot of things and it it could be significant well that still sounds",
    "start": "2307940",
    "end": "2313430"
  },
  {
    "text": "pretty good it's still not too bad yeah it's much better than a the API server I gonna leave so general I have a question",
    "start": "2313430",
    "end": "2325940"
  },
  {
    "text": "about Zuko scheduler so some sometimes",
    "start": "2325940",
    "end": "2331460"
  },
  {
    "text": "you are trying to optimize for opt throughput of the scheduler in some",
    "start": "2331460",
    "end": "2338359"
  },
  {
    "text": "scenario maybe we want to be it more one way schedule apart will need to be more",
    "start": "2338359",
    "end": "2344270"
  },
  {
    "text": "cost-effective one efficient we want to do a better job on bin packing for all",
    "start": "2344270",
    "end": "2349880"
  },
  {
    "text": "the parts and on the other side maybe we announce on some other case maybe you",
    "start": "2349880",
    "end": "2355310"
  },
  {
    "text": "will want to emphasize small on part of phonetic so how do you balance between",
    "start": "2355310",
    "end": "2360650"
  },
  {
    "text": "the different goals because they can they can conflict with each other they don't necessarily",
    "start": "2360650",
    "end": "2366160"
  },
  {
    "text": "conflict all the time so if we for example achieve better algorithmic",
    "start": "2366160",
    "end": "2371960"
  },
  {
    "text": "improvements without really compromising validity of the result we can we can",
    "start": "2371960",
    "end": "2380359"
  },
  {
    "text": "have higher performance without any compromise on the end result basically",
    "start": "2380359",
    "end": "2386030"
  },
  {
    "text": "but in some cases like what you saw like scoring fewer fewer nodes in the cluster",
    "start": "2386030",
    "end": "2392619"
  },
  {
    "text": "that can be the case so when you score fewer nodes in the cluster the quality",
    "start": "2392619",
    "end": "2398630"
  },
  {
    "text": "of the scheduling could could be reduced and some of your preferences essentially",
    "start": "2398630",
    "end": "2403730"
  },
  {
    "text": "may not be satisfied this is most this is only about preferences all the requirements of the API duelist will be",
    "start": "2403730",
    "end": "2411829"
  },
  {
    "text": "satisfied so in those cases we have made this configurable for that reason so we",
    "start": "2411829",
    "end": "2419270"
  },
  {
    "text": "can change the configuration to let's say score 100 percent of the parts so that you can guarantee that you will",
    "start": "2419270",
    "end": "2425569"
  },
  {
    "text": "achieve like the highest quality of schedule so basically it's a stew like a so as a user needs to be very careful",
    "start": "2425569",
    "end": "2434540"
  },
  {
    "text": "about the configuration of the scheduler right but to achieve there a particular goal or a practical level you said I",
    "start": "2434540",
    "end": "2441680"
  },
  {
    "text": "mean like it's sure the users responsibility should be very careful about how to configure their scheduler",
    "start": "2441680",
    "end": "2448460"
  },
  {
    "text": "to achieve their particular so I I believe the default configuration that the scheduler is currently shaped with",
    "start": "2448460",
    "end": "2454700"
  },
  {
    "text": "it's pretty good in terms of you know satisfying almost like 99% of the user",
    "start": "2454700",
    "end": "2461210"
  },
  {
    "text": "requirements but if someone really wants to emphasize on one aspect of to",
    "start": "2461210",
    "end": "2467270"
  },
  {
    "text": "scheduling wants to ensure that no cost for some reason is very optimized then",
    "start": "2467270",
    "end": "2474680"
  },
  {
    "text": "they can go and configure the scheduler in the way they like and actually the scheduling framework that we are also",
    "start": "2474680",
    "end": "2480589"
  },
  {
    "text": "working on is an effort to as that direction of giving you sort of like all the freedom to customize the scheduler",
    "start": "2480589",
    "end": "2487790"
  },
  {
    "text": "to your needs okay thank you yeah sure",
    "start": "2487790",
    "end": "2492760"
  },
  {
    "text": "thank you um I have a two question one is to have any like projection about the",
    "start": "2494299",
    "end": "2500960"
  },
  {
    "text": "performance of the scheduling throughput in like 18 months something like moore's",
    "start": "2500960",
    "end": "2506490"
  },
  {
    "text": "law like that's a good question well",
    "start": "2506490",
    "end": "2512490"
  },
  {
    "text": "first of all it's hard to predict but we have certain goals that you want to achieve so our goal is to reach 100",
    "start": "2512490",
    "end": "2520829"
  },
  {
    "text": "parts per second in a 5,000 node cluster and our hope is that in 114 which is",
    "start": "2520829",
    "end": "2527249"
  },
  {
    "text": "gonna be released in about three months we are gonna achieve that so 100 parts per second is the is our goal but one",
    "start": "2527249",
    "end": "2535049"
  },
  {
    "text": "thing that to note here is that the scheduler has the rate limitation for",
    "start": "2535049",
    "end": "2541230"
  },
  {
    "text": "sending bound requests to the API server all right so let's say that we achieve I don't know a thousand parts per second",
    "start": "2541230",
    "end": "2547740"
  },
  {
    "text": "we cannot send a thousand point requests to the API server it will overload the API server in fact our scalability team",
    "start": "2547740",
    "end": "2554880"
  },
  {
    "text": "looked at this rate limitation and noticed that raising the rate limitation",
    "start": "2554880",
    "end": "2560849"
  },
  {
    "text": "from like 20 parts per second to 50 parts per second causes one whole CPU",
    "start": "2560849",
    "end": "2567839"
  },
  {
    "text": "core more user basically more usage on the master node so that's quite",
    "start": "2567839",
    "end": "2573930"
  },
  {
    "text": "sensitive and we while we're trying to improve the scheduler throughput going",
    "start": "2573930",
    "end": "2581400"
  },
  {
    "text": "further than a certain number is not going to help much because we still need to rate limit the number of points that",
    "start": "2581400",
    "end": "2588269"
  },
  {
    "text": "we send to the API server okay I guess you partially answer my second question about the future direction for improving",
    "start": "2588269",
    "end": "2594989"
  },
  {
    "text": "the scheduling support and the youb you cover about the like API server like",
    "start": "2594989",
    "end": "2601369"
  },
  {
    "text": "limitation and the except that is there any other aspects that we can work on to",
    "start": "2601369",
    "end": "2607140"
  },
  {
    "text": "like improve you want to answer that question",
    "start": "2607140",
    "end": "2612380"
  },
  {
    "text": "as I said that if you want to improve the whole circle actually some",
    "start": "2613690",
    "end": "2619970"
  },
  {
    "text": "multi-factor multi expect you to impact you so because yeah every component is",
    "start": "2619970",
    "end": "2626990"
  },
  {
    "text": "pushing stuff to the API server and ethnicity and if at is it is name it is",
    "start": "2626990",
    "end": "2632510"
  },
  {
    "text": "there what Hank if it is city is not improved what we can improve is on the",
    "start": "2632510",
    "end": "2638750"
  },
  {
    "text": "other aspect so as far as I know so right now in Cabin NES there is already someone for example if if you",
    "start": "2638750",
    "end": "2644570"
  },
  {
    "text": "know a no hot bit so normally in I think in those in current versions every ten",
    "start": "2644570",
    "end": "2652610"
  },
  {
    "text": "seconds you were to try to send a habit to it has server IP f so HDD so you have",
    "start": "2652610",
    "end": "2658430"
  },
  {
    "text": "four five thousand that is so right every 10 minutes I'm sorry",
    "start": "2658430",
    "end": "2664280"
  },
  {
    "text": "every 10 seconds is just give a happy to be a server so and right now I think in",
    "start": "2664280",
    "end": "2670700"
  },
  {
    "text": "113 or 114 they are improving this signal is kind of trying to do a delta",
    "start": "2670700",
    "end": "2678710"
  },
  {
    "text": "or something habits kind of regularly they're worse than one habit every more minute and depends on whether they have",
    "start": "2678710",
    "end": "2685820"
  },
  {
    "text": "real information update then there was an update and also I think there is",
    "start": "2685820",
    "end": "2691250"
  },
  {
    "text": "socio improvement are other views for example if I check out the life cycle",
    "start": "2691250",
    "end": "2697850"
  },
  {
    "text": "apart there are several phases like create a pod and the scheduler will try to do the",
    "start": "2697850",
    "end": "2704810"
  },
  {
    "text": "no name binding right that also has the API server history and also in the queue",
    "start": "2704810",
    "end": "2711020"
  },
  {
    "text": "later side there are also some intermediate status updated to hit the",
    "start": "2711020",
    "end": "2716690"
  },
  {
    "text": "industry API server so those parts I think can also be improved so it's it's",
    "start": "2716690",
    "end": "2722240"
  },
  {
    "text": "kind of yeah every part can be improved so right now I think for schedule we are we will try to achieve 100 pass for 5000",
    "start": "2722240",
    "end": "2731030"
  },
  {
    "text": "and for other is improved yeah basically the select short answer to your question",
    "start": "2731030",
    "end": "2737600"
  },
  {
    "text": "is that scalability is a multi-dimensional problem and it should be addressed in",
    "start": "2737600",
    "end": "2745250"
  },
  {
    "text": "many different demand in order to have a like a global higher",
    "start": "2745250",
    "end": "2750730"
  },
  {
    "text": "scalability as as use you mentioned and we also mentioned we will face some",
    "start": "2750730",
    "end": "2756940"
  },
  {
    "text": "issues on the API server if we push the scheduler throughput beyond a certain",
    "start": "2756940",
    "end": "2762010"
  },
  {
    "text": "point we've similarly we may face other problems with respect to IP routing and",
    "start": "2762010",
    "end": "2768460"
  },
  {
    "text": "in our clusters there were some issues with domain name resolution if you ran",
    "start": "2768460",
    "end": "2773980"
  },
  {
    "text": "many services in your cluster there were some issues with a very large number of",
    "start": "2773980",
    "end": "2780099"
  },
  {
    "text": "volumes dynamic volumes in the cluster so it's not just something we can we can",
    "start": "2780099",
    "end": "2785650"
  },
  {
    "text": "address in one place and say we should resolve the problem it's a multi team",
    "start": "2785650",
    "end": "2790660"
  },
  {
    "text": "effort that we are trying to actually address yeah sure maybe one last",
    "start": "2790660",
    "end": "2798700"
  },
  {
    "text": "question here",
    "start": "2798700",
    "end": "2801359"
  },
  {
    "text": "the switch was at the bottom that's",
    "start": "2806280",
    "end": "2813400"
  },
  {
    "text": "really hard finding what is the plan for multi anti affinity where there's more",
    "start": "2813400",
    "end": "2819070"
  },
  {
    "text": "than one like two pods per failure domain instead of or two or three or ten or some percentage instead of like one",
    "start": "2819070",
    "end": "2826120"
  },
  {
    "text": "right because right now that's that's all you've got like there's a chicken on it but they kind of went nowhere yeah so",
    "start": "2826120",
    "end": "2831490"
  },
  {
    "text": "I guess they could answer that question better but anyways we're trying to to",
    "start": "2831490",
    "end": "2836890"
  },
  {
    "text": "solve that problem we were thinking that maybe we can we can add that feature in",
    "start": "2836890",
    "end": "2843100"
  },
  {
    "text": "the next version depending on race availability we may or may not be able to achieve that but anyways it's in our",
    "start": "2843100",
    "end": "2850930"
  },
  {
    "text": "radar and we are aware of that problem we actually worked on this problem in the past but since anti-authority was",
    "start": "2850930",
    "end": "2858250"
  },
  {
    "text": "and generally inter-party affinity was a thousand times slower we decided at that",
    "start": "2858250",
    "end": "2863620"
  },
  {
    "text": "point we shouldn't add any more features to it until we address the scalability",
    "start": "2863620",
    "end": "2868870"
  },
  {
    "text": "and performance issues there so now that those are kind of gone we can think about adding more features and this is",
    "start": "2868870",
    "end": "2874930"
  },
  {
    "text": "certainly one of those most requested features for inter pod affinity and we're working on it sure yeah well yeah",
    "start": "2874930",
    "end": "2881590"
  },
  {
    "text": "if you can add that and combine out 2d scheduler then you can get kind of a guaranteed pod distribution where best",
    "start": "2881590",
    "end": "2886660"
  },
  {
    "text": "effort to keep n replicas across domains sorry mate that's a good feature thank you yeah sure defend yourself yeah this",
    "start": "2886660",
    "end": "2897970"
  },
  {
    "text": "is this is a real this is a real problem because I saw some some users yes",
    "start": "2897970",
    "end": "2903160"
  },
  {
    "text": "especially if you're especially for anti affinity because right now the schedule Adam the minimum mean Union is apart but",
    "start": "2903160",
    "end": "2910690"
  },
  {
    "text": "I think about the rolling update case right if you're rolling update existing one is still there and you feel you",
    "start": "2910690",
    "end": "2917680"
  },
  {
    "text": "won't want to replace that not just replace no real places just hold one and",
    "start": "2917680",
    "end": "2923740"
  },
  {
    "text": "try to spin why and to replace that well but the the new one has no chance to be",
    "start": "2923740",
    "end": "2930400"
  },
  {
    "text": "to be scheduled at that one so if we can have this feature of course",
    "start": "2930400",
    "end": "2935500"
  },
  {
    "text": "the rowing update issue can be resolved so right now what I can come and there is for your department I try",
    "start": "2935500",
    "end": "2941590"
  },
  {
    "text": "to use the recreate strategy rather than struggle are I have one more question",
    "start": "2941590",
    "end": "2953710"
  },
  {
    "text": "Megan quickly please okay so it's about people like supporting for us so this kind of",
    "start": "2953710",
    "end": "2959860"
  },
  {
    "text": "framework will these sublease be established functional kind of or operator scene I'm sorry",
    "start": "2959860",
    "end": "2966550"
  },
  {
    "text": "functional service application be considered as like a workload running are supported by the community schedule",
    "start": "2966550",
    "end": "2973270"
  },
  {
    "text": "all what what properties does the",
    "start": "2973270",
    "end": "2978340"
  },
  {
    "text": "service need we have something called service affinity today in the scheduler but that's not probably that's not what",
    "start": "2978340",
    "end": "2985420"
  },
  {
    "text": "you are looking for I was wondering what what aspect of service do you have in service sorry sir beliefs oh sorry I",
    "start": "2985420",
    "end": "2993990"
  },
  {
    "text": "misheard you well several lists is kind of I mean there is nothing particularly different",
    "start": "2993990",
    "end": "3001260"
  },
  {
    "text": "in serverless workloads really that requires something new in the scheduler",
    "start": "3001260",
    "end": "3006720"
  },
  {
    "text": "but definitely we that's the direction that you are going to support but we",
    "start": "3006720",
    "end": "3012780"
  },
  {
    "text": "don't know what kind of particular scheduling feature in requires I think 100 like Hobbs ii may not be enough -",
    "start": "3012780",
    "end": "3021540"
  },
  {
    "text": "yeah what supports the throughput is actually you're right throughput for service for service several its",
    "start": "3021540",
    "end": "3028500"
  },
  {
    "text": "application is something that is needed and actually the reason that you're trying to get to like a hundred policy",
    "start": "3028500",
    "end": "3034020"
  },
  {
    "text": "and $5,000 is exactly for to target service applications better but other",
    "start": "3034020",
    "end": "3040290"
  },
  {
    "text": "than throughput we don't need to add features or language to do",
    "start": "3040290",
    "end": "3046640"
  }
]
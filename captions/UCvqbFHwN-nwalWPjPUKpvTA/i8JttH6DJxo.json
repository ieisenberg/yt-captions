[
  {
    "start": "0",
    "end": "81000"
  },
  {
    "text": "so thanks everyone for coming this is a deep dive on Jaeger if you had a chance",
    "start": "60",
    "end": "5819"
  },
  {
    "text": "to go yesterday so for the intro we hope that people sort of know what what",
    "start": "5819",
    "end": "11969"
  },
  {
    "text": "Jaeger is on a higher level and and and the very basic functionality so today which is gonna talk about new features",
    "start": "11969",
    "end": "17150"
  },
  {
    "text": "in more details and yes so I'll say a",
    "start": "17150",
    "end": "23490"
  },
  {
    "text": "few words about the project status will talk of show new features and talk about roadmap in in a bit more details and",
    "start": "23490",
    "end": "29939"
  },
  {
    "text": "maybe leave more time for Q&A and so I'm you rich Crowe from uber working on",
    "start": "29939",
    "end": "36660"
  },
  {
    "text": "Jaeger over here Pavel is from Red Hat also maintainer and and Joe is also from",
    "start": "36660",
    "end": "44160"
  },
  {
    "text": "uber he actually one of the authors of the new trace dish that we'll be showing",
    "start": "44160",
    "end": "49170"
  },
  {
    "text": "so he was not originally on the list so again this is probably repeat for many",
    "start": "49170",
    "end": "56640"
  },
  {
    "text": "people the Jaeger is is the distributed tracing platform inspired by the Saab",
    "start": "56640",
    "end": "62399"
  },
  {
    "text": "dapper and sort of compatible on a conceptual model level with the upper and upon Zipkin and has been a part of",
    "start": "62399",
    "end": "68729"
  },
  {
    "text": "C&C of since last year so we've had a good growth we actually applied for gradiation now because the we have like",
    "start": "68729",
    "end": "75960"
  },
  {
    "text": "sufficient number of users and and maturity of the project and as well as like number of contributors and this is",
    "start": "75960",
    "end": "84000"
  },
  {
    "start": "81000",
    "end": "81000"
  },
  {
    "text": "my pitch and from yesterday's that I now think of tracing of Yeager's not just a tracing system but a tracing platform",
    "start": "84000",
    "end": "90689"
  },
  {
    "text": "which means that it's it's not just the thing that does everything for you but",
    "start": "90689",
    "end": "96390"
  },
  {
    "text": "it provides a platform to do more exploration right and so the main thing about distributed tracing as a toolset",
    "start": "96390",
    "end": "103530"
  },
  {
    "text": "is that it's ultimately a root cause analysis tool so when we have a performance problem in application that",
    "start": "103530",
    "end": "110700"
  },
  {
    "text": "performance problem can manifest as like some error rates throw in somewhere or it could be latency but in the end it",
    "start": "110700",
    "end": "116490"
  },
  {
    "text": "affects in some way at the end user of the application right and so we want to find out where that problem is and of",
    "start": "116490",
    "end": "122759"
  },
  {
    "text": "all the existence sort of distributed monitoring tools today distributed tracing this is the best positions to",
    "start": "122759",
    "end": "128819"
  },
  {
    "text": "actually answer these questions because it can it understands the the flow of the application much better than any other tool and as a",
    "start": "128819",
    "end": "136920"
  },
  {
    "text": "platform once you start collecting this data what you really want to be able to do is like ask questions and proof or",
    "start": "136920",
    "end": "144120"
  },
  {
    "text": "like make hypotheses and prove them with with the data that you're collecting and without being a platform it's it's like",
    "start": "144120",
    "end": "151890"
  },
  {
    "text": "we can't really scale the project by building two very specific use cases that people have like saying oh well",
    "start": "151890",
    "end": "158519"
  },
  {
    "text": "trace D if we will show the twist is something that we we thought would be useful and we built it but there are many other things that might be useful",
    "start": "158519",
    "end": "164579"
  },
  {
    "text": "but they may be narrow use cases so by focusing more to be a platform where you",
    "start": "164579",
    "end": "169739"
  },
  {
    "text": "can like do actual experimentation we I think we open up a bit more to to people",
    "start": "169739",
    "end": "176040"
  },
  {
    "text": "to use that the whole like rich data that we are collecting technology stack is again the main thing I guess on the",
    "start": "176040",
    "end": "182909"
  },
  {
    "start": "179000",
    "end": "179000"
  },
  {
    "text": "slide is the client library support we have support for officially for seven",
    "start": "182909",
    "end": "188459"
  },
  {
    "text": "languages plus there are two unofficial like community supported libraries so a",
    "start": "188459",
    "end": "193560"
  },
  {
    "text": "pretty well covered if you if you have an application in production today that you will be able to instrument it for",
    "start": "193560",
    "end": "198840"
  },
  {
    "text": "tracing right and on the back consists of the back like a deep dive I will",
    "start": "198840",
    "end": "204060"
  },
  {
    "text": "mention so we have official support for elastic search and Cassandra the storage backends doesn't mean that you have to",
    "start": "204060",
    "end": "211590"
  },
  {
    "text": "use them but so they're people around in the community are trying to use with",
    "start": "211590",
    "end": "216780"
  },
  {
    "text": "other storage backends right now it sort of requires the fork of the code to",
    "start": "216780",
    "end": "221819"
  },
  {
    "text": "build a different storage plugin so we'll talk later about the plug-in framework that we are kind of moving",
    "start": "221819",
    "end": "226889"
  },
  {
    "text": "forward where you would be able to the resident user you should be able to take he agar core a and take a plugin that",
    "start": "226889",
    "end": "233579"
  },
  {
    "text": "someone develops and just combine matter on time rather than fork in the code this is sort of like not so much a",
    "start": "233579",
    "end": "239639"
  },
  {
    "text": "project problem but the goal language problem because go doesn't support plugins that well and as a health of the",
    "start": "239639",
    "end": "246449"
  },
  {
    "start": "245000",
    "end": "245000"
  },
  {
    "text": "project so as I mentioned we have seven maintainer z' like core martin maintainer from Red Hat and uber and we",
    "start": "246449",
    "end": "253349"
  },
  {
    "text": "have like a lot of contributions from the open source like 220 unique was our",
    "start": "253349",
    "end": "259380"
  },
  {
    "text": "self of different commits so now I'll give to power to show you some of",
    "start": "259380",
    "end": "265680"
  },
  {
    "text": "the new features in a live demo so hi I",
    "start": "265680",
    "end": "272160"
  },
  {
    "text": "will show you actually one feature it will be introduced in the latest release",
    "start": "272160",
    "end": "278400"
  },
  {
    "text": "which is 1/9 so I will just generate some data so this is the main physically",
    "start": "278400",
    "end": "289500"
  },
  {
    "text": "main screen where you can find all the traces and this is the trace like timeline diagram which shows you the",
    "start": "289500",
    "end": "296509"
  },
  {
    "text": "structure of the call graph and we also",
    "start": "296509",
    "end": "301710"
  },
  {
    "text": "we have introduced this new trace graph which helps you to understand like large",
    "start": "301710",
    "end": "307740"
  },
  {
    "text": "traces with a lot of spans and what it does basically it groups spans from the",
    "start": "307740",
    "end": "314460"
  },
  {
    "text": "same service with the same operation name so for example here we can see that this one is interesting",
    "start": "314460",
    "end": "321120"
  },
  {
    "text": "it's from service driver we can see that it's grouping spams with the operation",
    "start": "321120",
    "end": "327930"
  },
  {
    "text": "driver find nearest this is not a very good example because there is only one one span representing this operation but",
    "start": "327930",
    "end": "336120"
  },
  {
    "text": "if I go for example here to the road series we can see that that front end called wrote ten times with this",
    "start": "336120",
    "end": "343680"
  },
  {
    "text": "operation what is also interesting you can see like the the total duration so",
    "start": "343680",
    "end": "351990"
  },
  {
    "text": "it's the sum of durations of all these operations and also the so-called self",
    "start": "351990",
    "end": "359940"
  },
  {
    "text": "time which tells you like time spent within this operation - all the like",
    "start": "359940",
    "end": "368789"
  },
  {
    "text": "child of operations in this case there is no child operation so the the",
    "start": "368789",
    "end": "374039"
  },
  {
    "text": "durations basically equals we have also",
    "start": "374039",
    "end": "380610"
  },
  {
    "text": "this toggle if I switch it it will change colors and the idea is that it",
    "start": "380610",
    "end": "386759"
  },
  {
    "text": "should highlight the nodes which are taking the most time within the trace I",
    "start": "386759",
    "end": "394190"
  },
  {
    "text": "think this is still prototype it's not yet in the master maybe change some some color schemes",
    "start": "394190",
    "end": "404540"
  },
  {
    "text": "doing this one so so what I showed you",
    "start": "414410",
    "end": "420990"
  },
  {
    "text": "is it's useful to understand the structure but also to compare the",
    "start": "420990",
    "end": "426090"
  },
  {
    "text": "durations and what we also have is the trace diff which focuses only on the on",
    "start": "426090",
    "end": "432570"
  },
  {
    "text": "the structure of the trace so you don't see durations but you see only differences between like number of spans",
    "start": "432570",
    "end": "439400"
  },
  {
    "text": "between these two traces so in this particular example we are comparing a",
    "start": "439400",
    "end": "446130"
  },
  {
    "text": "and two to be right and this is red which means that B trace doesn't contain",
    "start": "446130",
    "end": "454070"
  },
  {
    "text": "one one operation from the ready series",
    "start": "454070",
    "end": "459410"
  },
  {
    "text": "yeah if it's like it can be also from green it would mean that there is one",
    "start": "460340",
    "end": "466680"
  },
  {
    "text": "more span from the from the Redis I think Joe we will talk more about this",
    "start": "466680",
    "end": "473250"
  },
  {
    "text": "trace diff with more like this is very simple example but if you have lot of",
    "start": "473250",
    "end": "479610"
  },
  {
    "text": "spans it helps you to understand when when to focus",
    "start": "479610",
    "end": "485000"
  },
  {
    "text": "so what we have also new is the new website and the nice feature is this",
    "start": "493070",
    "end": "501200"
  },
  {
    "start": "498000",
    "end": "498000"
  },
  {
    "text": "client features comparison so you can see like what clients support like what",
    "start": "501200",
    "end": "508760"
  },
  {
    "text": "kind of protocols what kind of senders and also there is a page where you can",
    "start": "508760",
    "end": "515719"
  },
  {
    "text": "find all the components like the the agent collector agent the eager",
    "start": "515720",
    "end": "521180"
  },
  {
    "text": "collector eager query Jagr agent and download page which is",
    "start": "521180",
    "end": "528410"
  },
  {
    "start": "526000",
    "end": "526000"
  },
  {
    "text": "basically the previous ok Joe hello ok",
    "start": "528410",
    "end": "543020"
  },
  {
    "text": "great hi I'm Joe Ferro or work on Yaeger primarily in the UI great to be here so",
    "start": "543020",
    "end": "548990"
  },
  {
    "text": "let's talk a little bit more about trace tips ok this is the first time seen it's",
    "start": "548990",
    "end": "554540"
  },
  {
    "text": "like the Gantt chart is great for traces with it's not great for traces with ten thousands of fans because it just get",
    "start": "554540",
    "end": "560780"
  },
  {
    "text": "kind of overwhelmingly complex it's too much information so with trace Tiff's you do two things",
    "start": "560780",
    "end": "566110"
  },
  {
    "text": "one you compare two traces and also we also compress or condense or reduce",
    "start": "566110",
    "end": "573290"
  },
  {
    "text": "rather the graph that represents the trace with the counting where you can have one node that represents multiple",
    "start": "573290",
    "end": "579680"
  },
  {
    "text": "spans additionally we've done some research on comparing one tracing it's a group of traces which is proved pretty",
    "start": "579680",
    "end": "586190"
  },
  {
    "text": "interesting people are showing some some affinity for that so that's something",
    "start": "586190",
    "end": "591350"
  },
  {
    "text": "we're actually exploring for a future release so the trace graph which Pavel mentioned is a single way to kind of",
    "start": "591350",
    "end": "597980"
  },
  {
    "text": "reduce the complexity of a trace so okay so here's a traced if Paula went into",
    "start": "597980",
    "end": "604790"
  },
  {
    "text": "that compression that reduction so I'm just going to go through a little again like a little bit more about the",
    "start": "604790",
    "end": "610900"
  },
  {
    "text": "coloring and kind of the way this works and also talked about this as a scenario",
    "start": "610900",
    "end": "616450"
  },
  {
    "text": "so down here we have the root node the root nodes great because they're that node exists in both trace and it's also",
    "start": "616450",
    "end": "623540"
  },
  {
    "text": "has the same count so there's one root node down here we have dark bone by the way",
    "start": "623540",
    "end": "628970"
  },
  {
    "text": "these colors are modified so they have more contrast in the screen they actually don't quite look like this I",
    "start": "628970",
    "end": "634030"
  },
  {
    "text": "can't see it but yeah so fYI the colors are adjusted to kind of like have the",
    "start": "634030",
    "end": "640160"
  },
  {
    "text": "differences more apparent so down here we have dark red and dark green that means this note is in one trace but not",
    "start": "640160",
    "end": "647330"
  },
  {
    "text": "the other so if it's dark red it's in trace a but not in trace B just dark green it's only in trace be up here we",
    "start": "647330",
    "end": "654590"
  },
  {
    "text": "have light red and light green so that means it's in both traces but there's more spans in one of them so for",
    "start": "654590",
    "end": "661610"
  },
  {
    "text": "instance if it's like green then it's in both traces but there's more of those fans in trace B okay so if we look at",
    "start": "661610",
    "end": "669080"
  },
  {
    "text": "this trace we try to kind of create a narrative about it we have this section in the upper half that's gray which",
    "start": "669080",
    "end": "674570"
  },
  {
    "text": "means it has a lot in common structurally and then we have some differences over by the three which",
    "start": "674570",
    "end": "680390"
  },
  {
    "text": "means things start to diverge and then around the two we have major divergence so we kind of have two things that are",
    "start": "680390",
    "end": "687050"
  },
  {
    "text": "going along similar paths with some differences and then they basically Fork so the rationale or the I guess the",
    "start": "687050",
    "end": "693800"
  },
  {
    "text": "story behind this is these are two eats orders that are both posts requests so",
    "start": "693800",
    "end": "700760"
  },
  {
    "text": "to create a nice order and things are kind of going along on same pads and then when the users credit is checked",
    "start": "700760",
    "end": "707410"
  },
  {
    "text": "the user in trace B doesn't have sufficient funds so a rollback is issued",
    "start": "707410",
    "end": "712580"
  },
  {
    "text": "whereas in trace a it continues and finishes the order so the dark green nodes are actually the rollback nodes",
    "start": "712580",
    "end": "719090"
  },
  {
    "text": "and the red nodes are the finalizing of the order so if we didn't know that for instance we can just see that there's",
    "start": "719090",
    "end": "725510"
  },
  {
    "text": "very strong divergence later in this trace we can go to the trace timeline when this is a section that has the",
    "start": "725510",
    "end": "731030"
  },
  {
    "text": "divergence I'm good at the trace timeline and we can see an error message that says you have an outstanding balance so that's kind of we can either",
    "start": "731030",
    "end": "737420"
  },
  {
    "text": "start from there and find a trace that has a finished order and then compare them to kind of verify our processing or",
    "start": "737420",
    "end": "744350"
  },
  {
    "text": "we can see that there's some divergence in this and then drill down to get the rationale behind it another form of",
    "start": "744350",
    "end": "750260"
  },
  {
    "text": "comparison is understanding the duration of the trace so if I look at this trace comparison relative to the previous one",
    "start": "750260",
    "end": "757370"
  },
  {
    "text": "we can see it's much similar far fewer differences between a and B so",
    "start": "757370",
    "end": "762610"
  },
  {
    "text": "here we have a lot of gray nodes and we have some green nodes kind of in the",
    "start": "762610",
    "end": "767779"
  },
  {
    "text": "sort of lower half of it some weird stuff in the upper half but basically it's very similar and these two traces",
    "start": "767779",
    "end": "773630"
  },
  {
    "text": "have similar number of spans a has 507 B has 526 but they're actually very",
    "start": "773630",
    "end": "778850"
  },
  {
    "text": "different in terms of their duration trace a has to point takes two point seven four seconds trace B is a 50%",
    "start": "778850",
    "end": "785690"
  },
  {
    "text": "increase in duration so it's pretty massive increase and we may care about that so we can kind of try to reason",
    "start": "785690",
    "end": "791480"
  },
  {
    "text": "about what might be attribute then I think there's three kind of general theories before we dive into actually",
    "start": "791480",
    "end": "797450"
  },
  {
    "text": "understanding it the first is maybe it's this difference this green area may be slow and attributing we can maybe attribute the",
    "start": "797450",
    "end": "804770"
  },
  {
    "text": "duration increase to this area which is only in B or another option is maybe we",
    "start": "804770",
    "end": "809990"
  },
  {
    "text": "can think like okay maybe like it's kind of spread out B is just generally slower the time is sort of distributed amongst",
    "start": "809990",
    "end": "816500"
  },
  {
    "text": "it and the third option would be it's something else it turns out it's something else so this view is coming",
    "start": "816500",
    "end": "822890"
  },
  {
    "text": "soon it's not currently in master but with this view we modify the coloring of our nodes to be based on the duration of",
    "start": "822890",
    "end": "829100"
  },
  {
    "text": "spans in those nodes so we compare the for any given node that's in shared between the two traces we compare the",
    "start": "829100",
    "end": "835490"
  },
  {
    "text": "average duration of the spans and a versus the average duration of the spans and B and then we color them though the",
    "start": "835490",
    "end": "842120"
  },
  {
    "text": "darkness of the colors is based on the maximum difference for any given node so",
    "start": "842120",
    "end": "847820"
  },
  {
    "text": "we can look at this and we can see well okay so over here it's all gray that's because they're very similar in duration",
    "start": "847820",
    "end": "853880"
  },
  {
    "text": "and then over here they're white this is a section that's only in trace a or",
    "start": "853880",
    "end": "859760"
  },
  {
    "text": "trace be rather so if the the nodes are not in both that we don't have a basis for comparison so we don't actually",
    "start": "859760",
    "end": "865910"
  },
  {
    "text": "color them we leave them Y to indicate that there's no common ground there so here we have the root node which is dark",
    "start": "865910",
    "end": "872899"
  },
  {
    "text": "red and maybe just kind of looks like dark gray in the screen that's kind in crease the contrast for the projection",
    "start": "872899",
    "end": "878440"
  },
  {
    "text": "so it's dark red and that's natural because trace B took 50% longer now if",
    "start": "878440",
    "end": "884750"
  },
  {
    "text": "we follow that we can see that of the children-- of that node only one is dark red so that means the duration increases",
    "start": "884750",
    "end": "891589"
  },
  {
    "text": "concentrate into that child and if we look at that child we can see it has 1 dark red node",
    "start": "891589",
    "end": "896600"
  },
  {
    "text": "and kind of two more sort of reddish nodes so we can conclude that the duration increased actually highly",
    "start": "896600",
    "end": "902630"
  },
  {
    "text": "concentrated in this trace so if we mouse over this we can this node we can see wizardly Omega accounts for over one",
    "start": "902630",
    "end": "909410"
  },
  {
    "text": "second of increase in duration and the node below it is 200 milliseconds of increase in duration so with this we can",
    "start": "909410",
    "end": "916040"
  },
  {
    "text": "kind of kind of dispel our sort of speculation and see the duration that the duration increase is highly",
    "start": "916040",
    "end": "921230"
  },
  {
    "text": "concentrated and I think that's all I have to thank you oh sure",
    "start": "921230",
    "end": "928400"
  },
  {
    "start": "924000",
    "end": "924000"
  },
  {
    "text": "the graph is realizations that there's a condensation of the structure the reduction so that facilitates like",
    "start": "928400",
    "end": "934550"
  },
  {
    "text": "dealing with like we have traces are sometimes like 80,000 but then they have a graph in this view that's similar to",
    "start": "934550",
    "end": "941690"
  },
  {
    "text": "the hot rod demo more so than the etes post so just it kind of highlights how much repetition there is and sometimes",
    "start": "941690",
    "end": "947540"
  },
  {
    "text": "super massive traces additionally there's no way to presently know where to drill down into details so one",
    "start": "947540",
    "end": "953120"
  },
  {
    "text": "benefit of that is you're not overwhelmed by those details and then yeah those are the main differences and",
    "start": "953120",
    "end": "959570"
  },
  {
    "text": "we also color code and highlight the the structural differences so and we",
    "start": "959570",
    "end": "965120"
  },
  {
    "text": "emphasize the structural and duration differences to kind of call that out so you don't have to one of the challenges",
    "start": "965120",
    "end": "971480"
  },
  {
    "text": "of using the Timeline view or even the trace graph view and isolation is if you want to understand the distinction",
    "start": "971480",
    "end": "976640"
  },
  {
    "text": "between that graph that's racing another one you can I have to piece it together in your mind a lot of cognitive overhead",
    "start": "976640",
    "end": "982400"
  },
  {
    "text": "so with this you it kind of highlights those differences and then additionally currently there's distinct comparison",
    "start": "982400",
    "end": "988490"
  },
  {
    "text": "modes between structural differences and the duration differences and so that kind of compartmentalizes that sort of",
    "start": "988490",
    "end": "995290"
  },
  {
    "text": "analysis in future iterations we may visit combining some of those and also",
    "start": "995290",
    "end": "1001330"
  },
  {
    "text": "creating new forms of analysis like maybe comparing self time or something else but in that that process one of the",
    "start": "1001330",
    "end": "1007990"
  },
  {
    "text": "challenges is going to be to keep the UI approachable so thank you",
    "start": "1007990",
    "end": "1016649"
  },
  {
    "text": "[Applause]",
    "start": "1017240",
    "end": "1022850"
  },
  {
    "text": "just so one thing I want to add about tres Dave's is that what's interesting",
    "start": "1028080",
    "end": "1036610"
  },
  {
    "text": "to me is that I think there are like two fairly distinct use cases that people",
    "start": "1036610",
    "end": "1041949"
  },
  {
    "text": "are applying distributed tracing to and that kind of reflects in the complexity",
    "start": "1041950",
    "end": "1047709"
  },
  {
    "text": "of the architecture that that people have in their systems right and so the classic use case of the trace this is",
    "start": "1047710",
    "end": "1054820"
  },
  {
    "text": "something that like pop wall original shot oh you have a hot rod tres you have maybe like five six services",
    "start": "1054820",
    "end": "1060850"
  },
  {
    "text": "you can reason very well about that architecture from one single trace you can investigate it and so and that works",
    "start": "1060850",
    "end": "1067480"
  },
  {
    "text": "well to like a certain number of services in our kitty actually maybe I don't know up to 50 and at some point",
    "start": "1067480",
    "end": "1073270"
  },
  {
    "text": "you tip the scale to the architecture which is as large as uber where we have 3,000 micro services and suddenly that",
    "start": "1073270",
    "end": "1079720"
  },
  {
    "text": "same analysis becomes no longer as easy even with distributed tracing because as",
    "start": "1079720",
    "end": "1084880"
  },
  {
    "text": "you mentioned the cognitive overhead of actually trying to understand what when you're looking at the trace which contains like 80,000 spans is it's",
    "start": "1084880",
    "end": "1092410"
  },
  {
    "text": "almost impossible right and so you surely you can you can like drill down into very specific parts of it saying oh",
    "start": "1092410",
    "end": "1099040"
  },
  {
    "text": "I know that this service is kept in a latency and you can look into so if you zoom in into the trace then that actually still makes sense right but if",
    "start": "1099040",
    "end": "1106570"
  },
  {
    "text": "you are trying to comprehend overall picture or even trying to understand well I know that this trace represents",
    "start": "1106570",
    "end": "1112390"
  },
  {
    "text": "some sort of failure scenario but how do I root cause it that's where it starts to break down to like the classic",
    "start": "1112390",
    "end": "1118120"
  },
  {
    "text": "tracing approach and so that's why we went into this more sort of aggregation approach where we say well we can try to",
    "start": "1118120",
    "end": "1125530"
  },
  {
    "text": "do some machine understanding first and then basically facilitate for the human to to to pinpoint where we think there",
    "start": "1125530",
    "end": "1132250"
  },
  {
    "text": "might be problems in stock visualization is obviously one of the easiest ways to do that because like we we give signals",
    "start": "1132250",
    "end": "1138970"
  },
  {
    "text": "to the visual cortex of the brain which is very powerful machine to actually try to see the patterns in it",
    "start": "1138970",
    "end": "1145420"
  },
  {
    "text": "so now in as far as the other features I think quick call out to a bunch of",
    "start": "1145420",
    "end": "1152650"
  },
  {
    "start": "1150000",
    "end": "1150000"
  },
  {
    "text": "integrations that have happened over the past year so recently the Jaeger",
    "start": "1152650",
    "end": "1158740"
  },
  {
    "text": "operator was released for kubernetes which allows like we used to have a helmet art I think operators like a lot easier to",
    "start": "1158740",
    "end": "1164830"
  },
  {
    "text": "use for actually just deploy energy production then open sensors is another",
    "start": "1164830",
    "end": "1169960"
  },
  {
    "text": "project which is sort of working on the instrumentation side of the things and it has full support for Yeager for to",
    "start": "1169960",
    "end": "1177370"
  },
  {
    "text": "export a date into Jaeger East yo the service match which is like mostly for",
    "start": "1177370",
    "end": "1182740"
  },
  {
    "text": "kubernetes with envoy if you if you run east your demo downloaded then it comes",
    "start": "1182740",
    "end": "1189490"
  },
  {
    "text": "up with Jaeger by default and so you can get traces from from any stadium application that you use and obviously",
    "start": "1189490",
    "end": "1195100"
  },
  {
    "text": "in production you can also a configure to spin up Jaeger and integrate with it and because this geo by default uses",
    "start": "1195100",
    "end": "1202270"
  },
  {
    "text": "envoy we've recently had some work done on a C++ client for Jaeger so not only",
    "start": "1202270",
    "end": "1208809"
  },
  {
    "text": "you can integrate Jaeger into C++ applications but also because Envoy is written in C++ now and we can use the",
    "start": "1208809",
    "end": "1215260"
  },
  {
    "text": "actual native Jaeger client which allows the same flexibility or for example adaptive sampling and other things that",
    "start": "1215260",
    "end": "1221380"
  },
  {
    "text": "we've had built into our clients like the feedback loop back into the client so that can be done with the with on",
    "start": "1221380",
    "end": "1228130"
  },
  {
    "text": "inside and before it was like very high-level integration only and finally",
    "start": "1228130",
    "end": "1234580"
  },
  {
    "text": "this is not something that I use Paul told me about this is a Eclipse trace compass so it's a project in in in",
    "start": "1234580",
    "end": "1241090"
  },
  {
    "text": "Eclipse incubation which allows you to like importing and usual license races",
    "start": "1241090",
    "end": "1246220"
  },
  {
    "text": "as well so another thing which was kind",
    "start": "1246220",
    "end": "1251380"
  },
  {
    "text": "of a major change since last year is we went into a different architecture for",
    "start": "1251380",
    "end": "1257049"
  },
  {
    "text": "Yaeger ingestion at least internally at uber and it's it's like open source so",
    "start": "1257049",
    "end": "1262120"
  },
  {
    "start": "1262000",
    "end": "1262000"
  },
  {
    "text": "the original architecture which when we just first open sourced it looked like this so in your application you have",
    "start": "1262120",
    "end": "1268210"
  },
  {
    "text": "client library Jaeger client which collects the spans and sends them out to",
    "start": "1268210",
    "end": "1273370"
  },
  {
    "text": "the agent runyan on the host or in the pod was a sidecar and then agent pushes",
    "start": "1273370",
    "end": "1278500"
  },
  {
    "text": "that data into Jaeger collectors usually cluster and those push data into some like",
    "start": "1278500",
    "end": "1285370"
  },
  {
    "text": "distributed database right Cassandra listicle whichever other database you want to use so that was sort of like",
    "start": "1285370",
    "end": "1292170"
  },
  {
    "text": "designed around the push method and collectors and agents and clients they",
    "start": "1292170",
    "end": "1298390"
  },
  {
    "text": "all had law changing capabilities so that they had the internal buffers so if they can't send data fast enough they'll",
    "start": "1298390",
    "end": "1304300"
  },
  {
    "text": "just drop the data right so all those things still exist but what we've",
    "start": "1304300",
    "end": "1309310"
  },
  {
    "text": "noticed in our experience at uber is that when we have some traffic spikes maybe there could be different reasons",
    "start": "1309310",
    "end": "1316210"
  },
  {
    "text": "it may be like Halloween is like the biggest day for bar for whatever reason I don't understand but like it it's like",
    "start": "1316210",
    "end": "1322710"
  },
  {
    "text": "highest traffic of the year always right and so if we are like under provision",
    "start": "1322710",
    "end": "1329260"
  },
  {
    "text": "for whatever reasons that that traffic may sort of overload our database ability to actually ingest all the data",
    "start": "1329260",
    "end": "1334750"
  },
  {
    "text": "in the push manner in real time and as a result collectors even though they have",
    "start": "1334750",
    "end": "1339820"
  },
  {
    "text": "like internal buffer that buffer feels very quickly if you actually if the database is not fast enough and so you",
    "start": "1339820",
    "end": "1345340"
  },
  {
    "text": "just have to drop data and and the worst part about it is that you have to drop data completely indiscriminantly because",
    "start": "1345340",
    "end": "1351180"
  },
  {
    "text": "collectors receive spans from like hundreds of hosts like you only know about what the trace is after you stitch",
    "start": "1351180",
    "end": "1357820"
  },
  {
    "text": "it from the database right and so collectors make these decisions about dropping spans completely randomly because they have no context I was like",
    "start": "1357820",
    "end": "1364540"
  },
  {
    "text": "oh it would be nice if they say okay well let's just share 10% of the traffic but consistently so that we can still",
    "start": "1364540",
    "end": "1370510"
  },
  {
    "text": "keep traces but that's physically impossible because of the stateless nature of collectors right and so I",
    "start": "1370510",
    "end": "1376020"
  },
  {
    "text": "guess this is like a summary of what I'm saying there's like the push model was struggling with with traffic spikes and",
    "start": "1376020",
    "end": "1382030"
  },
  {
    "start": "1377000",
    "end": "1377000"
  },
  {
    "text": "there are multiple reasons for traffic spy things could be like a real business traffic war it could be someone deployed",
    "start": "1382030",
    "end": "1387850"
  },
  {
    "text": "an application with a hundred percent something by mistake right and suddenly floods outdated the pipeline and so yeah",
    "start": "1387850",
    "end": "1396040"
  },
  {
    "text": "and so the data drop was always like unacceptable for us we wanted to get around that and so we've looked at Kafka",
    "start": "1396040",
    "end": "1402400"
  },
  {
    "text": "Kafka tuber is like well maintained there's like a team Runyon it's super",
    "start": "1402400",
    "end": "1407440"
  },
  {
    "text": "huge clusters doing like terabytes or look the trillions of messages per day or something like that so it's very",
    "start": "1407440",
    "end": "1414070"
  },
  {
    "text": "elastic as far as the volume of trace and data to be put in like it's comparative to the overall class Kafka clusters nothing right and",
    "start": "1414070",
    "end": "1420700"
  },
  {
    "text": "so if we have a traffic spike the Kafka classic can easily take like 10 times or something and so it's really elastic so",
    "start": "1420700",
    "end": "1427810"
  },
  {
    "text": "it allowed us to not lose any data we still have a push so this is the kind of",
    "start": "1427810",
    "end": "1434380"
  },
  {
    "start": "1433000",
    "end": "1433000"
  },
  {
    "text": "the new architecture we still have a push between agent clients into the collectors but then collectors only",
    "start": "1434380",
    "end": "1439390"
  },
  {
    "text": "right - Kafka and then they're done and and so there's no data loss almost ever at at this point unless there's some",
    "start": "1439390",
    "end": "1446050"
  },
  {
    "text": "like Kafka maybe brokers having bad day and then we have we released two new",
    "start": "1446050",
    "end": "1451660"
  },
  {
    "text": "services called Jaeger in gesture and indexer which read the Kafka stream and this like actually stored the data into",
    "start": "1451660",
    "end": "1458620"
  },
  {
    "text": "the database and the reason we separated them is because again they're a different value of store and the spans",
    "start": "1458620",
    "end": "1465190"
  },
  {
    "text": "themselves which is very well but it's the raw data and then building in this is so that you can search for those pants like indices are like less",
    "start": "1465190",
    "end": "1471790"
  },
  {
    "text": "important and so we actually split them into separate Kafka streams so that like if to have any capacity issues",
    "start": "1471790",
    "end": "1477360"
  },
  {
    "text": "temporarily we can just shut down that that in justin but keep ingesting all the spans in the database and the second",
    "start": "1477360",
    "end": "1485470"
  },
  {
    "text": "big reason why we went into the Kafka approach is that as I mentioned at the",
    "start": "1485470",
    "end": "1491680"
  },
  {
    "text": "beginning we wanted to develop Jaeger to be more expiratory platform and we",
    "start": "1491680",
    "end": "1499780"
  },
  {
    "text": "internally use flink streaming which kind of works well with Kaka so Kevin all the spans available another Kafka",
    "start": "1499780",
    "end": "1506080"
  },
  {
    "text": "stream allows us to build start building a lot of big data jobs on top of it in a stream in fashion right we also have",
    "start": "1506080",
    "end": "1512770"
  },
  {
    "text": "happened to have in infrastructure to beware any Kafka stream can be just flushed to HDFS which is also useful we",
    "start": "1512770",
    "end": "1518440"
  },
  {
    "text": "can get all the spans historical spans in the GTFS with like much longer attention than what we have in Cassandra",
    "start": "1518440",
    "end": "1524140"
  },
  {
    "text": "so this was the main reason and yeah it's all in production now and in",
    "start": "1524140",
    "end": "1529240"
  },
  {
    "text": "release 1.8 available for use and there's also a kind of interesting",
    "start": "1529240",
    "end": "1534610"
  },
  {
    "text": "moment is that the ticket at in iaeger back in 17 someone asking like oh can we",
    "start": "1534610",
    "end": "1540760"
  },
  {
    "text": "have Kafka and I said no we can't and but what people were asking they were asking to have Kafka between Jaeger",
    "start": "1540760",
    "end": "1546550"
  },
  {
    "text": "client and collectors right something that for example Zipkin does they their Jaeger their clients can",
    "start": "1546550",
    "end": "1552570"
  },
  {
    "text": "actually write to Kafka directly from the application right and we still think this is the wrong way one one reason is",
    "start": "1552570",
    "end": "1559169"
  },
  {
    "text": "because it actually introduces a lot of dependencies on the application you can't get into dependency hell with like",
    "start": "1559169",
    "end": "1564509"
  },
  {
    "text": "heaven Kafka driver inside your application if you don't need the dependency our dependencies UDP that's",
    "start": "1564509",
    "end": "1569759"
  },
  {
    "text": "it's like every every language has a UDP in it but the more important thing is that the oldest feedback loop that the",
    "start": "1569759",
    "end": "1576210"
  },
  {
    "text": "red lines in architecture they become very hard if you actually have like a Kafka where you have to capture",
    "start": "1576210",
    "end": "1581759"
  },
  {
    "text": "everything right and so so basically we will have Kafka after the collectors but",
    "start": "1581759",
    "end": "1587220"
  },
  {
    "text": "collect up to the collectors I still push mechanism we have no plans to change that another big change which",
    "start": "1587220",
    "end": "1593970"
  },
  {
    "text": "served like more internal but the reason it might affect users in the end so we",
    "start": "1593970",
    "end": "1599099"
  },
  {
    "text": "we've done some work to convert internal data model to be protobuf driven so we have an idea which kind of drives the",
    "start": "1599099",
    "end": "1605519"
  },
  {
    "text": "internal domain model and then all the communications between components inside Jaeger back-end happen with that domain",
    "start": "1605519",
    "end": "1612509"
  },
  {
    "text": "model right and what that allows us in the future blocked several PRS that have",
    "start": "1612509",
    "end": "1618149"
  },
  {
    "text": "been long outstanding one is we can finally define the clear API for the query service so today a query service",
    "start": "1618149",
    "end": "1625139"
  },
  {
    "text": "does have an API but we intentionally didn't document it because it's like some manually constructed JSON we didn't",
    "start": "1625139",
    "end": "1631259"
  },
  {
    "text": "want to be like to be forced to stick to that one and so with the IDL in protobuf",
    "start": "1631259",
    "end": "1636479"
  },
  {
    "text": "we can actually have very clear documentation about what the json api is and similarly the storage plugins that i",
    "start": "1636479",
    "end": "1642989"
  },
  {
    "text": "mentioned the sort of the goal doesn't have a good support for plugins like",
    "start": "1642989",
    "end": "1648869"
  },
  {
    "text": "java has like working just drop a jar so in go you have to I mean one approach is",
    "start": "1648869",
    "end": "1654960"
  },
  {
    "text": "like a harsh record plugin which does the jpc between two processes as a way",
    "start": "1654960",
    "end": "1660210"
  },
  {
    "text": "of plugins new function out there a kind of a sidecar approach and so this is the one that we experimenting like there's a",
    "start": "1660210",
    "end": "1665659"
  },
  {
    "text": "pull request in progress and again Kevin Jerry PC and protobuf model as the kind",
    "start": "1665659",
    "end": "1671220"
  },
  {
    "text": "of core foundation inside the Jaeger enables this much easier and finally there is husband people have some",
    "start": "1671220",
    "end": "1676950"
  },
  {
    "text": "problems with the fact that our agents to collector communication was over proprietary over",
    "start": "1676950",
    "end": "1682130"
  },
  {
    "text": "Kokichi on oh so sometimes it's hard to route because like yeah like my origin",
    "start": "1682130",
    "end": "1687260"
  },
  {
    "text": "may not understand that specific protocol but so we switched already to jar PC is gonna come out in the next release as an official and then I think",
    "start": "1687260",
    "end": "1694700"
  },
  {
    "text": "in the next series we'll just make a default so we will decoy the TT on our path so that it's a lot easier to route",
    "start": "1694700",
    "end": "1701450"
  },
  {
    "text": "oh I guess I have all these things that I just talked about and finally like",
    "start": "1701450",
    "end": "1708650"
  },
  {
    "start": "1708000",
    "end": "1708000"
  },
  {
    "text": "Zipkin computability has been improved since last year so we will have completely built in our multiple levels",
    "start": "1708650",
    "end": "1714650"
  },
  {
    "text": "so we collector can accept Zipkin data so if you have an application instrumented with Zipkin libraries like",
    "start": "1714650",
    "end": "1720230"
  },
  {
    "text": "brave in Java and and like in spring then you can just point a to Jager collector and it will take Zipkin data",
    "start": "1720230",
    "end": "1726080"
  },
  {
    "text": "and then process it as a native data right or alternatively if you have a new application that you want to instrument",
    "start": "1726080",
    "end": "1732290"
  },
  {
    "text": "with upon tracing and Jager but an old application instrumented with Zipkin you can configure your Jager client",
    "start": "1732290",
    "end": "1738110"
  },
  {
    "text": "libraries to use the same propagation format so that the traces don't get broken as they travel different types of",
    "start": "1738110",
    "end": "1743500"
  },
  {
    "text": "applications right and yes and so and we",
    "start": "1743500",
    "end": "1748970"
  },
  {
    "text": "support like several actual formats that Zipkin has like JSON v2 and and thrift",
    "start": "1748970",
    "end": "1755030"
  },
  {
    "text": "and the only thing we don't do is we don't we are not able to take Zipkin spans from the Kafka stream but we have",
    "start": "1755030",
    "end": "1761570"
  },
  {
    "text": "all the infrastructure in place like if someone needs to do that that's probably like a couple days of worth of work if on anyone wants to put the peer for that",
    "start": "1761570",
    "end": "1768010"
  },
  {
    "text": "and finally so I'm kind of like two minutes left so I don't know I will",
    "start": "1768010",
    "end": "1774620"
  },
  {
    "text": "probably skip the roadmap we'll put the slides on the thing so this is I talked",
    "start": "1774620",
    "end": "1779840"
  },
  {
    "text": "about most of this already yesterday so I think the data pipeline is kind of the probably the most interesting one again",
    "start": "1779840",
    "end": "1786650"
  },
  {
    "start": "1781000",
    "end": "1781000"
  },
  {
    "text": "is a our direction to take Jaeger to be a platform for data analysis the data",
    "start": "1786650",
    "end": "1792170"
  },
  {
    "text": "pipeline means that the fleeing jobs that we have internally to were Apache flink it's a streaming platform we can",
    "start": "1792170",
    "end": "1798170"
  },
  {
    "text": "open source them so that they will build a foundation of like you can you can you",
    "start": "1798170",
    "end": "1804170"
  },
  {
    "text": "can take like a library essentially to fling sane again this library if you run it in your fleeing job it will give you",
    "start": "1804170",
    "end": "1809450"
  },
  {
    "text": "a view of a trace assembled from the Kafka stream and after that you can do whatever you want with that trace you",
    "start": "1809450",
    "end": "1814850"
  },
  {
    "text": "can like extract features in do any analysis and but we also like we have big plans when in",
    "start": "1814850",
    "end": "1820639"
  },
  {
    "text": "terms of like how we can proceed on that data by planting yes and storage plugins",
    "start": "1820639",
    "end": "1825740"
  },
  {
    "start": "1824000",
    "end": "1824000"
  },
  {
    "text": "like I said there's gonna be this is ongoing work and once the plug-in framework lands in in master then I",
    "start": "1825740",
    "end": "1832820"
  },
  {
    "text": "think people will start actually putting up new storage because we've had lots of interest like silly DB dynamodb and all",
    "start": "1832820",
    "end": "1839179"
  },
  {
    "text": "kinds of like cloud provider databases could be used with Jager as a plugins",
    "start": "1839179",
    "end": "1844220"
  },
  {
    "text": "and this I'll skip this is less interesting so website as Powell mentioned has a lot of documentation on",
    "start": "1844220",
    "end": "1850639"
  },
  {
    "text": "how to run things this is our sort of social media stuff",
    "start": "1850639",
    "end": "1856009"
  },
  {
    "text": "and in waste you get in touch and oh yeah so this is the wrong slide this is",
    "start": "1856009",
    "end": "1862429"
  },
  {
    "text": "today and I guess we only have a couple questions but we'll be around outside if you have any questions so but now I have",
    "start": "1862429",
    "end": "1868879"
  },
  {
    "text": "I think I'm out of time pretty much [Applause]",
    "start": "1868879",
    "end": "1877690"
  }
]
[
  {
    "start": "0",
    "end": "230000"
  },
  {
    "text": "then [Music] press recorded it's recording all right so anyway any of us can do it",
    "start": "80",
    "end": "7200"
  },
  {
    "text": "right okay yeah and you always can do it all right so we can start i guess",
    "start": "7200",
    "end": "13599"
  },
  {
    "text": "uh so yeah welcome everyone um today's session is the first one with",
    "start": "13599",
    "end": "19359"
  },
  {
    "text": "this new platform so we got a few people here so maybe we lost some on the way but uh",
    "start": "19359",
    "end": "25439"
  },
  {
    "text": "hopefully not many um the",
    "start": "25439",
    "end": "30800"
  },
  {
    "text": "topic for today is this um hpc and htc",
    "start": "30800",
    "end": "37600"
  },
  {
    "text": "uh end user landscape review we sent a form two weeks ago",
    "start": "37600",
    "end": "45440"
  },
  {
    "text": "with a couple questions and this should be hopefully triggering some of the discussion i see some people",
    "start": "45440",
    "end": "51920"
  },
  {
    "text": "don't have microphones available so hi alex",
    "start": "51920",
    "end": "59440"
  },
  {
    "text": "can you hear me i'm a little quiet",
    "start": "59440",
    "end": "64480"
  },
  {
    "text": "can you hear me well jamie i can hear you fine yeah yes i'm here i think we're fine other people were",
    "start": "65439",
    "end": "71920"
  },
  {
    "text": "just muted or if they're uh uh okay just me too okay can you guys hear me everyone just",
    "start": "71920",
    "end": "79360"
  },
  {
    "text": "yeah okay so yeah thank you see we have a few teething problems on the new platform probably none of us have used",
    "start": "79360",
    "end": "85759"
  },
  {
    "text": "it in anger before all right just it keeps telling me my internet connection is unstable yeah just keep",
    "start": "85759",
    "end": "91759"
  },
  {
    "text": "going it does that to me as well i don't think i don't think it's serious right",
    "start": "91759",
    "end": "97280"
  },
  {
    "text": "so yeah so the topic today was this hpc htc and user landscape jamie we put",
    "start": "97280",
    "end": "103920"
  },
  {
    "text": "some questions it's kind of more to trigger discussion today we can go through the replies and maybe",
    "start": "103920",
    "end": "112799"
  },
  {
    "text": "stop on every topic and discuss a bit and uh hopefully",
    "start": "112799",
    "end": "118880"
  },
  {
    "text": "like one thing that would be nice is to kind of come up with some next steps of",
    "start": "118880",
    "end": "125680"
  },
  {
    "text": "what is needed in this area for the cloud native tooling and what would be really useful for",
    "start": "125680",
    "end": "132720"
  },
  {
    "text": "people so if there's no other thing to start with",
    "start": "132720",
    "end": "137760"
  },
  {
    "text": "we can just start by going through the survey yeah i guess uh make sure people put their names on the agenda as well like",
    "start": "137760",
    "end": "144720"
  },
  {
    "text": "normal on the um actually we don't need that anymore because we'll get the reports automatically from the platform",
    "start": "144720",
    "end": "150720"
  },
  {
    "text": "oh really i thought we said we're still going to do the google doc that's fine okay so no names i think we can keep the agenda for the",
    "start": "150720",
    "end": "157280"
  },
  {
    "text": "notes but i don't think we need to collect the attendees anymore fine so we just need to say just ask if there's any",
    "start": "157280",
    "end": "162640"
  },
  {
    "text": "new joins i mean there aren't this time but that that's true yeah i don't think there's anyone joining for the first time no no i",
    "start": "162640",
    "end": "169040"
  },
  {
    "text": "reckon ricardo will there be a way for the rest of us to see",
    "start": "169040",
    "end": "174400"
  },
  {
    "text": "who did attend each of these meetings if we if we want to follow up with anyone that's a good point i don't know about",
    "start": "174400",
    "end": "180560"
  },
  {
    "text": "car is the attendees list in the sessions public to everyone no it's not public",
    "start": "180560",
    "end": "187120"
  },
  {
    "text": "okay uh so do we want to keep the agenda then with the names",
    "start": "187120",
    "end": "192879"
  },
  {
    "text": "can also do that i think it might still be helpful all right",
    "start": "192879",
    "end": "198720"
  },
  {
    "text": "so that would be here hello",
    "start": "198720",
    "end": "205680"
  },
  {
    "text": "[Music]",
    "start": "210410",
    "end": "213520"
  },
  {
    "text": "no",
    "start": "223760",
    "end": "226760"
  },
  {
    "text": "all right so maybe we just go through yeah everyone if you can add your names there",
    "start": "229599",
    "end": "235200"
  },
  {
    "start": "230000",
    "end": "350000"
  },
  {
    "text": "and we can start by going through the through the questionnaire i think we can stop at each one and uh if anyone has",
    "start": "235200",
    "end": "242400"
  },
  {
    "text": "anything to highlight um we can discuss in detail so the first question was what kind of",
    "start": "242400",
    "end": "248640"
  },
  {
    "text": "solutions people are using for high performance computing or high throughput computing",
    "start": "248640",
    "end": "254879"
  },
  {
    "text": "and other batch like workloads so in total we actually got eight",
    "start": "254879",
    "end": "260000"
  },
  {
    "text": "responses which is not too bad i would say because it was kind of a long question",
    "start": "260000",
    "end": "265360"
  },
  {
    "text": "so the top two were slurm and pure kubernetes which is a pretty",
    "start": "265440",
    "end": "272160"
  },
  {
    "text": "i was a bit surprised actually um then we had two for hd condor",
    "start": "272160",
    "end": "278080"
  },
  {
    "text": "uh and then we had one for armada none for volcano i had added it just",
    "start": "278080",
    "end": "284400"
  },
  {
    "text": "because uh it's like a native kubernetes scheduler or cloud native scheduler there was one",
    "start": "284400",
    "end": "289840"
  },
  {
    "text": "for code flow which is interesting and then ancient torque system",
    "start": "289840",
    "end": "297840"
  },
  {
    "text": "so i think i don't know if anyone has any",
    "start": "298240",
    "end": "304720"
  },
  {
    "text": "particular comments on this well one thing that strikes me so people are clearly using more than one thing as",
    "start": "304720",
    "end": "310800"
  },
  {
    "text": "well uh so that's not yeah we've only you know got five five people",
    "start": "310800",
    "end": "316400"
  },
  {
    "text": "in stone and vanilla they're also not unique um so yeah that's that's kind of",
    "start": "316400",
    "end": "322240"
  },
  {
    "text": "interesting maybe maybe a question here is for the ones that uh if anyone here has answered",
    "start": "322240",
    "end": "328639"
  },
  {
    "text": "with more than one is that like from a transition to something new or is it a plan to maintain both in parallel",
    "start": "328639",
    "end": "338520"
  },
  {
    "text": "we're an example of people uh doing both uh for a transition",
    "start": "340000",
    "end": "345840"
  },
  {
    "text": "so and that would be like condor to ramana yeah well and also for the kidnaps actually but yeah",
    "start": "345840",
    "end": "351520"
  },
  {
    "start": "350000",
    "end": "530000"
  },
  {
    "text": "so i was wondering too you know are we not i would be surprised if",
    "start": "351520",
    "end": "356960"
  },
  {
    "text": "there's really nobody using volcano and armada and other things like that right so like you know maybe maybe it's also",
    "start": "356960",
    "end": "363280"
  },
  {
    "text": "kind of a call like hmm like maybe we need to put out feelers into those uh user groups and try to get them",
    "start": "363280",
    "end": "370400"
  },
  {
    "text": "more involved with this sig right because people who are doing who are actually using that would certainly have",
    "start": "370400",
    "end": "376400"
  },
  {
    "text": "overlap in what we're doing i think i wonder if there's ways we could reach out to those groups or even coop flow",
    "start": "376400",
    "end": "382240"
  },
  {
    "text": "too i mean you know those are i feel like those are i don't know too much about armada and volcano but i feel like",
    "start": "382240",
    "end": "387840"
  },
  {
    "text": "those are those are non-zero user communities right now torque i'm not really interested in",
    "start": "387840",
    "end": "394880"
  },
  {
    "text": "reaching out to that community i'm just kidding but all right",
    "start": "394880",
    "end": "400960"
  },
  {
    "text": "but yeah i think that's that's a good point actually and uh for volcano they they have quite a good structure of",
    "start": "400960",
    "end": "407280"
  },
  {
    "text": "like weekly meetings i think they're mostly targeting or at least they're mostly have end users in asia for now",
    "start": "407280",
    "end": "414639"
  },
  {
    "text": "and those are weekly meetings and then they have like uh every two weeks they have a meeting that",
    "start": "414639",
    "end": "419680"
  },
  {
    "text": "is kind of europe and north america friendly one other note on the volcano thing um",
    "start": "419680",
    "end": "426080"
  },
  {
    "text": "depending on the group they will not be able to access google docs or submit to google forms",
    "start": "426080",
    "end": "433039"
  },
  {
    "text": "um so like if trying to like that might segment off a you know other community",
    "start": "433039",
    "end": "438319"
  },
  {
    "text": "there but they can use this platform right because i've had calls with them and",
    "start": "438319",
    "end": "443759"
  },
  {
    "text": "they can only use zoom but i think they will also be able to use this baby yes",
    "start": "443759",
    "end": "449680"
  },
  {
    "text": "right um but if uh if creating a form for a global audience uh surveymonkey",
    "start": "449680",
    "end": "456880"
  },
  {
    "text": "will work in um in china okay that's good oh okay i see what",
    "start": "456880",
    "end": "464960"
  },
  {
    "text": "yeah but in terms of reaching out maybe maybe that's a good point we we can take as an action just to",
    "start": "464960",
    "end": "471360"
  },
  {
    "text": "to advertise this group in these communities to see if they are interested in joining",
    "start": "471360",
    "end": "477199"
  },
  {
    "text": "it it's not like we cover every time this kind of work uh topic either like",
    "start": "477199",
    "end": "482960"
  },
  {
    "text": "there's a lot of things that they will probably not be so interested in we need to find more people are doing ml",
    "start": "482960",
    "end": "489280"
  },
  {
    "text": "and data science and stuff like that i think",
    "start": "489280",
    "end": "493720"
  },
  {
    "text": "all right the other thing i don't know if uh like slurn has a pretty strong presence",
    "start": "495280",
    "end": "502400"
  },
  {
    "text": "here maybe maybe it would be nice to to know",
    "start": "502400",
    "end": "507759"
  },
  {
    "text": "more of how people are using slurm and if they are deploying it on kubernetes",
    "start": "507759",
    "end": "513039"
  },
  {
    "text": "or managing it with kubernetes what what are their plans there as well",
    "start": "513039",
    "end": "518719"
  },
  {
    "text": "don't know if anyone wants to expand on that",
    "start": "519599",
    "end": "523599"
  },
  {
    "text": "yeah do we have anyone on the call who is currently using snow i can i can speak for my old job",
    "start": "528320",
    "end": "536000"
  },
  {
    "start": "530000",
    "end": "640000"
  },
  {
    "text": "um yeah they were using both a mix of slurm and kubernetes um there wasn't any real transition plan",
    "start": "536000",
    "end": "543600"
  },
  {
    "text": "to go from one to the other um but that's also was uh the university",
    "start": "543600",
    "end": "548640"
  },
  {
    "text": "of michigan um and a good chunk of their users were very familiar with you know slurm they didn't really",
    "start": "548640",
    "end": "554480"
  },
  {
    "text": "want to like interrupt their workflow the biggest thing was all the the newer researchers and people coming on board",
    "start": "554480",
    "end": "560080"
  },
  {
    "text": "that were interested in using things like keep flow using things like jupiter notebooks so that was kind of the",
    "start": "560080",
    "end": "566080"
  },
  {
    "text": "you know separation there yeah i mean uh or nl obviously um",
    "start": "566080",
    "end": "572800"
  },
  {
    "text": "you heavily uh using slurm lsf um i put them all kind of together right tour slam lsf i",
    "start": "572800",
    "end": "580320"
  },
  {
    "text": "guess you know twerks kind of on the outs i guess these days but you know pbs all those right um",
    "start": "580320",
    "end": "586720"
  },
  {
    "text": "you know a lot of times you know certainly for us right the the vendor that we buy the super computer from at",
    "start": "586720",
    "end": "593120"
  },
  {
    "text": "the scale that they're building right you know like they're gonna it's gonna come it came with lsf right we bought an",
    "start": "593120",
    "end": "598399"
  },
  {
    "text": "ibm machine it came with lsf so you know those sorts of things i don't think are going away for",
    "start": "598399",
    "end": "603440"
  },
  {
    "text": "that traditional hpc community kind of like what bob's talking about right and so for us it was the name of the game is",
    "start": "603440",
    "end": "609200"
  },
  {
    "text": "like how do we how do we bridge that gap as much as possible how can people use the slurm commands s batch from inside",
    "start": "609200",
    "end": "616160"
  },
  {
    "text": "of a container that sort of thing so that's the direction that we've gone but yeah i don't i don't see those",
    "start": "616160",
    "end": "622880"
  },
  {
    "text": "getting supplanted i mean you know they've got like 30 years of like industry research being poured into those batch schedulers they're not going",
    "start": "622880",
    "end": "629440"
  },
  {
    "text": "to like go away overnight right so yeah yeah",
    "start": "629440",
    "end": "635200"
  },
  {
    "text": "that makes sense so any anything else in this topic",
    "start": "636800",
    "end": "644560"
  },
  {
    "text": "uh i guess for what it's worth i do see more people looking to transition or at least support running both um",
    "start": "644560",
    "end": "650800"
  },
  {
    "text": "largely just because it's a lot honestly easier especially these days um to get",
    "start": "650800",
    "end": "657440"
  },
  {
    "text": "up and going in kubernetes to potentially burst out to some place um",
    "start": "657440",
    "end": "663600"
  },
  {
    "text": "and a lot of the at least at my old job a lot of the researchers",
    "start": "663600",
    "end": "668959"
  },
  {
    "text": "were more interested in using things like keep flow and and it just made it a lot easier to get going there",
    "start": "668959",
    "end": "675600"
  },
  {
    "text": "yeah i agree i think it's a both and i completely agree about",
    "start": "675600",
    "end": "680560"
  },
  {
    "text": "yeah and see what one sorry go ahead no go ahead go ahead i was going to say like one question",
    "start": "681760",
    "end": "687680"
  },
  {
    "text": "there would be is there anything that is prohibiting people from moving towards using vanilla",
    "start": "687680",
    "end": "693040"
  },
  {
    "text": "kubernetes as the scheduler of choice or is it mostly just familiarity with the old stuff so let's continue using",
    "start": "693040",
    "end": "699760"
  },
  {
    "text": "what is not broken i guess yeah i think the answer there is there are things missing and uh at least for",
    "start": "699760",
    "end": "706800"
  },
  {
    "text": "us at least for us the things that are missing is uh like",
    "start": "706800",
    "end": "711920"
  },
  {
    "text": "priority queueing uh the notion of a queue on top of just the workloads on kubernetes and then the notion of fair",
    "start": "711920",
    "end": "718880"
  },
  {
    "text": "share to optimize the cluster usage that's another one",
    "start": "718880",
    "end": "724560"
  },
  {
    "text": "that is that is also stopping us priorities and preemptions exist already",
    "start": "724560",
    "end": "730639"
  },
  {
    "text": "at level of bots so that's already something there yeah um there was a very nice talk at the last",
    "start": "730639",
    "end": "737519"
  },
  {
    "text": "coupon from um i forget his name you one from apple",
    "start": "737519",
    "end": "742959"
  },
  {
    "text": "apple right yeah yeah you shared that i think on the exception yeah so they are trying to implement",
    "start": "742959",
    "end": "748079"
  },
  {
    "text": "those concepts on on the on the scheduler and this is also what like volcano is doing similarly",
    "start": "748079",
    "end": "755040"
  },
  {
    "text": "yeah so then and then therefore a follow-up would be kubernetes allows for custom",
    "start": "755040",
    "end": "760160"
  },
  {
    "text": "schedulers so i mean in fact i think volcano is an example of that are people building their own custom",
    "start": "760160",
    "end": "766079"
  },
  {
    "text": "schedulers because they're supposedly have not done myself but supposedly fairly straightforward to",
    "start": "766079",
    "end": "771360"
  },
  {
    "text": "build so is it something that people consider and people say we'll just build our own scheduler is that an option",
    "start": "771360",
    "end": "778240"
  },
  {
    "text": "like i i've seen people building their own scheduler uh there was a it was a problem for a bit because there",
    "start": "778240",
    "end": "784480"
  },
  {
    "text": "weren't a lot of hooks into the various different points scheduling gets considered however uh that has largely uh changed",
    "start": "784480",
    "end": "792480"
  },
  {
    "text": "um i think as of the 1 21 release so like this this past year",
    "start": "792480",
    "end": "799120"
  },
  {
    "text": "there is a significantly more hooks added to uh potentially you know",
    "start": "799120",
    "end": "804720"
  },
  {
    "text": "to make x writing or extending schedulers easier i think okay yeah it might be just it might be more",
    "start": "804720",
    "end": "812000"
  },
  {
    "text": "than just hooking the scheduler as well like if you want to introduce queues you actually need to to handle the persistency of those queues and if you",
    "start": "812000",
    "end": "818880"
  },
  {
    "text": "want to have multiple queues and a priority there's quite a bit of logic there that all these systems are very",
    "start": "818880",
    "end": "825120"
  },
  {
    "text": "good at because they've been developed for ages now a lot of them so",
    "start": "825120",
    "end": "831360"
  },
  {
    "text": "so it's not like a obvious transition i see okay better",
    "start": "831360",
    "end": "837120"
  },
  {
    "text": "that's it thank you we looked at that",
    "start": "837120",
    "end": "842880"
  },
  {
    "text": "briefly and um the issue for us was that we wanted to be able to schedule across multiple",
    "start": "842880",
    "end": "849839"
  },
  {
    "text": "clusters and so um",
    "start": "849839",
    "end": "855440"
  },
  {
    "text": "then you look at cube fed and that it didn't all work to do multiple classes which is why we ended up writing",
    "start": "855440",
    "end": "861760"
  },
  {
    "text": "armada i mean it was easy enough to do the uh custom scheduler part of it but not",
    "start": "861760",
    "end": "868160"
  },
  {
    "text": "the multi-cluster part so i think it's good points that's a good",
    "start": "868160",
    "end": "874160"
  },
  {
    "text": "point actually like the experiments we've been doing with managing things like hd condor with kubernetes even if",
    "start": "874160",
    "end": "879920"
  },
  {
    "text": "we are still submitting like under we could have multiple clusters managing the condor daemons and then have central",
    "start": "879920",
    "end": "886959"
  },
  {
    "text": "schedulers somewhere else so you could kind of benefit from the kubernetes uh",
    "start": "886959",
    "end": "894639"
  },
  {
    "text": "like operations uh simplification but then still use condor",
    "start": "894639",
    "end": "901360"
  },
  {
    "text": "i always thought your uh reason for not moving away from condors less about the lack of features and kubernetes more just the sort of inertia",
    "start": "902480",
    "end": "909040"
  },
  {
    "text": "of being able to change user behavior and the fact that they will know how to use condo and thousands of them",
    "start": "909040",
    "end": "915279"
  },
  {
    "text": "yeah but fair share like fair share is is something that has to be there basically yeah but i mean even if you",
    "start": "915279",
    "end": "920959"
  },
  {
    "text": "did let's say that was you know you either use armada or yes it's just in kubernetes even so you'd still",
    "start": "920959",
    "end": "927120"
  },
  {
    "text": "have to convince a large user base to start doing something differently yeah",
    "start": "927120",
    "end": "932560"
  },
  {
    "text": "i think that's true for a lot of yeah my gut feeling is that's actually the",
    "start": "932560",
    "end": "938240"
  },
  {
    "text": "one of the main reasons that lots of these traditional places are using the traditional software because it's",
    "start": "938240",
    "end": "944320"
  },
  {
    "text": "how things have always been done and it's kind of hard to force people to change",
    "start": "944320",
    "end": "949680"
  },
  {
    "start": "950000",
    "end": "1070000"
  },
  {
    "text": "i've been joining a bunch of uh hpc meetups and it's amazing how focused",
    "start": "955279",
    "end": "962800"
  },
  {
    "text": "that group of people is on hardware like they're",
    "start": "962800",
    "end": "967839"
  },
  {
    "text": "so into the late breaking hardware and how much uh we're going to be able to pump over this pci pipe and the dram and",
    "start": "967839",
    "end": "975759"
  },
  {
    "text": "this and that and and they're just fascinated at throwing more hardware at",
    "start": "975759",
    "end": "980880"
  },
  {
    "text": "the problem as opposed to what we're talking about which is how to use that hardware more efficiently",
    "start": "980880",
    "end": "987920"
  },
  {
    "text": "and you know yeah i've gone to a couple meetings now",
    "start": "987920",
    "end": "993199"
  },
  {
    "text": "and it's absolutely at that lower level the entire conversation so just",
    "start": "993199",
    "end": "998639"
  },
  {
    "text": "interesting where people's heads are at one last question sorry so do you guys",
    "start": "998639",
    "end": "1004560"
  },
  {
    "text": "anticipate that the existing kubernetes",
    "start": "1004560",
    "end": "1009839"
  },
  {
    "text": "or the existing kubernetes scheduler the default category that comes with kubernetes will have options for a bunch of these uh going forward or is this",
    "start": "1009839",
    "end": "1016560"
  },
  {
    "text": "always going to be like you know default scheduler can only do this if you want something more specialized either build your own scheduler or like use this",
    "start": "1016560",
    "end": "1023279"
  },
  {
    "text": "other open source scheduler and whatnot is that where do you see that going",
    "start": "1023279",
    "end": "1028640"
  },
  {
    "text": "i guess maybe personally i would expect that this goes into the into some",
    "start": "1034160",
    "end": "1040079"
  },
  {
    "text": "not into the like necessarily upstream kubernetes but in some sort of like crd",
    "start": "1040079",
    "end": "1045760"
  },
  {
    "text": "and well supported by like to make them almost first class resources uh i don't know if they're",
    "start": "1045760",
    "end": "1052160"
  },
  {
    "text": "implemented as crds got it yeah",
    "start": "1052160",
    "end": "1058000"
  },
  {
    "text": "and it's not only like hpc htc it's also the yeah workloads",
    "start": "1059440",
    "end": "1065799"
  },
  {
    "start": "1070000",
    "end": "1470000"
  },
  {
    "text": "all right i think we move to the next one then it's question one",
    "start": "1070720",
    "end": "1076480"
  },
  {
    "text": "all right this one should be easier i think so actually the",
    "start": "1076640",
    "end": "1082720"
  },
  {
    "text": "this was pretty overwhelming on premises i think from all the responses we got one that mentioned hybrid",
    "start": "1082720",
    "end": "1090160"
  },
  {
    "text": "so i think this is uh i think the main question is is this",
    "start": "1090160",
    "end": "1095280"
  },
  {
    "text": "staying like this or are people looking at hybrid deployments as well",
    "start": "1095280",
    "end": "1100559"
  },
  {
    "text": "and what are the stoppers there",
    "start": "1101520",
    "end": "1105799"
  },
  {
    "text": "i mean for us it's staying like this",
    "start": "1110480",
    "end": "1114080"
  },
  {
    "text": "uh we're certainly evaluating and exploring hybrid for us the bigger issues were um",
    "start": "1116080",
    "end": "1125200"
  },
  {
    "text": "things like the united states um government data protection stuff around",
    "start": "1125200",
    "end": "1130559"
  },
  {
    "text": "fed ramp um authorizations and things like that that being a government entity that's that's",
    "start": "1130559",
    "end": "1137440"
  },
  {
    "text": "the biggest barrier um but we are starting to explore that uh",
    "start": "1137440",
    "end": "1143679"
  },
  {
    "text": "that hybrid thing but not not really for hpc it would be more for um",
    "start": "1143679",
    "end": "1149280"
  },
  {
    "text": "for workloads um that could that i don't know we haven't we don't we",
    "start": "1149280",
    "end": "1154559"
  },
  {
    "text": "don't certainly don't have any clear workloads that are like oh this would be perfect it's really just kind of exploring what's even possible so it's",
    "start": "1154559",
    "end": "1161039"
  },
  {
    "text": "very very early stages i would imagine a lot of this group have got a relatively established",
    "start": "1161039",
    "end": "1167440"
  },
  {
    "text": "infrastructure have already have on-prem so it would start there um probably all various different degrees of security concerns as well and",
    "start": "1167440",
    "end": "1174240"
  },
  {
    "text": "you sort of know what you have and how to trust it and also probably just large data sets as",
    "start": "1174240",
    "end": "1179760"
  },
  {
    "text": "well which is probably a factor which might keep you on prem because",
    "start": "1179760",
    "end": "1184960"
  },
  {
    "text": "you know transferring large amounts of data around the cloud could be prohibitively expensive and also needing that the equivalent",
    "start": "1184960",
    "end": "1192000"
  },
  {
    "text": "amount of compute to be able to make good use of it one of the reasons uh the university of",
    "start": "1192000",
    "end": "1197760"
  },
  {
    "text": "michigan was looking at it was because a lot of the grants were coming with like cloud credits so it'd be a lot",
    "start": "1197760",
    "end": "1203039"
  },
  {
    "text": "easier to give people one interface that they're familiar with and just sort of abstract it all away",
    "start": "1203039",
    "end": "1208480"
  },
  {
    "text": "so the cloud credits could go to you know it could be gcp it could be amazon it could be wherever but they're still",
    "start": "1208480",
    "end": "1213919"
  },
  {
    "text": "getting an interface they're familiar with and know how to work with it'll be interesting to see what a new",
    "start": "1213919",
    "end": "1219760"
  },
  {
    "text": "org would do that would fit into this group so if there was a new company or uh institution invented tomorrow",
    "start": "1219760",
    "end": "1227760"
  },
  {
    "text": "where would they go you imagine they would start in the cloud because it's easy to do so but",
    "start": "1227760",
    "end": "1233120"
  },
  {
    "text": "i don't know i suppose the counter argument jamie to like that",
    "start": "1233120",
    "end": "1240320"
  },
  {
    "text": "the big data sets we have on prem is that companies that use cloud data sets like",
    "start": "1240320",
    "end": "1247280"
  },
  {
    "text": "data providers who are cloud-based initially then if you're in the cloud",
    "start": "1247280",
    "end": "1253120"
  },
  {
    "text": "you don't have to move them as far to your on-prem uh location so",
    "start": "1253120",
    "end": "1259440"
  },
  {
    "text": "you know we might even be in that state for some",
    "start": "1259440",
    "end": "1264559"
  },
  {
    "text": "if we wanted to",
    "start": "1264559",
    "end": "1267279"
  },
  {
    "text": "yes it depends whether your net consumers or producers of data yeah yeah",
    "start": "1270000",
    "end": "1278400"
  },
  {
    "text": "all right i can i cannot hear we i think the answer for hybrid is is ours so",
    "start": "1282880",
    "end": "1289440"
  },
  {
    "text": "we are already deploying some workloads uh in this hybrid mode and the ones we do are the ones that are",
    "start": "1289440",
    "end": "1298480"
  },
  {
    "text": "from this embarrassing parallel type of workload but we also have a couple where we actually established links uh network",
    "start": "1298480",
    "end": "1306320"
  },
  {
    "text": "links between our on-premises data center and some regions in different clouds it allows us to kind of expand the data",
    "start": "1306320",
    "end": "1313039"
  },
  {
    "text": "center and in there we can do more like any kind of",
    "start": "1313039",
    "end": "1318400"
  },
  {
    "text": "co-located workload can go anywhere and still have dependent dependencies on on-premises services it's much easier to",
    "start": "1318400",
    "end": "1325919"
  },
  {
    "text": "do what was describing which is you will you depend on the kubernetes api and you you",
    "start": "1325919",
    "end": "1333600"
  },
  {
    "text": "you just use it for workloads that can be loosely coupled and don't have like interdependencies that would require a",
    "start": "1333600",
    "end": "1340799"
  },
  {
    "text": "low latency or some sort of special network connectivity and the motivation is really bursting",
    "start": "1340799",
    "end": "1346080"
  },
  {
    "text": "and especially for accelerators uh which we don't have many uh on premises right now",
    "start": "1346080",
    "end": "1353360"
  },
  {
    "text": "mind sharing like how much do you guys go into public cloud like when do you",
    "start": "1356880",
    "end": "1362880"
  },
  {
    "text": "when there is this thing how many number of nodes do you spin up uh in public cloud",
    "start": "1362880",
    "end": "1368720"
  },
  {
    "text": "for these kinds of when that happens well it depends like which unit uh for",
    "start": "1368720",
    "end": "1376240"
  },
  {
    "text": "for for the batch systems we can really tune the amount of resources that are there",
    "start": "1376240",
    "end": "1381440"
  },
  {
    "text": "um for for things like the ml workloads using things like kubeflow for example um we",
    "start": "1381440",
    "end": "1389520"
  },
  {
    "text": "actually auto scale the clusters so um they will they will only scale up when workloads",
    "start": "1389520",
    "end": "1396400"
  },
  {
    "text": "go there and we try to define policies on what can go there and do you have one kubernetes cluster",
    "start": "1396400",
    "end": "1401919"
  },
  {
    "text": "spanning your that's kind of a hybrid cluster spanning your on-prem and okay yeah",
    "start": "1401919",
    "end": "1407360"
  },
  {
    "text": "these are multiple ones yeah okay because i was like that how that that would be like a networking miracle",
    "start": "1407360",
    "end": "1413440"
  },
  {
    "text": "no it's possible because we for if you choose a region within a cloud you can",
    "start": "1413440",
    "end": "1418640"
  },
  {
    "text": "set up this uh this extensions of the network and we do that i can expand our own premises data center to this",
    "start": "1418640",
    "end": "1424400"
  },
  {
    "text": "specific region but this is not super flexible so ideally we would need this kubernetes api and setting up",
    "start": "1424400",
    "end": "1431679"
  },
  {
    "text": "sort of vpn if needed there's a very cool project that is called a",
    "start": "1431679",
    "end": "1437360"
  },
  {
    "text": "tensile coupe it's a very hacky thing but it's basically an implementation of the",
    "start": "1437360",
    "end": "1442559"
  },
  {
    "text": "virtual complete where the node is backed by coordinates oh yeah yeah",
    "start": "1442559",
    "end": "1447679"
  },
  {
    "text": "i in fact yeah i've heard of one more thing called nodeless where essentially it's virtual public again",
    "start": "1447679",
    "end": "1454080"
  },
  {
    "text": "but so essentially you behind the scenes it will go to wherever you want it to run and run wherever whatever you want",
    "start": "1454080",
    "end": "1460400"
  },
  {
    "text": "but again cool very cool all right",
    "start": "1460400",
    "end": "1465919"
  },
  {
    "text": "any other point here okay so then we move to",
    "start": "1465919",
    "end": "1473279"
  },
  {
    "start": "1470000",
    "end": "1575000"
  },
  {
    "text": "a question which was if not already do you plan to move these workloads to kubernetes",
    "start": "1473279",
    "end": "1478640"
  },
  {
    "text": "please expand and yeah the couple of questions we had was no",
    "start": "1478640",
    "end": "1484559"
  },
  {
    "text": "uh but uh the ones with more details it said we have workloads in kubernetes that's for hpc",
    "start": "1484559",
    "end": "1491440"
  },
  {
    "text": "some use governance to launch jobs on supercomputers i guess that kind of makes sense",
    "start": "1491440",
    "end": "1498880"
  },
  {
    "text": "then for some workloads i guess it's the answer",
    "start": "1498880",
    "end": "1504000"
  },
  {
    "text": "um portability being the reason and trying to burst",
    "start": "1504000",
    "end": "1510880"
  },
  {
    "text": "this is in line with what was describing earlier i guess uh mostly already on kubernetes planning",
    "start": "1510880",
    "end": "1517360"
  },
  {
    "text": "interested or another so i guess the the next question is what's stopping us",
    "start": "1517360",
    "end": "1522480"
  },
  {
    "text": "we already covered up it i don't know if anyone wants to add something",
    "start": "1522480",
    "end": "1528039"
  },
  {
    "text": "for those interested what is the stopper right now",
    "start": "1530799",
    "end": "1536840"
  },
  {
    "text": "everyone wants to dig in otherwise we move to the next one",
    "start": "1545760",
    "end": "1553000"
  },
  {
    "text": "and for like it was it was honestly just a lot of",
    "start": "1556000",
    "end": "1562159"
  },
  {
    "text": "it's what people were used to yeah started going back to what we were talking about earlier",
    "start": "1562159",
    "end": "1568159"
  },
  {
    "text": "i guess we already covered most of this i guess all right so we know jamie do you want",
    "start": "1568159",
    "end": "1574640"
  },
  {
    "text": "to pick up this one yeah sure so this is around asking",
    "start": "1574640",
    "end": "1580400"
  },
  {
    "start": "1575000",
    "end": "1840000"
  },
  {
    "text": "people if people access kubernetes directly or via an indirection layer uh",
    "start": "1580400",
    "end": "1586320"
  },
  {
    "text": "it's actually quite interesting i think so no responses for just directly",
    "start": "1586320",
    "end": "1592720"
  },
  {
    "text": "majority over the majority to being both um",
    "start": "1592720",
    "end": "1598880"
  },
  {
    "text": "none i suppose people are not using kubernetes at all presumably",
    "start": "1598880",
    "end": "1604320"
  },
  {
    "text": "um [Music] i suppose really is probably what i expected to see in a way",
    "start": "1604320",
    "end": "1611039"
  },
  {
    "text": "uh we can't really tell within the both how much is one or the other um and we've got different i mean in our",
    "start": "1611039",
    "end": "1618000"
  },
  {
    "text": "case anyway we've got different groups of users where some people are a bit more sort of power users and do access kubernetes directly",
    "start": "1618000",
    "end": "1625760"
  },
  {
    "text": "and obviously the administrators thereof but most of the our researchers anyway go through",
    "start": "1625760",
    "end": "1632640"
  },
  {
    "text": "tools which we build for them to help them do what they need to do rather than using",
    "start": "1632640",
    "end": "1638080"
  },
  {
    "text": "kubernetes directly i don't know what anyone else's thoughts on us",
    "start": "1638080",
    "end": "1644158"
  },
  {
    "text": "one question here when someone says that they use indirectly does it also mean",
    "start": "1645360",
    "end": "1651600"
  },
  {
    "text": "like crds and stuff is that also kind of indirect use of kubernetes or no i guess i was thinking more like whether",
    "start": "1651600",
    "end": "1657600"
  },
  {
    "text": "you're using cube ctl or not uh so cube c user cube ctl is direct anything outside of cube ctl is indirect",
    "start": "1657600",
    "end": "1664240"
  },
  {
    "text": "essential right yeah so some kind of python wrapper framework yeah yeah yeah so",
    "start": "1664240",
    "end": "1670000"
  },
  {
    "text": "some of our users will be doing stuff on kubernetes they might even know they're sort of using kubernetes in a way they're sort of using some tools build",
    "start": "1670000",
    "end": "1676799"
  },
  {
    "text": "an image and push it and then run some things and you know that's why we consider an industry",
    "start": "1676799",
    "end": "1684158"
  },
  {
    "text": "it's important also um for the all the role-based access control that we've discussed in the past and the past and",
    "start": "1686480",
    "end": "1693440"
  },
  {
    "text": "credential management of this",
    "start": "1693440",
    "end": "1697720"
  },
  {
    "text": "at the university of michigan we had people like at like every tier people that didn't care they didn't they never",
    "start": "1702320",
    "end": "1708240"
  },
  {
    "text": "wanted to see kubernetes they just cared that they had a container and it ran some place um",
    "start": "1708240",
    "end": "1714320"
  },
  {
    "text": "we had people that like wanted access for like troubleshooting purposes or just to",
    "start": "1714320",
    "end": "1720559"
  },
  {
    "text": "diagnose problems um but yeah we were able to like and then people wanted direct access to",
    "start": "1720559",
    "end": "1726960"
  },
  {
    "text": "the api um and we got really good at having our back",
    "start": "1726960",
    "end": "1732000"
  },
  {
    "text": "profiles to allow that sort of thing and make sure people you know couldn't you know couldn't get out of there basically name",
    "start": "1732000",
    "end": "1738720"
  },
  {
    "text": "space",
    "start": "1738720",
    "end": "1741039"
  },
  {
    "text": "i'm also learning a little bit about some of these modern newer projects or at least modern and newer for me uh",
    "start": "1745919",
    "end": "1752559"
  },
  {
    "text": "which is uh ray uh be a v-a-e-x",
    "start": "1752559",
    "end": "1757679"
  },
  {
    "text": "uh anything one more uh i think that's no not that stacks is different uh dusk",
    "start": "1757679",
    "end": "1762799"
  },
  {
    "text": "yeah and and some of those things i believe the way they expect you to run with kubernetes is you have your local cube",
    "start": "1762799",
    "end": "1768799"
  },
  {
    "text": "config so they the the das scheduler will run pods inside kubernetes so the",
    "start": "1768799",
    "end": "1774240"
  },
  {
    "text": "user who's using it doesn't know that you know i mean they know that there is kubernetes they have to set up some",
    "start": "1774240",
    "end": "1779520"
  },
  {
    "text": "things but they are not the user is not the one who runs the cube ctl created or whatnot",
    "start": "1779520",
    "end": "1784880"
  },
  {
    "text": "so it is again i don't know how many people are using these modern services yet",
    "start": "1784880",
    "end": "1790399"
  },
  {
    "text": "uh again i don't know about modern sorry i keep saying modern as if it's modern for me but",
    "start": "1790399",
    "end": "1796399"
  },
  {
    "text": "but uh but it's possible that some people may not they since they themselves don't use kubernetes it's some abstraction layer",
    "start": "1796399",
    "end": "1802880"
  },
  {
    "text": "there it's those might be the cases yeah",
    "start": "1802880",
    "end": "1808159"
  },
  {
    "text": "yeah i think for for the particular case of task it also depends how you use it because there's these two modes where",
    "start": "1808159",
    "end": "1814000"
  },
  {
    "text": "you can submit directly or using the task gateway yes okay yeah the das gateway one where each",
    "start": "1814000",
    "end": "1820720"
  },
  {
    "text": "user has their own cluster basically it's quite interesting we had we had a presentation a while ago",
    "start": "1820720",
    "end": "1826880"
  },
  {
    "text": "about this actually oh somewhere in the archive",
    "start": "1826880",
    "end": "1834039"
  },
  {
    "text": "let's move on so scale so we just asked uh",
    "start": "1837679",
    "end": "1843600"
  },
  {
    "start": "1840000",
    "end": "1965000"
  },
  {
    "text": "compute resources in terms of order of magnitude of cpu cores from 100 to over ten thousand",
    "start": "1843600",
    "end": "1850640"
  },
  {
    "text": "um the bigger well not so majority but yeah the the biggest",
    "start": "1850640",
    "end": "1855919"
  },
  {
    "text": "response is large which maybe isn't too surprising because that's the kind of thing we're all doing",
    "start": "1855919",
    "end": "1861840"
  },
  {
    "text": "um i don't know who's got less than 100 cpu calls interesting what they're up to they've got one cluster i suppose and they're",
    "start": "1861840",
    "end": "1867760"
  },
  {
    "text": "playing with it um well that was 20 that was two out of the",
    "start": "1867760",
    "end": "1873919"
  },
  {
    "text": "eight responses actually yeah we have half of the replies being 10 000 or more so it's it's really",
    "start": "1873919",
    "end": "1880960"
  },
  {
    "text": "irrelevant sizes yeah",
    "start": "1880960",
    "end": "1885360"
  },
  {
    "text": "how big is the biggest if people want to know to say",
    "start": "1886080",
    "end": "1891799"
  },
  {
    "text": "can you share with jamie or is it important because i don't think i'm allowed",
    "start": "1893200",
    "end": "1899600"
  },
  {
    "text": "it's bigger than that okay okay yeah",
    "start": "1899600",
    "end": "1904880"
  },
  {
    "text": "how about you guys goodbye how we can we can share it our data center is three hundred",
    "start": "1904880",
    "end": "1910320"
  },
  {
    "text": "thousand and eighty percent of that is for four patches",
    "start": "1910320",
    "end": "1915200"
  },
  {
    "text": "i think it's actually more now but yeah sometimes",
    "start": "1927679",
    "end": "1932679"
  },
  {
    "text": "what's the refresh cycle for you on hardware five years",
    "start": "1934399",
    "end": "1939440"
  },
  {
    "text": "that just goes along with the experiment uh that's different yeah no it doesn't",
    "start": "1939440",
    "end": "1945360"
  },
  {
    "text": "no it doesn't go with it it's just a five year warranty",
    "start": "1945360",
    "end": "1950559"
  },
  {
    "text": "all right should we move on",
    "start": "1956480",
    "end": "1960600"
  },
  {
    "text": "so the question was about gpus and it was actually it was the interest here was to see how",
    "start": "1968000",
    "end": "1974399"
  },
  {
    "text": "much people are already integrating accelerators into these kind of systems",
    "start": "1974399",
    "end": "1980240"
  },
  {
    "text": "so the replies are pretty much integrating them although",
    "start": "1980240",
    "end": "1986480"
  },
  {
    "text": "um only one in one case or no like",
    "start": "1986480",
    "end": "1991679"
  },
  {
    "text": "yeah still quite relevant with a thousand or more we still have quite a bit there",
    "start": "1991679",
    "end": "1997279"
  },
  {
    "text": "so one one question i had i don't know if people want to say other things about",
    "start": "1997279",
    "end": "2002960"
  },
  {
    "text": "this but one question that i had was uh what types of gpus are this is it all",
    "start": "2002960",
    "end": "2008320"
  },
  {
    "text": "nvidia or and also is there any sort of virtualization or is it all like pci",
    "start": "2008320",
    "end": "2014960"
  },
  {
    "text": "password like and dedicated cards for the jobs",
    "start": "2014960",
    "end": "2020799"
  },
  {
    "text": "anyone wants to pick this one",
    "start": "2026880",
    "end": "2031080"
  },
  {
    "text": "i'm wondering if the people not speaking are just not able or uh",
    "start": "2032559",
    "end": "2038640"
  },
  {
    "text": "shout for help on the chat if you can't communicate uh i just want to say that um the uh we we",
    "start": "2038640",
    "end": "2046000"
  },
  {
    "text": "added some gpus it that the hardware took like three months to come in and we",
    "start": "2046000",
    "end": "2051520"
  },
  {
    "text": "using the gpu operator got the nodes up and running allocatable in the cluster in like two days you know the gpu",
    "start": "2051520",
    "end": "2059200"
  },
  {
    "text": "operator was awesome and uh i really can't say enough about that i think it's",
    "start": "2059200",
    "end": "2064560"
  },
  {
    "text": "really cool how that's uh how nvidia is able to kind of do that and just kind of throw that over the fence and i don't",
    "start": "2064560",
    "end": "2070158"
  },
  {
    "text": "even know how much they support it i mean they do some but um it's uh it's just pretty solid i don't know it was",
    "start": "2070159",
    "end": "2076158"
  },
  {
    "text": "neat i was excited",
    "start": "2076159",
    "end": "2079679"
  },
  {
    "text": "all right sick of that are you doing any any sort of virtualization of the gpus or is it just",
    "start": "2081599",
    "end": "2089679"
  },
  {
    "text": "so actually we just here um uh gpus in to start doing some of that",
    "start": "2089679",
    "end": "2095839"
  },
  {
    "text": "stuff with but we haven't haven't played with those yet those are sitting on the floor getting getting installed hopefully in the next week so but yeah i",
    "start": "2095839",
    "end": "2102160"
  },
  {
    "text": "know we haven't it was they were voltas um i believe was the ones we have today so",
    "start": "2102160",
    "end": "2107520"
  },
  {
    "text": "but yeah so so then you know we get like a jupiter notebook that allocates a full volta and they use it like maybe less",
    "start": "2107520",
    "end": "2114240"
  },
  {
    "text": "than 10 of the time so we're like well this isn't you know that was kind of what kind of prompted the the ampere",
    "start": "2114240",
    "end": "2120160"
  },
  {
    "text": "having a little bit more finer grain control over scheduling so",
    "start": "2120160",
    "end": "2125440"
  },
  {
    "text": "yeah we we offer also the possibility to do uh this uh virtual",
    "start": "2125440",
    "end": "2130880"
  },
  {
    "text": "gpu that uh nvidia already supported with t4s and v100s but it was kind of",
    "start": "2130880",
    "end": "2137040"
  },
  {
    "text": "time sharing oh okay we realized that in addition to being very unstable in",
    "start": "2137040",
    "end": "2143119"
  },
  {
    "text": "terms of performance there were limitations in doing things like um",
    "start": "2143119",
    "end": "2149839"
  },
  {
    "text": "that there were there were some bits of functionality that that were not available um",
    "start": "2150079",
    "end": "2155760"
  },
  {
    "text": "for for for this sort of driver it also needs an additional license but that we we managed",
    "start": "2155760",
    "end": "2161760"
  },
  {
    "text": "i know that the new versions the 13x drivers already support all this",
    "start": "2161760",
    "end": "2167200"
  },
  {
    "text": "functionality that we required so we are giving it another ago but we also are expecting the 100s for for me",
    "start": "2167200",
    "end": "2174480"
  },
  {
    "text": "yeah cool okay that's good to know",
    "start": "2174480",
    "end": "2178960"
  },
  {
    "text": "is anyone doing anything other than nvidia",
    "start": "2184160",
    "end": "2188880"
  },
  {
    "text": "i don't know i don't think we're doing anything specific i'm also not sure what we're",
    "start": "2194640",
    "end": "2200160"
  },
  {
    "text": "allowed to talk about jamie in terms of what we're doing other than gpus uh",
    "start": "2200160",
    "end": "2206800"
  },
  {
    "text": "what do you think uh you mean other other vendors other than nvidia for gpu so it was a question",
    "start": "2206800",
    "end": "2212880"
  },
  {
    "text": "i think yeah or other type of accelerators i'll be talking about that question at this point",
    "start": "2212880",
    "end": "2218720"
  },
  {
    "text": "uh i don't think we've got on to that yeah okay i thought that was that yeah no um",
    "start": "2218720",
    "end": "2226240"
  },
  {
    "text": "i think we're just nvidia at the moment fair enough",
    "start": "2226240",
    "end": "2231119"
  },
  {
    "text": "hey ricardo have you what about you guys it's easier for now but uh yeah",
    "start": "2233839",
    "end": "2239760"
  },
  {
    "text": "we would like to get uh something in addition there are there are sites because we",
    "start": "2239760",
    "end": "2246720"
  },
  {
    "text": "collaborate with a bunch of sites uh around the world and there are sites that have amd cards as well",
    "start": "2246720",
    "end": "2252800"
  },
  {
    "text": "so we started looking at integrating them but they run properly code",
    "start": "2252800",
    "end": "2258720"
  },
  {
    "text": "but uh yeah for now it's it's all anything yeah i think they've got pretty mad",
    "start": "2258720",
    "end": "2265040"
  },
  {
    "text": "markets there or we get but we also have issues with the delivery times",
    "start": "2265040",
    "end": "2270480"
  },
  {
    "text": "yeah i've been waiting for them for months i think that's the case across the board at the moment for any kind of hardware really",
    "start": "2270480",
    "end": "2277680"
  },
  {
    "text": "all right i'll move to the next one because we're actually going fast on time as well",
    "start": "2280960",
    "end": "2288079"
  },
  {
    "start": "2285000",
    "end": "2445000"
  },
  {
    "text": "uh so the next one is uh other types of accelerators i put here fpgas but",
    "start": "2288079",
    "end": "2293839"
  },
  {
    "text": "actually one another reason we burst into the cloud is to use things like tpus as well",
    "start": "2293839",
    "end": "2299920"
  },
  {
    "text": "so i don't know if someone wants to expand here especially on the fpgas and maybe it",
    "start": "2299920",
    "end": "2306720"
  },
  {
    "text": "gives some details of how they are integrated",
    "start": "2306720",
    "end": "2311400"
  },
  {
    "text": "they're not integrated in any of our sort of cloud native kubernetes type stuff yet though that's all quite quite separate beasts",
    "start": "2318240",
    "end": "2325040"
  },
  {
    "text": "currently not to say it won't be ever",
    "start": "2325040",
    "end": "2329920"
  },
  {
    "text": "yeah and i think that sort of following that there are a bunch of ipu's and",
    "start": "2331200",
    "end": "2337760"
  },
  {
    "text": "tpus and you know insert whatever character you want",
    "start": "2337760",
    "end": "2345359"
  },
  {
    "text": "thing that people are dreaming up these days that we're looking at in",
    "start": "2345359",
    "end": "2350880"
  },
  {
    "text": "lots and lots of ways but uh yeah there's nothing that's actually doing anything at the moment",
    "start": "2350880",
    "end": "2357359"
  },
  {
    "text": "you know we're looking at all the graph cores and sub novas and",
    "start": "2357359",
    "end": "2363599"
  },
  {
    "text": "uh what are some of the other ones um takians or",
    "start": "2363599",
    "end": "2370320"
  },
  {
    "text": "what are those other ones um ascension or something like that there's a there's a bunch of those",
    "start": "2370320",
    "end": "2376480"
  },
  {
    "text": "things that are being tested and played around with but nothing that's gone near to production or kubernetes status so",
    "start": "2376480",
    "end": "2385920"
  },
  {
    "text": "bob do you know any any specifics about running fpgas and kubernetes",
    "start": "2389680",
    "end": "2396440"
  },
  {
    "text": "honestly i experimented with it back when i was at the university but like outside of",
    "start": "2399599",
    "end": "2404960"
  },
  {
    "text": "uh mounting the device into into the container like beyond that not really um",
    "start": "2404960",
    "end": "2411839"
  },
  {
    "text": "it never got beyond essentially me messing with it",
    "start": "2411839",
    "end": "2417599"
  },
  {
    "text": "okay um i haven't really looked at i haven't looked at it uh really since then",
    "start": "2417599",
    "end": "2425839"
  },
  {
    "text": "okay now maybe maybe we take it as an action act i'm also to to",
    "start": "2426000",
    "end": "2432079"
  },
  {
    "text": "investigate a bit uh where we are with this maximum peaking inspiration",
    "start": "2432319",
    "end": "2438960"
  },
  {
    "text": "i have at least two things which would be uh",
    "start": "2438960",
    "end": "2443119"
  },
  {
    "text": "to engage with other communities that we mentioned above",
    "start": "2444560",
    "end": "2450318"
  },
  {
    "start": "2445000",
    "end": "2505000"
  },
  {
    "text": "and now maybe investigate a bit more integration with fpgas this would be an interesting one",
    "start": "2450480",
    "end": "2457519"
  },
  {
    "text": "for those that replied like this is uh just like seen as a like an extra pci",
    "start": "2459599",
    "end": "2465440"
  },
  {
    "text": "device that is given to the job or how does that work",
    "start": "2465440",
    "end": "2470720"
  },
  {
    "text": "well oh sorry as uh um",
    "start": "2477839",
    "end": "2484880"
  },
  {
    "text": "i know there is a way of mounting the device directly in there uh intel actually has like an operator that that",
    "start": "2484880",
    "end": "2490560"
  },
  {
    "text": "does it too if i recall um",
    "start": "2490560",
    "end": "2495720"
  },
  {
    "text": "it's all through uh device plugins all right",
    "start": "2495839",
    "end": "2500880"
  },
  {
    "text": "okay i think we can move to the next one",
    "start": "2503680",
    "end": "2508960"
  },
  {
    "start": "2505000",
    "end": "2597000"
  },
  {
    "text": "authentication so we covered this a couple of times in the past",
    "start": "2508960",
    "end": "2514560"
  },
  {
    "text": "i think i don't know if anyone wants to add anything to what is already here i think we see",
    "start": "2517520",
    "end": "2523680"
  },
  {
    "text": "yeah x 509 in kerberos so off and",
    "start": "2523680",
    "end": "2528240"
  },
  {
    "text": "the main thing would be how are these credentials being maintained and like refreshed for",
    "start": "2528720",
    "end": "2534079"
  },
  {
    "text": "long-lived jobs and things like this i guess everyone has this sorted out or",
    "start": "2534079",
    "end": "2539200"
  },
  {
    "text": "any problems there",
    "start": "2539200",
    "end": "2542240"
  },
  {
    "text": "i think it's interesting that almost everyone who responds it's got multiple things which i think quite",
    "start": "2545440",
    "end": "2550880"
  },
  {
    "text": "telling i don't know anyone who seems to have got their stories straight on this completely",
    "start": "2550880",
    "end": "2558240"
  },
  {
    "text": "it's a lot i guess when you're dealing with legacy things and new things which we all are there's going to be a",
    "start": "2558240",
    "end": "2563839"
  },
  {
    "text": "combination floating around and that's always a challenge",
    "start": "2563839",
    "end": "2567760"
  },
  {
    "text": "we haven't got away from kerberos it's still alive and well",
    "start": "2569839",
    "end": "2574800"
  },
  {
    "text": "i mean if anything we're getting doing even more of it by the day",
    "start": "2576079",
    "end": "2582000"
  },
  {
    "text": "yeah it's like the zombie's hand coming out",
    "start": "2582000",
    "end": "2587520"
  },
  {
    "text": "of the crypt grabbing your ankle and just thinking yeah totally",
    "start": "2587520",
    "end": "2593799"
  },
  {
    "text": "there you go bye okay so uh maybe we jump to storage then uh",
    "start": "2594160",
    "end": "2600800"
  },
  {
    "start": "2597000",
    "end": "2698000"
  },
  {
    "text": "jamie do you want to take this one yeah sure uh so yeah question around how we handle data in our clusters what kind",
    "start": "2600800",
    "end": "2606160"
  },
  {
    "text": "of file systems people use or other um",
    "start": "2606160",
    "end": "2611440"
  },
  {
    "text": "quite split lots of ceph uh cfs that is um",
    "start": "2611440",
    "end": "2617680"
  },
  {
    "text": "people choosing multiple as well but yeah lustre gps hdfs as well",
    "start": "2617680",
    "end": "2623920"
  },
  {
    "text": "quite i mean there's yeah lots of different various responses i don't know is anyone",
    "start": "2623920",
    "end": "2630319"
  },
  {
    "text": "interested to know if the hdfs people are on the call actually i haven't talked much about that previously in our",
    "start": "2630319",
    "end": "2636079"
  },
  {
    "text": "group yeah to be interested",
    "start": "2636079",
    "end": "2641760"
  },
  {
    "text": "group whether any hdfs users are looking at ozone um",
    "start": "2641760",
    "end": "2647599"
  },
  {
    "text": "apache ozone is a replacement for hdfs uh if any hdfs users are on the call be",
    "start": "2647599",
    "end": "2653680"
  },
  {
    "text": "interested but maybe they're not",
    "start": "2653680",
    "end": "2661800"
  },
  {
    "text": "it doesn't seem like anyone i'm i'm misreading the color actually i'll just realize",
    "start": "2664800",
    "end": "2670480"
  },
  {
    "text": "that would be why yeah the pinkish thing is ffs lustre deprecating and gps gpfs as the future",
    "start": "2670480",
    "end": "2680560"
  },
  {
    "text": "all right i just saw here also in the chat nathan i don't know if you cannot turn the microphone because i",
    "start": "2686560",
    "end": "2693440"
  },
  {
    "text": "just saw a couple of comments that you had that would be quite interesting which would be",
    "start": "2693440",
    "end": "2698560"
  },
  {
    "text": "uh how many sites how many of these sites are using containers in sloan",
    "start": "2698560",
    "end": "2704800"
  },
  {
    "text": "yeah i mean we slurn's battle i mean forever had",
    "start": "2704800",
    "end": "2710800"
  },
  {
    "text": "integration with the standalone container systems and singularity has been",
    "start": "2710800",
    "end": "2717119"
  },
  {
    "text": "quite popular and the new container sport coming in just be nice to understand how sites are doing that",
    "start": "2717520",
    "end": "2725200"
  },
  {
    "text": "i mean in theory you could take a container run it here run it there",
    "start": "2725200",
    "end": "2729680"
  },
  {
    "text": "i mean that's the goal right",
    "start": "2730480",
    "end": "2733838"
  },
  {
    "text": "sort of i don't know i mean so did you see that apptaner is the new singularity they just they just",
    "start": "2736880",
    "end": "2742880"
  },
  {
    "text": "announced that the other day um the",
    "start": "2742880",
    "end": "2748800"
  },
  {
    "text": "i feel like i feel like you know hpc containers people want more than",
    "start": "2748800",
    "end": "2754240"
  },
  {
    "text": "than what they think they want kind of thing right i feel like the name of the game you know we were working for a while on trying to replicate",
    "start": "2754240",
    "end": "2761520"
  },
  {
    "text": "singularity contain or hpc containers with podman and really the amount of holes that you",
    "start": "2761520",
    "end": "2766960"
  },
  {
    "text": "kind of poke in the container it turns into more of a sieve than it does like a container right because you really you",
    "start": "2766960",
    "end": "2773200"
  },
  {
    "text": "really want to bind mount up all all of your your your blast libraries you know the gpu line you know you want",
    "start": "2773200",
    "end": "2779520"
  },
  {
    "text": "to pull all that stuff in off the host right you know it kind of kind of necessarily breaks that isolation you",
    "start": "2779520",
    "end": "2786079"
  },
  {
    "text": "know i mean i still think there's really good stuff about it um and uh and even like uh like nurse um",
    "start": "2786079",
    "end": "2793280"
  },
  {
    "text": "nurse showed that uh with what are they it's not singularity",
    "start": "2793280",
    "end": "2798480"
  },
  {
    "text": "they've got their they've got another one based on docker but that um python",
    "start": "2798480",
    "end": "2803520"
  },
  {
    "text": "applications actually perform faster across a cluster in a container than outside of a container right",
    "start": "2803520",
    "end": "2810480"
  },
  {
    "text": "it has to do with the python looks up paths for um linking for dynamic libraries and",
    "start": "2810480",
    "end": "2816960"
  },
  {
    "text": "stuff it doesn't have as many paths to look up in a container because the way that the way that you link in a",
    "start": "2816960",
    "end": "2822160"
  },
  {
    "text": "container i guess is compared to like a normal hpc host so it's kind of funny but um but i don't know i mean",
    "start": "2822160",
    "end": "2828319"
  },
  {
    "text": "i don't know we get we get tons of requests for people to to to support hpc",
    "start": "2828319",
    "end": "2833359"
  },
  {
    "text": "containers but um and people do use them but i don't know i feel like i feel like uh we always have to have",
    "start": "2833359",
    "end": "2840319"
  },
  {
    "text": "this like hard conversation of like okay well you're not going to get you know repeatability completely you're",
    "start": "2840319",
    "end": "2846800"
  },
  {
    "text": "not going to get isolation completely you know it's like all these little you add on to all these things you know",
    "start": "2846800",
    "end": "2854319"
  },
  {
    "text": "well that's there's been a lot of research",
    "start": "2854319",
    "end": "2859440"
  },
  {
    "text": "like a good number of sites on how to get the performance out of it like the common trick now is to bind",
    "start": "2859440",
    "end": "2866640"
  },
  {
    "text": "mount uh the mpi layer in so that you use you know especially on the craze",
    "start": "2866640",
    "end": "2872079"
  },
  {
    "text": "and then of course breaks a whole bunch of other stuff um none of these limits are new actually",
    "start": "2872079",
    "end": "2878559"
  },
  {
    "text": "let me go look up the paper or the presentation i have on it these these lip these these issues have been around a long",
    "start": "2878559",
    "end": "2884400"
  },
  {
    "text": "time um yep uh there was a group when you want to use when you want to go fast",
    "start": "2884400",
    "end": "2890400"
  },
  {
    "text": "you will lose compatibility yeah i mean necessarily",
    "start": "2890400",
    "end": "2896640"
  },
  {
    "text": "um you know 100 utilization isn't exactly the top of their list",
    "start": "2897200",
    "end": "2902240"
  },
  {
    "text": "or they want to have some kind of network isolation and they are willing to pay the price for having um",
    "start": "2902240",
    "end": "2909040"
  },
  {
    "text": "uh was it plaid or something along those lines on hpc that's just not acceptable",
    "start": "2909040",
    "end": "2914640"
  },
  {
    "text": "i mean you pay an obscene amount of money for your infiniband or whatever latency low",
    "start": "2914640",
    "end": "2921280"
  },
  {
    "text": "latency interconnect and you want to use it because then otherwise you could just be using the one gigabit ethernet",
    "start": "2921280",
    "end": "2929040"
  },
  {
    "text": "there's a good good quote um from another guy in a different lab who said that uh that hpc containers is teaching",
    "start": "2933200",
    "end": "2940559"
  },
  {
    "text": "a whole new generation um the uh of of linking um for errors right library linking",
    "start": "2940559",
    "end": "2948160"
  },
  {
    "text": "errors right you know and it's it's so true because you're right that's what you're doing you're mounting it off if you want to get the performance so yeah",
    "start": "2948160",
    "end": "2954880"
  },
  {
    "text": "here i put the uh the link in there i mean we did this back in 2017",
    "start": "2954880",
    "end": "2961760"
  },
  {
    "text": "um and these aren't solvable by containers or anything else i mean and the whole",
    "start": "2961760",
    "end": "2968079"
  },
  {
    "text": "world of issues come in when you want to swap architectures or compile against ssc 4 versus scc3 or whatever",
    "start": "2968079",
    "end": "2976640"
  },
  {
    "text": "and then there's a lot of sites with the hard requirements of reproducibility",
    "start": "2978079",
    "end": "2984720"
  },
  {
    "text": "and bit for bit reproducibility at which point you have to basically run",
    "start": "2984720",
    "end": "2989839"
  },
  {
    "text": "an emulator on a new piece of hardware to get that yeah and i mean it really does matter",
    "start": "2989839",
    "end": "2996000"
  },
  {
    "text": "because you run a csm or wharf and your hurricane hits louisiana versus",
    "start": "2996000",
    "end": "3003520"
  },
  {
    "text": "florida and it's the same input same program",
    "start": "3003520",
    "end": "3009359"
  },
  {
    "text": "uh there's a lot of problems with that um especially with the move to the uh",
    "start": "3009359",
    "end": "3016160"
  },
  {
    "text": "the single floats um the gpus i mean",
    "start": "3016160",
    "end": "3021599"
  },
  {
    "text": "you get the fancier nvidia ones with the double floats it's not as much of an issue but it still matters and then the",
    "start": "3021599",
    "end": "3027920"
  },
  {
    "text": "lack of the ieee float standard being consistently implemented completely",
    "start": "3027920",
    "end": "3034960"
  },
  {
    "text": "makes it entertaining um yeah i posted the link of a lot of the",
    "start": "3034960",
    "end": "3040559"
  },
  {
    "text": "limits that you know been around for a while um",
    "start": "3040559",
    "end": "3045760"
  },
  {
    "text": "i don't think anybody's gonna really solve any of these anytime soon",
    "start": "3045760",
    "end": "3050559"
  },
  {
    "text": "i mean once they solve the halting problem they can but my thought is more just to make sure",
    "start": "3050960",
    "end": "3057440"
  },
  {
    "text": "that the containers can work so the user can you know develop on their laptop",
    "start": "3057440",
    "end": "3063760"
  },
  {
    "text": "throw it on the hpc system throw in their kubernetes system or have them burst to each other whatever",
    "start": "3063760",
    "end": "3069440"
  },
  {
    "text": "but it'd be really nice to know how sites are doing that i mean right now there's",
    "start": "3069440",
    "end": "3074640"
  },
  {
    "text": "a lot of uh glue work that goes in for like um [Music]",
    "start": "3074640",
    "end": "3080800"
  },
  {
    "text": "getting jupiter books to work on hbc or some of them run them on kubernetes and",
    "start": "3080800",
    "end": "3086319"
  },
  {
    "text": "then burst out to hbc and stuff like that really nice to know about you know what",
    "start": "3086319",
    "end": "3092160"
  },
  {
    "text": "the sites really need what they're doing i mean i understand the use case of you know you want to use coop flow you",
    "start": "3092160",
    "end": "3098880"
  },
  {
    "text": "use argo or something like that or hell you don't care how it runs you just wanted to run",
    "start": "3098880",
    "end": "3105200"
  },
  {
    "text": "but yeah you hit a lot of the complications i mean in a lot of cases you're gonna have to recompile absolutely everything",
    "start": "3107119",
    "end": "3114000"
  },
  {
    "text": "to get it to the full performance you know when you're jumping from your laptop which may be like an armed chromebook",
    "start": "3114000",
    "end": "3121520"
  },
  {
    "text": "to you know a zeon box or something like that or",
    "start": "3121520",
    "end": "3126880"
  },
  {
    "text": "even a power eight or power power one power where we power ten now",
    "start": "3126880",
    "end": "3132400"
  },
  {
    "text": "we should probably do the rest of this because we've only got a few minutes yep let's browse with the rest and then we",
    "start": "3132400",
    "end": "3137680"
  },
  {
    "text": "can come back uh i think we can go over like three or four minutes till we started late as well",
    "start": "3137680",
    "end": "3143200"
  },
  {
    "text": "thanks a lot yeah um should we browse real quickly then",
    "start": "3143200",
    "end": "3150400"
  },
  {
    "start": "3147000",
    "end": "3315000"
  },
  {
    "text": "monitoring monitoring we see prometheus okay",
    "start": "3150880",
    "end": "3156480"
  },
  {
    "text": "uh fluently uh alerting with no use there's nothing",
    "start": "3156480",
    "end": "3163440"
  },
  {
    "text": "like very outstanding there it's pretty standard i guess yeah that's important",
    "start": "3163440",
    "end": "3170160"
  },
  {
    "text": "all right so this is coming a bit to what uh nathan was just referring which is uh how our container image is built i",
    "start": "3171200",
    "end": "3178319"
  },
  {
    "text": "think this is a one of the replies i had for him which is uh in most cases we don't have people",
    "start": "3178319",
    "end": "3184400"
  },
  {
    "text": "building locally they just push somewhere and there's some sort of ci cd that will build for multiple",
    "start": "3184400",
    "end": "3190240"
  },
  {
    "text": "architectures um so those systems here we get gitlab",
    "start": "3190240",
    "end": "3198160"
  },
  {
    "text": "jenkins tecton and then manually as well",
    "start": "3198160",
    "end": "3204079"
  },
  {
    "text": "but then gitlab tech manual again uh very likely manual okay there's quite",
    "start": "3204079",
    "end": "3210400"
  },
  {
    "text": "a lot of manual um jenkins",
    "start": "3210400",
    "end": "3216640"
  },
  {
    "text": "be nice to know how they're actually using the get lab runners with jenkins to do it",
    "start": "3217280",
    "end": "3222640"
  },
  {
    "text": "yeah so i can tell you i can tell you how we do it we have",
    "start": "3222640",
    "end": "3227760"
  },
  {
    "text": "multiple runners on each of the platforms and when you push your image they will build in parallel and then",
    "start": "3227760",
    "end": "3233760"
  },
  {
    "text": "push to the same registry and then whatever runtime is pulling the image will pull",
    "start": "3233760",
    "end": "3240240"
  },
  {
    "text": "based on the architecture that they are deployed on",
    "start": "3240240",
    "end": "3244960"
  },
  {
    "text": "does that answer your question right now i i meant more like they'd use an ssh to",
    "start": "3249760",
    "end": "3256000"
  },
  {
    "text": "go on a rest api what is the runner calling",
    "start": "3256000",
    "end": "3262160"
  },
  {
    "text": "or it's going straight through the coops the cube api",
    "start": "3262559",
    "end": "3267039"
  },
  {
    "text": "the runner for building the image you mean or yeah well like here the top one get lab runners",
    "start": "3268000",
    "end": "3274000"
  },
  {
    "text": "i mean there's a few things you could do with that right so i'm just wondering how they do it",
    "start": "3274000",
    "end": "3280720"
  },
  {
    "text": "so for the git lab runners you push to uh to a branch and then the the runner will will get the web",
    "start": "3280720",
    "end": "3287520"
  },
  {
    "text": "hook and will just pull clone the code and build locally on where the hardware the run is running",
    "start": "3287520",
    "end": "3293520"
  },
  {
    "text": "and we basically replicate them on all the architectures",
    "start": "3293520",
    "end": "3298319"
  },
  {
    "text": "someone wants to add something maybe",
    "start": "3302559",
    "end": "3307240"
  },
  {
    "text": "all right then we go through uh registries so we have all",
    "start": "3312319",
    "end": "3318400"
  },
  {
    "start": "3315000",
    "end": "3378000"
  },
  {
    "text": "it's the answer",
    "start": "3318400",
    "end": "3321720"
  },
  {
    "text": "anyone particularly happy or unhappy with their current choice",
    "start": "3323440",
    "end": "3330200"
  },
  {
    "text": "or any any hard issue to raise we use artifactory we've run into some",
    "start": "3335200",
    "end": "3340880"
  },
  {
    "text": "scaling problems with it but we've recently started looking at um dragonfly it's like a sort of caching",
    "start": "3340880",
    "end": "3348960"
  },
  {
    "text": "yeah and uh it's very early days but it looks pretty good actually we started originally looking at",
    "start": "3349359",
    "end": "3354799"
  },
  {
    "text": "something called kraken which i think was out of uber but it seems to have died in a ditch so then we sort of moved",
    "start": "3354799",
    "end": "3360000"
  },
  {
    "text": "sideways onto dragonfly and it looks pretty good and that's sort of taking some of the",
    "start": "3360000",
    "end": "3365599"
  },
  {
    "text": "pain away from mars factory",
    "start": "3365599",
    "end": "3369040"
  },
  {
    "text": "anyone else all right let's go through i think we",
    "start": "3373520",
    "end": "3378559"
  },
  {
    "start": "3378000",
    "end": "3403000"
  },
  {
    "text": "only have two more so languages um",
    "start": "3378559",
    "end": "3383760"
  },
  {
    "text": "it's pretty much like half is bison and then the other half split",
    "start": "3383760",
    "end": "3388960"
  },
  {
    "text": "some four turn so that's pretty good",
    "start": "3388960",
    "end": "3394160"
  },
  {
    "text": "anything to highlight to anyone",
    "start": "3395119",
    "end": "3398480"
  },
  {
    "text": "all right so we go quickly the last one additional tools i guess it's more regarding deployment here",
    "start": "3401520",
    "end": "3409520"
  },
  {
    "start": "3403000",
    "end": "3425000"
  },
  {
    "text": "there's terraform [Music] argan city public",
    "start": "3409520",
    "end": "3414640"
  },
  {
    "text": "twice yeah at home",
    "start": "3414640",
    "end": "3419920"
  },
  {
    "text": "sounds pretty reasonable i think uh i think that's it i don't know do we want to highlight",
    "start": "3419920",
    "end": "3426720"
  },
  {
    "start": "3425000",
    "end": "3437000"
  },
  {
    "text": "anything particular already three minutes over",
    "start": "3426720",
    "end": "3431880"
  },
  {
    "text": "pretty good and just want to say thank you for the people that responded yeah thank you",
    "start": "3433920",
    "end": "3438960"
  },
  {
    "start": "3437000",
    "end": "3502000"
  },
  {
    "text": "um yeah i think i think i i took a couple of uh action items uh",
    "start": "3438960",
    "end": "3446079"
  },
  {
    "text": "i took also from the discussion we just had here about uh how people are actually using containers",
    "start": "3446079",
    "end": "3451440"
  },
  {
    "text": "in these environments uh what's the motivation to do that and any kind of limitations they're writing on their",
    "start": "3451440",
    "end": "3457119"
  },
  {
    "text": "servers so maybe maybe we take those as um as topics for you for our next session",
    "start": "3457119",
    "end": "3464640"
  },
  {
    "text": "yeah otherwise yeah thank you very much everyone and um we meet in two weeks for",
    "start": "3464640",
    "end": "3472000"
  },
  {
    "text": "uh jamie's jen's session i think we are going to try and reach out to the",
    "start": "3472000",
    "end": "3477680"
  },
  {
    "text": "cartographers working group right let's see if it doesn't work",
    "start": "3477680",
    "end": "3483119"
  },
  {
    "text": "i hope you have your guitar once you need it sounds like it's on me to sort that out right",
    "start": "3483119",
    "end": "3489838"
  },
  {
    "text": "cool cool okay thank you very much thanks everyone thank you",
    "start": "3490720",
    "end": "3496480"
  },
  {
    "text": "bye later",
    "start": "3496480",
    "end": "3500359"
  },
  {
    "text": "you",
    "start": "3502720",
    "end": "3504799"
  }
]
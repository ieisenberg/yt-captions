[
  {
    "start": "0",
    "end": "23000"
  },
  {
    "text": "hi my name is carl weinmeister and i'm joined today by stefano firavonzo",
    "start": "2000",
    "end": "7440"
  },
  {
    "text": "we're going to talk about the data science odyssey from a notebook all the way through to",
    "start": "7440",
    "end": "12960"
  },
  {
    "text": "serving a model and everything in between we're going to cover a complete data science workflow",
    "start": "12960",
    "end": "18720"
  },
  {
    "text": "and introduce several products that help along the way let's get started the primary use case",
    "start": "18720",
    "end": "26000"
  },
  {
    "start": "23000",
    "end": "72000"
  },
  {
    "text": "we're going to cover is hyper parameter optimization which is the ability to search across a wide",
    "start": "26000",
    "end": "32238"
  },
  {
    "text": "variety of parameters to find the parameters that will create the best model",
    "start": "32239",
    "end": "39120"
  },
  {
    "text": "in general in this session we're going to learn about simplifying your hyper parameter tuning as well as",
    "start": "39120",
    "end": "45280"
  },
  {
    "text": "your serving workflows with intuitive uis the benefit is that you will accelerate",
    "start": "45280",
    "end": "51680"
  },
  {
    "text": "your time to production with reduced training time and reduced time to build a process you're going to",
    "start": "51680",
    "end": "59120"
  },
  {
    "text": "get to the answers that you want faster into deployment faster and finally we're going to cover",
    "start": "59120",
    "end": "64799"
  },
  {
    "text": "collaboration so reducing friction between the teams that build the model and the teams that deploy the model",
    "start": "64799",
    "end": "73280"
  },
  {
    "start": "72000",
    "end": "102000"
  },
  {
    "text": "first what's kubeflow so kubflow is an open source project aimed at making ml deployments simple",
    "start": "73280",
    "end": "82080"
  },
  {
    "text": "portable across on-prem multiple cloud environments and because it takes",
    "start": "82080",
    "end": "87920"
  },
  {
    "text": "advantage of kubernetes scalable so that you can run distributed training jobs",
    "start": "87920",
    "end": "93840"
  },
  {
    "text": "and so that you can serve your models in a way that can handle the wide variety of use that you",
    "start": "93840",
    "end": "100000"
  },
  {
    "text": "might have the use cases we're going to cover today",
    "start": "100000",
    "end": "105920"
  },
  {
    "start": "102000",
    "end": "171000"
  },
  {
    "text": "i cover quite a variety the first is that we're going to cover a complex ml",
    "start": "105920",
    "end": "112000"
  },
  {
    "text": "system at scale so we're going to cover more than what they might call a toy data set",
    "start": "112000",
    "end": "117360"
  },
  {
    "text": "where it's small it fits in one virtual machine we're going to talk about handling a more complex scenario we're going to",
    "start": "117360",
    "end": "124719"
  },
  {
    "text": "talk about rapid experimentation hyper hyperparameter tuning seeing how",
    "start": "124719",
    "end": "130319"
  },
  {
    "text": "all this can work in both hybrid and multi-cloud workloads and finally you might see how these",
    "start": "130319",
    "end": "136400"
  },
  {
    "text": "traditional concepts and software development of continuous integration and deployment might apply in the machine learning",
    "start": "136400",
    "end": "142400"
  },
  {
    "text": "world if you think about it there's a lot of similarities there",
    "start": "142400",
    "end": "148239"
  },
  {
    "text": "concepts like testing the input data testing the output of your model",
    "start": "148239",
    "end": "155200"
  },
  {
    "text": "making sure there's not a regression so that your model is better than it was before if you want",
    "start": "155200",
    "end": "160319"
  },
  {
    "text": "to deploy it all of these things you can codify into a pipeline that's reproducible and",
    "start": "160319",
    "end": "168080"
  },
  {
    "text": "definable within your notebook so the kubeflow platform has multiple",
    "start": "168080",
    "end": "175680"
  },
  {
    "text": "layers let's walk through each of those first you can bring whatever framework that",
    "start": "175680",
    "end": "182159"
  },
  {
    "text": "you're comfortable with whatever machine learning library you've learned or want to learn",
    "start": "182159",
    "end": "188000"
  },
  {
    "text": "you can use on kubeflow there are a variety of what we call operators that allow you",
    "start": "188000",
    "end": "193920"
  },
  {
    "text": "to run your training jobs and serve your models",
    "start": "193920",
    "end": "199840"
  },
  {
    "text": "in this layer we see the heart of kubeflow which is a set of components for capabilities like notebooks",
    "start": "200720",
    "end": "209440"
  },
  {
    "text": "kale which is going to help convert the notebook into a pipeline the pipeline itself which helps to",
    "start": "209440",
    "end": "215599"
  },
  {
    "text": "orchestrate your workflow hyperparameter tuning which is called cotton",
    "start": "215599",
    "end": "221920"
  },
  {
    "text": "and several other components we won't get into all of these right now you also see a variety of serving",
    "start": "221920",
    "end": "227120"
  },
  {
    "text": "components as well as capabilities for logging and monitoring the whole stack of things that are",
    "start": "227120",
    "end": "232480"
  },
  {
    "text": "necessary and all of this is built on top of",
    "start": "232480",
    "end": "237519"
  },
  {
    "text": "kubernetes so that you're able to run your workload across multiple environments and the way",
    "start": "237519",
    "end": "244560"
  },
  {
    "text": "that kubeflow is designed it will come naturally if you're comfortable with kubernetes concepts",
    "start": "244560",
    "end": "251599"
  },
  {
    "text": "all right let's walk through the workflow we're going to discuss in more detail today so the first step is in the jupyter",
    "start": "252560",
    "end": "259759"
  },
  {
    "text": "notebook itself which is available in the kubeflow environment in this notebook you're",
    "start": "259759",
    "end": "264880"
  },
  {
    "text": "going to start with identifying the problem and some data exploration and analysis next you choose an",
    "start": "264880",
    "end": "272560"
  },
  {
    "text": "algorithm code your model the next step is experimentation",
    "start": "272560",
    "end": "278240"
  },
  {
    "text": "and model training we're going to tune the model parameters and then finally we'll be able to serve",
    "start": "278240",
    "end": "284320"
  },
  {
    "text": "it and that will take us all the way through the key steps of the process",
    "start": "284320",
    "end": "289360"
  },
  {
    "start": "288000",
    "end": "316000"
  },
  {
    "text": "let's look at how kubeflow works so let's start with the user interface",
    "start": "289360",
    "end": "296560"
  },
  {
    "text": "a picture of the user interface you see on the left side each of the key capabilities from",
    "start": "296560",
    "end": "302560"
  },
  {
    "text": "notebooks pipelines experiments and so forth are available to you you also have a dashboard that shows up",
    "start": "302560",
    "end": "308639"
  },
  {
    "text": "where you see recent assets you've worked with and shortcuts to common",
    "start": "308639",
    "end": "313759"
  },
  {
    "text": "things that you might need to do in addition to the user interface the",
    "start": "313759",
    "end": "319759"
  },
  {
    "start": "316000",
    "end": "370000"
  },
  {
    "text": "command line is another way to interact with kubeflow so they're actually two command lines",
    "start": "319759",
    "end": "325840"
  },
  {
    "text": "that you might want to use so first there's the standard",
    "start": "325840",
    "end": "331360"
  },
  {
    "text": "kubernetes command line that allows you to do things like check the status of a trading job",
    "start": "331360",
    "end": "337759"
  },
  {
    "text": "and check the pods that are running maybe get some logs things of that nature you also have the kubeflow command line",
    "start": "337759",
    "end": "345680"
  },
  {
    "text": "utility which allows you to take templates that are yaml files and apply them to customize",
    "start": "345680",
    "end": "353840"
  },
  {
    "text": "your configuration finally there are apis and sdks so if",
    "start": "353840",
    "end": "360080"
  },
  {
    "text": "you're going to build a model pipeline you're going to create a hyperparameter tuning job",
    "start": "360080",
    "end": "365840"
  },
  {
    "text": "these capabilities are available through an sdk",
    "start": "365840",
    "end": "371199"
  },
  {
    "start": "370000",
    "end": "436000"
  },
  {
    "text": "and the final thing i'm going to mention before i turn it over to step note is that",
    "start": "371919",
    "end": "379039"
  },
  {
    "text": "ml code is one small part of the process what we're seeing here in this diagram",
    "start": "379039",
    "end": "385360"
  },
  {
    "text": "is from a famous paper about hidden technical debt of machine learning systems and what i want to point out is that",
    "start": "385360",
    "end": "392000"
  },
  {
    "text": "these are things that you need to do when your code goes into production it's inevitable you will need to think",
    "start": "392000",
    "end": "399039"
  },
  {
    "text": "about monitoring logging testing managing your resources making sure that",
    "start": "399039",
    "end": "406240"
  },
  {
    "text": "you have a reproducible environment so you'll have to build and manage that by working with the infrastructure that",
    "start": "406240",
    "end": "412720"
  },
  {
    "text": "we're talking about today you're able to work on top of that and leverage it so that you could focus on the data",
    "start": "412720",
    "end": "419759"
  },
  {
    "text": "science as well as putting together a process in a pipeline that matches the goals of your business",
    "start": "419759",
    "end": "426880"
  },
  {
    "text": "or your project and you can leverage all the great work that's been",
    "start": "426880",
    "end": "431919"
  },
  {
    "text": "happening in this project so with that i'm going to turn it over to stefan thank you carla for the great",
    "start": "431919",
    "end": "438160"
  },
  {
    "text": "introduction to kubeflow now that you have a general idea of the architecture of qflo and all of the",
    "start": "438160",
    "end": "444240"
  },
  {
    "text": "components that it provides you might wonder how you can actually use it to develop and then",
    "start": "444240",
    "end": "450000"
  },
  {
    "text": "continually improve and validate machine learning models using jupyter notebooks kale",
    "start": "450000",
    "end": "456960"
  },
  {
    "text": "kilflow pipelines and brock so this is exactly what we're going to do",
    "start": "456960",
    "end": "462000"
  },
  {
    "text": "in this tutorial but first let's have a high level overview over the end-to-end workflow that we are going to",
    "start": "462000",
    "end": "468639"
  },
  {
    "start": "463000",
    "end": "541000"
  },
  {
    "text": "implement so first that the end user you will start from a jupiter notebook so a",
    "start": "468639",
    "end": "475360"
  },
  {
    "text": "local environment where you can develop your models or your training algorithms etc",
    "start": "475360",
    "end": "481840"
  },
  {
    "text": "and then once you're done all you need to do is to use scale to annotate notebook cells",
    "start": "481840",
    "end": "489039"
  },
  {
    "text": "to convert this notebook into a scalable pipeline and afterwards you can",
    "start": "489039",
    "end": "495440"
  },
  {
    "text": "spin up a hyper parameter tuning job to run hundreds or thousands",
    "start": "495440",
    "end": "502800"
  },
  {
    "text": "of parallel pipelines once that's done you can use again kale",
    "start": "502800",
    "end": "509039"
  },
  {
    "text": "to select the best model out of this massive workload and then with a very",
    "start": "509039",
    "end": "516640"
  },
  {
    "text": "convenient api serve this model for everyone to use",
    "start": "516640",
    "end": "521680"
  },
  {
    "text": "each step of the way is tracked by mlmd so you can have an end-to-end lineage",
    "start": "521680",
    "end": "528080"
  },
  {
    "text": "of the workflow also each step is backed by pvcs and rocks rock takes a snapshot of these",
    "start": "528080",
    "end": "535680"
  },
  {
    "text": "pvcs to have a complete time machine of your workflow",
    "start": "535680",
    "end": "541519"
  },
  {
    "start": "541000",
    "end": "575000"
  },
  {
    "text": "this is our agenda we'll start from deployment kf so our local our development environment",
    "start": "542480",
    "end": "549600"
  },
  {
    "text": "and then you'll learn how to convert notebooks to pipelines and then how to scale up",
    "start": "549600",
    "end": "555279"
  },
  {
    "text": "this workflow with the car tip and hyperparameter tuning and afterwards",
    "start": "555279",
    "end": "560560"
  },
  {
    "text": "how to serve the best model so check out this url which will redirect you to a",
    "start": "560560",
    "end": "567600"
  },
  {
    "text": "code lab where you can follow all of the steps of this tutorial at your own pace",
    "start": "567600",
    "end": "575440"
  },
  {
    "start": "575000",
    "end": "610000"
  },
  {
    "text": "let's start by deploying mini kf mini kf is our own portable and opinionated",
    "start": "575680",
    "end": "581600"
  },
  {
    "text": "kubeflow distribution so mini kf runs seamlessly on gcp or on your laptop or",
    "start": "581600",
    "end": "588880"
  },
  {
    "text": "on any on-premises infrastructure mini kf is a single node vm is a single",
    "start": "588880",
    "end": "596160"
  },
  {
    "text": "node kubernetes vm that runs um kuber that runs cube flow",
    "start": "596160",
    "end": "601519"
  },
  {
    "text": "alongside rocks data management platform it is super easy to deploy and in just",
    "start": "601519",
    "end": "606640"
  },
  {
    "text": "15 minutes you have everything ready to go let's see how easy it is to deploy mini kf on gcp",
    "start": "606640",
    "end": "614480"
  },
  {
    "start": "610000",
    "end": "702000"
  },
  {
    "text": "so i'm in the console of my gcp project and what i need to do to create",
    "start": "614480",
    "end": "620720"
  },
  {
    "text": "a new mini kf is to head over the marketplace so i'm clicking on marketplace",
    "start": "620720",
    "end": "628959"
  },
  {
    "text": "and then search for mini kf here it is let's click",
    "start": "628959",
    "end": "638160"
  },
  {
    "text": "and launch all i need to do is to provide a name",
    "start": "638720",
    "end": "647839"
  },
  {
    "text": "and that's it after clicking deploy the deployment procedure will take",
    "start": "650720",
    "end": "656880"
  },
  {
    "text": "roughly 15 minutes and you will be able to monitor all of the resources that we are deploying",
    "start": "656880",
    "end": "663440"
  },
  {
    "text": "inside the virtual machine for now i'm just going to use a mini kf",
    "start": "663440",
    "end": "670000"
  },
  {
    "text": "i have already deployed so once you start the deployment procedure you will see this page",
    "start": "670000",
    "end": "675440"
  },
  {
    "text": "and once it's complete this url will be available to you so i'm copying the password of my newly",
    "start": "675440",
    "end": "682000"
  },
  {
    "text": "generated user i'm clicking on this link and i will be",
    "start": "682000",
    "end": "687040"
  },
  {
    "text": "redirected to my q flow home page",
    "start": "687040",
    "end": "693600"
  },
  {
    "text": "so now that our mini kf is ready to use let's start with the fun part that is how to convert the notebook into",
    "start": "694000",
    "end": "700959"
  },
  {
    "text": "a pipeline but first let's talk a little bit about google pipelines",
    "start": "700959",
    "end": "706079"
  },
  {
    "start": "702000",
    "end": "736000"
  },
  {
    "text": "pipelines is the one of the most important components in the qfl platform this is because data science is",
    "start": "706079",
    "end": "712160"
  },
  {
    "text": "inherently a pipeline process right you always go through the same repeated steps whether they be",
    "start": "712160",
    "end": "718320"
  },
  {
    "text": "data processing data transformation model training and then serving and so on and so forth",
    "start": "718320",
    "end": "723519"
  },
  {
    "text": "so in this tutorial we'll try to simplify as much as possible the deployment and creation of this kind of",
    "start": "723519",
    "end": "729920"
  },
  {
    "text": "workflows and how to make them completely reproducible we'll do this with kale and rock now converting a",
    "start": "729920",
    "end": "738320"
  },
  {
    "start": "736000",
    "end": "769000"
  },
  {
    "text": "notebook into a pipeline has several benefits first of all the notebook allows us to",
    "start": "738320",
    "end": "744399"
  },
  {
    "text": "clearly define what is the structure of the resulting pipeline and since we",
    "start": "744399",
    "end": "750240"
  },
  {
    "text": "have multiple cells we can easily parallelize and isolate them",
    "start": "750240",
    "end": "756320"
  },
  {
    "text": "also once you have a pipeline you can apply data versioning and even different hardware requirements",
    "start": "756320",
    "end": "762320"
  },
  {
    "text": "for running them like running the training step in gpu and data processing in a cpu",
    "start": "762320",
    "end": "770000"
  },
  {
    "start": "769000",
    "end": "843000"
  },
  {
    "text": "let's look at how the workflow changes when you apply when you use klm rock so before that",
    "start": "771360",
    "end": "778399"
  },
  {
    "text": "what you would need to do to create a kubeflow pipeline is to write your machine learning code maybe you test it locally",
    "start": "778399",
    "end": "784720"
  },
  {
    "text": "and then you would need to write some specific dsl code to construct and",
    "start": "784720",
    "end": "791760"
  },
  {
    "text": "define the pipeline and then build the docker images to package your code and all of your",
    "start": "791760",
    "end": "798000"
  },
  {
    "text": "dependencies and then build and upload the pipeline once you run it if you bump into any bug",
    "start": "798000",
    "end": "805200"
  },
  {
    "text": "or if you want to amend your code in any way you would need to go all the way back to building new docker images and then to redeploy",
    "start": "805200",
    "end": "812160"
  },
  {
    "text": "the pipeline but now with kale and rock this workflow gets dramatically simplified because you",
    "start": "812160",
    "end": "819199"
  },
  {
    "text": "just need to develop on your notebook tag your notebook cells",
    "start": "819199",
    "end": "824639"
  },
  {
    "text": "with a very simple ui that you'll see later and then run the pipeline with the click of a button without any docker",
    "start": "824639",
    "end": "830639"
  },
  {
    "text": "image building and you can imagine how this workflow dramatically improves um",
    "start": "830639",
    "end": "838800"
  },
  {
    "text": "your your speed to production and iteration",
    "start": "838800",
    "end": "843839"
  },
  {
    "start": "843000",
    "end": "926000"
  },
  {
    "text": "let's also talk about beta management and how rock integrates with kubeflow so this is a tfx paper from 2017",
    "start": "844720",
    "end": "853760"
  },
  {
    "text": "that talks about a high-level component of view of a machine learning platform so we can",
    "start": "853760",
    "end": "860320"
  },
  {
    "text": "see here where the tfx components the machine learning libraries fit in the",
    "start": "860320",
    "end": "866480"
  },
  {
    "text": "overall platform and in our case this is where kubeflow comes in to provide",
    "start": "866480",
    "end": "872240"
  },
  {
    "text": "this kind of components in a containerized way kubeflow also provides",
    "start": "872240",
    "end": "877600"
  },
  {
    "text": "the integrated front-end to manage deploy and monitor all of the various applications all of",
    "start": "877600",
    "end": "884160"
  },
  {
    "text": "this is orchestrated by kubernetes now when you write write a pipeline or a",
    "start": "884160",
    "end": "891279"
  },
  {
    "text": "machine application on top of cube though you need to you need some storage so in",
    "start": "891279",
    "end": "896480"
  },
  {
    "text": "general you would write a pipeline that is specific that interacts specifically",
    "start": "896480",
    "end": "901760"
  },
  {
    "text": "with the vendor api based on the kind of storage technology that you're using so",
    "start": "901760",
    "end": "909440"
  },
  {
    "text": "ericto comes in and provides a general purpose storage layer so that you can",
    "start": "909440",
    "end": "916240"
  },
  {
    "text": "write pipelines that are not specific that don't have to interact with a specific storage api",
    "start": "916240",
    "end": "921600"
  },
  {
    "text": "but can just access super fast local storage how do we do that well we've extended q",
    "start": "921600",
    "end": "928320"
  },
  {
    "text": "flow to b data ware and specifically to use",
    "start": "928320",
    "end": "933360"
  },
  {
    "text": "kubernetes primitives pvcs persistent volume claims in all of its applications",
    "start": "933360",
    "end": "938800"
  },
  {
    "text": "we do this by integrating with the container storage interface and sitting on the side of the critical",
    "start": "938800",
    "end": "945279"
  },
  {
    "text": "io path in this way you can read and write data super fast from local from local data from local",
    "start": "945279",
    "end": "953920"
  },
  {
    "text": "volumes and in the meanwhile every rock can take snapshots of your volumes",
    "start": "953920",
    "end": "962000"
  },
  {
    "text": "immutable snapshots and shared them across locations via an object store so you can reproduce",
    "start": "962000",
    "end": "969040"
  },
  {
    "text": "your environment or share it with your colleagues okay so now we are ready to put our",
    "start": "969040",
    "end": "976399"
  },
  {
    "text": "hands on a notebook and convert it to a pipeline this is kubeflow's central dashboard the",
    "start": "976399",
    "end": "983440"
  },
  {
    "text": "place where all of the keyplus components come together and where i can navigate between them as you can see",
    "start": "983440",
    "end": "990079"
  },
  {
    "text": "on my left i have notebooks volumes models snapshot pipelines and then experiments",
    "start": "990079",
    "end": "996160"
  },
  {
    "text": "and runs where we group together objects coming from different applications that belong",
    "start": "996160",
    "end": "1003360"
  },
  {
    "text": "to the same place like pipelines experiments or hyper parameter tuning experiments as a",
    "start": "1003360",
    "end": "1010959"
  },
  {
    "text": "data scientist the first thing i want to do is to create my own development environment",
    "start": "1010959",
    "end": "1016240"
  },
  {
    "text": "so i'm going to create a new notebook server",
    "start": "1016240",
    "end": "1020240"
  },
  {
    "text": "and it is a matter just of just a matter of um assigning a name and in a matter of",
    "start": "1023519",
    "end": "1029839"
  },
  {
    "text": "seconds i'll have a fully uh full jupiter lab environment ready to use",
    "start": "1029839",
    "end": "1039839"
  },
  {
    "text": "great so the first thing i want to do is to clone the cable repository to pull",
    "start": "1065520",
    "end": "1072000"
  },
  {
    "text": "the example that we're going to run",
    "start": "1072000",
    "end": "1075760"
  },
  {
    "text": "so git clone http github q flow",
    "start": "1078000",
    "end": "1085840"
  },
  {
    "text": "kale kale",
    "start": "1086559",
    "end": "1090960"
  },
  {
    "text": "great so i get into the kale folder the",
    "start": "1092840",
    "end": "1098799"
  },
  {
    "text": "examples folder and then the open vaccine kaggle competition folder",
    "start": "1098799",
    "end": "1108720"
  },
  {
    "start": "1108000",
    "end": "1204000"
  },
  {
    "text": "so we created this notebook to work on the open boxing kegel challenge as we wanted to tackle the real world",
    "start": "1108720",
    "end": "1115360"
  },
  {
    "text": "problem the challenge is about trying to locate the weak spots of a messenger rna structure",
    "start": "1115360",
    "end": "1122000"
  },
  {
    "text": "to help create a stable vaccine this notebook contains a typical data",
    "start": "1122000",
    "end": "1127440"
  },
  {
    "text": "science pipeline starting from data processing to",
    "start": "1127440",
    "end": "1132559"
  },
  {
    "text": "model training and then evaluation",
    "start": "1132559",
    "end": "1137840"
  },
  {
    "text": "i won't go too much into details of what this notebook is actually doing because we",
    "start": "1137919",
    "end": "1142960"
  },
  {
    "text": "don't care right now but you will be able to play with it after the demo",
    "start": "1142960",
    "end": "1148400"
  },
  {
    "text": "so the first thing i want to do is to verify that i have all my dependencies available",
    "start": "1148400",
    "end": "1155280"
  },
  {
    "text": "so let's run the imports apparently i need to install some libraries so let's do just that",
    "start": "1155280",
    "end": "1165840"
  },
  {
    "text": "notice how i am installing libraries here on the fly and you will see later",
    "start": "1168080",
    "end": "1176559"
  },
  {
    "text": "what this means okay so now everything should be",
    "start": "1177600",
    "end": "1183760"
  },
  {
    "text": "running smoothly now since i know my notebook is working",
    "start": "1183760",
    "end": "1192080"
  },
  {
    "text": "i want to convert it to a pipeline with kale so i'll head over here on the left on",
    "start": "1192080",
    "end": "1197440"
  },
  {
    "text": "the kale panel and enable it you can see a bunch of colors and badges pop up in the notebook",
    "start": "1197440",
    "end": "1204400"
  },
  {
    "start": "1204000",
    "end": "1226000"
  },
  {
    "text": "this is scale showing you how the notebook has been annotated you can use kale's note annotations tool",
    "start": "1204400",
    "end": "1213679"
  },
  {
    "text": "to actually change these annotations create new ones so each cell can be annotated with the",
    "start": "1213679",
    "end": "1220080"
  },
  {
    "text": "name of a corresponding pipeline step and its dependencies",
    "start": "1220080",
    "end": "1226240"
  },
  {
    "text": "for example here the processing data step depends on the load data step all the cells",
    "start": "1226240",
    "end": "1233280"
  },
  {
    "text": "belonging having the same color will eventually belong to the same pipeline",
    "start": "1233280",
    "end": "1240480"
  },
  {
    "text": "step that's all we need and if i click the compile and run button",
    "start": "1240480",
    "end": "1246840"
  },
  {
    "start": "1242000",
    "end": "1250000"
  },
  {
    "text": "ko analyzes the notebook validates it",
    "start": "1246840",
    "end": "1254320"
  },
  {
    "start": "1250000",
    "end": "1265000"
  },
  {
    "text": "and then starts to take a rock snapshot of the current environment to completely",
    "start": "1254320",
    "end": "1261120"
  },
  {
    "text": "reproduce the environment we are developing on so since i",
    "start": "1261120",
    "end": "1267200"
  },
  {
    "start": "1265000",
    "end": "1283000"
  },
  {
    "text": "just installed on the fly some python libraries my pipeline will run regardless",
    "start": "1267200",
    "end": "1274400"
  },
  {
    "text": "seamlessly without having to build new docker images thanks to snapchat",
    "start": "1274400",
    "end": "1280320"
  },
  {
    "text": "to rock snapshots then i can follow these deep links to",
    "start": "1280320",
    "end": "1286080"
  },
  {
    "text": "see what is going on if i click here i'm redirected",
    "start": "1286080",
    "end": "1292240"
  },
  {
    "text": "to the kubeflow pipelines run page where i can see the new run that starts",
    "start": "1294000",
    "end": "1301520"
  },
  {
    "text": "since this run will take a few minutes to complete i will head over to an experiment i run",
    "start": "1301520",
    "end": "1308000"
  },
  {
    "text": "previously and show you the resulting pipeline",
    "start": "1308000",
    "end": "1313280"
  },
  {
    "text": "after a few minutes of computation as you can see we have a four step pipeline",
    "start": "1313280",
    "end": "1320799"
  },
  {
    "text": "each step corresponds to an annotation in the in the original notebook so",
    "start": "1320799",
    "end": "1327039"
  },
  {
    "text": "multiple cells have been packaged inside this step by kl which is running",
    "start": "1327039",
    "end": "1333039"
  },
  {
    "text": "in this in the exact same original environment with all of your dependencies",
    "start": "1333039",
    "end": "1339440"
  },
  {
    "text": "also k creates machine learning metadata execution for each pipeline step this allows us to",
    "start": "1340080",
    "end": "1347360"
  },
  {
    "text": "track and link other entities that either belong or relate to the step itself",
    "start": "1347360",
    "end": "1352480"
  },
  {
    "text": "some examples are the parent kfp run and artifacts that are consumed and",
    "start": "1352480",
    "end": "1357919"
  },
  {
    "text": "produced by the step we can see them by clicking here",
    "start": "1357919",
    "end": "1363280"
  },
  {
    "text": "and navigating so as you can see this is an mlmd execution that was created by",
    "start": "1363280",
    "end": "1370320"
  },
  {
    "text": "kale i can click here to go to the specific page",
    "start": "1370320",
    "end": "1376480"
  },
  {
    "text": "and notice for example how the run id so the kfprl id the parent",
    "start": "1376559",
    "end": "1382880"
  },
  {
    "text": "of this step execution is clickable this is because we are standardizing on",
    "start": "1382880",
    "end": "1389440"
  },
  {
    "text": "using global uris to reference and link resources across qfl applications",
    "start": "1389440",
    "end": "1394880"
  },
  {
    "text": "and we are extending the queue flow uis to interpret these unique identifiers irrespectively",
    "start": "1394880",
    "end": "1401120"
  },
  {
    "text": "to where the uis actually live so clicking here will redirect me",
    "start": "1401120",
    "end": "1406320"
  },
  {
    "text": "to the original run page",
    "start": "1406320",
    "end": "1416159"
  },
  {
    "text": "likewise going back to the execution page i can scroll down and see that we took a rock snapshot",
    "start": "1416159",
    "end": "1426880"
  },
  {
    "text": "at the end of this step so we are linking with kale this snapshot",
    "start": "1426880",
    "end": "1434000"
  },
  {
    "text": "to the step execution and we can even navigate to the rock ui",
    "start": "1434000",
    "end": "1440000"
  },
  {
    "text": "now that we have converted the notebook into a single round pipeline we want to scale this up and optimize",
    "start": "1440640",
    "end": "1447120"
  },
  {
    "text": "our model with hyper-parameter tuning so how do we do that well we could start",
    "start": "1447120",
    "end": "1453520"
  },
  {
    "start": "1450000",
    "end": "1469000"
  },
  {
    "text": "tinkering manually with the parameters in the notebook and run manually multiple pipelines like",
    "start": "1453520",
    "end": "1461360"
  },
  {
    "text": "just like we did now and then compare the metrics and choose the best model or we could use",
    "start": "1461360",
    "end": "1467520"
  },
  {
    "text": "catib to automate this process so katib is the official q-flow",
    "start": "1467520",
    "end": "1473279"
  },
  {
    "text": "hyper-parameter tuner uh it supports several machine learning frameworks from",
    "start": "1473279",
    "end": "1478960"
  },
  {
    "text": "tensorflow mxnet by torch and others it is very flexible",
    "start": "1478960",
    "end": "1484320"
  },
  {
    "text": "and we've integrated it with kail to run it from a notebook so what we can do is we can go back to",
    "start": "1484320",
    "end": "1491520"
  },
  {
    "text": "the notebook configure inputs and outputs in a pipeline",
    "start": "1491520",
    "end": "1496960"
  },
  {
    "text": "so we can create a pipeline that accepts input parameters and produces metrics that katip can use",
    "start": "1496960",
    "end": "1503760"
  },
  {
    "text": "to optimize over the resulting pipelines and then still from the notebook select",
    "start": "1503760",
    "end": "1510400"
  },
  {
    "text": "the input hyperparameter tuning space the search algorithms and the goal afterwards",
    "start": "1510400",
    "end": "1518000"
  },
  {
    "text": "just with the click of a button directly from the notebook we can create and submit the new cutie job",
    "start": "1518000",
    "end": "1525278"
  },
  {
    "text": "let's see how we can do that we are back to our original notebook",
    "start": "1525600",
    "end": "1532320"
  },
  {
    "text": "so the previous pipeline completed successfully and now we want to optimize it with",
    "start": "1532320",
    "end": "1539120"
  },
  {
    "text": "hyper parameter tuning as we said before we need two things a pipeline with",
    "start": "1539120",
    "end": "1544799"
  },
  {
    "text": "inputs and outputs in q flow pipelines it's possible to create pipelines that",
    "start": "1544799",
    "end": "1552480"
  },
  {
    "text": "have input parameters so that can vary between pipeline runs and output metrics",
    "start": "1552480",
    "end": "1561440"
  },
  {
    "text": "with scale creating such a pipeline is very easy because you just need to create a",
    "start": "1561440",
    "end": "1567039"
  },
  {
    "text": "notebook cell with some variables assignment and then annotate it with the pipeline parameters",
    "start": "1567039",
    "end": "1573120"
  },
  {
    "text": "annotation and with this kale will make sure that the resulting pipeline will be parameterized",
    "start": "1573120",
    "end": "1579200"
  },
  {
    "text": "with these values and then to create a pipeline metric",
    "start": "1579200",
    "end": "1585600"
  },
  {
    "text": "all i need to do is to select to choose which variable i want to",
    "start": "1585600",
    "end": "1591520"
  },
  {
    "text": "basically print to output from my pipeline in this case i'll i'm choosing the",
    "start": "1591520",
    "end": "1596799"
  },
  {
    "text": "validation loss here produced by my training procedure and then",
    "start": "1596799",
    "end": "1602880"
  },
  {
    "text": "on the bottom of the notebook i can just print",
    "start": "1602880",
    "end": "1609520"
  },
  {
    "text": "the validation loss and annotated this cell with the pipeline",
    "start": "1609520",
    "end": "1615600"
  },
  {
    "text": "metrics annotation and this will make sure that the pipeline will output",
    "start": "1615600",
    "end": "1620640"
  },
  {
    "text": "a qft pipeline metric now if i want to start the hyper",
    "start": "1620640",
    "end": "1625840"
  },
  {
    "text": "parameter tuning job to spin up hundreds of pipelines all i need to do",
    "start": "1625840",
    "end": "1631200"
  },
  {
    "text": "is to enable this toggle and open up the scatter dialog",
    "start": "1631200",
    "end": "1636320"
  },
  {
    "text": "that k provides you can notice how kale already recognized all of the",
    "start": "1636320",
    "end": "1642880"
  },
  {
    "text": "variables that we've tagged with the pipeline parameters annotation",
    "start": "1642880",
    "end": "1648320"
  },
  {
    "text": "we have already pre-filled this dialog before but you could choose between ranges and",
    "start": "1648320",
    "end": "1655360"
  },
  {
    "text": "lists however you wanted in all of the input parameters",
    "start": "1655360",
    "end": "1661919"
  },
  {
    "text": "also you can choose between various search algorithms and then the search objective that in",
    "start": "1662720",
    "end": "1668640"
  },
  {
    "text": "this case it's just the validation loss we chose before and we want to minimize it",
    "start": "1668640",
    "end": "1676799"
  },
  {
    "start": "1677000",
    "end": "1734000"
  },
  {
    "text": "so just like that we've defined a hyperparameter tuning job and by clicking the compile and run button kale",
    "start": "1677520",
    "end": "1684960"
  },
  {
    "text": "will basically again validate the notebook convert it and build it into a queue",
    "start": "1684960",
    "end": "1690960"
  },
  {
    "text": "flow pipeline rog is taking now a snapshot of the current environment",
    "start": "1690960",
    "end": "1696080"
  },
  {
    "text": "to reproduce the current state in the pipelines and then kale also creates and submits",
    "start": "1696080",
    "end": "1704240"
  },
  {
    "text": "a new cartibate experiment where each cutting trial will correspond to",
    "start": "1704240",
    "end": "1711039"
  },
  {
    "text": "a pipeline run also we can see here a live view over",
    "start": "1711039",
    "end": "1717679"
  },
  {
    "text": "the current state of the katib experiment so as soon as new trials and new rounds",
    "start": "1717679",
    "end": "1726320"
  },
  {
    "text": "pop up and then complete you can monitor here directly from the notebook",
    "start": "1726320",
    "end": "1735279"
  },
  {
    "start": "1734000",
    "end": "1781000"
  },
  {
    "text": "now i can also click in this link and navigate to the katib ui",
    "start": "1735440",
    "end": "1742080"
  },
  {
    "text": "this is a catibui we have built from scratch following the design patterns that you",
    "start": "1746640",
    "end": "1754080"
  },
  {
    "text": "may find already in other kubeflow applications we've we've improved over uh the",
    "start": "1754080",
    "end": "1761360"
  },
  {
    "text": "existing catbuy to show much more and much more detailed information over",
    "start": "1761360",
    "end": "1768240"
  },
  {
    "text": "the status and various details of the experiments",
    "start": "1768240",
    "end": "1774000"
  },
  {
    "text": "since this experiment will take a lot of time to run let me show you something i run before",
    "start": "1774000",
    "end": "1781679"
  },
  {
    "start": "1781000",
    "end": "1891000"
  },
  {
    "text": "so i'm going here on the left selecting experiments and then hp tuning to go to the home page of our",
    "start": "1781679",
    "end": "1788320"
  },
  {
    "text": "new catib ui as you can see i have my new experiment running and i can also see",
    "start": "1788320",
    "end": "1796080"
  },
  {
    "text": "something around before with 50 trials and at a glance i can also see what was",
    "start": "1796080",
    "end": "1802640"
  },
  {
    "text": "the best metric and the corresponding configure input",
    "start": "1802640",
    "end": "1807919"
  },
  {
    "text": "configuration let's go in and see",
    "start": "1807919",
    "end": "1812720"
  },
  {
    "text": "so our new ui also exposes the state of the entire experiment with",
    "start": "1813440",
    "end": "1818880"
  },
  {
    "text": "this nice graph where you can see color coded all of the triads that have executed and",
    "start": "1818880",
    "end": "1825440"
  },
  {
    "text": "their parameter configurations this plot is interactive so that you can",
    "start": "1825440",
    "end": "1831200"
  },
  {
    "text": "also basically explore how the various parameter",
    "start": "1831200",
    "end": "1837200"
  },
  {
    "text": "configurations behaved and",
    "start": "1837200",
    "end": "1842480"
  },
  {
    "text": "how they they basically",
    "start": "1843279",
    "end": "1848480"
  },
  {
    "text": "influence the output of the experiment",
    "start": "1848480",
    "end": "1853840"
  },
  {
    "text": "you can see at a glance what was the best trial configuration what's the current",
    "start": "1853840",
    "end": "1860960"
  },
  {
    "text": "state of the experiment and then a list of all the trials and when you hover on a row you see the",
    "start": "1860960",
    "end": "1868559"
  },
  {
    "text": "specific trial and its configuration in the graph by scrolling down",
    "start": "1868559",
    "end": "1877279"
  },
  {
    "text": "we can see at a glance also which one was the best trial this one highlighted",
    "start": "1877279",
    "end": "1885440"
  },
  {
    "text": "here it is if i click on this pipeline icon here on the right i",
    "start": "1888640",
    "end": "1895840"
  },
  {
    "text": "will be redirected to the corresponding q flow pipeline run",
    "start": "1895840",
    "end": "1902880"
  },
  {
    "text": "this is because each trial corresponds to a specific pipeline run so we want",
    "start": "1902880",
    "end": "1908399"
  },
  {
    "text": "you to be able to navigate between uis seamlessly and link together all of the entities",
    "start": "1908399",
    "end": "1916559"
  },
  {
    "text": "if i click on config here i can i also have some new category related entries",
    "start": "1917279",
    "end": "1924799"
  },
  {
    "text": "and navigate back to the original katib experiment so you",
    "start": "1924799",
    "end": "1931279"
  },
  {
    "text": "always know where you are and how specific objects and entities across",
    "start": "1931279",
    "end": "1936720"
  },
  {
    "text": "cube flow link together let's go back to the pipeline so this is the pipeline that performed",
    "start": "1936720",
    "end": "1945120"
  },
  {
    "text": "best in my original experiment you can also see that there are these",
    "start": "1945120",
    "end": "1951760"
  },
  {
    "start": "1948000",
    "end": "1988000"
  },
  {
    "text": "two icons this means that these two steps have been cached in fact when running a cutting",
    "start": "1951760",
    "end": "1958559"
  },
  {
    "text": "experiment not all not all steps need to be rerun across",
    "start": "1958559",
    "end": "1963679"
  },
  {
    "text": "across pipelines the first step in this pipeline that consumes the input",
    "start": "1963679",
    "end": "1969039"
  },
  {
    "text": "parameters is model training so we actually don't need to reload and reprocess the same",
    "start": "1969039",
    "end": "1975039"
  },
  {
    "text": "data over and over again so with rock and pvcs we're actually just skipping these",
    "start": "1975039",
    "end": "1981279"
  },
  {
    "text": "executions and starting from here from from a process data snapshot and let's",
    "start": "1981279",
    "end": "1988720"
  },
  {
    "start": "1988000",
    "end": "2042000"
  },
  {
    "text": "actually go see visually using mlmd since scale is logging",
    "start": "1988720",
    "end": "1996720"
  },
  {
    "text": "input and output artifacts for each step we can go look here at the artifacts",
    "start": "1996720",
    "end": "2003039"
  },
  {
    "text": "that the specific rock artifacts that are associated to this step so by clicking here i can navigate",
    "start": "2003039",
    "end": "2011279"
  },
  {
    "text": "to the rock snapshot artifact saved into mlmd then to the lineage explorer",
    "start": "2011279",
    "end": "2019840"
  },
  {
    "text": "and here this nice visualization allows me to understand that this rock snapshot artifact was",
    "start": "2020240",
    "end": "2028240"
  },
  {
    "text": "produced by many many steps and consumed",
    "start": "2028240",
    "end": "2033279"
  },
  {
    "text": "by many others this clearly means that all of these pipelines are using",
    "start": "2033279",
    "end": "2038880"
  },
  {
    "text": "the same step and so they were being cached now that we've run a massive hyper",
    "start": "2038880",
    "end": "2045519"
  },
  {
    "start": "2042000",
    "end": "2074000"
  },
  {
    "text": "parameter tuning job we want to take the best model and serve it with kf serving kf serving is kubeflow's",
    "start": "2045519",
    "end": "2054158"
  },
  {
    "text": "component for serving models into production it is based on k native and it allows serverless inferencing on",
    "start": "2054159",
    "end": "2061520"
  },
  {
    "text": "kubernetes so serving provides several abstractions on top of various machine learning",
    "start": "2061520",
    "end": "2067440"
  },
  {
    "text": "frameworks and provides quite a few features like canary deployments and scale to zero",
    "start": "2067440",
    "end": "2073118"
  },
  {
    "text": "and much more so what we want to do is to select the best trial of the",
    "start": "2073119",
    "end": "2078878"
  },
  {
    "start": "2074000",
    "end": "2121000"
  },
  {
    "text": "previous cutting experiment and restore a notebook out of a snapshot of that",
    "start": "2078879",
    "end": "2084158"
  },
  {
    "text": "of that pipeline so in this way we'll use rock to restore the notebook",
    "start": "2084159",
    "end": "2091118"
  },
  {
    "text": "from the best trained model and have the model directly into notebook memory",
    "start": "2091119",
    "end": "2096800"
  },
  {
    "text": "then we'll use a very convenient kale api to serve this model in general creating inference services",
    "start": "2096800",
    "end": "2103599"
  },
  {
    "text": "is quite a bit tedious as you can as you need to submit new crs",
    "start": "2103599",
    "end": "2110800"
  },
  {
    "text": "and maybe even build docker images if you're using pre-processing transformers you will see how this all becomes much",
    "start": "2110800",
    "end": "2117040"
  },
  {
    "text": "much easier with kale let's see how it's done",
    "start": "2117040",
    "end": "2122320"
  },
  {
    "start": "2121000",
    "end": "2203000"
  },
  {
    "text": "i'm back to the previous hyperparameter tuning experiment so i want to select the best trial",
    "start": "2122400",
    "end": "2130560"
  },
  {
    "text": "and then get the best model out of it and serve it so to do that i will first navigate",
    "start": "2130560",
    "end": "2138720"
  },
  {
    "text": "to the corresponding pipeline",
    "start": "2138720",
    "end": "2144400"
  },
  {
    "text": "and choose the last step in the pipeline this is",
    "start": "2144400",
    "end": "2150240"
  },
  {
    "text": "because i want to restore a notebook with the state after the model has been",
    "start": "2150240",
    "end": "2158160"
  },
  {
    "text": "trained so i'm heading over to visualizations",
    "start": "2158160",
    "end": "2163200"
  },
  {
    "text": "where kale has produced a bunch of artifacts so here i can see an artifact",
    "start": "2163200",
    "end": "2169839"
  },
  {
    "text": "corresponding to the first snapshot taken before the step execution",
    "start": "2169839",
    "end": "2175839"
  },
  {
    "text": "and then another artifact corresponding to a snapshot taken after the step",
    "start": "2175839",
    "end": "2182320"
  },
  {
    "text": "execution let's take the first one so i'll open this link",
    "start": "2182320",
    "end": "2187920"
  },
  {
    "text": "which will redirect me to the rock ui and specifically to this snapshot",
    "start": "2187920",
    "end": "2196560"
  },
  {
    "text": "page i'll copy this link which i can take back",
    "start": "2196560",
    "end": "2203280"
  },
  {
    "start": "2203000",
    "end": "2233000"
  },
  {
    "text": "to central dashboard i'll open up notebooks new server and i can copy here",
    "start": "2203280",
    "end": "2213359"
  },
  {
    "text": "um this special url which will make sure that my notebook is restored from this snapshot",
    "start": "2213359",
    "end": "2221280"
  },
  {
    "text": "let's call this actually let's call this",
    "start": "2221280",
    "end": "2226560"
  },
  {
    "text": "serving",
    "start": "2226839",
    "end": "2229839"
  },
  {
    "start": "2233000",
    "end": "2309000"
  },
  {
    "text": "now that my notebook is up when i click on connect something interesting happens so",
    "start": "2233920",
    "end": "2240480"
  },
  {
    "text": "kale notices that we are restoring an a notebook from a snapshot so what it",
    "start": "2240480",
    "end": "2248079"
  },
  {
    "text": "will do is it will automatically open up the original notebook and start",
    "start": "2248079",
    "end": "2255200"
  },
  {
    "text": "restoring a marshaling data uh so that the current in memory state is exactly",
    "start": "2255200",
    "end": "2263200"
  },
  {
    "text": "the one that i would have found um at that specific point in time",
    "start": "2263200",
    "end": "2268800"
  },
  {
    "text": "in the in the pipeline execution this means that i will find my model",
    "start": "2268800",
    "end": "2275839"
  },
  {
    "text": "in memory i will have in my python memory the best model trained out of the hyper",
    "start": "2275839",
    "end": "2282880"
  },
  {
    "text": "parameter tuning experiment that's it kale has completely completed the",
    "start": "2282880",
    "end": "2290880"
  },
  {
    "text": "resuming of the notebook i can create a new cell here and verify",
    "start": "2290880",
    "end": "2299520"
  },
  {
    "text": "that model actually is here i haven't done anything i just created a new notebook out of a snapshot and here it",
    "start": "2299520",
    "end": "2306160"
  },
  {
    "text": "is my model in memory okay so",
    "start": "2306160",
    "end": "2313440"
  },
  {
    "start": "2309000",
    "end": "2353000"
  },
  {
    "text": "now i have my best model here in the notebook and i want to serve it so kale provides",
    "start": "2313440",
    "end": "2320480"
  },
  {
    "text": "a very simple and convenient api to serve the model",
    "start": "2320480",
    "end": "2325680"
  },
  {
    "text": "let's see so i can import kale dot common dot servo tills",
    "start": "2325680",
    "end": "2332960"
  },
  {
    "text": "import serve and now i want to use this",
    "start": "2333040",
    "end": "2338839"
  },
  {
    "text": "function to to serve my model and it's just as",
    "start": "2338839",
    "end": "2344240"
  },
  {
    "text": "easy as saying serve model",
    "start": "2344240",
    "end": "2349599"
  },
  {
    "text": "but then i also want to to pass some pre-processing function",
    "start": "2349599",
    "end": "2356000"
  },
  {
    "start": "2353000",
    "end": "2388000"
  },
  {
    "text": "since kf serving supports both predictors and transformers we have",
    "start": "2356000",
    "end": "2361520"
  },
  {
    "text": "a very handy function here in the notebook which pre-processes features for us so",
    "start": "2361520",
    "end": "2368000"
  },
  {
    "text": "we can then pass just raw data to the corresponding model server let me",
    "start": "2368000",
    "end": "2374640"
  },
  {
    "text": "go here and redefine the function and the tokenizer",
    "start": "2374640",
    "end": "2381440"
  },
  {
    "text": "this function uses",
    "start": "2381440",
    "end": "2384640"
  },
  {
    "text": "so i'm back down to the bottom of the notebook and i want to tell my api that the corresponding model server will",
    "start": "2388640",
    "end": "2396480"
  },
  {
    "text": "have also to create a transformer",
    "start": "2396480",
    "end": "2402160"
  },
  {
    "text": "which will need to execute these process features function and",
    "start": "2402240",
    "end": "2412160"
  },
  {
    "text": "i will need to pass as well my tokenizer so that kale",
    "start": "2413119",
    "end": "2421680"
  },
  {
    "text": "knows that it needs to package this object alongside this function",
    "start": "2421680",
    "end": "2428160"
  },
  {
    "text": "so now that i'm running this we can see that ko recognizes the type of the model it",
    "start": "2429839",
    "end": "2436400"
  },
  {
    "text": "dumps it it saves it in a specific format and after this it starts it will start",
    "start": "2436400",
    "end": "2444800"
  },
  {
    "text": "taking a rock snapshot and afterwards creating a new inference service",
    "start": "2444800",
    "end": "2453838"
  },
  {
    "text": "okay",
    "start": "2478839",
    "end": "2481839"
  },
  {
    "start": "2494000",
    "end": "2761000"
  },
  {
    "text": "and now that the inference service is ready we can print this",
    "start": "2494880",
    "end": "2501440"
  },
  {
    "text": "object to see where it is served and by clicking here we can",
    "start": "2501440",
    "end": "2508240"
  },
  {
    "text": "navigate to our new models ui so we've built",
    "start": "2508240",
    "end": "2514480"
  },
  {
    "text": "a brand new ui to expose the entire state of kf serving to",
    "start": "2514480",
    "end": "2520880"
  },
  {
    "text": "monitor and expose all of the inference services that you may deploy as you can see here i have an overview",
    "start": "2520880",
    "end": "2529280"
  },
  {
    "text": "over where this model is exposed the fact that i deployed both a",
    "start": "2529280",
    "end": "2535520"
  },
  {
    "text": "predictor and a transformer and the entire state i can have",
    "start": "2535520",
    "end": "2544000"
  },
  {
    "text": "more details here about the various resources the fact that we are using a pvc where",
    "start": "2544000",
    "end": "2550319"
  },
  {
    "text": "it is mounted and then we can also have a look",
    "start": "2550319",
    "end": "2555760"
  },
  {
    "text": "at the various metrics exposed by the specific pods that are running one",
    "start": "2555760",
    "end": "2562160"
  },
  {
    "text": "for the predictor and one for the transformer",
    "start": "2562160",
    "end": "2567440"
  },
  {
    "text": "these are live updating metrics that come from the underlying k native",
    "start": "2569280",
    "end": "2576839"
  },
  {
    "text": "resources we can also see logs these are live logs",
    "start": "2576839",
    "end": "2583680"
  },
  {
    "text": "coming from the predictor and the transformer and we'll see how this update once we",
    "start": "2583680",
    "end": "2589040"
  },
  {
    "text": "send the prediction and also the yaml definition",
    "start": "2589040",
    "end": "2593839"
  },
  {
    "text": "and to have an overview of all the models we have a nice home page",
    "start": "2594400",
    "end": "2599839"
  },
  {
    "text": "where we can have a list we can see a list with a summary of all our of all our running model",
    "start": "2599839",
    "end": "2606000"
  },
  {
    "text": "servers okay so let's go back to the notebook",
    "start": "2606000",
    "end": "2613280"
  },
  {
    "text": "and actually send try to hit this model and get a prediction so i would want to",
    "start": "2613280",
    "end": "2621119"
  },
  {
    "text": "create a",
    "start": "2621119",
    "end": "2624480"
  },
  {
    "text": "a data some a data structure to to send to them to my model server for this",
    "start": "2627680",
    "end": "2635040"
  },
  {
    "text": "i'm creating a dictionary with an instances key which is a standard way to send",
    "start": "2635040",
    "end": "2642720"
  },
  {
    "text": "data to a tensorflow server and i'm going to pass our unprocessed",
    "start": "2642720",
    "end": "2650319"
  },
  {
    "text": "ex public test data that's this is some this is data that",
    "start": "2650319",
    "end": "2657200"
  },
  {
    "text": "we've defined before in the notebook and that was actually restored automatically",
    "start": "2657200",
    "end": "2662560"
  },
  {
    "text": "by ko so this is our data something that we will want to",
    "start": "2662560",
    "end": "2668960"
  },
  {
    "text": "to send and then to send a request to our model server",
    "start": "2668960",
    "end": "2676560"
  },
  {
    "text": "it's just as easy as saying kf serving dot predict data",
    "start": "2676560",
    "end": "2683440"
  },
  {
    "text": "actually it was kf server okay so sending a request",
    "start": "2685200",
    "end": "2692640"
  },
  {
    "text": "and let's head here to the logs page and you can see live that our",
    "start": "2692640",
    "end": "2698720"
  },
  {
    "text": "transformer is actually getting some input data and process data and then kale is doing some magic and",
    "start": "2698720",
    "end": "2705920"
  },
  {
    "text": "then the data is processed all these happened without having to",
    "start": "2705920",
    "end": "2714079"
  },
  {
    "text": "build any kind of docker image so kale was able to detect parse and package",
    "start": "2714079",
    "end": "2721839"
  },
  {
    "text": "the input processing function and its related assets create a new transformer initialize it",
    "start": "2721839",
    "end": "2730839"
  },
  {
    "text": "here then use it to actually process the raw data to be passed",
    "start": "2730839",
    "end": "2739680"
  },
  {
    "text": "to the to the predictor",
    "start": "2739680",
    "end": "2747680"
  },
  {
    "text": "and here i can print my predictions it should be quite a big response so",
    "start": "2747680",
    "end": "2755280"
  },
  {
    "text": "let's give jupiter lab a bit of time to process it here it is",
    "start": "2755280",
    "end": "2762240"
  },
  {
    "start": "2761000",
    "end": "2877000"
  },
  {
    "text": "that was the last part of our tutorial so now it's time to summarize what we've",
    "start": "2762640",
    "end": "2768160"
  },
  {
    "text": "learned today so you've learned you have learned how to",
    "start": "2768160",
    "end": "2773520"
  },
  {
    "text": "install and deploy mini kf in a super easy way and in no time and then how to use a",
    "start": "2773520",
    "end": "2781520"
  },
  {
    "text": "notebook to build some machine learning model and then using ko",
    "start": "2781520",
    "end": "2786720"
  },
  {
    "text": "annotate and deployed and converted to a scalable pipeline afterwards how to use scale to",
    "start": "2786720",
    "end": "2794720"
  },
  {
    "text": "even scale more this workload using hyper parameter tuning and run tens or hundreds of pipelines",
    "start": "2794720",
    "end": "2802000"
  },
  {
    "text": "using caching afterwards you've learned how using rock",
    "start": "2802000",
    "end": "2807760"
  },
  {
    "text": "and the snapshots that rock takes to reproduce every step of the way you can restore",
    "start": "2807760",
    "end": "2815040"
  },
  {
    "text": "a notebook from a pipeline to its previous state so in this case we took the best model",
    "start": "2815040",
    "end": "2820319"
  },
  {
    "text": "trained out of the hyperparameter tuning job to find the model ready to use in the",
    "start": "2820319",
    "end": "2826160"
  },
  {
    "text": "notebook's memory afterwards we used a convenient to use",
    "start": "2826160",
    "end": "2831359"
  },
  {
    "text": "scale api to serve this model directly from the notebook to make it production ready",
    "start": "2831359",
    "end": "2838880"
  },
  {
    "text": "all of this workflow was backed by mlmd so that you could have a complete lineage of the work",
    "start": "2838880",
    "end": "2846640"
  },
  {
    "text": "so we've also seen some cool new uis like the cate bui and the models ui",
    "start": "2846640",
    "end": "2853280"
  },
  {
    "text": "these uis are not open source yet but will work in the next weeks and",
    "start": "2853280",
    "end": "2858880"
  },
  {
    "text": "months to make sure that they will find their way into upstream cube flow",
    "start": "2858880",
    "end": "2864079"
  },
  {
    "text": "also note that this is a pre-recording and we are still heavily working on this",
    "start": "2864079",
    "end": "2869599"
  },
  {
    "text": "workflow so by the time you see this video some of the features might change or might see improvements",
    "start": "2869599",
    "end": "2877520"
  },
  {
    "start": "2877000",
    "end": "2956000"
  },
  {
    "text": "this is just a small sample of community contributions that we've done at richto we are investing a lot of time",
    "start": "2877599",
    "end": "2884559"
  },
  {
    "text": "and effort into making kubeflow a great platform for machine learning",
    "start": "2884559",
    "end": "2889839"
  },
  {
    "text": "so from jupiter manager to volume support mini kf and authorization manifest",
    "start": "2889839",
    "end": "2896880"
  },
  {
    "text": "installations across the board now qflow is a",
    "start": "2896880",
    "end": "2904000"
  },
  {
    "text": "big and vibrant community backed by many both large and small companies so if you feel",
    "start": "2904000",
    "end": "2909839"
  },
  {
    "text": "like you want to join as a developer or as an end user here is a list of",
    "start": "2909839",
    "end": "2915200"
  },
  {
    "text": "channels and public places that you can join and talk with us now",
    "start": "2915200",
    "end": "2923520"
  },
  {
    "text": "um all all the new things that you've seen today are the the product of the joint effort",
    "start": "2923520",
    "end": "2930480"
  },
  {
    "text": "of our internal team at a richto so i want to really thank all of my colleagues",
    "start": "2930480",
    "end": "2936000"
  },
  {
    "text": "who have contributed tons and tons of work to this so from ilias dimitris kimonos apostolos",
    "start": "2936000",
    "end": "2943040"
  },
  {
    "text": "constantinos and chris really thank you and thanks to you for sticking with us",
    "start": "2943040",
    "end": "2949200"
  },
  {
    "text": "until the end of this tutorial so now we are ready to answer all of your questions",
    "start": "2949200",
    "end": "2957839"
  }
]
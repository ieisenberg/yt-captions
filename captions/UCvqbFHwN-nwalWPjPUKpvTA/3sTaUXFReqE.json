[
  {
    "start": "0",
    "end": "120000"
  },
  {
    "text": "all right we're going to go ahead and get it sorry I'd like to thank everyone",
    "start": "7099",
    "end": "13170"
  },
  {
    "text": "who is generous today welcome to today's CN CF webinar resilient and fast burst and container",
    "start": "13170",
    "end": "20400"
  },
  {
    "text": "storage lovely Linux historic functionalities I am polymer solution junior and cloud",
    "start": "20400",
    "end": "27420"
  },
  {
    "text": "native practically there at Oracle Genesis as ambassador I don't I'll be",
    "start": "27420",
    "end": "33450"
  },
  {
    "text": "moderating today's webinar we would like to welcome our presenters today film has",
    "start": "33450",
    "end": "39480"
  },
  {
    "text": "nerve CEO of lean bid Christopher born weather enjoy college",
    "start": "39480",
    "end": "46579"
  },
  {
    "text": "also from Ling bit a few housekeeping items before we get started during the",
    "start": "46579",
    "end": "53280"
  },
  {
    "text": "webinar we are not able to talk as an attendee there is a key a box at the",
    "start": "53280",
    "end": "61710"
  },
  {
    "text": "bottom of your screen please feel free to drop your question in there and we will get to as many as we can at them",
    "start": "61710",
    "end": "69869"
  },
  {
    "text": "this is an official web ma webinar of CSF and SLE is subjects of CSF code",
    "start": "69869",
    "end": "78119"
  },
  {
    "text": "offed countered please do not add anything to the shed or questions that",
    "start": "78119",
    "end": "83250"
  },
  {
    "text": "would be in violation of that code of conduct basically please be respectful",
    "start": "83250",
    "end": "90689"
  },
  {
    "text": "of all of your travel parts plants and presenters please also note that the",
    "start": "90689",
    "end": "99960"
  },
  {
    "text": "record in the slide will be post later today to the CAF webinar page at mm CN",
    "start": "99960",
    "end": "107729"
  },
  {
    "text": "CF bio slash webinars with that we will",
    "start": "107729",
    "end": "113280"
  },
  {
    "text": "hand it over to Phillip to kick off today's presentation Thank You Paolo for",
    "start": "113280",
    "end": "122549"
  },
  {
    "start": "120000",
    "end": "200000"
  },
  {
    "text": "the introduction so my name is Phillip Eisner and I will put the pierre-yves",
    "start": "122549",
    "end": "130500"
  },
  {
    "text": "data store project in the spotlight today and that is kubernetes packaging",
    "start": "130500",
    "end": "141120"
  },
  {
    "text": "around Lin store and I will begin with some some slides about Lin store to give",
    "start": "141120",
    "end": "149580"
  },
  {
    "text": "you the let's say theoretical background about it and soil and Christophe do live",
    "start": "149580",
    "end": "158460"
  },
  {
    "text": "demos after operate and action and of the stock scheduler extension in actual",
    "start": "158460",
    "end": "169850"
  },
  {
    "text": "okay so let me introduce little bit for a minute so we are an organization of",
    "start": "169850",
    "end": "177750"
  },
  {
    "text": "about 30 people where our main",
    "start": "177750",
    "end": "183120"
  },
  {
    "text": "development office is in Vienna Austria and we have about 10 people on the west",
    "start": "183120",
    "end": "189660"
  },
  {
    "text": "coast of the US and we come from an 88",
    "start": "189660",
    "end": "195390"
  },
  {
    "text": "background and are now moving quickly into the software-defined storage area",
    "start": "195390",
    "end": "201709"
  },
  {
    "start": "200000",
    "end": "370000"
  },
  {
    "text": "so there if the foundation of all of that is the storage building blocks on",
    "start": "201709",
    "end": "209940"
  },
  {
    "text": "the linux kernel so i will fly over that real quick so there is a logic volume",
    "start": "209940",
    "end": "216780"
  },
  {
    "text": "manager in Linux and that's let's say Linux standard it has been there for",
    "start": "216780",
    "end": "222330"
  },
  {
    "text": "ages and what it does is it provides your fully allocated volumes which can",
    "start": "222330",
    "end": "230640"
  },
  {
    "text": "span multiple physical volumes and everything is marriage to Roland groups I'm pretty sure you are familiar with",
    "start": "230640",
    "end": "238380"
  },
  {
    "text": "that then that got extended with LVM",
    "start": "238380",
    "end": "244290"
  },
  {
    "text": "thin so an album thin one of these regular alvie's becomes a thin pool and",
    "start": "244290",
    "end": "250890"
  },
  {
    "text": "out of that we can create thinly allocated logic volumes and all the",
    "start": "250890",
    "end": "256470"
  },
  {
    "text": "snapshot of those and the main advantage is that the snapshot implementation this",
    "start": "256470",
    "end": "262740"
  },
  {
    "text": "area is a lot more capable than these",
    "start": "262740",
    "end": "268160"
  },
  {
    "text": "then there is a softer rate on the Linux",
    "start": "269730",
    "end": "274770"
  },
  {
    "text": "kernel so everything starting from striping to mirroring rate 5 4 8 6 8 10",
    "start": "274770",
    "end": "282870"
  },
  {
    "text": "it has two different front ends it's just one building block then there is",
    "start": "282870",
    "end": "290360"
  },
  {
    "text": "two implementations to use SSDs is",
    "start": "290360",
    "end": "295500"
  },
  {
    "text": "caching for rotating media and that's missing from the slide there's also an implementation that's targeted and using",
    "start": "295500",
    "end": "304460"
  },
  {
    "text": "PMM as cache for SSD so that is called TM right cache on the other end of the",
    "start": "304460",
    "end": "313380"
  },
  {
    "text": "performance scale there's also a deduplication building block so",
    "start": "313380",
    "end": "320820"
  },
  {
    "text": "full-blown in line in data path lead application you would use that if you",
    "start": "320820",
    "end": "329190"
  },
  {
    "text": "have let's say images of virtual machines where the same operating system",
    "start": "329190",
    "end": "335370"
  },
  {
    "text": "is installed there are targets and initiators and Linux just for ice cozy",
    "start": "335370",
    "end": "343890"
  },
  {
    "text": "and be merry fabrics etc and finally there's also CFS and Linux only relevant",
    "start": "343890",
    "end": "352620"
  },
  {
    "text": "to the bun to ecosystem and it brings about the same features as the LVM stack",
    "start": "352620",
    "end": "357960"
  },
  {
    "text": "when we look from it from a stand point of view where we only look at block",
    "start": "357960",
    "end": "364140"
  },
  {
    "text": "devices for the file system itself and then there is the DMD technology so that",
    "start": "364140",
    "end": "372570"
  },
  {
    "start": "370000",
    "end": "600000"
  },
  {
    "text": "debris forms an important part of our data plane so from a very high altitude",
    "start": "372570",
    "end": "380840"
  },
  {
    "text": "it is like a rate one between a local block device initiator and from there it",
    "start": "380840",
    "end": "386730"
  },
  {
    "text": "goes to a target and that sits on top of another block device in two different",
    "start": "386730",
    "end": "392910"
  },
  {
    "text": "nodes but this is not how its implemented on the Linux machine itself",
    "start": "392910",
    "end": "400080"
  },
  {
    "text": "it present you a block device note so deftly something a moment you open it",
    "start": "400080",
    "end": "407620"
  },
  {
    "text": "and the moment you mounted it demotes the role of this feebly and stands to",
    "start": "407620",
    "end": "413320"
  },
  {
    "text": "primary and that means everything is right there will be replicated over to the secondary if you unmount it it",
    "start": "413320",
    "end": "423010"
  },
  {
    "text": "denotes the secondary and a moment later you can mount it here and it will promote the primary and the direction of",
    "start": "423010",
    "end": "429790"
  },
  {
    "text": "replication is reversed so the goal is to make it very easy to access it it can",
    "start": "429790",
    "end": "437530"
  },
  {
    "text": "handle multiple volumes in a consistent way since I'm a little bit time",
    "start": "437530",
    "end": "445330"
  },
  {
    "text": "constraint I will not explain that in all the detail it can replicate to",
    "start": "445330",
    "end": "452910"
  },
  {
    "text": "multiple secondaries concurrently so this is like a 3-way replica of your",
    "start": "452910",
    "end": "461080"
  },
  {
    "text": "data it can also handle diskless nodes",
    "start": "461080",
    "end": "466210"
  },
  {
    "text": "and that can become in a cluster like anna kubernetes just important when the",
    "start": "466210",
    "end": "473169"
  },
  {
    "text": "kubernetes scheduler decides to move around the pods but we cannot move our",
    "start": "473169",
    "end": "479470"
  },
  {
    "text": "data replicas as quickly so we need a way to access it from arbitrary nodes so",
    "start": "479470",
    "end": "486340"
  },
  {
    "text": "you can imagine this like an iSCSI initiator that is connected to multiple",
    "start": "486340",
    "end": "492280"
  },
  {
    "text": "targets concurrently so for every read it needs to fulfill it can do a load",
    "start": "492280",
    "end": "498880"
  },
  {
    "text": "balancing scheme and send one read here and the other wait there for every write",
    "start": "498880",
    "end": "504340"
  },
  {
    "text": "it cuts down it sends to write concurrently to both peers",
    "start": "504340",
    "end": "509789"
  },
  {
    "text": "now it also shields the application from arrows right so if a read comes down the",
    "start": "509789",
    "end": "517060"
  },
  {
    "text": "stack it's sent to this node and this node fails this server will resend the",
    "start": "517060",
    "end": "526089"
  },
  {
    "text": "read here get the data and delivers it to the application so the application is",
    "start": "526089",
    "end": "531910"
  },
  {
    "text": "shielded from that arrow if that note returns after few minutes",
    "start": "531910",
    "end": "537069"
  },
  {
    "text": "or hours it will get an automatic resync only the Boxter changed in the meantime",
    "start": "537069",
    "end": "544990"
  },
  {
    "text": "and when that is finished is reintegrated and ready for i/o again",
    "start": "544990",
    "end": "552120"
  },
  {
    "text": "this technology comes from an age a background and has been in development",
    "start": "552360",
    "end": "558009"
  },
  {
    "text": "for about 20 years now it has a few features that only makes sense in the",
    "start": "558009",
    "end": "564339"
  },
  {
    "text": "age a world but it also comes with quorum that is a feature that fits a lot",
    "start": "564339",
    "end": "572889"
  },
  {
    "text": "better in a kubernetes world and what",
    "start": "572889",
    "end": "578439"
  },
  {
    "text": "happy recently done recently we optimized its metadata method in case",
    "start": "578439",
    "end": "585910"
  },
  {
    "text": "the metadata is located on PMM so that we even get more performance out of it",
    "start": "585910",
    "end": "595480"
  },
  {
    "text": "using the darks direct access access method then let's come to Lin store so",
    "start": "595480",
    "end": "606009"
  },
  {
    "start": "600000",
    "end": "660000"
  },
  {
    "text": "so far I talked about all these storage building blocks that are in Linux so nvm TBD then there's also an",
    "start": "606009",
    "end": "614079"
  },
  {
    "text": "encryption and the caching functions and video all these parts and all these",
    "start": "614079",
    "end": "621790"
  },
  {
    "text": "parts they are compatible on the data plane but all of them bring their own management tools and this is exactly",
    "start": "621790",
    "end": "629439"
  },
  {
    "text": "where Lin store comes into the picture so the idea of Lin story is it is a distributed application that runs on a",
    "start": "629439",
    "end": "636850"
  },
  {
    "text": "bunch of nodes and it manages all these storage components for you and presents",
    "start": "636850",
    "end": "642370"
  },
  {
    "text": "you one REST API and threw it at REST API you can request volumes like I need",
    "start": "642370",
    "end": "649120"
  },
  {
    "text": "a two-way replicated volumes that's the size that's the name etc and on top of",
    "start": "649120",
    "end": "654939"
  },
  {
    "text": "that REST API we have then connectors for kubernetes OpenStack and others so",
    "start": "654939",
    "end": "661779"
  },
  {
    "start": "660000",
    "end": "805000"
  },
  {
    "text": "let's go through that by the example so here on my cell",
    "start": "661779",
    "end": "667610"
  },
  {
    "text": "I call it a VM but for the kubernetes context this is a container or a pod so",
    "start": "667610",
    "end": "675290"
  },
  {
    "text": "we have nodes that have enough memory and CP CPU to carry the workload but",
    "start": "675290",
    "end": "682339"
  },
  {
    "text": "they also have built-in storage devices and if we get a request for a assistant",
    "start": "682339",
    "end": "690589"
  },
  {
    "text": "volume from kubernetes lynnster will place two replicas somewhere let's",
    "start": "690589",
    "end": "697940"
  },
  {
    "text": "assume the policy is the persistent volume should be two wave replicated and",
    "start": "697940",
    "end": "705459"
  },
  {
    "text": "ideally the workload the part is placed",
    "start": "705459",
    "end": "710930"
  },
  {
    "text": "on one node where we have a replica and this is solved by the stork scheduler",
    "start": "710930",
    "end": "717140"
  },
  {
    "text": "extension and we will look at that a little bit later so here we have the",
    "start": "717140",
    "end": "723260"
  },
  {
    "text": "optimal layout each ver cloud is co-located with one of the replicas so",
    "start": "723260",
    "end": "728269"
  },
  {
    "text": "it means all the read requests we have in that part we can fulfill them locally",
    "start": "728269",
    "end": "733550"
  },
  {
    "text": "we don't create any traffic on a network only for write operations we need to go",
    "start": "733550",
    "end": "740180"
  },
  {
    "text": "to network now a part might be relocated",
    "start": "740180",
    "end": "747880"
  },
  {
    "text": "in that case through the CSI driver you",
    "start": "747880",
    "end": "753019"
  },
  {
    "text": "will get this class if deras was there so that data is immediately available",
    "start": "753019",
    "end": "759130"
  },
  {
    "text": "but as you see now we also need to ship read requests over the network and it",
    "start": "759130",
    "end": "765310"
  },
  {
    "text": "takes either a time trigger policy or a single in store command and lynnster",
    "start": "765310",
    "end": "772339"
  },
  {
    "text": "will allocate an additional logic volume add that to the DVD configuration so it",
    "start": "772339",
    "end": "780470"
  },
  {
    "text": "can do a rethink of all the data to this new volume and when that we think is",
    "start": "780470",
    "end": "787430"
  },
  {
    "text": "finished it will remove the now redundant replicas since our policy says",
    "start": "787430",
    "end": "795230"
  },
  {
    "text": "we need to work we want to have two replicas of each persistent volume",
    "start": "795230",
    "end": "801319"
  },
  {
    "text": "so that's explained by example how it works now let's have a quick look at its",
    "start": "801319",
    "end": "807779"
  },
  {
    "start": "805000",
    "end": "1030000"
  },
  {
    "text": "architecture so it consists of two main parts one is the satellite the satellite",
    "start": "807779",
    "end": "817290"
  },
  {
    "text": "is a stateless component that needs to run on all storage nodes and all compute nodes and in context of kubernetes it's",
    "start": "817290",
    "end": "824429"
  },
  {
    "text": "it gets delivered as pod as a container",
    "start": "824429",
    "end": "830939"
  },
  {
    "text": "as a part in a traditional environment the Lim's to controller would be",
    "start": "830939",
    "end": "837179"
  },
  {
    "text": "stateful in the context of kubernetes is also stateless because the context of",
    "start": "837179",
    "end": "842220"
  },
  {
    "text": "kubernetes we can put everything into a at CD key value store or if you wish you",
    "start": "842220",
    "end": "849029"
  },
  {
    "text": "could also put everything into a SQL database outside the scope after",
    "start": "849029",
    "end": "854999"
  },
  {
    "text": "kubernetes Castro and yet a satellite that's like the node agent we use that",
    "start": "854999",
    "end": "860970"
  },
  {
    "text": "to do the actions on the machines itself so creating logic volumes configuring",
    "start": "860970",
    "end": "866939"
  },
  {
    "text": "debrie etc and well the controller is",
    "start": "866939",
    "end": "874290"
  },
  {
    "text": "like the central part of it and it can be relocated in case it fails and I also",
    "start": "874290",
    "end": "885059"
  },
  {
    "text": "need to add here that this whole control structure is outside of the data path so",
    "start": "885059",
    "end": "892110"
  },
  {
    "text": "that means a volume that is established continuous to do I owe even if we",
    "start": "892110",
    "end": "899160"
  },
  {
    "text": "restore the lens to controller or replace it somewhere else etc yeah and",
    "start": "899160",
    "end": "905309"
  },
  {
    "text": "on top of that controller provides our REST API and here comes connectors so",
    "start": "905309",
    "end": "912059"
  },
  {
    "text": "now let's yeah here a little bit too much detail for my time constraint in",
    "start": "912059",
    "end": "921600"
  },
  {
    "text": "the kubernetes context we have well we started with flex volume and extra",
    "start": "921600",
    "end": "927179"
  },
  {
    "text": "provisioner no one wants to use that anymore these days you want to use a CSI",
    "start": "927179",
    "end": "933449"
  },
  {
    "text": "driver an operator and so on let's keep the other technologies in",
    "start": "933449",
    "end": "940329"
  },
  {
    "text": "this context now for for kubernetes we",
    "start": "940329",
    "end": "946720"
  },
  {
    "text": "have packaged everything into containers and we call that the periods data store",
    "start": "946720",
    "end": "953679"
  },
  {
    "text": "project so we have to add a debris module loader package this container we",
    "start": "953679",
    "end": "960670"
  },
  {
    "text": "have lynnster satellite and the lens to control our prepackaged we have",
    "start": "960670",
    "end": "967379"
  },
  {
    "text": "deployment llamó files we have operator and the stock plug-in and yeah here is",
    "start": "967379",
    "end": "977949"
  },
  {
    "text": "the comparison so the various data project everything freely available all",
    "start": "977949",
    "end": "986529"
  },
  {
    "text": "the source code well this was good of all the software is open source but also",
    "start": "986529",
    "end": "992529"
  },
  {
    "text": "here all the packaging is freely available we also have a commercial offering we call that Lin with SDS so",
    "start": "992529",
    "end": "1002579"
  },
  {
    "text": "that's based on red heads ubi containers that allows us to get a red head OpenShift certification and it comes",
    "start": "1002579",
    "end": "1010470"
  },
  {
    "text": "with enterprise class support 24 by 7 but both versions of packaging ship you",
    "start": "1010470",
    "end": "1019259"
  },
  {
    "text": "the same components so that's the tool in store components the operator the mo",
    "start": "1019259",
    "end": "1025949"
  },
  {
    "text": "file help charts is our driver and stork component yeah so this is the summary so",
    "start": "1025949",
    "end": "1037250"
  },
  {
    "start": "1030000",
    "end": "1080000"
  },
  {
    "text": "Lin still covers you from discovering the hardware slicing up the storage",
    "start": "1037250",
    "end": "1045390"
  },
  {
    "text": "devices into the pieces we need using either LVM lbm thin sea affairs and then",
    "start": "1045390",
    "end": "1054919"
  },
  {
    "text": "it brings you to let's say block storage features like replication like",
    "start": "1054919",
    "end": "1060899"
  },
  {
    "text": "encryption at rest like caching like deduplication",
    "start": "1060899",
    "end": "1067220"
  },
  {
    "text": "and also the access and actually making it available to the node where it is",
    "start": "1067680",
    "end": "1074130"
  },
  {
    "text": "needed okay so this was the 20 minute version",
    "start": "1074130",
    "end": "1082620"
  },
  {
    "text": "of it and now I will hand over to 12 and",
    "start": "1082620",
    "end": "1088230"
  },
  {
    "text": "12 will show you all that in action",
    "start": "1088230",
    "end": "1093890"
  },
  {
    "text": "Thank You Phil this is Joe speaking and I'm also from in bit and I'm going to",
    "start": "1094640",
    "end": "1100740"
  },
  {
    "text": "show you today how the Piraeus operator works in terms of actually installing",
    "start": "1100740",
    "end": "1105800"
  },
  {
    "text": "the install into kubernetes and also",
    "start": "1105800",
    "end": "1111090"
  },
  {
    "start": "1110000",
    "end": "1160000"
  },
  {
    "text": "just how to actually go about using that so I hope you can now see my terminal",
    "start": "1111090",
    "end": "1118070"
  },
  {
    "text": "and let's see again so we're working",
    "start": "1118070",
    "end": "1124890"
  },
  {
    "text": "with a pretty standard 1:18 cuba Nettie's cluster today nothing too radical here and it's running on Center",
    "start": "1124890",
    "end": "1132810"
  },
  {
    "text": "7 and otherwise the only preparation I've done is to make sure that the thin",
    "start": "1132810",
    "end": "1139340"
  },
  {
    "text": "Paul module is loaded and make sure that the kernel devourer Etta's are available",
    "start": "1139340",
    "end": "1147210"
  },
  {
    "text": "so that we can compile the apotheke that's part of the Piraeus distribution",
    "start": "1147210",
    "end": "1152820"
  },
  {
    "text": "that do it is compiled so the steps are",
    "start": "1152820",
    "end": "1162270"
  },
  {
    "start": "1160000",
    "end": "1265000"
  },
  {
    "text": "going to show you now basically the steps are in the Piraeus operator readme we will also post",
    "start": "1162270",
    "end": "1167700"
  },
  {
    "text": "exactly this script unknown on my github",
    "start": "1167700",
    "end": "1173130"
  },
  {
    "text": "account so that you can get exactly the steps you did but if you just follow the",
    "start": "1173130",
    "end": "1179070"
  },
  {
    "text": "readme on the Prius operator then you'll basically have the same effect so start",
    "start": "1179070",
    "end": "1186840"
  },
  {
    "text": "by labeling the nodes to indicate that we want our prayers operator to use them and then we continue on by preparing bit",
    "start": "1186840",
    "end": "1195030"
  },
  {
    "text": "of storage for they'll enjoy 2d cluster so that when stock and storage database somewhere",
    "start": "1195030",
    "end": "1201150"
  },
  {
    "text": "and just check that's done there we go",
    "start": "1201150",
    "end": "1208600"
  },
  {
    "text": "it's just created us these three system volumes ready for in stores database itself in store hasn't done anything it",
    "start": "1208600",
    "end": "1215950"
  },
  {
    "text": "at all yet it's just preparation so now",
    "start": "1215950",
    "end": "1221830"
  },
  {
    "text": "this is the actual main step here we use how to install the Piraeus operator and",
    "start": "1221830",
    "end": "1228750"
  },
  {
    "text": "the only extra argument that we give it is to specify which kernel we are using",
    "start": "1228750",
    "end": "1235500"
  },
  {
    "text": "which distribution so that the kernel",
    "start": "1235500",
    "end": "1240640"
  },
  {
    "text": "module loaders can appropriately prepare the kernel module so let's see what this",
    "start": "1240640",
    "end": "1255520"
  },
  {
    "text": "is actually doing so here we see the",
    "start": "1255520",
    "end": "1268180"
  },
  {
    "start": "1265000",
    "end": "1430000"
  },
  {
    "text": "pods that are starting and at the bottom we see the Piraeus operator pod which is",
    "start": "1268180",
    "end": "1274660"
  },
  {
    "text": "the main one which is controlling everything else and this one just runs",
    "start": "1274660",
    "end": "1281350"
  },
  {
    "text": "once on the whole cluster and it's responsible for starting the other parts and managing upgrades and so on now it's",
    "start": "1281350",
    "end": "1290680"
  },
  {
    "text": "consider what happens when the user wants to create a persistent volume when",
    "start": "1290680",
    "end": "1295690"
  },
  {
    "text": "a user creates a persistent volume claim in the kubernetes cluster then it goes",
    "start": "1295690",
    "end": "1300790"
  },
  {
    "text": "down first to this CSI that's the container storage interface controller",
    "start": "1300790",
    "end": "1306610"
  },
  {
    "text": "that's the minstrel CSI in the various distribution and then that CSI",
    "start": "1306610",
    "end": "1313480"
  },
  {
    "text": "controllers just they the glue basically that connects them to the lin store controller which is this one and the lin",
    "start": "1313480",
    "end": "1321790"
  },
  {
    "text": "store controller in turn uses these EDD database to to store its data the one we",
    "start": "1321790",
    "end": "1328720"
  },
  {
    "text": "just set up the storage for and the Lin store has its notes as you just saw in Phil's",
    "start": "1328720",
    "end": "1334769"
  },
  {
    "text": "presentation these are the satellites these note pods and there's one for each",
    "start": "1334769",
    "end": "1343019"
  },
  {
    "text": "of the notes that we labeled so that we can provide storage when they do things",
    "start": "1343019",
    "end": "1348510"
  },
  {
    "text": "like setting up LVM setting up trad making everything ready and then finally",
    "start": "1348510",
    "end": "1356010"
  },
  {
    "text": "there are just these little CSI agent pods on each node as well to bind",
    "start": "1356010",
    "end": "1363149"
  },
  {
    "text": "everything together at the kubernetes level so while that's running we'll just",
    "start": "1363149",
    "end": "1374250"
  },
  {
    "text": "consider the question of how many pods are actually involved in this whole operation basically you've now seen them",
    "start": "1374250",
    "end": "1381870"
  },
  {
    "text": "all in this configuration of this solution there are no pods required for",
    "start": "1381870",
    "end": "1388350"
  },
  {
    "text": "a resource of her persistent volume it's just scales with the number of nodes so",
    "start": "1388350",
    "end": "1395159"
  },
  {
    "text": "if you have some more nodes then you get some more satellites and some more CSI pods but other than that there won't be",
    "start": "1395159",
    "end": "1402330"
  },
  {
    "text": "any extra overhead of extra pods being created and then otherwise is just one",
    "start": "1402330",
    "end": "1408419"
  },
  {
    "text": "of the controller one of the CSI controller standard database however you",
    "start": "1408419",
    "end": "1413610"
  },
  {
    "text": "wish to configure it and one of the operator so we can see now that",
    "start": "1413610",
    "end": "1420659"
  },
  {
    "text": "everything is ready and running which is very good so now we can consider what",
    "start": "1420659",
    "end": "1434549"
  },
  {
    "start": "1430000",
    "end": "1843000"
  },
  {
    "text": "this looks like from Lynn stores perspective so we can can't contact the",
    "start": "1434549",
    "end": "1439919"
  },
  {
    "text": "Lynn store controller which is running and the happens to be a Lynn store client also conveniently installed on",
    "start": "1439919",
    "end": "1445919"
  },
  {
    "text": "they control the pod so contact it there say from in stores perspective we see",
    "start": "1445919",
    "end": "1451590"
  },
  {
    "text": "that there are these four and pods which have been and registered the satellite",
    "start": "1451590",
    "end": "1458010"
  },
  {
    "text": "notes and they're all online and ready",
    "start": "1458010",
    "end": "1464179"
  },
  {
    "text": "so so far we haven't actually provided lynnster with any underlying storage devices to use that in store itself will",
    "start": "1465090",
    "end": "1472529"
  },
  {
    "text": "help us with configuring that so we can ask it what devices are available and we",
    "start": "1472529",
    "end": "1478950"
  },
  {
    "text": "see here that each of the four nodes has got one two gigabyte device available on",
    "start": "1478950",
    "end": "1484049"
  },
  {
    "text": "dev SDA so we can ask in store to set up",
    "start": "1484049",
    "end": "1490580"
  },
  {
    "text": "LVM thin for us so we just had it Jovian thin on that node and we create a",
    "start": "1490580",
    "end": "1497399"
  },
  {
    "text": "storage fall in that in store level because then store object itself and we",
    "start": "1497399",
    "end": "1507840"
  },
  {
    "text": "can do the same for a second node so that we've got enough storage poles to",
    "start": "1507840",
    "end": "1513600"
  },
  {
    "text": "actually do replication and now if we ask install D storage poles are then we",
    "start": "1513600",
    "end": "1522299"
  },
  {
    "text": "get a list here and we see that there are these two Albion thin storage pools",
    "start": "1522299",
    "end": "1527429"
  },
  {
    "text": "which we just created one on each node each with a two gigabytes roughly",
    "start": "1527429",
    "end": "1534679"
  },
  {
    "text": "available so now we've installed in",
    "start": "1534679",
    "end": "1543350"
  },
  {
    "text": "in store ideas actually ready to be used so let me show you have that in two",
    "start": "1543350",
    "end": "1550730"
  },
  {
    "text": "different directory so we're gonna start with a storage class as you'd expect",
    "start": "1550730",
    "end": "1557210"
  },
  {
    "text": "like given it is world and say this is just storage class indicating to the CSI",
    "start": "1557210",
    "end": "1564860"
  },
  {
    "text": "driver how to set up the deity replication and so on so it's telling us",
    "start": "1564860",
    "end": "1572990"
  },
  {
    "text": "is to use this CSI provisioner the one this is the CSI controller itself and",
    "start": "1572990",
    "end": "1578980"
  },
  {
    "text": "then to do two-way replication and use the lVN's in storage pool so let's apply",
    "start": "1578980",
    "end": "1589670"
  },
  {
    "text": "that and then we can use it in a system volume claim so this persistent volume",
    "start": "1589670",
    "end": "1597500"
  },
  {
    "text": "claim refers to exactly that storage class that we just created up here and",
    "start": "1597500",
    "end": "1603380"
  },
  {
    "text": "just tells us that it will have a storage one gigabyte storage volume and",
    "start": "1603380",
    "end": "1609410"
  },
  {
    "text": "that it wants the file system so it can be used from a pub that expects a file",
    "start": "1609410",
    "end": "1616340"
  },
  {
    "text": "system there's also a block mode if you want to use the block devices directly in your pod at this time I'll just show",
    "start": "1616340",
    "end": "1623510"
  },
  {
    "text": "the file system so it can find out too",
    "start": "1623510",
    "end": "1629770"
  },
  {
    "text": "and let's see what's actually happened",
    "start": "1629770",
    "end": "1634990"
  },
  {
    "text": "kubernetes level we can observe the persistent volumes and we see it",
    "start": "1635200",
    "end": "1641120"
  },
  {
    "text": "additional to the database ones that set up at the beginning we now also got this system volume created using the storage",
    "start": "1641120",
    "end": "1650480"
  },
  {
    "text": "class that we specified and that there's the claim that we created in every",
    "start": "1650480",
    "end": "1660190"
  },
  {
    "text": "in store level then we see that there are these two volumes created because",
    "start": "1660190",
    "end": "1665919"
  },
  {
    "text": "it's two-way replicated that's what we asked for in the storage class and it's",
    "start": "1665919",
    "end": "1671259"
  },
  {
    "text": "been created on each of the nodes which other yeah and finally just to prove",
    "start": "1671259",
    "end": "1680080"
  },
  {
    "text": "that it really works I'll give a demonstration of actually using this persistent volume claim so we're gonna",
    "start": "1680080",
    "end": "1686559"
  },
  {
    "text": "set up a my sequel database that's just",
    "start": "1686559",
    "end": "1694659"
  },
  {
    "text": "a very standard my sequel deployment and any special thing about it is that the",
    "start": "1694659",
    "end": "1700029"
  },
  {
    "text": "persistent volume claim is specified here and it's mounted on to the data",
    "start": "1700029",
    "end": "1705210"
  },
  {
    "text": "directory where it's expected let's",
    "start": "1705210",
    "end": "1710649"
  },
  {
    "text": "check how that's doing it's still loading gate and now it's running tree",
    "start": "1710649",
    "end": "1719789"
  },
  {
    "text": "see what that's done at Din star level it's at the Lin star level and we can",
    "start": "1719909",
    "end": "1728409"
  },
  {
    "text": "now see that it's created this diskless volume to connect to the data because if",
    "start": "1728409",
    "end": "1737350"
  },
  {
    "text": "i hadn't either what was on that no it's",
    "start": "1737350",
    "end": "1742779"
  },
  {
    "text": "just check how it's doing setting up yeah yep ready for connection so it's",
    "start": "1742779",
    "end": "1750039"
  },
  {
    "text": "certainly loaded and since we're sharing",
    "start": "1750039",
    "end": "1757029"
  },
  {
    "text": "a storage system we ought to put actually that's an actual data into it and this just loads and dummy data into",
    "start": "1757029",
    "end": "1764649"
  },
  {
    "text": "the I sequel pod",
    "start": "1764649",
    "end": "1767879"
  },
  {
    "text": "and then we just connect into that pod just to see what it's up to just grab",
    "start": "1774970",
    "end": "1789380"
  },
  {
    "text": "some of the data now we see ice equals running using a data that's very general",
    "start": "1789380",
    "end": "1797980"
  },
  {
    "text": "so and there you have it Lin store is now running in kubernetes a",
    "start": "1801190",
    "end": "1806650"
  },
  {
    "text": "very simple installation most the commands have actually been running have been diagnostic monsters to show you",
    "start": "1806650",
    "end": "1813290"
  },
  {
    "text": "what's happening there and recommends to actually install it extremely minimal and very simple so I hope that's useful",
    "start": "1813290",
    "end": "1822050"
  },
  {
    "text": "to you and now kind of hand over to Christophe he will tell you about a different very",
    "start": "1822050",
    "end": "1829190"
  },
  {
    "text": "cool future all right thank you for that",
    "start": "1829190",
    "end": "1835160"
  },
  {
    "text": "demo Joe I'll just share my screen here",
    "start": "1835160",
    "end": "1840760"
  },
  {
    "text": "there we go and I hope you can all see that so thanks for the demonstration Joe",
    "start": "1842860",
    "end": "1851210"
  },
  {
    "text": "um obviously that's a very cool way to get resistant or to get a redundant",
    "start": "1851210",
    "end": "1858500"
  },
  {
    "text": "storage in a kubernetes cluster it was very easy to setup and very convenient",
    "start": "1858500",
    "end": "1864700"
  },
  {
    "text": "that's all fine but that's just one small problem and so actually highlighted it a little",
    "start": "1864700",
    "end": "1870710"
  },
  {
    "text": "bit before let's take a look at the pods which is created here so this one part",
    "start": "1870710",
    "end": "1875840"
  },
  {
    "text": "is my sequel portage which is created is running on node 103 right if we now take",
    "start": "1875840",
    "end": "1882800"
  },
  {
    "text": "a look at the volumes lynnster created we can actually see that our disk full",
    "start": "1882800",
    "end": "1889280"
  },
  {
    "text": "replicas so where we actually storing data are on nodes 101 and 102",
    "start": "1889280",
    "end": "1895660"
  },
  {
    "text": "so across got starter stuff is Phillip",
    "start": "1895660",
    "end": "1901190"
  },
  {
    "text": "speaking yes okay",
    "start": "1901190",
    "end": "1906980"
  },
  {
    "text": "we are not seeing what you were highlighting okay okay now this screen",
    "start": "1906980",
    "end": "1916390"
  },
  {
    "text": "catched up and now we can see all the content was it's lagging behind or is it",
    "start": "1916390",
    "end": "1923900"
  },
  {
    "text": "working now yes now it catch it up yes I get up okay thanks",
    "start": "1923900",
    "end": "1930490"
  },
  {
    "text": "so I guess I'll go a little bit slower then so yeah basically we can see that",
    "start": "1930490",
    "end": "1936080"
  },
  {
    "text": "on the node where the pod was started which was note 103 it inste created is",
    "start": "1936080",
    "end": "1942530"
  },
  {
    "text": "so called disk yes resource which basically means as philip already",
    "start": "1942530",
    "end": "1948650"
  },
  {
    "text": "explained in his presentation means that we're doing all the reads and all the rights over the network so we don't have",
    "start": "1948650",
    "end": "1955040"
  },
  {
    "text": "any local disk data to actually store the data so this is obviously very cool feature of lynnster and is very useful",
    "start": "1955040",
    "end": "1961160"
  },
  {
    "text": "in a lot of scenarios but here it's a little bit of a problem right because if you had obviously most of the time the",
    "start": "1961160",
    "end": "1968630"
  },
  {
    "text": "network is much slower than the disk so this would degrade performance a lot so",
    "start": "1968630",
    "end": "1977799"
  },
  {
    "text": "let's quickly undo the deployment we did before and we will set it up again in a",
    "start": "1977799",
    "end": "1983330"
  },
  {
    "text": "second but only this time with some storage optimization so this is what",
    "start": "1983330",
    "end": "1989120"
  },
  {
    "text": "this store component is for that Philip was talking about in his presentation and the first component we need is the",
    "start": "1989120",
    "end": "1997040"
  },
  {
    "text": "Stork deployment I'll just apply this UML real quick and then show you what",
    "start": "1997040",
    "end": "2002380"
  },
  {
    "text": "it's about because it does take some time to set up right so looking at this yellow file it's a little bit big and",
    "start": "2002380",
    "end": "2009070"
  },
  {
    "text": "intimidating but you can actually get this from Stork so for basic deployment you don't have to worry about it too",
    "start": "2009070",
    "end": "2015520"
  },
  {
    "text": "much the gist of it is that it's a 3-way replicated service and it's running the",
    "start": "2015520",
    "end": "2021850"
  },
  {
    "text": "Stork command which is again the provided per project and we're here",
    "start": "2021850",
    "end": "2028929"
  },
  {
    "text": "telling it to use lynnster as its driver so stock will actually be able to talk",
    "start": "2028929",
    "end": "2033970"
  },
  {
    "text": "to lynnster in order to figure out where to place pots so that they get moved",
    "start": "2033970",
    "end": "2039040"
  },
  {
    "text": "close to their storage so that's what this is all about we're also telling it here where to reach the",
    "start": "2039040",
    "end": "2044590"
  },
  {
    "text": "links the controller which is basically just step Perez operator controller pod and let's",
    "start": "2044590",
    "end": "2053060"
  },
  {
    "text": "see how it's doing right seems like it",
    "start": "2053060",
    "end": "2058940"
  },
  {
    "text": "started we have our three-way replicated service here three stock instances for",
    "start": "2058940",
    "end": "2064340"
  },
  {
    "text": "the infrared cluster right so that's the first piece of the puzzle there's",
    "start": "2064340",
    "end": "2070070"
  },
  {
    "text": "actually another component we have to set up and wait in order to be able to",
    "start": "2070070",
    "end": "2076580"
  },
  {
    "text": "use this sort component with our scheduling and that is the recommended",
    "start": "2076580",
    "end": "2082280"
  },
  {
    "text": "way to do that is to create a new scheduler instance and I'm just again",
    "start": "2082280",
    "end": "2088520"
  },
  {
    "text": "I'm just gonna do it and then show you the demo so here it is again that's",
    "start": "2088520",
    "end": "2096080"
  },
  {
    "text": "there's a lot in there but this is also provided by the stock project so you shouldn't really have to worry about",
    "start": "2096080",
    "end": "2101180"
  },
  {
    "text": "this this is just a standard community scheduler image so you can see that here",
    "start": "2101180",
    "end": "2107030"
  },
  {
    "text": "it's just using the normal normal equivalent kubernetes scheduler for our version and we are giving it a name here",
    "start": "2107030",
    "end": "2113900"
  },
  {
    "text": "and that name is stork and we're also telling it to interface with stork so",
    "start": "2113900",
    "end": "2119870"
  },
  {
    "text": "basically what stork is is it's an extension for the kubernetes scheduler so the kubernetes scheduler will talk to",
    "start": "2119870",
    "end": "2126620"
  },
  {
    "text": "stork stork will talk to lynnster inste will figure out which nodes are best for",
    "start": "2126620",
    "end": "2132260"
  },
  {
    "text": "the pod and give that information back so that kubernetes can schedule the pod in the most efficient way again let's",
    "start": "2132260",
    "end": "2139700"
  },
  {
    "text": "see how that's doing perfect it just finished setting up here are three",
    "start": "2139700",
    "end": "2146540"
  },
  {
    "text": "instances three stork scheduler instances again three replicated yeah",
    "start": "2146540",
    "end": "2154220"
  },
  {
    "text": "that's part two now we are actually almost done the only thing that's left",
    "start": "2154220",
    "end": "2160040"
  },
  {
    "text": "is actually telling our port to use this scheduler because if we take a look at",
    "start": "2160040",
    "end": "2166130"
  },
  {
    "text": "our ports again we now actually have two schedulers in our cluster one of those is take you one at this scheduler",
    "start": "2166130",
    "end": "2172330"
  },
  {
    "text": "standard scheduler and the other one is the stork scheduler so we have two parallel schedulers and",
    "start": "2172330",
    "end": "2180170"
  },
  {
    "text": "we can still use the default scheduler if we would like to but between in this case obviously we want to use the new",
    "start": "2180170",
    "end": "2188780"
  },
  {
    "text": "stork scheduler so in order to do that we actually just have to edit our my",
    "start": "2188780",
    "end": "2196280"
  },
  {
    "text": "sequel demo file a little bit here and it's actually pretty simple it's just one line up in here in the container",
    "start": "2196280",
    "end": "2204140"
  },
  {
    "text": "spec we just have to put scheduler name and the name that we gave it which is",
    "start": "2204140",
    "end": "2209540"
  },
  {
    "text": "stork save that so now we have our new",
    "start": "2209540",
    "end": "2215620"
  },
  {
    "text": "llamo file and just so we we know what to expect let's look at the list of volumes again",
    "start": "2215620",
    "end": "2222940"
  },
  {
    "text": "again we can see here that on node 101 and 102 we have a disk for the data to",
    "start": "2222940",
    "end": "2229370"
  },
  {
    "text": "be stored on so that's we would expect stork to schedule it on one of those two",
    "start": "2229370",
    "end": "2235130"
  },
  {
    "text": "ports right so let's try that again",
    "start": "2235130",
    "end": "2240410"
  },
  {
    "text": "and what should it's doing and sure enough it scheduled it to the",
    "start": "2240410",
    "end": "2249680"
  },
  {
    "text": "node 102 which is where we have a disgrace replica a disk full replica of",
    "start": "2249680",
    "end": "2255110"
  },
  {
    "text": "the data and we can again check that let's look at the volumes again sure",
    "start": "2255110",
    "end": "2260870"
  },
  {
    "text": "enough lynnster didn't have to create a discus replica because we have all data",
    "start": "2260870",
    "end": "2265940"
  },
  {
    "text": "on disk right now so that means that our my sequel exercise should be nice and",
    "start": "2265940",
    "end": "2271520"
  },
  {
    "text": "fast because they are just going to a local disk alright so that just about",
    "start": "2271520",
    "end": "2279680"
  },
  {
    "text": "sums up the demos I messed roll already mentioned you can find a script for all",
    "start": "2279680",
    "end": "2285350"
  },
  {
    "text": "of this on limpets github page and the steps that I just did similar to jaws",
    "start": "2285350",
    "end": "2292810"
  },
  {
    "text": "are actually documented in the lean stores use the guide so you can read about all of this if this was a little",
    "start": "2292810",
    "end": "2298700"
  },
  {
    "text": "bit too fast it's all documented and it's pretty easy to setup right I thank",
    "start": "2298700",
    "end": "2305120"
  },
  {
    "text": "you very much and I think we have some time for questions",
    "start": "2305120",
    "end": "2309160"
  },
  {
    "text": "yeah yeah he's Phillip I think Thank You Christopher",
    "start": "2310390",
    "end": "2315860"
  },
  {
    "start": "2315000",
    "end": "2383000"
  },
  {
    "text": "well while I was watching the demo I realized that Joelle showed us that we",
    "start": "2315860",
    "end": "2325310"
  },
  {
    "text": "used PVCs with a file system and I want to point out that we tested and verified",
    "start": "2325310",
    "end": "2333140"
  },
  {
    "text": "that when you use the PVCs in block mode and you can combine that with cube world",
    "start": "2333140",
    "end": "2340810"
  },
  {
    "text": "and it also supports life migration with",
    "start": "2340810",
    "end": "2346640"
  },
  {
    "text": "Qbert and that's really cool if you",
    "start": "2346640",
    "end": "2352010"
  },
  {
    "text": "manage your virtual machines within your kubernetes cluster and also can do life integrations of such machines having",
    "start": "2352010",
    "end": "2359870"
  },
  {
    "text": "assistant volumes okay I think that's it",
    "start": "2359870",
    "end": "2367280"
  },
  {
    "text": "from our part and now let's hope for for",
    "start": "2367280",
    "end": "2374810"
  },
  {
    "text": "a few questions",
    "start": "2374810",
    "end": "2377230"
  },
  {
    "text": "great thanks Philip sanctum for a great presentation",
    "start": "2382600",
    "end": "2389020"
  },
  {
    "start": "2383000",
    "end": "2448000"
  },
  {
    "text": "all right and that's all the question we have time for today",
    "start": "2389920",
    "end": "2397010"
  },
  {
    "text": "I don't really was awesome thanks Philip",
    "start": "2397010",
    "end": "2402940"
  },
  {
    "text": "it's a great presentation we have more ten minutes for no 30 minutes for",
    "start": "2402940",
    "end": "2411380"
  },
  {
    "text": "questions we don't have questions here but you use them share your link the",
    "start": "2411380",
    "end": "2422180"
  },
  {
    "text": "link for the parrot could you kiddos show the page for the perfect and",
    "start": "2422180",
    "end": "2428720"
  },
  {
    "text": "you know for the participants see the project and if you have would have a",
    "start": "2428720",
    "end": "2437740"
  },
  {
    "text": "page for the for the project",
    "start": "2437740",
    "end": "2442060"
  },
  {
    "start": "2448000",
    "end": "2629000"
  },
  {
    "text": "could you share Philip the webpage for the benefit for the perfect space yes",
    "start": "2448990",
    "end": "2457820"
  },
  {
    "text": "yes from you sure over I will do it a second just like me",
    "start": "2457820",
    "end": "2464750"
  },
  {
    "text": "okay I got that fast this is the main",
    "start": "2464750",
    "end": "2470450"
  },
  {
    "text": "page for the Piraeus project itself from",
    "start": "2470450",
    "end": "2477670"
  },
  {
    "text": "the highest level and then this is the Perez operator just don't get up Perez",
    "start": "2477670",
    "end": "2484850"
  },
  {
    "text": "datastore project and this is the readme",
    "start": "2484850",
    "end": "2490190"
  },
  {
    "text": "which is basically explaining the steps that I will showing you and finally here",
    "start": "2490190",
    "end": "2497900"
  },
  {
    "text": "is the page that we are referencing with the files from today's demo in case you",
    "start": "2497900",
    "end": "2504020"
  },
  {
    "text": "want to try it out yourself great thank you and there is a community",
    "start": "2504020",
    "end": "2514100"
  },
  {
    "text": "can contribute it to product so we're an",
    "start": "2514100",
    "end": "2521240"
  },
  {
    "text": "open source project and get up and we welcome pull requests and we do most of",
    "start": "2521240",
    "end": "2527180"
  },
  {
    "text": "our development in the open using pull requests and get up so anyone who's interested almost contribute to code can",
    "start": "2527180",
    "end": "2535190"
  },
  {
    "text": "do so that way you can also contribute just by trying it out and seeing if it",
    "start": "2535190",
    "end": "2542390"
  },
  {
    "text": "works in your environment and cons for sending your feedback via slack channel",
    "start": "2542390",
    "end": "2548090"
  },
  {
    "text": "community slack channel or by a github issues we always like to have people",
    "start": "2548090",
    "end": "2554900"
  },
  {
    "text": "working on our using our stuff and providing that kind of feedback oh great",
    "start": "2554900",
    "end": "2563120"
  },
  {
    "text": "there is a select channel for for the perfect right yes yes oh wait great so",
    "start": "2563120",
    "end": "2575099"
  },
  {
    "text": "let's check the QA don't have more questions okay great text Phillip is",
    "start": "2575099",
    "end": "2588029"
  },
  {
    "text": "Pentium 4 negative presentation and talking for us about your brain is amazing alright thanks for joining us",
    "start": "2588029",
    "end": "2600450"
  },
  {
    "text": "today the webinar the web recording in the slides will be my lady today and we",
    "start": "2600450",
    "end": "2609749"
  },
  {
    "text": "are looking forward to seeing you at the future CSF webinar have a great day takes take",
    "start": "2609749",
    "end": "2618359"
  },
  {
    "text": "care have and thank you so much see you",
    "start": "2618359",
    "end": "2624588"
  }
]
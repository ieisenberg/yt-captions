[
  {
    "text": "all right hey folks my name is Andres ignor I work on linker D we're gonna go",
    "start": "30",
    "end": "5279"
  },
  {
    "text": "through a little bit of background on linker D then we're gonna turn it over to Fredrik to go through Santos and then hopefully",
    "start": "5279",
    "end": "12480"
  },
  {
    "text": "we're gonna do a demo that works that integrates the two and kind of shows kind of the benefits of of these two",
    "start": "12480",
    "end": "18119"
  },
  {
    "text": "projects working together so just a little bit of background linker D is a service mesh the service mesh really",
    "start": "18119",
    "end": "25529"
  },
  {
    "text": "does three things for you it gives you observability security and reliability across all of your applications and you",
    "start": "25529",
    "end": "32250"
  },
  {
    "text": "shouldn't have to change in your application code it's usually composed of two major components that control",
    "start": "32250",
    "end": "37739"
  },
  {
    "text": "plane which is kind of the administrative side of it where you do things like observability like you roll",
    "start": "37739",
    "end": "43469"
  },
  {
    "text": "up all your metrics you can set policy on managing traffic and it's like your user interface into it so you have a CLI",
    "start": "43469",
    "end": "49500"
  },
  {
    "text": "or or like a web dashboard or something to interact with it and then on the other side you have the data plane the",
    "start": "49500",
    "end": "55530"
  },
  {
    "text": "way we can enable all of this stuff is we put a little sidecar proxy next to all of your applications we inject a",
    "start": "55530",
    "end": "61949"
  },
  {
    "text": "little proxy into each pod so the origins of linker D actually go back",
    "start": "61949",
    "end": "68340"
  },
  {
    "text": "almost ten years the company I work for Blaine is composed mostly of former Twitter engineers the libraries that",
    "start": "68340",
    "end": "75780"
  },
  {
    "text": "linker D one was built around were were built at Twitter when we were",
    "start": "75780",
    "end": "81630"
  },
  {
    "text": "decomposing the largest rails app on the planet into a bunch of Micra services and there was this need for this uniform",
    "start": "81630",
    "end": "89000"
  },
  {
    "text": "observability reliability and security and that that was kind of the motivation for that's why I think our DUI name",
    "start": "89000",
    "end": "95460"
  },
  {
    "text": "ended up being written in Scala which worked great for a while but in the world of like everybody's running a",
    "start": "95460",
    "end": "100590"
  },
  {
    "text": "little go process and you know you you're taking up five or ten megabytes of memory trying to run a JVM as a",
    "start": "100590",
    "end": "107040"
  },
  {
    "text": "sidecar that may need a hundred megabytes or a gigabyte of memory it didn't really fit so about a year year",
    "start": "107040",
    "end": "114000"
  },
  {
    "text": "and a half ago we said about doing it complete from the ground up rewrite we kind of looked at like what we had",
    "start": "114000",
    "end": "119040"
  },
  {
    "text": "learned over the last several years with linker do you want and and made some like pretty specific design decisions",
    "start": "119040",
    "end": "124560"
  },
  {
    "text": "with linker d2 um the first one was it would support kubernetes only linker d1 would would run anywhere and we will",
    "start": "124560",
    "end": "131099"
  },
  {
    "text": "continue supporting it for a long but it made configuration pretty complex",
    "start": "131099",
    "end": "136220"
  },
  {
    "text": "it could use zookeeper it could use Maysles whatever by just targeting kubernetes it's super easy to set up and",
    "start": "136220",
    "end": "142130"
  },
  {
    "text": "you'll see that in a demo in a little bit the other piece was that prometheus",
    "start": "142130",
    "end": "147620"
  },
  {
    "text": "was gaining a lot of traction and we had most of our users were wanting integrations with it we had some",
    "start": "147620",
    "end": "153530"
  },
  {
    "text": "reference designs on how those two things work together with link 31 but in linker t2 we decided to just make",
    "start": "153530",
    "end": "159709"
  },
  {
    "text": "Prometheus like a first-class component of linker t2 so when you install linker D you get Prometheus with it the other",
    "start": "159709",
    "end": "168739"
  },
  {
    "text": "part was looking at kind of available languages go seem like a very natural fit for the control plane we're",
    "start": "168739",
    "end": "174050"
  },
  {
    "text": "integrating with kubernetes so we end up using a ton of libraries that are in the kubernetes codebase and related projects",
    "start": "174050",
    "end": "180080"
  },
  {
    "text": "it's been it's been really helpful to like use that code instead of writing our own for the proxy we knew we needed",
    "start": "180080",
    "end": "185570"
  },
  {
    "text": "performance and so we we kind of took a look at what was out there and rust seemed to fit the bill we've been lucky",
    "start": "185570",
    "end": "191360"
  },
  {
    "text": "enough to work with a number of the rust community like library developers the folks that are responsible for things",
    "start": "191360",
    "end": "197180"
  },
  {
    "text": "like protocol and i/o and they've they've helped out a lot in helping",
    "start": "197180",
    "end": "203209"
  },
  {
    "text": "build up this proxy so just kind of a really quick picture of the architecture if you remember that two components of a",
    "start": "203209",
    "end": "210440"
  },
  {
    "text": "service mesh you've got a control plane in a data plane I'm not expecting you all to understand every box here but",
    "start": "210440",
    "end": "215510"
  },
  {
    "text": "these slides are attached to the schedule so you can dig into it later and come ask many questions but really I",
    "start": "215510",
    "end": "221450"
  },
  {
    "text": "just wanted to call out like there is an observer the layer in here and that's where we're really focused on for this",
    "start": "221450",
    "end": "226610"
  },
  {
    "text": "talk and we're using Prometheus like we found it's worked so much better than trying to invent our own and in the",
    "start": "226610",
    "end": "233120"
  },
  {
    "text": "spirit of reusing things like we just plug a graph on or write on top of it and so if you're using linker D all of",
    "start": "233120",
    "end": "240079"
  },
  {
    "text": "your observability tooling should work like with like it should you feel very natural because you'll just plug in to",
    "start": "240079",
    "end": "245840"
  },
  {
    "text": "the existing components the way you interact with the service mesh again is through a CLI in a dashboard and those",
    "start": "245840",
    "end": "252440"
  },
  {
    "text": "are things that we provide to you so just really quick I wanted to focus on like kind of the core piece of",
    "start": "252440",
    "end": "258560"
  },
  {
    "text": "technology that ties all of this together which is when we inject that little proxy into each of your pods we're",
    "start": "258560",
    "end": "265599"
  },
  {
    "text": "exporting some very specific metrics that give us kind of three golden things to look at request rate success rate and",
    "start": "265599",
    "end": "272680"
  },
  {
    "text": "latency and the demo we're gonna do in a minute is going to focus mostly on latency but by counting those things it",
    "start": "272680",
    "end": "279159"
  },
  {
    "text": "allows us to give you very useful metrics on how your micro services are",
    "start": "279159",
    "end": "285219"
  },
  {
    "text": "behaving so with that writer okay so",
    "start": "285219",
    "end": "291749"
  },
  {
    "text": "let's do a little poll how many people here are already using Prometheus that's",
    "start": "291749",
    "end": "298240"
  },
  {
    "text": "wow that's almost everybody so I'm gonna run through this one a little bit more quickly so but there were a couple hands",
    "start": "298240",
    "end": "305259"
  },
  {
    "text": "that didn't go up so let's make sure everybody's on the same page so Prometheus is a pull based monitoring",
    "start": "305259",
    "end": "310960"
  },
  {
    "text": "system what that means is that Prometheus in a regular interval will go to our applications - literally an HTTP",
    "start": "310960",
    "end": "318909"
  },
  {
    "text": "endpoint and grab all the metrics and adjust it into its time series database so basically what the example that we",
    "start": "318909",
    "end": "326919"
  },
  {
    "text": "have up here is we have our application or user finishing application that is",
    "start": "326919",
    "end": "332500"
  },
  {
    "text": "exposing Prometheus style metrics and Prometheus grabs those at one point in time and inserts it into the time series",
    "start": "332500",
    "end": "339279"
  },
  {
    "text": "database then we actually get user facing our users actually are using our",
    "start": "339279",
    "end": "345639"
  },
  {
    "text": "applications we are actually making money or something and these requests",
    "start": "345639",
    "end": "351069"
  },
  {
    "text": "increase and over time the interval has passed so Prometheus will come again and",
    "start": "351069",
    "end": "356139"
  },
  {
    "text": "do a second request and insert that into its time series database and this will",
    "start": "356139",
    "end": "362020"
  },
  {
    "text": "just happen all the time and forever and as I seen a lot of you already use",
    "start": "362020",
    "end": "371159"
  },
  {
    "text": "Prometheus maybe even on criminales how many use previous on kubernetes already",
    "start": "371159",
    "end": "377310"
  },
  {
    "text": "great that's also a lot of hands not quite as much but also a lot of hands so",
    "start": "377310",
    "end": "382870"
  },
  {
    "text": "Prometheus the Prometheus ecosystem has main primarily revolved around in within",
    "start": "382870",
    "end": "389710"
  },
  {
    "text": "a single kubernetes cluster and everybody's here to see multi-class or manner",
    "start": "389710",
    "end": "395060"
  },
  {
    "text": "obviously but that part I feel like we've figured out pretty well",
    "start": "395060",
    "end": "401330"
  },
  {
    "text": "there are setups that give you out-of-the-box cluster monitoring I happen to work on one of those they're",
    "start": "401330",
    "end": "408650"
  },
  {
    "text": "Prometheus has a lot of guides out there there are lots of blog posts how to do app monitoring with all these things so",
    "start": "408650",
    "end": "415010"
  },
  {
    "text": "I feel like we've covered this pretty well but once people have are",
    "start": "415010",
    "end": "421730"
  },
  {
    "text": "comfortable with that we have pretty much the same repeating questions so what about long-term storage how can I",
    "start": "421730",
    "end": "428630"
  },
  {
    "text": "get a global view of all my clusters out there maybe even if I want to do some",
    "start": "428630",
    "end": "435680"
  },
  {
    "text": "analysis over a year worth of data my queries are getting really slow so how",
    "start": "435680",
    "end": "441470"
  },
  {
    "text": "can we solve this and just about a year and a half ago maybe a year ago a team",
    "start": "441470",
    "end": "450500"
  },
  {
    "text": "actually two individuals at improbable came up with a really really awesome",
    "start": "450500",
    "end": "457419"
  },
  {
    "text": "solution to this and they named it honest so tano's does have all of these",
    "start": "457419",
    "end": "462979"
  },
  {
    "text": "features and you can kind of think of it as a distributed prometheus basically",
    "start": "462979",
    "end": "468350"
  },
  {
    "text": "Thanos goes and takes all of these pieces that are in the that's called monolithic application that it makes up",
    "start": "468350",
    "end": "474440"
  },
  {
    "text": "Prometheus and it pulls out the query layer it pulls out the storage kind of",
    "start": "474440",
    "end": "479990"
  },
  {
    "text": "and makes it a distributed prometheus instead of the amount of the thick process now that doesn't mean that you",
    "start": "479990",
    "end": "485419"
  },
  {
    "text": "won't need your Prometheus anymore we want to monitor our distributed",
    "start": "485419",
    "end": "490430"
  },
  {
    "text": "monitoring system with a non distributed monitoring system but nevertheless this",
    "start": "490430",
    "end": "495800"
  },
  {
    "text": "is still a really really awesome project so I happen to be now one of the",
    "start": "495800",
    "end": "501080"
  },
  {
    "text": "maintainer of tano's as well even though I do not think I deserve that but the group was kind enough to grant",
    "start": "501080",
    "end": "506600"
  },
  {
    "text": "me maintain ership so let's dive a little bit into more how Thanos works so",
    "start": "506600",
    "end": "513500"
  },
  {
    "text": "as you see we on the slide we actually even when we are using tunnels we are",
    "start": "513500",
    "end": "518810"
  },
  {
    "text": "still using vanilla upstream prometheus but how does that tie into the whole",
    "start": "518810",
    "end": "524480"
  },
  {
    "text": "story so the way Thomas works is that it puts gives us a sidecar that runs next to our",
    "start": "524480",
    "end": "529989"
  },
  {
    "text": "prometheus Prometheus server and that way basically puts a common interface in",
    "start": "529989",
    "end": "537129"
  },
  {
    "text": "front of Prometheus that is this tunnel store API and I'll keep coming back to",
    "start": "537129",
    "end": "543970"
  },
  {
    "text": "this to the story API theme because I think this is a really cool aspect of tano's basically all the components",
    "start": "543970",
    "end": "551499"
  },
  {
    "text": "within the tunnels project implement this API and it's kind of the data exchange API for four metrics you could",
    "start": "551499",
    "end": "557709"
  },
  {
    "text": "say for a time series data so what the sidecar then does is Prometheus builds",
    "start": "557709",
    "end": "563769"
  },
  {
    "text": "these immutable blocks of data Prometheus always depends to the right",
    "start": "563769",
    "end": "569110"
  },
  {
    "text": "headlock we're very frequently that's when it collects data and writes to disk and every two hours it takes all of that",
    "start": "569110",
    "end": "575649"
  },
  {
    "text": "and puts it into an immutable block on disk so it's never gonna be changed again it's not entirely true but let's",
    "start": "575649",
    "end": "582399"
  },
  {
    "text": "treat it as that for now and Thomas goes ahead and sees that oh there's a new meter immutable block I'm gonna upload",
    "start": "582399",
    "end": "588879"
  },
  {
    "text": "that to object storage and then there's another component called Thanos store I know",
    "start": "588879",
    "end": "593920"
  },
  {
    "text": "store API store not great naming unfortunately it's hard to change that naming now but the story API is",
    "start": "593920",
    "end": "600490"
  },
  {
    "text": "essentially puts the story sorry I didn't mistake myself the store",
    "start": "600490",
    "end": "606160"
  },
  {
    "text": "component exposes the store API as a wrapper",
    "start": "606160",
    "end": "611259"
  },
  {
    "text": "around an object storage like Amazon s3 for example and that way that's a nose",
    "start": "611259",
    "end": "617319"
  },
  {
    "text": "query or can read all the live data basically from the Prometheus that is",
    "start": "617319",
    "end": "623949"
  },
  {
    "text": "live appending data and the historic data from object storage and that way we can essentially this is how the",
    "start": "623949",
    "end": "630129"
  },
  {
    "text": "long-term storage part was solved because we can treat object storage essentially as an endless bucket of",
    "start": "630129",
    "end": "637990"
  },
  {
    "text": "storage now Thanos actually and this is how I got involved into tano's harness",
    "start": "637990",
    "end": "643959"
  },
  {
    "text": "is about deployment flexibility and while the sidecar approach is a really",
    "start": "643959",
    "end": "650529"
  },
  {
    "text": "desirable one and it works extremely well there are lots of deployment scenarios where you may not be able to",
    "start": "650529",
    "end": "657339"
  },
  {
    "text": "have direct access to your edge Prometheus where your Santos courier cannot directly do these",
    "start": "657339",
    "end": "664730"
  },
  {
    "text": "G RPC calls to the Prometheus to the live Prometheus instance so actually I",
    "start": "664730",
    "end": "670880"
  },
  {
    "text": "had just just had a conversation about Prometheus servers that may be running on cars for example or just things that",
    "start": "670880",
    "end": "679220"
  },
  {
    "text": "may have interrupted internet connections so in those kind of scenarios it would be really nice if we",
    "start": "679220",
    "end": "684350"
  },
  {
    "text": "can just have the Prometheus and stream all of all of its data over time and if",
    "start": "684350",
    "end": "689780"
  },
  {
    "text": "there's a downtime of our back-end then it will just stop and continue once it has an internet connection again and for",
    "start": "689780",
    "end": "698210"
  },
  {
    "text": "our use case we actually are building this I work at Red Hat I work it sort of",
    "start": "698210",
    "end": "703340"
  },
  {
    "text": "within the OpenShift organization we're building this to monitor rollouts of clusters for",
    "start": "703340",
    "end": "711980"
  },
  {
    "text": "automatic upgrades and for that we don't necessarily have access to customer",
    "start": "711980",
    "end": "717710"
  },
  {
    "text": "clusters we can make random HTTP calls into customer clusters obviously so",
    "start": "717710",
    "end": "724780"
  },
  {
    "text": "basically what we're making use of here is a feature that is already available in Prometheus called remote write and",
    "start": "724780",
    "end": "731630"
  },
  {
    "text": "what this essentially does is it replicates the Prometheus database that is local to the Prometheus server to a",
    "start": "731630",
    "end": "737630"
  },
  {
    "text": "remote location and the donners receive component receives this and essentially",
    "start": "737630",
    "end": "743330"
  },
  {
    "text": "replicates the database locally and then does the same same thing as the Tanis",
    "start": "743330",
    "end": "750170"
  },
  {
    "text": "citecar does once the block has been produced but the town has received component would run on our premise in",
    "start": "750170",
    "end": "755780"
  },
  {
    "text": "that sense so I want to reiterate on",
    "start": "755780",
    "end": "761210"
  },
  {
    "text": "this Thanos is really a toolkit of components and you can use all of these components to build basically your own",
    "start": "761210",
    "end": "768710"
  },
  {
    "text": "very own monitoring system so we're all here for multi-class or monitoring so is",
    "start": "768710",
    "end": "776240"
  },
  {
    "text": "tano's equal does planas equal multi class or monitoring no but you can make",
    "start": "776240",
    "end": "783890"
  },
  {
    "text": "it your multi cluster monitoring system and again the store API is the I think",
    "start": "783890",
    "end": "789620"
  },
  {
    "text": "this is the coolest thing about Panos because the store API allows you to build all these wild combinations of of",
    "start": "789620",
    "end": "799120"
  },
  {
    "text": "components that ultimately make up the system that you exactly need so let's",
    "start": "799120",
    "end": "805160"
  },
  {
    "text": "look at this and look closely the slide that I had before and I removed",
    "start": "805160",
    "end": "811280"
  },
  {
    "text": "everything that does not have a store API and did you notice which component",
    "start": "811280",
    "end": "816950"
  },
  {
    "text": "is still up there that you may not have thought it's a courier so the courier itself also implements",
    "start": "816950",
    "end": "823190"
  },
  {
    "text": "the store API so what we can do now is we can stack Thanos Thanos clusters on",
    "start": "823190",
    "end": "831830"
  },
  {
    "text": "top of each other so we could even run a Thanos cluster in each of our kubernetes",
    "start": "831830",
    "end": "836840"
  },
  {
    "text": "clusters and there still have long-term storage horizontal scaling of the courier and all of those great things",
    "start": "836840",
    "end": "842990"
  },
  {
    "text": "that we want to have when there maybe maybe we have some network partitions so",
    "start": "842990",
    "end": "850220"
  },
  {
    "text": "we can't call into these clusters at a certain point in time but we can still fall fall down into the cluster and",
    "start": "850220",
    "end": "857360"
  },
  {
    "text": "troubleshoot our problems locally there so I think this is really what I want",
    "start": "857360",
    "end": "862820"
  },
  {
    "text": "people to go away with here Sano's is about flexibility and you should",
    "start": "862820",
    "end": "868780"
  },
  {
    "text": "architect your setup to your need and the store API is really the thing that allows us to do this with Thanos so",
    "start": "868780",
    "end": "876970"
  },
  {
    "text": "architect to your need so with that so you just gonna show us some action we'll",
    "start": "876970",
    "end": "884570"
  },
  {
    "text": "see all right thanks a lot all right so let's dig into demo everything we're gonna show you is a is",
    "start": "884570",
    "end": "890660"
  },
  {
    "text": "on a github repo so if you want to check it out go to bitly Thanos linker D follow it now or follow it later or",
    "start": "890660",
    "end": "896960"
  },
  {
    "text": "whatever I want to call out like I didn't write a single line of code to do this I definitely wrote some mo but kind",
    "start": "896960",
    "end": "903530"
  },
  {
    "text": "of the the goal of this demo is to show what you can do with kind of off-the-shelf parts that exist today so",
    "start": "903530",
    "end": "909260"
  },
  {
    "text": "to just kind of set the stage on what we're gonna be deploying we've just got a very dumb client server sample",
    "start": "909260",
    "end": "916070"
  },
  {
    "text": "application and the client puts a bunch of load by default like 100 requests per second on to a",
    "start": "916070",
    "end": "922410"
  },
  {
    "text": "of our application we're going to inject linker D into that that's going to enable us to get our observability",
    "start": "922410",
    "end": "929000"
  },
  {
    "text": "across like these applications that we're deploying then we're going to take that set up just a simple client server",
    "start": "929000",
    "end": "935069"
  },
  {
    "text": "in linker D and we're going to deploy it across four different cloud providers Amazon digitalocean",
    "start": "935069",
    "end": "940279"
  },
  {
    "text": "Microsoft and Google and then we're",
    "start": "940279",
    "end": "945420"
  },
  {
    "text": "gonna roll all of that up into a fan o Square and we're gonna be able to view these metrics in in an aggregated way",
    "start": "945420",
    "end": "952470"
  },
  {
    "text": "and then we'll use graph honor to kind of visualize all that data to dig into",
    "start": "952470",
    "end": "958350"
  },
  {
    "text": "specifically how the auto scaling is going to work I'll I'll kind of walk through this really quick so again we've",
    "start": "958350",
    "end": "963810"
  },
  {
    "text": "got our client server we've got our lucre D injected because linker D is working with Prometheus we're getting",
    "start": "963810",
    "end": "969240"
  },
  {
    "text": "things like request and latency information then the the custom part of",
    "start": "969240",
    "end": "975149"
  },
  {
    "text": "this demo is that we're going to attach a fan owes to the linker D that comes with the attached at Thanos to the",
    "start": "975149",
    "end": "981420"
  },
  {
    "text": "prometheus that comes with linker D when you install a like a vanilla linker D",
    "start": "981420",
    "end": "987240"
  },
  {
    "text": "obviously you don't get danos today but the the demo and the examples that that",
    "start": "987240",
    "end": "992370"
  },
  {
    "text": "I've got on github kind of demonstrate how you could do this and I found this",
    "start": "992370",
    "end": "999089"
  },
  {
    "text": "other nice piece of software called the case Prometheus adapter what that does is it takes Prometheus data and in this",
    "start": "999089",
    "end": "1006829"
  },
  {
    "text": "case it's the Thanos but because they know some Prometheus look exactly the same from an API perspective I just plug",
    "start": "1006829",
    "end": "1012500"
  },
  {
    "text": "it into the global Thanos query and that allows us that allows kubernetes to see",
    "start": "1012500",
    "end": "1018410"
  },
  {
    "text": "this Thanos data as as kubernetes metrics and from there when a latency",
    "start": "1018410",
    "end": "1024288"
  },
  {
    "text": "value goes above what we want it to in this case 10 milliseconds it's going to scale up the server replicas on all of",
    "start": "1024289",
    "end": "1030860"
  },
  {
    "text": "the clusters so kind of the the gist of this is given running the same system",
    "start": "1030860",
    "end": "1037938"
  },
  {
    "text": "across four different cloud providers if there's a problem or an observability event in one of them we can react and",
    "start": "1037939",
    "end": "1044630"
  },
  {
    "text": "adjust in a bunch of other data centers and to just kind of call out the the",
    "start": "1044630",
    "end": "1050870"
  },
  {
    "text": "line of I've drawn around all of that's what we're deploying for copies of the global fan no square runs in like",
    "start": "1050870",
    "end": "1058520"
  },
  {
    "text": "in one of the cloud providers but we don't really care which one it's just just know that there's one of those and there's four of everything else",
    "start": "1058520",
    "end": "1065710"
  },
  {
    "text": "all right let's see if this works so the",
    "start": "1065710",
    "end": "1077360"
  },
  {
    "text": "first thing I'm gonna do is just show you some empty dashboards I've already deployed the Thanos square cuz I didn't",
    "start": "1077360",
    "end": "1084470"
  },
  {
    "text": "want to bother waiting for all of us to like stare at this thing and deploy but",
    "start": "1084470",
    "end": "1090679"
  },
  {
    "text": "the important thing to note here is that we've got our Thanos query it's configured to talk to basically eight",
    "start": "1090679",
    "end": "1096140"
  },
  {
    "text": "backends there's two backends per per cloud provider it's those those Thanos",
    "start": "1096140",
    "end": "1102380"
  },
  {
    "text": "sidecar and Thanos stores that that Fredrik was talking about the sidecar gives you like real-time data and the",
    "start": "1102380",
    "end": "1108230"
  },
  {
    "text": "store gives you like long-term data because Thanos can leverage object storage on each of these providers",
    "start": "1108230",
    "end": "1114169"
  },
  {
    "text": "whether it's like digital ocean or Google or whatever it can plug into the appropriate object storage for that",
    "start": "1114169",
    "end": "1121899"
  },
  {
    "text": "okay so each pane is a cloud provider and we can confirm that just by all I've",
    "start": "1129560",
    "end": "1135140"
  },
  {
    "text": "done is set a special environment variable on each one so I've got a KS digitalocean ek Amazon and Google here",
    "start": "1135140",
    "end": "1143900"
  },
  {
    "text": "so I'm going to install linker D and then I'm going to install the sample app",
    "start": "1143900",
    "end": "1149350"
  },
  {
    "text": "so let me unpack the the command that I just ran there so let's see when you",
    "start": "1150880",
    "end": "1159050"
  },
  {
    "text": "install linker D like what what I want you to take away from this is how easy it is to do that we have a CLI tool",
    "start": "1159050",
    "end": "1165170"
  },
  {
    "text": "called linker D it's got if you use coop cuddle it feels like very very familiar we use a lot of the same code as coop",
    "start": "1165170",
    "end": "1171290"
  },
  {
    "text": "cuddle if you want to install it all you do is you type linker D install and that just dumps a bunch of yamo we tried to",
    "start": "1171290",
    "end": "1177920"
  },
  {
    "text": "be really explicit about what we were doing so if you're comfortable with that you would just pipe it into coop cuddle apply and I'm not going to do that now",
    "start": "1177920",
    "end": "1185510"
  },
  {
    "text": "because I don't want to install linker D on my laptop but that's like the entire installation procedure you may have",
    "start": "1185510",
    "end": "1191060"
  },
  {
    "text": "noticed that the command I just ran referenced an environment variable which was a file it's because I did had to",
    "start": "1191060",
    "end": "1197060"
  },
  {
    "text": "make a slight modification to the vanilla linker D to enable it for thanos but again all of that's documented in",
    "start": "1197060",
    "end": "1204020"
  },
  {
    "text": "the repo so I'm just gonna run a command really quick a version check just to",
    "start": "1204020",
    "end": "1210290"
  },
  {
    "text": "make sure that all the clusters came up it looks pretty good I'm gonna run one more command which is kind of a",
    "start": "1210290",
    "end": "1215330"
  },
  {
    "text": "Diagnostics check just to make sure things are looking good let me unpack this command a little bit so we have I'm",
    "start": "1215330",
    "end": "1225770"
  },
  {
    "text": "just gonna run this command against one of the clusters arbitrarily any time you install linker D you can run this check",
    "start": "1225770",
    "end": "1232190"
  },
  {
    "text": "command it runs a whole bunch of Diagnostics and just make sure they're like everything's up and running I got a warning it's ok we released the new",
    "start": "1232190",
    "end": "1238550"
  },
  {
    "text": "version a couple of days ago and it's telling me I know I need to go update but for the demo I think we'll be alright so so far so good the next thing",
    "start": "1238550",
    "end": "1246770"
  },
  {
    "text": "I'm going to do is to play our sample application and again I don't expect to be like reading every line here the",
    "start": "1246770",
    "end": "1252830"
  },
  {
    "text": "point is that like this is like really simple and easy to get going so let me unpack the command I just",
    "start": "1252830",
    "end": "1259070"
  },
  {
    "text": "ran there so what I did was I added a very simple client-server application",
    "start": "1259070",
    "end": "1265910"
  },
  {
    "text": "there's a client there's a server and there's a horizontal pod autoscaler with it that's configured to say our target",
    "start": "1265910",
    "end": "1272090"
  },
  {
    "text": "value is 10 milliseconds if our latency goes above Talent if our p99 latency goes above 10 milliseconds start scaling",
    "start": "1272090",
    "end": "1279080"
  },
  {
    "text": "up the servers and the command that I was doing specifically was I was taking that llamo and I was piping it into a",
    "start": "1279080",
    "end": "1286580"
  },
  {
    "text": "linker D inject command that once again",
    "start": "1286580",
    "end": "1291760"
  },
  {
    "text": "connected to a cluster live demos full of anxiety it's great so what that",
    "start": "1291760",
    "end": "1299510"
  },
  {
    "text": "inject command does it makes one small change to your e mo it adds an annotation that says when this thing",
    "start": "1299510",
    "end": "1304820"
  },
  {
    "text": "gets deployed onto the cluster please inject that Russ proxy into each pod you can set this annotation at the pod spec",
    "start": "1304820",
    "end": "1311960"
  },
  {
    "text": "level at the name space level by default obviously we don't want to start injecting all of your your applications",
    "start": "1311960",
    "end": "1317480"
  },
  {
    "text": "but so you can kind of roll it out gradually so if that all worked I should",
    "start": "1317480",
    "end": "1325940"
  },
  {
    "text": "be able to refresh this yes we're almost there so we can see that the fan of the global Thanos query is now connecting to",
    "start": "1325940",
    "end": "1332720"
  },
  {
    "text": "four sidecars and for store API so that means that all of the linker DS have come up we're now collecting metrics",
    "start": "1332720",
    "end": "1338600"
  },
  {
    "text": "from each of those providers if I flip over to this dashboard I should start to see metrics things are looking good so",
    "start": "1338600",
    "end": "1345290"
  },
  {
    "text": "the dashboard we were looking at here this is what you get like with a generic like vanilla link or D installation the",
    "start": "1345290",
    "end": "1351710"
  },
  {
    "text": "difference is that this dashboard is pointed at a thanos instead of a Prometheus that's embedded inside linker",
    "start": "1351710",
    "end": "1357080"
  },
  {
    "text": "D that's one of my favorite things about this project thanos because like all of your tooling",
    "start": "1357080",
    "end": "1362360"
  },
  {
    "text": "if it already works with Prometheus it's going to work with Thanos it's pretty awesome so you can see that like what",
    "start": "1362360",
    "end": "1369140"
  },
  {
    "text": "link your D is providing is those like golden metrics that like success rate request volume and and latency and the",
    "start": "1369140",
    "end": "1376280"
  },
  {
    "text": "the p99 latency is the one we're going to be focused on for the autoscaler",
    "start": "1376280",
    "end": "1381760"
  },
  {
    "text": "the one thing I did do all of these - words you see here are what you would get by default by deploying linker D but",
    "start": "1382810",
    "end": "1390680"
  },
  {
    "text": "I added one for this demo and it's specifically to kind of get a view on this particular application and what's",
    "start": "1390680",
    "end": "1396710"
  },
  {
    "text": "going on so if you look on the Left we've got one server instance like per",
    "start": "1396710",
    "end": "1402350"
  },
  {
    "text": "cluster and like the those are the different providers each one is doing 100 requests per second so we've got",
    "start": "1402350",
    "end": "1408050"
  },
  {
    "text": "about 400 total and then that's our the the gauge in the upper right is our",
    "start": "1408050",
    "end": "1413060"
  },
  {
    "text": "global p99 latency and that's aggregated across all four cloud providers and",
    "start": "1413060",
    "end": "1418430"
  },
  {
    "text": "that's the number that the auto scalars are going to be looking at as they scale",
    "start": "1418430",
    "end": "1423500"
  },
  {
    "text": "up so what I'm gonna do now is I'm gonna increase load on one of the cloud providers from a hundred requests per",
    "start": "1423500",
    "end": "1430430"
  },
  {
    "text": "second to like two thousand and hopefully if this all works we're gonna see the latency spike really quick and",
    "start": "1430430",
    "end": "1436640"
  },
  {
    "text": "then we're going to see the auto scalars kick in and those things start to scale up and that that value should hopefully",
    "start": "1436640",
    "end": "1442970"
  },
  {
    "text": "go back down to ten milliseconds so I'm",
    "start": "1442970",
    "end": "1451790"
  },
  {
    "text": "gonna set the replicate count on my load generator on just one of the cloud providers on Google just arbitrarily -",
    "start": "1451790",
    "end": "1459530"
  },
  {
    "text": "I'm gonna increase it from 1 to 20 so that's where we're gonna get the 2,000 requests per second this is all gonna go",
    "start": "1459530",
    "end": "1464840"
  },
  {
    "text": "pretty fast I'll try to talk through all the changes but I think you'll get the gist okay so we scaled it up so the",
    "start": "1464840",
    "end": "1472130"
  },
  {
    "text": "first thing we should notice probably if this worked is the the middle column should start to have a huge request",
    "start": "1472130",
    "end": "1478190"
  },
  {
    "text": "volume spike there we go and then all of a sudden you see the p99 latency vite went from 3 milliseconds to 60 - so like",
    "start": "1478190",
    "end": "1484580"
  },
  {
    "text": "we're in trouble that was a massive increase in in p99 latency starting to",
    "start": "1484580",
    "end": "1489800"
  },
  {
    "text": "come back down to 27 we should hopefully start to see the horizontal pod auto scalars kicking in if if we did all of",
    "start": "1489800",
    "end": "1497300"
  },
  {
    "text": "this right let's see there we go so Google is first to notice it they should all start kind of scaling up it's a",
    "start": "1497300",
    "end": "1503570"
  },
  {
    "text": "little bit bumpy on the way up as new servers come online since we're looking at p99 only takes one request out of a hundred",
    "start": "1503570",
    "end": "1510440"
  },
  {
    "text": "to like really like spike the metric and as the server comes online and needs to like do that first request and establish",
    "start": "1510440",
    "end": "1517400"
  },
  {
    "text": "connections there it is a little bit bumpy as you're cranking up the servers but you can see that where we are",
    "start": "1517400",
    "end": "1525140"
  },
  {
    "text": "starting to get these up these have a limit of ten but as those go up I would",
    "start": "1525140",
    "end": "1530299"
  },
  {
    "text": "expect that latency value to to stabilize a bit so we'll just give it",
    "start": "1530299",
    "end": "1537410"
  },
  {
    "text": "like a few more seconds it's a little bumpy we're at 37 milliseconds hopefully",
    "start": "1537410",
    "end": "1542600"
  },
  {
    "text": "it'll get down to about 10 milliseconds within a few moments but you can see like all of this happened within a few",
    "start": "1542600",
    "end": "1548630"
  },
  {
    "text": "seconds and kind of the gist of this is that like you should not have gotten woken up in the middle of the night for",
    "start": "1548630",
    "end": "1554840"
  },
  {
    "text": "like a 20x increase in traffic and a massive latency spike and it's important",
    "start": "1554840",
    "end": "1560780"
  },
  {
    "text": "to note that like you know typically horizontal pata auto scalars they out of the box they they work more often on",
    "start": "1560780",
    "end": "1567860"
  },
  {
    "text": "things like CPU and memory which are important metrics to look at and they are valid things to scale on but as far",
    "start": "1567860",
    "end": "1575150"
  },
  {
    "text": "as focusing on your users experience whether it's somebody looking at a web page or somebody calling your service",
    "start": "1575150",
    "end": "1582130"
  },
  {
    "text": "something like a p99 latency values is can be much more valuable to ensure that",
    "start": "1582130",
    "end": "1588409"
  },
  {
    "text": "you provide like a consistent experience for the person calling your service a",
    "start": "1588409",
    "end": "1596860"
  },
  {
    "text": "couple more things I want to call out so not only is are we leveraging fan O's to",
    "start": "1596860",
    "end": "1603860"
  },
  {
    "text": "do this Multi cluster setup but because we're using those object stores I've",
    "start": "1603860",
    "end": "1610669"
  },
  {
    "text": "been working on this demo for a few days and we should be able to go back way",
    "start": "1610669",
    "end": "1615740"
  },
  {
    "text": "beyond what Prometheus like would typically give you like default I think it's like 6 hours or 24 hours or",
    "start": "1615740",
    "end": "1621559"
  },
  {
    "text": "something like that it's limited right but fanox because it's plugged into these object storage in each of the",
    "start": "1621559",
    "end": "1628340"
  },
  {
    "text": "providers we can go back like several days and kind of roll up all of these aggregated metrics over a long period of",
    "start": "1628340",
    "end": "1635690"
  },
  {
    "text": "time so really that like the takeaways from this is that like all of this stuff just like should",
    "start": "1635690",
    "end": "1641760"
  },
  {
    "text": "work like out of the box you get p99 latency values with with very little",
    "start": "1641760",
    "end": "1646950"
  },
  {
    "text": "work just by installing linker D and by installing Thanos you get really nice flexible monitoring that can work across",
    "start": "1646950",
    "end": "1654840"
  },
  {
    "text": "clusters if you want it and yeah yeah it just kind of all works I'm really upset",
    "start": "1654840",
    "end": "1660420"
  },
  {
    "text": "that it didn't get below 10 milliseconds while we're standing here so I might click back after a slide or two but",
    "start": "1660420",
    "end": "1665430"
  },
  {
    "text": "we'll see what happens so let me just just summarize really quick please check",
    "start": "1665430",
    "end": "1671010"
  },
  {
    "text": "out both of these projects as far as as link or D we've got a pretty active",
    "start": "1671010",
    "end": "1676380"
  },
  {
    "text": "slack Channel there's about 3,000 of us in there a lot of me and my co-workers sitting in there so please come say hi",
    "start": "1676380",
    "end": "1682710"
  },
  {
    "text": "and and thanks a lot",
    "start": "1682710",
    "end": "1687080"
  },
  {
    "text": "okay I guess we'll leave that up and see if latency goes down but are there any",
    "start": "1695470",
    "end": "1700669"
  },
  {
    "text": "questions question over there",
    "start": "1700669",
    "end": "1705908"
  },
  {
    "text": "thank you for the talk we are in the process of also setting up Thanos and there's one thing that we have noticed",
    "start": "1712440",
    "end": "1718050"
  },
  {
    "text": "is we are using a GCS and if we cure a longer than so if acute a long storage",
    "start": "1718050",
    "end": "1724500"
  },
  {
    "text": "basically are for requests times out if you also experience such such issues",
    "start": "1724500",
    "end": "1730080"
  },
  {
    "text": "when you have implemented this and if so how to choose or solve this I can use",
    "start": "1730080",
    "end": "1737280"
  },
  {
    "text": "this mic so you want to make sure that you set up the compactor because essentially what the compactor does is",
    "start": "1737280",
    "end": "1744180"
  },
  {
    "text": "it's the thing that's responsible for down sampling so I that the blocks are",
    "start": "1744180",
    "end": "1751020"
  },
  {
    "text": "immutable right and this is kind of where the it's not a lie but what the compactor does is multiple things it",
    "start": "1751020",
    "end": "1757620"
  },
  {
    "text": "takes smaller blocks and produces larger blocks out of those but at the same time",
    "start": "1757620",
    "end": "1762930"
  },
  {
    "text": "it performs down something so it rolls up the values to a five-minute roll-up",
    "start": "1762930",
    "end": "1769020"
  },
  {
    "text": "and an hour roll-up and so on and then the Thanos courier when you do a query over a really long time span it can",
    "start": "1769020",
    "end": "1776430"
  },
  {
    "text": "automatically detect the optimal resolution for this particular query and",
    "start": "1776430",
    "end": "1782250"
  },
  {
    "text": "then instead of querying resolution of 15 seconds when you're querying over a",
    "start": "1782250",
    "end": "1789360"
  },
  {
    "text": "year you don't actually meet that resolution right Duda can't even place the dots in your graph on our graph for that so instead it would use the one",
    "start": "1789360",
    "end": "1798870"
  },
  {
    "text": "hour resolution so I highly recommend checking that out if you haven't already and if that still doesn't work then open",
    "start": "1798870",
    "end": "1804810"
  },
  {
    "text": "an issue for us and we'll look at it into it other questions right over there",
    "start": "1804810",
    "end": "1811730"
  },
  {
    "text": "hi guys thanks for the talk I've also a short question we have",
    "start": "1814100",
    "end": "1819900"
  },
  {
    "text": "customers which are collecting per day metrics and a size of to 3 terabytes and",
    "start": "1819900",
    "end": "1827270"
  },
  {
    "text": "I saw tano's is storing all the metrics on objects or how does it fit in terms",
    "start": "1827270",
    "end": "1837600"
  },
  {
    "text": "of performance I mean our customers are trying to push all these metrics currently to",
    "start": "1837600",
    "end": "1844489"
  },
  {
    "text": "Hadoop we spark or something like that to train models to analyze all the metrics and does it fit also with",
    "start": "1844489",
    "end": "1851879"
  },
  {
    "text": "castanos and this scale yeah so Thanos has multiple layers of caches so not it",
    "start": "1851879",
    "end": "1860309"
  },
  {
    "text": "doesn't it doesn't necessarily always go to object storage directly so basically",
    "start": "1860309",
    "end": "1865950"
  },
  {
    "text": "when the store API starts it downloads the index so that it basically you can",
    "start": "1865950",
    "end": "1873179"
  },
  {
    "text": "think of it as an M map but it instead of against your local disk against",
    "start": "1873179",
    "end": "1878190"
  },
  {
    "text": "object storage and so it will kind of fetch only the data that it needs and has an additional cash on disk so kind",
    "start": "1878190",
    "end": "1886679"
  },
  {
    "text": "of the recommendation is that for that local on this cache you should probably",
    "start": "1886679",
    "end": "1892200"
  },
  {
    "text": "use SSDs and then you get pretty much the same performance we're here just now",
    "start": "1892200",
    "end": "1904259"
  },
  {
    "text": "about scaling of the actual set up apart from the your test out so obviously",
    "start": "1904259",
    "end": "1910830"
  },
  {
    "text": "across different cloud providers make sense that you have like the query API or the query are part of it they're",
    "start": "1910830",
    "end": "1916619"
  },
  {
    "text": "available to do the store API if you're on a single cloud provider and you wanted to scale light Falmouth's itself",
    "start": "1916619",
    "end": "1922769"
  },
  {
    "text": "does it make sense putting that extra layer of the query er between queriers or would it be scaling it-- store",
    "start": "1922769",
    "end": "1928859"
  },
  {
    "text": "instead so I guess that's a little bit my own opinion I think you should",
    "start": "1928859",
    "end": "1935580"
  },
  {
    "text": "probably try out a couple of things but I don't think you would need the the",
    "start": "1935580",
    "end": "1941789"
  },
  {
    "text": "additional layer of of the courier that's usually meant for to like work",
    "start": "1941789",
    "end": "1947219"
  },
  {
    "text": "with your topology and you don't actually have that problem so I'd recommend just using the sidecars of the",
    "start": "1947219",
    "end": "1953129"
  },
  {
    "text": "receive to do the hot querying and then up upload to object storage and do the",
    "start": "1953129",
    "end": "1958889"
  },
  {
    "text": "long term data there maybe you want to do multiple careers across availability",
    "start": "1958889",
    "end": "1967440"
  },
  {
    "text": "zones or something like that but that would be for availability and so much performance we're here but I",
    "start": "1967440",
    "end": "1976460"
  },
  {
    "text": "think there was also someone in the back who has been raising their hand for a while but no I have one question around",
    "start": "1976460",
    "end": "1987890"
  },
  {
    "text": "this new proposal itano's receiver anything is that we use for example only at an off-site car and queerer without",
    "start": "1987890",
    "end": "1994340"
  },
  {
    "text": "long-term storage so with this new proposal does does it mean that tunnel",
    "start": "1994340",
    "end": "2000160"
  },
  {
    "text": "sight car will be deprecated no so these are there's a place for both of these",
    "start": "2000160",
    "end": "2005460"
  },
  {
    "text": "remote right also has has some overhead it has the different characteristics so",
    "start": "2005460",
    "end": "2011950"
  },
  {
    "text": "these are both are here to stay that answers the question thanks for the talk",
    "start": "2011950",
    "end": "2020710"
  },
  {
    "text": "both of you we are already using linker the one for some of the legacy",
    "start": "2020710",
    "end": "2027400"
  },
  {
    "text": "infrastructure we have we are looking forward for using service mesh in our new infrastructure we didn't decide yet",
    "start": "2027400",
    "end": "2034210"
  },
  {
    "text": "what can you give me what like right now",
    "start": "2034210",
    "end": "2039220"
  },
  {
    "text": "most people talk about SEO invoice or link RT - can you give me what the point that you think in your opinion the best",
    "start": "2039220",
    "end": "2046240"
  },
  {
    "text": "for link Rd to go to or what is the point that is missing from link Rd and",
    "start": "2046240",
    "end": "2051520"
  },
  {
    "text": "then go to East you and thanks for being honest sure yeah yeah that's a question we get a lot yeah you probably hear",
    "start": "2051520",
    "end": "2058090"
  },
  {
    "text": "quite a bit about sto and the linker D and you are kind of - two of the main service meshes in the space I'd say two",
    "start": "2058090",
    "end": "2064990"
  },
  {
    "text": "areas where we were doing pretty well in one area that we need a little ketchup on I think we with linker D we really",
    "start": "2064990",
    "end": "2071710"
  },
  {
    "text": "focus on usability and being really clear to the the operator on what's",
    "start": "2071710",
    "end": "2077710"
  },
  {
    "text": "going on so you saw like in this demo I did like a full installation of linker D and then like layered in an application",
    "start": "2077710",
    "end": "2085570"
  },
  {
    "text": "and that all took like a few seconds two minutes that's one of our like primary design goals we want to be as simple as",
    "start": "2085570",
    "end": "2091419"
  },
  {
    "text": "possible and with with more time there's a bunch of debugging tools that we build",
    "start": "2091419",
    "end": "2096580"
  },
  {
    "text": "into linker D because we want it to be very transparent it's it's a really critical part of your your",
    "start": "2096580",
    "end": "2102070"
  },
  {
    "text": "infrastructure and so we to be really clear on like what's going on and kind of what are all the",
    "start": "2102070",
    "end": "2107670"
  },
  {
    "text": "different what's the state of all the different components so that's why I'm like usability the other is performance",
    "start": "2107670",
    "end": "2113400"
  },
  {
    "text": "there are some like sort of controversial blog posts right now if you google for SEO link or D benchmarking but overall I think we've",
    "start": "2113400",
    "end": "2120750"
  },
  {
    "text": "done pretty well there rust was a bit of a bet a year year and a half ago but I think it's paying off for us the area",
    "start": "2120750",
    "end": "2127170"
  },
  {
    "text": "that I think we need to play catch-up is we don't quite out of the features we we don't quite yet have traffic shifting",
    "start": "2127170",
    "end": "2132720"
  },
  {
    "text": "like canary and blue green deploys we're planning that in the next month or two",
    "start": "2132720",
    "end": "2138330"
  },
  {
    "text": "but because link we're d2 is a from the ground up rewrite like a year ago we have more features to implement as you",
    "start": "2138330",
    "end": "2144150"
  },
  {
    "text": "probably know like linker d1 is like very full-featured but that was thanks to like ten years of development at",
    "start": "2144150",
    "end": "2149400"
  },
  {
    "text": "Twitter so we're kind of like re-implementing a lot of that logic in in rust and go now oh that's a good",
    "start": "2149400",
    "end": "2158610"
  },
  {
    "text": "question so the question was do you get tracing with linker D so like explicit",
    "start": "2158610",
    "end": "2164100"
  },
  {
    "text": "tracing like Zipkin or open tracing we do not provide that you would have to add it yourself our thinking is that",
    "start": "2164100",
    "end": "2170990"
  },
  {
    "text": "with with linker D because it's managing traffic between all of the micro",
    "start": "2170990",
    "end": "2176340"
  },
  {
    "text": "services in your cluster we can show you every edge in your topology graph and we can give you success rate latency and",
    "start": "2176340",
    "end": "2182370"
  },
  {
    "text": "request rate on every edge so we can't follow a single request all the way",
    "start": "2182370",
    "end": "2187530"
  },
  {
    "text": "through your system but we can pinpoint where on the graph and edge is failing and that lets you like zero in on the",
    "start": "2187530",
    "end": "2193770"
  },
  {
    "text": "requests that are specifically there which we found that in in a majority of debugging cases like that's what you",
    "start": "2193770",
    "end": "2201090"
  },
  {
    "text": "really need you need to know which request is failing where and not necessarily to follow an entire life",
    "start": "2201090",
    "end": "2206130"
  },
  {
    "text": "lifetime of a request sure I don't think",
    "start": "2206130",
    "end": "2211350"
  },
  {
    "text": "we have time for any more questions on a stage so thank you again for the talk thank you",
    "start": "2211350",
    "end": "2216650"
  },
  {
    "text": "[Music] [Applause]",
    "start": "2216650",
    "end": "2223790"
  }
]
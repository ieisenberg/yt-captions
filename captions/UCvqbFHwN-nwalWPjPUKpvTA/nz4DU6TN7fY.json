[
  {
    "text": "awesome can you hear me awesome cool W Namaste",
    "start": "919",
    "end": "7120"
  },
  {
    "text": "srial good evening and namaskara I'm Kavita GA I'm PM GK pm and",
    "start": "7120",
    "end": "15280"
  },
  {
    "text": "I've come all the way from Seattle to meet you all I think in other words actually I take every opportunity to",
    "start": "15280",
    "end": "21640"
  },
  {
    "text": "jump to India because I'm originally Indian so I'm so glad to be with you and attending the first Cube Conn India I've",
    "start": "21640",
    "end": "28279"
  },
  {
    "text": "attended almost the all the others so happy to be here to meeting this awesome crowd today we are going to go",
    "start": "28279",
    "end": "35840"
  },
  {
    "text": "and talk about distributed workload AI workloads on Cube using Cube Ray on",
    "start": "35840",
    "end": "41920"
  },
  {
    "text": "kubernetes how many people can understand all the statements here all the words here everyone oh my God you're",
    "start": "41920",
    "end": "49160"
  },
  {
    "text": "intelligent Bunch huh I don't think so I could understand it this morning okay uh",
    "start": "49160",
    "end": "55079"
  },
  {
    "text": "how many people know Ray 1 2 3 4 5 6 7 real",
    "start": "55079",
    "end": "60719"
  },
  {
    "text": "more how many people know Ray okay same number okay good okay then",
    "start": "60719",
    "end": "67479"
  },
  {
    "text": "I'll introduce to you guys what Ray is and why it's used uh Cube Ray do you who knows Cube",
    "start": "67479",
    "end": "74119"
  },
  {
    "text": "Ray Brian you cannot be the only one two three okay cool uh we'll then build the",
    "start": "74119",
    "end": "80720"
  },
  {
    "text": "foundation I think then I'll keep this uh session mostly on the introductory level to understand why this is used how",
    "start": "80720",
    "end": "88079"
  },
  {
    "text": "should it be used and what you should be doing doing after leaving from here so then let's concentrate on that I already",
    "start": "88079",
    "end": "94600"
  },
  {
    "text": "did my intro uh that's one of my cool picture from um can you guess",
    "start": "94600",
    "end": "100880"
  },
  {
    "text": "where I like that she's like it's Ai No",
    "start": "101479",
    "end": "107880"
  },
  {
    "text": "sorry it's um any other",
    "start": "107880",
    "end": "112600"
  },
  {
    "text": "guess oh God I'm disappointing you it's turkey it's tumul in topaki Palace I",
    "start": "113439",
    "end": "120039"
  },
  {
    "text": "thought the background of those tiles will give it away but that's why it was cool um let's jump right into it uh so",
    "start": "120039",
    "end": "129440"
  },
  {
    "text": "traditional ml models how many of you uh worked and deployed ml models here a ml",
    "start": "129440",
    "end": "134560"
  },
  {
    "text": "models 1 2 3 4 five6 okay sounds good for",
    "start": "134560",
    "end": "142800"
  },
  {
    "text": "it sure yeah whatever right well awesome so whenever you are doing a uh",
    "start": "143120",
    "end": "149280"
  },
  {
    "text": "traditional models which used to be a smaller models right it was your regressions or it maybe even including",
    "start": "149280",
    "end": "156200"
  },
  {
    "text": "your older um image identification models and things like that these models",
    "start": "156200",
    "end": "161840"
  },
  {
    "text": "actually took a lot of time to train a lot of compute to train that means lot of dollar to train however it does not",
    "start": "161840",
    "end": "167680"
  },
  {
    "text": "take a lot of time to infer the model because they're smaller model basically so you could do basically inference that",
    "start": "167680",
    "end": "174280"
  },
  {
    "text": "means hey is this image a dog image right that is going to be much easier or because on the CPU or a smaller GPU you",
    "start": "174280",
    "end": "181319"
  },
  {
    "text": "could use before and that's how all it worked but today whenever you're using large language models the large language",
    "start": "181319",
    "end": "188640"
  },
  {
    "text": "models as it says it is large right it's super large it's only getting larger because the large language models",
    "start": "188640",
    "end": "196120"
  },
  {
    "text": "actually not only you have to spend a lot of money training it but you also have to spend infering it not all of you",
    "start": "196120",
    "end": "203799"
  },
  {
    "text": "will train it has anyone trained a created an llm model or trained an llm model here",
    "start": "203799",
    "end": "210480"
  },
  {
    "text": "no right it's not you're not going to do it as often you're going to use all the things that they in the thing gamas of",
    "start": "210480",
    "end": "216799"
  },
  {
    "text": "the world lers of the world Gemini and anything else right and you're going to use that and then you might fine tune it",
    "start": "216799",
    "end": "224040"
  },
  {
    "text": "for your use cases and then you're going to mostly serve it that is for your your",
    "start": "224040",
    "end": "229599"
  },
  {
    "text": "um for your model whatever you have fine-tuned it you might want to serve it maybe if you're in a healthcare you",
    "start": "229599",
    "end": "236360"
  },
  {
    "text": "might want to understand you want the model to understand certain Medical medication terms what are the side effects etc etc and provide more",
    "start": "236360",
    "end": "244040"
  },
  {
    "text": "accurate information so what you're doing in that case is you're mostly serving the model however now serving",
    "start": "244040",
    "end": "250920"
  },
  {
    "text": "the model is also very very expensive it is CPU and memory expensive and that's",
    "start": "250920",
    "end": "257040"
  },
  {
    "text": "the reason you need gpus and others which has higher memory requirements so",
    "start": "257040",
    "end": "262759"
  },
  {
    "text": "in that's the reason there's a lot of innovation happening in the space with distributed computing so if if you go",
    "start": "262759",
    "end": "270960"
  },
  {
    "text": "back to 20154 how kubernetes was where you wanted to create your uh e-commerce",
    "start": "270960",
    "end": "276960"
  },
  {
    "text": "website and you wanted to scale during your birst seasons why did you do it and",
    "start": "276960",
    "end": "282080"
  },
  {
    "text": "why did you use cubon cubec con is sorry why did you use kubernetes is to scale",
    "start": "282080",
    "end": "288919"
  },
  {
    "text": "right today there's a lot of innovation happening of how to take a model and",
    "start": "288919",
    "end": "295360"
  },
  {
    "text": "then distribute it across multiple gpus or tpus and then it iiz that expensive",
    "start": "295360",
    "end": "301720"
  },
  {
    "text": "resources efficiently and one of that effort is actually Ray and so why distributed I'm just",
    "start": "301720",
    "end": "309680"
  },
  {
    "text": "going through these slides you guys know what it is it's you can just think it similarly as your kubernetes uh long",
    "start": "309680",
    "end": "316400"
  },
  {
    "text": "time ago Ray has basically it's a python first approach this with Ray you can",
    "start": "316400",
    "end": "324000"
  },
  {
    "text": "distribute your training actually you can do data processing you can do",
    "start": "324000",
    "end": "329919"
  },
  {
    "text": "training then you can do fine tuning and then you can infer while Distributing the task and create parallelism with",
    "start": "329919",
    "end": "336360"
  },
  {
    "text": "your model so it can run and scale across all kinds of accelerators like GPU tpus Etc that is why Ray was created",
    "start": "336360",
    "end": "345880"
  },
  {
    "text": "I just want to give you the overall view of this one take a look at this so if you go and actually search Ray as anyone",
    "start": "345880",
    "end": "353680"
  },
  {
    "text": "done that before the session went and searched Ray and tried to read about it",
    "start": "353680",
    "end": "359720"
  },
  {
    "text": "okay one okay good student you're a good student huh sorry anyone said anything I",
    "start": "359720",
    "end": "365840"
  },
  {
    "text": "was saying such a generic name yes you have to use a good search",
    "start": "365840",
    "end": "373000"
  },
  {
    "text": "parameter Ray in a AIML or llm so um it",
    "start": "373000",
    "end": "378720"
  },
  {
    "text": "is complex the reason I asked is it is complex the it has multi there are many",
    "start": "378720",
    "end": "385000"
  },
  {
    "text": "different libraries there's many different component so I just wanted to give you this view so that way you understand what it means this Cloud",
    "start": "385000",
    "end": "392240"
  },
  {
    "text": "underneath which provides you all the compute Ray core is the one that actually enables you to provide the",
    "start": "392240",
    "end": "399120"
  },
  {
    "text": "distributed computing and we are going to talk today more about the ray core and the cloud and on top of there's so",
    "start": "399120",
    "end": "407280"
  },
  {
    "text": "many Ray AI libraries to help you with serve tune train data name it they have",
    "start": "407280",
    "end": "414080"
  },
  {
    "text": "the libraries that you can use it for your all scenarios all the life cycle of",
    "start": "414080",
    "end": "419599"
  },
  {
    "text": "your llm so today we are going to concentrate with kubernetes why Raye and",
    "start": "419599",
    "end": "425599"
  },
  {
    "text": "kubernetes work really well they are actually a match made in",
    "start": "425599",
    "end": "431879"
  },
  {
    "text": "heaven as I just want to give you like if you see this this in the ray AI",
    "start": "431879",
    "end": "437280"
  },
  {
    "text": "Library you see um this Ray also has their own uh libraries does not mean",
    "start": "437280",
    "end": "443039"
  },
  {
    "text": "that's the only Library people use there's so many libraries for each one of them if you see at the bottom there",
    "start": "443039",
    "end": "448520"
  },
  {
    "text": "are so many libraries that's out there this is at this point the AIML space is",
    "start": "448520",
    "end": "453720"
  },
  {
    "text": "a wild west it is a space there lot of innovation happening lot of new things coming lot of consolidation which is",
    "start": "453720",
    "end": "460960"
  },
  {
    "text": "necessary because we are at the very low level there's so much of Innovations to be done so you see a lot of these uh",
    "start": "460960",
    "end": "467800"
  },
  {
    "text": "things not one model fits all and so as I told you those were the libraries but",
    "start": "467800",
    "end": "473680"
  },
  {
    "text": "we're not going to dellve into the libraries here here we're going to see how the distributed framework of Ray can",
    "start": "473680",
    "end": "480120"
  },
  {
    "text": "be implemented or used on kubernetes for distributed ml models so what is the",
    "start": "480120",
    "end": "485560"
  },
  {
    "text": "core key concept of let's see what's the core key concept of the ray core right",
    "start": "485560",
    "end": "491440"
  },
  {
    "text": "so it's basically you take something right let's say you have a model and it",
    "start": "491440",
    "end": "499440"
  },
  {
    "text": "needs to be uh you know it has lot T text classification let's say text",
    "start": "499440",
    "end": "505039"
  },
  {
    "text": "classification okay you need to take you you have so much of data and you cannot send all the data to this",
    "start": "505039",
    "end": "512279"
  },
  {
    "text": "model at the same time I don't think so anyone can do that lot of GPU tpus Etc",
    "start": "512279",
    "end": "517719"
  },
  {
    "text": "so what you want to do is using gray you might want to create various Tas jobs Etc and then each one of them may be",
    "start": "517719",
    "end": "525240"
  },
  {
    "text": "using VAR different apis and libraries you might want to send certain amount of data there's different kind of",
    "start": "525240",
    "end": "531279"
  },
  {
    "text": "classifications that you can do I'm just giving you some example here so you can understand it uh you just take some",
    "start": "531279",
    "end": "536920"
  },
  {
    "text": "amount of data and say okay this data I'll send it 1 to 10 let's say 100 um text you're training with 1 to 10 uh 10",
    "start": "536920",
    "end": "544760"
  },
  {
    "text": "to 20 20 30 whatever and then you are doing parallely your training your model on this and trying to get the output so",
    "start": "544760",
    "end": "552600"
  },
  {
    "text": "to do that you use something called tasks actors and objects in Ray task is",
    "start": "552600",
    "end": "558200"
  },
  {
    "text": "nothing but it's just a function just an anonymous function that's how I thought if you guys have",
    "start": "558200",
    "end": "564399"
  },
  {
    "text": "better understanding let me know I'm trying to use similarities here so that you can understand it's just a simple",
    "start": "564399",
    "end": "570000"
  },
  {
    "text": "function a python function that you can use write something and then this function can be fed and said take this",
    "start": "570000",
    "end": "577200"
  },
  {
    "text": "function and run it on 100 different computer and use different objects right",
    "start": "577200",
    "end": "583000"
  },
  {
    "text": "or data and then colate me collate output that is what is rare at this point it's basically taking and",
    "start": "583000",
    "end": "588800"
  },
  {
    "text": "paralyzing and running the same thing or or a different variation of it at the",
    "start": "588800",
    "end": "593839"
  },
  {
    "text": "same time uh across your Compu so that you don't have to use very expensive",
    "start": "593839",
    "end": "599360"
  },
  {
    "text": "ensive chips and you cannot get so much of memory at the same time and hence you're trying to distribute it across um",
    "start": "599360",
    "end": "606000"
  },
  {
    "text": "your gpus that's the overall idea to task it's like function actors has anybody know actor model it's very",
    "start": "606000",
    "end": "613399"
  },
  {
    "text": "famous in kubernetes right so it's nothing but a stateful model that means you have a state it you in other simple",
    "start": "613399",
    "end": "620040"
  },
  {
    "text": "terms it's nothing but you have let's say a variable it knows what's the value of the variable and it stores a variable",
    "start": "620040",
    "end": "625680"
  },
  {
    "text": "next time you increment it it goes 1 to two 2 to three so that's the ACT model it also has the data and the state that",
    "start": "625680",
    "end": "631360"
  },
  {
    "text": "stores objects are nothing but the data structure that you feed between these two and that's what will be used um",
    "start": "631360",
    "end": "639200"
  },
  {
    "text": "across task and actors and also to share between these things so that's the core",
    "start": "639200",
    "end": "644680"
  },
  {
    "text": "key concept and we'll see through demo and I'll show you some um code Etc to",
    "start": "644680",
    "end": "650639"
  },
  {
    "text": "understand what these are all of them and here's coming back to how an AIML",
    "start": "650639",
    "end": "658120"
  },
  {
    "text": "model if you have to run a AIML ecosystem is quite complex it needs lot",
    "start": "658120",
    "end": "663839"
  },
  {
    "text": "of things today and I just want to give you this a overview so that you know",
    "start": "663839",
    "end": "669720"
  },
  {
    "text": "where the ray will fit at this point right so if you are a operator so",
    "start": "669720",
    "end": "676800"
  },
  {
    "text": "there's multiple people in your organization will work this entire stack cannot be built by one role you have",
    "start": "676800",
    "end": "682639"
  },
  {
    "text": "your platform team your kubernetes guys if you guys are kubernetes this is where you come the blue one you platform",
    "start": "682639",
    "end": "689519"
  },
  {
    "text": "kubernetes team to enable this distribution to provide a platform to your ml Engineers your AI Engineers who",
    "start": "689519",
    "end": "697079"
  },
  {
    "text": "are building or training or serving you have to build something called an AIML platform underneath and that's where you",
    "start": "697079",
    "end": "703560"
  },
  {
    "text": "can use Ray and kubernetes to scale and the next is Ray as I said can",
    "start": "703560",
    "end": "709320"
  },
  {
    "text": "be used in everywhere underneath you can use GK with auto scaling with q and with",
    "start": "709320",
    "end": "714959"
  },
  {
    "text": "your aray and you can use all of this for data processing fine-tuning and inferencing I've given few other things",
    "start": "714959",
    "end": "720680"
  },
  {
    "text": "that mostly are used but it doesn't have to be you can use Ray as I showed you Ray has so many libraries you can use",
    "start": "720680",
    "end": "726639"
  },
  {
    "text": "Ray for data processing fine-tuning inferencing all of it but people uh use VMS which are very common how many know",
    "start": "726639",
    "end": "733880"
  },
  {
    "text": "VM here awesome yeah so and why do you use",
    "start": "733880",
    "end": "739040"
  },
  {
    "text": "it whoever raised in hands yeah so VM is built for inference",
    "start": "739040",
    "end": "745079"
  },
  {
    "text": "optimization so that's the reason it's on the inference side here and pytor for fine-tuning and it's base model",
    "start": "745079",
    "end": "751519"
  },
  {
    "text": "frameworking for training and Etc um perfect so how do now that you know what",
    "start": "751519",
    "end": "758920"
  },
  {
    "text": "Ray core is how do we run Ray right so this is where Cube Ray is comes into",
    "start": "758920",
    "end": "765519"
  },
  {
    "text": "picture Cube Ray is an extension of Ray and Cube Ray provides you the cuetes uh",
    "start": "765519",
    "end": "772880"
  },
  {
    "text": "crds to create the Cuban uh the ray objects and to run the ray objects all",
    "start": "772880",
    "end": "779480"
  },
  {
    "text": "the time so that's what is Cube Ray and if you can see here you have Ray uh Ray",
    "start": "779480",
    "end": "787160"
  },
  {
    "text": "core can be run in two ways one you can see on the right I don't have a does the",
    "start": "787160",
    "end": "792519"
  },
  {
    "text": "point to work yeah it does okay so you can run the ray core um Ray launchers on",
    "start": "792519",
    "end": "799279"
  },
  {
    "text": "the VMS Cloud VMS by yourself but it is that you have to manage all of this by",
    "start": "799279",
    "end": "804480"
  },
  {
    "text": "yourself on the other hand there's CU that is that enables you to use it on",
    "start": "804480",
    "end": "811000"
  },
  {
    "text": "kubernetes which provides you all the base layer of distributed computing such as consistency distribution scalability",
    "start": "811000",
    "end": "818240"
  },
  {
    "text": "availability Etc and you don't have to worry about those so and Cube allows you to use cubet constructs to provide that",
    "start": "818240",
    "end": "827800"
  },
  {
    "text": "scalability that you need for your ml platform with Ray that's where the ray comes Cub comes into",
    "start": "827800",
    "end": "835199"
  },
  {
    "text": "picture and um again this is yray on kubernetes it's same thing why did we",
    "start": "835199",
    "end": "841320"
  },
  {
    "text": "use um kubernetes it's high availability infrastructure automation multicloud etc",
    "start": "841320",
    "end": "847320"
  },
  {
    "text": "etc and this is kind of a diagram that kind of showing you how um you know",
    "start": "847320",
    "end": "853040"
  },
  {
    "text": "things work you provide a scaling request through actors Tas and actors comes to CU cubra is an operator that",
    "start": "853040",
    "end": "860839"
  },
  {
    "text": "understands and then it creates and and manages and maintains these resources",
    "start": "860839",
    "end": "866199"
  },
  {
    "text": "and then you have the advantage with cubre and other things all the other periphery advantage that you get you now have observability you",
    "start": "866199",
    "end": "873959"
  },
  {
    "text": "have monitoring you have scale you have all of that information at one place where you run your other workloads as",
    "start": "873959",
    "end": "880519"
  },
  {
    "text": "well that's the overview let's um H I think I should do this I should",
    "start": "880519",
    "end": "888240"
  },
  {
    "text": "introduce this before I show you the code um you know what maybe I'll show",
    "start": "888240",
    "end": "894279"
  },
  {
    "text": "you the code first and then we can go to that okay let's move on to the Corde and",
    "start": "894279",
    "end": "900199"
  },
  {
    "text": "let's so we introduce what did I introduce for as a part of um Can",
    "start": "900199",
    "end": "905600"
  },
  {
    "text": "somebody call out what did I introduce as part of Ray what are the key concepts of Ray",
    "start": "905600",
    "end": "912120"
  },
  {
    "text": "tasks actors objects exactly so task as",
    "start": "912120",
    "end": "917959"
  },
  {
    "text": "I said it's a function that's it that's all it is and here you can see that um I",
    "start": "917959",
    "end": "924120"
  },
  {
    "text": "have a function here and all it does it has some function that's it and it returns one that's all it does right uh",
    "start": "924120",
    "end": "932240"
  },
  {
    "text": "so you can write any kind of function obviously when you use your MLS and Etc it becomes complex but I just wanted to",
    "start": "932240",
    "end": "937680"
  },
  {
    "text": "introduce what this is but you can see I have other few things such as import Ray and Ray in it what it does is it",
    "start": "937680",
    "end": "944839"
  },
  {
    "text": "initializes a cluster for you Ray has something called a cluster and a worker",
    "start": "944839",
    "end": "950279"
  },
  {
    "text": "Ray cluster oh sorry thank",
    "start": "950279",
    "end": "956360"
  },
  {
    "text": "you come on oh sorry",
    "start": "956800",
    "end": "960920"
  },
  {
    "text": "yeah I'm trying to use the keyboard it's not nope wait hold",
    "start": "964600",
    "end": "969680"
  },
  {
    "text": "on",
    "start": "969680",
    "end": "972680"
  },
  {
    "text": "yeah wow let's",
    "start": "975120",
    "end": "981720"
  },
  {
    "text": "see thank you for helping me okay here",
    "start": "981720",
    "end": "990319"
  },
  {
    "text": "thank you somebody help me fine oh yeah Apple View correct you want",
    "start": "990319",
    "end": "998040"
  },
  {
    "text": "to zoom the entire thing okay zoom zoom it's command equal to awesome yeah",
    "start": "998040",
    "end": "1005800"
  },
  {
    "text": "cool there you go you now understand that I don't write",
    "start": "1005800",
    "end": "1010839"
  },
  {
    "text": "code much okay so um this is basically the array in it",
    "start": "1010839",
    "end": "1018279"
  },
  {
    "text": "will create you the cluster it create you the worker to run this task and that is what we are going to see further and",
    "start": "1018279",
    "end": "1025678"
  },
  {
    "text": "how we going to use kubernetes for it or cuay for it and and here what this is",
    "start": "1025679",
    "end": "1031360"
  },
  {
    "text": "the object I was talking about instead of wring one what I'm trying to use I'm using Cube Ray object so this is the",
    "start": "1031360",
    "end": "1037480"
  },
  {
    "text": "object you create a task you create an object it's stored and then that you can use it as a cube Ray function as get and",
    "start": "1037480",
    "end": "1044280"
  },
  {
    "text": "then there's an actor and in an actor here is basically",
    "start": "1044280",
    "end": "1050280"
  },
  {
    "text": "here you do a class it's more you have to persist your data right and hence you have a class here and then the class I",
    "start": "1050280",
    "end": "1056960"
  },
  {
    "text": "have this counter and I all I do with the counter is you know and I'm doing a follow Loop here and I keep incrementing",
    "start": "1056960",
    "end": "1063360"
  },
  {
    "text": "the counter and it retain for each run it retains the value so 1 2 3 if you run this it just become 1 2 3 Etc so that's",
    "start": "1063360",
    "end": "1070840"
  },
  {
    "text": "the basics of actor word actor and task this um and yes this is the simplest",
    "start": "1070840",
    "end": "1077280"
  },
  {
    "text": "explanation when it comes to to using these Concepts in your ml you have to use various different libraries that's",
    "start": "1077280",
    "end": "1083520"
  },
  {
    "text": "out there and create various different use various different architecture for your data parallelism your model",
    "start": "1083520",
    "end": "1089000"
  },
  {
    "text": "parallelism whatever that is to make sure you do distribute it there's some um we'll go through it later there's",
    "start": "1089000",
    "end": "1095400"
  },
  {
    "text": "some um Ray itself has a lot of examples that you can use and see how these larger",
    "start": "1095400",
    "end": "1102320"
  },
  {
    "text": "actors and larger tasks are written in the real ml life so we're going to go through and we'll deploy actually one of",
    "start": "1102320",
    "end": "1107640"
  },
  {
    "text": "the llm model actually I'll show you one it's already deployed it takes time if I deploy all of it so we can go through",
    "start": "1107640",
    "end": "1113720"
  },
  {
    "text": "that and then you'll see um how it all works awesome so the next topic is now",
    "start": "1113720",
    "end": "1120320"
  },
  {
    "text": "that you have this tasks and actors Etc which is the ray concept and Ray also",
    "start": "1120320",
    "end": "1125760"
  },
  {
    "text": "has something called cluster and work uh workers so it's basically you create it's like control plane and data plane",
    "start": "1125760",
    "end": "1131880"
  },
  {
    "text": "of your kubernetes where you have control plane you say I need so many workers and these workers need to have",
    "start": "1131880",
    "end": "1137679"
  },
  {
    "text": "these kind of configuration Etc and it then it creates that workers and it manages and maintains that workers so",
    "start": "1137679",
    "end": "1145400"
  },
  {
    "text": "that part is where the ray clusters comes into picture so in Cube Ray apis",
    "start": "1145400",
    "end": "1151240"
  },
  {
    "text": "it's nothing but you have something called Ray cluster um crd with Ray cluster crd you provide these uh yaml to",
    "start": "1151240",
    "end": "1160000"
  },
  {
    "text": "create the r u ray cluster at the end and use that rate cluster to run the jobs and services jobs as jobs are kind",
    "start": "1160000",
    "end": "1167240"
  },
  {
    "text": "of if you want to equate it you want to run any task or actors here in a job fashion then you use Ray jobs and if you",
    "start": "1167240",
    "end": "1173440"
  },
  {
    "text": "want to use a service and expose an endpoint or an application um AIML application use Ray service so this is",
    "start": "1173440",
    "end": "1180440"
  },
  {
    "text": "the demo that we're going to go through now and uh I I'm not going to do a live demo this will be a recorded demo um and",
    "start": "1180440",
    "end": "1187919"
  },
  {
    "text": "then but I'll explain it to you um how we are going through it",
    "start": "1187919",
    "end": "1193080"
  },
  {
    "text": "Etc awesome cool so what are we going to do",
    "start": "1193080",
    "end": "1200360"
  },
  {
    "text": "here is we have already created a ray cluster let's go look at this particular",
    "start": "1200360",
    "end": "1206039"
  },
  {
    "text": "Ray uh Ray cluster and then then we run few jobs and then we'll run an llm model",
    "start": "1206039",
    "end": "1212520"
  },
  {
    "text": "itself and then we'll start serving the model and I'll try to tie up all these concepts for you I think I already",
    "start": "1212520",
    "end": "1218559"
  },
  {
    "text": "introduced uh two sets of concept one is the task jobs and sorry T actors and",
    "start": "1218559",
    "end": "1224720"
  },
  {
    "text": "objects the key Core Concepts and then I introduced you the kubernetes ray",
    "start": "1224720",
    "end": "1230200"
  },
  {
    "text": "concept such as jobs and services and cluster cluster is nothing but basically to get you your workloads and resources",
    "start": "1230200",
    "end": "1237240"
  },
  {
    "text": "what do I need what kind of resource I need GPU on how many Etc that's what you do with clusters and with respect to the",
    "start": "1237240",
    "end": "1244960"
  },
  {
    "text": "um jobs and services is basically you're trying to say I this is how I want to",
    "start": "1244960",
    "end": "1250080"
  },
  {
    "text": "run it right I'll use this cluster and run this uh particular service or task",
    "start": "1250080",
    "end": "1255720"
  },
  {
    "text": "or objects in a job fashion or in a service fashion that is how you would want to tie the",
    "start": "1255720",
    "end": "1260840"
  },
  {
    "text": "cube Ray and then the ray Concepts together okay so here we are going to do",
    "start": "1260840",
    "end": "1266440"
  },
  {
    "text": "um we already have a cluster so we're going to pull up and um see whether I'll",
    "start": "1266440",
    "end": "1271720"
  },
  {
    "text": "show you the cluster information Etc before that I think we should also see whether we have and the cube Ray um crds",
    "start": "1271720",
    "end": "1280520"
  },
  {
    "text": "in the cluster and that is what we are trying to do we just did find the AP resource and grab pray and you see this",
    "start": "1280520",
    "end": "1286960"
  },
  {
    "text": "Ray clusters Ray jobs and Ray Services these crds are already installed and gke",
    "start": "1286960",
    "end": "1292720"
  },
  {
    "text": "you already have a ray operator you don't have to work um you don't have to go and in separately you just have to",
    "start": "1292720",
    "end": "1297799"
  },
  {
    "text": "enable the ray operator on GK and once we have this now let's go look at the cluster that we have on this particular",
    "start": "1297799",
    "end": "1305880"
  },
  {
    "text": "um on our on on cuber cluster I've already created so if you see this there",
    "start": "1305880",
    "end": "1312039"
  },
  {
    "text": "are many different clusters the one that I'm going to talk about today is the ray cluster demo right and each cluster will",
    "start": "1312039",
    "end": "1317880"
  },
  {
    "text": "also have a Sur service and uh and if you can see there's a ray cluster demo",
    "start": "1317880",
    "end": "1323000"
  },
  {
    "text": "head service there and it has multiple uh end points to it and we are going to",
    "start": "1323000",
    "end": "1328240"
  },
  {
    "text": "what we're going to do is it already has a port forwarding today um and we are going to now do another port forwarding",
    "start": "1328240",
    "end": "1334600"
  },
  {
    "text": "for its dashboard think like Prometheus grafana dashboard right it it has its own dashboard where you can see all the",
    "start": "1334600",
    "end": "1340919"
  },
  {
    "text": "jobs and etc etc so that is what we are going to see with the port forwarding today and we just going to do the port",
    "start": "1340919",
    "end": "1348760"
  },
  {
    "text": "forwarding and this is very helpful when you're working with um Ray Cube Ray",
    "start": "1348760",
    "end": "1354039"
  },
  {
    "text": "right so you can see what jobs you submitted whe it failed it passed you also have that easy dashboard that you",
    "start": "1354039",
    "end": "1359240"
  },
  {
    "text": "can do uh which otherwise would be harder um and you have to figure it out so now if you go here and if you go do",
    "start": "1359240",
    "end": "1366480"
  },
  {
    "text": "this so this is the dashboard I was talking about it is it has jobs clusters",
    "start": "1366480",
    "end": "1372120"
  },
  {
    "text": "actors metrics logs all the information is provided and it has like information of all the jobs that you have run so far",
    "start": "1372120",
    "end": "1379080"
  },
  {
    "text": "right you can see which one has failed which one has passed the actors you have the objects you have so all of this so",
    "start": "1379080",
    "end": "1385400"
  },
  {
    "text": "basically I have created a cluster I'll show you the cluster configuration for this Cube cluster AML uh what it was and",
    "start": "1385400",
    "end": "1392559"
  },
  {
    "text": "um that's the cluster that I already have um and I've created this is all running all good you have the cluster",
    "start": "1392559",
    "end": "1399799"
  },
  {
    "text": "now now that I have the cluster I might want to create the job and the job so",
    "start": "1399799",
    "end": "1405919"
  },
  {
    "text": "here is what um this is the cluster yel that I'm showing here and as you can see it has a master and then the head that's",
    "start": "1405919",
    "end": "1412960"
  },
  {
    "text": "we call it as and then it has workers and you can for your workers you can specify how many replicas of workers do",
    "start": "1412960",
    "end": "1420440"
  },
  {
    "text": "you want what kind of um GPU TPU what's the CPU what's the memory that you want",
    "start": "1420440",
    "end": "1425640"
  },
  {
    "text": "to do for your workers all of that this is basically compute you know that just",
    "start": "1425640",
    "end": "1430679"
  },
  {
    "text": "simple as compute and go for it and here's the job and what I'm going to do now is I'm just running some python code",
    "start": "1430679",
    "end": "1437840"
  },
  {
    "text": "on my cluster I'm selecting a cluster and this is my Ray cluster demo remember that Ray jobs can only be run on the ray",
    "start": "1437840",
    "end": "1444919"
  },
  {
    "text": "clusters right and you have created it I'm just saying that please use this Ray cluster demo and all I'm doing is I'm",
    "start": "1444919",
    "end": "1451840"
  },
  {
    "text": "just going and printing array cluster resources if you have a different job of running your inflence models or your",
    "start": "1451840",
    "end": "1458159"
  },
  {
    "text": "thing you just provide that particular entry point uh to the job and a job will initiate we'll work through it and then",
    "start": "1458159",
    "end": "1465279"
  },
  {
    "text": "go for it so you can see that the r job is working now and um that's the um",
    "start": "1465279",
    "end": "1474919"
  },
  {
    "text": "sorry perfect and uh and you yeah that's the a job that's running and if you go",
    "start": "1475000",
    "end": "1481880"
  },
  {
    "text": "see the logs you'll see that it you know in the python I just said go show all the cluster resources I've allocated if",
    "start": "1481880",
    "end": "1487640"
  },
  {
    "text": "you go back here you can see that the memory CPU Etc this is a simple way of showing how do you run a job on a ray",
    "start": "1487640",
    "end": "1495120"
  },
  {
    "text": "cluster very simple mechanism here that's all it is but jobs are okay right",
    "start": "1495120",
    "end": "1500440"
  },
  {
    "text": "jobs are similar to cuber job if you look at it right it takes runs something on the ray cluster and then it's done",
    "start": "1500440",
    "end": "1507159"
  },
  {
    "text": "with it and if you really want to that's a best practice you should not create a r cluster separately and job separately",
    "start": "1507159",
    "end": "1513919"
  },
  {
    "text": "you should actually create them as together as I'm showing you here this is the idea where when you submit a job it",
    "start": "1513919",
    "end": "1520919"
  },
  {
    "text": "wakes up creates a cluster for you it runs the job and then deletes the job this is very important so that you do",
    "start": "1520919",
    "end": "1527640"
  },
  {
    "text": "not spend lot of money on it you you know you don't uh have to manage the Clusters later on and all of those",
    "start": "1527640",
    "end": "1534000"
  },
  {
    "text": "things you just do it when it is necessary and it's called epimeral and we're going to talk a little bit of",
    "start": "1534000",
    "end": "1539039"
  },
  {
    "text": "advantage and disadvantages of it at the end of this uh next is the race service",
    "start": "1539039",
    "end": "1544399"
  },
  {
    "text": "so Race Service is the where I'm going to create an application or run an",
    "start": "1544399",
    "end": "1549840"
  },
  {
    "text": "application and then I'm going to serve it with an end point to it and here you",
    "start": "1549840",
    "end": "1555120"
  },
  {
    "text": "can see that we are using a model or the project that all Ray projects provide is",
    "start": "1555120",
    "end": "1561080"
  },
  {
    "text": "nothing but llm model uh the Lama model and for this Lama model it has an",
    "start": "1561080",
    "end": "1566640"
  },
  {
    "text": "application called Model that we're going to serve right that's basically we're using it to serve it and that's",
    "start": "1566640",
    "end": "1572840"
  },
  {
    "text": "the working directory um that you see up here uh if you go look you can um you",
    "start": "1572840",
    "end": "1578159"
  },
  {
    "text": "can go and look at this particular um uh git you can also use anything here it doesn't have to be get right it can be",
    "start": "1578159",
    "end": "1584559"
  },
  {
    "text": "your foil file storage or whatever that you want you can use that here doesn't have to be a zip at the end of the day",
    "start": "1584559",
    "end": "1590919"
  },
  {
    "text": "and here once you provide a location and here I provided this ZIP that is now in",
    "start": "1590919",
    "end": "1597279"
  },
  {
    "text": "this ZIP I have re operator I have a folder called config samples VM and then",
    "start": "1597279",
    "end": "1602880"
  },
  {
    "text": "something called a model model is my function this is basically a function that I'm trying to ask to call which is",
    "start": "1602880",
    "end": "1608960"
  },
  {
    "text": "nothing but we'll load the model and we'll serve the model that is how simple this is that's it so it's actually",
    "start": "1608960",
    "end": "1615600"
  },
  {
    "text": "writing the code is harder definitely to serve a model and all of that but to run",
    "start": "1615600",
    "end": "1620720"
  },
  {
    "text": "it to use your compute and to get that scalability on uh kubernetes it's going to be easy and here is where you provide",
    "start": "1620720",
    "end": "1627799"
  },
  {
    "text": "and tell you how much resources you want what kind of resources you want how much GPU and you can always use scaling Auto",
    "start": "1627799",
    "end": "1633799"
  },
  {
    "text": "scaling others on GK other Cloud where they provide this capability so that you can scale as you need uh overall and now",
    "start": "1633799",
    "end": "1642279"
  },
  {
    "text": "what we going to do is we are going to take up um so here's the service which",
    "start": "1642279",
    "end": "1647600"
  },
  {
    "text": "has already been created um for this one and once we have this what I'm going to",
    "start": "1647600",
    "end": "1652640"
  },
  {
    "text": "do is um we are going to create P forward so idea here is I'm going to",
    "start": "1652640",
    "end": "1659720"
  },
  {
    "text": "stop here for a minute so now you understood how we",
    "start": "1659720",
    "end": "1665559"
  },
  {
    "text": "going to use a service and a job and that uses the Q break core tasks and",
    "start": "1665559",
    "end": "1675480"
  },
  {
    "text": "actors Etc and then use underlying compute with C uh Ray clusters and run",
    "start": "1675480",
    "end": "1681360"
  },
  {
    "text": "it in a distributed manner right with the worker nodes like the worker workers of cube how much replica you want what",
    "start": "1681360",
    "end": "1688000"
  },
  {
    "text": "kind of resource you want that is basically the overall gist of this particular session of how you take Ray",
    "start": "1688000",
    "end": "1694440"
  },
  {
    "text": "why you would use Ray and how you use Cube Ray how you use kubernetes and align it all together does it make sense",
    "start": "1694440",
    "end": "1701799"
  },
  {
    "text": "okay did I make it simple enough any questions awesome cool I got some hands",
    "start": "1701799",
    "end": "1707840"
  },
  {
    "text": "up there there thumbs up there so cool what we're going to do now uh I'll show",
    "start": "1707840",
    "end": "1713720"
  },
  {
    "text": "you the code if you want I can also show you how does you know let me do that let me show you how does",
    "start": "1713720",
    "end": "1721960"
  },
  {
    "text": "the the here's that Ray Cube Ray so if you",
    "start": "1724240",
    "end": "1729480"
  },
  {
    "text": "go maximize this and um surray operator",
    "start": "1729480",
    "end": "1735480"
  },
  {
    "text": "and I think it was config so under config it was do you guys remember after",
    "start": "1735480",
    "end": "1742320"
  },
  {
    "text": "that security samp samples yeah not",
    "start": "1742320",
    "end": "1749440"
  },
  {
    "text": "security yes good job awesome and uh then there is the these two right this",
    "start": "1750080",
    "end": "1757240"
  },
  {
    "text": "is the serve this is the serve python right if you open this serve Python and expand it so this is your basically",
    "start": "1757240",
    "end": "1766200"
  },
  {
    "text": "the this is the class that that you are actor class that you're providing here and what you're doing is this is the",
    "start": "1766200",
    "end": "1773320"
  },
  {
    "text": "model you said serve. model so model is the object that you're wring so this is a basically it's giving you a structure",
    "start": "1773320",
    "end": "1780120"
  },
  {
    "text": "of how to go about it and use use the structure to create the objects in serving and use the underlying model so",
    "start": "1780120",
    "end": "1786880"
  },
  {
    "text": "this is the uh thee that you have written to serve the llm model the Lama",
    "start": "1786880",
    "end": "1793039"
  },
  {
    "text": "actually the LMA model here so that's basically what what it was what you",
    "start": "1793039",
    "end": "1798080"
  },
  {
    "text": "actually deployed as a race service and now that you have deployed it you might want to use it so it's",
    "start": "1798080",
    "end": "1805360"
  },
  {
    "text": "already deployed as you saw there was a service endpoint to it now let's send few um questions to it and see whether",
    "start": "1805360",
    "end": "1812080"
  },
  {
    "text": "it can answer and that's the fun part of the demo let's see if it all works or in",
    "start": "1812080",
    "end": "1817600"
  },
  {
    "text": "this case it's not me working it's actually in this case I have to see whether the um the Llama llm can work",
    "start": "1817600",
    "end": "1824960"
  },
  {
    "text": "and make sure uh it can provide the um answers so what I what in this demo what",
    "start": "1824960",
    "end": "1830720"
  },
  {
    "text": "we have already done is that here is my curl that where I'm providing because I've already done port forwarding here",
    "start": "1830720",
    "end": "1836240"
  },
  {
    "text": "for 8,000 so I'm just submitting this particular thing and now is the answer",
    "start": "1836240",
    "end": "1842159"
  },
  {
    "text": "there basically so the questions that we asked for it are your very helpful",
    "start": "1842159",
    "end": "1847919"
  },
  {
    "text": "assistant provide a brief sentence describing Ray open source project right",
    "start": "1847919",
    "end": "1853600"
  },
  {
    "text": "let's see what the answer is R project is open source high performance dispute Computing framework developed by data",
    "start": "1853600",
    "end": "1860320"
  },
  {
    "text": "breaks that supports Python and allows for scalable Computing and data processing is this",
    "start": "1860320",
    "end": "1868039"
  },
  {
    "text": "correct is this correct I did a demo guys you should be able to tell",
    "start": "1868120",
    "end": "1875639"
  },
  {
    "text": "this you don't think so what is wrong data breaks exactly this thing is",
    "start": "1875639",
    "end": "1882519"
  },
  {
    "text": "hallucinating here I mean yeah because I think I think we are loading a 3 billion model it's a token model so I'm thinking",
    "start": "1882519",
    "end": "1890279"
  },
  {
    "text": "maybe the 7 billion and the other might be good so this definitely is not developed by data bricks it's an open",
    "start": "1890279",
    "end": "1896360"
  },
  {
    "text": "source uh community and it's a rich open source Community not contributed by one",
    "start": "1896360",
    "end": "1902200"
  },
  {
    "text": "uh company or anything so that's the hallucination part here but the rest of it pretty intact that's right that I can",
    "start": "1902200",
    "end": "1909039"
  },
  {
    "text": "say so that's um what we did with the CU so that's the end of my demo and if I go",
    "start": "1909039",
    "end": "1915840"
  },
  {
    "text": "back let's talk quickly about epimeral versus persistent so epimeral is",
    "start": "1915840",
    "end": "1921519"
  },
  {
    "text": "basically think this is when you're running a service or a job you create your cluster that's it after that tear",
    "start": "1921519",
    "end": "1927519"
  },
  {
    "text": "it down once you at the end of it tear it down at the end of the job or Etc the reason is process reproductibility uh",
    "start": "1927519",
    "end": "1933919"
  },
  {
    "text": "reproducibility and then no need to maintain and things like that cons are obviously you have a latency uh all of",
    "start": "1933919",
    "end": "1940360"
  },
  {
    "text": "that and again um why would you do persistent so that you can reduce",
    "start": "1940360",
    "end": "1945399"
  },
  {
    "text": "startup latency um and uh you can have a um history you can monitor etc etc",
    "start": "1945399",
    "end": "1952720"
  },
  {
    "text": "awesome and there's no security you might want to use whatever the cloud providers uh provides for your Rend points uh for the Securities",
    "start": "1952720",
    "end": "1959600"
  },
  {
    "text": "Etc cool uh the community is growing you can always tag into this community and",
    "start": "1959600",
    "end": "1965080"
  },
  {
    "text": "then um you can always contribute see what is happening check their release notes and even try it on um there's so",
    "start": "1965080",
    "end": "1971880"
  },
  {
    "text": "many examples as I showed one of the example there's so many such examples and it's all in Python it's easy to",
    "start": "1971880",
    "end": "1977240"
  },
  {
    "text": "develop and run try out I think it'll be um easy so I think one uh before ending",
    "start": "1977240",
    "end": "1983080"
  },
  {
    "text": "I just want to talk about how this particular thing um how we are making it easy on um gke is we do have all the",
    "start": "1983080",
    "end": "1991799"
  },
  {
    "text": "latest gen um H 100 and tpus that we are providing there's a high bandwidth",
    "start": "1991799",
    "end": "1998399"
  },
  {
    "text": "Network that runs behind it and then we also have done a lot of innovation of how to load the data as well as your",
    "start": "1998399",
    "end": "2004600"
  },
  {
    "text": "containers faster and then to reduce your disrup option with checkpointing who understands checkpointing",
    "start": "2004600",
    "end": "2011440"
  },
  {
    "text": "here explain back sorry I just have to go somebody at the",
    "start": "2011440",
    "end": "2018960"
  },
  {
    "text": "back and when you use checkpointing training inference what",
    "start": "2030240",
    "end": "2037360"
  },
  {
    "text": "awesome so checkpointing is a is a concept uh in uh ml right where when",
    "start": "2038200",
    "end": "2044720"
  },
  {
    "text": "you're training such large models what happens if your compute went away you have to redo everything if you have to",
    "start": "2044720",
    "end": "2051638"
  },
  {
    "text": "redo everything how much cost you have done and the sum of these models takes a lot of time to train it if you think",
    "start": "2051639",
    "end": "2056919"
  },
  {
    "text": "about the billions of parameters right so it's quite expensive though that's",
    "start": "2056919",
    "end": "2062000"
  },
  {
    "text": "when you do checkpointing and that means you periodically save all your parameters and then and for at least for",
    "start": "2062000",
    "end": "2068878"
  },
  {
    "text": "some reason something fails you can start back from there even that can be sometimes expensive because even that",
    "start": "2068879",
    "end": "2074240"
  },
  {
    "text": "from last checkpoint to the current checkpoint if it before taking a checkpoint failed for example the",
    "start": "2074240",
    "end": "2080440"
  },
  {
    "text": "storing the data it was longer Etc even that sometimes is very expensive in today's ecosystem because of the",
    "start": "2080440",
    "end": "2087118"
  },
  {
    "text": "resource shortages and the resource prices um and you can see here we kind",
    "start": "2087119",
    "end": "2092599"
  },
  {
    "text": "of enabled uh a faster workload startup right so we are now able to obtain a",
    "start": "2092599",
    "end": "2100640"
  },
  {
    "text": "AIML images usually are very expensive right with secondary boot disk what we enabled is you can now load your AIML",
    "start": "2100640",
    "end": "2109160"
  },
  {
    "text": "and use secondary boot dis so that your VMS have it available instead of downloading it which was taking a lot of",
    "start": "2109160",
    "end": "2115400"
  },
  {
    "text": "time to speed up those things we have kind of enabled um I think it has enabled one of our customer um told us",
    "start": "2115400",
    "end": "2121880"
  },
  {
    "text": "about 29x Improvement in time and I think we also benchmarked it around it",
    "start": "2121880",
    "end": "2127079"
  },
  {
    "text": "and we also are using something called cloud storage fuse so you can use your ssts to cach these objects so that if",
    "start": "2127079",
    "end": "2133359"
  },
  {
    "text": "you want to read repeat reads and for random iio so you don't have to go back to the object s store and that causes a",
    "start": "2133359",
    "end": "2140280"
  },
  {
    "text": "lot of um um that that increases the time taken and adds latency Etc this are",
    "start": "2140280",
    "end": "2146240"
  },
  {
    "text": "some of the improvements that we are adding more and more into uh gke with Ray so using gray and Cube Ray and some",
    "start": "2146240",
    "end": "2154119"
  },
  {
    "text": "of these features will help you to train and infer f faster and more efficiently",
    "start": "2154119",
    "end": "2159359"
  },
  {
    "text": "and in more price performance Manner and here we have something called compute",
    "start": "2159359",
    "end": "2164640"
  },
  {
    "text": "classes which helps you to prioritize what compute you want you can say fall back compute you can say hey I want uh",
    "start": "2164640",
    "end": "2171280"
  },
  {
    "text": "sport priorities if I don't get it then fall back to something else otherwise fall back to something else so you can provide all your information this",
    "start": "2171280",
    "end": "2178000"
  },
  {
    "text": "becomes very important when you're running uh High compute workload um it's",
    "start": "2178000",
    "end": "2183880"
  },
  {
    "text": "anybody uses these kind of uh features because it's very hard if you're training if you're infering is really",
    "start": "2183880",
    "end": "2189400"
  },
  {
    "text": "hard if you don't have such kind of um uh such kind of facilities on you and",
    "start": "2189400",
    "end": "2195920"
  },
  {
    "text": "definitely the workload density with KQ uh I won't get you U I won't get into the Q Q is an amazing open source um uh",
    "start": "2195920",
    "end": "2205319"
  },
  {
    "text": "construct I think I would really recommend and it's very easy to use and uh if you go to any Cloud providing",
    "start": "2205319",
    "end": "2210960"
  },
  {
    "text": "including GK you will find it uh you'll have lot of examples of how to use Q to",
    "start": "2210960",
    "end": "2216160"
  },
  {
    "text": "run jobs for INF and servicing using tpus and GPU it's really helpful it's basically you're providing um a",
    "start": "2216160",
    "end": "2224240"
  },
  {
    "text": "prioritized way of saying what you want to run when do you want to run Etc and then we add Dynamic workload Schuler",
    "start": "2224240",
    "end": "2231560"
  },
  {
    "text": "which helps you to create a calendar to say when you should start it um has some Flex start mode it kind of tells you",
    "start": "2231560",
    "end": "2238160"
  },
  {
    "text": "what kind of request you want only when such kind of resources are available it runs and runs a job and gets back to you",
    "start": "2238160",
    "end": "2244280"
  },
  {
    "text": "so it does all of those things automatically and takes away all the headache that you'll get when you're like oh I don't find this resource what",
    "start": "2244280",
    "end": "2250400"
  },
  {
    "text": "am I supposed to do you know and then you can't keep waiting for resources to come you can submit it to q and you can",
    "start": "2250400",
    "end": "2256160"
  },
  {
    "text": "sub to Dynamic workload scheduler which will help you with all of this that's it I think I loaded a lot of information to",
    "start": "2256160",
    "end": "2262760"
  },
  {
    "text": "you guys and I'll stop here and raise for any question I didn't even know what I did with the",
    "start": "2262760",
    "end": "2269200"
  },
  {
    "text": "time okay I get almost a for time it's 5:32 3 minutes left for questions",
    "start": "2269200",
    "end": "2277839"
  },
  {
    "text": "I have a question",
    "start": "2277839",
    "end": "2280680"
  },
  {
    "text": "sure if you want so vertx AI should take away that complexity for you right it kind of does",
    "start": "2286480",
    "end": "2294079"
  },
  {
    "text": "all of that for you underneath so I don't think so you have to use Ray but you can use it on gke and we have a r",
    "start": "2294079",
    "end": "2300119"
  },
  {
    "text": "operator if you want to run and um manage all of this yourself yeah",
    "start": "2300119",
    "end": "2308040"
  },
  {
    "text": "yeah I think I can find a document and send it right yeah because even I haven't tried",
    "start": "2309800",
    "end": "2315760"
  },
  {
    "text": "it any other question we use",
    "start": "2315760",
    "end": "2323000"
  },
  {
    "text": "for function yeah it's basically you can use task and the task can just be a function",
    "start": "2332880",
    "end": "2339040"
  },
  {
    "text": "right and it just you inut Ray and then put uh um there's actually a a line that",
    "start": "2339040",
    "end": "2344480"
  },
  {
    "text": "you have to say for task what it is I just forget it's r. import or something um and then if you use that it tells",
    "start": "2344480",
    "end": "2350640"
  },
  {
    "text": "it's a task and you run anything that you want within it and you can use all of these framework data processing Frameworks it doesn't have to be the",
    "start": "2350640",
    "end": "2357480"
  },
  {
    "text": "just Ray libraries Ray is basically orchestrator yeah Ray is basically distributed computing forl that's what",
    "start": "2357480",
    "end": "2365160"
  },
  {
    "text": "you can take something and then run it across multiple compute at the same time so that you can increase efficiency",
    "start": "2365160",
    "end": "2371359"
  },
  {
    "text": "that's the overall idea any other",
    "start": "2371359",
    "end": "2375960"
  },
  {
    "text": "question okay I think the question is in the queue um it's if if you already have",
    "start": "2390400",
    "end": "2395520"
  },
  {
    "text": "running something it started and you gave some some kind of configuration and then uh another higher level is",
    "start": "2395520",
    "end": "2401160"
  },
  {
    "text": "available they should change to the higher level I don't think so I think it's already in the running State once",
    "start": "2401160",
    "end": "2406880"
  },
  {
    "text": "it's in the queue then it takes those things it'll just look for what compute you have provided that you want it to",
    "start": "2406880",
    "end": "2412200"
  },
  {
    "text": "run on then it'll match for that compute but then um if it's already running I don't think so it disrupts and runs on a",
    "start": "2412200",
    "end": "2419319"
  },
  {
    "text": "different clue any Google um any you want to add I don't I I don't think so it'll stop any application running at",
    "start": "2419319",
    "end": "2425200"
  },
  {
    "text": "this point and then move it to the next level if it's available it should not",
    "start": "2425200",
    "end": "2431319"
  },
  {
    "text": "us benchmarking with what bench efficiency because cues for jobs",
    "start": "2431720",
    "end": "2439520"
  },
  {
    "text": "at the end of them and benchmarking um in what stage of benchmarking are you I'm at the",
    "start": "2439520",
    "end": "2445599"
  },
  {
    "text": "inference level at the inference level inference you want to run it as a service and available so you can um I",
    "start": "2445599",
    "end": "2453480"
  },
  {
    "text": "think there's a lot of um this is a open source kubernetes but if if you go to",
    "start": "2453480",
    "end": "2459079"
  },
  {
    "text": "gke there's a lot of ways to uh make sure to run across multiple clusters",
    "start": "2459079",
    "end": "2464280"
  },
  {
    "text": "your models and then make sure there load latency is slow and uh you provide",
    "start": "2464280",
    "end": "2469720"
  },
  {
    "text": "the queue is mostly for jobs which you do not want to use for your inferences but only if for example you just want to",
    "start": "2469720",
    "end": "2475440"
  },
  {
    "text": "run few requests and run back as a batch inference yes yeah if you want to do batch inferences yeah any other",
    "start": "2475440",
    "end": "2484680"
  },
  {
    "text": "questions awesome did you reach the time thank you everyone take care have a good",
    "start": "2484680",
    "end": "2490560"
  },
  {
    "text": "evening we'll see you around have fun bye-bye",
    "start": "2490560",
    "end": "2496000"
  }
]
[
  {
    "text": "so hi uh my name is Philip I work for",
    "start": "280",
    "end": "2600"
  },
  {
    "text": "honeycomb um I'm on the product team uh",
    "start": "2600",
    "end": "5839"
  },
  {
    "text": "I um talking about a fun topic uh how",
    "start": "5839",
    "end": "9200"
  },
  {
    "text": "open Telemetry helps generative AI I'm",
    "start": "9200",
    "end": "11200"
  },
  {
    "text": "not going to talk about open Telemetry",
    "start": "11200",
    "end": "12599"
  },
  {
    "text": "very much though um and that's because",
    "start": "12599",
    "end": "14519"
  },
  {
    "text": "open Telemetry is like one of the least",
    "start": "14519",
    "end": "15839"
  },
  {
    "text": "interesting parts of all of this which I",
    "start": "15839",
    "end": "17320"
  },
  {
    "text": "think is kind of like a goal of the",
    "start": "17320",
    "end": "19240"
  },
  {
    "text": "project if you will just kind of works",
    "start": "19240",
    "end": "21039"
  },
  {
    "text": "and is really helpful for people um so",
    "start": "21039",
    "end": "23880"
  },
  {
    "text": "that's what this is going to be about uh",
    "start": "23880",
    "end": "25519"
  },
  {
    "text": "this is based on uh last year uh early",
    "start": "25519",
    "end": "28880"
  },
  {
    "text": "last year um I did the old around and",
    "start": "28880",
    "end": "31560"
  },
  {
    "text": "find out thing um where in the course of",
    "start": "31560",
    "end": "34079"
  },
  {
    "text": "around I found out a whole lot about how",
    "start": "34079",
    "end": "36160"
  },
  {
    "text": "you can make AI better when you uh build",
    "start": "36160",
    "end": "38800"
  },
  {
    "text": "a feature and then release it to all of",
    "start": "38800",
    "end": "40239"
  },
  {
    "text": "your users uh and um find out what they",
    "start": "40239",
    "end": "43440"
  },
  {
    "text": "actually want to do with it uh once it's",
    "start": "43440",
    "end": "45640"
  },
  {
    "text": "live um and it turns out having good",
    "start": "45640",
    "end": "48760"
  },
  {
    "text": "observability for things like what are",
    "start": "48760",
    "end": "51239"
  },
  {
    "text": "people putting into this input box what",
    "start": "51239",
    "end": "53480"
  },
  {
    "text": "is the output look like what do we do",
    "start": "53480",
    "end": "56120"
  },
  {
    "text": "about that um it's kind of a a good good",
    "start": "56120",
    "end": "59359"
  },
  {
    "text": "use for obser ability so let's get into",
    "start": "59359",
    "end": "61079"
  },
  {
    "text": "it um so a is all the hype AI is all the",
    "start": "61079",
    "end": "65320"
  },
  {
    "text": "hype these days um this talk is not",
    "start": "65320",
    "end": "67880"
  },
  {
    "text": "going to be focused on infrastructural",
    "start": "67880",
    "end": "69200"
  },
  {
    "text": "level stuff so this is not about like",
    "start": "69200",
    "end": "70920"
  },
  {
    "text": "monitoring your gpus um or anything like",
    "start": "70920",
    "end": "73960"
  },
  {
    "text": "that if you're like working in the cloud",
    "start": "73960",
    "end": "76520"
  },
  {
    "text": "offering gen Services you might care",
    "start": "76520",
    "end": "78320"
  },
  {
    "text": "more about that you might care more",
    "start": "78320",
    "end": "79600"
  },
  {
    "text": "about how you do inference um monitoring",
    "start": "79600",
    "end": "82479"
  },
  {
    "text": "all of those are like completely other",
    "start": "82479",
    "end": "83960"
  },
  {
    "text": "talks that we could give uh this is for",
    "start": "83960",
    "end": "86600"
  },
  {
    "text": "the majority of people out there who are",
    "start": "86600",
    "end": "88280"
  },
  {
    "text": "building applications that use some",
    "start": "88280",
    "end": "91079"
  },
  {
    "text": "generative AI model like",
    "start": "91079",
    "end": "93399"
  },
  {
    "text": "gp4 um behind an API and they want to",
    "start": "93399",
    "end": "97479"
  },
  {
    "text": "just make it good because what's really",
    "start": "97479",
    "end": "99840"
  },
  {
    "text": "cool is like it's kind of got into this",
    "start": "99840",
    "end": "102399"
  },
  {
    "text": "world where like quite literally the",
    "start": "102399",
    "end": "103640"
  },
  {
    "text": "world's most powerful machine learning",
    "start": "103640",
    "end": "105280"
  },
  {
    "text": "models are broadly available for anyone",
    "start": "105280",
    "end": "107200"
  },
  {
    "text": "to use at a relatively cheap price and",
    "start": "107200",
    "end": "110079"
  },
  {
    "text": "getting a lot faster and a lot cheaper",
    "start": "110079",
    "end": "111640"
  },
  {
    "text": "by the like month basically um so like",
    "start": "111640",
    "end": "114719"
  },
  {
    "text": "this bottleneck where like you could",
    "start": "114719",
    "end": "116439"
  },
  {
    "text": "maybe build something really cool using",
    "start": "116439",
    "end": "118560"
  },
  {
    "text": "AI um was like stuck in the likes of",
    "start": "118560",
    "end": "122360"
  },
  {
    "text": "Amazon and Google and meta and Microsoft",
    "start": "122360",
    "end": "125680"
  },
  {
    "text": "and all that like you just couldn't do",
    "start": "125680",
    "end": "127039"
  },
  {
    "text": "that as a normal developer now that's",
    "start": "127039",
    "end": "129319"
  },
  {
    "text": "not the case anymore but that doesn't",
    "start": "129319",
    "end": "131239"
  },
  {
    "text": "mean that like everything is all magic",
    "start": "131239",
    "end": "132879"
  },
  {
    "text": "and sugar and all of that um there's",
    "start": "132879",
    "end": "136840"
  },
  {
    "text": "there's a lot of problems that people",
    "start": "136840",
    "end": "138280"
  },
  {
    "text": "have um when it comes to managing costs",
    "start": "138280",
    "end": "141440"
  },
  {
    "text": "when it comes to understanding how these",
    "start": "141440",
    "end": "142680"
  },
  {
    "text": "models even perform when it comes to",
    "start": "142680",
    "end": "144440"
  },
  {
    "text": "figuring out what the right kind of",
    "start": "144440",
    "end": "145680"
  },
  {
    "text": "application you're going to build is um",
    "start": "145680",
    "end": "148280"
  },
  {
    "text": "there's like killer apps already like",
    "start": "148280",
    "end": "150160"
  },
  {
    "text": "chat gbt and G co-pilot but like chances",
    "start": "150160",
    "end": "152720"
  },
  {
    "text": "are if you're going to create like a",
    "start": "152720",
    "end": "154720"
  },
  {
    "text": "chat rapper it's not going to do very",
    "start": "154720",
    "end": "156360"
  },
  {
    "text": "well if you're going to try to create",
    "start": "156360",
    "end": "158440"
  },
  {
    "text": "like a little code completion thing um",
    "start": "158440",
    "end": "160519"
  },
  {
    "text": "Good Luck competing against GitHub uh",
    "start": "160519",
    "end": "162480"
  },
  {
    "text": "they've got like a five-year head start",
    "start": "162480",
    "end": "164040"
  },
  {
    "text": "on you so um you know it's great but",
    "start": "164040",
    "end": "167239"
  },
  {
    "text": "like there's a lot of opportunities out",
    "start": "167239",
    "end": "168640"
  },
  {
    "text": "there that are just outside of chat apps",
    "start": "168640",
    "end": "170680"
  },
  {
    "text": "and outside of little tab completion",
    "start": "170680",
    "end": "172920"
  },
  {
    "text": "code helpers um but I think like it's",
    "start": "172920",
    "end": "175760"
  },
  {
    "text": "safe to say that this sort of broke the",
    "start": "175760",
    "end": "177080"
  },
  {
    "text": "tech world uh and it's still a little",
    "start": "177080",
    "end": "178959"
  },
  {
    "text": "bit broken and we're probably due for",
    "start": "178959",
    "end": "180760"
  },
  {
    "text": "one of those like Gartner hype cycle",
    "start": "180760",
    "end": "182720"
  },
  {
    "text": "troughs of disillusionment pretty soon",
    "start": "182720",
    "end": "185200"
  },
  {
    "text": "um but like the the the like it's",
    "start": "185200",
    "end": "187000"
  },
  {
    "text": "fundamentally changed now like we have",
    "start": "187000",
    "end": "188599"
  },
  {
    "text": "fundamental Computing capabilities that",
    "start": "188599",
    "end": "190280"
  },
  {
    "text": "we just didn't have anymore um so what",
    "start": "190280",
    "end": "194959"
  },
  {
    "text": "does that mean well they are powerful",
    "start": "194959",
    "end": "197319"
  },
  {
    "text": "but inscrutable black boxes um It Is by",
    "start": "197319",
    "end": "200760"
  },
  {
    "text": "design that language models that",
    "start": "200760",
    "end": "202720"
  },
  {
    "text": "generative AI uh in general is either",
    "start": "202720",
    "end": "206080"
  },
  {
    "text": "non-deterministic by Design or even if",
    "start": "206080",
    "end": "207920"
  },
  {
    "text": "you turn down the temperature conf which",
    "start": "207920",
    "end": "210120"
  },
  {
    "text": "is a value that you can that you can use",
    "start": "210120",
    "end": "212159"
  },
  {
    "text": "um down to zero uh depending on the",
    "start": "212159",
    "end": "213959"
  },
  {
    "text": "model you're using it's still",
    "start": "213959",
    "end": "215280"
  },
  {
    "text": "non-deterministic and like there's a lot",
    "start": "215280",
    "end": "216959"
  },
  {
    "text": "of variants there where some smaller",
    "start": "216959",
    "end": "218200"
  },
  {
    "text": "models actually are deterministic and",
    "start": "218200",
    "end": "219680"
  },
  {
    "text": "all of that but like the point is if you",
    "start": "219680",
    "end": "221360"
  },
  {
    "text": "want to generate so-called creative",
    "start": "221360",
    "end": "223360"
  },
  {
    "text": "responses to Things based off of inputs",
    "start": "223360",
    "end": "225159"
  },
  {
    "text": "that come in you don't want something",
    "start": "225159",
    "end": "227799"
  },
  {
    "text": "that produces boring outputs usually",
    "start": "227799",
    "end": "230480"
  },
  {
    "text": "like that you just don't use AI if",
    "start": "230480",
    "end": "232000"
  },
  {
    "text": "that's the case like you want something",
    "start": "232000",
    "end": "233239"
  },
  {
    "text": "that produces really interesting outputs",
    "start": "233239",
    "end": "235159"
  },
  {
    "text": "that are interesting but like now your",
    "start": "235159",
    "end": "238560"
  },
  {
    "text": "users kind of do expect some degree of",
    "start": "238560",
    "end": "240879"
  },
  {
    "text": "reliability and you have an inscrutable",
    "start": "240879",
    "end": "242840"
  },
  {
    "text": "black box that like you try to prompt it",
    "start": "242840",
    "end": "245360"
  },
  {
    "text": "and like good luck trying to understand",
    "start": "245360",
    "end": "246879"
  },
  {
    "text": "what the best prompting technique is",
    "start": "246879",
    "end": "248239"
  },
  {
    "text": "there's like 20 or 30 of them that are",
    "start": "248239",
    "end": "250079"
  },
  {
    "text": "probably helpful and some are going to",
    "start": "250079",
    "end": "252040"
  },
  {
    "text": "regress certain things and make other",
    "start": "252040",
    "end": "253519"
  },
  {
    "text": "things better and like you're not going",
    "start": "253519",
    "end": "255000"
  },
  {
    "text": "to know UPF front which one is the right",
    "start": "255000",
    "end": "256239"
  },
  {
    "text": "one um you're going to have totally",
    "start": "256239",
    "end": "259199"
  },
  {
    "text": "different behavior in production",
    "start": "259199",
    "end": "260239"
  },
  {
    "text": "compared to development because your",
    "start": "260239",
    "end": "261639"
  },
  {
    "text": "users are going to do things you could",
    "start": "261639",
    "end": "263080"
  },
  {
    "text": "never possibly expect and you're going",
    "start": "263080",
    "end": "265800"
  },
  {
    "text": "to have to learn the hard way that like",
    "start": "265800",
    "end": "267240"
  },
  {
    "text": "you got to do something different you",
    "start": "267240",
    "end": "268520"
  },
  {
    "text": "can't just like write some unit test and",
    "start": "268520",
    "end": "270000"
  },
  {
    "text": "hope it gets better that's not going to",
    "start": "270000",
    "end": "271600"
  },
  {
    "text": "happen if you just try to say well it",
    "start": "271600",
    "end": "273320"
  },
  {
    "text": "looks good on my machine let's throw it",
    "start": "273320",
    "end": "274720"
  },
  {
    "text": "in production like it's going to it's",
    "start": "274720",
    "end": "276919"
  },
  {
    "text": "going to produce garbage it's not going",
    "start": "276919",
    "end": "278080"
  },
  {
    "text": "to be any good and you're not going to",
    "start": "278080",
    "end": "279039"
  },
  {
    "text": "be able to keep that feature in",
    "start": "279039",
    "end": "280919"
  },
  {
    "text": "production so um let's stare at a",
    "start": "280919",
    "end": "283199"
  },
  {
    "text": "diagram for a little bit this is",
    "start": "283199",
    "end": "284600"
  },
  {
    "text": "basically every geni app today uh it's",
    "start": "284600",
    "end": "287320"
  },
  {
    "text": "massively oversimplified of course um",
    "start": "287320",
    "end": "290320"
  },
  {
    "text": "but outside of like the super boring",
    "start": "290320",
    "end": "292639"
  },
  {
    "text": "useless chat apps that people right um",
    "start": "292639",
    "end": "294919"
  },
  {
    "text": "when they're not named open AI um",
    "start": "294919",
    "end": "297919"
  },
  {
    "text": "there's some form of input generally",
    "start": "297919",
    "end": "299720"
  },
  {
    "text": "producing some kind of output it's",
    "start": "299720",
    "end": "301280"
  },
  {
    "text": "almost always some kind of Json and the",
    "start": "301280",
    "end": "303440"
  },
  {
    "text": "things that happen in between are really",
    "start": "303440",
    "end": "304680"
  },
  {
    "text": "interesting there's one or more language",
    "start": "304680",
    "end": "306560"
  },
  {
    "text": "model calls it's usually only one",
    "start": "306560",
    "end": "308479"
  },
  {
    "text": "because that's usually all that you need",
    "start": "308479",
    "end": "309960"
  },
  {
    "text": "but there's this whole stack of stuff",
    "start": "309960",
    "end": "311919"
  },
  {
    "text": "beforehand um called search Service uh I",
    "start": "311919",
    "end": "315199"
  },
  {
    "text": "pulled this this diagram out there where",
    "start": "315199",
    "end": "316680"
  },
  {
    "text": "it talks about Vector search a lot of",
    "start": "316680",
    "end": "318440"
  },
  {
    "text": "the AI world is sort of relearning that",
    "start": "318440",
    "end": "320199"
  },
  {
    "text": "Vector search is not the only kind of",
    "start": "320199",
    "end": "321639"
  },
  {
    "text": "search that you can do that's really",
    "start": "321639",
    "end": "322720"
  },
  {
    "text": "helpful the goal is that you want to",
    "start": "322720",
    "end": "325120"
  },
  {
    "text": "take user input gather a whole bunch of",
    "start": "325120",
    "end": "327479"
  },
  {
    "text": "contextual information about like what",
    "start": "327479",
    "end": "329400"
  },
  {
    "text": "could be helpful to produce an answer to",
    "start": "329400",
    "end": "331440"
  },
  {
    "text": "the question that they have or the",
    "start": "331440",
    "end": "333199"
  },
  {
    "text": "output that you're trying to achieve and",
    "start": "333199",
    "end": "335600"
  },
  {
    "text": "gather as much of that as possible and",
    "start": "335600",
    "end": "337120"
  },
  {
    "text": "produce um uh a a context package if you",
    "start": "337120",
    "end": "339960"
  },
  {
    "text": "will it's uh it's called retrieval",
    "start": "339960",
    "end": "342000"
  },
  {
    "text": "augmented generation or rag it was this",
    "start": "342000",
    "end": "344120"
  },
  {
    "text": "really cool behavior that some meta",
    "start": "344120",
    "end": "345680"
  },
  {
    "text": "researchers found in 2020 where they",
    "start": "345680",
    "end": "348000"
  },
  {
    "text": "figured out that language models if they",
    "start": "348000",
    "end": "350039"
  },
  {
    "text": "are not trained on a certain kind of",
    "start": "350039",
    "end": "351840"
  },
  {
    "text": "data but you feed in that data on a",
    "start": "351840",
    "end": "354000"
  },
  {
    "text": "request to it they can kind of act like",
    "start": "354000",
    "end": "356000"
  },
  {
    "text": "they were trained on that data and",
    "start": "356000",
    "end": "357600"
  },
  {
    "text": "there's a little bit of wiggle room",
    "start": "357600",
    "end": "358680"
  },
  {
    "text": "there but like it's really cool because",
    "start": "358680",
    "end": "360319"
  },
  {
    "text": "you don't need to train your own",
    "start": "360319",
    "end": "362240"
  },
  {
    "text": "language model you can use an",
    "start": "362240",
    "end": "363960"
  },
  {
    "text": "off-the-shelf language model and pass in",
    "start": "363960",
    "end": "365440"
  },
  {
    "text": "a whole bunch of stuff and produce",
    "start": "365440",
    "end": "366479"
  },
  {
    "text": "useful things and so this is what almost",
    "start": "366479",
    "end": "368840"
  },
  {
    "text": "everybody who is building AI apps today",
    "start": "368840",
    "end": "370560"
  },
  {
    "text": "is building some form of this diagram",
    "start": "370560",
    "end": "374599"
  },
  {
    "text": "okay so there's really two key questions",
    "start": "374599",
    "end": "378440"
  },
  {
    "text": "that you need to answer when you're",
    "start": "378440",
    "end": "379599"
  },
  {
    "text": "building this stuff and you want to make",
    "start": "379599",
    "end": "380759"
  },
  {
    "text": "it better um notice I don't have the",
    "start": "380759",
    "end": "383280"
  },
  {
    "text": "words latency error rate CPU statistic",
    "start": "383280",
    "end": "386560"
  },
  {
    "text": "GPU blah blah blah whatever uh it's is",
    "start": "386560",
    "end": "389120"
  },
  {
    "text": "the data right like is the right data",
    "start": "389120",
    "end": "390919"
  },
  {
    "text": "being fed to the model in the first",
    "start": "390919",
    "end": "392319"
  },
  {
    "text": "place like if I'm gathering context for",
    "start": "392319",
    "end": "394960"
  },
  {
    "text": "somebody's user input am I actually",
    "start": "394960",
    "end": "396400"
  },
  {
    "text": "Gathering the right context uh I talked",
    "start": "396400",
    "end": "398759"
  },
  {
    "text": "to someone last year who has a version",
    "start": "398759",
    "end": "401400"
  },
  {
    "text": "of that diagram where that search",
    "start": "401400",
    "end": "402919"
  },
  {
    "text": "service is actually six different",
    "start": "402919",
    "end": "404400"
  },
  {
    "text": "databases and one of the questions they",
    "start": "404400",
    "end": "406280"
  },
  {
    "text": "have is okay based off of the user's",
    "start": "406280",
    "end": "407960"
  },
  {
    "text": "input are we calling the right database",
    "start": "407960",
    "end": "410280"
  },
  {
    "text": "or not um how many should we call how do",
    "start": "410280",
    "end": "413000"
  },
  {
    "text": "we merge those results together what",
    "start": "413000",
    "end": "415039"
  },
  {
    "text": "sorts of search um systems do we do we",
    "start": "415039",
    "end": "417680"
  },
  {
    "text": "actually have and like can I ass",
    "start": "417680",
    "end": "419560"
  },
  {
    "text": "statically show that on like classes of",
    "start": "419560",
    "end": "422919"
  },
  {
    "text": "inputs I can produce context packages if",
    "start": "422919",
    "end": "426680"
  },
  {
    "text": "you will that are actually right for",
    "start": "426680",
    "end": "428800"
  },
  {
    "text": "that kind of input how do I like measure",
    "start": "428800",
    "end": "431319"
  },
  {
    "text": "that and see if it's continuing to",
    "start": "431319",
    "end": "433720"
  },
  {
    "text": "improve over time and like not",
    "start": "433720",
    "end": "435560"
  },
  {
    "text": "progressing over time similarly on the",
    "start": "435560",
    "end": "438280"
  },
  {
    "text": "model side how do you know that it's",
    "start": "438280",
    "end": "439720"
  },
  {
    "text": "behaving correctly when you actually do",
    "start": "439720",
    "end": "441319"
  },
  {
    "text": "have the right inputs right so like",
    "start": "441319",
    "end": "444560"
  },
  {
    "text": "assume that you have retrieval which is",
    "start": "444560",
    "end": "446160"
  },
  {
    "text": "a really hard problem in a lot of cases",
    "start": "446160",
    "end": "448400"
  },
  {
    "text": "solved is it actually still doing the",
    "start": "448400",
    "end": "450599"
  },
  {
    "text": "right thing like are you using the right",
    "start": "450599",
    "end": "451800"
  },
  {
    "text": "prompting techniques are you at a point",
    "start": "451800",
    "end": "453800"
  },
  {
    "text": "where you need to actually fine-tune a",
    "start": "453800",
    "end": "455319"
  },
  {
    "text": "language model are you at a point where",
    "start": "455319",
    "end": "457199"
  },
  {
    "text": "God help you you have to train your own",
    "start": "457199",
    "end": "458639"
  },
  {
    "text": "language model I certainly hope that's",
    "start": "458639",
    "end": "460319"
  },
  {
    "text": "not the case and similarly can you",
    "start": "460319",
    "end": "462080"
  },
  {
    "text": "systematically show that you're making",
    "start": "462080",
    "end": "463759"
  },
  {
    "text": "progress when you go to production and",
    "start": "463759",
    "end": "466120"
  },
  {
    "text": "people are inputting all kinds of weird",
    "start": "466120",
    "end": "467840"
  },
  {
    "text": "stuff and there's like weird outputs and",
    "start": "467840",
    "end": "470360"
  },
  {
    "text": "you start thinking that you're fixing",
    "start": "470360",
    "end": "471720"
  },
  {
    "text": "those outputs are you a actually fixing",
    "start": "471720",
    "end": "474240"
  },
  {
    "text": "those outputs and B are you not",
    "start": "474240",
    "end": "476360"
  },
  {
    "text": "regressing the stuff that was already",
    "start": "476360",
    "end": "477599"
  },
  {
    "text": "working in the first place these are",
    "start": "477599",
    "end": "479759"
  },
  {
    "text": "like these are really important things",
    "start": "479759",
    "end": "482440"
  },
  {
    "text": "um there's some other stuff that doesn't",
    "start": "482440",
    "end": "483919"
  },
  {
    "text": "really matter as much but it still kind",
    "start": "483919",
    "end": "485360"
  },
  {
    "text": "of matters around like latency and error",
    "start": "485360",
    "end": "486960"
  },
  {
    "text": "rates um I'm labeling them this way",
    "start": "486960",
    "end": "489680"
  },
  {
    "text": "because to be frank they're usually",
    "start": "489680",
    "end": "491599"
  },
  {
    "text": "pretty easy to solve in part because",
    "start": "491599",
    "end": "493639"
  },
  {
    "text": "users don't expect language models to be",
    "start": "493639",
    "end": "495520"
  },
  {
    "text": "instantaneous and so if it takes like",
    "start": "495520",
    "end": "497319"
  },
  {
    "text": "one or two seconds to produce a response",
    "start": "497319",
    "end": "498960"
  },
  {
    "text": "it's usually fine uh these things are",
    "start": "498960",
    "end": "501039"
  },
  {
    "text": "getting hugely better over time uh when",
    "start": "501039",
    "end": "504120"
  },
  {
    "text": "we released our our application early",
    "start": "504120",
    "end": "506360"
  },
  {
    "text": "last year um average response times were",
    "start": "506360",
    "end": "508840"
  },
  {
    "text": "like 5 Seconds and now it's down to like",
    "start": "508840",
    "end": "510800"
  },
  {
    "text": "1.5 seconds uh through like no no action",
    "start": "510800",
    "end": "514360"
  },
  {
    "text": "of our own um cost is also something",
    "start": "514360",
    "end": "518440"
  },
  {
    "text": "that like I mean in this economy",
    "start": "518440",
    "end": "520039"
  },
  {
    "text": "everybody's worried about cost but like",
    "start": "520039",
    "end": "522279"
  },
  {
    "text": "let's be real like most organizations",
    "start": "522279",
    "end": "524519"
  },
  {
    "text": "have budget for AI and they're willing",
    "start": "524519",
    "end": "526000"
  },
  {
    "text": "to spend it uh and you really don't need",
    "start": "526000",
    "end": "528240"
  },
  {
    "text": "the most powerful models to achieve most",
    "start": "528240",
    "end": "529839"
  },
  {
    "text": "outcomes that you're looking for uh",
    "start": "529839",
    "end": "531560"
  },
  {
    "text": "we've been live in production with gbd",
    "start": "531560",
    "end": "533160"
  },
  {
    "text": "3.5 since May of last year and have had",
    "start": "533160",
    "end": "535720"
  },
  {
    "text": "no need to change it uh if we can do it",
    "start": "535720",
    "end": "538680"
  },
  {
    "text": "you probably can do um and",
    "start": "538680",
    "end": "542240"
  },
  {
    "text": "hallucinations like C previous slide",
    "start": "542240",
    "end": "544880"
  },
  {
    "text": "people talk about oh I don't want the AI",
    "start": "544880",
    "end": "546519"
  },
  {
    "text": "app to hallucinate but like it's not",
    "start": "546519",
    "end": "548519"
  },
  {
    "text": "about hallucinations it's am I feeding",
    "start": "548519",
    "end": "550959"
  },
  {
    "text": "the right information to the model and",
    "start": "550959",
    "end": "553040"
  },
  {
    "text": "am I producing the right output based",
    "start": "553040",
    "end": "554880"
  },
  {
    "text": "off of that right information that I'm",
    "start": "554880",
    "end": "556360"
  },
  {
    "text": "feeding in the first place and can I",
    "start": "556360",
    "end": "558279"
  },
  {
    "text": "actually systematically show that over",
    "start": "558279",
    "end": "559920"
  },
  {
    "text": "time this is just the core of making",
    "start": "559920",
    "end": "562040"
  },
  {
    "text": "these apps more",
    "start": "562040",
    "end": "563360"
  },
  {
    "text": "reliable and so like a way that that",
    "start": "563360",
    "end": "565600"
  },
  {
    "text": "might look is you could imagine you have",
    "start": "565600",
    "end": "568200"
  },
  {
    "text": "a whole bunch of info like you want to",
    "start": "568200",
    "end": "569600"
  },
  {
    "text": "log like a full prompt that you build up",
    "start": "569600",
    "end": "571480"
  },
  {
    "text": "programmatically maybe you have a whole",
    "start": "571480",
    "end": "573399"
  },
  {
    "text": "bunch of steps that lead up to that um",
    "start": "573399",
    "end": "575600"
  },
  {
    "text": "in the the application that we built",
    "start": "575600",
    "end": "577240"
  },
  {
    "text": "last year there's actually on the order",
    "start": "577240",
    "end": "579519"
  },
  {
    "text": "of about 38 distinct operations that",
    "start": "579519",
    "end": "581440"
  },
  {
    "text": "happen Upstream of a language model call",
    "start": "581440",
    "end": "583640"
  },
  {
    "text": "so like logging all of that stuff and",
    "start": "583640",
    "end": "586560"
  },
  {
    "text": "tracking that understanding your latency",
    "start": "586560",
    "end": "588880"
  },
  {
    "text": "like your status code what your error",
    "start": "588880",
    "end": "590279"
  },
  {
    "text": "was like your usage if you're doing any",
    "start": "590279",
    "end": "592079"
  },
  {
    "text": "post-processing on the Json like what",
    "start": "592079",
    "end": "593880"
  },
  {
    "text": "postprocessing steps you're actually",
    "start": "593880",
    "end": "595320"
  },
  {
    "text": "doing your diagram kind of looks like",
    "start": "595320",
    "end": "597040"
  },
  {
    "text": "this um and uh it just involves",
    "start": "597040",
    "end": "600519"
  },
  {
    "text": "Gathering user input contextual",
    "start": "600519",
    "end": "602959"
  },
  {
    "text": "information request to a service",
    "start": "602959",
    "end": "604800"
  },
  {
    "text": "sometimes you may do multiple searches",
    "start": "604800",
    "end": "606880"
  },
  {
    "text": "sometimes you may have to rerank search",
    "start": "606880",
    "end": "608440"
  },
  {
    "text": "results based off of like different",
    "start": "608440",
    "end": "611000"
  },
  {
    "text": "techniques that could work better and",
    "start": "611000",
    "end": "612640"
  },
  {
    "text": "certain C like certain inputs May lend",
    "start": "612640",
    "end": "614600"
  },
  {
    "text": "themselves better to a different like",
    "start": "614600",
    "end": "616000"
  },
  {
    "text": "search um system like these are kind of",
    "start": "616000",
    "end": "618519"
  },
  {
    "text": "complicated things um and like you",
    "start": "618519",
    "end": "620800"
  },
  {
    "text": "eventually get to the point where you're",
    "start": "620800",
    "end": "621839"
  },
  {
    "text": "calling an llm and you want to have like",
    "start": "621839",
    "end": "623560"
  },
  {
    "text": "okay what was the input what was the",
    "start": "623560",
    "end": "624480"
  },
  {
    "text": "output but like there's this whole",
    "start": "624480",
    "end": "625800"
  },
  {
    "text": "system that you're trying to gather",
    "start": "625800",
    "end": "627560"
  },
  {
    "text": "information about and post processing",
    "start": "627560",
    "end": "629959"
  },
  {
    "text": "steps can often be a rather large um set",
    "start": "629959",
    "end": "632920"
  },
  {
    "text": "of things like um speaking again from",
    "start": "632920",
    "end": "635160"
  },
  {
    "text": "from production we have about two dozen",
    "start": "635160",
    "end": "636880"
  },
  {
    "text": "or so possible post-processing steps",
    "start": "636880",
    "end": "638880"
  },
  {
    "text": "that can occur where a language model",
    "start": "638880",
    "end": "640760"
  },
  {
    "text": "gets something mostly right and that",
    "start": "640760",
    "end": "642800"
  },
  {
    "text": "mostly right is actually something that",
    "start": "642800",
    "end": "644320"
  },
  {
    "text": "we can deterministically check and",
    "start": "644320",
    "end": "646320"
  },
  {
    "text": "either insert or remove data from like",
    "start": "646320",
    "end": "648800"
  },
  {
    "text": "the response that we get like this is",
    "start": "648800",
    "end": "651279"
  },
  {
    "text": "when you're in production you're trying",
    "start": "651279",
    "end": "652399"
  },
  {
    "text": "to make stuff better for your users you",
    "start": "652399",
    "end": "653760"
  },
  {
    "text": "find out all of this fun stuff where you",
    "start": "653760",
    "end": "655320"
  },
  {
    "text": "can make this stuff actually work um so",
    "start": "655320",
    "end": "659320"
  },
  {
    "text": "sounds an awful lot like a tracing",
    "start": "659320",
    "end": "660720"
  },
  {
    "text": "problem right I got all this stuff",
    "start": "660720",
    "end": "662839"
  },
  {
    "text": "happening Upstream of this black box",
    "start": "662839",
    "end": "664720"
  },
  {
    "text": "maybe it involves some other black boxes",
    "start": "664720",
    "end": "666320"
  },
  {
    "text": "maybe it involves a whole bunch of calls",
    "start": "666320",
    "end": "667480"
  },
  {
    "text": "to language models maybe it eventually",
    "start": "667480",
    "end": "669079"
  },
  {
    "text": "calls a language model maybe it calls a",
    "start": "669079",
    "end": "670720"
  },
  {
    "text": "language model 20 times maybe it calls",
    "start": "670720",
    "end": "672240"
  },
  {
    "text": "it five times who knows who cares I do",
    "start": "672240",
    "end": "674320"
  },
  {
    "text": "something afterwards like there's all",
    "start": "674320",
    "end": "676639"
  },
  {
    "text": "these words like Services flying around",
    "start": "676639",
    "end": "678519"
  },
  {
    "text": "this is literally just a tracing problem",
    "start": "678519",
    "end": "680079"
  },
  {
    "text": "this is an observability problem so this",
    "start": "680079",
    "end": "681399"
  },
  {
    "text": "is where I talk about open Telemetry um",
    "start": "681399",
    "end": "684480"
  },
  {
    "text": "and as I said the otel part is like one",
    "start": "684480",
    "end": "686680"
  },
  {
    "text": "of the least interesting Parts but I",
    "start": "686680",
    "end": "688200"
  },
  {
    "text": "think that's great because",
    "start": "688200",
    "end": "689959"
  },
  {
    "text": "uh it's actually quite fit for purpose",
    "start": "689959",
    "end": "692079"
  },
  {
    "text": "here um what do you want to capture well",
    "start": "692079",
    "end": "695160"
  },
  {
    "text": "traces yay uh you have like an end to",
    "start": "695160",
    "end": "698279"
  },
  {
    "text": "end flow like a user types in a thing",
    "start": "698279",
    "end": "700639"
  },
  {
    "text": "and they like click a button or they hit",
    "start": "700639",
    "end": "702279"
  },
  {
    "text": "enter like what are all the different",
    "start": "702279",
    "end": "704680"
  },
  {
    "text": "things that are actually hit how do you",
    "start": "704680",
    "end": "706279"
  },
  {
    "text": "capture that well you use traces to like",
    "start": "706279",
    "end": "708480"
  },
  {
    "text": "tie all of that together now it gets a",
    "start": "708480",
    "end": "710480"
  },
  {
    "text": "little bit more um into the Weeds about",
    "start": "710480",
    "end": "712480"
  },
  {
    "text": "if you want to capture a whole bunch of",
    "start": "712480",
    "end": "714040"
  },
  {
    "text": "information in that Trace data or if you",
    "start": "714040",
    "end": "716160"
  },
  {
    "text": "want to capture like for example like a",
    "start": "716160",
    "end": "718360"
  },
  {
    "text": "full prompt text or LM response",
    "start": "718360",
    "end": "720160"
  },
  {
    "text": "depending on its size like that may be",
    "start": "720160",
    "end": "721800"
  },
  {
    "text": "more fit for a log that you then",
    "start": "721800",
    "end": "723399"
  },
  {
    "text": "correlate with the trace it's kind of up",
    "start": "723399",
    "end": "725240"
  },
  {
    "text": "to you it's kind of up to like what you",
    "start": "725240",
    "end": "727639"
  },
  {
    "text": "use for your tracing backend to analyze",
    "start": "727639",
    "end": "729519"
  },
  {
    "text": "this data in the first place um you want",
    "start": "729519",
    "end": "731519"
  },
  {
    "text": "to capture information about",
    "start": "731519",
    "end": "732560"
  },
  {
    "text": "post-processing results um and you can",
    "start": "732560",
    "end": "736399"
  },
  {
    "text": "also aggregate some metrics around",
    "start": "736399",
    "end": "738199"
  },
  {
    "text": "things like latency and cost your",
    "start": "738199",
    "end": "739480"
  },
  {
    "text": "typical error rate just typical boring",
    "start": "739480",
    "end": "741160"
  },
  {
    "text": "stuff you can throw up on a dashboard to",
    "start": "741160",
    "end": "742480"
  },
  {
    "text": "sort of say okay like I know that",
    "start": "742480",
    "end": "743880"
  },
  {
    "text": "generally speaking it's doing all right",
    "start": "743880",
    "end": "746040"
  },
  {
    "text": "um there is literally nothing as far as",
    "start": "746040",
    "end": "748720"
  },
  {
    "text": "I can tell at least in my experience an",
    "start": "748720",
    "end": "750560"
  },
  {
    "text": "open Telemetry that prevents you from",
    "start": "750560",
    "end": "752040"
  },
  {
    "text": "doing this today um they're depending on",
    "start": "752040",
    "end": "755959"
  },
  {
    "text": "the language you're using maybe like for",
    "start": "755959",
    "end": "757399"
  },
  {
    "text": "example go with logs is like not as far",
    "start": "757399",
    "end": "759399"
  },
  {
    "text": "along with Java with logs so if you have",
    "start": "759399",
    "end": "760959"
  },
  {
    "text": "a Java app it's going to be a lot easier",
    "start": "760959",
    "end": "762399"
  },
  {
    "text": "than if you use go or something but like",
    "start": "762399",
    "end": "764040"
  },
  {
    "text": "fundamentally all the places are there",
    "start": "764040",
    "end": "765639"
  },
  {
    "text": "for you to be able to do this um and so",
    "start": "765639",
    "end": "769160"
  },
  {
    "text": "then you get into the fun stuff like",
    "start": "769160",
    "end": "770639"
  },
  {
    "text": "actually analyzing this information um I",
    "start": "770639",
    "end": "774279"
  },
  {
    "text": "have found I I I I put it in quotes I",
    "start": "774279",
    "end": "776639"
  },
  {
    "text": "called it the golden triplet I don't",
    "start": "776639",
    "end": "778120"
  },
  {
    "text": "know if it's actually that um inputs",
    "start": "778120",
    "end": "780000"
  },
  {
    "text": "errors and responses for each request",
    "start": "780000",
    "end": "781959"
  },
  {
    "text": "that a user gives and uh like if I have",
    "start": "781959",
    "end": "784639"
  },
  {
    "text": "an agent or a chain or something like",
    "start": "784639",
    "end": "786399"
  },
  {
    "text": "maybe there's there's like a correlation",
    "start": "786399",
    "end": "788160"
  },
  {
    "text": "ID that I that I tie to like that",
    "start": "788160",
    "end": "789720"
  },
  {
    "text": "particular thing that I'm doing or maybe",
    "start": "789720",
    "end": "791399"
  },
  {
    "text": "it's represented as multiple traces that",
    "start": "791399",
    "end": "792959"
  },
  {
    "text": "are linked together via span links um",
    "start": "792959",
    "end": "795440"
  },
  {
    "text": "again oel fit for purpose for this kind",
    "start": "795440",
    "end": "797120"
  },
  {
    "text": "of stuff um and I just look at patterns",
    "start": "797120",
    "end": "799320"
  },
  {
    "text": "of inputs and outputs like in the",
    "start": "799320",
    "end": "800920"
  },
  {
    "text": "natural language query feature that we",
    "start": "800920",
    "end": "802120"
  },
  {
    "text": "built last year it was somebody that",
    "start": "802120",
    "end": "804160"
  },
  {
    "text": "like for example Honeycombs back end is",
    "start": "804160",
    "end": "806000"
  },
  {
    "text": "like strangely complicated to ask what",
    "start": "806000",
    "end": "808040"
  },
  {
    "text": "an error rate is if you don't have a",
    "start": "808040",
    "end": "809399"
  },
  {
    "text": "metric about that um and people were",
    "start": "809399",
    "end": "812120"
  },
  {
    "text": "asking for what's my error rate and it's",
    "start": "812120",
    "end": "814199"
  },
  {
    "text": "like well crap actually that is like",
    "start": "814199",
    "end": "816279"
  },
  {
    "text": "weirdly unanswerable in certain ways so",
    "start": "816279",
    "end": "818639"
  },
  {
    "text": "like what do we even do um when when",
    "start": "818639",
    "end": "821560"
  },
  {
    "text": "like this is a common thing they want to",
    "start": "821560",
    "end": "822839"
  },
  {
    "text": "do so like we were failing in like a",
    "start": "822839",
    "end": "825160"
  },
  {
    "text": "category like you can imagine all the",
    "start": "825160",
    "end": "826399"
  },
  {
    "text": "different ways that somebody might",
    "start": "826399",
    "end": "827480"
  },
  {
    "text": "phrase what is my error rate um doesn't",
    "start": "827480",
    "end": "830399"
  },
  {
    "text": "matter how they phrased it the category",
    "start": "830399",
    "end": "832480"
  },
  {
    "text": "of input led to a category of output",
    "start": "832480",
    "end": "834839"
  },
  {
    "text": "that just sucked and so we're like great",
    "start": "834839",
    "end": "837279"
  },
  {
    "text": "this is like a class of bug that can now",
    "start": "837279",
    "end": "839560"
  },
  {
    "text": "try to solve for and we can dig into",
    "start": "839560",
    "end": "842120"
  },
  {
    "text": "some of those requests be like okay",
    "start": "842120",
    "end": "843680"
  },
  {
    "text": "these are all the decisions that we made",
    "start": "843680",
    "end": "845560"
  },
  {
    "text": "Upstream with a language model call this",
    "start": "845560",
    "end": "847160"
  },
  {
    "text": "is what the language model actually",
    "start": "847160",
    "end": "848519"
  },
  {
    "text": "produced these are the post-processing",
    "start": "848519",
    "end": "850399"
  },
  {
    "text": "steps where like we accidentally just",
    "start": "850399",
    "end": "852040"
  },
  {
    "text": "removed a bunch of stuff that we",
    "start": "852040",
    "end": "853160"
  },
  {
    "text": "shouldn't have removed and there was",
    "start": "853160",
    "end": "854279"
  },
  {
    "text": "like a bug in that that was unrelated to",
    "start": "854279",
    "end": "856600"
  },
  {
    "text": "the language model it was just us being",
    "start": "856600",
    "end": "857920"
  },
  {
    "text": "dumb um and uh brought it into",
    "start": "857920",
    "end": "861360"
  },
  {
    "text": "development and just said great I have",
    "start": "861360",
    "end": "863440"
  },
  {
    "text": "like concrete what is actually happening",
    "start": "863440",
    "end": "865720"
  },
  {
    "text": "here and I can start then annotating",
    "start": "865720",
    "end": "868240"
  },
  {
    "text": "outputs and saying this is what the",
    "start": "868240",
    "end": "869880"
  },
  {
    "text": "output was this is what the output",
    "start": "869880",
    "end": "871839"
  },
  {
    "text": "should be and that's called an",
    "start": "871839",
    "end": "873720"
  },
  {
    "text": "evaluation if you're in the ml world and",
    "start": "873720",
    "end": "875880"
  },
  {
    "text": "you start building up sets of these",
    "start": "875880",
    "end": "877440"
  },
  {
    "text": "evaluations and then you can start",
    "start": "877440",
    "end": "878959"
  },
  {
    "text": "systematically actually fixing this",
    "start": "878959",
    "end": "880680"
  },
  {
    "text": "stuff and making it better and it makes",
    "start": "880680",
    "end": "882720"
  },
  {
    "text": "these inscrutable black boxes tangible",
    "start": "882720",
    "end": "884639"
  },
  {
    "text": "and actionable rather than just throw",
    "start": "884639",
    "end": "887600"
  },
  {
    "text": "stuff at the wall and hope it sticks so",
    "start": "887600",
    "end": "890079"
  },
  {
    "text": "what's open Telemetry doing to help well",
    "start": "890079",
    "end": "891759"
  },
  {
    "text": "aside from being mostly fit for purpose",
    "start": "891759",
    "end": "894639"
  },
  {
    "text": "um there is work going on in the uh llm",
    "start": "894639",
    "end": "897920"
  },
  {
    "text": "semantic conventions working group on",
    "start": "897920",
    "end": "899680"
  },
  {
    "text": "slack uh this is where it turns out",
    "start": "899680",
    "end": "902759"
  },
  {
    "text": "there's a whole lot of common operations",
    "start": "902759",
    "end": "904480"
  },
  {
    "text": "in this kind of application that you're",
    "start": "904480",
    "end": "905839"
  },
  {
    "text": "building when you're talking about",
    "start": "905839",
    "end": "906880"
  },
  {
    "text": "Vector databases you're talking about",
    "start": "906880",
    "end": "909079"
  },
  {
    "text": "calling different language models whe a",
    "start": "909079",
    "end": "910880"
  },
  {
    "text": "language model is like a single shot",
    "start": "910880",
    "end": "912720"
  },
  {
    "text": "sort of thing or if it's a part of an",
    "start": "912720",
    "end": "914040"
  },
  {
    "text": "agent um like there's names that you can",
    "start": "914040",
    "end": "916480"
  },
  {
    "text": "assign to this kind of stuff and names",
    "start": "916480",
    "end": "918079"
  },
  {
    "text": "that we are uh assigning to like what",
    "start": "918079",
    "end": "920839"
  },
  {
    "text": "should live on a span versus like should",
    "start": "920839",
    "end": "923199"
  },
  {
    "text": "this be captured in an event that's",
    "start": "923199",
    "end": "924720"
  },
  {
    "text": "correlated to a span and like what",
    "start": "924720",
    "end": "927399"
  },
  {
    "text": "should the default be should this data",
    "start": "927399",
    "end": "929120"
  },
  {
    "text": "captured or should it be redacted by",
    "start": "929120",
    "end": "930639"
  },
  {
    "text": "default and can you turn it on what does",
    "start": "930639",
    "end": "932079"
  },
  {
    "text": "that mechanism look like um and we're",
    "start": "932079",
    "end": "934720"
  },
  {
    "text": "working with the uh open lemetry folks",
    "start": "934720",
    "end": "937800"
  },
  {
    "text": "who have taken a spike at like let's",
    "start": "937800",
    "end": "939759"
  },
  {
    "text": "build a bunch of Auto instrumentations",
    "start": "939759",
    "end": "941120"
  },
  {
    "text": "for this stuff and see what it actually",
    "start": "941120",
    "end": "942519"
  },
  {
    "text": "looks like and working with them to say",
    "start": "942519",
    "end": "945079"
  },
  {
    "text": "okay based off of that this works this",
    "start": "945079",
    "end": "947519"
  },
  {
    "text": "one doesn't work this one works really",
    "start": "947519",
    "end": "949120"
  },
  {
    "text": "well this one yeah maybe I don't know",
    "start": "949120",
    "end": "951360"
  },
  {
    "text": "and see if we can formalize that into a",
    "start": "951360",
    "end": "953600"
  },
  {
    "text": "spec so it's very much underway right",
    "start": "953600",
    "end": "955199"
  },
  {
    "text": "now um there are pieces that are like",
    "start": "955199",
    "end": "959720"
  },
  {
    "text": "pretty like I don't want to say it's",
    "start": "959720",
    "end": "961639"
  },
  {
    "text": "stable it's like totally experimental",
    "start": "961639",
    "end": "963160"
  },
  {
    "text": "but like you could reasonably build",
    "start": "963160",
    "end": "964440"
  },
  {
    "text": "instrumentations off of what's been",
    "start": "964440",
    "end": "965720"
  },
  {
    "text": "defined today uh but there's a lot more",
    "start": "965720",
    "end": "967480"
  },
  {
    "text": "work to come and uh we really I would",
    "start": "967480",
    "end": "970279"
  },
  {
    "text": "really encourage anyone who's interested",
    "start": "970279",
    "end": "971680"
  },
  {
    "text": "in this space to uh uh engage in this",
    "start": "971680",
    "end": "974360"
  },
  {
    "text": "area um especially if you're working for",
    "start": "974360",
    "end": "977000"
  },
  {
    "text": "any of the tech companies that is",
    "start": "977000",
    "end": "978160"
  },
  {
    "text": "involved in building models because",
    "start": "978160",
    "end": "980759"
  },
  {
    "text": "y'all models have like weird ways to",
    "start": "980759",
    "end": "982800"
  },
  {
    "text": "capture inputs and outputs and like we",
    "start": "982800",
    "end": "984480"
  },
  {
    "text": "like standards and stuff so it'd be",
    "start": "984480",
    "end": "986199"
  },
  {
    "text": "great if we could figure out the best",
    "start": "986199",
    "end": "988480"
  },
  {
    "text": "possible way way to represent stuff",
    "start": "988480",
    "end": "989839"
  },
  {
    "text": "instead of treating open AI as a deao",
    "start": "989839",
    "end": "992160"
  },
  {
    "text": "standard for example um so this is",
    "start": "992160",
    "end": "995319"
  },
  {
    "text": "what's going on otel is like good enough",
    "start": "995319",
    "end": "997920"
  },
  {
    "text": "for you to use today you got to do a",
    "start": "997920",
    "end": "999480"
  },
  {
    "text": "little bit more manual instrumentation",
    "start": "999480",
    "end": "1000880"
  },
  {
    "text": "but like chances are uh with the budget",
    "start": "1000880",
    "end": "1002959"
  },
  {
    "text": "that's being assigned to these",
    "start": "1002959",
    "end": "1003839"
  },
  {
    "text": "applications you're going to have the",
    "start": "1003839",
    "end": "1004800"
  },
  {
    "text": "time to do that uh and there's going to",
    "start": "1004800",
    "end": "1007000"
  },
  {
    "text": "be more Auto instrumentations coming",
    "start": "1007000",
    "end": "1008680"
  },
  {
    "text": "there's good um uh good spec level stuff",
    "start": "1008680",
    "end": "1012360"
  },
  {
    "text": "being defined right now and I think in",
    "start": "1012360",
    "end": "1013759"
  },
  {
    "text": "the near future you could see this as",
    "start": "1013759",
    "end": "1015920"
  },
  {
    "text": "being as commonplace in otel as like",
    "start": "1015920",
    "end": "1019000"
  },
  {
    "text": "database stuff or HTTP stuff um and",
    "start": "1019000",
    "end": "1022600"
  },
  {
    "text": "hopefully without too much turn in the",
    "start": "1022600",
    "end": "1024600"
  },
  {
    "text": "spec itself so that's what I",
    "start": "1024600",
    "end": "1028520"
  },
  {
    "text": "got uh right now this is all patching",
    "start": "1030360",
    "end": "1032839"
  },
  {
    "text": "from the outside um so like I've written",
    "start": "1032839",
    "end": "1035959"
  },
  {
    "text": "like a library for like python that that",
    "start": "1035959",
    "end": "1038038"
  },
  {
    "text": "just calls like the open wraps the open",
    "start": "1038039",
    "end": "1039760"
  },
  {
    "text": "AI calls for example from the python SDK",
    "start": "1039760",
    "end": "1042240"
  },
  {
    "text": "um the open elemetry project is similar",
    "start": "1042240",
    "end": "1044038"
  },
  {
    "text": "sorts of things um what we are hoping as",
    "start": "1044039",
    "end": "1046678"
  },
  {
    "text": "a part of this that um like the AI",
    "start": "1046679",
    "end": "1050000"
  },
  {
    "text": "providers in their sdks just have the",
    "start": "1050000",
    "end": "1052840"
  },
  {
    "text": "otel apis and just you know like it's",
    "start": "1052840",
    "end": "1055480"
  },
  {
    "text": "just producing like no up spands for",
    "start": "1055480",
    "end": "1057000"
  },
  {
    "text": "example so it doesn't impact anyone",
    "start": "1057000",
    "end": "1058360"
  },
  {
    "text": "unless they turn it on um kind of going",
    "start": "1058360",
    "end": "1060400"
  },
  {
    "text": "again with sort of the goal of votel",
    "start": "1060400",
    "end": "1061720"
  },
  {
    "text": "where like instrumentation is everywhere",
    "start": "1061720",
    "end": "1063600"
  },
  {
    "text": "and then it just you can just turn it on",
    "start": "1063600",
    "end": "1065480"
  },
  {
    "text": "and and it's available so um but first I",
    "start": "1065480",
    "end": "1068280"
  },
  {
    "text": "think like we need to lay some of the",
    "start": "1068280",
    "end": "1069720"
  },
  {
    "text": "groundwork because they're going to have",
    "start": "1069720",
    "end": "1071120"
  },
  {
    "text": "immediately questions like hey should I",
    "start": "1071120",
    "end": "1073640"
  },
  {
    "text": "like put the prompt in the span or",
    "start": "1073640",
    "end": "1076120"
  },
  {
    "text": "should I create an event or like should",
    "start": "1076120",
    "end": "1077720"
  },
  {
    "text": "I even do that like what do I I do uh",
    "start": "1077720",
    "end": "1079960"
  },
  {
    "text": "and that's where like us nailing this",
    "start": "1079960",
    "end": "1081720"
  },
  {
    "text": "down on the spec Level side from the",
    "start": "1081720",
    "end": "1083320"
  },
  {
    "text": "open Telemetry project standpoint is",
    "start": "1083320",
    "end": "1084720"
  },
  {
    "text": "really going to help them out yeah so so",
    "start": "1084720",
    "end": "1087480"
  },
  {
    "text": "that yeah for anyone who didn't hear the",
    "start": "1087480",
    "end": "1089039"
  },
  {
    "text": "question this is so I gave input an",
    "start": "1089039",
    "end": "1090880"
  },
  {
    "text": "example of like user input possible",
    "start": "1090880",
    "end": "1092880"
  },
  {
    "text": "error and LM output as something that",
    "start": "1092880",
    "end": "1094799"
  },
  {
    "text": "you could look at what are some other",
    "start": "1094799",
    "end": "1096240"
  },
  {
    "text": "examples of things um so uh some some",
    "start": "1096240",
    "end": "1099799"
  },
  {
    "text": "examples that I can tell you by way of",
    "start": "1099799",
    "end": "1103120"
  },
  {
    "text": "um example from one of honeycombes",
    "start": "1103120",
    "end": "1105080"
  },
  {
    "text": "features is so like it's like natural",
    "start": "1105080",
    "end": "1107640"
  },
  {
    "text": "language to querying tool um so you need",
    "start": "1107640",
    "end": "1110960"
  },
  {
    "text": "to query a data set that data set has a",
    "start": "1110960",
    "end": "1113159"
  },
  {
    "text": "schema that schema can be massive and",
    "start": "1113159",
    "end": "1115720"
  },
  {
    "text": "you can't just include literally every",
    "start": "1115720",
    "end": "1117280"
  },
  {
    "text": "single name of everything in the schema",
    "start": "1117280",
    "end": "1118880"
  },
  {
    "text": "inside of every request that you make to",
    "start": "1118880",
    "end": "1120240"
  },
  {
    "text": "the model so there's this problem of",
    "start": "1120240",
    "end": "1122200"
  },
  {
    "text": "like okay what subset do we actually",
    "start": "1122200",
    "end": "1123679"
  },
  {
    "text": "pick which one is the most appropriate",
    "start": "1123679",
    "end": "1125080"
  },
  {
    "text": "subset so um we have like like there's",
    "start": "1125080",
    "end": "1129640"
  },
  {
    "text": "there's text based search and there's",
    "start": "1129640",
    "end": "1131120"
  },
  {
    "text": "Vector search and there's like which one",
    "start": "1131120",
    "end": "1132640"
  },
  {
    "text": "did we pick um which subset from each",
    "start": "1132640",
    "end": "1135400"
  },
  {
    "text": "did we end up picking what was the",
    "start": "1135400",
    "end": "1136799"
  },
  {
    "text": "actual like result that we gave so like",
    "start": "1136799",
    "end": "1139360"
  },
  {
    "text": "you know I'm I'm like you know you you",
    "start": "1139360",
    "end": "1140919"
  },
  {
    "text": "don't want to capture like the ACT if",
    "start": "1140919",
    "end": "1142120"
  },
  {
    "text": "you use ve Vector edings you don't want",
    "start": "1142120",
    "end": "1143559"
  },
  {
    "text": "to capture the actual Vector embeddings",
    "start": "1143559",
    "end": "1144840"
  },
  {
    "text": "because they're massive and like you're",
    "start": "1144840",
    "end": "1146320"
  },
  {
    "text": "not going to be able to interpret them",
    "start": "1146320",
    "end": "1147880"
  },
  {
    "text": "but you want to distill that down a",
    "start": "1147880",
    "end": "1149200"
  },
  {
    "text": "little bit uh there's also other",
    "start": "1149200",
    "end": "1150760"
  },
  {
    "text": "contextual things so like for example in",
    "start": "1150760",
    "end": "1153280"
  },
  {
    "text": "in our application um each request that",
    "start": "1153280",
    "end": "1155760"
  },
  {
    "text": "a user Make may be different to other",
    "start": "1155760",
    "end": "1158720"
  },
  {
    "text": "requests so like if you're talking to a",
    "start": "1158720",
    "end": "1160600"
  },
  {
    "text": "different data set that's a different",
    "start": "1160600",
    "end": "1162080"
  },
  {
    "text": "schema involved so you want to capture",
    "start": "1162080",
    "end": "1163640"
  },
  {
    "text": "some information about what that what",
    "start": "1163640",
    "end": "1165360"
  },
  {
    "text": "what's actually going on there so you",
    "start": "1165360",
    "end": "1166559"
  },
  {
    "text": "can distinguish between what are my",
    "start": "1166559",
    "end": "1168760"
  },
  {
    "text": "errors for this data set versus what are",
    "start": "1168760",
    "end": "1170480"
  },
  {
    "text": "my errors for this data set and like do",
    "start": "1170480",
    "end": "1172000"
  },
  {
    "text": "we perform better or one or the other",
    "start": "1172000",
    "end": "1173799"
  },
  {
    "text": "and does that tell us like okay is that",
    "start": "1173799",
    "end": "1175320"
  },
  {
    "text": "a problem with our prompting or is that",
    "start": "1175320",
    "end": "1177000"
  },
  {
    "text": "a problem with how we do retrieval",
    "start": "1177000",
    "end": "1178440"
  },
  {
    "text": "across different data sets um another",
    "start": "1178440",
    "end": "1180840"
  },
  {
    "text": "thing is there's other like specific",
    "start": "1180840",
    "end": "1183120"
  },
  {
    "text": "stuff that you pull in so a very common",
    "start": "1183120",
    "end": "1184760"
  },
  {
    "text": "prompting technique is called um like",
    "start": "1184760",
    "end": "1187799"
  },
  {
    "text": "few shot prompting where you sort of",
    "start": "1187799",
    "end": "1189280"
  },
  {
    "text": "embed little examples inside of the",
    "start": "1189280",
    "end": "1190960"
  },
  {
    "text": "prompt that you send as a part of a",
    "start": "1190960",
    "end": "1192480"
  },
  {
    "text": "request uh you can actually create a",
    "start": "1192480",
    "end": "1194559"
  },
  {
    "text": "database of those examples of like",
    "start": "1194559",
    "end": "1196440"
  },
  {
    "text": "well-known okay given some like",
    "start": "1196440",
    "end": "1199840"
  },
  {
    "text": "representation of what retrieval data",
    "start": "1199840",
    "end": "1201440"
  },
  {
    "text": "looks like a user's input and what the",
    "start": "1201440",
    "end": "1203240"
  },
  {
    "text": "ideal output for that input should look",
    "start": "1203240",
    "end": "1205080"
  },
  {
    "text": "like based off of that data you can",
    "start": "1205080",
    "end": "1206840"
  },
  {
    "text": "build up a whole a whole database of",
    "start": "1206840",
    "end": "1208480"
  },
  {
    "text": "that you can also do search techniques",
    "start": "1208480",
    "end": "1210880"
  },
  {
    "text": "on which pieces of that you actually",
    "start": "1210880",
    "end": "1212840"
  },
  {
    "text": "pull in on a pro request basis so if you",
    "start": "1212840",
    "end": "1214760"
  },
  {
    "text": "have like 50 fuse shot examples that are",
    "start": "1214760",
    "end": "1216919"
  },
  {
    "text": "all like generally really good which",
    "start": "1216919",
    "end": "1219200"
  },
  {
    "text": "three to five are going to be the most",
    "start": "1219200",
    "end": "1220840"
  },
  {
    "text": "helpful for this specific request",
    "start": "1220840",
    "end": "1222840"
  },
  {
    "text": "capture that information and then like",
    "start": "1222840",
    "end": "1224880"
  },
  {
    "text": "basically what you end up with is you",
    "start": "1224880",
    "end": "1227039"
  },
  {
    "text": "end up with like a really really big",
    "start": "1227039",
    "end": "1228240"
  },
  {
    "text": "grouping like imagine like a big CSV",
    "start": "1228240",
    "end": "1230120"
  },
  {
    "text": "with just tons and tons of columns and",
    "start": "1230120",
    "end": "1231679"
  },
  {
    "text": "you're like okay for each request here's",
    "start": "1231679",
    "end": "1233840"
  },
  {
    "text": "all the stuff that was interesting about",
    "start": "1233840",
    "end": "1235400"
  },
  {
    "text": "that and now you get into like okay what",
    "start": "1235400",
    "end": "1237159"
  },
  {
    "text": "are the patterns in each of those um",
    "start": "1237159",
    "end": "1239000"
  },
  {
    "text": "user behaviors uh fun fact if you are",
    "start": "1239000",
    "end": "1241120"
  },
  {
    "text": "working with an ml engineer they're",
    "start": "1241120",
    "end": "1242480"
  },
  {
    "text": "going to want that CSV uh and they're",
    "start": "1242480",
    "end": "1244440"
  },
  {
    "text": "going to want as many columns in it as",
    "start": "1244440",
    "end": "1246159"
  },
  {
    "text": "possible because that's going to help",
    "start": "1246159",
    "end": "1247440"
  },
  {
    "text": "their job if they're building like",
    "start": "1247440",
    "end": "1248600"
  },
  {
    "text": "evaluation sets it's going to make them",
    "start": "1248600",
    "end": "1250039"
  },
  {
    "text": "more um like I don't know I've talked",
    "start": "1250039",
    "end": "1252039"
  },
  {
    "text": "with a bunch of ml engineers and they're",
    "start": "1252039",
    "end": "1253320"
  },
  {
    "text": "like please load that CSV up with as",
    "start": "1253320",
    "end": "1255120"
  },
  {
    "text": "much data as you possibly can like air",
    "start": "1255120",
    "end": "1257559"
  },
  {
    "text": "on the side of too much dat data because",
    "start": "1257559",
    "end": "1259120"
  },
  {
    "text": "it's probably not even enough um so like",
    "start": "1259120",
    "end": "1262200"
  },
  {
    "text": "I don't know that that hopefully that's",
    "start": "1262200",
    "end": "1263559"
  },
  {
    "text": "helpful um well gigabytes per",
    "start": "1263559",
    "end": "1267520"
  },
  {
    "text": "hour I don't know it kind of depends on",
    "start": "1267520",
    "end": "1269480"
  },
  {
    "text": "the application I would say that first",
    "start": "1269480",
    "end": "1271600"
  },
  {
    "text": "chances are your prompts don't need to",
    "start": "1271600",
    "end": "1273360"
  },
  {
    "text": "be as big as they are and your responses",
    "start": "1273360",
    "end": "1274760"
  },
  {
    "text": "may not necessarily be that big either",
    "start": "1274760",
    "end": "1277440"
  },
  {
    "text": "um but like this I think is not too",
    "start": "1277440",
    "end": "1280400"
  },
  {
    "text": "different from any other observability",
    "start": "1280400",
    "end": "1281799"
  },
  {
    "text": "problem regarding sampling like chances",
    "start": "1281799",
    "end": "1283640"
  },
  {
    "text": "are that for some system there's going",
    "start": "1283640",
    "end": "1287039"
  },
  {
    "text": "to be some like Paro distribution of",
    "start": "1287039",
    "end": "1288720"
  },
  {
    "text": "like the kinds of inputs that people",
    "start": "1288720",
    "end": "1290240"
  },
  {
    "text": "actually want to ask about like if it's",
    "start": "1290240",
    "end": "1292360"
  },
  {
    "text": "a natural language tool for like",
    "start": "1292360",
    "end": "1293880"
  },
  {
    "text": "Prometheus for example um like 80% of",
    "start": "1293880",
    "end": "1297440"
  },
  {
    "text": "the questions that people are going to",
    "start": "1297440",
    "end": "1298480"
  },
  {
    "text": "ask are going to follow a pretty similar",
    "start": "1298480",
    "end": "1300159"
  },
  {
    "text": "kind of pattern and so you could sample",
    "start": "1300159",
    "end": "1301799"
  },
  {
    "text": "that much more aggressively than others",
    "start": "1301799",
    "end": "1303400"
  },
  {
    "text": "and so there's ways that you could",
    "start": "1303400",
    "end": "1304400"
  },
  {
    "text": "actually detect that um there are other",
    "start": "1304400",
    "end": "1307799"
  },
  {
    "text": "like to be frank like some observability",
    "start": "1307799",
    "end": "1310520"
  },
  {
    "text": "systems are a lot cheaper than others",
    "start": "1310520",
    "end": "1312120"
  },
  {
    "text": "and like it's a great opportunity to be",
    "start": "1312120",
    "end": "1313679"
  },
  {
    "text": "like oh wow maybe my bill's a little too",
    "start": "1313679",
    "end": "1315520"
  },
  {
    "text": "high right now and um maybe per gigabyte",
    "start": "1315520",
    "end": "1319120"
  },
  {
    "text": "pricing is not the right pricing scheme",
    "start": "1319120",
    "end": "1320840"
  },
  {
    "text": "for what I'm trying to deal with um I",
    "start": "1320840",
    "end": "1324279"
  },
  {
    "text": "think it kind of depends there but like",
    "start": "1324279",
    "end": "1326200"
  },
  {
    "text": "I don't think we're really at a point",
    "start": "1326200",
    "end": "1328039"
  },
  {
    "text": "where we're going to be limited by that",
    "start": "1328039",
    "end": "1330400"
  },
  {
    "text": "unless you're at the like Amazon",
    "start": "1330400",
    "end": "1333799"
  },
  {
    "text": "Microsoft scale of like oh I have a",
    "start": "1333799",
    "end": "1335919"
  },
  {
    "text": "million users who are doing this well I",
    "start": "1335919",
    "end": "1337440"
  },
  {
    "text": "don't know it's just going to be",
    "start": "1337440",
    "end": "1338240"
  },
  {
    "text": "expensive operating at that scale is",
    "start": "1338240",
    "end": "1339640"
  },
  {
    "text": "expensive um I think today yes there's",
    "start": "1339640",
    "end": "1342919"
  },
  {
    "text": "like there is certainly some active",
    "start": "1342919",
    "end": "1344320"
  },
  {
    "text": "research being done around like true",
    "start": "1344320",
    "end": "1345799"
  },
  {
    "text": "debuggability into these things but like",
    "start": "1345799",
    "end": "1348200"
  },
  {
    "text": "I I I think some of that could also just",
    "start": "1348200",
    "end": "1349640"
  },
  {
    "text": "end up being like incomprehensible where",
    "start": "1349640",
    "end": "1353200"
  },
  {
    "text": "like a model like gbd 3.5 even is just",
    "start": "1353200",
    "end": "1356480"
  },
  {
    "text": "there's so many like activations of",
    "start": "1356480",
    "end": "1359679"
  },
  {
    "text": "different layers that are going on that",
    "start": "1359679",
    "end": "1361279"
  },
  {
    "text": "like it that may not even be helpful um",
    "start": "1361279",
    "end": "1363799"
  },
  {
    "text": "or it may just be too hard to sort of",
    "start": "1363799",
    "end": "1365159"
  },
  {
    "text": "wrangle around now I know that there are",
    "start": "1365159",
    "end": "1367200"
  },
  {
    "text": "certain um things that you can do like",
    "start": "1367200",
    "end": "1369520"
  },
  {
    "text": "you can um you can ask it to generate",
    "start": "1369520",
    "end": "1371960"
  },
  {
    "text": "multiple responses and you have a system",
    "start": "1371960",
    "end": "1373720"
  },
  {
    "text": "that picks which response you want and",
    "start": "1373720",
    "end": "1375880"
  },
  {
    "text": "there's these there's these things that",
    "start": "1375880",
    "end": "1377360"
  },
  {
    "text": "are called log probabilties that assign",
    "start": "1377360",
    "end": "1379279"
  },
  {
    "text": "like okay the the probability of like",
    "start": "1379279",
    "end": "1382000"
  },
  {
    "text": "this token like this and and it'll",
    "start": "1382000",
    "end": "1384480"
  },
  {
    "text": "basically say like here's like a set of",
    "start": "1384480",
    "end": "1385840"
  },
  {
    "text": "tokens that we were going to generate",
    "start": "1385840",
    "end": "1387640"
  },
  {
    "text": "and these were the probabilities that",
    "start": "1387640",
    "end": "1388919"
  },
  {
    "text": "were assigned to them and that's why",
    "start": "1388919",
    "end": "1390159"
  },
  {
    "text": "this one was was was chosen now it",
    "start": "1390159",
    "end": "1392240"
  },
  {
    "text": "doesn't tell you the actual",
    "start": "1392240",
    "end": "1393919"
  },
  {
    "text": "decision-making process that led into",
    "start": "1393919",
    "end": "1395840"
  },
  {
    "text": "that but that can inch you a little bit",
    "start": "1395840",
    "end": "1397320"
  },
  {
    "text": "closer to that um to be honest I've not",
    "start": "1397320",
    "end": "1399320"
  },
  {
    "text": "really run into anyone who's like really",
    "start": "1399320",
    "end": "1401279"
  },
  {
    "text": "used that stuff a whole lot uh like I",
    "start": "1401279",
    "end": "1404679"
  },
  {
    "text": "know that it exists but like it's um",
    "start": "1404679",
    "end": "1407480"
  },
  {
    "text": "you're you're getting pretty",
    "start": "1407480",
    "end": "1408760"
  },
  {
    "text": "sophisticated and you're debugging it at",
    "start": "1408760",
    "end": "1410640"
  },
  {
    "text": "that point and I would say that most",
    "start": "1410640",
    "end": "1412240"
  },
  {
    "text": "people are just not at that point yet um",
    "start": "1412240",
    "end": "1415440"
  },
  {
    "text": "if ever um I think like also it's like",
    "start": "1415440",
    "end": "1418400"
  },
  {
    "text": "regular observability of systems is like",
    "start": "1418400",
    "end": "1420200"
  },
  {
    "text": "well sometimes we're working with stuff",
    "start": "1420200",
    "end": "1421480"
  },
  {
    "text": "that are black boxes that kind of suck",
    "start": "1421480",
    "end": "1423520"
  },
  {
    "text": "um sometimes and do weird stuff in",
    "start": "1423520",
    "end": "1425240"
  },
  {
    "text": "production that you can never reproduce",
    "start": "1425240",
    "end": "1426640"
  },
  {
    "text": "locally uh and then you are still still",
    "start": "1426640",
    "end": "1429279"
  },
  {
    "text": "in this place of like okay like what",
    "start": "1429279",
    "end": "1431400"
  },
  {
    "text": "patterns are leading to these outputs",
    "start": "1431400",
    "end": "1433240"
  },
  {
    "text": "and what can I do with that info um and",
    "start": "1433240",
    "end": "1436200"
  },
  {
    "text": "uh I think we're there right now",
    "start": "1436200",
    "end": "1439039"
  },
  {
    "text": "now um we might get somewhere in the",
    "start": "1439039",
    "end": "1441600"
  },
  {
    "text": "future where you could more like",
    "start": "1441600",
    "end": "1443039"
  },
  {
    "text": "fine-tune debug something but um",
    "start": "1443039",
    "end": "1445559"
  },
  {
    "text": "probably not for a while",
    "start": "1445559",
    "end": "1449320"
  }
]
[
  {
    "text": "hello my name is Andre Wapel and today I'm going to show you how we implemented GPU support in Cozy Stack But at first",
    "start": "1199",
    "end": "9040"
  },
  {
    "text": "let me explain what the Coyist is Actually Cozy Stack is cloud platform",
    "start": "9040",
    "end": "14240"
  },
  {
    "text": "which allows you to simply transform your bare metal servers with no operating system installed into",
    "start": "14240",
    "end": "19760"
  },
  {
    "text": "intelligent system uh based on Kubernetes with Kubernetes API for ordering managed services This cloud",
    "start": "19760",
    "end": "27119"
  },
  {
    "text": "system have everything preconfigured like monitoring dashboard alerts and ready managed services Cozy stack",
    "start": "27119",
    "end": "34640"
  },
  {
    "text": "provides ready infrastructure stack starting from the bottom layer that means operating system layer and",
    "start": "34640",
    "end": "39840"
  },
  {
    "text": "hardware layer where we have talis Linux Talis Linux allows us to prepare uh",
    "start": "39840",
    "end": "46160"
  },
  {
    "text": "reproducible environments because we can hardcode kernel modules kernel versions",
    "start": "46160",
    "end": "51520"
  },
  {
    "text": "and use them uh by the upper layers In the bottom layer we have operating",
    "start": "51520",
    "end": "57440"
  },
  {
    "text": "system prepared and on top of it we run storage system networking virtualization",
    "start": "57440",
    "end": "64158"
  },
  {
    "text": "On top of this we have operators cluster API monitoring system and on the fourth",
    "start": "64159",
    "end": "70320"
  },
  {
    "text": "layer we say user layer we have this beautiful dashboard where you can click",
    "start": "70320",
    "end": "75840"
  },
  {
    "text": "and order any managed services you wanted just like any cloud but on your",
    "start": "75840",
    "end": "80880"
  },
  {
    "text": "own on premis environment Uh cozy stack provides reading monitoring stack Uh we have",
    "start": "80880",
    "end": "88560"
  },
  {
    "text": "really fast and reliable storage Uh we use lin store which allows us to do bare",
    "start": "88560",
    "end": "95200"
  },
  {
    "text": "almost bare metal performance Uh we have networking system based on cubovn and selon Also we have",
    "start": "95200",
    "end": "103759"
  },
  {
    "text": "OEDC server based on key log and virtualization system based on cube This",
    "start": "103759",
    "end": "109200"
  },
  {
    "text": "way you can run uh managed Kubernetes managed databases vual machines load",
    "start": "109200",
    "end": "114960"
  },
  {
    "text": "balancers and even S3 buckets Uh our Kubernetes is fully",
    "start": "114960",
    "end": "120880"
  },
  {
    "text": "functional That means that our Kubernetes is like Kubernetes in every",
    "start": "120880",
    "end": "126240"
  },
  {
    "text": "cloud It has control plane separated Uh it supports persistent volumes It",
    "start": "126240",
    "end": "133760"
  },
  {
    "text": "supports load balancers and cluster after scaling database as a service We",
    "start": "133760",
    "end": "140000"
  },
  {
    "text": "do this full cycle management That means that we use operators to manage uh every",
    "start": "140000",
    "end": "146080"
  },
  {
    "text": "database life cycle to create new replicas to configure replication and to keep them alive",
    "start": "146080",
    "end": "154319"
  },
  {
    "text": "Uh on top of this on on top of all of these operators we actually created our",
    "start": "154319",
    "end": "159760"
  },
  {
    "text": "own API server which provides um Kubernetes native entities based on flux",
    "start": "159760",
    "end": "167760"
  },
  {
    "text": "uh flux helm charts actually um that allows you to create to define your",
    "start": "167760",
    "end": "174480"
  },
  {
    "text": "applications very quickly You can extend the platform with adding new services",
    "start": "174480",
    "end": "179760"
  },
  {
    "text": "and in the end you will always have Kubernetes API objects and if you want",
    "start": "179760",
    "end": "185519"
  },
  {
    "text": "to create new Kubernetes objects you don't have to recompile API server you",
    "start": "185519",
    "end": "190560"
  },
  {
    "text": "can actually just extend it with Helm charts and uh configure config map so",
    "start": "190560",
    "end": "197200"
  },
  {
    "text": "those um resources will appear in your Kubernetes API and then you can expose",
    "start": "197200",
    "end": "203360"
  },
  {
    "text": "this API to your end user users So they will be able to uh use those entities",
    "start": "203360",
    "end": "210319"
  },
  {
    "text": "and communicate with them directly Uh Coyst now is CNCF sandbox",
    "start": "210319",
    "end": "217040"
  },
  {
    "text": "project that means that now you have no vendor lock uh lower risks on changing",
    "start": "217040",
    "end": "223319"
  },
  {
    "text": "licensing and we have large community Uh let's start with talking",
    "start": "223319",
    "end": "229760"
  },
  {
    "text": "about tenant system We actually consume Kubernetes name spaces but we have",
    "start": "229760",
    "end": "235519"
  },
  {
    "text": "design of well-known Linux systems So we have tenant root pretty similar to root",
    "start": "235519",
    "end": "241920"
  },
  {
    "text": "user in Unix Um and um below this user",
    "start": "241920",
    "end": "247360"
  },
  {
    "text": "you can create new tenants and every tenant have uh domain name assigned and",
    "start": "247360",
    "end": "253599"
  },
  {
    "text": "every new tenant will get new domain name a subdomain to this domain Uh if",
    "start": "253599",
    "end": "261600"
  },
  {
    "text": "you'll look more closer we'll see that there is some man some specific services",
    "start": "261600",
    "end": "267680"
  },
  {
    "text": "uh needed to to run other managed services in our system So by default",
    "start": "267680",
    "end": "274080"
  },
  {
    "text": "tenant root have ATCD installed monitoring hub and ingress We also have",
    "start": "274080",
    "end": "279240"
  },
  {
    "text": "CVDS which provides S3 buckets If you create new tenant it can be created as",
    "start": "279240",
    "end": "285360"
  },
  {
    "text": "any application uh you can uh explicitly specify if you want to have separated um isolation in",
    "start": "285360",
    "end": "293280"
  },
  {
    "text": "terms of etc if you want to have separated ETCD cluster or monitoring hub",
    "start": "293280",
    "end": "299120"
  },
  {
    "text": "to collect the metrics from your applications and when you start deploying applications inside of this",
    "start": "299120",
    "end": "306000"
  },
  {
    "text": "tenant name space they automatically consume those services from the",
    "start": "306000",
    "end": "311639"
  },
  {
    "text": "um from the tenants if tenant have no specific isolation for example This blue",
    "start": "311639",
    "end": "317360"
  },
  {
    "text": "tenant f have no visilation by ingress So kubernetes cluster deployed here it",
    "start": "317360",
    "end": "323280"
  },
  {
    "text": "consumes upper tenant ingress Thanks to this system you can consume resources",
    "start": "323280",
    "end": "328479"
  },
  {
    "text": "very smart That means that you can have one monitoring system let's say for",
    "start": "328479",
    "end": "333759"
  },
  {
    "text": "tenant organization and you can have isolation for your team members Um by",
    "start": "333759",
    "end": "339759"
  },
  {
    "text": "default tenants have access networking access from up to down but from down to",
    "start": "339759",
    "end": "346080"
  },
  {
    "text": "up it they have access only to this specific services needed to store the",
    "start": "346080",
    "end": "352039"
  },
  {
    "text": "data Um this way you can create for example one common graphana and still",
    "start": "352039",
    "end": "358400"
  },
  {
    "text": "have isolation between the tenants but collect the metrics from those bottom",
    "start": "358400",
    "end": "364759"
  },
  {
    "text": "tenants That's actually it Now let's switch to live demo Uh here we have cluster installed",
    "start": "364759",
    "end": "374000"
  },
  {
    "text": "Uh it already have configured ODC server storage and",
    "start": "374000",
    "end": "380280"
  },
  {
    "text": "networking Uh the first time we log into cozy stack we we have some um",
    "start": "380280",
    "end": "386639"
  },
  {
    "text": "applications pre-installed So we have uh root tenant root application installed",
    "start": "386639",
    "end": "393360"
  },
  {
    "text": "and we have also monitoring etc and ingress Uh in case if you want to create",
    "start": "393360",
    "end": "400639"
  },
  {
    "text": "a new application you just switch to catalog and you can switch any application you want to for example you",
    "start": "400639",
    "end": "407280"
  },
  {
    "text": "can deploy your own kubernetes cluster virtual machine posgress radius or",
    "start": "407280",
    "end": "413520"
  },
  {
    "text": "anything else Uh if you want to create new tenant this is also a separated",
    "start": "413520",
    "end": "418880"
  },
  {
    "text": "application which you can click and install Uh and here you can specify if",
    "start": "418880",
    "end": "424880"
  },
  {
    "text": "you want to have um to configure this tenant having separated isolation uh for",
    "start": "424880",
    "end": "431360"
  },
  {
    "text": "example separated to DCD cluster In our case I'm not going to do that I'm going",
    "start": "431360",
    "end": "437199"
  },
  {
    "text": "to create new tenant for me for myself I will name it quaps and I will have one",
    "start": "437199",
    "end": "444840"
  },
  {
    "text": "isolation by the networking layer Let's deploy it",
    "start": "444840",
    "end": "450039"
  },
  {
    "text": "now Now we can switch to applications Let's refresh the",
    "start": "450039",
    "end": "457759"
  },
  {
    "text": "page And now we can see that new tenant is deployed here",
    "start": "458280",
    "end": "465120"
  },
  {
    "text": "Uh now I switch to my tenant name space and I can see that another default",
    "start": "465120",
    "end": "471680"
  },
  {
    "text": "application is already deployed here that's uh actually info application This",
    "start": "471680",
    "end": "477280"
  },
  {
    "text": "application uh needed just to get um cube config file So you can get uh cube",
    "start": "477280",
    "end": "484160"
  },
  {
    "text": "config file and give it to your tenant user Uh let's switch to console I can",
    "start": "484160",
    "end": "492120"
  },
  {
    "text": "actually create cube config I will copy paste it right from",
    "start": "492120",
    "end": "498800"
  },
  {
    "text": "the dashboard You can see that it have already uh preconfigured endpoint to",
    "start": "498800",
    "end": "504160"
  },
  {
    "text": "your server and already have ODC login for logging into your",
    "start": "504160",
    "end": "510520"
  },
  {
    "text": "cluster Now let's export environment variable to this cube config",
    "start": "510520",
    "end": "517159"
  },
  {
    "text": "file And now let's check the connection It will ask you to login in in your web",
    "start": "517159",
    "end": "526519"
  },
  {
    "text": "browser Um I think I already logged in So it will just get the token And now we",
    "start": "526519",
    "end": "532959"
  },
  {
    "text": "can use this cube config file to um access your cluster to access your",
    "start": "532959",
    "end": "539360"
  },
  {
    "text": "tenant name space This cube config already configured to exactly tenant",
    "start": "539360",
    "end": "544480"
  },
  {
    "text": "namespace you downloaded it from Uh so we can check if there are any pots",
    "start": "544480",
    "end": "550800"
  },
  {
    "text": "running There is nothing yet Uh but we can also check the nodes Uh in this",
    "start": "550800",
    "end": "557120"
  },
  {
    "text": "cluster I have three control plane nodes and one GPU node added for our",
    "start": "557120",
    "end": "563959"
  },
  {
    "text": "tests Those nodes actually deployed by Talis Linux Um we have our own tool to",
    "start": "563959",
    "end": "570480"
  },
  {
    "text": "configure Talis Linux itself And before we start using um before we start",
    "start": "570480",
    "end": "577519"
  },
  {
    "text": "demonstration of GPU functionality let me show how um the virtual machines are",
    "start": "577519",
    "end": "584360"
  },
  {
    "text": "work So in case if you want to create new virtual machine you can specify that",
    "start": "584360",
    "end": "589440"
  },
  {
    "text": "you need new virtual machine Let's call it test You can choose instance type",
    "start": "589440",
    "end": "598480"
  },
  {
    "text": "You can select the system you want to and you can create the virtual",
    "start": "598480",
    "end": "606240"
  },
  {
    "text": "machine itself Then it will start deploying Here it is Uh we can see",
    "start": "606240",
    "end": "615079"
  },
  {
    "text": "the workload state So for now this virtual machine is going to be prepared",
    "start": "615079",
    "end": "621600"
  },
  {
    "text": "Let's check what is happening in our Kubernetes cluster So we have uh cubert",
    "start": "621600",
    "end": "627360"
  },
  {
    "text": "virtual machine We can see that it is provisioning Uh yeah I can also check",
    "start": "627360",
    "end": "633519"
  },
  {
    "text": "data volume which is currently uh import in progress",
    "start": "633519",
    "end": "638760"
  },
  {
    "text": "state Um so we can take a look on this data volume Um that actually will create",
    "start": "638760",
    "end": "646399"
  },
  {
    "text": "persistent volume claim Then it will start downloading the uh Ubuntu image",
    "start": "646399",
    "end": "655200"
  },
  {
    "text": "Let's take a look at the spec You can see that there is URL",
    "start": "655200",
    "end": "660640"
  },
  {
    "text": "um which is going to be downloaded and place it in our",
    "start": "660640",
    "end": "665839"
  },
  {
    "text": "PVC And now we can see that it is in progress So after this persistent volume",
    "start": "666279",
    "end": "674000"
  },
  {
    "text": "claim created the image will be downloaded to it It will also automatically convert it If it is in",
    "start": "674000",
    "end": "680000"
  },
  {
    "text": "kamo format it will convert it into block device and right after that the",
    "start": "680000",
    "end": "686959"
  },
  {
    "text": "virtual machine will start Now we can see that our um data volume get",
    "start": "686959",
    "end": "692360"
  },
  {
    "text": "provisioned Now let's check our virtual machine It is in starting state We can",
    "start": "692360",
    "end": "698640"
  },
  {
    "text": "check because every virtual machine actually put",
    "start": "698640",
    "end": "704399"
  },
  {
    "text": "uh cube virtu process inside of the pot And",
    "start": "704399",
    "end": "710000"
  },
  {
    "text": "after the virtual machine is created we can uh use vct ctl",
    "start": "710000",
    "end": "716360"
  },
  {
    "text": "tool to attach console of this virtual machine and see what is happening inside",
    "start": "716360",
    "end": "723040"
  },
  {
    "text": "We can see that now this virtual machine is booted",
    "start": "723040",
    "end": "728800"
  },
  {
    "text": "So it will take some time to boot And after this virtual machine is booted you",
    "start": "728800",
    "end": "734160"
  },
  {
    "text": "can actually connect to it um through the SSH or using console or even",
    "start": "734160",
    "end": "742360"
  },
  {
    "text": "Vincy So you can use Vincy It will open your uh Vincy",
    "start": "742360",
    "end": "750399"
  },
  {
    "text": "browser and show the state of the virtual machine as well",
    "start": "750519",
    "end": "757079"
  },
  {
    "text": "Okay Um now it is about to configure",
    "start": "758760",
    "end": "767600"
  },
  {
    "text": "networking After um it's booted we can try to login But we actually didn't",
    "start": "769880",
    "end": "775920"
  },
  {
    "text": "specify any password So it will not let us to go Um we can",
    "start": "775920",
    "end": "783199"
  },
  {
    "text": "disconnect And now let's see how it looks like in terms of cozy stack API So",
    "start": "783240",
    "end": "791360"
  },
  {
    "text": "cozyst API is actually normal Kubernetes API You can check uh API resources in",
    "start": "791360",
    "end": "797920"
  },
  {
    "text": "coyst group",
    "start": "797920",
    "end": "801639"
  },
  {
    "text": "We'll see that there are a lot of resources",
    "start": "803440",
    "end": "809079"
  },
  {
    "text": "like yeah you can see that there are a lot of resources like posgress vual",
    "start": "809079",
    "end": "815040"
  },
  {
    "text": "machine disk virtual machine uh instance such resources like kafka",
    "start": "815040",
    "end": "823320"
  },
  {
    "text": "etc and stuff like that Um so you can actually query those",
    "start": "823320",
    "end": "829680"
  },
  {
    "text": "resources directly For example cubectl get virtual",
    "start": "829680",
    "end": "836959"
  },
  {
    "text": "machines in apps.cystack",
    "start": "838440",
    "end": "843320"
  },
  {
    "text": "io It will show that there is virtual machine test is created We can actually",
    "start": "844519",
    "end": "851360"
  },
  {
    "text": "tra see what is inside There is some",
    "start": "851360",
    "end": "857560"
  },
  {
    "text": "spec and we can save this virtual machine",
    "start": "857560",
    "end": "863639"
  },
  {
    "text": "to YAML file and then remove",
    "start": "863639",
    "end": "871040"
  },
  {
    "text": "status some service fields and now you can actually reuse",
    "start": "871320",
    "end": "879120"
  },
  {
    "text": "this resource to create another virtual machines",
    "start": "879120",
    "end": "885399"
  },
  {
    "text": "Uh let's save it like this And now we just want to create virtual machine with",
    "start": "885760",
    "end": "891079"
  },
  {
    "text": "GPU But before you start using GPU you need to configure your cluster to using",
    "start": "891079",
    "end": "896160"
  },
  {
    "text": "GPU So now let's talk from PT for cluster administrator So you just get",
    "start": "896160",
    "end": "901920"
  },
  {
    "text": "the node with GPU And now we want to use uh GPUs of",
    "start": "901920",
    "end": "909199"
  },
  {
    "text": "from this node to create virtual machines and pass them through In this",
    "start": "909199",
    "end": "914320"
  },
  {
    "text": "case um the coyst installed by default It has no GPU operator enabled",
    "start": "914320",
    "end": "922880"
  },
  {
    "text": "You need to enable it explicitly in this way You just edit uh",
    "start": "922880",
    "end": "928079"
  },
  {
    "text": "coyst configuration file This is common configuration file for coyst You just need to enable this component by bundle",
    "start": "928079",
    "end": "934480"
  },
  {
    "text": "enable option",
    "start": "934480",
    "end": "937360"
  },
  {
    "text": "and we just say GPU",
    "start": "943920",
    "end": "947920"
  },
  {
    "text": "operator After that we can check name",
    "start": "950040",
    "end": "954800"
  },
  {
    "text": "spaces Um the new name space will be created I was installing GP operator",
    "start": "955079",
    "end": "961360"
  },
  {
    "text": "previously So this name space still existing We can check ports inside of",
    "start": "961360",
    "end": "968720"
  },
  {
    "text": "it Cozy GPU operator Uh there are no pots yet",
    "start": "969560",
    "end": "977839"
  },
  {
    "text": "because this config map is getting reconciled every minute So it will take time to create um needed components",
    "start": "977839",
    "end": "985399"
  },
  {
    "text": "inside uh while we waiting that uh we need to also label this node with",
    "start": "985399",
    "end": "991920"
  },
  {
    "text": "specific label which will say that to GPU operator that we will use VM pass",
    "start": "991920",
    "end": "997839"
  },
  {
    "text": "through mode for our GPUs Yeah And now we can see that uh GPU",
    "start": "997839",
    "end": "1006079"
  },
  {
    "text": "operator just deployed It will also automatically discover the node we",
    "start": "1006079",
    "end": "1014040"
  },
  {
    "text": "have So it will create uh additional ports which will um configure",
    "start": "1014040",
    "end": "1021800"
  },
  {
    "text": "drivers to use this GPU It will also take some",
    "start": "1021800",
    "end": "1028760"
  },
  {
    "text": "time Let me first uh show you how can",
    "start": "1028760",
    "end": "1035760"
  },
  {
    "text": "you Yeah it will take some time Let's watch for this",
    "start": "1036839",
    "end": "1043360"
  },
  {
    "text": "It's creates actually the few manager which will configure your driver um your",
    "start": "1043360",
    "end": "1049200"
  },
  {
    "text": "GPU devices be ready to pass through uh after all the ports become ready we can",
    "start": "1049200",
    "end": "1057200"
  },
  {
    "text": "switch actually to start using this GPU but before you can pass it pass it",
    "start": "1057200",
    "end": "1063440"
  },
  {
    "text": "through uh you need to get information about this GPU device so we can um we",
    "start": "1063440",
    "end": "1071600"
  },
  {
    "text": "need to get some information what exactly device is For this we can just",
    "start": "1071600",
    "end": "1078240"
  },
  {
    "text": "uh check the node in allocatable",
    "start": "1078240",
    "end": "1084399"
  },
  {
    "text": "devices Uh you'll see this key value that our node have four",
    "start": "1086919",
    "end": "1094799"
  },
  {
    "text": "GPU devices ready to consume Um before we start using them in virtual machines",
    "start": "1094799",
    "end": "1101760"
  },
  {
    "text": "you need also to configure cube itself Uh for this you need to get exact",
    "start": "1101760",
    "end": "1110080"
  },
  {
    "text": "information um what the vendor ID and product ID it has Uh you have two methods here The",
    "start": "1110080",
    "end": "1118720"
  },
  {
    "text": "first method if you use Talis Linux you can ask Talis directly In this way you",
    "start": "1118720",
    "end": "1123919"
  },
  {
    "text": "need to go uh to your configuration and send request to the",
    "start": "1123919",
    "end": "1131200"
  },
  {
    "text": "node Um we use talm but you can use also talisl for",
    "start": "1133240",
    "end": "1140640"
  },
  {
    "text": "this Uh we just use get",
    "start": "1141240",
    "end": "1146520"
  },
  {
    "text": "devices to see all the devices of this node There are so many devices Let's",
    "start": "1146520",
    "end": "1153280"
  },
  {
    "text": "filter them by",
    "start": "1153280",
    "end": "1157440"
  },
  {
    "text": "Nvidia Here they are for Nvidia controllers in different",
    "start": "1158520",
    "end": "1164080"
  },
  {
    "text": "PCI buses We can even query specific",
    "start": "1164080",
    "end": "1170000"
  },
  {
    "text": "device The command tool the command line tool is pretty similar that Kubernetes",
    "start": "1170039",
    "end": "1176840"
  },
  {
    "text": "has So we can query it in YAML format and we'll see that there is vendor ID",
    "start": "1176840",
    "end": "1182880"
  },
  {
    "text": "and product ID In case if you want to use another method you can use node",
    "start": "1182880",
    "end": "1188880"
  },
  {
    "text": "shell plugin to create shell exactly on this node",
    "start": "1188880",
    "end": "1195360"
  },
  {
    "text": "uh we use X mode that means that it will not get exactly shell of the node",
    "start": "1195360",
    "end": "1200480"
  },
  {
    "text": "because talis have no any bash or shell installed but it will let us log in into",
    "start": "1200480",
    "end": "1206400"
  },
  {
    "text": "the container but this container should have all the access to the node So for",
    "start": "1206400",
    "end": "1211679"
  },
  {
    "text": "example you can have access to the host system",
    "start": "1211679",
    "end": "1216799"
  },
  {
    "text": "uh but what we interested here is PCI devices Um now we can switch",
    "start": "1216799",
    "end": "1224200"
  },
  {
    "text": "to cozy stack documentation We have operations",
    "start": "1224200",
    "end": "1231240"
  },
  {
    "text": "virtualization GPU pass through and there is a",
    "start": "1231240",
    "end": "1239080"
  },
  {
    "text": "command ls PCI Uh we can use it in here Now the",
    "start": "1239080",
    "end": "1245919"
  },
  {
    "text": "only thing we need to do is is to install PCI",
    "start": "1245919",
    "end": "1251840"
  },
  {
    "text": "tills and in here we can have the same output like a PCI bus",
    "start": "1257400",
    "end": "1264320"
  },
  {
    "text": "um vendor and device ID and those four devices",
    "start": "1264320",
    "end": "1269360"
  },
  {
    "text": "Uh the only thing you need to do now is to configure your",
    "start": "1269360",
    "end": "1274679"
  },
  {
    "text": "cube You can edit cube resource in cube coy cube name space and add this",
    "start": "1274679",
    "end": "1283080"
  },
  {
    "text": "configuration that cube can consume those",
    "start": "1283080",
    "end": "1288880"
  },
  {
    "text": "devices So this is resource name we get from the node and this is PCI vendor um",
    "start": "1289559",
    "end": "1297760"
  },
  {
    "text": "notation we used from lspci command or from talis output After you edit this",
    "start": "1297760",
    "end": "1305000"
  },
  {
    "text": "section your cluster is configured to those to use those",
    "start": "1305000",
    "end": "1311720"
  },
  {
    "text": "devices So now we can create another virtual machine Previously we created",
    "start": "1311720",
    "end": "1317080"
  },
  {
    "text": "this one I'll show preconfigured another",
    "start": "1317080",
    "end": "1323480"
  },
  {
    "text": "one It's quite similar The only thing I added here is uh cloud init",
    "start": "1323480",
    "end": "1329679"
  },
  {
    "text": "configuration to have password Um so I can login into this virtual",
    "start": "1329679",
    "end": "1335640"
  },
  {
    "text": "machine Um and also I specify that I want to use this GPU and I added my SSH",
    "start": "1335640",
    "end": "1343840"
  },
  {
    "text": "key Let's create this virtual",
    "start": "1343840",
    "end": "1350639"
  },
  {
    "text": "machine It should also be appeared in a cozy stack",
    "start": "1352520",
    "end": "1358640"
  },
  {
    "text": "dashboard because it looks into the same API and it is still in deploying state",
    "start": "1360280",
    "end": "1368640"
  },
  {
    "text": "Let's check the console",
    "start": "1368640",
    "end": "1372520"
  },
  {
    "text": "We can check data",
    "start": "1374400",
    "end": "1377679"
  },
  {
    "text": "volume So we can see the uh pot importer Um the data volume importer uses this",
    "start": "1389720",
    "end": "1398559"
  },
  {
    "text": "part to download the image and place it into persistent volume",
    "start": "1398559",
    "end": "1404159"
  },
  {
    "text": "We can see the process in um data",
    "start": "1404159",
    "end": "1410320"
  },
  {
    "text": "volumes Let's wait until it",
    "start": "1412919",
    "end": "1417120"
  },
  {
    "text": "finished Yeah now it seems done and the virtual machine should be starting in",
    "start": "1420600",
    "end": "1427600"
  },
  {
    "text": "cube Every virtual machine is actually pot So we can get um the",
    "start": "1427600",
    "end": "1435559"
  },
  {
    "text": "pots You can see that few virtual launcher pots are created Uh we can check the spec of this",
    "start": "1435559",
    "end": "1443520"
  },
  {
    "text": "pot Let's use edit for nice",
    "start": "1443520",
    "end": "1448799"
  },
  {
    "text": "formatting And in resources it should have this resource allocated That means",
    "start": "1451320",
    "end": "1457240"
  },
  {
    "text": "that uh this port is going to be created on virtual machine with res resource",
    "start": "1457240",
    "end": "1463320"
  },
  {
    "text": "allocatable So now this virtual machine will use this",
    "start": "1463320",
    "end": "1468679"
  },
  {
    "text": "GPU The v virtual machine is already running So we can connect to it using",
    "start": "1468679",
    "end": "1474720"
  },
  {
    "text": "vctl",
    "start": "1474720",
    "end": "1477720"
  },
  {
    "text": "Now we have a password",
    "start": "1480400",
    "end": "1484240"
  },
  {
    "text": "set We can use the same command for um",
    "start": "1490440",
    "end": "1495919"
  },
  {
    "text": "lspci",
    "start": "1495919",
    "end": "1498919"
  },
  {
    "text": "uh and we can see that there is um GPU existing inside of the virtual",
    "start": "1502799",
    "end": "1510120"
  },
  {
    "text": "machine Um let's try to consume it So now let's use um VCTL SSH command to get",
    "start": "1510120",
    "end": "1517440"
  },
  {
    "text": "access to our virtual machine Sometimes um the SSH of VCTL works not well So we",
    "start": "1517440",
    "end": "1524720"
  },
  {
    "text": "can use local SSH and you'll get access to the virtual machine",
    "start": "1524720",
    "end": "1531400"
  },
  {
    "text": "So now we are going to install Nvidia",
    "start": "1531679",
    "end": "1535919"
  },
  {
    "text": "drivers to let uh to have the opportunity consume this",
    "start": "1538919",
    "end": "1547120"
  },
  {
    "text": "GPU So after driver get installed you can use Nvidia tool to detect the GPU",
    "start": "1554760",
    "end": "1562559"
  },
  {
    "text": "inside of the virtual machine You can see um that um now it is using uh Nvidia",
    "start": "1562559",
    "end": "1569039"
  },
  {
    "text": "A10 card To test it we will use GPU start",
    "start": "1569039",
    "end": "1574960"
  },
  {
    "text": "application And now we can see that um driver is installed and everything is",
    "start": "1581720",
    "end": "1587919"
  },
  {
    "text": "working fine So you can use your workload to consume this GPU That's",
    "start": "1587919",
    "end": "1593840"
  },
  {
    "text": "actually it uh how it works inside of the virtual machines Uh in the latest",
    "start": "1593840",
    "end": "1599039"
  },
  {
    "text": "version of Cozy Stack we also introduced GPU support for tenant Kubernetes",
    "start": "1599039",
    "end": "1604840"
  },
  {
    "text": "clusters Uh let me first explain you how tenant Kubernetes clusters are",
    "start": "1604840",
    "end": "1610679"
  },
  {
    "text": "working Um at first we can get into catalog and we can install our",
    "start": "1610679",
    "end": "1617679"
  },
  {
    "text": "Kubernetes cluster by specifying name for it and this cluster has a",
    "start": "1617679",
    "end": "1624000"
  },
  {
    "text": "configuration for node groups So you can specify minimum replicas maximum",
    "start": "1624000",
    "end": "1629120"
  },
  {
    "text": "replicas um the amount of ephemeral storage the roles for the nodes and as well GPUs At",
    "start": "1629120",
    "end": "1638159"
  },
  {
    "text": "the beginning um I will not enable anything So we will create simple",
    "start": "1638159",
    "end": "1644240"
  },
  {
    "text": "Kubernetes cluster and wait until it get deployed You can see that um it has",
    "start": "1644240",
    "end": "1652520"
  },
  {
    "text": "workloads It has uh two control plane ports and um zero",
    "start": "1652520",
    "end": "1658679"
  },
  {
    "text": "workers So we need to wait a little bit We can also check the ports in our name",
    "start": "1658679",
    "end": "1664960"
  },
  {
    "text": "space It is going to provision also cluster",
    "start": "1664960",
    "end": "1670000"
  },
  {
    "text": "afterscaler uh cube controller manager and uh CSI",
    "start": "1670000",
    "end": "1676760"
  },
  {
    "text": "controller Um to provision cube Kubernetes clusters we use kamai Kamaji",
    "start": "1676760",
    "end": "1683440"
  },
  {
    "text": "has control plane uh resource which is currently",
    "start": "1683440",
    "end": "1690320"
  },
  {
    "text": "provisioning It gets data store assigned So here you use so it use etc from",
    "start": "1691159",
    "end": "1696640"
  },
  {
    "text": "tenant root and now we can see that it started",
    "start": "1696640",
    "end": "1702159"
  },
  {
    "text": "creating um kubernetes control",
    "start": "1702159",
    "end": "1706720"
  },
  {
    "text": "plane and after this control plane is created the cluster after scaler will",
    "start": "1708279",
    "end": "1713520"
  },
  {
    "text": "take a look inside of this control plane and will automatically create uh node",
    "start": "1713520",
    "end": "1719120"
  },
  {
    "text": "group out of u machine deployment",
    "start": "1719120",
    "end": "1723840"
  },
  {
    "text": "So for now we have single machine deployment which um have no replicas",
    "start": "1732159",
    "end": "1738200"
  },
  {
    "text": "assigned but in a while they should start to be",
    "start": "1738200",
    "end": "1743799"
  },
  {
    "text": "provisioned Okay cluster after scaler is",
    "start": "1743799",
    "end": "1748720"
  },
  {
    "text": "created and now we can see that it have assigned two worker nodes to our node",
    "start": "1749480",
    "end": "1756919"
  },
  {
    "text": "group and we can check VMs They also started to be provisioned",
    "start": "1756919",
    "end": "1764559"
  },
  {
    "text": "automatically Yeah they become running Now let's check what is inside",
    "start": "1765480",
    "end": "1772000"
  },
  {
    "text": "of the uh our dashboard We can see that control plane is ready and two worker",
    "start": "1772000",
    "end": "1777440"
  },
  {
    "text": "nodes are created Uh to consume this Kubernetes cluster you can download uh",
    "start": "1777440",
    "end": "1783919"
  },
  {
    "text": "tenant configuration file To do this you can download your secret admin",
    "start": "1783919",
    "end": "1790240"
  },
  {
    "text": "uh save as cube config for tenant cluster",
    "start": "1790240",
    "end": "1797039"
  },
  {
    "text": "uh you can see that now it go through our ingress So it has uh the specific",
    "start": "1797039",
    "end": "1805960"
  },
  {
    "text": "subdomain and also subdomain for tenant where it gets",
    "start": "1805960",
    "end": "1811720"
  },
  {
    "text": "deployed Let's use export to export our cube config",
    "start": "1811720",
    "end": "1817760"
  },
  {
    "text": "file and check what is happening inside So we can see two ingress nodes create",
    "start": "1817760",
    "end": "1825559"
  },
  {
    "text": "created that's actually worker nodes and we have already some",
    "start": "1825559",
    "end": "1832600"
  },
  {
    "text": "um pots or some workloads running actually selium cases driver core DNS",
    "start": "1832600",
    "end": "1839440"
  },
  {
    "text": "and connectivity agent So this way we can go back to our",
    "start": "1839440",
    "end": "1845360"
  },
  {
    "text": "management cluster by switching back to the uh old cube config file and get uh",
    "start": "1845360",
    "end": "1852240"
  },
  {
    "text": "kubernetes We can see that Kubernetes test is get",
    "start": "1852240",
    "end": "1860880"
  },
  {
    "text": "running and let's check what is inside actually the configuration we",
    "start": "1863159",
    "end": "1870799"
  },
  {
    "text": "specified node groups of this instance types max",
    "start": "1871799",
    "end": "1877120"
  },
  {
    "text": "replicas 10 min replicas zero",
    "start": "1877120",
    "end": "1882919"
  },
  {
    "text": "So now let's create Kubernetes uh with GPU Uh we will go to the uh catalog",
    "start": "1884080",
    "end": "1891360"
  },
  {
    "text": "Choose Kubernetes Click deploy Switch to YAML editor And in here we have node groups",
    "start": "1891360",
    "end": "1899039"
  },
  {
    "text": "uh configuration So we can create additional uh node group I'm going to",
    "start": "1899039",
    "end": "1904720"
  },
  {
    "text": "call it MD1 I want exactly one replica without after scaling Also we need to",
    "start": "1904720",
    "end": "1912240"
  },
  {
    "text": "specify better um instance type because the um smaller ones do not supported by",
    "start": "1912240",
    "end": "1921840"
  },
  {
    "text": "GPU operator and also I'm going to switch uh ephal storage to larger",
    "start": "1921840",
    "end": "1928279"
  },
  {
    "text": "one and in here you can specify GPU uh we specified for the virtual machine",
    "start": "1928279",
    "end": "1936720"
  },
  {
    "text": "uh so we can check um what the allocatable devices our node",
    "start": "1936720",
    "end": "1944200"
  },
  {
    "text": "has That's exactly the thing you have to specify",
    "start": "1944200",
    "end": "1949720"
  },
  {
    "text": "here Uh also we are going to enable search",
    "start": "1949720",
    "end": "1955200"
  },
  {
    "text": "manager jinxingress and GPU",
    "start": "1955399",
    "end": "1962559"
  },
  {
    "text": "operator That's probably it Now we can click deploy",
    "start": "1963559",
    "end": "1970120"
  },
  {
    "text": "and Kubernetes is getting to be",
    "start": "1974960",
    "end": "1980640"
  },
  {
    "text": "created inside of the uh console We can see",
    "start": "1983240",
    "end": "1988919"
  },
  {
    "text": "that tenant control plane from comm is going to be provisioned",
    "start": "1988919",
    "end": "1995679"
  },
  {
    "text": "It will take some time when it will generate cube config file and data",
    "start": "1995679",
    "end": "2002240"
  },
  {
    "text": "store Yeah now it get data store So we can check [Music]",
    "start": "2003320",
    "end": "2010279"
  },
  {
    "text": "pots It is still creating become to running So we can get",
    "start": "2010279",
    "end": "2018240"
  },
  {
    "text": "into the dashboard and download our cube config file",
    "start": "2018240",
    "end": "2024360"
  },
  {
    "text": "Let's save it to cube config",
    "start": "2025600",
    "end": "2029679"
  },
  {
    "text": "GPU and check the nodes You can see that our cluster have",
    "start": "2033880",
    "end": "2039840"
  },
  {
    "text": "no nodes yet It already have some pots pending but nodes are not started yet",
    "start": "2039840",
    "end": "2047360"
  },
  {
    "text": "So let's switch back to the management cluster and see and check how is it",
    "start": "2047360",
    "end": "2054440"
  },
  {
    "text": "going Uh here is MD1 our node with GPU and",
    "start": "2054440",
    "end": "2061720"
  },
  {
    "text": "MDO without GPU both are still in u",
    "start": "2061720",
    "end": "2067440"
  },
  {
    "text": "provisioning",
    "start": "2067440",
    "end": "2070078"
  },
  {
    "text": "state Okay the VMs are running So let's switch back to our",
    "start": "2073639",
    "end": "2079679"
  },
  {
    "text": "cluster They get",
    "start": "2083480",
    "end": "2087598"
  },
  {
    "text": "created and become ready We can also check pots in other name spaces We can",
    "start": "2090280",
    "end": "2097680"
  },
  {
    "text": "see that uh GPU operator is going to be created and jinxing grass Um to access",
    "start": "2097680",
    "end": "2107079"
  },
  {
    "text": "Jinxingress we can also uh update the configuration of our",
    "start": "2107079",
    "end": "2113520"
  },
  {
    "text": "cluster by specifying additional host names we want to pass through into into",
    "start": "2113720",
    "end": "2120560"
  },
  {
    "text": "the cluster I'm going to specify GPU",
    "start": "2120560",
    "end": "2127720"
  },
  {
    "text": "five infra So after we do this configuration",
    "start": "2127720",
    "end": "2135920"
  },
  {
    "text": "for ingress and jinx addon for this cluster it will take all the traffic and",
    "start": "2135920",
    "end": "2142160"
  },
  {
    "text": "pass through through the uh main ingress",
    "start": "2142160",
    "end": "2148000"
  },
  {
    "text": "controller inside of management cluster You can see that new ingress is",
    "start": "2149000",
    "end": "2155480"
  },
  {
    "text": "created for passing through all the traffic into jinxingress running inside",
    "start": "2155480",
    "end": "2161520"
  },
  {
    "text": "of the tenant",
    "start": "2161520",
    "end": "2164320"
  },
  {
    "text": "Kubernetes It seems our ingress is not ready",
    "start": "2172200",
    "end": "2177800"
  },
  {
    "text": "yet One replica become ready So we can check it with serial command and it will",
    "start": "2177800",
    "end": "2186480"
  },
  {
    "text": "report um default back end that's actually exactly this part um responding",
    "start": "2186480",
    "end": "2193680"
  },
  {
    "text": "to the uh our",
    "start": "2193680",
    "end": "2197440"
  },
  {
    "text": "requests We can also check the pots inside of the cozy GPU operator name",
    "start": "2198920",
    "end": "2205119"
  },
  {
    "text": "space We can see that new demon set is running This demon set is actually",
    "start": "2205119",
    "end": "2213040"
  },
  {
    "text": "downloading GPU drivers and installing it into our uh virtual machine This way",
    "start": "2213040",
    "end": "2220480"
  },
  {
    "text": "it allows you to uh specify exact driver you want to you can have open source",
    "start": "2220480",
    "end": "2226960"
  },
  {
    "text": "driver You can use proprietary one with different versions",
    "start": "2226960",
    "end": "2232240"
  },
  {
    "text": "um Nvidia GPU will automatically download specified versions",
    "start": "2232240",
    "end": "2237920"
  },
  {
    "text": "uh and inject it into your kernel You can see that uh there are Nvidia drivers",
    "start": "2237920",
    "end": "2245520"
  },
  {
    "text": "getting to be um created in the node We",
    "start": "2245520",
    "end": "2251119"
  },
  {
    "text": "can also check the pots and we need to have all the pots in",
    "start": "2251119",
    "end": "2258800"
  },
  {
    "text": "this name space in running state before we can",
    "start": "2258800",
    "end": "2264160"
  },
  {
    "text": "continue Okay now it seems ready So let's try to demonstrate",
    "start": "2264599",
    "end": "2270880"
  },
  {
    "text": "um how can we use it to demonstrate the work of uh GPU operator inside of the",
    "start": "2270880",
    "end": "2277119"
  },
  {
    "text": "tenant Kubernetes cluster I'm going to use table diffusion chart uh which I",
    "start": "2277119",
    "end": "2282560"
  },
  {
    "text": "downloaded from this repository Um the only thing it is",
    "start": "2282560",
    "end": "2289839"
  },
  {
    "text": "slightly updated so I was forced to change the model address",
    "start": "2289839",
    "end": "2296400"
  },
  {
    "text": "uh because the old one is not accessible anymore I have prepared values file where also",
    "start": "2296400",
    "end": "2303440"
  },
  {
    "text": "specified the host uh for the ingress and also enable TLS and",
    "start": "2303440",
    "end": "2311200"
  },
  {
    "text": "automatic um certificates um issued by search",
    "start": "2311200",
    "end": "2318280"
  },
  {
    "text": "manager to make it working I also need to create uh certificate issuers for",
    "start": "2318280",
    "end": "2325280"
  },
  {
    "text": "let's encrypt and now let's install the helm chart with helm install command and",
    "start": "2325280",
    "end": "2332240"
  },
  {
    "text": "with our values files it will actually create stateful set pot and pvc so the",
    "start": "2332240",
    "end": "2340320"
  },
  {
    "text": "good question where the data is stored uh actually we use persistent volume claim created inside of the management",
    "start": "2340320",
    "end": "2347640"
  },
  {
    "text": "cluster it get volumes provisioned and pass it through into tenant Kubernetes",
    "start": "2347640",
    "end": "2353200"
  },
  {
    "text": "cluster Let's check how it looks like For this we need to switch back to the",
    "start": "2353200",
    "end": "2359599"
  },
  {
    "text": "management Kubernetes cluster Uh we can see",
    "start": "2359599",
    "end": "2365240"
  },
  {
    "text": "that it has persistent volume provisioned for the tenant Kubernetes",
    "start": "2365240",
    "end": "2370400"
  },
  {
    "text": "cluster and the hot plug volume created Um this is actually pot",
    "start": "2370400",
    "end": "2378160"
  },
  {
    "text": "uh it use it for um attaching this persistent volume claim and it is always",
    "start": "2378160",
    "end": "2384400"
  },
  {
    "text": "running at the same node where the virtual machine is running Then cube uh",
    "start": "2384400",
    "end": "2389520"
  },
  {
    "text": "has its own logic to pass through this uh device directly into the virtual",
    "start": "2389520",
    "end": "2395200"
  },
  {
    "text": "machine So let's switch back to the um GPU cluster and check the pot",
    "start": "2395200",
    "end": "2403040"
  },
  {
    "text": "We can uh describe to see the state Uh we can see that it is already",
    "start": "2403040",
    "end": "2411200"
  },
  {
    "text": "finished the uh init container job Let's check the",
    "start": "2411200",
    "end": "2418000"
  },
  {
    "text": "logs Uh in this init container it downloads models and places into the",
    "start": "2418440",
    "end": "2424800"
  },
  {
    "text": "persistent volume created for this virtual machine for this pot And now it",
    "start": "2424800",
    "end": "2431520"
  },
  {
    "text": "is about to pull this image It is quite",
    "start": "2431520",
    "end": "2436960"
  },
  {
    "text": "uh thick So we can wait for a while until this image get",
    "start": "2436960",
    "end": "2443760"
  },
  {
    "text": "pulled Yeah now it seems running So we can access it through our",
    "start": "2444040",
    "end": "2452720"
  },
  {
    "text": "web browser",
    "start": "2452720",
    "end": "2456040"
  },
  {
    "text": "And here it is We have stable diffusion running on our cozy stack tenant",
    "start": "2461920",
    "end": "2467119"
  },
  {
    "text": "Kubernetes cluster And let's try to test it We can write a",
    "start": "2467119",
    "end": "2474078"
  },
  {
    "text": "prompt We can see some pictures All right Doc watching terminal",
    "start": "2487560",
    "end": "2497720"
  },
  {
    "text": "Let's try train to the future Seems",
    "start": "2503920",
    "end": "2511520"
  },
  {
    "text": "better Just nature Beautiful pictures",
    "start": "2517800",
    "end": "2525599"
  },
  {
    "text": "All right that's actually all I wanted to show you You can use cozy stack to run fully functional Kubernetes clusters",
    "start": "2525599",
    "end": "2532960"
  },
  {
    "text": "virtual machines and as well databases Now you can also use GPU workloads in",
    "start": "2532960",
    "end": "2538240"
  },
  {
    "text": "your clusters And here is practical example Please feel free to join our community channels We have Telegram",
    "start": "2538240",
    "end": "2545200"
  },
  {
    "text": "group and Slack channel in official Kubernetes Slack And if you're interested in enterprise support or if",
    "start": "2545200",
    "end": "2552480"
  },
  {
    "text": "you want to sponsor some features feel free to contact Enix Thank you and bye",
    "start": "2552480",
    "end": "2561359"
  }
]
[
  {
    "text": "hello everyone I am Vino and today I'm",
    "start": "120",
    "end": "3300"
  },
  {
    "text": "going to talk about building CI CD for",
    "start": "3300",
    "end": "5880"
  },
  {
    "text": "data and how can you use an existing set",
    "start": "5880",
    "end": "9059"
  },
  {
    "text": "of Open Source tools to build the CI CD",
    "start": "9059",
    "end": "12000"
  },
  {
    "text": "pipeline for your data lakes and before",
    "start": "12000",
    "end": "15480"
  },
  {
    "text": "we jump into the talk a brief intro of",
    "start": "15480",
    "end": "18000"
  },
  {
    "text": "you know who I am what my background is",
    "start": "18000",
    "end": "19800"
  },
  {
    "text": "I started out as a software engineer and",
    "start": "19800",
    "end": "22320"
  },
  {
    "text": "then I moved on to work in the data and",
    "start": "22320",
    "end": "23939"
  },
  {
    "text": "ml engineering space and currently I",
    "start": "23939",
    "end": "26519"
  },
  {
    "text": "work as a developer advocate for Lake FS",
    "start": "26519",
    "end": "29000"
  },
  {
    "text": "lakefs is an open source data versioning",
    "start": "29000",
    "end": "31859"
  },
  {
    "text": "engine that offers git like interface",
    "start": "31859",
    "end": "34200"
  },
  {
    "text": "for your data Lake",
    "start": "34200",
    "end": "36140"
  },
  {
    "text": "and more on that later of course",
    "start": "36140",
    "end": "39239"
  },
  {
    "text": "let's Dive Right In",
    "start": "39239",
    "end": "40980"
  },
  {
    "text": "I was a data engineer before and this is",
    "start": "40980",
    "end": "43440"
  },
  {
    "text": "more or less a very accurate description",
    "start": "43440",
    "end": "45420"
  },
  {
    "text": "of what I expected my job would be and",
    "start": "45420",
    "end": "48300"
  },
  {
    "text": "what it turned out to be and most of the",
    "start": "48300",
    "end": "50640"
  },
  {
    "text": "data pipelines today that we write do",
    "start": "50640",
    "end": "53399"
  },
  {
    "text": "not behave in a predictable manner or in",
    "start": "53399",
    "end": "55739"
  },
  {
    "text": "a way that we coded there are a lot of",
    "start": "55739",
    "end": "58320"
  },
  {
    "text": "changes that might happen in the",
    "start": "58320",
    "end": "60239"
  },
  {
    "text": "infrastructure side of it or the",
    "start": "60239",
    "end": "61680"
  },
  {
    "text": "business side of it that might lead to",
    "start": "61680",
    "end": "63840"
  },
  {
    "text": "breaking your data Pipelines",
    "start": "63840",
    "end": "66380"
  },
  {
    "text": "what are those changes that might break",
    "start": "66380",
    "end": "68820"
  },
  {
    "text": "your pipeline it could be anywhere",
    "start": "68820",
    "end": "70740"
  },
  {
    "text": "starting from EMR upgrade or spark you",
    "start": "70740",
    "end": "73979"
  },
  {
    "text": "know version upgrade that you're trying",
    "start": "73979",
    "end": "75240"
  },
  {
    "text": "to do or any infrastructure changes that",
    "start": "75240",
    "end": "77460"
  },
  {
    "text": "is coming up I don't know if you're you",
    "start": "77460",
    "end": "79200"
  },
  {
    "text": "know migrating from Snowflake to",
    "start": "79200",
    "end": "80640"
  },
  {
    "text": "bigquery and whatnot or sometimes it it",
    "start": "80640",
    "end": "83759"
  },
  {
    "text": "comes in from the business side where",
    "start": "83759",
    "end": "85380"
  },
  {
    "text": "you know your marketing team has updated",
    "start": "85380",
    "end": "87119"
  },
  {
    "text": "a definition of a kpi that they've been",
    "start": "87119",
    "end": "89759"
  },
  {
    "text": "tracking and now you suddenly have to",
    "start": "89759",
    "end": "91799"
  },
  {
    "text": "rerun your entire data pipeline to",
    "start": "91799",
    "end": "93780"
  },
  {
    "text": "arrive at the new metrics or to back to",
    "start": "93780",
    "end": "96000"
  },
  {
    "text": "backfill their kpi metric for all the",
    "start": "96000",
    "end": "98220"
  },
  {
    "text": "history historic period",
    "start": "98220",
    "end": "100200"
  },
  {
    "text": "and again troubleshooting failed spark",
    "start": "100200",
    "end": "102720"
  },
  {
    "text": "jobs none of our favorite but we still",
    "start": "102720",
    "end": "105180"
  },
  {
    "text": "have to do because that's part of the",
    "start": "105180",
    "end": "106740"
  },
  {
    "text": "responsibilities of a data engineering",
    "start": "106740",
    "end": "108780"
  },
  {
    "text": "team that we're you know working with",
    "start": "108780",
    "end": "110579"
  },
  {
    "text": "and non-ident pipelines of course most",
    "start": "110579",
    "end": "113759"
  },
  {
    "text": "of the times when we deal with pipelines",
    "start": "113759",
    "end": "115320"
  },
  {
    "text": "or the job runs that has failed we want",
    "start": "115320",
    "end": "118079"
  },
  {
    "text": "to write item put in pipeline so you",
    "start": "118079",
    "end": "120060"
  },
  {
    "text": "just click a rerun and it reruns",
    "start": "120060",
    "end": "121740"
  },
  {
    "text": "end-to-end but it does not happen very",
    "start": "121740",
    "end": "123780"
  },
  {
    "text": "often and do I also need to talk about",
    "start": "123780",
    "end": "126420"
  },
  {
    "text": "the Legacy dags that none of us want to",
    "start": "126420",
    "end": "128520"
  },
  {
    "text": "touch but at some point we do have to",
    "start": "128520",
    "end": "130619"
  },
  {
    "text": "make changes at least to keep them",
    "start": "130619",
    "end": "132480"
  },
  {
    "text": "running you know for a longer period of",
    "start": "132480",
    "end": "134580"
  },
  {
    "text": "time",
    "start": "134580",
    "end": "135480"
  },
  {
    "text": "so the challenges or the changes to your",
    "start": "135480",
    "end": "137879"
  },
  {
    "text": "data pipeline could be more than this",
    "start": "137879",
    "end": "140459"
  },
  {
    "text": "but this is only a limited experience or",
    "start": "140459",
    "end": "142980"
  },
  {
    "text": "a limited list from my experience",
    "start": "142980",
    "end": "145260"
  },
  {
    "text": "and now we have this host of changes",
    "start": "145260",
    "end": "147540"
  },
  {
    "text": "that can break your data pipeline what",
    "start": "147540",
    "end": "149879"
  },
  {
    "text": "can we do about it how can we make sure",
    "start": "149879",
    "end": "151620"
  },
  {
    "text": "that our pipeline is so robust right",
    "start": "151620",
    "end": "154319"
  },
  {
    "text": "pretty standard when you're thinking",
    "start": "154319",
    "end": "155879"
  },
  {
    "text": "about making your software robust or",
    "start": "155879",
    "end": "157920"
  },
  {
    "text": "your software application robust we",
    "start": "157920",
    "end": "159480"
  },
  {
    "text": "think about increasing or exhaustively",
    "start": "159480",
    "end": "161819"
  },
  {
    "text": "testing our software application but for",
    "start": "161819",
    "end": "164160"
  },
  {
    "text": "some reason we thought in the data world",
    "start": "164160",
    "end": "166860"
  },
  {
    "text": "we could just you know run our pipelines",
    "start": "166860",
    "end": "169379"
  },
  {
    "text": "without testing them enough and I have",
    "start": "169379",
    "end": "171840"
  },
  {
    "text": "been in the past guilty of working",
    "start": "171840",
    "end": "173940"
  },
  {
    "text": "directly with the production data and",
    "start": "173940",
    "end": "176280"
  },
  {
    "text": "not necessarily testing the pipelines",
    "start": "176280",
    "end": "177900"
  },
  {
    "text": "before I push my data into Broad",
    "start": "177900",
    "end": "180720"
  },
  {
    "text": "so we have these standard you know",
    "start": "180720",
    "end": "182700"
  },
  {
    "text": "testing we would you know borrow from",
    "start": "182700",
    "end": "184920"
  },
  {
    "text": "the software engineering World unit",
    "start": "184920",
    "end": "186599"
  },
  {
    "text": "testing of course black box and",
    "start": "186599",
    "end": "189000"
  },
  {
    "text": "integration testing is more important",
    "start": "189000",
    "end": "190739"
  },
  {
    "text": "here more than the other ones because",
    "start": "190739",
    "end": "193080"
  },
  {
    "text": "when you think about data pipelines you",
    "start": "193080",
    "end": "195060"
  },
  {
    "text": "have multiple data sources that are",
    "start": "195060",
    "end": "197760"
  },
  {
    "text": "writing or your data pipeline is reading",
    "start": "197760",
    "end": "200220"
  },
  {
    "text": "from all these multiple data sources and",
    "start": "200220",
    "end": "202379"
  },
  {
    "text": "at the end of the day your data pipeline",
    "start": "202379",
    "end": "203700"
  },
  {
    "text": "is again a complex Transformations which",
    "start": "203700",
    "end": "207420"
  },
  {
    "text": "are in multi-steps and then the other",
    "start": "207420",
    "end": "209700"
  },
  {
    "text": "end we also have multiple consumers",
    "start": "209700",
    "end": "211680"
  },
  {
    "text": "sometimes",
    "start": "211680",
    "end": "212819"
  },
  {
    "text": "read even concurrently from your data",
    "start": "212819",
    "end": "215159"
  },
  {
    "text": "pipelines or these transform data",
    "start": "215159",
    "end": "218400"
  },
  {
    "text": "and because of this complex ETL setup we",
    "start": "218400",
    "end": "222299"
  },
  {
    "text": "need to make sure we do the integration",
    "start": "222299",
    "end": "223980"
  },
  {
    "text": "testing or end-to-end testing of our",
    "start": "223980",
    "end": "225780"
  },
  {
    "text": "pipelines and not just stick to the",
    "start": "225780",
    "end": "227760"
  },
  {
    "text": "basic unit testing of the Black Box",
    "start": "227760",
    "end": "229319"
  },
  {
    "text": "testing ones but then easier said than",
    "start": "229319",
    "end": "231959"
  },
  {
    "text": "done right because in the data pipeline",
    "start": "231959",
    "end": "234420"
  },
  {
    "text": "world when you're talking about testing",
    "start": "234420",
    "end": "236640"
  },
  {
    "text": "it is Data heavy",
    "start": "236640",
    "end": "239159"
  },
  {
    "text": "and you need production like data to be",
    "start": "239159",
    "end": "241440"
  },
  {
    "text": "able to test your data pipelines and",
    "start": "241440",
    "end": "243900"
  },
  {
    "text": "where do we get production like data",
    "start": "243900",
    "end": "246540"
  },
  {
    "text": "again there is a spectrum of what we do",
    "start": "246540",
    "end": "248700"
  },
  {
    "text": "today some of us we try to Mock You Know",
    "start": "248700",
    "end": "251760"
  },
  {
    "text": "sample data and try to use that data to",
    "start": "251760",
    "end": "253799"
  },
  {
    "text": "test our Pipelines again it's not going",
    "start": "253799",
    "end": "256019"
  },
  {
    "text": "to reflect the you know entire scale and",
    "start": "256019",
    "end": "258000"
  },
  {
    "text": "the variation and the volume of the",
    "start": "258000",
    "end": "259500"
  },
  {
    "text": "production data but it helps us to some",
    "start": "259500",
    "end": "261540"
  },
  {
    "text": "extent to identify the you know",
    "start": "261540",
    "end": "263600"
  },
  {
    "text": "loopholes or the bugs in the pipeline",
    "start": "263600",
    "end": "266940"
  },
  {
    "text": "and then some of us go one level further",
    "start": "266940",
    "end": "269340"
  },
  {
    "text": "and copy",
    "start": "269340",
    "end": "271500"
  },
  {
    "text": "part of the production data into a test",
    "start": "271500",
    "end": "273479"
  },
  {
    "text": "or staging environment and try to use",
    "start": "273479",
    "end": "275460"
  },
  {
    "text": "that to test our pipelines again when",
    "start": "275460",
    "end": "278040"
  },
  {
    "text": "you're copying the data it doesn't",
    "start": "278040",
    "end": "279540"
  },
  {
    "text": "matter if you copy part of the",
    "start": "279540",
    "end": "280800"
  },
  {
    "text": "production or all of the production data",
    "start": "280800",
    "end": "282660"
  },
  {
    "text": "now you suddenly have instead of just",
    "start": "282660",
    "end": "285000"
  },
  {
    "text": "one place you have n copies of data",
    "start": "285000",
    "end": "287699"
  },
  {
    "text": "lying around now you need to make sure",
    "start": "287699",
    "end": "289620"
  },
  {
    "text": "all the data integration practices in",
    "start": "289620",
    "end": "291540"
  },
  {
    "text": "the pii",
    "start": "291540",
    "end": "292940"
  },
  {
    "text": "enforcements that you've been doing in",
    "start": "292940",
    "end": "294720"
  },
  {
    "text": "production needs to be applied to all",
    "start": "294720",
    "end": "296820"
  },
  {
    "text": "the other environments as well",
    "start": "296820",
    "end": "298800"
  },
  {
    "text": "this makes it the ETL testing or the",
    "start": "298800",
    "end": "301740"
  },
  {
    "text": "data pipeline testing a lot more complex",
    "start": "301740",
    "end": "303720"
  },
  {
    "text": "than software testing",
    "start": "303720",
    "end": "306720"
  },
  {
    "text": "now",
    "start": "306720",
    "end": "309259"
  },
  {
    "text": "when we want to do the data pipeline",
    "start": "309419",
    "end": "311759"
  },
  {
    "text": "testing the ideas here to probably copy",
    "start": "311759",
    "end": "315360"
  },
  {
    "text": "the best practices that are already",
    "start": "315360",
    "end": "316680"
  },
  {
    "text": "solved and established in the software",
    "start": "316680",
    "end": "318479"
  },
  {
    "text": "engineering world and then extend them",
    "start": "318479",
    "end": "320759"
  },
  {
    "text": "to the data engineering or the ETL",
    "start": "320759",
    "end": "322560"
  },
  {
    "text": "pipeline testing standard as it goes is",
    "start": "322560",
    "end": "325440"
  },
  {
    "text": "you know you have built tests and the",
    "start": "325440",
    "end": "326940"
  },
  {
    "text": "deploy phase and we make sure at each of",
    "start": "326940",
    "end": "328860"
  },
  {
    "text": "these faces we test our assets or these",
    "start": "328860",
    "end": "332039"
  },
  {
    "text": "applications",
    "start": "332039",
    "end": "333479"
  },
  {
    "text": "and make sure only the quality or",
    "start": "333479",
    "end": "336600"
  },
  {
    "text": "the data that passes certain tests are",
    "start": "336600",
    "end": "339840"
  },
  {
    "text": "promoted to the next stage",
    "start": "339840",
    "end": "342300"
  },
  {
    "text": "so while in the software development",
    "start": "342300",
    "end": "344280"
  },
  {
    "text": "world we might have in the build phase",
    "start": "344280",
    "end": "346020"
  },
  {
    "text": "we want to keep all the resources or the",
    "start": "346020",
    "end": "348120"
  },
  {
    "text": "data source code Version Control and in",
    "start": "348120",
    "end": "351060"
  },
  {
    "text": "the test phase we want to create you",
    "start": "351060",
    "end": "352680"
  },
  {
    "text": "know all these sandbox environments on",
    "start": "352680",
    "end": "354300"
  },
  {
    "text": "demand to run out you know",
    "start": "354300",
    "end": "356720"
  },
  {
    "text": "testing of our applications and in the",
    "start": "356720",
    "end": "359699"
  },
  {
    "text": "deploy phase we of course want to do",
    "start": "359699",
    "end": "361320"
  },
  {
    "text": "code reviews and make sure only the high",
    "start": "361320",
    "end": "362880"
  },
  {
    "text": "quality code gets into production",
    "start": "362880",
    "end": "365039"
  },
  {
    "text": "similarly in the data phase we want to",
    "start": "365039",
    "end": "368039"
  },
  {
    "text": "version all of the data assets together",
    "start": "368039",
    "end": "370860"
  },
  {
    "text": "in the build phase and then create",
    "start": "370860",
    "end": "373320"
  },
  {
    "text": "isolated data environments what I mean",
    "start": "373320",
    "end": "375780"
  },
  {
    "text": "by that is not just copying around",
    "start": "375780",
    "end": "377460"
  },
  {
    "text": "production data into multiple",
    "start": "377460",
    "end": "379860"
  },
  {
    "text": "testing or Dev stages but having this",
    "start": "379860",
    "end": "383100"
  },
  {
    "text": "ability to isolated",
    "start": "383100",
    "end": "384840"
  },
  {
    "text": "create these isolated data environments",
    "start": "384840",
    "end": "386880"
  },
  {
    "text": "but that are not necessarily just copies",
    "start": "386880",
    "end": "388740"
  },
  {
    "text": "of existing production data",
    "start": "388740",
    "end": "391319"
  },
  {
    "text": "and of course in the deploy phase we",
    "start": "391319",
    "end": "393180"
  },
  {
    "text": "also want to run a continuous",
    "start": "393180",
    "end": "394620"
  },
  {
    "text": "Integrations test or the CI Suite to you",
    "start": "394620",
    "end": "398039"
  },
  {
    "text": "know have a defined data quality test",
    "start": "398039",
    "end": "400080"
  },
  {
    "text": "and only the data that goes through",
    "start": "400080",
    "end": "402479"
  },
  {
    "text": "these tests and is successfully passing",
    "start": "402479",
    "end": "404400"
  },
  {
    "text": "is only promoted to your production and",
    "start": "404400",
    "end": "407460"
  },
  {
    "text": "as always it despite doing all these",
    "start": "407460",
    "end": "409979"
  },
  {
    "text": "checks and you know validations in place",
    "start": "409979",
    "end": "412380"
  },
  {
    "text": "you might still run into some production",
    "start": "412380",
    "end": "414300"
  },
  {
    "text": "errors so we also need a way of",
    "start": "414300",
    "end": "415860"
  },
  {
    "text": "automatically rolling back to a",
    "start": "415860",
    "end": "418080"
  },
  {
    "text": "consistent state of data suppose if you",
    "start": "418080",
    "end": "420060"
  },
  {
    "text": "still get into some production errors",
    "start": "420060",
    "end": "422880"
  },
  {
    "text": "these are almost like the top five best",
    "start": "422880",
    "end": "425400"
  },
  {
    "text": "practices that we you know take from the",
    "start": "425400",
    "end": "427500"
  },
  {
    "text": "software engineering world and try to",
    "start": "427500",
    "end": "428940"
  },
  {
    "text": "apply it to the data engineering or the",
    "start": "428940",
    "end": "430560"
  },
  {
    "text": "data pipeline side of things",
    "start": "430560",
    "end": "432419"
  },
  {
    "text": "and how do we do this let's just start",
    "start": "432419",
    "end": "435180"
  },
  {
    "text": "with you know one phase at a time and in",
    "start": "435180",
    "end": "437699"
  },
  {
    "text": "the build phase we want to place all our",
    "start": "437699",
    "end": "439740"
  },
  {
    "text": "data assets under Version Control",
    "start": "439740",
    "end": "442259"
  },
  {
    "text": "and when I say data assets I'm not",
    "start": "442259",
    "end": "444300"
  },
  {
    "text": "talking about just file level versioning",
    "start": "444300",
    "end": "446220"
  },
  {
    "text": "or even table level versioning today we",
    "start": "446220",
    "end": "449099"
  },
  {
    "text": "have different Open Table formats talk",
    "start": "449099",
    "end": "451620"
  },
  {
    "text": "about Apache Iceberg who D or even Delta",
    "start": "451620",
    "end": "454319"
  },
  {
    "text": "Lake that will give you these table",
    "start": "454319",
    "end": "456000"
  },
  {
    "text": "level versioning but then we want to",
    "start": "456000",
    "end": "458160"
  },
  {
    "text": "version the entire data lake or the",
    "start": "458160",
    "end": "461160"
  },
  {
    "text": "entire data repository needs to be",
    "start": "461160",
    "end": "463259"
  },
  {
    "text": "versioned which is why which is how you",
    "start": "463259",
    "end": "465300"
  },
  {
    "text": "can bring all your data assets under one",
    "start": "465300",
    "end": "467220"
  },
  {
    "text": "version",
    "start": "467220",
    "end": "468180"
  },
  {
    "text": "control system",
    "start": "468180",
    "end": "469919"
  },
  {
    "text": "and how exactly can you do this",
    "start": "469919",
    "end": "472199"
  },
  {
    "text": "this is where Lake FS comes in and like",
    "start": "472199",
    "end": "474840"
  },
  {
    "text": "I introduced lakefest before it is an",
    "start": "474840",
    "end": "477120"
  },
  {
    "text": "open source",
    "start": "477120",
    "end": "478680"
  },
  {
    "text": "data versioning engine",
    "start": "478680",
    "end": "480960"
  },
  {
    "text": "that offers git like API",
    "start": "480960",
    "end": "483300"
  },
  {
    "text": "and if you can look at it here it sits",
    "start": "483300",
    "end": "486120"
  },
  {
    "text": "at the lake efficets as a metadata or",
    "start": "486120",
    "end": "488580"
  },
  {
    "text": "versioning layer on top of your Object",
    "start": "488580",
    "end": "490800"
  },
  {
    "text": "Store the object store being any of",
    "start": "490800",
    "end": "492960"
  },
  {
    "text": "these you know Cloud providers S3 minio",
    "start": "492960",
    "end": "495660"
  },
  {
    "text": "Azure blob or GCS and like FS it's on",
    "start": "495660",
    "end": "499259"
  },
  {
    "text": "top of these and it provides git like",
    "start": "499259",
    "end": "501060"
  },
  {
    "text": "apis it could be you know create a",
    "start": "501060",
    "end": "503460"
  },
  {
    "text": "branch commit merge or even revert apis",
    "start": "503460",
    "end": "506940"
  },
  {
    "text": "exactly similar to git so you can",
    "start": "506940",
    "end": "509220"
  },
  {
    "text": "perform all the operations that you were",
    "start": "509220",
    "end": "510900"
  },
  {
    "text": "doing on your source code using git you",
    "start": "510900",
    "end": "514500"
  },
  {
    "text": "can do the exact same things with lakefs",
    "start": "514500",
    "end": "516419"
  },
  {
    "text": "on your data",
    "start": "516419",
    "end": "518099"
  },
  {
    "text": "and if you do have a current host of",
    "start": "518099",
    "end": "519899"
  },
  {
    "text": "applications who are already reading",
    "start": "519899",
    "end": "522180"
  },
  {
    "text": "from your existing Object Store now you",
    "start": "522180",
    "end": "524640"
  },
  {
    "text": "can read them through lakefs with the",
    "start": "524640",
    "end": "526680"
  },
  {
    "text": "versioning enabled as well and if on the",
    "start": "526680",
    "end": "529140"
  },
  {
    "text": "right side if you have a look at it this",
    "start": "529140",
    "end": "530820"
  },
  {
    "text": "is how it looks that the minimal",
    "start": "530820",
    "end": "532140"
  },
  {
    "text": "intervention to your existing code you",
    "start": "532140",
    "end": "534720"
  },
  {
    "text": "will have data versioning enabled",
    "start": "534720",
    "end": "537660"
  },
  {
    "text": "if you look at the S3 path right if you",
    "start": "537660",
    "end": "539700"
  },
  {
    "text": "already have your data repository under",
    "start": "539700",
    "end": "541320"
  },
  {
    "text": "a specific path by by having lakefest",
    "start": "541320",
    "end": "544320"
  },
  {
    "text": "sit in between your applications and",
    "start": "544320",
    "end": "545940"
  },
  {
    "text": "your Object Store all you're doing is",
    "start": "545940",
    "end": "548040"
  },
  {
    "text": "just adding an extra prefix in your S3",
    "start": "548040",
    "end": "551040"
  },
  {
    "text": "path which is the name of the branch and",
    "start": "551040",
    "end": "553080"
  },
  {
    "text": "it will help you identify which branch",
    "start": "553080",
    "end": "555000"
  },
  {
    "text": "specific data specific file belongs to",
    "start": "555000",
    "end": "558120"
  },
  {
    "text": "and",
    "start": "558120",
    "end": "559500"
  },
  {
    "text": "earlier I talked about creating",
    "start": "559500",
    "end": "562860"
  },
  {
    "text": "on demand data environments",
    "start": "562860",
    "end": "565740"
  },
  {
    "text": "without you know copying the exact data",
    "start": "565740",
    "end": "568080"
  },
  {
    "text": "right so you can do that by simply doing",
    "start": "568080",
    "end": "570180"
  },
  {
    "text": "a branch create so when you create a",
    "start": "570180",
    "end": "572459"
  },
  {
    "text": "branch from your actual data repository",
    "start": "572459",
    "end": "574800"
  },
  {
    "text": "you create these isolated data",
    "start": "574800",
    "end": "576839"
  },
  {
    "text": "environments exactly when you need",
    "start": "576839",
    "end": "580500"
  },
  {
    "text": "and to understand how exactly are these",
    "start": "580500",
    "end": "583500"
  },
  {
    "text": "branches created",
    "start": "583500",
    "end": "585120"
  },
  {
    "text": "are these when I create a new Branch am",
    "start": "585120",
    "end": "587640"
  },
  {
    "text": "I copying all of the data from",
    "start": "587640",
    "end": "589140"
  },
  {
    "text": "production into a new you know staging",
    "start": "589140",
    "end": "591240"
  },
  {
    "text": "or a Dev environment not exactly so",
    "start": "591240",
    "end": "594300"
  },
  {
    "text": "let's just dive into a quick overview of",
    "start": "594300",
    "end": "596580"
  },
  {
    "text": "how lakefs Works inside right",
    "start": "596580",
    "end": "599959"
  },
  {
    "text": "commits are just a bunch of collection",
    "start": "599959",
    "end": "602880"
  },
  {
    "text": "of pointers so you have storage object",
    "start": "602880",
    "end": "605399"
  },
  {
    "text": "objects underneath you hash the storage",
    "start": "605399",
    "end": "607380"
  },
  {
    "text": "objects you create a couple of you know",
    "start": "607380",
    "end": "609060"
  },
  {
    "text": "hashes and then you",
    "start": "609060",
    "end": "611700"
  },
  {
    "text": "reference those hashes for each of these",
    "start": "611700",
    "end": "613740"
  },
  {
    "text": "commits so even when you are trying to",
    "start": "613740",
    "end": "616200"
  },
  {
    "text": "create a new Branch it's just copying",
    "start": "616200",
    "end": "618480"
  },
  {
    "text": "those pointers or copying those hashes",
    "start": "618480",
    "end": "620339"
  },
  {
    "text": "of these underlying objects if you have",
    "start": "620339",
    "end": "622620"
  },
  {
    "text": "a petabyte scale data Lake when you're",
    "start": "622620",
    "end": "624540"
  },
  {
    "text": "trying to create a new Branch you're not",
    "start": "624540",
    "end": "626220"
  },
  {
    "text": "copying again petabytes of data into",
    "start": "626220",
    "end": "628019"
  },
  {
    "text": "another bucket you're just copying",
    "start": "628019",
    "end": "630000"
  },
  {
    "text": "pointers to those and of course the",
    "start": "630000",
    "end": "632880"
  },
  {
    "text": "minute you start changing the data",
    "start": "632880",
    "end": "634440"
  },
  {
    "text": "that's underneath let's say you deleted",
    "start": "634440",
    "end": "636480"
  },
  {
    "text": "an object and then committed it at that",
    "start": "636480",
    "end": "638399"
  },
  {
    "text": "time you want to delete the object",
    "start": "638399",
    "end": "639779"
  },
  {
    "text": "reference as well and if you write",
    "start": "639779",
    "end": "641519"
  },
  {
    "text": "something new like FS also does copy on",
    "start": "641519",
    "end": "643680"
  },
  {
    "text": "write so it is available for the future",
    "start": "643680",
    "end": "645480"
  },
  {
    "text": "commits so by sharing these pointers it",
    "start": "645480",
    "end": "648180"
  },
  {
    "text": "is not necessarily copying the data from",
    "start": "648180",
    "end": "651000"
  },
  {
    "text": "one branch to another it's just you know",
    "start": "651000",
    "end": "653160"
  },
  {
    "text": "all the branches refer to the same",
    "start": "653160",
    "end": "654420"
  },
  {
    "text": "pointers underneath",
    "start": "654420",
    "end": "656100"
  },
  {
    "text": "now if you think about it if you want to",
    "start": "656100",
    "end": "658019"
  },
  {
    "text": "create a new test data environment all",
    "start": "658019",
    "end": "660180"
  },
  {
    "text": "you need to do is create a branch and",
    "start": "660180",
    "end": "662160"
  },
  {
    "text": "even if you have petabyte scale data",
    "start": "662160",
    "end": "664800"
  },
  {
    "text": "Lake because this is a metadata only",
    "start": "664800",
    "end": "666720"
  },
  {
    "text": "operation like a point or only operation",
    "start": "666720",
    "end": "668640"
  },
  {
    "text": "it would only take few milliseconds",
    "start": "668640",
    "end": "670140"
  },
  {
    "text": "instead of copying the production data",
    "start": "670140",
    "end": "672300"
  },
  {
    "text": "which would take at least hours you",
    "start": "672300",
    "end": "674160"
  },
  {
    "text": "would take a quick coffee break and then",
    "start": "674160",
    "end": "675540"
  },
  {
    "text": "come back okay it's done now I can start",
    "start": "675540",
    "end": "677160"
  },
  {
    "text": "working",
    "start": "677160",
    "end": "678720"
  },
  {
    "text": "and you know in times like today when we",
    "start": "678720",
    "end": "681779"
  },
  {
    "text": "are trying to optimize you know costs",
    "start": "681779",
    "end": "683579"
  },
  {
    "text": "with everything the storage costs and",
    "start": "683579",
    "end": "686040"
  },
  {
    "text": "the performance savings on the storage",
    "start": "686040",
    "end": "687300"
  },
  {
    "text": "also would be drastic if the size of",
    "start": "687300",
    "end": "690120"
  },
  {
    "text": "your data lake is going to be bigger",
    "start": "690120",
    "end": "692880"
  },
  {
    "text": "now after the next stage now we know how",
    "start": "692880",
    "end": "695640"
  },
  {
    "text": "to version our data assets using it you",
    "start": "695640",
    "end": "698220"
  },
  {
    "text": "know versioning engine now after the",
    "start": "698220",
    "end": "700500"
  },
  {
    "text": "testing stage what exactly do we need",
    "start": "700500",
    "end": "703200"
  },
  {
    "text": "we want to create these isolated data",
    "start": "703200",
    "end": "705180"
  },
  {
    "text": "environments on demand and isolated data",
    "start": "705180",
    "end": "707880"
  },
  {
    "text": "environments are nothing but lakefest",
    "start": "707880",
    "end": "709500"
  },
  {
    "text": "branches because every branch is an",
    "start": "709500",
    "end": "711660"
  },
  {
    "text": "isolated environment for you to run",
    "start": "711660",
    "end": "713579"
  },
  {
    "text": "whatever experiments or tests you want",
    "start": "713579",
    "end": "715440"
  },
  {
    "text": "to run",
    "start": "715440",
    "end": "716220"
  },
  {
    "text": "and if you are a data engineer you may",
    "start": "716220",
    "end": "718079"
  },
  {
    "text": "want to create a new Branch every time",
    "start": "718079",
    "end": "719760"
  },
  {
    "text": "new data gets ingested so instead of",
    "start": "719760",
    "end": "722040"
  },
  {
    "text": "putting them in main directly you can",
    "start": "722040",
    "end": "724740"
  },
  {
    "text": "put them in an ingestion Branch or call",
    "start": "724740",
    "end": "726899"
  },
  {
    "text": "it a staging branch",
    "start": "726899",
    "end": "728579"
  },
  {
    "text": "all the new data goes into staging now",
    "start": "728579",
    "end": "730800"
  },
  {
    "text": "you can have whatever suit of quality",
    "start": "730800",
    "end": "732660"
  },
  {
    "text": "tests you want to run and only if they",
    "start": "732660",
    "end": "734940"
  },
  {
    "text": "are successful you can merge them into",
    "start": "734940",
    "end": "736440"
  },
  {
    "text": "production",
    "start": "736440",
    "end": "737459"
  },
  {
    "text": "which is here the main branch",
    "start": "737459",
    "end": "739860"
  },
  {
    "text": "and just like get lakefs also has Branch",
    "start": "739860",
    "end": "742800"
  },
  {
    "text": "protection rules enabled so you can have",
    "start": "742800",
    "end": "745260"
  },
  {
    "text": "these rules defined for who can access",
    "start": "745260",
    "end": "747540"
  },
  {
    "text": "main or who can directly merge into Main",
    "start": "747540",
    "end": "749760"
  },
  {
    "text": "and so on which means you have a lot",
    "start": "749760",
    "end": "751800"
  },
  {
    "text": "more control over the quality of data",
    "start": "751800",
    "end": "753720"
  },
  {
    "text": "that that is being promoted to",
    "start": "753720",
    "end": "755459"
  },
  {
    "text": "production not just anybody can Tinker",
    "start": "755459",
    "end": "757680"
  },
  {
    "text": "with production data directly",
    "start": "757680",
    "end": "759720"
  },
  {
    "text": "and again the experimentation is usually",
    "start": "759720",
    "end": "762180"
  },
  {
    "text": "for the ml use cases if you're a data",
    "start": "762180",
    "end": "764100"
  },
  {
    "text": "scientist or an ml engineer who is",
    "start": "764100",
    "end": "765480"
  },
  {
    "text": "running multiple experiments trying to",
    "start": "765480",
    "end": "767639"
  },
  {
    "text": "identify what algorithm gives you the",
    "start": "767639",
    "end": "769620"
  },
  {
    "text": "most accuracy you can you know Branch",
    "start": "769620",
    "end": "771720"
  },
  {
    "text": "out of the training data which is",
    "start": "771720",
    "end": "773160"
  },
  {
    "text": "sitting in production and for every",
    "start": "773160",
    "end": "775079"
  },
  {
    "text": "experiment you can create you know new",
    "start": "775079",
    "end": "777240"
  },
  {
    "text": "branch and then run your ml experiments",
    "start": "777240",
    "end": "779639"
  },
  {
    "text": "on that branch and at the end of the day",
    "start": "779639",
    "end": "781500"
  },
  {
    "text": "whatever Branch or whatever model gives",
    "start": "781500",
    "end": "783360"
  },
  {
    "text": "you the highest accuracy you could just",
    "start": "783360",
    "end": "785279"
  },
  {
    "text": "push those models into production this",
    "start": "785279",
    "end": "787920"
  },
  {
    "text": "way you're just making sure the highest",
    "start": "787920",
    "end": "789959"
  },
  {
    "text": "or the winning model is but is being",
    "start": "789959",
    "end": "792360"
  },
  {
    "text": "deployed to production",
    "start": "792360",
    "end": "794100"
  },
  {
    "text": "these are again a couple of use cases of",
    "start": "794100",
    "end": "796680"
  },
  {
    "text": "how you can use this isolated data",
    "start": "796680",
    "end": "799320"
  },
  {
    "text": "environments using lakewest branches",
    "start": "799320",
    "end": "801000"
  },
  {
    "text": "depending on whatever other use cases",
    "start": "801000",
    "end": "803760"
  },
  {
    "text": "you may be thinking of you can leverage",
    "start": "803760",
    "end": "805260"
  },
  {
    "text": "these git like apis for that as well",
    "start": "805260",
    "end": "809600"
  },
  {
    "text": "and now",
    "start": "809639",
    "end": "810959"
  },
  {
    "text": "the next step further is so you do have",
    "start": "810959",
    "end": "813180"
  },
  {
    "text": "all these tests that are running how do",
    "start": "813180",
    "end": "814920"
  },
  {
    "text": "you make sure that the merge or the",
    "start": "814920",
    "end": "817139"
  },
  {
    "text": "create Branch happens only when these",
    "start": "817139",
    "end": "818940"
  },
  {
    "text": "tests are successful so lakefs has these",
    "start": "818940",
    "end": "822180"
  },
  {
    "text": "features they're called Lake FS hooks",
    "start": "822180",
    "end": "824399"
  },
  {
    "text": "which are similar to git hooks too",
    "start": "824399",
    "end": "827279"
  },
  {
    "text": "so what happens you can Define the rules",
    "start": "827279",
    "end": "829500"
  },
  {
    "text": "on which rules are the conditions on",
    "start": "829500",
    "end": "831660"
  },
  {
    "text": "which you want these operations to be",
    "start": "831660",
    "end": "833160"
  },
  {
    "text": "successful so you can have a pre-merge",
    "start": "833160",
    "end": "835320"
  },
  {
    "text": "hook that will run and only if the",
    "start": "835320",
    "end": "837600"
  },
  {
    "text": "constraints are successful then the",
    "start": "837600",
    "end": "839820"
  },
  {
    "text": "merge will be you know succeeding if not",
    "start": "839820",
    "end": "841860"
  },
  {
    "text": "it would automatically revert to a",
    "start": "841860",
    "end": "843600"
  },
  {
    "text": "previous Commit This you know avoiding",
    "start": "843600",
    "end": "845760"
  },
  {
    "text": "low quality data getting ingested into",
    "start": "845760",
    "end": "847920"
  },
  {
    "text": "production",
    "start": "847920",
    "end": "849600"
  },
  {
    "text": "we will dive a bit deeper on hooks at",
    "start": "849600",
    "end": "851940"
  },
  {
    "text": "the later part of the talk as well now",
    "start": "851940",
    "end": "854519"
  },
  {
    "text": "so we understood for the testing part",
    "start": "854519",
    "end": "856680"
  },
  {
    "text": "how can we create isolated data",
    "start": "856680",
    "end": "858839"
  },
  {
    "text": "environments with these lakefest",
    "start": "858839",
    "end": "860399"
  },
  {
    "text": "branches now let's move on to the next",
    "start": "860399",
    "end": "862320"
  },
  {
    "text": "part which is the deploy phase",
    "start": "862320",
    "end": "865560"
  },
  {
    "text": "deploy phase like I said is enabled by",
    "start": "865560",
    "end": "868200"
  },
  {
    "text": "lakefest hoax because when you want to",
    "start": "868200",
    "end": "870120"
  },
  {
    "text": "deploy you want to run this CI test and",
    "start": "870120",
    "end": "872700"
  },
  {
    "text": "then only want you know you want to",
    "start": "872700",
    "end": "874260"
  },
  {
    "text": "continuously deploy your promote your",
    "start": "874260",
    "end": "875820"
  },
  {
    "text": "product",
    "start": "875820",
    "end": "877200"
  },
  {
    "text": "data to your production and again here",
    "start": "877200",
    "end": "880500"
  },
  {
    "text": "lakefest supports a python web server",
    "start": "880500",
    "end": "883019"
  },
  {
    "text": "hooks",
    "start": "883019",
    "end": "884100"
  },
  {
    "text": "and you can like it says the hooks it",
    "start": "884100",
    "end": "888120"
  },
  {
    "text": "hooks at the end of the day is a yaml",
    "start": "888120",
    "end": "890940"
  },
  {
    "text": "file and you can Define whatever you",
    "start": "890940",
    "end": "892800"
  },
  {
    "text": "know constraints you want for each of",
    "start": "892800",
    "end": "894540"
  },
  {
    "text": "the branches so you can say main branch",
    "start": "894540",
    "end": "896459"
  },
  {
    "text": "can only have parquet files and not csvs",
    "start": "896459",
    "end": "898500"
  },
  {
    "text": "or Json or only this person can merge",
    "start": "898500",
    "end": "901620"
  },
  {
    "text": "into Main and all the you know rules can",
    "start": "901620",
    "end": "903779"
  },
  {
    "text": "be defined in the yaml and",
    "start": "903779",
    "end": "906360"
  },
  {
    "text": "it's not just that you can also Define a",
    "start": "906360",
    "end": "909240"
  },
  {
    "text": "set of tests that you want to run you",
    "start": "909240",
    "end": "911579"
  },
  {
    "text": "can have custom suits or you can even",
    "start": "911579",
    "end": "912899"
  },
  {
    "text": "integrate with Great Expectations soda",
    "start": "912899",
    "end": "915000"
  },
  {
    "text": "or any other you know data quality tools",
    "start": "915000",
    "end": "916980"
  },
  {
    "text": "that you may be working with and like FS",
    "start": "916980",
    "end": "919860"
  },
  {
    "text": "hooks is just a framework for you to",
    "start": "919860",
    "end": "921540"
  },
  {
    "text": "Define your own conditions and tests so",
    "start": "921540",
    "end": "924600"
  },
  {
    "text": "if you have existing suit of tests that",
    "start": "924600",
    "end": "926459"
  },
  {
    "text": "you want to migrate to lakefest hooks",
    "start": "926459",
    "end": "927899"
  },
  {
    "text": "you can do that as well",
    "start": "927899",
    "end": "930360"
  },
  {
    "text": "and yeah so here is an example of an you",
    "start": "930360",
    "end": "933180"
  },
  {
    "text": "know a yaml file that you want to put",
    "start": "933180",
    "end": "934980"
  },
  {
    "text": "together for the hooks to run and here",
    "start": "934980",
    "end": "937079"
  },
  {
    "text": "I'm going to make sure that only you",
    "start": "937079",
    "end": "938880"
  },
  {
    "text": "know parquet files are in production so",
    "start": "938880",
    "end": "940800"
  },
  {
    "text": "I'm just going to define the condition",
    "start": "940800",
    "end": "942000"
  },
  {
    "text": "that you know I want a pre-merge hook on",
    "start": "942000",
    "end": "944040"
  },
  {
    "text": "the main branch and what am I going to",
    "start": "944040",
    "end": "946920"
  },
  {
    "text": "actually you know test it on I want to",
    "start": "946920",
    "end": "949440"
  },
  {
    "text": "make sure the format validator is",
    "start": "949440",
    "end": "951060"
  },
  {
    "text": "running and I have my own you know flask",
    "start": "951060",
    "end": "953279"
  },
  {
    "text": "web server running in a specific",
    "start": "953279",
    "end": "955860"
  },
  {
    "text": "URL and then it allows you can even like",
    "start": "955860",
    "end": "959820"
  },
  {
    "text": "you know set these restrictions to be",
    "start": "959820",
    "end": "961560"
  },
  {
    "text": "applied to a specific prefix and not",
    "start": "961560",
    "end": "963839"
  },
  {
    "text": "necessarily for the entire data Lake",
    "start": "963839",
    "end": "965519"
  },
  {
    "text": "also",
    "start": "965519",
    "end": "967019"
  },
  {
    "text": "and as you can see on the right side",
    "start": "967019",
    "end": "970620"
  },
  {
    "text": "by you know defining these rules the",
    "start": "970620",
    "end": "972660"
  },
  {
    "text": "primers hook will run before every merge",
    "start": "972660",
    "end": "975300"
  },
  {
    "text": "and then it will only allow certain data",
    "start": "975300",
    "end": "977880"
  },
  {
    "text": "that follows these rules into the",
    "start": "977880",
    "end": "979139"
  },
  {
    "text": "production",
    "start": "979139",
    "end": "981120"
  },
  {
    "text": "and you know as we've already you know",
    "start": "981120",
    "end": "983279"
  },
  {
    "text": "touched upon the rollbacks as well you",
    "start": "983279",
    "end": "985860"
  },
  {
    "text": "don't have to like say for example most",
    "start": "985860",
    "end": "987480"
  },
  {
    "text": "of time what happens when you have an",
    "start": "987480",
    "end": "989160"
  },
  {
    "text": "issue in production data right you have",
    "start": "989160",
    "end": "991320"
  },
  {
    "text": "on calls in place and like you also need",
    "start": "991320",
    "end": "993779"
  },
  {
    "text": "to figure out and basically troubleshoot",
    "start": "993779",
    "end": "995519"
  },
  {
    "text": "and debug what happened why is there",
    "start": "995519",
    "end": "997139"
  },
  {
    "text": "something",
    "start": "997139",
    "end": "998759"
  },
  {
    "text": "you know like maybe a spike in a number",
    "start": "998759",
    "end": "1000860"
  },
  {
    "text": "in a dashboard and whatnot and the first",
    "start": "1000860",
    "end": "1003079"
  },
  {
    "text": "thing you can do with this setup when",
    "start": "1003079",
    "end": "1004759"
  },
  {
    "text": "you have you know data version We enable",
    "start": "1004759",
    "end": "1006620"
  },
  {
    "text": "this like we always do in Git You just",
    "start": "1006620",
    "end": "1009380"
  },
  {
    "text": "revert back to the previous commit and",
    "start": "1009380",
    "end": "1010880"
  },
  {
    "text": "you have a consistent state of data so",
    "start": "1010880",
    "end": "1012920"
  },
  {
    "text": "your internal or external data consumers",
    "start": "1012920",
    "end": "1015139"
  },
  {
    "text": "can continue to you know consume the",
    "start": "1015139",
    "end": "1017420"
  },
  {
    "text": "data without any Interruption while",
    "start": "1017420",
    "end": "1019459"
  },
  {
    "text": "you're trying to figure out or",
    "start": "1019459",
    "end": "1020720"
  },
  {
    "text": "troubleshoot what's going on in the",
    "start": "1020720",
    "end": "1022399"
  },
  {
    "text": "production data and with just a one line",
    "start": "1022399",
    "end": "1024918"
  },
  {
    "text": "command without you having to do too",
    "start": "1024919",
    "end": "1026720"
  },
  {
    "text": "much about like copying the whole set of",
    "start": "1026720",
    "end": "1028339"
  },
  {
    "text": "data making sure you have like two",
    "start": "1028339",
    "end": "1030558"
  },
  {
    "text": "versions of production you know one is",
    "start": "1030559",
    "end": "1032720"
  },
  {
    "text": "running which is serving your customers",
    "start": "1032720",
    "end": "1034640"
  },
  {
    "text": "in one more where you're trying to you",
    "start": "1034640",
    "end": "1036558"
  },
  {
    "text": "know troubleshoot and debug",
    "start": "1036559",
    "end": "1039380"
  },
  {
    "text": "and it just quicker recap of how exactly",
    "start": "1039380",
    "end": "1044240"
  },
  {
    "text": "will your data Lake look with when you",
    "start": "1044240",
    "end": "1046459"
  },
  {
    "text": "have like FS first thing is you have",
    "start": "1046459",
    "end": "1048799"
  },
  {
    "text": "time travel option you can easily revert",
    "start": "1048799",
    "end": "1050840"
  },
  {
    "text": "corrupted data Whenever there is it",
    "start": "1050840",
    "end": "1052700"
  },
  {
    "text": "doesn't matter in which environment it",
    "start": "1052700",
    "end": "1054440"
  },
  {
    "text": "is all you need is a simple like CDL",
    "start": "1054440",
    "end": "1056419"
  },
  {
    "text": "revert one line command you go back to",
    "start": "1056419",
    "end": "1058940"
  },
  {
    "text": "the consistent state of data and the",
    "start": "1058940",
    "end": "1061039"
  },
  {
    "text": "second is of course you can safely test",
    "start": "1061039",
    "end": "1062600"
  },
  {
    "text": "your data pipelines by creating an",
    "start": "1062600",
    "end": "1064880"
  },
  {
    "text": "isolated environment from your",
    "start": "1064880",
    "end": "1066440"
  },
  {
    "text": "production this way you have production",
    "start": "1066440",
    "end": "1068660"
  },
  {
    "text": "like data in fact actual production data",
    "start": "1068660",
    "end": "1071600"
  },
  {
    "text": "but in an isolated environment so you're",
    "start": "1071600",
    "end": "1073640"
  },
  {
    "text": "not risking it like you're not affecting",
    "start": "1073640",
    "end": "1075620"
  },
  {
    "text": "your consumers consuming your production",
    "start": "1075620",
    "end": "1077720"
  },
  {
    "text": "data it's just completely isolated for",
    "start": "1077720",
    "end": "1080059"
  },
  {
    "text": "you to run your own tests",
    "start": "1080059",
    "end": "1081799"
  },
  {
    "text": "and the third is again you do you know",
    "start": "1081799",
    "end": "1085039"
  },
  {
    "text": "create these production ice identical",
    "start": "1085039",
    "end": "1087080"
  },
  {
    "text": "branches but then you can also run your",
    "start": "1087080",
    "end": "1089419"
  },
  {
    "text": "own set of tests to make sure the data",
    "start": "1089419",
    "end": "1091220"
  },
  {
    "text": "quality is in place because today we",
    "start": "1091220",
    "end": "1093140"
  },
  {
    "text": "data quality is one of the top",
    "start": "1093140",
    "end": "1094760"
  },
  {
    "text": "challenges for all the data teams that",
    "start": "1094760",
    "end": "1096440"
  },
  {
    "text": "we are you know dealing with or working",
    "start": "1096440",
    "end": "1098539"
  },
  {
    "text": "with and you can use like FS hooks to",
    "start": "1098539",
    "end": "1101360"
  },
  {
    "text": "you know enable that as well",
    "start": "1101360",
    "end": "1104000"
  },
  {
    "text": "and that's all I had and like I said",
    "start": "1104000",
    "end": "1106700"
  },
  {
    "text": "open like FS is an open source project",
    "start": "1106700",
    "end": "1109220"
  },
  {
    "text": "and we have a thriving community of",
    "start": "1109220",
    "end": "1111380"
  },
  {
    "text": "users contributors and also",
    "start": "1111380",
    "end": "1113059"
  },
  {
    "text": "organizations who use lakefs and if you",
    "start": "1113059",
    "end": "1116120"
  },
  {
    "text": "are interested feel free to sign up on",
    "start": "1116120",
    "end": "1118280"
  },
  {
    "text": "the slack",
    "start": "1118280",
    "end": "1119480"
  },
  {
    "text": "and yeah if you have any other questions",
    "start": "1119480",
    "end": "1122360"
  },
  {
    "text": "I'm here today",
    "start": "1122360",
    "end": "1125080"
  },
  {
    "text": "gotcha okay so the one thing that I did",
    "start": "1146419",
    "end": "1149240"
  },
  {
    "text": "not cover is Lake FS also has a garbage",
    "start": "1149240",
    "end": "1151700"
  },
  {
    "text": "collection",
    "start": "1151700",
    "end": "1152660"
  },
  {
    "text": "meaning you can set a retention policy",
    "start": "1152660",
    "end": "1155539"
  },
  {
    "text": "for example when I say suppose you have",
    "start": "1155539",
    "end": "1157520"
  },
  {
    "text": "a data in your main branch and you",
    "start": "1157520",
    "end": "1159080"
  },
  {
    "text": "deleted it and you committed it and then",
    "start": "1159080",
    "end": "1161480"
  },
  {
    "text": "you move forward right but then if the",
    "start": "1161480",
    "end": "1163400"
  },
  {
    "text": "deletion is by mistake when you revert",
    "start": "1163400",
    "end": "1165140"
  },
  {
    "text": "it you want to be able to access it so",
    "start": "1165140",
    "end": "1167179"
  },
  {
    "text": "every delete is a hard delete or soft",
    "start": "1167179",
    "end": "1168919"
  },
  {
    "text": "delete so you get to choose say if you",
    "start": "1168919",
    "end": "1172100"
  },
  {
    "text": "if your attention was 30 days that was",
    "start": "1172100",
    "end": "1174320"
  },
  {
    "text": "the soft delete and if it was above 30",
    "start": "1174320",
    "end": "1176059"
  },
  {
    "text": "days then that that has gone forever",
    "start": "1176059",
    "end": "1178700"
  },
  {
    "text": "and you need hard delete because with",
    "start": "1178700",
    "end": "1180559"
  },
  {
    "text": "all the pii and gdpr you really need to",
    "start": "1180559",
    "end": "1182780"
  },
  {
    "text": "delete the data not just soft delete",
    "start": "1182780",
    "end": "1184280"
  },
  {
    "text": "them so yeah you can set the retention",
    "start": "1184280",
    "end": "1186140"
  },
  {
    "text": "as well",
    "start": "1186140",
    "end": "1188559"
  },
  {
    "text": "awesome",
    "start": "1192200",
    "end": "1194539"
  },
  {
    "text": "thank you",
    "start": "1194539",
    "end": "1197059"
  },
  {
    "text": "foreign",
    "start": "1197059",
    "end": "1199899"
  }
]
[
  {
    "text": "welcome everyone um thanks for coming for the talk I hope you have enough energy this is the last talk of today",
    "start": "320",
    "end": "8360"
  },
  {
    "text": "sessions and yeah I'm shivanu I'm a founding engineer at signos I'm also a",
    "start": "8360",
    "end": "13920"
  },
  {
    "text": "CNF Ambassador and maintainer and cond to open DEET and uh we have Jonathan here who is",
    "start": "13920",
    "end": "24480"
  },
  {
    "text": "yeah who is the founder NC at buff pod so let's get started",
    "start": "24480",
    "end": "31119"
  },
  {
    "text": "so first of all um let's see what is the outline of the talk so firstly we will",
    "start": "31119",
    "end": "38120"
  },
  {
    "text": "see why network observ is important and uh what is evf and how you can use it",
    "start": "38120",
    "end": "45320"
  },
  {
    "text": "for Network obility what are the tooling available uh for to facilitate Network obility by",
    "start": "45320",
    "end": "52199"
  },
  {
    "text": "vpf and understand the architecture of open",
    "start": "52199",
    "end": "58559"
  },
  {
    "text": "network we'll dive deep into all the individual components and agents that",
    "start": "58920",
    "end": "64518"
  },
  {
    "text": "open tele Network uses finally will have a demo and also",
    "start": "64519",
    "end": "70320"
  },
  {
    "text": "how you can get involved so let's see why network",
    "start": "70320",
    "end": "75640"
  },
  {
    "text": "obility is important what problem does it solves and why use",
    "start": "75640",
    "end": "81759"
  },
  {
    "text": "vpf so modern distributed systems are hard they are hybrid meaning they are",
    "start": "81759",
    "end": "87640"
  },
  {
    "text": "running different kubernetes clusters across different regions sometimes M",
    "start": "87640",
    "end": "92880"
  },
  {
    "text": "cloud and they are heterogeneous in nature meaning there are collection of",
    "start": "92880",
    "end": "98000"
  },
  {
    "text": "VMS bare metals and communties clusters working all",
    "start": "98000",
    "end": "103759"
  },
  {
    "text": "together and it becomes challenging to uh figure out some problems especially",
    "start": "103759",
    "end": "109560"
  },
  {
    "text": "at the network level because lowlevel tetri are not present by default your",
    "start": "109560",
    "end": "115240"
  },
  {
    "text": "logs uh spans and traces does not give give enough context on the Network",
    "start": "115240",
    "end": "121360"
  },
  {
    "text": "clear even if you are using uh service smash uh for example if you are using",
    "start": "121360",
    "end": "126920"
  },
  {
    "text": "sto or Envoy sometimes you need to correlate the anoy logs to get the flow",
    "start": "126920",
    "end": "132239"
  },
  {
    "text": "of the logs and flow of the network request fundamentally it's very complex",
    "start": "132239",
    "end": "138480"
  },
  {
    "text": "uh to troubleshoot the network related problems there's limited visibility into",
    "start": "138480",
    "end": "143879"
  },
  {
    "text": "Network performance um there's in ineffective detection of anomaly and security threads so for for example if",
    "start": "143879",
    "end": "150519"
  },
  {
    "text": "some of the ports are open in your infrastructure you wouldn't know and and and if there's some traffic flowing",
    "start": "150519",
    "end": "155760"
  },
  {
    "text": "through it if there's not there's no network observability it would be very hard to figure out those",
    "start": "155760",
    "end": "161400"
  },
  {
    "text": "problems there's lack of insight into user experience and application performance there are compliance and",
    "start": "161400",
    "end": "168040"
  },
  {
    "text": "audit challenges and um it is very hard for",
    "start": "168040",
    "end": "173080"
  },
  {
    "text": "Network cost analysis so for example in a side car pattern if you're using sto There is extra overhead off side car but",
    "start": "173080",
    "end": "181120"
  },
  {
    "text": "if you're using some lowlevel tool which is gathering all the Telemetry from the Linux con itself uh the cost is low but",
    "start": "181120",
    "end": "189599"
  },
  {
    "text": "if you are not monitoring your network then figuring out the network cost analysis is is",
    "start": "189599",
    "end": "195640"
  },
  {
    "text": "hard also Network failure at the cloud provider and external vendors API is not",
    "start": "195640",
    "end": "202319"
  },
  {
    "text": "easy to figure out but if you have Network obility it helps so what is possible with uh",
    "start": "202319",
    "end": "209159"
  },
  {
    "text": "Network obs so it gives you enhanced security posture it helps in optimizing Network",
    "start": "209159",
    "end": "216360"
  },
  {
    "text": "performance it also helps in diagnosing packet loss uh resolving highlighty",
    "start": "216360",
    "end": "222680"
  },
  {
    "text": "issues user device identification using the MAC address and the network",
    "start": "222680",
    "end": "229599"
  },
  {
    "text": "interface you can get some protocol specific information like TCP metrics",
    "start": "229599",
    "end": "234640"
  },
  {
    "text": "udb statistics and also the flow data and D visibility into uh third party API",
    "start": "234640",
    "end": "243519"
  },
  {
    "text": "failures so why use EF for Network OB visibility uh APF provides low overhead",
    "start": "243519",
    "end": "251159"
  },
  {
    "text": "monitoring so you don't have to run a side car instead you can just run a",
    "start": "251159",
    "end": "256400"
  },
  {
    "text": "single agent which is collecting all the information from the kernel it's minimal and it has uh efficient data collection",
    "start": "256400",
    "end": "265360"
  },
  {
    "text": "it provides de visibility into canel and application Behavior access access to Canal events and application Level",
    "start": "265360",
    "end": "272759"
  },
  {
    "text": "insights you can filter out the events by programming the L Linux canel",
    "start": "272759",
    "end": "278160"
  },
  {
    "text": "dynamically it gives flexibility and program programmability and realtime",
    "start": "278160",
    "end": "283360"
  },
  {
    "text": "data and high frequency metrics it gives Rich Petry and you can",
    "start": "283360",
    "end": "288440"
  },
  {
    "text": "use that for correlation so what is abpf um if I may",
    "start": "288440",
    "end": "295520"
  },
  {
    "text": "ask how many people have heard about ebpf I think a lot of people and how many",
    "start": "295520",
    "end": "301320"
  },
  {
    "text": "people are actually using it in production quite few but it's nice that",
    "start": "301320",
    "end": "306800"
  },
  {
    "text": "people are using it so on a very high level this is how EF works it extends",
    "start": "306800",
    "end": "313560"
  },
  {
    "text": "the Linux kernel um you already know that it's extended Buckle packet filter",
    "start": "313560",
    "end": "319880"
  },
  {
    "text": "which means you can intercept your CIS calls and dynamically program to collect",
    "start": "319880",
    "end": "326000"
  },
  {
    "text": "and filter all the process all the CIS that are happening and filter that out",
    "start": "326000",
    "end": "332440"
  },
  {
    "text": "and put into an EF MF and you can use that collected data and the ABF maps to",
    "start": "332440",
    "end": "339240"
  },
  {
    "text": "do further further Cod relations so for example if there's a process and um",
    "start": "339240",
    "end": "345759"
  },
  {
    "text": "which is coming from uh from from some socket and then you can filter out some",
    "start": "345759",
    "end": "351319"
  },
  {
    "text": "information from that so what are the tooling available to facilitate Network",
    "start": "351319",
    "end": "357759"
  },
  {
    "text": "observability so there are a bunch of tools both for applications and",
    "start": "357759",
    "end": "363880"
  },
  {
    "text": "infrastructures um I iiser BCC provides it's it's a powerful tool and it colle",
    "start": "363880",
    "end": "370199"
  },
  {
    "text": "it is basically a collection of libraries and tools that facilitate the creation and compilation and execution",
    "start": "370199",
    "end": "375919"
  },
  {
    "text": "of BPF programs it provides tooling required for Io and network and",
    "start": "375919",
    "end": "383720"
  },
  {
    "text": "monitoring um llm VM compile infrastructure it is basically a",
    "start": "383720",
    "end": "388759"
  },
  {
    "text": "collection of modular and reusable compiler and Tool chain Technologies it",
    "start": "388759",
    "end": "394000"
  },
  {
    "text": "is being used most commonly as a as a compiler for all the BPF",
    "start": "394000",
    "end": "399759"
  },
  {
    "text": "programs and it contains a robust framework and used for developer",
    "start": "399759",
    "end": "405039"
  },
  {
    "text": "compilers um BPF Trace is again a high level tracing language for Linux U BP",
    "start": "405039",
    "end": "411599"
  },
  {
    "text": "BPF Trace uses L LL llvm compiler as a back end um to compile the scripts to",
    "start": "411599",
    "end": "419680"
  },
  {
    "text": "abpf by code so let's understand the open tary network",
    "start": "419680",
    "end": "426360"
  },
  {
    "text": "architecture here we have in this particular example two nodes where some",
    "start": "428080",
    "end": "433680"
  },
  {
    "text": "applications are running and you can see that there is Kernel collector KS collector and Cloud collector installed",
    "start": "433680",
    "end": "441199"
  },
  {
    "text": "and all of them are sending Telemetry to the reducer component which is in turn sending all the collected Telemetry to",
    "start": "441199",
    "end": "447240"
  },
  {
    "text": "oel collector which is acting at as a Gateway so let's see how these different",
    "start": "447240",
    "end": "452919"
  },
  {
    "text": "components are working so first component is Kernel collector it's usually deployed as a",
    "start": "452919",
    "end": "460360"
  },
  {
    "text": "single agent per node basically as a demon set and it collects all the lowlevel dmetry using a BPF Theus",
    "start": "460360",
    "end": "467360"
  },
  {
    "text": "collector is a deployment uh which collects all the events from kubernetes API server so it's it's basically",
    "start": "467360",
    "end": "474000"
  },
  {
    "text": "monitoring your kuties API server and collect collecting details like uh creation of pod and deltion of",
    "start": "474000",
    "end": "481159"
  },
  {
    "text": "pod the cloud collector agent is again deployed as a deployment",
    "start": "481159",
    "end": "487440"
  },
  {
    "text": "and it gathers uh so it uses cloud provider sdks and it uh gathers the",
    "start": "487440",
    "end": "494360"
  },
  {
    "text": "events from cloud provider itself and some metadata for example AWS",
    "start": "494360",
    "end": "500080"
  },
  {
    "text": "instance ID or zone region and reducer finally collects all this Telemetry and",
    "start": "500080",
    "end": "507479"
  },
  {
    "text": "uh enrich the data to do correlation between all the Tater that is being",
    "start": "507479",
    "end": "512959"
  },
  {
    "text": "collected from different components so let's dive deep into all the individual",
    "start": "512959",
    "end": "520719"
  },
  {
    "text": "components so first is Kel collector so let's first take a look at",
    "start": "520719",
    "end": "527640"
  },
  {
    "text": "the diagram here this is basically a data flow diagram inside a kernel collector how would your Telemetry would",
    "start": "527640",
    "end": "534560"
  },
  {
    "text": "flow from the Linux caner itself to finally to the reducer if you see there are ebf",
    "start": "534560",
    "end": "542240"
  },
  {
    "text": "programs which are loaded which are basically the probes for collecting DNS",
    "start": "542240",
    "end": "547560"
  },
  {
    "text": "request TCP connections cgp uh CG groups and process events so they are basically",
    "start": "547560",
    "end": "553959"
  },
  {
    "text": "monitoring all these things they are also collecting STP metrics and TCP",
    "start": "553959",
    "end": "559640"
  },
  {
    "text": "handling the BPF Handler is responsible to manage the cycles of EF programs it",
    "start": "559640",
    "end": "565720"
  },
  {
    "text": "loads the BPF code attaches the probes and hand handles the data",
    "start": "565720",
    "end": "571440"
  },
  {
    "text": "collection it's it is also responsible for perf events and filter now all the",
    "start": "571440",
    "end": "577360"
  },
  {
    "text": "data that is being collected goes to the data collection modules so first is data",
    "start": "577360",
    "end": "583399"
  },
  {
    "text": "DNS request collector it filters the DNS related uh information similarly the",
    "start": "583399",
    "end": "589600"
  },
  {
    "text": "kernel CG group and performance polling events and then it is uh then basically",
    "start": "589600",
    "end": "596880"
  },
  {
    "text": "there's a cloud metadata collection unit which collects AWS So currently it is",
    "start": "596880",
    "end": "602120"
  },
  {
    "text": "supported for AWS and gcp and it uh collected collects the Met data from AWS",
    "start": "602120",
    "end": "609000"
  },
  {
    "text": "and gcp as a cloud provider using this SDK and it also collects data from Docker and",
    "start": "609000",
    "end": "615640"
  },
  {
    "text": "Nomad this curl engine and then the agent flow and then finally it this",
    "start": "615640",
    "end": "621000"
  },
  {
    "text": "output you can output that into a file or to a reducer and this is basically",
    "start": "621000",
    "end": "628320"
  },
  {
    "text": "the information around every individual components that is there so I can",
    "start": "628320",
    "end": "634040"
  },
  {
    "text": "probably skip that because I just explained that through the diagram now this is a sample log where",
    "start": "634040",
    "end": "640399"
  },
  {
    "text": "you can see it is coming from a kernel collector and you can see that what is",
    "start": "640399",
    "end": "645720"
  },
  {
    "text": "the node name uh and what is the instance basically this is collected from the cloud",
    "start": "645720",
    "end": "651000"
  },
  {
    "text": "provider uh cloud provider agent and it is giving us the details around the",
    "start": "651000",
    "end": "657959"
  },
  {
    "text": "instance itself let's take a look at kubernetes collector It's relatively simple agent",
    "start": "657959",
    "end": "665440"
  },
  {
    "text": "because it's it contains two uh basically when it runs it contains two container one is KS Watcher and KS relay",
    "start": "665440",
    "end": "673680"
  },
  {
    "text": "the responsibility for KS Watcher is to basically watch the community's API and collect all the events and then it sends",
    "start": "673680",
    "end": "681600"
  },
  {
    "text": "all the data to ks relay which is in turn sending that to the reducer",
    "start": "681600",
    "end": "687440"
  },
  {
    "text": "server cloud collector is we briefly touched touched upon it so it basically",
    "start": "687440",
    "end": "693880"
  },
  {
    "text": "iate over all the network interfaces using the cloud provider sdks and it retrieves uh network",
    "start": "693880",
    "end": "700320"
  },
  {
    "text": "interfaces and reges and metadata it handles throttling and API errors the",
    "start": "700320",
    "end": "706200"
  },
  {
    "text": "cloud collector agents also schedules metadata collection handle handles error",
    "start": "706200",
    "end": "711680"
  },
  {
    "text": "recovery sends data to inje pipeline I think if you are able to see",
    "start": "711680",
    "end": "717839"
  },
  {
    "text": "it's basically how the the tele Telemetry would flow through the cloud",
    "start": "717839",
    "end": "723120"
  },
  {
    "text": "collector agent itself so now let's talk about the",
    "start": "723120",
    "end": "728360"
  },
  {
    "text": "reducer component please",
    "start": "728360",
    "end": "732519"
  },
  {
    "text": "Jonathan thank you shivanu can you hear me hi everybody so I'm Jonathan Perry I",
    "start": "736120",
    "end": "742480"
  },
  {
    "text": "uh founded the uh Network collector project and I'm a current maintainer so",
    "start": "742480",
    "end": "748120"
  },
  {
    "text": "uh this is a different diagram of system components uh you can uh see I'm going",
    "start": "748120",
    "end": "753920"
  },
  {
    "text": "to talk about the reducer the reducer is a critical component that receives data",
    "start": "753920",
    "end": "758959"
  },
  {
    "text": "from the kernel collectors as well as the kubernetes and Cloud collectors",
    "start": "758959",
    "end": "764639"
  },
  {
    "text": "analyzes it and output metrics into the otel collector uh here is an overview of the",
    "start": "764639",
    "end": "771000"
  },
  {
    "text": "reducer I'll start on the bottom uh there's a logging core that takes all the logs that the other cores of the",
    "start": "771000",
    "end": "777480"
  },
  {
    "text": "pipeline want to output and then prints it to the console and we did this because printing to the console is",
    "start": "777480",
    "end": "782800"
  },
  {
    "text": "relatively expensive we didn't want those prints to delay data flowing through the pipeline um the loging core also handles",
    "start": "782800",
    "end": "791320"
  },
  {
    "text": "internal Telemetry it collects health information about the health of the pipeline itself uh in the next few",
    "start": "791320",
    "end": "798279"
  },
  {
    "text": "slides I'll go through the analysis that the reducer makes from left to write in",
    "start": "798279",
    "end": "804279"
  },
  {
    "text": "these inest matching and aggregation core so let's start with inest",
    "start": "804279",
    "end": "809839"
  },
  {
    "text": "the reducer receives socket information but critically it needs",
    "start": "809839",
    "end": "815920"
  },
  {
    "text": "information about the context of the socket information about the process the container and host it's running on as",
    "start": "815920",
    "end": "823760"
  },
  {
    "text": "well as instance metadata that shivanu mentioned um availability zone for",
    "start": "823760",
    "end": "828839"
  },
  {
    "text": "example uh instance name information from uh local container uh runtime and",
    "start": "828839",
    "end": "837320"
  },
  {
    "text": "information about domains and Network address translation the reducer takes this data and combines it with",
    "start": "837320",
    "end": "843959"
  },
  {
    "text": "information from uh kubernetes API and from the cloud provider and what you",
    "start": "843959",
    "end": "849360"
  },
  {
    "text": "need to know about the inest cores is that they are a digital twin of your",
    "start": "849360",
    "end": "855920"
  },
  {
    "text": "cluster and uh what I mean by digital twin is that the inist cores replicate",
    "start": "855920",
    "end": "861839"
  },
  {
    "text": "state from all of the operating system in your cluster from the kubernetes API and from your cloud provider to create a",
    "start": "861839",
    "end": "868759"
  },
  {
    "text": "real time model of your entire cluster the pertinent Parts in memory in the",
    "start": "868759",
    "end": "874519"
  },
  {
    "text": "inest course so think about it it it has representations and objects for all the pods the containers the processes the",
    "start": "874519",
    "end": "881360"
  },
  {
    "text": "sockets and so on and the idea is you can analyze that and uh create uh create",
    "start": "881360",
    "end": "887639"
  },
  {
    "text": "the Telemetry deriv Telemetry from that digital",
    "start": "887639",
    "end": "892519"
  },
  {
    "text": "twin now maintaining a digital twin was also really good for performance uh we",
    "start": "892759",
    "end": "898839"
  },
  {
    "text": "met measured some a few live systems and found that for every container update that the system received uh there were",
    "start": "898839",
    "end": "905639"
  },
  {
    "text": "thousands of process and socket updates and hundreds of thousands of socket activity reports the digital twin",
    "start": "905639",
    "end": "913120"
  },
  {
    "text": "enables the reducer to receive metadata only once per entity and keep that and",
    "start": "913120",
    "end": "918800"
  },
  {
    "text": "that metadata is then accessible when you need it to derive uh",
    "start": "918800",
    "end": "924079"
  },
  {
    "text": "metrics we measured Network overhead in several production deployment and it is",
    "start": "924079",
    "end": "929120"
  },
  {
    "text": "usually it can see around half of a percent and a little bit over 1% in",
    "start": "929120",
    "end": "934399"
  },
  {
    "text": "extreme cases now imagine if we had to repeat the metadata over and over hundreds and",
    "start": "934399",
    "end": "940600"
  },
  {
    "text": "thousands of times we probably wouldn't be wouldn't have been able to reach these low overhead",
    "start": "940600",
    "end": "946240"
  },
  {
    "text": "numbers so onwards to the matching core network connections have two sides",
    "start": "946240",
    "end": "954000"
  },
  {
    "text": "uh and so we would like to combine all of the metadata from both sides if we have collector on both sides of the so",
    "start": "954000",
    "end": "960360"
  },
  {
    "text": "of the connection uh to a flow object so all funnel all the metadata there the",
    "start": "960360",
    "end": "966519"
  },
  {
    "text": "matching core takes the data from both sockets and the relevant kubernetes and",
    "start": "966519",
    "end": "971680"
  },
  {
    "text": "Cloud uh metadata and the enrichment function you can find it in in the code the",
    "start": "971680",
    "end": "977480"
  },
  {
    "text": "enrichment function decides what are the different attributes of the flow so for example if we have one side running on",
    "start": "977480",
    "end": "983600"
  },
  {
    "text": "kubernetes and the other side is running is the of the connection is a managed",
    "start": "983600",
    "end": "989399"
  },
  {
    "text": "database so maybe an RDS database running in your cloud provider so obviously there's no kernel collector on",
    "start": "989399",
    "end": "995399"
  },
  {
    "text": "there then the enrichment function would take the RDS instance name from your",
    "start": "995399",
    "end": "1000920"
  },
  {
    "text": "cloud provider right so you have all these data sources you combine them this is essentially what the",
    "start": "1000920",
    "end": "1008120"
  },
  {
    "text": "matching cord does so it combines both sides and enriches let's see the aggregation",
    "start": "1008120",
    "end": "1014639"
  },
  {
    "text": "cores the enrichment function assembles the following dimension for flows uh you",
    "start": "1014639",
    "end": "1020639"
  },
  {
    "text": "can see logical data about the workload such as the cluster name space the name",
    "start": "1020639",
    "end": "1025640"
  },
  {
    "text": "of the deployment and so on and physical location such as the host name availability Zone and",
    "start": "1025640",
    "end": "1031918"
  },
  {
    "text": "region this uh to Output all of the flows with all of this cardinality is",
    "start": "1031919",
    "end": "1037558"
  },
  {
    "text": "way too much so time series databases today just cannot handle this much cardinality all the flows in the system",
    "start": "1037559",
    "end": "1044038"
  },
  {
    "text": "they're unable to store it they're unable to query it it gets too expensive so really you need an aggregation on top",
    "start": "1044039",
    "end": "1050320"
  },
  {
    "text": "of this we found that there are three intuitive aggregations over these",
    "start": "1050320",
    "end": "1056080"
  },
  {
    "text": "Dimensions uh I'll go from the right hand side this time um where you have basically all of the information this is",
    "start": "1056080",
    "end": "1062440"
  },
  {
    "text": "a pod so the entities that you aggregate to our pods if you forget the individual",
    "start": "1062440",
    "end": "1067640"
  },
  {
    "text": "pods but you still remember the physical environment they run on the availability Zone in the region then you have this",
    "start": "1067640",
    "end": "1073120"
  },
  {
    "text": "middle aggregation which we call AZ uh and if you also forget about which",
    "start": "1073120",
    "end": "1078440"
  },
  {
    "text": "availability ility Zone the the Pod is running on then you have what is intuitively an application right this",
    "start": "1078440",
    "end": "1085600"
  },
  {
    "text": "logical thing that we deployed um and so now remember uh there",
    "start": "1085600",
    "end": "1091280"
  },
  {
    "text": "are two sides to the connection so there are both the center dimensions and receiver Dimensions uh and you need to",
    "start": "1091280",
    "end": "1097440"
  },
  {
    "text": "select which aggregation to perform on either side if you take roll roll the most aggregated rollup that we offer",
    "start": "1097440",
    "end": "1104440"
  },
  {
    "text": "then uh it's kind of this application is sending this data to that application is the metrics that you'll see if you take",
    "start": "1104440",
    "end": "1111360"
  },
  {
    "text": "the most granular one you'll see this pod is sending to that pod for every pod",
    "start": "1111360",
    "end": "1116400"
  },
  {
    "text": "in the system so every application might have thousands of these uh or you can do something in the",
    "start": "1116400",
    "end": "1123960"
  },
  {
    "text": "middle the aggregation core takes the flow data which is the super granular",
    "start": "1123960",
    "end": "1129480"
  },
  {
    "text": "data that we assembled before and then starts aggregating it to coarser and coarser aggregation for example it takes",
    "start": "1129480",
    "end": "1137240"
  },
  {
    "text": "all of the flows between two specific pods and Aggregates them so maybe there were a 100 sockets flowing between these",
    "start": "1137240",
    "end": "1144240"
  },
  {
    "text": "two pods but you just get after this aggregation step you get just get one metric or one set of metrics for this",
    "start": "1144240",
    "end": "1150919"
  },
  {
    "text": "pair of PODS one for uh latency one for the number of packet drops and so on you",
    "start": "1150919",
    "end": "1156039"
  },
  {
    "text": "can then take all the pod pod information and then aggregate it maybe you forget the sender pod ID and just",
    "start": "1156039",
    "end": "1161880"
  },
  {
    "text": "remember the application information in the availability Zone and on the destination side you still remember the",
    "start": "1161880",
    "end": "1166960"
  },
  {
    "text": "Pod so you get these Time series from the a aggregation to ID and so",
    "start": "1166960",
    "end": "1174360"
  },
  {
    "text": "on uh here's a measurement of a cluster with 1500 nodes and you can see that uh",
    "start": "1176919",
    "end": "1184080"
  },
  {
    "text": "on the top here is a fine grained aggregation uh and it outputed um 20",
    "start": "1184080",
    "end": "1190000"
  },
  {
    "text": "million data points per minute and on the bottom is the application to application aggregation only output 1.3",
    "start": "1190000",
    "end": "1197320"
  },
  {
    "text": "million data points per minute so 20 to 1.3 there's a huge saving when you have",
    "start": "1197320",
    "end": "1202440"
  },
  {
    "text": "this aggregation but you lose the dimensions and cardinality um so with that we have um",
    "start": "1202440",
    "end": "1210080"
  },
  {
    "text": "your endtoend view from the digital twin to the matching and enrichment and down",
    "start": "1210080",
    "end": "1215240"
  },
  {
    "text": "to the aggregation and output to The alel Collector and with that shivanu you have",
    "start": "1215240",
    "end": "1221559"
  },
  {
    "text": "a demo",
    "start": "1221559",
    "end": "1224679"
  },
  {
    "text": "so let's take a look at uh the demo let",
    "start": "1229840",
    "end": "1235640"
  },
  {
    "text": "me change this from Ming",
    "start": "1235640",
    "end": "1241880"
  },
  {
    "text": "to",
    "start": "1244600",
    "end": "1247600"
  },
  {
    "text": "cool so basically have already set up the demo and uh so there are basic if",
    "start": "1250960",
    "end": "1257200"
  },
  {
    "text": "you take a look at the number of nodes running in my Cas cluster there are two",
    "start": "1257200",
    "end": "1262640"
  },
  {
    "text": "nodes so we can see there are two kernel correctors deployed",
    "start": "1262640",
    "end": "1270320"
  },
  {
    "text": "oops so there are two Canal collectors which are running on the different nodes",
    "start": "1272360",
    "end": "1277440"
  },
  {
    "text": "and there's one KS collector which is collecting all the communities related",
    "start": "1277440",
    "end": "1283039"
  },
  {
    "text": "information the cloud collector and the open D collector itself so let's take a",
    "start": "1283039",
    "end": "1288159"
  },
  {
    "text": "look at add the logs for the",
    "start": "1288159",
    "end": "1293039"
  },
  {
    "text": "reducer and okay so right now the tracing is",
    "start": "1294679",
    "end": "1300720"
  },
  {
    "text": "enabled for this component and let me also first try to send some request",
    "start": "1300720",
    "end": "1309720"
  },
  {
    "text": "so let me complete the request flow for example I have the shoes place",
    "start": "1324039",
    "end": "1330240"
  },
  {
    "text": "order and let's make some couple of",
    "start": "1330240",
    "end": "1335120"
  },
  {
    "text": "requests",
    "start": "1336480",
    "end": "1339480"
  },
  {
    "text": "and I'm going to delete the reducer and so that we get the initial logs which",
    "start": "1343320",
    "end": "1349320"
  },
  {
    "text": "are",
    "start": "1349320",
    "end": "1351559"
  },
  {
    "text": "[Music] important now if we go and look at the",
    "start": "1356240",
    "end": "1364640"
  },
  {
    "text": "logs so a lot of EF related uh Matrix collection is enabled and we would see",
    "start": "1366640",
    "end": "1374600"
  },
  {
    "text": "when when the container is ready we see the metadata coming in",
    "start": "1374600",
    "end": "1380440"
  },
  {
    "text": "so this metadata is coming from the EF cuber collector we have all the network",
    "start": "1381520",
    "end": "1389440"
  },
  {
    "text": "interface detail information we have the role a and ID which is uh needed for the",
    "start": "1389440",
    "end": "1396720"
  },
  {
    "text": "correlation the instance itself and then the another metadata is coming from the",
    "start": "1396720",
    "end": "1402159"
  },
  {
    "text": "ebpf cloud collector where we have the other",
    "start": "1402159",
    "end": "1407679"
  },
  {
    "text": "metadata embedded in it again we have the information coming",
    "start": "1407679",
    "end": "1415120"
  },
  {
    "text": "from the kernel collector and then we would see all the",
    "start": "1415120",
    "end": "1420559"
  },
  {
    "text": "the trace that's happening in the in the agent itself but let's see what is",
    "start": "1420559",
    "end": "1428240"
  },
  {
    "text": "coming to The Collector we should be able to see all the matric that are",
    "start": "1428240",
    "end": "1433679"
  },
  {
    "text": "being collected from different collectors and ened by reducer that me take a look at the",
    "start": "1433679",
    "end": "1439679"
  },
  {
    "text": "collector",
    "start": "1439679",
    "end": "1442120"
  },
  {
    "text": "logs okay so we do have Matrix coming",
    "start": "1445520",
    "end": "1451919"
  },
  {
    "text": "in and we it is enriched by all the metadata that is being collected As the",
    "start": "1451919",
    "end": "1459279"
  },
  {
    "text": "metric attributes and if we do the so for",
    "start": "1459279",
    "end": "1464440"
  },
  {
    "text": "example this is TCP related information there's ebpf",
    "start": "1464440",
    "end": "1469919"
  },
  {
    "text": "Network level information basically all the Telemetry is being collected and then you can do a lot of um correlation",
    "start": "1469919",
    "end": "1477399"
  },
  {
    "text": "on top of it to get the overall Network view so we have a demo for that as",
    "start": "1477399",
    "end": "1485080"
  },
  {
    "text": "well let's",
    "start": "1485080",
    "end": "1488360"
  },
  {
    "text": "start yep demos",
    "start": "1490720",
    "end": "1497080"
  },
  {
    "text": "sorry so um thanks um the these demos first I I want to say a note about this",
    "start": "1497080",
    "end": "1503320"
  },
  {
    "text": "these are not open source this is an old UI that we had uh they're not part of the project uh but it just to show you",
    "start": "1503320",
    "end": "1509720"
  },
  {
    "text": "what kind of UI you can build on top of this type of data um the only vendor I",
    "start": "1509720",
    "end": "1514880"
  },
  {
    "text": "know about this about that has a solution is Splunk with Splunk npm and",
    "start": "1514880",
    "end": "1520679"
  },
  {
    "text": "if you know of other other vendors please let me know and I'll include them in slides uh later on um so you know",
    "start": "1520679",
    "end": "1527399"
  },
  {
    "text": "take this not as like I'm pitching you to use this exact thing uh so here you",
    "start": "1527399",
    "end": "1533000"
  },
  {
    "text": "can see um how you can map out cloud architectures with this because you have",
    "start": "1533000",
    "end": "1538799"
  },
  {
    "text": "you know the Roll Roll information which application is talking to which application that you saw refresh there",
    "start": "1538799",
    "end": "1543960"
  },
  {
    "text": "so this updates in real time you can see here throughput for example between the different components and the idea is",
    "start": "1543960",
    "end": "1550640"
  },
  {
    "text": "here is that this updates a lot faster than architecture diagrams so you can know what's happening in your system in",
    "start": "1550640",
    "end": "1556880"
  },
  {
    "text": "real time this is one of the use cases for this in",
    "start": "1556880",
    "end": "1562279"
  },
  {
    "text": "the other one um is how you can debug Security",
    "start": "1562279",
    "end": "1568039"
  },
  {
    "text": "Group problems so here you're monitoring an RDS instance this goes by really fast",
    "start": "1568039",
    "end": "1573640"
  },
  {
    "text": "um on the on the Amazon console we're going to fudge the security group so that they don't allow this port to",
    "start": "1573640",
    "end": "1580279"
  },
  {
    "text": "access RDS we fudged it up right like if you have an error somewhere in your script A refresh can show you these sin",
    "start": "1580279",
    "end": "1587559"
  },
  {
    "text": "timeouts that start occurring very quickly you can see kind of connectivity issues in your",
    "start": "1587559",
    "end": "1595159"
  },
  {
    "text": "cluster okay should I do this yeah so how do you get involved um we have a road map uh it's on the project there's",
    "start": "1598880",
    "end": "1605960"
  },
  {
    "text": "a link here it's just on the repo um and this has a bunch of topics but these are",
    "start": "1605960",
    "end": "1613480"
  },
  {
    "text": "suggestions and we're you know I'm I invite you if you have some that you",
    "start": "1613480",
    "end": "1618600"
  },
  {
    "text": "want to contribute and uh a direction that you think the the project should go",
    "start": "1618600",
    "end": "1624320"
  },
  {
    "text": "just engage this is not a hard road map that we need to follow so to get",
    "start": "1624320",
    "end": "1630840"
  },
  {
    "text": "involved if you haven't deployed yet uh the helm chart is part of the open Telemetry collection of Helm charts um",
    "start": "1630840",
    "end": "1637520"
  },
  {
    "text": "and uh it's called open Telemetry ebpf at this point we didn't want to interrupt folks using the helm chart by",
    "start": "1637520",
    "end": "1643840"
  },
  {
    "text": "renaming it to open Telemetry Network so it's still called o BPF similarly",
    "start": "1643840",
    "end": "1649480"
  },
  {
    "text": "you know we were on cncf slack we monitored that so please hop on um ask whatever you need if you have a problem",
    "start": "1649480",
    "end": "1655840"
  },
  {
    "text": "or you need anything or open an issue on the repos and we have a weekly meeting on Tuesdays and uh here again you know",
    "start": "1655840",
    "end": "1663039"
  },
  {
    "text": "there's the open Telemetry Community repo where you can see all of these meetings and so you can get a link to",
    "start": "1663039",
    "end": "1668519"
  },
  {
    "text": "join super easy uh but uh I didn't include the link or you know I have the time here but just check for the most",
    "start": "1668519",
    "end": "1675080"
  },
  {
    "text": "recent time in case it moves um if I invite everybody uh contribute just go",
    "start": "1675080",
    "end": "1681840"
  },
  {
    "text": "on the repo if you have something that you know if if you see a problem open an",
    "start": "1681840",
    "end": "1687000"
  },
  {
    "text": "issue um or you know submit a patch so there are kind of two main repos the",
    "start": "1687000",
    "end": "1692519"
  },
  {
    "text": "main main repo is the open Telemetry Network one where you can see the colle you the it includes the collectors and",
    "start": "1692519",
    "end": "1698240"
  },
  {
    "text": "the reducers and then there's a build environment uh that includes all of the",
    "start": "1698240",
    "end": "1703399"
  },
  {
    "text": "uh requirements to build the system and uh that is in a separate repos repository which gets arguably less work",
    "start": "1703399",
    "end": "1711399"
  },
  {
    "text": "but it's uh it's still there for you uh and so with that um I'd like to thank",
    "start": "1711399",
    "end": "1717440"
  },
  {
    "text": "shivanu for pulling pulling this off the presentation and um thank you all for coming and uh invite questions so",
    "start": "1717440",
    "end": "1725000"
  },
  {
    "text": "there's a mic in there thank you [Applause]",
    "start": "1725000",
    "end": "1735029"
  },
  {
    "text": "we can wait how memory intensive is the system",
    "start": "1740799",
    "end": "1747760"
  },
  {
    "text": "sorry sorry uh we have another questions there but I'll ask answer this one so good question uh we've spent uh a quite",
    "start": "1747760",
    "end": "1756720"
  },
  {
    "text": "a a bit of engineering effort in order to make sure that the kernel collectors and the reducers are both very uh have",
    "start": "1756720",
    "end": "1764840"
  },
  {
    "text": "very low memory footprint uh we did this uh by uh",
    "start": "1764840",
    "end": "1773720"
  },
  {
    "text": "the if you look at the code uh it pre-allocate large buffers in order to",
    "start": "1773720",
    "end": "1780200"
  },
  {
    "text": "uh in order to be able to hold as much as the largest deployments possible but uh the code is very careful",
    "start": "1780200",
    "end": "1788159"
  },
  {
    "text": "we it's in C++ and we were very careful not to touch that memory so basically you allocate this memory it's a huge",
    "start": "1788159",
    "end": "1794440"
  },
  {
    "text": "chunk but the operating system doesn't actually get pages that that belong to",
    "start": "1794440",
    "end": "1799720"
  },
  {
    "text": "the application until you really need them so this way we were able to avoid maloc and free kind of the overhead on",
    "start": "1799720",
    "end": "1805519"
  },
  {
    "text": "every every time you need to process a socket where you have hundreds of thousands of these events uh while still",
    "start": "1805519",
    "end": "1811720"
  },
  {
    "text": "maintaining low uh low memory utilization I hope this answers the",
    "start": "1811720",
    "end": "1818200"
  },
  {
    "text": "question yeah thanks guys uh super basic question so you mentioned uh a lot of the capabilities you can get during",
    "start": "1818200",
    "end": "1824320"
  },
  {
    "text": "aggregation when you have both sides of a flow available what if you have none of that let's say",
    "start": "1824320",
    "end": "1831000"
  },
  {
    "text": "you only have one side I'm sitting in a kubernetes cluster and a socket has come in from",
    "start": "1831000",
    "end": "1836480"
  },
  {
    "text": "somewhere yes so um the kernel collector collects metadata on on",
    "start": "1836480",
    "end": "1844640"
  },
  {
    "text": "both directions of traffic so both incoming traffic and outgoing traffic so",
    "start": "1844640",
    "end": "1850360"
  },
  {
    "text": "even if you have just one side of the connection you still get almost full Telemetry uh for example you don't get",
    "start": "1850360",
    "end": "1856360"
  },
  {
    "text": "resets on the other side but get resets that you see on your",
    "start": "1856360",
    "end": "1861440"
  },
  {
    "text": "side the then the enrichment function really",
    "start": "1861639",
    "end": "1868760"
  },
  {
    "text": "shines because you want to paint what that other IP address that you don't have a kernel collector on so I",
    "start": "1868760",
    "end": "1874159"
  },
  {
    "text": "mentioned an example with RDS instances uh but also the reducer has support for",
    "start": "1874159",
    "end": "1879360"
  },
  {
    "text": "this reverse mapping of IP addresses to geogra to um autonomous systems so it",
    "start": "1879360",
    "end": "1885440"
  },
  {
    "text": "would tell you this came from 18 this came from Amazon so you'd know",
    "start": "1885440",
    "end": "1891600"
  },
  {
    "text": "roughly so you'd have an IP address but also kind of roughly where it's from if you have no other",
    "start": "1891600",
    "end": "1897519"
  },
  {
    "text": "metadata um the other I'll I'll the other thing is uh you get DNS",
    "start": "1897519",
    "end": "1903320"
  },
  {
    "text": "information so if the site that you have the collector on made the request then",
    "start": "1903320",
    "end": "1909519"
  },
  {
    "text": "you'd least know for example if you tried to send to api. stripe.com You'll",
    "start": "1909519",
    "end": "1914559"
  },
  {
    "text": "the traffic would be labeled with api. stripe.com so as you were talking I another",
    "start": "1914559",
    "end": "1920840"
  },
  {
    "text": "question kind of popped up in mind so uh is there a way to provide maybe a custom",
    "start": "1920840",
    "end": "1926519"
  },
  {
    "text": "enricher maybe I know stuff about my own network obviously cannot tie into ebpf",
    "start": "1926519",
    "end": "1932960"
  },
  {
    "text": "on like let's a a Windows system but I know what that thing is I can provide",
    "start": "1932960",
    "end": "1939000"
  },
  {
    "text": "information is the uh enrichment capability",
    "start": "1939000",
    "end": "1944440"
  },
  {
    "text": "extensible this came up a few times and there so the question is uh can can you",
    "start": "1944440",
    "end": "1950840"
  },
  {
    "text": "add information externally about entities and paint them that way for enrichment uh this came up a few times",
    "start": "1950840",
    "end": "1958639"
  },
  {
    "text": "as we developed the collector the this was too much to we",
    "start": "1958639",
    "end": "1966799"
  },
  {
    "text": "felt like we didn't have the bandwidth in order to implement such a system so you could with a configuration you know con",
    "start": "1966799",
    "end": "1973840"
  },
  {
    "text": "file a yaml file maybe add that and we we didn't do it if you want to contribute that that would be a good uh",
    "start": "1973840",
    "end": "1980679"
  },
  {
    "text": "a good contribution I would say that the the open Telemetry Network collector can",
    "start": "1980679",
    "end": "1986360"
  },
  {
    "text": "is not exclusively for cloud native workloads so if you have a Linux VM it doesn't support Windows but if you have",
    "start": "1986360",
    "end": "1992159"
  },
  {
    "text": "a Linux VM you can slap it on there if you have a bare metal machine slap it on there and it kind of does the right",
    "start": "1992159",
    "end": "1997639"
  },
  {
    "text": "thing it accesses the local uh Docker uh metadata if it's if it's there it",
    "start": "1997639",
    "end": "2004039"
  },
  {
    "text": "accesses instance metadata and uh there are also environment VAR where you can",
    "start": "2004039",
    "end": "2009399"
  },
  {
    "text": "override kind of what cluster it's in kind of logically thank you",
    "start": "2009399",
    "end": "2016440"
  },
  {
    "text": "guys uh so I have a question did you measure the CPU overhead of the ebpf",
    "start": "2019760",
    "end": "2024880"
  },
  {
    "text": "hooks let's say a sustained multi- gigabit transfer rates like maxing out the 20 gbits per second link and what's",
    "start": "2024880",
    "end": "2031760"
  },
  {
    "text": "the CPU over here uh yes I don't have it available right now we did measure it uh",
    "start": "2031760",
    "end": "2037880"
  },
  {
    "text": "we found that the redu sorry The Collector was under oh now I don't",
    "start": "2037880",
    "end": "2045360"
  },
  {
    "text": "remember if it's half a percent or 1% CPU uh so this was something that we measured and we we cared about deeply",
    "start": "2045360",
    "end": "2052760"
  },
  {
    "text": "and we made sure that we measure not only the user space component of the kernel collector but also the evpa",
    "start": "2052760",
    "end": "2060200"
  },
  {
    "text": "functions themselves so we used perf and I have one presentation where we have the recipe and we gave it to to users uh",
    "start": "2060200",
    "end": "2067960"
  },
  {
    "text": "and then they could analyze it and see um right so so that's great that you",
    "start": "2067960",
    "end": "2074358"
  },
  {
    "text": "also measured the CPU time of the of the actual hooks but one problem that I see I saw in one slide you show the two",
    "start": "2074359",
    "end": "2081679"
  },
  {
    "text": "functions two car functions that you could be possibly hooking one was send message the other receive message so assuming those are for",
    "start": "2081679",
    "end": "2087919"
  },
  {
    "text": "TCP a process that's using TCP can pass one megabyte buffer to the kernel so TCP",
    "start": "2087919",
    "end": "2093599"
  },
  {
    "text": "and message will see in one megabyte so that's very efficient that's fine and then the Kel we chop we chop the buffer",
    "start": "2093599",
    "end": "2099119"
  },
  {
    "text": "up into smaller packets later on but for UDP that's that's not the case right an",
    "start": "2099119",
    "end": "2104880"
  },
  {
    "text": "application using UDP and sending megabytes per second cannot pass a one megabyte buffer to the kernel that's",
    "start": "2104880",
    "end": "2110000"
  },
  {
    "text": "going to be rejected immediately so what you end up there is tens of thousands hundreds of thousands of system calls",
    "start": "2110000",
    "end": "2115839"
  },
  {
    "text": "right sending UDP packets at a very small size so if if you have a a kernel hook an EF",
    "start": "2115839",
    "end": "2123200"
  },
  {
    "text": "hook that's hooking udps and mthods say then that's going to be executed I don't know 100,000",
    "start": "2123200",
    "end": "2128920"
  },
  {
    "text": "times if you're actually sending and then and then I like I have strong doubts that the CPU overhead is going to",
    "start": "2128920",
    "end": "2133960"
  },
  {
    "text": "be less than 1% like it doesn't seem very likely yes so there are these extreme",
    "start": "2133960",
    "end": "2140720"
  },
  {
    "text": "cases but if you look at the code there there are a lot of these tricks or",
    "start": "2140720",
    "end": "2146560"
  },
  {
    "text": "mechanisms that we used in order to reduce overhead um so you might see that",
    "start": "2146560",
    "end": "2152400"
  },
  {
    "text": "the ebpf code has a per socket counter and then it only sends messages up to",
    "start": "2152400",
    "end": "2158319"
  },
  {
    "text": "the user space every hundred or thousand reports uh it's a trade-off between how much overhead you have and how much",
    "start": "2158319",
    "end": "2165000"
  },
  {
    "text": "timely is the information that you get um there um we've also significantly",
    "start": "2165000",
    "end": "2171520"
  },
  {
    "text": "optimized the overhead of sending this Telemetry so the encoding is super simple and we made sure that you know",
    "start": "2171520",
    "end": "2178000"
  },
  {
    "text": "it's minimal um for exam another example is we used CF rings to communicate",
    "start": "2178000",
    "end": "2183359"
  },
  {
    "text": "between evf code and user space and those rings um are not shared between different",
    "start": "2183359",
    "end": "2190400"
  },
  {
    "text": "cores there's one per core uh that the operating system manages so there are no locks in order",
    "start": "2190400",
    "end": "2198119"
  },
  {
    "text": "to send these messages so there's multiple things that we optimize in order to reduce overhead to say that you",
    "start": "2198119",
    "end": "2204920"
  },
  {
    "text": "couldn't find this case that is uh abnormal in in overhead I'm I I can't",
    "start": "2204920",
    "end": "2212440"
  },
  {
    "text": "say you wouldn't but I think we covered a lot of the common uh cases and if you find something you know create an issue",
    "start": "2212440",
    "end": "2218839"
  },
  {
    "text": "and let's work on uh reducing it okay great thank you and thank you I think we're at time so let's let's take this",
    "start": "2218839",
    "end": "2225560"
  },
  {
    "text": "uh like if anybody has more questions like take it offline thank you everybody thanks",
    "start": "2225560",
    "end": "2233359"
  }
]
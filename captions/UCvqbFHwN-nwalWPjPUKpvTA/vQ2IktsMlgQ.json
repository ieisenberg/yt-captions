[
  {
    "start": "0",
    "end": "173000"
  },
  {
    "text": "check cool all right how's everyone doing",
    "start": "60",
    "end": "5270"
  },
  {
    "text": "cool so my name is subbu I'm going to be the track host for this afternoon I'd",
    "start": "5270",
    "end": "10769"
  },
  {
    "text": "like to introduce this session by Stephan and David they are from one and one male and media they are going to",
    "start": "10769",
    "end": "17730"
  },
  {
    "text": "talk about how to integrate kubernetes with legacy systems using service mesh",
    "start": "17730",
    "end": "23070"
  },
  {
    "text": "and without further ado here's Stephan and David thanks",
    "start": "23070",
    "end": "30740"
  },
  {
    "text": "hi everybody do you me okay hi everybody wow that's quite a crowd as far as who",
    "start": "33650",
    "end": "41940"
  },
  {
    "text": "as we could see from sket about 600 something people would like to come or of course some of them just have two or",
    "start": "41940",
    "end": "48630"
  },
  {
    "text": "three in parallel but it's quite a crowd and still people are coming in but we",
    "start": "48630",
    "end": "55200"
  },
  {
    "text": "have a tight schedule so let's get started we have some seats left here and the middle seat in the first row is",
    "start": "55200",
    "end": "62070"
  },
  {
    "text": "still free so everybody who would like to volunteer okay so this talk is about",
    "start": "62070",
    "end": "70040"
  },
  {
    "text": "service mesh loves legacy likes legacy service mesh and legacy versus legacy",
    "start": "70040",
    "end": "77960"
  },
  {
    "text": "maybe hates legacy we will see in the talk what we did at one in one is we",
    "start": "77960",
    "end": "87150"
  },
  {
    "text": "have a bunch of we have a freshly new kubernetes cluster and of course we have a bunch of legacy services and what",
    "start": "87150",
    "end": "92940"
  },
  {
    "text": "we'll see in this talk is how we tried to merge both worlds by using service",
    "start": "92940",
    "end": "99450"
  },
  {
    "text": "mesh technology and how good we did or how bad we did so who are we",
    "start": "99450",
    "end": "104490"
  },
  {
    "text": "my name is Stefan videos I'm an expert for container platforms I have a 16",
    "start": "104490",
    "end": "109680"
  },
  {
    "text": "years track record of distributed systems I work in one on one meteor",
    "start": "109680",
    "end": "115290"
  },
  {
    "text": "since 2017 and I'm with with the one in one group since 2005 my current main job",
    "start": "115290",
    "end": "123090"
  },
  {
    "text": "is being a product owner for our internal kubernetes cluster so a set of clusters we just used for internal",
    "start": "123090",
    "end": "130200"
  },
  {
    "text": "purposes where our application operation teams are running their application zone okay I'm damaged miramar ad I am a",
    "start": "130200",
    "end": "138450"
  },
  {
    "text": "systems architect with one alone made in media originally I started as a physicist and gradually moved through",
    "start": "138450",
    "end": "144750"
  },
  {
    "text": "HPC to the internet business and that shift acquired like 15 years ago and for",
    "start": "144750",
    "end": "152160"
  },
  {
    "text": "a couple of years I'm a systems architect with the focus on everything connected with automation so that that's",
    "start": "152160",
    "end": "161669"
  },
  {
    "text": "a lot of work and at the interface between standardizing software development and and creating the matching",
    "start": "161669",
    "end": "168800"
  },
  {
    "text": "infrastructure together with people like Stefan so to give you a quick idea of",
    "start": "168800",
    "end": "176510"
  },
  {
    "start": "173000",
    "end": "388000"
  },
  {
    "text": "who we are and what we do United Internet is one of the biggest",
    "start": "176510",
    "end": "182540"
  },
  {
    "text": "German internet providers and specialists actually we have something",
    "start": "182540",
    "end": "188780"
  },
  {
    "text": "like over 9,000 employees at a time close to 100,000 servers and 10 data",
    "start": "188780",
    "end": "196790"
  },
  {
    "text": "centers distributed worldwide so there's quite a number of challenges to main",
    "start": "196790",
    "end": "202940"
  },
  {
    "text": "business units applications is essentially what you'd call that hosting",
    "start": "202940",
    "end": "208420"
  },
  {
    "text": "and the mail mail email and online data",
    "start": "208420",
    "end": "214280"
  },
  {
    "text": "storage business and X has would be mobile phones and landlines so our",
    "start": "214280",
    "end": "220250"
  },
  {
    "text": "business unit is the one-on-one mailed media as you can see here we are offering mainly email services with",
    "start": "220250",
    "end": "226970"
  },
  {
    "text": "about close to 36 million active users currently most of them using free",
    "start": "226970",
    "end": "235070"
  },
  {
    "text": "accounts but there's premium services as well you see the logos of a couple of",
    "start": "235070",
    "end": "240080"
  },
  {
    "text": "brands you may or may not have seen them gmx and web TV being the largest ones in",
    "start": "240080",
    "end": "245090"
  },
  {
    "text": "Germany and mail.com are also being available internationally as I mentioned",
    "start": "245090",
    "end": "252050"
  },
  {
    "text": "that's the product the product portfolio that made a media is offering main thing",
    "start": "252050",
    "end": "260419"
  },
  {
    "text": "obviously everything around email email contacts calendar stuff like that we",
    "start": "260419",
    "end": "268190"
  },
  {
    "text": "also have an online office offering so that's sort of similar to what you know",
    "start": "268190",
    "end": "274400"
  },
  {
    "text": "from Google probably and we also offer cloud storage things think of Dropbox or",
    "start": "274400",
    "end": "282020"
  },
  {
    "text": "Google Drive so how do we get these products to our customers and so this is",
    "start": "282020",
    "end": "289970"
  },
  {
    "text": "the architecture you as simple as it can be so our product guys have",
    "start": "289970",
    "end": "298830"
  },
  {
    "text": "product ideas obviously developers turned that into code which is thought somewhere in get lab together with the",
    "start": "298830",
    "end": "306150"
  },
  {
    "text": "configuration for the applications from there we have a build system let's think",
    "start": "306150",
    "end": "312390"
  },
  {
    "text": "Jenkins or gate lab CI which produces the deployable artifacts which are",
    "start": "312390",
    "end": "318210"
  },
  {
    "text": "stored in a repository like artifactory from j frog and we also store the",
    "start": "318210",
    "end": "324150"
  },
  {
    "text": "configurations together with the artifacts there we pick the the",
    "start": "324150",
    "end": "330960"
  },
  {
    "text": "artifacts up with with a tool for deploying we are using go CD for orchestrating things like that under the",
    "start": "330960",
    "end": "339540"
  },
  {
    "text": "hood we are doing very lot of graphic rotate sorry great amount of things",
    "start": "339540",
    "end": "345480"
  },
  {
    "text": "using ansible which is a good thing because we're tangible we can deploy to",
    "start": "345480",
    "end": "351360"
  },
  {
    "text": "the host based world about 15,000 hosts which we currently have an Malin media",
    "start": "351360",
    "end": "360230"
  },
  {
    "text": "on the other hand we can use helm from ansible to deploy into kubernetes so you see",
    "start": "360230",
    "end": "367980"
  },
  {
    "text": "both hosts and kubernetes on front of",
    "start": "367980",
    "end": "373890"
  },
  {
    "text": "that we have a load balancer distributing the load between between them or also between the data centers to",
    "start": "373890",
    "end": "381990"
  },
  {
    "text": "provide the products to our customers so",
    "start": "381990",
    "end": "389300"
  },
  {
    "start": "388000",
    "end": "602000"
  },
  {
    "text": "that's about the context in which we are living and working and when we started",
    "start": "389300",
    "end": "395250"
  },
  {
    "text": "kubernetes we hadn't we of course had a strategy why we want to do containers",
    "start": "395250",
    "end": "400710"
  },
  {
    "text": "and you see parts of them there we provide kubernetes as a central installation for the application",
    "start": "400710",
    "end": "407280"
  },
  {
    "text": "operations teams and we use that for centrally providing orchestration of",
    "start": "407280",
    "end": "412290"
  },
  {
    "text": "containers within the 101 mainland media the main goal we want to achieve is having fast deployment cycles we want to",
    "start": "412290",
    "end": "419010"
  },
  {
    "text": "enable the application development and application operator operating teams to fastly deploy their new changes their",
    "start": "419010",
    "end": "426930"
  },
  {
    "text": "customer demands to a running infrastructure and as well developing a new product",
    "start": "426930",
    "end": "432400"
  },
  {
    "text": "and previously before we had kubernetes as a platform of course we partially used virtualization we use bare metal as",
    "start": "432400",
    "end": "438520"
  },
  {
    "text": "well depending on the requirements and every time a team had a new product idea first new systems had to be set up a new",
    "start": "438520",
    "end": "445600"
  },
  {
    "text": "public code had to be written and with kubernetes that's just easy you you have",
    "start": "445600",
    "end": "451690"
  },
  {
    "text": "you're already running infrastructure the capacity is already there you just throw your deployments into the cluster and everything works just out of the box",
    "start": "451690",
    "end": "459220"
  },
  {
    "text": "and we have a focus for multi-tenancy so this is why at least we try taking part",
    "start": "459220",
    "end": "465760"
  },
  {
    "text": "in the multi-tenancy working group of kubernetes as well because multi-tenancy",
    "start": "465760",
    "end": "471789"
  },
  {
    "text": "is crucial for us because we cannot provide a kubernetes cluster for every application operations teams or even",
    "start": "471789",
    "end": "478360"
  },
  {
    "text": "every development team for their own stuff we provide central clusters it's about 15 clusters so far with overall like 500",
    "start": "478360",
    "end": "487840"
  },
  {
    "text": "servers and in these clusters we provide each tenant each application operations",
    "start": "487840",
    "end": "494020"
  },
  {
    "text": "teams their space and we separate them from each other of course by using our",
    "start": "494020",
    "end": "499120"
  },
  {
    "text": "back and port security policies our benefit is we have friendly users so we",
    "start": "499120",
    "end": "504370"
  },
  {
    "text": "don't need to have strong multi-tenancy requirements it is sufficient to just",
    "start": "504370",
    "end": "510070"
  },
  {
    "text": "have them there space where they cannot break the others of course as nearly",
    "start": "510070",
    "end": "515440"
  },
  {
    "text": "everybody who is going for kubernetes we focus on micro services we do not try to",
    "start": "515440",
    "end": "520839"
  },
  {
    "text": "do a lift and shift of the existing monolith but we try to make small services and then put them into",
    "start": "520839",
    "end": "527529"
  },
  {
    "text": "kubernetes as set we have multiple clusters and we split them on multiple",
    "start": "527529",
    "end": "532750"
  },
  {
    "text": "dimensions we have a split between front-end and back-end networks and only the front-end networks of course are",
    "start": "532750",
    "end": "538240"
  },
  {
    "text": "exposed to the public Internet we have multiple data centers where our clusters are running in in fact that's three",
    "start": "538240",
    "end": "544420"
  },
  {
    "text": "clusters one in the US and two in Europe we have a split according to life and non-life systems and interesting is we",
    "start": "544420",
    "end": "553870"
  },
  {
    "text": "do not use virtualization for running kubernetes clusters because since we have a central infrastructure",
    "start": "553870",
    "end": "558910"
  },
  {
    "text": "provisioning we said hey that we don't need that additional layer we can really just use the full power of",
    "start": "558910",
    "end": "566330"
  },
  {
    "text": "another thing which gets important when we talk about service mesh later is our",
    "start": "566330",
    "end": "571410"
  },
  {
    "text": "network infrastructure in our clusters for the pot ciders and the service ciders we use non-routable IP addresses",
    "start": "571410",
    "end": "578550"
  },
  {
    "text": "so they are not routable outside of the kubernetes clusters and they are reused",
    "start": "578550",
    "end": "584250"
  },
  {
    "text": "we use the CG nap space from RFC six five nine eight and so the pot ciders",
    "start": "584250",
    "end": "591000"
  },
  {
    "text": "within different clusters are overlapping so they cannot be uniquely addressed that's important as we will",
    "start": "591000",
    "end": "598410"
  },
  {
    "text": "see later okay it's nice to have",
    "start": "598410",
    "end": "604890"
  },
  {
    "text": "containers but the companies and business for like 30 years and that resulted in about thousand services and",
    "start": "604890",
    "end": "612000"
  },
  {
    "text": "applications being online today as you",
    "start": "612000",
    "end": "617100"
  },
  {
    "text": "can imagine most of them still are running on the ends or hardware and currently about 10% run on the",
    "start": "617100",
    "end": "624150"
  },
  {
    "text": "kubernetes cluster on top of that thousand applications as you can",
    "start": "624150",
    "end": "629250"
  },
  {
    "text": "probably imagine not all of them are micro services yet so it's getting worse with micro service transformation that's",
    "start": "629250",
    "end": "637340"
  },
  {
    "text": "generating a pretty messy mesh of dependencies which needs to be handled",
    "start": "637340",
    "end": "644610"
  },
  {
    "text": "some way or the other on top of that it's obviously we probably will not be",
    "start": "644610",
    "end": "651330"
  },
  {
    "text": "able to move all of them into kubernetes and and containers because some many are",
    "start": "651330",
    "end": "660540"
  },
  {
    "text": "not yet cloud native or cloud ready so some are somewhat just not stateless",
    "start": "660540",
    "end": "666690"
  },
  {
    "text": "need some storage and stuff like that but we cannot easily currently provide",
    "start": "666690",
    "end": "672540"
  },
  {
    "text": "in the kubernetes world we have some very funny legacy things and the ACL",
    "start": "672540",
    "end": "678680"
  },
  {
    "text": "area where we use IP addresses fixed IP address lists and stuff like that so all",
    "start": "678680",
    "end": "684540"
  },
  {
    "text": "of that needs to be sort of translated into the cloud native world or at least",
    "start": "684540",
    "end": "690710"
  },
  {
    "text": "these two worlds need to interact for quite quite a substantial a long time",
    "start": "690710",
    "end": "697570"
  },
  {
    "text": "and we'll see how we how our approach looks like for achieving that and",
    "start": "697570",
    "end": "703950"
  },
  {
    "text": "there's another thing I'd like to mention a typical application may look",
    "start": "703950",
    "end": "709690"
  },
  {
    "text": "like that so dawa is the main the main programming",
    "start": "709690",
    "end": "716920"
  },
  {
    "text": "language and one on one Springwood the current standard good old",
    "start": "716920",
    "end": "722890"
  },
  {
    "text": "spring before but we also have PHP we have a little bit of JavaScript and",
    "start": "722890",
    "end": "728200"
  },
  {
    "text": "nodejs stuff like that and a bunch of other things but on some of all",
    "start": "728200",
    "end": "734410"
  },
  {
    "text": "applications you'd like to have a number of services for observability for",
    "start": "734410",
    "end": "741520"
  },
  {
    "text": "telemetry for a lot of things so besides your actual application code an entire",
    "start": "741520",
    "end": "749020"
  },
  {
    "text": "stack of libraries usually are used in these applications not all of them might be in all applications but that's how it",
    "start": "749020",
    "end": "756880"
  },
  {
    "text": "could look like so every request traverses a number of layers which are",
    "start": "756880",
    "end": "762100"
  },
  {
    "text": "baked into the applications before it can leave the application and when entering the next call dependency it",
    "start": "762100",
    "end": "769570"
  },
  {
    "text": "reverses that stack back so this has to",
    "start": "769570",
    "end": "775720"
  },
  {
    "text": "this is some implementation effort and there's this substantial duplication of work and so wouldn't it be nice to have",
    "start": "775720",
    "end": "785890"
  },
  {
    "text": "something that looks like that which removes all these layers which you need",
    "start": "785890",
    "end": "792610"
  },
  {
    "text": "in all the applications from the applications themselves and puts them into infrastructure components like",
    "start": "792610",
    "end": "799210"
  },
  {
    "text": "using a proxy which is handling that totally language agnostic totally",
    "start": "799210",
    "end": "804370"
  },
  {
    "text": "platform agnostic and so reduces that duplication and lets the developers",
    "start": "804370",
    "end": "811090"
  },
  {
    "text": "focus on the functionality of their application so that's where the benefits",
    "start": "811090",
    "end": "818890"
  },
  {
    "start": "816000",
    "end": "1029000"
  },
  {
    "text": "of the service mesh come into play the main goal of the service mesh is to deal",
    "start": "818890",
    "end": "823960"
  },
  {
    "text": "with the service mess of micro services because as you if you if you gather",
    "start": "823960",
    "end": "829360"
  },
  {
    "text": "additional Microsoft it gets a hundred to get two thousand and gets thousands and you need to keep",
    "start": "829360",
    "end": "835569"
  },
  {
    "text": "track what you have there and how they behave you need to have observability we heard",
    "start": "835569",
    "end": "840669"
  },
  {
    "text": "that term quite a bit the last two days what service measures are doing is they",
    "start": "840669",
    "end": "846219"
  },
  {
    "text": "externalize required standard functionality like extracting telemetry out of the services routing of requests",
    "start": "846219",
    "end": "854109"
  },
  {
    "text": "doing a be switching blue/green deployments Cannery deployments they help us with doing circuit breaking so",
    "start": "854109",
    "end": "861309"
  },
  {
    "text": "if you're upstream service has a problem and is down then it just cuts the circuit especially important if you're",
    "start": "861309",
    "end": "867489"
  },
  {
    "text": "upstream service just gets slow you don't want to have a slow application yourself so you cut the application off",
    "start": "867489",
    "end": "873099"
  },
  {
    "text": "and then you can work just with having no data of course circuit breaking does",
    "start": "873099",
    "end": "878319"
  },
  {
    "text": "only work properly if your application is aware of that that the that it's optional and it's just not there at the",
    "start": "878319",
    "end": "884739"
  },
  {
    "text": "moment and can behave accordingly by using cache data for example rate limiting is always an interesting thing",
    "start": "884739",
    "end": "891099"
  },
  {
    "text": "when you especially know that your service can cope with a specific amount of load and you wanna you want to take",
    "start": "891099",
    "end": "898209"
  },
  {
    "text": "care of the point in time where you get too many requests but you still want to serve those you know your support if you",
    "start": "898209",
    "end": "905649"
  },
  {
    "text": "don't do rate limiting it might be that your service breaks down completely and then you have nothing anymore and the",
    "start": "905649",
    "end": "911709"
  },
  {
    "text": "most important thing for a service mesh for us was doing encryption on the",
    "start": "911709",
    "end": "917529"
  },
  {
    "text": "transport layer and having authentication and authorization and especially we will see that in a few",
    "start": "917529",
    "end": "923199"
  },
  {
    "text": "slides that that's especially important for us when connecting kubernetes",
    "start": "923199",
    "end": "928569"
  },
  {
    "text": "services with house based or legacy services another benefit of the service",
    "start": "928569",
    "end": "934179"
  },
  {
    "text": "mesh is that they can be configured in a declarative way so no change to be",
    "start": "934179",
    "end": "939339"
  },
  {
    "text": "applications themselves I can just declare some yellow stuff and we will see an example in a second I can just",
    "start": "939339",
    "end": "945339"
  },
  {
    "text": "declare a bit of llamo and then have my application enriched by that functionality I can maintain them in a",
    "start": "945339",
    "end": "951729"
  },
  {
    "text": "set in the central fashion I can do infrastructure as code I have all my configuration just in the central git repository and I do every change there I",
    "start": "951729",
    "end": "958989"
  },
  {
    "text": "roll that out and I have everything there and one other prime feature of a",
    "start": "958989",
    "end": "964519"
  },
  {
    "text": "service mesh is that it's language agnostic we just saw the slide where we had an exemplary Java stack of applications but of course usually you",
    "start": "964519",
    "end": "972199"
  },
  {
    "text": "don't have have homogeneous software stacks you have Java stacks you have PHP you have JavaScript you have Fortran",
    "start": "972199",
    "end": "979610"
  },
  {
    "text": "code maybe we don't have em luckily and",
    "start": "979610",
    "end": "986860"
  },
  {
    "text": "you would need to do all the service mesh functionality for each language again and again and with the service",
    "start": "986860",
    "end": "992749"
  },
  {
    "text": "mesh I'm solving that on V and on the infrastructure level it's completely agnostic from the language it just works",
    "start": "992749",
    "end": "999139"
  },
  {
    "text": "at least for the base functionality and what we did is trying that first with is",
    "start": "999139",
    "end": "1006040"
  },
  {
    "text": "do yesterday I wasn't the intro session to link early and there was one one",
    "start": "1006040",
    "end": "1011889"
  },
  {
    "text": "Twitter post on a slide and that said if you want to do it will go for service",
    "start": "1011889",
    "end": "1017379"
  },
  {
    "text": "mesh use lingua G first because then you already have a basis and then you can go for is geo and try that for nine months",
    "start": "1017379",
    "end": "1023640"
  },
  {
    "text": "we will see in a second if it took nine months for us or not we still started with this do so how would that work in a",
    "start": "1023640",
    "end": "1032470"
  },
  {
    "start": "1029000",
    "end": "1201000"
  },
  {
    "text": "service mesh and as you see here you have three parts which have their services a B and C and each of them have",
    "start": "1032470",
    "end": "1039490"
  },
  {
    "text": "just a proxy attached and usually you wouldn't you to have another client within the cluster which has its own",
    "start": "1039490",
    "end": "1045308"
  },
  {
    "text": "proxy it interacts by using the proxy transparently you don't need to do that yourself in the application it interacts",
    "start": "1045309",
    "end": "1052570"
  },
  {
    "text": "with the service a and port 1 and then your request just gets forwarded through your different pots and if you have a",
    "start": "1052570",
    "end": "1060159"
  },
  {
    "text": "destination in the end then that destination within the cluster is still attached to a proxy but what if your",
    "start": "1060159",
    "end": "1068049"
  },
  {
    "text": "client application or your destination application is not part of your kubernetes cluster then if you has",
    "start": "1068049",
    "end": "1074740"
  },
  {
    "text": "something like an ingress gateway and an egress gateway so you have a client which is not service measure or not is",
    "start": "1074740",
    "end": "1080320"
  },
  {
    "text": "too aware outside of your kubernetes cluster requests from that client would be ingested in an ingress gateway like",
    "start": "1080320",
    "end": "1087399"
  },
  {
    "text": "an ingress controller in standard kubernetes and that has its first instance of a",
    "start": "1087399",
    "end": "1092919"
  },
  {
    "text": "proxy and every proxy to proxy connection then has the full flexibility and the full capabilities of the service mesh like",
    "start": "1092919",
    "end": "1099830"
  },
  {
    "text": "for example the TLS encryption between the proxy and the ingress gateway and the proxy of POD one would already be",
    "start": "1099830",
    "end": "1105590"
  },
  {
    "text": "handled by sto the egress gateway is an optional component you don't need to do",
    "start": "1105590",
    "end": "1111140"
  },
  {
    "text": "that you can directly connect to the outside world without the egress gateway as well but the egress gateway can",
    "start": "1111140",
    "end": "1116900"
  },
  {
    "text": "provide additional functionality if you have a dedicated host which has maybe a dedicated IP address and only that one",
    "start": "1116900",
    "end": "1123140"
  },
  {
    "text": "is from a firewall perspective allowed to connect to the outside world out of the kubernetes cluster I promised I will",
    "start": "1123140",
    "end": "1130370"
  },
  {
    "text": "show you a bit of Yamaha SEO would be configured not the issue control plane",
    "start": "1130370",
    "end": "1136580"
  },
  {
    "text": "itself but just for a given service what you see here is you have a client pod",
    "start": "1136580",
    "end": "1141650"
  },
  {
    "text": "and a virtual service and the destination rule these are two CRTs for Sto and then the request would go to the",
    "start": "1141650",
    "end": "1148010"
  },
  {
    "text": "destination pot and what you need to do for a sto service is you need to configure a so-called virtual service",
    "start": "1148010",
    "end": "1155060"
  },
  {
    "text": "the virtual service hasn't in this case an HTTP service it has a roud definition and says 75% of the requests for the",
    "start": "1155060",
    "end": "1163220"
  },
  {
    "text": "reduced service go to version 1 and 25% of the request just go to version 2 so",
    "start": "1163220",
    "end": "1168890"
  },
  {
    "text": "what is subset v1 and subset v2 this is defined in the destination rule there",
    "start": "1168890",
    "end": "1174770"
  },
  {
    "text": "you have the subset declaration and say subset v1 is made up of all the pots",
    "start": "1174770",
    "end": "1180800"
  },
  {
    "text": "which have just this label combination so the pots need to have a label version",
    "start": "1180800",
    "end": "1186320"
  },
  {
    "text": "v1 and then it's part of subset we want so that's already it for each subset or",
    "start": "1186320",
    "end": "1192170"
  },
  {
    "text": "generally you can provide a dedicated load balancer specification so if you want to distinguish between random robin",
    "start": "1192170",
    "end": "1198710"
  },
  {
    "text": "or round robin ok so how do we connect",
    "start": "1198710",
    "end": "1206420"
  },
  {
    "start": "1201000",
    "end": "1328000"
  },
  {
    "text": "all that to the old world with the bunches of legacy applications that's",
    "start": "1206420",
    "end": "1212690"
  },
  {
    "text": "what the master expansion of this you can do and what we work mostly with us",
    "start": "1212690",
    "end": "1218240"
  },
  {
    "text": "the master expansion that has been offered in version 1.0",
    "start": "1218240",
    "end": "1223900"
  },
  {
    "text": "and the principle is relatively easy you just install the envoi proxy at a side",
    "start": "1224059",
    "end": "1230599"
  },
  {
    "text": "of your application on the virtual machine or physical host and just",
    "start": "1230599",
    "end": "1236419"
  },
  {
    "text": "connect that simply to the control plane of Sto which still resides on the kubernetes cluster as Don mentioned TLS",
    "start": "1236419",
    "end": "1245570"
  },
  {
    "text": "encryption mutual TLS encryption was the main focus because some of the",
    "start": "1245570",
    "end": "1251419"
  },
  {
    "text": "applications are not especially the internal ones are not totally capable of",
    "start": "1251419",
    "end": "1256759"
  },
  {
    "text": "running TLS by themselves so that was very very important and getting",
    "start": "1256759",
    "end": "1262960"
  },
  {
    "text": "client-side authentication it's very important to replace that ACL stuff in particular in the server's mesh",
    "start": "1262960",
    "end": "1270559"
  },
  {
    "text": "we can declaratively connect things and that replace the ACS and this instantly",
    "start": "1270559",
    "end": "1280070"
  },
  {
    "text": "also gives you all the telemetry and observability circuit breaking stuff and",
    "start": "1280070",
    "end": "1285769"
  },
  {
    "text": "all the features that is to just brings with the proxy and this is how it",
    "start": "1285769",
    "end": "1291469"
  },
  {
    "text": "essentially looks like I just explained it's essentially installing the proxy on",
    "start": "1291469",
    "end": "1297710"
  },
  {
    "text": "the hosts connected to the control plane and what it immediately worked was",
    "start": "1297710",
    "end": "1303009"
  },
  {
    "text": "calling host based services from the kubernetes cluster this is what the",
    "start": "1303009",
    "end": "1309049"
  },
  {
    "text": "arrows indicate but the same is the same task as true for you other direction",
    "start": "1309049",
    "end": "1315739"
  },
  {
    "text": "which turned out to be a little bit more complicated calling cluster services from from",
    "start": "1315739",
    "end": "1323929"
  },
  {
    "text": "within hosts so but mainly we are here because of the",
    "start": "1323929",
    "end": "1331930"
  },
  {
    "start": "1328000",
    "end": "1505000"
  },
  {
    "text": "problems we had when using SEO at least in our setup I will not say that it's not our fault",
    "start": "1331930",
    "end": "1339610"
  },
  {
    "text": "I'm sure quite of the things what kind of delays have been our fault maybe not using most priority on that but we are",
    "start": "1339610",
    "end": "1347560"
  },
  {
    "text": "here to show what we stumbled upon first thing we noticed our security concerns I",
    "start": "1347560",
    "end": "1353800"
  },
  {
    "text": "mentioned we run in a multi-tenancy environment and the multi-tenancy Pro environment has put security policies so",
    "start": "1353800",
    "end": "1360310"
  },
  {
    "text": "usually we don't allow pots running as root and usually we don't allow pots writing in their topmost container layer",
    "start": "1360310",
    "end": "1367330"
  },
  {
    "text": "if they want to write something they should mount volumes so the sto control",
    "start": "1367330",
    "end": "1372700"
  },
  {
    "text": "plane doesn't do that mostly ok the control plane components we can say hey",
    "start": "1372700",
    "end": "1378940"
  },
  {
    "text": "that's managed objects from us as a cluster provider that's fine",
    "start": "1378940",
    "end": "1384010"
  },
  {
    "text": "but in is 21.0 and before in fact before is to see and I existed the proxies for",
    "start": "1384010",
    "end": "1393640"
  },
  {
    "text": "each application come into play by being a sidecar container in your application pods and these sidecar containers are",
    "start": "1393640",
    "end": "1400510"
  },
  {
    "text": "enriched either in an automatic fashion or in a manual fashion manual fashion means you have an sto control",
    "start": "1400510",
    "end": "1406600"
  },
  {
    "text": "command-line tool which enriches your kubernetes manifest and yet then you can do it you control apply and send them to",
    "start": "1406600",
    "end": "1412480"
  },
  {
    "text": "the cluster the sidecar container the proxy sidecar or not no in fact not the",
    "start": "1412480",
    "end": "1419440"
  },
  {
    "text": "really the proxy sidecar the init container which changes your IP tables rules this needs privileged mode and it needs",
    "start": "1419440",
    "end": "1428410"
  },
  {
    "text": "net admin capabilities and since that's done as part of an application",
    "start": "1428410",
    "end": "1433450"
  },
  {
    "text": "deployment these are privileges and application operator needs to have and not the cluster operator and this is",
    "start": "1433450",
    "end": "1439810"
  },
  {
    "text": "something we really did not like and it was a problem for us the same problem",
    "start": "1439810",
    "end": "1446230"
  },
  {
    "text": "worked with with the book info sample application of Sto they want to run as root as well in most",
    "start": "1446230",
    "end": "1451420"
  },
  {
    "text": "places I think this has improved in 1.1 but still not at the end but we have",
    "start": "1451420",
    "end": "1456670"
  },
  {
    "text": "some patches which we would like to submit to get that fixed as well the citecar injection that's the",
    "start": "1456670",
    "end": "1462929"
  },
  {
    "text": "automatic mechanism I mentioned you can just inject your manifest into a tech namespace and then an admission",
    "start": "1462929",
    "end": "1469919"
  },
  {
    "text": "controller will enrich your configuration if you use port security policies you get a problem with the",
    "start": "1469919",
    "end": "1475919"
  },
  {
    "text": "order of events partially your admission controller for Sto enriches the pot",
    "start": "1475919",
    "end": "1481710"
  },
  {
    "text": "before the port security policies are evaluated or vice versa and it might have have happened that",
    "start": "1481710",
    "end": "1488480"
  },
  {
    "text": "your you had the wrong part security policy identified automatically and then",
    "start": "1488480",
    "end": "1494309"
  },
  {
    "text": "the citecar was attached and then the deployment controller could not deploy your pot anymore because it needed too",
    "start": "1494309",
    "end": "1500309"
  },
  {
    "text": "much permissions for the currently active port security policy another",
    "start": "1500309",
    "end": "1508110"
  },
  {
    "start": "1505000",
    "end": "1591000"
  },
  {
    "text": "problem we had with the mesh expansion was the connection to the control plane in issue 1.0 we had the problem that an",
    "start": "1508110",
    "end": "1516090"
  },
  {
    "text": "expansion node needs to have DNS tweaks you need to tell him that an cluster",
    "start": "1516090",
    "end": "1524940"
  },
  {
    "text": "internal name is available at the IP address of the ingress gateway of Sto",
    "start": "1524940",
    "end": "1530960"
  },
  {
    "text": "there was no way outside of the world to bring that into DNS so the first thing",
    "start": "1530960",
    "end": "1537270"
  },
  {
    "text": "was and that was part of the documentation of Sto that you install the DNS mask on your expansion nodes and",
    "start": "1537270",
    "end": "1543480"
  },
  {
    "text": "then inject your DNS configuration there even when we have that we could not",
    "start": "1543480",
    "end": "1548789"
  },
  {
    "text": "submit telemetry data to sto because that was just done as part of the sto",
    "start": "1548789",
    "end": "1553860"
  },
  {
    "text": "proxies and it tried to reach a pot IP address and not and configurable gateway",
    "start": "1553860",
    "end": "1559890"
  },
  {
    "text": "IP address and as I said our upon IP addresses are from the CG nut range and",
    "start": "1559890",
    "end": "1565080"
  },
  {
    "text": "they are not routable so we were not able to submit telemetry data and the",
    "start": "1565080",
    "end": "1570360"
  },
  {
    "text": "inbound part so you have a host based installation outside of the cluster and want to call a kubernetes service with",
    "start": "1570360",
    "end": "1576390"
  },
  {
    "text": "mesh expansion that we get that we didn't get running at all because it wanted to contact the pot IP addresses",
    "start": "1576390",
    "end": "1583260"
  },
  {
    "text": "of the destination service as well and MPLS did not work out of the box as well",
    "start": "1583260",
    "end": "1592330"
  },
  {
    "text": "okay so in the end it turned out that sto 1.0 was not essentially suitable for",
    "start": "1592330",
    "end": "1600020"
  },
  {
    "text": "our problem and our use case to run it was too many things we had to tweak too",
    "start": "1600020",
    "end": "1606500"
  },
  {
    "text": "many things that didn't work smoothly and in particular Stephan explained the",
    "start": "1606500",
    "end": "1612230"
  },
  {
    "text": "expansion didn't work as as good as we needed that so that was actually a",
    "start": "1612230",
    "end": "1617900"
  },
  {
    "text": "blocker of migrating from migrating a lot of lots of service services into the kubernetes cluster because in that case",
    "start": "1617900",
    "end": "1625940"
  },
  {
    "text": "they wouldn't be able to reach their dependencies so we needed an",
    "start": "1625940",
    "end": "1631640"
  },
  {
    "text": "intermediate solution for helping our colleagues to migrate your stuff what we",
    "start": "1631640",
    "end": "1639110"
  },
  {
    "text": "did as an intermediate thing was something we internally called the service mesh light but don't take photos",
    "start": "1639110",
    "end": "1644540"
  },
  {
    "text": "of that place it's all online so we mimicked a set up that looks a little",
    "start": "1644540",
    "end": "1651470"
  },
  {
    "text": "like a service mesh but it isn't anna kubernetes a world we put a spread",
    "start": "1651470",
    "end": "1657620"
  },
  {
    "text": "sidecar container in front of that to unload client certificates and TLS on",
    "start": "1657620",
    "end": "1663050"
  },
  {
    "text": "the host sides we put an Apache which in most cases we already have available to",
    "start": "1663050",
    "end": "1668620"
  },
  {
    "text": "unload to TLS encryption and verify the client certificates we could sort of",
    "start": "1668620",
    "end": "1676700"
  },
  {
    "text": "semi automate all of that and that helped a lot of colleagues to proceed",
    "start": "1676700",
    "end": "1681830"
  },
  {
    "text": "with their kubernetes migration but of course that's not the thing we want to",
    "start": "1681830",
    "end": "1687260"
  },
  {
    "text": "do in the long run so s21 one has been released is two one one to the rescue",
    "start": "1687260",
    "end": "1695050"
  },
  {
    "text": "spoiler it got a lot better the control plane connections yes we got them",
    "start": "1695050",
    "end": "1701720"
  },
  {
    "text": "running with is to11 without a problem outbound expansion so I have a kubernetes service and want to talk to",
    "start": "1701720",
    "end": "1707120"
  },
  {
    "text": "some host based installation outside of kubernetes works like a charm em TLS setup yes M TLS as well or both between",
    "start": "1707120",
    "end": "1716540"
  },
  {
    "text": "kubernetes servers and expansion servers and for the control plane components yes",
    "start": "1716540",
    "end": "1722150"
  },
  {
    "text": "works out of the box and the one thing I mentioned with the iptables configuration is TOC ni is out",
    "start": "1722150",
    "end": "1727850"
  },
  {
    "text": "runs with admin privileges in as a CNI plugin and not with operator or",
    "start": "1727850",
    "end": "1733580"
  },
  {
    "text": "application operator permissions anymore so even our security concerns there have",
    "start": "1733580",
    "end": "1738740"
  },
  {
    "text": "been solved with is geo 1 node 1 but there always is a but inbound expansion",
    "start": "1738740",
    "end": "1745130"
  },
  {
    "text": "still not working so far because it tries to reach pod IP addresses directly the automatic cycler injection the thing",
    "start": "1745130",
    "end": "1752659"
  },
  {
    "text": "with the order and port security policies we did not test that successfully with 1.1 as well the",
    "start": "1752659",
    "end": "1760100"
  },
  {
    "text": "documentation and general e-service mesh or is - it's complex it's not something",
    "start": "1760100",
    "end": "1765919"
  },
  {
    "text": "you should just take on lightly it's absolutely doable or I hope at least but",
    "start": "1765919",
    "end": "1773059"
  },
  {
    "text": "it is complex and the documentation is partially but that's a matter of development for a fast running thing the",
    "start": "1773059",
    "end": "1779929"
  },
  {
    "text": "documentation is partially inconsistent and one thing which is very important",
    "start": "1779929",
    "end": "1785779"
  },
  {
    "text": "for us multi-tenancy that's a bit unclear still who is responsible for deploying which artifacts into the",
    "start": "1785779",
    "end": "1792679"
  },
  {
    "text": "cluster like who is doing the virtual service who is doing the destination rules is that the destination service",
    "start": "1792679",
    "end": "1797899"
  },
  {
    "text": "provider is the client who wants to deploy that thing and do other things",
    "start": "1797899",
    "end": "1803380"
  },
  {
    "text": "come up which are unclear who has to",
    "start": "1803380",
    "end": "1808880"
  },
  {
    "text": "deploy the service and who needs to have the permissions to deploy specific series what's up next",
    "start": "1808880",
    "end": "1815330"
  },
  {
    "start": "1813000",
    "end": "1948000"
  },
  {
    "text": "of course solving the remaining issues to have a final picture on if issue is the right choice for us to use we want",
    "start": "1815330",
    "end": "1823279"
  },
  {
    "text": "to get the inbound message expansion running we need to evaluate that in large scale they have been multiple discussions regarding the performance",
    "start": "1823279",
    "end": "1829370"
  },
  {
    "text": "overhead of service mesh we want to test that with our test setup we do have services which have thousands of",
    "start": "1829370",
    "end": "1835490"
  },
  {
    "text": "requests per second so that most likely those services will not be one of the",
    "start": "1835490",
    "end": "1840529"
  },
  {
    "text": "first candidates to do yeah that's part of the production readiness things redundancy needs to be tested that it",
    "start": "1840529",
    "end": "1846770"
  },
  {
    "text": "works properly we need to tune the permissions of the control plane components on the end of the series that",
    "start": "1846770",
    "end": "1852409"
  },
  {
    "text": "goes again into the multi-tenancy thing and yeah performance and overhead I already mentioned um and we can get",
    "start": "1852409",
    "end": "1863210"
  },
  {
    "text": "more benefits out of Sto especially it still won that one on further multi cluster connectivity that's definitely a",
    "start": "1863210",
    "end": "1869030"
  },
  {
    "text": "topic for us we want to connect for example our front-end and back-end clusters or make it available that we",
    "start": "1869030",
    "end": "1874670"
  },
  {
    "text": "connect one cluster of one data center with the with a corresponding cluster in the other data center so to help with",
    "start": "1874670",
    "end": "1881360"
  },
  {
    "text": "faint over to have in mesh faint over the locality based routing goes into the",
    "start": "1881360",
    "end": "1887030"
  },
  {
    "text": "direct Asian direction as well we want to have short the shortest possible data paths so why switch over to the other",
    "start": "1887030",
    "end": "1894350"
  },
  {
    "text": "data center if there is a locally deployed service maybe even really cool and spiffy interoperability currently we",
    "start": "1894350",
    "end": "1901430"
  },
  {
    "text": "plan for multi cluster with just having a certificate of the same root CA but we",
    "start": "1901430",
    "end": "1906770"
  },
  {
    "text": "want to have general interoperability by using the spiffy standard and is to has support for that error scenarios are to",
    "start": "1906770",
    "end": "1914600"
  },
  {
    "text": "be tested anyway and authorization is as well something we did not look into so",
    "start": "1914600",
    "end": "1919670"
  },
  {
    "text": "far so specific request based authorization we just have the service",
    "start": "1919670",
    "end": "1924800"
  },
  {
    "text": "to service and direction covered so far and sto was our first choice but we",
    "start": "1924800",
    "end": "1930500"
  },
  {
    "text": "definitely will evaluate link ID as well liberty to in fact and we will see how",
    "start": "1930500",
    "end": "1935690"
  },
  {
    "text": "that behaves according to our requirements and I mentioned that in",
    "start": "1935690",
    "end": "1940730"
  },
  {
    "text": "vegan in the beginning I think we definitely want to provide upstream patches for our concerns as well as far",
    "start": "1940730",
    "end": "1946100"
  },
  {
    "text": "as we can patch them okay so in summary I can probably say that it looks like is",
    "start": "1946100",
    "end": "1953240"
  },
  {
    "start": "1948000",
    "end": "2001000"
  },
  {
    "text": "still one that one fits what what we need most of the things look fine in",
    "start": "1953240",
    "end": "1959450"
  },
  {
    "text": "particular compared to one or zero a couple of things need to be clarified but yeah it's it's doable we think as",
    "start": "1959450",
    "end": "1969440"
  },
  {
    "text": "you heard it's not too easy to set it up and a couple of organizational questions",
    "start": "1969440",
    "end": "1975710"
  },
  {
    "text": "need to be clarified but the overall summary is that the direction of",
    "start": "1975710",
    "end": "1980780"
  },
  {
    "text": "development in istria 1.1 is very very promising and I suppose that at the",
    "start": "1980780",
    "end": "1985910"
  },
  {
    "text": "latest with 1.2 we fully able to set sails and speed up our",
    "start": "1985910",
    "end": "1992020"
  },
  {
    "text": "cloud native journey thanks [Applause]",
    "start": "1992020",
    "end": "2003259"
  }
]
[
  {
    "text": "thank you for attending our session we were not sure we're gonna receive thank",
    "start": "120",
    "end": "5819"
  },
  {
    "text": "you for attending our session we were not sure we're gonna receive such a big",
    "start": "5819",
    "end": "10920"
  },
  {
    "text": "interest in our topic but we're very happy to see you and let's start",
    "start": "10920",
    "end": "17179"
  },
  {
    "text": "so this is a GPU talk too many users very little resources",
    "start": "17760",
    "end": "23279"
  },
  {
    "text": "thank you for coming we're presenting efficient access to share GPU resources",
    "start": "23279",
    "end": "30740"
  },
  {
    "text": "with a Computing engineer with the CERN kubernetes team",
    "start": "30740",
    "end": "35820"
  },
  {
    "text": "I'm Diana I'm a Computing engineer as at CERN as well",
    "start": "35820",
    "end": "41040"
  },
  {
    "text": "okay so for a bit of context certain is the European Center for nuclear research",
    "start": "41040",
    "end": "47100"
  },
  {
    "text": "the largest particle physics laboratory in the world situated in",
    "start": "47100",
    "end": "52620"
  },
  {
    "text": "Geneva Switzerland we one of our biggest apparatus is a",
    "start": "52620",
    "end": "57960"
  },
  {
    "text": "circular accelerator which accelerates protons close to the speed of light and",
    "start": "57960",
    "end": "63660"
  },
  {
    "text": "clockwise and anti-clockwise and in certain points of this accelerator we make them collide",
    "start": "63660",
    "end": "70100"
  },
  {
    "text": "this is one of these points is the compact muon solenoid which is not very Compact and uh",
    "start": "70100",
    "end": "77460"
  },
  {
    "text": "and basically it acts like a big photographic camera which takes uh 40",
    "start": "77460",
    "end": "83700"
  },
  {
    "text": "million pictures per second this is one example of one of those pictures and each accelerator it's a",
    "start": "83700",
    "end": "91259"
  },
  {
    "text": "detector can produce about terabytes of data a second so we actually filtered",
    "start": "91259",
    "end": "97140"
  },
  {
    "text": "this data with hardware and software um filtering and to make it down to a more",
    "start": "97140",
    "end": "103979"
  },
  {
    "text": "manageable size of on the order of 10 gigabits a second but still with all the",
    "start": "103979",
    "end": "109740"
  },
  {
    "text": "all the detectors before we generate about 70 petabytes of data a year and this is just only going to grow up",
    "start": "109740",
    "end": "117299"
  },
  {
    "text": "so we have a very big and large data set and but the good",
    "start": "117299",
    "end": "125100"
  },
  {
    "text": "thing is that this is highly parallelizable which is great for gpus and also in the community we use the",
    "start": "125100",
    "end": "132780"
  },
  {
    "text": "gpus to do simulation even filtering as I explained and also some other event",
    "start": "132780",
    "end": "139260"
  },
  {
    "text": "reconstruction or anal physics um data to process the data",
    "start": "139260",
    "end": "147720"
  },
  {
    "text": "um so we have some challenges when using CPU gpus um some of them some users have",
    "start": "147720",
    "end": "154860"
  },
  {
    "text": "sub-optimal code um basically because they have some strong",
    "start": "154860",
    "end": "160680"
  },
  {
    "text": "interactions between CPU GPU or they move memory around other types of challenges these Legacy code which we do",
    "start": "160680",
    "end": "167819"
  },
  {
    "text": "have a lot and basically code was not designed for CPUs and the people just bought them to gpus it's not going to",
    "start": "167819",
    "end": "174360"
  },
  {
    "text": "work the same way and also some workloads which are",
    "start": "174360",
    "end": "179459"
  },
  {
    "text": "spiking nature so for example we can take this as a as a scientist developing",
    "start": "179459",
    "end": "185280"
  },
  {
    "text": "some algorithm on the notebooks and basically it's just seat idle and it doesn't use the GPU at all on the other",
    "start": "185280",
    "end": "192120"
  },
  {
    "text": "hand there's some infrastructure perspective about the GPU power density constraints but probably the most",
    "start": "192120",
    "end": "198720"
  },
  {
    "text": "important is the limited resources to meet all users demand because gpus are",
    "start": "198720",
    "end": "204180"
  },
  {
    "text": "scarce are expensive and there's a lot of people looking for them",
    "start": "204180",
    "end": "210480"
  },
  {
    "text": "so story time we're going to present three use cases",
    "start": "210480",
    "end": "216060"
  },
  {
    "text": "um and which basically reflect our users uh use cases",
    "start": "216060",
    "end": "221580"
  },
  {
    "text": "so meet Mr Brown Mr Brown is a badly coded simulation job which has some vram",
    "start": "221580",
    "end": "228480"
  },
  {
    "text": "requirements but when he uses it doesn't really take advantage of the GPU so it",
    "start": "228480",
    "end": "235319"
  },
  {
    "text": "you know an average uses about 20 percent of the the GPU processing power",
    "start": "235319",
    "end": "241319"
  },
  {
    "text": "Mr Pink is an inference service which is occasionally triggered by outside events",
    "start": "241319",
    "end": "247019"
  },
  {
    "text": "it's spiky and unpredictable we know that it mostly sits idle but when it",
    "start": "247019",
    "end": "252599"
  },
  {
    "text": "runs it actually takes advantage of the GPU and it also has some other memory",
    "start": "252599",
    "end": "258060"
  },
  {
    "text": "requirements and last but not least Mr orange which is our wild card and uh",
    "start": "258060",
    "end": "263580"
  },
  {
    "text": "we can have this being uh a physics user",
    "start": "263580",
    "end": "268979"
  },
  {
    "text": "that is using some GPU notebook and there's some potential memory leaks or",
    "start": "268979",
    "end": "275280"
  },
  {
    "text": "where or the user just leaves and does not use the GPU and basically the GPU",
    "start": "275280",
    "end": "280979"
  },
  {
    "text": "stays locked to this user which is not using it and it's not returned to the GPU pool",
    "start": "280979",
    "end": "287520"
  },
  {
    "text": "um so to configure all this we're going to use the we're going we're gonna assume that we're using Nvidia cards and",
    "start": "287520",
    "end": "295020"
  },
  {
    "text": "to make this run on our kubernetes cluster we install it with the GPU operator Helm chart and this will",
    "start": "295020",
    "end": "303240"
  },
  {
    "text": "make a new resource available on our cluster which is the GPU resource",
    "start": "303240",
    "end": "308940"
  },
  {
    "text": "so with this in mind let's onboard Mr Orange and as we said before Mr orange is a",
    "start": "308940",
    "end": "316740"
  },
  {
    "text": "Mr Brown story Mr Brown when using the GPU does not really take advantage of",
    "start": "316740",
    "end": "322979"
  },
  {
    "text": "the GPU and we can see that the GPU utilization is on average 10 20 at best",
    "start": "322979",
    "end": "329520"
  },
  {
    "text": "and we can clearly see that it would be really nice to actually share this GPU",
    "start": "329520",
    "end": "335039"
  },
  {
    "text": "with other users because we have we can do this so to do this we are going to first",
    "start": "335039",
    "end": "342780"
  },
  {
    "text": "we're gonna set up time slicing um so basically on time slicing the",
    "start": "342780",
    "end": "349199"
  },
  {
    "text": "scheduler gives an equal amount of share time between the GPU processes and alternates between them in a round robin",
    "start": "349199",
    "end": "355440"
  },
  {
    "text": "fashion but the memory of the GPU card is shared",
    "start": "355440",
    "end": "360720"
  },
  {
    "text": "between all the processes that are assigned to this card though the compute only happens at one",
    "start": "360720",
    "end": "368280"
  },
  {
    "text": "process at a time so to do this we go back to our GPU",
    "start": "368280",
    "end": "373979"
  },
  {
    "text": "operator Helm chart and we do some configuration saying that we want our nvidia.com GPU resource that we had",
    "start": "373979",
    "end": "381240"
  },
  {
    "text": "before to be to to have four replicas now and because we use this rename by",
    "start": "381240",
    "end": "387180"
  },
  {
    "text": "default tag our resources that will be renamed are going to be appended with",
    "start": "387180",
    "end": "393539"
  },
  {
    "text": "the dot shared extension so now we have the Jeep we have the node with one GPU now we have",
    "start": "393539",
    "end": "400319"
  },
  {
    "text": "four GPU shared resources so now we can onboard Mr Pink because we",
    "start": "400319",
    "end": "407520"
  },
  {
    "text": "can share the GPU Mr Brown and Mr Pink are going to run using time sharing and",
    "start": "407520",
    "end": "414060"
  },
  {
    "text": "here we have the same example and at some point Mr Pink randomly is executing",
    "start": "414060",
    "end": "419400"
  },
  {
    "text": "and we can see that we have a better memory consumption and we have improved",
    "start": "419400",
    "end": "424919"
  },
  {
    "text": "GPU utilization we can still see that we can definitely",
    "start": "424919",
    "end": "430020"
  },
  {
    "text": "take more advances of this so we're gonna risk it and onboard our Wild Card Mr Orange",
    "start": "430020",
    "end": "435539"
  },
  {
    "text": "and as I told you before Mr Orange has some memory consumption problems at at",
    "start": "435539",
    "end": "441240"
  },
  {
    "text": "some point is going to execute and he's just going to consume memory and disregard other users so what we'll see",
    "start": "441240",
    "end": "448500"
  },
  {
    "text": "is memory is going to climb up climb up climb up and then at some point in time",
    "start": "448500",
    "end": "453599"
  },
  {
    "text": "Mr Pink is going to go execute and uh he's gonna die because",
    "start": "453599",
    "end": "460259"
  },
  {
    "text": "well stuff happened so this is really bad because we are offering our service",
    "start": "460259",
    "end": "466080"
  },
  {
    "text": "to users and we don't want users to complain look I just ran my simulation last week and I have to do it all over",
    "start": "466080",
    "end": "472800"
  },
  {
    "text": "again so this is the problem with time slicing is",
    "start": "472800",
    "end": "479340"
  },
  {
    "text": "there there's no memory isolation and there's also no ability to set priorities between the processes and",
    "start": "479340",
    "end": "486240"
  },
  {
    "text": "this uh uh this also affects that we cannot use like for this reason we",
    "start": "486240",
    "end": "492840"
  },
  {
    "text": "cannot do latency sensitive applications but as you can see we could share a GPU",
    "start": "492840",
    "end": "498240"
  },
  {
    "text": "between two and a half users and and it was going really well and",
    "start": "498240",
    "end": "505560"
  },
  {
    "text": "this is one of the advantages that this works pretty much on a wide range of Nvidia architectures and it's an easy",
    "start": "505560",
    "end": "512159"
  },
  {
    "text": "way to set up GPU concurrency can we do better I don't know can we",
    "start": "512159",
    "end": "519979"
  },
  {
    "text": "let's see yes I think we can so in this context let's discuss about Mig Mig stands for multi-instance GPU",
    "start": "519979",
    "end": "527820"
  },
  {
    "text": "it's a technology from Nvidia that allows us to share a GPU but now we have isolated",
    "start": "527820",
    "end": "535320"
  },
  {
    "text": "partitions we have isolated memory we have isolated cache we have isolated",
    "start": "535320",
    "end": "540600"
  },
  {
    "text": "compute course so that's similar stuff is not happening again I love this image because it allows us",
    "start": "540600",
    "end": "549000"
  },
  {
    "text": "to see the GPU as an abstraction of eight memory compute memory units and",
    "start": "549000",
    "end": "555000"
  },
  {
    "text": "seven compute units and now we can see but we cannot just randomly take partitions we need to follow certain",
    "start": "555000",
    "end": "562080"
  },
  {
    "text": "rules we can go down down on this image and divide into more partitions that",
    "start": "562080",
    "end": "567899"
  },
  {
    "text": "have less resources as we see fit based on our use cases so remember please that we have eight",
    "start": "567899",
    "end": "575040"
  },
  {
    "text": "memory units and seven compute one and name eight memory in this context means",
    "start": "575040",
    "end": "580260"
  },
  {
    "text": "for a 100 means 40 gigabytes of virtual memory",
    "start": "580260",
    "end": "585959"
  },
  {
    "text": "and in terms of code we just need to set some some stuff in the GPU operator we need to set the strategy to mixed this",
    "start": "585959",
    "end": "593100"
  },
  {
    "text": "is just something we do in order to enumerate the resource type for every Mig device available",
    "start": "593100",
    "end": "598800"
  },
  {
    "text": "and other than that is the same as with time slicing we just have a config map and we say we want these devices to be",
    "start": "598800",
    "end": "605760"
  },
  {
    "text": "available just make sure but when you sum the devices you have the full GPU",
    "start": "605760",
    "end": "612300"
  },
  {
    "text": "because with Mig you can really lose compute or memory if you're not careful",
    "start": "612300",
    "end": "618000"
  },
  {
    "text": "for example here we have 2G point 10 GB we have",
    "start": "618000",
    "end": "624300"
  },
  {
    "text": "three instances and one of 3G 20gb and if you count them you have seven compute",
    "start": "624300",
    "end": "630420"
  },
  {
    "text": "units and you have 30 gigabytes of memory this is what you want and if you apply this malware GPU one will",
    "start": "630420",
    "end": "637740"
  },
  {
    "text": "transform into gpu0 and our media instances",
    "start": "637740",
    "end": "643160"
  },
  {
    "text": "and now with this we can assign instances to our actors we're going to assign the more powerful",
    "start": "643620",
    "end": "649380"
  },
  {
    "text": "one to Mr orange because we saw that he wants more he tries to get all of it",
    "start": "649380",
    "end": "656100"
  },
  {
    "text": "and let's see what's happening one cool thing to to notice this is that",
    "start": "656100",
    "end": "662100"
  },
  {
    "text": "now we can have Telemetry data for every partition so we have nice pink lines",
    "start": "662100",
    "end": "668160"
  },
  {
    "text": "Brown lines orange ones but let's see what this dashboard is telling us",
    "start": "668160",
    "end": "673860"
  },
  {
    "text": "first of all the memory consumption and the GPU utilization is very good they",
    "start": "673860",
    "end": "679140"
  },
  {
    "text": "are trying to get advantage of the resources they have which is very cool on the other side I wanna",
    "start": "679140",
    "end": "686880"
  },
  {
    "text": "I want to ask you to look at the orange line for the memory utilization it goes up and it still goes up up up and at",
    "start": "686880",
    "end": "694800"
  },
  {
    "text": "some point the GPU utilization for Mr orange is going down because Mr orange is trying to allocate",
    "start": "694800",
    "end": "700620"
  },
  {
    "text": "more memory again but now he cannot do it because he's isolated",
    "start": "700620",
    "end": "706320"
  },
  {
    "text": "and he terminates himself a little bit",
    "start": "706320",
    "end": "711839"
  },
  {
    "text": "Mr Brown and Mr ping they have no idea how close they were to a very bad outcome but like even",
    "start": "711839",
    "end": "720079"
  },
  {
    "text": "so the conclusions here are that Mig is cool we have Hardware isolation now we",
    "start": "720300",
    "end": "725940"
  },
  {
    "text": "have monitoring data and we are very flexible based on our use cases",
    "start": "725940",
    "end": "731399"
  },
  {
    "text": "but disadvantages is that Mig comes with a price and I don't mean metaphorical",
    "start": "731399",
    "end": "736860"
  },
  {
    "text": "price it's just very pricey the gpus are very expensive you need Empire or Hopper architecture and it's this is like",
    "start": "736860",
    "end": "743700"
  },
  {
    "text": "server-side gpus are very very expensive from another point of view if you're not",
    "start": "743700",
    "end": "748800"
  },
  {
    "text": "careful you might lose computer memory as I already told you and other than that you need to evict",
    "start": "748800",
    "end": "756300"
  },
  {
    "text": "all the running processes in order to change the layout so this is maybe something you want to keep in mind",
    "start": "756300",
    "end": "763320"
  },
  {
    "text": "I need someone",
    "start": "763320",
    "end": "765920"
  },
  {
    "text": "so the question that you should ask yourself do we have performance trade-offs are we",
    "start": "769019",
    "end": "775019"
  },
  {
    "text": "losing something because we are doing extra work we're sharing and for this we need to do some",
    "start": "775019",
    "end": "780180"
  },
  {
    "text": "benchmarking I don't want to spend too much time here it's just a few words we're using an",
    "start": "780180",
    "end": "786779"
  },
  {
    "text": "Nvidia a140 gigabytes pcie GPU on an 122 kubernetes cluster and we are doing some",
    "start": "786779",
    "end": "794339"
  },
  {
    "text": "simulation script the generates Collision events and this script is",
    "start": "794339",
    "end": "799800"
  },
  {
    "text": "built with execute please check this project out it's very cool it's written in Python",
    "start": "799800",
    "end": "805920"
  },
  {
    "text": "um other than that the script is very heavy on GPU utilization but it's not very heavy on CPU to GPU communication",
    "start": "805920",
    "end": "814320"
  },
  {
    "text": "or memory accesses so just to have a like an overview of what is happening",
    "start": "814320",
    "end": "821040"
  },
  {
    "text": "and yeah let's see the results our first benchmarked use case is what is",
    "start": "821040",
    "end": "826680"
  },
  {
    "text": "happening if we enable time slicing but we are not using it because we are on",
    "start": "826680",
    "end": "831720"
  },
  {
    "text": "boarding only one process this is why it's called shared one and velocity is very small like",
    "start": "831720",
    "end": "837839"
  },
  {
    "text": "initially it was less than two percent but when you drop to less than one percent and I would say this loss is kinda",
    "start": "837839",
    "end": "844500"
  },
  {
    "text": "negligible if you take into account the amount of good stuff you can receive from actually sharing the GPU",
    "start": "844500",
    "end": "852740"
  },
  {
    "text": "the problems appear when we actually have to do the contact switching so when we have this shared two",
    "start": "853320",
    "end": "860399"
  },
  {
    "text": "we are expecting the time to double but I don't know let's look at the last row 30 million particles",
    "start": "860399",
    "end": "867120"
  },
  {
    "text": "if you're looking at it we're expecting the time for share2 to be around 300 seconds actually it's more around for",
    "start": "867120",
    "end": "874519"
  },
  {
    "text": "420 which is a very big loss it's it's enormous it's like more than 100 seconds",
    "start": "874519",
    "end": "880440"
  },
  {
    "text": "and this is not something you want this is the equivalent of almost 40 percent loss",
    "start": "880440",
    "end": "886380"
  },
  {
    "text": "and this is what you have to remember is when you have to do the contact switching and you have a long running process it's gonna come with a price",
    "start": "886380",
    "end": "894300"
  },
  {
    "text": "and don't do it if you have processes that are using the gpus a lot",
    "start": "894300",
    "end": "901079"
  },
  {
    "text": "on the bright side it's not all that on the right side if you onboard more processes like four or eight the time",
    "start": "901079",
    "end": "908760"
  },
  {
    "text": "just doubles you're not losing Additionally you lose once when you have to perform the contact switching but",
    "start": "908760",
    "end": "914940"
  },
  {
    "text": "after that you're in the safe it's cool but yeah you need you need to keep in mind the contact switching otherwise",
    "start": "914940",
    "end": "921120"
  },
  {
    "text": "you're not on the right path but what about Mig with Mig stuff is a",
    "start": "921120",
    "end": "928500"
  },
  {
    "text": "little bit different so the point here is that an a100 GPU has",
    "start": "928500",
    "end": "935399"
  },
  {
    "text": "108 streaming multiprocessors I'm gonna use SMS because it's too long to say it",
    "start": "935399",
    "end": "940440"
  },
  {
    "text": "again so basically when you enable Mig you lose 10 SMS by default by doing",
    "start": "940440",
    "end": "948000"
  },
  {
    "text": "nothing by just enabling and this is equivalent of 9.25 performance",
    "start": "948000",
    "end": "953880"
  },
  {
    "text": "and you care about this because assames is what defines how many could acquires",
    "start": "953880",
    "end": "958980"
  },
  {
    "text": "in tensor cores you have so if you lose 10 of them you lose a lot of course",
    "start": "958980",
    "end": "964380"
  },
  {
    "text": "which is what you can see here the difference is quite big and you care about this but this is left this is the",
    "start": "964380",
    "end": "971699"
  },
  {
    "text": "theoretical stuff and what we want here is we want to do our benchmarking and",
    "start": "971699",
    "end": "976800"
  },
  {
    "text": "see if this aligns with a theoretical ideas and it does",
    "start": "976800",
    "end": "982079"
  },
  {
    "text": "we benchmarked this but 7g 40gb is actually the full GPU but",
    "start": "982079",
    "end": "988740"
  },
  {
    "text": "with Mig enabled this is what it's called 7g because it's the seven compute cores I talked about and 40 GB is the",
    "start": "988740",
    "end": "996000"
  },
  {
    "text": "full memory so yeah velos is about nine percent this is what we expect",
    "start": "996000",
    "end": "1001639"
  },
  {
    "text": "so just remember that if you want to lose Mig you have to actually share the GPU if you just enable Mig but you don't",
    "start": "1001639",
    "end": "1008360"
  },
  {
    "text": "use it you lose scores for nothing it doesn't really make sense",
    "start": "1008360",
    "end": "1013899"
  },
  {
    "text": "Mr Pink is here to help us because it's a lot of tables it's benchmarking I try",
    "start": "1014060",
    "end": "1019279"
  },
  {
    "text": "to make it interesting but this is it's not so much I can do",
    "start": "1019279",
    "end": "1025339"
  },
  {
    "text": "so the first table is just like to give you the Baseline of our calculations but",
    "start": "1025339",
    "end": "1031280"
  },
  {
    "text": "I want to focus on the second one and namely let's let's look at the last column of a second table",
    "start": "1031280",
    "end": "1038178"
  },
  {
    "text": "so we see 1G 5gb this means one compute unit and five",
    "start": "1038179",
    "end": "1043880"
  },
  {
    "text": "gigabytes of memory and we have 2G 10gb which is actually double very sources we're doubling",
    "start": "1043880",
    "end": "1050780"
  },
  {
    "text": "everything we're doubling because we're doubling the memory and we're doubling the bandwidth and we expect the time to",
    "start": "1050780",
    "end": "1057740"
  },
  {
    "text": "be two times better this is what why we save it by ideal scale it's going to be two and our",
    "start": "1057740",
    "end": "1064160"
  },
  {
    "text": "calculation give us 197 and then 198 and we are converging to Ideal value which",
    "start": "1064160",
    "end": "1070280"
  },
  {
    "text": "is very cool some final conclusions here so",
    "start": "1070280",
    "end": "1076700"
  },
  {
    "text": "first Mig is very cool it's kinda suitable for everything because Mig gives you the feeling but",
    "start": "1076700",
    "end": "1083900"
  },
  {
    "text": "you're the only one using a full GPU and you really don't care but there are some other users",
    "start": "1083900",
    "end": "1089600"
  },
  {
    "text": "but with time slicing it's not the case we already know time slicing is very good when you have",
    "start": "1089600",
    "end": "1096320"
  },
  {
    "text": "a lot of idle time and you want to take advantage of it and it's very cool when you have low priority jobs that can run",
    "start": "1096320",
    "end": "1103340"
  },
  {
    "text": "for more time and you don't really care if you use time slicing for users that",
    "start": "1103340",
    "end": "1108620"
  },
  {
    "text": "have a lot of idle time you have to add some kind of memory management",
    "start": "1108620",
    "end": "1115039"
  },
  {
    "text": "procedure or script because you don't want stuff like this to happen again especially in production",
    "start": "1115039",
    "end": "1122620"
  },
  {
    "text": "but yeah time slicing has its use cases but don't use it for something that is",
    "start": "1122620",
    "end": "1127700"
  },
  {
    "text": "very latency sensitive or very performance intensity because the whole switching thing is gonna come with a",
    "start": "1127700",
    "end": "1134299"
  },
  {
    "text": "very big performance price yeah so this is this is not something we",
    "start": "1134299",
    "end": "1140900"
  },
  {
    "text": "talked a lot or mentioned a lot in this talk but it's very nice to know and it took us a",
    "start": "1140900",
    "end": "1147080"
  },
  {
    "text": "while to to actually see what we can do this this is the monitoring of different pipeline utilization so namely we can",
    "start": "1147080",
    "end": "1154760"
  },
  {
    "text": "see if the tensor cores are utilized if floating Point 16 or 32 are utilized and",
    "start": "1154760",
    "end": "1161299"
  },
  {
    "text": "this helps us because now we can understand what kind of jobs our users",
    "start": "1161299",
    "end": "1166520"
  },
  {
    "text": "are running on the gpus and a 100 and h100 they are coming with",
    "start": "1166520",
    "end": "1172520"
  },
  {
    "text": "tensor cores which personally makes them as pricey as they are and if you see",
    "start": "1172520",
    "end": "1178039"
  },
  {
    "text": "that in this graph the tensor cores are really not utilized you want to approach",
    "start": "1178039",
    "end": "1183140"
  },
  {
    "text": "this problem and do something about it and we have a lot of other stuff everything you saw it's something we use",
    "start": "1183140",
    "end": "1190460"
  },
  {
    "text": "for our GPU monitoring so check this link here in the QR code if this is",
    "start": "1190460",
    "end": "1196100"
  },
  {
    "text": "something that is of interest for you because yeah some some kind some stuff took us a lot of time and this maybe",
    "start": "1196100",
    "end": "1202640"
  },
  {
    "text": "could help you yeah I'm gonna give you a sec",
    "start": "1202640",
    "end": "1209740"
  },
  {
    "text": "we did a lot of benchmarking this is not everything of course there is not enough time and I think",
    "start": "1214299",
    "end": "1221120"
  },
  {
    "text": "you're gonna get worked pretty fast by tables and tables but please check out the first thing is",
    "start": "1221120",
    "end": "1227960"
  },
  {
    "text": "the link to our blog post about GPU GPU utilization setting up the GPU operator",
    "start": "1227960",
    "end": "1233900"
  },
  {
    "text": "time slicing different approaches to this it's a lot of things we're still publishing this we're still working on",
    "start": "1233900",
    "end": "1240320"
  },
  {
    "text": "this and feedback is always very welcome so please make sure to foreign",
    "start": "1240320",
    "end": "1248299"
  },
  {
    "text": "operator that just makes our life so much easier because I cannot imagine managing all this stuff for myself",
    "start": "1252640",
    "end": "1261159"
  },
  {
    "text": "and special thanks this is our colleagues this is Ricardo and Diane",
    "start": "1261200",
    "end": "1266919"
  },
  {
    "text": "Ricardo has a keynote tomorrow make sure to check it out they helped us a lot and we are very thankful for for their",
    "start": "1267320",
    "end": "1274520"
  },
  {
    "text": "support on our benchmarking Journey and of course the amazing movie Reservoir Dogs that served as an",
    "start": "1274520",
    "end": "1280760"
  },
  {
    "text": "inspiration for everything you saw today thank you questions",
    "start": "1280760",
    "end": "1286090"
  },
  {
    "text": "[Applause]",
    "start": "1286090",
    "end": "1295029"
  },
  {
    "text": "we have a question here yeah there's a microphone",
    "start": "1297039",
    "end": "1303220"
  },
  {
    "text": "here yeah hi uh Kevin Clues from Nvidia",
    "start": "1304940",
    "end": "1313460"
  },
  {
    "text": "um I have more of a comment than a question so I'm the one that built the",
    "start": "1313460",
    "end": "1318679"
  },
  {
    "text": "time slicing and the make support and I drew that picture that you said um and I just want to add you know at",
    "start": "1318679",
    "end": "1325700"
  },
  {
    "text": "some point in here you said can we do better and I'll just let you know yes you can even do much better than what you have here and so we should talk",
    "start": "1325700",
    "end": "1331460"
  },
  {
    "text": "after this about what you can do yeah when you said you're from a video I I",
    "start": "1331460",
    "end": "1337880"
  },
  {
    "text": "got stressed I thought I got something very wrong",
    "start": "1337880",
    "end": "1343360"
  },
  {
    "text": "hi thanks for the talk can you combine the time slicing with Mick yes you can",
    "start": "1348020",
    "end": "1353120"
  },
  {
    "text": "do this this is possible you basically just replace the resource instead of using the Nvidia GPU use the resource",
    "start": "1353120",
    "end": "1360919"
  },
  {
    "text": "with the make name that you want to time slice",
    "start": "1360919",
    "end": "1365080"
  },
  {
    "text": "before this will be your ideal make Profile or how does it look like",
    "start": "1370340",
    "end": "1375620"
  },
  {
    "text": "so this we actually who works we have the kubeflow cluster which basically is",
    "start": "1375620",
    "end": "1382340"
  },
  {
    "text": "used by multiple users and they aren't actually it was the one that worked with this um we we do some profiling for some",
    "start": "1382340",
    "end": "1390080"
  },
  {
    "text": "users um and we we say which if if their workload actually requires a lot of time",
    "start": "1390080",
    "end": "1396140"
  },
  {
    "text": "to run and a lot of gpus we we give it a test and assign it to some like you",
    "start": "1396140",
    "end": "1402500"
  },
  {
    "text": "should use these cards that appropriately",
    "start": "1402500",
    "end": "1406240"
  },
  {
    "text": "yeah I've more of the same question is how do you define the mic the mic profile",
    "start": "1413360",
    "end": "1419299"
  },
  {
    "text": "because in your example it's very nice you have a four two one but how do you",
    "start": "1419299",
    "end": "1424640"
  },
  {
    "text": "allocate this to the user and isn't it easier to just do seven one g",
    "start": "1424640",
    "end": "1431780"
  },
  {
    "text": "and then let's all the job brands or I don't know the overhead to determine the",
    "start": "1431780",
    "end": "1437600"
  },
  {
    "text": "the Mig profiles the optimal one is way too high so yes this is why we do the",
    "start": "1437600",
    "end": "1444500"
  },
  {
    "text": "benchmarking to just understand the use cases better for each user for each user",
    "start": "1444500",
    "end": "1449900"
  },
  {
    "text": "for groups of users let's say like git love runners or some kind of machine",
    "start": "1449900",
    "end": "1455240"
  },
  {
    "text": "learning training or CI jobs stuff like this so we are kind of grouping them by",
    "start": "1455240",
    "end": "1460940"
  },
  {
    "text": "use case but yeah we we think we're thinking about just uh",
    "start": "1460940",
    "end": "1466460"
  },
  {
    "text": "partitioning it into seven instances but I think if you do it you lose five",
    "start": "1466460",
    "end": "1472520"
  },
  {
    "text": "gigabytes of memory you don't want this but yeah we're thinking because even the",
    "start": "1472520",
    "end": "1478039"
  },
  {
    "text": "smallest partition is very powerful this is this is a possibility we're not we're",
    "start": "1478039",
    "end": "1483380"
  },
  {
    "text": "still like testing the water here yeah and then uh what was the same question",
    "start": "1483380",
    "end": "1488840"
  },
  {
    "text": "is would it be better to have uh worker nodes with one profile only",
    "start": "1488840",
    "end": "1496280"
  },
  {
    "text": "and other part of worker node with a bigger profile and then you just",
    "start": "1496280",
    "end": "1501860"
  },
  {
    "text": "I think this is auto mix like you have done I think this is the way to have",
    "start": "1501860",
    "end": "1506900"
  },
  {
    "text": "nodes with better gpus or smaller and then you just assign to to which one you",
    "start": "1506900",
    "end": "1512179"
  },
  {
    "text": "want because if you want in the future to kind of centralize the whole GPU effort to make sure you are using the",
    "start": "1512179",
    "end": "1519260"
  },
  {
    "text": "GPU to where most possibilities let's say then yes you would have different",
    "start": "1519260",
    "end": "1524419"
  },
  {
    "text": "partitions on different nodes we're not doing it dynamically because you have to evict everything which just doesn't make",
    "start": "1524419",
    "end": "1530299"
  },
  {
    "text": "any sense for us but yeah thank you",
    "start": "1530299",
    "end": "1535360"
  },
  {
    "text": "so if we need to buy a specific license I think you only need the license to",
    "start": "1557600",
    "end": "1564679"
  },
  {
    "text": "have the gpus not for the software itself if I I I don't remember this this",
    "start": "1564679",
    "end": "1571039"
  },
  {
    "text": "was I did this long time ago yeah yeah",
    "start": "1571039",
    "end": "1576100"
  },
  {
    "text": "yeah for the vgpu you need and uh and we talk about them in the blog post yeah so",
    "start": "1577520",
    "end": "1583360"
  },
  {
    "text": "vgpus is actually a bit more I found it a bit more difficult to set up and you",
    "start": "1583360",
    "end": "1589039"
  },
  {
    "text": "need licenses and uh we actually don't fit our use case so we actually didn't go really down on it but we comment we",
    "start": "1589039",
    "end": "1596600"
  },
  {
    "text": "have them and on the blog post just check it out hi",
    "start": "1596600",
    "end": "1602240"
  },
  {
    "text": "yeah thanks for first of all thanks for producing all that Benchmark data it's a really useful resource for the community",
    "start": "1602240",
    "end": "1607760"
  },
  {
    "text": "that I know it takes a long time to produce so thanks for putting that together um my question is uh is it since you've",
    "start": "1607760",
    "end": "1615980"
  },
  {
    "text": "spent all this time evaluating Mig is have you found it to be um better than simply using smaller gpus",
    "start": "1615980",
    "end": "1622400"
  },
  {
    "text": "combined perhaps with an auto scaler",
    "start": "1622400",
    "end": "1626080"
  },
  {
    "text": "um I don't think I we don't use smaller GPS with t-force I think that was the",
    "start": "1627620",
    "end": "1634039"
  },
  {
    "text": "smallest I thought we used on the cluster um I don't think this would be appropriate",
    "start": "1634039",
    "end": "1641179"
  },
  {
    "text": "because well the more amount of Hardware you have you have more power consumption they will probably end up by costing",
    "start": "1641179",
    "end": "1647000"
  },
  {
    "text": "more I would say and basically what we want is just we have a resource problem so we have a lot",
    "start": "1647000",
    "end": "1653059"
  },
  {
    "text": "of users that they want gpus and if they don't find it here they will go somewhere so we tend to offer locally",
    "start": "1653059",
    "end": "1659299"
  },
  {
    "text": "our gpus and we make want to make for example one of the biggest problems is",
    "start": "1659299",
    "end": "1664760"
  },
  {
    "text": "that basically the users take a GPU and keep it so they don't lose access to it",
    "start": "1664760",
    "end": "1669980"
  },
  {
    "text": "and we don't we want to actually have if we share the a100 into seven instances",
    "start": "1669980",
    "end": "1676279"
  },
  {
    "text": "if we have 10 a100 we have 70 instances",
    "start": "1676279",
    "end": "1681919"
  },
  {
    "text": "and this is much more that users can use so they can actually experiment in this",
    "start": "1681919",
    "end": "1687980"
  },
  {
    "text": "small environment and then when they actually have a production code or something that actually requires more",
    "start": "1687980",
    "end": "1693200"
  },
  {
    "text": "processing we assign them to a new graphic cards and yeah that's",
    "start": "1693200",
    "end": "1699620"
  },
  {
    "text": "great thank you",
    "start": "1699620",
    "end": "1702520"
  },
  {
    "text": "hi I was just wondering um where the the data in the grafana charts is coming from is that just",
    "start": "1706220",
    "end": "1712400"
  },
  {
    "text": "coming from dcgm exporter or do you have some other utility yeah so this is this",
    "start": "1712400",
    "end": "1717559"
  },
  {
    "text": "is all very nice the GPU operator from Nvidia is very nice and this is just provided with the dcgm operator and then",
    "start": "1717559",
    "end": "1725240"
  },
  {
    "text": "the UF Prometheus scraping the data and it's made available and yeah that's it",
    "start": "1725240",
    "end": "1731840"
  },
  {
    "text": "thank you",
    "start": "1731840",
    "end": "1734500"
  },
  {
    "text": "we have a question here",
    "start": "1737960",
    "end": "1741100"
  },
  {
    "text": "did you ever try to use the automatic mix position sorry automatic mix precision",
    "start": "1751900",
    "end": "1760120"
  },
  {
    "text": "it was very training a lot I don't know about concrete use cases to give you unfortunately I can ask around and come",
    "start": "1765919",
    "end": "1771980"
  },
  {
    "text": "back to you if you want but yeah we need this and we are really looking into this",
    "start": "1771980",
    "end": "1777679"
  },
  {
    "text": "you're welcome",
    "start": "1777679",
    "end": "1780158"
  },
  {
    "text": "yes hi thanks for the interesting talk I",
    "start": "1786679",
    "end": "1793340"
  },
  {
    "text": "just have a kind of side note to it I saw a lot of monitoring so one case is",
    "start": "1793340",
    "end": "1798799"
  },
  {
    "text": "what you saw that the user is trying to grab too many resources but we also talked about under usage are actually",
    "start": "1798799",
    "end": "1804740"
  },
  {
    "text": "using this monitoring to actually flag the users that are not using so many",
    "start": "1804740",
    "end": "1809840"
  },
  {
    "text": "resources as their request for example even if you have make and you have the bigger partition and then that person is",
    "start": "1809840",
    "end": "1815600"
  },
  {
    "text": "asking for a bigger partition then they actually need to use are you using those kind of data in some way to kind of",
    "start": "1815600",
    "end": "1822140"
  },
  {
    "text": "guide the users to the right profiles or this is just for your benchmarking",
    "start": "1822140",
    "end": "1829240"
  },
  {
    "text": "uh I'd say but we are trying to improve the GP utilization because it's a pain",
    "start": "1829240",
    "end": "1835399"
  },
  {
    "text": "point we have users that need GPU so this is an ongoing thing and the benchmarking is kind of just the",
    "start": "1835399",
    "end": "1840799"
  },
  {
    "text": "beginning so I think we will do this in the future not really flag users this is send them",
    "start": "1840799",
    "end": "1848299"
  },
  {
    "text": "an email this sounds bad but yeah we're gonna use the data to understand the",
    "start": "1848299",
    "end": "1853760"
  },
  {
    "text": "users better and give them more of what they need this would probably be my",
    "start": "1853760",
    "end": "1859700"
  },
  {
    "text": "answer but not for now uh sorry actually also one of the important things is the",
    "start": "1859700",
    "end": "1865039"
  },
  {
    "text": "profiling metrics which basically users are users and they want the best and uh",
    "start": "1865039",
    "end": "1871220"
  },
  {
    "text": "so like they just give me uh a100 but their use case doesn't actually uses the",
    "start": "1871220",
    "end": "1877399"
  },
  {
    "text": "tensor course so maybe they would be more appropriate to use a less uh less",
    "start": "1877399",
    "end": "1882740"
  },
  {
    "text": "recent GPU which is also least less expensive so we actually are are",
    "start": "1882740",
    "end": "1888700"
  },
  {
    "text": "watching this and yeah we take this into consideration to optimize the resources",
    "start": "1888700",
    "end": "1894380"
  },
  {
    "text": "thanks a lot",
    "start": "1894380",
    "end": "1897159"
  },
  {
    "text": "hi uh it sounded like some of your workloads are really responsive you know like filtering on a 10 gigabit incoming",
    "start": "1900260",
    "end": "1906679"
  },
  {
    "text": "data stream um and like on the CPU side you have a lot of history on like CFS and",
    "start": "1906679",
    "end": "1913039"
  },
  {
    "text": "optimizing responsiveness and bulk workloads at the same time do you have any experience with how well time",
    "start": "1913039",
    "end": "1918500"
  },
  {
    "text": "slicing works for these mixed cases if you if you do time sharing and and like",
    "start": "1918500",
    "end": "1923720"
  },
  {
    "text": "these responsive workloads on the same GPU or is that something you haven't looked into",
    "start": "1923720",
    "end": "1929980"
  },
  {
    "text": "I would say I'm not sure I'm gonna answer your question I'm sorry if I don't but I think once you have less GPU",
    "start": "1931220",
    "end": "1940100"
  },
  {
    "text": "utilization because you have some kind of communication additionally to perform",
    "start": "1940100",
    "end": "1945340"
  },
  {
    "text": "you're actually lost is going to be a little bit smaller this is what we saw in the benchmarking we did",
    "start": "1945340",
    "end": "1951980"
  },
  {
    "text": "so once for example we did some machine learning stuff where we had Epoch so",
    "start": "1951980",
    "end": "1957580"
  },
  {
    "text": "when we did this the error was not 40 for sure it was like 10. because you're",
    "start": "1957580",
    "end": "1963020"
  },
  {
    "text": "introducing some extra latency what influences this but we're still",
    "start": "1963020",
    "end": "1968500"
  },
  {
    "text": "researching it we don't know everything but this is the direction probably",
    "start": "1968500",
    "end": "1973520"
  },
  {
    "text": "thank you you're welcome",
    "start": "1973520",
    "end": "1976419"
  },
  {
    "text": "hi there I was wondering how do you select the amount to limit",
    "start": "1981679",
    "end": "1987320"
  },
  {
    "text": "the slice like if it's one one GPU and two gig memory or",
    "start": "1987320",
    "end": "1993320"
  },
  {
    "text": "stuff like that and how do you Monitor and manage it yeah as we told before like we don't",
    "start": "1993320",
    "end": "2000940"
  },
  {
    "text": "actually select this on some use cases we actually go through this effort and",
    "start": "2000940",
    "end": "2006519"
  },
  {
    "text": "assign users because they are actually very active users but generally we want",
    "start": "2006519",
    "end": "2012399"
  },
  {
    "text": "to make an offering make the most gpus available as possible and yeah and then",
    "start": "2012399",
    "end": "2019120"
  },
  {
    "text": "use the user's test with the small GPU and then they can request or like give me an increase on my quota this is",
    "start": "2019120",
    "end": "2027039"
  },
  {
    "text": "probably the best use case scenario that you can do thank you",
    "start": "2027039",
    "end": "2033659"
  },
  {
    "text": "I think that's it I think that's it no more questions",
    "start": "2036840",
    "end": "2042720"
  },
  {
    "text": "thank you for coming and enjoy your coupon thank you",
    "start": "2042720",
    "end": "2049919"
  }
]
[
  {
    "text": "so this is uh scaling kubernetes nodes",
    "start": "880",
    "end": "3120"
  },
  {
    "text": "without breaking the bankery sanity i'm",
    "start": "3120",
    "end": "5120"
  },
  {
    "text": "nick tran and this is brandon over here",
    "start": "5120",
    "end": "9358"
  },
  {
    "text": "um so we'll talk a little bit about",
    "start": "10960",
    "end": "13679"
  },
  {
    "text": "what spot is exactly and some of the",
    "start": "13679",
    "end": "15599"
  },
  {
    "text": "best practices you can use for spot",
    "start": "15599",
    "end": "17680"
  },
  {
    "text": "and then we'll go into",
    "start": "17680",
    "end": "19199"
  },
  {
    "text": "kubernetes and spot how they work well",
    "start": "19199",
    "end": "20800"
  },
  {
    "text": "together and then how to auto scale your",
    "start": "20800",
    "end": "22880"
  },
  {
    "text": "nodes with these spot nodes",
    "start": "22880",
    "end": "25039"
  },
  {
    "text": "and then we'll hopefully go into a demo",
    "start": "25039",
    "end": "26640"
  },
  {
    "text": "after that",
    "start": "26640",
    "end": "28720"
  },
  {
    "text": "so what is ec2 spot",
    "start": "28720",
    "end": "30400"
  },
  {
    "text": "um so ec2 spot is spare virtual machine",
    "start": "30400",
    "end": "32558"
  },
  {
    "text": "capacity",
    "start": "32559",
    "end": "33680"
  },
  {
    "text": "this is available at a steep discount",
    "start": "33680",
    "end": "35520"
  },
  {
    "text": "from on-demand instances",
    "start": "35520",
    "end": "37600"
  },
  {
    "text": "and these instances are the same",
    "start": "37600",
    "end": "39520"
  },
  {
    "text": "underlying instance the only difference",
    "start": "39520",
    "end": "41360"
  },
  {
    "text": "is that",
    "start": "41360",
    "end": "42879"
  },
  {
    "text": "these are interruptable and so what that",
    "start": "42879",
    "end": "45760"
  },
  {
    "text": "means is that ec2 can claim these",
    "start": "45760",
    "end": "48640"
  },
  {
    "text": "instances when they need to for an",
    "start": "48640",
    "end": "50000"
  },
  {
    "text": "on-demand customer and they'll give you",
    "start": "50000",
    "end": "51680"
  },
  {
    "text": "a two-minute notice from which you can",
    "start": "51680",
    "end": "53199"
  },
  {
    "text": "reclaim this instance",
    "start": "53199",
    "end": "55280"
  },
  {
    "text": "sometimes",
    "start": "55280",
    "end": "56559"
  },
  {
    "text": "ec2 can also give you a rebalance",
    "start": "56559",
    "end": "58079"
  },
  {
    "text": "recommendation to give you some more",
    "start": "58079",
    "end": "60320"
  },
  {
    "text": "time and now we'll talk a little bit",
    "start": "60320",
    "end": "62000"
  },
  {
    "text": "about that later",
    "start": "62000",
    "end": "64239"
  },
  {
    "text": "so some common workloads you can use",
    "start": "64239",
    "end": "65680"
  },
  {
    "text": "with spot are quick continuous",
    "start": "65680",
    "end": "67280"
  },
  {
    "text": "integration this could be something like",
    "start": "67280",
    "end": "68560"
  },
  {
    "text": "tekton",
    "start": "68560",
    "end": "69760"
  },
  {
    "text": "or you could also do batch processing",
    "start": "69760",
    "end": "71439"
  },
  {
    "text": "status apis or dev workloads basically",
    "start": "71439",
    "end": "73520"
  },
  {
    "text": "something that's tolerant to the",
    "start": "73520",
    "end": "75200"
  },
  {
    "text": "interruptions and you can clean up",
    "start": "75200",
    "end": "76640"
  },
  {
    "text": "quickly",
    "start": "76640",
    "end": "78880"
  },
  {
    "text": "and so some of these spot best practices",
    "start": "78880",
    "end": "80479"
  },
  {
    "text": "we'll talk about are spot max price and",
    "start": "80479",
    "end": "82880"
  },
  {
    "text": "not how not to set it",
    "start": "82880",
    "end": "84400"
  },
  {
    "text": "flexible instance type requests and",
    "start": "84400",
    "end": "86080"
  },
  {
    "text": "rebalance recommendations and these are",
    "start": "86080",
    "end": "88159"
  },
  {
    "text": "all going to maximize your instance run",
    "start": "88159",
    "end": "89840"
  },
  {
    "text": "time uh minimize the cost you have and",
    "start": "89840",
    "end": "92079"
  },
  {
    "text": "also maximize the chances that you can",
    "start": "92079",
    "end": "93600"
  },
  {
    "text": "get an instance when you ask ec2 for one",
    "start": "93600",
    "end": "97200"
  },
  {
    "text": "so prior to ec2 sorry prior to 2017",
    "start": "97200",
    "end": "100880"
  },
  {
    "text": "the",
    "start": "100880",
    "end": "101759"
  },
  {
    "text": "spot pricing model was a bidding system",
    "start": "101759",
    "end": "104240"
  },
  {
    "text": "and so what this meant was when you set",
    "start": "104240",
    "end": "105759"
  },
  {
    "text": "your max price",
    "start": "105759",
    "end": "107040"
  },
  {
    "text": "um this is what you would pay for the",
    "start": "107040",
    "end": "108720"
  },
  {
    "text": "instance and it would it would maximize",
    "start": "108720",
    "end": "111439"
  },
  {
    "text": "the instance run time based on how high",
    "start": "111439",
    "end": "113520"
  },
  {
    "text": "you set your max price and so sometimes",
    "start": "113520",
    "end": "115600"
  },
  {
    "text": "you would see with this bidding system",
    "start": "115600",
    "end": "116960"
  },
  {
    "text": "is that it would go over the on-demand",
    "start": "116960",
    "end": "118719"
  },
  {
    "text": "price",
    "start": "118719",
    "end": "119600"
  },
  {
    "text": "and so after 2017 ec2 decided to change",
    "start": "119600",
    "end": "122079"
  },
  {
    "text": "this and make it based off long-term",
    "start": "122079",
    "end": "123680"
  },
  {
    "text": "supply and demand and max price is where",
    "start": "123680",
    "end": "126719"
  },
  {
    "text": "uh what you're willing to pay and so if",
    "start": "126719",
    "end": "128879"
  },
  {
    "text": "you don't set max price",
    "start": "128879",
    "end": "130640"
  },
  {
    "text": "um it would default to the on-demand",
    "start": "130640",
    "end": "132319"
  },
  {
    "text": "price",
    "start": "132319",
    "end": "133200"
  },
  {
    "text": "and when you have the max price",
    "start": "133200",
    "end": "136319"
  },
  {
    "text": "set that opens you up to another",
    "start": "136319",
    "end": "138720"
  },
  {
    "text": "condition from which ec2 can reclaim the",
    "start": "138720",
    "end": "140400"
  },
  {
    "text": "instance for you so most of the time",
    "start": "140400",
    "end": "142239"
  },
  {
    "text": "what you want to do is just to not set",
    "start": "142239",
    "end": "143680"
  },
  {
    "text": "max price so that you can maximize your",
    "start": "143680",
    "end": "145440"
  },
  {
    "text": "instance runtime",
    "start": "145440",
    "end": "147760"
  },
  {
    "text": "another one you can do are flexible",
    "start": "147760",
    "end": "149440"
  },
  {
    "text": "instance types so",
    "start": "149440",
    "end": "152319"
  },
  {
    "text": "ec2 has a lot of",
    "start": "152319",
    "end": "154080"
  },
  {
    "text": "vm capacity and it's important to know",
    "start": "154080",
    "end": "156080"
  },
  {
    "text": "how these are segmented across all",
    "start": "156080",
    "end": "157680"
  },
  {
    "text": "regions um and so there are these the",
    "start": "157680",
    "end": "160480"
  },
  {
    "text": "concept of capacity pools which is a",
    "start": "160480",
    "end": "162239"
  },
  {
    "text": "tuple of availability zones and instance",
    "start": "162239",
    "end": "164800"
  },
  {
    "text": "types",
    "start": "164800",
    "end": "165760"
  },
  {
    "text": "and so you can see each of these orange",
    "start": "165760",
    "end": "167200"
  },
  {
    "text": "squares right here uh would be a",
    "start": "167200",
    "end": "169040"
  },
  {
    "text": "capacity pool and if you have some",
    "start": "169040",
    "end": "171599"
  },
  {
    "text": "capacity requirements or resource",
    "start": "171599",
    "end": "173040"
  },
  {
    "text": "requirements for your instances let's",
    "start": "173040",
    "end": "174720"
  },
  {
    "text": "say you need at least a size 2xl the",
    "start": "174720",
    "end": "177280"
  },
  {
    "text": "on-demand price is would say 44 cents",
    "start": "177280",
    "end": "180080"
  },
  {
    "text": "here per hour",
    "start": "180080",
    "end": "181519"
  },
  {
    "text": "you can actually request in 2xl and also",
    "start": "181519",
    "end": "184159"
  },
  {
    "text": "4xl and 8xl and anything above",
    "start": "184159",
    "end": "186720"
  },
  {
    "text": "because the 8xl is still cheaper than",
    "start": "186720",
    "end": "189120"
  },
  {
    "text": "the 2xl because of the spot discount",
    "start": "189120",
    "end": "192800"
  },
  {
    "text": "so capacity pools are the amount of",
    "start": "192800",
    "end": "195840"
  },
  {
    "text": "unused instances in ec2 and so here",
    "start": "195840",
    "end": "198959"
  },
  {
    "text": "we'll have these three capacity pools",
    "start": "198959",
    "end": "200720"
  },
  {
    "text": "which is the m6i.large",
    "start": "200720",
    "end": "202879"
  },
  {
    "text": "and then the us east 2a 2b and 2c",
    "start": "202879",
    "end": "205599"
  },
  {
    "text": "availability zones",
    "start": "205599",
    "end": "207120"
  },
  {
    "text": "and so there's something you can do with",
    "start": "207120",
    "end": "209120"
  },
  {
    "text": "ec2 when you ask for an instance and",
    "start": "209120",
    "end": "210879"
  },
  {
    "text": "that's using the capacity optimized",
    "start": "210879",
    "end": "213120"
  },
  {
    "text": "allocation strategy and when you ask ec2",
    "start": "213120",
    "end": "215920"
  },
  {
    "text": "given these capacity pools it'll pick",
    "start": "215920",
    "end": "217680"
  },
  {
    "text": "from the capacity pool that has the",
    "start": "217680",
    "end": "218959"
  },
  {
    "text": "deepest amount or the most unused",
    "start": "218959",
    "end": "221519"
  },
  {
    "text": "instances and when you use this capacity",
    "start": "221519",
    "end": "224080"
  },
  {
    "text": "optimized allocation strategy that will",
    "start": "224080",
    "end": "226720"
  },
  {
    "text": "really maximize your instance run time",
    "start": "226720",
    "end": "229280"
  },
  {
    "text": "because it'll pick from the ins the pool",
    "start": "229280",
    "end": "231200"
  },
  {
    "text": "that has the most instances meaning that",
    "start": "231200",
    "end": "232879"
  },
  {
    "text": "ec2 will be the will be more less likely",
    "start": "232879",
    "end": "235599"
  },
  {
    "text": "to reclaim your instance because an",
    "start": "235599",
    "end": "237120"
  },
  {
    "text": "on-demand customer needs it",
    "start": "237120",
    "end": "239760"
  },
  {
    "text": "you can see here that here are some",
    "start": "239760",
    "end": "241519"
  },
  {
    "text": "instance types and these are the",
    "start": "241519",
    "end": "243200"
  },
  {
    "text": "frequency of interruptions so",
    "start": "243200",
    "end": "245040"
  },
  {
    "text": "it's important to note that these",
    "start": "245040",
    "end": "246959"
  },
  {
    "text": "interruptions if they do happen are not",
    "start": "246959",
    "end": "249120"
  },
  {
    "text": "going to happen all that often as well",
    "start": "249120",
    "end": "252799"
  },
  {
    "text": "so the one of the best practices you can",
    "start": "253120",
    "end": "255280"
  },
  {
    "text": "also do is rebalance recommendations um",
    "start": "255280",
    "end": "257519"
  },
  {
    "text": "and so this is just a warning that the",
    "start": "257519",
    "end": "259040"
  },
  {
    "text": "interruption is coming and at the worst",
    "start": "259040",
    "end": "261440"
  },
  {
    "text": "this can also come at the same time at",
    "start": "261440",
    "end": "263280"
  },
  {
    "text": "the interruption notice",
    "start": "263280",
    "end": "264800"
  },
  {
    "text": "it will be vended through the same",
    "start": "264800",
    "end": "266479"
  },
  {
    "text": "service the instance metadata service",
    "start": "266479",
    "end": "268160"
  },
  {
    "text": "that you'll see for the interruption",
    "start": "268160",
    "end": "269199"
  },
  {
    "text": "notice and so if you have workloads that",
    "start": "269199",
    "end": "271520"
  },
  {
    "text": "can't be cleaned up in two minutes",
    "start": "271520",
    "end": "273840"
  },
  {
    "text": "this rebalance recommendation might be",
    "start": "273840",
    "end": "275120"
  },
  {
    "text": "useful for you",
    "start": "275120",
    "end": "277759"
  },
  {
    "text": "and so something else so sorry so going",
    "start": "278080",
    "end": "281040"
  },
  {
    "text": "to the next thing kubernetes and spot",
    "start": "281040",
    "end": "282479"
  },
  {
    "text": "work super well together um and",
    "start": "282479",
    "end": "285199"
  },
  {
    "text": "within spot and your cluster you might",
    "start": "285199",
    "end": "287199"
  },
  {
    "text": "want to have these programmatically",
    "start": "287199",
    "end": "288960"
  },
  {
    "text": "configured to watch for these",
    "start": "288960",
    "end": "290080"
  },
  {
    "text": "termination",
    "start": "290080",
    "end": "291759"
  },
  {
    "text": "so these interruption notifications so",
    "start": "291759",
    "end": "294320"
  },
  {
    "text": "within",
    "start": "294320",
    "end": "295919"
  },
  {
    "text": "aws brand has actually worked on the aws",
    "start": "295919",
    "end": "298160"
  },
  {
    "text": "no termination handler and you can",
    "start": "298160",
    "end": "299840"
  },
  {
    "text": "configure this within your clusters to",
    "start": "299840",
    "end": "301520"
  },
  {
    "text": "work",
    "start": "301520",
    "end": "302400"
  },
  {
    "text": "and watch for interruption notifications",
    "start": "302400",
    "end": "304080"
  },
  {
    "text": "in rebalance recommendations",
    "start": "304080",
    "end": "306960"
  },
  {
    "text": "so when you do this there's also an",
    "start": "306960",
    "end": "308720"
  },
  {
    "text": "important kubernetes concept called the",
    "start": "308720",
    "end": "310720"
  },
  {
    "text": "pod disruption budgets",
    "start": "310720",
    "end": "312400"
  },
  {
    "text": "and these are used mostly to ensure that",
    "start": "312400",
    "end": "315039"
  },
  {
    "text": "a certain amount of replicas on your",
    "start": "315039",
    "end": "316400"
  },
  {
    "text": "pods are running at one time and",
    "start": "316400",
    "end": "318240"
  },
  {
    "text": "sometimes if you use pod disruption",
    "start": "318240",
    "end": "319919"
  },
  {
    "text": "budgets you might run into problems when",
    "start": "319919",
    "end": "321680"
  },
  {
    "text": "you have spa instances and they need to",
    "start": "321680",
    "end": "323360"
  },
  {
    "text": "be cleaned up within two minutes",
    "start": "323360",
    "end": "325919"
  },
  {
    "text": "so we'll go into a little bit of an",
    "start": "325919",
    "end": "327520"
  },
  {
    "text": "example here so the kubernetes eviction",
    "start": "327520",
    "end": "329680"
  },
  {
    "text": "api",
    "start": "329680",
    "end": "331120"
  },
  {
    "text": "is what is used when you have when you",
    "start": "331120",
    "end": "333440"
  },
  {
    "text": "drain your node and the cubelet will",
    "start": "333440",
    "end": "335039"
  },
  {
    "text": "basically be sending sig terms and sig",
    "start": "335039",
    "end": "336880"
  },
  {
    "text": "kills based on this kubernetes eviction",
    "start": "336880",
    "end": "338720"
  },
  {
    "text": "api if it respects all the pod",
    "start": "338720",
    "end": "340479"
  },
  {
    "text": "disruption budgets within your cluster",
    "start": "340479",
    "end": "343120"
  },
  {
    "text": "so let's say you have no termination",
    "start": "343120",
    "end": "344560"
  },
  {
    "text": "handler installed in your cluster what",
    "start": "344560",
    "end": "346479"
  },
  {
    "text": "this will do you can configure it to",
    "start": "346479",
    "end": "348000"
  },
  {
    "text": "watch for interruption notices",
    "start": "348000",
    "end": "350479"
  },
  {
    "text": "and when it sees an interruption notice",
    "start": "350479",
    "end": "352160"
  },
  {
    "text": "you can configure it so that it also",
    "start": "352160",
    "end": "353600"
  },
  {
    "text": "drains the node and when it drains the",
    "start": "353600",
    "end": "355440"
  },
  {
    "text": "node what the keyblade will first do",
    "start": "355440",
    "end": "357919"
  },
  {
    "text": "is it'll send some sig terms to the pods",
    "start": "357919",
    "end": "360160"
  },
  {
    "text": "once these have like say let's say that",
    "start": "360160",
    "end": "362240"
  },
  {
    "text": "the pod disruption budgets won't violate",
    "start": "362240",
    "end": "364080"
  },
  {
    "text": "be violated and that you can evict these",
    "start": "364080",
    "end": "365600"
  },
  {
    "text": "pods",
    "start": "365600",
    "end": "366560"
  },
  {
    "text": "um for instance this pod could be saving",
    "start": "366560",
    "end": "368240"
  },
  {
    "text": "data or shutting down",
    "start": "368240",
    "end": "369759"
  },
  {
    "text": "um",
    "start": "369759",
    "end": "370560"
  },
  {
    "text": "and that from that",
    "start": "370560",
    "end": "372000"
  },
  {
    "text": "qubit will send a sig term and",
    "start": "372000",
    "end": "374880"
  },
  {
    "text": "once it's done it'll be deleted",
    "start": "374880",
    "end": "377440"
  },
  {
    "text": "and then you can also do another one",
    "start": "377440",
    "end": "379360"
  },
  {
    "text": "where this could pod this pod could be",
    "start": "379360",
    "end": "381120"
  },
  {
    "text": "draining connections this could be",
    "start": "381120",
    "end": "382240"
  },
  {
    "text": "something like batch processing",
    "start": "382240",
    "end": "384479"
  },
  {
    "text": "sometimes when you are cleaning up your",
    "start": "384479",
    "end": "386560"
  },
  {
    "text": "pods sometimes they take",
    "start": "386560",
    "end": "388319"
  },
  {
    "text": "too long",
    "start": "388319",
    "end": "389840"
  },
  {
    "text": "maybe too long way too long",
    "start": "389840",
    "end": "392240"
  },
  {
    "text": "and that point when it reaches the",
    "start": "392240",
    "end": "393759"
  },
  {
    "text": "termination grace period seconds",
    "start": "393759",
    "end": "395919"
  },
  {
    "text": "the cubelet will send a sig kill to the",
    "start": "395919",
    "end": "397600"
  },
  {
    "text": "pod",
    "start": "397600",
    "end": "399360"
  },
  {
    "text": "and at that point it'll be forcefully",
    "start": "399360",
    "end": "401199"
  },
  {
    "text": "deleted and then it'll be cleaned up",
    "start": "401199",
    "end": "405039"
  },
  {
    "text": "so that's how you can use kubernetes in",
    "start": "405440",
    "end": "407840"
  },
  {
    "text": "spot to clean up your workloads",
    "start": "407840",
    "end": "409680"
  },
  {
    "text": "programmatically",
    "start": "409680",
    "end": "411039"
  },
  {
    "text": "but sometimes we need to also provision",
    "start": "411039",
    "end": "412800"
  },
  {
    "text": "our workloads to get those instances in",
    "start": "412800",
    "end": "414240"
  },
  {
    "text": "the first place",
    "start": "414240",
    "end": "415440"
  },
  {
    "text": "so we'll talk about how to auto scale",
    "start": "415440",
    "end": "416880"
  },
  {
    "text": "your cluster",
    "start": "416880",
    "end": "418400"
  },
  {
    "text": "so",
    "start": "418400",
    "end": "419680"
  },
  {
    "text": "you can use hpa and gpa to auto scale",
    "start": "419680",
    "end": "422160"
  },
  {
    "text": "your pods and so",
    "start": "422160",
    "end": "423840"
  },
  {
    "text": "hpa is the horizontal pod autoscaler and",
    "start": "423840",
    "end": "426160"
  },
  {
    "text": "so when you horizontally scale your pods",
    "start": "426160",
    "end": "428720"
  },
  {
    "text": "this will be in the form of scaling",
    "start": "428720",
    "end": "431680"
  },
  {
    "text": "the amount of desired replicas on your",
    "start": "431680",
    "end": "433599"
  },
  {
    "text": "deployment for your pods and so you see",
    "start": "433599",
    "end": "435680"
  },
  {
    "text": "on the top one you can see the pods",
    "start": "435680",
    "end": "437520"
  },
  {
    "text": "going from one replica to four replicas",
    "start": "437520",
    "end": "439840"
  },
  {
    "text": "and the same would be for vertically",
    "start": "439840",
    "end": "441280"
  },
  {
    "text": "scaling you could go from one smaller",
    "start": "441280",
    "end": "442880"
  },
  {
    "text": "pod that maybe has one v cpu and five",
    "start": "442880",
    "end": "445520"
  },
  {
    "text": "gigs to",
    "start": "445520",
    "end": "447280"
  },
  {
    "text": "a larger pod that is 2v cpu and 10 gigs",
    "start": "447280",
    "end": "451680"
  },
  {
    "text": "and so",
    "start": "451680",
    "end": "452639"
  },
  {
    "text": "within this",
    "start": "452639",
    "end": "454160"
  },
  {
    "text": "sometimes you might not have the nodes",
    "start": "454160",
    "end": "456479"
  },
  {
    "text": "or the instances to hold these pods and",
    "start": "456479",
    "end": "458560"
  },
  {
    "text": "so you need to also auto scale your",
    "start": "458560",
    "end": "460160"
  },
  {
    "text": "nodes",
    "start": "460160",
    "end": "461360"
  },
  {
    "text": "and so",
    "start": "461360",
    "end": "462319"
  },
  {
    "text": "a very common node auto scanning",
    "start": "462319",
    "end": "464319"
  },
  {
    "text": "solution used in kubernetes is the",
    "start": "464319",
    "end": "465840"
  },
  {
    "text": "cluster autoscaler and for aws this is a",
    "start": "465840",
    "end": "468560"
  },
  {
    "text": "simple interface between the",
    "start": "468560",
    "end": "470319"
  },
  {
    "text": "ec2 auto scaling groups and it would",
    "start": "470319",
    "end": "472800"
  },
  {
    "text": "look at the existing pods within the",
    "start": "472800",
    "end": "474479"
  },
  {
    "text": "cluster",
    "start": "474479",
    "end": "475520"
  },
  {
    "text": "and if they can't schedule to the",
    "start": "475520",
    "end": "476879"
  },
  {
    "text": "existing pods sorry it's the existing",
    "start": "476879",
    "end": "478800"
  },
  {
    "text": "nodes",
    "start": "478800",
    "end": "479919"
  },
  {
    "text": "it will increment desired capacity for",
    "start": "479919",
    "end": "481599"
  },
  {
    "text": "the associated asgs that you have",
    "start": "481599",
    "end": "483280"
  },
  {
    "text": "configured",
    "start": "483280",
    "end": "485759"
  },
  {
    "text": "and so cluster autoscaler in this sense",
    "start": "486400",
    "end": "488879"
  },
  {
    "text": "uses externally managed infrastructure",
    "start": "488879",
    "end": "491440"
  },
  {
    "text": "if you have",
    "start": "491440",
    "end": "492800"
  },
  {
    "text": "a lot of different capacity type",
    "start": "492800",
    "end": "494160"
  },
  {
    "text": "requests availabilities and requests and",
    "start": "494160",
    "end": "496240"
  },
  {
    "text": "instance shapes",
    "start": "496240",
    "end": "498560"
  },
  {
    "text": "you could have this set up where you",
    "start": "498560",
    "end": "499919"
  },
  {
    "text": "have six different asgs where they're",
    "start": "499919",
    "end": "501759"
  },
  {
    "text": "each of the yellow ones",
    "start": "501759",
    "end": "504000"
  },
  {
    "text": "and",
    "start": "504000",
    "end": "504960"
  },
  {
    "text": "that leads us to something else that",
    "start": "504960",
    "end": "506960"
  },
  {
    "text": "we'd like to talk about which is",
    "start": "506960",
    "end": "508080"
  },
  {
    "text": "carpenter",
    "start": "508080",
    "end": "509919"
  },
  {
    "text": "yeah so oh clicker cool um so yeah so",
    "start": "509919",
    "end": "513120"
  },
  {
    "text": "that's why we decided can you okay there",
    "start": "513120",
    "end": "514800"
  },
  {
    "text": "we go that's why we decided to build uh",
    "start": "514800",
    "end": "516640"
  },
  {
    "text": "carpenter so carpenter is a new node",
    "start": "516640",
    "end": "518800"
  },
  {
    "text": "auto scaler for kubernetes",
    "start": "518800",
    "end": "520800"
  },
  {
    "text": "it's a groupless node autoscaler so",
    "start": "520800",
    "end": "523039"
  },
  {
    "text": "cluster autoscaler kind of takes the",
    "start": "523039",
    "end": "524320"
  },
  {
    "text": "approach of using this externally",
    "start": "524320",
    "end": "526240"
  },
  {
    "text": "managed infrastructure",
    "start": "526240",
    "end": "527839"
  },
  {
    "text": "like autoscaling groups or virtual",
    "start": "527839",
    "end": "529120"
  },
  {
    "text": "machine groups",
    "start": "529120",
    "end": "530320"
  },
  {
    "text": "that you'd increment this desired",
    "start": "530320",
    "end": "531519"
  },
  {
    "text": "capacity on like nick was talking about",
    "start": "531519",
    "end": "533760"
  },
  {
    "text": "carpenter is completely groupless and",
    "start": "533760",
    "end": "535600"
  },
  {
    "text": "kubernetes native so we use provisioner",
    "start": "535600",
    "end": "537600"
  },
  {
    "text": "crd",
    "start": "537600",
    "end": "538720"
  },
  {
    "text": "which is our custom resource in in",
    "start": "538720",
    "end": "540320"
  },
  {
    "text": "carpenter to define this configuration",
    "start": "540320",
    "end": "542000"
  },
  {
    "text": "for scaling out your nodes",
    "start": "542000",
    "end": "544640"
  },
  {
    "text": "carpenter is familiar to use if you're",
    "start": "544640",
    "end": "546160"
  },
  {
    "text": "coming from cluster autoscaler because",
    "start": "546160",
    "end": "547440"
  },
  {
    "text": "we do we do just in time provisioning so",
    "start": "547440",
    "end": "550000"
  },
  {
    "text": "we look at pending pods that are",
    "start": "550000",
    "end": "551360"
  },
  {
    "text": "unscheduleable",
    "start": "551360",
    "end": "552640"
  },
  {
    "text": "by cube scheduler and that's how we know",
    "start": "552640",
    "end": "554720"
  },
  {
    "text": "when to scale up your cluster",
    "start": "554720",
    "end": "557440"
  },
  {
    "text": "carpenter is designed to be completely",
    "start": "557440",
    "end": "558959"
  },
  {
    "text": "vendor neutral",
    "start": "558959",
    "end": "560160"
  },
  {
    "text": "currently we only have the aws cloud",
    "start": "560160",
    "end": "561519"
  },
  {
    "text": "provider but we're we're hoping to add",
    "start": "561519",
    "end": "563200"
  },
  {
    "text": "on more cloud providers in the future",
    "start": "563200",
    "end": "567120"
  },
  {
    "text": "so let's look at an example here so you",
    "start": "567120",
    "end": "568880"
  },
  {
    "text": "have a cluster you have some pinning",
    "start": "568880",
    "end": "570160"
  },
  {
    "text": "pods coming in",
    "start": "570160",
    "end": "572080"
  },
  {
    "text": "uh just like cluster autoscaler coupe",
    "start": "572080",
    "end": "573600"
  },
  {
    "text": "scheduler gets the first pass so if you",
    "start": "573600",
    "end": "575279"
  },
  {
    "text": "have existing capacity in your nodes",
    "start": "575279",
    "end": "577440"
  },
  {
    "text": "that are running in your cluster",
    "start": "577440",
    "end": "579120"
  },
  {
    "text": "the cube scheduler will just schedule",
    "start": "579120",
    "end": "580800"
  },
  {
    "text": "that those pods onto those nodes",
    "start": "580800",
    "end": "584959"
  },
  {
    "text": "if you have unscheduled pods so this you",
    "start": "585279",
    "end": "587279"
  },
  {
    "text": "know pods that keep scheduler is not",
    "start": "587279",
    "end": "589120"
  },
  {
    "text": "able to place on nodes because of",
    "start": "589120",
    "end": "590640"
  },
  {
    "text": "scheduling constraints or just not",
    "start": "590640",
    "end": "592399"
  },
  {
    "text": "enough capacity",
    "start": "592399",
    "end": "593760"
  },
  {
    "text": "this is where carpenter comes in",
    "start": "593760",
    "end": "595760"
  },
  {
    "text": "so carpenter will look at these pods",
    "start": "595760",
    "end": "597760"
  },
  {
    "text": "it'll look at your provisioner spec",
    "start": "597760",
    "end": "599839"
  },
  {
    "text": "and it'll kind of do an intersection of",
    "start": "599839",
    "end": "601680"
  },
  {
    "text": "the requirements in both the pod spec",
    "start": "601680",
    "end": "604000"
  },
  {
    "text": "and the provisioner spec",
    "start": "604000",
    "end": "605839"
  },
  {
    "text": "and then carpenter will",
    "start": "605839",
    "end": "607440"
  },
  {
    "text": "look at the nodes available in the cloud",
    "start": "607440",
    "end": "609120"
  },
  {
    "text": "that you're launching capacity in and",
    "start": "609120",
    "end": "611440"
  },
  {
    "text": "figure out the set of nodes that it",
    "start": "611440",
    "end": "613040"
  },
  {
    "text": "should launch to fulfill the capacity",
    "start": "613040",
    "end": "616880"
  },
  {
    "text": "so like i was saying carpenter is",
    "start": "617600",
    "end": "619360"
  },
  {
    "text": "completely kubernetes native so there's",
    "start": "619360",
    "end": "621519"
  },
  {
    "text": "no external infrastructure that you have",
    "start": "621519",
    "end": "622880"
  },
  {
    "text": "to set up to use carpenter other than a",
    "start": "622880",
    "end": "624480"
  },
  {
    "text": "few permissions",
    "start": "624480",
    "end": "626079"
  },
  {
    "text": "and so we use a custom resource",
    "start": "626079",
    "end": "627279"
  },
  {
    "text": "definition that we call the provisioner",
    "start": "627279",
    "end": "630079"
  },
  {
    "text": "and so this is an example of a provision",
    "start": "630079",
    "end": "632560"
  },
  {
    "text": "respect",
    "start": "632560",
    "end": "634720"
  },
  {
    "text": "uh so we have some like main sections of",
    "start": "634720",
    "end": "636560"
  },
  {
    "text": "the spec uh main one being the",
    "start": "636560",
    "end": "638079"
  },
  {
    "text": "requirements uh so the requirements uses",
    "start": "638079",
    "end": "640480"
  },
  {
    "text": "the same you know kubernetes",
    "start": "640480",
    "end": "641680"
  },
  {
    "text": "requirements apis that you're probably",
    "start": "641680",
    "end": "643200"
  },
  {
    "text": "familiar with if you're using like",
    "start": "643200",
    "end": "644880"
  },
  {
    "text": "affinities in your pod specs",
    "start": "644880",
    "end": "647920"
  },
  {
    "text": "and we use this to",
    "start": "647920",
    "end": "649519"
  },
  {
    "text": "kind of layer on these scheduling",
    "start": "649519",
    "end": "651600"
  },
  {
    "text": "constraints",
    "start": "651600",
    "end": "652880"
  },
  {
    "text": "so",
    "start": "652880",
    "end": "653839"
  },
  {
    "text": "in this example like the kubernetes i o",
    "start": "653839",
    "end": "656240"
  },
  {
    "text": "arc that's a well-known kubernetes label",
    "start": "656240",
    "end": "658720"
  },
  {
    "text": "to set the cpu architecture",
    "start": "658720",
    "end": "660720"
  },
  {
    "text": "this provisioner is flexible to both",
    "start": "660720",
    "end": "662959"
  },
  {
    "text": "x86 cpu architectures as well as",
    "start": "662959",
    "end": "665920"
  },
  {
    "text": "arm64 architectures so this provisioner",
    "start": "665920",
    "end": "668160"
  },
  {
    "text": "would be allowed to launch",
    "start": "668160",
    "end": "669839"
  },
  {
    "text": "pods that require either of those or if",
    "start": "669839",
    "end": "672399"
  },
  {
    "text": "you build your containers for both",
    "start": "672399",
    "end": "674240"
  },
  {
    "text": "architectures uh carpenter will",
    "start": "674240",
    "end": "676880"
  },
  {
    "text": "union together all the nodes or all the",
    "start": "676880",
    "end": "679360"
  },
  {
    "text": "instance types in the cloud that support",
    "start": "679360",
    "end": "681360"
  },
  {
    "text": "those two architectures and pass it to",
    "start": "681360",
    "end": "683360"
  },
  {
    "text": "ec2 for ec2 to make the best decision",
    "start": "683360",
    "end": "686079"
  },
  {
    "text": "like nick was talking about with the",
    "start": "686079",
    "end": "687200"
  },
  {
    "text": "capacity optimized allocation strategy",
    "start": "687200",
    "end": "689920"
  },
  {
    "text": "with spot this works really well because",
    "start": "689920",
    "end": "691519"
  },
  {
    "text": "you can pass it a huge array of instance",
    "start": "691519",
    "end": "693839"
  },
  {
    "text": "type options and then let ec2 select the",
    "start": "693839",
    "end": "695839"
  },
  {
    "text": "one that's going to run the longest with",
    "start": "695839",
    "end": "697519"
  },
  {
    "text": "the best discount",
    "start": "697519",
    "end": "699920"
  },
  {
    "text": "so similarly to uh you know the cpu",
    "start": "699920",
    "end": "702000"
  },
  {
    "text": "architecture you can also be flexible",
    "start": "702000",
    "end": "703920"
  },
  {
    "text": "across capacity types",
    "start": "703920",
    "end": "705839"
  },
  {
    "text": "so your pods as always can override kind",
    "start": "705839",
    "end": "708480"
  },
  {
    "text": "of what the provisioner's flexibility is",
    "start": "708480",
    "end": "710560"
  },
  {
    "text": "it'll do this layering intersection of",
    "start": "710560",
    "end": "712880"
  },
  {
    "text": "of constraints",
    "start": "712880",
    "end": "714399"
  },
  {
    "text": "but if you're flexible to both spot and",
    "start": "714399",
    "end": "716320"
  },
  {
    "text": "on demand and your provisioner carpenter",
    "start": "716320",
    "end": "718480"
  },
  {
    "text": "assumes that you want the cheapest node",
    "start": "718480",
    "end": "720160"
  },
  {
    "text": "option if you're flexible to both so",
    "start": "720160",
    "end": "721760"
  },
  {
    "text": "we'll default you to spot",
    "start": "721760",
    "end": "724079"
  },
  {
    "text": "uh but you know of course you can",
    "start": "724079",
    "end": "725360"
  },
  {
    "text": "override to on demand if your pods",
    "start": "725360",
    "end": "726880"
  },
  {
    "text": "require that uh kind of or aren't",
    "start": "726880",
    "end": "729200"
  },
  {
    "text": "interruptable",
    "start": "729200",
    "end": "731760"
  },
  {
    "text": "so another section",
    "start": "731760",
    "end": "733120"
  },
  {
    "text": "of the provision respect is the provider",
    "start": "733120",
    "end": "734800"
  },
  {
    "text": "spec so this is a generic spec but in",
    "start": "734800",
    "end": "737120"
  },
  {
    "text": "this example this is the aws cloud",
    "start": "737120",
    "end": "738800"
  },
  {
    "text": "provider this would be where other cloud",
    "start": "738800",
    "end": "740560"
  },
  {
    "text": "providers are also implemented",
    "start": "740560",
    "end": "743120"
  },
  {
    "text": "and this is just you know uh cloud",
    "start": "743120",
    "end": "745040"
  },
  {
    "text": "specific parameters for launching your",
    "start": "745040",
    "end": "747200"
  },
  {
    "text": "your nodes",
    "start": "747200",
    "end": "749839"
  },
  {
    "text": "so nick was talking about this spot best",
    "start": "750560",
    "end": "752160"
  },
  {
    "text": "practices of like not setting a max",
    "start": "752160",
    "end": "754399"
  },
  {
    "text": "price because that was kind of the",
    "start": "754399",
    "end": "755680"
  },
  {
    "text": "bidding error of spot at least on easy",
    "start": "755680",
    "end": "757920"
  },
  {
    "text": "tube",
    "start": "757920",
    "end": "758880"
  },
  {
    "text": "and then you know the big one with spot",
    "start": "758880",
    "end": "760240"
  },
  {
    "text": "best practices is flexibility and that",
    "start": "760240",
    "end": "762240"
  },
  {
    "text": "was one of the main reasons we built",
    "start": "762240",
    "end": "763680"
  },
  {
    "text": "carpenter is because we needed to be",
    "start": "763680",
    "end": "765760"
  },
  {
    "text": "really flexible with the compute request",
    "start": "765760",
    "end": "767600"
  },
  {
    "text": "with all the instance types that ec2 is",
    "start": "767600",
    "end": "770839"
  },
  {
    "text": "releasing and then rebalance",
    "start": "770839",
    "end": "772639"
  },
  {
    "text": "recommendations gives you a way if you",
    "start": "772639",
    "end": "774240"
  },
  {
    "text": "can't tolerate a two minute interruption",
    "start": "774240",
    "end": "776320"
  },
  {
    "text": "window rebalance recommendations can uh",
    "start": "776320",
    "end": "778560"
  },
  {
    "text": "potentially give you more time",
    "start": "778560",
    "end": "780480"
  },
  {
    "text": "to to tolerate or to gracefully shut",
    "start": "780480",
    "end": "782800"
  },
  {
    "text": "down your application",
    "start": "782800",
    "end": "784639"
  },
  {
    "text": "so we're going to look at kind of how",
    "start": "784639",
    "end": "785600"
  },
  {
    "text": "carpenter helps with this approach",
    "start": "785600",
    "end": "788320"
  },
  {
    "text": "and so these are kind of the things i",
    "start": "788320",
    "end": "789600"
  },
  {
    "text": "already mentioned like the architecture",
    "start": "789600",
    "end": "790880"
  },
  {
    "text": "flexibility carpenter builds this right",
    "start": "790880",
    "end": "792480"
  },
  {
    "text": "in uh here where you can be flexible",
    "start": "792480",
    "end": "794800"
  },
  {
    "text": "across different cpu architectures",
    "start": "794800",
    "end": "797600"
  },
  {
    "text": "and then like i was saying your your pod",
    "start": "797600",
    "end": "799200"
  },
  {
    "text": "spec here if you require specific",
    "start": "799200",
    "end": "801600"
  },
  {
    "text": "architecture you can override it in the",
    "start": "801600",
    "end": "803120"
  },
  {
    "text": "pod spec",
    "start": "803120",
    "end": "804800"
  },
  {
    "text": "capacity type works the exact same way",
    "start": "804800",
    "end": "806639"
  },
  {
    "text": "with spot and on demand it will default",
    "start": "806639",
    "end": "808480"
  },
  {
    "text": "to spot if you're flexible to both",
    "start": "808480",
    "end": "810320"
  },
  {
    "text": "and you can override in the pod spec",
    "start": "810320",
    "end": "812959"
  },
  {
    "text": "uh and the requirements section isn't uh",
    "start": "812959",
    "end": "815839"
  },
  {
    "text": "limited to just the ones i'm showing",
    "start": "815839",
    "end": "817279"
  },
  {
    "text": "here these these are kind of well-known",
    "start": "817279",
    "end": "818639"
  },
  {
    "text": "labels in kubernetes uh there's not a",
    "start": "818639",
    "end": "820639"
  },
  {
    "text": "capacity type one on label and",
    "start": "820639",
    "end": "821920"
  },
  {
    "text": "kubernetes so we've used the carpenter",
    "start": "821920",
    "end": "824160"
  },
  {
    "text": "namespace for it",
    "start": "824160",
    "end": "825760"
  },
  {
    "text": "but you can use your own labels here so",
    "start": "825760",
    "end": "827360"
  },
  {
    "text": "you can kind of make your own scheduling",
    "start": "827360",
    "end": "829600"
  },
  {
    "text": "constraints if you need that so another",
    "start": "829600",
    "end": "831680"
  },
  {
    "text": "one that is a well-known label is the",
    "start": "831680",
    "end": "833600"
  },
  {
    "text": "node kubernetes instance type label so",
    "start": "833600",
    "end": "835839"
  },
  {
    "text": "if you do require if your",
    "start": "835839",
    "end": "838000"
  },
  {
    "text": "pods can't run on specific nodes you can",
    "start": "838000",
    "end": "840560"
  },
  {
    "text": "do an exclusion list here and again it",
    "start": "840560",
    "end": "842720"
  },
  {
    "text": "uses the requirements api and kubernetes",
    "start": "842720",
    "end": "844399"
  },
  {
    "text": "so you just do a nod in operator here",
    "start": "844399",
    "end": "848000"
  },
  {
    "text": "so another interesting scheduling",
    "start": "848560",
    "end": "850160"
  },
  {
    "text": "constraint you can do is with gpus or",
    "start": "850160",
    "end": "852560"
  },
  {
    "text": "extended resources more generally so in",
    "start": "852560",
    "end": "855279"
  },
  {
    "text": "this pod spec you're",
    "start": "855279",
    "end": "856880"
  },
  {
    "text": "you're doing a resource request for",
    "start": "856880",
    "end": "858800"
  },
  {
    "text": "nvidia gpu and carpenter knows how to",
    "start": "858800",
    "end": "861519"
  },
  {
    "text": "look at your gpu resource requests",
    "start": "861519",
    "end": "863839"
  },
  {
    "text": "query your cloud provider for nodes that",
    "start": "863839",
    "end": "865760"
  },
  {
    "text": "support an nvidia gpu and then provision",
    "start": "865760",
    "end": "868800"
  },
  {
    "text": "that",
    "start": "868800",
    "end": "869519"
  },
  {
    "text": "instance for this for this pod",
    "start": "869519",
    "end": "873279"
  },
  {
    "text": "so here's a little bit more details on",
    "start": "873600",
    "end": "874880"
  },
  {
    "text": "the aws cloud provider side and how",
    "start": "874880",
    "end": "876320"
  },
  {
    "text": "we're doing this flexibility that we've",
    "start": "876320",
    "end": "878079"
  },
  {
    "text": "kind of talked about a little bit but",
    "start": "878079",
    "end": "879279"
  },
  {
    "text": "this is more concrete on the apis that",
    "start": "879279",
    "end": "880959"
  },
  {
    "text": "we're using",
    "start": "880959",
    "end": "882160"
  },
  {
    "text": "so we use the ec2 fleet api",
    "start": "882160",
    "end": "884639"
  },
  {
    "text": "in what's called instant mode",
    "start": "884639",
    "end": "887199"
  },
  {
    "text": "so carpenter will get these unscheduled",
    "start": "887199",
    "end": "889440"
  },
  {
    "text": "pods",
    "start": "889440",
    "end": "890480"
  },
  {
    "text": "and then it will compute this constraint",
    "start": "890480",
    "end": "892240"
  },
  {
    "text": "intersection between the pod specs",
    "start": "892240",
    "end": "894560"
  },
  {
    "text": "and the provisioner spec",
    "start": "894560",
    "end": "896399"
  },
  {
    "text": "and once it does that it'll query the",
    "start": "896399",
    "end": "898560"
  },
  {
    "text": "cloud provider for all the instance",
    "start": "898560",
    "end": "900240"
  },
  {
    "text": "types that match the scheduling",
    "start": "900240",
    "end": "901519"
  },
  {
    "text": "constraints and the bin packing that",
    "start": "901519",
    "end": "903199"
  },
  {
    "text": "carpenter is doing for the pods onto",
    "start": "903199",
    "end": "905279"
  },
  {
    "text": "those nodes",
    "start": "905279",
    "end": "906720"
  },
  {
    "text": "once it computes this list of instance",
    "start": "906720",
    "end": "908399"
  },
  {
    "text": "types it'll pass that to the ec2 fleet",
    "start": "908399",
    "end": "910639"
  },
  {
    "text": "api with an allocation strategy so if",
    "start": "910639",
    "end": "912639"
  },
  {
    "text": "you're using spot it'll use capacity",
    "start": "912639",
    "end": "914240"
  },
  {
    "text": "optimize and if you're using",
    "start": "914240",
    "end": "917199"
  },
  {
    "text": "on demand it'll be a lowest price",
    "start": "917199",
    "end": "918959"
  },
  {
    "text": "allocation strategy",
    "start": "918959",
    "end": "920720"
  },
  {
    "text": "but you can potentially get you know a",
    "start": "920720",
    "end": "922639"
  },
  {
    "text": "huge list of these instance type options",
    "start": "922639",
    "end": "925440"
  },
  {
    "text": "which makes you know obviously your",
    "start": "925440",
    "end": "926639"
  },
  {
    "text": "request very flexible uh you you have",
    "start": "926639",
    "end": "928880"
  },
  {
    "text": "more guarantees on getting capacity",
    "start": "928880",
    "end": "931199"
  },
  {
    "text": "and hopefully your spot capacity will",
    "start": "931199",
    "end": "932800"
  },
  {
    "text": "also live a lot longer",
    "start": "932800",
    "end": "935920"
  },
  {
    "text": "so and all of this is taken care of with",
    "start": "936480",
    "end": "938320"
  },
  {
    "text": "one provision respect you don't need to",
    "start": "938320",
    "end": "940000"
  },
  {
    "text": "make a bunch of these",
    "start": "940000",
    "end": "941680"
  },
  {
    "text": "provisioners to get you know hugely",
    "start": "941680",
    "end": "943759"
  },
  {
    "text": "flexible a set of instance types that",
    "start": "943759",
    "end": "945839"
  },
  {
    "text": "are launched",
    "start": "945839",
    "end": "947120"
  },
  {
    "text": "and so like this provisioner will",
    "start": "947120",
    "end": "948320"
  },
  {
    "text": "support on-demand spot different cpu",
    "start": "948320",
    "end": "950800"
  },
  {
    "text": "architectures gpus",
    "start": "950800",
    "end": "952800"
  },
  {
    "text": "all of that",
    "start": "952800",
    "end": "954079"
  },
  {
    "text": "we also support topology constraints for",
    "start": "954079",
    "end": "956480"
  },
  {
    "text": "zonal constraints host names you know",
    "start": "956480",
    "end": "958560"
  },
  {
    "text": "all the regular stuff you're doing with",
    "start": "958560",
    "end": "960000"
  },
  {
    "text": "your pod topology today",
    "start": "960000",
    "end": "963680"
  },
  {
    "text": "so we talked a lot about scaling up so",
    "start": "964000",
    "end": "965920"
  },
  {
    "text": "now let's talk a little bit about",
    "start": "965920",
    "end": "966880"
  },
  {
    "text": "scaling down so carpenter has two main",
    "start": "966880",
    "end": "968800"
  },
  {
    "text": "fields in the provisional spec that",
    "start": "968800",
    "end": "970399"
  },
  {
    "text": "controls scaling down",
    "start": "970399",
    "end": "972079"
  },
  {
    "text": "so we have a ttl seconds after empty and",
    "start": "972079",
    "end": "974240"
  },
  {
    "text": "so this is when you have a node up and",
    "start": "974240",
    "end": "976160"
  },
  {
    "text": "all of your pods are evicted or you know",
    "start": "976160",
    "end": "978720"
  },
  {
    "text": "exit if they're jobs",
    "start": "978720",
    "end": "980639"
  },
  {
    "text": "and so you need to spin that node down",
    "start": "980639",
    "end": "982240"
  },
  {
    "text": "so carpenter will look for empty nodes",
    "start": "982240",
    "end": "984560"
  },
  {
    "text": "excluding daemon sets and then you know",
    "start": "984560",
    "end": "986480"
  },
  {
    "text": "turn those nodes off after this time to",
    "start": "986480",
    "end": "989519"
  },
  {
    "text": "live has expired",
    "start": "989519",
    "end": "991519"
  },
  {
    "text": "the next one is the ttl seconds until",
    "start": "991519",
    "end": "993519"
  },
  {
    "text": "expired and so this fulfills a",
    "start": "993519",
    "end": "995600"
  },
  {
    "text": "requirement if you need to roll your",
    "start": "995600",
    "end": "996880"
  },
  {
    "text": "nodes",
    "start": "996880",
    "end": "997839"
  },
  {
    "text": "over a specific you know time period you",
    "start": "997839",
    "end": "999360"
  },
  {
    "text": "don't want them to live longer than 30",
    "start": "999360",
    "end": "1001279"
  },
  {
    "text": "days or a week or something",
    "start": "1001279",
    "end": "1002959"
  },
  {
    "text": "carpenter will",
    "start": "1002959",
    "end": "1004560"
  },
  {
    "text": "basically fulfill this",
    "start": "1004560",
    "end": "1006240"
  },
  {
    "text": "expiration period for you and roll your",
    "start": "1006240",
    "end": "1008320"
  },
  {
    "text": "nodes over",
    "start": "1008320",
    "end": "1010639"
  },
  {
    "text": "and whenever carpenter rolls a node over",
    "start": "1010639",
    "end": "1013199"
  },
  {
    "text": "or turns it off due to it being empty",
    "start": "1013199",
    "end": "1016480"
  },
  {
    "text": "it'll gracefully drain these pods",
    "start": "1016480",
    "end": "1018800"
  },
  {
    "text": "from the nodes it'll use the eviction",
    "start": "1018800",
    "end": "1020160"
  },
  {
    "text": "apis it'll respect your your pod",
    "start": "1020160",
    "end": "1022000"
  },
  {
    "text": "disruption budgets",
    "start": "1022000",
    "end": "1023920"
  },
  {
    "text": "and we even go a little bit further",
    "start": "1023920",
    "end": "1025280"
  },
  {
    "text": "where we install a node finalizer",
    "start": "1025280",
    "end": "1027678"
  },
  {
    "text": "on all the node resources in your",
    "start": "1027679",
    "end": "1029199"
  },
  {
    "text": "kubernetes cluster so you can actually",
    "start": "1029199",
    "end": "1031038"
  },
  {
    "text": "cube cut or delete a node that's",
    "start": "1031039",
    "end": "1032798"
  },
  {
    "text": "provisioned by carpenter and carpenter",
    "start": "1032799",
    "end": "1035120"
  },
  {
    "text": "will call the eviction api to drain the",
    "start": "1035120",
    "end": "1037120"
  },
  {
    "text": "pods respecting your pod disruption",
    "start": "1037120",
    "end": "1038798"
  },
  {
    "text": "budgets and then we'll terminate the",
    "start": "1038799",
    "end": "1040640"
  },
  {
    "text": "backing ec2 capacity behind it",
    "start": "1040640",
    "end": "1044959"
  },
  {
    "text": "so carpenter today doesn't support",
    "start": "1046400",
    "end": "1048558"
  },
  {
    "text": "natively spot",
    "start": "1048559",
    "end": "1050480"
  },
  {
    "text": "like being able to watch for",
    "start": "1050480",
    "end": "1051679"
  },
  {
    "text": "interruptions but you can always install",
    "start": "1051679",
    "end": "1053039"
  },
  {
    "text": "the aws node termination handler in your",
    "start": "1053039",
    "end": "1054640"
  },
  {
    "text": "cluster which is pretty easy to install",
    "start": "1054640",
    "end": "1057200"
  },
  {
    "text": "and it will pass that signal back uh so",
    "start": "1057200",
    "end": "1059840"
  },
  {
    "text": "that carpenter can kind of handle your",
    "start": "1059840",
    "end": "1061840"
  },
  {
    "text": "your node evictions for",
    "start": "1061840",
    "end": "1064840"
  },
  {
    "text": "you and so this is a similar um",
    "start": "1064840",
    "end": "1068480"
  },
  {
    "text": "kind of walkthrough of like what nick",
    "start": "1068480",
    "end": "1070000"
  },
  {
    "text": "did but with a rebalance recommendation",
    "start": "1070000",
    "end": "1071840"
  },
  {
    "text": "so this would be used if you need more",
    "start": "1071840",
    "end": "1073360"
  },
  {
    "text": "time than that two minutes window that",
    "start": "1073360",
    "end": "1075200"
  },
  {
    "text": "an interruption would give you",
    "start": "1075200",
    "end": "1076880"
  },
  {
    "text": "so no termination handler is installed",
    "start": "1076880",
    "end": "1078320"
  },
  {
    "text": "in this cluster it watches for rebalance",
    "start": "1078320",
    "end": "1079919"
  },
  {
    "text": "recommendations",
    "start": "1079919",
    "end": "1081600"
  },
  {
    "text": "and then it sees one and",
    "start": "1081600",
    "end": "1084240"
  },
  {
    "text": "decides to drain the node due to this",
    "start": "1084240",
    "end": "1087600"
  },
  {
    "text": "this rebalance another way you can",
    "start": "1087600",
    "end": "1089440"
  },
  {
    "text": "handle a rebalance recommendation is to",
    "start": "1089440",
    "end": "1090960"
  },
  {
    "text": "simply cordon the node and that's an",
    "start": "1090960",
    "end": "1092480"
  },
  {
    "text": "option in node termination handler if",
    "start": "1092480",
    "end": "1094000"
  },
  {
    "text": "you just don't want further pods to",
    "start": "1094000",
    "end": "1095600"
  },
  {
    "text": "schedule onto it",
    "start": "1095600",
    "end": "1097360"
  },
  {
    "text": "and so then the eviction process happens",
    "start": "1097360",
    "end": "1098960"
  },
  {
    "text": "where the cube sends it a sick term",
    "start": "1098960",
    "end": "1100799"
  },
  {
    "text": "hopefully the pod shuts down in a",
    "start": "1100799",
    "end": "1102320"
  },
  {
    "text": "reasonable amount of time you know",
    "start": "1102320",
    "end": "1104000"
  },
  {
    "text": "within your termination grace period and",
    "start": "1104000",
    "end": "1106000"
  },
  {
    "text": "then it just shuts down and everything's",
    "start": "1106000",
    "end": "1108559"
  },
  {
    "text": "good",
    "start": "1108559",
    "end": "1110799"
  },
  {
    "text": "so what do we talk about today so we",
    "start": "1110880",
    "end": "1112720"
  },
  {
    "text": "talked a little bit about spot and how",
    "start": "1112720",
    "end": "1114080"
  },
  {
    "text": "spot can drastically reduce costs of",
    "start": "1114080",
    "end": "1115919"
  },
  {
    "text": "your cluster you know discounts up to 90",
    "start": "1115919",
    "end": "1118320"
  },
  {
    "text": "on your nodes where it's the same",
    "start": "1118320",
    "end": "1120000"
  },
  {
    "text": "backing capacity the only caveat is you",
    "start": "1120000",
    "end": "1122080"
  },
  {
    "text": "have to handle that interruption notice",
    "start": "1122080",
    "end": "1124240"
  },
  {
    "text": "but handling the interruption notice",
    "start": "1124240",
    "end": "1125600"
  },
  {
    "text": "isn't that different from an on-demand",
    "start": "1125600",
    "end": "1128000"
  },
  {
    "text": "right because you still have to handle",
    "start": "1128000",
    "end": "1129919"
  },
  {
    "text": "pods shutting down for on demand",
    "start": "1129919",
    "end": "1131840"
  },
  {
    "text": "hardware failures and on demand so you",
    "start": "1131840",
    "end": "1133679"
  },
  {
    "text": "kind of have to be able to shut down",
    "start": "1133679",
    "end": "1135120"
  },
  {
    "text": "fast anyways in a lot of applications",
    "start": "1135120",
    "end": "1137679"
  },
  {
    "text": "so why not why not try out spot we",
    "start": "1137679",
    "end": "1139919"
  },
  {
    "text": "looked at spot best practices mainly on",
    "start": "1139919",
    "end": "1141679"
  },
  {
    "text": "the provisioning side",
    "start": "1141679",
    "end": "1143280"
  },
  {
    "text": "on",
    "start": "1143280",
    "end": "1144400"
  },
  {
    "text": "being super flexible",
    "start": "1144400",
    "end": "1146000"
  },
  {
    "text": "to different instance types which will",
    "start": "1146000",
    "end": "1147440"
  },
  {
    "text": "allow your spot instances to run for",
    "start": "1147440",
    "end": "1149280"
  },
  {
    "text": "longer periods of time",
    "start": "1149280",
    "end": "1151039"
  },
  {
    "text": "and also hopefully get better discounts",
    "start": "1151039",
    "end": "1153039"
  },
  {
    "text": "if you're being super flexible",
    "start": "1153039",
    "end": "1156000"
  },
  {
    "text": "then we talked about how kubernetes and",
    "start": "1156000",
    "end": "1157280"
  },
  {
    "text": "spot",
    "start": "1157280",
    "end": "1158400"
  },
  {
    "text": "are really",
    "start": "1158400",
    "end": "1159520"
  },
  {
    "text": "you know a match made in heaven really",
    "start": "1159520",
    "end": "1161679"
  },
  {
    "text": "the kubernetes node lifecycle",
    "start": "1161679",
    "end": "1163679"
  },
  {
    "text": "abstractions",
    "start": "1163679",
    "end": "1164880"
  },
  {
    "text": "make it super easy to handle these spot",
    "start": "1164880",
    "end": "1166559"
  },
  {
    "text": "interruptions and components like the",
    "start": "1166559",
    "end": "1167919"
  },
  {
    "text": "node termination handler",
    "start": "1167919",
    "end": "1169440"
  },
  {
    "text": "standardize everything for you",
    "start": "1169440",
    "end": "1171679"
  },
  {
    "text": "then we talked a little bit about how",
    "start": "1171679",
    "end": "1172880"
  },
  {
    "text": "scaling up your pods",
    "start": "1172880",
    "end": "1174720"
  },
  {
    "text": "requires you scaling up nodes and how",
    "start": "1174720",
    "end": "1176559"
  },
  {
    "text": "you can be flexible with cluster",
    "start": "1176559",
    "end": "1177679"
  },
  {
    "text": "autoscaler or you can try out carpenter",
    "start": "1177679",
    "end": "1180160"
  },
  {
    "text": "and use our our crd approach with a",
    "start": "1180160",
    "end": "1182240"
  },
  {
    "text": "provisionary spec to do groupless node",
    "start": "1182240",
    "end": "1184559"
  },
  {
    "text": "autoscaling",
    "start": "1184559",
    "end": "1186320"
  },
  {
    "text": "and we did have a demo but we had severe",
    "start": "1186320",
    "end": "1188880"
  },
  {
    "text": "technical difficulty before so i'm not",
    "start": "1188880",
    "end": "1190640"
  },
  {
    "text": "sure",
    "start": "1190640",
    "end": "1191760"
  },
  {
    "text": "is it gone okay yeah i think my laptop",
    "start": "1191760",
    "end": "1194000"
  },
  {
    "text": "died like right when i walked up here",
    "start": "1194000",
    "end": "1195919"
  },
  {
    "text": "and wouldn't charge anywhere so no demo",
    "start": "1195919",
    "end": "1198320"
  },
  {
    "text": "um",
    "start": "1198320",
    "end": "1199200"
  },
  {
    "text": "but if you catch me around and i get my",
    "start": "1199200",
    "end": "1201039"
  },
  {
    "text": "laptop uh working again we can",
    "start": "1201039",
    "end": "1202799"
  },
  {
    "text": "definitely show you a demo of of",
    "start": "1202799",
    "end": "1204799"
  },
  {
    "text": "carpenter in action",
    "start": "1204799",
    "end": "1206880"
  },
  {
    "text": "so yeah that's all we have so are there",
    "start": "1206880",
    "end": "1208960"
  },
  {
    "text": "any questions i think we have like four",
    "start": "1208960",
    "end": "1210640"
  },
  {
    "text": "minutes left maybe",
    "start": "1210640",
    "end": "1213920"
  },
  {
    "text": "[Applause]",
    "start": "1213920",
    "end": "1224670"
  },
  {
    "text": "sure i",
    "start": "1226240",
    "end": "1227440"
  },
  {
    "text": "i think we have mics up here if you",
    "start": "1227440",
    "end": "1228720"
  },
  {
    "text": "wanna",
    "start": "1228720",
    "end": "1230880"
  },
  {
    "text": "justin garrison emcee",
    "start": "1233600",
    "end": "1237120"
  },
  {
    "text": "so you will would you recommend only if",
    "start": "1239360",
    "end": "1242559"
  },
  {
    "text": "i use carpenter",
    "start": "1242559",
    "end": "1244400"
  },
  {
    "text": "um",
    "start": "1244400",
    "end": "1245360"
  },
  {
    "text": "to scale my notes would you recommend to",
    "start": "1245360",
    "end": "1247360"
  },
  {
    "text": "only use",
    "start": "1247360",
    "end": "1248400"
  },
  {
    "text": "spot instances in production",
    "start": "1248400",
    "end": "1250799"
  },
  {
    "text": "but i mean it really depends so there",
    "start": "1250799",
    "end": "1253120"
  },
  {
    "text": "are certainly applications that can't",
    "start": "1253120",
    "end": "1254480"
  },
  {
    "text": "tolerate interruptions like you just",
    "start": "1254480",
    "end": "1256080"
  },
  {
    "text": "can't do it so in those cases",
    "start": "1256080",
    "end": "1259120"
  },
  {
    "text": "if you can handle some interruption but",
    "start": "1259120",
    "end": "1261039"
  },
  {
    "text": "you need to guarantee some amount of",
    "start": "1261039",
    "end": "1262480"
  },
  {
    "text": "capacity then you can do a topology",
    "start": "1262480",
    "end": "1264640"
  },
  {
    "text": "spread across on demand and spot nodes",
    "start": "1264640",
    "end": "1267440"
  },
  {
    "text": "so you get like a 50 50 spread",
    "start": "1267440",
    "end": "1269760"
  },
  {
    "text": "and hopefully one day we'll be able to",
    "start": "1269760",
    "end": "1270960"
  },
  {
    "text": "do weight based topology spreads where",
    "start": "1270960",
    "end": "1272640"
  },
  {
    "text": "you could do",
    "start": "1272640",
    "end": "1273760"
  },
  {
    "text": "like a 10 on demand and ninety percent",
    "start": "1273760",
    "end": "1276320"
  },
  {
    "text": "spot spread but there's definitely",
    "start": "1276320",
    "end": "1278159"
  },
  {
    "text": "workloads that require spot and",
    "start": "1278159",
    "end": "1279679"
  },
  {
    "text": "carpenter will fulfill that use case as",
    "start": "1279679",
    "end": "1281520"
  },
  {
    "text": "well but uh but it's really easy to use",
    "start": "1281520",
    "end": "1284000"
  },
  {
    "text": "spot with with carpenter",
    "start": "1284000",
    "end": "1286720"
  },
  {
    "text": "okay and",
    "start": "1286720",
    "end": "1288000"
  },
  {
    "text": "also is it possible for copper carpenter",
    "start": "1288000",
    "end": "1290880"
  },
  {
    "text": "to get rebalance recommendations to use",
    "start": "1290880",
    "end": "1293280"
  },
  {
    "text": "to yeah so as long as you install the",
    "start": "1293280",
    "end": "1295600"
  },
  {
    "text": "node termination handler in your",
    "start": "1295600",
    "end": "1296880"
  },
  {
    "text": "kubernetes cluster a carpenter knows how",
    "start": "1296880",
    "end": "1299200"
  },
  {
    "text": "to drain the empty nodes or knows how to",
    "start": "1299200",
    "end": "1301200"
  },
  {
    "text": "shut down the empty nodes and so no",
    "start": "1301200",
    "end": "1302799"
  },
  {
    "text": "termination handler will actually do the",
    "start": "1302799",
    "end": "1304799"
  },
  {
    "text": "graceful draining part of the process",
    "start": "1304799",
    "end": "1306640"
  },
  {
    "text": "when it sees an interruption or a",
    "start": "1306640",
    "end": "1308080"
  },
  {
    "text": "rebalance and then carpenter will shut",
    "start": "1308080",
    "end": "1310159"
  },
  {
    "text": "down the node for you",
    "start": "1310159",
    "end": "1313039"
  },
  {
    "text": "hello you said that carpenter can",
    "start": "1314960",
    "end": "1317679"
  },
  {
    "text": "shut down the nodes that seems empty",
    "start": "1317679",
    "end": "1320559"
  },
  {
    "text": "excluding demon sets what about",
    "start": "1320559",
    "end": "1323280"
  },
  {
    "text": "moving pods that can be scheduled on",
    "start": "1323280",
    "end": "1326159"
  },
  {
    "text": "remaining capacity",
    "start": "1326159",
    "end": "1327840"
  },
  {
    "text": "to",
    "start": "1327840",
    "end": "1328640"
  },
  {
    "text": "defragment the cluster yeah exactly so",
    "start": "1328640",
    "end": "1331200"
  },
  {
    "text": "yeah defragment is definitely on like",
    "start": "1331200",
    "end": "1332880"
  },
  {
    "text": "the the top of our priority list right",
    "start": "1332880",
    "end": "1334559"
  },
  {
    "text": "now we've done a lot of work on it so",
    "start": "1334559",
    "end": "1335919"
  },
  {
    "text": "far it's not released yet but um",
    "start": "1335919",
    "end": "1338480"
  },
  {
    "text": "we're thinking about that problem a lot",
    "start": "1338480",
    "end": "1341039"
  },
  {
    "text": "there's a work around today where you",
    "start": "1341039",
    "end": "1342640"
  },
  {
    "text": "can actually use",
    "start": "1342640",
    "end": "1344080"
  },
  {
    "text": "the expiration feature where you can set",
    "start": "1344080",
    "end": "1346320"
  },
  {
    "text": "an expiration and if you have a good pod",
    "start": "1346320",
    "end": "1348320"
  },
  {
    "text": "disruptions",
    "start": "1348320",
    "end": "1349520"
  },
  {
    "text": "set up you can you know shut down",
    "start": "1349520",
    "end": "1351280"
  },
  {
    "text": "instances that have expired and then the",
    "start": "1351280",
    "end": "1353200"
  },
  {
    "text": "pods will go back into pinning and",
    "start": "1353200",
    "end": "1354480"
  },
  {
    "text": "they'll be packed more efficiently on",
    "start": "1354480",
    "end": "1356559"
  },
  {
    "text": "that round so that's kind of our",
    "start": "1356559",
    "end": "1357760"
  },
  {
    "text": "workaround currently",
    "start": "1357760",
    "end": "1359600"
  },
  {
    "text": "but hopefully defrag will be out soon",
    "start": "1359600",
    "end": "1362080"
  },
  {
    "text": "hi",
    "start": "1362080",
    "end": "1363120"
  },
  {
    "text": "do you see",
    "start": "1363120",
    "end": "1364480"
  },
  {
    "text": "spot and carpenter actually",
    "start": "1364480",
    "end": "1367760"
  },
  {
    "text": "helping with carbon footprint for",
    "start": "1367760",
    "end": "1369760"
  },
  {
    "text": "companies",
    "start": "1369760",
    "end": "1370880"
  },
  {
    "text": "part of the green",
    "start": "1370880",
    "end": "1372640"
  },
  {
    "text": "you know revolution so to speak right i",
    "start": "1372640",
    "end": "1375120"
  },
  {
    "text": "i don't have any data on it but i i",
    "start": "1375120",
    "end": "1377280"
  },
  {
    "text": "definitely see carpenter as uh more",
    "start": "1377280",
    "end": "1380000"
  },
  {
    "text": "efficiently utilizing nodes and capacity",
    "start": "1380000",
    "end": "1383600"
  },
  {
    "text": "and i you know hopefully moving forward",
    "start": "1383600",
    "end": "1385600"
  },
  {
    "text": "capacity will be",
    "start": "1385600",
    "end": "1387360"
  },
  {
    "text": "more utilized and therefore more",
    "start": "1387360",
    "end": "1389120"
  },
  {
    "text": "efficient and you know therefore more",
    "start": "1389120",
    "end": "1390640"
  },
  {
    "text": "carbon efficient as well",
    "start": "1390640",
    "end": "1393600"
  },
  {
    "text": "hi have you",
    "start": "1396799",
    "end": "1398159"
  },
  {
    "text": "noticed any changes in the spot markets",
    "start": "1398159",
    "end": "1401520"
  },
  {
    "text": "over the last like two years i would",
    "start": "1401520",
    "end": "1404159"
  },
  {
    "text": "imagine companies are using ec2 a lot",
    "start": "1404159",
    "end": "1407120"
  },
  {
    "text": "differently",
    "start": "1407120",
    "end": "1408400"
  },
  {
    "text": "after pandemic than before",
    "start": "1408400",
    "end": "1410720"
  },
  {
    "text": "yeah i i have not i don't have access to",
    "start": "1410720",
    "end": "1413440"
  },
  {
    "text": "that data so i wouldn't know to be",
    "start": "1413440",
    "end": "1416240"
  },
  {
    "text": "honest",
    "start": "1416240",
    "end": "1417520"
  },
  {
    "text": "but yeah hopefully more people are using",
    "start": "1417520",
    "end": "1420080"
  },
  {
    "text": "spot",
    "start": "1420080",
    "end": "1421520"
  },
  {
    "text": "i don't i don't know if the pandemic had",
    "start": "1421520",
    "end": "1423039"
  },
  {
    "text": "anything to do with it or just you know",
    "start": "1423039",
    "end": "1425520"
  },
  {
    "text": "it's a it's a good deal right",
    "start": "1425520",
    "end": "1427760"
  },
  {
    "text": "people like discounts",
    "start": "1427760",
    "end": "1431200"
  },
  {
    "text": "yep",
    "start": "1431200",
    "end": "1433039"
  },
  {
    "text": "hi and this is a great slide to ask the",
    "start": "1433039",
    "end": "1435039"
  },
  {
    "text": "question for because i see that you have",
    "start": "1435039",
    "end": "1438000"
  },
  {
    "text": "r5",
    "start": "1438000",
    "end": "1439200"
  },
  {
    "text": "instance specified here",
    "start": "1439200",
    "end": "1441120"
  },
  {
    "text": "does carpenter support the attribute",
    "start": "1441120",
    "end": "1443120"
  },
  {
    "text": "based notes",
    "start": "1443120",
    "end": "1445039"
  },
  {
    "text": "selection",
    "start": "1445039",
    "end": "1446080"
  },
  {
    "text": "so",
    "start": "1446080",
    "end": "1446880"
  },
  {
    "text": "that's an interesting question so",
    "start": "1446880",
    "end": "1448880"
  },
  {
    "text": "we're working on a",
    "start": "1448880",
    "end": "1451440"
  },
  {
    "text": "addition to this provisioner spec where",
    "start": "1451440",
    "end": "1453200"
  },
  {
    "text": "you could specify attributes to",
    "start": "1453200",
    "end": "1455600"
  },
  {
    "text": "constrain the list of instance types but",
    "start": "1455600",
    "end": "1457760"
  },
  {
    "text": "by default carpenter uses all instance",
    "start": "1457760",
    "end": "1459600"
  },
  {
    "text": "types and it'll look at the pods to kind",
    "start": "1459600",
    "end": "1461679"
  },
  {
    "text": "of figure out what constraints would",
    "start": "1461679",
    "end": "1463520"
  },
  {
    "text": "prevent it from launching certain",
    "start": "1463520",
    "end": "1464720"
  },
  {
    "text": "instance types",
    "start": "1464720",
    "end": "1466320"
  },
  {
    "text": "but yeah we're working on the attribute",
    "start": "1466320",
    "end": "1468400"
  },
  {
    "text": "based like filtering down in the",
    "start": "1468400",
    "end": "1470240"
  },
  {
    "text": "provision respect thank you hopefully",
    "start": "1470240",
    "end": "1472400"
  },
  {
    "text": "that'll be out soon too",
    "start": "1472400",
    "end": "1475279"
  },
  {
    "text": "hi i i also have a question about",
    "start": "1478960",
    "end": "1480640"
  },
  {
    "text": "carpenter i mean the spot instances is",
    "start": "1480640",
    "end": "1482559"
  },
  {
    "text": "really interesting i think pretty well",
    "start": "1482559",
    "end": "1484559"
  },
  {
    "text": "understood carpenter's interesting for a",
    "start": "1484559",
    "end": "1486640"
  },
  {
    "text": "lot of reasons you've talked about the",
    "start": "1486640",
    "end": "1487840"
  },
  {
    "text": "bin packing",
    "start": "1487840",
    "end": "1489120"
  },
  {
    "text": "on at least the metrics of cpu and",
    "start": "1489120",
    "end": "1491279"
  },
  {
    "text": "memory uh have you also considered the",
    "start": "1491279",
    "end": "1494320"
  },
  {
    "text": "constraint of volume attachments yes",
    "start": "1494320",
    "end": "1497200"
  },
  {
    "text": "yeah we definitely have uh so",
    "start": "1497200",
    "end": "1499360"
  },
  {
    "text": "we support",
    "start": "1499360",
    "end": "1500480"
  },
  {
    "text": "some uh like uh empty directory packing",
    "start": "1500480",
    "end": "1503679"
  },
  {
    "text": "today we're looking at supporting more",
    "start": "1503679",
    "end": "1505679"
  },
  {
    "text": "dynamic like ephemeral storage",
    "start": "1505679",
    "end": "1507440"
  },
  {
    "text": "attachment uh like scheduling and bin",
    "start": "1507440",
    "end": "1509360"
  },
  {
    "text": "backing awareness we are aware of like",
    "start": "1509360",
    "end": "1511200"
  },
  {
    "text": "persistent volumes so we'll schedule in",
    "start": "1511200",
    "end": "1513279"
  },
  {
    "text": "the correct zone if you're trying to",
    "start": "1513279",
    "end": "1514720"
  },
  {
    "text": "attach like an ebs volume to it but yeah",
    "start": "1514720",
    "end": "1517120"
  },
  {
    "text": "that's definitely something that we're",
    "start": "1517120",
    "end": "1518559"
  },
  {
    "text": "working on currently",
    "start": "1518559",
    "end": "1520080"
  },
  {
    "text": "just because of the volume attachment",
    "start": "1520080",
    "end": "1521600"
  },
  {
    "text": "limit right right exactly yeah",
    "start": "1521600",
    "end": "1526360"
  },
  {
    "text": "make justin run",
    "start": "1528559",
    "end": "1531440"
  },
  {
    "text": "hi um",
    "start": "1531440",
    "end": "1533600"
  },
  {
    "text": "you said carpenter doesn't work with uh",
    "start": "1533600",
    "end": "1537200"
  },
  {
    "text": "auto-scaling groups",
    "start": "1537200",
    "end": "1538799"
  },
  {
    "text": "yeah but how does it work with managed",
    "start": "1538799",
    "end": "1540720"
  },
  {
    "text": "nodes",
    "start": "1540720",
    "end": "1541760"
  },
  {
    "text": "yeah so today carpenter doesn't work",
    "start": "1541760",
    "end": "1543760"
  },
  {
    "text": "with manager now so they're separate",
    "start": "1543760",
    "end": "1545440"
  },
  {
    "text": "like solutions uh so with managed nodes",
    "start": "1545440",
    "end": "1548159"
  },
  {
    "text": "you'd use uh customer autoscaler today",
    "start": "1548159",
    "end": "1550320"
  },
  {
    "text": "for managed nodes because it is in an",
    "start": "1550320",
    "end": "1551919"
  },
  {
    "text": "auto scaling group and carpenter would",
    "start": "1551919",
    "end": "1553600"
  },
  {
    "text": "just be completely without without any",
    "start": "1553600",
    "end": "1555520"
  },
  {
    "text": "groups",
    "start": "1555520",
    "end": "1557440"
  },
  {
    "text": "okay thanks",
    "start": "1557440",
    "end": "1560240"
  },
  {
    "text": "i think that's time",
    "start": "1560400",
    "end": "1562000"
  },
  {
    "text": "so thank you very much thanks everyone",
    "start": "1562000",
    "end": "1563679"
  },
  {
    "text": "thanks",
    "start": "1563679",
    "end": "1566679"
  }
]
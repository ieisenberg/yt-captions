[
  {
    "start": "0",
    "end": "31000"
  },
  {
    "text": "okay hi everybody I'm vas left turret chick I work over at Asher at Microsoft",
    "start": "1910",
    "end": "9920"
  },
  {
    "text": "on a little thing called service fabric and I'm gonna talk today about how we're using envoy to solve some of the data",
    "start": "9920",
    "end": "16760"
  },
  {
    "text": "aware traffic routing that we have in this platform data where we heard that earlier excerpt a in a different talk so",
    "start": "16760",
    "end": "23510"
  },
  {
    "text": "kind of hoping that doesn't become a buzzword but I'll show you what that means and to do that I want to start by",
    "start": "23510",
    "end": "30199"
  },
  {
    "text": "just telling you what the service fabric thing is so this is a platform that we",
    "start": "30199",
    "end": "36350"
  },
  {
    "start": "31000",
    "end": "31000"
  },
  {
    "text": "have inside of Microsoft we call this thing a it's a data we're distributed systems platform and it was a little",
    "start": "36350",
    "end": "42350"
  },
  {
    "text": "vague so I'll tell you what it actually does it's it's a platform for managing and writing and orchestrating",
    "start": "42350",
    "end": "49039"
  },
  {
    "text": "applications that run containers and processes but with a focus on managing",
    "start": "49039",
    "end": "54649"
  },
  {
    "text": "the data associated with those applications and so this is just",
    "start": "54649",
    "end": "59839"
  },
  {
    "text": "software runs on a cluster of Linux and Windows hosts that we use pretty extensively in the company and the",
    "start": "59839",
    "end": "64878"
  },
  {
    "text": "reason it matters to us is because most of Asia as well as Microsoft runs on this platform today so all of the Azure",
    "start": "64879",
    "end": "70840"
  },
  {
    "text": "infrastructure as a software-defined infrastructure rather when you go to",
    "start": "70840",
    "end": "76070"
  },
  {
    "text": "Azure and you ask for a network or you ask for a VM it's applications running on this platform that answer that",
    "start": "76070",
    "end": "81500"
  },
  {
    "text": "request and provision those things a lot of other Microsoft services like office in tune dynamics all these things kind",
    "start": "81500",
    "end": "87229"
  },
  {
    "text": "of run on this platform so we use it very very extensively inside of the",
    "start": "87229",
    "end": "92479"
  },
  {
    "text": "company and of course like with a lot of things on Microsoft today that platform is open source so the interesting thing",
    "start": "92479",
    "end": "99170"
  },
  {
    "text": "about this platform it was designed with States in mind so it came out of the",
    "start": "99170",
    "end": "104479"
  },
  {
    "text": "sequel org about a decade ago when we were developing sequel on Azure and what",
    "start": "104479",
    "end": "110479"
  },
  {
    "text": "we found is that we have a lot of common a lot of common distributed data problems that we need to solve across",
    "start": "110479",
    "end": "115820"
  },
  {
    "text": "the company and across Asia and so we built this platform with a lot of these data primitives built in from",
    "start": "115820",
    "end": "121880"
  },
  {
    "text": "distributed applications so there's of course clustering in Federation this is just a layer that stitches a bunch of",
    "start": "121880",
    "end": "127999"
  },
  {
    "text": "machines or VMs together and took cohesive cluster but the interesting things are for example leader election",
    "start": "127999",
    "end": "133190"
  },
  {
    "text": "consensus algorithms configuration of placement all that stuff is built and as primitives into",
    "start": "133190",
    "end": "139690"
  },
  {
    "text": "this platform as well as replication of data quorum consistency and different",
    "start": "139690",
    "end": "144940"
  },
  {
    "text": "modes of consistency balancing keeping state balanced across different machines and then finally partitioning which is",
    "start": "144940",
    "end": "152140"
  },
  {
    "text": "just a fancy word for data sharding so these are all primitives built into the platform that we use to build out other",
    "start": "152140",
    "end": "158770"
  },
  {
    "text": "data aware platforms or data bases so anytime we have a distributed database or any kind of a data ingress service",
    "start": "158770",
    "end": "166000"
  },
  {
    "text": "like the you know the eventing systems are taken events from IOT devices that kind of stuff that all runs on this",
    "start": "166000",
    "end": "172420"
  },
  {
    "text": "platform makes use of these primitives so let me show you what this actually",
    "start": "172420",
    "end": "177580"
  },
  {
    "start": "176000",
    "end": "176000"
  },
  {
    "text": "looks like when the platform starts up this kind of a self bootstrapping platform it starts up you take a set of",
    "start": "177580",
    "end": "184510"
  },
  {
    "text": "nodes which are just VMs or machines and that forms a cluster services that are",
    "start": "184510",
    "end": "189700"
  },
  {
    "text": "written for this platform that get deployed to it they take two forms the",
    "start": "189700",
    "end": "194890"
  },
  {
    "text": "kind of simple one which is something that we're probably used to in most places is what we call a stateless service and that just means that every",
    "start": "194890",
    "end": "201790"
  },
  {
    "text": "instance of your code is running the exact same way doing the exact same thing this could be anything like a node.js application an asp net",
    "start": "201790",
    "end": "208030"
  },
  {
    "text": "application it doesn't really matter this is kind of things like a web farm or something like that everything is identical so that one I'm not gonna",
    "start": "208030",
    "end": "215200"
  },
  {
    "text": "focus too much on today because that's that's sort of been covered in a lot of the other talks how this kind of thing works this is this is what I want to",
    "start": "215200",
    "end": "221620"
  },
  {
    "text": "talk about today this is the the staple version of that so when you run your code here every instance that runs on a",
    "start": "221620",
    "end": "227290"
  },
  {
    "text": "separate node isn't actually created equal because it's holding the data in inside so in this case you'll have",
    "start": "227290",
    "end": "234160"
  },
  {
    "text": "multiple replicas but only one of those for example will be a primary replica that can take write operations whereas",
    "start": "234160",
    "end": "239860"
  },
  {
    "text": "the other than secondary replicas which are just getting States replicated to them and those don't accept write",
    "start": "239860",
    "end": "246220"
  },
  {
    "text": "applications or write requests rather so when you take those together that forms",
    "start": "246220",
    "end": "251709"
  },
  {
    "text": "a partition and so that partition is kind of a collection of replicas or a collection of endpoints and then you can",
    "start": "251709",
    "end": "257560"
  },
  {
    "text": "deploy multiple these partitions and the partitions you can think of that as a database shard so each one will have a",
    "start": "257560",
    "end": "262960"
  },
  {
    "text": "subset of the total amount of data when you can't fit data on a single machine kind of idiot and so you take that whole",
    "start": "262960",
    "end": "268650"
  },
  {
    "text": "thing put it all together that's what makes a stateful service so you can kind of see the little bit of a difference how that runs versus just a stateless",
    "start": "268650",
    "end": "275310"
  },
  {
    "text": "one and then what you have inside each one of those replicas is the application",
    "start": "275310",
    "end": "280650"
  },
  {
    "text": "code or the service code I'll probably use words application service interchangeably here that's running next",
    "start": "280650",
    "end": "286530"
  },
  {
    "text": "to the data that its operating on so that state is kept in memory optionally written to disk",
    "start": "286530",
    "end": "291960"
  },
  {
    "text": "all that is and replicated out to multiple machines and that provides high availability so another way to think",
    "start": "291960",
    "end": "298410"
  },
  {
    "text": "about this is if you were running a net CD cluster or a Redis cluster or",
    "start": "298410",
    "end": "303660"
  },
  {
    "text": "something imagine if your code was running inside of that cluster rather than making a remote calls to it you're running inside",
    "start": "303660",
    "end": "309720"
  },
  {
    "text": "and next to the data that it's storing so that's that's kind of the idea each one of those systems obviously has to",
    "start": "309720",
    "end": "314790"
  },
  {
    "text": "provide a way to route data to the appropriate place where the data is located depending on the request so",
    "start": "314790",
    "end": "320670"
  },
  {
    "text": "usually a client library will do something like that a thick client library something that understands how to find those endpoints and of course we",
    "start": "320670",
    "end": "329310"
  },
  {
    "text": "have the same kind of thing in service fabric but what we're doing now is replacing a lot of that with Envoy and",
    "start": "329310",
    "end": "335310"
  },
  {
    "text": "using that as the main mechanism to route requests and socially exactly how that works so and this is what we say or",
    "start": "335310",
    "end": "342960"
  },
  {
    "start": "341000",
    "end": "341000"
  },
  {
    "text": "this is what I mean when I say has to be data aware so there are four main",
    "start": "342960",
    "end": "348420"
  },
  {
    "text": "they're four main parts that I want to talk about today the first is obviously service discovery and routing this is",
    "start": "348420",
    "end": "354930"
  },
  {
    "text": "probably the main piece how do you find where to write where to route data to",
    "start": "354930",
    "end": "360330"
  },
  {
    "text": "and then how do you actually do the routing and this actually this idea of being data where affects every part of",
    "start": "360330",
    "end": "368540"
  },
  {
    "text": "traffic writing so even load balancing how you distribute load across different replicas or even different partitions is",
    "start": "368540",
    "end": "375270"
  },
  {
    "text": "affected by this how health checking is done how health monitoring is done and even down to versions and upgrades has",
    "start": "375270",
    "end": "381720"
  },
  {
    "text": "to be handled a little bit differently when the data and the compute or co-located in the same process or in the",
    "start": "381720",
    "end": "388230"
  },
  {
    "text": "same container space so I'll start with a simple example just looking at these",
    "start": "388230",
    "end": "394170"
  },
  {
    "start": "391000",
    "end": "391000"
  },
  {
    "text": "as stateless services so imagine these are web endpoints or web applications",
    "start": "394170",
    "end": "399310"
  },
  {
    "text": "in envoy terminology these would each be a cluster each replica would be an end",
    "start": "399310",
    "end": "405520"
  },
  {
    "text": "point inside that cluster and so when you deploy something like this on service fabric it's really no different",
    "start": "405520",
    "end": "411850"
  },
  {
    "text": "than what you would have on any other platform there's the discovery the XDS discovery services for envoy downstream",
    "start": "411850",
    "end": "419710"
  },
  {
    "text": "talks through envoy in this case you can think of envoy as a knowed agent where there's one instance running per node",
    "start": "419710",
    "end": "425169"
  },
  {
    "text": "you can do the same thing as a sidecar model it doesn't really make a whole lot of difference just to just for",
    "start": "425169",
    "end": "430810"
  },
  {
    "text": "simplicity we'll display this as a node agent for now the the little orange box",
    "start": "430810",
    "end": "435850"
  },
  {
    "text": "then at the bottom there that's a system services this this is a specific thing to service fabric this is where service",
    "start": "435850",
    "end": "442510"
  },
  {
    "text": "discovery actually happens the system services themselves are just a set of stateful services that run on the",
    "start": "442510",
    "end": "449410"
  },
  {
    "text": "platform that manage the cluster and they manage the applications so they know those system services know what",
    "start": "449410",
    "end": "454510"
  },
  {
    "text": "nodes are in the cluster what applications are running where applications should be placed how replicas should be placed they detect",
    "start": "454510",
    "end": "460630"
  },
  {
    "text": "failure etc they also act as the service discovery mechanism so what you don't see here is zookeeper @cd or anything",
    "start": "460630",
    "end": "467560"
  },
  {
    "text": "else because the again the platform itself is meant to be a data platform so all of the stages kept on the platform",
    "start": "467560",
    "end": "473830"
  },
  {
    "text": "yourself there's no external databases here and in fact there can't be because we develop our databases on this so you",
    "start": "473830",
    "end": "480669"
  },
  {
    "text": "wouldn't have a sequel backed by a sequel for example so so this is what it looks like when it's stateless now if we",
    "start": "480669",
    "end": "485890"
  },
  {
    "text": "replace this with the idea of stateful services this is where it gets kind of",
    "start": "485890",
    "end": "493570"
  },
  {
    "text": "interesting because now when the downstream client or downstream service makes a request to envoy and says I want",
    "start": "493570",
    "end": "499120"
  },
  {
    "text": "to talk to application a well we know where that is but we don't know which partition to go to to get to the data",
    "start": "499120",
    "end": "506440"
  },
  {
    "text": "that you're requesting so for example if you want to send a request to user /foo",
    "start": "506440",
    "end": "511630"
  },
  {
    "text": "which partition is that user in and so there needs to be an extra piece of data",
    "start": "511630",
    "end": "516669"
  },
  {
    "text": "that's sent somewhere but that needs to be available somewhere to help envoy make these decisions on where to send",
    "start": "516669",
    "end": "521860"
  },
  {
    "text": "that request so typically the way this works there's this there's this",
    "start": "521860",
    "end": "527140"
  },
  {
    "text": "partition resolution pattern that we follow on the platform where you take",
    "start": "527140",
    "end": "532310"
  },
  {
    "text": "some data from the request if it's an HTTP request you take something from the path or from the header or a query string and you use that to transform it",
    "start": "532310",
    "end": "539810"
  },
  {
    "text": "into a partition key which is you can think of it as a hash table so you take some value you hash it that tells you",
    "start": "539810",
    "end": "546470"
  },
  {
    "text": "what bucket of the hash table it's in you send the traffic there once you determine that then you can look up the",
    "start": "546470",
    "end": "553100"
  },
  {
    "text": "location look at the endpoint where that data is so that's the service discovery part of it then you ask service carry I",
    "start": "553100",
    "end": "559940"
  },
  {
    "text": "have service am going to with partition key five tell me where the end point for that is and then it'll respond with that",
    "start": "559940",
    "end": "566120"
  },
  {
    "text": "and then finally you forward the request so again typically this was done in in these kind of heavy clients the clients",
    "start": "566120",
    "end": "572600"
  },
  {
    "text": "that would do all this work on the client side which has a number of challenges associated with it of course",
    "start": "572600",
    "end": "578020"
  },
  {
    "text": "which I think we heard in one of the previous talks - you have to write it in however many languages that you want to support it's difficult to keep it",
    "start": "578020",
    "end": "584240"
  },
  {
    "text": "updated the clients doing a lot of the work etc so what we did an envoy to make",
    "start": "584240",
    "end": "592550"
  },
  {
    "text": "this work so here's an example of a of a partitioning scheme that uses a range partition and that just means that the",
    "start": "592550",
    "end": "598310"
  },
  {
    "text": "key range very partition is just some some integer range so for that for example users as a zero through nine",
    "start": "598310",
    "end": "605420"
  },
  {
    "text": "will go to partition one and so on and so forth so what we did is we added this range",
    "start": "605420",
    "end": "612050"
  },
  {
    "text": "match header to - envoy this is this is one of our small contributions that we",
    "start": "612050",
    "end": "617570"
  },
  {
    "text": "did and this just allows you to match a header to a range of integers so rather",
    "start": "617570",
    "end": "622850"
  },
  {
    "text": "than say a header equals x or header matches some reg X you say if a header",
    "start": "622850",
    "end": "627860"
  },
  {
    "text": "falls within a numerical range that's a match go to that cluster and so this",
    "start": "627860",
    "end": "633680"
  },
  {
    "text": "allows the client then to send request like so I can say go to the application",
    "start": "633680",
    "end": "639709"
  },
  {
    "text": "with this domain name on this path and then here's the partition key and all",
    "start": "639709",
    "end": "644870"
  },
  {
    "text": "that doesn't envoy is it just matches this header range match and then gets routed appropriately and so we're of",
    "start": "644870",
    "end": "650720"
  },
  {
    "text": "course treating each partition here as an upstream cluster with a set of endpoints and so we're just trying to",
    "start": "650720",
    "end": "656240"
  },
  {
    "text": "figure out a way to send a request to the appropriate cluster so this works this allows us to route traffic from a",
    "start": "656240",
    "end": "663530"
  },
  {
    "text": "downstream to the appropriate upstream part ition based on a key value or a header",
    "start": "663530",
    "end": "668840"
  },
  {
    "text": "value but it has a number of problems though and mainly is the main problems that it kind of couples the downstream",
    "start": "668840",
    "end": "674930"
  },
  {
    "text": "upstream together pretty tightly so the downstream now has to know intimate",
    "start": "674930",
    "end": "680990"
  },
  {
    "text": "details about the upstream how it's implemented it has to know first of all it has to know that is a stateful partition two thing in service fabric",
    "start": "680990",
    "end": "687200"
  },
  {
    "text": "that's bad enough as it is but it has to know even more intimate details about it for example it has to know the upstream",
    "start": "687200",
    "end": "693110"
  },
  {
    "text": "partitioning scheme so the range match is just one way that you can do partitioning you can do named partitions that are an exact name match for example",
    "start": "693110",
    "end": "700010"
  },
  {
    "text": "the downstream would have to know this about the upstream the downstream has to know if it's using if it is using a",
    "start": "700010",
    "end": "706670"
  },
  {
    "text": "range match it has to know the range of keys that the upstream is chosen so the upstream can choose any range of keys",
    "start": "706670",
    "end": "712550"
  },
  {
    "text": "here it's 0 to 29 and it could be 1 to 10 it could be in might in 2 min in max",
    "start": "712550",
    "end": "718690"
  },
  {
    "text": "the downstream then has to know all this about the upstream and the worst yet",
    "start": "718690",
    "end": "724310"
  },
  {
    "text": "about this I think is that the downstream here now has control over the data distribution of the upstream so if",
    "start": "724310",
    "end": "732200"
  },
  {
    "text": "I'm sending requests to an upstream and I'm deciding what the hash key is that",
    "start": "732200",
    "end": "737690"
  },
  {
    "text": "means I'm also deciding how data is distributed in the upstream service so I could overload partition 1 pretty easily",
    "start": "737690",
    "end": "743270"
  },
  {
    "text": "by saying everyone just falls into partition 1 everyone's everyone's 0 and that kind of ruins the upstream so what",
    "start": "743270",
    "end": "749870"
  },
  {
    "text": "we really want to do is we want to take that responsibility out of the downstream transfer that over where the",
    "start": "749870",
    "end": "755360"
  },
  {
    "text": "upstream has control of it by putting that into the proxy in between and so",
    "start": "755360",
    "end": "761750"
  },
  {
    "text": "the way we the way we did this initially was with a custom HTTP filter where the",
    "start": "761750",
    "end": "767450"
  },
  {
    "text": "upstream service can now send some of that partition config information through the system services and into the",
    "start": "767450",
    "end": "774350"
  },
  {
    "text": "discovery services for Envoy to consume where that HTTP filter can then consume that information so it's not it's it's",
    "start": "774350",
    "end": "780800"
  },
  {
    "text": "basically kind of template parameters so the upstream will say something like my is my partitioning range is this my",
    "start": "780800",
    "end": "787070"
  },
  {
    "text": "partition scheme is that and then more importantly here's the value I want you to take from the HTTP request and here's",
    "start": "787070",
    "end": "794810"
  },
  {
    "text": "the hashing algorithm I to run against it and that hashing algorithms usually the same thing it's",
    "start": "794810",
    "end": "800399"
  },
  {
    "text": "usually FN V ash or something but the point is that as long as the up stream is the one that's defining the API it's",
    "start": "800399",
    "end": "807479"
  },
  {
    "text": "also the best place to say what part of the API should I grab a value that should be used as a hashing key into my",
    "start": "807479",
    "end": "815389"
  },
  {
    "text": "distributed hash table so we did this with a with a custom h-2b filter it's",
    "start": "815389",
    "end": "822059"
  },
  {
    "text": "kind of interesting because when you do that the routing decisions happen before that runs before the HB filter runs and",
    "start": "822059",
    "end": "829229"
  },
  {
    "text": "so the way we the way we did it is since we have this range match header already built in what we would do is we would",
    "start": "829229",
    "end": "835049"
  },
  {
    "text": "inject that range match header into the request so the HB filter would take the",
    "start": "835049",
    "end": "841709"
  },
  {
    "text": "request grab a value like the something from the path apply hash function and then inject an HTTP request header so",
    "start": "841709",
    "end": "848669"
  },
  {
    "text": "that the routing mechanism that's already in an envoy it would just take that match it's basically rewriting the",
    "start": "848669",
    "end": "854879"
  },
  {
    "text": "routing rules on-the-fly is kind of what it is you can do that you have to clear the routing cache first otherwise it",
    "start": "854879",
    "end": "860849"
  },
  {
    "text": "won't work but as long as you do that it'll reapply the rules and then route accordingly we found an even better way",
    "start": "860849",
    "end": "866369"
  },
  {
    "text": "to do this though is to just use the built-in Lua script filter that already exists that allows us to just index some",
    "start": "866369",
    "end": "872429"
  },
  {
    "text": "configuration that way xvs basically writes the Lua script as it needs to be when it gets to envoy envoy execute the",
    "start": "872429",
    "end": "879059"
  },
  {
    "text": "Lua script does the hash grabs value does the hash puts in the header and then it gets routed to the right place",
    "start": "879059",
    "end": "884869"
  },
  {
    "text": "so that's how we pick that's why we pick what cluster to go to what upstream cluster to go to the partition basically",
    "start": "884869",
    "end": "891739"
  },
  {
    "text": "the next part of this then is load balancing once we've once we decided on",
    "start": "891739",
    "end": "897479"
  },
  {
    "start": "894000",
    "end": "894000"
  },
  {
    "text": "the upstream cluster so load balancing in the stateful world is kind of a",
    "start": "897479",
    "end": "905459"
  },
  {
    "text": "question of consistency versus availability because again not every",
    "start": "905459",
    "end": "910799"
  },
  {
    "text": "endpoint is treated equal and so this is this little picture on the right I'll keep that up throughout this so that you",
    "start": "910799",
    "end": "917849"
  },
  {
    "text": "can kind of kind of see how this works so it's really only the primary replicas here that's accepting read or write",
    "start": "917849",
    "end": "923699"
  },
  {
    "text": "operations the secondary replicas are just there to keep copies of the data for high availability so",
    "start": "923699",
    "end": "929570"
  },
  {
    "text": "for a full consistent model you would only ever read and write to and from the",
    "start": "929570",
    "end": "934650"
  },
  {
    "text": "primary for higher availability you can",
    "start": "934650",
    "end": "940560"
  },
  {
    "text": "read from secondaries but at the cost of consistency because the secondary is although they have the same data it is a",
    "start": "940560",
    "end": "946500"
  },
  {
    "text": "quorum Act based system so when you when you make a right to a primary replica that that transaction commits when a",
    "start": "946500",
    "end": "954120"
  },
  {
    "text": "majority of secondaries have acknowledged that transaction but not necessarily all of them so in this case",
    "start": "954120",
    "end": "961080"
  },
  {
    "text": "where I have three replicas one of those will probably be stale some of the time in rare cases you can be even worse you",
    "start": "961080",
    "end": "968910"
  },
  {
    "text": "can get false progress so you're reading values from a future that hasn't happened yet or that will never happen",
    "start": "968910",
    "end": "973980"
  },
  {
    "text": "and then it gets rolled back so so in this kind of in this in this lower",
    "start": "973980",
    "end": "979290"
  },
  {
    "text": "consistency but higher availability model you can send reads to the secondaries so question is how do you do",
    "start": "979290",
    "end": "986130"
  },
  {
    "text": "this basically what you want is I have for example an HTTP API like API users",
    "start": "986130",
    "end": "992520"
  },
  {
    "text": "and I want to send all my rights to just that one primary endpoint in this",
    "start": "992520",
    "end": "997860"
  },
  {
    "text": "cluster so for example my puts post deletes are going to go there and then",
    "start": "997860",
    "end": "1002990"
  },
  {
    "text": "my gets on the same API can go to any one of these replicas so there is a",
    "start": "1002990",
    "end": "1008240"
  },
  {
    "text": "pretty cool way to do this in Envoy that doesn't really require us to do any additional you know additional work here",
    "start": "1008240",
    "end": "1014210"
  },
  {
    "text": "this is the load balance or subset so we also heard about earlier this is a very cool thing you can do so essentially",
    "start": "1014210",
    "end": "1020450"
  },
  {
    "text": "what we do is we set up these subset",
    "start": "1020450",
    "end": "1026150"
  },
  {
    "text": "selectors which are just a set of keys that you can then apply in your endpoints so I'm basically tagging each",
    "start": "1026150",
    "end": "1033079"
  },
  {
    "text": "endpoint with this value to say this endpoint is tagged as a primary these",
    "start": "1033079",
    "end": "1038180"
  },
  {
    "text": "other endpoints are tagged as the secondaries then when the when the",
    "start": "1038180",
    "end": "1043970"
  },
  {
    "text": "routes come in when when we set up the routes we can set up a regular route using you know just a prefix match or",
    "start": "1043970",
    "end": "1050210"
  },
  {
    "text": "something we can actually match on the HTTP verb by looking at the method",
    "start": "1050210",
    "end": "1056420"
  },
  {
    "text": "header which is kind of cool all you have to do is just match that header and say okay if it's a post match this route and then finally you just apply those",
    "start": "1056420",
    "end": "1063230"
  },
  {
    "text": "those selectors took this route so you say if you see a request to this",
    "start": "1063230",
    "end": "1068270"
  },
  {
    "text": "particular URL that's a post or a put or a delete and that means apply just that",
    "start": "1068270",
    "end": "1075760"
  },
  {
    "text": "just that selector there which will go to the one endpoint that has that selector so that will only ever go to",
    "start": "1075760",
    "end": "1081200"
  },
  {
    "text": "the primaries and so that's how you do this kind of load balancing now load balancing exactly but it's how you can",
    "start": "1081200",
    "end": "1087980"
  },
  {
    "text": "can kind of pick which particular end points you want to send the traffic to so on to health checking unfortunately",
    "start": "1087980",
    "end": "1097070"
  },
  {
    "start": "1093000",
    "end": "1093000"
  },
  {
    "text": "in a system like this where only one of those endpoints is a right endpoint when that thing goes bad there really isn't",
    "start": "1097070",
    "end": "1103640"
  },
  {
    "text": "much you can do at the proxy level so you just really have to rely on the platform to fail that thing over as fast",
    "start": "1103640",
    "end": "1109010"
  },
  {
    "text": "as you possibly can again it's we can be we can be as good as we possibly can about failing things",
    "start": "1109010",
    "end": "1114680"
  },
  {
    "text": "over detecting failure and failing a primary over to another note as fast as we possibly can but it's never gonna be",
    "start": "1114680",
    "end": "1120560"
  },
  {
    "text": "perfect application code can be slow to shut down it can be slow to start back",
    "start": "1120560",
    "end": "1125630"
  },
  {
    "text": "up so again that's what that availability versus consistency trade-off comes in at the very least in",
    "start": "1125630",
    "end": "1131540"
  },
  {
    "text": "this situation you can make use of secondary reads but there's nothing you",
    "start": "1131540",
    "end": "1136550"
  },
  {
    "text": "can really do about writes unfortunately you can't really go into a different partition because your data is not going",
    "start": "1136550",
    "end": "1141980"
  },
  {
    "text": "to be there so the only thing you can really do then is just let the system fail it over to a different node and",
    "start": "1141980",
    "end": "1147650"
  },
  {
    "text": "hope that it comes back up same deal with versioning and upgrades this is",
    "start": "1147650",
    "end": "1153230"
  },
  {
    "start": "1150000",
    "end": "1150000"
  },
  {
    "text": "also another difficult part where the proxy part of this in us in the in this",
    "start": "1153230",
    "end": "1158360"
  },
  {
    "text": "kind of stateful world is only limited and how much you can do and I'll show you why exactly this works so if you",
    "start": "1158360",
    "end": "1164060"
  },
  {
    "text": "wanted to do a side-by-side test of a service like I have v1 stood up I'm gonna stand up v2 and then I'm gonna",
    "start": "1164060",
    "end": "1169670"
  },
  {
    "text": "send you know 10% of my traffic to v2 to test it out unfortunately it doesn't work because all your data is still in",
    "start": "1169670",
    "end": "1175700"
  },
  {
    "text": "that v1 instance remember they're all co-located so the data is sitting next to next the next to the compute so you",
    "start": "1175700",
    "end": "1182060"
  },
  {
    "text": "can't really do it this way you can't really do the side-by-side gradually move traffic over so the only way this",
    "start": "1182060",
    "end": "1189170"
  },
  {
    "text": "really works is with in-place rolling upgrades and that's of course built into the platform here one of the places",
    "start": "1189170",
    "end": "1195170"
  },
  {
    "text": "where the proxy can Brown boy can help is since this is a very cooperative effort as you roll",
    "start": "1195170",
    "end": "1201260"
  },
  {
    "text": "through upgrade domains you're taking down one machine doing the upgrade taken out of the machine and so forth every time you do that you need to be able to",
    "start": "1201260",
    "end": "1207920"
  },
  {
    "text": "drain all those requests out and make sure all those transactions finish so that's the only thing we can do there for testing instead of instead of saying",
    "start": "1207920",
    "end": "1216710"
  },
  {
    "text": "I'm gonna move 10% of my traffic over and test it out shadowing is actually one technique that we can use here and",
    "start": "1216710",
    "end": "1222530"
  },
  {
    "text": "so basically what this means is that a hundred percent of the traffic is still going to be one I stood up beat you next",
    "start": "1222530",
    "end": "1227990"
  },
  {
    "text": "to it none of my data is there but I can copy five or ten percent of the traffic over so all my users are still sitting on v1 but I'm just shadowing some of the",
    "start": "1227990",
    "end": "1234680"
  },
  {
    "text": "traffic over that allows me to run some integration tests all in that version with real user traffic but without",
    "start": "1234680",
    "end": "1239960"
  },
  {
    "text": "actually disrupting the services that they're running on okay so those were",
    "start": "1239960",
    "end": "1245510"
  },
  {
    "text": "just a quick crash course on some of the issues that we have with data where traffic routing and how envoy helps to",
    "start": "1245510",
    "end": "1252860"
  },
  {
    "text": "solve at least some of these problems I wanted to spend just a little bit talking about the work we did porting",
    "start": "1252860",
    "end": "1258230"
  },
  {
    "start": "1255000",
    "end": "1255000"
  },
  {
    "text": "envoy over to Windows just in full disclosure earnest this wasn't me doing",
    "start": "1258230",
    "end": "1263390"
  },
  {
    "text": "the work week borrowed permanently a developer from the C++ compiler team the B C++ compiler",
    "start": "1263390",
    "end": "1270680"
  },
  {
    "text": "team so I'm mostly just telling you what but Connie the things that you went through and it turns out most of on was",
    "start": "1270680",
    "end": "1277940"
  },
  {
    "text": "actually he actually wasn't a whole lot of work at C++ so a lot of it was OS agnostic and portable over for the parts",
    "start": "1277940",
    "end": "1284900"
  },
  {
    "text": "that we did have to make changes it was about 30% of it API changes 70% behavioral changes so I want to show you",
    "start": "1284900",
    "end": "1291800"
  },
  {
    "text": "a few just a few of the things that stood out in our minds that were kind of interesting about doing the support work",
    "start": "1291800",
    "end": "1296830"
  },
  {
    "text": "via the build system was actually the biggest challenge none of us having ever used basil before",
    "start": "1296830",
    "end": "1303200"
  },
  {
    "text": "that was hard luckily there was a lot of help from the community which was we're very thankful",
    "start": "1303200",
    "end": "1309650"
  },
  {
    "text": "for that we didn't get very far on that one so so just a couple of just the Cole",
    "start": "1309650",
    "end": "1315920"
  },
  {
    "text": "things that were interesting error codes for example there are some error codes it just didn't exist on Windows so that we had to go and define those there were",
    "start": "1315920",
    "end": "1322070"
  },
  {
    "text": "a whole lot of error codes that we had to redefine to work with a Windows socket API that were different that",
    "start": "1322070",
    "end": "1329000"
  },
  {
    "text": "switch statement on for quite a while this one was really",
    "start": "1329000",
    "end": "1335059"
  },
  {
    "text": "fun so close on Linux you have this close method that exists in actually both places only some",
    "start": "1335059",
    "end": "1341659"
  },
  {
    "text": "windows it takes a file descriptor on Linux this close the sockets and anything else is scrap five by a file",
    "start": "1341659",
    "end": "1347360"
  },
  {
    "text": "which is pretty much everything on Windows we don't describe everything as a file so this doesn't actually close",
    "start": "1347360",
    "end": "1353840"
  },
  {
    "text": "sockets on Windows but it does still compile and still runs and it doesn't there are no errors so we ran this the",
    "start": "1353840",
    "end": "1360770"
  },
  {
    "text": "first time and we're like we have a lot of like just sockets hanging around this is really weird so there's actually a",
    "start": "1360770",
    "end": "1367039"
  },
  {
    "text": "different API and Windows to close sockets it's called a closed socket and it takes the socket um the other thing",
    "start": "1367039",
    "end": "1373460"
  },
  {
    "text": "was live event live event doesn't work too great on Windows the the problem is",
    "start": "1373460",
    "end": "1379159"
  },
  {
    "text": "there's no edge triggering doesn't know what it is if you're not familiar with edge triggering it's this idea where just real quick when when the socket",
    "start": "1379159",
    "end": "1386450"
  },
  {
    "text": "buffer is full for example you want to write to it you want to get notified when there's space in the buffer so when that value changes now there's buffer",
    "start": "1386450",
    "end": "1393770"
  },
  {
    "text": "space available hate go write something to the socket if you don't have anything to write say I don't have anything to",
    "start": "1393770",
    "end": "1399289"
  },
  {
    "text": "write and then and then live event leaves you alone on Windows it just keeps bugging you it's like no there's",
    "start": "1399289",
    "end": "1404419"
  },
  {
    "text": "there's there's a user space right some that there's space there space so that's called level triggering and so just keep doing that",
    "start": "1404419",
    "end": "1409700"
  },
  {
    "text": "so when it's actually when the when envoy is idle it's eating up a ton of",
    "start": "1409700",
    "end": "1414950"
  },
  {
    "text": "CPU so when we initially launched this ingress gateway component that uses",
    "start": "1414950",
    "end": "1422510"
  },
  {
    "text": "envoy into service fabric we ran I think two instance of it and immediately a CPU is just pegged up to hundred percent and",
    "start": "1422510",
    "end": "1428419"
  },
  {
    "text": "it was because of this issue so we we put in a workaround that kind of it",
    "start": "1428419",
    "end": "1434659"
  },
  {
    "text": "simulates what it's triggering does not perfectly the real long term solution of course is to use IO completion ports we",
    "start": "1434659",
    "end": "1440840"
  },
  {
    "text": "haven't done this work yet because this is a much much much bigger task to take on",
    "start": "1440840",
    "end": "1445909"
  },
  {
    "text": "so those are just some of the interesting things that we run into during that work to port this over to Windows ok and the last thing I wanted",
    "start": "1445909",
    "end": "1455059"
  },
  {
    "start": "1453000",
    "end": "1453000"
  },
  {
    "text": "to close that was why why we chose envoy a given that he doesn't really solve all our problems it does solve some",
    "start": "1455059",
    "end": "1461580"
  },
  {
    "text": "why did we go down this route why didn't we just go and write a proxy of our own we did it was hard proxies are hard",
    "start": "1461580",
    "end": "1468630"
  },
  {
    "text": "there they're hard to write we we wrote it on the HTTP sis kernel module which is what runs IAS",
    "start": "1468630",
    "end": "1474360"
  },
  {
    "text": "underneath performance-wise we got about on par but there was a lot missing there so we did",
    "start": "1474360",
    "end": "1481290"
  },
  {
    "text": "look at a lot of a lot of the proxies that are available out out in the open",
    "start": "1481290",
    "end": "1486540"
  },
  {
    "text": "source space and just out in the community own way was by far our favorite just a few reasons why one it's",
    "start": "1486540",
    "end": "1492420"
  },
  {
    "text": "c++ service fabric itself is about two million lines of C++ code so it's we",
    "start": "1492420",
    "end": "1497490"
  },
  {
    "text": "like C++ we're pretty familiar with it we didn't want have to go out and learn a go or anything else so this is nice",
    "start": "1497490",
    "end": "1503010"
  },
  {
    "text": "and also portability across across operating systems is helped quite a bit number two is fast it's very very fast",
    "start": "1503010",
    "end": "1508860"
  },
  {
    "text": "this is very important for us the extend ability is super super nice being a little write filters and plug-in custom",
    "start": "1508860",
    "end": "1515340"
  },
  {
    "text": "filters was a huge huge part of this and we obviously need a little bit of extend ability although we didn't have to",
    "start": "1515340",
    "end": "1521010"
  },
  {
    "text": "extend it as much as we thought we would because it's very feature-rich so there's already a lot in there that we can use so this is actually very good",
    "start": "1521010",
    "end": "1526790"
  },
  {
    "text": "and last but definitely not least the community is fantastic a lot a lot of",
    "start": "1526790",
    "end": "1532260"
  },
  {
    "text": "great people working on this and it was super fun to actually do even just a little bit of the contributions we did",
    "start": "1532260",
    "end": "1537510"
  },
  {
    "text": "was real good time so that's all I have on how we did a little bit of envoy work",
    "start": "1537510",
    "end": "1542550"
  },
  {
    "text": "in service fabric over on Azure time for questions good time questions",
    "start": "1542550",
    "end": "1549740"
  },
  {
    "text": "yeah so so the first part that question was a lot of the recent Windows porting",
    "start": "1587820",
    "end": "1593110"
  },
  {
    "text": "work that has been pushed back upstream has been done my pivotal they from what I understand we have to confirm them but",
    "start": "1593110",
    "end": "1598600"
  },
  {
    "text": "from I understand they picked up essentially where we left off so we forked envoy initially over an Arg we",
    "start": "1598600",
    "end": "1603970"
  },
  {
    "text": "did a lot of the kind of front work on getting things just to run Windows they picked it up from there and made the build system work mainly",
    "start": "1603970",
    "end": "1610720"
  },
  {
    "text": "and then I think they're doing some additional work and then pushing that back upstream so they kind of picked up where we where we stopped initially when",
    "start": "1610720",
    "end": "1616420"
  },
  {
    "text": "we got stuck on the build system yeah I don't think we're gonna fork and",
    "start": "1616420",
    "end": "1622390"
  },
  {
    "text": "continue to use our own we'll definitely want to have just one and hopefully we can get back to helping them out with",
    "start": "1622390",
    "end": "1627730"
  },
  {
    "text": "that as well pretty soon a second question was if we've looked at using libuv instead of live event we did",
    "start": "1627730",
    "end": "1633700"
  },
  {
    "text": "briefly that was another thing that we could do so we actually use Lemieux V pretty extensively on a different web",
    "start": "1633700",
    "end": "1639190"
  },
  {
    "text": "server that we ran a Microsoft called kestrel which is the web server that runs an asp net core so we do have quite",
    "start": "1639190",
    "end": "1645100"
  },
  {
    "text": "a bit of experience with libuv I think ultimately it's probably going to come",
    "start": "1645100",
    "end": "1650470"
  },
  {
    "text": "down to where we can do I Oh completion ports the easiest but we haven't looked",
    "start": "1650470",
    "end": "1655900"
  },
  {
    "text": "too extensively until the movie yet but that that's them that's an opportunity as well",
    "start": "1655900",
    "end": "1661740"
  },
  {
    "text": "how do you make sure that writers read their own rights yeah oh I see so the",
    "start": "1673120",
    "end": "1695000"
  },
  {
    "text": "question is how do we how do we get how do we do right read your own rights so if there are requests going into the",
    "start": "1695000",
    "end": "1700640"
  },
  {
    "text": "secondary someone up it's the primary how do we make sure they get the same value there's no guarantee there if",
    "start": "1700640",
    "end": "1706220"
  },
  {
    "text": "you're reading from secondaries so again it's it's you lose out on that that",
    "start": "1706220",
    "end": "1712760"
  },
  {
    "text": "level of consistency if you're reading from secondaries generally we discourage it for the most part just because I",
    "start": "1712760",
    "end": "1719420"
  },
  {
    "text": "think it comes with a lot of surprises like that so we usually say at least if you're talking if you're trying if your",
    "start": "1719420",
    "end": "1725690"
  },
  {
    "text": "goal is to scale things out like I'm overloading one machine and I need to read four more machines the way to do",
    "start": "1725690",
    "end": "1731420"
  },
  {
    "text": "that is that partitioning concept break your data up into smaller chunks where as reading from secondaries is only",
    "start": "1731420",
    "end": "1736880"
  },
  {
    "text": "about availability but we don't have guarantees like that yeah yes a question",
    "start": "1736880",
    "end": "1754600"
  },
  {
    "text": "catch yeah so the question is does the if the primary comes back up does that the same endpoint as it did before does",
    "start": "1754600",
    "end": "1759770"
  },
  {
    "text": "the XDS have to update it it depends so you can do it either way so you can it",
    "start": "1759770",
    "end": "1765050"
  },
  {
    "text": "depends on if you've assigned static IP addresses which isn't something that most of the time is done usually it's a",
    "start": "1765050",
    "end": "1772490"
  },
  {
    "text": "completely different point it comes up on a different node it's got a new IP address it might even have a different port if you're assigning ports",
    "start": "1772490",
    "end": "1778220"
  },
  {
    "text": "dynamically so so in that case yeah that what happens is when that primary comes",
    "start": "1778220",
    "end": "1783290"
  },
  {
    "text": "up on another node that gets reported up to the system services system services update XTS and that gets pushed back down on where then it updates there's a",
    "start": "1783290",
    "end": "1789800"
  },
  {
    "text": "little window there though there's a small window where there's nothing yeah",
    "start": "1789800",
    "end": "1795380"
  },
  {
    "text": "right behind the pillar there",
    "start": "1795380",
    "end": "1798700"
  },
  {
    "text": "okay yes the question is if one of the if one of the partitions is overloaded",
    "start": "1820510",
    "end": "1825950"
  },
  {
    "text": "so too many users end up in one partition they end up overloading a node how do we handle that we don't have a good way to handle splitting and merging",
    "start": "1825950",
    "end": "1832780"
  },
  {
    "text": "partitions today so taking taking a partition splitting it up into other places the one way you can do that is",
    "start": "1832780",
    "end": "1840500"
  },
  {
    "text": "instead of using a range partition you use a name to partition so the partition just belongs to a name so for example",
    "start": "1840500",
    "end": "1846650"
  },
  {
    "text": "you have 50 States you can have 50 partitions each has a name of a state you could do that way and then you can",
    "start": "1846650",
    "end": "1853790"
  },
  {
    "text": "add more partitions and then kind of rearrange how the routing happens but there's no way to then merge it back together if if the hotspot dies down or",
    "start": "1853790",
    "end": "1861770"
  },
  {
    "text": "you lose users so that's that's a we call that a science fiction problem because over years of research we",
    "start": "1861770",
    "end": "1868490"
  },
  {
    "text": "haven't been able to figure out a good way to do a split and merge that those partitions win when it's the application",
    "start": "1868490",
    "end": "1874520"
  },
  {
    "text": "that's actually responsible for determining the distribution in the first place so if it was a completely",
    "start": "1874520",
    "end": "1879860"
  },
  {
    "text": "closed system where it is always the same distribution we could probably manage that but because it's totally random code that someone wrote that does",
    "start": "1879860",
    "end": "1887030"
  },
  {
    "text": "the distribution and the traffic routing it's harder to do it that way I think with when envoy is actually doing the",
    "start": "1887030",
    "end": "1893960"
  },
  {
    "text": "work of routing and it's programmable by the upstream service the more and more constraints we can put on that the more",
    "start": "1893960",
    "end": "1899330"
  },
  {
    "text": "realistic it becomes so this actually helps out with that a little bit but we're not quite there yet do you have",
    "start": "1899330",
    "end": "1905870"
  },
  {
    "text": "time for one more okay [Music]",
    "start": "1905870",
    "end": "1911039"
  },
  {
    "text": "okay so if you wanted to go out to a different data store to figure out which partition to route to and using Lua to",
    "start": "1929460",
    "end": "1936460"
  },
  {
    "text": "do that haven't tried it yet but I believe that that should be possible",
    "start": "1936460",
    "end": "1942340"
  },
  {
    "text": "because in Lua you can at least make some requests out before you make a decision so we did actually look at that",
    "start": "1942340",
    "end": "1948850"
  },
  {
    "text": "because of one of the proxies we wrote earlier does something like that it's sort of on demand so rather than feeding the proxy a bunch of information right",
    "start": "1948850",
    "end": "1955330"
  },
  {
    "text": "here's all the endpoints and your setter out them all it would happen a request would arrive of the proxy you would then",
    "start": "1955330",
    "end": "1961059"
  },
  {
    "text": "go make a quick call out to resolve the endpoint to come back and then complete the request so you can do that with Lua",
    "start": "1961059",
    "end": "1966820"
  },
  {
    "text": "but we haven't tried yet so I don't know what the performance implications that are should be possible to do though all",
    "start": "1966820",
    "end": "1972970"
  },
  {
    "text": "right I think that's I think we're good thanks",
    "start": "1972970",
    "end": "1979020"
  }
]
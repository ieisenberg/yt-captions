[
  {
    "text": "thank you for coming to our tutorial building an open source observability stack",
    "start": "0",
    "end": "5580"
  },
  {
    "text": "um let's just introduce ourselves here so my name is Hannah and I work at New Relic and",
    "start": "5580",
    "end": "12380"
  },
  {
    "text": "primarily on contributing to pixie hi everyone I'm Michelle and I also work",
    "start": "12380",
    "end": "19260"
  },
  {
    "text": "at New Relic I'm one of the maintainers of Pixie and later I'll be walking you through the demo that we have at the end",
    "start": "19260",
    "end": "27140"
  },
  {
    "text": "hi I'm vihang I also work at neuralik and I'm one of the maintainers for pixie",
    "start": "27420",
    "end": "34160"
  },
  {
    "text": "hi everyone and I'm Clements I am not one of the maintainers or developers of Pixie I'm actually from VMware and I",
    "start": "34260",
    "end": "40680"
  },
  {
    "text": "represent more of one of you guys so essentially I am a user of Pixie and I will walk you through not only open",
    "start": "40680",
    "end": "47160"
  },
  {
    "text": "Telemetry but also how do we use these tools in one of the projects that VMware to show you kind of how to get",
    "start": "47160",
    "end": "53520"
  },
  {
    "text": "observability and what to do with that data all right let's get started",
    "start": "53520",
    "end": "58680"
  },
  {
    "text": "so it's it's super interesting right there was a cncf study last year where they",
    "start": "58680",
    "end": "65820"
  },
  {
    "text": "were asking what observability tools do you use and what are the challenges that you see",
    "start": "65820",
    "end": "71400"
  },
  {
    "text": "and more than half of the people said they are actually struggling with just a",
    "start": "71400",
    "end": "77400"
  },
  {
    "text": "sheer volume of different tools that different teams are using so",
    "start": "77400",
    "end": "82619"
  },
  {
    "text": "this is a problem that we need to address right observability has many many different ways many different",
    "start": "82619",
    "end": "87720"
  },
  {
    "text": "things you can collect many ways that you can collect them stored and visualize it and so on and so part of",
    "start": "87720",
    "end": "93840"
  },
  {
    "text": "what we want to do today is really walk you guys through what is observability",
    "start": "93840",
    "end": "99060"
  },
  {
    "text": "how do you do this how do you instruct instrument your code to detect all these things how do you store them how do you",
    "start": "99060",
    "end": "105360"
  },
  {
    "text": "visualize them just how they get observable observability in your cluster",
    "start": "105360",
    "end": "110460"
  },
  {
    "text": "and Kate's is actually very specific in terms of separability because there's just so many open source tools and we",
    "start": "110460",
    "end": "116939"
  },
  {
    "text": "want to guide you down a path of understanding what are the most common tools out there which ones might be",
    "start": "116939",
    "end": "123479"
  },
  {
    "text": "specifically interesting for your environment and how do you actually use them so we first want to walk through",
    "start": "123479",
    "end": "129300"
  },
  {
    "text": "very high level what are the tools and then in the second section Michelle is",
    "start": "129300",
    "end": "134879"
  },
  {
    "text": "going to walk you through all right Hands-On how do I get this done so one other thing that is super",
    "start": "134879",
    "end": "140819"
  },
  {
    "text": "interesting is you know because there are so many open source Technologies you can ask yourself okay how do I avoid",
    "start": "140819",
    "end": "146099"
  },
  {
    "text": "being locked into one because it is very very tricky if you make wrong assumptions wrong decisions early in",
    "start": "146099",
    "end": "152640"
  },
  {
    "text": "your project to say what if I later want to change something does that mean I have to rebuild my entire observability",
    "start": "152640",
    "end": "159239"
  },
  {
    "text": "stack or can I just swap out individual pieces especially with closed Source",
    "start": "159239",
    "end": "165599"
  },
  {
    "text": "Solutions the lock-in could be very dangerous right let's say you're logged into a specific vendor and the vendor",
    "start": "165599",
    "end": "171540"
  },
  {
    "text": "increases price is twofold threefold that will be an issue that you have to deal with so by understanding what are",
    "start": "171540",
    "end": "177480"
  },
  {
    "text": "the different tools and what are your options you can think forward and remain flexible",
    "start": "177480",
    "end": "184340"
  },
  {
    "text": "all right so as I was saying understanding this flexibility is super important and let's assume you have an",
    "start": "184800",
    "end": "190680"
  },
  {
    "text": "application and you have already instrumented your application to get a Telemetry so let's just say you do",
    "start": "190680",
    "end": "197040"
  },
  {
    "text": "distributed tracing which is awesome as we'll see in you know the rest of this this discussion and the tutorial later",
    "start": "197040",
    "end": "203220"
  },
  {
    "text": "and you use sipkin for looking at your distributed traces you have a working end-to-end workflow you visualize your",
    "start": "203220",
    "end": "209159"
  },
  {
    "text": "traces you can debug your system everything is awesome but let's say for whatever reason you want to switch away",
    "start": "209159",
    "end": "215940"
  },
  {
    "text": "from sipkin so if you understand the ecosystem and you know what the system can do what is",
    "start": "215940",
    "end": "222900"
  },
  {
    "text": "the format of the traces that it receives what other systems in the ecosystem does it work with you can",
    "start": "222900",
    "end": "228659"
  },
  {
    "text": "essentially say well you know sipkin does distributed traces what else is distributed tracing well there is Jaeger",
    "start": "228659",
    "end": "234420"
  },
  {
    "text": "just one random example that could essentially replace one component and",
    "start": "234420",
    "end": "240000"
  },
  {
    "text": "essentially replug your end-to-end workflow to understand how do I get observability within my cluster so again",
    "start": "240000",
    "end": "247819"
  },
  {
    "text": "understanding your options and knowing what open source tools there are really",
    "start": "247819",
    "end": "253500"
  },
  {
    "text": "help you think forward plan your system plan your environment your ecosystem",
    "start": "253500",
    "end": "259440"
  },
  {
    "text": "so I want to take a step back though before we jump into individual systems just like we talk about observability but",
    "start": "259440",
    "end": "266400"
  },
  {
    "text": "what does that actually mean in practice so in my opinion there's three main pillars of observability that you need",
    "start": "266400",
    "end": "272400"
  },
  {
    "text": "to know about which are logs metrics and traces probably all of you know what logs are essentially it is a timestamp",
    "start": "272400",
    "end": "279120"
  },
  {
    "text": "event of your system maybe your application emits literally a log line that says hey I have an issue",
    "start": "279120",
    "end": "285960"
  },
  {
    "text": "processing a particular request or your system screams for help saying I just ran out of memory or something didn't",
    "start": "285960",
    "end": "292080"
  },
  {
    "text": "work as expected that is a log a metric on the other hand is a numeric representation of something that",
    "start": "292080",
    "end": "299100"
  },
  {
    "text": "happened at a particular point in time so for instance what is right now my CPU usage on a particular kubernetes node or",
    "start": "299100",
    "end": "307020"
  },
  {
    "text": "how many HTTP requests have I processed in the last 30 seconds or how many messages are in my Kafka queue that I",
    "start": "307020",
    "end": "313259"
  },
  {
    "text": "need to process so metrics very very useful for observability especially as many of you probably know for automatic",
    "start": "313259",
    "end": "319680"
  },
  {
    "text": "scaling for alerting a queue that is too long is probably a problem things like this but it's not as clear what are",
    "start": "319680",
    "end": "326340"
  },
  {
    "text": "traces to some of you maybe logs and metrics almost everybody knows traces are slightly different",
    "start": "326340",
    "end": "331620"
  },
  {
    "text": "so when you think of a trace you need to think of essentially a series of events of events that belong together that show",
    "start": "331620",
    "end": "339060"
  },
  {
    "text": "how one particular request is processed within your application and what is",
    "start": "339060",
    "end": "344160"
  },
  {
    "text": "important here is that a trace might be distributed as a request comes into your load balancer it gets processed by the",
    "start": "344160",
    "end": "350699"
  },
  {
    "text": "load balancer Maybe by your HTTP endpoint that might make distributed calls to other services within your",
    "start": "350699",
    "end": "356400"
  },
  {
    "text": "application and the trace encapsulates all the steps that are involved in processing this single request coming",
    "start": "356400",
    "end": "363780"
  },
  {
    "text": "into your application a span is one single event within a trace so a span",
    "start": "363780",
    "end": "370380"
  },
  {
    "text": "could be an individual API call that you make or the individual query that you",
    "start": "370380",
    "end": "375660"
  },
  {
    "text": "make to your database or it could be an HTTP request from one part to another and if you summarize all the spans that",
    "start": "375660",
    "end": "382319"
  },
  {
    "text": "are relevant to processing of your inbound request you call that a trace It's a combination of things so here we",
    "start": "382319",
    "end": "388620"
  },
  {
    "text": "have logs metrics and traces and this is typically what we talk about when we talk about observability",
    "start": "388620",
    "end": "394800"
  },
  {
    "text": "so what we want to do very concretely today is we want to show you how do you now",
    "start": "394800",
    "end": "401220"
  },
  {
    "text": "tackle these logs metrics and traces possibly distributed with open source",
    "start": "401220",
    "end": "408120"
  },
  {
    "text": "tools and in this specific case actually four different cncf projects so we're going to be talking about fluent bit for",
    "start": "408120",
    "end": "414479"
  },
  {
    "text": "logging we're going to talk about Prometheus for metrics we're going to be talking about open Telemetry which is really about metrics distributed phrases",
    "start": "414479",
    "end": "420780"
  },
  {
    "text": "end logs and then finally you know us being from pixie or working with Pixie we're going to talk about the pixie",
    "start": "420780",
    "end": "426900"
  },
  {
    "text": "project of course which also tackles metrics traces and application profiles and what is actually interesting is that",
    "start": "426900",
    "end": "432840"
  },
  {
    "text": "these are different projects in different stages of their cncf life cycle so we have fluent bit and",
    "start": "432840",
    "end": "438000"
  },
  {
    "text": "Prometheus which many of you might already be using they've been around for quite a while they're you know very",
    "start": "438000",
    "end": "443060"
  },
  {
    "text": "mature projects open Telemetry slightly newer and pixie is currently a Sandbox project and we're working on making it",
    "start": "443060",
    "end": "450060"
  },
  {
    "text": "you know advanced in its cncf lifetime all right so first let's focus on",
    "start": "450060",
    "end": "457319"
  },
  {
    "text": "logging and fluentbit so what is the problem with logging in kubernetes everybody knows logging and",
    "start": "457319",
    "end": "463080"
  },
  {
    "text": "it seems so simple right but there is this key problem that you probably all know if you've ever looked at the logs",
    "start": "463080",
    "end": "468479"
  },
  {
    "text": "of a pod and there is an issue and I just want to know more about it right so typically first thing that I do Kate",
    "start": "468479",
    "end": "474300"
  },
  {
    "text": "edits deployment and I increase log velocity and of course now these logs are gone because the part",
    "start": "474300",
    "end": "480479"
  },
  {
    "text": "we started and they're gone so Parts in kubernetes as you probably know are ephemeral so getting access to them and",
    "start": "480479",
    "end": "486539"
  },
  {
    "text": "storing them outside of the part is super important but it's also difficult now typically when we have a kubernetes",
    "start": "486539",
    "end": "492120"
  },
  {
    "text": "application we'll have 5 10 50 different applications you can be guaranteed that",
    "start": "492120",
    "end": "497520"
  },
  {
    "text": "you'll have 15 different log formats because why why you standardized right so we need something that is able to to",
    "start": "497520",
    "end": "504419"
  },
  {
    "text": "be able to handle different logging formats and also I don't want to go to different ports to get the logs I want",
    "start": "504419",
    "end": "511020"
  },
  {
    "text": "to have one central place where I can see all the logs of my entire kubernetes cluster",
    "start": "511020",
    "end": "516479"
  },
  {
    "text": "the problem with kubernetes as you probably know is it's intended to scale massively right we could have thousands",
    "start": "516479",
    "end": "522599"
  },
  {
    "text": "of Parts on hundreds of notes or even more so logging has become a real issue",
    "start": "522599",
    "end": "527820"
  },
  {
    "text": "in terms of performance so whatever we do for capturing these logs it has to scale massively and so really what we're",
    "start": "527820",
    "end": "535680"
  },
  {
    "text": "looking for is a lightweight logging solution and actually we have one it is",
    "start": "535680",
    "end": "540800"
  },
  {
    "text": "so fluidbit has been around four four quite a bit and we'll talk about a",
    "start": "540800",
    "end": "546779"
  },
  {
    "text": "little bit you know what's the difference between fluent D influent bit but essentially it is a system for capturing your logs processing them so",
    "start": "546779",
    "end": "553860"
  },
  {
    "text": "you can have a standardized View now I do not want to go too much into the",
    "start": "553860",
    "end": "558899"
  },
  {
    "text": "details of the architecture of fluid but I think it's important to understand what does it offer you what can you do",
    "start": "558899",
    "end": "565800"
  },
  {
    "text": "with fluentbit that allows you to say this is the right solution for Me Maybe",
    "start": "565800",
    "end": "570839"
  },
  {
    "text": "it's not for you but you know understanding what can it do helps you selecting fluent bit maybe over fluent D",
    "start": "570839",
    "end": "577260"
  },
  {
    "text": "or some other log system so at its core fluentbit really is a very Plug and Play",
    "start": "577260",
    "end": "583560"
  },
  {
    "text": "architecture that has multiple stages that take care of your logs so first of all it's able to to consume information",
    "start": "583560",
    "end": "589620"
  },
  {
    "text": "from different sources it can monitor your pods by integrating with Journal D or using tail to capture logs but it can",
    "start": "589620",
    "end": "596820"
  },
  {
    "text": "get data from many different sources it then essentially goes through a series of stages to process your logs so it has",
    "start": "596820",
    "end": "603180"
  },
  {
    "text": "a parser to make things more more structured so you know sometimes",
    "start": "603180",
    "end": "608519"
  },
  {
    "text": "you have logs that are simple log lines what fluent bit allows you to do is say I choose a particular parser that could",
    "start": "608519",
    "end": "614580"
  },
  {
    "text": "be a regular expression to say you know I always have let's say the the process name first and I have a timestamp that I",
    "start": "614580",
    "end": "619980"
  },
  {
    "text": "have a paid and so on because that might be different in your different applications so by having this parser step it essentially brings you a",
    "start": "619980",
    "end": "626519"
  },
  {
    "text": "structured metadata could also be a parts of a Json or for whatever else there is then it goes through a",
    "start": "626519",
    "end": "631800"
  },
  {
    "text": "filtering step because you might actually not be interested in all the logs of your application so fluidbit",
    "start": "631800",
    "end": "637380"
  },
  {
    "text": "allows you to filter let's say I only care about things that are python process business from a particular node",
    "start": "637380",
    "end": "642420"
  },
  {
    "text": "and so on typically you would if you can capture as much as possible but maybe in your environment that's not possible",
    "start": "642420",
    "end": "648360"
  },
  {
    "text": "fluent bit allows you to do that the interesting piece here is that filtering is not actually not only removing",
    "start": "648360",
    "end": "654000"
  },
  {
    "text": "information it can only I can also add information so for instance as I was saying you know we have the ability to",
    "start": "654000",
    "end": "660060"
  },
  {
    "text": "get kubernetes logs or pod logs by integrating with tail or Journal d you can actually in the filter step also",
    "start": "660060",
    "end": "666660"
  },
  {
    "text": "integrate with kubernetes API so you will get metadata around a log line captured a certain timestamp belongs to",
    "start": "666660",
    "end": "672480"
  },
  {
    "text": "a container in a pod in a name step in namespace and so on so if you have Rich metadata that helps you",
    "start": "672480",
    "end": "678360"
  },
  {
    "text": "and then it allows you to buffer and essentially route your data you might say hey something has a particular tag I",
    "start": "678360",
    "end": "684480"
  },
  {
    "text": "wanted to go to this log storage or if it has another attack it goes to another storage or go to all of them if you have",
    "start": "684480",
    "end": "690839"
  },
  {
    "text": "multiple and so on so it is incredibly incredibly configurable which makes it great to decide you know hey is this for",
    "start": "690839",
    "end": "697500"
  },
  {
    "text": "you one thing that is very common and that will try throughout the presentation but also later in what Michelle is showing",
    "start": "697500",
    "end": "704220"
  },
  {
    "text": "you is to help you distinguish between different projects that are out there and one of the things that people ask",
    "start": "704220",
    "end": "709980"
  },
  {
    "text": "very often is hey what's the difference between fluent do fluent D and fluent bit aren't they the same thing and it is",
    "start": "709980",
    "end": "716399"
  },
  {
    "text": "confusing because they come from the same from the same Source like the same people worked on them",
    "start": "716399",
    "end": "722399"
  },
  {
    "text": "and essentially you can say that fluent bit is a more scalable version of fluent",
    "start": "722399",
    "end": "728339"
  },
  {
    "text": "D alright so fluent D excels as how configurable it is it has tons of",
    "start": "728339",
    "end": "735120"
  },
  {
    "text": "plugins for capturing data outputting data filtering data and so on they share the same underlying architecture but",
    "start": "735120",
    "end": "741720"
  },
  {
    "text": "fluent D allows you to do much more of this fluent bit on the other hand while",
    "start": "741720",
    "end": "746760"
  },
  {
    "text": "it has fewer Integrations is incredibly scalable so if you have a cluster that",
    "start": "746760",
    "end": "752399"
  },
  {
    "text": "is incredibly large we're talking about hundreds and hundreds of nodes thousands of Parts maybe fluent bit is something",
    "start": "752399",
    "end": "758100"
  },
  {
    "text": "that you want to look at fluent D if you have very particular data sources data parsing data output needs maybe fluent D",
    "start": "758100",
    "end": "764639"
  },
  {
    "text": "is more for you just because it is so vastly configurable so that's the difference fluent bit is",
    "start": "764639",
    "end": "770279"
  },
  {
    "text": "just incredibly fast and kind of the the new cool thing so that's what we're going to be showing in the demo later",
    "start": "770279",
    "end": "776639"
  },
  {
    "text": "all right we have talked about logging let's talk about metrics so metrics probably many of you might be using",
    "start": "776639",
    "end": "783420"
  },
  {
    "text": "Prometheus already so let's talk a little bit about premises it's clearly one of the most stable systems out there",
    "start": "783420",
    "end": "788760"
  },
  {
    "text": "for dealing with large volumes of metrics so we want to tell you what does it do how does it work could it be for",
    "start": "788760",
    "end": "795720"
  },
  {
    "text": "you but like logging before let's briefly talk about what is the problem even with",
    "start": "795720",
    "end": "801540"
  },
  {
    "text": "metrics and kubernetes I mean isn't that easy so we already talked about Parts being ephemeral and just having this",
    "start": "801540",
    "end": "807779"
  },
  {
    "text": "massive amount of data that we have to capture which is not only logging also in metrics a problem so we need a system",
    "start": "807779",
    "end": "814200"
  },
  {
    "text": "that scales really really well but what is also interesting is that there is this key idea of dimensionality",
    "start": "814200",
    "end": "821760"
  },
  {
    "text": "of metrics in kubernetes so it's not just typically today that you want to say my application records this one",
    "start": "821760",
    "end": "829019"
  },
  {
    "text": "value at a particular timestamp you want to be able to say well but I don't care",
    "start": "829019",
    "end": "834300"
  },
  {
    "text": "about one pod I care about let's say I have a replicated set of PODS that belong to a Daemon set to a deployment",
    "start": "834300",
    "end": "840959"
  },
  {
    "text": "to a whatever that are just you know sibling containers I want to know about all of them so the idea that when you",
    "start": "840959",
    "end": "846839"
  },
  {
    "text": "capture metrics is we're going to annotate them with metadata and do that automatically to say well give me the",
    "start": "846839",
    "end": "853800"
  },
  {
    "text": "sum of all the number of HTTP requests processed for parts that belong to the",
    "start": "853800",
    "end": "859560"
  },
  {
    "text": "same application so we want to be able to augment the metrics as we capture that so we can later aggregate filter",
    "start": "859560",
    "end": "865019"
  },
  {
    "text": "using these metrics and of course we need centralized access right so we do",
    "start": "865019",
    "end": "871320"
  },
  {
    "text": "not want to go to different places to collect information about different problems we want to be able to go to one place and Prometheus or the ecosystem",
    "start": "871320",
    "end": "878639"
  },
  {
    "text": "that the open source environment has been built around Prometheus that allows us to do exactly this it's very scalable",
    "start": "878639",
    "end": "886199"
  },
  {
    "text": "very configurable way to capture annotated metrics and have a centralized place to visualize them",
    "start": "886199",
    "end": "892740"
  },
  {
    "text": "so let's talk a little about how does cook Prometheus work because it will be very very important for you to decide is",
    "start": "892740",
    "end": "898620"
  },
  {
    "text": "Prometheus for me and even more importantly how can I use kubernetes how can I use",
    "start": "898620",
    "end": "904800"
  },
  {
    "text": "Prometheus within kubernetes to configure the data collection I think the key thing you need to know about",
    "start": "904800",
    "end": "910380"
  },
  {
    "text": "kubernetes is at its core it has two models of capturing metrics one is the",
    "start": "910380",
    "end": "916440"
  },
  {
    "text": "pull-based and one one is the push-based model let's talk about the pool based model because I think it's the more",
    "start": "916440",
    "end": "922440"
  },
  {
    "text": "outlandish one but the one that allows it to really really scale so the idea of Prometheus is it does not so it does",
    "start": "922440",
    "end": "929940"
  },
  {
    "text": "want to capture metrics by going to the individual ports in your environment and say hey tell me about all the all the",
    "start": "929940",
    "end": "937139"
  },
  {
    "text": "metrics that you have to report so what Prometheus does it you know it uses a kind of a a",
    "start": "937139",
    "end": "943519"
  },
  {
    "text": "service to say what are all the parts that are available and essentially goes and says hey tell me all your your",
    "start": "943519",
    "end": "949620"
  },
  {
    "text": "metrics the reason why this pool based system is so powerful is if you think of the",
    "start": "949620",
    "end": "955380"
  },
  {
    "text": "opposite where you have different applications pushing data to to Prometheus you quickly run into this",
    "start": "955380",
    "end": "961260"
  },
  {
    "text": "problem that you have different parts possibly all at the same time pushing metrics to this Prometheus",
    "start": "961260",
    "end": "968279"
  },
  {
    "text": "instance which is of course is scalable but if they all push at the same time they might just take it down so by",
    "start": "968279",
    "end": "973980"
  },
  {
    "text": "having a pool based system essentially Prometheus can say I know what is the best cyclicity or times at which I can",
    "start": "973980",
    "end": "982260"
  },
  {
    "text": "go through the different parts and collect data when it works for me the downside of this pull-based system",
    "start": "982260",
    "end": "988199"
  },
  {
    "text": "is every single system that it talks to must have an interface could be an HTTP",
    "start": "988199",
    "end": "993600"
  },
  {
    "text": "endpoint something that allows it to pull information in some standard that it supports right so Prometheus has a",
    "start": "993600",
    "end": "999959"
  },
  {
    "text": "way that typically goes to an endpoint there's an HTTP request to get the metrics in a specific format parse it",
    "start": "999959",
    "end": "1006079"
  },
  {
    "text": "and put it into its storage but that implies your endpoints or your ports will have to have an end point from",
    "start": "1006079",
    "end": "1012259"
  },
  {
    "text": "which you can fetch this so if you have a closed source application which doesn't have it the pool based model of",
    "start": "1012259",
    "end": "1017300"
  },
  {
    "text": "Prometheus might not be for you but we have a solution for this don't worry another thing that is important to understand about the Prometheus",
    "start": "1017300",
    "end": "1023360"
  },
  {
    "text": "architecture is it is very configurable in terms of how does it store its metrics right there's different timestamp series databases things that",
    "start": "1023360",
    "end": "1030260"
  },
  {
    "text": "it could integrate with for storing data but also for visualizing this data very typically people use grafana for",
    "start": "1030260",
    "end": "1036918"
  },
  {
    "text": "visualizing things which of course means that there's a query language underneath that you might be able to integrate with directly but this is something that you",
    "start": "1036919",
    "end": "1043699"
  },
  {
    "text": "will want to look into and what's also interesting very typically you will want to have alerts from your kubernetes",
    "start": "1043699",
    "end": "1049040"
  },
  {
    "text": "environment right you want to be able to say hey if there's more than 10 000 elements in my queue I want to get an",
    "start": "1049040",
    "end": "1054860"
  },
  {
    "text": "alert so alert management is also something that Prometheus can give you by integrating with other Solutions but",
    "start": "1054860",
    "end": "1061100"
  },
  {
    "text": "it's the probably nicest place in your architecture where you can implement this so let me just very briefly briefly",
    "start": "1061100",
    "end": "1067880"
  },
  {
    "text": "talk about now what if you can't do this pool based model and there's as I said already one",
    "start": "1067880",
    "end": "1074120"
  },
  {
    "text": "reason that you couldn't do that is if you have a closed source application that might just not have this endpoint where you can go and fetch the metrics",
    "start": "1074120",
    "end": "1079760"
  },
  {
    "text": "but there's other problems with this pull-based model for example if you think of very very short-lived containers",
    "start": "1079760",
    "end": "1085760"
  },
  {
    "text": "so you know because Prometheus decides when to pull its data let's say you have I don't know a Kate's Crown job or",
    "start": "1085760",
    "end": "1091280"
  },
  {
    "text": "something that runs for a millisecond if Promethean not right at that second when you know this thing runs pulls the data",
    "start": "1091280",
    "end": "1097039"
  },
  {
    "text": "it's just going to be lost as I said parts are ephemeral so how would it get this data so there is the model to also",
    "start": "1097039",
    "end": "1102740"
  },
  {
    "text": "be able to push information to Prometheus which exactly handles this case if you have very short-lived",
    "start": "1102740",
    "end": "1108260"
  },
  {
    "text": "processes or if you have systems that do not allow an end point or maybe it has an endpoint but it's just the way your",
    "start": "1108260",
    "end": "1114320"
  },
  {
    "text": "system is designed you cannot access it think that there's this push-based model as well that might be able to un like",
    "start": "1114320",
    "end": "1121100"
  },
  {
    "text": "circumvent that problem so I hope by understanding the architecture of Prometheus you have an",
    "start": "1121100",
    "end": "1126140"
  },
  {
    "text": "idea of what requirements does it have very often this this interface from which you can pull information and kind",
    "start": "1126140",
    "end": "1132020"
  },
  {
    "text": "of how does it work is it for you I think in very many cases it might be interesting to you so definitely check",
    "start": "1132020",
    "end": "1137120"
  },
  {
    "text": "out the details of Prometheus it's an amazing system alrighty so now we've talked about",
    "start": "1137120",
    "end": "1142520"
  },
  {
    "text": "metrics now we want to talk a little bit more about Open Telemetry distribute traces and so on and for this I want to",
    "start": "1142520",
    "end": "1149299"
  },
  {
    "text": "hand over the microphone ready",
    "start": "1149299",
    "end": "1154240"
  },
  {
    "text": "all right so I'm going to talk about open telemetry which is also called otel for short if",
    "start": "1154700",
    "end": "1161240"
  },
  {
    "text": "you've heard that so um one General observability challenge that we have is that there are a ton of",
    "start": "1161240",
    "end": "1167539"
  },
  {
    "text": "options so this is a picture of the cncf open uh landscape mode picture of all",
    "start": "1167539",
    "end": "1174080"
  },
  {
    "text": "the observability monitoring tools out there and the open source ones are shown with the white background and the",
    "start": "1174080",
    "end": "1180500"
  },
  {
    "text": "commercial vendors are shown with the gray background so you can see that there are just so many options for you to use",
    "start": "1180500",
    "end": "1186440"
  },
  {
    "text": "and it's possible that each tool here could have its own custom way of instrumenting your application to",
    "start": "1186440",
    "end": "1192260"
  },
  {
    "text": "generate data collect data and export data so this could make switching between observability Solutions or",
    "start": "1192260",
    "end": "1198919"
  },
  {
    "text": "adding a new one very difficult so this is the problem that open Telemetry is set out to solve",
    "start": "1198919",
    "end": "1205880"
  },
  {
    "text": "now what is open Telemetry this is actually very confusing and I hope that",
    "start": "1205880",
    "end": "1211220"
  },
  {
    "text": "one of the main things you can go away with today is like a clear understanding of all the cool projects that are happening under the open Telemetry",
    "start": "1211220",
    "end": "1217820"
  },
  {
    "text": "umbrella because I think each sort of thing I'm going to mention could be a project on its own",
    "start": "1217820",
    "end": "1223340"
  },
  {
    "text": "so at its core open Telemetry is a collection of standardized vendor",
    "start": "1223340",
    "end": "1228559"
  },
  {
    "text": "agnostic tools to generate collect and Export Telemetry data",
    "start": "1228559",
    "end": "1233900"
  },
  {
    "text": "so what does that mean so first of all it's a universal format for Telemetry data and that includes metrics logs and",
    "start": "1233900",
    "end": "1241340"
  },
  {
    "text": "traces so that's one part of open Telemetry the second part is that it provides client",
    "start": "1241340",
    "end": "1247580"
  },
  {
    "text": "libraries to instrument your app so for example you have like otel for Java and",
    "start": "1247580",
    "end": "1253580"
  },
  {
    "text": "open Telemetry provides ways to do manual instrumentation as well as automatic instrumentation",
    "start": "1253580",
    "end": "1260059"
  },
  {
    "text": "another thing that open Telemetry has is an API for sending and receiving data in the open Telemetry format now this",
    "start": "1260059",
    "end": "1267380"
  },
  {
    "text": "enables you to collect to connect open Telemetry supporting applications and libraries together",
    "start": "1267380",
    "end": "1272960"
  },
  {
    "text": "and finally what open Telemetry is is the otel collector and this allows you to receive transform and send data in",
    "start": "1272960",
    "end": "1279860"
  },
  {
    "text": "the open Telemetry format and this is useful because it gives you one single spot to collect and process all of your",
    "start": "1279860",
    "end": "1286220"
  },
  {
    "text": "metrics and then it's a single thing that has to talk to your storage solution now one thing to note that open",
    "start": "1286220",
    "end": "1292400"
  },
  {
    "text": "Telemetry is not is it's not an observability back end Like Jaeger or Prometheus",
    "start": "1292400",
    "end": "1299019"
  },
  {
    "text": "so I'm not going to go into the implementation details of open Telemetry right now but um one thing I want to",
    "start": "1299900",
    "end": "1306740"
  },
  {
    "text": "again demystify is like the overlap between Prometheus and open Telemetry and these projects are very",
    "start": "1306740",
    "end": "1312740"
  },
  {
    "text": "intraoperable um Prometheus is at the current moment more widely adopted it has an SDK for",
    "start": "1312740",
    "end": "1319520"
  },
  {
    "text": "instrumenting your code it defines a standard metric format and it also has a back end for storage and querying",
    "start": "1319520",
    "end": "1326419"
  },
  {
    "text": "now open Telemetry is a newer project and it also defines a standard which is a superset of the Prometheus metric",
    "start": "1326419",
    "end": "1332480"
  },
  {
    "text": "standard and it also provides standards for traces and logs in addition open",
    "start": "1332480",
    "end": "1337580"
  },
  {
    "text": "Telemetry also has an SDK for instrumenting your app but unlike Prometheus open Telemetry does not have",
    "start": "1337580",
    "end": "1343460"
  },
  {
    "text": "a back end thank you so that was open Telemetry now we're",
    "start": "1343460",
    "end": "1349400"
  },
  {
    "text": "going to briefly uh discuss pixie and pixie as we discussed is an incubating or sorry sandbox project we just applied",
    "start": "1349400",
    "end": "1356179"
  },
  {
    "text": "for incubating and um it is a newer project and the goal behind this project",
    "start": "1356179",
    "end": "1361580"
  },
  {
    "text": "is that right now adding instrumentation to your app is very tedious it takes a",
    "start": "1361580",
    "end": "1367400"
  },
  {
    "text": "significant amount of time for you to set up trace and Metric collection this is some example application code and",
    "start": "1367400",
    "end": "1373700"
  },
  {
    "text": "highlighted in red is the instrumentation logic and highlighted in green is the actual application business",
    "start": "1373700",
    "end": "1379880"
  },
  {
    "text": "logic and so it just goes to show that like instrumentation can take a lot of time to add and so the idea is like what",
    "start": "1379880",
    "end": "1388340"
  },
  {
    "text": "if we could automatically collect some of this Telemetry data and I think that's where the observability field is",
    "start": "1388340",
    "end": "1393740"
  },
  {
    "text": "going one of the ways so uh and one way we're going to look at",
    "start": "1393740",
    "end": "1399260"
  },
  {
    "text": "this is using ebpf technology so this technology allows you to dynamically",
    "start": "1399260",
    "end": "1404539"
  },
  {
    "text": "program the kernel for efficient networking observability tracing and security",
    "start": "1404539",
    "end": "1410360"
  },
  {
    "text": "so we're going to talk about how Pixi uses ebpf for observability but basically at a high level when you",
    "start": "1410360",
    "end": "1418280"
  },
  {
    "text": "have pixie deployed to the nodes in your cluster it deploys these ebpf kernel probes that are set up to trigger on",
    "start": "1418280",
    "end": "1424640"
  },
  {
    "text": "Linux sysk calls related to networking and so whenever any of your applications makes Network related system calls such",
    "start": "1424640",
    "end": "1431000"
  },
  {
    "text": "as send or receive these ebpf probes can snoop the data that's being sent parse",
    "start": "1431000",
    "end": "1436159"
  },
  {
    "text": "it according to various protocols and store it for querying so the cool part now that you kind of",
    "start": "1436159",
    "end": "1443299"
  },
  {
    "text": "know how evpf Works uh the like the main point here is that you can use this new technology to capture full body requests",
    "start": "1443299",
    "end": "1450980"
  },
  {
    "text": "Network metrics and even application CPU profiles",
    "start": "1450980",
    "end": "1456880"
  },
  {
    "text": "so I think the cool thing here is that the observability ecosystem has noted that like automated instrumentation",
    "start": "1457340",
    "end": "1463520"
  },
  {
    "text": "would be the best way for people to instrument their apps well not the best but let's get like 80 of the metrics",
    "start": "1463520",
    "end": "1469880"
  },
  {
    "text": "that we need off the table and obviously we need custom metrics still for very",
    "start": "1469880",
    "end": "1474919"
  },
  {
    "text": "specific things that we're looking at so all of these projects are interoperable Pixi exports in the open Telemetry",
    "start": "1474919",
    "end": "1482299"
  },
  {
    "text": "format so you can use all of these together to get both automated forms of telemetry and more manual forms for",
    "start": "1482299",
    "end": "1488840"
  },
  {
    "text": "specific things you're interested in so that was pixie I'm going to hand it",
    "start": "1488840",
    "end": "1493880"
  },
  {
    "text": "back to Clemens to discuss like what would this what this might look like in a real world use case",
    "start": "1493880",
    "end": "1500299"
  },
  {
    "text": "thanks Anna alrighty so as I said in the beginning I'm part of VMware so I'm working on as",
    "start": "1500299",
    "end": "1506900"
  },
  {
    "text": "part of the office of the CTO in a environment called xlabs and so we try to build cool new stuff that is not yet",
    "start": "1506900",
    "end": "1513740"
  },
  {
    "text": "part of a product but thinking forward you know what will our customers our users need down the line and",
    "start": "1513740",
    "end": "1519880"
  },
  {
    "text": "observability and security is clearly top of mind for all of you I mean that's hopefully why you're here",
    "start": "1519880",
    "end": "1526279"
  },
  {
    "text": "um and so I want to just very briefly talk about what we call Project Trinidad which is what I'm personally working on",
    "start": "1526279",
    "end": "1531620"
  },
  {
    "text": "which uses many of these tools and technologies that we just talked about to solve a security problem",
    "start": "1531620",
    "end": "1537559"
  },
  {
    "text": "so I don't want to dive into the details it's not a marketing pitch but really what we want to solve essentially let's",
    "start": "1537559",
    "end": "1543679"
  },
  {
    "text": "automatically collect open Telemetry information about your kubernetes clusters and learn what is normal in",
    "start": "1543679",
    "end": "1549919"
  },
  {
    "text": "your cluster in terms of security so I want to know what are the pods how do they talk to each other what are the",
    "start": "1549919",
    "end": "1555799"
  },
  {
    "text": "protocols that they use to talk to each other and just understand what is normal what are the apis that are invoked from",
    "start": "1555799",
    "end": "1561740"
  },
  {
    "text": "which types of PODS and what are the API parameters that are used right and so I",
    "start": "1561740",
    "end": "1568159"
  },
  {
    "text": "can very clearly see there's certain patterns that you know how these pods are interacting and learn what is normal",
    "start": "1568159",
    "end": "1574039"
  },
  {
    "text": "and maybe one day suddenly one of your parts really misbehaves talks to things that has never talked to before invokes",
    "start": "1574039",
    "end": "1580940"
  },
  {
    "text": "apis that shouldn't be invoking sets parameters that we've never seen in the past and that could be a sign of an",
    "start": "1580940",
    "end": "1587539"
  },
  {
    "text": "attack maybe one of your parts got compromised and now there's an attacker maybe trying to extract data from your",
    "start": "1587539",
    "end": "1592880"
  },
  {
    "text": "database and send it out to the internet clearly a problem and the cool thing is if you look inside kubernetes cluster",
    "start": "1592880",
    "end": "1598580"
  },
  {
    "text": "the East-West traffic is really very standardized and when you have lots of data very standard things and you want",
    "start": "1598580",
    "end": "1604460"
  },
  {
    "text": "to find outliers what could be better than machine learning to do that and that is exactly what we're trying to do with project Trinidad we'll learn",
    "start": "1604460",
    "end": "1610460"
  },
  {
    "text": "automatically what is your normal in your environment just to alert you haters probably a security incident if we see something that is not very normal",
    "start": "1610460",
    "end": "1616820"
  },
  {
    "text": "now we're using many of the tools that we've seen before but essentially we deploy Pixi at the core of your",
    "start": "1616820",
    "end": "1623179"
  },
  {
    "text": "kubernetes cluster to collect a lot of information and get this in the open Telemetry format and send it to a cloud",
    "start": "1623179",
    "end": "1629299"
  },
  {
    "text": "we use many open source Technologies by the way I'm presenting this just to kind of show you how even in your environment",
    "start": "1629299",
    "end": "1636020"
  },
  {
    "text": "you could plug these things together in a very similar fashion right so we use actually to streams the operator to",
    "start": "1636020",
    "end": "1641120"
  },
  {
    "text": "automatically deploy Kafka for uploading data from the open Telemetry collector which is you know supported out of the",
    "start": "1641120",
    "end": "1646940"
  },
  {
    "text": "box by the hotel collector and then we use a whole bunch of stuff for example we use Cube flow we use ml flow to",
    "start": "1646940",
    "end": "1652460"
  },
  {
    "text": "essentially look at data which we store in elasticsearch which the Jaeger tool can",
    "start": "1652460",
    "end": "1657559"
  },
  {
    "text": "actually write for us directly taking it off of Kafka queue storing elasticsearch and we can use coupon ml flow to learn",
    "start": "1657559",
    "end": "1663860"
  },
  {
    "text": "what is normal and then we can perform inference to find out normal stuff but by the way in the end we can even",
    "start": "1663860",
    "end": "1670159"
  },
  {
    "text": "use the Jaeger UI to visualize what is going on in your environment and take things that are not normal right but you",
    "start": "1670159",
    "end": "1675740"
  },
  {
    "text": "can see I mean clearly maybe you don't want to do fancy stuff like ml for finding security relevant anomalies but",
    "start": "1675740",
    "end": "1681919"
  },
  {
    "text": "a lot of this stuff you can build yourself using all the Technologies we've talked about today and just plug",
    "start": "1681919",
    "end": "1687440"
  },
  {
    "text": "them together so again understanding the ecosystem how things interact and understanding these formats and how you",
    "start": "1687440",
    "end": "1694700"
  },
  {
    "text": "can you know swap one for the other really empowers you to do a lot of very very cool things",
    "start": "1694700",
    "end": "1700580"
  },
  {
    "text": "all right I'm sure you all want to get your hands dirty and see how does this work in practice right I see you all",
    "start": "1700580",
    "end": "1706220"
  },
  {
    "text": "have your your laptops open so I would say Michelle walk us through how does this work you know in a real environment",
    "start": "1706220",
    "end": "1714460"
  },
  {
    "text": "okay thank you Clemens so up on the screen you see we have a QR code or if you guys are more comfortable typing",
    "start": "1715100",
    "end": "1721220"
  },
  {
    "text": "your Prof you should feel free to type out the URL as well but this is basically a set of demo applications",
    "start": "1721220",
    "end": "1727279"
  },
  {
    "text": "we've built on top of the open Telemetry demo and uh there's a lot a bunch of",
    "start": "1727279",
    "end": "1732799"
  },
  {
    "text": "different steps you know setting up your cluster there's deploying the demo application itself and then walking",
    "start": "1732799",
    "end": "1738320"
  },
  {
    "text": "through the dashboards and the data that it provides you so I highly encourage",
    "start": "1738320",
    "end": "1744080"
  },
  {
    "text": "everybody to go check it out but I also want to you know make note of the time that we have because we've actually seen",
    "start": "1744080",
    "end": "1749720"
  },
  {
    "text": "you know as some of you may or may not know Wi-Fi is very slow at this conference and so when we try to",
    "start": "1749720",
    "end": "1756140"
  },
  {
    "text": "personally deploy it ourselves it took about 30 minutes I was like okay we're not going to have everybody sit there",
    "start": "1756140",
    "end": "1761539"
  },
  {
    "text": "for 30 minutes while we do that so what I'm going to do instead is just walk you through what some of this data looks",
    "start": "1761539",
    "end": "1766940"
  },
  {
    "text": "like to give color into some of the tools that you know Hannah and Clemens",
    "start": "1766940",
    "end": "1772220"
  },
  {
    "text": "mentioned earlier so when you deploy the demo applications",
    "start": "1772220",
    "end": "1777980"
  },
  {
    "text": "this is basically the flow of what you have so first you have the demo application I'll show you what that",
    "start": "1777980",
    "end": "1783440"
  },
  {
    "text": "looks like in a moment but from the demo application we're collecting things such as metrics traces and logs so the",
    "start": "1783440",
    "end": "1789919"
  },
  {
    "text": "metrics and traces are actually going to be collected by open Telemetry using both Auto instrumentation and manual",
    "start": "1789919",
    "end": "1796820"
  },
  {
    "text": "instrumentation and then we will have logs which will be collected by fluentbit which we also mentioned",
    "start": "1796820",
    "end": "1801980"
  },
  {
    "text": "earlier these will flow through to the open Telemetry collector the open Telemetry collector will then send this",
    "start": "1801980",
    "end": "1808220"
  },
  {
    "text": "data out to different data sources so first we have Prometheus which will be collecting your metrics then you have",
    "start": "1808220",
    "end": "1816140"
  },
  {
    "text": "otel or Jaeger which will be collecting the traces and storing them then for the logs we will be sending that from for",
    "start": "1816140",
    "end": "1823760"
  },
  {
    "text": "the open cylindry format to Loki and then at the end of that we have grafana",
    "start": "1823760",
    "end": "1829220"
  },
  {
    "text": "which is going to be pulling information from all of these different data sources and showing you them in the why so you",
    "start": "1829220",
    "end": "1835820"
  },
  {
    "text": "can make sense of what's happening in your cluster okay so I'm going to actually",
    "start": "1835820",
    "end": "1842299"
  },
  {
    "text": "change up the display because I will need to mirror this instead of splitting these screens so just give me",
    "start": "1842299",
    "end": "1849320"
  },
  {
    "text": "a moment",
    "start": "1849320",
    "end": "1851679"
  },
  {
    "text": "okay so if you follow through our tutorial that I linked to in the QR code earlier",
    "start": "1868279",
    "end": "1874279"
  },
  {
    "text": "you're going to be deploying a few things in your cluster we don't need to go into what all these different pods",
    "start": "1874279",
    "end": "1879559"
  },
  {
    "text": "are just know that there's a bunch of different pods that all do different things some will be for the purpose of the demo application some will be such",
    "start": "1879559",
    "end": "1886399"
  },
  {
    "text": "as you can see here these are the fluent bid collectors there will be pods for",
    "start": "1886399",
    "end": "1891440"
  },
  {
    "text": "grafana and so on and so forth so the next part of the tutorial is that in",
    "start": "1891440",
    "end": "1896480"
  },
  {
    "text": "order to actually see all this stuff in a UI you're going to want to port forward so I'm going to go ahead and run",
    "start": "1896480",
    "end": "1902539"
  },
  {
    "text": "that great so that's starting up and I'm going to open the grifana UI",
    "start": "1902539",
    "end": "1910700"
  },
  {
    "text": "or actually let me show you the demo application first so this is the demo application that comes with the open",
    "start": "1910700",
    "end": "1916399"
  },
  {
    "text": "Telemetry demo this is a simple e-commerce application where you can basically just go and shop for a bunch",
    "start": "1916399",
    "end": "1922760"
  },
  {
    "text": "of different telescopes so you can click in view the product you know add more things that you want to buy add it to",
    "start": "1922760",
    "end": "1928700"
  },
  {
    "text": "your cart check out so on and so forth and uh there's a lot of potential",
    "start": "1928700",
    "end": "1934159"
  },
  {
    "text": "information that you might want to track here to make sure that you're always serving the best experience for your customers so we can go ahead and go into",
    "start": "1934159",
    "end": "1940940"
  },
  {
    "text": "grafana see what some of that data looks like",
    "start": "1940940",
    "end": "1948520"
  },
  {
    "text": "so with the demo application we've also deployed a bunch of different grafana dashboards that you can see here we're",
    "start": "1948620",
    "end": "1955880"
  },
  {
    "text": "going to dive into each of these and see what you might be able to see about the demo application so first we're going to",
    "start": "1955880",
    "end": "1961880"
  },
  {
    "text": "start with Prometheus or metrics and you see here that you know there's a bunch of different metrics that you can gather",
    "start": "1961880",
    "end": "1968120"
  },
  {
    "text": "you can visualize them in many different ways so for the top two I can let me",
    "start": "1968120",
    "end": "1973159"
  },
  {
    "text": "actually zoom in to make it clearer so you can collect things like system metrics so a lot of this can be done it",
    "start": "1973159",
    "end": "1980179"
  },
  {
    "text": "can be Auto instrumented by open Telemetry so the top two are actually done through Auto instrumentation you",
    "start": "1980179",
    "end": "1985760"
  },
  {
    "text": "can get things such as CPU and memory that helps you figure out things like you know your program might be running a",
    "start": "1985760",
    "end": "1991159"
  },
  {
    "text": "very long for Loop an infinite Loop you might have you know your memory continues to grow and you can find",
    "start": "1991159",
    "end": "1996200"
  },
  {
    "text": "things such as memory leaks you can trace or get metrics about your network",
    "start": "1996200",
    "end": "2001779"
  },
  {
    "text": "requests so you can see the latency of your different network requests or you might be able to track the error rate",
    "start": "2001779",
    "end": "2008380"
  },
  {
    "text": "here is a different kind of metric that I wanted to point out is the recommendations count so as you may have",
    "start": "2008380",
    "end": "2014260"
  },
  {
    "text": "heard earlier there's many different kinds of metrics and custom metrics are ones that are specific to your",
    "start": "2014260",
    "end": "2020679"
  },
  {
    "text": "application and the needs that you might have so in this case where we have this e-commerce application where we make",
    "start": "2020679",
    "end": "2025960"
  },
  {
    "text": "different recommendations to people about what products they might be interested in you might want to count how many recommendations that you're",
    "start": "2025960",
    "end": "2031899"
  },
  {
    "text": "showing to people you know for example this count goes to zero maybe there's something that's broken in your pipeline",
    "start": "2031899",
    "end": "2036940"
  },
  {
    "text": "and so to do that you have to do some manual instrumentation you can use libraries such as open Telemetry or",
    "start": "2036940",
    "end": "2044019"
  },
  {
    "text": "Prometheus to do that and then you can send that data over to open Telemetry and visualize that in the dashboard such",
    "start": "2044019",
    "end": "2050679"
  },
  {
    "text": "as this next we're going to look at logs so",
    "start": "2050679",
    "end": "2057099"
  },
  {
    "text": "everybody is pretty familiar with Vlogs I believe this has a lot of logs so it's a little bit slow but here you can see",
    "start": "2057099",
    "end": "2064179"
  },
  {
    "text": "we've collected a bunch of logs across from all of the kubernetes pods in your cluster and the nice thing that fluent",
    "start": "2064179",
    "end": "2071020"
  },
  {
    "text": "can do as Clemens was mentioning earlier is you can add you know filters you can add different processing to what you're",
    "start": "2071020",
    "end": "2078339"
  },
  {
    "text": "collecting from the logs to add color to the data that you're collecting so here we've actually added you know what is",
    "start": "2078339",
    "end": "2084700"
  },
  {
    "text": "the kubernetes container that this law came from you have the log itself and you also have things like you know who's",
    "start": "2084700",
    "end": "2091358"
  },
  {
    "text": "the person who exported it what kind of log this is was standard out standard error so you know you can get logs from",
    "start": "2091359",
    "end": "2099040"
  },
  {
    "text": "across from all your different environments all your different pods and view them and filter them however you like to give you the most information",
    "start": "2099040",
    "end": "2104740"
  },
  {
    "text": "about what's going on in your application and then we will move on to our traces",
    "start": "2104740",
    "end": "2115440"
  },
  {
    "text": "all right so here you can actually flip through different services so you can find you know which Trace was generated",
    "start": "2117880",
    "end": "2125680"
  },
  {
    "text": "by which service so this is currently on the feature flag service I just switched to the product catalog service which is",
    "start": "2125680",
    "end": "2131619"
  },
  {
    "text": "responsible for showing the different products that you see on the opent Telemetry demo website and so you can",
    "start": "2131619",
    "end": "2138280"
  },
  {
    "text": "actually click into a trace so this one you can see this is following the get product request and if we click in you",
    "start": "2138280",
    "end": "2145119"
  },
  {
    "text": "can actually get a nice view this one's not as interesting so I'll click into a different one after you can get a view of you know where was this request",
    "start": "2145119",
    "end": "2151720"
  },
  {
    "text": "generated from and so this started the front end so somebody hit the UI they",
    "start": "2151720",
    "end": "2157359"
  },
  {
    "text": "wanted to get the product and that sent a request down to the product catalog service",
    "start": "2157359",
    "end": "2163180"
  },
  {
    "text": "and so we can click into that and also get more information about that request so with open Telemetry or other tools",
    "start": "2163180",
    "end": "2170260"
  },
  {
    "text": "you can add different attributes to these traces so at its core a trace you'll be able to get information like",
    "start": "2170260",
    "end": "2177220"
  },
  {
    "text": "who's making this request who's receiving that request how much time is that taking but you can also add your",
    "start": "2177220",
    "end": "2183460"
  },
  {
    "text": "own custom attributes to give you more information about what's going on so here we're able to instrument this with",
    "start": "2183460",
    "end": "2189760"
  },
  {
    "text": "what is the product name of the product that somebody tried to fetch what is the product ID and you can essentially add",
    "start": "2189760",
    "end": "2195460"
  },
  {
    "text": "whatever information you might need that works best for you and so some of these traces let me see if I can try to find",
    "start": "2195460",
    "end": "2200560"
  },
  {
    "text": "one they can get pretty complicated so this one for example right you're able to trace somebody made a request from",
    "start": "2200560",
    "end": "2206260"
  },
  {
    "text": "the front end that then hit the recommendation service which then hit you know the feature flag service and so",
    "start": "2206260",
    "end": "2211720"
  },
  {
    "text": "it helps you dive really deep into what's happening in your application and what's really nice is that sometimes you",
    "start": "2211720",
    "end": "2217720"
  },
  {
    "text": "know the customers complaining they're saying hey I'm hitting the front end getting this product is really slow and you",
    "start": "2217720",
    "end": "2225400"
  },
  {
    "text": "don't actually know where in that pipeline because you're making calls across so many different microservices you have no idea where that slowness is",
    "start": "2225400",
    "end": "2231460"
  },
  {
    "text": "so you can actually go and take visualizations like these and go ahead and see hey where is this taking a lot",
    "start": "2231460",
    "end": "2238060"
  },
  {
    "text": "longer than I expect figure out which microservice it is and fix that and hopefully resolve that problem for your",
    "start": "2238060",
    "end": "2243460"
  },
  {
    "text": "users so I'm now going to hand it over to vihong who's going to talk a little bit",
    "start": "2243460",
    "end": "2249640"
  },
  {
    "text": "about Pixie",
    "start": "2249640",
    "end": "2252838"
  },
  {
    "text": "um thanks Michelle so this is sort of what you get when you deploy pixie so as",
    "start": "2260920",
    "end": "2267160"
  },
  {
    "text": "Michelle said uh with Pixie you can collect all of this data using ebpf",
    "start": "2267160",
    "end": "2273880"
  },
  {
    "text": "automatically so this is a the same cluster of the open Telemetry demo deployed on it and",
    "start": "2273880",
    "end": "2280839"
  },
  {
    "text": "when you go to the pixie UI this is the kind of view you get straight off the bat we can see that we",
    "start": "2280839",
    "end": "2287500"
  },
  {
    "text": "have a service map the service map is created by looking at all of the network",
    "start": "2287500",
    "end": "2293200"
  },
  {
    "text": "traffic that pixie collects using the ebpf probes that we have installed and",
    "start": "2293200",
    "end": "2298900"
  },
  {
    "text": "we can then parse that traffic compute stuff like latencies for it and understand uh what sort of services are",
    "start": "2298900",
    "end": "2305980"
  },
  {
    "text": "running in your cluster and how they're talking to each other so now if we zoom in a little bit more we can see the",
    "start": "2305980",
    "end": "2312820"
  },
  {
    "text": "various demo apps running in here we can tell that there's like Loki running",
    "start": "2312820",
    "end": "2318400"
  },
  {
    "text": "which is doing the logs processing part for grafana we have a collector for open",
    "start": "2318400",
    "end": "2324520"
  },
  {
    "text": "Telemetry running and we have a bunch of other stuff like that [Music] um",
    "start": "2324520",
    "end": "2329800"
  },
  {
    "text": "let's dive a little bit deeper into the the actual Network traffic that Pixies collecting so the stuff that uh Powers",
    "start": "2329800",
    "end": "2337240"
  },
  {
    "text": "this service map [Music] um and so we can look at the HTTP data in",
    "start": "2337240",
    "end": "2342700"
  },
  {
    "text": "this cluster so you can see that pixie actually manages to collect all sort of",
    "start": "2342700",
    "end": "2348700"
  },
  {
    "text": "requests in the cluster and if we expand one of these out we can see that we have",
    "start": "2348700",
    "end": "2355420"
  },
  {
    "text": "all sorts of details for this request so you know when you collect the network",
    "start": "2355420",
    "end": "2360700"
  },
  {
    "text": "data we have access for the IP address that's making the request the request",
    "start": "2360700",
    "end": "2366040"
  },
  {
    "text": "headers the response headers and the entire body and then we talked to the",
    "start": "2366040",
    "end": "2371980"
  },
  {
    "text": "kubernetes API to sort of resolve these IP addresses and enrich it with the kubernetes metadata to sort of",
    "start": "2371980",
    "end": "2378700"
  },
  {
    "text": "understand which pods are talking to which other pods or services and so on and so forth",
    "start": "2378700",
    "end": "2384000"
  },
  {
    "text": "note that one of the cool things about using abpf is that we can trace this",
    "start": "2384000",
    "end": "2391060"
  },
  {
    "text": "data even if you're using mtls in your cluster because we can hook probes into",
    "start": "2391060",
    "end": "2396160"
  },
  {
    "text": "the openssl library and capture the requests and response bodies before",
    "start": "2396160",
    "end": "2401260"
  },
  {
    "text": "they're encrypted and sent over the wire so that's one of the cool things you can do with Pixi",
    "start": "2401260",
    "end": "2407800"
  },
  {
    "text": "and then another another feature of Pixie uh that comes automatically because of the fact that we can use the",
    "start": "2407800",
    "end": "2414579"
  },
  {
    "text": "BPF to install these probes is the fact that you can get uh flame graphs so let's say you're looking at different",
    "start": "2414579",
    "end": "2421780"
  },
  {
    "text": "applications that you're running and wondering about performance and trying to optimize that and you need to know",
    "start": "2421780",
    "end": "2427420"
  },
  {
    "text": "where the CPU time is being spent Pixi can give you access to some of that so let's look at one of the nodes in our",
    "start": "2427420",
    "end": "2433900"
  },
  {
    "text": "cluster I can scroll down and you can see sort of like the entire uh CPU cores on this",
    "start": "2433900",
    "end": "2441760"
  },
  {
    "text": "node being used and where all the time is being spent they get broken out by our various pods and the containers",
    "start": "2441760",
    "end": "2449079"
  },
  {
    "text": "running in each pod and then for any one of those containers we actually can zoom in further and we get access to what the",
    "start": "2449079",
    "end": "2456520"
  },
  {
    "text": "funk was actually doing at time of that as part of that application so this sort",
    "start": "2456520",
    "end": "2462760"
  },
  {
    "text": "of information it's is why we think ebpf is a cool way to collect some of those Telemetry data because collecting these",
    "start": "2462760",
    "end": "2470680"
  },
  {
    "text": "frame graphs and stuff like that it's kind of hard to manually instrument this stuff and Pixi lets you sort of do this",
    "start": "2470680",
    "end": "2478780"
  },
  {
    "text": "on an application when it's sort of you might be debugging something goes wrong in production you don't have the time to",
    "start": "2478780",
    "end": "2485619"
  },
  {
    "text": "add instrumentation rebuild all of your apps and deploy them to try to test it",
    "start": "2485619",
    "end": "2490660"
  },
  {
    "text": "out again with using abpf probes you can kind of get this sort of debugability and observability into the stuff you're",
    "start": "2490660",
    "end": "2497500"
  },
  {
    "text": "running uh directly",
    "start": "2497500",
    "end": "2501119"
  },
  {
    "text": "so we wanted to open it up for any questions that anybody had about any of these particular tools that we mentioned",
    "start": "2504040",
    "end": "2510220"
  },
  {
    "text": "about observability I think Clemens and Hannah if you'd like to join us back on the stage for that",
    "start": "2510220",
    "end": "2517740"
  },
  {
    "text": "also I wanted to mention that if anyone's following along with the guide and you're trying to get everything",
    "start": "2527500",
    "end": "2533920"
  },
  {
    "text": "deployed on your cluster over this wi-fi first of all Kudos but second off all if",
    "start": "2533920",
    "end": "2539440"
  },
  {
    "text": "you need any help if you run into issues just raise your hand one of us can help help out help come help you out",
    "start": "2539440",
    "end": "2547720"
  },
  {
    "text": "yes and we also wanted to say for anyone who is trying this at home and then maybe later on support or wants to ask",
    "start": "2547720",
    "end": "2553119"
  },
  {
    "text": "any questions there's also the cncf slack there's the channel I think I believe it's called two dash kubecon",
    "start": "2553119",
    "end": "2559420"
  },
  {
    "text": "dash sessions so we'll be monitoring that for any questions you all might have",
    "start": "2559420",
    "end": "2565200"
  },
  {
    "text": "all right so are there any questions you can wander around then we'll just wander around oh I see one yeah in the",
    "start": "2567880",
    "end": "2574839"
  },
  {
    "text": "back you walk up to duck",
    "start": "2574839",
    "end": "2581279"
  },
  {
    "text": "are up here",
    "start": "2585280",
    "end": "2588180"
  },
  {
    "text": "thanks my name is belinder and I'm a devops engineer and thanks for this cool",
    "start": "2595480",
    "end": "2601359"
  },
  {
    "text": "demo I just have a question about this uh setup the storage",
    "start": "2601359",
    "end": "2606579"
  },
  {
    "text": "so all these applications you have integrated together",
    "start": "2606579",
    "end": "2611940"
  },
  {
    "text": "in a very busy environment how practical it is to",
    "start": "2612420",
    "end": "2618280"
  },
  {
    "text": "um to manage it you know on a daily basis especially from the storage point of view and the actual usability point",
    "start": "2618280",
    "end": "2624160"
  },
  {
    "text": "of view I mean this is very cool in a demo but I just want to understand the storage part thanks",
    "start": "2624160",
    "end": "2632040"
  },
  {
    "text": "so are you particularly interested in the storage of Pixie or of all the other well all of them the logs locky I know",
    "start": "2632980",
    "end": "2640480"
  },
  {
    "text": "that we can store you know the locker comes up with the storage engine engine but I'm interested in if you have build",
    "start": "2640480",
    "end": "2647140"
  },
  {
    "text": "this one as a one application we still have to manage storage for all of them separately",
    "start": "2647140",
    "end": "2654240"
  },
  {
    "text": "so then in this case it's all stored in Prometheus right Loki so most of it is",
    "start": "2654700",
    "end": "2661480"
  },
  {
    "text": "stored in Loki so you know you don't want to have a central storage because yes you definitely do not want to have to manage all these different storage",
    "start": "2661480",
    "end": "2667800"
  },
  {
    "text": "systems so yes okay in this case is like one place in a very busy",
    "start": "2667800",
    "end": "2675280"
  },
  {
    "text": "very very busy environment let's say is it practical do you have this running in",
    "start": "2675280",
    "end": "2680500"
  },
  {
    "text": "a busy system or this is still under development or or beta for example so I",
    "start": "2680500",
    "end": "2687099"
  },
  {
    "text": "mean the open Telemetry demo of course is something that we use right so this is not something that we have deployed okay but yes um I mean this is used on a",
    "start": "2687099",
    "end": "2695260"
  },
  {
    "text": "very large scale so for our experiments clearly you will have you know dozens if not hundreds of notes in which you want",
    "start": "2695260",
    "end": "2701140"
  },
  {
    "text": "to deploy uh Pixie for instance yeah and yes there are issues that you need to",
    "start": "2701140",
    "end": "2706300"
  },
  {
    "text": "look into the the scaling the storage yeah I think it's really important like one of the things we talked about right",
    "start": "2706300",
    "end": "2712240"
  },
  {
    "text": "is this this architecture where you can say what is important to you because I believe that it's just deploying and",
    "start": "2712240",
    "end": "2718240"
  },
  {
    "text": "capturing everything is just not reasonable right yeah so there is a lot of this this thought around okay what is",
    "start": "2718240",
    "end": "2724119"
  },
  {
    "text": "important to you to capture um deduplicate filter for the things",
    "start": "2724119",
    "end": "2729760"
  },
  {
    "text": "that are interesting to you and actually the demo when you do it yourself you can see how you can have that just config",
    "start": "2729760",
    "end": "2735460"
  },
  {
    "text": "maps on your kubernetes cluster where you say what do you really care about right and actually one of the nice things that Hannah was talking to is the",
    "start": "2735460",
    "end": "2742240"
  },
  {
    "text": "central piece of the open Telemetry collector which has several ex so we didn't talk about the architecture too",
    "start": "2742240",
    "end": "2748180"
  },
  {
    "text": "much there but the collector is actually quite nice and that is also multiple components that can be launched in a",
    "start": "2748180",
    "end": "2753700"
  },
  {
    "text": "sequence so what you can actually say is that you have a collector you have a Batcher and then you have a filter so",
    "start": "2753700",
    "end": "2758980"
  },
  {
    "text": "maybe in your case you want to use head-based sampling you want to use tail based sampling for those who might not",
    "start": "2758980",
    "end": "2765339"
  },
  {
    "text": "be aware so a head-based sampling is essentially when you get the like when you generate the first Span in your",
    "start": "2765339",
    "end": "2771040"
  },
  {
    "text": "Trace you might want to say oh this is coming from the IP that is always causing the issue right so you could say",
    "start": "2771040",
    "end": "2776560"
  },
  {
    "text": "I want that specific um span I want that trace and all the spans connected with it so when you",
    "start": "2776560",
    "end": "2783099"
  },
  {
    "text": "create the first span you decide do I want to use it or drop it tail-based sampling is very different in the sense",
    "start": "2783099",
    "end": "2789400"
  },
  {
    "text": "that it is done at the end of your processing and you can say I'm going to use let's say one percent of all my data",
    "start": "2789400",
    "end": "2795579"
  },
  {
    "text": "right but so you might not have a lot of information like what is the the most",
    "start": "2795579",
    "end": "2800980"
  },
  {
    "text": "interesting one yeah maybe having one percent five percent might make use or might make sense to you",
    "start": "2800980",
    "end": "2806920"
  },
  {
    "text": "um batching for example in the in the example that I was showing we do collection on your cluster but we want",
    "start": "2806920",
    "end": "2812859"
  },
  {
    "text": "to process the data in our cluster because you know the setting up ML is not that easy you know talking from",
    "start": "2812859",
    "end": "2818980"
  },
  {
    "text": "experience kubeflow and so on you want to have in the cloud shared across different clusters and so uploading data",
    "start": "2818980",
    "end": "2825640"
  },
  {
    "text": "could be an issue right so you could say well maybe it's just too much or I need to batch it so the open Telemetry",
    "start": "2825640",
    "end": "2832480"
  },
  {
    "text": "collector has this this concept of batching prior to filtering so you can do so many cool things by understanding",
    "start": "2832480",
    "end": "2838060"
  },
  {
    "text": "how they work so certainly when it comes to volumes always think about batching sampling what is your sample strategy",
    "start": "2838060",
    "end": "2844359"
  },
  {
    "text": "and so on right so that's quite interesting the other thing that because you said you know like are we talking open Telemetry metrics are we talking",
    "start": "2844359",
    "end": "2850660"
  },
  {
    "text": "pixie um and please you guys keep me honest here but I want to say that pixie has",
    "start": "2850660",
    "end": "2856119"
  },
  {
    "text": "this really really neat solution that it's actually not something that you install in your cluster and starts to",
    "start": "2856119",
    "end": "2861940"
  },
  {
    "text": "stream data to your backend because can you imagine the volume of traffic that we would receive right so the idea of",
    "start": "2861940",
    "end": "2867700"
  },
  {
    "text": "Pixie is that it captures data stores it locally and then you can from the portal",
    "start": "2867700",
    "end": "2873339"
  },
  {
    "text": "go down into the into the bigger solution and say Hey I want the HTTP request of the last five seconds right",
    "start": "2873339",
    "end": "2879819"
  },
  {
    "text": "so you on demand go and say what is the data that I need and that is a very very scalable solution right it's actually",
    "start": "2879819",
    "end": "2886240"
  },
  {
    "text": "very similar conceptually to what I was talking about with Prometheus where you don't want everybody spamming you at all",
    "start": "2886240",
    "end": "2891940"
  },
  {
    "text": "times you want to be in control I think this is something you know if you think about the architecture forward looking always keep that in mind where are the",
    "start": "2891940",
    "end": "2898480"
  },
  {
    "text": "choke points is maybe the pushing the issue so you can turn it around to be pool based where do I do filtering",
    "start": "2898480",
    "end": "2904540"
  },
  {
    "text": "batching and just with Peaks as well right maybe you do on-demand access so there's you know a lot of these",
    "start": "2904540",
    "end": "2911760"
  },
  {
    "text": "conceptual problems that if you didn't think them up front you'll have a very",
    "start": "2911760",
    "end": "2916960"
  },
  {
    "text": "hard time solving them right but if you think up front we say oh I want a collector that is able to filter later",
    "start": "2916960",
    "end": "2922000"
  },
  {
    "text": "and maybe today it literally copies 100 of the inputs into 100 of outputs but you know on that Saturday morning 3 A.M",
    "start": "2922000",
    "end": "2928599"
  },
  {
    "text": "when your buzzer goes off that you have too much data coming in that will come in very handy to just change one line in",
    "start": "2928599",
    "end": "2934839"
  },
  {
    "text": "your logger and everything works better right okay there was a lot of information but yeah answer your",
    "start": "2934839",
    "end": "2941319"
  },
  {
    "text": "question no my question was actually uh you know a complex one I understand there's no one answer but where I was",
    "start": "2941319",
    "end": "2948760"
  },
  {
    "text": "coming from is the route we want to get to the root cause and most of the time this information is just using up space",
    "start": "2948760",
    "end": "2954460"
  },
  {
    "text": "and costing we want to be able to use these filters ideally at the time of",
    "start": "2954460",
    "end": "2960400"
  },
  {
    "text": "production consume it not store it just store the analytics massage the data get what you",
    "start": "2960400",
    "end": "2967420"
  },
  {
    "text": "want as you say which is you answered my question which is great but so filters and a bit of you know bit of custom",
    "start": "2967420",
    "end": "2973720"
  },
  {
    "text": "development maybe and and then we can get the extract that out and what's useful for us it's all great but it's",
    "start": "2973720",
    "end": "2981520"
  },
  {
    "text": "the cost is always for us is a big issue so I'll be happy to give it a go 100 but",
    "start": "2981520",
    "end": "2987400"
  },
  {
    "text": "I think really what you want I mean is exactly what you said right you want to stream up the relevant information so",
    "start": "2987400",
    "end": "2992500"
  },
  {
    "text": "let's say a metric that will wake you up at 3am because you just have to and then maybe have something like pixie that",
    "start": "2992500",
    "end": "2998500"
  },
  {
    "text": "says all right something is so wrong go filter go deep and on demand and I think pixie just its architecture allows you",
    "start": "2998500",
    "end": "3004859"
  },
  {
    "text": "to do exactly that it's an incredibly powerful Solution that's smashing thank you very much thank you",
    "start": "3004859",
    "end": "3011220"
  },
  {
    "text": "there's a question up front maybe you just want to use the microphone right next to you so Hannah doesn't have to run around on",
    "start": "3011220",
    "end": "3017160"
  },
  {
    "text": "hello um do you think it's a good idea that showing clear text of a data that should",
    "start": "3017160",
    "end": "3024480"
  },
  {
    "text": "be encrypted because yeah with ebpf we know that we can do it but should we do",
    "start": "3024480",
    "end": "3030720"
  },
  {
    "text": "it is an ethical question do you want to take it sure uh yeah this",
    "start": "3030720",
    "end": "3036599"
  },
  {
    "text": "is this is a great question and something that people are always concerned about uh especially when you",
    "start": "3036599",
    "end": "3041819"
  },
  {
    "text": "know you demo off something that says hey we can look at the clear text Data even if you use mtls encryption so we",
    "start": "3041819",
    "end": "3049140"
  },
  {
    "text": "think about it in two different a couple of different ways one of the things that pixie does to sort of address the risk",
    "start": "3049140",
    "end": "3055319"
  },
  {
    "text": "of having clear Text data is the fact that it the data that pixie collects is",
    "start": "3055319",
    "end": "3061140"
  },
  {
    "text": "stored only in memory within your cluster it doesn't really leave your cluster when you query Pixi for the data",
    "start": "3061140",
    "end": "3068420"
  },
  {
    "text": "whatever querying you're doing once it's filtered and aggregated that final",
    "start": "3068420",
    "end": "3073440"
  },
  {
    "text": "result does does you know get sent to the client but that connection is also end-to-end encrypted",
    "start": "3073440",
    "end": "3080059"
  },
  {
    "text": "however eventually the the answer is like you know you need to sort of evaluate the usefulness of that data",
    "start": "3080059",
    "end": "3086760"
  },
  {
    "text": "Pixi does offer some tools to sort of like try to detect and strip out pii",
    "start": "3086760",
    "end": "3091980"
  },
  {
    "text": "from such kind of data so eventually you have to weigh out weigh the pros and cons of being able to get that data and",
    "start": "3091980",
    "end": "3098819"
  },
  {
    "text": "then you know maybe you don't want to use that uh clear Text data and you want to strip out the pi to try to say hey I",
    "start": "3098819",
    "end": "3105420"
  },
  {
    "text": "want all of the other metrics maybe you want flame graphs and stuff like that but you don't care about the network traffic",
    "start": "3105420",
    "end": "3112520"
  },
  {
    "text": "hello question about Pixie I'm not that familiar with EPF as as in not in the",
    "start": "3115500",
    "end": "3122099"
  },
  {
    "text": "use case that you showed here you showed a nice Trace graphs yeah and do you have",
    "start": "3122099",
    "end": "3127319"
  },
  {
    "text": "experience with multiple programming languages how it could help because as I",
    "start": "3127319",
    "end": "3132359"
  },
  {
    "text": "said I show it to my developers and they can even debug the optimization problems",
    "start": "3132359",
    "end": "3137640"
  },
  {
    "text": "with the application seeing what times what call spend or yeah longest but",
    "start": "3137640",
    "end": "3144000"
  },
  {
    "text": "there are dividual machines or like virtual machines python interpreters and sometimes those trade scores don't go",
    "start": "3144000",
    "end": "3149640"
  },
  {
    "text": "that deep so what's your experience and in what language is it helpful",
    "start": "3149640",
    "end": "3157020"
  },
  {
    "text": "yeah I can talk about what sort of uh Pixie can support and maybe if you have experience using it you can talk about",
    "start": "3157020",
    "end": "3163319"
  },
  {
    "text": "how you've used it uh so out of the box of course uh compiled languages are very",
    "start": "3163319",
    "end": "3168960"
  },
  {
    "text": "easy uh so as long as you have symbols in your binaries uh C C plus plus rust",
    "start": "3168960",
    "end": "3174480"
  },
  {
    "text": "and go that stuff is very simple to do for uh interpreted languages or",
    "start": "3174480",
    "end": "3179700"
  },
  {
    "text": "languages with with a VM as you said like things get challenging um so we do have an a solution for Java",
    "start": "3179700",
    "end": "3187260"
  },
  {
    "text": "where we use a agent to actually get flame graphs for Java binaries too and",
    "start": "3187260",
    "end": "3193680"
  },
  {
    "text": "we are currently investigating what we can do from a node.js perspective but you know given that the kubernetes",
    "start": "3193680",
    "end": "3199740"
  },
  {
    "text": "ecosystem has been heavily invested and like uses a lot of go tooling I think it",
    "start": "3199740",
    "end": "3205319"
  },
  {
    "text": "really sort of works very well with the fact that most of the tooling that you use in kubernetes is written in go",
    "start": "3205319",
    "end": "3211020"
  },
  {
    "text": "symbols are typically included in the binaries that are shipped so uh at least within pixie when we have needed to",
    "start": "3211020",
    "end": "3217800"
  },
  {
    "text": "debug production systems the flame graphs have been super useful what's up yeah",
    "start": "3217800",
    "end": "3223619"
  },
  {
    "text": "just to add to this I think the yesterday was an awesome excellent talk just specifically around ebpf how do you",
    "start": "3223619",
    "end": "3229319"
  },
  {
    "text": "stack walking things that you can do even in you know interpreted languages and stuff like this so please if you",
    "start": "3229319",
    "end": "3235079"
  },
  {
    "text": "haven't seen that one um that would be interesting um the cool thing though is Pixie and",
    "start": "3235079",
    "end": "3240780"
  },
  {
    "text": "ebpf more generally right it allows you to capture data on multiple levels so I understand of course that you know maybe",
    "start": "3240780",
    "end": "3246780"
  },
  {
    "text": "the flame graphs might not be as complete in a Java or python application as in a c application but just as the",
    "start": "3246780",
    "end": "3254160"
  },
  {
    "text": "fact that we capture on a user mode as well as on a kernel mode level gives us a ton of visibility right if you think",
    "start": "3254160",
    "end": "3260040"
  },
  {
    "text": "about networking how are you going to send a network request without going through the kernel right and that's just the beauty of these these kernel mode",
    "start": "3260040",
    "end": "3267240"
  },
  {
    "text": "probes and in our project for instance we actually mostly use kernel data because from there you can capture which",
    "start": "3267240",
    "end": "3275579"
  },
  {
    "text": "process is talking what other process pixie does this beautiful magic of resolving not only processes but you",
    "start": "3275579",
    "end": "3281099"
  },
  {
    "text": "know which pod in what or like which container in which part in which namespace is talking to what other other",
    "start": "3281099",
    "end": "3286500"
  },
  {
    "text": "process on a different node automatically resolves that for you and then by going deep into the payload",
    "start": "3286500",
    "end": "3292319"
  },
  {
    "text": "right it parses HTTP for you for instance right it supports several several other protocols Network",
    "start": "3292319",
    "end": "3298319"
  },
  {
    "text": "protocols you get a ton of visibility just by using the the kernel mode instrumentation and then yes your you",
    "start": "3298319",
    "end": "3305460"
  },
  {
    "text": "know mileage may vary for user mode hooks might just not be supported for your application for your library for",
    "start": "3305460",
    "end": "3310859"
  },
  {
    "text": "your program online language but just on the mere system level you get so much Telemetry that allows you to be like",
    "start": "3310859",
    "end": "3317579"
  },
  {
    "text": "most of the things that you will use or need for like finding the core of an issue but you're right it may vary",
    "start": "3317579",
    "end": "3324540"
  },
  {
    "text": "depending on your use case thank you for a very complete answer",
    "start": "3324540",
    "end": "3329420"
  },
  {
    "text": "any other questions in the room",
    "start": "3330359",
    "end": "3333680"
  },
  {
    "text": "all right I guess yeah we'll continue to hang out here for anyone who's following through the guide",
    "start": "3337020",
    "end": "3342059"
  },
  {
    "text": "uh so just kind of raise your hand wave one of us down and we can help you if you run into any issues",
    "start": "3342059",
    "end": "3348839"
  },
  {
    "text": "and if if not thank you for all the others for attending and please do reach out on the slack channels that we were",
    "start": "3348839",
    "end": "3354599"
  },
  {
    "text": "pointing out thank you",
    "start": "3354599",
    "end": "3358040"
  }
]
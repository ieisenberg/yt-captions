[
  {
    "text": "welcome to my talk on for the Dapper Day",
    "start": "560",
    "end": "3560"
  },
  {
    "text": "this presentation will talk about how my",
    "start": "3560",
    "end": "5600"
  },
  {
    "text": "team is able to process a ton of data",
    "start": "5600",
    "end": "8120"
  },
  {
    "text": "points daily using",
    "start": "8120",
    "end": "11040"
  },
  {
    "text": "Dapper before we Deep dive a little bit",
    "start": "11040",
    "end": "13719"
  },
  {
    "text": "about myself my name is Sira vaju",
    "start": "13719",
    "end": "16480"
  },
  {
    "text": "currently a software engineer in",
    "start": "16480",
    "end": "17920"
  },
  {
    "text": "Microsoft I'm a freelance contributor",
    "start": "17920",
    "end": "20480"
  },
  {
    "text": "and love hiking as well this is my",
    "start": "20480",
    "end": "22760"
  },
  {
    "text": "LinkedIn and email please feel free to",
    "start": "22760",
    "end": "24640"
  },
  {
    "text": "reach out to me if you have any",
    "start": "24640",
    "end": "26439"
  },
  {
    "text": "questions or suggestions regarding the",
    "start": "26439",
    "end": "28080"
  },
  {
    "text": "talk or if you want to talk about Apper",
    "start": "28080",
    "end": "30039"
  },
  {
    "text": "in",
    "start": "30039",
    "end": "31960"
  },
  {
    "text": "general coming to the agenda we'll first",
    "start": "31960",
    "end": "34680"
  },
  {
    "text": "talk about the business problem we are",
    "start": "34680",
    "end": "36120"
  },
  {
    "text": "trying to solve then we look at the",
    "start": "36120",
    "end": "38960"
  },
  {
    "text": "architecture we had before Dapper what",
    "start": "38960",
    "end": "41320"
  },
  {
    "text": "did the infrastructure look like and",
    "start": "41320",
    "end": "43039"
  },
  {
    "text": "what were the complexities we were",
    "start": "43039",
    "end": "44559"
  },
  {
    "text": "running into and why we were looking",
    "start": "44559",
    "end": "46840"
  },
  {
    "text": "outside then we'll look at a bit of",
    "start": "46840",
    "end": "49960"
  },
  {
    "text": "overview of dapper and then we'll talk",
    "start": "49960",
    "end": "52600"
  },
  {
    "text": "about how Dapper changed our",
    "start": "52600",
    "end": "54359"
  },
  {
    "text": "architecture what our infrastructure",
    "start": "54359",
    "end": "56399"
  },
  {
    "text": "looks like right now and then uh how it",
    "start": "56399",
    "end": "60239"
  },
  {
    "text": "simplified some of the processes then we",
    "start": "60239",
    "end": "63519"
  },
  {
    "text": "look at what are this what are the",
    "start": "63519",
    "end": "65680"
  },
  {
    "text": "things we learned as part of D Dapper",
    "start": "65680",
    "end": "67640"
  },
  {
    "text": "migration what are the gas we ran into",
    "start": "67640",
    "end": "70799"
  },
  {
    "text": "and what are the subtle nuances we had",
    "start": "70799",
    "end": "73640"
  },
  {
    "text": "to be we had to keep in mind when",
    "start": "73640",
    "end": "76439"
  },
  {
    "text": "working with Dapper finally we'll talk",
    "start": "76439",
    "end": "79799"
  },
  {
    "text": "about what's next for us we have started",
    "start": "79799",
    "end": "81960"
  },
  {
    "text": "with one building block how do we plan",
    "start": "81960",
    "end": "83759"
  },
  {
    "text": "to incorporate some of the other",
    "start": "83759",
    "end": "85240"
  },
  {
    "text": "building block the",
    "start": "85240",
    "end": "87640"
  },
  {
    "text": "Dapper provides us and make our",
    "start": "87640",
    "end": "90520"
  },
  {
    "text": "architecture more",
    "start": "90520",
    "end": "91920"
  },
  {
    "text": "resilient and then we'll conclude the",
    "start": "91920",
    "end": "96078"
  },
  {
    "text": "talk so coming to the problem statement",
    "start": "96360",
    "end": "99320"
  },
  {
    "text": "my team at Azure is responsible for",
    "start": "99320",
    "end": "102399"
  },
  {
    "text": "protecting net protecting Azure",
    "start": "102399",
    "end": "105320"
  },
  {
    "text": "workloads from Network related threats",
    "start": "105320",
    "end": "108159"
  },
  {
    "text": "and how we do that is by provide is by",
    "start": "108159",
    "end": "111240"
  },
  {
    "text": "recommending secure rules to our",
    "start": "111240",
    "end": "113560"
  },
  {
    "text": "customers so that once they apply it",
    "start": "113560",
    "end": "116560"
  },
  {
    "text": "their infrastructure starts becoming",
    "start": "116560",
    "end": "118799"
  },
  {
    "text": "resilient to any network based attacks",
    "start": "118799",
    "end": "122240"
  },
  {
    "text": "now what do I mean by rules and",
    "start": "122240",
    "end": "124439"
  },
  {
    "text": "recommendations let's take let's take a",
    "start": "124439",
    "end": "126719"
  },
  {
    "text": "small example to explain",
    "start": "126719",
    "end": "130360"
  },
  {
    "text": "this many of us who are working on Azure",
    "start": "130840",
    "end": "134000"
  },
  {
    "text": "have familiarity with virtual Network it",
    "start": "134000",
    "end": "137000"
  },
  {
    "text": "is basically how you control your",
    "start": "137000",
    "end": "139680"
  },
  {
    "text": "traffic to the services behind it for",
    "start": "139680",
    "end": "142519"
  },
  {
    "text": "example in this case I have an app",
    "start": "142519",
    "end": "144239"
  },
  {
    "text": "service and have a virtual machine and",
    "start": "144239",
    "end": "147239"
  },
  {
    "text": "if I want to control what traffic gets",
    "start": "147239",
    "end": "150239"
  },
  {
    "text": "into my virtual machine or app service I",
    "start": "150239",
    "end": "153000"
  },
  {
    "text": "can apply rules at my vet the the rules",
    "start": "153000",
    "end": "156480"
  },
  {
    "text": "here can be your Ingress or regress",
    "start": "156480",
    "end": "158280"
  },
  {
    "text": "rules and the vnet would only allow",
    "start": "158280",
    "end": "161680"
  },
  {
    "text": "anything that is compliant with those",
    "start": "161680",
    "end": "163840"
  },
  {
    "text": "rules and block the rest of",
    "start": "163840",
    "end": "166400"
  },
  {
    "text": "them the snippet what you see on the",
    "start": "166400",
    "end": "169080"
  },
  {
    "text": "right is basically an example of one",
    "start": "169080",
    "end": "171400"
  },
  {
    "text": "suchar rule where we are allowing any",
    "start": "171400",
    "end": "174920"
  },
  {
    "text": "traffic on any port to communicate to",
    "start": "174920",
    "end": "177599"
  },
  {
    "text": "the back end of course this is broad but",
    "start": "177599",
    "end": "181519"
  },
  {
    "text": "the rules that are applied on Broad are",
    "start": "181519",
    "end": "183400"
  },
  {
    "text": "more stringent now in order to even",
    "start": "183400",
    "end": "187280"
  },
  {
    "text": "apply these rules we have to understand",
    "start": "187280",
    "end": "190040"
  },
  {
    "text": "the team's Network",
    "start": "190040",
    "end": "191440"
  },
  {
    "text": "topology and when I say Network",
    "start": "191440",
    "end": "194080"
  },
  {
    "text": "topology what kind of rule what kind of",
    "start": "194080",
    "end": "197319"
  },
  {
    "text": "uh systems the team is talking to and",
    "start": "197319",
    "end": "200080"
  },
  {
    "text": "then what kind of services they are",
    "start": "200080",
    "end": "201920"
  },
  {
    "text": "depend on are they talking to internet",
    "start": "201920",
    "end": "204480"
  },
  {
    "text": "and so on and in order to process this",
    "start": "204480",
    "end": "207400"
  },
  {
    "text": "network topology we further have have to",
    "start": "207400",
    "end": "211360"
  },
  {
    "text": "process millions of events daily which",
    "start": "211360",
    "end": "214319"
  },
  {
    "text": "will enrich the network",
    "start": "214319",
    "end": "216799"
  },
  {
    "text": "topology so to summarize we want to",
    "start": "216799",
    "end": "220799"
  },
  {
    "text": "protect Azure worklow from Network",
    "start": "220799",
    "end": "222599"
  },
  {
    "text": "threats by processing millions of",
    "start": "222599",
    "end": "224519"
  },
  {
    "text": "network events",
    "start": "224519",
    "end": "226000"
  },
  {
    "text": "daily and showing the teams their",
    "start": "226000",
    "end": "228560"
  },
  {
    "text": "Network",
    "start": "228560",
    "end": "229720"
  },
  {
    "text": "topology this is what we want to",
    "start": "229720",
    "end": "232480"
  },
  {
    "text": "solve now let's look at the architecture",
    "start": "232480",
    "end": "235239"
  },
  {
    "text": "we had before",
    "start": "235239",
    "end": "236560"
  },
  {
    "text": "Dapper what you see on the left is the",
    "start": "236560",
    "end": "239079"
  },
  {
    "text": "source data store the millions of Agents",
    "start": "239079",
    "end": "242439"
  },
  {
    "text": "sitting on the virtual machine send data",
    "start": "242439",
    "end": "245159"
  },
  {
    "text": "to the source data store with all the",
    "start": "245159",
    "end": "247959"
  },
  {
    "text": "network network Telemetry sets now the",
    "start": "247959",
    "end": "251239"
  },
  {
    "text": "St data store is blob storage which is",
    "start": "251239",
    "end": "254480"
  },
  {
    "text": "part which has data partition on an",
    "start": "254480",
    "end": "256400"
  },
  {
    "text": "hourly",
    "start": "256400",
    "end": "257639"
  },
  {
    "text": "basis what the injection engine does is",
    "start": "257639",
    "end": "260919"
  },
  {
    "text": "because the data is partitioned on an",
    "start": "260919",
    "end": "262520"
  },
  {
    "text": "hourly basis and each day has 24 hours",
    "start": "262520",
    "end": "266120"
  },
  {
    "text": "it puts 24 markers into the cube and",
    "start": "266120",
    "end": "269560"
  },
  {
    "text": "then then the aggregation infrastructure",
    "start": "269560",
    "end": "271639"
  },
  {
    "text": "pulls the marker from the queue goes to",
    "start": "271639",
    "end": "274199"
  },
  {
    "text": "the corresponding partition in the blob",
    "start": "274199",
    "end": "276479"
  },
  {
    "text": "store starts downloading each file and",
    "start": "276479",
    "end": "279759"
  },
  {
    "text": "once it downloads the files it enriches",
    "start": "279759",
    "end": "282240"
  },
  {
    "text": "it with some metadata and puts it into",
    "start": "282240",
    "end": "284919"
  },
  {
    "text": "the destination data",
    "start": "284919",
    "end": "286680"
  },
  {
    "text": "store and then we have an API sitting on",
    "start": "286680",
    "end": "289800"
  },
  {
    "text": "the destination data store that would",
    "start": "289800",
    "end": "291440"
  },
  {
    "text": "expose the network topology to the",
    "start": "291440",
    "end": "295240"
  },
  {
    "text": "users a quick summary so there's a",
    "start": "295240",
    "end": "297759"
  },
  {
    "text": "source data store which has all the",
    "start": "297759",
    "end": "299360"
  },
  {
    "text": "network teret data which is partitioned",
    "start": "299360",
    "end": "302039"
  },
  {
    "text": "on a hourly basis per day the injection",
    "start": "302039",
    "end": "305960"
  },
  {
    "text": "marker puts the puts the hourly markers",
    "start": "305960",
    "end": "310199"
  },
  {
    "text": "into the queue the aggregation data",
    "start": "310199",
    "end": "312560"
  },
  {
    "text": "store pulls the files from the partition",
    "start": "312560",
    "end": "316120"
  },
  {
    "text": "under the source data store enriches it",
    "start": "316120",
    "end": "318479"
  },
  {
    "text": "with metadata and puts it into the",
    "start": "318479",
    "end": "320720"
  },
  {
    "text": "destination data store for the apis to",
    "start": "320720",
    "end": "324840"
  },
  {
    "text": "consum now to understand the problem a",
    "start": "324840",
    "end": "327759"
  },
  {
    "text": "bit more let's look at what aggregation",
    "start": "327759",
    "end": "330520"
  },
  {
    "text": "engine here",
    "start": "330520",
    "end": "333479"
  },
  {
    "text": "does coming to the aggregation engine",
    "start": "334880",
    "end": "337800"
  },
  {
    "text": "once it pulls the record the first thing",
    "start": "337800",
    "end": "340880"
  },
  {
    "text": "that it does is it fetches the number of",
    "start": "340880",
    "end": "343360"
  },
  {
    "text": "files under the",
    "start": "343360",
    "end": "345080"
  },
  {
    "text": "partition second it fetches from which",
    "start": "345080",
    "end": "349400"
  },
  {
    "text": "file it has to resume processing for",
    "start": "349400",
    "end": "351360"
  },
  {
    "text": "example let's say there are 10 or 15",
    "start": "351360",
    "end": "353400"
  },
  {
    "text": "files under partition and I have to",
    "start": "353400",
    "end": "355560"
  },
  {
    "text": "start processing from the sixth file it",
    "start": "355560",
    "end": "358360"
  },
  {
    "text": "gives me that information",
    "start": "358360",
    "end": "360440"
  },
  {
    "text": "then I also do a aggregation at the VM",
    "start": "360440",
    "end": "364360"
  },
  {
    "text": "level so this file contains Telemetry",
    "start": "364360",
    "end": "368479"
  },
  {
    "text": "data of maybe 10 or 20,000 rows and each",
    "start": "368479",
    "end": "372039"
  },
  {
    "text": "rows represent a VM I aggregate the data",
    "start": "372039",
    "end": "375759"
  },
  {
    "text": "at the VM level and for each",
    "start": "375759",
    "end": "380360"
  },
  {
    "text": "VM we get this uh VM metod data which",
    "start": "380360",
    "end": "385039"
  },
  {
    "text": "talks about which service this VM",
    "start": "385039",
    "end": "387919"
  },
  {
    "text": "belongs to then we get get the service",
    "start": "387919",
    "end": "391639"
  },
  {
    "text": "details which which tell me if the",
    "start": "391639",
    "end": "394440"
  },
  {
    "text": "service is praud or non fraud if the",
    "start": "394440",
    "end": "397160"
  },
  {
    "text": "service is go or public Cloud because",
    "start": "397160",
    "end": "400319"
  },
  {
    "text": "rules change depending on this and then",
    "start": "400319",
    "end": "403599"
  },
  {
    "text": "we ingest that information into the",
    "start": "403599",
    "end": "406680"
  },
  {
    "text": "destination data",
    "start": "406680",
    "end": "408639"
  },
  {
    "text": "store now I told you the source file",
    "start": "408639",
    "end": "412479"
  },
  {
    "text": "itself has around 20,000 R and after",
    "start": "412479",
    "end": "415360"
  },
  {
    "text": "aggregating at the VM level there might",
    "start": "415360",
    "end": "418120"
  },
  {
    "text": "be 8 to 9,000 VMS right let's imagine",
    "start": "418120",
    "end": "423160"
  },
  {
    "text": "the Pod dies after processing four or",
    "start": "423160",
    "end": "426000"
  },
  {
    "text": "5,000 VMS right so we have done the",
    "start": "426000",
    "end": "429479"
  },
  {
    "text": "fetch metadata calls for four or 5,000",
    "start": "429479",
    "end": "431720"
  },
  {
    "text": "VMS and then the Pod",
    "start": "431720",
    "end": "433919"
  },
  {
    "text": "dice now when I restart the",
    "start": "433919",
    "end": "437759"
  },
  {
    "text": "process I again restart from the zero at",
    "start": "437759",
    "end": "441919"
  },
  {
    "text": "VM again this is the problem we had so",
    "start": "441919",
    "end": "444759"
  },
  {
    "text": "because we were starting at the zero PM",
    "start": "444759",
    "end": "447039"
  },
  {
    "text": "again again we had to process all all",
    "start": "447039",
    "end": "449800"
  },
  {
    "text": "the API calls for all the 8,000",
    "start": "449800",
    "end": "452680"
  },
  {
    "text": "VMS now as the system is growing we saw",
    "start": "452680",
    "end": "458080"
  },
  {
    "text": "that 20 to 30% of our Network calls",
    "start": "458080",
    "end": "461520"
  },
  {
    "text": "attribute to this duplicate",
    "start": "461520",
    "end": "466199"
  },
  {
    "text": "processing we wanted to reduce that that",
    "start": "466199",
    "end": "468879"
  },
  {
    "text": "is the first thing",
    "start": "468879",
    "end": "472080"
  },
  {
    "text": "second what we see here are the three",
    "start": "472080",
    "end": "475319"
  },
  {
    "text": "steps fetch metadata fetch service",
    "start": "475319",
    "end": "477400"
  },
  {
    "text": "detail and inje now now even though",
    "start": "477400",
    "end": "480599"
  },
  {
    "text": "these are three steps for us they belong",
    "start": "480599",
    "end": "482720"
  },
  {
    "text": "to one Atomic unit that means even if",
    "start": "482720",
    "end": "485400"
  },
  {
    "text": "one of the step fails we end up",
    "start": "485400",
    "end": "489199"
  },
  {
    "text": "restarting from the fetch metadata Cate",
    "start": "489199",
    "end": "492960"
  },
  {
    "text": "again there are redundancies here as",
    "start": "492960",
    "end": "495440"
  },
  {
    "text": "well and if you are able to reduce it",
    "start": "495440",
    "end": "498120"
  },
  {
    "text": "down the advantage we would achieve is",
    "start": "498120",
    "end": "501400"
  },
  {
    "text": "we are able to boil down the 20 to 30%",
    "start": "501400",
    "end": "505199"
  },
  {
    "text": "calls we were seeing and then also",
    "start": "505199",
    "end": "508599"
  },
  {
    "text": "increase the efficiency and delays in",
    "start": "508599",
    "end": "511000"
  },
  {
    "text": "the",
    "start": "511000",
    "end": "512240"
  },
  {
    "text": "system so to summarize two problems one",
    "start": "512240",
    "end": "516120"
  },
  {
    "text": "because we were not resuming from where",
    "start": "516120",
    "end": "521039"
  },
  {
    "text": "we",
    "start": "521039",
    "end": "522080"
  },
  {
    "text": "failed we were running",
    "start": "522080",
    "end": "524680"
  },
  {
    "text": "into uh we were running into a lot of",
    "start": "524680",
    "end": "527240"
  },
  {
    "text": "duplicate processing second each of our",
    "start": "527240",
    "end": "530120"
  },
  {
    "text": "workflow also does not resume from from",
    "start": "530120",
    "end": "534320"
  },
  {
    "text": "the failure point so these are the two",
    "start": "534320",
    "end": "536240"
  },
  {
    "text": "problems we run",
    "start": "536240",
    "end": "537560"
  },
  {
    "text": "into now the first thing thing that",
    "start": "537560",
    "end": "540120"
  },
  {
    "text": "comes into my mind to solve this is what",
    "start": "540120",
    "end": "543079"
  },
  {
    "text": "if you are able to resume at that",
    "start": "543079",
    "end": "545079"
  },
  {
    "text": "particular VMV fail for example let's",
    "start": "545079",
    "end": "547440"
  },
  {
    "text": "say we have processed the 2,000 VMS and",
    "start": "547440",
    "end": "550519"
  },
  {
    "text": "if we are able to resume processing from",
    "start": "550519",
    "end": "553519"
  },
  {
    "text": "the 2001 VM we save all these 3 calls",
    "start": "553519",
    "end": "560160"
  },
  {
    "text": "and that is where we were looking for",
    "start": "560160",
    "end": "562959"
  },
  {
    "text": "some",
    "start": "562959",
    "end": "563839"
  },
  {
    "text": "solutions now building such a",
    "start": "563839",
    "end": "567519"
  },
  {
    "text": "checkpointing or a state management",
    "start": "567519",
    "end": "569680"
  },
  {
    "text": "system is not easy",
    "start": "569680",
    "end": "573320"
  },
  {
    "text": "because what would that involve is I",
    "start": "573320",
    "end": "576399"
  },
  {
    "text": "would have to determine what the state",
    "start": "576399",
    "end": "579440"
  },
  {
    "text": "management schema would look like I",
    "start": "579440",
    "end": "582240"
  },
  {
    "text": "would have to determine the data store I",
    "start": "582240",
    "end": "585040"
  },
  {
    "text": "uh data store I have to use and then",
    "start": "585040",
    "end": "588560"
  },
  {
    "text": "transactions uh how would roll backs be",
    "start": "588560",
    "end": "591279"
  },
  {
    "text": "there and then uh",
    "start": "591279",
    "end": "593800"
  },
  {
    "text": "observability so building a state",
    "start": "593800",
    "end": "596079"
  },
  {
    "text": "management engine and maintaining it is",
    "start": "596079",
    "end": "600519"
  },
  {
    "text": "a multi-on effort and also it's an",
    "start": "600519",
    "end": "603120"
  },
  {
    "text": "additional operational",
    "start": "603120",
    "end": "605040"
  },
  {
    "text": "constraint what we were looking for is",
    "start": "605040",
    "end": "607640"
  },
  {
    "text": "are there any existing outof thee box",
    "start": "607640",
    "end": "609680"
  },
  {
    "text": "solutions that give us these management",
    "start": "609680",
    "end": "613480"
  },
  {
    "text": "capabilities second what we also were",
    "start": "613480",
    "end": "616200"
  },
  {
    "text": "looking for is because we are already",
    "start": "616200",
    "end": "618600"
  },
  {
    "text": "running on AKs kubernetes are there any",
    "start": "618600",
    "end": "622279"
  },
  {
    "text": "out of the box solutions that come",
    "start": "622279",
    "end": "625000"
  },
  {
    "text": "support with the kubernetes",
    "start": "625000",
    "end": "627440"
  },
  {
    "text": "environment these are the two two",
    "start": "627440",
    "end": "629839"
  },
  {
    "text": "requirements we",
    "start": "629839",
    "end": "631360"
  },
  {
    "text": "had and when we started researching that",
    "start": "631360",
    "end": "634399"
  },
  {
    "text": "is when we found out specifically about",
    "start": "634399",
    "end": "637000"
  },
  {
    "text": "Dapper and then Dapper",
    "start": "637000",
    "end": "639600"
  },
  {
    "text": "workflows before we Deep dive into them",
    "start": "639600",
    "end": "642440"
  },
  {
    "text": "let's look at the actual infrastructure",
    "start": "642440",
    "end": "644360"
  },
  {
    "text": "we had before",
    "start": "644360",
    "end": "646680"
  },
  {
    "text": "Dapper",
    "start": "646680",
    "end": "648519"
  },
  {
    "text": "so here what we see is the uh AK all of",
    "start": "648519",
    "end": "652880"
  },
  {
    "text": "us all of our services deployed in AKs",
    "start": "652880",
    "end": "656839"
  },
  {
    "text": "and we have we use the a storage to",
    "start": "656839",
    "end": "660040"
  },
  {
    "text": "store our blob data and then the pods",
    "start": "660040",
    "end": "663480"
  },
  {
    "text": "start pulling in from the cues and then",
    "start": "663480",
    "end": "667680"
  },
  {
    "text": "goes to the actual storage to fetch the",
    "start": "667680",
    "end": "670360"
  },
  {
    "text": "or to download the",
    "start": "670360",
    "end": "672040"
  },
  {
    "text": "data next we have the metadata service",
    "start": "672040",
    "end": "676200"
  },
  {
    "text": "which gives us all the metadata required",
    "start": "676200",
    "end": "678399"
  },
  {
    "text": "and put the data into the Azure data",
    "start": "678399",
    "end": "680800"
  },
  {
    "text": "Explorer cluster finally I I also",
    "start": "680800",
    "end": "685120"
  },
  {
    "text": "mentioned we resume file processing from",
    "start": "685120",
    "end": "688519"
  },
  {
    "text": "the previous",
    "start": "688519",
    "end": "690120"
  },
  {
    "text": "uh we resume file processing that",
    "start": "690120",
    "end": "692000"
  },
  {
    "text": "metadata is stored in Cosmos TV and all",
    "start": "692000",
    "end": "695440"
  },
  {
    "text": "of this I authentication and then is",
    "start": "695440",
    "end": "699720"
  },
  {
    "text": "done to manage",
    "start": "699720",
    "end": "702519"
  },
  {
    "text": "identities before we Deep dive into how",
    "start": "703079",
    "end": "705760"
  },
  {
    "text": "Dapper workflow solves a problem a bit",
    "start": "705760",
    "end": "707560"
  },
  {
    "text": "of overview uh Dapper workflows as I",
    "start": "707560",
    "end": "710880"
  },
  {
    "text": "believe have three main components one",
    "start": "710880",
    "end": "712639"
  },
  {
    "text": "is the workflow SDK which you use as",
    "start": "712639",
    "end": "715200"
  },
  {
    "text": "part of your app to curate Dapper uh to",
    "start": "715200",
    "end": "720560"
  },
  {
    "text": "curate Dapper workflows and activities",
    "start": "720560",
    "end": "723360"
  },
  {
    "text": "then you have the Dapper side",
    "start": "723360",
    "end": "725480"
  },
  {
    "text": "card which your workflow SDK",
    "start": "725480",
    "end": "727880"
  },
  {
    "text": "communicates with and then the state",
    "start": "727880",
    "end": "730600"
  },
  {
    "text": "store and then the persistent store also",
    "start": "730600",
    "end": "733279"
  },
  {
    "text": "called the state store where the Dapper",
    "start": "733279",
    "end": "736000"
  },
  {
    "text": "workflow store all the state that",
    "start": "736000",
    "end": "738880"
  },
  {
    "text": "belongs to a particular",
    "start": "738880",
    "end": "741560"
  },
  {
    "text": "workflow now some of the constructs and",
    "start": "741560",
    "end": "744440"
  },
  {
    "text": "Dapper workflows so each workflow is",
    "start": "744440",
    "end": "748279"
  },
  {
    "text": "divided into work flow and activities",
    "start": "748279",
    "end": "750320"
  },
  {
    "text": "one workflow can have multiple",
    "start": "750320",
    "end": "752480"
  },
  {
    "text": "activities and how it achieves a",
    "start": "752480",
    "end": "756040"
  },
  {
    "text": "resuming state is through event sourcing",
    "start": "756040",
    "end": "759600"
  },
  {
    "text": "basically what instead of taking a",
    "start": "759600",
    "end": "761440"
  },
  {
    "text": "snapshot it maintains atend only history",
    "start": "761440",
    "end": "764440"
  },
  {
    "text": "log of events and when and the golden",
    "start": "764440",
    "end": "767880"
  },
  {
    "text": "keyword here is aate whenever you aate",
    "start": "767880",
    "end": "771240"
  },
  {
    "text": "an activity Dapper offloads all of the",
    "start": "771240",
    "end": "775600"
  },
  {
    "text": "uh history to the state store and once",
    "start": "775600",
    "end": "779600"
  },
  {
    "text": "the a task is complete it from the state",
    "start": "779600",
    "end": "784480"
  },
  {
    "text": "store it gets the history builds the",
    "start": "784480",
    "end": "787560"
  },
  {
    "text": "world and then starts",
    "start": "787560",
    "end": "790040"
  },
  {
    "text": "resuming that is what uh the workflows",
    "start": "790040",
    "end": "792760"
  },
  {
    "text": "do and coming to the patterns Dapper the",
    "start": "792760",
    "end": "796880"
  },
  {
    "text": "workflow patterns are multiple there is",
    "start": "796880",
    "end": "798800"
  },
  {
    "text": "fan out pattern where using task. venol",
    "start": "798800",
    "end": "803000"
  },
  {
    "text": "you can uh you can put out M you can",
    "start": "803000",
    "end": "807560"
  },
  {
    "text": "schedule multiple workflow same time or",
    "start": "807560",
    "end": "810480"
  },
  {
    "text": "task chaining where you have where you",
    "start": "810480",
    "end": "814399"
  },
  {
    "text": "run activities one after the",
    "start": "814399",
    "end": "817880"
  },
  {
    "text": "other so the golden thing that also",
    "start": "817880",
    "end": "820760"
  },
  {
    "text": "soled us was event sourcing because that",
    "start": "820760",
    "end": "823120"
  },
  {
    "text": "is what we were actually looking for",
    "start": "823120",
    "end": "825959"
  },
  {
    "text": "where we were able to resume from the",
    "start": "825959",
    "end": "829600"
  },
  {
    "text": "previous failure",
    "start": "829600",
    "end": "831000"
  },
  {
    "text": "point now let's look at how our previous",
    "start": "831000",
    "end": "836399"
  },
  {
    "text": "aggregation workflow changed once we",
    "start": "836399",
    "end": "839120"
  },
  {
    "text": "Incorporated",
    "start": "839120",
    "end": "841720"
  },
  {
    "text": "Dapper so we first started with",
    "start": "841800",
    "end": "845440"
  },
  {
    "text": "integrating Dapper with our aggregation",
    "start": "845440",
    "end": "847320"
  },
  {
    "text": "infrastructure because this is where",
    "start": "847320",
    "end": "848920"
  },
  {
    "text": "much of complexity is and we continue to",
    "start": "848920",
    "end": "852680"
  },
  {
    "text": "use Cosmos TV as our intermediate store",
    "start": "852680",
    "end": "856600"
  },
  {
    "text": "I think this is where we should have",
    "start": "856600",
    "end": "858360"
  },
  {
    "text": "done some more better I'll explain why",
    "start": "858360",
    "end": "861680"
  },
  {
    "text": "that is the",
    "start": "861680",
    "end": "864160"
  },
  {
    "text": "case so coming to the aggregator coming",
    "start": "864680",
    "end": "868600"
  },
  {
    "text": "to how the aggregator was itself",
    "start": "868600",
    "end": "871800"
  },
  {
    "text": "modified once we pull the",
    "start": "871800",
    "end": "874600"
  },
  {
    "text": "record we kick off a parent workflow now",
    "start": "874600",
    "end": "878440"
  },
  {
    "text": "the parent workflow the input to the",
    "start": "878440",
    "end": "880680"
  },
  {
    "text": "parent workflow is the partition uh it",
    "start": "880680",
    "end": "883360"
  },
  {
    "text": "has to process and",
    "start": "883360",
    "end": "887279"
  },
  {
    "text": "then there are two there are two",
    "start": "887279",
    "end": "889639"
  },
  {
    "text": "activities first first is the one that",
    "start": "889639",
    "end": "892440"
  },
  {
    "text": "down that gets the count of files under",
    "start": "892440",
    "end": "895199"
  },
  {
    "text": "the partition and the second is the one",
    "start": "895199",
    "end": "898639"
  },
  {
    "text": "that retrieves the previous state until",
    "start": "898639",
    "end": "901480"
  },
  {
    "text": "we have uh done the processing for this",
    "start": "901480",
    "end": "905000"
  },
  {
    "text": "we use the Dapper Save State API to uh",
    "start": "905000",
    "end": "910519"
  },
  {
    "text": "resume and sorry use the get State API",
    "start": "910519",
    "end": "914000"
  },
  {
    "text": "to get the state from where we have",
    "start": "914000",
    "end": "916920"
  },
  {
    "text": "processed",
    "start": "916920",
    "end": "918800"
  },
  {
    "text": "previously then we download the file do",
    "start": "918800",
    "end": "921839"
  },
  {
    "text": "the",
    "start": "921839",
    "end": "922519"
  },
  {
    "text": "aggregation here what we do is after we",
    "start": "922519",
    "end": "924959"
  },
  {
    "text": "do the aggregation remember we have",
    "start": "924959",
    "end": "926800"
  },
  {
    "text": "mentioned we do aggregation at the V",
    "start": "926800",
    "end": "929199"
  },
  {
    "text": "level that means there are 4,000 or",
    "start": "929199",
    "end": "931120"
  },
  {
    "text": "5,000 VMS for each of them we schedule a",
    "start": "931120",
    "end": "935600"
  },
  {
    "text": "child",
    "start": "935600",
    "end": "937399"
  },
  {
    "text": "workflow the child",
    "start": "937399",
    "end": "939519"
  },
  {
    "text": "workflow has three sub activities again",
    "start": "939519",
    "end": "942959"
  },
  {
    "text": "the first one fetches the metad data for",
    "start": "942959",
    "end": "945560"
  },
  {
    "text": "the VM second one the service",
    "start": "945560",
    "end": "948920"
  },
  {
    "text": "details",
    "start": "948920",
    "end": "950639"
  },
  {
    "text": "now for the",
    "start": "950639",
    "end": "952959"
  },
  {
    "text": "inje the input to the child workflow is",
    "start": "952959",
    "end": "955920"
  },
  {
    "text": "the aggregated data",
    "start": "955920",
    "end": "957920"
  },
  {
    "text": "itself so because the aggregated data is",
    "start": "957920",
    "end": "961319"
  },
  {
    "text": "present and all the metadata is present",
    "start": "961319",
    "end": "963920"
  },
  {
    "text": "we do the inje also in the child",
    "start": "963920",
    "end": "967000"
  },
  {
    "text": "workflow one more",
    "start": "967000",
    "end": "969199"
  },
  {
    "text": "benefit we receive uh with using child",
    "start": "969199",
    "end": "973279"
  },
  {
    "text": "workf flow is we are able to keep the",
    "start": "973279",
    "end": "976480"
  },
  {
    "text": "state uh the parent we are able to keep",
    "start": "976480",
    "end": "979759"
  },
  {
    "text": "the",
    "start": "979759",
    "end": "980600"
  },
  {
    "text": "history uh replay history for the parent",
    "start": "980600",
    "end": "983519"
  },
  {
    "text": "workflow pretty",
    "start": "983519",
    "end": "985279"
  },
  {
    "text": "low that is one advantage we had",
    "start": "985279",
    "end": "989720"
  },
  {
    "text": "and then finally once the child workflow",
    "start": "989720",
    "end": "992639"
  },
  {
    "text": "Returns what we also do is save the",
    "start": "992639",
    "end": "995440"
  },
  {
    "text": "progress we made into the save save the",
    "start": "995440",
    "end": "998279"
  },
  {
    "text": "progress we made into the state store",
    "start": "998279",
    "end": "1000920"
  },
  {
    "text": "using the Save State",
    "start": "1000920",
    "end": "1003639"
  },
  {
    "text": "API so a quick recap of what you have",
    "start": "1003639",
    "end": "1006319"
  },
  {
    "text": "discussed we have one parent workflow",
    "start": "1006319",
    "end": "1008839"
  },
  {
    "text": "the parent workflow has two activities",
    "start": "1008839",
    "end": "1011480"
  },
  {
    "text": "the first activity gets the count of",
    "start": "1011480",
    "end": "1013519"
  },
  {
    "text": "files in the partition and Al the second",
    "start": "1013519",
    "end": "1016639"
  },
  {
    "text": "activity retrieves the partition retri",
    "start": "1016639",
    "end": "1019120"
  },
  {
    "text": "the state then there's a child workflow",
    "start": "1019120",
    "end": "1022040"
  },
  {
    "text": "that is scheduled",
    "start": "1022040",
    "end": "1023880"
  },
  {
    "text": "to fetch the",
    "start": "1023880",
    "end": "1026038"
  },
  {
    "text": "metadata service details and do the",
    "start": "1026039",
    "end": "1028438"
  },
  {
    "text": "injection and then finally we we do the",
    "start": "1028439",
    "end": "1032360"
  },
  {
    "text": "Save State",
    "start": "1032360",
    "end": "1033678"
  },
  {
    "text": "API this is how our workflow changed",
    "start": "1033679",
    "end": "1037720"
  },
  {
    "text": "when we incorporated daper workflow and",
    "start": "1037720",
    "end": "1040480"
  },
  {
    "text": "activities the advantage we also receive",
    "start": "1040480",
    "end": "1042959"
  },
  {
    "text": "is",
    "start": "1042959",
    "end": "1044438"
  },
  {
    "text": "because the parent workflow saves the",
    "start": "1044439",
    "end": "1048438"
  },
  {
    "text": "state uh saves the ongoing events",
    "start": "1048439",
    "end": "1050960"
  },
  {
    "text": "whenever we do an AIT in case of",
    "start": "1050960",
    "end": "1053840"
  },
  {
    "text": "failures since the input does not change",
    "start": "1053840",
    "end": "1057160"
  },
  {
    "text": "we are able to resume without making any",
    "start": "1057160",
    "end": "1059919"
  },
  {
    "text": "IO additional IO calls or scheduling",
    "start": "1059919",
    "end": "1062400"
  },
  {
    "text": "those workflows that is the advantage we",
    "start": "1062400",
    "end": "1065039"
  },
  {
    "text": "also",
    "start": "1065039",
    "end": "1067519"
  },
  {
    "text": "received uh coming to the inputs and",
    "start": "1067799",
    "end": "1070640"
  },
  {
    "text": "outputs to the workflows and activities",
    "start": "1070640",
    "end": "1073160"
  },
  {
    "text": "as I mentioned before the input to the",
    "start": "1073160",
    "end": "1075919"
  },
  {
    "text": "parent workflow is the partition name uh",
    "start": "1075919",
    "end": "1078960"
  },
  {
    "text": "that it has to query and to the both",
    "start": "1078960",
    "end": "1081320"
  },
  {
    "text": "activities we pass in the partition",
    "start": "1081320",
    "end": "1084360"
  },
  {
    "text": "name all these are strings",
    "start": "1084360",
    "end": "1088799"
  },
  {
    "text": "and and and then we get the file name",
    "start": "1088799",
    "end": "1093000"
  },
  {
    "text": "this returns as a list of",
    "start": "1093000",
    "end": "1095640"
  },
  {
    "text": "objects then we do the aggregation and",
    "start": "1095640",
    "end": "1098200"
  },
  {
    "text": "to the child workflow we pass the",
    "start": "1098200",
    "end": "1100039"
  },
  {
    "text": "aggregated object the aggregated object",
    "start": "1100039",
    "end": "1103280"
  },
  {
    "text": "has the VM ID which pulls in the VM",
    "start": "1103280",
    "end": "1106880"
  },
  {
    "text": "details service details and using the",
    "start": "1106880",
    "end": "1110000"
  },
  {
    "text": "aggregated data VM plus service and",
    "start": "1110000",
    "end": "1113360"
  },
  {
    "text": "Ingress we inest the",
    "start": "1113360",
    "end": "1116480"
  },
  {
    "text": "data coming to the code uh let me",
    "start": "1117080",
    "end": "1120320"
  },
  {
    "text": "explain by showing the code directly",
    "start": "1120320",
    "end": "1124080"
  },
  {
    "text": "itself so this is how our code looks",
    "start": "1124080",
    "end": "1127400"
  },
  {
    "text": "like so the network record input has the",
    "start": "1127400",
    "end": "1130600"
  },
  {
    "text": "partition",
    "start": "1130600",
    "end": "1132400"
  },
  {
    "text": "name now when we the first activity that",
    "start": "1132400",
    "end": "1136159"
  },
  {
    "text": "it does is get the blob partition record",
    "start": "1136159",
    "end": "1139080"
  },
  {
    "text": "count so number of Records under the",
    "start": "1139080",
    "end": "1142480"
  },
  {
    "text": "partition and then the last process",
    "start": "1142480",
    "end": "1144919"
  },
  {
    "text": "record assume if there's a worklow let's",
    "start": "1144919",
    "end": "1148440"
  },
  {
    "text": "assume there's a pod failure here or",
    "start": "1148440",
    "end": "1150320"
  },
  {
    "text": "there is some other kind of failure",
    "start": "1150320",
    "end": "1152640"
  },
  {
    "text": "because the partition name does not",
    "start": "1152640",
    "end": "1155039"
  },
  {
    "text": "change Dapper is able to replay this",
    "start": "1155039",
    "end": "1158559"
  },
  {
    "text": "from the state store and get me the",
    "start": "1158559",
    "end": "1162039"
  },
  {
    "text": "output without make scheduling this",
    "start": "1162039",
    "end": "1165159"
  },
  {
    "text": "activity",
    "start": "1165159",
    "end": "1167679"
  },
  {
    "text": "again coming to the uh processing itself",
    "start": "1167720",
    "end": "1173080"
  },
  {
    "text": "once so here we download we pass in the",
    "start": "1173080",
    "end": "1176360"
  },
  {
    "text": "file name then we get the list of",
    "start": "1176360",
    "end": "1180159"
  },
  {
    "text": "Records back here and then we do the",
    "start": "1180159",
    "end": "1183600"
  },
  {
    "text": "aggregation here so this is nothing but",
    "start": "1183600",
    "end": "1186039"
  },
  {
    "text": "VM ID and this is the aggregated",
    "start": "1186039",
    "end": "1188280"
  },
  {
    "text": "data and then for each VM ID we call the",
    "start": "1188280",
    "end": "1192520"
  },
  {
    "text": "child",
    "start": "1192520",
    "end": "1194360"
  },
  {
    "text": "workflow and when we call the child",
    "start": "1194360",
    "end": "1196440"
  },
  {
    "text": "workflow we pass in the network",
    "start": "1196440",
    "end": "1200159"
  },
  {
    "text": "data and if you look at the enrichment",
    "start": "1200159",
    "end": "1202840"
  },
  {
    "text": "workflow itself there is again call to",
    "start": "1202840",
    "end": "1205840"
  },
  {
    "text": "the service metad data and then security",
    "start": "1205840",
    "end": "1208640"
  },
  {
    "text": "exception activity to get the exception",
    "start": "1208640",
    "end": "1211919"
  },
  {
    "text": "details and then we we pass all this",
    "start": "1211919",
    "end": "1214960"
  },
  {
    "text": "information to the data inor",
    "start": "1214960",
    "end": "1218039"
  },
  {
    "text": "activity and once we get that back we",
    "start": "1218039",
    "end": "1222360"
  },
  {
    "text": "use the Dapper sto to save the activity",
    "start": "1222360",
    "end": "1226679"
  },
  {
    "text": "we made till now for example if there is",
    "start": "1226679",
    "end": "1229799"
  },
  {
    "text": "any failure here also because the VM the",
    "start": "1229799",
    "end": "1233400"
  },
  {
    "text": "object does not change we are able to",
    "start": "1233400",
    "end": "1236760"
  },
  {
    "text": "achieve uh minimum cost when recovery",
    "start": "1236760",
    "end": "1240559"
  },
  {
    "text": "and make our workflows",
    "start": "1240559",
    "end": "1244720"
  },
  {
    "text": "faster going back to the presentation",
    "start": "1244720",
    "end": "1247640"
  },
  {
    "text": "itself now how our infrastructure",
    "start": "1247640",
    "end": "1250679"
  },
  {
    "text": "changed once",
    "start": "1250679",
    "end": "1252799"
  },
  {
    "text": "we in Incorporated Apper so because we",
    "start": "1252799",
    "end": "1256520"
  },
  {
    "text": "are using AKs we install all Dapper with",
    "start": "1256520",
    "end": "1259720"
  },
  {
    "text": "the AKs extension and we down uh all of",
    "start": "1259720",
    "end": "1263440"
  },
  {
    "text": "this is deployed using the bicep",
    "start": "1263440",
    "end": "1266760"
  },
  {
    "text": "template and then the templates itself",
    "start": "1266760",
    "end": "1270400"
  },
  {
    "text": "the extension also installs the Sentry",
    "start": "1270400",
    "end": "1272919"
  },
  {
    "text": "placement and injector Dapper side cards",
    "start": "1272919",
    "end": "1275960"
  },
  {
    "text": "as",
    "start": "1275960",
    "end": "1277600"
  },
  {
    "text": "well sorry install the Sentry placement",
    "start": "1277600",
    "end": "1281240"
  },
  {
    "text": "injector uh containers as well and then",
    "start": "1281240",
    "end": "1284919"
  },
  {
    "text": "all of this is pushed to Prometheus and",
    "start": "1284919",
    "end": "1287559"
  },
  {
    "text": "then to grafo",
    "start": "1287559",
    "end": "1290520"
  },
  {
    "text": "now",
    "start": "1290760",
    "end": "1292520"
  },
  {
    "text": "to talk with the state store the manage",
    "start": "1292520",
    "end": "1295600"
  },
  {
    "text": "identity we use Dapper uses manage",
    "start": "1295600",
    "end": "1298279"
  },
  {
    "text": "identity this is where we had one more",
    "start": "1298279",
    "end": "1300799"
  },
  {
    "text": "learning where when we use when we have",
    "start": "1300799",
    "end": "1302880"
  },
  {
    "text": "to use manage identity the",
    "start": "1302880",
    "end": "1304840"
  },
  {
    "text": "authentication takes a bit more of time",
    "start": "1304840",
    "end": "1307400"
  },
  {
    "text": "and the Dapper default timeout wouldn't",
    "start": "1307400",
    "end": "1309600"
  },
  {
    "text": "work and we had to increase the time",
    "start": "1309600",
    "end": "1313960"
  },
  {
    "text": "out F and then coming to the learnings",
    "start": "1314520",
    "end": "1317880"
  },
  {
    "text": "itself",
    "start": "1317880",
    "end": "1319039"
  },
  {
    "text": "first smaller workflows are better the",
    "start": "1319039",
    "end": "1322080"
  },
  {
    "text": "reason being",
    "start": "1322080",
    "end": "1323840"
  },
  {
    "text": "uh because of the EV sourcing",
    "start": "1323840",
    "end": "1327200"
  },
  {
    "text": "pattern all the events are recorded and",
    "start": "1327200",
    "end": "1330720"
  },
  {
    "text": "if if the parent workfl T off",
    "start": "1330720",
    "end": "1333760"
  },
  {
    "text": "activities what would end up happening",
    "start": "1333760",
    "end": "1335760"
  },
  {
    "text": "is every time it would have to when it",
    "start": "1335760",
    "end": "1338279"
  },
  {
    "text": "tries to construct events when it tries",
    "start": "1338279",
    "end": "1340799"
  },
  {
    "text": "to construct the world from the events",
    "start": "1340799",
    "end": "1343480"
  },
  {
    "text": "it uh it becomes a little",
    "start": "1343480",
    "end": "1346480"
  },
  {
    "text": "tricky second understand understanding",
    "start": "1346480",
    "end": "1348880"
  },
  {
    "text": "the states of limitations this is what",
    "start": "1348880",
    "end": "1351240"
  },
  {
    "text": "we were caught little off off guard the",
    "start": "1351240",
    "end": "1353640"
  },
  {
    "text": "reason being Cosmos DB has a 5m",
    "start": "1353640",
    "end": "1357240"
  },
  {
    "text": "limitation of the request and we saw",
    "start": "1357240",
    "end": "1360080"
  },
  {
    "text": "that 2 to 3% of our workflows when they",
    "start": "1360080",
    "end": "1363520"
  },
  {
    "text": "were running into issue that is when we",
    "start": "1363520",
    "end": "1366080"
  },
  {
    "text": "found out that okay this might not",
    "start": "1366080",
    "end": "1369159"
  },
  {
    "text": "eventually work so we are planning to",
    "start": "1369159",
    "end": "1372799"
  },
  {
    "text": "Migra do some migration there but I",
    "start": "1372799",
    "end": "1375880"
  },
  {
    "text": "wouldn't say this is the end of the",
    "start": "1375880",
    "end": "1377440"
  },
  {
    "text": "world the reason Reon",
    "start": "1377440",
    "end": "1379799"
  },
  {
    "text": "being Dapper abstracts away the state",
    "start": "1379799",
    "end": "1383400"
  },
  {
    "text": "store implementation datas beautifully",
    "start": "1383400",
    "end": "1386200"
  },
  {
    "text": "now the the thing you have to change is",
    "start": "1386200",
    "end": "1389520"
  },
  {
    "text": "most probably the Stage store yaml file",
    "start": "1389520",
    "end": "1392440"
  },
  {
    "text": "which switches the cosmos DB to redis or",
    "start": "1392440",
    "end": "1395039"
  },
  {
    "text": "something and none of your workflow has",
    "start": "1395039",
    "end": "1398559"
  },
  {
    "text": "to change or the code has to change",
    "start": "1398559",
    "end": "1401120"
  },
  {
    "text": "everything Dapper takes care",
    "start": "1401120",
    "end": "1403320"
  },
  {
    "text": "of and then the constructs of using",
    "start": "1403320",
    "end": "1406720"
  },
  {
    "text": "workflows and activities",
    "start": "1406720",
    "end": "1409120"
  },
  {
    "text": "and more fundamentally all your service",
    "start": "1409120",
    "end": "1411559"
  },
  {
    "text": "invocations are recommended to happen",
    "start": "1411559",
    "end": "1413919"
  },
  {
    "text": "through activities because of the",
    "start": "1413919",
    "end": "1416240"
  },
  {
    "text": "inherent advantage that if the input is",
    "start": "1416240",
    "end": "1419080"
  },
  {
    "text": "same the activities wouldn't have to be",
    "start": "1419080",
    "end": "1420960"
  },
  {
    "text": "scheduled anymore this is uh so these",
    "start": "1420960",
    "end": "1424120"
  },
  {
    "text": "are the constructs we had to keep in",
    "start": "1424120",
    "end": "1426400"
  },
  {
    "text": "mind when designing Dapper workflows and",
    "start": "1426400",
    "end": "1429039"
  },
  {
    "text": "activities and it was a very good",
    "start": "1429039",
    "end": "1430880"
  },
  {
    "text": "learning for",
    "start": "1430880",
    "end": "1433480"
  },
  {
    "text": "us coming to the norstar we have started",
    "start": "1434679",
    "end": "1438240"
  },
  {
    "text": "with",
    "start": "1438240",
    "end": "1439120"
  },
  {
    "text": "aggregation INF integrating Dapper into",
    "start": "1439120",
    "end": "1442320"
  },
  {
    "text": "aggregation infrastructure now the next",
    "start": "1442320",
    "end": "1444600"
  },
  {
    "text": "steps are from the inherent pattern here",
    "start": "1444600",
    "end": "1447679"
  },
  {
    "text": "we see this as pops up so the we believe",
    "start": "1447679",
    "end": "1450720"
  },
  {
    "text": "the Dapper pops up building block will",
    "start": "1450720",
    "end": "1452640"
  },
  {
    "text": "be a beautiful fit into this",
    "start": "1452640",
    "end": "1454960"
  },
  {
    "text": "architecture here and then the Dapper",
    "start": "1454960",
    "end": "1458440"
  },
  {
    "text": "service invocation API is also something",
    "start": "1458440",
    "end": "1460760"
  },
  {
    "text": "we are looking for because the inherent",
    "start": "1460760",
    "end": "1464200"
  },
  {
    "text": "nature of cloud workloads",
    "start": "1464200",
    "end": "1466679"
  },
  {
    "text": "are they are you have to have retra",
    "start": "1466679",
    "end": "1470120"
  },
  {
    "text": "mechanisms built in because there are",
    "start": "1470120",
    "end": "1473120"
  },
  {
    "text": "transient call failures and one",
    "start": "1473120",
    "end": "1476520"
  },
  {
    "text": "advantage we get is Dapper side car",
    "start": "1476520",
    "end": "1478720"
  },
  {
    "text": "already has this logic to handle all",
    "start": "1478720",
    "end": "1481919"
  },
  {
    "text": "these has all this retry logic second uh",
    "start": "1481919",
    "end": "1485679"
  },
  {
    "text": "it also helps you restrict the access",
    "start": "1485679",
    "end": "1488120"
  },
  {
    "text": "policy by placing access policies that",
    "start": "1488120",
    "end": "1491760"
  },
  {
    "text": "which API which containers can invoke",
    "start": "1491760",
    "end": "1495159"
  },
  {
    "text": "which apis so these are the restrictions",
    "start": "1495159",
    "end": "1497760"
  },
  {
    "text": "that also I can",
    "start": "1497760",
    "end": "1499399"
  },
  {
    "text": "use so the notar would be uh looking",
    "start": "1499399",
    "end": "1503720"
  },
  {
    "text": "into how we can invoke incorporate",
    "start": "1503720",
    "end": "1506480"
  },
  {
    "text": "service invocation API and the pops of",
    "start": "1506480",
    "end": "1509640"
  },
  {
    "text": "apis uh I think that's it uh this is uh",
    "start": "1509640",
    "end": "1513279"
  },
  {
    "text": "this is what our daper journey has been",
    "start": "1513279",
    "end": "1515240"
  },
  {
    "text": "and it has simply been amazing and uh",
    "start": "1515240",
    "end": "1518399"
  },
  {
    "text": "with all the stage tore management",
    "start": "1518399",
    "end": "1520760"
  },
  {
    "text": "capabilities we saved months of effort",
    "start": "1520760",
    "end": "1523120"
  },
  {
    "text": "building such capabilities and",
    "start": "1523120",
    "end": "1525279"
  },
  {
    "text": "observability infrastructure and uh add",
    "start": "1525279",
    "end": "1529600"
  },
  {
    "text": "more business value in a short",
    "start": "1529600",
    "end": "1531960"
  },
  {
    "text": "duration with that I wrap up my talk and",
    "start": "1531960",
    "end": "1534640"
  },
  {
    "text": "hand it over back to Mark and sisle",
    "start": "1534640",
    "end": "1537200"
  },
  {
    "text": "thank you",
    "start": "1537200",
    "end": "1540440"
  }
]
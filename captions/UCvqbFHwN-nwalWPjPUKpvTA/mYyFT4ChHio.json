[
  {
    "start": "0",
    "end": "270000"
  },
  {
    "text": "okay hello everybody okay very good my name is Tom I'm Tom Wilkie from",
    "start": "60",
    "end": "7680"
  },
  {
    "text": "katana labs and I am Bryan Boram from we've works we work on their project",
    "start": "7680",
    "end": "12929"
  },
  {
    "text": "called cortex so who was here for the intro",
    "start": "12929",
    "end": "18109"
  },
  {
    "text": "who is here for the intro talk we were oh wow I was expecting more people okay",
    "start": "18350",
    "end": "25680"
  },
  {
    "text": "what'd you reckon shall we change the talk I think it's most of them okay so who runs Prometheus then who's here most",
    "start": "25680",
    "end": "33510"
  },
  {
    "text": "of you good and who's like already familiar with cortex considering this is the deep dive okay",
    "start": "33510",
    "end": "40590"
  },
  {
    "text": "well we'll do it we'll do a bit of an intro before we get in like here's only a 30 minute talk so what we thought we'd",
    "start": "40590",
    "end": "47760"
  },
  {
    "text": "do is just focus on one particular piece of cortex so we're going to do a bit of an intro we'll do a bit of a demo and",
    "start": "47760",
    "end": "53910"
  },
  {
    "text": "then the main like deep dive is going to be about cortex is query path in the past year or so we've done a huge amount",
    "start": "53910",
    "end": "60120"
  },
  {
    "text": "of work on making it really fast and that's why it's awesome so I'll do the brief intro yeah this is not working",
    "start": "60120",
    "end": "68100"
  },
  {
    "text": "very well so cortex is a time series database it's a horizontally scalable highly available",
    "start": "68100",
    "end": "74930"
  },
  {
    "text": "what's the long-term storage for Prometheus so it's got a Prometheus",
    "start": "74930",
    "end": "80009"
  },
  {
    "text": "compatible API you use Prometheus to send samples to cortex and then from",
    "start": "80009",
    "end": "85409"
  },
  {
    "text": "there you know you can scale it to as much as you like to pretty much you know so CNCs projects there's it's on github",
    "start": "85409",
    "end": "90869"
  },
  {
    "text": "it's all patchy licensed you might ask like why did we implement it like this why is it got these features what's",
    "start": "90869",
    "end": "96780"
  },
  {
    "text": "interesting about that we've done for use cases we've tried to address so when",
    "start": "96780",
    "end": "102810"
  },
  {
    "text": "we really want to see a bit that's kind of missing from the Prometheus world is this idea of getting a global picture of",
    "start": "102810",
    "end": "109259"
  },
  {
    "text": "all of your metrics if you're running multiple clusters maybe geographically distributed you're",
    "start": "109259",
    "end": "114899"
  },
  {
    "text": "going to have to put a Prometheus in each one of them and then you need a way of getting a big picture so there are a",
    "start": "114899",
    "end": "120210"
  },
  {
    "text": "few ways of doing this you can federate your Promethea Prometheus's you can use stano's or you can use cortex like so",
    "start": "120210",
    "end": "127560"
  },
  {
    "text": "they're the kind of three there was a talk earlier from the uber guys during m3 very similar use case",
    "start": "127560",
    "end": "133600"
  },
  {
    "text": "the second one is we we want a different story to a high availability in the prometheus world you run a pair of",
    "start": "133600",
    "end": "139930"
  },
  {
    "text": "Promethea and if one of them fails you kind of have a second one but in most",
    "start": "139930",
    "end": "146020"
  },
  {
    "text": "worlds this you know it tends to lead to inconsistent results or gaps in the graph we wanted a different story we",
    "start": "146020",
    "end": "151360"
  },
  {
    "text": "wanted no gaps and we wanted to put a bit more time and effort into like using more modern consistency and high",
    "start": "151360",
    "end": "157600"
  },
  {
    "text": "availability techniques so we basically do replication we wanted to offer long",
    "start": "157600",
    "end": "163090"
  },
  {
    "text": "term storage when we started this project three years ago prometheus had a",
    "start": "163090",
    "end": "168400"
  },
  {
    "text": "bit naive storage engine you know there was very practical but wasn't potentially that advanced since then",
    "start": "168400",
    "end": "174730"
  },
  {
    "text": "Prometheus to dotto has a much better storage engine you can put long term data in Prometheus don't let anyone tell",
    "start": "174730",
    "end": "179770"
  },
  {
    "text": "you otherwise but we wanted to offer a different trade-off we wanted some it was a bit more durable we wanted something with a bit more replication we",
    "start": "179770",
    "end": "186340"
  },
  {
    "text": "also wanted to take advantage of cloud storage so we wanted to have cortex basically write its data to BigTable",
    "start": "186340",
    "end": "192940"
  },
  {
    "text": "dynamodb GCS that kind of thing s3 that kind of thing and then finally",
    "start": "192940",
    "end": "197980"
  },
  {
    "text": "we originally started the project at a company called weave works at problem works for when we originally started",
    "start": "197980",
    "end": "204160"
  },
  {
    "text": "that we wanted to offer Prometheus as a service we wanted to sell this so that people could send their data and have",
    "start": "204160",
    "end": "209770"
  },
  {
    "text": "someone else worry about the storage side of things to do that we wanted to make the system multi-tenant so what we",
    "start": "209770",
    "end": "217780"
  },
  {
    "text": "really didn't want to do is have to run a new cortex or new Prometheus for every new customer we got and so we wanted it",
    "start": "217780",
    "end": "224020"
  },
  {
    "text": "to be multi-tenant what this means is a single core test cluster can manage kind of isolated Promethea Prometheus",
    "start": "224020",
    "end": "230709"
  },
  {
    "text": "instances within the cluster by every job fundamentally understands every request is for a given user are you",
    "start": "230709",
    "end": "239230"
  },
  {
    "text": "trying to sit down bro you're supposed to be people needing a seat so I thought I'd free one up there okay so please",
    "start": "239230",
    "end": "246570"
  },
  {
    "text": "yeah that's really like that's the introduction to Prometheus really to cortex really super straightforward what",
    "start": "246570",
    "end": "253030"
  },
  {
    "text": "it is what it's for if you have more questions about how we achieve some of this stuff the intro talk goes into a",
    "start": "253030",
    "end": "259450"
  },
  {
    "text": "few more details the readme on github has links to three years worst of presentations and talks the",
    "start": "259450",
    "end": "265790"
  },
  {
    "text": "talk about the algorithms and the design and architecture and so on really what I",
    "start": "265790",
    "end": "271580"
  },
  {
    "start": "270000",
    "end": "778000"
  },
  {
    "text": "want to do now about half of you were here for the intro and I didn't have enough time to finish my demo so I just",
    "start": "271580",
    "end": "276680"
  },
  {
    "text": "want to show you cortex I want to run it and show you how to how to use it and then we'll get into some more",
    "start": "276680",
    "end": "283670"
  },
  {
    "text": "interesting stuff well this would be interesting I hope down the windows you",
    "start": "283670",
    "end": "290090"
  },
  {
    "text": "want to provide a running commentary well there's nothing new on yours oh it says demo time okay right right then so",
    "start": "290090",
    "end": "297230"
  },
  {
    "text": "can we all see my screen we're not going to show that so thomas thomas gonna run",
    "start": "297230",
    "end": "302740"
  },
  {
    "text": "cortex on his laptop he's just gonna run it in docker containers you know in in",
    "start": "302740",
    "end": "310370"
  },
  {
    "text": "production we tend to run in big clusters using kubernetes but for the purpose of firing up a small demo he's",
    "start": "310370",
    "end": "319310"
  },
  {
    "text": "gonna run docker containers so can everyone see that is that big enough you can see hopefully you can see there's",
    "start": "319310",
    "end": "324740"
  },
  {
    "text": "nothing up my sleeves there's no docker docker containers running so I'm just gonna run first I'm",
    "start": "324740",
    "end": "330020"
  },
  {
    "text": "gonna run a console node I've typed these commands in before so I'm just searching for there we go",
    "start": "330020",
    "end": "335300"
  },
  {
    "text": "so cortex needs somewhere to put kind of coordination data to decide which cortex",
    "start": "335300",
    "end": "341030"
  },
  {
    "text": "instance owns which bit of data effectively we use console and there's a PR open to use at CD as well and",
    "start": "341030",
    "end": "348140"
  },
  {
    "text": "eventually I want to really do gossip to kind of get rid of this dependency but it's not too hard to run a single console the state of the data that's",
    "start": "348140",
    "end": "355580"
  },
  {
    "text": "stored in that console is kind of not super important you can afford to lose it so we don't you don't have to back it",
    "start": "355580",
    "end": "360710"
  },
  {
    "text": "up for instance anyway so now we have a console tell my brightness object it I'm",
    "start": "360710",
    "end": "368540"
  },
  {
    "text": "now going to run all I'm go first I'm gonna set the replication factor so",
    "start": "368540",
    "end": "375860"
  },
  {
    "text": "cortex is configured via a config file in the config file you can specify what",
    "start": "375860",
    "end": "382160"
  },
  {
    "text": "this is relatively new actually it was previously configured using command line flags we've just recently added a config",
    "start": "382160",
    "end": "387920"
  },
  {
    "text": "file to make it easier to try and easier to get started with so I'm going to set the replication factor to three",
    "start": "387920",
    "end": "393140"
  },
  {
    "text": "hopefully you can all see that this will mean that every day every bit of data is written to cortex is replicated three",
    "start": "393140",
    "end": "398540"
  },
  {
    "text": "times or at least two times and then I'm gonna",
    "start": "398540",
    "end": "404099"
  },
  {
    "text": "cortex one so I've conveniently moved",
    "start": "404099",
    "end": "410020"
  },
  {
    "text": "the config file since I type this command so we're gonna Docs",
    "start": "410020",
    "end": "416159"
  },
  {
    "text": "now we're creating a campaign called cortex one we're putting it on the cortex Network this is where it can find",
    "start": "416159",
    "end": "421300"
  },
  {
    "text": "the console and we're exposing it and port 9001 telling it to use that config file telling you to use the cortex image",
    "start": "421300",
    "end": "427779"
  },
  {
    "text": "telling to use a confident I'll again telling it to use that console again and then log level debug because when I",
    "start": "427779",
    "end": "433240"
  },
  {
    "text": "tried the demo yesterday it didn't work hopefully it does today so there is now",
    "start": "433240",
    "end": "439330"
  },
  {
    "text": "- and I'm just going to run that a few more times calling it cortex - yep",
    "start": "439330",
    "end": "448349"
  },
  {
    "text": "fingers crossed cortex 3 so this is what cube cut' will",
    "start": "448349",
    "end": "455289"
  },
  {
    "text": "run - replicas equals 3 does pretty much you could have Tom come around to your data center and run it right so they all",
    "start": "455289",
    "end": "463810"
  },
  {
    "text": "seem to be running fine so we've now got a cortex cluster and if you don't believe me we just no no that's what I",
    "start": "463810",
    "end": "473830"
  },
  {
    "text": "wanted if you don't believe me we can actually go localhost 9000 and one was",
    "start": "473830",
    "end": "479379"
  },
  {
    "text": "the cortex the port I exposed cortex on now this is a view of that state that we store in console to basically show how",
    "start": "479379",
    "end": "485889"
  },
  {
    "text": "much each in gesture owns of our disputed hash table so we've got a little bit of ownership you've got a",
    "start": "485889",
    "end": "491110"
  },
  {
    "text": "little bit of actions if you know one of the machines fail you can delete it and so on and hopefully if we go to every",
    "start": "491110",
    "end": "497080"
  },
  {
    "text": "single one of these hosts we'll see the same data yep this shows that",
    "start": "497080",
    "end": "503289"
  },
  {
    "text": "everything's really much ready to go now we're going to start at Prometheus I'm just in the Prometheus repo and I've",
    "start": "503289",
    "end": "511779"
  },
  {
    "text": "added to the default Prometheus config I've just added some remote right config this tells Prometheus to send every",
    "start": "511779",
    "end": "517719"
  },
  {
    "text": "sample its grapes to this endpoint and so you can see I'm sending it to port 9001 which is the first replica of console if",
    "start": "517719",
    "end": "524050"
  },
  {
    "text": "you're running this in product there cortex if if I was running this in production I'd put a load balancer in front of that and I'd have that",
    "start": "524050",
    "end": "530550"
  },
  {
    "text": "pick the console to send each requester cortex and have that pick the cortex to send every request to anyway so I'm",
    "start": "530550",
    "end": "539820"
  },
  {
    "text": "deleting the data because obviously I've run this demo multiple times and I'm running quarter prometheus so that seems",
    "start": "539820",
    "end": "546930"
  },
  {
    "text": "to be working and then finally I'm just gonna run a graph honor",
    "start": "546930",
    "end": "552630"
  },
  {
    "text": "so dr. brown port 3000 Network cortex for fun now if we don't look in the",
    "start": "552630",
    "end": "559110"
  },
  {
    "text": "graph I know I just started which would be localhost 3000 everyone knows that",
    "start": "559110",
    "end": "566399"
  },
  {
    "text": "password to graph on all right it's just admin no one ever changes it and this is an empty graph owner so we",
    "start": "566399",
    "end": "575040"
  },
  {
    "text": "can add a data source first we're gonna add the Prometheus that's running on my laptop because I can never remember in",
    "start": "575040",
    "end": "580529"
  },
  {
    "text": "dhaka how to do that I've got a handy little URL here this demo well this is",
    "start": "580529",
    "end": "586709"
  },
  {
    "text": "an extension of the demo but this demo will be written up in the readme in cortex if you want to try it yourself at home so we're saying connector",
    "start": "586709",
    "end": "594260"
  },
  {
    "text": "Prometheus previous is port 1990 right yep I'm sorry saving test that works now",
    "start": "594260",
    "end": "601020"
  },
  {
    "text": "we're going to add a cortex replica cortex data source again if you were",
    "start": "601020",
    "end": "606810"
  },
  {
    "text": "running this in production you'd stick a load balancer queue Bonetti service ELB whatever you fancy in front of cortex",
    "start": "606810",
    "end": "613970"
  },
  {
    "text": "but here I'm just going to point it out because I'm on docker and we don't have that kind of thing just gonna point it",
    "start": "613970",
    "end": "620700"
  },
  {
    "text": "at court exporting 9009 which should be the right port it is so cortex",
    "start": "620700",
    "end": "628170"
  },
  {
    "text": "this is cortex one actually cortex three because I like to live life dangerously",
    "start": "628170",
    "end": "635690"
  },
  {
    "text": "so cortex one is where the data is being written and I really want to show you that clustering works so I'm going to",
    "start": "635690",
    "end": "640829"
  },
  {
    "text": "try and read the data from another instance cortex three 9009 didn't work",
    "start": "640829",
    "end": "646279"
  },
  {
    "text": "why didn't work",
    "start": "646279",
    "end": "649640"
  },
  {
    "text": "9009 for the port number isn't it let's",
    "start": "651580",
    "end": "657530"
  },
  {
    "text": "consult the consult this that will tell me you're supposed to here we go yeah of",
    "start": "657530",
    "end": "662750"
  },
  {
    "text": "course cortex exposes the Prometheus eye under API Prometheus which is there for",
    "start": "662750",
    "end": "670730"
  },
  {
    "text": "various historic reasons yeah that works now here we can show that the data is in",
    "start": "670730",
    "end": "676610"
  },
  {
    "text": "Prometheus so we're going to do rate Prometheus head no greasiest TS DB head",
    "start": "676610",
    "end": "688570"
  },
  {
    "text": "samples appended total so this shows you that something is going on in that",
    "start": "688570",
    "end": "693890"
  },
  {
    "text": "Prometheus instance it's reading some samples not a particularly high load 25 per second if we split and show you that",
    "start": "693890",
    "end": "701270"
  },
  {
    "text": "you can read it from cortex yes we got the same data so hopefully you followed that I did it a bit quickly sorry about",
    "start": "701270",
    "end": "707000"
  },
  {
    "text": "that but we can see that core Prometheus is pushing data to that cortex cluster I've replicated it three ways and then",
    "start": "707000",
    "end": "712370"
  },
  {
    "text": "we're reading it from one of the nodes and now the thing I actually want to show I'm gonna delete one of the nodes",
    "start": "712370",
    "end": "717530"
  },
  {
    "text": "and show that it all still works so docker RM - F cortex - I'm not going to",
    "start": "717530",
    "end": "724310"
  },
  {
    "text": "let cortex 1 because that's where we're writing the data and I'm not gonna delete cortex 3 because that's where we're reading the data so deleting",
    "start": "724310",
    "end": "729650"
  },
  {
    "text": "cortex - not giving it a chance to leave the ring or do any kind of tidying up so",
    "start": "729650",
    "end": "735800"
  },
  {
    "text": "if we go into here you'll see that there's a heartbeat being written to console and the cortex - which I assume",
    "start": "735800",
    "end": "742460"
  },
  {
    "text": "is this one the top one is not writing it Hartley anymore so cortex has noticed it's gone away and then if we run this",
    "start": "742460",
    "end": "750320"
  },
  {
    "text": "you'll see that it's still reading I'm writing I don't know why it's increased in throughput but still reading I'm writing for it's still popular",
    "start": "750320",
    "end": "756080"
  },
  {
    "text": "prometheus is still working and cortex is still receiving the data I'm replicating it and no one you know no",
    "start": "756080",
    "end": "762350"
  },
  {
    "text": "user should notice any outage here so if you were for the earlier talk you would see me one through a bit earlier bits of",
    "start": "762350",
    "end": "768320"
  },
  {
    "text": "that demo and that's just showing you that we do replication and high availability okay that's the demo Tom",
    "start": "768320",
    "end": "775660"
  },
  {
    "text": "sure we do you need the speaking notes now can't read them anyway",
    "start": "776080",
    "end": "781480"
  },
  {
    "start": "778000",
    "end": "893000"
  },
  {
    "text": "I just I might just try because I need them so I'm gonna take over now and talk",
    "start": "781480",
    "end": "787690"
  },
  {
    "text": "for a bit about how a little bit more detail of the storage engine of cortex",
    "start": "787690",
    "end": "795990"
  },
  {
    "text": "so the what Tom set up was was cortex receiving samples from Prometheus and",
    "start": "795990",
    "end": "805560"
  },
  {
    "text": "you know in the in the demo it was like 25 30 samples per second people run",
    "start": "805560",
    "end": "812860"
  },
  {
    "text": "cortex a much bigger scale than that millions and millions of samples coming",
    "start": "812860",
    "end": "819010"
  },
  {
    "text": "in over time billions that will be handy thank you and we store them all in some",
    "start": "819010",
    "end": "827830"
  },
  {
    "text": "kind of storage database we we all subscribe to the view that you should",
    "start": "827830",
    "end": "832930"
  },
  {
    "text": "never write your own database agreed right Tom don't want to do that so we",
    "start": "832930",
    "end": "838720"
  },
  {
    "text": "use a database like dynamodb or Cassandra or BigTable or something like that and so the ingest path we've getting all",
    "start": "838720",
    "end": "850720"
  },
  {
    "text": "these samples in there all four different metrics they got different labels there for different tenants and",
    "start": "850720",
    "end": "857140"
  },
  {
    "text": "over time we've got billions of them on disk so the the problem I want to talk",
    "start": "857140",
    "end": "862300"
  },
  {
    "text": "about is when a query comes in if you think about it we have to find the right",
    "start": "862300",
    "end": "869080"
  },
  {
    "text": "information and on disk using only what's in the query so that's a walk",
    "start": "869080",
    "end": "876310"
  },
  {
    "text": "through exactly how that happens and then Tom's going to tell us how many",
    "start": "876310",
    "end": "881410"
  },
  {
    "text": "medical faster and this is doing nothing",
    "start": "881410",
    "end": "886810"
  },
  {
    "text": "for me yeah you know click it three times it'll happen once you think yeah go for it I do want to use the cat",
    "start": "886810",
    "end": "895690"
  },
  {
    "start": "893000",
    "end": "1048000"
  },
  {
    "text": "botherer device so the we have we gone",
    "start": "895690",
    "end": "902500"
  },
  {
    "text": "on too far we have it it clicked eventually there",
    "start": "902500",
    "end": "907939"
  },
  {
    "text": "we go that's the picture I wanted and I wanted to point lasers at it because I love lasers",
    "start": "907939",
    "end": "913509"
  },
  {
    "text": "so this is a this is a diagram of the query path of cortex and in in an",
    "start": "913509",
    "end": "922879"
  },
  {
    "text": "earlier state so you know it's pretty much cortex the project has been going for over three years this is pretty much",
    "start": "922879",
    "end": "930379"
  },
  {
    "text": "the original design and didn't change much until about a year ago a lot of",
    "start": "930379",
    "end": "936470"
  },
  {
    "text": "work is going in the last year so as I say a query comes in and that's you know",
    "start": "936470",
    "end": "942709"
  },
  {
    "text": "some rate this divided by that times you know linear predictor whatever your",
    "start": "942709",
    "end": "949250"
  },
  {
    "text": "whatever your prom qil queries comes in we we run multiple queriers that's the",
    "start": "949250",
    "end": "957199"
  },
  {
    "text": "whole horizontal scalable idea so you probably run at least two of these for",
    "start": "957199",
    "end": "964060"
  },
  {
    "text": "availability you might run ten of them you can run 100 of them if you want I'm",
    "start": "964060",
    "end": "970399"
  },
  {
    "text": "you have some kind of load balancer on the front of that because we really don't care which one we pick we just",
    "start": "970399",
    "end": "977420"
  },
  {
    "text": "enter one of these queriers we use Prometheus code to parse the query we",
    "start": "977420",
    "end": "986540"
  },
  {
    "text": "use a lot of Prometheus code and then we need to go to places with the query the",
    "start": "986540",
    "end": "992839"
  },
  {
    "text": "very latest the very latest data is in the memory of the injectors isn't in the ingest path it's getting compressed down",
    "start": "992839",
    "end": "1000550"
  },
  {
    "text": "we do this extremely powerful compression and it's it's held in memory so we need to go find that data that's",
    "start": "1000550",
    "end": "1007720"
  },
  {
    "text": "the very latest data and we go to the what we call the chunk store which is",
    "start": "1007720",
    "end": "1016029"
  },
  {
    "text": "the the blobs which are the the you know basic samples compressed down and an",
    "start": "1016029",
    "end": "1023019"
  },
  {
    "text": "index to find the right ones and I'll repeat that the the whole trick of this",
    "start": "1023019",
    "end": "1030280"
  },
  {
    "text": "is how do we find the exact right blobs you know given given we've got billions of them we need to find the exact right",
    "start": "1030280",
    "end": "1037390"
  },
  {
    "text": "ones to to load up to pass back to the prom",
    "start": "1037390",
    "end": "1042620"
  },
  {
    "text": "ql engine which is going to then do the the arithmetic on the samples so there",
    "start": "1042620",
    "end": "1051920"
  },
  {
    "start": "1048000",
    "end": "1210000"
  },
  {
    "text": "is a query how do we answer that query",
    "start": "1051920",
    "end": "1057380"
  },
  {
    "text": "we have an inverted index so this is a",
    "start": "1057380",
    "end": "1062690"
  },
  {
    "text": "very standard technique in no snowsuit sequel databases the the basic idea is",
    "start": "1062690",
    "end": "1071570"
  },
  {
    "text": "that the metric has a name and we're querying on one label which is you know",
    "start": "1071570",
    "end": "1078950"
  },
  {
    "text": "our our shipping job just for example sake in the database we've got this",
    "start": "1078950",
    "end": "1084950"
  },
  {
    "text": "metric and we've got a bunch of different labels that we've recorded the data under you know we've recorded it",
    "start": "1084950",
    "end": "1091670"
  },
  {
    "text": "for different jobs we've recorded it for different instances it's some kind of HTTP server so we've recorded it for",
    "start": "1091670",
    "end": "1098360"
  },
  {
    "text": "different paths we've recorded the different error codes that came back and and what happens in it cortex is that we",
    "start": "1098360",
    "end": "1109510"
  },
  {
    "text": "we start with the metric that you're asking for and then you ask to narrow it",
    "start": "1109510",
    "end": "1116270"
  },
  {
    "text": "down on a label so that takes us to this line here and then we match on what's",
    "start": "1116270",
    "end": "1122300"
  },
  {
    "text": "this one here right shipping and that points in the index to a series of time",
    "start": "1122300",
    "end": "1129200"
  },
  {
    "text": "series the time series then point to the chunks of data each chunk is typically",
    "start": "1129200",
    "end": "1136880"
  },
  {
    "text": "like six hours of data crushed down to a couple of kilobytes and that's that's",
    "start": "1136880",
    "end": "1142880"
  },
  {
    "text": "what we read from the store so look at that I think another thing to add there is you can just for brevity we've only",
    "start": "1142880",
    "end": "1149990"
  },
  {
    "text": "had one matcher on this you can have multiple sets of matches and then we'll do a an intersection of the lookups in the index",
    "start": "1149990",
    "end": "1156530"
  },
  {
    "text": "yeah we have we handle you know queries of any complexity which is certainly",
    "start": "1156530",
    "end": "1163220"
  },
  {
    "text": "what my customers use and just to kind",
    "start": "1163220",
    "end": "1169310"
  },
  {
    "text": "of state that another way so the the the query came in same query I'm talking about we go to the index row",
    "start": "1169310",
    "end": "1176660"
  },
  {
    "text": "for that particular label we find shipping that gives us a set of time series we look up that time series we",
    "start": "1176660",
    "end": "1183440"
  },
  {
    "text": "get these chunks which are effectively time-based a few a few K compressed and",
    "start": "1183440",
    "end": "1189350"
  },
  {
    "text": "stored in the store so now we we read those chunks in those have the raw",
    "start": "1189350",
    "end": "1196780"
  },
  {
    "text": "samples in the time series and we hand them back to Prometheus which does the",
    "start": "1196780",
    "end": "1202820"
  },
  {
    "text": "original to go for them and I'm now gonna hand back to Tom who's gonna go into even more detail about thank you",
    "start": "1202820",
    "end": "1208910"
  },
  {
    "text": "Brian did this work so one of the things",
    "start": "1208910",
    "end": "1214910"
  },
  {
    "text": "the reason we did the demo first is because we wanted to highlight that cortex does replication we do a three-way replication by default is",
    "start": "1214910",
    "end": "1221060"
  },
  {
    "text": "configurable but by default is three-way replication what this means is you end up with three copies all the chunks in",
    "start": "1221060",
    "end": "1227210"
  },
  {
    "text": "your chunk store and through various like jitter and and failures and rollouts and all these kind of normal",
    "start": "1227210",
    "end": "1233540"
  },
  {
    "text": "noise that happens in your cluster those chunks aren't going to necessarily align in fact you had an interesting stat you",
    "start": "1233540",
    "end": "1240770"
  },
  {
    "text": "were telling me yeah sometimes they do align they align about a quarter of the time about a quarter of the time they're",
    "start": "1240770",
    "end": "1246200"
  },
  {
    "text": "aligned but 75% of the time they're subtly different so the first thing we have to do when answering a query is we",
    "start": "1246200",
    "end": "1251990"
  },
  {
    "text": "have to deegeu p-- we have to merge these all together into an iterator and dilute them yeah that's this is just",
    "start": "1251990",
    "end": "1258470"
  },
  {
    "text": "kind of you trying to visualize how they might not align yeah this is useless",
    "start": "1258470",
    "end": "1264160"
  },
  {
    "text": "it works so a lot of text sorry about that that's really out style for me we",
    "start": "1264160",
    "end": "1270500"
  },
  {
    "text": "tried a bunch of ways of doing this the obvious way would be to kind of turn these chunks into big slices and go and",
    "start": "1270500",
    "end": "1276920"
  },
  {
    "text": "use a merge to kind of merge them all together into even bigger slices and turns out that's really fast it's",
    "start": "1276920",
    "end": "1283340"
  },
  {
    "text": "actually the fastest way we could find to do it the problem is these chunks there might only be a few kilobytes but",
    "start": "1283340",
    "end": "1289850"
  },
  {
    "text": "you do tend to load millions of them and then loading that decompressing them all you know each sample in a chunk only",
    "start": "1289850",
    "end": "1296570"
  },
  {
    "text": "uses about a byte but when not in a chunk is like eight sixteen sixteen sixteen yeah okay so when you decompress",
    "start": "1296570",
    "end": "1303200"
  },
  {
    "text": "them you end up with a lot of data and so this is how cortex did it you know year or two ago and it would run out of",
    "start": "1303200",
    "end": "1310330"
  },
  {
    "text": "memory if you ran a big enough query that's kind of sucks right so the mean it's obvious the solution is iterators",
    "start": "1310330",
    "end": "1316420"
  },
  {
    "text": "right everyone said the solution is iterators obviously the solution is arteritis so we built iterators and then the",
    "start": "1316420",
    "end": "1322450"
  },
  {
    "text": "question becomes how do you detect overlaps between the iterators so we put all the iterators into a heap and we pop",
    "start": "1322450",
    "end": "1328210"
  },
  {
    "text": "them off and then pop the next one off the iterator and then put it back into the heap and that use basically constant amount of memory or very very small",
    "start": "1328210",
    "end": "1334750"
  },
  {
    "text": "amount of memory it's just really slow like it's got the same to go complexity but that popping and pushing from the",
    "start": "1334750",
    "end": "1341590"
  },
  {
    "text": "heap and that constant moving stuff around we did loads of work optimizing this but it was really slow it stopped",
    "start": "1341590",
    "end": "1347260"
  },
  {
    "text": "doing it was just slow so these are like the different stages that you went through optimizing you know so Gotham",
    "start": "1347260",
    "end": "1353470"
  },
  {
    "text": "who's not here one of the other cortex developers had an idea that we could quickly scan over the chunks and detect",
    "start": "1353470",
    "end": "1358990"
  },
  {
    "text": "ones that don't overlap and produce really kind of simple naive iterators for those and that kind of reduces the",
    "start": "1358990",
    "end": "1364840"
  },
  {
    "text": "iteration problem down to just looking at three or four different streams of iterators still pretty slow it turns out",
    "start": "1364840",
    "end": "1371020"
  },
  {
    "text": "and the final solution we ended up with is instead of just in when you're iterating through a chunk iterating",
    "start": "1371020",
    "end": "1376060"
  },
  {
    "text": "through a series so there's just looking at a single sample look at a batch of samples and so I think the batch size we",
    "start": "1376060",
    "end": "1382570"
  },
  {
    "text": "tuned it like the backsides ended up being 12 not particularly big but it gets you almost back to doing it with",
    "start": "1382570",
    "end": "1388990"
  },
  {
    "text": "slices like really really close 90% of the speed but it gets you like oh one memory and it's I'm really proud of it",
    "start": "1388990",
    "end": "1395590"
  },
  {
    "text": "like I look at the code now and I'm like oh wow like I really don't understand I have to revise when I go and fix bugs in",
    "start": "1395590",
    "end": "1400960"
  },
  {
    "text": "that code and anyone familiar with like database engineering and building query engines we're very familiar with these",
    "start": "1400960",
    "end": "1406750"
  },
  {
    "text": "techniques like I didn't invent them we just implemented them in cortex so if anyone tells you that algorithms are",
    "start": "1406750",
    "end": "1413620"
  },
  {
    "text": "only used in interviews yeah this is like a great interview question I think we should use it so we've seen this",
    "start": "1413620",
    "end": "1420550"
  },
  {
    "start": "1418000",
    "end": "1533000"
  },
  {
    "text": "we've seen this diagram but you see like we've now moved on a little bit we've added two more to some caches in the",
    "start": "1420550",
    "end": "1427000"
  },
  {
    "text": "front of our stores so we added a an index cache this was awesome again I did this the challenge with the index cache",
    "start": "1427000",
    "end": "1434260"
  },
  {
    "text": "was very much that we need the index to be live you know it's the changing as we're writing more data",
    "start": "1434260",
    "end": "1440000"
  },
  {
    "text": "so you have to coordinate between the in jesters in when we introduced the index cash we had to hold chunks in the in",
    "start": "1440000",
    "end": "1446570"
  },
  {
    "text": "jesters for some time period 15 minutes and that meant that the index cash entries could be live for 15 minutes",
    "start": "1446570",
    "end": "1453950"
  },
  {
    "text": "could be fresh for 15 minutes and you have to keep those two things coordinated and you have to like make sure you do that so that every time you",
    "start": "1453950",
    "end": "1460250"
  },
  {
    "text": "do a query you're guaranteed to recover the chunks and the entries for all series that match the chunk memcache on",
    "start": "1460250",
    "end": "1466610"
  },
  {
    "text": "the other hand at least chunks the minute they hit storage they're immutable so the chunk memcache can can",
    "start": "1466610",
    "end": "1472820"
  },
  {
    "text": "hold stuff forever and all we found now really is that you've got to make sure your chunk memcache is really big I think we run",
    "start": "1472820",
    "end": "1478549"
  },
  {
    "text": "hundreds of gigabytes of chunk memcache in production and it's got pretty good",
    "start": "1478549",
    "end": "1485419"
  },
  {
    "text": "you know we were getting there we're starting to get a better performance out of this thing and this is where it starts to get fun we put out a design",
    "start": "1485419",
    "end": "1491299"
  },
  {
    "text": "doc had some comments from the community and we introduced what we call the query front-end and this is where we start doing our own load balancing oh yeah",
    "start": "1491299",
    "end": "1497990"
  },
  {
    "text": "nourish it won't work with server messages here either so we were talking",
    "start": "1497990",
    "end": "1504529"
  },
  {
    "text": "about how to make cortex work with service measures but so now the query is get told what queries to execute by the",
    "start": "1504529",
    "end": "1510080"
  },
  {
    "text": "query front-end and this gave us an opportunity to also introduce query results caching so in the query as we",
    "start": "1510080",
    "end": "1516620"
  },
  {
    "text": "well we've actually will go into a lot more detail about what we do in the query front-end so you can see how the",
    "start": "1516620",
    "end": "1522470"
  },
  {
    "text": "the point I'm trying to make really is we cache a lot in cortex at every single level there every opportunity we will",
    "start": "1522470",
    "end": "1528830"
  },
  {
    "text": "try and cache the result and and this has had huge improvements to performance so what is the query front-end what does",
    "start": "1528830",
    "end": "1535940"
  },
  {
    "start": "1533000",
    "end": "1674000"
  },
  {
    "text": "it do did you get a query this is the same query we had earlier because consistency is good and first we",
    "start": "1535940",
    "end": "1541700"
  },
  {
    "text": "eventually know no fully consistent so the first thing we do is we align the",
    "start": "1541700",
    "end": "1547279"
  },
  {
    "text": "start and end of the queries with the step so in Prometheus you provide a start and end in a step and like the",
    "start": "1547279",
    "end": "1553340"
  },
  {
    "text": "step might be 30 seconds and it effectively tell you how many data points your query is going to return in",
    "start": "1553340",
    "end": "1559039"
  },
  {
    "text": "a lot of you eyes and in earlier versions of graph honor those two things would be unaligned and this is makes it",
    "start": "1559039",
    "end": "1565399"
  },
  {
    "text": "really hard to cache the results because basically every time we refresh the page will get subtly different results",
    "start": "1565399",
    "end": "1570919"
  },
  {
    "text": "modern versions of Gravano will align them in the client side and so this is a no op but just for backwards",
    "start": "1570919",
    "end": "1576440"
  },
  {
    "text": "compatibility we we add this little alignment in here and it massively increases the cache ability the next",
    "start": "1576440",
    "end": "1582380"
  },
  {
    "text": "step we add is we split the queries up we split them up by day this is configurable but the most effective we've found is by day because that",
    "start": "1582380",
    "end": "1589160"
  },
  {
    "text": "actually aligns really nicely with how we shot our index so that means if you",
    "start": "1589160",
    "end": "1594890"
  },
  {
    "text": "do a 30-day query it splits into 30 individual queries yeah now to the nice",
    "start": "1594890",
    "end": "1600740"
  },
  {
    "text": "thing is you can you can execute those in power level Oh before we do that we then cache the results of the query at",
    "start": "1600740",
    "end": "1605900"
  },
  {
    "text": "this step this helps bound the size of the entries in the mem cache for the query results",
    "start": "1605900",
    "end": "1611120"
  },
  {
    "text": "and generally means you don't have to do too much maths when you're kind of figuring out what bits are cached and",
    "start": "1611120",
    "end": "1617090"
  },
  {
    "text": "what bits aren't cached and it can cope with missing bits in the cache you know if you did a query here for an hour's",
    "start": "1617090",
    "end": "1623360"
  },
  {
    "text": "worth of data and a query here for an hour's worth of data you can you can fill it in the bit in the middle and cortex will figure out which bit needs",
    "start": "1623360",
    "end": "1629690"
  },
  {
    "text": "to be you know computed and go and dispatch that then the final bits we",
    "start": "1629690",
    "end": "1635030"
  },
  {
    "text": "actually dispatch the queries out to the query or in parallel so a 30-day query will do 30 sub queries some of them",
    "start": "1635030",
    "end": "1640490"
  },
  {
    "text": "might get cached some of them might already have been calculated the rest of them will get processed in parallel in",
    "start": "1640490",
    "end": "1646130"
  },
  {
    "text": "fact we actually do a step more than that they actually get put in a queue and then we do kind of fair quality of",
    "start": "1646130",
    "end": "1651290"
  },
  {
    "text": "service between tenants so that one tenant can't come along and do a 120-day query and kill another tenant who's just",
    "start": "1651290",
    "end": "1657470"
  },
  {
    "text": "trying to do like little one-hour queries and so there's a queue and then we dispatch them do not take that as a",
    "start": "1657470",
    "end": "1663350"
  },
  {
    "text": "challenge I mean yeah I think there's",
    "start": "1663350",
    "end": "1669200"
  },
  {
    "text": "still some work to be done on the quality on Tom's server so how good did",
    "start": "1669200",
    "end": "1675260"
  },
  {
    "start": "1674000",
    "end": "1721000"
  },
  {
    "text": "this get I mean I know unfortunately I haven't didn't record like methodically like performance results from before we",
    "start": "1675260",
    "end": "1682040"
  },
  {
    "text": "did all this work but these are results from last week and our average great performance and you can really see the effect of caching in these numbers RFU",
    "start": "1682040",
    "end": "1689090"
  },
  {
    "text": "creative performance which is basically when you hit the cache is 50 milliseconds like that that's I'm pretty",
    "start": "1689090",
    "end": "1695270"
  },
  {
    "text": "happy with that number I'm 99 across this is across our entire production fleet which is involving some very large",
    "start": "1695270",
    "end": "1702440"
  },
  {
    "text": "very several customers who who luckily aren't in the room is about 500 milliseconds I",
    "start": "1702440",
    "end": "1708320"
  },
  {
    "text": "still think we've got a little bit more work to do but I'm considering some of these queries are give me a year's worth of data over 800,000 time series I'm",
    "start": "1708320",
    "end": "1715640"
  },
  {
    "text": "actually pretty proud of that number so that's it that sound we've optimized",
    "start": "1715640",
    "end": "1723260"
  },
  {
    "start": "1721000",
    "end": "1757000"
  },
  {
    "text": "queries in cortex I think one last closing comment most talks about",
    "start": "1723260",
    "end": "1728300"
  },
  {
    "text": "distributed time series databases seem to focus on the ingestion path every talk I've given about cortex has talked",
    "start": "1728300",
    "end": "1734390"
  },
  {
    "text": "about how ingestion is hard and diming wrong ingestion is really hard but as Brian said we've been doing this project",
    "start": "1734390",
    "end": "1740480"
  },
  {
    "text": "for about three years and I one of the things I'm really happy with and really proud of is the fact that we've kind of",
    "start": "1740480",
    "end": "1745700"
  },
  {
    "text": "solved most of the problems we had at least in the ingestion path and we've got time to spend on optimizing the",
    "start": "1745700",
    "end": "1751250"
  },
  {
    "text": "queries and it's like I think is a good sign of the maturity of the project that we've got to spend so much time there yeah so we should say repeat it's an",
    "start": "1751250",
    "end": "1760700"
  },
  {
    "start": "1757000",
    "end": "1789000"
  },
  {
    "text": "open source project it's a CNC F sandbox project we are very keen to get people",
    "start": "1760700",
    "end": "1766490"
  },
  {
    "text": "involved please try it out please file bugs please please please file pr's to",
    "start": "1766490",
    "end": "1774110"
  },
  {
    "text": "fix bugs we have a slack you can join ask questions join in",
    "start": "1774110",
    "end": "1781940"
  },
  {
    "text": "so with that has anyone got any questions I should run around with a mic um how did I get to be the one running",
    "start": "1781940",
    "end": "1787790"
  },
  {
    "text": "around locked out you can shout they will shout one of the peter savio you're the nearest you",
    "start": "1787790",
    "end": "1793400"
  },
  {
    "start": "1789000",
    "end": "1826000"
  },
  {
    "text": "weren't the first so we started implementing tunnels we posted and now I",
    "start": "1793400",
    "end": "1799250"
  },
  {
    "text": "saw m3 and I saw cortex and I wonder when to choose which you want you want to ask me the author of cortex which one",
    "start": "1799250",
    "end": "1806420"
  },
  {
    "text": "you should choose",
    "start": "1806420",
    "end": "1808870"
  },
  {
    "text": "I mean we're being recorded so I'll be nice okay you should choose cortex all",
    "start": "1812790",
    "end": "1818670"
  },
  {
    "text": "right you want to add anything to that Brian okay fine yeah so I mean the",
    "start": "1818670",
    "end": "1828300"
  },
  {
    "text": "they're solving the same problem but with very different engineering trade-offs you know em threes they wrote",
    "start": "1828300",
    "end": "1835830"
  },
  {
    "text": "their own database they didn't hear that piece of advice",
    "start": "1835830",
    "end": "1840980"
  },
  {
    "text": "thanos palace really the similarities are greater than the differences with",
    "start": "1842000",
    "end": "1848850"
  },
  {
    "text": "cortex but but the nose the the latest data is at the leaf you know any query",
    "start": "1848850",
    "end": "1854970"
  },
  {
    "text": "which is up-to-date is hitting your older Prometheus servers cortex brings the data centrally so there's quite a",
    "start": "1854970",
    "end": "1862140"
  },
  {
    "text": "big philosophical difference and also the multi-tenancy you know those those",
    "start": "1862140",
    "end": "1868170"
  },
  {
    "text": "particular things that the fact that you all the data is owned and stored centrally and multi-tenancy separating",
    "start": "1868170",
    "end": "1876210"
  },
  {
    "text": "one set of people from another those those features certainly appeal in certain cases if those aren't your cases",
    "start": "1876210",
    "end": "1883290"
  },
  {
    "text": "I don't know why has different engineering trade-offs that's that's as far as I go",
    "start": "1883290",
    "end": "1888560"
  },
  {
    "text": "another question back I think you were first I just add to the fantasy cortex",
    "start": "1888560",
    "end": "1894120"
  },
  {
    "text": "debate dannis got easy to use they got it right from day zero yeah so first of",
    "start": "1894120",
    "end": "1899340"
  },
  {
    "text": "all I also like lasers those are nice second we actually started using cortex",
    "start": "1899340",
    "end": "1905400"
  },
  {
    "text": "a little bit but then didn't quite work so we started using the hosted version from girl fauna and it works really well",
    "start": "1905400",
    "end": "1911610"
  },
  {
    "text": "but we just get like these random for two ones and and like weird so 41 I",
    "start": "1911610",
    "end": "1918210"
  },
  {
    "text": "think too many requests okay we have we have rate 49 yeah we have rate limit on",
    "start": "1918210",
    "end": "1924450"
  },
  {
    "text": "queries and we have rate limits on rights as well I mean not a pitch but talk to one of our support reps we can",
    "start": "1924450",
    "end": "1929580"
  },
  {
    "text": "raise your regular oh it's you know we have a lot of clients there are there are other okay anyways but so if we want",
    "start": "1929580",
    "end": "1936929"
  },
  {
    "text": "to run our own because we might want to run them like for example on BigTable on top of big",
    "start": "1936929",
    "end": "1942279"
  },
  {
    "text": "table or on a replicated GCS bucket so we might want to run our own is that",
    "start": "1942279",
    "end": "1948610"
  },
  {
    "text": "like just plug and play from that and is there a migration path it's getting more",
    "start": "1948610",
    "end": "1955240"
  },
  {
    "text": "plug-and-play the the work we did in the lead up to cubic on were to enable that demo to make it much easier to spin up a",
    "start": "1955240",
    "end": "1962020"
  },
  {
    "text": "cortex cluster is all about helping people who aren't Brian and I start their own cortex clusters so there's now",
    "start": "1962020",
    "end": "1968470"
  },
  {
    "text": "a doc to show you how to get started there's now deep you know example config we're going to be working hard over the",
    "start": "1968470",
    "end": "1973570"
  },
  {
    "text": "next weeks and months to document more and more and make it easier to do this yeah when we started we just",
    "start": "1973570",
    "end": "1978720"
  },
  {
    "text": "extrapolated this from the code yeah yeah yeah a little bit hard cortex used to you know two years ago three years",
    "start": "1978720",
    "end": "1984789"
  },
  {
    "text": "ago it had no Doc's so we're trying hard to be better but also like if you've learned anything from running it a good",
    "start": "1984789",
    "end": "1991120"
  },
  {
    "text": "way to get involved with the project is to contribute docs and so you know if you you know found anything incorrect or",
    "start": "1991120",
    "end": "1996940"
  },
  {
    "text": "found anything it's not documented like you know write it down and we'll we'll merge that you know really quickly yeah",
    "start": "1996940",
    "end": "2002510"
  },
  {
    "text": "thank you thank you Brian yeah other hosted cortex other hosted prometheus as",
    "start": "2002510",
    "end": "2010860"
  },
  {
    "start": "2005000",
    "end": "2051000"
  },
  {
    "text": "a service are available but when you're like open on the Internet to absolutely",
    "start": "2010860",
    "end": "2016230"
  },
  {
    "text": "anyone who wants to show up and I'm trying to get to you but I I thought there was like an aisle down the middle or this is just not happening is it let",
    "start": "2016230",
    "end": "2023580"
  },
  {
    "text": "me just finish my point the the you know like we're kind of open on the internet to anyone who wants to throw any kind of",
    "start": "2023580",
    "end": "2030380"
  },
  {
    "text": "socket at us and and so yes you have to put rate limiters in you have to put protection many many levels and those",
    "start": "2030380",
    "end": "2040980"
  },
  {
    "text": "levels are configurable you know cortex is part tenant configurable on all the limits so it's a fact of life yeah okay",
    "start": "2040980",
    "end": "2048388"
  },
  {
    "text": "go ahead hi I was wondering how a line",
    "start": "2048389",
    "end": "2056010"
  },
  {
    "text": "with specification are you I mean there has been very little soup chorus",
    "start": "2056010",
    "end": "2061440"
  },
  {
    "text": "recently it was",
    "start": "2061440",
    "end": "2064520"
  },
  {
    "text": "okay so we're we up today we try and stay up-to-date with the latest release",
    "start": "2068760",
    "end": "2073980"
  },
  {
    "text": "of Prometheus we just vendor the same code so it's not as if we have our own implementation of prompt QR we just you",
    "start": "2073980",
    "end": "2080128"
  },
  {
    "text": "know so with the potato we're up to date it's a short answer if you ever find a way if you ever find a way we're not up",
    "start": "2080129",
    "end": "2086220"
  },
  {
    "text": "to date and then file a bug and it just means we need to update our vendor we do it quite proactively though the ones you",
    "start": "2086220",
    "end": "2092250"
  },
  {
    "text": "reference about sub-queries there was a bug and we fixed it are you using the",
    "start": "2092250",
    "end": "2101400"
  },
  {
    "text": "same code for the function for example there's a extradition in the rate",
    "start": "2101400",
    "end": "2107250"
  },
  {
    "text": "function of a delta function of royalties are you using the same color I was doing the same extra operation yeah",
    "start": "2107250",
    "end": "2112859"
  },
  {
    "text": "we literally vendor the Prometheus query engine parser and execution even like",
    "start": "2112859",
    "end": "2117960"
  },
  {
    "text": "the chunked compression that Brian alluded to is from the Prometheus codebase as well like we've we've",
    "start": "2117960",
    "end": "2123210"
  },
  {
    "text": "effectively taken Prometheus broke it up into little bits and added our own glue between them to do all the distributed systems work but we only get one",
    "start": "2123210",
    "end": "2129420"
  },
  {
    "text": "question so right we've last one now so choose wisely Brian last one go on one",
    "start": "2129420",
    "end": "2137310"
  },
  {
    "start": "2132000",
    "end": "2212000"
  },
  {
    "text": "more okay first I try to take this have",
    "start": "2137310",
    "end": "2147420"
  },
  {
    "text": "to hold it okay for instance if we want to have global distributed parameters",
    "start": "2147420",
    "end": "2154260"
  },
  {
    "text": "and push data into cortex what would you advise if it's like easy as like pushing",
    "start": "2154260",
    "end": "2162690"
  },
  {
    "text": "data or should we do something else special yeah just do it yeah I mean wow",
    "start": "2162690",
    "end": "2171720"
  },
  {
    "text": "so so you in terms of can both ends of the wire handle high latency yes the the",
    "start": "2171720",
    "end": "2180830"
  },
  {
    "text": "Prometheus sending side will will shard the sending channel to cope with the",
    "start": "2180830",
    "end": "2188490"
  },
  {
    "text": "fact that you might have like a 200 millisecond round-trip time or something like that so that'll work fine on the",
    "start": "2188490",
    "end": "2194910"
  },
  {
    "text": "receiving side there might be a question about whether you care about replicating your data geographically that we punt",
    "start": "2194910",
    "end": "2202410"
  },
  {
    "text": "to the Dynamo DBS and the big tables and and so on so so yeah just you know party",
    "start": "2202410",
    "end": "2208290"
  },
  {
    "text": "on geographically distribute the heck of it it's up to you one more would you reckon",
    "start": "2208290",
    "end": "2213960"
  },
  {
    "start": "2212000",
    "end": "2317000"
  },
  {
    "text": "one more yeah one more gone you choose quickly thank you sign closer so it",
    "start": "2213960",
    "end": "2224130"
  },
  {
    "text": "looks like the big advantage of cortex over alternatives is there multi-tenancy could you explain a bit more how how",
    "start": "2224130",
    "end": "2229650"
  },
  {
    "text": "does it work and from the API cortex or prom to use API perspective so the the",
    "start": "2229650",
    "end": "2235200"
  },
  {
    "text": "easiest way to explain it is on the way in when you're sending data you have to provide an extra HTTP header that says",
    "start": "2235200",
    "end": "2240750"
  },
  {
    "text": "what tenon is for and then on the way out when you're doing queries you have to provide the same header and then",
    "start": "2240750",
    "end": "2246690"
  },
  {
    "text": "every single data structure every index every storage system within cortex is keyed by that in that thing you provide",
    "start": "2246690",
    "end": "2254490"
  },
  {
    "text": "and it can be anything like the point I think you made sorry I've got the mic so the point you made that I thought was really good in the last talk was there's",
    "start": "2254490",
    "end": "2261960"
  },
  {
    "text": "no API to cortex to create a new tenant like tenon data structures are created",
    "start": "2261960",
    "end": "2267300"
  },
  {
    "text": "on demand so if data comes in for tenant one and we don't have an in-memory data structure for it we just created this",
    "start": "2267300",
    "end": "2274170"
  },
  {
    "text": "also means that any kind of authentication and authorization is beyond the scope of cortex the expectation is your stick and nginx to",
    "start": "2274170",
    "end": "2280800"
  },
  {
    "text": "do HTTP basic in front of it and then put that HTTP basic in your remote right",
    "start": "2280800",
    "end": "2286020"
  },
  {
    "text": "pastor from Prometheus to do authentication now you can also with the",
    "start": "2286020",
    "end": "2301680"
  },
  {
    "text": "recent changes you can turn it all off as well which has made that demo possible that demo wasn't multi-tenant single tenant anyway we're out of time",
    "start": "2301680",
    "end": "2307770"
  },
  {
    "text": "now so thank you very much everybody [Applause]",
    "start": "2307770",
    "end": "2313360"
  }
]
[
  {
    "start": "0",
    "end": "103000"
  },
  {
    "text": "so thank you all for for coming to our talk reaching 5 million messaging connections on kubernetes so I'm sure",
    "start": "30",
    "end": "8309"
  },
  {
    "text": "that some of you in the audience might be wondering why a 50 year old audio",
    "start": "8309",
    "end": "13440"
  },
  {
    "text": "company and a product development company from Toronto or on stage talking about such a thing so allow me to",
    "start": "13440",
    "end": "21029"
  },
  {
    "text": "demonstrate and all things going well with conference Wi-Fi in cellular Alexa play",
    "start": "21029",
    "end": "28619"
  },
  {
    "text": "lonely boy by the Black Keys on stage",
    "start": "28619",
    "end": "33559"
  },
  {
    "text": "lonely boy by the Black Keys from Dylan Spotify playing on stage",
    "start": "34730",
    "end": "41180"
  },
  {
    "text": "Alexa power offstage okay so really",
    "start": "48320",
    "end": "55380"
  },
  {
    "text": "simple problem right these two devices I spoke into this one this one started playing music they can even see each",
    "start": "55380",
    "end": "62129"
  },
  {
    "text": "other and they're loaded with wireless antennas this really is it's a very very simple problem right well it turns out",
    "start": "62129",
    "end": "69540"
  },
  {
    "text": "it's actually quite difficult and that's why Dave and I are here today to share the lessons but his team learned the",
    "start": "69540",
    "end": "75540"
  },
  {
    "text": "hard way and we connected Bose connected with connected to help us develop a",
    "start": "75540",
    "end": "82020"
  },
  {
    "text": "large-scale prototype of a 100% cloud native solution that supports at least 5",
    "start": "82020",
    "end": "88410"
  },
  {
    "text": "million sports smart speakers I'll just take a few short minutes to explain our",
    "start": "88410",
    "end": "93750"
  },
  {
    "text": "problem domain and then Dave will take you through the technical stumbling blocks that his team demolished one by",
    "start": "93750",
    "end": "99479"
  },
  {
    "text": "one on the way to proving out a solution so to solve this problem why do you even",
    "start": "99479",
    "end": "106920"
  },
  {
    "text": "need the cloud well as we say in New England you can't get there from here",
    "start": "106920",
    "end": "112289"
  },
  {
    "text": "there simply is no direct interface that exists between these two devices so it",
    "start": "112289",
    "end": "117330"
  },
  {
    "text": "actually takes hundreds of miles of networking to bridge this 3-foot gap right here so let's start with the the",
    "start": "117330",
    "end": "125970"
  },
  {
    "text": "Amazon echo dot the actual voice marts live in amazon's cloud not in the device itself and when I speak my voice",
    "start": "125970",
    "end": "133620"
  },
  {
    "text": "recording is sent up to the electric cloud for processing and once Amazon actually determined what it is that I'm",
    "start": "133620",
    "end": "139890"
  },
  {
    "text": "trying to do then it hands off the instructions to the Bose cloud to handle and we lovingly refer to our Bose cloud",
    "start": "139890",
    "end": "147450"
  },
  {
    "text": "as Galapagos and this is where the messaging connections come into play so",
    "start": "147450",
    "end": "152610"
  },
  {
    "text": "like any other piece of Wi-Fi connected gear in your home it's not actually directly exposed on the open Internet so",
    "start": "152610",
    "end": "160050"
  },
  {
    "text": "we all have firewalls in place on our home routers so these devices can initiate messages out of our home but",
    "start": "160050",
    "end": "166650"
  },
  {
    "text": "never ever allow direct unsolicited messages to come in so the best solution",
    "start": "166650",
    "end": "172740"
  },
  {
    "text": "to solve that problem is to set up a persistent line when the speaker first powers up and we chose",
    "start": "172740",
    "end": "179230"
  },
  {
    "text": "MQTT and we have a bi-directional WebSocket running from every one of these speakers to the cloud so that it",
    "start": "179230",
    "end": "186280"
  },
  {
    "text": "can basically receive these unsolicited messages at any point in time for even a",
    "start": "186280",
    "end": "192100"
  },
  {
    "text": "few thousand products this solution is obvious it's very tenable scaling is the crux of",
    "start": "192100",
    "end": "197590"
  },
  {
    "text": "the problem managing millions of connections through a central broker is a tremendous challenge and so hopefully",
    "start": "197590",
    "end": "204250"
  },
  {
    "text": "at this point you've got a sense for the problem that we set out to solve and a couple of years ago when I looked around",
    "start": "204250",
    "end": "210340"
  },
  {
    "text": "for a suitable solution and I actually came up empty there are some cloud",
    "start": "210340",
    "end": "216310"
  },
  {
    "text": "systems out there some managed services that we could have gone with that scales to hundreds of thousands of connections",
    "start": "216310",
    "end": "221800"
  },
  {
    "text": "but we could not find any that would actually scale to millions so as we waited for the industry to",
    "start": "221800",
    "end": "227260"
  },
  {
    "text": "catch up we needed to find some smart people to partner with to prove out that this was even possible and Dave was the",
    "start": "227260",
    "end": "233770"
  },
  {
    "text": "leader of these smart people and connected work really helped us prove out that a kubernetes based solution",
    "start": "233770",
    "end": "240460"
  },
  {
    "text": "could be both cost-effective and reached this tremendous scale of 5 million speakers in the wild always connected to",
    "start": "240460",
    "end": "247600"
  },
  {
    "text": "our cloud so Dave's going to walk you through what it actually took to solve this sort of a problem thank you darling",
    "start": "247600",
    "end": "256320"
  },
  {
    "text": "so just to set the stage where I'm coming from I'm just a dev standing in",
    "start": "256320",
    "end": "264220"
  },
  {
    "start": "259000",
    "end": "298000"
  },
  {
    "text": "front of a room of cloud engineers asking you to love me so when you work as an app dev and in",
    "start": "264220",
    "end": "271120"
  },
  {
    "text": "the web scaling a web app is a pretty solved problem load balancing sessions",
    "start": "271120",
    "end": "276810"
  },
  {
    "text": "you see it every day with massive websites messaging is another thing entirely so this is just about just as",
    "start": "276810",
    "end": "284980"
  },
  {
    "text": "much about the discovery of what does and doesn't work and how kubernetes",
    "start": "284980",
    "end": "290320"
  },
  {
    "text": "would change how we worked we iterated quickly there's lots we could have done but if it was working we just ran with",
    "start": "290320",
    "end": "296080"
  },
  {
    "text": "it so the team four people two teams",
    "start": "296080",
    "end": "301650"
  },
  {
    "start": "298000",
    "end": "325000"
  },
  {
    "text": "makers and breakers the makers focused on building the system the the breakers",
    "start": "301650",
    "end": "308140"
  },
  {
    "text": "were focused on building the test rig we could move people around teams to get exposure to both sides we grew together",
    "start": "308140",
    "end": "314580"
  },
  {
    "text": "we found each other's weak points it was a really good dynamic so we're gonna talk about the stack then the testing",
    "start": "314580",
    "end": "321580"
  },
  {
    "text": "process and finally our key learnings so let's get started so we're gonna go from",
    "start": "321580",
    "end": "329020"
  },
  {
    "start": "325000",
    "end": "341000"
  },
  {
    "text": "the ground up what our infrastructure looks like and why are we doing this again there was no off-the-shelf IOT",
    "start": "329020",
    "end": "336040"
  },
  {
    "text": "that gives us the scale and flexibility that we think we can achieve so",
    "start": "336040",
    "end": "341790"
  },
  {
    "start": "341000",
    "end": "384000"
  },
  {
    "text": "Galapagos this is a kubernetes rollout on AWS not eks a small team in the room",
    "start": "341790",
    "end": "350380"
  },
  {
    "text": "here at Bose was responsible for this very impressive deployment it's deployed by a terraform and ansible single region",
    "start": "350380",
    "end": "357220"
  },
  {
    "text": "multi AZ and each of my team got a full",
    "start": "357220",
    "end": "362350"
  },
  {
    "text": "row role out of the stack mini coop is great but being able to spin up the full",
    "start": "362350",
    "end": "368050"
  },
  {
    "text": "stack was really key if you are going to build something at scale you really have to test it at scale the",
    "start": "368050",
    "end": "374800"
  },
  {
    "text": "reproduce environment reproducible environment was really handy we were able to change the compute instances underneath each of the nodes and the",
    "start": "374800",
    "end": "381340"
  },
  {
    "text": "resources very easily for us so our solution model as mentioned we used mqtt",
    "start": "381340",
    "end": "387430"
  },
  {
    "start": "384000",
    "end": "407000"
  },
  {
    "text": "which is the dominant communications protocol in IOT it's lightweight binary",
    "start": "387430",
    "end": "392860"
  },
  {
    "text": "payload agnostic persistent WebSocket connections but what's in the cloud have",
    "start": "392860",
    "end": "397930"
  },
  {
    "text": "you ever had to describe this to your parents to them it's just magic what we actually",
    "start": "397930",
    "end": "404139"
  },
  {
    "text": "used was for an MQ so this is our kind",
    "start": "404139",
    "end": "409329"
  },
  {
    "start": "407000",
    "end": "438000"
  },
  {
    "text": "of end-to-end stack so on kubernetes we had h a proxy as our ingress and load balancer we had Vern and Q as our",
    "start": "409329",
    "end": "416289"
  },
  {
    "text": "message broker we built our own custom little service very uncreated Lee called the listening service that listens for",
    "start": "416289",
    "end": "423519"
  },
  {
    "text": "device Status Messages which is what we are simulating all of the messages coming up from device are then",
    "start": "423519",
    "end": "428679"
  },
  {
    "text": "publishing through to Cassandra which is going to store a shadow version of the device status the volume when it's",
    "start": "428679",
    "end": "435519"
  },
  {
    "text": "playing what its firmware version is so component by component seems to be a",
    "start": "435519",
    "end": "442839"
  },
  {
    "start": "438000",
    "end": "485000"
  },
  {
    "text": "heck of a lot of HTTP ingress examples in kubernetes not a lot of tcp we",
    "start": "442839",
    "end": "448509"
  },
  {
    "text": "weren't using the HTTP upgrade we were just using straight up WebSockets are",
    "start": "448509",
    "end": "454689"
  },
  {
    "text": "there other people doing tcp and grass it's very hey there you are a little hard to find examples so ingress is",
    "start": "454689",
    "end": "462039"
  },
  {
    "text": "confusing so we chose h a proxy it's the de facto standard for reverse proxy load",
    "start": "462039",
    "end": "468249"
  },
  {
    "text": "balancing it is rock-solid it used a ridiculously low amount of",
    "start": "468249",
    "end": "473889"
  },
  {
    "text": "resources for a ridiculously high number of connections so TCP load balancing for",
    "start": "473889",
    "end": "479259"
  },
  {
    "text": "WebSockets quite a bit less confusing than the inter ingress examples that I",
    "start": "479259",
    "end": "484989"
  },
  {
    "text": "could find message broker we chose Vern MQ it's a high-performance open source",
    "start": "484989",
    "end": "491110"
  },
  {
    "start": "485000",
    "end": "589000"
  },
  {
    "text": "distributed MQTT broker built on Erlang OTP Erlang OTP is used very heavily in",
    "start": "491110",
    "end": "497139"
  },
  {
    "text": "telephony originally really solid base for clustering and concurrency it scales vertically and horizontally and",
    "start": "497139",
    "end": "503259"
  },
  {
    "text": "commodity hardware Vernon T really stood out for us we wanted an open source",
    "start": "503259",
    "end": "508719"
  },
  {
    "text": "solution hive MQ who is proprietary mosquito has no clustering EMQ TTD",
    "start": "508719",
    "end": "516419"
  },
  {
    "text": "didn't have a good model for recovering after a network partition so vern mq",
    "start": "516419",
    "end": "523719"
  },
  {
    "text": "offered us clustering bridging which is a way to move messages between multiple",
    "start": "523719",
    "end": "529720"
  },
  {
    "text": "clusters of message brokers which is really key in our future consideration mqtt five shared subscriptions so this",
    "start": "529720",
    "end": "537190"
  },
  {
    "text": "is a way you can load balance the flow of messages since the listening service actually has to process every single",
    "start": "537190",
    "end": "543640"
  },
  {
    "text": "message that comes through the broker it would then round-robin through all the instances of the listening service it",
    "start": "543640",
    "end": "551260"
  },
  {
    "text": "give us fault tolerance and extremely well-defined netsplit behavior you can tell it if you can still register new",
    "start": "551260",
    "end": "557350"
  },
  {
    "text": "clients and how to behave during a net split and time order integrity which is",
    "start": "557350",
    "end": "563770"
  },
  {
    "text": "really important when you're talking with a speaker in your phone if you are telling it to raise the volume play",
    "start": "563770",
    "end": "569290"
  },
  {
    "text": "pause you want those to come in order very important it also had there are",
    "start": "569290",
    "end": "576700"
  },
  {
    "text": "other messaging solutions in cloud native there's gnats stomp lamp but they didn't seem to",
    "start": "576700",
    "end": "582100"
  },
  {
    "text": "support the array of features that we needed for an MQ really did it for us so",
    "start": "582100",
    "end": "590140"
  },
  {
    "start": "589000",
    "end": "620000"
  },
  {
    "text": "the glue this is our listening service we wrote this little component in golang",
    "start": "590140",
    "end": "595900"
  },
  {
    "text": "it's only about a hundred lines it subscribes to the verne mq with a shared",
    "start": "595900",
    "end": "601510"
  },
  {
    "text": "subscription to process all of the Status Messages that we were simulating and it writes directly to Cassandra so",
    "start": "601510",
    "end": "609400"
  },
  {
    "text": "this little component is super performant and so easy to build it was",
    "start": "609400",
    "end": "615850"
  },
  {
    "text": "incredible finally we have our datastore",
    "start": "615850",
    "end": "621340"
  },
  {
    "start": "620000",
    "end": "667000"
  },
  {
    "text": "Cassandra so Cassandra is a wide column store and non-relational DB it's able to",
    "start": "621340",
    "end": "626620"
  },
  {
    "text": "scale and maintain high availability without compromising performance it stores the most recent state of a device",
    "start": "626620",
    "end": "633370"
  },
  {
    "text": "to mirror other IOT offerings a digital duplicate of the device in the cloud we",
    "start": "633370",
    "end": "640120"
  },
  {
    "text": "were focused in this POC on write not read but what we needed to know is can",
    "start": "640120",
    "end": "646420"
  },
  {
    "text": "it handle the volume it did very easily so I won't be talking a heck of a lot",
    "start": "646420",
    "end": "651850"
  },
  {
    "text": "about Cassandra but it was a key component of our build so Cassandra was",
    "start": "651850",
    "end": "657430"
  },
  {
    "text": "absolutely performant fault-tolerant massively scalable and extremely stable",
    "start": "657430",
    "end": "666210"
  },
  {
    "text": "so how did we put this all on kubernetes all of our images we've custom-built for",
    "start": "666680",
    "end": "673829"
  },
  {
    "start": "667000",
    "end": "714000"
  },
  {
    "text": "everything they were all built on Alpine to give us a nice small image for Vern",
    "start": "673829",
    "end": "679440"
  },
  {
    "text": "MQ and Cassandra because they are clustering pieces of software we used a stateful set so it would bring up each",
    "start": "679440",
    "end": "684839"
  },
  {
    "text": "node in order give them a name and DNS that is consistent",
    "start": "684839",
    "end": "690660"
  },
  {
    "text": "we used a daemon set for H a proxy to make sure it was delivered to all of our ingress nodes we used a deployment for",
    "start": "690660",
    "end": "698490"
  },
  {
    "text": "the listening service and as an aside we also had Prometheus incra fauna to make sure we had some observability on the",
    "start": "698490",
    "end": "704220"
  },
  {
    "text": "cluster man there's a lot of proper nouns in kubernetes you have to as I'm",
    "start": "704220",
    "end": "710190"
  },
  {
    "text": "sure you were aware if you're in the room gets a bid to take getting used to so that's all of the build let's take a",
    "start": "710190",
    "end": "720060"
  },
  {
    "text": "look at the test rank so we chose Lucas this is what the other half of the team",
    "start": "720060",
    "end": "726990"
  },
  {
    "text": "was building we needed to customize a rig to simulate different client behaviors one to one publisher to",
    "start": "726990",
    "end": "733740"
  },
  {
    "text": "subscriber one-to-many fan-out gate crashing so we looked at things like MZ",
    "start": "733740",
    "end": "739680"
  },
  {
    "text": "bench and jmeter in fact run MQ has its own tests pre-built in MZ bench but",
    "start": "739680",
    "end": "745760"
  },
  {
    "text": "they're not very flexible they're really kind of built for request response not pub/sub you can do it but it's not as",
    "start": "745760",
    "end": "752760"
  },
  {
    "text": "flexible we decided not to go with it we went with Lucas so locus is a Python",
    "start": "752760",
    "end": "760620"
  },
  {
    "text": "based system it has a master node and it can instruct workers to do all kinds of",
    "start": "760620",
    "end": "766350"
  },
  {
    "text": "different behaviors based on what you want so this way we could simulate all",
    "start": "766350",
    "end": "772079"
  },
  {
    "text": "the behaviors we needed now we deployed this to bear ec2 instances we didn't want our kubernetes cluster competing",
    "start": "772079",
    "end": "778170"
  },
  {
    "text": "for resources so our high level architecture when you get to the end of",
    "start": "778170",
    "end": "783420"
  },
  {
    "start": "780000",
    "end": "810000"
  },
  {
    "text": "it you had locus on the outside and the",
    "start": "783420",
    "end": "789300"
  },
  {
    "text": "deployment of all the workers they go into H a proxy which was pointed at",
    "start": "789300",
    "end": "796529"
  },
  {
    "text": "Arverne MQ cluster on the other side of that the listening service has a shared subscription to all",
    "start": "796529",
    "end": "802350"
  },
  {
    "text": "of the messages coming through vern mq and it then in turns writes that to cassandra so on to testing will go",
    "start": "802350",
    "end": "812279"
  },
  {
    "start": "810000",
    "end": "841000"
  },
  {
    "text": "through a number of the issues this is by no means an exhaustive list it's always something",
    "start": "812279",
    "end": "817649"
  },
  {
    "text": "it's configuration networking resource limits cluster sizes most of these will",
    "start": "817649",
    "end": "822839"
  },
  {
    "text": "be on the build side but there were certainly challenges on the test side first hurdle in particular but this way",
    "start": "822839",
    "end": "829230"
  },
  {
    "text": "we can validate the entire throughput so we're gonna spin it up we're gonna make",
    "start": "829230",
    "end": "834720"
  },
  {
    "text": "one locus worker to see how many connections we can get so we can level set what kind of thing we can do with it",
    "start": "834720",
    "end": "840769"
  },
  {
    "text": "so a reminder we are going for five million persistent concurrent",
    "start": "840769",
    "end": "849529"
  },
  {
    "start": "841000",
    "end": "865000"
  },
  {
    "text": "connections all at the same time other platforms support tens even hundreds of",
    "start": "849529",
    "end": "855689"
  },
  {
    "text": "thousands of clients and devices but we need millions five million all at once",
    "start": "855689",
    "end": "862649"
  },
  {
    "text": "that's a different kettle of fish so obviously let's kick the tires how",
    "start": "862649",
    "end": "869189"
  },
  {
    "text": "many connections can I get with one worker what",
    "start": "869189",
    "end": "877010"
  },
  {
    "text": "memory CPU I'd have to go back and look but there's a we did a lot of component level testing around it just to see what",
    "start": "877010",
    "end": "883220"
  },
  {
    "text": "we needed I think we got about ten thousand at one point per worker but uh",
    "start": "883220",
    "end": "890750"
  },
  {
    "text": "so let's run the test let's take a look",
    "start": "890750",
    "end": "896269"
  },
  {
    "start": "895000",
    "end": "945000"
  },
  {
    "text": "at the first result damn it that was unexpected a little",
    "start": "896269",
    "end": "903410"
  },
  {
    "text": "underwhelming so underneath the hood we're using Python and we ran into a",
    "start": "903410",
    "end": "910130"
  },
  {
    "text": "problem with Python file descriptor limits the paho mqtt client and python is what we were using for our clients so",
    "start": "910130",
    "end": "917449"
  },
  {
    "text": "underneath that it's using Python and the Select system call so this is what",
    "start": "917449",
    "end": "922930"
  },
  {
    "text": "everything is a file descriptor so when you open a socket that's a file descriptor each connection requires one",
    "start": "922930",
    "end": "929600"
  },
  {
    "text": "for the MQTT broker and two sockets connected to each other so three file descriptors per connected 1,024 divided",
    "start": "929600",
    "end": "936589"
  },
  {
    "text": "by three rounded down that's 340 so why",
    "start": "936589",
    "end": "944240"
  },
  {
    "text": "did it block at that so the workaround we replace the Select call we tried",
    "start": "944240",
    "end": "951230"
  },
  {
    "text": "using a library called a sync i/o this was an utter failure this did not play",
    "start": "951230",
    "end": "957560"
  },
  {
    "text": "well with the locus concurrency model we had two different concurrency models fighting with one another so we rebuilt",
    "start": "957560",
    "end": "965660"
  },
  {
    "text": "Python there's a nice little constant called FD set size that's hard-coded",
    "start": "965660",
    "end": "972019"
  },
  {
    "text": "into Python you can have 1024 file descriptors and that's it did not expect",
    "start": "972019",
    "end": "977329"
  },
  {
    "text": "to begin this by recompiling the Python but there you go alright so let's get down to the next",
    "start": "977329",
    "end": "983089"
  },
  {
    "text": "test 700,000 connections well that's a bit better so what's the problem",
    "start": "983089",
    "end": "990730"
  },
  {
    "text": "configuration defaults and network address translation so we ran into an H",
    "start": "990730",
    "end": "997430"
  },
  {
    "text": "a proxy port exhaustion problem we ran into just a basic configuration limit",
    "start": "997430",
    "end": "1003490"
  },
  {
    "text": "that was the default in verne mq and the service abstraction we had Vern and Q",
    "start": "1003490",
    "end": "1008589"
  },
  {
    "text": "behind a service object in kubernetes and that's just another",
    "start": "1008589",
    "end": "1014020"
  },
  {
    "text": "place where you have an ad issue so if you're not familiar with not issues for",
    "start": "1014020",
    "end": "1019420"
  },
  {
    "text": "for anyone that's new to this sort of stuff you basically have a tuple of source IP and port destination IP and",
    "start": "1019420",
    "end": "1027250"
  },
  {
    "text": "port and your protocol you only have so many combinations that of those we did",
    "start": "1027250",
    "end": "1034300"
  },
  {
    "text": "not properly configure everything h8 proxy I think by default starts at port 30,000 so we had to fix that",
    "start": "1034300",
    "end": "1041199"
  },
  {
    "text": "so our workaround reconfigure everything",
    "start": "1041199",
    "end": "1047850"
  },
  {
    "start": "1042000",
    "end": "1102000"
  },
  {
    "text": "so fix the max connection setting in vern mq and add three more listeners",
    "start": "1047850",
    "end": "1053770"
  },
  {
    "text": "it's trivial to add more listeners for Vern and Q so we had four listeners on different ports we bypassed the",
    "start": "1053770",
    "end": "1059680"
  },
  {
    "text": "kubernetes service instead of pointing a chief proxy of the service we had it pointed at each individual for an mq",
    "start": "1059680",
    "end": "1065200"
  },
  {
    "text": "instance and we would round-robin through them each a proxy so we had it",
    "start": "1065200",
    "end": "1071500"
  },
  {
    "text": "Vern round-robin we had to increase the number of source ports that was my fault",
    "start": "1071500",
    "end": "1076960"
  },
  {
    "text": "we had to vertically scale the ingress nodes we ran into a problem AWS doesn't necessarily tell you exactly",
    "start": "1076960",
    "end": "1082870"
  },
  {
    "text": "how much bandwidth and how many I ops you get but we ran into an issue and as soon as we kicked up the instant size it",
    "start": "1082870",
    "end": "1088720"
  },
  {
    "text": "was working great so I even created a little Ruby Sinatra app that would query the kubernetes api",
    "start": "1088720",
    "end": "1095050"
  },
  {
    "text": "and it would return templated config 4h a proxy and prometheus and Griffin as a",
    "start": "1095050",
    "end": "1103240"
  },
  {
    "start": "1102000",
    "end": "1113000"
  },
  {
    "text": "little interlude considering all these problems discoverability configuration I really should have thought of something like a service mesh do you know where I",
    "start": "1103240",
    "end": "1109330"
  },
  {
    "text": "can find a talk about that it could be really helpful so our next result 1.1 million ok we",
    "start": "1109330",
    "end": "1119050"
  },
  {
    "text": "breached the million this is good our subscriptions fell off a cliff so",
    "start": "1119050",
    "end": "1124810"
  },
  {
    "text": "whenever you create a connection to the broker it would immediately subscribe to a unique subscription for its device you",
    "start": "1124810",
    "end": "1131740"
  },
  {
    "text": "know something like device slash and the ID of the device burn mq nodes were",
    "start": "1131740",
    "end": "1138010"
  },
  {
    "text": "being terminated by kubernetes kubernetes very helpfully brought them right back up",
    "start": "1138010",
    "end": "1143320"
  },
  {
    "text": "and as it was transferring all the session information and blew up another node and so we had this beautiful flap-flap-flap of nodes going up and",
    "start": "1143320",
    "end": "1149650"
  },
  {
    "text": "down this one was harder to figure out so we had to do a little more digging we",
    "start": "1149650",
    "end": "1159460"
  },
  {
    "start": "1154000",
    "end": "1213000"
  },
  {
    "text": "scaled for an MQ incrementally we went from 10 15 20 40 80 nodes now as a point",
    "start": "1159460",
    "end": "1165400"
  },
  {
    "text": "of comparison some of the biggest Erlang OTP clusters are about 200 nodes so we were already at about 40% of the largest",
    "start": "1165400",
    "end": "1171580"
  },
  {
    "text": "nodes but it didn't make a difference we made these huge clusters and it did that",
    "start": "1171580",
    "end": "1178660"
  },
  {
    "text": "made absolutely no difference we still pitched off a cliff at one point 1 million connections we're",
    "start": "1178660",
    "end": "1184000"
  },
  {
    "text": "running into some kind of resize reallocation problem under the hood Vernon hue is using level DB for all",
    "start": "1184000",
    "end": "1189370"
  },
  {
    "text": "sorts of metadata and subscriptions and something was obviously hitting its limit in all the meta data replication I",
    "start": "1189370",
    "end": "1196920"
  },
  {
    "text": "have to say do not wait to set up monitoring graph on ax and prometheus",
    "start": "1196920",
    "end": "1203440"
  },
  {
    "text": "were absolutely key in figuring this out using stern to tail the logs of all of our running pods were absolutely key in",
    "start": "1203440",
    "end": "1209980"
  },
  {
    "text": "finding all these problems so what was our workaround exponential back-off we",
    "start": "1209980",
    "end": "1218770"
  },
  {
    "start": "1213000",
    "end": "1231000"
  },
  {
    "text": "modified the clients to add a custom behavior so instead of connecting and then subscribing we would delay",
    "start": "1218770",
    "end": "1224320"
  },
  {
    "text": "subscriptions so they would happen at a decaying rate to make sure that we weren't overwhelming the vern mq server",
    "start": "1224320",
    "end": "1230940"
  },
  {
    "text": "vern mq recovered oh yeah",
    "start": "1230940",
    "end": "1236450"
  },
  {
    "start": "1231000",
    "end": "1250000"
  },
  {
    "text": "so rate-limiting may be a really key consideration in this sort of thing especially if you suddenly hit one of",
    "start": "1236450",
    "end": "1242520"
  },
  {
    "text": "these allocation problems or if you can figure out how to pre allocate all of these resources so the next result 1.5",
    "start": "1242520",
    "end": "1252180"
  },
  {
    "start": "1250000",
    "end": "1294000"
  },
  {
    "text": "million connections not quite as big a jump as hoped but we're getting there",
    "start": "1252180",
    "end": "1257840"
  },
  {
    "text": "our problem was the Erlang OTP scheduler so all of the schedulers went to 100%",
    "start": "1258620",
    "end": "1265650"
  },
  {
    "text": "utilization Erlang does these lightweight threads you might call them fibers but Erlang threads are a thing it",
    "start": "1265650",
    "end": "1271500"
  },
  {
    "text": "puts a scheduler on each CPU that it has available to it it auto automatically looks at how many CPUs it has available",
    "start": "1271500",
    "end": "1278010"
  },
  {
    "text": "and it puts a scheduler on it but everything chug to a halt increasing",
    "start": "1278010",
    "end": "1283710"
  },
  {
    "text": "resources didn't help again so we took these vern mq instances and we really beefed up the amount of resources that",
    "start": "1283710",
    "end": "1289980"
  },
  {
    "text": "it had available I think we were at about 12 CPUs so what went wrong",
    "start": "1289980",
    "end": "1296780"
  },
  {
    "start": "1294000",
    "end": "1328000"
  },
  {
    "text": "cgroups so in the containerized world c",
    "start": "1296780",
    "end": "1302100"
  },
  {
    "text": "groups are really key this is the way docker and container engines report the",
    "start": "1302100",
    "end": "1307290"
  },
  {
    "text": "amount of resources are available to your container Erlang OTP is not C group aware it configured itself to use for",
    "start": "1307290",
    "end": "1315510"
  },
  {
    "text": "CPUs it had 12 it just ignored them so we had to directly configure the number",
    "start": "1315510",
    "end": "1321780"
  },
  {
    "text": "of V CPUs that were available to it thankfully this got us to the next stage",
    "start": "1321780",
    "end": "1326940"
  },
  {
    "text": "so one to skip a few 99 1,004.50 m",
    "start": "1326940",
    "end": "1335790"
  },
  {
    "start": "1328000",
    "end": "1393000"
  },
  {
    "text": "8 5 million connections what was our blocker",
    "start": "1335790",
    "end": "1341000"
  },
  {
    "text": "resources again starting to get really frustrated I mean we got to four point",
    "start": "1342390",
    "end": "1348510"
  },
  {
    "text": "eight five million connections I mean we could say we made it to five million but you know it feels like you're lying to",
    "start": "1348510",
    "end": "1354360"
  },
  {
    "text": "yourself a little I know what's 150,000 between friends but as you can see on a",
    "start": "1354360",
    "end": "1360360"
  },
  {
    "text": "graph on a date dashboard we were so close but not enough to feel validated at full scale these tests took five or",
    "start": "1360360",
    "end": "1367800"
  },
  {
    "text": "six hours to get going we had to ramp up all of the connections we had to run it for a while we had to ramp down connections we had a testing budget we",
    "start": "1367800",
    "end": "1375420"
  },
  {
    "text": "blew through our monthly budget in a day sorry so we were getting ready for demos some",
    "start": "1375420",
    "end": "1385110"
  },
  {
    "text": "internal demos and we were getting so close so we started this running again we up the resources we get ready for our",
    "start": "1385110",
    "end": "1393690"
  },
  {
    "start": "1393000",
    "end": "1398000"
  },
  {
    "text": "internal demos we walk up on stage at our company in front of everyone five",
    "start": "1393690",
    "end": "1399390"
  },
  {
    "start": "1398000",
    "end": "1464000"
  },
  {
    "text": "million and one active WebSocket connections Thank You hot so 69",
    "start": "1399390",
    "end": "1411480"
  },
  {
    "text": "millisecond average latency from publisher to subscriber now this is important because 250 milliseconds is a",
    "start": "1411480",
    "end": "1418500"
  },
  {
    "text": "magic number in this world that is below human notice latency if you hit play on",
    "start": "1418500",
    "end": "1423870"
  },
  {
    "text": "your phone and it starts playing on your speaker in less than a quarter second it's a relatively imperceptible note",
    "start": "1423870",
    "end": "1430050"
  },
  {
    "text": "difference you don't notice it if you wait half a second that half a second is enough for your brain to go why is that",
    "start": "1430050",
    "end": "1435720"
  },
  {
    "text": "working we were publishing about nine",
    "start": "1435720",
    "end": "1441240"
  },
  {
    "text": "thousand seven hundred and seventy nine messages per second we had other tests that got as high as",
    "start": "1441240",
    "end": "1446730"
  },
  {
    "text": "twenty five thousand it depends on the use case this was just one of twelve scenarios that we ran we would",
    "start": "1446730",
    "end": "1453210"
  },
  {
    "text": "distribute the clients across different availability zones different regions",
    "start": "1453210",
    "end": "1458779"
  },
  {
    "text": "but we did it so what were our key learnings what did we learn through this",
    "start": "1460470",
    "end": "1467410"
  },
  {
    "start": "1464000",
    "end": "1470000"
  },
  {
    "text": "process and boy is it punishing mind your dependencies kubernetes does not",
    "start": "1467410",
    "end": "1474430"
  },
  {
    "start": "1470000",
    "end": "1507000"
  },
  {
    "text": "manage dependencies and relationships between workloads this is by design but",
    "start": "1474430",
    "end": "1479680"
  },
  {
    "text": "as an app developer this is not the pattern I'm used to we brought each service up in order so",
    "start": "1479680",
    "end": "1485890"
  },
  {
    "text": "we could configure each a proxy and Prometheus later I know you can mitigate this sort of thing with Hynek containers",
    "start": "1485890",
    "end": "1491320"
  },
  {
    "text": "and have a little listener on a particular port but it was a little confusing when you're looking at a clustered resource when do you say it is",
    "start": "1491320",
    "end": "1498520"
  },
  {
    "text": "available do you wait for one replica do you wait for half of them do you wait for all of them so that was something we",
    "start": "1498520",
    "end": "1505360"
  },
  {
    "text": "really have to think about experiment with your resource limits it is hard to",
    "start": "1505360",
    "end": "1511720"
  },
  {
    "start": "1507000",
    "end": "1527000"
  },
  {
    "text": "figure out what your limits are you have to try different workloads different scenarios until you push the pace you",
    "start": "1511720",
    "end": "1517570"
  },
  {
    "text": "cannot estimate do component level load tests you're going to need rate limiting",
    "start": "1517570",
    "end": "1523780"
  },
  {
    "text": "and there's no way around doing it at scale layers really troubled complicate",
    "start": "1523780",
    "end": "1532240"
  },
  {
    "start": "1527000",
    "end": "1567000"
  },
  {
    "text": "troubleshooting we had layers of networking resources ingress routing",
    "start": "1532240",
    "end": "1537660"
  },
  {
    "text": "abstraction on top of abstraction it's Turtles all the way down man mo layers",
    "start": "1537660",
    "end": "1543520"
  },
  {
    "text": "mo problems so with all these layers figuring out where to look is really key are you",
    "start": "1543520",
    "end": "1549790"
  },
  {
    "text": "looking right down at your ec2 level are you looking at your ingress your H a",
    "start": "1549790",
    "end": "1555130"
  },
  {
    "text": "proxy the service level abstraction is it the is it throughput through the Cassandra is it the broker itself it's",
    "start": "1555130",
    "end": "1562300"
  },
  {
    "text": "really hard this is why setting up monitoring early matters so much and",
    "start": "1562300",
    "end": "1568630"
  },
  {
    "start": "1567000",
    "end": "1604000"
  },
  {
    "text": "starting at scale is different than organic growth you break through one wall and you hit another immediately but",
    "start": "1568630",
    "end": "1576280"
  },
  {
    "text": "you got to get back up and keep going this doesn't invalidate what you've accomplished you literally break through one of these",
    "start": "1576280",
    "end": "1582280"
  },
  {
    "text": "walls five minutes later placed on the floor effortless effortless ly scaling",
    "start": "1582280",
    "end": "1588730"
  },
  {
    "text": "via kubernetes is a boring feature but it is a killer feature you don't realize how incredible it is",
    "start": "1588730",
    "end": "1595420"
  },
  {
    "text": "to be able to say double the size of my cluster just like that take pleasure in breaking those walls and finally our",
    "start": "1595420",
    "end": "1605680"
  },
  {
    "start": "1604000",
    "end": "1683000"
  },
  {
    "text": "solution was a lot cheaper so I can't share numbers that nice little orange line it is a major IOT platform provider",
    "start": "1605680",
    "end": "1612790"
  },
  {
    "text": "a little blue line is my team over time",
    "start": "1612790",
    "end": "1618100"
  },
  {
    "text": "every year you're going to expect to add more devices so cost decreased for our",
    "start": "1618100",
    "end": "1623500"
  },
  {
    "text": "workload initially over time we were more expensive you had to have people to build and monitor and keep track of all",
    "start": "1623500",
    "end": "1629920"
  },
  {
    "text": "the resources and handle it but the major IOT platform they build based on metrics not on resources it can",
    "start": "1629920",
    "end": "1637240"
  },
  {
    "text": "be a number of connections number of messages how many active connections how many stored messages how big is your",
    "start": "1637240",
    "end": "1643210"
  },
  {
    "text": "shadow store further in the middle of this experiment the cost model changed",
    "start": "1643210",
    "end": "1649390"
  },
  {
    "text": "on the one we were comparing against so you can't predict these changes you can't have cost predictability so you",
    "start": "1649390",
    "end": "1658930"
  },
  {
    "text": "even see it the two-year mark there's that I'm a good Canadian lad that's a hockey stick you can't predict those",
    "start": "1658930",
    "end": "1666850"
  },
  {
    "text": "kind of changes and if you are scaling your own resources are what determine",
    "start": "1666850",
    "end": "1673690"
  },
  {
    "text": "what scales not the metrics of what you're doing so we expected cheaper we did not expect",
    "start": "1673690",
    "end": "1679720"
  },
  {
    "text": "how much cheaper so in conclusion building a messaging service for",
    "start": "1679720",
    "end": "1686830"
  },
  {
    "start": "1683000",
    "end": "1705000"
  },
  {
    "text": "millions of devices is a unique challenge the blockers evolved as this solution grows deploying the specific",
    "start": "1686830",
    "end": "1694360"
  },
  {
    "text": "components in pursuit of a scaled outcome was only possible through the flexibility of kubernetes so thank you",
    "start": "1694360",
    "end": "1702340"
  },
  {
    "text": "to Cooper Nettie's and thank you for all of you listening [Applause] [Music]",
    "start": "1702340",
    "end": "1708140"
  },
  {
    "start": "1705000",
    "end": "1755000"
  },
  {
    "text": "[Applause] [Music] and I'll quickly say thank you very much",
    "start": "1708140",
    "end": "1714130"
  },
  {
    "text": "to my incredible team no team lead has been as lucky as me and thank you to the Bo's team the people that built and",
    "start": "1714130",
    "end": "1721030"
  },
  {
    "text": "rolled out that kubernetes deployment are here it has been an incredible experience any questions so register we",
    "start": "1721030",
    "end": "1769030"
  },
  {
    "start": "1755000",
    "end": "2034000"
  },
  {
    "text": "were cheating when we were doing this all the connections all the clients had a list of all of the ingress points of",
    "start": "1769030",
    "end": "1776590"
  },
  {
    "text": "each a proxy and it was just round-robin there's you know this is not an apples to apples comparison we were comparing",
    "start": "1776590",
    "end": "1782200"
  },
  {
    "text": "against an IOT platform but that included all kinds of extra things including that lovely little DNS at the",
    "start": "1782200",
    "end": "1789070"
  },
  {
    "text": "front that will distribute the load through for you yes sir how many active",
    "start": "1789070",
    "end": "1798280"
  },
  {
    "text": "connections per CPU that depends we're at the age a proxy level of trivial I",
    "start": "1798280",
    "end": "1805780"
  },
  {
    "text": "think we probably had on the order of 300 thousand connections going through a",
    "start": "1805780",
    "end": "1812020"
  },
  {
    "text": "single Lecce proxy instance I know you can get a lot more than that but that was using something like 20 Meg's of RAM",
    "start": "1812020",
    "end": "1817720"
  },
  {
    "text": "it was ridiculous and the CPU I don't think it ever went above 1% at the",
    "start": "1817720",
    "end": "1823179"
  },
  {
    "text": "runtime queue level I'd have to go back and check we had pretty beefy instances 12 CPUs probably on the order of 40 gigs",
    "start": "1823179",
    "end": "1831370"
  },
  {
    "text": "of RAM or so and most of our tests were conducted with 10 replicas so you can do",
    "start": "1831370",
    "end": "1838900"
  },
  {
    "text": "the math there are 5 million through 10 so about half a million there yeah we do",
    "start": "1838900",
    "end": "1850929"
  },
  {
    "text": "not use TLS for the test the idea being that if we wanted to use TLS we would terminate terminate it at the eh a proxy",
    "start": "1850929",
    "end": "1857109"
  },
  {
    "text": "level we were just trying to set a baseline in terms of number I mean we",
    "start": "1857109",
    "end": "1862119"
  },
  {
    "text": "conducted a vast number of tests with varying degrees of you know different numbers of HF proxy different numbers",
    "start": "1862119",
    "end": "1869559"
  },
  {
    "text": "and sizes of random queue clusters so there was a it's not easy to say what there was we did a huge number of",
    "start": "1869559",
    "end": "1877239"
  },
  {
    "text": "comparisons of different levels of replicas and what kind of resource",
    "start": "1877239",
    "end": "1882699"
  },
  {
    "text": "limits they had so at minimum we had ten replicas of the broker I think I think",
    "start": "1882699",
    "end": "1888069"
  },
  {
    "text": "we only had about six ingress nodes with H a proxy not entirely sure after look",
    "start": "1888069",
    "end": "1895169"
  },
  {
    "text": "at one point yeah we had more on different tests we tried fifteen we tried twenty other than that one time we",
    "start": "1898109",
    "end": "1904269"
  },
  {
    "text": "scaled up to eighty I don't think we ever went over twenty okay a gentleman there",
    "start": "1904269",
    "end": "1910709"
  },
  {
    "text": "how did we deal with so much uncertainty and in product management that's kind of",
    "start": "1922210",
    "end": "1928750"
  },
  {
    "text": "our sweet spot that's part of the fun we got to bring order to the chaos they",
    "start": "1928750",
    "end": "1934270"
  },
  {
    "text": "Bo's give us a very simple problem that has a very complex answer and they trusted us to just cope with it",
    "start": "1934270",
    "end": "1940960"
  },
  {
    "text": "we kept them in the loop the whole time we had one-on-ones with them every week but our lovely product manager Thomas",
    "start": "1940960",
    "end": "1949210"
  },
  {
    "text": "over here brought order to the chaos for us and we are a research company so we will used to hitting our heads against",
    "start": "1949210",
    "end": "1955690"
  },
  {
    "text": "Wolves repeatedly until breaking through so it was pretty standard pattern for us sorry had that gentleman there we did",
    "start": "1955690",
    "end": "1967300"
  },
  {
    "text": "not do a heck of a lot of tests with fault tolerance but basically for an MQ is able to it does have well-defined",
    "start": "1967300",
    "end": "1975490"
  },
  {
    "text": "netsplit behavior and it does reconcile eventually after you open up the",
    "start": "1975490",
    "end": "1980800"
  },
  {
    "text": "connection we didn't do a heck of a lot of tests that we were focus more on throughput but as far as we saw it was",
    "start": "1980800",
    "end": "1987130"
  },
  {
    "text": "able to heal split-brain pretty well without losing information oh yeah if",
    "start": "1987130",
    "end": "1995200"
  },
  {
    "text": "nodes go down you don't necessarily lose data there are sessions that are on each",
    "start": "1995200",
    "end": "2001590"
  },
  {
    "text": "individual vern mq node but once when you we intercepted you know the the sick",
    "start": "2001590",
    "end": "2007800"
  },
  {
    "text": "term and we it would vern mq would then transfer all of its sessions to another node and then another node would come up",
    "start": "2007800",
    "end": "2014460"
  },
  {
    "text": "and sessions would redistribute okay sorry I think this gentleman here",
    "start": "2014460",
    "end": "2021769"
  },
  {
    "text": "uh what was the reason these gentlemen",
    "start": "2021799",
    "end": "2027919"
  },
  {
    "text": "built a fantastic system for us to work on did the question was why not use AWS eks it actually didn't exist at the time",
    "start": "2027919",
    "end": "2034460"
  },
  {
    "start": "2034000",
    "end": "2323000"
  },
  {
    "text": "that we started I know that's true they announced it in the middle no no we were",
    "start": "2034460",
    "end": "2043009"
  },
  {
    "text": "firmly committed to upstream kubernetes we're very very happy with what we have right now I know we've rolled it",
    "start": "2043009",
    "end": "2055579"
  },
  {
    "text": "ourselves",
    "start": "2055579",
    "end": "2057669"
  },
  {
    "text": "so the N or production cluster right now is 340 and ec2 nodes and we were",
    "start": "2065779",
    "end": "2073138"
  },
  {
    "text": "tremendously happy with the with the uptime the stability and there's some people who do some incredible work here",
    "start": "2073139",
    "end": "2079589"
  },
  {
    "text": "in the room keeping keeping the system up and running but it's compared honestly to a managed service where you",
    "start": "2079589",
    "end": "2085888"
  },
  {
    "text": "really lose control over your uptime and your performance and it's it's been a really really good choice for us I'm",
    "start": "2085889",
    "end": "2092429"
  },
  {
    "text": "losing track of all the questions I'm sorry the answer is as a firm yes and",
    "start": "2092429",
    "end": "2107130"
  },
  {
    "text": "we're actively in the process of trying to figure that out it's an it's yeah we are across three AZ's right now in one",
    "start": "2107130",
    "end": "2113849"
  },
  {
    "text": "region and going multi-region active active kind of breaks things up and down the stack so this is it there's no easy",
    "start": "2113849",
    "end": "2119849"
  },
  {
    "text": "answer unfortunately to that question but we're we're committed to getting there",
    "start": "2119849",
    "end": "2124460"
  },
  {
    "text": "running in kubernetes header was running in kubernetes as a stateful set yes",
    "start": "2130030",
    "end": "2136289"
  },
  {
    "text": "sorry I couldn't be here so they look what load testing tools were using Andrew our any part of that open-source",
    "start": "2146010",
    "end": "2151920"
  },
  {
    "text": "well locus IO is an open platform open source we just deployed that the client",
    "start": "2151920",
    "end": "2158109"
  },
  {
    "text": "we wrote ourselves is not open source but it's probably not all that complex",
    "start": "2158109",
    "end": "2163240"
  },
  {
    "text": "we really all it needs is do I subscribe do I publish how often so it's actually",
    "start": "2163240",
    "end": "2171460"
  },
  {
    "text": "really easy with the Pajo mqtt client to build a very simple client to use with locus",
    "start": "2171460",
    "end": "2178380"
  },
  {
    "text": "so the question was do we have well persistent volumes on EBS yes we did for",
    "start": "2192840",
    "end": "2200610"
  },
  {
    "text": "Cassandra we use persistent volumes as well as Prometheus and did we have any",
    "start": "2200610",
    "end": "2206850"
  },
  {
    "text": "problems with Java interacting with the C groups not that we saw Cassandra honestly was one of the easiest parts of",
    "start": "2206850",
    "end": "2212880"
  },
  {
    "text": "the system it was never our blocker when we conducted a test that was a little",
    "start": "2212880",
    "end": "2217980"
  },
  {
    "text": "more ambitious in terms of the distribution of the cluster it fell over but that's because we forgot to change the network topology settings in",
    "start": "2217980",
    "end": "2225030"
  },
  {
    "text": "Cassandra I'm not sure do you recall what version of Java Scott no we'd have",
    "start": "2225030",
    "end": "2233430"
  },
  {
    "text": "to go look it up our report on this ended up being about 118 pages so there's a lot of stuff to know about it",
    "start": "2233430",
    "end": "2241160"
  },
  {
    "text": "question we'll take that back yes sir",
    "start": "2246560",
    "end": "2254210"
  },
  {
    "text": "did we sorry yep in fact so the the",
    "start": "2255440",
    "end": "2261630"
  },
  {
    "text": "tests I ran earlier so everything David describing today was a proof of concept and it is again this is dating back",
    "start": "2261630",
    "end": "2266850"
  },
  {
    "text": "you're over a year what we actually have today what I demonstrated is actually running on AWS IOT for the concept test",
    "start": "2266850",
    "end": "2277740"
  },
  {
    "text": "in fact I was one of the one of the IT platforms that we compared to the results with so we checked latency we",
    "start": "2277740",
    "end": "2282930"
  },
  {
    "text": "checked a number of connections and so forth and AWS IOT and a few others as well which I won't name",
    "start": "2282930",
    "end": "2289760"
  },
  {
    "text": "bernisa masternodes I'm Hamish resource no idea m2 to excel thanks miles",
    "start": "2297660",
    "end": "2306630"
  },
  {
    "text": "we probably changed that we messed with a lot of your settings",
    "start": "2306630",
    "end": "2311810"
  },
  {
    "text": "oh the the costs are actually per device per year so so basically that's the",
    "start": "2322120",
    "end": "2328570"
  },
  {
    "start": "2326000",
    "end": "2386000"
  },
  {
    "text": "beauty of cloud you know at a worse you should be getting linear scale and in fact we were getting sub linear scale",
    "start": "2328570",
    "end": "2333640"
  },
  {
    "text": "because basically you know supporting twice as many clients shouldn't cost twice as much in terms of infrastructure so that's why the cost we're dropping",
    "start": "2333640",
    "end": "2341880"
  },
  {
    "text": "yeah absolutely yeah in fact Thomas at the back of the room created a tremendous spreadsheet with more cells",
    "start": "2346790",
    "end": "2353720"
  },
  {
    "text": "than I care to remember and with with all of that information so that was a big piece honestly from my perspective",
    "start": "2353720",
    "end": "2359090"
  },
  {
    "text": "cost was one of the biggest pieces and that was most interesting about this POC the way that you could truly get two sub",
    "start": "2359090",
    "end": "2365660"
  },
  {
    "text": "linear cost and not bankrupt the company by having you know 510 million speakers out in the wild you're still good for",
    "start": "2365660",
    "end": "2374960"
  },
  {
    "text": "time one more minute it's all right oh no no we were you",
    "start": "2374960",
    "end": "2387380"
  },
  {
    "start": "2386000",
    "end": "2429000"
  },
  {
    "text": "straight up using Prometheus feeding under Gravano we had to give it a pretty",
    "start": "2387380",
    "end": "2394640"
  },
  {
    "text": "beefy instance we only have one instance of Prometheus so it was in gathering metrics from a hell of a lot of stuff",
    "start": "2394640",
    "end": "2401050"
  },
  {
    "text": "metrics from Cassandra from Vernon Q from H a proxy but we didn't have any",
    "start": "2401050",
    "end": "2407480"
  },
  {
    "text": "particular problem with it nope no",
    "start": "2407480",
    "end": "2416390"
  },
  {
    "text": "authentication we cheated",
    "start": "2416390",
    "end": "2421510"
  },
  {
    "text": "I thank you all we'll take the rest of the questions all right and if you want a sticker to avert MQ",
    "start": "2422200",
    "end": "2428110"
  },
  {
    "text": "come on [Applause]",
    "start": "2428110",
    "end": "2431659"
  }
]
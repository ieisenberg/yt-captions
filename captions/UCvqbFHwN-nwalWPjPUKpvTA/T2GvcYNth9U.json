[
  {
    "text": "hello hello i'm audible yeah yeah",
    "start": "25920",
    "end": "31359"
  },
  {
    "text": "so um yeah i guess no one is going so welcome",
    "start": "31359",
    "end": "36960"
  },
  {
    "text": "everyone to my talk i'm going to talk about the shiny new histograms that's going to come in from india soon",
    "start": "36960",
    "end": "44559"
  },
  {
    "text": "yeah so i am ganesh vernecker i am a software",
    "start": "44559",
    "end": "49840"
  },
  {
    "text": "engineer at grafana labs i am a prometheus team member and i maintain the tsdb in the prometheus",
    "start": "49840",
    "end": "56640"
  },
  {
    "text": "so before we talk about the shiny new histograms let's see what is a histogram a histogram lets you distribute your",
    "start": "56640",
    "end": "64478"
  },
  {
    "text": "observations into multiple buckets let's take this example so in all the",
    "start": "64479",
    "end": "69920"
  },
  {
    "text": "examples that i talk it's i am going to observe the latency of a request so on the y-axis",
    "start": "69920",
    "end": "76560"
  },
  {
    "text": "it's the number of requests on the x-axis it's the request duration so in this particular histogram",
    "start": "76560",
    "end": "83920"
  },
  {
    "text": "we can what we can get out of this is there are 15 requests that are less than 0.1",
    "start": "83920",
    "end": "89840"
  },
  {
    "text": "second latency there are 25 requests from 0.1 to one second and",
    "start": "89840",
    "end": "95520"
  },
  {
    "text": "one to two seconds and the last bucket is special it encapsulates all the requests that were",
    "start": "95520",
    "end": "101360"
  },
  {
    "text": "greater than two seconds into a single bucket so how do we store this in prometheus",
    "start": "101360",
    "end": "107520"
  },
  {
    "text": "so in prometheus we give one time series for each bucket so we have a label for a series called l",
    "start": "107520",
    "end": "114880"
  },
  {
    "text": "e which means less than or equal to and prometheus recognizes this special",
    "start": "114880",
    "end": "120079"
  },
  {
    "text": "label as the bucket value for a time series so so for this particular histogram we",
    "start": "120079",
    "end": "126719"
  },
  {
    "text": "have four bucket time series each mentioning here the",
    "start": "126719",
    "end": "132560"
  },
  {
    "text": "bucket boundaries and if you notice it is less than or equal to",
    "start": "132560",
    "end": "137920"
  },
  {
    "text": "so the first time series which is 0.1 includes all the count of all the requests that had latency less than 0.1",
    "start": "137920",
    "end": "145200"
  },
  {
    "text": "seconds which is 15 and the next one is less than or equal to 1 seconds which is",
    "start": "145200",
    "end": "151599"
  },
  {
    "text": "all the requests that were before one second so it includes the first bar and the second bar",
    "start": "151599",
    "end": "157599"
  },
  {
    "text": "similarly the third time series is the sum of first second and third bar and there is a plus infinity bucket which is",
    "start": "157599",
    "end": "165040"
  },
  {
    "text": "everything before infinity basically the total count and we have two additional time series for the entire count and",
    "start": "165040",
    "end": "170560"
  },
  {
    "text": "some so this is a problem the first problem",
    "start": "170560",
    "end": "175840"
  },
  {
    "text": "is we have to pre-define these bucket boundaries even before instrumenting like when you write the instrumentation",
    "start": "175840",
    "end": "182239"
  },
  {
    "text": "code you have to mention these bucket boundaries and it can get tricky and it can take some experimentation to",
    "start": "182239",
    "end": "188879"
  },
  {
    "text": "get these bucket boundaries right and the buckets are cumulative if you see this particular example we have",
    "start": "188879",
    "end": "195760"
  },
  {
    "text": "four buckets that are filled and i have changed the bucket boundaries a little bit but we have defined a whole",
    "start": "195760",
    "end": "202720"
  },
  {
    "text": "lot of time bucket boundaries for this particular histogram so lots of time series are going to be empty",
    "start": "202720",
    "end": "209200"
  },
  {
    "text": "basically lots of buckets are going to be empty but still each time series is going to take memory disk space and lot",
    "start": "209200",
    "end": "215840"
  },
  {
    "text": "of other resources that come with the time series and it's going to slow down queries a bit",
    "start": "215840",
    "end": "221599"
  },
  {
    "text": "yeah because the bucket's empty but they still exist yeah and if you got the bucket",
    "start": "221599",
    "end": "226879"
  },
  {
    "text": "boundaries wrong and if you want to reinstrument them again you have to reinstrument all the applications with the new bucket",
    "start": "226879",
    "end": "233519"
  },
  {
    "text": "boundaries and you have to redeploy it everywhere to get the new buckets",
    "start": "233519",
    "end": "239680"
  },
  {
    "text": "this can also be a problem for example if you change your bucket boundaries in an incompatible way where",
    "start": "239680",
    "end": "245920"
  },
  {
    "text": "for this example the left buckets and right buckets are not matching and if you know about the prometheus queries",
    "start": "245920",
    "end": "252080"
  },
  {
    "text": "the labels need to match to do any kind of comparison so in this example you may be able to",
    "start": "252080",
    "end": "258079"
  },
  {
    "text": "compare the bucket 1.0 and bucket 2.0 but all other variations are",
    "start": "258079",
    "end": "264639"
  },
  {
    "text": "incomparable so you will have to wait for some time so that you have all the new buckets ready",
    "start": "264639",
    "end": "271600"
  },
  {
    "text": "yeah and for every histogram that you define the number of total memory series which is",
    "start": "271680",
    "end": "278960"
  },
  {
    "text": "the time series that promises consumes is number of buckets plus three so why why this is a problem uh take an",
    "start": "278960",
    "end": "286320"
  },
  {
    "text": "example you are instrumenting the requests and you have sharded the",
    "start": "286320",
    "end": "291360"
  },
  {
    "text": "histograms like one histogram per status code per route",
    "start": "291360",
    "end": "296639"
  },
  {
    "text": "so this is a simple example let's say you have 1000 parts which are instrumenting these",
    "start": "296639",
    "end": "301919"
  },
  {
    "text": "histograms and a single bucket takes about few thousand series across",
    "start": "301919",
    "end": "307759"
  },
  {
    "text": "all your deployment so even if you add let's say five additional buckets it's going to",
    "start": "307759",
    "end": "312880"
  },
  {
    "text": "take exponential number of um not exponential but a huge number of",
    "start": "312880",
    "end": "318080"
  },
  {
    "text": "time series so here comes the new uh histograms that we are working right now",
    "start": "318080",
    "end": "325280"
  },
  {
    "text": "it's in poc stage we have a huge design and we'll build it step by step in a simple way i'm leaving out a lot of",
    "start": "325280",
    "end": "331759"
  },
  {
    "text": "details out of this so that it's easier to understand so what i'm going to talk in the next",
    "start": "331759",
    "end": "336960"
  },
  {
    "text": "five to ten minutes explaining this is a multi-year study and research by beyond who is here with us right now so beyond",
    "start": "336960",
    "end": "344240"
  },
  {
    "text": "myself and dieter my colleague from graphene labs we worked on the code and all this poc",
    "start": "344240",
    "end": "350240"
  },
  {
    "text": "we are calling it proof of concept because few things here and there still need to be defined and standardized but",
    "start": "350240",
    "end": "356000"
  },
  {
    "text": "most of it is ready and open source at the moment yeah so the first property of the new",
    "start": "356000",
    "end": "362639"
  },
  {
    "text": "histograms you don't have to pre-define your buckets the buckets are already pre-defined for you",
    "start": "362639",
    "end": "369360"
  },
  {
    "text": "but you can set the precision like the resolution factor of the new histograms",
    "start": "369360",
    "end": "374639"
  },
  {
    "text": "for example let's take the factor of 2 power of 1 what does it mean it means",
    "start": "374639",
    "end": "381520"
  },
  {
    "text": "the you multiply a bucket boundary with 2 to get the next bucket boundary and we",
    "start": "381520",
    "end": "386720"
  },
  {
    "text": "always start with the number 1. so if the bucket boundary is 1 the next bucket boundary will be 2 4 6 8 and so",
    "start": "386720",
    "end": "394240"
  },
  {
    "text": "on now this is one resolution of histograms and we always have the factor as some",
    "start": "394240",
    "end": "400800"
  },
  {
    "text": "power of two if you want to lower the resolution like the gap between two consecutive bucket boundaries is huge",
    "start": "400800",
    "end": "407840"
  },
  {
    "text": "you just take the factories 2 2 and you get the bucket boundaries as 1 2 4 1 sorry 1 4 16 64 and so on and you can",
    "start": "407840",
    "end": "415520"
  },
  {
    "text": "take the factor of 2 power 4 or 2 power 8 and so on you cannot have the powers like 2 power 3 or 2 power 5",
    "start": "415520",
    "end": "422800"
  },
  {
    "text": "the powers are also power of 2 and this is about the going up",
    "start": "422800",
    "end": "429440"
  },
  {
    "text": "going a lower resolution which means bigger buckets if you want to go in the other direction",
    "start": "429440",
    "end": "436479"
  },
  {
    "text": "the factors look like 2 and then 2 power 1 by 2 which is square root of 2 then x will be 2 power",
    "start": "436479",
    "end": "442319"
  },
  {
    "text": "1 by 4 which is square root of square root of 2 and so on so you multiplied square root of 2",
    "start": "442319",
    "end": "448479"
  },
  {
    "text": "with 1 you get the next bucket boundary and then you multiply it again you get the 2. you don't have to worry about",
    "start": "448479",
    "end": "454319"
  },
  {
    "text": "this math you can just assume that it works and we will see soon how this",
    "start": "454319",
    "end": "460400"
  },
  {
    "text": "solves all the remaining problems and if you see the color uh colors like",
    "start": "460400",
    "end": "466400"
  },
  {
    "text": "once you go up like once you increase the resolution for example let's take the factor of two",
    "start": "466400",
    "end": "472000"
  },
  {
    "text": "power one by two and two power one by four so we have three bucket boundaries in",
    "start": "472000",
    "end": "477360"
  },
  {
    "text": "above and when you increase the resolution one step a new bucket boundary comes between all",
    "start": "477360",
    "end": "483599"
  },
  {
    "text": "the bucket boundaries that were there before and if you take the third and fourth example",
    "start": "483599",
    "end": "489360"
  },
  {
    "text": "all the boundaries from above remain the same you just get new boundaries in between",
    "start": "489360",
    "end": "495840"
  },
  {
    "text": "yeah i just talked about the boundaries which come after one if you want before one you just divide the factor so",
    "start": "498960",
    "end": "505840"
  },
  {
    "text": "everything after one you just keep multiplying the factor to get the new boundaries and before one you keep",
    "start": "505840",
    "end": "510879"
  },
  {
    "text": "dividing and it keeps on going getting small",
    "start": "510879",
    "end": "516320"
  },
  {
    "text": "so why is it like this so",
    "start": "516479",
    "end": "521760"
  },
  {
    "text": "if we just glance at this for a moment we see that between resolutions there are some common buckets",
    "start": "521760",
    "end": "528160"
  },
  {
    "text": "so that helps us move from a higher resolution histogram to a lower his resolution histogram in this example the",
    "start": "528160",
    "end": "534880"
  },
  {
    "text": "first histogram uses a factor of 2 so the boundaries are 1 to 2 2 4 4 to 8 and",
    "start": "534880",
    "end": "540640"
  },
  {
    "text": "so on so if you wanted to decrease the resolution of this histogram you choose the the next factor which is 2 power of",
    "start": "540640",
    "end": "547440"
  },
  {
    "text": "2 and you add the buckets which fall into the new buckets and you get the new",
    "start": "547440",
    "end": "553040"
  },
  {
    "text": "histogram and you increase the like lower the resolution again and you get the new histogram so why do we want",
    "start": "553040",
    "end": "559680"
  },
  {
    "text": "this we saw earlier that if you change the bucket bucket layout you cannot",
    "start": "559680",
    "end": "566320"
  },
  {
    "text": "match the buckets between two histograms again because they can be incompatible",
    "start": "566320",
    "end": "571519"
  },
  {
    "text": "but with this the first histogram above is of resolution to power of one the second is",
    "start": "571519",
    "end": "578240"
  },
  {
    "text": "of two power of two so if you let's say if you wanted to add these two histograms you just convert the",
    "start": "578240",
    "end": "584320"
  },
  {
    "text": "histogram of a higher resolution to a lower resolution and now you can do any kind of arithmetic that you want so that's a",
    "start": "584320",
    "end": "590560"
  },
  {
    "text": "part of predefining buckets to some power of something so that histograms of different resolution can",
    "start": "590560",
    "end": "597120"
  },
  {
    "text": "be compared together yeah so i have skipped the step of converting",
    "start": "597120",
    "end": "602160"
  },
  {
    "text": "the higher resolution to a lower resolution but you can match the colors the yellow",
    "start": "602160",
    "end": "607440"
  },
  {
    "text": "bucket matches here and the blue buckets are added together to get the blue bucket",
    "start": "607440",
    "end": "612800"
  },
  {
    "text": "yeah i'll move on to the next slide and because we have predefined the",
    "start": "612800",
    "end": "619920"
  },
  {
    "text": "bucket boundaries now you have to just only specify the the factor that you want to multiply for",
    "start": "619920",
    "end": "626959"
  },
  {
    "text": "every new bucket boundary so now that the bucket boundaries are fixed you don't need to store the bucket",
    "start": "626959",
    "end": "633279"
  },
  {
    "text": "boundaries itself in the storage because encoding float numbers is expensive and not very efficient so",
    "start": "633279",
    "end": "639760"
  },
  {
    "text": "we can use integer numbers which starts from 0 goes up the number and down the",
    "start": "639760",
    "end": "644959"
  },
  {
    "text": "number line and this is very efficient to encode and takes less space and less",
    "start": "644959",
    "end": "650560"
  },
  {
    "text": "cpu to encode and decode so we give the id 0 to the bucket which",
    "start": "650560",
    "end": "656720"
  },
  {
    "text": "has the upper boundary as one so in these are three different solution one",
    "start": "656720",
    "end": "661760"
  },
  {
    "text": "is two power of one the second histogram is two power one by four which is a higher resolution bucket the next is two",
    "start": "661760",
    "end": "668480"
  },
  {
    "text": "power of two so we start at zeroth bucket and every new bucket gets the id one two three",
    "start": "668480",
    "end": "674399"
  },
  {
    "text": "four when the bucket boundaries are increasing and when it's decreasing we go in the negative direction",
    "start": "674399",
    "end": "680880"
  },
  {
    "text": "so so we have built up all the information that we need about the histograms",
    "start": "680880",
    "end": "686320"
  },
  {
    "text": "and this is how we encode it we take it we take an example of this",
    "start": "686320",
    "end": "691680"
  },
  {
    "text": "histogram so the first part in the histogram is the metadata which encodes the resolution the total sum resolution",
    "start": "691680",
    "end": "699200"
  },
  {
    "text": "is just the factor that we talked about 2 power of 2 power of something and the sum and count this is enough to",
    "start": "699200",
    "end": "705839"
  },
  {
    "text": "decode the rest of the histogram so the next part we call it a span which",
    "start": "705839",
    "end": "712800"
  },
  {
    "text": "tells you what's the bucket layout in this particular histogram so if you observe the histogram the",
    "start": "712800",
    "end": "719680"
  },
  {
    "text": "first four buckets are consecutive they are one after another and then there is a gap of",
    "start": "719680",
    "end": "725040"
  },
  {
    "text": "two buckets and then there is a bucket again we are using the factory two power one",
    "start": "725040",
    "end": "731040"
  },
  {
    "text": "and let me use that to decode what's written in the span so we have zero comma four then two comma one",
    "start": "731040",
    "end": "737200"
  },
  {
    "text": "it means the first bucket starts at index zero because the first bucket has",
    "start": "737200",
    "end": "742320"
  },
  {
    "text": "upper boundary of one and at zero index there are four buckets",
    "start": "742320",
    "end": "748639"
  },
  {
    "text": "hence zero comma four and the next two comma one says that after the previous set of buckets you have a gap of two",
    "start": "748639",
    "end": "755680"
  },
  {
    "text": "buckets so you have to skip two buckets and the next stream of buckets is of length one so",
    "start": "755680",
    "end": "761360"
  },
  {
    "text": "you have one bucket so this compressed format tells you what's the bucket layout and now you",
    "start": "761360",
    "end": "766959"
  },
  {
    "text": "know which buckets are filled and which buckets are unfilled",
    "start": "766959",
    "end": "772079"
  },
  {
    "text": "and we just store the count in each bucket consecutive there are there on we don't need to map the buckets with the",
    "start": "772079",
    "end": "778320"
  },
  {
    "text": "count we just have the bucket layout and the count and we can use some kind of efficient encoding to store this",
    "start": "778320",
    "end": "787320"
  },
  {
    "text": "and we now have only one time series per histogram because all the bucket layout",
    "start": "789120",
    "end": "797120"
  },
  {
    "text": "and the values are encoded into a single piece we map one time series to all the",
    "start": "797120",
    "end": "802959"
  },
  {
    "text": "systems currently in prometheus a sample which is a sample has timestamp as in 64",
    "start": "802959",
    "end": "809839"
  },
  {
    "text": "and a value as float 64. we just replace the float64 with the new encoding that we just",
    "start": "809839",
    "end": "816160"
  },
  {
    "text": "described right now and yeah and you just have one time series like if you increase the number of buckets or",
    "start": "816160",
    "end": "823040"
  },
  {
    "text": "decrease it doesn't change the number of series and it's efficient",
    "start": "823040",
    "end": "829440"
  },
  {
    "text": "like there was a talk in prom con last year and we saw that this new encoding without",
    "start": "829440",
    "end": "834800"
  },
  {
    "text": "uh having one series per bucket gives about more than 90 percent of index size",
    "start": "834800",
    "end": "840720"
  },
  {
    "text": "savings if you have too many buckets previously and roughly around 50 of disk",
    "start": "840720",
    "end": "846240"
  },
  {
    "text": "size savings yeah so how do you instrument this",
    "start": "846240",
    "end": "853040"
  },
  {
    "text": "it is as simple as this so everything remains same as previous instrumentation",
    "start": "853040",
    "end": "858880"
  },
  {
    "text": "and you don't define your buckets you just define what factor you want to use",
    "start": "858880",
    "end": "864480"
  },
  {
    "text": "so here i have example of two and four four is to power of two and you don't need to get the precision very right",
    "start": "864480",
    "end": "871120"
  },
  {
    "text": "the instrumentation library automatically chooses the closest precision from what you",
    "start": "871120",
    "end": "876959"
  },
  {
    "text": "define and as and when you observe any values the buckets are filled automatically you",
    "start": "876959",
    "end": "883360"
  },
  {
    "text": "don't have to like yeah it's just filled automatically the new buckets are created if it has",
    "start": "883360",
    "end": "888880"
  },
  {
    "text": "value if it doesn't have any value the bucket does not exist hence the name sparse high resolution histogram sparse",
    "start": "888880",
    "end": "896480"
  },
  {
    "text": "comes from the fact that we don't care about empty buckets we don't store it anywhere higher resolution",
    "start": "896480",
    "end": "901839"
  },
  {
    "text": "because with this efficient encoding you can now afford to have hundreds of buckets in a",
    "start": "901839",
    "end": "908639"
  },
  {
    "text": "histogram and it doesn't really make a dent in the resource consumption",
    "start": "908639",
    "end": "915040"
  },
  {
    "text": "and in this proof of concept the scraping looks like this currently",
    "start": "915680",
    "end": "923040"
  },
  {
    "text": "we have a http request which asks for a text format matrix which gives the time series",
    "start": "923040",
    "end": "928720"
  },
  {
    "text": "in the format that we saw earlier and we do another http request to get the new sparse histograms we are encoding this",
    "start": "928720",
    "end": "935920"
  },
  {
    "text": "new space histogram in protocol buffer format because it's more efficient and can be easily described like the new",
    "start": "935920",
    "end": "942639"
  },
  {
    "text": "histograms can be easily described in protobuf compared to the text format so prometheus does two requests to a target",
    "start": "942639",
    "end": "948399"
  },
  {
    "text": "to get all the data that it needs now it's final time for demo like",
    "start": "948399",
    "end": "954240"
  },
  {
    "text": "i cannot mirror my screen so i'll try my best to give that demo because i have to see here too",
    "start": "954240",
    "end": "960880"
  },
  {
    "text": "okay",
    "start": "960880",
    "end": "963880"
  },
  {
    "text": "so i am running grafana here and i am running a prometheus which supports",
    "start": "968720",
    "end": "974240"
  },
  {
    "text": "sparse histograms and i am running some synthetic load this is",
    "start": "974240",
    "end": "979920"
  },
  {
    "text": "something called storyteller and some other synthetic load that i did like we have two synthetic loads and i'm going",
    "start": "979920",
    "end": "985120"
  },
  {
    "text": "to show a live load soon so this is the context of what's",
    "start": "985120",
    "end": "990560"
  },
  {
    "text": "running right now i will get another browser on the screen",
    "start": "990560",
    "end": "997839"
  },
  {
    "text": "just a second",
    "start": "1017600",
    "end": "1020920"
  },
  {
    "text": "so i have like the instrumentation example that i showed is the same thing that we are seeing here right now so i",
    "start": "1025120",
    "end": "1031280"
  },
  {
    "text": "have two histograms one is called midi a lower resolution whose factor is 2 power of 2 which is 4",
    "start": "1031280",
    "end": "1038558"
  },
  {
    "text": "and the medium resolution is 2 power of 1 which is 2 don't worry about that number i am going",
    "start": "1038559",
    "end": "1043678"
  },
  {
    "text": "to use different timestamp to show you different values and arithmetic like we have implemented a bunch of from ql",
    "start": "1043679",
    "end": "1049440"
  },
  {
    "text": "functions which work on these new histograms so i'm going to get",
    "start": "1049440",
    "end": "1054880"
  },
  {
    "text": "this histogram at a particular time",
    "start": "1054880",
    "end": "1058720"
  },
  {
    "text": "yeah so at this time stamp we have three buckets filled 0.5 to 1 2 to 4 and 16 to",
    "start": "1064840",
    "end": "1071440"
  },
  {
    "text": "32 and okay",
    "start": "1071440",
    "end": "1079000"
  },
  {
    "text": "so",
    "start": "1100960",
    "end": "1103960"
  },
  {
    "text": "yeah this is the same histogram again but different buckets are filled which",
    "start": "1109679",
    "end": "1115280"
  },
  {
    "text": "either overlaps with the bucket that is above or it doesn't overlap and there are empty",
    "start": "1115280",
    "end": "1121120"
  },
  {
    "text": "buckets above so okay",
    "start": "1121120",
    "end": "1126240"
  },
  {
    "text": "this is not really comfortable what i'm trying are you able to see what i'm able to show okay",
    "start": "1126240",
    "end": "1134280"
  },
  {
    "text": "yeah and if you add the buckets they're kind of merged together like it's the same resolution",
    "start": "1144000",
    "end": "1149600"
  },
  {
    "text": "now let's let's take an example of merging histograms that have",
    "start": "1149600",
    "end": "1155679"
  },
  {
    "text": "different bucket layouts",
    "start": "1155679",
    "end": "1159559"
  },
  {
    "text": "okay",
    "start": "1171840",
    "end": "1174840"
  },
  {
    "text": "now we have two histograms the first histogram's resolution is 2",
    "start": "1189200",
    "end": "1194240"
  },
  {
    "text": "power 4 the second histograms resolution is 2 power of 2",
    "start": "1194240",
    "end": "1199440"
  },
  {
    "text": "and if we do a sum of this histogram the resultant histogram has a factor of",
    "start": "1204799",
    "end": "1210080"
  },
  {
    "text": "2 power of 4 which follows the concept that we discussed earlier the higher resolution is converted into a lower",
    "start": "1210080",
    "end": "1216400"
  },
  {
    "text": "resolution and they are added together and we can also do",
    "start": "1216400",
    "end": "1223679"
  },
  {
    "text": "stuff like histogram quantile of",
    "start": "1224240",
    "end": "1230200"
  },
  {
    "text": "at this point i'm just giving examples of what works what's present and stuff",
    "start": "1238159",
    "end": "1244400"
  },
  {
    "text": "yeah i'm adding data at the constant rate so you have the histogram contact now ends",
    "start": "1244400",
    "end": "1250640"
  },
  {
    "text": "the boring part i will move on to the interesting part that we wanted to show",
    "start": "1250640",
    "end": "1257440"
  },
  {
    "text": "okay so remember i have something called sorry before storyteller i'm going to",
    "start": "1257919",
    "end": "1264320"
  },
  {
    "text": "show a live cluster with heat maps",
    "start": "1264320",
    "end": "1268880"
  },
  {
    "text": "so my friends at grafana labs they worked on a new efficient heat maps",
    "start": "1269919",
    "end": "1275360"
  },
  {
    "text": "the name are leon and ryan so the currently heat maps crash when",
    "start": "1275360",
    "end": "1282799"
  },
  {
    "text": "you have too many buckets like we tried to render some high resolution histograms few months ago and the laptop",
    "start": "1282799",
    "end": "1288480"
  },
  {
    "text": "just crashes because there's just too many buckets because for every bucket you need to have a time series",
    "start": "1288480",
    "end": "1295200"
  },
  {
    "text": "okay now this is actually scraping a live cluster we",
    "start": "1302880",
    "end": "1308880"
  },
  {
    "text": "have a mimir which is like memory cluster running in our dev environment we have instrumented it with",
    "start": "1308880",
    "end": "1315200"
  },
  {
    "text": "this new histograms with a very high resolution and we have a prometheus running in dev",
    "start": "1315200",
    "end": "1321600"
  },
  {
    "text": "which is scraping these histograms and i'm port forwarding that pod and connecting into a local",
    "start": "1321600",
    "end": "1327600"
  },
  {
    "text": "uh local prometheus yeah these are just requests",
    "start": "1327600",
    "end": "1334240"
  },
  {
    "text": "and here you can clearly identify that there is a band of latency there are",
    "start": "1334240",
    "end": "1339520"
  },
  {
    "text": "different bands of latencies one is here one is here and one is here and if you look at the y-axis",
    "start": "1339520",
    "end": "1346799"
  },
  {
    "text": "they are very close together like the buckets are very close together and",
    "start": "1346799",
    "end": "1351919"
  },
  {
    "text": "the browser did not crash but this is still not the full capability of the histograms like i have",
    "start": "1351919",
    "end": "1358080"
  },
  {
    "text": "a bunch of other histograms i'll jump into",
    "start": "1358080",
    "end": "1362880"
  },
  {
    "text": "another histogram",
    "start": "1363520",
    "end": "1366840"
  },
  {
    "text": "yeah this is again a synthetic load but there are so many buckets that it looks",
    "start": "1386720",
    "end": "1392080"
  },
  {
    "text": "like a continuous gradient so i just wanted to show that we also have a heat map which is compatible",
    "start": "1392080",
    "end": "1398799"
  },
  {
    "text": "with the new histograms and it works super efficiently and you can just play with this like",
    "start": "1398799",
    "end": "1405520"
  },
  {
    "text": "there is a story behind why this heat map looks like this but i'm going to skip that story for now",
    "start": "1405520",
    "end": "1414399"
  },
  {
    "text": "i had a bunch of backup slides in case the demo did not work",
    "start": "1423200",
    "end": "1431000"
  },
  {
    "text": "and if i had to show how fast the histograms load i can",
    "start": "1433200",
    "end": "1438799"
  },
  {
    "text": "just try running a 6r query and it should just load i guess",
    "start": "1438799",
    "end": "1444400"
  },
  {
    "text": "fingers crossed yeah",
    "start": "1444400",
    "end": "1449360"
  },
  {
    "text": "did it load yeah i guess it loaded six hours of query yeah",
    "start": "1450640",
    "end": "1456559"
  },
  {
    "text": "and how can you use this so everything that we saw here is open source",
    "start": "1456559",
    "end": "1463919"
  },
  {
    "text": "um the instrumentation is available in the client golang library a client blue line repo but it's in a branch called",
    "start": "1463919",
    "end": "1470080"
  },
  {
    "text": "space histogram similarly the prometheus server that we ran is open source and it's in the sparse instagram branch and",
    "start": "1470080",
    "end": "1476720"
  },
  {
    "text": "the grafana it is actually running the main branch but the new heat maps are",
    "start": "1476720",
    "end": "1482159"
  },
  {
    "text": "hidden behind a feature flag and with this thank you do you have any questions",
    "start": "1482159",
    "end": "1490158"
  },
  {
    "text": "so if you have any questions i was asked like you can go towards mike which is at the center and ask there or if you can",
    "start": "1495600",
    "end": "1502960"
  },
  {
    "text": "shout any question from here i can say the question again",
    "start": "1502960",
    "end": "1510600"
  },
  {
    "text": "so the question is like the scraping happens by protobuf for the new histograms and is there no",
    "start": "1517679",
    "end": "1524159"
  },
  {
    "text": "text format the answer is no there is no text format implemented for that and i don't think we'll have text member at",
    "start": "1524159",
    "end": "1530159"
  },
  {
    "text": "the end unless we find some super efficient way to do it",
    "start": "1530159",
    "end": "1534880"
  },
  {
    "text": "hi um yeah thanks for the talk was very interesting so i get the mathematical properties of",
    "start": "1537360",
    "end": "1544000"
  },
  {
    "text": "this i think it's really pretty nice but let me know if i'm looking at this correctly so let's say we're measuring",
    "start": "1544000",
    "end": "1549919"
  },
  {
    "text": "latency and we our latency for a specific endpoint is has a normal distribution",
    "start": "1549919",
    "end": "1556159"
  },
  {
    "text": "centered at around like 200 milliseconds right so",
    "start": "1556159",
    "end": "1561919"
  },
  {
    "text": "if we don't do anything most of our and so we have a standard deviation that makes it go from",
    "start": "1561919",
    "end": "1568480"
  },
  {
    "text": "like 150 to 250 right so if we",
    "start": "1568480",
    "end": "1573840"
  },
  {
    "text": "depending on the factor that we use we're losing a lot of precision there right like most of it is going to the to",
    "start": "1573840",
    "end": "1578960"
  },
  {
    "text": "go to the same kinds of packets is there a like are you thinking about this like we thought to play with offsets and",
    "start": "1578960",
    "end": "1585279"
  },
  {
    "text": "scale so that you can uh get the best resolution for your metric",
    "start": "1585279",
    "end": "1592000"
  },
  {
    "text": "so can you repeat the last part yeah it's like what would you recommend right let's say that's our situation and we want to",
    "start": "1592000",
    "end": "1598799"
  },
  {
    "text": "have like to take advantage of most of the uh precision right like where most",
    "start": "1598799",
    "end": "1603840"
  },
  {
    "text": "of the position is right on the area where our metric has the most",
    "start": "1603840",
    "end": "1609440"
  },
  {
    "text": "variability okay so when you set a precision the bucket",
    "start": "1609440",
    "end": "1614640"
  },
  {
    "text": "boundaries are fixed so you cannot ask to focus on a particular range of values",
    "start": "1614640",
    "end": "1620000"
  },
  {
    "text": "but what could be done is like there was another option in the client library which i did not mention is you limit",
    "start": "1620000",
    "end": "1626159"
  },
  {
    "text": "number of buckets that you want so you can set a very high precision and a limit on buckets like 150 or 200 which",
    "start": "1626159",
    "end": "1632559"
  },
  {
    "text": "is still very practical with these new histograms and once it hits the for example 200",
    "start": "1632559",
    "end": "1639120"
  },
  {
    "text": "bucket limit it will automatically go into the next lower precision for",
    "start": "1639120",
    "end": "1644480"
  },
  {
    "text": "example if you are using a pressure of two power one by eight and hits the bucket limit it will automatically",
    "start": "1644480",
    "end": "1650159"
  },
  {
    "text": "switch to two power one by four so that's the best thing possible at the end like you can start with the highest",
    "start": "1650159",
    "end": "1655600"
  },
  {
    "text": "resolution also at every particular interval uh there is something called a",
    "start": "1655600",
    "end": "1661600"
  },
  {
    "text": "compressed unit of histograms called chunks which contains 120 histograms at a time",
    "start": "1661600",
    "end": "1667200"
  },
  {
    "text": "so once those 120 histograms are done uh you start okay this is wrong okay sorry",
    "start": "1667200",
    "end": "1674559"
  },
  {
    "text": "so it's possible that you can reset a histogram for example after every 10 minutes or",
    "start": "1674559",
    "end": "1680000"
  },
  {
    "text": "half an hour one hour you can set it to reset the histogram so that you again start with the highest precision and low",
    "start": "1680000",
    "end": "1686399"
  },
  {
    "text": "number of buckets filled so that's another way to move back to high resolution again okay got you thanks",
    "start": "1686399",
    "end": "1694000"
  },
  {
    "text": "hi thanks for this it's uh seems very elegant um it might be a misunderstanding of mine",
    "start": "1694960",
    "end": "1701919"
  },
  {
    "text": "but i feel like the uh it seems like the the sort of uh distribution of the buckets across",
    "start": "1701919",
    "end": "1709679"
  },
  {
    "text": "the number line is assuming the data is going to be followed like a long tail distribution",
    "start": "1709679",
    "end": "1715440"
  },
  {
    "text": "um like there's going to be more sort of",
    "start": "1715440",
    "end": "1721520"
  },
  {
    "text": "like samples at the lower end of the number line and they'll get more and more sort of spread out as you go up is",
    "start": "1721840",
    "end": "1728159"
  },
  {
    "text": "that correct and yeah like what if the data doesn't fit that yeah and that's correct like if you set",
    "start": "1728159",
    "end": "1734559"
  },
  {
    "text": "higher precision the size of buckets is going to be small up to some extent and it just exponentially",
    "start": "1734559",
    "end": "1740799"
  },
  {
    "text": "grows so the idea with this was the gap between two consecutive buckets like",
    "start": "1740799",
    "end": "1747120"
  },
  {
    "text": "the percentage difference between two consecutive buckets is fixed so and whenever you do a quantile",
    "start": "1747120",
    "end": "1753520"
  },
  {
    "text": "estimation the error of your estimation is limited to what's the difference",
    "start": "1753520",
    "end": "1759039"
  },
  {
    "text": "between the buckets like the percentage difference so the idea was to reduce the percentage error of the histogram",
    "start": "1759039",
    "end": "1764399"
  },
  {
    "text": "quantile estimations and if you take the plus infinity bucket currently in prometheus if there is a value which",
    "start": "1764399",
    "end": "1770480"
  },
  {
    "text": "falls in that bucket you cannot accurately predict within a certain percentage if the quantile estimation is",
    "start": "1770480",
    "end": "1777200"
  },
  {
    "text": "correct if it falls there so that's right like the spread will be big but if you take the percentage error of",
    "start": "1777200",
    "end": "1783440"
  },
  {
    "text": "your estimations that's going to be limited wherever you go",
    "start": "1783440",
    "end": "1789120"
  },
  {
    "text": "thank you hello thank you for uh the presentation",
    "start": "1789120",
    "end": "1794720"
  },
  {
    "text": "it was very clear so i've seen that uh you added the instrumentation in",
    "start": "1794720",
    "end": "1800960"
  },
  {
    "text": "the golang parameters client are you planning to add this feature in other",
    "start": "1800960",
    "end": "1806159"
  },
  {
    "text": "languages like python library for example yeah so this was just a proof of concept we're still",
    "start": "1806159",
    "end": "1812559"
  },
  {
    "text": "playing with it once this goes into prometheus for sure it will just spread to other client",
    "start": "1812559",
    "end": "1819200"
  },
  {
    "text": "libraries okay thank you",
    "start": "1819200",
    "end": "1823840"
  },
  {
    "text": "we still have five minutes i",
    "start": "1827200",
    "end": "1830398"
  },
  {
    "text": "guess do have one more question then is that okay",
    "start": "1834840",
    "end": "1840640"
  },
  {
    "text": "okay uh you can ask the question okay i was just gonna ask um like if you were to to go ahead with this it",
    "start": "1840640",
    "end": "1847279"
  },
  {
    "text": "sort of sets the precedent for non-uh floating point series values",
    "start": "1847279",
    "end": "1853360"
  },
  {
    "text": "do you think there's other use cases for that like with you know once once that precedence has been set are there other",
    "start": "1853360",
    "end": "1861360"
  },
  {
    "text": "precedents okay you mean how will we have both the histograms together i mean",
    "start": "1861519",
    "end": "1867679"
  },
  {
    "text": "the old instagrams and the new instagrams uh no more like once you",
    "start": "1867679",
    "end": "1873440"
  },
  {
    "text": "once you've um once you've allowed like non-floating point numbers",
    "start": "1873440",
    "end": "1879600"
  },
  {
    "text": "as series values for this case are there other kinds of uh",
    "start": "1879600",
    "end": "1884880"
  },
  {
    "text": "series types that you might do something okay before yeah",
    "start": "1884880",
    "end": "1890240"
  },
  {
    "text": "um so doing changes to if i understand your question right uh",
    "start": "1890240",
    "end": "1897039"
  },
  {
    "text": "you mean we replace float64 with a different data structure yeah is this scope to add different",
    "start": "1897039",
    "end": "1902960"
  },
  {
    "text": "more data structures yeah so there is it's possible but the big problem that",
    "start": "1902960",
    "end": "1908799"
  },
  {
    "text": "comes with it is making any change to the data type requires changing the tsdb the from kill",
    "start": "1908799",
    "end": "1916240"
  },
  {
    "text": "engine and everywhere you access the sample so if you have to make any change they should there needs to be a very solid",
    "start": "1916240",
    "end": "1923039"
  },
  {
    "text": "use case that it's required and in a like many if if it has a bigger use",
    "start": "1923039",
    "end": "1929279"
  },
  {
    "text": "case it's possible yeah okay i would say it's possible but it will require some real big use case",
    "start": "1929279",
    "end": "1936000"
  },
  {
    "text": "for that to happen yeah and your question was how will old",
    "start": "1936000",
    "end": "1941519"
  },
  {
    "text": "histograms work with the new",
    "start": "1941519",
    "end": "1944960"
  },
  {
    "text": "to like histograms uh see what percentage perhaps of one uh versus",
    "start": "1947200",
    "end": "1954398"
  },
  {
    "text": "breakdown a single bucket okay is there a way to do that with that basically",
    "start": "1955279",
    "end": "1961600"
  },
  {
    "text": "okay so your question was how can we access individual buckets so",
    "start": "1961600",
    "end": "1967519"
  },
  {
    "text": "um we have a prom a huge design dock explaining all the proper things that we",
    "start": "1967519",
    "end": "1973679"
  },
  {
    "text": "want to do with this and this is included there so we will have the ability to",
    "start": "1973679",
    "end": "1980000"
  },
  {
    "text": "ask for a value at a bucket just that it's not implemented at the moment",
    "start": "1980000",
    "end": "1986000"
  },
  {
    "text": "we are just running it in dev we are still playing with this yeah we have just one prometheus which is",
    "start": "1993679",
    "end": "2000480"
  },
  {
    "text": "scraping just one day of cluster which is instrumented with fast histograms",
    "start": "2000480",
    "end": "2006399"
  },
  {
    "text": "two more minutes",
    "start": "2011360",
    "end": "2014679"
  },
  {
    "text": "i think a lot of the previous questions were around the bucket distribution right it seems like the center of mass",
    "start": "2025440",
    "end": "2030960"
  },
  {
    "text": "of the distribution will be around zero right now once yeah see",
    "start": "2030960",
    "end": "2036960"
  },
  {
    "text": "exactly h will be around one and then it will spread out exponentially so is it possible to add a single offset so for",
    "start": "2036960",
    "end": "2043440"
  },
  {
    "text": "example if you're measuring latencies you can say plus 200 and then it'll be the center will be around 200 which is",
    "start": "2043440",
    "end": "2049599"
  },
  {
    "text": "where the normal latency would be let's say so when you say the center of mass it is",
    "start": "2049599",
    "end": "2055679"
  },
  {
    "text": "just the calculation which starts at one like the like the calculation of bucket",
    "start": "2055679",
    "end": "2060800"
  },
  {
    "text": "boundaries which starts at one but the observations that you do can be",
    "start": "2060800",
    "end": "2066240"
  },
  {
    "text": "centered anywhere but the problem with centering the calculation somewhere else",
    "start": "2066240",
    "end": "2071440"
  },
  {
    "text": "is it creates a problem again you cannot mix and match other histograms",
    "start": "2071440",
    "end": "2077760"
  },
  {
    "text": "okay no i mean the pockets will be the smallest the most high resolution near",
    "start": "2078800",
    "end": "2083919"
  },
  {
    "text": "one right now right like the smallest most fine-grained buckets will be near one yeah because of the multiplication",
    "start": "2083919",
    "end": "2090240"
  },
  {
    "text": "factor right right but if people could sort of move that fine grained resolution buckets to 300 ms where the",
    "start": "2090240",
    "end": "2096878"
  },
  {
    "text": "latency will be and then they'll be a higher accuracy quantile function",
    "start": "2096879",
    "end": "2102480"
  },
  {
    "text": "results right yeah that's possible but",
    "start": "2102480",
    "end": "2108000"
  },
  {
    "text": "again it kind of skews the bucket layout and makes it incompatible with each other",
    "start": "2108000",
    "end": "2113359"
  },
  {
    "text": "with the merging",
    "start": "2113359",
    "end": "2116000"
  },
  {
    "text": "i guess we are out of time thank you for joining the talk",
    "start": "2119599",
    "end": "2124920"
  }
]
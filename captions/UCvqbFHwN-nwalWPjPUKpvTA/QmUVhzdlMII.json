[
  {
    "text": "i'm here to share a little bit about how",
    "start": "80",
    "end": "2080"
  },
  {
    "text": "we use Quark to help us prepare for",
    "start": "2080",
    "end": "4080"
  },
  {
    "text": "scale as we manage our large fleet of",
    "start": "4080",
    "end": "6400"
  },
  {
    "text": "data centers so if I had 30 seconds to",
    "start": "6400",
    "end": "9519"
  },
  {
    "text": "leave you with something to take away",
    "start": "9519",
    "end": "10960"
  },
  {
    "text": "from this talk it would be what is Quark",
    "start": "10960",
    "end": "13360"
  },
  {
    "text": "and why is it that you might find that",
    "start": "13360",
    "end": "15519"
  },
  {
    "text": "interesting so Quark is basically a tool",
    "start": "15519",
    "end": "17920"
  },
  {
    "text": "you can use to simulate a large number",
    "start": "17920",
    "end": "20160"
  },
  {
    "text": "of nodes or pods on a very minimal",
    "start": "20160",
    "end": "22800"
  },
  {
    "text": "resource requirement so you could use a",
    "start": "22800",
    "end": "24960"
  },
  {
    "text": "single laptop or a very small Kubernetes",
    "start": "24960",
    "end": "27199"
  },
  {
    "text": "cluster now why quawk so if you manage",
    "start": "27199",
    "end": "31519"
  },
  {
    "text": "control plane services whose behavior",
    "start": "31519",
    "end": "34000"
  },
  {
    "text": "would probably be affected by the number",
    "start": "34000",
    "end": "36480"
  },
  {
    "text": "of nodes in the cluster or the state of",
    "start": "36480",
    "end": "38800"
  },
  {
    "text": "those nodes then quark might be a great",
    "start": "38800",
    "end": "40800"
  },
  {
    "text": "toolkit for you to play around with",
    "start": "40800",
    "end": "42840"
  },
  {
    "text": "scale so now now that I've set that up",
    "start": "42840",
    "end": "45840"
  },
  {
    "text": "and um you know what quark and why you",
    "start": "45840",
    "end": "48320"
  },
  {
    "text": "would need it I'd like to share a little",
    "start": "48320",
    "end": "50480"
  },
  {
    "text": "bit about how we used it and uh it might",
    "start": "50480",
    "end": "53840"
  },
  {
    "text": "even extrapolate a use case you might",
    "start": "53840",
    "end": "55680"
  },
  {
    "text": "have so firstly I'd like to get started",
    "start": "55680",
    "end": "58079"
  },
  {
    "text": "giving you a background about our scale",
    "start": "58079",
    "end": "59920"
  },
  {
    "text": "so we have about 80 data centers",
    "start": "59920",
    "end": "62079"
  },
  {
    "text": "worldwide which are production clusters",
    "start": "62079",
    "end": "64239"
  },
  {
    "text": "and we deploy about 50 microservices per",
    "start": "64239",
    "end": "67040"
  },
  {
    "text": "data center so the resource crunch is",
    "start": "67040",
    "end": "69360"
  },
  {
    "text": "pretty heavy for us so now uh yeah so",
    "start": "69360",
    "end": "73439"
  },
  {
    "text": "looking at the scale of the clusters",
    "start": "73439",
    "end": "75200"
  },
  {
    "text": "themselves so typically our dev",
    "start": "75200",
    "end": "77280"
  },
  {
    "text": "environments have about 50 nodes and our",
    "start": "77280",
    "end": "79360"
  },
  {
    "text": "production are about 800 nodes i think",
    "start": "79360",
    "end": "81600"
  },
  {
    "text": "our largest one is 1250 nodes and uh the",
    "start": "81600",
    "end": "84799"
  },
  {
    "text": "workload if you look at that we have",
    "start": "84799",
    "end": "86240"
  },
  {
    "text": "about 1500 pods running on our dev",
    "start": "86240",
    "end": "88400"
  },
  {
    "text": "environments and about 18,000 pods",
    "start": "88400",
    "end": "90479"
  },
  {
    "text": "running on our production clusters so",
    "start": "90479",
    "end": "92240"
  },
  {
    "text": "the scale difference between our dev and",
    "start": "92240",
    "end": "93840"
  },
  {
    "text": "prod are pretty huge so anytime we",
    "start": "93840",
    "end": "96079"
  },
  {
    "text": "develop or implement something new we",
    "start": "96079",
    "end": "98240"
  },
  {
    "text": "test it against our dev clusters of",
    "start": "98240",
    "end": "99840"
  },
  {
    "text": "course but we have to make sure that it",
    "start": "99840",
    "end": "102240"
  },
  {
    "text": "can work at the scale of our production",
    "start": "102240",
    "end": "104200"
  },
  {
    "text": "environments so something that we have",
    "start": "104200",
    "end": "106880"
  },
  {
    "text": "to keep in mind is to always build for",
    "start": "106880",
    "end": "109280"
  },
  {
    "text": "scale and this is something I'll keep",
    "start": "109280",
    "end": "111040"
  },
  {
    "text": "referring back to um so now let's get",
    "start": "111040",
    "end": "113759"
  },
  {
    "text": "into the spec specifics of this use case",
    "start": "113759",
    "end": "115840"
  },
  {
    "text": "I've been talking about so um we deploy",
    "start": "115840",
    "end": "118799"
  },
  {
    "text": "most of our services using Helm charts",
    "start": "118799",
    "end": "120640"
  },
  {
    "text": "and many of our services have demon sets",
    "start": "120640",
    "end": "122799"
  },
  {
    "text": "so the default uh deployment behavior",
    "start": "122799",
    "end": "124960"
  },
  {
    "text": "for a demon set if you don't have any",
    "start": "124960",
    "end": "127040"
  },
  {
    "text": "specific tolerations uh defined is that",
    "start": "127040",
    "end": "129599"
  },
  {
    "text": "it will try to launch one part of your",
    "start": "129599",
    "end": "132560"
  },
  {
    "text": "demon set on every node that matches",
    "start": "132560",
    "end": "134640"
  },
  {
    "text": "your criteria so any nodes that are not",
    "start": "134640",
    "end": "137280"
  },
  {
    "text": "ready it will automatically skip it from",
    "start": "137280",
    "end": "139360"
  },
  {
    "text": "rollout but we had a special case where",
    "start": "139360",
    "end": "141840"
  },
  {
    "text": "some of our demon sets defined a",
    "start": "141840",
    "end": "143599"
  },
  {
    "text": "specific toleration which said I want to",
    "start": "143599",
    "end": "145599"
  },
  {
    "text": "tolerate all taints this meant that it",
    "start": "145599",
    "end": "148160"
  },
  {
    "text": "would also try to launch the nodes uh",
    "start": "148160",
    "end": "150480"
  },
  {
    "text": "pods on nodes which are not ready so the",
    "start": "150480",
    "end": "153040"
  },
  {
    "text": "pods get stuck pending forever this",
    "start": "153040",
    "end": "155680"
  },
  {
    "text": "caused our demon set rollout to fail",
    "start": "155680",
    "end": "157599"
  },
  {
    "text": "which marked our Helm deployments as",
    "start": "157599",
    "end": "159360"
  },
  {
    "text": "failure so but our criteria we wanted to",
    "start": "159360",
    "end": "162640"
  },
  {
    "text": "deploy it on all nodes possible but skip",
    "start": "162640",
    "end": "165200"
  },
  {
    "text": "the nodes that are not ready so how did",
    "start": "165200",
    "end": "167760"
  },
  {
    "text": "we handle that so as any",
    "start": "167760",
    "end": "170319"
  },
  {
    "text": "automationdriven team would do we first",
    "start": "170319",
    "end": "172480"
  },
  {
    "text": "wrote a script so in our first iteration",
    "start": "172480",
    "end": "174959"
  },
  {
    "text": "a script would basically get the list of",
    "start": "174959",
    "end": "177280"
  },
  {
    "text": "nodes check how many of that match the",
    "start": "177280",
    "end": "179440"
  },
  {
    "text": "deployment criteria and if the pods are",
    "start": "179440",
    "end": "181680"
  },
  {
    "text": "coming up okay on those it will mark the",
    "start": "181680",
    "end": "183519"
  },
  {
    "text": "roll out as success so we were happy",
    "start": "183519",
    "end": "185760"
  },
  {
    "text": "with that we started rolling this out",
    "start": "185760",
    "end": "187599"
  },
  {
    "text": "across the fleet now this worked well on",
    "start": "187599",
    "end": "190640"
  },
  {
    "text": "some of our initial clusters but as we",
    "start": "190640",
    "end": "193040"
  },
  {
    "text": "started hitting our larger production",
    "start": "193040",
    "end": "194720"
  },
  {
    "text": "environments we started running into out",
    "start": "194720",
    "end": "196879"
  },
  {
    "text": "of memory issues so we realized we",
    "start": "196879",
    "end": "199599"
  },
  {
    "text": "hadn't built this for scale so how can",
    "start": "199599",
    "end": "202560"
  },
  {
    "text": "we go about making improvements to our",
    "start": "202560",
    "end": "205200"
  },
  {
    "text": "script but be able to test it for scale",
    "start": "205200",
    "end": "208000"
  },
  {
    "text": "without having to hit our large",
    "start": "208000",
    "end": "210080"
  },
  {
    "text": "production environments so this is where",
    "start": "210080",
    "end": "212239"
  },
  {
    "text": "Quark came into picture and really",
    "start": "212239",
    "end": "213840"
  },
  {
    "text": "helped us so if you look at this flow",
    "start": "213840",
    "end": "215599"
  },
  {
    "text": "here so first we will make changes to",
    "start": "215599",
    "end": "218080"
  },
  {
    "text": "our script any improvements that we want",
    "start": "218080",
    "end": "219840"
  },
  {
    "text": "to make we can go ahead and execute it",
    "start": "219840",
    "end": "222080"
  },
  {
    "text": "on our current dev clusters verify that",
    "start": "222080",
    "end": "224879"
  },
  {
    "text": "the functionality is still working as",
    "start": "224879",
    "end": "226720"
  },
  {
    "text": "expected now to test for scale we were",
    "start": "226720",
    "end": "229120"
  },
  {
    "text": "able to use Quark and launch thousand",
    "start": "229120",
    "end": "231720"
  },
  {
    "text": "nodes,500 nodes and run the test hook",
    "start": "231720",
    "end": "234720"
  },
  {
    "text": "again now if it worked here we were sure",
    "start": "234720",
    "end": "236879"
  },
  {
    "text": "that it was ready for scale so we could",
    "start": "236879",
    "end": "239280"
  },
  {
    "text": "continuously iterate over our script and",
    "start": "239280",
    "end": "241840"
  },
  {
    "text": "test it for both functionality and scale",
    "start": "241840",
    "end": "244480"
  },
  {
    "text": "because of the help of Quark so using",
    "start": "244480",
    "end": "247680"
  },
  {
    "text": "Quark we were able to simulate more than",
    "start": "247680",
    "end": "249680"
  },
  {
    "text": "2,000 nodes which is already bigger than",
    "start": "249680",
    "end": "251840"
  },
  {
    "text": "our current max scale and using that we",
    "start": "251840",
    "end": "254159"
  },
  {
    "text": "were able to make all of these",
    "start": "254159",
    "end": "255439"
  },
  {
    "text": "improvements to our script so we were",
    "start": "255439",
    "end": "257280"
  },
  {
    "text": "able to improve implement caching",
    "start": "257280",
    "end": "259120"
  },
  {
    "text": "because of which we were able to reduce",
    "start": "259120",
    "end": "260720"
  },
  {
    "text": "the amount of queries we were making by",
    "start": "260720",
    "end": "262479"
  },
  {
    "text": "40% we could batch the API calls that we",
    "start": "262479",
    "end": "265199"
  },
  {
    "text": "were making to list the nodes and we",
    "start": "265199",
    "end": "267120"
  },
  {
    "text": "also were able to reduce the amount of",
    "start": "267120",
    "end": "268800"
  },
  {
    "text": "data that we stored in memory about the",
    "start": "268800",
    "end": "270800"
  },
  {
    "text": "node so using quark we were able to",
    "start": "270800",
    "end": "273440"
  },
  {
    "text": "achieve our goal which was to always",
    "start": "273440",
    "end": "275280"
  },
  {
    "text": "build for scale so I hope that has piqu",
    "start": "275280",
    "end": "278880"
  },
  {
    "text": "your curiosity about quark uh some of my",
    "start": "278880",
    "end": "281759"
  },
  {
    "text": "colleagues are also having some talks",
    "start": "281759",
    "end": "283680"
  },
  {
    "text": "about some additional use cases where we",
    "start": "283680",
    "end": "285840"
  },
  {
    "text": "have used Quark so I'd encourage you to",
    "start": "285840",
    "end": "288160"
  },
  {
    "text": "check them out as well um that's all I",
    "start": "288160",
    "end": "290240"
  },
  {
    "text": "have thank you",
    "start": "290240",
    "end": "292020"
  },
  {
    "text": "[Applause]",
    "start": "292020",
    "end": "296360"
  }
]
[
  {
    "text": "hi all thanks for joining this session",
    "start": "240",
    "end": "2639"
  },
  {
    "text": "in this session",
    "start": "2639",
    "end": "3520"
  },
  {
    "text": "i will try to give you an answer on a",
    "start": "3520",
    "end": "5359"
  },
  {
    "text": "very interesting question for machine",
    "start": "5359",
    "end": "6960"
  },
  {
    "text": "learning workloads",
    "start": "6960",
    "end": "8000"
  },
  {
    "text": "running on top of kubernetes and",
    "start": "8000",
    "end": "9519"
  },
  {
    "text": "consuming gpus this question also gained",
    "start": "9519",
    "end": "12160"
  },
  {
    "text": "huge traction and attention by the",
    "start": "12160",
    "end": "14000"
  },
  {
    "text": "kubernetes community overall",
    "start": "14000",
    "end": "16160"
  },
  {
    "text": "so we at sap artificial intelligence",
    "start": "16160",
    "end": "18640"
  },
  {
    "text": "were also very interested in finding an",
    "start": "18640",
    "end": "20800"
  },
  {
    "text": "answer",
    "start": "20800",
    "end": "21600"
  },
  {
    "text": "in this session i will not only give you",
    "start": "21600",
    "end": "23199"
  },
  {
    "text": "an introduction how the provisioning of",
    "start": "23199",
    "end": "25359"
  },
  {
    "text": "gpus work",
    "start": "25359",
    "end": "26320"
  },
  {
    "text": "but also share our findings",
    "start": "26320",
    "end": "28000"
  },
  {
    "text": "implementation outlook",
    "start": "28000",
    "end": "29519"
  },
  {
    "text": "how you could get started already today",
    "start": "29519",
    "end": "31840"
  },
  {
    "text": "in answering a question",
    "start": "31840",
    "end": "33200"
  },
  {
    "text": "whether sharing gpu to multiple",
    "start": "33200",
    "end": "35040"
  },
  {
    "text": "containers is visible",
    "start": "35040",
    "end": "37280"
  },
  {
    "text": "so but first a little bit about myself i",
    "start": "37280",
    "end": "39840"
  },
  {
    "text": "am currently working as developer at sap",
    "start": "39840",
    "end": "42160"
  },
  {
    "text": "artificial intelligence",
    "start": "42160",
    "end": "43600"
  },
  {
    "text": "mainly on infrastructure related topics",
    "start": "43600",
    "end": "45600"
  },
  {
    "text": "for machine learning",
    "start": "45600",
    "end": "47039"
  },
  {
    "text": "and continuous delivery i have been",
    "start": "47039",
    "end": "49200"
  },
  {
    "text": "ethically",
    "start": "49200",
    "end": "50239"
  },
  {
    "text": "contributing to community projects of",
    "start": "50239",
    "end": "52079"
  },
  {
    "text": "terraform",
    "start": "52079",
    "end": "53360"
  },
  {
    "text": "and cloud fundraising and the most",
    "start": "53360",
    "end": "55120"
  },
  {
    "text": "important i can combine",
    "start": "55120",
    "end": "56559"
  },
  {
    "text": "the two worlds of germany and turkey",
    "start": "56559",
    "end": "59120"
  },
  {
    "text": "with the german bee",
    "start": "59120",
    "end": "60399"
  },
  {
    "text": "beer and church kept up by living in",
    "start": "60399",
    "end": "62399"
  },
  {
    "text": "germany and having turkish roots",
    "start": "62399",
    "end": "64239"
  },
  {
    "text": "if you want to have further coffee with",
    "start": "64239",
    "end": "66240"
  },
  {
    "text": "me after the session",
    "start": "66240",
    "end": "67439"
  },
  {
    "text": "feel free to dm me on tilata or over the",
    "start": "67439",
    "end": "69600"
  },
  {
    "text": "conference platform",
    "start": "69600",
    "end": "70720"
  },
  {
    "text": "i'm really looking forward to chat with",
    "start": "70720",
    "end": "72320"
  },
  {
    "text": "you so",
    "start": "72320",
    "end": "74240"
  },
  {
    "text": "regarding open source sap is a platform",
    "start": "74240",
    "end": "76640"
  },
  {
    "text": "sponsor of a cloud native computing",
    "start": "76640",
    "end": "78400"
  },
  {
    "text": "foundation",
    "start": "78400",
    "end": "79040"
  },
  {
    "text": "we at sap are committed to contribute to",
    "start": "79040",
    "end": "81439"
  },
  {
    "text": "open source",
    "start": "81439",
    "end": "82400"
  },
  {
    "text": "so we do this with projects such as",
    "start": "82400",
    "end": "84240"
  },
  {
    "text": "garner",
    "start": "84240",
    "end": "85439"
  },
  {
    "text": "kima or for the kubernetes world but",
    "start": "85439",
    "end": "87759"
  },
  {
    "text": "also for java vote of the java",
    "start": "87759",
    "end": "89360"
  },
  {
    "text": "submachine or luigi",
    "start": "89360",
    "end": "91520"
  },
  {
    "text": "and feel free to check out these",
    "start": "91520",
    "end": "92880"
  },
  {
    "text": "projects and",
    "start": "92880",
    "end": "95439"
  },
  {
    "text": "about artificial intelligence we care a",
    "start": "95439",
    "end": "97600"
  },
  {
    "text": "lot at sap about artificial intelligence",
    "start": "97600",
    "end": "99920"
  },
  {
    "text": "and work on different business services",
    "start": "99920",
    "end": "101920"
  },
  {
    "text": "which are later",
    "start": "101920",
    "end": "102880"
  },
  {
    "text": "directly consumed on the ai platform or",
    "start": "102880",
    "end": "106240"
  },
  {
    "text": "embedded into a large product portfolio",
    "start": "106240",
    "end": "108640"
  },
  {
    "text": "our vision is to build the intelligent",
    "start": "108640",
    "end": "110479"
  },
  {
    "text": "enterprise",
    "start": "110479",
    "end": "111200"
  },
  {
    "text": "by embedding step by step easy to",
    "start": "111200",
    "end": "113520"
  },
  {
    "text": "consume",
    "start": "113520",
    "end": "114240"
  },
  {
    "text": "machine learning services running on top",
    "start": "114240",
    "end": "116159"
  },
  {
    "text": "of kubernetes",
    "start": "116159",
    "end": "117360"
  },
  {
    "text": "one of the most consumed services or",
    "start": "117360",
    "end": "119439"
  },
  {
    "text": "document information extraction you can",
    "start": "119439",
    "end": "121040"
  },
  {
    "text": "see to the right",
    "start": "121040",
    "end": "122479"
  },
  {
    "text": "where we can extract information from",
    "start": "122479",
    "end": "124399"
  },
  {
    "text": "invoices with that",
    "start": "124399",
    "end": "126000"
  },
  {
    "text": "and many other services we run a very",
    "start": "126000",
    "end": "128239"
  },
  {
    "text": "serious number of models and production",
    "start": "128239",
    "end": "130160"
  },
  {
    "text": "kubernetes",
    "start": "130160",
    "end": "131280"
  },
  {
    "text": "which not only consume cpus",
    "start": "131280",
    "end": "134720"
  },
  {
    "text": "but also gpus for in machine learning",
    "start": "134720",
    "end": "137040"
  },
  {
    "text": "inference",
    "start": "137040",
    "end": "138800"
  },
  {
    "text": "so for machining workloads it's most of",
    "start": "138800",
    "end": "142239"
  },
  {
    "text": "the time we are using gpus and gpus are",
    "start": "142239",
    "end": "144400"
  },
  {
    "text": "very expensive workload this is also",
    "start": "144400",
    "end": "146319"
  },
  {
    "text": "what we have seen in the production",
    "start": "146319",
    "end": "148080"
  },
  {
    "text": "environment",
    "start": "148080",
    "end": "148959"
  },
  {
    "text": "of us and so the gpu",
    "start": "148959",
    "end": "152640"
  },
  {
    "text": "is also a challenge meaning if i look",
    "start": "152640",
    "end": "156080"
  },
  {
    "text": "into our production environments and",
    "start": "156080",
    "end": "157680"
  },
  {
    "text": "seeing",
    "start": "157680",
    "end": "158560"
  },
  {
    "text": "gpus only um average utilization of 70",
    "start": "158560",
    "end": "161760"
  },
  {
    "text": "percent makes me really feel",
    "start": "161760",
    "end": "163920"
  },
  {
    "text": "sad about it because why we are not able",
    "start": "163920",
    "end": "166160"
  },
  {
    "text": "to fully utilize the gpu",
    "start": "166160",
    "end": "167840"
  },
  {
    "text": "so on the right side i did some",
    "start": "167840",
    "end": "169519"
  },
  {
    "text": "fictional calculation on",
    "start": "169519",
    "end": "170879"
  },
  {
    "text": "how much one can lose actually if we run",
    "start": "170879",
    "end": "174480"
  },
  {
    "text": "about 500 gpu models for an average",
    "start": "174480",
    "end": "177280"
  },
  {
    "text": "price of three",
    "start": "177280",
    "end": "178319"
  },
  {
    "text": "dollars and you can see that we are that",
    "start": "178319",
    "end": "181280"
  },
  {
    "text": "one can actually use",
    "start": "181280",
    "end": "182480"
  },
  {
    "text": "about 300 000 um dollars per month",
    "start": "182480",
    "end": "186560"
  },
  {
    "text": "um when running on gpus 500 models",
    "start": "186560",
    "end": "189840"
  },
  {
    "text": "on an average deputization of 70 percent",
    "start": "189840",
    "end": "193040"
  },
  {
    "text": "and this is a challenge so at sap we ask",
    "start": "193040",
    "end": "196640"
  },
  {
    "text": "ourselves",
    "start": "196640",
    "end": "197599"
  },
  {
    "text": "um how we can improve the situation can",
    "start": "197599",
    "end": "200400"
  },
  {
    "text": "we actually share a gpu to improve the",
    "start": "200400",
    "end": "202239"
  },
  {
    "text": "situation",
    "start": "202239",
    "end": "202959"
  },
  {
    "text": "so we asked ourselves whether the",
    "start": "202959",
    "end": "205200"
  },
  {
    "text": "sharing of gpu",
    "start": "205200",
    "end": "206400"
  },
  {
    "text": "is in containers is feasible so in",
    "start": "206400",
    "end": "209599"
  },
  {
    "text": "general at sap we are using gpus from",
    "start": "209599",
    "end": "212319"
  },
  {
    "text": "nvidia and i think in the machine",
    "start": "212319",
    "end": "214080"
  },
  {
    "text": "learning area it is also widely adopted",
    "start": "214080",
    "end": "216400"
  },
  {
    "text": "talking about gpus i asked often myself",
    "start": "216400",
    "end": "219200"
  },
  {
    "text": "back then how the magic works behind the",
    "start": "219200",
    "end": "221200"
  },
  {
    "text": "scene",
    "start": "221200",
    "end": "221760"
  },
  {
    "text": "how does a device made available to",
    "start": "221760",
    "end": "223920"
  },
  {
    "text": "kubernetes so kubernetes can consume it",
    "start": "223920",
    "end": "226560"
  },
  {
    "text": "and in the end how it's consumed by",
    "start": "226560",
    "end": "228159"
  },
  {
    "text": "report there has been a great work done",
    "start": "228159",
    "end": "230560"
  },
  {
    "text": "back in kubernetes 1.10",
    "start": "230560",
    "end": "232560"
  },
  {
    "text": "the so-called device plug-in where",
    "start": "232560",
    "end": "234480"
  },
  {
    "text": "everyone and every vendor can provide",
    "start": "234480",
    "end": "236480"
  },
  {
    "text": "its own custom device",
    "start": "236480",
    "end": "238000"
  },
  {
    "text": "this could be a gpu an fpga or your own",
    "start": "238000",
    "end": "240879"
  },
  {
    "text": "custom device such as bitcoin miner",
    "start": "240879",
    "end": "243040"
  },
  {
    "text": "could be consumed by containers the",
    "start": "243040",
    "end": "245599"
  },
  {
    "text": "contributors put a great work here to",
    "start": "245599",
    "end": "247680"
  },
  {
    "text": "lower boundaries of accessing custom",
    "start": "247680",
    "end": "249519"
  },
  {
    "text": "devices",
    "start": "249519",
    "end": "250319"
  },
  {
    "text": "so let's check it out let's keep it",
    "start": "250319",
    "end": "252799"
  },
  {
    "text": "general and imagine we are on a worker",
    "start": "252799",
    "end": "254720"
  },
  {
    "text": "note",
    "start": "254720",
    "end": "255519"
  },
  {
    "text": "um as we all know each of our node is",
    "start": "255519",
    "end": "258239"
  },
  {
    "text": "running kubernetes or node agent",
    "start": "258239",
    "end": "260000"
  },
  {
    "text": "which is responsible for a variety of",
    "start": "260000",
    "end": "261919"
  },
  {
    "text": "things such as spawning or containers",
    "start": "261919",
    "end": "263759"
  },
  {
    "text": "and keeping them running",
    "start": "263759",
    "end": "264880"
  },
  {
    "text": "and talking to the queen eats master if",
    "start": "264880",
    "end": "267199"
  },
  {
    "text": "we now attach our own custom device to",
    "start": "267199",
    "end": "269440"
  },
  {
    "text": "our node and we want to make it not only",
    "start": "269440",
    "end": "271440"
  },
  {
    "text": "consumable",
    "start": "271440",
    "end": "272400"
  },
  {
    "text": "but scheduled through kubernetes itself",
    "start": "272400",
    "end": "274800"
  },
  {
    "text": "we need to install the windows device",
    "start": "274800",
    "end": "276320"
  },
  {
    "text": "plugin",
    "start": "276320",
    "end": "277360"
  },
  {
    "text": "which is actually a simple jrpc server",
    "start": "277360",
    "end": "280080"
  },
  {
    "text": "running",
    "start": "280080",
    "end": "280560"
  },
  {
    "text": "on every node where we have and one to",
    "start": "280560",
    "end": "282720"
  },
  {
    "text": "all of our custom device",
    "start": "282720",
    "end": "284639"
  },
  {
    "text": "once the device plug-in is deployed",
    "start": "284639",
    "end": "286639"
  },
  {
    "text": "through user deployment through",
    "start": "286639",
    "end": "288080"
  },
  {
    "text": "kubernetes",
    "start": "288080",
    "end": "289120"
  },
  {
    "text": "the vendor device plugin does some",
    "start": "289120",
    "end": "291280"
  },
  {
    "text": "initial hardware initialization",
    "start": "291280",
    "end": "293680"
  },
  {
    "text": "for example finding the hardware loading",
    "start": "293680",
    "end": "295759"
  },
  {
    "text": "with driver etc",
    "start": "295759",
    "end": "297199"
  },
  {
    "text": "once done it registers itself by",
    "start": "297199",
    "end": "301360"
  },
  {
    "text": "uh it reduces itself by calling register",
    "start": "301360",
    "end": "304160"
  },
  {
    "text": "and passes the resource identifier we",
    "start": "304160",
    "end": "306080"
  },
  {
    "text": "already have seen on our pod",
    "start": "306080",
    "end": "307360"
  },
  {
    "text": "specification",
    "start": "307360",
    "end": "308560"
  },
  {
    "text": "consisting of a vendor name and the",
    "start": "308560",
    "end": "310560"
  },
  {
    "text": "device name once done cubelet will",
    "start": "310560",
    "end": "312880"
  },
  {
    "text": "register the given device plugin",
    "start": "312880",
    "end": "315120"
  },
  {
    "text": "and the offered resource and continue on",
    "start": "315120",
    "end": "318080"
  },
  {
    "text": "requesting",
    "start": "318080",
    "end": "318800"
  },
  {
    "text": "more details on the number of available",
    "start": "318800",
    "end": "320880"
  },
  {
    "text": "resources and also identifiers",
    "start": "320880",
    "end": "322800"
  },
  {
    "text": "by kubelet regularly checks we have",
    "start": "322800",
    "end": "324720"
  },
  {
    "text": "setups of the device ids for given",
    "start": "324720",
    "end": "327039"
  },
  {
    "text": "devices",
    "start": "327039",
    "end": "327840"
  },
  {
    "text": "the device ids are used before container",
    "start": "327840",
    "end": "330880"
  },
  {
    "text": "creation and pass by kubelet through",
    "start": "330880",
    "end": "333199"
  },
  {
    "text": "allocate function to the device plugin",
    "start": "333199",
    "end": "337199"
  },
  {
    "text": "during the allocate function the device",
    "start": "337199",
    "end": "339039"
  },
  {
    "text": "plugin prepares the device",
    "start": "339039",
    "end": "340800"
  },
  {
    "text": "marks it internally as use and returns",
    "start": "340800",
    "end": "343759"
  },
  {
    "text": "back",
    "start": "343759",
    "end": "344320"
  },
  {
    "text": "data which is crucial for the container",
    "start": "344320",
    "end": "347280"
  },
  {
    "text": "to",
    "start": "347280",
    "end": "347759"
  },
  {
    "text": "yeah to consume with device correctly",
    "start": "347759",
    "end": "350639"
  },
  {
    "text": "and so the key function",
    "start": "350639",
    "end": "352240"
  },
  {
    "text": "to be implemented in the device plugin",
    "start": "352240",
    "end": "354080"
  },
  {
    "text": "are the functions allocate",
    "start": "354080",
    "end": "356160"
  },
  {
    "text": "register and list and watch so",
    "start": "356160",
    "end": "360000"
  },
  {
    "text": "let's have a look on what happens behind",
    "start": "360000",
    "end": "361919"
  },
  {
    "text": "the scenes once i deploy a machine",
    "start": "361919",
    "end": "363680"
  },
  {
    "text": "learning model to kubernetes which",
    "start": "363680",
    "end": "365520"
  },
  {
    "text": "requests an nvidia gpu",
    "start": "365520",
    "end": "367360"
  },
  {
    "text": "in the swim line diagram you can see to",
    "start": "367360",
    "end": "369280"
  },
  {
    "text": "the most right or gpu",
    "start": "369280",
    "end": "371280"
  },
  {
    "text": "to the left um most right by the device",
    "start": "371280",
    "end": "374880"
  },
  {
    "text": "plugin then our workers in our master",
    "start": "374880",
    "end": "376960"
  },
  {
    "text": "node",
    "start": "376960",
    "end": "377919"
  },
  {
    "text": "in the first stage as discussed before",
    "start": "377919",
    "end": "380160"
  },
  {
    "text": "our device plugin does some hardware",
    "start": "380160",
    "end": "381759"
  },
  {
    "text": "unitization",
    "start": "381759",
    "end": "382639"
  },
  {
    "text": "by discovering the gpus which are",
    "start": "382639",
    "end": "384960"
  },
  {
    "text": "attached to the node",
    "start": "384960",
    "end": "386160"
  },
  {
    "text": "once done it reduces itself in the",
    "start": "386160",
    "end": "388400"
  },
  {
    "text": "second stage of kubernetes",
    "start": "388400",
    "end": "390000"
  },
  {
    "text": "and interestingly is that that cubelet",
    "start": "390000",
    "end": "392960"
  },
  {
    "text": "reports back to the master",
    "start": "392960",
    "end": "395199"
  },
  {
    "text": "note the availability of the new device",
    "start": "395199",
    "end": "397520"
  },
  {
    "text": "as just advertised by the device",
    "start": "397520",
    "end": "399360"
  },
  {
    "text": "flagging",
    "start": "399360",
    "end": "399919"
  },
  {
    "text": "if not already done by other device",
    "start": "399919",
    "end": "401600"
  },
  {
    "text": "plugins which are running on other nodes",
    "start": "401600",
    "end": "403440"
  },
  {
    "text": "upon that cubelet gets data about the",
    "start": "403440",
    "end": "405520"
  },
  {
    "text": "available devices on the node",
    "start": "405520",
    "end": "407360"
  },
  {
    "text": "from the device plugin in the third",
    "start": "407360",
    "end": "409199"
  },
  {
    "text": "stage the device plugin makes",
    "start": "409199",
    "end": "411280"
  },
  {
    "text": "all gpus unique and returns back their",
    "start": "411280",
    "end": "415199"
  },
  {
    "text": "ids",
    "start": "415199",
    "end": "416720"
  },
  {
    "text": "as kubernetes is now aware of the number",
    "start": "416720",
    "end": "418800"
  },
  {
    "text": "of available gpus on the nodes",
    "start": "418800",
    "end": "421199"
  },
  {
    "text": "it reports to count back to the master",
    "start": "421199",
    "end": "423599"
  },
  {
    "text": "because the master needs to know what is",
    "start": "423599",
    "end": "425520"
  },
  {
    "text": "available",
    "start": "425520",
    "end": "426400"
  },
  {
    "text": "to schedule the tensorflow model a which",
    "start": "426400",
    "end": "428479"
  },
  {
    "text": "are just",
    "start": "428479",
    "end": "429599"
  },
  {
    "text": "submitting as a user once kubernetes",
    "start": "429599",
    "end": "432639"
  },
  {
    "text": "receives the request to schedule the",
    "start": "432639",
    "end": "434479"
  },
  {
    "text": "model it allocates in stage 4 a gpu",
    "start": "434479",
    "end": "437680"
  },
  {
    "text": "given that the user requests the gpu and",
    "start": "437680",
    "end": "440720"
  },
  {
    "text": "then the nvidia device plugin returns an",
    "start": "440720",
    "end": "443120"
  },
  {
    "text": "environment variable",
    "start": "443120",
    "end": "444160"
  },
  {
    "text": "nvidia visible device gpu with the gpu",
    "start": "444160",
    "end": "446800"
  },
  {
    "text": "id",
    "start": "446800",
    "end": "447360"
  },
  {
    "text": "which is later then passed to the",
    "start": "447360",
    "end": "448840"
  },
  {
    "text": "container and which can directly access",
    "start": "448840",
    "end": "451199"
  },
  {
    "text": "the corresponding gpu",
    "start": "451199",
    "end": "452720"
  },
  {
    "text": "within the container and at this point",
    "start": "452720",
    "end": "455840"
  },
  {
    "text": "where it gets very interesting for",
    "start": "455840",
    "end": "459039"
  },
  {
    "text": "implementation and actually this was the",
    "start": "459039",
    "end": "461440"
  },
  {
    "text": "whole magic",
    "start": "461440",
    "end": "462479"
  },
  {
    "text": "provisioning a gpu",
    "start": "462479",
    "end": "465520"
  },
  {
    "text": "back then we actually shared our initial",
    "start": "465520",
    "end": "468080"
  },
  {
    "text": "thoughts",
    "start": "468080",
    "end": "468639"
  },
  {
    "text": "findings and implementation approaches",
    "start": "468639",
    "end": "471039"
  },
  {
    "text": "with the community in many comments",
    "start": "471039",
    "end": "473280"
  },
  {
    "text": "thanks again here for thomas youngblood",
    "start": "473280",
    "end": "475440"
  },
  {
    "text": "working with me on this topic",
    "start": "475440",
    "end": "477520"
  },
  {
    "text": "back then we identified three possible",
    "start": "477520",
    "end": "480240"
  },
  {
    "text": "variants on sharing a gpu",
    "start": "480240",
    "end": "482160"
  },
  {
    "text": "the first which was already in place is",
    "start": "482160",
    "end": "484479"
  },
  {
    "text": "the model staffing on application logic",
    "start": "484479",
    "end": "486800"
  },
  {
    "text": "where we bake multiple models into one",
    "start": "486800",
    "end": "489840"
  },
  {
    "text": "docker image and use tensorflow serving",
    "start": "489840",
    "end": "492000"
  },
  {
    "text": "to switch between these",
    "start": "492000",
    "end": "493599"
  },
  {
    "text": "this very static approach does not offer",
    "start": "493599",
    "end": "495840"
  },
  {
    "text": "any c groups for each model",
    "start": "495840",
    "end": "497680"
  },
  {
    "text": "but the whole model and in addition to",
    "start": "497680",
    "end": "499759"
  },
  {
    "text": "that extended features such as rate",
    "start": "499759",
    "end": "501680"
  },
  {
    "text": "limiting per model is not possible",
    "start": "501680",
    "end": "504479"
  },
  {
    "text": "the third variant has been the node",
    "start": "504479",
    "end": "506400"
  },
  {
    "text": "selector hacking and you hear it",
    "start": "506400",
    "end": "508240"
  },
  {
    "text": "it is hacking we do not use the device",
    "start": "508240",
    "end": "511120"
  },
  {
    "text": "plugin at all we give the container the",
    "start": "511120",
    "end": "513200"
  },
  {
    "text": "privilege mode which",
    "start": "513200",
    "end": "514479"
  },
  {
    "text": "which you should never ever do and let",
    "start": "514479",
    "end": "516800"
  },
  {
    "text": "the containers use the gpus on their own",
    "start": "516800",
    "end": "519200"
  },
  {
    "text": "the drawback of this approach is that",
    "start": "519200",
    "end": "521200"
  },
  {
    "text": "kubernetes does not really know that",
    "start": "521200",
    "end": "522959"
  },
  {
    "text": "there are gpus and cannot respect them",
    "start": "522959",
    "end": "524959"
  },
  {
    "text": "during the scheduling",
    "start": "524959",
    "end": "526320"
  },
  {
    "text": "and a very large problem is that",
    "start": "526320",
    "end": "528480"
  },
  {
    "text": "kubernetes might schedule pots on your",
    "start": "528480",
    "end": "530320"
  },
  {
    "text": "node",
    "start": "530320",
    "end": "530800"
  },
  {
    "text": "even though you do not have any gpus",
    "start": "530800",
    "end": "532720"
  },
  {
    "text": "left in",
    "start": "532720",
    "end": "534000"
  },
  {
    "text": "the end we have decided for variant two",
    "start": "534000",
    "end": "536640"
  },
  {
    "text": "well it was not really a decision but",
    "start": "536640",
    "end": "538800"
  },
  {
    "text": "more exploration",
    "start": "538800",
    "end": "540080"
  },
  {
    "text": "and with the health initial help of some",
    "start": "540080",
    "end": "542720"
  },
  {
    "text": "developers from the nvidia device plugin",
    "start": "542720",
    "end": "545040"
  },
  {
    "text": "bavarian too tries to solve this issue",
    "start": "545040",
    "end": "547040"
  },
  {
    "text": "in a more native way by extending with",
    "start": "547040",
    "end": "549200"
  },
  {
    "text": "device plug-in",
    "start": "549200",
    "end": "550720"
  },
  {
    "text": "by so called vgpus to be honest vgp",
    "start": "550720",
    "end": "553680"
  },
  {
    "text": "sound",
    "start": "553680",
    "end": "554080"
  },
  {
    "text": "very terrific but there are not so let's",
    "start": "554080",
    "end": "556720"
  },
  {
    "text": "check out how we extended the device",
    "start": "556720",
    "end": "558320"
  },
  {
    "text": "plugin to",
    "start": "558320",
    "end": "559040"
  },
  {
    "text": "share some gpus so the problem",
    "start": "559040",
    "end": "562080"
  },
  {
    "text": "in general was that once a gpu id is",
    "start": "562080",
    "end": "564640"
  },
  {
    "text": "allocated",
    "start": "564640",
    "end": "565440"
  },
  {
    "text": "it is marked as used by the device",
    "start": "565440",
    "end": "567279"
  },
  {
    "text": "plugin and so no more",
    "start": "567279",
    "end": "569200"
  },
  {
    "text": "device are advertised from a kubernetes",
    "start": "569200",
    "end": "571040"
  },
  {
    "text": "to the kubernetes master",
    "start": "571040",
    "end": "572640"
  },
  {
    "text": "in other words any deployments",
    "start": "572640",
    "end": "574640"
  },
  {
    "text": "requesting",
    "start": "574640",
    "end": "575760"
  },
  {
    "text": "gpu will be pushed back as request",
    "start": "575760",
    "end": "578080"
  },
  {
    "text": "requirements cannot be met",
    "start": "578080",
    "end": "579680"
  },
  {
    "text": "in addition to that we knew from node",
    "start": "579680",
    "end": "581519"
  },
  {
    "text": "selector hacking and model stuffing",
    "start": "581519",
    "end": "583839"
  },
  {
    "text": "that the gpu can actually handle",
    "start": "583839",
    "end": "586000"
  },
  {
    "text": "multiple processes",
    "start": "586000",
    "end": "587200"
  },
  {
    "text": "accessing directly to the gpu so we",
    "start": "587200",
    "end": "589680"
  },
  {
    "text": "started thinking about",
    "start": "589680",
    "end": "591519"
  },
  {
    "text": "how we can do that why we shouldn't",
    "start": "591519",
    "end": "593760"
  },
  {
    "text": "advertise more gpus if there's even only",
    "start": "593760",
    "end": "596000"
  },
  {
    "text": "one gpu",
    "start": "596000",
    "end": "596959"
  },
  {
    "text": "so a solution was that simple we",
    "start": "596959",
    "end": "599200"
  },
  {
    "text": "generate using the gpu id of a physical",
    "start": "599200",
    "end": "601920"
  },
  {
    "text": "gpu",
    "start": "601920",
    "end": "602640"
  },
  {
    "text": "a number of virtual gpus by simply",
    "start": "602640",
    "end": "604640"
  },
  {
    "text": "adding a suffix",
    "start": "604640",
    "end": "605760"
  },
  {
    "text": "afterwards we assign those vgpus in the",
    "start": "605760",
    "end": "608000"
  },
  {
    "text": "device plugin",
    "start": "608000",
    "end": "609040"
  },
  {
    "text": "to the physical one and tell cubelet",
    "start": "609040",
    "end": "611760"
  },
  {
    "text": "that we own more gpus with gpu id so we",
    "start": "611760",
    "end": "614399"
  },
  {
    "text": "lie",
    "start": "614399",
    "end": "615279"
  },
  {
    "text": "once google had calls for allocate",
    "start": "615279",
    "end": "616880"
  },
  {
    "text": "function we simply remap the virtual gpu",
    "start": "616880",
    "end": "619519"
  },
  {
    "text": "id",
    "start": "619519",
    "end": "620000"
  },
  {
    "text": "to a physical one and that's it",
    "start": "620000",
    "end": "623279"
  },
  {
    "text": "but as simple it sounds we have quite a",
    "start": "623279",
    "end": "625440"
  },
  {
    "text": "few trade-offs of this approach it",
    "start": "625440",
    "end": "627279"
  },
  {
    "text": "already starts",
    "start": "627279",
    "end": "628240"
  },
  {
    "text": "with a problem how many vgpus can we or",
    "start": "628240",
    "end": "631279"
  },
  {
    "text": "shall we provision per gpu",
    "start": "631279",
    "end": "633440"
  },
  {
    "text": "how do we set the limit and are there",
    "start": "633440",
    "end": "635600"
  },
  {
    "text": "any boundaries with regards to recall",
    "start": "635600",
    "end": "638160"
  },
  {
    "text": "and gpu memory so we ask ourselves",
    "start": "638160",
    "end": "640880"
  },
  {
    "text": "following questions",
    "start": "640880",
    "end": "642800"
  },
  {
    "text": "how many models can we fit on the nvidia",
    "start": "642800",
    "end": "645040"
  },
  {
    "text": "k80 we are running",
    "start": "645040",
    "end": "646640"
  },
  {
    "text": "our machine inference models on the k80",
    "start": "646640",
    "end": "649120"
  },
  {
    "text": "how does the whole system behave",
    "start": "649120",
    "end": "650800"
  },
  {
    "text": "and what are the trade-offs in doing so",
    "start": "650800",
    "end": "652959"
  },
  {
    "text": "and limitations of course",
    "start": "652959",
    "end": "654399"
  },
  {
    "text": "so we did our experiments and collected",
    "start": "654399",
    "end": "656560"
  },
  {
    "text": "data talking about collecting data",
    "start": "656560",
    "end": "659040"
  },
  {
    "text": "the device plugging is nothing more than",
    "start": "659040",
    "end": "661120"
  },
  {
    "text": "a port accessing the local devices to",
    "start": "661120",
    "end": "663440"
  },
  {
    "text": "advertise resources to kubernetes",
    "start": "663440",
    "end": "665760"
  },
  {
    "text": "meaning that the very same strategy of",
    "start": "665760",
    "end": "668240"
  },
  {
    "text": "parts for monitoring and collecting data",
    "start": "668240",
    "end": "670800"
  },
  {
    "text": "can be used here too so we extended with",
    "start": "670800",
    "end": "673680"
  },
  {
    "text": "nvidia device plugin",
    "start": "673680",
    "end": "674959"
  },
  {
    "text": "which internally uses the nvidia",
    "start": "674959",
    "end": "677120"
  },
  {
    "text": "management library",
    "start": "677120",
    "end": "679279"
  },
  {
    "text": "to collect additional data from the",
    "start": "679279",
    "end": "681279"
  },
  {
    "text": "devices",
    "start": "681279",
    "end": "682480"
  },
  {
    "text": "and the nvml library actually offers low",
    "start": "682480",
    "end": "684880"
  },
  {
    "text": "level access",
    "start": "684880",
    "end": "685920"
  },
  {
    "text": "with code c binding so in the end we",
    "start": "685920",
    "end": "688160"
  },
  {
    "text": "created a few graphana dashboards",
    "start": "688160",
    "end": "690240"
  },
  {
    "text": "with the data we got from promotois to",
    "start": "690240",
    "end": "692160"
  },
  {
    "text": "track different values",
    "start": "692160",
    "end": "693519"
  },
  {
    "text": "such as number of virtual gpus we",
    "start": "693519",
    "end": "695760"
  },
  {
    "text": "consume gpu",
    "start": "695760",
    "end": "696959"
  },
  {
    "text": "param per vgpu and with utilization",
    "start": "696959",
    "end": "700480"
  },
  {
    "text": "so we have collected data we have a",
    "start": "700480",
    "end": "702800"
  },
  {
    "text": "proper question and so we did some",
    "start": "702800",
    "end": "705040"
  },
  {
    "text": "experiments to answer those",
    "start": "705040",
    "end": "706560"
  },
  {
    "text": "so let's check out our experiments in",
    "start": "706560",
    "end": "708399"
  },
  {
    "text": "the first experiment we do the vowel",
    "start": "708399",
    "end": "710399"
  },
  {
    "text": "noun and body simulation",
    "start": "710399",
    "end": "712160"
  },
  {
    "text": "while it is not really comparable to",
    "start": "712160",
    "end": "714000"
  },
  {
    "text": "machine learning inference it still",
    "start": "714000",
    "end": "715760"
  },
  {
    "text": "gives us some insight on how the work",
    "start": "715760",
    "end": "717839"
  },
  {
    "text": "might be distributed internally",
    "start": "717839",
    "end": "719600"
  },
  {
    "text": "and amazingly to left we can see that",
    "start": "719600",
    "end": "722079"
  },
  {
    "text": "the g flops per",
    "start": "722079",
    "end": "723279"
  },
  {
    "text": "second are distributed evenly with every",
    "start": "723279",
    "end": "725839"
  },
  {
    "text": "part we just added",
    "start": "725839",
    "end": "727680"
  },
  {
    "text": "the spare scheduling is also confirmed",
    "start": "727680",
    "end": "729680"
  },
  {
    "text": "by our data to the right",
    "start": "729680",
    "end": "731040"
  },
  {
    "text": "where the amount of time for an",
    "start": "731040",
    "end": "732639"
  },
  {
    "text": "experiment to finish",
    "start": "732639",
    "end": "734079"
  },
  {
    "text": "grows linearly with the number of ports",
    "start": "734079",
    "end": "736160"
  },
  {
    "text": "accessing a vgpu",
    "start": "736160",
    "end": "738800"
  },
  {
    "text": "keep in mind that we did not limit the",
    "start": "738800",
    "end": "740800"
  },
  {
    "text": "vgpu nor the gpu",
    "start": "740800",
    "end": "743440"
  },
  {
    "text": "hadn't have given every part a fair",
    "start": "743440",
    "end": "745680"
  },
  {
    "text": "share of cpu",
    "start": "745680",
    "end": "747120"
  },
  {
    "text": "from the node p2x large at aws we were",
    "start": "747120",
    "end": "750320"
  },
  {
    "text": "running on",
    "start": "750320",
    "end": "751279"
  },
  {
    "text": "while the experiment is kind of",
    "start": "751279",
    "end": "752720"
  },
  {
    "text": "comparable to machine learning training",
    "start": "752720",
    "end": "754639"
  },
  {
    "text": "we were more interested in sharing gpus",
    "start": "754639",
    "end": "757120"
  },
  {
    "text": "in the case of machine learning",
    "start": "757120",
    "end": "758320"
  },
  {
    "text": "inference",
    "start": "758320",
    "end": "760000"
  },
  {
    "text": "um actually it includes more factors",
    "start": "760000",
    "end": "762720"
  },
  {
    "text": "such as network",
    "start": "762720",
    "end": "763760"
  },
  {
    "text": "throughput and latency so let's check",
    "start": "763760",
    "end": "766000"
  },
  {
    "text": "out those",
    "start": "766000",
    "end": "767120"
  },
  {
    "text": "experiments we have done um in general",
    "start": "767120",
    "end": "770480"
  },
  {
    "text": "let's forget to say this we are running",
    "start": "770480",
    "end": "772240"
  },
  {
    "text": "all of our experiments on a p2x large",
    "start": "772240",
    "end": "774320"
  },
  {
    "text": "instance which has",
    "start": "774320",
    "end": "775519"
  },
  {
    "text": "four cores and one nvidia tesla k80",
    "start": "775519",
    "end": "778240"
  },
  {
    "text": "attached with 12 gigabyte ram",
    "start": "778240",
    "end": "780240"
  },
  {
    "text": "as the inception v3 model was used back",
    "start": "780240",
    "end": "782880"
  },
  {
    "text": "then for a large amount of our",
    "start": "782880",
    "end": "784320"
  },
  {
    "text": "production workload",
    "start": "784320",
    "end": "785440"
  },
  {
    "text": "we use it to thrive for our experiments",
    "start": "785440",
    "end": "787519"
  },
  {
    "text": "the first very inference experiment we",
    "start": "787519",
    "end": "789519"
  },
  {
    "text": "spawned in total up to",
    "start": "789519",
    "end": "790880"
  },
  {
    "text": "12 redeviews and sent in total of 10 000",
    "start": "790880",
    "end": "793920"
  },
  {
    "text": "required per part",
    "start": "793920",
    "end": "795279"
  },
  {
    "text": "and limited each part with 350 amp cpu",
    "start": "795279",
    "end": "798959"
  },
  {
    "text": "you will see later how important in our",
    "start": "798959",
    "end": "801200"
  },
  {
    "text": "implementation",
    "start": "801200",
    "end": "802079"
  },
  {
    "text": "the limiting of cpu actually is a",
    "start": "802079",
    "end": "804399"
  },
  {
    "text": "disclaimer at this point",
    "start": "804399",
    "end": "805680"
  },
  {
    "text": "this experiment is done using a",
    "start": "805680",
    "end": "807279"
  },
  {
    "text": "sequential request pattern",
    "start": "807279",
    "end": "809040"
  },
  {
    "text": "meaning each model handles at most one",
    "start": "809040",
    "end": "811839"
  },
  {
    "text": "request at a time given the data to the",
    "start": "811839",
    "end": "814800"
  },
  {
    "text": "left for 12 models running on 12 vgpus",
    "start": "814800",
    "end": "817680"
  },
  {
    "text": "we have a p99",
    "start": "817680",
    "end": "819440"
  },
  {
    "text": "in response time below 500 milliseconds",
    "start": "819440",
    "end": "822399"
  },
  {
    "text": "you might be asking how we managed to",
    "start": "822399",
    "end": "824399"
  },
  {
    "text": "fit 12 inception models onto one k80",
    "start": "824399",
    "end": "826959"
  },
  {
    "text": "with software by drum",
    "start": "826959",
    "end": "828800"
  },
  {
    "text": "while most of the time a model wants to",
    "start": "828800",
    "end": "830800"
  },
  {
    "text": "allocate a full gpu",
    "start": "830800",
    "end": "832399"
  },
  {
    "text": "for that matter we used a very nice",
    "start": "832399",
    "end": "834320"
  },
  {
    "text": "functionality of tensorflow",
    "start": "834320",
    "end": "836000"
  },
  {
    "text": "serving and in terms of reserving one",
    "start": "836000",
    "end": "839279"
  },
  {
    "text": "can specify using tf.g",
    "start": "839279",
    "end": "842240"
  },
  {
    "text": "options the fraction of gpu ram and",
    "start": "842240",
    "end": "844160"
  },
  {
    "text": "model is limited to",
    "start": "844160",
    "end": "845519"
  },
  {
    "text": "given our data to the right you can see",
    "start": "845519",
    "end": "847279"
  },
  {
    "text": "that with 12 models",
    "start": "847279",
    "end": "848800"
  },
  {
    "text": "running on 1k80 we assign each model",
    "start": "848800",
    "end": "851600"
  },
  {
    "text": "only five percent of",
    "start": "851600",
    "end": "852959"
  },
  {
    "text": "available vram which corresponds approx",
    "start": "852959",
    "end": "856079"
  },
  {
    "text": "600 megabyte for each model another",
    "start": "856079",
    "end": "858639"
  },
  {
    "text": "approach was to offer vgpus",
    "start": "858639",
    "end": "860720"
  },
  {
    "text": "until our memory is full to get the most",
    "start": "860720",
    "end": "862560"
  },
  {
    "text": "of the gpu",
    "start": "862560",
    "end": "864000"
  },
  {
    "text": "but actually we were very keen about",
    "start": "864000",
    "end": "866160"
  },
  {
    "text": "finding the",
    "start": "866160",
    "end": "867120"
  },
  {
    "text": "upper limit how many models can be run",
    "start": "867120",
    "end": "869199"
  },
  {
    "text": "without crashing on a 1k80",
    "start": "869199",
    "end": "871839"
  },
  {
    "text": "so we ask ourselves can we go actually",
    "start": "871839",
    "end": "874160"
  },
  {
    "text": "deeper and",
    "start": "874160",
    "end": "875360"
  },
  {
    "text": "hell yeah the inception model 3 model",
    "start": "875360",
    "end": "878000"
  },
  {
    "text": "requests at most 228 megabytes",
    "start": "878000",
    "end": "881120"
  },
  {
    "text": "per model so it's theoretically possible",
    "start": "881120",
    "end": "883680"
  },
  {
    "text": "to stack up to 50 models on one gpu",
    "start": "883680",
    "end": "886720"
  },
  {
    "text": "due to the cpu limitation on our cp2",
    "start": "886720",
    "end": "889120"
  },
  {
    "text": "instance we could run this x-men only",
    "start": "889120",
    "end": "891279"
  },
  {
    "text": "for",
    "start": "891279",
    "end": "891839"
  },
  {
    "text": "30 models with a cpu limit of 100m",
    "start": "891839",
    "end": "895519"
  },
  {
    "text": "and assigning the three percent of which",
    "start": "895519",
    "end": "897760"
  },
  {
    "text": "ram we are",
    "start": "897760",
    "end": "898639"
  },
  {
    "text": "having on our gpu keep in mind that this",
    "start": "898639",
    "end": "901040"
  },
  {
    "text": "is still sequential request pattern",
    "start": "901040",
    "end": "903120"
  },
  {
    "text": "nevertheless for 30 moles or p99",
    "start": "903120",
    "end": "906160"
  },
  {
    "text": "response time",
    "start": "906160",
    "end": "907199"
  },
  {
    "text": "versioned only by factor 10",
    "start": "907199",
    "end": "910480"
  },
  {
    "text": "compared to a single deployment in our",
    "start": "910480",
    "end": "912720"
  },
  {
    "text": "opinion this is an",
    "start": "912720",
    "end": "913839"
  },
  {
    "text": "amazing way to keep models running which",
    "start": "913839",
    "end": "916240"
  },
  {
    "text": "do not have large spikes",
    "start": "916240",
    "end": "918160"
  },
  {
    "text": "in the amount of incoming requests these",
    "start": "918160",
    "end": "920959"
  },
  {
    "text": "were quite some interesting results",
    "start": "920959",
    "end": "922959"
  },
  {
    "text": "but we also emulated of course the",
    "start": "922959",
    "end": "925199"
  },
  {
    "text": "parallel request pattern",
    "start": "925199",
    "end": "928000"
  },
  {
    "text": "and keep in mind we are still on our p2",
    "start": "928000",
    "end": "930079"
  },
  {
    "text": "setup with inception v3 but this time we",
    "start": "930079",
    "end": "932639"
  },
  {
    "text": "let the model process",
    "start": "932639",
    "end": "933920"
  },
  {
    "text": "10 requests at the time we did not",
    "start": "933920",
    "end": "936160"
  },
  {
    "text": "enable matching here to establish a",
    "start": "936160",
    "end": "938399"
  },
  {
    "text": "baseline where we could later",
    "start": "938399",
    "end": "940160"
  },
  {
    "text": "on compared with batching when we start",
    "start": "940160",
    "end": "943199"
  },
  {
    "text": "our experiment for one deployment to",
    "start": "943199",
    "end": "945199"
  },
  {
    "text": "establish a battery sign",
    "start": "945199",
    "end": "946639"
  },
  {
    "text": "we were able to observe that increasing",
    "start": "946639",
    "end": "948959"
  },
  {
    "text": "or decreasing the cpu limit",
    "start": "948959",
    "end": "950959"
  },
  {
    "text": "with also limit or deputization so",
    "start": "950959",
    "end": "953920"
  },
  {
    "text": "simply stated",
    "start": "953920",
    "end": "955279"
  },
  {
    "text": "we introduce an artificial bottleneck",
    "start": "955279",
    "end": "957600"
  },
  {
    "text": "here for the gpu utilization",
    "start": "957600",
    "end": "959519"
  },
  {
    "text": "this has a huge impact as we can avoid",
    "start": "959519",
    "end": "962320"
  },
  {
    "text": "the cpu limit",
    "start": "962320",
    "end": "964000"
  },
  {
    "text": "and over commitment of the gpu in",
    "start": "964000",
    "end": "966639"
  },
  {
    "text": "general",
    "start": "966639",
    "end": "967199"
  },
  {
    "text": "we have observed that and our commitment",
    "start": "967199",
    "end": "969440"
  },
  {
    "text": "will lead to a large increase in latency",
    "start": "969440",
    "end": "971920"
  },
  {
    "text": "so the equation is really simple in that",
    "start": "971920",
    "end": "973839"
  },
  {
    "text": "regard if you increase your throughput",
    "start": "973839",
    "end": "975680"
  },
  {
    "text": "the gpu has more work to do",
    "start": "975680",
    "end": "978320"
  },
  {
    "text": "so given the limit of 350 amp for the",
    "start": "978320",
    "end": "980800"
  },
  {
    "text": "cpu and three person vram",
    "start": "980800",
    "end": "982880"
  },
  {
    "text": "we were able to have 10.7 queries per",
    "start": "982880",
    "end": "986000"
  },
  {
    "text": "second",
    "start": "986000",
    "end": "986480"
  },
  {
    "text": "at the gpu utilization of 50 for one",
    "start": "986480",
    "end": "989440"
  },
  {
    "text": "deployment",
    "start": "989440",
    "end": "990399"
  },
  {
    "text": "for two deployments we were successfully",
    "start": "990399",
    "end": "992959"
  },
  {
    "text": "able to fully utilize",
    "start": "992959",
    "end": "994720"
  },
  {
    "text": "a gpu at about 98 percent",
    "start": "994720",
    "end": "998079"
  },
  {
    "text": "and achieved more than double of a qps",
    "start": "998079",
    "end": "1001120"
  },
  {
    "text": "for a similar latency enabling batching",
    "start": "1001120",
    "end": "1004160"
  },
  {
    "text": "we could even decrease the latency and",
    "start": "1004160",
    "end": "1006320"
  },
  {
    "text": "increase the throughput by two times in",
    "start": "1006320",
    "end": "1008320"
  },
  {
    "text": "exchange for 6",
    "start": "1008320",
    "end": "1009600"
  },
  {
    "text": "times more vram given all these data",
    "start": "1009600",
    "end": "1013759"
  },
  {
    "text": "we ask ourselves again is sharing to gpu",
    "start": "1013759",
    "end": "1016959"
  },
  {
    "text": "to multiple containers really feasible",
    "start": "1016959",
    "end": "1019839"
  },
  {
    "text": "well in germany",
    "start": "1019839",
    "end": "1021519"
  },
  {
    "text": "germans after seeing all of these",
    "start": "1021519",
    "end": "1022880"
  },
  {
    "text": "results would say yang",
    "start": "1022880",
    "end": "1024558"
  },
  {
    "text": "which is a slang for yes and now or in",
    "start": "1024559",
    "end": "1026720"
  },
  {
    "text": "other words in our world",
    "start": "1026720",
    "end": "1028240"
  },
  {
    "text": "yes you can share every gpu but we have",
    "start": "1028240",
    "end": "1030240"
  },
  {
    "text": "trade-offs and except at least for",
    "start": "1030240",
    "end": "1032558"
  },
  {
    "text": "this implementation um some limitations",
    "start": "1032559",
    "end": "1037199"
  },
  {
    "text": "so after having so many figures and",
    "start": "1037199",
    "end": "1040558"
  },
  {
    "text": "numbers you were asking yourself okay",
    "start": "1040559",
    "end": "1041918"
  },
  {
    "text": "what happened now here",
    "start": "1041919",
    "end": "1043280"
  },
  {
    "text": "so what does it all mean for our",
    "start": "1043280",
    "end": "1045038"
  },
  {
    "text": "implementation to be clear and honest",
    "start": "1045039",
    "end": "1047199"
  },
  {
    "text": "here our solution is",
    "start": "1047199",
    "end": "1048400"
  },
  {
    "text": "far away from product generatedness but",
    "start": "1048400",
    "end": "1051039"
  },
  {
    "text": "we",
    "start": "1051039",
    "end": "1051440"
  },
  {
    "text": "were still able to share our gpu with",
    "start": "1051440",
    "end": "1053919"
  },
  {
    "text": "very promising results",
    "start": "1053919",
    "end": "1055600"
  },
  {
    "text": "but for that result we really tried hard",
    "start": "1055600",
    "end": "1058080"
  },
  {
    "text": "we had to do a lot of runs",
    "start": "1058080",
    "end": "1059679"
  },
  {
    "text": "find out how much vram we actually need",
    "start": "1059679",
    "end": "1062320"
  },
  {
    "text": "and what our minimum limits",
    "start": "1062320",
    "end": "1064160"
  },
  {
    "text": "are and what is the relationship between",
    "start": "1064160",
    "end": "1066320"
  },
  {
    "text": "deputization cpu limitation",
    "start": "1066320",
    "end": "1068559"
  },
  {
    "text": "and throughput and latency nevertheless",
    "start": "1068559",
    "end": "1071679"
  },
  {
    "text": "we were able to save up to 30 times of",
    "start": "1071679",
    "end": "1074160"
  },
  {
    "text": "our costs for inception briefing models",
    "start": "1074160",
    "end": "1076320"
  },
  {
    "text": "running on top of k80 for machine",
    "start": "1076320",
    "end": "1078240"
  },
  {
    "text": "learning inference",
    "start": "1078240",
    "end": "1080000"
  },
  {
    "text": "besides the lock into tensorflow serving",
    "start": "1080000",
    "end": "1082240"
  },
  {
    "text": "for inference",
    "start": "1082240",
    "end": "1083200"
  },
  {
    "text": "due to the inability to limit virtual",
    "start": "1083200",
    "end": "1085840"
  },
  {
    "text": "ram from a device plugin",
    "start": "1085840",
    "end": "1087440"
  },
  {
    "text": "we had to misuse kubernetes cpu limits",
    "start": "1087440",
    "end": "1090720"
  },
  {
    "text": "to artificially",
    "start": "1090720",
    "end": "1091840"
  },
  {
    "text": "limit origin utilization while this is",
    "start": "1091840",
    "end": "1094160"
  },
  {
    "text": "very hacky and not really kubernetes",
    "start": "1094160",
    "end": "1096240"
  },
  {
    "text": "native we were still",
    "start": "1096240",
    "end": "1097360"
  },
  {
    "text": "able to deploy multiple models with",
    "start": "1097360",
    "end": "1100400"
  },
  {
    "text": "very similar latencies by fully",
    "start": "1100400",
    "end": "1102720"
  },
  {
    "text": "utilizing our gpu",
    "start": "1102720",
    "end": "1104160"
  },
  {
    "text": "and remember the calculation gpu",
    "start": "1104160",
    "end": "1106320"
  },
  {
    "text": "utilization was a problem",
    "start": "1106320",
    "end": "1108480"
  },
  {
    "text": "and with that we actually can fully",
    "start": "1108480",
    "end": "1111440"
  },
  {
    "text": "utilize our gpu",
    "start": "1111440",
    "end": "1112559"
  },
  {
    "text": "so we have saved some money to buy us",
    "start": "1112559",
    "end": "1114720"
  },
  {
    "text": "some things with our 300 000k",
    "start": "1114720",
    "end": "1118000"
  },
  {
    "text": "um so well there are of course other",
    "start": "1118000",
    "end": "1120880"
  },
  {
    "text": "limitations besides",
    "start": "1120880",
    "end": "1122240"
  },
  {
    "text": "the control of virtual ram and gpu",
    "start": "1122240",
    "end": "1125039"
  },
  {
    "text": "utilization the first and foremost is",
    "start": "1125039",
    "end": "1127280"
  },
  {
    "text": "that we do not really have a clue about",
    "start": "1127280",
    "end": "1129520"
  },
  {
    "text": "what happens on the gpu level",
    "start": "1129520",
    "end": "1131280"
  },
  {
    "text": "when we run multiple processes we assume",
    "start": "1131280",
    "end": "1133919"
  },
  {
    "text": "that there is some sort of fair",
    "start": "1133919",
    "end": "1135520"
  },
  {
    "text": "scheduling",
    "start": "1135520",
    "end": "1136480"
  },
  {
    "text": "mechanism which we could find out by our",
    "start": "1136480",
    "end": "1139280"
  },
  {
    "text": "experiments but still given the fact",
    "start": "1139280",
    "end": "1141280"
  },
  {
    "text": "nvidia cannot guarantee isolation on",
    "start": "1141280",
    "end": "1143600"
  },
  {
    "text": "hardware level",
    "start": "1143600",
    "end": "1144400"
  },
  {
    "text": "it does not make sense for us to run gpu",
    "start": "1144400",
    "end": "1146720"
  },
  {
    "text": "sharing in our multi-tenancy setup",
    "start": "1146720",
    "end": "1149280"
  },
  {
    "text": "moreover we are simply not able to",
    "start": "1149280",
    "end": "1151440"
  },
  {
    "text": "specify the vram and gpu cores",
    "start": "1151440",
    "end": "1154080"
  },
  {
    "text": "which makes it very hard to use native",
    "start": "1154080",
    "end": "1156160"
  },
  {
    "text": "kubernetes scheduling to schedule parts",
    "start": "1156160",
    "end": "1158640"
  },
  {
    "text": "speaking about scheduling we do our",
    "start": "1158640",
    "end": "1160720"
  },
  {
    "text": "scheduling driven by the number of",
    "start": "1160720",
    "end": "1162559"
  },
  {
    "text": "virtual gpus",
    "start": "1162559",
    "end": "1163679"
  },
  {
    "text": "it is not kubernetes deciding using some",
    "start": "1163679",
    "end": "1166880"
  },
  {
    "text": "detailed sub resources such as cars and",
    "start": "1166880",
    "end": "1169200"
  },
  {
    "text": "vram",
    "start": "1169200",
    "end": "1170320"
  },
  {
    "text": "but it's only using wii gpus where",
    "start": "1170320",
    "end": "1173600"
  },
  {
    "text": "we are responsible on deciding yeah how",
    "start": "1173600",
    "end": "1176559"
  },
  {
    "text": "we map our gpu to v3 pools",
    "start": "1176559",
    "end": "1179520"
  },
  {
    "text": "and another very simple problem is the",
    "start": "1179520",
    "end": "1181520"
  },
  {
    "text": "resource fragmentation",
    "start": "1181520",
    "end": "1182960"
  },
  {
    "text": "even if we have gpu sharing where we",
    "start": "1182960",
    "end": "1185120"
  },
  {
    "text": "have isolation and also",
    "start": "1185120",
    "end": "1187520"
  },
  {
    "text": "maybe possibility to specify limits on",
    "start": "1187520",
    "end": "1189679"
  },
  {
    "text": "vram and gpu costs",
    "start": "1189679",
    "end": "1191280"
  },
  {
    "text": "we are still unable to bin pack our",
    "start": "1191280",
    "end": "1193440"
  },
  {
    "text": "models correctly",
    "start": "1193440",
    "end": "1194640"
  },
  {
    "text": "because kubelet returns the api server",
    "start": "1194640",
    "end": "1197039"
  },
  {
    "text": "aggregated information",
    "start": "1197039",
    "end": "1199520"
  },
  {
    "text": "and it does not see the gpu as a first",
    "start": "1199520",
    "end": "1201600"
  },
  {
    "text": "class citizen",
    "start": "1201600",
    "end": "1202640"
  },
  {
    "text": "so it can happen that during the",
    "start": "1202640",
    "end": "1204400"
  },
  {
    "text": "scheduling of a workload",
    "start": "1204400",
    "end": "1206000"
  },
  {
    "text": "a gpu might get over-committed if there",
    "start": "1206000",
    "end": "1208320"
  },
  {
    "text": "are multiple gpus running on the same",
    "start": "1208320",
    "end": "1210320"
  },
  {
    "text": "node",
    "start": "1210320",
    "end": "1210960"
  },
  {
    "text": "for this problem we would have need a",
    "start": "1210960",
    "end": "1213120"
  },
  {
    "text": "locality area",
    "start": "1213120",
    "end": "1214480"
  },
  {
    "text": "scheduling mechanism implemented at the",
    "start": "1214480",
    "end": "1216720"
  },
  {
    "text": "nvidia device plugin",
    "start": "1216720",
    "end": "1218320"
  },
  {
    "text": "which avoids formal commitment of gpus",
    "start": "1218320",
    "end": "1222000"
  },
  {
    "text": "so now what do we really need to run gpu",
    "start": "1222000",
    "end": "1225679"
  },
  {
    "text": "sharing in production",
    "start": "1225679",
    "end": "1227120"
  },
  {
    "text": "we need isolation on gpu level with gpu",
    "start": "1227120",
    "end": "1229760"
  },
  {
    "text": "device driver should offer an api to",
    "start": "1229760",
    "end": "1232080"
  },
  {
    "text": "specify vram and gpu cores",
    "start": "1232080",
    "end": "1234320"
  },
  {
    "text": "constraints per process like like we had",
    "start": "1234320",
    "end": "1236799"
  },
  {
    "text": "in c groups",
    "start": "1236799",
    "end": "1237840"
  },
  {
    "text": "and we see we already see in cpu and",
    "start": "1237840",
    "end": "1240240"
  },
  {
    "text": "memory",
    "start": "1240240",
    "end": "1241440"
  },
  {
    "text": "at the current point of time nvidia",
    "start": "1241440",
    "end": "1243120"
  },
  {
    "text": "doesn't spot any solution with regards",
    "start": "1243120",
    "end": "1245360"
  },
  {
    "text": "to that",
    "start": "1245360",
    "end": "1246000"
  },
  {
    "text": "with we discussed before we source the",
    "start": "1246000",
    "end": "1248159"
  },
  {
    "text": "fragmentation our equipment",
    "start": "1248159",
    "end": "1250000"
  },
  {
    "text": "we need a device plugin which is able to",
    "start": "1250000",
    "end": "1251919"
  },
  {
    "text": "manage sharing of multiple gpus on one",
    "start": "1251919",
    "end": "1254159"
  },
  {
    "text": "node by",
    "start": "1254159",
    "end": "1255039"
  },
  {
    "text": "being locally aware and avoiding over",
    "start": "1255039",
    "end": "1257280"
  },
  {
    "text": "commitment of gpus",
    "start": "1257280",
    "end": "1258880"
  },
  {
    "text": "and another chapter we did not really",
    "start": "1258880",
    "end": "1260880"
  },
  {
    "text": "discuss at all is the initialization",
    "start": "1260880",
    "end": "1263200"
  },
  {
    "text": "overhead",
    "start": "1263200",
    "end": "1264159"
  },
  {
    "text": "when we spawn a vgpu but also how fast",
    "start": "1264159",
    "end": "1267679"
  },
  {
    "text": "can",
    "start": "1267679",
    "end": "1268159"
  },
  {
    "text": "a device plug in switch processes which",
    "start": "1268159",
    "end": "1270799"
  },
  {
    "text": "are using",
    "start": "1270799",
    "end": "1271679"
  },
  {
    "text": "the gpu and of course last but not least",
    "start": "1271679",
    "end": "1274640"
  },
  {
    "text": "we need those",
    "start": "1274640",
    "end": "1275440"
  },
  {
    "text": "limits to actually use native kubernetes",
    "start": "1275440",
    "end": "1278000"
  },
  {
    "text": "scheduling",
    "start": "1278000",
    "end": "1278720"
  },
  {
    "text": "which where people can just specify in",
    "start": "1278720",
    "end": "1280960"
  },
  {
    "text": "their pot",
    "start": "1280960",
    "end": "1282559"
  },
  {
    "text": "um yeah which limits we want to have on",
    "start": "1282559",
    "end": "1285600"
  },
  {
    "text": "the",
    "start": "1285600",
    "end": "1286159"
  },
  {
    "text": "machinery model and i have to tell you",
    "start": "1286159",
    "end": "1288320"
  },
  {
    "text": "that our community is actually amazing",
    "start": "1288320",
    "end": "1290320"
  },
  {
    "text": "since our initial proposal on the issue",
    "start": "1290320",
    "end": "1292480"
  },
  {
    "text": "there have been",
    "start": "1292480",
    "end": "1293360"
  },
  {
    "text": "four projects trying to solve this issue",
    "start": "1293360",
    "end": "1295919"
  },
  {
    "text": "where even one very promising was",
    "start": "1295919",
    "end": "1298320"
  },
  {
    "text": "released",
    "start": "1298320",
    "end": "1298880"
  },
  {
    "text": "after the original date of the session",
    "start": "1298880",
    "end": "1301039"
  },
  {
    "text": "so let's check them out",
    "start": "1301039",
    "end": "1303360"
  },
  {
    "text": "the first project is diplomatic it uses",
    "start": "1303360",
    "end": "1305679"
  },
  {
    "text": "the same approach like we do",
    "start": "1305679",
    "end": "1307600"
  },
  {
    "text": "and let's see the user specify the",
    "start": "1307600",
    "end": "1309600"
  },
  {
    "text": "number of vgpus to be proposed to the",
    "start": "1309600",
    "end": "1311760"
  },
  {
    "text": "user",
    "start": "1311760",
    "end": "1312400"
  },
  {
    "text": "using tensorflow serving and cpu limits",
    "start": "1312400",
    "end": "1314559"
  },
  {
    "text": "one could realize the very same setup",
    "start": "1314559",
    "end": "1316720"
  },
  {
    "text": "like we did in this session the second",
    "start": "1316720",
    "end": "1318720"
  },
  {
    "text": "project is from tankand",
    "start": "1318720",
    "end": "1320080"
  },
  {
    "text": "and called gpu manager it internally",
    "start": "1320080",
    "end": "1322400"
  },
  {
    "text": "uses another project developed by tenkan",
    "start": "1322400",
    "end": "1324720"
  },
  {
    "text": "called the cuda controller which is a",
    "start": "1324720",
    "end": "1326640"
  },
  {
    "text": "wrapper around the nvidia device library",
    "start": "1326640",
    "end": "1328640"
  },
  {
    "text": "hooking up on cuda calls to enforce",
    "start": "1328640",
    "end": "1330720"
  },
  {
    "text": "isolation to the right you can see that",
    "start": "1330720",
    "end": "1332720"
  },
  {
    "text": "you are then able to specify limits",
    "start": "1332720",
    "end": "1334880"
  },
  {
    "text": "um akin to the gpu moreover it requires",
    "start": "1334880",
    "end": "1337520"
  },
  {
    "text": "at the custom scheduler",
    "start": "1337520",
    "end": "1339039"
  },
  {
    "text": "extender to extend the default",
    "start": "1339039",
    "end": "1340640"
  },
  {
    "text": "kubernetes scheduler for gpu admission",
    "start": "1340640",
    "end": "1344159"
  },
  {
    "text": "last year the newly released work",
    "start": "1344159",
    "end": "1345919"
  },
  {
    "text": "cubeshare which also enforces hardware",
    "start": "1345919",
    "end": "1348159"
  },
  {
    "text": "isolation",
    "start": "1348159",
    "end": "1349039"
  },
  {
    "text": "by intercepting cuda calls at gpu and",
    "start": "1349039",
    "end": "1351600"
  },
  {
    "text": "implementing an",
    "start": "1351600",
    "end": "1352559"
  },
  {
    "text": "own scheduling mechanism while gpu",
    "start": "1352559",
    "end": "1354640"
  },
  {
    "text": "manager requires",
    "start": "1354640",
    "end": "1355679"
  },
  {
    "text": "the extension of kubernetes scheduler we",
    "start": "1355679",
    "end": "1358240"
  },
  {
    "text": "see from",
    "start": "1358240",
    "end": "1359039"
  },
  {
    "text": "tenkan cubeshare co-access as controller",
    "start": "1359039",
    "end": "1362320"
  },
  {
    "text": "and",
    "start": "1362320",
    "end": "1362960"
  },
  {
    "text": "solves a lot of information problems",
    "start": "1362960",
    "end": "1364799"
  },
  {
    "text": "with custom resources",
    "start": "1364799",
    "end": "1366720"
  },
  {
    "text": "we have also written a paper about their",
    "start": "1366720",
    "end": "1368720"
  },
  {
    "text": "approach showing",
    "start": "1368720",
    "end": "1370240"
  },
  {
    "text": "their approach and their results i would",
    "start": "1370240",
    "end": "1372000"
  },
  {
    "text": "recommend you to check it out it gives a",
    "start": "1372000",
    "end": "1374320"
  },
  {
    "text": "very comprehensive insight into the",
    "start": "1374320",
    "end": "1376159"
  },
  {
    "text": "world of containers",
    "start": "1376159",
    "end": "1377600"
  },
  {
    "text": "second scheduling gpus and gpu sharing",
    "start": "1377600",
    "end": "1380159"
  },
  {
    "text": "if you are planning to contribute or",
    "start": "1380159",
    "end": "1382000"
  },
  {
    "text": "implement at your company gpu sharing",
    "start": "1382000",
    "end": "1384240"
  },
  {
    "text": "you should definitely check out those",
    "start": "1384240",
    "end": "1386240"
  },
  {
    "text": "projects and contribute to them at this",
    "start": "1386240",
    "end": "1388480"
  },
  {
    "text": "point i want to give a big thanks to all",
    "start": "1388480",
    "end": "1390480"
  },
  {
    "text": "of these people",
    "start": "1390480",
    "end": "1391440"
  },
  {
    "text": "contributing to the ecosystem we already",
    "start": "1391440",
    "end": "1393440"
  },
  {
    "text": "have and with that we are actually",
    "start": "1393440",
    "end": "1395280"
  },
  {
    "text": "coming",
    "start": "1395280",
    "end": "1396080"
  },
  {
    "text": "to the end of this session um thanks for",
    "start": "1396080",
    "end": "1399520"
  },
  {
    "text": "having me here",
    "start": "1399520",
    "end": "1400320"
  },
  {
    "text": "feel free to contact me on github",
    "start": "1400320",
    "end": "1402320"
  },
  {
    "text": "linkedin or twitter on the slash summit",
    "start": "1402320",
    "end": "1404240"
  },
  {
    "text": "guana",
    "start": "1404240",
    "end": "1405679"
  },
  {
    "text": "i'm happy to answer your question",
    "start": "1405679",
    "end": "1409279"
  },
  {
    "text": "hi all um so thanks for joining the",
    "start": "1412480",
    "end": "1415200"
  },
  {
    "text": "session i'm now going to answer a few",
    "start": "1415200",
    "end": "1417360"
  },
  {
    "text": "questions",
    "start": "1417360",
    "end": "1418159"
  },
  {
    "text": "i got here so first question is from",
    "start": "1418159",
    "end": "1421120"
  },
  {
    "text": "josh",
    "start": "1421120",
    "end": "1421840"
  },
  {
    "text": "um he's asking based on the fact that",
    "start": "1421840",
    "end": "1424159"
  },
  {
    "text": "nvidia can't see a way to get c",
    "start": "1424159",
    "end": "1426400"
  },
  {
    "text": "group equivalence gpus into white build",
    "start": "1426400",
    "end": "1429039"
  },
  {
    "text": "this remaining",
    "start": "1429039",
    "end": "1429760"
  },
  {
    "text": "unsolved keep this very niche and",
    "start": "1429760",
    "end": "1432159"
  },
  {
    "text": "outside of",
    "start": "1432159",
    "end": "1432880"
  },
  {
    "text": "upstream so um this has something to do",
    "start": "1432880",
    "end": "1436640"
  },
  {
    "text": "with",
    "start": "1436640",
    "end": "1437120"
  },
  {
    "text": "device or with the nvidia device we",
    "start": "1437120",
    "end": "1439600"
  },
  {
    "text": "actually use",
    "start": "1439600",
    "end": "1440400"
  },
  {
    "text": "so for example nvidia has announced the",
    "start": "1440400",
    "end": "1443520"
  },
  {
    "text": "t4",
    "start": "1443520",
    "end": "1444080"
  },
  {
    "text": "devices which are allowing up to seven",
    "start": "1444080",
    "end": "1446559"
  },
  {
    "text": "gpus",
    "start": "1446559",
    "end": "1447600"
  },
  {
    "text": "um or seven workloads on one uh one gpu",
    "start": "1447600",
    "end": "1451120"
  },
  {
    "text": "so we have in our experience we have",
    "start": "1451120",
    "end": "1453360"
  },
  {
    "text": "used ak 80s to do this and the k8 is at",
    "start": "1453360",
    "end": "1456000"
  },
  {
    "text": "the current state",
    "start": "1456000",
    "end": "1457520"
  },
  {
    "text": "and does not support and i am not",
    "start": "1457520",
    "end": "1459840"
  },
  {
    "text": "believing that",
    "start": "1459840",
    "end": "1460799"
  },
  {
    "text": "k 80s and also v100s are going to",
    "start": "1460799",
    "end": "1463039"
  },
  {
    "text": "support",
    "start": "1463039",
    "end": "1464400"
  },
  {
    "text": "gpu soon or at any time therefore",
    "start": "1464400",
    "end": "1467600"
  },
  {
    "text": "we have also these great um works i've",
    "start": "1467600",
    "end": "1470159"
  },
  {
    "text": "just shown you",
    "start": "1470159",
    "end": "1471360"
  },
  {
    "text": "um for example from cubeshare which are",
    "start": "1471360",
    "end": "1474480"
  },
  {
    "text": "trying to solve just by",
    "start": "1474480",
    "end": "1476000"
  },
  {
    "text": "implementing your own yeah scheduling",
    "start": "1476000",
    "end": "1478240"
  },
  {
    "text": "mechanism on a lower level",
    "start": "1478240",
    "end": "1481039"
  },
  {
    "text": "um let's go i hope this answers with",
    "start": "1481039",
    "end": "1483279"
  },
  {
    "text": "question let's go on on the next",
    "start": "1483279",
    "end": "1485039"
  },
  {
    "text": "question",
    "start": "1485039",
    "end": "1485679"
  },
  {
    "text": "from claymore is it usable on gke",
    "start": "1485679",
    "end": "1489120"
  },
  {
    "text": "there's already a cubelet device plugged",
    "start": "1489120",
    "end": "1491200"
  },
  {
    "text": "on them does it bypass it",
    "start": "1491200",
    "end": "1493360"
  },
  {
    "text": "so um the device plugin is just a daemon",
    "start": "1493360",
    "end": "1496960"
  },
  {
    "text": "set you install on the",
    "start": "1496960",
    "end": "1498640"
  },
  {
    "text": "notes you which are actually having",
    "start": "1498640",
    "end": "1500559"
  },
  {
    "text": "nvidia gpus",
    "start": "1500559",
    "end": "1502159"
  },
  {
    "text": "and as far as i know you can also",
    "start": "1502159",
    "end": "1505279"
  },
  {
    "text": "uninstall existing device plugin this",
    "start": "1505279",
    "end": "1507279"
  },
  {
    "text": "shouldn't be a problem so",
    "start": "1507279",
    "end": "1508720"
  },
  {
    "text": "yes you could use any of the open source",
    "start": "1508720",
    "end": "1511200"
  },
  {
    "text": "projects to install on the gte cluster",
    "start": "1511200",
    "end": "1513440"
  },
  {
    "text": "with gpu sharing",
    "start": "1513440",
    "end": "1516480"
  },
  {
    "text": "another question is by jab",
    "start": "1516559",
    "end": "1519919"
  },
  {
    "text": "i always thought that context switching",
    "start": "1519919",
    "end": "1521919"
  },
  {
    "text": "between processes slowed down gpu",
    "start": "1521919",
    "end": "1524080"
  },
  {
    "text": "processes",
    "start": "1524080",
    "end": "1524960"
  },
  {
    "text": "from your experiment it seems like",
    "start": "1524960",
    "end": "1527200"
  },
  {
    "text": "you've disproven this",
    "start": "1527200",
    "end": "1528720"
  },
  {
    "text": "does this have anything to do with the",
    "start": "1528720",
    "end": "1530480"
  },
  {
    "text": "software you're using for serving",
    "start": "1530480",
    "end": "1532559"
  },
  {
    "text": "or is contact switching not not big of a",
    "start": "1532559",
    "end": "1535600"
  },
  {
    "text": "problem anymore",
    "start": "1535600",
    "end": "1536480"
  },
  {
    "text": "i have to be honest here um so because",
    "start": "1536480",
    "end": "1539279"
  },
  {
    "text": "we are trying to solve the problem on a",
    "start": "1539279",
    "end": "1542080"
  },
  {
    "text": "very high level on the device plug in",
    "start": "1542080",
    "end": "1543840"
  },
  {
    "text": "level we do not really know what happens",
    "start": "1543840",
    "end": "1546159"
  },
  {
    "text": "um on the gpu level um",
    "start": "1546159",
    "end": "1549279"
  },
  {
    "text": "i strongly assume that there is some",
    "start": "1549279",
    "end": "1551679"
  },
  {
    "text": "kind of thrashing",
    "start": "1551679",
    "end": "1553360"
  },
  {
    "text": "behavior that process are stopped and",
    "start": "1553360",
    "end": "1555679"
  },
  {
    "text": "then um",
    "start": "1555679",
    "end": "1556640"
  },
  {
    "text": "new processes take over offer available",
    "start": "1556640",
    "end": "1559919"
  },
  {
    "text": "capacity",
    "start": "1559919",
    "end": "1560960"
  },
  {
    "text": "of the gpu but to be honest here i do",
    "start": "1560960",
    "end": "1563760"
  },
  {
    "text": "not really know but it's really amazing",
    "start": "1563760",
    "end": "1565679"
  },
  {
    "text": "to see that",
    "start": "1565679",
    "end": "1566640"
  },
  {
    "text": "context switching is actually not a big",
    "start": "1566640",
    "end": "1568880"
  },
  {
    "text": "deal",
    "start": "1568880",
    "end": "1570720"
  },
  {
    "text": "yes so i hope that answers your question",
    "start": "1570720",
    "end": "1574080"
  },
  {
    "text": "um there's another question um",
    "start": "1574080",
    "end": "1578080"
  },
  {
    "text": "what are your thoughts about on gpu",
    "start": "1578080",
    "end": "1580320"
  },
  {
    "text": "sharing for short-lived ml jobs",
    "start": "1580320",
    "end": "1582720"
  },
  {
    "text": "would you think it's better to get it",
    "start": "1582720",
    "end": "1584480"
  },
  {
    "text": "done faster",
    "start": "1584480",
    "end": "1585840"
  },
  {
    "text": "or have a higher bandwidth",
    "start": "1585840",
    "end": "1588880"
  },
  {
    "text": "um so i think by short of ml jobs you",
    "start": "1588880",
    "end": "1592000"
  },
  {
    "text": "mean",
    "start": "1592000",
    "end": "1592640"
  },
  {
    "text": "multiple or in parallel running machine",
    "start": "1592640",
    "end": "1595440"
  },
  {
    "text": "learning experiments",
    "start": "1595440",
    "end": "1596799"
  },
  {
    "text": "for example for training i would suggest",
    "start": "1596799",
    "end": "1599840"
  },
  {
    "text": "that",
    "start": "1599840",
    "end": "1601840"
  },
  {
    "text": "get it done faster and would be better",
    "start": "1601840",
    "end": "1604640"
  },
  {
    "text": "thing than",
    "start": "1604640",
    "end": "1605279"
  },
  {
    "text": "deploying multiple machine learning",
    "start": "1605279",
    "end": "1607120"
  },
  {
    "text": "training jobs onto the same",
    "start": "1607120",
    "end": "1609120"
  },
  {
    "text": "gpu of course this changes from use case",
    "start": "1609120",
    "end": "1611919"
  },
  {
    "text": "to use case",
    "start": "1611919",
    "end": "1613440"
  },
  {
    "text": "but in general my advice would be to",
    "start": "1613440",
    "end": "1616799"
  },
  {
    "text": "get it done fast you can also",
    "start": "1616799",
    "end": "1620240"
  },
  {
    "text": "if you see that model doesn't converge",
    "start": "1620240",
    "end": "1622159"
  },
  {
    "text": "in a given time period you can also",
    "start": "1622159",
    "end": "1623840"
  },
  {
    "text": "cancel and deploy the next job",
    "start": "1623840",
    "end": "1626159"
  },
  {
    "text": "and i cannot see any other questions",
    "start": "1626159",
    "end": "1629840"
  },
  {
    "text": "here",
    "start": "1629840",
    "end": "1630400"
  },
  {
    "text": "um although the question i have put an",
    "start": "1630400",
    "end": "1632640"
  },
  {
    "text": "answer on it",
    "start": "1632640",
    "end": "1633760"
  },
  {
    "text": "um so i think i can",
    "start": "1633760",
    "end": "1636880"
  },
  {
    "text": "end this session here thanks very much",
    "start": "1636880",
    "end": "1639200"
  },
  {
    "text": "for joining again this session",
    "start": "1639200",
    "end": "1641360"
  },
  {
    "text": "it was great to be here in this virtual",
    "start": "1641360",
    "end": "1644000"
  },
  {
    "text": "event",
    "start": "1644000",
    "end": "1644559"
  },
  {
    "text": "and have a nice virtual event in",
    "start": "1644559",
    "end": "1646240"
  },
  {
    "text": "upcoming days see you bye bye",
    "start": "1646240",
    "end": "1650799"
  }
]
[
  {
    "text": "hi everyone welcome to join today's session I hope you have a great work",
    "start": "1040",
    "end": "6240"
  },
  {
    "text": "week in Detroit uh so today we're going to share",
    "start": "6240",
    "end": "12599"
  },
  {
    "text": "some handsome experience on running Cube schedule including configuration",
    "start": "12599",
    "end": "18680"
  },
  {
    "text": "extension and operation we hope by the end of this talk you will get",
    "start": "18680",
    "end": "24840"
  },
  {
    "text": "some uh practical ideas and actionable",
    "start": "24840",
    "end": "30119"
  },
  {
    "text": "practice is to run your schedule more efficiently in your production",
    "start": "30119",
    "end": "35239"
  },
  {
    "text": "environment and firstly let's introduce ourselves hi I'm Yan CH from Apple cloud",
    "start": "35239",
    "end": "41600"
  },
  {
    "text": "service so glad to meet you and it's cool to so see so many people show up",
    "start": "41600",
    "end": "46719"
  },
  {
    "text": "hopefully there are many more people online uh I'm Wayan I'm also from Apple",
    "start": "46719",
    "end": "53199"
  },
  {
    "text": "uh I'm also the co-chair of the six scheduling uh I'm EO uh I work in as a",
    "start": "53199",
    "end": "60239"
  },
  {
    "text": "software engineer in apple C Services uh this is actually my first cubec con so I'm pretty",
    "start": "60239",
    "end": "66119"
  },
  {
    "text": "excited hello everyone I'm Chen Wong from IBM research and I actively uh",
    "start": "66119",
    "end": "71759"
  },
  {
    "text": "contribute to uh schedular plugins and Autos scaling on the other side because",
    "start": "71759",
    "end": "77159"
  },
  {
    "text": "I'm in research I also did a lot of research work uh in resource management",
    "start": "77159",
    "end": "82240"
  },
  {
    "text": "for uh kubernetes and I also try to enhance kuber ntic with for all types of",
    "start": "82240",
    "end": "88360"
  },
  {
    "text": "machine learning workload um very looking forward to talking to you in person",
    "start": "88360",
    "end": "94759"
  },
  {
    "text": "cool uh so this is today's agenda firstly we will give a very high level",
    "start": "94759",
    "end": "100399"
  },
  {
    "text": "introduction on the cube scheduling and then we'll Deep dive into each part",
    "start": "100399",
    "end": "106520"
  },
  {
    "text": "configuration operation and extension and in the end we hope we can have five to 10 minutes for answering",
    "start": "106520",
    "end": "113759"
  },
  {
    "text": "questions all right the first part is about what is scheding anyways",
    "start": "113759",
    "end": "120039"
  },
  {
    "text": "so when we talk about scheduling we usually talk about the typical part life",
    "start": "120039",
    "end": "125759"
  },
  {
    "text": "cycle because schedule is just playing a certain part in the whole life cycle so",
    "start": "125759",
    "end": "131840"
  },
  {
    "text": "starts with the part creation you should either by a us directory creating a path",
    "start": "131840",
    "end": "137120"
  },
  {
    "text": "or creating a deployment and the controller manager is responsible for spinning up The Path so after that the",
    "start": "137120",
    "end": "145640"
  },
  {
    "text": "job of the controller manager is done then is turn to the schedule to try to use its knowledge on the whole",
    "start": "145640",
    "end": "153120"
  },
  {
    "text": "cluster to find the best Note for the PA so right now it just treat the schedule",
    "start": "153120",
    "end": "159159"
  },
  {
    "text": "as a black box the input is the pending part and the output is uh the part",
    "start": "159159",
    "end": "165640"
  },
  {
    "text": "associated with Noe and after that it's culate is responsibility then the",
    "start": "165640",
    "end": "173760"
  },
  {
    "text": "corresponding Cate will get notified okay there part coming to mind I know I so I",
    "start": "173760",
    "end": "180920"
  },
  {
    "text": "should be responsible to bring it up to spin up the corresponding containers",
    "start": "180920",
    "end": "186480"
  },
  {
    "text": "then the part gets into running State and after that optionally if it's a run",
    "start": "186480",
    "end": "192440"
  },
  {
    "text": "to completion part then it will run its job finish the job and it's",
    "start": "192440",
    "end": "198959"
  },
  {
    "text": "done then the part gets into a competitive state but can be also that the part is are long running Services",
    "start": "198959",
    "end": "205280"
  },
  {
    "text": "then the power Just Stay running forever so this is basically the whole",
    "start": "205280",
    "end": "210959"
  },
  {
    "text": "part life cycle and the schedule just focus on uh between the part creation",
    "start": "210959",
    "end": "218519"
  },
  {
    "text": "and part running so let's zoom into the red rectangle box to look into a little",
    "start": "218519",
    "end": "224680"
  },
  {
    "text": "bit into the internal of the scheduler the first thing to look at Schuler is",
    "start": "224680",
    "end": "229959"
  },
  {
    "text": "what's the input and output so the input one type input is definitely",
    "start": "229959",
    "end": "235879"
  },
  {
    "text": "the panding pass that the schedu should be diligent work count to find it the",
    "start": "235879",
    "end": "241439"
  },
  {
    "text": "best notified and the other thing to make the part placement decision it",
    "start": "241439",
    "end": "247480"
  },
  {
    "text": "should be aware of the upated Custer status including not only",
    "start": "247480",
    "end": "253480"
  },
  {
    "text": "to the running PA the NOS information uh storage information pvpc",
    "start": "253480",
    "end": "261799"
  },
  {
    "text": "Etc so in this case internally scheduling will uh cat all the",
    "start": "261799",
    "end": "268240"
  },
  {
    "text": "information and so that you can make the right decision for placing the PA this",
    "start": "268240",
    "end": "273840"
  },
  {
    "text": "is the first first part and second part is the we call internal cues so the path",
    "start": "273840",
    "end": "280080"
  },
  {
    "text": "comes in we should find the a proper mechanisms to solve them prop play and",
    "start": "280080",
    "end": "286720"
  },
  {
    "text": "also have some uh back off mechanisms so that it's uh pretty fair to schedule both the",
    "start": "286720",
    "end": "295880"
  },
  {
    "text": "high priority paths and those or low priority paths that's a second part for Q and then the third part is called core",
    "start": "295880",
    "end": "302320"
  },
  {
    "text": "scheduling then a typical workflow is that a part popped up from the internal",
    "start": "302320",
    "end": "308479"
  },
  {
    "text": "queue then the cor scheding works on it goes through a series of the uh actions",
    "start": "308479",
    "end": "317400"
  },
  {
    "text": "then the output comes into two ways one is okay we can't find the node to host",
    "start": "317400",
    "end": "324479"
  },
  {
    "text": "the PA so we go to The Binding cycle binding cycle is nothing but",
    "start": "324479",
    "end": "330319"
  },
  {
    "text": "uh associate with associate a no name with the path so that is one up and the",
    "start": "330319",
    "end": "335759"
  },
  {
    "text": "other part part is that okay sorry I cannot find a node to host that the PA",
    "start": "335759",
    "end": "342039"
  },
  {
    "text": "then the PA goes back to the internal queue and uh went through some pretty",
    "start": "342039",
    "end": "347680"
  },
  {
    "text": "fun back off timers then it has another chance to be retried later so this is basically also pretty high level of the",
    "start": "347680",
    "end": "355000"
  },
  {
    "text": "internal of the schedule then if you zoom in the",
    "start": "355000",
    "end": "360319"
  },
  {
    "text": "uh course scheduling a little bit uh we came up with extensible framework that",
    "start": "360319",
    "end": "368919"
  },
  {
    "text": "we Define a series of the extensible extension point and at each phase you",
    "start": "368919",
    "end": "377560"
  },
  {
    "text": "can associate with the corresponding logic to overcome a particular scheduling constraint but back here I",
    "start": "377560",
    "end": "385599"
  },
  {
    "text": "won't go to into two details because later I will slid some detailing each EXT point but here you just uh I want",
    "start": "385599",
    "end": "393360"
  },
  {
    "text": "you to understand that there are two typical or three typical phase in the",
    "start": "393360",
    "end": "400240"
  },
  {
    "text": "regular scheduling cycle one is called filter so the filter output is that it",
    "start": "400240",
    "end": "406759"
  },
  {
    "text": "will give you yes or no answer if",
    "start": "406759",
    "end": "412400"
  },
  {
    "text": "there we can find a Noe or multiple nodes to host the part not it's a ban uh",
    "start": "412400",
    "end": "420120"
  },
  {
    "text": "result and after futter if we can find at least one note we will go to the",
    "start": "420120",
    "end": "425720"
  },
  {
    "text": "score phase then the score is to rank the feasible NOS then by giving some",
    "start": "425720",
    "end": "432319"
  },
  {
    "text": "predefined algorithm and policies then come up with a final node we suggested",
    "start": "432319",
    "end": "438720"
  },
  {
    "text": "the part to be wrong on so this is the happy pass we can't find noes but that can be a negative pass right we cannot",
    "start": "438720",
    "end": "445360"
  },
  {
    "text": "find noes then in that case it goes to the post filter",
    "start": "445360",
    "end": "450400"
  },
  {
    "text": "uh in the red rectangle go to the Post filter pH post filter a typical",
    "start": "450400",
    "end": "456160"
  },
  {
    "text": "implantation is called preemption so preemption effort is that okay I may",
    "start": "456160",
    "end": "462720"
  },
  {
    "text": "want to sacrifice some low priority passs to make room for the hyper pass to",
    "start": "462720",
    "end": "468919"
  },
  {
    "text": "run so yeah that is basically the most critical three phase by now I want you",
    "start": "468919",
    "end": "475400"
  },
  {
    "text": "to to get to know but later I will just go a little deep into that and uh",
    "start": "475400",
    "end": "482199"
  },
  {
    "text": "another thing I want to mention is that uh scheduling is not only just a fix the",
    "start": "482199",
    "end": "488800"
  },
  {
    "text": "block it can be very Dynamic so in two ways one is you can craft different",
    "start": "488800",
    "end": "498520"
  },
  {
    "text": "scheduling flavors by a term called profiles so each file is like can be",
    "start": "498520",
    "end": "504919"
  },
  {
    "text": "associated with a particular uh scheding pattern or flavor like you want the part",
    "start": "504919",
    "end": "511400"
  },
  {
    "text": "to be more pimpa or be more uh spread and each profile is consisted with a lot",
    "start": "511400",
    "end": "519839"
  },
  {
    "text": "of plugins the plugins is like the minimal unit that resolve a particular",
    "start": "519839",
    "end": "526399"
  },
  {
    "text": "scheding domain problem and then you can just build the profile using the plugins",
    "start": "526399",
    "end": "533240"
  },
  {
    "text": "like using Lego blocks and uh EO will go pretty deep into profile plugins in the",
    "start": "533240",
    "end": "541160"
  },
  {
    "text": "next sections about the schedu configuration we hand over to youo thanks",
    "start": "541160",
    "end": "547200"
  },
  {
    "text": "way so uh I will be going",
    "start": "547200",
    "end": "552000"
  },
  {
    "text": "over okay thank you so uh I will be going over the schuer configuration",
    "start": "556680",
    "end": "561800"
  },
  {
    "text": "itself um so you can think of the kubernetes schedu or configuration um is",
    "start": "561800",
    "end": "567560"
  },
  {
    "text": "you can do that in the declarative format similar to like a podspec for example so you can see here um that we",
    "start": "567560",
    "end": "573440"
  },
  {
    "text": "have like a sample Cube schedu or configuration um there it's kind of",
    "start": "573440",
    "end": "578480"
  },
  {
    "text": "mostly consists of the global configurations uh the global parameters so these are things like for example the",
    "start": "578480",
    "end": "584279"
  },
  {
    "text": "cube config to use to be used to connect to the API server or things like their uh leader election configuration um and",
    "start": "584279",
    "end": "590720"
  },
  {
    "text": "things like you know the PO initial backup seconds and Max back of seconds which I'll go over in a bit um we also",
    "start": "590720",
    "end": "596519"
  },
  {
    "text": "have a list of profiles that you can configure as way mentioned earlier um that basically can Define the exactly",
    "start": "596519",
    "end": "604160"
  },
  {
    "text": "exact behavior of this particular schedule instance um so and also at the",
    "start": "604160",
    "end": "609320"
  },
  {
    "text": "profile level you can have a per plugin configuration uh which you can control for example which set of plugins to",
    "start": "609320",
    "end": "615120"
  },
  {
    "text": "enable and disable um as well as things like um uh like the parameters that you",
    "start": "615120",
    "end": "621200"
  },
  {
    "text": "pass into the specific plugin itself um so one thing to note here is that the API version that's currently supported",
    "start": "621200",
    "end": "627120"
  },
  {
    "text": "is V1 beta 2 V1 beta 3 and V1 one and B1 beta 2 is in the process of being",
    "start": "627120",
    "end": "632600"
  },
  {
    "text": "deprecated so um at the global kind of parameters level um we've got a couple",
    "start": "632600",
    "end": "638079"
  },
  {
    "text": "things to know that you can kind of tune and um and and see how how it performs so percentage of note to score is",
    "start": "638079",
    "end": "644600"
  },
  {
    "text": "basically a percentage of all the nodes uh used for the initial search of like feasible nodes so by default um it is",
    "start": "644600",
    "end": "651680"
  },
  {
    "text": "doing an Adaptive uh percentage between 5 and 50% and this is to kind of make sure that the Schuler is performing",
    "start": "651680",
    "end": "658120"
  },
  {
    "text": "enough especially for large CL clusters where you may not not necessarily need to consider all possible notes at all",
    "start": "658120",
    "end": "663360"
  },
  {
    "text": "time um but if you do need to kind of cons want to do that you can tune this percentage yourself um so one of the",
    "start": "663360",
    "end": "669920"
  },
  {
    "text": "thing that my colleague Yan has recently actually submitted a PO request on got merge Upstream which is to be able to",
    "start": "669920",
    "end": "675399"
  },
  {
    "text": "configure this at a per profile level and not just at as a global parameter um",
    "start": "675399",
    "end": "680839"
  },
  {
    "text": "the next section here is on leader election so you can control this to B basically have your schedule run in",
    "start": "680839",
    "end": "686040"
  },
  {
    "text": "leader action mode um this is to encourage for high availability um and the locks here that you can support are",
    "start": "686040",
    "end": "692920"
  },
  {
    "text": "um uh leases end points as well as config Maps um for the initial backup",
    "start": "692920",
    "end": "698399"
  },
  {
    "text": "seconds and Max backup seconds so these are essentially um for unscheduled pod",
    "start": "698399",
    "end": "703519"
  },
  {
    "text": "uh unschedulable pod case where the Pod may go through a sequence of exponential back offs so just is to avoid things",
    "start": "703519",
    "end": "710120"
  },
  {
    "text": "like head of line blocking where you don't want to con constantly trying to reschedule over and over like this",
    "start": "710120",
    "end": "715760"
  },
  {
    "text": "unschedulable parts so at a high level um this is like",
    "start": "715760",
    "end": "721000"
  },
  {
    "text": "a very simplified view of the scheduler internal cues um so there are three main cues that make up the the scheduler so",
    "start": "721000",
    "end": "727720"
  },
  {
    "text": "there is the active cues where all the pods will be uh placed in this queue are kind of ready to be scheduled so you can",
    "start": "727720",
    "end": "734880"
  },
  {
    "text": "think of uh you know at the every single schedu or interval called the schedule one is going to pop off that pod from",
    "start": "734880",
    "end": "741000"
  },
  {
    "text": "the active que and tries to find a feasible node for that and if I'm unable to find a feasible node then I will be",
    "start": "741000",
    "end": "746959"
  },
  {
    "text": "placing that part into the unschedulable queue and there will be a bunch of events and triggers that'll basically",
    "start": "746959",
    "end": "752360"
  },
  {
    "text": "flush those unschedulable queue into either the backup queue or the active queue to be consider for rescheduling so",
    "start": "752360",
    "end": "758720"
  },
  {
    "text": "in the case of the back off queue um essentially this is where it's going through the exponential back off",
    "start": "758720",
    "end": "764199"
  },
  {
    "text": "starting from the initial backup seconds all the way until maximum backup seconds so for example you may want to uh set",
    "start": "764199",
    "end": "771199"
  },
  {
    "text": "your max backup seconds to be quite high for like a very large cluster where you want to kind of uh con not to like for",
    "start": "771199",
    "end": "779279"
  },
  {
    "text": "posor like maybe un schedulable for a long time you may want to have that go through a high like a longer back of",
    "start": "779279",
    "end": "785639"
  },
  {
    "text": "time so that it doesn't kind of do with headline blocking um so now moving on to like the",
    "start": "785639",
    "end": "793519"
  },
  {
    "text": "specific profile configuration um so the profile configuration itself allows for like a",
    "start": "793519",
    "end": "799720"
  },
  {
    "text": "granular control of the extension points so those extension points are like Q or preil I'm not going to go over all of",
    "start": "799720",
    "end": "805600"
  },
  {
    "text": "these um there's going to be a specific section going over each every single one of the extension Point um but basically",
    "start": "805600",
    "end": "812399"
  },
  {
    "text": "you can kind of see from an example here that um I've got a my awesome sort Uh",
    "start": "812399",
    "end": "818440"
  },
  {
    "text": "custom plugin that I want to enable for the Q sort extension point with some parameters like percentage of node",
    "start": "818440",
    "end": "825079"
  },
  {
    "text": "reserved or something like a learning strategy for example if this uh plugin is doing some kind of learning uh",
    "start": "825079",
    "end": "831279"
  },
  {
    "text": "placement algorithm um but you can control these parameters for that specific plugin in the plug-in config",
    "start": "831279",
    "end": "837639"
  },
  {
    "text": "section um and you can also see that I've uh not only enabled my custom plugin a uh I've also enabled this uh",
    "start": "837639",
    "end": "844480"
  },
  {
    "text": "for my custom plugin B with a different weight so the weight here really allows for favoring uh plugin score during uh",
    "start": "844480",
    "end": "851959"
  },
  {
    "text": "the What's called the normalization so how that works is at the scoring layer um is going to go through every single",
    "start": "851959",
    "end": "858240"
  },
  {
    "text": "plugin and finding a per plugin uh score for uh every single particular node and",
    "start": "858240",
    "end": "864480"
  },
  {
    "text": "then it's going to kind of create a normalized uh final score that's basically factoring the weight so it's",
    "start": "864480",
    "end": "870360"
  },
  {
    "text": "going to take that score multiply by the weight and divide by the weight sum of all the enabled plugins uh and find the",
    "start": "870360",
    "end": "876680"
  },
  {
    "text": "final score for that particular node and basically the node that's scoring the that has ended up with the highest score",
    "start": "876680",
    "end": "883240"
  },
  {
    "text": "will be chosen as a node for placement of the Pod um so starting from V1 beta 3 of the",
    "start": "883240",
    "end": "891000"
  },
  {
    "text": "schedu configuration um we have uh there's an added support called a multipoint um inside the plug-in",
    "start": "891000",
    "end": "897680"
  },
  {
    "text": "configuration which uh simplifies the enablement and disablement across several extension points so prior to",
    "start": "897680",
    "end": "904279"
  },
  {
    "text": "this if um you know I have a plugin that extends a series of different extension points then I would have to go through",
    "start": "904279",
    "end": "911519"
  },
  {
    "text": "and turn this on for every single extension point which can be kind of combersome for example if I just want to",
    "start": "911519",
    "end": "917000"
  },
  {
    "text": "enable this across like a bunch of extension points so let's run through an example here where I've got my default Q",
    "start": "917000",
    "end": "924120"
  },
  {
    "text": "sword which is the default one that ships with the scheduler but I want to kind of disable it and I want to use my",
    "start": "924120",
    "end": "929680"
  },
  {
    "text": "custom C sort uh extension um I've also got two default plugins that's shipped",
    "start": "929680",
    "end": "934920"
  },
  {
    "text": "but I kind of want to for example disable the plugin uh one for filter",
    "start": "934920",
    "end": "939959"
  },
  {
    "text": "stage and maybe uh enable my plugin for only the scoring stage of uh uh the the",
    "start": "939959",
    "end": "945800"
  },
  {
    "text": "plug-in too but I also for example I have two custom plugins with one being",
    "start": "945800",
    "end": "951240"
  },
  {
    "text": "um both of the plug-in being uh extending you know all the filter and scoring stages so if I were to do this",
    "start": "951240",
    "end": "957839"
  },
  {
    "text": "in the prior multi Point uh uh approach then I would have to go in and say you",
    "start": "957839",
    "end": "963440"
  },
  {
    "text": "know pre filter enable plugin one plugin two filter enable plug-in one plugin two which is pretty tedious and there's a",
    "start": "963440",
    "end": "970519"
  },
  {
    "text": "lot of lines that you have to of yo that you have to write but in this particular case I can just simply say multipoint uh",
    "start": "970519",
    "end": "976800"
  },
  {
    "text": "enable my custom plug-in one with a scoring weight of three and and and it will be able to enable that for all the",
    "start": "976800",
    "end": "983199"
  },
  {
    "text": "extension points so this would be you know pre filter filter prescore and score",
    "start": "983199",
    "end": "989560"
  },
  {
    "text": "um so we've briefly touched upon like multi-profile but I want to kind of dive a little bit deeper here so um basically",
    "start": "990440",
    "end": "997880"
  },
  {
    "text": "a single instance of cube scheduler here can run multiple profiles and under each",
    "start": "997880",
    "end": "1003000"
  },
  {
    "text": "profile um you would Define a name for that particular scheduler as well as um",
    "start": "1003000",
    "end": "1008279"
  },
  {
    "text": "a set of plug-in specific configurations so this is things like the multipoint for enable one or more plugins or uh",
    "start": "1008279",
    "end": "1015839"
  },
  {
    "text": "specific plug-in arguments um so when you have done that um then for your pod",
    "start": "1015839",
    "end": "1022160"
  },
  {
    "text": "to be able to Target a specific profile um you would set that in the spec scheduler name of the pods back and",
    "start": "1022160",
    "end": "1031438"
  },
  {
    "text": "basically if you don't do any customization for the cube scheduler out of the box you will get a single uh",
    "start": "1031439",
    "end": "1037038"
  },
  {
    "text": "scheduler profile with the name being default scheduler and the Pod will uh by default set the spe scheduler name to be",
    "start": "1037039",
    "end": "1043918"
  },
  {
    "text": "default scheduler but in this particular example um I've got like two profiles with one default scheduler and one",
    "start": "1043919",
    "end": "1050559"
  },
  {
    "text": "second scheduler with some customizations and for example if I want to Target my pod for the second",
    "start": "1050559",
    "end": "1056640"
  },
  {
    "text": "scheduler I would set this in the spec scheduler name um one thing to note here is that",
    "start": "1056640",
    "end": "1062679"
  },
  {
    "text": "all the profiles here um must use the same plug-in uh for Q sour this is because the schedule itself has only one",
    "start": "1062679",
    "end": "1069320"
  },
  {
    "text": "pending po Q so um you must ensure that when you're specify multiple profiles",
    "start": "1069320",
    "end": "1074720"
  },
  {
    "text": "that the Q sort layer um whether you enable a custom sorting algorithm or",
    "start": "1074720",
    "end": "1080080"
  },
  {
    "text": "something um that they have to be the same across all the",
    "start": "1080080",
    "end": "1084679"
  },
  {
    "text": "profiles so uh the the the cube scheduler itself uh comes is already",
    "start": "1085360",
    "end": "1090440"
  },
  {
    "text": "like Bas driven based on plugins so there's a list of default plugins that ships with the cube scheduler um I don't",
    "start": "1090440",
    "end": "1096840"
  },
  {
    "text": "have the entire list here um but there are some notable ones here that really kind of is something that's important to",
    "start": "1096840",
    "end": "1102600"
  },
  {
    "text": "tune as well something important to to to kind of make note of um one of them",
    "start": "1102600",
    "end": "1107679"
  },
  {
    "text": "being the node resources fit plugin um with a default weight of one and the default uh scoring strategy being least",
    "start": "1107679",
    "end": "1114360"
  },
  {
    "text": "allocated with a CPU weight and a memory weight of one each so I will be going over uh in a in the next slide um uh in",
    "start": "1114360",
    "end": "1121679"
  },
  {
    "text": "depth about the know resources fit itself um there is also the interpod Affinity plugin as well as the node",
    "start": "1121679",
    "end": "1127679"
  },
  {
    "text": "resource balance allocation plugin which is used for ensuring like nodes uh generally you prefer to score notes with",
    "start": "1127679",
    "end": "1135240"
  },
  {
    "text": "and up with a placement of a balanced CPU and memory allocation",
    "start": "1135240",
    "end": "1140720"
  },
  {
    "text": "so let's talk a little bit about B packing itself um so the default node",
    "start": "1141600",
    "end": "1146799"
  },
  {
    "text": "resources fit um plug-in uses the least allocated strategy so what this will do",
    "start": "1146799",
    "end": "1152600"
  },
  {
    "text": "is if you have end nodes and you're trying to place pods into them what it will do is it will always pick the Noe",
    "start": "1152600",
    "end": "1158159"
  },
  {
    "text": "with the lead the resources being used so it's attempting to be a more spread strategy where you kind of think of that",
    "start": "1158159",
    "end": "1164520"
  },
  {
    "text": "as like horizontally placing pod until everything fills up um but one thing that you can do let's say if you prefer",
    "start": "1164520",
    "end": "1171159"
  },
  {
    "text": "to bin pack more aggressively by saying I want to place Parts in a way such that I want to fill up one note first before",
    "start": "1171159",
    "end": "1177720"
  },
  {
    "text": "I move on to the next note um you can use the most allocated um strategy here",
    "start": "1177720",
    "end": "1184000"
  },
  {
    "text": "within your schedu or configuration so you just set this the the the scoring strategy type being most allocated under",
    "start": "1184000",
    "end": "1190520"
  },
  {
    "text": "your node resources fit and in here what it will do is um it will basically start",
    "start": "1190520",
    "end": "1196000"
  },
  {
    "text": "packing pots in a way that fills up the first node and then move on to the next s etc etc um and the Al and here's the",
    "start": "1196000",
    "end": "1203039"
  },
  {
    "text": "algorithm which is basically uh you go request resource uh resource requested divided by re request capacity multiply",
    "start": "1203039",
    "end": "1209280"
  },
  {
    "text": "by the percentage um as well as multiply by the weight that's associated with that particular resource so you could",
    "start": "1209280",
    "end": "1214720"
  },
  {
    "text": "tune this such such as like if you want to do you know higher weight for CPU or lower weight for memory or maybe a",
    "start": "1214720",
    "end": "1220679"
  },
  {
    "text": "different you know weight for like a custom resource like a GPU or something like this you can you can tune this according to um you know how your",
    "start": "1220679",
    "end": "1227280"
  },
  {
    "text": "cluster and your note resource look like so another thing that another",
    "start": "1227280",
    "end": "1233880"
  },
  {
    "text": "strategy that comes with the no resources fit is What's called the request to capacity ratio so this allows",
    "start": "1233880",
    "end": "1239240"
  },
  {
    "text": "you to have really kind of fine control of the scoring shape by giving kind of",
    "start": "1239240",
    "end": "1244720"
  },
  {
    "text": "the exact mapping of my node utilization to the actual score that I want to get",
    "start": "1244720",
    "end": "1250960"
  },
  {
    "text": "so in this particular example um I've got my um you know scoring strategy to",
    "start": "1250960",
    "end": "1256640"
  },
  {
    "text": "be requested capacity ratio and and my shape looks something like if my noes utilization is 0% then the score is zero",
    "start": "1256640",
    "end": "1264520"
  },
  {
    "text": "and if my node utilization is 100% then I want to score a 10 10 being the max here so what this will do is you can see",
    "start": "1264520",
    "end": "1270240"
  },
  {
    "text": "it will draw like a linear line from you know zero to to to 10 essentially and",
    "start": "1270240",
    "end": "1276320"
  },
  {
    "text": "basically if your note percentage lands on one of the dots it'll G give you a score according to what the line says so",
    "start": "1276320",
    "end": "1283720"
  },
  {
    "text": "this can be really useful if you don't uh necessar I mean this is a very simplified example but if you want to",
    "start": "1283720",
    "end": "1289360"
  },
  {
    "text": "have a more complicated different shaping example you could really kind of find your control like your utilization",
    "start": "1289360",
    "end": "1296039"
  },
  {
    "text": "to like your score mapping so in this particular case you know I see that I I've got like a more like a parabolic",
    "start": "1296039",
    "end": "1303240"
  },
  {
    "text": "kind of shape where you know as the percentage goes uh really high then my score change is much more less",
    "start": "1303240",
    "end": "1309679"
  },
  {
    "text": "significant than you know at the lower uh uh a utilization",
    "start": "1309679",
    "end": "1316039"
  },
  {
    "text": "percentage so I'm going to do demo here of the node resources fit",
    "start": "1316760",
    "end": "1323760"
  },
  {
    "text": "here so um I'm inside a VM and um I'm going to be using a kind cluster here to",
    "start": "1325000",
    "end": "1331679"
  },
  {
    "text": "show this so I've got four nodes here with uh one control plane node and three",
    "start": "1331679",
    "end": "1337559"
  },
  {
    "text": "worker nodes so what I'm going to do here is um",
    "start": "1337559",
    "end": "1344000"
  },
  {
    "text": "rather than uh I'm going to show basically um how I would conf configure this by deploying actually a second",
    "start": "1344000",
    "end": "1350480"
  },
  {
    "text": "scheduler into the cluster and the second scheduler here um I've I've specified my configuration here um with",
    "start": "1350480",
    "end": "1357039"
  },
  {
    "text": "two profiles so the first profile here is going to be a spread scheduler and what I'm going to do here is I'm going",
    "start": "1357039",
    "end": "1362559"
  },
  {
    "text": "to turn off all the other scoring plugin except for the node resources fit this is just to really amplify this example",
    "start": "1362559",
    "end": "1368799"
  },
  {
    "text": "here um of what this uh of requested capacity ratio um uh looks like and in",
    "start": "1368799",
    "end": "1375360"
  },
  {
    "text": "the plugin config itself I want to say okay I'm going to wait CPU and memory being equal and my Capac requested",
    "start": "1375360",
    "end": "1381840"
  },
  {
    "text": "capacity ratio is going to say if I'm at 0% utilization then I'm going to give it Mass Max score and if my utilization is",
    "start": "1381840",
    "end": "1388760"
  },
  {
    "text": "100% then again I'm going to give it Min score so the spread scheduler really just behaves like the least uh allocated",
    "start": "1388760",
    "end": "1395279"
  },
  {
    "text": "um scoring strategy and then I've got a second uh profile called the pack scheduler and what this pack scheduler",
    "start": "1395279",
    "end": "1401240"
  },
  {
    "text": "is going to do is it's going to do the opposite which is going to say if my utilization is 0% then I'm going to give",
    "start": "1401240",
    "end": "1406400"
  },
  {
    "text": "it a score of zero and if my utilization is 100% then I'm going to give a score 10 so this is basically saying I want to",
    "start": "1406400",
    "end": "1412520"
  },
  {
    "text": "impact such that the most the notes with uh the the notes that's most used will be chosen for for my",
    "start": "1412520",
    "end": "1419520"
  },
  {
    "text": "placement so um what're going to do what I'm going to do here is I'm going to be deploying this",
    "start": "1419520",
    "end": "1427480"
  },
  {
    "text": "Schuler so I've got my second scheduler uh uh deploy now so um what I'm going to",
    "start": "1433480",
    "end": "1438960"
  },
  {
    "text": "do now is I'm going to just test this out by looking at my uh so I'm going to",
    "start": "1438960",
    "end": "1445600"
  },
  {
    "text": "create a deployment of six replicas um and then going to set my scheduler name to Target the spread scheduler so I want",
    "start": "1445600",
    "end": "1452919"
  },
  {
    "text": "to kind of spread my parts out across the three worker nodes so I'm going",
    "start": "1452919",
    "end": "1459520"
  },
  {
    "text": "to apply the spread case",
    "start": "1459520",
    "end": "1467960"
  },
  {
    "text": "so you can see that my uh all all six my my replicas are running and uh they're placed evenly across three worker noes I",
    "start": "1473200",
    "end": "1480080"
  },
  {
    "text": "got two in each",
    "start": "1480080",
    "end": "1482799"
  },
  {
    "text": "node so I'm going to delete this deployment and then I'm going to be deploying a second example that's um",
    "start": "1485240",
    "end": "1492640"
  },
  {
    "text": "targeting the pack scheduler so exactly the same configuration the only thing is I'm targeting this to a different",
    "start": "1492640",
    "end": "1498080"
  },
  {
    "text": "profile file and I'm going to apply",
    "start": "1498080",
    "end": "1505640"
  },
  {
    "text": "this and all of them are running and you can see that basically all six parts got placed on that one node so this is",
    "start": "1511960",
    "end": "1518480"
  },
  {
    "text": "basically um we are essentially been packing as much as possible until this node fills up before we move we move",
    "start": "1518480",
    "end": "1524480"
  },
  {
    "text": "on so that's all I wanted to show here in the demo",
    "start": "1524480",
    "end": "1530320"
  },
  {
    "text": "um let me jump back to the keynote so I think next uh Yan is going",
    "start": "1530440",
    "end": "1535480"
  },
  {
    "text": "to be talking about the schedu or",
    "start": "1535480",
    "end": "1539640"
  },
  {
    "text": "operation do we do we want to take questions now or take a question at the",
    "start": "1541720",
    "end": "1546880"
  },
  {
    "text": "end uh yeah so I've got a couple questions maybe we can just take that right now",
    "start": "1547440",
    "end": "1554440"
  },
  {
    "text": "sure so the question was um did you did did we have any specific use cases where",
    "start": "1577320",
    "end": "1582640"
  },
  {
    "text": "you wanted to actually configure these profiles rather than just use the default one so um we have some use cases",
    "start": "1582640",
    "end": "1589320"
  },
  {
    "text": "where um we have particular large clusters where some customers we may want to really fin pack really tight um",
    "start": "1589320",
    "end": "1595840"
  },
  {
    "text": "because they run a very large scale deployment and in those cases um you know we do need to help them finding",
    "start": "1595840",
    "end": "1601840"
  },
  {
    "text": "because some of the default spread strategy may not be the most efficient at placement of",
    "start": "1601840",
    "end": "1609159"
  },
  {
    "text": "PODS uh go ahead yeah this is",
    "start": "1610760",
    "end": "1615640"
  },
  {
    "text": "a a lot",
    "start": "1617240",
    "end": "1620559"
  },
  {
    "text": "ofy",
    "start": "1623840",
    "end": "1626840"
  },
  {
    "text": "V customers access you",
    "start": "1634320",
    "end": "1641120"
  },
  {
    "text": "I think I so the short answer is uh it's up to the randers to like how to make",
    "start": "1650480",
    "end": "1658840"
  },
  {
    "text": "their control plan more extensible and uh manipulatable for the for the user",
    "start": "1658840",
    "end": "1665960"
  },
  {
    "text": "but in a practical view is that uh you can deployment the whole your customer",
    "start": "1665960",
    "end": "1673159"
  },
  {
    "text": "Plugin or whatever in outside because you don't have the control on on the",
    "start": "1673159",
    "end": "1678600"
  },
  {
    "text": "control plane so that because you specify a secondary scheduler so ideally",
    "start": "1678600",
    "end": "1684519"
  },
  {
    "text": "it doesn't conflict with the default SCH if you don't use the def at all you just use the because you want to control over",
    "start": "1684519",
    "end": "1691720"
  },
  {
    "text": "that yeah because use it this way you uh you",
    "start": "1691720",
    "end": "1697120"
  },
  {
    "text": "have the 100% compatibility with default schedule and you just have the pure",
    "start": "1697120",
    "end": "1702600"
  },
  {
    "text": "add-ons for to fit your customer needs I think we should continue yeah to finish",
    "start": "1702600",
    "end": "1707760"
  },
  {
    "text": "it then and by the end of the Q&A session we will live time yeah",
    "start": "1707760",
    "end": "1712799"
  },
  {
    "text": "questions yeah I I I think we can it's my audio on can you hear me well okay so",
    "start": "1712799",
    "end": "1720320"
  },
  {
    "text": "we can take more questions after the talk yeah uh yeah just come to to us",
    "start": "1720320",
    "end": "1725360"
  },
  {
    "text": "thanks for iore for the great presentation the demo I think iore has covered everything and did the work for",
    "start": "1725360",
    "end": "1732760"
  },
  {
    "text": "me maybe I can just skip my next session but uh anyway so my",
    "start": "1732760",
    "end": "1740039"
  },
  {
    "text": "next session I'm going to focus more on how to operate the schedule right and in",
    "start": "1740159",
    "end": "1747640"
  },
  {
    "text": "particular share and the some the experience and knowledge with you how to",
    "start": "1747640",
    "end": "1753880"
  },
  {
    "text": "for example build deployer scheduler and uh when you run a schedu def the events",
    "start": "1753880",
    "end": "1760519"
  },
  {
    "text": "and L information very important in particularly and uh if you maintain the",
    "start": "1760519",
    "end": "1766640"
  },
  {
    "text": "schedu you will know most of the problem right the customer users come to you and",
    "start": "1766640",
    "end": "1771720"
  },
  {
    "text": "said oh why my ports and are not scheduled why it's so slow to schedule right so how to troot and some the",
    "start": "1771720",
    "end": "1778240"
  },
  {
    "text": "typical problems then I will also show some key metrics and some example",
    "start": "1778240",
    "end": "1783279"
  },
  {
    "text": "dashboards and hopefully you will find it helpful uh so I have uh yeah created",
    "start": "1783279",
    "end": "1791279"
  },
  {
    "text": "some of the examples and we uploaded to this in the GitHub repo so if you go to",
    "start": "1791279",
    "end": "1797360"
  },
  {
    "text": "our present ation and we upload the presentation uh PDF file so in this on",
    "start": "1797360",
    "end": "1804240"
  },
  {
    "text": "these slides and uh you can click the link if you want to play with it as long as you have the go 119 and you can yeah",
    "start": "1804240",
    "end": "1812279"
  },
  {
    "text": "just download and clone the cutic latest version you have a local kubernetes",
    "start": "1812279",
    "end": "1818240"
  },
  {
    "text": "environment NE Medi Cube or kind yeah both should work then also I have a",
    "start": "1818240",
    "end": "1823519"
  },
  {
    "text": "bunch of the uh yamama files there so you you you can yeah play with it and if",
    "start": "1823519",
    "end": "1829279"
  },
  {
    "text": "you're interested uh so so one thing that I want to mention right eore and uh",
    "start": "1829279",
    "end": "1836279"
  },
  {
    "text": "mention not also we and detail and how advanced the schedule make the decision",
    "start": "1836279",
    "end": "1842880"
  },
  {
    "text": "right the different queue and different pluging different placement strategy but",
    "start": "1842880",
    "end": "1848360"
  },
  {
    "text": "uh if we put the simplest uh way right what does a schedule and do right it's",
    "start": "1848360",
    "end": "1855080"
  },
  {
    "text": "basically just get unscheduled port and choose a node and then assign a node",
    "start": "1855080",
    "end": "1860760"
  },
  {
    "text": "name to that Port that's all right you can use very an advanced algorithm or",
    "start": "1860760",
    "end": "1866320"
  },
  {
    "text": "the simplest way you could use a random right I just the random choose one if it's working and then just place there",
    "start": "1866320",
    "end": "1872120"
  },
  {
    "text": "so also and uh if you want run a schedule from API server perspective",
    "start": "1872120",
    "end": "1877720"
  },
  {
    "text": "schedule is nothing and different from it's another client or another controller right as long as you can",
    "start": "1877720",
    "end": "1883720"
  },
  {
    "text": "connect it to the kubernetes API server you are fine and you can get the port",
    "start": "1883720",
    "end": "1888760"
  },
  {
    "text": "information you can update the report so it's simple like that also you can run and as many schedule as you want as long",
    "start": "1888760",
    "end": "1896480"
  },
  {
    "text": "as each schedule have a different name unique name you already cover that so okay so go back to this and uh if we",
    "start": "1896480",
    "end": "1904440"
  },
  {
    "text": "look at the the schedule right and uh here I I I I just want to show you iny",
    "start": "1904440",
    "end": "1912720"
  },
  {
    "text": "and everyone can play with it and with your Lo environment and customize it and",
    "start": "1912720",
    "end": "1917960"
  },
  {
    "text": "other thing this is a report I I downloaded right I simply you just make",
    "start": "1917960",
    "end": "1923320"
  },
  {
    "text": "a cube schedule and it will and uh generate okay so by default and uh it",
    "start": "1923320",
    "end": "1930720"
  },
  {
    "text": "will generate this created this and uh binary files here and called the cube",
    "start": "1930720",
    "end": "1936840"
  },
  {
    "text": "schedule that's the default name then you can run it the interesting thing another thing is how you want to run the",
    "start": "1936840",
    "end": "1943760"
  },
  {
    "text": "schedule right is The Voice still working right",
    "start": "1943760",
    "end": "1949080"
  },
  {
    "text": "it's also just simple and you run this command and the only interesting thing",
    "start": "1949080",
    "end": "1956519"
  },
  {
    "text": "or matter and what matters most or the only parameter basically is you need is",
    "start": "1956519",
    "end": "1961799"
  },
  {
    "text": "specify the schedule Poli file or configuration file you b r color right the simplest one in configuration file",
    "start": "1961799",
    "end": "1968679"
  },
  {
    "text": "also there only one single parameters properly is really matters is this in",
    "start": "1968679",
    "end": "1974559"
  },
  {
    "text": "the kubernetes configure right kubernetes configure and I hope you you know right specify your your certificate",
    "start": "1974559",
    "end": "1981159"
  },
  {
    "text": "key how you connect VP server if you have that yeah that's all you can just the wrong schedule so option two of",
    "start": "1981159",
    "end": "1989000"
  },
  {
    "text": "course in most the production system will wrong and we containerize the schedule and wrong it in uh ports and",
    "start": "1989000",
    "end": "1996639"
  },
  {
    "text": "uh containers but nothing different right you create image and in a command 9 you just started so if we go back to",
    "start": "1996639",
    "end": "2004720"
  },
  {
    "text": "and my demo and here right my environment and here yeah so so you will see yeah I I also have",
    "start": "2004720",
    "end": "2013200"
  },
  {
    "text": "the script there you can see here yeah just run this and schedule I just buil",
    "start": "2016080",
    "end": "2022279"
  },
  {
    "text": "and specify the configuration file also the configuration file and now you",
    "start": "2022279",
    "end": "2028120"
  },
  {
    "text": "already cover it and I give you a simple example that I created two basic the profile one is I call the default one",
    "start": "2028120",
    "end": "2035000"
  },
  {
    "text": "nothing plug in I didn't disc cost anything another one I call best feat",
    "start": "2035000",
    "end": "2040519"
  },
  {
    "text": "you mention the the the the curve scoring curve here and I use the default",
    "start": "2040519",
    "end": "2047200"
  },
  {
    "text": "the inry already Upstream one but it's not a default default called Leist",
    "start": "2047200",
    "end": "2052878"
  },
  {
    "text": "allocator you can think it's a worst Feit right try to find the most idle notes most Advocate one means I will",
    "start": "2052879",
    "end": "2060000"
  },
  {
    "text": "best Feit try to find the most allocated one is like being packing yeah something",
    "start": "2060000",
    "end": "2065118"
  },
  {
    "text": "like this yeah other parameters you both covered I I I just specify there then",
    "start": "2065119",
    "end": "2070158"
  },
  {
    "text": "yeah you you just dra and uh yeah this kind of you if you see all this information yeah it's working right you",
    "start": "2070159",
    "end": "2076679"
  },
  {
    "text": "see this so it's just the simple like that then you can debug and try and if you want to play with it and test with",
    "start": "2076679",
    "end": "2084040"
  },
  {
    "text": "it okay so go back to my talk here yeah I already covered",
    "start": "2084040",
    "end": "2091320"
  },
  {
    "text": "this so as I mentioned so firstly of course if you didn't start it successful most is right",
    "start": "2091320",
    "end": "2099160"
  },
  {
    "text": "make sure your pass is correct you have the right config also you you should",
    "start": "2099160",
    "end": "2104520"
  },
  {
    "text": "config our back and other make sure your schedule can get the information can also update the Nots but one tip I want",
    "start": "2104520",
    "end": "2112079"
  },
  {
    "text": "to show you here is a uh relative new and feature I don't know when it's",
    "start": "2112079",
    "end": "2117920"
  },
  {
    "text": "available in this so if you want to debug and your configuration other thing you can specify with run command called",
    "start": "2117920",
    "end": "2124760"
  },
  {
    "text": "right config two with this and uh command n the flag so it will generate",
    "start": "2124760",
    "end": "2130720"
  },
  {
    "text": "basically and the configuration files for you and what you are running so for",
    "start": "2130720",
    "end": "2135839"
  },
  {
    "text": "example here okay so now of course I I really run the the schedule and but this",
    "start": "2135839",
    "end": "2142040"
  },
  {
    "text": "one if I use this I have another one I call it right configure the only",
    "start": "2142040",
    "end": "2147680"
  },
  {
    "text": "difference here I want start the SK schedule and the actual schedule instead",
    "start": "2147680",
    "end": "2153760"
  },
  {
    "text": "just generate this and the profile configuration file so so if you use this",
    "start": "2153760",
    "end": "2158960"
  },
  {
    "text": "one of course you can play in the N we I have all this script there okay it's",
    "start": "2158960",
    "end": "2164280"
  },
  {
    "text": "basically we generate and the schedule files for you and this one so if you",
    "start": "2164280",
    "end": "2170400"
  },
  {
    "text": "check this and it's a known file and a notch file right it is already populated",
    "start": "2170400",
    "end": "2177520"
  },
  {
    "text": "all this and the default and the configuration of plugin information so then you can see is anything right or",
    "start": "2177520",
    "end": "2184000"
  },
  {
    "text": "wrong right your configuration and this default venue you can see or lead election is two or fource so this will",
    "start": "2184000",
    "end": "2191200"
  },
  {
    "text": "be very useful for you to debug and if your configuration or your schedule and",
    "start": "2191200",
    "end": "2197480"
  },
  {
    "text": "uh didn't and uh start okay then switch",
    "start": "2197480",
    "end": "2206359"
  },
  {
    "text": "back okay so once you started and as I mentioned so most important thing and I",
    "start": "2210280",
    "end": "2216400"
  },
  {
    "text": "I think is you should understand uh check or look at the schedule loog file so typically and",
    "start": "2216400",
    "end": "2223920"
  },
  {
    "text": "there are all different way you can specify config it and ear version you can specify in the uh log file and just",
    "start": "2223920",
    "end": "2230920"
  },
  {
    "text": "on the command and the flag now I think there are different log and utility and can configure it so in the schedule of",
    "start": "2230920",
    "end": "2238040"
  },
  {
    "text": "fire I would just see yeah we and give a brief and introduction the the life",
    "start": "2238040",
    "end": "2243440"
  },
  {
    "text": "cycle so most important information here we see neither a port is scheduled",
    "start": "2243440",
    "end": "2248760"
  },
  {
    "text": "successfully or a schedule not scheduled you will you need to check this key",
    "start": "2248760",
    "end": "2254920"
  },
  {
    "text": "events in the log file one is when a port is submitted you will see a add event for this unscheduled Port",
    "start": "2254920",
    "end": "2262119"
  },
  {
    "text": "basically is Right added to the scheduled queue then it have to wait in the queue until the schedule pick it up",
    "start": "2262119",
    "end": "2269319"
  },
  {
    "text": "so once it's turn to be schedu you will see this information this keyword attempting to schedule this sport this",
    "start": "2269319",
    "end": "2276599"
  },
  {
    "text": "is the time the schedule we run the plugin try to find a another feed to it right if it it's successfully scheduled",
    "start": "2276599",
    "end": "2283880"
  },
  {
    "text": "you will see this message successfully bond this ports to a node you will see the node name then you will see delete",
    "start": "2283880",
    "end": "2290520"
  },
  {
    "text": "the uh unscheduled Port Right add the schedule port on the other hand if a",
    "start": "2290520",
    "end": "2296760"
  },
  {
    "text": "schedule and is not is a p if a port is not scheduled most important thing",
    "start": "2296760",
    "end": "2302880"
  },
  {
    "text": "information and uh in addition to the queue and other events information you",
    "start": "2302880",
    "end": "2308000"
  },
  {
    "text": "will see this and not fit also each node",
    "start": "2308000",
    "end": "2313119"
  },
  {
    "text": "right and what's the reason that caused the schedule uh this schedule portal",
    "start": "2313119",
    "end": "2318880"
  },
  {
    "text": "scheduling field the reason right the 72 ports didn't match other information that's how you can debug and your",
    "start": "2318880",
    "end": "2325960"
  },
  {
    "text": "information why it's successfully and or not so typically and tons of reasons",
    "start": "2325960",
    "end": "2332280"
  },
  {
    "text": "right and a a port is not scheduled successfully but I would like to",
    "start": "2332280",
    "end": "2338520"
  },
  {
    "text": "summarize and yeah three high level and categories and that's what and we have seen and in production or in practice",
    "start": "2338520",
    "end": "2346280"
  },
  {
    "text": "one is yeah could be not misconfiguration in particular related to the uh storage persistant volume or",
    "start": "2346280",
    "end": "2353160"
  },
  {
    "text": "persistent volume claim right it's not found other things so that's one thing in particularly I think different",
    "start": "2353160",
    "end": "2358920"
  },
  {
    "text": "customers or CL Cloud providers have different Storage Solutions so that's is",
    "start": "2358920",
    "end": "2364240"
  },
  {
    "text": "something and uh you should and uh yeah definitely check be careful another the second one and uh of course is if the",
    "start": "2364240",
    "end": "2372560"
  },
  {
    "text": "scheduler and is not able to find a feasible nodes to fit this in the ports",
    "start": "2372560",
    "end": "2378880"
  },
  {
    "text": "right and uh then that's also very typical and we have seen and uh depending on the availability alloca",
    "start": "2378880",
    "end": "2385160"
  },
  {
    "text": "resources also the physical and the capacity you will find it the last one is the yeah so the a port can specify a",
    "start": "2385160",
    "end": "2393880"
  },
  {
    "text": "not of the constraints additional constraints right port Affinity no Affinity no s if it's soft constant is",
    "start": "2393880",
    "end": "2402160"
  },
  {
    "text": "preference it's okay but if it's hard constants then you will see and maybe",
    "start": "2402160",
    "end": "2407200"
  },
  {
    "text": "even you have noes available right resource available in general but it cannot the schedule reports so now and",
    "start": "2407200",
    "end": "2414160"
  },
  {
    "text": "yeah if we look at the log here and I I will quickly yeah just Sho and some",
    "start": "2414160",
    "end": "2419760"
  },
  {
    "text": "examples as well and",
    "start": "2419760",
    "end": "2424160"
  },
  {
    "text": "yeah uh so again I I'm going to start this schedule right so now if I I have a",
    "start": "2428440",
    "end": "2437280"
  },
  {
    "text": "ports very simple ports here right and like yeah it's nothing specify 5 CPU",
    "start": "2437280",
    "end": "2446160"
  },
  {
    "text": "and I use this profile name you remember our schedule right we have the",
    "start": "2446160",
    "end": "2454359"
  },
  {
    "text": "this yeah uh we specify we create two profile right you can use anyone to do",
    "start": "2459560",
    "end": "2468720"
  },
  {
    "text": "it it's little bit stone at all",
    "start": "2470040",
    "end": "2475599"
  },
  {
    "text": "okay what's going on oh I have this Notch ports and I draw",
    "start": "2475599",
    "end": "2482720"
  },
  {
    "text": "early and",
    "start": "2482720",
    "end": "2486160"
  },
  {
    "text": "otherwise it's can only run one port okay so as I mentioned early right you will see and the the the",
    "start": "2488440",
    "end": "2495480"
  },
  {
    "text": "information about the ports right and basically try to attempting to schedule",
    "start": "2495480",
    "end": "2501280"
  },
  {
    "text": "it attempting bind it then successfully bound the ports to node then add the",
    "start": "2501280",
    "end": "2507800"
  },
  {
    "text": "scheduled event deleted the scheduled event and this but if I run a another",
    "start": "2507800",
    "end": "2513000"
  },
  {
    "text": "and Notch ports right I have a notch ports two CPU because my notes if you",
    "start": "2513000",
    "end": "2518920"
  },
  {
    "text": "look",
    "start": "2518920",
    "end": "2521200"
  },
  {
    "text": "at yeah so so far it's already used 60% yeah almost 1.2 CPU yeah this node and",
    "start": "2525160",
    "end": "2533160"
  },
  {
    "text": "if you check the allocatable resources is two CPU so now it's only have this",
    "start": "2533160",
    "end": "2538599"
  },
  {
    "text": "and less than point8 CPU available so now I purposely create a n p request",
    "start": "2538599",
    "end": "2545480"
  },
  {
    "text": "yeah this unschedulable one I request two CPU right it should not be able to",
    "start": "2545480",
    "end": "2551319"
  },
  {
    "text": "schedule",
    "start": "2551319",
    "end": "2554079"
  },
  {
    "text": "right yeah you see it's pending right here and also as you can see this",
    "start": "2557160",
    "end": "2562359"
  },
  {
    "text": "message as I just H right one means there one node because I I I I'm using a",
    "start": "2562359",
    "end": "2567720"
  },
  {
    "text": "media Cube and the class is only a one not so means there one node in sufficient CPU so anyway that's the most",
    "start": "2567720",
    "end": "2574440"
  },
  {
    "text": "if you want to check look into the reason why uh Port is not scheduled and",
    "start": "2574440",
    "end": "2579839"
  },
  {
    "text": "you search the not just look at this unable to schedule it right and then look at the reason why the ports not",
    "start": "2579839",
    "end": "2588440"
  },
  {
    "text": "schedule okay then let's switch back and uh yeah unfortunately due to the time",
    "start": "2588440",
    "end": "2594640"
  },
  {
    "text": "this a little bit uh complicated other case I didn't shoot but this is the",
    "start": "2594640",
    "end": "2599800"
  },
  {
    "text": "typical message you can check and the misconfiguration position the volume as",
    "start": "2599800",
    "end": "2604960"
  },
  {
    "text": "I mentioned also the tent and the aity okay the second one is okay maybe the",
    "start": "2604960",
    "end": "2610520"
  },
  {
    "text": "the port is scheduled but it's too slow right that's also and uh yeah as we we",
    "start": "2610520",
    "end": "2616880"
  },
  {
    "text": "are maintaining and uh yeah kubernetes and a lot of times customers oh it's way too slow into scheduled report so here I",
    "start": "2616880",
    "end": "2625319"
  },
  {
    "text": "I also want to mention and the yeah some of the common the cases or or tricky",
    "start": "2625319",
    "end": "2631680"
  },
  {
    "text": "cases the first one is you know the the schedule need to talk API server maybe",
    "start": "2631680",
    "end": "2636720"
  },
  {
    "text": "even talk to some the admission controller because it need to update the ports so it need the networking",
    "start": "2636720",
    "end": "2643920"
  },
  {
    "text": "connection and make sure the network and the latency is uh okay otherwise a lot",
    "start": "2643920",
    "end": "2649359"
  },
  {
    "text": "of times we also notice that because of the network and latency isue so the schedule make a good decision and right",
    "start": "2649359",
    "end": "2656480"
  },
  {
    "text": "decision and a quick decision but unfortunately and it cannot update the ports and the status then this will slow",
    "start": "2656480",
    "end": "2663599"
  },
  {
    "text": "down the entire Pipeline and finally slow down the uh the schedu portal schedule increase",
    "start": "2663599",
    "end": "2671400"
  },
  {
    "text": "the latency so normally if you check the log you will see some yeah like the uh",
    "start": "2671400",
    "end": "2676559"
  },
  {
    "text": "collection timeout other information like Arrow updating the and ports that's one thing the second thing yeah e b and",
    "start": "2676559",
    "end": "2684480"
  },
  {
    "text": "mentioned it's very important is this so there are two parameters called a back",
    "start": "2684480",
    "end": "2690359"
  },
  {
    "text": "off right if a schedule the first time was not scheduled successfully it will",
    "start": "2690359",
    "end": "2695839"
  },
  {
    "text": "be put into unsch of Q then to the back off Q then wait for its back off time",
    "start": "2695839",
    "end": "2701480"
  },
  {
    "text": "right expire then it's move back to the active que to get another chance to be scheduled but it's also I think",
    "start": "2701480",
    "end": "2708599"
  },
  {
    "text": "important also sometimes tricky to set these parameters and the default one is",
    "start": "2708599",
    "end": "2714040"
  },
  {
    "text": "1 second for the initial back of seconds and 10 times for the maximum one so it's",
    "start": "2714040",
    "end": "2719800"
  },
  {
    "text": "exponentially increased so it's like a three times it will increase to 10 seconds only wait in the back of que for",
    "start": "2719800",
    "end": "2726760"
  },
  {
    "text": "10 seconds use this and the default one obviously it's quite good right if you want the more the responsibilities right",
    "start": "2726760",
    "end": "2734520"
  },
  {
    "text": "because the cluster status could be changed so far the cluster didn't have the 5 minutes ago 1 seconds ago and it",
    "start": "2734520",
    "end": "2742240"
  },
  {
    "text": "didn't have the resources but maybe just 10x L some ports and finish it can",
    "start": "2742240",
    "end": "2747880"
  },
  {
    "text": "schedule but another thing that we have to be careful is if you set too small even use the default one we noticed it",
    "start": "2747880",
    "end": "2755319"
  },
  {
    "text": "could in large clusters and with thousands of notes or 10 thousands of ports you have different priority of the",
    "start": "2755319",
    "end": "2762319"
  },
  {
    "text": "Clusters it could cause some of the head of nine blocking isue what's what what",
    "start": "2762319",
    "end": "2768319"
  },
  {
    "text": "what caused that is because your highest priority ports for example highest priority port and didn't find the",
    "start": "2768319",
    "end": "2775440"
  },
  {
    "text": "sufficient and the resource to run it put back to the back of q but it's back",
    "start": "2775440",
    "end": "2781760"
  },
  {
    "text": "off and just wait for a few seconds then come back to the active queue because",
    "start": "2781760",
    "end": "2787160"
  },
  {
    "text": "the default queue and the ranking or sorting is based on priority right if you have a large number of this",
    "start": "2787160",
    "end": "2792760"
  },
  {
    "text": "unscheduled higher priority and ports they are unschedulable misconfigure",
    "start": "2792760",
    "end": "2799240"
  },
  {
    "text": "other thing then we just keep back to the active queue rescheduling too frequently",
    "start": "2799240",
    "end": "2805520"
  },
  {
    "text": "then they can cause other no priority ports right blocked and cannot be",
    "start": "2805520",
    "end": "2810880"
  },
  {
    "text": "scheduled so this is uh something and uh you have to make the Tweet off right",
    "start": "2810880",
    "end": "2816520"
  },
  {
    "text": "respon this and also make sure the fan is and other thing so maybe I can",
    "start": "2816520",
    "end": "2822359"
  },
  {
    "text": "quickly and show example here this percentage of notes the effect hopefully",
    "start": "2822359",
    "end": "2828599"
  },
  {
    "text": "we can let me see now what's the default configuration I",
    "start": "2828599",
    "end": "2835640"
  },
  {
    "text": "started okay so now is the default why I Just sh here you don't need to specify",
    "start": "2835640",
    "end": "2840960"
  },
  {
    "text": "this default initial is 1 seconds maximum is 10 seconds means the unscheduled only wait for the uh in the",
    "start": "2840960",
    "end": "2848720"
  },
  {
    "text": "back of que for 10 seconds so now one reason yeah I I start to post early",
    "start": "2848720",
    "end": "2854160"
  },
  {
    "text": "because this not CPU not CPU one is pending and because it's didn't get",
    "start": "2854160",
    "end": "2859960"
  },
  {
    "text": "enough resource but what about if I delete it and deleted",
    "start": "2859960",
    "end": "2865800"
  },
  {
    "text": "the this ports right okay I can Del just call it",
    "start": "2865800",
    "end": "2872599"
  },
  {
    "text": "ports okay let's see and uh I should restart it and uh but let's see how",
    "start": "2874920",
    "end": "2881720"
  },
  {
    "text": "quickly and it's get I don't know if this is the lar CPU",
    "start": "2881720",
    "end": "2887160"
  },
  {
    "text": "ports or unschedulable one uh okay maybe let me start it from",
    "start": "2887160",
    "end": "2897078"
  },
  {
    "text": "beginning okay that's 1.2 okay so I start a small one it should running",
    "start": "2902800",
    "end": "2909960"
  },
  {
    "text": "right now I start I'm starting this Notch",
    "start": "2909960",
    "end": "2916160"
  },
  {
    "text": "one it's pending okay now I delete this small",
    "start": "2916480",
    "end": "2923960"
  },
  {
    "text": "one okay so you can see this one quickly yeah even as 17 seconds because the back",
    "start": "2933359",
    "end": "2938839"
  },
  {
    "text": "of time is 10 Okay now what's happened and if we change this to let me just give",
    "start": "2938839",
    "end": "2947160"
  },
  {
    "text": "a 60 seconds okay maximum 60 seconds and the initial 60 seconds and the maximum",
    "start": "2947160",
    "end": "2953839"
  },
  {
    "text": "also 60 seconds I restart the schedule because I changed the configuration file",
    "start": "2953839",
    "end": "2960079"
  },
  {
    "text": "I have to restart it okay let's see what happened",
    "start": "2960079",
    "end": "2965839"
  },
  {
    "text": "we start the small one right it should wrong okay now we start this Notch",
    "start": "2974319",
    "end": "2982480"
  },
  {
    "text": "one you should pend it okay now we delete this small one",
    "start": "2982480",
    "end": "2991839"
  },
  {
    "text": "you see it's still pending of course we don't need wait but uh we can come back to check but uh it's already it have to",
    "start": "2997720",
    "end": "3006200"
  },
  {
    "text": "wait to has to wait and for at least 60 seconds right so hopefully yeah you you",
    "start": "3006200",
    "end": "3013000"
  },
  {
    "text": "you get this information so this is some parameters we we we find and we found in our practice yeah it can be useful so",
    "start": "3013000",
    "end": "3021280"
  },
  {
    "text": "last one yeah so I want to mention is this uh percentage of those two score",
    "start": "3021280",
    "end": "3027960"
  },
  {
    "text": "yeah you both also already covered that uh this is important and I want to",
    "start": "3027960",
    "end": "3033599"
  },
  {
    "text": "emphasize it again is is a balance basically your schedule schedule",
    "start": "3033599",
    "end": "3038680"
  },
  {
    "text": "quantity and a schedule performance right so you don't you can imagine you can have a fastest and schedule quickest",
    "start": "3038680",
    "end": "3047040"
  },
  {
    "text": "schedule just randomly choose one right and then the quality could be Po and you may not find the best notes but it's",
    "start": "3047040",
    "end": "3054400"
  },
  {
    "text": "definitely it is the fastest one so the kuet have this percentage of those two",
    "start": "3054400",
    "end": "3059640"
  },
  {
    "text": "score and uh you can specify it by default is zero they use a adaptive and",
    "start": "3059640",
    "end": "3065359"
  },
  {
    "text": "the formula so it's 50 50 minus the class size divid by 125 so here is",
    "start": "3065359",
    "end": "3072400"
  },
  {
    "text": "examples and if you specify 60 and uh percent then 200 uh50 notes means 250",
    "start": "3072400",
    "end": "3081040"
  },
  {
    "text": "time 60 and you get the 150 does so means the schedule will just scan the",
    "start": "3081040",
    "end": "3087240"
  },
  {
    "text": "all this clust noes until it find the 150 feasible noes right for this example",
    "start": "3087240",
    "end": "3092520"
  },
  {
    "text": "you can see here and that's from some dogs and I I I I run and offline so it's",
    "start": "3092520",
    "end": "3098400"
  },
  {
    "text": "evaluate a total of 232 notes then fin find this and 150 and",
    "start": "3098400",
    "end": "3105280"
  },
  {
    "text": "yeah Port but if you don't specify the parameter use the default one the default use this formula the percentage",
    "start": "3105280",
    "end": "3112839"
  },
  {
    "text": "is 28% 28% of the 250 nodes is less than 100 so the current implementation the",
    "start": "3112839",
    "end": "3120160"
  },
  {
    "text": "default minimum and the feasible notes is 100 so because it's less than to 100",
    "start": "3120160",
    "end": "3127240"
  },
  {
    "text": "so you can see here it search 172 nodes until it found 100 phable",
    "start": "3127240",
    "end": "3134640"
  },
  {
    "text": "nodes I just want to mention the use cases for this one is for example for batch workload you have some spark job",
    "start": "3134640",
    "end": "3141079"
  },
  {
    "text": "with thousands of ports you may don't care about where it's get run right you",
    "start": "3141079",
    "end": "3146520"
  },
  {
    "text": "you just maybe said oh I use a small percentage quickly I want right improved",
    "start": "3146520",
    "end": "3151640"
  },
  {
    "text": "the throughput you just find a not for me but for your non running service you may want to make sure all the soft",
    "start": "3151640",
    "end": "3157680"
  },
  {
    "text": "constraints Affinity rule yeah load Affinity anti Affinity rule can be met",
    "start": "3157680",
    "end": "3163119"
  },
  {
    "text": "then you may want to them and yeah search scan a LGE number of the nodes recently we and already found if this",
    "start": "3163119",
    "end": "3170280"
  },
  {
    "text": "number use the default one maybe your Port Infinity Ru cannot be met why",
    "start": "3170280",
    "end": "3176000"
  },
  {
    "text": "because this node get one set of feasible nodes another PST get another one basically they are disjoint set of",
    "start": "3176000",
    "end": "3183760"
  },
  {
    "text": "nodes even the entire class you can fight those collocated these two ports to minimize your networking connection",
    "start": "3183760",
    "end": "3190240"
  },
  {
    "text": "or latency but because each individually get two disjoint nodes pool so you cannot find them so that's something and",
    "start": "3190240",
    "end": "3197799"
  },
  {
    "text": "uh I I think will be very interesting and to look at and could be a useful",
    "start": "3197799",
    "end": "3203319"
  },
  {
    "text": "thing so last and uh is about metrix so",
    "start": "3203319",
    "end": "3208359"
  },
  {
    "text": "finally of course you can check the log and there are some parameters and IO and I already discussed is a tons of the",
    "start": "3208359",
    "end": "3216000"
  },
  {
    "text": "scheduling and the schedule related metrics uh you can check so here and I",
    "start": "3216000",
    "end": "3221200"
  },
  {
    "text": "put three key uh the categories of the metric you may find useful and when you",
    "start": "3221200",
    "end": "3226760"
  },
  {
    "text": "operate WR a schedule one is performance related one so there are bunch of the metrics High Lev is you can get a end to",
    "start": "3226760",
    "end": "3234520"
  },
  {
    "text": "endend from a submission submission until it's successfully uh uh scheduled",
    "start": "3234520",
    "end": "3240599"
  },
  {
    "text": "one so even multiple Cycles if it's one go to go through three Cycles get",
    "start": "3240599",
    "end": "3247119"
  },
  {
    "text": "scheduled so this is the total end to end time you can also get a single scheduled Cycles time you",
    "start": "3247119",
    "end": "3254400"
  },
  {
    "text": "also can have the each plugin and we mentioned right like the fter scoring",
    "start": "3254400",
    "end": "3261680"
  },
  {
    "text": "even different preemption the performance the second category is you can get the schedule different results",
    "start": "3261680",
    "end": "3268440"
  },
  {
    "text": "said okay how many get scheduled how many and unschedulable also in the queue",
    "start": "3268440",
    "end": "3274119"
  },
  {
    "text": "you can get the how many ports so far in active queue in unscheduled queue or in the back of queue finally and the",
    "start": "3274119",
    "end": "3281079"
  },
  {
    "text": "preemption is important right if your high priority ports are not scheduled",
    "start": "3281079",
    "end": "3286480"
  },
  {
    "text": "and the schedule try to evict other ports so you can get a bunch of the preemption information total preemption",
    "start": "3286480",
    "end": "3292760"
  },
  {
    "text": "attempts right if this ratio is too high and probably means Your Capacity might be in a trouble right or how how many",
    "start": "3292760",
    "end": "3300240"
  },
  {
    "text": "ports actually and are evicted or preempted so you can check this yeah I",
    "start": "3300240",
    "end": "3305799"
  },
  {
    "text": "have the link here you can check this and uh the the metrix files uh in the",
    "start": "3305799",
    "end": "3311760"
  },
  {
    "text": "schedule package they list all these metrics as well as the descriptions so",
    "start": "3311760",
    "end": "3317040"
  },
  {
    "text": "here I want go to the detail then of course you can create the graph dashboard can monitoring the all this",
    "start": "3317040",
    "end": "3323200"
  },
  {
    "text": "information yeah I said the latency information the port information and",
    "start": "3323200",
    "end": "3328559"
  },
  {
    "text": "preemption information all kinds of information that's definitely will be a great to and to get the information",
    "start": "3328559",
    "end": "3334400"
  },
  {
    "text": "about the performance about the uh overall status of the schedule so okay I",
    "start": "3334400",
    "end": "3340760"
  },
  {
    "text": "think that's all I have and uh I probably don't have time to take any",
    "start": "3340760",
    "end": "3346039"
  },
  {
    "text": "questions but uh we hopefully can answer something and some question at the end",
    "start": "3346039",
    "end": "3351319"
  },
  {
    "text": "of the talk or you can talk come to us to ask any questions okay wait all",
    "start": "3351319",
    "end": "3358480"
  },
  {
    "text": "right thanks Jan and both for the operation and the configuration part so",
    "start": "3358480",
    "end": "3364599"
  },
  {
    "text": "next part is about schedu extension sorry uh yeah schu does",
    "start": "3364599",
    "end": "3370799"
  },
  {
    "text": "provide a lot of inry functionality and provides a flexibility for you to config",
    "start": "3370799",
    "end": "3376119"
  },
  {
    "text": "to behave it differently but it's also very possible you still miss the fundamental",
    "start": "3376119",
    "end": "3384319"
  },
  {
    "text": "functionality you want to fit your customer work close so what should you do is there any way to push the boundary",
    "start": "3384319",
    "end": "3391920"
  },
  {
    "text": "of the def schuer the answer is yes so there's a couple of extension ways to",
    "start": "3391920",
    "end": "3399200"
  },
  {
    "text": "extend the cube schedule just like the principle of the overall kubernetes",
    "start": "3399200",
    "end": "3404359"
  },
  {
    "text": "platform so the first one is called schedule extender this is the first mechanism we introduced I think a couple",
    "start": "3404359",
    "end": "3411160"
  },
  {
    "text": "of years ago uh so basically extender is a external",
    "start": "3411160",
    "end": "3416799"
  },
  {
    "text": "HTTP web hook you can just associate with particular phase of a sagun cycle uh but",
    "start": "3416799",
    "end": "3425520"
  },
  {
    "text": "there's a two problem one is it only provides a pretty limited pH for you to",
    "start": "3425520",
    "end": "3431880"
  },
  {
    "text": "hook on uh I think I if I remember correctly right now you any can hook",
    "start": "3431880",
    "end": "3437119"
  },
  {
    "text": "into filter score and preemption and second problem is that this mechanism",
    "start": "3437119",
    "end": "3443559"
  },
  {
    "text": "this design is based on well you have have to involve the network cost to",
    "start": "3443559",
    "end": "3449839"
  },
  {
    "text": "exchange data between your web Hook and the cular and also the mro and demal cost",
    "start": "3449839",
    "end": "3458559"
  },
  {
    "text": "cannot be uh avoided so because of these two issues right now we don't quite",
    "start": "3458559",
    "end": "3466039"
  },
  {
    "text": "recommend it to use them in a large cluster so we do get some reports that",
    "start": "3466039",
    "end": "3471520"
  },
  {
    "text": "the extender can slow down the overall scheding throughput so so the second way",
    "start": "3471520",
    "end": "3477160"
  },
  {
    "text": "schedule pluging is the most recommended way to extend Cube SC right now and uh",
    "start": "3477160",
    "end": "3483680"
  },
  {
    "text": "yeah the later stats were basically based on this so it resolve the two",
    "start": "3483680",
    "end": "3489280"
  },
  {
    "text": "problem I mentioned in extender first one is it provides a bunch of extendable points",
    "start": "3489280",
    "end": "3497039"
  },
  {
    "text": "for you to extend and basically at every single place you can think of to extent",
    "start": "3497039",
    "end": "3504079"
  },
  {
    "text": "basically there's a exential point for you to use and second one is that we",
    "start": "3504079",
    "end": "3509280"
  },
  {
    "text": "long longer to use the HTTP or RPC connection between your extension and",
    "start": "3509280",
    "end": "3516559"
  },
  {
    "text": "the C schedule instead we provide a language specific interface so basically you have to implement that interface",
    "start": "3516559",
    "end": "3524599"
  },
  {
    "text": "then recompile the extra plugins at top the",
    "start": "3524599",
    "end": "3530680"
  },
  {
    "text": "default schedule so basically you have the 100% compatibility and just have the net benefits of the product in your",
    "start": "3530680",
    "end": "3538920"
  },
  {
    "text": "developers and also the third way uh because kuber netics doesn't have hidden",
    "start": "3538920",
    "end": "3545240"
  },
  {
    "text": "API what Cube schedule can build you can also build the same thing from scratch",
    "start": "3545240",
    "end": "3550839"
  },
  {
    "text": "you own the in that way you own the everything you own the kills you own the cash you own the everything and have to",
    "start": "3550839",
    "end": "3557319"
  },
  {
    "text": "implement all the scheduling uh constraint primtive in the in the P you",
    "start": "3557319",
    "end": "3563359"
  },
  {
    "text": "everything so but yeah you own it so this chart will basically focus on the",
    "start": "3563359",
    "end": "3569480"
  },
  {
    "text": "second extension",
    "start": "3569480",
    "end": "3574559"
  },
  {
    "text": "oops give one",
    "start": "3576440",
    "end": "3579920"
  },
  {
    "text": "second oh anyway okay if you look at the typical",
    "start": "3584359",
    "end": "3589839"
  },
  {
    "text": "scheding cycle uh it first starts with the so-called qord interface Q is the",
    "start": "3589839",
    "end": "3597119"
  },
  {
    "text": "interface between your starts pop up the part and gets started with SC part so",
    "start": "3597119",
    "end": "3604400"
  },
  {
    "text": "the qad is a provides a uh stainless",
    "start": "3604400",
    "end": "3609559"
  },
  {
    "text": "function interface just give you two parts and you tell me which part is",
    "start": "3609559",
    "end": "3614839"
  },
  {
    "text": "should be prioritized over the other then so that with this function",
    "start": "3614839",
    "end": "3621160"
  },
  {
    "text": "default schedular can know how to sort all the paths into its internal cu",
    "start": "3621160",
    "end": "3626720"
  },
  {
    "text": "and then in terms of implementation Right Now the default schedule Q pluging",
    "start": "3626720",
    "end": "3633960"
  },
  {
    "text": "just look at the priority value that you set associated with the priority Cass",
    "start": "3633960",
    "end": "3639599"
  },
  {
    "text": "then it can priority more high priority pass over the others but it doesn't",
    "start": "3639599",
    "end": "3645039"
  },
  {
    "text": "prevent you to implement your own logic like uh Co schedu pluging in the",
    "start": "3645039",
    "end": "3650960"
  },
  {
    "text": "community just to prefer uh sort the pa",
    "start": "3650960",
    "end": "3657200"
  },
  {
    "text": "uh belongs the same Part Group over the other so that they can schedule a group",
    "start": "3657200",
    "end": "3662799"
  },
  {
    "text": "of PA back to back so that you can get more chance to schedule a group of pass",
    "start": "3662799",
    "end": "3668440"
  },
  {
    "text": "all together so this is the QA and after QA you should have a very uh High chance",
    "start": "3668440",
    "end": "3677920"
  },
  {
    "text": "to pop up the PA which which you think is more important right immediately to",
    "start": "3677920",
    "end": "3684640"
  },
  {
    "text": "gu that scheduling so next phas is called pre filter pre- filter as the names suggest uh is the",
    "start": "3684640",
    "end": "3692000"
  },
  {
    "text": "pre-step before filter and there's several uh use cases for perter the",
    "start": "3692000",
    "end": "3698440"
  },
  {
    "text": "first one is simply simple is just you tell me whether the PA should be in",
    "start": "3698440",
    "end": "3704680"
  },
  {
    "text": "pretty lightweight cost to tell me that we should continue the scheding or not",
    "start": "3704680",
    "end": "3710200"
  },
  {
    "text": "so if the PA like uh we can in a very early phase to determine that the power",
    "start": "3710200",
    "end": "3716799"
  },
  {
    "text": "shouldn't continue then we just stop here so return as early as you can uh",
    "start": "3716799",
    "end": "3722920"
  },
  {
    "text": "and the other use case is that we pring a SC cycle related data",
    "start": "3722920",
    "end": "3732079"
  },
  {
    "text": "structure for your pro to prom in your specific data structure so you can use later on uh for example uh for some",
    "start": "3732079",
    "end": "3740799"
  },
  {
    "text": "complicated scheduling requirements like part topology spread and part definity",
    "start": "3740799",
    "end": "3746920"
  },
  {
    "text": "it needs to look at the part distribution across the cluster so in",
    "start": "3746920",
    "end": "3752880"
  },
  {
    "text": "this case later on the filter interface doesn't quite fit because it doesn't know the entire cluster's uh part",
    "start": "3752880",
    "end": "3761039"
  },
  {
    "text": "distribution so usually uh best practice is that you",
    "start": "3761039",
    "end": "3766440"
  },
  {
    "text": "pre-calculate sort of a predefined that structure and for the functionality you",
    "start": "3766440",
    "end": "3773480"
  },
  {
    "text": "want to schedule later on then then the data structure value will be passed down",
    "start": "3773480",
    "end": "3780039"
  },
  {
    "text": "in the same cycle so you can find the similar implementation in part topologic",
    "start": "3780039",
    "end": "3785279"
  },
  {
    "text": "spread and part Affinity so this is for pre filter and another thing I want to",
    "start": "3785279",
    "end": "3791160"
  },
  {
    "text": "uh also mention is that uh in the latest kubernetes uh offering we",
    "start": "3791160",
    "end": "3797440"
  },
  {
    "text": "provide a hook called prefi result so in the",
    "start": "3797440",
    "end": "3802559"
  },
  {
    "text": "before it doesn't exist so basically it can give you the knp",
    "start": "3802559",
    "end": "3809400"
  },
  {
    "text": "to a very smaller list of nails so that",
    "start": "3809400",
    "end": "3814440"
  },
  {
    "text": "the later on scheduling will just do the scheduling logic am the nails you",
    "start": "3814440",
    "end": "3821039"
  },
  {
    "text": "provide so it's pretty useful in terms like your schedule uh demon add part so",
    "start": "3821039",
    "end": "3827720"
  },
  {
    "text": "that you just because demon add is just you singularly schedule the part onto the single note so you don't need to",
    "start": "3827720",
    "end": "3834000"
  },
  {
    "text": "search the whole cluster so you but you can have some similar Innovative idea in",
    "start": "3834000",
    "end": "3839279"
  },
  {
    "text": "your prefilter implementation so next filter filter is",
    "start": "3839279",
    "end": "3845000"
  },
  {
    "text": "just give you the part and give you a note and you tell me whether the note",
    "start": "3845000",
    "end": "3850079"
  },
  {
    "text": "fits the part or not and uh uh yeah you can be using the",
    "start": "3850079",
    "end": "3857160"
  },
  {
    "text": "pre-calculated uh information that promp into the cycle State and also you can if",
    "start": "3857160",
    "end": "3864960"
  },
  {
    "text": "the SCH logic pretty simple you just uh implement the the logic without without",
    "start": "3864960",
    "end": "3870240"
  },
  {
    "text": "help of the cycle State and then next after filter we should come up with the",
    "start": "3870240",
    "end": "3876760"
  },
  {
    "text": "output of uh bunch of candidates notes and among the candidate notes what we",
    "start": "3876760",
    "end": "3883200"
  },
  {
    "text": "should do is we uh score them rank them to come out with a final winner node for",
    "start": "3883200",
    "end": "3890279"
  },
  {
    "text": "the part of the B to so in this pH PR prescho is Sim like prescore to score is",
    "start": "3890279",
    "end": "3897079"
  },
  {
    "text": "similar like prefilter to filter it's just that in this pH we don't need to provide a yes or no answer because when",
    "start": "3897079",
    "end": "3904079"
  },
  {
    "text": "it comes to Pro score the node we provide here in the node uh list are all",
    "start": "3904079",
    "end": "3910920"
  },
  {
    "text": "fible nodes so in this case so the most uh practical usage is to again pre promp",
    "start": "3910920",
    "end": "3918400"
  },
  {
    "text": "some calculation so that you can use later in the score phas and score phas",
    "start": "3918400",
    "end": "3924240"
  },
  {
    "text": "along with the uh call the normalized score is to come out with the final",
    "start": "3924240",
    "end": "3931480"
  },
  {
    "text": "score by given logic and then the score will be accumulated and then finally we",
    "start": "3931480",
    "end": "3938839"
  },
  {
    "text": "come up with the final score so we pick up the highest score for the for the P to bind",
    "start": "3938839",
    "end": "3945599"
  },
  {
    "text": "here uh yeah that's for score so next usually",
    "start": "3945599",
    "end": "3952480"
  },
  {
    "text": "after score actually we can just say say okay we are all down we can enter the",
    "start": "3952480",
    "end": "3960079"
  },
  {
    "text": "bonding phase but hold on a little bit so there's a two more pH we provided for",
    "start": "3960079",
    "end": "3965760"
  },
  {
    "text": "you to do some extra uh enhancement or accuracy control",
    "start": "3965760",
    "end": "3972079"
  },
  {
    "text": "the first one is called Reserve so if you take a step step back so what's the",
    "start": "3972079",
    "end": "3977880"
  },
  {
    "text": "source of truth of part scheduling and what source of choose of P dat the",
    "start": "3977880",
    "end": "3984039"
  },
  {
    "text": "source of choose is that only the part get persistent into ATD we can think",
    "start": "3984039",
    "end": "3990720"
  },
  {
    "text": "okay the part is really running there and the occupying the resources right that",
    "start": "3990720",
    "end": "3998160"
  },
  {
    "text": "means by the end of the score the part hasn't be B in yet it can fail or it can",
    "start": "3998160",
    "end": "4004880"
  },
  {
    "text": "success so in this phase to prevent to",
    "start": "4004880",
    "end": "4010599"
  },
  {
    "text": "Temporary reserve the resources but we don't know yet whether it's finally",
    "start": "4010599",
    "end": "4016079"
  },
  {
    "text": "positionist or not we should provide a reserve phase for you to reserve the C",
    "start": "4016079",
    "end": "4023119"
  },
  {
    "text": "specific chunk of resources temporary we hope in happy pass that later on the",
    "start": "4023119",
    "end": "4029039"
  },
  {
    "text": "banding will become pretty fast and then we just duplicate the the resolve",
    "start": "4029039",
    "end": "4035400"
  },
  {
    "text": "resources or if some unexpected failure happens after the war we just R back the",
    "start": "4035400",
    "end": "4041680"
  },
  {
    "text": "changes we resoled right now in the in the in the patter this pattern is pretty",
    "start": "4041680",
    "end": "4047880"
  },
  {
    "text": "pretty important because in uh declarative",
    "start": "4047880",
    "end": "4053200"
  },
  {
    "text": "patterns if we just look at the dec patterns there will be a lag",
    "start": "4053200",
    "end": "4060480"
  },
  {
    "text": "right between the part gets schedule internally to the face that the part get",
    "start": "4060480",
    "end": "4066720"
  },
  {
    "text": "persistently so there is the is the gap so we want to during the Gap we still",
    "start": "4066720",
    "end": "4073359"
  },
  {
    "text": "want to schedu in work close accurate accurately so that is why we provide the",
    "start": "4073359",
    "end": "4080880"
  },
  {
    "text": "reserve uh phase that is based on the uh this pattern okay and the permit",
    "start": "4080880",
    "end": "4088960"
  },
  {
    "text": "is also for the same purpose but it's usually a little differently so",
    "start": "4088960",
    "end": "4094039"
  },
  {
    "text": "basically permit if you look at the interface uh it returns a duration that",
    "start": "4094039",
    "end": "4100359"
  },
  {
    "text": "means in this pH we semi approve a part scheduling but return with a timeout",
    "start": "4100359",
    "end": "4107080"
  },
  {
    "text": "meaning by default is by the end of this time out if nobody",
    "start": "4107080",
    "end": "4112480"
  },
  {
    "text": "tells me I should fully approve this part or not I will reject it but within",
    "start": "4112480",
    "end": "4119278"
  },
  {
    "text": "the timeout usually a typical user case is co- scheding or gang scattering so",
    "start": "4119279",
    "end": "4126040"
  },
  {
    "text": "the sipling path of uh precedent pass we are tell the scheduler okay here we come",
    "start": "4126040",
    "end": "4133960"
  },
  {
    "text": "and we have reached the Corum finally and then all the sibling Parts should be approved within the timeout so that's a",
    "start": "4133960",
    "end": "4141318"
  },
  {
    "text": "very typical use case for for for permit use case for permit extension point but",
    "start": "4141319",
    "end": "4147359"
  },
  {
    "text": "the default entry pluging doesn't use this permit interface yet all right",
    "start": "4147359",
    "end": "4153199"
  },
  {
    "text": "after permit uh we enter the other cycle called binding Bing is pretty",
    "start": "4153199",
    "end": "4158960"
  },
  {
    "text": "straightforward it's just for performance uh consideration we put it into another go routine that means by",
    "start": "4158960",
    "end": "4165920"
  },
  {
    "text": "the end of the schedule cycle by the end of the permit the schedule will just jump right into the another cycle to",
    "start": "4165920",
    "end": "4171838"
  },
  {
    "text": "schedule the next apart and then meanwhile in another concurrent go routine it start The Binding so binding",
    "start": "4171839",
    "end": "4178920"
  },
  {
    "text": "includes three parts pre-bond so you can do some final check on whether the path",
    "start": "4178920",
    "end": "4185120"
  },
  {
    "text": "uh can be uh b b so typical use case is volum",
    "start": "4185120",
    "end": "4190318"
  },
  {
    "text": "bonding it does find some final check on the PB PVC Association and after",
    "start": "4190319",
    "end": "4196440"
  },
  {
    "text": "pre-bond is the bind bind it does nothing but binded node to the part so",
    "start": "4196440",
    "end": "4203080"
  },
  {
    "text": "uh basically you don't need to implement your own Bond Bond implementation and",
    "start": "4203080",
    "end": "4209000"
  },
  {
    "text": "after bond is poster Bond poster bond is usually for post processing or logging",
    "start": "4209000",
    "end": "4214840"
  },
  {
    "text": "for some information uh which is may be useful for your for your",
    "start": "4214840",
    "end": "4219960"
  },
  {
    "text": "scenario so this is basically the happy pass of how schedule internally Expos",
    "start": "4219960",
    "end": "4228880"
  },
  {
    "text": "the extend point for you to hook up to schedule a PA but that can be a negative",
    "start": "4228880",
    "end": "4234480"
  },
  {
    "text": "pass is that again what if no node can fit the part so there's another Rec CLE",
    "start": "4234480",
    "end": "4243000"
  },
  {
    "text": "in up is the code post filter so post filter the intention for you to",
    "start": "4243000",
    "end": "4250760"
  },
  {
    "text": "implement is that you uh do some logic like preemption to",
    "start": "4250760",
    "end": "4259159"
  },
  {
    "text": "evaluate whether you have some alternatives to make it a part schedulable like in the default",
    "start": "4259159",
    "end": "4266560"
  },
  {
    "text": "preemption it choice to sacrifice some low priority to make room for the high",
    "start": "4266560",
    "end": "4272480"
  },
  {
    "text": "priority but your implementation can be pre quite Innovative you can just invent",
    "start": "4272480",
    "end": "4280120"
  },
  {
    "text": "what kind of your logic can fit your business need like in some if I remember",
    "start": "4280120",
    "end": "4285400"
  },
  {
    "text": "corly some Community plugins needs to depend on some customer resource objects",
    "start": "4285400",
    "end": "4291280"
  },
  {
    "text": "so their logic is pretty uh customized so they have to uh reinvent the",
    "start": "4291280",
    "end": "4298159"
  },
  {
    "text": "preemption logic in the post filter so you can Implement your own so this is pretty much the uh",
    "start": "4298159",
    "end": "4306040"
  },
  {
    "text": "overall of each what each extension point is and each has a again a large",
    "start": "4306040",
    "end": "4312600"
  },
  {
    "text": "adoption in the industry like IBM and the rad has building some plugins into",
    "start": "4312600",
    "end": "4320360"
  },
  {
    "text": "their like open shift offerings so next uh chain from IBM will give us some",
    "start": "4320360",
    "end": "4327760"
  },
  {
    "text": "practical examples of how they use the schedu framework to build some",
    "start": "4327760",
    "end": "4332960"
  },
  {
    "text": "commercial plugins yeah thank you thank you way and uh for the nice uh",
    "start": "4332960",
    "end": "4339239"
  },
  {
    "text": "introduction of all the extension points and plugins and uh thank you all for",
    "start": "4339239",
    "end": "4344320"
  },
  {
    "text": "still staying with us and I know you must all be hungry but I will be quick",
    "start": "4344320",
    "end": "4350080"
  },
  {
    "text": "uh so I will introduce some use cases of using schul plugins to uh customize our",
    "start": "4350080",
    "end": "4356280"
  },
  {
    "text": "own Schuler for different um um types of workload for different classs and then",
    "start": "4356280",
    "end": "4362920"
  },
  {
    "text": "uh I will also give a short tutorial on how you can start writing your own",
    "start": "4362920",
    "end": "4368239"
  },
  {
    "text": "schedule plug-in for your particular use case so um the first use case we work on",
    "start": "4368239",
    "end": "4375320"
  },
  {
    "text": "in IBM to together with PayPal is the load Word schedular plugins so the",
    "start": "4375320",
    "end": "4381280"
  },
  {
    "text": "default kubernetes scheduler only considered the uh request and limit",
    "start": "4381280",
    "end": "4386760"
  },
  {
    "text": "request values of the part to uh place the part on the Node and then uh what it",
    "start": "4386760",
    "end": "4394639"
  },
  {
    "text": "end up with is usually your uh developers are over allocating resources",
    "start": "4394639",
    "end": "4400560"
  },
  {
    "text": "they specify very high uh uh resource for the request Val values and then um",
    "start": "4400560",
    "end": "4407560"
  },
  {
    "text": "the from the trace I show in the uh bottom right and then this is the real",
    "start": "4407560",
    "end": "4413080"
  },
  {
    "text": "Google tra and it says the request value usually set by developers as much larger",
    "start": "4413080",
    "end": "4418760"
  },
  {
    "text": "than the usage and then what it end up is is you significantly over provisioning resources for your all your",
    "start": "4418760",
    "end": "4425480"
  },
  {
    "text": "parts in the cluster and your cluster would be uh very uh low utilized and",
    "start": "4425480",
    "end": "4431840"
  },
  {
    "text": "then you cannot schedule more parts that's why we come up with this load whereare schedular plugins and then we",
    "start": "4431840",
    "end": "4438199"
  },
  {
    "text": "want to schedule Pass based on the actual usage of the node but not the allocations of resources on the Node so",
    "start": "4438199",
    "end": "4446080"
  },
  {
    "text": "there's three different plugins in this um series and then uh I will introduce",
    "start": "4446080",
    "end": "4452040"
  },
  {
    "text": "two here uh for example the first one target load plugin plugin this is a plugin we collaborate with the uh with",
    "start": "4452040",
    "end": "4459120"
  },
  {
    "text": "PayPal and it is a very simple plugins uh be what it does is it um",
    "start": "4459120",
    "end": "4465719"
  },
  {
    "text": "allow you to try to maintain a certain percentage of utilization for all nodes",
    "start": "4465719",
    "end": "4472440"
  },
  {
    "text": "in your cluster and then the benefit of it is uh you you make sure all your",
    "start": "4472440",
    "end": "4477760"
  },
  {
    "text": "notes in the cluster achieve a certain utilization and it's not",
    "start": "4477760",
    "end": "4483159"
  },
  {
    "text": "underutilized uh again and if you keep the margin with one uh minus x% then you",
    "start": "4483159",
    "end": "4489600"
  },
  {
    "text": "still have a margin safe margin for you uh for the birthday workload and then so",
    "start": "4489600",
    "end": "4495800"
  },
  {
    "text": "you get a nice balance between both the utilization and your uh performance of",
    "start": "4495800",
    "end": "4501600"
  },
  {
    "text": "the worklad and the second one is uh this is a particular IBM cluster use case we",
    "start": "4501600",
    "end": "4509000"
  },
  {
    "text": "notice that uh some parts have a very high variations on uh utilizations and",
    "start": "4509000",
    "end": "4515960"
  },
  {
    "text": "then if we place those parts together on a particular node then what happen is in",
    "start": "4515960",
    "end": "4521639"
  },
  {
    "text": "the Noe probably on average you will have a very low util ation but at certain period because the variation is",
    "start": "4521639",
    "end": "4528159"
  },
  {
    "text": "so high then uh you would have birthday workload all the performance would get",
    "start": "4528159",
    "end": "4533239"
  },
  {
    "text": "done and then you would end up with out of memory evictions of those paths and you lose the high availability and",
    "start": "4533239",
    "end": "4540920"
  },
  {
    "text": "performance so what we were doing is we were trying to balance the risk of",
    "start": "4540920",
    "end": "4546560"
  },
  {
    "text": "having part evictions of performance issues by scheduling path considering",
    "start": "4546560",
    "end": "4552040"
  },
  {
    "text": "both the average utilization on the note and the variations of the uh load on the",
    "start": "4552040",
    "end": "4557920"
  },
  {
    "text": "Node and then what it does is actually to maintain a constant value for both",
    "start": "4557920",
    "end": "4563600"
  },
  {
    "text": "the note average utilization and uh standard deviation the plus of the sum",
    "start": "4563600",
    "end": "4569760"
  },
  {
    "text": "of those so uh another use case where already introduced a lot is we we will",
    "start": "4569760",
    "end": "4576080"
  },
  {
    "text": "have a lot of like machine learning jobs training jobs spark jobs that you want",
    "start": "4576080",
    "end": "4581400"
  },
  {
    "text": "to schedule a group of paths all together uh make sure they're running at the same time and we already introduced",
    "start": "4581400",
    "end": "4589120"
  },
  {
    "text": "all of those uh uh plugin extension point and Co Cod scheduler is the uh",
    "start": "4589120",
    "end": "4596280"
  },
  {
    "text": "scheduler that utilize those extension point to make sure you have a certain",
    "start": "4596280",
    "end": "4601600"
  },
  {
    "text": "number or ratio of uh uh PS group of PS running together and then you may check",
    "start": "4601600",
    "end": "4607520"
  },
  {
    "text": "more details on this and it's widely used for spark jobs and Tor flow training",
    "start": "4607520",
    "end": "4613520"
  },
  {
    "text": "jobs so next I will uh give a very simple tutorial in just four steps and",
    "start": "4613520",
    "end": "4620560"
  },
  {
    "text": "then let's go through it uh you can scan the barcode to get the full tutorial uh",
    "start": "4620560",
    "end": "4626239"
  },
  {
    "text": "if you want to try it yourself so usually uh the first step you want to",
    "start": "4626239",
    "end": "4631600"
  },
  {
    "text": "start developing your own schedular plugin is uh go go to the schedule plug-in Ripple clone the Ripple and then",
    "start": "4631600",
    "end": "4639600"
  },
  {
    "text": "create a package for your own schedule let's take the scoring plugin for example here uh uh the the first thing",
    "start": "4639600",
    "end": "4647000"
  },
  {
    "text": "you want to do is to define the uh the plug-in uh struct like here we Define",
    "start": "4647000",
    "end": "4652400"
  },
  {
    "text": "the score by label and then this in this example we just Implement a simple scoring plugin that takes the labels",
    "start": "4652400",
    "end": "4660520"
  },
  {
    "text": "scoring value as the score uh for scheduling and then we give it a name",
    "start": "4660520",
    "end": "4665800"
  },
  {
    "text": "score by label and then uh uh you also want to define the name function to",
    "start": "4665800",
    "end": "4671760"
  },
  {
    "text": "return the name as uh part of the necessary function uh defined by the plug-in",
    "start": "4671760",
    "end": "4677679"
  },
  {
    "text": "framework and the next the The only thing the most important thing you want",
    "start": "4677679",
    "end": "4682960"
  },
  {
    "text": "to do is you want to write your own SC uh score function and in this score",
    "start": "4682960",
    "end": "4688120"
  },
  {
    "text": "function we Implement some simple Logics like reading the Noe labels get the node",
    "start": "4688120",
    "end": "4694800"
  },
  {
    "text": "label uh value as the score for your node and then uh for example if your the",
    "start": "4694800",
    "end": "4703239"
  },
  {
    "text": "scores you derived for scoring the noes is not within zero to 100 you can also",
    "start": "4703239",
    "end": "4709040"
  },
  {
    "text": "use the score extension interface and Implement a normalized score function to",
    "start": "4709040",
    "end": "4715960"
  },
  {
    "text": "normalize all your scores between zero to 100 so next you usually when you want to",
    "start": "4715960",
    "end": "4724239"
  },
  {
    "text": "develop some algorithms you want to take some input arguments to configure your",
    "start": "4724239",
    "end": "4729560"
  },
  {
    "text": "score uh plugins uh and then the way to do that is to Simply add uh for example",
    "start": "4729560",
    "end": "4735760"
  },
  {
    "text": "plugin name plus ARS in the apis uh in those folders like uh either we W beta",
    "start": "4735760",
    "end": "4743400"
  },
  {
    "text": "two or we W beta three right and then uh this score uh let's take a look at the",
    "start": "4743400",
    "end": "4749639"
  },
  {
    "text": "score by label arcs struct for example and here we want the user to be able to",
    "start": "4749639",
    "end": "4756000"
  },
  {
    "text": "configure their own uh label Keys uh that's why we put the label key as a string here and then you can also uh add",
    "start": "4756000",
    "end": "4764480"
  },
  {
    "text": "fun functions to set the default value for your uh input if it's",
    "start": "4764480",
    "end": "4770440"
  },
  {
    "text": "amazing so lastly uh uh as uh UB already",
    "start": "4770440",
    "end": "4775560"
  },
  {
    "text": "uh mentioned we can run uh the the your schedular plugins as a secondary",
    "start": "4775560",
    "end": "4780679"
  },
  {
    "text": "schedular for certain uh certain types of workload in your cluster and then the",
    "start": "4780679",
    "end": "4786320"
  },
  {
    "text": "only thing you need to configure is the uh Cube schedular configuration profile",
    "start": "4786320",
    "end": "4791719"
  },
  {
    "text": "and then here uh because we want to test the score by label plugin we just enable",
    "start": "4791719",
    "end": "4797040"
  },
  {
    "text": "it and disable all other plugins and then um the way the workloud spfy the",
    "start": "4797040",
    "end": "4803040"
  },
  {
    "text": "secondary scheduler is by the scheduler name and then here we give the name of the uh scheduler as the score by label",
    "start": "4803040",
    "end": "4810679"
  },
  {
    "text": "and then we specify the schedule name for the part next let's um try to deploy it",
    "start": "4810679",
    "end": "4822400"
  },
  {
    "text": "so here we are in a cluster with three nose uh let's remember the node ipce",
    "start": "4845480",
    "end": "4850960"
  },
  {
    "text": "with 232 2 43 253 and then we uh we don't have any workload right",
    "start": "4850960",
    "end": "4859199"
  },
  {
    "text": "now and then the first thing we want to set up is uh to test the score by label",
    "start": "4859199",
    "end": "4865000"
  },
  {
    "text": "plugging is to label the node with a certain score the key is score by",
    "start": "4865000",
    "end": "4872719"
  },
  {
    "text": "label and 2 32 we label it with 10 2 43 we label it with five and uh two FES we",
    "start": "4873280",
    "end": "4882520"
  },
  {
    "text": "label it with one and then now uh the node 232 has the highest",
    "start": "4882520",
    "end": "4888400"
  },
  {
    "text": "score and we double check if the label is already",
    "start": "4888400",
    "end": "4893800"
  },
  {
    "text": "there we can now try to deploy the score by label",
    "start": "4897960",
    "end": "4904239"
  },
  {
    "text": "scheder um using a simple deployment getting the image I already built with",
    "start": "4904239",
    "end": "4911000"
  },
  {
    "text": "together with all the RB rules available also in the schedular pluging rle and",
    "start": "4911000",
    "end": "4917960"
  },
  {
    "text": "uh we Mount the the the schedular configuration uh to the part so it take",
    "start": "4917960",
    "end": "4924840"
  },
  {
    "text": "as the uh kubernetes configo and we go ahead and deploy uh",
    "start": "4924840",
    "end": "4933639"
  },
  {
    "text": "the the score by label scheduler as the secondary",
    "start": "4933639",
    "end": "4940639"
  },
  {
    "text": "Schuler now it's running",
    "start": "4941400",
    "end": "4946040"
  },
  {
    "text": "what we do next is uh we want to go ahead to stream the the locks in another",
    "start": "4950320",
    "end": "4959840"
  },
  {
    "text": "window and then let's take a look at the testing workload which is a test part uh",
    "start": "4959840",
    "end": "4966480"
  },
  {
    "text": "it's used the score by label scheduler",
    "start": "4966480",
    "end": "4971639"
  },
  {
    "text": "and we go ahead and create the path now you can see it's um actually the",
    "start": "4971639",
    "end": "4978679"
  },
  {
    "text": "score by label plugin is already running uh the logs shows eight uh get all the",
    "start": "4978679",
    "end": "4984480"
  },
  {
    "text": "scores from different node and then the highest score is the 253 uh with the",
    "start": "4984480",
    "end": "4991360"
  },
  {
    "text": "score of 10 what it shows is it attempts to bend the partt to the no down to",
    "start": "4991360",
    "end": "4997520"
  },
  {
    "text": "three uh 232 and then it finished binding for the",
    "start": "4997520",
    "end": "5002760"
  },
  {
    "text": "part on that note and we can double check if the uh the",
    "start": "5002760",
    "end": "5010239"
  },
  {
    "text": "party successfully binded uh using the events yeah it's I say the part is",
    "start": "5010239",
    "end": "5016480"
  },
  {
    "text": "already started and it's uh successfully assigned to uh",
    "start": "5016480",
    "end": "5022040"
  },
  {
    "text": "232 and those are very useful techniques introduced by",
    "start": "5022040",
    "end": "5028040"
  },
  {
    "text": "um by way and Y for debugging",
    "start": "5028040",
    "end": "5034960"
  },
  {
    "text": "so then let's uh change the 253 node with a score uh label of of 100 now uh",
    "start": "5037199",
    "end": "5045199"
  },
  {
    "text": "253 becomes the high the scored",
    "start": "5045199",
    "end": "5049920"
  },
  {
    "text": "node and let's try to deploy the workload again and see see where it is",
    "start": "5059840",
    "end": "5067360"
  },
  {
    "text": "scheduled we first delete the part and create it",
    "start": "5075320",
    "end": "5080639"
  },
  {
    "text": "again esip a little bit",
    "start": "5083719",
    "end": "5088440"
  },
  {
    "text": "because okay we create again and this time what it happened is um it tried to",
    "start": "5091639",
    "end": "5099560"
  },
  {
    "text": "add the event for bending",
    "start": "5099560",
    "end": "5104119"
  },
  {
    "text": "um and it attempting to bind the part to",
    "start": "5105080",
    "end": "5110440"
  },
  {
    "text": "253 no surprise",
    "start": "5110440",
    "end": "5114320"
  },
  {
    "text": "right okay we double check the events and we have more events that it says um",
    "start": "5115800",
    "end": "5121560"
  },
  {
    "text": "successfully bind the power to 2553 and um please follow the tutorial on",
    "start": "5121560",
    "end": "5127679"
  },
  {
    "text": "this and uh uh I will hand it back to to",
    "start": "5127679",
    "end": "5133600"
  },
  {
    "text": "you question all",
    "start": "5135840",
    "end": "5141560"
  },
  {
    "text": "right I think this is pretty much for today's session and uh here are some",
    "start": "5141560",
    "end": "5148040"
  },
  {
    "text": "references and also on Friday there's uh six scheduling deep die so that talk we",
    "start": "5148040",
    "end": "5154800"
  },
  {
    "text": "basically talk about some latest updates both on the schedule itself and some sub",
    "start": "5154800",
    "end": "5160800"
  },
  {
    "text": "project of the six scheduling so yeah we can have a few minutes to answer",
    "start": "5160800",
    "end": "5169239"
  },
  {
    "text": "[Applause]",
    "start": "5172070",
    "end": "5175229"
  },
  {
    "text": "questions um what I'm curious about our do you all have IDE of like when you",
    "start": "5180000",
    "end": "5185280"
  },
  {
    "text": "want to take plugins and kind of merge them into like like Upstream so that",
    "start": "5185280",
    "end": "5191360"
  },
  {
    "text": "more people can use stuff like scheduling and things like that yeah so",
    "start": "5191360",
    "end": "5197320"
  },
  {
    "text": "the question was whether we have plans to move some out of tree plings to the",
    "start": "5197320",
    "end": "5203679"
  },
  {
    "text": "in tree to the core uh so it quite depends on a few",
    "start": "5203679",
    "end": "5211480"
  },
  {
    "text": "factors like how the pling itself is mature and how is widely needed by the",
    "start": "5211480",
    "end": "5219400"
  },
  {
    "text": "by the community and the last piece is the API compatibility whether it needs",
    "start": "5219400",
    "end": "5225679"
  },
  {
    "text": "to introduce a new like high level P API so I would say it's possible but it",
    "start": "5225679",
    "end": "5232719"
  },
  {
    "text": "needs to be working on Case by case there's no general principles says okay you check mark this this this and you",
    "start": "5232719",
    "end": "5239760"
  },
  {
    "text": "can push up to the to the upam but the good thing is that is totally compatible",
    "start": "5239760",
    "end": "5245440"
  },
  {
    "text": "so maybe you just have some spend some extra efforts to to just recompile that",
    "start": "5245440",
    "end": "5250639"
  },
  {
    "text": "packing into there yeah yeah go ahead right so I have a",
    "start": "5250639",
    "end": "5256719"
  },
  {
    "text": "question related to Performance uhhuh optim",
    "start": "5256719",
    "end": "5265800"
  },
  {
    "text": "around uhhuh so if I answer the question was",
    "start": "5268440",
    "end": "5273520"
  },
  {
    "text": "about per performance like uh maybe in the first round of the scheduling for",
    "start": "5273520",
    "end": "5279159"
  },
  {
    "text": "for the part one is evaluating the like part zero to 500 and then for the next",
    "start": "5279159",
    "end": "5285199"
  },
  {
    "text": "one is evaluate another round of uh pass uh sorry Nails instead your question yes",
    "start": "5285199",
    "end": "5291400"
  },
  {
    "text": "say you have say you have yeah yeah yeah",
    "start": "5291400",
    "end": "5296520"
  },
  {
    "text": "all each potentially take a long time you mhm yeah I think you are recently",
    "start": "5296520",
    "end": "5303199"
  },
  {
    "text": "have the use case in your want to talk about it you can talk offline just right time for the launch again thanks",
    "start": "5303199",
    "end": "5310440"
  },
  {
    "text": "everyone I think coming to our session particularly you staying and until the",
    "start": "5310440",
    "end": "5316000"
  },
  {
    "text": "end of the session really appreciate thank you again so yeah we'll be around so if you want to discuss",
    "start": "5316000",
    "end": "5323000"
  },
  {
    "text": "we'll be",
    "start": "5323000",
    "end": "5325480"
  }
]
[
  {
    "text": "right so everyone I'm a jaswal uh I work at reworks I am a flagger mainteno and I",
    "start": "4799",
    "end": "12300"
  },
  {
    "text": "dabble along with a few Cloud new technologies um I just graduated like a few months ago and it's my first coupon uh so I'm",
    "start": "12300",
    "end": "19080"
  },
  {
    "text": "really excited to be here and talk about I mean as low validation yeah",
    "start": "19080",
    "end": "24439"
  },
  {
    "text": "but I'm here to help I'm Kingdom Barrett I'm a open source support engineer at",
    "start": "25460",
    "end": "30720"
  },
  {
    "text": "weaveworks and also a flux maintainer and This Is Us",
    "start": "30720",
    "end": "38239"
  },
  {
    "text": "okay okay so how many of you have implemented Progressive delivery",
    "start": "38820",
    "end": "45000"
  },
  {
    "text": "clusters or you know played around with Progressive delivery like can I get a show of hands okay",
    "start": "45000",
    "end": "50879"
  },
  {
    "text": "so not not as many people are expecting actually so for those of you don't",
    "start": "50879",
    "end": "56219"
  },
  {
    "text": "understand what Progressive delivery is let me try and convince you or that you should be practicing Progressive",
    "start": "56219",
    "end": "61800"
  },
  {
    "text": "delivery in your clusters because it's a really really good thing to do so Progressive Derby is the",
    "start": "61800",
    "end": "68520"
  },
  {
    "text": "art of producing new software into your clusters in a safe and iterative manner",
    "start": "68520",
    "end": "74400"
  },
  {
    "text": "basically what you do is when you want to introduce new software into your cluster and expose it to your end",
    "start": "74400",
    "end": "80180"
  },
  {
    "text": "try and get very fine gained control over the so as soon so as to if the new version",
    "start": "80180",
    "end": "86340"
  },
  {
    "text": "is not working as expected if there are or if it breaks features the number of users that are impacted are",
    "start": "86340",
    "end": "94340"
  },
  {
    "text": "right so what do you need to implement Progressive delivery in your cluster well the first thing you need",
    "start": "96600",
    "end": "103500"
  },
  {
    "text": "the CI pipeline is required the next thing you need the continuous",
    "start": "103500",
    "end": "109619"
  },
  {
    "text": "delivery a continuous delivery system something like flux or Argo or whatever have you right something which can take",
    "start": "109619",
    "end": "115079"
  },
  {
    "text": "those artifacts that have been published by your CI Pipeline and deploy them onto your cluster",
    "start": "115079",
    "end": "121619"
  },
  {
    "text": "then you need a service measure in Ingress for traffic to traffic to come through and hit your applications right",
    "start": "121619",
    "end": "127259"
  },
  {
    "text": "and this is important because yeah you can't just use a plain old trust or IP service to you know expose your",
    "start": "127259",
    "end": "133020"
  },
  {
    "text": "applications right you need some kind of a Ingress or like a load balance solution and which in our case is a service mesh or something like Ingress",
    "start": "133020",
    "end": "140340"
  },
  {
    "text": "nginx right so and most importantly for those of our talk you need a good observability stack",
    "start": "140340",
    "end": "147360"
  },
  {
    "text": "right something which you can use get metrics and validate your slos and",
    "start": "147360",
    "end": "153360"
  },
  {
    "text": "see whether kpis are being hit for so the purpose of this thought census problem days we'll use Prometheus but you can use anything you want really",
    "start": "153360",
    "end": "161360"
  },
  {
    "text": "so there are three main ways you can do uh Progressive delivery I mean that I",
    "start": "162540",
    "end": "168120"
  },
  {
    "text": "know of at least so the first is a canary release or communities Works uh",
    "start": "168120",
    "end": "174360"
  },
  {
    "text": "based on routing traffic to different services so you have two Services your new",
    "start": "174360",
    "end": "180480"
  },
  {
    "text": "service and your old service and you shift traffic from your old service to your new service in a gradual grade",
    "start": "180480",
    "end": "186180"
  },
  {
    "text": "based manner will this is the main uh topic of our talk I'll just briefly describe the",
    "start": "186180",
    "end": "192300"
  },
  {
    "text": "other two as well so the next is Alpha Beta Testing I'm guessing this is more popular amongst",
    "start": "192300",
    "end": "197640"
  },
  {
    "text": "you guys it's a pretty old way of testing so you have some beta users and the way you",
    "start": "197640",
    "end": "203459"
  },
  {
    "text": "differentiate between those data users is because they have the traffic that they generate the request that they have uh are gonna have head on it and you use",
    "start": "203459",
    "end": "210599"
  },
  {
    "text": "headers to differentiate between your beta users uh and the last is blue game deployments",
    "start": "210599",
    "end": "218280"
  },
  {
    "text": "blue game deployments is a bit different than the other because it doesn't actually expose any uh new traffic to",
    "start": "218280",
    "end": "225060"
  },
  {
    "text": "your users so the new version is not never goes directly to your users what you do is when you have your old version",
    "start": "225060",
    "end": "231239"
  },
  {
    "text": "up and running you stand up your new version as well and then you run like load tests you know generally",
    "start": "231239",
    "end": "236480"
  },
  {
    "text": "artificially generated traffic right so using those uh tests you verify whether",
    "start": "236480",
    "end": "242640"
  },
  {
    "text": "the new version is incorrectly or not and that's how you do blue game deployments",
    "start": "242640",
    "end": "248599"
  },
  {
    "text": "I'm gonna explain this very complicated",
    "start": "248879",
    "end": "253400"
  },
  {
    "text": "and there's uh so",
    "start": "260120",
    "end": "265320"
  },
  {
    "text": "so uh as you see in version one because my mic I think my mic is uh",
    "start": "271320",
    "end": "278660"
  },
  {
    "text": "just use this one okay all right so we're going to go from version one to version two I'm gonna do",
    "start": "281240",
    "end": "287520"
  },
  {
    "text": "it progressively so in panel one we have just version one is running with two replicas",
    "start": "287520",
    "end": "293460"
  },
  {
    "text": "and Flagger is is monitoring um and in version two uh or panel two",
    "start": "293460",
    "end": "299580"
  },
  {
    "text": "we've added version two we've added a pod for version two and we've started routing some traffic to it",
    "start": "299580",
    "end": "305900"
  },
  {
    "text": "meanwhile Flagger is monitoring uh the metrics to see that everything's going okay",
    "start": "305900",
    "end": "311880"
  },
  {
    "text": "and as it seems that everything is going okay we're incrementally adding traffic",
    "start": "311880",
    "end": "317400"
  },
  {
    "text": "to the canary version two uh we go from 10 up to 50 percent",
    "start": "317400",
    "end": "323280"
  },
  {
    "text": "once we get to 50 and our metrics all still look fine we're reasonably confident at this point",
    "start": "323280",
    "end": "329340"
  },
  {
    "text": "that the release is good so we begin the promotion phase and",
    "start": "329340",
    "end": "334979"
  },
  {
    "text": "phase four here you see now we've begun a rolling update of the deployment of",
    "start": "334979",
    "end": "340680"
  },
  {
    "text": "version one so we actually have two separate deployments here if it's not clear uh diverse one deployment",
    "start": "340680",
    "end": "348320"
  },
  {
    "text": "and Flagger is taking care of that for us so in panel five now the upgrade the",
    "start": "348320",
    "end": "355740"
  },
  {
    "text": "rolling update is complete and we've shifted all the traffic to the new upgraded uh original deployment I'm",
    "start": "355740",
    "end": "364080"
  },
  {
    "text": "going to call it the primary because that's what it's called in flagger and in version six we tear down our Canary",
    "start": "364080",
    "end": "369419"
  },
  {
    "text": "pods and now all of the traffic is being served by the primary actually since panel five so",
    "start": "369419",
    "end": "376280"
  },
  {
    "text": "okay um so how many of you have heard about Flagger as a project or just like you know installed into clusters on with it",
    "start": "377400",
    "end": "383940"
  },
  {
    "text": "okay boy um so Flagger is a cncf incubating project it falls under the flux family",
    "start": "383940",
    "end": "390900"
  },
  {
    "text": "of projects flux is the guitars tool um so the entire diagram that Kingdom",
    "start": "390900",
    "end": "397139"
  },
  {
    "text": "explained right in the last slide Flagger is the communities operator which automates that entire thing so",
    "start": "397139",
    "end": "402780"
  },
  {
    "text": "right from shifting traffic incrementally to monitoring metrics all of that is automated for you by flag",
    "start": "402780",
    "end": "410580"
  },
  {
    "text": "you can see it enables you know safer releases right and one of the things which Library does really good is uh is",
    "start": "410580",
    "end": "416759"
  },
  {
    "text": "that it handles Disaster Recovery very well so if unfortunately our version 2",
    "start": "416759",
    "end": "421919"
  },
  {
    "text": "is not a working expected it has bugs or something like that uh you'd want users",
    "start": "421919",
    "end": "427080"
  },
  {
    "text": "to be shifted to the stable version ASAP right and that's what Flagger takes care",
    "start": "427080",
    "end": "432960"
  },
  {
    "text": "of so you can deploy on a Friday and be satisfied that if there's something wrong with the new version uh your end",
    "start": "432960",
    "end": "439560"
  },
  {
    "text": "users won't be impacted as much right um extensive validation right so you can",
    "start": "439560",
    "end": "444840"
  },
  {
    "text": "validate your slos right using a bunch of tools we'll use promises for the demo but yeah you can see these are",
    "start": "444840",
    "end": "451800"
  },
  {
    "text": "some of the things we support and it has an extensive webwork mechanism which you can use to run load tests and various",
    "start": "451800",
    "end": "458880"
  },
  {
    "text": "acceptance tests uh throughout every phase of the canary so that if you want to say that I want to run some different",
    "start": "458880",
    "end": "464580"
  },
  {
    "text": "tests uh at 20 of the weight and if I want to transfer different tests when uh",
    "start": "464580",
    "end": "469620"
  },
  {
    "text": "it's being when the new version has been promoted Flagger allows for that and um this is one of my favorite",
    "start": "469620",
    "end": "476340"
  },
  {
    "text": "features about Flagger it's not a feature it's more like the list of Integrations we have so we support pretty much every other Ingress service",
    "start": "476340",
    "end": "483300"
  },
  {
    "text": "mesh out there you can just see some of the logos I'm not going to go through all of them but yeah it's a pretty extensive list and we",
    "start": "483300",
    "end": "489479"
  },
  {
    "text": "also have support for Gateway API which is the new standard for uh supposed to be the new standard for networking and",
    "start": "489479",
    "end": "494940"
  },
  {
    "text": "load balancing and uh kubernetes and as more and more projects start adopting a Gateway API we are confident that we",
    "start": "494940",
    "end": "501240"
  },
  {
    "text": "will be working with all of them",
    "start": "501240",
    "end": "504259"
  },
  {
    "text": "Canary definition uh this is the uh main unit of currency of Flagger so",
    "start": "508560",
    "end": "515339"
  },
  {
    "text": "we're going to define a canary and we're going to start with some targets so we have a Target deployment and that's the",
    "start": "515339",
    "end": "522180"
  },
  {
    "text": "deployment that I mentioned before that Flagger is going to copy for us",
    "start": "522180",
    "end": "529040"
  },
  {
    "text": "and make a primary out of it we also have a service we can have an auto scaler ref the service Flagger will",
    "start": "529040",
    "end": "536820"
  },
  {
    "text": "create and we have an analysis section which is really the interesting part",
    "start": "536820",
    "end": "544019"
  },
  {
    "text": "uh so as you see we have a schedule there's an interval their threshold is kind of unfortunately",
    "start": "544019",
    "end": "551100"
  },
  {
    "text": "named this is the number of failures that are",
    "start": "551100",
    "end": "556140"
  },
  {
    "text": "in order to uh eventually land at a successful release go on the max weight is the point at",
    "start": "556140",
    "end": "564660"
  },
  {
    "text": "which we should stop and we start motion uh step weight is every five percent we",
    "start": "564660",
    "end": "571680"
  },
  {
    "text": "add and and here the metrics is really the interesting part for today because",
    "start": "571680",
    "end": "577019"
  },
  {
    "text": "we can add custom metrics here or any kind of metric so there are predefined metrics there are a couple of metrics",
    "start": "577019",
    "end": "583260"
  },
  {
    "text": "that are listed here and then there's this webhook section which is also very interesting you can use it for things",
    "start": "583260",
    "end": "589500"
  },
  {
    "text": "like inline testing and also pre-flight validation as well as load testing here",
    "start": "589500",
    "end": "596100"
  },
  {
    "text": "so right",
    "start": "596100",
    "end": "601140"
  },
  {
    "text": "um so I'm just gonna try to tie it all together and explain to you in a brief Mano how flag actually works",
    "start": "601140",
    "end": "608399"
  },
  {
    "text": "so you apply the canary object uh and Flagger is basically reconciling that Canadian object but Flagger is a bit",
    "start": "608399",
    "end": "616200"
  },
  {
    "text": "different and other it is operators in the way that um you are not continuously reconciling",
    "start": "616200",
    "end": "622500"
  },
  {
    "text": "the state right so a typical kubernetes operator would continuously reconcile the state of the cluster to match your",
    "start": "622500",
    "end": "628800"
  },
  {
    "text": "desired state right but in the case of Flagger you have certain intervals where you want to run",
    "start": "628800",
    "end": "635160"
  },
  {
    "text": "the canary release where especially more specifically when you introduce a new version or you change something in your",
    "start": "635160",
    "end": "641100"
  },
  {
    "text": "deployment uh rest of the times flaggers are sitting there idle um so the way it works is we wanted to",
    "start": "641100",
    "end": "647519"
  },
  {
    "text": "be as um as like pretty much loaded as possible",
    "start": "647519",
    "end": "652800"
  },
  {
    "text": "so that you as users don't have to do anything to do anything much so what Flagger does is you give it a",
    "start": "652800",
    "end": "659700"
  },
  {
    "text": "deployment it creates an exact deployment for you so and it names it primary deployment and then you have a",
    "start": "659700",
    "end": "666180"
  },
  {
    "text": "canary deployment so the primary deployment is a stable deployment so it's the one that you'll want your",
    "start": "666180",
    "end": "672060"
  },
  {
    "text": "users to hit all the time deployment where you are running all sorts",
    "start": "672060",
    "end": "678920"
  },
  {
    "text": "[Music] um it basically creates services for your Canadian performance and your primary",
    "start": "680550",
    "end": "685920"
  },
  {
    "text": "deployments right so all you need is to create a primary deployment",
    "start": "685920",
    "end": "690980"
  },
  {
    "text": "and Flagger will create uh will create or handle all of these other objects so what Flagger does is it seems oh I have",
    "start": "691019",
    "end": "697740"
  },
  {
    "text": "a query deployment and you know it's a new version so what I'm going to do is I'm going to scale this up and I'm going",
    "start": "697740",
    "end": "702779"
  },
  {
    "text": "to scale that up and then I'm going to use an HTTP route so HTTP route is a generic term that I've used here uh it can be anything it",
    "start": "702779",
    "end": "709500"
  },
  {
    "text": "needs to Virtual service it can be a SMR traffic split it can be a Canadian nginx right it can be anything anything which",
    "start": "709500",
    "end": "716519"
  },
  {
    "text": "can distribute traffic um to uh to different Services can be considered an HTTP route",
    "start": "716519",
    "end": "722519"
  },
  {
    "text": "so what flag what Flagler does is it orchestrases HTTP route to basically Route traffic based on weights to to",
    "start": "722519",
    "end": "729600"
  },
  {
    "text": "these two different right and what it does is check the metrics based on those metric",
    "start": "729600",
    "end": "736560"
  },
  {
    "text": "validation it will you know Drive the analysis forward um so this in a nutshell how Flagger works we'll understand more when we see",
    "start": "736560",
    "end": "743519"
  },
  {
    "text": "the demo okay I'm going to talk about this section",
    "start": "743519",
    "end": "748620"
  },
  {
    "text": "um these are metrics in prom ql you've probably seen something like this before if you're here at Prometheus day",
    "start": "748620",
    "end": "755940"
  },
  {
    "text": "um just to point out on the left this is a metric for nginx",
    "start": "755940",
    "end": "761220"
  },
  {
    "text": "and it has a namespace and a Target interval setting we're looking for a",
    "start": "761220",
    "end": "767399"
  },
  {
    "text": "latency under a particular number so it has this by Le that means less than or equal and on the right we have another",
    "start": "767399",
    "end": "774839"
  },
  {
    "text": "metric this one is for error rate it looks a little bit different",
    "start": "774839",
    "end": "780120"
  },
  {
    "text": "I'm not going to go into too much detail about this because like I said you've probably seen things like this before",
    "start": "780120",
    "end": "785160"
  },
  {
    "text": "but this one is um out of a hundred percent so we're",
    "start": "785160",
    "end": "790920"
  },
  {
    "text": "multiplying by 100 after we divide the numerator by the denominator numerator",
    "start": "790920",
    "end": "796500"
  },
  {
    "text": "is successful requests that are not in the 500 range and then the denominator is the number",
    "start": "796500",
    "end": "803880"
  },
  {
    "text": "of total requests so",
    "start": "803880",
    "end": "807380"
  },
  {
    "text": "that's mine too also so this is a metric template and we're going to take",
    "start": "811680",
    "end": "817320"
  },
  {
    "text": "advantage of one of our definitions that we've just written so here we're plugging our not found percentage so",
    "start": "817320",
    "end": "824940"
  },
  {
    "text": "actually we'd like to redefine uh the error code we'd like to say we're really",
    "start": "824940",
    "end": "829980"
  },
  {
    "text": "interested in 404s we don't want there to be 404s in our release so um we're just going to go ahead and make",
    "start": "829980",
    "end": "836579"
  },
  {
    "text": "this not found percentage metric template and we can plug it in to Flagger this might be useful if you have",
    "start": "836579",
    "end": "843060"
  },
  {
    "text": "like a JavaScript application that is actually serverless and uh really the",
    "start": "843060",
    "end": "848220"
  },
  {
    "text": "404 is the only bat the only signal that you get from it maybe or there could be other reasons why you want to do",
    "start": "848220",
    "end": "853680"
  },
  {
    "text": "something like this but uh that's the main event here",
    "start": "853680",
    "end": "859279"
  },
  {
    "text": "this kind of this this object is basically the products of how a flagger",
    "start": "860839",
    "end": "867000"
  },
  {
    "text": "you know validates metrics so if you see here you have um a type and an address right in the",
    "start": "867000",
    "end": "873839"
  },
  {
    "text": "metric template object and this is how you can have multiple different observability Stacks running in parallel",
    "start": "873839",
    "end": "880740"
  },
  {
    "text": "and you can use all of them and basically have a very complex uh you know mechanism on how you want to",
    "start": "880740",
    "end": "886620"
  },
  {
    "text": "promote new versions in your in your cluster and this is how you attach a metric",
    "start": "886620",
    "end": "892380"
  },
  {
    "text": "template to a canary object and then you have this whole way of where you can say you know if you so in our case we don't want the",
    "start": "892380",
    "end": "899699"
  },
  {
    "text": "not found percentage to be more than five percent right and that every one every one minute plug is gonna check or",
    "start": "899699",
    "end": "906180"
  },
  {
    "text": "you know uh like so not flag is gonna check that whether the fire",
    "start": "906180",
    "end": "912740"
  },
  {
    "text": "component as well so like if you have a",
    "start": "914760",
    "end": "918740"
  },
  {
    "text": "okay okay good so if latency is a big concern uh in your so you can have something like a latency",
    "start": "921959",
    "end": "929459"
  },
  {
    "text": "okay okay so latency is like a",
    "start": "929459",
    "end": "933860"
  },
  {
    "text": "H you can have a latency template which would say something like I don't want",
    "start": "935820",
    "end": "940920"
  },
  {
    "text": "the latency to be more than 500 milliseconds something like that it's very accessible and like it's it's sky's",
    "start": "940920",
    "end": "946260"
  },
  {
    "text": "the limit on how you want to do that okay um I'm gonna talk about a rather new",
    "start": "946260",
    "end": "953339"
  },
  {
    "text": "software called cater how many of you have heard about cater just like for sure okay that's that's",
    "start": "953339",
    "end": "960180"
  },
  {
    "text": "a problem so Keda is um if I were to give it a tagline I would say it's it's HPA on steroids",
    "start": "960180",
    "end": "965880"
  },
  {
    "text": "um so it's like a more advanced HPA version uh HPA thing",
    "start": "965880",
    "end": "970940"
  },
  {
    "text": "it's into it can get events from it can run queries on and based on the based on those metrics or whatever events it gets",
    "start": "974100",
    "end": "980160"
  },
  {
    "text": "it can scale up or down uh deployments and it can also work for jobs",
    "start": "980160",
    "end": "985940"
  },
  {
    "text": "can be instrumented with Prometheus right so if it's an instrument deployment cada will scale those metrics",
    "start": "993300",
    "end": "999240"
  },
  {
    "text": "right and uh uh metrics and based on that uh Prometheus",
    "start": "999240",
    "end": "1006440"
  },
  {
    "text": "uh can expose those metrics right and uh based on those metrics kada will scale the deployments so this is a more",
    "start": "1006440",
    "end": "1013040"
  },
  {
    "text": "powerful version of how you can do uh scaling than HP is so we just wanted to highlight that because when you are",
    "start": "1013040",
    "end": "1018500"
  },
  {
    "text": "doing testing um load testing can also be a very very important factor and uh",
    "start": "1018500",
    "end": "1024558"
  },
  {
    "text": "if you if you only have like one deployment running for your Canary uh it's your work you're more likely to run",
    "start": "1024559",
    "end": "1031040"
  },
  {
    "text": "into memory or errors or something like that because it won't split with Google contents real world conditions we have",
    "start": "1031040",
    "end": "1037520"
  },
  {
    "text": "Auto scaling enabled to you know cope with",
    "start": "1037520",
    "end": "1042039"
  },
  {
    "text": "you know Argo setup like a git Ops tool setup um if you specify the replicas field in",
    "start": "1043360",
    "end": "1049100"
  },
  {
    "text": "a deployment that's just a recipe for disaster you should never do that in case you're doing that don't do that never do that because that can lead to",
    "start": "1049100",
    "end": "1056179"
  },
  {
    "text": "all sorts of problems so you should always have a scalar or Auto scalar setup",
    "start": "1056179",
    "end": "1061299"
  },
  {
    "text": "okay so just to go back quickly to the diagram it's pretty much the same diagram but there's a new addition",
    "start": "1061880",
    "end": "1068120"
  },
  {
    "text": "there's a new component in the diagram which is see that Prometheus is like really",
    "start": "1068120",
    "end": "1073580"
  },
  {
    "text": "driving everything here right if you remove Prometheus Flagger will not be able to determine whether your version 2",
    "start": "1073580",
    "end": "1078860"
  },
  {
    "text": "is performing expected or not it won't be able to increase the time okay and Keda won't be able to scale the",
    "start": "1078860",
    "end": "1084620"
  },
  {
    "text": "deployment if the parameters is not working Prometheus is Prometheus or any other observability tool is very very",
    "start": "1084620",
    "end": "1091039"
  },
  {
    "text": "essential to how you uh Implement Progressive delivery in your clusters",
    "start": "1091039",
    "end": "1096440"
  },
  {
    "text": "okay so it's demo dying",
    "start": "1096440",
    "end": "1100659"
  },
  {
    "text": "we're going to start with a preview of something",
    "start": "1110660",
    "end": "1114700"
  },
  {
    "text": "foreign mission to show this off because it",
    "start": "1120200",
    "end": "1125539"
  },
  {
    "text": "shows very well how Flagger works so",
    "start": "1125539",
    "end": "1130519"
  },
  {
    "text": "yeah hi thanks I need to do a quick port forward oh",
    "start": "1136280",
    "end": "1142280"
  },
  {
    "text": "it's already forwarded that's good",
    "start": "1142280",
    "end": "1145539"
  },
  {
    "text": "and I'm going to need to switch this to https and start my port forward again",
    "start": "1147740",
    "end": "1153860"
  },
  {
    "text": "because I made a mistake",
    "start": "1153860",
    "end": "1156940"
  },
  {
    "text": "so we're going to go to the delivery tab this is the piece that you won't get on we've get Ops",
    "start": "1165860",
    "end": "1171919"
  },
  {
    "text": "um the free version open source uh but uh we can see we have a canary",
    "start": "1171919",
    "end": "1177200"
  },
  {
    "text": "here and we can see that it's in a failed state which means it's rolled back from",
    "start": "1177200",
    "end": "1183320"
  },
  {
    "text": "a previous attempt to upgrade we have a list of objects that the",
    "start": "1183320",
    "end": "1188780"
  },
  {
    "text": "canary is aware of and we can see things like the deployment primary and Canary",
    "start": "1188780",
    "end": "1194360"
  },
  {
    "text": "so here's our primary and here's our Canary so when we do the upgrade we'll see this one kick into action",
    "start": "1194360",
    "end": "1201799"
  },
  {
    "text": "and we have a list of events and we can see that our we have defined a custom",
    "start": "1201799",
    "end": "1207260"
  },
  {
    "text": "metric here as well one of the built-in ones so all right and there's a yaml view",
    "start": "1207260",
    "end": "1214900"
  },
  {
    "text": "so we're going to try and upgrade now",
    "start": "1215179",
    "end": "1218919"
  },
  {
    "text": "all right what I'm doing here I'm just changing the image out so we're going to",
    "start": "1228559",
    "end": "1233660"
  },
  {
    "text": "deploy pod info again with a new image we'll we'll see pod info is running here",
    "start": "1233660",
    "end": "1240160"
  },
  {
    "text": "hotinfo.demo.test here so we can see",
    "start": "1241000",
    "end": "1246100"
  },
  {
    "text": "and we're just going to kick flux here we're going to tell it to reconcile immediately so we don't have to wait for",
    "start": "1259880",
    "end": "1264980"
  },
  {
    "text": "this part and this is normally where I would go into the terminal and pull up the canary",
    "start": "1264980",
    "end": "1272179"
  },
  {
    "text": "but since we've received permission to show our Flagger UI we can see",
    "start": "1272179",
    "end": "1277820"
  },
  {
    "text": "here oh",
    "start": "1277820",
    "end": "1284200"
  },
  {
    "text": "doing right now is it's creating the",
    "start": "1287539",
    "end": "1292000"
  },
  {
    "text": "so you we have two ingresses one is a one is handling the",
    "start": "1293000",
    "end": "1298120"
  },
  {
    "text": "uh it's basically uh configuring the engine to traffic to the",
    "start": "1298880",
    "end": "1305780"
  },
  {
    "text": "primary and right now it's protecting",
    "start": "1305780",
    "end": "1311299"
  },
  {
    "text": "so here five percent of 95 traffic to the primary Department",
    "start": "1311299",
    "end": "1319220"
  },
  {
    "text": "right if if you were to simulate a real condition five percent of your users would be experiencing",
    "start": "1319220",
    "end": "1327159"
  },
  {
    "text": "and all this while uh trying to check whether the subbing met so there is what",
    "start": "1329360",
    "end": "1335539"
  },
  {
    "text": "we have in on you here is there a load tester that's running trying to simulate real right and that's how uh we're trying to",
    "start": "1335539",
    "end": "1342320"
  },
  {
    "text": "show that when when we have like different",
    "start": "1342320",
    "end": "1347799"
  },
  {
    "text": "Flagger will automatically validate all this metrics for you so right now it's trying to validate those and",
    "start": "1350600",
    "end": "1356620"
  },
  {
    "text": "the traffic for you so we have a little",
    "start": "1356900",
    "end": "1362200"
  },
  {
    "text": "right so the reason for that um",
    "start": "1368240",
    "end": "1372880"
  },
  {
    "text": "that will progress and what we want what we want to see here is that it eventually it boards because",
    "start": "1375220",
    "end": "1382899"
  },
  {
    "text": "will requests go through to the new um Canary",
    "start": "1385840",
    "end": "1392740"
  },
  {
    "text": "idios is really limited of our misconfiguration right so so if you were to assume that this",
    "start": "1393679",
    "end": "1401320"
  },
  {
    "text": "version only five percent of the traffic uh five percent",
    "start": "1401419",
    "end": "1406299"
  },
  {
    "text": "which is a good thing as opposed to if you're",
    "start": "1407000",
    "end": "1411520"
  },
  {
    "text": "switch okay",
    "start": "1417440",
    "end": "1421360"
  },
  {
    "text": "yeah yeah okay let me know what's visible what's not is",
    "start": "1433120",
    "end": "1438919"
  },
  {
    "text": "the sign okay okay that's",
    "start": "1438919",
    "end": "1444799"
  },
  {
    "text": "nice um uh an audible or do any this might",
    "start": "1444799",
    "end": "1451580"
  },
  {
    "text": "okay cool um so here we have a metric template which defines the latency uh based on",
    "start": "1451580",
    "end": "1457520"
  },
  {
    "text": "istio workloads so I have a istio virtual service up and running right um so this basically defines that we we",
    "start": "1457520",
    "end": "1464299"
  },
  {
    "text": "want this recipe calculates the latency for every request that comes in right and this is our scaled object",
    "start": "1464299",
    "end": "1472760"
  },
  {
    "text": "so this is what cada uses to scale or scale your deployments so it's pretty simple we say that we",
    "start": "1472760",
    "end": "1479720"
  },
  {
    "text": "want to scale the product for deployment uh 10 seconds what's happening uh we want",
    "start": "1479720",
    "end": "1487340"
  },
  {
    "text": "at least one replica running at all times and we want a maximum radicals of three and this is how you configure you",
    "start": "1487340",
    "end": "1493039"
  },
  {
    "text": "to listen to Prometheus so you say I want to listen to a Prometheus server and this is where it's located at and",
    "start": "1493039",
    "end": "1498500"
  },
  {
    "text": "this is the query I want to run and this is the Threshold at which I want to start scaling up my deployments pretty",
    "start": "1498500",
    "end": "1503720"
  },
  {
    "text": "simple right so let's uh let's go to the canary",
    "start": "1503720",
    "end": "1510820"
  },
  {
    "text": "okay so here we have a canary uh it's pretty simple as we explained earlier as",
    "start": "1511039",
    "end": "1516080"
  },
  {
    "text": "well as it goes very quickly so we say that we want to run the check every 15 seconds uh we want to we want a maximum",
    "start": "1516080",
    "end": "1523340"
  },
  {
    "text": "15 failure checks before we decide that you know it's time to roll back this is a bad version and we want to take a 10 steps or",
    "start": "1523340",
    "end": "1531799"
  },
  {
    "text": "steplades basically that which means that uh we want to increase the traffic by 10 every 15 seconds",
    "start": "1531799",
    "end": "1537740"
  },
  {
    "text": "and we want to do that until we reach a 50 uh traffic uh split into The Canal at which point we can say that uh our new",
    "start": "1537740",
    "end": "1544159"
  },
  {
    "text": "version is working perfectly right so",
    "start": "1544159",
    "end": "1550158"
  },
  {
    "text": "pod info this is the canary version this is the beta version this is the primary",
    "start": "1557659",
    "end": "1563059"
  },
  {
    "text": "version both of them are 6.2.1 right both of them are at 6.2.1 and this is",
    "start": "1563059",
    "end": "1568820"
  },
  {
    "text": "right now a zero replicas it's not it's not working so what I'm gonna do is I'm gonna",
    "start": "1568820",
    "end": "1575059"
  },
  {
    "text": "change the version to 0.6.0.2 to the of the canary deployment so this is simulating a change in our introducing a",
    "start": "1575059",
    "end": "1581900"
  },
  {
    "text": "new software into our clusters okay so what's happening is that we have a",
    "start": "1581900",
    "end": "1588620"
  },
  {
    "text": "virtual service here right",
    "start": "1588620",
    "end": "1593840"
  },
  {
    "text": "okay so this virtual service is shifting traffic based on what Flagger",
    "start": "1593840",
    "end": "1599059"
  },
  {
    "text": "is doing a quick watch here",
    "start": "1599059",
    "end": "1605139"
  },
  {
    "text": "right so right now 100 of traffic is going to the primary and zero percent of traffic is going to the canary right so",
    "start": "1618860",
    "end": "1624799"
  },
  {
    "text": "if we look at what uh Flagger is doing is that now we have our pod info",
    "start": "1624799",
    "end": "1630440"
  },
  {
    "text": "deployment has been scaled up from zero replicas to one replica so now flywheel is going to start spending some sending",
    "start": "1630440",
    "end": "1635600"
  },
  {
    "text": "some traffic to the canary version right",
    "start": "1635600",
    "end": "1639880"
  },
  {
    "text": "right so 10 of the traffic is going to the canary service and 90 traffic is going to the primary service right and",
    "start": "1644299",
    "end": "1650059"
  },
  {
    "text": "in the background Flagger is checking the metrics based on the Prometheus server and seeing whether everything is",
    "start": "1650059",
    "end": "1655700"
  },
  {
    "text": "working fine or not so we can see that as well uh let me put forward",
    "start": "1655700",
    "end": "1661240"
  },
  {
    "text": "yeah yeah",
    "start": "1661900",
    "end": "1665860"
  },
  {
    "text": "right so we can see here so we have something called uh red Matrix and use metrics I'm guessing this is prom ql so",
    "start": "1678020",
    "end": "1684740"
  },
  {
    "text": "most of you are familiar with what red and used metrics are in case you're not uh red basically calculates like you",
    "start": "1684740",
    "end": "1690559"
  },
  {
    "text": "know stuff like requests latency error rate and use calculates CPU usage memory",
    "start": "1690559",
    "end": "1695960"
  },
  {
    "text": "usage bandwidth Etc so as you can see here some so some traffic is going to the primary and some",
    "start": "1695960",
    "end": "1702260"
  },
  {
    "text": "graph is going to Canary but you can see primary is getting more such traffic compared to the canary because 90 of",
    "start": "1702260",
    "end": "1707539"
  },
  {
    "text": "traffic is going to the primary and 10 traffic is going to the canary and these metrics are being validated by by",
    "start": "1707539",
    "end": "1712940"
  },
  {
    "text": "Flagger in the background so that when these when these metrics are you know like uh properly validated",
    "start": "1712940",
    "end": "1718940"
  },
  {
    "text": "Flagger will start shifting more traffic to the canary and that's gonna keep happening until we reach a point where 50 of traffic is two percent traffic",
    "start": "1718940",
    "end": "1727340"
  },
  {
    "text": "and at that point we can we can be satisfied with our new version and we can say that this is this version works",
    "start": "1727340",
    "end": "1733220"
  },
  {
    "text": "fine foreign",
    "start": "1733220",
    "end": "1738640"
  },
  {
    "text": "what's going on I'm going to exit exec into a port",
    "start": "1742039",
    "end": "1747460"
  },
  {
    "text": "right so here you can see that we Canadian deployment and efficient so the",
    "start": "1756980",
    "end": "1762980"
  },
  {
    "text": "primary deployment right so it's it depends on the weights are configured so so like if we keep doing it",
    "start": "1762980",
    "end": "1770539"
  },
  {
    "text": "uh we're heading the primary deployment right but if I keep doing it I keep doing it now I have the Canadian",
    "start": "1770539",
    "end": "1775640"
  },
  {
    "text": "deployment right the new version so this is what your users are experiencing",
    "start": "1775640",
    "end": "1780679"
  },
  {
    "text": "um if you want to enable some kind of a sticky session thing uh that is being worked on uh actually it's like there's",
    "start": "1780679",
    "end": "1787220"
  },
  {
    "text": "a PR open right now which I'm working on support to this as well so that if if",
    "start": "1787220",
    "end": "1792380"
  },
  {
    "text": "you have if you have a use case some kind of a legacy application where if a user Falls",
    "start": "1792380",
    "end": "1797419"
  },
  {
    "text": "onto the new application you don't want them to go to go back that is",
    "start": "1797419",
    "end": "1803179"
  },
  {
    "text": "you want to do this you can do this using a b testing you can just have headers for your beta users but then you",
    "start": "1803179",
    "end": "1809720"
  },
  {
    "text": "don't get this Progressive delivery step uh it'll just be all your beta users in one go",
    "start": "1809720",
    "end": "1815480"
  },
  {
    "text": "right so just thank you so I'm gonna get out of here I'm gonna",
    "start": "1815480",
    "end": "1821360"
  },
  {
    "text": "do a quick get of the canary and it says it's promoting",
    "start": "1821360",
    "end": "1826700"
  },
  {
    "text": "right now so right now 50 traffic went to the",
    "start": "1826700",
    "end": "1831100"
  },
  {
    "text": "this version works great so what I'm gonna do is I'm gonna take the new version the Canadian deployment 6.0.2",
    "start": "1836919",
    "end": "1842899"
  },
  {
    "text": "and I'm going to tell primary to be at 6.0.2 which was at 6.0.1 previously so",
    "start": "1842899",
    "end": "1848179"
  },
  {
    "text": "by now we should be done we are done we're almost done so we'll just do a quick uh watch on the deployments",
    "start": "1848179",
    "end": "1856419"
  },
  {
    "text": "and one thing which I couldn't really show you during the demo is if you see memory is at three replicas right now",
    "start": "1865279",
    "end": "1871460"
  },
  {
    "text": "right but when we started uh it was at one replica and that is due to uh the",
    "start": "1871460",
    "end": "1877220"
  },
  {
    "text": "scaled object that we defined so Keda noticed that traffic is being generated to the Pod info deployments and based on",
    "start": "1877220",
    "end": "1883700"
  },
  {
    "text": "that the replicas got scaled up to three and if you see here both part info and both part in for primary is at 6.0.2",
    "start": "1883700",
    "end": "1890539"
  },
  {
    "text": "right but the Pod info scale to 0 to 0 replicas right so all the traffic right now is going to the primary deployment",
    "start": "1890539",
    "end": "1897260"
  },
  {
    "text": "and we can validate that by looking at the virtual Service as well",
    "start": "1897260",
    "end": "1901840"
  },
  {
    "text": "right so all so 45 primary has 100 of the weight and what if the community has zero percent of the weight",
    "start": "1903620",
    "end": "1909260"
  },
  {
    "text": "right so this basically shows like this demo was meant to show you how you can promote a new promote a new version",
    "start": "1909260",
    "end": "1916279"
  },
  {
    "text": "safely in your production clusters by shifting traffic gradually and you know like now we can say that all all our 100",
    "start": "1916279",
    "end": "1923779"
  },
  {
    "text": "of the users are experiencing the primary version and we can be more confident about that yeah so that's it",
    "start": "1923779",
    "end": "1929720"
  },
  {
    "text": "for the demo um thanks for coming guys thanks very much for your attention",
    "start": "1929720",
    "end": "1935980"
  },
  {
    "text": "excellent job sanskar",
    "start": "1936140",
    "end": "1939460"
  },
  {
    "text": "oh we do I told people over time I wonder quick I was I was I was running through it fast because I thought I was",
    "start": "1941360",
    "end": "1947059"
  },
  {
    "text": "voting do we have oh okay thanks everyone",
    "start": "1947059",
    "end": "1952940"
  },
  {
    "text": "thanks everyone uh yeah and sorry about the technical the activities let's talk uh so yeah in",
    "start": "1952940",
    "end": "1960500"
  },
  {
    "text": "two minutes we'll uh talk about run book automation systems for Prometheus and kubernetes",
    "start": "1960500",
    "end": "1966980"
  },
  {
    "text": "sorry yeah so if there are any questions they are still here and and are happy to answer them after afterwards",
    "start": "1966980",
    "end": "1975039"
  },
  {
    "text": "all right thank you and sorry again",
    "start": "1976520",
    "end": "1980200"
  }
]
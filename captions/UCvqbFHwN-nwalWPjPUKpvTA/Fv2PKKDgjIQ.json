[
  {
    "text": "and thank you everyone for being here so there's been a switch in the room so if you're looking for the security session",
    "start": "60",
    "end": "6509"
  },
  {
    "text": "it's in g2 and well here in g1 it's the multi cluster toolbox so multi cluster",
    "start": "6509",
    "end": "15440"
  },
  {
    "text": "some of you may wonder why anyone would need multiple clusters dealing with one",
    "start": "15440",
    "end": "20789"
  },
  {
    "text": "is hard enough but if you're in this room you probably have an idea and this",
    "start": "20789",
    "end": "28470"
  },
  {
    "text": "question has been answered multiple times so today I won't be focusing so much on the why rather on the how how we",
    "start": "28470",
    "end": "36239"
  },
  {
    "text": "solve multi cluster problems so just",
    "start": "36239",
    "end": "41489"
  },
  {
    "text": "picture multiple teams working with multiple clouds multiple data centers",
    "start": "41489",
    "end": "47160"
  },
  {
    "text": "and multiple regions problems problems are bound to happen so the tools that",
    "start": "47160",
    "end": "56820"
  },
  {
    "text": "we'll introduce in this talk our lessons learned for a months of research at Admiralty a company I founded through",
    "start": "56820",
    "end": "63059"
  },
  {
    "text": "research this domain space and offer solutions but I won't talk about those",
    "start": "63059",
    "end": "68180"
  },
  {
    "text": "products in this talk so why not just",
    "start": "68180",
    "end": "73799"
  },
  {
    "text": "use cube fed cube fed for those of you who don't know is the new name of the Federation v2 project they renamed the",
    "start": "73799",
    "end": "79590"
  },
  {
    "text": "repository last week and in some situations it's a very valid response",
    "start": "79590",
    "end": "85140"
  },
  {
    "text": "it's a yes if your views case you know matches so what does Federation v2 solve",
    "start": "85140",
    "end": "92780"
  },
  {
    "text": "it solves a problem where you have a central cluster and you want to do",
    "start": "92780",
    "end": "98400"
  },
  {
    "text": "top-down resource declaration so you want to define declaratively your infra",
    "start": "98400",
    "end": "107040"
  },
  {
    "text": "your resources across your Federation from one cluster and you can do that by",
    "start": "107040",
    "end": "113369"
  },
  {
    "text": "decomposing your problem into templates that is basically you want to deploy for",
    "start": "113369",
    "end": "121710"
  },
  {
    "text": "example deployment here into multiple clusters with like this basic template",
    "start": "121710",
    "end": "127530"
  },
  {
    "text": "and then you define placement which is a list of cluster names or cluster selector because",
    "start": "127530",
    "end": "133499"
  },
  {
    "text": "clusters are customer resources information and over eyes if you want",
    "start": "133499",
    "end": "140549"
  },
  {
    "text": "some variations so in this example there are just more replicas in close to true",
    "start": "140549",
    "end": "145889"
  },
  {
    "text": "than cluster one but not all multi cluster problems are can be solved with",
    "start": "145889",
    "end": "152730"
  },
  {
    "text": "Federation there are plenty of application examples of multi cluster we",
    "start": "152730",
    "end": "160680"
  },
  {
    "text": "don't have time to you know go through this list and discuss it but feel free",
    "start": "160680",
    "end": "166409"
  },
  {
    "text": "to you give it a look read them and I'm sure some of these will resonate with some of you so but",
    "start": "166409",
    "end": "178459"
  },
  {
    "text": "download off-the-shelf solutions to solve these problems the tools are",
    "start": "178459",
    "end": "185669"
  },
  {
    "text": "missing but what kind of tools what are we trying to build so just like to build",
    "start": "185669",
    "end": "193889"
  },
  {
    "text": "a shelf you know you need some tools and well you know you want to build a shelf",
    "start": "193889",
    "end": "198989"
  },
  {
    "text": "but you do you know what you want to build when you think about multi cluster and what I think we need is just like",
    "start": "198989",
    "end": "206479"
  },
  {
    "text": "controllers are solutions to many problem in kubernetes that's how humanities works weed Multi cluster",
    "start": "206479",
    "end": "213629"
  },
  {
    "text": "controllers and so what is missing to create multi cluster controllers is a",
    "start": "213629",
    "end": "219659"
  },
  {
    "text": "way to watch and reconcile resources in different clusters say you have a high",
    "start": "219659",
    "end": "226769"
  },
  {
    "text": "level API in one cluster and some either communities or other custom api's and",
    "start": "226769",
    "end": "234569"
  },
  {
    "text": "another and I want to reconcile them but if I delete an object in one cluster",
    "start": "234569",
    "end": "240000"
  },
  {
    "text": "I want the dependent resources to be deleted in the other cluster and we don't have garbage collection across clusters and finally if you've tried a",
    "start": "240000",
    "end": "248549"
  },
  {
    "text": "few multi cluster solutions out there it's it's usually pretty difficult to",
    "start": "248549",
    "end": "255060"
  },
  {
    "text": "set up there's a you need to generate queue configs and store them in secrets",
    "start": "255060",
    "end": "260789"
  },
  {
    "text": "load them or there is a custom CLI that you have to use and run an inn relative command and so that it'd be",
    "start": "260789",
    "end": "267830"
  },
  {
    "text": "nice if there was a declarative bootstrapping for those things so the",
    "start": "267830",
    "end": "276050"
  },
  {
    "text": "generalized solutions to these problems have are packaged in some of Admiralty's",
    "start": "276050",
    "end": "281510"
  },
  {
    "text": "open-source projects like multi cluster controller and multi cluster service account Multi cluster controller is in a",
    "start": "281510",
    "end": "288530"
  },
  {
    "text": "way sort of a multiplexer version of the controller runtime project which is an official humanities project that",
    "start": "288530",
    "end": "294770"
  },
  {
    "text": "basically drives queue builder or the operator operator SDK and a multi",
    "start": "294770",
    "end": "301070"
  },
  {
    "text": "cluster service account is a way to as a system of controllers that imports in Odum at odd amounts service accounts",
    "start": "301070",
    "end": "308150"
  },
  {
    "text": "from other clusters into pods of a local cluster but actually we won't see a lot",
    "start": "308150",
    "end": "315860"
  },
  {
    "text": "of multi cluster controller in this talk I thought it would be more instructive if we built a multi cluster controller",
    "start": "315860",
    "end": "321260"
  },
  {
    "text": "from scratch and so we're gonna start with the sample controller project some",
    "start": "321260",
    "end": "327710"
  },
  {
    "text": "of you are familiar with it it's a sort of the like a an example project that",
    "start": "327710",
    "end": "336110"
  },
  {
    "text": "you can use you can fork it vendor it and create your own controller from it and what does it do so it's it's it's",
    "start": "336110",
    "end": "345530"
  },
  {
    "text": "it's an example right so there's a high level API in this project that's called foo and when you create a foo object",
    "start": "345530",
    "end": "353690"
  },
  {
    "text": "then a nginx server deployment is created with some parameters and so some",
    "start": "353690",
    "end": "363200"
  },
  {
    "text": "people like to have higher-level api's for their users so that they don't have to figure out all the details of you",
    "start": "363200",
    "end": "369200"
  },
  {
    "text": "know how to deploy this thing yeah so uh let's let's try it",
    "start": "369200",
    "end": "377710"
  },
  {
    "text": "so there will be some live coding live demonstration and I don't want to waste",
    "start": "378430",
    "end": "384500"
  },
  {
    "text": "your time so I'm getting a lot of I'm gonna do a lot of copy pasting I mean also a shameless slow typer so beef",
    "start": "384500",
    "end": "395810"
  },
  {
    "text": "before you can create a few object you have to declare a custom resource and",
    "start": "395810",
    "end": "401330"
  },
  {
    "text": "for that there is a custom resource definition this big enough for people in the back so so yes I'll try one like",
    "start": "401330",
    "end": "413659"
  },
  {
    "text": "this and so this is a very simple custom resource definition that has nothing of",
    "start": "413659",
    "end": "420319"
  },
  {
    "text": "the advanced features that you should use like validation and other things so",
    "start": "420319",
    "end": "425870"
  },
  {
    "text": "but we don't need that for the purpose of this talk so so we're going to create",
    "start": "425870",
    "end": "435740"
  },
  {
    "text": "it in cluster one of four information I just tested them before this demo I've traded three clusters in gke that I'm",
    "start": "435740",
    "end": "442909"
  },
  {
    "text": "going to use for purpose of this talk and they are associated with cluster 0 cluster 1 and cluster 2 context in my",
    "start": "442909",
    "end": "451039"
  },
  {
    "text": "cube config and I also extracted individual cube config files in a specific folder as a convenience you'll",
    "start": "451039",
    "end": "459529"
  },
  {
    "text": "see why so I mean cluster 1 I create the CR D and then so I checked out the code I",
    "start": "459529",
    "end": "469610"
  },
  {
    "text": "mean just a few tweaks it's really very very similar to a sample controller in master in origin and so yeah I just",
    "start": "469610",
    "end": "479089"
  },
  {
    "text": "added a plug-in for GCP login and things like that so this controller is running",
    "start": "479089",
    "end": "488740"
  },
  {
    "text": "in another terminal I can create a fruit object which is",
    "start": "488949",
    "end": "496860"
  },
  {
    "text": "this one it's just an example the nginx deployment will be called example foo",
    "start": "496860",
    "end": "502620"
  },
  {
    "text": "and we'll have one replica let's see if",
    "start": "502620",
    "end": "509340"
  },
  {
    "text": "the deployment was created yes what does it look like it's an engine X deployment",
    "start": "509340",
    "end": "519590"
  },
  {
    "text": "and we can update it with true replicas",
    "start": "519590",
    "end": "526790"
  },
  {
    "text": "and you can see that the deployment has been updated down on to replicas and the",
    "start": "540270",
    "end": "545910"
  },
  {
    "text": "usual you know the usual controller loops things so when you delete the deployment you want you want it to be",
    "start": "545910",
    "end": "554130"
  },
  {
    "text": "recreated because the food object still exists that means as a user you want",
    "start": "554130",
    "end": "559190"
  },
  {
    "text": "constantly to be a deployment with the same name so if something that deletes",
    "start": "559190",
    "end": "565200"
  },
  {
    "text": "that deployment they should be recreated recreated it's nice also to in a control",
    "start": "565200",
    "end": "572459"
  },
  {
    "text": "loop to update the status of the owning resource and so here in the in the few",
    "start": "572459",
    "end": "577709"
  },
  {
    "text": "objects we see that there are indeed two available replicas and it's also nice",
    "start": "577709",
    "end": "584190"
  },
  {
    "text": "for the user to broadcast events and so in the sample control project their",
    "start": "584190",
    "end": "590880"
  },
  {
    "text": "events are broadcasted when there are errors or the sync loop it was",
    "start": "590880",
    "end": "595920"
  },
  {
    "text": "successful and finally if you delete the owning object which is the fruit object",
    "start": "595920",
    "end": "601620"
  },
  {
    "text": "you want the deployment to disappear to DB delete it that is using a garbage",
    "start": "601620",
    "end": "609000"
  },
  {
    "text": "collection all right so we want to",
    "start": "609000",
    "end": "615500"
  },
  {
    "text": "transform this sample controller project and make it multi cluster so I'm gonna start with by changing a few things and",
    "start": "615500",
    "end": "623100"
  },
  {
    "text": "basically watching foo in one cluster and deployments in another cluster and",
    "start": "623100",
    "end": "629990"
  },
  {
    "text": "at the same time I'm kind of combining a few steps here um I also in this example",
    "start": "629990",
    "end": "637320"
  },
  {
    "text": "I want all those nginx deployments to be deployed in the same namespace in that",
    "start": "637320",
    "end": "642540"
  },
  {
    "text": "different cluster I don't want the namespaces too much it makes sense in a",
    "start": "642540",
    "end": "648060"
  },
  {
    "text": "single cluster to want to the owner dependent relationship to only exists within a single namespace but across",
    "start": "648060",
    "end": "654390"
  },
  {
    "text": "clusters not necessarily so that I can deploy that foo object which could be",
    "start": "654390",
    "end": "661380"
  },
  {
    "text": "you know like oh I need a database in that database is in so I mean clustering",
    "start": "661380",
    "end": "669050"
  },
  {
    "text": "aks and I want a database but my software needs you DynamoDB and so I declare foo and so in",
    "start": "669050",
    "end": "679200"
  },
  {
    "text": "in the other cluster we can deploy a sorry in cluster 0 here we apply all",
    "start": "679200",
    "end": "687149"
  },
  {
    "text": "those common resources central resources from you know like this in the end of",
    "start": "687149",
    "end": "693360"
  },
  {
    "text": "this at the end of this talk out there will be a second step where I we can define and declare those who resources",
    "start": "693360",
    "end": "700260"
  },
  {
    "text": "from any cluster they're all connected to close to 0 and cluster 0 runs all",
    "start": "700260",
    "end": "705450"
  },
  {
    "text": "those dependencies in the same namespace",
    "start": "705450",
    "end": "709640"
  },
  {
    "text": "so but if we want to do that we have to understand how a controller works and so",
    "start": "710600",
    "end": "716720"
  },
  {
    "text": "this is a this is a diagram from the sample controller projects documentation",
    "start": "716720",
    "end": "722880"
  },
  {
    "text": "it was actually originally published in cloud ARC's blog and so it was nice of the data to contributed to the project",
    "start": "722880",
    "end": "730649"
  },
  {
    "text": "and because it's a great way to explain controllers so how does the controller",
    "start": "730649",
    "end": "736950"
  },
  {
    "text": "work in just a few minutes usually create a set of informers in indexers",
    "start": "736950",
    "end": "746519"
  },
  {
    "text": "and reflector so like whining former index for reflector from a factory you",
    "start": "746519",
    "end": "751589"
  },
  {
    "text": "create one yet there's one created per resource they can be shared if you have",
    "start": "751589",
    "end": "757110"
  },
  {
    "text": "multiple controllers running in the same process for aptitude so that's the way to optimize API calls and so the",
    "start": "757110",
    "end": "766350"
  },
  {
    "text": "reflector just lists and watches objects from the kubernetes api which are cuban",
    "start": "766350",
    "end": "772410"
  },
  {
    "text": "ATIS verbs and the informer listens to those changes caches there is the the",
    "start": "772410",
    "end": "779130"
  },
  {
    "text": "objects in using the indexer so that all the gets and lists that you need to use",
    "start": "779130",
    "end": "787110"
  },
  {
    "text": "in your code are optimized they don't always call the API they don't they use",
    "start": "787110",
    "end": "792120"
  },
  {
    "text": "the cache and your controller can subscribe to changes and that's where",
    "start": "792120",
    "end": "800040"
  },
  {
    "text": "the controller does and the controller sees some change like a deployment was",
    "start": "800040",
    "end": "805050"
  },
  {
    "text": "created if you object what's updated anything deleted and used a key in a",
    "start": "805050",
    "end": "812760"
  },
  {
    "text": "work queue that key is what we call the reconstruction and it's important to have the same key for the objects that",
    "start": "812760",
    "end": "819870"
  },
  {
    "text": "you need to reconcile so usually in a single cluster what we do is the is that",
    "start": "819870",
    "end": "825959"
  },
  {
    "text": "we define the key as name space plus name that is a unique way to identify an",
    "start": "825959",
    "end": "833040"
  },
  {
    "text": "object in kubernetes and so if we want to reconcile a few object with a",
    "start": "833040",
    "end": "838920"
  },
  {
    "text": "dependent deployment object so with foo we just say okay let's take your name space on your name that's your key with",
    "start": "838920",
    "end": "844620"
  },
  {
    "text": "the deployment we need to know what the owners name and name space are and for",
    "start": "844620",
    "end": "850920"
  },
  {
    "text": "that we can rely on owner references and so an owner reference is that is a",
    "start": "850920",
    "end": "858440"
  },
  {
    "text": "identification of the owner here at foo object called example foo and the unique identifier note that there is no",
    "start": "858440",
    "end": "865260"
  },
  {
    "text": "namespace in here because in kubernetes we assume that owner dependent relationships are only exist in",
    "start": "865260",
    "end": "870690"
  },
  {
    "text": "namespaces yeah and finally we process the items",
    "start": "870690",
    "end": "876899"
  },
  {
    "text": "and so there's a there here's where you put your business logic it actually often looks the same it's a it's the",
    "start": "876899",
    "end": "883769"
  },
  {
    "text": "usual control loop where you you have a key for that key namespace name you get if you get the own owning object in this",
    "start": "883769",
    "end": "891060"
  },
  {
    "text": "case that's a very common pattern for higher-level api's and so you get the",
    "start": "891060",
    "end": "897209"
  },
  {
    "text": "foo object if it's possible they doesn't exist anymore because in the meantime it",
    "start": "897209",
    "end": "902819"
  },
  {
    "text": "was leaden between the time it was changed was noticed and the time the",
    "start": "902819",
    "end": "908550"
  },
  {
    "text": "controller processes the the key in the work queue first of all it's disappeared well garbage garbage collection won't",
    "start": "908550",
    "end": "915180"
  },
  {
    "text": "take you up the deployment we're good but if so if we find the foo object we",
    "start": "915180",
    "end": "920880"
  },
  {
    "text": "need to make sure that it has a deployment so if it's not if we don't find the deployment mean it means needs",
    "start": "920880",
    "end": "926910"
  },
  {
    "text": "to be created so here is the it could mean that the deployment has been deleted it could mean that it's never",
    "start": "926910",
    "end": "933420"
  },
  {
    "text": "been created yet we actually don't really care because this is a level based algorithm we care about this the",
    "start": "933420",
    "end": "940170"
  },
  {
    "text": "state the current of the world and what we want it to be and so if we find it it has to be",
    "start": "940170",
    "end": "947400"
  },
  {
    "text": "up-to-date if not we updated in any case it's a good practice to update the status of the owning object and",
    "start": "947400",
    "end": "953460"
  },
  {
    "text": "broadcast some events so yeah it's uh",
    "start": "953460",
    "end": "961820"
  },
  {
    "text": "let's try to to a change sample controller to do this like you have",
    "start": "961880",
    "end": "968330"
  },
  {
    "text": "deployments created in a different cluster in the fruiting space all the time so I'm going to check out a code",
    "start": "968330",
    "end": "979620"
  },
  {
    "text": "change I will I will push this branch to",
    "start": "979620",
    "end": "988260"
  },
  {
    "text": "a repository after the talk so you guys can read redo the same things on your",
    "start": "988260",
    "end": "994860"
  },
  {
    "text": "own if you want oh I already built it",
    "start": "994860",
    "end": "1000200"
  },
  {
    "text": "sorry so build to manage the the manager to the current state let's see let's see",
    "start": "1000200",
    "end": "1007280"
  },
  {
    "text": "what what I did here in the code I won't go into too many details but down so many changes actually so in uh in this",
    "start": "1007280",
    "end": "1015230"
  },
  {
    "text": "first change I was a little naive I may",
    "start": "1015230",
    "end": "1022370"
  },
  {
    "text": "have broken things we'll see and so just this controller this manager has a cube",
    "start": "1022370",
    "end": "1030230"
  },
  {
    "text": "confits that QQ config flag to be run out of cluster and so I just added one which I use to create a different",
    "start": "1030230",
    "end": "1037280"
  },
  {
    "text": "kubernetes configuration in code now use that configuration to create a client and an informer Factory and in the",
    "start": "1037280",
    "end": "1047600"
  },
  {
    "text": "controller I just replaced every where we needed to create a deployment updated",
    "start": "1047600",
    "end": "1055280"
  },
  {
    "text": "deployment delete no we don't delete because we rely on garbage collection and anytime we need to do things with",
    "start": "1055280",
    "end": "1062180"
  },
  {
    "text": "deployments I replaced the using the foo namespace with a constant the foo",
    "start": "1062180",
    "end": "1067340"
  },
  {
    "text": "namespace instead and that's it that's all I did let's see if it works",
    "start": "1067340",
    "end": "1074760"
  },
  {
    "text": "I said I wouldn't waste your time",
    "start": "1123440",
    "end": "1126879"
  },
  {
    "text": "and what just happened",
    "start": "1133740",
    "end": "1138408"
  },
  {
    "text": "all right so",
    "start": "1142690",
    "end": "1145919"
  },
  {
    "text": "see if the next step works",
    "start": "1147750",
    "end": "1151460"
  },
  {
    "text": "it's Prime with my cute config alright never mind I'm gonna like say my",
    "start": "1165979",
    "end": "1177779"
  },
  {
    "text": "messages first and we'll try to go back to it a little later so this had worked",
    "start": "1177779",
    "end": "1187830"
  },
  {
    "text": "it actually wouldn't work properly like I'm just here I'm just not able to run it but I should be able to run it and",
    "start": "1187830",
    "end": "1193769"
  },
  {
    "text": "what so in the example I touch hopefully you can do later or we can do later you",
    "start": "1193769",
    "end": "1201960"
  },
  {
    "text": "create a you create a few object and Wow",
    "start": "1201960",
    "end": "1207419"
  },
  {
    "text": "the dearies deployment in the few namespace in the other cluster so you're happy but a few things don't work for",
    "start": "1207419",
    "end": "1214379"
  },
  {
    "text": "example events are not broadcasted the when you delete the deployment in the",
    "start": "1214379",
    "end": "1222659"
  },
  {
    "text": "few name space it is not recreated and if you delete the foo object the",
    "start": "1222659",
    "end": "1229469"
  },
  {
    "text": "deployment is not deleted so garbage collection doesn't work and the the way to figure out what the owner is of a",
    "start": "1229469",
    "end": "1238229"
  },
  {
    "text": "deployment doesn't work either and so to fix that we we need to enhance the owner",
    "start": "1238229",
    "end": "1244649"
  },
  {
    "text": "reference the owner reference only provides information about the name of an object but should also in our case",
    "start": "1244649",
    "end": "1251249"
  },
  {
    "text": "for multi cluster say what namespace in the other class area did what Nate what",
    "start": "1251249",
    "end": "1258629"
  },
  {
    "text": "namespace the owner is in and also what cluster in this case we still have just",
    "start": "1258629",
    "end": "1264899"
  },
  {
    "text": "one cluster that has contains the Foo objects and the next step needed another",
    "start": "1264899",
    "end": "1271879"
  },
  {
    "text": "enhancement and garbage collection doesn't work so why does garbage",
    "start": "1271879",
    "end": "1278639"
  },
  {
    "text": "collection not work there are so I'd step back a little bit there are three",
    "start": "1278639",
    "end": "1286919"
  },
  {
    "text": "modes of deletion in kubernetes which are either orphan the dependence so you",
    "start": "1286919",
    "end": "1293460"
  },
  {
    "text": "just leave them be say I if I delete the owning object foo",
    "start": "1293460",
    "end": "1299110"
  },
  {
    "text": "I want to keep the deployment in place but just remove the owner reference orphan it what you want cascade",
    "start": "1299110",
    "end": "1307179"
  },
  {
    "text": "cascading deletion which is what if I delete the full object my intention is",
    "start": "1307179",
    "end": "1312789"
  },
  {
    "text": "to also delete the deployment and so this can be done either in the background or in the foreground and that",
    "start": "1312789",
    "end": "1319090"
  },
  {
    "text": "is done by the garbage collection controller the garbage collection controller is a generic kubernetes",
    "start": "1319090",
    "end": "1324309"
  },
  {
    "text": "controller that maintains a graph of owner dependent relationships and is",
    "start": "1324309",
    "end": "1331659"
  },
  {
    "text": "when it detects that so it listens to basically all resources and when say a",
    "start": "1331659",
    "end": "1340059"
  },
  {
    "text": "food object is deleted it will check the dependency graph and see that oh that",
    "start": "1340059",
    "end": "1347860"
  },
  {
    "text": "deployment needs to be deleted I'll delete it and so that can be done in the background so when you delete foo it",
    "start": "1347860",
    "end": "1354249"
  },
  {
    "text": "disappears right away and the deployment is deleted just a few seconds later or immediately and Vince called faster",
    "start": "1354249",
    "end": "1362320"
  },
  {
    "text": "cluster runs and or in the foreground so how does that work he uses finalized",
    "start": "1362320",
    "end": "1368950"
  },
  {
    "text": "errs so in the foreground that when you want to delete in the foreground the",
    "start": "1368950",
    "end": "1374559"
  },
  {
    "text": "foreground that means you don't want the owning object the foo object in our case to disappear until all of its dependence",
    "start": "1374559",
    "end": "1381730"
  },
  {
    "text": "your just the deployment have been deleted as well and so the garbage",
    "start": "1381730",
    "end": "1386820"
  },
  {
    "text": "collection controller does that by adding a finalizer to the to an owning resource when it's",
    "start": "1386820",
    "end": "1396460"
  },
  {
    "text": "deleted this example is actually a deployment if you deleted a deployment",
    "start": "1396460",
    "end": "1403720"
  },
  {
    "text": "you would want the replica set to be deleted as well and cascading to the pods and so when you delete the",
    "start": "1403720",
    "end": "1410740"
  },
  {
    "text": "deployment deletion time stamp is added but also a foreground deletion and when the garbage collection controller is",
    "start": "1410740",
    "end": "1416889"
  },
  {
    "text": "done deleting all the dependents it removes the finalizer and finally deletes the owning object well from in",
    "start": "1416889",
    "end": "1427240"
  },
  {
    "text": "our case is that we have two clusters each has its own garbage collection controller and they",
    "start": "1427240",
    "end": "1434980"
  },
  {
    "text": "don't agree they basically each have their own representation of of owner",
    "start": "1434980",
    "end": "1440980"
  },
  {
    "text": "dependent relationships and only in their own clusters they don't communicate so they're unable they don't",
    "start": "1440980",
    "end": "1446380"
  },
  {
    "text": "know what a multi cluster owner references so we could and I'm actually",
    "start": "1446380",
    "end": "1452680"
  },
  {
    "text": "working on one create a multi cluster garbage collection controller that is generic and we could have a multi",
    "start": "1452680",
    "end": "1460360"
  },
  {
    "text": "cluster owner reference that actually is something that exists in multi cluster controller but the solution in this",
    "start": "1460360",
    "end": "1468370"
  },
  {
    "text": "example is actually what I call poor-man's in controller garbage",
    "start": "1468370",
    "end": "1475600"
  },
  {
    "text": "collection using finalized errs basically in our in our control loop we're going to add a finalizer right",
    "start": "1475600",
    "end": "1481870"
  },
  {
    "text": "when the object is created and before any of its dependents are created to",
    "start": "1481870",
    "end": "1488020"
  },
  {
    "text": "avoid any race condition if if a foo exists it cannot have dependents the",
    "start": "1488020",
    "end": "1496330"
  },
  {
    "text": "dependents unless it has a finalizer that way when we delete the foo object",
    "start": "1496330",
    "end": "1502900"
  },
  {
    "text": "we'll be sure to delete manually or like not not only automatically in our",
    "start": "1502900",
    "end": "1508270"
  },
  {
    "text": "control loop but like custom code deletes the dependents before we remove",
    "start": "1508270",
    "end": "1513610"
  },
  {
    "text": "the finalized the finalizer so this is a like in in the in our sink handler in",
    "start": "1513610",
    "end": "1521440"
  },
  {
    "text": "the controller we implement basically a decision tree based on observations so",
    "start": "1521440",
    "end": "1529840"
  },
  {
    "text": "is the true object terminated does have a deletion timestamp if it doesn't I",
    "start": "1529840",
    "end": "1535900"
  },
  {
    "text": "mean is still alive and first things first make sure it has a finalizer and then go back to our control from the",
    "start": "1535900",
    "end": "1546310"
  },
  {
    "text": "very beginning is the deployment found no created is that today no updated things like that I for clarity I removed",
    "start": "1546310",
    "end": "1554620"
  },
  {
    "text": "I didn't loop back with update status broadcast events but you still need that",
    "start": "1554620",
    "end": "1561570"
  },
  {
    "text": "so if it but if it's terminating in so kind of typically at the end of the",
    "start": "1561570",
    "end": "1568000"
  },
  {
    "text": "lifecycle but remember that the lifecycle is not the same thing as your",
    "start": "1568000",
    "end": "1574810"
  },
  {
    "text": "logic in your sink handler because we're edge based sorry well level pace note",
    "start": "1574810",
    "end": "1581500"
  },
  {
    "text": "edge based and so it's so if the deployment is found we need to delete it",
    "start": "1581500",
    "end": "1588400"
  },
  {
    "text": "if the foo object is terminating and if not what that means we're ready to remove the finalizer we do that and then",
    "start": "1588400",
    "end": "1596050"
  },
  {
    "text": "we can just rely on our single cluster garbage collection controller to remove the foo object in this second example I",
    "start": "1596050",
    "end": "1608640"
  },
  {
    "text": "added a cluster to the mix so like I said earlier and so this example should",
    "start": "1610860",
    "end": "1619860"
  },
  {
    "text": "should work better because I'm running it in cluster the first example was running out of cluster from my laptop",
    "start": "1619860",
    "end": "1626580"
  },
  {
    "text": "using cube config files one of them apparently has been tampered with so in",
    "start": "1626580",
    "end": "1634450"
  },
  {
    "text": "this example I will deploy a pod in a cluster 0 this is where we want to run",
    "start": "1634450",
    "end": "1641050"
  },
  {
    "text": "our controller we want to run it in this example in the central cluster 0 and if",
    "start": "1641050",
    "end": "1647650"
  },
  {
    "text": "we wanted to watch all the clusters 1 2 however many you want and see if when",
    "start": "1647650",
    "end": "1655600"
  },
  {
    "text": "they create foo object make sure that we create the deployments that they need so",
    "start": "1655600",
    "end": "1664110"
  },
  {
    "text": "how does a pod call the kubernetes api of its own cluster first well it has a",
    "start": "1664110",
    "end": "1673300"
  },
  {
    "text": "service account when you create a service account the service account",
    "start": "1673300",
    "end": "1678820"
  },
  {
    "text": "controller creates a secret in the same namespace with a token to call the API and the token is auto mounted and auto",
    "start": "1678820",
    "end": "1688900"
  },
  {
    "text": "mounted in the pod when it is admitted and",
    "start": "1688900",
    "end": "1694530"
  },
  {
    "text": "germinate his clients like client go decline girl library know how to load",
    "start": "1694610",
    "end": "1700000"
  },
  {
    "text": "the token file that has been mounted mounted as a volume and so always good",
    "start": "1700000",
    "end": "1708620"
  },
  {
    "text": "now you can extract actually the token from that secret and create an equivalent",
    "start": "1708620",
    "end": "1715210"
  },
  {
    "text": "queue config file and is what people usually do when they do multi cluster of",
    "start": "1715210",
    "end": "1720890"
  },
  {
    "text": "things so you take that token you put it here in the user and then you take the",
    "start": "1720890",
    "end": "1727159"
  },
  {
    "text": "the druvan anus api of that cluster and add some like names to know where to",
    "start": "1727159",
    "end": "1734630"
  },
  {
    "text": "find things and then store that in a secret so it's a bit of a pain but it",
    "start": "1734630",
    "end": "1741080"
  },
  {
    "text": "works so here is a example of an installation procedure for sto multi",
    "start": "1741080",
    "end": "1748610"
  },
  {
    "text": "cluster with VPN connectivity and so run all these bash scripts and extract that extract this create that it works but",
    "start": "1748610",
    "end": "1757970"
  },
  {
    "text": "it's it's it's a pain point I believe so",
    "start": "1757970",
    "end": "1763870"
  },
  {
    "text": "what I suggest is a decorative way to do",
    "start": "1763870",
    "end": "1771830"
  },
  {
    "text": "this to import a service account from another cluster and so Multi cluster",
    "start": "1771830",
    "end": "1778850"
  },
  {
    "text": "service account comes with a Ciardi called service account import and a",
    "start": "1778850",
    "end": "1783950"
  },
  {
    "text": "service account import is simply a cluster name namespace and name of a service account and most cluster service",
    "start": "1783950",
    "end": "1790549"
  },
  {
    "text": "account controller takes care of finding that secret in the other cluster",
    "start": "1790549",
    "end": "1795850"
  },
  {
    "text": "importing it and then if your namespace",
    "start": "1795850",
    "end": "1801470"
  },
  {
    "text": "enables it at admission pods that are annotated with those service account",
    "start": "1801470",
    "end": "1809600"
  },
  {
    "text": "import names will see those tokens as cube config files are amounted in a non",
    "start": "1809600",
    "end": "1817070"
  },
  {
    "text": "robot in an own folder so that then you're Cuban it is client library like",
    "start": "1817070",
    "end": "1825200"
  },
  {
    "text": "client go or I think the Python library does that although maybe I shouldn't I say that",
    "start": "1825200",
    "end": "1832520"
  },
  {
    "text": "because I haven't used it but most humanities client libraries know how to use cube config files because that's",
    "start": "1832520",
    "end": "1838880"
  },
  {
    "text": "what you use when in development when you're just dealing with your clusters that you create it and so you can just",
    "start": "1838880",
    "end": "1847100"
  },
  {
    "text": "use your code as usual but wait some of",
    "start": "1847100",
    "end": "1852950"
  },
  {
    "text": "you may think how does multi cluster service account import those tokens from",
    "start": "1852950",
    "end": "1858410"
  },
  {
    "text": "the other clusters right once the chicken and egg problem you get to start somewhere and so I believe that if you",
    "start": "1858410",
    "end": "1866900"
  },
  {
    "text": "install multi cluster service account you do that brute bootstrapping process once where the custom CLI but then all",
    "start": "1866900",
    "end": "1874340"
  },
  {
    "text": "of your other multi placer controllers can use the declarative API of distributes account import so you don't",
    "start": "1874340",
    "end": "1880460"
  },
  {
    "text": "have to do that ever again so it probably wasn't a rooster or the urn",
    "start": "1880460",
    "end": "1887270"
  },
  {
    "text": "fertilized eggs by the way let's write let's write a demo of that",
    "start": "1887270",
    "end": "1894520"
  },
  {
    "text": "so I'm going to check out my code add a different tag and they see because it",
    "start": "1905370",
    "end": "1913860"
  },
  {
    "text": "just adds an example and I'm going to deploy those stacks and so I have a",
    "start": "1913860",
    "end": "1919830"
  },
  {
    "text": "cluster n stack and a cluster 0 stack what's in what's in cluster 1 and",
    "start": "1919830",
    "end": "1925770"
  },
  {
    "text": "cluster 2 we have a custom resource definition for few objects we do create",
    "start": "1925770",
    "end": "1932340"
  },
  {
    "text": "a foo namespace even though it will not contain any deployments it's just a way",
    "start": "1932340",
    "end": "1937410"
  },
  {
    "text": "to host a service account that is allowed to list watch get update the",
    "start": "1937410",
    "end": "1944700"
  },
  {
    "text": "fool objects and creative X and it's so",
    "start": "1944700",
    "end": "1950280"
  },
  {
    "text": "there is our back rules for that in cluster zero which is our central cluster in this example we have a",
    "start": "1950280",
    "end": "1958380"
  },
  {
    "text": "namespace that will host all the nginx deployments and the service account that",
    "start": "1958380",
    "end": "1965400"
  },
  {
    "text": "is allowed to list watch guy create those deployments some binding for that",
    "start": "1965400",
    "end": "1972570"
  },
  {
    "text": "and in here our true service account imports to import that other service",
    "start": "1972570",
    "end": "1978600"
  },
  {
    "text": "account from all the dependent federated",
    "start": "1978600",
    "end": "1983900"
  },
  {
    "text": "as a general term clusters and finally a very simple deployments for the",
    "start": "1983900",
    "end": "1990540"
  },
  {
    "text": "controller that is annotated so I can import those service accounts in a way",
    "start": "1990540",
    "end": "1996090"
  },
  {
    "text": "to I just call the the with the same",
    "start": "1996090",
    "end": "2002090"
  },
  {
    "text": "arguments that I used in the previous demo so you configured it from this",
    "start": "2002090",
    "end": "2008290"
  },
  {
    "text": "folder where Admiralty serves the counting port usually puts tokens",
    "start": "2008290",
    "end": "2015520"
  },
  {
    "text": "[Music] okay yeah it's almost done",
    "start": "2021380",
    "end": "2029630"
  },
  {
    "text": "it's actually a good thing that first demo didn't work because we wouldn't have had time for this so so I applied",
    "start": "2035160",
    "end": "2046289"
  },
  {
    "text": "those tax to cluster one cluster to four cluster n then I'm installing a multi",
    "start": "2046289",
    "end": "2052108"
  },
  {
    "text": "class of service account in cluster 0 and then bootstrapping with a custom CLI cluster 1 cluster 2",
    "start": "2052109",
    "end": "2059250"
  },
  {
    "text": "these two steps you should only do them for your first months of cluster setup",
    "start": "2059250",
    "end": "2065550"
  },
  {
    "text": "if you create more multi cluster controllers you don't have to do this your clusters are already well well",
    "start": "2065550",
    "end": "2072419"
  },
  {
    "text": "known to each other and they can import tokens from each other",
    "start": "2072419",
    "end": "2077240"
  },
  {
    "text": "[Music] so when once it's bootstrap I can",
    "start": "2078239",
    "end": "2084658"
  },
  {
    "text": "finally install the multi cluster controller in cluster 0 I create the",
    "start": "2084659",
    "end": "2095669"
  },
  {
    "text": "example foo in cluster 1 in a different example called bar in cluster 2 and",
    "start": "2095669",
    "end": "2102180"
  },
  {
    "text": "cluster 0 you can see that our deployments have been created that's",
    "start": "2102180",
    "end": "2109880"
  },
  {
    "text": "that's it for the demo so in short we create the created this custom multi",
    "start": "2109880",
    "end": "2116250"
  },
  {
    "text": "cluster controller system using cross cluster control loops cross cluster",
    "start": "2116250",
    "end": "2122069"
  },
  {
    "text": "garbage collection and decorative bootstrapping which are the common ingredients at the",
    "start": "2122069",
    "end": "2127140"
  },
  {
    "text": "core of these projects now many examples and I be curious to hear about yours",
    "start": "2127140",
    "end": "2132770"
  },
  {
    "text": "because just just so many things we need to do with multiple clusters and so",
    "start": "2132770",
    "end": "2140010"
  },
  {
    "text": "here's how you can connect with me if you want in some links to the different",
    "start": "2140010",
    "end": "2145700"
  },
  {
    "text": "projects I've talked about either from Admiralty multi just a controller",
    "start": "2145700",
    "end": "2151230"
  },
  {
    "text": "service accounting scheduler which I actually barely mentioned it solves two of the things in that list of examples",
    "start": "2151230",
    "end": "2157940"
  },
  {
    "text": "and then some of the official projects that I mentioned - yeah and if we have",
    "start": "2157940",
    "end": "2165960"
  },
  {
    "text": "time for questions I'll be happy to answer a few [Applause]",
    "start": "2165960",
    "end": "2176989"
  }
]
[
  {
    "text": "good afternoon um welcome to a session my name is Olivia T I'm a principal",
    "start": "1160",
    "end": "7080"
  },
  {
    "text": "research scientist at IBM research and today I'm joined by yeah hi I'm y I'm the staff research scientist at IBM",
    "start": "7080",
    "end": "14440"
  },
  {
    "text": "research and this afternoon we're going to talk about uh large language models and how we can try to better understand",
    "start": "14440",
    "end": "21080"
  },
  {
    "text": "how they perform right these these problems comes from essentially what we've observed on our clusters right",
    "start": "21080",
    "end": "28119"
  },
  {
    "text": "like I'm sure many of you we've observed that GP utilization is not as good as we' like it to be right and when we look",
    "start": "28119",
    "end": "34200"
  },
  {
    "text": "at the reasons for that there's a number of reasons one is you know how do you get your cud kernel to perform as as",
    "start": "34200",
    "end": "39879"
  },
  {
    "text": "well as we would like but the other one is simply that people don't quite know how to share gpus right they know how to",
    "start": "39879",
    "end": "46079"
  },
  {
    "text": "share GP maybe in time uh this is not good maybe in time because you know I",
    "start": "46079",
    "end": "51520"
  },
  {
    "text": "run for five minutes you run for five minutes and so on but when they have long running workloads and these",
    "start": "51520",
    "end": "56600"
  },
  {
    "text": "workloads don't quite require an entire GPU we don't really have the mechanisms and the mental model yes to do this",
    "start": "56600",
    "end": "63800"
  },
  {
    "text": "sharing so um there are really two problems there the first one is that act",
    "start": "63800",
    "end": "69720"
  },
  {
    "text": "as of today kubernetes doesn't really help sharing gpus right and the second one is people don't really know how much",
    "start": "69720",
    "end": "75759"
  },
  {
    "text": "of a GPU they need for their workloads right because again we have not really started this process of trying to",
    "start": "75759",
    "end": "81640"
  },
  {
    "text": "understand how much we need and internalize as we have for CPU and memory consumption and and and these kind of things so in in in the platform",
    "start": "81640",
    "end": "90439"
  },
  {
    "text": "side of things in fact we already had a talk on Tuesday at the cloud Aid where we describ how we're trying to make it easier on kubernetes to share gpus so",
    "start": "90439",
    "end": "97720"
  },
  {
    "text": "I'm I'm not really going to Touch Too Much on that today what we're here to talk about is how do we know how much of",
    "start": "97720",
    "end": "105560"
  },
  {
    "text": "uh uh how big a piece of a GPU how much of a fraction of a GPU we need to run a particular Model A large language model",
    "start": "105560",
    "end": "113280"
  },
  {
    "text": "uh and an INF server on on a particular GPU so uh to briefly to to the talk I'm",
    "start": "113280",
    "end": "120479"
  },
  {
    "text": "going to tell you a little bit more about the motivation why why why is it not entirely trivial to know how the per",
    "start": "120479",
    "end": "126520"
  },
  {
    "text": "the the system is going a large language model is going to perform I'll briefly touch on how we can go after GPU",
    "start": "126520",
    "end": "132680"
  },
  {
    "text": "fractioning I should mention here that this is the technique we're going to use in the demo but fundamentally the the",
    "start": "132680",
    "end": "139720"
  },
  {
    "text": "the modeling the the the profiling approach we're discussing here has nothing to do with the particulars of how we're going to fraction GPU you",
    "start": "139720",
    "end": "146040"
  },
  {
    "text": "could use that with other fractioning techniques and then way will you know",
    "start": "146040",
    "end": "151200"
  },
  {
    "text": "walk you through the the details the math how we're going after understanding this performance and finally I'll bring",
    "start": "151200",
    "end": "157400"
  },
  {
    "text": "all of these back to kubernetes showing you how we can take an estimator a predictor and you know turn this into a",
    "start": "157400",
    "end": "163360"
  },
  {
    "text": "tool that we use on the kubernetes cluster to automatically uh scale and size a large language model",
    "start": "163360",
    "end": "171200"
  },
  {
    "text": "deployments so motivation um so really",
    "start": "171200",
    "end": "176640"
  },
  {
    "text": "fundamentally uh we have model when we say large language models you know foundational models we have all kinds of",
    "start": "176640",
    "end": "182080"
  },
  {
    "text": "sizes yes we have model we have models in the uh you know hundreds or billions",
    "start": "182080",
    "end": "188280"
  },
  {
    "text": "of parameters if you were at the cas serve talk just before they were talking about doing uh multi- noes uh model",
    "start": "188280",
    "end": "194840"
  },
  {
    "text": "serving that's not what we're going after here we have but we also have relatively small models like Lama 3.2",
    "start": "194840",
    "end": "201440"
  },
  {
    "text": "models that have just came out right and so if these models are are small enough uh given the size the the memory the",
    "start": "201440",
    "end": "208159"
  },
  {
    "text": "amount of memory we get in GPU these days which is in tens of gigabytes but now we have models in in just gigabytes",
    "start": "208159",
    "end": "215000"
  },
  {
    "text": "uh we should be able to squeeze and and and and use a a single GPU to run multiple models at the same time the",
    "start": "215000",
    "end": "222200"
  },
  {
    "text": "challenge of course is you know this is not just about memory or or you know memory capacity and that's the graph",
    "start": "222200",
    "end": "229080"
  },
  {
    "text": "that is on the right and that's what essentially we're going to try to explain in great details today right but as we squeeze a model to smaller and",
    "start": "229080",
    "end": "236000"
  },
  {
    "text": "smaller fraction of a GPU that's what you see from the curve going from the right to the left here where you know if",
    "start": "236000",
    "end": "242120"
  },
  {
    "text": "the model is small enough it's going to fit but the throughput the amount of request we're going to be able to serve",
    "start": "242120",
    "end": "248079"
  },
  {
    "text": "at the same time is going to drop right but if we have low inous traffic and and",
    "start": "248079",
    "end": "255280"
  },
  {
    "text": "and and and flexible enough uh service level objectives we can actually run small models with fraction of gpus and",
    "start": "255280",
    "end": "262840"
  },
  {
    "text": "achieve the performance that we need out of them right and that's what we're trying to uh make possible here and",
    "start": "262840",
    "end": "268440"
  },
  {
    "text": "actually automate so uh how do we uh you know how do we go",
    "start": "268440",
    "end": "274680"
  },
  {
    "text": "after uh you know uh using fractions of gpus one of the possible techniques is",
    "start": "274680",
    "end": "280880"
  },
  {
    "text": "NVIDIA technique called multi-instance GPU it's essentially a mechanism that makes it possible to take so yeah so so",
    "start": "280880",
    "end": "289039"
  },
  {
    "text": "this is technique that let us uh divide the GPU into uh up to seven slices so up",
    "start": "289039",
    "end": "295960"
  },
  {
    "text": "to seven um uh uh you know independent fraction of the gpus that can be used",
    "start": "295960",
    "end": "301360"
  },
  {
    "text": "independently from independent you know servers like VM for instance without any",
    "start": "301360",
    "end": "306400"
  },
  {
    "text": "really configuration change or or changes needed at the application Level and what's nice about these techniques",
    "start": "306400",
    "end": "312120"
  },
  {
    "text": "is that we can go all the way down to you know 7 sevens but we can also do uh",
    "start": "312120",
    "end": "317639"
  },
  {
    "text": "larger slices medium slices and so on and not only that but we can also mix and match so I can in a single GPU get",
    "start": "317639",
    "end": "325759"
  },
  {
    "text": "small models medium models larger models with what they need and can also do this incrementally so for instance I can",
    "start": "325759",
    "end": "332199"
  },
  {
    "text": "start using a piece of a GPU and then later load another model using another piece of the GPU and and and do",
    "start": "332199",
    "end": "340000"
  },
  {
    "text": "essentially what we expect from kubernetes which is to be able to you know schedule things as they come and",
    "start": "340000",
    "end": "346039"
  },
  {
    "text": "go so uh the way you do that on kuber just last slide on on platform and then",
    "start": "346039",
    "end": "351319"
  },
  {
    "text": "we'll really switch to um uh uh the the the meat of the of the of the of the",
    "start": "351319",
    "end": "357759"
  },
  {
    "text": "talk which is how do we do performance prediction you can either use the Nvidia",
    "start": "357759",
    "end": "363199"
  },
  {
    "text": "GPU operator which makes it possible so you choose the layout and then you use the Nvidia GPU operator and is going to",
    "start": "363199",
    "end": "369880"
  },
  {
    "text": "make this layout on all your gpus on your node and then you can have pods and they can request those slies and run",
    "start": "369880",
    "end": "376639"
  },
  {
    "text": "with the fraction of the GPU that you want right the drawback with this approach is you have to know ahead of",
    "start": "376639",
    "end": "381919"
  },
  {
    "text": "time in advance exactly the layout you want it has to be homogeneous at least at the node level so with uh our",
    "start": "381919",
    "end": "388599"
  },
  {
    "text": "colleagues at rat been developing an alternative experimental uh project that makes it possible essentially to have",
    "start": "388599",
    "end": "395120"
  },
  {
    "text": "the exact same pod specifications where I go after asking for the same slices",
    "start": "395120",
    "end": "400160"
  },
  {
    "text": "but uh I don't have to pre uh pre- partition I don't have to slice the pizza ahead of time or the GPU ahead of",
    "start": "400160",
    "end": "407240"
  },
  {
    "text": "time so that's it for me and I'm going to try to switch the laptop while you're speaking um so right now I'm going to",
    "start": "407240",
    "end": "414479"
  },
  {
    "text": "talk about the modeling part in our talk um so we have done lots of per",
    "start": "414479",
    "end": "419560"
  },
  {
    "text": "performance profiling studies and what today's session we want to talk about what we learn from this profiling study",
    "start": "419560",
    "end": "425960"
  },
  {
    "text": "and how we build up our analytic models So based on the figure we're showing on the slides over here the access is the",
    "start": "425960",
    "end": "433360"
  },
  {
    "text": "late throughput the Y AIS is the latency and this performance numbers are measured for llama 7 billion and Lama 13",
    "start": "433360",
    "end": "440360"
  },
  {
    "text": "billion models and for those numbers besides the dot they are actually the uh",
    "start": "440360",
    "end": "446080"
  },
  {
    "text": "number of concurrent requests um so as we can see from the figures that when we",
    "start": "446080",
    "end": "452039"
  },
  {
    "text": "try to increase the concurrent request count um so come back to this figure so",
    "start": "452039",
    "end": "457479"
  },
  {
    "text": "basically the number besides the dot is the concurrent request count and based on those results we can tell is when we",
    "start": "457479",
    "end": "463360"
  },
  {
    "text": "try to increase the concurrent request count we do see after certain points um",
    "start": "463360",
    "end": "468759"
  },
  {
    "text": "the latencies sharply increase but the throughput stays relatively constant so",
    "start": "468759",
    "end": "474240"
  },
  {
    "text": "we are thinking probably there exist a knee point on this performance curve that can help us to make analytic",
    "start": "474240",
    "end": "480479"
  },
  {
    "text": "performance model so on the next slide which we are showing right now is we show the similar performance results for",
    "start": "480479",
    "end": "487479"
  },
  {
    "text": "different type of GPU and mix size so for the both figure the access is still the throughput the Y AIS is the latency",
    "start": "487479",
    "end": "495039"
  },
  {
    "text": "and for the figure on the left side we show the performance numbers that we measured on",
    "start": "495039",
    "end": "500199"
  },
  {
    "text": "a100 80 gab GPU and also the rec cor respond me slices and for the figure on",
    "start": "500199",
    "end": "506039"
  },
  {
    "text": "the right side is some performance numbers on 8100 and also h100 so",
    "start": "506039",
    "end": "511159"
  },
  {
    "text": "similarly U for both those two figures we do observe that when we increase concurrent request count with this per",
    "start": "511159",
    "end": "518599"
  },
  {
    "text": "um latency we do say the throughput and latency hat this performance wall so we",
    "start": "518599",
    "end": "524519"
  },
  {
    "text": "believe uh this is caused by the intersections of GPU computation and memory bandwidth limit so in the next",
    "start": "524519",
    "end": "531279"
  },
  {
    "text": "few slides we are going to talk about how we estimate throughput and latency and also how we find this KNE point and",
    "start": "531279",
    "end": "538360"
  },
  {
    "text": "before we go into the deta detail of the analytic model we want to give up um give some backend backgrounds about",
    "start": "538360",
    "end": "544519"
  },
  {
    "text": "attention layers so this is the transformal model architectures that we",
    "start": "544519",
    "end": "549560"
  },
  {
    "text": "U gather this figure from original attention is all your need paper so Bas",
    "start": "549560",
    "end": "554640"
  },
  {
    "text": "on what we showing on the slides for other um layers that circled by this",
    "start": "554640",
    "end": "560399"
  },
  {
    "text": "green rectangles now attenion layers and the Transformer are build with multiple stacked tension layer and what we show",
    "start": "560399",
    "end": "567720"
  },
  {
    "text": "on the right side is actually one example of what the an attention layer looks like it needs inputs from like",
    "start": "567720",
    "end": "575839"
  },
  {
    "text": "cury key and value and also it need to do some Mass um",
    "start": "575839",
    "end": "581240"
  },
  {
    "text": "mathematic like uh Matrix uh multiplications soft uh soft Max and those computations are summarized on the",
    "start": "581240",
    "end": "588680"
  },
  {
    "text": "left side so in this computations we do need to load the data from the GPU",
    "start": "588680",
    "end": "594760"
  },
  {
    "text": "memory and also we need to store the intermediate result to the GPU memory",
    "start": "594760",
    "end": "599880"
  },
  {
    "text": "and because the attention layers dulat the overall Transformer models",
    "start": "599880",
    "end": "605120"
  },
  {
    "text": "architecture so we use the attention layer to estimate the throughput through the model's arithmetic intensity so the",
    "start": "605120",
    "end": "612600"
  },
  {
    "text": "question here is what is the model's arithmetic intensity so it is the flops",
    "start": "612600",
    "end": "617720"
  },
  {
    "text": "per seconds divided by the bytes moved per seconds so since um in our example",
    "start": "617720",
    "end": "623079"
  },
  {
    "text": "here the tension layers stimulates the Transformer architectures so the computation cost of the",
    "start": "623079",
    "end": "630240"
  },
  {
    "text": "of the com attention layer divided by the memory cost of the attention layers",
    "start": "630240",
    "end": "635519"
  },
  {
    "text": "is the model's intensity so as we will know lots of lots of models performance",
    "start": "635519",
    "end": "641760"
  },
  {
    "text": "are limited by the GPU memory band withs so the throughput here equals the model's intensity times the um the GPU",
    "start": "641760",
    "end": "648920"
  },
  {
    "text": "memory bandwith so on this slide what we are showing here is we try to summarize what",
    "start": "648920",
    "end": "655079"
  },
  {
    "text": "are the cost for loading the data and storing those results from the GPU memory and also the computations for the",
    "start": "655079",
    "end": "661880"
  },
  {
    "text": "attention layers so um to be more easier to understand for this uh table we try",
    "start": "661880",
    "end": "667519"
  },
  {
    "text": "to summarize this all the values on this uh computation column so we have this",
    "start": "667519",
    "end": "672880"
  },
  {
    "text": "new equations for the computation cost and then uh we summarize the data",
    "start": "672880",
    "end": "678920"
  },
  {
    "text": "movements CA from the first and the last columns we have this memory movement cost equations So based on what we",
    "start": "678920",
    "end": "686600"
  },
  {
    "text": "discussed in the previous slides we have a new equation for the surut which is the memory um computation cost divided",
    "start": "686600",
    "end": "693760"
  },
  {
    "text": "by the memory cost times the uh GPU memory band ws and also we all know that",
    "start": "693760",
    "end": "699200"
  },
  {
    "text": "it's is really hard to achieve the peak GPU memory bandwidth so in real practice",
    "start": "699200",
    "end": "705399"
  },
  {
    "text": "we try to summarize deriv this portion for the computation cost into a and the",
    "start": "705399",
    "end": "710880"
  },
  {
    "text": "this two two portion into of the memory cost into B and C so we get a new",
    "start": "710880",
    "end": "716480"
  },
  {
    "text": "equations which is what we're showing over here it looks much much simple and it also can help you to fade your models",
    "start": "716480",
    "end": "724760"
  },
  {
    "text": "on different type of GPU devices but the question here is how we find the value",
    "start": "724760",
    "end": "730000"
  },
  {
    "text": "for a b and c so in the real practice you don't need to do the profilings and",
    "start": "730000",
    "end": "736000"
  },
  {
    "text": "for lots of data you just need a very few data points to fit in this function to find find the correspond value for a",
    "start": "736000",
    "end": "742360"
  },
  {
    "text": "and b and c of course the more data you fit in the better um um estimation you",
    "start": "742360",
    "end": "748519"
  },
  {
    "text": "can get and so for the KNE points we talk about in the previous slides so the",
    "start": "748519",
    "end": "753760"
  },
  {
    "text": "knee point of this throughput function actually correspond to the knee points of this the performance model that we",
    "start": "753760",
    "end": "760360"
  },
  {
    "text": "mentioned previously the question now is how we want to leverage this KNE",
    "start": "760360",
    "end": "766000"
  },
  {
    "text": "point so for here we are going to talk about how we estimate the latency so for the top part we showed",
    "start": "766000",
    "end": "773440"
  },
  {
    "text": "the example for the Lama 27 billion model on a 1880 GB GPU and for the",
    "start": "773440",
    "end": "779519"
  },
  {
    "text": "access we sh here is the batch size which is the concurrent request we are referring to and the Y access is the",
    "start": "779519",
    "end": "785959"
  },
  {
    "text": "latency and we use the different sequence lens over here and as we can see from this figure before we reach the",
    "start": "785959",
    "end": "792920"
  },
  {
    "text": "knee point the latency increase linearly uh with the badge size and also one",
    "start": "792920",
    "end": "799120"
  },
  {
    "text": "thing to note here is for those larger badge size is also easier for them to reach this knee point and this is due to",
    "start": "799120",
    "end": "805560"
  },
  {
    "text": "the GPU memory capacity limit and we have talk a lot about this uh what we",
    "start": "805560",
    "end": "811160"
  },
  {
    "text": "have observed and so to calculate U to estimate the latency um we use the",
    "start": "811160",
    "end": "816720"
  },
  {
    "text": "number of layers times the time spend on the uh computation and also the memory",
    "start": "816720",
    "end": "822440"
  },
  {
    "text": "and also we can derive this function at the last at the bottom which is a linear function and like what we just described",
    "start": "822440",
    "end": "829639"
  },
  {
    "text": "you can we can just have a very few data points to fit in and find the correspond value for a and C",
    "start": "829639",
    "end": "836000"
  },
  {
    "text": "here and in the last few slides we are going to talk about some of our um performance models and try to compare um",
    "start": "836000",
    "end": "844160"
  },
  {
    "text": "this analytical model with the Real Performance number that we measured on our system so one thing to note here for",
    "start": "844160",
    "end": "851000"
  },
  {
    "text": "the performance model that analytic model we use over here we only use the six results from the data profiling and",
    "start": "851000",
    "end": "858160"
  },
  {
    "text": "to fit in the model but we do try to measure the multiple different batch size for the given sequence lens to see",
    "start": "858160",
    "end": "864399"
  },
  {
    "text": "what's the differences between our Me performance number and also our s number",
    "start": "864399",
    "end": "870040"
  },
  {
    "text": "so for the figure here that the blue line is the Real Performance number that we measured through V LM and the orange",
    "start": "870040",
    "end": "876839"
  },
  {
    "text": "line here is the estimate number that we reported through our analytic performance model so for the top row",
    "start": "876839",
    "end": "883279"
  },
  {
    "text": "here is the perform throughput performance and the lower row here is the latency performance and for each",
    "start": "883279",
    "end": "889120"
  },
  {
    "text": "columns the performance numbers are measured for different type of mix slices and um the takeway message we",
    "start": "889120",
    "end": "895279"
  },
  {
    "text": "want to tell from this figure is the throughput match um our predict throughput train and also before we",
    "start": "895279",
    "end": "902079"
  },
  {
    "text": "reach that knee point the latency linearly increase with the bat size and also um our estimation matches with uh",
    "start": "902079",
    "end": "909959"
  },
  {
    "text": "the real experiments and for the next slid is the performance Model results we had for the mistro 7 B",
    "start": "909959",
    "end": "917079"
  },
  {
    "text": "model and for the here we show the results for different sequence lens but the one is on 7g 40 gab slice one is on",
    "start": "917079",
    "end": "924160"
  },
  {
    "text": "the 3G 20 gab slice and we do see some variation here but the overall train",
    "start": "924160",
    "end": "929600"
  },
  {
    "text": "remains constants with our estimation and here is the latency result for this",
    "start": "929600",
    "end": "934800"
  },
  {
    "text": "mistal 7 billion contest model and similarly um we do see some variations",
    "start": "934800",
    "end": "940160"
  },
  {
    "text": "but we still um the overall train remains constant and this is the Lama 3",
    "start": "940160",
    "end": "945680"
  },
  {
    "text": "bilon Model through results on on this one we measure the performance number on",
    "start": "945680",
    "end": "950880"
  },
  {
    "text": "a100 and also h100 um similarly we do observe the similar train and this is",
    "start": "950880",
    "end": "957360"
  },
  {
    "text": "the performance number that we measure for the Llama 7 billion model um still on two different type of GPU but it is",
    "start": "957360",
    "end": "964040"
  },
  {
    "text": "for the latency um still like before we reach that knee point the latency linearly increase the badge size and",
    "start": "964040",
    "end": "970880"
  },
  {
    "text": "also match with our estimation so then I'm going to pass uh to the Olivia for",
    "start": "970880",
    "end": "976959"
  },
  {
    "text": "the design of the ofo fit okay so as I said in introduction",
    "start": "976959",
    "end": "982079"
  },
  {
    "text": "how can we use this uh you know in the simplest possible manner in kubernetes",
    "start": "982079",
    "end": "987199"
  },
  {
    "text": "right fundamentally we want to have uh developers you know uh people you",
    "start": "987199",
    "end": "992680"
  },
  {
    "text": "know system submitting uh uh you know uh creating pods on the system that will",
    "start": "992680",
    "end": "999279"
  },
  {
    "text": "contain uh INF servers we want them not to worry about how many gpus they need for that and we want to magically at the",
    "start": "999279",
    "end": "1006399"
  },
  {
    "text": "end uh replace their requirements which is you know uh not really precise to",
    "start": "1006399",
    "end": "1012360"
  },
  {
    "text": "what we think is going to be exactly needed for this particular uh model and this particular target load and this",
    "start": "1012360",
    "end": "1018959"
  },
  {
    "text": "particular Target SLA so you know there's a very simple way to do exactly that on kubernetes called a webbook this",
    "start": "1018959",
    "end": "1025280"
  },
  {
    "text": "is something that's going to watch for the part being created can you know you have two types in we books in kues I'm",
    "start": "1025280",
    "end": "1031959"
  },
  {
    "text": "sure you all know this you know you can you have validation web books that are just about verifying that the part that",
    "start": "1031959",
    "end": "1037480"
  },
  {
    "text": "you're submitting makes sense doesn't have any you know things you you don't want there they are mutating web books",
    "start": "1037480",
    "end": "1043038"
  },
  {
    "text": "that's the next level that makes it possible to change the specification of a pod or any kubernetes kind on the fly",
    "start": "1043039",
    "end": "1049679"
  },
  {
    "text": "so again this is what we're using here so we have a webbook it watches for pot being created it's going to extract",
    "start": "1049679",
    "end": "1056919"
  },
  {
    "text": "which is what I'm going to describe in the next slides from that pod information about the model that is being run and what we want to do with it",
    "start": "1056919",
    "end": "1064440"
  },
  {
    "text": "and based on that is going to call our predictor performance predictor for the model figure out what is the smallest",
    "start": "1064440",
    "end": "1070320"
  },
  {
    "text": "possible fraction of a GPU the Mig slice as I was talking about earlier that",
    "start": "1070320",
    "end": "1075400"
  },
  {
    "text": "should satisfy the requirements make the changes to the pods spec then the part is going to reach uh you know the",
    "start": "1075400",
    "end": "1082320"
  },
  {
    "text": "scheduler is going to be scheduled it's going to be running and then in the demo we're going to be able to see how uh you",
    "start": "1082320",
    "end": "1088240"
  },
  {
    "text": "know how good a prediction we have so the way we do this in this demo is demo",
    "start": "1088240",
    "end": "1093840"
  },
  {
    "text": "Weare we're going to do as simple as possible we're actually going to have pods that contain both an inference",
    "start": "1093840",
    "end": "1100600"
  },
  {
    "text": "runtime VM is what we use as well as a you know benchmarking script as as as a",
    "start": "1100600",
    "end": "1106760"
  },
  {
    "text": "as a load generator that will let us exercise uh the model uh with certain",
    "start": "1106760",
    "end": "1113120"
  },
  {
    "text": "characteristics and then you know uh output you know compute metrics out of uh this run and then again compare the",
    "start": "1113120",
    "end": "1120559"
  },
  {
    "text": "theoretical expectations we had from the model with what we observe in practice right so from that specification we're",
    "start": "1120559",
    "end": "1127000"
  },
  {
    "text": "going to extract model characteristics we're going to extract characteristics of the load we're expecting and we also",
    "start": "1127000",
    "end": "1134000"
  },
  {
    "text": "provide uh in terms of an environment variable here uh the expected the the",
    "start": "1134000",
    "end": "1139720"
  },
  {
    "text": "the the the time per output to token requirements that we want this deployment to satisfy right so uh you",
    "start": "1139720",
    "end": "1148520"
  },
  {
    "text": "know given that as I said we are going to run the estimator the estimator is essentially going to look at at the the",
    "start": "1148520",
    "end": "1155559"
  },
  {
    "text": "curves on the right say you want to have for instance a low load you want to have eight concurrent users or eight",
    "start": "1155559",
    "end": "1161520"
  },
  {
    "text": "concurrent requests you want 50 milliseconds per token Max so I can actually give you the smallest slice",
    "start": "1161520",
    "end": "1167720"
  },
  {
    "text": "because the purple curve actually the eight point on the purple curve is going to be below the red line right um if you",
    "start": "1167720",
    "end": "1175799"
  },
  {
    "text": "want 16 on the other hand that's not going to be enough us you're actually going to go all the way through a 3G 40gb slice so a bigger chunk of my GPU",
    "start": "1175799",
    "end": "1183760"
  },
  {
    "text": "to actually satisfy the need so it's still the same model but it's because we want to serve more loads and because we",
    "start": "1183760",
    "end": "1189080"
  },
  {
    "text": "don't want our latency or or or per token latency to you know creep up too",
    "start": "1189080",
    "end": "1194440"
  },
  {
    "text": "much we are going to go higher and again because this is a simple demo Focus on",
    "start": "1194440",
    "end": "1200280"
  },
  {
    "text": "uh squeezing focused on GPU sharing if we cannot satisfy the requirements we're",
    "start": "1200280",
    "end": "1206240"
  },
  {
    "text": "just going to give every the entire GPU to the to the to the model right now that's again I would say de aware a real",
    "start": "1206240",
    "end": "1214240"
  },
  {
    "text": "system is going to look much more like that again think K serve think any of your uh serving platforms that you have",
    "start": "1214240",
    "end": "1221240"
  },
  {
    "text": "uh you're going to have first a separation between the description of a model and the description of an instantiation of that model targeted as",
    "start": "1221240",
    "end": "1227600"
  },
  {
    "text": "a specific load so you would have something like a a model custom resource that describe the checkpoints that you",
    "start": "1227600",
    "end": "1233360"
  },
  {
    "text": "want to load the size of the model somehow typically the parameter count and the Precision the bit width of the",
    "start": "1233360",
    "end": "1239360"
  },
  {
    "text": "tensors right and the kind of things you get from a model card then you're going to get a model deployment that's where",
    "start": "1239360",
    "end": "1245919"
  },
  {
    "text": "you're actually going to say I'm deploying this model with the intent of serving that much load and the intent of",
    "start": "1245919",
    "end": "1252679"
  },
  {
    "text": "achieving these service level objectives and then on top of that it's not going to be just a simple webbook but there is",
    "start": "1252679",
    "end": "1258720"
  },
  {
    "text": "going to be a deployment controller that is going to embed autofit to make this prediction and what it's going to do is",
    "start": "1258720",
    "end": "1264760"
  },
  {
    "text": "typically uh generate a deployment maybe service you know all the all the kubernetes object that you actually need",
    "start": "1264760",
    "end": "1271120"
  },
  {
    "text": "to then instantiate and run your model on your system what I want to also use",
    "start": "1271120",
    "end": "1276200"
  },
  {
    "text": "these slides for is to say there's even more than that of course in a real system uh one of the things we are not",
    "start": "1276200",
    "end": "1282559"
  },
  {
    "text": "talking about here for instance no so autofit is a local ahead of time Optimizer right so one of the things",
    "start": "1282559",
    "end": "1288000"
  },
  {
    "text": "we're not talking about here is that once you've deployed the model of course you want to monitor its performance",
    "start": "1288000",
    "end": "1293600"
  },
  {
    "text": "right and it's actually deviating quite a bit or the load that you're getting on the model is deviating quite a bit from",
    "start": "1293600",
    "end": "1299039"
  },
  {
    "text": "what you were expecting you want to correct things you want to scale up or down uh accordingly similarly another",
    "start": "1299039",
    "end": "1305679"
  },
  {
    "text": "problem or or you know another thing we're not focusing on here is that autoit is a local Optimizer that says",
    "start": "1305679",
    "end": "1311880"
  },
  {
    "text": "given a model assuming you have all the gpus in the world what is exactly how many GPU you know how much of a fraction",
    "start": "1311880",
    "end": "1318080"
  },
  {
    "text": "of a GP you needs but in practice we live in a constrainted world and so in addition to this local Optimizer there's",
    "start": "1318080",
    "end": "1324440"
  },
  {
    "text": "going to be a global Optimizer that says that's what you want but you know that's what I can give you and I need to",
    "start": "1324440",
    "end": "1331200"
  },
  {
    "text": "prioritize things between different models different users levels of services and so on so none of these are",
    "start": "1331200",
    "end": "1336679"
  },
  {
    "text": "part of this demo but the ultimate goal is to have autoit as you can see in this picture doing what we",
    "start": "1336679",
    "end": "1343960"
  },
  {
    "text": "described um now we are going to talk about our demo so for action actually in our demo recording we do include the",
    "start": "1344360",
    "end": "1350880"
  },
  {
    "text": "deployments for two type of models one is opt 1.3 billion models and another",
    "start": "1350880",
    "end": "1356279"
  },
  {
    "text": "one is the Mr quanti models but due to the time limit we are only able to show",
    "start": "1356279",
    "end": "1361520"
  },
  {
    "text": "the first one and feel free to check the full recordings online and we do have the URL and the the QR code feel free to",
    "start": "1361520",
    "end": "1368039"
  },
  {
    "text": "scan it oh yes this is my laop sorry H it's",
    "start": "1368039",
    "end": "1373640"
  },
  {
    "text": "just here no it's not here",
    "start": "1373640",
    "end": "1380120"
  },
  {
    "text": "um that's what you want yes so you",
    "start": "1383919",
    "end": "1390240"
  },
  {
    "text": "can I can do back and force between these two yeah so what we are showing",
    "start": "1394760",
    "end": "1399880"
  },
  {
    "text": "right now on the left side is actually we have prefigure that make slices on this",
    "start": "1399880",
    "end": "1406760"
  },
  {
    "text": "machines and on the right side what we are showing is with how we deploy the autoed and this is the part for the",
    "start": "1407000",
    "end": "1413279"
  },
  {
    "text": "autoed Web Web book so now what we're showing on the",
    "start": "1413279",
    "end": "1418320"
  },
  {
    "text": "left side is how we set up the performance profiling data in this Json file so in this Json file we do includes",
    "start": "1418320",
    "end": "1425360"
  },
  {
    "text": "the models name model configurations the device name correspond memory limit for each device and also the correspond",
    "start": "1425360",
    "end": "1432600"
  },
  {
    "text": "performance profiling data that we need for this analytic model so where I sh you here is like four type of",
    "start": "1432600",
    "end": "1438960"
  },
  {
    "text": "devices and also what we're showing at the bottom is actually the mol models",
    "start": "1438960",
    "end": "1444000"
  },
  {
    "text": "but since due to the time limit we are not going to show the deployment for this",
    "start": "1444000",
    "end": "1449679"
  },
  {
    "text": "part so right now what we are showing is the uh model configuration f file for",
    "start": "1450200",
    "end": "1456679"
  },
  {
    "text": "the opt 1.3 billion model and you can get those parameters actually from the huging phase Model H and now what we are",
    "start": "1456679",
    "end": "1463400"
  },
  {
    "text": "showing is act the actual performance profiling data we fit in for the auto fed like what we showing here actually",
    "start": "1463400",
    "end": "1469840"
  },
  {
    "text": "we only include the performance round for performance result for six rounds and this includes the throughput number",
    "start": "1469840",
    "end": "1476080"
  },
  {
    "text": "and also the latest the latency number and what we are showing right now is the",
    "start": "1476080",
    "end": "1482320"
  },
  {
    "text": "uh performance numbers for 2G 10 gab slice and I forget to mention the previous one is the performance number",
    "start": "1482320",
    "end": "1488360"
  },
  {
    "text": "of 1G 10 gab mix slice and I'm going to skip the mistal",
    "start": "1488360",
    "end": "1496000"
  },
  {
    "text": "part and right now what we are showing on the right on the right side is the log from auto feed and next part going",
    "start": "1496000",
    "end": "1502200"
  },
  {
    "text": "to show us how we add what our estimation looks like and our Pro placement decision so right now on the",
    "start": "1502200",
    "end": "1508600"
  },
  {
    "text": "left side we deploy the One op opt 1.3 billion model um with for the low load",
    "start": "1508600",
    "end": "1514799"
  },
  {
    "text": "request so in this test setup where the input request the input sequence latency",
    "start": "1514799",
    "end": "1520279"
  },
  {
    "text": "is 128 and also the maximum concurrent request is 15 and for the time per",
    "start": "1520279",
    "end": "1526440"
  },
  {
    "text": "output token our requirement is uh 25 and also we are asking for one GPU",
    "start": "1526440",
    "end": "1534360"
  },
  {
    "text": "for n deployment on the right side that's",
    "start": "1534360",
    "end": "1540039"
  },
  {
    "text": "showing our performance estimations so this is the um throughput and the latency number for the 1G 10 gigabytes",
    "start": "1540039",
    "end": "1547240"
  },
  {
    "text": "when the concurrent request is 15 and because the latency number is smaller than 25 so it meets our requirements and",
    "start": "1547240",
    "end": "1554320"
  },
  {
    "text": "necess the small the smallest make Slice on the machine so we deploy we choose to",
    "start": "1554320",
    "end": "1560320"
  },
  {
    "text": "deploy this part on the 1G 10 gab slides so what we are showing here is we are showing we are showing that this port is",
    "start": "1560320",
    "end": "1568039"
  },
  {
    "text": "actually deployed on this 1G 10 gab M",
    "start": "1568039",
    "end": "1573519"
  },
  {
    "text": "slice this is showing Here and Now what we are going to show is for the performance result for this R so",
    "start": "1576919",
    "end": "1583840"
  },
  {
    "text": "basically that we what we're showing on left side which is the latency numbers that uh is about 15.3 38 which is much",
    "start": "1583840",
    "end": "1592080"
  },
  {
    "text": "lower than our performance requirements and but it's similar to what we reported on the uh right",
    "start": "1592080",
    "end": "1598279"
  },
  {
    "text": "sides and now we are going to deploy um opt model with high request",
    "start": "1598279",
    "end": "1605480"
  },
  {
    "text": "load like what we showing here we still use the input sequence lens as 128 the",
    "start": "1605480",
    "end": "1610799"
  },
  {
    "text": "maximum concurrence concurrency is 16 um the performance number requirement still",
    "start": "1610799",
    "end": "1617480"
  },
  {
    "text": "the same and we asking for one GPU on the right side of the screen that we try to check the performance for 1G 10 gab",
    "start": "1617480",
    "end": "1624840"
  },
  {
    "text": "slice 2G 10 gab slice but we find out only the 2G slice meets our performance",
    "start": "1624840",
    "end": "1630399"
  },
  {
    "text": "requirements which is 25 so we choose to place npod on the 2G 10 gab M",
    "start": "1630399",
    "end": "1637919"
  },
  {
    "text": "slice so now what we are showing is that npod is actually being placed for on",
    "start": "1637919",
    "end": "1644000"
  },
  {
    "text": "this 2G 10 gbyte MX slice and what we are showing right now is the performance",
    "start": "1644000",
    "end": "1649600"
  },
  {
    "text": "number that for this run and for the latency number we reported for this run is 23.2 three and on the right side we",
    "start": "1649600",
    "end": "1657840"
  },
  {
    "text": "do have our Pro um estimate Laten number is 2182 and for the througho number is",
    "start": "1657840",
    "end": "1664240"
  },
  {
    "text": "2188 and the estimate of the throughput number is 2094 which is actually very",
    "start": "1664240",
    "end": "1670480"
  },
  {
    "text": "close to our reported performance number and for the L is for the misual models",
    "start": "1670480",
    "end": "1675600"
  },
  {
    "text": "but we won't include in today's uh that",
    "start": "1675600",
    "end": "1680120"
  },
  {
    "text": "talk thank you so going back to the to the slides and to the uh conclusion",
    "start": "1684480",
    "end": "1691080"
  },
  {
    "text": "about of the talk so what we've essentially shown you here is that if we have a good enough understanding of how",
    "start": "1691080",
    "end": "1697120"
  },
  {
    "text": "the GPU computes of what an llm does actually when we run it we can combine",
    "start": "1697120",
    "end": "1702720"
  },
  {
    "text": "these two things together to get to essentially a mathematical understanding of the complexity of that computation",
    "start": "1702720",
    "end": "1709159"
  },
  {
    "text": "whether it's memory consumption memory band with comput find what is the bottleneck in all of these and from that",
    "start": "1709159",
    "end": "1716399"
  },
  {
    "text": "derive essentially an analytical model of how these llm will behave under",
    "start": "1716399",
    "end": "1721480"
  },
  {
    "text": "different conditions right what we've done here though is that we've kind of we're doing this model with the",
    "start": "1721480",
    "end": "1728480"
  },
  {
    "text": "assumption that we can saturate the memory bandwidth of the GPU which is not quite right where again a good kud",
    "start": "1728480",
    "end": "1734720"
  },
  {
    "text": "kernel will achieve more than 80% memory bandwidth a good the tension kernel let's say and so so this is not an exact",
    "start": "1734720",
    "end": "1742640"
  },
  {
    "text": "mathematical model that really fits the data but because we have this model we can now actually fit that model we can",
    "start": "1742640",
    "end": "1750440"
  },
  {
    "text": "get a very good predictor for the performance of the model by just combining this shape that we expect with",
    "start": "1750440",
    "end": "1756440"
  },
  {
    "text": "very few data points right taking a step back one thing I should have said more clearly here is our goal is to actually",
    "start": "1756440",
    "end": "1762600"
  },
  {
    "text": "predict the performance of large language model without having to do a lot of benchmarking beforehand and say",
    "start": "1762600",
    "end": "1767640"
  },
  {
    "text": "you know my prediction is just fetching a number from a table we want to over time as time goes by reduce further and",
    "start": "1767640",
    "end": "1775279"
  },
  {
    "text": "further and further and further how much we have to do in terms of measurements to calibrate all of these things so",
    "start": "1775279",
    "end": "1781559"
  },
  {
    "text": "today we calibrate per model tomorrow we want to calibrate their model family today we calibrate their per per per per",
    "start": "1781559",
    "end": "1787919"
  },
  {
    "text": "fraction tomorrow we want to calibrate so this is a work in progress but really that's the goal the goal is to be able",
    "start": "1787919",
    "end": "1793679"
  },
  {
    "text": "to predict machine learning model performance with as little data as as little input data as possible in",
    "start": "1793679",
    "end": "1800440"
  },
  {
    "text": "particular because they change all the time right and so we don't want to be all the time running these benchmarks to predict what's going to happen now that",
    "start": "1800440",
    "end": "1807840"
  },
  {
    "text": "we have this scale prediction that uh is as you've seen from the demo pretty",
    "start": "1807840",
    "end": "1813480"
  },
  {
    "text": "accurate we can turn this into a right sizing method right which is I take the prediction I take the fractions whatever",
    "start": "1813480",
    "end": "1821000"
  },
  {
    "text": "the fractional techniques so this is also works by the way in terms of different families of gpus I think we've",
    "start": "1821000",
    "end": "1826720"
  },
  {
    "text": "shown this a little bit by a140 and A180 and h100 you know benchmarks right so",
    "start": "1826720",
    "end": "1832840"
  },
  {
    "text": "you can use this right sizing model to scale your request for your GPU you can",
    "start": "1832840",
    "end": "1838159"
  },
  {
    "text": "scale it in terms of in you know type of GPU and and and size of the fraction of",
    "start": "1838159",
    "end": "1843799"
  },
  {
    "text": "GPU what we didn't show also in the demo I think I said this is that we can U you",
    "start": "1843799",
    "end": "1849200"
  },
  {
    "text": "know this this works not only to say oh you don't need a full GPU to serve your model but that can also say you need",
    "start": "1849200",
    "end": "1855440"
  },
  {
    "text": "many replicas of that GPU to serve the traffic you for this model because one GPU by itself will not be able to do it",
    "start": "1855440",
    "end": "1862159"
  },
  {
    "text": "right so that's what we've shown you today and what we also shown you is how we can essentially bring this back",
    "start": "1862159",
    "end": "1868240"
  },
  {
    "text": "inside a kubernetes controller or webook that is now going to help users by",
    "start": "1868240",
    "end": "1874080"
  },
  {
    "text": "essentially removing the uh the challenge of making these decisions by themselves right and we hoping to uh",
    "start": "1874080",
    "end": "1882760"
  },
  {
    "text": "open source this code at least the demo code that we've shown today very very soon",
    "start": "1882760",
    "end": "1888799"
  },
  {
    "text": "thank you for your attention and I think we have a couple of minutes for [Applause]",
    "start": "1888799",
    "end": "1900209"
  },
  {
    "text": "questions can you hear me yes okay cool so I guess it's actually working I think",
    "start": "1913120",
    "end": "1918799"
  },
  {
    "text": "at this point if you hello yeah okay so are you defining the mix in advance per",
    "start": "1918799",
    "end": "1924880"
  },
  {
    "text": "node the mix in advance no well so in the demo yes right what what what again",
    "start": "1924880",
    "end": "1930600"
  },
  {
    "text": "I i' send you back to the talk I gave with a colleague on Tuesday we don't have to do that the work we've done de",
    "start": "1930600",
    "end": "1937000"
  },
  {
    "text": "are all about avoiding this this the need for pre-s slicing your notes right",
    "start": "1937000",
    "end": "1942720"
  },
  {
    "text": "so but in the particular demo you at there what What U showed we are just using the regular NV GPU operator that",
    "start": "1942720",
    "end": "1949440"
  },
  {
    "text": "was pre-sliced uh uh beforehand yes okay and so the whole idea of this is to",
    "start": "1949440",
    "end": "1956240"
  },
  {
    "text": "dynamically yes absolutely this is why we need to combine this you know a technology to improve what the yes the",
    "start": "1956240",
    "end": "1963600"
  },
  {
    "text": "insta slice with with that stuff thank you very",
    "start": "1963600",
    "end": "1968840"
  },
  {
    "text": "much hey thanks for the great talk so I have a quick question so uh since you're",
    "start": "1969320",
    "end": "1974799"
  },
  {
    "text": "like larger models like 70b or 45 B models that requires like more than one",
    "start": "1974799",
    "end": "1979960"
  },
  {
    "text": "GPU to run so does your methodology support like using Mig for those kind of larger models modle gpus and is so how",
    "start": "1979960",
    "end": "1988840"
  },
  {
    "text": "how do you like make make decisions on those cases uh yes so right now the assumption is where the model can fit in",
    "start": "1988840",
    "end": "1994600"
  },
  {
    "text": "only one GPU because for those larger models you do have to consider the communication overheads but for here",
    "start": "1994600",
    "end": "2000240"
  },
  {
    "text": "that part is not considered but we do believe after some TBS this model still can be fit in to help you improve the",
    "start": "2000240",
    "end": "2006559"
  },
  {
    "text": "distributed models because we are not like we say ABC is a fix value is based on your profiling",
    "start": "2006559",
    "end": "2012840"
  },
  {
    "text": "data thanks I think as I said at the beginning also the the we we see much",
    "start": "2012840",
    "end": "2019200"
  },
  {
    "text": "less challenges in practice from people and platform perspective using multiple",
    "start": "2019200",
    "end": "2024399"
  },
  {
    "text": "gpus then we see going down to you know fractions of the GPU so that that's the focus of this work but indeed a model",
    "start": "2024399",
    "end": "2031320"
  },
  {
    "text": "for you know like sharded uh models would be a little bit different from this one yes thanks thanks",
    "start": "2031320",
    "end": "2038799"
  },
  {
    "text": "hi uh great talk a lot of useful insights here uh so I had one question",
    "start": "2038799",
    "end": "2044120"
  },
  {
    "text": "on uh how you were approximating for the estimation uh is it relying on just the",
    "start": "2044120",
    "end": "2049280"
  },
  {
    "text": "number of layers bat size and what are the other parameters yes like what we",
    "start": "2049280",
    "end": "2054760"
  },
  {
    "text": "have show is like we do have a a model configure file in that file we do take like the embeding size number of layers",
    "start": "2054760",
    "end": "2061520"
  },
  {
    "text": "and you can find out actually in our demo for like what other parameters we are taking into account and this also in",
    "start": "2061520",
    "end": "2067720"
  },
  {
    "text": "to the GPU memory as limitation okay uh one follow-up question like uh you",
    "start": "2067720",
    "end": "2073079"
  },
  {
    "text": "mentioned there could be some limitations so flash attention actually reduces the memory access so it could",
    "start": "2073079",
    "end": "2080599"
  },
  {
    "text": "the ratio could potentially change so does it work for all models or what are",
    "start": "2080599",
    "end": "2086480"
  },
  {
    "text": "the limitations you would say so so very hard to quantify universally so you have",
    "start": "2086480",
    "end": "2092679"
  },
  {
    "text": "a very good point right so what really may be the key Point here is that this is a very fast moving field right what",
    "start": "2092679",
    "end": "2099040"
  },
  {
    "text": "we see at this point in time is for the baseball even with some of these more optimized algorithms the memory band",
    "start": "2099040",
    "end": "2105400"
  },
  {
    "text": "we've continues to be essentially the the dominating bottleneck right but because it's the bottleneck we're",
    "start": "2105400",
    "end": "2111160"
  },
  {
    "text": "starting to see techniques for instance like speculation that are uh introduced to use the you know kind of freely",
    "start": "2111160",
    "end": "2117680"
  },
  {
    "text": "available you know compute Cycles to do more compute so as these things take",
    "start": "2117680",
    "end": "2122920"
  },
  {
    "text": "place um uh this is going to change the model but what we didn't show in this St and maybe I can briefly flash I guess is",
    "start": "2122920",
    "end": "2131400"
  },
  {
    "text": "that yes we're working on the or maybe well I guess that's not that's also",
    "start": "2131400",
    "end": "2137240"
  },
  {
    "text": "somewhat relevant but yes there's a you know there's a there's also another knee Point another inflection point which",
    "start": "2137240",
    "end": "2143480"
  },
  {
    "text": "corresponds to whether you're essentially data movement Bond or compute Bond these are things we're",
    "start": "2143480",
    "end": "2148640"
  },
  {
    "text": "looking at but right now we're on the left of that of that of that picture at this point at least okay thank",
    "start": "2148640",
    "end": "2156319"
  },
  {
    "text": "you hello so thank you for the talk I have two questions first one is how are you patching the board yaml spec on",
    "start": "2156319",
    "end": "2164720"
  },
  {
    "text": "runtime are using like admission controller or something else uh you mean what I was showing for fitting when you",
    "start": "2164720",
    "end": "2172079"
  },
  {
    "text": "are changing the GPU allocation yeah that's like the prev yeah that and previous that one so so so again I I",
    "start": "2172079",
    "end": "2180079"
  },
  {
    "text": "said this right now what what I show here is demo Weare right we have in the webbook we have a parser that recognizes",
    "start": "2180079",
    "end": "2187119"
  },
  {
    "text": "these two commments and recognize the parameters for these two commments and use this to extract this information",
    "start": "2187119",
    "end": "2193560"
  },
  {
    "text": "then send this you know use this as parameters for the estimator right in in",
    "start": "2193560",
    "end": "2199760"
  },
  {
    "text": "in the production environment this this looks like this this looks like you have we have actually have crds you can think",
    "start": "2199760",
    "end": "2206760"
  },
  {
    "text": "of this as a key value essentially thing that describ the model you can think of this as a key value thing that describes",
    "start": "2206760",
    "end": "2213760"
  },
  {
    "text": "these values is actually simpler right in that the demo i' I've shown but there are more moving pieces more components",
    "start": "2213760",
    "end": "2221599"
  },
  {
    "text": "so what does the controller do to change the pods spec on the run time so so in",
    "start": "2221599",
    "end": "2227480"
  },
  {
    "text": "that case what the controller does in that case this is not a controller this is webook you cannot change the P spec",
    "start": "2227480",
    "end": "2232880"
  },
  {
    "text": "once it's been created so we intercept the creation the P at creation time uh",
    "start": "2232880",
    "end": "2239800"
  },
  {
    "text": "bit of a toy in reality we start with something a precursor right we start with this which is not a pod nothing and",
    "start": "2239800",
    "end": "2247079"
  },
  {
    "text": "what we do is we actually generate the deployment from scratch with the right value in there right makes sense thank",
    "start": "2247079",
    "end": "2254200"
  },
  {
    "text": "you uh second question is how does the GPU fractioning work together with Dynamic resource allocation and Autos",
    "start": "2254200",
    "end": "2261040"
  },
  {
    "text": "scaling component like Carpenter so Dr and Carpenter I will",
    "start": "2261040",
    "end": "2266200"
  },
  {
    "text": "leave that to Kevin maybe in the back uh but uh um oh it works so so so",
    "start": "2266200",
    "end": "2274119"
  },
  {
    "text": "um so right now we're using the Nvidia GP operator kind of uh uh uh mechanism",
    "start": "2274119",
    "end": "2281680"
  },
  {
    "text": "the device plug-in mechanism which is we specify a resource with a particular name right so the way in kubernetes",
    "start": "2281680",
    "end": "2288319"
  },
  {
    "text": "today if you use a GPU operator is all of these slices are different names they're just strings that are different",
    "start": "2288319",
    "end": "2293720"
  },
  {
    "text": "and the device plug-in magically knows what they mean right uh Dr is a",
    "start": "2293720",
    "end": "2298920"
  },
  {
    "text": "different system is the future where this is actually meaningful numbers name",
    "start": "2298920",
    "end": "2305400"
  },
  {
    "text": "you know like uh you um so but but essentially at the end of",
    "start": "2305400",
    "end": "2312000"
  },
  {
    "text": "the day this is the same right the the yaml will be different for the but we're essentially going to generate the yaml",
    "start": "2312000",
    "end": "2318560"
  },
  {
    "text": "that is exactly the one that corresponds to asking the Dr uh the Dr augmented",
    "start": "2318560",
    "end": "2324760"
  },
  {
    "text": "scheduler to give you the the size of the slice that we want right yeah thank you",
    "start": "2324760",
    "end": "2332400"
  }
]
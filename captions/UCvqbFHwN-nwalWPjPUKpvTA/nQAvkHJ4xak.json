[
  {
    "start": "0",
    "end": "0"
  },
  {
    "text": "welcome everyone",
    "start": "160",
    "end": "3120"
  },
  {
    "text": "today i'll be talking about how to keep",
    "start": "3120",
    "end": "5520"
  },
  {
    "text": "calm and container deon",
    "start": "5520",
    "end": "7839"
  },
  {
    "text": "my name is anusha raghunathan and i'm a",
    "start": "7839",
    "end": "10400"
  },
  {
    "text": "principal software engineer at intuit",
    "start": "10400",
    "end": "14639"
  },
  {
    "text": "introvid is a fintech company that makes",
    "start": "14639",
    "end": "18400"
  },
  {
    "text": "software around",
    "start": "18400",
    "end": "19920"
  },
  {
    "text": "tax preparation",
    "start": "19920",
    "end": "21920"
  },
  {
    "text": "accounting",
    "start": "21920",
    "end": "23439"
  },
  {
    "text": "consumer credit reports and stuff",
    "start": "23439",
    "end": "26080"
  },
  {
    "text": "so if you've ever used turbotax mint",
    "start": "26080",
    "end": "28560"
  },
  {
    "text": "credit karma or quickbooks then that's",
    "start": "28560",
    "end": "31519"
  },
  {
    "text": "us",
    "start": "31519",
    "end": "33679"
  },
  {
    "text": "the agenda for today is basically",
    "start": "35200",
    "end": "37680"
  },
  {
    "text": "starting off with why why are we even",
    "start": "37680",
    "end": "40239"
  },
  {
    "text": "doing this talk",
    "start": "40239",
    "end": "41600"
  },
  {
    "text": "what is the background what are cris",
    "start": "41600",
    "end": "44559"
  },
  {
    "text": "then we'll do",
    "start": "44559",
    "end": "45680"
  },
  {
    "text": "a section on how we went ahead planning",
    "start": "45680",
    "end": "48160"
  },
  {
    "text": "the migration to this new cri",
    "start": "48160",
    "end": "51680"
  },
  {
    "text": "what happened during our great migration",
    "start": "51680",
    "end": "54879"
  },
  {
    "text": "and some performance analysis that we",
    "start": "54879",
    "end": "56640"
  },
  {
    "text": "did with the new cri and finally finish",
    "start": "56640",
    "end": "59520"
  },
  {
    "text": "it off with takeaways",
    "start": "59520",
    "end": "62480"
  },
  {
    "text": "before we get started i want to give a",
    "start": "64479",
    "end": "66640"
  },
  {
    "text": "quick intro",
    "start": "66640",
    "end": "68400"
  },
  {
    "text": "introduction about our kubernetes based",
    "start": "68400",
    "end": "70720"
  },
  {
    "text": "infrastructure we run about 220 plus",
    "start": "70720",
    "end": "74320"
  },
  {
    "text": "clusters",
    "start": "74320",
    "end": "75759"
  },
  {
    "text": "and",
    "start": "75759",
    "end": "76880"
  },
  {
    "text": "they average about 16 000 nodes and this",
    "start": "76880",
    "end": "79280"
  },
  {
    "text": "number of nodes actually goes up pretty",
    "start": "79280",
    "end": "81439"
  },
  {
    "text": "high during our tax peak seasons",
    "start": "81439",
    "end": "84159"
  },
  {
    "text": "and a number of kubernetes namespaces",
    "start": "84159",
    "end": "86159"
  },
  {
    "text": "roughly about 15 000 and odd",
    "start": "86159",
    "end": "89280"
  },
  {
    "text": "we run about 2000 production services on",
    "start": "89280",
    "end": "91520"
  },
  {
    "text": "this kubernetes-based infrastructure",
    "start": "91520",
    "end": "93439"
  },
  {
    "text": "serving about 5000 developers",
    "start": "93439",
    "end": "96479"
  },
  {
    "text": "and we have about 17 000 assets that we",
    "start": "96479",
    "end": "99360"
  },
  {
    "text": "manage with this",
    "start": "99360",
    "end": "101439"
  },
  {
    "text": "and each kubernetes cluster runs about",
    "start": "101439",
    "end": "104799"
  },
  {
    "text": "25 add-ons on top of the vanilla",
    "start": "104799",
    "end": "107840"
  },
  {
    "text": "kubernetes cluster we get",
    "start": "107840",
    "end": "109840"
  },
  {
    "text": "these are primarily around security and",
    "start": "109840",
    "end": "112720"
  },
  {
    "text": "compliance cluster life cycle management",
    "start": "112720",
    "end": "116159"
  },
  {
    "text": "i want to",
    "start": "116159",
    "end": "117200"
  },
  {
    "text": "call out our keiko proj which is a",
    "start": "117200",
    "end": "119280"
  },
  {
    "text": "intuit uh started",
    "start": "119280",
    "end": "121280"
  },
  {
    "text": "open source project that manages our",
    "start": "121280",
    "end": "123759"
  },
  {
    "text": "cluster add-ons instance management",
    "start": "123759",
    "end": "126000"
  },
  {
    "text": "upgrade management and stuff",
    "start": "126000",
    "end": "128479"
  },
  {
    "text": "then we have add-ons around",
    "start": "128479",
    "end": "130399"
  },
  {
    "text": "observability metrics tracing and",
    "start": "130399",
    "end": "132720"
  },
  {
    "text": "logging",
    "start": "132720",
    "end": "134080"
  },
  {
    "text": "networking cni and service mesh",
    "start": "134080",
    "end": "136720"
  },
  {
    "text": "storage",
    "start": "136720",
    "end": "138720"
  },
  {
    "text": "reliability testing around chaos",
    "start": "138720",
    "end": "140400"
  },
  {
    "text": "experiments",
    "start": "140400",
    "end": "141599"
  },
  {
    "text": "and finally container native workflow",
    "start": "141599",
    "end": "144160"
  },
  {
    "text": "engines",
    "start": "144160",
    "end": "145520"
  },
  {
    "text": "specifically argo workflows",
    "start": "145520",
    "end": "149120"
  },
  {
    "start": "149000",
    "end": "149000"
  },
  {
    "text": "now what's a cri",
    "start": "150000",
    "end": "152239"
  },
  {
    "text": "a cri is a container runtime interface",
    "start": "152239",
    "end": "155440"
  },
  {
    "text": "and kubernetes has interfaces for",
    "start": "155440",
    "end": "159599"
  },
  {
    "text": "running your storage and running your",
    "start": "159599",
    "end": "161440"
  },
  {
    "text": "network container networking using cni",
    "start": "161440",
    "end": "163840"
  },
  {
    "text": "and csi",
    "start": "163840",
    "end": "165040"
  },
  {
    "text": "similar to that",
    "start": "165040",
    "end": "166319"
  },
  {
    "text": "for running a container and doing some",
    "start": "166319",
    "end": "168800"
  },
  {
    "text": "image management there is a cri",
    "start": "168800",
    "end": "171280"
  },
  {
    "text": "interface that the kubelet calls out to",
    "start": "171280",
    "end": "174879"
  },
  {
    "text": "and a high level container runtime like",
    "start": "174879",
    "end": "177200"
  },
  {
    "text": "docker shim or container d manages of",
    "start": "177200",
    "end": "180319"
  },
  {
    "text": "containers and images life cycle of them",
    "start": "180319",
    "end": "183519"
  },
  {
    "text": "and in in in turn calls out to a low",
    "start": "183519",
    "end": "186959"
  },
  {
    "text": "level container runtime such as run c",
    "start": "186959",
    "end": "190720"
  },
  {
    "text": "and a cri is a well established uh",
    "start": "190720",
    "end": "192959"
  },
  {
    "text": "interface that the kublet calls over",
    "start": "192959",
    "end": "195840"
  },
  {
    "text": "and it's grpc based and",
    "start": "195840",
    "end": "199120"
  },
  {
    "text": "examples of container runtimes like i",
    "start": "199120",
    "end": "200640"
  },
  {
    "text": "mentioned docker shim cryo and container",
    "start": "200640",
    "end": "202879"
  },
  {
    "text": "d",
    "start": "202879",
    "end": "204080"
  },
  {
    "text": "now why is it that we're talking about",
    "start": "204080",
    "end": "206239"
  },
  {
    "text": "container d and cri and stuff at this",
    "start": "206239",
    "end": "208879"
  },
  {
    "text": "point in time",
    "start": "208879",
    "end": "210080"
  },
  {
    "text": "typically your average kubernetes",
    "start": "210080",
    "end": "212080"
  },
  {
    "text": "operator doesn't have to worry about",
    "start": "212080",
    "end": "213760"
  },
  {
    "text": "these things",
    "start": "213760",
    "end": "215040"
  },
  {
    "text": "however",
    "start": "215040",
    "end": "216239"
  },
  {
    "text": "now",
    "start": "216239",
    "end": "217200"
  },
  {
    "text": "we have to worry about it because",
    "start": "217200",
    "end": "219440"
  },
  {
    "text": "of something that happened in kubernetes",
    "start": "219440",
    "end": "221760"
  },
  {
    "text": "120",
    "start": "221760",
    "end": "223440"
  },
  {
    "start": "222000",
    "end": "222000"
  },
  {
    "text": "which is the primary container runtime",
    "start": "223440",
    "end": "226000"
  },
  {
    "text": "that was used in kubernetes which was",
    "start": "226000",
    "end": "228159"
  },
  {
    "text": "docker shim got deprecated",
    "start": "228159",
    "end": "231920"
  },
  {
    "text": "and docker just a little bit of history",
    "start": "231920",
    "end": "234640"
  },
  {
    "text": "docker demon was the primary runtime for",
    "start": "234640",
    "end": "237760"
  },
  {
    "text": "kubernetes",
    "start": "237760",
    "end": "239360"
  },
  {
    "text": "but it was not cri compliant mainly",
    "start": "239360",
    "end": "241200"
  },
  {
    "text": "because docker demon was written way",
    "start": "241200",
    "end": "243680"
  },
  {
    "text": "before kubernetes originated so a thin",
    "start": "243680",
    "end": "246959"
  },
  {
    "text": "shim layer was written on top of docker",
    "start": "246959",
    "end": "249519"
  },
  {
    "text": "daemon to make it cri compliant",
    "start": "249519",
    "end": "253040"
  },
  {
    "text": "a problem was the shim struggled to find",
    "start": "253040",
    "end": "255599"
  },
  {
    "text": "maintainer ship",
    "start": "255599",
    "end": "256959"
  },
  {
    "text": "and also there were rising container run",
    "start": "256959",
    "end": "259359"
  },
  {
    "text": "times that were cri compliant",
    "start": "259359",
    "end": "262479"
  },
  {
    "text": "so in kubernetes 120",
    "start": "262479",
    "end": "266000"
  },
  {
    "text": "docker shim was deprecated as the",
    "start": "266000",
    "end": "268080"
  },
  {
    "text": "default uh cri",
    "start": "268080",
    "end": "270720"
  },
  {
    "text": "and in to kubernetes upstream 124 it's",
    "start": "270720",
    "end": "274080"
  },
  {
    "text": "going to be removed that's why we all",
    "start": "274080",
    "end": "276240"
  },
  {
    "text": "have to worry about",
    "start": "276240",
    "end": "277919"
  },
  {
    "text": "the cri runtimes now",
    "start": "277919",
    "end": "281199"
  },
  {
    "start": "281000",
    "end": "281000"
  },
  {
    "text": "so we decided to pick container d as our",
    "start": "281680",
    "end": "284880"
  },
  {
    "text": "cri",
    "start": "284880",
    "end": "286080"
  },
  {
    "text": "run time uh why because docker daemon",
    "start": "286080",
    "end": "289040"
  },
  {
    "text": "eventually calls container id anyway",
    "start": "289040",
    "end": "290960"
  },
  {
    "text": "today even when it's not the shim it's",
    "start": "290960",
    "end": "293120"
  },
  {
    "text": "not the cri",
    "start": "293120",
    "end": "294560"
  },
  {
    "text": "and it's been battle tested really well",
    "start": "294560",
    "end": "297120"
  },
  {
    "text": "and it offers better performance in",
    "start": "297120",
    "end": "299360"
  },
  {
    "text": "terms of cpu memory consumption as well",
    "start": "299360",
    "end": "301840"
  },
  {
    "text": "as pod startup times",
    "start": "301840",
    "end": "303840"
  },
  {
    "text": "and it's supported by our cloud provider",
    "start": "303840",
    "end": "305759"
  },
  {
    "text": "so we went with it it was an easy choice",
    "start": "305759",
    "end": "310400"
  },
  {
    "start": "310000",
    "end": "310000"
  },
  {
    "text": "uh this is a quick comparison about the",
    "start": "310400",
    "end": "313199"
  },
  {
    "text": "container runtime invocation between",
    "start": "313199",
    "end": "315280"
  },
  {
    "text": "docker shim and container d you will",
    "start": "315280",
    "end": "318000"
  },
  {
    "text": "notice that in docker shim we have the",
    "start": "318000",
    "end": "320560"
  },
  {
    "text": "extra hops between dock kubelet",
    "start": "320560",
    "end": "324720"
  },
  {
    "text": "and docker shim and eventually",
    "start": "324720",
    "end": "326960"
  },
  {
    "text": "reading up to container d on the right",
    "start": "326960",
    "end": "329120"
  },
  {
    "text": "side you will notice that the kubelet",
    "start": "329120",
    "end": "331039"
  },
  {
    "text": "directly calls container d and the extra",
    "start": "331039",
    "end": "333840"
  },
  {
    "text": "hops are eliminated",
    "start": "333840",
    "end": "337240"
  },
  {
    "text": "so how did we go about planning our",
    "start": "338240",
    "end": "340080"
  },
  {
    "text": "migration",
    "start": "340080",
    "end": "342720"
  },
  {
    "text": "first you need to understand the cri",
    "start": "343120",
    "end": "345120"
  },
  {
    "text": "wiring in your cluster look at your",
    "start": "345120",
    "end": "347280"
  },
  {
    "text": "worker nodes and see how many places you",
    "start": "347280",
    "end": "349759"
  },
  {
    "text": "have docker",
    "start": "349759",
    "end": "351199"
  },
  {
    "text": "daemon docker shim sockets being exposed",
    "start": "351199",
    "end": "353759"
  },
  {
    "text": "to all of your cluster components",
    "start": "353759",
    "end": "356479"
  },
  {
    "text": "in our clay in our case the blue docker",
    "start": "356479",
    "end": "359360"
  },
  {
    "text": "veil in the middle is actually the heart",
    "start": "359360",
    "end": "362319"
  },
  {
    "text": "of a lot of things",
    "start": "362319",
    "end": "364080"
  },
  {
    "text": "and it was exposing docker shim and",
    "start": "364080",
    "end": "366560"
  },
  {
    "text": "docker",
    "start": "366560",
    "end": "367680"
  },
  {
    "text": "docker shim socket as well as docker",
    "start": "367680",
    "end": "369360"
  },
  {
    "text": "demon socket and um if you look at the",
    "start": "369360",
    "end": "372960"
  },
  {
    "text": "bottom of this diagram there is a box",
    "start": "372960",
    "end": "375120"
  },
  {
    "text": "with all our add-ons that were actually",
    "start": "375120",
    "end": "376880"
  },
  {
    "text": "relying on a cri socket",
    "start": "376880",
    "end": "379919"
  },
  {
    "text": "namely the cni",
    "start": "379919",
    "end": "382319"
  },
  {
    "text": "chaos engineering toolkits falco add-on",
    "start": "382319",
    "end": "385280"
  },
  {
    "text": "which we use for security scanning for",
    "start": "385280",
    "end": "387120"
  },
  {
    "text": "our container runtime images as well as",
    "start": "387120",
    "end": "390160"
  },
  {
    "text": "argo workflow controller",
    "start": "390160",
    "end": "392800"
  },
  {
    "text": "the other obvious clients of docker uh",
    "start": "392800",
    "end": "395199"
  },
  {
    "text": "daemon where the kublet uh making the",
    "start": "395199",
    "end": "398160"
  },
  {
    "text": "client connection through grpc as well",
    "start": "398160",
    "end": "400800"
  },
  {
    "text": "as docker cli and api",
    "start": "400800",
    "end": "404560"
  },
  {
    "text": "the",
    "start": "404880",
    "end": "406000"
  },
  {
    "text": "settings on the left side",
    "start": "406000",
    "end": "408720"
  },
  {
    "text": "were mainly around docker daemon",
    "start": "408720",
    "end": "410960"
  },
  {
    "text": "configuration and",
    "start": "410960",
    "end": "413199"
  },
  {
    "text": "as you might see there is sc linux",
    "start": "413199",
    "end": "415440"
  },
  {
    "text": "policies that we were writing based on",
    "start": "415440",
    "end": "417919"
  },
  {
    "text": "docker daemon",
    "start": "417919",
    "end": "419520"
  },
  {
    "text": "gpu configurations for our ml workloads",
    "start": "419520",
    "end": "422080"
  },
  {
    "text": "as well as container log management",
    "start": "422080",
    "end": "426080"
  },
  {
    "text": "and",
    "start": "426080",
    "end": "427280"
  },
  {
    "text": "another indirect uh",
    "start": "427280",
    "end": "429599"
  },
  {
    "text": "dependency that we had was that",
    "start": "429599",
    "end": "432240"
  },
  {
    "text": "we were expecting the container logs to",
    "start": "432240",
    "end": "434319"
  },
  {
    "text": "be in json format which was offered by",
    "start": "434319",
    "end": "437120"
  },
  {
    "text": "docker daemon",
    "start": "437120",
    "end": "438720"
  },
  {
    "text": "and we were using fluently to ship them",
    "start": "438720",
    "end": "441120"
  },
  {
    "text": "out",
    "start": "441120",
    "end": "443120"
  },
  {
    "text": "so we had to rewire our worker nodes to",
    "start": "443120",
    "end": "446560"
  },
  {
    "text": "use",
    "start": "446560",
    "end": "447680"
  },
  {
    "text": "container d or other mechanisms when we",
    "start": "447680",
    "end": "450160"
  },
  {
    "text": "had to migrate",
    "start": "450160",
    "end": "452639"
  },
  {
    "start": "452000",
    "end": "452000"
  },
  {
    "text": "here is uh how we rewired container d",
    "start": "452639",
    "end": "456960"
  },
  {
    "text": "so",
    "start": "456960",
    "end": "458560"
  },
  {
    "text": "we",
    "start": "458560",
    "end": "459280"
  },
  {
    "text": "mainly baked the container d client",
    "start": "459280",
    "end": "462000"
  },
  {
    "text": "which was the cry cuddle client which",
    "start": "462000",
    "end": "463680"
  },
  {
    "text": "worked out well for us",
    "start": "463680",
    "end": "465680"
  },
  {
    "text": "and uh the cricket client would talk to",
    "start": "465680",
    "end": "468720"
  },
  {
    "text": "the",
    "start": "468720",
    "end": "469680"
  },
  {
    "text": "container d socket and um",
    "start": "469680",
    "end": "473520"
  },
  {
    "text": "the continuity socket was also used to",
    "start": "473520",
    "end": "475680"
  },
  {
    "text": "communicate with our add-ons in the",
    "start": "475680",
    "end": "477599"
  },
  {
    "text": "bottom so the cni chaos",
    "start": "477599",
    "end": "481280"
  },
  {
    "text": "falco plug-ins all ended up working",
    "start": "481280",
    "end": "483440"
  },
  {
    "text": "really well with our",
    "start": "483440",
    "end": "485520"
  },
  {
    "text": "new container id",
    "start": "485520",
    "end": "487440"
  },
  {
    "text": "situation",
    "start": "487440",
    "end": "489039"
  },
  {
    "text": "and notice that the",
    "start": "489039",
    "end": "491360"
  },
  {
    "text": "container d config file now actually",
    "start": "491360",
    "end": "493919"
  },
  {
    "text": "still continues to take gpu config and",
    "start": "493919",
    "end": "496160"
  },
  {
    "text": "sc linux but the container log",
    "start": "496160",
    "end": "498800"
  },
  {
    "text": "management has now moved to the kubelet",
    "start": "498800",
    "end": "501440"
  },
  {
    "text": "so it's no longer maintained in",
    "start": "501440",
    "end": "503120"
  },
  {
    "text": "container d you just have to configure",
    "start": "503120",
    "end": "504960"
  },
  {
    "text": "your kubelet um accordingly",
    "start": "504960",
    "end": "508479"
  },
  {
    "text": "also notice that our argo workflow",
    "start": "508479",
    "end": "510720"
  },
  {
    "text": "controller is not dependent on",
    "start": "510720",
    "end": "512880"
  },
  {
    "text": "continuity socket anymore",
    "start": "512880",
    "end": "515120"
  },
  {
    "text": "our workflow controller had a dependency",
    "start": "515120",
    "end": "517760"
  },
  {
    "text": "on docker",
    "start": "517760",
    "end": "519039"
  },
  {
    "text": "mainly because uh it needed a primitive",
    "start": "519039",
    "end": "521440"
  },
  {
    "text": "to share the container name spaces two",
    "start": "521440",
    "end": "524080"
  },
  {
    "text": "containers needed to have uh the same",
    "start": "524080",
    "end": "526320"
  },
  {
    "text": "process uh namespace and",
    "start": "526320",
    "end": "529120"
  },
  {
    "text": "we were now able to use the kubelet",
    "start": "529120",
    "end": "531440"
  },
  {
    "text": "because kubelet provides process",
    "start": "531440",
    "end": "532800"
  },
  {
    "text": "namespace sharing so our dependency on",
    "start": "532800",
    "end": "535440"
  },
  {
    "text": "the container runtime",
    "start": "535440",
    "end": "537519"
  },
  {
    "text": "was removed and now we had a dependency",
    "start": "537519",
    "end": "539279"
  },
  {
    "text": "on kubelet",
    "start": "539279",
    "end": "541600"
  },
  {
    "text": "and finally",
    "start": "541600",
    "end": "543360"
  },
  {
    "text": "the dependency i was talking about as",
    "start": "543360",
    "end": "545360"
  },
  {
    "text": "far as the json log format was",
    "start": "545360",
    "end": "548880"
  },
  {
    "text": "that container d doesn't have a concept",
    "start": "548880",
    "end": "551360"
  },
  {
    "text": "of logging plugins and it was only",
    "start": "551360",
    "end": "554160"
  },
  {
    "text": "logging container logs in text format",
    "start": "554160",
    "end": "557680"
  },
  {
    "text": "and we'll see what happens because of",
    "start": "557680",
    "end": "559360"
  },
  {
    "text": "that in a bit",
    "start": "559360",
    "end": "562920"
  },
  {
    "text": "a word about container",
    "start": "563040",
    "end": "565519"
  },
  {
    "text": "declined cry cuddle we baked it",
    "start": "565519",
    "end": "567680"
  },
  {
    "text": "basically we baked this client basically",
    "start": "567680",
    "end": "569920"
  },
  {
    "text": "into all of our worker nodes",
    "start": "569920",
    "end": "572480"
  },
  {
    "text": "and for the most part we were able to",
    "start": "572480",
    "end": "574640"
  },
  {
    "text": "actually find parity with the docker api",
    "start": "574640",
    "end": "577200"
  },
  {
    "text": "cli main handy commands that we would",
    "start": "577200",
    "end": "580160"
  },
  {
    "text": "use for cryker ps krakatoa images uh",
    "start": "580160",
    "end": "583519"
  },
  {
    "text": "instead of docker inspect if you were",
    "start": "583519",
    "end": "586000"
  },
  {
    "text": "used to using docker inspect you could",
    "start": "586000",
    "end": "587600"
  },
  {
    "text": "do the same thing with krakatoa get info",
    "start": "587600",
    "end": "589440"
  },
  {
    "text": "which was used in our use case primarily",
    "start": "589440",
    "end": "592320"
  },
  {
    "text": "to work around",
    "start": "592320",
    "end": "594000"
  },
  {
    "text": "sc linux policies so you can actually",
    "start": "594000",
    "end": "596720"
  },
  {
    "text": "explore more on cry cuttle um as your",
    "start": "596720",
    "end": "599920"
  },
  {
    "text": "cri continuity client",
    "start": "599920",
    "end": "603120"
  },
  {
    "text": "we couldn't find exact parity for some",
    "start": "603120",
    "end": "605279"
  },
  {
    "text": "of the uh use cases uh one thing i would",
    "start": "605279",
    "end": "608240"
  },
  {
    "text": "like to call out is the docker system",
    "start": "608240",
    "end": "610880"
  },
  {
    "text": "prune command that we were used to for",
    "start": "610880",
    "end": "613200"
  },
  {
    "text": "actually cleaning up leaky containers",
    "start": "613200",
    "end": "615680"
  },
  {
    "text": "um",
    "start": "615680",
    "end": "616560"
  },
  {
    "text": "again since docker was more than just a",
    "start": "616560",
    "end": "618959"
  },
  {
    "text": "cri",
    "start": "618959",
    "end": "620320"
  },
  {
    "text": "he did a lot more than just container",
    "start": "620320",
    "end": "622560"
  },
  {
    "text": "and edge management um so assist system",
    "start": "622560",
    "end": "625440"
  },
  {
    "text": "prune we had to find uh like some hacky",
    "start": "625440",
    "end": "628720"
  },
  {
    "text": "bash scripting and cron jobs on top of",
    "start": "628720",
    "end": "630880"
  },
  {
    "text": "cry cuddle and we were able to get it",
    "start": "630880",
    "end": "632480"
  },
  {
    "text": "done so the big takeaway is get familiar",
    "start": "632480",
    "end": "634959"
  },
  {
    "text": "with some",
    "start": "634959",
    "end": "636160"
  },
  {
    "text": "container d client and so that it's",
    "start": "636160",
    "end": "638560"
  },
  {
    "text": "helpful during your migration",
    "start": "638560",
    "end": "641839"
  },
  {
    "text": "um another container decline the obvious",
    "start": "642560",
    "end": "644720"
  },
  {
    "text": "one is kublet and",
    "start": "644720",
    "end": "647279"
  },
  {
    "text": "the one thing that was",
    "start": "647279",
    "end": "649680"
  },
  {
    "text": "handy again for us during our migration",
    "start": "649680",
    "end": "651839"
  },
  {
    "text": "is that kublet actually can be",
    "start": "651839",
    "end": "653839"
  },
  {
    "text": "configured to have a different cri",
    "start": "653839",
    "end": "657040"
  },
  {
    "text": "in this case the options are container",
    "start": "657040",
    "end": "658480"
  },
  {
    "text": "runtime and container runtime",
    "start": "658480",
    "end": "661360"
  },
  {
    "text": "socket where you could actually spin up",
    "start": "661360",
    "end": "663200"
  },
  {
    "text": "a test cluster today",
    "start": "663200",
    "end": "665440"
  },
  {
    "text": "by setting these options and you will",
    "start": "665440",
    "end": "667360"
  },
  {
    "text": "get a container d",
    "start": "667360",
    "end": "668800"
  },
  {
    "text": "cluster so it's easy to just basically",
    "start": "668800",
    "end": "671680"
  },
  {
    "text": "jump start on it and see which part of",
    "start": "671680",
    "end": "673760"
  },
  {
    "text": "your bootstrap code you need to be",
    "start": "673760",
    "end": "675760"
  },
  {
    "text": "changing in order to actually perform",
    "start": "675760",
    "end": "677680"
  },
  {
    "text": "your migration",
    "start": "677680",
    "end": "679519"
  },
  {
    "text": "and like i mentioned earlier now log",
    "start": "679519",
    "end": "681519"
  },
  {
    "text": "management has moved from the cri to",
    "start": "681519",
    "end": "684320"
  },
  {
    "text": "kubelet so",
    "start": "684320",
    "end": "685600"
  },
  {
    "text": "you can get familiar with the log",
    "start": "685600",
    "end": "687279"
  },
  {
    "text": "rotation options for max size as well as",
    "start": "687279",
    "end": "690240"
  },
  {
    "text": "max",
    "start": "690240",
    "end": "691120"
  },
  {
    "text": "files",
    "start": "691120",
    "end": "693519"
  },
  {
    "start": "694000",
    "end": "694000"
  },
  {
    "text": "all right",
    "start": "694800",
    "end": "696480"
  },
  {
    "text": "so we planned our",
    "start": "696480",
    "end": "699680"
  },
  {
    "text": "migration we made all the code changes",
    "start": "699680",
    "end": "702160"
  },
  {
    "text": "that were required in our cluster",
    "start": "702160",
    "end": "703839"
  },
  {
    "text": "bootstrapper we had reconfigured things",
    "start": "703839",
    "end": "706720"
  },
  {
    "text": "to um use the container d configuration",
    "start": "706720",
    "end": "709760"
  },
  {
    "text": "rather than docker",
    "start": "709760",
    "end": "711519"
  },
  {
    "text": "and all our add-ons um that code was",
    "start": "711519",
    "end": "714560"
  },
  {
    "text": "also changed to accommodate for",
    "start": "714560",
    "end": "718240"
  },
  {
    "text": "container d a lot of our end user teams",
    "start": "718240",
    "end": "720480"
  },
  {
    "text": "and our platform teams had also migrated",
    "start": "720480",
    "end": "722959"
  },
  {
    "text": "their code path",
    "start": "722959",
    "end": "724720"
  },
  {
    "text": "so",
    "start": "724720",
    "end": "726320"
  },
  {
    "text": "one thing i would like to mention here",
    "start": "726320",
    "end": "728160"
  },
  {
    "text": "is that at into it we",
    "start": "728160",
    "end": "730480"
  },
  {
    "text": "go through monthly cluster upgrade",
    "start": "730480",
    "end": "732639"
  },
  {
    "text": "cycles mainly for security and",
    "start": "732639",
    "end": "735360"
  },
  {
    "text": "compliance reasons as well as a time to",
    "start": "735360",
    "end": "738320"
  },
  {
    "text": "actually introduce new features to our",
    "start": "738320",
    "end": "739920"
  },
  {
    "text": "kubernetes platform",
    "start": "739920",
    "end": "741680"
  },
  {
    "text": "and this is",
    "start": "741680",
    "end": "742720"
  },
  {
    "text": "the time when we actually migrated from",
    "start": "742720",
    "end": "745200"
  },
  {
    "text": "docker d to container d",
    "start": "745200",
    "end": "748240"
  },
  {
    "text": "and one thing to note that is that we",
    "start": "748240",
    "end": "750079"
  },
  {
    "text": "perform rolling upgrades of our clusters",
    "start": "750079",
    "end": "753120"
  },
  {
    "text": "which means that you started out with",
    "start": "753120",
    "end": "754800"
  },
  {
    "text": "docker as your cri for your cluster and",
    "start": "754800",
    "end": "757519"
  },
  {
    "text": "then you ended up with container d a cri",
    "start": "757519",
    "end": "760000"
  },
  {
    "text": "but then there is a period of time",
    "start": "760000",
    "end": "762560"
  },
  {
    "text": "during the cluster upgrade where you",
    "start": "762560",
    "end": "765040"
  },
  {
    "text": "have a mix of both what kinds of nodes",
    "start": "765040",
    "end": "767279"
  },
  {
    "text": "in your cluster",
    "start": "767279",
    "end": "768959"
  },
  {
    "text": "and",
    "start": "768959",
    "end": "769839"
  },
  {
    "text": "we guarantee to our end user developers",
    "start": "769839",
    "end": "773440"
  },
  {
    "text": "that there will be zero downtime during",
    "start": "773440",
    "end": "776160"
  },
  {
    "text": "the upgrade",
    "start": "776160",
    "end": "778560"
  },
  {
    "text": "so",
    "start": "778560",
    "end": "779279"
  },
  {
    "text": "we planned and planned and we did the",
    "start": "779279",
    "end": "781120"
  },
  {
    "text": "right things",
    "start": "781120",
    "end": "782959"
  },
  {
    "text": "any guesses on whether it went uh smooth",
    "start": "782959",
    "end": "786560"
  },
  {
    "text": "or did we have any gotchas",
    "start": "786560",
    "end": "790000"
  },
  {
    "text": "well of course we had gotchas",
    "start": "790639",
    "end": "793600"
  },
  {
    "text": "and i'm gonna be talking about uh two of",
    "start": "793600",
    "end": "795920"
  },
  {
    "text": "them today",
    "start": "795920",
    "end": "797920"
  },
  {
    "text": "first was about the logging pipeline",
    "start": "797920",
    "end": "802320"
  },
  {
    "text": "now before we get into the details of",
    "start": "802320",
    "end": "805200"
  },
  {
    "start": "804000",
    "end": "804000"
  },
  {
    "text": "the problem and how we solve for it",
    "start": "805200",
    "end": "807600"
  },
  {
    "text": "um a quick refresher on our logging",
    "start": "807600",
    "end": "810000"
  },
  {
    "text": "pipeline",
    "start": "810000",
    "end": "811200"
  },
  {
    "text": "we use fluentd as our node",
    "start": "811200",
    "end": "814560"
  },
  {
    "text": "driver for logging",
    "start": "814560",
    "end": "816959"
  },
  {
    "text": "and a fluent is responsible for log",
    "start": "816959",
    "end": "819839"
  },
  {
    "text": "collection",
    "start": "819839",
    "end": "821120"
  },
  {
    "text": "log parsing if it's needed as well as",
    "start": "821120",
    "end": "823360"
  },
  {
    "text": "shipping it to our log aggregator which",
    "start": "823360",
    "end": "825519"
  },
  {
    "text": "is splunk",
    "start": "825519",
    "end": "827839"
  },
  {
    "text": "um fluently takes care of shipping",
    "start": "827839",
    "end": "829839"
  },
  {
    "text": "pretty much all the logs uh in our nodes",
    "start": "829839",
    "end": "832079"
  },
  {
    "text": "but the critical ones are container logs",
    "start": "832079",
    "end": "834720"
  },
  {
    "text": "and we cannot afford to miss even a",
    "start": "834720",
    "end": "836639"
  },
  {
    "text": "small gap of logs",
    "start": "836639",
    "end": "838720"
  },
  {
    "text": "so log loss was not a is a big no-no in",
    "start": "838720",
    "end": "841600"
  },
  {
    "text": "our infrastructure",
    "start": "841600",
    "end": "843839"
  },
  {
    "text": "and fluvindi runs as a daemon set and",
    "start": "843839",
    "end": "845920"
  },
  {
    "text": "it's a cluster add-on",
    "start": "845920",
    "end": "849120"
  },
  {
    "start": "849000",
    "end": "849000"
  },
  {
    "text": "so what is the first problem well",
    "start": "849519",
    "end": "853199"
  },
  {
    "text": "our entire logging pipeline had the",
    "start": "853199",
    "end": "855600"
  },
  {
    "text": "assumption of",
    "start": "855600",
    "end": "857279"
  },
  {
    "text": "json formatted container logs",
    "start": "857279",
    "end": "860959"
  },
  {
    "text": "and container d basically broke that",
    "start": "860959",
    "end": "863279"
  },
  {
    "text": "assumption",
    "start": "863279",
    "end": "865360"
  },
  {
    "text": "right from container logs to fluency to",
    "start": "865360",
    "end": "868880"
  },
  {
    "text": "our",
    "start": "868880",
    "end": "870560"
  },
  {
    "text": "to how it reaches our",
    "start": "870560",
    "end": "872959"
  },
  {
    "text": "splunk servers everything was expected",
    "start": "872959",
    "end": "875120"
  },
  {
    "text": "to be in json format",
    "start": "875120",
    "end": "877440"
  },
  {
    "text": "and this was because uh json offered",
    "start": "877440",
    "end": "879839"
  },
  {
    "text": "better performance as opposed to other",
    "start": "879839",
    "end": "881440"
  },
  {
    "text": "formats that we had considered before",
    "start": "881440",
    "end": "884720"
  },
  {
    "text": "and",
    "start": "884720",
    "end": "886320"
  },
  {
    "text": "what happened was because of this change",
    "start": "886320",
    "end": "888639"
  },
  {
    "text": "in this uh log format there was log loss",
    "start": "888639",
    "end": "891839"
  },
  {
    "text": "because there were portions of our",
    "start": "891839",
    "end": "893839"
  },
  {
    "text": "pipeline that did not recognize formats",
    "start": "893839",
    "end": "895920"
  },
  {
    "text": "and we ended up with log losses and like",
    "start": "895920",
    "end": "899199"
  },
  {
    "text": "i said this was a big no-no",
    "start": "899199",
    "end": "901279"
  },
  {
    "text": "and how did we solve it",
    "start": "901279",
    "end": "904639"
  },
  {
    "start": "904000",
    "end": "904000"
  },
  {
    "text": "well luckily",
    "start": "904639",
    "end": "907120"
  },
  {
    "text": "even though container logs were in text",
    "start": "907120",
    "end": "910079"
  },
  {
    "text": "format",
    "start": "910079",
    "end": "911120"
  },
  {
    "text": "there there is a",
    "start": "911120",
    "end": "912720"
  },
  {
    "text": "predefined specification for the format",
    "start": "912720",
    "end": "916399"
  },
  {
    "text": "which is a time stamp",
    "start": "916399",
    "end": "919279"
  },
  {
    "text": "the stream",
    "start": "919279",
    "end": "920639"
  },
  {
    "text": "tag and the actual log message and they",
    "start": "920639",
    "end": "922959"
  },
  {
    "text": "were all space delimited",
    "start": "922959",
    "end": "925519"
  },
  {
    "text": "and",
    "start": "925519",
    "end": "926399"
  },
  {
    "text": "we could",
    "start": "926399",
    "end": "927519"
  },
  {
    "text": "pretty much use fluency configuration to",
    "start": "927519",
    "end": "929839"
  },
  {
    "text": "actually parse it out using a regex",
    "start": "929839",
    "end": "934079"
  },
  {
    "text": "so that's precisely what we did",
    "start": "934079",
    "end": "937519"
  },
  {
    "text": "what we did was we changed our bootstrap",
    "start": "937519",
    "end": "939360"
  },
  {
    "text": "code to",
    "start": "939360",
    "end": "941440"
  },
  {
    "text": "make sure that each node came up with",
    "start": "941440",
    "end": "943600"
  },
  {
    "text": "the cri runtime that was nes that was",
    "start": "943600",
    "end": "946160"
  },
  {
    "text": "running that node and our fluency",
    "start": "946160",
    "end": "949120"
  },
  {
    "text": "bootstrap container would read that file",
    "start": "949120",
    "end": "952639"
  },
  {
    "text": "and load up the right fluency config map",
    "start": "952639",
    "end": "956240"
  },
  {
    "text": "for docker it remained the same json",
    "start": "956240",
    "end": "959120"
  },
  {
    "text": "based configurations but for container d",
    "start": "959120",
    "end": "962399"
  },
  {
    "text": "it was a regex parser that would extract",
    "start": "962399",
    "end": "965199"
  },
  {
    "text": "out the log message and eventually send",
    "start": "965199",
    "end": "967519"
  },
  {
    "text": "it out to splunk",
    "start": "967519",
    "end": "970560"
  },
  {
    "text": "the one thing to note that is",
    "start": "970959",
    "end": "973440"
  },
  {
    "text": "with this approach we did observe a 17",
    "start": "973440",
    "end": "976720"
  },
  {
    "text": "dip in performance of log throughput",
    "start": "976720",
    "end": "979519"
  },
  {
    "text": "that was sent out and this was because",
    "start": "979519",
    "end": "981600"
  },
  {
    "text": "of the additional regex overhead that we",
    "start": "981600",
    "end": "984240"
  },
  {
    "text": "were seeing",
    "start": "984240",
    "end": "985519"
  },
  {
    "text": "with fluency",
    "start": "985519",
    "end": "988320"
  },
  {
    "text": "what was the second problem",
    "start": "988880",
    "end": "990959"
  },
  {
    "start": "989000",
    "end": "989000"
  },
  {
    "text": "well",
    "start": "990959",
    "end": "992000"
  },
  {
    "text": "the way our cluster upgrades work is",
    "start": "992000",
    "end": "994160"
  },
  {
    "text": "that",
    "start": "994160",
    "end": "995040"
  },
  {
    "text": "the nodes are rotated out first and then",
    "start": "995040",
    "end": "998560"
  },
  {
    "text": "the add-ons are upgraded",
    "start": "998560",
    "end": "1001759"
  },
  {
    "text": "and what was happening was there was a",
    "start": "1001759",
    "end": "1003680"
  },
  {
    "text": "period of time when the nodes were",
    "start": "1003680",
    "end": "1005040"
  },
  {
    "text": "rotated out and the new cri was coming",
    "start": "1005040",
    "end": "1007440"
  },
  {
    "text": "in place",
    "start": "1007440",
    "end": "1008560"
  },
  {
    "text": "but fluency still did not recognize",
    "start": "1008560",
    "end": "1011440"
  },
  {
    "text": "that",
    "start": "1011440",
    "end": "1012320"
  },
  {
    "text": "they need it needed to do the",
    "start": "1012320",
    "end": "1013519"
  },
  {
    "text": "bootstrapping changes we had made as a",
    "start": "1013519",
    "end": "1015839"
  },
  {
    "text": "result there was again log loss during",
    "start": "1015839",
    "end": "1017839"
  },
  {
    "text": "that period of time when the clusters",
    "start": "1017839",
    "end": "1019360"
  },
  {
    "text": "were getting upgraded",
    "start": "1019360",
    "end": "1022399"
  },
  {
    "text": "so how did we solve it it was pretty",
    "start": "1022639",
    "end": "1024240"
  },
  {
    "text": "simple we just got our code for the",
    "start": "1024240",
    "end": "1026798"
  },
  {
    "start": "1025000",
    "end": "1025000"
  },
  {
    "text": "platform uh the release before the",
    "start": "1026799",
    "end": "1029360"
  },
  {
    "text": "actual migration to container d so that",
    "start": "1029360",
    "end": "1032319"
  },
  {
    "text": "that that was one big takeaway for us is",
    "start": "1032319",
    "end": "1034480"
  },
  {
    "text": "you have to actually not just make all",
    "start": "1034480",
    "end": "1036880"
  },
  {
    "text": "the wiring changes you have to actually",
    "start": "1036880",
    "end": "1038880"
  },
  {
    "text": "get it in a release one release at least",
    "start": "1038880",
    "end": "1042400"
  },
  {
    "text": "n minus one release before your actual",
    "start": "1042400",
    "end": "1044720"
  },
  {
    "text": "cri migration",
    "start": "1044720",
    "end": "1047678"
  },
  {
    "text": "the second gotcha i'm going to talk",
    "start": "1049360",
    "end": "1050880"
  },
  {
    "text": "about today is regarding cni",
    "start": "1050880",
    "end": "1054160"
  },
  {
    "text": "again a quick refresher",
    "start": "1054160",
    "end": "1057600"
  },
  {
    "text": "the cni that we were using along with",
    "start": "1057760",
    "end": "1060320"
  },
  {
    "text": "pod and",
    "start": "1060320",
    "end": "1062320"
  },
  {
    "text": "host networking stack wiring for",
    "start": "1062320",
    "end": "1064840"
  },
  {
    "text": "um for canada networking also took care",
    "start": "1064840",
    "end": "1068160"
  },
  {
    "text": "of ipam daemon so basically the ipam",
    "start": "1068160",
    "end": "1070799"
  },
  {
    "text": "daemon was like this",
    "start": "1070799",
    "end": "1072720"
  },
  {
    "text": "local host demon",
    "start": "1072720",
    "end": "1074400"
  },
  {
    "text": "that was responsible for two things one",
    "start": "1074400",
    "end": "1076799"
  },
  {
    "text": "maintaining a warm pool of ip addresses",
    "start": "1076799",
    "end": "1079679"
  },
  {
    "text": "to hand out to",
    "start": "1079679",
    "end": "1081039"
  },
  {
    "text": "pods and also taking care of allocating",
    "start": "1081039",
    "end": "1083200"
  },
  {
    "text": "and deallocating ip addresses",
    "start": "1083200",
    "end": "1086240"
  },
  {
    "text": "for the pods",
    "start": "1086240",
    "end": "1087440"
  },
  {
    "text": "and for ip allocation and deallocation",
    "start": "1087440",
    "end": "1089440"
  },
  {
    "text": "it would query the cri socket",
    "start": "1089440",
    "end": "1092160"
  },
  {
    "text": "to get a list of running pods",
    "start": "1092160",
    "end": "1095600"
  },
  {
    "text": "and cni was running as a daemon set in",
    "start": "1095600",
    "end": "1098480"
  },
  {
    "text": "all our cluster nodes",
    "start": "1098480",
    "end": "1101600"
  },
  {
    "start": "1102000",
    "end": "1102000"
  },
  {
    "text": "so what was the problem",
    "start": "1102400",
    "end": "1104480"
  },
  {
    "text": "well to prepare our cni for our cr",
    "start": "1104480",
    "end": "1107840"
  },
  {
    "text": "container d migration we had actually",
    "start": "1107840",
    "end": "1109679"
  },
  {
    "text": "mounted container d socket",
    "start": "1109679",
    "end": "1111840"
  },
  {
    "text": "uh in the cni pod spec as expected from",
    "start": "1111840",
    "end": "1114880"
  },
  {
    "text": "our cni vendor",
    "start": "1114880",
    "end": "1116640"
  },
  {
    "text": "and cni is actually a bootstrap add-on",
    "start": "1116640",
    "end": "1119760"
  },
  {
    "text": "for us so in this case the bootstrap",
    "start": "1119760",
    "end": "1122240"
  },
  {
    "text": "add-ons get rotate like upgraded before",
    "start": "1122240",
    "end": "1125120"
  },
  {
    "text": "the nodes get rotated out",
    "start": "1125120",
    "end": "1127520"
  },
  {
    "text": "so you can see the problem right this",
    "start": "1127520",
    "end": "1130320"
  },
  {
    "text": "meant that like a node would a docker",
    "start": "1130320",
    "end": "1133280"
  },
  {
    "text": "node would still be running but the",
    "start": "1133280",
    "end": "1136720"
  },
  {
    "text": "cni would think that this was container",
    "start": "1136720",
    "end": "1139200"
  },
  {
    "text": "e",
    "start": "1139200",
    "end": "1139919"
  },
  {
    "text": "um node and it would query the",
    "start": "1139919",
    "end": "1142160"
  },
  {
    "text": "continuity socket get an empty list of",
    "start": "1142160",
    "end": "1144640"
  },
  {
    "text": "pods and voila it would be like okay",
    "start": "1144640",
    "end": "1147120"
  },
  {
    "text": "this node doesn't need any more ips so",
    "start": "1147120",
    "end": "1149520"
  },
  {
    "text": "let me start de-allocating from",
    "start": "1149520",
    "end": "1151600"
  },
  {
    "text": "uh the docker pods which were actually",
    "start": "1151600",
    "end": "1154000"
  },
  {
    "text": "live and running so",
    "start": "1154000",
    "end": "1155919"
  },
  {
    "text": "this was again a big no-no for us",
    "start": "1155919",
    "end": "1159200"
  },
  {
    "text": "so how did we solve it",
    "start": "1159200",
    "end": "1161919"
  },
  {
    "start": "1161000",
    "end": "1161000"
  },
  {
    "text": "well",
    "start": "1161919",
    "end": "1162799"
  },
  {
    "text": "we created a generic sim link for",
    "start": "1162799",
    "end": "1166799"
  },
  {
    "text": "whether it's a c a container d socket or",
    "start": "1166799",
    "end": "1169120"
  },
  {
    "text": "a docker socket",
    "start": "1169120",
    "end": "1170640"
  },
  {
    "text": "in our bootstrap code",
    "start": "1170640",
    "end": "1172160"
  },
  {
    "text": "so if a node came up with docker daemon",
    "start": "1172160",
    "end": "1174799"
  },
  {
    "text": "then",
    "start": "1174799",
    "end": "1176000"
  },
  {
    "text": "this generic dot sock would actually",
    "start": "1176000",
    "end": "1178240"
  },
  {
    "text": "point to that",
    "start": "1178240",
    "end": "1179440"
  },
  {
    "text": "if it came up with a container d then it",
    "start": "1179440",
    "end": "1181919"
  },
  {
    "text": "would point to canadian id dot stock",
    "start": "1181919",
    "end": "1184480"
  },
  {
    "text": "and uh",
    "start": "1184480",
    "end": "1185679"
  },
  {
    "text": "the cra stock was actually mounted into",
    "start": "1185679",
    "end": "1187600"
  },
  {
    "text": "our pots",
    "start": "1187600",
    "end": "1188799"
  },
  {
    "text": "cni parts spec",
    "start": "1188799",
    "end": "1190559"
  },
  {
    "text": "and we made sure that again that these",
    "start": "1190559",
    "end": "1193200"
  },
  {
    "text": "changes got into a release prior to the",
    "start": "1193200",
    "end": "1196480"
  },
  {
    "text": "actual migration because you had to",
    "start": "1196480",
    "end": "1198160"
  },
  {
    "text": "prepare your cni a code to handle this",
    "start": "1198160",
    "end": "1202080"
  },
  {
    "text": "before the actual migration",
    "start": "1202080",
    "end": "1205960"
  },
  {
    "text": "all right let's talk about performance",
    "start": "1206000",
    "end": "1209760"
  },
  {
    "text": "we had already",
    "start": "1210400",
    "end": "1212000"
  },
  {
    "text": "set expectations",
    "start": "1212000",
    "end": "1213679"
  },
  {
    "text": "that",
    "start": "1213679",
    "end": "1214640"
  },
  {
    "text": "pod startup times and cpu memory",
    "start": "1214640",
    "end": "1216960"
  },
  {
    "text": "consumption for pods would be lesser in",
    "start": "1216960",
    "end": "1218799"
  },
  {
    "text": "containery but we wanted to actually",
    "start": "1218799",
    "end": "1220559"
  },
  {
    "text": "verify that",
    "start": "1220559",
    "end": "1221919"
  },
  {
    "text": "and see how much of a performance and",
    "start": "1221919",
    "end": "1224080"
  },
  {
    "text": "gain we get",
    "start": "1224080",
    "end": "1226880"
  },
  {
    "start": "1227000",
    "end": "1227000"
  },
  {
    "text": "so",
    "start": "1227600",
    "end": "1228559"
  },
  {
    "text": "our setup was running docker",
    "start": "1228559",
    "end": "1231159"
  },
  {
    "text": "19.3 and container d146 on kubernetes",
    "start": "1231159",
    "end": "1235120"
  },
  {
    "text": "121",
    "start": "1235120",
    "end": "1237120"
  },
  {
    "text": "and the test service is a java spring",
    "start": "1237120",
    "end": "1239760"
  },
  {
    "text": "boot application that very closely",
    "start": "1239760",
    "end": "1242240"
  },
  {
    "text": "mimics our developer environments",
    "start": "1242240",
    "end": "1246080"
  },
  {
    "text": "and our test line generates about 6000",
    "start": "1246080",
    "end": "1248880"
  },
  {
    "text": "transactions per second and these",
    "start": "1248880",
    "end": "1250559"
  },
  {
    "text": "transactions are mostly a combination of",
    "start": "1250559",
    "end": "1253760"
  },
  {
    "text": "reads and writes into a memory heavy um",
    "start": "1253760",
    "end": "1256960"
  },
  {
    "text": "like memory heavy",
    "start": "1256960",
    "end": "1258880"
  },
  {
    "text": "uh load",
    "start": "1258880",
    "end": "1260240"
  },
  {
    "text": "a graphql in memory database calls",
    "start": "1260240",
    "end": "1264400"
  },
  {
    "text": "and um the test was set up to actually",
    "start": "1264400",
    "end": "1267120"
  },
  {
    "text": "ramp up for the first 16 minutes and",
    "start": "1267120",
    "end": "1269200"
  },
  {
    "text": "then have a steady load of about",
    "start": "1269200",
    "end": "1271760"
  },
  {
    "text": "6000 transactions per second for the for",
    "start": "1271760",
    "end": "1274640"
  },
  {
    "text": "two hours and we started with an hpa uh",
    "start": "1274640",
    "end": "1279520"
  },
  {
    "text": "replica of count three",
    "start": "1279520",
    "end": "1283039"
  },
  {
    "text": "how did we do in this",
    "start": "1283039",
    "end": "1286080"
  },
  {
    "start": "1285000",
    "end": "1285000"
  },
  {
    "text": "well uh",
    "start": "1286080",
    "end": "1287679"
  },
  {
    "text": "continuity definitely fed well",
    "start": "1287679",
    "end": "1290880"
  },
  {
    "text": "especially in the startup times we",
    "start": "1290880",
    "end": "1292799"
  },
  {
    "text": "noticed that containery startup time",
    "start": "1292799",
    "end": "1295440"
  },
  {
    "text": "maximum",
    "start": "1295440",
    "end": "1296799"
  },
  {
    "text": "latency was only about 120 seconds in",
    "start": "1296799",
    "end": "1299760"
  },
  {
    "text": "our synthetic workload as opposed to",
    "start": "1299760",
    "end": "1301919"
  },
  {
    "text": "docker",
    "start": "1301919",
    "end": "1303039"
  },
  {
    "text": "which which took about 200 seconds and",
    "start": "1303039",
    "end": "1305679"
  },
  {
    "text": "we're pretty excited about this",
    "start": "1305679",
    "end": "1307200"
  },
  {
    "text": "performance game because",
    "start": "1307200",
    "end": "1309200"
  },
  {
    "text": "it will come in handy during our tax",
    "start": "1309200",
    "end": "1311120"
  },
  {
    "text": "peak seasons when there is very",
    "start": "1311120",
    "end": "1313840"
  },
  {
    "text": "high hpa kicks in and we have a lot of",
    "start": "1313840",
    "end": "1316480"
  },
  {
    "text": "replicas running at the same time and",
    "start": "1316480",
    "end": "1318640"
  },
  {
    "text": "startup times really matter",
    "start": "1318640",
    "end": "1321919"
  },
  {
    "text": "and",
    "start": "1321919",
    "end": "1322720"
  },
  {
    "text": "during the steady state of about 120",
    "start": "1322720",
    "end": "1325440"
  },
  {
    "text": "minutes we noticed that because of a",
    "start": "1325440",
    "end": "1327760"
  },
  {
    "text": "lower slightly lower cpu consumption",
    "start": "1327760",
    "end": "1330640"
  },
  {
    "text": "there was lesser number of pod and node",
    "start": "1330640",
    "end": "1333520"
  },
  {
    "text": "usage because it like it was just a",
    "start": "1333520",
    "end": "1336480"
  },
  {
    "text": "slightly more efficient and hp doesn't",
    "start": "1336480",
    "end": "1338799"
  },
  {
    "text": "kick in for a slightly longer than when",
    "start": "1338799",
    "end": "1341360"
  },
  {
    "text": "compared to docker",
    "start": "1341360",
    "end": "1344080"
  },
  {
    "text": "so",
    "start": "1345440",
    "end": "1347039"
  },
  {
    "text": "i'm going to wrap it up with some",
    "start": "1347039",
    "end": "1348240"
  },
  {
    "text": "takeaways",
    "start": "1348240",
    "end": "1350799"
  },
  {
    "start": "1351000",
    "end": "1351000"
  },
  {
    "text": "understand your cluster cri wiring this",
    "start": "1351600",
    "end": "1354960"
  },
  {
    "text": "was our use case where we thought we",
    "start": "1354960",
    "end": "1357039"
  },
  {
    "text": "could just start off with a simple",
    "start": "1357039",
    "end": "1358400"
  },
  {
    "text": "migration from docker to container d it",
    "start": "1358400",
    "end": "1360799"
  },
  {
    "text": "turned out to be",
    "start": "1360799",
    "end": "1362159"
  },
  {
    "text": "a",
    "start": "1362159",
    "end": "1362960"
  },
  {
    "text": "several month project for us",
    "start": "1362960",
    "end": "1365280"
  },
  {
    "text": "so understand your cri wiring",
    "start": "1365280",
    "end": "1368320"
  },
  {
    "text": "and plan to test co and verify ahead of",
    "start": "1368320",
    "end": "1371360"
  },
  {
    "text": "time because kubernetes 124 is coming up",
    "start": "1371360",
    "end": "1374640"
  },
  {
    "text": "and there will not be a docker shim",
    "start": "1374640",
    "end": "1376320"
  },
  {
    "text": "anymore",
    "start": "1376320",
    "end": "1377760"
  },
  {
    "text": "and",
    "start": "1377760",
    "end": "1378880"
  },
  {
    "text": "the third big takeaway for us is",
    "start": "1378880",
    "end": "1382000"
  },
  {
    "text": "you have to account for live cluster",
    "start": "1382000",
    "end": "1383760"
  },
  {
    "text": "migration if you have a big big platform",
    "start": "1383760",
    "end": "1386720"
  },
  {
    "text": "like us for us with the 220 plus",
    "start": "1386720",
    "end": "1389120"
  },
  {
    "text": "clusters we had and with zero downtime",
    "start": "1389120",
    "end": "1392480"
  },
  {
    "text": "you had to we had to make sure that",
    "start": "1392480",
    "end": "1395120"
  },
  {
    "text": "all the live migration use cases were",
    "start": "1395120",
    "end": "1397200"
  },
  {
    "text": "handled",
    "start": "1397200",
    "end": "1399679"
  },
  {
    "text": "thank you very much and we are hiring at",
    "start": "1400240",
    "end": "1403039"
  },
  {
    "text": "introvid so if you're interested please",
    "start": "1403039",
    "end": "1404480"
  },
  {
    "text": "come and talk to me and i can take some",
    "start": "1404480",
    "end": "1406159"
  },
  {
    "text": "questions now",
    "start": "1406159",
    "end": "1408100"
  },
  {
    "text": "[Applause]",
    "start": "1408100",
    "end": "1417148"
  },
  {
    "text": "okay",
    "start": "1428640",
    "end": "1429760"
  },
  {
    "text": "hello uh you mentioned that your cni",
    "start": "1429760",
    "end": "1433360"
  },
  {
    "text": "needs access to the docker socket right",
    "start": "1433360",
    "end": "1435760"
  },
  {
    "text": "yes and do do you know if the docker",
    "start": "1435760",
    "end": "1438880"
  },
  {
    "text": "socket",
    "start": "1438880",
    "end": "1439919"
  },
  {
    "text": "if the container this socket is",
    "start": "1439919",
    "end": "1441679"
  },
  {
    "text": "compatible like fully compatible or you",
    "start": "1441679",
    "end": "1444480"
  },
  {
    "text": "need to change your cni codes to read it",
    "start": "1444480",
    "end": "1447360"
  },
  {
    "text": "in a different format",
    "start": "1447360",
    "end": "1449279"
  },
  {
    "text": "so the cni stock the cni basically",
    "start": "1449279",
    "end": "1452240"
  },
  {
    "text": "queries the cri socket mainly to get a",
    "start": "1452240",
    "end": "1456000"
  },
  {
    "text": "list of",
    "start": "1456000",
    "end": "1457039"
  },
  {
    "text": "containers and parts so that it can",
    "start": "1457039",
    "end": "1458799"
  },
  {
    "text": "actually do ip allocation",
    "start": "1458799",
    "end": "1460960"
  },
  {
    "text": "so",
    "start": "1460960",
    "end": "1461840"
  },
  {
    "text": "as far as compatibility goes it's a it's",
    "start": "1461840",
    "end": "1465279"
  },
  {
    "text": "the interface is pretty well established",
    "start": "1465279",
    "end": "1467120"
  },
  {
    "text": "and to what it is expected so we didn't",
    "start": "1467120",
    "end": "1469200"
  },
  {
    "text": "see any compatibility issues there",
    "start": "1469200",
    "end": "1472559"
  },
  {
    "text": "it was more around the live migration",
    "start": "1472559",
    "end": "1474720"
  },
  {
    "text": "where our cni did not account for both",
    "start": "1474720",
    "end": "1477760"
  },
  {
    "text": "set of",
    "start": "1477760",
    "end": "1479200"
  },
  {
    "text": "cris to be available at a particular",
    "start": "1479200",
    "end": "1481360"
  },
  {
    "text": "point in a cluster upgrade situation",
    "start": "1481360",
    "end": "1486600"
  },
  {
    "text": "just a question about the gpu you see in",
    "start": "1497039",
    "end": "1499200"
  },
  {
    "text": "the description you hit some issue with",
    "start": "1499200",
    "end": "1501520"
  },
  {
    "text": "gpu can you say more about that please",
    "start": "1501520",
    "end": "1504159"
  },
  {
    "text": "so the gpu issue was about so",
    "start": "1504159",
    "end": "1508880"
  },
  {
    "text": "it's more about a vendor issue more than",
    "start": "1508880",
    "end": "1510559"
  },
  {
    "text": "a container issue so",
    "start": "1510559",
    "end": "1513039"
  },
  {
    "text": "we get our gpu support from nvidia and",
    "start": "1513039",
    "end": "1516400"
  },
  {
    "text": "our cloud provider is aws",
    "start": "1516400",
    "end": "1519120"
  },
  {
    "text": "and uh",
    "start": "1519120",
    "end": "1521679"
  },
  {
    "text": "the issue there was",
    "start": "1521679",
    "end": "1523919"
  },
  {
    "text": "the nvidia gpu operator out there for",
    "start": "1523919",
    "end": "1526400"
  },
  {
    "text": "container id doesn't work out of the box",
    "start": "1526400",
    "end": "1528320"
  },
  {
    "text": "for aws",
    "start": "1528320",
    "end": "1531200"
  },
  {
    "text": "it's mainly around os support",
    "start": "1531679",
    "end": "1534799"
  },
  {
    "text": "so we had to work closely with aws to",
    "start": "1534799",
    "end": "1537440"
  },
  {
    "text": "actually get a separate recipe and",
    "start": "1537440",
    "end": "1540720"
  },
  {
    "text": "bake it into our amis",
    "start": "1540720",
    "end": "1542720"
  },
  {
    "text": "and the other uh sort of glitch in there",
    "start": "1542720",
    "end": "1545440"
  },
  {
    "text": "was the",
    "start": "1545440",
    "end": "1547360"
  },
  {
    "text": "end user license agreement between",
    "start": "1547360",
    "end": "1549120"
  },
  {
    "text": "nvidia and aws had to be sorted out",
    "start": "1549120",
    "end": "1552480"
  },
  {
    "text": "so",
    "start": "1552480",
    "end": "1553679"
  },
  {
    "text": "so far uh we've done some preliminary",
    "start": "1553679",
    "end": "1555919"
  },
  {
    "text": "testing with gpu there have been no",
    "start": "1555919",
    "end": "1557600"
  },
  {
    "text": "issues with container d although we",
    "start": "1557600",
    "end": "1559039"
  },
  {
    "text": "haven't gone fully production with it",
    "start": "1559039",
    "end": "1562639"
  },
  {
    "text": "but i think if you have nvidia a gpu",
    "start": "1566000",
    "end": "1568640"
  },
  {
    "text": "operator running on",
    "start": "1568640",
    "end": "1570400"
  },
  {
    "text": "centos",
    "start": "1570400",
    "end": "1572720"
  },
  {
    "text": "and or ubuntu",
    "start": "1572720",
    "end": "1574480"
  },
  {
    "text": "then you have out of the box support",
    "start": "1574480",
    "end": "1578760"
  },
  {
    "text": "all right thank you everyone",
    "start": "1588480",
    "end": "1590660"
  },
  {
    "text": "[Applause]",
    "start": "1590660",
    "end": "1595739"
  }
]
[
  {
    "text": "um I'd like to thank everyone who is joining us today welcome to today CN CF",
    "start": "0",
    "end": "5940"
  },
  {
    "text": "webinar Data Services for cloud native workloads my name is ariel j'tia i'm",
    "start": "5940",
    "end": "11940"
  },
  {
    "text": "business development manager at happen to CN CF ambassador I'll be moderating today's webinar we'd like to welcome our",
    "start": "11940",
    "end": "19020"
  },
  {
    "text": "presenters today of a thing founding engineer and architect that diamonte show coma Jana member the",
    "start": "19020",
    "end": "25949"
  },
  {
    "text": "technical staff and Narendra director of product marketing before we get started",
    "start": "25949",
    "end": "33239"
  },
  {
    "text": "just a few housekeeping items during the webinar you're not going to be able to talk as an attendee there is a Q&A box",
    "start": "33239",
    "end": "40350"
  },
  {
    "text": "that you're gonna see at the bottom of your screen please feel free to drop your question in there and we'll get to",
    "start": "40350",
    "end": "46289"
  },
  {
    "text": "as many as we can at the end this is an official webinar at the CN CF",
    "start": "46289",
    "end": "53129"
  },
  {
    "text": "and as such is subject to the CN CF code of conduct please do not say anything or to the chat or the questions that would",
    "start": "53129",
    "end": "59699"
  },
  {
    "text": "be in violation of that code of conduct basically please be respectful of all your fellow participants and presenters",
    "start": "59699",
    "end": "66710"
  },
  {
    "text": "also please note that our recording and slides will be posted today later on the",
    "start": "66710",
    "end": "72060"
  },
  {
    "text": "CNC half webinar page at CMC f dot io forward slash webinars and with that",
    "start": "72060",
    "end": "77580"
  },
  {
    "text": "I'll hand over I'll hand it over to the team from the Amonte kick off today's presentation all right Thank You Ariel",
    "start": "77580",
    "end": "87869"
  },
  {
    "text": "good morning everyone thank you all for joining us in these busy times the hope",
    "start": "87869",
    "end": "93960"
  },
  {
    "text": "everyone is staying safe let's get started just a quick intro I'm up here a",
    "start": "93960",
    "end": "103110"
  },
  {
    "text": "passing founding in your architected diamonte we have Lorraine from product",
    "start": "103110",
    "end": "108899"
  },
  {
    "text": "marketing and she'll Paul so from technical team engineering team I'll",
    "start": "108899",
    "end": "115500"
  },
  {
    "text": "quickly go over the agenda so in today's",
    "start": "115500",
    "end": "121409"
  },
  {
    "text": "webinar I'm going to start with some cloud native fundamentals before getting into data services and recovery point or",
    "start": "121409",
    "end": "129090"
  },
  {
    "text": "recovery time objectives these services provide data services that I'm going to talk about",
    "start": "129090",
    "end": "135180"
  },
  {
    "text": "today are the services that protects data against any kind of failure it could be a software failure heart",
    "start": "135180",
    "end": "141180"
  },
  {
    "text": "failure node failure network failure data center and so on data center failure and so on and we'll also see why",
    "start": "141180",
    "end": "150420"
  },
  {
    "text": "it's critical for storage architecture to adhere to crawl native principles for these data services well after that",
    "start": "150420",
    "end": "160290"
  },
  {
    "text": "we'll go with few demos that Shilpa is going to help me with and followed by a",
    "start": "160290",
    "end": "166129"
  },
  {
    "text": "Q&A okay these are the cloud native",
    "start": "166129",
    "end": "179069"
  },
  {
    "text": "storage fundamentals that I'm gonna briefly talk about scaling resiliency",
    "start": "179069",
    "end": "184349"
  },
  {
    "text": "isolation tearing and mobility and how they're how storage architectures should",
    "start": "184349",
    "end": "191909"
  },
  {
    "text": "take care of these fundamentals at architectural architecture level so one",
    "start": "191909",
    "end": "205379"
  },
  {
    "text": "of the fundamentals are scaling releases because the need application may require",
    "start": "205379",
    "end": "212269"
  },
  {
    "text": "the need for resources as well as I ops",
    "start": "212269",
    "end": "219209"
  },
  {
    "text": "and bandwidth can go up and down depending on the need of application so",
    "start": "219209",
    "end": "224940"
  },
  {
    "text": "underlying storage infrastructure should be able to provide that support so when we talk about getting a lot of times",
    "start": "224940",
    "end": "233669"
  },
  {
    "text": "people talk about creating multiple replicas replicas and it should",
    "start": "233669",
    "end": "238739"
  },
  {
    "text": "basically scale scale out rather in other words scale out however that",
    "start": "238739",
    "end": "244409"
  },
  {
    "text": "doesn't complete the whole story the specifically for a stateful application",
    "start": "244409",
    "end": "250530"
  },
  {
    "text": "story completes if underlying storage infrastructure can also scale up the eye",
    "start": "250530",
    "end": "257909"
  },
  {
    "text": "ops or bandwidth needed for the application whenever whenever it is whenever it is needed",
    "start": "257909",
    "end": "265039"
  },
  {
    "text": "so when we talk about scaling it's both in terms of capacity as well as",
    "start": "266030",
    "end": "271570"
  },
  {
    "text": "performance provision die-offs we should be able to scale up and down are",
    "start": "271570",
    "end": "277700"
  },
  {
    "text": "depending on the need the next is resiliency microservices can",
    "start": "277700",
    "end": "286580"
  },
  {
    "text": "fail and restart so the restart could be",
    "start": "286580",
    "end": "291590"
  },
  {
    "text": "on a different note could be in a different zone different data centers so there has to be some data service at the",
    "start": "291590",
    "end": "299720"
  },
  {
    "text": "back that provides data access whenever whenever and wherever application or micro service comes up anything that can",
    "start": "299720",
    "end": "309530"
  },
  {
    "text": "fail will fail at some point of time so our infrastructure should be able to to",
    "start": "309530",
    "end": "315620"
  },
  {
    "text": "have those things built in to provide the required resiliency it's a not only",
    "start": "315620",
    "end": "323690"
  },
  {
    "text": "micro service but any of the components can fail a node can fail Drive can fail",
    "start": "323690",
    "end": "330820"
  },
  {
    "text": "so in order to have the data available we need these data services at services",
    "start": "330820",
    "end": "339860"
  },
  {
    "text": "to support resiliency of resiliency for micro services the next is isolation the",
    "start": "339860",
    "end": "350210"
  },
  {
    "text": "whole premise of cloud native is we",
    "start": "350210",
    "end": "355910"
  },
  {
    "text": "share the common infrastructure and variety of applications can run on the same infrastructure which means",
    "start": "355910",
    "end": "362290"
  },
  {
    "text": "applications with different kind of higher loads different requirements will",
    "start": "362290",
    "end": "367760"
  },
  {
    "text": "be running on the same infrastructure they would be sharing the same node same",
    "start": "367760",
    "end": "375380"
  },
  {
    "text": "CPUs same PCI lanes all the way to say maybe same set of drives so noisy",
    "start": "375380",
    "end": "381680"
  },
  {
    "text": "neighbor a problem is is really complex to address and it's very important to",
    "start": "381680",
    "end": "388370"
  },
  {
    "text": "address for such environments",
    "start": "388370",
    "end": "392590"
  },
  {
    "text": "it may for security we we may require for volume encryption because there can",
    "start": "396020",
    "end": "403050"
  },
  {
    "text": "be multiple tenants running on the same infrastructure so you may need to secure",
    "start": "403050",
    "end": "408139"
  },
  {
    "text": "each and every a tenant or each for for that matter each and every volume",
    "start": "408139",
    "end": "413960"
  },
  {
    "text": "independently with their own keys to the",
    "start": "413960",
    "end": "423120"
  },
  {
    "text": "next clearing some applications may",
    "start": "423120",
    "end": "430460"
  },
  {
    "text": "require high excess high level of access another application may require medium",
    "start": "430460",
    "end": "436380"
  },
  {
    "text": "or low there are multiple ways to look at this problem one a lot of people solve this problem",
    "start": "436380",
    "end": "444180"
  },
  {
    "text": "by media type so anything that is a high priority or requires a low latency",
    "start": "444180",
    "end": "451770"
  },
  {
    "text": "access would be located from at least from the storage perspective would be located on flash secondary data could be",
    "start": "451770",
    "end": "461520"
  },
  {
    "text": "located on on hard drives or could be",
    "start": "461520",
    "end": "466590"
  },
  {
    "text": "located far what we believe is in",
    "start": "466590",
    "end": "472760"
  },
  {
    "text": "standardizing the infrastructure and virtualizing the tiers so the same",
    "start": "472760",
    "end": "479010"
  },
  {
    "text": "infrastructure is used for all kind of applications and what what can be done",
    "start": "479010",
    "end": "484500"
  },
  {
    "text": "is tears can be virtualized so high tier application can get let's say 40k 50k",
    "start": "484500",
    "end": "492360"
  },
  {
    "text": "100k I ops that can be a meteor which main gates say 10 to 20 ki ops low tier",
    "start": "492360",
    "end": "500039"
  },
  {
    "text": "can get 1 1 K - 2 K ions but everything is running on the same",
    "start": "500039",
    "end": "505289"
  },
  {
    "text": "infrastructure the underlying the storage layer takes care of the tearing",
    "start": "505289",
    "end": "512539"
  },
  {
    "text": "so we believe that nvme is the new set up earlier the quality of drives were",
    "start": "512539",
    "end": "520020"
  },
  {
    "text": "defined by let's say rpm 15k rpm 10k 5k and now that has kind of transitions to",
    "start": "520020",
    "end": "527820"
  },
  {
    "text": "a number of bribe writes per day so for example 10 Drive rights per day 5 1 and so on so it can be virtualized up",
    "start": "527820",
    "end": "538410"
  },
  {
    "text": "to that layer 2 up to that level 2 so for one application a volume can be",
    "start": "538410",
    "end": "543480"
  },
  {
    "text": "provided that supports 10 rights a day for example for another application it",
    "start": "543480",
    "end": "550790"
  },
  {
    "text": "virtualized volume can provide one right try today and students classes have been",
    "start": "550790",
    "end": "560250"
  },
  {
    "text": "designed to do same so these things can be configured using a storage classes in kubernetes environments so the last one",
    "start": "560250",
    "end": "570110"
  },
  {
    "text": "that I'm going to touch on is mobility so application mobility requires",
    "start": "570110",
    "end": "577890"
  },
  {
    "text": "efficient data mobility as well in case of multi zone clusters the data or data",
    "start": "577890",
    "end": "586170"
  },
  {
    "text": "could be sitting in two zones could be in two different rooms in the same data",
    "start": "586170",
    "end": "593400"
  },
  {
    "text": "center or completely two different data centers in case of failure or whenever I know whenever an application needs to",
    "start": "593400",
    "end": "600300"
  },
  {
    "text": "move to another data center that the data has to be available there so it",
    "start": "600300",
    "end": "606870"
  },
  {
    "text": "requires efficient migration and replication solutions or services at",
    "start": "606870",
    "end": "612150"
  },
  {
    "text": "storage layer so another way to look at",
    "start": "612150",
    "end": "617490"
  },
  {
    "text": "it as for some of the secondary applications like testin dev or",
    "start": "617490",
    "end": "624570"
  },
  {
    "text": "analytics you a user may more require to move the data to a different cluster and",
    "start": "624570",
    "end": "631010"
  },
  {
    "text": "run their run their workload however if",
    "start": "631010",
    "end": "636290"
  },
  {
    "text": "underlying infrastructure itself provides isolation and tearing that I just talked about then maybe those",
    "start": "636290",
    "end": "642900"
  },
  {
    "text": "secondary applications can run directly on the same infrastructure without affecting primary applications and their",
    "start": "642900",
    "end": "649830"
  },
  {
    "text": "performance right so in that case there",
    "start": "649830",
    "end": "657450"
  },
  {
    "text": "may not be it may not be needed to copy the data to another place for these applications",
    "start": "657450",
    "end": "662610"
  },
  {
    "text": "or these workloads alright moving",
    "start": "662610",
    "end": "672990"
  },
  {
    "text": "forward so these are the data services",
    "start": "672990",
    "end": "679740"
  },
  {
    "text": "that I'm gonna talk about great mirroring snapshot backup replication",
    "start": "679740",
    "end": "686610"
  },
  {
    "text": "they all have their specific use cases and it's not that I'm not gonna",
    "start": "686610",
    "end": "692779"
  },
  {
    "text": "advertise that you need mirroring it it solves all your problems and the same",
    "start": "692779",
    "end": "698040"
  },
  {
    "text": "for other services too we need we need all and they also different purposes let's take a look at",
    "start": "698040",
    "end": "709230"
  },
  {
    "text": "what kind of ARP you are to you these services provide and and what actually",
    "start": "709230",
    "end": "714540"
  },
  {
    "text": "it means so all these services have a",
    "start": "714540",
    "end": "733890"
  },
  {
    "text": "different schedule traditional tape backup where you move time off off from",
    "start": "733890",
    "end": "739949"
  },
  {
    "text": "Isis the schedule is runs in days or weeks",
    "start": "739949",
    "end": "745279"
  },
  {
    "text": "back up typically done let's say once a",
    "start": "745380",
    "end": "750790"
  },
  {
    "text": "day or so snapshots could have lower",
    "start": "750790",
    "end": "757350"
  },
  {
    "text": "schedule for example a few snapshots every day every four hours or every six",
    "start": "757350",
    "end": "763570"
  },
  {
    "text": "hours the replication is in general when",
    "start": "763570",
    "end": "769270"
  },
  {
    "text": "I say replication I mean as a synchronous replication for synchronous replication I am using the term mirroring here so replication runs",
    "start": "769270",
    "end": "777850"
  },
  {
    "text": "behind typically a few minutes could be 10 15 20 minutes and mirroring is",
    "start": "777850",
    "end": "785950"
  },
  {
    "text": "synchronous so application rights are not acknowledged to the host until it",
    "start": "785950",
    "end": "791050"
  },
  {
    "text": "gets written at all the places so in case of two-way mirror it needs to be",
    "start": "791050",
    "end": "798550"
  },
  {
    "text": "written at both places three-way mirror would require these the data to be written at all three places before",
    "start": "798550",
    "end": "804040"
  },
  {
    "text": "application areas are acknowledged it has latency implications so we do not",
    "start": "804040",
    "end": "811330"
  },
  {
    "text": "recommend mirrors to be separated by long distances the schedule of these",
    "start": "811330",
    "end": "825610"
  },
  {
    "text": "data services defines what kind of recovery point you can achieve if you",
    "start": "825610",
    "end": "834910"
  },
  {
    "text": "need to data from the tape backup the data that you're gonna get is gonna be days behind",
    "start": "834910",
    "end": "840240"
  },
  {
    "text": "depending on when was the last scheduled route a backup the same is for backup",
    "start": "840240",
    "end": "846180"
  },
  {
    "text": "snapshot and replication so going to if",
    "start": "846180",
    "end": "851190"
  },
  {
    "text": "when you go to the last backup that or that basically kind of defines what is the ARP you going to be provided by",
    "start": "851190",
    "end": "857970"
  },
  {
    "text": "these services so how far back you need to go to recover your data RTO defines",
    "start": "857970",
    "end": "870170"
  },
  {
    "text": "how long does it take to recover your data from these data services in case of",
    "start": "870170",
    "end": "882540"
  },
  {
    "text": "traditional tape backup it typically they take days before you can get your",
    "start": "882540",
    "end": "889350"
  },
  {
    "text": "data and have your application up and running disk backup cloud backup also",
    "start": "889350",
    "end": "899790"
  },
  {
    "text": "takes hours before you can populate your data and application can be brought up",
    "start": "899790",
    "end": "905420"
  },
  {
    "text": "snapshot snapshot is interesting because it totally depends on on the",
    "start": "909320",
    "end": "917040"
  },
  {
    "text": "architecture how much are to you you can achieve schedule is in general",
    "start": "917040",
    "end": "922830"
  },
  {
    "text": "configurable every four hours six hours so that defines the ARP you but how long it takes to recover it totally depends",
    "start": "922830",
    "end": "930210"
  },
  {
    "text": "on the central architecture if it will involve state a copy then again it can",
    "start": "930210",
    "end": "935790"
  },
  {
    "text": "take hours before you can bring up your application and recover the data however",
    "start": "935790",
    "end": "942660"
  },
  {
    "text": "an architecture can provide instant restore then you within minutes you can",
    "start": "942660",
    "end": "948840"
  },
  {
    "text": "be up and running",
    "start": "948840",
    "end": "951380"
  },
  {
    "text": "same goes with replication because data is getting replicated to a different",
    "start": "955680",
    "end": "962399"
  },
  {
    "text": "site and data is available it can it will probably be few minutes behind but",
    "start": "962399",
    "end": "969390"
  },
  {
    "text": "it can be brought up application can be brought up within minutes once the failure is detected finally mirroring",
    "start": "969390",
    "end": "981680"
  },
  {
    "text": "mirroring would provide near zero RPO and r2 you near zero ARP you because the",
    "start": "981680",
    "end": "989940"
  },
  {
    "text": "data is sync synchronously getting written to both the places and once the",
    "start": "989940",
    "end": "995610"
  },
  {
    "text": "failure is detected on one site of one's own it can be brought up immediately on",
    "start": "995610",
    "end": "1004100"
  },
  {
    "text": "on the second zone where data is available so for most of",
    "start": "1004100",
    "end": "1024290"
  },
  {
    "text": "data data services that I talked about except mirroring snapshot network",
    "start": "1024290",
    "end": "1029870"
  },
  {
    "text": "technology basically forms the base or core of of the data service backups are",
    "start": "1029870",
    "end": "1037430"
  },
  {
    "text": "typically done on top of snapshot in order to be consistent replication can",
    "start": "1037430",
    "end": "1043430"
  },
  {
    "text": "also be done on top of snapshots there are continuous replication solutions too",
    "start": "1043430",
    "end": "1050630"
  },
  {
    "text": "but if our Pugh requirement is beyond ten minute or 15 minutes for for",
    "start": "1050630",
    "end": "1058340"
  },
  {
    "text": "application then it's typically snapshot based periodically replication is more",
    "start": "1058340",
    "end": "1064880"
  },
  {
    "text": "efficient so snapshot architecture",
    "start": "1064880",
    "end": "1071330"
  },
  {
    "text": "matters for for all these data services and whether we adhere to the",
    "start": "1071330",
    "end": "1079040"
  },
  {
    "text": "coordinative principles is also important for example a snapshot does",
    "start": "1079040",
    "end": "1084500"
  },
  {
    "text": "face optimized that basically defines how much you can scale does it require",
    "start": "1084500",
    "end": "1089990"
  },
  {
    "text": "data copy if it requires data copy then you are in in you may be affecting your",
    "start": "1089990",
    "end": "1097970"
  },
  {
    "text": "primary application as well and it also limits the scaling how fast can data be",
    "start": "1097970",
    "end": "1108170"
  },
  {
    "text": "restored can it provide instant restore so that basically defines the resiliency",
    "start": "1108170",
    "end": "1115250"
  },
  {
    "text": "of the system if it takes hours before you can you can recover your application that's not resilient enough can snapshot",
    "start": "1115250",
    "end": "1125840"
  },
  {
    "text": "exes be a different tier so application is running in a high tier virtualized",
    "start": "1125840",
    "end": "1132530"
  },
  {
    "text": "high tier can another secondary workload whether it's taking the backup or",
    "start": "1132530",
    "end": "1139070"
  },
  {
    "text": "running some kind of test in dev or or analytics application which can run",
    "start": "1139070",
    "end": "1146780"
  },
  {
    "text": "on snapshot can it be provided on a different tier medium or low so that it doesn't affect the primary applications",
    "start": "1146780",
    "end": "1153770"
  },
  {
    "text": "running on the same infrastructure which means basically is your storage",
    "start": "1153770",
    "end": "1160950"
  },
  {
    "text": "infrastructure is providing enough isolation or tearing this edition of",
    "start": "1160950",
    "end": "1168000"
  },
  {
    "text": "snapshots effect parent volumes performance which which basically",
    "start": "1168000",
    "end": "1177210"
  },
  {
    "text": "clearly defined by isolation then both the workloads are actually not isolated",
    "start": "1177210",
    "end": "1182549"
  },
  {
    "text": "from each other so with that I would",
    "start": "1182549",
    "end": "1193440"
  },
  {
    "text": "hand over to Shilpa for for the demos",
    "start": "1193440",
    "end": "1199309"
  },
  {
    "text": "let me stop sharing thanks a by hi",
    "start": "1199309",
    "end": "1211200"
  },
  {
    "text": "everyone this is Shilpa mana today I'll be demonstrating some of the key data",
    "start": "1211200",
    "end": "1217770"
  },
  {
    "text": "service features that are available on diamonte platform first let me share my",
    "start": "1217770",
    "end": "1224130"
  },
  {
    "text": "screen",
    "start": "1224130",
    "end": "1226340"
  },
  {
    "text": "okay first I'll go over the mirroring feature support that we have only a multi-platform so with this you're going",
    "start": "1249620",
    "end": "1256770"
  },
  {
    "text": "to see how a stateful applications can seamlessly failover from one node to",
    "start": "1256770",
    "end": "1262200"
  },
  {
    "text": "another node within the diamante cluster whenever there is a node failure so",
    "start": "1262200",
    "end": "1267419"
  },
  {
    "text": "you're going to see how applications can seamlessly trail over without experiencing any data loss because the",
    "start": "1267419",
    "end": "1274350"
  },
  {
    "text": "data is highly available on the amanti platform for this demo we have a",
    "start": "1274350",
    "end": "1279900"
  },
  {
    "text": "topology set up this way there is a cluster that's already created with multiple nodes there is an application",
    "start": "1279900",
    "end": "1287070"
  },
  {
    "text": "that is running on one of the nodes in the cluster and this application is",
    "start": "1287070",
    "end": "1292409"
  },
  {
    "text": "using a persistent storage on a diamonte volume the volume itself is actually",
    "start": "1292409",
    "end": "1300330"
  },
  {
    "text": "created on two different nodes in the cluster it has two mirrors so whenever the",
    "start": "1300330",
    "end": "1305760"
  },
  {
    "text": "application is performing writes to the volume the storage subsystem ensures",
    "start": "1305760",
    "end": "1311490"
  },
  {
    "text": "that the data is synchronously replicated across both the available mirrors in the cluster so with this in",
    "start": "1311490",
    "end": "1321210"
  },
  {
    "text": "case if there is any node loss in the cluster if a cluster happens to lose a",
    "start": "1321210",
    "end": "1327990"
  },
  {
    "text": "node on which the application is running the application can seamlessly failover",
    "start": "1327990",
    "end": "1333270"
  },
  {
    "text": "to another node where the mirror exists we want to see that the application",
    "start": "1333270",
    "end": "1338549"
  },
  {
    "text": "won't experience any data loss and it can start resuming from where it left",
    "start": "1338549",
    "end": "1344250"
  },
  {
    "text": "off so now I'm gonna start sharing the",
    "start": "1344250",
    "end": "1352620"
  },
  {
    "text": "demo screen or",
    "start": "1352620",
    "end": "1355400"
  },
  {
    "text": "as I mentioned earlier there is already a cluster created this cluster has three",
    "start": "1362889",
    "end": "1368749"
  },
  {
    "text": "nodes here and I've also deployed an application it's a wordpress application",
    "start": "1368749",
    "end": "1375980"
  },
  {
    "text": "that is using my sequel database in that back-end for its persistent storage",
    "start": "1375980",
    "end": "1381730"
  },
  {
    "text": "these volumes are associated with a given BBC's here and let's take a look",
    "start": "1381730",
    "end": "1390139"
  },
  {
    "text": "at the volume that corresponds to my sequel PVC you can see here there are",
    "start": "1390139",
    "end": "1396919"
  },
  {
    "text": "two mirrors for this volume that are created on two different nodes in the cluster application itself is running on",
    "start": "1396919",
    "end": "1405049"
  },
  {
    "text": "apps of 86 and both the mirrors that are available for this volume is kept in",
    "start": "1405049",
    "end": "1411499"
  },
  {
    "text": "sync which means when application is performing writes on this volume the",
    "start": "1411499",
    "end": "1416509"
  },
  {
    "text": "storage subsystem is making sure that the data is kept in sync on both the available copies now let's verify what",
    "start": "1416509",
    "end": "1426379"
  },
  {
    "text": "we have within this application currently I have the applique WordPress",
    "start": "1426379",
    "end": "1432919"
  },
  {
    "text": "application running on this particular IP address so through the browser I'm",
    "start": "1432919",
    "end": "1438230"
  },
  {
    "text": "going to just verify what the application has there is a simple diamonte website created here which is",
    "start": "1438230",
    "end": "1445789"
  },
  {
    "text": "pre-populated with some blogs as you can see there are two blocks created I'm",
    "start": "1445789",
    "end": "1453109"
  },
  {
    "text": "going to create one more block here saying that I'm gonna test application",
    "start": "1453109",
    "end": "1462940"
  },
  {
    "text": "publish the blog let's verify this blog",
    "start": "1464200",
    "end": "1470109"
  },
  {
    "text": "on the website as you can see the new blog that I posted appears on the",
    "start": "1470109",
    "end": "1475820"
  },
  {
    "text": "website the data for this is persistently stored on my sequel database so now I'm gonna simulate a",
    "start": "1475820",
    "end": "1485929"
  },
  {
    "text": "node failure so in order to bring down the node I'm just go to cordon",
    "start": "1485929",
    "end": "1491479"
  },
  {
    "text": "the node on which the application is running and then delete the pods manually absol 86 is Corden and both the",
    "start": "1491479",
    "end": "1504649"
  },
  {
    "text": "pods that are running on this node has been deleted since these pods were created with",
    "start": "1504649",
    "end": "1511009"
  },
  {
    "text": "kubernetes deployment the moment the pods are deleted the deployment controller will automatically create",
    "start": "1511009",
    "end": "1517729"
  },
  {
    "text": "another instance of these spots and this will cause application to failover on",
    "start": "1517729",
    "end": "1523879"
  },
  {
    "text": "any of the available nodes in the cluster now let's verify the status of",
    "start": "1523879",
    "end": "1529969"
  },
  {
    "text": "the new pods that are created as you can see here the new pod both of these pods",
    "start": "1529969",
    "end": "1536089"
  },
  {
    "text": "got failed over two apps of 87 which is where the other mirror existed on the system and there is the same IP address",
    "start": "1536089",
    "end": "1543979"
  },
  {
    "text": "associated with that pod let's verify",
    "start": "1543979",
    "end": "1551269"
  },
  {
    "text": "the content of this application one more time and look at all the blocks as you",
    "start": "1551269",
    "end": "1563119"
  },
  {
    "text": "can see here although the application failed over it didn't have any impact because it has up-to-date data there is",
    "start": "1563119",
    "end": "1573429"
  },
  {
    "text": "no time spent in the recovery of the data so this is how the applications can",
    "start": "1573429",
    "end": "1579200"
  },
  {
    "text": "get an RTO and RPO of zero when there is a mirroring feature enabled on the",
    "start": "1579200",
    "end": "1584809"
  },
  {
    "text": "system so now let's verify this status",
    "start": "1584809",
    "end": "1590959"
  },
  {
    "text": "of the volume that corresponds to the application as you can see here one of",
    "start": "1590959",
    "end": "1598579"
  },
  {
    "text": "the mirror for this volume is in the cat State and the reason for that is AB sub",
    "start": "1598579",
    "end": "1603979"
  },
  {
    "text": "86 was previously cordoned now at the moment I uncoordinated the backing",
    "start": "1603979",
    "end": "1611629"
  },
  {
    "text": "system will start the synchronization of this mirror and it will bring this both",
    "start": "1611629",
    "end": "1617690"
  },
  {
    "text": "the mirrors back in sync let's take a look at the volume stick it",
    "start": "1617690",
    "end": "1624809"
  },
  {
    "text": "was one more time and you can see now both the mirrors are active and both are",
    "start": "1624809",
    "end": "1631920"
  },
  {
    "text": "in sync so this completes the demo that",
    "start": "1631920",
    "end": "1637860"
  },
  {
    "text": "I had for Sigma's mirroring feature let's move on to the next demo so here",
    "start": "1637860",
    "end": "1649770"
  },
  {
    "text": "I'm going to demonstrate how you can instantly restore a volume from a given",
    "start": "1649770",
    "end": "1655260"
  },
  {
    "text": "snapshot a snapshot is a way of providing data protection for volumes",
    "start": "1655260",
    "end": "1661919"
  },
  {
    "text": "within the cluster so when you create a snapshot it actually captures a state of",
    "start": "1661919",
    "end": "1668700"
  },
  {
    "text": "a volume at a specific point in time so this is how the topology looks like for",
    "start": "1668700",
    "end": "1676679"
  },
  {
    "text": "the demo there's an application running which is using a diamante volume for its persistent storage you can actually set",
    "start": "1676679",
    "end": "1684450"
  },
  {
    "text": "up a volume to take periodic snapshots in the cluster at regular intervals and",
    "start": "1684450",
    "end": "1691220"
  },
  {
    "text": "during this time if application accidentally overrides any data within",
    "start": "1691640",
    "end": "1697890"
  },
  {
    "text": "the volume you can still choose to restore this volume for in you from any",
    "start": "1697890",
    "end": "1703950"
  },
  {
    "text": "of the available snapshots in the system so we do have support for something",
    "start": "1703950",
    "end": "1710549"
  },
  {
    "text": "called instant snapshots a restore here there is no time consuming data copy it",
    "start": "1710549",
    "end": "1716130"
  },
  {
    "text": "just happens within few seconds the moment you specify a snapshot for a",
    "start": "1716130",
    "end": "1721380"
  },
  {
    "text": "volume all the data from the snapshot and data will be available on the volume",
    "start": "1721380",
    "end": "1727100"
  },
  {
    "text": "so now let's move on to the demo here and I'll be walking through the steps on",
    "start": "1727100",
    "end": "1734280"
  },
  {
    "text": "how to create a snapshot of a volume and how do we restore that volume from a",
    "start": "1734280",
    "end": "1740190"
  },
  {
    "text": "snapshot again for this demo I am going to use the same cluster and I'm going to",
    "start": "1740190",
    "end": "1750450"
  },
  {
    "text": "take a snapshot of our volume that corresponds to one of this application here",
    "start": "1750450",
    "end": "1755940"
  },
  {
    "text": "in order to create the snapshot I'm going to log on to diamonte UI this is",
    "start": "1755940",
    "end": "1764860"
  },
  {
    "text": "the cluster that I'm trying to operate on so when you look at the list of warnings that it hats",
    "start": "1764860",
    "end": "1770710"
  },
  {
    "text": "it reflects smooth the volumes and is associated with the app here I want to",
    "start": "1770710",
    "end": "1777430"
  },
  {
    "text": "create a snapshot of a volume that corresponds to my sequel PVC so there's",
    "start": "1777430",
    "end": "1783760"
  },
  {
    "text": "an option to create snapshot from the UI here and I can choose on which node I",
    "start": "1783760",
    "end": "1791950"
  },
  {
    "text": "want to create the snapshot on so now",
    "start": "1791950",
    "end": "1801520"
  },
  {
    "text": "you can see there is one snapshot created for this volume let's take a look at the snapshot page here there is",
    "start": "1801520",
    "end": "1808960"
  },
  {
    "text": "a snapshot that's an available state at this point in time this snapshot has all",
    "start": "1808960",
    "end": "1815650"
  },
  {
    "text": "the information that was there within the volume for this application so now",
    "start": "1815650",
    "end": "1823270"
  },
  {
    "text": "I'm going to do some writes on modify this application to delete some of the blocks",
    "start": "1823270",
    "end": "1830190"
  },
  {
    "text": "let me also delete this blog let's go",
    "start": "1842970",
    "end": "1850510"
  },
  {
    "text": "back to the website and you can see right now there is only one blog that exists which is quality a multivision so",
    "start": "1850510",
    "end": "1861190"
  },
  {
    "text": "now I want to now restore my applications data from the slapshot to",
    "start": "1861190",
    "end": "1866890"
  },
  {
    "text": "recover all the blog that has been deleted so how do I do that I can choose to restore the original",
    "start": "1866890",
    "end": "1874990"
  },
  {
    "text": "volume itself from the snapshot but in order to do this I'll have to first bring down the application so since it",
    "start": "1874990",
    "end": "1883270"
  },
  {
    "text": "is created as a kubernetes deployment I'm going to scale down both of these applications to have the replica count 0",
    "start": "1883270",
    "end": "1894060"
  },
  {
    "text": "so at this point the volumes is actually",
    "start": "1902670",
    "end": "1908220"
  },
  {
    "text": "detached and it's an available status",
    "start": "1908220",
    "end": "1916050"
  },
  {
    "text": "now you can choose to restore this volume from a given snapshot in the",
    "start": "1916050",
    "end": "1922420"
  },
  {
    "text": "system so this is the snapshot that was created try out to modifying the application I'm gonna check this box to",
    "start": "1922420",
    "end": "1930910"
  },
  {
    "text": "see I want to proceed the store so the",
    "start": "1930910",
    "end": "1936430"
  },
  {
    "text": "moment I restored the snapshot you can see the volume immediately goes into available state so now this volume can",
    "start": "1936430",
    "end": "1945190"
  },
  {
    "text": "be used to bring up the application so all I have to do is again scale up the application here I'm gonna reset the",
    "start": "1945190",
    "end": "1955780"
  },
  {
    "text": "replica come back to one",
    "start": "1955780",
    "end": "1959010"
  },
  {
    "text": "let's look at the status of this volume on the UI both of the wall you should transition to attach state and three",
    "start": "1965160",
    "end": "1976270"
  },
  {
    "text": "verify the application you see if it has",
    "start": "1976270",
    "end": "1985420"
  },
  {
    "text": "all the blog's that were previously deleted so as you saw like prior to",
    "start": "1985420",
    "end": "1991560"
  },
  {
    "text": "creating the snapshot I had all of these blog information later I modified my app",
    "start": "1991560",
    "end": "1997090"
  },
  {
    "text": "to delete these blocks now once I restored this application all the blogs",
    "start": "1997090",
    "end": "2002460"
  },
  {
    "text": "are back within the volume this shows that the volume that we had was",
    "start": "2002460",
    "end": "2009000"
  },
  {
    "text": "instantly restored from the slapshot within the cluster so with this I'm",
    "start": "2009000",
    "end": "2019260"
  },
  {
    "text": "going to move on to the next demo",
    "start": "2019260",
    "end": "2022940"
  },
  {
    "text": "so here I'll be demonstrating how to set up a replication of a set of volumes",
    "start": "2031830",
    "end": "2038260"
  },
  {
    "text": "across diamonte cluster with the last demo you saw that there we enable data",
    "start": "2038260",
    "end": "2044980"
  },
  {
    "text": "protection for volumes within the cluster here we only extend this across",
    "start": "2044980",
    "end": "2050860"
  },
  {
    "text": "clusters this is basically done to handle disaster recovery so in case of",
    "start": "2050860",
    "end": "2056830"
  },
  {
    "text": "losing the entire primary cluster the application can still be brought up on the dr site with a replicated data",
    "start": "2056830",
    "end": "2064470"
  },
  {
    "text": "however when the application is brought up on the dr site the volume that it's",
    "start": "2064470",
    "end": "2070929"
  },
  {
    "text": "gonna use is based on when the data was last replicated from the primary cluster",
    "start": "2070929",
    "end": "2076860"
  },
  {
    "text": "so for this demo i have two clusters created here one is the primary cluster",
    "start": "2076860",
    "end": "2084340"
  },
  {
    "text": "which is also called active cluster and the other one on the right side is my dr cluster there is an application that's",
    "start": "2084340",
    "end": "2091480"
  },
  {
    "text": "running on the primary cluster which is you using diamonte volume go whenever we",
    "start": "2091480",
    "end": "2098740"
  },
  {
    "text": "will set up a replication across clusters there is a driver that runs within the cluster to facilitate this",
    "start": "2098740",
    "end": "2105610"
  },
  {
    "text": "operation on the primary cluster there is a slapshot of four volume that's",
    "start": "2105610",
    "end": "2111910"
  },
  {
    "text": "taken and this nap shorted volume is used by the replication driver to copy",
    "start": "2111910",
    "end": "2117940"
  },
  {
    "text": "the data onto the dr cluster on the dr cluster now again a snapshot of a volume",
    "start": "2117940",
    "end": "2125680"
  },
  {
    "text": "is taken and this is basically done to keep the slapshots consistent across",
    "start": "2125680",
    "end": "2131740"
  },
  {
    "text": "both the primary and the dr cluster so",
    "start": "2131740",
    "end": "2137710"
  },
  {
    "text": "for this i think let's go back to the demo screen",
    "start": "2137710",
    "end": "2143250"
  },
  {
    "text": "so you use the same cluster here for the",
    "start": "2149780",
    "end": "2162230"
  },
  {
    "text": "primary site the one that I had for my ring and snapshot and there is a dr",
    "start": "2162230",
    "end": "2169430"
  },
  {
    "text": "cluster that's created on the secondary side and let's verify what we have on",
    "start": "2169430",
    "end": "2179900"
  },
  {
    "text": "the dr capacitor only there are no applications running and there are no",
    "start": "2179900",
    "end": "2187460"
  },
  {
    "text": "Peavey's earth PBC's on the primary side",
    "start": "2187460",
    "end": "2194060"
  },
  {
    "text": "I have WordPress our application and my sequel database running and both of",
    "start": "2194060",
    "end": "2201980"
  },
  {
    "text": "these are associated with two PVCs here",
    "start": "2201980",
    "end": "2207220"
  },
  {
    "text": "now I'm going to set up a replication for both of these PVCs to copy the data",
    "start": "2207220",
    "end": "2212600"
  },
  {
    "text": "from primary cluster to the dr cluster so for this let me go back to the UI",
    "start": "2212600",
    "end": "2219380"
  },
  {
    "text": "here first I need to set up the volumes",
    "start": "2219380",
    "end": "2224720"
  },
  {
    "text": "on the dr cluster currently there are no",
    "start": "2224720",
    "end": "2235400"
  },
  {
    "text": "volumes on the dr side i'm going to create a PVC here and this PVC is",
    "start": "2235400",
    "end": "2240950"
  },
  {
    "text": "created with the exact same name as it appears on the primary cluster it's made",
    "start": "2240950",
    "end": "2255560"
  },
  {
    "text": "for the PVC to be created now i'm going to create the second PVC",
    "start": "2255560",
    "end": "2263620"
  },
  {
    "text": "okay so now both the PVCs are created already our cluster now we can actually go ahead",
    "start": "2277830",
    "end": "2284770"
  },
  {
    "text": "and set up a replication for these two volumes on the DL that side so for this",
    "start": "2284770",
    "end": "2291820"
  },
  {
    "text": "we want to create our application object so this is this is the target name that",
    "start": "2291820",
    "end": "2297820"
  },
  {
    "text": "application object I started it and also set up the role for this as a target in",
    "start": "2297820",
    "end": "2303880"
  },
  {
    "text": "point and here there is there multiple",
    "start": "2303880",
    "end": "2311290"
  },
  {
    "text": "volumes that is replicated within a given replication object so I'm going to create a PVC group for it and add both",
    "start": "2311290",
    "end": "2320590"
  },
  {
    "text": "the PVCs within this group so now we",
    "start": "2320590",
    "end": "2328630"
  },
  {
    "text": "have everything set up on the DR cluster for that application let's go back to the primary side on the primary side the",
    "start": "2328630",
    "end": "2337540"
  },
  {
    "text": "volume already exists we just have to go and create an application object for this volume or a name the replication",
    "start": "2337540",
    "end": "2344830"
  },
  {
    "text": "object a source set up the role as source here I'm going to specify the",
    "start": "2344830",
    "end": "2353410"
  },
  {
    "text": "remote end point where the replicated data on its trip cop needs to be copied on to so this is the IP address",
    "start": "2353410",
    "end": "2362140"
  },
  {
    "text": "associated with that application driver that comes up on the DR site so here you",
    "start": "2362140",
    "end": "2369820"
  },
  {
    "text": "can specify the interval how often you want the data to be replicated between these clusters again here we want to",
    "start": "2369820",
    "end": "2377530"
  },
  {
    "text": "group the volumes that we have here into a PVC group and see their application",
    "start": "2377530",
    "end": "2388060"
  },
  {
    "text": "object so at this point in time we have",
    "start": "2388060",
    "end": "2395410"
  },
  {
    "text": "replication objects created both on the source cluster as well as the dr cluster",
    "start": "2395410",
    "end": "2403230"
  },
  {
    "text": "let's see what objects got created on both of this cluster as a result of setting up their application for step I",
    "start": "2403230",
    "end": "2414819"
  },
  {
    "text": "created two PVCs to match the PVC that exists on the source cluster which is my",
    "start": "2414819",
    "end": "2420760"
  },
  {
    "text": "sequel PVC and WP PVC is also PV that",
    "start": "2420760",
    "end": "2428500"
  },
  {
    "text": "corresponds to these PVCs here and there",
    "start": "2428500",
    "end": "2437740"
  },
  {
    "text": "is a diamonte volume that got created as a result of this PVC creation least the",
    "start": "2437740",
    "end": "2443950"
  },
  {
    "text": "volume that corresponds to both of these PVCs and if the replication object is",
    "start": "2443950",
    "end": "2453190"
  },
  {
    "text": "created as a kubernetes custom resource",
    "start": "2453190",
    "end": "2457318"
  },
  {
    "text": "the described on this replication object will have all the parameters that were specified through the UI and this",
    "start": "2458490",
    "end": "2470170"
  },
  {
    "text": "includes the information about the PVC map and the frequency for their application and the role for this",
    "start": "2470170",
    "end": "2478289"
  },
  {
    "text": "cluster similarly on the primary side we",
    "start": "2478289",
    "end": "2484359"
  },
  {
    "text": "have the exact same replication object created and let's take a deep look at",
    "start": "2484359",
    "end": "2494230"
  },
  {
    "text": "this replication object on the source side here",
    "start": "2494230",
    "end": "2501690"
  },
  {
    "text": "so we have a list of PVCs provided to this replication object there is a destination endpoint that is specified",
    "start": "2505150",
    "end": "2513359"
  },
  {
    "text": "to copy the data on to and there's an RPO interval here which says this",
    "start": "2513359",
    "end": "2520359"
  },
  {
    "text": "replication has to be done every fifth minute then our currently their",
    "start": "2520359",
    "end": "2525670"
  },
  {
    "text": "application is not running it's in the detach state whenever the replication starts you can see the admin state of",
    "start": "2525670",
    "end": "2532450"
  },
  {
    "text": "this object going into attached state and the connection will also reflect accordingly and once their application",
    "start": "2532450",
    "end": "2540759"
  },
  {
    "text": "completes the status of this object gets updated to indicate when did the replication start how long it took and",
    "start": "2540759",
    "end": "2547720"
  },
  {
    "text": "also the number of blocks that got transferred as a result of creating this",
    "start": "2547720",
    "end": "2554559"
  },
  {
    "text": "replication object the replication driver creates a kubernetes cron job and",
    "start": "2554559",
    "end": "2559960"
  },
  {
    "text": "this cron job will be set up to run on",
    "start": "2559960",
    "end": "2566619"
  },
  {
    "text": "every first minute which is the replication interval that we specified currently the replication is active it",
    "start": "2566619",
    "end": "2575529"
  },
  {
    "text": "started like few seconds back let's verify the status of this cron job one more time",
    "start": "2575529",
    "end": "2580690"
  },
  {
    "text": "replication is also completed at this point in time you can actually lower",
    "start": "2580690",
    "end": "2585789"
  },
  {
    "text": "describe on their applications and see the status of this object here it sees",
    "start": "2585789",
    "end": "2592569"
  },
  {
    "text": "the number of blocks that was transferred during this replication as four thousand four hundred and nine",
    "start": "2592569",
    "end": "2598059"
  },
  {
    "text": "thousand and these the status of this replication says it is completed",
    "start": "2598059",
    "end": "2603670"
  },
  {
    "text": "successfully now we know the volume that on the DR cluster has been populated",
    "start": "2603670",
    "end": "2610029"
  },
  {
    "text": "with the data from the primary cluster how do we verify what exists on the volume on the dr side for this i'm going",
    "start": "2610029",
    "end": "2617380"
  },
  {
    "text": "to run of fire drill operation and for",
    "start": "2617380",
    "end": "2622680"
  },
  {
    "text": "in order to run this fire drill operation first i need to go and create a volume from the snapshot on the dr",
    "start": "2622680",
    "end": "2629890"
  },
  {
    "text": "side there are two",
    "start": "2629890",
    "end": "2635060"
  },
  {
    "text": "shots that got created on the dr cluster after the replication process so here",
    "start": "2635060",
    "end": "2641270"
  },
  {
    "text": "i'm gonna say i want to create a volume from the snapshot for this fire drill",
    "start": "2641270",
    "end": "2647710"
  },
  {
    "text": "application and this fire drill application expects the volume to be",
    "start": "2647710",
    "end": "2653930"
  },
  {
    "text": "with certain name so i have to create the name of the volume with the exact",
    "start": "2653930",
    "end": "2659090"
  },
  {
    "text": "same name and similarly for this as well",
    "start": "2659090",
    "end": "2671090"
  },
  {
    "text": "so both of these snapshots now has",
    "start": "2671090",
    "end": "2688280"
  },
  {
    "text": "volumes created so with this let's go back to the dr cluster and try to spin",
    "start": "2688280",
    "end": "2695930"
  },
  {
    "text": "up the application so this application",
    "start": "2695930",
    "end": "2711020"
  },
  {
    "text": "is exactly same as it appears on the source side let's verify the status of",
    "start": "2711020",
    "end": "2720110"
  },
  {
    "text": "this application wordpress is running and this is the IP address that is associated with the wordpress on the DR",
    "start": "2720110",
    "end": "2727340"
  },
  {
    "text": "cluster let's verify what this",
    "start": "2727340",
    "end": "2734120"
  },
  {
    "text": "application has on the dr side as you can see here the dr clusters volume has",
    "start": "2734120",
    "end": "2740420"
  },
  {
    "text": "exactly same blogs that were posted from the primary side so this shows that our",
    "start": "2740420",
    "end": "2748850"
  },
  {
    "text": "fire drill operation completed successfully the data that we have on the dr side reflects the exact same data",
    "start": "2748850",
    "end": "2755780"
  },
  {
    "text": "that we had on the primary side this",
    "start": "2755780",
    "end": "2762410"
  },
  {
    "text": "pretty much concludes what i had for the demo today i'm now gonna hand it over to",
    "start": "2762410",
    "end": "2767990"
  },
  {
    "text": "Noreen I'll stop sharing can you focus in my",
    "start": "2767990",
    "end": "2799460"
  },
  {
    "text": "screen can you hear me well yes it says",
    "start": "2799460",
    "end": "2805099"
  },
  {
    "text": "thank you so much all right so you talked about the fundamentals of data",
    "start": "2805099",
    "end": "2812150"
  },
  {
    "text": "services for cloud native workloads as well as some of the attributes regarding",
    "start": "2812150",
    "end": "2817760"
  },
  {
    "text": "the types of data service that we could have as well as what do we get out of each of those types of services as well",
    "start": "2817760",
    "end": "2824300"
  },
  {
    "text": "as the key demos of those requirements and features but overall you know CSI",
    "start": "2824300",
    "end": "2830780"
  },
  {
    "text": "container storage interface is the conduit or the Gateway for any data services and kubernetes so just to sort",
    "start": "2830780",
    "end": "2839480"
  },
  {
    "text": "of cover sheis at a very high level container storage interface is actually based on",
    "start": "2839480",
    "end": "2844910"
  },
  {
    "text": "flex volume and the flex volume is something that the amount you actually",
    "start": "2844910",
    "end": "2849920"
  },
  {
    "text": "worked on along with the rest of the community members such as Google to make",
    "start": "2849920",
    "end": "2855920"
  },
  {
    "text": "it open source and contributed into the community back in the days which finally evolved into container storage interface",
    "start": "2855920",
    "end": "2862730"
  },
  {
    "text": "which we use today for all storage services in kubernetes and this was the",
    "start": "2862730",
    "end": "2868609"
  },
  {
    "text": "beginning where or this is the point of time when we could start running",
    "start": "2868609",
    "end": "2874430"
  },
  {
    "text": "stateful applications on kubernetes and it was a very critical point to you know",
    "start": "2874430",
    "end": "2882710"
  },
  {
    "text": "make kubernetes the infrastructure for any application whether it's stateful or stateless at the same time another",
    "start": "2882710",
    "end": "2889790"
  },
  {
    "text": "important aspect here is you know we can have different types of data services we",
    "start": "2889790",
    "end": "2895640"
  },
  {
    "text": "can have different types of requirements for each of our applications but at the",
    "start": "2895640",
    "end": "2900770"
  },
  {
    "text": "same time doing a bottom-up view of infrastructure",
    "start": "2900770",
    "end": "2907109"
  },
  {
    "text": "up to the application one of the key things is also scheduler extensions so",
    "start": "2907109",
    "end": "2912780"
  },
  {
    "text": "if we have an application we should be able to deploy those cloud native workloads using specific well-defined",
    "start": "2912780",
    "end": "2919859"
  },
  {
    "text": "attributes that match the best infrastructure and resource choices this enables us to use utilize the best",
    "start": "2919859",
    "end": "2928230"
  },
  {
    "text": "choice of infrastructure as well as efficiently utilize all of the options",
    "start": "2928230",
    "end": "2933300"
  },
  {
    "text": "available to us and that is driven through scheduler extensions which again",
    "start": "2933300",
    "end": "2938670"
  },
  {
    "text": "diamonte was a key contributor to in the early days so we heard about data",
    "start": "2938670",
    "end": "2947760"
  },
  {
    "text": "services overall so any storage system any data system that we have the key pieces that it needs to offer our",
    "start": "2947760",
    "end": "2957030"
  },
  {
    "text": "mirroring snapshot back and replication and we have heard about this at the same",
    "start": "2957030",
    "end": "2962760"
  },
  {
    "text": "time you know okay so those are the key services that we need to have but what are some of the key requirements for",
    "start": "2962760",
    "end": "2971130"
  },
  {
    "text": "data services infrastructure in a cloud native environment right",
    "start": "2971130",
    "end": "2976590"
  },
  {
    "text": "so just to recap from what our beyond super covered here scalability is very",
    "start": "2976590",
    "end": "2982440"
  },
  {
    "text": "important scalability with respect to being able to increase or decrease decrease in capacity as well as",
    "start": "2982440",
    "end": "2990920"
  },
  {
    "text": "according to the demands of the applications being able to cater to their performance requirements",
    "start": "2990920",
    "end": "2997160"
  },
  {
    "text": "resiliency is very critical and resiliency on a per volume basis not",
    "start": "2997160",
    "end": "3003440"
  },
  {
    "text": "only not only as a full-fledged system but being able to granularly provide",
    "start": "3003440",
    "end": "3008900"
  },
  {
    "text": "that at a volume level isolation yes you know we can have the ultra fast storage",
    "start": "3008900",
    "end": "3015050"
  },
  {
    "text": "system but at the same time it needs to be able to isolate noisy neighbors so",
    "start": "3015050",
    "end": "3020990"
  },
  {
    "text": "that we don't end up over provisioning the infrastructure because one",
    "start": "3020990",
    "end": "3027020"
  },
  {
    "text": "application at some point in a very uncontrollable fashion is going to take over the entire system because there are",
    "start": "3027020",
    "end": "3033109"
  },
  {
    "text": "no bounds there are no limitations the amount of resources that it can use at any point in the system and then of",
    "start": "3033109",
    "end": "3041030"
  },
  {
    "text": "course isolation is not only for performance I performance attributes it's also for security reasons so that",
    "start": "3041030",
    "end": "3049310"
  },
  {
    "text": "one application is completely separated from another one control plane is",
    "start": "3049310",
    "end": "3054860"
  },
  {
    "text": "separated from ten ends and give us those fundamental bounds within which",
    "start": "3054860",
    "end": "3061940"
  },
  {
    "text": "applications can operate cheering so end of the day you know we",
    "start": "3061940",
    "end": "3068390"
  },
  {
    "text": "will have one infrastructure so we should be able to deploy many applications with different types of",
    "start": "3068390",
    "end": "3074510"
  },
  {
    "text": "requirements and an infrastructure and the data services with on that infrastructure needs to be able to",
    "start": "3074510",
    "end": "3080630"
  },
  {
    "text": "provide this right and not only that it also needs to be able to provide some",
    "start": "3080630",
    "end": "3086090"
  },
  {
    "text": "sort of a policy based mechanism so that you know scalability resiliency",
    "start": "3086090",
    "end": "3091630"
  },
  {
    "text": "isolation all of these could be achieved and forced and implemented in a very",
    "start": "3091630",
    "end": "3097940"
  },
  {
    "text": "seamless and consistent manner last but not the least in terms of the overall",
    "start": "3097940",
    "end": "3104470"
  },
  {
    "text": "you know data attributes is mobility right so and again mobility is not just",
    "start": "3104470",
    "end": "3109850"
  },
  {
    "text": "data its application and data mobility on demand or by choice and being able to",
    "start": "3109850",
    "end": "3117410"
  },
  {
    "text": "migrate applications migrate data as well as to replicate data in a very",
    "start": "3117410",
    "end": "3123080"
  },
  {
    "text": "efficient as well as timely manner and of course all of these things land into",
    "start": "3123080",
    "end": "3128930"
  },
  {
    "text": "the the key requirements that an application will have or an organization",
    "start": "3128930",
    "end": "3134720"
  },
  {
    "text": "will have with respect to the RPO RTO targets recovery point objective and recovery time objective targets another",
    "start": "3134720",
    "end": "3143860"
  },
  {
    "text": "another key point in this checklist is form factor you know are we looking for",
    "start": "3143860",
    "end": "3149000"
  },
  {
    "text": "a date you know storage or data services system that is dedicated only to storage are we looking at a hyper converge",
    "start": "3149000",
    "end": "3155360"
  },
  {
    "text": "system here as well as or is it a cloud or hybrid cloud architecture or design",
    "start": "3155360",
    "end": "3162550"
  },
  {
    "text": "that you would like to take on of course cost is very important so what is the",
    "start": "3162550",
    "end": "3168020"
  },
  {
    "text": "cost per unit of story with respect to a replication with respect to scalability with respect to overall storage all that matters and",
    "start": "3168020",
    "end": "3177610"
  },
  {
    "text": "also while we you know we are seeing X",
    "start": "3177610",
    "end": "3182630"
  },
  {
    "text": "orders of data exodus' of information being out there it also comes down to",
    "start": "3182630",
    "end": "3188540"
  },
  {
    "text": "resource efficiencies are there ways that we can leverage advancements in",
    "start": "3188540",
    "end": "3193700"
  },
  {
    "text": "silicon to actually be able to have very",
    "start": "3193700",
    "end": "3199340"
  },
  {
    "text": "optimal cost per unit of storage and hardware resource utilization to achieve",
    "start": "3199340",
    "end": "3205700"
  },
  {
    "text": "all of these requirements all right so",
    "start": "3205700",
    "end": "3212390"
  },
  {
    "text": "those with that you know here is more information if you would like to learn about us you can go to diamonte come to",
    "start": "3212390",
    "end": "3221480"
  },
  {
    "text": "see what's coming up from diamonte next you know as we talked about data services and stateful applications in a",
    "start": "3221480",
    "end": "3228440"
  },
  {
    "text": "timely manner on May 21st we have we are hosting a webinar on supercharging your",
    "start": "3228440",
    "end": "3234860"
  },
  {
    "text": "stateful applications like any of you know your database applications for example Postgres maria DB MongoDB",
    "start": "3234860",
    "end": "3241040"
  },
  {
    "text": "Microsoft sequel so be sure to join us on May 21st of course geometry Rome has a lot of",
    "start": "3241040",
    "end": "3247790"
  },
  {
    "text": "very useful resources go to diamonte comm / resources there's a bunch of",
    "start": "3247790",
    "end": "3252980"
  },
  {
    "text": "white papers as well as key customer case studies one of the key ones here noted as interest asan Paulo who fast",
    "start": "3252980",
    "end": "3261110"
  },
  {
    "text": "tracked their digital transformation with Gia Monte of course at any time you",
    "start": "3261110",
    "end": "3266120"
  },
  {
    "text": "can follow us on LinkedIn Twitter and Facebook all right with that let's",
    "start": "3266120",
    "end": "3272750"
  },
  {
    "text": "transition to Q&A",
    "start": "3272750",
    "end": "3276880"
  },
  {
    "text": "hey this is IRA I think there was a couple answers and folks responded but",
    "start": "3282780",
    "end": "3288580"
  },
  {
    "text": "we'll capture it here we have three minutes left [Music] maybe the group can can also respond for",
    "start": "3288580",
    "end": "3296170"
  },
  {
    "text": "those who haven't looked at the Q&A box",
    "start": "3296170",
    "end": "3301270"
  },
  {
    "text": "hello what happens if there's an interruption in interruption to the connection during with the replication",
    "start": "3301270",
    "end": "3309390"
  },
  {
    "text": "yeah arvind replied to the question but let me replayed so in case of",
    "start": "3314340",
    "end": "3321040"
  },
  {
    "text": "synchronous moving if there is interruption application would move forward with only one mirrors but",
    "start": "3321040",
    "end": "3327940"
  },
  {
    "text": "whenever whenever the connection restores it quickly resynchronize 'as",
    "start": "3327940",
    "end": "3333970"
  },
  {
    "text": "the the mirror based on it see in the block so it maintains the differences",
    "start": "3333970",
    "end": "3339910"
  },
  {
    "text": "and it only syncs those blocks and the same goes for a replication replication",
    "start": "3339910",
    "end": "3345190"
  },
  {
    "text": "is also based on changed blocks so if there is an interruption it will",
    "start": "3345190",
    "end": "3351640"
  },
  {
    "text": "whenever the replication cycle restarts it will synchronize it will synchronize",
    "start": "3351640",
    "end": "3357250"
  },
  {
    "text": "those blocks looks like we have another question that just came in anonymous how",
    "start": "3357250",
    "end": "3366400"
  },
  {
    "text": "many nodes are possible in a cluster is there a storage limiter I think those",
    "start": "3366400",
    "end": "3372070"
  },
  {
    "text": "are two separate kind of concerns there do you want to try to tackle that one I",
    "start": "3372070",
    "end": "3378420"
  },
  {
    "text": "let go pal answer this one I mean sure",
    "start": "3378420",
    "end": "3385830"
  },
  {
    "text": "so how many nodes are possible in a cluster is basically a kubernetes",
    "start": "3385830",
    "end": "3391210"
  },
  {
    "text": "cluster so you know kubernetes basically with with every release says and tested",
    "start": "3391210",
    "end": "3401980"
  },
  {
    "text": "around five thousand nodes however for us what we have tested so far is 96",
    "start": "3401980",
    "end": "3410680"
  },
  {
    "text": "nodes within a cluster so hopefully that answers that question",
    "start": "3410680",
    "end": "3415990"
  },
  {
    "text": "the second question was about about the storage so de Monte being an sei",
    "start": "3415990",
    "end": "3425020"
  },
  {
    "text": "platform as Narain pointed out there are different conflicts of nodes they can go",
    "start": "3425020",
    "end": "3432670"
  },
  {
    "text": "from you know 4 terabytes per node to 32",
    "start": "3432670",
    "end": "3438880"
  },
  {
    "text": "terabytes per node and so if you do the math and multiply that out for the",
    "start": "3438880",
    "end": "3445570"
  },
  {
    "text": "number of nodes you will get an idea of the scale we're talking petabyte scale",
    "start": "3445570",
    "end": "3452880"
  },
  {
    "text": "easily possible I hope that answers the",
    "start": "3452880",
    "end": "3458920"
  },
  {
    "text": "question back to you that it did did yeah it did for me I have actually one",
    "start": "3458920",
    "end": "3465520"
  },
  {
    "text": "final question a lot of this functionality is there in that storage",
    "start": "3465520",
    "end": "3470700"
  },
  {
    "text": "that the amount a storage stack in the diagrams and the layers there any open source technology in there I know things",
    "start": "3470700",
    "end": "3477670"
  },
  {
    "text": "like fto arc now tangible arrow or examples of open source punch tooling",
    "start": "3477670",
    "end": "3483910"
  },
  {
    "text": "that provide at least for some of the functionality that you described is there anything that you guys are",
    "start": "3483910",
    "end": "3489550"
  },
  {
    "text": "consuming at that layer that comes from projects and out of the ecosystem that's",
    "start": "3489550",
    "end": "3497740"
  },
  {
    "text": "a great question you know imagine when we say cloud",
    "start": "3497740",
    "end": "3505089"
  },
  {
    "text": "native storage really what we mean is that it should be consumed like a service right so you know take the case",
    "start": "3505089",
    "end": "3513820"
  },
  {
    "text": "of public cloud providers you know EBS",
    "start": "3513820",
    "end": "3520170"
  },
  {
    "text": "can be consumed by a kubernetes cluster why are the CSI interfaces which are",
    "start": "3520170",
    "end": "3526359"
  },
  {
    "text": "again all open source right but that the way EBS itself and",
    "start": "3526359",
    "end": "3532240"
  },
  {
    "text": "the storage services which basically up here alluded to they are all basically",
    "start": "3532240",
    "end": "3539130"
  },
  {
    "text": "you know our own implementation now",
    "start": "3539130",
    "end": "3544230"
  },
  {
    "text": "you ask a question what standard do we follow so the standard which we follow is is",
    "start": "3544230",
    "end": "3553390"
  },
  {
    "text": "nvme so in in in in this implementation",
    "start": "3553390",
    "end": "3558880"
  },
  {
    "text": "we are virtualizing nvme to each board so to speak the nvme is an open standard",
    "start": "3558880",
    "end": "3568210"
  },
  {
    "text": "and it already has drivers available",
    "start": "3568210",
    "end": "3574960"
  },
  {
    "text": "natively in in Linux and Windows kernels right so from that perspective yes we",
    "start": "3574960",
    "end": "3582550"
  },
  {
    "text": "leverage open standards like CSI nvme",
    "start": "3582550",
    "end": "3588190"
  },
  {
    "text": "and moving forward nvme over fabrics and",
    "start": "3588190",
    "end": "3593580"
  },
  {
    "text": "what Shilpa assured the examples of how",
    "start": "3593580",
    "end": "3598950"
  },
  {
    "text": "replication objects are created and tied together is all the then the six storage",
    "start": "3598950",
    "end": "3608170"
  },
  {
    "text": "group six storage group as you may know within kubernetes is one of the most",
    "start": "3608170",
    "end": "3613840"
  },
  {
    "text": "active groups and they are us together",
    "start": "3613840",
    "end": "3618910"
  },
  {
    "text": "in the community are trying to standardize on these storage features as",
    "start": "3618910",
    "end": "3625060"
  },
  {
    "text": "to how they are consumed so the CR DS and the objects basically are all based",
    "start": "3625060",
    "end": "3632020"
  },
  {
    "text": "on what the six storage group is is it advocating did I you you you say thank",
    "start": "3632020",
    "end": "3642760"
  },
  {
    "text": "you and I appreciate the answer in Christy patience as we ran a couple of",
    "start": "3642760",
    "end": "3650080"
  },
  {
    "text": "minutes over but I want to thank all of you for a great presentation today that is all the questions we have for us",
    "start": "3650080",
    "end": "3658600"
  },
  {
    "text": "today and the webinar recording slides will be available later on today and we look forward to seeing you at a future",
    "start": "3658600",
    "end": "3665640"
  },
  {
    "text": "CN CF webinar have a great day thank you and Jessica",
    "start": "3665640",
    "end": "3671560"
  },
  {
    "text": "thank you so much have a great day",
    "start": "3671560",
    "end": "3674970"
  }
]
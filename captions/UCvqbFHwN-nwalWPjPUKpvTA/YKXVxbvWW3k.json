[
  {
    "start": "0",
    "end": "88000"
  },
  {
    "text": "according to um maximizing m3 pushing performance boundaries in a distributed",
    "start": "320",
    "end": "5680"
  },
  {
    "text": "metrics engine i'm kristy tan and i'll be moderating today's webinar we would like to welcome our presenter",
    "start": "5680",
    "end": "11360"
  },
  {
    "text": "ryan allen senior software engineer at chronosphere a few housekeeping items before we get",
    "start": "11360",
    "end": "16880"
  },
  {
    "text": "started during the webinar you are not able to talk as an attendee there is a q a box at the bottom of your",
    "start": "16880",
    "end": "23039"
  },
  {
    "text": "screen please feel free to drop in your questions and we'll get to as many as we can at the end this is an official webinar",
    "start": "23039",
    "end": "30080"
  },
  {
    "text": "of the cncf and as such is subject to the cncf code of conduct please do not add anything to the chat",
    "start": "30080",
    "end": "37040"
  },
  {
    "text": "or questions that would be in violation of that code of conduct basically please be respectful of all",
    "start": "37040",
    "end": "42399"
  },
  {
    "text": "your fellow participants and presenters please also note that the recording and slides will be posted",
    "start": "42399",
    "end": "47440"
  },
  {
    "text": "later today to the cncf webinars page at cncf dot io slash webinars with that i'll hand it",
    "start": "47440",
    "end": "54480"
  },
  {
    "text": "over to ryan to kick off today's presentation take it away thank you",
    "start": "54480",
    "end": "60719"
  },
  {
    "text": "uh hello everyone thanks for attending um my name is ryan and i'll be walking",
    "start": "60719",
    "end": "66159"
  },
  {
    "text": "through this presentation maximizing m3 pushing performance boundaries in a",
    "start": "66159",
    "end": "71439"
  },
  {
    "text": "distributed metric metrics engine and so kind of uh when we wrap up we'll",
    "start": "71439",
    "end": "76560"
  },
  {
    "text": "have you know 10 to 15 minutes of questions we can read through the q a box and um answer anything live that anyone",
    "start": "76560",
    "end": "83920"
  },
  {
    "text": "might have on their minds cool so let's begin uh",
    "start": "83920",
    "end": "89040"
  },
  {
    "start": "88000",
    "end": "162000"
  },
  {
    "text": "just a quick background of who i am so for the past year i've been a senior",
    "start": "89040",
    "end": "94320"
  },
  {
    "text": "software engineer at chronosphere cronus at chronosphere where metrics monitoring",
    "start": "94320",
    "end": "100400"
  },
  {
    "text": "platform company um that fundamentally relies on kind of open source",
    "start": "100400",
    "end": "105920"
  },
  {
    "text": "m3 as our core metrics storage uh and so kind of over the past year i've been working a lot on",
    "start": "105920",
    "end": "112479"
  },
  {
    "text": "performance improvements to that system and just improving the scale at which it can",
    "start": "112479",
    "end": "117680"
  },
  {
    "text": "operate um prior to being at chronosphere i was working at a company called applied",
    "start": "117680",
    "end": "123920"
  },
  {
    "text": "predictive technologies and so there it was not really necessarily monitoring metrics",
    "start": "123920",
    "end": "129920"
  },
  {
    "text": "but it was time series related in that we were kind of building products that performed",
    "start": "129920",
    "end": "135520"
  },
  {
    "text": "analytic aggregations on large financial transaction data sets",
    "start": "135520",
    "end": "141200"
  },
  {
    "text": "and so you can imagine for example uh kind of like a mastercard transaction data set across many",
    "start": "141200",
    "end": "147280"
  },
  {
    "text": "companies and doing various types of statistical analysis on that to understand spend behavior so kind of the core",
    "start": "147280",
    "end": "153599"
  },
  {
    "text": "thread there between um my current role of chronosphere in my previous role at apt has been related to time series in",
    "start": "153599",
    "end": "160560"
  },
  {
    "text": "general so just to go over kind of what",
    "start": "160560",
    "end": "166080"
  },
  {
    "start": "162000",
    "end": "209000"
  },
  {
    "text": "is on the agenda in this presentation first we'll just kind of talk about more abstractly",
    "start": "166080",
    "end": "171840"
  },
  {
    "text": "what metrics monitoring even is um give some examples of",
    "start": "171840",
    "end": "176879"
  },
  {
    "text": "some metrics in the series that comprise those metrics so we better understand",
    "start": "176879",
    "end": "182480"
  },
  {
    "text": "you know what we're actually monitoring um the second piece is diving into the problems that come",
    "start": "182480",
    "end": "188959"
  },
  {
    "text": "about in metrics monitoring particularly when you reach certain",
    "start": "188959",
    "end": "194159"
  },
  {
    "text": "scale and then thirdly we'll talk about how with the m3 project we've sought to",
    "start": "194159",
    "end": "201840"
  },
  {
    "text": "remedy a lot of these problems that will kind of enumerate throughout the",
    "start": "201840",
    "end": "206879"
  },
  {
    "text": "presentation cool so to kind of dive into that first piece which",
    "start": "206879",
    "end": "212000"
  },
  {
    "start": "209000",
    "end": "357000"
  },
  {
    "text": "is you know what what even is a metric let's say so kind of very abstractly",
    "start": "212000",
    "end": "218480"
  },
  {
    "text": "and simply one could think about a metric as kind of a generic schema for data that",
    "start": "218480",
    "end": "225120"
  },
  {
    "text": "you would like to track and collect and aggregate over time um so a tangible example of this you know",
    "start": "225120",
    "end": "232319"
  },
  {
    "text": "for an actual engineer might be counting the number of http requests",
    "start": "232319",
    "end": "237360"
  },
  {
    "text": "so you know the name of this metric would be http requests this would be incrementing over time",
    "start": "237360",
    "end": "243120"
  },
  {
    "text": "uh kind of across all of your applications let's say and obviously kind of at that level of",
    "start": "243120",
    "end": "248560"
  },
  {
    "text": "granularity it's not that useful yes you can understand kind of the total number of http requests that are happening over",
    "start": "248560",
    "end": "254239"
  },
  {
    "text": "time but what you really care about are kind of the more granular characteristics about",
    "start": "254239",
    "end": "259680"
  },
  {
    "text": "these http requests right so that's where kind of metric dimensions come in",
    "start": "259680",
    "end": "265360"
  },
  {
    "text": "so every metric that you can conceptually think about actually can be broken out by",
    "start": "265360",
    "end": "270560"
  },
  {
    "text": "various different dimensions which describe in more granular detail the particular",
    "start": "270560",
    "end": "276160"
  },
  {
    "text": "characteristics about that you know instance of the metric so a dimension for example with our",
    "start": "276160",
    "end": "282400"
  },
  {
    "text": "http request example could be endpoint and so you know one one particular",
    "start": "282400",
    "end": "289600"
  },
  {
    "text": "endpoint could be api search but then you can imagine many others uh that would be occurring",
    "start": "289600",
    "end": "295360"
  },
  {
    "text": "kind of throughout a whole system so you could kind of break out a an h2 your quick request by",
    "start": "295360",
    "end": "300880"
  },
  {
    "text": "the particular endpoint that that it was associated with and then furthermore the same kind of another dimension that",
    "start": "300880",
    "end": "306960"
  },
  {
    "text": "would be relevant for a http request would be status code so you know 200 success 500 era error",
    "start": "306960",
    "end": "314160"
  },
  {
    "text": "etc etc um and then it can even be kind of in more granular detail with with",
    "start": "314160",
    "end": "320080"
  },
  {
    "text": "dimensions that change over time very often like something like a git deploy version shaw so",
    "start": "320080",
    "end": "328639"
  },
  {
    "text": "you know whenever a request is actually served by a particular server",
    "start": "328639",
    "end": "335360"
  },
  {
    "text": "the actual git sha associated with the server serving that request",
    "start": "335440",
    "end": "340479"
  },
  {
    "text": "is also kind of a piece of information that you could be attaching to this metric and caring",
    "start": "340479",
    "end": "346080"
  },
  {
    "text": "about so kind of that's kind of more conceptually how you think about a metric and how",
    "start": "346080",
    "end": "352080"
  },
  {
    "text": "like a user would approach metrics monitoring but then if we think about what then",
    "start": "352080",
    "end": "359759"
  },
  {
    "start": "357000",
    "end": "439000"
  },
  {
    "text": "under the hood a metric is comprised of it actually all fundamentally boils down to",
    "start": "359759",
    "end": "365520"
  },
  {
    "text": "distinct time series and so if we look again just at our example of an http request kind of",
    "start": "365520",
    "end": "373600"
  },
  {
    "text": "for every combination of all of the dimensions and their values there is a",
    "start": "373600",
    "end": "379199"
  },
  {
    "text": "unique kind of time series value that is changing over time",
    "start": "379199",
    "end": "384960"
  },
  {
    "text": "associated with that unique combination so if we just take this very kind of boiled down example let's say we only",
    "start": "384960",
    "end": "391919"
  },
  {
    "text": "cared about a few different dimensions right endpoint and status code endpoint we have two possible endpoints",
    "start": "391919",
    "end": "397919"
  },
  {
    "text": "status code we have three so for this request metric while we",
    "start": "397919",
    "end": "404160"
  },
  {
    "text": "conceptually think of it as one thing when we're actually storing it and the way it's actually laid out",
    "start": "404160",
    "end": "409919"
  },
  {
    "text": "on disk or in memory it will actually be broken out into six total different time series um and",
    "start": "409919",
    "end": "416720"
  },
  {
    "text": "if we were at let's say kind of another dimension that had two different values that would then multiply that",
    "start": "416720",
    "end": "422880"
  },
  {
    "text": "kind of total set of series again by two um and so there's kind of this multiplicative",
    "start": "422880",
    "end": "429360"
  },
  {
    "text": "uh inherent quality to metrics insofar as how they fundamentally end up",
    "start": "429360",
    "end": "435520"
  },
  {
    "text": "being stored uh over time so that kind of leads to one of the",
    "start": "435520",
    "end": "442479"
  },
  {
    "start": "439000",
    "end": "556000"
  },
  {
    "text": "fundamental challenges surrounding metrics monitoring and that is a challenge of scale so",
    "start": "442479",
    "end": "451599"
  },
  {
    "text": "again you know because ultimately all these metrics are comprised of many many different time",
    "start": "451599",
    "end": "458400"
  },
  {
    "text": "series that we're storing in some location we need to be able to kind of scale out",
    "start": "458400",
    "end": "465039"
  },
  {
    "text": "our ability to store and then also retrieve all of these different series in an efficient way and",
    "start": "465039",
    "end": "471280"
  },
  {
    "text": "you know over time our environments have become",
    "start": "471280",
    "end": "476720"
  },
  {
    "text": "uh you know in a cloud-native environment one of having very ephemeral types of",
    "start": "476720",
    "end": "483599"
  },
  {
    "text": "dimensions that would be attached to different metrics so for example um",
    "start": "483599",
    "end": "489360"
  },
  {
    "text": "within kind of a kubernetes deployment infrastructure a particular dimension",
    "start": "489360",
    "end": "495440"
  },
  {
    "text": "that would be attached to nearly every metric would be the actual unique pod name associated with",
    "start": "495440",
    "end": "503280"
  },
  {
    "text": "kind of the origination of that particular metric and so you know for for example let's say we had three",
    "start": "503280",
    "end": "509599"
  },
  {
    "text": "different time series associated with a particular deployment right cpu",
    "start": "509599",
    "end": "514640"
  },
  {
    "text": "memory and go routines all coming from the same single pod if then we just redeployed",
    "start": "514640",
    "end": "521279"
  },
  {
    "text": "you know the same service with the same metrics that would just double then the number of unique time",
    "start": "521279",
    "end": "527040"
  },
  {
    "text": "series that we've generated kind of in that by just taking that deployment action",
    "start": "527040",
    "end": "532160"
  },
  {
    "text": "and so as you can imagine this is kind of like a three different you know series for just a single pod",
    "start": "532160",
    "end": "538480"
  },
  {
    "text": "but you know across many different microservices across you know many different regions",
    "start": "538480",
    "end": "543680"
  },
  {
    "text": "etc etc you can imagine how that easily can explode to millions and and",
    "start": "543680",
    "end": "549360"
  },
  {
    "text": "even billions of series that are comprising the metrics that you ultimately care about",
    "start": "549360",
    "end": "555839"
  },
  {
    "text": "so kind of in the in the kind of modern day solution",
    "start": "555920",
    "end": "563040"
  },
  {
    "start": "556000",
    "end": "820000"
  },
  {
    "text": "architecture for metrics monitoring there are a lot of really good options but also as we were describing because",
    "start": "563040",
    "end": "570720"
  },
  {
    "text": "of the scaling problem it becomes more and more difficult to maintain this infrastructure over",
    "start": "570720",
    "end": "576000"
  },
  {
    "text": "time because the solutions become more and more complex so uh most people are familiar with prometheus which is a cncf",
    "start": "576000",
    "end": "583200"
  },
  {
    "text": "uh open source project uh it's really kind of everyone's de facto go-to solution for",
    "start": "583200",
    "end": "589600"
  },
  {
    "text": "getting out of the box metrics monitoring so kind of in this first bucket most",
    "start": "589600",
    "end": "595519"
  },
  {
    "text": "companies when they're trying to adopt metrics monitoring as a standard you just deploy a single instance of",
    "start": "595519",
    "end": "602240"
  },
  {
    "text": "prometheus everything just kind of works perfectly right out of the box and all as well you know engineers can",
    "start": "602240",
    "end": "608079"
  },
  {
    "text": "track their metrics over time it's very easy to add metrics uh it's all centralized in this one",
    "start": "608079",
    "end": "613760"
  },
  {
    "text": "place for people to view them and you know everything works really well",
    "start": "613760",
    "end": "619360"
  },
  {
    "text": "at that kind of initial level of scale but then you know over time um companies start producing",
    "start": "619360",
    "end": "627839"
  },
  {
    "text": "more and more metrics engineers become more prolific and how they're instrumenting their applications so they themselves are kind",
    "start": "627839",
    "end": "634399"
  },
  {
    "text": "of leveraging the monitoring infrastructure to be able to be more granular but that means",
    "start": "634399",
    "end": "639680"
  },
  {
    "text": "you know more and more series ultimately are being produced under the hood that are being stored and then you have",
    "start": "639680",
    "end": "644880"
  },
  {
    "text": "you know again kind of systems like with kubernetes automated metrics that are being emitted",
    "start": "644880",
    "end": "651600"
  },
  {
    "text": "in and those tend to be very ephemeral so they're constantly changing thereby dramatically increasing the",
    "start": "651600",
    "end": "659040"
  },
  {
    "text": "number of series being stored as well and so then companies start running into challenges where you",
    "start": "659040",
    "end": "665200"
  },
  {
    "text": "know yeah you can continue to increase your prometheus instance and just beefing it up adding more more",
    "start": "665200",
    "end": "670959"
  },
  {
    "text": "memory to it but eventually that just not that that becomes kind of like not a sustainable solution so you have",
    "start": "670959",
    "end": "677920"
  },
  {
    "text": "to come up with more interesting solutions so you know often people will",
    "start": "677920",
    "end": "683040"
  },
  {
    "text": "uh actually run multiple different prometheus instances and and kind of in shard their",
    "start": "683040",
    "end": "688959"
  },
  {
    "text": "infrastructure so you know some subset of my applications go to prometheus a",
    "start": "688959",
    "end": "694320"
  },
  {
    "text": "some different subset of my applications go to prometheus b and then in order to actually be able to",
    "start": "694320",
    "end": "701600"
  },
  {
    "text": "you know consolidate all of all of this data in a way where we can retrieve it from a single source",
    "start": "701600",
    "end": "707040"
  },
  {
    "text": "uh there are a lot of open source solutions where you know for example all of these",
    "start": "707040",
    "end": "713040"
  },
  {
    "text": "different charted prometheuses can ultimately dump their long-term store to",
    "start": "713040",
    "end": "718079"
  },
  {
    "text": "something like s3 or gcs and [Music] again like that that is definitely a",
    "start": "718079",
    "end": "724399"
  },
  {
    "text": "solution that that kind of allows you to pass that that initial scaling barrier of a single",
    "start": "724399",
    "end": "731200"
  },
  {
    "text": "prometheus but at the cost of having this operational complexity you know that these different",
    "start": "731200",
    "end": "736480"
  },
  {
    "text": "prometheuses aren't necessarily balanced so provisioning them and maintaining them",
    "start": "736480",
    "end": "742560"
  },
  {
    "text": "over time is operationally difficult um and it's also just kind of infrastructurally",
    "start": "742560",
    "end": "748240"
  },
  {
    "text": "way more complex because now you don't just have this one prometheus instance you have many and they're also talking to like these other",
    "start": "748240",
    "end": "754399"
  },
  {
    "text": "services that are doing querying and this other you know remote storage piece and so kind of the whole",
    "start": "754399",
    "end": "760959"
  },
  {
    "text": "infrastructure has evolved to become a lot more complicated and then you know um while while those solutions",
    "start": "760959",
    "end": "769200"
  },
  {
    "text": "are in place and companies are doing this to handle their kind of surpassed scale um you can even kind of reach a",
    "start": "769200",
    "end": "776560"
  },
  {
    "text": "place where even something like this just becomes not sustainable either operationally or just",
    "start": "776560",
    "end": "783920"
  },
  {
    "text": "kind of the cost-effective nature of it is not sustainable because you don't really",
    "start": "783920",
    "end": "790399"
  },
  {
    "text": "have something that is linearly scalable in terms of just like raw dollars so",
    "start": "790399",
    "end": "796240"
  },
  {
    "text": "kind of in this third bucket the question is all right trying to maintain this kind of sharded",
    "start": "796240",
    "end": "801680"
  },
  {
    "text": "prometheus infrastructure with these other open source tools that we've kind of pieced together it's it's kind of a nightmare is there",
    "start": "801680",
    "end": "808560"
  },
  {
    "text": "is there's a solution that actually just can you know give us some sort of",
    "start": "808560",
    "end": "815360"
  },
  {
    "text": "sustainable solution to the indefinite scaling problem um i have one other",
    "start": "815360",
    "end": "822320"
  },
  {
    "start": "820000",
    "end": "890000"
  },
  {
    "text": "piece to note about kind of a challenge with that type of many different prometheuses",
    "start": "822320",
    "end": "828480"
  },
  {
    "text": "using some remote store and kind of blob storage is the fact that while",
    "start": "828480",
    "end": "833600"
  },
  {
    "text": "you can just cheaply indefinitely scale the storage side in something like s3",
    "start": "833600",
    "end": "840399"
  },
  {
    "text": "because you can just pay for more and more of it",
    "start": "840399",
    "end": "846160"
  },
  {
    "text": "you still kind of have this single bottleneck in terms of the execution",
    "start": "846160",
    "end": "852240"
  },
  {
    "text": "side when you're when you're doing the reads from this data because for example if you're",
    "start": "852240",
    "end": "857279"
  },
  {
    "text": "storing all of this data all in blob storage you still need some service to actually",
    "start": "857279",
    "end": "862880"
  },
  {
    "text": "index this information and search through it in a way where you can aggregate it all up properly and",
    "start": "862880",
    "end": "870399"
  },
  {
    "text": "that also tends to overwhelm kind of single node",
    "start": "870399",
    "end": "875440"
  },
  {
    "text": "solutions um and so you can beef up this you know query engine as much as you",
    "start": "875440",
    "end": "881120"
  },
  {
    "text": "want but you still have that kind of limitation of it being a single pipe towards this this enormous set of",
    "start": "881120",
    "end": "888480"
  },
  {
    "text": "data so one last problem",
    "start": "888480",
    "end": "894160"
  },
  {
    "start": "890000",
    "end": "1002000"
  },
  {
    "text": "with metrics monitoring that comes about kind of similarly to the to the point about the",
    "start": "894160",
    "end": "901360"
  },
  {
    "text": "limitations with single node execution is reliability so you know in a case where let's say",
    "start": "901360",
    "end": "906959"
  },
  {
    "text": "you're running a single prometheus instance obviously in that world you're highly",
    "start": "906959",
    "end": "912639"
  },
  {
    "text": "susceptible to an outage because all if one if that one single prometheus instance",
    "start": "912639",
    "end": "919920"
  },
  {
    "text": "goes down then now you have no visibility into",
    "start": "919920",
    "end": "925360"
  },
  {
    "text": "your kind of infrastructure you wouldn't be aware in this example if you know app c were",
    "start": "925360",
    "end": "931279"
  },
  {
    "text": "to go out because you know your prometheus instance is out and this is also like really bad just",
    "start": "931279",
    "end": "938880"
  },
  {
    "text": "from a user or engineering standpoint because if you don't have you know the",
    "start": "938880",
    "end": "944720"
  },
  {
    "text": "visibility into your infrastructure then you can't actually like diagnose problems and take actions so",
    "start": "944720",
    "end": "951519"
  },
  {
    "text": "you know kind of one of the pieces of critical infrastructure is the monitoring side you kind of have",
    "start": "951519",
    "end": "957199"
  },
  {
    "text": "to assume that that always will be up and in the world where you're",
    "start": "957199",
    "end": "962480"
  },
  {
    "text": "relying on that infrastructure being kind of the single point of failure that that can be problematic and then lastly",
    "start": "962480",
    "end": "968800"
  },
  {
    "text": "um kind of a limitation with with this paradigm is the fact that uh they're like",
    "start": "968800",
    "end": "975120"
  },
  {
    "text": "something like prometheus on its own doesn't have you know kind of long-term persistent",
    "start": "975120",
    "end": "981120"
  },
  {
    "text": "storage built in and so you need to kind of come up with some other solution to that or you're also",
    "start": "981120",
    "end": "986399"
  },
  {
    "text": "susceptible to losing data permanently if things just kind of crash so kind of those two points in metrics",
    "start": "986399",
    "end": "994160"
  },
  {
    "text": "monitoring have been long-standing challenges that that many companies have been",
    "start": "994160",
    "end": "999279"
  },
  {
    "text": "encountering for a long time which are scale and reliability uh so that kind of leads us to how do we",
    "start": "999279",
    "end": "1007759"
  },
  {
    "start": "1002000",
    "end": "1112000"
  },
  {
    "text": "try to approach those challenges with solutions in m3 and",
    "start": "1007759",
    "end": "1014639"
  },
  {
    "text": "so first i'll just briefly talk about what even is m3 so m3 is an open source distributed metris",
    "start": "1014639",
    "end": "1022000"
  },
  {
    "text": "engine so kind of the notable difference between the metrics engine of m3 versus",
    "start": "1022000",
    "end": "1028480"
  },
  {
    "text": "uh many others is its distributed nature and it you know is highly compatible",
    "start": "1028480",
    "end": "1034640"
  },
  {
    "text": "with prometheus it can kind of be pointed to by prometheus so um your your single prometheus or many",
    "start": "1034640",
    "end": "1042160"
  },
  {
    "text": "can just direct all of their read and write traffic to m3 and m3 can kind of be the",
    "start": "1042160",
    "end": "1050880"
  },
  {
    "text": "horizontally scalable distributed system solution to the the limitations that exist with",
    "start": "1050880",
    "end": "1057280"
  },
  {
    "text": "kind of a single node solution um and so as we see here kind of the architecture",
    "start": "1057280",
    "end": "1063200"
  },
  {
    "text": "would look something like prometheus talks to kind of this arbiter in between called the m3",
    "start": "1063200",
    "end": "1068320"
  },
  {
    "text": "coordinator and the m3 coordinators and is in charge of issuing kind of",
    "start": "1068320",
    "end": "1074400"
  },
  {
    "text": "or basically forwarding the operations to the actual distributed system which is",
    "start": "1074400",
    "end": "1081120"
  },
  {
    "text": "the the m3 db component and you can see here this is an example where we have you",
    "start": "1081120",
    "end": "1087360"
  },
  {
    "text": "know three different replicas of m3 db clusters which allows us",
    "start": "1087360",
    "end": "1096000"
  },
  {
    "text": "to kind of both have horizontal scaling capability because we can continue to add nodes to",
    "start": "1096000",
    "end": "1102080"
  },
  {
    "text": "all each of these you know replica clusters and then also because we're replicating",
    "start": "1102080",
    "end": "1107679"
  },
  {
    "text": "the data if some of these go down we're resilient to failures so we'll kind of quickly walk through",
    "start": "1107679",
    "end": "1113919"
  },
  {
    "start": "1112000",
    "end": "1219000"
  },
  {
    "text": "how those benefits actually play out so again kind of on the real reliability",
    "start": "1113919",
    "end": "1120559"
  },
  {
    "text": "side the way we in m3 tackle this problem is via replication",
    "start": "1120559",
    "end": "1126960"
  },
  {
    "text": "and so you know by by having this functionality",
    "start": "1126960",
    "end": "1132640"
  },
  {
    "text": "you know not only are we resistant to single points of failure but also just",
    "start": "1132640",
    "end": "1139200"
  },
  {
    "text": "kind of you know no downtime requirements for upgrades no downtime requirements for",
    "start": "1139200",
    "end": "1145679"
  },
  {
    "text": "data migrations no downtime requirements for kind of deployments and things like that um",
    "start": "1145679",
    "end": "1152880"
  },
  {
    "text": "and you can imagine kind of let's say all three of our replicas are currently working obviously reads",
    "start": "1152880",
    "end": "1158640"
  },
  {
    "text": "are then able to be served in this situation if one replica goes down",
    "start": "1158640",
    "end": "1164720"
  },
  {
    "text": "we still can fully serve you know consistent reads because we have two other copy copies and have",
    "start": "1164720",
    "end": "1171440"
  },
  {
    "text": "kind of quorum consensus about what the truth actually is and so only until you",
    "start": "1171440",
    "end": "1177760"
  },
  {
    "text": "actually have two replicas down which would be kind of an unlikely event scenario would you have you know",
    "start": "1177760",
    "end": "1184640"
  },
  {
    "text": "especially if you were to kind of you know let's say put one replica in one region another replica and another um only",
    "start": "1184640",
    "end": "1192640"
  },
  {
    "text": "until you would have two actually down would you no longer be able to provide truly consistent reads but even",
    "start": "1192640",
    "end": "1199520"
  },
  {
    "text": "then in kind of this like worst in this like very bad case scenario um you could still even serve the data",
    "start": "1199520",
    "end": "1206480"
  },
  {
    "text": "that is existing on replica 3 just without kind of the same consistency guarantees that you would have with",
    "start": "1206480",
    "end": "1214720"
  },
  {
    "text": "more than one replica operational so on the scale side the way kind of",
    "start": "1214720",
    "end": "1223919"
  },
  {
    "start": "1219000",
    "end": "1334000"
  },
  {
    "text": "m3 tackles this problem is again kind of in its distributed nature and there are kind of two pieces to this",
    "start": "1223919",
    "end": "1230559"
  },
  {
    "text": "so uh again you can imagine how kind of the database side is actually comprised of",
    "start": "1230559",
    "end": "1236080"
  },
  {
    "text": "many different nodes and so one really strong benefit of this disturbing nature is that you",
    "start": "1236080",
    "end": "1243039"
  },
  {
    "text": "can just add and remove you know more nodes as needed",
    "start": "1243039",
    "end": "1248480"
  },
  {
    "text": "as you need to support greater metrics volume in total and",
    "start": "1248480",
    "end": "1255679"
  },
  {
    "text": "so it's kind of a horizontally scalable solution as opposed to having to kind of indefinitely beef up a",
    "start": "1255679",
    "end": "1261840"
  },
  {
    "text": "single instance to support more volume um and then kind of the other advantage of",
    "start": "1261840",
    "end": "1268240"
  },
  {
    "text": "this distributed nature is not not not really related to the storage itself but rather kind of",
    "start": "1268240",
    "end": "1273919"
  },
  {
    "text": "the read path and so we we talked about earlier how there are limitations with",
    "start": "1273919",
    "end": "1279360"
  },
  {
    "text": "kind of the single node execution path well on the distributed side",
    "start": "1279360",
    "end": "1285760"
  },
  {
    "text": "when you're doing reads it actually kind of becomes a map produced problem where you can kind of distribute that",
    "start": "1285760",
    "end": "1291360"
  },
  {
    "text": "load across all of these nodes in a way that makes it so",
    "start": "1291360",
    "end": "1297120"
  },
  {
    "text": "you don't have that kind of single node execution limitation where that one",
    "start": "1297120",
    "end": "1303440"
  },
  {
    "text": "node needs to be extremely beefy in instead we can kind of more evenly distribute this load across",
    "start": "1303440",
    "end": "1311120"
  },
  {
    "text": "kind of much smaller instances that that cost less money",
    "start": "1311120",
    "end": "1316960"
  },
  {
    "text": "and it also just improves kind of you know query speeds because uh we're able to kind of parallelize a",
    "start": "1316960",
    "end": "1324159"
  },
  {
    "text": "lot of the aggregations across the nodes themselves as opposed to having having to happen kind of in some single",
    "start": "1324159",
    "end": "1332960"
  },
  {
    "text": "instance so those are kind of like the solutions to",
    "start": "1332960",
    "end": "1339360"
  },
  {
    "start": "1334000",
    "end": "1417000"
  },
  {
    "text": "scale and reliability from the very beginning of m3 and so one could say oh okay well we must now then have",
    "start": "1339360",
    "end": "1347600"
  },
  {
    "text": "infinitely horizontal scale so kind of now problem solved everything",
    "start": "1347600",
    "end": "1352960"
  },
  {
    "text": "is fine we've we've removed the blocker that was you know the physics limitation of",
    "start": "1352960",
    "end": "1360240"
  },
  {
    "text": "running something on a single instance so what what problems are remaining",
    "start": "1360240",
    "end": "1365760"
  },
  {
    "text": "uh well essentially the problem then becomes okay well yes we can in",
    "start": "1365760",
    "end": "1372799"
  },
  {
    "text": "in theory just linearly infinitely scale but you're still linearly paying for that",
    "start": "1372799",
    "end": "1379520"
  },
  {
    "text": "volume as you're increasing the total volume of you know metric series data you're",
    "start": "1379520",
    "end": "1386720"
  },
  {
    "text": "ingesting and so uh in a world where cardinality is certainly not decreasing so again kind",
    "start": "1386720",
    "end": "1393760"
  },
  {
    "text": "of cardinality being the like density of all the different dimensions and",
    "start": "1393760",
    "end": "1399200"
  },
  {
    "text": "how often they're changing like all of that is not decreasing and",
    "start": "1399200",
    "end": "1404640"
  },
  {
    "text": "instead in kind of a cloud native world it's only increasing so the question is how do we make sure that",
    "start": "1404640",
    "end": "1410320"
  },
  {
    "text": "while we're scaling these things out we're doing it in a way that isn't you know breaking the bank um",
    "start": "1410320",
    "end": "1417120"
  },
  {
    "start": "1417000",
    "end": "1669000"
  },
  {
    "text": "and so that kind of leads to the maximization problems that we've more recently been focusing on and",
    "start": "1417120",
    "end": "1424880"
  },
  {
    "text": "um kind of you can think about these maximization problems as in as kind of two different buckets one",
    "start": "1424880",
    "end": "1430720"
  },
  {
    "text": "is just trying to get the absolute most performance you can per dollar of like you know",
    "start": "1430720",
    "end": "1438480"
  },
  {
    "text": "compute spend um but then secondly and it's this is a little more kind of like",
    "start": "1438480",
    "end": "1444080"
  },
  {
    "text": "from the perspective of the engineer who's like relying on this monitoring",
    "start": "1444080",
    "end": "1449760"
  },
  {
    "text": "infrastructure what we're trying to maximize is kind of the actual value to that engineer or",
    "start": "1449760",
    "end": "1455520"
  },
  {
    "text": "the insights one can get from the actual kind of stuff we're ultimately storing so like",
    "start": "1455520",
    "end": "1461919"
  },
  {
    "text": "you can go with take an approach of let's just store literally everything and you can",
    "start": "1461919",
    "end": "1467600"
  },
  {
    "text": "do that but you also are paying for it so how do we make it so that you know for every dollar we're paying to store",
    "start": "1467600",
    "end": "1473440"
  },
  {
    "text": "stuff we're actually getting the absolute most insight or or value to engineer out of",
    "start": "1473440",
    "end": "1478720"
  },
  {
    "text": "that um and so kind of there are a few different problems that we've solved",
    "start": "1478720",
    "end": "1484400"
  },
  {
    "text": "uh in this space that we can illustrate so",
    "start": "1484400",
    "end": "1489600"
  },
  {
    "text": "the first maximization problem in this space is uh kind of the problem of",
    "start": "1489600",
    "end": "1496240"
  },
  {
    "text": "balancing and this is kind of a an inherent problem with the distributed nature of m3 so you can",
    "start": "1496240",
    "end": "1503360"
  },
  {
    "text": "imagine let's say we have three full nodes right with 30 days of data so kind of they",
    "start": "1503360",
    "end": "1509679"
  },
  {
    "text": "have a look back period of 30 days that we're keeping where we're fully at capacity",
    "start": "1509679",
    "end": "1515919"
  },
  {
    "text": "with those 30 days we we want to kind of expand our cluster so that you know um we can let's say add",
    "start": "1515919",
    "end": "1523360"
  },
  {
    "text": "up to 90 days or something um then we add go then we go from kind of",
    "start": "1523360",
    "end": "1530720"
  },
  {
    "text": "three to nine notes total so we're going through a migration where we went to add",
    "start": "1530720",
    "end": "1536080"
  },
  {
    "text": "six more nodes to our cluster obviously when you first do this those",
    "start": "1536080",
    "end": "1542159"
  },
  {
    "text": "six newest nodes are completely empty they have no data um what will happen in kind of",
    "start": "1542159",
    "end": "1549360"
  },
  {
    "text": "a world where you know we're not taking any action to rebalance in any way",
    "start": "1549360",
    "end": "1554559"
  },
  {
    "text": "after a single day our cluster is going to be immensely lopsided",
    "start": "1554559",
    "end": "1559600"
  },
  {
    "text": "because you know we'll have the the new six nodes will have taken rights and so they'll have",
    "start": "1559600",
    "end": "1565600"
  },
  {
    "text": "now kind of a day's worth of data distributed among them but then you know the original uh three",
    "start": "1565600",
    "end": "1572799"
  },
  {
    "text": "nodes have almost all of the data still and like this has many different implications that are that are",
    "start": "1572799",
    "end": "1579760"
  },
  {
    "text": "negative so for one um the query load is immensely kind of imbalanced in a way",
    "start": "1579760",
    "end": "1587200"
  },
  {
    "text": "that would result in slower speeds because you can imagine searching through all of the data um on these like really",
    "start": "1587200",
    "end": "1594799"
  },
  {
    "text": "large on these instances with way more data it's going to be much slower than if that were",
    "start": "1594799",
    "end": "1599919"
  },
  {
    "text": "actually like evenly distributed among all nine different nodes um another problem is that this is just",
    "start": "1599919",
    "end": "1607520"
  },
  {
    "text": "very you know operationally cumbersome because",
    "start": "1607520",
    "end": "1612720"
  },
  {
    "text": "you have these nodes that are kind of changing over long periods of time",
    "start": "1612720",
    "end": "1617919"
  },
  {
    "text": "in how much data they actually will have right so kind of at first three of these nodes",
    "start": "1617919",
    "end": "1623760"
  },
  {
    "text": "are huge and full but then over time that will go down over 30 days in this example",
    "start": "1623760",
    "end": "1629520"
  },
  {
    "text": "and so having to maintain and efficiently only kind of provision instances to what",
    "start": "1629520",
    "end": "1635840"
  },
  {
    "text": "you actually need in terms of you know total storage space uh is is much more difficult to manage over",
    "start": "1635840",
    "end": "1643600"
  },
  {
    "text": "time and then lastly it's just very inefficient because like you could to make things operationally easier you",
    "start": "1643600",
    "end": "1649440"
  },
  {
    "text": "could still just provision everything to the max point at which you need to support but the downside there is then now",
    "start": "1649440",
    "end": "1655600"
  },
  {
    "text": "you're for like a whole 30-day period you're actually kind of wasting money on servers that",
    "start": "1655600",
    "end": "1663120"
  },
  {
    "text": "have you know only a fraction of the data that they're provisioned to hold",
    "start": "1663120",
    "end": "1669840"
  },
  {
    "start": "1669000",
    "end": "1915000"
  },
  {
    "text": "so kind of a solution to this is uh kind of an idea or a piece of",
    "start": "1670640",
    "end": "1677840"
  },
  {
    "text": "functionality called peer streaming and so the idea here is that whenever we add or remove a node to an",
    "start": "1677840",
    "end": "1685039"
  },
  {
    "text": "m3 db cluster in the background the nodes will kind of",
    "start": "1685039",
    "end": "1690159"
  },
  {
    "text": "collectively reassign what data belongs on what nodes and then they stream data",
    "start": "1690159",
    "end": "1697919"
  },
  {
    "text": "in a way to kind of perfectly rebalance it across the new kind of topology of the",
    "start": "1697919",
    "end": "1704159"
  },
  {
    "text": "cluster um and so obviously the benefits of this are that you know when we're",
    "start": "1704159",
    "end": "1711520"
  },
  {
    "text": "provisioning or adding these new nodes right at the outset we can provision them to have the",
    "start": "1711520",
    "end": "1716640"
  },
  {
    "text": "correct efficient amount of necessary resources and then also right at the outset of",
    "start": "1716640",
    "end": "1723600"
  },
  {
    "text": "kind of doing this edition as as soon as like the streaming has completed now the query load is is immediately",
    "start": "1723600",
    "end": "1729679"
  },
  {
    "text": "even whereas before it would be kind of a 30-day period where it's very lopsided",
    "start": "1729679",
    "end": "1735679"
  },
  {
    "text": "so kind of to walk through this example again of adding six nodes to",
    "start": "1735679",
    "end": "1740880"
  },
  {
    "text": "a cluster um let's say or let's kind of walk through",
    "start": "1740880",
    "end": "1747600"
  },
  {
    "text": "what the steps in this case would be so you know we've added these new nodes they're empty then collectively what",
    "start": "1747600",
    "end": "1754480"
  },
  {
    "text": "they decide is okay um we're going to assign some of these existing shards on the",
    "start": "1754480",
    "end": "1761919"
  },
  {
    "text": "leftmost you know three nodes to some subset of the right most ones so kind of",
    "start": "1761919",
    "end": "1768799"
  },
  {
    "text": "there's this background assignment of shards going on um then kind of the second and third steps",
    "start": "1768799",
    "end": "1775200"
  },
  {
    "text": "are actually you know streaming that data in the background from the existing",
    "start": "1775200",
    "end": "1780880"
  },
  {
    "text": "nodes to the new nodes and then as soon as the new nodes have a given new shard fully",
    "start": "1780880",
    "end": "1789120"
  },
  {
    "text": "you know on their side they then kind of publicly say hey i have this shard now available and",
    "start": "1789120",
    "end": "1795919"
  },
  {
    "text": "then that leads to kind of the final step which is to say once shards are you know publicly",
    "start": "1795919",
    "end": "1802559"
  },
  {
    "text": "said to be made available by their new destination then finally the",
    "start": "1802559",
    "end": "1808320"
  },
  {
    "text": "the existing nodes can fully drop that data uh and then be kind of rebalanced back to what",
    "start": "1808320",
    "end": "1816080"
  },
  {
    "text": "their peers would have and so kind of the advantage here clearly is now",
    "start": "1816080",
    "end": "1822159"
  },
  {
    "text": "instead of having to provision these these nodes at a point that's like much higher",
    "start": "1822159",
    "end": "1827600"
  },
  {
    "text": "to kind of the max point that they could be we could just provision them at the outset to have been you know what",
    "start": "1827600",
    "end": "1834640"
  },
  {
    "text": "the expected rebalance would look like um and then you know oh",
    "start": "1834640",
    "end": "1841840"
  },
  {
    "text": "additionally to kind of the the provisioning benefit we also now have kind of even query load",
    "start": "1841840",
    "end": "1848159"
  },
  {
    "text": "distributed in parallel across all these nodes rather than having kind of some nodes incur much more of a given",
    "start": "1848159",
    "end": "1854880"
  },
  {
    "text": "query cost than others and just to kind of compare that benefit",
    "start": "1854880",
    "end": "1861679"
  },
  {
    "text": "to kind of some alternative uh you know monitoring solution strategies",
    "start": "1861679",
    "end": "1867120"
  },
  {
    "text": "uh imagine how you know with a solution that is putting all of the the data into some",
    "start": "1867120",
    "end": "1874799"
  },
  {
    "text": "long-term kind of cloud storage like s3 or gcs um while that kind of does have this",
    "start": "1874799",
    "end": "1883279"
  },
  {
    "text": "indefinite scale still um again you have this kind of single node execution issue where",
    "start": "1883279",
    "end": "1890320"
  },
  {
    "text": "when you're executing a query across all of that data here's a case where",
    "start": "1890320",
    "end": "1896640"
  },
  {
    "text": "you're it actually is executing all the data on this single node whereas",
    "start": "1896640",
    "end": "1901679"
  },
  {
    "text": "in kind of the the peer stream distributed case all of that's being equally distributed",
    "start": "1901679",
    "end": "1907919"
  },
  {
    "text": "across nine different nine different instances",
    "start": "1907919",
    "end": "1914320"
  },
  {
    "start": "1915000",
    "end": "1971000"
  },
  {
    "text": "cool so now let's talk about query load so uh",
    "start": "1915919",
    "end": "1922640"
  },
  {
    "text": "another maximization problem is trying to make sure that when we're provisioning",
    "start": "1922640",
    "end": "1928320"
  },
  {
    "text": "instances um we're doing so efficient efficiently um and so",
    "start": "1928320",
    "end": "1934960"
  },
  {
    "text": "here's a graph of kind of query load over a couple of weeks and this kind of shows how",
    "start": "1934960",
    "end": "1941919"
  },
  {
    "text": "while query load tends to be generally consistent it also is kind of unpredictably",
    "start": "1941919",
    "end": "1949120"
  },
  {
    "text": "spiky in many different cases and so then the question is like given that kind of pattern of usage how do we",
    "start": "1949120",
    "end": "1956080"
  },
  {
    "text": "make sure that our nodes are provisioned in a way that is resistant to out of memory issues and we'll be able",
    "start": "1956080",
    "end": "1963679"
  },
  {
    "text": "to handle the cases where there's way more load than than the norm",
    "start": "1963679",
    "end": "1971679"
  },
  {
    "text": "so the way we've sought to tackle this in m3 is by providing kind of",
    "start": "1971679",
    "end": "1978559"
  },
  {
    "text": "ability to avoid having to provision uh query resources to",
    "start": "1978559",
    "end": "1985120"
  },
  {
    "text": "handle worst case scenarios and but and and to achieve that we kind of offer controls to tune",
    "start": "1985120",
    "end": "1991600"
  },
  {
    "text": "clusters so that they're protected against those worst case scenarios",
    "start": "1991600",
    "end": "1996640"
  },
  {
    "text": "as well as automatic transparency into this usage so that engineers who",
    "start": "1996640",
    "end": "2002320"
  },
  {
    "text": "are tuning these clusters can can do so effectively",
    "start": "2002320",
    "end": "2007519"
  },
  {
    "text": "um so one limit that can be put in place to kind",
    "start": "2007519",
    "end": "2014799"
  },
  {
    "start": "2008000",
    "end": "2121000"
  },
  {
    "text": "of allow nodes to be protected against these like this spiky behavior is being able to",
    "start": "2014799",
    "end": "2021279"
  },
  {
    "text": "kind of put a cap on the concurrent memory that would be resulting from all queries",
    "start": "2021279",
    "end": "2029440"
  },
  {
    "text": "running in a given period of time on a node so",
    "start": "2029440",
    "end": "2035200"
  },
  {
    "text": "in m3db nodes we automatically emit a metric that allows us to get a sense",
    "start": "2036559",
    "end": "2042480"
  },
  {
    "text": "of what that kind of peak concurrent memory usage is over time so you can then kind of very easily",
    "start": "2042480",
    "end": "2050079"
  },
  {
    "text": "go look at your historical use in these nodes and then use that to inform kind of",
    "start": "2050079",
    "end": "2055839"
  },
  {
    "text": "limits that you set so you can just put that you know right at what is the reasonable",
    "start": "2055839",
    "end": "2060878"
  },
  {
    "text": "median normal uh query load that you expect to support and then um have that be the cap",
    "start": "2060879",
    "end": "2068878"
  },
  {
    "text": "so that uh if if in the case where that spikes way above what we've",
    "start": "2068879",
    "end": "2075760"
  },
  {
    "text": "provisioned for the nodes will actually just kind of either um abandon queries or return kind of",
    "start": "2075760",
    "end": "2082158"
  },
  {
    "text": "partial results for queries to to make sure that we're we're remaining under this memory limit",
    "start": "2082159",
    "end": "2088000"
  },
  {
    "text": "and so you can see here all this can be done via configs that are referenced in the m3db",
    "start": "2088000",
    "end": "2094158"
  },
  {
    "text": "docs and so here you actually just specify kind of the number of blocks which is kind of like a",
    "start": "2094159",
    "end": "2099760"
  },
  {
    "text": "consistent um consistent amount of memory that would be pulled into memory",
    "start": "2099760",
    "end": "2105200"
  },
  {
    "text": "and you can specify kind of the how many of those blocks you want to allow to to be pulled into memory",
    "start": "2105200",
    "end": "2112160"
  },
  {
    "text": "concurrently as a result of queries in some given look back period and in this case it would be like within a",
    "start": "2112160",
    "end": "2118320"
  },
  {
    "text": "five second kind of look back um and then on top of being",
    "start": "2118320",
    "end": "2123599"
  },
  {
    "text": "able to kind of limit kind of the memory being pulled in across all queries in a given time",
    "start": "2123599",
    "end": "2130480"
  },
  {
    "text": "period we also emit metrics for single query",
    "start": "2130480",
    "end": "2137359"
  },
  {
    "text": "uh memory costs and and allow people to set limits based on that as",
    "start": "2137359",
    "end": "2143440"
  },
  {
    "text": "well and that's very useful because it allows you to kind of ensure that um there aren't",
    "start": "2143440",
    "end": "2151440"
  },
  {
    "text": "you know single culprit queries taking down different database nodes and you're not",
    "start": "2151440",
    "end": "2156800"
  },
  {
    "text": "having to cater towards those one-off uh unique unique kind of",
    "start": "2156800",
    "end": "2162480"
  },
  {
    "text": "uniquely costly uh query instances um so in the same way with the global",
    "start": "2162480",
    "end": "2168720"
  },
  {
    "text": "side we have metrics that inform this we also then from the config side allow people to set",
    "start": "2168720",
    "end": "2174079"
  },
  {
    "text": "these types of caps and in this case you can actually set it so that it's either on series and or on",
    "start": "2174079",
    "end": "2181040"
  },
  {
    "text": "docs or or blocks as kind of the tracking of memory um and then you can",
    "start": "2181040",
    "end": "2186720"
  },
  {
    "text": "also optionally set here if you want queries to fail in cases where they're exceeding a memory limit or just kind of",
    "start": "2186720",
    "end": "2194480"
  },
  {
    "text": "truncate the result so it still returns you results but just only a portion of them",
    "start": "2194480",
    "end": "2201200"
  },
  {
    "start": "2199000",
    "end": "2284000"
  },
  {
    "text": "and so then lastly a maximization problem is kind of handling the ever increasing",
    "start": "2201200",
    "end": "2209920"
  },
  {
    "text": "uh right load that we see with you know the the the increasing",
    "start": "2209920",
    "end": "2215599"
  },
  {
    "text": "cardinality of metrics over time so obviously if if literally we're seeing just increases in the number of",
    "start": "2215599",
    "end": "2222240"
  },
  {
    "text": "series being produced we could just linearly pay more to support that",
    "start": "2222240",
    "end": "2227359"
  },
  {
    "text": "but then the question is how do we how do we make sure that what we're paying for",
    "start": "2227359",
    "end": "2232800"
  },
  {
    "text": "actually is getting the most engineering value uh and the way we can do this is by",
    "start": "2232800",
    "end": "2238560"
  },
  {
    "text": "is via this kind of other component that can sit alongside the",
    "start": "2238560",
    "end": "2243760"
  },
  {
    "text": "coordinator and that's called the m3 aggregator and so what what this",
    "start": "2243760",
    "end": "2248800"
  },
  {
    "text": "service does is it allows us to be optionally more selective about the metrics and dimensions we",
    "start": "2248800",
    "end": "2256079"
  },
  {
    "text": "actually care about so that we're not needlessly storing things that we ever actually will look",
    "start": "2256079",
    "end": "2262400"
  },
  {
    "text": "at um and get engineering value for and so the kind of the functionality it actually",
    "start": "2262400",
    "end": "2268960"
  },
  {
    "text": "achieves is being able to kind of re-aggregate metrics by different dimensions to",
    "start": "2268960",
    "end": "2275359"
  },
  {
    "text": "produce different metrics at different types of kind of resolutions and retentions and we'll kind of walk through what that",
    "start": "2275359",
    "end": "2281680"
  },
  {
    "text": "looks like so if we kind of think back to our http",
    "start": "2281680",
    "end": "2288480"
  },
  {
    "text": "request latency example let's imagine how uh let's imagine how many series would",
    "start": "2288480",
    "end": "2295280"
  },
  {
    "text": "comprise this with you know a real life example so if we were tracking http request latency so in this",
    "start": "2295280",
    "end": "2303680"
  },
  {
    "text": "case we're not actually just tracking the count of requests in this case we're actually bucketing the time that request took into many",
    "start": "2303680",
    "end": "2310560"
  },
  {
    "text": "different histogram buckets so here we would actually have you know a dimension",
    "start": "2310560",
    "end": "2316240"
  },
  {
    "text": "called bucket and that let's say we have 30 different buckets that make up that histogram",
    "start": "2316240",
    "end": "2321520"
  },
  {
    "text": "then let's say we have 10 different status codes 50 different routes four active versions four regions",
    "start": "2321520",
    "end": "2329280"
  },
  {
    "text": "and then you know uh again this kind of pod dimension which are kind of",
    "start": "2329280",
    "end": "2334800"
  },
  {
    "text": "ephemeral pod names that are changing over time of a hundred so if you kind of multiply",
    "start": "2334800",
    "end": "2340160"
  },
  {
    "text": "all those together this metric would be comprised of actually 24 million series under the hood um if",
    "start": "2340160",
    "end": "2348079"
  },
  {
    "text": "though let's say we just dropped that single pod dimension and you know in this case we don't",
    "start": "2348079",
    "end": "2355119"
  },
  {
    "text": "actually care about the pods because when we're thinking about http request latency",
    "start": "2355119",
    "end": "2360240"
  },
  {
    "text": "we're really thinking about it from kind of a service level or kind of a region level we're never",
    "start": "2360240",
    "end": "2365359"
  },
  {
    "text": "thinking about it as like a single pod versus another pod that was that's running the same service",
    "start": "2365359",
    "end": "2371520"
  },
  {
    "text": "so if you were to just not store the series associated with having to break out by",
    "start": "2371520",
    "end": "2376880"
  },
  {
    "text": "pods that actually reduces in this case the total number of series down by a factor of",
    "start": "2376880",
    "end": "2382800"
  },
  {
    "text": "you know 100 and that would only be 240 000 series so if we could actually be able to do",
    "start": "2382800",
    "end": "2390720"
  },
  {
    "text": "this we actually we can way more efficiently choose what we're storing um but get the same kind of engineering",
    "start": "2390720",
    "end": "2397359"
  },
  {
    "text": "value for it so this is also to kind of illustrate why it's valid for",
    "start": "2397359",
    "end": "2402560"
  },
  {
    "start": "2398000",
    "end": "2650000"
  },
  {
    "text": "us to be able to just not care about something like pod so imagine our m3 coordinator read service",
    "start": "2402560",
    "end": "2408800"
  },
  {
    "text": "so this is the same service running in the same area right but just over time every time we redeploy it",
    "start": "2408800",
    "end": "2415119"
  },
  {
    "text": "um it's actually being tracked as a new metric right or a new not a new metric but like the same metric is being tracked as kind of a",
    "start": "2415119",
    "end": "2422240"
  },
  {
    "text": "new underlying series which is kind of illustrated by the fact that each of these colored lines is a",
    "start": "2422240",
    "end": "2428000"
  },
  {
    "text": "distinct series so when you're when we're actually querying this latency we don't",
    "start": "2428000",
    "end": "2434720"
  },
  {
    "text": "care that how would redeployment happen these like five different times throughout this period",
    "start": "2434720",
    "end": "2439760"
  },
  {
    "text": "we're actually going to just aggregate that together and the dimensionality of pod is just going to be kind of lost but",
    "start": "2439760",
    "end": "2445920"
  },
  {
    "text": "so what from like the user side we don't care that this had happened and",
    "start": "2445920",
    "end": "2451680"
  },
  {
    "text": "when we query it it'll actually look like this because we're going to we're going to query the the latency metric",
    "start": "2451680",
    "end": "2458000"
  },
  {
    "text": "we're going to um actually view it from the perspective of just the coordinator",
    "start": "2458000",
    "end": "2463119"
  },
  {
    "text": "not the coordinator that was deployed at time a versus the coordinator that was deployed at time b",
    "start": "2463119",
    "end": "2468160"
  },
  {
    "text": "etc so if if we're if we're doing this aggregation at query time and we don't",
    "start": "2468160",
    "end": "2473760"
  },
  {
    "text": "care about this dimensionality uh otherwise then why are we storing it in that way",
    "start": "2473760",
    "end": "2478960"
  },
  {
    "text": "because kind of when you look at what the metrics look like just broken out by all the different pods",
    "start": "2478960",
    "end": "2484800"
  },
  {
    "text": "that would happen over kind of like a let's say 90 day period where you're doing deployments often",
    "start": "2484800",
    "end": "2489839"
  },
  {
    "text": "um you're incurring this needless exp like multiplicative series storage for",
    "start": "2489839",
    "end": "2496000"
  },
  {
    "text": "something that you don't even look at it's and so it's very inefficient um so kind of",
    "start": "2496000",
    "end": "2501440"
  },
  {
    "text": "to solve this problem what you can add with the aggregator are roll up rules",
    "start": "2501440",
    "end": "2507280"
  },
  {
    "text": "and essentially what what you can do is you can say okay i'm going to kind of sum up",
    "start": "2507280",
    "end": "2513680"
  },
  {
    "text": "all of these or sum up a particular metrics values by the dimensions i",
    "start": "2513680",
    "end": "2520800"
  },
  {
    "text": "actually care about but exclude you know some other dimension or some set of dimensions and so in this",
    "start": "2520800",
    "end": "2527040"
  },
  {
    "text": "case we're saying grouped by all the dimensions except for pod um and so what that ultimately looks like",
    "start": "2527040",
    "end": "2533760"
  },
  {
    "text": "is you know now on disk it's actually a single series instead of you know what this would look",
    "start": "2533760",
    "end": "2539040"
  },
  {
    "text": "like um and so this is kind of a before after picture of what that kind of collapsing of",
    "start": "2539040",
    "end": "2546560"
  },
  {
    "text": "your seri collapsing of your metric down by a particular dimension would look",
    "start": "2546560",
    "end": "2551760"
  },
  {
    "text": "like where you have many different series broken out by pod name and then we've collapsed them into a single one",
    "start": "2551760",
    "end": "2558319"
  },
  {
    "text": "and then very lastly uh kind of another value of the aggregation side is it",
    "start": "2558319",
    "end": "2563760"
  },
  {
    "text": "allows you to choose how long we keep data around for and at what level of granularity and what",
    "start": "2563760",
    "end": "2570480"
  },
  {
    "text": "this allows us to be more selective about is to be able to say hey",
    "start": "2570480",
    "end": "2575760"
  },
  {
    "text": "okay maybe i care about um you know the most raw level of granularity",
    "start": "2575760",
    "end": "2581760"
  },
  {
    "text": "possible for kind of the last week or last month because diagnosing and debugging issues",
    "start": "2581760",
    "end": "2588880"
  },
  {
    "text": "for that purpose it's it's important that i have like the very most raw level of granularity",
    "start": "2588880",
    "end": "2594960"
  },
  {
    "text": "possible but let's say i also really do care about kind of year-long trends or",
    "start": "2594960",
    "end": "2600319"
  },
  {
    "text": "month-long trends but almost never would i need to be breaking out by kind of the same level of granularity",
    "start": "2600319",
    "end": "2606079"
  },
  {
    "text": "you know a year ago so what you can do at the aggregation side is you can say okay",
    "start": "2606079",
    "end": "2611680"
  },
  {
    "text": "you know we want to use this level of resolution so time resolution",
    "start": "2611680",
    "end": "2616880"
  },
  {
    "text": "so kind of like the granularity with respect to how often you're measuring something for kind of this period of look back",
    "start": "2616880",
    "end": "2624160"
  },
  {
    "text": "time but then have this different aggregation that uses a different combination of",
    "start": "2624160",
    "end": "2630480"
  },
  {
    "text": "resolution and retention and what that allows you to do is say okay i want to take and save stuff really granularly",
    "start": "2630480",
    "end": "2637760"
  },
  {
    "text": "for short periods of time and not so granularly for long periods of time and as a result it means that we're kind",
    "start": "2637760",
    "end": "2645280"
  },
  {
    "text": "of storing only what we actually will be looking at and not needlessly storing just everything",
    "start": "2645280",
    "end": "2650880"
  },
  {
    "start": "2650000",
    "end": "2708000"
  },
  {
    "text": "so just to quickly summarize and we'll get to kind of the q a in a sec",
    "start": "2650880",
    "end": "2658160"
  },
  {
    "text": "the three kind of maximization problems solutions we reviewed here are peer streaming and so that's rebalancing",
    "start": "2658160",
    "end": "2664560"
  },
  {
    "text": "the different nodes so that load and storage is evenly distributed",
    "start": "2664560",
    "end": "2669680"
  },
  {
    "text": "across them um query limits and metrics which allows us to you know provision our nodes for the",
    "start": "2669680",
    "end": "2677119"
  },
  {
    "text": "normal load case and not the worst node case um and then lastly aggregator roll-ups which allows us to be",
    "start": "2677119",
    "end": "2683200"
  },
  {
    "text": "way more efficient in choosing what series actually are stored versus",
    "start": "2683200",
    "end": "2688400"
  },
  {
    "text": "and and you know informing that decision really based on kind of the engineering",
    "start": "2688400",
    "end": "2694319"
  },
  {
    "text": "value or the engineer value um rather than just de facto",
    "start": "2694319",
    "end": "2699440"
  },
  {
    "text": "storing everything given that that costs money and we want to make sure that the insights we're",
    "start": "2699440",
    "end": "2704560"
  },
  {
    "text": "paying for we're getting the most insight per dollar so thank you for coming i just want to",
    "start": "2704560",
    "end": "2711200"
  },
  {
    "start": "2708000",
    "end": "2807000"
  },
  {
    "text": "do a quick shout out before we get to questions to kind of all the m3 contributors so uh you know",
    "start": "2711200",
    "end": "2717520"
  },
  {
    "text": "the folks at uber which is the company at which uh um m3 originated linkedin uh",
    "start": "2717520",
    "end": "2724319"
  },
  {
    "text": "cloudera many other you know great contributors to the m3 open source project um we also",
    "start": "2724319",
    "end": "2731200"
  },
  {
    "text": "have like slack rooms and office hours that are linked here so feel free to reach out through any of",
    "start": "2731200",
    "end": "2736240"
  },
  {
    "text": "those media um but awesome and now we can kind of jump to questions",
    "start": "2736240",
    "end": "2747838"
  },
  {
    "text": "okay",
    "start": "2758839",
    "end": "2761839"
  },
  {
    "text": "i guess should i do this in order maybe i'll just do in reverse order okay regarding maximus maximization problem b",
    "start": "2766560",
    "end": "2774480"
  },
  {
    "text": "can you just scale up query nodes in a couple of seconds",
    "start": "2774480",
    "end": "2779440"
  },
  {
    "text": "let's see regarding maximization problem b",
    "start": "2781520",
    "end": "2788240"
  },
  {
    "text": "sorry i'm just going to pull up that slide",
    "start": "2788240",
    "end": "2791920"
  },
  {
    "text": "and i can reshare i just need to zoom out okay",
    "start": "2795040",
    "end": "2803839"
  },
  {
    "text": "regarding access it should probably be can you just scrub query nodes in a",
    "start": "2804480",
    "end": "2810560"
  },
  {
    "start": "2807000",
    "end": "3024000"
  },
  {
    "text": "couple of seconds oh interestingly so yeah so i guess that so dynamic scaling of the nodes i guess",
    "start": "2810560",
    "end": "2819040"
  },
  {
    "text": "the problem with that is it's really hard to do that in kind of a just-in-time fashion right so like yes you can have elastic scaling",
    "start": "2819040",
    "end": "2828240"
  },
  {
    "text": "to some degree um but that at least on the m3 side we don't",
    "start": "2828240",
    "end": "2834240"
  },
  {
    "text": "have that kind of as a first class feature and i think for most people who are kind of",
    "start": "2834240",
    "end": "2839920"
  },
  {
    "text": "managing their resource allocation within their infrastructure it's really hard to do this in a way that's like",
    "start": "2839920",
    "end": "2845760"
  },
  {
    "text": "so dynamically elastic that's you know a result of just kind of",
    "start": "2845760",
    "end": "2851040"
  },
  {
    "text": "current user usage and again the reason that is is because you can see in this case how like unpredictably",
    "start": "2851040",
    "end": "2857839"
  },
  {
    "text": "spiky this is it's not like we're seeing something trending up and so i have time to actually kind of",
    "start": "2857839",
    "end": "2863119"
  },
  {
    "text": "provision the instance to have more memory um you would really need in order to support those like huge spikes that",
    "start": "2863119",
    "end": "2870000"
  },
  {
    "text": "come about in an unpredictable fashion uh you you would really need to provision",
    "start": "2870000",
    "end": "2875359"
  },
  {
    "text": "it ahead of time as opposed to being able to just dynamically do that in advance i guess there probably there",
    "start": "2875359",
    "end": "2880800"
  },
  {
    "text": "are ways to maybe know that um or maybe like cue things",
    "start": "2880800",
    "end": "2886640"
  },
  {
    "text": "up and redistribute those over time but but as for kind of like dynamic elastic scaling um i think that's that's a pretty tough",
    "start": "2886640",
    "end": "2893680"
  },
  {
    "text": "kind of solution to the problem of this like you know spiky behavior as opposed to with the limit case where",
    "start": "2893680",
    "end": "2900559"
  },
  {
    "text": "you're kind of just saying these are these are rare cases that we just don't want to be harmed by and instead we can make sure that the",
    "start": "2900559",
    "end": "2906640"
  },
  {
    "text": "resource spending we're planning for is is is not kind of needlessly excessive and",
    "start": "2906640",
    "end": "2913599"
  },
  {
    "text": "supporting the on mohamed worst case",
    "start": "2913599",
    "end": "2917920"
  },
  {
    "text": "so when you write in your diagram query to s3 gcs are you referring to remote right",
    "start": "2919359",
    "end": "2925680"
  },
  {
    "text": "to s3 using prometheus or other open source systems so i guess uh",
    "start": "2925680",
    "end": "2931359"
  },
  {
    "text": "it so in that case i i it really is kind of like both so i think there are there are many",
    "start": "2931359",
    "end": "2938000"
  },
  {
    "text": "different open source solutions who's that kind of sit in between prometheus",
    "start": "2938000",
    "end": "2944000"
  },
  {
    "text": "and some cloud storage as the fundamental solution so you know uh there are a few different",
    "start": "2944000",
    "end": "2950480"
  },
  {
    "text": "open source projects that whose kind of approach is that and um that that is kind of",
    "start": "2950480",
    "end": "2959200"
  },
  {
    "text": "what we're talking about when we're talking about the uh i can i can go back to that slide kind of this single execution limitation",
    "start": "2959200",
    "end": "2967440"
  },
  {
    "text": "right where uh no matter what service is sitting in front of your",
    "start": "2967440",
    "end": "2974240"
  },
  {
    "text": "big cloud storage you know uh option that that single query",
    "start": "2974240",
    "end": "2980880"
  },
  {
    "text": "instance is gonna be having this limitation of being just one instance that needs to incur all of that",
    "start": "2980880",
    "end": "2986559"
  },
  {
    "text": "index cost rather than it being able to be distributed across many different",
    "start": "2986559",
    "end": "2991760"
  },
  {
    "text": "machines let's see what algorithm",
    "start": "2991760",
    "end": "2998000"
  },
  {
    "text": "is or that one was new maybe i should have done this in order",
    "start": "2998000",
    "end": "3003680"
  },
  {
    "text": "so you mean when using m3 you should deploy three clusters of m3db",
    "start": "3008960",
    "end": "3014720"
  },
  {
    "text": "uh so so three so i guess the way to think about kind of the deployment architecture",
    "start": "3014720",
    "end": "3022720"
  },
  {
    "text": "is it's pretty configurable to kind of what one's use case would be but in general",
    "start": "3022720",
    "end": "3030400"
  },
  {
    "start": "3024000",
    "end": "3120000"
  },
  {
    "text": "um kind of a recommended deployment configuration would be that you have",
    "start": "3030400",
    "end": "3036880"
  },
  {
    "text": "kind of three different replications uh or replicas so that you can have kind of the two of",
    "start": "3036880",
    "end": "3043119"
  },
  {
    "text": "three quorum consistent uh read guarantees um and",
    "start": "3043119",
    "end": "3049839"
  },
  {
    "text": "each of these you can think of as kind of a different cluster and then you can indefinitely add nodes",
    "start": "3049839",
    "end": "3055760"
  },
  {
    "text": "to those clusters so this is a case where like in each of these like replica clusters we have three nodes in them",
    "start": "3055760",
    "end": "3061359"
  },
  {
    "text": "but you can add more nodes to them over time and in this case it's just three and three",
    "start": "3061359",
    "end": "3067760"
  },
  {
    "text": "coincidentally but like you could have you know five nodes in each of these clusters or more",
    "start": "3067760",
    "end": "3073839"
  },
  {
    "text": "as well for example um can you add a node and immediately be",
    "start": "3073839",
    "end": "3078880"
  },
  {
    "text": "available to read or do you have to wait for shards to relocate to use it",
    "start": "3078880",
    "end": "3087440"
  },
  {
    "text": "like like it happens in kapha",
    "start": "3087440",
    "end": "3097838"
  },
  {
    "start": "3120000",
    "end": "3384000"
  },
  {
    "text": "that uh would be coming in and until kind of the the the nude shard",
    "start": "3120480",
    "end": "3126160"
  },
  {
    "text": "ownerships are made public that that would remain so and but just",
    "start": "3126160",
    "end": "3131599"
  },
  {
    "text": "kind of as as the new nodes are fully claiming those shards then the reads would be like directed to them instead of the",
    "start": "3131599",
    "end": "3137440"
  },
  {
    "text": "original nodes what do you mean by scaling the",
    "start": "3137440",
    "end": "3143520"
  },
  {
    "text": "aggregations in the query does it happen inside the diminished or you mean the query nodes",
    "start": "3143520",
    "end": "3149680"
  },
  {
    "text": "is using other query nodes to distribute the query notes all right let me see i'm going to read",
    "start": "3149680",
    "end": "3156240"
  },
  {
    "text": "that once more what do you mean by scaling the aggregations in the query",
    "start": "3156240",
    "end": "3162720"
  },
  {
    "text": "does it happen inside the db nodes or you mean the query nodes is using",
    "start": "3163040",
    "end": "3170559"
  },
  {
    "text": "other query nodes to distribute the query notes i don't know if i totally understand the",
    "start": "3170559",
    "end": "3177040"
  },
  {
    "text": "question but as but it sounds kind of so correct me if i'm wrong and and um you know clarify the question",
    "start": "3177040",
    "end": "3185200"
  },
  {
    "text": "if i'm misunderstanding but it sounds like you're asking",
    "start": "3185200",
    "end": "3190640"
  },
  {
    "text": "how is it that we distribute kind of the query load across the different nodes and if that's the question um",
    "start": "3191680",
    "end": "3200000"
  },
  {
    "text": "the way to think about it is kind of like all of the series are ultimately kind of sharded randomly across",
    "start": "3200000",
    "end": "3207440"
  },
  {
    "text": "the different nodes and so when a query is issued that query fans out to",
    "start": "3207440",
    "end": "3214319"
  },
  {
    "text": "all of the different nodes each node is responsible for matching the relevant series data for that query",
    "start": "3214319",
    "end": "3222960"
  },
  {
    "text": "and then returning it back up to kind of the query service who then",
    "start": "3222960",
    "end": "3228240"
  },
  {
    "text": "pulls it all together to return to the user um and so kind of in that way though like",
    "start": "3228240",
    "end": "3234000"
  },
  {
    "text": "the query nodes themselves or sorry the db nodes themselves are doing various like you know types of",
    "start": "3234000",
    "end": "3240319"
  },
  {
    "text": "aggregations but also because all the data is sharded randomly a given query",
    "start": "3240319",
    "end": "3245920"
  },
  {
    "text": "is kind of incurring a cost divided by n different nodes as opposed to the cost being kind of you know",
    "start": "3245920",
    "end": "3252640"
  },
  {
    "text": "lopsided on one node versus another or something like that um what what algorithm is used to",
    "start": "3252640",
    "end": "3260000"
  },
  {
    "text": "rebalance shards i mean how is it done collectively ah well so kind of",
    "start": "3260000",
    "end": "3266640"
  },
  {
    "text": "the so there there are a few different kind of uh like um consensus algorithms",
    "start": "3266640",
    "end": "3274880"
  },
  {
    "text": "like that that are available and so i i'm pretty sure the the consensus",
    "start": "3274880",
    "end": "3280240"
  },
  {
    "text": "algorithm in this case is just uh raft which you can look up and it's a pretty simple one which is basically",
    "start": "3280240",
    "end": "3285599"
  },
  {
    "text": "just a way of kind of claiming ownership in a distributed fashion and making sure kind of all of the the",
    "start": "3285599",
    "end": "3293599"
  },
  {
    "text": "the nodes that comprise the cluster land on the same answer of who owns what",
    "start": "3293599",
    "end": "3299359"
  },
  {
    "text": "shard um and so kind of that that process is kind of done and then",
    "start": "3299359",
    "end": "3307359"
  },
  {
    "text": "where different shards are being claimed by new nodes um then that data is streamed to them",
    "start": "3307359",
    "end": "3314160"
  },
  {
    "text": "and then only once those shards are then kind of made publicly said to have been kind of",
    "start": "3314160",
    "end": "3321440"
  },
  {
    "text": "fully fully retrieved by this new shard do the original node say okay now it's safe",
    "start": "3321440",
    "end": "3328000"
  },
  {
    "text": "for me to to dump my data but if it were to like not receive that then kind of the the",
    "start": "3328000",
    "end": "3333920"
  },
  {
    "text": "the streaming would be like retried in a different way and then the shard would be kind of re-consensus uh distributed to",
    "start": "3333920",
    "end": "3340160"
  },
  {
    "text": "some different note um all right i think that's the last",
    "start": "3340160",
    "end": "3347680"
  },
  {
    "text": "of the queued up questions yeah hey ryan it's christy again um do you want to pull up that last slide of where folks",
    "start": "3347680",
    "end": "3353920"
  },
  {
    "text": "can find out more information or connect with you um just in case there are additional questions yeah awesome there are some",
    "start": "3353920",
    "end": "3359280"
  },
  {
    "text": "links here for slack um again ryan thanks for a great presentation and a lively discussion",
    "start": "3359280",
    "end": "3364319"
  },
  {
    "text": "here great to see that um and thank you everyone for attending a reminder that the recording and the slides will be posted later today to the",
    "start": "3364319",
    "end": "3371200"
  },
  {
    "text": "cncf webinars page at cncf.io webinars",
    "start": "3371200",
    "end": "3376400"
  },
  {
    "text": "we hope to see you at a future cmcf webinar have a great day everyone stay safe thanks thanks everyone",
    "start": "3376400",
    "end": "3386480"
  }
]
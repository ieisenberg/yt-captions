[
  {
    "text": "my name is Kish and he is Ryan we are um software Engineers from",
    "start": "240",
    "end": "5960"
  },
  {
    "text": "Red um and we are going to talk about highly",
    "start": "5960",
    "end": "11040"
  },
  {
    "text": "available keycloak and how we go about",
    "start": "11040",
    "end": "16519"
  },
  {
    "text": "it how you uh how many of you already use keycloak um show off",
    "start": "16640",
    "end": "23160"
  },
  {
    "text": "hands awesome for how uh how many of you are",
    "start": "23160",
    "end": "29279"
  },
  {
    "text": "attending Cube on for the first time pretty much it overlaps very",
    "start": "29279",
    "end": "36320"
  },
  {
    "text": "well and thank you for sticking around till the end of cubec con to attend this",
    "start": "36320",
    "end": "42440"
  },
  {
    "text": "and hopefully it will be a good takeaway uh for you",
    "start": "42440",
    "end": "47600"
  },
  {
    "text": "all um so",
    "start": "47600",
    "end": "54800"
  },
  {
    "text": "all right I think most of us saw this slide in the keynote today and Cube um",
    "start": "63840",
    "end": "73520"
  },
  {
    "text": "keycloak uh is a incubating part project and we are in that uh Chasm phase and we",
    "start": "73520",
    "end": "82320"
  },
  {
    "text": "always uh intend to explore the opportunities to improve",
    "start": "82320",
    "end": "87680"
  },
  {
    "text": "kylo and making it highly available is one of the aspects of it um little bit",
    "start": "87680",
    "end": "94880"
  },
  {
    "text": "of what we want to do today is to introduce keycloak and explain what it",
    "start": "94880",
    "end": "101360"
  },
  {
    "text": "means um for organizations and users alike uh initially and we'll go more uh",
    "start": "101360",
    "end": "109320"
  },
  {
    "text": "into the details of how we achieve High availability and",
    "start": "109320",
    "end": "115200"
  },
  {
    "text": "on all right what is the identity and access management and do you need one um",
    "start": "117680",
    "end": "125399"
  },
  {
    "text": "most of us if we put some credentials inside uh an application yes we would",
    "start": "125399",
    "end": "131840"
  },
  {
    "text": "need one um to keep our uh content secure and provide easier access to the",
    "start": "131840",
    "end": "139560"
  },
  {
    "text": "users and provide more seamless experience uh using single sign",
    "start": "139560",
    "end": "146239"
  },
  {
    "text": "on and how does that work um a user logs in to keycloak and he",
    "start": "146239",
    "end": "155440"
  },
  {
    "text": "requests for a token to access a particular resource keycloak makes sure",
    "start": "155440",
    "end": "160840"
  },
  {
    "text": "the user is um allowed to do that and verifies the",
    "start": "160840",
    "end": "167440"
  },
  {
    "text": "token and provides the access and there are multiple ways to do",
    "start": "167440",
    "end": "173720"
  },
  {
    "text": "it using OD z o n and different things that you do on an identity and access",
    "start": "173720",
    "end": "180680"
  },
  {
    "text": "management platform is to manage users uh manage their credentials",
    "start": "180680",
    "end": "186200"
  },
  {
    "text": "permissions handle user registration uh password uh reset and handling and",
    "start": "186200",
    "end": "195200"
  },
  {
    "text": "integrating the IM IM platform into your existing security",
    "start": "195200",
    "end": "200640"
  },
  {
    "text": "infrastructure so single sign on is cool on day one you your users now only have",
    "start": "201040",
    "end": "207239"
  },
  {
    "text": "to remember one password and only authenticate maybe once a day depending upon your session",
    "start": "207239",
    "end": "213519"
  },
  {
    "text": "TTL and you could also make it more secure using um additional",
    "start": "213519",
    "end": "219239"
  },
  {
    "text": "authentication like multiactor authentication pass Keys Etc you can customize now your front end of the",
    "start": "219239",
    "end": "226080"
  },
  {
    "text": "login um using custom themes make sense already for like a small application",
    "start": "226080",
    "end": "232439"
  },
  {
    "text": "right and this is how it will look uh when you first open key cloak once it's",
    "start": "232439",
    "end": "238280"
  },
  {
    "text": "configured the login screen for your applications and but this is all good for day one how",
    "start": "238280",
    "end": "246319"
  },
  {
    "text": "about day two now we look at integrating our existing security infrastructure",
    "start": "246319",
    "end": "252879"
  },
  {
    "text": "with keylo like alap and caros we would want to do identity brokering with saml",
    "start": "252879",
    "end": "259560"
  },
  {
    "text": "and oidc services and integrate with probably the existing stores like active",
    "start": "259560",
    "end": "265000"
  },
  {
    "text": "directory or your own database uh so that you are not uh spending spending more on cloud",
    "start": "265000",
    "end": "272919"
  },
  {
    "text": "costs um how you can do that like very similar uh user screens so that users",
    "start": "272919",
    "end": "279800"
  },
  {
    "text": "are having seamless experience and you can use the existing providers for uh",
    "start": "279800",
    "end": "287038"
  },
  {
    "text": "brokering uh and that looks uh great so what else is",
    "start": "287400",
    "end": "292479"
  },
  {
    "text": "required uh obviously once you have everything deployed and ready you want maintenance to be done you want use",
    "start": "292479",
    "end": "299880"
  },
  {
    "text": "workflows to be working you want your user passwords uh to be reset or recovered",
    "start": "299880",
    "end": "306199"
  },
  {
    "text": "you want new users to be self-registered without major uh um repetition of steps",
    "start": "306199",
    "end": "314199"
  },
  {
    "text": "you want the user data to be self-managed uh by the users themselves",
    "start": "314199",
    "end": "319280"
  },
  {
    "text": "or the admins and that reduces the number of tickets that you have to handle the number of calls you have to",
    "start": "319280",
    "end": "325840"
  },
  {
    "text": "be on as an admin and how we can do that like using some of",
    "start": "325840",
    "end": "332199"
  },
  {
    "text": "these screens um for password recovery and self-",
    "start": "332199",
    "end": "337520"
  },
  {
    "text": "registration and by the time you already realize",
    "start": "337520",
    "end": "342880"
  },
  {
    "text": "keylo is already an important infrastructure component and you are heavily relying on it for your uh",
    "start": "342880",
    "end": "349600"
  },
  {
    "text": "security and seamless authentication and you want it to be available 24 7 right and how do we do",
    "start": "349600",
    "end": "357960"
  },
  {
    "text": "that and to go more in detail um let's talk with Ryan thanks Kesh so",
    "start": "357960",
    "end": "365600"
  },
  {
    "text": "now that Key's critical in your infrastructure um if keyo was to go down",
    "start": "365600",
    "end": "371000"
  },
  {
    "text": "uh the tokens that you already have with your microservices or your using session datas if keycloak goes down then there's",
    "start": "371000",
    "end": "378000"
  },
  {
    "text": "nothing to say actually that's an acceptable token and so your business flow is completely disrupted and your",
    "start": "378000",
    "end": "385039"
  },
  {
    "text": "application's going to have downtime as well obviously we don't want that so in",
    "start": "385039",
    "end": "390520"
  },
  {
    "text": "order to understand the kind of ha Journey key cloer has gone on I'm first going to take a step back and explain",
    "start": "390520",
    "end": "396880"
  },
  {
    "text": "Key cloer is most basic and then kind of build a story from there so you can appreciate some of the challenges we",
    "start": "396880",
    "end": "402960"
  },
  {
    "text": "have in order to provide ha architectures so at the most basic we",
    "start": "402960",
    "end": "408960"
  },
  {
    "text": "have all keycloak users or clients in the case of microservices going to a single keycloak instance um within that",
    "start": "408960",
    "end": "416720"
  },
  {
    "text": "keycloak instance we have infin which is a inmemory cache that's there",
    "start": "416720",
    "end": "422560"
  },
  {
    "text": "for performance reasons and keycloak is reaching out to a traditional database",
    "start": "422560",
    "end": "428400"
  },
  {
    "text": "to uh persist state so in the event of restarts Etc all of your critical data",
    "start": "428400",
    "end": "433879"
  },
  {
    "text": "is still there so this is fine for Dev and proof of concept um but beyond that",
    "start": "433879",
    "end": "441360"
  },
  {
    "text": "this leaves a lot to be desired desired because if your single key cck instance goes down then like I said before your",
    "start": "441360",
    "end": "448960"
  },
  {
    "text": "workflows are not going to be able to proceed so typically what we see in",
    "start": "448960",
    "end": "454199"
  },
  {
    "text": "production is people utilize multiple keycloak instances so now we have two",
    "start": "454199",
    "end": "460319"
  },
  {
    "text": "keycloak pods in this example um talking to a persistent database we have two",
    "start": "460319",
    "end": "467039"
  },
  {
    "text": "instances in this example but it could be two three five you can horizontally scale as your requirements uh",
    "start": "467039",
    "end": "474520"
  },
  {
    "text": "demand so by adding these extra instances we get increased performance",
    "start": "474520",
    "end": "479759"
  },
  {
    "text": "because you benefit from parallelism and you get the increased resilience that we were talking about",
    "start": "479759",
    "end": "485919"
  },
  {
    "text": "today unfortunately this isn't without a cost though we now have the added complication of needing to ensure that",
    "start": "485919",
    "end": "492800"
  },
  {
    "text": "the cash uh that is maintained by all of the keycloak instances is both updated",
    "start": "492800",
    "end": "498479"
  },
  {
    "text": "and invalidated um as required when the keycloak state",
    "start": "498479",
    "end": "504360"
  },
  {
    "text": "changes um and you know this is cntf usually we see this deployed in",
    "start": "504360",
    "end": "509720"
  },
  {
    "text": "kubernetes because it's in kubernetes we can tolerate pod failures and if you",
    "start": "509720",
    "end": "515279"
  },
  {
    "text": "configure your Affinity settings appropriately you can also tolerate node failures however the crucial thing",
    "start": "515279",
    "end": "521880"
  },
  {
    "text": "that's missing here is this kubernetes cluster is deployed to a single availability zone so as much as the",
    "start": "521880",
    "end": "528720"
  },
  {
    "text": "cloud providers like to say that a a failures don't happen we all know they do from time to time and so we need a",
    "start": "528720",
    "end": "535800"
  },
  {
    "text": "solution that allows us to tolerate such failures",
    "start": "535800",
    "end": "540880"
  },
  {
    "text": "so you're probably going to guess where I'm going with this the solution to tolerating an a failure is to Simply",
    "start": "540880",
    "end": "547000"
  },
  {
    "text": "throw another a into the mix so now we have a multisite configuration and what",
    "start": "547000",
    "end": "552720"
  },
  {
    "text": "that looks like is we have az1 as before with our kubernetes cluster keycloak",
    "start": "552720",
    "end": "557800"
  },
  {
    "text": "pods um we also then have the second a with the exact same sack however as simple as this diagram",
    "start": "557800",
    "end": "565720"
  },
  {
    "text": "looks the reality is it's much more complicated than that because we now have to maintain the cache State across",
    "start": "565720",
    "end": "572120"
  },
  {
    "text": "a boundaries and we have to deploy the database in such a way that it's going",
    "start": "572120",
    "end": "578000"
  },
  {
    "text": "to be available if one of the A's go down previously we could deploy uh your database in just the same a as your",
    "start": "578000",
    "end": "584920"
  },
  {
    "text": "kubernetes cluster unfortunately that's no longer the case so yeah the big challenge is how do",
    "start": "584920",
    "end": "591560"
  },
  {
    "text": "we manage those uh bits of state and the other problem is how do we route user",
    "start": "591560",
    "end": "597320"
  },
  {
    "text": "requests when you're in a single C n his cluster you can rely on your service and your Ingress Etc to do that for you but",
    "start": "597320",
    "end": "605079"
  },
  {
    "text": "now we need a way to ensure that um keycloak requests only go to healthy",
    "start": "605079",
    "end": "610240"
  },
  {
    "text": "availability zones so to begin with I'll talk about how we do manage those user connections",
    "start": "610240",
    "end": "617120"
  },
  {
    "text": "um our proposal um is to use AWS is global accelerator uh the global",
    "start": "617120",
    "end": "623880"
  },
  {
    "text": "accelerator is nice it's very fast solution uh where appropriate it'll use Amazon inter internal Network the nice",
    "start": "623880",
    "end": "631440"
  },
  {
    "text": "thing about this solution is it's not dns-based if you use a DNS based solution here uh clients can actually",
    "start": "631440",
    "end": "639320"
  },
  {
    "text": "cach the IP resolution and you can attempt they will continually reattempt",
    "start": "639320",
    "end": "644399"
  },
  {
    "text": "to connect to fail A's um we don't have to worry about that with the global",
    "start": "644399",
    "end": "650040"
  },
  {
    "text": "accelerator so the idea is that now all keycloak users connect via a accelerator",
    "start": "650040",
    "end": "657519"
  },
  {
    "text": "endpoint the accelerator then communicates with a network load balancer uh that's located in each of",
    "start": "657519",
    "end": "663440"
  },
  {
    "text": "our two availability zones and the network load balancer forwards traffics",
    "start": "663440",
    "end": "669440"
  },
  {
    "text": "to the healthy keycloak pods within the kubernetes cluster that's in the same availability",
    "start": "669440",
    "end": "675480"
  },
  {
    "text": "Zone there's then periodic health checks at both the network load balancer level and the global accelerator to see um if",
    "start": "675480",
    "end": "682959"
  },
  {
    "text": "an availability zone is healthy and traffic is only reled to healthy sites so to give you an example",
    "start": "682959",
    "end": "691480"
  },
  {
    "text": "if the keycloak pods all go down at one time because of node failures or something like that the network load",
    "start": "691480",
    "end": "697000"
  },
  {
    "text": "balancer will detect this and it will report there's no healthy pods and so the accelerator finds us out and we'll",
    "start": "697000",
    "end": "703560"
  },
  {
    "text": "only Route traffic to A2 in the event of the catastrophic az1",
    "start": "703560",
    "end": "709040"
  },
  {
    "text": "failure you also lose the network load balancer in which case the accelerator also detects this and only routes",
    "start": "709040",
    "end": "715519"
  },
  {
    "text": "traffic to A2 so we now have our two sites and users",
    "start": "715519",
    "end": "722320"
  },
  {
    "text": "are only connecting to the healthy sites um what about cash and",
    "start": "722320",
    "end": "727560"
  },
  {
    "text": "validation well I mentioned before about infinispan um I'll quickly go into what",
    "start": "727560",
    "end": "733880"
  },
  {
    "text": "infinispan is so you have a bit more context and how it helps us to solve the problem here so infinispan is a inmemory",
    "start": "733880",
    "end": "742120"
  },
  {
    "text": "key value cache it has very Advanced clustering capabilities and it is",
    "start": "742120",
    "end": "747480"
  },
  {
    "text": "actually an independent project so some of you who are familiar with keycloak May associate it with keycloak but it's",
    "start": "747480",
    "end": "753160"
  },
  {
    "text": "been on the go for 12 13 years something like that at this point so you can use it for um your own application use cases",
    "start": "753160",
    "end": "761519"
  },
  {
    "text": "as well the nice thing about an infinis ban is the entire stack is Apache 2 licensed",
    "start": "761519",
    "end": "768000"
  },
  {
    "text": "and we do provide a reddis compatible end point because you know red is no",
    "start": "768000",
    "end": "773040"
  },
  {
    "text": "longer is open source um so you can use infinish span as a drop in replacement",
    "start": "773040",
    "end": "779720"
  },
  {
    "text": "um we have a kubernetes operator that's very mature we have Helm charts that um",
    "start": "779720",
    "end": "785360"
  },
  {
    "text": "sorry infinis Manan has Helm charts that are um available for simpler deployments",
    "start": "785360",
    "end": "791800"
  },
  {
    "text": "and it also integrates with quarkus and spring boot Frameworks for you know app developers out there so why am I talking",
    "start": "791800",
    "end": "799360"
  },
  {
    "text": "about infinispan in so much detail well previously when we just had all of our",
    "start": "799360",
    "end": "804639"
  },
  {
    "text": "keycloak instances in one availability Zone um we use what we call embedded mode in infinispan and that means the",
    "start": "804639",
    "end": "811680"
  },
  {
    "text": "cache State lives within the same jvm process as keycloak itself um however",
    "start": "811680",
    "end": "817240"
  },
  {
    "text": "for this ha architecture we're going to adopt the client server model which is where infinispan has its own server",
    "start": "817240",
    "end": "824680"
  },
  {
    "text": "processes and all cache State lives within the infinite span process your",
    "start": "824680",
    "end": "829920"
  },
  {
    "text": "application in this case keycloak communicates with infinish span via a remote endpoint like HTTP the reddish",
    "start": "829920",
    "end": "836800"
  },
  {
    "text": "endpoint Etc so going back to the multi-site",
    "start": "836800",
    "end": "842600"
  },
  {
    "text": "architecture um what we now have is uh we're now using infinispan server and um",
    "start": "842600",
    "end": "850279"
  },
  {
    "text": "what we do is the infinispan server uses the infinispan cross-site replication capability to ensure that any cache",
    "start": "850279",
    "end": "857680"
  },
  {
    "text": "update a right or an invalidation is propagated synchronously from A1 to",
    "start": "857680",
    "end": "864560"
  },
  {
    "text": "A2 so what this means from a keycloak perspective is when a user request comes",
    "start": "864560",
    "end": "870199"
  },
  {
    "text": "into keycloak it performs a cache operation on the infinispan server pod remotely it waits for that to complete",
    "start": "870199",
    "end": "877600"
  },
  {
    "text": "the synchronous right will occur to A2 when A1 gets a response it returns",
    "start": "877600",
    "end": "882639"
  },
  {
    "text": "this back to the keycloak pods and the keycloak P then return a successful response to the keycloak",
    "start": "882639",
    "end": "889800"
  },
  {
    "text": "users so when the key clo user receives a successful response they know that the",
    "start": "889800",
    "end": "896360"
  },
  {
    "text": "cache state is consistent across both sides so they don't have to worry about inconsistencies um if a failover",
    "start": "896360",
    "end": "903120"
  },
  {
    "text": "occurred and their request was routed to A2 for example and so the reason for the",
    "start": "903120",
    "end": "909480"
  },
  {
    "text": "infinispan server is we have our sres in mind here the infinispan server provides",
    "start": "909480",
    "end": "915639"
  },
  {
    "text": "a lot more advanced operational capabilities than are available in the embedded mode and by utilizing",
    "start": "915639",
    "end": "920800"
  },
  {
    "text": "infinispan server you can automate a lot of the kind of day two operations that",
    "start": "920800",
    "end": "925920"
  },
  {
    "text": "might be necessary",
    "start": "925920",
    "end": "929279"
  },
  {
    "text": "so we now have our multiple sites we have requests being routed accordingly",
    "start": "932759",
    "end": "938839"
  },
  {
    "text": "and we have a consistent cach State what about the all important database how can we make that fail over between",
    "start": "938839",
    "end": "945880"
  },
  {
    "text": "A's well we leverage some AWS Services again here um in this case we use",
    "start": "945880",
    "end": "952120"
  },
  {
    "text": "Amazon's Aurora database um Aurora database is very nice because it was",
    "start": "952120",
    "end": "957440"
  },
  {
    "text": "built with multi-az deploy ments in mind um so we leverage their capabilities to",
    "start": "957440",
    "end": "963199"
  },
  {
    "text": "the full extent here for those not familiar with Aurora database I'll give a very high level overview of how it",
    "start": "963199",
    "end": "969720"
  },
  {
    "text": "works and what why that's good for keycloak and our requirements so we have our keycloak",
    "start": "969720",
    "end": "977839"
  },
  {
    "text": "pods connecting to a Aurora endpoint via jdbc then Aurora has an availability",
    "start": "977839",
    "end": "985120"
  },
  {
    "text": "Zone one what they call a writer instance this writer instance is responsible responsible of handling all read and write requests um but the nice",
    "start": "985120",
    "end": "992800"
  },
  {
    "text": "thing is when a write occurs is the writer not only writes the uh to its",
    "start": "992800",
    "end": "998319"
  },
  {
    "text": "local data copy or data store um it also synchronously writes the data to the",
    "start": "998319",
    "end": "1005600"
  },
  {
    "text": "data store on availability Zone too and this is all to facilitate",
    "start": "1005600",
    "end": "1011079"
  },
  {
    "text": "failover so when A1 does go down um Aurora transparently elects a new writer",
    "start": "1011079",
    "end": "1018040"
  },
  {
    "text": "instance in this case on A2 and um keycloak Can resume where it was before",
    "start": "1018040",
    "end": "1024760"
  },
  {
    "text": "the a failure the failover from one writer instance to another takes approximately",
    "start": "1024760",
    "end": "1031280"
  },
  {
    "text": "one minute and um from a keycloak perspective we think that's acceptable",
    "start": "1031280",
    "end": "1036360"
  },
  {
    "text": "there will be downtime for that minute but only if keycloak users are trying to perform right operations if things are",
    "start": "1036360",
    "end": "1043280"
  },
  {
    "text": "cached in memory which they most likely will be keycloak will actually have no downtime",
    "start": "1043280",
    "end": "1049080"
  },
  {
    "text": "the really nice thing about Aurora is the only thing we had to do from a keycloak perspective was utilize the AWS",
    "start": "1049080",
    "end": "1055360"
  },
  {
    "text": "jwc driver and what this does is it ensures that when A1 has failed any",
    "start": "1055360",
    "end": "1061840"
  },
  {
    "text": "existing Connections in your connection pool are invalidated so you're not going to get logs in keycloak saying hey a1's",
    "start": "1061840",
    "end": "1068960"
  },
  {
    "text": "not available until the connection pool figures it out these are invalidated automatically so no additional semantics",
    "start": "1068960",
    "end": "1076720"
  },
  {
    "text": "were required on the keycloak side and it would be the the same if you adopted Aurora for your own",
    "start": "1076720",
    "end": "1083400"
  },
  {
    "text": "applications so I've covered quite a lot of topics I think there so I'll just try",
    "start": "1083559",
    "end": "1088840"
  },
  {
    "text": "and bring it all back together and give it an overview of what this ha architecture is now looking like um all",
    "start": "1088840",
    "end": "1095880"
  },
  {
    "text": "user requests go via a global accelerator This Global accelerator then",
    "start": "1095880",
    "end": "1101480"
  },
  {
    "text": "talks to a network load balancer within an availability Zone the network load balancer forwards traffic to our",
    "start": "1101480",
    "end": "1107960"
  },
  {
    "text": "keycloak pods which is in a kubernetes cluster collocated in the same kubernetes cluster are our infinispan",
    "start": "1107960",
    "end": "1114799"
  },
  {
    "text": "server pods and then we have the keycloak pods reaching out to Aurora for",
    "start": "1114799",
    "end": "1119880"
  },
  {
    "text": "our persistent state so we then add the second a for",
    "start": "1119880",
    "end": "1125360"
  },
  {
    "text": "redundancy for the failover and um we can see here that the infinis band server pods are maintaining the cach",
    "start": "1125360",
    "end": "1132320"
  },
  {
    "text": "state bidirectionally between the two azs and the Aurora writer instance say",
    "start": "1132320",
    "end": "1138000"
  },
  {
    "text": "from A1 is writing the data to A2 so this architecture didn't happen",
    "start": "1138000",
    "end": "1144960"
  },
  {
    "text": "overnight um it took quite a while um a lot of testing for the keycloak team to come to this um so I'll now hand back to",
    "start": "1144960",
    "end": "1151960"
  },
  {
    "text": "kamesh and he'll talk about some of the behaviors we encoun along the",
    "start": "1151960",
    "end": "1157200"
  },
  {
    "text": "way thanks Ryan o how good was he wish I had a professor like him in my",
    "start": "1157200",
    "end": "1163480"
  },
  {
    "text": "University I would have learned a lot better uh but as he said uh uh it was it",
    "start": "1163480",
    "end": "1169400"
  },
  {
    "text": "didn't happen overnight it was a big undertaking for us to make kylo highly",
    "start": "1169400",
    "end": "1174640"
  },
  {
    "text": "available and reliable and we did learn a lot along the way and some surprising system",
    "start": "1174640",
    "end": "1181600"
  },
  {
    "text": "behaviors under the load while this was happening and we were incrementally reaching our goal of making um keylo",
    "start": "1181600",
    "end": "1190679"
  },
  {
    "text": "active active um between multi sites uh overloading situations when",
    "start": "1190679",
    "end": "1197400"
  },
  {
    "text": "load shedding is required um it's common for applications to shed",
    "start": "1197400",
    "end": "1202600"
  },
  {
    "text": "the load uh when the connections are overwhelmed or the que is too much to",
    "start": "1202600",
    "end": "1207720"
  },
  {
    "text": "handle uh but what happens in in such situation um when more requests are",
    "start": "1207720",
    "end": "1214720"
  },
  {
    "text": "incoming than what it can handle the observation what we had was like request are um queuing up memory usage increases",
    "start": "1214720",
    "end": "1224320"
  },
  {
    "text": "uh C client request starts timing out and what we did as a remedy was to drop",
    "start": "1224320",
    "end": "1230760"
  },
  {
    "text": "the request by replying uh 503 so that at least like the current connections",
    "start": "1230760",
    "end": "1236080"
  },
  {
    "text": "can handle the existing uh requests and only some partial amount of the",
    "start": "1236080",
    "end": "1243880"
  },
  {
    "text": "application is uh having an outage and when the Q length um",
    "start": "1243880",
    "end": "1252080"
  },
  {
    "text": "basically settles down then we resume the operations to normal and the there could be a",
    "start": "1252080",
    "end": "1259200"
  },
  {
    "text": "situation where the pods are restarting and like there was a bad pod the new pod",
    "start": "1259200",
    "end": "1264720"
  },
  {
    "text": "comes up because of uh replica set and the New Port then tries",
    "start": "1264720",
    "end": "1272159"
  },
  {
    "text": "to uh restart under high load and it tries to uh do many parallel requests to",
    "start": "1272159",
    "end": "1280240"
  },
  {
    "text": "the database to um reload the cache and when that happens uh we see like lot of",
    "start": "1280240",
    "end": "1286320"
  },
  {
    "text": "timeouts happening exhaustion of the database connections Etc um this was a",
    "start": "1286320",
    "end": "1292360"
  },
  {
    "text": "uh interesting problem where we have to solve it by introducing jvm blocking uh",
    "start": "1292360",
    "end": "1297400"
  },
  {
    "text": "for a specific resource if it is being fetched uh from the database that",
    "start": "1297400",
    "end": "1302720"
  },
  {
    "text": "allowed us to do some uh synchronous loading of caching and we had a better",
    "start": "1302720",
    "end": "1308120"
  },
  {
    "text": "ramp up uh after the Pod restarted and and also using like blocking probes",
    "start": "1308120",
    "end": "1316240"
  },
  {
    "text": "and metrics uh will cause um too many requests that are being uh",
    "start": "1316240",
    "end": "1322440"
  },
  {
    "text": "done leading to slow response times and also leads to again load shedding Behavior",
    "start": "1322440",
    "end": "1329279"
  },
  {
    "text": "and the observation was like it will stop the working of the Pod and it will",
    "start": "1329279",
    "end": "1334679"
  },
  {
    "text": "you will experience so many pod restarts for um unexplainable reasons and the way",
    "start": "1334679",
    "end": "1341320"
  },
  {
    "text": "we went about it was to introduce U non-blocking probes so that they don't",
    "start": "1341320",
    "end": "1346760"
  },
  {
    "text": "uh enq um too much and going into an overload",
    "start": "1346760",
    "end": "1352360"
  },
  {
    "text": "situation and some of the good habits uh we would like to call them uh uh we",
    "start": "1352360",
    "end": "1358440"
  },
  {
    "text": "picked up along this and tried to be consistent at is to have upto-date",
    "start": "1358440",
    "end": "1363640"
  },
  {
    "text": "documentation it's really really important to keep our project up to date and fresh and docks having the right and",
    "start": "1363640",
    "end": "1371400"
  },
  {
    "text": "relevant information which is specific to that release and we also use antur",
    "start": "1371400",
    "end": "1378279"
  },
  {
    "text": "and and asid dos to uh use our documentation uh to be crisp and",
    "start": "1378279",
    "end": "1384919"
  },
  {
    "text": "clean and we use ephemeral environments in our CI system and so that like we can",
    "start": "1384919",
    "end": "1392120"
  },
  {
    "text": "save on cloud cost and we are repeatedly testing our provisioning module over and",
    "start": "1392120",
    "end": "1397520"
  },
  {
    "text": "over again with new builds so we know like if something is breaking in the provisioning we can fix that and also uh",
    "start": "1397520",
    "end": "1404960"
  },
  {
    "text": "consistently measure uh the um synthetic benchmarks",
    "start": "1404960",
    "end": "1410360"
  },
  {
    "text": "that we run every uh every night and we collect all the metrics and we generate",
    "start": "1410360",
    "end": "1417000"
  },
  {
    "text": "um actionable data objects from those results like for example how many CPU",
    "start": "1417000",
    "end": "1423600"
  },
  {
    "text": "logins per uh uh CPU logins per second a virtual CPU can support or how many um",
    "start": "1423600",
    "end": "1433159"
  },
  {
    "text": "login sessions uh can fit in a 500 MB memory block or how many client",
    "start": "1433159",
    "end": "1439520"
  },
  {
    "text": "credential grants can we support so we try to keep that information up to date with um each run so that our community",
    "start": "1439520",
    "end": "1449440"
  },
  {
    "text": "users and customers can uh read into that and look at like if something is",
    "start": "1449440",
    "end": "1454480"
  },
  {
    "text": "changing over a period of time and our nightly performance and",
    "start": "1454480",
    "end": "1459720"
  },
  {
    "text": "functional test runs will uh highlight those regressions and that data set can",
    "start": "1459720",
    "end": "1465720"
  },
  {
    "text": "act as uh the base for doing some",
    "start": "1465720",
    "end": "1471320"
  },
  {
    "text": "analytics and we for continuous integration we extensively use uh GitHub",
    "start": "1471320",
    "end": "1476360"
  },
  {
    "text": "workflows and actions 3 years ago we probably had one uh right now we have more than like 25 uh workflows doing",
    "start": "1476360",
    "end": "1484440"
  },
  {
    "text": "different different things um from provisioning to testing to tearing it",
    "start": "1484440",
    "end": "1489640"
  },
  {
    "text": "down and also like reporting on the results",
    "start": "1489640",
    "end": "1495679"
  },
  {
    "text": "um we can do that using like the workflow dispatch and also like um run",
    "start": "1495679",
    "end": "1500720"
  },
  {
    "text": "it from CLI or UI to make it make the developer experience more seamless",
    "start": "1500720",
    "end": "1507240"
  },
  {
    "text": "within our team and some of the cncf projects that were really really helpful",
    "start": "1507240",
    "end": "1512320"
  },
  {
    "text": "for us uh were open Telemetry for our observability grafana for visualization",
    "start": "1512320",
    "end": "1519640"
  },
  {
    "text": "Prometheus for metric scraping uh and Helm charts for package management and",
    "start": "1519640",
    "end": "1527080"
  },
  {
    "text": "the recently sent box project Ken uh for our chaos testing so chaos testing is um",
    "start": "1527080",
    "end": "1535240"
  },
  {
    "text": "now incubated into our key clo Benchmark uh our Benchmark um framework and there",
    "start": "1535240",
    "end": "1543960"
  },
  {
    "text": "are like patterns on how you can run those benchmarks and Chaos tests on your own deployments and we would like to",
    "start": "1543960",
    "end": "1551200"
  },
  {
    "text": "encourage everyone to try those out and um highlight any regressions or give us",
    "start": "1551200",
    "end": "1557399"
  },
  {
    "text": "feedback on how we can improve on that and obviously this would not have",
    "start": "1557399",
    "end": "1562799"
  },
  {
    "text": "been possible without kubernetes right like everything coexists because of that",
    "start": "1562799",
    "end": "1568080"
  },
  {
    "text": "and for what's in stake for the future I would like to call back uh Ryan to talk about it yeah thank you so um these are",
    "start": "1568080",
    "end": "1576360"
  },
  {
    "text": "a few things that we've got in mind for the near future of keycloak um I can't give specific releases because things",
    "start": "1576360",
    "end": "1582640"
  },
  {
    "text": "been actively worked upon but they should be appearing very soon very soon being the the next year I",
    "start": "1582640",
    "end": "1589440"
  },
  {
    "text": "guess but yeah so the big thing um we're going for is zero downtime upgrades we",
    "start": "1589440",
    "end": "1594880"
  },
  {
    "text": "hear that upgrades is a pain Point like we're listening to the community on this one for patch releases yeah sorry yeah",
    "start": "1594880",
    "end": "1601679"
  },
  {
    "text": "for patch releases to begin with um we're going to start small and then go big um maybe minor major who knows but",
    "start": "1601679",
    "end": "1609919"
  },
  {
    "text": "you know we'll start with patch releases and take it from there um the next thing",
    "start": "1609919",
    "end": "1615080"
  },
  {
    "text": "as well is you know we're aware this talk is very AWS specific uh what we",
    "start": "1615080",
    "end": "1620799"
  },
  {
    "text": "talked about at the moment so we're looking into different ways U where we can adapt this architecture so it's",
    "start": "1620799",
    "end": "1627120"
  },
  {
    "text": "going to be either ideally Cloud vendor agnostic or uh provide blueprints that",
    "start": "1627120",
    "end": "1632760"
  },
  {
    "text": "will also work on the different Cloud providers um there's been a lot of inspiration for that this week so uh",
    "start": "1632760",
    "end": "1638600"
  },
  {
    "text": "we've got some ideas in mind for this and definitely yeah watch this space on that one um arm support um I think most",
    "start": "1638600",
    "end": "1647080"
  },
  {
    "text": "keycloak things kind of work already but we need to full ensure the full stack works as expected and again the various",
    "start": "1647080",
    "end": "1653880"
  },
  {
    "text": "blueprints that we're promoting work as expected so Greener keycloak cheaper",
    "start": "1653880",
    "end": "1659880"
  },
  {
    "text": "keycloak everyone wins um we want to provide more security",
    "start": "1659880",
    "end": "1665279"
  },
  {
    "text": "hardened blueprints um you know it's a security product at the end of the day you can't get more you know you can't",
    "start": "1665279",
    "end": "1671960"
  },
  {
    "text": "have enough security and again you know it's been a great week um lot of inspiration",
    "start": "1671960",
    "end": "1678679"
  },
  {
    "text": "um the more we can integrate with the cncf ecosystem you know the better and",
    "start": "1678679",
    "end": "1685080"
  },
  {
    "text": "there's been a lot of topics to discussion at the project Pavilion this week that aren't on these slides but you know we're going to come up with a uh",
    "start": "1685080",
    "end": "1692120"
  },
  {
    "text": "we're going to take on board all the feedback we've heard and that'll definitely influence the the road map in the near",
    "start": "1692120",
    "end": "1698120"
  },
  {
    "text": "future and we definitely see like a lot of familiar faces who have visited our booth and thank you for taking the time",
    "start": "1698120",
    "end": "1704720"
  },
  {
    "text": "and coming and giving us the feedback it it's very very crucial we also encourage you to uh take part in",
    "start": "1704720",
    "end": "1711919"
  },
  {
    "text": "different initiatives that keylo Community does different special interest groups uh different events that",
    "start": "1711919",
    "end": "1718399"
  },
  {
    "text": "happen like Klo hour of code Etc yeah there's for those not familiar there's",
    "start": "1718399",
    "end": "1724399"
  },
  {
    "text": "two special interest groups there's the oor one and then there is the new Sr one",
    "start": "1724399",
    "end": "1730279"
  },
  {
    "text": "um there's dedicated slack channels for this anybody who's interested in contributing or just you just attending",
    "start": "1730279",
    "end": "1736760"
  },
  {
    "text": "to see what it's like we highly encourage you to do that for those of you who are not familiar with keycloak",
    "start": "1736760",
    "end": "1743240"
  },
  {
    "text": "um there's a QR code here for keycloak website um please drop by have a look",
    "start": "1743240",
    "end": "1748799"
  },
  {
    "text": "and we also have a QR code for feedback but I think now if if anybody has any questions that like to ask on a",
    "start": "1748799",
    "end": "1754880"
  },
  {
    "text": "microphone or me and commes will be around for a few minutes after the talk as well feel free to approach us happy",
    "start": "1754880",
    "end": "1760519"
  },
  {
    "text": "to discuss anything you want to talk about key CL",
    "start": "1760519",
    "end": "1765320"
  },
  {
    "text": "related so I I have a question if you have your um keycloak server deployed on a multi-az or yeah multi-az kubernetes",
    "start": "1765919",
    "end": "1773279"
  },
  {
    "text": "cluster where your workers are spread across multiple A's do you need an external infinis band server to make",
    "start": "1773279",
    "end": "1779679"
  },
  {
    "text": "that work correctly so we're actively kind of working on that at the moment",
    "start": "1779679",
    "end": "1784840"
  },
  {
    "text": "you can use a multi-az kubernetes cluster and just you know you can make",
    "start": "1784840",
    "end": "1790200"
  },
  {
    "text": "use of affinity settings and things like that however the problem is in the",
    "start": "1790200",
    "end": "1795679"
  },
  {
    "text": "resiliency of the cach so if you want to use persistent user sessions and number",
    "start": "1795679",
    "end": "1801880"
  },
  {
    "text": "of the num owners one in the cache you're probably going to be okay um with what we provide at the moment however if",
    "start": "1801880",
    "end": "1809039"
  },
  {
    "text": "you want the cash uh to be replicated in a fault tolerant way there's a bit of",
    "start": "1809039",
    "end": "1815320"
  },
  {
    "text": "things missing there and we're actively working on that it's a thing called infinispan server hinting and we need to",
    "start": "1815320",
    "end": "1821559"
  },
  {
    "text": "improve the keycloak integration there but multi-az kubernetes is something",
    "start": "1821559",
    "end": "1827159"
  },
  {
    "text": "we're working on and that might be our solution to the provide supporting uh",
    "start": "1827159",
    "end": "1833080"
  },
  {
    "text": "multiple Cloud vendors for example if we can have a full stack including the database that works well in a multi-az",
    "start": "1833080",
    "end": "1838760"
  },
  {
    "text": "kubernetes cluster then maybe that's the work done depends what the community thinks okay sounds good thank you and",
    "start": "1838760",
    "end": "1845600"
  },
  {
    "text": "there are also like blueprints that are available in the guide section of keylo documentation in the high availability",
    "start": "1845600",
    "end": "1853360"
  },
  {
    "text": "and there you will can get like more details about like how the blueprint was implemented and the architecture that",
    "start": "1853360",
    "end": "1860279"
  },
  {
    "text": "Ryan just talked about uh is uh laid out in much more detail okay thank",
    "start": "1860279",
    "end": "1866919"
  },
  {
    "text": "you yeah so can you couple uh the high availability inside an availability Zone",
    "start": "1866919",
    "end": "1873159"
  },
  {
    "text": "with high availability across availability zones your architecture showed you know two availability zones",
    "start": "1873159",
    "end": "1879519"
  },
  {
    "text": "but if I wanted to put in a second instance of keycloak inside of the same availability Zone do a and across",
    "start": "1879519",
    "end": "1886679"
  },
  {
    "text": "availability zones would you support that I mean is that functional yeah it is possible uh to support within the",
    "start": "1886679",
    "end": "1892559"
  },
  {
    "text": "same availability Zone we did similar tests for that um but at least for the",
    "start": "1892559",
    "end": "1898279"
  },
  {
    "text": "blueprints and the tests and the numbers that we captured we did the multi side was done between two sites for now but",
    "start": "1898279",
    "end": "1906559"
  },
  {
    "text": "in theory it should be able to expand it for more clusters thank",
    "start": "1906559",
    "end": "1912638"
  },
  {
    "text": "you so the very nature of authentic appliation Services is that the load is",
    "start": "1914760",
    "end": "1920480"
  },
  {
    "text": "going to be varying a lot during the time of day also sometimes the",
    "start": "1920480",
    "end": "1925519"
  },
  {
    "text": "applications can Implement something like incorrectly and then it's going to create like bad traffic uh how",
    "start": "1925519",
    "end": "1933360"
  },
  {
    "text": "do you guys what you guys did you guys come across these kind of situations how do you guys suggest we should handle",
    "start": "1933360",
    "end": "1939799"
  },
  {
    "text": "that yeah that is a very important consideration we brainstorm when we come up with our synthetic workloads I would",
    "start": "1939799",
    "end": "1946679"
  },
  {
    "text": "like to call that like a camel curve when organizations open up their office like you see a big spike and then like",
    "start": "1946679",
    "end": "1953799"
  },
  {
    "text": "slowly goes down and then after the time to live expires for a certain period then again you see some uh influx in",
    "start": "1953799",
    "end": "1961760"
  },
  {
    "text": "more requests so we do account for that in our synthetic workloads when we do",
    "start": "1961760",
    "end": "1967000"
  },
  {
    "text": "our tests and that's where like uh the feature like load shedding and other",
    "start": "1967000",
    "end": "1972799"
  },
  {
    "text": "safeguards will help uh the admin's control that's traffic do you guys uh",
    "start": "1972799",
    "end": "1979919"
  },
  {
    "text": "have any um suggestions on warming the cash or anything of that sort so that",
    "start": "1979919",
    "end": "1986840"
  },
  {
    "text": "you can have like minimal amount of load sharing um warming the cache yes it's",
    "start": "1986840",
    "end": "1995399"
  },
  {
    "text": "generally a good practice to do that uh to warm up the cash but we don't have like specific operational procedures to",
    "start": "1995399",
    "end": "2001880"
  },
  {
    "text": "do that I don't think so no no yeah but it would warm up by the nature of adding",
    "start": "2001880",
    "end": "2007440"
  },
  {
    "text": "more sessions to it gotta yeah thanks but in our test like we don't we don't",
    "start": "2007440",
    "end": "2012480"
  },
  {
    "text": "really see issues because of like a cold cash or something yeah and as well you can size your caches accordingly so yeah",
    "start": "2012480",
    "end": "2020120"
  },
  {
    "text": "you know if your keycloak instance is going to be quite long lived and so if you have quite a lot if you can",
    "start": "2020120",
    "end": "2025399"
  },
  {
    "text": "accommodate quite a large cash size maybe you're going to get some low chading on the first day or the first two days but as time progresses you",
    "start": "2025399",
    "end": "2032360"
  },
  {
    "text": "would expect the low shedding not to happen every day because you're going to have a fair bit of the content already",
    "start": "2032360",
    "end": "2037559"
  },
  {
    "text": "in the bres oh that's a good idea thank",
    "start": "2037559",
    "end": "2042278"
  },
  {
    "text": "you when you were describing infinispan you were talking about it having a redis compatible API sure um I'm assuming that",
    "start": "2043760",
    "end": "2051398"
  },
  {
    "text": "keycloak is not using that API and is only using the infinispan one yeah so",
    "start": "2051399",
    "end": "2056440"
  },
  {
    "text": "okay yeah so the reason for that though is um because the infinispan native um",
    "start": "2056440",
    "end": "2063200"
  },
  {
    "text": "client uh hot rod it's called as the protocol um it is topology aware so by",
    "start": "2063200",
    "end": "2069398"
  },
  {
    "text": "Key C utilizing that then we get some efficiency gains",
    "start": "2069399",
    "end": "2074960"
  },
  {
    "text": "okay right we have time for some more questions if somebody's up for",
    "start": "2079520",
    "end": "2085440"
  },
  {
    "text": "it uh my question is has keyo mostly our organization and",
    "start": "2090800",
    "end": "2098000"
  },
  {
    "text": "I believe most other organizations mostly use keycloak for authentication um has there been you know I'm sure you",
    "start": "2098000",
    "end": "2104560"
  },
  {
    "text": "guys get requests can ke do authorization as well and it's it's kind",
    "start": "2104560",
    "end": "2110320"
  },
  {
    "text": "of the sort of the the other sort of the missing half if you will so keyo does authorization today",
    "start": "2110320",
    "end": "2117680"
  },
  {
    "text": "um yeah so authorization the authorization workflows that keycloak supports that's fully supported in this",
    "start": "2117680",
    "end": "2124320"
  },
  {
    "text": "ha architecture the right the ha architecture we've talked about today doesn't change that keycloak is fully",
    "start": "2124320",
    "end": "2130359"
  },
  {
    "text": "featured um anything it can do with a single instance it can do in this thanks maybe I need to talk to you",
    "start": "2130359",
    "end": "2136920"
  },
  {
    "text": "afterwards about yeah yeah sure it sounds",
    "start": "2136920",
    "end": "2140599"
  },
  {
    "text": "good okay well thank you everyone for the questions and attending today really appreciate it um we're pretty much at",
    "start": "2142880",
    "end": "2148880"
  },
  {
    "text": "the end of the conference but yeah safe trip out",
    "start": "2148880",
    "end": "2153560"
  }
]
[
  {
    "start": "0",
    "end": "16000"
  },
  {
    "text": "thank you for joining me here I'm Alex",
    "start": "800",
    "end": "3929"
  },
  {
    "text": "brand I work at hefty Oh which I guess",
    "start": "3929",
    "end": "5970"
  },
  {
    "text": "now is VMware so super excited about",
    "start": "5970",
    "end": "8429"
  },
  {
    "text": "that this session is about performance",
    "start": "8429",
    "end": "11370"
  },
  {
    "text": "testing ingress for internet scale",
    "start": "11370",
    "end": "13769"
  },
  {
    "text": "workloads so when I say ingress I'm",
    "start": "13769",
    "end": "18420"
  },
  {
    "start": "16000",
    "end": "16000"
  },
  {
    "text": "talking about kubernetes ingress so for",
    "start": "18420",
    "end": "20880"
  },
  {
    "text": "those of you that are not necessarily",
    "start": "20880",
    "end": "22470"
  },
  {
    "text": "familiar with kubernetes there's a",
    "start": "22470",
    "end": "24720"
  },
  {
    "text": "resource in kubernetes called ingress",
    "start": "24720",
    "end": "26519"
  },
  {
    "text": "very similar to how you have a",
    "start": "26519",
    "end": "28590"
  },
  {
    "text": "deployment or a pod or a service there",
    "start": "28590",
    "end": "31380"
  },
  {
    "text": "is a resource called ingress which",
    "start": "31380",
    "end": "33300"
  },
  {
    "text": "allows you to expose services that live",
    "start": "33300",
    "end": "36360"
  },
  {
    "text": "inside of the cluster to the outside of",
    "start": "36360",
    "end": "38489"
  },
  {
    "text": "the cluster so organizations typically",
    "start": "38489",
    "end": "40890"
  },
  {
    "text": "have a portfolio of apps that they want",
    "start": "40890",
    "end": "43440"
  },
  {
    "text": "to expose outside of the cluster and if",
    "start": "43440",
    "end": "46140"
  },
  {
    "text": "you're looking for a layer 7 load",
    "start": "46140",
    "end": "48660"
  },
  {
    "text": "balancing solution ingress and ingress",
    "start": "48660",
    "end": "51390"
  },
  {
    "text": "controllers are typically what you're",
    "start": "51390",
    "end": "53039"
  },
  {
    "text": "looking for",
    "start": "53039",
    "end": "54559"
  },
  {
    "text": "adeptia we have been working on a couple",
    "start": "54559",
    "end": "57570"
  },
  {
    "text": "of projects one of them is contour so",
    "start": "57570",
    "end": "60930"
  },
  {
    "text": "contour is our ingress controller for",
    "start": "60930",
    "end": "63480"
  },
  {
    "text": "kubernetes it is built on top of envoy",
    "start": "63480",
    "end": "66299"
  },
  {
    "text": "the proxy that was built by lyft so we",
    "start": "66299",
    "end": "70500"
  },
  {
    "text": "were very happy with with with envoy and",
    "start": "70500",
    "end": "72240"
  },
  {
    "text": "the Android community so contour is",
    "start": "72240",
    "end": "74820"
  },
  {
    "text": "responsible for ingress inside of a",
    "start": "74820",
    "end": "77310"
  },
  {
    "text": "single cluster but what we what we've",
    "start": "77310",
    "end": "80340"
  },
  {
    "text": "been seeing is that the majority of our",
    "start": "80340",
    "end": "82439"
  },
  {
    "text": "customers are actually running multiple",
    "start": "82439",
    "end": "84450"
  },
  {
    "text": "clusters and that's exactly where gimble",
    "start": "84450",
    "end": "86790"
  },
  {
    "text": "comes in",
    "start": "86790",
    "end": "87299"
  },
  {
    "text": "so gimble is a multi cluster ingress",
    "start": "87299",
    "end": "90960"
  },
  {
    "text": "controller a load balancer that we have",
    "start": "90960",
    "end": "93150"
  },
  {
    "text": "built so why did we create gimble so as",
    "start": "93150",
    "end": "98759"
  },
  {
    "start": "96000",
    "end": "96000"
  },
  {
    "text": "I mentioned the majority of our",
    "start": "98759",
    "end": "100560"
  },
  {
    "text": "customers are running multiple clusters",
    "start": "100560",
    "end": "102090"
  },
  {
    "text": "they want to load balanced across a",
    "start": "102090",
    "end": "104250"
  },
  {
    "text": "variety of clusters in their data",
    "start": "104250",
    "end": "106590"
  },
  {
    "text": "centers but more specifically we",
    "start": "106590",
    "end": "108540"
  },
  {
    "text": "actually built gimble in conjunction",
    "start": "108540",
    "end": "110790"
  },
  {
    "text": "with or in a partnership with Octavio",
    "start": "110790",
    "end": "114450"
  },
  {
    "text": "which is a subsidiary of Yahoo Japan",
    "start": "114450",
    "end": "117240"
  },
  {
    "text": "here in the United States and the reason",
    "start": "117240",
    "end": "120119"
  },
  {
    "text": "for this is that they actually reached",
    "start": "120119",
    "end": "122189"
  },
  {
    "text": "out to us and they have this problem",
    "start": "122189",
    "end": "123630"
  },
  {
    "text": "where they're running hundreds of",
    "start": "123630",
    "end": "125969"
  },
  {
    "text": "services that they expose over the",
    "start": "125969",
    "end": "127979"
  },
  {
    "text": "internet that they've historically been",
    "start": "127979",
    "end": "130890"
  },
  {
    "text": "running on OpenStack but",
    "start": "130890",
    "end": "132610"
  },
  {
    "text": "been slowly migrating them over to",
    "start": "132610",
    "end": "134620"
  },
  {
    "text": "kubernetes so they've had this problem",
    "start": "134620",
    "end": "136420"
  },
  {
    "text": "where they want to merge this two worlds",
    "start": "136420",
    "end": "138700"
  },
  {
    "text": "of VMs and containers through like a",
    "start": "138700",
    "end": "141520"
  },
  {
    "text": "single layer of load balancing and",
    "start": "141520",
    "end": "144430"
  },
  {
    "text": "that's exactly where like gimble comes",
    "start": "144430",
    "end": "147100"
  },
  {
    "text": "in so you can not only route traffic to",
    "start": "147100",
    "end": "149290"
  },
  {
    "text": "multiple kubernetes clusters but you can",
    "start": "149290",
    "end": "151540"
  },
  {
    "text": "also route traffic to OpenStack clusters",
    "start": "151540",
    "end": "153670"
  },
  {
    "text": "which is really cool",
    "start": "153670",
    "end": "155220"
  },
  {
    "text": "so if we look at gimble from like a",
    "start": "155220",
    "end": "158080"
  },
  {
    "text": "picture perspective you can see here",
    "start": "158080",
    "end": "160840"
  },
  {
    "text": "where we have the Internet the traffic",
    "start": "160840",
    "end": "163750"
  },
  {
    "text": "comes in through gimble and then gimble",
    "start": "163750",
    "end": "166120"
  },
  {
    "text": "sends the traffic to the right cluster",
    "start": "166120",
    "end": "169800"
  },
  {
    "text": "if we zoom in a little bit we can see",
    "start": "169800",
    "end": "173170"
  },
  {
    "text": "the gimbal architecture so in the bottom",
    "start": "173170",
    "end": "176230"
  },
  {
    "text": "you can see the clusters where we're",
    "start": "176230",
    "end": "177580"
  },
  {
    "text": "sending traffic to and then we see this",
    "start": "177580",
    "end": "179920"
  },
  {
    "text": "box that is gimble we actually use",
    "start": "179920",
    "end": "183570"
  },
  {
    "text": "kubernetes as a building block to build",
    "start": "183570",
    "end": "187590"
  },
  {
    "text": "gimble on top so we use kubernetes as a",
    "start": "187590",
    "end": "190780"
  },
  {
    "text": "platform to build a system which is",
    "start": "190780",
    "end": "192580"
  },
  {
    "text": "really cool on the data plane which as I",
    "start": "192580",
    "end": "195850"
  },
  {
    "text": "mentioned before we are using envoy and",
    "start": "195850",
    "end": "197860"
  },
  {
    "text": "then from the gimble perspective we have",
    "start": "197860",
    "end": "200350"
  },
  {
    "text": "two main components or subsystems we",
    "start": "200350",
    "end": "202810"
  },
  {
    "text": "have a service discovery subsystem which",
    "start": "202810",
    "end": "205390"
  },
  {
    "text": "is responsible for discovering services",
    "start": "205390",
    "end": "208090"
  },
  {
    "text": "in the underlying kubernetes and",
    "start": "208090",
    "end": "210190"
  },
  {
    "text": "OpenStack clusters and then we have a",
    "start": "210190",
    "end": "212200"
  },
  {
    "text": "routing and rule engine which is really",
    "start": "212200",
    "end": "215350"
  },
  {
    "text": "contoured so contour is that ingress",
    "start": "215350",
    "end": "216880"
  },
  {
    "text": "controller which gimbal builds on top of",
    "start": "216880",
    "end": "219910"
  },
  {
    "text": "and then also we not really we wanted to",
    "start": "219910",
    "end": "224110"
  },
  {
    "text": "build something that was easy to operate",
    "start": "224110",
    "end": "226330"
  },
  {
    "text": "and monitor so we also have",
    "start": "226330",
    "end": "228340"
  },
  {
    "text": "out-of-the-box monitoring and alerting",
    "start": "228340",
    "end": "230290"
  },
  {
    "text": "solutions built on top of graph on ax",
    "start": "230290",
    "end": "232660"
  },
  {
    "text": "and Prometheus so we are in the",
    "start": "232660",
    "end": "237400"
  },
  {
    "text": "performance track slide you know we gave",
    "start": "237400",
    "end": "239560"
  },
  {
    "text": "a bit of an overview of what gimble is",
    "start": "239560",
    "end": "241450"
  },
  {
    "text": "but let's talk about its performance and",
    "start": "241450",
    "end": "243519"
  },
  {
    "text": "and and how gimbal behaves on their load",
    "start": "243519",
    "end": "246930"
  },
  {
    "text": "so while while working this project we",
    "start": "246930",
    "end": "249640"
  },
  {
    "start": "248000",
    "end": "248000"
  },
  {
    "text": "had some very interesting requirements",
    "start": "249640",
    "end": "250989"
  },
  {
    "text": "so millions of concurrent connections",
    "start": "250989",
    "end": "253110"
  },
  {
    "text": "thousands of services per data center",
    "start": "253110",
    "end": "255340"
  },
  {
    "text": "tens of thousands of endpoints per data",
    "start": "255340",
    "end": "258190"
  },
  {
    "text": "center and all of this we wanted to",
    "start": "258190",
    "end": "260769"
  },
  {
    "text": "achieve while maintaining the latency",
    "start": "260770",
    "end": "263200"
  },
  {
    "text": "the p99 latency under",
    "start": "263200",
    "end": "265780"
  },
  {
    "text": "30 milliseconds so when we started",
    "start": "265780",
    "end": "269830"
  },
  {
    "start": "269000",
    "end": "269000"
  },
  {
    "text": "thinking about this and we when we",
    "start": "269830",
    "end": "271420"
  },
  {
    "text": "started thinking about how to test this",
    "start": "271420",
    "end": "273700"
  },
  {
    "text": "system we started realizing that there",
    "start": "273700",
    "end": "275950"
  },
  {
    "text": "is a lot of variables that you can play",
    "start": "275950",
    "end": "277990"
  },
  {
    "text": "with so you know there a number of",
    "start": "277990",
    "end": "279910"
  },
  {
    "text": "requests per second number of concurrent",
    "start": "279910",
    "end": "281620"
  },
  {
    "text": "connections what is the response payload",
    "start": "281620",
    "end": "284380"
  },
  {
    "text": "size how many services how many",
    "start": "284380",
    "end": "286120"
  },
  {
    "text": "endpoints so there's a lot of variables",
    "start": "286120",
    "end": "288070"
  },
  {
    "text": "and we have to try to you know boil down",
    "start": "288070",
    "end": "290080"
  },
  {
    "text": "the problem a little bit there's not",
    "start": "290080",
    "end": "294250"
  },
  {
    "start": "293000",
    "end": "293000"
  },
  {
    "text": "only multiple variables but there's also",
    "start": "294250",
    "end": "295630"
  },
  {
    "text": "multiple subsystems so as we saw in that",
    "start": "295630",
    "end": "297700"
  },
  {
    "text": "diagram you had the data plane the",
    "start": "297700",
    "end": "300250"
  },
  {
    "text": "control plane the monitoring subsystem",
    "start": "300250",
    "end": "302830"
  },
  {
    "text": "the discovery subsystem so there's a lot",
    "start": "302830",
    "end": "305320"
  },
  {
    "text": "of things that we had to test and make",
    "start": "305320",
    "end": "307270"
  },
  {
    "text": "sure that we're behaving properly so",
    "start": "307270",
    "end": "311710"
  },
  {
    "start": "311000",
    "end": "311000"
  },
  {
    "text": "when we started thinking about this we",
    "start": "311710",
    "end": "314400"
  },
  {
    "text": "initially went down the path of what we",
    "start": "314400",
    "end": "317620"
  },
  {
    "text": "called micro benchmarks so we started",
    "start": "317620",
    "end": "320110"
  },
  {
    "text": "testing the system through very specific",
    "start": "320110",
    "end": "323430"
  },
  {
    "text": "looking at very specific variables so",
    "start": "323430",
    "end": "325870"
  },
  {
    "text": "for example what happens when I increase",
    "start": "325870",
    "end": "329320"
  },
  {
    "text": "the number of concurrent connections on",
    "start": "329320",
    "end": "331479"
  },
  {
    "text": "the system is the latency going to go",
    "start": "331479",
    "end": "333520"
  },
  {
    "text": "down is it going to go up it's gonna",
    "start": "333520",
    "end": "335380"
  },
  {
    "text": "stay the same so we were trying to solve",
    "start": "335380",
    "end": "336820"
  },
  {
    "text": "and understand how that was gonna impact",
    "start": "336820",
    "end": "340030"
  },
  {
    "text": "the system once we started going down",
    "start": "340030",
    "end": "343930"
  },
  {
    "text": "the path of more micro benchmarks we",
    "start": "343930",
    "end": "345760"
  },
  {
    "text": "started realizing that we also wanted to",
    "start": "345760",
    "end": "347410"
  },
  {
    "text": "understand how the system behaves in a",
    "start": "347410",
    "end": "349870"
  },
  {
    "text": "more realistic scenario in a more",
    "start": "349870",
    "end": "351550"
  },
  {
    "text": "production like scenario and that's what",
    "start": "351550",
    "end": "354039"
  },
  {
    "text": "we kind of called my macro benchmarks so",
    "start": "354039",
    "end": "356260"
  },
  {
    "text": "you want to understand how the system",
    "start": "356260",
    "end": "358090"
  },
  {
    "text": "behaves when you're throwing realistic",
    "start": "358090",
    "end": "360400"
  },
  {
    "text": "load at it so in this example we wanted",
    "start": "360400",
    "end": "364330"
  },
  {
    "text": "to see you know what happens when I send",
    "start": "364330",
    "end": "366910"
  },
  {
    "text": "or I open a hundred thousand concurrent",
    "start": "366910",
    "end": "369550"
  },
  {
    "text": "connections and we send thirty thirty",
    "start": "369550",
    "end": "371440"
  },
  {
    "text": "thousand requests per second and what",
    "start": "371440",
    "end": "373030"
  },
  {
    "text": "does the performance look like so if you",
    "start": "373030",
    "end": "376210"
  },
  {
    "text": "look more closely at micro benchmarks an",
    "start": "376210",
    "end": "378550"
  },
  {
    "text": "example that we kind of talked about",
    "start": "378550",
    "end": "379780"
  },
  {
    "start": "379000",
    "end": "379000"
  },
  {
    "text": "already this I grabbed from we had a",
    "start": "379780",
    "end": "383020"
  },
  {
    "text": "huge spreadsheet that where we listed",
    "start": "383020",
    "end": "385750"
  },
  {
    "text": "all the tests that we were running so",
    "start": "385750",
    "end": "387610"
  },
  {
    "text": "this is an example of one of one of them",
    "start": "387610",
    "end": "389380"
  },
  {
    "text": "what happens when I increase the number",
    "start": "389380",
    "end": "391810"
  },
  {
    "text": "of concurrent connections on the latency",
    "start": "391810",
    "end": "393820"
  },
  {
    "text": "so what is the effect on the latency so",
    "start": "393820",
    "end": "396400"
  },
  {
    "text": "we defined all the tests we define the",
    "start": "396400",
    "end": "398650"
  },
  {
    "text": "test",
    "start": "398650",
    "end": "399140"
  },
  {
    "text": "which variable was under test what were",
    "start": "399140",
    "end": "401360"
  },
  {
    "text": "test cases and what was the expectation",
    "start": "401360",
    "end": "404000"
  },
  {
    "text": "that we were looking for so some of the",
    "start": "404000",
    "end": "408110"
  },
  {
    "text": "pros for mock micro benchmarks they very",
    "start": "408110",
    "end": "411200"
  },
  {
    "text": "quickly helped us identify bottlenecks",
    "start": "411200",
    "end": "412820"
  },
  {
    "text": "and bugs in contour and some of the",
    "start": "412820",
    "end": "415970"
  },
  {
    "text": "components in the discovery subsystem so",
    "start": "415970",
    "end": "418700"
  },
  {
    "text": "some examples here we ran into one where",
    "start": "418700",
    "end": "421940"
  },
  {
    "text": "contour would actually panic when we",
    "start": "421940",
    "end": "424160"
  },
  {
    "text": "were trying to create a lot of ingress",
    "start": "424160",
    "end": "426740"
  },
  {
    "text": "routes so ingress routes is a CRD that",
    "start": "426740",
    "end": "429440"
  },
  {
    "text": "we've built and when we started running",
    "start": "429440",
    "end": "432650"
  },
  {
    "text": "these tests contour would actually panic",
    "start": "432650",
    "end": "434840"
  },
  {
    "text": "and like break down and the reason for",
    "start": "434840",
    "end": "437150"
  },
  {
    "text": "this is we had a race condition that",
    "start": "437150",
    "end": "439040"
  },
  {
    "text": "would only happen at high load so that",
    "start": "439040",
    "end": "441710"
  },
  {
    "text": "was I was cool to find another issue",
    "start": "441710",
    "end": "445070"
  },
  {
    "text": "that we initially thought was just a",
    "start": "445070",
    "end": "447320"
  },
  {
    "text": "logging issue it actually turned out to",
    "start": "447320",
    "end": "449360"
  },
  {
    "text": "be much more interesting so you can see",
    "start": "449360",
    "end": "452030"
  },
  {
    "text": "here I'm hopefully you can see the",
    "start": "452030",
    "end": "453410"
  },
  {
    "text": "graphs but they're like going up and up",
    "start": "453410",
    "end": "455690"
  },
  {
    "text": "and up and up which you don't typically",
    "start": "455690",
    "end": "457250"
  },
  {
    "text": "want you don't typically like to see",
    "start": "457250",
    "end": "459050"
  },
  {
    "text": "that so in this case we are looking at Q",
    "start": "459050",
    "end": "462860"
  },
  {
    "text": "here so we use a Q internally in the",
    "start": "462860",
    "end": "465170"
  },
  {
    "text": "discovery system where we queue all the",
    "start": "465170",
    "end": "468050"
  },
  {
    "text": "services that we've discovered to be",
    "start": "468050",
    "end": "469970"
  },
  {
    "text": "then sent over to the gimbal cluster and",
    "start": "469970",
    "end": "472400"
  },
  {
    "text": "in this case what had happened is that",
    "start": "472400",
    "end": "475280"
  },
  {
    "text": "client go which is the library that we",
    "start": "475280",
    "end": "477590"
  },
  {
    "text": "use to talk with kubernetes actually has",
    "start": "477590",
    "end": "481100"
  },
  {
    "text": "a built in raid limiter that has a very",
    "start": "481100",
    "end": "483740"
  },
  {
    "text": "small default so I think it's five",
    "start": "483740",
    "end": "485930"
  },
  {
    "text": "requests per second so we have to",
    "start": "485930",
    "end": "488630"
  },
  {
    "text": "actually increase that limit and",
    "start": "488630",
    "end": "490130"
  },
  {
    "text": "actually make that configurable so that",
    "start": "490130",
    "end": "492140"
  },
  {
    "text": "the users of gimble could actually",
    "start": "492140",
    "end": "494330"
  },
  {
    "text": "configure that and you know use it as as",
    "start": "494330",
    "end": "497000"
  },
  {
    "text": "they really want it and get more",
    "start": "497000",
    "end": "498620"
  },
  {
    "text": "performance out of it so helped us",
    "start": "498620",
    "end": "503750"
  },
  {
    "text": "identify bottlenecks and then once we",
    "start": "503750",
    "end": "505700"
  },
  {
    "text": "did that it also gave us you know",
    "start": "505700",
    "end": "507410"
  },
  {
    "text": "confidence that contour itself could",
    "start": "507410",
    "end": "509900"
  },
  {
    "text": "actually handle a large number of all",
    "start": "509900",
    "end": "512810"
  },
  {
    "text": "these objects so we actually inside of",
    "start": "512810",
    "end": "514580"
  },
  {
    "text": "contour we build a graph that keeps",
    "start": "514580",
    "end": "517909"
  },
  {
    "text": "track of all the objects and we wanted",
    "start": "517910",
    "end": "520250"
  },
  {
    "text": "to make sure that contour could actually",
    "start": "520250",
    "end": "521510"
  },
  {
    "text": "handle a large number of these and micro",
    "start": "521510",
    "end": "524150"
  },
  {
    "text": "benchmarks we're really helpful there",
    "start": "524150",
    "end": "525470"
  },
  {
    "text": "and then finally micro benchmarks are",
    "start": "525470",
    "end": "528830"
  },
  {
    "text": "much more easier than macro benchmarks",
    "start": "528830",
    "end": "531350"
  },
  {
    "text": "to run and",
    "start": "531350",
    "end": "532820"
  },
  {
    "text": "so if your 10 constrains you know if",
    "start": "532820",
    "end": "534980"
  },
  {
    "text": "you're under any time like it's just",
    "start": "534980",
    "end": "537950"
  },
  {
    "text": "very much faster to uh to set up than",
    "start": "537950",
    "end": "542510"
  },
  {
    "text": "the macro benchmarks but of course the",
    "start": "542510",
    "end": "544610"
  },
  {
    "text": "big con is that you're evaluating the",
    "start": "544610",
    "end": "546950"
  },
  {
    "text": "system through a very narrow lens so",
    "start": "546950",
    "end": "549050"
  },
  {
    "text": "you're looking at a very specific",
    "start": "549050",
    "end": "550370"
  },
  {
    "text": "variable that might not really reflect",
    "start": "550370",
    "end": "553310"
  },
  {
    "text": "real-world usage so again doesn't really",
    "start": "553310",
    "end": "556070"
  },
  {
    "text": "reflect the reality of how the system is",
    "start": "556070",
    "end": "557960"
  },
  {
    "text": "going to behave at scale and that's",
    "start": "557960",
    "end": "561020"
  },
  {
    "text": "exactly where something like a macro",
    "start": "561020",
    "end": "562400"
  },
  {
    "text": "benchmark comes in",
    "start": "562400",
    "end": "563240"
  },
  {
    "text": "so macro benchmarks you know they test",
    "start": "563240",
    "end": "565550"
  },
  {
    "start": "564000",
    "end": "564000"
  },
  {
    "text": "the system on their realistic load they",
    "start": "565550",
    "end": "568250"
  },
  {
    "text": "measure and evaluate multiple metrics",
    "start": "568250",
    "end": "570010"
  },
  {
    "text": "and then while you're running these",
    "start": "570010",
    "end": "572720"
  },
  {
    "text": "tests you can start seeing where the",
    "start": "572720",
    "end": "574790"
  },
  {
    "text": "bottlenecks are and it'll give you an",
    "start": "574790",
    "end": "576530"
  },
  {
    "text": "idea of what you need to do to actually",
    "start": "576530",
    "end": "578840"
  },
  {
    "text": "scale the system so perhaps you want to",
    "start": "578840",
    "end": "581810"
  },
  {
    "text": "increase memory or you want to increase",
    "start": "581810",
    "end": "583460"
  },
  {
    "text": "CPU or perhaps you're hitting network",
    "start": "583460",
    "end": "585080"
  },
  {
    "text": "limitations so running macro benchmarks",
    "start": "585080",
    "end": "587450"
  },
  {
    "text": "really gave us the this sense of where",
    "start": "587450",
    "end": "590660"
  },
  {
    "text": "the bottlenecks were in this system one",
    "start": "590660",
    "end": "594260"
  },
  {
    "text": "thing with macro benchmarks though is",
    "start": "594260",
    "end": "595970"
  },
  {
    "text": "that given that you're doing a lot more",
    "start": "595970",
    "end": "599540"
  },
  {
    "text": "load or you know a lot many more",
    "start": "599540",
    "end": "602120"
  },
  {
    "text": "connections or requests per second you",
    "start": "602120",
    "end": "605240"
  },
  {
    "text": "might actually have to scale your tests",
    "start": "605240",
    "end": "607190"
  },
  {
    "text": "down to something that's more realistic",
    "start": "607190",
    "end": "608780"
  },
  {
    "text": "so we were a little limited with",
    "start": "608780",
    "end": "610790"
  },
  {
    "text": "hardware so what we ended up doing is we",
    "start": "610790",
    "end": "613400"
  },
  {
    "start": "613000",
    "end": "613000"
  },
  {
    "text": "actually ran tests at three different",
    "start": "613400",
    "end": "615800"
  },
  {
    "text": "scales and we wanted to ensure that the",
    "start": "615800",
    "end": "619190"
  },
  {
    "text": "resource utilization scaled as we",
    "start": "619190",
    "end": "622580"
  },
  {
    "text": "expected either linearly or sub linearly",
    "start": "622580",
    "end": "625300"
  },
  {
    "text": "according to our expectations so you can",
    "start": "625300",
    "end": "627650"
  },
  {
    "text": "see here and instead of running you know",
    "start": "627650",
    "end": "629630"
  },
  {
    "text": "millions of concurrent connections we",
    "start": "629630",
    "end": "631910"
  },
  {
    "text": "have to scale that down to three",
    "start": "631910",
    "end": "633830"
  },
  {
    "text": "different scales and run tests across",
    "start": "633830",
    "end": "635390"
  },
  {
    "text": "those so from an infrastructure",
    "start": "635390",
    "end": "639830"
  },
  {
    "start": "638000",
    "end": "638000"
  },
  {
    "text": "perspective we used a kubernetes cluster",
    "start": "639830",
    "end": "644420"
  },
  {
    "text": "where we split up the nodes in a way",
    "start": "644420",
    "end": "647120"
  },
  {
    "text": "that each node had a very specific role",
    "start": "647120",
    "end": "649790"
  },
  {
    "text": "so at the top we have a set of load",
    "start": "649790",
    "end": "651980"
  },
  {
    "text": "generating nodes that would actually",
    "start": "651980",
    "end": "653960"
  },
  {
    "text": "generate load against the gimble gimble",
    "start": "653960",
    "end": "658370"
  },
  {
    "text": "processes specifically envoy envoy was",
    "start": "658370",
    "end": "662480"
  },
  {
    "text": "running on the gimble nodes which were",
    "start": "662480",
    "end": "664570"
  },
  {
    "text": "labeled and then finally we had a couple",
    "start": "664570",
    "end": "667780"
  },
  {
    "text": "of back-end clusters where we were",
    "start": "667780",
    "end": "669190"
  },
  {
    "text": "actually sending traffic to from a",
    "start": "669190",
    "end": "673120"
  },
  {
    "text": "hardware perspective all of these we're",
    "start": "673120",
    "end": "675640"
  },
  {
    "text": "bare metal machines so there were 56",
    "start": "675640",
    "end": "677920"
  },
  {
    "text": "cores 264 gigs of ram and they were all",
    "start": "677920",
    "end": "681280"
  },
  {
    "text": "connected with a 10g network from a",
    "start": "681280",
    "end": "686680"
  },
  {
    "start": "686000",
    "end": "686000"
  },
  {
    "text": "tooling perspective from the load",
    "start": "686680",
    "end": "689800"
  },
  {
    "text": "generating side we use a couple of tools",
    "start": "689800",
    "end": "691720"
  },
  {
    "text": "work too and tcp kali and hope i'm",
    "start": "691720",
    "end": "694360"
  },
  {
    "text": "pronouncing that right",
    "start": "694360",
    "end": "696400"
  },
  {
    "text": "then on the gimble node we talked a",
    "start": "696400",
    "end": "698530"
  },
  {
    "text": "little bit about this there's envoy",
    "start": "698530",
    "end": "700030"
  },
  {
    "text": "contour the discovery system and then on",
    "start": "700030",
    "end": "703480"
  },
  {
    "text": "the back end we actually used nginx so",
    "start": "703480",
    "end": "705520"
  },
  {
    "text": "the typical example up and then you'll",
    "start": "705520",
    "end": "709180"
  },
  {
    "text": "notice that Prometheus and Griffin is",
    "start": "709180",
    "end": "710920"
  },
  {
    "text": "actually all over the place here we",
    "start": "710920",
    "end": "712990"
  },
  {
    "text": "really needed Prometheus Ravana to",
    "start": "712990",
    "end": "716890"
  },
  {
    "text": "understand how the system was behaving",
    "start": "716890",
    "end": "718930"
  },
  {
    "text": "while we were testing so super key so if",
    "start": "718930",
    "end": "724300"
  },
  {
    "text": "we died a bit if we go a bit deeper with",
    "start": "724300",
    "end": "726400"
  },
  {
    "text": "some of these tools work - if you're",
    "start": "726400",
    "end": "728500"
  },
  {
    "text": "unfamiliar woodwork - it's an HTTP level",
    "start": "728500",
    "end": "731020"
  },
  {
    "text": "benchmarking tool that can actually give",
    "start": "731020",
    "end": "734020"
  },
  {
    "text": "you some accurate latency measurements",
    "start": "734020",
    "end": "736150"
  },
  {
    "text": "so you can run you can run work -",
    "start": "736150",
    "end": "738610"
  },
  {
    "text": "against your service I run it for a",
    "start": "738610",
    "end": "740800"
  },
  {
    "text": "specified period of time and it'll give",
    "start": "740800",
    "end": "743320"
  },
  {
    "text": "you some information about how that",
    "start": "743320",
    "end": "744520"
  },
  {
    "text": "service is behaving it can actually",
    "start": "744520",
    "end": "747040"
  },
  {
    "text": "generate some significant load it takes",
    "start": "747040",
    "end": "748960"
  },
  {
    "text": "advantage of all the cores in the",
    "start": "748960",
    "end": "750700"
  },
  {
    "text": "machine and that was one of the things",
    "start": "750700",
    "end": "751870"
  },
  {
    "text": "that we really were looking for when it",
    "start": "751870",
    "end": "754450"
  },
  {
    "text": "came to deploying work - on the cluster",
    "start": "754450",
    "end": "757540"
  },
  {
    "text": "we used a kubernetes job so the job",
    "start": "757540",
    "end": "760510"
  },
  {
    "text": "resource was actually very helpful",
    "start": "760510",
    "end": "762400"
  },
  {
    "text": "helpful for some of these tests and",
    "start": "762400",
    "end": "764710"
  },
  {
    "text": "actually we can we can see what that",
    "start": "764710",
    "end": "767020"
  },
  {
    "text": "looks like so if you're familiar with",
    "start": "767020",
    "end": "769210"
  },
  {
    "text": "kubernetes this is your typical",
    "start": "769210",
    "end": "771630"
  },
  {
    "text": "kubernetes resource definition you have",
    "start": "771630",
    "end": "774430"
  },
  {
    "text": "your API version your kind so in this",
    "start": "774430",
    "end": "776350"
  },
  {
    "text": "case we're looking at a job and the",
    "start": "776350",
    "end": "779050"
  },
  {
    "text": "first thing I want to highlight is a",
    "start": "779050",
    "end": "780070"
  },
  {
    "text": "generate name feature which I found is",
    "start": "780070",
    "end": "782260"
  },
  {
    "text": "not very known and is not known very",
    "start": "782260",
    "end": "785350"
  },
  {
    "text": "widely so generating name will actually",
    "start": "785350",
    "end": "787990"
  },
  {
    "text": "allow you to specify a prefix and let",
    "start": "787990",
    "end": "791410"
  },
  {
    "text": "the API server generate a random name",
    "start": "791410",
    "end": "793630"
  },
  {
    "text": "for your resource this was super helpful",
    "start": "793630",
    "end": "796000"
  },
  {
    "text": "for it for us because",
    "start": "796000",
    "end": "798040"
  },
  {
    "text": "instead of having to you know create the",
    "start": "798040",
    "end": "801190"
  },
  {
    "text": "job delete it created again deleted it",
    "start": "801190",
    "end": "803589"
  },
  {
    "text": "was very easy for us to just submit a",
    "start": "803589",
    "end": "805180"
  },
  {
    "text": "bunch of jobs and then the API server",
    "start": "805180",
    "end": "807279"
  },
  {
    "text": "would be able to would generate the name",
    "start": "807279",
    "end": "809680"
  },
  {
    "text": "for us the next thing I want to",
    "start": "809680",
    "end": "812860"
  },
  {
    "text": "highlight is pod anti affinity so as I",
    "start": "812860",
    "end": "816040"
  },
  {
    "text": "mentioned before work to would actually",
    "start": "816040",
    "end": "818230"
  },
  {
    "text": "consume all the CPUs on the machines so",
    "start": "818230",
    "end": "821620"
  },
  {
    "text": "if two work two pods would land on the",
    "start": "821620",
    "end": "823779"
  },
  {
    "text": "same machine they would actually contend",
    "start": "823779",
    "end": "825819"
  },
  {
    "text": "for the CPU resources and that's",
    "start": "825819",
    "end": "827649"
  },
  {
    "text": "something that we didn't want to happen",
    "start": "827649",
    "end": "829470"
  },
  {
    "text": "so we used anti affinity to actually",
    "start": "829470",
    "end": "832509"
  },
  {
    "text": "tell the scheduler hey you know spread",
    "start": "832509",
    "end": "834639"
  },
  {
    "text": "these pods onto different nodes on the",
    "start": "834639",
    "end": "837370"
  },
  {
    "text": "cluster we also use the nib containers",
    "start": "837370",
    "end": "842230"
  },
  {
    "text": "and the reason for this is that we need",
    "start": "842230",
    "end": "844720"
  },
  {
    "text": "it to tweak the kernel so some kernel",
    "start": "844720",
    "end": "846790"
  },
  {
    "text": "settings for specific workloads in this",
    "start": "846790",
    "end": "848800"
  },
  {
    "text": "case work too we needed to tweak some of",
    "start": "848800",
    "end": "851769"
  },
  {
    "text": "those settings to be able to for example",
    "start": "851769",
    "end": "854410"
  },
  {
    "text": "open the number of connections that we",
    "start": "854410",
    "end": "856329"
  },
  {
    "text": "wanted to open so if you want to open a",
    "start": "856329",
    "end": "858550"
  },
  {
    "text": "lot of connections you actually need a",
    "start": "858550",
    "end": "860620"
  },
  {
    "text": "lot of ephemeral ports on your machines",
    "start": "860620",
    "end": "862810"
  },
  {
    "text": "and the default range is very small so",
    "start": "862810",
    "end": "865540"
  },
  {
    "text": "we increase that range so in this",
    "start": "865540",
    "end": "867220"
  },
  {
    "text": "example it's from 1024 to 65,000 so we",
    "start": "867220",
    "end": "871120"
  },
  {
    "text": "used an init container here to actually",
    "start": "871120",
    "end": "872920"
  },
  {
    "text": "increase that port range and then",
    "start": "872920",
    "end": "876730"
  },
  {
    "text": "finally this is what work to command",
    "start": "876730",
    "end": "879459"
  },
  {
    "text": "looks like so you give it the duration",
    "start": "879459",
    "end": "882100"
  },
  {
    "text": "of your test the number of connections",
    "start": "882100",
    "end": "883569"
  },
  {
    "text": "that you want to open the request rate",
    "start": "883569",
    "end": "886120"
  },
  {
    "text": "that you want to send against your",
    "start": "886120",
    "end": "887589"
  },
  {
    "text": "service and then you know where is the",
    "start": "887589",
    "end": "889600"
  },
  {
    "text": "service so in this case we are using the",
    "start": "889600",
    "end": "891610"
  },
  {
    "text": "internal envoy and service inside of the",
    "start": "891610",
    "end": "895569"
  },
  {
    "text": "gimble contour namespace the next tool",
    "start": "895569",
    "end": "901420"
  },
  {
    "text": "that we used which came along a little",
    "start": "901420",
    "end": "904000"
  },
  {
    "text": "bit later is TCP Cali the reason for TCP",
    "start": "904000",
    "end": "908680"
  },
  {
    "text": "Cali is that we found that work 2 was",
    "start": "908680",
    "end": "912010"
  },
  {
    "text": "not very good at opening a large number",
    "start": "912010",
    "end": "914680"
  },
  {
    "text": "of connections so given that we wanted",
    "start": "914680",
    "end": "917050"
  },
  {
    "text": "to open you know 300,000 connections we",
    "start": "917050",
    "end": "919839"
  },
  {
    "text": "had to bring another tool in so TCP Kali",
    "start": "919839",
    "end": "921790"
  },
  {
    "text": "is a TCP load generator and we found",
    "start": "921790",
    "end": "925720"
  },
  {
    "text": "that it was much better at opening a lot",
    "start": "925720",
    "end": "927430"
  },
  {
    "text": "of",
    "start": "927430",
    "end": "928390"
  },
  {
    "text": "connections when it came to deploying",
    "start": "928390",
    "end": "931390"
  },
  {
    "text": "this it was very similar to work too so",
    "start": "931390",
    "end": "934210"
  },
  {
    "text": "if we go here we can see that you know",
    "start": "934210",
    "end": "936040"
  },
  {
    "text": "it's the same job definition we use the",
    "start": "936040",
    "end": "938830"
  },
  {
    "text": "job as well what's interesting here is",
    "start": "938830",
    "end": "941230"
  },
  {
    "text": "that we actually used completions and",
    "start": "941230",
    "end": "943480"
  },
  {
    "text": "parallelism to be able to run multiple",
    "start": "943480",
    "end": "945370"
  },
  {
    "text": "jobs at the same time and that way",
    "start": "945370",
    "end": "947860"
  },
  {
    "text": "increase the number of connections that",
    "start": "947860",
    "end": "950020"
  },
  {
    "text": "we were opening so in this case we were",
    "start": "950020",
    "end": "952300"
  },
  {
    "text": "running six of these workloads at the",
    "start": "952300",
    "end": "954850"
  },
  {
    "text": "same time and this is what the command",
    "start": "954850",
    "end": "959890"
  },
  {
    "text": "line looks like for TCP Cali you give it",
    "start": "959890",
    "end": "962350"
  },
  {
    "text": "the number of connections that you want",
    "start": "962350",
    "end": "963880"
  },
  {
    "text": "to open the duration of how long you",
    "start": "963880",
    "end": "966490"
  },
  {
    "text": "want to keep those open and then what is",
    "start": "966490",
    "end": "968650"
  },
  {
    "text": "the connection rate so how many",
    "start": "968650",
    "end": "969760"
  },
  {
    "text": "connections do you want to make for a",
    "start": "969760",
    "end": "971710"
  },
  {
    "text": "second and then as I mentioned before we",
    "start": "971710",
    "end": "976870"
  },
  {
    "start": "975000",
    "end": "975000"
  },
  {
    "text": "used nginx as the target service we just",
    "start": "976870",
    "end": "980230"
  },
  {
    "text": "deployed it as a kubernetes deployment",
    "start": "980230",
    "end": "981940"
  },
  {
    "text": "and we actually ran tests against two",
    "start": "981940",
    "end": "983880"
  },
  {
    "text": "variations of of nginx the classic or",
    "start": "983880",
    "end": "987670"
  },
  {
    "text": "the vanilla that you can get out of",
    "start": "987670",
    "end": "989530"
  },
  {
    "text": "docker hub which responds with about 600",
    "start": "989530",
    "end": "992110"
  },
  {
    "text": "bytes of data and then we also wanted to",
    "start": "992110",
    "end": "994900"
  },
  {
    "text": "use a custom nginx that would reply with",
    "start": "994900",
    "end": "997870"
  },
  {
    "text": "22 kilobytes of data which is the",
    "start": "997870",
    "end": "1000120"
  },
  {
    "text": "average payload size that Yahoo Japan",
    "start": "1000120",
    "end": "1003360"
  },
  {
    "text": "was was experiencing when it came to",
    "start": "1003360",
    "end": "1006900"
  },
  {
    "text": "testing against nginx we found that the",
    "start": "1006900",
    "end": "1010140"
  },
  {
    "text": "default config that it comes with wasn't",
    "start": "1010140",
    "end": "1013350"
  },
  {
    "text": "really enough for the tests that we were",
    "start": "1013350",
    "end": "1016590"
  },
  {
    "text": "doing so we actually had to customize",
    "start": "1016590",
    "end": "1019710"
  },
  {
    "text": "and tweak some of the configuration of",
    "start": "1019710",
    "end": "1021660"
  },
  {
    "text": "nginx so here is a config map of the",
    "start": "1021660",
    "end": "1028050"
  },
  {
    "text": "nginx config that we used and there's a",
    "start": "1028050",
    "end": "1030000"
  },
  {
    "text": "couple of things I want to highlight",
    "start": "1030000",
    "end": "1030810"
  },
  {
    "text": "here so in line 5 we are telling nginx",
    "start": "1030810",
    "end": "1034260"
  },
  {
    "text": "to fork as many worker processes as",
    "start": "1034260",
    "end": "1039569"
  },
  {
    "text": "there are CPUs on the machine so the way",
    "start": "1039570",
    "end": "1042540"
  },
  {
    "text": "nginx works is there's a master process",
    "start": "1042540",
    "end": "1044880"
  },
  {
    "text": "and then it Forks a bunch of workers",
    "start": "1044880",
    "end": "1046290"
  },
  {
    "text": "that actually accepts all the requests",
    "start": "1046290",
    "end": "1048780"
  },
  {
    "text": "or the connections so we wanted to make",
    "start": "1048780",
    "end": "1050880"
  },
  {
    "text": "sure that nginx was utilizing all the",
    "start": "1050880",
    "end": "1052560"
  },
  {
    "text": "CPUs available on the machines the next",
    "start": "1052560",
    "end": "1056190"
  },
  {
    "text": "thing on line 6 is the number of open",
    "start": "1056190",
    "end": "1058500"
  },
  {
    "text": "file descriptors so when you're",
    "start": "1058500",
    "end": "1059760"
  },
  {
    "text": "accepting a lot of connections",
    "start": "1059760",
    "end": "1061180"
  },
  {
    "text": "you actually are consuming file",
    "start": "1061180",
    "end": "1062860"
  },
  {
    "text": "descriptors so we had to increase that",
    "start": "1062860",
    "end": "1064960"
  },
  {
    "text": "as well then a couple other things line",
    "start": "1064960",
    "end": "1067780"
  },
  {
    "text": "14 how many actual connections each",
    "start": "1067780",
    "end": "1070840"
  },
  {
    "text": "worker could open or could accept so we",
    "start": "1070840",
    "end": "1073990"
  },
  {
    "text": "had to increase that to around 65,000",
    "start": "1073990",
    "end": "1076360"
  },
  {
    "text": "another thing that it's not really",
    "start": "1076360",
    "end": "1078160"
  },
  {
    "text": "visible here is that we actually",
    "start": "1078160",
    "end": "1079090"
  },
  {
    "text": "disabled the access log so we found that",
    "start": "1079090",
    "end": "1081850"
  },
  {
    "text": "the access log would actually slow down",
    "start": "1081850",
    "end": "1083710"
  },
  {
    "text": "the nginx process so we disabled the",
    "start": "1083710",
    "end": "1088030"
  },
  {
    "text": "access log in nginx so let's talk a",
    "start": "1088030",
    "end": "1093100"
  },
  {
    "text": "little bit about results we are going to",
    "start": "1093100",
    "end": "1096280"
  },
  {
    "text": "look at four charts or graphs that they",
    "start": "1096280",
    "end": "1100090"
  },
  {
    "text": "all look at the impact of concurrency",
    "start": "1100090",
    "end": "1102550"
  },
  {
    "text": "and requests per second on specific",
    "start": "1102550",
    "end": "1104830"
  },
  {
    "text": "variables so in this case we are looking",
    "start": "1104830",
    "end": "1107320"
  },
  {
    "text": "at the impact of concurrency and RPS on",
    "start": "1107320",
    "end": "1109960"
  },
  {
    "text": "latency and we can see here that during",
    "start": "1109960",
    "end": "1112930"
  },
  {
    "text": "our tests all the latency measurements",
    "start": "1112930",
    "end": "1116860"
  },
  {
    "text": "that we got were under 15 milliseconds",
    "start": "1116860",
    "end": "1119260"
  },
  {
    "text": "so very much under our target anywhere",
    "start": "1119260",
    "end": "1123730"
  },
  {
    "text": "between 5 and 12 milliseconds CPU is",
    "start": "1123730",
    "end": "1129640"
  },
  {
    "text": "where it starts to get interesting the",
    "start": "1129640",
    "end": "1132040"
  },
  {
    "text": "more requests per second that we were",
    "start": "1132040",
    "end": "1134020"
  },
  {
    "text": "sending the more CPU that Envoy was",
    "start": "1134020",
    "end": "1137080"
  },
  {
    "text": "consuming so you can see here that you",
    "start": "1137080",
    "end": "1139600"
  },
  {
    "text": "know when we started at the blue line",
    "start": "1139600",
    "end": "1141490"
  },
  {
    "text": "which is 10 you know red which is 20,000",
    "start": "1141490",
    "end": "1144700"
  },
  {
    "text": "requests per second and then all the way",
    "start": "1144700",
    "end": "1146650"
  },
  {
    "text": "up to 30,000 requests per second the CPU",
    "start": "1146650",
    "end": "1149440"
  },
  {
    "text": "you know envoy was consuming more CPU",
    "start": "1149440",
    "end": "1152200"
  },
  {
    "text": "which kind of makes sense the more",
    "start": "1152200",
    "end": "1153940"
  },
  {
    "text": "requests you're sending the more churned",
    "start": "1153940",
    "end": "1155470"
  },
  {
    "text": "the more processing that envoy has to do",
    "start": "1155470",
    "end": "1159390"
  },
  {
    "text": "impact on memory was also interesting",
    "start": "1159660",
    "end": "1163030"
  },
  {
    "text": "the more connections we were opening the",
    "start": "1163030",
    "end": "1167500"
  },
  {
    "text": "more memory envoy was consuming and this",
    "start": "1167500",
    "end": "1169990"
  },
  {
    "text": "also kind of makes sense",
    "start": "1169990",
    "end": "1171270"
  },
  {
    "text": "you are keeping track of more",
    "start": "1171270",
    "end": "1173530"
  },
  {
    "text": "connections the more memory that you're",
    "start": "1173530",
    "end": "1175180"
  },
  {
    "text": "going to use so we can see here that the",
    "start": "1175180",
    "end": "1177460"
  },
  {
    "text": "memory went up all the way up to around",
    "start": "1177460",
    "end": "1179080"
  },
  {
    "text": "eight hundred and twenty megabytes and",
    "start": "1179080",
    "end": "1184380"
  },
  {
    "text": "then finally the impact on the network",
    "start": "1184380",
    "end": "1187270"
  },
  {
    "text": "so how did the network ingress or sorry",
    "start": "1187270",
    "end": "1190510"
  },
  {
    "text": "egress behaved here",
    "start": "1190510",
    "end": "1192400"
  },
  {
    "text": "and we can see that it looks very",
    "start": "1192400",
    "end": "1194020"
  },
  {
    "text": "similar to the CPU graph where the more",
    "start": "1194020",
    "end": "1197050"
  },
  {
    "text": "requests per second we were making the",
    "start": "1197050",
    "end": "1199150"
  },
  {
    "text": "more bandwidth we were consuming and",
    "start": "1199150",
    "end": "1201700"
  },
  {
    "text": "again this makes sense the more requests",
    "start": "1201700",
    "end": "1203590"
  },
  {
    "text": "the more data is flowing through the",
    "start": "1203590",
    "end": "1204880"
  },
  {
    "text": "pipes so this was good to see as well so",
    "start": "1204880",
    "end": "1208330"
  },
  {
    "text": "this is a summary of all the the graphs",
    "start": "1208330",
    "end": "1210400"
  },
  {
    "text": "we saw and one of the conclusions that",
    "start": "1210400",
    "end": "1213310"
  },
  {
    "text": "we were able to make here is that a",
    "start": "1213310",
    "end": "1215440"
  },
  {
    "text": "single Envoy pod or machine or machine",
    "start": "1215440",
    "end": "1222070"
  },
  {
    "text": "running envoy could actually handle a",
    "start": "1222070",
    "end": "1224320"
  },
  {
    "text": "lot of load and if they wanted to go up",
    "start": "1224320",
    "end": "1227290"
  },
  {
    "text": "to you know three million concurrent",
    "start": "1227290",
    "end": "1229690"
  },
  {
    "text": "connections they could actually just run",
    "start": "1229690",
    "end": "1231340"
  },
  {
    "text": "ten envoy pods which was which was",
    "start": "1231340",
    "end": "1234850"
  },
  {
    "text": "interesting so that's what it was great",
    "start": "1234850",
    "end": "1237010"
  },
  {
    "text": "to see that the system actually just",
    "start": "1237010",
    "end": "1238390"
  },
  {
    "text": "scales you know in a linear fashion so",
    "start": "1238390",
    "end": "1241090"
  },
  {
    "text": "that was that was cool to get some of",
    "start": "1241090",
    "end": "1245500"
  },
  {
    "text": "that data as I mentioned before we used",
    "start": "1245500",
    "end": "1247240"
  },
  {
    "text": "uber fauna and Prometheus and this is an",
    "start": "1247240",
    "end": "1249250"
  },
  {
    "text": "example of a dashboard that we built for",
    "start": "1249250",
    "end": "1251500"
  },
  {
    "text": "our tests so if we zoom in a little bit",
    "start": "1251500",
    "end": "1254050"
  },
  {
    "text": "and hopefully you can see it on the left",
    "start": "1254050",
    "end": "1258160"
  },
  {
    "text": "we have requests per second than",
    "start": "1258160",
    "end": "1260110"
  },
  {
    "text": "connections per second and the latency",
    "start": "1260110",
    "end": "1262150"
  },
  {
    "text": "and then the total connections",
    "start": "1262150",
    "end": "1264880"
  },
  {
    "text": "downstream and upstream if we scroll",
    "start": "1264880",
    "end": "1268060"
  },
  {
    "text": "down a little by the way these are all",
    "start": "1268060",
    "end": "1269410"
  },
  {
    "text": "coming out of envoy so thank you envoy",
    "start": "1269410",
    "end": "1271720"
  },
  {
    "text": "community super helpful metrics",
    "start": "1271720",
    "end": "1274180"
  },
  {
    "text": "out-of-the-box so it was it was it was",
    "start": "1274180",
    "end": "1278080"
  },
  {
    "text": "great to have these metrics to",
    "start": "1278080",
    "end": "1279580"
  },
  {
    "text": "understand the system if we scroll down",
    "start": "1279580",
    "end": "1282760"
  },
  {
    "text": "a little bit we will see that we added a",
    "start": "1282760",
    "end": "1284920"
  },
  {
    "text": "couple more things so mainly how is",
    "start": "1284920",
    "end": "1288160"
  },
  {
    "text": "Envoy using the CPU using memory and",
    "start": "1288160",
    "end": "1290920"
  },
  {
    "text": "using the network so we wanted to get on",
    "start": "1290920",
    "end": "1293110"
  },
  {
    "text": "insta to get insights into that",
    "start": "1293110",
    "end": "1294970"
  },
  {
    "text": "utilization there so my main idea for",
    "start": "1294970",
    "end": "1300700"
  },
  {
    "text": "this talk wasn't really about to talk",
    "start": "1300700",
    "end": "1302200"
  },
  {
    "text": "about the numbers it was more to share",
    "start": "1302200",
    "end": "1305020"
  },
  {
    "text": "some of the lessons that we learned so",
    "start": "1305020",
    "end": "1306880"
  },
  {
    "text": "we it was it was hard work we made",
    "start": "1306880",
    "end": "1310720"
  },
  {
    "text": "mistakes along the way so hopefully you",
    "start": "1310720",
    "end": "1312790"
  },
  {
    "text": "know talking about this is going to help",
    "start": "1312790",
    "end": "1314860"
  },
  {
    "text": "you when it comes to doing your own",
    "start": "1314860",
    "end": "1317620"
  },
  {
    "text": "testing with your own services so the",
    "start": "1317620",
    "end": "1321550"
  },
  {
    "start": "1321000",
    "end": "1321000"
  },
  {
    "text": "first thing is document everything I",
    "start": "1321550",
    "end": "1323470"
  },
  {
    "text": "can't stress this enough",
    "start": "1323470",
    "end": "1325180"
  },
  {
    "text": "create a plan that just outlines how",
    "start": "1325180",
    "end": "1327790"
  },
  {
    "text": "you're going to test what you're going",
    "start": "1327790",
    "end": "1329260"
  },
  {
    "text": "to test part of that plan or part of",
    "start": "1329260",
    "end": "1331480"
  },
  {
    "text": "that document should probably should be",
    "start": "1331480",
    "end": "1333220"
  },
  {
    "text": "a like a results table or maybe have a",
    "start": "1333220",
    "end": "1335800"
  },
  {
    "text": "results document where you already set",
    "start": "1335800",
    "end": "1337720"
  },
  {
    "text": "up and know exactly which number is",
    "start": "1337720",
    "end": "1340210"
  },
  {
    "text": "you're interested in because while",
    "start": "1340210",
    "end": "1341500"
  },
  {
    "text": "you're running the test we're going to",
    "start": "1341500",
    "end": "1342610"
  },
  {
    "text": "get a lot of data and you want to be",
    "start": "1342610",
    "end": "1345220"
  },
  {
    "text": "consistent across test runs so make sure",
    "start": "1345220",
    "end": "1347290"
  },
  {
    "text": "that you have a table where you are",
    "start": "1347290",
    "end": "1349510"
  },
  {
    "text": "actually jotting down some of these",
    "start": "1349510",
    "end": "1350740"
  },
  {
    "text": "results once you have that outline over",
    "start": "1350740",
    "end": "1354700"
  },
  {
    "text": "that plan before running any tests",
    "start": "1354700",
    "end": "1357250"
  },
  {
    "text": "document the environment so document you",
    "start": "1357250",
    "end": "1359980"
  },
  {
    "text": "know the number of nodes that you're",
    "start": "1359980",
    "end": "1361570"
  },
  {
    "text": "running against the number of CPUs that",
    "start": "1361570",
    "end": "1363640"
  },
  {
    "text": "each node has how much memory the",
    "start": "1363640",
    "end": "1366059"
  },
  {
    "text": "version of the software that you're",
    "start": "1366059",
    "end": "1367990"
  },
  {
    "text": "running so all of these things are very",
    "start": "1367990",
    "end": "1369370"
  },
  {
    "text": "important so that once you're analyzing",
    "start": "1369370",
    "end": "1371140"
  },
  {
    "text": "the results you actually know you can",
    "start": "1371140",
    "end": "1374140"
  },
  {
    "text": "compare and contrast across software",
    "start": "1374140",
    "end": "1376900"
  },
  {
    "text": "versions or memory and stuff like that",
    "start": "1376900",
    "end": "1378490"
  },
  {
    "text": "and then finally I found it useful to",
    "start": "1378490",
    "end": "1382059"
  },
  {
    "text": "just keep a journal or a scratch pad",
    "start": "1382059",
    "end": "1383679"
  },
  {
    "text": "where I could just take notes when",
    "start": "1383679",
    "end": "1385030"
  },
  {
    "text": "something weird happened so I recommend",
    "start": "1385030",
    "end": "1387880"
  },
  {
    "text": "doing that as well",
    "start": "1387880",
    "end": "1390900"
  },
  {
    "start": "1391000",
    "end": "1391000"
  },
  {
    "text": "observability very very important",
    "start": "1391980",
    "end": "1395910"
  },
  {
    "text": "Promethean graph on a--",
    "start": "1395910",
    "end": "1397390"
  },
  {
    "text": "super helpful the we were lucky that you",
    "start": "1397390",
    "end": "1400990"
  },
  {
    "text": "know envoy has great metrics contour and",
    "start": "1400990",
    "end": "1404110"
  },
  {
    "text": "gimbal they already had metrics we were",
    "start": "1404110",
    "end": "1407290"
  },
  {
    "text": "missing some that we added so that was",
    "start": "1407290",
    "end": "1409090"
  },
  {
    "text": "also cool so yeah it was again metrics",
    "start": "1409090",
    "end": "1412660"
  },
  {
    "text": "are super key for these tests we also",
    "start": "1412660",
    "end": "1415480"
  },
  {
    "text": "found the node level metrics to be",
    "start": "1415480",
    "end": "1417280"
  },
  {
    "text": "useful so not only not only how you know",
    "start": "1417280",
    "end": "1419710"
  },
  {
    "text": "each of the components are behaving but",
    "start": "1419710",
    "end": "1422050"
  },
  {
    "text": "how are the nodes themselves behaving",
    "start": "1422050",
    "end": "1423700"
  },
  {
    "text": "that was also useful we used know the",
    "start": "1423700",
    "end": "1426190"
  },
  {
    "text": "exporter for that and we found that",
    "start": "1426190",
    "end": "1428500"
  },
  {
    "text": "creating test dashboards instead of you",
    "start": "1428500",
    "end": "1431860"
  },
  {
    "text": "know jumping across dashboards was very",
    "start": "1431860",
    "end": "1433540"
  },
  {
    "text": "helpful as well",
    "start": "1433540",
    "end": "1434370"
  },
  {
    "text": "but you know in summary just use and use",
    "start": "1434370",
    "end": "1438730"
  },
  {
    "text": "some of these tools you know don't don't",
    "start": "1438730",
    "end": "1440470"
  },
  {
    "text": "fly blind understand how your systems",
    "start": "1440470",
    "end": "1442420"
  },
  {
    "text": "are behaving short tests can be",
    "start": "1442420",
    "end": "1446500"
  },
  {
    "start": "1445000",
    "end": "1445000"
  },
  {
    "text": "deceptive when we started doing these",
    "start": "1446500",
    "end": "1449590"
  },
  {
    "text": "tests we were actually running like 10",
    "start": "1449590",
    "end": "1451960"
  },
  {
    "text": "second tests for 15 second tests I think",
    "start": "1451960",
    "end": "1454780"
  },
  {
    "text": "we might have gone up to 30 seconds",
    "start": "1454780",
    "end": "1456909"
  },
  {
    "text": "and while we were running multiple tests",
    "start": "1456909",
    "end": "1459099"
  },
  {
    "text": "we were seeing that there was a lot of",
    "start": "1459099",
    "end": "1460450"
  },
  {
    "text": "variability between them between the",
    "start": "1460450",
    "end": "1462009"
  },
  {
    "text": "results and the reason for this is that",
    "start": "1462009",
    "end": "1464409"
  },
  {
    "text": "it's just not enough time so we moved",
    "start": "1464409",
    "end": "1466779"
  },
  {
    "text": "over to longer tests or five-minute",
    "start": "1466779",
    "end": "1469389"
  },
  {
    "text": "10-minute tests and you know that allows",
    "start": "1469389",
    "end": "1472059"
  },
  {
    "text": "first of all your components to warm up",
    "start": "1472059",
    "end": "1474279"
  },
  {
    "text": "and to actually be ready for the load",
    "start": "1474279",
    "end": "1476470"
  },
  {
    "text": "that you're sending and then also in",
    "start": "1476470",
    "end": "1478629"
  },
  {
    "text": "some networks you're actually going to",
    "start": "1478629",
    "end": "1480190"
  },
  {
    "text": "see jitter and you know traffic or yeah",
    "start": "1480190",
    "end": "1482979"
  },
  {
    "text": "jitter so with a longer measurement",
    "start": "1482979",
    "end": "1486159"
  },
  {
    "text": "period you're actually minimizing the",
    "start": "1486159",
    "end": "1487840"
  },
  {
    "text": "impact of that",
    "start": "1487840",
    "end": "1490859"
  },
  {
    "start": "1491000",
    "end": "1491000"
  },
  {
    "text": "next check the network so someone can",
    "start": "1491999",
    "end": "1496479"
  },
  {
    "text": "say this is a 10 G network but",
    "start": "1496479",
    "end": "1498609"
  },
  {
    "text": "effectively it might be much slower so",
    "start": "1498609",
    "end": "1502029"
  },
  {
    "text": "I'm not necessarily much small slower",
    "start": "1502029",
    "end": "1504070"
  },
  {
    "text": "but when we started running these tests",
    "start": "1504070",
    "end": "1506950"
  },
  {
    "text": "we just assumed that we had a 10 G",
    "start": "1506950",
    "end": "1508929"
  },
  {
    "text": "network and some of the measurements",
    "start": "1508929",
    "end": "1510970"
  },
  {
    "text": "that we were doing and the calculations",
    "start": "1510970",
    "end": "1512649"
  },
  {
    "text": "that we were doing the math just wasn't",
    "start": "1512649",
    "end": "1514359"
  },
  {
    "text": "adding up and one of the reasons was",
    "start": "1514359",
    "end": "1516609"
  },
  {
    "text": "that it wasn't effectively a 10 G",
    "start": "1516609",
    "end": "1518710"
  },
  {
    "text": "network it was more like an 8 dot",
    "start": "1518710",
    "end": "1520359"
  },
  {
    "text": "something so you have to keep that",
    "start": "1520359",
    "end": "1523840"
  },
  {
    "text": "capacity in mind you don't want to",
    "start": "1523840",
    "end": "1525369"
  },
  {
    "text": "overfill your pipes because otherwise",
    "start": "1525369",
    "end": "1528159"
  },
  {
    "text": "you're gonna start seeing weird weird",
    "start": "1528159",
    "end": "1529929"
  },
  {
    "text": "stuff so yeah measure your network we",
    "start": "1529929",
    "end": "1533590"
  },
  {
    "text": "used I / 3 4 for doing this there's",
    "start": "1533590",
    "end": "1537249"
  },
  {
    "text": "actually an open source project around",
    "start": "1537249",
    "end": "1539139"
  },
  {
    "text": "running iperf 3 on kubernetes which is",
    "start": "1539139",
    "end": "1541359"
  },
  {
    "text": "just orchestrating everything which is",
    "start": "1541359",
    "end": "1542710"
  },
  {
    "text": "really nice so yeah check your network",
    "start": "1542710",
    "end": "1546960"
  },
  {
    "text": "tweak the kernel so we saw an example of",
    "start": "1546960",
    "end": "1549549"
  },
  {
    "start": "1547000",
    "end": "1547000"
  },
  {
    "text": "this and the work - job definition the",
    "start": "1549549",
    "end": "1554019"
  },
  {
    "text": "kernel can actually get in your way so",
    "start": "1554019",
    "end": "1556059"
  },
  {
    "text": "make sure that you check the logs check",
    "start": "1556059",
    "end": "1558909"
  },
  {
    "text": "the system logs check the kernel logs",
    "start": "1558909",
    "end": "1560229"
  },
  {
    "text": "some of it might end up there some of it",
    "start": "1560229",
    "end": "1562450"
  },
  {
    "text": "might not I found a couple of things",
    "start": "1562450",
    "end": "1564039"
  },
  {
    "text": "that did end up there but sometimes you",
    "start": "1564039",
    "end": "1566679"
  },
  {
    "text": "just have to know a bit more about what",
    "start": "1566679",
    "end": "1569259"
  },
  {
    "text": "to look for and then as you saw we used",
    "start": "1569259",
    "end": "1571779"
  },
  {
    "text": "an init container to tweak the kernel or",
    "start": "1571779",
    "end": "1575379"
  },
  {
    "text": "tune the kernel and that's kind of how",
    "start": "1575379",
    "end": "1577389"
  },
  {
    "text": "we did it in kubernetes pine box rabbit",
    "start": "1577389",
    "end": "1581559"
  },
  {
    "start": "1580000",
    "end": "1580000"
  },
  {
    "text": "hole so this is an interesting one when",
    "start": "1581559",
    "end": "1584229"
  },
  {
    "text": "we were doing these tests we would find",
    "start": "1584229",
    "end": "1588070"
  },
  {
    "text": "weird things",
    "start": "1588070",
    "end": "1589270"
  },
  {
    "text": "happen so there would be an outlier or",
    "start": "1589270",
    "end": "1591730"
  },
  {
    "text": "you know we would run into some Network",
    "start": "1591730",
    "end": "1594280"
  },
  {
    "text": "issues and we weren't sure if it was",
    "start": "1594280",
    "end": "1597250"
  },
  {
    "text": "like an environment thing or a an actual",
    "start": "1597250",
    "end": "1599470"
  },
  {
    "text": "bug so we would actually try to",
    "start": "1599470",
    "end": "1600880"
  },
  {
    "text": "investigate and try to replicate some of",
    "start": "1600880",
    "end": "1603280"
  },
  {
    "text": "these issues that we saw the issue here",
    "start": "1603280",
    "end": "1608800"
  },
  {
    "text": "is that you can actually spend a lot of",
    "start": "1608800",
    "end": "1609970"
  },
  {
    "text": "time trying to track these down so just",
    "start": "1609970",
    "end": "1612010"
  },
  {
    "text": "make sure that when you're running to",
    "start": "1612010",
    "end": "1614050"
  },
  {
    "text": "these and you're going to investigate",
    "start": "1614050",
    "end": "1615670"
  },
  {
    "text": "just try to put a time box around it",
    "start": "1615670",
    "end": "1617770"
  },
  {
    "text": "because you might find that you're",
    "start": "1617770",
    "end": "1619180"
  },
  {
    "text": "actually chasing something that isn't",
    "start": "1619180",
    "end": "1620200"
  },
  {
    "text": "really a thing that might have been an",
    "start": "1620200",
    "end": "1621400"
  },
  {
    "text": "environmental thing so yeah just one",
    "start": "1621400",
    "end": "1624480"
  },
  {
    "text": "time box rabbit holes understand first",
    "start": "1624480",
    "end": "1630610"
  },
  {
    "start": "1629000",
    "end": "1629000"
  },
  {
    "text": "automate later so as engineers as",
    "start": "1630610",
    "end": "1634260"
  },
  {
    "text": "developers we typically like to automate",
    "start": "1634260",
    "end": "1637180"
  },
  {
    "text": "everything make our lives easier but we",
    "start": "1637180",
    "end": "1639880"
  },
  {
    "text": "found that the plan that we had built",
    "start": "1639880",
    "end": "1643000"
  },
  {
    "text": "would actually change along the way so",
    "start": "1643000",
    "end": "1644950"
  },
  {
    "text": "the more we learned about our system the",
    "start": "1644950",
    "end": "1646960"
  },
  {
    "text": "more we learned about the environment",
    "start": "1646960",
    "end": "1648820"
  },
  {
    "text": "the more we learned about how to test",
    "start": "1648820",
    "end": "1650770"
  },
  {
    "text": "this system the plan that we were",
    "start": "1650770",
    "end": "1653020"
  },
  {
    "text": "building would actually change and the",
    "start": "1653020",
    "end": "1654400"
  },
  {
    "text": "automation was actually would actually",
    "start": "1654400",
    "end": "1656920"
  },
  {
    "text": "have to change as well so wait until you",
    "start": "1656920",
    "end": "1660070"
  },
  {
    "text": "actually understand your strategy how",
    "start": "1660070",
    "end": "1661510"
  },
  {
    "text": "you're going to test your system before",
    "start": "1661510",
    "end": "1663010"
  },
  {
    "text": "actually building any automation so once",
    "start": "1663010",
    "end": "1664750"
  },
  {
    "text": "that strategy is solid documented have",
    "start": "1664750",
    "end": "1667540"
  },
  {
    "text": "someone else run the tests make sure",
    "start": "1667540",
    "end": "1669850"
  },
  {
    "text": "that someone else can actually do it and",
    "start": "1669850",
    "end": "1671410"
  },
  {
    "text": "then go and build some automation we",
    "start": "1671410",
    "end": "1674860"
  },
  {
    "text": "actually found that creating and when",
    "start": "1674860",
    "end": "1676180"
  },
  {
    "text": "the automation wasn't really worth it",
    "start": "1676180",
    "end": "1677620"
  },
  {
    "text": "because it's actually really hard you",
    "start": "1677620",
    "end": "1678970"
  },
  {
    "text": "know you have to look at graphs you have",
    "start": "1678970",
    "end": "1681190"
  },
  {
    "text": "to look at some data you have to there's",
    "start": "1681190",
    "end": "1683320"
  },
  {
    "text": "a lot so it's it's actually not very",
    "start": "1683320",
    "end": "1686410"
  },
  {
    "text": "easy so with that hopefully that was",
    "start": "1686410",
    "end": "1691000"
  },
  {
    "text": "helpful if you're doing anything around",
    "start": "1691000",
    "end": "1693490"
  },
  {
    "text": "testing at scale in kubernetes or you",
    "start": "1693490",
    "end": "1696550"
  },
  {
    "text": "know anywhere I would love to learn more",
    "start": "1696550",
    "end": "1698470"
  },
  {
    "text": "if you're interested in contour gimble",
    "start": "1698470",
    "end": "1701260"
  },
  {
    "text": "you can check them out there we also",
    "start": "1701260",
    "end": "1702790"
  },
  {
    "text": "have a booth down and sponsor area I",
    "start": "1702790",
    "end": "1706360"
  },
  {
    "text": "guess and if you want to reach out I'm",
    "start": "1706360",
    "end": "1708820"
  },
  {
    "text": "gonna be here so there's any questions",
    "start": "1708820",
    "end": "1710560"
  },
  {
    "text": "let me know but thank you and happy",
    "start": "1710560",
    "end": "1712840"
  },
  {
    "text": "testing",
    "start": "1712840",
    "end": "1714960"
  }
]
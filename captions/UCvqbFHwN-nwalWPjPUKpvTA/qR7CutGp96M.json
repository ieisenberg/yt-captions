[
  {
    "start": "0",
    "end": "50000"
  },
  {
    "text": "hello everyone my name is Abbas and Sheila I'm one of the founders of flute",
    "start": "30",
    "end": "6060"
  },
  {
    "text": "sir and with me I have I'm Simon Pearce from sis 11 from Berlin",
    "start": "6060",
    "end": "11360"
  },
  {
    "text": "and atz's Levin we're a managed hosting company from Berlin we've been offering",
    "start": "11360",
    "end": "18990"
  },
  {
    "text": "our customers managed hosting for the last 10 years and up to now it's been a fairly traditional platform we've been",
    "start": "18990",
    "end": "25289"
  },
  {
    "text": "offering virtual Linux containers we have about 4000 of them which the majority are managed with puppet as",
    "start": "25289",
    "end": "31679"
  },
  {
    "text": "configuration management and orchestrated by our own hauling over various Hardware nodes distributed over",
    "start": "31679",
    "end": "39300"
  },
  {
    "text": "a few data centers we also have our own OpenStack cloud which we run for infrastructure as a service and we",
    "start": "39300",
    "end": "45899"
  },
  {
    "text": "basically wanted to extend that portfolio with kubernetes so we were",
    "start": "45899",
    "end": "51149"
  },
  {
    "start": "50000",
    "end": "112000"
  },
  {
    "text": "looking in a way what would be the best way for a medium-sized German hosting provider to run a managed communities",
    "start": "51149",
    "end": "56610"
  },
  {
    "text": "offering of course we're not Google we're not AWS so we needed to find something else and our partner Lutz are",
    "start": "56610",
    "end": "64110"
  },
  {
    "text": "here helped us integrate great installer into our network yeah I'm from the",
    "start": "64110",
    "end": "69479"
  },
  {
    "text": "Bastion I'm Sebastian I'm from Lutzer we are startup from Hamburg and we built a",
    "start": "69479",
    "end": "75090"
  },
  {
    "text": "platform how you can run and manage multiple Cuba needs cluster like a Google container engine in your own",
    "start": "75090",
    "end": "81390"
  },
  {
    "text": "environment ah no mistake on bare metal or on different cloud providers and together was this 11 we built up the",
    "start": "81390",
    "end": "88200"
  },
  {
    "text": "platform for them yeah so we would like to take some time to talk with you about",
    "start": "88200",
    "end": "94290"
  },
  {
    "text": "that today and basically show us how we did that and give you a short live demo of",
    "start": "94290",
    "end": "99390"
  },
  {
    "text": "everything works out as well so you can actually see how that installer runs and how you can basically set up a",
    "start": "99390",
    "end": "105750"
  },
  {
    "text": "communities cluster where the few mouse clicks so as we get started it's okay so",
    "start": "105750",
    "end": "113220"
  },
  {
    "start": "112000",
    "end": "253000"
  },
  {
    "text": "basically we start off what was the challenge for us and also for the looter",
    "start": "113220",
    "end": "120200"
  },
  {
    "text": "basically getting a management interface up and running which would allow us to",
    "start": "120200",
    "end": "125520"
  },
  {
    "text": "maintain and view multiple clusters we didn't want to have to log on to each",
    "start": "125520",
    "end": "132840"
  },
  {
    "text": "individual so to check the update status of the different customer clusters we wanted to",
    "start": "132840",
    "end": "139049"
  },
  {
    "text": "have like a unified web interface where a system engineer can look at and could see the state of the clusters we'll be",
    "start": "139049",
    "end": "145709"
  },
  {
    "text": "able to start an installation for a customer if you didn't want to do himself or - to see basically the",
    "start": "145709",
    "end": "153599"
  },
  {
    "text": "version of kubernetes we're just installed maybe even add or remove a node also a thing that was very",
    "start": "153599",
    "end": "161670"
  },
  {
    "text": "important to us was multi-tenancy which is something which most of the",
    "start": "161670",
    "end": "166889"
  },
  {
    "text": "offerings that we've seen up to today seem to lack they all seem to focus on single projects or on single companies",
    "start": "166889",
    "end": "173639"
  },
  {
    "text": "what we our idea was basically to have this multi-tenancy approach where you could have more than one customer",
    "start": "173639",
    "end": "179220"
  },
  {
    "text": "running and we've also wanted the master",
    "start": "179220",
    "end": "186030"
  },
  {
    "text": "components as a complete managed service so we want to take care of the API",
    "start": "186030",
    "end": "191129"
  },
  {
    "text": "server the queue controller the scheduler and also the etcd we want to",
    "start": "191129",
    "end": "197790"
  },
  {
    "text": "take all that hassle away from the customers so they don't have to deal with those sort of things and give them",
    "start": "197790",
    "end": "202980"
  },
  {
    "text": "the ability to be able to update that this very quickly if they want to and",
    "start": "202980",
    "end": "210299"
  },
  {
    "text": "also an administration interface where you could maybe as a later date change",
    "start": "210299",
    "end": "216209"
  },
  {
    "text": "certificates add users and do various things with the cluster and also offer a",
    "start": "216209",
    "end": "226260"
  },
  {
    "text": "choice of add-ons which could be installed one to be named here would be a CNI so you could choose between for",
    "start": "226260",
    "end": "232139"
  },
  {
    "text": "instance calico kernel flannel so customer would be able to have things",
    "start": "232139",
    "end": "237690"
  },
  {
    "text": "like network policies if you needed it or other people might be more interested in bgp networking so give the customer",
    "start": "237690",
    "end": "244079"
  },
  {
    "text": "the choice and allow him during that installation to choose between the different network interfaces which exist",
    "start": "244079",
    "end": "253609"
  },
  {
    "start": "253000",
    "end": "361000"
  },
  {
    "text": "the Kade 8k desk master is run as a container and it's run in an individual",
    "start": "255300",
    "end": "261180"
  },
  {
    "text": "namespace for the customer which I will show you a detail later on we also have",
    "start": "261180",
    "end": "268530"
  },
  {
    "text": "a single service endpoint in which we maintain which has also been a challenge we have like one IP address which is the",
    "start": "268530",
    "end": "274650"
  },
  {
    "text": "API service and that endpoint is for all of the customers so we have multiple",
    "start": "274650",
    "end": "280290"
  },
  {
    "text": "clusters running behind one service endpoint which also allows us to do a lot of nice things with that as well",
    "start": "280290",
    "end": "287330"
  },
  {
    "text": "and we can also upgrade multiple clusters as well so we are able to view",
    "start": "287330",
    "end": "294000"
  },
  {
    "text": "all of the clusters see them check the upgrade status and maybe upgrade them all at once otherwise you'd be sitting",
    "start": "294000",
    "end": "301020"
  },
  {
    "text": "there you'd have some form of terraform or maybe Anza ball playbooks and you don't need to upgrade every individual",
    "start": "301020",
    "end": "308340"
  },
  {
    "text": "cluster which will take forever to be honest and it would also bring lots of errors with it as well trying to do that",
    "start": "308340",
    "end": "313680"
  },
  {
    "text": "we tried it in the past and it didn't work very well it scales up to about maybe 10 20 clusters but after that you",
    "start": "313680",
    "end": "320130"
  },
  {
    "text": "need so many members of staff to actually do unmanaged all the clusters it just doesn't work out",
    "start": "320130",
    "end": "326660"
  },
  {
    "text": "another thing is user role management which is also very important so you can",
    "start": "326810",
    "end": "332430"
  },
  {
    "text": "have different roles with our back people that are allowed to deploy to maybe different namespaces and also",
    "start": "332430",
    "end": "342780"
  },
  {
    "text": "provide the customers with a unified way to install helm charts and different",
    "start": "342780",
    "end": "348210"
  },
  {
    "text": "things the idea is later on to have like a service catalog where you'll be able to use a monocular to install a various",
    "start": "348210",
    "end": "355770"
  },
  {
    "text": "helm apps and other things from the dashboard most of the existing tours",
    "start": "355770",
    "end": "363870"
  },
  {
    "start": "361000",
    "end": "458000"
  },
  {
    "text": "sorry most of the existing tours focus on a single cluster but not really on",
    "start": "363870",
    "end": "371280"
  },
  {
    "text": "multiple clusters as I said earlier most of the existing solutions don't really",
    "start": "371280",
    "end": "377880"
  },
  {
    "text": "seem to have that as a model the access",
    "start": "377880",
    "end": "383790"
  },
  {
    "text": "to the Kas master is also slightly different because behind that one IP address",
    "start": "383790",
    "end": "389100"
  },
  {
    "text": "we don't just have one Kade as master running there are multiple masters running so we need to find a way to",
    "start": "389100",
    "end": "394980"
  },
  {
    "text": "actually get that API call to the right master and I'll show you how we did that",
    "start": "394980",
    "end": "401370"
  },
  {
    "text": "later on as well there various ways that this can be done and we require within",
    "start": "401370",
    "end": "410130"
  },
  {
    "text": "our Staller a minimum of three VMs because we're running this on top of OpenStack you can basically choose the",
    "start": "410130",
    "end": "416250"
  },
  {
    "text": "flavor do you want similar that you would do when you spin up a traditional VM with a cloud provider you can",
    "start": "416250",
    "end": "423180"
  },
  {
    "text": "basically choose the flavor you keep mixed different flavors but we require that you have a minimum of three VMs so",
    "start": "423180",
    "end": "429000"
  },
  {
    "text": "that you can distribute your pods between the VMS of course you can you can add more anytime you want we can add",
    "start": "429000",
    "end": "435420"
  },
  {
    "text": "Prometheus you can check the utilization of your cluster and you can add new ones",
    "start": "435420",
    "end": "442440"
  },
  {
    "text": "at any time and that can also be automated as well and of course to",
    "start": "442440",
    "end": "449760"
  },
  {
    "text": "accomplish this additional tooling is required one thing maybe a specific proxy to get into the correct cluster",
    "start": "449760",
    "end": "459140"
  },
  {
    "start": "458000",
    "end": "721000"
  },
  {
    "text": "yeah and so when we started to in Drive years ago was customers working on",
    "start": "459560",
    "end": "465120"
  },
  {
    "text": "kubernetes we also Google Google partner and when we were on the blue cloud it was every",
    "start": "465120",
    "end": "470850"
  },
  {
    "text": "time quite easy press a button and you have a cluster and for other customers it was every time at challenge okay we",
    "start": "470850",
    "end": "477120"
  },
  {
    "text": "built it with their tools and then it starts every time the same same way so first we build up a first-class stars",
    "start": "477120",
    "end": "483720"
  },
  {
    "text": "and they ask hey can you help us with updates then they come we also want to have some more clusters can you help us",
    "start": "483720",
    "end": "489540"
  },
  {
    "text": "building up more classes to manage them and yeah we want to have something like self-service and it ends mostly it was",
    "start": "489540",
    "end": "496800"
  },
  {
    "text": "like yeah we want to have something like a Google container engine but on our platform and then we did this a few",
    "start": "496800",
    "end": "502050"
  },
  {
    "text": "times for customers and we're asking ourself can't we do this better can't we build something which feels and works",
    "start": "502050",
    "end": "507570"
  },
  {
    "text": "like probably a Google container engine and the customer can run this and managers in their own environment on",
    "start": "507570",
    "end": "512940"
  },
  {
    "text": "their own platform like old mistake per metal or even on their own cloud provider and so",
    "start": "512940",
    "end": "520000"
  },
  {
    "text": "what we really want to achieve is like providing a self-service for the developers the developers can create and",
    "start": "520000",
    "end": "525610"
  },
  {
    "text": "manage their clusters so a tea can concentrate on operating the infrastructure but the developers can",
    "start": "525610",
    "end": "531220"
  },
  {
    "text": "create clusters can decide on their own when it's time to upgrade my cluster how do I want to size my cluster and",
    "start": "531220",
    "end": "537100"
  },
  {
    "text": "different teams can have different clusters instead of putting everything in one big cluster everyone can decide",
    "start": "537100",
    "end": "543130"
  },
  {
    "text": "ok should I have a bigger cluster or do I want to have smaller clusters also probably building up trust us in your CI",
    "start": "543130",
    "end": "549670"
  },
  {
    "text": "pipeline like we have work drop running you want to test something spin up quickly a cluster do your jobs sawed",
    "start": "549670",
    "end": "556960"
  },
  {
    "text": "away again another challenge was of course updates of a cluster so we really",
    "start": "556960",
    "end": "563200"
  },
  {
    "text": "want that the developers can focusing updating the cluster and it's not a big deal for the operations updating many of",
    "start": "563200",
    "end": "570760"
  },
  {
    "text": "the clusters as Simon said if you are have to five classes it's working ok",
    "start": "570760",
    "end": "576640"
  },
  {
    "text": "with tools but if you go into like 10 50 100 and even more clusters it's getting",
    "start": "576640",
    "end": "583510"
  },
  {
    "text": "quite difficult to update and especially also to provide to your developers different version of clusters so that",
    "start": "583510",
    "end": "589780"
  },
  {
    "text": "you can manage and run those of course we also want to install like add-ons see",
    "start": "589780",
    "end": "597300"
  },
  {
    "text": "CNI add-ons ham charts and the dashboard so that the customer was a developers",
    "start": "597300",
    "end": "603910"
  },
  {
    "text": "can immediately start and don't must think about how do i integrate this how do I need additional or what do I must",
    "start": "603910",
    "end": "610870"
  },
  {
    "text": "install additional to the plain setup and of course we want to have",
    "start": "610870",
    "end": "618040"
  },
  {
    "text": "flexibilities in our cluster so we add we want to add and remove worker notes and the developer should decide when",
    "start": "618040",
    "end": "626470"
  },
  {
    "text": "it's time to add the worker notes we currently also working on like cluster",
    "start": "626470",
    "end": "631780"
  },
  {
    "text": "auto-scaling that in the future we don't want to rely on the cloud provider specific auto scaling we want to have an",
    "start": "631780",
    "end": "637710"
  },
  {
    "text": "integration of the cluster autoscaler so that we can do auto scaling on any",
    "start": "637710",
    "end": "643300"
  },
  {
    "text": "platform and we don't must look into it how is Google AWS or how is OpenStack",
    "start": "643300",
    "end": "649510"
  },
  {
    "text": "doing this we can then doing it anywhere yeah as I said auto-scaling of worker",
    "start": "649510",
    "end": "656470"
  },
  {
    "text": "notes we're currently working on this to get this done of course there is a",
    "start": "656470",
    "end": "662050"
  },
  {
    "text": "question how do I work with external load balancers so we we integrate we",
    "start": "662050",
    "end": "667660"
  },
  {
    "text": "want to integrate the same with networking with the existing tooling our focus is really spinning up all this set",
    "start": "667660",
    "end": "674830"
  },
  {
    "text": "ups and yeah let's a customer choose okay what's the best networking option what load balancers do I have in my own",
    "start": "674830",
    "end": "681780"
  },
  {
    "text": "cloud and how do I can work closely together with cuban eaters of course one",
    "start": "681780",
    "end": "690220"
  },
  {
    "text": "important thing is also automatically backup and recovery from the cuban ITA's",
    "start": "690220",
    "end": "695440"
  },
  {
    "text": "master so that we ensure that your EDD master is every time he'll see and in in",
    "start": "695440",
    "end": "701590"
  },
  {
    "text": "the case that something happens you're one of the node crash or the complete",
    "start": "701590",
    "end": "707890"
  },
  {
    "text": "program is lost that we can recover your EDD and that you don't have manually",
    "start": "707890",
    "end": "713100"
  },
  {
    "text": "interact with it so that it's completely automated and the system is completely",
    "start": "713100",
    "end": "718150"
  },
  {
    "text": "running out of the box and you don't have much to do and what we mainly do is",
    "start": "718150",
    "end": "723850"
  },
  {
    "text": "we come up with the idea what's the best way or how we can run a lot of cuban it",
    "start": "723850",
    "end": "729250"
  },
  {
    "text": "is cluster and we ask ourself can't we run cuban it is on cuban eaters so what",
    "start": "729250",
    "end": "734710"
  },
  {
    "text": "we spin up is we have one management kubernetes cluster and on this cuban it",
    "start": "734710",
    "end": "740020"
  },
  {
    "text": "is cluster we spin up for each cluster in a namespace or the computer component",
    "start": "740020",
    "end": "745800"
  },
  {
    "text": "humanities needs and then we can connect from the outside world like from",
    "start": "745800",
    "end": "751860"
  },
  {
    "text": "OpenStack the worker nodes from the specific cluster so that it's connected and connected to the specific cluster we",
    "start": "751860",
    "end": "759850"
  },
  {
    "text": "only need one dedicated IP address for all of these clusters connected and yeah",
    "start": "759850",
    "end": "765250"
  },
  {
    "text": "heaven SSH tunnel that's a API server can talk to the Twizy nodes and do some",
    "start": "765250",
    "end": "771400"
  },
  {
    "text": "stuff there but that's our main setup what we technically build it's like kubernetes operator which knows how to deploy and",
    "start": "771400",
    "end": "778390"
  },
  {
    "text": "to upgrade queue benitez cluster but in that way that we only need this operator",
    "start": "778390",
    "end": "783460"
  },
  {
    "text": "more or less for the for the start-up and for the upgrade phase after but you could completely remove our",
    "start": "783460",
    "end": "789130"
  },
  {
    "text": "operator out of it the clusters are working and the good thing is because it's running on Cuban eaters when something is failing like when the API",
    "start": "789130",
    "end": "795459"
  },
  {
    "text": "servers crashing it's automatically restarted and updates of the master control plane is for us quite easy we do",
    "start": "795459",
    "end": "801760"
  },
  {
    "text": "a rolling update from Cuban Eaters and we are done so yeah and this we can easily then move",
    "start": "801760",
    "end": "808720"
  },
  {
    "text": "also to different cloud providers and integrating new cloud providers now takes us between like two to ten days",
    "start": "808720",
    "end": "814510"
  },
  {
    "text": "because we only must look into it how we can connect the worker nodes to it and on the worker nodes we only need",
    "start": "814510",
    "end": "820420"
  },
  {
    "text": "like a container runtime we need the couplet we must configure the couplet with a token or of the API server and the URL",
    "start": "820420",
    "end": "827740"
  },
  {
    "text": "of the API server and then we are done and all of the rest we then roll out again with kubernetes",
    "start": "827740",
    "end": "833200"
  },
  {
    "text": "itself so the networking is rolled out with daemon sets and all the rest also",
    "start": "833200",
    "end": "839190"
  },
  {
    "start": "838000",
    "end": "902000"
  },
  {
    "text": "and we saw on the talk before they had the discussion about machine API and",
    "start": "839190",
    "end": "845470"
  },
  {
    "text": "class the API we come up with a similar concept we called it we call it node set",
    "start": "845470",
    "end": "850600"
  },
  {
    "text": "we are also commonly in discussion with the guys how we can combine this both",
    "start": "850600",
    "end": "856089"
  },
  {
    "text": "concepts together because they are from from the concept side quite close together from the technical",
    "start": "856089",
    "end": "862480"
  },
  {
    "text": "implementation sides there are some difference but we want to make it yeah why we won't have an alignment and yeah",
    "start": "862480",
    "end": "869890"
  },
  {
    "text": "in best case get it as close to cube Anita's as possible and the idea is like really when we started we were thinking",
    "start": "869890",
    "end": "876370"
  },
  {
    "text": "ok why can I not manage with kubernetes nodes so we come up with the idea hey we",
    "start": "876370",
    "end": "882040"
  },
  {
    "text": "need something like nodes we need something like a node set like a replica set and then we want to have a node set",
    "start": "882040",
    "end": "887350"
  },
  {
    "text": "controller who every time checks how many node should I start and then it creates a node resource and Xenophon",
    "start": "887350",
    "end": "892779"
  },
  {
    "text": "node controller which talks to the specific cloud provider API and spin up the nodes and then it's configured and",
    "start": "892779",
    "end": "899230"
  },
  {
    "text": "so that we have the complete flexibility",
    "start": "899230",
    "end": "903240"
  },
  {
    "start": "902000",
    "end": "968000"
  },
  {
    "text": "of course we are dealing on the one side with quite a lot of cloud providers but",
    "start": "904350",
    "end": "913180"
  },
  {
    "text": "on the other side also enterprise customers who want to run hybrid setups and their authorization and access",
    "start": "913180",
    "end": "919600"
  },
  {
    "text": "management is every time a challenge so what we support is different identity identity provider",
    "start": "919600",
    "end": "926810"
  },
  {
    "text": "like what we mainly do versus all out or add up you can use Google as logon",
    "start": "926810",
    "end": "933529"
  },
  {
    "text": "possibility use you can use github but you can even provide us your own identity provider and then we can",
    "start": "933529",
    "end": "940129"
  },
  {
    "text": "integrate it or your Active Directory and we can integrate it and you can use this users for the management so what we",
    "start": "940129",
    "end": "947899"
  },
  {
    "text": "want to have is like a seamless management and cluster login so really single sign-on for the users that don't",
    "start": "947899",
    "end": "952970"
  },
  {
    "text": "need additional users on our side and the next step we want to also we support",
    "start": "952970",
    "end": "959420"
  },
  {
    "text": "Eric and network policies inside our clusters but we want to like push it from the outside provider inside to the",
    "start": "959420",
    "end": "965389"
  },
  {
    "text": "cluster this is something where we're currently working on yeah and what would",
    "start": "965389",
    "end": "976009"
  },
  {
    "start": "968000",
    "end": "1060000"
  },
  {
    "text": "you want to F is like we want to provide multiple providers so we want to have the same setup of the or what we have",
    "start": "976009",
    "end": "982100"
  },
  {
    "text": "now is the same setup of the kubernetes cluster master on every provider because",
    "start": "982100",
    "end": "987500"
  },
  {
    "text": "we every time we run queue bonitas we can do this more or less anywhere and",
    "start": "987500",
    "end": "992800"
  },
  {
    "text": "what we only need is like we must deploy a VM we need docker or a container runtime on it and couplet and configures",
    "start": "993339",
    "end": "1000130"
  },
  {
    "text": "a couplet and then we are done so the complex part running and maintaining the cluster we can take it every time and",
    "start": "1000130",
    "end": "1006670"
  },
  {
    "text": "put it to the new cloud provider or to a different provider as long as we have a",
    "start": "1006670",
    "end": "1012130"
  },
  {
    "text": "queue benitez running we are fast and easy to set this up and the good Cygnus",
    "start": "1012130",
    "end": "1020680"
  },
  {
    "text": "is also when you have different setups so in this case like OpenStack and permettre the same team can operate all",
    "start": "1020680",
    "end": "1027699"
  },
  {
    "text": "of them because like the master control plan works I would every time the same so you don't have this challenge oh now",
    "start": "1027699",
    "end": "1033339"
  },
  {
    "text": "I'm on this platform I have complete different tooling or have a different deployment method then on another platform all of the setup is more or",
    "start": "1033339",
    "end": "1040688"
  },
  {
    "text": "less the same like 99% is same there are of course flavors which is different like load balancer storage and how we",
    "start": "1040689",
    "end": "1048548"
  },
  {
    "text": "deploy especially on metal the nodes but like all the communication all the stuff is done the same and",
    "start": "1048549",
    "end": "1054640"
  },
  {
    "text": "it's easy for the team to operate all this clusters and to manage orders okay",
    "start": "1054640",
    "end": "1061500"
  },
  {
    "start": "1060000",
    "end": "1212000"
  },
  {
    "text": "so now we would like to talk a bit about the hybrid setup and the way we set all",
    "start": "1061500",
    "end": "1067660"
  },
  {
    "text": "this up and got it running some of you might think oh this is kind of unusually these guys are taking like bare-metal servers they're installing hypervisors",
    "start": "1067660",
    "end": "1073929"
  },
  {
    "text": "on our OpenStack and all this stuff and on top of that they're putting kubernetes what and on top of that they're putting",
    "start": "1073929",
    "end": "1079660"
  },
  {
    "text": "the kubernetes into communities how does this work and is this a good idea yes it is it's a good idea because we can use",
    "start": "1079660",
    "end": "1085690"
  },
  {
    "text": "existing api's which we already have an open stack it allows us to leverage things like storage as well via the",
    "start": "1085690",
    "end": "1091960"
  },
  {
    "text": "cinder api and use images and also scheduling underneath which we need with",
    "start": "1091960",
    "end": "1097809"
  },
  {
    "text": "an open stack so it also one thing we're working on the moment is our second",
    "start": "1097809",
    "end": "1103240"
  },
  {
    "text": "cloud region it's going to go online I think in January or February and next year so that will then allow us to",
    "start": "1103240",
    "end": "1109450"
  },
  {
    "text": "integrate to cloud regions within the Installer and the customers will be able to use something similar to federate I",
    "start": "1109450",
    "end": "1115780"
  },
  {
    "text": "suppose you'll be able to distribute your worker nodes between the two",
    "start": "1115780",
    "end": "1122140"
  },
  {
    "text": "regions we also have certain customers",
    "start": "1122140",
    "end": "1127210"
  },
  {
    "text": "have very specific demands they don't want to run on a shared platform they",
    "start": "1127210",
    "end": "1132850"
  },
  {
    "text": "say ok OpenStack and hypervisors with shared by different customers is not an",
    "start": "1132850",
    "end": "1138010"
  },
  {
    "text": "option for them so we can also integrate bare-metal servers that we have in our data center a customer may rent three or",
    "start": "1138010",
    "end": "1144850"
  },
  {
    "text": "four bare-metal servers or even a whole rack of servers for his own personal use with his own switching and routing",
    "start": "1144850",
    "end": "1151179"
  },
  {
    "text": "equipment to make sure it's completely isolated from other any other customers",
    "start": "1151179",
    "end": "1156600"
  },
  {
    "text": "we also run two storage zones we work with a storage provider from Berlin Cork",
    "start": "1156600",
    "end": "1161950"
  },
  {
    "text": "whoa boy cool byte and they offer us a storage which we utilize via the cinder API",
    "start": "1161950",
    "end": "1168309"
  },
  {
    "text": "which allows us have two different storage zones in both data centers all of the node type SSDs for the storage so",
    "start": "1168309",
    "end": "1175600"
  },
  {
    "text": "it's very fast as well integration of additional data centers or cloud",
    "start": "1175600",
    "end": "1181000"
  },
  {
    "text": "providers as possible loads have done a lot of work on that for other customers they've already integrated digital ocean",
    "start": "1181000",
    "end": "1187789"
  },
  {
    "text": "ws Google and it would be easy to integrate any further partners that we",
    "start": "1187789",
    "end": "1193039"
  },
  {
    "text": "may had or even maybe on an on-prem solution if the customers got a form of API which we can authenticate and some",
    "start": "1193039",
    "end": "1199999"
  },
  {
    "text": "form of provisioning servers or VMs it can be used so it's fairly easy to",
    "start": "1199999",
    "end": "1206570"
  },
  {
    "text": "extend this setup as well which is great for us as well because it offers a lot of flexibility as well what I'd like to",
    "start": "1206570",
    "end": "1214519"
  },
  {
    "start": "1212000",
    "end": "1549000"
  },
  {
    "text": "show you next is a live demonstration so hopefully fingers crossed is it's gonna work out we're gonna start up a live",
    "start": "1214519",
    "end": "1220669"
  },
  {
    "text": "demonstration on our servers in Berlin so long distance is hope it works out so",
    "start": "1220669",
    "end": "1226879"
  },
  {
    "text": "basically this is the interface at its current state it's a very simple",
    "start": "1226879",
    "end": "1232039"
  },
  {
    "text": "interface we did this deliberately so there's nothing not much of not many menu options here or anything you can",
    "start": "1232039",
    "end": "1239330"
  },
  {
    "text": "basically what you start off with is you upload your SSH key which I've already done here to distribute on all the",
    "start": "1239330",
    "end": "1245840"
  },
  {
    "text": "worker nodes we've basically got the manage cluster and the create cluster and we're gonna try and create a cluster",
    "start": "1245840",
    "end": "1253369"
  },
  {
    "text": "here Oh cube Khan yep and then we",
    "start": "1253369",
    "end": "1261139"
  },
  {
    "text": "continue to the provider so you can see here we have our OpenStack and our bare-metal service here so we're not",
    "start": "1261139",
    "end": "1267529"
  },
  {
    "text": "going to try provision a bare-metal service Akers will probably take too long but what we're gonna try and do is start up a cluster on OpenStack so we",
    "start": "1267529",
    "end": "1275749"
  },
  {
    "text": "select OpenStack as provider we continue to then select the data center at the moment as I said we have one region that",
    "start": "1275749",
    "end": "1281929"
  },
  {
    "text": "we're running all this stuff on from January onwards you'll be able to choose the region you run it or run different",
    "start": "1281929",
    "end": "1287960"
  },
  {
    "text": "worker workloads on different regions so",
    "start": "1287960",
    "end": "1294169"
  },
  {
    "text": "basically here is an option to add my tenant and everything which I'm going to do now so I'm just gonna quickly add in",
    "start": "1294169",
    "end": "1301489"
  },
  {
    "text": "my data at the moment we're running the stuff that we have on Ubuntu let me just",
    "start": "1301489",
    "end": "1309259"
  },
  {
    "text": "grow up my password",
    "start": "1309259",
    "end": "1312249"
  },
  {
    "text": "just copy this yeah so that's basically",
    "start": "1314500",
    "end": "1321440"
  },
  {
    "text": "all that we need to do we'll also add my SSH key sorry",
    "start": "1321440",
    "end": "1327560"
  },
  {
    "text": "pull it down here add my SSH key and that's basically all we do so what we've",
    "start": "1327560",
    "end": "1333560"
  },
  {
    "text": "got here we're using the all the default settings basically I've got my tenant already added I'm going to spin up three",
    "start": "1333560",
    "end": "1341330"
  },
  {
    "text": "machines with Ubuntu 1604 and afterwards hopefully install the cubelet on them",
    "start": "1341330",
    "end": "1346670"
  },
  {
    "text": "and connect them to the master so we can review the settings here what we've",
    "start": "1346670",
    "end": "1351950"
  },
  {
    "text": "created and basically after that will create the cluster and if everything",
    "start": "1351950",
    "end": "1357590"
  },
  {
    "text": "works out we should see some master components coming off so as you can see now on the dashboard we've got these",
    "start": "1357590",
    "end": "1363290"
  },
  {
    "text": "twirling symbols at the top showing us the health of our master components so",
    "start": "1363290",
    "end": "1369350"
  },
  {
    "text": "we're running a cube Annette is one point eight point four here we can also",
    "start": "1369350",
    "end": "1375290"
  },
  {
    "text": "decide which versions we want to provide for our customers so basically we check the versions first and then we're able",
    "start": "1375290",
    "end": "1381650"
  },
  {
    "text": "to to activate them here or we could also allow specific customers only to",
    "start": "1381650",
    "end": "1388130"
  },
  {
    "text": "see specific versions so we can already see we've got the first green button here that should be our etcd so the etcd",
    "start": "1388130",
    "end": "1395210"
  },
  {
    "text": "operator is deployed we have a three node etcd cluster with a persistent",
    "start": "1395210",
    "end": "1401030"
  },
  {
    "text": "volume underneath so the etcd cluster takes snapshots onto that persistent volume which also allows it to be",
    "start": "1401030",
    "end": "1407750"
  },
  {
    "text": "recovered as Sebastian mentioned earlier which is of course a great thing to have because I'm not sure if any one of you",
    "start": "1407750",
    "end": "1413930"
  },
  {
    "text": "have tried to recover an ET CD from a broken state it can be a pain so we",
    "start": "1413930",
    "end": "1419840"
  },
  {
    "text": "should also see an API server coming up at the moment yes we've got a cube controller and a scheduler so we've",
    "start": "1419840",
    "end": "1428450"
  },
  {
    "text": "nearly got all of the master components up once they are up and running we should see the creation of our worker",
    "start": "1428450",
    "end": "1436100"
  },
  {
    "text": "nodes to actually distribute our workload on so we'll just wait for a",
    "start": "1436100",
    "end": "1441350"
  },
  {
    "text": "moment for this to happen and then I can quickly show you in the OpenStack",
    "start": "1441350",
    "end": "1446360"
  },
  {
    "text": "dashboard the games that are created so how many of",
    "start": "1446360",
    "end": "1452960"
  },
  {
    "text": "you if I quickly ask question were running our demonstration or actually running kubernetes in a production",
    "start": "1452960",
    "end": "1458149"
  },
  {
    "text": "environment the moment Oh quite a few people and how many of you have actually got a working C icd pipeline up and",
    "start": "1458149",
    "end": "1465649"
  },
  {
    "text": "running Oh what's a quite a few people's that was a something that was quite interesting because you see lots of talks about CID pipelines at the moment",
    "start": "1465649",
    "end": "1472190"
  },
  {
    "text": "it seems to be an issue at the moment in the community okay so we see our nodes",
    "start": "1472190",
    "end": "1477559"
  },
  {
    "text": "already they are being created let's see if we can see them here on our dashboard",
    "start": "1477559",
    "end": "1483669"
  },
  {
    "text": "hopefully if everything works out all right slug me out I'll just quickly log back in again",
    "start": "1483669",
    "end": "1489850"
  },
  {
    "text": "yep so we have the three VMs that we created with zero minutes so they're",
    "start": "1491200",
    "end": "1496520"
  },
  {
    "text": "just coming up and waiting to be provisioned so the next thing that would",
    "start": "1496520",
    "end": "1502399"
  },
  {
    "text": "happen after a pre provisioned they will get their cubelet the qiblah will start",
    "start": "1502399",
    "end": "1507830"
  },
  {
    "text": "and then they should hopefully if everything works out they should join the master then basically all that we",
    "start": "1507830",
    "end": "1514909"
  },
  {
    "text": "need to do after that is we have a button here which then allows us to download pre-configured cube config for",
    "start": "1514909",
    "end": "1523250"
  },
  {
    "text": "that customer and then you can basically start running so basically as you see from 0 to go kubernetes in about 5",
    "start": "1523250",
    "end": "1532100"
  },
  {
    "text": "minutes which of course is very simple every single developer can set up his own cluster if he needs to",
    "start": "1532100",
    "end": "1537950"
  },
  {
    "text": "or you could share a cluster with other members of staff if he needs to so we",
    "start": "1537950",
    "end": "1543620"
  },
  {
    "text": "should see that coming up shortly yeah",
    "start": "1543620",
    "end": "1550220"
  },
  {
    "text": "I'm what do you see also on the top is currently we run the latest version but it's it's grayed out",
    "start": "1550220",
    "end": "1556100"
  },
  {
    "text": "there's the upgrade button so when there's a new version available the developer can decide ok up press the",
    "start": "1556100",
    "end": "1561260"
  },
  {
    "text": "Update button and then first we'll upgrade the master and later upgrade the nodes and of course the developer can",
    "start": "1561260",
    "end": "1567440"
  },
  {
    "text": "add or remove nodes depending on their requirements so they are completely flexible can you find ok what workloads",
    "start": "1567440",
    "end": "1574370"
  },
  {
    "text": "I do I run when I want to scale up when I want to scale down and yes then a plain vanilla Cuban eaters",
    "start": "1574370",
    "end": "1581630"
  },
  {
    "text": "with dashboard and all the stuff running can use storage classes out-of-the-box",
    "start": "1581630",
    "end": "1587870"
  },
  {
    "text": "from old mistake and it really feels like for the developer like a Google",
    "start": "1587870",
    "end": "1593780"
  },
  {
    "text": "container engine they easily can also move from there into the setup and can",
    "start": "1593780",
    "end": "1599720"
  },
  {
    "text": "work that deploys application there yeah so we see our first worker nodes just come up now so we see we've got our",
    "start": "1599720",
    "end": "1605990"
  },
  {
    "text": "green indicator here so the other one should come up within a few minutes it normally takes about roughly about five",
    "start": "1605990",
    "end": "1612650"
  },
  {
    "text": "minutes for everything to come up so we can basically then download the cube",
    "start": "1612650",
    "end": "1617750"
  },
  {
    "text": "corn fig here if you want to and [Music]",
    "start": "1617750",
    "end": "1624819"
  },
  {
    "text": "oops cute convict",
    "start": "1630320",
    "end": "1635320"
  },
  {
    "text": "now let's see and I would think they wouldn't be ready yet but they should be",
    "start": "1638110",
    "end": "1644110"
  },
  {
    "text": "new you ready yeah so here we can see",
    "start": "1644110",
    "end": "1650049"
  },
  {
    "text": "two of the machines already ready as you can also see here on the side they've already signed up to the master and the",
    "start": "1650049",
    "end": "1655990"
  },
  {
    "text": "others are just about to be registered so we should see them all coming up now",
    "start": "1655990",
    "end": "1661179"
  },
  {
    "text": "yep so we've got the last two aren't quite ready but that will happen in a few seconds yeah so that's basically it from",
    "start": "1661179",
    "end": "1669460"
  },
  {
    "text": "the demonstration side we go back to the presentation",
    "start": "1669460",
    "end": "1674590"
  },
  {
    "text": "yeah one more thing I talked about already our cube node is open source if",
    "start": "1674590",
    "end": "1681519"
  },
  {
    "text": "you're interesting into it we are in discussion with a machine API where we want to integrate additional we're",
    "start": "1681519",
    "end": "1687309"
  },
  {
    "text": "currently working on because what we see from the customer it's one to get like",
    "start": "1687309",
    "end": "1692320"
  },
  {
    "text": "clusters up on the other side we must get work load and on it and we were looking around and also had a discussion",
    "start": "1692320",
    "end": "1698860"
  },
  {
    "text": "with Simon okay what's the best way to do this and play the road was wet Jenkins and other tools and I was saying",
    "start": "1698860",
    "end": "1705970"
  },
  {
    "text": "we every time want to run native on cue Benitez so we were singing okay is why is there not a native tool for",
    "start": "1705970",
    "end": "1712000"
  },
  {
    "text": "communities to run Cuba Cuba neeta's workloads oversea ICD workloads and we",
    "start": "1712000",
    "end": "1717370"
  },
  {
    "text": "come up with an idea building cube C I which is extension to drone CI and which",
    "start": "1717370",
    "end": "1724539"
  },
  {
    "text": "makes the once AI possible to run on cue Benitez so instead of connecting to the docker socket it will in the future",
    "start": "1724539",
    "end": "1732090"
  },
  {
    "text": "spin-ups pots and also I have some plugins already developed for cube City",
    "start": "1732090",
    "end": "1738639"
  },
  {
    "text": "and for him so we want to make a package so that Simon can go to their customers",
    "start": "1738639",
    "end": "1744700"
  },
  {
    "text": "and say hey here's an easy pipeline put this in your git repository and then we get it on our platform and everything",
    "start": "1744700",
    "end": "1751570"
  },
  {
    "text": "works natively we can easily manage this yeah okay so let's come back to our last",
    "start": "1751570",
    "end": "1759010"
  },
  {
    "text": "few slides and yeah thank you",
    "start": "1759010",
    "end": "1764350"
  },
  {
    "start": "1762000",
    "end": "1945000"
  },
  {
    "text": "so basically I want to quickly wrap this up and talk to you about some of the lessons we learned and about the future",
    "start": "1764350",
    "end": "1771700"
  },
  {
    "text": "roadmap where were actually going and some of our targets that we have for 2018 so basically as Sebastian said we",
    "start": "1771700",
    "end": "1781419"
  },
  {
    "text": "need to wrap this thing up with some tooling we the Cade as a service is not enough people need a workshops people",
    "start": "1781419",
    "end": "1788649"
  },
  {
    "text": "need the correct tooling to enable them to be able to deploy their applications",
    "start": "1788649",
    "end": "1793690"
  },
  {
    "text": "most people don't or most developers don't really have this great interest in communities most people have the great",
    "start": "1793690",
    "end": "1799029"
  },
  {
    "text": "interest in their apps which is good they want to be able to deploy them in a standardized way and they don't want to",
    "start": "1799029",
    "end": "1806039"
  },
  {
    "text": "be having to go through the internet or read for ages until they can find out how to do that so we want to allow",
    "start": "1806039",
    "end": "1812350"
  },
  {
    "text": "enable them to do that with an easy way what we did first is we use the same port for every single API request what",
    "start": "1812350",
    "end": "1820360"
  },
  {
    "text": "we did is we were using sni so we were sending HTTP headers to distinguish the",
    "start": "1820360",
    "end": "1825490"
  },
  {
    "text": "different clusters that worked it worked well with like standard tooling but we had quite a few problems to accomplish",
    "start": "1825490",
    "end": "1831279"
  },
  {
    "text": "there for instance things like Prometheus they want to do a service discovery within the cluster and they",
    "start": "1831279",
    "end": "1836860"
  },
  {
    "text": "don't use the hostname they send like a direct request to the IP address so it wasn't accessing the correct cluster and",
    "start": "1836860",
    "end": "1842740"
  },
  {
    "text": "there was also a few other tools that had problems with that so we decided to change this and to give every customer a",
    "start": "1842740",
    "end": "1848740"
  },
  {
    "text": "unique port for his API server but always used the same IP address so that",
    "start": "1848740",
    "end": "1853809"
  },
  {
    "text": "we got that unique service endpoint to that I mentioned at the beginning of the talk yeah one of the things we",
    "start": "1853809",
    "end": "1859419"
  },
  {
    "text": "definitely run into when we were first had our first 15 20 clusters running I",
    "start": "1859419",
    "end": "1864610"
  },
  {
    "text": "think was a severe etcd problem we actually decided that it would be a good idea which it wasn't to",
    "start": "1864610",
    "end": "1871179"
  },
  {
    "text": "limit the resources the etcd can use it crashed on us because we had so much data because we were running",
    "start": "1871179",
    "end": "1877269"
  },
  {
    "text": "kubernetes in these namespaces it created a lot more etcd data than we had",
    "start": "1877269",
    "end": "1882490"
  },
  {
    "text": "previously and it basically crushed the database and we needed to recover from it which took me quite a while take",
    "start": "1882490",
    "end": "1890950"
  },
  {
    "text": "regular etcd snapshots on persistent volumes always make sure that you",
    "start": "1890950",
    "end": "1896269"
  },
  {
    "text": "a decent backup of all those etcd data it is definitely a lifesaver if anything",
    "start": "1896269",
    "end": "1901279"
  },
  {
    "text": "goes wrong do that for every individual cluster but also for the master cluster",
    "start": "1901279",
    "end": "1906320"
  },
  {
    "text": "as well that was definitely also a very important thing that we found that we need it to do and also restrict access",
    "start": "1906320",
    "end": "1914690"
  },
  {
    "text": "to master components may sound weird but you saw this also from AWS and also Google won't allow you anywhere near the",
    "start": "1914690",
    "end": "1921349"
  },
  {
    "text": "etcd it's normally a good idea to keep your customers away from these sort of things I mean give them a button where",
    "start": "1921349",
    "end": "1927440"
  },
  {
    "text": "they can update it but don't allow them to just update to any version because it would break and we had customers which",
    "start": "1927440",
    "end": "1933229"
  },
  {
    "text": "actually decided they would try an alpha version of communities which of course didn't work correctly on our platform so",
    "start": "1933229",
    "end": "1938869"
  },
  {
    "text": "that's why we make sure that we are the people that actually give give out the",
    "start": "1938869",
    "end": "1944779"
  },
  {
    "text": "or hand out the versions which can be installed and last but not least is our",
    "start": "1944779",
    "end": "1950269"
  },
  {
    "start": "1945000",
    "end": "2199000"
  },
  {
    "text": "roadmap one of the things we're working at the moment is improving the",
    "start": "1950269",
    "end": "1955279"
  },
  {
    "text": "cholesterol identification we're working on a role based access control system",
    "start": "1955279",
    "end": "1961219"
  },
  {
    "text": "similar to what AWS was talking to in the opening keynote like I am sounds",
    "start": "1961219",
    "end": "1967579"
  },
  {
    "text": "something interesting something that we're gonna need to later on to make sure that we can restrict developers to",
    "start": "1967579",
    "end": "1973519"
  },
  {
    "text": "certain namespaces and also to certain tasks as well within the cluster and maybe give people read-only access and",
    "start": "1973519",
    "end": "1979429"
  },
  {
    "text": "other things quite a few of our customers need these worker node auto",
    "start": "1979429",
    "end": "1985369"
  },
  {
    "text": "scaling is also a thing I mean due to communities most of you know you have the horizontal pot auto scaling which",
    "start": "1985369",
    "end": "1991009"
  },
  {
    "text": "makes it easy on a CPU load or maybe on HTTP requests to scale the pots but what",
    "start": "1991009",
    "end": "1998599"
  },
  {
    "text": "you actually do when you've reached the capacity of your three worker nodes we need to know this and we need to be able",
    "start": "1998599",
    "end": "2005499"
  },
  {
    "text": "to scale the worker nodes up to a limit so the customer could maybe say okay I want to scale between 3 and 10 worker",
    "start": "2005499",
    "end": "2012070"
  },
  {
    "text": "nodes so that's also something that we're working on at the moment which I think we'll be able to release early",
    "start": "2012070",
    "end": "2017589"
  },
  {
    "text": "next year support for different Linux distributions is also a thing at the",
    "start": "2017589",
    "end": "2024129"
  },
  {
    "text": "moment our cloud is running on Ubuntu and we are running Ubuntu - for the work notes but we had quite a few people that",
    "start": "2024129",
    "end": "2030670"
  },
  {
    "text": "said why don't you support Center ass why don't you support core OS what about all these auto updating features of",
    "start": "2030670",
    "end": "2036940"
  },
  {
    "text": "course we want this we don't want to use Ubuntu so that's also something we're looking into at the moment another thing",
    "start": "2036940",
    "end": "2047320"
  },
  {
    "text": "that we're doing at the moment is also configuring an external load balancer I mean Google they're in a in a happy",
    "start": "2047320",
    "end": "2055600"
  },
  {
    "text": "position that they have a load balancer which is distributed on and announced 150 different points of presence we",
    "start": "2055600",
    "end": "2062020"
  },
  {
    "text": "don't I mean we're a medium-sized service provider we have three or four data centers which we can run on and we",
    "start": "2062020",
    "end": "2067570"
  },
  {
    "text": "would like to use an external load balancer for this so one of the things",
    "start": "2067570",
    "end": "2072669"
  },
  {
    "text": "that can be used as CloudFlare we basically modified and also put it in a recap or request for external DNS it's",
    "start": "2072669",
    "end": "2079780"
  },
  {
    "text": "on the contract repo of communities and that allows us then to monitor ingress",
    "start": "2079780",
    "end": "2085960"
  },
  {
    "text": "resources and automatically update CloudFlare with IP addresses of new",
    "start": "2085960",
    "end": "2091840"
  },
  {
    "text": "worker nodes and new ingress resources so a CloudFlare actively does health checks on the worker nodes and we can",
    "start": "2091840",
    "end": "2099490"
  },
  {
    "text": "also add new ones and get them in the load balancing pool automatically without touching CloudFlare so we just",
    "start": "2099490",
    "end": "2106960"
  },
  {
    "text": "use the CloudFlare api for that and also drone which Sebastian just talked about",
    "start": "2106960",
    "end": "2113890"
  },
  {
    "text": "is we would like a standard way for CI CD something which a new customer may",
    "start": "2113890",
    "end": "2119500"
  },
  {
    "text": "start off with us and he's looking what what can i what can I do how can i deploy there's so many different",
    "start": "2119500",
    "end": "2125230"
  },
  {
    "text": "deployment tools around and we think drone could be a good idea I tried deploying stuff with Jenkins it works",
    "start": "2125230",
    "end": "2132580"
  },
  {
    "text": "but it's complicated and we'd like a unified way so that at the time to",
    "start": "2132580",
    "end": "2137860"
  },
  {
    "text": "market for the customers is very short and it would be easy to transform a setup which is running on conventional",
    "start": "2137860",
    "end": "2144850"
  },
  {
    "text": "VMs into a containerized setup and the",
    "start": "2144850",
    "end": "2151360"
  },
  {
    "text": "last last bullet point is basically automate the upgrade process the out",
    "start": "2151360",
    "end": "2158710"
  },
  {
    "text": "we've already automated the master upgrade process but afterwards you need to add further",
    "start": "2158710",
    "end": "2164600"
  },
  {
    "text": "worker nodes and then drain these worker nodes to get to the new version we would like to completely automate this and",
    "start": "2164600",
    "end": "2170360"
  },
  {
    "text": "take all that pain away from the customers it only takes about 30 minutes to do this but I mean still 30 minutes of your time so does anybody have any",
    "start": "2170360",
    "end": "2181160"
  },
  {
    "text": "questions you would like to ask if you have a few minutes of time yeah haha",
    "start": "2181160",
    "end": "2187100"
  },
  {
    "text": "sorry yeah if you have if you have questions we are still here or otherwise",
    "start": "2187100",
    "end": "2194450"
  },
  {
    "text": "we also have a boost wherever loot Sabu's come by and we can discuss",
    "start": "2194450",
    "end": "2201160"
  }
]
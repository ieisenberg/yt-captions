[
  {
    "text": "alright hello everybody we're gonna go ahead and get started they're supposed to be 600 of you where is everybody it's",
    "start": "770",
    "end": "7319"
  },
  {
    "text": "the last lot of the conference we understand everyone I'm rob some ski I'm a product manager for open shift at Red",
    "start": "7319",
    "end": "13440"
  },
  {
    "text": "Hat and I'm chance ball ski I am the lead software engineer for the metering project at Red Hat so today we're gonna",
    "start": "13440",
    "end": "21060"
  },
  {
    "text": "talk about collecting operational metrics across some really large clusters you know 5,000 10,000 namespaces and go",
    "start": "21060",
    "end": "27630"
  },
  {
    "text": "through some of the use cases for doing that and then we're gonna take a live demo at some of the technology and we'll",
    "start": "27630",
    "end": "34260"
  },
  {
    "text": "show you some reports running from some of these clusters what we're going to talk about today is a component of our",
    "start": "34260",
    "end": "40379"
  },
  {
    "text": "operator framework the metering component of that and I'll explain a little bit about what the operator framework is if you're interested in",
    "start": "40379",
    "end": "47579"
  },
  {
    "text": "demos we're going to do some towards the end so stick around but we're going to kind of explain how we get to some of those demos first so the operator",
    "start": "47579",
    "end": "56250"
  },
  {
    "text": "framework is a set of tools to build operators operators are pieces of",
    "start": "56250",
    "end": "63030"
  },
  {
    "text": "software that have specialized knowledge about how to run something in this case we have an SDK that helps you build",
    "start": "63030",
    "end": "68729"
  },
  {
    "text": "these so you take the operational complexity that makes up your application you embed it in a piece of",
    "start": "68729",
    "end": "73950"
  },
  {
    "text": "software and we have a bunch of tools to help you do that run testing cycles all that type of stuff we also have our",
    "start": "73950",
    "end": "80130"
  },
  {
    "text": "lifecycle manager this helps you run a number of operators on a cluster you know 1 5 10 30 and manage the lifecycle",
    "start": "80130",
    "end": "87030"
  },
  {
    "text": "and upgrades of those then what we have is our operator metering this is what we're gonna spend the bulk of this talk",
    "start": "87030",
    "end": "92549"
  },
  {
    "text": "on and this is all about collecting operational metrics from the Prometheus",
    "start": "92549",
    "end": "98250"
  },
  {
    "text": "stack that we have running in the cluster and then you know turning that into useful reports for humans to do",
    "start": "98250",
    "end": "103320"
  },
  {
    "text": "things with all this is hosted in a vendor neutral github board we'd love for you to check out the code get",
    "start": "103320",
    "end": "109170"
  },
  {
    "text": "involved file bugs all that good stuff and so for metering the way that this",
    "start": "109170",
    "end": "115710"
  },
  {
    "text": "works is we've got a few different things that we're interested in the first is app specific insights these are",
    "start": "115710",
    "end": "121500"
  },
  {
    "text": "you know custom metrics that your operators and the applications that they're running know about anything from",
    "start": "121500",
    "end": "127110"
  },
  {
    "text": "the number of database tables you're running to if you need to do data rebalance operations you might want to track that as",
    "start": "127110",
    "end": "133209"
  },
  {
    "text": "kind of look at node failures and that type of stuff see how those affect each other but also we have this really great",
    "start": "133209",
    "end": "139959"
  },
  {
    "text": "data source on the cluster that's our pre installed Prometheus stack and this already knows about all the pods running",
    "start": "139959",
    "end": "145450"
  },
  {
    "text": "on the cluster it knows what namespaces they're in so it's got a bunch of rich data that we can include kind of out of",
    "start": "145450",
    "end": "150700"
  },
  {
    "text": "the box to help you get a bunch of reports so I want to talk about some of",
    "start": "150700",
    "end": "156010"
  },
  {
    "text": "those use cases and what this is useful for so at the goal for this is really",
    "start": "156010",
    "end": "161680"
  },
  {
    "text": "out of the box you can have chargeback show back this is reporting on resource",
    "start": "161680",
    "end": "167079"
  },
  {
    "text": "usage by a number of different metrics and this really encourages the correct behavior of folks that are using your",
    "start": "167079",
    "end": "172629"
  },
  {
    "text": "cluster if somebody is requesting a gig of ram you want to make sure that they're using that gig because you can't",
    "start": "172629",
    "end": "177969"
  },
  {
    "text": "use that gig and give it to somebody else so we use cluster monitoring like I said so we've already got this really",
    "start": "177969",
    "end": "183400"
  },
  {
    "text": "smart data source so we're not you know tackling this huge problem it's a little bit smaller of a problem and then we",
    "start": "183400",
    "end": "189370"
  },
  {
    "text": "want to make this framework extensible such that you get a report about RAM or CPU capacity or storage capacity and if",
    "start": "189370",
    "end": "196659"
  },
  {
    "text": "you want to further post-process that we want to make that very easy to do so",
    "start": "196659",
    "end": "201930"
  },
  {
    "text": "before we get into it this is kind of our end result this is where we're going to get to this is a CSV file that comes",
    "start": "202169",
    "end": "207310"
  },
  {
    "text": "out of our system and what this is looking at is a number of pods and namespaces across the cluster what nodes",
    "start": "207310",
    "end": "213280"
  },
  {
    "text": "they're scheduled on - exactly how long that the pod was alive and then getting some resource utilization out of it in",
    "start": "213280",
    "end": "219939"
  },
  {
    "text": "this case we're looking at CPU seconds as well as the actual dollar cost of",
    "start": "219939",
    "end": "224979"
  },
  {
    "text": "that when you have a really rich cloud billing API you can actually then start computing these very easily and say this",
    "start": "224979",
    "end": "230859"
  },
  {
    "text": "pod cost a dollar and 20 cents to run that type of thing so we're gonna talk about how we get there and so I",
    "start": "230859",
    "end": "237669"
  },
  {
    "text": "mentioned we have these out-of-the-box reports this is because these are the things that we can slice and dice based on our cluster monitoring and so it's",
    "start": "237669",
    "end": "243909"
  },
  {
    "text": "the things you can think about you know kubernetes needs to track for doing scheduling CPU memory and storage and",
    "start": "243909",
    "end": "249699"
  },
  {
    "text": "then we can do either the request that you have in like your pod spec the actual utilization as reported when that",
    "start": "249699",
    "end": "255699"
  },
  {
    "text": "pot is running and then the percentage starting to look at either total capacity and some ratios between some of",
    "start": "255699",
    "end": "261760"
  },
  {
    "text": "these and then we can do that on a pod level and namespace level node level and then the entire cluster",
    "start": "261760",
    "end": "267810"
  },
  {
    "text": "itself and you can picture you know we've got reports for all of these and you can mix and match everything that you want to do so what this looks like",
    "start": "267810",
    "end": "276060"
  },
  {
    "text": "under the hood is this is looking at two clusters that have this installed I break out Amazon because we can do some",
    "start": "276060",
    "end": "282480"
  },
  {
    "text": "dollar correlation there so that flow is a little bit different but you've got a bunch of clusters running they have",
    "start": "282480",
    "end": "288210"
  },
  {
    "text": "namespaces there's pods in those namespaces and we have metering software running that's looking at all that and tracking it continuously on Amazon we",
    "start": "288210",
    "end": "296010"
  },
  {
    "text": "can actually hit the Amazon billing API and say this pod was on this node what type of instance is that how much does it cost what is the percentage of the",
    "start": "296010",
    "end": "302610"
  },
  {
    "text": "pot it is being used or the node is being used by that pod and can get to an actual dollar amount so we're doing this",
    "start": "302610",
    "end": "309660"
  },
  {
    "text": "on Amazon today we hope to extend this to any rich billing API and there's some really interesting use cases for doing",
    "start": "309660",
    "end": "315090"
  },
  {
    "text": "this on bare metal as well and then we want to output these reports to stable storage we're using Prometheus as our",
    "start": "315090",
    "end": "321090"
  },
  {
    "text": "main data source and that doesn't stick around forever you have to store it Ram you don't need to be doing that for",
    "start": "321090",
    "end": "326280"
  },
  {
    "text": "months and months at a time and so we want to output these reports at a scheduled interval to persistent storage",
    "start": "326280",
    "end": "332190"
  },
  {
    "text": "whether that's a PV on disk you can go to like at s3 bucket those types of things whatever you want to consume this",
    "start": "332190",
    "end": "338160"
  },
  {
    "text": "in your archival data warehouse so when we talk through some concrete use cases",
    "start": "338160",
    "end": "344280"
  },
  {
    "text": "that are pretty interesting this is our first one which is your dis on Amazon and you want to do show back to teams",
    "start": "344280",
    "end": "349979"
  },
  {
    "text": "that are using the cluster and let's just say every team you know has the standard three projects or namespaces on",
    "start": "349979",
    "end": "355260"
  },
  {
    "text": "the cluster dead stage prod and then each team just has a blanket budget",
    "start": "355260",
    "end": "360840"
  },
  {
    "text": "let's say $10,000 how do you start computing this well are metering software you can use one of our default",
    "start": "360840",
    "end": "367080"
  },
  {
    "text": "reports for looking at plot dollars like we just showed on the previous screen and then you can either just dump that",
    "start": "367080",
    "end": "373050"
  },
  {
    "text": "into Excel and start sorting columns start adding things up you could further post-process that process that into a bi",
    "start": "373050",
    "end": "379560"
  },
  {
    "text": "tool of choice there are a number of these out there you could even start piping this into a graph honest our",
    "start": "379560",
    "end": "384750"
  },
  {
    "text": "building dashboards or even you know starts sitting off like slack web hooks or anything you wanted to do so these",
    "start": "384750",
    "end": "391440"
  },
  {
    "text": "yellow boxes and all these diagrams are going to be any further post-processing that you want to do start comparing",
    "start": "391440",
    "end": "396510"
  },
  {
    "text": "reports together take out data that your company knows about or cares about and start making this custom",
    "start": "396510",
    "end": "402740"
  },
  {
    "text": "to your organization so a really popular one is just shame underutilization",
    "start": "402740",
    "end": "408490"
  },
  {
    "text": "everybody kind of wants to do the right thing when it comes down to it but they just need to know that they're being",
    "start": "408490",
    "end": "413840"
  },
  {
    "text": "kind of a bad actor on the system so let's say we're we have a cluster or set of clusters that are used by 15 teams",
    "start": "413840",
    "end": "420550"
  },
  {
    "text": "and so we just want to say hey look our threshold is if you request twice as much as you're actually using you",
    "start": "420550",
    "end": "427160"
  },
  {
    "text": "shouldn't do that we're gonna just gonna let you know so you can compare two of our reports and look at the ratio of",
    "start": "427160",
    "end": "432590"
  },
  {
    "text": "that and you know have a piece of software that's doing some math you could do this by hand you could pipe it",
    "start": "432590",
    "end": "438050"
  },
  {
    "text": "into something it says anything above 2x let's go send off a slack web hook into that team's channel let's go send people",
    "start": "438050",
    "end": "444229"
  },
  {
    "text": "emails let's put them on like a leader board in this case leading is not good so you can do anything and what you want",
    "start": "444229",
    "end": "449810"
  },
  {
    "text": "to do here is incentivize the correct behavior you're just wasting company resources and then here's a use case for",
    "start": "449810",
    "end": "458660"
  },
  {
    "text": "bare metal and let's say we've got a few different clusters on bare metal and you want to start looking at the usage",
    "start": "458660",
    "end": "464570"
  },
  {
    "text": "across both of these clusters for a single team and to also do some things like you know answer the question how",
    "start": "464570",
    "end": "470630"
  },
  {
    "text": "much RAM are we using but you can also go a little bit further and start saying well actually we know how much that RAM",
    "start": "470630",
    "end": "477050"
  },
  {
    "text": "cost because we you know spend X thousands of dollars per machine we also pay for maybe a bundle of bandwidth or",
    "start": "477050",
    "end": "484070"
  },
  {
    "text": "we had this big nazar√© that we use for storage and we want to distribute that amongst all those teams you can start",
    "start": "484070",
    "end": "490639"
  },
  {
    "text": "doing all this logic whatever kind of fits the needs of your organization and then show it back to those teams you",
    "start": "490639",
    "end": "496820"
  },
  {
    "text": "could start shaming them on the storage cost if this thing costs you a hundred grand you know it matters so these are",
    "start": "496820",
    "end": "502099"
  },
  {
    "text": "the types of things that you can plug in with this system and so where this is",
    "start": "502099",
    "end": "507320"
  },
  {
    "text": "really really useful is for capacity planning so set aside it's shaming people for a second and we can use this",
    "start": "507320",
    "end": "515029"
  },
  {
    "text": "knowledge about the cluster to know where the cluster is going so you know you've got real-time utilization you can",
    "start": "515029",
    "end": "520760"
  },
  {
    "text": "start turning that over time you can see where this is going there's a number of things you can do here the interesting",
    "start": "520760",
    "end": "526250"
  },
  {
    "text": "use case for this is what we're going to talk about for the rest of the talk is this environment called open shift online",
    "start": "526250",
    "end": "531710"
  },
  {
    "text": "these are these really really big highly multi-tenant clusters that OpenShift runs and we do these are unreal",
    "start": "531710",
    "end": "537890"
  },
  {
    "text": "workloads so you can sign up with an email address and get two gigs of ram or a gig of ram and go to town running real",
    "start": "537890",
    "end": "543170"
  },
  {
    "text": "docker containers and we use these for scale testing for OpenShift and so they're super highly multi-tenant",
    "start": "543170",
    "end": "548630"
  },
  {
    "text": "you know we can fit 5,000 10,000 namespaces on these clusters and they're really unique environments to start",
    "start": "548630",
    "end": "554000"
  },
  {
    "text": "testing out some of this software and so I've talked a lot about these built-in",
    "start": "554000",
    "end": "560450"
  },
  {
    "text": "reports but as I said in the beginning we want to do this with custom metrics all the things that make your",
    "start": "560450",
    "end": "565760"
  },
  {
    "text": "applications tick the things that are really really important to them you also might want to meet her on those you even",
    "start": "565760",
    "end": "570860"
  },
  {
    "text": "just doing capacity planning but you might want to do things like telemetry license enforcement if you say built an",
    "start": "570860",
    "end": "577430"
  },
  {
    "text": "operator that is commercial software and you want to distribute that to all of your customers you need to know if you",
    "start": "577430",
    "end": "583070"
  },
  {
    "text": "license per core per database table per gigs of RAM per gigs of storage whatever",
    "start": "583070",
    "end": "588170"
  },
  {
    "text": "it is you need a meter that and collect it so this can form the basis of usage based billing and we do kind of a",
    "start": "588170",
    "end": "594530"
  },
  {
    "text": "variety of all of these inside of Red Hat as well all right thanks Rob so now",
    "start": "594530",
    "end": "602240"
  },
  {
    "text": "that we've actually gone over some of the use cases we had mine when developing metering and some of the things that we're trying to solve is it",
    "start": "602240",
    "end": "608150"
  },
  {
    "text": "let's go a little bit more in tips about how we actually achieve this what technologies we've chosen why and also",
    "start": "608150",
    "end": "614480"
  },
  {
    "text": "some of the challenges we have so one of the most important pieces of our stack",
    "start": "614480",
    "end": "620630"
  },
  {
    "text": "is our query engine we're using a database called presto which was written by Facebook they market it as a",
    "start": "620630",
    "end": "627980"
  },
  {
    "text": "distributed sequel engine that is designed for interactive processing and particularly for analytics this is super",
    "start": "627980",
    "end": "634310"
  },
  {
    "text": "useful for us because we're really just trying to get up to a place where people",
    "start": "634310",
    "end": "640160"
  },
  {
    "text": "can really interact with our operators and our reports without having to you know wait you know until the end of the",
    "start": "640160",
    "end": "645980"
  },
  {
    "text": "day or you know like typical batch jobs run maybe once per day or something or even less we'd really like to be able to",
    "start": "645980",
    "end": "652250"
  },
  {
    "text": "enable people is to actually iterate on these rapidly make changes customize things potentially just use the things",
    "start": "652250",
    "end": "657410"
  },
  {
    "text": "out of the box as well but we want a lot of people in this cluster being able to interact with the system the other interesting thing is that",
    "start": "657410",
    "end": "663530"
  },
  {
    "text": "presto actually doesn't really store any data it's not traditional like a traditional database that actually",
    "start": "663530",
    "end": "669230"
  },
  {
    "text": "puts everything on disk and teep just treats it like a bunch of files it's actually designed to be more of a maybe",
    "start": "669230",
    "end": "677420"
  },
  {
    "text": "a proxy in some ways what it does is it's got this concept of connectors which allow presto to actually connect",
    "start": "677420",
    "end": "682880"
  },
  {
    "text": "to other underlying databases so what this means is you can effectively join",
    "start": "682880",
    "end": "688430"
  },
  {
    "text": "database tables from many different database technologies so you can have it connect to hive which I'll go into in a",
    "start": "688430",
    "end": "694310"
  },
  {
    "text": "second you can have it connect Presta or Postgres equal my sequel Cassandra MongoDB and you can have it join tables",
    "start": "694310",
    "end": "701420"
  },
  {
    "text": "or documents across these different sources into a single and through a single interface just using regular",
    "start": "701420",
    "end": "706460"
  },
  {
    "text": "sequel which is pretty powerful the other component is Apache hive Apache",
    "start": "706460",
    "end": "712370"
  },
  {
    "text": "hive is a also a sequel engine designed for sequel on Hadoop we leverage this",
    "start": "712370",
    "end": "718970"
  },
  {
    "text": "because it allows us to actually do storage and compute separate we can actually have storage done entirely in",
    "start": "718970",
    "end": "725450"
  },
  {
    "text": "s3 or HDFS or a local TV with read/write mini semantics and at the end of the day",
    "start": "725450",
    "end": "732380"
  },
  {
    "text": "Presto's interacting through hive to actually find where the data is and then it's actually interacting with the underlying data wherever it lives we",
    "start": "732380",
    "end": "742070"
  },
  {
    "text": "also have a few operators so the first main operator is the reporting operator the reporting operator is pretty much",
    "start": "742070",
    "end": "749720"
  },
  {
    "text": "what ties everything together it is what talks to presto it's what talks to hive it's what talks to a Prometheus and the",
    "start": "749720",
    "end": "757640"
  },
  {
    "text": "various cloud API is to actually tie everything together in reality what it's actually doing what that means is it's",
    "start": "757640",
    "end": "764000"
  },
  {
    "text": "taking a Prometheus query executing against Prometheus and then storing those metrics into presto at the same",
    "start": "764000",
    "end": "771680"
  },
  {
    "text": "time it's running these other sequel queries to actually run reports and produce the kind of actual information",
    "start": "771680",
    "end": "777740"
  },
  {
    "text": "that you want to see which might be what is the total capacity of my cluster for this duration of time or maybe what is",
    "start": "777740",
    "end": "785510"
  },
  {
    "text": "the percentage of the utilization in that style the other piece is the metering operator the metering operator",
    "start": "785510",
    "end": "791540"
  },
  {
    "text": "is really what ties the different components together from a deployment and configuration and it's",
    "start": "791540",
    "end": "797230"
  },
  {
    "text": "kind of point of view it's what handles the lifecycle so you basically say well",
    "start": "797230",
    "end": "803050"
  },
  {
    "text": "first you installed a metering operator typically through olam or some scripts and then at the input side you're going",
    "start": "803050",
    "end": "811480"
  },
  {
    "text": "to be creating a metering resource a custom CRT and metering resource has spec just like everything else it's kind",
    "start": "811480",
    "end": "817870"
  },
  {
    "text": "of like a deployment and when you fill it out it will actually output all these other components as deployments staple",
    "start": "817870",
    "end": "823750"
  },
  {
    "text": "sets secrets and services for presto hive reporting operator and even",
    "start": "823750",
    "end": "829030"
  },
  {
    "text": "optionally HDFS if you don't have object storage for available so I want to talk",
    "start": "829030",
    "end": "835090"
  },
  {
    "text": "a little bit about why we chose some of these components as you might be wondering we've made some interesting",
    "start": "835090",
    "end": "840580"
  },
  {
    "text": "choices about using things like hive or presto as you might imagine why not use something like Postgres or why not one",
    "start": "840580",
    "end": "848290"
  },
  {
    "text": "of the main things is that we want to integrate well with existing systems not necessarily have to fully replace other",
    "start": "848290",
    "end": "853420"
  },
  {
    "text": "systems that are good at what they already do so one of the biggest pieces that we want to work well with prometheus Prometheus is really good for",
    "start": "853420",
    "end": "860080"
  },
  {
    "text": "monitoring collecting metrics doing queries against that information so we're taking full advantage of",
    "start": "860080",
    "end": "865840"
  },
  {
    "text": "Prometheus as our actual part that is responsible for figuring out what's happening on the cluster and we're using",
    "start": "865840",
    "end": "871090"
  },
  {
    "text": "it as a data source to actually run queries against the other piece is that we want to make sure that this works",
    "start": "871090",
    "end": "876700"
  },
  {
    "text": "well on like bare metal environments in any really any kubernetes environment which means it can't be a SAS it can't",
    "start": "876700",
    "end": "882520"
  },
  {
    "text": "rely on entirely rely on cloud api's I mean you can use s3 as an optional piece but it's not required so that was a key",
    "start": "882520",
    "end": "889750"
  },
  {
    "text": "piece related to that though is that we chose hive in particular along with",
    "start": "889750",
    "end": "894880"
  },
  {
    "text": "presto because it means that we don't necessarily have to worry about the storage piece there's a lot of storage",
    "start": "894880",
    "end": "899920"
  },
  {
    "text": "technologies out there a lot of the current data relational databases around are designed to scale horizontally",
    "start": "899920",
    "end": "905790"
  },
  {
    "text": "necessarily or if they are if there's trade-offs that you have to make so this allows us to actually have storage",
    "start": "905790",
    "end": "911740"
  },
  {
    "text": "either outside of the cluster inside of the cluster leverage whatever you really want to use and then it can do all the",
    "start": "911740",
    "end": "916990"
  },
  {
    "text": "compute inside the cluster and as I mentioned before Prest is really unique",
    "start": "916990",
    "end": "922510"
  },
  {
    "text": "in that you can just really work with a pre-existing data there's not a import phase necessarily I'll get more into",
    "start": "922510",
    "end": "928060"
  },
  {
    "text": "that in a second but what that really means is it's basically when you execute a sequel query it's not like going to just",
    "start": "928060",
    "end": "935710"
  },
  {
    "text": "download everything all at once it's gonna determine what that query needs to talk to like actually look at maybe in",
    "start": "935710",
    "end": "941260"
  },
  {
    "text": "your s3 bucket or not and it's going to basically on-demand pull down the things that it needs for that query so now that",
    "start": "941260",
    "end": "949840"
  },
  {
    "text": "we've actually got a little bit of a better idea on how these components interact let's talk a little bit about what the data flow looks like when it",
    "start": "949840",
    "end": "955990"
  },
  {
    "text": "comes to metering so the primary component that's doing most of this is a reporting operator it's going to be",
    "start": "955990",
    "end": "961600"
  },
  {
    "text": "talking to Prometheus performing Prometheus queries inserting those that by data into presto and then presto is",
    "start": "961600",
    "end": "968200"
  },
  {
    "text": "going to be using hive to actually store that in something like s3 or HDFS or a local TV where it can be mounted at on",
    "start": "968200",
    "end": "974530"
  },
  {
    "text": "multiple pods at the same time it's calculating reports so when you create a",
    "start": "974530",
    "end": "980530"
  },
  {
    "text": "report object it's typically with a schedule something like an hourly schedule a daily schedule or longer and",
    "start": "980530",
    "end": "986290"
  },
  {
    "text": "in the background it's running against the schedule and it's calculating running the sequel queries against presto to actually calculate the results",
    "start": "986290",
    "end": "992770"
  },
  {
    "text": "and then also storing them through hive and something like HDFS or s3 so I want",
    "start": "992770",
    "end": "1001830"
  },
  {
    "text": "to give you a bit of a better idea what this actually looks like from a user point of view so right here we have a reports er the report is going to be",
    "start": "1001830",
    "end": "1008130"
  },
  {
    "text": "using what's called our report generation query you can see this referenced and the generation query",
    "start": "1008130",
    "end": "1013260"
  },
  {
    "text": "field here that query I'll show you in a second but then today you don't really have to",
    "start": "1013260",
    "end": "1019170"
  },
  {
    "text": "do a whole lot to use everything that's built into these existing reports are really easy to create you just say what",
    "start": "1019170",
    "end": "1024959"
  },
  {
    "text": "where you want you set scheduled and create it so here's an example report",
    "start": "1024959",
    "end": "1030480"
  },
  {
    "text": "query it's got some things emitted but the main things you have to know is it's going to contain a list of columns so it",
    "start": "1030480",
    "end": "1035579"
  },
  {
    "text": "knows what the date of the actual output is going to look like and so I can validate things but it's got effectively",
    "start": "1035579",
    "end": "1041400"
  },
  {
    "text": "just a giant sequel query in there using go templates as a way to provide extension mechanisms kind of like a",
    "start": "1041400",
    "end": "1047760"
  },
  {
    "text": "macro system that allows the query to be slightly more flexible depending on what user inputs are being provided to the",
    "start": "1047760",
    "end": "1053640"
  },
  {
    "text": "report and things like that which I'll show you also in the demo",
    "start": "1053640",
    "end": "1058100"
  },
  {
    "text": "all right so now I want to talk about actually what you guys all came here for",
    "start": "1059470",
    "end": "1065960"
  },
  {
    "text": "which is how we use metering on open shift line which are these really large clusters so one of the very key things",
    "start": "1065960",
    "end": "1076310"
  },
  {
    "text": "that we talked about earlier in the talk was capacity planning OpenShift online as Rob said anybody with an email",
    "start": "1076310",
    "end": "1082640"
  },
  {
    "text": "address can sign up no credit card no payment details nothing you want access you can get it it's really designed for",
    "start": "1082640",
    "end": "1090380"
  },
  {
    "text": "kind of smaller apps we're not going to give you a huge amount of resources by",
    "start": "1090380",
    "end": "1095900"
  },
  {
    "text": "default we give you about one gigabyte of memory and two CPUs but the way you actually get that is you sign up and",
    "start": "1095900",
    "end": "1101570"
  },
  {
    "text": "then there's somewhat of a queue these clusters are kind of a fixed capacity because we're not caught charging you",
    "start": "1101570",
    "end": "1107960"
  },
  {
    "text": "for it we can't just scale this out with infinite nodes that cost money we're not going to just spend endless amounts of",
    "start": "1107960",
    "end": "1113630"
  },
  {
    "text": "money for people to run free apps like Bitcoin miners so the way this works is we gate by capacity if there's no",
    "start": "1113630",
    "end": "1119990"
  },
  {
    "text": "capacity you have to wait until there is and so all actually understanding what is being used what's not being used is",
    "start": "1119990",
    "end": "1126470"
  },
  {
    "text": "extremely important because we want to make sure people can have access to these clusters so one thing that we did",
    "start": "1126470",
    "end": "1132890"
  },
  {
    "text": "to actually solve some of these problems are we have teams that wrote a pod D scheduler which is basically designed to",
    "start": "1132890",
    "end": "1140300"
  },
  {
    "text": "delete pods so that the cluster can be rebalanced in a more efficient way kubernetes doesn't have that by default",
    "start": "1140300",
    "end": "1145940"
  },
  {
    "text": "so we need a way to actually make sure the pods are running on well size nodes or in a bin that actually fits better",
    "start": "1145940",
    "end": "1153230"
  },
  {
    "text": "for it another piece that we have is we have a component which is responsible for removing inactive users who haven't",
    "start": "1153230",
    "end": "1159110"
  },
  {
    "text": "actually used the name space or the quota we've given to them after a period of time of inactivity and as I mentioned",
    "start": "1159110",
    "end": "1166160"
  },
  {
    "text": "before there's a default quota of a single gigabyte of memory and two cores",
    "start": "1166160",
    "end": "1172030"
  },
  {
    "text": "so what did we find well one of the more interesting things",
    "start": "1172030",
    "end": "1177170"
  },
  {
    "text": "that we found is that given the default quota of 1k byte of memory and 2 cores",
    "start": "1177170",
    "end": "1184040"
  },
  {
    "text": "pretty much nobody actually sets their own resource limits or quotas so that means we're going to be giving them the",
    "start": "1184040",
    "end": "1190160"
  },
  {
    "text": "default that we set which is 50% of their quit and in reality we found that the top",
    "start": "1190160",
    "end": "1195320"
  },
  {
    "text": "1,000 namespaces don't do anything with their quotas they just leave it blank which means they get half of their quota",
    "start": "1195320",
    "end": "1201380"
  },
  {
    "text": "by default and at the end of the day we can basically come to the conclusion that most people aren't making customizations and more often than not",
    "start": "1201380",
    "end": "1208360"
  },
  {
    "text": "we can actually see that our cluster being underutilized by these these users and and we could also then maybe go to",
    "start": "1208360",
    "end": "1216080"
  },
  {
    "text": "the conclusion that we could probably oversubscribe this cluster since the average person is not actually using everything we're giving them on the same",
    "start": "1216080",
    "end": "1225080"
  },
  {
    "text": "note we looked at the people are using the cluster what we found was people who",
    "start": "1225080",
    "end": "1231409"
  },
  {
    "text": "are using the cluster which are apps that have real usage not like idle say I",
    "start": "1231409",
    "end": "1237980"
  },
  {
    "text": "have 500 megabytes of RAM and I only use one but actually are using some percentage of their memory or CPU and in",
    "start": "1237980",
    "end": "1245530"
  },
  {
    "text": "practice most people are using around 85% of their limits for something like memory and a little bit less for CPU is",
    "start": "1245530",
    "end": "1253100"
  },
  {
    "text": "in full spike here so in this case this is a graph that we took from the data we produce and as you can see most usage",
    "start": "1253100",
    "end": "1260870"
  },
  {
    "text": "for this period of about I think it's two hours or more it's showing that on average people are using about 85% of",
    "start": "1260870",
    "end": "1267409"
  },
  {
    "text": "their quotas so what this tells us is that it's pretty well dialed in if they're using one or like always at one",
    "start": "1267409",
    "end": "1274159"
  },
  {
    "text": "that would mean they're always hitting their quotas and if it was something closer to 50% like our defaults it means they're not really using all of it so",
    "start": "1274159",
    "end": "1280460"
  },
  {
    "text": "most of our most active users are getting a good usage but they're not also hitting the quota limits what you",
    "start": "1280460",
    "end": "1285500"
  },
  {
    "text": "might expect so what are the some of the problems we encountered it's a really",
    "start": "1285500",
    "end": "1291950"
  },
  {
    "text": "interesting question one of the biggest pieces that was difficult for us was actually ingesting this data from each",
    "start": "1291950",
    "end": "1298490"
  },
  {
    "text": "this is really good at this it's really it's got a good design for this and it's basically polling periodically all the",
    "start": "1298490",
    "end": "1304220"
  },
  {
    "text": "data that's are all the metrics and points in the cluster we followed a very similar model with the reporting",
    "start": "1304220",
    "end": "1309950"
  },
  {
    "text": "operator right now there isn't a good way for presto to actually natively make these queries for us so what we had to",
    "start": "1309950",
    "end": "1316250"
  },
  {
    "text": "do is we actually did have to import data which is turning out to be about as big of a problem as we thought it might",
    "start": "1316250",
    "end": "1321440"
  },
  {
    "text": "be so at the end of the day one of the problems we encounter is that importing this metrics gets back after a while just because of the sheer",
    "start": "1321440",
    "end": "1327650"
  },
  {
    "text": "amount of volume part of that's related to the high metric resolution right now we collect at about a 60 second round",
    "start": "1327650",
    "end": "1333410"
  },
  {
    "text": "solution for these clusters which might be a bit a bit of a low resolution for us or high resolution rather and it",
    "start": "1333410",
    "end": "1340700"
  },
  {
    "text": "actually causes a really huge growth in storage requirements again we're not necessarily building on top of a time",
    "start": "1340700",
    "end": "1347510"
  },
  {
    "text": "series data base here so some of those efficiencies we gain from Prometheus are lost when we actually import the data so",
    "start": "1347510",
    "end": "1353750"
  },
  {
    "text": "longer-term we're hoping to actually leverage Prometheus more by hopefully actually having presto make two queries",
    "start": "1353750",
    "end": "1358880"
  },
  {
    "text": "against Prometheus directly rather than importing the data the other issue we",
    "start": "1358880",
    "end": "1364190"
  },
  {
    "text": "encountered was depending on the time of the day or what's going on in the cluster of the Prometheus instance isn't",
    "start": "1364190",
    "end": "1369260"
  },
  {
    "text": "necessarily always going to be able to handle these larger queries that we want to make and what's nice about making",
    "start": "1369260",
    "end": "1374660"
  },
  {
    "text": "large queries is we can get a lot of data at once but also potentially import more data at once rather than small",
    "start": "1374660",
    "end": "1380570"
  },
  {
    "text": "making smaller amounts of queries so it affects our throughput as well and then",
    "start": "1380570",
    "end": "1386150"
  },
  {
    "text": "one of the last things that we've kind of hit was when we get these reports they have everything we want but",
    "start": "1386150",
    "end": "1392690"
  },
  {
    "text": "sometimes that's too much information with 5,000 namespaces you can imagine with an hour report that runs on the",
    "start": "1392690",
    "end": "1399770"
  },
  {
    "text": "hour 5,000 named stasis times 24 hours you get a hundred and twenty thousand rows for just a day's worth of data in",
    "start": "1399770",
    "end": "1406250"
  },
  {
    "text": "the CSV file and that can be come a little bit less manageable so we're looking at ways to fix that by probably",
    "start": "1406250",
    "end": "1412460"
  },
  {
    "text": "making our report support more inputs to do things like filtering by default get the top in namespaces maybe instead of",
    "start": "1412460",
    "end": "1418940"
  },
  {
    "text": "everything that said we also had some successes we found that our Prometheus",
    "start": "1418940",
    "end": "1426530"
  },
  {
    "text": "stack actually is going way beyond some of the typical recommended scaling",
    "start": "1426530",
    "end": "1432560"
  },
  {
    "text": "values that even we document for Red Hat on openshift in practice we have much",
    "start": "1432560",
    "end": "1437810"
  },
  {
    "text": "much more than 7200 pods on these clusters with a cluster of 5,000 to 8,000 namespaces one to two pods per",
    "start": "1437810",
    "end": "1445100"
  },
  {
    "text": "namespace and you're definitely going over that amount the number of nodes is about the same but maybe a little bit",
    "start": "1445100",
    "end": "1450470"
  },
  {
    "text": "higher especially with Spector and the lack of compute that we have available now in cloud and the storage departments",
    "start": "1450470",
    "end": "1457100"
  },
  {
    "text": "are also pretty high not not that much higher than this when it came to metering metering actually",
    "start": "1457100",
    "end": "1463350"
  },
  {
    "text": "did provide us value we were actually able to run these reports on these clusters some tuning and it worked",
    "start": "1463350",
    "end": "1470309"
  },
  {
    "text": "really well with Prometheus at the end despite some of the issues I mentioned before all right so next I want to",
    "start": "1470309",
    "end": "1477929"
  },
  {
    "text": "actually show you guys what this looks like to interact with a real cluster in this demo I have a test cluster setup",
    "start": "1477929",
    "end": "1484200"
  },
  {
    "text": "that's got roughly 2,000 mm spaces it turns out there costs a lot of money to run on g-cloud a 5,000 namesakes cluster",
    "start": "1484200",
    "end": "1490380"
  },
  {
    "text": "so I hope you still trust me when it comes to 5,000 namespaces but here we go",
    "start": "1490380",
    "end": "1497659"
  },
  {
    "text": "so the first thing I want to show you is some of the reports that we've created out of the box in this list we have a",
    "start": "1500240",
    "end": "1508890"
  },
  {
    "text": "number of hourly reports yes I can so",
    "start": "1508890",
    "end": "1514799"
  },
  {
    "text": "now I'm gonna have a bunch of terminals of slightly how's that",
    "start": "1514799",
    "end": "1524000"
  },
  {
    "text": "now it's replying rapping okay all right so each one of these reports is",
    "start": "1526490",
    "end": "1534320"
  },
  {
    "text": "something that you can create out of the box and what each one of these reports",
    "start": "1534320",
    "end": "1539390"
  },
  {
    "text": "is doing is running on a schedule right now it's gonna run on the hour every hour and each one of these is running a",
    "start": "1539390",
    "end": "1545960"
  },
  {
    "text": "very particular query which basically specifies what it's going to do each time so I'm going to show you one of those really quick let's see let's show",
    "start": "1545960",
    "end": "1554030"
  },
  {
    "text": "you guys the usage for CPU anybody ever seen the custom printer columns for coop",
    "start": "1554030",
    "end": "1559130"
  },
  {
    "text": "cuddle it's pretty cool so you can actually put in your own stuff which is we're using here so what I'm doing is",
    "start": "1559130",
    "end": "1568280"
  },
  {
    "text": "I'm playing the report generation query custom resource actually let me show you the whole list really quick so we have a",
    "start": "1568280",
    "end": "1575150"
  },
  {
    "text": "number of built-in queries some of these are more flexible than others and some are just kind of building blocks for",
    "start": "1575150",
    "end": "1580670"
  },
  {
    "text": "other queries especially the ones that end in slash raw but query I pull it out",
    "start": "1580670",
    "end": "1587600"
  },
  {
    "text": "earlier here it's basically just the spec dot there we go it's basically a",
    "start": "1587600",
    "end": "1595580"
  },
  {
    "text": "bigger two spec doc query for the custom resource that I showed before the actual",
    "start": "1595580",
    "end": "1606560"
  },
  {
    "text": "contents isn't super important but I want you to understand that this is just raw sequel there's a little bit of other",
    "start": "1606560",
    "end": "1612110"
  },
  {
    "text": "stuff in there there's some go templates it's there to make it flexible and particularly this one is designed for a",
    "start": "1612110",
    "end": "1617780"
  },
  {
    "text": "concept called roll-up that means we can actually have an hourly report which calculates data on an hourly basis from",
    "start": "1617780",
    "end": "1625130"
  },
  {
    "text": "raw data and then we can have a daily report that reports on the hourly reports data which actually it saves us",
    "start": "1625130",
    "end": "1632150"
  },
  {
    "text": "a lot of computation because we're basically spreading out the computation over time we don't actually have to go through the millions and millions of",
    "start": "1632150",
    "end": "1638390"
  },
  {
    "text": "rows the raw data when we've already calculated a summary at an hourly level so what I want to show you is that an",
    "start": "1638390",
    "end": "1645530"
  },
  {
    "text": "actual report that uses some of this what we have here is a namespace memory",
    "start": "1645530",
    "end": "1651920"
  },
  {
    "text": "utilization and a namespace utilization data query or report each one of these is going to run every day and then they",
    "start": "1651920",
    "end": "1659300"
  },
  {
    "text": "have some custom info that actually tell us i want to aggregate the results of another report",
    "start": "1659300",
    "end": "1664530"
  },
  {
    "text": "so let's go ahead and create that all right and then let's actually see",
    "start": "1664530",
    "end": "1673280"
  },
  {
    "text": "its status so that's we can see the name",
    "start": "1673280",
    "end": "1681480"
  },
  {
    "text": "say super utilization report has been created and its status has been set to",
    "start": "1681480",
    "end": "1687300"
  },
  {
    "text": "scheduled so that means it's about to run or it's already running and then we also can see it's got a table and then i",
    "start": "1687300",
    "end": "1694610"
  },
  {
    "text": "know this is kind of hard to see we can also see the last time it reported I set it up to start from the 8th because",
    "start": "1694610",
    "end": "1700410"
  },
  {
    "text": "that's when this cluster was set up and I want it to calculate not only what is the current times data but all the data",
    "start": "1700410",
    "end": "1705900"
  },
  {
    "text": "that we art you did have collected as well so that's cool get the status one",
    "start": "1705900",
    "end": "1711210"
  },
  {
    "text": "more time and make sure it's been updated and we can see it's already caught up to a few days worth of data",
    "start": "1711210",
    "end": "1717390"
  },
  {
    "text": "it's now the 11th from the 8th in a few seconds we'll catch up to the 14th as you can see all the other hour they once",
    "start": "1717390",
    "end": "1722880"
  },
  {
    "text": "have and then well that's also running I want to show you the other query which",
    "start": "1722880",
    "end": "1728820"
  },
  {
    "text": "is interesting which is a cluster wide version of the same thing so the previous one was for namespaces this is for the cluster wide utilization for CPU",
    "start": "1728820",
    "end": "1736200"
  },
  {
    "text": "memory very similar you can give some custom inputs i want to aggregate these other cluster capacity hourly reports as",
    "start": "1736200",
    "end": "1742790"
  },
  {
    "text": "indicated here so I'm also gonna create that and then let's check on the status",
    "start": "1742790",
    "end": "1754309"
  },
  {
    "text": "so we have the name six memory utilization one and it's basically almost caught up one day behind and",
    "start": "1756310",
    "end": "1762530"
  },
  {
    "text": "let's actually get some of these results so I know this URL is somewhat hard to",
    "start": "1762530",
    "end": "1767780"
  },
  {
    "text": "see but it's basically we're using an open ship route to expose the reporting operators API you can also use a load bouncer service or ingress if you like",
    "start": "1767780",
    "end": "1775310"
  },
  {
    "text": "right now I'm taking advantage of some open ship features that make it a little bit easier and then the reporting API is",
    "start": "1775310",
    "end": "1782090"
  },
  {
    "text": "basically a simple REST API where you can create the results in whatever format that you prefer so right now we support JSON CSV and tabular format so",
    "start": "1782090",
    "end": "1790550"
  },
  {
    "text": "let's actually take a look at this in the tabular format really quick and again this is the cluster memory utilization report so this report right",
    "start": "1790550",
    "end": "1799040"
  },
  {
    "text": "now it's caught up look just like to the 12th also go to the right don't worry but the first two columns basically",
    "start": "1799040",
    "end": "1805190"
  },
  {
    "text": "indicate the period that it was reporting on for that row the third column is the total capacity available",
    "start": "1805190",
    "end": "1810740"
  },
  {
    "text": "in bytes seconds so that's basically the actual of memory times the time that it",
    "start": "1810740",
    "end": "1817100"
  },
  {
    "text": "was at that value and then we also have to use the usage you know far right we",
    "start": "1817100",
    "end": "1822680"
  },
  {
    "text": "have the percentage of overall cluster capacity that this is taking that is taken up so beginning of the week last",
    "start": "1822680",
    "end": "1829340"
  },
  {
    "text": "week one before I set up 2,000 names faces it was about 4% utilized and now it's about 12% utilized we also have",
    "start": "1829340",
    "end": "1835940"
  },
  {
    "text": "some averages in case that's a very interesting for you and same for the nib counts and then the same thing can be",
    "start": "1835940",
    "end": "1843290"
  },
  {
    "text": "done for the namespace level report so this one is going to be quite a bit",
    "start": "1843290",
    "end": "1848300"
  },
  {
    "text": "bigger and that's because it's going to have a row for each namespace per day so",
    "start": "1848300",
    "end": "1853820"
  },
  {
    "text": "this might take a second and don't worry I also have another view for this in a second so what we have here is a bunch",
    "start": "1853820",
    "end": "1860510"
  },
  {
    "text": "of clusters or namespaces rather and we have one for each row this is our",
    "start": "1860510",
    "end": "1866930"
  },
  {
    "text": "columns the namespace as shown we have usage going to the right we have the",
    "start": "1866930",
    "end": "1873080"
  },
  {
    "text": "request we have the percent utilization or usage and then we also have the",
    "start": "1873080",
    "end": "1879050"
  },
  {
    "text": "percentage of the clusters capacity and requests so a lot of these ones are basically idling they're not doing a lot",
    "start": "1879050",
    "end": "1884630"
  },
  {
    "text": "they're actually the bad actors that we want to shame like Rob is talking about well we have some even back worse actors that I want to show you so",
    "start": "1884630",
    "end": "1892130"
  },
  {
    "text": "I've already actually downloaded some of these reports as CSVs and opened them up in whatever the I",
    "start": "1892130",
    "end": "1898100"
  },
  {
    "text": "told you might want to use in this case I'm gonna use Libre Office and so one of",
    "start": "1898100",
    "end": "1904820"
  },
  {
    "text": "the things Rob talked about was actually just finding out what are people doing on this clusters so what I've done is",
    "start": "1904820",
    "end": "1911900"
  },
  {
    "text": "I've imported this in to LibreOffice and I've actually set it up so that it's going to show us the more recent data",
    "start": "1911900",
    "end": "1918980"
  },
  {
    "text": "first it's going to show the data that's most recent with a high request but a",
    "start": "1918980",
    "end": "1924350"
  },
  {
    "text": "low usage which means things that are asking for too much and not using any of it in this case the top usage is",
    "start": "1924350",
    "end": "1931970"
  },
  {
    "text": "metering it's the only thing doing anything in this cluster no surprise its usage is about one percent of the",
    "start": "1931970",
    "end": "1936980"
  },
  {
    "text": "cluster and it's requesting about fifteen percent of capacity probably because I over scaled it to make this demo run really fast but as you can see",
    "start": "1936980",
    "end": "1943970"
  },
  {
    "text": "the following ones are these plus test or over-allocated namespaces I wonder what those are so if we look at the",
    "start": "1943970",
    "end": "1950450"
  },
  {
    "text": "usage it's literally zero these pods again don't do anything they're literally the pause container but",
    "start": "1950450",
    "end": "1955910"
  },
  {
    "text": "they're requesting something like seven thousand or seven hundred seventeen thousand cp4 seconds which is something",
    "start": "1955910",
    "end": "1962930"
  },
  {
    "text": "like if I recall four cores and like something like that and over a period of",
    "start": "1962930",
    "end": "1968360"
  },
  {
    "text": "time and we can see its usage is really low zero percent but it's request is quite high eight percent and that's out",
    "start": "1968360",
    "end": "1975200"
  },
  {
    "text": "of the overall cluster capacity meaning each one of these namespaces is basically adding up to almost a total of",
    "start": "1975200",
    "end": "1980420"
  },
  {
    "text": "a quarter of this clusters capacity and we can do the same for namespace in this",
    "start": "1980420",
    "end": "1985460"
  },
  {
    "text": "case the name space is a little different values but it's very similar we can see that they're asking for a lot",
    "start": "1985460",
    "end": "1990710"
  },
  {
    "text": "of memory but they're not actually using it and then at the end of the day if you",
    "start": "1990710",
    "end": "1996800"
  },
  {
    "text": "want to know at a bird's eye view what is my cluster looking like maybe not at a namespace level you can also look at",
    "start": "1996800",
    "end": "2003070"
  },
  {
    "text": "these CPU or name space or memory cluster wide reports which basically",
    "start": "2003070",
    "end": "2008200"
  },
  {
    "text": "give you Oh on the 12th to the 13th you had 4% of your clusters CPU used which",
    "start": "2008200",
    "end": "2015490"
  },
  {
    "text": "is shown here that row and",
    "start": "2015490",
    "end": "2020040"
  },
  {
    "text": "we used 11% of memory and this cluster for the last day alright and I think I",
    "start": "2021000",
    "end": "2029260"
  },
  {
    "text": "think that was it yeah that's it yeah so",
    "start": "2029260",
    "end": "2035250"
  },
  {
    "text": "thank you I wanted to get a show of",
    "start": "2035250",
    "end": "2041289"
  },
  {
    "text": "hands does anybody have a tool like this running against a cluster they're running today",
    "start": "2041289",
    "end": "2046710"
  },
  {
    "text": "nobody kind of ish maybe a few people okay does anybody ever run into problems",
    "start": "2046710",
    "end": "2053500"
  },
  {
    "text": "with pods that can't be scheduled because they ran out of capacity yeah everybody running small clusters for dev",
    "start": "2053500",
    "end": "2058810"
  },
  {
    "text": "tests yeah so you can imagine that this is a problem at any size but it's a huge",
    "start": "2058810",
    "end": "2064030"
  },
  {
    "text": "problem for us at large size and the cool thing about this is we know that this will work against these really",
    "start": "2064030",
    "end": "2069579"
  },
  {
    "text": "large clusters so we can go ahead and hand this off to any sort of financial institution or big insurance company or",
    "start": "2069579",
    "end": "2075940"
  },
  {
    "text": "whoever and know that we're probably going to exceed their scale and so as long as you've got a bunch of gigs to",
    "start": "2075940",
    "end": "2081760"
  },
  {
    "text": "throw at Prometheus you can really crunch that data and make it into something useful so this whole is",
    "start": "2081760",
    "end": "2087460"
  },
  {
    "text": "open-source it's on github I think we've got a few links here we'd love you to try it out this is a screenshot of our",
    "start": "2087460",
    "end": "2092980"
  },
  {
    "text": "readme we're currently testing this with customers but it works against you know any kubernetes cluster this is all very",
    "start": "2092980",
    "end": "2099220"
  },
  {
    "text": "agnostic we've got installation guides guide through how to run reports the reason we",
    "start": "2099220",
    "end": "2104589"
  },
  {
    "text": "showed you all these sequel queries is because you can write these custom we've handed it off to a customer and actually",
    "start": "2104589",
    "end": "2110260"
  },
  {
    "text": "like you know a few hours later he'd already reported back that he'd been writing custom queries because he didn't like some of our logic so it's really",
    "start": "2110260",
    "end": "2116650"
  },
  {
    "text": "really extensible and so we'd love for y'all to try it out get feedback file bugs all that good stuff thank you",
    "start": "2116650",
    "end": "2123569"
  },
  {
    "text": "you",
    "start": "2124870",
    "end": "2126930"
  }
]
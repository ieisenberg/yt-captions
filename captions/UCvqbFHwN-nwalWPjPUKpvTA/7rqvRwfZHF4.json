[
  {
    "start": "0",
    "end": "54000"
  },
  {
    "text": "okay yeah okay I can speak hello you're Alexandra play we're going to",
    "start": "30",
    "end": "7680"
  },
  {
    "text": "talk about our experiences in building kubernetes cluster on bare metal",
    "start": "7680",
    "end": "12840"
  },
  {
    "text": "hardware for Wikipedia so first some",
    "start": "12840",
    "end": "18270"
  },
  {
    "text": "information about who we are I think most of you are familiar with our main",
    "start": "18270",
    "end": "24930"
  },
  {
    "text": "project which is Wikipedia leukemia foundation is a nonprofit organization that works on maintaining the",
    "start": "24930",
    "end": "31109"
  },
  {
    "text": "infrastructure for Wikipedia but not just Wikipedia our sister projects like wiki data or we travel with users and so",
    "start": "31109",
    "end": "39090"
  },
  {
    "text": "on not with leaks as you can see we have",
    "start": "39090",
    "end": "44760"
  },
  {
    "text": "half the amount of traffic monthly so we are one of at um top 10 websites as far",
    "start": "44760",
    "end": "53219"
  },
  {
    "text": "as traffic is concerned still we have our infrastructure as two primary data",
    "start": "53219",
    "end": "60359"
  },
  {
    "start": "54000",
    "end": "54000"
  },
  {
    "text": "centers where the application layer stays and persistence layer stays and then we have free caching data centers",
    "start": "60359",
    "end": "66900"
  },
  {
    "text": "one in San Francisco one in Amsterdam and a new one in Singapore but are basically just keeping the caches of a",
    "start": "66900",
    "end": "73860"
  },
  {
    "text": "content so that like we can serve a content nearer to a user so it's kind of our own home-baked CDN even with the",
    "start": "73860",
    "end": "81840"
  },
  {
    "text": "amount of traffic that we have our cluster is relatively small we just have 1,200 hardware machines we don't",
    "start": "81840",
    "end": "89909"
  },
  {
    "text": "typically use VMs in production just lately we're using a couple of vanity",
    "start": "89909",
    "end": "95340"
  },
  {
    "text": "clusters what was that about hundred VMs and we're not just lean in terms of",
    "start": "95340",
    "end": "102920"
  },
  {
    "text": "hardware we're also lean in terms of the size of the organization as you can see around 160 ingenious overall and the",
    "start": "102920",
    "end": "110040"
  },
  {
    "text": "people that care about the application layer which is what we're moving to kubernetes is just four people so why",
    "start": "110040",
    "end": "117869"
  },
  {
    "text": "we're moving to kubernetes just a few words about this and up until 2014 we",
    "start": "117869",
    "end": "122939"
  },
  {
    "text": "just had the big monolithic application which is MediaWiki and one service which",
    "start": "122939",
    "end": "129060"
  },
  {
    "text": "is called par soil that was the helping with our visual editor fast",
    "start": "129060",
    "end": "134650"
  },
  {
    "text": "forward four years to today we have much more services we are moving somehow towards a micro service-oriented",
    "start": "134650",
    "end": "141160"
  },
  {
    "text": "architecture slowly but even with slow motion the toyline",
    "start": "141160",
    "end": "147910"
  },
  {
    "text": "on our team which is very small is increasing increasing and we need a way",
    "start": "147910",
    "end": "153340"
  },
  {
    "text": "both for us to work faster and for the developers to be able to deploy our",
    "start": "153340",
    "end": "158890"
  },
  {
    "text": "services better and with less weight on our time but these are not the only",
    "start": "158890",
    "end": "164230"
  },
  {
    "text": "reasons to move to kubernetes one big reason for us is elasticity so V ability to scale up and scale down each function",
    "start": "164230",
    "end": "172360"
  },
  {
    "text": "that we have in a short amount of time after traffic bursts and also well the",
    "start": "172360",
    "end": "181120"
  },
  {
    "text": "fact that it kind of frees up us from having to deal too much with a failure",
    "start": "181120",
    "end": "186459"
  },
  {
    "text": "of a physical node because companies basically detected south and reorganised",
    "start": "186459",
    "end": "192519"
  },
  {
    "text": "resources by itself instead of having us doing that and also containers are a",
    "start": "192519",
    "end": "197829"
  },
  {
    "text": "good thing because they allow developers to have basically the same consistent",
    "start": "197829",
    "end": "203320"
  },
  {
    "text": "environment on their own development machine and in production so that reduces surprises when things are coming",
    "start": "203320",
    "end": "210670"
  },
  {
    "text": "to production and finally we are giving the same developers with people that deploy code on the cluster more control",
    "start": "210670",
    "end": "217209"
  },
  {
    "text": "over their applications because the configurations about realisations is not",
    "start": "217209",
    "end": "222549"
  },
  {
    "text": "anymore in puppet which is controlled by us so they can have much more flexibility about what they do but we",
    "start": "222549",
    "end": "229000"
  },
  {
    "text": "also see also saw some challenges so the first one kubernetes is complex as we've",
    "start": "229000",
    "end": "235090"
  },
  {
    "text": "just seen in the previous talk right just the QoS is very complex and",
    "start": "235090",
    "end": "240310"
  },
  {
    "text": "everything else is complex and there are a lot of moving parts we didn't want to sacrifice the best ability that we have",
    "start": "240310",
    "end": "246989"
  },
  {
    "text": "just to get flexibility also it's a new paradigm anyone has heard cloud native",
    "start": "246989",
    "end": "253750"
  },
  {
    "text": "in last few days yet it's a new paradigm and it's a good thing but it's also a",
    "start": "253750",
    "end": "259570"
  },
  {
    "text": "problem for all the tooling that we have around our cluster which is based on butt concept of having physical servers we've",
    "start": "259570",
    "end": "266530"
  },
  {
    "text": "services installed on them and finally containers ourselves are also a",
    "start": "266530",
    "end": "271930"
  },
  {
    "text": "challenge for us because we used to be very efficient in doing security upgrades and everybody that has dealt",
    "start": "271930",
    "end": "279139"
  },
  {
    "text": "with containers knows that's that's kind of almost a salt problem on containers",
    "start": "279139",
    "end": "284560"
  },
  {
    "text": "so why we're doing things on bare metal why are we at the cloud native",
    "start": "284560",
    "end": "290000"
  },
  {
    "start": "285000",
    "end": "285000"
  },
  {
    "text": "conference talking about standing things of them they're made aware well there are some reasons why we can't use a",
    "start": "290000",
    "end": "296389"
  },
  {
    "text": "public cloud first and foremost is that we value the privacy of our users very",
    "start": "296389",
    "end": "302210"
  },
  {
    "text": "much and the contract that we have with our users in terms of their privacy and",
    "start": "302210",
    "end": "307759"
  },
  {
    "text": "we feel that if we are the third party actor in the middle we have to have to",
    "start": "307759",
    "end": "313280"
  },
  {
    "text": "trust that for party fully in order to guarantee gave the use of the same guarantees and that's not gonna happen",
    "start": "313280",
    "end": "319669"
  },
  {
    "text": "with public cloud also we already have our infrastructure you already maintaining it so it's not",
    "start": "319669",
    "end": "326000"
  },
  {
    "text": "like we have an upscale cost for just maintaining a bare cluster a bare metal cluster and finally costs as I said in",
    "start": "326000",
    "end": "334580"
  },
  {
    "text": "the first slide right we have quite some traffic what quite some amount of traffic think of the Bill of just taking",
    "start": "334580",
    "end": "341090"
  },
  {
    "text": "all of us by it's out of cloud what what wet would be and we don't really have money being a non-profit and relying on",
    "start": "341090",
    "end": "347300"
  },
  {
    "text": "donations of individuals why we're not doing a private cloud van well we",
    "start": "347300",
    "end": "352940"
  },
  {
    "text": "already do it actually for another project that we ran on top of OpenStack with kubernetes but that's a platform as",
    "start": "352940",
    "end": "360319"
  },
  {
    "text": "a service for editors that can build tools that have helped them edit the week is for the production path we felt",
    "start": "360319",
    "end": "367610"
  },
  {
    "text": "it's it's not really something we want because you want to reduce the number of moving parts right and OpenStack is",
    "start": "367610",
    "end": "373190"
  },
  {
    "text": "actually more moving parts when kubernetes so we didn't receive a reason to do that because the elasticity we",
    "start": "373190",
    "end": "379789"
  },
  {
    "text": "need is already given us by Kuber needs itself since we want to move all the application layer to kubernetes we have",
    "start": "379789",
    "end": "386060"
  },
  {
    "text": "a set of machines that are dedicated to that and we just want to switch resources between one or and the other",
    "start": "386060",
    "end": "391699"
  },
  {
    "text": "and so we don't need the additional that is the city that's given by cloud",
    "start": "391699",
    "end": "396810"
  },
  {
    "start": "396000",
    "end": "396000"
  },
  {
    "text": "so this is it for my part and let Alex talk about how we set up cluster hello",
    "start": "396810",
    "end": "404190"
  },
  {
    "text": "everyone nice to be here so talking about how our clusters are set up we",
    "start": "404190",
    "end": "411419"
  },
  {
    "text": "have a very Debian developer populated as a reteam there are a lot of those",
    "start": "411419",
    "end": "417270"
  },
  {
    "text": "people there and that's why we decided to go of course with the BIM packages way so we package our own debian",
    "start": "417270",
    "end": "423740"
  },
  {
    "text": "versions of communities and very very recently in this conference we found out",
    "start": "423740",
    "end": "429600"
  },
  {
    "text": "that Google is also providing tabs for people so thank you for that we aim to evaluate them and if they are",
    "start": "429600",
    "end": "436980"
  },
  {
    "text": "good enough use them and I'm hoping that they are because maintaining that package is a little bit of a pain anyone",
    "start": "436980",
    "end": "442980"
  },
  {
    "text": "who has ever gone into the process of building communities can probably attest to that so we currently are at version",
    "start": "442980",
    "end": "450840"
  },
  {
    "text": "1.7 and we which is of course as you probably know and maintained right now because Benitez team only maintains the",
    "start": "450840",
    "end": "458340"
  },
  {
    "text": "last three releases so it's 1 cell 1 8 1 9 and 110 that are currently maintained",
    "start": "458340",
    "end": "463440"
  },
  {
    "text": "and we need to upgrade of course and maybe we'll be here next year telling",
    "start": "463440",
    "end": "469410"
  },
  {
    "text": "you how web graded all these - all these versions we also use calico but for",
    "start": "469410",
    "end": "474990"
  },
  {
    "text": "those of those of you do not know it's CNI plugin basically for kubernetes and we are currently at version 2 to 0 and",
    "start": "474990",
    "end": "482520"
  },
  {
    "text": "of course 3.0 is out and again we need to break and we are also using etcd 2 to",
    "start": "482520",
    "end": "488310"
  },
  {
    "text": "1 and you're probably already asking why are you not on 3 point X and the answer",
    "start": "488310",
    "end": "493560"
  },
  {
    "text": "is yes we need again to grade we're packaging all these software on our own and we need to maintain it our clusters",
    "start": "493560",
    "end": "500850"
  },
  {
    "text": "well we're a very big pet shop if you go to if you want to go to our Gerrit or",
    "start": "500850",
    "end": "506220"
  },
  {
    "text": "you go to github where we have a mirror of our Gerrit you can see our pipette repo it's I think the biggest open",
    "start": "506220",
    "end": "512969"
  },
  {
    "text": "source puppet repo there is out there even though it doesn't have a license but don't please judge us on that so we",
    "start": "512969",
    "end": "519120"
  },
  {
    "text": "configure everything via a puppet so we configured all of the community's components by puppet as well and that",
    "start": "519120",
    "end": "524550"
  },
  {
    "text": "had one very nice thing it has our list it allowed us to have Els for all the components everywhere",
    "start": "524550",
    "end": "531540"
  },
  {
    "text": "from the go just by reusing the puppet see a and also showed a couple of",
    "start": "531540",
    "end": "536880"
  },
  {
    "text": "problems with a puppet ca in the process we would like at some points all these or migrate away from it we will see what",
    "start": "536880",
    "end": "544470"
  },
  {
    "text": "we do not maintain by a puppet even though we pondered the idea was the community's resources there is even a",
    "start": "544470",
    "end": "550320"
  },
  {
    "text": "puppet module in puppet Forge that allows you to do that but on thinking",
    "start": "550320",
    "end": "556740"
  },
  {
    "text": "about it we realize that maintaining such a puppet module and making generic and nos and all that and publishing it",
    "start": "556740",
    "end": "563190"
  },
  {
    "text": "in puppet Forge would be a pretty big toriel and then we even realized later on it would not make sense for our case",
    "start": "563190",
    "end": "569190"
  },
  {
    "text": "because we end up maintaining most of the resources if not all of them via helm at the end a little bit more about",
    "start": "569190",
    "end": "577920"
  },
  {
    "text": "how those processors are set up we have API servers 2 per cluster and they are",
    "start": "577920",
    "end": "585000"
  },
  {
    "text": "behind a load balancer and in-house a load balancer which I will describe a little bit more in detail afterwards and",
    "start": "585000",
    "end": "591240"
  },
  {
    "text": "we also have the coop scheduler and the cube controller manager also on the same node and we pass - - select masters in",
    "start": "591240",
    "end": "600510"
  },
  {
    "text": "true equals true and the reason for that is that it allows us to produce two",
    "start": "600510",
    "end": "606660"
  },
  {
    "text": "components to be on the same node as the key API server and talk to it on the unfit ik aided port and just rely on",
    "start": "606660",
    "end": "613440"
  },
  {
    "text": "firewalling in order to protect our API that allowed us to avoid for now authentication and",
    "start": "613440",
    "end": "620700"
  },
  {
    "text": "authorization that we would need to do for those two components of communities to talk to the API server a little bit",
    "start": "620700",
    "end": "630540"
  },
  {
    "text": "more about those two production clusters they are currently three well one is not really production it's the staging",
    "start": "630540",
    "end": "636840"
  },
  {
    "text": "cluster which we are now binding to our built-in deployment pipeline and we have",
    "start": "636840",
    "end": "644310"
  },
  {
    "text": "one primary DC we were talking about the primary basis previously we have separated these two clusters for every",
    "start": "644310",
    "end": "651180"
  },
  {
    "text": "one of those kubernetes clusters and of course we use a basic idea of three in",
    "start": "651180",
    "end": "658740"
  },
  {
    "text": "order to maintain quorum they are of course DC local in order to maintain level of latency and funnily enough",
    "start": "658740",
    "end": "665190"
  },
  {
    "text": "those are on VMs from Ghana DBMS gannett is a mature virtualization orchestration framework by Google thank you google for",
    "start": "665190",
    "end": "673079"
  },
  {
    "text": "that as well you can expect what we run q proxy in the default way which is a tables mode",
    "start": "673079",
    "end": "679829"
  },
  {
    "text": "but we are evaluating at PBS we already have very heavy lvsd our shop and so",
    "start": "679829",
    "end": "685529"
  },
  {
    "text": "this is actually interesting in with for us and we do have expertise already in this and we host our own registry and we",
    "start": "685529",
    "end": "692310"
  },
  {
    "text": "enforce it we do not allow things off of docker hub running in our infrastructure",
    "start": "692310",
    "end": "697410"
  },
  {
    "text": "and the reason for that is what you can probably guess and a lot of people have said in this conference is that you",
    "start": "697410",
    "end": "703380"
  },
  {
    "text": "cannot guarantee a if you're pulling things from docker hub you cannot guarantee what you're running and most",
    "start": "703380",
    "end": "708750"
  },
  {
    "text": "importantly if and if you can trust the person doing it has he updated hash he",
    "start": "708750",
    "end": "714180"
  },
  {
    "text": "updated the specific image that you are running so what we do is we run all",
    "start": "714180",
    "end": "719399"
  },
  {
    "text": "lowering we build and run all our images from scratch and you can even go around",
    "start": "719399",
    "end": "724949"
  },
  {
    "text": "check out our images your docket Pokemon is there feel free to see what kind of images we have there of course very",
    "start": "724949",
    "end": "731399"
  },
  {
    "text": "specific to our use cases but your feel free of course they are well they're being based as I said we're Debian shop",
    "start": "731399",
    "end": "738649"
  },
  {
    "text": "the backend for this specific docker registry which uses the reference docker registry from docker is OpenStack Swift",
    "start": "738649",
    "end": "744810"
  },
  {
    "text": "and it works reliably well remarkably well we went with our back rule based",
    "start": "744810",
    "end": "753660"
  },
  {
    "text": "access control from day one and the reason for that is very simply we're not cloud we cannot have our comedians",
    "start": "753660",
    "end": "761639"
  },
  {
    "text": "classes in the cloud which means that we cannot assign a kabillion this class super team or / service or whatever so",
    "start": "761639",
    "end": "768360"
  },
  {
    "text": "we had to have our box in order to protect the various tenants of the infrastructure from each other we have a",
    "start": "768360",
    "end": "775319"
  },
  {
    "text": "policy of applying one namespace per service and the result of that is",
    "start": "775319",
    "end": "781889"
  },
  {
    "text": "Conway's law for those of you who do not know what Conway's law it says basically",
    "start": "781889",
    "end": "787050"
  },
  {
    "text": "that the organizational structure or the structure for your organization is going to show up in your products and what has",
    "start": "787050",
    "end": "793769"
  },
  {
    "text": "happened in the past in organization is that there have been a lot of changes and we were kind enough",
    "start": "793769",
    "end": "799820"
  },
  {
    "text": "locks in the last few years so we decided instead of going to team centric approach to go for a product centric",
    "start": "799820",
    "end": "806570"
  },
  {
    "text": "approach where product is of course the service authentication wise we use",
    "start": "806570",
    "end": "812120"
  },
  {
    "text": "parently token for our file we have evaluated all the various authentication",
    "start": "812120",
    "end": "817400"
  },
  {
    "text": "modules there is actually a fabricator task and our fabricator it's fabricated at Wikimedia dad org so",
    "start": "817400",
    "end": "822920"
  },
  {
    "text": "say if it were if you want it's written by yours truly and it valuates more each",
    "start": "822920",
    "end": "828529"
  },
  {
    "text": "one of those vindication methods and why on we ended up with toka North which is",
    "start": "828529",
    "end": "833900"
  },
  {
    "text": "a little bit difficult to maintain but we would like at some point to go to the web hook authentication mode but we",
    "start": "833900",
    "end": "840440"
  },
  {
    "text": "first need to run a service that actually allows you to off against the",
    "start": "840440",
    "end": "847400"
  },
  {
    "text": "emission controls is we have all the standards that are the standard mission controllers that we run for keep the RQ",
    "start": "847400",
    "end": "853040"
  },
  {
    "text": "news version we have not deviated from that what we have done in however is that we have firm which is a wrapper",
    "start": "853040",
    "end": "860390"
  },
  {
    "text": "around IP six tables and IP tables that makes managing rules why are these tools",
    "start": "860390",
    "end": "865970"
  },
  {
    "text": "way way way more easier so we have this across the entire fleet there is not a",
    "start": "865970",
    "end": "871280"
  },
  {
    "text": "box without well there's not a box that cannot be absolutely true but anyway so where most of the boxes have firm there",
    "start": "871280",
    "end": "878450"
  },
  {
    "text": "and they have default policy of drop and that specific thing also is applied on the kubernetes nodes and of course the",
    "start": "878450",
    "end": "884810"
  },
  {
    "text": "API servers we were kind of worried about this because we also applied firm to our open stack boxes and well there",
    "start": "884810",
    "end": "893120"
  },
  {
    "text": "are race conditions you reload firm and flashes of course the entire rule set will fight the tables and then Nova",
    "start": "893120",
    "end": "899360"
  },
  {
    "text": "network and does not notice because no but networks just execute commands and does not want your anything and of",
    "start": "899360",
    "end": "904490"
  },
  {
    "text": "course you're left without the rule the federal rules and default job and your that in order the good thing is that",
    "start": "904490",
    "end": "912350"
  },
  {
    "text": "both cubelet bubbles queue proxy and queue Blair and the Felix agent which is",
    "start": "912350",
    "end": "917420"
  },
  {
    "text": "what calico names the thing that runs in your node all monitor and now they all",
    "start": "917420",
    "end": "922880"
  },
  {
    "text": "fix rules and this thing works way better than we feared",
    "start": "922880",
    "end": "928420"
  },
  {
    "start": "928000",
    "end": "928000"
  },
  {
    "text": "so let's go a little bit into network this is our typical primary DC these are",
    "start": "928430",
    "end": "937720"
  },
  {
    "text": "for rock rows F as you can see we're in",
    "start": "937720",
    "end": "943010"
  },
  {
    "text": "one of those adding a fifth one and every rock row is comprised of eight tracks and every Rock low has one tour",
    "start": "943010",
    "end": "950240"
  },
  {
    "text": "top of the rock switch and they are stacked into being a single single",
    "start": "950240",
    "end": "957080"
  },
  {
    "text": "managed switch which means that basically if you reboot that specific switch the entire rack row which is 32",
    "start": "957080",
    "end": "964130"
  },
  {
    "text": "racks is going to go down for the duration of the reboot which by the way jr. predicts does take a little bit of",
    "start": "964130",
    "end": "970250"
  },
  {
    "text": "time in that big switches it's a little bit of a collapsed cloth topology if you",
    "start": "970250",
    "end": "977780"
  },
  {
    "text": "want to be not very pedantic about it in the form that we have those two effects",
    "start": "977780",
    "end": "983020"
  },
  {
    "text": "switches without which are basically 10g port switches that are the spines and",
    "start": "983020",
    "end": "989990"
  },
  {
    "text": "there are the next witches that are the the Leafs the thing to note in this",
    "start": "989990",
    "end": "995810"
  },
  {
    "text": "specific diagram is the fact that if you have a box in one rack row we know de to reach any other box in any other row you have to go through the routers now we",
    "start": "995810",
    "end": "1002500"
  },
  {
    "text": "might have quite a bit of traffic outbound but in between traffic rules it's not that huge and it's fine for us",
    "start": "1002500",
    "end": "1011410"
  },
  {
    "text": "to use those routers because we feel that at this specific point in time layer 3 is more debuggable familiar to a",
    "start": "1011410",
    "end": "1021010"
  },
  {
    "text": "little bit more about it so we have currently the clusters are rather small therefore machines and so we have one",
    "start": "1021010",
    "end": "1028000"
  },
  {
    "text": "per row but we plan to increase these to 12 very soon and we had this requirement",
    "start": "1028000",
    "end": "1034270"
  },
  {
    "text": "since the beginning that the kubernetes clusters needed to be fully compatible with the legacy infrastructure we're",
    "start": "1034270",
    "end": "1041170"
  },
  {
    "text": "legacies what we currently have which meant that we could not do not know",
    "start": "1041170",
    "end": "1046300"
  },
  {
    "text": "network and its relation every anywhere we started looking at the various solutions and two years ago at FOSDEM in",
    "start": "1046300",
    "end": "1053850"
  },
  {
    "text": "2016 there was a calico talk we looked at it and we said whoa this thing is",
    "start": "1053850",
    "end": "1060070"
  },
  {
    "text": "what we need but calico does is that you have an agent and every one of your nodes and it",
    "start": "1060070",
    "end": "1067870"
  },
  {
    "text": "talks bgp we follow with well either all the other nodes or without your routers",
    "start": "1067870",
    "end": "1073600"
  },
  {
    "text": "or whatever you tell it it's fully configurable and it announces the prod I piece to the rest of the world so what",
    "start": "1073600",
    "end": "1080950"
  },
  {
    "text": "we have done we have it configured again by a puppet well partly by a puppet part in manual because there are two things",
    "start": "1080950",
    "end": "1086650"
  },
  {
    "text": "that we do not currently do by a puppet in calico and those are the IP pools and the BGP peers the routers basically and",
    "start": "1086650",
    "end": "1094540"
  },
  {
    "text": "it's working quite fine and we're probably happy with it we do not do BGP full mesh that would be",
    "start": "1094540",
    "end": "1101790"
  },
  {
    "text": "all the nodes talking to each other in changing the routes of the paths so that",
    "start": "1101790",
    "end": "1107290"
  },
  {
    "text": "you would have one only hop four or one pole to reach another because as I said",
    "start": "1107290",
    "end": "1112750"
  },
  {
    "text": "we have this rack row aware networking",
    "start": "1112750",
    "end": "1117790"
  },
  {
    "text": "diagram where you have to go via the router in order to reach a different rack row we're thinking about row space",
    "start": "1117790",
    "end": "1125740"
  },
  {
    "text": "specific full mesh though in order to keep it no more local have a more affinity in the rock row for inter pot",
    "start": "1125740",
    "end": "1132460"
  },
  {
    "text": "traffic we are using 10 dot X / 8 IP",
    "start": "1132460",
    "end": "1137860"
  },
  {
    "text": "addresses for the pods and they're fully routable in our network thanks to calico and we are using the exact same IPS for",
    "start": "1137860",
    "end": "1144400"
  },
  {
    "text": "the exact same not nothing is that's the same IP space but a different different",
    "start": "1144400",
    "end": "1150190"
  },
  {
    "text": "slash 24 for the service IPS and this is the part where you'll say service type",
    "start": "1150190",
    "end": "1155440"
  },
  {
    "text": "these are not really route or bullion cabinet is there they're not really a piece to start with they are tags basically you say the pod just needs to",
    "start": "1155440",
    "end": "1163090"
  },
  {
    "text": "have an IP for to talk to so those are effectively just reservations we just reserved IP spaces because we do not",
    "start": "1163090",
    "end": "1169690"
  },
  {
    "text": "want to have 192 168 IP is in our network because whenever we met those",
    "start": "1169690",
    "end": "1175360"
  },
  {
    "text": "for some reason it was due to a either a miss configuration something very confusing going on so it was just",
    "start": "1175360",
    "end": "1180970"
  },
  {
    "text": "maintaining the status quo and one thing that calico has allowed us to do and was",
    "start": "1180970",
    "end": "1187299"
  },
  {
    "text": "very very nice and thank you calico for that is we now have even though communities does not support ipv6 or at",
    "start": "1187299",
    "end": "1194020"
  },
  {
    "text": "least in our version our paths are ipv6 enabled and in order",
    "start": "1194020",
    "end": "1200390"
  },
  {
    "text": "to do that it was very easy to do that in the ipam for colic or just the sign maybe before true a sign of pv6 true and",
    "start": "1200390",
    "end": "1206390"
  },
  {
    "text": "then we had to go to every node and set those to see CTL configurations that you",
    "start": "1206390",
    "end": "1212000"
  },
  {
    "text": "see there now for those that I perhaps you do ipv4 forwarding and haven't done ipv6 forwarding on Linux that thing does",
    "start": "1212000",
    "end": "1220010"
  },
  {
    "text": "not do what it does in ipv4 go read the darks they are completely different they",
    "start": "1220010",
    "end": "1225740"
  },
  {
    "text": "do different things the second one is because we wanted to have routing in ipv6 in our nodes but at the same time",
    "start": "1225740",
    "end": "1234860"
  },
  {
    "text": "we did not have to go around and manage all the aspects of a router in Linux and that value there except array equals to",
    "start": "1234860",
    "end": "1241790"
  },
  {
    "text": "allows the nodes to receive router advertisements from our juniper routers",
    "start": "1241790",
    "end": "1247040"
  },
  {
    "text": "in order to continue working as the normal boxes that we now pass having the capability of rewarding activity six",
    "start": "1247040",
    "end": "1253910"
  },
  {
    "text": "packets for the pots we also have network policies I know so for those who",
    "start": "1253910",
    "end": "1262160"
  },
  {
    "start": "1256000",
    "end": "1256000"
  },
  {
    "text": "don't know one point seven does not support egress one point eight does so",
    "start": "1262160",
    "end": "1268160"
  },
  {
    "text": "we had to work around that we're hoping to drop that workaround in the future in one point eight calico does support us",
    "start": "1268160",
    "end": "1276500"
  },
  {
    "text": "and we asks how you implemented a workaround and the second thing that we met was the fact that one point seven",
    "start": "1276500",
    "end": "1282620"
  },
  {
    "text": "does not allow you to change a network policy you have to bring down and reinstall it in order to to change the",
    "start": "1282620",
    "end": "1291890"
  },
  {
    "text": "policy and we had to do that via hell the authority that we have actually",
    "start": "1291890",
    "end": "1297320"
  },
  {
    "text": "implemented is we patch the calculate s controller the version was zero point six zero and it's a Python one and it's",
    "start": "1297320",
    "end": "1304670"
  },
  {
    "text": "no longer there because it was rewritten in go so our solution well it's not",
    "start": "1304670",
    "end": "1310490"
  },
  {
    "text": "needed anymore thankfully with one point eight we don't even need that it's what's really really small we",
    "start": "1310490",
    "end": "1316730"
  },
  {
    "text": "haven't default ingress policy and our",
    "start": "1316730",
    "end": "1321890"
  },
  {
    "text": "patch is like very minimal fourteen lines of code all it does is read a config map and populate the Calico",
    "start": "1321890",
    "end": "1328310"
  },
  {
    "text": "configuration what about ingress we evaluated back in",
    "start": "1328310",
    "end": "1334380"
  },
  {
    "start": "1330000",
    "end": "1330000"
  },
  {
    "text": "2017 and said nope not yet not ready not for us so how do",
    "start": "1334380",
    "end": "1339630"
  },
  {
    "text": "we route traffic to our classes you asked that's a pretty valid question so",
    "start": "1339630",
    "end": "1345810"
  },
  {
    "text": "what we do is we use that Python in-house built daemon that we have been having for like what it's now eight",
    "start": "1345810",
    "end": "1352320"
  },
  {
    "text": "years maybe it's called PI Bo and there is a URL for you and github if you want",
    "start": "1352320",
    "end": "1358080"
  },
  {
    "text": "to go and take a look what it does is it monitors lvsd our entries in the kernel",
    "start": "1358080",
    "end": "1366810"
  },
  {
    "text": "lvsd are obvious direct routing what it basically does is when the packet reaches the load balancer the only thing",
    "start": "1366810",
    "end": "1373470"
  },
  {
    "text": "that it does it through the IP packet is change the Mac it doesn't alter in any way the IPP headers or anything like",
    "start": "1373470",
    "end": "1380040"
  },
  {
    "text": "that so it's very very lightweight and the traffic goes directly to the backend that means however that the backend",
    "start": "1380040",
    "end": "1386550"
  },
  {
    "text": "needs to have that IP set up in its interfaces otherwise it's not going to accept the traffic the good thing is",
    "start": "1386550",
    "end": "1394200"
  },
  {
    "text": "that it does not have to reply back to the load balancer and then load balancer does not have to reply to the client",
    "start": "1394200",
    "end": "1400350"
  },
  {
    "text": "outgoing traffic leaves all the backends and goes straight back to the client",
    "start": "1400350",
    "end": "1406650"
  },
  {
    "text": "instead of going through your load balancers which is good in our case because we have minimal into traffic",
    "start": "1406650",
    "end": "1412560"
  },
  {
    "text": "bits basically get slash and article but we have a lot of outgoing traffic from",
    "start": "1412560",
    "end": "1418800"
  },
  {
    "text": "those boxes we had a lot of expertise over this software and we decided to",
    "start": "1418800",
    "end": "1424170"
  },
  {
    "text": "reuse it and we know from a blog post from github they have more or less a",
    "start": "1424170",
    "end": "1430440"
  },
  {
    "text": "similar approach a little bit bit different but we're happy where at least we're not alone in this and we're using",
    "start": "1430440",
    "end": "1435810"
  },
  {
    "text": "node port in order to with external IDs that change by the way in Bernie's 1.65",
    "start": "1435810",
    "end": "1441900"
  },
  {
    "text": "member correctly it used to be different in the API that caught us off surprise for a little bit then figure out that",
    "start": "1441900",
    "end": "1447630"
  },
  {
    "text": "this is actually a better way about metrics collection we actually connect",
    "start": "1447630",
    "end": "1453420"
  },
  {
    "start": "1450000",
    "end": "1450000"
  },
  {
    "text": "metrics thank you from easiest for that it works quite well and the only thing",
    "start": "1453420",
    "end": "1459180"
  },
  {
    "text": "that we did was have pop-eyed populate the configuration so what we do have is that Prometheus",
    "start": "1459180",
    "end": "1467299"
  },
  {
    "text": "discovers the API and pause the couplets the couplets eadvisor it all so Paul's",
    "start": "1467299",
    "end": "1472970"
  },
  {
    "text": "the the couplet API itself and we've met a bug in 1.73 where the API it's a",
    "start": "1472970",
    "end": "1480620"
  },
  {
    "text": "little bit was a little bit different the interesting thing with that was the",
    "start": "1480620",
    "end": "1486260"
  },
  {
    "text": "Prometheus community already documented is in the example configuration that was great great however applications are a little bit",
    "start": "1486260",
    "end": "1493010"
  },
  {
    "text": "more interesting so we also use Fermi fix for that too what we did is all",
    "start": "1493010",
    "end": "1498559"
  },
  {
    "text": "other implications you surgically use stats D so we have stats the exporter",
    "start": "1498559",
    "end": "1503750"
  },
  {
    "text": "that's a sidecar container to all our parts applications talk to localhost and",
    "start": "1503750",
    "end": "1510230"
  },
  {
    "text": "push all the stats team metrics and then Prometheus discovers all the pods and",
    "start": "1510230",
    "end": "1515540"
  },
  {
    "text": "Paul's all the pods and gathers the information and we we visualize all of",
    "start": "1515540",
    "end": "1522110"
  },
  {
    "text": "that through grow fauna and here's a link if you want to get our graph on our",
    "start": "1522110",
    "end": "1527480"
  },
  {
    "text": "installation big kudos to the graph on a team this is an excellent software thank",
    "start": "1527480",
    "end": "1532760"
  },
  {
    "text": "you very much rather on pretty sure you all know it it's just a shout out alerting is not that great currently and",
    "start": "1532760",
    "end": "1539960"
  },
  {
    "start": "1536000",
    "end": "1536000"
  },
  {
    "text": "this is mostly for historical reasons we use Prometheus again but partly because",
    "start": "1539960",
    "end": "1546110"
  },
  {
    "text": "we're still on I shall I sing a sharp eye single you know for those of you do",
    "start": "1546110",
    "end": "1551120"
  },
  {
    "text": "not know it's I'm all software from the 90s it's very node centric not service centric we won on my grade off of it we have",
    "start": "1551120",
    "end": "1559160"
  },
  {
    "text": "started by integrating check Prometheus metric script in bash and of course we",
    "start": "1559160",
    "end": "1565669"
  },
  {
    "text": "had problems with it because it's not support floats and we and various other small corner cases and then we ended up",
    "start": "1565669",
    "end": "1571490"
  },
  {
    "text": "rewriting it in Python and if you add in puppet which is how you manage all of",
    "start": "1571490",
    "end": "1576620"
  },
  {
    "text": "our alerts you can get that very very weird-looking alert like what does this",
    "start": "1576620",
    "end": "1583070"
  },
  {
    "text": "thing even do we're fixing this one of my colleagues actually while we were",
    "start": "1583070",
    "end": "1589730"
  },
  {
    "text": "here submitted patches to fix this and all of the alerts themselves are now in",
    "start": "1589730",
    "end": "1594770"
  },
  {
    "text": "the Prometheus engine and we just all the very specific name alert for that the",
    "start": "1594770",
    "end": "1601550"
  },
  {
    "text": "last thing that we did is that we decided to go forward with a different",
    "start": "1601550",
    "end": "1607280"
  },
  {
    "text": "way of monitoring applications that what a singer did because basically applications are a little bit difficult to monitor when it comes to api's",
    "start": "1607280",
    "end": "1613460"
  },
  {
    "text": "because each of them one of the eight points can fail in a myriad ways and all of the other points may not fail so it's",
    "start": "1613460",
    "end": "1621110"
  },
  {
    "text": "difficult to go around and create a software that monitors all of these api is and have a die single compatible and all that so what we did is we extended",
    "start": "1621110",
    "end": "1628040"
  },
  {
    "text": "our swagger specs for all these applications with a very specific expect that allowed us to create an applicator",
    "start": "1628040",
    "end": "1634640"
  },
  {
    "text": "that would go around walk all the API and the endpoints and submit a a test",
    "start": "1634640",
    "end": "1641950"
  },
  {
    "text": "query to that specific endpoint and that's where I pass the ball again -",
    "start": "1641950",
    "end": "1647780"
  },
  {
    "text": "gizelle okay so we call the project",
    "start": "1647780",
    "end": "1653240"
  },
  {
    "text": "stream nine service delivery because the main point for us was that kubernetes allows you to change the way you manage",
    "start": "1653240",
    "end": "1660890"
  },
  {
    "text": "this lifecycle of software and specifically micro service from development to production there is this",
    "start": "1660890",
    "end": "1667940"
  },
  {
    "text": "big scheme of what we did that which is pretty detailed I won't get into that or",
    "start": "1667940",
    "end": "1674080"
  },
  {
    "text": "let you leave at 6 o'clock I'm just going to concentrate on the details of",
    "start": "1674080",
    "end": "1679640"
  },
  {
    "text": "deploy stage if you want to say the details of everything where it's also all documented on wiki so if you just",
    "start": "1679640",
    "end": "1686840"
  },
  {
    "text": "search with enough tenacity you will find all the documentation about this",
    "start": "1686840",
    "end": "1693070"
  },
  {
    "start": "1693000",
    "end": "1693000"
  },
  {
    "text": "let's just concentrate on deployments so as we said we have one namespace per",
    "start": "1693070",
    "end": "1698570"
  },
  {
    "text": "service basically and we will have several people which should be allowed to the product of that service but we",
    "start": "1698570",
    "end": "1704270"
  },
  {
    "text": "want people to be extracted from the problem of knowing the details of our kubernetes works so we use Elm which is",
    "start": "1704270",
    "end": "1712400"
  },
  {
    "text": "working very well for us I will it did we set up element production so that we",
    "start": "1712400",
    "end": "1717800"
  },
  {
    "text": "could secure registration as much as possible what we did is that we have one Taylor instance running in each",
    "start": "1717800",
    "end": "1726200"
  },
  {
    "text": "namespace with specific Arabic rules which are basically what they what is",
    "start": "1726200",
    "end": "1731980"
  },
  {
    "text": "suggested in guide from tiller apart from the fact that we also need to set up a networking rules for egress because",
    "start": "1731980",
    "end": "1739030"
  },
  {
    "text": "we basically white least the ability of a pod to call our pods to make connections to our pods and when we have",
    "start": "1739030",
    "end": "1746590"
  },
  {
    "text": "a deploy user which is just allowed by our buck to speak with tiller basically",
    "start": "1746590",
    "end": "1752620"
  },
  {
    "text": "so we only think that somebody that has we credentials for way the pro users can",
    "start": "1752620",
    "end": "1758140"
  },
  {
    "text": "do is use them basically on the cluster we can't use cube Caudill so we",
    "start": "1758140",
    "end": "1764950"
  },
  {
    "text": "restricted the user coop kado to administrators and normal the players just have to use them we don't have to",
    "start": "1764950",
    "end": "1770620"
  },
  {
    "text": "care about when treatises wait can basically shoot themselves in the foot with avocado all of this is implemented",
    "start": "1770620",
    "end": "1778090"
  },
  {
    "text": "with a seem very simple and kind of shameful at the moment Raptor around helm this rapper does some more things",
    "start": "1778090",
    "end": "1788140"
  },
  {
    "text": "we said we have to make primary data centers most things that we deploy all things that we deploy on kubernetes at",
    "start": "1788140",
    "end": "1794560"
  },
  {
    "text": "the moment are active active between two data centers so we want release to go to both data centers and this rapper does",
    "start": "1794560",
    "end": "1801430"
  },
  {
    "text": "that and also we are working at the moment we hope to be finished before the conference but we're not on doing",
    "start": "1801430",
    "end": "1808180"
  },
  {
    "text": "cannery releases the way we do it is pretty simple we just have we cheat basically we have two LM releases for",
    "start": "1808180",
    "end": "1815440"
  },
  {
    "text": "each practical degrees a canary release with a small set of replicas and when",
    "start": "1815440",
    "end": "1821080"
  },
  {
    "text": "production release but as larger set of replicas and the service definition but",
    "start": "1821080",
    "end": "1826420"
  },
  {
    "text": "the selectors to select all the pots from both releases whenever we do a new release we first really do Alan first",
    "start": "1826420",
    "end": "1833470"
  },
  {
    "text": "upgrades the canary release we check the metrics and vlogs to see if everything's",
    "start": "1833470",
    "end": "1839080"
  },
  {
    "text": "green we go on and approach of a production part so basically what we do is proper coloring the number of people",
    "start": "1839080",
    "end": "1846880"
  },
  {
    "text": "they are proportional to the amount of replicas in the tube class two clusters we get a new version for a small amount",
    "start": "1846880",
    "end": "1853030"
  },
  {
    "text": "of time and if we don't roll back after a few minutes everybody's getting the new version finally as I said it's a",
    "start": "1853030",
    "end": "1861070"
  },
  {
    "text": "shameful bash script at the moment what we plan to do is to try to rewrite everything including this part as an",
    "start": "1861070",
    "end": "1867429"
  },
  {
    "text": "plugins so that we can basically give service with a rest of the community",
    "start": "1867429",
    "end": "1873690"
  },
  {
    "text": "finally we have our very own and very new elm repo which at the moment that's",
    "start": "1873690",
    "end": "1879190"
  },
  {
    "text": "just one chart which is a public repo so that you anybody can run the services which we run in production using our and",
    "start": "1879190",
    "end": "1886119"
  },
  {
    "text": "charts in the future and where's the link and finally since we're almost done",
    "start": "1886119",
    "end": "1891970"
  },
  {
    "text": "and I think everybody's very tired at this point of a conference I want to thank you for sticking with us until",
    "start": "1891970",
    "end": "1897759"
  },
  {
    "text": "five o'clock and a shameful plug as I said our team is too small and we are hiring at the moment and I'm living this",
    "start": "1897759",
    "end": "1905590"
  },
  {
    "text": "slide because you have some links to the Fayetteville resources that you can consult remember we're a compounder",
    "start": "1905590",
    "end": "1911710"
  },
  {
    "text": "percent free software shop so everything we've talked about and everything we do is publicly available as free software",
    "start": "1911710",
    "end": "1918669"
  },
  {
    "text": "and you can take a look and even contribute if you want to so that",
    "start": "1918669",
    "end": "1924190"
  },
  {
    "text": "concludes our talk with a couple of minutes available and if somebody has questions we are here to answer them",
    "start": "1924190",
    "end": "1931870"
  },
  {
    "text": "[Applause]",
    "start": "1931870",
    "end": "1935240"
  },
  {
    "text": "[Music] [Applause]",
    "start": "1937780",
    "end": "1942869"
  },
  {
    "text": "the site said uh you were thinking about moving from docker to rocket what's",
    "start": "1955940",
    "end": "1961229"
  },
  {
    "text": "motivating that that mindset so the question is about why we evaluated",
    "start": "1961229",
    "end": "1967769"
  },
  {
    "text": "rocket I think rocket has some interesting characteristics the most interesting of which from our perspective is the",
    "start": "1967769",
    "end": "1974070"
  },
  {
    "text": "ability to use the TPM to verify the images and to check consistency we're",
    "start": "1974070",
    "end": "1980460"
  },
  {
    "text": "very concerned with security remember our site is a site that accepts arbitrary input both in text and binary",
    "start": "1980460",
    "end": "1987479"
  },
  {
    "text": "form because Wikimedia Commons accept binary forms as well so we have to be",
    "start": "1987479",
    "end": "1992519"
  },
  {
    "text": "very very careful with security and that was one thing that seemed appealing I don't think that the support for rocket",
    "start": "1992519",
    "end": "1999599"
  },
  {
    "text": "was there when we decided to deploy communities in production into kubernetes so we're stick with sticking",
    "start": "1999599",
    "end": "2006169"
  },
  {
    "text": "with docker for now and we have quite some tooling around docker we would have to adapt that rocket whenever we want to",
    "start": "2006169",
    "end": "2012830"
  },
  {
    "text": "do that you call the the session",
    "start": "2012830",
    "end": "2025899"
  },
  {
    "text": "installing on bare metal so you're installing the kubernetes or all your",
    "start": "2025899",
    "end": "2031279"
  },
  {
    "text": "Dockers on bare metal or on virtual machines now the virtual machines are",
    "start": "2031279",
    "end": "2037039"
  },
  {
    "text": "only the API servers everything else is bare metal",
    "start": "2037039",
    "end": "2041799"
  },
  {
    "text": "did you get a scoop yes yes so the",
    "start": "2045320",
    "end": "2050879"
  },
  {
    "text": "server physical servers are used for running pots and and all the applications basically okay I don't",
    "start": "2050880",
    "end": "2060990"
  },
  {
    "text": "think where if there are any other questions and see anybody because I'm right by the lights but if you have",
    "start": "2060990",
    "end": "2066090"
  },
  {
    "text": "questions we are just around for a few more minutes thank you again",
    "start": "2066090",
    "end": "2071379"
  },
  {
    "text": "[Applause]",
    "start": "2071380",
    "end": "2073558"
  }
]
[
  {
    "text": "okay thank you for being here for our",
    "start": "160",
    "end": "2320"
  },
  {
    "text": "presentation",
    "start": "2320",
    "end": "4160"
  },
  {
    "text": "here i'd like to start off by",
    "start": "4160",
    "end": "5839"
  },
  {
    "text": "introducing the team my name is",
    "start": "5839",
    "end": "9200"
  },
  {
    "text": "the team also has another member",
    "start": "9200",
    "end": "12799"
  },
  {
    "text": "we are both from vera octo office of the",
    "start": "12799",
    "end": "15599"
  },
  {
    "text": "cto outdoor belong to our one group",
    "start": "15599",
    "end": "18720"
  },
  {
    "text": "that's epg for the ones technological",
    "start": "18720",
    "end": "21199"
  },
  {
    "text": "group our group focuses on compatible",
    "start": "21199",
    "end": "24160"
  },
  {
    "text": "new communication through our bad",
    "start": "24160",
    "end": "26320"
  },
  {
    "text": "alignment and collaboration with our new",
    "start": "26320",
    "end": "29199"
  },
  {
    "text": "product team and even partner customer",
    "start": "29199",
    "end": "32960"
  },
  {
    "text": "basically we are trying to include",
    "start": "32960",
    "end": "35120"
  },
  {
    "text": "emerging technology solutions",
    "start": "35120",
    "end": "38800"
  },
  {
    "text": "back here today we're going to talk",
    "start": "38800",
    "end": "40640"
  },
  {
    "text": "about this empower heterogeneous energy",
    "start": "40640",
    "end": "43760"
  },
  {
    "text": "acceleration in kubernetes",
    "start": "43760",
    "end": "46079"
  },
  {
    "text": "is about accelerating hai on kubernetes",
    "start": "46079",
    "end": "51680"
  },
  {
    "text": "now let's go through today's agenda at",
    "start": "51680",
    "end": "54000"
  },
  {
    "text": "first i will talk some problem areas",
    "start": "54000",
    "end": "56960"
  },
  {
    "text": "while running ai to the edge and then",
    "start": "56960",
    "end": "59600"
  },
  {
    "text": "we'll talk about how to boost air at the",
    "start": "59600",
    "end": "62000"
  },
  {
    "text": "edge over next with our solution we also",
    "start": "62000",
    "end": "65360"
  },
  {
    "text": "have a demo",
    "start": "65360",
    "end": "66720"
  },
  {
    "text": "in the end what's next",
    "start": "66720",
    "end": "70320"
  },
  {
    "text": "talking about hdr i think most people",
    "start": "70960",
    "end": "73760"
  },
  {
    "text": "know machine learning area and also",
    "start": "73760",
    "end": "76159"
  },
  {
    "text": "heard at the compute we are facilitated",
    "start": "76159",
    "end": "78880"
  },
  {
    "text": "data processing and or near source our",
    "start": "78880",
    "end": "81280"
  },
  {
    "text": "data generation but what's aji",
    "start": "81280",
    "end": "85600"
  },
  {
    "text": "are processing that connected or created",
    "start": "85600",
    "end": "88799"
  },
  {
    "text": "on the device at the edge of our",
    "start": "88799",
    "end": "90799"
  },
  {
    "text": "networking but using artificial",
    "start": "90799",
    "end": "93119"
  },
  {
    "text": "intelligence as a result",
    "start": "93119",
    "end": "95040"
  },
  {
    "text": "for simply put hdr is a combination of",
    "start": "95040",
    "end": "98159"
  },
  {
    "text": "edge computing and artificial",
    "start": "98159",
    "end": "99680"
  },
  {
    "text": "intelligence",
    "start": "99680",
    "end": "101200"
  },
  {
    "text": "according to some reports hai in the",
    "start": "101200",
    "end": "103439"
  },
  {
    "text": "growing gravity",
    "start": "103439",
    "end": "105119"
  },
  {
    "text": "actually i believe or you can find many",
    "start": "105119",
    "end": "107119"
  },
  {
    "text": "other kissing around your life",
    "start": "107119",
    "end": "109439"
  },
  {
    "text": "however there are many challenges in",
    "start": "109439",
    "end": "111840"
  },
  {
    "text": "listening for a good implication of hdr",
    "start": "111840",
    "end": "114399"
  },
  {
    "text": "architecture",
    "start": "114399",
    "end": "116079"
  },
  {
    "text": "but usually machine learning tasks",
    "start": "116079",
    "end": "117840"
  },
  {
    "text": "require powerful ai hardware but many",
    "start": "117840",
    "end": "121439"
  },
  {
    "text": "led users are resource constrained and",
    "start": "121439",
    "end": "124399"
  },
  {
    "text": "they have limited install space or",
    "start": "124399",
    "end": "126399"
  },
  {
    "text": "limited power supply so it's harder to",
    "start": "126399",
    "end": "129200"
  },
  {
    "text": "enable machine learning on these edge",
    "start": "129200",
    "end": "131120"
  },
  {
    "text": "uic",
    "start": "131120",
    "end": "132640"
  },
  {
    "text": "variety of hdr accelerators have been",
    "start": "132640",
    "end": "135520"
  },
  {
    "text": "introduced but they are from different",
    "start": "135520",
    "end": "137840"
  },
  {
    "text": "vendors",
    "start": "137840",
    "end": "138879"
  },
  {
    "text": "so the architectures are heterogeneous",
    "start": "138879",
    "end": "142319"
  },
  {
    "text": "most upstream machine learning",
    "start": "142319",
    "end": "144000"
  },
  {
    "text": "frameworks such as tensorflow patterns",
    "start": "144000",
    "end": "147280"
  },
  {
    "text": "and so on do not support them directly",
    "start": "147280",
    "end": "150640"
  },
  {
    "text": "you have to send out sort of sdk or",
    "start": "150640",
    "end": "153120"
  },
  {
    "text": "toolkit to a user or maybe somewhere you",
    "start": "153120",
    "end": "156080"
  },
  {
    "text": "can find some machine learning",
    "start": "156080",
    "end": "157599"
  },
  {
    "text": "frameworks can support",
    "start": "157599",
    "end": "159519"
  },
  {
    "text": "some edi accelerator but they are",
    "start": "159519",
    "end": "161840"
  },
  {
    "text": "released and maintained by the hardware",
    "start": "161840",
    "end": "164319"
  },
  {
    "text": "vendor",
    "start": "164319",
    "end": "165920"
  },
  {
    "text": "and it's also difficult to get the best",
    "start": "165920",
    "end": "168480"
  },
  {
    "text": "performance on the hdr accelerator",
    "start": "168480",
    "end": "171280"
  },
  {
    "text": "because you should realize there are",
    "start": "171280",
    "end": "173200"
  },
  {
    "text": "many technologies potentially can be",
    "start": "173200",
    "end": "176239"
  },
  {
    "text": "optimized to accelerate machine learning",
    "start": "176239",
    "end": "178480"
  },
  {
    "text": "on this edge accelerator",
    "start": "178480",
    "end": "181360"
  },
  {
    "text": "in the meantime you know air and",
    "start": "181360",
    "end": "183440"
  },
  {
    "text": "emotional workload are the most popular",
    "start": "183440",
    "end": "185599"
  },
  {
    "text": "workload on kubernetes",
    "start": "185599",
    "end": "187840"
  },
  {
    "text": "now actually the edge user also expects",
    "start": "187840",
    "end": "190560"
  },
  {
    "text": "kubernetes will be the platform of",
    "start": "190560",
    "end": "192640"
  },
  {
    "text": "choice for running ai and machine",
    "start": "192640",
    "end": "194879"
  },
  {
    "text": "learning workloads at the edge",
    "start": "194879",
    "end": "197120"
  },
  {
    "text": "how can we unlock with the add ai",
    "start": "197120",
    "end": "201680"
  },
  {
    "text": "in our solution",
    "start": "201920",
    "end": "203440"
  },
  {
    "text": "we intend to meet those challenges by",
    "start": "203440",
    "end": "206159"
  },
  {
    "text": "building such and to animation and",
    "start": "206159",
    "end": "208400"
  },
  {
    "text": "implement service on kubernetes at the",
    "start": "208400",
    "end": "211760"
  },
  {
    "text": "well mostly it includes two key parts",
    "start": "211760",
    "end": "214560"
  },
  {
    "text": "one is booster motion influencer with",
    "start": "214560",
    "end": "217599"
  },
  {
    "text": "our backend acceleration mechanism",
    "start": "217599",
    "end": "220720"
  },
  {
    "text": "the other is to enable ci based",
    "start": "220720",
    "end": "223040"
  },
  {
    "text": "accelerator for selling unknown",
    "start": "223040",
    "end": "227560"
  },
  {
    "text": "okay um let's first talk about our",
    "start": "228400",
    "end": "230640"
  },
  {
    "text": "transparent backing acceleration",
    "start": "230640",
    "end": "233120"
  },
  {
    "text": "now here our goal is to build an",
    "start": "233120",
    "end": "235599"
  },
  {
    "text": "acceleration 7 system",
    "start": "235599",
    "end": "237760"
  },
  {
    "text": "the system is backing and automated so",
    "start": "237760",
    "end": "240080"
  },
  {
    "text": "this can work automatically the system",
    "start": "240080",
    "end": "242879"
  },
  {
    "text": "also had a unified software work so you",
    "start": "242879",
    "end": "246000"
  },
  {
    "text": "can easily integrate that to any",
    "start": "246000",
    "end": "247920"
  },
  {
    "text": "platform",
    "start": "247920",
    "end": "249360"
  },
  {
    "text": "we also enabled a lot of external",
    "start": "249360",
    "end": "252080"
  },
  {
    "text": "technology enabled our many id",
    "start": "252080",
    "end": "254640"
  },
  {
    "text": "accelerator",
    "start": "254640",
    "end": "256720"
  },
  {
    "text": "here once it was mentioning is that no",
    "start": "256720",
    "end": "259600"
  },
  {
    "text": "any code change to your application",
    "start": "259600",
    "end": "262479"
  },
  {
    "text": "written with those upstream motion",
    "start": "262479",
    "end": "265040"
  },
  {
    "text": "works",
    "start": "265040",
    "end": "266639"
  },
  {
    "text": "how can we make this happen",
    "start": "266639",
    "end": "269120"
  },
  {
    "text": "let's move on",
    "start": "269120",
    "end": "270800"
  },
  {
    "text": "here's the architecture",
    "start": "270800",
    "end": "272560"
  },
  {
    "text": "but you know we already integrated these",
    "start": "272560",
    "end": "274479"
  },
  {
    "text": "two kubernetes but here i leave this out",
    "start": "274479",
    "end": "277040"
  },
  {
    "text": "in order to explain that easily",
    "start": "277040",
    "end": "280000"
  },
  {
    "text": "overall as you see here when you find",
    "start": "280000",
    "end": "282160"
  },
  {
    "text": "multiple logic nodes each node has given",
    "start": "282160",
    "end": "285120"
  },
  {
    "text": "you a name",
    "start": "285120",
    "end": "287280"
  },
  {
    "text": "now basically we first deploy system",
    "start": "287280",
    "end": "289360"
  },
  {
    "text": "agent on your node this agent can help",
    "start": "289360",
    "end": "291919"
  },
  {
    "text": "connect some",
    "start": "291919",
    "end": "293440"
  },
  {
    "text": "necessary information including your",
    "start": "293440",
    "end": "295680"
  },
  {
    "text": "edge er accelerate on your platform and",
    "start": "295680",
    "end": "298080"
  },
  {
    "text": "your cpu type and we also want to know",
    "start": "298080",
    "end": "300720"
  },
  {
    "text": "if your cpu can support some special cpu",
    "start": "300720",
    "end": "303600"
  },
  {
    "text": "instruction like erx or ex2 or you know",
    "start": "303600",
    "end": "306880"
  },
  {
    "text": "in some cases where you will need",
    "start": "306880",
    "end": "309039"
  },
  {
    "text": "feature to accelerate motion inputs",
    "start": "309039",
    "end": "312800"
  },
  {
    "text": "and the manager of deploy runtime",
    "start": "312800",
    "end": "314880"
  },
  {
    "text": "serving with a default back acceleration",
    "start": "314880",
    "end": "318400"
  },
  {
    "text": "but the user can reconfigure that to",
    "start": "318400",
    "end": "320880"
  },
  {
    "text": "any acceleration technology and we are",
    "start": "320880",
    "end": "323280"
  },
  {
    "text": "supported on this platform through",
    "start": "323280",
    "end": "325199"
  },
  {
    "text": "controller",
    "start": "325199",
    "end": "326560"
  },
  {
    "text": "then manager injects interpolator to a",
    "start": "326560",
    "end": "329280"
  },
  {
    "text": "niche emotional improvement work on this",
    "start": "329280",
    "end": "331280"
  },
  {
    "text": "node once the users call any ai code on",
    "start": "331280",
    "end": "335199"
  },
  {
    "text": "this native machining",
    "start": "335199",
    "end": "337600"
  },
  {
    "text": "the one hand our interpol can help get",
    "start": "337600",
    "end": "340400"
  },
  {
    "text": "some data",
    "start": "340400",
    "end": "342080"
  },
  {
    "text": "including model or model info",
    "start": "342080",
    "end": "344720"
  },
  {
    "text": "and our",
    "start": "344720",
    "end": "346080"
  },
  {
    "text": "auto compiler can compare this print",
    "start": "346080",
    "end": "348800"
  },
  {
    "text": "trainer model to a one given",
    "start": "348800",
    "end": "351039"
  },
  {
    "text": "intermediate reputation specifically to",
    "start": "351039",
    "end": "353600"
  },
  {
    "text": "this uh back and forth acceleration",
    "start": "353600",
    "end": "355759"
  },
  {
    "text": "technology",
    "start": "355759",
    "end": "357120"
  },
  {
    "text": "and even cache and store that",
    "start": "357120",
    "end": "359520"
  },
  {
    "text": "on the other hand um interpolant can",
    "start": "359520",
    "end": "361919"
  },
  {
    "text": "intercept that api i will do emotionally",
    "start": "361919",
    "end": "364720"
  },
  {
    "text": "influence caused by this native",
    "start": "364720",
    "end": "366560"
  },
  {
    "text": "emotionally good work",
    "start": "366560",
    "end": "368240"
  },
  {
    "text": "instead we use our bacon accessory",
    "start": "368240",
    "end": "371039"
  },
  {
    "text": "technology to do real machine influence",
    "start": "371039",
    "end": "373680"
  },
  {
    "text": "with that pre-compiled intermediate",
    "start": "373680",
    "end": "375919"
  },
  {
    "text": "gravitation and then get that result and",
    "start": "375919",
    "end": "378960"
  },
  {
    "text": "output back to our major machinery will",
    "start": "378960",
    "end": "381600"
  },
  {
    "text": "work that's it",
    "start": "381600",
    "end": "384800"
  },
  {
    "text": "hey i'd like to elaborate a bit of our",
    "start": "386000",
    "end": "388560"
  },
  {
    "text": "long-term interposer essentially it's",
    "start": "388560",
    "end": "390880"
  },
  {
    "text": "targeted to our eps mapping",
    "start": "390880",
    "end": "393759"
  },
  {
    "text": "it's more like a mapping between machine",
    "start": "393759",
    "end": "395840"
  },
  {
    "text": "learning upstream works to our backhand",
    "start": "395840",
    "end": "398800"
  },
  {
    "text": "accelerating technology",
    "start": "398800",
    "end": "400960"
  },
  {
    "text": "example is on tensorflow on one typical",
    "start": "400960",
    "end": "403840"
  },
  {
    "text": "person code often called some api like",
    "start": "403840",
    "end": "406560"
  },
  {
    "text": "load mode under the grids to generate",
    "start": "406560",
    "end": "408720"
  },
  {
    "text": "the graph",
    "start": "408720",
    "end": "409919"
  },
  {
    "text": "and turn another api predicted to our",
    "start": "409919",
    "end": "412479"
  },
  {
    "text": "machining difference here we use some",
    "start": "412479",
    "end": "414880"
  },
  {
    "text": "passion chips to redirect and know the",
    "start": "414880",
    "end": "417440"
  },
  {
    "text": "model to our customer and model",
    "start": "417440",
    "end": "419680"
  },
  {
    "text": "predicted to our customized predicts to",
    "start": "419680",
    "end": "422479"
  },
  {
    "text": "our work this out",
    "start": "422479",
    "end": "424479"
  },
  {
    "text": "we also support cr plus plus in this",
    "start": "424479",
    "end": "426960"
  },
  {
    "text": "case we um pre-compile our handler into",
    "start": "426960",
    "end": "430880"
  },
  {
    "text": "a shared object library",
    "start": "430880",
    "end": "433199"
  },
  {
    "text": "and in the wrong time",
    "start": "433199",
    "end": "434720"
  },
  {
    "text": "we hijack the motion learning framework",
    "start": "434720",
    "end": "437599"
  },
  {
    "text": "process to a load data model and",
    "start": "437599",
    "end": "440160"
  },
  {
    "text": "operation api to our handler to make",
    "start": "440160",
    "end": "444000"
  },
  {
    "text": "this out",
    "start": "444000",
    "end": "446560"
  },
  {
    "text": "a summary of these parts now we can",
    "start": "448880",
    "end": "451840"
  },
  {
    "text": "support several upstream machine",
    "start": "451840",
    "end": "453759"
  },
  {
    "text": "learning frameworks tensorflow patterns",
    "start": "453759",
    "end": "457039"
  },
  {
    "text": "onyx and close to a tensorflow 7 system",
    "start": "457039",
    "end": "460639"
  },
  {
    "text": "there are a few vacant acceleration",
    "start": "460639",
    "end": "462560"
  },
  {
    "text": "technologies available in our system",
    "start": "462560",
    "end": "465039"
  },
  {
    "text": "including pvm intel openvino ah",
    "start": "465039",
    "end": "468080"
  },
  {
    "text": "immediate tensor rt",
    "start": "468080",
    "end": "469840"
  },
  {
    "text": "we also enabled those popular ai",
    "start": "469840",
    "end": "472080"
  },
  {
    "text": "accelerator intel movies vpu google edge",
    "start": "472080",
    "end": "475599"
  },
  {
    "text": "tpu",
    "start": "475599",
    "end": "476639"
  },
  {
    "text": "media edge gpu we also leverage some",
    "start": "476639",
    "end": "479840"
  },
  {
    "text": "technology",
    "start": "479840",
    "end": "481199"
  },
  {
    "text": "like remote cuda to connect the gpu to",
    "start": "481199",
    "end": "484479"
  },
  {
    "text": "any x device to a machine difference in",
    "start": "484479",
    "end": "487440"
  },
  {
    "text": "some cases are we using cpu to",
    "start": "487440",
    "end": "489360"
  },
  {
    "text": "accelerate motion immigrants",
    "start": "489360",
    "end": "491680"
  },
  {
    "text": "okay",
    "start": "491680",
    "end": "493199"
  },
  {
    "text": "how to enable this transparent backhand",
    "start": "493199",
    "end": "496319"
  },
  {
    "text": "acceleration to our kubernetes ipad",
    "start": "496319",
    "end": "498800"
  },
  {
    "text": "tools",
    "start": "498800",
    "end": "501198"
  },
  {
    "text": "thanks tijin hi everyone my name is",
    "start": "502639",
    "end": "505360"
  },
  {
    "text": "zitong and i'm part of the project team",
    "start": "505360",
    "end": "507919"
  },
  {
    "text": "from william we're going to china octo",
    "start": "507919",
    "end": "509919"
  },
  {
    "text": "department",
    "start": "509919",
    "end": "511680"
  },
  {
    "text": "as tiage mentioned earlier in the",
    "start": "511680",
    "end": "513760"
  },
  {
    "text": "solution section i will be providing",
    "start": "513760",
    "end": "516159"
  },
  {
    "text": "more details about solutions for",
    "start": "516159",
    "end": "518399"
  },
  {
    "text": "deploying end-to-end machine learning",
    "start": "518399",
    "end": "520719"
  },
  {
    "text": "workflows based on kubernetes",
    "start": "520719",
    "end": "525279"
  },
  {
    "text": "when doing machine learning customers",
    "start": "526160",
    "end": "528480"
  },
  {
    "text": "want to have a consistent kubernetes",
    "start": "528480",
    "end": "531279"
  },
  {
    "text": "platform to deploy and management the",
    "start": "531279",
    "end": "534399"
  },
  {
    "text": "machine learning workflow",
    "start": "534399",
    "end": "536240"
  },
  {
    "text": "and make use of ai hardware accelerators",
    "start": "536240",
    "end": "540000"
  },
  {
    "text": "on the edge for grid performance",
    "start": "540000",
    "end": "543519"
  },
  {
    "text": "here we mainly combine several popular",
    "start": "543519",
    "end": "546320"
  },
  {
    "text": "technologies",
    "start": "546320",
    "end": "548160"
  },
  {
    "text": "the first one is node feature discovery",
    "start": "548160",
    "end": "552959"
  },
  {
    "text": "as name implies",
    "start": "552959",
    "end": "554800"
  },
  {
    "text": "it is used to detect hardware features",
    "start": "554800",
    "end": "558000"
  },
  {
    "text": "on each node in the kubernetes cluster",
    "start": "558000",
    "end": "561279"
  },
  {
    "text": "and use node labels to advertise these",
    "start": "561279",
    "end": "564480"
  },
  {
    "text": "features",
    "start": "564480",
    "end": "565600"
  },
  {
    "text": "we use it to do detection of pci devices",
    "start": "565600",
    "end": "570080"
  },
  {
    "text": "and usb devices on the node",
    "start": "570080",
    "end": "573519"
  },
  {
    "text": "the second one is device plugin",
    "start": "573519",
    "end": "576720"
  },
  {
    "text": "which is a framework from kubernetes",
    "start": "576720",
    "end": "579760"
  },
  {
    "text": "that you can use to advertise system",
    "start": "579760",
    "end": "582640"
  },
  {
    "text": "hardware resources to the kuberleat",
    "start": "582640",
    "end": "586240"
  },
  {
    "text": "we will use them to register and",
    "start": "586240",
    "end": "589680"
  },
  {
    "text": "publish hardware resources on the notes",
    "start": "589680",
    "end": "592720"
  },
  {
    "text": "to the corporate for scheduler to",
    "start": "592720",
    "end": "595360"
  },
  {
    "text": "schedule",
    "start": "595360",
    "end": "597839"
  },
  {
    "text": "currently kubernetes already provided",
    "start": "597920",
    "end": "600880"
  },
  {
    "text": "some official implementation examples",
    "start": "600880",
    "end": "604240"
  },
  {
    "text": "for amd gpu nvidia gpu intel gpu vpo",
    "start": "604240",
    "end": "609839"
  },
  {
    "text": "fpga and etc",
    "start": "609839",
    "end": "613680"
  },
  {
    "text": "openvino runtime plugins also enables",
    "start": "613680",
    "end": "617120"
  },
  {
    "text": "inference of",
    "start": "617120",
    "end": "618560"
  },
  {
    "text": "deep learning models on some supported",
    "start": "618560",
    "end": "621920"
  },
  {
    "text": "vpu gpu devices such as",
    "start": "621920",
    "end": "625040"
  },
  {
    "text": "intel neural compute stick",
    "start": "625040",
    "end": "628320"
  },
  {
    "text": "intel mobile ds",
    "start": "628320",
    "end": "630320"
  },
  {
    "text": "vpos",
    "start": "630320",
    "end": "632240"
  },
  {
    "text": "we should note that intel kubernetes",
    "start": "632240",
    "end": "635200"
  },
  {
    "text": "device plugins just support many new bpu",
    "start": "635200",
    "end": "639360"
  },
  {
    "text": "cards and does not support the old",
    "start": "639360",
    "end": "641600"
  },
  {
    "text": "device like",
    "start": "641600",
    "end": "643040"
  },
  {
    "text": "ncs1",
    "start": "643040",
    "end": "644560"
  },
  {
    "text": "thus we did an investigation on",
    "start": "644560",
    "end": "647360"
  },
  {
    "text": "deploying on openvino vpo plugins",
    "start": "647360",
    "end": "652640"
  },
  {
    "text": "then we also use some kubernetes",
    "start": "653360",
    "end": "656480"
  },
  {
    "text": "features like node selector",
    "start": "656480",
    "end": "659440"
  },
  {
    "text": "which is the simplest recommended way of",
    "start": "659440",
    "end": "663200"
  },
  {
    "text": "node selection constraints",
    "start": "663200",
    "end": "666079"
  },
  {
    "text": "which",
    "start": "666079",
    "end": "666880"
  },
  {
    "text": "also is a field of prospect that can",
    "start": "666880",
    "end": "670480"
  },
  {
    "text": "make this part work on a specific node",
    "start": "670480",
    "end": "675360"
  },
  {
    "text": "finally kubernetes scheduler will assign",
    "start": "675360",
    "end": "678800"
  },
  {
    "text": "other machine learning paths to work on",
    "start": "678800",
    "end": "681760"
  },
  {
    "text": "the targeted node",
    "start": "681760",
    "end": "684240"
  },
  {
    "text": "according to the registered information",
    "start": "684240",
    "end": "687279"
  },
  {
    "text": "as mentioned before",
    "start": "687279",
    "end": "690480"
  },
  {
    "text": "by integrating the above popular",
    "start": "691440",
    "end": "693920"
  },
  {
    "text": "technologies we designed an end-to-end",
    "start": "693920",
    "end": "697200"
  },
  {
    "text": "machine learning framework solution",
    "start": "697200",
    "end": "699360"
  },
  {
    "text": "which greatly reduced the complexity of",
    "start": "699360",
    "end": "702560"
  },
  {
    "text": "environment configurations for users",
    "start": "702560",
    "end": "706000"
  },
  {
    "text": "when using heterogeneous hardware",
    "start": "706000",
    "end": "708800"
  },
  {
    "text": "accelerators",
    "start": "708800",
    "end": "710639"
  },
  {
    "text": "and improves the efficiency",
    "start": "710639",
    "end": "715200"
  },
  {
    "text": "at the same time users just to need to",
    "start": "715200",
    "end": "718800"
  },
  {
    "text": "use the basic kubernetes command lines",
    "start": "718800",
    "end": "721760"
  },
  {
    "text": "to manage edge accelerators with the",
    "start": "721760",
    "end": "724639"
  },
  {
    "text": "help of",
    "start": "724639",
    "end": "726079"
  },
  {
    "text": "back-end acceleration technologies",
    "start": "726079",
    "end": "728880"
  },
  {
    "text": "such as",
    "start": "728880",
    "end": "730480"
  },
  {
    "text": "apache tvm which is an open source",
    "start": "730480",
    "end": "733839"
  },
  {
    "text": "machine learning compiler framework for",
    "start": "733839",
    "end": "736880"
  },
  {
    "text": "cpus gpus and machine learning",
    "start": "736880",
    "end": "739920"
  },
  {
    "text": "accelerators",
    "start": "739920",
    "end": "741839"
  },
  {
    "text": "we also exploit intel open window tour",
    "start": "741839",
    "end": "745839"
  },
  {
    "text": "kate or nvidia tensority as back-end",
    "start": "745839",
    "end": "749279"
  },
  {
    "text": "acceleration technologies",
    "start": "749279",
    "end": "751839"
  },
  {
    "text": "by adopting them customers can boast",
    "start": "751839",
    "end": "755360"
  },
  {
    "text": "their machine learning tasks in the",
    "start": "755360",
    "end": "758639"
  },
  {
    "text": "clusters without any native code change",
    "start": "758639",
    "end": "763920"
  },
  {
    "text": "okay now let's move on to the next",
    "start": "763920",
    "end": "766399"
  },
  {
    "text": "slides and take a look at the overall",
    "start": "766399",
    "end": "768959"
  },
  {
    "text": "architecture",
    "start": "768959",
    "end": "771670"
  },
  {
    "text": "[Music]",
    "start": "771670",
    "end": "774870"
  },
  {
    "text": "here assume customers have a management",
    "start": "775600",
    "end": "779279"
  },
  {
    "text": "cluster and they have several hosts",
    "start": "779279",
    "end": "782639"
  },
  {
    "text": "equipped with heterogeneous ai",
    "start": "782639",
    "end": "786000"
  },
  {
    "text": "accelerators",
    "start": "786000",
    "end": "787600"
  },
  {
    "text": "they can easily manage and take",
    "start": "787600",
    "end": "790079"
  },
  {
    "text": "advantage of them by adding them to",
    "start": "790079",
    "end": "792320"
  },
  {
    "text": "kubernetes clusters",
    "start": "792320",
    "end": "794959"
  },
  {
    "text": "as you see we have two worker nodes",
    "start": "794959",
    "end": "799279"
  },
  {
    "text": "where the left one represents a general",
    "start": "799279",
    "end": "802320"
  },
  {
    "text": "structure where the red one",
    "start": "802320",
    "end": "805040"
  },
  {
    "text": "illustrates a",
    "start": "805040",
    "end": "807279"
  },
  {
    "text": "specific example for nvidia gpu",
    "start": "807279",
    "end": "811920"
  },
  {
    "text": "in general process firstly we adopt node",
    "start": "812320",
    "end": "816560"
  },
  {
    "text": "feature discovery and make it works as a",
    "start": "816560",
    "end": "819440"
  },
  {
    "text": "democrat on every node",
    "start": "819440",
    "end": "821760"
  },
  {
    "text": "and we know node feature discovery leads",
    "start": "821760",
    "end": "825199"
  },
  {
    "text": "pci usb ids in the node labels to",
    "start": "825199",
    "end": "829440"
  },
  {
    "text": "represent the device edge devices",
    "start": "829440",
    "end": "833199"
  },
  {
    "text": "here we can see in the right side",
    "start": "833199",
    "end": "835440"
  },
  {
    "text": "example the node label is a number",
    "start": "835440",
    "end": "838720"
  },
  {
    "text": "series which is hard for users to",
    "start": "838720",
    "end": "841040"
  },
  {
    "text": "distinguish device names immediately",
    "start": "841040",
    "end": "844399"
  },
  {
    "text": "thus we have simplified this step by",
    "start": "844399",
    "end": "847199"
  },
  {
    "text": "adding a myping function",
    "start": "847199",
    "end": "849839"
  },
  {
    "text": "which can automatically translate and",
    "start": "849839",
    "end": "853600"
  },
  {
    "text": "translate the discover device ids into",
    "start": "853600",
    "end": "857040"
  },
  {
    "text": "human readable classes",
    "start": "857040",
    "end": "859360"
  },
  {
    "text": "wonders and device names",
    "start": "859360",
    "end": "862959"
  },
  {
    "text": "in the example the digital series has",
    "start": "862959",
    "end": "865760"
  },
  {
    "text": "been automatically translated to the",
    "start": "865760",
    "end": "868480"
  },
  {
    "text": "specific nvidia gpu cards as you can see",
    "start": "868480",
    "end": "871600"
  },
  {
    "text": "in the left side",
    "start": "871600",
    "end": "873440"
  },
  {
    "text": "which is geforce jt 710",
    "start": "873440",
    "end": "878160"
  },
  {
    "text": "next by adding the specific device",
    "start": "878320",
    "end": "881360"
  },
  {
    "text": "labels in the node label field the",
    "start": "881360",
    "end": "884480"
  },
  {
    "text": "customers can efficiently deploy device",
    "start": "884480",
    "end": "887360"
  },
  {
    "text": "plugins demonstrate only on the node",
    "start": "887360",
    "end": "890320"
  },
  {
    "text": "with targeted devices",
    "start": "890320",
    "end": "893199"
  },
  {
    "text": "upon the startup the device plugins will",
    "start": "893199",
    "end": "896959"
  },
  {
    "text": "report and register",
    "start": "896959",
    "end": "899839"
  },
  {
    "text": "hardware resources to the device plugin",
    "start": "899839",
    "end": "902959"
  },
  {
    "text": "manager incorporate",
    "start": "902959",
    "end": "905920"
  },
  {
    "text": "and then starts the",
    "start": "905920",
    "end": "908480"
  },
  {
    "text": "grpc server for kuberlate to excise",
    "start": "908480",
    "end": "912959"
  },
  {
    "text": "next corporate will establish",
    "start": "912959",
    "end": "915920"
  },
  {
    "text": "the listen and watch link to get the",
    "start": "915920",
    "end": "918320"
  },
  {
    "text": "device id",
    "start": "918320",
    "end": "919760"
  },
  {
    "text": "and provide a health check",
    "start": "919760",
    "end": "924320"
  },
  {
    "text": "in the end kubulate will update the",
    "start": "924320",
    "end": "927519"
  },
  {
    "text": "device information to the node status",
    "start": "927519",
    "end": "931120"
  },
  {
    "text": "and wait",
    "start": "931120",
    "end": "932320"
  },
  {
    "text": "for",
    "start": "932320",
    "end": "933199"
  },
  {
    "text": "further scheduling",
    "start": "933199",
    "end": "935680"
  },
  {
    "text": "i will be providing a clear device",
    "start": "935680",
    "end": "938800"
  },
  {
    "text": "plugin precise in the upcoming demo part",
    "start": "938800",
    "end": "944639"
  },
  {
    "text": "after successfully deploying device",
    "start": "946959",
    "end": "949519"
  },
  {
    "text": "plugin demon sites we can start to",
    "start": "949519",
    "end": "952800"
  },
  {
    "text": "create machine learning parts",
    "start": "952800",
    "end": "955759"
  },
  {
    "text": "here we can provide ready to build",
    "start": "955759",
    "end": "958880"
  },
  {
    "text": "docker files",
    "start": "958880",
    "end": "960639"
  },
  {
    "text": "which include everything you need to run",
    "start": "960639",
    "end": "963839"
  },
  {
    "text": "machine learning tasks",
    "start": "963839",
    "end": "965839"
  },
  {
    "text": "with the backend acceleration",
    "start": "965839",
    "end": "968240"
  },
  {
    "text": "interposers",
    "start": "968240",
    "end": "970639"
  },
  {
    "text": "for example",
    "start": "970639",
    "end": "972240"
  },
  {
    "text": "apache tvm intel openvino and nvidia",
    "start": "972240",
    "end": "976880"
  },
  {
    "text": "tensority",
    "start": "976880",
    "end": "978639"
  },
  {
    "text": "and the necessary environment for",
    "start": "978639",
    "end": "980880"
  },
  {
    "text": "interposing mechanism hardware",
    "start": "980880",
    "end": "983600"
  },
  {
    "text": "configurations and etc",
    "start": "983600",
    "end": "986560"
  },
  {
    "text": "it will create an image on the worker",
    "start": "986560",
    "end": "989279"
  },
  {
    "text": "node for users to run their native",
    "start": "989279",
    "end": "992320"
  },
  {
    "text": "inference codes with different ad",
    "start": "992320",
    "end": "994480"
  },
  {
    "text": "devices in the container",
    "start": "994480",
    "end": "998240"
  },
  {
    "text": "overall this solution not only provides",
    "start": "998240",
    "end": "1001920"
  },
  {
    "text": "customers with small edge device",
    "start": "1001920",
    "end": "1005040"
  },
  {
    "text": "selections but also greatly shortens the",
    "start": "1005040",
    "end": "1008560"
  },
  {
    "text": "user's learning time",
    "start": "1008560",
    "end": "1010720"
  },
  {
    "text": "for",
    "start": "1010720",
    "end": "1011600"
  },
  {
    "text": "wasetor",
    "start": "1011600",
    "end": "1013279"
  },
  {
    "text": "backend interposers",
    "start": "1013279",
    "end": "1016880"
  },
  {
    "text": "now let's head to the demonstration part",
    "start": "1016880",
    "end": "1022360"
  },
  {
    "text": "firstly check nodes in kubernetes",
    "start": "1028640",
    "end": "1031280"
  },
  {
    "text": "cluster",
    "start": "1031280",
    "end": "1033760"
  },
  {
    "text": "here we can see we already deployed the",
    "start": "1036160",
    "end": "1039038"
  },
  {
    "text": "node feature discovery demonstrate on",
    "start": "1039039",
    "end": "1041199"
  },
  {
    "text": "each node and we have four worker nodes",
    "start": "1041199",
    "end": "1046319"
  },
  {
    "text": "we can check the node labels by using",
    "start": "1048000",
    "end": "1051200"
  },
  {
    "text": "this kubernetes command line",
    "start": "1051200",
    "end": "1055519"
  },
  {
    "text": "we have heterogeneous hardware backends",
    "start": "1056240",
    "end": "1059039"
  },
  {
    "text": "with human readable device names in our",
    "start": "1059039",
    "end": "1061840"
  },
  {
    "text": "environment for example nvidia gpu intel",
    "start": "1061840",
    "end": "1065679"
  },
  {
    "text": "cpu",
    "start": "1065679",
    "end": "1067039"
  },
  {
    "text": "intel mirade vpo google htpo intel gpo",
    "start": "1067039",
    "end": "1072559"
  },
  {
    "text": "and amd gpu",
    "start": "1072559",
    "end": "1074799"
  },
  {
    "text": "then we can check gpu capacity on each",
    "start": "1074799",
    "end": "1077440"
  },
  {
    "text": "node",
    "start": "1077440",
    "end": "1080440"
  },
  {
    "text": "here we can see the nvidia gpu has not",
    "start": "1083840",
    "end": "1086160"
  },
  {
    "text": "been registered",
    "start": "1086160",
    "end": "1089280"
  },
  {
    "text": "now checking the node with amd gpu",
    "start": "1090160",
    "end": "1095840"
  },
  {
    "text": "the amd gpu has not been registered",
    "start": "1102480",
    "end": "1106880"
  },
  {
    "text": "and deploy device plugin demon site",
    "start": "1106880",
    "end": "1111360"
  },
  {
    "text": "here we add the node selector with the",
    "start": "1115280",
    "end": "1117600"
  },
  {
    "text": "node label",
    "start": "1117600",
    "end": "1120919"
  },
  {
    "text": "the amd device labels to the node",
    "start": "1122480",
    "end": "1124960"
  },
  {
    "text": "selector field",
    "start": "1124960",
    "end": "1128000"
  },
  {
    "text": "then create nvidia gpu device plugin",
    "start": "1128799",
    "end": "1131280"
  },
  {
    "text": "demon site",
    "start": "1131280",
    "end": "1133919"
  },
  {
    "text": "and create amd gpu device plugin demon",
    "start": "1135520",
    "end": "1138400"
  },
  {
    "text": "site",
    "start": "1138400",
    "end": "1140720"
  },
  {
    "text": "demon sites are successfully deployed on",
    "start": "1142240",
    "end": "1144640"
  },
  {
    "text": "the proper node",
    "start": "1144640",
    "end": "1147600"
  },
  {
    "text": "then we can check the gpu capacity on",
    "start": "1149600",
    "end": "1152000"
  },
  {
    "text": "each node again",
    "start": "1152000",
    "end": "1154880"
  },
  {
    "text": "here we can see nvidia gpu has been",
    "start": "1160559",
    "end": "1163039"
  },
  {
    "text": "registered",
    "start": "1163039",
    "end": "1165840"
  },
  {
    "text": "and the amd gpu has been registered too",
    "start": "1167360",
    "end": "1172880"
  },
  {
    "text": "then we can start deploying inference",
    "start": "1174799",
    "end": "1177280"
  },
  {
    "text": "parts",
    "start": "1177280",
    "end": "1179840"
  },
  {
    "text": "in the demonstration we will use tvm",
    "start": "1182960",
    "end": "1185280"
  },
  {
    "text": "intervals as an example",
    "start": "1185280",
    "end": "1187679"
  },
  {
    "text": "then we can create inference part of",
    "start": "1187679",
    "end": "1190320"
  },
  {
    "text": "nvidia gpu",
    "start": "1190320",
    "end": "1192400"
  },
  {
    "text": "and our amd gpu",
    "start": "1192400",
    "end": "1195280"
  },
  {
    "text": "and on an intel cpu",
    "start": "1195280",
    "end": "1199200"
  },
  {
    "text": "then we can view the path status",
    "start": "1203919",
    "end": "1207840"
  },
  {
    "text": "here the inference parts are assigned to",
    "start": "1209679",
    "end": "1212159"
  },
  {
    "text": "the corresponding nodes",
    "start": "1212159",
    "end": "1216200"
  },
  {
    "text": "then we can run tvm interpol inference",
    "start": "1220080",
    "end": "1222960"
  },
  {
    "text": "demo on",
    "start": "1222960",
    "end": "1224320"
  },
  {
    "text": "nvidia gpu node",
    "start": "1224320",
    "end": "1228360"
  },
  {
    "text": "this is customer local inference code",
    "start": "1243200",
    "end": "1245600"
  },
  {
    "text": "for machine learning influence",
    "start": "1245600",
    "end": "1249799"
  },
  {
    "text": "then we can enable the tvm interpol's",
    "start": "1251840",
    "end": "1254559"
  },
  {
    "text": "backend server",
    "start": "1254559",
    "end": "1257520"
  },
  {
    "text": "in another terminal we can run inference",
    "start": "1258559",
    "end": "1260960"
  },
  {
    "text": "demo for resonant 50 we want model",
    "start": "1260960",
    "end": "1265280"
  },
  {
    "text": "here we can see we triggered cache",
    "start": "1265280",
    "end": "1267840"
  },
  {
    "text": "mechanism",
    "start": "1267840",
    "end": "1270640"
  },
  {
    "text": "we can run pvm",
    "start": "1273520",
    "end": "1275440"
  },
  {
    "text": "inference demo on amd gpu node",
    "start": "1275440",
    "end": "1279759"
  },
  {
    "text": "enable the backend compiler",
    "start": "1280559",
    "end": "1284320"
  },
  {
    "text": "see the target is rcom",
    "start": "1284720",
    "end": "1288320"
  },
  {
    "text": "in another terminal we can run inference",
    "start": "1289360",
    "end": "1291760"
  },
  {
    "text": "demo for resonate 50 we want model",
    "start": "1291760",
    "end": "1296919"
  },
  {
    "text": "okay as time consideration here we just",
    "start": "1320480",
    "end": "1323919"
  },
  {
    "text": "showed the tvm example but if you're",
    "start": "1323919",
    "end": "1326480"
  },
  {
    "text": "interested in other backend interposers",
    "start": "1326480",
    "end": "1329039"
  },
  {
    "text": "such as openvino please feel free to",
    "start": "1329039",
    "end": "1331600"
  },
  {
    "text": "contact us",
    "start": "1331600",
    "end": "1333520"
  },
  {
    "text": "okay let's move on to the next sled",
    "start": "1333520",
    "end": "1337600"
  },
  {
    "text": "this slide shows the performance",
    "start": "1338640",
    "end": "1340720"
  },
  {
    "text": "corresponding to the demo",
    "start": "1340720",
    "end": "1342720"
  },
  {
    "text": "we have compared the inference time",
    "start": "1342720",
    "end": "1345520"
  },
  {
    "text": "between the tvm interposer enabled and",
    "start": "1345520",
    "end": "1349200"
  },
  {
    "text": "the tvm interposer disabled for",
    "start": "1349200",
    "end": "1352080"
  },
  {
    "text": "different modules such as resonate 50",
    "start": "1352080",
    "end": "1355840"
  },
  {
    "text": "resonate 101",
    "start": "1355840",
    "end": "1358480"
  },
  {
    "text": "mobile nate we want trained by cipher",
    "start": "1358480",
    "end": "1361440"
  },
  {
    "text": "data site and",
    "start": "1361440",
    "end": "1363520"
  },
  {
    "text": "imaginate data site mobile nate way2",
    "start": "1363520",
    "end": "1368000"
  },
  {
    "text": "on different hardware accelerators such",
    "start": "1368000",
    "end": "1370559"
  },
  {
    "text": "as",
    "start": "1370559",
    "end": "1371679"
  },
  {
    "text": "nvidia gpu and emd gpu",
    "start": "1371679",
    "end": "1375280"
  },
  {
    "text": "in our testing the tvm interpose",
    "start": "1375280",
    "end": "1378799"
  },
  {
    "text": "performs as well as tvm",
    "start": "1378799",
    "end": "1381440"
  },
  {
    "text": "and generally accelerated the machine",
    "start": "1381440",
    "end": "1384400"
  },
  {
    "text": "learning inference time",
    "start": "1384400",
    "end": "1388360"
  },
  {
    "text": "here we can see in the left hand side",
    "start": "1388720",
    "end": "1391679"
  },
  {
    "text": "for nvidia the best case is the mobile",
    "start": "1391679",
    "end": "1395120"
  },
  {
    "text": "network module",
    "start": "1395120",
    "end": "1396960"
  },
  {
    "text": "where with our backend acceleration",
    "start": "1396960",
    "end": "1399360"
  },
  {
    "text": "mechanism the inference is eight times",
    "start": "1399360",
    "end": "1402880"
  },
  {
    "text": "faster",
    "start": "1402880",
    "end": "1405440"
  },
  {
    "text": "for amd gpu the best case is also the",
    "start": "1405840",
    "end": "1409120"
  },
  {
    "text": "mobile network model",
    "start": "1409120",
    "end": "1411200"
  },
  {
    "text": "which has been accelerated 19 times",
    "start": "1411200",
    "end": "1415760"
  },
  {
    "text": "and",
    "start": "1415760",
    "end": "1416480"
  },
  {
    "text": "we believe this will even perform better",
    "start": "1416480",
    "end": "1419280"
  },
  {
    "text": "on newer accelerator cards",
    "start": "1419280",
    "end": "1423279"
  },
  {
    "text": "okay that's it for my presentation part",
    "start": "1424640",
    "end": "1427440"
  },
  {
    "text": "and i'd like to hand over to teejing",
    "start": "1427440",
    "end": "1429679"
  },
  {
    "text": "again thank you",
    "start": "1429679",
    "end": "1431520"
  },
  {
    "text": "well thanks also okay the last part was",
    "start": "1431520",
    "end": "1434240"
  },
  {
    "text": "our next now we want to support more",
    "start": "1434240",
    "end": "1436480"
  },
  {
    "text": "machine learning works and more",
    "start": "1436480",
    "end": "1438240"
  },
  {
    "text": "commercially solar system in production",
    "start": "1438240",
    "end": "1440880"
  },
  {
    "text": "we also need to be able to edge network",
    "start": "1440880",
    "end": "1444320"
  },
  {
    "text": "next version um when they are we will",
    "start": "1444320",
    "end": "1447440"
  },
  {
    "text": "make this adder open source",
    "start": "1447440",
    "end": "1450799"
  },
  {
    "text": "okay now that's all please feel free to",
    "start": "1450880",
    "end": "1453760"
  },
  {
    "text": "reach out to us if you have any question",
    "start": "1453760",
    "end": "1456320"
  },
  {
    "text": "and feedback thank you",
    "start": "1456320",
    "end": "1459840"
  }
]
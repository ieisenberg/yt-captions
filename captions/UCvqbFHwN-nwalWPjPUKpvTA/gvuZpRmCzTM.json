[
  {
    "start": "0",
    "end": "44000"
  },
  {
    "text": "hello hello hello how's everybody doing good good Friday afternoon Friday",
    "start": "30",
    "end": "6270"
  },
  {
    "text": "afternoon I just spoke next door I had to run over I'm sorry for being a minute late so let's get started come take a",
    "start": "6270",
    "end": "12179"
  },
  {
    "text": "seat all right I'm talking about a topic here with joy today that I'm really excited",
    "start": "12179",
    "end": "19020"
  },
  {
    "text": "about I know joy is as well so democratizing machine learning on kubernetes and I don't know what you",
    "start": "19020",
    "end": "25410"
  },
  {
    "text": "want what you expect when you see that title but we're going to talk about a journey that we've both had speaking",
    "start": "25410",
    "end": "30570"
  },
  {
    "text": "from the heart and some different things that we've seen and then give you some best practices for what we've learnt and",
    "start": "30570",
    "end": "36600"
  },
  {
    "text": "how we propose we might move together as a community so with that I will hand it",
    "start": "36600",
    "end": "45239"
  },
  {
    "start": "44000",
    "end": "123000"
  },
  {
    "text": "over to my lovely colleague joy to introduce yourself hi I'm joy I'm a",
    "start": "45239",
    "end": "51629"
  },
  {
    "text": "solution architect from the Microsoft AI and research org so I work with 30 M of",
    "start": "51629",
    "end": "57270"
  },
  {
    "text": "data scientists and engineers on a daily basis we're all basically building",
    "start": "57270",
    "end": "63570"
  },
  {
    "text": "models training models every single day and obviously doing it in a very",
    "start": "63570",
    "end": "68700"
  },
  {
    "text": "efficient way is super important and that's where kubernetes comes in and and",
    "start": "68700",
    "end": "74220"
  },
  {
    "text": "lucky has been tremendously helpful thank you joy joy is absolutely a",
    "start": "74220",
    "end": "80729"
  },
  {
    "text": "wonderful mind and it's been a pleasure working with her for the last few months but I I'm lucky I'm an SRE over at",
    "start": "80729",
    "end": "87720"
  },
  {
    "text": "Microsoft on Azure and what I spend my day doing is helping folks with kubernetes so Joey came to me several",
    "start": "87720",
    "end": "93869"
  },
  {
    "text": "months ago said hey can you help me I hear kubernetes a great place for me to run machine learning workloads she'd",
    "start": "93869",
    "end": "100170"
  },
  {
    "text": "already taken a great look around and had a lot of things running but we took a look together and what we found is",
    "start": "100170",
    "end": "106049"
  },
  {
    "text": "what we're going to present and see see what you all think but I represent the SRA so I build and maintain the",
    "start": "106049",
    "end": "113159"
  },
  {
    "text": "infrastructure I know how to build kubernetes I know how it should look but I have no machine learning experience",
    "start": "113159",
    "end": "119250"
  },
  {
    "text": "right what I would like to propose here that this is a quite a common occurrence",
    "start": "119250",
    "end": "124500"
  },
  {
    "text": "in this space you have highly talented people at the infrastructure level who",
    "start": "124500",
    "end": "129780"
  },
  {
    "text": "know how to build kubernetes with their eyes sharp and run it and then you have a team of more than capable wonderful data",
    "start": "129780",
    "end": "135060"
  },
  {
    "text": "scientists chomping at the bit to use this infrastructure that you've built the problem is that in the middle of",
    "start": "135060",
    "end": "140430"
  },
  {
    "text": "that then Venn diagram lives no one right so nobody lives there so what",
    "start": "140430",
    "end": "149100"
  },
  {
    "text": "we're looking to do with this talk is start conversation around how do we get people in that middle middle point so",
    "start": "149100",
    "end": "155190"
  },
  {
    "text": "that the data scientists can get the best out of kubernetes as a platform to run the machine learning deeply Newell",
    "start": "155190",
    "end": "161280"
  },
  {
    "text": "Network workloads and me have confidence that I'm actually building the most efficient platform for them to utilize",
    "start": "161280",
    "end": "167900"
  },
  {
    "text": "and this is where the revelation is I won't chomp at the bit here so what I'm",
    "start": "167900",
    "end": "175200"
  },
  {
    "text": "seeing in the environment and working with joy is the right tools are out there to run machine learning the",
    "start": "175200",
    "end": "181140"
  },
  {
    "text": "tooling is already there and kubernetes is the right platform but we have two distinct set of people that know two",
    "start": "181140",
    "end": "188640"
  },
  {
    "text": "different knowledge pillars with not nobody in the middle right so how do we",
    "start": "188640",
    "end": "193830"
  },
  {
    "text": "actually start this conversation between infrastructure engineers who can lay down kubernetes and the data scientists",
    "start": "193830",
    "end": "200790"
  },
  {
    "text": "who want to do want to put kubernetes to the test which is what I was really excited about so you know what we found",
    "start": "200790",
    "end": "209340"
  },
  {
    "start": "207000",
    "end": "260000"
  },
  {
    "text": "taking a look at the documentation it's it's fairly spotty out there when you take a look in the wild there's anybody",
    "start": "209340",
    "end": "215220"
  },
  {
    "text": "running machine learning on kubernetes workloads neural networks - or",
    "start": "215220",
    "end": "220680"
  },
  {
    "text": "traditional ok ok fantastic so you",
    "start": "220680",
    "end": "226709"
  },
  {
    "text": "probably can sympathize with some of this so the documentation is lacking in some places and when you do get a chance",
    "start": "226709",
    "end": "232890"
  },
  {
    "text": "to take a look everything's moving at the speed of light and typically it's out of date and or does not work and",
    "start": "232890",
    "end": "238290"
  },
  {
    "text": "it's several weeks old right because kubernetes is moving at a",
    "start": "238290",
    "end": "243750"
  },
  {
    "text": "different plane to machine learning libraries and meeting them in the middle somewhere so you know that was the",
    "start": "243750",
    "end": "248940"
  },
  {
    "text": "challenge for me coming in with the infrastructure I and Joey coming in with the ML I looking at the same set of",
    "start": "248940",
    "end": "254670"
  },
  {
    "text": "documentation making sure how are we how do we make this a successful outcome so",
    "start": "254670",
    "end": "260970"
  },
  {
    "start": "260000",
    "end": "297000"
  },
  {
    "text": "thinking thinking about that just digging down into what we do here how do we lower the barrier",
    "start": "260970",
    "end": "266340"
  },
  {
    "text": "so when we say democratizing I think there's a whole world and I believe",
    "start": "266340",
    "end": "271790"
  },
  {
    "text": "working with joy that there's a whole world of folks chomping up a bit to get out this they have neural networks to",
    "start": "271790",
    "end": "277800"
  },
  {
    "text": "build and there's great minds out there to build them but the barrier to entry is still very high for them to be able",
    "start": "277800",
    "end": "282930"
  },
  {
    "text": "to get this knowledge out of their head and actually start putting it to the test so how do we get some best practices and create some content out",
    "start": "282930",
    "end": "289860"
  },
  {
    "text": "there so people don't stumble around as as much as I did I don't know if anybody else did but to get there so let's get",
    "start": "289860",
    "end": "297120"
  },
  {
    "start": "297000",
    "end": "460000"
  },
  {
    "text": "started but we're going to take you on a tour of deep learning because I think one of the things that trips me up at",
    "start": "297120",
    "end": "302850"
  },
  {
    "text": "least is naming and nomenclature a lot of these things are very deeply related but they have different names in the ml",
    "start": "302850",
    "end": "308760"
  },
  {
    "text": "world and different names in the infrastructure world so joy is going to give us a very great tour of how",
    "start": "308760",
    "end": "314460"
  },
  {
    "text": "distributed deep learning works and I think I'm going to speak for the infrastructure engineers so I'll hand it",
    "start": "314460",
    "end": "320610"
  },
  {
    "text": "back to joy okay thank you Lackey um so before I dive into the nitty-gritty",
    "start": "320610",
    "end": "327600"
  },
  {
    "text": "details about doing deep learning especially distributed deep learning",
    "start": "327600",
    "end": "332760"
  },
  {
    "text": "which is actually much harder than a single node deep learning training on kubernetes I would like to just to",
    "start": "332760",
    "end": "341220"
  },
  {
    "text": "provide a quick context on the typical distributed training architecture on",
    "start": "341220",
    "end": "347910"
  },
  {
    "text": "multiple nodes so there are mainly in a deep learning space specifically there are mainly two ways of doing distributed",
    "start": "347910",
    "end": "355070"
  },
  {
    "text": "training if you want to scale out to multiple nodes one most popular way is",
    "start": "355070",
    "end": "361229"
  },
  {
    "text": "actually data parallelism basically if you have multiple GPUs sitting across",
    "start": "361229",
    "end": "367680"
  },
  {
    "text": "multiple nodes the way you do deep distributed training for deep learning",
    "start": "367680",
    "end": "373979"
  },
  {
    "text": "is basically you place a copy of your deep neural net model within each every",
    "start": "373979",
    "end": "381000"
  },
  {
    "text": "single GPU that you have and then you feed a mini batch of the entire training",
    "start": "381000",
    "end": "387750"
  },
  {
    "text": "data once one batch at a time into each every single GPU and each GPU basically just",
    "start": "387750",
    "end": "395810"
  },
  {
    "text": "works on that mini batch of the data is being fed to and train a model one",
    "start": "395810",
    "end": "401990"
  },
  {
    "text": "iteration at a time and at the end of each iteration basically a sense are the",
    "start": "401990",
    "end": "408130"
  },
  {
    "text": "the Delta which we often call the gradient which is basically the Delta of",
    "start": "408130",
    "end": "414889"
  },
  {
    "text": "the parameters of the model that need to be updated at the end of that iteration",
    "start": "414889",
    "end": "419930"
  },
  {
    "text": "and a sense that Delta that gradient to a centralized parameter server and the",
    "start": "419930",
    "end": "426320"
  },
  {
    "text": "parameter server basically talks to all GPUs aggregate all of all of those",
    "start": "426320",
    "end": "431449"
  },
  {
    "text": "gradients there are sent across all those GPUs and do a central elevation and then update a",
    "start": "431449",
    "end": "438680"
  },
  {
    "text": "model globally and then push back the updated version of the model to each GPU",
    "start": "438680",
    "end": "446090"
  },
  {
    "text": "again and then the whole process the whole iteration starts again so this is",
    "start": "446090",
    "end": "453139"
  },
  {
    "text": "the way a typical data parallel parallelism distributed training",
    "start": "453139",
    "end": "458570"
  },
  {
    "text": "architecture works the second way is called model or parallelism and this",
    "start": "458570",
    "end": "465680"
  },
  {
    "start": "460000",
    "end": "507000"
  },
  {
    "text": "happens when you have a model that is too big to fit into one single GPU and",
    "start": "465680",
    "end": "472400"
  },
  {
    "text": "this normally happens when you have a big large Miron and that is doing some",
    "start": "472400",
    "end": "477580"
  },
  {
    "text": "natural language processing big LSP hermanos or those big neural machine",
    "start": "477580",
    "end": "486470"
  },
  {
    "text": "translation models those are typically pretty big and cannot fit into one GPU",
    "start": "486470",
    "end": "491479"
  },
  {
    "text": "so you in this case you divide the model into K sub models and each gh GPU just",
    "start": "491479",
    "end": "497750"
  },
  {
    "text": "works on a sub model and they all need to work with with each other to in order to do the global model training so this",
    "start": "497750",
    "end": "508669"
  },
  {
    "text": "picture I'm sure if you have used tensorflow distributive training you must have seen",
    "start": "508669",
    "end": "513690"
  },
  {
    "text": "a architecture diagram alot and this is a typical setting when you do tensile",
    "start": "513690",
    "end": "519120"
  },
  {
    "text": "flaw and distributive training you can have one or more parameters servers",
    "start": "519120",
    "end": "525180"
  },
  {
    "text": "sitting at the top and then you have multiple GPUs across multiple nodes one",
    "start": "525180",
    "end": "530370"
  },
  {
    "text": "thing to call out is tensile flow has done some basic optimization in terms of",
    "start": "530370",
    "end": "536370"
  },
  {
    "text": "the gradient that are being sent from each GPU each worker node that is doing",
    "start": "536370",
    "end": "544860"
  },
  {
    "text": "the work with multiple GPUs they do do like a logo aggregation first to",
    "start": "544860",
    "end": "550890"
  },
  {
    "text": "optimize the network bandwidth before they send the per node level aggregated",
    "start": "550890",
    "end": "557400"
  },
  {
    "text": "variants up to the centralized parameter server fantastic thank you joy I think",
    "start": "557400",
    "end": "563700"
  },
  {
    "text": "one of the things just in hearing those three slides that was a revelation to me as an engineer knowing where the bits",
    "start": "563700",
    "end": "569760"
  },
  {
    "text": "get pushed and crunched and knowing I can already mentally map how that lays down on a kubernetes so what joy",
    "start": "569760",
    "end": "575640"
  },
  {
    "text": "actually did for me and open-source that was just a bunch of steps to actually help me build out and map what she was",
    "start": "575640",
    "end": "583350"
  },
  {
    "text": "doing so she's created a very lightweight kind of in the weeds set up",
    "start": "583350",
    "end": "589710"
  },
  {
    "start": "587000",
    "end": "736000"
  },
  {
    "text": "for us so that we can see a very low level of how this thing hangs together without making it overly complex so",
    "start": "589710",
    "end": "596990"
  },
  {
    "text": "bring any kubernetes cluster on your provider of choice this will work but what we're doing here is with kubernetes",
    "start": "596990",
    "end": "603030"
  },
  {
    "text": "we make sure that we have availability to the GPUs so if you've ever used GPUs in kubernetes they are scheduled as a",
    "start": "603030",
    "end": "610200"
  },
  {
    "text": "resource you see them there but just because they show up doesn't mean you have all your house in order on the nodes right so you need the libraries to",
    "start": "610200",
    "end": "617640"
  },
  {
    "text": "access the GPU hardware whatever that be a common common one is Nvidia so you",
    "start": "617640",
    "end": "623400"
  },
  {
    "text": "need to make sure that you contain a runtimes actually have access to utilize that hardware right so just because you",
    "start": "623400",
    "end": "629310"
  },
  {
    "text": "can see that you have four GPUs doesn't mean your workloads actually have access to those GPUs so there's a script inside",
    "start": "629310",
    "end": "635130"
  },
  {
    "text": "that repo that will actually go and on your nodes you can and make sure that your GPUs are in the right place and shape and then you can",
    "start": "635130",
    "end": "641480"
  },
  {
    "text": "run this um or file so there's a I'll quickly just pop over to this one yeah",
    "start": "641480",
    "end": "649450"
  },
  {
    "text": "okay fantastic thank you and we'll have we'll have the links here at the end but",
    "start": "649450",
    "end": "654950"
  },
  {
    "text": "for me joy putting this together and actually I could get in the weeds I know lots of folks are like this but knowing",
    "start": "654950",
    "end": "660920"
  },
  {
    "text": "what a PS 0 and a PS 1 wasn't a worker 0 and a worker 1 in the context of what we just learnt was incredibly I was",
    "start": "660920",
    "end": "669649"
  },
  {
    "text": "incredibly grateful that I had that knowledge because I could start to peel back how I could design an infrastructure for what her workload was",
    "start": "669649",
    "end": "677089"
  },
  {
    "text": "so you can work through this at your own pace but what it ends up is is you have a parameter server in several workers",
    "start": "677089",
    "end": "682220"
  },
  {
    "text": "and number of workers we run a Python script manually inside them all and describe where the parameter servers and",
    "start": "682220",
    "end": "688490"
  },
  {
    "text": "the workers are and this kicks off the process that joy just detailed but what",
    "start": "688490",
    "end": "693500"
  },
  {
    "text": "you can see in there is you can see the number of batches we want to serve up and the different models which is going",
    "start": "693500",
    "end": "698750"
  },
  {
    "text": "to be great joy is going to take us into what we actually saw when we did a lot of benchmarking and testing so this is",
    "start": "698750",
    "end": "704720"
  },
  {
    "text": "available to you and we'll have the links there at the end let me pop back over to the deck and",
    "start": "704720",
    "end": "711700"
  },
  {
    "text": "so finally if you do a describe on your nodes you will see GPUs if they're",
    "start": "717820",
    "end": "723190"
  },
  {
    "text": "available that is that features tool and alpha I believe but you can do that and most some providers gke have access a CS",
    "start": "723190",
    "end": "730930"
  },
  {
    "text": "to GPU nodes you can run this up and start playing with it today now I'm",
    "start": "730930",
    "end": "737050"
  },
  {
    "start": "736000",
    "end": "767000"
  },
  {
    "text": "going to hand it back over to joy and she's going to take us through what we actually found together as we built this infrastructure yeah so artists to share",
    "start": "737050",
    "end": "747700"
  },
  {
    "text": "with you some of the key learnings we observed when we were doing a lot of",
    "start": "747700",
    "end": "753160"
  },
  {
    "text": "training on kubernetes especially doing a lot of the benchmarking test tuning",
    "start": "753160",
    "end": "759160"
  },
  {
    "text": "various different knobs and auctions and and what we've learned so far so just to",
    "start": "759160",
    "end": "768550"
  },
  {
    "start": "767000",
    "end": "828000"
  },
  {
    "text": "let you know quickly the training environment we used for the benchmark",
    "start": "768550",
    "end": "774460"
  },
  {
    "text": "testing we did a couple of months ago I was using basically two worker nodes",
    "start": "774460",
    "end": "779590"
  },
  {
    "text": "each worker has four Tesla ki t GPUs and I was using one just GPU VM for my",
    "start": "779590",
    "end": "789880"
  },
  {
    "text": "parameter server since parameter server as you have seen basically its job is to",
    "start": "789880",
    "end": "795850"
  },
  {
    "text": "do a lot of the gradient aggregation and update it actually doesn't do the amount of training itself so the parameter",
    "start": "795850",
    "end": "803350"
  },
  {
    "text": "server doesn't does not really need the GPU so I was just using a CPU server for",
    "start": "803350",
    "end": "809350"
  },
  {
    "text": "that and we were using the rail image all the whole image net data set and",
    "start": "809350",
    "end": "816130"
  },
  {
    "text": "those benchmark scripts so we did use the upstream benchmark scripts from tensorflow as well right so you can take",
    "start": "816130",
    "end": "822910"
  },
  {
    "text": "this and run the same thing on your own test bed yes correct",
    "start": "822910",
    "end": "828600"
  },
  {
    "start": "828000",
    "end": "885000"
  },
  {
    "text": "so - before we go into the distributed training just to show you what we",
    "start": "828600",
    "end": "836410"
  },
  {
    "text": "observed on a single part with multiple GPUs as you can see mr. chart showing",
    "start": "836410",
    "end": "842950"
  },
  {
    "text": "here you pretty much you can get a pretty good linear scalability here",
    "start": "842950",
    "end": "850000"
  },
  {
    "text": "and I'm showing a res not here just for an example but actually the same pretty",
    "start": "850000",
    "end": "855580"
  },
  {
    "text": "predictable linear scalability applies to a lot of different models we ran and",
    "start": "855580",
    "end": "860890"
  },
  {
    "text": "tested so vgg 60 and Inception v3 Google met different versions of Rasmus we try",
    "start": "860890",
    "end": "868990"
  },
  {
    "text": "vanilla we try them all and they they all scale from one GPU to two to four on",
    "start": "868990",
    "end": "874720"
  },
  {
    "text": "a single node pretty nicely and all the GPUs are fully saturated which is actually good that means you're not",
    "start": "874720",
    "end": "881530"
  },
  {
    "text": "wasting your GPU resources and for the distributed training testing just a",
    "start": "881530",
    "end": "889390"
  },
  {
    "start": "885000",
    "end": "979000"
  },
  {
    "text": "quick settings sortie I was using just",
    "start": "889390",
    "end": "894460"
  },
  {
    "text": "one parameter server and two workers and I was doing the async a gradient update",
    "start": "894460",
    "end": "901210"
  },
  {
    "text": "between because of the communication between the parameter server and the worker node can happen in a synchronous",
    "start": "901210",
    "end": "908260"
  },
  {
    "text": "fashion or in an asynchronous fashion I think sometimes can help you if you",
    "start": "908260",
    "end": "913450"
  },
  {
    "text": "especially if you have slow network bandwidth that means if you're using a",
    "start": "913450",
    "end": "918940"
  },
  {
    "text": "think the worker each worker does not have to wait for the rest of the workers",
    "start": "918940",
    "end": "924820"
  },
  {
    "text": "to all finish their batch of the data before the worker can move on to the",
    "start": "924820",
    "end": "930490"
  },
  {
    "text": "next batch the communication the synchronizer it does it can happen asynchronously",
    "start": "930490",
    "end": "936300"
  },
  {
    "text": "but sometimes using async can also hurt your speed to accuracy meaning the",
    "start": "936300",
    "end": "942760"
  },
  {
    "text": "primary server sometimes you can get a stale model coming from a slower worker",
    "start": "942760",
    "end": "948490"
  },
  {
    "text": "node which might be having some network issues so the the model your training",
    "start": "948490",
    "end": "954370"
  },
  {
    "text": "the performance might go up and down a little bit if you're using async and and",
    "start": "954370",
    "end": "961240"
  },
  {
    "text": "in this particular testing the parameter server each parameter server and each worker part has their own dedicated host",
    "start": "961240",
    "end": "967960"
  },
  {
    "text": "so they're not competing for resources in this particular and I'm not using anything that Network",
    "start": "967960",
    "end": "975110"
  },
  {
    "text": "just pure Ethernet our GPR CD protocol so here is the distributed testing",
    "start": "975110",
    "end": "985990"
  },
  {
    "start": "979000",
    "end": "1087000"
  },
  {
    "text": "results as you can see actually we have tested different models here and you can",
    "start": "985990",
    "end": "993620"
  },
  {
    "text": "see different models actually have very different behaviour when you scale out so it's not necessarily that you will",
    "start": "993620",
    "end": "1001060"
  },
  {
    "text": "always get the linear scalability in this case as you can see Google net",
    "start": "1001060",
    "end": "1007560"
  },
  {
    "text": "which is the very left here it basically has pretty much the best nearly linear",
    "start": "1007560",
    "end": "1015400"
  },
  {
    "text": "scalability here whereas in the instruction v3 the rest not 50 they all",
    "start": "1015400",
    "end": "1022080"
  },
  {
    "text": "they they have worse scalability in this case I was only getting about 1.6",
    "start": "1022080",
    "end": "1028360"
  },
  {
    "text": "speed-up when training onto nars versus Bonnar I think this was when I first saw",
    "start": "1028360",
    "end": "1034510"
  },
  {
    "text": "these results this is a bit of a revelation because I was under the impression that you could just throw more hardware at the problem but if",
    "start": "1034510",
    "end": "1040750"
  },
  {
    "text": "these models aren't built to take advantage of that distributed hardware you're just wasting your time so a lot",
    "start": "1040750",
    "end": "1045790"
  },
  {
    "text": "of effort on my part was wasted building larger clusters with bigger GPUs and putting more of them out there when the",
    "start": "1045790",
    "end": "1051610"
  },
  {
    "text": "model couldn't actually saturate them so you can see there that first diagram Google node actually linear scales in",
    "start": "1051610",
    "end": "1057010"
  },
  {
    "text": "the distributed fashion but over to the right there's a model there that's actually worse when you run it distributed right and some of 1.6 the",
    "start": "1057010",
    "end": "1064540"
  },
  {
    "text": "average their Google nets the outlier there the rest is not linearly scaling so we're going to talk a little bit more",
    "start": "1064540",
    "end": "1070480"
  },
  {
    "text": "about that but me as an infrastructure engineer give it more GPUs give it more hardware that we talk about that now",
    "start": "1070480",
    "end": "1077370"
  },
  {
    "text": "causes other problems so this is kind of the knowledge gap that I was receiving",
    "start": "1077370",
    "end": "1082780"
  },
  {
    "text": "and starting to build clusters a different way for these folks so just to dive a little deeper on why",
    "start": "1082780",
    "end": "1090780"
  },
  {
    "start": "1087000",
    "end": "1246000"
  },
  {
    "text": "those models are behaving very differently when you scale out basically",
    "start": "1090780",
    "end": "1096880"
  },
  {
    "text": "it all comes down to in one single sentence a critical",
    "start": "1096880",
    "end": "1102800"
  },
  {
    "text": "characteristic of your actual model architecture which is the compute over",
    "start": "1102800",
    "end": "1109030"
  },
  {
    "text": "communication ratio of the model basically those two factors how much GP",
    "start": "1109030",
    "end": "1114710"
  },
  {
    "text": "how much GPU resources your MOU takes to get trained and also how many parameters",
    "start": "1114710",
    "end": "1119810"
  },
  {
    "text": "your how many layers your Mountaineer Annette model architecture has it has a",
    "start": "1119810",
    "end": "1125390"
  },
  {
    "text": "dictating factor or how much network bandwidth it needs to consume so the",
    "start": "1125390",
    "end": "1131210"
  },
  {
    "text": "compute our communication ratio of the model really decides how well your model",
    "start": "1131210",
    "end": "1137870"
  },
  {
    "text": "can scale when you try to scale out when you're doing the training and as you can",
    "start": "1137870",
    "end": "1143900"
  },
  {
    "text": "see Google net really has the highest ratio here so that's why obviously we we",
    "start": "1143900",
    "end": "1150230"
  },
  {
    "text": "saw during our real training as well it does scale pretty well whereas the other",
    "start": "1150230",
    "end": "1156200"
  },
  {
    "text": "models they have lower ratio and they don't scale as as well and also for me I",
    "start": "1156200",
    "end": "1162110"
  },
  {
    "text": "actually thought disk access was going to be the largest factor in this that ratio so compute to disk access and",
    "start": "1162110",
    "end": "1168410"
  },
  {
    "text": "talking to Joyce she informed me of something that I didn't know so under the ml banner right which contains a lot",
    "start": "1168410",
    "end": "1174890"
  },
  {
    "text": "of robots that do good and bad things there is traditional ml things like",
    "start": "1174890",
    "end": "1180830"
  },
  {
    "text": "spark which are disk intensive and then there's distributed deep learning neural",
    "start": "1180830",
    "end": "1188360"
  },
  {
    "text": "networks which is the more modern some more modern approaches which are actually moving these data sets around",
    "start": "1188360",
    "end": "1196010"
  },
  {
    "text": "the network crunch move crunch move so it's actually the move of that data",
    "start": "1196010",
    "end": "1201020"
  },
  {
    "text": "after the models been trained that it actually causes that the whole model to slow down how fast can I get the train",
    "start": "1201020",
    "end": "1207800"
  },
  {
    "text": "model these layers pushed around so everybody else knows about them so again a revelation to me here we are with 40",
    "start": "1207800",
    "end": "1215240"
  },
  {
    "text": "gig NICs right so to actually move this around otherwise the hardware also I",
    "start": "1215240",
    "end": "1220280"
  },
  {
    "text": "think you know in the parameter server model as you scale out more things get go to the parameter server so your",
    "start": "1220280",
    "end": "1225920"
  },
  {
    "text": "parameter server actually becomes your bottleneck because everybody's trying to shoot them 40 gigabits per sec",
    "start": "1225920",
    "end": "1231380"
  },
  {
    "text": "and and he's only got a 40 kid gigabit per second Nick so again I thought you could throw more hardware at the problem",
    "start": "1231380",
    "end": "1237320"
  },
  {
    "text": "and actually made the problem worse right so let's yeah but this is things we need to talk about and think about as",
    "start": "1237320",
    "end": "1243320"
  },
  {
    "text": "we're building this infrastructure so some other observations are that we",
    "start": "1243320",
    "end": "1251360"
  },
  {
    "start": "1246000",
    "end": "1347000"
  },
  {
    "text": "wanted to call out when we were doing the training in addition to the network",
    "start": "1251360",
    "end": "1256700"
  },
  {
    "text": "bandwidth and obviously the compute our communication ratio of your actual model",
    "start": "1256700",
    "end": "1262720"
  },
  {
    "text": "there were so as a obviously Cooper natty admin when you're supporting your",
    "start": "1262720",
    "end": "1269720"
  },
  {
    "text": "data scientist with your kubernetes cluster they are doing their training on your kubernetes the one big important",
    "start": "1269720",
    "end": "1278690"
  },
  {
    "text": "thing to monitor is whether they are saturating you are their GPUs or not because if they their GPUs are basically",
    "start": "1278690",
    "end": "1287120"
  },
  {
    "text": "sitting there idle not getting saturated then you want to think twice before you",
    "start": "1287120",
    "end": "1292750"
  },
  {
    "text": "throw more hardware and the problem and",
    "start": "1292750",
    "end": "1297860"
  },
  {
    "text": "also another thing that I was having to basically try different options and",
    "start": "1297860",
    "end": "1304100"
  },
  {
    "text": "wasn't really very intuitive for me to come up with an optimal design at the beginning was the correct ratio between",
    "start": "1304100",
    "end": "1311420"
  },
  {
    "text": "the price of the worker to the parameter servers I was testing with two primary servers",
    "start": "1311420",
    "end": "1317380"
  },
  {
    "text": "with one parameter server with two parameter server sitting on the same host which the worker on the same was",
    "start": "1317380",
    "end": "1325880"
  },
  {
    "text": "the same as the same host as the worker pass or should I be having the parameter",
    "start": "1325880",
    "end": "1331490"
  },
  {
    "text": "server sitting separately on a separate host so those are all very not so easy",
    "start": "1331490",
    "end": "1340850"
  },
  {
    "text": "and intuitive to to design at the beginning of your training",
    "start": "1340850",
    "end": "1347140"
  },
  {
    "text": "so we've shared a lot of pain points and a lot of learnings so how can we do",
    "start": "1347260",
    "end": "1353420"
  },
  {
    "text": "better so this is where I want to do",
    "start": "1353420",
    "end": "1358640"
  },
  {
    "text": "some quick call-out on some of the latest tech No and framework that literally just came",
    "start": "1358640",
    "end": "1363960"
  },
  {
    "text": "out about over the past few months one thing is horrible that is ubers",
    "start": "1363960",
    "end": "1372960"
  },
  {
    "text": "recently open source distributed deep learning framework for tensile flow it",
    "start": "1372960",
    "end": "1380250"
  },
  {
    "text": "is important to note that it is not replacing tensile flow or just yet another fourth of canceled flow it is",
    "start": "1380250",
    "end": "1387210"
  },
  {
    "text": "actually a standalone Python package that works on top of tensile flow so you",
    "start": "1387210",
    "end": "1392460"
  },
  {
    "text": "don't have to worry about getting distracted or getting detached from the",
    "start": "1392460",
    "end": "1398880"
  },
  {
    "text": "mainstream kinds of flour this is just another nice standalone package that",
    "start": "1398880",
    "end": "1403950"
  },
  {
    "text": "works with tensile flour and it solves a lot of the the network bottleneck issues",
    "start": "1403950",
    "end": "1410130"
  },
  {
    "text": "and also the hard decision or was the",
    "start": "1410130",
    "end": "1415770"
  },
  {
    "text": "correct ratio between your parameter server and worker it solves a lot of those problems by using the ring or",
    "start": "1415770",
    "end": "1423840"
  },
  {
    "text": "reduced algorithms so that all of those workers instead of sinking and top",
    "start": "1423840",
    "end": "1431160"
  },
  {
    "text": "standing their parameters those gradients to a centralized primary server they can all just talk directly",
    "start": "1431160",
    "end": "1438870"
  },
  {
    "start": "1432000",
    "end": "1551000"
  },
  {
    "text": "among each other so now with hora world you don't need even to specify how many",
    "start": "1438870",
    "end": "1447540"
  },
  {
    "text": "parameters servers you need anymore there is no parameter server all the workers can just talk directly with each",
    "start": "1447540",
    "end": "1454800"
  },
  {
    "text": "other among themselves using this ring or reduced algorithm that is highly",
    "start": "1454800",
    "end": "1460740"
  },
  {
    "text": "efficient at communic note internal or",
    "start": "1460740",
    "end": "1466050"
  },
  {
    "text": "internal GPU communication and it is using this nickel and nickel 2 library",
    "start": "1466050",
    "end": "1473220"
  },
  {
    "text": "from nvidia nickel 1 is for internal GPU communication inter nico to is for",
    "start": "1473220",
    "end": "1479970"
  },
  {
    "text": "internal a GPU communication and they all uses ring all radios to talk to each",
    "start": "1479970",
    "end": "1486270"
  },
  {
    "text": "other directly and also it basically because all the workers now",
    "start": "1486270",
    "end": "1493940"
  },
  {
    "text": "can talk directly to each other from the network bandwidth perspective you also",
    "start": "1493940",
    "end": "1500570"
  },
  {
    "text": "basically avoid a lot of the other network bandwidth bottleneck we were",
    "start": "1500570",
    "end": "1505830"
  },
  {
    "text": "running into earlier so as you can see from the chart here if you're running",
    "start": "1505830",
    "end": "1512220"
  },
  {
    "text": "horrible on top of tensorflow you get a much better a much more predictable linear scalability when you",
    "start": "1512220",
    "end": "1519990"
  },
  {
    "text": "scale out and it doesn't matter what model what your specific model",
    "start": "1519990",
    "end": "1525030"
  },
  {
    "text": "architecture is anymore as you can see whether you using instruction v3 ResNet or v2 g16 your",
    "start": "1525030",
    "end": "1532800"
  },
  {
    "text": "model can all pretty much scale pretty nicely and in this way since you get",
    "start": "1532800",
    "end": "1538290"
  },
  {
    "text": "better predictability of the scalability you then can design in a much easier way",
    "start": "1538290",
    "end": "1543900"
  },
  {
    "text": "how exactly how many workers we need how many GPUs you need instead of guessing and testing and another thing is this",
    "start": "1543900",
    "end": "1553020"
  },
  {
    "start": "1551000",
    "end": "1622000"
  },
  {
    "text": "deep gradient in compression technology there's a page this is a paper that",
    "start": "1553020",
    "end": "1559230"
  },
  {
    "text": "literally just came out about two weeks ago it also directly targets on addressing",
    "start": "1559230",
    "end": "1565170"
  },
  {
    "text": "the the huge network communication",
    "start": "1565170",
    "end": "1570210"
  },
  {
    "text": "bandwidth issue here when you're doing deep learning training across multiple",
    "start": "1570210",
    "end": "1576150"
  },
  {
    "text": "nodes basically it turned out that 99.9%",
    "start": "1576150",
    "end": "1581880"
  },
  {
    "text": "of the gradients exchanged could be to actually tiny to be significantly",
    "start": "1581880",
    "end": "1587220"
  },
  {
    "text": "significant enough to be transferred in the first place so it does a lot of compression technique without losing the",
    "start": "1587220",
    "end": "1594330"
  },
  {
    "text": "accuracy if you're interested in this check out this paper is actually it can",
    "start": "1594330",
    "end": "1601140"
  },
  {
    "text": "really democratize distributive training over community just one Gigabit Ethernet",
    "start": "1601140",
    "end": "1606620"
  },
  {
    "text": "yeah I like the smaller next two and I think even the Google pixel to ships",
    "start": "1606620",
    "end": "1612480"
  },
  {
    "text": "with the TPU so they're obviously doing something very similar yeah as well now you can actually process these models",
    "start": "1612480",
    "end": "1618230"
  },
  {
    "text": "not have to have large bandwidth between them thanks joy so thinking the spirit",
    "start": "1618230",
    "end": "1624169"
  },
  {
    "start": "1622000",
    "end": "1648000"
  },
  {
    "text": "the spirit of making this easier one of the things that the the Microsoft Research ml Research Lab did was",
    "start": "1624169",
    "end": "1630650"
  },
  {
    "text": "actually created an open-source repo where you can bring your own kubernetes cluster and install just a couple of",
    "start": "1630650",
    "end": "1636320"
  },
  {
    "text": "pods and have a lightweight framework and Joe is just going to take us through how you could run these models yourself",
    "start": "1636320",
    "end": "1642260"
  },
  {
    "text": "in that workspace can you do that so",
    "start": "1642260",
    "end": "1648410"
  },
  {
    "start": "1648000",
    "end": "1686000"
  },
  {
    "text": "this is a basically an open-source toolkit we just released about a few",
    "start": "1648410",
    "end": "1655490"
  },
  {
    "text": "months ago is from Microsoft Research this is the deep learning workspace that",
    "start": "1655490",
    "end": "1660770"
  },
  {
    "text": "are being used by our researchers data scientists from Microsoft Research on a",
    "start": "1660770",
    "end": "1666620"
  },
  {
    "text": "daily basis when they do a lot of deep learning training and it is backed by",
    "start": "1666620",
    "end": "1672770"
  },
  {
    "text": "kubernetes and you can install this on crime on any cloud providers so it is",
    "start": "1672770",
    "end": "1679669"
  },
  {
    "text": "integrated with Active Directory so I can just quickly log in there and",
    "start": "1679669",
    "end": "1685780"
  },
  {
    "text": "obviously a typical data scientist typical data scientist wouldn't really",
    "start": "1685780",
    "end": "1690830"
  },
  {
    "start": "1686000",
    "end": "1772000"
  },
  {
    "text": "know anything about kubernetes and all they need to have is just access to this very intuitive simple to use GUI so if I",
    "start": "1690830",
    "end": "1701690"
  },
  {
    "text": "for example if I want to just spin up a Jupiter notebook I can go and select a",
    "start": "1701690",
    "end": "1707660"
  },
  {
    "text": "tensorflow iPad for CPU template and I can just click on a something it button",
    "start": "1707660",
    "end": "1713210"
  },
  {
    "text": "and I'll get a jupiter notebook really quickly and but what i really want to show you now is how i can do a",
    "start": "1713210",
    "end": "1719860"
  },
  {
    "text": "distributed tensorflow training just from this simple GUI interface so i can",
    "start": "1719860",
    "end": "1727429"
  },
  {
    "text": "now just basically select a job type to be a distributed training and i can give",
    "start": "1727429",
    "end": "1733130"
  },
  {
    "text": "it a job name i can call it joy IDF test in this case for example I can have just",
    "start": "1733130",
    "end": "1742700"
  },
  {
    "text": "one parameter server and two workers and each worker should have just one GPU and",
    "start": "1742700",
    "end": "1750460"
  },
  {
    "text": "for the darker version I want to use say for example tensorflow 1.2 and in the",
    "start": "1750460",
    "end": "1759860"
  },
  {
    "text": "containing command I can just simply tell it this is the Python obviously the",
    "start": "1759860",
    "end": "1766730"
  },
  {
    "text": "part of my talk my pencil flow Python script here so I can enable tensile",
    "start": "1766730",
    "end": "1773990"
  },
  {
    "start": "1772000",
    "end": "1796000"
  },
  {
    "text": "board so obviously people love tensile board for debugging purposes or in order",
    "start": "1773990",
    "end": "1779210"
  },
  {
    "text": "to do your training often you can't just say enable tensile board and you will get an endpoint and you can just quickly",
    "start": "1779210",
    "end": "1786710"
  },
  {
    "text": "specify a model path for saving your model checkpoint and then you just click",
    "start": "1786710",
    "end": "1793610"
  },
  {
    "text": "on submit and now you as you can see a job some jobs are being killed and they",
    "start": "1793610",
    "end": "1801110"
  },
  {
    "text": "will get scheduled very shortly and while we are waiting for the jobs to get",
    "start": "1801110",
    "end": "1807230"
  },
  {
    "text": "scheduled I can show you a previous notebook Jupiter a novel job that I spin",
    "start": "1807230",
    "end": "1815120"
  },
  {
    "start": "1809000",
    "end": "1837000"
  },
  {
    "text": "out so this is a Jupiter note book job",
    "start": "1815120",
    "end": "1820190"
  },
  {
    "text": "that I can open",
    "start": "1820190",
    "end": "1824230"
  },
  {
    "text": "so here I was given an end point and by just simply clicking on a tiempo and Ike",
    "start": "1826950",
    "end": "1833620"
  },
  {
    "text": "there's my Jupiter notebook and then back to my previous distributed training",
    "start": "1833620",
    "end": "1841540"
  },
  {
    "start": "1837000",
    "end": "1868000"
  },
  {
    "text": "job as you can see the job is already running so if I click into the Java code",
    "start": "1841540",
    "end": "1847660"
  },
  {
    "text": "you can see actually there's a real time training going on here I specified 5,000",
    "start": "1847660",
    "end": "1854290"
  },
  {
    "text": "stats across to worker nose and you can see there are like there are two workers",
    "start": "1854290",
    "end": "1859750"
  },
  {
    "text": "each working on some steps here so and",
    "start": "1859750",
    "end": "1867780"
  },
  {
    "text": "then just quickly if I want to see my pencil board I can just go into my",
    "start": "1867780",
    "end": "1878129"
  },
  {
    "start": "1868000",
    "end": "1891000"
  },
  {
    "text": "chance of world",
    "start": "1880200",
    "end": "1883590"
  },
  {
    "text": "and point so there's my pencil bar that",
    "start": "1886550",
    "end": "1893480"
  },
  {
    "start": "1891000",
    "end": "1909000"
  },
  {
    "text": "is literally the graph for my model that I specified in my script so back to the",
    "start": "1893480",
    "end": "1905150"
  },
  {
    "text": "slide so just very quickly two quick things I",
    "start": "1905150",
    "end": "1912100"
  },
  {
    "start": "1909000",
    "end": "2019000"
  },
  {
    "text": "want to call out there is a free flow CNI plug-in that comes with deep",
    "start": "1912100",
    "end": "1918910"
  },
  {
    "text": "learning workspace we've just shown you and the plugin is from Microsoft reserves it basically it automatically",
    "start": "1918910",
    "end": "1927900"
  },
  {
    "text": "leveraged shared memory if you happen to have part of the arsenio same host and",
    "start": "1927900",
    "end": "1935080"
  },
  {
    "text": "also if you do have our DMA Network whether it's walkie or if in event it",
    "start": "1935080",
    "end": "1940150"
  },
  {
    "text": "automatically detects that you have our DMA network and it will use the our DMA",
    "start": "1940150",
    "end": "1945610"
  },
  {
    "text": "network automatically and it's completely transparent to your path and",
    "start": "1945610",
    "end": "1951040"
  },
  {
    "text": "your apps so it's mainly because this is super critical than you're doing deep",
    "start": "1951040",
    "end": "1956650"
  },
  {
    "text": "learning workloads on kubernetes network bandwidth Network communication speed is always super important and this is why",
    "start": "1956650",
    "end": "1963840"
  },
  {
    "text": "we use the free flow CNI plugin ourselves a lot to help with the network",
    "start": "1963840",
    "end": "1970120"
  },
  {
    "text": "performance and also we're contributing back to the crew burn and convenient community by we're gonna be contributing",
    "start": "1970120",
    "end": "1978160"
  },
  {
    "text": "a GPU resource scheduler and that is from Sanjeev from our Microsoft research",
    "start": "1978160",
    "end": "1984640"
  },
  {
    "text": "team as well so with that scheduler as a custom plugin that you can plug into",
    "start": "1984640",
    "end": "1990010"
  },
  {
    "text": "your core in any cluster your data scientist can or your DevOps can specify",
    "start": "1990010",
    "end": "1995440"
  },
  {
    "text": "apart not only with just how many GPUs you need for the path but also how many",
    "start": "1995440",
    "end": "2000840"
  },
  {
    "text": "GPUs with how much memory and also how many GPUs with that are inter inter",
    "start": "2000840",
    "end": "2007080"
  },
  {
    "text": "connected through an MV link those are all very important when you're running",
    "start": "2007080",
    "end": "2012840"
  },
  {
    "text": "deep learning GPU related our clothes on kubernetes thanks Joey and just to just",
    "start": "2012840",
    "end": "2020370"
  },
  {
    "start": "2019000",
    "end": "2033000"
  },
  {
    "text": "a roundup there's a bunch of other resources that we placed on here there's a lot of community engagement already going on I know that the folks at Google",
    "start": "2020370",
    "end": "2027390"
  },
  {
    "text": "announced cube flow a couple of days and that we folks rallying around that so maybe go take a look at that as well but",
    "start": "2027390",
    "end": "2034200"
  },
  {
    "start": "2033000",
    "end": "2063000"
  },
  {
    "text": "everything up here today but what we're hoping for is that we can all work together and build a commune around making ML workloads run great on",
    "start": "2034200",
    "end": "2041700"
  },
  {
    "text": "kubernetes and get some knowledge gaps that existed in between me knowing ml and the data scientists knowing",
    "start": "2041700",
    "end": "2047700"
  },
  {
    "text": "kubernetes feel free to engage with both Joe and myself we do this day in and day",
    "start": "2047700",
    "end": "2052950"
  },
  {
    "text": "out via Twitter or you can find us somewhere other or we'll take questions but thank you very much for your time",
    "start": "2052950",
    "end": "2058108"
  },
  {
    "text": "thank you [Applause]",
    "start": "2058109",
    "end": "2065650"
  }
]
[
  {
    "text": "okay hello and welcome everyone uh this",
    "start": "120",
    "end": "2919"
  },
  {
    "text": "will be a talk about increasing GPU",
    "start": "2919",
    "end": "5040"
  },
  {
    "text": "utilization on kubernetes clusters and I",
    "start": "5040",
    "end": "7359"
  },
  {
    "text": "wanted to starts from thanking you for",
    "start": "7359",
    "end": "9120"
  },
  {
    "text": "still being here after this exhausting",
    "start": "9120",
    "end": "11160"
  },
  {
    "text": "week I hope you are not as tired as I am",
    "start": "11160",
    "end": "13920"
  },
  {
    "text": "and will stay with me through the talk",
    "start": "13920",
    "end": "16480"
  },
  {
    "text": "uh so my name is machek mazur I'm the",
    "start": "16480",
    "end": "19080"
  },
  {
    "text": "principal AI engineer in canonical",
    "start": "19080",
    "end": "21400"
  },
  {
    "text": "that's the company behind Ubuntu and I'm",
    "start": "21400",
    "end": "24199"
  },
  {
    "text": "typically working on the other side of",
    "start": "24199",
    "end": "26560"
  },
  {
    "text": "the fence I know that you guys are",
    "start": "26560",
    "end": "27880"
  },
  {
    "text": "mostly SS admins devops engineers people",
    "start": "27880",
    "end": "30679"
  },
  {
    "text": "working on kubernetes clusters I'm the",
    "start": "30679",
    "end": "33320"
  },
  {
    "text": "user of the great stuff that you guys",
    "start": "33320",
    "end": "35440"
  },
  {
    "text": "build and do and I wanted to tell you a",
    "start": "35440",
    "end": "37600"
  },
  {
    "text": "little bit uh about how we are actually",
    "start": "37600",
    "end": "40559"
  },
  {
    "text": "using it what are our goals and how we",
    "start": "40559",
    "end": "42440"
  },
  {
    "text": "build couple of projects last year with",
    "start": "42440",
    "end": "45280"
  },
  {
    "text": "infrastructures which varies from like",
    "start": "45280",
    "end": "47719"
  },
  {
    "text": "7,000 to 12,000 gpus in one project",
    "start": "47719",
    "end": "51440"
  },
  {
    "text": "setup or a cluster so why we are even",
    "start": "51440",
    "end": "55920"
  },
  {
    "text": "interested in kubernetes for AIML from",
    "start": "55920",
    "end": "58680"
  },
  {
    "text": "the ml engineer perspective like power",
    "start": "58680",
    "end": "60840"
  },
  {
    "text": "life is typically super structured there",
    "start": "60840",
    "end": "63920"
  },
  {
    "text": "is a process that we are following",
    "start": "63920",
    "end": "65720"
  },
  {
    "text": "called mlops and basically there are lot",
    "start": "65720",
    "end": "69040"
  },
  {
    "text": "of small steps that needs to happen",
    "start": "69040",
    "end": "70960"
  },
  {
    "text": "using various types of compute and from",
    "start": "70960",
    "end": "73960"
  },
  {
    "text": "our experience we saw that kubernetes",
    "start": "73960",
    "end": "76000"
  },
  {
    "text": "gives us a lot of repeatability gives us",
    "start": "76000",
    "end": "78680"
  },
  {
    "text": "all the pipelines portability scaling so",
    "start": "78680",
    "end": "81560"
  },
  {
    "text": "all the standard stuff that you guys",
    "start": "81560",
    "end": "83479"
  },
  {
    "text": "realized already 10 years ago it took us",
    "start": "83479",
    "end": "85240"
  },
  {
    "text": "a little bit more time but we now uh",
    "start": "85240",
    "end": "87400"
  },
  {
    "text": "started using it properly as well I",
    "start": "87400",
    "end": "89360"
  },
  {
    "text": "think but why this talk is about gpus",
    "start": "89360",
    "end": "91960"
  },
  {
    "text": "and why we do even need them in the",
    "start": "91960",
    "end": "94799"
  },
  {
    "text": "cluster so the actual things that we are",
    "start": "94799",
    "end": "97600"
  },
  {
    "text": "doing is mostly matrix multiplication a",
    "start": "97600",
    "end": "100759"
  },
  {
    "text": "lot of things will show ml as something",
    "start": "100759",
    "end": "103320"
  },
  {
    "text": "very complicated but mathematically",
    "start": "103320",
    "end": "105040"
  },
  {
    "text": "these are uh sort of a standard",
    "start": "105040",
    "end": "107680"
  },
  {
    "text": "computations and why gpus because it's",
    "start": "107680",
    "end": "110439"
  },
  {
    "text": "very similar to this this would be your",
    "start": "110439",
    "end": "112240"
  },
  {
    "text": "screen with RGB and it's also Matrix so",
    "start": "112240",
    "end": "114520"
  },
  {
    "text": "all the Silicon being built by Nvidia by",
    "start": "114520",
    "end": "118280"
  },
  {
    "text": "AMD by Intel is basically the tool that",
    "start": "118280",
    "end": "122280"
  },
  {
    "text": "was used to do a lot of similar",
    "start": "122280",
    "end": "124200"
  },
  {
    "text": "computations and that's why uh in",
    "start": "124200",
    "end": "126640"
  },
  {
    "text": "machine learning gpus become super",
    "start": "126640",
    "end": "128239"
  },
  {
    "text": "popular and that's why we are uh using",
    "start": "128239",
    "end": "131680"
  },
  {
    "text": "it very heavily during our processes so",
    "start": "131680",
    "end": "135519"
  },
  {
    "text": "typically what you would do in any",
    "start": "135519",
    "end": "137560"
  },
  {
    "text": "kubernetes cluster you need your GPU",
    "start": "137560",
    "end": "140480"
  },
  {
    "text": "operator something that will enable the",
    "start": "140480",
    "end": "142200"
  },
  {
    "text": "device to be visible uh if the cluster",
    "start": "142200",
    "end": "145319"
  },
  {
    "text": "is bigger you would also go with a",
    "start": "145319",
    "end": "146879"
  },
  {
    "text": "network operator to connect the gpus",
    "start": "146879",
    "end": "148920"
  },
  {
    "text": "together so that's like a fairly",
    "start": "148920",
    "end": "150200"
  },
  {
    "text": "standard example of a stack from Nvidia",
    "start": "150200",
    "end": "152720"
  },
  {
    "text": "but uh okay so we want to use gpus which",
    "start": "152720",
    "end": "157200"
  },
  {
    "text": "ones and is there really any difference",
    "start": "157200",
    "end": "159840"
  },
  {
    "text": "and uh with gpus you can go with the",
    "start": "159840",
    "end": "163920"
  },
  {
    "text": "setup from Nvidia that's the most",
    "start": "163920",
    "end": "165879"
  },
  {
    "text": "popular one that's something that most",
    "start": "165879",
    "end": "167319"
  },
  {
    "text": "of the people are using and how uh the",
    "start": "167319",
    "end": "169959"
  },
  {
    "text": "Clusters are being built these days but",
    "start": "169959",
    "end": "172400"
  },
  {
    "text": "you also have uh contenders you have AMD",
    "start": "172400",
    "end": "176280"
  },
  {
    "text": "with their Rock M kit and being uh",
    "start": "176280",
    "end": "179840"
  },
  {
    "text": "basically also working a lot uh on the",
    "start": "179840",
    "end": "182680"
  },
  {
    "text": "optimization of the Frameworks the same",
    "start": "182680",
    "end": "185120"
  },
  {
    "text": "goes for uh Intel with open Vino and all",
    "start": "185120",
    "end": "188120"
  },
  {
    "text": "the extensions to tensor flow and Pythor",
    "start": "188120",
    "end": "190760"
  },
  {
    "text": "like ipex and itex uh so these are",
    "start": "190760",
    "end": "194280"
  },
  {
    "text": "multiple options but what we are as",
    "start": "194280",
    "end": "196319"
  },
  {
    "text": "users mostly looking into is actually",
    "start": "196319",
    "end": "198680"
  },
  {
    "text": "the pure statistics and power so if you",
    "start": "198680",
    "end": "201159"
  },
  {
    "text": "look at the set of gpus from Nvidia",
    "start": "201159",
    "end": "203879"
  },
  {
    "text": "there will be obviously some performance",
    "start": "203879",
    "end": "205879"
  },
  {
    "text": "metrics and benchmarks being made by",
    "start": "205879",
    "end": "207879"
  },
  {
    "text": "people but very important from my",
    "start": "207879",
    "end": "211439"
  },
  {
    "text": "perspective as a user and a solution",
    "start": "211439",
    "end": "213159"
  },
  {
    "text": "architect is this basically performance",
    "start": "213159",
    "end": "215879"
  },
  {
    "text": "per the price of the GPU and if you look",
    "start": "215879",
    "end": "218959"
  },
  {
    "text": "at this list this does not look exactly",
    "start": "218959",
    "end": "221200"
  },
  {
    "text": "the same so there is a lot of caveats in",
    "start": "221200",
    "end": "223640"
  },
  {
    "text": "terms of which gpus you are actually",
    "start": "223640",
    "end": "225360"
  },
  {
    "text": "choosing to the computation that you",
    "start": "225360",
    "end": "227080"
  },
  {
    "text": "want to do and how the mix should look",
    "start": "227080",
    "end": "228959"
  },
  {
    "text": "like so the price performance is a very",
    "start": "228959",
    "end": "231280"
  },
  {
    "text": "important aspect especially that the",
    "start": "231280",
    "end": "234360"
  },
  {
    "text": "most powerful gpus obviously it's a new",
    "start": "234360",
    "end": "236280"
  },
  {
    "text": "technology it needs to be priced a",
    "start": "236280",
    "end": "237959"
  },
  {
    "text": "little uh higher because of the",
    "start": "237959",
    "end": "240239"
  },
  {
    "text": "development cost so that's something",
    "start": "240239",
    "end": "242560"
  },
  {
    "text": "that we are looking into very much and",
    "start": "242560",
    "end": "246040"
  },
  {
    "text": "how we are actually using gpus there are",
    "start": "246040",
    "end": "248360"
  },
  {
    "text": "a couple of main categories so we have",
    "start": "248360",
    "end": "251040"
  },
  {
    "text": "the training environment where we are",
    "start": "251040",
    "end": "253120"
  },
  {
    "text": "basically taking the data training the",
    "start": "253120",
    "end": "254959"
  },
  {
    "text": "models perform the fine tuning processes",
    "start": "254959",
    "end": "257160"
  },
  {
    "text": "and we have inference environments and",
    "start": "257160",
    "end": "259320"
  },
  {
    "text": "on the training side what we are doing",
    "start": "259320",
    "end": "261359"
  },
  {
    "text": "we are starting our work with a notebook",
    "start": "261359",
    "end": "264199"
  },
  {
    "text": "typically or like a vs code or intellig",
    "start": "264199",
    "end": "267000"
  },
  {
    "text": "hooked up to a notebook server we have",
    "start": "267000",
    "end": "269080"
  },
  {
    "text": "our mlops pipelines on kubernetes with",
    "start": "269080",
    "end": "271880"
  },
  {
    "text": "Cube flow uh we are doing some",
    "start": "271880",
    "end": "273840"
  },
  {
    "text": "processing tasks which are also GPU",
    "start": "273840",
    "end": "275919"
  },
  {
    "text": "accelerated if you go with spark and",
    "start": "275919",
    "end": "278080"
  },
  {
    "text": "Rapids and we are testing a lot on this",
    "start": "278080",
    "end": "280280"
  },
  {
    "text": "type of environments but we also need to",
    "start": "280280",
    "end": "283160"
  },
  {
    "text": "do inference where we are actually",
    "start": "283160",
    "end": "284919"
  },
  {
    "text": "serving the models to end users that's",
    "start": "284919",
    "end": "286720"
  },
  {
    "text": "completely different requirements in",
    "start": "286720",
    "end": "288320"
  },
  {
    "text": "terms of computational speed we are",
    "start": "288320",
    "end": "290800"
  },
  {
    "text": "doing also a lot of serving in the real",
    "start": "290800",
    "end": "292919"
  },
  {
    "text": "time especially if you do like iot",
    "start": "292919",
    "end": "295280"
  },
  {
    "text": "devices or analysis of signals from a",
    "start": "295280",
    "end": "298520"
  },
  {
    "text": "telecom Network uh a lot of",
    "start": "298520",
    "end": "300320"
  },
  {
    "text": "pre-processing and also dpus as",
    "start": "300320",
    "end": "302919"
  },
  {
    "text": "additional Hardware type uh but what is",
    "start": "302919",
    "end": "306720"
  },
  {
    "text": "super important is sharing that",
    "start": "306720",
    "end": "308759"
  },
  {
    "text": "infrastructure among multiple teams and",
    "start": "308759",
    "end": "311479"
  },
  {
    "text": "uh multiple users because gpus are that",
    "start": "311479",
    "end": "313720"
  },
  {
    "text": "expensive price performance is important",
    "start": "313720",
    "end": "316080"
  },
  {
    "text": "we need to figure out how we are",
    "start": "316080",
    "end": "318199"
  },
  {
    "text": "actually fitting the workload into the",
    "start": "318199",
    "end": "320639"
  },
  {
    "text": "GPU in a proper way and there are",
    "start": "320639",
    "end": "322440"
  },
  {
    "text": "multiple ways how you can do it you can",
    "start": "322440",
    "end": "325360"
  },
  {
    "text": "time slice the GPU so basically give",
    "start": "325360",
    "end": "327440"
  },
  {
    "text": "everyone a time slot when they are using",
    "start": "327440",
    "end": "329520"
  },
  {
    "text": "it",
    "start": "329520",
    "end": "330319"
  },
  {
    "text": "but the most popular way especially in",
    "start": "330319",
    "end": "332160"
  },
  {
    "text": "big clusters would be MC or any other",
    "start": "332160",
    "end": "335080"
  },
  {
    "text": "kind of GPU slicing so basically if you",
    "start": "335080",
    "end": "337240"
  },
  {
    "text": "have 40 gig or 80 gig GPU you slice it",
    "start": "337240",
    "end": "340240"
  },
  {
    "text": "into smaller pieces to be able to",
    "start": "340240",
    "end": "342400"
  },
  {
    "text": "efficiently place the workloads which",
    "start": "342400",
    "end": "344319"
  },
  {
    "text": "does not require the full GPU like if",
    "start": "344319",
    "end": "346479"
  },
  {
    "text": "you have a 40 gigs on the GPU and your",
    "start": "346479",
    "end": "348840"
  },
  {
    "text": "training process requires one gig",
    "start": "348840",
    "end": "351120"
  },
  {
    "text": "because it's something super simple",
    "start": "351120",
    "end": "352360"
  },
  {
    "text": "reserving the whole GPU is very",
    "start": "352360",
    "end": "354880"
  },
  {
    "text": "counterproductive and uh if we have more",
    "start": "354880",
    "end": "359240"
  },
  {
    "text": "GPU we need to start looking into",
    "start": "359240",
    "end": "361360"
  },
  {
    "text": "networking and this is typically a big",
    "start": "361360",
    "end": "363560"
  },
  {
    "text": "bottleneck because gpus are very fast by",
    "start": "363560",
    "end": "366440"
  },
  {
    "text": "themselves if they are in one server",
    "start": "366440",
    "end": "368520"
  },
  {
    "text": "they also have uh a ways to link them in",
    "start": "368520",
    "end": "371240"
  },
  {
    "text": "a fast uh manner but if you have",
    "start": "371240",
    "end": "373560"
  },
  {
    "text": "multiple data centers especially in",
    "start": "373560",
    "end": "375280"
  },
  {
    "text": "different locations or even different",
    "start": "375280",
    "end": "377400"
  },
  {
    "text": "availability zones or fire compartments",
    "start": "377400",
    "end": "379840"
  },
  {
    "text": "you need fast networking there are lot",
    "start": "379840",
    "end": "382160"
  },
  {
    "text": "of Technologies between uh RDMA over",
    "start": "382160",
    "end": "385280"
  },
  {
    "text": "conver internet uh infin band or",
    "start": "385280",
    "end": "388039"
  },
  {
    "text": "recently Spectrum X that will allow you",
    "start": "388039",
    "end": "390720"
  },
  {
    "text": "to basically have the networking that is",
    "start": "390720",
    "end": "392960"
  },
  {
    "text": "fast enough to pull those gpus together",
    "start": "392960",
    "end": "395240"
  },
  {
    "text": "in uh bigger training processes but what",
    "start": "395240",
    "end": "398560"
  },
  {
    "text": "it leads to it increases the deployment",
    "start": "398560",
    "end": "400680"
  },
  {
    "text": "complexity because we need to have a",
    "start": "400680",
    "end": "403160"
  },
  {
    "text": "network for all of our data and",
    "start": "403160",
    "end": "404919"
  },
  {
    "text": "everything that we do normally but we",
    "start": "404919",
    "end": "406840"
  },
  {
    "text": "also need a dedicated Network for any",
    "start": "406840",
    "end": "409800"
  },
  {
    "text": "GPU related tasks and processing so",
    "start": "409800",
    "end": "412800"
  },
  {
    "text": "there are a couple of options infin band",
    "start": "412800",
    "end": "414680"
  },
  {
    "text": "and Spectrum X are coming from Nvidia uh",
    "start": "414680",
    "end": "417360"
  },
  {
    "text": "RC can be used uh in basically with any",
    "start": "417360",
    "end": "421280"
  },
  {
    "text": "type of hardware and these are the",
    "start": "421280",
    "end": "423759"
  },
  {
    "text": "choices that you would look into in the",
    "start": "423759",
    "end": "426599"
  },
  {
    "text": "networking space so when you have those",
    "start": "426599",
    "end": "428759"
  },
  {
    "text": "gpus connected already you have a big",
    "start": "428759",
    "end": "430800"
  },
  {
    "text": "pool of them then the next question is",
    "start": "430800",
    "end": "433039"
  },
  {
    "text": "how to schedule the resources and from",
    "start": "433039",
    "end": "435360"
  },
  {
    "text": "our perspective as users the ml job",
    "start": "435360",
    "end": "438639"
  },
  {
    "text": "would look like in a way that you uh do",
    "start": "438639",
    "end": "441599"
  },
  {
    "text": "some CPU based computations then some",
    "start": "441599",
    "end": "444199"
  },
  {
    "text": "GPU based stuff then a bit of waiting",
    "start": "444199",
    "end": "447120"
  },
  {
    "text": "time I do process fetch the data from",
    "start": "447120",
    "end": "448919"
  },
  {
    "text": "the dis and then then uh ear instant",
    "start": "448919",
    "end": "450840"
  },
  {
    "text": "repeat that type of process so basically",
    "start": "450840",
    "end": "453400"
  },
  {
    "text": "what you would have is a queue uh of",
    "start": "453400",
    "end": "456639"
  },
  {
    "text": "things that need to run on top of your",
    "start": "456639",
    "end": "458840"
  },
  {
    "text": "Hardware so uh the problem is that if",
    "start": "458840",
    "end": "462960"
  },
  {
    "text": "the queue there something that you want",
    "start": "462960",
    "end": "464440"
  },
  {
    "text": "to put in a queue exceeds the available",
    "start": "464440",
    "end": "466280"
  },
  {
    "text": "GPU space that's when you would start",
    "start": "466280",
    "end": "469199"
  },
  {
    "text": "having problems and needing to uh",
    "start": "469199",
    "end": "471639"
  },
  {
    "text": "basically do more resource aware",
    "start": "471639",
    "end": "473520"
  },
  {
    "text": "scheduling and if you have a bigger",
    "start": "473520",
    "end": "474919"
  },
  {
    "text": "setup the problem is even bigger because",
    "start": "474919",
    "end": "476919"
  },
  {
    "text": "on one single GPU it's easy to man you",
    "start": "476919",
    "end": "479800"
  },
  {
    "text": "can use stains tolerations and basically",
    "start": "479800",
    "end": "481840"
  },
  {
    "text": "describe your pods in a way that it",
    "start": "481840",
    "end": "483080"
  },
  {
    "text": "makes sense uh but if you have a full",
    "start": "483080",
    "end": "486159"
  },
  {
    "text": "data center or multiple racks like this",
    "start": "486159",
    "end": "488720"
  },
  {
    "text": "this problem gets more and more complex",
    "start": "488720",
    "end": "490800"
  },
  {
    "text": "so we are starting typically from the",
    "start": "490800",
    "end": "493120"
  },
  {
    "text": "place where we actually interact with",
    "start": "493120",
    "end": "494879"
  },
  {
    "text": "the system uh that would be Cube flow in",
    "start": "494879",
    "end": "497120"
  },
  {
    "text": "that case because it gives you a nice",
    "start": "497120",
    "end": "498560"
  },
  {
    "text": "way to generate pipelines notebooks the",
    "start": "498560",
    "end": "501560"
  },
  {
    "text": "QR code will bring you to the way how to",
    "start": "501560",
    "end": "503240"
  },
  {
    "text": "install it in an easy way and that's",
    "start": "503240",
    "end": "506960"
  },
  {
    "text": "like the front end part what's actual",
    "start": "506960",
    "end": "509919"
  },
  {
    "text": "important and what the stock is about is",
    "start": "509919",
    "end": "511840"
  },
  {
    "text": "what happens behind Cube flow and what",
    "start": "511840",
    "end": "513680"
  },
  {
    "text": "are the things that are enabling using",
    "start": "513680",
    "end": "516640"
  },
  {
    "text": "it in very big infrastructures so the",
    "start": "516640",
    "end": "520200"
  },
  {
    "text": "first project that we are utilizing very",
    "start": "520200",
    "end": "522919"
  },
  {
    "text": "heavily is paddle paddle that's",
    "start": "522919",
    "end": "524440"
  },
  {
    "text": "basically something that allows you to",
    "start": "524440",
    "end": "526640"
  },
  {
    "text": "split the bigger task or a training job",
    "start": "526640",
    "end": "528920"
  },
  {
    "text": "into smaller pieces because obviously in",
    "start": "528920",
    "end": "531240"
  },
  {
    "text": "any scheduling if you want to fit stuff",
    "start": "531240",
    "end": "533120"
  },
  {
    "text": "in the queue if they are smaller that's",
    "start": "533120",
    "end": "535000"
  },
  {
    "text": "easier right like queuing uh 70 gigs of",
    "start": "535000",
    "end": "539000"
  },
  {
    "text": "a work CL on 80 gigs GPU you don't have",
    "start": "539000",
    "end": "541440"
  },
  {
    "text": "a lot of flexibility if you have it like",
    "start": "541440",
    "end": "543600"
  },
  {
    "text": "a lot of small jobs which require five 5",
    "start": "543600",
    "end": "546120"
  },
  {
    "text": "gigs of GPU memory it's much easier to",
    "start": "546120",
    "end": "548360"
  },
  {
    "text": "distribute them and then the scheduler",
    "start": "548360",
    "end": "551000"
  },
  {
    "text": "the standard kubernetes scheduler is not",
    "start": "551000",
    "end": "553040"
  },
  {
    "text": "really great with various types of",
    "start": "553040",
    "end": "554880"
  },
  {
    "text": "Hardware so what we are using typically",
    "start": "554880",
    "end": "557320"
  },
  {
    "text": "on those bigger infrastructures would be",
    "start": "557320",
    "end": "558959"
  },
  {
    "text": "volcano that's a really great project",
    "start": "558959",
    "end": "561279"
  },
  {
    "text": "that allows you to perform gang",
    "start": "561279",
    "end": "563120"
  },
  {
    "text": "scheduling and more like complicated",
    "start": "563120",
    "end": "565600"
  },
  {
    "text": "assignments of things so if you have a",
    "start": "565600",
    "end": "567800"
  },
  {
    "text": "job that actually price of multiple",
    "start": "567800",
    "end": "570240"
  },
  {
    "text": "tasks because you manag to split it with",
    "start": "570240",
    "end": "572560"
  },
  {
    "text": "paddle puddle then the next thing that",
    "start": "572560",
    "end": "574240"
  },
  {
    "text": "you will be doing is basically",
    "start": "574240",
    "end": "576200"
  },
  {
    "text": "calculating how much resources does the",
    "start": "576200",
    "end": "578480"
  },
  {
    "text": "job needs so that you can do a proper",
    "start": "578480",
    "end": "580720"
  },
  {
    "text": "workload placement so if you see that",
    "start": "580720",
    "end": "582360"
  },
  {
    "text": "okay I need 20 gigs of GPU memory I need",
    "start": "582360",
    "end": "585480"
  },
  {
    "text": "five CPU CES and that amount of ram",
    "start": "585480",
    "end": "587720"
  },
  {
    "text": "these are my options and that's how I",
    "start": "587720",
    "end": "589959"
  },
  {
    "text": "can place the workload so volcano works",
    "start": "589959",
    "end": "592880"
  },
  {
    "text": "by itself on a single kubernetes cluster",
    "start": "592880",
    "end": "595399"
  },
  {
    "text": "as a scheduler really nicely but in",
    "start": "595399",
    "end": "597640"
  },
  {
    "text": "reality whenever you have a bigger",
    "start": "597640",
    "end": "600079"
  },
  {
    "text": "training environment and you need to run",
    "start": "600079",
    "end": "602399"
  },
  {
    "text": "on top of multiple case clusters because",
    "start": "602399",
    "end": "604680"
  },
  {
    "text": "obviously a single kubernetes will not",
    "start": "604680",
    "end": "606680"
  },
  {
    "text": "be really able to serve like 12,000 gpus",
    "start": "606680",
    "end": "609320"
  },
  {
    "text": "because if you calculate to nodes four",
    "start": "609320",
    "end": "611760"
  },
  {
    "text": "gpus per Noe it's still too big",
    "start": "611760",
    "end": "614120"
  },
  {
    "text": "infrastructure to run it in one cluster",
    "start": "614120",
    "end": "616480"
  },
  {
    "text": "so you will have uh different ways of",
    "start": "616480",
    "end": "619320"
  },
  {
    "text": "how to actually split it in terms of the",
    "start": "619320",
    "end": "621399"
  },
  {
    "text": "resources and pulling it and the actual",
    "start": "621399",
    "end": "624240"
  },
  {
    "text": "scheduling is pretty uh much uh",
    "start": "624240",
    "end": "627600"
  },
  {
    "text": "something that looks like like this on",
    "start": "627600",
    "end": "629680"
  },
  {
    "text": "the picture here and it allows you to",
    "start": "629680",
    "end": "632720"
  },
  {
    "text": "the for an every job to either schedule",
    "start": "632720",
    "end": "634640"
  },
  {
    "text": "it but you can also preempt some jobs or",
    "start": "634640",
    "end": "636600"
  },
  {
    "text": "remove them from the queue or actually",
    "start": "636600",
    "end": "638600"
  },
  {
    "text": "even evict the pods if the higher",
    "start": "638600",
    "end": "640800"
  },
  {
    "text": "priority thing comes in so if you have",
    "start": "640800",
    "end": "642399"
  },
  {
    "text": "multiple teams you can allocate",
    "start": "642399",
    "end": "644639"
  },
  {
    "text": "priorities between them and Define which",
    "start": "644639",
    "end": "647160"
  },
  {
    "text": "job uh would take a precedent for",
    "start": "647160",
    "end": "650120"
  },
  {
    "text": "example if you have uh an overflow of a",
    "start": "650120",
    "end": "652800"
  },
  {
    "text": "queue or other problems like this if you",
    "start": "652800",
    "end": "655320"
  },
  {
    "text": "have more kubernetes clusters the Armada",
    "start": "655320",
    "end": "657720"
  },
  {
    "text": "project is really great if you want to",
    "start": "657720",
    "end": "659040"
  },
  {
    "text": "have one single point of entry and then",
    "start": "659040",
    "end": "662240"
  },
  {
    "text": "distribute it across uh multiple case",
    "start": "662240",
    "end": "664760"
  },
  {
    "text": "clusters with its own schedulers so uh",
    "start": "664760",
    "end": "668360"
  },
  {
    "text": "with this long intro of the technologies",
    "start": "668360",
    "end": "670639"
  },
  {
    "text": "that we use let me bring you to the",
    "start": "670639",
    "end": "672959"
  },
  {
    "text": "actual part of the real world examples",
    "start": "672959",
    "end": "676320"
  },
  {
    "text": "and the projects that I was working on",
    "start": "676320",
    "end": "678880"
  },
  {
    "text": "before coming here and over last six to",
    "start": "678880",
    "end": "681000"
  },
  {
    "text": "nine months so basically there was one",
    "start": "681000",
    "end": "684279"
  },
  {
    "text": "common denominator in all of them they",
    "start": "684279",
    "end": "686040"
  },
  {
    "text": "were all like public sector related big",
    "start": "686040",
    "end": "688560"
  },
  {
    "text": "clouds that give compute capacity to",
    "start": "688560",
    "end": "691519"
  },
  {
    "text": "multiple tenants so the size of the",
    "start": "691519",
    "end": "694440"
  },
  {
    "text": "infrastructure was between 10 to 15 K",
    "start": "694440",
    "end": "696959"
  },
  {
    "text": "gpus which means around 3,000 nodes and",
    "start": "696959",
    "end": "700720"
  },
  {
    "text": "typically something around a few",
    "start": "700720",
    "end": "702360"
  },
  {
    "text": "thousand of users uh splited into",
    "start": "702360",
    "end": "704880"
  },
  {
    "text": "various teams so that's basically the",
    "start": "704880",
    "end": "707839"
  },
  {
    "text": "main problem sharing the resources in an",
    "start": "707839",
    "end": "709760"
  },
  {
    "text": "efficient way they do everything on",
    "start": "709760",
    "end": "711920"
  },
  {
    "text": "those clusters it's not only running",
    "start": "711920",
    "end": "713519"
  },
  {
    "text": "training and inference but also stores",
    "start": "713519",
    "end": "716360"
  },
  {
    "text": "the data and uh typically if it's like a",
    "start": "716360",
    "end": "719920"
  },
  {
    "text": "sovereign Cloud environment uh people",
    "start": "719920",
    "end": "722680"
  },
  {
    "text": "are looking into open source projects",
    "start": "722680",
    "end": "724320"
  },
  {
    "text": "and want to build it fully full stack",
    "start": "724320",
    "end": "727600"
  },
  {
    "text": "end to endend open source and there are",
    "start": "727600",
    "end": "729360"
  },
  {
    "text": "lot of strict requirements about",
    "start": "729360",
    "end": "730800"
  },
  {
    "text": "security and slas and the setup that one",
    "start": "730800",
    "end": "735079"
  },
  {
    "text": "of the projects was using was uh couple",
    "start": "735079",
    "end": "739160"
  },
  {
    "text": "different open source projects as",
    "start": "739160",
    "end": "740480"
  },
  {
    "text": "databases the new additions to the",
    "start": "740480",
    "end": "742560"
  },
  {
    "text": "standard thing that you would see here",
    "start": "742560",
    "end": "744240"
  },
  {
    "text": "would be the vector DB and what we saw",
    "start": "744240",
    "end": "747720"
  },
  {
    "text": "that works really well as especially",
    "start": "747720",
    "end": "749560"
  },
  {
    "text": "with like internal llms with racks and",
    "start": "749560",
    "end": "753600"
  },
  {
    "text": "uh trying to get like internal data uh",
    "start": "753600",
    "end": "756839"
  },
  {
    "text": "and knowledge about it into the llm",
    "start": "756839",
    "end": "759000"
  },
  {
    "text": "would be open search or postgress with",
    "start": "759000",
    "end": "761120"
  },
  {
    "text": "PG VOR extension these are the two most",
    "start": "761120",
    "end": "763800"
  },
  {
    "text": "POS most uh dominant things that we saw",
    "start": "763800",
    "end": "766800"
  },
  {
    "text": "working well in those environments and",
    "start": "766800",
    "end": "769079"
  },
  {
    "text": "the rest is like a fairly standard mlops",
    "start": "769079",
    "end": "771600"
  },
  {
    "text": "tool chain uh we also work with them on",
    "start": "771600",
    "end": "774680"
  },
  {
    "text": "a like a full guided Journey started",
    "start": "774680",
    "end": "776959"
  },
  {
    "text": "with architecting that environment",
    "start": "776959",
    "end": "778839"
  },
  {
    "text": "putting into production and now",
    "start": "778839",
    "end": "780920"
  },
  {
    "text": "expanding it to multiple nodes but what",
    "start": "780920",
    "end": "783720"
  },
  {
    "text": "are the learnings so first thing that we",
    "start": "783720",
    "end": "786000"
  },
  {
    "text": "learned is to listen to various people",
    "start": "786000",
    "end": "788720"
  },
  {
    "text": "the biggest pitfalls that we got were",
    "start": "788720",
    "end": "791240"
  },
  {
    "text": "actually not coming from the data",
    "start": "791240",
    "end": "793000"
  },
  {
    "text": "scientists or from the end users of the",
    "start": "793000",
    "end": "794600"
  },
  {
    "text": "models but from places like compliance",
    "start": "794600",
    "end": "797360"
  },
  {
    "text": "Department legal people and lot of other",
    "start": "797360",
    "end": "799720"
  },
  {
    "text": "problems in terms of how stuff is being",
    "start": "799720",
    "end": "801839"
  },
  {
    "text": "shared and it's important in terms of",
    "start": "801839",
    "end": "803440"
  },
  {
    "text": "the GPU sharing because some of the",
    "start": "803440",
    "end": "805160"
  },
  {
    "text": "methods of how you can allocate the GPU",
    "start": "805160",
    "end": "807560"
  },
  {
    "text": "to a workload will a low memory leakage",
    "start": "807560",
    "end": "810480"
  },
  {
    "text": "and obviously if you are running uh",
    "start": "810480",
    "end": "812320"
  },
  {
    "text": "workloads in the GOL space uh there are",
    "start": "812320",
    "end": "815920"
  },
  {
    "text": "strict requirements about who can see",
    "start": "815920",
    "end": "817639"
  },
  {
    "text": "what and what type of data so you need",
    "start": "817639",
    "end": "819160"
  },
  {
    "text": "to really watch out especially if you",
    "start": "819160",
    "end": "821040"
  },
  {
    "text": "slice GPU into smaller pieces so that",
    "start": "821040",
    "end": "823160"
  },
  {
    "text": "you don't have any leakage between the",
    "start": "823160",
    "end": "825680"
  },
  {
    "text": "workloads the hardware choice that was",
    "start": "825680",
    "end": "827800"
  },
  {
    "text": "really well working for us is a mixture",
    "start": "827800",
    "end": "831160"
  },
  {
    "text": "of different things so first of all the",
    "start": "831160",
    "end": "833560"
  },
  {
    "text": "bigger portion of things around 70% of",
    "start": "833560",
    "end": "835880"
  },
  {
    "text": "the cluster would be something big H1",
    "start": "835880",
    "end": "839399"
  },
  {
    "text": "h200 powerful gpus that has a lot of",
    "start": "839399",
    "end": "842000"
  },
  {
    "text": "memory we can slice it into mix slices",
    "start": "842000",
    "end": "845040"
  },
  {
    "text": "and basically run the big jobs the small",
    "start": "845040",
    "end": "847360"
  },
  {
    "text": "jobs like very flexible here the 20%",
    "start": "847360",
    "end": "851000"
  },
  {
    "text": "would be mid-range gpus that will allow",
    "start": "851000",
    "end": "853920"
  },
  {
    "text": "us to basically make scheduling more",
    "start": "853920",
    "end": "856000"
  },
  {
    "text": "efficient that's the only reason why",
    "start": "856000",
    "end": "857320"
  },
  {
    "text": "they exist here so that you have some",
    "start": "857320",
    "end": "859160"
  },
  {
    "text": "additional capacity that you can place",
    "start": "859160",
    "end": "860920"
  },
  {
    "text": "the workflows that are spilling over the",
    "start": "860920",
    "end": "863320"
  },
  {
    "text": "memory of your big GPU and also around",
    "start": "863320",
    "end": "866399"
  },
  {
    "text": "10% you will have the lowend GPU",
    "start": "866399",
    "end": "869639"
  },
  {
    "text": "something like l40 which is uh best in",
    "start": "869639",
    "end": "873560"
  },
  {
    "text": "terms of price performance like dollars",
    "start": "873560",
    "end": "875440"
  },
  {
    "text": "per flops and it's for inference it's",
    "start": "875440",
    "end": "879000"
  },
  {
    "text": "for testing and also for putting even",
    "start": "879000",
    "end": "881839"
  },
  {
    "text": "the smallest pieces of the job into the",
    "start": "881839",
    "end": "884440"
  },
  {
    "text": "GPU that uh does you don't require that",
    "start": "884440",
    "end": "887000"
  },
  {
    "text": "kind of level of speed and that fast",
    "start": "887000",
    "end": "889800"
  },
  {
    "text": "connectivity uh another thing is that",
    "start": "889800",
    "end": "892440"
  },
  {
    "text": "actually people still use VMS which is",
    "start": "892440",
    "end": "894560"
  },
  {
    "text": "really bad but uh in that particular",
    "start": "894560",
    "end": "896800"
  },
  {
    "text": "space if you want to put them in the mix",
    "start": "896800",
    "end": "898680"
  },
  {
    "text": "but nevertheless uh it's they are still",
    "start": "898680",
    "end": "900920"
  },
  {
    "text": "important they are utilizing them first",
    "start": "900920",
    "end": "903320"
  },
  {
    "text": "for the performance on the databases and",
    "start": "903320",
    "end": "906440"
  },
  {
    "text": "also a lot of Legacy workflows that they",
    "start": "906440",
    "end": "908160"
  },
  {
    "text": "use to pull the data from uh like",
    "start": "908160",
    "end": "911440"
  },
  {
    "text": "especially in the federal sector we have",
    "start": "911440",
    "end": "913720"
  },
  {
    "text": "seen tons of people still using things",
    "start": "913720",
    "end": "915800"
  },
  {
    "text": "like sap from which they need to pull uh",
    "start": "915800",
    "end": "918800"
  },
  {
    "text": "their data Legacy deployments and we are",
    "start": "918800",
    "end": "921720"
  },
  {
    "text": "solving this problem using the open",
    "start": "921720",
    "end": "924160"
  },
  {
    "text": "source projects FD and basically on the",
    "start": "924160",
    "end": "926480"
  },
  {
    "text": "same cluster with the same resources but",
    "start": "926480",
    "end": "929440"
  },
  {
    "text": "defining resource pools with Metals a",
    "start": "929440",
    "end": "932240"
  },
  {
    "text": "service and flexibly scaling the amount",
    "start": "932240",
    "end": "935720"
  },
  {
    "text": "of things that are still running on VMS",
    "start": "935720",
    "end": "937519"
  },
  {
    "text": "and shrinking it down every month",
    "start": "937519",
    "end": "939680"
  },
  {
    "text": "whenever they start migrating to",
    "start": "939680",
    "end": "941519"
  },
  {
    "text": "something newer uh one additional thing",
    "start": "941519",
    "end": "944759"
  },
  {
    "text": "is that whenever you design this type of",
    "start": "944759",
    "end": "946839"
  },
  {
    "text": "architecture you need to look to have",
    "start": "946839",
    "end": "948600"
  },
  {
    "text": "multiple storage types obviously",
    "start": "948600",
    "end": "951519"
  },
  {
    "text": "standard Object Store S3 that's cool but",
    "start": "951519",
    "end": "954759"
  },
  {
    "text": "you also need some additional local",
    "start": "954759",
    "end": "956839"
  },
  {
    "text": "storage and one thing that typically",
    "start": "956839",
    "end": "958519"
  },
  {
    "text": "people from get about is a big file",
    "start": "958519",
    "end": "960720"
  },
  {
    "text": "storage there are a lot of places where",
    "start": "960720",
    "end": "963120"
  },
  {
    "text": "uh either the llm model itself is a file",
    "start": "963120",
    "end": "965759"
  },
  {
    "text": "that will exceed your fire system",
    "start": "965759",
    "end": "967680"
  },
  {
    "text": "capacity or you have big files like from",
    "start": "967680",
    "end": "971360"
  },
  {
    "text": "oil and gas industry field maps might be",
    "start": "971360",
    "end": "974160"
  },
  {
    "text": "something that will not fit on a",
    "start": "974160",
    "end": "975399"
  },
  {
    "text": "standard storage so that's another thing",
    "start": "975399",
    "end": "977920"
  },
  {
    "text": "that can bite you the scheduling",
    "start": "977920",
    "end": "979720"
  },
  {
    "text": "complexity so we tried various different",
    "start": "979720",
    "end": "982240"
  },
  {
    "text": "schedulers ways of sharing the gpus and",
    "start": "982240",
    "end": "984720"
  },
  {
    "text": "the combination of MiG volcano and",
    "start": "984720",
    "end": "987120"
  },
  {
    "text": "Armada was the best thing that allowed",
    "start": "987120",
    "end": "989480"
  },
  {
    "text": "us to actually increase the GPU",
    "start": "989480",
    "end": "992480"
  },
  {
    "text": "utilization and we are typically using",
    "start": "992480",
    "end": "996079"
  },
  {
    "text": "Cube flow as the UI part to control it",
    "start": "996079",
    "end": "998600"
  },
  {
    "text": "because those projects by themselves and",
    "start": "998600",
    "end": "1001399"
  },
  {
    "text": "M as a technology is super complicated",
    "start": "1001399",
    "end": "1003319"
  },
  {
    "text": "and it's not that easy to use by the end",
    "start": "1003319",
    "end": "1006079"
  },
  {
    "text": "user so that's the setup that worked",
    "start": "1006079",
    "end": "1008079"
  },
  {
    "text": "best for us over course of those",
    "start": "1008079",
    "end": "1010279"
  },
  {
    "text": "projects and networking as the main",
    "start": "1010279",
    "end": "1013040"
  },
  {
    "text": "bottleneck if you have an infra with any",
    "start": "1013040",
    "end": "1015959"
  },
  {
    "text": "new gpus you have to go with X that's",
    "start": "1015959",
    "end": "1019560"
  },
  {
    "text": "the only thing that will give you enough",
    "start": "1019560",
    "end": "1021519"
  },
  {
    "text": "performance and enough scalability in",
    "start": "1021519",
    "end": "1023199"
  },
  {
    "text": "those clusters in order to go with h100",
    "start": "1023199",
    "end": "1025600"
  },
  {
    "text": "h200 level uh and especially with the",
    "start": "1025600",
    "end": "1028798"
  },
  {
    "text": "recently few days ago announced",
    "start": "1028799",
    "end": "1030400"
  },
  {
    "text": "blackwall chip that that will be the",
    "start": "1030400",
    "end": "1031918"
  },
  {
    "text": "networking that you will use so if you",
    "start": "1031919",
    "end": "1033360"
  },
  {
    "text": "want your cluster ready to be expanded",
    "start": "1033360",
    "end": "1036079"
  },
  {
    "text": "by that that's super important uh make",
    "start": "1036079",
    "end": "1039000"
  },
  {
    "text": "sure that you have three dedicated",
    "start": "1039000",
    "end": "1040400"
  },
  {
    "text": "networks one for the GPU traffic which",
    "start": "1040400",
    "end": "1043120"
  },
  {
    "text": "will be one of those technologies that I",
    "start": "1043120",
    "end": "1044678"
  },
  {
    "text": "mentioned a dedicated storage Network",
    "start": "1044679",
    "end": "1047000"
  },
  {
    "text": "because that also is uh sometimes a huge",
    "start": "1047000",
    "end": "1049520"
  },
  {
    "text": "bottleneck whenever your fractional",
    "start": "1049520",
    "end": "1052520"
  },
  {
    "text": "piece of the job needs to fetch",
    "start": "1052520",
    "end": "1054440"
  },
  {
    "text": "additional data from your S3 or any",
    "start": "1054440",
    "end": "1057000"
  },
  {
    "text": "other place and also whatever automation",
    "start": "1057000",
    "end": "1060640"
  },
  {
    "text": "tooling you are using it needs to be",
    "start": "1060640",
    "end": "1063080"
  },
  {
    "text": "aware of the top of the rck switch and",
    "start": "1063080",
    "end": "1065120"
  },
  {
    "text": "be able to reconfigure it actually",
    "start": "1065120",
    "end": "1067440"
  },
  {
    "text": "during the scheduling when we have jobs",
    "start": "1067440",
    "end": "1069720"
  },
  {
    "text": "that are doing rebalancing and changing",
    "start": "1069720",
    "end": "1071799"
  },
  {
    "text": "the amount of nodes in each cluster or",
    "start": "1071799",
    "end": "1073440"
  },
  {
    "text": "rules for scheduling you will in lot of",
    "start": "1073440",
    "end": "1077159"
  },
  {
    "text": "cases end up in a moment where where you",
    "start": "1077159",
    "end": "1079039"
  },
  {
    "text": "have to reconfigure your networking and",
    "start": "1079039",
    "end": "1081200"
  },
  {
    "text": "if the automation tooling that you are",
    "start": "1081200",
    "end": "1082679"
  },
  {
    "text": "using is not able to see it that will be",
    "start": "1082679",
    "end": "1085159"
  },
  {
    "text": "super difficult and will require a lot",
    "start": "1085159",
    "end": "1087320"
  },
  {
    "text": "of manual stuff and hacks so typical",
    "start": "1087320",
    "end": "1091159"
  },
  {
    "text": "deployment in terms of Hardware that is",
    "start": "1091159",
    "end": "1093280"
  },
  {
    "text": "under the bare metal kubernetes that you",
    "start": "1093280",
    "end": "1095000"
  },
  {
    "text": "would want to run would split more or",
    "start": "1095000",
    "end": "1098400"
  },
  {
    "text": "less like this so on the left hand side",
    "start": "1098400",
    "end": "1099960"
  },
  {
    "text": "you see the man management track this",
    "start": "1099960",
    "end": "1102400"
  },
  {
    "text": "will be no GPU compute where you have",
    "start": "1102400",
    "end": "1106440"
  },
  {
    "text": "your control plane you will have your",
    "start": "1106440",
    "end": "1108799"
  },
  {
    "text": "CPU based compute for stuff like uis",
    "start": "1108799",
    "end": "1111640"
  },
  {
    "text": "your AMA web UI or whatever you project",
    "start": "1111640",
    "end": "1114320"
  },
  {
    "text": "you are using to basically uh visualize",
    "start": "1114320",
    "end": "1116840"
  },
  {
    "text": "the llm to people your notes that are",
    "start": "1116840",
    "end": "1118760"
  },
  {
    "text": "controlling the vector database doing",
    "start": "1118760",
    "end": "1120480"
  },
  {
    "text": "some data ingestion stuff and so on on",
    "start": "1120480",
    "end": "1122600"
  },
  {
    "text": "the right hand side you have your GPU",
    "start": "1122600",
    "end": "1125000"
  },
  {
    "text": "notes and storage noes uh from the",
    "start": "1125000",
    "end": "1127720"
  },
  {
    "text": "networking perspective it's really good",
    "start": "1127720",
    "end": "1129280"
  },
  {
    "text": "to put place them in the same rack and",
    "start": "1129280",
    "end": "1131520"
  },
  {
    "text": "then you can see here two different",
    "start": "1131520",
    "end": "1134080"
  },
  {
    "text": "mentions of observability stock that's",
    "start": "1134080",
    "end": "1136559"
  },
  {
    "text": "also something that we learn the hard",
    "start": "1136559",
    "end": "1138520"
  },
  {
    "text": "way not to mix those two so the",
    "start": "1138520",
    "end": "1140400"
  },
  {
    "text": "observability for the ml pipelines and",
    "start": "1140400",
    "end": "1143000"
  },
  {
    "text": "the tools running there versus the",
    "start": "1143000",
    "end": "1144440"
  },
  {
    "text": "observability for the underlying",
    "start": "1144440",
    "end": "1146720"
  },
  {
    "text": "Hardware uh it was much better for us to",
    "start": "1146720",
    "end": "1149520"
  },
  {
    "text": "separate those and then if you look at",
    "start": "1149520",
    "end": "1152000"
  },
  {
    "text": "the tooling perspective so having those",
    "start": "1152000",
    "end": "1154600"
  },
  {
    "text": "notes and those racks placed like on the",
    "start": "1154600",
    "end": "1156799"
  },
  {
    "text": "previous screen you put metal as a",
    "start": "1156799",
    "end": "1159400"
  },
  {
    "text": "service to control them and add them to",
    "start": "1159400",
    "end": "1162280"
  },
  {
    "text": "the plane and then you can run a",
    "start": "1162280",
    "end": "1164200"
  },
  {
    "text": "kubernetes cluster with volcano GPU",
    "start": "1164200",
    "end": "1166960"
  },
  {
    "text": "Network operator me configured and your",
    "start": "1166960",
    "end": "1169400"
  },
  {
    "text": "tools on top of those case clusters but",
    "start": "1169400",
    "end": "1172360"
  },
  {
    "text": "what's nice if you have any Cloud",
    "start": "1172360",
    "end": "1174480"
  },
  {
    "text": "management platform on top and multiple",
    "start": "1174480",
    "end": "1177320"
  },
  {
    "text": "of those clusters shared across multiple",
    "start": "1177320",
    "end": "1179559"
  },
  {
    "text": "teams you have your job cues and then",
    "start": "1179559",
    "end": "1182440"
  },
  {
    "text": "the resource pools that are in Mass",
    "start": "1182440",
    "end": "1184679"
  },
  {
    "text": "allow you the flexibility so whenever",
    "start": "1184679",
    "end": "1187559"
  },
  {
    "text": "your observability system sees that TMA",
    "start": "1187559",
    "end": "1190120"
  },
  {
    "text": "is typically utilizing additional",
    "start": "1190120",
    "end": "1191960"
  },
  {
    "text": "resources they schedule a lot of job on",
    "start": "1191960",
    "end": "1193799"
  },
  {
    "text": "an idle resources that are on the",
    "start": "1193799",
    "end": "1195360"
  },
  {
    "text": "cluster of Team B you can rebalance it",
    "start": "1195360",
    "end": "1197760"
  },
  {
    "text": "you can add nodes from the resource pool",
    "start": "1197760",
    "end": "1200200"
  },
  {
    "text": "B to Resource pool a and put them in one",
    "start": "1200200",
    "end": "1202200"
  },
  {
    "text": "kubernetes cluster so basically that's",
    "start": "1202200",
    "end": "1203679"
  },
  {
    "text": "an exercise that we are doing with uh",
    "start": "1203679",
    "end": "1205919"
  },
  {
    "text": "weekly over the weekend to re-balance",
    "start": "1205919",
    "end": "1208039"
  },
  {
    "text": "all the resources and keep them confined",
    "start": "1208039",
    "end": "1210760"
  },
  {
    "text": "into each and one cluster because",
    "start": "1210760",
    "end": "1213000"
  },
  {
    "text": "whatever you do on the initial stage on",
    "start": "1213000",
    "end": "1215280"
  },
  {
    "text": "the workshop asking the customer for",
    "start": "1215280",
    "end": "1216880"
  },
  {
    "text": "requirements yes this team a needs 200",
    "start": "1216880",
    "end": "1219200"
  },
  {
    "text": "gpus Team B needs 400 that's an",
    "start": "1219200",
    "end": "1222200"
  },
  {
    "text": "assumption and typically in reality it",
    "start": "1222200",
    "end": "1224720"
  },
  {
    "text": "changes a lot even like completely",
    "start": "1224720",
    "end": "1227400"
  },
  {
    "text": "opposite and and the whole observability",
    "start": "1227400",
    "end": "1230679"
  },
  {
    "text": "and evolution why it's super important",
    "start": "1230679",
    "end": "1232799"
  },
  {
    "text": "we are monitoring the utilization of the",
    "start": "1232799",
    "end": "1235880"
  },
  {
    "text": "gpus and also of the network and all the",
    "start": "1235880",
    "end": "1238080"
  },
  {
    "text": "other components of the system and then",
    "start": "1238080",
    "end": "1240720"
  },
  {
    "text": "do a full reconfiguration so besides the",
    "start": "1240720",
    "end": "1244640"
  },
  {
    "text": "resource pools we are also changing the",
    "start": "1244640",
    "end": "1247039"
  },
  {
    "text": "Priority Access between the teams in",
    "start": "1247039",
    "end": "1249120"
  },
  {
    "text": "terms of the priority on the scheduling",
    "start": "1249120",
    "end": "1250799"
  },
  {
    "text": "queue uh changing the slicing of the",
    "start": "1250799",
    "end": "1253200"
  },
  {
    "text": "gpus because if we see that all the jobs",
    "start": "1253200",
    "end": "1256240"
  },
  {
    "text": "that we run are utilizing at least two",
    "start": "1256240",
    "end": "1258600"
  },
  {
    "text": "for at least four slices it means that",
    "start": "1258600",
    "end": "1260360"
  },
  {
    "text": "it doesn't make sense to slide this in",
    "start": "1260360",
    "end": "1262440"
  },
  {
    "text": "that granular way uh and lose some",
    "start": "1262440",
    "end": "1265720"
  },
  {
    "text": "performance on that and also there's a",
    "start": "1265720",
    "end": "1267720"
  },
  {
    "text": "lot of optimizations that you can do on",
    "start": "1267720",
    "end": "1269240"
  },
  {
    "text": "the framework level itself on Tron ker",
    "start": "1269240",
    "end": "1271919"
  },
  {
    "text": "or however you handle the request that's",
    "start": "1271919",
    "end": "1274559"
  },
  {
    "text": "also additional place where you can look",
    "start": "1274559",
    "end": "1277919"
  },
  {
    "text": "into and if you want to ask some",
    "start": "1277919",
    "end": "1280279"
  },
  {
    "text": "questions about those projects or you",
    "start": "1280279",
    "end": "1281679"
  },
  {
    "text": "have something similar this is the way",
    "start": "1281679",
    "end": "1283600"
  },
  {
    "text": "how you can reach me and contact me and",
    "start": "1283600",
    "end": "1286039"
  },
  {
    "text": "I'm happy to talk more with you after",
    "start": "1286039",
    "end": "1288200"
  },
  {
    "text": "this uh thank you for listening",
    "start": "1288200",
    "end": "1292720"
  },
  {
    "text": "that",
    "start": "1293880",
    "end": "1296880"
  }
]
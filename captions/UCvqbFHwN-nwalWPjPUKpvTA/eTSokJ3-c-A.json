[
  {
    "start": "0",
    "end": "45000"
  },
  {
    "text": "all right hello and welcome to kubecon we're happy to to be here with you today to talk about rook and seth and the deep dive uh i'm",
    "start": "160",
    "end": "7120"
  },
  {
    "text": "travis nielsen from red hat i'm one of the maintainers focusing on the seth operator here with sebastian uh hi",
    "start": "7120",
    "end": "16480"
  },
  {
    "text": "everyone happy to be here as well in this virtual event um i'm sebastian i work with travis",
    "start": "16480",
    "end": "22400"
  },
  {
    "text": "um we're both at red hat i'm i'm one of the rook maintainers as well and i'm i'm focusing mainly on the step",
    "start": "22400",
    "end": "29599"
  },
  {
    "text": "integration the step back-end provider yep so let's see if we can get this",
    "start": "29599",
    "end": "34960"
  },
  {
    "text": "virtual event figured out and i'm going to turn off our video so we can focus on",
    "start": "34960",
    "end": "40640"
  },
  {
    "text": "the slides so next slide here",
    "start": "40640",
    "end": "45840"
  },
  {
    "start": "45000",
    "end": "45000"
  },
  {
    "text": "all right so you've heard a bit from jared and alexander in the rook introduction talk a couple of days ago",
    "start": "45920",
    "end": "51199"
  },
  {
    "text": "hopefully if you didn't have a chance to go check that out i'd definitely recommend it um",
    "start": "51199",
    "end": "57920"
  },
  {
    "text": "we uh you know what what's happening in rook just to recap what they might have already said",
    "start": "57920",
    "end": "63520"
  },
  {
    "text": "so the we we've been a cnc i think you've been competing projects since september of uh",
    "start": "63520",
    "end": "69200"
  },
  {
    "text": "2018 uh and we're now going through the final phases of graduation the voting is in",
    "start": "69200",
    "end": "76720"
  },
  {
    "text": "progress as of our recording today and we're really hoping fingers crossed that the",
    "start": "76720",
    "end": "81840"
  },
  {
    "text": "voting is all completed and we can announce graduation at kubecon now we hope for your vote there as well",
    "start": "81840",
    "end": "88240"
  },
  {
    "text": "it's just been a great journey and and looking forward to to that being done",
    "start": "88240",
    "end": "95360"
  },
  {
    "text": "our latest release is version 1.4 so check it out try it out we'd love",
    "start": "95600",
    "end": "102560"
  },
  {
    "text": "your feedback we always value the feedback of the community to make the product better and better",
    "start": "102560",
    "end": "109520"
  },
  {
    "start": "109000",
    "end": "109000"
  },
  {
    "text": "so again what is rook so to start off rook is an open source project apache 2 license",
    "start": "110479",
    "end": "117280"
  },
  {
    "text": "and it is a a collection of storage operators for kubernetes uh",
    "start": "117280",
    "end": "123360"
  },
  {
    "text": "for multiple storage providers including ceph and cassandra nfs and a few others but today",
    "start": "123360",
    "end": "130479"
  },
  {
    "text": "we're going to focus on the ceph operator for this deep dive",
    "start": "130479",
    "end": "135680"
  },
  {
    "text": "so rook fundamentally its job is to automate the management of ceph",
    "start": "135680",
    "end": "142640"
  },
  {
    "text": "seth as a software defined storage system is you know it's it's complex and it well",
    "start": "142640",
    "end": "148800"
  },
  {
    "text": "it needs to be deployed configured when it's time to upgrade you know there are tasks that we just",
    "start": "148800",
    "end": "155840"
  },
  {
    "text": "want to make sure work smoothly that work well and do it in a way that",
    "start": "155840",
    "end": "161599"
  },
  {
    "text": "works in an absolutely integrated way with kubernetes there's no reason for doing things",
    "start": "161599",
    "end": "168400"
  },
  {
    "text": "outside kubernetes when you can do it all inside your same kubernetes cluster you need storage",
    "start": "168400",
    "end": "174400"
  },
  {
    "text": "um come to rook and ceph to get that that storage",
    "start": "174400",
    "end": "179760"
  },
  {
    "start": "180000",
    "end": "180000"
  },
  {
    "text": "so next uh what is ceph many of you i'm sure you've heard of it",
    "start": "180319",
    "end": "185599"
  },
  {
    "text": "but it is also a separate open source project and it is the distributed",
    "start": "185599",
    "end": "191840"
  },
  {
    "text": "software defined solution storage solution it provides block",
    "start": "191840",
    "end": "198800"
  },
  {
    "text": "shared file system and object storage so think of block storage as what we",
    "start": "198800",
    "end": "205360"
  },
  {
    "text": "typically think of as you need read write once volumes rwo volumes and kubernetes",
    "start": "205360",
    "end": "212080"
  },
  {
    "text": "you know that's going to be a block volume typically a shared file system you need multiple clients to share the",
    "start": "212080",
    "end": "219760"
  },
  {
    "text": "same volume rwx typically used for that and then object storage if",
    "start": "219760",
    "end": "226239"
  },
  {
    "text": "you need an s3 endpoint seth also can provide that layer of the storage so that's",
    "start": "226239",
    "end": "234080"
  },
  {
    "text": "saf in a nutshell so what does this look like we've got a",
    "start": "234080",
    "end": "239200"
  },
  {
    "text": "few diagrams here well before we get to the diagrams actually let me talk about three",
    "start": "239200",
    "end": "245599"
  },
  {
    "text": "layers of the system that are just important and helpful to understand the difference",
    "start": "245599",
    "end": "251120"
  },
  {
    "text": "so rook the operator has an operator for ceph and it owns the management of ceph that means it deploys",
    "start": "251120",
    "end": "258320"
  },
  {
    "text": "ceph it manages everything about kubernetes integration with ceph okay that's the first layer",
    "start": "258320",
    "end": "266320"
  },
  {
    "text": "second layer is csi so csi allows you to",
    "start": "266320",
    "end": "272240"
  },
  {
    "text": "dynamically provision and attach your your client pods or applications to",
    "start": "272240",
    "end": "279919"
  },
  {
    "text": "the storage layer now csi is the the interface for um any any storage",
    "start": "279919",
    "end": "286639"
  },
  {
    "text": "volume for uh in kubernetes and other uh platforms but there's a cf csi driver that then",
    "start": "286639",
    "end": "294320"
  },
  {
    "text": "provides that in rook and to provide the sep storage and then",
    "start": "294320",
    "end": "299600"
  },
  {
    "text": "finally the third layer is the data layer with ceph and it's seth as already mentioned absolutely provides",
    "start": "299600",
    "end": "306080"
  },
  {
    "text": "that that data connection rook in no way",
    "start": "306080",
    "end": "311280"
  },
  {
    "text": "is involved in the data path once all of this is set up and running and so let's take a look now at these",
    "start": "311280",
    "end": "318000"
  },
  {
    "text": "diagrams of what what it looks like from rook's perspective so layer one what does rook",
    "start": "318000",
    "end": "323199"
  },
  {
    "start": "320000",
    "end": "320000"
  },
  {
    "text": "like look like let's see if i can point with my mouse here so the the rook",
    "start": "323199",
    "end": "328880"
  },
  {
    "text": "operator is is the core the core component in in the system",
    "start": "328880",
    "end": "336560"
  },
  {
    "text": "of managing seth the operator is the brains that decides how to deploy",
    "start": "336560",
    "end": "342240"
  },
  {
    "text": "ceph you know it stores or calls all the kubernetes apis",
    "start": "342240",
    "end": "347520"
  },
  {
    "text": "and works to make sure seth is just working seamlessly so a comment about the color",
    "start": "347520",
    "end": "354720"
  },
  {
    "text": "coding here the blue pods are what we consider as rook you know core rook pods like we've got",
    "start": "354720",
    "end": "362479"
  },
  {
    "text": "discovery demons that are running on nodes to discover what devices are available",
    "start": "362479",
    "end": "368080"
  },
  {
    "text": "but most things are not actually core rook pods these green pods then are layer two with",
    "start": "368080",
    "end": "375039"
  },
  {
    "text": "these csi plug-in csi driver for stuff and then the red pods",
    "start": "375039",
    "end": "381360"
  },
  {
    "text": "are going to be all of the ceph demons so steph has a number of different demons that",
    "start": "381360",
    "end": "387600"
  },
  {
    "text": "have their responsibilities to provide the storage and now you've got the mons that are the",
    "start": "387600",
    "end": "393919"
  },
  {
    "text": "brains for ceph you've got the osds that actually manage the individual data devices where",
    "start": "393919",
    "end": "400400"
  },
  {
    "text": "where storage is is bound on on an actual node",
    "start": "400400",
    "end": "406240"
  },
  {
    "text": "and anyway we don't have time to go into all what all these demons are but just know that so rook is deploying",
    "start": "406560",
    "end": "413759"
  },
  {
    "text": "these pods and services and other kubernetes resources to manage seth and and the csi drive",
    "start": "413759",
    "end": "422240"
  },
  {
    "text": "okay fill up layer two um in layer two we've got the csi",
    "start": "422240",
    "end": "429360"
  },
  {
    "start": "423000",
    "end": "423000"
  },
  {
    "text": "drivers so we're at the point now where if layer one is deployed we're assuming okay seth is ready to go it's ready to be",
    "start": "429360",
    "end": "436080"
  },
  {
    "text": "consumed now let's figure out how to consume it so you create your app and",
    "start": "436080",
    "end": "445520"
  },
  {
    "text": "you define a storage class so here let's start on the left so you'd",
    "start": "445520",
    "end": "452160"
  },
  {
    "text": "define a volume claim a pvc where you want to claim that storage",
    "start": "452160",
    "end": "458638"
  },
  {
    "text": "that requests that from the rbd storage class so rbd is the seth block layer",
    "start": "458960",
    "end": "466879"
  },
  {
    "text": "so you define the storage class and then the cfcsi driver for rbd provisions that",
    "start": "466879",
    "end": "475440"
  },
  {
    "text": "that volume and returns it back to the application pod and mounts it in that pod",
    "start": "475440",
    "end": "482400"
  },
  {
    "text": "okay and the same basic pattern happens for the shared file system i mean you've got the pvc",
    "start": "482400",
    "end": "489199"
  },
  {
    "text": "that request the storage from this ffs storage class now uh cfs is the shared file system",
    "start": "489199",
    "end": "496560"
  },
  {
    "text": "and then uh the csi driver for cephas is the one that provisions the volume",
    "start": "496560",
    "end": "501840"
  },
  {
    "text": "and again mounts it for the application pod and the third type of storage we've",
    "start": "501840",
    "end": "507360"
  },
  {
    "text": "got here is object with the s3 or rest endpoint",
    "start": "507360",
    "end": "513440"
  },
  {
    "text": "and we've got in rook a bucket claim a concept very similar to pvc but it's",
    "start": "513440",
    "end": "520240"
  },
  {
    "text": "for object storage it gives you a bucket from a special kind of object storage class",
    "start": "520240",
    "end": "526399"
  },
  {
    "text": "which we've defined and then the bucket provisioner",
    "start": "526399",
    "end": "531440"
  },
  {
    "text": "creates the bucket and returns it to the application",
    "start": "531440",
    "end": "535839"
  },
  {
    "text": "okay so now that we've deployed rook and layer one we've got the csi driver",
    "start": "536560",
    "end": "545519"
  },
  {
    "start": "537000",
    "end": "537000"
  },
  {
    "text": "attaching all the storage to your pods in layer two now it comes time to actually write data",
    "start": "545519",
    "end": "551360"
  },
  {
    "text": "to seth player three so when in this this picture",
    "start": "551360",
    "end": "556480"
  },
  {
    "text": "the um layer one and two are really out of the picture we're just talking about",
    "start": "556480",
    "end": "561920"
  },
  {
    "text": "your application now needs to write data so it goes to the volume mount",
    "start": "561920",
    "end": "567200"
  },
  {
    "text": "here for rbd there is an rbd kernel driver that knows how to go talk to all of",
    "start": "567200",
    "end": "574000"
  },
  {
    "text": "these ceph demons which are running here the mods and lsds and",
    "start": "574000",
    "end": "579760"
  },
  {
    "text": "it just abstracts all of that for you and makes it work the and same first ffs and object store",
    "start": "579760",
    "end": "588160"
  },
  {
    "text": "object storage you you know the the client just talks to the volume or the s3",
    "start": "588160",
    "end": "596160"
  },
  {
    "text": "i use the s3 client like it would any other targeting s3 or targeting volume",
    "start": "596160",
    "end": "603120"
  },
  {
    "text": "and underneath the covers set the best kernel driver handles the connection to ceph or the s3 client handles the connection",
    "start": "603120",
    "end": "610560"
  },
  {
    "text": "to the rdw endpoint for that object storage",
    "start": "610560",
    "end": "616399"
  },
  {
    "text": "okay well time is flying i wish we had even more time to dive in here so what does it take to get",
    "start": "616399",
    "end": "622240"
  },
  {
    "text": "started with rook uh we we've made it as simple as possible in kubernetes and",
    "start": "622240",
    "end": "627839"
  },
  {
    "start": "626000",
    "end": "626000"
  },
  {
    "text": "and you also hopefully saw that demo in the intro talk on on it actually working uh but there's",
    "start": "627839",
    "end": "634800"
  },
  {
    "text": "basically three manifests or yaml files that you need to create so you start off with one they",
    "start": "634800",
    "end": "641440"
  },
  {
    "text": "call common.yaml that gives you your rbac settings gives privileges to the operator",
    "start": "641440",
    "end": "646800"
  },
  {
    "text": "basically so you create the operator and then you define how you want rook to",
    "start": "646800",
    "end": "653519"
  },
  {
    "text": "deploy the seth cluster in the cluster yaml on the right here we've got a snippet that",
    "start": "653519",
    "end": "658959"
  },
  {
    "text": "we don't really have time to talk about but basically we tell we tell this tells",
    "start": "658959",
    "end": "664000"
  },
  {
    "text": "rook how to deploy ceph in your cluster once you've deployed seth then again",
    "start": "664000",
    "end": "670399"
  },
  {
    "text": "that layer 1 this picture kind of shows the layer two and three where",
    "start": "670399",
    "end": "675920"
  },
  {
    "text": "you define the storage class you create a pvc for your application",
    "start": "675920",
    "end": "681360"
  },
  {
    "text": "and then if your application might define its pod spec something like",
    "start": "681360",
    "end": "687120"
  },
  {
    "text": "this where the volume has a pvc",
    "start": "687120",
    "end": "692160"
  },
  {
    "text": "that refers back to that that volume that's been cleaned and from there it's just like any",
    "start": "692160",
    "end": "698480"
  },
  {
    "text": "application that has the local volume and can write and read read from it",
    "start": "698480",
    "end": "704800"
  },
  {
    "text": "so let's back up a second and say okay that seemed too simple well yeah you probably need to to plan a",
    "start": "706480",
    "end": "712399"
  },
  {
    "text": "little more ahead for how you want to deploy in your production servers",
    "start": "712399",
    "end": "717839"
  },
  {
    "text": "you know do you want to deploy in on bare metal do you have your own data center or are you deploying to the cloud",
    "start": "717839",
    "end": "725040"
  },
  {
    "text": "do you have local devices or do you have something else so whether you're in the on bare metal",
    "start": "725040",
    "end": "731040"
  },
  {
    "text": "or in the cloud you need you can decide well do i want to provision",
    "start": "731040",
    "end": "737279"
  },
  {
    "text": "storage that sef uses provision that from a pv if i'm in the cloud like maybe i want to",
    "start": "737279",
    "end": "743440"
  },
  {
    "text": "to back ceph by an ebs or",
    "start": "743440",
    "end": "748959"
  },
  {
    "text": "you know google volume whatever storage provider or cloud provider i'm in i should be",
    "start": "748959",
    "end": "754240"
  },
  {
    "text": "able to consume its storage and put stuff on top of it and we'll talk more about that in a minute in that scenario or if i'm in my data",
    "start": "754240",
    "end": "761760"
  },
  {
    "text": "center and and i just have raw devices okay maybe i want to use all raw devices",
    "start": "761760",
    "end": "767760"
  },
  {
    "text": "maybe i want to list all the nodes and devices individually because i don't",
    "start": "767760",
    "end": "772880"
  },
  {
    "text": "trust rook or don't want rook to use all devices or maybe i want a lot more flexibility",
    "start": "772880",
    "end": "779519"
  },
  {
    "text": "for these for a new concept called stef drive groups and roof lets you configure those drive groups",
    "start": "779519",
    "end": "785519"
  },
  {
    "text": "in our latest release and again when you're setting up your",
    "start": "785519",
    "end": "791839"
  },
  {
    "start": "788000",
    "end": "788000"
  },
  {
    "text": "cluster topology your you got to think about your failure domains",
    "start": "791839",
    "end": "797519"
  },
  {
    "text": "you know where do you you know if if you have a node or or a zone whole zone go down",
    "start": "797519",
    "end": "804399"
  },
  {
    "text": "you know how can you keep your your cluster working you want you need to spread the different",
    "start": "804399",
    "end": "811440"
  },
  {
    "text": "root components and set components across those failure domains because if one failure domain goes down if it's set",
    "start": "811440",
    "end": "816639"
  },
  {
    "text": "up properly your storage keeps on working and it handles that it's designed for that resiliency",
    "start": "816639",
    "end": "824000"
  },
  {
    "text": "and also you know as you're doing that you know rook is as flexible as possible within the means",
    "start": "826480",
    "end": "833279"
  },
  {
    "text": "that kubernetes provides so you can have node affinity you know you've you're tainting your nodes and",
    "start": "833279",
    "end": "839360"
  },
  {
    "text": "you can add tolerations to rook you can pod and affinity et cetera",
    "start": "839360",
    "end": "845040"
  },
  {
    "text": "whatever options for placement that kubernetes offers we do our best to",
    "start": "845040",
    "end": "851920"
  },
  {
    "text": "expose that through book and one more so back to this topic on",
    "start": "851920",
    "end": "858240"
  },
  {
    "text": "cloud environment so why would you want to run rook and ceph in a cloud environment",
    "start": "858240",
    "end": "863360"
  },
  {
    "text": "you might ask because the cloud provider already has storage well there's a few important concepts",
    "start": "863360",
    "end": "868480"
  },
  {
    "text": "here so first you know having a consistent storage platform wherever kubernetes is deployed is a",
    "start": "868480",
    "end": "875680"
  },
  {
    "text": "powerful concept rook gives you that storage abstraction where you can run rook everywhere kubernetes runs",
    "start": "875680",
    "end": "883760"
  },
  {
    "text": "store our cloud providers do have shortcomings that we hear about you know whether it's having storage",
    "start": "883760",
    "end": "889360"
  },
  {
    "text": "across azs or there's slow failover times",
    "start": "889360",
    "end": "894480"
  },
  {
    "text": "limitations of the number of pvs per node and even proof characteristics of a",
    "start": "894480",
    "end": "899839"
  },
  {
    "text": "large you want the perfect characteristics of large volumes not small volumes so you get that with with",
    "start": "899839",
    "end": "905040"
  },
  {
    "text": "rook and then finally yes you can run",
    "start": "905040",
    "end": "911360"
  },
  {
    "text": "the cef components so the mons and the osds are the the two that are stateful and that store all the state",
    "start": "911360",
    "end": "916959"
  },
  {
    "text": "first off um you can run them on pvcs meaning you don't need direct",
    "start": "916959",
    "end": "922399"
  },
  {
    "text": "access to local devices these these can run request pvcs from",
    "start": "922399",
    "end": "928399"
  },
  {
    "text": "the cloud environment all right and now i'll hand the torch",
    "start": "928399",
    "end": "934560"
  },
  {
    "text": "over to sebastian to continue on some other key features in rook take it away yeah thanks travis",
    "start": "934560",
    "end": "941839"
  },
  {
    "text": "so now that we are familiar with what rook is what it does and also what ceph is and",
    "start": "941839",
    "end": "947920"
  },
  {
    "text": "what it can provide to us in terms of functionality then let's dive into some of the",
    "start": "947920",
    "end": "953279"
  },
  {
    "text": "key features that rook provides to you all right so one of the beauty of",
    "start": "953279",
    "end": "959839"
  },
  {
    "text": "rook is that everything is automated and that's it's it's essentially it is",
    "start": "959839",
    "end": "965920"
  },
  {
    "text": "really what the goal of every single operator is is is to",
    "start": "965920",
    "end": "971600"
  },
  {
    "text": "take all of that operational knowledge and just just put it into a logical entity",
    "start": "971600",
    "end": "978959"
  },
  {
    "text": "where it could really benefit of years of experience of managing upgrades and actually",
    "start": "978959",
    "end": "985279"
  },
  {
    "text": "upgrades is probably always one of the most painful and difficult thing to to",
    "start": "985279",
    "end": "992399"
  },
  {
    "text": "achieve when it comes to software so fortunately rook is here for you and",
    "start": "992399",
    "end": "999839"
  },
  {
    "text": "rook can handle all of that so there are two things right the first one is",
    "start": "999839",
    "end": "1004880"
  },
  {
    "text": "upgrading rook on its own and it's super easy you just need to update the image spec",
    "start": "1004880",
    "end": "1012160"
  },
  {
    "text": "of your deployment and then kubernetes will go ahead and roll out a new version",
    "start": "1012160",
    "end": "1017279"
  },
  {
    "text": "of of your operator obviously once we we do a big step to a new",
    "start": "1017279",
    "end": "1025280"
  },
  {
    "text": "version of rook for example we we just released 1.4 so if you go from 1.3 to",
    "start": "1025280",
    "end": "1030959"
  },
  {
    "text": "1.4 then there are steps that you would have to apply so to using using the the upgrade guide",
    "start": "1030959",
    "end": "1039678"
  },
  {
    "text": "so that crd definitions can be updated as well as necessary r backs to to have",
    "start": "1039679",
    "end": "1046319"
  },
  {
    "text": "rook keep keep on working and then probably the most interesting piece here is",
    "start": "1046319",
    "end": "1051440"
  },
  {
    "text": "the ceph upgrade on its own where rook will really be handling everything",
    "start": "1051440",
    "end": "1058960"
  },
  {
    "text": "and again it is really simple the only thing you have to do here is just to update the setcaster custom resource and change",
    "start": "1058960",
    "end": "1066559"
  },
  {
    "text": "its image by a new one rook supports pinpoints updates as well as major upgrades of",
    "start": "1066559",
    "end": "1075600"
  },
  {
    "text": "ceph and all of the intricacies and all of the details that",
    "start": "1075600",
    "end": "1081120"
  },
  {
    "text": "you have to all the things you would be doing manually per se all of these things would be would be",
    "start": "1081120",
    "end": "1087280"
  },
  {
    "text": "handled by rook rook will go one by one demon by demon and make sure that",
    "start": "1087280",
    "end": "1093200"
  },
  {
    "text": "they're all healthy before moving to the next one as part of its own reconciliation so yeah",
    "start": "1093200",
    "end": "1100559"
  },
  {
    "text": "upgrades are i would say finally made really simple and really",
    "start": "1100559",
    "end": "1105919"
  },
  {
    "text": "easy to do and actually we just have really good feedback from the community",
    "start": "1105919",
    "end": "1111039"
  },
  {
    "text": "it's really super straightforward to upgrade rook and not painful at all so moving on now",
    "start": "1111039",
    "end": "1117600"
  },
  {
    "text": "to the csi driver uh obviously as travis mentioned",
    "start": "1117600",
    "end": "1123200"
  },
  {
    "text": "we can deploy rook deploys ceph maintains it through its entire",
    "start": "1123200",
    "end": "1128799"
  },
  {
    "text": "life cycle but there is no point of simply deploying storage technology also what you have to do is to",
    "start": "1128799",
    "end": "1135039"
  },
  {
    "text": "use it so that you can provide persistent storage to your containers and this is where csi and particularly sap csi plays a big",
    "start": "1135039",
    "end": "1143120"
  },
  {
    "text": "role as part of the latest version of rook we also introduced and released at the same time a three",
    "start": "1143120",
    "end": "1150080"
  },
  {
    "text": "dollar version of the csi driver as we saw earlier it still supports",
    "start": "1150080",
    "end": "1156000"
  },
  {
    "text": "dynamic provisioning for all the access methods rwx and for both block devices as well as",
    "start": "1156000",
    "end": "1162799"
  },
  {
    "text": "the system but what's really new about this is really the snapshots and cloning functionality",
    "start": "1162799",
    "end": "1168400"
  },
  {
    "text": "that are actually better and ready to be consumed as some kind of tech preview let's say",
    "start": "1168400",
    "end": "1175679"
  },
  {
    "text": "also we still have support for flex drivers so if you're still using it then upgrade",
    "start": "1175679",
    "end": "1182640"
  },
  {
    "text": "will be supported and you you can continue on using it but obviously this is where the community is moving",
    "start": "1182640",
    "end": "1188480"
  },
  {
    "text": "communities moving out of flex driver for csi so it's it's really highly recommended",
    "start": "1188480",
    "end": "1194960"
  },
  {
    "text": "to move um but to csi but still we we support flex",
    "start": "1194960",
    "end": "1200640"
  },
  {
    "text": "all right x no cluster connection that was probably one of the most desired",
    "start": "1200640",
    "end": "1206640"
  },
  {
    "start": "1201000",
    "end": "1201000"
  },
  {
    "text": "feature uh two or three releases ago and essentially what what we do here is that it is not",
    "start": "1206640",
    "end": "1213280"
  },
  {
    "text": "always about green fields right not everybody has moved to fully capabilities",
    "start": "1213280",
    "end": "1218400"
  },
  {
    "text": "environments yet and maybe some of you will never do because you already have a brownfield",
    "start": "1218400",
    "end": "1224480"
  },
  {
    "text": "environment and your subcluster is already there maybe it's serving other purposes maybe it's connected to openstack maybe it's connected to your",
    "start": "1224480",
    "end": "1231360"
  },
  {
    "text": "proximos hypervisor whatever it might be and what",
    "start": "1231360",
    "end": "1236559"
  },
  {
    "text": "this excellent mode allows you to do is basically start this consumer producer",
    "start": "1236559",
    "end": "1243039"
  },
  {
    "text": "relationship where the producer is the external tester and the consumer at this point is rook",
    "start": "1243039",
    "end": "1249520"
  },
  {
    "text": "so the major difference here is that at this point won't be managing the resources it will",
    "start": "1249520",
    "end": "1256799"
  },
  {
    "text": "only consume them and the beauty of that is that it is really simple so the only thing you have to do is to",
    "start": "1256799",
    "end": "1263280"
  },
  {
    "text": "inject a couple of details from your external cluster and and you're ready to go csi would get",
    "start": "1263280",
    "end": "1269520"
  },
  {
    "text": "those information and then you can go ahead and create your pvc start your",
    "start": "1269520",
    "end": "1274799"
  },
  {
    "text": "pods and you you got your storage object pickup provisioning",
    "start": "1274799",
    "end": "1280159"
  },
  {
    "text": "so aka obc we have already discussed that briefly",
    "start": "1280159",
    "end": "1287360"
  },
  {
    "text": "in one of the diagrams that travis showed you earlier but essentially it is really similar to the pvc interface",
    "start": "1287360",
    "end": "1294799"
  },
  {
    "text": "where at this point you don't do block devices you just do bucket as a user",
    "start": "1294799",
    "end": "1300080"
  },
  {
    "text": "you don't want to really go into the let's say well the pain of having to create a",
    "start": "1300080",
    "end": "1305840"
  },
  {
    "text": "bucket manually having to create a user manually the only thing you care about is give me a bucket give me credentials so that i",
    "start": "1305840",
    "end": "1312000"
  },
  {
    "text": "can start playing with this s3 api and i can connect my application",
    "start": "1312000",
    "end": "1318000"
  },
  {
    "text": "to it and rook basically provides you that that support",
    "start": "1318000",
    "end": "1323280"
  },
  {
    "text": "all right here it is the latest and greatest release of rook i'm super excited about",
    "start": "1323280",
    "end": "1330000"
  },
  {
    "text": "all the things that everyone has been doing all the contributions we received from",
    "start": "1330000",
    "end": "1335600"
  },
  {
    "text": "from the community and here are some some of the highlights",
    "start": "1335600",
    "end": "1341120"
  },
  {
    "start": "1340000",
    "end": "1340000"
  },
  {
    "text": "first off we maltus first we we introduced multis during the",
    "start": "1341520",
    "end": "1348080"
  },
  {
    "text": "1.3 cycle and uh we we actually marked it as experimental the reason why we marked it",
    "start": "1348080",
    "end": "1354880"
  },
  {
    "text": "as experimental is because we we have we had half of the picture complete and",
    "start": "1354880",
    "end": "1361520"
  },
  {
    "text": "what i mean by that is in one three we were already able to consume",
    "start": "1361520",
    "end": "1367679"
  },
  {
    "text": "motors by basically bootstrapping the entire roof cluster",
    "start": "1367679",
    "end": "1372960"
  },
  {
    "text": "using dedicated network interfaces but was what was not available yet is",
    "start": "1372960",
    "end": "1379200"
  },
  {
    "text": "the connection through csi what we what we added in that 1.4",
    "start": "1379200",
    "end": "1384400"
  },
  {
    "text": "release is basically the ability to connect csi",
    "start": "1384400",
    "end": "1391120"
  },
  {
    "text": "through voltas so that application pods can consume the storage via a dedicated",
    "start": "1391120",
    "end": "1397440"
  },
  {
    "text": "network so if we step back a little bit like in malta's why would you",
    "start": "1397440",
    "end": "1404960"
  },
  {
    "text": "need to have notice if you if you're using a burglar environment",
    "start": "1404960",
    "end": "1410400"
  },
  {
    "text": "and then you really want to take advantage of all the network interfaces that",
    "start": "1410400",
    "end": "1415520"
  },
  {
    "text": "you're that that basically both for for your hardware",
    "start": "1415520",
    "end": "1420960"
  },
  {
    "text": "then this is where multis comes into play we don't really want to use the host networking mode because",
    "start": "1420960",
    "end": "1428559"
  },
  {
    "text": "it has some security implications since we expose the entire network stack",
    "start": "1428559",
    "end": "1434960"
  },
  {
    "text": "from the host into containers but with multis we can actually",
    "start": "1434960",
    "end": "1441840"
  },
  {
    "text": "we can actually decide which ip which network interface we want to",
    "start": "1441840",
    "end": "1447440"
  },
  {
    "text": "expose into a given container so we just get best of both worlds",
    "start": "1447440",
    "end": "1453760"
  },
  {
    "text": "still we the way multis is supported is through the",
    "start": "1454159",
    "end": "1459600"
  },
  {
    "text": "whereabouts ipam it is really preferred and that's the the essentially the only one we support",
    "start": "1459600",
    "end": "1466240"
  },
  {
    "text": "right now it's probably the one that works best at scale because there is no dhcp involved and",
    "start": "1466240",
    "end": "1473520"
  },
  {
    "text": "and whereabouts does its own ip management internally",
    "start": "1473520",
    "end": "1478559"
  },
  {
    "text": "so it is a more than a year old and of really active development so",
    "start": "1478559",
    "end": "1485679"
  },
  {
    "text": "obviously we don't have the full picture yet and things are missing like supporting services",
    "start": "1485679",
    "end": "1491679"
  },
  {
    "text": "we still cannot create services that are backed by multis networks basically but this is",
    "start": "1491679",
    "end": "1497919"
  },
  {
    "text": "coming and what we have today is really consumable so we're super excited about this",
    "start": "1497919",
    "end": "1504320"
  },
  {
    "text": "okay uh on to the object multi-site replication so this is a feature that has been around in ceph",
    "start": "1504320",
    "end": "1509760"
  },
  {
    "text": "uh for its object gateways for years now and it's probably one of the most desired",
    "start": "1509760",
    "end": "1516480"
  },
  {
    "text": "feature that community has been asking for for the past year is the basically ability to do object",
    "start": "1516480",
    "end": "1524799"
  },
  {
    "text": "through multi-site either you have geographically separated data center",
    "start": "1524799",
    "end": "1532480"
  },
  {
    "text": "between regions maybe and the idea here is to replicate objects between rook set",
    "start": "1532480",
    "end": "1540080"
  },
  {
    "text": "clusters are that are distanced distant to to each other's with that we we added",
    "start": "1540080",
    "end": "1548400"
  },
  {
    "text": "new concepts and they are coming straight from stuff like realms and zone groups and zone which gives us",
    "start": "1548400",
    "end": "1556720"
  },
  {
    "text": "they they really give us a thin granularity on how to configure this geo replication",
    "start": "1556720",
    "end": "1564159"
  },
  {
    "text": "so it is marked as experimental because we only have the controllers as well as the new",
    "start": "1564159",
    "end": "1570880"
  },
  {
    "text": "custom resources and in one five we will be working to basically get all the",
    "start": "1570880",
    "end": "1576640"
  },
  {
    "text": "pieces together to get a complete a complete experience",
    "start": "1576640",
    "end": "1581840"
  },
  {
    "text": "and mission controller you cannot actually uh validate everything through",
    "start": "1581840",
    "end": "1588720"
  },
  {
    "text": "the api validation from your line from your yaml definitions also you don't necessarily want to do",
    "start": "1588720",
    "end": "1595440"
  },
  {
    "text": "all of your cr cr spec validation through the controller so",
    "start": "1595440",
    "end": "1601200"
  },
  {
    "text": "through the operator because essentially once you do that it is a little bit too late",
    "start": "1601200",
    "end": "1606559"
  },
  {
    "text": "this cr has been injected and now the admin has to go through the logs and see why nothing's",
    "start": "1606559",
    "end": "1612960"
  },
  {
    "text": "happening but what's really good about the admission controller is that",
    "start": "1612960",
    "end": "1618080"
  },
  {
    "text": "the admission control will effectively intercept the creation request of the custom",
    "start": "1618080",
    "end": "1623760"
  },
  {
    "text": "resource even before the operator reconciles and knows about it so that is really useful because",
    "start": "1623760",
    "end": "1631520"
  },
  {
    "text": "straight from uh after straight after the injection you know if something's wrong and badly",
    "start": "1631520",
    "end": "1636960"
  },
  {
    "text": "configured so yeah it is uh it was also one of the most desired features we we",
    "start": "1636960",
    "end": "1643760"
  },
  {
    "text": "have not enabled it yet uh but we will do that soon the toolbox",
    "start": "1643760",
    "end": "1648960"
  },
  {
    "start": "1648000",
    "end": "1648000"
  },
  {
    "text": "the toolbox has been around for like since uh since ruka actually started it is a",
    "start": "1648960",
    "end": "1655679"
  },
  {
    "text": "little deployment that allows us to get",
    "start": "1655679",
    "end": "1661039"
  },
  {
    "text": "hands-on access to the step environment you just bootstrap it like a normal part",
    "start": "1661039",
    "end": "1667600"
  },
  {
    "text": "and once you exec into it you can run any of the staff comments just like you would be like just like",
    "start": "1667600",
    "end": "1674480"
  },
  {
    "text": "you would do normally and in 1 4 what we added essentially",
    "start": "1674480",
    "end": "1680840"
  },
  {
    "text": "is jobs that would do specific actions such as day",
    "start": "1680840",
    "end": "1686880"
  },
  {
    "text": "two operations again we don't",
    "start": "1686880",
    "end": "1692240"
  },
  {
    "text": "the main point of rook is to make storage easy easily consumable easily",
    "start": "1692240",
    "end": "1697679"
  },
  {
    "text": "configurable and easily maintained and self-maintained as well through rook so the idea here is to have",
    "start": "1697679",
    "end": "1706000"
  },
  {
    "text": "no manual integration and we have jobs that will do specific actions for example",
    "start": "1706000",
    "end": "1712320"
  },
  {
    "text": "if if a disk is is dead then we can simply remove it and for that we",
    "start": "1712320",
    "end": "1718559"
  },
  {
    "text": "would have a specific job that we care take care all of that will take care of that it will just",
    "start": "1718559",
    "end": "1725200"
  },
  {
    "text": "remove the osd remove all the keys and all the little details that you would have to do",
    "start": "1725200",
    "end": "1730480"
  },
  {
    "text": "manually but again this is fully automated and more more templates and more jobs",
    "start": "1730480",
    "end": "1736399"
  },
  {
    "text": "will be coming as we move forward we improved our",
    "start": "1736399",
    "end": "1741600"
  },
  {
    "start": "1740000",
    "end": "1740000"
  },
  {
    "text": "external mode as mentioned before this was really one of the best features",
    "start": "1741600",
    "end": "1747600"
  },
  {
    "text": "that we delivered in one three and we have been building on top of what we had so it's",
    "start": "1747600",
    "end": "1753760"
  },
  {
    "text": "even more stable even more robust right now we added the support for uh gathering",
    "start": "1753760",
    "end": "1759039"
  },
  {
    "text": "external metrics from the external cluster through the theft manager promised exporter so if you have an external",
    "start": "1759039",
    "end": "1765440"
  },
  {
    "text": "subcluster and if you have your kubernetes environment with rook then you can connect both and then you",
    "start": "1765440",
    "end": "1771120"
  },
  {
    "text": "can basically have metrics coming from your external cluster in prometheus and then you can generate",
    "start": "1771120",
    "end": "1778080"
  },
  {
    "text": "generate alerts in graphs so it's basically",
    "start": "1778080",
    "end": "1783279"
  },
  {
    "text": "getting the best out of prometheus onto an external environment which is",
    "start": "1783279",
    "end": "1788799"
  },
  {
    "text": "which is kind of cool also we extended the external support to the staff object store",
    "start": "1788799",
    "end": "1794799"
  },
  {
    "text": "so now you can actually connect to external gateways and they will be integrated in the exact",
    "start": "1794799",
    "end": "1800159"
  },
  {
    "text": "exact same fashion as when you do the converged mode so you",
    "start": "1800159",
    "end": "1805279"
  },
  {
    "text": "just pass gateway iap addresses and they will be integrated as a kubernetes service",
    "start": "1805279",
    "end": "1811360"
  },
  {
    "text": "so that is also a really nice feature and much more unfortunately we don't",
    "start": "1811360",
    "end": "1817039"
  },
  {
    "text": "have much time to discuss into many details all the good things",
    "start": "1817039",
    "end": "1822159"
  },
  {
    "text": "all the good contributions we received in that wonderful 1 4 cycle but some of the few",
    "start": "1822159",
    "end": "1828960"
  },
  {
    "text": "last items worth mentioning encryption for osd on pvc",
    "start": "1828960",
    "end": "1834399"
  },
  {
    "text": "so essentially just um doing encryption at rest on the on the drive",
    "start": "1834399",
    "end": "1840080"
  },
  {
    "text": "health checks and liveness probe configuration rook has some internal health checks",
    "start": "1840080",
    "end": "1845679"
  },
  {
    "text": "like checking demands are in quorum checking the status of the cluster checking the osd status",
    "start": "1845679",
    "end": "1850960"
  },
  {
    "text": "and these are now can be more thinly grained configured as well",
    "start": "1850960",
    "end": "1857360"
  },
  {
    "text": "as the liveness probe for each individual demons also nonetheless the all the rook crds",
    "start": "1857360",
    "end": "1864240"
  },
  {
    "text": "have been converted to use the control room time library so we are really moving uh with the",
    "start": "1864240",
    "end": "1869279"
  },
  {
    "text": "community where by using the same framework uh the same primitives",
    "start": "1869279",
    "end": "1877120"
  },
  {
    "text": "as the as all the other operators out there just to clean up was already available",
    "start": "1877120",
    "end": "1884000"
  },
  {
    "text": "in one three but we added a nice announcement uh as part of the",
    "start": "1884000",
    "end": "1889279"
  },
  {
    "text": "cleanup for the drives now not only you can clean up the drive but you can also apply specific and actually more powerful",
    "start": "1889279",
    "end": "1898000"
  },
  {
    "text": "sanitizing functionality for for your drives also just like travis mentioned earlier",
    "start": "1898000",
    "end": "1904559"
  },
  {
    "text": "we that there is a new self-drive group standard to define uh osd drives",
    "start": "1904559",
    "end": "1911279"
  },
  {
    "text": "and this has been embedded into the the step cluster cr",
    "start": "1911279",
    "end": "1916399"
  },
  {
    "text": "and i guess with that this really concludes our presentation",
    "start": "1916399",
    "end": "1921519"
  },
  {
    "text": "it was a really interesting experience at first i guess so hopefully you will",
    "start": "1921519",
    "end": "1928880"
  },
  {
    "text": "enjoy that don't forget to reach out to us go on rook.io you will see all the",
    "start": "1928880",
    "end": "1936080"
  },
  {
    "text": "materials all the dock how to get started where to find us go on github as well and we'll be really",
    "start": "1936080",
    "end": "1942880"
  },
  {
    "text": "happy to to hear from you yeah thanks sebastian it's been great to be with you today and we",
    "start": "1942880",
    "end": "1949039"
  },
  {
    "text": "definitely look forward to all your questions or contributions come find us on slack and github and all",
    "start": "1949039",
    "end": "1954640"
  },
  {
    "text": "that and hopefully we'll talk to you soon thanks everyone all right thanks stay safe take care bye",
    "start": "1954640",
    "end": "1963840"
  }
]
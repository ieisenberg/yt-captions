[
  {
    "start": "0",
    "end": "25000"
  },
  {
    "text": "hello everyone welcome to our virtual cubecon session",
    "start": "2960",
    "end": "9200"
  },
  {
    "text": "we have an interesting topic today this is on multi-node jobs with kubernetes",
    "start": "9200",
    "end": "14639"
  },
  {
    "text": "i'm madukar and this will be a joint presentation with my colleague sanjay chatterjee",
    "start": "14639",
    "end": "21759"
  },
  {
    "text": "let's begin our work is motivated by applications of",
    "start": "22720",
    "end": "29359"
  },
  {
    "start": "25000",
    "end": "25000"
  },
  {
    "text": "deep learning as you know deep learning is becoming popular in several areas",
    "start": "29359",
    "end": "37360"
  },
  {
    "text": "example in transportation self-driving cars medical imaging smart cities",
    "start": "37360",
    "end": "45280"
  },
  {
    "text": "robotics and so on in each of these areas deep learning is enabling more",
    "start": "45280",
    "end": "52320"
  },
  {
    "text": "automation and also adding new value by uncovering",
    "start": "52320",
    "end": "57360"
  },
  {
    "text": "more insights",
    "start": "57360",
    "end": "60160"
  },
  {
    "start": "62000",
    "end": "62000"
  },
  {
    "text": "now if you look into the ai deep learning stack there are several layers the top layer",
    "start": "63440",
    "end": "70560"
  },
  {
    "text": "we have the different applications like computer vision with image classification",
    "start": "70560",
    "end": "76640"
  },
  {
    "text": "natural language processing recommendation engines languages and so on at the bottom layer",
    "start": "76640",
    "end": "83680"
  },
  {
    "text": "we have the hardware components like gpus cpus",
    "start": "83680",
    "end": "89680"
  },
  {
    "text": "the various systems that are built using these components",
    "start": "89680",
    "end": "94079"
  },
  {
    "text": "above them are the architecture specific libraries like nickel and so on",
    "start": "95439",
    "end": "102880"
  },
  {
    "text": "about those are the deep learning frameworks like tensorflow pytorch etc",
    "start": "102880",
    "end": "108799"
  },
  {
    "text": "now for an application to work well all these layers must function well together there's a lot of",
    "start": "108799",
    "end": "116240"
  },
  {
    "text": "innovation happening in each of the layers so in this talk we'll see how to put",
    "start": "116240",
    "end": "122719"
  },
  {
    "text": "these things together to work well",
    "start": "122719",
    "end": "129840"
  },
  {
    "start": "130000",
    "end": "130000"
  },
  {
    "text": "so a trend we see in all these applications is that the data is becoming big and",
    "start": "130640",
    "end": "137200"
  },
  {
    "text": "models are also increasingly complex and larger",
    "start": "137200",
    "end": "142720"
  },
  {
    "text": "as an example for natural language processing bert is a recent popular model it began",
    "start": "142720",
    "end": "149120"
  },
  {
    "text": "with around 110 million parameters and burt large grew to around 330",
    "start": "149120",
    "end": "154959"
  },
  {
    "text": "million parameters more recent ones are like 8 billion and 17 billion parameters",
    "start": "154959",
    "end": "162319"
  },
  {
    "text": "so so for such large models training them takes a long time even",
    "start": "162319",
    "end": "168959"
  },
  {
    "text": "with a single gpu because of this there's a demand for",
    "start": "168959",
    "end": "174319"
  },
  {
    "text": "multi gpu jobs it's an example if you look at the graph here",
    "start": "174319",
    "end": "179599"
  },
  {
    "text": "it shows the training time for bird large using different numbers of gpus x axis",
    "start": "179599",
    "end": "185920"
  },
  {
    "text": "is the number of nvidia v100 gpus and y-axis is the",
    "start": "185920",
    "end": "191280"
  },
  {
    "text": "training time in minutes so we can see that 16 gpus it takes around 60 hours just around 2.5 days",
    "start": "191280",
    "end": "200080"
  },
  {
    "text": "1000 gpus it comes down to about an hour",
    "start": "200080",
    "end": "204800"
  },
  {
    "text": "so this speed up is significant because the data scientists can then have a faster",
    "start": "205920",
    "end": "213040"
  },
  {
    "text": "turnaround debug faster iterate faster and improve the results they can also handle",
    "start": "213040",
    "end": "220319"
  },
  {
    "text": "larger problems similar trend can also be seen in the mlp of training results so mlp is a",
    "start": "220319",
    "end": "226560"
  },
  {
    "text": "competition where several organizations submit their best training results",
    "start": "226560",
    "end": "231680"
  },
  {
    "text": "for popular benchmarks and even there we see that more gpus",
    "start": "231680",
    "end": "236799"
  },
  {
    "text": "feels faster running times",
    "start": "236799",
    "end": "241840"
  },
  {
    "start": "242000",
    "end": "242000"
  },
  {
    "text": "now given the demand for these multi gpu systems how do we build them so here's a sample",
    "start": "243519",
    "end": "250640"
  },
  {
    "text": "multi gpu node from nvidia called dgx1 so this has eight v100 gpus shown in",
    "start": "250640",
    "end": "257759"
  },
  {
    "text": "green here and they're connected by nvi link within the node",
    "start": "257759",
    "end": "263519"
  },
  {
    "text": "the node has dual socket cpus and four nicks these are melanox edr mix",
    "start": "263840",
    "end": "272080"
  },
  {
    "text": "capable of about 100 gbps so we can run up to an 8 gpu job inside",
    "start": "272080",
    "end": "277520"
  },
  {
    "text": "this node using fast and willing and if you want to go beyond a gpus then",
    "start": "277520",
    "end": "283919"
  },
  {
    "text": "we can connect multiple nodes together we can connect them using infiniband or rocky",
    "start": "283919",
    "end": "289840"
  },
  {
    "text": "which is rdma over ethernet and we do that by connecting these four",
    "start": "289840",
    "end": "296240"
  },
  {
    "text": "next to a connected fabric using different topologies",
    "start": "296240",
    "end": "301919"
  },
  {
    "text": "like factory dragonfly or other things based on our requirements so that's the",
    "start": "301919",
    "end": "308560"
  },
  {
    "text": "hardware part now let's look at the software side",
    "start": "308560",
    "end": "314400"
  },
  {
    "start": "312000",
    "end": "312000"
  },
  {
    "text": "so how do we train these multi-gpu multi-node systems",
    "start": "314400",
    "end": "319919"
  },
  {
    "text": "so there are two popular approaches data parallelism and model parallelism and you can also have a hybrid of these",
    "start": "319919",
    "end": "326639"
  },
  {
    "text": "combining the two so in this talk we'll focus on data parallelism",
    "start": "326639",
    "end": "331840"
  },
  {
    "text": "another important concept with deep learning is that of sjd stochastic gradient descent this is",
    "start": "331840",
    "end": "338080"
  },
  {
    "text": "where in the backward path of the neural network we compute gradients",
    "start": "338080",
    "end": "343520"
  },
  {
    "text": "and apply them to the weights of the neurons there are two popular hdd approaches",
    "start": "343520",
    "end": "348880"
  },
  {
    "text": "async and sync so async sjd is the parameter support approach shown here and sync sjd is the already",
    "start": "348880",
    "end": "357280"
  },
  {
    "text": "approach shown in the figure below so here the different workers",
    "start": "357280",
    "end": "364639"
  },
  {
    "text": "come gpu nodes they do a computation and at the end of the cycle they",
    "start": "364639",
    "end": "369680"
  },
  {
    "text": "exchange the gradients in all reduced fashion and that's implemented through nickel",
    "start": "369680",
    "end": "375600"
  },
  {
    "text": "or mpi nickel is nvidia collective communications library",
    "start": "375600",
    "end": "380880"
  },
  {
    "text": "and it internally handles unveiling and also infiniband rocky across nodes",
    "start": "380880",
    "end": "388479"
  },
  {
    "text": "so does it makes use of the fast interconnects the recent horror world library from",
    "start": "388479",
    "end": "394000"
  },
  {
    "text": "uber makes it easy to run the all reduced approach with tensorflow",
    "start": "394000",
    "end": "400000"
  },
  {
    "text": "and phi torch",
    "start": "400000",
    "end": "402720"
  },
  {
    "start": "404000",
    "end": "404000"
  },
  {
    "text": "so while multi-node is gaining traction kubernetes is also becoming increasingly popular to",
    "start": "405759",
    "end": "412560"
  },
  {
    "text": "orchestrate these clusters mainly because of its advantages in ease",
    "start": "412560",
    "end": "418560"
  },
  {
    "text": "of management operations cicd and then",
    "start": "418560",
    "end": "423840"
  },
  {
    "text": "other aspects over running multi-node and kubernetes has multiple challenges",
    "start": "423840",
    "end": "429759"
  },
  {
    "text": "so we divide this into two parts the left side part one",
    "start": "429759",
    "end": "435120"
  },
  {
    "text": "is how to get a single multi-node job running end-to-end and then the right side is",
    "start": "435120",
    "end": "441840"
  },
  {
    "text": "part two where we look at running multiple multi-node jobs at the same time in a cluster shared",
    "start": "441840",
    "end": "449280"
  },
  {
    "text": "cluster so let's focus on the left side and here we will look into",
    "start": "449280",
    "end": "455039"
  },
  {
    "text": "the end-to-end flow like array jobs mpi gang scheduling and multi-rail rdma",
    "start": "455039",
    "end": "464800"
  },
  {
    "start": "464000",
    "end": "464000"
  },
  {
    "text": "towards that here's a big picture overview of the flow user submits a multi-node job using a",
    "start": "464800",
    "end": "470720"
  },
  {
    "text": "cli or ui so that goes to the api server",
    "start": "470720",
    "end": "476080"
  },
  {
    "text": "it's a custom job controller which watches for that and creates an mpi job",
    "start": "476080",
    "end": "482800"
  },
  {
    "text": "and we use the upstream mpi operator from kubeflow",
    "start": "482800",
    "end": "488319"
  },
  {
    "text": "that watches for the mpi jobs and then creates corresponding pods for the mpa job those parts are then",
    "start": "488319",
    "end": "495120"
  },
  {
    "text": "scheduled by the scheduler using a gang scheduling approach",
    "start": "495120",
    "end": "500240"
  },
  {
    "text": "once scheduled the cubelet takes up the pod and tries to run it",
    "start": "500240",
    "end": "506560"
  },
  {
    "text": "so it pulls the container and the container image has the necessary libraries it'll have framework tensorflow pytorch",
    "start": "506560",
    "end": "514080"
  },
  {
    "text": "nickel mpa and so on once these pods are up and running they communicate using nickel on the",
    "start": "514080",
    "end": "520479"
  },
  {
    "text": "back end so that's how the system works",
    "start": "520479",
    "end": "525760"
  },
  {
    "start": "528000",
    "end": "528000"
  },
  {
    "text": "now let's look at a sample by dot job a bird job with two nodes how we would do that so",
    "start": "529600",
    "end": "536080"
  },
  {
    "text": "on the left side we see a command on node 0 node 1 which is rank",
    "start": "536080",
    "end": "541600"
  },
  {
    "text": "0 and then the command on node 2 which is rank 1.",
    "start": "541600",
    "end": "548320"
  },
  {
    "text": "so on both these nodes we run torch.distribute.launch and then that starts up eight processes",
    "start": "548320",
    "end": "554560"
  },
  {
    "text": "on the node one on each gpu and on this gpu we run",
    "start": "554560",
    "end": "559760"
  },
  {
    "text": "the word train dot py script that's a single gpu script so we run that eight times on node zero",
    "start": "559760",
    "end": "567519"
  },
  {
    "text": "and then mode one can the master address is set to local host on rank zero",
    "start": "567519",
    "end": "574080"
  },
  {
    "text": "and ip address of rank 0 and rank 1. so that's how they communicate",
    "start": "574080",
    "end": "580480"
  },
  {
    "text": "so on the right side we see how we launch the same job using mpi run so we use mpi run is the launcher we",
    "start": "581200",
    "end": "588000"
  },
  {
    "text": "specify the number of replicas which is array size and then it creates that many instances",
    "start": "588000",
    "end": "593839"
  },
  {
    "text": "of the torch distributed launch okay so rest all is same as before",
    "start": "593839",
    "end": "600560"
  },
  {
    "text": "so note that we use mpi run as the launcher here the back end is still nickel",
    "start": "600560",
    "end": "607360"
  },
  {
    "text": "so we manage these mpi jobs using the mpi operator and for that i'll hand it over to sanjay",
    "start": "609040",
    "end": "617279"
  },
  {
    "start": "612000",
    "end": "612000"
  },
  {
    "text": "thanks mother girl hi i'm sanjay chatterjee and it's great to be presenting at kubecon europe",
    "start": "617600",
    "end": "622800"
  },
  {
    "text": "2020 virtual all right so we have seen how a multi-node job",
    "start": "622800",
    "end": "628959"
  },
  {
    "text": "can be submitted by the user now let us look inside the kubernetes cluster in slightly more detail now typically",
    "start": "628959",
    "end": "636640"
  },
  {
    "text": "clusters have many different implementations different hardware different stack etc",
    "start": "636640",
    "end": "642880"
  },
  {
    "text": "so we use the term array jobs as an abstraction for all kinds of multi-node",
    "start": "642880",
    "end": "648399"
  },
  {
    "text": "jobs and users can configure the type and size of the job they want",
    "start": "648399",
    "end": "654640"
  },
  {
    "text": "after an array job is submitted to the cluster a an internal job spec for the cluster",
    "start": "654640",
    "end": "662720"
  },
  {
    "text": "is created and this spec is converted by the control plane components",
    "start": "662720",
    "end": "668560"
  },
  {
    "text": "to create the actual k8s pods for a multi-node job now we use a component called uh mpi",
    "start": "668560",
    "end": "676079"
  },
  {
    "text": "operator from upstream and queue flow which creates the pods and also manages their",
    "start": "676079",
    "end": "682240"
  },
  {
    "text": "life cycle as a group or gang of pods now the pod specs include uh the",
    "start": "682240",
    "end": "689760"
  },
  {
    "text": "setup to handle all the multi-part job launch as well as all the node specific",
    "start": "689760",
    "end": "696959"
  },
  {
    "text": "resource requests as shown here and finally all the parts belonging to a",
    "start": "696959",
    "end": "703200"
  },
  {
    "text": "specific job are gang scheduled by the scheduler to run on the clusters nodes",
    "start": "703200",
    "end": "710320"
  },
  {
    "text": "okay next we'll focus on a few key areas in this flow",
    "start": "710320",
    "end": "715760"
  },
  {
    "text": "and see what's going on under the hood",
    "start": "715760",
    "end": "719920"
  },
  {
    "start": "719000",
    "end": "719000"
  },
  {
    "text": "first let us look at how we enable high-speed networking for multi-node jobs in a kubernetes",
    "start": "720800",
    "end": "727600"
  },
  {
    "text": "cluster now this is an absolutely key requirement for high performance distributed deep learning applications",
    "start": "727600",
    "end": "735279"
  },
  {
    "text": "uh we've seen earlier a single nvidia dgx1 node comes equipped with eight volta v100",
    "start": "735279",
    "end": "742160"
  },
  {
    "text": "gpus and four 100 gig melanox rdma nx",
    "start": "742160",
    "end": "748000"
  },
  {
    "text": "along with dual 10 gig ethernet nics so when the keraspot spec requests all",
    "start": "748000",
    "end": "754480"
  },
  {
    "text": "these resources as shown here with this four sri vrdma resources and a gpus we need to make",
    "start": "754480",
    "end": "762959"
  },
  {
    "text": "all these available to the pod when it lands on the node now the cubelet is the kubernetes node",
    "start": "762959",
    "end": "770079"
  },
  {
    "text": "agent and it manages all the allocatable resources on the node for a pod",
    "start": "770079",
    "end": "776720"
  },
  {
    "text": "so to first include the cube rdm nx as cubelet managed resources we use",
    "start": "776720",
    "end": "783920"
  },
  {
    "text": "a sriv network device plugin which will discover the rdma nx",
    "start": "783920",
    "end": "790639"
  },
  {
    "text": "and register them with the cubelet all right so after a pod is bound to a",
    "start": "790639",
    "end": "797519"
  },
  {
    "text": "node the cubelet will start the process of moving the requested network resources from the",
    "start": "797519",
    "end": "803680"
  },
  {
    "text": "host namespace to the pods namespace and to do this it invokes",
    "start": "803680",
    "end": "809519"
  },
  {
    "text": "the associated cni plugin cni meaning the container network interface",
    "start": "809519",
    "end": "815839"
  },
  {
    "text": "since uh the dgx1 node has multiple network interfaces we use a",
    "start": "815839",
    "end": "822480"
  },
  {
    "text": "meta plugin called multis which can delegate to multiple other plugins",
    "start": "822480",
    "end": "830399"
  },
  {
    "text": "now all of these other plugins can be specific to a different kind of network interface so",
    "start": "830399",
    "end": "836480"
  },
  {
    "text": "we have a sriv cni plug-in to configure the rdma virtual interfaces",
    "start": "836480",
    "end": "842240"
  },
  {
    "text": "and a component called flannel which configures the default zero interface and both of these",
    "start": "842240",
    "end": "848480"
  },
  {
    "text": "are managed by multis okay the next thing we are going to",
    "start": "848480",
    "end": "854320"
  },
  {
    "start": "852000",
    "end": "852000"
  },
  {
    "text": "focus on is the scheduling of array jobs specifically the gang scheduling aspect of it",
    "start": "854320",
    "end": "860079"
  },
  {
    "text": "um we've seen earlier that an array job in kubernetes will create multiple ks pods now a",
    "start": "860079",
    "end": "866320"
  },
  {
    "text": "further requirement of these pods is to run as a gang that is a all-or-none policy",
    "start": "866320",
    "end": "872399"
  },
  {
    "text": "meaning either all the pods belonging to the same multi-node job will get scheduled to run or none of",
    "start": "872399",
    "end": "879120"
  },
  {
    "text": "them can run similarly one fails then all of them should fail now this is primarily so",
    "start": "879120",
    "end": "885279"
  },
  {
    "text": "that deep learning applications which use the synchronous sgd model we talked about earlier now they can",
    "start": "885279",
    "end": "892639"
  },
  {
    "text": "make progress when they use collectives such as all reduce broadcast etc",
    "start": "892639",
    "end": "899360"
  },
  {
    "text": "now the default cube scheduler schedule spots one by one and so if parts from different array",
    "start": "899360",
    "end": "906399"
  },
  {
    "text": "jobs get scheduled in an interleaved manner it can lead to deadlocks",
    "start": "906399",
    "end": "911760"
  },
  {
    "text": "so gang scheduling is currently actively discussed in the community and one proposal is to repeatedly try",
    "start": "911760",
    "end": "919920"
  },
  {
    "text": "scheduling the pods and if that fails then back off and repeat again",
    "start": "919920",
    "end": "925519"
  },
  {
    "text": "and with this approach there might be a potential for live lock so we are experimenting with a different",
    "start": "925519",
    "end": "932160"
  },
  {
    "text": "approach namely using a reservation system for full node bonds",
    "start": "932160",
    "end": "938079"
  },
  {
    "start": "937000",
    "end": "937000"
  },
  {
    "text": "right so in our approach to gang scheduling we use something called as a pod groups to be the unit",
    "start": "938480",
    "end": "944480"
  },
  {
    "text": "of scheduling for multi-node jobs now pod groups are essentially a logical",
    "start": "944480",
    "end": "950240"
  },
  {
    "text": "grouping of pods belonging to this a single multi-node job and currently we",
    "start": "950240",
    "end": "955600"
  },
  {
    "text": "only support scheduling full node pods in a multi-node job",
    "start": "955600",
    "end": "961279"
  },
  {
    "text": "so to schedule board groups we made uh some extensions to the default kubernetes schedule which include a",
    "start": "961279",
    "end": "968000"
  },
  {
    "text": "new scheduling queue that holds bot groups that is in addition to the regular pods",
    "start": "968000",
    "end": "975680"
  },
  {
    "text": "we are also experimenting with a new module called the pod group manager",
    "start": "975680",
    "end": "980880"
  },
  {
    "text": "which can reserve full nodes for the pods now the node reservations are actually",
    "start": "980880",
    "end": "987040"
  },
  {
    "text": "added as a label on the board and this allows the main scheduling control loop to bypass the regular",
    "start": "987040",
    "end": "993600"
  },
  {
    "text": "uh pod scheduling and directly bind the pods to its reserve nodes",
    "start": "993600",
    "end": "1000319"
  },
  {
    "start": "1000000",
    "end": "1000000"
  },
  {
    "text": "okay now we're going to look at a demo that will actually show the scheduling and end-to-end flow",
    "start": "1000959",
    "end": "1007199"
  },
  {
    "text": "of the multi-node jobs so here i'm submitting a two node by bert pytorch multi-node training job",
    "start": "1007199",
    "end": "1015839"
  },
  {
    "text": "and we'll see that the job will be creating uh kubernetes pods that will be scheduled and will be expected to run on",
    "start": "1015839",
    "end": "1022720"
  },
  {
    "text": "the notes so uh once the job is created we can look into the cluster and see",
    "start": "1022720",
    "end": "1028798"
  },
  {
    "text": "that the pods are created and we see that two parts are created worker zero and worker one with the same job id",
    "start": "1028799",
    "end": "1035918"
  },
  {
    "text": "and they are currently in the pending state so we can look into the pods annotations to",
    "start": "1035919",
    "end": "1041038"
  },
  {
    "text": "look at acute reason to see why it's spending and we can see that the reason",
    "start": "1041039",
    "end": "1047199"
  },
  {
    "text": "is resources are unavailable and if you look at the current state of the queue we can see",
    "start": "1047199",
    "end": "1052880"
  },
  {
    "text": "there's a number of q and pods that are in queue we can look into the",
    "start": "1052880",
    "end": "1058559"
  },
  {
    "text": "pod spec in more detail to see it's the same command eventually these pods will get",
    "start": "1058559",
    "end": "1065600"
  },
  {
    "text": "to the running state and then the user can actually look at",
    "start": "1065600",
    "end": "1071120"
  },
  {
    "text": "some real-time telemetry uh some utilization numbers and uh",
    "start": "1071120",
    "end": "1076880"
  },
  {
    "text": "with these at real time they can also look at the status history and some",
    "start": "1076880",
    "end": "1082240"
  },
  {
    "text": "logging as well okay",
    "start": "1082240",
    "end": "1087360"
  },
  {
    "text": "so now let's take a look at the job telemetry in",
    "start": "1087919",
    "end": "1095120"
  },
  {
    "start": "1090000",
    "end": "1090000"
  },
  {
    "text": "slightly more detail this is an experimental ui created for",
    "start": "1095120",
    "end": "1100160"
  },
  {
    "text": "some internal users and it's a very useful tool for them to monitor their jobs in real time",
    "start": "1100160",
    "end": "1106160"
  },
  {
    "text": "now as we can see here uh they can see some key metrics from their",
    "start": "1106160",
    "end": "1111679"
  },
  {
    "text": "jobs such as utilization numbers for gpus tensor ports cpus",
    "start": "1111679",
    "end": "1117840"
  },
  {
    "text": "memory pci links and so on and we've built a monitoring and logging",
    "start": "1117840",
    "end": "1123840"
  },
  {
    "text": "pipeline that exports all these node level performance counters and other information to the users so",
    "start": "1123840",
    "end": "1131679"
  },
  {
    "text": "that they can view how their jobs are progressing in real time",
    "start": "1131679",
    "end": "1137840"
  },
  {
    "start": "1137000",
    "end": "1137000"
  },
  {
    "text": "okay if you remember we had submitted a bird multi-node training job in the demo",
    "start": "1137919",
    "end": "1143200"
  },
  {
    "text": "so here's some throughput scaling numbers from a similar bird job and",
    "start": "1143200",
    "end": "1150640"
  },
  {
    "text": "uh they have two different configurations phase one and phase two uh",
    "start": "1150640",
    "end": "1157520"
  },
  {
    "text": "and they are using some sample training data sets now we know all the performance",
    "start": "1157520",
    "end": "1164799"
  },
  {
    "text": "uh depends on a number of system and application dependent factors such as batch size for gpu we have seen",
    "start": "1164799",
    "end": "1173120"
  },
  {
    "text": "that the throughput scaling results for example here the sequences per second have been",
    "start": "1173120",
    "end": "1179039"
  },
  {
    "text": "consistently high in terms of their parallel efficiency and in this case we",
    "start": "1179039",
    "end": "1185120"
  },
  {
    "text": "can see that the application can scale uh close to ideal",
    "start": "1185120",
    "end": "1190400"
  },
  {
    "text": "even when running on a very large number of gpus for example here on 32 nodes uh the job was",
    "start": "1190400",
    "end": "1198000"
  },
  {
    "text": "uh actually using 256 gpus concurrently and mind you these results are from a",
    "start": "1198000",
    "end": "1204320"
  },
  {
    "text": "shared cluster where multiple other jobs were also running and sharing the cluster network",
    "start": "1204320",
    "end": "1212000"
  },
  {
    "text": "all right so now i'm going to hand it back over to madhukar for the rest of the slides",
    "start": "1212000",
    "end": "1217440"
  },
  {
    "text": "thank you thank you sanjay so we now looked at",
    "start": "1217440",
    "end": "1223600"
  },
  {
    "text": "part one which shows how to run a single multi-node job end-to-end",
    "start": "1223600",
    "end": "1228720"
  },
  {
    "text": "using the bird example now let's look at part two here how do we run",
    "start": "1228720",
    "end": "1235120"
  },
  {
    "text": "multiple multi-node jobs at the same time in a shared cluster and this needs additional features like",
    "start": "1235120",
    "end": "1242320"
  },
  {
    "text": "quotas time limits backfilling etc so let's see how we handle this",
    "start": "1242320",
    "end": "1249840"
  },
  {
    "start": "1250000",
    "end": "1250000"
  },
  {
    "text": "so towards this we have a we're building a production k8s cluster",
    "start": "1251280",
    "end": "1256559"
  },
  {
    "text": "for multi-node jobs this is a shared on-prem cluster",
    "start": "1256559",
    "end": "1262000"
  },
  {
    "text": "inside a data centers and it's currently comprised of about 100 dgx nodes arranged in a single hop",
    "start": "1262000",
    "end": "1269360"
  },
  {
    "text": "fashion and it's being tried out by early internal users",
    "start": "1269360",
    "end": "1274640"
  },
  {
    "text": "so these are data scientists who are interested in training large models",
    "start": "1274640",
    "end": "1281039"
  },
  {
    "text": "so if to enable these users to share the cluster efficiently",
    "start": "1281120",
    "end": "1286159"
  },
  {
    "text": "we enforce quotas each user has a default gpu quota of about 32 gpus and",
    "start": "1286159",
    "end": "1293440"
  },
  {
    "text": "that determines how many they can use concurrently it's configurable we also enforce time limits on jobs a",
    "start": "1293440",
    "end": "1300480"
  },
  {
    "text": "wall time limit and also a node r limit let's say 128 hours which means a 16 knot job can run",
    "start": "1300480",
    "end": "1307679"
  },
  {
    "text": "about eight hours one key angle with multi-node jobs is that of starvation and bad filling",
    "start": "1307679",
    "end": "1315440"
  },
  {
    "text": "what this means is because gang scheduling is not blocking there is a large multi-node job set that",
    "start": "1315440",
    "end": "1323120"
  },
  {
    "text": "will do no job upfront it can start for a long time",
    "start": "1323120",
    "end": "1329360"
  },
  {
    "text": "so to work around that we enforces threshold and beyond the threshold we start blocking for that job",
    "start": "1330400",
    "end": "1336960"
  },
  {
    "text": "this can cause low utilization because of ideal nodes so then we backfill the nodes using",
    "start": "1336960",
    "end": "1342400"
  },
  {
    "text": "smaller jobs shorter jobs that helps us to improve utilization so this is a work in progress",
    "start": "1342400",
    "end": "1348880"
  },
  {
    "text": "we have some initial things in place but we're looking for more input and feedback to improve that",
    "start": "1348880",
    "end": "1356480"
  },
  {
    "text": "we also enforce fairness via the drx score so drf stands for dominant resource fairness",
    "start": "1356720",
    "end": "1362320"
  },
  {
    "text": "it's a popular measure we also use starvation and age as factors for the",
    "start": "1362320",
    "end": "1368720"
  },
  {
    "text": "job and we combine all these using a weighted function so this gives us a dynamic priority for the job",
    "start": "1368720",
    "end": "1375520"
  },
  {
    "text": "so that the scheduler can use that to decide which job to pick next",
    "start": "1375520",
    "end": "1381120"
  },
  {
    "text": "for a production cluster we also need good operations srd ci cd and also dashboards and alerts",
    "start": "1383200",
    "end": "1391919"
  },
  {
    "text": "so here's an example this is scheduler and mpi operator",
    "start": "1391919",
    "end": "1397120"
  },
  {
    "start": "1394000",
    "end": "1394000"
  },
  {
    "text": "dashboard it shows number of jobs in the queue for money over quota how many under",
    "start": "1397120",
    "end": "1403200"
  },
  {
    "text": "quota it says scheduling latency starvation duration and so on even for",
    "start": "1403200",
    "end": "1410720"
  },
  {
    "text": "the mpa operator it shows latency and other angles so this is a",
    "start": "1410720",
    "end": "1416000"
  },
  {
    "text": "regular grafana chart built using prometheus matrix and",
    "start": "1416000",
    "end": "1421440"
  },
  {
    "text": "one can build different dashboards like this easily using grafana these are you this can be used by the",
    "start": "1421440",
    "end": "1430080"
  },
  {
    "text": "art admins and also engineers we are also trying to enable alerts so",
    "start": "1430080",
    "end": "1436240"
  },
  {
    "text": "that sre can react to changes quickly",
    "start": "1436240",
    "end": "1441039"
  },
  {
    "text": "so in summary we have looked at multi-node clusters with kubernetes how",
    "start": "1442480",
    "end": "1447600"
  },
  {
    "text": "to enable that using gang scheduling mpi rdm etc so this is a work in progress",
    "start": "1447600",
    "end": "1455919"
  },
  {
    "text": "as next steps we are looking to harden these production deployments also need to improve performance using",
    "start": "1455919",
    "end": "1462880"
  },
  {
    "text": "storage caching and so on multi-node clusters also looking to add additional array",
    "start": "1462880",
    "end": "1468320"
  },
  {
    "text": "types like mpi spark",
    "start": "1468320",
    "end": "1473840"
  },
  {
    "text": "also aligning with upstream framework and so on so there's a work in progress and we",
    "start": "1474720",
    "end": "1480559"
  },
  {
    "text": "would like to hear from other folks who are trying similar things one thing",
    "start": "1480559",
    "end": "1486559"
  },
  {
    "text": "i would like to draw attention to is the multi-node enabled containers",
    "start": "1486559",
    "end": "1491679"
  },
  {
    "text": "so for frameworks like tensorflow pytorch and also models like bird with",
    "start": "1491679",
    "end": "1498159"
  },
  {
    "text": "multi-node enabled containers with all the necessary libraries and packages these are available from",
    "start": "1498159",
    "end": "1504760"
  },
  {
    "text": "ngc.nbc.com so we encourage all of you to download it from there and",
    "start": "1504760",
    "end": "1510240"
  },
  {
    "text": "use them finally i would like to acknowledge the contributions of various team members",
    "start": "1510240",
    "end": "1518080"
  },
  {
    "text": "within nvidia and also outside folks who are working on different layers of the stack the deep learning stack it all comes",
    "start": "1518080",
    "end": "1526840"
  },
  {
    "text": "together would also like to thank kubecon for giving us this opportunity",
    "start": "1526840",
    "end": "1532640"
  },
  {
    "text": "thank you and we'll now take questions",
    "start": "1532640",
    "end": "1536799"
  },
  {
    "text": "so we have a few questions uh first one is on whether the telemetry dashboard is open",
    "start": "1537760",
    "end": "1544640"
  },
  {
    "text": "sourced so the components we are using are open",
    "start": "1544640",
    "end": "1550400"
  },
  {
    "text": "sourced for example dcgm which is data center gpu manager it exports the different gpu",
    "start": "1550400",
    "end": "1557200"
  },
  {
    "text": "metrics to prometheus and other components so that's upstream and using that in grafana one can build",
    "start": "1557200",
    "end": "1565120"
  },
  {
    "text": "different kinds of dashboards the particular one we are using here is an experimental one",
    "start": "1565120",
    "end": "1571200"
  },
  {
    "text": "that we built for some internal teams and we are trying to get feedback and see what makes sense",
    "start": "1571200",
    "end": "1577360"
  },
  {
    "text": "etc also looking at the uh slide here",
    "start": "1577360",
    "end": "1586159"
  },
  {
    "start": "1579000",
    "end": "1579000"
  },
  {
    "text": "several other components we are using are already upstream for example the rocky cni",
    "start": "1586159",
    "end": "1593200"
  },
  {
    "text": "mpi operator on already upstream also the gpu specific things like device",
    "start": "1593200",
    "end": "1598320"
  },
  {
    "text": "plug-in gpu operator upstream so using these one can start putting together a different",
    "start": "1598320",
    "end": "1604080"
  },
  {
    "text": "multi-node solutions",
    "start": "1604080",
    "end": "1607039"
  },
  {
    "text": "okay second question is if we can it will be sharing the slides on",
    "start": "1611360",
    "end": "1617760"
  },
  {
    "text": "sked.com sure yes we'll upload them after this presentation",
    "start": "1617760",
    "end": "1627840"
  },
  {
    "text": "yeah one thing i think",
    "start": "1628880",
    "end": "1631919"
  },
  {
    "text": "also we'd like to add that if anybody has tried simple things",
    "start": "1634480",
    "end": "1640559"
  },
  {
    "text": "we would be interested to hear your experience and feedback so we look forward to discussing with",
    "start": "1640799",
    "end": "1645919"
  },
  {
    "text": "you either now or on slack afterlife",
    "start": "1645919",
    "end": "1650799"
  },
  {
    "text": "okay um so i can see a question here uh so the question is",
    "start": "1652640",
    "end": "1660240"
  },
  {
    "text": "is the gang scheduling code uh pgm open sourced",
    "start": "1660240",
    "end": "1666480"
  },
  {
    "text": "so as we said earlier in the talk that we have this experimental module called the pod group manager and",
    "start": "1666720",
    "end": "1674159"
  },
  {
    "text": "we are looking at different aspects of it uh some of the work is currently in",
    "start": "1674159",
    "end": "1679679"
  },
  {
    "text": "progress things that we talked about earlier about starvation handling backfilling",
    "start": "1679679",
    "end": "1685679"
  },
  {
    "text": "etc we're trying out different things looking at seeing what it what works",
    "start": "1685679",
    "end": "1692960"
  },
  {
    "text": "at scale uh and then finally once we are confident",
    "start": "1692960",
    "end": "1699200"
  },
  {
    "text": "about uh the code then we'll go to the next steps",
    "start": "1699200",
    "end": "1705600"
  },
  {
    "text": "um upstream it and we'll see how that works",
    "start": "1705600",
    "end": "1712559"
  },
  {
    "text": "okay um there's another question here uh this is about so the question is what",
    "start": "1713440",
    "end": "1721279"
  },
  {
    "text": "is the network bandwidth requirements for shared gpu experiments",
    "start": "1721279",
    "end": "1729520"
  },
  {
    "text": "so a large majority of the multi-node jobs in our clusters",
    "start": "1730240",
    "end": "1737840"
  },
  {
    "text": "distributed training applications and they use um what motherboard",
    "start": "1737840",
    "end": "1745679"
  },
  {
    "text": "talked about earlier the synchronous sgd model",
    "start": "1745679",
    "end": "1750320"
  },
  {
    "text": "so these applications um heavily use uh collective primitives like all reduce",
    "start": "1750960",
    "end": "1758559"
  },
  {
    "text": "broadcast etc and all of these collective primitives they",
    "start": "1758559",
    "end": "1764080"
  },
  {
    "text": "require high speed high bandwidth networks",
    "start": "1764080",
    "end": "1769039"
  },
  {
    "text": "so our job is to enable these applications to use",
    "start": "1769200",
    "end": "1774320"
  },
  {
    "text": "the these high bandwidth networks as easily and transparently as possible",
    "start": "1774320",
    "end": "1781840"
  },
  {
    "text": "so nvidia gpus they come equipped with",
    "start": "1781840",
    "end": "1788080"
  },
  {
    "text": "envy link and and it also supports",
    "start": "1788080",
    "end": "1794480"
  },
  {
    "text": "the nodes they support gpu detect rdma across nodes",
    "start": "1795039",
    "end": "1800240"
  },
  {
    "text": "and to integrate all of this there there's a library called nickel that we talked about earlier and so",
    "start": "1800240",
    "end": "1808480"
  },
  {
    "text": "applications can transparently uh use nvi link and gpu direct rdma using",
    "start": "1808480",
    "end": "1814880"
  },
  {
    "text": "nickel by either using nickel as part of the application or using a",
    "start": "1814880",
    "end": "1822000"
  },
  {
    "text": "framework like by torture tensorflow overall i think",
    "start": "1822000",
    "end": "1828159"
  },
  {
    "text": "the network requirements or its utilization depends on",
    "start": "1828159",
    "end": "1835679"
  },
  {
    "text": "many factors like how the application is written they can either use collectives through",
    "start": "1835679",
    "end": "1843039"
  },
  {
    "text": "nickel or they can use some sort of communication and",
    "start": "1843039",
    "end": "1849520"
  },
  {
    "text": "computation overlaps so applications are",
    "start": "1849520",
    "end": "1856720"
  },
  {
    "text": "but we have seen that most applications have been able to scale well with very good",
    "start": "1858399",
    "end": "1864720"
  },
  {
    "text": "parallel efficiency on these clusters so yeah that's",
    "start": "1864720",
    "end": "1872639"
  },
  {
    "text": "so we have another question which is on comparisons with volcano so",
    "start": "1875360",
    "end": "1883200"
  },
  {
    "text": "when we started few months back volcano was still not in a production ready state and",
    "start": "1883200",
    "end": "1891440"
  },
  {
    "text": "also we had some gpu requirements like working with high",
    "start": "1891440",
    "end": "1898399"
  },
  {
    "text": "speed networks rocky and so on and also dgx specific ones like working",
    "start": "1898399",
    "end": "1905279"
  },
  {
    "text": "with full node jobs so our solution is kind of tailored towards gpu and djx",
    "start": "1905279",
    "end": "1910960"
  },
  {
    "text": "specific requirements and that's what we are demoing in production and yeah i think",
    "start": "1910960",
    "end": "1918399"
  },
  {
    "text": "so we can now perhaps check with volcano and see what can be added there",
    "start": "1918399",
    "end": "1924880"
  },
  {
    "text": "and so on",
    "start": "1924880",
    "end": "1927360"
  },
  {
    "text": "yeah one thing we would also add is that as we see on the future work screen different things need to come together",
    "start": "1931840",
    "end": "1938799"
  },
  {
    "text": "uh for this to work in production like the cni mpi stuff",
    "start": "1938799",
    "end": "1944799"
  },
  {
    "text": "um and also like efficient storage being able to download the containers",
    "start": "1944799",
    "end": "1950399"
  },
  {
    "text": "efficiently so all these things need to work together and hardened in production forever to",
    "start": "1950399",
    "end": "1956320"
  },
  {
    "text": "have a good cluster so our goal has been to kind of share our learnings",
    "start": "1956320",
    "end": "1962000"
  },
  {
    "text": "from these things and also learn from the community",
    "start": "1962000",
    "end": "1967440"
  },
  {
    "text": "okay i think we can now close the session and follow up on the slack channel for",
    "start": "1975519",
    "end": "1982399"
  },
  {
    "text": "discussion thank you all for joining",
    "start": "1982399",
    "end": "1990559"
  },
  {
    "text": "you",
    "start": "1990559",
    "end": "1992640"
  }
]
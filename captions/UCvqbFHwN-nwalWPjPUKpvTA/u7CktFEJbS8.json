[
  {
    "text": "these slides may be familiar to you if you have been in the keynote this morning I can go through them in two and",
    "start": "120",
    "end": "5319"
  },
  {
    "text": "a half minutes but I think you are all here to get more information about Dynamic resource allocation so we will",
    "start": "5319",
    "end": "11719"
  },
  {
    "text": "do a lot more talking go more into details than we could in the keynote my name is Patrick Olie I work for Intel",
    "start": "11719",
    "end": "18160"
  },
  {
    "text": "I'm one of the key Architects behind this new feature that you have been hearing about this is Kevin G from",
    "start": "18160",
    "end": "23199"
  },
  {
    "text": "Nvidia he's one of our biggest users of it and also contributing to a lot of",
    "start": "23199",
    "end": "28240"
  },
  {
    "text": "content the example drivers so he will talk about how to use this feature with",
    "start": "28240",
    "end": "33800"
  },
  {
    "text": "gpus which is what you all care about if you're running AI worklow so let's let's talk a little bit",
    "start": "33800",
    "end": "40879"
  },
  {
    "text": "about what Dr does how it's designed uh it started out as an attempt to overcome",
    "start": "40879",
    "end": "47840"
  },
  {
    "text": "the limitations of the device plug-in interface we took Inspirations from the",
    "start": "47840",
    "end": "55120"
  },
  {
    "text": "volume management if you're familiar with the volume handling in kubernetes this new API is very similar we have",
    "start": "55120",
    "end": "61280"
  },
  {
    "text": "something called a resource class that can be created by an administrator users create resource claims these resource",
    "start": "61280",
    "end": "68200"
  },
  {
    "text": "claims get matched to specific hardware and then in a pot and in a container we",
    "start": "68200",
    "end": "74280"
  },
  {
    "text": "reference this resource instance to give a container access to that allocated",
    "start": "74280",
    "end": "79759"
  },
  {
    "text": "Hardware uh we designed it so that uh a resource can be local to a node that was",
    "start": "79759",
    "end": "86280"
  },
  {
    "text": "what you could be doing with a device plugin interface but it can also be Network ATT attached um then I mentioned the API",
    "start": "86280",
    "end": "93680"
  },
  {
    "text": "allows flexible sharing between ports and containers just because it's more it does have a standalone concept of",
    "start": "93680",
    "end": "100280"
  },
  {
    "text": "something that you're referencing and then we also added a new concept for",
    "start": "100280",
    "end": "105640"
  },
  {
    "text": "defining parameters for your resource claim these parameters",
    "start": "105640",
    "end": "111719"
  },
  {
    "text": "are uh affecting their scheduling you may request something of a certain size",
    "start": "111719",
    "end": "116960"
  },
  {
    "text": "but you can also in the same object Define parameters that configure your hardware and that becomes relevant when",
    "start": "116960",
    "end": "124719"
  },
  {
    "text": "we have a complex piece of Hardware that needs to be initialized in a certain way in a vendor specific format so I've already mentioned vendors",
    "start": "124719",
    "end": "132319"
  },
  {
    "text": "uh once now the key Point really is that Dr in kubernetes is just a framework in",
    "start": "132319",
    "end": "139080"
  },
  {
    "text": "and it enables Hardware vendors to extend kubernetes by writing Dr",
    "start": "139080",
    "end": "146640"
  },
  {
    "text": "drivers and these Dr drivers are then responsible for the hardware and also",
    "start": "146640",
    "end": "152840"
  },
  {
    "text": "for user facing interface how to specify parameters depends on the hardware that",
    "start": "152840",
    "end": "158280"
  },
  {
    "text": "you are asking for it has been an alpha for a while and",
    "start": "158280",
    "end": "163599"
  },
  {
    "text": "we've been trying to get it to beer got some feedback from the community and to",
    "start": "163599",
    "end": "169200"
  },
  {
    "text": "clarify why that has been controversial we look at a little bit of the background how it works at the moment or",
    "start": "169200",
    "end": "175319"
  },
  {
    "text": "how it was originally meant to work the original idea was that we wanted to keep",
    "start": "175319",
    "end": "183519"
  },
  {
    "text": "logic and knowledge about the resources out of kubernetes it seemed like a daunting task to teach kubernetes how to",
    "start": "183519",
    "end": "189480"
  },
  {
    "text": "handle arbitrary Hardware so we try to hide that behind that interface that the",
    "start": "189480",
    "end": "194640"
  },
  {
    "text": "vendors uh implement the Dr driver controller basically takes those",
    "start": "194640",
    "end": "199840"
  },
  {
    "text": "parameters that it gets from the user and it has its own way of tracking its",
    "start": "199840",
    "end": "206799"
  },
  {
    "text": "own resource availability on a note and it does all the matching and the",
    "start": "206799",
    "end": "212480"
  },
  {
    "text": "kubernetes Schuler gets involved they both both need to coordinate between it",
    "start": "212480",
    "end": "217920"
  },
  {
    "text": "among themselves because the schul is the part that knows about CPU and RAM the traditional resources and the D",
    "start": "217920",
    "end": "226239"
  },
  {
    "text": "vendor or driver knows about resource availability for the more complex Hardware that was the the idea",
    "start": "226239",
    "end": "233400"
  },
  {
    "text": "originally um the problem with that is that we have",
    "start": "233400",
    "end": "238519"
  },
  {
    "text": "to have some kind of communication protocol between the Schuler and the driver that is this PO schuling context",
    "start": "238519",
    "end": "245720"
  },
  {
    "text": "in the middle it is a built-in type where currently the kubernetes Schuler",
    "start": "245720",
    "end": "251959"
  },
  {
    "text": "stores some information I think we have no I think we may we may have I'll explain it just based on these",
    "start": "251959",
    "end": "258759"
  },
  {
    "text": "slides here um the idea is that theat schu basically lists some suitable notes",
    "start": "258759",
    "end": "265479"
  },
  {
    "text": "stores that in the PO schedule two two slides down okay well then I'll get to",
    "start": "265479",
    "end": "270560"
  },
  {
    "text": "that later um this is this concept is what we've been talking about at",
    "start": "270560",
    "end": "276919"
  },
  {
    "text": "previous cucon there is a talk from Kevin and Alexa a colleague of mine",
    "start": "276919",
    "end": "282479"
  },
  {
    "text": "about building such a driver we have a repository",
    "start": "282479",
    "end": "287560"
  },
  {
    "text": "available that uh gives you a skeleton framework of an example driver it's",
    "start": "287560",
    "end": "292919"
  },
  {
    "text": "actually functional you can run it on your local development machine it runs in kind you bring up a cluster that",
    "start": "292919",
    "end": "298639"
  },
  {
    "text": "simul it's having some GPU so you can all see this in action uh on your local",
    "start": "298639",
    "end": "303919"
  },
  {
    "text": "machine uh we do have a resource class resource claims that are already mentioned so you can see how it works",
    "start": "303919",
    "end": "310720"
  },
  {
    "text": "with this approach um this is a more complete picture of",
    "start": "310720",
    "end": "317000"
  },
  {
    "text": "the communication between the kubernetes schul it goes through the API server it was one of one other idea that we had",
    "start": "317000",
    "end": "323800"
  },
  {
    "text": "that deploying a Dray driver should be fairly simple you just need to connect it to the API server and that's all",
    "start": "323800",
    "end": "330199"
  },
  {
    "text": "no need to configure web hooks or anything that may be cluster specific it could have been standardized like that",
    "start": "330199",
    "end": "336240"
  },
  {
    "text": "on and run on any arbitrary cuat distribution uh the drawback is that",
    "start": "336240",
    "end": "341479"
  },
  {
    "text": "there is a lot of back and forth when scheduler and Driver need to coordinate it starts with a Comm schul identifying",
    "start": "341479",
    "end": "348440"
  },
  {
    "text": "a port that needs to be run it looks at nodes that it finds suitable it dumps that information into the port",
    "start": "348440",
    "end": "354360"
  },
  {
    "text": "scheduling context then the D resource driver looks at that it replies back okay well these nodes here don't work",
    "start": "354360",
    "end": "361840"
  },
  {
    "text": "for me try something else there are some back and forth and that's kind of where the name of this Dynamic resource",
    "start": "361840",
    "end": "367840"
  },
  {
    "text": "allocation comes from eventually the kubernetes schuer can be",
    "start": "367840",
    "end": "373199"
  },
  {
    "text": "relatively sure that it has identified the suitable note it tells all the drivers it could be more than one more",
    "start": "373199",
    "end": "379240"
  },
  {
    "text": "than one driver can be listening to this PO schedu in context if you have multiple resources from different vendors that also works they all just",
    "start": "379240",
    "end": "385840"
  },
  {
    "text": "need to agree on a note then allocate the resource uh that gets report uh",
    "start": "385840",
    "end": "391680"
  },
  {
    "text": "recorded in the resource claim status and then eventually the CU schedular knows okay now I can run my port the",
    "start": "391680",
    "end": "398520"
  },
  {
    "text": "advantage is that the port never gets scheduled unless it's fairly certain that it really can run on the Node you",
    "start": "398520",
    "end": "404280"
  },
  {
    "text": "don't get into a situation where it gets scheduled then is stuck on a node and blocks resources which is often",
    "start": "404280",
    "end": "411400"
  },
  {
    "text": "sometimes that has happened in the past with the device plug-in interface where people just try to extend it and uh then",
    "start": "411400",
    "end": "418680"
  },
  {
    "text": "found add run time on the Node but the setup wasn't quite",
    "start": "418680",
    "end": "424720"
  },
  {
    "text": "right the problem with this approach is that the communication between scheduler",
    "start": "425160",
    "end": "431599"
  },
  {
    "text": "and Dr driver is not something that works for other kubernetes components most notably the cluster autoscaler the",
    "start": "431599",
    "end": "439720"
  },
  {
    "text": "cluster autoscaler operates purely in readon mode it sees what the current cluster state is which ports are not",
    "start": "439720",
    "end": "446599"
  },
  {
    "text": "running and it tries to determine through simulation whether adding a node may help to get a port running but it",
    "start": "446599",
    "end": "454080"
  },
  {
    "text": "can't ask the Dr driver we don't have an interface for that yet not in Virtual design there were some ideas about",
    "start": "454080",
    "end": "460440"
  },
  {
    "text": "plugging vendor logic into the cluster autoscala binary but it would have implied recompiling that binary which is",
    "start": "460440",
    "end": "467840"
  },
  {
    "text": "often not an option or doing remote procedure calls which are also difficult",
    "start": "467840",
    "end": "473680"
  },
  {
    "text": "from a pform performance perspective so in the end with after discussions with the maintainers and Community we came up",
    "start": "473680",
    "end": "481319"
  },
  {
    "text": "with this idea of builtin parameters um this takes the same ideas",
    "start": "481319",
    "end": "488800"
  },
  {
    "text": "we have resource claim parameters but they now have a built-in type in a format defined by kubernetes the",
    "start": "488800",
    "end": "496080"
  },
  {
    "text": "corresponding resource information uses the same format the same model and now",
    "start": "496080",
    "end": "501639"
  },
  {
    "text": "we have code in the kubernetes schula itself which mat does the matching and tracks resource allocation and assigns",
    "start": "501639",
    "end": "509120"
  },
  {
    "text": "resour sources from nodes to a resource claim there's no difference for the user",
    "start": "509120",
    "end": "516479"
  },
  {
    "text": "we still allow a vendor to Define his own crd for the",
    "start": "516479",
    "end": "522560"
  },
  {
    "text": "parameters they just then need to convert those parameters into the built-in resource claim parameter type",
    "start": "522560",
    "end": "530360"
  },
  {
    "text": "and the rest is handled by kubernetes so the writing a d driver actually becomes",
    "start": "530360",
    "end": "535600"
  },
  {
    "text": "simpler with this model with a caveat that it needs to fit into what is supported",
    "start": "535600",
    "end": "543000"
  },
  {
    "text": "by kubernetes in terms of uh things that you can do with a",
    "start": "543000",
    "end": "548279"
  },
  {
    "text": "build-in model we have some things defined right now in 130 but it's",
    "start": "548279",
    "end": "554760"
  },
  {
    "text": "literally just getting started and we know that more work is needed in that",
    "start": "554760",
    "end": "561160"
  },
  {
    "text": "area and yeah we have that's a recap that's a recap of the old",
    "start": "561160",
    "end": "567079"
  },
  {
    "text": "approach and here's how it works with a new approach it's basically just the",
    "start": "567079",
    "end": "573040"
  },
  {
    "text": "task of a Dr resource driver to produce these resource claim parameters the schedular reads all of that information",
    "start": "573040",
    "end": "579320"
  },
  {
    "text": "doesn't need to communicate with anything it can also do rapid pod scheduling now it can basically look at",
    "start": "579320",
    "end": "586360"
  },
  {
    "text": "one claim one part assign resources keep track of what resources it claimed look",
    "start": "586360",
    "end": "591480"
  },
  {
    "text": "at the next port and do rapid poort schedu like it does before with with a built-in uh Native",
    "start": "591480",
    "end": "597160"
  },
  {
    "text": "resources so that is another Advantage uh yeah and the named resource",
    "start": "597160",
    "end": "603640"
  },
  {
    "text": "model that is what we got into 130 uh as a starting point and Kevin I",
    "start": "603640",
    "end": "609839"
  },
  {
    "text": "think you will take over and explain more yeah so before I jump into the details of some of this I just want to",
    "start": "609839",
    "end": "616760"
  },
  {
    "text": "kind of uh set some expectations about this talk which um you know this is a",
    "start": "616760",
    "end": "622079"
  },
  {
    "text": "maintain maintainer track talk and so we're not going through all of the details about how this whole mechanism",
    "start": "622079",
    "end": "628240"
  },
  {
    "text": "works and so if I just back up to this slide right here real quick if you have if you're very new to Dr and don't know",
    "start": "628240",
    "end": "634160"
  },
  {
    "text": "anything about it you know we're kind of glossing over a lot of the details but if you watch this talk from from last",
    "start": "634160",
    "end": "639720"
  },
  {
    "text": "year in Amsterdam um it gets a it gives a very good overview of what Dr is how it works um and what these different",
    "start": "639720",
    "end": "646200"
  },
  {
    "text": "abstractions that we're talking about are resource class resource claim class parameters claim parameters and so on",
    "start": "646200",
    "end": "651560"
  },
  {
    "text": "and so you know this is really kind of the the purpose of this talk is to highlight you know the state of the",
    "start": "651560",
    "end": "657760"
  },
  {
    "text": "project and where we see it going uh in in the future and so I just wanted to set expectations on that in case you",
    "start": "657760",
    "end": "664160"
  },
  {
    "text": "feel a little bit lost that's um it's my fault that's that's where uh where this",
    "start": "664160",
    "end": "669839"
  },
  {
    "text": "is coming from um so yeah so as Patrick mentioned you know the the world of Dr",
    "start": "669839",
    "end": "675040"
  },
  {
    "text": "the way it looked in the original um incarnation of it uh looked something like this where you have you know the",
    "start": "675040",
    "end": "680760"
  },
  {
    "text": "kubernetes scheduler talking with the Dr resource driver and the Dr resource driver is in full control of how these",
    "start": "680760",
    "end": "687519"
  },
  {
    "text": "resources get allocated and in fact the API between these two is a very simple API it's kubernetes scheduler looks at",
    "start": "687519",
    "end": "694279"
  },
  {
    "text": "the constraints that it knows how to resolve how much CPU do you need how much memory do you need you know some of these built-in um and even the extended",
    "start": "694279",
    "end": "701200"
  },
  {
    "text": "resource types that it would need to use to figure out what what node a pod could land on and if it sees a claim a",
    "start": "701200",
    "end": "707600"
  },
  {
    "text": "resource claim uh referenced in that pod it looks up what what resource driver that's associated with and just says I",
    "start": "707600",
    "end": "713720"
  },
  {
    "text": "don't know how to deal with resource claims Hey Driver you figure out how to narrow down this list of nodes that I've",
    "start": "713720",
    "end": "719240"
  },
  {
    "text": "come up with with the constraints that I know about um and tell me what nodes from that set you might be able to",
    "start": "719240",
    "end": "725639"
  },
  {
    "text": "allocate resources for this claim on and then this process goes back and forth until an actual node is found where you",
    "start": "725639",
    "end": "731360"
  },
  {
    "text": "can allocate those resources and that's where this long Loop comes where you know scheduling might be slowed down the",
    "start": "731360",
    "end": "738959"
  },
  {
    "text": "uh interfaces to doing cluster Auto scaling don't exist because all this logic is custom inside this resource driver",
    "start": "738959",
    "end": "746320"
  },
  {
    "text": "and the built-in scheduler knows nothing about this and so as Patrick mentioned this move towards a model where we have",
    "start": "746320",
    "end": "753079"
  },
  {
    "text": "built-in parameters basically allows these in tree types to exist that all",
    "start": "753079",
    "end": "760639"
  },
  {
    "text": "that the that your driver can advertise its resources to and any ven vendor",
    "start": "760639",
    "end": "766399"
  },
  {
    "text": "specific logic around how you might select a specific resource or configure that resource at the end of the day once",
    "start": "766399",
    "end": "771800"
  },
  {
    "text": "it lands on the Node can be encoded in these intry types that the scheduler can actually look at and make decisions on",
    "start": "771800",
    "end": "778040"
  },
  {
    "text": "and so in this picture here here everything that's in green is a vendor specific component and everything that's in blue is an entry type and so you can",
    "start": "778040",
    "end": "784680"
  },
  {
    "text": "see how you know the kuet plugin will advertise something to the kuet so it can write this entry type called a",
    "start": "784680",
    "end": "789800"
  },
  {
    "text": "resource slice that the kubernetes scheduler can now pick up to figure out what resources are available so that it",
    "start": "789800",
    "end": "795839"
  },
  {
    "text": "can make this node selection decision without having this back and forth with uh the custom",
    "start": "795839",
    "end": "801120"
  },
  {
    "text": "driver um and so as Patrick mentioned you know the in 130 for this built-in",
    "start": "801120",
    "end": "806199"
  },
  {
    "text": "model we came up with this uh reference implementation there something called named resources and if you're familiar",
    "start": "806199",
    "end": "811279"
  },
  {
    "text": "with the existing device plug-in API um basically what the device plug-in API allows you to do is advertise a list of",
    "start": "811279",
    "end": "818560"
  },
  {
    "text": "opaque strings back to the kuet which represent the resources that you might be able to allocate so in the world of",
    "start": "818560",
    "end": "823800"
  },
  {
    "text": "gpus you might advertise that I have uh eight gpus and the opaque strings that represent them are GPU 0 1 two up",
    "start": "823800",
    "end": "830720"
  },
  {
    "text": "through seven right that's the only information you pass back to the kuet the kuet then tracks that as the set of",
    "start": "830720",
    "end": "836360"
  },
  {
    "text": "resources that it's able to allocate and and then it writes into the API server just a simple count of how many it has",
    "start": "836360",
    "end": "842800"
  },
  {
    "text": "back into the node object so you know you've passed back these eight strings kuer has recorded those eight strings",
    "start": "842800",
    "end": "848320"
  },
  {
    "text": "and said that there's eight of this resource type available on this node and then the scheduler makes all of its scheduling decisions based on that um in",
    "start": "848320",
    "end": "856240"
  },
  {
    "text": "this built-in resource models for Dr we're basically doing the same thing except instead of passing back just a",
    "start": "856240",
    "end": "861320"
  },
  {
    "text": "string we're able to pass back a name a name of a resource and then a set of attributes that are that are attached to",
    "start": "861320",
    "end": "867440"
  },
  {
    "text": "that so in the example I'm showing here here um the instance that I'm passing back is called gpu0 that's similar to",
    "start": "867440",
    "end": "873639"
  },
  {
    "text": "this opaque string that I would have passed back in the traditional device plugin but now I've got all these attributes on it so I've got an index of",
    "start": "873639",
    "end": "880519"
  },
  {
    "text": "zero associated with this device I've got a uuid with this long string I've got a product name of Nvidia uh a100 uh",
    "start": "880519",
    "end": "887759"
  },
  {
    "text": "sxm 4 I say that there's 40 gabt of memory on this and so on and so um you",
    "start": "887759",
    "end": "892920"
  },
  {
    "text": "can kind of imagine how this is going to be used by the scheduler is that instead of just having the ability to say okay",
    "start": "892920",
    "end": "898399"
  },
  {
    "text": "I'm going to allocate some arbitrary GPU you can actually do very precise selection on the type of GPU that you",
    "start": "898399",
    "end": "903560"
  },
  {
    "text": "want right you can match against these attributes based on some selection criteria for what type of resource",
    "start": "903560",
    "end": "909399"
  },
  {
    "text": "you're actually trying to get access to and so you know people have worked around this today by using some",
    "start": "909399",
    "end": "915000"
  },
  {
    "text": "combination of node attributes and and other mechanisms where you basically have to have a homogeneous set of",
    "start": "915000",
    "end": "920279"
  },
  {
    "text": "devices on a node and if you have that then you can use labels on the nodes to",
    "start": "920279",
    "end": "925440"
  },
  {
    "text": "try and get access to a specific type of GPU because you know that if you land on that node that's the only type of gpus",
    "start": "925440",
    "end": "930680"
  },
  {
    "text": "that are available there right but with this model we can actually do precise device selection which will kind of",
    "start": "930680",
    "end": "935839"
  },
  {
    "text": "automatically enable you to have different types of gpus on the same node at this at the same",
    "start": "935839",
    "end": "941000"
  },
  {
    "text": "time um and again you know using this analogy of what the existing device uh",
    "start": "941000",
    "end": "946759"
  },
  {
    "text": "plug-in API looks like if you're familiar with that uh existing device plug-in API you'll know that there's a list and watch API call that exists in",
    "start": "946759",
    "end": "953680"
  },
  {
    "text": "the drivers that are written for that which allow you to stream this list of um uh devices as I mentioned before is",
    "start": "953680",
    "end": "960560"
  },
  {
    "text": "opaque strings back to the uh to the kuet so that it can update the the node with how many are available and in um in",
    "start": "960560",
    "end": "968120"
  },
  {
    "text": "this new structure parameters model it's a very similar thing except instead of streaming back this opaque list you're streaming back an entire model that",
    "start": "968120",
    "end": "975079"
  },
  {
    "text": "looks like what I had on this last slide you're you're streaming all of this back and instead of just a count being made",
    "start": "975079",
    "end": "980319"
  },
  {
    "text": "available to the scheduler this entire object is being made available to the scheduler so that it can do this PR this",
    "start": "980319",
    "end": "986360"
  },
  {
    "text": "precise um device selection based on on that information um and yeah you know if you",
    "start": "986360",
    "end": "993639"
  },
  {
    "text": "you you send this once when when the node starts up and then if something goes wrong like some some resource goes",
    "start": "993639",
    "end": "999120"
  },
  {
    "text": "unhealthy or whatnot you can update you can send an update of the stream of of of things that might have fallen off the",
    "start": "999120",
    "end": "1004519"
  },
  {
    "text": "bus or gone unhealthy for for some other reason um and so if we go back to this",
    "start": "1004519",
    "end": "1010000"
  },
  {
    "text": "picture that I had before um the kuet plugin of the Dr driver basically uh",
    "start": "1010000",
    "end": "1015319"
  },
  {
    "text": "satisfies this part of the picture right so you've got your Dr resource driver kuet plug-in advertises its resources",
    "start": "1015319",
    "end": "1020959"
  },
  {
    "text": "through the streaming API to the kuet kuet uses that to write a resource slice into the API server and now the",
    "start": "1020959",
    "end": "1027319"
  },
  {
    "text": "scheduler has uh the ability to to look at this information when it's trying to make scheduling decisions for your",
    "start": "1027319",
    "end": "1034000"
  },
  {
    "text": "pod on the other side of that um is this notion uh that Patrick also mentioned of",
    "start": "1034000",
    "end": "1039760"
  },
  {
    "text": "introducing this intry abstraction called the resource uh claim parameter object um in both original Dr for opaque",
    "start": "1039760",
    "end": "1047438"
  },
  {
    "text": "parameters and our built-in par model we do have the notion of allowing you as a vendor that's writing your device driver",
    "start": "1047439",
    "end": "1053880"
  },
  {
    "text": "to introduce vendor specific claim parameters and that's what you're seeing here on the left um this is the claim",
    "start": "1053880",
    "end": "1061039"
  },
  {
    "text": "parameters object that our uh GPU driver for for Dr implements and it allows you",
    "start": "1061039",
    "end": "1066200"
  },
  {
    "text": "to to specify both selection criteria meaning how can I get access to a specific type of GPU as well as",
    "start": "1066200",
    "end": "1072480"
  },
  {
    "text": "configuration criteria meaning once this thing once this this G has been allocated to a pod and it lands on a",
    "start": "1072480",
    "end": "1079320"
  },
  {
    "text": "node how do I want that GPU configured for use on on that node and so you can see it's divided into two sections for",
    "start": "1079320",
    "end": "1085520"
  },
  {
    "text": "that so at the top you know you can see that you have in this spec I want um a count of one GPU that follows the",
    "start": "1085520",
    "end": "1092159"
  },
  {
    "text": "selector expression saying that I want the uh basically I want a GPU that has",
    "start": "1092159",
    "end": "1097400"
  },
  {
    "text": "a100 in its product name and it must have less than or equal to 40 gbt um of",
    "start": "1097400",
    "end": "1103280"
  },
  {
    "text": "memory and once it lands on the Node I want it configured uh for anyone that shares access to this GPU I want want it",
    "start": "1103280",
    "end": "1109080"
  },
  {
    "text": "to use time slicing with a long time slice configured as opposed to a short time slice or or a medium time slice um",
    "start": "1109080",
    "end": "1117320"
  },
  {
    "text": "and so you know the only job then of the of the controller piece of a of a Dr",
    "start": "1117320",
    "end": "1123440"
  },
  {
    "text": "driver that you that you need to implement um as opposed to the opaque parameters model where the controller had to do all of the logic for actually",
    "start": "1123440",
    "end": "1130120"
  },
  {
    "text": "allocating because the scheduler didn't know how to do that now all your controller needs to know how to do is to",
    "start": "1130120",
    "end": "1135200"
  },
  {
    "text": "take this vendor specific claim parameters object and translate it into this inre generic representation so that",
    "start": "1135200",
    "end": "1141760"
  },
  {
    "text": "the scheduler knows how to actually operate on that and the way that it does this uh is that it it generates that",
    "start": "1141760",
    "end": "1147200"
  },
  {
    "text": "claim uh the resource claim parameters object and then it puts a back reference in that to your original uh resource",
    "start": "1147200",
    "end": "1153720"
  },
  {
    "text": "claim object so that um so that the scheduler knows how to to to find this to attach uh other pieces of information",
    "start": "1153720",
    "end": "1160480"
  },
  {
    "text": "to the to the resource claim parameters object and so there's an explicit generated from section that refers back",
    "start": "1160480",
    "end": "1165720"
  },
  {
    "text": "to your vendor specific claim parameters object there's also a uh generated cell",
    "start": "1165720",
    "end": "1171919"
  },
  {
    "text": "expression for selection so the scheduler knows how to interpret this cell expression so if you're not fam",
    "start": "1171919",
    "end": "1178000"
  },
  {
    "text": "familiar with cell it's a um I don't know how you would how do you describe cell um a simple expression language",
    "start": "1178000",
    "end": "1186440"
  },
  {
    "text": "that can be evaluated in constant time it's strongly typed in this case so it",
    "start": "1186440",
    "end": "1191760"
  },
  {
    "text": "evaluates always to a Boolean and there's some validation going on that you are not calling something that is",
    "start": "1191760",
    "end": "1197159"
  },
  {
    "text": "not defined in this particular context so it can be extended these attributes do string this is something that comes",
    "start": "1197159",
    "end": "1204200"
  },
  {
    "text": "that we are adding in this particular cell environment to Grant this",
    "start": "1204200",
    "end": "1209240"
  },
  {
    "text": "expression access to the to the resource attributes Yeah so basically what we have expressed over here can be",
    "start": "1209240",
    "end": "1216200"
  },
  {
    "text": "translated into a cell expression and what Patrick mentioned with the attributes is that you know in the",
    "start": "1216200",
    "end": "1221320"
  },
  {
    "text": "resource slice that I showed an example for before there was a set of attributes attached to the resource and you can",
    "start": "1221320",
    "end": "1227120"
  },
  {
    "text": "basically match on those here and that allows you to do this precise selection of the GPU that happens to be available",
    "start": "1227120",
    "end": "1232679"
  },
  {
    "text": "for for what you're asking for um and then any vendor specific things that you know the resource claim parameters",
    "start": "1232679",
    "end": "1238679"
  },
  {
    "text": "object itself doesn't actually care about but you need available on the Node when you go to actually allocate these resources you can tack those onto the",
    "start": "1238679",
    "end": "1245600"
  },
  {
    "text": "end in this specific vendor uh parameter section and then if from the perspective of the resource claim parameters object",
    "start": "1245600",
    "end": "1251880"
  },
  {
    "text": "this is just an unstructured type that's tacked on there and then you have to reinterpret this once uh the node itself",
    "start": "1251880",
    "end": "1259280"
  },
  {
    "text": "um starts to allocate resources for this um and so yeah like you know if we",
    "start": "1259280",
    "end": "1264679"
  },
  {
    "text": "go back to this uh this picture now this is kind of the top half of the picture where the vendor specific controller uh",
    "start": "1264679",
    "end": "1270360"
  },
  {
    "text": "sees one of these vendor specific claim parameters objects created it generates",
    "start": "1270360",
    "end": "1275440"
  },
  {
    "text": "uh an intry race uh resource claim parameters object that the scheduler then knows about and then putting this",
    "start": "1275440",
    "end": "1281080"
  },
  {
    "text": "all back together now the scheduler has all the information it needs to select a node containing the requested resources",
    "start": "1281080",
    "end": "1287279"
  },
  {
    "text": "alongside all of the other constraints that's resolved for any other types of resources that it",
    "start": "1287279",
    "end": "1293159"
  },
  {
    "text": "has um uh one of the earlier slides we pointed out that we have an example Dr",
    "start": "1293159",
    "end": "1299279"
  },
  {
    "text": "driver um repo where you can go in and play around with some of this stuff um",
    "start": "1299279",
    "end": "1304880"
  },
  {
    "text": "we haven't updated that for structured parameters yet but we plan to uh once kind has a an image that's been released",
    "start": "1304880",
    "end": "1311480"
  },
  {
    "text": "for 130 so I mean 130 is not even out yet right if you wanted to start trying to play around with this you'd have to",
    "start": "1311480",
    "end": "1317240"
  },
  {
    "text": "compile it against uh um you know master of kubernetes but once kind has an image that's released for 130 we we will also",
    "start": "1317240",
    "end": "1324480"
  },
  {
    "text": "coincide that with uh having structure parameters implemented in this um that said I have already implemented",
    "start": "1324480",
    "end": "1330640"
  },
  {
    "text": "structure parameters for our Nvidia GPU driver so if that's what you're interested in in potentially playing",
    "start": "1330640",
    "end": "1336760"
  },
  {
    "text": "around with and seeing how it works uh you can uh go to this branch and see what changes were made from the opaque",
    "start": "1336760",
    "end": "1343480"
  },
  {
    "text": "version of um uh of of this implementation um and speaking of which",
    "start": "1343480",
    "end": "1350159"
  },
  {
    "text": "um even with this very very simple model for for named resources I have this uh",
    "start": "1350159",
    "end": "1355480"
  },
  {
    "text": "document that I put together a few months ago which called Nvidia GPU use cases for dynamic resource allocation um",
    "start": "1355480",
    "end": "1361679"
  },
  {
    "text": "where I outlined 12 use cases that Dr is able to solve um for gpus that you can't",
    "start": "1361679",
    "end": "1367640"
  },
  {
    "text": "do with the existing device plug-in API um and even with this very simple named resources model we already cover six of",
    "start": "1367640",
    "end": "1373440"
  },
  {
    "text": "those 12 um use cases which is actually a pretty good number given how simple this model is is um and um these are",
    "start": "1373440",
    "end": "1381960"
  },
  {
    "text": "this if you if you watch my talk from from cucon last November uh these are the the same use cases that I identify",
    "start": "1381960",
    "end": "1388320"
  },
  {
    "text": "there where I go into lots of details about how Dr works and how specifically",
    "start": "1388320",
    "end": "1393840"
  },
  {
    "text": "um it maps to the different problems we're trying to solve with gpus so I encourage you to to check out that talk if you're if you're interested in that",
    "start": "1393840",
    "end": "1401279"
  },
  {
    "text": "um and so these are those six uh actually the full 12 use cases of what's supported and what's unsupported so I",
    "start": "1401279",
    "end": "1407640"
  },
  {
    "text": "just want to really quickly name each of them so that you you see which you know the difference between what is supported",
    "start": "1407640",
    "end": "1412760"
  },
  {
    "text": "and what isn't and so um the things that named resources actually gives us the ability to do is control GPU sharing",
    "start": "1412760",
    "end": "1418200"
  },
  {
    "text": "right so I can create a claim I can have uh two different containers point to",
    "start": "1418200",
    "end": "1423279"
  },
  {
    "text": "that claim and now they get you know shared access to that in a very controlled way because the claim is where this resource is bound to um I can",
    "start": "1423279",
    "end": "1430360"
  },
  {
    "text": "also get GPU selection via complex Contra constraints that's this whole selection mechanism that's that",
    "start": "1430360",
    "end": "1435799"
  },
  {
    "text": "eventually gets translated into a cell expression I can still do that with this resource model um you can have multiple",
    "start": "1435799",
    "end": "1442520"
  },
  {
    "text": "GPU types per node I can have an a100 and a T4 sitting next to each other um and as long as I put my selection",
    "start": "1442520",
    "end": "1448520"
  },
  {
    "text": "criteria together appropriately I can pick one versus the other um you can still do user-driven time slicing",
    "start": "1448520",
    "end": "1454840"
  },
  {
    "text": "support across a subset of gpus that's this vendor specific information that you tack on the end um at the node level",
    "start": "1454840",
    "end": "1462039"
  },
  {
    "text": "you can still interpret that the same way you would have in the opaque parameters model and so there's no changes there same thing with MPS um MPS",
    "start": "1462039",
    "end": "1469880"
  },
  {
    "text": "is the you know I mentioned this this morning in in the keynote but it's a way of doing space partitioning instead of",
    "start": "1469880",
    "end": "1475320"
  },
  {
    "text": "time uh time partitioning um and you can still you know take advantage of the MPS support because again this is a node",
    "start": "1475320",
    "end": "1481640"
  },
  {
    "text": "level thing we just tack on to the vendor uh parameters at the end of our our resource claim and they just get passed along to the node to to to um to",
    "start": "1481640",
    "end": "1491399"
  },
  {
    "text": "actualize them um and then the last one is dynamic swapping of an Nvidia driver with a vfio driver depending on intended",
    "start": "1491399",
    "end": "1497559"
  },
  {
    "text": "use case of of the GPU so this is for being able to support um virtual machines like kuvert or Kata need this",
    "start": "1497559",
    "end": "1504760"
  },
  {
    "text": "kind of capability so that you can on a GPU by GPU basis say hey this GPU is going to be injected into a virtual",
    "start": "1504760",
    "end": "1510520"
  },
  {
    "text": "machine cool I want that governed by the vfio driver rather than the native Nvidia GPU driver that's sitting on on",
    "start": "1510520",
    "end": "1517039"
  },
  {
    "text": "the host um and these other six are are unsupported at the moment but that said",
    "start": "1517039",
    "end": "1523279"
  },
  {
    "text": "by 131 so you know One release later uh we already have plans to uh support the",
    "start": "1523279",
    "end": "1528799"
  },
  {
    "text": "majority of these uh just within the next release cycle so we'll be able to support 10 out of these 12 where we can",
    "start": "1528799",
    "end": "1534279"
  },
  {
    "text": "do um some of the dynamic uh allocation of MiG devices we can do Mig device",
    "start": "1534279",
    "end": "1539799"
  },
  {
    "text": "alignment subdivide Mig devices basically support partitioning of devices rather than allocating out just",
    "start": "1539799",
    "end": "1545880"
  },
  {
    "text": "full uh full gpus um what's still unsupported but we do have plans support fairly soon we",
    "start": "1545880",
    "end": "1553080"
  },
  {
    "text": "have designs in place but we're still trying to wiggle out the the details of that is the ability to do custom",
    "start": "1553080",
    "end": "1558600"
  },
  {
    "text": "policies to align multiple resources such as gpus and Nyx or even between two different gpus making sure that you have",
    "start": "1558600",
    "end": "1565120"
  },
  {
    "text": "the optimal connection with in terms of NV links and um Numa alignment and things like this um the last one though",
    "start": "1565120",
    "end": "1573039"
  },
  {
    "text": "where you can do very very custom application specific policies for how gpus are allocated across containers and",
    "start": "1573039",
    "end": "1578159"
  },
  {
    "text": "pods I don't see how we'll ever really be able to do this with structured parameters um this is you know it's it's",
    "start": "1578159",
    "end": "1585399"
  },
  {
    "text": "possible with opaque the opaque parameters model but um I really don't see how we're ever",
    "start": "1585399",
    "end": "1591039"
  },
  {
    "text": "really you know going to be able to do this with structured parameters because this is the type of thing where you might have an application that says I",
    "start": "1591039",
    "end": "1597039"
  },
  {
    "text": "have two pods um if those can both fit on the same GPU on one node give them access to",
    "start": "1597039",
    "end": "1603520"
  },
  {
    "text": "that same GPU if there's no single GPU where these could run but there's two gpus on a node where they could each get",
    "start": "1603520",
    "end": "1609520"
  },
  {
    "text": "one of them give them each one if that doesn't exist but there's two nodes that have a GPU that could satisfy one of the",
    "start": "1609520",
    "end": "1616320"
  },
  {
    "text": "two of them great run them on the those separate nodes but also allocate um an",
    "start": "1616320",
    "end": "1621559"
  },
  {
    "text": "RDMA device that can allow them to communicate very quickly between each other right and with opaque parameters",
    "start": "1621559",
    "end": "1626840"
  },
  {
    "text": "you can actually write a controller that encodes all of this logic and does what I just said but there's no way we're",
    "start": "1626840",
    "end": "1632799"
  },
  {
    "text": "going to be able to do this in a generic way and so um we need to think hard about whether we want to be able to support those use cases I just described",
    "start": "1632799",
    "end": "1639440"
  },
  {
    "text": "or not if we ever want to try and get rid of the opaque parameters model uh going",
    "start": "1639440",
    "end": "1645159"
  },
  {
    "text": "forward um and one thing to point out that at Le at least in this move from opaque parameters to uh the built-in",
    "start": "1645159",
    "end": "1652120"
  },
  {
    "text": "parameters model that we have today um from a gpus perspective uh from the user",
    "start": "1652120",
    "end": "1657880"
  },
  {
    "text": "of the GPU driver's perspective there are no changes needed to migrate from from Dr with opaque parameters to structure parameters so if you've",
    "start": "1657880",
    "end": "1663840"
  },
  {
    "text": "already started playing around with this a little bit and um have been you know experimenting with it um if you decide",
    "start": "1663840",
    "end": "1670480"
  },
  {
    "text": "to to try and play around with the built-in um model and you're you you're",
    "start": "1670480",
    "end": "1675840"
  },
  {
    "text": "only doing things with one of those first six out of the 12 use cases nothing should have to change from from",
    "start": "1675840",
    "end": "1681440"
  },
  {
    "text": "your perspective in this uh migrating to to 130 from 129 um and I'll let Patrick then uh",
    "start": "1681440",
    "end": "1689120"
  },
  {
    "text": "finish up with this last slide yeah so the the question that we discussed at",
    "start": "1689120",
    "end": "1694279"
  },
  {
    "text": "the contributor Summit really was can we promote something to Beta in this year",
    "start": "1694279",
    "end": "1702200"
  },
  {
    "text": "which is fairly aggressive so for 131 yeah we we kind of we kind of at the",
    "start": "1702200",
    "end": "1707559"
  },
  {
    "text": "end decided yes we can we just need to figure out exactly what it is what's the",
    "start": "1707559",
    "end": "1713360"
  },
  {
    "text": "scope limit that we can achieve in 131 so many of these enhancement that we",
    "start": "1713360",
    "end": "1718880"
  },
  {
    "text": "still need for some additional use cases that needs to go in then we can finalize the API structur parameters will be the",
    "start": "1718880",
    "end": "1726039"
  },
  {
    "text": "default mode and then we kind of keep the rest of the functionality the core or",
    "start": "1726039",
    "end": "1732840"
  },
  {
    "text": "traditional Dr depending on how you want to call it hidden behind the second feature gate",
    "start": "1732840",
    "end": "1738559"
  },
  {
    "text": "incubators 132 then ideally we have some more feedback we know that it works and then",
    "start": "1738559",
    "end": "1745760"
  },
  {
    "text": "we just flip the feature gate for structured parameters and that becomes",
    "start": "1745760",
    "end": "1750960"
  },
  {
    "text": "beta in 132 hopefully um the rest will still be",
    "start": "1750960",
    "end": "1756279"
  },
  {
    "text": "there because we still see cases where it's useful U exploring additional",
    "start": "1756279",
    "end": "1762120"
  },
  {
    "text": "contol controller logic that is where we where we need for po scheduling context",
    "start": "1762120",
    "end": "1767360"
  },
  {
    "text": "um so this will still be available and then going beyond that we need to really",
    "start": "1767360",
    "end": "1773840"
  },
  {
    "text": "think hard about whether we can still support it or whether we arrive at a",
    "start": "1773840",
    "end": "1779320"
  },
  {
    "text": "structured parameter model that is so sufficiently capable that it works well enough for the majority of use cases and",
    "start": "1779320",
    "end": "1785919"
  },
  {
    "text": "then we might drop the rest of the code because the concern of the maintainers is clearly the complexity that we are",
    "start": "1785919",
    "end": "1792480"
  },
  {
    "text": "now adding to compen is that this is not maintainable in the long run uh because",
    "start": "1792480",
    "end": "1797600"
  },
  {
    "text": "there are a lot of if check if else cases now in the schedular to support both of these models and that just may",
    "start": "1797600",
    "end": "1803840"
  },
  {
    "text": "be too complex for the future but we are going to discuss that",
    "start": "1803840",
    "end": "1809640"
  },
  {
    "text": "when we get to that point right now the focus is 132 there's a lot of support in",
    "start": "1809640",
    "end": "1815399"
  },
  {
    "text": "the community because we all agree that kubernetes needs to do something that makes AI training and inference work",
    "start": "1815399",
    "end": "1822960"
  },
  {
    "text": "better natively without any hacks that you might have used might have to use with Device plugin so there is a strong",
    "start": "1822960",
    "end": "1829240"
  },
  {
    "text": "support from the community for the structured parameters and I'm I'm hopeful that we can do",
    "start": "1829240",
    "end": "1834880"
  },
  {
    "text": "it and that's it so I think we do have time for",
    "start": "1837240",
    "end": "1843399"
  },
  {
    "text": "questions five minutes there's a microphone over there I",
    "start": "1843399",
    "end": "1849200"
  },
  {
    "text": "see um so I have a question about how will this work with network devices",
    "start": "1850360",
    "end": "1857000"
  },
  {
    "text": "where you can have say uh a device that can only take one connection at a time",
    "start": "1857000",
    "end": "1863120"
  },
  {
    "text": "so will the schedule be able to know that it's the same device that it exposed on different nodes and ensure",
    "start": "1863120",
    "end": "1869279"
  },
  {
    "text": "that it isn't used at the same time by different nodes so that would be a network attached device that gets",
    "start": "1869279",
    "end": "1876039"
  },
  {
    "text": "connected to a node this is one of the use cases where we are currently still",
    "start": "1876039",
    "end": "1881559"
  },
  {
    "text": "exploring how to use structured parameters there is no concept for",
    "start": "1881559",
    "end": "1886799"
  },
  {
    "text": "publishing that such a resource exists in the cluster in the first place that's one of the missing pieces and then the",
    "start": "1886799",
    "end": "1892919"
  },
  {
    "text": "logic of okay so we so how do we allocated and when do we enact any kind",
    "start": "1892919",
    "end": "1898200"
  },
  {
    "text": "of cluster reconfiguration does that happen when a pot starts to run that may work with a",
    "start": "1898200",
    "end": "1904799"
  },
  {
    "text": "current model so you would have to have a demon set that knows how to reconfigure that network attached",
    "start": "1904799",
    "end": "1910399"
  },
  {
    "text": "device that might work but yeah it is a use case that currently has taken",
    "start": "1910399",
    "end": "1916679"
  },
  {
    "text": "slightly the back seat to just get no local resources to Beta",
    "start": "1916679",
    "end": "1923679"
  },
  {
    "text": "okay but the core the traditional tra Dr is still there so if people want to",
    "start": "1923679",
    "end": "1929519"
  },
  {
    "text": "explore such use cases you can you just have to use the traditional Dr with your",
    "start": "1929519",
    "end": "1935039"
  },
  {
    "text": "own controller and then it your limitation yeah that's your limitation you don't",
    "start": "1935039",
    "end": "1940200"
  },
  {
    "text": "get cluster Autos scaling because we don't have a solution for that but you can explore you can do prototyping you can come back with your use cases to the",
    "start": "1940200",
    "end": "1946600"
  },
  {
    "text": "community and say okay this this works perfectly for my network attached device let's figure out how to do the same",
    "start": "1946600",
    "end": "1952120"
  },
  {
    "text": "thing with structured parameters that's that's ideally the result of all these",
    "start": "1952120",
    "end": "1957840"
  },
  {
    "text": "discussions uh have this been designed with multi tensy in mind so that you can",
    "start": "1957840",
    "end": "1962919"
  },
  {
    "text": "use resource quers we have some very simplistic idea",
    "start": "1962919",
    "end": "1968039"
  },
  {
    "text": "of doing quoters at the moment it's like volumes you get both you you just count",
    "start": "1968039",
    "end": "1973679"
  },
  {
    "text": "the resource claims per namespace that would be fairly simple to support I do have a PR pending for that we didn't",
    "start": "1973679",
    "end": "1980600"
  },
  {
    "text": "merge it yet because it wasn't sure whether it's sufficient it probably isn't because one claim can be for some",
    "start": "1980600",
    "end": "1989080"
  },
  {
    "text": "very cheap Hardware or it can be a big GPU we need be structured parameters to",
    "start": "1989080",
    "end": "1995600"
  },
  {
    "text": "make the quarter mechanism more capable and more specific it is probably",
    "start": "1995600",
    "end": "2002159"
  },
  {
    "text": "something that can be added but for the sake of yeah having a reasonable scope",
    "start": "2002159",
    "end": "2008480"
  },
  {
    "text": "feature set feature set we are not currently planning that for 132 to be",
    "start": "2008480",
    "end": "2014120"
  },
  {
    "text": "honest yeah it's also worth pointing out that with the opaque parameters model you could bring along your own custom",
    "start": "2014120",
    "end": "2020799"
  },
  {
    "text": "way of doing quotas because you have full control of if you want to allow the",
    "start": "2020799",
    "end": "2025840"
  },
  {
    "text": "allocation to happen or not from within your controller um and we were planning until",
    "start": "2025840",
    "end": "2031159"
  },
  {
    "text": "the whole structured parameters discussion started we were planning on shipping our own custom quota mechanism",
    "start": "2031159",
    "end": "2036320"
  },
  {
    "text": "along with the helm chart that deploys our our driver um but we just never bother doing that because we've kind of",
    "start": "2036320",
    "end": "2042360"
  },
  {
    "text": "pushed things more towards the our efforts towards the structure parameters model",
    "start": "2042360",
    "end": "2048158"
  },
  {
    "text": "now all right thank you I have a quick one if that's time uh what about the scheduling once",
    "start": "2048159",
    "end": "2055760"
  },
  {
    "text": "you have scheduled the part and you have the resource SES do you optimize like we do with assistant volumes where it was",
    "start": "2055760",
    "end": "2062760"
  },
  {
    "text": "scheduled perhaps with some labels on the notes or like topology",
    "start": "2062760",
    "end": "2069720"
  },
  {
    "text": "not sure whether I get the question though you you you so if I if a a",
    "start": "2069839",
    "end": "2075280"
  },
  {
    "text": "deployment get some resources GPU and you need to reschedule it do we optimize",
    "start": "2075280",
    "end": "2080919"
  },
  {
    "text": "so that we don't need to provide the whole list of nodes and do the evaluation again so that we perhaps put",
    "start": "2080919",
    "end": "2087520"
  },
  {
    "text": "it in the resource SCE uh resource which node it has previously so there is no",
    "start": "2087520",
    "end": "2094040"
  },
  {
    "text": "rescheduling at the moment that is not supported by kubernetes itself so we are",
    "start": "2094040",
    "end": "2099599"
  },
  {
    "text": "bound by what is supported here by kubernetes once the port has been scheduled it's bound to that note it can",
    "start": "2099599",
    "end": "2106119"
  },
  {
    "text": "only be deleted if it doesn't if it cannot run and then we rely on an app controller to recreate the port and that",
    "start": "2106119",
    "end": "2113160"
  },
  {
    "text": "Port will get scheduled again there is a cap in Pro in Flight where where someone",
    "start": "2113160",
    "end": "2119800"
  },
  {
    "text": "is proposing to allow rescheduling basically cupet can mark that part as",
    "start": "2119800",
    "end": "2125440"
  },
  {
    "text": "not suitable for this node try again elsewhere but this is a New Concept in kubernetes we don't have that",
    "start": "2125440",
    "end": "2132240"
  },
  {
    "text": "yet all right thank",
    "start": "2132240",
    "end": "2138480"
  },
  {
    "text": "you last question I'm afraid we are at the end of the session uh yeah you",
    "start": "2142800",
    "end": "2148480"
  },
  {
    "text": "mentioned that the uh the resources you define with the the dynamic resource",
    "start": "2148480",
    "end": "2153599"
  },
  {
    "text": "allocation will be used for scheduling only but will is there a plan to use them also for setting a hard limit for",
    "start": "2153599",
    "end": "2161599"
  },
  {
    "text": "the resources like the memory and uh the CPU count and to um evict the ports if",
    "start": "2161599",
    "end": "2169720"
  },
  {
    "text": "they overpass their limit for example in the usage of gpus or network so we don't really plan to touch",
    "start": "2169720",
    "end": "2179160"
  },
  {
    "text": "anything with CPU or Ram at the moment um there are some experimental Dray",
    "start": "2179160",
    "end": "2185640"
  },
  {
    "text": "drivers that add additional con strains about which CPUs may be usable for a pod",
    "start": "2185640",
    "end": "2192280"
  },
  {
    "text": "um but it's only really piggy bagging on this whole effort of having a custom apepi and then they doing something",
    "start": "2192280",
    "end": "2198319"
  },
  {
    "text": "special in their Dr driver on the Node uh but it's not a main feature that we're trying to support",
    "start": "2198319",
    "end": "2206480"
  },
  {
    "text": "okay okay well thank",
    "start": "2207160",
    "end": "2212280"
  },
  {
    "text": "you",
    "start": "2214319",
    "end": "2217319"
  }
]
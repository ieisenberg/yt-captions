[
  {
    "start": "0",
    "end": "58000"
  },
  {
    "text": "so good afternoon everybody so my name is min Han I'm a software engineer on",
    "start": "179",
    "end": "5940"
  },
  {
    "text": "the GK networking team and I'm Rohit also software engineer and GK networking so today we're here to share our",
    "start": "5940",
    "end": "13259"
  },
  {
    "text": "experience running and supporting kubernetes at Google so networking is",
    "start": "13259",
    "end": "19740"
  },
  {
    "text": "hard and kubernetes networking can get even harder so at Google we have levels",
    "start": "19740",
    "end": "26279"
  },
  {
    "text": "of support for customer issues and we are the last line of defense so when the",
    "start": "26279",
    "end": "33059"
  },
  {
    "text": "customer issues get to us the better be tricky and this talk we don't want to",
    "start": "33059",
    "end": "40020"
  },
  {
    "text": "make into a lecture or training sessions although some of the slides coming from our internal training sessions so we",
    "start": "40020",
    "end": "46980"
  },
  {
    "text": "first pick a few fun cases and then we're gonna talk about what are the",
    "start": "46980",
    "end": "53219"
  },
  {
    "text": "lessons learned and what are the best practices we think we should share with the community so first case it's a black",
    "start": "53219",
    "end": "60930"
  },
  {
    "start": "58000",
    "end": "171000"
  },
  {
    "text": "hole so let me explain the set up a little bit so it's a service with three",
    "start": "60930",
    "end": "67080"
  },
  {
    "text": "backends and the deployments has like had three replicates and this and this",
    "start": "67080",
    "end": "72960"
  },
  {
    "text": "service is actually a UDP service with the port 53 it looks very suspicious",
    "start": "72960",
    "end": "78409"
  },
  {
    "text": "similar to a cube DNS so a climb pod",
    "start": "78409",
    "end": "84390"
  },
  {
    "text": "comes in so the plank climb pod in this case is a green one it sends a request",
    "start": "84390",
    "end": "89640"
  },
  {
    "text": "to the service cluster IP and we're gonna use Matthew McConaughey from",
    "start": "89640",
    "end": "95990"
  },
  {
    "text": "interstellar to represent a network packet",
    "start": "95990",
    "end": "100909"
  },
  {
    "text": "so the packet gets to the service cluster IP and the service supposed to",
    "start": "102240",
    "end": "110470"
  },
  {
    "text": "low balance to request the service picks one back-end and then delivers the",
    "start": "110470",
    "end": "118240"
  },
  {
    "text": "packet to the backend and this in this case matthew is happy and let's say the",
    "start": "118240",
    "end": "125740"
  },
  {
    "text": "service back end changes for whatever reason rescaling or no disruptions or",
    "start": "125740",
    "end": "130830"
  },
  {
    "text": "upgrades whatnot so one of the pods is gone and the cross represents that",
    "start": "130830",
    "end": "138730"
  },
  {
    "text": "deployment is really relevant here so it's removed so the green pod again is",
    "start": "138730",
    "end": "145000"
  },
  {
    "text": "sends another network packet and it goes to the service and this time a black",
    "start": "145000",
    "end": "150970"
  },
  {
    "text": "hole shows up and it swallows all the requests and no back end gets it and",
    "start": "150970",
    "end": "156130"
  },
  {
    "text": "matthew is sad in this case so this actually happens like a while back but",
    "start": "156130",
    "end": "163590"
  },
  {
    "text": "and this is consistently like the Green pod requests will get swallowed",
    "start": "163590",
    "end": "170019"
  },
  {
    "text": "consistently so to explain what happened we need to have we need to talk about",
    "start": "170019",
    "end": "176769"
  },
  {
    "start": "171000",
    "end": "243000"
  },
  {
    "text": "some of the background knowledge so first its contract so contract stands",
    "start": "176769",
    "end": "182500"
  },
  {
    "text": "for Linux kernel connection tracking so it basically provides the functionality to remembers the network address and the",
    "start": "182500",
    "end": "189970"
  },
  {
    "text": "port add report translations happen inside the kernel so it's based on the",
    "start": "189970",
    "end": "195610"
  },
  {
    "text": "five tuples like protocol source IP source port destination IP and destination port and the and like the",
    "start": "195610",
    "end": "205600"
  },
  {
    "text": "packet will get reversed the network address translation will get reversed on the way back so that the client will get",
    "start": "205600",
    "end": "211720"
  },
  {
    "text": "not will not get confused so on the example on the right so the order on top",
    "start": "211720",
    "end": "219640"
  },
  {
    "text": "you see the original request is sending from part one to service one and it got",
    "start": "219640",
    "end": "225220"
  },
  {
    "text": "translated to part the destination IP got translated to part 99 this will this",
    "start": "225220",
    "end": "231639"
  },
  {
    "text": "happens when the service but when request gets to a cluster IP in the",
    "start": "231639",
    "end": "236640"
  },
  {
    "text": "classroom and cost IP low bounce it to one of the back end pod the next",
    "start": "236640",
    "end": "245520"
  },
  {
    "start": "243000",
    "end": "321000"
  },
  {
    "text": "background knowledge is net filter the filter is a very important Linux component it stands for Linux packet",
    "start": "245520",
    "end": "251610"
  },
  {
    "text": "filtering framework it gives like hooks to allow users to intercept and",
    "start": "251610",
    "end": "257010"
  },
  {
    "text": "manipulate network packets and it's capable of that we're filtering which is used by network policy and also network",
    "start": "257010",
    "end": "264360"
  },
  {
    "text": "address translation or NAT in port translation which use for a cue proxy to",
    "start": "264360",
    "end": "269880"
  },
  {
    "text": "to to do the service load balancing and IP tables EB tables contract tables and",
    "start": "269880",
    "end": "277170"
  },
  {
    "text": "etc are all part of the net filter framework so on the right we have a",
    "start": "277170",
    "end": "282320"
  },
  {
    "text": "snippet of the net future processing flow chart so it's a very complex but",
    "start": "282320",
    "end": "288210"
  },
  {
    "text": "we're only going to talk about what's relevant here so in this case the network packet comes from the network",
    "start": "288210",
    "end": "294180"
  },
  {
    "text": "interface and then it enters the pre routing hook it's provided by the net filter and then within the pre routing",
    "start": "294180",
    "end": "302160"
  },
  {
    "text": "hook he first checks if there's an existing contract entry matches the network packet if it it is then it will",
    "start": "302160",
    "end": "308550"
  },
  {
    "text": "proceed if not then it will first look at it will it will pass the packet to",
    "start": "308550",
    "end": "313590"
  },
  {
    "text": "the NAT table to see if it matches any of the Matt natin adding rules and then",
    "start": "313590",
    "end": "318960"
  },
  {
    "text": "take it from there so so let me explain what happened in the black hole case",
    "start": "318960",
    "end": "324210"
  },
  {
    "start": "321000",
    "end": "366000"
  },
  {
    "text": "so first the packet comes in and the service picks a back-end and a contract",
    "start": "324210",
    "end": "331440"
  },
  {
    "text": "entries created in this case the source the original destination IP is the",
    "start": "331440",
    "end": "336690"
  },
  {
    "text": "cluster IP and then got translated to the yellow parts IP ok so the second",
    "start": "336690",
    "end": "345240"
  },
  {
    "text": "time when the request comes in there's an existing counter entry that matches",
    "start": "345240",
    "end": "351090"
  },
  {
    "text": "the packet and then the black hole shows up because contra entry decided to send",
    "start": "351090",
    "end": "357480"
  },
  {
    "text": "it for the two stale endpoint which is the yellow pod which doesn't exist",
    "start": "357480",
    "end": "363120"
  },
  {
    "text": "anymore causing the black hole so what we learn from this so it's when we",
    "start": "363120",
    "end": "370380"
  },
  {
    "start": "366000",
    "end": "484000"
  },
  {
    "text": "have contract contract can only be turned on for all the network traffic you can turn it on or off for all but",
    "start": "370380",
    "end": "376860"
  },
  {
    "text": "you cannot turn it on for partial like traffic and then you have we have NAT in",
    "start": "376860",
    "end": "382380"
  },
  {
    "text": "which we use extensively with queue proxy to increment this community",
    "start": "382380",
    "end": "387660"
  },
  {
    "text": "service and then the nature of UDP which is doesn't guarantee the reliable",
    "start": "387660",
    "end": "392670"
  },
  {
    "text": "delivery and there's no UDP like there's no connections there so and then the",
    "start": "392670",
    "end": "398250"
  },
  {
    "text": "infirm or nature of pods which has come and go all the time and then that's a",
    "start": "398250",
    "end": "403500"
  },
  {
    "text": "recipe for black hole so the fix for this is actually happen in queue proxy",
    "start": "403500",
    "end": "410820"
  },
  {
    "text": "so what we did is that we flushed the stale contract entry when the backend",
    "start": "410820",
    "end": "416640"
  },
  {
    "text": "changes we will find a corresponding back-end at the corresponding entry and then we flush it so that the next packet",
    "start": "416640",
    "end": "423330"
  },
  {
    "text": "comes in it will go through the NAT table and then go deliver to the right back-end but this is still a problem",
    "start": "423330",
    "end": "430020"
  },
  {
    "text": "because there's a student there's slight gap between like flushing the endpoint flushing the backend and the new",
    "start": "430020",
    "end": "437340"
  },
  {
    "text": "back-end and then the backend changes right there's always a gap between so - you will get a UDP packet loss basically",
    "start": "437340",
    "end": "444360"
  },
  {
    "text": "and also for UDP in general it's very tricky because the timeouts how the",
    "start": "444360",
    "end": "452190"
  },
  {
    "text": "kernel decide whether this UDP is timeout or not is just by looking at the",
    "start": "452190",
    "end": "458250"
  },
  {
    "text": "source what we're looking at the whether the packet mat mat matches the existing contract entry and there's a kernel",
    "start": "458250",
    "end": "465390"
  },
  {
    "text": "parameter to configure it but let's say you have a very long time out then you are risking the black hole but if you",
    "start": "465390",
    "end": "472650"
  },
  {
    "text": "have a very short timeout then probably the request and response cannot make the",
    "start": "472650",
    "end": "478440"
  },
  {
    "text": "round trip then it's always tricky for for UDP well we have another case for a",
    "start": "478440",
    "end": "487020"
  },
  {
    "start": "484000",
    "end": "603000"
  },
  {
    "text": "black hole so this is a typical part",
    "start": "487020",
    "end": "492510"
  },
  {
    "text": "networking set up on a VM so you have a big giant grey rectangle to represent a",
    "start": "492510",
    "end": "500310"
  },
  {
    "text": "VM and then inside this VM we have multiple Network namespaces so you have a root namespace",
    "start": "500310",
    "end": "507370"
  },
  {
    "text": "which contains the east zero that connects the VM to the network fabric and then the CBR 0 which is the",
    "start": "507370",
    "end": "513310"
  },
  {
    "text": "container bridge is also in this root namespace and each part gets this gets a",
    "start": "513310",
    "end": "519190"
  },
  {
    "text": "separate network namespace that's the default mechanism to for the pol isolation so to make to connect the",
    "start": "519190",
    "end": "527140"
  },
  {
    "text": "network namespace part one uses a network P and each part gets a virtual",
    "start": "527140",
    "end": "533920"
  },
  {
    "text": "network interface pair and then it's basically like a network cable it's like",
    "start": "533920",
    "end": "539410"
  },
  {
    "text": "once one n is in the pots network namespace the other end is hook up on to the network bridge and within the root",
    "start": "539410",
    "end": "546490"
  },
  {
    "text": "namespace that's a very typical network set up on the kubernetes node and in",
    "start": "546490",
    "end": "552670"
  },
  {
    "text": "this case network traffic can flow between part 1 and part 2 and basically",
    "start": "552670",
    "end": "558790"
  },
  {
    "text": "between the paws on the same note but no traffic can come in or go out from the",
    "start": "558790",
    "end": "565330"
  },
  {
    "text": "VM basically nothing can reach the parts on the VM and the parts cannot reach out",
    "start": "565330",
    "end": "571180"
  },
  {
    "text": "it was asked if there's a black hole in between that swallows all the traffic so",
    "start": "571180",
    "end": "577540"
  },
  {
    "text": "this actually happens and then and then multiple customer issues get to into our",
    "start": "577540",
    "end": "583530"
  },
  {
    "text": "pipeline and then finally there's an internal customer which is a Google",
    "start": "583530",
    "end": "588610"
  },
  {
    "text": "another Google team and that usually we don't have access to the customers node and this time we had a internal customer",
    "start": "588610",
    "end": "595270"
  },
  {
    "text": "then we asked them what hey gave us the permissions to log on to a VM and take a look at what happened and then we debug",
    "start": "595270",
    "end": "601060"
  },
  {
    "text": "the hell out of it and then what we found is quite tricky so memory pressure",
    "start": "601060",
    "end": "608020"
  },
  {
    "start": "603000",
    "end": "663000"
  },
  {
    "text": "happened on the VM and then and then the kernel star oome killing processes so",
    "start": "608020",
    "end": "615400"
  },
  {
    "text": "then in this case the network D which is a very important Linux component that it",
    "start": "615400",
    "end": "620500"
  },
  {
    "text": "is basically in charge of the networking stack that one killed because it got a",
    "start": "620500",
    "end": "625540"
  },
  {
    "text": "very bad um score and then there's a particular network debug in that kernel",
    "start": "625540",
    "end": "631900"
  },
  {
    "text": "which resets Colonel parameter on restart the kernel",
    "start": "631900",
    "end": "639050"
  },
  {
    "text": "parameter decides whether east zero on the VM is allowed to forward packet or",
    "start": "639050",
    "end": "647390"
  },
  {
    "text": "not in this case reset to zero that means the easier are not allowed to fold",
    "start": "647390",
    "end": "653360"
  },
  {
    "text": "packet so that's why all nobody can get in or nobody can get no nope traffic can",
    "start": "653360",
    "end": "659720"
  },
  {
    "text": "get in or no traffic can get out so so what we learn in this case so you have",
    "start": "659720",
    "end": "666140"
  },
  {
    "start": "663000",
    "end": "720000"
  },
  {
    "text": "to think deeper so so sometimes before we get to this the root cause we always",
    "start": "666140",
    "end": "672560"
  },
  {
    "text": "suggest that customers say oh hey don't try to overload your VM and then you might get into this problem and then",
    "start": "672560",
    "end": "679490"
  },
  {
    "text": "when you get into this problem restart because restart we're going to refresh the refresh the does kernel convicts but",
    "start": "679490",
    "end": "688310"
  },
  {
    "text": "like in this case it's actually a kernel bug and then fortunately at Google we have a whole team to support the host OS",
    "start": "688310",
    "end": "694880"
  },
  {
    "text": "which we call the container optimized operating system which runs on ones 4gk",
    "start": "694880",
    "end": "701330"
  },
  {
    "text": "nodes and then the team gets the bug and they fix the bug so this will not happen",
    "start": "701330",
    "end": "706990"
  },
  {
    "text": "once again and then secondly is the kernel come fix really matters",
    "start": "706990",
    "end": "712430"
  },
  {
    "text": "kubernetes depends a lot of communities features depends on the kernel itself ok",
    "start": "712430",
    "end": "721600"
  },
  {
    "start": "720000",
    "end": "797000"
  },
  {
    "text": "so we talked a little bit about black holes now we'll get into a wormhole so",
    "start": "721600",
    "end": "728270"
  },
  {
    "text": "the setup for this one on the right and the yellow we have a daemon set called a",
    "start": "728270",
    "end": "733930"
  },
  {
    "text": "and a daemon set exposes a host port 443",
    "start": "733930",
    "end": "739120"
  },
  {
    "text": "and in the blue we have a service type load bouncer which is also exposing port",
    "start": "739120",
    "end": "745670"
  },
  {
    "text": "443 and that's kind of fronting a deployment of two replicas and we can call that B so how this kind of looks we",
    "start": "745670",
    "end": "754160"
  },
  {
    "text": "have our load bouncer and we have three nodes and the demon set obviously exists",
    "start": "754160",
    "end": "759380"
  },
  {
    "text": "on all three nodes and the deployment exists on the left and right ones and we",
    "start": "759380",
    "end": "765320"
  },
  {
    "text": "can represent our packet again with our astronaut and he hits the load",
    "start": "765320",
    "end": "771180"
  },
  {
    "text": "balancer VIP at port 443 to talk to B and he gets routed to this node this is",
    "start": "771180",
    "end": "779610"
  },
  {
    "text": "a particularly unlucky node you'll see in a second because it contains both a and B so what happened was the request",
    "start": "779610",
    "end": "788760"
  },
  {
    "text": "was intended for B but it got sent to a and that makes him very sad so before we",
    "start": "788760",
    "end": "797310"
  },
  {
    "start": "797000",
    "end": "868000"
  },
  {
    "text": "can get into why this happened let's do a little refresher on IP tables so IP",
    "start": "797310",
    "end": "802980"
  },
  {
    "text": "tables is how we implement service routing and quote unquote load balancing",
    "start": "802980",
    "end": "808410"
  },
  {
    "text": "in kubernetes IP tables rules are configured by both Q proxy and cubelet",
    "start": "808410",
    "end": "815720"
  },
  {
    "text": "cubelet takes care of one specific case which is the host port case Q proxy takes care of everything else and like",
    "start": "815720",
    "end": "823019"
  },
  {
    "text": "Manhattan mentioned before IP tables works on top of netfilter",
    "start": "823019",
    "end": "829579"
  },
  {
    "text": "and so on the right is a really really simplified view of how it kind of works",
    "start": "829579",
    "end": "835529"
  },
  {
    "text": "we'll go into a much more detailed view of how it actually works in kubernetes in a little bit but as you can see we",
    "start": "835529",
    "end": "843089"
  },
  {
    "text": "register at Hook's could be like a pre routing or output and we install a bunch",
    "start": "843089",
    "end": "850019"
  },
  {
    "text": "of chains I'm Andrea in reality we have a couple layers of nesting of chains and",
    "start": "850019",
    "end": "855290"
  },
  {
    "text": "eventually we get to the actual rules which you know it can be a bunch of",
    "start": "855290",
    "end": "860820"
  },
  {
    "text": "things but in the simplest case it can be a if your destination IP is this or your port is this then do something",
    "start": "860820",
    "end": "866880"
  },
  {
    "text": "right and so now we can look at what happened so in this case a was created",
    "start": "866880",
    "end": "873209"
  },
  {
    "text": "this is the daemon set and as I mentioned before cubelet programs the IP tables rules for the host port and so",
    "start": "873209",
    "end": "881130"
  },
  {
    "text": "what happened was it programmed one rule in a chain and it basically said if the",
    "start": "881130",
    "end": "886290"
  },
  {
    "text": "destination ports 443 then Dean at two A's IP now B is created this is the",
    "start": "886290",
    "end": "892589"
  },
  {
    "text": "deployment and therefore cube proxy programs diabete Abel's rules and because it's separate X",
    "start": "892589",
    "end": "901080"
  },
  {
    "text": "Bossier type as in service is different",
    "start": "901080",
    "end": "906540"
  },
  {
    "text": "from the host port we actually have to create a new chain for that it's not on the same chain therefore we have another",
    "start": "906540",
    "end": "911820"
  },
  {
    "text": "chain here and the rule in a really simplistic view says if the source IP is the load balancer of it then dnat to be",
    "start": "911820",
    "end": "919050"
  },
  {
    "text": "is IP and so what happens is this created a wormhole right and so any",
    "start": "919050",
    "end": "925230"
  },
  {
    "text": "packet coming in that had a destination of port 443 which in this case was both",
    "start": "925230",
    "end": "930930"
  },
  {
    "text": "it always got Dean added two A's IP regardless of what the intended destination was and so we kind of like",
    "start": "930930",
    "end": "937770"
  },
  {
    "text": "to coin this as a wormhole and so some things we learned here iptables is",
    "start": "937770",
    "end": "943380"
  },
  {
    "start": "940000",
    "end": "988000"
  },
  {
    "text": "really tricky and there's two reasons why the first is you need to make sure that rules are as explicit as possible",
    "start": "943380",
    "end": "951510"
  },
  {
    "text": "as you saw that first rule which basically swallowed up all traffic on port 443 was not explicit it was really",
    "start": "951510",
    "end": "958920"
  },
  {
    "text": "wide and we should aim for having rules that are really narrow and cover a very",
    "start": "958920",
    "end": "965070"
  },
  {
    "text": "very small set of use cases and the second thing is that rules should be",
    "start": "965070",
    "end": "971250"
  },
  {
    "text": "precedence agnostic it shouldn't really matter where in the order your rule is executed it should be this it shouldn't",
    "start": "971250",
    "end": "978540"
  },
  {
    "text": "matter right but in this case it did if we had moved that first rule to be the second one we haven't met we would have",
    "start": "978540",
    "end": "984840"
  },
  {
    "text": "never seen this issue okay and so now",
    "start": "984840",
    "end": "990450"
  },
  {
    "start": "988000",
    "end": "1020000"
  },
  {
    "text": "we're gonna get into some best practices stuff that we've learned debugging customer issues and I know debugging",
    "start": "990450",
    "end": "997950"
  },
  {
    "text": "networking at least for me it can be really hard to just get started can be really daunting but what we like to do",
    "start": "997950",
    "end": "1005060"
  },
  {
    "text": "is kind of identify sources of truth and these sources of truth kind of give you",
    "start": "1005060",
    "end": "1011120"
  },
  {
    "text": "a definitive view of how the system is going to act and what the state of the",
    "start": "1011120",
    "end": "1017030"
  },
  {
    "text": "system is is in at any point in time and so one of the first sources of truth is",
    "start": "1017030",
    "end": "1022670"
  },
  {
    "start": "1020000",
    "end": "1042000"
  },
  {
    "text": "IP tables this is kind of how the IP tables dump would look if you went on a",
    "start": "1022670",
    "end": "1028959"
  },
  {
    "text": "node and just called IP tables save this is for",
    "start": "1028959",
    "end": "1034730"
  },
  {
    "text": "me when I first saw it really daunting but if you kind of break it down step by step it makes sense so let's do that",
    "start": "1034730",
    "end": "1042250"
  },
  {
    "start": "1042000",
    "end": "1109000"
  },
  {
    "text": "so this first chain here is called cube services and we can see that any packet",
    "start": "1042250",
    "end": "1049640"
  },
  {
    "text": "that's destined for 10 0 at 16 at 10 which is just a cluster VIP cluster IP",
    "start": "1049640",
    "end": "1055220"
  },
  {
    "text": "VIP sorry goes to jumps to this chain called cube service in the green and",
    "start": "1055220",
    "end": "1061360"
  },
  {
    "text": "this is kind of representative of a service right so we have our cluster IP there okay",
    "start": "1061360",
    "end": "1070910"
  },
  {
    "text": "and so now we have two more chains here the cube SCP which is just stands for",
    "start": "1070910",
    "end": "1077630"
  },
  {
    "text": "endpoint service endpoint and this is just kind of a really this is what we",
    "start": "1077630",
    "end": "1083270"
  },
  {
    "text": "say quote unquote load balancing because we basically use probability to distribute between the endpoints and so",
    "start": "1083270",
    "end": "1091370"
  },
  {
    "text": "you can see there are two endpoints here and that's how we have represented it here at the bottom two endpoints and",
    "start": "1091370",
    "end": "1098350"
  },
  {
    "text": "then for each of those endpoints we can see that a D net occurs to a specific IP",
    "start": "1098350",
    "end": "1103850"
  },
  {
    "text": "and that's a pot IP and that's represented by those right there okay",
    "start": "1103850",
    "end": "1110870"
  },
  {
    "text": "next source of truth contract contract is a really good way to see the state of",
    "start": "1110870",
    "end": "1118220"
  },
  {
    "text": "the system in a dynamic way whereas iptables is kind of static it doesn't show you what's going on at any given",
    "start": "1118220",
    "end": "1124010"
  },
  {
    "text": "time contract does and so we have kind of two examples here the first is a",
    "start": "1124010",
    "end": "1130070"
  },
  {
    "text": "really simple just kind of pot to pot communication case as you can see the",
    "start": "1130070",
    "end": "1136160"
  },
  {
    "text": "stuff in the blue tells you that it's an entry for traffic from one pot to the",
    "start": "1136160",
    "end": "1144200"
  },
  {
    "text": "other and then they read is the way coming back and then the second case is",
    "start": "1144200",
    "end": "1149419"
  },
  {
    "text": "a little more interesting actually you can tell by looking at the source IP that would be a load balancer IP and the",
    "start": "1149419",
    "end": "1157100"
  },
  {
    "text": "destination port and the blue is a very common node port so this kind of gives you a clue that this is an entry for a",
    "start": "1157100",
    "end": "1164390"
  },
  {
    "text": "node port type service all right so generally when we look at a",
    "start": "1164390",
    "end": "1172639"
  },
  {
    "text": "customer issue we first determine whether this is a control plane problem or data plane problem so that you can",
    "start": "1172639",
    "end": "1179029"
  },
  {
    "text": "tell by like like the symptoms and what are the problems you show up so when",
    "start": "1179029",
    "end": "1185509"
  },
  {
    "text": "it's a control plane problem generally speaking go to the logs first logs events and we'll see what happened and",
    "start": "1185509",
    "end": "1193730"
  },
  {
    "text": "then take it from there for data plane is a little bit tricky because the stack is a little bit deeper so first from the",
    "start": "1193730",
    "end": "1199370"
  },
  {
    "text": "user space you have the application coming from the users place and then it enters the kernel space and then finally",
    "start": "1199370",
    "end": "1205909"
  },
  {
    "text": "get out to the network fabric so there's many places to look at so in this",
    "start": "1205909",
    "end": "1212840"
  },
  {
    "text": "example we're gonna show you like a sample like troubleshooting mythology or",
    "start": "1212840",
    "end": "1219259"
  },
  {
    "text": "process that we do in this case the customer is like complaining DNS queries",
    "start": "1219259",
    "end": "1226429"
  },
  {
    "text": "are timing out so first things first we need to figure out how how's the traffic",
    "start": "1226429",
    "end": "1232190"
  },
  {
    "text": "flow what's the data plane looks like so first the traffic comes out from the",
    "start": "1232190",
    "end": "1238309"
  },
  {
    "text": "client pod the grandpa censor request goes to the CBR zero and traverse the IP",
    "start": "1238309",
    "end": "1244279"
  },
  {
    "text": "tables and out of the east zero interface to the network fabric and then",
    "start": "1244279",
    "end": "1250549"
  },
  {
    "text": "magically the network fabric delivers the packet to the destination node and",
    "start": "1250549",
    "end": "1256519"
  },
  {
    "text": "then the destination node route the packet to the DNS server pod in this",
    "start": "1256519",
    "end": "1263899"
  },
  {
    "text": "case the request doesn't ends here because cube DNS only serves cluster",
    "start": "1263899",
    "end": "1269629"
  },
  {
    "text": "internal DNS queries when he finds the queries it cannot serve it will forward",
    "start": "1269629",
    "end": "1275450"
  },
  {
    "text": "to upstream DNS servers in this case the server a DNS server pod process it and",
    "start": "1275450",
    "end": "1281090"
  },
  {
    "text": "decide ok I'm not in I'm gonna afford it and then the traffic will come out and",
    "start": "1281090",
    "end": "1286820"
  },
  {
    "text": "to the CBR 0 bridge out to the narrow fabric and go to the upstream DNS so DNS",
    "start": "1286820",
    "end": "1294860"
  },
  {
    "text": "query is timing out so like what what do we look at so first thing first",
    "start": "1294860",
    "end": "1301700"
  },
  {
    "text": "that it actually sent now the request right this can be tailed by the application logs to tell it certain to",
    "start": "1301700",
    "end": "1309139"
  },
  {
    "text": "to tell it definitely you need to dirty use TCP dump to see if actually the",
    "start": "1309139",
    "end": "1314840"
  },
  {
    "text": "request comes out from the interface so just keep in mind that TCP dump works at",
    "start": "1314840",
    "end": "1320779"
  },
  {
    "text": "the interface level so you have to attach to an interface the it doesn't it",
    "start": "1320779",
    "end": "1325880"
  },
  {
    "text": "depends on how the traffic flows and whether the traffic gets knotted or not you will see the packet as it arrives on",
    "start": "1325880",
    "end": "1333139"
  },
  {
    "text": "the interface so in this case you can dump it on the east zero inside the pot",
    "start": "1333139",
    "end": "1339649"
  },
  {
    "text": "namespace or outside in who if you do TCP dump in the root namespace then you",
    "start": "1339649",
    "end": "1346039"
  },
  {
    "text": "need to find their correct VF pair of the pod and then dump on that interface",
    "start": "1346039",
    "end": "1352100"
  },
  {
    "text": "and then you can tell whether there's DNS requests actually coming out from",
    "start": "1352100",
    "end": "1357889"
  },
  {
    "text": "the pod and then you can also dump on the CB r0 bridge and see if the CBR 0",
    "start": "1357889",
    "end": "1364250"
  },
  {
    "text": "bridge is actually routing is actually except taking the traffic and routing it",
    "start": "1364250",
    "end": "1369260"
  },
  {
    "text": "correctly and finally you can dump on any interfaces and see if there's if the",
    "start": "1369260",
    "end": "1377299"
  },
  {
    "text": "IP tables are actually processing the request correctly whether it's for the",
    "start": "1377299",
    "end": "1383090"
  },
  {
    "text": "forwarding the traffic to correct back in and when the traffic when the packet",
    "start": "1383090",
    "end": "1390620"
  },
  {
    "text": "goes on to the network abric then it's the typical stuff on to look at on your",
    "start": "1390620",
    "end": "1395720"
  },
  {
    "text": "network fabric where you need to look at routes if you are using overlay whether",
    "start": "1395720",
    "end": "1400760"
  },
  {
    "text": "the overlay is functioning correctly your firewalls and all the other stuff so and then on the destination node",
    "start": "1400760",
    "end": "1409779"
  },
  {
    "text": "check on the east zero to see if the destination node actually accepts the",
    "start": "1409779",
    "end": "1415340"
  },
  {
    "text": "traffic and then finally in the in the",
    "start": "1415340",
    "end": "1420649"
  },
  {
    "text": "DNS part and see if the requests are actually coming from the client part and the server logs can tell you how whether",
    "start": "1420649",
    "end": "1429289"
  },
  {
    "text": "the server is actually receiving it and how is getting processed if you want more",
    "start": "1429289",
    "end": "1435440"
  },
  {
    "text": "you can use s trace to attach to the server parts the process ID and then see",
    "start": "1435440",
    "end": "1442490"
  },
  {
    "text": "what's this cause it says it is making and then similarly to check if the how",
    "start": "1442490",
    "end": "1448970"
  },
  {
    "text": "going request the for the requests are actually heading to in this case ad ID",
    "start": "1448970",
    "end": "1454250"
  },
  {
    "text": "and then Excel so eventually you can see ok what breaks and the whole data plane",
    "start": "1454250",
    "end": "1462700"
  },
  {
    "text": "so that basically concludes our talk so",
    "start": "1462700",
    "end": "1468290"
  },
  {
    "start": "1463000",
    "end": "1503000"
  },
  {
    "text": "networking is hard but like with some patience and more background knowledge",
    "start": "1468290",
    "end": "1474820"
  },
  {
    "text": "kubernetes networking is not magic anymore all right",
    "start": "1474820",
    "end": "1481690"
  },
  {
    "text": "[Applause]",
    "start": "1481700",
    "end": "1485209"
  },
  {
    "text": "any questions",
    "start": "1488200",
    "end": "1491740"
  },
  {
    "text": "I can talk about that yeah so you said",
    "start": "1496650",
    "end": "1503790"
  },
  {
    "start": "1503000",
    "end": "1603000"
  },
  {
    "text": "what about ipbs yeah so good that you mentioned that actually I PBS for anyone",
    "start": "1503790",
    "end": "1510990"
  },
  {
    "text": "who doesn't know it's just another form of load balancing in the kernel it's actually more adept to load balancing",
    "start": "1510990",
    "end": "1517200"
  },
  {
    "text": "than iptables is it's actually beta and kubernetes right now the plan is to go",
    "start": "1517200",
    "end": "1523760"
  },
  {
    "text": "GA with it in the next release which is 1.11 but to your question i PVS is still",
    "start": "1523760",
    "end": "1531210"
  },
  {
    "text": "built on top of netfilter just the way it kind of uses those hooks is a little different like iptables we",
    "start": "1531210",
    "end": "1538800"
  },
  {
    "text": "do dnat and pre routing where as an IP vs they do d net and input and so stuff",
    "start": "1538800",
    "end": "1544620"
  },
  {
    "text": "like that varies but for the most part the underlying like stuff is the same so",
    "start": "1544620",
    "end": "1552470"
  },
  {
    "text": "um yeah I mean it's it's a different technology and it's one that all of us",
    "start": "1554150",
    "end": "1560610"
  },
  {
    "text": "on the team have to get on boarded to and so we definitely expect problems but it's good that the underlying",
    "start": "1560610",
    "end": "1567210"
  },
  {
    "text": "technologies are the same and we're familiar with that so",
    "start": "1567210",
    "end": "1572090"
  },
  {
    "text": "yeah we Oh doesn't work you can come",
    "start": "1589100",
    "end": "1598559"
  },
  {
    "text": "down yeah oh it works now okay so so the",
    "start": "1598559",
    "end": "1604980"
  },
  {
    "start": "1603000",
    "end": "1916000"
  },
  {
    "text": "question is like any other tools that you that we recommend - I see so so",
    "start": "1604980",
    "end": "1617789"
  },
  {
    "text": "there are more monitoring and logging like support on gke but generally",
    "start": "1617789",
    "end": "1624419"
  },
  {
    "text": "speaking we can't touch the user's VM so that gives us a lot of a barrier so we",
    "start": "1624419",
    "end": "1632309"
  },
  {
    "text": "have to sometimes we have to ask the users to give us to execute something",
    "start": "1632309",
    "end": "1637740"
  },
  {
    "text": "for us and then just give us more clue what's happening and we are also having",
    "start": "1637740",
    "end": "1645120"
  },
  {
    "text": "like we're also thinking of like kind of like a debug tool kit or something that can be deployed as a privilege pod on",
    "start": "1645120",
    "end": "1653370"
  },
  {
    "text": "any node and then have a better debugging so but that depends on there",
    "start": "1653370",
    "end": "1658620"
  },
  {
    "text": "has a lot of dependency so first the know has to be functioning and things like that so but for now we",
    "start": "1658620",
    "end": "1665340"
  },
  {
    "text": "use that whatever you saw is what we use",
    "start": "1665340",
    "end": "1669350"
  },
  {
    "text": "[Music] so so the question is that wormholes are",
    "start": "1696610",
    "end": "1703729"
  },
  {
    "text": "common right that's what you experience it depends on the setup I think it depends on your q proxy implementation",
    "start": "1703729",
    "end": "1710599"
  },
  {
    "text": "and all your network network provider so if those are compatible usually these",
    "start": "1710599",
    "end": "1717199"
  },
  {
    "text": "happens when they are not compatible they say okay is too like two components",
    "start": "1717199",
    "end": "1722269"
  },
  {
    "text": "are programming iptables and don't they don't know each other they collide that happens right so it really depends on",
    "start": "1722269",
    "end": "1729079"
  },
  {
    "text": "your network setup and whoever manages the setup needs to make sure that these",
    "start": "1729079",
    "end": "1734539"
  },
  {
    "text": "are compatible right that's I think that's the right answer where it needs to be fully tested out in all the corner",
    "start": "1734539",
    "end": "1741019"
  },
  {
    "text": "cases like hairpins hairpin traffic's or other like mattad traffic or no port so",
    "start": "1741019",
    "end": "1747619"
  },
  {
    "text": "basically there's a there's a variety of a networking test suite exist on the",
    "start": "1747619",
    "end": "1753229"
  },
  {
    "text": "kubernetes repo where it has to pass right and then and then yeah that's",
    "start": "1753229",
    "end": "1760999"
  },
  {
    "text": "basically my answers yeah like not",
    "start": "1760999",
    "end": "1766879"
  },
  {
    "text": "end-user I would say whoever manages the cluster right yeah",
    "start": "1766879",
    "end": "1773829"
  },
  {
    "text": "yeah okay",
    "start": "1774369",
    "end": "1782439"
  },
  {
    "text": "yeah yeah we had a lot of ideas but the",
    "start": "1801280",
    "end": "1809900"
  },
  {
    "text": "thing is that troubleshooting the every issue is very different and then hopefully because cubanelle is still",
    "start": "1809900",
    "end": "1816620"
  },
  {
    "text": "very young compared to a lot of other projects it's still like three years old",
    "start": "1816620",
    "end": "1821750"
  },
  {
    "text": "believe it or not it's still having so much adoption so there are like if if",
    "start": "1821750",
    "end": "1827090"
  },
  {
    "text": "Google if you are very mature project engineer should not get any like",
    "start": "1827090",
    "end": "1832190"
  },
  {
    "text": "customer issues at all right so right now we are still getting the fact that it was still get it means that it's not",
    "start": "1832190",
    "end": "1838580"
  },
  {
    "text": "perfect so we are also learning and exploring like you said it's a very",
    "start": "1838580",
    "end": "1844250"
  },
  {
    "text": "common problem where you have many many pages of notes and and things like that",
    "start": "1844250",
    "end": "1850250"
  },
  {
    "text": "yeah that that can get very daunting but",
    "start": "1850250",
    "end": "1854920"
  },
  {
    "text": "when you ask about security the answer is always defense-in-depth right so it",
    "start": "1867490",
    "end": "1873530"
  },
  {
    "text": "provides you a certain level of security you say never policy can you rely on it",
    "start": "1873530",
    "end": "1878570"
  },
  {
    "text": "yeah maybe but a certain level and then and then you are talking about container level security then you probably want",
    "start": "1878570",
    "end": "1885020"
  },
  {
    "text": "like like gee visor right where you have real a sandbox around your container",
    "start": "1885020",
    "end": "1891320"
  },
  {
    "text": "thing yeah ask the Calico guys they were",
    "start": "1891320",
    "end": "1902590"
  },
  {
    "text": "our targets mostly about like what doesn't work well so any other questions",
    "start": "1902590",
    "end": "1910880"
  },
  {
    "text": "or we can always chat offline right oh yeah thank you",
    "start": "1910880",
    "end": "1917919"
  }
]
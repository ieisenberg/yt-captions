[
  {
    "start": "0",
    "end": "77000"
  },
  {
    "text": "hello everyone welcome to the prometheus deep dive we're super excited to show you how to use prometheus and how to",
    "start": "320",
    "end": "6160"
  },
  {
    "text": "take prometheus usage to the next level before we start a quick intro hi i'm",
    "start": "6160",
    "end": "12400"
  },
  {
    "text": "gautham i'm a software engineer at grifana labs and i am a prometheus and cortex",
    "start": "12400",
    "end": "17760"
  },
  {
    "text": "maintainer i've actually started contributing to prometheus about three and a half years four years ago",
    "start": "17760",
    "end": "22880"
  },
  {
    "text": "and later i started working on cortex to provide a hosted prometheus service between prometheus and cortex i also",
    "start": "22880",
    "end": "30960"
  },
  {
    "text": "was one of the initial authors of loki a logging project an open source logging solution inspired",
    "start": "30960",
    "end": "36719"
  },
  {
    "text": "by prometheus amazing okay my name is bartok vodka and",
    "start": "36719",
    "end": "42320"
  },
  {
    "text": "i'm an engineer working in the monitoring team at red hat i love open source and",
    "start": "42320",
    "end": "47600"
  },
  {
    "text": "solving problems i am part of the promotions properties team and i'm also a cauter of thanos and",
    "start": "47600",
    "end": "54480"
  },
  {
    "text": "on the top of on top of that you might know me from the newly created cnc special interest group",
    "start": "54480",
    "end": "60079"
  },
  {
    "text": "observability uh where we focus on the cloud native observability",
    "start": "60079",
    "end": "65280"
  },
  {
    "text": "topics like and projects like you know cortex plantanos prometheus open telemetry and so on so if you find",
    "start": "65280",
    "end": "71680"
  },
  {
    "text": "this interesting please visit us on um on this git repository",
    "start": "71680",
    "end": "77200"
  },
  {
    "start": "77000",
    "end": "77000"
  },
  {
    "text": "so let's start with a typical team in this case the team in which kate and tom are a part of so they run an api service they've",
    "start": "77200",
    "end": "84000"
  },
  {
    "text": "successfully built and launched that api service and it works really well but a couple of days later they noticed",
    "start": "84000",
    "end": "91119"
  },
  {
    "text": "that the users are looking at 500 issues or 500 errors and they're trying hard to debug what is",
    "start": "91119",
    "end": "97200"
  },
  {
    "text": "throwing these 500 is it the load balancer is it their own application is the database locking up is the database being slow",
    "start": "97200",
    "end": "103600"
  },
  {
    "text": "what was the cause of it to debug this they were adding more logs and deploying into production to try to",
    "start": "103600",
    "end": "109040"
  },
  {
    "text": "figure out where the error was being introduced now this is not ideal and this",
    "start": "109040",
    "end": "115759"
  },
  {
    "text": "was frustrating kate and tom so kate decided to look into how to fix this and the easiest way to fix this is to add",
    "start": "115759",
    "end": "121759"
  },
  {
    "start": "120000",
    "end": "120000"
  },
  {
    "text": "monitoring in this case uh kate actually chose prometheus and grafana the golden stack",
    "start": "121759",
    "end": "127600"
  },
  {
    "text": "and she added an exporter in front of the load balancer in the database exposing all the metrics of the load",
    "start": "127600",
    "end": "133040"
  },
  {
    "text": "balancer and database and she also instrumented the application itself to expose prometheus metrics prometheus now collects all this",
    "start": "133040",
    "end": "140160"
  },
  {
    "text": "data and kate can now alert on 500 errors or other issues she also added dashboarding on top of it",
    "start": "140160",
    "end": "146959"
  },
  {
    "start": "146000",
    "end": "146000"
  },
  {
    "text": "so whenever there's an alert or an issue they can directly look at all this dashboard with all the information to directly figure out okay",
    "start": "146959",
    "end": "153760"
  },
  {
    "text": "the database is having issues which is why we are throwing 500 address so their outages didn't stop but",
    "start": "153760",
    "end": "159519"
  },
  {
    "text": "whenever there was an outage they could very quickly figure out what was happening what was going wrong and what",
    "start": "159519",
    "end": "164560"
  },
  {
    "text": "to debug and they were very quick at fixing all these issues looking at their success the other teams",
    "start": "164560",
    "end": "171200"
  },
  {
    "text": "also started using prometheus as is the prometheus best practice each team was maintaining their own",
    "start": "171200",
    "end": "177280"
  },
  {
    "text": "prometheus they were metering their own grafana and all of this was working really well now all the teams in the",
    "start": "177280",
    "end": "183599"
  },
  {
    "text": "organization were using prometheus and as the usage of the organization and the application grew they started deploying",
    "start": "183599",
    "end": "190159"
  },
  {
    "text": "to several data centers again as is the prometheus best practice you deploy a prometheus poor data center",
    "start": "190159",
    "end": "196720"
  },
  {
    "text": "the next slide yeah um this is because prometheus needs to be close to the application",
    "start": "196720",
    "end": "202159"
  },
  {
    "text": "it's monitoring so in this case they were deploying to us central one and eu s2 and whenever there's an alert the",
    "start": "202159",
    "end": "208080"
  },
  {
    "text": "alert actually contains which prometheus generated this so if they're looking at an alert from u.s central one they directly go to the",
    "start": "208080",
    "end": "214159"
  },
  {
    "text": "grafana of us central one look at look at the system and see what was going wrong and it was all working",
    "start": "214159",
    "end": "220319"
  },
  {
    "text": "really well until until at some point kate and tom wanted to",
    "start": "220319",
    "end": "227760"
  },
  {
    "text": "figure it out how to aggregate the data on the global level from the multiple promoter servers",
    "start": "227760",
    "end": "233920"
  },
  {
    "text": "right it was so let's imagine that tom wanted to answer maybe simple question right what is the",
    "start": "233920",
    "end": "239840"
  },
  {
    "text": "error rate of um of the http requests made by or received by his service right",
    "start": "239840",
    "end": "247840"
  },
  {
    "text": "and he want to aggregate and know the rate across all the um and some of those rays across all the",
    "start": "247840",
    "end": "255280"
  },
  {
    "text": "all the clusters and and as you remember uh in each of those there are prominent",
    "start": "255280",
    "end": "260479"
  },
  {
    "text": "servers so we have um essentially we have to aggregate from more than one premier servers",
    "start": "260479",
    "end": "265600"
  },
  {
    "text": "how to do that uh just in promo just using promote use alone now um",
    "start": "265600",
    "end": "272240"
  },
  {
    "start": "271000",
    "end": "271000"
  },
  {
    "text": "well you cannot use query api which is um which is kind of the the first thing you",
    "start": "272240",
    "end": "277280"
  },
  {
    "text": "would you would try to use and this is because chromeql elevation is made on the leaf node so",
    "start": "277280",
    "end": "283600"
  },
  {
    "text": "once you have the data from two sources there is already pro chrome ql evaluation made so you would",
    "start": "283600",
    "end": "290400"
  },
  {
    "text": "need to have another layer of uh query evaluation to be made to adjust and to add additional",
    "start": "290400",
    "end": "296560"
  },
  {
    "text": "aggregate like for example sum to summarize those results together to tell you the overall error rate for",
    "start": "296560",
    "end": "303440"
  },
  {
    "text": "example now this is not trivial work because there are lots of um catchy things and cabinets like",
    "start": "303440",
    "end": "311360"
  },
  {
    "text": "um additional load uh on doing from ql and and resolutions and steps so",
    "start": "311360",
    "end": "317600"
  },
  {
    "text": "all of this is not easy to solve with using using query api however the prompt use allows other apis",
    "start": "317600",
    "end": "324720"
  },
  {
    "text": "to solve this problem and first of those apis is the federation api let's call it",
    "start": "324720",
    "end": "329919"
  },
  {
    "start": "326000",
    "end": "326000"
  },
  {
    "text": "in in this um kind of scenario we are deploying another prominent use",
    "start": "329919",
    "end": "336160"
  },
  {
    "text": "server on top of those cluster maybe in another cluster maybe in one of those clusters",
    "start": "336160",
    "end": "342000"
  },
  {
    "text": "and you configure this promoters to scrape a federate endpoint that those",
    "start": "342000",
    "end": "347520"
  },
  {
    "text": "leaf prometuses expose and it scrapes like a normal scrape very similar and so even you",
    "start": "347520",
    "end": "354160"
  },
  {
    "text": "create a scrape configuration for that and this kind of works great",
    "start": "354160",
    "end": "360240"
  },
  {
    "text": "until you have huge or like you know bigger amount of data",
    "start": "360240",
    "end": "366560"
  },
  {
    "text": "in those leaf produces because as you can imagine if you are scraping and replicating all",
    "start": "366560",
    "end": "372160"
  },
  {
    "text": "of the data into the global promoters uh or like yeah into the global chromato server",
    "start": "372160",
    "end": "378160"
  },
  {
    "text": "it grows in the same um with the same kind of pace as the lift from it uses because",
    "start": "378160",
    "end": "384240"
  },
  {
    "text": "you replicate all of this data and suddenly you do that for the single instance that is running on the single",
    "start": "384240",
    "end": "389759"
  },
  {
    "text": "machine um this causes lots of problems so the um the thing that we suggest um as",
    "start": "389759",
    "end": "397120"
  },
  {
    "text": "prometheus maintainers and the community you should only use federation for only only for subset of",
    "start": "397120",
    "end": "403919"
  },
  {
    "text": "your data and the easiest way to do that is to essentially uh create recording rules for the things",
    "start": "403919",
    "end": "410639"
  },
  {
    "text": "that you want to have on the global level and also you can you know things of that reduce the cardinality of the recorded",
    "start": "410639",
    "end": "417440"
  },
  {
    "text": "data because you can sum aggregate across those um and you configure",
    "start": "417440",
    "end": "422720"
  },
  {
    "text": "federation to only federate to only scrape the rules by the",
    "start": "422720",
    "end": "428080"
  },
  {
    "text": "parameter of matcher and well because of that you need to also adjust the query that",
    "start": "428080",
    "end": "433280"
  },
  {
    "text": "um that tom has to make to query essential recording rule not the data itself anyway the valid and",
    "start": "433280",
    "end": "441039"
  },
  {
    "text": "the precise answer is available for tom so tom is most likely happy",
    "start": "441039",
    "end": "446240"
  },
  {
    "text": "however there are other options as well the third option is really similar to",
    "start": "446240",
    "end": "452000"
  },
  {
    "text": "the query api where you just provide a query that that has to be evaluated for your answer",
    "start": "452000",
    "end": "458960"
  },
  {
    "text": "instead of that you are going deeper and trying to access the actual samples stored in the database of",
    "start": "458960",
    "end": "466160"
  },
  {
    "text": "properties and this is the api that allows that is called remote read so during that um api you are using",
    "start": "466160",
    "end": "474160"
  },
  {
    "text": "a slight different payload it's not a json it's protobuf is actually should be familiar to you if",
    "start": "474160",
    "end": "481520"
  },
  {
    "text": "you are using jrpc protocols and inside that api you are specifying",
    "start": "481520",
    "end": "486960"
  },
  {
    "text": "the matchers so we are matching a certain data that you want to fetch and then you need to",
    "start": "486960",
    "end": "492560"
  },
  {
    "text": "have some kind of automation that will do some nice work from it and one of the example",
    "start": "492560",
    "end": "498319"
  },
  {
    "text": "of the of the projects that allows you to do that is tunnels and essentially thanos allows you to",
    "start": "498319",
    "end": "505919"
  },
  {
    "start": "500000",
    "end": "500000"
  },
  {
    "text": "add a side card which probably to use that using that's just using this reit protocol and then expose it into the",
    "start": "505919",
    "end": "512719"
  },
  {
    "text": "grpc that prompted thanos is using and then you essentially allow",
    "start": "512719",
    "end": "518959"
  },
  {
    "text": "yourself to create and to deploy and global query component which does the pronquial",
    "start": "518959",
    "end": "525839"
  },
  {
    "text": "evaluation on the global level having the data from each promote users um separately so and this is how you can",
    "start": "525839",
    "end": "534000"
  },
  {
    "text": "essentially transparently have the global view without recording rules and without replicating all of your data",
    "start": "534000",
    "end": "540560"
  },
  {
    "text": "multiple times however you know there are other um",
    "start": "540560",
    "end": "547839"
  },
  {
    "start": "544000",
    "end": "544000"
  },
  {
    "text": "when we are thinking about you know with bigger adoption and more users so at some point kate was kind of",
    "start": "547839",
    "end": "554640"
  },
  {
    "text": "annoyed that she has very short metric retention only you know a couple of weeks",
    "start": "554640",
    "end": "560000"
  },
  {
    "text": "so she thought about hey what about maybe longer one maybe uh years of data",
    "start": "560000",
    "end": "565040"
  },
  {
    "text": "so i can analyze my uh my data maybe um also some teams",
    "start": "565040",
    "end": "570640"
  },
  {
    "text": "um have the policy to store uh the metrics for whatever was like",
    "start": "570640",
    "end": "576959"
  },
  {
    "text": "life period of your service so it is kind of crucial requirement for some companies so",
    "start": "576959",
    "end": "583839"
  },
  {
    "start": "583000",
    "end": "583000"
  },
  {
    "text": "it would be beautiful if you would be able to just query those directly into pro materials",
    "start": "583839",
    "end": "589120"
  },
  {
    "text": "and just just have those two years query working smoothly and i can tell you that this is totally",
    "start": "589120",
    "end": "595120"
  },
  {
    "start": "595000",
    "end": "595000"
  },
  {
    "text": "doable with just promote use there is a misconception that promoters",
    "start": "595120",
    "end": "600320"
  },
  {
    "text": "is not suitable for long-term storage and you have to deploy some external systems and and",
    "start": "600320",
    "end": "606079"
  },
  {
    "text": "have some integration that's not always the case because especially from prometus 2",
    "start": "606079",
    "end": "611440"
  },
  {
    "text": "and the recent versions of promote use we made sure that the older data that you store",
    "start": "611440",
    "end": "618160"
  },
  {
    "text": "actually adds marginal resources when they are not used so whenever you are just querying short",
    "start": "618160",
    "end": "625519"
  },
  {
    "text": "period of times and and mostly from from our experience people",
    "start": "625519",
    "end": "631200"
  },
  {
    "text": "are queries you know the very fresh data um those all their data even for years time are not really",
    "start": "631200",
    "end": "637440"
  },
  {
    "text": "um increasing your resources so it doesn't the the the resources and consumption of",
    "start": "637440",
    "end": "642959"
  },
  {
    "text": "those resources for promotion server doesn't scale with the retention that you give and um to make it easier for you",
    "start": "642959",
    "end": "651040"
  },
  {
    "text": "we would really recommend setting you know some large disk and precisely try to precisely effect",
    "start": "651040",
    "end": "658240"
  },
  {
    "text": "and plan the capacity of the disk space uh because you want to avoid kind of you know resizes and and",
    "start": "658240",
    "end": "665040"
  },
  {
    "text": "things like that after those years time so it's totally doable and we have lots of users who are",
    "start": "665040",
    "end": "670079"
  },
  {
    "text": "having you know two years data on their prometus server however yes there are some trade-offs",
    "start": "670079",
    "end": "677600"
  },
  {
    "start": "675000",
    "end": "675000"
  },
  {
    "text": "after all prometheus was mainly focused on the monitoring for resin",
    "start": "677600",
    "end": "682720"
  },
  {
    "text": "and data and alerting so there are some caveats one of it is that it's super hard to",
    "start": "682720",
    "end": "688240"
  },
  {
    "text": "efficiently or like effectively plan um capacity of your disks because",
    "start": "688240",
    "end": "693440"
  },
  {
    "text": "there are lots of unpredictable spikes um it's hard to sometimes control cardinality",
    "start": "693440",
    "end": "698560"
  },
  {
    "text": "of the data you're ingesting so it's not the easy task after all um the second problem might be",
    "start": "698560",
    "end": "705839"
  },
  {
    "text": "backup you know if you have those disk hardware can fail and you have to have some",
    "start": "705839",
    "end": "711440"
  },
  {
    "text": "backup plan and operational kind of you know structure of it some scripts automation",
    "start": "711440",
    "end": "717200"
  },
  {
    "text": "and it's not always the easiest way um especially on bare metal and last but not the least uh well there",
    "start": "717200",
    "end": "724079"
  },
  {
    "text": "is no native down sampling on prometheus side which means that the large range queries",
    "start": "724079",
    "end": "730240"
  },
  {
    "text": "like for example for two years for two years will fetch all those samples into the prom ql engine and fromql has",
    "start": "730240",
    "end": "738480"
  },
  {
    "text": "to run for all those samples to calculate your response and while this is doable it will take",
    "start": "738480",
    "end": "745279"
  },
  {
    "text": "some time and there is definitely some room for some",
    "start": "745279",
    "end": "750480"
  },
  {
    "text": "down sampling that will reduce the resolution that you don't need um for querying such a long time range",
    "start": "750480",
    "end": "759600"
  },
  {
    "text": "cool um so now in the organization every team is using",
    "start": "759600",
    "end": "765040"
  },
  {
    "text": "prometheus and now more and more users want to use prometheus and there are more use cases",
    "start": "765040",
    "end": "770160"
  },
  {
    "text": "coming up for example uh let's say the marketing team comes to kate and us asks if they could use the data",
    "start": "770160",
    "end": "777279"
  },
  {
    "text": "in their data lake or on another database or maybe some uh someone wants to use the prometheus",
    "start": "777279",
    "end": "783839"
  },
  {
    "text": "data and store it in a replicated or distributed database that was that is much better at storing long-term",
    "start": "783839",
    "end": "789839"
  },
  {
    "text": "long-term storage how do you send all of this data to a different database how do you do this",
    "start": "789839",
    "end": "795040"
  },
  {
    "text": "replication so prometheus has a protocol called remote right it's an extremely simple protocol",
    "start": "795040",
    "end": "800480"
  },
  {
    "text": "uh so in your prometheus configuration you just add of stamps are called remote right uh",
    "start": "800480",
    "end": "805519"
  },
  {
    "text": "you name the remote or remote endpoint uh you if you have any authentication on it you specify the authentication",
    "start": "805519",
    "end": "812079"
  },
  {
    "text": "and then prometheus will start sending every single sample its create to this remote endpoint",
    "start": "812079",
    "end": "818000"
  },
  {
    "text": "now typically uh your prometheus will scrape millions of samples a second and sometimes you only want to send a",
    "start": "818000",
    "end": "824880"
  },
  {
    "text": "subset of the data to the remote endpoint and doing that is also extremely use easy you can use",
    "start": "824880",
    "end": "830639"
  },
  {
    "text": "the right relabel configs to kind of specify what data you want to send over and what data you want to",
    "start": "830639",
    "end": "836959"
  },
  {
    "text": "keep uh or like what data you want to drop and it's a very powerful uh config you",
    "start": "836959",
    "end": "843120"
  },
  {
    "text": "can also manipulate the data before sending it over so with this you can send as much or as",
    "start": "843120",
    "end": "848720"
  },
  {
    "text": "little as you want if marketing just wants to look at the ui level visits you can only send",
    "start": "848720",
    "end": "854399"
  },
  {
    "text": "the metrics for the ui level visits to a remote store and now this is extremely popular and we",
    "start": "854399",
    "end": "861040"
  },
  {
    "text": "already have almost every single popular time series database out there integrating with the prometheus remote",
    "start": "861040",
    "end": "867440"
  },
  {
    "text": "right and read natively so we have a non exhaustive list of projects like about 25 of them which",
    "start": "867440",
    "end": "873920"
  },
  {
    "text": "kind of support prometheus read and prometheus right and you will most likely see all your",
    "start": "873920",
    "end": "880880"
  },
  {
    "text": "favorite dhdbs in there but in case you want to send a prometheus remote right data to a",
    "start": "880880",
    "end": "887680"
  },
  {
    "text": "different database that's not in the list that doesn't have a existing integration it's extremely easy",
    "start": "887680",
    "end": "893279"
  },
  {
    "text": "to build an integration we use the same protobufs if you're familiar with grpc you will be familiar",
    "start": "893279",
    "end": "899199"
  },
  {
    "text": "with this so in this case we are basically uh sending a prototype of message",
    "start": "899199",
    "end": "904480"
  },
  {
    "text": "called write request uh which is a list of time series now what is the time series a time",
    "start": "904480",
    "end": "909760"
  },
  {
    "text": "series is basically the labels for the time series and the samples in that time series so with this extremely simple",
    "start": "909760",
    "end": "915839"
  },
  {
    "text": "protobuf you just create the protobufs and send it across like prometheus creates this protobuf and sends it",
    "start": "915839",
    "end": "921680"
  },
  {
    "text": "across and if you can actually accept this protocol you can store all the data",
    "start": "921680",
    "end": "926959"
  },
  {
    "text": "that prometheus sends to you now one of the typical use cases for this",
    "start": "926959",
    "end": "932399"
  },
  {
    "start": "930000",
    "end": "930000"
  },
  {
    "text": "is actually long-term storage this is also another solution for the global view problem that bartek was talking",
    "start": "932399",
    "end": "938720"
  },
  {
    "text": "before if you want to combine the data between u.s central one and eu s2 prometheus you just basically remote write data from",
    "start": "938720",
    "end": "945360"
  },
  {
    "text": "both the prometheus to a central cluster and because all the data is in a central place you can query the single",
    "start": "945360",
    "end": "951440"
  },
  {
    "text": "single central cluster and you get all your data that you want one of the examples of the projects that",
    "start": "951440",
    "end": "957279"
  },
  {
    "text": "you can use for this is cortex which i help maintain it's also a cmcf project",
    "start": "957279",
    "end": "962399"
  },
  {
    "text": "you can also use thanos or m3 or several different time series databases out there so this",
    "start": "962399",
    "end": "970560"
  },
  {
    "text": "is about remote right uh i just also want to talk to you about metadata this is extremely useful as you scale your teams",
    "start": "970560",
    "end": "978399"
  },
  {
    "text": "so one of the things that we notice is new people come to the teams they look at dashboards and sometimes it's hard to",
    "start": "978399",
    "end": "983680"
  },
  {
    "text": "understand what a particular prom ql query is doing proncul",
    "start": "983680",
    "end": "989199"
  },
  {
    "text": "itself is simple but if you don't understand what the metric means it's extremely hard to figure out what",
    "start": "989199",
    "end": "994959"
  },
  {
    "text": "the query means and in most cases you will be able to figure out just by looking at the metrics",
    "start": "994959",
    "end": "1000079"
  },
  {
    "text": "for example node cpu seconds total so this you can kind of guess okay this is the cpu usage per node",
    "start": "1000079",
    "end": "1007360"
  },
  {
    "text": "and the reason of behind this like behind the obviousness is because we have an exhaustive and really nice",
    "start": "1007360",
    "end": "1014399"
  },
  {
    "text": "guide on how you should label your metrics and the labels always follow the naming best practices",
    "start": "1014399",
    "end": "1021839"
  },
  {
    "text": "but sometimes when you deploy an exporter it might not follow the",
    "start": "1021839",
    "end": "1026959"
  },
  {
    "text": "best practices or even after following the best practices sometimes the name the metric or the",
    "start": "1026959",
    "end": "1034480"
  },
  {
    "text": "query is not clear for example cube node status capacity you kind of don't understand",
    "start": "1034480",
    "end": "1040319"
  },
  {
    "text": "right away what it is to help with that we actually expose the help and type information for",
    "start": "1040319",
    "end": "1046000"
  },
  {
    "text": "every single metric as part of the exposition format so if you hit the slash metrics page",
    "start": "1046000",
    "end": "1052000"
  },
  {
    "text": "you will already see for example in this case you we can see that",
    "start": "1052000",
    "end": "1057280"
  },
  {
    "text": "go gc duration second is a summary of the past duration of garbage collection cycles",
    "start": "1057280",
    "end": "1062799"
  },
  {
    "text": "go go routines is a number of go routines that currently exists so we already have all of this",
    "start": "1062799",
    "end": "1067840"
  },
  {
    "text": "information that is being exposed by all these all this application so in previous",
    "start": "1067840",
    "end": "1073520"
  },
  {
    "text": "versions prometheus was not able to store all of this data but in the recent version starting 2.17",
    "start": "1073520",
    "end": "1079039"
  },
  {
    "text": "i think we actually store and expose all this metadata uh inside prometheus itself so we have now",
    "start": "1079039",
    "end": "1086480"
  },
  {
    "text": "we now have the metadata api uh where you can query for the metadata of a particular metric",
    "start": "1086480",
    "end": "1093280"
  },
  {
    "text": "next slide here you can see it's slash api slash v1 slash metadata",
    "start": "1093280",
    "end": "1098960"
  },
  {
    "text": "you can specify the limit uh the number of metrics you would like to return uh and also if you want to look at a",
    "start": "1098960",
    "end": "1104480"
  },
  {
    "text": "metadata of a particular metric you just pass in the metric name and it will uh",
    "start": "1104480",
    "end": "1109600"
  },
  {
    "text": "it will give you the metadata for that you can already use this like you don't need to hit this api you it is part of",
    "start": "1109600",
    "end": "1116160"
  },
  {
    "text": "the ui in grafana 7.0 so if you're using rafana 70 or the explore tab or even the",
    "start": "1116160",
    "end": "1121280"
  },
  {
    "text": "dashboards whenever you type in the metric name it kind of helps you figure out what the metric is",
    "start": "1121280",
    "end": "1127120"
  },
  {
    "text": "in this case you can see this cube node status capacity cpu course is a gauge and it's a total cpu course of the node",
    "start": "1127120",
    "end": "1134559"
  },
  {
    "text": "so this is super useful especially for newcomers uh to understand what is happening",
    "start": "1134559",
    "end": "1140080"
  },
  {
    "text": "now just as an aside we are having a new react ui as part of prometheus so if you are",
    "start": "1140080",
    "end": "1145200"
  },
  {
    "start": "1142000",
    "end": "1142000"
  },
  {
    "text": "running prometheus we have a tiny new shiny uh try experimental ui button just click",
    "start": "1145200",
    "end": "1150720"
  },
  {
    "text": "on it and you will be taken to the new react ui uh we're actively developing this ui and",
    "start": "1150720",
    "end": "1156400"
  },
  {
    "text": "the same feature the metadata expansion will be part of this ui as well and we would like to we would like all",
    "start": "1156400",
    "end": "1163919"
  },
  {
    "text": "of you to press this ui if you have bugs uh please file issues and if you're a front-end developer",
    "start": "1163919",
    "end": "1169600"
  },
  {
    "text": "please contribute to all the uh like all the issues around the new ui this is going to be the future ui of prometheus",
    "start": "1169600",
    "end": "1176000"
  },
  {
    "text": "and don't worry about breaking things if something breaks you can basically click on the classic ui and go",
    "start": "1176000",
    "end": "1181200"
  },
  {
    "text": "back to the old ui all right so going to the future of my",
    "start": "1181200",
    "end": "1187120"
  },
  {
    "start": "1184000",
    "end": "1184000"
  },
  {
    "text": "data we are just not done with metadata yet so we currently store metadata in memory",
    "start": "1187120",
    "end": "1192640"
  },
  {
    "text": "but now in the future we want to persist this metadata so over time you will be able to see how the help text and types",
    "start": "1192640",
    "end": "1198640"
  },
  {
    "text": "of each metric evolved we also want to be able to write these metadata",
    "start": "1198640",
    "end": "1203919"
  },
  {
    "text": "write all this material to remote systems like cortex or thanos so that even when you're using the remote system",
    "start": "1203919",
    "end": "1209679"
  },
  {
    "text": "you have the same apis and same data we already have a pr for it uh and there",
    "start": "1209679",
    "end": "1215039"
  },
  {
    "text": "was a lot of discussion around how this pr should be structured a lot of contention but in a recent dev",
    "start": "1215039",
    "end": "1220400"
  },
  {
    "text": "summit that happened a few weeks ago uh we've reached consensus and hopefully you know in the next release or two you",
    "start": "1220400",
    "end": "1226960"
  },
  {
    "text": "will have remote right remote writing of metadata thanks god um so in the same dev summit",
    "start": "1226960",
    "end": "1235280"
  },
  {
    "start": "1233000",
    "end": "1233000"
  },
  {
    "text": "we actually discussed more more items and one of the um further discussion points were",
    "start": "1235280",
    "end": "1241360"
  },
  {
    "text": "backfilling and this is like very wanted feature uh of prometheus",
    "start": "1241360",
    "end": "1246640"
  },
  {
    "text": "so imagine that you know our team and and katie really wants to import the metrics",
    "start": "1246640",
    "end": "1252960"
  },
  {
    "text": "into the prometheus from other systems maybe um she's using you know on some other",
    "start": "1252960",
    "end": "1258799"
  },
  {
    "text": "promoters or some other system she want to migrate the data into her existing instance so how do i do it with",
    "start": "1258799",
    "end": "1265280"
  },
  {
    "text": "prometheus right so it was always available um",
    "start": "1265280",
    "end": "1270640"
  },
  {
    "start": "1267000",
    "end": "1267000"
  },
  {
    "text": "this kind of way of migrating and and and allowing to query your data from the other systems using prometheus",
    "start": "1270640",
    "end": "1278080"
  },
  {
    "text": "it's called remote read so you can configure your pro materials to read from the external system for example influx db so every time you",
    "start": "1278080",
    "end": "1285840"
  },
  {
    "text": "query something it will go to that system but this is not really backfilling right because backfilling means that you",
    "start": "1285840",
    "end": "1292640"
  },
  {
    "text": "want to import of data into your promotion storage directly to persist that and use it for future so",
    "start": "1292640",
    "end": "1300320"
  },
  {
    "text": "how do i do this maybe it would be super amazing if you know um katie could just put and write some",
    "start": "1300320",
    "end": "1306480"
  },
  {
    "text": "csv file which is easy to you know play with and just generate and uh put",
    "start": "1306480",
    "end": "1311840"
  },
  {
    "text": "it imported into the promote storage now well this is or will be possible very very",
    "start": "1311840",
    "end": "1318480"
  },
  {
    "start": "1317000",
    "end": "1317000"
  },
  {
    "text": "soon um so we started like the actual work on adding support uh for importing uh from",
    "start": "1318480",
    "end": "1326559"
  },
  {
    "text": "two file formats csv and open metrics and it will look like this you will",
    "start": "1326559",
    "end": "1332000"
  },
  {
    "start": "1331000",
    "end": "1331000"
  },
  {
    "text": "essentially have an a tool called tsdb import and you just pass the file that will",
    "start": "1332000",
    "end": "1339120"
  },
  {
    "text": "stream the data into the rows let's say into the into this tool which will generate the blocks which is",
    "start": "1339120",
    "end": "1346720"
  },
  {
    "text": "uh you know kind of parsed and understandable by pro materials tsdb database so once you generate such",
    "start": "1346720",
    "end": "1354000"
  },
  {
    "text": "blocks like such such files you can just copy them onto the promoters um",
    "start": "1354000",
    "end": "1359679"
  },
  {
    "text": "working directory and prometheus will immediately reload that and um and allow you to",
    "start": "1359679",
    "end": "1366080"
  },
  {
    "text": "access everything okay now let's try to show you how it can look like once",
    "start": "1366080",
    "end": "1373520"
  },
  {
    "text": "everything is merged and available so let's go to my terminal and let's play",
    "start": "1373520",
    "end": "1379600"
  },
  {
    "text": "with it a little bit so let's imagine we have some data to import and",
    "start": "1379600",
    "end": "1385120"
  },
  {
    "text": "well i don't have any csv file anywhere handy so maybe let's do something quick so i",
    "start": "1385120",
    "end": "1390880"
  },
  {
    "text": "will go to demo robust perception server let's pick some nice interesting metric",
    "start": "1390880",
    "end": "1397520"
  },
  {
    "text": "to import i really like this one hour range of goal routines for all four services so let's let's just",
    "start": "1397520",
    "end": "1404880"
  },
  {
    "text": "grab that um so let's let i just quickly wrote um a very um handy basket which essentially",
    "start": "1404880",
    "end": "1412559"
  },
  {
    "text": "queries that server and generate the csv file from it so let's quickly run that um",
    "start": "1412559",
    "end": "1420559"
  },
  {
    "text": "in the csv file i can specify and different uh fields by headers",
    "start": "1420559",
    "end": "1427440"
  },
  {
    "text": "and essentially let's let's show it and you can see that i kind of defined the",
    "start": "1427440",
    "end": "1432880"
  },
  {
    "text": "type of the field by by the field name and by the head in the header so you know all those libel name little values are",
    "start": "1432880",
    "end": "1439279"
  },
  {
    "text": "defining essentially what part of the csv file field is is for um label values or names",
    "start": "1439279",
    "end": "1445600"
  },
  {
    "text": "or what are the actual um where you put timestamp and where output values and",
    "start": "1445600",
    "end": "1450640"
  },
  {
    "text": "things like that so now we generated like 1000 uh rows of of data so let's install our tsdb",
    "start": "1450640",
    "end": "1458720"
  },
  {
    "text": "tool uh you can install this via one such comment where i just go get and um essentially",
    "start": "1458720",
    "end": "1465039"
  },
  {
    "text": "i'm pulling a certain comment that uh as is essentially part of my pull",
    "start": "1465039",
    "end": "1471120"
  },
  {
    "text": "request so ongoing work but should be available soon once this is installed i can hopefully",
    "start": "1471120",
    "end": "1478159"
  },
  {
    "text": "run tsdb tool to generate my uh my blog",
    "start": "1478159",
    "end": "1486159"
  },
  {
    "text": "this is done let's check our help of such tool you can see the new",
    "start": "1486159",
    "end": "1491840"
  },
  {
    "text": "available commands imports open metrics and import csv",
    "start": "1491840",
    "end": "1497200"
  },
  {
    "text": "let's actually do that right so we will cut our file into the tsdb import tool and output that in some directory this",
    "start": "1497200",
    "end": "1505120"
  },
  {
    "text": "is actually kind of fast because we don't have much data it's only four series and it generated a",
    "start": "1505120",
    "end": "1510799"
  },
  {
    "text": "block of one hour block essentially that um",
    "start": "1510799",
    "end": "1516559"
  },
  {
    "text": "has following id you can see that block is written and have all the necessary uh files um for our tsdb to understand",
    "start": "1516559",
    "end": "1524400"
  },
  {
    "text": "that so let's just let's just run from it use right so i would just create empty configuration",
    "start": "1524400",
    "end": "1529760"
  },
  {
    "text": "doesn't matter we just want to have something that will read the storage and just run the promoters yeah",
    "start": "1529760",
    "end": "1536720"
  },
  {
    "text": "now let's see if our data is available",
    "start": "1536720",
    "end": "1542000"
  },
  {
    "text": "so as you can imagine app is not there because we actually uploaded gogo routines and it",
    "start": "1542000",
    "end": "1547360"
  },
  {
    "text": "is available so when we execute for our needed time range we will see the data",
    "start": "1547360",
    "end": "1555840"
  },
  {
    "text": "available for us and you can see and that this data is exactly the same as on our robust",
    "start": "1555840",
    "end": "1562240"
  },
  {
    "text": "perception server but actually robust perception server has more of it versus you know our server has only",
    "start": "1562240",
    "end": "1569200"
  },
  {
    "text": "imported only a bit of it",
    "start": "1569200",
    "end": "1573679"
  },
  {
    "text": "so that's a demo and this is the future so it's super exciting to",
    "start": "1574240",
    "end": "1579360"
  },
  {
    "text": "explore and extend that idea further that was great um to summarize",
    "start": "1579360",
    "end": "1587600"
  },
  {
    "start": "1584000",
    "end": "1584000"
  },
  {
    "text": "we've initially talked about how to do global view how to aggregate data between several different",
    "start": "1587600",
    "end": "1592720"
  },
  {
    "text": "prometheuses the different ways you can use to do that and then we've talked about remote right",
    "start": "1592720",
    "end": "1598080"
  },
  {
    "text": "and long-term storage how you can use just prometheus what the caveats are how you can use remote right",
    "start": "1598080",
    "end": "1603919"
  },
  {
    "text": "to write to a different server and how you can you do global view through remote right",
    "start": "1603919",
    "end": "1609279"
  },
  {
    "text": "we've talked about metadata one of the new features uh that i'm super excited about um",
    "start": "1609279",
    "end": "1614640"
  },
  {
    "text": "and finally we've also talked about backfilling and the future features that",
    "start": "1614640",
    "end": "1619919"
  },
  {
    "text": "are coming into backfilling so this is something i'm super excited about again because it will help people migrate from",
    "start": "1619919",
    "end": "1625600"
  },
  {
    "text": "older systems to prometheus with all their data all right that's it uh if you have any",
    "start": "1625600",
    "end": "1632559"
  },
  {
    "text": "questions uh feel free to ask them now or you can reach us via prometheus community or on",
    "start": "1632559",
    "end": "1638399"
  },
  {
    "text": "github thank you",
    "start": "1638399",
    "end": "1641919"
  },
  {
    "text": "okay thank you guys thank you for sharing and it's online qra session",
    "start": "1660799",
    "end": "1667120"
  },
  {
    "text": "and",
    "start": "1667120",
    "end": "1669840"
  },
  {
    "text": "instagram your review and microphone okay hi hello",
    "start": "1674320",
    "end": "1682640"
  },
  {
    "text": "okay i see some questions for you guys in the chat box",
    "start": "1688320",
    "end": "1697760"
  },
  {
    "text": "yes so we've seen those questions as well i think i can take the first one",
    "start": "1697760",
    "end": "1703039"
  },
  {
    "text": "so the first question is from rick what do you think to have scalability feature addressed",
    "start": "1703039",
    "end": "1708960"
  },
  {
    "text": "within project from promute use itself um instead of you know having sub projects like merger cortex and tunnels",
    "start": "1708960",
    "end": "1715840"
  },
  {
    "text": "and so on i think it's a great a great idea and a great great question and there is a reason for that",
    "start": "1715840",
    "end": "1722080"
  },
  {
    "text": "why you know spanish and cortex and elements of the system that did not",
    "start": "1722080",
    "end": "1727360"
  },
  {
    "text": "start in the prometheus itself and the main kind of reason behind that is that we want to as a prompteus maintainers we want to",
    "start": "1727360",
    "end": "1734240"
  },
  {
    "text": "make sure that the project is focused and as you can imagine if you focus on few",
    "start": "1734240",
    "end": "1739760"
  },
  {
    "text": "functionalities versus everything to solve every problem you will you you will end up with",
    "start": "1739760",
    "end": "1744960"
  },
  {
    "text": "more solid and concise product that actually will excellent will excel on those elements",
    "start": "1744960",
    "end": "1751039"
  },
  {
    "text": "that matters so pick only a few goals and this will kind of reduce the risk of failure",
    "start": "1751039",
    "end": "1757279"
  },
  {
    "text": "um so this is what we did with probably to use we focus on scrape scraping metal methodologies so make",
    "start": "1757279",
    "end": "1763120"
  },
  {
    "text": "sure there is very consistent you know scraping mechanism very reliable we focus on the single node time series",
    "start": "1763120",
    "end": "1770399"
  },
  {
    "text": "database which is very very fast to ingest and query data from uh we",
    "start": "1770399",
    "end": "1775760"
  },
  {
    "text": "invested our time in alerting in prom ql language and and then we invent and kind of focus",
    "start": "1775760",
    "end": "1782240"
  },
  {
    "text": "on extensible apis to make sure you can extend that system with um with with kind of further stories and",
    "start": "1782240",
    "end": "1788799"
  },
  {
    "text": "this is how we created tunnels and cortex on the way that we integrated to fulfill those goals that prompted us",
    "start": "1788799",
    "end": "1795440"
  },
  {
    "text": "did not address and that's totally okay because those projects are not competing with with each other um supreme use it's",
    "start": "1795440",
    "end": "1802720"
  },
  {
    "text": "not competing with tunnels and cortex in fact we are collaborating and and we are extensions of each other",
    "start": "1802720",
    "end": "1808000"
  },
  {
    "text": "let's say um so yeah this is why chrome to use probably will never kind of address kind",
    "start": "1808000",
    "end": "1814320"
  },
  {
    "text": "of you know those scalability issues that tunnels and and and cortez cortex allows uh when you add that to",
    "start": "1814320",
    "end": "1821840"
  },
  {
    "text": "promote use however it might be a single you know organizations and we can kind of",
    "start": "1821840",
    "end": "1827120"
  },
  {
    "text": "maybe organize it a little bit better but from the binary perspective from the project focus i think this is a good",
    "start": "1827120",
    "end": "1832640"
  },
  {
    "text": "idea so far thank you do you want to address a",
    "start": "1832640",
    "end": "1839520"
  },
  {
    "text": "second question so there's the second question which is uh cortex",
    "start": "1839520",
    "end": "1844559"
  },
  {
    "text": "or thanos seem to be more suitable for end user consumption what do you think so the idea around prometheus is you",
    "start": "1844559",
    "end": "1851760"
  },
  {
    "text": "should not rely like it's not a distributed system it's a single node system that has everything and it focuses on a subset of",
    "start": "1851760",
    "end": "1858640"
  },
  {
    "text": "the features that as martech said and one thing is it's not a distributed system so it's very",
    "start": "1858640",
    "end": "1864320"
  },
  {
    "text": "robust and even when your data center is under fire you can go to your prometheus and query",
    "start": "1864320",
    "end": "1870320"
  },
  {
    "text": "it and it's super stable that way and even when you use cortex or thanos",
    "start": "1870320",
    "end": "1875600"
  },
  {
    "text": "you still need prometheus to do the scraping and collection of matrix and then you send these metrics to",
    "start": "1875600",
    "end": "1881039"
  },
  {
    "text": "cortex or thanos for long term studies so even if you run cortex or thanos you",
    "start": "1881039",
    "end": "1886240"
  },
  {
    "text": "still need prometheus and for most organizations as you start out you like you can do a lot with just",
    "start": "1886240",
    "end": "1893519"
  },
  {
    "text": "prometheus and only once you reach a certain scale once you go beyond few data centers",
    "start": "1893519",
    "end": "1898640"
  },
  {
    "text": "that's when cortex and thanos come into picture so always start with prometheus and then",
    "start": "1898640",
    "end": "1903760"
  },
  {
    "text": "extend it okay any further questions",
    "start": "1903760",
    "end": "1910480"
  },
  {
    "text": "thank you gotham we have another question um one yeah operator development plan",
    "start": "1910480",
    "end": "1917440"
  },
  {
    "text": "um so that's good question so actually i was just yesterday was preparing some",
    "start": "1917440",
    "end": "1923360"
  },
  {
    "text": "tutorials for prometheus operator because premature computer operators supports",
    "start": "1923360",
    "end": "1928720"
  },
  {
    "text": "uh stateful parts of thanos let's say um so you can enable prometheus operator to",
    "start": "1928720",
    "end": "1934080"
  },
  {
    "text": "schedule or like to you know you can define promote users but people you can also define tunnels rulers and you can add",
    "start": "1934080",
    "end": "1941120"
  },
  {
    "text": "uh by single switch um sidecar to the promoters as well so in some",
    "start": "1941120",
    "end": "1946240"
  },
  {
    "text": "some way um from two separators supports tunnels then uh there are like two other",
    "start": "1946240",
    "end": "1952640"
  },
  {
    "text": "operators that um focus on the full kind of tunnel support so definitely there is work on that you can check the banzai cloud",
    "start": "1952640",
    "end": "1958799"
  },
  {
    "text": "thunder separator i think that's that's one thing um however i would recommend and this is my",
    "start": "1958799",
    "end": "1966000"
  },
  {
    "text": "personal suggestion to use operators with care and use them only for stateful services",
    "start": "1966000",
    "end": "1971840"
  },
  {
    "text": "and stateful resources on kubernetes because that's where operators are extremely useful um so and and",
    "start": "1971840",
    "end": "1979200"
  },
  {
    "text": "other tennis components are just stateless um but yeah there are some options there in this",
    "start": "1979200",
    "end": "1984799"
  },
  {
    "text": "field okay um please please ask more questions",
    "start": "1984799",
    "end": "1990480"
  },
  {
    "text": "i would love to have your feedback on the backfilling um feature do you like that um please give",
    "start": "1990480",
    "end": "1995919"
  },
  {
    "text": "us some feedback as well in comments and uh yeah on furthering the project issues as well",
    "start": "1995919",
    "end": "2001600"
  },
  {
    "text": "okay thank you thank you is there any other questions would i have these",
    "start": "2001600",
    "end": "2008720"
  },
  {
    "text": "okay i think it's no more questions for two guys and thank you so much thank you bye-bye have",
    "start": "2011600",
    "end": "2017360"
  },
  {
    "text": "a nice day bye bye",
    "start": "2017360",
    "end": "2022399"
  }
]
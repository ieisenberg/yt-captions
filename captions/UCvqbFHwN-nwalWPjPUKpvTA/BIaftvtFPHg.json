[
  {
    "text": "and now I have the pleasure to to",
    "start": "280",
    "end": "2919"
  },
  {
    "text": "welcome Bradon Kes from Google Cloud",
    "start": "2919",
    "end": "5480"
  },
  {
    "text": "who's going to talk to us about how much",
    "start": "5480",
    "end": "8000"
  },
  {
    "text": "overhead how to evaluate your",
    "start": "8000",
    "end": "10200"
  },
  {
    "text": "observability agent performance which is",
    "start": "10200",
    "end": "13040"
  },
  {
    "text": "a really interesting topic so give it",
    "start": "13040",
    "end": "14599"
  },
  {
    "text": "Applause to to Bron",
    "start": "14599",
    "end": "16720"
  },
  {
    "text": "for to get",
    "start": "16720",
    "end": "20119"
  },
  {
    "text": "started all right is it on oh yeah there",
    "start": "21000",
    "end": "23199"
  },
  {
    "text": "it is all right cool uh so hi my name is",
    "start": "23199",
    "end": "25880"
  },
  {
    "text": "Braden and I'm going to be talking I",
    "start": "25880",
    "end": "27359"
  },
  {
    "text": "worded it differently on this slide",
    "start": "27359",
    "end": "28599"
  },
  {
    "text": "maybe I should have checked before I",
    "start": "28599",
    "end": "29599"
  },
  {
    "text": "wrote that",
    "start": "29599",
    "end": "30519"
  },
  {
    "text": "um but I'm here to present the most",
    "start": "30519",
    "end": "32078"
  },
  {
    "text": "boring looking slides you've ever seen",
    "start": "32079",
    "end": "33719"
  },
  {
    "text": "everybody had way cooler slides than me",
    "start": "33719",
    "end": "35760"
  },
  {
    "text": "uh observability agents are one of the",
    "start": "35760",
    "end": "37800"
  },
  {
    "text": "most important parts of our oh shoot",
    "start": "37800",
    "end": "40000"
  },
  {
    "text": "it's not changing there we go here we go",
    "start": "40000",
    "end": "42360"
  },
  {
    "text": "there we go uh observability agents are",
    "start": "42360",
    "end": "44239"
  },
  {
    "text": "quickly becoming one of the most",
    "start": "44239",
    "end": "45239"
  },
  {
    "text": "important parts of most modern",
    "start": "45239",
    "end": "47280"
  },
  {
    "text": "infrastructure uh especially in",
    "start": "47280",
    "end": "48960"
  },
  {
    "text": "scenarios where uh you can't go change",
    "start": "48960",
    "end": "51559"
  },
  {
    "text": "an application and add a bunch of",
    "start": "51559",
    "end": "52719"
  },
  {
    "text": "instrumentation to get metrics or you",
    "start": "52719",
    "end": "54399"
  },
  {
    "text": "just need to get the system metrics uh",
    "start": "54399",
    "end": "57480"
  },
  {
    "text": "that's running alongside this uh running",
    "start": "57480",
    "end": "59199"
  },
  {
    "text": "alongside your applic ation uh when",
    "start": "59199",
    "end": "61160"
  },
  {
    "text": "you're installing a new piece of",
    "start": "61160",
    "end": "62680"
  },
  {
    "text": "critical infrastructure on your VMS or",
    "start": "62680",
    "end": "64439"
  },
  {
    "text": "on your in your clusters one of the",
    "start": "64439",
    "end": "66520"
  },
  {
    "text": "first big questions is what's the",
    "start": "66520",
    "end": "68479"
  },
  {
    "text": "overhead what's the effect uh that this",
    "start": "68479",
    "end": "71080"
  },
  {
    "text": "is going to have by installing it on my",
    "start": "71080",
    "end": "72880"
  },
  {
    "text": "system uh unfortunately as important as",
    "start": "72880",
    "end": "75799"
  },
  {
    "text": "a question as this is uh there isn't",
    "start": "75799",
    "end": "78119"
  },
  {
    "text": "really a straight answer um",
    "start": "78119",
    "end": "80720"
  },
  {
    "text": "observability agents are I yeah I love",
    "start": "80720",
    "end": "83320"
  },
  {
    "text": "this picture uh observability agents are",
    "start": "83320",
    "end": "85280"
  },
  {
    "text": "by Design uh an orchestration of ENT",
    "start": "85280",
    "end": "90119"
  },
  {
    "text": "tiny little programs that you can put",
    "start": "90119",
    "end": "91560"
  },
  {
    "text": "together to do any combination of things",
    "start": "91560",
    "end": "93159"
  },
  {
    "text": "that you want which means that asking",
    "start": "93159",
    "end": "94960"
  },
  {
    "text": "what the overhead is uh you're not going",
    "start": "94960",
    "end": "97240"
  },
  {
    "text": "to get an authoritative answer but in",
    "start": "97240",
    "end": "98920"
  },
  {
    "text": "this talk I'm going to try and explain",
    "start": "98920",
    "end": "100840"
  },
  {
    "text": "ways that we can rephrase the question",
    "start": "100840",
    "end": "102600"
  },
  {
    "text": "to get more valuable information first",
    "start": "102600",
    "end": "104960"
  },
  {
    "text": "I'll explain who I am uh my name is",
    "start": "104960",
    "end": "106439"
  },
  {
    "text": "Braden KES I'm a software developer at",
    "start": "106439",
    "end": "108240"
  },
  {
    "text": "Google Cloud uh the team I'm on is",
    "start": "108240",
    "end": "110200"
  },
  {
    "text": "called collection Services we're focused",
    "start": "110200",
    "end": "112159"
  },
  {
    "text": "on uh making the Telemetry collection",
    "start": "112159",
    "end": "114680"
  },
  {
    "text": "experiences uh the best they can be and",
    "start": "114680",
    "end": "117000"
  },
  {
    "text": "the best way for us to do that is to",
    "start": "117000",
    "end": "118240"
  },
  {
    "text": "work in the open so I'm having involved",
    "start": "118240",
    "end": "120320"
  },
  {
    "text": "in the fluent bit and open Telemetry",
    "start": "120320",
    "end": "122119"
  },
  {
    "text": "projects to try and uh make it better",
    "start": "122119",
    "end": "123920"
  },
  {
    "text": "for everyone uh and I'm also the Creator",
    "start": "123920",
    "end": "126439"
  },
  {
    "text": "and maintainer of a tool called the amlm",
    "start": "126439",
    "end": "128080"
  },
  {
    "text": "so if you want to come yell at me about",
    "start": "128080",
    "end": "129560"
  },
  {
    "text": "how it doesn't work on Helm charts or",
    "start": "129560",
    "end": "131120"
  },
  {
    "text": "something you can come find me",
    "start": "131120",
    "end": "133640"
  },
  {
    "text": "after if you're a Linux user you're",
    "start": "133640",
    "end": "135680"
  },
  {
    "text": "probably going to be familiar with a",
    "start": "135680",
    "end": "137319"
  },
  {
    "text": "command like this uh Linux lets you uh",
    "start": "137319",
    "end": "140680"
  },
  {
    "text": "or the Unix philosophy is for is Tiny",
    "start": "140680",
    "end": "143840"
  },
  {
    "text": "programs that do one thing and do them",
    "start": "143840",
    "end": "145319"
  },
  {
    "text": "well and they work by stringing them",
    "start": "145319",
    "end": "147519"
  },
  {
    "text": "together to get new use cases that you",
    "start": "147519",
    "end": "149640"
  },
  {
    "text": "could have imagined on their own uh in",
    "start": "149640",
    "end": "152040"
  },
  {
    "text": "this example I have a command where I",
    "start": "152040",
    "end": "154040"
  },
  {
    "text": "grab some information about a process",
    "start": "154040",
    "end": "155480"
  },
  {
    "text": "from the system I grab some sort of",
    "start": "155480",
    "end": "158000"
  },
  {
    "text": "information out of it by I filter out",
    "start": "158000",
    "end": "159760"
  },
  {
    "text": "the information I don't want and then I",
    "start": "159760",
    "end": "161840"
  },
  {
    "text": "do a transformation to get some sort of",
    "start": "161840",
    "end": "163599"
  },
  {
    "text": "useful output now if you're familiar",
    "start": "163599",
    "end": "165680"
  },
  {
    "text": "with observability agents you'll",
    "start": "165680",
    "end": "167680"
  },
  {
    "text": "probably recognize this pattern as the",
    "start": "167680",
    "end": "169480"
  },
  {
    "text": "same sort of uh same sort of pipelines",
    "start": "169480",
    "end": "172080"
  },
  {
    "text": "that you're creating in your agent",
    "start": "172080",
    "end": "174080"
  },
  {
    "text": "configurations uh observability agents",
    "start": "174080",
    "end": "176720"
  },
  {
    "text": "are generally the same pattern of you",
    "start": "176720",
    "end": "179280"
  },
  {
    "text": "either you ingest the data either",
    "start": "179280",
    "end": "180720"
  },
  {
    "text": "through pull-based or push-based",
    "start": "180720",
    "end": "182760"
  },
  {
    "text": "ingestion you process that data to",
    "start": "182760",
    "end": "185040"
  },
  {
    "text": "transform it into something more useful",
    "start": "185040",
    "end": "187400"
  },
  {
    "text": "uh and then there's a stage where you",
    "start": "187400",
    "end": "188720"
  },
  {
    "text": "can export it to different backends and",
    "start": "188720",
    "end": "190840"
  },
  {
    "text": "there might be some work to translate it",
    "start": "190840",
    "end": "192480"
  },
  {
    "text": "to different protocols to send it to uh",
    "start": "192480",
    "end": "194959"
  },
  {
    "text": "a compliant backend or you're sending it",
    "start": "194959",
    "end": "196760"
  },
  {
    "text": "to some very specific bespoke CL major",
    "start": "196760",
    "end": "199040"
  },
  {
    "text": "cloud provider or something like",
    "start": "199040",
    "end": "201280"
  },
  {
    "text": "Prometheus unfortunately observability",
    "start": "201280",
    "end": "203840"
  },
  {
    "text": "agents don't look like the last slide",
    "start": "203840",
    "end": "206120"
  },
  {
    "text": "when they're configured for production",
    "start": "206120",
    "end": "207440"
  },
  {
    "text": "they look more like this you can",
    "start": "207440",
    "end": "209080"
  },
  {
    "text": "configure your agent to have any number",
    "start": "209080",
    "end": "210840"
  },
  {
    "text": "of different pipelines and those",
    "start": "210840",
    "end": "212040"
  },
  {
    "text": "pipelines could have varying amounts of",
    "start": "212040",
    "end": "214159"
  },
  {
    "text": "complexity uh and that's why asking what",
    "start": "214159",
    "end": "217480"
  },
  {
    "text": "is the overhead is not always going to",
    "start": "217480",
    "end": "219159"
  },
  {
    "text": "be such an easy answer if you don't know",
    "start": "219159",
    "end": "221080"
  },
  {
    "text": "what you're going to be doing with it so",
    "start": "221080",
    "end": "222799"
  },
  {
    "text": "I'm going to try and rephrase the one",
    "start": "222799",
    "end": "224680"
  },
  {
    "text": "question what's the overhead into three",
    "start": "224680",
    "end": "227080"
  },
  {
    "text": "different questions uh where is my",
    "start": "227080",
    "end": "229280"
  },
  {
    "text": "overhead coming from what can I do to",
    "start": "229280",
    "end": "231959"
  },
  {
    "text": "try and improve it uh and how do I try",
    "start": "231959",
    "end": "234640"
  },
  {
    "text": "to evaluate it for",
    "start": "234640",
    "end": "236360"
  },
  {
    "text": "myself to do this um for first I have to",
    "start": "236360",
    "end": "240079"
  },
  {
    "text": "uh Define what I'm calling overhead and",
    "start": "240079",
    "end": "242439"
  },
  {
    "text": "how I'm thinking about it in this talk",
    "start": "242439",
    "end": "244439"
  },
  {
    "text": "um it's generally a combination of",
    "start": "244439",
    "end": "246439"
  },
  {
    "text": "resource usage measured against",
    "start": "246439",
    "end": "248720"
  },
  {
    "text": "throughput so resource uses being memory",
    "start": "248720",
    "end": "251560"
  },
  {
    "text": "um I mentioned resident set size here I",
    "start": "251560",
    "end": "253640"
  },
  {
    "text": "was the one who raised my hand and said",
    "start": "253640",
    "end": "254879"
  },
  {
    "text": "that last time and I got egg on my face",
    "start": "254879",
    "end": "256639"
  },
  {
    "text": "but I think for for that for that",
    "start": "256639",
    "end": "258720"
  },
  {
    "text": "scenario it made sense for this scenario",
    "start": "258720",
    "end": "260519"
  },
  {
    "text": "I think resident set size makes sense",
    "start": "260519",
    "end": "261919"
  },
  {
    "text": "which is resident set size is the amount",
    "start": "261919",
    "end": "263440"
  },
  {
    "text": "of memory that the process is actually",
    "start": "263440",
    "end": "265199"
  },
  {
    "text": "taking up in the system which for an",
    "start": "265199",
    "end": "267080"
  },
  {
    "text": "overhead snapshot might be more useful",
    "start": "267080",
    "end": "269199"
  },
  {
    "text": "uh but what Brian said is true there's",
    "start": "269199",
    "end": "270800"
  },
  {
    "text": "no one memory metric to rule them all um",
    "start": "270800",
    "end": "273600"
  },
  {
    "text": "CPU usage is a little bit easier because",
    "start": "273600",
    "end": "275440"
  },
  {
    "text": "you can measure the CPU time of the",
    "start": "275440",
    "end": "277800"
  },
  {
    "text": "process and that's a little bit easier",
    "start": "277800",
    "end": "279199"
  },
  {
    "text": "to to get a more solid answer on uh dis",
    "start": "279199",
    "end": "283560"
  },
  {
    "text": "usage is important especially if you are",
    "start": "283560",
    "end": "285479"
  },
  {
    "text": "configuring your agent which is",
    "start": "285479",
    "end": "287199"
  },
  {
    "text": "something I recommend to do is",
    "start": "287199",
    "end": "288240"
  },
  {
    "text": "configuring your agent to buffer data on",
    "start": "288240",
    "end": "290560"
  },
  {
    "text": "disk so that you don't lose it in tragic",
    "start": "290560",
    "end": "292680"
  },
  {
    "text": "scenarios like Network outages um and",
    "start": "292680",
    "end": "295720"
  },
  {
    "text": "all of these things will be measured",
    "start": "295720",
    "end": "296880"
  },
  {
    "text": "against throughput which depending on",
    "start": "296880",
    "end": "298280"
  },
  {
    "text": "the type of signal it might make more",
    "start": "298280",
    "end": "299720"
  },
  {
    "text": "sense to talk about data point count or",
    "start": "299720",
    "end": "301960"
  },
  {
    "text": "it might make more sense to talk about",
    "start": "301960",
    "end": "304280"
  },
  {
    "text": "uh bytes per second",
    "start": "304280",
    "end": "306680"
  },
  {
    "text": "count I'm going to start going through",
    "start": "306680",
    "end": "308759"
  },
  {
    "text": "each stage of the pipeline I'm going to",
    "start": "308759",
    "end": "310400"
  },
  {
    "text": "talk about my experience in finding some",
    "start": "310400",
    "end": "313160"
  },
  {
    "text": "performance potential Performance",
    "start": "313160",
    "end": "314360"
  },
  {
    "text": "challenges or potential",
    "start": "314360",
    "end": "315199"
  },
  {
    "text": "misconfigurations in each one and we're",
    "start": "315199",
    "end": "317080"
  },
  {
    "text": "going to start with uh pull base",
    "start": "317080",
    "end": "318720"
  },
  {
    "text": "ingestion pull base ingestion is the is",
    "start": "318720",
    "end": "321440"
  },
  {
    "text": "the mechanism of going out somewhere",
    "start": "321440",
    "end": "324800"
  },
  {
    "text": "getting data on an interval so most",
    "start": "324800",
    "end": "327919"
  },
  {
    "text": "people will be familiar with things like",
    "start": "327919",
    "end": "329240"
  },
  {
    "text": "PR promethus scrapes where you're",
    "start": "329240",
    "end": "330840"
  },
  {
    "text": "scraping a Prometheus endpoint to get",
    "start": "330840",
    "end": "332479"
  },
  {
    "text": "text metrics um another common one is uh",
    "start": "332479",
    "end": "335680"
  },
  {
    "text": "open cemetry collector has host metrics",
    "start": "335680",
    "end": "337360"
  },
  {
    "text": "and it'll scrape slpr to get information",
    "start": "337360",
    "end": "339720"
  },
  {
    "text": "about either all processes or you can",
    "start": "339720",
    "end": "341240"
  },
  {
    "text": "ask it for a specific process or you",
    "start": "341240",
    "end": "343240"
  },
  {
    "text": "might be familiar with some thirdparty",
    "start": "343240",
    "end": "344520"
  },
  {
    "text": "application receivers in otel contrib",
    "start": "344520",
    "end": "346520"
  },
  {
    "text": "like Apache which will query the uh",
    "start": "346520",
    "end": "349560"
  },
  {
    "text": "server's server status",
    "start": "349560",
    "end": "351759"
  },
  {
    "text": "URL some of the challenges with",
    "start": "351759",
    "end": "353720"
  },
  {
    "text": "pole-based I think the the nice thing",
    "start": "353720",
    "end": "355800"
  },
  {
    "text": "about pull-based ingestion is that it's",
    "start": "355800",
    "end": "357400"
  },
  {
    "text": "under most circumstances a very",
    "start": "357400",
    "end": "358840"
  },
  {
    "text": "predictable size workload uh and it's",
    "start": "358840",
    "end": "362039"
  },
  {
    "text": "happening on an interval so really the",
    "start": "362039",
    "end": "363639"
  },
  {
    "text": "biggest problem with perform measuring",
    "start": "363639",
    "end": "366039"
  },
  {
    "text": "the performance is just how much data",
    "start": "366039",
    "end": "367240"
  },
  {
    "text": "you're actually going to be working with",
    "start": "367240",
    "end": "370360"
  },
  {
    "text": "uh my favorite example of this is with",
    "start": "370360",
    "end": "371880"
  },
  {
    "text": "Prometheus scrape specifically uh the",
    "start": "371880",
    "end": "374440"
  },
  {
    "text": "scraping library has a limitation where",
    "start": "374440",
    "end": "376720"
  },
  {
    "text": "because of the way the Prometheus",
    "start": "376720",
    "end": "378199"
  },
  {
    "text": "metrics format works you kind of need to",
    "start": "378199",
    "end": "380520"
  },
  {
    "text": "have the entire buffer ready to properly",
    "start": "380520",
    "end": "383199"
  },
  {
    "text": "parse all the metrics out of it and that",
    "start": "383199",
    "end": "385360"
  },
  {
    "text": "requires the Prometheus library to make",
    "start": "385360",
    "end": "386880"
  },
  {
    "text": "an entire copy of the scrape in memory",
    "start": "386880",
    "end": "390440"
  },
  {
    "text": "uh we've had scenarios where we've",
    "start": "390440",
    "end": "392039"
  },
  {
    "text": "helped customers with Prometheus setups",
    "start": "392039",
    "end": "393720"
  },
  {
    "text": "where they have like 160,000 metrics or",
    "start": "393720",
    "end": "396639"
  },
  {
    "text": "something like that and it takes the",
    "start": "396639",
    "end": "398039"
  },
  {
    "text": "agent takes gigabytes of memory to try",
    "start": "398039",
    "end": "399680"
  },
  {
    "text": "and process that especially if you're on",
    "start": "399680",
    "end": "401720"
  },
  {
    "text": "too short of a scraping interval if",
    "start": "401720",
    "end": "403520"
  },
  {
    "text": "you're scraping too quickly and you're",
    "start": "403520",
    "end": "405039"
  },
  {
    "text": "scraping lots of data and especially if",
    "start": "405039",
    "end": "406759"
  },
  {
    "text": "you're not using things like scrape",
    "start": "406759",
    "end": "408000"
  },
  {
    "text": "timeouts to control that you're going to",
    "start": "408000",
    "end": "410280"
  },
  {
    "text": "overrun your agent while it tries to uh",
    "start": "410280",
    "end": "413160"
  },
  {
    "text": "while it tries to finish the last scrape",
    "start": "413160",
    "end": "415199"
  },
  {
    "text": "then there's a new one tries to finish",
    "start": "415199",
    "end": "416720"
  },
  {
    "text": "this scrape then there's a new one you",
    "start": "416720",
    "end": "417840"
  },
  {
    "text": "can really get yourself into a bad",
    "start": "417840",
    "end": "419080"
  },
  {
    "text": "scenario with that um the scraping",
    "start": "419080",
    "end": "422000"
  },
  {
    "text": "implementation is something that users",
    "start": "422000",
    "end": "423440"
  },
  {
    "text": "don't always have a good uh a good",
    "start": "423440",
    "end": "426759"
  },
  {
    "text": "control over but there are examples of",
    "start": "426759",
    "end": "429199"
  },
  {
    "text": "scrapers that aren't necessarily",
    "start": "429199",
    "end": "431280"
  },
  {
    "text": "implemented as efficiently as they could",
    "start": "431280",
    "end": "433400"
  },
  {
    "text": "be um I'm quite familiar with open",
    "start": "433400",
    "end": "435599"
  },
  {
    "text": "telemetry's host metrics process scraper",
    "start": "435599",
    "end": "438319"
  },
  {
    "text": "uh which is not not very efficient when",
    "start": "438319",
    "end": "441960"
  },
  {
    "text": "it processes these metrics because of",
    "start": "441960",
    "end": "443440"
  },
  {
    "text": "the underlying library that it use uses",
    "start": "443440",
    "end": "445599"
  },
  {
    "text": "being targeted for single process and",
    "start": "445599",
    "end": "447879"
  },
  {
    "text": "when you try to do that same thing over",
    "start": "447879",
    "end": "449520"
  },
  {
    "text": "and over again you're go doing a lot",
    "start": "449520",
    "end": "451400"
  },
  {
    "text": "more work than you technically need to",
    "start": "451400",
    "end": "453879"
  },
  {
    "text": "and this is something that users don't",
    "start": "453879",
    "end": "455280"
  },
  {
    "text": "really have control over unless you know",
    "start": "455280",
    "end": "456800"
  },
  {
    "text": "how to want to contribute something that",
    "start": "456800",
    "end": "458800"
  },
  {
    "text": "is is better than what's there U but",
    "start": "458800",
    "end": "461360"
  },
  {
    "text": "it's something worth keeping an eye on",
    "start": "461360",
    "end": "463599"
  },
  {
    "text": "push based ingestion is the oppositive",
    "start": "463599",
    "end": "465520"
  },
  {
    "text": "pull based where instead of going and",
    "start": "465520",
    "end": "467560"
  },
  {
    "text": "fetching data from somewhere on an",
    "start": "467560",
    "end": "468680"
  },
  {
    "text": "interval you're just opening yourself up",
    "start": "468680",
    "end": "470560"
  },
  {
    "text": "to the world to receive data um I put I",
    "start": "470560",
    "end": "474199"
  },
  {
    "text": "put file here if you're familiar with",
    "start": "474199",
    "end": "475479"
  },
  {
    "text": "like the implementation files it's kind",
    "start": "475479",
    "end": "476960"
  },
  {
    "text": "of more pull based but anyways um",
    "start": "476960",
    "end": "479440"
  },
  {
    "text": "considering it in push base you be you",
    "start": "479440",
    "end": "480919"
  },
  {
    "text": "could be writing logs to a file or you",
    "start": "480919",
    "end": "483319"
  },
  {
    "text": "could be opening yourself up for",
    "start": "483319",
    "end": "484840"
  },
  {
    "text": "something like Prometheus remote write",
    "start": "484840",
    "end": "486599"
  },
  {
    "text": "or uh Jagger open cemetry on your",
    "start": "486599",
    "end": "489599"
  },
  {
    "text": "agent um the big challenge with",
    "start": "489599",
    "end": "492960"
  },
  {
    "text": "push-based data is unlike pull-based is",
    "start": "492960",
    "end": "495479"
  },
  {
    "text": "not a very predictable workload you need",
    "start": "495479",
    "end": "498240"
  },
  {
    "text": "to have a lot more uh what's intimate",
    "start": "498240",
    "end": "503120"
  },
  {
    "text": "knowledge I guess of like what you can",
    "start": "503120",
    "end": "504840"
  },
  {
    "text": "expect to push into this but there's",
    "start": "504840",
    "end": "507479"
  },
  {
    "text": "nothing stopping you from writing way",
    "start": "507479",
    "end": "510639"
  },
  {
    "text": "more logs in one second and then like",
    "start": "510639",
    "end": "512518"
  },
  {
    "text": "nothing for 10 minutes like those sorts",
    "start": "512519",
    "end": "514039"
  },
  {
    "text": "of bursts of data can very easily",
    "start": "514039",
    "end": "516200"
  },
  {
    "text": "overwhelm the pipeline if you're not",
    "start": "516200",
    "end": "518080"
  },
  {
    "text": "ready for them and something I'm going",
    "start": "518080",
    "end": "519599"
  },
  {
    "text": "to be talking about later is uh back",
    "start": "519599",
    "end": "521680"
  },
  {
    "text": "pressure and batching and how to deal",
    "start": "521680",
    "end": "523560"
  },
  {
    "text": "with uh when you potentially are",
    "start": "523560",
    "end": "525440"
  },
  {
    "text": "bursting data and if you're configured",
    "start": "525440",
    "end": "527720"
  },
  {
    "text": "for file system you can overrun your",
    "start": "527720",
    "end": "529160"
  },
  {
    "text": "disc really quickly or if you're not",
    "start": "529160",
    "end": "531760"
  },
  {
    "text": "limiting your memory you can overrun",
    "start": "531760",
    "end": "533399"
  },
  {
    "text": "your memory really quickly if you're not",
    "start": "533399",
    "end": "534760"
  },
  {
    "text": "ready for these sorts of bursts of data",
    "start": "534760",
    "end": "538200"
  },
  {
    "text": "um",
    "start": "538200",
    "end": "539880"
  },
  {
    "text": "oh yes um most agents have kind of",
    "start": "539880",
    "end": "542560"
  },
  {
    "text": "worked around this by now but I decided",
    "start": "542560",
    "end": "543959"
  },
  {
    "text": "to put it in here anyway especially if",
    "start": "543959",
    "end": "545160"
  },
  {
    "text": "you're someone who's running like an old",
    "start": "545160",
    "end": "546240"
  },
  {
    "text": "version of fluent bit or something uh",
    "start": "546240",
    "end": "548040"
  },
  {
    "text": "there can be issues where if you're",
    "start": "548040",
    "end": "549880"
  },
  {
    "text": "tailing a bunch of files for example but",
    "start": "549880",
    "end": "552560"
  },
  {
    "text": "one file is way busier than the rest of",
    "start": "552560",
    "end": "554680"
  },
  {
    "text": "them uh there used to be issues where",
    "start": "554680",
    "end": "557839"
  },
  {
    "text": "the main process would be starved",
    "start": "557839",
    "end": "560240"
  },
  {
    "text": "because it's so busy processing the one",
    "start": "560240",
    "end": "561839"
  },
  {
    "text": "busy file and it keeps on accidentally",
    "start": "561839",
    "end": "563600"
  },
  {
    "text": "prioritizing it I haven't looked into",
    "start": "563600",
    "end": "565480"
  },
  {
    "text": "how open slamry handles this so if you",
    "start": "565480",
    "end": "567480"
  },
  {
    "text": "know more about that uh please come talk",
    "start": "567480",
    "end": "569920"
  },
  {
    "text": "to me after because I actually want to",
    "start": "569920",
    "end": "571079"
  },
  {
    "text": "know how fluent pit handles it and how",
    "start": "571079",
    "end": "572880"
  },
  {
    "text": "open syry handles this scenario a little",
    "start": "572880",
    "end": "574880"
  },
  {
    "text": "better uh processing is the step in the",
    "start": "574880",
    "end": "578000"
  },
  {
    "text": "middle uh it's where you want to try and",
    "start": "578000",
    "end": "579880"
  },
  {
    "text": "do something useful with your data uh",
    "start": "579880",
    "end": "582120"
  },
  {
    "text": "you maybe you want to filter out",
    "start": "582120",
    "end": "583160"
  },
  {
    "text": "unwanted data or you're transforming it",
    "start": "583160",
    "end": "585920"
  },
  {
    "text": "um you might be doing structured log",
    "start": "585920",
    "end": "587800"
  },
  {
    "text": "parsing uh Json and regx logs are very",
    "start": "587800",
    "end": "590480"
  },
  {
    "text": "popular uh there's kubernetes filters",
    "start": "590480",
    "end": "593279"
  },
  {
    "text": "and processors in most popular agents",
    "start": "593279",
    "end": "595320"
  },
  {
    "text": "that will fetch metadata from the",
    "start": "595320",
    "end": "596720"
  },
  {
    "text": "kubernetes API to enrich your logs and",
    "start": "596720",
    "end": "598600"
  },
  {
    "text": "data uh and was becoming more popular is",
    "start": "598600",
    "end": "601600"
  },
  {
    "text": "influent bit Lua and in and and wasum",
    "start": "601600",
    "end": "604760"
  },
  {
    "text": "and in open cemetry wasm processors in",
    "start": "604760",
    "end": "607399"
  },
  {
    "text": "the middle that let you do a lot more",
    "start": "607399",
    "end": "609320"
  },
  {
    "text": "advanced processing in your pipeline in",
    "start": "609320",
    "end": "611480"
  },
  {
    "text": "case there's something that the default",
    "start": "611480",
    "end": "612959"
  },
  {
    "text": "processes aren't going to do for",
    "start": "612959",
    "end": "615240"
  },
  {
    "text": "you the biggest challenge with this is",
    "start": "615240",
    "end": "617560"
  },
  {
    "text": "mostly that you do anything on a",
    "start": "617560",
    "end": "620360"
  },
  {
    "text": "pipeline that's handling megabytes of",
    "start": "620360",
    "end": "622399"
  },
  {
    "text": "data a second even the smallest actions",
    "start": "622399",
    "end": "624680"
  },
  {
    "text": "are going to have a multiplicative",
    "start": "624680",
    "end": "626040"
  },
  {
    "text": "effect on your overhead um my",
    "start": "626040",
    "end": "629640"
  },
  {
    "text": "especially if you're doing like a regx",
    "start": "629640",
    "end": "631000"
  },
  {
    "text": "log or Json log parsing that the effects",
    "start": "631000",
    "end": "633320"
  },
  {
    "text": "of that grow really quickly um where the",
    "start": "633320",
    "end": "637120"
  },
  {
    "text": "plug-in actually runs in the pipeline is",
    "start": "637120",
    "end": "639360"
  },
  {
    "text": "uh becoming more important uh especially",
    "start": "639360",
    "end": "642600"
  },
  {
    "text": "now with fluent bit fluent bit 2 what",
    "start": "642600",
    "end": "644120"
  },
  {
    "text": "Eduardo talked about with uh processors",
    "start": "644120",
    "end": "646040"
  },
  {
    "text": "instead of the old filters processors",
    "start": "646040",
    "end": "648399"
  },
  {
    "text": "can run in input and output threads",
    "start": "648399",
    "end": "651720"
  },
  {
    "text": "instead of the old way which is filters",
    "start": "651720",
    "end": "653680"
  },
  {
    "text": "running all in the main thread uh it",
    "start": "653680",
    "end": "656160"
  },
  {
    "text": "used to bog down the performance but",
    "start": "656160",
    "end": "658040"
  },
  {
    "text": "processors are much better so if you are",
    "start": "658040",
    "end": "660040"
  },
  {
    "text": "in a scenario where you can move your",
    "start": "660040",
    "end": "662560"
  },
  {
    "text": "you're you can move to a newer version",
    "start": "662560",
    "end": "663920"
  },
  {
    "text": "of fluent bit and try processors instead",
    "start": "663920",
    "end": "665600"
  },
  {
    "text": "of filters I highly recommend it I've",
    "start": "665600",
    "end": "667519"
  },
  {
    "text": "had a lot of success with them um",
    "start": "667519",
    "end": "669639"
  },
  {
    "text": "another example is on tail input there",
    "start": "669639",
    "end": "672040"
  },
  {
    "text": "are in in in otel and fluent bit and I",
    "start": "672040",
    "end": "674560"
  },
  {
    "text": "think in Vector there are ways for you",
    "start": "674560",
    "end": "676920"
  },
  {
    "text": "to on a tail input specify a parser that",
    "start": "676920",
    "end": "679800"
  },
  {
    "text": "happens before it makes it to the rest",
    "start": "679800",
    "end": "682079"
  },
  {
    "text": "of the pipeline this this could be like",
    "start": "682079",
    "end": "683760"
  },
  {
    "text": "a Json processor or a multi-line",
    "start": "683760",
    "end": "685519"
  },
  {
    "text": "processor and that's really convenient",
    "start": "685519",
    "end": "687200"
  },
  {
    "text": "for understanding the pipeline and like",
    "start": "687200",
    "end": "689200"
  },
  {
    "text": "make sending it through like you don't",
    "start": "689200",
    "end": "690360"
  },
  {
    "text": "have to send it through a Json processor",
    "start": "690360",
    "end": "691880"
  },
  {
    "text": "first uh one of the problems with that",
    "start": "691880",
    "end": "694000"
  },
  {
    "text": "is that if you're overworking the tail",
    "start": "694000",
    "end": "695560"
  },
  {
    "text": "plugin with also doing the parsing you",
    "start": "695560",
    "end": "697320"
  },
  {
    "text": "can really hamstring how fast you can",
    "start": "697320",
    "end": "699480"
  },
  {
    "text": "read data out of the file because it's",
    "start": "699480",
    "end": "700959"
  },
  {
    "text": "so busy doing other stuff uh we've had",
    "start": "700959",
    "end": "703320"
  },
  {
    "text": "some issues with like the docker log",
    "start": "703320",
    "end": "705320"
  },
  {
    "text": "processor on in on the input tail plugin",
    "start": "705320",
    "end": "707600"
  },
  {
    "text": "in in fluent bit uh where instead we",
    "start": "707600",
    "end": "710480"
  },
  {
    "text": "just decided to move it off to a filter",
    "start": "710480",
    "end": "711959"
  },
  {
    "text": "and it was a crazy crazy performance",
    "start": "711959",
    "end": "714000"
  },
  {
    "text": "Improvement in comparison to putting it",
    "start": "714000",
    "end": "715279"
  },
  {
    "text": "on the tail plugin so that's something",
    "start": "715279",
    "end": "717000"
  },
  {
    "text": "to keep an eye out",
    "start": "717000",
    "end": "720959"
  },
  {
    "text": "um Json is a data format that for some",
    "start": "721000",
    "end": "724000"
  },
  {
    "text": "reason we've universally decided is the",
    "start": "724000",
    "end": "727079"
  },
  {
    "text": "uh default way to communicate with",
    "start": "727079",
    "end": "728839"
  },
  {
    "text": "computers uh but unfortunately parsing",
    "start": "728839",
    "end": "731000"
  },
  {
    "text": "it is very difficult and slow and hard",
    "start": "731000",
    "end": "734040"
  },
  {
    "text": "and it can be a real problem when you're",
    "start": "734040",
    "end": "736440"
  },
  {
    "text": "trying to parse something especially",
    "start": "736440",
    "end": "738440"
  },
  {
    "text": "that is deeply nested uh if you're",
    "start": "738440",
    "end": "740279"
  },
  {
    "text": "trying to parse deeply nested Json logs",
    "start": "740279",
    "end": "742160"
  },
  {
    "text": "you can get into a lot of trouble um we",
    "start": "742160",
    "end": "744560"
  },
  {
    "text": "had some trouble in the Google uh stack",
    "start": "744560",
    "end": "746519"
  },
  {
    "text": "driver output plugin where someone was",
    "start": "746519",
    "end": "748519"
  },
  {
    "text": "trying to log a mongodb query that kept",
    "start": "748519",
    "end": "751440"
  },
  {
    "text": "on going in and in and in and in was",
    "start": "751440",
    "end": "753560"
  },
  {
    "text": "crashing the process uh and so if you",
    "start": "753560",
    "end": "756519"
  },
  {
    "text": "have really deeply nested data uh that",
    "start": "756519",
    "end": "759079"
  },
  {
    "text": "can be a real problem but really Json is",
    "start": "759079",
    "end": "760720"
  },
  {
    "text": "just slow in general especially if",
    "start": "760720",
    "end": "761880"
  },
  {
    "text": "you're running it on all your logs if",
    "start": "761880",
    "end": "763279"
  },
  {
    "text": "you're Json processing like every log",
    "start": "763279",
    "end": "765120"
  },
  {
    "text": "you're putting",
    "start": "765120",
    "end": "766480"
  },
  {
    "text": "through exporting is the final stage now",
    "start": "766480",
    "end": "768959"
  },
  {
    "text": "that you've done all this nice uh",
    "start": "768959",
    "end": "770360"
  },
  {
    "text": "ingestion and processing on your data",
    "start": "770360",
    "end": "771839"
  },
  {
    "text": "you need to put it somewhere uh you",
    "start": "771839",
    "end": "773440"
  },
  {
    "text": "might be sending it to one of the major",
    "start": "773440",
    "end": "774680"
  },
  {
    "text": "Cloud providers you might be remote",
    "start": "774680",
    "end": "776399"
  },
  {
    "text": "writing it to an external Prometheus or",
    "start": "776399",
    "end": "778639"
  },
  {
    "text": "you you might be sending it to an OTL",
    "start": "778639",
    "end": "780360"
  },
  {
    "text": "compatible vendor or even another agent",
    "start": "780360",
    "end": "783480"
  },
  {
    "text": "uh the biggest challenge with exporting",
    "start": "783480",
    "end": "785240"
  },
  {
    "text": "is that most exporting happens uh over",
    "start": "785240",
    "end": "787959"
  },
  {
    "text": "the network and all the problems with",
    "start": "787959",
    "end": "791199"
  },
  {
    "text": "sending data over the network are going",
    "start": "791199",
    "end": "793279"
  },
  {
    "text": "to come into play here sending data over",
    "start": "793279",
    "end": "795760"
  },
  {
    "text": "a network is never going to be as fast",
    "start": "795760",
    "end": "797480"
  },
  {
    "text": "as sending data within the program and",
    "start": "797480",
    "end": "800760"
  },
  {
    "text": "it's very easy for your input to outpace",
    "start": "800760",
    "end": "804199"
  },
  {
    "text": "your export uh and that's where we start",
    "start": "804199",
    "end": "806720"
  },
  {
    "text": "getting into problems with back pressure",
    "start": "806720",
    "end": "809720"
  },
  {
    "text": "uh with batching and back pressure you",
    "start": "809720",
    "end": "811600"
  },
  {
    "text": "can handle these bursts of data without",
    "start": "811600",
    "end": "814160"
  },
  {
    "text": "losing it um if if your output is still",
    "start": "814160",
    "end": "818199"
  },
  {
    "text": "so busy looking at at data trying to",
    "start": "818199",
    "end": "820440"
  },
  {
    "text": "send out the network request maybe",
    "start": "820440",
    "end": "821680"
  },
  {
    "text": "you're just having one slow API request",
    "start": "821680",
    "end": "823120"
  },
  {
    "text": "that's slowing everything down if you're",
    "start": "823120",
    "end": "824639"
  },
  {
    "text": "not uh sending any back pressure back",
    "start": "824639",
    "end": "827040"
  },
  {
    "text": "you're just going to keep on building up",
    "start": "827040",
    "end": "828920"
  },
  {
    "text": "memory building up memory as you try and",
    "start": "828920",
    "end": "830680"
  },
  {
    "text": "hold on to all these logs without",
    "start": "830680",
    "end": "832000"
  },
  {
    "text": "dropping them uh batching is a good way",
    "start": "832000",
    "end": "834519"
  },
  {
    "text": "to deal with this where if you batch",
    "start": "834519",
    "end": "836000"
  },
  {
    "text": "your data up a bit larger you might use",
    "start": "836000",
    "end": "839160"
  },
  {
    "text": "a little bit more resources or it might",
    "start": "839160",
    "end": "841079"
  },
  {
    "text": "take a little bit longer to buffer up",
    "start": "841079",
    "end": "843000"
  },
  {
    "text": "enough resources to send it out but if",
    "start": "843000",
    "end": "844680"
  },
  {
    "text": "you're batching up more data before you",
    "start": "844680",
    "end": "846440"
  },
  {
    "text": "send it out uh then there's less overall",
    "start": "846440",
    "end": "849040"
  },
  {
    "text": "requests that need to be made for your",
    "start": "849040",
    "end": "850720"
  },
  {
    "text": "throughput um overall when you're",
    "start": "850720",
    "end": "853160"
  },
  {
    "text": "dealing with batching and back pressure",
    "start": "853160",
    "end": "854360"
  },
  {
    "text": "it takes a lot of experimentation to",
    "start": "854360",
    "end": "855800"
  },
  {
    "text": "find the right sizes though especially",
    "start": "855800",
    "end": "857800"
  },
  {
    "text": "because the Hammer's got to drop",
    "start": "857800",
    "end": "859800"
  },
  {
    "text": "somewhere like if you are putting",
    "start": "859800",
    "end": "861560"
  },
  {
    "text": "through so much data and you are not",
    "start": "861560",
    "end": "864440"
  },
  {
    "text": "having a big enough batch size you're",
    "start": "864440",
    "end": "866240"
  },
  {
    "text": "just going to lose data eventually",
    "start": "866240",
    "end": "868000"
  },
  {
    "text": "especially if you have other things on",
    "start": "868000",
    "end": "869279"
  },
  {
    "text": "your collector like uh memory limiters",
    "start": "869279",
    "end": "872079"
  },
  {
    "text": "uh if you have other other things that",
    "start": "872079",
    "end": "873240"
  },
  {
    "text": "are trying to limit your usage",
    "start": "873240",
    "end": "875160"
  },
  {
    "text": "eventually you're going to lose data if",
    "start": "875160",
    "end": "876360"
  },
  {
    "text": "you're pushing through too much uh so",
    "start": "876360",
    "end": "878160"
  },
  {
    "text": "it's takes a lot of tweaking to get that",
    "start": "878160",
    "end": "881360"
  },
  {
    "text": "right um threading and if you're running",
    "start": "881360",
    "end": "885000"
  },
  {
    "text": "fluent bit and your output plugin",
    "start": "885000",
    "end": "888199"
  },
  {
    "text": "doesn't support threading you should ask",
    "start": "888199",
    "end": "890279"
  },
  {
    "text": "them to are there any I don't think",
    "start": "890279",
    "end": "891600"
  },
  {
    "text": "there are any that don't support it at",
    "start": "891600",
    "end": "893199"
  },
  {
    "text": "the moment um I think pretty much",
    "start": "893199",
    "end": "894839"
  },
  {
    "text": "everyone will so if you are having",
    "start": "894839",
    "end": "896839"
  },
  {
    "text": "trouble with sending data fast enough I",
    "start": "896839",
    "end": "899800"
  },
  {
    "text": "highly recommend increasing the workers",
    "start": "899800",
    "end": "901839"
  },
  {
    "text": "or at least leaning into the threading",
    "start": "901839",
    "end": "903519"
  },
  {
    "text": "implementation of the agent where you",
    "start": "903519",
    "end": "904959"
  },
  {
    "text": "can uh cuz if you exporting is one of",
    "start": "904959",
    "end": "908480"
  },
  {
    "text": "the uh the really the only step in the",
    "start": "908480",
    "end": "911120"
  },
  {
    "text": "pipeline that can easily be parallelized",
    "start": "911120",
    "end": "913639"
  },
  {
    "text": "most backends can handle time stamps",
    "start": "913639",
    "end": "915920"
  },
  {
    "text": "being a little bit out of order if like",
    "start": "915920",
    "end": "917480"
  },
  {
    "text": "one worker sends it a little bit faster",
    "start": "917480",
    "end": "918880"
  },
  {
    "text": "than the other usually they will be able",
    "start": "918880",
    "end": "920079"
  },
  {
    "text": "to Recon reconcile that so it's really",
    "start": "920079",
    "end": "922240"
  },
  {
    "text": "easy to set it up into if if you set it",
    "start": "922240",
    "end": "925839"
  },
  {
    "text": "to like eight workers for example that",
    "start": "925839",
    "end": "927240"
  },
  {
    "text": "means a threadpool of eight workers",
    "start": "927240",
    "end": "928680"
  },
  {
    "text": "sending data at the same time and it can",
    "start": "928680",
    "end": "930600"
  },
  {
    "text": "really open up your pipeline if it can",
    "start": "930600",
    "end": "932480"
  },
  {
    "text": "send data along at least it can dispatch",
    "start": "932480",
    "end": "934279"
  },
  {
    "text": "it to the threadpool and let one of the",
    "start": "934279",
    "end": "935720"
  },
  {
    "text": "workers figure out the slow",
    "start": "935720",
    "end": "938839"
  },
  {
    "text": "part so the the last question we need to",
    "start": "939040",
    "end": "941319"
  },
  {
    "text": "answer really is how you evaluate it for",
    "start": "941319",
    "end": "943399"
  },
  {
    "text": "yourself if no one's going to give you",
    "start": "943399",
    "end": "944800"
  },
  {
    "text": "an authoritative answer on which agent",
    "start": "944800",
    "end": "946279"
  },
  {
    "text": "is the best or what sort of overhead you",
    "start": "946279",
    "end": "947880"
  },
  {
    "text": "can expect you need to figure out how to",
    "start": "947880",
    "end": "949600"
  },
  {
    "text": "find it for yourself and the only way is",
    "start": "949600",
    "end": "951800"
  },
  {
    "text": "to try running it uh if you are able to",
    "start": "951800",
    "end": "955319"
  },
  {
    "text": "replicate your production environment",
    "start": "955319",
    "end": "956880"
  },
  {
    "text": "and try installing the agent configuring",
    "start": "956880",
    "end": "958720"
  },
  {
    "text": "it and watching some of the metrics that",
    "start": "958720",
    "end": "960440"
  },
  {
    "text": "I mentioned in the earlier slide that is",
    "start": "960440",
    "end": "962399"
  },
  {
    "text": "by far going to be the best way you're",
    "start": "962399",
    "end": "963759"
  },
  {
    "text": "going to get an answer here uh but in",
    "start": "963759",
    "end": "965800"
  },
  {
    "text": "case you're not in a scenario where you",
    "start": "965800",
    "end": "966959"
  },
  {
    "text": "can really easily replicate your uh",
    "start": "966959",
    "end": "969440"
  },
  {
    "text": "production environment I have some some",
    "start": "969440",
    "end": "971959"
  },
  {
    "text": "ideas for test workloads some of the",
    "start": "971959",
    "end": "973440"
  },
  {
    "text": "things that I've done to try and do a",
    "start": "973440",
    "end": "975120"
  },
  {
    "text": "little bit of benchmarking on our own",
    "start": "975120",
    "end": "976920"
  },
  {
    "text": "products uh using a log generator is",
    "start": "976920",
    "end": "979440"
  },
  {
    "text": "sort of the obvious default one if",
    "start": "979440",
    "end": "980839"
  },
  {
    "text": "you're if you're testing a log pipeline",
    "start": "980839",
    "end": "983759"
  },
  {
    "text": "uh there's a really good log generator",
    "start": "983759",
    "end": "985160"
  },
  {
    "text": "from AWS called AWS log bench I or maybe",
    "start": "985160",
    "end": "988000"
  },
  {
    "text": "they call it like something bigger but I",
    "start": "988000",
    "end": "990279"
  },
  {
    "text": "call it AWS log bench uh it lets you",
    "start": "990279",
    "end": "992959"
  },
  {
    "text": "specify a size for your logs and a rate",
    "start": "992959",
    "end": "995199"
  },
  {
    "text": "per second to send them uh and that's a",
    "start": "995199",
    "end": "997279"
  },
  {
    "text": "good way to get answers for like if",
    "start": "997279",
    "end": "999120"
  },
  {
    "text": "you're at 100 megabytes a second of logs",
    "start": "999120",
    "end": "1001560"
  },
  {
    "text": "some ridiculous number like what's the",
    "start": "1001560",
    "end": "1003000"
  },
  {
    "text": "overhead going to look like and you can",
    "start": "1003000",
    "end": "1004199"
  },
  {
    "text": "test it at different amounts and you can",
    "start": "1004199",
    "end": "1006000"
  },
  {
    "text": "test it by sending it through a Json",
    "start": "1006000",
    "end": "1007800"
  },
  {
    "text": "processor or sending it through 14",
    "start": "1007800",
    "end": "1009120"
  },
  {
    "text": "modify fields or something like that you",
    "start": "1009120",
    "end": "1010560"
  },
  {
    "text": "can try and test the limits really well",
    "start": "1010560",
    "end": "1012040"
  },
  {
    "text": "with a log generator log generators",
    "start": "1012040",
    "end": "1014079"
  },
  {
    "text": "aren't always the most they're they're",
    "start": "1014079",
    "end": "1015480"
  },
  {
    "text": "they're very synthetic because they're",
    "start": "1015480",
    "end": "1016720"
  },
  {
    "text": "sending data at like a specified per",
    "start": "1016720",
    "end": "1020319"
  },
  {
    "text": "second same amount same logs it's not",
    "start": "1020319",
    "end": "1022880"
  },
  {
    "text": "the most",
    "start": "1022880",
    "end": "1024438"
  },
  {
    "text": "uh realistic environment uh but it's a",
    "start": "1024439",
    "end": "1027438"
  },
  {
    "text": "good start if you want to test the",
    "start": "1027439",
    "end": "1030480"
  },
  {
    "text": "limits uh if you're scraping Prometheus",
    "start": "1030480",
    "end": "1033438"
  },
  {
    "text": "if that's the main thing you're going to",
    "start": "1033439",
    "end": "1034280"
  },
  {
    "text": "be doing with the agent it's actually",
    "start": "1034280",
    "end": "1035798"
  },
  {
    "text": "very easy to replicate it because you",
    "start": "1035799",
    "end": "1037160"
  },
  {
    "text": "can take a copy of the text scrape and",
    "start": "1037160",
    "end": "1039720"
  },
  {
    "text": "if you don't expect that to change much",
    "start": "1039720",
    "end": "1041480"
  },
  {
    "text": "setting up a mock server with just that",
    "start": "1041480",
    "end": "1043038"
  },
  {
    "text": "text scrape is a really good way to get",
    "start": "1043039",
    "end": "1044678"
  },
  {
    "text": "a sense of what kind of resources you're",
    "start": "1044679",
    "end": "1046640"
  },
  {
    "text": "going to be having because uh the",
    "start": "1046640",
    "end": "1049080"
  },
  {
    "text": "changing of metric values or adding well",
    "start": "1049080",
    "end": "1052400"
  },
  {
    "text": "adding new labels can be changed the",
    "start": "1052400",
    "end": "1054080"
  },
  {
    "text": "changing of metric values isn't really",
    "start": "1054080",
    "end": "1056039"
  },
  {
    "text": "where the resource usage comes from in",
    "start": "1056039",
    "end": "1057919"
  },
  {
    "text": "Prometheus it's about processing of the",
    "start": "1057919",
    "end": "1059520"
  },
  {
    "text": "scrape so if you can at least set up a",
    "start": "1059520",
    "end": "1062160"
  },
  {
    "text": "mock of your scrape of like what the",
    "start": "1062160",
    "end": "1063440"
  },
  {
    "text": "shape is going to be uh then that can be",
    "start": "1063440",
    "end": "1066039"
  },
  {
    "text": "a good test workload",
    "start": "1066039",
    "end": "1069919"
  },
  {
    "text": "um why can't I read that oh yes of",
    "start": "1070360",
    "end": "1073120"
  },
  {
    "text": "course um if you are scraping metrics um",
    "start": "1073120",
    "end": "1078559"
  },
  {
    "text": "and you can try and force High",
    "start": "1078559",
    "end": "1079679"
  },
  {
    "text": "cardinality scenarios to test the limits",
    "start": "1079679",
    "end": "1082039"
  },
  {
    "text": "uh this is especially important if",
    "start": "1082039",
    "end": "1083200"
  },
  {
    "text": "you're scraping if you expect to be",
    "start": "1083200",
    "end": "1084799"
  },
  {
    "text": "scraping like a database database",
    "start": "1084799",
    "end": "1086720"
  },
  {
    "text": "metrics are one of the first ones that",
    "start": "1086720",
    "end": "1088120"
  },
  {
    "text": "will go a little bit crazy in terms of",
    "start": "1088120",
    "end": "1090600"
  },
  {
    "text": "cardinality because there will be a time",
    "start": "1090600",
    "end": "1092600"
  },
  {
    "text": "series per table or per replica or per",
    "start": "1092600",
    "end": "1095919"
  },
  {
    "text": "table in replica or it depends on the",
    "start": "1095919",
    "end": "1097720"
  },
  {
    "text": "database if you can find a way to force",
    "start": "1097720",
    "end": "1100039"
  },
  {
    "text": "more High cardinality scenarios like you",
    "start": "1100039",
    "end": "1101679"
  },
  {
    "text": "can scrape an example database with tons",
    "start": "1101679",
    "end": "1103320"
  },
  {
    "text": "and tons of tables then that's a good",
    "start": "1103320",
    "end": "1105080"
  },
  {
    "text": "way to sort of stress the limits of uh",
    "start": "1105080",
    "end": "1107440"
  },
  {
    "text": "how the",
    "start": "1107440",
    "end": "1109200"
  },
  {
    "text": "acts when it's pushing through too many",
    "start": "1109200",
    "end": "1111840"
  },
  {
    "text": "points if you don't like the answer if",
    "start": "1111840",
    "end": "1114039"
  },
  {
    "text": "you do this evaluation you figure out",
    "start": "1114039",
    "end": "1116400"
  },
  {
    "text": "how much overhead your agent's going to",
    "start": "1116400",
    "end": "1117480"
  },
  {
    "text": "have and you don't like it what are you",
    "start": "1117480",
    "end": "1118799"
  },
  {
    "text": "going to do um trying to do less is sort",
    "start": "1118799",
    "end": "1122120"
  },
  {
    "text": "of the obvious one it seems pretty",
    "start": "1122120",
    "end": "1123919"
  },
  {
    "text": "obvious when I put it that way uh but",
    "start": "1123919",
    "end": "1126080"
  },
  {
    "text": "generally if you're doing more you're",
    "start": "1126080",
    "end": "1128120"
  },
  {
    "text": "using more resources if you can find",
    "start": "1128120",
    "end": "1130440"
  },
  {
    "text": "ways to reduce how much you're",
    "start": "1130440",
    "end": "1132679"
  },
  {
    "text": "processing if you can reduce the size of",
    "start": "1132679",
    "end": "1135200"
  },
  {
    "text": "your scrape or if you can offload the",
    "start": "1135200",
    "end": "1138320"
  },
  {
    "text": "work somewhere else which is my favorite",
    "start": "1138320",
    "end": "1140559"
  },
  {
    "text": "my favorite way that is the best way to",
    "start": "1140559",
    "end": "1142080"
  },
  {
    "text": "do it if you can if you have a backend",
    "start": "1142080",
    "end": "1144200"
  },
  {
    "text": "that will do the Json processing for you",
    "start": "1144200",
    "end": "1146600"
  },
  {
    "text": "I mean that would be a dream world if",
    "start": "1146600",
    "end": "1147880"
  },
  {
    "text": "that exists uh because if you could just",
    "start": "1147880",
    "end": "1150840"
  },
  {
    "text": "shovel Json raw Json over there and let",
    "start": "1150840",
    "end": "1153400"
  },
  {
    "text": "them do the Json processing that would",
    "start": "1153400",
    "end": "1154919"
  },
  {
    "text": "be great but I'm also pretty bullish on",
    "start": "1154919",
    "end": "1157000"
  },
  {
    "text": "like aggregator nodes where you have",
    "start": "1157000",
    "end": "1158880"
  },
  {
    "text": "lots of agents who can handle data being",
    "start": "1158880",
    "end": "1161080"
  },
  {
    "text": "pushed to it uh it's a lot easier to",
    "start": "1161080",
    "end": "1163520"
  },
  {
    "text": "manage one location of agents and try",
    "start": "1163520",
    "end": "1165440"
  },
  {
    "text": "and scale that out than trying to deal",
    "start": "1165440",
    "end": "1167440"
  },
  {
    "text": "with agents all across your Fleet doing",
    "start": "1167440",
    "end": "1170000"
  },
  {
    "text": "too much or growing too",
    "start": "1170000",
    "end": "1172520"
  },
  {
    "text": "big uh if you are truly in a scenario",
    "start": "1172520",
    "end": "1175159"
  },
  {
    "text": "where you think you're you have an",
    "start": "1175159",
    "end": "1176760"
  },
  {
    "text": "unacceptable performance or youve found",
    "start": "1176760",
    "end": "1178600"
  },
  {
    "text": "a regression in some upgrade uh when you",
    "start": "1178600",
    "end": "1181320"
  },
  {
    "text": "do open an issue for maintainers uh make",
    "start": "1181320",
    "end": "1184600"
  },
  {
    "text": "sure that you have good information and",
    "start": "1184600",
    "end": "1187679"
  },
  {
    "text": "it's hard to say authoritatively like",
    "start": "1187679",
    "end": "1189280"
  },
  {
    "text": "what is the right information to always",
    "start": "1189280",
    "end": "1190960"
  },
  {
    "text": "include uh but really any information",
    "start": "1190960",
    "end": "1193080"
  },
  {
    "text": "helps with performance stuff because a",
    "start": "1193080",
    "end": "1195159"
  },
  {
    "text": "lot of the performance issues that are",
    "start": "1195159",
    "end": "1196679"
  },
  {
    "text": "open in these repos are about things",
    "start": "1196679",
    "end": "1199200"
  },
  {
    "text": "that maintainers will never be able to",
    "start": "1199200",
    "end": "1201440"
  },
  {
    "text": "access so making sure that you have ways",
    "start": "1201440",
    "end": "1203600"
  },
  {
    "text": "to replicate the performance issue",
    "start": "1203600",
    "end": "1205240"
  },
  {
    "text": "you're seeing making sure you can",
    "start": "1205240",
    "end": "1206640"
  },
  {
    "text": "include graphs or csvs making sure you",
    "start": "1206640",
    "end": "1208880"
  },
  {
    "text": "can in include uh Linux per reports or",
    "start": "1208880",
    "end": "1211640"
  },
  {
    "text": "PPR profiles any of this stuff is going",
    "start": "1211640",
    "end": "1213919"
  },
  {
    "text": "to be very helpful for maintainers",
    "start": "1213919",
    "end": "1215320"
  },
  {
    "text": "trying to look into performance",
    "start": "1215320",
    "end": "1217000"
  },
  {
    "text": "issues and I think that's everything so",
    "start": "1217000",
    "end": "1219280"
  },
  {
    "text": "thank you uh my name is Braden you can",
    "start": "1219280",
    "end": "1221120"
  },
  {
    "text": "find me on the cncf slack or uh or on on",
    "start": "1221120",
    "end": "1224400"
  },
  {
    "text": "Twitter I have my Twitter up there at",
    "start": "1224400",
    "end": "1225600"
  },
  {
    "text": "some point U anyways yeah thank you",
    "start": "1225600",
    "end": "1230158"
  },
  {
    "text": "another question hey great Doug thanks",
    "start": "1238159",
    "end": "1240200"
  },
  {
    "text": "of course the obvious question is which",
    "start": "1240200",
    "end": "1242120"
  },
  {
    "text": "collector is the best but I understand",
    "start": "1242120",
    "end": "1243720"
  },
  {
    "text": "why you didn't want to answer that maybe",
    "start": "1243720",
    "end": "1246240"
  },
  {
    "text": "you could answer uh what do you use in",
    "start": "1246240",
    "end": "1249520"
  },
  {
    "text": "Google cloud or what the customers of",
    "start": "1249520",
    "end": "1251039"
  },
  {
    "text": "Google Cloud are using and why or are",
    "start": "1251039",
    "end": "1252960"
  },
  {
    "text": "you considering a change or why yeah so",
    "start": "1252960",
    "end": "1255559"
  },
  {
    "text": "I probably should have prefaced the talk",
    "start": "1255559",
    "end": "1257000"
  },
  {
    "text": "with that a little more um but my team",
    "start": "1257000",
    "end": "1260200"
  },
  {
    "text": "one of the main things we work on is the",
    "start": "1260200",
    "end": "1261559"
  },
  {
    "text": "Google Cloud Ops agent which is I call",
    "start": "1261559",
    "end": "1264200"
  },
  {
    "text": "it two agents in a trench coat uh cuz",
    "start": "1264200",
    "end": "1266400"
  },
  {
    "text": "it's under the hood it's uh fluent bit",
    "start": "1266400",
    "end": "1269080"
  },
  {
    "text": "collecting logs and open Telemetry",
    "start": "1269080",
    "end": "1270960"
  },
  {
    "text": "collecting metrics and traces um and",
    "start": "1270960",
    "end": "1274720"
  },
  {
    "text": "that's mainly we have a a central config",
    "start": "1274720",
    "end": "1277440"
  },
  {
    "text": "layer uh that will generate configs for",
    "start": "1277440",
    "end": "1280320"
  },
  {
    "text": "the underlying open Telemetry and",
    "start": "1280320",
    "end": "1281600"
  },
  {
    "text": "underlying fluent bit with the sort of",
    "start": "1281600",
    "end": "1283919"
  },
  {
    "text": "recommended tunings for folks running on",
    "start": "1283919",
    "end": "1286320"
  },
  {
    "text": "primarily VMS like plain VM",
    "start": "1286320",
    "end": "1290039"
  },
  {
    "text": "uh collecting metrics us",
    "start": "1291400",
    "end": "1294039"
  },
  {
    "text": "using like we use the host metrics",
    "start": "1294039",
    "end": "1296480"
  },
  {
    "text": "receiver uh by default we also use a lot",
    "start": "1296480",
    "end": "1298679"
  },
  {
    "text": "of we have a lot of third- party",
    "start": "1298679",
    "end": "1299760"
  },
  {
    "text": "applications so like the Apache receiver",
    "start": "1299760",
    "end": "1301840"
  },
  {
    "text": "the engine X all the database receivers",
    "start": "1301840",
    "end": "1303360"
  },
  {
    "text": "we use all of those and we also do have",
    "start": "1303360",
    "end": "1306279"
  },
  {
    "text": "support for Prometheus we have a",
    "start": "1306279",
    "end": "1307400"
  },
  {
    "text": "Prometheus receiver that a lot of folks",
    "start": "1307400",
    "end": "1308760"
  },
  {
    "text": "have started using and an OTL receiver",
    "start": "1308760",
    "end": "1310799"
  },
  {
    "text": "that is less people are",
    "start": "1310799",
    "end": "1312720"
  },
  {
    "text": "using uh that's mainly what we use and",
    "start": "1312720",
    "end": "1315520"
  },
  {
    "text": "so the reason that I think about all",
    "start": "1315520",
    "end": "1318080"
  },
  {
    "text": "this stuff is that I'm we're trying to",
    "start": "1318080",
    "end": "1319880"
  },
  {
    "text": "make the best recommendation when we",
    "start": "1319880",
    "end": "1321880"
  },
  {
    "text": "generate these configs for people they",
    "start": "1321880",
    "end": "1323240"
  },
  {
    "text": "don't really know what all the knobs are",
    "start": "1323240",
    "end": "1324600"
  },
  {
    "text": "so we've tried to find the right",
    "start": "1324600",
    "end": "1326559"
  },
  {
    "text": "settings for the knobs that's really",
    "start": "1326559",
    "end": "1328400"
  },
  {
    "text": "that's kind of why I'm thinking about",
    "start": "1328400",
    "end": "1330320"
  },
  {
    "text": "all",
    "start": "1330320",
    "end": "1332200"
  },
  {
    "text": "this uh can you also speak to uh",
    "start": "1332200",
    "end": "1335320"
  },
  {
    "text": "horizontally scaling these agents uh in",
    "start": "1335320",
    "end": "1338480"
  },
  {
    "text": "case uh like the application is big and",
    "start": "1338480",
    "end": "1341080"
  },
  {
    "text": "you have to send the logs and metrics to",
    "start": "1341080",
    "end": "1343600"
  },
  {
    "text": "multiple agents what are the best",
    "start": "1343600",
    "end": "1345520"
  },
  {
    "text": "practices to do that sorry can I hear",
    "start": "1345520",
    "end": "1348400"
  },
  {
    "text": "can I hear that again can you okay yeah",
    "start": "1348400",
    "end": "1351279"
  },
  {
    "text": "can you speak to the best practices to",
    "start": "1351279",
    "end": "1353159"
  },
  {
    "text": "scaling the agents as well horizontally",
    "start": "1353159",
    "end": "1355159"
  },
  {
    "text": "scaling the agents if if there if the",
    "start": "1355159",
    "end": "1356919"
  },
  {
    "text": "application is the number of application",
    "start": "1356919",
    "end": "1359080"
  },
  {
    "text": "Parts is growing then how do you decide",
    "start": "1359080",
    "end": "1361520"
  },
  {
    "text": "which agent to send that particular log",
    "start": "1361520",
    "end": "1363640"
  },
  {
    "text": "or metric too right so it it's about",
    "start": "1363640",
    "end": "1367279"
  },
  {
    "text": "like best practices for scaling the",
    "start": "1367279",
    "end": "1368880"
  },
  {
    "text": "agent and deciding which agent to to",
    "start": "1368880",
    "end": "1370880"
  },
  {
    "text": "send like what to send where uh I think",
    "start": "1370880",
    "end": "1374520"
  },
  {
    "text": "it does I I don't have a lot of",
    "start": "1374520",
    "end": "1377000"
  },
  {
    "text": "experience with like scaling the agents",
    "start": "1377000",
    "end": "1378960"
  },
  {
    "text": "in the aggregator node like I mentioned",
    "start": "1378960",
    "end": "1382360"
  },
  {
    "text": "um yeah I don't have a good answer for",
    "start": "1382360",
    "end": "1384559"
  },
  {
    "text": "that in terms of like deciding what",
    "start": "1384559",
    "end": "1385679"
  },
  {
    "text": "agent to send where I think if you are",
    "start": "1385679",
    "end": "1388080"
  },
  {
    "text": "if you're not doing a lot of",
    "start": "1388080",
    "end": "1389840"
  },
  {
    "text": "processing basically any agent can",
    "start": "1389840",
    "end": "1392919"
  },
  {
    "text": "shovel data super fast except for fluent",
    "start": "1392919",
    "end": "1395320"
  },
  {
    "text": "uh every agent can send data super fast",
    "start": "1395320",
    "end": "1397640"
  },
  {
    "text": "without any processing in the middle um",
    "start": "1397640",
    "end": "1400320"
  },
  {
    "text": "so it doesn't matter too much and then",
    "start": "1400320",
    "end": "1401640"
  },
  {
    "text": "it's going to come it's going to come",
    "start": "1401640",
    "end": "1402600"
  },
  {
    "text": "down a little bit more to functionality",
    "start": "1402600",
    "end": "1404480"
  },
  {
    "text": "uh but in terms of uh in terms of",
    "start": "1404480",
    "end": "1407039"
  },
  {
    "text": "performance yeah kind of just have to",
    "start": "1407039",
    "end": "1408440"
  },
  {
    "text": "try it I think is is the best way is the",
    "start": "1408440",
    "end": "1410679"
  },
  {
    "text": "best way to tell but I've I've really",
    "start": "1410679",
    "end": "1412919"
  },
  {
    "text": "liked working with fluent bit I think",
    "start": "1412919",
    "end": "1415000"
  },
  {
    "text": "the there's not a big upfront cost uh",
    "start": "1415000",
    "end": "1417720"
  },
  {
    "text": "like open Telemetry collector being a go",
    "start": "1417720",
    "end": "1419679"
  },
  {
    "text": "program has in our experience we've seen",
    "start": "1419679",
    "end": "1422720"
  },
  {
    "text": "more usage in that than influent bit by",
    "start": "1422720",
    "end": "1424840"
  },
  {
    "text": "default uh but it does kind of depend on",
    "start": "1424840",
    "end": "1426760"
  },
  {
    "text": "what you're doing with",
    "start": "1426760",
    "end": "1429360"
  },
  {
    "text": "it",
    "start": "1433520",
    "end": "1435799"
  },
  {
    "text": "okay thank you Bron",
    "start": "1435799",
    "end": "1439880"
  }
]
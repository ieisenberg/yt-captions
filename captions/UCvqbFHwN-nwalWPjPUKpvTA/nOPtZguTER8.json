[
  {
    "text": "alright looks like the numbers are stabilizing so let's go ahead and get started welcome to today's CMC f webinar",
    "start": "210",
    "end": "5879"
  },
  {
    "text": "planet scale machine learning workflows with advanced data management on cube flow I'm Kaitlin Barnard marketing",
    "start": "5879",
    "end": "12269"
  },
  {
    "text": "manager at CNCs and I'd like to thank you all for joining us today I'd also like to welcome today's presenter bangle",
    "start": "12269",
    "end": "18390"
  },
  {
    "text": "is cookus CTO and co-founder at a Rick doe so just a few housekeeping items before we get started during the webinar",
    "start": "18390",
    "end": "25380"
  },
  {
    "text": "you are not able to speak as an attendee there is a Q&A box at the bottom of your screen so if you have any questions that",
    "start": "25380",
    "end": "32219"
  },
  {
    "text": "come up throughout the webinar please feel free to drop them in there and then we'll hold Q&A until the end and get to",
    "start": "32219",
    "end": "38489"
  },
  {
    "text": "as many of those questions as we can this session is also being recorded and will be sent out along with the slides",
    "start": "38489",
    "end": "44850"
  },
  {
    "text": "and after the presentation so with that I'll hand it over to Benglis to kick off today's presentation Thank",
    "start": "44850",
    "end": "51600"
  },
  {
    "text": "You Kate it's a great pleasure to be here today nice to meet you I hope you enjoy today",
    "start": "51600",
    "end": "57059"
  },
  {
    "text": "sooner so as Caitlin mentioned my name is Curtis founder and CTO of erecto what",
    "start": "57059",
    "end": "63480"
  },
  {
    "text": "we're doing here it too is planet-scale data management and we focus on kubernetes and ml environments so let me",
    "start": "63480",
    "end": "72060"
  },
  {
    "text": "switch let me make sure I can switch our slides share my screen you should be",
    "start": "72060",
    "end": "83040"
  },
  {
    "text": "seeing the slide yep you can feel great so today we'll be talking about climate",
    "start": "83040",
    "end": "90420"
  },
  {
    "text": "scale and mail workflows with advanced data management on Cooper what does that mean it means we'll go over what",
    "start": "90420",
    "end": "97680"
  },
  {
    "text": "planning scale means for us we'll talk about machine learning on kubernetes",
    "start": "97680",
    "end": "103049"
  },
  {
    "text": "coop flow which is BML to kid for kubernetes focus on how managing data is",
    "start": "103049",
    "end": "111450"
  },
  {
    "text": "very important for efficient machine learning talk about data management in coop flow which is the area in which we",
    "start": "111450",
    "end": "118259"
  },
  {
    "text": "have made a few contributions to cook flow and then move the platform and to",
    "start": "118259",
    "end": "124439"
  },
  {
    "text": "end coop flow along with our integrations so by now it's a definite fact that we",
    "start": "124439",
    "end": "131730"
  },
  {
    "text": "live in the kubernetes era kubernetes has become the default container",
    "start": "131730",
    "end": "137010"
  },
  {
    "text": "istration engine no one can question that anymore across platforms across different kinds",
    "start": "137010",
    "end": "143160"
  },
  {
    "text": "of infrastructure kubernetes is the single simple way to declare your",
    "start": "143160",
    "end": "148560"
  },
  {
    "text": "containerized infrastructure and then the underlying platform does whatever",
    "start": "148560",
    "end": "153989"
  },
  {
    "text": "you guys could do but this is a sincere planner so there's no reason for me to",
    "start": "153989",
    "end": "159239"
  },
  {
    "text": "argue for kubernetes parents who are already so company's the question is what happens with machine learning now",
    "start": "159239",
    "end": "167310"
  },
  {
    "text": "that kubernetes is gaining ground so fast so although everyone is doing their",
    "start": "167310",
    "end": "173730"
  },
  {
    "text": "own thing right now we believe that eventually ml will run on kubernetes",
    "start": "173730",
    "end": "179750"
  },
  {
    "text": "with kubernetes primitives gaining all the benefits at kubernetes brings with",
    "start": "179750",
    "end": "187410"
  },
  {
    "text": "kubernetes primitives means that machine learning will be running in a declarative way users will be declaring",
    "start": "187410",
    "end": "196049"
  },
  {
    "text": "to kubernetes the kind of a mail infrastructure they need and kubernetes will make it happen",
    "start": "196049",
    "end": "202310"
  },
  {
    "text": "users will have a single way of asking what they want to have across",
    "start": "202310",
    "end": "208350"
  },
  {
    "text": "infrastructure across locations and kubernetes will make it - it will make it happen and because users cannot",
    "start": "208350",
    "end": "215310"
  },
  {
    "text": "really don't really have to speak to kubernetes directly because their ml",
    "start": "215310",
    "end": "222329"
  },
  {
    "text": "users the data scientists what do we need in between we need coop flow that's the overall idea so why should a man run",
    "start": "222329",
    "end": "231780"
  },
  {
    "text": "on kubernetes because this will bring containerization but better more",
    "start": "231780",
    "end": "238109"
  },
  {
    "text": "efficient handling of hardware sources auto-scaling portability across",
    "start": "238109",
    "end": "244230"
  },
  {
    "text": "locations across infrastructure extensibility and no vendor locking so",
    "start": "244230",
    "end": "250859"
  },
  {
    "text": "we are just getting started on things but the very good first step is coop",
    "start": "250859",
    "end": "258230"
  },
  {
    "text": "flow is here and coop flow is the ML toolkit for kubernetes it is the first",
    "start": "258230",
    "end": "266060"
  },
  {
    "text": "native machine learning to teach for kubernetes announced by Google just over",
    "start": "266060",
    "end": "271580"
  },
  {
    "text": "a year ago end of 2017 it is already picking up speed to become the de-facto",
    "start": "271580",
    "end": "277160"
  },
  {
    "text": "ml platform it's a way of declaring your",
    "start": "277160",
    "end": "283640"
  },
  {
    "text": "ml platform using kubernetes primitive music Burnett as components so I will",
    "start": "283640",
    "end": "289970"
  },
  {
    "text": "spend the next few minutes with some slides I got from a presentation by J",
    "start": "289970",
    "end": "296840"
  },
  {
    "text": "Smith and David our own chick David our own ship is the co-founder of the coop flow project this presentation was given",
    "start": "296840",
    "end": "302810"
  },
  {
    "text": "in koukin North America 2018 in Seattle last December machine dominguez code to",
    "start": "302810",
    "end": "309800"
  },
  {
    "text": "essentially introduce coop flow to those of you who may not have heard about it before or maybe that week recap to get",
    "start": "309800",
    "end": "317330"
  },
  {
    "text": "upstream so when people think about machine learning today a big mistake",
    "start": "317330",
    "end": "324590"
  },
  {
    "text": "many people make is that well we need a data scientist and this data scientist is gonna be build a model for us and",
    "start": "324590",
    "end": "331280"
  },
  {
    "text": "this is a now well building a model is part of an email workflow but it's not",
    "start": "331280",
    "end": "339700"
  },
  {
    "text": "what the mail is all about building a model is just one stick in a very big",
    "start": "339700",
    "end": "347479"
  },
  {
    "text": "email workflow it's a multitude of components but we need to take care of and we need to",
    "start": "347479",
    "end": "353810"
  },
  {
    "text": "stitch together - how about working ml a pipeline end-to-end from an initial data",
    "start": "353810",
    "end": "360650"
  },
  {
    "text": "set that we have to ingest we have to analyze we have to transform and validate and split and then we have to",
    "start": "360650",
    "end": "367820"
  },
  {
    "text": "train an initial version of our model and validate that it works and maybe it",
    "start": "367820",
    "end": "373280"
  },
  {
    "text": "doesn't so we have to go back and train it again and modify it so it's an",
    "start": "373280",
    "end": "378290"
  },
  {
    "text": "iterative process and then we have to train at scale and when we have a model",
    "start": "378290",
    "end": "383720"
  },
  {
    "text": "that in train that scale and works you have to roll it out and serve it in production and then you have to monitor",
    "start": "383720",
    "end": "391039"
  },
  {
    "text": "it and then have a blog which progress and then we have to go back and fix things so from the initial data to",
    "start": "391039",
    "end": "398599"
  },
  {
    "text": "having a model running in production there is many steps and these steps",
    "start": "398599",
    "end": "404770"
  },
  {
    "text": "sometimes have to happen in different places and sometimes have to be executed by",
    "start": "404770",
    "end": "411410"
  },
  {
    "text": "different people different personas so",
    "start": "411410",
    "end": "416979"
  },
  {
    "text": "this becomes a very complex talk and it requires expertise in a multitude of",
    "start": "416979",
    "end": "423200"
  },
  {
    "text": "layers because it's not just the top layers that the data scientists or the",
    "start": "423200",
    "end": "430940"
  },
  {
    "text": "data engineer would care about it's not just the framework and the tooling and being you X and the model building it's",
    "start": "430940",
    "end": "437000"
  },
  {
    "text": "also the lower level things what about my runtime what my drivers my operating",
    "start": "437000",
    "end": "442190"
  },
  {
    "text": "system my GPUs the hardware we ran on how do i scale my infrastructure so this",
    "start": "442190",
    "end": "450890"
  },
  {
    "text": "is complicated enough but then given that different parts of the work flow will run in different places and you",
    "start": "450890",
    "end": "458960"
  },
  {
    "text": "need to replicate all this so what we talked about so far is the upper layers",
    "start": "458960",
    "end": "465490"
  },
  {
    "text": "if you have to replicate this for experimentation locally maybe on my",
    "start": "465490",
    "end": "471169"
  },
  {
    "text": "laptop and then to train at scale in some bigger infrastructure and then to",
    "start": "471169",
    "end": "477890"
  },
  {
    "text": "have the model running in production on the cloud I have to replicate all these layers how do I do that so the first",
    "start": "477890",
    "end": "486140"
  },
  {
    "text": "step is let's stop thinking about these lower level hard layers",
    "start": "486140",
    "end": "493570"
  },
  {
    "text": "let's get kubernetes to take care of them so kubernetes takes care of the low",
    "start": "493570",
    "end": "503599"
  },
  {
    "text": "level handling of the runtime so kubernetes is the platform on which I",
    "start": "503599",
    "end": "509659"
  },
  {
    "text": "run my machine learning so now I can move from location to location and from one kind of infrastructure to another",
    "start": "509659",
    "end": "516320"
  },
  {
    "text": "from one cloud provider to the other with Burnett as being the language in which I declare my",
    "start": "516320",
    "end": "521990"
  },
  {
    "text": "infrastructure and then let's get cook slow as the single way of the developing",
    "start": "521990",
    "end": "530959"
  },
  {
    "text": "deploying and managing machine learning on kubernetes so let's get could flow to",
    "start": "530959",
    "end": "536300"
  },
  {
    "text": "be the single language in which I describe kubernetes my machine learning",
    "start": "536300",
    "end": "541880"
  },
  {
    "text": "infrastructure so again kubernetes takes care of the lower-level stuff and then coop flow",
    "start": "541880",
    "end": "548540"
  },
  {
    "text": "becomes the language in which I declare the way I handle my steps in I'm island",
    "start": "548540",
    "end": "554300"
  },
  {
    "text": "mail workflow so coop flow becomes this part and then have coop flow everywhere so my job is much simpler I guess",
    "start": "554300",
    "end": "562370"
  },
  {
    "text": "kubernetes in notations and then I declare my machine learning",
    "start": "562370",
    "end": "567560"
  },
  {
    "text": "infrastructure using coop flow that's the basic premise behind control",
    "start": "567560",
    "end": "573160"
  },
  {
    "text": "okay so coop flow and kubernetes in our view are pivotal in enabling",
    "start": "573190",
    "end": "582199"
  },
  {
    "text": "next-generation machine learning and what do we mean by next-generation",
    "start": "582199",
    "end": "588740"
  },
  {
    "text": "machine learning we means the ability for distinct roles the data engineer the",
    "start": "588740",
    "end": "596360"
  },
  {
    "text": "data scientist the DevOps a person all interacting across rotations to make",
    "start": "596360",
    "end": "604190"
  },
  {
    "text": "this workflow function so we need collaboration we need different people",
    "start": "604190",
    "end": "610910"
  },
  {
    "text": "doing different parts of this workflow and still being able to collaborate in a",
    "start": "610910",
    "end": "617269"
  },
  {
    "text": "way that's reproducible whatever producer would mean that when someone has a step completed some other person",
    "start": "617269",
    "end": "624649"
  },
  {
    "text": "can they can hand it over to some other person some other person can take over their work and they can reproduce near",
    "start": "624649",
    "end": "630529"
  },
  {
    "text": "exact state so they can continue the the workflow we need a simple streamlined",
    "start": "630529",
    "end": "636260"
  },
  {
    "text": "unified workflow from the first pre-processing steps to developing the",
    "start": "636260",
    "end": "641750"
  },
  {
    "text": "model to training to get into production from my laptop to the cloud to the",
    "start": "641750",
    "end": "647690"
  },
  {
    "text": "autonomous car may be well the model relation will eventually run where inference will happen",
    "start": "647690",
    "end": "652970"
  },
  {
    "text": "and ideally in next generation and milk would like everything to execute fast so",
    "start": "652970",
    "end": "658819"
  },
  {
    "text": "the question comes where is the data for the steps to happen the data should be",
    "start": "658819",
    "end": "665269"
  },
  {
    "text": "ideal in local if I keep a data somewhere remote on a slow data Lake if",
    "start": "665269",
    "end": "671689"
  },
  {
    "text": "I depend on a single slow object store then no matter how many GPUs I have how",
    "start": "671689",
    "end": "677839"
  },
  {
    "text": "fast my infrastructure is I will be bound by data access latencies so this",
    "start": "677839",
    "end": "684560"
  },
  {
    "text": "is where we as a Richter coming to the picture and this is how this was the trigger for our involvement with cook",
    "start": "684560",
    "end": "691639"
  },
  {
    "text": "flock the question is how do you manage data for this ml workflow when this data",
    "start": "691639",
    "end": "700399"
  },
  {
    "text": "has to be in multiplication how do you manage data in a pipeline that runs",
    "start": "700399",
    "end": "706430"
  },
  {
    "text": "across locations because I'm a milk pipeline is as good as its data so I",
    "start": "706430",
    "end": "713329"
  },
  {
    "text": "will spend the next few minutes describing we are we come from a systems engineering background we work mostly on",
    "start": "713329",
    "end": "721339"
  },
  {
    "text": "data management for kubernetes our involvement with coop flow is",
    "start": "721339",
    "end": "726939"
  },
  {
    "text": "contributing code to it so coop flow manages data as kubernetes native",
    "start": "726939",
    "end": "733550"
  },
  {
    "text": "resources and then if coop flow Margie's",
    "start": "733550",
    "end": "738800"
  },
  {
    "text": "data as kubernetes native resources our software can sit on the side and provide",
    "start": "738800",
    "end": "745519"
  },
  {
    "text": "the efficient data management for these resources what we do explicitly is we",
    "start": "745519",
    "end": "752540"
  },
  {
    "text": "allow you to snapshot version package distribute and eventually share with",
    "start": "752540",
    "end": "758899"
  },
  {
    "text": "others your full environment your resources on coop flow along with their",
    "start": "758899",
    "end": "764240"
  },
  {
    "text": "data so this makes the pipeline the ML workflow work across teams across",
    "start": "764240",
    "end": "770930"
  },
  {
    "text": "locations and across different kinds of infrastructure on Prem or on the cloud",
    "start": "770930",
    "end": "776139"
  },
  {
    "text": "this is the overall idea in some sort of experimentation locally you",
    "start": "776139",
    "end": "783100"
  },
  {
    "text": "do it on your laptop so if you run control and coop flow is extended so it",
    "start": "783100",
    "end": "791410"
  },
  {
    "text": "becomes data where it stores your data on kubernetes objects named persistent",
    "start": "791410",
    "end": "797560"
  },
  {
    "text": "Bolden claims and then these persistent volume claims are stored on whatever",
    "start": "797560",
    "end": "802899"
  },
  {
    "text": "storage you happened to have local your local disk at some point but this is a",
    "start": "802899",
    "end": "807970"
  },
  {
    "text": "full single could flow way of describing your pipeline so you use the exact same",
    "start": "807970",
    "end": "815139"
  },
  {
    "text": "primitives at the exact same API to do your job and then when you're done you",
    "start": "815139",
    "end": "820540"
  },
  {
    "text": "are another person uses cook flow again to spin up the exact same pipeline on",
    "start": "820540",
    "end": "826899"
  },
  {
    "text": "another location for training on the Google cloud for example our software seeds are long kubernetes to enable this",
    "start": "826899",
    "end": "834579"
  },
  {
    "text": "kind of interruption so our contribution to tube flow is a two-fold we extend it",
    "start": "834579",
    "end": "840129"
  },
  {
    "text": "so it works over PVCs and then we use our software on the side of PVCs to",
    "start": "840129",
    "end": "847240"
  },
  {
    "text": "enable cross location collaboration this is the overall picture of what I will be",
    "start": "847240",
    "end": "852939"
  },
  {
    "text": "coming to you today what you get with this is a way to version packets and",
    "start": "852939",
    "end": "859689"
  },
  {
    "text": "distribute your data and then you can have a unified hybrid pipeline that",
    "start": "859689",
    "end": "865209"
  },
  {
    "text": "works both on Prem and on the cloud and because we work with snapshots because",
    "start": "865209",
    "end": "870819"
  },
  {
    "text": "when we move data we essentially snapshot the data you can always go back in time and see what the state of the",
    "start": "870819",
    "end": "877480"
  },
  {
    "text": "pipeline was so you can always reduce it and try again and come back to the exact",
    "start": "877480",
    "end": "884079"
  },
  {
    "text": "state where you were I've talked a bit",
    "start": "884079",
    "end": "889810"
  },
  {
    "text": "about these things but it's best if we can watch it live so this is the demo",
    "start": "889810",
    "end": "895510"
  },
  {
    "text": "that we'll be doing we have a machine learning pipeline same as I showed",
    "start": "895510",
    "end": "901480"
  },
  {
    "text": "before on crude flow we have two users Sarah which will be doing the experimentation part the data ingestion",
    "start": "901480",
    "end": "909130"
  },
  {
    "text": "and pre-processing part in location a and James who will be doing the training",
    "start": "909130",
    "end": "914470"
  },
  {
    "text": "part location B so you build a model and train it so given this and Mel pipeline Sarah",
    "start": "914470",
    "end": "924190"
  },
  {
    "text": "will live will essentially be doing these steps a bit shortened and James",
    "start": "924190",
    "end": "930400"
  },
  {
    "text": "will be doing these steps and for this we'll use an example that a cube flow",
    "start": "930400",
    "end": "936580"
  },
  {
    "text": "community has created called the github issue summarization example this example",
    "start": "936580",
    "end": "943150"
  },
  {
    "text": "is a machine learning pipeline where we get data from github issue data is she",
    "start": "943150",
    "end": "950290"
  },
  {
    "text": "text and the model tries to create a summary but describes the content of the",
    "start": "950290",
    "end": "956500"
  },
  {
    "text": "issues as good as possible so let's start with this I'll use two locations",
    "start": "956500",
    "end": "964540"
  },
  {
    "text": "this virtual desktop is location a he trans on Amazon in zone uswest",
    "start": "964540",
    "end": "971470"
  },
  {
    "text": "1a it runs coop flow on kubernetes and this desktop will be location B it runs",
    "start": "971470",
    "end": "979150"
  },
  {
    "text": "on Amazon again zone he West West is West one be running with Cooper",
    "start": "979150",
    "end": "985210"
  },
  {
    "text": "so this is where changes on B and this is where Sarah is on a so what does",
    "start": "985210",
    "end": "992080"
  },
  {
    "text": "Sarah do she uses coop flow she starts a Jupiter notebook a Jupiter notebook is",
    "start": "992080",
    "end": "999459"
  },
  {
    "text": "the a very well-known development environment for ml so she logs into",
    "start": "999459",
    "end": "1005360"
  },
  {
    "text": "Jupiter hub using coop flow and she will be creating her notebook okay so she",
    "start": "1005360",
    "end": "1015720"
  },
  {
    "text": "needs a development environment she'll use a standard image she requests",
    "start": "1015720",
    "end": "1023370"
  },
  {
    "text": "2 CPUs 8 gigabytes of memory what about",
    "start": "1023370",
    "end": "1029610"
  },
  {
    "text": "your data she'll have a simple workspace will she'll store your code and your",
    "start": "1029610",
    "end": "1035400"
  },
  {
    "text": "libraries mounted here and she'll also use a data volume let's call it become",
    "start": "1035400",
    "end": "1042900"
  },
  {
    "text": "Delta 10 gigabytes in size which will be mounted here so Sara will be managing",
    "start": "1042900",
    "end": "1049020"
  },
  {
    "text": "her data as another locally mounted filesystem this is backed by a persistent volume on kubernetes so Sara",
    "start": "1049020",
    "end": "1057000"
  },
  {
    "text": "creates your notebook so what happens here is Sara uses code flow to allocate",
    "start": "1057000",
    "end": "1062760"
  },
  {
    "text": "a new development environment for her do a map and this development environment",
    "start": "1062760",
    "end": "1068160"
  },
  {
    "text": "will be a jupiter notebook we give it some more time underneath what happens",
    "start": "1068160",
    "end": "1074820"
  },
  {
    "text": "is our cube flow asks kubernetes to create a new pod to serve Sara's",
    "start": "1074820",
    "end": "1082320"
  },
  {
    "text": "notebook and this user interface managing data volumes was one of the",
    "start": "1082320",
    "end": "1089370"
  },
  {
    "text": "first contributions will be to the Cupra project so this is",
    "start": "1089370",
    "end": "1096269"
  },
  {
    "text": "development environment she has data volume worship extortion data she has",
    "start": "1096269",
    "end": "1104759"
  },
  {
    "text": "the ability to start terminals or create notebooks so let's start a terminal and",
    "start": "1104759",
    "end": "1110539"
  },
  {
    "text": "what we'll do is a increase the font size a bit get it full screen also okay",
    "start": "1110539",
    "end": "1122929"
  },
  {
    "text": "so we will close the issue summarization",
    "start": "1122929",
    "end": "1131789"
  },
  {
    "text": "example from cook flow so Sarah brings",
    "start": "1131789",
    "end": "1138059"
  },
  {
    "text": "her code here this is your code okay and",
    "start": "1138059",
    "end": "1143119"
  },
  {
    "text": "this is where she bookstore her data this data volume is backed by a local",
    "start": "1143119",
    "end": "1152209"
  },
  {
    "text": "ephemeral nvme disk SSD on an amazon ec2 instance currently so Sarah stores as",
    "start": "1152209",
    "end": "1160320"
  },
  {
    "text": "fast as she can with minimum latency to a local disk so she can work as fast as",
    "start": "1160320",
    "end": "1165959"
  },
  {
    "text": "you can this could be her laptop even she is working on her laptop and storing to her local hard disk",
    "start": "1165959",
    "end": "1172770"
  },
  {
    "text": "okay so let's say Sarah needs to install a few missing libraries before she",
    "start": "1172770",
    "end": "1178510"
  },
  {
    "text": "starts so she can install mission missing libraries so she can do machine",
    "start": "1178510",
    "end": "1185980"
  },
  {
    "text": "learning inside your development environment and these libraries become",
    "start": "1185980",
    "end": "1194740"
  },
  {
    "text": "part of your development environment managed by cook flow and us so she can",
    "start": "1194740",
    "end": "1202780"
  },
  {
    "text": "install him libraries as well okay and",
    "start": "1202780",
    "end": "1208050"
  },
  {
    "text": "now she starts with a notebook we already have a notebook to start from we",
    "start": "1208050",
    "end": "1213640"
  },
  {
    "text": "won't be creating from we won't be creating it from scratch this is the",
    "start": "1213640",
    "end": "1219390"
  },
  {
    "text": "notebook we will be using so Sarah can now import shared libraries okay and now",
    "start": "1219390",
    "end": "1228700"
  },
  {
    "text": "what's the first part in animal pipeline Sarah wants to experiment so the very first part is let's get the data that",
    "start": "1228700",
    "end": "1236650"
  },
  {
    "text": "we're going to be using into our development environment let's ingest the data into the pipeline",
    "start": "1236650",
    "end": "1243750"
  },
  {
    "text": "so Sarah has this empty directory where",
    "start": "1243750",
    "end": "1249100"
  },
  {
    "text": "she will store your data mounted onto her pod she remembers it in a variable",
    "start": "1249100",
    "end": "1254710"
  },
  {
    "text": "and she uses W gate to fetch the issued",
    "start": "1254710",
    "end": "1260290"
  },
  {
    "text": "data as a big zip file somewhere from an external data lake so this is the first",
    "start": "1260290",
    "end": "1265990"
  },
  {
    "text": "data ingestion part and then once she's brought the data into her environment",
    "start": "1265990",
    "end": "1272890"
  },
  {
    "text": "she will also uncompress it she will unzip it so this is an initial data",
    "start": "1272890",
    "end": "1279220"
  },
  {
    "text": "transformation step so Sarah runs W gate",
    "start": "1279220",
    "end": "1285670"
  },
  {
    "text": "she goes to the external data leak register data into her environment",
    "start": "1285670",
    "end": "1290990"
  },
  {
    "text": "this is quite fast because all storage happens locally and then she unzips a",
    "start": "1290990",
    "end": "1308510"
  },
  {
    "text": "zip file to create our comma separated values file a CSV file this is not a",
    "start": "1308510",
    "end": "1316100"
  },
  {
    "text": "small data set this is a in the order of three gigabytes data sets let's take a",
    "start": "1316100",
    "end": "1321590"
  },
  {
    "text": "look so it's a one gigabyte compressed",
    "start": "1321590",
    "end": "1327560"
  },
  {
    "text": "file and it will expand to about 2.8 in",
    "start": "1327560",
    "end": "1332690"
  },
  {
    "text": "a box total so this is done Sarah",
    "start": "1332690",
    "end": "1340280"
  },
  {
    "text": "pretty quickly stored four gigabytes of data in her environment so going back to",
    "start": "1340280",
    "end": "1346750"
  },
  {
    "text": "all joys I keep clicking okay going back",
    "start": "1346750",
    "end": "1358610"
  },
  {
    "text": "the road book so sarah has unzipped the data she has done an initial",
    "start": "1358610",
    "end": "1364220"
  },
  {
    "text": "transformation step okay let's assume this is the first type of the pipeline",
    "start": "1364220",
    "end": "1369470"
  },
  {
    "text": "so let's assume sarah has completed that to the ingestion and analysis and transformation part okay now at this",
    "start": "1369470",
    "end": "1376850"
  },
  {
    "text": "point she may want to hand over her work to somebody else or she may want to take",
    "start": "1376850",
    "end": "1382550"
  },
  {
    "text": "a snapshot of her work so she can go back in time and review what she did",
    "start": "1382550",
    "end": "1388510"
  },
  {
    "text": "okay so for this because of data is stored on a compare method object a",
    "start": "1388510",
    "end": "1398920"
  },
  {
    "text": "persistent volume we can use our software to take a snapshot of the whole",
    "start": "1401170",
    "end": "1406220"
  },
  {
    "text": "infrastructure so let's take with two of our sofa this is rock this",
    "start": "1406220",
    "end": "1413710"
  },
  {
    "text": "is what runs alongside coupe flow and this integrated would cook flow so you",
    "start": "1413710",
    "end": "1418990"
  },
  {
    "text": "can manage your data across locations so this is Sarah's deployment on your local",
    "start": "1418990",
    "end": "1426100"
  },
  {
    "text": "infrastructure there is two buckets Sarah's bike it and James bucket buckets",
    "start": "1426100",
    "end": "1432640"
  },
  {
    "text": "is where we keep all user data snapshots of food environments let's have a look",
    "start": "1432640",
    "end": "1439450"
  },
  {
    "text": "in a previous budget this one for example it contains a few snapshots of",
    "start": "1439450",
    "end": "1445390"
  },
  {
    "text": "environments we took previously some time ago each environment is a snapshot",
    "start": "1445390",
    "end": "1452770"
  },
  {
    "text": "of the workspace volume where Sarah keeps her libraries and the data volume",
    "start": "1452770",
    "end": "1460320"
  },
  {
    "text": "for Sarah would keep your data so the Alice an environment snapshot is a group",
    "start": "1460320",
    "end": "1466810"
  },
  {
    "text": "of two snapshots a workspace snapshot and the data snapshot and then for each",
    "start": "1466810",
    "end": "1472240"
  },
  {
    "text": "environment we can have multiple versions so you can go back in time and",
    "start": "1472240",
    "end": "1478830"
  },
  {
    "text": "see what your environment looked like ten minutes ago 20 minutes ago or a week",
    "start": "1478830",
    "end": "1485890"
  },
  {
    "text": "ago so it's essentially a time machine for their full environment based on",
    "start": "1485890",
    "end": "1493240"
  },
  {
    "text": "snapshots and this is how we enable the pipeline to span multiple locations we",
    "start": "1493240",
    "end": "1500140"
  },
  {
    "text": "move the pipeline State from one location to another to allow to move from location to location so these are",
    "start": "1500140",
    "end": "1508540"
  },
  {
    "text": "these are pre-existing snapshots older ones let's see how Sarah can go into",
    "start": "1508540",
    "end": "1514870"
  },
  {
    "text": "here empty bucket no files here yet and ask for a full",
    "start": "1514870",
    "end": "1522750"
  },
  {
    "text": "snapshot of your environment so Sarah will snapchat your full lab she'll",
    "start": "1522750",
    "end": "1530550"
  },
  {
    "text": "snapshot both your workspace and the data this is essentially get like Sarah",
    "start": "1530550",
    "end": "1539160"
  },
  {
    "text": "commits her food environment into our software into Rock including the data",
    "start": "1539160",
    "end": "1545190"
  },
  {
    "text": "suggest landlord so ingress data",
    "start": "1545190",
    "end": "1552330"
  },
  {
    "text": "unzip into CSV ingress the entry date",
    "start": "1552330",
    "end": "1559730"
  },
  {
    "text": "run initial decompression step these are",
    "start": "1559730",
    "end": "1565050"
  },
  {
    "text": "notes she keeps for herself in the complete message okay I'm at this point what",
    "start": "1565050",
    "end": "1571560"
  },
  {
    "text": "happens is our software creates an a synchronous task that gets to the",
    "start": "1571560",
    "end": "1580250"
  },
  {
    "text": "kubernetes native objects the PVCs that Google has created and takes a snapshot",
    "start": "1580250",
    "end": "1586860"
  },
  {
    "text": "of them so we take a snapshot of whatever libraries she has created and",
    "start": "1586860",
    "end": "1594800"
  },
  {
    "text": "whatever data she has brought into her environment and it's interesting to note",
    "start": "1594800",
    "end": "1600720"
  },
  {
    "text": "that we do it thinly so we know what parts of the Degas it has changed who",
    "start": "1600720",
    "end": "1607020"
  },
  {
    "text": "have changed and we only read the changed part so if you look at the data",
    "start": "1607020",
    "end": "1612210"
  },
  {
    "text": "volume she has brought in more or less 4 Giga 4 gigabytes of data that's why",
    "start": "1612210",
    "end": "1618540"
  },
  {
    "text": "we're reading this many data pieces next time Sarah wants to take another",
    "start": "1618540",
    "end": "1625650"
  },
  {
    "text": "snapshot of your environment this is going to happen much faster because she won't have touched us much they go so we",
    "start": "1625650",
    "end": "1635040"
  },
  {
    "text": "give it some more time and click snap",
    "start": "1635040",
    "end": "1647280"
  },
  {
    "text": "ship is done so Sarah now has a full",
    "start": "1647280",
    "end": "1652560"
  },
  {
    "text": "snapshot of your environment at this point in time containing her data volume",
    "start": "1652560",
    "end": "1657930"
  },
  {
    "text": "and your library body this is it anak can continue now she can pre-process the",
    "start": "1657930",
    "end": "1667170"
  },
  {
    "text": "data okay so she will split the data into a training set and a test set we",
    "start": "1667170",
    "end": "1675540"
  },
  {
    "text": "will use a limited sample size of 200 samples so it executes is quite quickly",
    "start": "1675540",
    "end": "1683130"
  },
  {
    "text": "so this is the pre-processing part now running I gain these runs over in local",
    "start": "1683130",
    "end": "1691230"
  },
  {
    "text": "SSD so it's as fast as possible we read a full CSV file into memory and splitted",
    "start": "1691230",
    "end": "1700190"
  },
  {
    "text": "so we can ask Shoom that serve essentially runs the data splitting part here okay",
    "start": "1705620",
    "end": "1724290"
  },
  {
    "text": "this is a sample of our issues the data we are working with and then we do some",
    "start": "1724290",
    "end": "1731400"
  },
  {
    "text": "more conversion into data structures so we can continue with our training and",
    "start": "1731400",
    "end": "1738530"
  },
  {
    "text": "then we do pre-processing again following our notebook we import",
    "start": "1738530",
    "end": "1745680"
  },
  {
    "text": "libraries continue working instantiate a",
    "start": "1745680",
    "end": "1751620"
  },
  {
    "text": "text process or we have our text process or okay we have processed our data a",
    "start": "1751620",
    "end": "1761190"
  },
  {
    "text": "small sample of it anyway so it finishes quickly and now we'll serialize everything to",
    "start": "1761190",
    "end": "1767490"
  },
  {
    "text": "disk so at this point Sara will dump the pre-processed state into the data volume",
    "start": "1767490",
    "end": "1775460"
  },
  {
    "text": "she'll dump files into her mounted filesystem okay so this is the result of",
    "start": "1775460",
    "end": "1783560"
  },
  {
    "text": "the data pre-processing step so if server goes to the data body you see",
    "start": "1783560",
    "end": "1789900"
  },
  {
    "text": "that we have the original dataset at the zip file and zipped and then we have the result of the pre-processing step so at",
    "start": "1789900",
    "end": "1798780"
  },
  {
    "text": "this point Sara's done with the pre-processing step",
    "start": "1798780",
    "end": "1804230"
  },
  {
    "text": "she has a trainer already it's part of the notebook so we're done we now need",
    "start": "1804230",
    "end": "1809700"
  },
  {
    "text": "to build the model so we need to move the pipeline now so James can work James",
    "start": "1809700",
    "end": "1815250"
  },
  {
    "text": "has to start from where sara has left the pipeline or sara may need to come",
    "start": "1815250",
    "end": "1821430"
  },
  {
    "text": "back to this step if things fail and try over or modify a few parameters or try",
    "start": "1821430",
    "end": "1827190"
  },
  {
    "text": "out the new things try out some new things and she needs to do it in a way that retribution she needs to know",
    "start": "1827190",
    "end": "1833210"
  },
  {
    "text": "exactly what she did to reach this point so what Sara will do again after having",
    "start": "1833210",
    "end": "1839880"
  },
  {
    "text": "completed processing she will go and get another snapshot so she gets our software",
    "start": "1839880",
    "end": "1847510"
  },
  {
    "text": "snapchat her full environment again",
    "start": "1847510",
    "end": "1851770"
  },
  {
    "text": "pre-processed date disk so she has completed the",
    "start": "1852669",
    "end": "1862570"
  },
  {
    "text": "pre-processing step and she has done",
    "start": "1862570",
    "end": "1869750"
  },
  {
    "text": "toast a to this podium so she takes another snapshot this time the snapshot",
    "start": "1869750",
    "end": "1877400"
  },
  {
    "text": "will be way faster because she didn't actually touch all of your data we will",
    "start": "1877400",
    "end": "1883549"
  },
  {
    "text": "detect that she has only inserted new state in here volume the happy processed",
    "start": "1883549",
    "end": "1891200"
  },
  {
    "text": "data and this is done so now Sarah can go back either to this state or to her",
    "start": "1891200",
    "end": "1897559"
  },
  {
    "text": "previous state before starting to processing okay and now that we're here we can move the",
    "start": "1897559",
    "end": "1906559"
  },
  {
    "text": "pipeline to James so James will reproduce Sara's State in",
    "start": "1906559",
    "end": "1912980"
  },
  {
    "text": "another location and continue with building the model and training it so",
    "start": "1912980",
    "end": "1920240"
  },
  {
    "text": "Sara's done huge James James is on a",
    "start": "1920240",
    "end": "1926419"
  },
  {
    "text": "completely different zone completely different location AB doesn't actually",
    "start": "1926419",
    "end": "1932090"
  },
  {
    "text": "share anything with Sara they don't use",
    "start": "1932090",
    "end": "1937880"
  },
  {
    "text": "a single s3 as a data length exchange data say James won't go to Sara to find",
    "start": "1937880",
    "end": "1946789"
  },
  {
    "text": "the data he needs the data has already been synchronized locally for him by our",
    "start": "1946789",
    "end": "1953059"
  },
  {
    "text": "software so this is James's view of what's going on",
    "start": "1953059",
    "end": "1958930"
  },
  {
    "text": "this is the sarah bucket it already contains data on his side because our",
    "start": "1958930",
    "end": "1966460"
  },
  {
    "text": "software took care of synchronizing it here is more information on this this",
    "start": "1966460",
    "end": "1972130"
  },
  {
    "text": "packet Sarah actually has two connected peers two occasions one is James's",
    "start": "1972130",
    "end": "1980080"
  },
  {
    "text": "location one B the other is Sarah's location if three or four or five people",
    "start": "1980080",
    "end": "1987430"
  },
  {
    "text": "or five locations were involved you'd see five items here underneath we do",
    "start": "1987430",
    "end": "1994900"
  },
  {
    "text": "peer to peer synchronization of these buckets so you can have a pipeline that",
    "start": "1994900",
    "end": "1999970"
  },
  {
    "text": "extends to multiple locations and down locations synchronize data state with",
    "start": "1999970",
    "end": "2006690"
  },
  {
    "text": "peer to peer encrypted connections so James already has the data he needs this",
    "start": "2006690",
    "end": "2014460"
  },
  {
    "text": "is the day that he needs this is the latest snapshot if he looks into the file she will see that it has two",
    "start": "2014460",
    "end": "2021060"
  },
  {
    "text": "versions the original one right after bringing the data into the environment and the second one right after pre",
    "start": "2021060",
    "end": "2028380"
  },
  {
    "text": "processing the data so James can start from the latest snapshot get to his",
    "start": "2028380",
    "end": "2037610"
  },
  {
    "text": "instance of cook flow log into his distance of cook flow and pre initialize",
    "start": "2037610",
    "end": "2047580"
  },
  {
    "text": "the environment with whatever Sarah gave him so what I did was copy the mink to",
    "start": "2047580",
    "end": "2056520"
  },
  {
    "text": "Sara's snapshot from our software and give it to cook flow so it can proceed",
    "start": "2056520",
    "end": "2064850"
  },
  {
    "text": "so here's what change will start from James will start with two CPUs and eight",
    "start": "2064850",
    "end": "2071580"
  },
  {
    "text": "gigabytes of memory because we maintain all metadata for the environment",
    "start": "2071580",
    "end": "2076950"
  },
  {
    "text": "so it's reproducible James will have the exact same environment pads on kubernetes manage button flow James will",
    "start": "2076950",
    "end": "2085230"
  },
  {
    "text": "have access to Sara's workspace so she'll see the exact same libraries",
    "start": "2085230",
    "end": "2090408"
  },
  {
    "text": "unchanged we'll also see the exact same data right before Sara took the snapshot",
    "start": "2090409",
    "end": "2095908"
  },
  {
    "text": "Sara can continue to work in her local infrastructure can continue to produce",
    "start": "2095909",
    "end": "2103019"
  },
  {
    "text": "snapshots and James can continue with his branch of the environment so this is",
    "start": "2103019",
    "end": "2109950"
  },
  {
    "text": "essentially the combination of coop flow plus rock our software is get full data",
    "start": "2109950",
    "end": "2116010"
  },
  {
    "text": "and your Holdeman environment so James spawns the environment we wait",
    "start": "2116010",
    "end": "2124049"
  },
  {
    "text": "for a few seconds underneath coop Flo asks kubernetes to create the pods the",
    "start": "2124049",
    "end": "2130859"
  },
  {
    "text": "pod to support his environment the data will be stored on our kubernetes",
    "start": "2130859",
    "end": "2138390"
  },
  {
    "text": "persistent volumes this took no more",
    "start": "2138390",
    "end": "2143430"
  },
  {
    "text": "than 120 seconds",
    "start": "2143430",
    "end": "2147410"
  },
  {
    "text": "let's give it some more time okay so",
    "start": "2160060",
    "end": "2185970"
  },
  {
    "text": "this is James's clove of the environment and we see the environment is already",
    "start": "2185970",
    "end": "2193480"
  },
  {
    "text": "initialized so he has reproduced several state her code is here data is here both",
    "start": "2193480",
    "end": "2205480"
  },
  {
    "text": "the original data set and the pre-processed data so he can pick up and",
    "start": "2205480",
    "end": "2211750"
  },
  {
    "text": "continue the pipeline from where Sara left so what did James do now chill",
    "start": "2211750",
    "end": "2221560"
  },
  {
    "text": "train so let me increase the font size",
    "start": "2221560",
    "end": "2231960"
  },
  {
    "text": "engage screen okay so James knows where",
    "start": "2231960",
    "end": "2243760"
  },
  {
    "text": "the notebooks lead and he can see the data this is our four gigabytes of data",
    "start": "2243760",
    "end": "2252360"
  },
  {
    "text": "and now James will use a trainer a training module in Python to train his",
    "start": "2252360",
    "end": "2260260"
  },
  {
    "text": "model this is the training module and it needs some information so James",
    "start": "2260260",
    "end": "2268910"
  },
  {
    "text": "would just use the local file that he conceived this is the input data and he",
    "start": "2268910",
    "end": "2276109"
  },
  {
    "text": "won't be doing any pre-processing because we've already done it doesn't",
    "start": "2276109",
    "end": "2281269"
  },
  {
    "text": "need to use in temporary directories he'll just train the module into this",
    "start": "2281269",
    "end": "2286849"
  },
  {
    "text": "file for sample size of 200 issues because the sample size that Sarah gives",
    "start": "2286849",
    "end": "2294230"
  },
  {
    "text": "during pre-processing so now James grant runs training on a",
    "start": "2294230",
    "end": "2300069"
  },
  {
    "text": "different location which could be the cloud using GPUs",
    "start": "2300069",
    "end": "2305240"
  },
  {
    "text": "maybe we have extended the ML pipeline from service location into James's",
    "start": "2305240",
    "end": "2311329"
  },
  {
    "text": "rotations to run training put different hardware or maybe at scale so James uses",
    "start": "2311329",
    "end": "2320960"
  },
  {
    "text": "the pre-processed data to train the model we're only using a very small sample size or training she can click",
    "start": "2320960",
    "end": "2328039"
  },
  {
    "text": "quickly okay and this is the trend model",
    "start": "2328039",
    "end": "2341230"
  },
  {
    "text": "so James has completed training and then",
    "start": "2341230",
    "end": "2346359"
  },
  {
    "text": "how can this continue two options James could spawn a distributed job",
    "start": "2346359",
    "end": "2355130"
  },
  {
    "text": "right from within the notebook using the same primitive using a snapshot of his",
    "start": "2355130",
    "end": "2362390"
  },
  {
    "text": "environment to power the distributed our training job so he can submit a cook",
    "start": "2362390",
    "end": "2369589"
  },
  {
    "text": "flow tensorflow job object to start a distributed jug or",
    "start": "2369589",
    "end": "2375400"
  },
  {
    "text": "and then this is what we'll do now she can take a snapshot of his food environment including the model so he",
    "start": "2375400",
    "end": "2384410"
  },
  {
    "text": "can give it to sir or some other collaborator maybe a production person",
    "start": "2384410",
    "end": "2390640"
  },
  {
    "text": "who would try it out and deploy it to production",
    "start": "2390640",
    "end": "2395349"
  },
  {
    "text": "so again now that the model is done",
    "start": "2395779",
    "end": "2403309"
  },
  {
    "text": "James can go here and request this is",
    "start": "2403309",
    "end": "2410039"
  },
  {
    "text": "his bucket request a snapshot of his",
    "start": "2410039",
    "end": "2415469"
  },
  {
    "text": "environment training the model so he",
    "start": "2415469",
    "end": "2422579"
  },
  {
    "text": "keeps a note train the model something size equals 200 model is in this file okay and again",
    "start": "2422579",
    "end": "2434849"
  },
  {
    "text": "this will start a new snapshot job in our software super fast so at this point",
    "start": "2434849",
    "end": "2443119"
  },
  {
    "text": "James is snapshotting around 5 gigabytes of data but this happens very quickly",
    "start": "2443119",
    "end": "2448319"
  },
  {
    "text": "because the software keeps track of what has changed so again",
    "start": "2448319",
    "end": "2458930"
  },
  {
    "text": "location B we move back location a and",
    "start": "2458930",
    "end": "2464470"
  },
  {
    "text": "Sarah can go to James's bucket and she can see but here is the data but James",
    "start": "2464500",
    "end": "2473450"
  },
  {
    "text": "just purchased so the snapshot that James took has been synchronized back to",
    "start": "2473450",
    "end": "2478760"
  },
  {
    "text": "Sarah's location so she can continue she can iterate on the model within seconds",
    "start": "2478760",
    "end": "2485500"
  },
  {
    "text": "so we are kind of yeah exactly when the",
    "start": "2487869",
    "end": "2494359"
  },
  {
    "text": "presentation should finish I'll stop the demo here so we also have some time for questions I'll hand it over to Kate name",
    "start": "2494359",
    "end": "2501410"
  },
  {
    "text": "for this awesome thanks so much for the presentation so we do have some time for",
    "start": "2501410",
    "end": "2507890"
  },
  {
    "text": "Q&A right now so just a reminder there is a Q&A box at the bottom of your screen so please drop your questions in",
    "start": "2507890",
    "end": "2515510"
  },
  {
    "text": "there and then we'll get to as many as we have time for so a few questions have",
    "start": "2515510",
    "end": "2521059"
  },
  {
    "text": "come in during the presentation um how is ROK authenticated to get access to Sara's volumes this is a good question",
    "start": "2521059",
    "end": "2530660"
  },
  {
    "text": "okay so Rach manages Sara's volumes Rock",
    "start": "2530660",
    "end": "2536960"
  },
  {
    "text": "is integrated with kubernetes as what it's called a CSI plugin so whenever our",
    "start": "2536960",
    "end": "2545720"
  },
  {
    "text": "coop flow requests new volumes it asks Rock to create them to manage them so",
    "start": "2545720",
    "end": "2553130"
  },
  {
    "text": "the question is the reverse how does the Kukla user interface the Spooner",
    "start": "2553130",
    "end": "2560059"
  },
  {
    "text": "interface this interface right here let me destroy certain environment and show you the question is destroy the in the",
    "start": "2560059",
    "end": "2572750"
  },
  {
    "text": "interface anyway I have to destroy it either we have to stir them in order to",
    "start": "2572750",
    "end": "2579349"
  },
  {
    "text": "show you the question is how does the crew flow user interface authenticate itself to rock so it has access to its",
    "start": "2579349",
    "end": "2586190"
  },
  {
    "text": "snapshot we maintain secrets in kubernetes Sara maintains",
    "start": "2586190",
    "end": "2592400"
  },
  {
    "text": "our own secrets in kubernetes giving access to whatever tokens Rock needs for",
    "start": "2592400",
    "end": "2600529"
  },
  {
    "text": "coop flow to access it so the very first time Sara will access the control environment she'll see a warning message",
    "start": "2600529",
    "end": "2607460"
  },
  {
    "text": "that says this could flow deployment is not authenticated access Rock please go",
    "start": "2607460",
    "end": "2612829"
  },
  {
    "text": "to rock get your tokens and insert them as a secret in kubernetes accessible by",
    "start": "2612829",
    "end": "2619460"
  },
  {
    "text": "the coop flow user interface so cook flow can access rock so it's not Rock accessing service volumes it's Sara",
    "start": "2619460",
    "end": "2627349"
  },
  {
    "text": "crude flow accessing rock bottom's does",
    "start": "2627349",
    "end": "2633200"
  },
  {
    "text": "this answer the question back and forth missions yes yes if you want any",
    "start": "2633200",
    "end": "2638750"
  },
  {
    "text": "information on any other questions that we're answering please drop the follow-up question in the Q&A and we'll get back to it another one what does the",
    "start": "2638750",
    "end": "2647150"
  },
  {
    "text": "trained Python script run okay that's a good question we didn't go into the ml specifics the",
    "start": "2647150",
    "end": "2656869"
  },
  {
    "text": "this repository the cube flow examples repository is open on the web so you can",
    "start": "2656869",
    "end": "2662660"
  },
  {
    "text": "either download the original version by the cook flow community or our version accessible here and see exactly what the",
    "start": "2662660",
    "end": "2672049"
  },
  {
    "text": "script does the the training code is all available right here ok this is the",
    "start": "2672049",
    "end": "2684980"
  },
  {
    "text": "vagina so it cleans the model and trains it but I'm not familiar with the immense",
    "start": "2684980",
    "end": "2690049"
  },
  {
    "text": "specifics alright so the demo makes it",
    "start": "2690049",
    "end": "2698839"
  },
  {
    "text": "look like the same blocks are stored twice once for Sara and once for James is that a common thing to do mm-hmm okay",
    "start": "2698839",
    "end": "2709119"
  },
  {
    "text": "so the question is Sarah James work in",
    "start": "2709119",
    "end": "2715099"
  },
  {
    "text": "different locations okay seven James work completely dependent",
    "start": "2715099",
    "end": "2722940"
  },
  {
    "text": "Sara works on her laptop and James may be working on the cloud would they be able to use the exact same block storage",
    "start": "2722940",
    "end": "2730230"
  },
  {
    "text": "would it make sense for James to to have the impact of latency to go all the way",
    "start": "2730230",
    "end": "2737550"
  },
  {
    "text": "to service laptop would he be able to go do it the service laptop to actually fetch the same blocks",
    "start": "2737550",
    "end": "2742590"
  },
  {
    "text": "so if seven James are working on the same location that can actually be actually the exact same blocks but if",
    "start": "2742590",
    "end": "2749130"
  },
  {
    "text": "you're working across locations then the question becomes does your code Traverse",
    "start": "2749130",
    "end": "2754830"
  },
  {
    "text": "regions to find its data in another data leg if you're on an account if you're in",
    "start": "2754830",
    "end": "2762150"
  },
  {
    "text": "an autonomous in an autonomous car do you actually multiply to find your data this example and our approach is let's",
    "start": "2762150",
    "end": "2770700"
  },
  {
    "text": "bring the data set close to where the compute part runs let's have the data",
    "start": "2770700",
    "end": "2776940"
  },
  {
    "text": "set be the globally accessible resource refer to it and synchronize it locally",
    "start": "2776940",
    "end": "2783080"
  },
  {
    "text": "whenever they snapshot they don't create new blocks locally write all the",
    "start": "2783080",
    "end": "2788730"
  },
  {
    "text": "snapshots locally maintain a shared set of blocks but yes when talking about",
    "start": "2788730",
    "end": "2795570"
  },
  {
    "text": "distinct locations because we actually want locations to be independent in",
    "start": "2795570",
    "end": "2801540"
  },
  {
    "text": "terms of security and speed we maintain two distinct sets of blocks one for",
    "start": "2801540",
    "end": "2808440"
  },
  {
    "text": "location a 1/4 location B all right so",
    "start": "2808440",
    "end": "2819300"
  },
  {
    "text": "is there a concept of teams for example so that by default anyone in the team has access to the volumes of other",
    "start": "2819300",
    "end": "2826160"
  },
  {
    "text": "members of the team for example to enable access cleanup when a member leaves I didn't show it we have we have",
    "start": "2826160",
    "end": "2837300"
  },
  {
    "text": "what we call the rock registry the single hub where all locations",
    "start": "2837300",
    "end": "2843710"
  },
  {
    "text": "essentially discover one another because one question I didn't really go into is how did Sarah's bucket get to be",
    "start": "2843710",
    "end": "2851550"
  },
  {
    "text": "synchronized with James's Park how did the bucket Sara on Sara's infrastructure come to be synchronized",
    "start": "2851550",
    "end": "2857620"
  },
  {
    "text": "with budget Sara on James's infrastructure so what they did is they went through a publish and subscribe",
    "start": "2857620",
    "end": "2863550"
  },
  {
    "text": "step on a single datum cog that we",
    "start": "2863550",
    "end": "2869470"
  },
  {
    "text": "called the rock registry so on the rock registry you can define organizations similarly to how you would define",
    "start": "2869470",
    "end": "2875650"
  },
  {
    "text": "organizations on github you can share your your buckets your datasets with",
    "start": "2875650",
    "end": "2881260"
  },
  {
    "text": "whole organizations and then if a person leaves the organization whatever",
    "start": "2881260",
    "end": "2886650"
  },
  {
    "text": "infrastructure is authorized by them to access this data is automatically thrown",
    "start": "2886650",
    "end": "2892240"
  },
  {
    "text": "out of the synchronization storms so you can have members of the team leaving the",
    "start": "2892240",
    "end": "2897670"
  },
  {
    "text": "team you can have new members of the team joining into the team and then the",
    "start": "2897670",
    "end": "2902880"
  },
  {
    "text": "peer to peer synchronization is authentic is updated to take into",
    "start": "2902880",
    "end": "2910270"
  },
  {
    "text": "account your changes to team members and then this is also a very good comment",
    "start": "2910270",
    "end": "2916000"
  },
  {
    "text": "that I see on the Q&A panel snapshotting is not just for sharing yes it's for versioning even if you're local",
    "start": "2916000",
    "end": "2923170"
  },
  {
    "text": "somewhere if you maintain multiple snapshots of your own environment even",
    "start": "2923170",
    "end": "2928540"
  },
  {
    "text": "if you share with no one else even if you're using just a single local data Lake it makes sense to be able to smash",
    "start": "2928540",
    "end": "2936430"
  },
  {
    "text": "up your environment because this is essentially an immutable deep like",
    "start": "2936430",
    "end": "2941730"
  },
  {
    "text": "timeline to your work so when something goes bad because not everything happens",
    "start": "2941730",
    "end": "2946860"
  },
  {
    "text": "perfectly with the very first trial you can go back in time and reproduce your",
    "start": "2946860",
    "end": "2952330"
  },
  {
    "text": "work so sharing this immutable timeline across data centers is an extra point is",
    "start": "2952330",
    "end": "2961120"
  },
  {
    "text": "an extra value added thing that we do but even if we you keep this inside a",
    "start": "2961120",
    "end": "2966160"
  },
  {
    "text": "single data center it makes sense to work with snapshots to maintain an immutable timeline of your steps alright",
    "start": "2966160",
    "end": "2977350"
  },
  {
    "text": "there's a couple more that we you yeah there's a couple to get to from the chat that we answered",
    "start": "2977350",
    "end": "2984690"
  },
  {
    "text": "in there but I want to get to them live as well is the snapshot stored locally",
    "start": "2984690",
    "end": "2994579"
  },
  {
    "text": "is the snapshot stored locally okay rock",
    "start": "2994579",
    "end": "3001960"
  },
  {
    "text": "so for each individual location rock",
    "start": "3001960",
    "end": "3007640"
  },
  {
    "text": "needs some sort of persistent store for",
    "start": "3007640",
    "end": "3012829"
  },
  {
    "text": "long-term archival of its the duplicated blocks so all the live volumes are",
    "start": "3012829",
    "end": "3020059"
  },
  {
    "text": "stored on kubernetes persistent problems so they're stored on local SSDs even",
    "start": "3020059",
    "end": "3025940"
  },
  {
    "text": "super fast that can't get any faster than that but when you snapshot rock the",
    "start": "3025940",
    "end": "3031190"
  },
  {
    "text": "duplicates your data and needs up an archival place where it stores your data in the long run and this is different",
    "start": "3031190",
    "end": "3039019"
  },
  {
    "text": "for each location so each location is completely dependent from other locations and that's how you can scale",
    "start": "3039019",
    "end": "3044869"
  },
  {
    "text": "to potentially hundreds of locations that's how this can work across a few thousands of autonomous cars running on",
    "start": "3044869",
    "end": "3052039"
  },
  {
    "text": "the roads right so you need some sort of local storage storage local to the",
    "start": "3052039",
    "end": "3058249"
  },
  {
    "text": "region to store your archive blocks if you're on Amazon we use whatever local s3 instance you",
    "start": "3058249",
    "end": "3067160"
  },
  {
    "text": "have so if you on us west 1a we use the s3 region us West one if you're in",
    "start": "3067160",
    "end": "3074690"
  },
  {
    "text": "another region we use us three for this region if you're on Google Cloud we use Google object storage if you're",
    "start": "3074690",
    "end": "3081680"
  },
  {
    "text": "your laptop we use part of your local disk a local directory if you're on",
    "start": "3081680",
    "end": "3088549"
  },
  {
    "text": "on-prem kubernetes we just find with using Mineo for example as an s3",
    "start": "3088549",
    "end": "3094130"
  },
  {
    "text": "endpoint to store the archive data so we just need some sort of local or tribal",
    "start": "3094130",
    "end": "3099710"
  },
  {
    "text": "endpoint will restore that the duplicated chunks out of which we form",
    "start": "3099710",
    "end": "3107329"
  },
  {
    "text": "the virtual snapshots",
    "start": "3107329",
    "end": "3110890"
  },
  {
    "text": "all right and then another question could you talk a little bit about how rock is different from something like",
    "start": "3114000",
    "end": "3119980"
  },
  {
    "text": "rock or port works okay I like the questions where they're very focused exactly the questions we would",
    "start": "3119980",
    "end": "3128410"
  },
  {
    "text": "like to talk about so Luke is a great project for orchestrating storage",
    "start": "3128410",
    "end": "3135730"
  },
  {
    "text": "locally Luke can create a safe cluster",
    "start": "3135730",
    "end": "3142320"
  },
  {
    "text": "pretty easily locally so you can ask it I need safe to store my local golems okay",
    "start": "3142320",
    "end": "3149050"
  },
  {
    "text": "so Luke will give you a local safe plaster then you can have local problems so part of our work with coop flow is",
    "start": "3149050",
    "end": "3158320"
  },
  {
    "text": "getting coop flow to use local persistent volumes so in this case coop",
    "start": "3158320",
    "end": "3164140"
  },
  {
    "text": "flow would use safe volumes managed by Luke to store the data but then how",
    "start": "3164140",
    "end": "3174220"
  },
  {
    "text": "would you snapshot these volumes so you can go back in time you could use safe",
    "start": "3174220",
    "end": "3181780"
  },
  {
    "text": "snapshots maybe or you could use our software alongside safe volumes to",
    "start": "3181780",
    "end": "3191770"
  },
  {
    "text": "maintain these snapshots because once we maintain these snapshots in our own",
    "start": "3191770",
    "end": "3197980"
  },
  {
    "text": "format then we can take these snapshots and synchronize them in a peer-to-peer",
    "start": "3197980",
    "end": "3203950"
  },
  {
    "text": "network across tens or hundreds of locations because if you use route to",
    "start": "3203950",
    "end": "3209710"
  },
  {
    "text": "manage a local safe cluster how do you then synchronize the content of this",
    "start": "3209710",
    "end": "3215080"
  },
  {
    "text": "safe cluster with other surf casters you may do and most storage technologies do",
    "start": "3215080",
    "end": "3220900"
  },
  {
    "text": "this kind of PA of point-to-point master-slave replication right you can",
    "start": "3220900",
    "end": "3226690"
  },
  {
    "text": "have a primary site on the secondary side and you can be synchronizing your",
    "start": "3226690",
    "end": "3232690"
  },
  {
    "text": "volumes from one side to the other but this essentially means that the two",
    "start": "3232690",
    "end": "3238359"
  },
  {
    "text": "sides trust one another and this also means that it's not the user",
    "start": "3238359",
    "end": "3245090"
  },
  {
    "text": "who's in control of the synchronization process it's the administrator who has set it up explicitly our approach is",
    "start": "3245090",
    "end": "3252770"
  },
  {
    "text": "let's make the data a kubernetes managed",
    "start": "3252770",
    "end": "3257860"
  },
  {
    "text": "resource something that the users themselves can actually refer to and then let's allow the users to specify",
    "start": "3257860",
    "end": "3266380"
  },
  {
    "text": "what gets accessed where ruk manages",
    "start": "3266380",
    "end": "3272630"
  },
  {
    "text": "primary storage we do not target primary storage we do not store your data so if",
    "start": "3272630",
    "end": "3281000"
  },
  {
    "text": "you take a look at this part of the presentation we assume that there is",
    "start": "3281000",
    "end": "3289070"
  },
  {
    "text": "some way to store data locally PVCs this is our contribution can flow making",
    "start": "3289070",
    "end": "3294260"
  },
  {
    "text": "could flow work or PVCs so this could be route unsafe provided PVCs also and this could be route any",
    "start": "3294260",
    "end": "3302480"
  },
  {
    "text": "storage and then our software sits on the side and keeps track of what has",
    "start": "3302480",
    "end": "3308810"
  },
  {
    "text": "been changed and maintains immutable snapshots and then synchronizes these snapshots and this is the the this is",
    "start": "3308810",
    "end": "3318260"
  },
  {
    "text": "the same answer as with port works hardwood this compare to port works port hooks is a very fast very nice way of",
    "start": "3318260",
    "end": "3326240"
  },
  {
    "text": "managing primary storage on a kubernetes cluster but then how do you move from",
    "start": "3326240",
    "end": "3332570"
  },
  {
    "text": "one location to another how do you synchronize locations that ran different kinds of storage maybe that's our",
    "start": "3332570",
    "end": "3340510"
  },
  {
    "text": "approach given our software on the side of what table primary storage you run on",
    "start": "3340510",
    "end": "3345950"
  },
  {
    "text": "each location we maintain snapshots we expose them as user accessible resources",
    "start": "3345950",
    "end": "3351770"
  },
  {
    "text": "and we synchronize them independently of whatever primary storage stars all right",
    "start": "3351770",
    "end": "3362240"
  },
  {
    "text": "before we run out of time are there api's to programmatically snapshot the work space and/or volumes that will",
    "start": "3362240",
    "end": "3369859"
  },
  {
    "text": "allow a CT CD pipeline with minimal manual intervention okay so I didn't",
    "start": "3369859",
    "end": "3376310"
  },
  {
    "text": "have a chance to show it I can show it now yes there are whatever you see here is actually API driven so the ROC user",
    "start": "3376310",
    "end": "3384680"
  },
  {
    "text": "interface is actually am API client so whatever you can do from the user",
    "start": "3384680",
    "end": "3390349"
  },
  {
    "text": "interface you can do programmatically exactly because and this is our next step and this is what we will be demoing",
    "start": "3390349",
    "end": "3396560"
  },
  {
    "text": "next is running an automated pipeline system like OOP flow pipelines or our go",
    "start": "3396560",
    "end": "3403390"
  },
  {
    "text": "over our snapshots so you can have two visibility on whatever the output of one",
    "start": "3403390",
    "end": "3410270"
  },
  {
    "text": "step is and whatever the output of another step is so you can go to each individual step of a pipeline and say",
    "start": "3410270",
    "end": "3416390"
  },
  {
    "text": "what is this step do why did have a simple and what it produces out can",
    "start": "3416390",
    "end": "3421580"
  },
  {
    "text": "actually mount its input and its output so I can very easily have first-hand experience with what happened this is",
    "start": "3421580",
    "end": "3427910"
  },
  {
    "text": "great for debugging by the way it's full visibility into all steps of a pipeline by being able to retrace whatever every",
    "start": "3427910",
    "end": "3437000"
  },
  {
    "text": "step did by mounting it's immutable input and it's snapshot at the middle",
    "start": "3437000",
    "end": "3443210"
  },
  {
    "text": "block so let me show it this is James inside his environment and he can",
    "start": "3443210",
    "end": "3450170"
  },
  {
    "text": "actually access rock programmatically and say let me get my notes for this",
    "start": "3450170",
    "end": "3457970"
  },
  {
    "text": "though and he can say let me create a",
    "start": "3457970",
    "end": "3464030"
  },
  {
    "text": "new snapshot of my environment inside the James budget and at this point this",
    "start": "3464030",
    "end": "3474260"
  },
  {
    "text": "is an API call that we do to rock so this is the same thing that the user",
    "start": "3474260",
    "end": "3480380"
  },
  {
    "text": "interface would show but in a text r2 in CLI tool so demoing API driven snapshots",
    "start": "3480380",
    "end": "3491080"
  },
  {
    "text": "okay just taking us using the API okay so we submit this to",
    "start": "3491080",
    "end": "3498710"
  },
  {
    "text": "kubernetes and again I see a light - so totally",
    "start": "3498710",
    "end": "3504530"
  },
  {
    "text": "automated takes a snapshot of James's environment and if we go into so this is",
    "start": "3504530",
    "end": "3511760"
  },
  {
    "text": "happening right now right I switch to the visual interface and there's a new task that's actually progressing so I",
    "start": "3511760",
    "end": "3518090"
  },
  {
    "text": "used the API here to create a new task programmatically and this task is what",
    "start": "3518090",
    "end": "3525020"
  },
  {
    "text": "is running here and this task is almost",
    "start": "3525020",
    "end": "3530930"
  },
  {
    "text": "done this task is almost almost done this task is done and yes this task is",
    "start": "3530930",
    "end": "3538970"
  },
  {
    "text": "done here the emitter boolean's I can use to access my snapshot and this is it",
    "start": "3538970",
    "end": "3545600"
  },
  {
    "text": "I cannot take this identifier and this is an immutable permanent identifier that I can use to access my snapshot so",
    "start": "3545600",
    "end": "3553580"
  },
  {
    "text": "I can use it in pipelines programmatically I hope this answers the question awesome thank you and thank you",
    "start": "3553580",
    "end": "3562850"
  },
  {
    "text": "all for those great questions that brings us to the end of our time today so once again thank you so much Vangelis",
    "start": "3562850",
    "end": "3570109"
  },
  {
    "text": "for the great presentation in to all of our attendees just as a reminder the webinar recording and slides will be",
    "start": "3570109",
    "end": "3575750"
  },
  {
    "text": "online later today I mean we look forward to seeing you all in the future ciancia webinar thank you thank you for giving",
    "start": "3575750",
    "end": "3581390"
  },
  {
    "text": "me the chance to present thanks everyone have a great day",
    "start": "3581390",
    "end": "3585970"
  }
]
[
  {
    "text": "hello everyone so um by the way I do speak Chinese so if you guys want to talk to me after that in in Chinese",
    "start": "199",
    "end": "6040"
  },
  {
    "text": "that's fine but since I see you know um as non-chinese faces I suppose I should",
    "start": "6040",
    "end": "11799"
  },
  {
    "text": "speak English in this talk all right so my name is Michael Y and uh I'm the",
    "start": "11799",
    "end": "17359"
  },
  {
    "text": "maintainer of uh cnf's w m project so um the the title of this talk is wrong",
    "start": "17359",
    "end": "23599"
  },
  {
    "text": "large language model agents on self-hosted devices so there are lots of questions why do you want to do that and",
    "start": "23599",
    "end": "30439"
  },
  {
    "text": "how do we do that but before we start anything else let's start with the demo I think because you know in the early",
    "start": "30439",
    "end": "36600"
  },
  {
    "text": "afternoon it's probably the easiest way to keep you guys awake right you know that's uh you know to see a a large",
    "start": "36600",
    "end": "43280"
  },
  {
    "text": "language model running on this computer you know this you know this uh when I bought this",
    "start": "43280",
    "end": "49520"
  },
  {
    "text": "computer um in the middle of the pandemic about two years ago three years ago you know my um you know my my",
    "start": "49520",
    "end": "56359"
  },
  {
    "text": "assistant asked me you know how much memory do you need um I said you know I just I only do word processing and do",
    "start": "56359",
    "end": "63239"
  },
  {
    "text": "some writing some code uh video studio and you know things like that so I only need a very slow uh low configuration",
    "start": "63239",
    "end": "69479"
  },
  {
    "text": "the Mac is overpowered for me and that was a huge mistake because you know now we run large language model and the one",
    "start": "69479",
    "end": "75680"
  },
  {
    "text": "thing that needs is memory so you know so we had um so we have to have much larger computers to run large language",
    "start": "75680",
    "end": "82159"
  },
  {
    "text": "model but I want to show you that even with this computer that's only has uh uh 16 GB of memory that we can run a large",
    "start": "82159",
    "end": "89640"
  },
  {
    "text": "l a very capable large language model at reasonable speed so um I believe this p uh this this um",
    "start": "89640",
    "end": "98439"
  },
  {
    "text": "this PBT should be available you know um uh on the website soon after this talk um so I listed the command those the the",
    "start": "98439",
    "end": "107079"
  },
  {
    "text": "whole process of running a large language model on your computer really fits into one PowerPoint slide you know",
    "start": "107079",
    "end": "113439"
  },
  {
    "text": "that's all there is there's four steps right so I going to go through those steps um but because I have very slow",
    "start": "113439",
    "end": "119600"
  },
  {
    "text": "Wi-Fi here so I'll not attempt to uh download the larg language model here right here because you know I made a",
    "start": "119600",
    "end": "125920"
  },
  {
    "text": "mistake um in cucon EU you know when I ask the all audience to download the large language model and immediately",
    "start": "125920",
    "end": "131920"
  },
  {
    "text": "crash to the entire conference Wi-Fi you know because you know each of this model is like 5 gigabytes right it's like a",
    "start": "131920",
    "end": "137560"
  },
  {
    "text": "full siiz movie right so you know um so there uh there are a couple steps the",
    "start": "137560",
    "end": "142959"
  },
  {
    "text": "first um I know it's it's kind of fun to see but the first is a curl command and",
    "start": "142959",
    "end": "148319"
  },
  {
    "text": "download a script and run through bash okay what it does is install uh waset",
    "start": "148319",
    "end": "154640"
  },
  {
    "text": "dra time U why do we need that I going to get to that later but um the very",
    "start": "154640",
    "end": "159840"
  },
  {
    "text": "important thing to notice is that there's no python dependency you don't need python or pytorch or anything like",
    "start": "159840",
    "end": "165640"
  },
  {
    "text": "that the whole package is about 20 megabytes okay so if you think about",
    "start": "165640",
    "end": "170800"
  },
  {
    "text": "running a large language model in py torch the doer image itself is 4 GB to 8",
    "start": "170800",
    "end": "176360"
  },
  {
    "text": "GB depending on what version of GPU drivers that you have okay okay so right here we have 20 megab versus 4 GB of",
    "start": "176360",
    "end": "183720"
  },
  {
    "text": "stuff of of the WR time so the first step is download and install software which I I have already done on my",
    "start": "183720",
    "end": "189560"
  },
  {
    "text": "computer and uh if you have a um you know if you have your laptop with you you can you can do that too it's only 20",
    "start": "189560",
    "end": "195319"
  },
  {
    "text": "megabytes so it won't crash the network fortunately and the second is um because this is uh um because we are in China so",
    "start": "195319",
    "end": "202599"
  },
  {
    "text": "I want to show you uh uh a Chinese open source model you know so um essentially",
    "start": "202599",
    "end": "208000"
  },
  {
    "text": "any s open source large language model works know so you can do llama 3 which we're going to show later llama 3.1 gamma um",
    "start": "208000",
    "end": "215239"
  },
  {
    "text": "you know Microsoft 5 and uh but here you know that's um um in China we also have",
    "start": "215239",
    "end": "221120"
  },
  {
    "text": "Chen and um and uh uh ngg and you know things like that so here we're going to",
    "start": "221120",
    "end": "227879"
  },
  {
    "text": "initialize a a CH 2 1.5 billion parameter model which is a very small",
    "start": "227879",
    "end": "233640"
  },
  {
    "text": "model you know uh and make it suitable to run on a small device on age device",
    "start": "233640",
    "end": "238959"
  },
  {
    "text": "so I can even run this not only on my laptop but also on Raspberry Pi device so you know as as we'll see in a minute",
    "start": "238959",
    "end": "247519"
  },
  {
    "text": "so the command is also very simple it's uh because in the first step you you installed a command line utility called",
    "start": "247519",
    "end": "252840"
  },
  {
    "text": "gyet so this is a gyet inet give you a configuration file and the configuration",
    "start": "252840",
    "end": "258280"
  },
  {
    "text": "specifies where to download this file and then the third step is where we're going to is so here let me show you the",
    "start": "258280",
    "end": "266800"
  },
  {
    "text": "configuration file that I have just downloaded garet",
    "start": "266800",
    "end": "272680"
  },
  {
    "text": "config.js okay so um I hope it's big enough yeah so you",
    "start": "272680",
    "end": "281000"
  },
  {
    "text": "can see there's a there's a a hugging face link to the model right you know this is",
    "start": "281000",
    "end": "286560"
  },
  {
    "text": "uh oh no sorry actually let me let me run this command actually okay",
    "start": "286560",
    "end": "294800"
  },
  {
    "text": "because um Okay so",
    "start": "294800",
    "end": "300479"
  },
  {
    "text": "now I do this the inet command all it does is to",
    "start": "300479",
    "end": "307039"
  },
  {
    "text": "is to download a configuration file and look into the configuration file to see if the model exists locally because I",
    "start": "307039",
    "end": "313039"
  },
  {
    "text": "have already downloaded the model uh the model file locally so it just goes through the the configuration step",
    "start": "313039",
    "end": "319440"
  },
  {
    "text": "without actually downloading the file right so you can see um we have the chat model which is um CH to 1.5 billion",
    "start": "319440",
    "end": "327960"
  },
  {
    "text": "parameters and uh we we we tell it's the model parameters like the contact lens and you know things like that and then",
    "start": "327960",
    "end": "334680"
  },
  {
    "text": "we have a embedding model you know if you are familiar with large language model you need the embedding model to do",
    "start": "334680",
    "end": "339720"
  },
  {
    "text": "search so you know so the chat model you ask a question and it answers right but a lot of times you need to search a",
    "start": "339720",
    "end": "346240"
  },
  {
    "text": "knowledge base to understand what the user is asking so that brings in all the",
    "start": "346240",
    "end": "351720"
  },
  {
    "text": "all the you know um infrastructure about Vector database and all that stuff so we there's also a uh you know uh an model",
    "start": "351720",
    "end": "360120"
  },
  {
    "text": "here to convert the uh natural language into a vector so that you can search them later and there's a model template",
    "start": "360120",
    "end": "366240"
  },
  {
    "text": "and you know there's prompt and you know things like that your help your your help assistant and you know things like",
    "start": "366240",
    "end": "371520"
  },
  {
    "text": "that so this is a fairly simple you know Json configuration file and once we have that the next step is really easy just",
    "start": "371520",
    "end": "378759"
  },
  {
    "text": "to do guet start and what it does is that it loads the model file which I",
    "start": "378759",
    "end": "384319"
  },
  {
    "text": "have just downloaded and with using the wasm Ed run time um and run the model as",
    "start": "384319",
    "end": "390240"
  },
  {
    "text": "a API Ser as a chatbot and uh um after the model starts it verifies that the model actually runs so as you can see it",
    "start": "390240",
    "end": "398479"
  },
  {
    "text": "says the API server is running and then gives the information like that so for this demo what I'm going to do is that",
    "start": "398479",
    "end": "405000"
  },
  {
    "text": "I'm going to go to Local Host 880 which",
    "start": "405000",
    "end": "410080"
  },
  {
    "text": "is where I just started the API server and uh if I say chat with this note I started the chat chat B what I going to",
    "start": "410080",
    "end": "416879"
  },
  {
    "text": "do what I going to show you right now is I going to turn off my Wi-Fi okay okay so just to make sure that I'm not cheating with open AI I'm not sending",
    "start": "416879",
    "end": "424080"
  },
  {
    "text": "this request to anywhere else so here I just who are",
    "start": "424080",
    "end": "431280"
  },
  {
    "text": "you okay the first response is always a little slow because it needs to load the model into the into the memory but it's",
    "start": "431280",
    "end": "437400"
  },
  {
    "text": "still pretty fast as you can see because this is a fairly small model but you know enchantment is a really well",
    "start": "437400",
    "end": "443440"
  },
  {
    "text": "trained model so it knows itself was created by the Alibaba cloud and uh it's designed to understand and generate",
    "start": "443440",
    "end": "449919"
  },
  {
    "text": "human human like text and all that so let me ask a longer question so that we can see the speed is generate text right",
    "start": "449919",
    "end": "457560"
  },
  {
    "text": "so plan me a 2-day trip",
    "start": "457560",
    "end": "465240"
  },
  {
    "text": "to visit major",
    "start": "465240",
    "end": "471560"
  },
  {
    "text": "attractions in Hong Kong okay so you know it's test",
    "start": "471560",
    "end": "477560"
  },
  {
    "text": "both the knowledge of the model and the ability for to formulate text as you can see the the speed it generate text on",
    "start": "477560",
    "end": "483919"
  },
  {
    "text": "this load Mac machine you know that's I bought over two years ago with explicit",
    "start": "483919",
    "end": "490560"
  },
  {
    "text": "instruction for my assistant to have the lowest configuration it generated text faster than I can speak actually a lot",
    "start": "490560",
    "end": "496840"
  },
  {
    "text": "faster than I can speak you know so it generates a two-day aner that goes through um those major things in Hong",
    "start": "496840",
    "end": "503199"
  },
  {
    "text": "Kong like of Victoria Park you know uh Stanley market you know stuff like that",
    "start": "503199",
    "end": "508680"
  },
  {
    "text": "right so now I can say please",
    "start": "508680",
    "end": "514880"
  },
  {
    "text": "please translate the trip plan",
    "start": "514880",
    "end": "522320"
  },
  {
    "text": "to Chinese okay they going to take the trip plan",
    "start": "522320",
    "end": "528240"
  },
  {
    "text": "and then it going to translate all the the the thing about day one and about day two into Chinese that again it",
    "start": "528240",
    "end": "533640"
  },
  {
    "text": "speaks fast it's it types the result faster than I can speak right you know so you that's our first demo as you can",
    "start": "533640",
    "end": "540760"
  },
  {
    "text": "see I I I want to emphasize I'm I'm running all this with Wi-Fi completely turned off so it's completely running on",
    "start": "540760",
    "end": "546920"
  },
  {
    "text": "my own machine you know I installed everything from scratch and uh you know and uh",
    "start": "546920",
    "end": "552240"
  },
  {
    "text": "um so you know that's I would say I turn back on because my my presentation is",
    "start": "552240",
    "end": "558320"
  },
  {
    "text": "actually on Google on Google Drive so if I keep it off it's going to um you know the presentation will not work okay so",
    "start": "558320",
    "end": "566640"
  },
  {
    "text": "only four steps you know that's you would uh uh download and install WR Time",
    "start": "566640",
    "end": "571680"
  },
  {
    "text": "download and install uh the model configure the model and then start guyet",
    "start": "571680",
    "end": "577360"
  },
  {
    "text": "in fact let me stop guyet for now so that not interfere with the next demo",
    "start": "577360",
    "end": "584200"
  },
  {
    "text": "okay and then um and this um this node is really represent itself as a as a",
    "start": "584200",
    "end": "590720"
  },
  {
    "text": "chatbot application and then you can have a little nice UI to chat Vis it you know so that's our first demo you know",
    "start": "590720",
    "end": "597360"
  },
  {
    "text": "to have a model running on your own device and then chat with it right",
    "start": "597360",
    "end": "603160"
  },
  {
    "text": "so there are some unique features about this before we dive into the technical architecture of this thing so the first",
    "start": "603160",
    "end": "609720"
  },
  {
    "text": "um as I mentioned is lightweight as you can see there's no python dependency there's uh there's no multi step to",
    "start": "609720",
    "end": "616399"
  },
  {
    "text": "install drivers and you know all that heavyweight stuff so if you want to install Python and py to on this you are",
    "start": "616399",
    "end": "621880"
  },
  {
    "text": "looking at multiple gigabytes of downloads and installation and uh um for this for this thing it's about 20",
    "start": "621880",
    "end": "627640"
  },
  {
    "text": "megabytes so it's a lot smaller and a lot slider and uh another very interesting about why we choose wasm as",
    "start": "627640",
    "end": "633760"
  },
  {
    "text": "as underlying wrong time is that it's portable across different gpus so you know um um I'm old enough to remember",
    "start": "633760",
    "end": "642000"
  },
  {
    "text": "the old days of java you know um when people look back at Java today they saw you know um they feel confused by the",
    "start": "642000",
    "end": "649320"
  },
  {
    "text": "slogan you know right once wrong anywhere isn't that what supposed to be you know that's uh you know um you",
    "start": "649320",
    "end": "654440"
  },
  {
    "text": "develop because back then you only have the Intel CPU right you know you develop on Intel CPU and run on Intel if you",
    "start": "654440",
    "end": "659639"
  },
  {
    "text": "what's what's a big deal um back then most developers have um Windows machine",
    "start": "659639",
    "end": "665160"
  },
  {
    "text": "to write their applications but the server is on Linux right you know so Java solved that problem so you develop",
    "start": "665160",
    "end": "670839"
  },
  {
    "text": "on your Linux on your Windows machine without recompiling without rewriting a code you can run on Linux today we have",
    "start": "670839",
    "end": "677079"
  },
  {
    "text": "the exact same problem with gpus most developers have a setup that I have right now they have a Mac if you develop",
    "start": "677079",
    "end": "684360"
  },
  {
    "text": "uh uh AI or large language model application on the Mac you are likely to using the Mac GPU which is the metal",
    "start": "684360",
    "end": "690040"
  },
  {
    "text": "framework you know the whole Mac setup but when you compile the application you",
    "start": "690040",
    "end": "695079"
  },
  {
    "text": "want to deploy it on the server on Nidia application in all likelihood it would not work at all because on the server",
    "start": "695079",
    "end": "701040"
  },
  {
    "text": "the Nvidia uses a different hardware and different software drivers to use Cuda so not only you need to recompile your",
    "start": "701040",
    "end": "707240"
  },
  {
    "text": "application you typically need to rewrite your application all together you know in order to move the application from one device to the",
    "start": "707240",
    "end": "713200"
  },
  {
    "text": "another right and uh we are not considering the arm mpus and you know things like that today I think every",
    "start": "713200",
    "end": "719639"
  },
  {
    "text": "cloud provider have their own AI accelerator uh Solutions right you know so that's uh so it is it's a very acute",
    "start": "719639",
    "end": "726639"
  },
  {
    "text": "problem that's uh application portability problems right so um with wasm adding another lightweight",
    "start": "726639",
    "end": "732440"
  },
  {
    "text": "abstraction layer in the middle allows you to develop on the Mac compile to wasm and then forget about it then you",
    "start": "732440",
    "end": "739279"
  },
  {
    "text": "just copy the file into different platforms you know that's something that I don't have time to demo in a in a in a",
    "start": "739279",
    "end": "745000"
  },
  {
    "text": "in 40 minutes today you know uh hopefully that we'll be be able to demo it in another session on Friday you know",
    "start": "745000",
    "end": "751320"
  },
  {
    "text": "so we will be able to show application that was developed and compiled on the Mac and I just copy it I just FTP it to",
    "start": "751320",
    "end": "758160"
  },
  {
    "text": "uh Nvidia uh Linux device that need going to be able to run there taking for advantage of uh of the Native GPU right",
    "start": "758160",
    "end": "766519"
  },
  {
    "text": "and uh um the way that I showed support a wide variety of models you know so if",
    "start": "766519",
    "end": "772720"
  },
  {
    "text": "you look at hugging phase there's um uh in terms of large language model there's thousands of them you know so when Lama",
    "start": "772720",
    "end": "778560"
  },
  {
    "text": "3 first came out you know people on Twitter said you know that's uh um we're going to see 10,000 fine tune version of",
    "start": "778560",
    "end": "785600"
  },
  {
    "text": "llama 3 within this weekend within the weekend it's released and that number was actually correct you know that's",
    "start": "785600",
    "end": "792040"
  },
  {
    "text": "because people find T those models for all kinds of purposes to mimic certain person to speak to make it speak like",
    "start": "792040",
    "end": "798079"
  },
  {
    "text": "Donald Trump for instance you know to make it be better at certain language to make it better at Japanese better better",
    "start": "798079",
    "end": "804720"
  },
  {
    "text": "Chinese to have larger contact lens smaller contact lens to make it a speaking po you know so there's all",
    "start": "804720",
    "end": "810199"
  },
  {
    "text": "kinds of models that you can um um you can fine tune with those Bas models and have them available on hunging face and",
    "start": "810199",
    "end": "817000"
  },
  {
    "text": "uh you know so the setup that I have just to shown would be able to run all those models you just give it a link to",
    "start": "817000",
    "end": "822440"
  },
  {
    "text": "the model file and not only that it can also run models like stable diffusion which is um you know a image generation",
    "start": "822440",
    "end": "829079"
  },
  {
    "text": "model and the whisper which is a um W to text model so it takes the W file and do",
    "start": "829079",
    "end": "834639"
  },
  {
    "text": "uh and generate text for you and uh you you know and the uh chat TT which is uh",
    "start": "834639",
    "end": "840920"
  },
  {
    "text": "um text to voice so it's going to uh take a text and generates the the um the",
    "start": "840920",
    "end": "846040"
  },
  {
    "text": "voice verier for you right so other interesting aspect of the the demo I",
    "start": "846040",
    "end": "852160"
  },
  {
    "text": "have just shown is that it has a very simple and transparent Model Management there's no opaque uh model repository",
    "start": "852160",
    "end": "859399"
  },
  {
    "text": "you know that's you don't know where your model lives and it's magically downloaded somewhere all the models are",
    "start": "859399",
    "end": "864480"
  },
  {
    "text": "represented by the simple URL you know it's uh um you know in our case we using the hugging face U but if you're inside",
    "start": "864480",
    "end": "870560"
  },
  {
    "text": "China you can because you're inside the firewall you can have the um G you know uh all the I forgot what's U what it's",
    "start": "870560",
    "end": "879120"
  },
  {
    "text": "called you know there's a there's a hugging pH alternative in China which you can use you just all you need is",
    "start": "879120",
    "end": "884519"
  },
  {
    "text": "somewhere to host the model file you can use you know any cloud provider to host that file right so you can just download",
    "start": "884519",
    "end": "890199"
  },
  {
    "text": "that file and it's easily embeddable into other applications and I've just shown that I have a chatbot application",
    "start": "890199",
    "end": "896040"
  },
  {
    "text": "that has a UI that I have the model embedded in it right right you know so I can easily start that",
    "start": "896040",
    "end": "902600"
  },
  {
    "text": "so with that you know that's the demo and uh you know that's um um why I thought it's interesting so let me take",
    "start": "902600",
    "end": "909720"
  },
  {
    "text": "a step back to say you know why people want to run those local model anyway you",
    "start": "909720",
    "end": "914839"
  },
  {
    "text": "know isn't open AI good enough you know is your open source model going to be better than open AI you know so I I get",
    "start": "914839",
    "end": "920800"
  },
  {
    "text": "this questions a lot you know um and uh there are actually some very um I think",
    "start": "920800",
    "end": "926600"
  },
  {
    "text": "compelling reasons right you know so the first of course is privacy Ting control you know you don't want say your model",
    "start": "926600",
    "end": "934000"
  },
  {
    "text": "does Financial analys or your model writes your email and do you really want open eye or Microsoft to know about that",
    "start": "934000",
    "end": "940319"
  },
  {
    "text": "right the second is really speed you know for a smaller model running locally it going to be a lot faster than the",
    "start": "940319",
    "end": "946440"
  },
  {
    "text": "model that's running on the cloud on someone else computer right and the reliability on your on your computer you",
    "start": "946440",
    "end": "952040"
  },
  {
    "text": "can plan the capacity you can make sure that the GPU is always available when you need it you know um the same can't",
    "start": "952040",
    "end": "958560"
  },
  {
    "text": "be set by say a SAS based or cloud-based model but I think perhaps U more interestingly is that um as the model",
    "start": "958560",
    "end": "966040"
  },
  {
    "text": "use case grow more complex um people have different alignment and bias requirements so for instance all those",
    "start": "966040",
    "end": "972920"
  },
  {
    "text": "um open a ey and all those St models are tuned to not to say specific things you",
    "start": "972920",
    "end": "978040"
  },
  {
    "text": "know so U we use um a large language Model A Lot internally to help our",
    "start": "978040",
    "end": "983319"
  },
  {
    "text": "programming work so in our office we have a we have a Mac Studio with 190 GB",
    "start": "983319",
    "end": "988560"
  },
  {
    "text": "of memory so we run several large models that fine tuned with with uh with coding",
    "start": "988560",
    "end": "994680"
  },
  {
    "text": "tasks on it so we um connect them to our GitHub repository so that it automatically reviews all the pr that",
    "start": "994680",
    "end": "1000639"
  },
  {
    "text": "submitted to our open source um uh repository and point out you know the problem and you know things like that",
    "start": "1000639",
    "end": "1006160"
  },
  {
    "text": "but if you use open AI a lot of times uh it would refuse to identify uh security",
    "start": "1006160",
    "end": "1011560"
  },
  {
    "text": "issues because it's considers that as a risk right you know as a risk to the community because it doesn't want people",
    "start": "1011560",
    "end": "1017720"
  },
  {
    "text": "to give it a piece of a code and to say uh ai ai please tell me how to hack it right you know so it would not tell you",
    "start": "1017720",
    "end": "1024640"
  },
  {
    "text": "what the security issues exist in the code so you know so there's so one person's alignment is another person's",
    "start": "1024640",
    "end": "1031400"
  },
  {
    "text": "shortcoming so I think for different use cases there's a lot of things we want the model to say or to generate that is",
    "start": "1031400",
    "end": "1038199"
  },
  {
    "text": "outside of what the open AI corporate people deemed to be um you know to be uh",
    "start": "1038199",
    "end": "1044678"
  },
  {
    "text": "to be appropriate right you know or you know entropic for that matter or Alibaba you know whatever right you know so so",
    "start": "1044679",
    "end": "1050679"
  },
  {
    "text": "you know so I think there's a there's a really strong need for um for people to",
    "start": "1050679",
    "end": "1055840"
  },
  {
    "text": "uh fine tune their own model to make the model answer questions that they they like to get answered right so um and",
    "start": "1055840",
    "end": "1062520"
  },
  {
    "text": "then there's another interesting thing I think this is uh this is a point from um uh uh Dr Dr Andrew NG G that's uh um",
    "start": "1062520",
    "end": "1070320"
  },
  {
    "text": "that he he talk he wrote a paper about uh AIC models you know mean agenic tasks meaning there's a lot of tasks where you",
    "start": "1070320",
    "end": "1077360"
  },
  {
    "text": "can use a single model to handle it and you it gets um you know um certain scores or you can use multiple model to",
    "start": "1077360",
    "end": "1084720"
  },
  {
    "text": "handle it and break the task up into to have a large language model break up the T task so for instance writing code you",
    "start": "1084720",
    "end": "1091400"
  },
  {
    "text": "can have a model to analyze to act as a product manager to analyze the task and",
    "start": "1091400",
    "end": "1097080"
  },
  {
    "text": "have the then break up the task into five and then have five different models to implement each of those task coding",
    "start": "1097080",
    "end": "1103679"
  },
  {
    "text": "tasks and then have another model to evaluate the results you know by acting as a QA so you know to go through the",
    "start": "1103679",
    "end": "1111120"
  },
  {
    "text": "agenic workflow often yields much better results than say a single model that's that's uh uh that is prompt in uh in the",
    "start": "1111120",
    "end": "1119440"
  },
  {
    "text": "you know um uh you know so for each of the steps you",
    "start": "1119440",
    "end": "1124760"
  },
  {
    "text": "not not only need different prompts but you also often times you need different models right and then there's another",
    "start": "1124760",
    "end": "1130039"
  },
  {
    "text": "point which I thought was interesting is that it's of Overlook is that uh there are a lot of times uh we need um today's",
    "start": "1130039",
    "end": "1137360"
  },
  {
    "text": "uh uh large language model often need uh tight coupling between the models and the applications uh what does",
    "start": "1137360",
    "end": "1143960"
  },
  {
    "text": "that even mean you know so tight coupling means the application depend is has to be engineered around the model",
    "start": "1143960",
    "end": "1151120"
  },
  {
    "text": "you know so um a lot of applications uh you would find when open AI upgrade",
    "start": "1151120",
    "end": "1156720"
  },
  {
    "text": "their Model A lot of applications break because the prompt that used to work doesn't work anymore you know the new",
    "start": "1156720",
    "end": "1162159"
  },
  {
    "text": "model doesn't understand the specific techniques that used in the old prom and uh you know the contact window change",
    "start": "1162159",
    "end": "1168360"
  },
  {
    "text": "the the the language capability change and all that stuff so we believe you know there's a there's a strong need for",
    "start": "1168360",
    "end": "1174320"
  },
  {
    "text": "applications to be upgraded and to be T to be uh to be embedded together with the with the model itself right you know",
    "start": "1174320",
    "end": "1180880"
  },
  {
    "text": "so instead of providing the model as a side car service in kubernetes you know like uh like API server um we want to",
    "start": "1180880",
    "end": "1187960"
  },
  {
    "text": "embed the model and the bottle the model R time into application so that they can especially for AG use cases so that they",
    "start": "1187960",
    "end": "1193960"
  },
  {
    "text": "can be distributed together so those are some of the reasons why you know um um",
    "start": "1193960",
    "end": "1199200"
  },
  {
    "text": "when I gave this talk similar talks before you know people you know they more or less come you know they more or less yeah you know that's maybe all",
    "start": "1199200",
    "end": "1205880"
  },
  {
    "text": "right but maybe not but you know since then I think there's a strong validation you know is that um companies like Apple",
    "start": "1205880",
    "end": "1213200"
  },
  {
    "text": "and Google has both adopted this similar type of architecture if you look at Apple intelligence there's a small model",
    "start": "1213200",
    "end": "1220000"
  },
  {
    "text": "that's running on the device and to treat um you know um tasks that it's been trained for like a Seri type of",
    "start": "1220000",
    "end": "1226159"
  },
  {
    "text": "tasks but for strong logical reason tasks it's offloads to the to online",
    "start": "1226159",
    "end": "1231919"
  },
  {
    "text": "model that's that's that um that provided as a s service right and uh um",
    "start": "1231919",
    "end": "1238039"
  },
  {
    "text": "Google has the same thing so this come from you know just the the Google conference that had that was I think",
    "start": "1238039",
    "end": "1244000"
  },
  {
    "text": "last week you know so they have G solutions for Android developers you know so you have high performance on device on the aai that's uh that's",
    "start": "1244000",
    "end": "1251240"
  },
  {
    "text": "running on the um on the device as a self-hosted model and then you have a MTI model cloud-based AI model that's",
    "start": "1251240",
    "end": "1258080"
  },
  {
    "text": "that's available in the cloud right so and here is a little um architecture",
    "start": "1258080",
    "end": "1263720"
  },
  {
    "text": "that's the the the Google folks has published which I thought was um was very interesting because that's",
    "start": "1263720",
    "end": "1269559"
  },
  {
    "text": "essentially the the the type of applications that have we have been building for the last year um a year and",
    "start": "1269559",
    "end": "1276440"
  },
  {
    "text": "a half you know that's uh so you know we um take all those model elements",
    "start": "1276440",
    "end": "1282279"
  },
  {
    "text": "including the model itself The Prompt the vector database the um you know all those things and bundle them together",
    "start": "1282279",
    "end": "1288720"
  },
  {
    "text": "into a tightly coupled application and then use use a common portable R time",
    "start": "1288720",
    "end": "1294080"
  },
  {
    "text": "underneath some to to make some portable across different devices right instead of having all those as separate",
    "start": "1294080",
    "end": "1301080"
  },
  {
    "text": "microservices and uh um have them say you know you have four say if you have",
    "start": "1301080",
    "end": "1306159"
  },
  {
    "text": "if your application is a longchain application and uh is a microservice the model is a is a microservice the vector",
    "start": "1306159",
    "end": "1313039"
  },
  {
    "text": "database is a micros service say someday you update the Lan piece and then the other piece you don't update them then",
    "start": "1313039",
    "end": "1319360"
  },
  {
    "text": "the entire application breaks because the model can no longer understand the prompt right you know so you know so there's um a lot of things Loosely coupl",
    "start": "1319360",
    "end": "1327000"
  },
  {
    "text": "application although we we like Loosely coupled application in Cloud native in general but in in the current stage of",
    "start": "1327000",
    "end": "1333440"
  },
  {
    "text": "model uh large language model application development we think this is um there's there's a by far a stronger",
    "start": "1333440",
    "end": "1339919"
  },
  {
    "text": "case to have a tightly coupled application that has a application has a model itself self-hosted and embedded",
    "start": "1339919",
    "end": "1345840"
  },
  {
    "text": "into the application right so here's the um the Tex stack I I'm going to go",
    "start": "1345840",
    "end": "1351520"
  },
  {
    "text": "quickly you know that's so um um because I mentioned those before you know that's um this is a CN project called wasm and",
    "start": "1351520",
    "end": "1359520"
  },
  {
    "text": "uh it's a it's a web assembly around time that provide cross GPU model inference services so you know so that's",
    "start": "1359520",
    "end": "1365440"
  },
  {
    "text": "uh the basis you can think of is uh is a the Kuda of this whole stack ex except",
    "start": "1365440",
    "end": "1371120"
  },
  {
    "text": "it's not Kuda right you know it's so we write in Rust in go or in JavaScript and compile to wasm and once we compile to",
    "start": "1371120",
    "end": "1378159"
  },
  {
    "text": "wasam it become crossplatform it runs any GPU on any driver so that's the role of the wasm edge run time and on top of",
    "start": "1378159",
    "end": "1385120"
  },
  {
    "text": "WM Edge run time we have a project called llama Edge so if you consider wasm Edge is a jvm the Llama Edge is the",
    "start": "1385120",
    "end": "1392760"
  },
  {
    "text": "web sphere or the web logic or JBoss the application server so it's a application that built on the underlying run time",
    "start": "1392760",
    "end": "1399840"
  },
  {
    "text": "for the specific task of running large language models right you know so it's uh it um so it provides open air",
    "start": "1399840",
    "end": "1406679"
  },
  {
    "text": "compatibl API it provide a chatbot interface it provide connections to those agent Frameworks and you know",
    "start": "1406679",
    "end": "1412880"
  },
  {
    "text": "things like that so it so the Llama H project is also open source project and provide API uh uh API and SDK for for",
    "start": "1412880",
    "end": "1421120"
  },
  {
    "text": "developers to use so and then at the very top of the layer because you know um if you notice that the the demo I",
    "start": "1421120",
    "end": "1428080"
  },
  {
    "text": "have just shown is called ganet so it's uh it's um this is actually it's also",
    "start": "1428080",
    "end": "1433279"
  },
  {
    "text": "open source project but it's one of our customers you know so they build uh a fully integrated applic ation with large",
    "start": "1433279",
    "end": "1439279"
  },
  {
    "text": "language model embedded in their note so each of their so the idea is that each",
    "start": "1439279",
    "end": "1444480"
  },
  {
    "text": "person have uh your own knowledge so this project originated from UC Berkeley right you know so one of the things you",
    "start": "1444480",
    "end": "1450120"
  },
  {
    "text": "know I have a you know it's um so they they have a um severe shortage of",
    "start": "1450120",
    "end": "1455840"
  },
  {
    "text": "teaching assistant you know the reason why is because you know uh I think last year there's a there's a a huge",
    "start": "1455840",
    "end": "1462080"
  },
  {
    "text": "inflation in the US right so the teaching assistant feel like they're paid too little so they went on a strike to say you know that's where that we",
    "start": "1462080",
    "end": "1468039"
  },
  {
    "text": "demand pay more so University decided to pay them 25% more but cut 25% of them",
    "start": "1468039",
    "end": "1474240"
  },
  {
    "text": "okay so so the university is a cost neutral decision but but the result is",
    "start": "1474240",
    "end": "1480440"
  },
  {
    "text": "that they have less ta to work with and uh so that's where they say you know um",
    "start": "1480440",
    "end": "1485600"
  },
  {
    "text": "you know perhaps we can use the best T from the past years and embed their knowledge into a large language model",
    "start": "1485600",
    "end": "1491360"
  },
  {
    "text": "node and have them uh help new students right you know so it's a it's an integrated system which which is which",
    "start": "1491360",
    "end": "1498440"
  },
  {
    "text": "it own knowledge base and with its own large language model and uh uh everything pieced together and using the",
    "start": "1498440",
    "end": "1505039"
  },
  {
    "text": "stack that I just mentioned you know the the Z was Lama stack that I mentioned so",
    "start": "1505039",
    "end": "1511320"
  },
  {
    "text": "that that brings us to our next demo is to enhance the model with your personal",
    "start": "1511320",
    "end": "1516399"
  },
  {
    "text": "knowledge so we have just shown the um um chenan 1.5b model it knows about Hong",
    "start": "1516399",
    "end": "1523760"
  },
  {
    "text": "Kong it knows about you know Common Sense stuff but if you if I ask it something that is uh uh it is ambiguous",
    "start": "1523760",
    "end": "1530919"
  },
  {
    "text": "or highly specific it going to hallucinate it going to give me entirely wrong answers so to solve this problem",
    "start": "1530919",
    "end": "1539000"
  },
  {
    "text": "we have a um we have another four steps right you know so the first step still is install the was uh the Lama Ed",
    "start": "1539000",
    "end": "1546640"
  },
  {
    "text": "software essentially is the around time 20 megabytes WR time the second instead of installing the CH 2 uh 1.5b model I",
    "start": "1546640",
    "end": "1555679"
  },
  {
    "text": "switch to a llama 3.1 model I just I I could still use the CH model but I just want to show a different model so I so I",
    "start": "1555679",
    "end": "1561919"
  },
  {
    "text": "chose the Llama Lama 3.1 model but the model is supplemented with a vector database the vector database is",
    "start": "1561919",
    "end": "1568159"
  },
  {
    "text": "generated from the Samsung Galaxy s25 smartphone menu so if you have a",
    "start": "1568159",
    "end": "1574120"
  },
  {
    "text": "smartphone Samsung smartphone they all have a menu the menu is about 200 pages long right it talks about everything",
    "start": "1574120",
    "end": "1579720"
  },
  {
    "text": "about the smartphone and uh you unless you have a problem you would have no idea what's what's going on in that in",
    "start": "1579720",
    "end": "1586120"
  },
  {
    "text": "that menu and you will not read it so we take that menu and break into chapters and uh generate knowledge embeddings and",
    "start": "1586120",
    "end": "1593080"
  },
  {
    "text": "then supplement that into the model so the model itself is just the stand Lama 3.1 model so that's what I going to do",
    "start": "1593080",
    "end": "1600000"
  },
  {
    "text": "is that I going to re reinitialize my gyet node with",
    "start": "1600000",
    "end": "1606480"
  },
  {
    "text": "this with this knowledge base okay so what it does is that you know it's it",
    "start": "1606480",
    "end": "1612279"
  },
  {
    "text": "use the Llama lamaas 3.1 ADB instruct model which because we have we I have",
    "start": "1612279",
    "end": "1617399"
  },
  {
    "text": "already pre-downloaded locally so you already have it what it does is that it's um um it downloads the knowledge",
    "start": "1617399",
    "end": "1624159"
  },
  {
    "text": "collection which is the vector database snapshot I generated from the 200 Pages PDF of the Samsung device menu and uh",
    "start": "1624159",
    "end": "1633200"
  },
  {
    "text": "it's automatically Imports that into the vector database as I mentioned the vector database is fine is matched with",
    "start": "1633200",
    "end": "1639840"
  },
  {
    "text": "the model so the vector database going to generate um context that is the right size and the right difficulty level for",
    "start": "1639840",
    "end": "1646200"
  },
  {
    "text": "this model so that it can function so so with that with the knowledge with the",
    "start": "1646200",
    "end": "1651320"
  },
  {
    "text": "knowledge um with the knowledge base and the model both downloaded and installed I going to do start again so you can see",
    "start": "1651320",
    "end": "1658880"
  },
  {
    "text": "the startup command become longer because now loads the the knowledge base as well and no and loads the context so",
    "start": "1658880",
    "end": "1667200"
  },
  {
    "text": "we're going to wait for a second for it to because this is a much larger model than the Chan 1.4b so it's going to take",
    "start": "1667200",
    "end": "1673960"
  },
  {
    "text": "longer for for it to um for it to load and then it going to have the same chatbot UI",
    "start": "1673960",
    "end": "1680440"
  },
  {
    "text": "interface that's that I'm going to show you okay so okay so now it's started uh",
    "start": "1680440",
    "end": "1686240"
  },
  {
    "text": "what I'm going to do is I'm going to do Local Host again 880 load up the chatbot and uh",
    "start": "1686240",
    "end": "1694039"
  },
  {
    "text": "just for for the Fone off it I going to turn off the Wi-Fi and uh now I ask a",
    "start": "1694039",
    "end": "1699799"
  },
  {
    "text": "question can I use eim for this",
    "start": "1699799",
    "end": "1705440"
  },
  {
    "text": "phone okay so this is the super m question what is this phone okay if you",
    "start": "1705440",
    "end": "1711960"
  },
  {
    "text": "if you ask this on chat gbt it would never it would not be able to answer this question at all and uh because I'm",
    "start": "1711960",
    "end": "1719919"
  },
  {
    "text": "not specifying which phone and what's and each phone has different requirements for eim and uh you know and",
    "start": "1719919",
    "end": "1727799"
  },
  {
    "text": "also it's a very obscure knowledge and they tends to hallucinate a lot if you do that but because I have a knowledge",
    "start": "1727799",
    "end": "1734279"
  },
  {
    "text": "base backed by this model so the model actually knows that I the the only",
    "start": "1734279",
    "end": "1739519"
  },
  {
    "text": "context that I have this phone refers to the Samsung Galaxy s24 smartphone okay",
    "start": "1739519",
    "end": "1745279"
  },
  {
    "text": "and it it goes into the menu and find out the the um you know whether it's",
    "start": "1745279",
    "end": "1750840"
  },
  {
    "text": "compatible with the E the answer is it is compatible with e you can use the S with that but I can ask a follow-up",
    "start": "1750840",
    "end": "1756600"
  },
  {
    "text": "question how do I change",
    "start": "1756600",
    "end": "1763360"
  },
  {
    "text": "the physical SIM card okay so it's it's another obscure",
    "start": "1763519",
    "end": "1769720"
  },
  {
    "text": "part it's another obscure part that in the that's in the in the phone menu",
    "start": "1769720",
    "end": "1774840"
  },
  {
    "text": "right you know the the the pH menu basically said is the Nano thing and you know here are the steps to do that um it",
    "start": "1774840",
    "end": "1780679"
  },
  {
    "text": "is a little slow you know as you can see even it's slow it's still generate text",
    "start": "1780679",
    "end": "1785799"
  },
  {
    "text": "faster than I can speak right you know so if I speak like this it's about uh three to five tokens per second but this",
    "start": "1785799",
    "end": "1792480"
  },
  {
    "text": "easily generates 20 tokens per second right you know so it's give a step-by-step instruction based on that in man menu and that is something even",
    "start": "1792480",
    "end": "1800480"
  },
  {
    "text": "if I don't turn off the Wi-Fi you would know that chap gbt would not be able to answer because this is too obscure you",
    "start": "1800480",
    "end": "1806440"
  },
  {
    "text": "know it's uh it's something if you really ask chat gbt about it it's going to hallucinate and give you a bunch of",
    "start": "1806440",
    "end": "1812000"
  },
  {
    "text": "wrong answers okay so let me turn it back on and so this is um you know so so",
    "start": "1812000",
    "end": "1817799"
  },
  {
    "text": "this is our second demo that's uh that talks about you know um the same easy",
    "start": "1817799",
    "end": "1823960"
  },
  {
    "text": "four easy steps you know to supplement change to a different model and supplement the model with a different",
    "start": "1823960",
    "end": "1829360"
  },
  {
    "text": "knowledge base as you can see you can supplement with anything you can you know my son did a Model like that he has",
    "start": "1829360",
    "end": "1836279"
  },
  {
    "text": "a chemistry textbook you know so he worked with a professor and you know he's a he's a middle school student so",
    "start": "1836279",
    "end": "1841799"
  },
  {
    "text": "he build a chemistry bot that's um that's so he also build an interface that in that's in telegram so and in",
    "start": "1841799",
    "end": "1848320"
  },
  {
    "text": "Discord so his student so his uh classmates can interact with the model and talk about say you know um different",
    "start": "1848320",
    "end": "1854720"
  },
  {
    "text": "chemical elements right you know so by having a knowledge base that with your model you can have a node that's that's",
    "start": "1854720",
    "end": "1860519"
  },
  {
    "text": "uh you know running locally but with your own knowledge right so finally I want to do uh a final demo which is to",
    "start": "1860519",
    "end": "1868159"
  },
  {
    "text": "showcase the API capabilities because right now we have seen one kind of applications that is called chatbot",
    "start": "1868159",
    "end": "1874080"
  },
  {
    "text": "chatbot is interesting but you know it's uh but in a lot of agenic use cases you don't necessarily want to want to have",
    "start": "1874080",
    "end": "1881320"
  },
  {
    "text": "the chat interaction although chatbot not only on the web you can do it on Telegram and you know things like that but the more interesting use case is to",
    "start": "1881320",
    "end": "1887960"
  },
  {
    "text": "connect the model to Something Real not just to connect the model to something to to a speech so that's is still just H",
    "start": "1887960",
    "end": "1897600"
  },
  {
    "text": "sorry okay it's still four steps but instead you know so the first two three steps",
    "start": "1897600",
    "end": "1903519"
  },
  {
    "text": "are all the same you know so what I going to do is I going to um start",
    "start": "1903519",
    "end": "1910399"
  },
  {
    "text": "this so what it does is that it's start a fine-tune model you know it's oh sorry",
    "start": "1910399",
    "end": "1917399"
  },
  {
    "text": "but you know that's um let's go directly to the to our backup plan you know because I didn't download this model I",
    "start": "1917399",
    "end": "1923519"
  },
  {
    "text": "don't have time to to download the entire model but but I have but I have it catched uh on my machine so what I",
    "start": "1923519",
    "end": "1930840"
  },
  {
    "text": "going to do is I I going to start uh uh sorry",
    "start": "1930840",
    "end": "1938780"
  },
  {
    "text": "[Music] python that oh sorry",
    "start": "1938780",
    "end": "1944840"
  },
  {
    "text": "I my apologize but you know but I can show you how it works here so what it",
    "start": "1944840",
    "end": "1952039"
  },
  {
    "text": "does so so we have a full documentation so assume that you start this models in I'm running of time that's uh you can",
    "start": "1952039",
    "end": "1957080"
  },
  {
    "text": "configure your uh your python application to use this model as as API",
    "start": "1957080",
    "end": "1962559"
  },
  {
    "text": "not as a chatbot so in here then it would give you a text prompt to say you know um ask something so here I say help",
    "start": "1962559",
    "end": "1969960"
  },
  {
    "text": "me write down I'm going to fix a bug okay so the python application has embedded sqlite database the model can",
    "start": "1969960",
    "end": "1977120"
  },
  {
    "text": "not respond a a human language response it going to respond something like that it's going to respond a Json structure",
    "start": "1977120",
    "end": "1984919"
  },
  {
    "text": "that asks the python application to make a function call so what the python application is that there's predefined",
    "start": "1984919",
    "end": "1991039"
  },
  {
    "text": "function called to create task so it's a to-do list application by the way so it sees this as a to-do item and then it's",
    "start": "1991039",
    "end": "1997639"
  },
  {
    "text": "uh it's creates a entry to the um uh uh SQL database locally on your computer",
    "start": "1997639",
    "end": "2003279"
  },
  {
    "text": "and then it's um once the two does that the two result give the result okay and",
    "start": "2003279",
    "end": "2008600"
  },
  {
    "text": "then it's result okay goes back to large language model the large language model says I have added so it's it's give you",
    "start": "2008600",
    "end": "2014600"
  },
  {
    "text": "a report in natural language what it has done so you can do this over and over and add different task to it and you can",
    "start": "2014600",
    "end": "2020480"
  },
  {
    "text": "check off task to it so you can have a complete L language um interface that interact with a local database on your",
    "start": "2020480",
    "end": "2026600"
  },
  {
    "text": "machine through this approach you can have you know we have um people in our community to have to interact with say a",
    "start": "2026600",
    "end": "2033360"
  },
  {
    "text": "drone that connect to my computer so I say please make the Drone take off it going to write a piece of python code",
    "start": "2033360",
    "end": "2039240"
  },
  {
    "text": "which I going to which this machine going to send that to the Drone and then the Drone will take off I going to say",
    "start": "2039240",
    "end": "2044760"
  },
  {
    "text": "go back go outside of this room and see what's outside you're going to find the it's going to see the the do opening and",
    "start": "2044760",
    "end": "2050480"
  },
  {
    "text": "go out of that and take a picture and come back right you know so all those have been done you know that's uh to use",
    "start": "2050480",
    "end": "2055599"
  },
  {
    "text": "to make large language model use tools right and all this can be done that's entirely on your own computer with the",
    "start": "2055599",
    "end": "2062480"
  },
  {
    "text": "hardware that's you know that you have full control of that no one will be able to will be able to hack with your with",
    "start": "2062480",
    "end": "2069878"
  },
  {
    "text": "everything that's you know that's um that's with your own privacy anyway so",
    "start": "2069879",
    "end": "2075240"
  },
  {
    "text": "you know that's uh um the last project I want to mention is uh so um uh a lot of",
    "start": "2075240",
    "end": "2081280"
  },
  {
    "text": "people complain to say you know that's uh this is all good but you know so much command line stuff you know I don't",
    "start": "2081280",
    "end": "2086919"
  },
  {
    "text": "really you know can I can I get something more visual so so there's another project in the community that is",
    "start": "2086919",
    "end": "2092638"
  },
  {
    "text": "called moing which is rust UI project that's uh that build a UI around the AG",
    "start": "2092639",
    "end": "2098520"
  },
  {
    "text": "where you can use a UI you know you can do that from your windows or your Mac computer you can use you can click through and download applications and",
    "start": "2098520",
    "end": "2105960"
  },
  {
    "text": "you can download models try it and then have start API server and have other python applications to you know uh to",
    "start": "2105960",
    "end": "2112480"
  },
  {
    "text": "interact with it so that's another GitHub repository so yeah that said you know I think my time is up thank you",
    "start": "2112480",
    "end": "2117839"
  },
  {
    "text": "very much [Applause]",
    "start": "2117839",
    "end": "2122800"
  }
]
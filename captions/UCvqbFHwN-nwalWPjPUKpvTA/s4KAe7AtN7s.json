[
  {
    "text": "so thanks for joining us today Like",
    "start": "240",
    "end": "1920"
  },
  {
    "text": "we're excited to be here in London and",
    "start": "1920",
    "end": "4240"
  },
  {
    "text": "uh excited to be here with the Cubeflow",
    "start": "4240",
    "end": "5920"
  },
  {
    "text": "community Big thanks to them I think",
    "start": "5920",
    "end": "7839"
  },
  {
    "text": "they're doing a lot of great work and",
    "start": "7839",
    "end": "9200"
  },
  {
    "text": "they're very supportive and",
    "start": "9200",
    "end": "10240"
  },
  {
    "text": "collaborative So really really excited",
    "start": "10240",
    "end": "12240"
  },
  {
    "text": "to be here Another big thanks goes to",
    "start": "12240",
    "end": "14240"
  },
  {
    "text": "our open source program office at our",
    "start": "14240",
    "end": "16640"
  },
  {
    "text": "company So I think they're supportive of",
    "start": "16640",
    "end": "18480"
  },
  {
    "text": "us getting here and doing these talks So",
    "start": "18480",
    "end": "20640"
  },
  {
    "text": "really want to thank them for making it",
    "start": "20640",
    "end": "22279"
  },
  {
    "text": "happen Actually I work in a team that",
    "start": "22279",
    "end": "24640"
  },
  {
    "text": "provides key data and ML technologies",
    "start": "24640",
    "end": "26880"
  },
  {
    "text": "for Apple and we're here today to",
    "start": "26880",
    "end": "28880"
  },
  {
    "text": "present some work around speeding up",
    "start": "28880",
    "end": "30640"
  },
  {
    "text": "your ML workloads using in-memory data",
    "start": "30640",
    "end": "32480"
  },
  {
    "text": "caching So let's dive in",
    "start": "32480",
    "end": "36079"
  },
  {
    "text": "At present everyone knows in this room",
    "start": "36079",
    "end": "37840"
  },
  {
    "text": "like GPUs are scarce and an expensive",
    "start": "37840",
    "end": "39960"
  },
  {
    "text": "resource and achieving efficiency in the",
    "start": "39960",
    "end": "42719"
  },
  {
    "text": "cloud Um and compute particularly is an",
    "start": "42719",
    "end": "45280"
  },
  {
    "text": "important topic but it becomes paramount",
    "start": "45280",
    "end": "47600"
  },
  {
    "text": "in the world of GPUs right Um we know",
    "start": "47600",
    "end": "50719"
  },
  {
    "text": "there's fragmentation in passing data to",
    "start": "50719",
    "end": "52559"
  },
  {
    "text": "GPUs as the phases of data loading",
    "start": "52559",
    "end": "55559"
  },
  {
    "text": "deserialization and transformation can",
    "start": "55559",
    "end": "57680"
  },
  {
    "text": "cause GPUs to be idle just waiting for",
    "start": "57680",
    "end": "60320"
  },
  {
    "text": "these phases to complete so that data",
    "start": "60320",
    "end": "63120"
  },
  {
    "text": "can actually get to the GPU",
    "start": "63120",
    "end": "66159"
  },
  {
    "text": "In this simplistic diagram you can see",
    "start": "66159",
    "end": "68400"
  },
  {
    "text": "the phases of the typical data pipeline",
    "start": "68400",
    "end": "70560"
  },
  {
    "text": "feeding GPU in a single pod These phases",
    "start": "70560",
    "end": "74080"
  },
  {
    "text": "are IO and CPU and memory bound delaying",
    "start": "74080",
    "end": "76960"
  },
  {
    "text": "the start of the GPU compute These",
    "start": "76960",
    "end": "79439"
  },
  {
    "text": "phases can be extra wasteful as they can",
    "start": "79439",
    "end": "81280"
  },
  {
    "text": "be done repetitively for larger training",
    "start": "81280",
    "end": "83520"
  },
  {
    "text": "workloads involving multiple GPU workers",
    "start": "83520",
    "end": "86159"
  },
  {
    "text": "So this presents an interesting",
    "start": "86159",
    "end": "87520"
  },
  {
    "text": "opportunity for us to speed up ML",
    "start": "87520",
    "end": "89759"
  },
  {
    "text": "workloads and to use these resources",
    "start": "89759",
    "end": "91600"
  },
  {
    "text": "more",
    "start": "91600",
    "end": "92920"
  },
  {
    "text": "efficiently In order to achieve a better",
    "start": "92920",
    "end": "95119"
  },
  {
    "text": "data flow we introduce kind of sharding",
    "start": "95119",
    "end": "97439"
  },
  {
    "text": "of the data set and efficiently reading",
    "start": "97439",
    "end": "100240"
  },
  {
    "text": "those shards from a serialization",
    "start": "100240",
    "end": "102079"
  },
  {
    "text": "optimized in-memory cache reducing uh IO",
    "start": "102079",
    "end": "105680"
  },
  {
    "text": "and DS serialization costs The data can",
    "start": "105680",
    "end": "108720"
  },
  {
    "text": "be fed to the GPUs more quickly and thus",
    "start": "108720",
    "end": "110720"
  },
  {
    "text": "improving system throughput and GPU",
    "start": "110720",
    "end": "112880"
  },
  {
    "text": "efficiency So we'll discuss this in",
    "start": "112880",
    "end": "115200"
  },
  {
    "text": "detail a little bit later but first I",
    "start": "115200",
    "end": "117680"
  },
  {
    "text": "think it's important to point out that",
    "start": "117680",
    "end": "118880"
  },
  {
    "text": "this technique presents a particularly",
    "start": "118880",
    "end": "120719"
  },
  {
    "text": "interesting opportunity for larger scale",
    "start": "120719",
    "end": "122640"
  },
  {
    "text": "training workloads requiring like larger",
    "start": "122640",
    "end": "125200"
  },
  {
    "text": "data",
    "start": "125200",
    "end": "126040"
  },
  {
    "text": "sets So I'll diverge a little bit and",
    "start": "126040",
    "end": "128319"
  },
  {
    "text": "we'll kind of revisit some revisit",
    "start": "128319",
    "end": "130160"
  },
  {
    "text": "topics on the big data space So for",
    "start": "130160",
    "end": "132720"
  },
  {
    "text": "years in like high volume data",
    "start": "132720",
    "end": "134160"
  },
  {
    "text": "environments tools like Hadoop Spark",
    "start": "134160",
    "end": "136800"
  },
  {
    "text": "HDFS uh Parquet have been used for data",
    "start": "136800",
    "end": "139760"
  },
  {
    "text": "processing and storage right um newer",
    "start": "139760",
    "end": "142879"
  },
  {
    "text": "compatible technologies like iceberg",
    "start": "142879",
    "end": "144959"
  },
  {
    "text": "represent a big leap forward for",
    "start": "144959",
    "end": "146959"
  },
  {
    "text": "efficiently storing and accessing large",
    "start": "146959",
    "end": "149040"
  },
  {
    "text": "data and scalable storage environments",
    "start": "149040",
    "end": "151520"
  },
  {
    "text": "and columner formats and table formats",
    "start": "151520",
    "end": "153440"
  },
  {
    "text": "have matured to allow for very efficient",
    "start": "153440",
    "end": "155200"
  },
  {
    "text": "access to large data while min",
    "start": "155200",
    "end": "157920"
  },
  {
    "text": "minimizing IO ops from the storage",
    "start": "157920",
    "end": "160599"
  },
  {
    "text": "solutions As teams do more and more",
    "start": "160599",
    "end": "162879"
  },
  {
    "text": "machine learning in big data",
    "start": "162879",
    "end": "164000"
  },
  {
    "text": "environments it is a natural extension",
    "start": "164000",
    "end": "165920"
  },
  {
    "text": "of their work to use iceberg tables to",
    "start": "165920",
    "end": "168080"
  },
  {
    "text": "capture features and/or materialized",
    "start": "168080",
    "end": "169840"
  },
  {
    "text": "data transformations to feed large data",
    "start": "169840",
    "end": "172319"
  },
  {
    "text": "in ML",
    "start": "172319",
    "end": "173640"
  },
  {
    "text": "training Large data sets require",
    "start": "173640",
    "end": "176000"
  },
  {
    "text": "training workloads to use more GPUs",
    "start": "176000",
    "end": "177599"
  },
  {
    "text": "across more training",
    "start": "177599",
    "end": "179000"
  },
  {
    "text": "workers and iceberg paret and the sister",
    "start": "179000",
    "end": "181840"
  },
  {
    "text": "big data technologies like arrow offer",
    "start": "181840",
    "end": "183760"
  },
  {
    "text": "unique value to improve efficiency and",
    "start": "183760",
    "end": "186400"
  },
  {
    "text": "speed of ML training So now I'll hand it",
    "start": "186400",
    "end": "189200"
  },
  {
    "text": "over to one of our brightest minds and",
    "start": "189200",
    "end": "191280"
  },
  {
    "text": "an impeccable teammate Haku to discuss",
    "start": "191280",
    "end": "193519"
  },
  {
    "text": "how these key technologies can be",
    "start": "193519",
    "end": "195040"
  },
  {
    "text": "combined uh on Kubernetes to solve this",
    "start": "195040",
    "end": "197959"
  },
  {
    "text": "problem Thanks Ash",
    "start": "197959",
    "end": "202200"
  },
  {
    "text": "So um for distributed training on",
    "start": "205440",
    "end": "207440"
  },
  {
    "text": "Kubernetes um Cubeflow project aims to",
    "start": "207440",
    "end": "210319"
  },
  {
    "text": "simplify enhance user experience by",
    "start": "210319",
    "end": "212400"
  },
  {
    "text": "modeling training using native",
    "start": "212400",
    "end": "213920"
  },
  {
    "text": "Kubernetes APIs and with the recently",
    "start": "213920",
    "end": "216319"
  },
  {
    "text": "released trainer V2 project cluster",
    "start": "216319",
    "end": "218480"
  },
  {
    "text": "operators can configure runtimes which",
    "start": "218480",
    "end": "220720"
  },
  {
    "text": "is essentially a blueprints or templates",
    "start": "220720",
    "end": "223760"
  },
  {
    "text": "um that um that model training uh and",
    "start": "223760",
    "end": "226959"
  },
  {
    "text": "finetuning using Kubernetes API",
    "start": "226959",
    "end": "228879"
  },
  {
    "text": "abstracting all the infra Kubernetes",
    "start": "228879",
    "end": "230560"
  },
  {
    "text": "complexities away from data scientist",
    "start": "230560",
    "end": "232239"
  },
  {
    "text": "HTML engineers So engineers can leverage",
    "start": "232239",
    "end": "234560"
  },
  {
    "text": "this um runtimes and use SDK to create",
    "start": "234560",
    "end": "237200"
  },
  {
    "text": "train",
    "start": "237200",
    "end": "238200"
  },
  {
    "text": "jobs It also it also has APIs to add",
    "start": "238200",
    "end": "241680"
  },
  {
    "text": "initializers to streamline asset",
    "start": "241680",
    "end": "243519"
  },
  {
    "text": "initialization that can be shared across",
    "start": "243519",
    "end": "245439"
  },
  {
    "text": "nodes This improves GPU utilization by",
    "start": "245439",
    "end": "247760"
  },
  {
    "text": "offloading IIO task to CPUs For example",
    "start": "247760",
    "end": "250239"
  },
  {
    "text": "here in this um in this diagram we have",
    "start": "250239",
    "end": "252640"
  },
  {
    "text": "a data set initializer which is",
    "start": "252640",
    "end": "254560"
  },
  {
    "text": "configured to run as a separate job to",
    "start": "254560",
    "end": "256400"
  },
  {
    "text": "download data sets from hugging phase",
    "start": "256400",
    "end": "258160"
  },
  {
    "text": "and share it on trainer",
    "start": "258160",
    "end": "260199"
  },
  {
    "text": "parts And it has integrations with",
    "start": "260199",
    "end": "262560"
  },
  {
    "text": "multiple ML frameworks and provides um",
    "start": "262560",
    "end": "264800"
  },
  {
    "text": "capabilities to scale model training",
    "start": "264800",
    "end": "266720"
  },
  {
    "text": "from a single machine to large clusters",
    "start": "266720",
    "end": "269919"
  },
  {
    "text": "um using native government API and um it",
    "start": "269919",
    "end": "272639"
  },
  {
    "text": "integrates with advanced scheduulers",
    "start": "272639",
    "end": "274080"
  },
  {
    "text": "like Q to optimize on resource",
    "start": "274080",
    "end": "277758"
  },
  {
    "text": "utilization While uh CubeFlow offers",
    "start": "278520",
    "end": "281199"
  },
  {
    "text": "flexibility and scalability to run",
    "start": "281199",
    "end": "282720"
  },
  {
    "text": "distributed model training on Kubernetes",
    "start": "282720",
    "end": "284960"
  },
  {
    "text": "several challenges exist today uh when",
    "start": "284960",
    "end": "287199"
  },
  {
    "text": "dealing with large table data",
    "start": "287199",
    "end": "288960"
  },
  {
    "text": "particularly loading data set across",
    "start": "288960",
    "end": "290560"
  },
  {
    "text": "multiple training",
    "start": "290560",
    "end": "291720"
  },
  {
    "text": "pods So large data sets can exceed",
    "start": "291720",
    "end": "294880"
  },
  {
    "text": "memory of a single GPU worker which",
    "start": "294880",
    "end": "297320"
  },
  {
    "text": "requires sophisticated solutions to",
    "start": "297320",
    "end": "299759"
  },
  {
    "text": "shard the data and with data parallelism",
    "start": "299759",
    "end": "302479"
  },
  {
    "text": "uh each worker would only need to access",
    "start": "302479",
    "end": "304080"
  },
  {
    "text": "subset of the data and the challenge",
    "start": "304080",
    "end": "305600"
  },
  {
    "text": "lies in how to efficiently select a",
    "start": "305600",
    "end": "307759"
  },
  {
    "text": "subset from um the entire data set So in",
    "start": "307759",
    "end": "311440"
  },
  {
    "text": "the previous example where we saw where",
    "start": "311440",
    "end": "313120"
  },
  {
    "text": "um the initializer shares the data set",
    "start": "313120",
    "end": "315680"
  },
  {
    "text": "in a PVC which is mounted on a multiple",
    "start": "315680",
    "end": "317600"
  },
  {
    "text": "worker pods each worker would load the",
    "start": "317600",
    "end": "319840"
  },
  {
    "text": "entire data set by default if using pygd",
    "start": "319840",
    "end": "322960"
  },
  {
    "text": "and select a subset from in-memory um",
    "start": "322960",
    "end": "325280"
  },
  {
    "text": "data set or in other cases with",
    "start": "325280",
    "end": "327680"
  },
  {
    "text": "streaming um the um let's say for",
    "start": "327680",
    "end": "330560"
  },
  {
    "text": "example using pyarch iterable data set",
    "start": "330560",
    "end": "332800"
  },
  {
    "text": "workers stream the data and select a",
    "start": "332800",
    "end": "334639"
  },
  {
    "text": "subset without loading the entire data",
    "start": "334639",
    "end": "336320"
  },
  {
    "text": "set but this will require workers to",
    "start": "336320",
    "end": "338720"
  },
  {
    "text": "reream the uh data from source for every",
    "start": "338720",
    "end": "341240"
  },
  {
    "text": "epoch and which adds latency IOU latency",
    "start": "341240",
    "end": "344080"
  },
  {
    "text": "and GPU and CPU",
    "start": "344080",
    "end": "346759"
  },
  {
    "text": "cycles Hence um I think simplifying",
    "start": "346759",
    "end": "349919"
  },
  {
    "text": "sharding of a data set becomes um uh a",
    "start": "349919",
    "end": "353199"
  },
  {
    "text": "challenge to effectively utilize GPU",
    "start": "353199",
    "end": "354960"
  },
  {
    "text": "resources and reduce the CPU usage and",
    "start": "354960",
    "end": "357440"
  },
  {
    "text": "latency especially with data",
    "start": "357440",
    "end": "359800"
  },
  {
    "text": "loading Also maintaining consistent",
    "start": "359800",
    "end": "362000"
  },
  {
    "text": "shuffling across epochs is essential to",
    "start": "362000",
    "end": "364240"
  },
  {
    "text": "prevent overfitting and require um",
    "start": "364240",
    "end": "366720"
  },
  {
    "text": "solutions to again shuffle the shuffle",
    "start": "366720",
    "end": "368960"
  },
  {
    "text": "the data So this also ties to similar",
    "start": "368960",
    "end": "370960"
  },
  {
    "text": "problem on how to efficiently access",
    "start": "370960",
    "end": "372960"
  },
  {
    "text": "unique subset of the data set for every",
    "start": "372960",
    "end": "377160"
  },
  {
    "text": "epoch So to address these challenges um",
    "start": "377160",
    "end": "380080"
  },
  {
    "text": "inmemory solution inmemory caching can",
    "start": "380080",
    "end": "383360"
  },
  {
    "text": "uh can be an effective solution for uh",
    "start": "383360",
    "end": "385120"
  },
  {
    "text": "GPU workers to readily access data in an",
    "start": "385120",
    "end": "387520"
  },
  {
    "text": "optimal way improving efficiency and",
    "start": "387520",
    "end": "389680"
  },
  {
    "text": "reducing CPU",
    "start": "389680",
    "end": "391080"
  },
  {
    "text": "bottlenecks specifically for table data",
    "start": "391080",
    "end": "393360"
  },
  {
    "text": "sets This would reduce CPU cycles spent",
    "start": "393360",
    "end": "395600"
  },
  {
    "text": "to convert data from a storage optimized",
    "start": "395600",
    "end": "398160"
  },
  {
    "text": "park format to a format which is uh",
    "start": "398160",
    "end": "400880"
  },
  {
    "text": "consumed by GPU workers and with",
    "start": "400880",
    "end": "403120"
  },
  {
    "text": "repetitive access pattern during",
    "start": "403120",
    "end": "404639"
  },
  {
    "text": "training cache reduces the need to fetch",
    "start": "404639",
    "end": "407759"
  },
  {
    "text": "the data from slower disc storage or",
    "start": "407759",
    "end": "410080"
  },
  {
    "text": "object stores minimizing IO latency",
    "start": "410080",
    "end": "412160"
  },
  {
    "text": "which is typically timeconuming and",
    "start": "412160",
    "end": "413600"
  },
  {
    "text": "latency",
    "start": "413600",
    "end": "416080"
  },
  {
    "text": "prone Also with also with distributed",
    "start": "417000",
    "end": "419680"
  },
  {
    "text": "caching um it also allows data to be",
    "start": "419680",
    "end": "421919"
  },
  {
    "text": "partitioned and stored across multiple",
    "start": "421919",
    "end": "424319"
  },
  {
    "text": "um multiple let's say multiple nodes and",
    "start": "424319",
    "end": "427039"
  },
  {
    "text": "this enables parallel access uh to these",
    "start": "427039",
    "end": "429280"
  },
  {
    "text": "shards from multiple workers improving",
    "start": "429280",
    "end": "430960"
  },
  {
    "text": "latency and throughput and by and by",
    "start": "430960",
    "end": "433520"
  },
  {
    "text": "loading or streaming only a portion of",
    "start": "433520",
    "end": "435440"
  },
  {
    "text": "our data set into memory each worker",
    "start": "435440",
    "end": "437680"
  },
  {
    "text": "requires less memory reducing the",
    "start": "437680",
    "end": "439759"
  },
  {
    "text": "overall memory footprint Also by",
    "start": "439759",
    "end": "442400"
  },
  {
    "text": "providing direct access to the sharded",
    "start": "442400",
    "end": "443840"
  },
  {
    "text": "data with caching",
    "start": "443840",
    "end": "446080"
  },
  {
    "text": "um it can easily allow workers to access",
    "start": "446080",
    "end": "448160"
  },
  {
    "text": "specific shards across",
    "start": "448160",
    "end": "450680"
  },
  {
    "text": "epochs Also when multiple training jobs",
    "start": "450680",
    "end": "453039"
  },
  {
    "text": "access the same data set caching",
    "start": "453039",
    "end": "455120"
  },
  {
    "text": "solution can greatly improve resource",
    "start": "455120",
    "end": "457360"
  },
  {
    "text": "usage reducing the need to redownload",
    "start": "457360",
    "end": "460319"
  },
  {
    "text": "and reprocess the um the entire data set",
    "start": "460319",
    "end": "463360"
  },
  {
    "text": "from storage",
    "start": "463360",
    "end": "466599"
  },
  {
    "text": "Hence the proposed solution this slide",
    "start": "467759",
    "end": "469759"
  },
  {
    "text": "actually talks about the uh overall",
    "start": "469759",
    "end": "471360"
  },
  {
    "text": "highle architecture and the proposed",
    "start": "471360",
    "end": "473440"
  },
  {
    "text": "solution consists of um loading and",
    "start": "473440",
    "end": "475599"
  },
  {
    "text": "caching the data in an iceberg table for",
    "start": "475599",
    "end": "477360"
  },
  {
    "text": "example in a parket format to a memory",
    "start": "477360",
    "end": "479599"
  },
  {
    "text": "efficient arrow",
    "start": "479599",
    "end": "480759"
  },
  {
    "text": "format So arrow is an um inmemory column",
    "start": "480759",
    "end": "484000"
  },
  {
    "text": "format supporting um zero copy reads",
    "start": "484000",
    "end": "486560"
  },
  {
    "text": "when sharing data between multiple",
    "start": "486560",
    "end": "488639"
  },
  {
    "text": "processor systems It's specifically",
    "start": "488639",
    "end": "491120"
  },
  {
    "text": "advantages to use with table data which",
    "start": "491120",
    "end": "493120"
  },
  {
    "text": "is um which is already stored in",
    "start": "493120",
    "end": "495280"
  },
  {
    "text": "columner format on on disk storage and",
    "start": "495280",
    "end": "497360"
  },
  {
    "text": "object",
    "start": "497360",
    "end": "498280"
  },
  {
    "text": "stores It also supports streaming",
    "start": "498280",
    "end": "500400"
  },
  {
    "text": "allowing clients to process batches of",
    "start": "500400",
    "end": "502240"
  },
  {
    "text": "data overlapping with the time spent to",
    "start": "502240",
    "end": "504319"
  },
  {
    "text": "derialize the next",
    "start": "504319",
    "end": "506360"
  },
  {
    "text": "batch and the architecture uses data",
    "start": "506360",
    "end": "509039"
  },
  {
    "text": "fusion uh to actually shard um Apache",
    "start": "509039",
    "end": "511599"
  },
  {
    "text": "data fusion to actually shard the data",
    "start": "511599",
    "end": "513200"
  },
  {
    "text": "sets data set and allowing clients to",
    "start": "513200",
    "end": "515440"
  },
  {
    "text": "actually query shard of arrow data So",
    "start": "515440",
    "end": "518159"
  },
  {
    "text": "data fusion is an embedded query engine",
    "start": "518159",
    "end": "520320"
  },
  {
    "text": "that uses arrow format and provides fast",
    "start": "520320",
    "end": "522560"
  },
  {
    "text": "inmemory proing capabilities on column",
    "start": "522560",
    "end": "524480"
  },
  {
    "text": "data It is extensible by design and has",
    "start": "524480",
    "end": "527440"
  },
  {
    "text": "several integrations with table and file",
    "start": "527440",
    "end": "529680"
  },
  {
    "text": "formats like",
    "start": "529680",
    "end": "531800"
  },
  {
    "text": "park and and to and finally to stream",
    "start": "531800",
    "end": "534640"
  },
  {
    "text": "the data set from cachet to GPU workers",
    "start": "534640",
    "end": "536959"
  },
  {
    "text": "Um the solution leverage uh Apache arrow",
    "start": "536959",
    "end": "539600"
  },
  {
    "text": "flight framework flight uh uh uses gRPC",
    "start": "539600",
    "end": "542720"
  },
  {
    "text": "API to actually send and receive arrow",
    "start": "542720",
    "end": "544320"
  },
  {
    "text": "arrays It optimizes gRPC API to directly",
    "start": "544320",
    "end": "547760"
  },
  {
    "text": "access inmemory buffer of error data to",
    "start": "547760",
    "end": "550320"
  },
  {
    "text": "convert it to an IPC format like to with",
    "start": "550320",
    "end": "552640"
  },
  {
    "text": "no serialization",
    "start": "552640",
    "end": "554279"
  },
  {
    "text": "overhead framework Uh the flight",
    "start": "554279",
    "end": "556399"
  },
  {
    "text": "framework also allows clients to access",
    "start": "556399",
    "end": "557920"
  },
  {
    "text": "the data directly from data nodes",
    "start": "557920",
    "end": "559680"
  },
  {
    "text": "without streaming from coordinator like",
    "start": "559680",
    "end": "561680"
  },
  {
    "text": "improving which improves the resource",
    "start": "561680",
    "end": "563399"
  },
  {
    "text": "utilization particularly when dealing",
    "start": "563399",
    "end": "565279"
  },
  {
    "text": "with large data",
    "start": "565279",
    "end": "567959"
  },
  {
    "text": "sets Here we providing um high level",
    "start": "567959",
    "end": "570560"
  },
  {
    "text": "overview of the functioning of the cache",
    "start": "570560",
    "end": "572560"
  },
  {
    "text": "Here um this slide specifically",
    "start": "572560",
    "end": "574399"
  },
  {
    "text": "describes the bootstrap of the cache",
    "start": "574399",
    "end": "575839"
  },
  {
    "text": "with data and head",
    "start": "575839",
    "end": "577160"
  },
  {
    "text": "nodes So um during the during the",
    "start": "577160",
    "end": "579920"
  },
  {
    "text": "bootstrap a head nodes um can scan the",
    "start": "579920",
    "end": "582880"
  },
  {
    "text": "iceberg table to fetch the metadata of",
    "start": "582880",
    "end": "584720"
  },
  {
    "text": "relevant data files uh in the table It",
    "start": "584720",
    "end": "587760"
  },
  {
    "text": "then groups the data files equally based",
    "start": "587760",
    "end": "589600"
  },
  {
    "text": "on the number of rows into logical",
    "start": "589600",
    "end": "591040"
  },
  {
    "text": "shards It then distributes the shards to",
    "start": "591040",
    "end": "593600"
  },
  {
    "text": "data nodes in a round rob fashion And",
    "start": "593600",
    "end": "596080"
  },
  {
    "text": "then the headnode constructs an index",
    "start": "596080",
    "end": "597920"
  },
  {
    "text": "table which actually stores the metadata",
    "start": "597920",
    "end": "599680"
  },
  {
    "text": "about individual charts So this um so",
    "start": "599680",
    "end": "602480"
  },
  {
    "text": "this table contains information like the",
    "start": "602480",
    "end": "604399"
  },
  {
    "text": "shard location and the and the range of",
    "start": "604399",
    "end": "606720"
  },
  {
    "text": "the rows in that",
    "start": "606720",
    "end": "608440"
  },
  {
    "text": "shard and um the other hand the data",
    "start": "608440",
    "end": "611120"
  },
  {
    "text": "node loads the data from these data",
    "start": "611120",
    "end": "613200"
  },
  {
    "text": "files into arrow format in an inmemory",
    "start": "613200",
    "end": "615680"
  },
  {
    "text": "table and adds an indexing column for",
    "start": "615680",
    "end": "618160"
  },
  {
    "text": "every batch as it loads to the table So",
    "start": "618160",
    "end": "620480"
  },
  {
    "text": "hidden uh worker nodes today are",
    "start": "620480",
    "end": "622640"
  },
  {
    "text": "implemented using rasbased data fusion",
    "start": "622640",
    "end": "624880"
  },
  {
    "text": "for transforming the park files to",
    "start": "624880",
    "end": "626880"
  },
  {
    "text": "inmemory arrow tables and use it to and",
    "start": "626880",
    "end": "629360"
  },
  {
    "text": "use the data fusion actually to um um to",
    "start": "629360",
    "end": "632560"
  },
  {
    "text": "for its memory efficient query execution",
    "start": "632560",
    "end": "635200"
  },
  {
    "text": "to query these",
    "start": "635200",
    "end": "638160"
  },
  {
    "text": "tables So uh once the cache is ready so",
    "start": "638279",
    "end": "641120"
  },
  {
    "text": "this slide talks about how GPU workers",
    "start": "641120",
    "end": "642959"
  },
  {
    "text": "can access and stream data set from",
    "start": "642959",
    "end": "644839"
  },
  {
    "text": "cache So let's say the in this case like",
    "start": "644839",
    "end": "648079"
  },
  {
    "text": "head node is responsible to autoshot the",
    "start": "648079",
    "end": "650079"
  },
  {
    "text": "data set logically based on the number",
    "start": "650079",
    "end": "652079"
  },
  {
    "text": "of GPU workers in a training job and",
    "start": "652079",
    "end": "654800"
  },
  {
    "text": "workers access the shard using ind shard",
    "start": "654800",
    "end": "657279"
  },
  {
    "text": "index that is passed to head node using",
    "start": "657279",
    "end": "659040"
  },
  {
    "text": "the flight protocol So for forh in this",
    "start": "659040",
    "end": "662640"
  },
  {
    "text": "example shown in this slide So rank two",
    "start": "662640",
    "end": "664800"
  },
  {
    "text": "of a train job access a head node first",
    "start": "664800",
    "end": "667440"
  },
  {
    "text": "to know about the location of the shard",
    "start": "667440",
    "end": "669360"
  },
  {
    "text": "with index one Head node responds back",
    "start": "669360",
    "end": "671600"
  },
  {
    "text": "with the endpoints to access um which",
    "start": "671600",
    "end": "673920"
  },
  {
    "text": "allows the clients to directly access",
    "start": "673920",
    "end": "675279"
  },
  {
    "text": "the data nodes to fetch the data So in",
    "start": "675279",
    "end": "677120"
  },
  {
    "text": "this case shard lives in both data node",
    "start": "677120",
    "end": "678800"
  },
  {
    "text": "one and data node two and workers then",
    "start": "678800",
    "end": "681680"
  },
  {
    "text": "um connect to uh data nodes to access",
    "start": "681680",
    "end": "684160"
  },
  {
    "text": "the shard using a range query on the on",
    "start": "684160",
    "end": "686399"
  },
  {
    "text": "inmemory table on on a on a data node",
    "start": "686399",
    "end": "689680"
  },
  {
    "text": "So this architecture implementation with",
    "start": "689680",
    "end": "691279"
  },
  {
    "text": "data fusion is beneficial as for",
    "start": "691279",
    "end": "693839"
  },
  {
    "text": "specific reasons like the data is stored",
    "start": "693839",
    "end": "696240"
  },
  {
    "text": "in arrow format and using data fusion to",
    "start": "696240",
    "end": "698399"
  },
  {
    "text": "select a range of rows from a table is",
    "start": "698399",
    "end": "700240"
  },
  {
    "text": "very efficient fast as data is",
    "start": "700240",
    "end": "702560"
  },
  {
    "text": "represented as continuous block in a",
    "start": "702560",
    "end": "704440"
  },
  {
    "text": "memory and since data node hence the",
    "start": "704440",
    "end": "707920"
  },
  {
    "text": "head node creates logical shards it",
    "start": "707920",
    "end": "710320"
  },
  {
    "text": "doesn't require to reshuffle the data",
    "start": "710320",
    "end": "711760"
  },
  {
    "text": "across nodes Hence multiple jobs with",
    "start": "711760",
    "end": "714399"
  },
  {
    "text": "different topology can access the same",
    "start": "714399",
    "end": "716160"
  },
  {
    "text": "cache instance which would allow for",
    "start": "716160",
    "end": "718000"
  },
  {
    "text": "reusing of the data set when in a let's",
    "start": "718000",
    "end": "720880"
  },
  {
    "text": "say for example a Kubernetes",
    "start": "720880",
    "end": "723480"
  },
  {
    "text": "cluster and to shard uh to shuffle",
    "start": "723480",
    "end": "726880"
  },
  {
    "text": "across epochs clients can dynamically",
    "start": "726880",
    "end": "728399"
  },
  {
    "text": "compute chart index which is which can",
    "start": "728399",
    "end": "730399"
  },
  {
    "text": "be different for every",
    "start": "730399",
    "end": "733120"
  },
  {
    "text": "epoch So this slide describes key",
    "start": "733160",
    "end": "735839"
  },
  {
    "text": "concepts with flight framework and",
    "start": "735839",
    "end": "737680"
  },
  {
    "text": "flight client um that can be used to",
    "start": "737680",
    "end": "740480"
  },
  {
    "text": "stream the data using flight API It",
    "start": "740480",
    "end": "742639"
  },
  {
    "text": "actually talks about creating a flight",
    "start": "742639",
    "end": "744320"
  },
  {
    "text": "descriptor which is um which describes",
    "start": "744320",
    "end": "747040"
  },
  {
    "text": "about the identifier to access the data",
    "start": "747040",
    "end": "748560"
  },
  {
    "text": "shed data shard and um the client passes",
    "start": "748560",
    "end": "751600"
  },
  {
    "text": "this info uh to the head node with get",
    "start": "751600",
    "end": "754079"
  },
  {
    "text": "flight call flight info call to fetch",
    "start": "754079",
    "end": "755920"
  },
  {
    "text": "the flights and each flight consists of",
    "start": "755920",
    "end": "758800"
  },
  {
    "text": "an endpoint to access and the ticket",
    "start": "758800",
    "end": "760720"
  },
  {
    "text": "that is that's required to pass to the",
    "start": "760720",
    "end": "762959"
  },
  {
    "text": "data node to access that specific",
    "start": "762959",
    "end": "765079"
  },
  {
    "text": "shard And if the shard that's being",
    "start": "765079",
    "end": "767600"
  },
  {
    "text": "accessed lives in multiple data nodes",
    "start": "767600",
    "end": "769040"
  },
  {
    "text": "like we saw in the previous example the",
    "start": "769040",
    "end": "770560"
  },
  {
    "text": "flight info would have multiple flights",
    "start": "770560",
    "end": "772800"
  },
  {
    "text": "um in the",
    "start": "772800",
    "end": "773959"
  },
  {
    "text": "response Using this flight info clients",
    "start": "773959",
    "end": "776480"
  },
  {
    "text": "can stream arrow record batches from um",
    "start": "776480",
    "end": "778720"
  },
  {
    "text": "data nodes And in the in the next in the",
    "start": "778720",
    "end": "781519"
  },
  {
    "text": "demo we'll also see how we can use this",
    "start": "781519",
    "end": "783279"
  },
  {
    "text": "flight client um to with pyarch data",
    "start": "783279",
    "end": "786320"
  },
  {
    "text": "loader to actually access the data from",
    "start": "786320",
    "end": "788480"
  },
  {
    "text": "data from cacher during a training",
    "start": "788480",
    "end": "791639"
  },
  {
    "text": "run and and to leverage cache with um",
    "start": "791639",
    "end": "794959"
  },
  {
    "text": "training on kubernetes Users can easily",
    "start": "794959",
    "end": "796880"
  },
  {
    "text": "integrate with",
    "start": "796880",
    "end": "798279"
  },
  {
    "text": "cubeflow Users can uh extend any of the",
    "start": "798279",
    "end": "801200"
  },
  {
    "text": "existing runtimes which are the",
    "start": "801200",
    "end": "802880"
  },
  {
    "text": "blueprints which we talked about earlier",
    "start": "802880",
    "end": "804480"
  },
  {
    "text": "to add cache iner as a data set",
    "start": "804480",
    "end": "806680"
  },
  {
    "text": "initializer And once the cache is up and",
    "start": "806680",
    "end": "809040"
  },
  {
    "text": "running workers workers can be scheduled",
    "start": "809040",
    "end": "811440"
  },
  {
    "text": "to access the data in from cache in",
    "start": "811440",
    "end": "813240"
  },
  {
    "text": "parallel So currently the life cycle of",
    "start": "813240",
    "end": "815680"
  },
  {
    "text": "the um cache itself is tied to the train",
    "start": "815680",
    "end": "818560"
  },
  {
    "text": "job by adding the owner reference um",
    "start": "818560",
    "end": "820959"
  },
  {
    "text": "which would launch the cache specific to",
    "start": "820959",
    "end": "823040"
  },
  {
    "text": "the uh job and destroy it on the",
    "start": "823040",
    "end": "825040"
  },
  {
    "text": "completion of the",
    "start": "825040",
    "end": "826519"
  },
  {
    "text": "job and the cluster is deployed using",
    "start": "826519",
    "end": "829040"
  },
  {
    "text": "leader worker set API on Kubernetes Um",
    "start": "829040",
    "end": "831519"
  },
  {
    "text": "the leader worker set is used for to",
    "start": "831519",
    "end": "834480"
  },
  {
    "text": "disadvantage specifically like deploys",
    "start": "834480",
    "end": "836720"
  },
  {
    "text": "cluster as single unit and um that can",
    "start": "836720",
    "end": "839519"
  },
  {
    "text": "easily that that can be used to easily",
    "start": "839519",
    "end": "841440"
  },
  {
    "text": "scale scale it with multiple replicas",
    "start": "841440",
    "end": "843360"
  },
  {
    "text": "for fall tolerance and",
    "start": "843360",
    "end": "844839"
  },
  {
    "text": "HA It provides a failure handling with",
    "start": "844839",
    "end": "847440"
  },
  {
    "text": "all or nothing restart across the nodes",
    "start": "847440",
    "end": "849440"
  },
  {
    "text": "avoiding partial failures in this case",
    "start": "849440",
    "end": "851279"
  },
  {
    "text": "as data is in",
    "start": "851279",
    "end": "852680"
  },
  {
    "text": "inmemory It also provides support for",
    "start": "852680",
    "end": "854880"
  },
  {
    "text": "dual templates uh which advantages here",
    "start": "854880",
    "end": "857279"
  },
  {
    "text": "because the data nodes might require",
    "start": "857279",
    "end": "859760"
  },
  {
    "text": "more resources compared to the head",
    "start": "859760",
    "end": "861160"
  },
  {
    "text": "nodes and um and also we're excited",
    "start": "861160",
    "end": "863839"
  },
  {
    "text": "about the future road map of this",
    "start": "863839",
    "end": "865440"
  },
  {
    "text": "project because it also in line to",
    "start": "865440",
    "end": "867279"
  },
  {
    "text": "support gang scheduling enabling all or",
    "start": "867279",
    "end": "869360"
  },
  {
    "text": "nothing scheduling of nodes which with",
    "start": "869360",
    "end": "871440"
  },
  {
    "text": "with the launch of train",
    "start": "871440",
    "end": "874120"
  },
  {
    "text": "job and um this slide specifically talks",
    "start": "874120",
    "end": "876720"
  },
  {
    "text": "about how easy it is to configure and",
    "start": "876720",
    "end": "878320"
  },
  {
    "text": "create train job with cache as a cluster",
    "start": "878320",
    "end": "881040"
  },
  {
    "text": "operators can actually uh update",
    "start": "881040",
    "end": "883199"
  },
  {
    "text": "existing ing runtimes with the template",
    "start": "883199",
    "end": "884720"
  },
  {
    "text": "spec to add custom initializer job and",
    "start": "884720",
    "end": "886880"
  },
  {
    "text": "ML users on the right side can easily",
    "start": "886880",
    "end": "889920"
  },
  {
    "text": "create a train job using the passing the",
    "start": "889920",
    "end": "891920"
  },
  {
    "text": "data set initializer config or like or",
    "start": "891920",
    "end": "894240"
  },
  {
    "text": "the data data source config um with",
    "start": "894240",
    "end": "896320"
  },
  {
    "text": "using the",
    "start": "896320",
    "end": "897639"
  },
  {
    "text": "SDK The API itself is extensible that",
    "start": "897639",
    "end": "900320"
  },
  {
    "text": "the operators can configure cachzer to",
    "start": "900320",
    "end": "902560"
  },
  {
    "text": "launch on uh to launch the cluster on",
    "start": "902560",
    "end": "904399"
  },
  {
    "text": "CPU node groups uh specifically with",
    "start": "904399",
    "end": "906480"
  },
  {
    "text": "memory optimized um instances for",
    "start": "906480",
    "end": "908800"
  },
  {
    "text": "warming up the cache and leveraging um",
    "start": "908800",
    "end": "911920"
  },
  {
    "text": "which and using CPU groups because it's",
    "start": "911920",
    "end": "914160"
  },
  {
    "text": "CP intensive task and leveraging GPU",
    "start": "914160",
    "end": "916079"
  },
  {
    "text": "nodes for uh uh to schedule training",
    "start": "916079",
    "end": "918399"
  },
  {
    "text": "training",
    "start": "918399",
    "end": "919959"
  },
  {
    "text": "pods Using this example we also want to",
    "start": "919959",
    "end": "922480"
  },
  {
    "text": "demonstrate how cubeflow trainer can be",
    "start": "922480",
    "end": "924399"
  },
  {
    "text": "easily extended to support various use",
    "start": "924399",
    "end": "926320"
  },
  {
    "text": "cases",
    "start": "926320",
    "end": "929040"
  },
  {
    "text": "Now we'll um see in the demo how uh easy",
    "start": "929040",
    "end": "931519"
  },
  {
    "text": "it is to integrate with PyTorch uh to",
    "start": "931519",
    "end": "934240"
  },
  {
    "text": "fine-tune an",
    "start": "934240",
    "end": "936800"
  },
  {
    "text": "LLM So um here um I have a notebook",
    "start": "939320",
    "end": "943199"
  },
  {
    "text": "where um uh it'll it'll it's actually um",
    "start": "943199",
    "end": "947360"
  },
  {
    "text": "using B model to fine-tune using an LPV",
    "start": "947360",
    "end": "950880"
  },
  {
    "text": "data set using cubeflow train job and",
    "start": "950880",
    "end": "953040"
  },
  {
    "text": "the LPV data set uh is currently in an",
    "start": "953040",
    "end": "955440"
  },
  {
    "text": "iceberg table First user can create um",
    "start": "955440",
    "end": "958880"
  },
  {
    "text": "would need to install the SDK and using",
    "start": "958880",
    "end": "961600"
  },
  {
    "text": "the SDK users can",
    "start": "961600",
    "end": "964759"
  },
  {
    "text": "um you um users can access the um",
    "start": "964759",
    "end": "969800"
  },
  {
    "text": "cubeflow um uh cubeflow train uh",
    "start": "969800",
    "end": "972959"
  },
  {
    "text": "runtimes So here um with SDK we can list",
    "start": "972959",
    "end": "975680"
  },
  {
    "text": "the runtimes in this cluster Let's say I",
    "start": "975680",
    "end": "977600"
  },
  {
    "text": "have three runtimes I'm specifically",
    "start": "977600",
    "end": "979440"
  },
  {
    "text": "interested in the runtime distribute",
    "start": "979440",
    "end": "981160"
  },
  {
    "text": "cach So this has all the config which we",
    "start": "981160",
    "end": "984320"
  },
  {
    "text": "talked about earlier where we'll um",
    "start": "984320",
    "end": "986240"
  },
  {
    "text": "where we'll we added the cache in slicer",
    "start": "986240",
    "end": "989040"
  },
  {
    "text": "as a um as the first step um during the",
    "start": "989040",
    "end": "992240"
  },
  {
    "text": "uh run of the train job and the next",
    "start": "992240",
    "end": "995199"
  },
  {
    "text": "step we'll uh specifically use um uh to",
    "start": "995199",
    "end": "998240"
  },
  {
    "text": "create a to run uh to create a training",
    "start": "998240",
    "end": "1001040"
  },
  {
    "text": "function which would actually access",
    "start": "1001040",
    "end": "1003519"
  },
  {
    "text": "data in the cache In order to do that uh",
    "start": "1003519",
    "end": "1006000"
  },
  {
    "text": "we'll we are interested in creating a",
    "start": "1006000",
    "end": "1008639"
  },
  {
    "text": "cacher data set API which is an iterable",
    "start": "1008639",
    "end": "1011360"
  },
  {
    "text": "data set from PyTorch taking in the bat",
    "start": "1011360",
    "end": "1015000"
  },
  {
    "text": "size and um in the iterator um for every",
    "start": "1015000",
    "end": "1019680"
  },
  {
    "text": "um uh in the iterator we actually",
    "start": "1019680",
    "end": "1021440"
  },
  {
    "text": "calculate the shard index dynamically",
    "start": "1021440",
    "end": "1023920"
  },
  {
    "text": "for that specific data set and use the",
    "start": "1023920",
    "end": "1026319"
  },
  {
    "text": "flight client which we described earlier",
    "start": "1026319",
    "end": "1027839"
  },
  {
    "text": "Here I'm using Pyro flight client uh",
    "start": "1027839",
    "end": "1030079"
  },
  {
    "text": "creating a flight descriptor and passing",
    "start": "1030079",
    "end": "1031918"
  },
  {
    "text": "that flight client with descriptor with",
    "start": "1031919",
    "end": "1034720"
  },
  {
    "text": "the shard shard information shard index",
    "start": "1034720",
    "end": "1037120"
  },
  {
    "text": "specifically and connecting to the head",
    "start": "1037120",
    "end": "1038959"
  },
  {
    "text": "node to get the list of endpoints and um",
    "start": "1038959",
    "end": "1042880"
  },
  {
    "text": "and use the and uh connect to this data",
    "start": "1042880",
    "end": "1045199"
  },
  {
    "text": "nodes using the endpoints passing in the",
    "start": "1045199",
    "end": "1046880"
  },
  {
    "text": "tickets which has the um which has the",
    "start": "1046880",
    "end": "1050160"
  },
  {
    "text": "range of rows to actually",
    "start": "1050160",
    "end": "1053160"
  },
  {
    "text": "stream and then um I'm converting the",
    "start": "1053160",
    "end": "1055840"
  },
  {
    "text": "record batch the arrow batch",
    "start": "1055840",
    "end": "1058320"
  },
  {
    "text": "um into chunks where each chunk is of",
    "start": "1058320",
    "end": "1060720"
  },
  {
    "text": "batch size and um in the chunk um we'll",
    "start": "1060720",
    "end": "1065679"
  },
  {
    "text": "um we'll specifically use a function to",
    "start": "1065679",
    "end": "1068960"
  },
  {
    "text": "convert the arrow record batch data to a",
    "start": "1068960",
    "end": "1071200"
  },
  {
    "text": "tensor For that let's say for for this",
    "start": "1071200",
    "end": "1073840"
  },
  {
    "text": "specific example I'm using L preview",
    "start": "1073840",
    "end": "1075840"
  },
  {
    "text": "data set So I'm um overriding my",
    "start": "1075840",
    "end": "1078480"
  },
  {
    "text": "function to actually convert uh the",
    "start": "1078480",
    "end": "1080960"
  },
  {
    "text": "record batch to a tensor um by by um",
    "start": "1080960",
    "end": "1084799"
  },
  {
    "text": "converting using the um arrow APIs to",
    "start": "1084799",
    "end": "1087679"
  },
  {
    "text": "actually convert to a pyarch data",
    "start": "1087679",
    "end": "1089840"
  },
  {
    "text": "structures with no copy which is the",
    "start": "1089840",
    "end": "1092160"
  },
  {
    "text": "benefit of arrow data and um using",
    "start": "1092160",
    "end": "1095520"
  },
  {
    "text": "tokenizer from hugging face to actually",
    "start": "1095520",
    "end": "1097360"
  },
  {
    "text": "encode and uh converting it to a tensors",
    "start": "1097360",
    "end": "1100799"
  },
  {
    "text": "and passing the tensors back This",
    "start": "1100799",
    "end": "1103280"
  },
  {
    "text": "actually is a I'm using a pyarch data",
    "start": "1103280",
    "end": "1105520"
  },
  {
    "text": "loader to uh train the function to load",
    "start": "1105520",
    "end": "1108480"
  },
  {
    "text": "the to load the data set from um the",
    "start": "1108480",
    "end": "1110960"
  },
  {
    "text": "cache and um I'm running a training",
    "start": "1110960",
    "end": "1114080"
  },
  {
    "text": "training loop here and once we define",
    "start": "1114080",
    "end": "1116720"
  },
  {
    "text": "the training function the next step is",
    "start": "1116720",
    "end": "1118320"
  },
  {
    "text": "to use uh the SDK to create a custom",
    "start": "1118320",
    "end": "1120960"
  },
  {
    "text": "trainer pass in my train function and",
    "start": "1120960",
    "end": "1122960"
  },
  {
    "text": "the configuration required to uh for my",
    "start": "1122960",
    "end": "1125280"
  },
  {
    "text": "training job and uh required packages to",
    "start": "1125280",
    "end": "1128559"
  },
  {
    "text": "install uh in this case and in this case",
    "start": "1128559",
    "end": "1131440"
  },
  {
    "text": "specifically I'm accessing a specific um",
    "start": "1131440",
    "end": "1134000"
  },
  {
    "text": "icebook table So I'm passing in a custom",
    "start": "1134000",
    "end": "1136160"
  },
  {
    "text": "data set config which is arrow data data",
    "start": "1136160",
    "end": "1138160"
  },
  {
    "text": "set",
    "start": "1138160",
    "end": "1139000"
  },
  {
    "text": "config Um I'm passing in an initializer",
    "start": "1139000",
    "end": "1142080"
  },
  {
    "text": "with the custom config here Uh here I'm",
    "start": "1142080",
    "end": "1144640"
  },
  {
    "text": "just accessing static table Uh so hence",
    "start": "1144640",
    "end": "1147280"
  },
  {
    "text": "I'm using the my metadata JSON file and",
    "start": "1147280",
    "end": "1150320"
  },
  {
    "text": "also once I configure the initializer",
    "start": "1150320",
    "end": "1152160"
  },
  {
    "text": "I'm also passing the runtime which I'm",
    "start": "1152160",
    "end": "1153600"
  },
  {
    "text": "interested in um where I configure the",
    "start": "1153600",
    "end": "1156640"
  },
  {
    "text": "cache So um I'm creating a train um I'm",
    "start": "1156640",
    "end": "1160640"
  },
  {
    "text": "triggering a train",
    "start": "1160640",
    "end": "1161960"
  },
  {
    "text": "function You we can use the SDK to",
    "start": "1161960",
    "end": "1164320"
  },
  {
    "text": "actually list uh the train jobs Now the",
    "start": "1164320",
    "end": "1166799"
  },
  {
    "text": "train job is in created",
    "start": "1166799",
    "end": "1168440"
  },
  {
    "text": "state I can uh also see my",
    "start": "1168440",
    "end": "1173480"
  },
  {
    "text": "um my u the um the initializer is",
    "start": "1173480",
    "end": "1177360"
  },
  {
    "text": "actually triggered by the runtime which",
    "start": "1177360",
    "end": "1180240"
  },
  {
    "text": "uses the runtime initializer and it",
    "start": "1180240",
    "end": "1182000"
  },
  {
    "text": "triggered a cache This leader work is a",
    "start": "1182000",
    "end": "1184080"
  },
  {
    "text": "cache instance which is triggered",
    "start": "1184080",
    "end": "1186080"
  },
  {
    "text": "directly from the train job and uh it",
    "start": "1186080",
    "end": "1188640"
  },
  {
    "text": "would wait for the uh we would wait for",
    "start": "1188640",
    "end": "1190720"
  },
  {
    "text": "the cluster to be cache cluster to be",
    "start": "1190720",
    "end": "1193200"
  },
  {
    "text": "ready and once it's ready um it would uh",
    "start": "1193200",
    "end": "1196480"
  },
  {
    "text": "the train job would trigger um the",
    "start": "1196480",
    "end": "1200160"
  },
  {
    "text": "workers in",
    "start": "1200160",
    "end": "1201799"
  },
  {
    "text": "parallel These workers are configured um",
    "start": "1201799",
    "end": "1205200"
  },
  {
    "text": "these workers would access the uh the",
    "start": "1205200",
    "end": "1208320"
  },
  {
    "text": "cluster to access the data without any",
    "start": "1208320",
    "end": "1211200"
  },
  {
    "text": "decentralization cost Users can also use",
    "start": "1211200",
    "end": "1214240"
  },
  {
    "text": "SDK to actually check the",
    "start": "1214240",
    "end": "1217919"
  },
  {
    "text": "um the status of the job and also stream",
    "start": "1217919",
    "end": "1221600"
  },
  {
    "text": "the logs directly from using SDK Here in",
    "start": "1221600",
    "end": "1225600"
  },
  {
    "text": "this case I'm actually streaming the",
    "start": "1225600",
    "end": "1227200"
  },
  {
    "text": "logs from the",
    "start": "1227200",
    "end": "1229400"
  },
  {
    "text": "um the the um trainer node.0 zero and",
    "start": "1229400",
    "end": "1233760"
  },
  {
    "text": "where it's accessing the batch record",
    "start": "1233760",
    "end": "1235840"
  },
  {
    "text": "batch and converting its So this just",
    "start": "1235840",
    "end": "1238720"
  },
  {
    "text": "demonstrates how easy it is to plug the",
    "start": "1238720",
    "end": "1240799"
  },
  {
    "text": "cache uh into the life cycle of train",
    "start": "1240799",
    "end": "1243960"
  },
  {
    "text": "job Going back to the",
    "start": "1243960",
    "end": "1246200"
  },
  {
    "text": "slides here",
    "start": "1246200",
    "end": "1248280"
  },
  {
    "text": "um so um so reiterating the benefits",
    "start": "1248280",
    "end": "1251360"
  },
  {
    "text": "with cach so users can easily access the",
    "start": "1251360",
    "end": "1254240"
  },
  {
    "text": "table data from cache without worrying",
    "start": "1254240",
    "end": "1256320"
  },
  {
    "text": "about sharding of the data set across",
    "start": "1256320",
    "end": "1257919"
  },
  {
    "text": "GPU worker nodes Users can see improved",
    "start": "1257919",
    "end": "1260720"
  },
  {
    "text": "uh GP utilization as workers consume",
    "start": "1260720",
    "end": "1262880"
  },
  {
    "text": "data via zero copy arrow streams",
    "start": "1262880",
    "end": "1264880"
  },
  {
    "text": "eliminating the need to des serialize uh",
    "start": "1264880",
    "end": "1267360"
  },
  {
    "text": "the data and it supports direct",
    "start": "1267360",
    "end": "1269840"
  },
  {
    "text": "conversions to pandas or",
    "start": "1269840",
    "end": "1271960"
  },
  {
    "text": "numpy So data set installation parts can",
    "start": "1271960",
    "end": "1274960"
  },
  {
    "text": "be scheduled on GPU nodes freeing CPU",
    "start": "1274960",
    "end": "1277360"
  },
  {
    "text": "nodes freeing the GPU nodes from",
    "start": "1277360",
    "end": "1279360"
  },
  {
    "text": "computer intensive workloads and users",
    "start": "1279360",
    "end": "1282080"
  },
  {
    "text": "can also launch uh training workers with",
    "start": "1282080",
    "end": "1284400"
  },
  {
    "text": "reduced memory and this size as clients",
    "start": "1284400",
    "end": "1286159"
  },
  {
    "text": "can uh can stream data a batch of data",
    "start": "1286159",
    "end": "1288480"
  },
  {
    "text": "from",
    "start": "1288480",
    "end": "1289799"
  },
  {
    "text": "cache Users can also easily shuffle",
    "start": "1289799",
    "end": "1292320"
  },
  {
    "text": "globally across partitions while",
    "start": "1292320",
    "end": "1294559"
  },
  {
    "text": "maintaining per batch um in memory",
    "start": "1294559",
    "end": "1296880"
  },
  {
    "text": "shuffling as well and multiple users",
    "start": "1296880",
    "end": "1299280"
  },
  {
    "text": "running uh train jobs in the cluster can",
    "start": "1299280",
    "end": "1301280"
  },
  {
    "text": "access same data set cache irrespective",
    "start": "1301280",
    "end": "1303039"
  },
  {
    "text": "of the number of",
    "start": "1303039",
    "end": "1304679"
  },
  {
    "text": "workers and um the users can also use um",
    "start": "1304679",
    "end": "1308320"
  },
  {
    "text": "leverage uh cubeflow trainer API to",
    "start": "1308320",
    "end": "1310640"
  },
  {
    "text": "provision and access cache without any",
    "start": "1310640",
    "end": "1312480"
  },
  {
    "text": "overhead simplifying u the creation of",
    "start": "1312480",
    "end": "1315520"
  },
  {
    "text": "jobs using SDK and",
    "start": "1315520",
    "end": "1318720"
  },
  {
    "text": "runtimes So um regarding the future work",
    "start": "1319080",
    "end": "1322559"
  },
  {
    "text": "we've um we have proposed an enhance uh",
    "start": "1322559",
    "end": "1325360"
  },
  {
    "text": "kept with cubeflow community which we",
    "start": "1325360",
    "end": "1328000"
  },
  {
    "text": "shared um with the community and we are",
    "start": "1328000",
    "end": "1331600"
  },
  {
    "text": "um we are soliciting feedback from the",
    "start": "1331600",
    "end": "1333520"
  },
  {
    "text": "community and we're also working on",
    "start": "1333520",
    "end": "1335320"
  },
  {
    "text": "benchmarks So currently we u as a next",
    "start": "1335320",
    "end": "1338240"
  },
  {
    "text": "step we also want to support um",
    "start": "1338240",
    "end": "1339919"
  },
  {
    "text": "accessing data set via catalog Right now",
    "start": "1339919",
    "end": "1342240"
  },
  {
    "text": "uh as an example I'm just I just showed",
    "start": "1342240",
    "end": "1344400"
  },
  {
    "text": "how easy it is to access via static",
    "start": "1344400",
    "end": "1346720"
  },
  {
    "text": "table but we want to support",
    "start": "1346720",
    "end": "1349400"
  },
  {
    "text": "catalogs and also we want to uh support",
    "start": "1349400",
    "end": "1352559"
  },
  {
    "text": "calculating the cluster size based on",
    "start": "1352559",
    "end": "1354559"
  },
  {
    "text": "data set size without requiring users to",
    "start": "1354559",
    "end": "1356720"
  },
  {
    "text": "configure the size of the cluster",
    "start": "1356720",
    "end": "1358960"
  },
  {
    "text": "manually using the train job uh",
    "start": "1358960",
    "end": "1362200"
  },
  {
    "text": "SDK and um right now the life cycle of",
    "start": "1362200",
    "end": "1365919"
  },
  {
    "text": "the cluster itself is um tied to the uh",
    "start": "1365919",
    "end": "1369120"
  },
  {
    "text": "life cycle of the train jobs So we want",
    "start": "1369120",
    "end": "1371280"
  },
  {
    "text": "to we want to support um reusing of the",
    "start": "1371280",
    "end": "1374080"
  },
  {
    "text": "cache uh from multiple jobs as well Um",
    "start": "1374080",
    "end": "1377440"
  },
  {
    "text": "and also we want to support custom",
    "start": "1377440",
    "end": "1379120"
  },
  {
    "text": "iceberg types and tensor types Um and we",
    "start": "1379120",
    "end": "1382159"
  },
  {
    "text": "want to try to see um to support u",
    "start": "1382159",
    "end": "1385120"
  },
  {
    "text": "trainer v1 um qfl trainer v1 as",
    "start": "1385120",
    "end": "1388600"
  },
  {
    "text": "well This has a link uh QR code has a",
    "start": "1388600",
    "end": "1391360"
  },
  {
    "text": "link to the proposal which we shared",
    "start": "1391360",
    "end": "1392640"
  },
  {
    "text": "with the community and uh yeah let let",
    "start": "1392640",
    "end": "1395039"
  },
  {
    "text": "us know if you have any questions Thanks",
    "start": "1395039",
    "end": "1397679"
  },
  {
    "text": "Let me go back to QR for a second",
    "start": "1397679",
    "end": "1401840"
  },
  {
    "text": "I think we have one minute for the",
    "start": "1402000",
    "end": "1403360"
  },
  {
    "text": "question Uh any questions from from the",
    "start": "1403360",
    "end": "1406720"
  },
  {
    "text": "audience Yeah go ahead Uh can you take",
    "start": "1406720",
    "end": "1408320"
  },
  {
    "text": "the mic here and feel free to ask",
    "start": "1408320",
    "end": "1410320"
  },
  {
    "text": "questions",
    "start": "1410320",
    "end": "1413320"
  },
  {
    "text": "Let me bring you the mic",
    "start": "1413840",
    "end": "1417559"
  },
  {
    "text": "Well thank you very much I have a",
    "start": "1418320",
    "end": "1420080"
  },
  {
    "text": "actually a very simple question Uh I I",
    "start": "1420080",
    "end": "1422559"
  },
  {
    "text": "don't think we have been using this more",
    "start": "1422559",
    "end": "1425520"
  },
  {
    "text": "advanced ways of training I think we've",
    "start": "1425520",
    "end": "1427039"
  },
  {
    "text": "been using Cubeflow for 45 years Four",
    "start": "1427039",
    "end": "1429600"
  },
  {
    "text": "not 45 four and a half years I meant to",
    "start": "1429600",
    "end": "1433360"
  },
  {
    "text": "say Um and we just train on the",
    "start": "1433360",
    "end": "1436080"
  },
  {
    "text": "pipelines and uh we have a lot of issues",
    "start": "1436080",
    "end": "1438159"
  },
  {
    "text": "with that Sometimes the pipeline fails",
    "start": "1438159",
    "end": "1439919"
  },
  {
    "text": "But I I one of the common issues we have",
    "start": "1439919",
    "end": "1442880"
  },
  {
    "text": "is that we are lacking these gigantic",
    "start": "1442880",
    "end": "1445280"
  },
  {
    "text": "data sets And uh my question is like",
    "start": "1445280",
    "end": "1447840"
  },
  {
    "text": "this data set initializer is that",
    "start": "1447840",
    "end": "1449760"
  },
  {
    "text": "something you created from scratch Is",
    "start": "1449760",
    "end": "1451520"
  },
  {
    "text": "that something that's part of the",
    "start": "1451520",
    "end": "1453200"
  },
  {
    "text": "cluster training runtime um because I'm",
    "start": "1453200",
    "end": "1456159"
  },
  {
    "text": "I'm not familiar with this I haven't",
    "start": "1456159",
    "end": "1458000"
  },
  {
    "text": "used it Would be nice to learn something",
    "start": "1458000",
    "end": "1460400"
  },
  {
    "text": "and yeah I can answer the question Um so",
    "start": "1460400",
    "end": "1463039"
  },
  {
    "text": "I'll repeat the question So basically",
    "start": "1463039",
    "end": "1464480"
  },
  {
    "text": "the question is about the data set",
    "start": "1464480",
    "end": "1466840"
  },
  {
    "text": "initializer as I understand Yes So yeah",
    "start": "1466840",
    "end": "1469760"
  },
  {
    "text": "so with the with the new runtime APIs",
    "start": "1469760",
    "end": "1472320"
  },
  {
    "text": "trainer v2 cubeflow trainer v2 it has",
    "start": "1472320",
    "end": "1475320"
  },
  {
    "text": "initializers which which can be",
    "start": "1475320",
    "end": "1477120"
  },
  {
    "text": "configured as a separate job So um you",
    "start": "1477120",
    "end": "1480320"
  },
  {
    "text": "can configure your runtimes with a data",
    "start": "1480320",
    "end": "1482240"
  },
  {
    "text": "set initializer which can which can be a",
    "start": "1482240",
    "end": "1484799"
  },
  {
    "text": "separate cubeflow job You can you can",
    "start": "1484799",
    "end": "1486559"
  },
  {
    "text": "have your com um template spec um with",
    "start": "1486559",
    "end": "1489840"
  },
  {
    "text": "uh which is uh which is like a job spec",
    "start": "1489840",
    "end": "1492240"
  },
  {
    "text": "So you can use that spec and you can you",
    "start": "1492240",
    "end": "1494080"
  },
  {
    "text": "can have your own uh initializers like",
    "start": "1494080",
    "end": "1496240"
  },
  {
    "text": "uh docker image and also config But you",
    "start": "1496240",
    "end": "1499360"
  },
  {
    "text": "you coded this from from scratch Let's",
    "start": "1499360",
    "end": "1501520"
  },
  {
    "text": "say you created the job you created this",
    "start": "1501520",
    "end": "1503760"
  },
  {
    "text": "job and then you just added you can add",
    "start": "1503760",
    "end": "1505760"
  },
  {
    "text": "whatever you want Yeah you need to just",
    "start": "1505760",
    "end": "1507039"
  },
  {
    "text": "pass as part of the runtime Okay And the",
    "start": "1507039",
    "end": "1509600"
  },
  {
    "text": "trainer trainer APS would uh will create",
    "start": "1509600",
    "end": "1512159"
  },
  {
    "text": "the uh will create the job as part of",
    "start": "1512159",
    "end": "1514159"
  },
  {
    "text": "the installation of train job And do you",
    "start": "1514159",
    "end": "1516480"
  },
  {
    "text": "one one so follow up do you have this",
    "start": "1516480",
    "end": "1518720"
  },
  {
    "text": "publicly shared like yes it is Okay I",
    "start": "1518720",
    "end": "1522640"
  },
  {
    "text": "think trainer v2 was released I think a",
    "start": "1522640",
    "end": "1525360"
  },
  {
    "text": "while back Um yeah you can check the doc",
    "start": "1525360",
    "end": "1528400"
  },
  {
    "text": "I I mean the the data set initializer is",
    "start": "1528400",
    "end": "1530880"
  },
  {
    "text": "that something you could share with the",
    "start": "1530880",
    "end": "1532159"
  },
  {
    "text": "community or so specifically data set",
    "start": "1532159",
    "end": "1533840"
  },
  {
    "text": "initializer the arrow data initializer",
    "start": "1533840",
    "end": "1536559"
  },
  {
    "text": "is something which we worked on so we'll",
    "start": "1536559",
    "end": "1538320"
  },
  {
    "text": "be sharing it with the community yes",
    "start": "1538320",
    "end": "1540159"
  },
  {
    "text": "please thank you it's very useful thank",
    "start": "1540159",
    "end": "1542400"
  },
  {
    "text": "you so much",
    "start": "1542400",
    "end": "1544320"
  },
  {
    "text": "yeah it's a great question yeah we're",
    "start": "1544320",
    "end": "1545679"
  },
  {
    "text": "working on to make it accessible support",
    "start": "1545679",
    "end": "1547760"
  },
  {
    "text": "for inference for pipelines for training",
    "start": "1547760",
    "end": "1550240"
  },
  {
    "text": "so definitely like you know you can",
    "start": "1550240",
    "end": "1551760"
  },
  {
    "text": "leverage from this you know you can",
    "start": "1551760",
    "end": "1552880"
  },
  {
    "text": "benefit from cach for many many stages",
    "start": "1552880",
    "end": "1554320"
  },
  {
    "text": "of life cycle all right um thanks",
    "start": "1554320",
    "end": "1557840"
  },
  {
    "text": "speakers Great talk Uh super excited",
    "start": "1557840",
    "end": "1559760"
  },
  {
    "text": "about it",
    "start": "1559760",
    "end": "1562919"
  }
]
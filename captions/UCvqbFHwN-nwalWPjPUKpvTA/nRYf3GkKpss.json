[
  {
    "start": "0",
    "end": "36000"
  },
  {
    "text": "all right hi everyone I'm Flavio and",
    "start": "240",
    "end": "2560"
  },
  {
    "text": "together with my friend JP we're very",
    "start": "2560",
    "end": "3919"
  },
  {
    "text": "excited to talk about some of the",
    "start": "3919",
    "end": "5600"
  },
  {
    "text": "infrastructure elements they go into",
    "start": "5600",
    "end": "6879"
  },
  {
    "text": "fine-tuning uh large language models",
    "start": "6879",
    "end": "8719"
  },
  {
    "text": "such as metas Lama 2 on kubernetes with",
    "start": "8719",
    "end": "11320"
  },
  {
    "text": "Argo workflows and Hera we'll do some",
    "start": "11320",
    "end": "14360"
  },
  {
    "text": "quick intros again my name is Flavio I'm",
    "start": "14360",
    "end": "16080"
  },
  {
    "text": "a Staff engineer at Dino Therapeutics a",
    "start": "16080",
    "end": "17880"
  },
  {
    "text": "biotech company in Watertown",
    "start": "17880",
    "end": "19160"
  },
  {
    "text": "Massachusetts where we focus on uh",
    "start": "19160",
    "end": "21760"
  },
  {
    "text": "designing delivery mechanisms for Gene",
    "start": "21760",
    "end": "23800"
  },
  {
    "text": "therapies and my name is JP zilich I am",
    "start": "23800",
    "end": "26400"
  },
  {
    "text": "the CTO and co-founder of pip kit where",
    "start": "26400",
    "end": "28720"
  },
  {
    "text": "we do uh expertise services with uh Argo",
    "start": "28720",
    "end": "32320"
  },
  {
    "text": "and additionally provide a control plane",
    "start": "32320",
    "end": "34239"
  },
  {
    "text": "on top of Argo",
    "start": "34239",
    "end": "36040"
  },
  {
    "start": "36000",
    "end": "63000"
  },
  {
    "text": "workflows all right so doing a quick",
    "start": "36040",
    "end": "38280"
  },
  {
    "text": "outline first we're going to talk about",
    "start": "38280",
    "end": "39640"
  },
  {
    "text": "the motivation uh for this talk uh who",
    "start": "39640",
    "end": "42160"
  },
  {
    "text": "it's for and what you should expect to",
    "start": "42160",
    "end": "43879"
  },
  {
    "text": "get out of it then uh flab will do a bit",
    "start": "43879",
    "end": "46280"
  },
  {
    "text": "of a walkthrough of uh what Foundation",
    "start": "46280",
    "end": "48360"
  },
  {
    "text": "models are the process of fine-tuning",
    "start": "48360",
    "end": "50760"
  },
  {
    "text": "and why you would be interested in fine",
    "start": "50760",
    "end": "52359"
  },
  {
    "text": "tuning I'll be handling the",
    "start": "52359",
    "end": "53840"
  },
  {
    "text": "infrastructure piece and then lastly",
    "start": "53840",
    "end": "55879"
  },
  {
    "text": "I'll hand it back to faav who's going to",
    "start": "55879",
    "end": "57440"
  },
  {
    "text": "do a full-on walkthrough of the herac",
    "start": "57440",
    "end": "59440"
  },
  {
    "text": "code needed to actually uh do the",
    "start": "59440",
    "end": "62800"
  },
  {
    "text": "fine-tuning cool so doing the motivation",
    "start": "62800",
    "end": "65760"
  },
  {
    "start": "63000",
    "end": "106000"
  },
  {
    "text": "uh so we wanted to show in this talk how",
    "start": "65760",
    "end": "68000"
  },
  {
    "text": "to do scalable distributed uh fine",
    "start": "68000",
    "end": "70200"
  },
  {
    "text": "tuning for llms so um the target",
    "start": "70200",
    "end": "73759"
  },
  {
    "text": "audience is really going to be these uh",
    "start": "73759",
    "end": "75439"
  },
  {
    "text": "like individuals teams companies who",
    "start": "75439",
    "end": "77240"
  },
  {
    "text": "want to use llms but need to do some",
    "start": "77240",
    "end": "79680"
  },
  {
    "text": "additional customization like let's say",
    "start": "79680",
    "end": "82560"
  },
  {
    "text": "uh for example you wanted to um",
    "start": "82560",
    "end": "85040"
  },
  {
    "text": "customize an llm to represent like a",
    "start": "85040",
    "end": "87600"
  },
  {
    "text": "certain tone of voice maybe Alan AR from",
    "start": "87600",
    "end": "90360"
  },
  {
    "text": "the uh 2012 movie named uh Argo perhaps",
    "start": "90360",
    "end": "95320"
  },
  {
    "text": "or Christopher Walkin right that would",
    "start": "95320",
    "end": "97720"
  },
  {
    "text": "be a like a good use case also if you're",
    "start": "97720",
    "end": "100399"
  },
  {
    "text": "just interested in distributed model",
    "start": "100399",
    "end": "102079"
  },
  {
    "text": "training generally you're going to get a",
    "start": "102079",
    "end": "103960"
  },
  {
    "text": "lot out of this",
    "start": "103960",
    "end": "106520"
  },
  {
    "start": "106000",
    "end": "169000"
  },
  {
    "text": "talk all right we'll get started with",
    "start": "106520",
    "end": "108439"
  },
  {
    "text": "Foundation models um which is a",
    "start": "108439",
    "end": "110439"
  },
  {
    "text": "relatively recent term that was",
    "start": "110439",
    "end": "111719"
  },
  {
    "text": "introduced to describe these generally",
    "start": "111719",
    "end": "113880"
  },
  {
    "text": "available open source models that have",
    "start": "113880",
    "end": "115360"
  },
  {
    "text": "been trained on vast amounts of data for",
    "start": "115360",
    "end": "117840"
  },
  {
    "text": "tasks such as image generation or or Tex",
    "start": "117840",
    "end": "120280"
  },
  {
    "text": "generation these are generally very",
    "start": "120280",
    "end": "123399"
  },
  {
    "text": "prohibitively expensive uh to train they",
    "start": "123399",
    "end": "125439"
  },
  {
    "text": "require a lot of In-House scientific and",
    "start": "125439",
    "end": "126960"
  },
  {
    "text": "Engineering expertise um and they take a",
    "start": "126960",
    "end": "130679"
  },
  {
    "text": "lot of data and and a lot of time which",
    "start": "130679",
    "end": "133959"
  },
  {
    "text": "essentially provides the motivation to",
    "start": "133959",
    "end": "135640"
  },
  {
    "text": "take these models essentially off the",
    "start": "135640",
    "end": "137120"
  },
  {
    "text": "shelf and fine-tune them on your own",
    "start": "137120",
    "end": "138840"
  },
  {
    "text": "data which is a process that I'll",
    "start": "138840",
    "end": "140640"
  },
  {
    "text": "explain in a minute but it essentially",
    "start": "140640",
    "end": "142840"
  },
  {
    "text": "boils down to taking these models",
    "start": "142840",
    "end": "144239"
  },
  {
    "text": "feeding your Fe feeding them your own",
    "start": "144239",
    "end": "146239"
  },
  {
    "text": "data so that they you improve them at a",
    "start": "146239",
    "end": "148560"
  },
  {
    "text": "particular task that your business might",
    "start": "148560",
    "end": "150720"
  },
  {
    "text": "be interested in for the applications",
    "start": "150720",
    "end": "152200"
  },
  {
    "text": "that you build for your",
    "start": "152200",
    "end": "153440"
  },
  {
    "text": "customers and this can be applied to a",
    "start": "153440",
    "end": "155440"
  },
  {
    "text": "variety of domains such as you know if",
    "start": "155440",
    "end": "157440"
  },
  {
    "text": "you have medical notes or support",
    "start": "157440",
    "end": "159720"
  },
  {
    "text": "tickets or access logs or something like",
    "start": "159720",
    "end": "161519"
  },
  {
    "text": "that that you want these models to per",
    "start": "161519",
    "end": "164080"
  },
  {
    "text": "essentially perform Q&A on um they're",
    "start": "164080",
    "end": "166480"
  },
  {
    "text": "they're very good for um for",
    "start": "166480",
    "end": "169680"
  },
  {
    "start": "169000",
    "end": "223000"
  },
  {
    "text": "that fine-tuning generally speaking um",
    "start": "169680",
    "end": "172879"
  },
  {
    "text": "it is a transfer learning technique",
    "start": "172879",
    "end": "174920"
  },
  {
    "text": "you're taking essentially the knowledge",
    "start": "174920",
    "end": "176720"
  },
  {
    "text": "that's embedded in a model that has",
    "start": "176720",
    "end": "178040"
  },
  {
    "text": "already been trained on a particular",
    "start": "178040",
    "end": "180280"
  },
  {
    "text": "task and you're transferring that to",
    "start": "180280",
    "end": "182120"
  },
  {
    "text": "your specific domain and by fine-tuning",
    "start": "182120",
    "end": "185200"
  },
  {
    "text": "by F fine-tuning the model by giving it",
    "start": "185200",
    "end": "187360"
  },
  {
    "text": "more of your own data you're essentially",
    "start": "187360",
    "end": "189440"
  },
  {
    "text": "making it better at a task that you're",
    "start": "189440",
    "end": "191280"
  },
  {
    "text": "interested in of course for example if",
    "start": "191280",
    "end": "194319"
  },
  {
    "text": "you take Matas llama 2 L 2 hasn't been",
    "start": "194319",
    "end": "196319"
  },
  {
    "text": "trained on your proprietary data but you",
    "start": "196319",
    "end": "198840"
  },
  {
    "text": "can actually take this open source model",
    "start": "198840",
    "end": "201480"
  },
  {
    "text": "and um feed it some of your own examples",
    "start": "201480",
    "end": "204280"
  },
  {
    "text": "in order to do better at your particular",
    "start": "204280",
    "end": "207000"
  },
  {
    "text": "application there's multiple stages that",
    "start": "207000",
    "end": "209159"
  },
  {
    "text": "goes that go into fine tuning such as",
    "start": "209159",
    "end": "210720"
  },
  {
    "text": "setting up your infrastructure you know",
    "start": "210720",
    "end": "212640"
  },
  {
    "text": "getting access to these specific models",
    "start": "212640",
    "end": "214599"
  },
  {
    "text": "and then feeding them uh your your own",
    "start": "214599",
    "end": "216680"
  },
  {
    "text": "data and in this stock we're going to",
    "start": "216680",
    "end": "218080"
  },
  {
    "text": "focus on as JP mentioned on the",
    "start": "218080",
    "end": "219680"
  },
  {
    "text": "infrastructure of that which JP will",
    "start": "219680",
    "end": "222000"
  },
  {
    "text": "start describing now thank you Flav all",
    "start": "222000",
    "end": "224599"
  },
  {
    "start": "223000",
    "end": "284000"
  },
  {
    "text": "right so given this is argoon and cpcom",
    "start": "224599",
    "end": "227680"
  },
  {
    "text": "we will need a kubernetes cluster I",
    "start": "227680",
    "end": "230120"
  },
  {
    "text": "think that one is a given uh so we'll",
    "start": "230120",
    "end": "232480"
  },
  {
    "text": "need some gpus and which we're going to",
    "start": "232480",
    "end": "234519"
  },
  {
    "text": "be doing the actual model training on uh",
    "start": "234519",
    "end": "237799"
  },
  {
    "text": "within that kubernetes cluster we're",
    "start": "237799",
    "end": "239360"
  },
  {
    "text": "going to need need principally three",
    "start": "239360",
    "end": "240760"
  },
  {
    "text": "things uh we're going to need a custom",
    "start": "240760",
    "end": "242799"
  },
  {
    "text": "storage class we'll delve into the",
    "start": "242799",
    "end": "244760"
  },
  {
    "text": "reasons for that in just a minute uh",
    "start": "244760",
    "end": "246599"
  },
  {
    "text": "we're going to need the gpus as afer",
    "start": "246599",
    "end": "248599"
  },
  {
    "text": "mentioned and then lastly we're going to",
    "start": "248599",
    "end": "250560"
  },
  {
    "text": "need Argo workflows installed which is",
    "start": "250560",
    "end": "252840"
  },
  {
    "text": "going to be the workflow orchestration",
    "start": "252840",
    "end": "254760"
  },
  {
    "text": "system of choice that will allow us to",
    "start": "254760",
    "end": "256759"
  },
  {
    "text": "string all of these pieces together uh",
    "start": "256759",
    "end": "259359"
  },
  {
    "text": "outside of the kubernetes cluster we're",
    "start": "259359",
    "end": "261359"
  },
  {
    "text": "going to need a hugging face account uh",
    "start": "261359",
    "end": "263960"
  },
  {
    "text": "saw the hugging face individuals earlier",
    "start": "263960",
    "end": "266280"
  },
  {
    "text": "this morning they have very distinctive",
    "start": "266280",
    "end": "268000"
  },
  {
    "text": "uh shirts love the logo",
    "start": "268000",
    "end": "270199"
  },
  {
    "text": "and uh lastly we need approval from meta",
    "start": "270199",
    "end": "272360"
  },
  {
    "text": "that you can use llama I think that's a",
    "start": "272360",
    "end": "274600"
  },
  {
    "text": "a pretty simple process but it is a",
    "start": "274600",
    "end": "276440"
  },
  {
    "text": "checkbox that you need if you're using",
    "start": "276440",
    "end": "278520"
  },
  {
    "text": "another uh llm uh you might uh not",
    "start": "278520",
    "end": "282440"
  },
  {
    "text": "necessarily need that cool so we will",
    "start": "282440",
    "end": "286000"
  },
  {
    "start": "284000",
    "end": "370000"
  },
  {
    "text": "jump into a quick architecture diagram",
    "start": "286000",
    "end": "288199"
  },
  {
    "text": "of how this is going to look uh so the",
    "start": "288199",
    "end": "291759"
  },
  {
    "text": "data scientist or the data engineer in",
    "start": "291759",
    "end": "293759"
  },
  {
    "text": "this case the U with the uh exclamation",
    "start": "293759",
    "end": "296840"
  },
  {
    "text": "point on this one is going to be",
    "start": "296840",
    "end": "298600"
  },
  {
    "text": "submitting the workflow that Flavio is",
    "start": "298600",
    "end": "301199"
  },
  {
    "text": "going to demonstrate to the Argo",
    "start": "301199",
    "end": "302800"
  },
  {
    "text": "workflow server the Argo workflow server",
    "start": "302800",
    "end": "305520"
  },
  {
    "text": "is then a wrapper for the Argo workflows",
    "start": "305520",
    "end": "308240"
  },
  {
    "text": "controller which manages uh the workflow",
    "start": "308240",
    "end": "310720"
  },
  {
    "text": "State across the kubernetes cluster that",
    "start": "310720",
    "end": "313039"
  },
  {
    "text": "is going to be creating the workflow and",
    "start": "313039",
    "end": "315160"
  },
  {
    "text": "this workflow is going to consist of",
    "start": "315160",
    "end": "317160"
  },
  {
    "text": "three parts the first is creating a",
    "start": "317160",
    "end": "320319"
  },
  {
    "text": "distributed key Value Store uh that is",
    "start": "320319",
    "end": "323039"
  },
  {
    "text": "going to be handling the metadata for",
    "start": "323039",
    "end": "325680"
  },
  {
    "text": "the uh model training uh in this",
    "start": "325680",
    "end": "328039"
  },
  {
    "text": "instance we have chosen to use CD to",
    "start": "328039",
    "end": "330600"
  },
  {
    "text": "clarify we are not using the ETD that is",
    "start": "330600",
    "end": "333759"
  },
  {
    "text": "uh coming built in with kubernetes but",
    "start": "333759",
    "end": "336120"
  },
  {
    "text": "rather standing up a separate etcd",
    "start": "336120",
    "end": "338240"
  },
  {
    "text": "instance right etcd is really just a",
    "start": "338240",
    "end": "341080"
  },
  {
    "text": "distributed key value store so why not",
    "start": "341080",
    "end": "344039"
  },
  {
    "text": "use it to do other things than just",
    "start": "344039",
    "end": "345680"
  },
  {
    "text": "storing kubernetes State second we are",
    "start": "345680",
    "end": "348440"
  },
  {
    "text": "going to be creating four nodes each",
    "start": "348440",
    "end": "350720"
  },
  {
    "text": "with four gpus to specify we were",
    "start": "350720",
    "end": "352919"
  },
  {
    "text": "talking about server nodes not uh nodes",
    "start": "352919",
    "end": "355160"
  },
  {
    "text": "within an Argo workflow so these are",
    "start": "355160",
    "end": "357199"
  },
  {
    "text": "four GPU instances uh this could be more",
    "start": "357199",
    "end": "360520"
  },
  {
    "text": "but we're doing four for this example",
    "start": "360520",
    "end": "362840"
  },
  {
    "text": "and then lastly at the end we're going",
    "start": "362840",
    "end": "364800"
  },
  {
    "text": "to be deleting all of the resources and",
    "start": "364800",
    "end": "367479"
  },
  {
    "text": "treating each of these workflows as",
    "start": "367479",
    "end": "370639"
  },
  {
    "start": "370000",
    "end": "423000"
  },
  {
    "text": "ephemeral so next touching a little bit",
    "start": "370639",
    "end": "373199"
  },
  {
    "text": "more around the distributed key value",
    "start": "373199",
    "end": "375560"
  },
  {
    "text": "store so the problem is that we want to",
    "start": "375560",
    "end": "377880"
  },
  {
    "text": "track which shards of the model have",
    "start": "377880",
    "end": "379400"
  },
  {
    "text": "been trained on which sections of the",
    "start": "379400",
    "end": "381080"
  },
  {
    "text": "data set uh and make sure that uh each",
    "start": "381080",
    "end": "384520"
  },
  {
    "text": "section of the um gpus can share",
    "start": "384520",
    "end": "388000"
  },
  {
    "text": "metadata um with with one another so",
    "start": "388000",
    "end": "391199"
  },
  {
    "text": "again we want to be using a distributed",
    "start": "391199",
    "end": "393880"
  },
  {
    "text": "key value uh store and it could be any",
    "start": "393880",
    "end": "396759"
  },
  {
    "text": "key value store we chose to use etcd in",
    "start": "396759",
    "end": "399240"
  },
  {
    "text": "this instance because we are familiar",
    "start": "399240",
    "end": "400759"
  },
  {
    "text": "with it there's existing P torch",
    "start": "400759",
    "end": "402919"
  },
  {
    "text": "documentation on how to use etcd and we",
    "start": "402919",
    "end": "405560"
  },
  {
    "text": "found that spinning it up on kubernetes",
    "start": "405560",
    "end": "408080"
  },
  {
    "text": "was relatively easy um so again",
    "start": "408080",
    "end": "411039"
  },
  {
    "text": "highlighting that this is separate from",
    "start": "411039",
    "end": "412759"
  },
  {
    "text": "the existing ETD instance that",
    "start": "412759",
    "end": "415080"
  },
  {
    "text": "kubernetes uh uses so we will refer to",
    "start": "415080",
    "end": "417800"
  },
  {
    "text": "this as the training at CD instance just",
    "start": "417800",
    "end": "421160"
  },
  {
    "text": "for clarity",
    "start": "421160",
    "end": "422440"
  },
  {
    "text": "sake all right so next I'll be handing",
    "start": "422440",
    "end": "424800"
  },
  {
    "start": "423000",
    "end": "488000"
  },
  {
    "text": "it to flab to talk about the workflow",
    "start": "424800",
    "end": "427120"
  },
  {
    "text": "steps all right so now that we have that",
    "start": "427120",
    "end": "429199"
  },
  {
    "text": "etcd deployment actually available in",
    "start": "429199",
    "end": "431039"
  },
  {
    "text": "the cluster which we're going to cover",
    "start": "431039",
    "end": "432360"
  },
  {
    "text": "how to do in in a few minutes I wanted",
    "start": "432360",
    "end": "434639"
  },
  {
    "text": "to illustrate what happens with these uh",
    "start": "434639",
    "end": "436560"
  },
  {
    "text": "containers once they spin up so each",
    "start": "436560",
    "end": "438199"
  },
  {
    "text": "container here mounts four gpus so we",
    "start": "438199",
    "end": "440800"
  },
  {
    "text": "have 16 gpus in total each container",
    "start": "440800",
    "end": "443360"
  },
  {
    "text": "talks to etcd the moment it actually",
    "start": "443360",
    "end": "445319"
  },
  {
    "text": "spins up to communicate via etcd it",
    "start": "445319",
    "end": "448280"
  },
  {
    "text": "about its existence and Readiness and it",
    "start": "448280",
    "end": "450960"
  },
  {
    "text": "just Waits until all of the other peer",
    "start": "450960",
    "end": "453240"
  },
  {
    "text": "containers are actually uh spun up as",
    "start": "453240",
    "end": "455520"
  },
  {
    "text": "well once that is done all of them start",
    "start": "455520",
    "end": "458160"
  },
  {
    "text": "downloading the data and the model and",
    "start": "458160",
    "end": "460759"
  },
  {
    "text": "the data will be sharded across the",
    "start": "460759",
    "end": "462199"
  },
  {
    "text": "independent gpus and in addition the",
    "start": "462199",
    "end": "464919"
  },
  {
    "text": "model will also be shed across the",
    "start": "464919",
    "end": "466400"
  },
  {
    "text": "different gpus because a model such as",
    "start": "466400",
    "end": "468560"
  },
  {
    "text": "llama llama 2 that has 7 billion uh",
    "start": "468560",
    "end": "471280"
  },
  {
    "text": "parameters does not fit on its own on a",
    "start": "471280",
    "end": "473440"
  },
  {
    "text": "single GPU so there are different",
    "start": "473440",
    "end": "476440"
  },
  {
    "text": "approaches that you can use to take",
    "start": "476440",
    "end": "478000"
  },
  {
    "text": "chunks of the model and then put that at",
    "start": "478000",
    "end": "479960"
  },
  {
    "text": "a time on the GPU and then just train",
    "start": "479960",
    "end": "482159"
  },
  {
    "text": "and essentially pass data just through",
    "start": "482159",
    "end": "483680"
  },
  {
    "text": "that specific um that specific",
    "start": "483680",
    "end": "488639"
  },
  {
    "start": "488000",
    "end": "611000"
  },
  {
    "text": "Shard I wanted to show an example um",
    "start": "489319",
    "end": "492440"
  },
  {
    "text": "about how this actually works in in in",
    "start": "492440",
    "end": "494319"
  },
  {
    "text": "pyto but they have an amazing diagram",
    "start": "494319",
    "end": "495919"
  },
  {
    "text": "that illustrates just this so we're",
    "start": "495919",
    "end": "497080"
  },
  {
    "text": "going to walk through that uh right now",
    "start": "497080",
    "end": "498919"
  },
  {
    "text": "this is taken directly from the Pythor",
    "start": "498919",
    "end": "500759"
  },
  {
    "text": "documentation so this process is called",
    "start": "500759",
    "end": "502319"
  },
  {
    "text": "fully sharded data parallel and here we",
    "start": "502319",
    "end": "504639"
  },
  {
    "text": "have an example where we have two",
    "start": "504639",
    "end": "507280"
  },
  {
    "text": "parallel processes processing data",
    "start": "507280",
    "end": "510159"
  },
  {
    "text": "uh and different chunks of the of of the",
    "start": "510159",
    "end": "512839"
  },
  {
    "text": "model that we're training so at the top",
    "start": "512839",
    "end": "515320"
  },
  {
    "text": "we really just have a single GPU and at",
    "start": "515320",
    "end": "517560"
  },
  {
    "text": "the bottom we have another GPU that",
    "start": "517560",
    "end": "520320"
  },
  {
    "text": "those pull from the same data set they",
    "start": "520320",
    "end": "522560"
  },
  {
    "text": "pull one simple uh one example at a time",
    "start": "522560",
    "end": "526360"
  },
  {
    "text": "one of the the the chunk is",
    "start": "526360",
    "end": "528880"
  },
  {
    "text": "loaded um or the model shart is loaded",
    "start": "528880",
    "end": "531880"
  },
  {
    "text": "onto the GPU there's some",
    "start": "531880",
    "end": "534080"
  },
  {
    "text": "synchronization that happens across the",
    "start": "534080",
    "end": "535920"
  },
  {
    "text": "gpus which is where uh etcd is useful",
    "start": "535920",
    "end": "538880"
  },
  {
    "text": "because it it stores things metadata for",
    "start": "538880",
    "end": "541640"
  },
  {
    "text": "communication and synchronization across",
    "start": "541640",
    "end": "543240"
  },
  {
    "text": "the different",
    "start": "543240",
    "end": "544440"
  },
  {
    "text": "ranks data is actually passed through",
    "start": "544440",
    "end": "546680"
  },
  {
    "text": "that specific chunk um and the details",
    "start": "546680",
    "end": "550279"
  },
  {
    "text": "of what happens you know with the",
    "start": "550279",
    "end": "551600"
  },
  {
    "text": "forward and backward and gradient",
    "start": "551600",
    "end": "553040"
  },
  {
    "text": "computation don't generally matter for",
    "start": "553040",
    "end": "555839"
  },
  {
    "text": "this uh in in this specific diagram the",
    "start": "555839",
    "end": "558240"
  },
  {
    "text": "take-home message is that at different",
    "start": "558240",
    "end": "560279"
  },
  {
    "text": "stages in training there are different",
    "start": "560279",
    "end": "562760"
  },
  {
    "text": "uh synchronization steps such as this",
    "start": "562760",
    "end": "565399"
  },
  {
    "text": "Gathering of Weights which is ensures",
    "start": "565399",
    "end": "567160"
  },
  {
    "text": "that the parameters are consistent",
    "start": "567160",
    "end": "568519"
  },
  {
    "text": "across the G gpus um because the they",
    "start": "568519",
    "end": "572560"
  },
  {
    "text": "they can process different data sets",
    "start": "572560",
    "end": "574200"
  },
  {
    "text": "they'll get different weights which have",
    "start": "574200",
    "end": "575519"
  },
  {
    "text": "to be uh again gathered and uh",
    "start": "575519",
    "end": "578399"
  },
  {
    "text": "synchronized across the ranks and then",
    "start": "578399",
    "end": "580519"
  },
  {
    "text": "once we actually modify the network in",
    "start": "580519",
    "end": "582760"
  },
  {
    "text": "the learning process we have to sync uh",
    "start": "582760",
    "end": "584720"
  },
  {
    "text": "the so-called gradients um as well and",
    "start": "584720",
    "end": "587640"
  },
  {
    "text": "once that specific chunk is done it gets",
    "start": "587640",
    "end": "589560"
  },
  {
    "text": "offloaded uh optionally to to to CPU",
    "start": "589560",
    "end": "592640"
  },
  {
    "text": "memory and then the next trunk can be uh",
    "start": "592640",
    "end": "595160"
  },
  {
    "text": "can be",
    "start": "595160",
    "end": "597440"
  },
  {
    "text": "processed now of course we have have to",
    "start": "597440",
    "end": "599440"
  },
  {
    "text": "take all we we easily we can easily spin",
    "start": "599440",
    "end": "602240"
  },
  {
    "text": "up all of the resources and",
    "start": "602240",
    "end": "603320"
  },
  {
    "text": "infrastructure necessary for actually",
    "start": "603320",
    "end": "604720"
  },
  {
    "text": "running this on kubernetes but we also",
    "start": "604720",
    "end": "606519"
  },
  {
    "text": "have to take it down because it's very",
    "start": "606519",
    "end": "607800"
  },
  {
    "text": "expensive and I'll pass it to JP to show",
    "start": "607800",
    "end": "610399"
  },
  {
    "text": "us how we do that aren't you glad we",
    "start": "610399",
    "end": "612800"
  },
  {
    "start": "611000",
    "end": "705000"
  },
  {
    "text": "scheduled a very uh light and fluffy",
    "start": "612800",
    "end": "614800"
  },
  {
    "text": "talk to be the first talk right after",
    "start": "614800",
    "end": "617279"
  },
  {
    "text": "lunch all right so I'm going to go over",
    "start": "617279",
    "end": "619600"
  },
  {
    "text": "the tear down of uh the workflow that",
    "start": "619600",
    "end": "622040"
  },
  {
    "text": "you just saw earlier so um tear Downs",
    "start": "622040",
    "end": "625320"
  },
  {
    "text": "are uh where we're going to treat each",
    "start": "625320",
    "end": "627680"
  },
  {
    "text": "of these workflow instances as being",
    "start": "627680",
    "end": "629519"
  },
  {
    "text": "ephemeral so walking through the steps",
    "start": "629519",
    "end": "631680"
  },
  {
    "text": "in the tear down first the training ETD",
    "start": "631680",
    "end": "634079"
  },
  {
    "text": "instance is going to be torn down at the",
    "start": "634079",
    "end": "635680"
  },
  {
    "text": "end of the workflow using an exit",
    "start": "635680",
    "end": "637360"
  },
  {
    "text": "Handler in Hera or Argo workflows um for",
    "start": "637360",
    "end": "640959"
  },
  {
    "text": "those not the most familiar with Hera",
    "start": "640959",
    "end": "642839"
  },
  {
    "text": "Argo workflows this is a concept where",
    "start": "642839",
    "end": "645360"
  },
  {
    "text": "at the end of a single workflow run it's",
    "start": "645360",
    "end": "647680"
  },
  {
    "text": "just a cleanup step uh it can be a tear",
    "start": "647680",
    "end": "650000"
  },
  {
    "text": "down you can tell it to do other things",
    "start": "650000",
    "end": "651800"
  },
  {
    "text": "like post a slack etc etc etc um but",
    "start": "651800",
    "end": "654880"
  },
  {
    "text": "whether a workflow succeeds or fails it",
    "start": "654880",
    "end": "657360"
  },
  {
    "text": "is going to execute second the cluster",
    "start": "657360",
    "end": "659959"
  },
  {
    "text": "Auto scaler is going to be tearing down",
    "start": "659959",
    "end": "661639"
  },
  {
    "text": "the gpus uh since they are no longer",
    "start": "661639",
    "end": "664240"
  },
  {
    "text": "needed right like this is uh pretty",
    "start": "664240",
    "end": "667000"
  },
  {
    "text": "normal uh kubernetes concept we have",
    "start": "667000",
    "end": "669279"
  },
  {
    "text": "several nodes they are now no longer",
    "start": "669279",
    "end": "671079"
  },
  {
    "text": "going to have pods scheduled on them we",
    "start": "671079",
    "end": "673000"
  },
  {
    "text": "don't need them anymore don't want to",
    "start": "673000",
    "end": "674680"
  },
  {
    "text": "get build for them next uh we are",
    "start": "674680",
    "end": "679480"
  },
  {
    "text": "guaranteed that the tear down is going",
    "start": "679480",
    "end": "681079"
  },
  {
    "text": "to happen regardless of the success or",
    "start": "681079",
    "end": "683040"
  },
  {
    "text": "failure of the workflow run itself again",
    "start": "683040",
    "end": "684959"
  },
  {
    "text": "since we're using that exit Handler",
    "start": "684959",
    "end": "687120"
  },
  {
    "text": "concept right whether it's EDS fails",
    "start": "687120",
    "end": "690040"
  },
  {
    "text": "doesn't matter and then as a general",
    "start": "690040",
    "end": "691959"
  },
  {
    "text": "rule we want to treat all of these",
    "start": "691959",
    "end": "693440"
  },
  {
    "text": "workflow runs as being uh as ephemeral",
    "start": "693440",
    "end": "696560"
  },
  {
    "text": "as possible there are some situations in",
    "start": "696560",
    "end": "698880"
  },
  {
    "text": "which you might not want to do that",
    "start": "698880",
    "end": "700360"
  },
  {
    "text": "which we'll cover a little bit later but",
    "start": "700360",
    "end": "702079"
  },
  {
    "text": "for now we'll keep them uh",
    "start": "702079",
    "end": "704680"
  },
  {
    "text": "ephemeral all right so next we'll hand",
    "start": "704680",
    "end": "707040"
  },
  {
    "start": "705000",
    "end": "966000"
  },
  {
    "text": "it back to flab who's going to actually",
    "start": "707040",
    "end": "708800"
  },
  {
    "text": "walk you through the herac code on how",
    "start": "708800",
    "end": "710440"
  },
  {
    "text": "to accomplish",
    "start": "710440",
    "end": "713160"
  },
  {
    "text": "this all right so now we're going to",
    "start": "713720",
    "end": "715680"
  },
  {
    "text": "step to the deepest level and actually",
    "start": "715680",
    "end": "717200"
  },
  {
    "text": "go through the code that is used to",
    "start": "717200",
    "end": "718440"
  },
  {
    "text": "schedule only of these resources spin",
    "start": "718440",
    "end": "720079"
  },
  {
    "text": "them up on kubernetes Via hero and Argo",
    "start": "720079",
    "end": "722200"
  },
  {
    "text": "workflows and talk about some of the",
    "start": "722200",
    "end": "723920"
  },
  {
    "text": "requirements so uh of course you can",
    "start": "723920",
    "end": "726839"
  },
  {
    "text": "access this there's a public repository",
    "start": "726839",
    "end": "728320"
  },
  {
    "text": "of all the code um and for those of you",
    "start": "728320",
    "end": "731079"
  },
  {
    "text": "who are stock stock in yaml land welcome",
    "start": "731079",
    "end": "733399"
  },
  {
    "text": "to python it's much nicer here um so",
    "start": "733399",
    "end": "736920"
  },
  {
    "text": "very briefly Hera is a is a is a python",
    "start": "736920",
    "end": "739839"
  },
  {
    "text": "SDK for Argo workflows that allows you",
    "start": "739839",
    "end": "741800"
  },
  {
    "text": "to um uh set up basically your own mini",
    "start": "741800",
    "end": "745720"
  },
  {
    "text": "platform through Hera by importing you",
    "start": "745720",
    "end": "748040"
  },
  {
    "text": "know things like global fix Hooks and",
    "start": "748040",
    "end": "749720"
  },
  {
    "text": "things like that to to set up everything",
    "start": "749720",
    "end": "751959"
  },
  {
    "text": "that your internal users might need um",
    "start": "751959",
    "end": "754199"
  },
  {
    "text": "so such as authentication the host the",
    "start": "754199",
    "end": "756639"
  },
  {
    "text": "tokens and things like that so they",
    "start": "756639",
    "end": "758120"
  },
  {
    "text": "don't have to worry about it so I wrote",
    "start": "758120",
    "end": "760959"
  },
  {
    "text": "Such a wrapper just for the purposes of",
    "start": "760959",
    "end": "762800"
  },
  {
    "text": "the talk and we're going to go through",
    "start": "762800",
    "end": "764000"
  },
  {
    "text": "now so there are requirements such as",
    "start": "764000",
    "end": "765720"
  },
  {
    "text": "setting your host like host of your Aro",
    "start": "765720",
    "end": "768399"
  },
  {
    "text": "server your token in case that is",
    "start": "768399",
    "end": "770440"
  },
  {
    "text": "actually necessary of course you can",
    "start": "770440",
    "end": "771680"
  },
  {
    "text": "connect through Local Host as well um",
    "start": "771680",
    "end": "774000"
  },
  {
    "text": "you need a kubernetes name space where",
    "start": "774000",
    "end": "776079"
  },
  {
    "text": "all of these resources will actually be",
    "start": "776079",
    "end": "777560"
  },
  {
    "text": "provisioned and in this case case I",
    "start": "777560",
    "end": "779120"
  },
  {
    "text": "created a single Docker file that I I'm",
    "start": "779120",
    "end": "780959"
  },
  {
    "text": "using for all of my uh all of my",
    "start": "780959",
    "end": "782839"
  },
  {
    "text": "resources that is set globally",
    "start": "782839",
    "end": "785000"
  },
  {
    "text": "here then I have some hooks that will",
    "start": "785000",
    "end": "787519"
  },
  {
    "text": "intercept any uh containers that are",
    "start": "787519",
    "end": "789839"
  },
  {
    "text": "created and container here is",
    "start": "789839",
    "end": "791639"
  },
  {
    "text": "essentially the same it it is one to one",
    "start": "791639",
    "end": "794800"
  },
  {
    "text": "mapped with Concept in Argo workflow so",
    "start": "794800",
    "end": "796600"
  },
  {
    "text": "container is a dock container that is",
    "start": "796600",
    "end": "798399"
  },
  {
    "text": "created by Argo",
    "start": "798399",
    "end": "800199"
  },
  {
    "text": "workflows um I'm always setting an image",
    "start": "800199",
    "end": "802399"
  },
  {
    "text": "policy of always uh and I'm also adding",
    "start": "802399",
    "end": "805079"
  },
  {
    "text": "the necessary tolerations because if",
    "start": "805079",
    "end": "806680"
  },
  {
    "text": "you're using specialized uh",
    "start": "806680",
    "end": "808279"
  },
  {
    "text": "infrastructure such as gpus uh cunes",
    "start": "808279",
    "end": "811199"
  },
  {
    "text": "will often have uh taints and it will",
    "start": "811199",
    "end": "813760"
  },
  {
    "text": "require tolerations to be set on your",
    "start": "813760",
    "end": "815440"
  },
  {
    "text": "pods in order for those pods to be",
    "start": "815440",
    "end": "816800"
  },
  {
    "text": "schedulable on those specific nodes um",
    "start": "816800",
    "end": "820000"
  },
  {
    "text": "the Dem the the talk was actually run on",
    "start": "820000",
    "end": "821760"
  },
  {
    "text": "gke so I'm adding a specific node",
    "start": "821760",
    "end": "823800"
  },
  {
    "text": "selector here if you have a different",
    "start": "823800",
    "end": "825639"
  },
  {
    "text": "Crow provider this might change for you",
    "start": "825639",
    "end": "827600"
  },
  {
    "text": "but it is it is easily U adjustable for",
    "start": "827600",
    "end": "830320"
  },
  {
    "text": "for your own",
    "start": "830320",
    "end": "832120"
  },
  {
    "text": "infrastructure uh and I'm also adding",
    "start": "832120",
    "end": "834160"
  },
  {
    "text": "this um a very important bit it's an",
    "start": "834160",
    "end": "836440"
  },
  {
    "text": "empty directory that is mounted to/ f/",
    "start": "836440",
    "end": "839240"
  },
  {
    "text": "shm and this is the shared memory space",
    "start": "839240",
    "end": "841480"
  },
  {
    "text": "of the node which is required for uh",
    "start": "841480",
    "end": "843600"
  },
  {
    "text": "inter GPU communication on the same node",
    "start": "843600",
    "end": "846519"
  },
  {
    "text": "on the same kubernetes node and if you",
    "start": "846519",
    "end": "847959"
  },
  {
    "text": "don't set this you'll get things like",
    "start": "847959",
    "end": "849720"
  },
  {
    "text": "python boss errors which are incredibly",
    "start": "849720",
    "end": "851440"
  },
  {
    "text": "hard to",
    "start": "851440",
    "end": "852720"
  },
  {
    "text": "debug the next thing I'll talk about is",
    "start": "852720",
    "end": "855240"
  },
  {
    "text": "how we actually spin up the etcd",
    "start": "855240",
    "end": "856880"
  },
  {
    "text": "resources so one of the great thing",
    "start": "856880",
    "end": "859440"
  },
  {
    "text": "things about Argo workflows is that if",
    "start": "859440",
    "end": "860959"
  },
  {
    "text": "it doesn't have a primitive such as a",
    "start": "860959",
    "end": "862959"
  },
  {
    "text": "service um that you can just like spin",
    "start": "862959",
    "end": "865079"
  },
  {
    "text": "up dynamically you still have the uh the",
    "start": "865079",
    "end": "868120"
  },
  {
    "text": "the Liberty to use a resource to give it",
    "start": "868120",
    "end": "870000"
  },
  {
    "text": "a specific yamamo definition and it will",
    "start": "870000",
    "end": "872199"
  },
  {
    "text": "just create it for you so I'm creating",
    "start": "872199",
    "end": "873720"
  },
  {
    "text": "that here I'm creating a load balancer",
    "start": "873720",
    "end": "876519"
  },
  {
    "text": "for the etcd instance that JP",
    "start": "876519",
    "end": "879360"
  },
  {
    "text": "described then I'm defining an etcd",
    "start": "879360",
    "end": "882519"
  },
  {
    "text": "stateful set that actually creates the",
    "start": "882519",
    "end": "884720"
  },
  {
    "text": "replicas the the the replicas that are",
    "start": "884720",
    "end": "887560"
  },
  {
    "text": "uh the independent etcd uh workers and",
    "start": "887560",
    "end": "891079"
  },
  {
    "text": "these ones Mount um an SSD and this is",
    "start": "891079",
    "end": "894440"
  },
  {
    "text": "required be well it's not required it is",
    "start": "894440",
    "end": "896680"
  },
  {
    "text": "recommended by etcd because etcd writes",
    "start": "896680",
    "end": "899759"
  },
  {
    "text": "data to dis so the depending on the the",
    "start": "899759",
    "end": "902560"
  },
  {
    "text": "the performance of etcd is tightly",
    "start": "902560",
    "end": "904120"
  },
  {
    "text": "coupled with the performance of the dis",
    "start": "904120",
    "end": "906279"
  },
  {
    "text": "itself and then finally deleting uh",
    "start": "906279",
    "end": "909000"
  },
  {
    "text": "those those resources and I also have",
    "start": "909000",
    "end": "911240"
  },
  {
    "text": "this magic container that runs a very",
    "start": "911240",
    "end": "913320"
  },
  {
    "text": "ugly bash command and the reason I have",
    "start": "913320",
    "end": "915120"
  },
  {
    "text": "this is because waiting for I I we need",
    "start": "915120",
    "end": "918320"
  },
  {
    "text": "during training the IP of the load",
    "start": "918320",
    "end": "920120"
  },
  {
    "text": "balancer and getting that IP actually",
    "start": "920120",
    "end": "921959"
  },
  {
    "text": "provisioned takes a bit of time so I I",
    "start": "921959",
    "end": "924279"
  },
  {
    "text": "added a bit of a a small container that",
    "start": "924279",
    "end": "926519"
  },
  {
    "text": "will wait uh for that IP to become",
    "start": "926519",
    "end": "929800"
  },
  {
    "text": "available um all of these are",
    "start": "929800",
    "end": "932079"
  },
  {
    "text": "independent components we're covering",
    "start": "932079",
    "end": "933600"
  },
  {
    "text": "right now and we're going to get to how",
    "start": "933600",
    "end": "935519"
  },
  {
    "text": "we're actually putting all of these",
    "start": "935519",
    "end": "937040"
  },
  {
    "text": "things together into a dag on our go",
    "start": "937040",
    "end": "938600"
  },
  {
    "text": "workflows in a second I'll show you",
    "start": "938600",
    "end": "940680"
  },
  {
    "text": "really quick how the SSD is defined um",
    "start": "940680",
    "end": "943600"
  },
  {
    "text": "we're using",
    "start": "943600",
    "end": "945279"
  },
  {
    "text": "um an an SSD on GK that has a volume",
    "start": "945279",
    "end": "948519"
  },
  {
    "text": "binding mode of weight for first",
    "start": "948519",
    "end": "950040"
  },
  {
    "text": "consumer so that the dis is actually",
    "start": "950040",
    "end": "952880"
  },
  {
    "text": "attached to your is it is provision when",
    "start": "952880",
    "end": "956120"
  },
  {
    "text": "a specific part actually wants to mount",
    "start": "956120",
    "end": "958040"
  },
  {
    "text": "it cuz otherwise you can get uh pods and",
    "start": "958040",
    "end": "960560"
  },
  {
    "text": "discs in different zones and they become",
    "start": "960560",
    "end": "962920"
  },
  {
    "text": "they're not mountable in that",
    "start": "962920",
    "end": "965000"
  },
  {
    "text": "case all right so finally the the actual",
    "start": "965000",
    "end": "968040"
  },
  {
    "start": "966000",
    "end": "1094000"
  },
  {
    "text": "training workflow so be before we",
    "start": "968040",
    "end": "970560"
  },
  {
    "text": "actually Define the uh the actual",
    "start": "970560",
    "end": "972880"
  },
  {
    "text": "workflow and all of the dependencies I'm",
    "start": "972880",
    "end": "974720"
  },
  {
    "text": "going to show you what we actually",
    "start": "974720",
    "end": "976040"
  },
  {
    "text": "create for the independent containers",
    "start": "976040",
    "end": "978480"
  },
  {
    "text": "that we previously talked about that",
    "start": "978480",
    "end": "979800"
  },
  {
    "text": "have the four gpus attached to them so",
    "start": "979800",
    "end": "981880"
  },
  {
    "text": "we have a fine tuning",
    "start": "981880",
    "end": "983399"
  },
  {
    "text": "container um that has some environment",
    "start": "983399",
    "end": "986319"
  },
  {
    "text": "variables for the hugging face token",
    "start": "986319",
    "end": "988079"
  },
  {
    "text": "that JP mentioned it has an image we're",
    "start": "988079",
    "end": "990560"
  },
  {
    "text": "using torch run as the core command",
    "start": "990560",
    "end": "992920"
  },
  {
    "text": "which is part of the container this is",
    "start": "992920",
    "end": "994639"
  },
  {
    "text": "the one that will actually run the",
    "start": "994639",
    "end": "995680"
  },
  {
    "text": "script and do the message passing and",
    "start": "995680",
    "end": "998279"
  },
  {
    "text": "the synchronization between the gpus and",
    "start": "998279",
    "end": "1000399"
  },
  {
    "text": "it's part of of",
    "start": "1000399",
    "end": "1002160"
  },
  {
    "text": "pytorch it has specific Flags to",
    "start": "1002160",
    "end": "1004720"
  },
  {
    "text": "actually inform pytorch how many uh how",
    "start": "1004720",
    "end": "1006959"
  },
  {
    "text": "many gpus there are how many ranks there",
    "start": "1006959",
    "end": "1008600"
  },
  {
    "text": "are what um so how many how many",
    "start": "1008600",
    "end": "1011120"
  },
  {
    "text": "containers how many nodes um and that is",
    "start": "1011120",
    "end": "1013680"
  },
  {
    "text": "specified through end noes here so in",
    "start": "1013680",
    "end": "1015040"
  },
  {
    "text": "our case we have four of course we have",
    "start": "1015040",
    "end": "1017199"
  },
  {
    "text": "um four processes per node or four",
    "start": "1017199",
    "end": "1021120"
  },
  {
    "text": "gpus we specified that the rendevu back",
    "start": "1021120",
    "end": "1024038"
  },
  {
    "text": "end is etcd the rendevu backend is used",
    "start": "1024039",
    "end": "1027000"
  },
  {
    "text": "for synchronization um by by Pythor",
    "start": "1027000",
    "end": "1030319"
  },
  {
    "text": "between the different ranks we have the",
    "start": "1030319",
    "end": "1032760"
  },
  {
    "text": "etcd IP that is actually passed as a",
    "start": "1032760",
    "end": "1035319"
  },
  {
    "text": "parameter from uh through ouro",
    "start": "1035319",
    "end": "1037918"
  },
  {
    "text": "workflows and we have some extra",
    "start": "1037919",
    "end": "1039839"
  },
  {
    "text": "parameters here that uh represent the ID",
    "start": "1039839",
    "end": "1042280"
  },
  {
    "text": "of the training session which is like a",
    "start": "1042280",
    "end": "1043798"
  },
  {
    "text": "unique identifier in etcd for all of the",
    "start": "1043799",
    "end": "1046000"
  },
  {
    "text": "metadata of the training run and finally",
    "start": "1046000",
    "end": "1048840"
  },
  {
    "text": "we have the actual fine-tuning script uh",
    "start": "1048840",
    "end": "1052360"
  },
  {
    "text": "which we which we borrowed from uh llama",
    "start": "1052360",
    "end": "1054840"
  },
  {
    "text": "recipes uh that has the actual training",
    "start": "1054840",
    "end": "1056960"
  },
  {
    "text": "Loop that uh for for for the model and",
    "start": "1056960",
    "end": "1059840"
  },
  {
    "text": "the download of the data set uh we're",
    "start": "1059840",
    "end": "1061840"
  },
  {
    "text": "focused on the infrastructure aspect if",
    "start": "1061840",
    "end": "1063559"
  },
  {
    "text": "you're curious about uh the details",
    "start": "1063559",
    "end": "1065480"
  },
  {
    "text": "there the the details of the training",
    "start": "1065480",
    "end": "1067720"
  },
  {
    "text": "Loop uh it is a great llama recipes is a",
    "start": "1067720",
    "end": "1070559"
  },
  {
    "text": "great repository for getting some of",
    "start": "1070559",
    "end": "1072160"
  },
  {
    "text": "those",
    "start": "1072160",
    "end": "1073280"
  },
  {
    "text": "details okay so back to back to training",
    "start": "1073280",
    "end": "1077039"
  },
  {
    "text": "uh we have some yeah inputs defined",
    "start": "1077039",
    "end": "1079280"
  },
  {
    "text": "which are the input parameters to the",
    "start": "1079280",
    "end": "1080760"
  },
  {
    "text": "specific job and of course we have um",
    "start": "1080760",
    "end": "1083799"
  },
  {
    "text": "the actual resources that we have to use",
    "start": "1083799",
    "end": "1085840"
  },
  {
    "text": "so we have four gpus we need quite a bit",
    "start": "1085840",
    "end": "1087480"
  },
  {
    "text": "of memory for this so 120 GB uh and",
    "start": "1087480",
    "end": "1090559"
  },
  {
    "text": "several um",
    "start": "1090559",
    "end": "1093440"
  },
  {
    "text": "CPUs we also Mount some some volumes",
    "start": "1093440",
    "end": "1096919"
  },
  {
    "start": "1094000",
    "end": "1168000"
  },
  {
    "text": "that are dynamically provisioned this",
    "start": "1096919",
    "end": "1098760"
  },
  {
    "text": "container actually turns into a Argo",
    "start": "1098760",
    "end": "1100960"
  },
  {
    "text": "workflows template inside the workflow",
    "start": "1100960",
    "end": "1102880"
  },
  {
    "text": "itself so if you just use dynamically",
    "start": "1102880",
    "end": "1105000"
  },
  {
    "text": "provisioned volumes all of the container",
    "start": "1105000",
    "end": "1107360"
  },
  {
    "text": "copies will actually mount the same",
    "start": "1107360",
    "end": "1108720"
  },
  {
    "text": "volume um so you need to create volume",
    "start": "1108720",
    "end": "1111080"
  },
  {
    "text": "mounts that mount Dynamic volumes",
    "start": "1111080",
    "end": "1113600"
  },
  {
    "text": "dynamically which are created through",
    "start": "1113600",
    "end": "1115280"
  },
  {
    "text": "the",
    "start": "1115280",
    "end": "1117039"
  },
  {
    "text": "workflow all right so here's where we",
    "start": "1117039",
    "end": "1119600"
  },
  {
    "text": "Define the workflow through Hera we have",
    "start": "1119600",
    "end": "1122880"
  },
  {
    "text": "several volume claim templates that one",
    "start": "1122880",
    "end": "1125120"
  },
  {
    "text": "volume claim template that is defined",
    "start": "1125120",
    "end": "1126600"
  },
  {
    "text": "for every container that we create so",
    "start": "1126600",
    "end": "1128880"
  },
  {
    "text": "here's where we say uh give me a",
    "start": "1128880",
    "end": "1131480"
  },
  {
    "text": "persistent volume claim called rank I",
    "start": "1131480",
    "end": "1135039"
  },
  {
    "text": "for zero through three uh through three",
    "start": "1135039",
    "end": "1138559"
  },
  {
    "text": "um each will have 20 Gigabytes and this",
    "start": "1138559",
    "end": "1140559"
  },
  {
    "text": "is useful if you want to save the the",
    "start": "1140559",
    "end": "1142120"
  },
  {
    "text": "model to disk after you actually train",
    "start": "1142120",
    "end": "1144360"
  },
  {
    "text": "it to save it in your own buckets or",
    "start": "1144360",
    "end": "1146760"
  },
  {
    "text": "Registries or something like",
    "start": "1146760",
    "end": "1148919"
  },
  {
    "text": "that um so these will this will um tell",
    "start": "1148919",
    "end": "1153720"
  },
  {
    "text": "kubernetes that four of these uh",
    "start": "1153720",
    "end": "1155799"
  },
  {
    "text": "containers four of the volumes will",
    "start": "1155799",
    "end": "1157760"
  },
  {
    "text": "should be provisioned and this volume",
    "start": "1157760",
    "end": "1159440"
  },
  {
    "text": "Mount will actually Mount the uh in the",
    "start": "1159440",
    "end": "1162840"
  },
  {
    "text": "independent volumes to the right",
    "start": "1162840",
    "end": "1164360"
  },
  {
    "text": "container based on the the the",
    "start": "1164360",
    "end": "1167240"
  },
  {
    "text": "name",
    "start": "1167240",
    "end": "1168919"
  },
  {
    "start": "1168000",
    "end": "1276000"
  },
  {
    "text": "so finally we get to the part where we",
    "start": "1168919",
    "end": "1170559"
  },
  {
    "text": "actually Define our dependency so we",
    "start": "1170559",
    "end": "1172120"
  },
  {
    "text": "have a workflow we Define a rendevu ID",
    "start": "1172120",
    "end": "1175280"
  },
  {
    "text": "which is the training session ID that",
    "start": "1175280",
    "end": "1176679"
  },
  {
    "text": "goes to",
    "start": "1176679",
    "end": "1177760"
  },
  {
    "text": "etcd we Define an Argo workflow dag",
    "start": "1177760",
    "end": "1180960"
  },
  {
    "text": "called",
    "start": "1180960",
    "end": "1182200"
  },
  {
    "text": "finetune we the first step we do is",
    "start": "1182200",
    "end": "1184720"
  },
  {
    "text": "create the SS SSD storage class that uh",
    "start": "1184720",
    "end": "1188480"
  },
  {
    "text": "that that is required for uh for etcd in",
    "start": "1188480",
    "end": "1192039"
  },
  {
    "text": "parallel we have this list here we",
    "start": "1192039",
    "end": "1194120"
  },
  {
    "text": "create the etcd stateful Set uh and the",
    "start": "1194120",
    "end": "1196799"
  },
  {
    "text": "load balancer in in par parallel then we",
    "start": "1196799",
    "end": "1199760"
  },
  {
    "text": "have the the independent container that",
    "start": "1199760",
    "end": "1201360"
  },
  {
    "text": "I showed you to wait for that specific",
    "start": "1201360",
    "end": "1203880"
  },
  {
    "text": "uh load balancer IP to become available",
    "start": "1203880",
    "end": "1206480"
  },
  {
    "text": "and then it has an argument called etcd",
    "start": "1206480",
    "end": "1208799"
  },
  {
    "text": "service name so that specific job",
    "start": "1208799",
    "end": "1210799"
  },
  {
    "text": "requires an input for the service name",
    "start": "1210799",
    "end": "1213320"
  },
  {
    "text": "that it should wait uh and and and",
    "start": "1213320",
    "end": "1215400"
  },
  {
    "text": "monitor for for that specific IP to",
    "start": "1215400",
    "end": "1217679"
  },
  {
    "text": "become",
    "start": "1217679",
    "end": "1218799"
  },
  {
    "text": "available and finally we have in",
    "start": "1218799",
    "end": "1221480"
  },
  {
    "text": "parallel uh in here in in a loop we're",
    "start": "1221480",
    "end": "1224840"
  },
  {
    "text": "defining we're calling fine tune um four",
    "start": "1224840",
    "end": "1227679"
  },
  {
    "text": "times of course or up to the number of",
    "start": "1227679",
    "end": "1229080"
  },
  {
    "text": "nodes and we pass in the randev ID the",
    "start": "1229080",
    "end": "1232280"
  },
  {
    "text": "node rank the node volume that should be",
    "start": "1232280",
    "end": "1234159"
  },
  {
    "text": "mounted and finally the etcd IP that it",
    "start": "1234159",
    "end": "1237120"
  },
  {
    "text": "uh that each container should connect",
    "start": "1237120",
    "end": "1239280"
  },
  {
    "text": "to and as JP mentioned we have to",
    "start": "1239280",
    "end": "1241679"
  },
  {
    "text": "somehow actually delete all of the",
    "start": "1241679",
    "end": "1243480"
  },
  {
    "text": "resources that that are spun up um",
    "start": "1243480",
    "end": "1246200"
  },
  {
    "text": "dynamically for for the training session",
    "start": "1246200",
    "end": "1248280"
  },
  {
    "text": "so we call the delete etcd resources uh",
    "start": "1248280",
    "end": "1251600"
  },
  {
    "text": "in the end as an exit uh as an exit dag",
    "start": "1251600",
    "end": "1254880"
  },
  {
    "text": "in Argo workflows which will execute",
    "start": "1254880",
    "end": "1256799"
  },
  {
    "text": "irrespective of the result of the of the",
    "start": "1256799",
    "end": "1259440"
  },
  {
    "text": "workflow and then finally we create the",
    "start": "1259440",
    "end": "1261440"
  },
  {
    "text": "training workflow uh now I'm not going",
    "start": "1261440",
    "end": "1263240"
  },
  {
    "text": "to run it uh at the moment because these",
    "start": "1263240",
    "end": "1265320"
  },
  {
    "text": "are um first of all expensive resources",
    "start": "1265320",
    "end": "1268000"
  },
  {
    "text": "second take a lot of time to actually",
    "start": "1268000",
    "end": "1269720"
  },
  {
    "text": "spin up uh and it would be Dreadful to",
    "start": "1269720",
    "end": "1272000"
  },
  {
    "text": "wait for them to actually come up uh so",
    "start": "1272000",
    "end": "1274279"
  },
  {
    "text": "we'll go back to the",
    "start": "1274279",
    "end": "1276279"
  },
  {
    "start": "1276000",
    "end": "1474000"
  },
  {
    "text": "talk none of this is actually would have",
    "start": "1276279",
    "end": "1278559"
  },
  {
    "text": "been possible without a lot of community",
    "start": "1278559",
    "end": "1280039"
  },
  {
    "text": "involvement so we're very thankful for",
    "start": "1280039",
    "end": "1281760"
  },
  {
    "text": "contributions to Hera Argo workflows uh",
    "start": "1281760",
    "end": "1285000"
  },
  {
    "text": "pie torch the open source single llama 2",
    "start": "1285000",
    "end": "1287720"
  },
  {
    "text": "um",
    "start": "1287720",
    "end": "1288640"
  },
  {
    "text": "which are all amazing resources that you",
    "start": "1288640",
    "end": "1290520"
  },
  {
    "text": "should definitely check out we'd love to",
    "start": "1290520",
    "end": "1292960"
  },
  {
    "text": "hear your feedback um and here's a QR",
    "start": "1292960",
    "end": "1295640"
  },
  {
    "text": "code for the repository um as well thank",
    "start": "1295640",
    "end": "1299520"
  },
  {
    "text": "you for the crew for welcoming us in our",
    "start": "1299520",
    "end": "1301360"
  },
  {
    "text": "talk and thank you everyone for your",
    "start": "1301360",
    "end": "1303400"
  },
  {
    "text": "attention I think we have about three",
    "start": "1303400",
    "end": "1305880"
  },
  {
    "text": "and a half minutes if anyone wants to",
    "start": "1305880",
    "end": "1308240"
  },
  {
    "text": "ask some",
    "start": "1308240",
    "end": "1310600"
  },
  {
    "text": "questions thanks",
    "start": "1310600",
    "end": "1313840"
  },
  {
    "text": "everybody yeah I I see you you want to",
    "start": "1316840",
    "end": "1319279"
  },
  {
    "text": "answer ask a question yep I can hand you",
    "start": "1319279",
    "end": "1322440"
  },
  {
    "text": "my mic",
    "start": "1322440",
    "end": "1325360"
  },
  {
    "text": "many mik in the center",
    "start": "1325360",
    "end": "1329720"
  },
  {
    "text": "okay how many different uh instances",
    "start": "1332760",
    "end": "1335840"
  },
  {
    "text": "have you tried running with this because",
    "start": "1335840",
    "end": "1337360"
  },
  {
    "text": "I imagine now it's easy to spin up many",
    "start": "1337360",
    "end": "1340400"
  },
  {
    "text": "different",
    "start": "1340400",
    "end": "1341679"
  },
  {
    "text": "models when you say instance do you mean",
    "start": "1341679",
    "end": "1344440"
  },
  {
    "text": "like uh different llms like llama versus",
    "start": "1344440",
    "end": "1347000"
  },
  {
    "text": "other models exactly exactly yeah yeah",
    "start": "1347000",
    "end": "1349799"
  },
  {
    "text": "we've only focused on training llama 2",
    "start": "1349799",
    "end": "1352159"
  },
  {
    "text": "um the Train the the training Loop that",
    "start": "1352159",
    "end": "1354480"
  },
  {
    "text": "you find in the laa recipes um will",
    "start": "1354480",
    "end": "1357080"
  },
  {
    "text": "provide a lot of examples of how you can",
    "start": "1357080",
    "end": "1358919"
  },
  {
    "text": "actually wrap other llms through through",
    "start": "1358919",
    "end": "1361480"
  },
  {
    "text": "a similar infrastructure or and and Pie",
    "start": "1361480",
    "end": "1363720"
  },
  {
    "text": "torch and all of this so you should be",
    "start": "1363720",
    "end": "1365159"
  },
  {
    "text": "able to train uh from scratch if your",
    "start": "1365159",
    "end": "1367919"
  },
  {
    "text": "business is interested in that or fine",
    "start": "1367919",
    "end": "1369200"
  },
  {
    "text": "tune on your own data using this type of",
    "start": "1369200",
    "end": "1370760"
  },
  {
    "text": "model as well and that's regardless of",
    "start": "1370760",
    "end": "1373080"
  },
  {
    "text": "the model or their specific limitations",
    "start": "1373080",
    "end": "1375440"
  },
  {
    "text": "on Which models can be",
    "start": "1375440",
    "end": "1376960"
  },
  {
    "text": "used",
    "start": "1376960",
    "end": "1379159"
  },
  {
    "text": "this type of infrastructure is useful",
    "start": "1379159",
    "end": "1380640"
  },
  {
    "text": "for large models if you don't have",
    "start": "1380640",
    "end": "1383320"
  },
  {
    "text": "models that benefit from sharding",
    "start": "1383320",
    "end": "1385360"
  },
  {
    "text": "independent chunks of a model to a GPU",
    "start": "1385360",
    "end": "1387760"
  },
  {
    "text": "then don't use this if the model is",
    "start": "1387760",
    "end": "1389520"
  },
  {
    "text": "small don't use this uh it's going to be",
    "start": "1389520",
    "end": "1391840"
  },
  {
    "text": "very costly for the actual requirements",
    "start": "1391840",
    "end": "1394480"
  },
  {
    "text": "of the",
    "start": "1394480",
    "end": "1396760"
  },
  {
    "text": "model looks like we got another one",
    "start": "1400919",
    "end": "1405519"
  },
  {
    "text": "yep so imagine that your gpus are mostly",
    "start": "1406880",
    "end": "1411919"
  },
  {
    "text": "reliable and you have now a very large",
    "start": "1411919",
    "end": "1414360"
  },
  {
    "text": "expensive job and your GPU number three",
    "start": "1414360",
    "end": "1417080"
  },
  {
    "text": "just failed and you don't want to lose",
    "start": "1417080",
    "end": "1419400"
  },
  {
    "text": "the inputs that you had on the other",
    "start": "1419400",
    "end": "1421080"
  },
  {
    "text": "three gpus so what's the story here how",
    "start": "1421080",
    "end": "1423520"
  },
  {
    "text": "do I rerun exactly that chart and that",
    "start": "1423520",
    "end": "1425640"
  },
  {
    "text": "chart",
    "start": "1425640",
    "end": "1427120"
  },
  {
    "text": "only there's actually a retry flag on",
    "start": "1427120",
    "end": "1430360"
  },
  {
    "text": "the on the on on torch run itself and I",
    "start": "1430360",
    "end": "1433559"
  },
  {
    "text": "believe it keeps track of the failures",
    "start": "1433559",
    "end": "1436799"
  },
  {
    "text": "within a specific rank or one of these",
    "start": "1436799",
    "end": "1438720"
  },
  {
    "text": "specific containers and it will try",
    "start": "1438720",
    "end": "1440799"
  },
  {
    "text": "retry uh that specific job or continuing",
    "start": "1440799",
    "end": "1444919"
  },
  {
    "text": "fine tuning from that specific point and",
    "start": "1444919",
    "end": "1446640"
  },
  {
    "text": "there's also checkpointing that you can",
    "start": "1446640",
    "end": "1448440"
  },
  {
    "text": "use and I believe it uses that as well",
    "start": "1448440",
    "end": "1450559"
  },
  {
    "text": "which saves the models to the disk and",
    "start": "1450559",
    "end": "1453200"
  },
  {
    "text": "then Rel reloads them upon",
    "start": "1453200",
    "end": "1456760"
  },
  {
    "text": "retrying all right 50 seconds any other",
    "start": "1459640",
    "end": "1464720"
  },
  {
    "text": "questions going once twice thce again",
    "start": "1464720",
    "end": "1469440"
  },
  {
    "text": "thank you guys so much for coming out",
    "start": "1469440",
    "end": "1470960"
  },
  {
    "text": "and checking out the talk we really",
    "start": "1470960",
    "end": "1472039"
  },
  {
    "text": "appreciate",
    "start": "1472039",
    "end": "1473880"
  },
  {
    "text": "yall",
    "start": "1473880",
    "end": "1476880"
  }
]
[
  {
    "text": "hi hello everyone so I nikunj goyel",
    "start": "120",
    "end": "3840"
  },
  {
    "text": "member of technical staff at adovi where",
    "start": "3840",
    "end": "6160"
  },
  {
    "text": "I work to bring the generative a to all",
    "start": "6160",
    "end": "8599"
  },
  {
    "text": "the Adobe blood apps hello everyone I'm",
    "start": "8599",
    "end": "11120"
  },
  {
    "text": "Aditi Gupta I'm a software developer",
    "start": "11120",
    "end": "13080"
  },
  {
    "text": "engineer at Disney plus hot star where I",
    "start": "13080",
    "end": "16080"
  },
  {
    "text": "work to enhance the consumer experience",
    "start": "16080",
    "end": "18279"
  },
  {
    "text": "for the",
    "start": "18279",
    "end": "19519"
  },
  {
    "text": "application let's quickly gloss over the",
    "start": "19519",
    "end": "21960"
  },
  {
    "text": "presentation outline so starting with",
    "start": "21960",
    "end": "24359"
  },
  {
    "text": "the role of",
    "start": "24359",
    "end": "26480"
  },
  {
    "text": "jeus so starting with the role of Jeep",
    "start": "26480",
    "end": "29080"
  },
  {
    "text": "use for computation intensive task we",
    "start": "29080",
    "end": "31560"
  },
  {
    "text": "will first cover the concurrent",
    "start": "31560",
    "end": "33320"
  },
  {
    "text": "landscape and challenges of GPU",
    "start": "33320",
    "end": "34879"
  },
  {
    "text": "scheduling in kubernetes and propose a",
    "start": "34879",
    "end": "37239"
  },
  {
    "text": "RL based solution designed to address",
    "start": "37239",
    "end": "39840"
  },
  {
    "text": "these limitations offering improvements",
    "start": "39840",
    "end": "42520"
  },
  {
    "text": "in efficiency workload prioritization",
    "start": "42520",
    "end": "45280"
  },
  {
    "text": "and",
    "start": "45280",
    "end": "46440"
  },
  {
    "text": "scalability in recent years as more and",
    "start": "46440",
    "end": "49360"
  },
  {
    "text": "more large- scale ml models are being",
    "start": "49360",
    "end": "51559"
  },
  {
    "text": "deployed gpus have gained prominence to",
    "start": "51559",
    "end": "54840"
  },
  {
    "text": "handle the increasing computational",
    "start": "54840",
    "end": "56600"
  },
  {
    "text": "demands of deep learning workloads with",
    "start": "56600",
    "end": "59199"
  },
  {
    "text": "the increase inserts workloads public",
    "start": "59199",
    "end": "61600"
  },
  {
    "text": "clouds have provision GPU resources at",
    "start": "61600",
    "end": "64360"
  },
  {
    "text": "the scale of thousands of nodes in data",
    "start": "64360",
    "end": "66840"
  },
  {
    "text": "centers however gpus are relatively new",
    "start": "66840",
    "end": "70400"
  },
  {
    "text": "to the cloud stack support for efficient",
    "start": "70400",
    "end": "73280"
  },
  {
    "text": "GPU management lacks as State ofth art",
    "start": "73280",
    "end": "76560"
  },
  {
    "text": "cluster resource orchestration treat",
    "start": "76560",
    "end": "79360"
  },
  {
    "text": "gpus only as a specific resource",
    "start": "79360",
    "end": "82000"
  },
  {
    "text": "constraint while ignoring its unique",
    "start": "82000",
    "end": "85000"
  },
  {
    "text": "characteristics and application",
    "start": "85000",
    "end": "87320"
  },
  {
    "text": "properties so now with the help of of",
    "start": "87320",
    "end": "90079"
  },
  {
    "text": "some Modern Day applications let's see",
    "start": "90079",
    "end": "92799"
  },
  {
    "text": "why efficient GPU scheduling is needed",
    "start": "92799",
    "end": "95799"
  },
  {
    "text": "for data intensive ml models in",
    "start": "95799",
    "end": "98880"
  },
  {
    "text": "applications like the self-driving cars",
    "start": "98880",
    "end": "101600"
  },
  {
    "text": "CNN are trained on millions of labeled",
    "start": "101600",
    "end": "104240"
  },
  {
    "text": "images to recognize objects efficient",
    "start": "104240",
    "end": "107399"
  },
  {
    "text": "GPU scheduling ensures that these large",
    "start": "107399",
    "end": "110799"
  },
  {
    "text": "data sets are processed swiftly enabling",
    "start": "110799",
    "end": "114280"
  },
  {
    "text": "faster model training next in the",
    "start": "114280",
    "end": "117000"
  },
  {
    "text": "e-commerce recommendation systems mult",
    "start": "117000",
    "end": "119880"
  },
  {
    "text": "multiple machine learning tasks may run",
    "start": "119880",
    "end": "122759"
  },
  {
    "text": "simultaneously each needing access to a",
    "start": "122759",
    "end": "125399"
  },
  {
    "text": "GPU resource effective scheduling helps",
    "start": "125399",
    "end": "128840"
  },
  {
    "text": "manage these concurrent workloads",
    "start": "128840",
    "end": "131160"
  },
  {
    "text": "preventing resource",
    "start": "131160",
    "end": "132800"
  },
  {
    "text": "contention then in the natural language",
    "start": "132800",
    "end": "135680"
  },
  {
    "text": "processing that is the NLP for chat",
    "start": "135680",
    "end": "138400"
  },
  {
    "text": "boards like open AI GPT models these",
    "start": "138400",
    "end": "142239"
  },
  {
    "text": "often run multiple queries concurrently",
    "start": "142239",
    "end": "145599"
  },
  {
    "text": "efficient GP scheduling maximizes the",
    "start": "145599",
    "end": "148120"
  },
  {
    "text": "utilization of available GP use allowing",
    "start": "148120",
    "end": "151480"
  },
  {
    "text": "for numerous user interaction to be",
    "start": "151480",
    "end": "153560"
  },
  {
    "text": "processed at once which is very crucial",
    "start": "153560",
    "end": "156400"
  },
  {
    "text": "for responsive customer service however",
    "start": "156400",
    "end": "159959"
  },
  {
    "text": "as we will see later that the support",
    "start": "159959",
    "end": "162239"
  },
  {
    "text": "for efficient GPU management is very",
    "start": "162239",
    "end": "164920"
  },
  {
    "text": "limited and gpus are mostly treated as a",
    "start": "164920",
    "end": "168239"
  },
  {
    "text": "specific resource constraint while",
    "start": "168239",
    "end": "170680"
  },
  {
    "text": "ignoring its unique characteristics and",
    "start": "170680",
    "end": "173000"
  },
  {
    "text": "application",
    "start": "173000",
    "end": "174480"
  },
  {
    "text": "properties in any Computing system",
    "start": "174480",
    "end": "177080"
  },
  {
    "text": "scheduling refers to the way resources",
    "start": "177080",
    "end": "180040"
  },
  {
    "text": "are allocated to different tasks GPU",
    "start": "180040",
    "end": "182680"
  },
  {
    "text": "scheduling is the process of allocating",
    "start": "182680",
    "end": "185840"
  },
  {
    "text": "this GPU resource to applications or",
    "start": "185840",
    "end": "188319"
  },
  {
    "text": "workloads that need it let's skim over",
    "start": "188319",
    "end": "192120"
  },
  {
    "text": "and outline that how this scheduling",
    "start": "192120",
    "end": "194799"
  },
  {
    "text": "works first is the resource request so",
    "start": "194799",
    "end": "199080"
  },
  {
    "text": "when a workload like a machine learning",
    "start": "199080",
    "end": "201200"
  },
  {
    "text": "training job is submitted it specifies",
    "start": "201200",
    "end": "204000"
  },
  {
    "text": "that how many gpus resources it needs",
    "start": "204000",
    "end": "207000"
  },
  {
    "text": "this is done by the application",
    "start": "207000",
    "end": "208799"
  },
  {
    "text": "requesting a certain number of gpus",
    "start": "208799",
    "end": "211599"
  },
  {
    "text": "second is the scheduling decision the",
    "start": "211599",
    "end": "214200"
  },
  {
    "text": "scheduler like the kubernetes native",
    "start": "214200",
    "end": "216519"
  },
  {
    "text": "Cube scheduler looks at the available",
    "start": "216519",
    "end": "219200"
  },
  {
    "text": "gpus across the system and then",
    "start": "219200",
    "end": "222040"
  },
  {
    "text": "determines where the workload should be",
    "start": "222040",
    "end": "224200"
  },
  {
    "text": "placed based on availability priority",
    "start": "224200",
    "end": "226840"
  },
  {
    "text": "and resource needs job placement is",
    "start": "226840",
    "end": "229840"
  },
  {
    "text": "third so once a decision is made the job",
    "start": "229840",
    "end": "232920"
  },
  {
    "text": "is assigned to the node node means a",
    "start": "232920",
    "end": "235640"
  },
  {
    "text": "server in the cluster that has the",
    "start": "235640",
    "end": "237720"
  },
  {
    "text": "requested gpus and then the application",
    "start": "237720",
    "end": "240720"
  },
  {
    "text": "starts using those resources the last is",
    "start": "240720",
    "end": "244159"
  },
  {
    "text": "the monitoring and scaling the scheduler",
    "start": "244159",
    "end": "246959"
  },
  {
    "text": "continuously monitors GPU usage if more",
    "start": "246959",
    "end": "250159"
  },
  {
    "text": "resources are needed or if the workload",
    "start": "250159",
    "end": "252239"
  },
  {
    "text": "can scale down it address",
    "start": "252239",
    "end": "255079"
  },
  {
    "text": "accordingly so to understand how we lack",
    "start": "255079",
    "end": "258040"
  },
  {
    "text": "in efficient GPU scheduling let's dive",
    "start": "258040",
    "end": "260720"
  },
  {
    "text": "deep in the default kubernetes scheduler",
    "start": "260720",
    "end": "263560"
  },
  {
    "text": "that is the cube scheduler well the",
    "start": "263560",
    "end": "266520"
  },
  {
    "text": "entry point is API server which are",
    "start": "266520",
    "end": "269880"
  },
  {
    "text": "scheduler watches for any ports that",
    "start": "269880",
    "end": "272360"
  },
  {
    "text": "lack a nnm field which means that the",
    "start": "272360",
    "end": "274960"
  },
  {
    "text": "port isn't yet",
    "start": "274960",
    "end": "276400"
  },
  {
    "text": "scheduled so but it uses a very",
    "start": "276400",
    "end": "279479"
  },
  {
    "text": "generalized scheduling policy that got",
    "start": "279479",
    "end": "281840"
  },
  {
    "text": "no specialized handling for gpus or any",
    "start": "281840",
    "end": "284680"
  },
  {
    "text": "other task specific",
    "start": "284680",
    "end": "286520"
  },
  {
    "text": "preference however the cube scheduler",
    "start": "286520",
    "end": "289160"
  },
  {
    "text": "allows for custom scheduling through",
    "start": "289160",
    "end": "291280"
  },
  {
    "text": "both plugins and scheduler framework",
    "start": "291280",
    "end": "293960"
  },
  {
    "text": "which are able to enhance its sched",
    "start": "293960",
    "end": "295840"
  },
  {
    "text": "capabilities so here we are",
    "start": "295840",
    "end": "297520"
  },
  {
    "text": "demonstrating a basic architecture of",
    "start": "297520",
    "end": "300199"
  },
  {
    "text": "how Cube schedul works so in centrer you",
    "start": "300199",
    "end": "302199"
  },
  {
    "text": "got this API server which listens to all",
    "start": "302199",
    "end": "304639"
  },
  {
    "text": "the incoming nodes and uh then the",
    "start": "304639",
    "end": "307680"
  },
  {
    "text": "scheduler connects to this API server",
    "start": "307680",
    "end": "309880"
  },
  {
    "text": "and decides which ports go to which",
    "start": "309880",
    "end": "314240"
  },
  {
    "text": "node so let's coming to the detail of",
    "start": "314280",
    "end": "317080"
  },
  {
    "text": "current scheduling policy the algorithm",
    "start": "317080",
    "end": "319080"
  },
  {
    "text": "basically got two main phases the",
    "start": "319080",
    "end": "321199"
  },
  {
    "text": "filtering phase and then the scoring",
    "start": "321199",
    "end": "322919"
  },
  {
    "text": "phase so in the first filtering phase it",
    "start": "322919",
    "end": "325639"
  },
  {
    "text": "filters out all the nodes unsuitable for",
    "start": "325639",
    "end": "327919"
  },
  {
    "text": "the P based on P affinity tend and",
    "start": "327919",
    "end": "330800"
  },
  {
    "text": "Toleration like it evaluates if the",
    "start": "330800",
    "end": "333520"
  },
  {
    "text": "ports Affinity or anti-affinity rules",
    "start": "333520",
    "end": "336479"
  },
  {
    "text": "that is preference or restriction to be",
    "start": "336479",
    "end": "339520"
  },
  {
    "text": "scheduled on certain nodes matches the",
    "start": "339520",
    "end": "342039"
  },
  {
    "text": "nodes labels it also filter out nodes",
    "start": "342039",
    "end": "345400"
  },
  {
    "text": "where tends don't align with the ports",
    "start": "345400",
    "end": "348400"
  },
  {
    "text": "Toleration after it got a list of",
    "start": "348400",
    "end": "350880"
  },
  {
    "text": "visible nodes they are then assigned",
    "start": "350880",
    "end": "353720"
  },
  {
    "text": "unnormalized score which is on a scale",
    "start": "353720",
    "end": "356039"
  },
  {
    "text": "of 1 12 100 based on the load balancing",
    "start": "356039",
    "end": "359639"
  },
  {
    "text": "node Affinity or any other user",
    "start": "359639",
    "end": "361919"
  },
  {
    "text": "specified criteria it favor nodes that",
    "start": "361919",
    "end": "365360"
  },
  {
    "text": "have the least resource consumption to",
    "start": "365360",
    "end": "367639"
  },
  {
    "text": "spread ports evenly while in certain",
    "start": "367639",
    "end": "370759"
  },
  {
    "text": "scenarios clustering more ports on fewer",
    "start": "370759",
    "end": "373560"
  },
  {
    "text": "nodes may be preferred to conserve",
    "start": "373560",
    "end": "376080"
  },
  {
    "text": "resources uh this can be seen in",
    "start": "376080",
    "end": "378240"
  },
  {
    "text": "scenarios such as Auto scaling or bur",
    "start": "378240",
    "end": "380800"
  },
  {
    "text": "scenarios in this manner it selects the",
    "start": "380800",
    "end": "383400"
  },
  {
    "text": "node with highest score communicates",
    "start": "383400",
    "end": "386520"
  },
  {
    "text": "this decision to the API server where it",
    "start": "386520",
    "end": "389080"
  },
  {
    "text": "binds the the P to the choosen",
    "start": "389080",
    "end": "391400"
  },
  {
    "text": "node however if selected node become",
    "start": "391400",
    "end": "394680"
  },
  {
    "text": "unsuitable due to any reason during The",
    "start": "394680",
    "end": "396840"
  },
  {
    "text": "Binding phase a secondary node may be",
    "start": "396840",
    "end": "399800"
  },
  {
    "text": "choosen but if you are in a very bad",
    "start": "399800",
    "end": "401520"
  },
  {
    "text": "luck and no suitable node is found Port",
    "start": "401520",
    "end": "404520"
  },
  {
    "text": "is recued for further scheduling",
    "start": "404520",
    "end": "407960"
  },
  {
    "text": "attempts so let's hope onto some of the",
    "start": "407960",
    "end": "411240"
  },
  {
    "text": "major drawbacks of cube scheduler in",
    "start": "411240",
    "end": "413199"
  },
  {
    "text": "context of",
    "start": "413199",
    "end": "414599"
  },
  {
    "text": "gpus first and the foremost is the",
    "start": "414599",
    "end": "417199"
  },
  {
    "text": "resource fragmentation Cube sh",
    "start": "417199",
    "end": "420120"
  },
  {
    "text": "does not natively support the fine grain",
    "start": "420120",
    "end": "422440"
  },
  {
    "text": "GPU resource sharing it treats gpus as",
    "start": "422440",
    "end": "425800"
  },
  {
    "text": "integer units meaning a pod is either",
    "start": "425800",
    "end": "428759"
  },
  {
    "text": "assigned a whole GPU or none leading to",
    "start": "428759",
    "end": "431759"
  },
  {
    "text": "the inefficient",
    "start": "431759",
    "end": "433120"
  },
  {
    "text": "utilization if a workload does not fully",
    "start": "433120",
    "end": "435680"
  },
  {
    "text": "use the gpu's power this leads to",
    "start": "435680",
    "end": "438560"
  },
  {
    "text": "inefficient resource utilization where",
    "start": "438560",
    "end": "440560"
  },
  {
    "text": "some workloads may underutilize the GPU",
    "start": "440560",
    "end": "443160"
  },
  {
    "text": "While others are left waiting also this",
    "start": "443160",
    "end": "446720"
  },
  {
    "text": "inability to handle the partial GPU",
    "start": "446720",
    "end": "449599"
  },
  {
    "text": "allocations lead to fragmentation that",
    "start": "449599",
    "end": "451759"
  },
  {
    "text": "means the jobs that need fewer resources",
    "start": "451759",
    "end": "454560"
  },
  {
    "text": "still consume entire GPU making the",
    "start": "454560",
    "end": "457199"
  },
  {
    "text": "cluster very inefficient this",
    "start": "457199",
    "end": "459759"
  },
  {
    "text": "inefficient use of available gpus makes",
    "start": "459759",
    "end": "462680"
  },
  {
    "text": "small jobs block gpus with unused",
    "start": "462680",
    "end": "466560"
  },
  {
    "text": "capacity second is the heterogeneous",
    "start": "466560",
    "end": "469280"
  },
  {
    "text": "Hardware management the cube scheduler",
    "start": "469280",
    "end": "472039"
  },
  {
    "text": "doesn't have built-in features to manage",
    "start": "472039",
    "end": "474159"
  },
  {
    "text": "different types of gpus that is the",
    "start": "474159",
    "end": "476479"
  },
  {
    "text": "Nvidia and the AMD just for an example",
    "start": "476479",
    "end": "480080"
  },
  {
    "text": "custom configurations or vendor specific",
    "start": "480080",
    "end": "482599"
  },
  {
    "text": "plugins like the Nvidia device plug-in",
    "start": "482599",
    "end": "485520"
  },
  {
    "text": "are required to manage this heterogenity",
    "start": "485520",
    "end": "488560"
  },
  {
    "text": "but they do not integrate seamlessly",
    "start": "488560",
    "end": "491039"
  },
  {
    "text": "with the cube",
    "start": "491039",
    "end": "493159"
  },
  {
    "text": "scheduler then we have the lack of",
    "start": "493159",
    "end": "495560"
  },
  {
    "text": "preemptive scheduling so yes you heard",
    "start": "495560",
    "end": "498319"
  },
  {
    "text": "it right the cube scheduler does not",
    "start": "498319",
    "end": "500520"
  },
  {
    "text": "even support the preemptive scheduling",
    "start": "500520",
    "end": "502400"
  },
  {
    "text": "for GPU resources meaning high priority",
    "start": "502400",
    "end": "505840"
  },
  {
    "text": "jobs can't preempt the lower priority",
    "start": "505840",
    "end": "508360"
  },
  {
    "text": "ones they work as a monopoly causing",
    "start": "508360",
    "end": "511960"
  },
  {
    "text": "delays for critical tasks if long",
    "start": "511960",
    "end": "514440"
  },
  {
    "text": "running jobs are occupying the gpus",
    "start": "514440",
    "end": "517560"
  },
  {
    "text": "hence resulting in higher job latency",
    "start": "517560",
    "end": "519800"
  },
  {
    "text": "for the critical",
    "start": "519800",
    "end": "521518"
  },
  {
    "text": "task the cube scheduler also does not",
    "start": "521519",
    "end": "524560"
  },
  {
    "text": "natively have a strong awareness of the",
    "start": "524560",
    "end": "526880"
  },
  {
    "text": "realtime status or health of GPO",
    "start": "526880",
    "end": "529360"
  },
  {
    "text": "resources it relies on static",
    "start": "529360",
    "end": "531959"
  },
  {
    "text": "information like resource requests and",
    "start": "531959",
    "end": "534560"
  },
  {
    "text": "limits when making scheduling decision",
    "start": "534560",
    "end": "537560"
  },
  {
    "text": "this leads to potential delays or job",
    "start": "537560",
    "end": "539920"
  },
  {
    "text": "failures if the GPU availability changes",
    "start": "539920",
    "end": "543880"
  },
  {
    "text": "dynamically let's see how the",
    "start": "543880",
    "end": "546640"
  },
  {
    "text": "reinforcement learning could be a",
    "start": "546640",
    "end": "548600"
  },
  {
    "text": "prominent solution for the multifaceted",
    "start": "548600",
    "end": "551760"
  },
  {
    "text": "problems in GPU",
    "start": "551760",
    "end": "553720"
  },
  {
    "text": "utilization reinforcement learning that",
    "start": "553720",
    "end": "556399"
  },
  {
    "text": "is RL is one of the three flavors of",
    "start": "556399",
    "end": "559160"
  },
  {
    "text": "machine learning but unlike supervised",
    "start": "559160",
    "end": "562320"
  },
  {
    "text": "or unsupervised learning where the model",
    "start": "562320",
    "end": "565040"
  },
  {
    "text": "learns from labeled or unlabeled data",
    "start": "565040",
    "end": "568079"
  },
  {
    "text": "respectively the ARL has an agent that",
    "start": "568079",
    "end": "571279"
  },
  {
    "text": "interacts with an environment then it",
    "start": "571279",
    "end": "574000"
  },
  {
    "text": "takes actions and get feedback feedback",
    "start": "574000",
    "end": "576920"
  },
  {
    "text": "means the rewards these feedbacks are",
    "start": "576920",
    "end": "579880"
  },
  {
    "text": "based on how good or bad those actions",
    "start": "579880",
    "end": "582320"
  },
  {
    "text": "are by constantly learning from this",
    "start": "582320",
    "end": "585079"
  },
  {
    "text": "feedback and reward cycle the agent",
    "start": "585079",
    "end": "587720"
  },
  {
    "text": "eventually figures out how to make the",
    "start": "587720",
    "end": "590079"
  },
  {
    "text": "best decisions to maximize its",
    "start": "590079",
    "end": "593120"
  },
  {
    "text": "rewards yep so why we think ARL is a",
    "start": "593120",
    "end": "596560"
  },
  {
    "text": "good option for scheduling these gpus",
    "start": "596560",
    "end": "599519"
  },
  {
    "text": "so first RL can do multiple objective",
    "start": "599519",
    "end": "603279"
  },
  {
    "text": "optimization it can consider",
    "start": "603279",
    "end": "605680"
  },
  {
    "text": "optimization of diverse metrics like GPU",
    "start": "605680",
    "end": "608399"
  },
  {
    "text": "utilization task latency and power",
    "start": "608399",
    "end": "611079"
  },
  {
    "text": "efficiency all of these",
    "start": "611079",
    "end": "613440"
  },
  {
    "text": "simultaneously it can also manage large",
    "start": "613440",
    "end": "616440"
  },
  {
    "text": "State space like zp utilization Q length",
    "start": "616440",
    "end": "619600"
  },
  {
    "text": "job types all of them together quite",
    "start": "619600",
    "end": "622680"
  },
  {
    "text": "well it further inherently supports",
    "start": "622680",
    "end": "625680"
  },
  {
    "text": "feedback loops thus improving the",
    "start": "625680",
    "end": "627640"
  },
  {
    "text": "scheduling policy as it gains more",
    "start": "627640",
    "end": "630040"
  },
  {
    "text": "experience lastly you have got a",
    "start": "630040",
    "end": "632720"
  },
  {
    "text": "autonomous decision making machine so it",
    "start": "632720",
    "end": "635440"
  },
  {
    "text": "minimizes the need for constant manual",
    "start": "635440",
    "end": "637639"
  },
  {
    "text": "tuning and configuration",
    "start": "637639",
    "end": "641320"
  },
  {
    "text": "updates so we can't use RL just as a",
    "start": "641680",
    "end": "645639"
  },
  {
    "text": "plug-in player to use RL you need to",
    "start": "645639",
    "end": "648680"
  },
  {
    "text": "first model the GPU scheduling problem",
    "start": "648680",
    "end": "650880"
  },
  {
    "text": "as a mark of decision process so in a",
    "start": "650880",
    "end": "653639"
  },
  {
    "text": "mark of decision process you got three",
    "start": "653639",
    "end": "655160"
  },
  {
    "text": "things first a state a action and a",
    "start": "655160",
    "end": "657839"
  },
  {
    "text": "reward so in a our case the state is",
    "start": "657839",
    "end": "661839"
  },
  {
    "text": "just a onedimensional vector with",
    "start": "661839",
    "end": "664160"
  },
  {
    "text": "normalized node and P features so what",
    "start": "664160",
    "end": "667440"
  },
  {
    "text": "would be a state it's just a vector with",
    "start": "667440",
    "end": "669880"
  },
  {
    "text": "entri such as node one node two node 3 4",
    "start": "669880",
    "end": "673079"
  },
  {
    "text": "up to node n and then the",
    "start": "673079",
    "end": "675160"
  },
  {
    "text": "port next uh the scheduler plays the",
    "start": "675160",
    "end": "678399"
  },
  {
    "text": "role of agent here uh whose actions are",
    "start": "678399",
    "end": "681880"
  },
  {
    "text": "to select a node for the given P to be",
    "start": "681880",
    "end": "685240"
  },
  {
    "text": "executed and thus the xtion spaces all",
    "start": "685240",
    "end": "688240"
  },
  {
    "text": "the possible nodes in the cluster",
    "start": "688240",
    "end": "691000"
  },
  {
    "text": "finally the reward function of DRS",
    "start": "691000",
    "end": "694000"
  },
  {
    "text": "reflects the average resource",
    "start": "694000",
    "end": "695600"
  },
  {
    "text": "utilization across your cluster which is",
    "start": "695600",
    "end": "698760"
  },
  {
    "text": "a custom function that takes into",
    "start": "698760",
    "end": "701720"
  },
  {
    "text": "account the different utilization",
    "start": "701720",
    "end": "703480"
  },
  {
    "text": "metrics and it can easily be customized",
    "start": "703480",
    "end": "706279"
  },
  {
    "text": "to reflect some of the particular",
    "start": "706279",
    "end": "709920"
  },
  {
    "text": "situations So based on this we propose a",
    "start": "710040",
    "end": "714079"
  },
  {
    "text": "deep reinforcement based scheduler which",
    "start": "714079",
    "end": "716279"
  },
  {
    "text": "we name as DRS scheduler this drf",
    "start": "716279",
    "end": "719360"
  },
  {
    "text": "scheduler has got three main components",
    "start": "719360",
    "end": "722680"
  },
  {
    "text": "first you got the monitors which run on",
    "start": "722680",
    "end": "725279"
  },
  {
    "text": "each of the node that has got a GPU and",
    "start": "725279",
    "end": "728519"
  },
  {
    "text": "on each node this monitor collects your",
    "start": "728519",
    "end": "731040"
  },
  {
    "text": "realtime GPU usage Matrix and then",
    "start": "731040",
    "end": "734120"
  },
  {
    "text": "passes them on to the decision maker the",
    "start": "734120",
    "end": "736920"
  },
  {
    "text": "decision",
    "start": "736920",
    "end": "737959"
  },
  {
    "text": "maker is our our elent it receives the",
    "start": "737959",
    "end": "741639"
  },
  {
    "text": "metrix from the monitors make the",
    "start": "741639",
    "end": "743720"
  },
  {
    "text": "scheduling decision based on its inner",
    "start": "743720",
    "end": "745800"
  },
  {
    "text": "noodle networks and passes them on to",
    "start": "745800",
    "end": "748800"
  },
  {
    "text": "the Q scheduler the cube scheder that we",
    "start": "748800",
    "end": "751279"
  },
  {
    "text": "discussed earlier this Cube scheder then",
    "start": "751279",
    "end": "754120"
  },
  {
    "text": "actually uses the RL agent's decision to",
    "start": "754120",
    "end": "756560"
  },
  {
    "text": "schedule the ports on the nodes and",
    "start": "756560",
    "end": "759000"
  },
  {
    "text": "across all this you got a feedback loop",
    "start": "759000",
    "end": "761120"
  },
  {
    "text": "that provide feedback from actual",
    "start": "761120",
    "end": "763320"
  },
  {
    "text": "scheduling outcomes back to the AR agent",
    "start": "763320",
    "end": "766320"
  },
  {
    "text": "allowing it to improve over the",
    "start": "766320",
    "end": "769720"
  },
  {
    "text": "time so coming to the main Crux of our",
    "start": "770120",
    "end": "773519"
  },
  {
    "text": "whole model the decision maker so what",
    "start": "773519",
    "end": "776600"
  },
  {
    "text": "is the decision maker it's just a deep Q",
    "start": "776600",
    "end": "778959"
  },
  {
    "text": "Net Network model that leverage Mark of",
    "start": "778959",
    "end": "781880"
  },
  {
    "text": "decision process to accurately represent",
    "start": "781880",
    "end": "784560"
  },
  {
    "text": "the behavior of our scheduling agent uh",
    "start": "784560",
    "end": "787959"
  },
  {
    "text": "this DRS decision maker communicate with",
    "start": "787959",
    "end": "790120"
  },
  {
    "text": "the native Cube scheder and DRS monitor",
    "start": "790120",
    "end": "793240"
  },
  {
    "text": "which are situated on each of the worker",
    "start": "793240",
    "end": "794920"
  },
  {
    "text": "nodes through socket based channel the",
    "start": "794920",
    "end": "797399"
  },
  {
    "text": "socket based channels are used so that",
    "start": "797399",
    "end": "799720"
  },
  {
    "text": "it enables the decision maker to collect",
    "start": "799720",
    "end": "802199"
  },
  {
    "text": "and respond to real time",
    "start": "802199",
    "end": "804760"
  },
  {
    "text": "data uh then it got this experience pool",
    "start": "804760",
    "end": "808440"
  },
  {
    "text": "which is filled with scheduling data as",
    "start": "808440",
    "end": "811160"
  },
  {
    "text": "a new new scheduling events keep on",
    "start": "811160",
    "end": "813360"
  },
  {
    "text": "occurring once this pool reaches its",
    "start": "813360",
    "end": "815800"
  },
  {
    "text": "capacity which is a pred determined",
    "start": "815800",
    "end": "818480"
  },
  {
    "text": "constant it is leveraged for training",
    "start": "818480",
    "end": "820839"
  },
  {
    "text": "the neural network the decision- making",
    "start": "820839",
    "end": "823079"
  },
  {
    "text": "process itself is centered around",
    "start": "823079",
    "end": "825680"
  },
  {
    "text": "calculating Q values based on your",
    "start": "825680",
    "end": "828360"
  },
  {
    "text": "normalized cluster State",
    "start": "828360",
    "end": "830759"
  },
  {
    "text": "Vector these Q values guide the",
    "start": "830759",
    "end": "833399"
  },
  {
    "text": "selection of actions prioritizing those",
    "start": "833399",
    "end": "835959"
  },
  {
    "text": "that promise the highest reward giving",
    "start": "835959",
    "end": "838040"
  },
  {
    "text": "the current state of flush",
    "start": "838040",
    "end": "840120"
  },
  {
    "text": "after reaching 50 scheduling iterations",
    "start": "840120",
    "end": "842800"
  },
  {
    "text": "the weight of Target networks are",
    "start": "842800",
    "end": "844480"
  },
  {
    "text": "synchronized with that of evaluation",
    "start": "844480",
    "end": "846320"
  },
  {
    "text": "Network to stabilize the training",
    "start": "846320",
    "end": "850120"
  },
  {
    "text": "process so how we train this decision",
    "start": "850120",
    "end": "853079"
  },
  {
    "text": "maker so to train this decision maker",
    "start": "853079",
    "end": "856639"
  },
  {
    "text": "effectively We Begin by random",
    "start": "856639",
    "end": "859160"
  },
  {
    "text": "initialization which happens in all of",
    "start": "859160",
    "end": "861279"
  },
  {
    "text": "the machine learning",
    "start": "861279",
    "end": "862480"
  },
  {
    "text": "algorithms in this context the",
    "start": "862480",
    "end": "865399"
  },
  {
    "text": "initialization involves setting up an",
    "start": "865399",
    "end": "867720"
  },
  {
    "text": "experience pool with a capacity of 300",
    "start": "867720",
    "end": "870959"
  },
  {
    "text": "entries as well as defining the Q",
    "start": "870959",
    "end": "873759"
  },
  {
    "text": "function through a neural network with",
    "start": "873759",
    "end": "876079"
  },
  {
    "text": "weight initialized to random values so",
    "start": "876079",
    "end": "878959"
  },
  {
    "text": "both of the neural networks got their",
    "start": "878959",
    "end": "880360"
  },
  {
    "text": "random weight",
    "start": "880360",
    "end": "881880"
  },
  {
    "text": "initialization the first phase of the",
    "start": "881880",
    "end": "883759"
  },
  {
    "text": "training algorithm focus on handling",
    "start": "883759",
    "end": "886519"
  },
  {
    "text": "real time scheduling request from the",
    "start": "886519",
    "end": "889000"
  },
  {
    "text": "kubernetes",
    "start": "889000",
    "end": "890079"
  },
  {
    "text": "scheduler like for each scheduling",
    "start": "890079",
    "end": "892440"
  },
  {
    "text": "request the model captures the current",
    "start": "892440",
    "end": "895399"
  },
  {
    "text": "cluster State compute Q values for the",
    "start": "895399",
    "end": "898519"
  },
  {
    "text": "all the post possible actions these Q",
    "start": "898519",
    "end": "901120"
  },
  {
    "text": "values represent the potential reward or",
    "start": "901120",
    "end": "904240"
  },
  {
    "text": "benefit for each action in relation to",
    "start": "904240",
    "end": "907000"
  },
  {
    "text": "the given State once the Q values are",
    "start": "907000",
    "end": "910120"
  },
  {
    "text": "calculated an Epsilon gitty algorithm is",
    "start": "910120",
    "end": "913000"
  },
  {
    "text": "applied to select the next action what",
    "start": "913000",
    "end": "916480"
  },
  {
    "text": "this algo does with a probability",
    "start": "916480",
    "end": "918839"
  },
  {
    "text": "Epsilon this algo will choose a action",
    "start": "918839",
    "end": "921639"
  },
  {
    "text": "with the highest Q value and then send",
    "start": "921639",
    "end": "924399"
  },
  {
    "text": "it to the Experience",
    "start": "924399",
    "end": "925759"
  },
  {
    "text": "Store now if the Experience Store is",
    "start": "925759",
    "end": "928600"
  },
  {
    "text": "full",
    "start": "928600",
    "end": "929600"
  },
  {
    "text": "the model will initiate training by",
    "start": "929600",
    "end": "932319"
  },
  {
    "text": "randomly sampling experiences from the",
    "start": "932319",
    "end": "934319"
  },
  {
    "text": "pool this sample serve as training data",
    "start": "934319",
    "end": "937319"
  },
  {
    "text": "for the neural network enabling it to",
    "start": "937319",
    "end": "939759"
  },
  {
    "text": "learn from the par scheduling decisions",
    "start": "939759",
    "end": "942079"
  },
  {
    "text": "and refine it Q value",
    "start": "942079",
    "end": "944360"
  },
  {
    "text": "predictions however if the pool is not",
    "start": "944360",
    "end": "947440"
  },
  {
    "text": "yet at capacity the model simply",
    "start": "947440",
    "end": "950319"
  },
  {
    "text": "continues to add new experiences without",
    "start": "950319",
    "end": "953399"
  },
  {
    "text": "initiate the",
    "start": "953399",
    "end": "956000"
  },
  {
    "text": "training so next we got the second part",
    "start": "957000",
    "end": "959680"
  },
  {
    "text": "of our model that is the DRS monitors so",
    "start": "959680",
    "end": "962759"
  },
  {
    "text": "this DRS monitor is responsible for",
    "start": "962759",
    "end": "965920"
  },
  {
    "text": "deploying monitoring agents across each",
    "start": "965920",
    "end": "968920"
  },
  {
    "text": "node that has got",
    "start": "968920",
    "end": "970800"
  },
  {
    "text": "gpus these monitoring agents are",
    "start": "970800",
    "end": "973639"
  },
  {
    "text": "implemented as demon sets ensuring that",
    "start": "973639",
    "end": "976839"
  },
  {
    "text": "a dedicated monitoring is available on",
    "start": "976839",
    "end": "979680"
  },
  {
    "text": "each of the GPU enabled node the DRS",
    "start": "979680",
    "end": "983120"
  },
  {
    "text": "agents utilize nvidia's data center GPU",
    "start": "983120",
    "end": "986759"
  },
  {
    "text": "manager dcgm to to facilate GPU",
    "start": "986759",
    "end": "990160"
  },
  {
    "text": "telemetric collection and monitor GPU",
    "start": "990160",
    "end": "992959"
  },
  {
    "text": "Health among the key matrics collected",
    "start": "992959",
    "end": "995839"
  },
  {
    "text": "so the metrics are shown on",
    "start": "995839",
    "end": "998639"
  },
  {
    "text": "the bottom left of the screen so among",
    "start": "998639",
    "end": "1002040"
  },
  {
    "text": "the key metrics are device memory",
    "start": "1002040",
    "end": "1004880"
  },
  {
    "text": "activity",
    "start": "1004880",
    "end": "1006839"
  },
  {
    "text": "which measures memory load and bandwidth",
    "start": "1006839",
    "end": "1010000"
  },
  {
    "text": "usage on the GPU GPU temperature which",
    "start": "1010000",
    "end": "1013079"
  },
  {
    "text": "is another critical indicator of",
    "start": "1013079",
    "end": "1015440"
  },
  {
    "text": "Hardware health and cooling efficiency",
    "start": "1015440",
    "end": "1019040"
  },
  {
    "text": "then you got the graphic engine activity",
    "start": "1019040",
    "end": "1021440"
  },
  {
    "text": "which reflect the utilization of the",
    "start": "1021440",
    "end": "1023440"
  },
  {
    "text": "gpus graphical processing resources and",
    "start": "1023440",
    "end": "1027038"
  },
  {
    "text": "buffer memory uses among others which",
    "start": "1027039",
    "end": "1029480"
  },
  {
    "text": "helps gge memory demand and",
    "start": "1029480",
    "end": "1033360"
  },
  {
    "text": "availability so once collected these GPU",
    "start": "1033360",
    "end": "1036240"
  },
  {
    "text": "metrics are stored in a Time series",
    "start": "1036240",
    "end": "1039079"
  },
  {
    "text": "database such as Prometheus which is",
    "start": "1039079",
    "end": "1042199"
  },
  {
    "text": "well suited for managing and quering",
    "start": "1042199",
    "end": "1044839"
  },
  {
    "text": "historical data in kubernetes",
    "start": "1044839",
    "end": "1046480"
  },
  {
    "text": "environments",
    "start": "1046480",
    "end": "1049480"
  },
  {
    "text": "so let's put it all together and come to",
    "start": "1049559",
    "end": "1053400"
  },
  {
    "text": "how we train and serve our model so as",
    "start": "1053400",
    "end": "1056320"
  },
  {
    "text": "you discussed earlier the collected",
    "start": "1056320",
    "end": "1059200"
  },
  {
    "text": "historical data in Prometheus is used to",
    "start": "1059200",
    "end": "1062320"
  },
  {
    "text": "create a simulated environment so we",
    "start": "1062320",
    "end": "1065080"
  },
  {
    "text": "train our agent with synthetic workload",
    "start": "1065080",
    "end": "1067520"
  },
  {
    "text": "that includes that historical data plus",
    "start": "1067520",
    "end": "1069559"
  },
  {
    "text": "some augmented data and this is trained",
    "start": "1069559",
    "end": "1072799"
  },
  {
    "text": "in this simulated environment before",
    "start": "1072799",
    "end": "1074840"
  },
  {
    "text": "deploying it in the",
    "start": "1074840",
    "end": "1076400"
  },
  {
    "text": "production so a hybrid approach is for",
    "start": "1076400",
    "end": "1078840"
  },
  {
    "text": "followed that is offline for initial",
    "start": "1078840",
    "end": "1080919"
  },
  {
    "text": "training and online for fine tuning and",
    "start": "1080919",
    "end": "1084120"
  },
  {
    "text": "this works quite",
    "start": "1084120",
    "end": "1085600"
  },
  {
    "text": "well so how decision making workflow",
    "start": "1085600",
    "end": "1088640"
  },
  {
    "text": "works",
    "start": "1088640",
    "end": "1089840"
  },
  {
    "text": "here so we implement the trend model in",
    "start": "1089840",
    "end": "1093039"
  },
  {
    "text": "a lightweight inference server for",
    "start": "1093039",
    "end": "1094799"
  },
  {
    "text": "example we can take tensorflow serving",
    "start": "1094799",
    "end": "1097880"
  },
  {
    "text": "to reduce",
    "start": "1097880",
    "end": "1100159"
  },
  {
    "text": "latency next you integrate the RL model",
    "start": "1100159",
    "end": "1103400"
  },
  {
    "text": "as an external scheduler plugin to the",
    "start": "1103400",
    "end": "1106039"
  },
  {
    "text": "kubernetes scheduler so what happens at",
    "start": "1106039",
    "end": "1109200"
  },
  {
    "text": "each scheduling event the external",
    "start": "1109200",
    "end": "1111240"
  },
  {
    "text": "scheduler would call the all agent",
    "start": "1111240",
    "end": "1113880"
  },
  {
    "text": "passing the current state and in return",
    "start": "1113880",
    "end": "1116520"
  },
  {
    "text": "receiv receiving a scheduling decision",
    "start": "1116520",
    "end": "1118360"
  },
  {
    "text": "as",
    "start": "1118360",
    "end": "1120600"
  },
  {
    "text": "action so in what ways using this RL",
    "start": "1121480",
    "end": "1124840"
  },
  {
    "text": "based GP scheduler could help so we have",
    "start": "1124840",
    "end": "1128280"
  },
  {
    "text": "identified four major areas where this",
    "start": "1128280",
    "end": "1131480"
  },
  {
    "text": "RL based scheduler could help first it",
    "start": "1131480",
    "end": "1135720"
  },
  {
    "text": "will help balance load and to avoid",
    "start": "1135720",
    "end": "1138919"
  },
  {
    "text": "overload by Distributing workloads",
    "start": "1138919",
    "end": "1141640"
  },
  {
    "text": "evenly across all the gpus in your",
    "start": "1141640",
    "end": "1145360"
  },
  {
    "text": "cluster next the RL scheduler can",
    "start": "1145360",
    "end": "1148720"
  },
  {
    "text": "provide support for mixed workloads as",
    "start": "1148720",
    "end": "1151760"
  },
  {
    "text": "it can easily learn to handle diverse",
    "start": "1151760",
    "end": "1154679"
  },
  {
    "text": "workload types further it can minimize",
    "start": "1154679",
    "end": "1158360"
  },
  {
    "text": "weight times and allocate job faster",
    "start": "1158360",
    "end": "1161880"
  },
  {
    "text": "resulting in reduce job completion time",
    "start": "1161880",
    "end": "1165360"
  },
  {
    "text": "finally the I policy can also",
    "start": "1165360",
    "end": "1168039"
  },
  {
    "text": "incorporate energy consumption metrics",
    "start": "1168039",
    "end": "1170919"
  },
  {
    "text": "which result in Energy Efficiency and in",
    "start": "1170919",
    "end": "1173760"
  },
  {
    "text": "result the cost",
    "start": "1173760",
    "end": "1175760"
  },
  {
    "text": "savings now let's explore that how the",
    "start": "1175760",
    "end": "1179000"
  },
  {
    "text": "rlb solution that we proposed can",
    "start": "1179000",
    "end": "1181799"
  },
  {
    "text": "enhance some key cncf projects first we",
    "start": "1181799",
    "end": "1185120"
  },
  {
    "text": "go on Argo Argo manages workflows with",
    "start": "1185120",
    "end": "1188120"
  },
  {
    "text": "Ds ARL will help dynamical task",
    "start": "1188120",
    "end": "1192480"
  },
  {
    "text": "prioritization and hence boost",
    "start": "1192480",
    "end": "1194559"
  },
  {
    "text": "throughput and scalability Cube flow",
    "start": "1194559",
    "end": "1197280"
  },
  {
    "text": "uses kubernetes native scheduling but RL",
    "start": "1197280",
    "end": "1200320"
  },
  {
    "text": "can enhance job scheduling hence",
    "start": "1200320",
    "end": "1202640"
  },
  {
    "text": "reducing the training times and improve",
    "start": "1202640",
    "end": "1205600"
  },
  {
    "text": "the pipeline efficiency native uses",
    "start": "1205600",
    "end": "1208600"
  },
  {
    "text": "demand-based Auto scaling but RL will",
    "start": "1208600",
    "end": "1211320"
  },
  {
    "text": "implement the predictive Auto scaling",
    "start": "1211320",
    "end": "1213679"
  },
  {
    "text": "that will lead to the better performance",
    "start": "1213679",
    "end": "1215720"
  },
  {
    "text": "and more responsive autoscaling in",
    "start": "1215720",
    "end": "1218440"
  },
  {
    "text": "Native now let's dive deep that how RL",
    "start": "1218440",
    "end": "1222280"
  },
  {
    "text": "based shed can be integrated with Cube",
    "start": "1222280",
    "end": "1224799"
  },
  {
    "text": "flow and enhance its overall performance",
    "start": "1224799",
    "end": "1229080"
  },
  {
    "text": "Cube flow pipelines often face GPU",
    "start": "1229080",
    "end": "1231280"
  },
  {
    "text": "bottlenecks when running concurrent ml",
    "start": "1231280",
    "end": "1233480"
  },
  {
    "text": "workloads RL driven DRS scheduler",
    "start": "1233480",
    "end": "1236799"
  },
  {
    "text": "address GPU assignments based on",
    "start": "1236799",
    "end": "1238880"
  },
  {
    "text": "realtime loads hence providing faster",
    "start": "1238880",
    "end": "1241880"
  },
  {
    "text": "execution of GPU intensive tasks",
    "start": "1241880",
    "end": "1244240"
  },
  {
    "text": "reducing overall workflow completion",
    "start": "1244240",
    "end": "1247280"
  },
  {
    "text": "time as you know KF serving is a key",
    "start": "1247280",
    "end": "1250559"
  },
  {
    "text": "component of cube flow that is designed",
    "start": "1250559",
    "end": "1253240"
  },
  {
    "text": "to handle endtoend flow of inference",
    "start": "1253240",
    "end": "1256159"
  },
  {
    "text": "requests for machine learning models in",
    "start": "1256159",
    "end": "1258480"
  },
  {
    "text": "the the production environment in",
    "start": "1258480",
    "end": "1260640"
  },
  {
    "text": "inference Services the demand for GPU",
    "start": "1260640",
    "end": "1263120"
  },
  {
    "text": "resources can vary widely this is based",
    "start": "1263120",
    "end": "1266200"
  },
  {
    "text": "on type of the user request with some",
    "start": "1266200",
    "end": "1268679"
  },
  {
    "text": "requests requiring very much power and",
    "start": "1268679",
    "end": "1271120"
  },
  {
    "text": "some requiring very less this is all due",
    "start": "1271120",
    "end": "1273960"
  },
  {
    "text": "to the difference in the nature of the",
    "start": "1273960",
    "end": "1275960"
  },
  {
    "text": "complexity of these requests to address",
    "start": "1275960",
    "end": "1279000"
  },
  {
    "text": "this RL based scheduling dynamically",
    "start": "1279000",
    "end": "1281440"
  },
  {
    "text": "allocates GPU resources based on",
    "start": "1281440",
    "end": "1284039"
  },
  {
    "text": "realtime demand ensuring that each",
    "start": "1284039",
    "end": "1287080"
  },
  {
    "text": "service gets the approp rate resource",
    "start": "1287080",
    "end": "1290080"
  },
  {
    "text": "during peak times the system predicts",
    "start": "1290080",
    "end": "1292559"
  },
  {
    "text": "workload patterns prioritizes critical",
    "start": "1292559",
    "end": "1295679"
  },
  {
    "text": "requests and minimizes resource",
    "start": "1295679",
    "end": "1298400"
  },
  {
    "text": "contention this reduces the latency",
    "start": "1298400",
    "end": "1301440"
  },
  {
    "text": "additionally the RL scheduler informs",
    "start": "1301440",
    "end": "1304320"
  },
  {
    "text": "autoscaling decisions optimizing GPU",
    "start": "1304320",
    "end": "1307360"
  },
  {
    "text": "resource distribution across replicas to",
    "start": "1307360",
    "end": "1310159"
  },
  {
    "text": "handle the traffic fluctuations",
    "start": "1310159",
    "end": "1312480"
  },
  {
    "text": "efficiently by continuously learning",
    "start": "1312480",
    "end": "1314720"
  },
  {
    "text": "from performance metrics the RL model",
    "start": "1314720",
    "end": "1317760"
  },
  {
    "text": "improves res Source utilization reduces",
    "start": "1317760",
    "end": "1320919"
  },
  {
    "text": "idle GPU time prevents over provisoning",
    "start": "1320919",
    "end": "1324240"
  },
  {
    "text": "and ultimately lowering the cost while",
    "start": "1324240",
    "end": "1327039"
  },
  {
    "text": "ensuring faster response times for these",
    "start": "1327039",
    "end": "1329840"
  },
  {
    "text": "realtime",
    "start": "1329840",
    "end": "1331960"
  },
  {
    "text": "applications finally we have the cutp in",
    "start": "1331960",
    "end": "1335679"
  },
  {
    "text": "Cube flow the model training also",
    "start": "1335679",
    "end": "1338000"
  },
  {
    "text": "includes hyperparameter tuning of chobs",
    "start": "1338000",
    "end": "1341600"
  },
  {
    "text": "and this generally generates multiple",
    "start": "1341600",
    "end": "1344400"
  },
  {
    "text": "experiments that can overwhelm the GPU",
    "start": "1344400",
    "end": "1346799"
  },
  {
    "text": "resources if not scheduled efficiently",
    "start": "1346799",
    "end": "1350400"
  },
  {
    "text": "the DRS scheduler learns to allocate GPU",
    "start": "1350400",
    "end": "1353240"
  },
  {
    "text": "resources based on the computational",
    "start": "1353240",
    "end": "1355279"
  },
  {
    "text": "needs of each cutab experiment hence the",
    "start": "1355279",
    "end": "1358480"
  },
  {
    "text": "cube flow benefits by receiving reduced",
    "start": "1358480",
    "end": "1362159"
  },
  {
    "text": "idle GPU time and faster exploration of",
    "start": "1362159",
    "end": "1365600"
  },
  {
    "text": "hyperparameters this all leads to a",
    "start": "1365600",
    "end": "1367760"
  },
  {
    "text": "quicker convergence in the model",
    "start": "1367760",
    "end": "1370279"
  },
  {
    "text": "optimization hence we see that RL can be",
    "start": "1370279",
    "end": "1373480"
  },
  {
    "text": "a big game changer in the landscape of",
    "start": "1373480",
    "end": "1375799"
  },
  {
    "text": "GPU scheduling for both the cube",
    "start": "1375799",
    "end": "1377960"
  },
  {
    "text": "scheduler and other projects and hence",
    "start": "1377960",
    "end": "1380559"
  },
  {
    "text": "we are up for the Q&A thank you",
    "start": "1380559",
    "end": "1384070"
  },
  {
    "text": "[Applause]",
    "start": "1384070",
    "end": "1389960"
  },
  {
    "text": "folks any questions",
    "start": "1398760",
    "end": "1402440"
  },
  {
    "text": "please hey thank you for the talk um I",
    "start": "1403720",
    "end": "1406480"
  },
  {
    "text": "just had one question um something I've",
    "start": "1406480",
    "end": "1409279"
  },
  {
    "text": "really run into when messing around with",
    "start": "1409279",
    "end": "1411480"
  },
  {
    "text": "custom schedulers on a shared use",
    "start": "1411480",
    "end": "1413760"
  },
  {
    "text": "cluster is that users can get quite",
    "start": "1413760",
    "end": "1416720"
  },
  {
    "text": "interested in why their jobs didn't get",
    "start": "1416720",
    "end": "1418240"
  },
  {
    "text": "scheduled or did get scheduled um you",
    "start": "1418240",
    "end": "1420760"
  },
  {
    "text": "know when it's the thing stopping them",
    "start": "1420760",
    "end": "1422360"
  },
  {
    "text": "from being able to run their experiment",
    "start": "1422360",
    "end": "1424480"
  },
  {
    "text": "and train a new model they can be yeah",
    "start": "1424480",
    "end": "1426200"
  },
  {
    "text": "quite interested in exactly why a",
    "start": "1426200",
    "end": "1428000"
  },
  {
    "text": "scheduling decision was made um do you",
    "start": "1428000",
    "end": "1430840"
  },
  {
    "text": "think that using like kind of blackbox",
    "start": "1430840",
    "end": "1434080"
  },
  {
    "text": "methods like reinforcement learning",
    "start": "1434080",
    "end": "1435960"
  },
  {
    "text": "would like impact that do you think that",
    "start": "1435960",
    "end": "1437240"
  },
  {
    "text": "would be a problem or is that not",
    "start": "1437240",
    "end": "1438960"
  },
  {
    "text": "something you guys think that would be",
    "start": "1438960",
    "end": "1441000"
  },
  {
    "text": "not an issue you think would be run into",
    "start": "1441000",
    "end": "1443520"
  },
  {
    "text": "so basically uh so as you discussed so",
    "start": "1443520",
    "end": "1446480"
  },
  {
    "text": "that what this RL can do in your",
    "start": "1446480",
    "end": "1449520"
  },
  {
    "text": "scenario is you can tune that specific",
    "start": "1449520",
    "end": "1453360"
  },
  {
    "text": "reward function so reward function is a",
    "start": "1453360",
    "end": "1455440"
  },
  {
    "text": "totally customizable function so if I",
    "start": "1455440",
    "end": "1457520"
  },
  {
    "text": "need to tune down parameter 1 tune up",
    "start": "1457520",
    "end": "1459480"
  },
  {
    "text": "the parameter 10 so you just code out",
    "start": "1459480",
    "end": "1462000"
  },
  {
    "text": "the relevant reward function and it will",
    "start": "1462000",
    "end": "1464679"
  },
  {
    "text": "act",
    "start": "1464679",
    "end": "1465480"
  },
  {
    "text": "accordingly so it's just like you put",
    "start": "1465480",
    "end": "1468200"
  },
  {
    "text": "out your own reward function and then do",
    "start": "1468200",
    "end": "1470159"
  },
  {
    "text": "your",
    "start": "1470159",
    "end": "1471600"
  },
  {
    "text": "job thank",
    "start": "1471600",
    "end": "1474799"
  },
  {
    "text": "you hi a quick question um so how do you",
    "start": "1478440",
    "end": "1482279"
  },
  {
    "text": "distinguish between a short uh um",
    "start": "1482279",
    "end": "1486679"
  },
  {
    "text": "short-term running jobs and longterm up",
    "start": "1486679",
    "end": "1489919"
  },
  {
    "text": "uh",
    "start": "1489919",
    "end": "1491000"
  },
  {
    "text": "upfront if um so in your presentation",
    "start": "1491000",
    "end": "1495480"
  },
  {
    "text": "you said that long uh long running jobs",
    "start": "1495480",
    "end": "1497919"
  },
  {
    "text": "could",
    "start": "1497919",
    "end": "1498880"
  },
  {
    "text": "um uh create kind of starvation",
    "start": "1498880",
    "end": "1501520"
  },
  {
    "text": "scenarios for short uh short jobs so how",
    "start": "1501520",
    "end": "1504679"
  },
  {
    "text": "do you distinguish that so it's not",
    "start": "1504679",
    "end": "1507279"
  },
  {
    "text": "about uh differentiating between the",
    "start": "1507279",
    "end": "1509200"
  },
  {
    "text": "short-term jobs and the long-term jobs",
    "start": "1509200",
    "end": "1511919"
  },
  {
    "text": "so like you consider two different",
    "start": "1511919",
    "end": "1513880"
  },
  {
    "text": "scenarios in which the scenario one the",
    "start": "1513880",
    "end": "1517000"
  },
  {
    "text": "long-term job it just hangs out the",
    "start": "1517000",
    "end": "1519240"
  },
  {
    "text": "system for",
    "start": "1519240",
    "end": "1520559"
  },
  {
    "text": "and all the other jobs are exhausted so",
    "start": "1520559",
    "end": "1525279"
  },
  {
    "text": "none of them get to schedule on a GPU",
    "start": "1525279",
    "end": "1527640"
  },
  {
    "text": "and in scenario to you got a critical",
    "start": "1527640",
    "end": "1530440"
  },
  {
    "text": "long-term job which is pending since",
    "start": "1530440",
    "end": "1532360"
  },
  {
    "text": "other short-term jobs are getting",
    "start": "1532360",
    "end": "1533520"
  },
  {
    "text": "scheduled continuously so in this like",
    "start": "1533520",
    "end": "1536600"
  },
  {
    "text": "it's a loss loss situation so what Ariel",
    "start": "1536600",
    "end": "1539399"
  },
  {
    "text": "can do in this scenario is like you",
    "start": "1539399",
    "end": "1541480"
  },
  {
    "text": "calculate the loss one so one is minus",
    "start": "1541480",
    "end": "1543279"
  },
  {
    "text": "10 and another is- so you got to choose",
    "start": "1543279",
    "end": "1546120"
  },
  {
    "text": "which is less harmful for you so if like",
    "start": "1546120",
    "end": "1549520"
  },
  {
    "text": "if you are okay with a long-term what",
    "start": "1549520",
    "end": "1551880"
  },
  {
    "text": "critical job hanging out all other jobs",
    "start": "1551880",
    "end": "1554440"
  },
  {
    "text": "that is okay so we like we don't",
    "start": "1554440",
    "end": "1556640"
  },
  {
    "text": "distinguish between the short-term jobs",
    "start": "1556640",
    "end": "1558279"
  },
  {
    "text": "and long-term jobs It ultimately like",
    "start": "1558279",
    "end": "1560240"
  },
  {
    "text": "scheduling which one of them results in",
    "start": "1560240",
    "end": "1562919"
  },
  {
    "text": "more benefit for entire scheduling",
    "start": "1562919",
    "end": "1566120"
  },
  {
    "text": "activity yeah just to add on like it's",
    "start": "1566120",
    "end": "1569600"
  },
  {
    "text": "uh about the complete system performance",
    "start": "1569600",
    "end": "1572080"
  },
  {
    "text": "it's not like we will prioritize on the",
    "start": "1572080",
    "end": "1574279"
  },
  {
    "text": "longer jobs or the shorter jobs RL will",
    "start": "1574279",
    "end": "1577200"
  },
  {
    "text": "adjust itself accordingly and",
    "start": "1577200",
    "end": "1579799"
  },
  {
    "text": "automatically and will create a balance",
    "start": "1579799",
    "end": "1582120"
  },
  {
    "text": "for the efficiency of the complete",
    "start": "1582120",
    "end": "1584200"
  },
  {
    "text": "system and not deprioritizing any one of",
    "start": "1584200",
    "end": "1586880"
  },
  {
    "text": "them",
    "start": "1586880",
    "end": "1589679"
  },
  {
    "text": "um like I hope that answers your",
    "start": "1589679",
    "end": "1591200"
  },
  {
    "text": "question thank",
    "start": "1591200",
    "end": "1593679"
  },
  {
    "text": "you uh thank you Aditi and nikun um I",
    "start": "1593679",
    "end": "1597240"
  },
  {
    "text": "had a question based on what was asked",
    "start": "1597240",
    "end": "1600279"
  },
  {
    "text": "before uh deterministic and",
    "start": "1600279",
    "end": "1602279"
  },
  {
    "text": "non-deterministic scheduling so um I",
    "start": "1602279",
    "end": "1605480"
  },
  {
    "text": "think one of the colleague highlighted",
    "start": "1605480",
    "end": "1606799"
  },
  {
    "text": "this would be non-deterministic which",
    "start": "1606799",
    "end": "1609399"
  },
  {
    "text": "it's uh reinforcement based learning so",
    "start": "1609399",
    "end": "1613159"
  },
  {
    "text": "do you have any benchmarking uh to",
    "start": "1613159",
    "end": "1615120"
  },
  {
    "text": "support that this would be",
    "start": "1615120",
    "end": "1616600"
  },
  {
    "text": "beneficial So currently we haven't uh so",
    "start": "1616600",
    "end": "1620640"
  },
  {
    "text": "I haven't come across any of the metrics",
    "start": "1620640",
    "end": "1623600"
  },
  {
    "text": "which uh takes in account into non dat",
    "start": "1623600",
    "end": "1626279"
  },
  {
    "text": "minist scheduling so I guess that is an",
    "start": "1626279",
    "end": "1628240"
  },
  {
    "text": "open new okay thank you and one more",
    "start": "1628240",
    "end": "1630640"
  },
  {
    "text": "question uh I think there's been this",
    "start": "1630640",
    "end": "1633000"
  },
  {
    "text": "theme of Dr I think which also targets a",
    "start": "1633000",
    "end": "1636200"
  },
  {
    "text": "similar solution so um are you guys also",
    "start": "1636200",
    "end": "1640159"
  },
  {
    "text": "planning to do a benchmarking against",
    "start": "1640159",
    "end": "1642200"
  },
  {
    "text": "that once that gets GA because that",
    "start": "1642200",
    "end": "1645279"
  },
  {
    "text": "would be a solution which targets",
    "start": "1645279",
    "end": "1646760"
  },
  {
    "text": "towards GPU optimization as in",
    "start": "1646760",
    "end": "1649039"
  },
  {
    "text": "scheduling optimization and usage op",
    "start": "1649039",
    "end": "1651840"
  },
  {
    "text": "optimization yeah I guess we can Target",
    "start": "1651840",
    "end": "1653840"
  },
  {
    "text": "on that so I'm not aware of the details",
    "start": "1653840",
    "end": "1657000"
  },
  {
    "text": "about that sure but I guess we can go",
    "start": "1657000",
    "end": "1659320"
  },
  {
    "text": "offline if need to discuss for perfect",
    "start": "1659320",
    "end": "1661240"
  },
  {
    "text": "thank you thank you so much appreciate",
    "start": "1661240",
    "end": "1665039"
  }
]
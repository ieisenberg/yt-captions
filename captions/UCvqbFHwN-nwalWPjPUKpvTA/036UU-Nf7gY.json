[
  {
    "text": "all right so before I get started um I want to actually give a couple of shout outs to a couple of people so um",
    "start": "1140",
    "end": "8220"
  },
  {
    "text": "if you checked out the schedule before basically yesterday uh you may have noticed that I wasn't originally on the",
    "start": "8220",
    "end": "14280"
  },
  {
    "text": "schedule so first of all um originally my colleague Samara was going",
    "start": "14280",
    "end": "20220"
  },
  {
    "text": "to give it but for health reasons she couldn't show up she's okay but she couldn't travel",
    "start": "20220",
    "end": "25740"
  },
  {
    "text": "um and then secondly uh thank you to Ganesh and Ruslan for agreeing to swap",
    "start": "25740",
    "end": "32820"
  },
  {
    "text": "their slots last minute as well so do check out their their talk",
    "start": "32820",
    "end": "38219"
  },
  {
    "text": "um they gave the talk today at 10 50 in the morning so thanks to everyone for",
    "start": "38219",
    "end": "43620"
  },
  {
    "text": "all of your flexibility uh so that we could uh end up giving this talk all right so as uh bartek already said",
    "start": "43620",
    "end": "51539"
  },
  {
    "text": "uh we've already heard about profiling a couple of times today we've talked about",
    "start": "51539",
    "end": "57000"
  },
  {
    "text": "you know extending open Telemetry um to have a standard for profiling and",
    "start": "57000",
    "end": "62219"
  },
  {
    "text": "hopefully today I'm going to be able to give you kind of an at least a little bit of an Insight of what formats are",
    "start": "62219",
    "end": "68280"
  },
  {
    "text": "there um the kind of different trade-offs that different formats have chosen to implement",
    "start": "68280",
    "end": "74280"
  },
  {
    "text": "and what I think could be an interesting format for the kind of profiling that",
    "start": "74280",
    "end": "81180"
  },
  {
    "text": "we're seeing in this you know new Cloud native era because I think it does differ a little bit from what we've seen",
    "start": "81180",
    "end": "87240"
  },
  {
    "text": "traditionally so before we get started on on format uh maybe a show of hands",
    "start": "87240",
    "end": "92700"
  },
  {
    "text": "who here knows what profiling is and has used profilers before",
    "start": "92700",
    "end": "97979"
  },
  {
    "text": "all right that's that's a good 70 60 of the room um how many of you know how profilers",
    "start": "97979",
    "end": "104820"
  },
  {
    "text": "work okay that's considerably less",
    "start": "104820",
    "end": "110159"
  },
  {
    "text": "um and then last but not least um who here had has an understanding of",
    "start": "110159",
    "end": "115320"
  },
  {
    "text": "uh you know how profilers actually persist the the data that they that they",
    "start": "115320",
    "end": "120659"
  },
  {
    "text": "obtain all right cool so hopefully after this talk um pretty much all hands are going to be",
    "start": "120659",
    "end": "127380"
  },
  {
    "text": "able to go up for all of those questions so without further Ado uh profiling",
    "start": "127380",
    "end": "133319"
  },
  {
    "text": "what's what is profiling profiling is really uh as old as software engineering itself is because with profiling what",
    "start": "133319",
    "end": "141480"
  },
  {
    "text": "profiling allows us to do is understand where resources of our software are",
    "start": "141480",
    "end": "147360"
  },
  {
    "text": "being spent so when our program is running what pieces of code are using CPU what",
    "start": "147360",
    "end": "153540"
  },
  {
    "text": "pieces of code are using memory what is allocating memory what is holding memory",
    "start": "153540",
    "end": "159420"
  },
  {
    "text": "all of these kinds of things in order for us to be able to improve it right if",
    "start": "159420",
    "end": "165000"
  },
  {
    "text": "we don't have the data of what code is actually causing a lot of CPU time what",
    "start": "165000",
    "end": "170160"
  },
  {
    "text": "code is causing a lot of allocations what code is holding a lot of Heap",
    "start": "170160",
    "end": "175620"
  },
  {
    "text": "memory for example we're not we're in no place to fix that right best case",
    "start": "175620",
    "end": "181260"
  },
  {
    "text": "scenario we would kind of be like poking poking in the dark and maybe because we know our code base really well maybe we",
    "start": "181260",
    "end": "188040"
  },
  {
    "text": "can make good changes but really with data we're so much more more efficient so that's kind of the why",
    "start": "188040",
    "end": "194720"
  },
  {
    "text": "we want to improve the performance of code and ultimately that could have",
    "start": "194720",
    "end": "200580"
  },
  {
    "text": "other effects as well right it could be because we're not now doing the same task with less CPU for example that",
    "start": "200580",
    "end": "208560"
  },
  {
    "text": "could mean that we're spending less money on our infrastructure today we actually heard several times how do we",
    "start": "208560",
    "end": "214260"
  },
  {
    "text": "reduce cost of our observability infrastructure right and my two of my",
    "start": "214260",
    "end": "220860"
  },
  {
    "text": "colleagues actually recently did a live stream where they showed how to identify uh kind of metrics that were being",
    "start": "220860",
    "end": "228920"
  },
  {
    "text": "produced on Hardware components that their cluster didn't even have right so we",
    "start": "228920",
    "end": "235140"
  },
  {
    "text": "were spending a ton of CPU Cycles on something that just fundamentally didn't make any sense and we were able to see",
    "start": "235140",
    "end": "240659"
  },
  {
    "text": "that using profiling data um so using profiling we can improve",
    "start": "240659",
    "end": "248480"
  },
  {
    "text": "CPU we can improve memory usage we can pick just about uh improve on just about",
    "start": "248480",
    "end": "254939"
  },
  {
    "text": "any Dimension and fundamentally what profiling data is is we're taking a",
    "start": "254939",
    "end": "262019"
  },
  {
    "text": "function call stack and we're assigning a number to it in essence that is all that profiling data is and so I want to",
    "start": "262019",
    "end": "270540"
  },
  {
    "text": "take a kind of two main categories of private profilers",
    "start": "270540",
    "end": "276000"
  },
  {
    "text": "but primarily speak about one and so I'm going to get the one out of the way that I'm not going to speak about much today",
    "start": "276000",
    "end": "281520"
  },
  {
    "text": "which is tracing profiling tracing profiling is essentially we're we're truly recording",
    "start": "281520",
    "end": "287100"
  },
  {
    "text": "um at a very very granular level when does function a um start when does function end when uh does this other",
    "start": "287100",
    "end": "294120"
  },
  {
    "text": "function start and so on right like we're actually tracing the program execution and so this is useful but",
    "start": "294120",
    "end": "299940"
  },
  {
    "text": "generally speaking this is not done very much in production because it has a very very very high cost",
    "start": "299940",
    "end": "305520"
  },
  {
    "text": "and so typically in production we use sampling profilers and so what that",
    "start": "305520",
    "end": "310919"
  },
  {
    "text": "essentially means and I'm going to specifically talk most about CPU profiling because that's the one where",
    "start": "310919",
    "end": "316740"
  },
  {
    "text": "we tend to get the most gains the way that sampling CPU profilers work",
    "start": "316740",
    "end": "322560"
  },
  {
    "text": "is we truly just let's say 100 times per second look at what is the current",
    "start": "322560",
    "end": "327840"
  },
  {
    "text": "function call stack right so 100 times per second we're recording this and if we're seeing the same function call",
    "start": "327840",
    "end": "334080"
  },
  {
    "text": "stack multiple times we just count up by one and we can use this data then to",
    "start": "334080",
    "end": "340199"
  },
  {
    "text": "kind of build statistics to see where is that CPU time being spent because if we",
    "start": "340199",
    "end": "345240"
  },
  {
    "text": "see the same function call stack multiple times that must mean at least statistically speaking that's where",
    "start": "345240",
    "end": "351000"
  },
  {
    "text": "we're spending our time and most sampling profilers use something in",
    "start": "351000",
    "end": "357120"
  },
  {
    "text": "the range of five to ten percent overhead if you use the right techniques and I'm going to talk about that later",
    "start": "357120",
    "end": "362820"
  },
  {
    "text": "you can get it as low as 0.2 percent but these are um kind of sampling profilers where",
    "start": "362820",
    "end": "370020"
  },
  {
    "text": "we're profiling let's say at a hundred thousand at 10 000 Hertz so we are collecting 10 000 samples per second we",
    "start": "370020",
    "end": "378419"
  },
  {
    "text": "can considerably get this overhead down using a couple of techniques but we'll talk about that later",
    "start": "378419",
    "end": "385759"
  },
  {
    "text": "all right so um I have a a very small piece of example",
    "start": "387419",
    "end": "393720"
  },
  {
    "text": "code here so first we're going to have a function called iterate long which has just a for Loop that iterates 10 billion",
    "start": "393720",
    "end": "402120"
  },
  {
    "text": "times and just doesn't do anything We're just trying to produce some CPU time right and then we have the same function",
    "start": "402120",
    "end": "408240"
  },
  {
    "text": "that does the same thing but with one billion iterations and so I made up",
    "start": "408240",
    "end": "413880"
  },
  {
    "text": "these numbers but the point being the second the iterate short takes one",
    "start": "413880",
    "end": "420960"
  },
  {
    "text": "tenth of the first execution right so we have 20 samples that we observed for the long and two",
    "start": "420960",
    "end": "429000"
  },
  {
    "text": "for the short and what we're actually seeing on the left side sorry on the right hand side here is our first format",
    "start": "429000",
    "end": "435720"
  },
  {
    "text": "is called folded Stacks I think I'd consider this to be probably the simplest format out there it's a very",
    "start": "435720",
    "end": "442620"
  },
  {
    "text": "human readable one but as we'll see later it also has a lot of kind of shortcomings so let's talk about formats",
    "start": "442620",
    "end": "450060"
  },
  {
    "text": "now that we have kind of a simple understanding of what profilers are what",
    "start": "450060",
    "end": "455520"
  },
  {
    "text": "kind of formats and what formats you know at least in spirit represent how",
    "start": "455520",
    "end": "461099"
  },
  {
    "text": "are what are some very concrete implementations of these formats look like and one that I particularly like",
    "start": "461099",
    "end": "468120"
  },
  {
    "text": "and I think is very very widespread especially in the cloud native ecosystem because the go runtime natively",
    "start": "468120",
    "end": "475620"
  },
  {
    "text": "implements profilers that produce profiling data in the prep format so",
    "start": "475620",
    "end": "481440"
  },
  {
    "text": "that's the first one that I want to talk about today um people have kind of descends out of",
    "start": "481440",
    "end": "487440"
  },
  {
    "text": "uh what is generally referred to as the Google Performance Tool Suite um this kind of went through a couple of",
    "start": "487440",
    "end": "493080"
  },
  {
    "text": "iterations until Google eventually published this work um and P Prof uh is protobuf as so many",
    "start": "493080",
    "end": "502500"
  },
  {
    "text": "things in in Google and this is a relatively my slides look different",
    "start": "502500",
    "end": "510240"
  },
  {
    "text": "even though it's mirrored okay",
    "start": "510240",
    "end": "515279"
  },
  {
    "text": "weird um so in essence what P Prof is is it's a list of samples",
    "start": "515279",
    "end": "522719"
  },
  {
    "text": "the sample and we'll look at this in more detail in a second the sample is just a stack trace and a value right",
    "start": "522719",
    "end": "530580"
  },
  {
    "text": "like a a recurring theme that we'll see throughout this talk as I said that's truly the essence of what profiling data",
    "start": "530580",
    "end": "537899"
  },
  {
    "text": "is we have a stack trace an attached a sample to it what the meaning of that sample is depends on the profiling data",
    "start": "537899",
    "end": "544740"
  },
  {
    "text": "right it can be CPU time it can be allocations it can be Heap memory held",
    "start": "544740",
    "end": "551519"
  },
  {
    "text": "it can be a lot of things right whenever we can make an association between a cost function call stack and the value",
    "start": "551519",
    "end": "558240"
  },
  {
    "text": "it can be put into profiling data and used and profiling tools can be used to",
    "start": "558240",
    "end": "563519"
  },
  {
    "text": "analyze this data um so these are the kind of four main components I think of uh people there's",
    "start": "563519",
    "end": "570779"
  },
  {
    "text": "a bunch more metadata but I think this is the core so we have samples stack traces and values mappings and we'll go",
    "start": "570779",
    "end": "578880"
  },
  {
    "text": "into mappings uh first um in the next step we have locations so",
    "start": "578880",
    "end": "586440"
  },
  {
    "text": "these are kind of an abstraction for function call frames and we'll look at that in a second as well and then",
    "start": "586440",
    "end": "594000"
  },
  {
    "text": "um just functions uh that's function name uh line numbers",
    "start": "594000",
    "end": "600180"
  },
  {
    "text": "um file names and so on so mappings I think the reason why I",
    "start": "600180",
    "end": "607019"
  },
  {
    "text": "wanted to specifically call out mappings was because when I was very new to all",
    "start": "607019",
    "end": "612540"
  },
  {
    "text": "of this this was the one that kind of confused me the most because why like what does this even mean right like what",
    "start": "612540",
    "end": "618899"
  },
  {
    "text": "what is it talking about address ranges file offsets file name build ID what's",
    "start": "618899",
    "end": "624000"
  },
  {
    "text": "even a build ID so I want to give you a very very quick uh demo of what this",
    "start": "624000",
    "end": "629820"
  },
  {
    "text": "actually is and I'm on a Mac so I actually had to ask a co-worker who is",
    "start": "629820",
    "end": "636060"
  },
  {
    "text": "on Linux to actually provide this for me because what this is is typically when we I hope every everybody can see this",
    "start": "636060",
    "end": "643260"
  },
  {
    "text": "but oh oops when we're on a Linux system uh the way",
    "start": "643260",
    "end": "649019"
  },
  {
    "text": "a program executes is set up to execute code is the operating system kind of",
    "start": "649019",
    "end": "654959"
  },
  {
    "text": "memory Max maps the executable code to be executed and the mappings file which",
    "start": "654959",
    "end": "661680"
  },
  {
    "text": "you can find kind of in this scheme proc PID maps on any kind of Linux system",
    "start": "661680",
    "end": "668160"
  },
  {
    "text": "will tell you which kind of object code is mapped into which address space",
    "start": "668160",
    "end": "676440"
  },
  {
    "text": "and that's essentially what these mappings mean in P Prof it tells us so",
    "start": "676440",
    "end": "681720"
  },
  {
    "text": "here what we have here is um a the memory mappings of systemd we",
    "start": "681720",
    "end": "687839"
  },
  {
    "text": "just happen to choose that because you know pit one of that machine so we can see uh Lipsy as Mount is memory mapped",
    "start": "687839",
    "end": "695160"
  },
  {
    "text": "here and a bunch of other libraries that are just happen to be used by systemd",
    "start": "695160",
    "end": "700519"
  },
  {
    "text": "why do we need this right and where did the build ID come from so the build ID",
    "start": "700519",
    "end": "707579"
  },
  {
    "text": "um and I have another quick demo here is something pretty interesting that is",
    "start": "707579",
    "end": "713279"
  },
  {
    "text": "kind of an identifier for binaries and so what pprof is saying",
    "start": "713279",
    "end": "718920"
  },
  {
    "text": "whenever there's an address in this address space look at this binary with",
    "start": "718920",
    "end": "724019"
  },
  {
    "text": "this build ID to figure out what an address space means so I have a the",
    "start": "724019",
    "end": "733560"
  },
  {
    "text": "code that we were looking at earlier here right and I compiled this",
    "start": "733560",
    "end": "739200"
  },
  {
    "text": "and what we can then do using some standard tooling",
    "start": "739200",
    "end": "745260"
  },
  {
    "text": "is I mean I hope everybody can see this but if not um basically there's a tool called Adder",
    "start": "745260",
    "end": "752040"
  },
  {
    "text": "to line where you can say you know pass this executable and an address and then",
    "start": "752040",
    "end": "758760"
  },
  {
    "text": "it can tell us which files this um",
    "start": "758760",
    "end": "763860"
  },
  {
    "text": "this function name belongs to the function name and in this case we're actually seeing multiple functions and",
    "start": "763860",
    "end": "769320"
  },
  {
    "text": "what this means is that the compiler made a specific optimization called inlining where it decided setting up an",
    "start": "769320",
    "end": "777000"
  },
  {
    "text": "additional function call is actually too expensive we're just going to do all this in one function that's the short",
    "start": "777000",
    "end": "783240"
  },
  {
    "text": "story um but that's what mappings are about so that we can do the translation of an",
    "start": "783240",
    "end": "790860"
  },
  {
    "text": "address into actually something that we humans understand right and in the",
    "start": "790860",
    "end": "796200"
  },
  {
    "text": "folded folded Stacks that's not really something that we can communicate right the only thing that we could do with",
    "start": "796200",
    "end": "801480"
  },
  {
    "text": "solid Stacks were strings and so here we already see kind of an a difference",
    "start": "801480",
    "end": "806880"
  },
  {
    "text": "between P Prof and folded Stacks prep is obviously kind of designed to be able to",
    "start": "806880",
    "end": "812339"
  },
  {
    "text": "support what we call a synchronous symbolization so next components of P Prof uh the",
    "start": "812339",
    "end": "820380"
  },
  {
    "text": "sample like I said truly the sample is only a list of locations remember I said",
    "start": "820380",
    "end": "825779"
  },
  {
    "text": "locations are kind of an abstraction over function call frames and what we're",
    "start": "825779",
    "end": "831180"
  },
  {
    "text": "seeing now is a location can be what a location can be is just an",
    "start": "831180",
    "end": "836820"
  },
  {
    "text": "address right it just has an address and a mapping ID that is a possibility for",
    "start": "836820",
    "end": "842040"
  },
  {
    "text": "for a location so we don't have to have the symbols available in the pprof",
    "start": "842040",
    "end": "847220"
  },
  {
    "text": "formatted profile that can actually happen at analysis time and this can save a ton of information a kind of a",
    "start": "847220",
    "end": "855060"
  },
  {
    "text": "ton of you know space in storage or data that",
    "start": "855060",
    "end": "861000"
  },
  {
    "text": "needs to be transferred and so on so again sample is all our sample is is",
    "start": "861000",
    "end": "868200"
  },
  {
    "text": "a function call stack which happens to be an abstraction",
    "start": "868200",
    "end": "873300"
  },
  {
    "text": "mapped to a value so um",
    "start": "873300",
    "end": "879120"
  },
  {
    "text": "what I wanted to show here is so I did I took the kind of folded stack Trace that",
    "start": "879120",
    "end": "886260"
  },
  {
    "text": "we had earlier and I converted it to a p profile using a tool created by someone",
    "start": "886260",
    "end": "893940"
  },
  {
    "text": "in the community shout out to Felix for creating it and what I wanted to do is uh kind of",
    "start": "893940",
    "end": "901680"
  },
  {
    "text": "show this people have this exactly the same excuse me um exactly the same data",
    "start": "901680",
    "end": "908100"
  },
  {
    "text": "that we had as the folded Stacks now in P Prof and what we can already see",
    "start": "908100",
    "end": "914160"
  },
  {
    "text": "um is that this data is much more kind of complex right but it comes at a",
    "start": "914160",
    "end": "920639"
  },
  {
    "text": "trade-off right the folded Stacks were very very easy for us as humans to understand however P Prof is able to",
    "start": "920639",
    "end": "927660"
  },
  {
    "text": "represent much more complex situations and be much more efficient in doing that the first thing that we'll see on the",
    "start": "927660",
    "end": "934440"
  },
  {
    "text": "right hand side here is that P Prof actually makes a very great attempt at deduplicating as much information as",
    "start": "934440",
    "end": "940740"
  },
  {
    "text": "possible so it has a string table it tries to deduplicate locations as much as possible and therefore kind of try to",
    "start": "940740",
    "end": "948360"
  },
  {
    "text": "save as much space as possible so we we see the string table and whenever we see a number for example in",
    "start": "948360",
    "end": "956820"
  },
  {
    "text": "the uh in the function names um we just see um a reference into this string table so",
    "start": "956820",
    "end": "963540"
  },
  {
    "text": "in this case you know uh zero one two three four five six so the last function",
    "start": "963540",
    "end": "969360"
  },
  {
    "text": "that we have here is the iterate short function right so all I'm trying to say is this is a binary format and it's able",
    "start": "969360",
    "end": "975480"
  },
  {
    "text": "to represent a lot of very complex uh situations that may be interesting to",
    "start": "975480",
    "end": "981360"
  },
  {
    "text": "handle um all right so that was the uh P Prof",
    "start": "981360",
    "end": "987000"
  },
  {
    "text": "demo the next format that I want to talk about um is speed scope",
    "start": "987000",
    "end": "992339"
  },
  {
    "text": "um speed scope um I specifically wanted to cover because",
    "start": "992339",
    "end": "997740"
  },
  {
    "text": "um it is able to not just um kind of map a single stack Trace to a",
    "start": "997740",
    "end": "1003980"
  },
  {
    "text": "single value it's actually able to also say kind of the relationship over time",
    "start": "1003980",
    "end": "1009380"
  },
  {
    "text": "and so it can tell us um not just you know over these 10 seconds there were two seconds spent in",
    "start": "1009380",
    "end": "1016220"
  },
  {
    "text": "function X Y it can also tell us it was actually called First add time T1 and",
    "start": "1016220",
    "end": "1024678"
  },
  {
    "text": "terminated at T2 but it was again called at T25 right like it doesn't really",
    "start": "1024679",
    "end": "1030918"
  },
  {
    "text": "matter the point is that it can not it just doesn't doesn't just have an aggregate view of the data it can also",
    "start": "1030919",
    "end": "1037040"
  },
  {
    "text": "tell us about the timeline of it and so [Music] um the way that this format I don't know",
    "start": "1037040",
    "end": "1043760"
  },
  {
    "text": "what this is doing this okay if I go forward and backward I see",
    "start": "1043760",
    "end": "1049580"
  },
  {
    "text": "everything on the uh slide again anyway what we're seeing is that",
    "start": "1049580",
    "end": "1056780"
  },
  {
    "text": "um the in the shared kind of section of the specification and by the way I specifically chose P Prof and speed",
    "start": "1056780",
    "end": "1063740"
  },
  {
    "text": "scope because they actually have specifications there are a lot more profiling formats out there but many of",
    "start": "1063740",
    "end": "1070460"
  },
  {
    "text": "them you know the implementation is the specification so I wanted to specifically take two that have an",
    "start": "1070460",
    "end": "1076820"
  },
  {
    "text": "actual specification and so in speed scope you can Define frames so the same",
    "start": "1076820",
    "end": "1083179"
  },
  {
    "text": "same thing as we saw in P Prof but not quite as optimized it doesn't have a string table or something like that so",
    "start": "1083179",
    "end": "1088640"
  },
  {
    "text": "it's somewhere somewhere in between right it's saying okay frame one is our",
    "start": "1088640",
    "end": "1093740"
  },
  {
    "text": "let's take our example of the main function frame two is the iterate",
    "start": "1093740",
    "end": "1098840"
  },
  {
    "text": "function frame three the iterate long and frame four the iterate short function for example and then you can",
    "start": "1098840",
    "end": "1105919"
  },
  {
    "text": "Define these profiles as evented or sampled and this is exactly the",
    "start": "1105919",
    "end": "1111799"
  },
  {
    "text": "difference that I wanted to show so the sample profile um speed scope essentially it's very",
    "start": "1111799",
    "end": "1118220"
  },
  {
    "text": "similar to P Prof there it only shows us the aggregate aggregate view across the entire timeline",
    "start": "1118220",
    "end": "1124880"
  },
  {
    "text": "so this is really exactly the same thing right like we have a sample stack that is just number uh numbers into the frame",
    "start": "1124880",
    "end": "1133460"
  },
  {
    "text": "um array so this is you know different representation but in essence kind of the same thing as P Prof however it does",
    "start": "1133460",
    "end": "1142220"
  },
  {
    "text": "not save the address space it does not save um you know addresses and so on so it",
    "start": "1142220",
    "end": "1147679"
  },
  {
    "text": "does not support a synchronous stabilization so therefore we would always have to have these frames already",
    "start": "1147679",
    "end": "1154840"
  },
  {
    "text": "symbolized at collection time which can be very very expensive to do or maybe even impossible",
    "start": "1154840",
    "end": "1162620"
  },
  {
    "text": "because symbols may not always be available on a host where you're doing profiling",
    "start": "1162620",
    "end": "1168620"
  },
  {
    "text": "um but the really interesting thing that I wanted to look at with speed scope is this one the e-advented profile so what",
    "start": "1168620",
    "end": "1175340"
  },
  {
    "text": "we're seeing I don't know why it's doing this um what we're seeing is that",
    "start": "1175340",
    "end": "1182600"
  },
  {
    "text": "um it kind of differentiates in uh two types of events opening a frame and",
    "start": "1182600",
    "end": "1189080"
  },
  {
    "text": "closing a frame right so what it's doing is it's telling us this hierarchy of",
    "start": "1189080",
    "end": "1194240"
  },
  {
    "text": "different frames and when they're being opened so we see the at attribute for",
    "start": "1194240",
    "end": "1199820"
  },
  {
    "text": "example that's a timestamp and the kind as well as the frame number",
    "start": "1199820",
    "end": "1204919"
  },
  {
    "text": "so again quite similar to what we were seeing before however it's also telling us in addition to the frame it's also",
    "start": "1204919",
    "end": "1211880"
  },
  {
    "text": "telling us it was opened here at this particular point in time or it was closed at this particular point in time",
    "start": "1211880",
    "end": "1217880"
  },
  {
    "text": "with this value so quick speed scope demo",
    "start": "1217880",
    "end": "1225640"
  },
  {
    "text": "actually I'm gonna use this cool example that they have on their website so",
    "start": "1230539",
    "end": "1236960"
  },
  {
    "text": "um I'm gonna kind of start with just the left heavy one so this is what we would see as uh kind of the aggregate view",
    "start": "1236960",
    "end": "1244460"
  },
  {
    "text": "right like all we're seeing is always the whole aggregation across the entire uh time frame so this is what typically",
    "start": "1244460",
    "end": "1251299"
  },
  {
    "text": "sampled profiles look like right but the really cool thing about speed scope is that it can tell us about the timeline",
    "start": "1251299",
    "end": "1257900"
  },
  {
    "text": "and how things behave over time so we can select just this portion of the",
    "start": "1257900",
    "end": "1264559"
  },
  {
    "text": "um of the profiling data so that's super cool to see you know how did this actually evolve over time where was my",
    "start": "1264559",
    "end": "1271520"
  },
  {
    "text": "sapu time spent over time because this could be interesting to to use when we want to figure out You",
    "start": "1271520",
    "end": "1280940"
  },
  {
    "text": "Know What's this called multiple times or was this called once for a very long",
    "start": "1280940",
    "end": "1286039"
  },
  {
    "text": "period of time that can make it make a big impact on how we're going to",
    "start": "1286039",
    "end": "1291080"
  },
  {
    "text": "actually improve this code um all right that's pretty much all I",
    "start": "1291080",
    "end": "1296120"
  },
  {
    "text": "wanted to show for Speed scope I know one more thing um",
    "start": "1296120",
    "end": "1301840"
  },
  {
    "text": "the actual format then looks exactly like I just like I just said it kind of",
    "start": "1302120",
    "end": "1309020"
  },
  {
    "text": "defines the starting frame from zero as well as the end frame to Value number 22",
    "start": "1309020",
    "end": "1315140"
  },
  {
    "text": "and then we have the opening frame another opening frame and we always have",
    "start": "1315140",
    "end": "1320600"
  },
  {
    "text": "the reference into the array for our functions at the very top here right and",
    "start": "1320600",
    "end": "1327440"
  },
  {
    "text": "then eventually you know it needs to actually close it and so on so this format is a little bit different to",
    "start": "1327440",
    "end": "1334580"
  },
  {
    "text": "what we were seeing before right like it's not just a list of locations or frames",
    "start": "1334580",
    "end": "1339980"
  },
  {
    "text": "to values it's actually already telling us something about how we're going to",
    "start": "1339980",
    "end": "1345260"
  },
  {
    "text": "visualize this information so that's kind of unique about speed scope in that",
    "start": "1345260",
    "end": "1350840"
  },
  {
    "text": "sense so how am I doing in time need to speed up",
    "start": "1350840",
    "end": "1357620"
  },
  {
    "text": "a little bit so last lastly what I want to talk about is continuous profiling so so far I've only",
    "start": "1357620",
    "end": "1364940"
  },
  {
    "text": "talked about kind of this point in time profiling right I'm looking at a process for a 10 second period of time I'm doing",
    "start": "1364940",
    "end": "1372440"
  },
  {
    "text": "very high sampling so 10 000 templates per second",
    "start": "1372440",
    "end": "1377559"
  },
  {
    "text": "and that obviously as I said in the beginning has some overhead so five to ten percent in overhead continuous",
    "start": "1377559",
    "end": "1384919"
  },
  {
    "text": "profiling kind of takes the kind of extreme opposite approach we're always",
    "start": "1384919",
    "end": "1390260"
  },
  {
    "text": "going to profile absolutely everything in your infrastructure but we're going to do it at very very low sampling",
    "start": "1390260",
    "end": "1395840"
  },
  {
    "text": "frequency so the profiler that I happen to work on actually only profiles at 19",
    "start": "1395840",
    "end": "1401179"
  },
  {
    "text": "Hertz so only 19 samples per CPU core per second and so we've been thinking about you",
    "start": "1401179",
    "end": "1408200"
  },
  {
    "text": "know there's some very drastically different trade-offs that we've chosen uh for",
    "start": "1408200",
    "end": "1413299"
  },
  {
    "text": "continuous profiling do these formats that actually took very different approaches for collection",
    "start": "1413299",
    "end": "1420020"
  },
  {
    "text": "um actually suit this kind of profiling and we you know while",
    "start": "1420020",
    "end": "1425659"
  },
  {
    "text": "um while you know the obligatory XKCD applies we did think that uh you know",
    "start": "1425659",
    "end": "1432500"
  },
  {
    "text": "because there's such fundamental differences in the collection of this data there is actually a possibility for",
    "start": "1432500",
    "end": "1439760"
  },
  {
    "text": "um for a huge amount of possibility for improvement so at polar signals we actually run a continuous profiling",
    "start": "1439760",
    "end": "1445640"
  },
  {
    "text": "service where our customers send us profiling data right and so we were",
    "start": "1445640",
    "end": "1451100"
  },
  {
    "text": "thinking about how much of this data is actually could be optimized away right",
    "start": "1451100",
    "end": "1456380"
  },
  {
    "text": "and one core and in our with our product and this is kind of you know roughly the",
    "start": "1456380",
    "end": "1464120"
  },
  {
    "text": "lowest that that I'm aware of it produces 675 megabytes per month per",
    "start": "1464120",
    "end": "1470840"
  },
  {
    "text": "core and so um if we multiply that by you know relatively small infrastructure size 10",
    "start": "1470840",
    "end": "1477080"
  },
  {
    "text": "nodes with 120 28 cores um each machine we get almost a terabyte of data that",
    "start": "1477080",
    "end": "1483380"
  },
  {
    "text": "needs to be transferred out let's say you know our infrastructure is in gcp our customers infrastructure may be in",
    "start": "1483380",
    "end": "1489620"
  },
  {
    "text": "AWS they're actually paying egress cost to use our product right aside from you know paying us for for using our product",
    "start": "1489620",
    "end": "1496400"
  },
  {
    "text": "so we want to make sure that that kind of cost is as minimal as possible while",
    "start": "1496400",
    "end": "1501740"
  },
  {
    "text": "still communicating the same same intention and so",
    "start": "1501740",
    "end": "1506960"
  },
  {
    "text": "um if we were to use P Prof and that's what we're doing today we're producing this amount of data right we're just",
    "start": "1506960",
    "end": "1513140"
  },
  {
    "text": "kind of marshaling all the stack traces every single time every 10 seconds um and sending those off to the service",
    "start": "1513140",
    "end": "1519440"
  },
  {
    "text": "so we're we're producing roughly eighty dollars um and cost just by sending this amount of data and so we did some analysis and",
    "start": "1519440",
    "end": "1526400"
  },
  {
    "text": "found out that the stack traces that we're sending just the like you know function names uh file names and all",
    "start": "1526400",
    "end": "1533299"
  },
  {
    "text": "these things make up about 80 of all of this data being sent however",
    "start": "1533299",
    "end": "1539539"
  },
  {
    "text": "with continuous profiling we're looking at the same processes across time right and the kind of",
    "start": "1539539",
    "end": "1546140"
  },
  {
    "text": "reality is that long-running processes tend to roughly do the same thing right",
    "start": "1546140",
    "end": "1551360"
  },
  {
    "text": "and so what we're doing is we can just keep over and over and over sending the same stack traces",
    "start": "1551360",
    "end": "1558500"
  },
  {
    "text": "um all over again right with 100 um kind of granularity and detail",
    "start": "1558500",
    "end": "1565100"
  },
  {
    "text": "and so that means if we could optimize these 80 away",
    "start": "1565100",
    "end": "1570260"
  },
  {
    "text": "um we could actually save our customers or you know anyone running continuous profiling infrastructure everything that",
    "start": "1570260",
    "end": "1575360"
  },
  {
    "text": "we do is open source by the way under the parka open source project parca",
    "start": "1575360",
    "end": "1580520"
  },
  {
    "text": "um then we could make everyone's life better right and so what we've been",
    "start": "1580520",
    "end": "1585559"
  },
  {
    "text": "thinking about is something I call P Prof but with a Twist um and so essentially what we would be",
    "start": "1585559",
    "end": "1592820"
  },
  {
    "text": "doing is instead of us kind of sending the same stack traces over and over and",
    "start": "1592820",
    "end": "1598880"
  },
  {
    "text": "over again we actually only send the hashes of the stacks and only and only",
    "start": "1598880",
    "end": "1605240"
  },
  {
    "text": "if um this hash is not known to the back end",
    "start": "1605240",
    "end": "1610400"
  },
  {
    "text": "do we actually kind of retry and send everything at the at kind of 100 detail",
    "start": "1610400",
    "end": "1616580"
  },
  {
    "text": "right and so the reason why I'm kind of calling this paper off with a Twist",
    "start": "1616580",
    "end": "1622100"
  },
  {
    "text": "um is this is actually only a single field difference to what is currently known as the people format so I believe",
    "start": "1622100",
    "end": "1629360"
  },
  {
    "text": "uh this could actually be an interesting change that we could propose through the prepro format in order to gain this",
    "start": "1629360",
    "end": "1635900"
  },
  {
    "text": "efficiency efficiency gain however it is not just the format right that's kind of",
    "start": "1635900",
    "end": "1641600"
  },
  {
    "text": "the important thing and why I also find it a bit awkward to put this into P Prof P Prof is a file format right so I",
    "start": "1641600",
    "end": "1648020"
  },
  {
    "text": "should be able to kind of read this information from disk and it should have everything it needs like self-contained",
    "start": "1648020",
    "end": "1655159"
  },
  {
    "text": "in this file and so this kind of actually changes it into sort of a",
    "start": "1655159",
    "end": "1660320"
  },
  {
    "text": "stateful protocol right the client kind of says Hey I want to send you some data",
    "start": "1660320",
    "end": "1665419"
  },
  {
    "text": "for stack XYZ and I observed it 123 times the server says Ah no actually I",
    "start": "1665419",
    "end": "1671480"
  },
  {
    "text": "don't know what this stack is can you tell me what the stack is so the client kind of retries and says actually at",
    "start": "1671480",
    "end": "1677779"
  },
  {
    "text": "full detail this is the full stack Trace um at which top point then the backend",
    "start": "1677779",
    "end": "1683000"
  },
  {
    "text": "can say okay cool I'll accept that I'll write that to storage um and I'll I'll kind of remember this",
    "start": "1683000",
    "end": "1688400"
  },
  {
    "text": "hash for the next time so my point here was kind of",
    "start": "1688400",
    "end": "1694460"
  },
  {
    "text": "um trying to show um and by the way this is my opinion I know there's a kind of working group",
    "start": "1694460",
    "end": "1700460"
  },
  {
    "text": "within the open Telemetry project which we also participate in",
    "start": "1700460",
    "end": "1705799"
  },
  {
    "text": "um the thing is I personally think this type of stuff is not really explored",
    "start": "1705799",
    "end": "1711679"
  },
  {
    "text": "quite well enough so my personal belief is that I think we're a little bit too early to kind of standardize these",
    "start": "1711679",
    "end": "1717260"
  },
  {
    "text": "things in the profiling space because I think most of these things that I'm proposing here haven't really been tried",
    "start": "1717260",
    "end": "1723799"
  },
  {
    "text": "and tested and if we were to kind of set in stone these protocols today I",
    "start": "1723799",
    "end": "1730220"
  },
  {
    "text": "feel like we're kind of blocking ourselves from kind of innovating in this space so I you know while I'd love",
    "start": "1730220",
    "end": "1736760"
  },
  {
    "text": "to have some standard at the same time I feel like uh there's there's still so much to explore here",
    "start": "1736760",
    "end": "1743240"
  },
  {
    "text": "um that we just haven't done yet so that's kind of my overview for profiling",
    "start": "1743240",
    "end": "1749659"
  },
  {
    "text": "and profiling formats and why I think we should kind of emphasize",
    "start": "1749659",
    "end": "1756440"
  },
  {
    "text": "um innovation in the profiling space because I feel like there's still so much uh left on the table to to explore",
    "start": "1756440",
    "end": "1763520"
  },
  {
    "text": "thank you",
    "start": "1763520",
    "end": "1766240"
  },
  {
    "text": "we are out of time but one quick let's go",
    "start": "1769820",
    "end": "1774880"
  },
  {
    "text": "so it seems to me that there is no clear winner on a transport side of things is",
    "start": "1775039",
    "end": "1780440"
  },
  {
    "text": "there a clear winner on the storage I like only storage on a on disk on the",
    "start": "1780440",
    "end": "1785659"
  },
  {
    "text": "representation on disk so the if I understand the question is like",
    "start": "1785659",
    "end": "1790880"
  },
  {
    "text": "um clearly I've or at least my opinion is the protocol hasn't really been set in stone is the storage set in stone",
    "start": "1790880",
    "end": "1797840"
  },
  {
    "text": "um I don't really think so we happen to invest very much into kind of a column or a database to store this data but",
    "start": "1797840",
    "end": "1804679"
  },
  {
    "text": "actually the symbol storage is much much much much much more complicated um and so no there's definitely still",
    "start": "1804679",
    "end": "1811880"
  },
  {
    "text": "very very much um Innovation left to be done uh in this space I'd like to think that we're",
    "start": "1811880",
    "end": "1817220"
  },
  {
    "text": "getting better out of it um but definitely we're we're nowhere near you know the majority of uh metric",
    "start": "1817220",
    "end": "1824000"
  },
  {
    "text": "storage or Lock Storage um with with profiling and I think there's still a lot of efficiency that",
    "start": "1824000",
    "end": "1830059"
  },
  {
    "text": "we can gain okay I'm sure Frederick can answer more questions around here but it's time for another talk so thank you",
    "start": "1830059",
    "end": "1839080"
  }
]
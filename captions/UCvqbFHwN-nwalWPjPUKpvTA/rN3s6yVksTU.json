[
  {
    "text": "okay since it's like already 10:35 so good morning everyone though it's not that early uh this is Selen sh and",
    "start": "1439",
    "end": "8840"
  },
  {
    "text": "evangelist from M Huawei and today it's been a great pleasure to be here sharing about the automated parallel technique",
    "start": "8840",
    "end": "16000"
  },
  {
    "text": "in mindspo to boost the efficiency of large language model development and",
    "start": "16000",
    "end": "22160"
  },
  {
    "text": "training so today's content will be divided into these four topics first",
    "start": "22160",
    "end": "27439"
  },
  {
    "text": "we'll just like briefly going through the evolution of artificial intelligence in industry and we're going to details",
    "start": "27439",
    "end": "33840"
  },
  {
    "text": "to talk about like the native support for my sport automatic parallelism in details with code implementation to see",
    "start": "33840",
    "end": "40399"
  },
  {
    "text": "how it is different from like other Frameworks and what we've done to improve the usability as well as the",
    "start": "40399",
    "end": "46120"
  },
  {
    "text": "efficiency and performance of large language model training and we'll just talk about some like detailed issues",
    "start": "46120",
    "end": "53039"
  },
  {
    "text": "during the large langu model training and our solution to tackle with them and finally it's just a report about the",
    "start": "53039",
    "end": "59440"
  },
  {
    "text": "ecosystem progress about myport team So currently we as we all know we",
    "start": "59440",
    "end": "65320"
  },
  {
    "text": "are experiencing the fourth wave of artificial intelligence which is characterized by the rise of large",
    "start": "65320",
    "end": "71320"
  },
  {
    "text": "language models for example like Chad GPT and gp4 so this seems to redefine",
    "start": "71320",
    "end": "77200"
  },
  {
    "text": "the role of machine learning and deep learning from just perceiving and comprehending the world's information",
    "start": "77200",
    "end": "83240"
  },
  {
    "text": "and data into just a restricted field towards like a towards generating the",
    "start": "83240",
    "end": "89920"
  },
  {
    "text": "for example images text and other forms of context in a general domain and",
    "start": "89920",
    "end": "95799"
  },
  {
    "text": "especially it can also work as an assistant with the Professional Knowledge of a particular area so we can",
    "start": "95799",
    "end": "103920"
  },
  {
    "text": "see there's a big jum of the capability of these models and this is driven this",
    "start": "103920",
    "end": "110360"
  },
  {
    "text": "is powered by the exponential growth of the large Lang the size of the large",
    "start": "110360",
    "end": "116439"
  },
  {
    "text": "language models and research consistently shows that as we increase",
    "start": "116439",
    "end": "121840"
  },
  {
    "text": "for example the number of parameters of the models expanding the size of the training data as well as deploying more",
    "start": "121840",
    "end": "128599"
  },
  {
    "text": "computational resources the large language models become more powerful however like this kind of phenomenon",
    "start": "128599",
    "end": "136040"
  },
  {
    "text": "also known as the scaling law has driven a Relentless push forward to even larger",
    "start": "136040",
    "end": "142040"
  },
  {
    "text": "models and this has brought the challenges in terms of the difficulty to",
    "start": "142040",
    "end": "148360"
  },
  {
    "text": "for example to develop the large language model because we not only need to consider like how we implement the",
    "start": "148360",
    "end": "155160"
  },
  {
    "text": "algorithms but also like the knowledge from a an experimen software engineer",
    "start": "155160",
    "end": "160760"
  },
  {
    "text": "and also we need to maintain the stable Lang Lang language model training to lower the recovery time once the failure",
    "start": "160760",
    "end": "167680"
  },
  {
    "text": "occurs and finally we also need to lower the cost of inflence of the model so a",
    "start": "167680",
    "end": "173280"
  },
  {
    "text": "Stakes topic we'll mainly focus on the first two challenges which is the development and training",
    "start": "173280",
    "end": "181400"
  },
  {
    "text": "tring so we summarize the challenges of large scale cluster training for large",
    "start": "181400",
    "end": "187480"
  },
  {
    "text": "language models into four domains and since we mentioned in the previous slide",
    "start": "187480",
    "end": "194560"
  },
  {
    "text": "that the morrow exponentially grows so it becomes impossible to load this model",
    "start": "194560",
    "end": "200720"
  },
  {
    "text": "with hundreds of billions of parameters onto a single device because it takes a",
    "start": "200720",
    "end": "206040"
  },
  {
    "text": "great amount of memory by just storing the parameters now to say it's entire",
    "start": "206040",
    "end": "211640"
  },
  {
    "text": "training progress including the model parameters and also the activations gradients as well as the optimizer",
    "start": "211640",
    "end": "218680"
  },
  {
    "text": "States so the distributed machine learning of the models becomes not only",
    "start": "218680",
    "end": "224760"
  },
  {
    "text": "just an optimizes method but also an NE a necessity in this large language model",
    "start": "224760",
    "end": "231280"
  },
  {
    "text": "training and once we tried to distribute this large scale model across different",
    "start": "231280",
    "end": "238879"
  },
  {
    "text": "devices and the second like obstacle comes is to say that it we need to",
    "start": "238879",
    "end": "244120"
  },
  {
    "text": "design a really proper way to slice these models onto across the devices so",
    "start": "244120",
    "end": "250720"
  },
  {
    "text": "that we can um we can M we can like maintain its efficiency and these a lot",
    "start": "250720",
    "end": "257199"
  },
  {
    "text": "of factors need to be considered in this case for example like the number of parameters the computational workload",
    "start": "257199",
    "end": "263800"
  },
  {
    "text": "the computation type as well as the cluster bandwidth and from also from the",
    "start": "263800",
    "end": "269160"
  },
  {
    "text": "perspective of developers and we are always considering like which is like",
    "start": "269160",
    "end": "274320"
  },
  {
    "text": "the suitable programming diagram needed to for the uh developers to design like",
    "start": "274320",
    "end": "281120"
  },
  {
    "text": "the slicing and distributed algorithms and how it is different from like the",
    "start": "281120",
    "end": "287400"
  },
  {
    "text": "common uh script for the model training and finally once we've also launch the",
    "start": "287400",
    "end": "294039"
  },
  {
    "text": "training of large language models it is also difficult in the optimization",
    "start": "294039",
    "end": "299199"
  },
  {
    "text": "because we need to make a balance between the correctness as well as the per performance and availability of",
    "start": "299199",
    "end": "306000"
  },
  {
    "text": "commutations so overall as a conclusion considering all these four walls of the",
    "start": "306000",
    "end": "312360"
  },
  {
    "text": "lar scale cluster training we a developer not only need to master the",
    "start": "312360",
    "end": "318440"
  },
  {
    "text": "algorithm knowledge but also like the software knowledge to know how the",
    "start": "318440",
    "end": "323800"
  },
  {
    "text": "devices can communicate with each other and how for example the tensor is sliced across these devices",
    "start": "323800",
    "end": "331479"
  },
  {
    "text": "so our solution to tackle with these four challenges is to design a framework",
    "start": "331479",
    "end": "337720"
  },
  {
    "text": "that natively support the automatic parallelism of this large language model training including to just use a F line",
    "start": "337720",
    "end": "345840"
  },
  {
    "text": "just use a few lines to choose like the strategy automatically for this training",
    "start": "345840",
    "end": "352360"
  },
  {
    "text": "and we have make a combination of these different uh slicing Pol policies from",
    "start": "352360",
    "end": "360800"
  },
  {
    "text": "multi-dimensions and we'll go into that in",
    "start": "360800",
    "end": "365039"
  },
  {
    "text": "details so as this is an elaboration about like the uh par distributed",
    "start": "366199",
    "end": "373520"
  },
  {
    "text": "parallel parallelization capability of Mind SP including all this multi-dimensional H parallelism with the",
    "start": "373520",
    "end": "381520"
  },
  {
    "text": "commonly used parallelism such as the operator level paradism this might be a special name and we'll explain later why",
    "start": "381520",
    "end": "388199"
  },
  {
    "text": "we call it like operator level parallelism instead of like other names such as tensor parallelism or motor",
    "start": "388199",
    "end": "393840"
  },
  {
    "text": "parallelism and as well as the pipeline parallelism optimiz the parallelism and",
    "start": "393840",
    "end": "399720"
  },
  {
    "text": "as regards the multi-dimensional storage and heterogeneous optimization We performed recut for example",
    "start": "399720",
    "end": "405599"
  },
  {
    "text": "recomputation to optimize the",
    "start": "405599",
    "end": "409440"
  },
  {
    "text": "memory and for the operative level par parallelism we may just brief briefly",
    "start": "411039",
    "end": "417240"
  },
  {
    "text": "like review like the a role of tensor parallelism uh with this visualized",
    "start": "417240",
    "end": "423400"
  },
  {
    "text": "example uh of this straightforward computation of matrix multiplication so",
    "start": "423400",
    "end": "429280"
  },
  {
    "text": "in the tensor parallelism each tensor in this case in this case like the W here is",
    "start": "429280",
    "end": "436879"
  },
  {
    "text": "sliced into like multiple chunks and here we have like two chunks each of",
    "start": "436879",
    "end": "442160"
  },
  {
    "text": "this is assigned to like one of these two devices so that for each step with",
    "start": "442160",
    "end": "448039"
  },
  {
    "text": "the same mini batch of of data input the the data is processed independently in",
    "start": "448039",
    "end": "454479"
  },
  {
    "text": "parallel along like each device to have like different outputs and because of",
    "start": "454479",
    "end": "459800"
  },
  {
    "text": "the strong dependence of the input output relationship between the operators we need to do like the or",
    "start": "459800",
    "end": "465759"
  },
  {
    "text": "communication to aggregate the output together and to pass it into other like",
    "start": "465759",
    "end": "470960"
  },
  {
    "text": "the uh following operators so in this case why we call it",
    "start": "470960",
    "end": "476879"
  },
  {
    "text": "like the operator level parallelism in multiple is that it functions at the",
    "start": "476879",
    "end": "482080"
  },
  {
    "text": "level of individual operators that is to say we model each operator independently",
    "start": "482080",
    "end": "489000"
  },
  {
    "text": "and so that developers can just Define the sh strategy whether we need to like",
    "start": "489000",
    "end": "494759"
  },
  {
    "text": "slice in terms of rows or in terms of columns for the tenses associated with",
    "start": "494759",
    "end": "500560"
  },
  {
    "text": "each op trator and under this design there's no need to care about how to",
    "start": "500560",
    "end": "506280"
  },
  {
    "text": "manage the actual distribution of each sh of the model across the Clusters",
    "start": "506280",
    "end": "513959"
  },
  {
    "text": "manually and for the implementation of the operator level parallelism here's a",
    "start": "514919",
    "end": "520880"
  },
  {
    "text": "code for like really simple like to a really simple like uh Network",
    "start": "520880",
    "end": "526040"
  },
  {
    "text": "computation including like two Mo uh Meto like computations with the comparison with Megatron solution and",
    "start": "526040",
    "end": "534160"
  },
  {
    "text": "from the Megatron solution we can see that we we need to implement both both",
    "start": "534160",
    "end": "539720"
  },
  {
    "text": "like the uh how like the SL how the model or the tensor is sliced across",
    "start": "539720",
    "end": "544760"
  },
  {
    "text": "different devices and how they gather together both in the forward PA and the backward propagation but in my SP we",
    "start": "544760",
    "end": "552200"
  },
  {
    "text": "only need to care about how we design the straw strategy by operating this sh",
    "start": "552200",
    "end": "557240"
  },
  {
    "text": "function upon the operators here is shown by the Ops M Mo here and to go",
    "start": "557240",
    "end": "564360"
  },
  {
    "text": "into details about this function we can see that we are actually calculating like the X which is the input multiplied",
    "start": "564360",
    "end": "571959"
  },
  {
    "text": "by the weight Matrix and then like the result is f continuously uh multiply",
    "start": "571959",
    "end": "578240"
  },
  {
    "text": "multiplying with another weight Matrix called V and in this case let's look at",
    "start": "578240",
    "end": "583720"
  },
  {
    "text": "into like the first calculation which is X Matrix multiplied by W here we have normally we have like dimensions of X",
    "start": "583720",
    "end": "591079"
  },
  {
    "text": "with the B size as the First Dimension and input size as the second dimension and with we of input size and output",
    "start": "591079",
    "end": "597640"
  },
  {
    "text": "size so we have have like two brackets in the sharp function with each corresponding to the Shar policy for",
    "start": "597640",
    "end": "605160"
  },
  {
    "text": "each input so here we have four one for the X which means to slice X and the",
    "start": "605160",
    "end": "611600"
  },
  {
    "text": "column uh and uh in the dimension of row so here in the dimension of but SI and",
    "start": "611600",
    "end": "618000"
  },
  {
    "text": "to maintain the correctness of matrix multiplication we just keep like the entire weight Matrix uh for each device",
    "start": "618000",
    "end": "626120"
  },
  {
    "text": "so here we actually doing the data paraly so that's why we have like actually the operator Lev paradism is",
    "start": "626120",
    "end": "632600"
  },
  {
    "text": "kind of like a slightly higher level L for this parallelism because it's referring to the parallelism that",
    "start": "632600",
    "end": "639560"
  },
  {
    "text": "contains or involves the slicing of tenses associated with The Operators no",
    "start": "639560",
    "end": "646120"
  },
  {
    "text": "matter it is the model parameter or the data input so and or and similarly for the",
    "start": "646120",
    "end": "653120"
  },
  {
    "text": "second mimal computation we have like the final result of the X multipli by W",
    "start": "653120",
    "end": "659040"
  },
  {
    "text": "and further multiplied by V and here we can see like we have one one here like which is number corresponding to the",
    "start": "659040",
    "end": "666079"
  },
  {
    "text": "number of SES number of shots for each computation and here we just maintain like the entire input of Y and to slice",
    "start": "666079",
    "end": "674440"
  },
  {
    "text": "like to do the colum slicing of the parameter of w here so like in this case",
    "start": "674440",
    "end": "680839"
  },
  {
    "text": "we split into four parts along the second dimension so in this case we uh just leave the work of actual slicing",
    "start": "680839",
    "end": "688440"
  },
  {
    "text": "and distributing is sh into a particular device and finally to Comm finally let",
    "start": "688440",
    "end": "694519"
  },
  {
    "text": "like the devices to communicate together to the framework and we just need to care about like which tens we need to",
    "start": "694519",
    "end": "700920"
  },
  {
    "text": "slice and how many number of shs we need to obtain and which is strongly relying",
    "start": "700920",
    "end": "706839"
  },
  {
    "text": "on like the number of devices available and which dimension is this operation uh",
    "start": "706839",
    "end": "715040"
  },
  {
    "text": "functional and for like the parallel parallelism unlike the traditional data",
    "start": "716279",
    "end": "721680"
  },
  {
    "text": "parallelism and um model or tens parallelism as shown in the previous slide which surface from The Limited",
    "start": "721680",
    "end": "729160"
  },
  {
    "text": "communication bandwidth between servers Pine parallelism enhances its efficiency",
    "start": "729160",
    "end": "734880"
  },
  {
    "text": "by sequentially just Distributing the model in in terms of slicing layers",
    "start": "734880",
    "end": "740720"
  },
  {
    "text": "instead of slicing the tenses acrossing different stages and each stage May contains like uh multiple layers of",
    "start": "740720",
    "end": "747519"
  },
  {
    "text": "segments of the model and and this approach allows like each device to just",
    "start": "747519",
    "end": "752880"
  },
  {
    "text": "handle the layers or segments it is responsible for and it just need to do the communication between adjacent",
    "start": "752880",
    "end": "759639"
  },
  {
    "text": "devices and in this case for the M uh for the P parallelism we are actually",
    "start": "759639",
    "end": "765440"
  },
  {
    "text": "doing the same work so we just leave like how they how to send and receive",
    "start": "765440",
    "end": "770839"
  },
  {
    "text": "operations to the framework so we just abstract a way which is also complicated to implement and just let the developers",
    "start": "770839",
    "end": "778760"
  },
  {
    "text": "to design like which layers are assigned to for example the first device or the",
    "start": "778760",
    "end": "784560"
  },
  {
    "text": "second device by adding the TX of pipeline P pipeline Sage here so as this",
    "start": "784560",
    "end": "791040"
  },
  {
    "text": "example shown on the left hand side we have like a resent model which where",
    "start": "791040",
    "end": "796480"
  },
  {
    "text": "like the head and to like the layer two is assigned to the first device and",
    "start": "796480",
    "end": "802839"
  },
  {
    "text": "layer three to the final fully connected layer assigned to like the",
    "start": "802839",
    "end": "808120"
  },
  {
    "text": "second uh second device by just adding the pipeline stage interface here so it",
    "start": "808120",
    "end": "815000"
  },
  {
    "text": "is operating uh on a granularity of a cell so every cell here will alsoo which is",
    "start": "815000",
    "end": "823160"
  },
  {
    "text": "the fundamental unit of the network with the trainable parameters must be signed",
    "start": "823160",
    "end": "828560"
  },
  {
    "text": "to a pipeline stage and it must be executed in the same order of like what",
    "start": "828560",
    "end": "834279"
  },
  {
    "text": "is what like the total workflow is executed through",
    "start": "834279",
    "end": "840560"
  },
  {
    "text": "and for like the implementation of and for the recomputation it um IT addresses",
    "start": "841560",
    "end": "849320"
  },
  {
    "text": "the issue of the memory optimization from a different approach by trading off",
    "start": "849320",
    "end": "854399"
  },
  {
    "text": "the computation resources for example by adding additional computation time to",
    "start": "854399",
    "end": "860079"
  },
  {
    "text": "save the memory usage uh except for like the static memory occupation of for",
    "start": "860079",
    "end": "866279"
  },
  {
    "text": "example the model parameters gradients and Optimizer States we also have like dyam Dynamic occupations for example the",
    "start": "866279",
    "end": "873560"
  },
  {
    "text": "activations which will accumulate through the forward pass so that's why we will have this like pick of the",
    "start": "873560",
    "end": "880639"
  },
  {
    "text": "memory allocation in this entire map which may exceed the capability for",
    "start": "880639",
    "end": "886360"
  },
  {
    "text": "device memory and in this case for the rec computation we just uh re we don't",
    "start": "886360",
    "end": "893480"
  },
  {
    "text": "uh we don't store all the activations in the for pass but to release release them",
    "start": "893480",
    "end": "899279"
  },
  {
    "text": "and to recalculate the forward pass when the gradients are required to be",
    "start": "899279",
    "end": "904360"
  },
  {
    "text": "computed during the backward propagation so it kind of like wasting some of like the communication time which is",
    "start": "904360",
    "end": "910720"
  },
  {
    "text": "acceptable since the for pass is uh cause less time than back propagation to",
    "start": "910720",
    "end": "917079"
  },
  {
    "text": "make sure that like thisp can be lowered just to this like",
    "start": "917079",
    "end": "923279"
  },
  {
    "text": "platform and for user convenience M will provides recomputation interface so as",
    "start": "924680",
    "end": "931000"
  },
  {
    "text": "show here as to recompute for the individual operators and sales so when",
    "start": "931000",
    "end": "936839"
  },
  {
    "text": "it's so it's not only available for this single operator like redo but also just",
    "start": "936839",
    "end": "942440"
  },
  {
    "text": "a combination of operators in the network as a cell is assigned to this",
    "start": "942440",
    "end": "948759"
  },
  {
    "text": "compute tag and all like the forward operators within the cell will be set to",
    "start": "948759",
    "end": "953959"
  },
  {
    "text": "computation so for this like uh for the process of computation will add tax to",
    "start": "953959",
    "end": "961440"
  },
  {
    "text": "The Operators once we place the rec comput interface here and once during",
    "start": "961440",
    "end": "966639"
  },
  {
    "text": "the compile phas the T the tag of the operator is identified the framework",
    "start": "966639",
    "end": "972279"
  },
  {
    "text": "will automatically insert the release of forward pause as well as the recompute",
    "start": "972279",
    "end": "977920"
  },
  {
    "text": "of forward pause during the back propagation into the overall",
    "start": "977920",
    "end": "983120"
  },
  {
    "text": "process and for zero it tackles with the problem from a different aspect but not",
    "start": "984079",
    "end": "991440"
  },
  {
    "text": "just making compromises between for example like the computation time and",
    "start": "991440",
    "end": "997000"
  },
  {
    "text": "the memory op optimization but to slice the optimizer State here which involves",
    "start": "997000",
    "end": "1003279"
  },
  {
    "text": "for example the momentum of optimization algorithms so as shown in this graph",
    "start": "1003279",
    "end": "1008880"
  },
  {
    "text": "here we have like the stat static memory like uh over overload uh divided into",
    "start": "1008880",
    "end": "1016120"
  },
  {
    "text": "like three main like uh domains which is which are the parameters shown as blue",
    "start": "1016120",
    "end": "1021519"
  },
  {
    "text": "here and the gradients shown as orange as well as the optimizer States shown as green here and we can see like the from",
    "start": "1021519",
    "end": "1029079"
  },
  {
    "text": "the distribution of the memory upon like a single device the parameters of",
    "start": "1029079",
    "end": "1034480"
  },
  {
    "text": "gradients occupies like similar PL uh similar place which is kind of like negl",
    "start": "1034480",
    "end": "1040918"
  },
  {
    "text": "uh negligible like compared to the optimizer States so what zero does is to",
    "start": "1040919",
    "end": "1046000"
  },
  {
    "text": "petition the optimizer state which um takes like account the majority of the",
    "start": "1046000",
    "end": "1051080"
  },
  {
    "text": "memory usage across different devices so it can effectively reduce like the",
    "start": "1051080",
    "end": "1056440"
  },
  {
    "text": "memory consumed to adjust a quarter of it by simply slicing the optimizing",
    "start": "1056440",
    "end": "1061919"
  },
  {
    "text": "States and we can go further to like the extrem but also slicing for example the",
    "start": "1061919",
    "end": "1067320"
  },
  {
    "text": "gradients and well as even the parameters which corresponds to the",
    "start": "1067320",
    "end": "1072400"
  },
  {
    "text": "implementation of 02 and 03 but this big",
    "start": "1072400",
    "end": "1077440"
  },
  {
    "text": "drop of the memory consumed needs to needs uh causes the rise of the",
    "start": "1077440",
    "end": "1083360"
  },
  {
    "text": "communication because we need the parameters to do like for example the ga",
    "start": "1083360",
    "end": "1088559"
  },
  {
    "text": "and ruce together to communicate between devices and uh to get the final outcome",
    "start": "1088559",
    "end": "1094799"
  },
  {
    "text": "for like the next computation and for mindful impli about",
    "start": "1094799",
    "end": "1100240"
  },
  {
    "text": "zero it matches with the 03 and it's named as Optimizer parallelism in mypo",
    "start": "1100240",
    "end": "1106520"
  },
  {
    "text": "so for the implementation of this we we first set the semi paral semi-auto",
    "start": "1106520",
    "end": "1112679"
  },
  {
    "text": "parallel mode here and we'll explain like why we call a semi-auto parallel instead of like just the auto parallel",
    "start": "1112679",
    "end": "1119679"
  },
  {
    "text": "and also we enable like the parallel Optimizer so we just need to add this",
    "start": "1119679",
    "end": "1125280"
  },
  {
    "text": "line to set or activate the optimizer paration in in the uh across the",
    "start": "1125280",
    "end": "1132440"
  },
  {
    "text": "framework before the network is initialized",
    "start": "1132440",
    "end": "1137760"
  },
  {
    "text": "and finally like all this capabilities of the automatic or semi-automatic",
    "start": "1139600",
    "end": "1145799"
  },
  {
    "text": "parallelism is leveraged by the tool case provided by mport so what it is is",
    "start": "1145799",
    "end": "1152480"
  },
  {
    "text": "to simplify the overall development process of large language model production so we have like mple",
    "start": "1152480",
    "end": "1159720"
  },
  {
    "text": "Transformers which is focusing on the transform based models as well as the",
    "start": "1159720",
    "end": "1165080"
  },
  {
    "text": "mind one which is mainly responsible for the diffusion based models and for these",
    "start": "1165080",
    "end": "1170600"
  },
  {
    "text": "two suits we have like the we we provided like the rebu open source pre-",
    "start": "1170600",
    "end": "1176600"
  },
  {
    "text": "trint models for example like llama GM Byran Etc as well as like the down",
    "start": "1176600",
    "end": "1182520"
  },
  {
    "text": "strring TOS common down string tops for example like the TCH Generation image caption captioning and so on so with the",
    "start": "1182520",
    "end": "1189400"
  },
  {
    "text": "help of these two case we can just use like a few lines of code to perform the",
    "start": "1189400",
    "end": "1194520"
  },
  {
    "text": "overall process of like for example a llama model training including is TR is",
    "start": "1194520",
    "end": "1200000"
  },
  {
    "text": "pre-training fine-tuning inference and finally the deployment and for like def finding of",
    "start": "1200000",
    "end": "1208200"
  },
  {
    "text": "the large language models we have a toet of of multile pad which is also called",
    "start": "1208200",
    "end": "1213640"
  },
  {
    "text": "and and the multiple Transformers when going through like the fine tuning process and this provides like the rebu",
    "start": "1213640",
    "end": "1220200"
  },
  {
    "text": "fine tuning algorithms especially the parameter efficient uh fine tuning methods for example like Laura to",
    "start": "1220200",
    "end": "1227640"
  },
  {
    "text": "finding the model just funing just 40% of the parameters of the model but to",
    "start": "1227640",
    "end": "1233120"
  },
  {
    "text": "achieve a compatible performance with like the full parameter fine-tuning so",
    "start": "1233120",
    "end": "1239280"
  },
  {
    "text": "this is also a way to effectively reduce like the memory cost of uh the large",
    "start": "1239280",
    "end": "1245320"
  },
  {
    "text": "during the large language mode of fine tuning and for MF so as it name said it",
    "start": "1245320",
    "end": "1251919"
  },
  {
    "text": "is responsible for like reinforcement learning from Human feedback allowing",
    "start": "1251919",
    "end": "1256960"
  },
  {
    "text": "the developers to design the customize the GPT CH gbt like",
    "start": "1256960",
    "end": "1263120"
  },
  {
    "text": "models and we after just discussing like the overall like key challenges of like",
    "start": "1264720",
    "end": "1271720"
  },
  {
    "text": "the L language model training and how we Implement like these different forms of",
    "start": "1271720",
    "end": "1277200"
  },
  {
    "text": "paralyzation we're going to some like part of this challenges or we we say is",
    "start": "1277200",
    "end": "1282240"
  },
  {
    "text": "the large language model issues and the Sol and our Solutions so it's just like to emphasize",
    "start": "1282240",
    "end": "1291559"
  },
  {
    "text": "all this paralyzation capabilities is built upon the slicing of static graphs",
    "start": "1291559",
    "end": "1297480"
  },
  {
    "text": "into subgraphs with each sub subgraph assigned to a single device so the",
    "start": "1297480",
    "end": "1302720"
  },
  {
    "text": "single operator script is uh built into the comp Computing graph by the compiler",
    "start": "1302720",
    "end": "1308760"
  },
  {
    "text": "and it will automatically slice the graph based on the distribution strategy as we",
    "start": "1308760",
    "end": "1314360"
  },
  {
    "text": "defined and which uh gives like kind of a easy to use and strategy flexible uh",
    "start": "1314360",
    "end": "1321000"
  },
  {
    "text": "solution to the uh to the developers and the overall like technical uh stack has",
    "start": "1321000",
    "end": "1327559"
  },
  {
    "text": "been divided into five levels from starting from the bottom of the fundamental Parts towards the uh advanc",
    "start": "1327559",
    "end": "1334840"
  },
  {
    "text": "parts and since we've talked a lot about the multi-dimensional parallelism here",
    "start": "1334840",
    "end": "1340480"
  },
  {
    "text": "and so we'll just explain some of like our just uh self-design for example the",
    "start": "1340480",
    "end": "1345679"
  },
  {
    "text": "in in pipeline which is kind kind of a optimized level compared with the",
    "start": "1345679",
    "end": "1351440"
  },
  {
    "text": "intralayer pipeline solution of the Megatron LM as well as like the global memory reuse and the grub sync which",
    "start": "1351440",
    "end": "1358760"
  },
  {
    "text": "responsible which is responsible for the memory op optimization and the hyper movement",
    "start": "1358760",
    "end": "1366080"
  },
  {
    "text": "scheduling and from like the experience of the large language model training it",
    "start": "1367279",
    "end": "1372840"
  },
  {
    "text": "seems like the typical distributed large language mode training seems to form like a pattern including like the data",
    "start": "1372840",
    "end": "1380000"
  },
  {
    "text": "parallel comp combined with Optimizer parallel also called like name zero and",
    "start": "1380000",
    "end": "1385279"
  },
  {
    "text": "model parallel so here like referring to for example like the tensor parallels as well as the pipeline and Rec compute",
    "start": "1385279",
    "end": "1392200"
  },
  {
    "text": "together so for this recipe we'll just slice like the entire model and input in",
    "start": "1392200",
    "end": "1398720"
  },
  {
    "text": "from different dimensions as shown here in the graph and for this design will bring like three major cost of the",
    "start": "1398720",
    "end": "1407000"
  },
  {
    "text": "efficiency one is is the motor parallelism activation communication because of the property that we need to",
    "start": "1407000",
    "end": "1414799"
  },
  {
    "text": "update like the outcome of the computation after the model parallel to",
    "start": "1414799",
    "end": "1420480"
  },
  {
    "text": "make sure that it's stays consistent with the next computation so we need to",
    "start": "1420480",
    "end": "1425559"
  },
  {
    "text": "do the computation every time we finish the communication every time we finish the computation and so this necessary",
    "start": "1425559",
    "end": "1434760"
  },
  {
    "text": "communication between devices is difficult to hide or overlap with the computations so there was always bit of",
    "start": "1434760",
    "end": "1441600"
  },
  {
    "text": "time waiting for the devices to communicate and the second one stats for",
    "start": "1441600",
    "end": "1447600"
  },
  {
    "text": "the pipeline bubble which refers to the idle devices when Com when performing",
    "start": "1447600",
    "end": "1453120"
  },
  {
    "text": "the pipeline uh paralyzation this is because like for example like for the",
    "start": "1453120",
    "end": "1458240"
  },
  {
    "text": "devices which is in the later like subsequential order they need to wait",
    "start": "1458240",
    "end": "1463360"
  },
  {
    "text": "until like their previous stages to obtain the final like for to obtain and",
    "start": "1463360",
    "end": "1468480"
  },
  {
    "text": "to obtain and send like the outcome and for it to go through like the whole",
    "start": "1468480",
    "end": "1474000"
  },
  {
    "text": "process so there will always not like all the devices are working at like",
    "start": "1474000",
    "end": "1479399"
  },
  {
    "text": "simultaneously so which cause lowers the efficiency of the over training so we just want to like make sure like the",
    "start": "1479399",
    "end": "1486440"
  },
  {
    "text": "ratio of the working devices at the time is as high as imposs as high as possible",
    "start": "1486440",
    "end": "1493360"
  },
  {
    "text": "and finally for the data parallel we have like the gradient aggregation every time we finish data paralyzation to",
    "start": "1493360",
    "end": "1501200"
  },
  {
    "text": "aggregate the gradient and send it and to copy it or send it across devices for",
    "start": "1501200",
    "end": "1506840"
  },
  {
    "text": "further mod model optimization and this phenomenon gets worse when we are",
    "start": "1506840",
    "end": "1513120"
  },
  {
    "text": "scaling up the models for like a large scale like of costers so let's go into step by step",
    "start": "1513120",
    "end": "1521000"
  },
  {
    "text": "about like how for each issue how we uh how we work on them and for like the",
    "start": "1521000",
    "end": "1526799"
  },
  {
    "text": "talism or just we just call like both a tensor parallelism sequence parm as well",
    "start": "1526799",
    "end": "1533000"
  },
  {
    "text": "as the a parm ofe models uh as the operator level parm and this like",
    "start": "1533000",
    "end": "1539399"
  },
  {
    "text": "intralayer like tensor parm Communications is hard to overlap and will add about like 20% to 40% actual",
    "start": "1539399",
    "end": "1547120"
  },
  {
    "text": "latency to the overall",
    "start": "1547120",
    "end": "1550640"
  },
  {
    "text": "process and what we do is to overlap the inlayer uh tensor parm communication by",
    "start": "1552200",
    "end": "1559279"
  },
  {
    "text": "the intr layer pipeline so it's kind of to further slice like to do the further",
    "start": "1559279",
    "end": "1564440"
  },
  {
    "text": "slicing so for example like as we always as like the structure of lar large",
    "start": "1564440",
    "end": "1571000"
  },
  {
    "text": "language model has been converged to the structure of a transformer including the",
    "start": "1571000",
    "end": "1576399"
  },
  {
    "text": "attention followed by the multi-layer uh follow sorry for followed by the MLP and",
    "start": "1576399",
    "end": "1582840"
  },
  {
    "text": "we'll have the communication of the tensor model paraliz of every time we",
    "start": "1582840",
    "end": "1588960"
  },
  {
    "text": "finish the computation so what we did is to split further split along either the",
    "start": "1588960",
    "end": "1594720"
  },
  {
    "text": "sequence Axis or the batch axis so that we have like for example uh let's look",
    "start": "1594720",
    "end": "1600640"
  },
  {
    "text": "into like the first case about slicing along the sequin axis we have like the",
    "start": "1600640",
    "end": "1605679"
  },
  {
    "text": "first half half of the sequence and the second half of the sequence and because of like the computation property and of",
    "start": "1605679",
    "end": "1613559"
  },
  {
    "text": "the attention like it's hard to slice based on the sequences so we slice uh",
    "start": "1613559",
    "end": "1618640"
  },
  {
    "text": "the linear uh the linear computation for the projection and the final step so the",
    "start": "1618640",
    "end": "1624919"
  },
  {
    "text": "communication of this linear com computation is overlapped of the first",
    "start": "1624919",
    "end": "1630720"
  },
  {
    "text": "half of the sequence is overlapped with the linear computation of the second half sequence so that we can we don't",
    "start": "1630720",
    "end": "1638080"
  },
  {
    "text": "need to just wait until the communication finishes and the similar case Works uh",
    "start": "1638080",
    "end": "1644720"
  },
  {
    "text": "works on like the splitting along the batch axis where we are able to also slice the attention and to high the",
    "start": "1644720",
    "end": "1651799"
  },
  {
    "text": "communication uh High the communication just into like the calculation of other",
    "start": "1651799",
    "end": "1658039"
  },
  {
    "text": "batches and this will reduce like the intralayer communication cost by about",
    "start": "1658039",
    "end": "1663240"
  },
  {
    "text": "75% which is a really just a reason reasonable",
    "start": "1663240",
    "end": "1668679"
  },
  {
    "text": "reduce and for the in pipeline issues we for like for the first approach about",
    "start": "1670080",
    "end": "1677360"
  },
  {
    "text": "the pipeline bubble so as shown here in the dark areas so these are the idle devices that is not working and we and",
    "start": "1677360",
    "end": "1685000"
  },
  {
    "text": "first and the first approach is to uh uh first first approach is to divide like",
    "start": "1685000",
    "end": "1692279"
  },
  {
    "text": "the bat size into microbites so in this case we have like uh about eight microb",
    "start": "1692279",
    "end": "1697880"
  },
  {
    "text": "batches AC distributed across like full devices so for once like the first micr",
    "start": "1697880",
    "end": "1704880"
  },
  {
    "text": "batch is passed towards like the second device we then just input insert like",
    "start": "1704880",
    "end": "1710480"
  },
  {
    "text": "the second microbat to device one so that like the device one is still working on the next microb Bates when",
    "start": "1710480",
    "end": "1717640"
  },
  {
    "text": "device two is still processing so also in this case we perform like the call a",
    "start": "1717640",
    "end": "1723320"
  },
  {
    "text": "strategy called one forward One backwards so that is to immediately call",
    "start": "1723320",
    "end": "1728919"
  },
  {
    "text": "the backward pause after the forward pause of this single micro batch is",
    "start": "1728919",
    "end": "1734080"
  },
  {
    "text": "finished so in this this case we'll reduce like the activation accumulation",
    "start": "1734080",
    "end": "1739640"
  },
  {
    "text": "about like the device so that we can avoid like the peck of the memory over",
    "start": "1739640",
    "end": "1744960"
  },
  {
    "text": "overload and we can further to further like further conduct Improvement by just",
    "start": "1744960",
    "end": "1751600"
  },
  {
    "text": "assigning multiple stages to each device which is called like interlayer P lining",
    "start": "1751600",
    "end": "1756760"
  },
  {
    "text": "so in this case we just assign inter interlift like uh stages towards",
    "start": "1756760",
    "end": "1762720"
  },
  {
    "text": "different devices so other than we have like for example layer one layer one and Layer Two or assign to device one",
    "start": "1762720",
    "end": "1769320"
  },
  {
    "text": "probably we'll assign like for example layer one and layer five to device one so it's like we first compute the half",
    "start": "1769320",
    "end": "1776200"
  },
  {
    "text": "of the first half of the motel uh during like the forward pass and then continue to compute the second half of the ne",
    "start": "1776200",
    "end": "1783640"
  },
  {
    "text": "which uh also to some extent increase the ratio of the like working working",
    "start": "1783640",
    "end": "1790760"
  },
  {
    "text": "devices to reduce pipeline bubbles but here we can see that like it this is",
    "start": "1790760",
    "end": "1796760"
  },
  {
    "text": "trading of like the memory cost of devices especially for device one cuz we",
    "start": "1796760",
    "end": "1801799"
  },
  {
    "text": "it need to wait until like the entire model to finish is forward computation so we can see there will be like a huge",
    "start": "1801799",
    "end": "1809240"
  },
  {
    "text": "uh junk of the uh activations here which uh which is memory",
    "start": "1809240",
    "end": "1817279"
  },
  {
    "text": "costly and what's uh what we designed for in this case so this is like a",
    "start": "1818600",
    "end": "1825000"
  },
  {
    "text": "similar uh similar case as the previous so we have the forward PA which is which",
    "start": "1825000",
    "end": "1831240"
  },
  {
    "text": "is marked as green and orange and the backward paes so the blue corresponds to the backr P of the green full proces and",
    "start": "1831240",
    "end": "1839880"
  },
  {
    "text": "the red one corresponds to like the backr P of the orange forward poses and",
    "start": "1839880",
    "end": "1845320"
  },
  {
    "text": "in this case we part partially like postpones the forward passing of a few",
    "start": "1845320",
    "end": "1850720"
  },
  {
    "text": "microbadges so we can see that the green full poses some of the green four proces",
    "start": "1850720",
    "end": "1856600"
  },
  {
    "text": "has been postponed to a later stage so that we can reduce the activation memory",
    "start": "1856600",
    "end": "1862039"
  },
  {
    "text": "for like especially like the first device and we can also do some flexible",
    "start": "1862039",
    "end": "1867159"
  },
  {
    "text": "configuration about just adding the all4 all backward together with the 141 or",
    "start": "1867159",
    "end": "1873600"
  },
  {
    "text": "141 backward so it will solve the problem of the data parallel gradient",
    "start": "1873600",
    "end": "1879600"
  },
  {
    "text": "aggregation so we can see that the gradient aggregation here is overlapped",
    "start": "1879600",
    "end": "1885039"
  },
  {
    "text": "with the backward calculation of like of the second uh the second like stages of",
    "start": "1885039",
    "end": "1892000"
  },
  {
    "text": "the of like the second uh microb batches or certain group of micro",
    "start": "1892000",
    "end": "1898279"
  },
  {
    "text": "batches and uh as you can tell from this SC like the one forward one backward and",
    "start": "1898279",
    "end": "1903600"
  },
  {
    "text": "all for all backwards can be flexibly adjusted to achieve like the best computation all the communication",
    "start": "1903600",
    "end": "1910440"
  },
  {
    "text": "performance and and like the ratio is dependent on the motor size and the",
    "start": "1910440",
    "end": "1916440"
  },
  {
    "text": "cluster scale and finally like the SAS which is the",
    "start": "1916440",
    "end": "1923039"
  },
  {
    "text": "memory management for the Computing growth basically like the framework controls the entire memory P occupying",
    "start": "1923039",
    "end": "1930679"
  },
  {
    "text": "all available memory by default and during the compilation it identifies the",
    "start": "1930679",
    "end": "1936039"
  },
  {
    "text": "life cycle of tenses and allocates memory accordingly so that with this",
    "start": "1936039",
    "end": "1941399"
  },
  {
    "text": "Global Information we can optimize best memory allocation and release plan for this entire process",
    "start": "1941399",
    "end": "1949840"
  },
  {
    "text": "and also for like the growth compiling and execution our previous plan involves",
    "start": "1950320",
    "end": "1955480"
  },
  {
    "text": "like small scale or like the fundamental operates which needs to be launched one by one in a sequential manner so as",
    "start": "1955480",
    "end": "1962039"
  },
  {
    "text": "shown here so which waste time in host device interaction and has the both neck",
    "start": "1962039",
    "end": "1968320"
  },
  {
    "text": "in the efficiency Improvement so the key solution is to build like the computer growth from source code and sync the",
    "start": "1968320",
    "end": "1976279"
  },
  {
    "text": "entire growth to divide in one go which will gain back about like the 5%",
    "start": "1976279",
    "end": "1983600"
  },
  {
    "text": "Improvement and as regards like the usability as we mentioned in the",
    "start": "1985120",
    "end": "1990440"
  },
  {
    "text": "challenges uh in the challenges of large language motor training it is uh it is",
    "start": "1990440",
    "end": "1996519"
  },
  {
    "text": "unavoidable to have failures during this long time Lun language model training across a lot scho uh clusters no matter",
    "start": "1996519",
    "end": "2004600"
  },
  {
    "text": "like how it is caused for example by the no error computer Arrow or the network Arrow so the main like the main like",
    "start": "2004600",
    "end": "2012120"
  },
  {
    "text": "importance stays in the case at how we can reduce the recovery time so that it",
    "start": "2012120",
    "end": "2017240"
  },
  {
    "text": "can quickly recover to it's for example lat State and continue training instead",
    "start": "2017240",
    "end": "2022360"
  },
  {
    "text": "of to instead of resorting the entire cluster whenever like a failure occurs",
    "start": "2022360",
    "end": "2028120"
  },
  {
    "text": "so in this case once like a note is like breaks down during the training we",
    "start": "2028120",
    "end": "2034840"
  },
  {
    "text": "accelate this failure note and do the elastic scaling cluster and for this",
    "start": "2034840",
    "end": "2040000"
  },
  {
    "text": "finicle we'll analyze the arrrow whether it is like uh caused by for example",
    "start": "2040000",
    "end": "2045120"
  },
  {
    "text": "Computing arrrow Network Arrow or the node arrow and to load the checkpoint before the failure and to keep on the",
    "start": "2045120",
    "end": "2053200"
  },
  {
    "text": "training so with this overall design we can reduce like the F recovery of the",
    "start": "2053200",
    "end": "2059638"
  },
  {
    "text": "model into like about 20 minutes and supporting the stable training for uh",
    "start": "2059639",
    "end": "2065358"
  },
  {
    "text": "nearly like a month and also like uh speaking of like the",
    "start": "2065359",
    "end": "2072280"
  },
  {
    "text": "usability of uh in terms of the development we uh just like a revision",
    "start": "2072280",
    "end": "2079079"
  },
  {
    "text": "about like implementation of different modes of parallelism we we can here see that although it's already been",
    "start": "2079079",
    "end": "2085200"
  },
  {
    "text": "simplified we still need to design like the sh strategy which requires knowledge",
    "start": "2085200",
    "end": "2090560"
  },
  {
    "text": "about how the tenses is is s and distributed uh large language model",
    "start": "2090560",
    "end": "2095679"
  },
  {
    "text": "training so is there a case or or is there like a way that we can also just AB abstract away the work of Designing",
    "start": "2095679",
    "end": "2103480"
  },
  {
    "text": "this uh sh strategy and just lets the framework to do all of the jobs and that",
    "start": "2103480",
    "end": "2110320"
  },
  {
    "text": "is that is like the transfer from the semi auto parallelism to the fully auto",
    "start": "2110320",
    "end": "2118000"
  },
  {
    "text": "parallelism so for the fully like for the design of the fully automatic",
    "start": "2118440",
    "end": "2124720"
  },
  {
    "text": "parallelism and we have like a will build a course model based on the",
    "start": "2124720",
    "end": "2129920"
  },
  {
    "text": "compute and communication of the mpus so it will automatically design like which",
    "start": "2129920",
    "end": "2136079"
  },
  {
    "text": "slicing strategies or which modes of the paration we are using and how we uh",
    "start": "2136079",
    "end": "2142000"
  },
  {
    "text": "allocate them in terms of allocate in across devices how we distri how we manage the memory and as well as the",
    "start": "2142000",
    "end": "2149319"
  },
  {
    "text": "commutation and Communications and we'll achieve it by using like the bidirectional regression and we which",
    "start": "2149319",
    "end": "2156359"
  },
  {
    "text": "reduces the search comp complexity from expans to linear so for example for an",
    "start": "2156359",
    "end": "2162640"
  },
  {
    "text": "experienced expert probably takes for example two weeks or even M to design like a suitable like way a suitable",
    "start": "2162640",
    "end": "2169520"
  },
  {
    "text": "design suitable strategy of the paralyzation desp TRS and with like this technique we can reduce it for example",
    "start": "2169520",
    "end": "2176319"
  },
  {
    "text": "just in 10 minutes to automatically search for a strategy that can achieve",
    "start": "2176319",
    "end": "2181599"
  },
  {
    "text": "about 90% of the experts best",
    "start": "2181599",
    "end": "2186359"
  },
  {
    "text": "and finally about just a a brief report about the ecosystem progress of the",
    "start": "2188760",
    "end": "2194280"
  },
  {
    "text": "mindful frame mindful framework we uh since our open sourcing in 2020 we have",
    "start": "2194280",
    "end": "2200440"
  },
  {
    "text": "been focusing on Gathering the strengthes from a large variety including the industries scientific",
    "start": "2200440",
    "end": "2207760"
  },
  {
    "text": "research field and open source Community to develop the EOS system and now we",
    "start": "2207760",
    "end": "2213160"
  },
  {
    "text": "have like about uh 7, 750,000 downloads all over the world and we are",
    "start": "2213160",
    "end": "2219760"
  },
  {
    "text": "also organiz organizing like for example the activities like MP study groups which is uh abbreviated as the msgs",
    "start": "2219760",
    "end": "2227760"
  },
  {
    "text": "across 22 cities not just only in China but also seven other countries globally",
    "start": "2227760",
    "end": "2233440"
  },
  {
    "text": "so we can uh just let let the developers into in personal online uh forms to",
    "start": "2233440",
    "end": "2240560"
  },
  {
    "text": "understand like the artificial intelligence and how to do the development based on mindpool and in",
    "start": "2240560",
    "end": "2246839"
  },
  {
    "text": "terms of like the uh open source ecosystem now we have like 34,000",
    "start": "2246839",
    "end": "2253079"
  },
  {
    "text": "Community uh Community contributors and with also build like building the",
    "start": "2253079",
    "end": "2258319"
  },
  {
    "text": "collaboration of more than five uh 5,500 Enterprise uh clients and we also covers",
    "start": "2258319",
    "end": "2265079"
  },
  {
    "text": "the majority City cities in China by uh participating into for example the",
    "start": "2265079",
    "end": "2271400"
  },
  {
    "text": "commun uh Computing networks and they across some key cities",
    "start": "2271400",
    "end": "2278720"
  },
  {
    "text": "and in terms of like the open source L language models we are supporting because uh currently like our uh our",
    "start": "2279520",
    "end": "2286640"
  },
  {
    "text": "recipe will be just to choose like a pre- mod uh a pre typical pre- model we",
    "start": "2286640",
    "end": "2292760"
  },
  {
    "text": "want to F tune on and to choose like a uh parental efficient fine tuning method",
    "start": "2292760",
    "end": "2300119"
  },
  {
    "text": "with our self-design data set and to try to deploy this finding model across for",
    "start": "2300119",
    "end": "2306480"
  },
  {
    "text": "example the de uh upon like the devices or the phones so to for like the application and for like the uh large",
    "start": "2306480",
    "end": "2314960"
  },
  {
    "text": "language uh large language model for example the mle Transformers to Kit now it is providing like 30 plus pre- models",
    "start": "2314960",
    "end": "2322599"
  },
  {
    "text": "as well as like 10 plus fine tuning algorithms and 10 plus Downstream tasks as shown in this graph and for m one",
    "start": "2322599",
    "end": "2329839"
  },
  {
    "text": "which is for the diffusion based models now it is also supporting like 20 plus prein models with like six plus fine",
    "start": "2329839",
    "end": "2337599"
  },
  {
    "text": "tuning algorithms and six plus stable uh uh sampling algorithms for the inference",
    "start": "2337599",
    "end": "2344119"
  },
  {
    "text": "and 10 plus end to end components for including for example the mix precision",
    "start": "2344119",
    "end": "2349440"
  },
  {
    "text": "and like the data precompute to further optim to uh to do the further",
    "start": "2349440",
    "end": "2354920"
  },
  {
    "text": "optimization and finally we're also doing the compa uh com make like the",
    "start": "2354920",
    "end": "2360599"
  },
  {
    "text": "toolk compatible with the huging face diffuses to lower like the cost of study",
    "start": "2360599",
    "end": "2367040"
  },
  {
    "text": "for a developer which is familiar with the huging fist diffusers so we can use like the same H we can follow the same",
    "start": "2367040",
    "end": "2373599"
  },
  {
    "text": "habit when designing like the overall production workflow using mind uh using",
    "start": "2373599",
    "end": "2379040"
  },
  {
    "text": "mind SP one and finally like this is just uh the",
    "start": "2379040",
    "end": "2385880"
  },
  {
    "text": "information about our official website including like the documents uh",
    "start": "2385880",
    "end": "2391480"
  },
  {
    "text": "introducing the design of the code framework and the uh and the access to",
    "start": "2391480",
    "end": "2398000"
  },
  {
    "text": "the repositories as well as like the repository for the CR framework and the repositories as shown here for like the",
    "start": "2398000",
    "end": "2405359"
  },
  {
    "text": "sees including like the those we mentioned like multile Transformers and multile one and we are welcome we're",
    "start": "2405359",
    "end": "2411760"
  },
  {
    "text": "very welcome to like the developers who ever feel interested to join the myo",
    "start": "2411760",
    "end": "2416880"
  },
  {
    "text": "community and that's all for like uh the for the report and thanks you very much",
    "start": "2416880",
    "end": "2422560"
  },
  {
    "text": "for listening [Applause]",
    "start": "2422560",
    "end": "2431349"
  },
  {
    "text": "okay yes",
    "start": "2433440",
    "end": "2435960"
  },
  {
    "text": "please um thanks for a talk uh can you go back to the slides we'll do op",
    "start": "2441720",
    "end": "2446960"
  },
  {
    "text": "parallel uh yeah just want to check uh do you do uh yeah here here here just go",
    "start": "2446960",
    "end": "2454280"
  },
  {
    "text": "back right so you set uh in in the code at",
    "start": "2454280",
    "end": "2459319"
  },
  {
    "text": "Ops uh mm. Shard so you do sharing on op",
    "start": "2459319",
    "end": "2464720"
  },
  {
    "text": "or do sharting on tensor oh we are doing the sharing on tensor but it is like operating at the level of operators so",
    "start": "2464720",
    "end": "2471200"
  },
  {
    "text": "we just focus on like The Operators as a unit and to consider like the slicing of",
    "start": "2471200",
    "end": "2476720"
  },
  {
    "text": "tenses which are associated with this operator so that's why I call Operator level yeah it's it's bit confusing",
    "start": "2476720",
    "end": "2483680"
  },
  {
    "text": "because like you sh if you do shouting on op then the question is like do you do shouting",
    "start": "2483680",
    "end": "2490280"
  },
  {
    "text": "on the weights on the for example here there might be bias right or you do shouting on the input or the output I'm",
    "start": "2490280",
    "end": "2497520"
  },
  {
    "text": "not sure like uh does this API clarify uh so like to this uh to Define like",
    "start": "2497520",
    "end": "2505640"
  },
  {
    "text": "whether like we are doing shorting for example on the input or for example the weight of bi we are using like we",
    "start": "2505640",
    "end": "2511760"
  },
  {
    "text": "implementing in terms of like this bracket with each bracket corresponding to like for example the tenses",
    "start": "2511760",
    "end": "2517920"
  },
  {
    "text": "associated with this operator so for example like for okay so do you have like uh internal",
    "start": "2517920",
    "end": "2525359"
  },
  {
    "text": "implementation of something uh like d tens equivalence uh for this I guess like",
    "start": "2525359",
    "end": "2532240"
  },
  {
    "text": "it's better to refer to like the official website about like this okay okay uh another question is about um",
    "start": "2532240",
    "end": "2539240"
  },
  {
    "text": "zero you're talking about your implementation of zero so do you have like um some something like torch fsdp w",
    "start": "2539240",
    "end": "2547680"
  },
  {
    "text": "to implement zero or um you kind of like break the functionality of fsdp into the",
    "start": "2547680",
    "end": "2554680"
  },
  {
    "text": "shouting of specific Ops or tensors so for like the zero here or we",
    "start": "2554680",
    "end": "2562680"
  },
  {
    "text": "call like the optimizer like parallelism it's uh it's just like matching with",
    "start": "2562680",
    "end": "2569440"
  },
  {
    "text": "like the third level of zero so is doing like the partitioning of all of like the",
    "start": "2569440",
    "end": "2575040"
  },
  {
    "text": "parameters gradients on optimized States yeah I I know that you have this functionality I mean like do you have um",
    "start": "2575040",
    "end": "2583400"
  },
  {
    "text": "is it a wrapper inside MP set for example something like mp. fsdp and you",
    "start": "2583400",
    "end": "2589920"
  },
  {
    "text": "can use this wrapper to wrap a a TP model or something like that or you",
    "start": "2589920",
    "end": "2595480"
  },
  {
    "text": "break the fstp functionalities into specif uh into the",
    "start": "2595480",
    "end": "2601160"
  },
  {
    "text": "shadings of specific tensors or gradients or parameters oh I see so it's",
    "start": "2601160",
    "end": "2606640"
  },
  {
    "text": "like the implementation is not like for for example doing the Ws so by it's kind",
    "start": "2606640",
    "end": "2611720"
  },
  {
    "text": "of like simple just by adding like this line to enable like the parallel Optimizer and just SL the framework to",
    "start": "2611720",
    "end": "2618200"
  },
  {
    "text": "do the work which might be abstracted away um",
    "start": "2618200",
    "end": "2626359"
  },
  {
    "text": "okay sorry for uh sorry for like the time uh time limit and probably we can",
    "start": "2629960",
    "end": "2635640"
  },
  {
    "text": "if if any of us like have like the questions we can discuss like in person",
    "start": "2635640",
    "end": "2642000"
  },
  {
    "text": "[Applause]",
    "start": "2643380",
    "end": "2646979"
  }
]
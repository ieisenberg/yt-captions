[
  {
    "text": "uh so hello uh my name is Madeline Olsen I'm a member of the redis open source",
    "start": "60",
    "end": "5520"
  },
  {
    "text": "project I'm also a engineer at AWS and today I'm going to be talking a little bit about",
    "start": "5520",
    "end": "11219"
  },
  {
    "text": "how to use redis in Cloud native architectures to build an asynchronous messaging system",
    "start": "11219",
    "end": "17100"
  },
  {
    "text": "and before I talk too much about the agenda I like the motivation for this talk is I know a lot of people use",
    "start": "17100",
    "end": "22920"
  },
  {
    "text": "radius just kind of like quick show Advance who here is aware of what redis is it's like everyone who here thinks rice",
    "start": "22920",
    "end": "28800"
  },
  {
    "text": "is just a cash so those like it's really tailored for you guys",
    "start": "28800",
    "end": "34920"
  },
  {
    "text": "um which is that a lot of people know just like they don't know what else Reds can do and they often think about it's just",
    "start": "34920",
    "end": "40559"
  },
  {
    "text": "like an ephemeral data store you throw data in it and it can go away so um the specific use case I'm going to",
    "start": "40559",
    "end": "46920"
  },
  {
    "text": "dive deep into today um is the event broker kind of design pattern so I'll start kind of",
    "start": "46920",
    "end": "53160"
  },
  {
    "text": "introducing that explain how it works in traditional service oriented architectures fan I'll kind of give a pseudo",
    "start": "53160",
    "end": "60239"
  },
  {
    "text": "introduction to redis it seems like most people know so I won't go too deep but kind of talk a little bit about why it's",
    "start": "60239",
    "end": "65760"
  },
  {
    "text": "good at what it does um not talk too much about what it is and then kind of put Radisson to this",
    "start": "65760",
    "end": "72540"
  },
  {
    "text": "architecture we're talking about and see how it actually kind of fits the that role and then I'll show kind of a simple",
    "start": "72540",
    "end": "79920"
  },
  {
    "text": "toy application kind of putting everything together um and I'll close off with some best practices and then we'll hopefully have",
    "start": "79920",
    "end": "85740"
  },
  {
    "text": "some time for some q a if people have questions great so",
    "start": "85740",
    "end": "91938"
  },
  {
    "text": "um why like what why do people need message Brokers So In traditional service oriented architectures you",
    "start": "92159",
    "end": "98640"
  },
  {
    "text": "basically have a lot of different services and they're all talking to each other with tightly coupled apis um this works pretty well",
    "start": "98640",
    "end": "105180"
  },
  {
    "text": "um some people I know Amazon is well known for having this very complex service oriented architecture because",
    "start": "105180",
    "end": "110340"
  },
  {
    "text": "they used to have this big monolith had lots of problems so they broke everything up so service oriented",
    "start": "110340",
    "end": "115619"
  },
  {
    "text": "architecture is great the problem starts to stem when that starts to get very complex right when you have one service",
    "start": "115619",
    "end": "120780"
  },
  {
    "text": "calling lots of other services you end up with you know dependency hell and a very high latency as all these services",
    "start": "120780",
    "end": "127619"
  },
  {
    "text": "start chaining together um you also start seeing issues with being able to maintain slas as when one",
    "start": "127619",
    "end": "135599"
  },
  {
    "text": "of these microservices fail the whole architecture might stop working so the idea behind that",
    "start": "135599",
    "end": "141660"
  },
  {
    "text": "um to solve this is like uh either a message brokering architecture so the idea behind here is you do all your",
    "start": "141660",
    "end": "147840"
  },
  {
    "text": "synchronous work and then you just record an event that all the other services eventually read and then they",
    "start": "147840",
    "end": "153599"
  },
  {
    "text": "you know take their actions based on that so this breaks the tight coupling you",
    "start": "153599",
    "end": "158640"
  },
  {
    "text": "still have some coupling since these messages need to be still well formed so all of the downstream consumer services",
    "start": "158640",
    "end": "166500"
  },
  {
    "text": "know what's going on um but it solves kind of those two major problems we had before",
    "start": "166500",
    "end": "171660"
  },
  {
    "text": "so the first is now we get back to having super low latency since all we have to do is do our synchronous work and then record the event into the event",
    "start": "171660",
    "end": "178019"
  },
  {
    "text": "uh the message broker and then we also have much better API slas since um we're just now dependent",
    "start": "178019",
    "end": "185340"
  },
  {
    "text": "on the synchronous work and all of the asynchronous work kind of can just happen in the background if a service dies it doesn't affect the main apis",
    "start": "185340",
    "end": "193680"
  },
  {
    "text": "so if you were to have you know an e-commerce website you want to make sure those orders are going through and if",
    "start": "193680",
    "end": "199440"
  },
  {
    "text": "you're doing some of the non-essential work that can always happen later so when you have a message uh broker",
    "start": "199440",
    "end": "206819"
  },
  {
    "text": "architecture it becomes very easy to scale and add more services in since you just need to Define how these Services consume sort",
    "start": "206819",
    "end": "213360"
  },
  {
    "text": "of from this main message bus um and for the rest of talk I'm going to talk about these message bus in two",
    "start": "213360",
    "end": "218760"
  },
  {
    "text": "different forms the first is what I'm going to call an authoritative log so an authoritative log you basically have a",
    "start": "218760",
    "end": "224099"
  },
  {
    "text": "single stream of every single message that ever was produced as part of this",
    "start": "224099",
    "end": "229920"
  },
  {
    "text": "message bus and so if you just want to set me up a new service let's say we have some new",
    "start": "229920",
    "end": "234959"
  },
  {
    "text": "business intelligence that needs to know like what's going on it's able to basically go back in time",
    "start": "234959",
    "end": "241140"
  },
  {
    "text": "start from the beginning of the log consume everything to the head of the log and basically bootstrap as a new service",
    "start": "241140",
    "end": "247500"
  },
  {
    "text": "so this is one type of good use case the other really common use case I've",
    "start": "247500",
    "end": "252780"
  },
  {
    "text": "seen and it's pretty common with redis and with a lot of our customers is what I call like ephemeral logs so the best",
    "start": "252780",
    "end": "260299"
  },
  {
    "text": "frame for this is that you could lose a message and so that's a lot of people get kind",
    "start": "260299",
    "end": "266340"
  },
  {
    "text": "of scared of that they're like why would I want to lose a message from a log and the best place to think about this is if late events are the same as the",
    "start": "266340",
    "end": "273600"
  },
  {
    "text": "message not showing up at all if you have some type of you know maybe you're delivering some type of package and that",
    "start": "273600",
    "end": "280500"
  },
  {
    "text": "you're trying to give like real-time updates to the end user you want to give a real-time update of where that package is if you're going to deliver two days",
    "start": "280500",
    "end": "287160"
  },
  {
    "text": "late they don't care anymore you can just have basically the same has dropped it um there's some other interesting use",
    "start": "287160",
    "end": "293220"
  },
  {
    "text": "cases like maybe you're okay with inconsistencies between your services because you have some background reconciliation",
    "start": "293220",
    "end": "300300"
  },
  {
    "text": "storing data durably is relatively expensive comparing to storing stuff sort of as a best effort so if you're",
    "start": "300300",
    "end": "306720"
  },
  {
    "text": "okay with periodic drift and you have some mechanism reconcile it then that's a good maybe use case for having",
    "start": "306720",
    "end": "311940"
  },
  {
    "text": "something more ephemeral okay so those are sort of like the main",
    "start": "311940",
    "end": "317520"
  },
  {
    "text": "basics of how you have a message broker so what type of data store do we want to use for this",
    "start": "317520",
    "end": "323639"
  },
  {
    "text": "ideally we want to support those two different types of cases the authoritative log case and the ephemeral",
    "start": "323639",
    "end": "329220"
  },
  {
    "text": "case we want to be highly performed and scalable those are you know Cloud native we want",
    "start": "329220",
    "end": "335699"
  },
  {
    "text": "everything to be performed and scalable and we want to be able to",
    "start": "335699",
    "end": "341400"
  },
  {
    "text": "support different types of events so not something that's too specific to one individual use case and can Shard to",
    "start": "341400",
    "end": "347699"
  },
  {
    "text": "different individual types of logs you don't want to be if you have one specific log that holds all",
    "start": "347699",
    "end": "352860"
  },
  {
    "text": "your data it'll eventually become the bottleneck for your service and of course",
    "start": "352860",
    "end": "358199"
  },
  {
    "text": "we're at kubernetes conference we want to be industry standard and we would love open apis so with that I'm going to suggest redis",
    "start": "358199",
    "end": "365699"
  },
  {
    "text": "as a good way um to solve that problem uh I know a couple people said they didn't know what rest is but res is a",
    "start": "365699",
    "end": "372360"
  },
  {
    "text": "fast and simple in-memory First Data store uh it's completely open source as I",
    "start": "372360",
    "end": "377699"
  },
  {
    "text": "mentioned I'm one of the maintainers we love active we have a very active Community we're still building a lot",
    "start": "377699",
    "end": "383340"
  },
  {
    "text": "with inside the and we're still releasing new versions so the main trade off the rest kind of",
    "start": "383340",
    "end": "390180"
  },
  {
    "text": "thinks about is that it stores everything in memory first and then optionally will persist stuff to disk so",
    "start": "390180",
    "end": "396300"
  },
  {
    "text": "it doesn't try to expose many trade-offs for end users right so it's not one of",
    "start": "396300",
    "end": "401759"
  },
  {
    "text": "those applications that will try to make it as easy for the uh consumer to the client to use but it wants to make it",
    "start": "401759",
    "end": "407819"
  },
  {
    "text": "like predictably high performance is also well known to be very flexible",
    "start": "407819",
    "end": "413819"
  },
  {
    "text": "there's lots of data structures and we'll be talking about one of those specifically today and it also has high availability and",
    "start": "413819",
    "end": "420720"
  },
  {
    "text": "various forms of durability so the main framing I want us to use for res today is that it's that it's that",
    "start": "420720",
    "end": "427560"
  },
  {
    "text": "basically a it's a API for shared data um and you can build applications on top",
    "start": "427560",
    "end": "433020"
  },
  {
    "text": "of it right so if you have one client who writes data everyone else can read from it so if that's the one frame you",
    "start": "433020",
    "end": "438479"
  },
  {
    "text": "take away like that's what I kind of want for the rest of the talk um I know most people you know raise",
    "start": "438479",
    "end": "444840"
  },
  {
    "text": "their hands when I mentioned right it says cash this is what by and large everyone uses reddits for",
    "start": "444840",
    "end": "450720"
  },
  {
    "text": "um the idea being that since Fridays is in memory first and not necessarily durable you're able to do expensive",
    "start": "450720",
    "end": "456539"
  },
  {
    "text": "operations take the result of it and then stick it in redis and then when your application goes and",
    "start": "456539",
    "end": "462479"
  },
  {
    "text": "tries to do that same operation again it's able to first check for redis so this is by far the traditional use",
    "start": "462479",
    "end": "468660"
  },
  {
    "text": "case for redis and this works great without durability without replication and fits into a lot of uh",
    "start": "468660",
    "end": "475740"
  },
  {
    "text": "service warranty architectures the use case I'm trying to push more for",
    "start": "475740",
    "end": "481319"
  },
  {
    "text": "Reddit is generally is this idea of Beyond caching which incorporates a",
    "start": "481319",
    "end": "486599"
  },
  {
    "text": "bunch of different aspects but one specific I want to talk about is data projection so this sort of fits into",
    "start": "486599",
    "end": "491699"
  },
  {
    "text": "this message book we talked about earlier where you have a primary database and it emits a series of logs",
    "start": "491699",
    "end": "496800"
  },
  {
    "text": "based for the updates from that um that like for mutations and the rest is able to consume those updates",
    "start": "496800",
    "end": "503580"
  },
  {
    "text": "and then project the some form of the data into redis so the the authoritative data still comes from redis sorry it",
    "start": "503580",
    "end": "510720"
  },
  {
    "text": "still comes from the backend database in this case I'm using postgres everywhere um and if Reds were to die you'd",
    "start": "510720",
    "end": "517620"
  },
  {
    "text": "basically be able to go back to the postgres database reproject all the data um",
    "start": "517620",
    "end": "522959"
  },
  {
    "text": "and Eventing works really great in this case right so one of the things that science was rested as periodic backups",
    "start": "522959",
    "end": "529019"
  },
  {
    "text": "so you can basically take an entire snapshot of the data set save it to disk and then restore that snapshot so if you",
    "start": "529019",
    "end": "535320"
  },
  {
    "text": "keep track of where you are in the updates from the message uh bus you're able to like restart from that point in",
    "start": "535320",
    "end": "541200"
  },
  {
    "text": "time so res is a great is already great in message bus systems",
    "start": "541200",
    "end": "547560"
  },
  {
    "text": "um and I'd like to argue that can also be great for actual the message bus itself so",
    "start": "547560",
    "end": "553620"
  },
  {
    "text": "um what types of functionality does rats have to build messaging so there are two",
    "start": "553620",
    "end": "560899"
  },
  {
    "text": "there could theoretically be a third but there's usually two main use cases that res has that people use the first is",
    "start": "560899",
    "end": "567240"
  },
  {
    "text": "what's called Pub sub so publish And subscribe clients are able to subscribe to channels inside",
    "start": "567240",
    "end": "573120"
  },
  {
    "text": "redis and when messages get published to those channels rather than broadcast the messages to all the various consumers of",
    "start": "573120",
    "end": "580260"
  },
  {
    "text": "that channel so you might see here this doesn't work at all for authoritative Vlogs it's",
    "start": "580260",
    "end": "585600"
  },
  {
    "text": "really just targeting that sort of ephemeral workload and it's really targeting just making it as simple as possible because there's no data being",
    "start": "585600",
    "end": "592019"
  },
  {
    "text": "stored within redis it's just immediately broadcasting it out so it's really good for",
    "start": "592019",
    "end": "597720"
  },
  {
    "text": "um the normal thinking about res where you don't really have any type of schema you just pushed it in broadcast the data out and then you kind of forget about it",
    "start": "597720",
    "end": "603980"
  },
  {
    "text": "firing forgets often used to describe Pub sub um the second data structure which was",
    "start": "603980",
    "end": "610560"
  },
  {
    "text": "released in redness five which it's like four years old now as what's called red streams so red",
    "start": "610560",
    "end": "618060"
  },
  {
    "text": "streams took a live uh inspiration from Kafka and is basically a uh append Only",
    "start": "618060",
    "end": "624240"
  },
  {
    "text": "log of data so that's this sort of fits more into our our Paradigm we just had of of an authoritative log",
    "start": "624240",
    "end": "631680"
  },
  {
    "text": "so you put a bunch of events in redis and then you're able to cooperatively consume them through what's called",
    "start": "631680",
    "end": "637920"
  },
  {
    "text": "consumer groups or an individual client can basically keep track of where they are um and then keep reading from that point",
    "start": "637920",
    "end": "644459"
  },
  {
    "text": "in time this data will need to eventually be trimmed out of redis",
    "start": "644459",
    "end": "650880"
  },
  {
    "text": "cool so um so how do these two actually look most everything in redis uses commands",
    "start": "650880",
    "end": "658079"
  },
  {
    "text": "it doesn't have any query language like something like SQL so in this case we have a command called xad which is",
    "start": "658079",
    "end": "663540"
  },
  {
    "text": "responsible for adding data into streams um so you have a stream name and it has",
    "start": "663540",
    "end": "669060"
  },
  {
    "text": "a corresponding unique ID that's generated uh you can also for us to generate a stream automatic uh sorry",
    "start": "669060",
    "end": "674399"
  },
  {
    "text": "stream ID automatically for you when you push the message so in this case we're pushing a message",
    "start": "674399",
    "end": "680959"
  },
  {
    "text": "that says message hello into a stream called My Stream and it produces a unique identifier when you push in the",
    "start": "680959",
    "end": "687300"
  },
  {
    "text": "redis and then the consumers are able to pull",
    "start": "687300",
    "end": "692820"
  },
  {
    "text": "this data out and then also as I said earlier there's um so it's x-rayed if you're just",
    "start": "692820",
    "end": "699060"
  },
  {
    "text": "consuming it yourself or you can cooperatively consume stuff the demo I'll show in a second is going to show this Cooperative consumption of data",
    "start": "699060",
    "end": "707779"
  },
  {
    "text": "um and then similarly we have the pub sub system which does something very similar but since kind of in the reverse",
    "start": "708540",
    "end": "714060"
  },
  {
    "text": "so consumers are the ones that start the transaction they say hey I would like to subscribe to this channel and then when messages are published",
    "start": "714060",
    "end": "720600"
  },
  {
    "text": "into the channel uh everyone's able to get basically how many messages were broadcast and everyone that got the",
    "start": "720600",
    "end": "726120"
  },
  {
    "text": "consumers so with these two data structures we're able to basically kind of stick right as where it was before right where the",
    "start": "726120",
    "end": "732240"
  },
  {
    "text": "message broker was way back when the early part of the stock so streams provide the good",
    "start": "732240",
    "end": "737880"
  },
  {
    "text": "authoritative log as well as can be used for the ephemeral uh logs that we talked about and Pub sub can also then be used",
    "start": "737880",
    "end": "744060"
  },
  {
    "text": "as part of the ephemeral use case as well so we mentioned before that we also needed um some type of partitioning of",
    "start": "744060",
    "end": "751200"
  },
  {
    "text": "streams so rennis has a deployment called rest cluster mode which is a natively sharded deployment",
    "start": "751200",
    "end": "757800"
  },
  {
    "text": "and it then partitions the data by the crc16 of either the name which can",
    "start": "757800",
    "end": "762899"
  },
  {
    "text": "either be the channel name or the name of the Stream",
    "start": "762899",
    "end": "768540"
  },
  {
    "text": "so that's all well and good but there is still an elephant in the room that haven't really talked super",
    "start": "768540",
    "end": "774060"
  },
  {
    "text": "too much about it's not postgres I do like postgres postgres was known to be the most loved database which stole away",
    "start": "774060",
    "end": "780660"
  },
  {
    "text": "redis's title but it's actually durability of data so most people think",
    "start": "780660",
    "end": "785700"
  },
  {
    "text": "redis is not durable and for the vast majority of people that actually use res it's not it's not right people deploy it",
    "start": "785700",
    "end": "792060"
  },
  {
    "text": "without um any mechanism of strong durability so the default configuration of redis is",
    "start": "792060",
    "end": "798540"
  },
  {
    "text": "that even if you had repl replicas even if you had the built-in mechanism called aof",
    "start": "798540",
    "end": "804180"
  },
  {
    "text": "um which is the appendally log most people use aof without a very specific flag",
    "start": "804180",
    "end": "809880"
  },
  {
    "text": "which is absync every right which means that before we acknowledge any right to a client we will actually make sure it's",
    "start": "809880",
    "end": "816120"
  },
  {
    "text": "persisted to disk and even in that case if it's only persistent one disk it's not super durable so even though most",
    "start": "816120",
    "end": "824040"
  },
  {
    "text": "people don't use res durably it does have ways to be used arably you can do you can set up in such a way so you're",
    "start": "824040",
    "end": "830639"
  },
  {
    "text": "actually appsyncing to multiple different disks and then you have to build some type of mechanism to restore that after node",
    "start": "830639",
    "end": "837360"
  },
  {
    "text": "failure so rice has not particularly great at being durable but it can be so",
    "start": "837360",
    "end": "843360"
  },
  {
    "text": "um it can be used as its authority of long because it's still good at that high throughput high efficiency type workloads",
    "start": "843360",
    "end": "849720"
  },
  {
    "text": "um so I will argue that it can be used for that and in many cases using a durable store for an event bus is better",
    "start": "849720",
    "end": "856860"
  },
  {
    "text": "than using an ephemeral store because it makes it simple you don't have to worry too much about messages not getting delivered but a lot of event Bridges",
    "start": "856860",
    "end": "863760"
  },
  {
    "text": "inherently assume like some type of item potency or having to Think Through you know how",
    "start": "863760",
    "end": "870420"
  },
  {
    "text": "to handle at least once or at most once type of messages so the ephemeral workload still you still have to solve a",
    "start": "870420",
    "end": "876000"
  },
  {
    "text": "lot of the same problems so even though if you're not using durable rest can still work pretty well as an event bus",
    "start": "876000",
    "end": "883380"
  },
  {
    "text": "in either mode and there is also multiple managed providers that provide redis like apis",
    "start": "883380",
    "end": "889680"
  },
  {
    "text": "that do provide durability so if you don't want to self-manage durability there are there are still options and",
    "start": "889680",
    "end": "895199"
  },
  {
    "text": "you're still able to you know do all the local testing because you have the open source project to test against",
    "start": "895199",
    "end": "901019"
  },
  {
    "text": "cool so best practices for redis at scale",
    "start": "901019",
    "end": "906480"
  },
  {
    "text": "um as I mentioned briefly redis has a shared nothing partitioning scheme when you use it in its clustered",
    "start": "906480",
    "end": "911959"
  },
  {
    "text": "configuration you can typically get between 100 150 000 operations per like",
    "start": "911959",
    "end": "918180"
  },
  {
    "text": "process per core um in typical non-durable configurations it falls to between like 60 to 100",
    "start": "918180",
    "end": "925079"
  },
  {
    "text": "000 operations per second in more durable configurations but you can scale up to about a thousand",
    "start": "925079",
    "end": "930959"
  },
  {
    "text": "different shards which gives somewhere around like 50 to 150 million operations",
    "start": "930959",
    "end": "936300"
  },
  {
    "text": "per second which is pretty much higher than anyone I've ever seen practically used we have a couple of customers AWS",
    "start": "936300",
    "end": "943139"
  },
  {
    "text": "who kind of get close to those numbers but practically it there's plenty of scaling room as long as you have a good",
    "start": "943139",
    "end": "949260"
  },
  {
    "text": "way to Shard the data um starting with redis 7 we actually introduced",
    "start": "949260",
    "end": "954779"
  },
  {
    "text": "um what's called chartered Pub sub in the olden days before red is seven there was no good charting for Pub sub",
    "start": "954779",
    "end": "960300"
  },
  {
    "text": "messages so in round seven not that's more or less been fixed that was contributed by AWS",
    "start": "960300",
    "end": "967880"
  },
  {
    "text": "um and then also if you want High availability for your data a high availability is not as important for",
    "start": "968220",
    "end": "974940"
  },
  {
    "text": "event buses because if you kind of take an outage for a while and bring up a new node",
    "start": "974940",
    "end": "980339"
  },
  {
    "text": "um it will still like that you have that built-in slack because you don't need the synchronous operation so it's not as",
    "start": "980339",
    "end": "986940"
  },
  {
    "text": "important um but you should understand like when you actually do need it",
    "start": "986940",
    "end": "992579"
  },
  {
    "text": "and if you think about if you're adding replicas you're really optimizing for that case when failures do happen and 99",
    "start": "992579",
    "end": "999600"
  },
  {
    "text": "of the time they aren't happening so you're paying that cost so just be very deliberate about choosing to run with",
    "start": "999600",
    "end": "1004759"
  },
  {
    "text": "replication and then the important thing about rest is it does not try to solve heart hotkeys or hot channels for you so if",
    "start": "1004759",
    "end": "1012800"
  },
  {
    "text": "you do end up funneling too much data into one Shard um that Shard will get overwhelmed and you'll have problems so",
    "start": "1012800",
    "end": "1019639"
  },
  {
    "text": "and rest as I said before it just doesn't try to solve those problems for you",
    "start": "1019639",
    "end": "1025938"
  },
  {
    "text": "uh then as I mentioned before um the when you're using an",
    "start": "1025939",
    "end": "1031520"
  },
  {
    "text": "authoritative log eventually you'll need to trim data um so in that case you'll typically take",
    "start": "1031520",
    "end": "1036558"
  },
  {
    "text": "the hot date and keep in redis reddis as I said memory in memory first all the data is stored in memory so you don't",
    "start": "1036559",
    "end": "1043819"
  },
  {
    "text": "actually want that because that's expensive so you eventually want to tear it to disk so most people running with this will want to have some type of",
    "start": "1043819",
    "end": "1049400"
  },
  {
    "text": "system to take the data from rather than memory and then spill its disk",
    "start": "1049400",
    "end": "1054500"
  },
  {
    "text": "ideally magnetic Drive ssds can work but it's usually not as needed and then",
    "start": "1054500",
    "end": "1060200"
  },
  {
    "text": "time-based events for ephemeral logs can usually just be trimmed based on capacity or time kind of based on what",
    "start": "1060200",
    "end": "1065840"
  },
  {
    "text": "you want um the red snapshotting mechanism I talked about a little bit earlier can also work kind of well here",
    "start": "1065840",
    "end": "1073640"
  },
  {
    "text": "if your data is set up in such a way that the events all sort of can get conducted together and put into the end",
    "start": "1073640",
    "end": "1078919"
  },
  {
    "text": "at like an end State like if you have multiple different values you're like continually updating it we're at a",
    "start": "1078919",
    "end": "1084620"
  },
  {
    "text": "snapshot's probably a good way to sort of compact all the logs events together so you can kind of stick it on disk and then restore that that's a little bit",
    "start": "1084620",
    "end": "1091220"
  },
  {
    "text": "more specific um it depends a little bit on your use case so I've been talking a lot about just",
    "start": "1091220",
    "end": "1096440"
  },
  {
    "text": "about redis but since res is an open source project um and is one of the most downloaded res",
    "start": "1096440",
    "end": "1102679"
  },
  {
    "text": "uh sorry Docker containers it has a lot of support for all the cncf projects",
    "start": "1102679",
    "end": "1107740"
  },
  {
    "text": "I'll specifically talking a bunch about how it integrates with Prometheus what type of metrics to look at to make sure",
    "start": "1107740",
    "end": "1113960"
  },
  {
    "text": "it doesn't kind of explode because I said it's like it's a lot of people think of it's kind of like a race car",
    "start": "1113960",
    "end": "1119059"
  },
  {
    "text": "like can go really fast but if you kind of drift a little too much it just piles on and explodes so it's very important",
    "start": "1119059",
    "end": "1125720"
  },
  {
    "text": "to make sure you kind of understand those failure modes cool so with that I'm going to walk",
    "start": "1125720",
    "end": "1131480"
  },
  {
    "text": "through a short little demo and kind of walk through how you can actually use redis in this configuration",
    "start": "1131480",
    "end": "1138940"
  },
  {
    "text": "if it works there we go cool all right and I have internet so this is",
    "start": "1141559",
    "end": "1147620"
  },
  {
    "text": "all working oh cool everything's connected um so in this example there will be",
    "start": "1147620",
    "end": "1153980"
  },
  {
    "text": "three main components we'll be talking about there's going to be a web app a queue that's consuming data",
    "start": "1153980",
    "end": "1159440"
  },
  {
    "text": "and a generator of data that we'll throw a load in a second I actually don't want this thing",
    "start": "1159440",
    "end": "1164900"
  },
  {
    "text": "generating consuming any load for that seconds I'll turn that off",
    "start": "1164900",
    "end": "1170140"
  },
  {
    "text": "um some people might ask one of my favorite things is just that like I love kubernetes it's so nice to use",
    "start": "1170360",
    "end": "1176179"
  },
  {
    "text": "I've been so long as a database engineer that's I forgot that some things can actually be nice",
    "start": "1176179",
    "end": "1182360"
  },
  {
    "text": "riding in C all the time I'm used to things being painful um",
    "start": "1182360",
    "end": "1187580"
  },
  {
    "text": "cool so um so the main part of this is we have a",
    "start": "1187580",
    "end": "1192860"
  },
  {
    "text": "very simple web application it's built in flask and so you know we have some configurations set the rest",
    "start": "1192860",
    "end": "1199100"
  },
  {
    "text": "connection yada yada if people want I could I can I was planning on posting",
    "start": "1199100",
    "end": "1204799"
  },
  {
    "text": "this at some point in the future um just to sort of emphasize this",
    "start": "1204799",
    "end": "1210520"
  },
  {
    "text": "um so there's there's a bunch of contents up here they're good to know about um all of our events are going to have a very specific schema you should probably",
    "start": "1210860",
    "end": "1217160"
  },
  {
    "text": "use something more like protobuf or something but I wanted this because it's a little bit more readable to at least follow and you once you use prototype",
    "start": "1217160",
    "end": "1224120"
  },
  {
    "text": "everything kind of gets lost so this is a very simple web API that",
    "start": "1224120",
    "end": "1229640"
  },
  {
    "text": "basically implements an order functionality so we do some you know on marshalling of the data get the",
    "start": "1229640",
    "end": "1235160"
  },
  {
    "text": "arguments out uh create an object on top of it and then all like this is the main operation we do we just do an X ad",
    "start": "1235160",
    "end": "1242360"
  },
  {
    "text": "um you'll see I do in a batch um redis is a little bit more performant when you send a bunch of argument commands together",
    "start": "1242360",
    "end": "1248480"
  },
  {
    "text": "I do this just for some monitoring aspects later in a newer version of rice",
    "start": "1248480",
    "end": "1254539"
  },
  {
    "text": "it'll be much easier to see the size of streams but right now there isn't so I have to keep track of that all manually",
    "start": "1254539",
    "end": "1259700"
  },
  {
    "text": "so not super important but as you can see here the only thing we're doing in this order operation is just putting an",
    "start": "1259700",
    "end": "1265039"
  },
  {
    "text": "item in the Stream in the real world we'd probably want to be doing other synchronous work making",
    "start": "1265039",
    "end": "1270440"
  },
  {
    "text": "sure we have capacity making sure the user is authenticated but that's all you know business logic will figure that out",
    "start": "1270440",
    "end": "1276200"
  },
  {
    "text": "kind of in a second um and what are we doing with this we're putting in a stream and then we'll have",
    "start": "1276200",
    "end": "1282380"
  },
  {
    "text": "two consumers for this the first consumer will be showing the last item this user has purchased and the second",
    "start": "1282380",
    "end": "1289039"
  },
  {
    "text": "is we will be showing the overall top sellers for this given operation",
    "start": "1289039",
    "end": "1294740"
  },
  {
    "text": "okay so let's quickly make sure this is all working not that one this one",
    "start": "1294740",
    "end": "1300020"
  },
  {
    "text": "so let's buy an item make sure it's not working",
    "start": "1300020",
    "end": "1304720"
  },
  {
    "text": "okay and so we got the basically the stream ID that was generated as well as the size of the cues that were generated",
    "start": "1305059",
    "end": "1313580"
  },
  {
    "text": "so I mentioned before all this data is being ingested into Prometheus I can prove that it's you know actually",
    "start": "1313580",
    "end": "1319520"
  },
  {
    "text": "through Prometheus it's over here everything's up um we have a redis exporter which is",
    "start": "1319520",
    "end": "1325159"
  },
  {
    "text": "generating metrics from redis and then we have a custom exporter and that web app that's basically jungle latency",
    "start": "1325159",
    "end": "1333340"
  },
  {
    "text": "um so we have one item in the queue it's not being processed it's been unconsumed we have a log size I put putting some",
    "start": "1333500",
    "end": "1340940"
  },
  {
    "text": "data in here earlier so it's non-zero but it's there and we're seeing latency about four to five milliseconds a lot of",
    "start": "1340940",
    "end": "1347600"
  },
  {
    "text": "people are used to write as being sub milliseconds but I'm using rice in a more durably stored configuration so we're actually running to three separate",
    "start": "1347600",
    "end": "1353720"
  },
  {
    "text": "azs inside AWS which takes a little bit more time so that all looks great",
    "start": "1353720",
    "end": "1360500"
  },
  {
    "text": "oops not fair so I'm going to go ahead and we're also going to start putting some load on here",
    "start": "1360500",
    "end": "1367400"
  },
  {
    "text": "let's load um I'm thinking about shoes I want to show that uh this kind of the cubes kind",
    "start": "1367400",
    "end": "1373760"
  },
  {
    "text": "of keep growing and then once everything is all scaled up we'll add some consumers of the data",
    "start": "1373760",
    "end": "1382840"
  },
  {
    "text": "wow this refresh a little bit more regularly oh uh yeah one other thing I wanted to show you was that uh I can",
    "start": "1385820",
    "end": "1391340"
  },
  {
    "text": "prove that this actually hasn't been consuming yet um because his history is still empty",
    "start": "1391340",
    "end": "1398419"
  },
  {
    "text": "because we the consumer of the data has not consumed the data so while everything is soaring to start up I'll",
    "start": "1398419",
    "end": "1403640"
  },
  {
    "text": "quickly show what the consumers look like consumer the consumers are really simple",
    "start": "1403640",
    "end": "1409580"
  },
  {
    "text": "so we have uh down here we have a function that we're calling basically when an item actually gets processed so",
    "start": "1409580",
    "end": "1416659"
  },
  {
    "text": "we're using we're still using rats for everything because why not we're using a sword set to keep track of the top selling items and then we're just",
    "start": "1416659",
    "end": "1423380"
  },
  {
    "text": "storing the last purchased item in a hash value",
    "start": "1423380",
    "end": "1428960"
  },
  {
    "text": "so going back and talking a little bit what we said before we're going to use the X group",
    "start": "1428960",
    "end": "1434200"
  },
  {
    "text": "commands which are the Cooperative consumers so we can have multiple different nudes consuming multiple",
    "start": "1434200",
    "end": "1439580"
  },
  {
    "text": "different nodes consuming data so being very unread is like you actually have to call an explicit",
    "start": "1439580",
    "end": "1446059"
  },
  {
    "text": "function to do X group creates and have to like catch exceptions if you do it multiple times typically redis is very schema-less but",
    "start": "1446059",
    "end": "1453200"
  },
  {
    "text": "not in this case um we're still trying to work on a better way to do that but we'll figure out eventually",
    "start": "1453200",
    "end": "1459679"
  },
  {
    "text": "so how do we actually consume the data we have the X group read commands so we",
    "start": "1459679",
    "end": "1464780"
  },
  {
    "text": "have uh every stream so we have the stream name here and then we have the worker name",
    "start": "1464780",
    "end": "1471080"
  },
  {
    "text": "which is the oops so the group is created on a stream and then you read from a group and so that",
    "start": "1471080",
    "end": "1477200"
  },
  {
    "text": "makes sure that uh every message within the stream is only delivered once",
    "start": "1477200",
    "end": "1482559"
  },
  {
    "text": "so uh lots of fun stuff here there's some just Plumbing to basically bootstrap a",
    "start": "1482600",
    "end": "1488360"
  },
  {
    "text": "node it hasn't consumed anything this just means start consuming from the beginning um and then we're consuming up to 500",
    "start": "1488360",
    "end": "1494539"
  },
  {
    "text": "elements and we're weighing one second in case there is no items currently in the Stream",
    "start": "1494539",
    "end": "1500480"
  },
  {
    "text": "um the other interesting case we have to cover is when an item gets every item that's read from a group has to be",
    "start": "1500480",
    "end": "1506360"
  },
  {
    "text": "acknowledged and if an item is dropped we need someone to go and claim it so we have a separate command called X auto claim which will allow you to actually",
    "start": "1506360",
    "end": "1512840"
  },
  {
    "text": "claim commands which aren't owned if they're idle for at least one uh one seconds and this does mean in this configuration",
    "start": "1512840",
    "end": "1519380"
  },
  {
    "text": "we're doing it most once since a node could have read an item gone off not you know done whatever been",
    "start": "1519380",
    "end": "1526880"
  },
  {
    "text": "disconnected for more than a second kubernetes might have not killed it let it keep running and then it would come",
    "start": "1526880",
    "end": "1532820"
  },
  {
    "text": "back and acknowledge that it's done the work so in this case everything should more or less be item potent",
    "start": "1532820",
    "end": "1539139"
  },
  {
    "text": "um so let's see did this thing run okay so at least we know everything's now running um so let's go back looking here so we",
    "start": "1540320",
    "end": "1545900"
  },
  {
    "text": "have we can see that the number of elements is steadily growing with the log size keeps growing up and up and up we've",
    "start": "1545900",
    "end": "1552200"
  },
  {
    "text": "added we've been continually adding names to the log and the unconsumed message uh kind of",
    "start": "1552200",
    "end": "1557539"
  },
  {
    "text": "ticked up for a second and that's because we started the producers faster than the consumers",
    "start": "1557539",
    "end": "1562700"
  },
  {
    "text": "and I kind of came back down it's been hovering around zero not quite zero",
    "start": "1562700",
    "end": "1568039"
  },
  {
    "text": "I will say also this metric is not quite accurate but I was too afraid to fix it",
    "start": "1568039",
    "end": "1573559"
  },
  {
    "text": "right before the demo so it's it drifts a little bit um and then this pending queue size",
    "start": "1573559",
    "end": "1579679"
  },
  {
    "text": "shows the number of outstanding messages so the one last thing I kind of want to",
    "start": "1579679",
    "end": "1585140"
  },
  {
    "text": "show is if we go and then kill the uh let's increase the number of load",
    "start": "1585140",
    "end": "1591740"
  },
  {
    "text": "generators because we want to show that um you know if the queue starts growing over time you kind of want to start",
    "start": "1591740",
    "end": "1597260"
  },
  {
    "text": "setting um alarms on that to do",
    "start": "1597260",
    "end": "1603200"
  },
  {
    "text": "it's not that uh this one",
    "start": "1603200",
    "end": "1610059"
  },
  {
    "text": "um I talked a bit about you know how to make sure you're alarming um you definitely want to make sure you have if you're not consuming messages",
    "start": "1612860",
    "end": "1618620"
  },
  {
    "text": "you need some type of lump on that so it depends on you know you should figure out your application to figure out how fast you can consume messages and figure",
    "start": "1618620",
    "end": "1624799"
  },
  {
    "text": "out how long you're willing to tolerate messages not being consumed because once the qsr gets too long it will take a",
    "start": "1624799",
    "end": "1631640"
  },
  {
    "text": "long time for it to actually drain back out and you can have other problems as well that aren't immediately obvious in your system",
    "start": "1631640",
    "end": "1638320"
  },
  {
    "text": "um there's actually been a lot of very notable AWS events aided with outages that are basically this problem",
    "start": "1638360",
    "end": "1644419"
  },
  {
    "text": "um where you have a huge backlog of items and you're not able to effectively process them",
    "start": "1644419",
    "end": "1649460"
  },
  {
    "text": "um there's one interesting Paradigm inside AWS where if you're falling too far behind what you should start doing",
    "start": "1649460",
    "end": "1655100"
  },
  {
    "text": "is instead of process processing first in first out you should do the opposite start processing last in first out so",
    "start": "1655100",
    "end": "1661700"
  },
  {
    "text": "you're actually doing some successful requests um and actually kind of getting latency",
    "start": "1661700",
    "end": "1667640"
  },
  {
    "text": "down otherwise you might just kind of keep getting further and further behind",
    "start": "1667640",
    "end": "1672880"
  },
  {
    "text": "how's this going it's all starting should have probably figured out a better series to actually",
    "start": "1675500",
    "end": "1681080"
  },
  {
    "text": "do this yeah these are all still creating and maybe we'll come back to this in a second",
    "start": "1681080",
    "end": "1687140"
  },
  {
    "text": "um and I can quickly go and catch the last of the best practices",
    "start": "1687140",
    "end": "1693559"
  },
  {
    "text": "best practices um so yeah this is the last thing I want to talk about um when building message brokering",
    "start": "1693559",
    "end": "1699919"
  },
  {
    "text": "systems the most important thing is you really need to understand what's what needs to be done synchronously um in this you know web app example",
    "start": "1699919",
    "end": "1706700"
  },
  {
    "text": "we're talking about like no user likes to get a successfully purchased and then",
    "start": "1706700",
    "end": "1711799"
  },
  {
    "text": "found out oh no async had failed because we didn't actually have capacity so make sure you know what needs to be",
    "start": "1711799",
    "end": "1717200"
  },
  {
    "text": "done synchronously what needs to be communicated to users since if something is failing asynchronously you kind of need to like",
    "start": "1717200",
    "end": "1723320"
  },
  {
    "text": "you need to know how to resolve that because you didn't give a synchronous error to users",
    "start": "1723320",
    "end": "1728779"
  },
  {
    "text": "and make sure you test failure modes as I said this is a pattern which is really helps but it also can be a huge Thor in",
    "start": "1728779",
    "end": "1735320"
  },
  {
    "text": "the side reminds me a lot of caching in that case a lot of people have failures because their cash Falls over and then",
    "start": "1735320",
    "end": "1740779"
  },
  {
    "text": "they storm their backend database and sad things happen so just like I feel like in a lot of places with red it's",
    "start": "1740779",
    "end": "1745940"
  },
  {
    "text": "just making sure you understand your failure modes and you test them regularly um an example we're just kind of talking",
    "start": "1745940",
    "end": "1751700"
  },
  {
    "text": "about to try making sure like just turn off all your consumers seeds with see what happens when you restart them cold starts are nice and easy to do in",
    "start": "1751700",
    "end": "1758779"
  },
  {
    "text": "kubernetes for the most part um another important thing is to like really make sure you're avoiding poison",
    "start": "1758779",
    "end": "1764960"
  },
  {
    "text": "pills make sure you have like schemas for events and that everyone is like adhering to them uh your messaging",
    "start": "1764960",
    "end": "1770419"
  },
  {
    "text": "system should validate that schema and not accept messages that don't conform to it once you have like a poison pill",
    "start": "1770419",
    "end": "1776240"
  },
  {
    "text": "in your system it can like kind of bring everything down I had a bug earlier when I was building",
    "start": "1776240",
    "end": "1781760"
  },
  {
    "text": "this demo where I actually put a a character like a s inside the user ID when I was expect everything else was",
    "start": "1781760",
    "end": "1787520"
  },
  {
    "text": "expecting it to be purely hints and then nothing was accepting it and it was took a long time to debug",
    "start": "1787520",
    "end": "1793760"
  },
  {
    "text": "and I would have helped if I actually been properly ballading stuff instead of just shoving it in redis",
    "start": "1793760",
    "end": "1799520"
  },
  {
    "text": "um monitoring uh we already talked about this a little bit make sure you enough burst capacity to handle whatever type of load you want to do",
    "start": "1799520",
    "end": "1806960"
  },
  {
    "text": "um especially in the res case when RES can actually burst into memory make sure you have enough like spare memory capacity uh cues are typically a good",
    "start": "1806960",
    "end": "1814460"
  },
  {
    "text": "use case for redis because you usually don't consume all that much memory you kind of like you add items",
    "start": "1814460",
    "end": "1820460"
  },
  {
    "text": "remove items so memory stays pretty constant but make sure you have enough to actually burst into",
    "start": "1820460",
    "end": "1826580"
  },
  {
    "text": "um the last thing is message partitioning we talked a little bit about how to name uh stuff in redis",
    "start": "1826580",
    "end": "1832279"
  },
  {
    "text": "using like crc16 uh it's still important to understand like how you like what's the right Dimension to partition your",
    "start": "1832279",
    "end": "1837980"
  },
  {
    "text": "messages on most people do it by something like a user ID or a customer ID but there's other ways as well like",
    "start": "1837980",
    "end": "1846940"
  },
  {
    "text": "um like you know based like just logically grouping stuff instead of doing something like a hash on top of the customer ID",
    "start": "1847460",
    "end": "1854480"
  },
  {
    "text": "um so that's all I have for you at the moment I believe I'm supposed to show you a QR code and give you",
    "start": "1854480",
    "end": "1861740"
  },
  {
    "text": "something so I'll just briefly say like Thank you Madeline Nelson you can follow me on Twitter here's the QR code if you",
    "start": "1861740",
    "end": "1868760"
  },
  {
    "text": "need it um and yeah I think that's all I have",
    "start": "1868760",
    "end": "1873820"
  },
  {
    "text": "[Applause]",
    "start": "1874070",
    "end": "1882260"
  },
  {
    "text": "anyone know how to like question do people come and ask questions is that thing sure what's up",
    "start": "1882260",
    "end": "1888700"
  },
  {
    "text": "I have no idea how is it does anyone else have examples or do people just go and mingle oh we have microphones nice",
    "start": "1889279",
    "end": "1896440"
  },
  {
    "text": "priority hey the salon all right to go to ready okay I repeat",
    "start": "1896539",
    "end": "1904520"
  },
  {
    "text": "if we're already using the Kafka as a message broker for the same purpose is there a reason to up to to change to",
    "start": "1904520",
    "end": "1912140"
  },
  {
    "text": "redist or it's just a matter of preferences for the most part I've seen like Grannis",
    "start": "1912140",
    "end": "1917240"
  },
  {
    "text": "so Kafka really only Sports the the logs more have and it stores everything durably if you don't need that",
    "start": "1917240",
    "end": "1922880"
  },
  {
    "text": "durability that's the biggest reason I've seen people move away from Kafka because rest tends to be more efficient and has lower cost to operate but I",
    "start": "1922880",
    "end": "1930020"
  },
  {
    "text": "would say it's a lot about preference um a lot of people already have redis in their deployments already and people",
    "start": "1930020",
    "end": "1935840"
  },
  {
    "text": "understand it it's kind of nice to use one system for multiple things as opposed to kind of purpose built things",
    "start": "1935840",
    "end": "1942140"
  },
  {
    "text": "everywhere so I but yeah it is ultimately more or less a preference thing",
    "start": "1942140",
    "end": "1947539"
  },
  {
    "text": "yeah so um thanks for the presentation so uh when the pub sub messages are being",
    "start": "1947539",
    "end": "1954200"
  },
  {
    "text": "stored is I'm assuming it's also stored in the redis um so what happens if I have a bus and I",
    "start": "1954200",
    "end": "1961399"
  },
  {
    "text": "have this lots of messages that are being generated and that's causing a huge memory usage so what would be your",
    "start": "1961399",
    "end": "1967880"
  },
  {
    "text": "recommendation around uh um you know bus capacity uh planning and",
    "start": "1967880",
    "end": "1974360"
  },
  {
    "text": "what are the uh things that we should plan memory disk",
    "start": "1974360",
    "end": "1979399"
  },
  {
    "text": "um and things like that things yeah especially for memory um as I said it kind of really comes down",
    "start": "1979399",
    "end": "1986000"
  },
  {
    "text": "to your capacity planning at some point you should stop accepting messages if you're running if you have no memory like spare memory to actually like put",
    "start": "1986000",
    "end": "1992960"
  },
  {
    "text": "them um so typically you want to start like you'll want to reject them and have the back pressure push it back to the front",
    "start": "1992960",
    "end": "1998600"
  },
  {
    "text": "end so it like things stop adding more data in so you'll want to for capacity planning that's I mean too it's very you",
    "start": "1998600",
    "end": "2006100"
  },
  {
    "text": "know system dependent AWS we usually do like you know 10x kind of what we expect to be the worst case to make sure we",
    "start": "2006100",
    "end": "2011799"
  },
  {
    "text": "have capacity for that in this case it's much easier to Super over provision this is um it's almost a message cues are",
    "start": "2011799",
    "end": "2019240"
  },
  {
    "text": "almost always CPU and throughput bound not memory bound unless you're like really far falling far behind",
    "start": "2019240",
    "end": "2026919"
  },
  {
    "text": "um so try to figure out like how like how much time are you willing to keep accepting rights before you kind of have",
    "start": "2026919",
    "end": "2032500"
  },
  {
    "text": "a hard outage is another thing we you do at AWS um like for we have like uh when we do",
    "start": "2032500",
    "end": "2038260"
  },
  {
    "text": "like authentication we have like six hours so we usually say you need at least six hours of",
    "start": "2038260",
    "end": "2043559"
  },
  {
    "text": "reasonable extra capacity before you should start rejecting uh requests",
    "start": "2043559",
    "end": "2049599"
  },
  {
    "text": "um but obviously that becomes very different if you're actually very constrained on memory or disk then you",
    "start": "2049599",
    "end": "2055300"
  },
  {
    "text": "might need to keep less Surplus um for disk yeah you have the same problem if you're using with aof",
    "start": "2055300",
    "end": "2061599"
  },
  {
    "text": "um you should figure out how much you're willing to spill um before you start actually rejecting the front-end apps because most of the",
    "start": "2061599",
    "end": "2067960"
  },
  {
    "text": "time message Brokers are used to keep availability up and have the latency does that help",
    "start": "2067960",
    "end": "2075179"
  },
  {
    "text": "yeah we'll try to get you a microphone unless you want to yell and I can repeat it",
    "start": "2077200",
    "end": "2082980"
  },
  {
    "text": "that's fair",
    "start": "2082980",
    "end": "2086220"
  },
  {
    "text": "it works um one of our Communications do you have to ensure durability for streams in the",
    "start": "2089320",
    "end": "2095740"
  },
  {
    "text": "event of node failures can you say that one more time yes uh what recommendations do you have if you want",
    "start": "2095740",
    "end": "2102820"
  },
  {
    "text": "to have durable streams that tolerate node failures so for example like if",
    "start": "2102820",
    "end": "2108160"
  },
  {
    "text": "your cloud provider or if you want to upgrade nodes and that requires node restarts",
    "start": "2108160",
    "end": "2114420"
  },
  {
    "text": "and if you want to maintain a given stream like have it still remain available",
    "start": "2115000",
    "end": "2122040"
  },
  {
    "text": "what recommendations do you have for that yeah so typically you'll not just want to do a node restart on a node that",
    "start": "2122040",
    "end": "2128920"
  },
  {
    "text": "doesn't have any backup of the data that will lose the data I think aof is usually the best thing for that because",
    "start": "2128920",
    "end": "2134800"
  },
  {
    "text": "you can take a synchronous flush basically of the data and restart with it",
    "start": "2134800",
    "end": "2139960"
  },
  {
    "text": "um some of the managed providers like do that all for you so I mean I basically just don't restart the node have some",
    "start": "2139960",
    "end": "2147099"
  },
  {
    "text": "backup of the data I think we're out of time so thank God",
    "start": "2147099",
    "end": "2152500"
  },
  {
    "text": "thank you all for coming if you have more questions I'll hang out [Applause]",
    "start": "2152500",
    "end": "2159869"
  }
]
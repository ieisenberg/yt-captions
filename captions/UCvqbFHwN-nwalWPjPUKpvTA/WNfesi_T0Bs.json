[
  {
    "text": "so hello everyone and welcome to the Jagger session uh it's super amazing to see so many people interested in the",
    "start": "120",
    "end": "7440"
  },
  {
    "text": "project I think this might be the biggest session we have ever had at",
    "start": "7440",
    "end": "12839"
  },
  {
    "text": "cucon so that's uh yeah it's great thanks for coming uh my name is pav I a",
    "start": "12839",
    "end": "19840"
  },
  {
    "text": "software engineer at redhead I'm Jagger maintainer and as well maintainer of the",
    "start": "19840",
    "end": "25000"
  },
  {
    "text": "open Telemetry operator and graphon Tempo operator um and in general I",
    "start": "25000",
    "end": "30679"
  },
  {
    "text": "contribute to the observability projects in the cncf um B in Switzerland when I'm not",
    "start": "30679",
    "end": "36520"
  },
  {
    "text": "working I'm usually in the Alps doing some free ride skiing or mountain biking",
    "start": "36520",
    "end": "41879"
  },
  {
    "text": "and with me is Jonah thank you Pavo I spend time in the",
    "start": "41879",
    "end": "47680"
  },
  {
    "text": "opposite area uh my name is Jonah Cowell I'm the VP of product management at Ivan",
    "start": "47680",
    "end": "54320"
  },
  {
    "text": "and for fun and my extracurricular open source work I am a maintainer of the",
    "start": "54320",
    "end": "60440"
  },
  {
    "text": "project and I'm also heavily involved in open search um and observability is uh",
    "start": "60440",
    "end": "67159"
  },
  {
    "text": "near and dear to my heart I spend a lot of I live in Miami Florida and I spend a",
    "start": "67159",
    "end": "72680"
  },
  {
    "text": "lot of time underwater opposite of pavl exploring what happens beneath so some",
    "start": "72680",
    "end": "79439"
  },
  {
    "text": "photos I took too uh so today we're going to go over",
    "start": "79439",
    "end": "85079"
  },
  {
    "text": "uh we have a couple of demos for you but we're also going to go over some of the basic",
    "start": "85079",
    "end": "90720"
  },
  {
    "text": "uh this morning at the booth for the first couple of hours we had people coming up to us asking what is tracing",
    "start": "90720",
    "end": "97479"
  },
  {
    "text": "so we're going to do some a few minutes on the basics and then we're going to get deeper and deeper into jger for",
    "start": "97479",
    "end": "103560"
  },
  {
    "text": "those of you that are well along your journey in distributed tracing and",
    "start": "103560",
    "end": "108799"
  },
  {
    "text": "observability uh we'll be showing you a couple of demos and we'll be talking about what's coming next to the project",
    "start": "108799",
    "end": "115040"
  },
  {
    "text": "we've got a very ambitious plan that we're going to outline and we obviously",
    "start": "115040",
    "end": "120079"
  },
  {
    "text": "love contributors and we'll talk about some of the things that we're doing where you all can get involved in the",
    "start": "120079",
    "end": "126079"
  },
  {
    "text": "project and then be up on stage of cubec con talking to all of these people uh",
    "start": "126079",
    "end": "131520"
  },
  {
    "text": "well we should have time for Q&A as well um and with that I will jump into",
    "start": "131520",
    "end": "137000"
  },
  {
    "text": "distributed tracing 101 for those of you that are not familiar so most folks and this number",
    "start": "137000",
    "end": "144400"
  },
  {
    "text": "may be a little bit out of date are running microservices architectures where you've got a lot lot of",
    "start": "144400",
    "end": "150200"
  },
  {
    "text": "distributed components potentially owned by different teams and the challenge is",
    "start": "150200",
    "end": "155560"
  },
  {
    "text": "that when things break we do a lot of finger pointing or uh looking at logs",
    "start": "155560",
    "end": "161120"
  },
  {
    "text": "and trying to figure out where it broke who broke it and how to fix it and get our customers back going again as",
    "start": "161120",
    "end": "168080"
  },
  {
    "text": "quickly as possible and so the purpose of distributed tracing is the ability to",
    "start": "168080",
    "end": "173720"
  },
  {
    "text": "do the root cause analysis looking at the relationships between different services and and then being able to",
    "start": "173720",
    "end": "180959"
  },
  {
    "text": "drill in and really understand what's happening where is it slow where is the error happening and this enables you to",
    "start": "180959",
    "end": "188519"
  },
  {
    "text": "collaborate across all of your distributed teams with data and not just",
    "start": "188519",
    "end": "193760"
  },
  {
    "text": "pointing fingers uh and then it can also be used and we'll talk about how it's",
    "start": "193760",
    "end": "198799"
  },
  {
    "text": "used for monitoring where you can get visibility into your slas and your",
    "start": "198799",
    "end": "204000"
  },
  {
    "text": "performance and how your services are doing so there's a few basics with",
    "start": "204000",
    "end": "210040"
  },
  {
    "text": "tracing uh the first is instrumentation you'll hear us talk about that a lot",
    "start": "210040",
    "end": "215120"
  },
  {
    "text": "that is putting something in or near your software to emit data that can then",
    "start": "215120",
    "end": "220400"
  },
  {
    "text": "be collected the second part is collecting that data and storing it uh which is part of what jerger does and",
    "start": "220400",
    "end": "227200"
  },
  {
    "text": "then finally with that storage we can then analyze the data that we collect which is also part of jerger and we'll",
    "start": "227200",
    "end": "234439"
  },
  {
    "text": "talk about all of these pieces in the next few minutes so to to give you this",
    "start": "234439",
    "end": "242120"
  },
  {
    "text": "mind yeah so I'll continue with introduction to jger um I will deploy it",
    "start": "242120",
    "end": "248040"
  },
  {
    "text": "on my on my laptop and we will deploy as well very simple microservice application and we will use Jagger to",
    "start": "248040",
    "end": "254879"
  },
  {
    "text": "monitor it and try to reason about its performance before we do that I would like to talk about the data model that",
    "start": "254879",
    "end": "262759"
  },
  {
    "text": "is used in tracing in general um and there's mainly two concepts that are",
    "start": "262759",
    "end": "268320"
  },
  {
    "text": "important first one is a span and a span it's essentially data structure that uh",
    "start": "268320",
    "end": "275880"
  },
  {
    "text": "models invocation in the system and invocation it can be HTTP call database",
    "start": "275880",
    "end": "281919"
  },
  {
    "text": "invocation or even internal method call in your business logic um so since it's",
    "start": "281919",
    "end": "288520"
  },
  {
    "text": "call it has a start and end so you know implies duration uh but most importantly",
    "start": "288520",
    "end": "294400"
  },
  {
    "text": "it contains metadata that we called Tags or attributes as you will see in the demo that help us to understand what the",
    "start": "294400",
    "end": "302000"
  },
  {
    "text": "operation actually did in our system um so that's a single operation but in",
    "start": "302000",
    "end": "307840"
  },
  {
    "text": "tracing the value is in the distributed environment in the distributed um",
    "start": "307840",
    "end": "313680"
  },
  {
    "text": "execution right so when we stitch together spans um we form a trace and",
    "start": "313680",
    "end": "321759"
  },
  {
    "text": "Trace essentially it's a list of spans that are um kind of correlated they",
    "start": "321759",
    "end": "327400"
  },
  {
    "text": "contain the same ID we call it Trace ID and then each operation contains spin ID",
    "start": "327400",
    "end": "333319"
  },
  {
    "text": "and the parent ID um and based on this we are able to to create a tree uh that",
    "start": "333319",
    "end": "340319"
  },
  {
    "text": "is one way to visualize Trace uh and the most common visualization is what you",
    "start": "340319",
    "end": "345360"
  },
  {
    "text": "see on the right side which is uh timeline view or gun chart uh it's the",
    "start": "345360",
    "end": "351319"
  },
  {
    "text": "visualization I think every tracing tool really uses and with that we'll jump",
    "start": "351319",
    "end": "357639"
  },
  {
    "text": "into demo and I will show you how we can use use the timeline view to to understand um tracing",
    "start": "357639",
    "end": "365840"
  },
  {
    "text": "data",
    "start": "365840",
    "end": "368840"
  },
  {
    "text": "this so what I deployed locally it's the theer allinone which is a single",
    "start": "371240",
    "end": "378479"
  },
  {
    "text": "container that that runs all the Jagger components uh and in the second terminal",
    "start": "378479",
    "end": "386400"
  },
  {
    "text": "I'm running the Hotrod app from from the theer project uh it's a goang",
    "start": "386400",
    "end": "391919"
  },
  {
    "text": "application that that kind of contains free microservices um uh as we can see",
    "start": "391919",
    "end": "397599"
  },
  {
    "text": "from the logs there is the Ser the the customer service the route the driver",
    "start": "397599",
    "end": "403000"
  },
  {
    "text": "and front end uh so let's jump to",
    "start": "403000",
    "end": "408039"
  },
  {
    "text": "the to the browser to see the UI so this is the UI and essentially when I click",
    "start": "408039",
    "end": "414319"
  },
  {
    "text": "on one of these buttons what happens is I order a car so let's try to do that uh",
    "start": "414319",
    "end": "420960"
  },
  {
    "text": "and then I get a response from backend saying that the driver with the license",
    "start": "420960",
    "end": "426520"
  },
  {
    "text": "plate will arrive in 2 minutes uh this is the request ID and this is the latency measured from the browser um",
    "start": "426520",
    "end": "434400"
  },
  {
    "text": "when I jump back into the console I see the the logs right and by reading the",
    "start": "434400",
    "end": "440520"
  },
  {
    "text": "logs I'm able to sort of understand what is happening right I see that the front",
    "start": "440520",
    "end": "446599"
  },
  {
    "text": "end received the request then the customer was was processing the request by getting the customer",
    "start": "446599",
    "end": "453199"
  },
  {
    "text": "data then the driver service was probably trying to find the the nearby",
    "start": "453199",
    "end": "460000"
  },
  {
    "text": "drivers um and then there was some Road calculation and finally I think the the",
    "start": "460000",
    "end": "467720"
  },
  {
    "text": "request was dispatched back to the to the browser so that's fine right I can",
    "start": "467720",
    "end": "472840"
  },
  {
    "text": "use logging to sort of understand what's what's happening the problem with",
    "start": "472840",
    "end": "478120"
  },
  {
    "text": "logging is if there are multiple concurrent requests as I'm kind of simulating right now if I jump back to",
    "start": "478120",
    "end": "485479"
  },
  {
    "text": "the console I'm no longer to understand you know what's happening here because all those logs are mixed together across",
    "start": "485479",
    "end": "492319"
  },
  {
    "text": "multiple concurrent requests and this is where tracing can help you to correlate",
    "start": "492319",
    "end": "497479"
  },
  {
    "text": "these logs together uh into a nice visualization that we will see in the",
    "start": "497479",
    "end": "502560"
  },
  {
    "text": "Jager console so let me jump back to to Jagger and jger not only it's able to",
    "start": "502560",
    "end": "510120"
  },
  {
    "text": "visualize the tra trace or the timeline view as we will see but it has as well",
    "start": "510120",
    "end": "515399"
  },
  {
    "text": "the capability to show you the dependencies uh in your environment um so what we see here it's",
    "start": "515399",
    "end": "522959"
  },
  {
    "text": "very similar to what we saw on the locks right we see the service names the front end the customer and the",
    "start": "522959",
    "end": "529080"
  },
  {
    "text": "driver um so what is happening here is Jagger is looking at the spend data and he trying to understand which service is",
    "start": "529080",
    "end": "535680"
  },
  {
    "text": "calling which one and as well how many times",
    "start": "535680",
    "end": "541440"
  },
  {
    "text": "so this is one capability and the second capability is the search where we can find um the the collected",
    "start": "541880",
    "end": "550519"
  },
  {
    "text": "traces so let me find the traces for the front end service which is the first one",
    "start": "550519",
    "end": "555600"
  },
  {
    "text": "as we saw in the um in the system architecture and here we see the um you",
    "start": "555600",
    "end": "561959"
  },
  {
    "text": "know the stored traces in eger um we see you know what was the overall",
    "start": "561959",
    "end": "568920"
  },
  {
    "text": "invocation time for request in this case 1.8 seconds the next one took only you",
    "start": "568920",
    "end": "575200"
  },
  {
    "text": "know 50 40 uh micros seconds um and so on uh we see as well you know what were",
    "start": "575200",
    "end": "581640"
  },
  {
    "text": "the services uh involved to in these requests how many operations or spans",
    "start": "581640",
    "end": "587880"
  },
  {
    "text": "are reported and how many errors so I will just choose this one and now we get the timeline you um",
    "start": "587880",
    "end": "595920"
  },
  {
    "text": "it might be overwhelming to CD see the screen for the first time because there is a lot of information but it's",
    "start": "595920",
    "end": "602680"
  },
  {
    "text": "actually very easy to understand this um this diagram on the left side we see the",
    "start": "602680",
    "end": "608959"
  },
  {
    "text": "service name with the operation name and then on the right side we see these bars",
    "start": "608959",
    "end": "614519"
  },
  {
    "text": "and the longer the bar is the longer the operation took um so for instance this",
    "start": "614519",
    "end": "621399"
  },
  {
    "text": "MySQL call took 1.4 seconds out of 1.8",
    "start": "621399",
    "end": "627560"
  },
  {
    "text": "so it's maybe like no 70% % of the whole invocation was spent in the mySQL",
    "start": "627560",
    "end": "633640"
  },
  {
    "text": "database when I look further what I see here are the calls from the driver to",
    "start": "633640",
    "end": "639399"
  },
  {
    "text": "redis uh and I see this they're very short but they are done in a sequence",
    "start": "639399",
    "end": "645000"
  },
  {
    "text": "right so maybe there is a for Loop executing calls to redis maybe this was intentional but maybe this is something",
    "start": "645000",
    "end": "651680"
  },
  {
    "text": "the developer forgot to optimize and use bch API or execute all these requests in",
    "start": "651680",
    "end": "657680"
  },
  {
    "text": "parallel in a in a separate go so by looking at this diagram I'm able",
    "start": "657680",
    "end": "663040"
  },
  {
    "text": "to understand you know where the time is spent and what are the structure of the calls that help me to understand the",
    "start": "663040",
    "end": "668600"
  },
  {
    "text": "application and make the optimizations uh what we have as well is the highlighting of the critical",
    "start": "668600",
    "end": "676839"
  },
  {
    "text": "path uh which is uh denoted by this solid black line um so the critical p is very",
    "start": "676839",
    "end": "684399"
  },
  {
    "text": "important because if I want to optimize the the overall latency of this uh request which was 1.8 seconds I should",
    "start": "684399",
    "end": "692160"
  },
  {
    "text": "optimize only operations that are on the critical path so what I see next is the um the",
    "start": "692160",
    "end": "701320"
  },
  {
    "text": "exclamation marks um that um shows me there is an error when I click on it uh",
    "start": "701320",
    "end": "708240"
  },
  {
    "text": "it comes from the redice I see the acception there was",
    "start": "708240",
    "end": "714480"
  },
  {
    "text": "exception I see the exception message it was already time out so nothing probably really really serious um so in a tracing",
    "start": "714480",
    "end": "722240"
  },
  {
    "text": "the instrumentation when it sees an error it will attach it to the to the spans which",
    "start": "722240",
    "end": "727560"
  },
  {
    "text": "is very very helpful and then um each span has text",
    "start": "727560",
    "end": "735279"
  },
  {
    "text": "and a process and tex are the attributes that describe the",
    "start": "735279",
    "end": "741839"
  },
  {
    "text": "operation I would like to show you the text from the HTP call from the front end",
    "start": "742279",
    "end": "747800"
  },
  {
    "text": "Service uh and and we get the texts that describe the the HTTP method the route",
    "start": "747800",
    "end": "755480"
  },
  {
    "text": "the the status code and all the important information that we care about for the HTTP request if this was a",
    "start": "755480",
    "end": "762680"
  },
  {
    "text": "database call we would get the different tags but um the the ones that are",
    "start": "762680",
    "end": "771040"
  },
  {
    "text": "important to understand the database call what is very useful in tracing",
    "start": "771040",
    "end": "777760"
  },
  {
    "text": "compared to logging is this you know the correlation that we get this nice view with correlated um logs but as well is",
    "start": "777760",
    "end": "785519"
  },
  {
    "text": "the consistency in logging there is no standardization on what data should be",
    "start": "785519",
    "end": "790560"
  },
  {
    "text": "in the logs different languages different uh Frameworks and different",
    "start": "790560",
    "end": "795760"
  },
  {
    "text": "developers they put different data into into logs which makes it very hard to",
    "start": "795760",
    "end": "800880"
  },
  {
    "text": "understand logging at scale in micros service you know environment with multiple languages with logging with",
    "start": "800880",
    "end": "808120"
  },
  {
    "text": "tracing we get the consistent set of attributes for the same events so for",
    "start": "808120",
    "end": "813880"
  },
  {
    "text": "instance if a front end is written in goang I get the same attributes as the",
    "start": "813880",
    "end": "820279"
  },
  {
    "text": "in the in the road service that is written probably maybe in node.js or even a different",
    "start": "820279",
    "end": "826959"
  },
  {
    "text": "language okay so you can think about tracing as well about the logging with",
    "start": "830279",
    "end": "835360"
  },
  {
    "text": "strong correlation and with consistency on what is in the data that will help you to understand the",
    "start": "835360",
    "end": "842399"
  },
  {
    "text": "application um okay this is all I",
    "start": "842399",
    "end": "849360"
  },
  {
    "text": "will and we will continue with the",
    "start": "849360",
    "end": "855279"
  },
  {
    "text": "monitoring thank you so uh one of the things that we recently added uh to",
    "start": "856519",
    "end": "862920"
  },
  {
    "text": "Jager in the last couple of years is integration with Prometheus and the use",
    "start": "862920",
    "end": "868120"
  },
  {
    "text": "case here is in set of the Diagnostics that pavle just went through is for monitoring so one of the things that we",
    "start": "868120",
    "end": "875079"
  },
  {
    "text": "wanted to do is to make joer more useful operationally and so the purpose is to",
    "start": "875079",
    "end": "881800"
  },
  {
    "text": "move jerger from only distributed tracing towards APM or application",
    "start": "881800",
    "end": "887160"
  },
  {
    "text": "performance monitoring and it's about incorporating the tracing and the metrics together it also allows you with",
    "start": "887160",
    "end": "895040"
  },
  {
    "text": "Prometheus alert manager or whatever you're using for alerting to enable",
    "start": "895040",
    "end": "900600"
  },
  {
    "text": "those types of use cases so now you can get alerts to your team when certain",
    "start": "900600",
    "end": "905680"
  },
  {
    "text": "things are occurring and I'm going to give you a few examples in the demo of how this is useful in addition to what",
    "start": "905680",
    "end": "913279"
  },
  {
    "text": "pble shared which is very useful to developers but operationally it's sort",
    "start": "913279",
    "end": "918639"
  },
  {
    "text": "of an after the fact instead of a before the fact type of situation so the way that this works",
    "start": "918639",
    "end": "925560"
  },
  {
    "text": "today is that when you set up your open Telemetry to collect that data there's a",
    "start": "925560",
    "end": "931839"
  },
  {
    "text": "component a processor called the span metrics processor and what this uh",
    "start": "931839",
    "end": "937920"
  },
  {
    "text": "processor does is it allows you to then derive metrics off of the trace data so",
    "start": "937920",
    "end": "944199"
  },
  {
    "text": "you don't have to do any additional work The Collector is actually going to take the trace data and build metrics and",
    "start": "944199",
    "end": "952399"
  },
  {
    "text": "then send those off to any supported metrics backend in joerger we have built",
    "start": "952399",
    "end": "958399"
  },
  {
    "text": "this for Prometheus but if you're using some other metrics backend commercial or",
    "start": "958399",
    "end": "964519"
  },
  {
    "text": "open source that's supported in open Telemetry you can use this same method",
    "start": "964519",
    "end": "971040"
  },
  {
    "text": "but of course feel free to contribute to jerger to support it in the UI which is",
    "start": "971040",
    "end": "976120"
  },
  {
    "text": "what I'm going to show you in a minute so in the connector in your open",
    "start": "976120",
    "end": "981199"
  },
  {
    "text": "Telemetry pipeline you will basically Define the the use of the span metrics",
    "start": "981199",
    "end": "987759"
  },
  {
    "text": "connector uh that will then build these data sets there's a lot of other uh",
    "start": "987759",
    "end": "994920"
  },
  {
    "text": "definitions that you can put into this configuration so I suggest that you look at that processor in the open Telemetry",
    "start": "994920",
    "end": "1002800"
  },
  {
    "text": "repository where there are further examples of how you can configure buckets and various other things that",
    "start": "1002800",
    "end": "1009720"
  },
  {
    "text": "help with percentiles and other things that might be useful to you in monitoring um but this is the basic",
    "start": "1009720",
    "end": "1016560"
  },
  {
    "text": "configuration that we'll generate uh that data and I'm going to show you a",
    "start": "1016560",
    "end": "1022279"
  },
  {
    "text": "demo so we don't need to talk about this but uh give me a moment and I will pull",
    "start": "1022279",
    "end": "1027280"
  },
  {
    "text": "that",
    "start": "1027280",
    "end": "1029600"
  },
  {
    "text": "up thank you so um we've been running",
    "start": "1032480",
    "end": "1037839"
  },
  {
    "text": "another Docker container besides the one that pavle was showing you that's generating spans automatically in the",
    "start": "1037839",
    "end": "1044798"
  },
  {
    "text": "background so I can show you the same view that Pavo was just showing you the data is going to be less interesting",
    "start": "1044799",
    "end": "1051880"
  },
  {
    "text": "because they're simulated spans so they all kind of look the same and there's no real",
    "start": "1051880",
    "end": "1057720"
  },
  {
    "text": "errors the interesting part of this is aside from the tabs in the UI that Pavo",
    "start": "1057720",
    "end": "1063799"
  },
  {
    "text": "was showing you we have this new monitor Tab and we've been running this now",
    "start": "1063799",
    "end": "1069200"
  },
  {
    "text": "since before you all sat down and what you see here is that we're collecting uh",
    "start": "1069200",
    "end": "1074679"
  },
  {
    "text": "a few different metrics at a high level so these are often known as red metrics",
    "start": "1074679",
    "end": "1080440"
  },
  {
    "text": "but what that is is it's the request request rate of my service that I can see how many times it's being called the",
    "start": "1080440",
    "end": "1088120"
  },
  {
    "text": "error rate of my service this one is very nice I wish my production looked",
    "start": "1088120",
    "end": "1093200"
  },
  {
    "text": "like this where there was no errors um and then of course the latency or the",
    "start": "1093200",
    "end": "1098840"
  },
  {
    "text": "response time of uh of that service itself in this case it's it's very even",
    "start": "1098840",
    "end": "1105360"
  },
  {
    "text": "but the idea here is that I can look at this operationally I can also set up alerting in Prometheus so that when that",
    "start": "1105360",
    "end": "1112640"
  },
  {
    "text": "error rate starts creeping up to a level that I'm uncomfortable with maybe your service averages 5% but when it jumps to",
    "start": "1112640",
    "end": "1120720"
  },
  {
    "text": "30% you want to be notified and you want to understand that these metrics are",
    "start": "1120720",
    "end": "1126039"
  },
  {
    "text": "given to you automatically through that integration so it's really helpful operationally to have these things",
    "start": "1126039",
    "end": "1132919"
  },
  {
    "text": "without having to configure additional Prometheus metrics or any other type of",
    "start": "1132919",
    "end": "1138919"
  },
  {
    "text": "application code the list of endpoints will be uh will be listed below in terms",
    "start": "1138919",
    "end": "1145080"
  },
  {
    "text": "of the types of calls and we can also look at other microservices which you",
    "start": "1145080",
    "end": "1150400"
  },
  {
    "text": "know all of them are calculated um interesting the redest one",
    "start": "1150400",
    "end": "1155679"
  },
  {
    "text": "looks a little bit different which is odd considering they're simulated but in your production environment you'll",
    "start": "1155679",
    "end": "1161400"
  },
  {
    "text": "obviously see a lot more variation in the data that's coming into this so uh",
    "start": "1161400",
    "end": "1167400"
  },
  {
    "text": "that's the advantage of the monitoring Tab and uh and definitely something to",
    "start": "1167400",
    "end": "1172440"
  },
  {
    "text": "check out and of course you can visualize those in your own grafana or",
    "start": "1172440",
    "end": "1177720"
  },
  {
    "text": "other tools that you're using on top of Prometheus so they're helpful uh for",
    "start": "1177720",
    "end": "1182880"
  },
  {
    "text": "other purposes as well going to just jump back to the",
    "start": "1182880",
    "end": "1189240"
  },
  {
    "text": "presentation here and Pavo is going to take us through uh jger ingestion",
    "start": "1189240",
    "end": "1195919"
  },
  {
    "text": "pipelines y thank you junah y um yes so I will talk about how we can deploy",
    "start": "1195919",
    "end": "1201120"
  },
  {
    "text": "Jagger and how we can as well deploy it alongside the collector because as we saw the new capabilities in Jagger",
    "start": "1201120",
    "end": "1208640"
  },
  {
    "text": "require The Collector uh as the span metric connector um and it's not only for the",
    "start": "1208640",
    "end": "1216039"
  },
  {
    "text": "span metric connector as you know the Jagger project it deprecated uh its sdks",
    "start": "1216039",
    "end": "1221520"
  },
  {
    "text": "in in favor of the open Telemetry SD case and we have as well deprecated",
    "start": "1221520",
    "end": "1226720"
  },
  {
    "text": "theer agent and if if you have workloads that need to emit um or that emits the",
    "start": "1226720",
    "end": "1234280"
  },
  {
    "text": "um the spans in the Legacy Jagger formats you can consume that data with",
    "start": "1234280",
    "end": "1240559"
  },
  {
    "text": "the open Telemetry collector with the Jagger receiver um um but on top of that",
    "start": "1240559",
    "end": "1246280"
  },
  {
    "text": "the open Telemetry collector can as well receive the at the moment supported eer protocols the grpc and the thrift over",
    "start": "1246280",
    "end": "1254440"
  },
  {
    "text": "HTTP uh and then there is as well uh support for the Jager remote sampler uh",
    "start": "1254440",
    "end": "1260320"
  },
  {
    "text": "in The Collector and as well the Kafka receiver and exporter can send uh data",
    "start": "1260320",
    "end": "1266320"
  },
  {
    "text": "in the Jagger payloads and that's not all right the open Telemetry collector as well gives",
    "start": "1266320",
    "end": "1272799"
  },
  {
    "text": "you um access to large ecosystem of additional capabilities uh for instance there is",
    "start": "1272799",
    "end": "1279640"
  },
  {
    "text": "lot of functionality for massaging the data you know to remove the attributes that you don't want to send to Jagger or",
    "start": "1279640",
    "end": "1286320"
  },
  {
    "text": "to any observability vendor or a processor that can automatically",
    "start": "1286320",
    "end": "1291960"
  },
  {
    "text": "attach kubernetes resource attributes to your data that will help you to identify",
    "start": "1291960",
    "end": "1297840"
  },
  {
    "text": "you know what was the the Pod name the deployment name and so on um and yeah just take a look at the",
    "start": "1297840",
    "end": "1306279"
  },
  {
    "text": "uh open tet collector contri to the processor directory and you will see large set of capabilities that you can",
    "start": "1306279",
    "end": "1313000"
  },
  {
    "text": "use with the Jagger project as well if you deploy The Collector so how do we",
    "start": "1313000",
    "end": "1318919"
  },
  {
    "text": "deploy these two systems together um it's very simple right we have application instrumented with open",
    "start": "1318919",
    "end": "1324480"
  },
  {
    "text": "Telemetry SDK uh and then we can send data directly to jger or to the",
    "start": "1324480",
    "end": "1331799"
  },
  {
    "text": "collector and then from The Collector to jger um Jagger can as well receive the",
    "start": "1331799",
    "end": "1339000"
  },
  {
    "text": "data in the open Telemetry format in the OTP um so you can you know combine these",
    "start": "1339000",
    "end": "1344600"
  },
  {
    "text": "two systems uh based on your requirements and needs",
    "start": "1344600",
    "end": "1349760"
  },
  {
    "text": "that's the most simplest deployment um if you need more scale you would typically deploy Kafka in front of jger",
    "start": "1349760",
    "end": "1357919"
  },
  {
    "text": "uh and as I mentioned before the alel collector can send data to Kafka in the",
    "start": "1357919",
    "end": "1364279"
  },
  {
    "text": "Jager format that can be then received by the Jager ingestor and stored into",
    "start": "1364279",
    "end": "1370279"
  },
  {
    "text": "your database",
    "start": "1370279",
    "end": "1376440"
  },
  {
    "text": "right so we jer's been stable for quite some time and we've been in version one",
    "start": "1376440",
    "end": "1383000"
  },
  {
    "text": "basically since the project started or became part of cncf but we're doing a",
    "start": "1383000",
    "end": "1388679"
  },
  {
    "text": "pretty major re architecture where there's going to be some breaking changes and we're trying to minimize",
    "start": "1388679",
    "end": "1395440"
  },
  {
    "text": "those but ultimately we're rebuilding jger around the open Telemetry collector",
    "start": "1395440",
    "end": "1401080"
  },
  {
    "text": "and the idea is to embrace the ecosystem to reduce redundancy in the code base",
    "start": "1401080",
    "end": "1406679"
  },
  {
    "text": "and the things that folks have to learn about and maintain and so this is a very big project for us to move towards this",
    "start": "1406679",
    "end": "1413919"
  },
  {
    "text": "that's been in the works for quite some time and the goal besides adopting The",
    "start": "1413919",
    "end": "1419440"
  },
  {
    "text": "Collector is also to support new types of storage and apis so today the",
    "start": "1419440",
    "end": "1426039"
  },
  {
    "text": "supported backends for joerger officially are Cassandra elastic search",
    "start": "1426039",
    "end": "1431520"
  },
  {
    "text": "open search we're very close to click house I'm going to talk about that later",
    "start": "1431520",
    "end": "1437000"
  },
  {
    "text": "uh but the idea is to build new new storage apis in open Telemetry to support that we also want to make sure",
    "start": "1437000",
    "end": "1444120"
  },
  {
    "text": "that it's compatible with those of you that are using Jagger version one so that the UI continues to function either",
    "start": "1444120",
    "end": "1451200"
  },
  {
    "text": "way and we're trying to make it as compatible as possible to avoid any",
    "start": "1451200",
    "end": "1456720"
  },
  {
    "text": "issues with your migrations or as you're in the middle of changing it and part of",
    "start": "1456720",
    "end": "1462120"
  },
  {
    "text": "it is also supporting OTP natively uh as much as possible and not just on the",
    "start": "1462120",
    "end": "1468399"
  },
  {
    "text": "edges of joer as pav just described uh similarly today there's a few different",
    "start": "1468399",
    "end": "1474960"
  },
  {
    "text": "binaries for joer that are part of the microservices the goal is to incorporate",
    "start": "1474960",
    "end": "1480000"
  },
  {
    "text": "those into a single binary that can be used in many different ways within your jger environment so simplifying the",
    "start": "1480000",
    "end": "1487480"
  },
  {
    "text": "complexity of the services and making it so that you can configure it in any way that you need to in terms of your scale",
    "start": "1487480",
    "end": "1494799"
  },
  {
    "text": "and use cases um and the config we're moving",
    "start": "1494799",
    "end": "1500159"
  },
  {
    "text": "instead of the CLI Jagger you can pass crazy amounts of arguments into and",
    "start": "1500159",
    "end": "1505880"
  },
  {
    "text": "configure everything on the CLI only there's no config file open Telemetry",
    "start": "1505880",
    "end": "1511720"
  },
  {
    "text": "uses config files specifically so we're moving in that direction where config",
    "start": "1511720",
    "end": "1516880"
  },
  {
    "text": "files will be used and not huge amounts of arguments to the to the binaries that",
    "start": "1516880",
    "end": "1522279"
  },
  {
    "text": "are being executed so these are some of the goals that that we had in mind with the project and uh Pavo will kind of",
    "start": "1522279",
    "end": "1530440"
  },
  {
    "text": "take you through a little bit more of the architecture yeah so essentially what we",
    "start": "1530440",
    "end": "1535799"
  },
  {
    "text": "want to do we want to implement Jagger functionality as open telemetric collector",
    "start": "1535799",
    "end": "1541840"
  },
  {
    "text": "components uh so for instance the query will be an extension and the storage",
    "start": "1541840",
    "end": "1548000"
  },
  {
    "text": "will be as exporter um and then produce a single build of this Jagger",
    "start": "1548000",
    "end": "1556200"
  },
  {
    "text": "collector um where you will be able to you know pick the right exporter for",
    "start": "1556200",
    "end": "1561279"
  },
  {
    "text": "your storage uh as well enable the the span metric connector or any uh other",
    "start": "1561279",
    "end": "1569000"
  },
  {
    "text": "collector capability that are available in the ecosystem so let's take a look at the",
    "start": "1569000",
    "end": "1575279"
  },
  {
    "text": "config um hopefully it's it's big enough um so this is what we have um what I",
    "start": "1575279",
    "end": "1583120"
  },
  {
    "text": "mention I think the most important here is the extensions there are two of them",
    "start": "1583120",
    "end": "1588320"
  },
  {
    "text": "it's the Jagger storage extension and the Jagger query extension in the",
    "start": "1588320",
    "end": "1594480"
  },
  {
    "text": "storage extension you define which storage back end you want to use um in this case it's in memory and then you",
    "start": "1594480",
    "end": "1601799"
  },
  {
    "text": "wire the storage with the query extension so in this case uh in the",
    "start": "1601799",
    "end": "1607360"
  },
  {
    "text": "query extension I specifi the mem store which the configuration for the M store",
    "start": "1607360",
    "end": "1612799"
  },
  {
    "text": "is in the storage extension and then in the exporter I again refer",
    "start": "1612799",
    "end": "1618760"
  },
  {
    "text": "the um the Jagger storage extension this is the way how we wire together the",
    "start": "1618760",
    "end": "1624399"
  },
  {
    "text": "exporter with the query which is sort of kind of new innovation in the open telemetric",
    "start": "1624399",
    "end": "1630240"
  },
  {
    "text": "collector there is at the moment no way how these things are",
    "start": "1630240",
    "end": "1636679"
  },
  {
    "text": "done um what is cool about this setup is as well that you can easily combine multiple exporters in your config so for",
    "start": "1637000",
    "end": "1645480"
  },
  {
    "text": "instance um I showed you the dependency diagram right the uh the system",
    "start": "1645480",
    "end": "1651760"
  },
  {
    "text": "architecture uh in my setup it's using the the inmemory store but if you are",
    "start": "1651760",
    "end": "1657240"
  },
  {
    "text": "using elastic search um you would need to as well enable that for elastic search but it's much easier to calculate",
    "start": "1657240",
    "end": "1664480"
  },
  {
    "text": "this data just in memory um and with the new setup you will be able to you know",
    "start": "1664480",
    "end": "1669519"
  },
  {
    "text": "combine your Spence store with the persistent storage of elastic search and the dependency store with the with the",
    "start": "1669519",
    "end": "1676640"
  },
  {
    "text": "inmemory solution uh so on the progress uh we already have",
    "start": "1676640",
    "end": "1682720"
  },
  {
    "text": "the build uh the base uh is in the place uh we as well publish the docker images",
    "start": "1682720",
    "end": "1688399"
  },
  {
    "text": "so we can run it uh it's in beta uh and we would like to release um G probably",
    "start": "1688399",
    "end": "1695120"
  },
  {
    "text": "this year um most of the work is uh happening from mentorship um uh and we",
    "start": "1695120",
    "end": "1702799"
  },
  {
    "text": "would like to as well invite you to help us with the project um uh at a cube Con",
    "start": "1702799",
    "end": "1708440"
  },
  {
    "text": "on Friday there is a jagger contri Fest um and I invite you all to to join me",
    "start": "1708440",
    "end": "1714039"
  },
  {
    "text": "and try to work on the Jager V2 support and now let's talk about the the",
    "start": "1714039",
    "end": "1721480"
  },
  {
    "text": "road map thank you very much yeah so we're uh",
    "start": "1721480",
    "end": "1726720"
  },
  {
    "text": "we're super excited about V2 uh we we're really thankful to the mentees that are",
    "start": "1726720",
    "end": "1732080"
  },
  {
    "text": "helping both through Linux foundation and Google summer of code so we have two",
    "start": "1732080",
    "end": "1737240"
  },
  {
    "text": "mentorships running we try to do this to get more maintainers and more participants in the",
    "start": "1737240",
    "end": "1743480"
  },
  {
    "text": "project um wrong way so uh a few new things and I've had folks come to the",
    "start": "1743480",
    "end": "1749760"
  },
  {
    "text": "booth this morning and ask we now officially support elastic search V8 so that was something that was missing for",
    "start": "1749760",
    "end": "1756200"
  },
  {
    "text": "some time that's new uh we've already kind of talked about uh Jagger V3 but",
    "start": "1756200",
    "end": "1762279"
  },
  {
    "text": "some additional capabilities uh we uh also support open search and Badger",
    "start": "1762279",
    "end": "1768799"
  },
  {
    "text": "these are sort of new and updated versions of the backends we've created a few new capabilities in the UI um these",
    "start": "1768799",
    "end": "1777120"
  },
  {
    "text": "are mostly enhancements you saw pavle talk about critical path there's a lot of other capabilities that we've added",
    "start": "1777120",
    "end": "1783760"
  },
  {
    "text": "into the UI uh to make it easier I'm not going to go by through them one at a",
    "start": "1783760",
    "end": "1788840"
  },
  {
    "text": "time uh in terms of the road map uh joerger V2 is soon to be beta hopefully",
    "start": "1788840",
    "end": "1795880"
  },
  {
    "text": "in the next couple of months as the goal and uh we kind of explained some of the the pieces here but uh that also we have",
    "start": "1795880",
    "end": "1803679"
  },
  {
    "text": "to work on our Pipeline and documentation and various other things so even if you don't write code and you",
    "start": "1803679",
    "end": "1810039"
  },
  {
    "text": "can help with docs or you're interested in the project please reach out we we are on the cncf slack which I'll mention",
    "start": "1810039",
    "end": "1818399"
  },
  {
    "text": "uh but we're always looking for help you don't have to be you know a great coder you can do all kinds of things to help",
    "start": "1818399",
    "end": "1824519"
  },
  {
    "text": "the project the other thing that we're doing is we're supporting click house natively in joerger V2 a lot of people",
    "start": "1824519",
    "end": "1831480"
  },
  {
    "text": "are interested in Click house and it's a a great database that's highly efficient for uh trace and log data uh so there's",
    "start": "1831480",
    "end": "1840000"
  },
  {
    "text": "much more coming um but before I go to Q&A uh definitely check out the docs we",
    "start": "1840000",
    "end": "1847279"
  },
  {
    "text": "have a community call monthly join the cncf slack um and definitely you can leave",
    "start": "1847279",
    "end": "1854880"
  },
  {
    "text": "feedback and uh with that I guess we will open open it up to Q&A I think we've got a few minutes uh there's a",
    "start": "1854880",
    "end": "1862159"
  },
  {
    "text": "couple of mics on either side on Long Booms that you can feel free to ask any",
    "start": "1862159",
    "end": "1870320"
  },
  {
    "text": "[Applause]",
    "start": "1872710",
    "end": "1880600"
  },
  {
    "text": "questions got one question on the left here thanks hello and you have very nice",
    "start": "1880600",
    "end": "1886000"
  },
  {
    "text": "presentation and we are eager to see Jagger version too uh so yeah I wanted",
    "start": "1886000",
    "end": "1891039"
  },
  {
    "text": "to ask uh in a very high uh Lo",
    "start": "1891039",
    "end": "1896120"
  },
  {
    "text": "environments where you have lots of transactions or requests uh we found uh",
    "start": "1896120",
    "end": "1902440"
  },
  {
    "text": "useful to utilize sampling however uh what would you uh",
    "start": "1902440",
    "end": "1909840"
  },
  {
    "text": "advise or what would be the best practices when using sampling to combine",
    "start": "1909840",
    "end": "1915360"
  },
  {
    "text": "multiple instrumentation data and make sure that they are all",
    "start": "1915360",
    "end": "1921960"
  },
  {
    "text": "sample I'll give you my opinion and then Pav's uh what we've seen is that for",
    "start": "1921960",
    "end": "1928720"
  },
  {
    "text": "things like 200 error so using uh tailbase sampling is always better",
    "start": "1928720",
    "end": "1934240"
  },
  {
    "text": "because then you can look at the end of a transaction and decide whether to keep it or discard it so for example if",
    "start": "1934240",
    "end": "1940760"
  },
  {
    "text": "you're having requests that are 200 where they're okay and the latency is relatively low you probably only need 1%",
    "start": "1940760",
    "end": "1948720"
  },
  {
    "text": "of those just so that you have a baseline if they're 500 errors or they exhibit High latency you want to keep",
    "start": "1948720",
    "end": "1955159"
  },
  {
    "text": "those so using different types of tailbase sampling is the best approach",
    "start": "1955159",
    "end": "1961039"
  },
  {
    "text": "but that also requires a lot of collector resources so it's a balancing act you need more memory in The",
    "start": "1961039",
    "end": "1967159"
  },
  {
    "text": "Collector to do tailbase sampling and it uses more processing power so it's",
    "start": "1967159",
    "end": "1972360"
  },
  {
    "text": "always a tradeoff whatever you decide to do but let me let Pavo give his opin",
    "start": "1972360",
    "end": "1977840"
  },
  {
    "text": "opinion too I think that that was good enough yeah okay so we're in agreement uh but yeah that that's always a good",
    "start": "1977840",
    "end": "1984600"
  },
  {
    "text": "thing we've got two minutes uh for one more question over there on the left thank you for the",
    "start": "1984600",
    "end": "1990799"
  },
  {
    "text": "question I noticed there was a kka support in V2 uh just wanted to ask if",
    "start": "1990799",
    "end": "1995960"
  },
  {
    "text": "there was any discussion about Pulsar support um whatsoever can you repeat about what",
    "start": "1995960",
    "end": "2002639"
  },
  {
    "text": "Paar support yeah I don't know any okay I so uh we the we support Kafka today",
    "start": "2002639",
    "end": "2009760"
  },
  {
    "text": "it's part of the architecture and it will continue to be supported because a lot of folks use it Pulsar uh does",
    "start": "2009760",
    "end": "2016840"
  },
  {
    "text": "support Kafka protocols so it should work have I used it or seen a customer",
    "start": "2016840",
    "end": "2022519"
  },
  {
    "text": "using Pulsar not personally but uh it should in theory work if the protocol is",
    "start": "2022519",
    "end": "2028880"
  },
  {
    "text": "compatible uh but I I haven't seen it offand all right thank you yeah",
    "start": "2028880",
    "end": "2035600"
  },
  {
    "text": "thanks so if there's no no other questions then thank you all for coming",
    "start": "2035600",
    "end": "2041960"
  },
  {
    "text": "have a great week at cubec con and uh see you at the contrib",
    "start": "2041960",
    "end": "2048519"
  },
  {
    "text": "Fest",
    "start": "2048919",
    "end": "2051919"
  }
]
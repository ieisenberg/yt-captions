[
  {
    "text": "good afternoon everyone welcome welcome welcome to kcon and thanks for coming",
    "start": "359",
    "end": "5759"
  },
  {
    "text": "into my talk today we're going to talk about something interesting about streaming data",
    "start": "5759",
    "end": "11160"
  },
  {
    "text": "processing my name is Derek W my body BJ marus is supposed to be here but he has",
    "start": "11160",
    "end": "17320"
  },
  {
    "text": "some last minute change cannot make it both vet and I are principal Engineers working for",
    "start": "17320",
    "end": "23720"
  },
  {
    "text": "in and we are the Project Lead or open source project nma flow I personally",
    "start": "23720",
    "end": "29519"
  },
  {
    "text": "also the project leader or cncf graduate project ARG",
    "start": "29519",
    "end": "34520"
  },
  {
    "text": "events here's today's agenda we're going to start with a brief introduction about our employer into it and then we're",
    "start": "37760",
    "end": "44200"
  },
  {
    "text": "going to talk about stream data processing its benefits in use cases and",
    "start": "44200",
    "end": "49520"
  },
  {
    "text": "we're also going to talk about the challenges we experienced when we use streaming technology with our system",
    "start": "49520",
    "end": "54640"
  },
  {
    "text": "platforms and then give our resolutions our open source project nlow followed by",
    "start": "54640",
    "end": "60440"
  },
  {
    "text": "demo and then in the end I'm going to take",
    "start": "60440",
    "end": "65198"
  },
  {
    "text": "questions start with the introduction about int I'm not sure how familiar you",
    "start": "67320",
    "end": "73080"
  },
  {
    "text": "guys are with the int the int is a a well-known fintech company which is",
    "start": "73080",
    "end": "78680"
  },
  {
    "text": "based in North America because we have some very famous product turu P Karma QuickBooks and",
    "start": "78680",
    "end": "86320"
  },
  {
    "text": "melin the turx is the most popular uh tax returning folling tool almost",
    "start": "86320",
    "end": "92920"
  },
  {
    "text": "everyone knows about it in North America and all these major products are actually powered by our five key",
    "start": "92920",
    "end": "99439"
  },
  {
    "text": "platform areas these five key platform areas make sure we deliver value to our customers and Accel Innovations",
    "start": "99439",
    "end": "106960"
  },
  {
    "text": "consistently across our organizations and with 100% of our service running on kubernetes based",
    "start": "106960",
    "end": "113880"
  },
  {
    "text": "modern s platform we are enabling billions of machine learning predictions",
    "start": "113880",
    "end": "119320"
  },
  {
    "text": "to billions Dollar's movement across our systems with the secure and smart",
    "start": "119320",
    "end": "125880"
  },
  {
    "text": "approach inter is also very large open source Community player we do not only",
    "start": "125880",
    "end": "131120"
  },
  {
    "text": "use open source technology build our platforms bu our services we also contribute a lot to open source Community as many of you know in is a",
    "start": "131120",
    "end": "138959"
  },
  {
    "text": "creator of Argo which is one of the most popular cncf graduate",
    "start": "138959",
    "end": "145080"
  },
  {
    "text": "project we also got two time cncf and user award in 2019 22 and more than that",
    "start": "145080",
    "end": "152040"
  },
  {
    "text": "we actually open source a lot of projects some of are listed here and the one we're going to talk about today is",
    "start": "152040",
    "end": "158840"
  },
  {
    "text": "called Numa flow which is a c native stream data processing platform the one with a PO",
    "start": "158840",
    "end": "167000"
  },
  {
    "text": "icon okay um finishing all these introductions let's move on to talk about stream data",
    "start": "167120",
    "end": "172920"
  },
  {
    "text": "processing before doing that I would like to ask you some questions how many of you actually um",
    "start": "172920",
    "end": "180040"
  },
  {
    "text": "data Engineers or ever working on data processing if you don't mind can raise your",
    "start": "180040",
    "end": "186360"
  },
  {
    "text": "hand quite a lot and how many of you uh actually are doing or ever done",
    "start": "186360",
    "end": "193120"
  },
  {
    "text": "streaming data processing are so so many okay so I'm",
    "start": "193120",
    "end": "199360"
  },
  {
    "text": "very glad that there are so many data engineers and non coming uh here for this talk and hope we can learn from",
    "start": "199360",
    "end": "205560"
  },
  {
    "text": "each other what is streaming data processing stream data processing is a technology",
    "start": "205560",
    "end": "211360"
  },
  {
    "text": "that continuously generate data process data and analyze data from various data",
    "start": "211360",
    "end": "216400"
  },
  {
    "text": "sources in real time or neuro time so streaming data is processed as the time",
    "start": "216400",
    "end": "221599"
  },
  {
    "text": "is generated is quite different from traditional data processing this traditional data processing system they",
    "start": "221599",
    "end": "227879"
  },
  {
    "text": "actually capture data in central data warehouse and process data in groups or",
    "start": "227879",
    "end": "233760"
  },
  {
    "text": "batches so those traditional systems were buil to inest data structure Data",
    "start": "233760",
    "end": "238799"
  },
  {
    "text": "before Analytics right however the nature of Enterprise",
    "start": "238799",
    "end": "245079"
  },
  {
    "text": "data is analyst there's no Bound for those data those are those are streaming",
    "start": "245079",
    "end": "251560"
  },
  {
    "text": "data so which means generating data volumes for those streaming data source could be very",
    "start": "251560",
    "end": "257519"
  },
  {
    "text": "large that makes that makes it no way to use traditional batch processing technology to to real time the streaming",
    "start": "257519",
    "end": "264919"
  },
  {
    "text": "analytics right and that's one of the reason why in the past year the streaming data process platform start to",
    "start": "264919",
    "end": "272000"
  },
  {
    "text": "evolve so imagine you have a iot application or you have some sensor data",
    "start": "272000",
    "end": "278160"
  },
  {
    "text": "and you are using tools like a cka kesis or P to process data you're most prop",
    "start": "278160",
    "end": "283479"
  },
  {
    "text": "doing stream data processing why streaming processing so",
    "start": "283479",
    "end": "289560"
  },
  {
    "text": "important so a lot of people are actually interested in stre data processing because it has many",
    "start": "289560",
    "end": "294639"
  },
  {
    "text": "benefits it give you Insight quickly about what's happening in your systems with the so that you can make quick",
    "start": "294639",
    "end": "300880"
  },
  {
    "text": "decisions it brings you better use experience it makes your business activity more efficient or imagine you",
    "start": "300880",
    "end": "307199"
  },
  {
    "text": "are building application like uber lift or any uh navigation system you really",
    "start": "307199",
    "end": "313320"
  },
  {
    "text": "want to know what happened in the past minutes or even seconds or you're building some system",
    "start": "313320",
    "end": "318880"
  },
  {
    "text": "like anomal detection really want to quickly detect if there any a problem with their services so that can take",
    "start": "318880",
    "end": "325759"
  },
  {
    "text": "quick actions or your buildings and fraud detection platform you want to Pro protect your customer from any data loss",
    "start": "325759",
    "end": "332080"
  },
  {
    "text": "or you know money loss in a short period of time right to build this kind of",
    "start": "332080",
    "end": "337360"
  },
  {
    "text": "system to achieve this kind of goals you really need to use streaming data processing",
    "start": "337360",
    "end": "343720"
  },
  {
    "text": "Technologies and on the other hand a lot of people think streaming data is or",
    "start": "344680",
    "end": "350440"
  },
  {
    "text": "streaming data processing is only the job of data unit actually it's not",
    "start": "350440",
    "end": "358080"
  },
  {
    "text": "right even you're not not using tools like a CA KES to store those data but",
    "start": "358080",
    "end": "365479"
  },
  {
    "text": "think about it your application keeps generating data keeps generating logs and matrics all day long that never ends",
    "start": "365479",
    "end": "373360"
  },
  {
    "text": "your customers keep booking hotels flights from your booking system or your",
    "start": "373360",
    "end": "378759"
  },
  {
    "text": "customers actually placing orders through your shopping system those those kind of data keeps coming to your system",
    "start": "378759",
    "end": "384160"
  },
  {
    "text": "it never ends those are all streaming data so that's why we why we said streaming is actually for everyone",
    "start": "384160",
    "end": "391120"
  },
  {
    "text": "stream data processing stream data is everywhere and stre data processing is for",
    "start": "391120",
    "end": "397000"
  },
  {
    "text": "everyone and we talk about stream data processing and its benefits use cases",
    "start": "397960",
    "end": "404880"
  },
  {
    "text": "but actually doing streaming realtime streaming process is not easy we have been using uh streaming",
    "start": "404880",
    "end": "411599"
  },
  {
    "text": "technology to build a lot of system and platforms and we actually experi a lot of",
    "start": "411599",
    "end": "417680"
  },
  {
    "text": "challenges one of a system we have we have buil is a anomal detection platform which is used uh used to detect the",
    "start": "417680",
    "end": "424319"
  },
  {
    "text": "anomaly of the of the application running kubernetes coners by applying",
    "start": "424319",
    "end": "429919"
  },
  {
    "text": "the Matrix emitted by those applications such as latency error rate or any custom",
    "start": "429919",
    "end": "435400"
  },
  {
    "text": "matrics to apply those matrics to AI machine learning model and to compute some anom score and then we use anomal",
    "start": "435400",
    "end": "442319"
  },
  {
    "text": "score to determine if your application is healthy or not right so this is a",
    "start": "442319",
    "end": "448280"
  },
  {
    "text": "system actually uh with the combined technology with stream data proc processing and the air machine",
    "start": "448280",
    "end": "455120"
  },
  {
    "text": "learning Technologies so the streaming The Matrix after streaming data keeps coming to our system and we experience a",
    "start": "455120",
    "end": "462080"
  },
  {
    "text": "lot of challenges to build this system the first challenge we",
    "start": "462080",
    "end": "467639"
  },
  {
    "text": "experienced is there was actually lots of boiler plate code for streaming in",
    "start": "467639",
    "end": "473039"
  },
  {
    "text": "every component what that means is for the anom detction platform we found our",
    "start": "473039",
    "end": "479759"
  },
  {
    "text": "machine learning Engineers spend a lot of time on writing code for screaming",
    "start": "479759",
    "end": "486120"
  },
  {
    "text": "infrastructure so for example you can imagine for the best thing that machine learning engineer can do is like to do",
    "start": "486120",
    "end": "492400"
  },
  {
    "text": "machine learning exploration and experiments but actually found they actually need to write code to consume",
    "start": "492400",
    "end": "498280"
  },
  {
    "text": "data from data source like C call or any other data sources and really they really need to figure out how to write a",
    "start": "498280",
    "end": "503720"
  },
  {
    "text": "reliable code to do that I found there are a lot of things like this so that's",
    "start": "503720",
    "end": "509800"
  },
  {
    "text": "first big challenge for us the Second Challenge we experience",
    "start": "509800",
    "end": "515440"
  },
  {
    "text": "is without having a dedicated stream data processing platform you probably will end up with running your streaming",
    "start": "515440",
    "end": "522399"
  },
  {
    "text": "platform with a collection of microservices right so to be honest with",
    "start": "522399",
    "end": "527800"
  },
  {
    "text": "you uh the nor detction platform we buil at the beginning is actually running you know some micros service to do that and",
    "start": "527800",
    "end": "533680"
  },
  {
    "text": "then actually you know we figure out you know we really need to deal with a lot of edog so for example you really figure",
    "start": "533680",
    "end": "539600"
  },
  {
    "text": "out how to make those micros service running in a springing fashion you how to make those micros servic like",
    "start": "539600",
    "end": "545320"
  },
  {
    "text": "reliable and maintainable so there are a lot of ad hoc you need to deal with let's assume you have Microsoft a and",
    "start": "545320",
    "end": "551680"
  },
  {
    "text": "Microsoft B you want to really figure out you know a c b and b c c right it's like a stream faction it's really hard",
    "start": "551680",
    "end": "556800"
  },
  {
    "text": "to do that so that's a second challenge for us the third one is",
    "start": "556800",
    "end": "563279"
  },
  {
    "text": "um for the traditional architecture it's really hard to do things like experiment",
    "start": "563279",
    "end": "569920"
  },
  {
    "text": "experimentation or exploration so for example for example if you want to try a new uh model for",
    "start": "569920",
    "end": "578040"
  },
  {
    "text": "the ninous score generation and found it really hard to um get it plugged into",
    "start": "578040",
    "end": "584079"
  },
  {
    "text": "the micros service system or if you want to do some extra data enrichment or do",
    "start": "584079",
    "end": "589640"
  },
  {
    "text": "some feature engineering there almost no way to do that for live running",
    "start": "589640",
    "end": "596200"
  },
  {
    "text": "system so that's the third challenge we experienced but this does not mean there's no",
    "start": "596200",
    "end": "602480"
  },
  {
    "text": "existing streaming system exist available so there are a lot like",
    "start": "602480",
    "end": "608399"
  },
  {
    "text": "fling and Spark streams they are all a very good streaming data processing",
    "start": "608399",
    "end": "613880"
  },
  {
    "text": "platform but the problem for this kind of system is they do centralized data",
    "start": "613880",
    "end": "619079"
  },
  {
    "text": "processing they're very costly and very heavy so imagine that's not a system you",
    "start": "619079",
    "end": "625120"
  },
  {
    "text": "can easily manage by yourself or install by yourself right you need to have a team",
    "start": "625120",
    "end": "630240"
  },
  {
    "text": "have maybe organization to to do that and those kind of actually require",
    "start": "630240",
    "end": "636320"
  },
  {
    "text": "very steep learning curve right so it's not a easy manage",
    "start": "636320",
    "end": "641519"
  },
  {
    "text": "system I can use another problem with the existing system is like almost most of the system",
    "start": "641519",
    "end": "647760"
  },
  {
    "text": "actually jvm based which means you need to use Java or Scala or those kind of",
    "start": "647760",
    "end": "653760"
  },
  {
    "text": "language to R your data processing jobs but think about it it's really hard",
    "start": "653760",
    "end": "658959"
  },
  {
    "text": "for data uh for machine learning Engineers for this Anon detection platform python is the most most popular",
    "start": "658959",
    "end": "666720"
  },
  {
    "text": "language and the favorite Lang by the machine learning engineers and and you know python is the language that bu for",
    "start": "666720",
    "end": "675079"
  },
  {
    "text": "the machine learning infrastructure in the library and it's really hard for our machine Lear to switch a different language like Java to write uh the",
    "start": "675079",
    "end": "682360"
  },
  {
    "text": "processing logic and sometime it's not about how to learn to a different language but",
    "start": "682360",
    "end": "688240"
  },
  {
    "text": "actually there's no way to use Java to achieve some sort of machine learning",
    "start": "688240",
    "end": "694120"
  },
  {
    "text": "because there's no available infrastructure for machine learning for you know Java language",
    "start": "694120",
    "end": "702399"
  },
  {
    "text": "right another problem with the existing platform is um they're not kubernetes",
    "start": "702560",
    "end": "708360"
  },
  {
    "text": "native which means they were not designed and buil for kubernetes even though they can wrong on",
    "start": "708360",
    "end": "715839"
  },
  {
    "text": "kuet somehow but for kubernetes we know the part",
    "start": "715839",
    "end": "724120"
  },
  {
    "text": "could be terminated or restarted very often due to many different kind of reasons you want to do not upgrade you",
    "start": "724120",
    "end": "730680"
  },
  {
    "text": "want to do a secure patch so your service needs to be very resilient to those kind of kubernetes life cycle",
    "start": "730680",
    "end": "737639"
  },
  {
    "text": "events but systems like flank if there's a PO res for this",
    "start": "737639",
    "end": "743320"
  },
  {
    "text": "worker Noe and then you really need to pass the pass your data person job to",
    "start": "743320",
    "end": "748440"
  },
  {
    "text": "wait for the work not come back and this is a big problem which means your",
    "start": "748440",
    "end": "755279"
  },
  {
    "text": "streaming data person platform cannot be running on the same infrastructure just like your regular applications",
    "start": "755279",
    "end": "763680"
  },
  {
    "text": "do so those are challenge we experienced and to address those",
    "start": "763680",
    "end": "768959"
  },
  {
    "text": "challenge solve this problem we come up with the solution which is our open source project called",
    "start": "768959",
    "end": "775240"
  },
  {
    "text": "Numa flow so Numa flow is uh kubernetes",
    "start": "775240",
    "end": "780880"
  },
  {
    "text": "Native streaming T processing platform here kubernetes native means we do not only running on",
    "start": "780880",
    "end": "787320"
  },
  {
    "text": "kubernetes we also use kubernetes native feature to build the platform which means you actually uh can",
    "start": "787320",
    "end": "795480"
  },
  {
    "text": "which means N Flow actually is like a resid to the C native life cycle events",
    "start": "795480",
    "end": "801240"
  },
  {
    "text": "like power restar not upgrade and then your data plan Java will not be interrupt that also means if you are if",
    "start": "801240",
    "end": "808079"
  },
  {
    "text": "you know about C and can easily use nflow to run your data processing jobs to do stream data",
    "start": "808079",
    "end": "813560"
  },
  {
    "text": "processing it's a very lightweight and easy to use framework you can install in your kuet cluster in cluster scope or",
    "start": "813560",
    "end": "820760"
  },
  {
    "text": "running your own namespace it's also a language agnostic",
    "start": "820760",
    "end": "826440"
  },
  {
    "text": "framework which means you can use whatever language you want to use to write for data processing jobs meanwhile",
    "start": "826440",
    "end": "832320"
  },
  {
    "text": "provide SDK for those different language right now we have Java python go rer score and it's easy to uh provide some",
    "start": "832320",
    "end": "841360"
  },
  {
    "text": "other language support as long as the the common uh JP interface are",
    "start": "841360",
    "end": "846839"
  },
  {
    "text": "implemented we also provide many building uh Source ins sys which means",
    "start": "846839",
    "end": "852560"
  },
  {
    "text": "you don't need to write any code to consume data or write data to common source and things like Kafka",
    "start": "852560",
    "end": "859360"
  },
  {
    "text": "Nas Redd Etc but meanwhile you still have the flexibility to write your own",
    "start": "859360",
    "end": "865120"
  },
  {
    "text": "user defin Source user defin sys an Autos scaling feature is auto the",
    "start": "865120",
    "end": "871759"
  },
  {
    "text": "Box supported we support Autos scaling Autos scale your worklow all the way down to",
    "start": "871759",
    "end": "878160"
  },
  {
    "text": "zero if there's no traffic in your data person Pipeline and scaling up to whatever number is needed based on",
    "start": "878160",
    "end": "885920"
  },
  {
    "text": "traffic and load in a full uh stream data processing feature provided platform we support",
    "start": "885920",
    "end": "893240"
  },
  {
    "text": "back pressure detection of back pressure handling and provided uh watermark",
    "start": "893240",
    "end": "899040"
  },
  {
    "text": "support out of the box and because of all this features we actually can",
    "start": "899040",
    "end": "904800"
  },
  {
    "text": "achieve the cost reduced like one3 compared with the similar infrastructure",
    "start": "904800",
    "end": "909920"
  },
  {
    "text": "running same Pipeline and we have we have some open",
    "start": "909920",
    "end": "915639"
  },
  {
    "text": "source Community user actually running nlow in uh some GPU devices which has no internet",
    "start": "915639",
    "end": "921680"
  },
  {
    "text": "access so it's very uh lightweight",
    "start": "921680",
    "end": "926639"
  },
  {
    "text": "structure we talk about the basic feature of Numa flow in let's look at what is nlow pipeline how to use nlow",
    "start": "927639",
    "end": "936000"
  },
  {
    "text": "Pipeline and suppose you have a streaming data stream a stream data source and you want to do some streaming",
    "start": "936000",
    "end": "941480"
  },
  {
    "text": "data processing for the data coming from the stream and how you going to do it with",
    "start": "941480",
    "end": "947440"
  },
  {
    "text": "nlow in nlow we actually abstract all the data jobs to a kuet is CR crd object",
    "start": "947440",
    "end": "954560"
  },
  {
    "text": "named pipeline so each pipeline contains multiple data process and steps and we",
    "start": "954560",
    "end": "960880"
  },
  {
    "text": "name each step as a Vertex so for this particular use case the first thing we need to do is come",
    "start": "960880",
    "end": "967279"
  },
  {
    "text": "about the source verdex it depend on what kind of data source you have you can use a um",
    "start": "967279",
    "end": "974000"
  },
  {
    "text": "peing Source verdex like kka or you write your own data user defined",
    "start": "974000",
    "end": "980800"
  },
  {
    "text": "source and after having a source verdex and what you need to do next is add in",
    "start": "980800",
    "end": "985959"
  },
  {
    "text": "some udfs UDF vertices here you UDF stands for uh user defined",
    "start": "985959",
    "end": "992480"
  },
  {
    "text": "functions and we support map reducer a box so which mean you can have some map UD UDF Vertex or some you know reduce",
    "start": "992480",
    "end": "1001560"
  },
  {
    "text": "UDF so usually you do things like a data enrichment data transformation you a map UDF and for this use case we also have a",
    "start": "1001560",
    "end": "1010120"
  },
  {
    "text": "reduce UDF following the map one so where you can do things like aggregation",
    "start": "1010120",
    "end": "1015199"
  },
  {
    "text": "AG aggregate by uh some sort of keys by appear",
    "start": "1015199",
    "end": "1020440"
  },
  {
    "text": "time and then in the end you actually forward data process data some data syns and similar to The Source you can use a",
    "start": "1020440",
    "end": "1027319"
  },
  {
    "text": "user Define source can here you can use a user Define sync or your us user Define I'm",
    "start": "1027319",
    "end": "1033319"
  },
  {
    "text": "sorry the building Sy or us defin things and an FL has a very interesting",
    "start": "1033319",
    "end": "1039558"
  },
  {
    "text": "feature called conditional forwarding which means you actually can forward your data uh to different Downstream",
    "start": "1039559",
    "end": "1047360"
  },
  {
    "text": "vertices when some sort of a conditions are met so uh here shows the condition",
    "start": "1047360",
    "end": "1053360"
  },
  {
    "text": "of forward into multiple things and each box on this diagram is actually a vertex and each vertex is",
    "start": "1053360",
    "end": "1060320"
  },
  {
    "text": "nothing but a set of Parts running your workload so we autoscale the",
    "start": "1060320",
    "end": "1065919"
  },
  {
    "text": "vertex for the different number of PS for each vertex that's Auto",
    "start": "1065919",
    "end": "1072320"
  },
  {
    "text": "skting and next I'm I'm going to go going to do a demo and if you want to",
    "start": "1073600",
    "end": "1079760"
  },
  {
    "text": "try this demo by yourself you actually can scan this QR code and you will lead you it will lead you to um get a",
    "start": "1079760",
    "end": "1086320"
  },
  {
    "text": "repository where you can find all the source code the steps to install or um",
    "start": "1086320",
    "end": "1091360"
  },
  {
    "text": "the demo needed scripts you will probably can do it byself in less than",
    "start": "1091360",
    "end": "1096679"
  },
  {
    "text": "10 minutes so set from Context for the demo",
    "start": "1096679",
    "end": "1102400"
  },
  {
    "text": "suppose you have a fot delivery application just like uber East I know",
    "start": "1102400",
    "end": "1107720"
  },
  {
    "text": "Uber East actually oper operational in France so you have some streaming order",
    "start": "1107720",
    "end": "1113600"
  },
  {
    "text": "coming from different clients web browser or um cell phone apps so at the",
    "start": "1113600",
    "end": "1121200"
  },
  {
    "text": "time your backend server is taking care of those uh streaming orders you you also want to do some streaming analytics",
    "start": "1121200",
    "end": "1128200"
  },
  {
    "text": "you want to see uh what are most popular restaurant in the past one hour or you",
    "start": "1128200",
    "end": "1135039"
  },
  {
    "text": "want to do something like a you know what is the revenue of those restaurant things like that right and then in the",
    "start": "1135039",
    "end": "1140960"
  },
  {
    "text": "end you want to um send the aggregated data back to another C",
    "start": "1140960",
    "end": "1147520"
  },
  {
    "text": "topic so this is a very generical use case for streaming analytics you actually find similar use case in",
    "start": "1147520",
    "end": "1153520"
  },
  {
    "text": "different scenarios to do this demo actually wrot a piece of code to simulate the order",
    "start": "1153520",
    "end": "1159080"
  },
  {
    "text": "examing order which is population the order information to a c topic and now I I create a newl",
    "start": "1159080",
    "end": "1167720"
  },
  {
    "text": "pipeline to do uh the the",
    "start": "1167720",
    "end": "1172760"
  },
  {
    "text": "analysis and then in the pipeline we're actually doing some data enrichment and data aggregation and things like that if",
    "start": "1173039",
    "end": "1180760"
  },
  {
    "text": "you look at the pipeline topology so I'm going to have a a source Vex which is used to consume",
    "start": "1180760",
    "end": "1188400"
  },
  {
    "text": "data from the C topic and then I have a enrichment Vex to add some missing",
    "start": "1188400",
    "end": "1194840"
  },
  {
    "text": "information or any information is needed for the analysis and then do agregation",
    "start": "1194840",
    "end": "1200240"
  },
  {
    "text": "and in the end send to",
    "start": "1200240",
    "end": "1204440"
  },
  {
    "text": "cing and quickly look into um the data transformation for this demo so this a",
    "start": "1205559",
    "end": "1212480"
  },
  {
    "text": "raw order information and there's a ID for this order it's a gon format okay",
    "start": "1212480",
    "end": "1218679"
  },
  {
    "text": "for this particular data there's a order ID in the resturant ID and the order time and there's some dishes that",
    "start": "1218679",
    "end": "1225760"
  },
  {
    "text": "customer order somehow uh the dish price is not in the order information so in",
    "start": "1225760",
    "end": "1231200"
  },
  {
    "text": "the enrichment step actually adding the dish price into uh the",
    "start": "1231200",
    "end": "1237480"
  },
  {
    "text": "data and because I I want to do agregation per restaurant right so it",
    "start": "1237480",
    "end": "1242880"
  },
  {
    "text": "would be better show the restaurant name instead instead of the restaurant ID so also add the restaurant name into do the",
    "start": "1242880",
    "end": "1248200"
  },
  {
    "text": "order information and this is the aggregated data so you can see there's a window",
    "start": "1248200",
    "end": "1254840"
  },
  {
    "text": "start time window end time and there a restaur name how many orders and what's the",
    "start": "1254840",
    "end": "1260320"
  },
  {
    "text": "revenue uh coming from the agregation now let me go to the",
    "start": "1260320",
    "end": "1269240"
  },
  {
    "text": "demo to do this demo I already pre uh install the nflow",
    "start": "1269640",
    "end": "1277440"
  },
  {
    "text": "controller in my local cluster actually running",
    "start": "1277440",
    "end": "1284600"
  },
  {
    "text": "a I'm running a k3d classroom my laptop you can you can actually run this demo",
    "start": "1284600",
    "end": "1290600"
  },
  {
    "text": "in whatever Comm cluster you want to do and I already got the pipeline grade",
    "start": "1290600",
    "end": "1297360"
  },
  {
    "text": "before I came to the stage so you can see there's actually a cka service",
    "start": "1297360",
    "end": "1305000"
  },
  {
    "text": "I running in my local names",
    "start": "1305000",
    "end": "1309760"
  },
  {
    "text": "space and also I have a order gen which is a piece code I mentioned earlier which is used to simulate the order",
    "start": "1311360",
    "end": "1317840"
  },
  {
    "text": "streaming order so if you take a look at the uh logs so",
    "start": "1317840",
    "end": "1325559"
  },
  {
    "text": "we are actually uh generating some streaming orders in the order information like the the order ID",
    "start": "1325559",
    "end": "1332080"
  },
  {
    "text": "restaurant ID right just like the one we just looking uh we we just want look in in the",
    "start": "1332080",
    "end": "1339520"
  },
  {
    "text": "slides and now if I will go to our UI coming from nlow",
    "start": "1339520",
    "end": "1347440"
  },
  {
    "text": "nlow provides a a very fancy UI something like this you actually can",
    "start": "1347440",
    "end": "1354000"
  },
  {
    "text": "uh check the transer view names View for the pipelines and I create the name I create",
    "start": "1354000",
    "end": "1361520"
  },
  {
    "text": "the pipeline in the default names space so I click default you're going to see there's a pipeline running it's called",
    "start": "1361520",
    "end": "1366919"
  },
  {
    "text": "order analysis and if you want to create a new pipeline you have click the button right",
    "start": "1366919",
    "end": "1372080"
  },
  {
    "text": "here and and put the you know your pipeline back and then you do a submit",
    "start": "1372080",
    "end": "1379679"
  },
  {
    "text": "so uh there's some other option you can do from this UI there's a pause there's a delete pipeline there's this kind of",
    "start": "1379679",
    "end": "1385200"
  },
  {
    "text": "operation for existing pipeline if you click this button you're going to see the pipeline to for this order analysis",
    "start": "1385200",
    "end": "1391320"
  },
  {
    "text": "there's in which is used to consume data from T topic on my laptop and there's a",
    "start": "1391320",
    "end": "1399559"
  },
  {
    "text": "enrichment aggregation and to do this demo actually create two things for this pipeline one is used to write the data",
    "start": "1399559",
    "end": "1407440"
  },
  {
    "text": "to so if you can see this spec I'm actually writing the aggregate data to another",
    "start": "1407440",
    "end": "1415039"
  },
  {
    "text": "topic mind topic output also have the lock sync which is",
    "start": "1415039",
    "end": "1420080"
  },
  {
    "text": "also a building sync which is used to print the Lo uh print the data in the syst log so that we can easily check we",
    "start": "1420080",
    "end": "1426279"
  },
  {
    "text": "don't need to to check the Kafka data over there right so if you look at this",
    "start": "1426279",
    "end": "1432159"
  },
  {
    "text": "pipeline actually putting out the enrichment uh orders for each order receipt from the C topic",
    "start": "1432159",
    "end": "1439080"
  },
  {
    "text": "so you can see for the enriched order we can see there's order information and there's a",
    "start": "1439080",
    "end": "1445200"
  },
  {
    "text": "um dis price right and there's a a rest name",
    "start": "1445200",
    "end": "1452400"
  },
  {
    "text": "which added to the order information if you look into uh the lock",
    "start": "1452400",
    "end": "1459880"
  },
  {
    "text": "sync and we can see the aggregated aggre information is something like this",
    "start": "1459880",
    "end": "1465919"
  },
  {
    "text": "there's a window start time window end time and restaurant name how many orders to the amount just like we uh expected",
    "start": "1465919",
    "end": "1472880"
  },
  {
    "text": "at the beginning and then we are seeing um for same aggregation window we are seeing",
    "start": "1472880",
    "end": "1480120"
  },
  {
    "text": "the the AG data for different restaurant if we go back to the pipeline",
    "start": "1480120",
    "end": "1486320"
  },
  {
    "text": "we're actually seeing some other information for for for stre data processing pipeline you're seeing the",
    "start": "1486320",
    "end": "1491399"
  },
  {
    "text": "average processing rate for one minute five minutes and 15 minutes we're also",
    "start": "1491399",
    "end": "1497080"
  },
  {
    "text": "showing uh The Watermark and is there any back pressure",
    "start": "1497080",
    "end": "1502159"
  },
  {
    "text": "for this pipeline showing the panning message in the backlog it's pretty pretty powerful uh",
    "start": "1502159",
    "end": "1510200"
  },
  {
    "text": "UI provided by Neu and then back to",
    "start": "1510200",
    "end": "1517039"
  },
  {
    "text": "slid and quickly look at the pipeline uh spec as I mentioned earlier we have a",
    "start": "1522640",
    "end": "1528679"
  },
  {
    "text": "vertices in a pipeline CD definition and for this pipeline we have in enrichment and aggregation and output we actually",
    "start": "1528679",
    "end": "1535799"
  },
  {
    "text": "have two uh two things I didn't mention in this this slides the second major",
    "start": "1535799",
    "end": "1541760"
  },
  {
    "text": "section for pipeline crd object is called Edge which use Define the relationship between those",
    "start": "1541760",
    "end": "1549159"
  },
  {
    "text": "vertices in the last piece of the of the demo is let's look at the source code all the source code needed for this",
    "start": "1549159",
    "end": "1556919"
  },
  {
    "text": "demo only these two pieces so one is for the enrichment and we're seeing there's",
    "start": "1556919",
    "end": "1563080"
  },
  {
    "text": "function called enrich and we are adding some U information like a rest name for the",
    "start": "1563080",
    "end": "1569200"
  },
  {
    "text": "each data received and returning we also add the dis price here and returning uh",
    "start": "1569200",
    "end": "1576360"
  },
  {
    "text": "a list of messages and if you look at this function it's very generic you're not",
    "start": "1576360",
    "end": "1583320"
  },
  {
    "text": "seeing any upstream or Downstream vertices you're not seeing any source and Sy",
    "start": "1583320",
    "end": "1588919"
  },
  {
    "text": "you only see there's a mapper do data it's like the data received for this particular uh enrichment of",
    "start": "1588919",
    "end": "1597760"
  },
  {
    "text": "verdex and this this is actually the most powerful part for neow that you don't need to care about all those abs",
    "start": "1597760",
    "end": "1604279"
  },
  {
    "text": "Downstream the platform will take care all the things for you you don't need to worry about",
    "start": "1604279",
    "end": "1609320"
  },
  {
    "text": "it and one more piece of this enrichment code is like uh we pay attention to the",
    "start": "1609320",
    "end": "1615720"
  },
  {
    "text": "return message we're actually doing the message returning with the with the keys",
    "start": "1615720",
    "end": "1621200"
  },
  {
    "text": "here because we know we're going to use the restaurant as the group by keys in the next aggregation step so returning",
    "start": "1621200",
    "end": "1627919"
  },
  {
    "text": "the message with keys or like a Resturant name and then on the right side is the aggregation",
    "start": "1627919",
    "end": "1633480"
  },
  {
    "text": "code similarly uh there's a generic function provided for the aggregation feature for the reduced",
    "start": "1633480",
    "end": "1639679"
  },
  {
    "text": "feature so you're getting a list of keys and you're getting um a channel for the",
    "start": "1639679",
    "end": "1645159"
  },
  {
    "text": "message you received this is a Soo code uh in in goand so you're seeing Channel",
    "start": "1645159",
    "end": "1650840"
  },
  {
    "text": "but if you're using some other SD like ja you're going to see something like the iterator or you know list it's like",
    "start": "1650840",
    "end": "1657000"
  },
  {
    "text": "that and there's some metadata and returning a list of reduced message and we're getting the rest name",
    "start": "1657000",
    "end": "1663960"
  },
  {
    "text": "from the keys and for all the message from the channel we do our for Loop and then you do some simple math right to",
    "start": "1663960",
    "end": "1670559"
  },
  {
    "text": "calculate how many orders in the to amount revenue and then we return the reduce",
    "start": "1670559",
    "end": "1676679"
  },
  {
    "text": "message as a Json stream we set that window start window end and rest name order count and",
    "start": "1676679",
    "end": "1682080"
  },
  {
    "text": "two and we're not seeing anything about uh the op and downstream",
    "start": "1682080",
    "end": "1688279"
  },
  {
    "text": "right so this like we're doing some sort of um unit function unit for swim data",
    "start": "1688279",
    "end": "1695679"
  },
  {
    "text": "processing you don't need to care about what's your data source and data sync you can easily switch the data source",
    "start": "1695679",
    "end": "1701679"
  },
  {
    "text": "and data syns to different different types you don't need to make any code change for that you don't need to make",
    "start": "1701679",
    "end": "1707840"
  },
  {
    "text": "any logic to your data person",
    "start": "1707840",
    "end": "1712080"
  },
  {
    "text": "pipeline all right so we just look at a demo um I hope you you know you know",
    "start": "1714360",
    "end": "1720440"
  },
  {
    "text": "some idea about how Numa to do exer data processing the stre analytics and we",
    "start": "1720440",
    "end": "1726519"
  },
  {
    "text": "just check the pipeline which is like you know line or tree tree shift and",
    "start": "1726519",
    "end": "1733080"
  },
  {
    "text": "actually um it's much more powerful than that so the first picture we're seeing here here is like a mul multiple Source",
    "start": "1733080",
    "end": "1740559"
  },
  {
    "text": "use case so suppose you have multiple Source One is cka another one is paa and",
    "start": "1740559",
    "end": "1745919"
  },
  {
    "text": "there in they have similar data structure you want to process that from these two different sources you don't instead of writing two pipeline you",
    "start": "1745919",
    "end": "1752039"
  },
  {
    "text": "actually combine both sources into one Pipeline and second picture actually uh",
    "start": "1752039",
    "end": "1760039"
  },
  {
    "text": "shows the joining use case joining is like you can join multiple option works",
    "start": "1760039",
    "end": "1766679"
  },
  {
    "text": "to uh say Downstream verx and we support maap joining or reduce",
    "start": "1766679",
    "end": "1773440"
  },
  {
    "text": "joining you you can do either one so this is like a fork and Joint use",
    "start": "1773440",
    "end": "1779159"
  },
  {
    "text": "case like a diamond shape right the third one is more interesting it's like",
    "start": "1779159",
    "end": "1784360"
  },
  {
    "text": "you can do cycling which means you can uh forward data to yourself or someone",
    "start": "1784360",
    "end": "1790640"
  },
  {
    "text": "in front of you this is very useful when you do sort of um reprocessing when some",
    "start": "1790640",
    "end": "1796279"
  },
  {
    "text": "sort of conditions are met or something like a rewi",
    "start": "1796279",
    "end": "1802600"
  },
  {
    "text": "right and last picture the fourth picture shows the side input support and side input is something um if you're",
    "start": "1802600",
    "end": "1810320"
  },
  {
    "text": "familiar with the appach beam and you probably know about side input that you actually can broadcast the change for",
    "start": "1810320",
    "end": "1815799"
  },
  {
    "text": "your screen processing unit for those kind of configuring change which is you know not very uh frequent to to",
    "start": "1815799",
    "end": "1824039"
  },
  {
    "text": "broadcast those kind to your stream processing unit without interruption your Pipeline and this is something",
    "start": "1824039",
    "end": "1830519"
  },
  {
    "text": "supporting IMF as well now let's to te a look at the use",
    "start": "1830519",
    "end": "1837080"
  },
  {
    "text": "cases first one is ding analytics for nlow of course I mean demo which is the",
    "start": "1837080",
    "end": "1844279"
  },
  {
    "text": "is actually an analytics and second one is you know ml",
    "start": "1844279",
    "end": "1850120"
  },
  {
    "text": "offs the example I mentioned earlier for uh streaming for nor DET detection",
    "start": "1850120",
    "end": "1855440"
  },
  {
    "text": "platform is actually mlops platform we actually get this running for in across all of in",
    "start": "1855440",
    "end": "1862480"
  },
  {
    "text": "I clusters and of course you can use it do like EV D applications your pipeline can",
    "start": "1862480",
    "end": "1868720"
  },
  {
    "text": "consume data from data source like Kafka and of course you can use write your own data source uh user defined source to",
    "start": "1868720",
    "end": "1875440"
  },
  {
    "text": "can set from any data source wanted you and some other information I want to",
    "start": "1875440",
    "end": "1882679"
  },
  {
    "text": "share and how nlow is used in the open source community and a lot of people are using it to Doom detection and one of",
    "start": "1882679",
    "end": "1889760"
  },
  {
    "text": "the user I think I mentioned earlier that they're using neop to do digital digital signal processing which is",
    "start": "1889760",
    "end": "1896159"
  },
  {
    "text": "running nflow in a GPU device which has no internet access we also run nflow run some",
    "start": "1896159",
    "end": "1905000"
  },
  {
    "text": "raspberry pie it's it's also working and one of the use case we have",
    "start": "1905000",
    "end": "1912519"
  },
  {
    "text": "is actually our C our open source user actually running IM flow it's actually very large car manufacturer I don't want",
    "start": "1912519",
    "end": "1919519"
  },
  {
    "text": "to mention the name right here but they're using IMA flow to do map data processing for their navigation",
    "start": "1919519",
    "end": "1926240"
  },
  {
    "text": "system and some data I can share here for in it uh we have been doing like",
    "start": "1926240",
    "end": "1932880"
  },
  {
    "text": "five billion message process each day and we're doing 60 million machine learning",
    "start": "1932880",
    "end": "1939320"
  },
  {
    "text": "predictions and UniFi model fine tune is like 45k per day in Twitter model it's",
    "start": "1939320",
    "end": "1946120"
  },
  {
    "text": "like 135k some of the information I can share here I think um that's all for my demo",
    "start": "1946120",
    "end": "1953440"
  },
  {
    "text": "if you are interested into this project actually can scan the large the bigger one to go to our open source uh",
    "start": "1953440",
    "end": "1961279"
  },
  {
    "text": "repos and the second one is the demo I just did we are initi want to run it by ourself just scan the barcode here and",
    "start": "1961279",
    "end": "1968960"
  },
  {
    "text": "now I'm taking question thank",
    "start": "1968960",
    "end": "1972880"
  },
  {
    "text": "you go ahead uh just a quick question when",
    "start": "1976840",
    "end": "1982720"
  },
  {
    "text": "you when you have those uh inputs and outputs those are the buffers inside of",
    "start": "1982720",
    "end": "1989120"
  },
  {
    "text": "um inside of the Numa flow documentation I just looked at yeah you can actually found all this information from our it's",
    "start": "1989120",
    "end": "1997639"
  },
  {
    "text": "it's it's um you mentioned the key at the output and in your example and I is",
    "start": "1997639",
    "end": "2004559"
  },
  {
    "text": "that the buffer concept so that buffer is like key value store that you have",
    "start": "2004559",
    "end": "2009880"
  },
  {
    "text": "somehow when you pass the messages around from one step to The Other M so",
    "start": "2009880",
    "end": "2015159"
  },
  {
    "text": "the keys the keys you only use for when you want to do some aggregation do some reduce feature right for for a regular",
    "start": "2015159",
    "end": "2020720"
  },
  {
    "text": "map operation you actually don't need do the keys uh so but if you want to do a reduce right Group by sort of um fixed",
    "start": "2020720",
    "end": "2028240"
  },
  {
    "text": "window sliding window or session window you want to group by uh some sort of keys or or you have you're not doing any",
    "start": "2028240",
    "end": "2035279"
  },
  {
    "text": "Cas you just want to to go by window and then you don't to have the keys but if you want to goow back Keys you need to",
    "start": "2035279",
    "end": "2040919"
  },
  {
    "text": "give the keys uh be in the previous Maps",
    "start": "2040919",
    "end": "2046600"
  },
  {
    "text": "UDF I'm not sure I answer your question it's not not really",
    "start": "2046840",
    "end": "2053638"
  },
  {
    "text": "but okay I have two questions I hope it's okay yeah uh you mentioned kavka in",
    "start": "2053639",
    "end": "2059800"
  },
  {
    "text": "the example uh but you also mentioned Pulsar um is there any plan to support",
    "start": "2059800",
    "end": "2065560"
  },
  {
    "text": "pulsar natively uh so that's first question uh right now we we actually have several",
    "start": "2065560",
    "end": "2073000"
  },
  {
    "text": "different kind of uh Source support one is you know 100% native which means the",
    "start": "2073000",
    "end": "2078240"
  },
  {
    "text": "source code for example kafa the source code of consuming data from kafa is actually embedded in in the platform",
    "start": "2078240",
    "end": "2084520"
  },
  {
    "text": "code in nflow source code so that's 100% native supported and we also have a",
    "start": "2084520",
    "end": "2089720"
  },
  {
    "text": "second layer of native support which means we provide some sort of uh Source",
    "start": "2089720",
    "end": "2095520"
  },
  {
    "text": "implementation but you're going to use it as a sard container and the other one is is um you",
    "start": "2095520",
    "end": "2103720"
  },
  {
    "text": "actually write your own source code you want you want to process data from a from for example from database we don't know what kind of schema you have in",
    "start": "2103720",
    "end": "2109880"
  },
  {
    "text": "your database table right so you have to write your own uh own user defined",
    "start": "2109880",
    "end": "2115079"
  },
  {
    "text": "Source the consumer data for that and for paa it's not in the it's not the first use case right now but we can make",
    "start": "2115079",
    "end": "2122400"
  },
  {
    "text": "it a native support yeah and that would be great uh second question question uh",
    "start": "2122400",
    "end": "2128480"
  },
  {
    "text": "you had Numa flow in the same cluster as kfka from what understood um is it",
    "start": "2128480",
    "end": "2134079"
  },
  {
    "text": "possible to have kfka in one cluster and Numa flow in different cluster",
    "start": "2134079",
    "end": "2139400"
  },
  {
    "text": "completely decoupled yeah of course so we don't care about what where your c car is sitting uh as long as as a c can",
    "start": "2139400",
    "end": "2147000"
  },
  {
    "text": "be accessible from the neow pipeline I'll I'll give you a hint why I'm asking",
    "start": "2147000",
    "end": "2153480"
  },
  {
    "text": "uh we use Pulsar uh we would use o for authentication right right so just",
    "start": "2153480",
    "end": "2159680"
  },
  {
    "text": "hinting into how would you handle having Pulsar cluster completely isolated right",
    "start": "2159680",
    "end": "2165920"
  },
  {
    "text": "now I would have a client I would authenticate and I could consume I would be super curious to see how that could",
    "start": "2165920",
    "end": "2171800"
  },
  {
    "text": "work with Numa flow um uh so you mention you have a paa",
    "start": "2171800",
    "end": "2177280"
  },
  {
    "text": "completely separate in one cluster yes but where do you want to run your pipeline that's so on a separate cluster",
    "start": "2177280",
    "end": "2184960"
  },
  {
    "text": "on separate and they need to make sure there's a connectivity to yes just hinting in this uh so maybe",
    "start": "2184960",
    "end": "2192480"
  },
  {
    "text": "we'll comment in a repo but it's really interesting uh because maybe we don't want to use pulser functions and that",
    "start": "2192480",
    "end": "2198720"
  },
  {
    "text": "would be an interesting use case to use Numa flow yeah of course uh we actually have slack Channel mentioning the G",
    "start": "2198720",
    "end": "2204599"
  },
  {
    "text": "reposer if you are interested in uh use case or interesting you know by using",
    "start": "2204599",
    "end": "2209680"
  },
  {
    "text": "Numa do your use case you're welcome to Sure reach out to us thank you thank",
    "start": "2209680",
    "end": "2216520"
  },
  {
    "text": "you I I have a question so my understanding is that Numa flow acts bit",
    "start": "2216520",
    "end": "2221960"
  },
  {
    "text": "as a CF cast streams application so it consumes from an input topic and wres to",
    "start": "2221960",
    "end": "2227440"
  },
  {
    "text": "an output topic would you confirm or um uh no we're not using kast stream we",
    "start": "2227440",
    "end": "2232760"
  },
  {
    "text": "actually it's like a c so the num pipeline is a is a you know have nothing",
    "start": "2232760",
    "end": "2238720"
  },
  {
    "text": "to do with you know CA stream it's like you actually can use it to consume whatever data you want to consume K got",
    "start": "2238720",
    "end": "2245160"
  },
  {
    "text": "just use because you know we into it we have a lot of Kafka use case and which",
    "start": "2245160",
    "end": "2250480"
  },
  {
    "text": "so we provide a first layer support for Kafka we provide native support for Kafka you don't need",
    "start": "2250480",
    "end": "2256319"
  },
  {
    "text": "to write any code consim dat from Kafka and what I what I was what I wanted to say is like you're trying to like do",
    "start": "2256319",
    "end": "2262240"
  },
  {
    "text": "what Kafka stream does in a cloud native way like and and then like my question is basically for um for the database so",
    "start": "2262240",
    "end": "2271160"
  },
  {
    "text": "for the aggregation function do you have an internal database for the aggregation",
    "start": "2271160",
    "end": "2276440"
  },
  {
    "text": "or sorry I didn't hear you very",
    "start": "2276440",
    "end": "2281078"
  },
  {
    "text": "clear Oh you mean for internal massage transmission or",
    "start": "2286040",
    "end": "2293839"
  },
  {
    "text": "yeah yeah okay I got your question so there",
    "start": "2293839",
    "end": "2299200"
  },
  {
    "text": "are two um two layer of a data prist for um num pipelines we actually support",
    "start": "2299200",
    "end": "2304640"
  },
  {
    "text": "exact once delivery symmetrics mentioned that during the talk we actually support",
    "start": "2304640",
    "end": "2309720"
  },
  {
    "text": "that so there are two layer of a process for running pipeline uh we have some",
    "start": "2309720",
    "end": "2315040"
  },
  {
    "text": "something called indust buffer between each vertex so um all the message",
    "start": "2315040",
    "end": "2320720"
  },
  {
    "text": "transmitting the pipeline we actually persistent in the in this a buffer right now we're using G room Nas G room",
    "start": "2320720",
    "end": "2327000"
  },
  {
    "text": "someone mentioned that in previous talk we also use G room to do that but it's but actually it's a plugin you can use",
    "start": "2327000",
    "end": "2332560"
  },
  {
    "text": "whatever um you can use some other sort of ISB implementation to do that that's",
    "start": "2332560",
    "end": "2338560"
  },
  {
    "text": "first level persistence for the particular reduce use case uh for reduce",
    "start": "2338560",
    "end": "2343880"
  },
  {
    "text": "we also we also process data in each of the part by using PVC so when you come",
    "start": "2343880",
    "end": "2349520"
  },
  {
    "text": "up with the when you come up with the uh I actually can show that in",
    "start": "2349520",
    "end": "2355440"
  },
  {
    "text": "the spec here uh when you put your aggregation step",
    "start": "2355440",
    "end": "2363520"
  },
  {
    "text": "here you actually need to provide a PVC or provide any other sort of uh person",
    "start": "2363520",
    "end": "2369319"
  },
  {
    "text": "solution you write directly on file system or like do you have a layer uh it's say in the file system right so you",
    "start": "2369319",
    "end": "2376760"
  },
  {
    "text": "don't have any kind of cach like for like large large scale",
    "start": "2376760",
    "end": "2382599"
  },
  {
    "text": "data yeah so right now the throughput with support is around you know any any",
    "start": "2382599",
    "end": "2387800"
  },
  {
    "text": "throughput below 30k per second you can use me for the",
    "start": "2387800",
    "end": "2394520"
  },
  {
    "text": "process thanks and also like when one other question do you have AO support",
    "start": "2394520",
    "end": "2399680"
  },
  {
    "text": "for for for Kafka I mean ordering support AO AO a schemas support other",
    "start": "2399680",
    "end": "2406800"
  },
  {
    "text": "schema support you mean other type of data source or a a is just a modeling",
    "start": "2406800",
    "end": "2412640"
  },
  {
    "text": "like model uh it's if you have other schemas if you can consume data with",
    "start": "2412640",
    "end": "2418440"
  },
  {
    "text": "other schem okay so actually we don't care about what kind of data data format in your your data source so in our",
    "start": "2418440",
    "end": "2425400"
  },
  {
    "text": "platform in our system in the project actually what we see is like B array it's just binary so if you write your",
    "start": "2425400",
    "end": "2433319"
  },
  {
    "text": "own user defined functions you actually need to be aware of what kind of data schema you're using so we we don't care",
    "start": "2433319",
    "end": "2439960"
  },
  {
    "text": "about what kind of schema you're using it's not I just use a Json as a example to um for demo but you can determine",
    "start": "2439960",
    "end": "2447440"
  },
  {
    "text": "what kind of data format I want to use okay thanks any other",
    "start": "2447440",
    "end": "2455359"
  },
  {
    "text": "questions so uh small question how do you define",
    "start": "2456240",
    "end": "2461800"
  },
  {
    "text": "how you um what's your access point in the container because I assume you're",
    "start": "2461800",
    "end": "2467520"
  },
  {
    "text": "not starting a new container for every element you have to process in your stream but I don't see here any entry",
    "start": "2467520",
    "end": "2474960"
  },
  {
    "text": "point of how this container should start like I see image and I see a lot of other other parts but how do you know",
    "start": "2474960",
    "end": "2481079"
  },
  {
    "text": "which function to execute in a container for example uh we actually provide an",
    "start": "2481079",
    "end": "2486880"
  },
  {
    "text": "some DK support uh so I actually can show you the source code for this demo",
    "start": "2486880",
    "end": "2492319"
  },
  {
    "text": "so this is the small QR code I showed there if you scan the C code you actually can see uh all the source code",
    "start": "2492319",
    "end": "2498920"
  },
  {
    "text": "for uh this demo if you go to so there's a main",
    "start": "2498920",
    "end": "2505160"
  },
  {
    "text": "function which is the image I mentioned in in the demo so you're seeing main",
    "start": "2505160",
    "end": "2511000"
  },
  {
    "text": "function here right if it's inrich we actually start the inrich function like this mapper new Ser that's something we",
    "start": "2511000",
    "end": "2517000"
  },
  {
    "text": "provide Ed so in SDK or reduce with a similar function than",
    "start": "2517000",
    "end": "2524200"
  },
  {
    "text": "yeah any other question uh I have a question if you uh",
    "start": "2524839",
    "end": "2534000"
  },
  {
    "text": "the whole pipeline exists in one custom resource uh is it correct so if we want",
    "start": "2534000",
    "end": "2540400"
  },
  {
    "text": "to add the new Sy uh how does it work should we recreate all PIP plan or",
    "start": "2540400",
    "end": "2549119"
  },
  {
    "text": "uh if we are adding uh syn for existing pipeline",
    "start": "2549200",
    "end": "2554559"
  },
  {
    "text": "uhhuh so you actually want to change the top for the pipeline right you want for example you want to add a branch you",
    "start": "2554559",
    "end": "2560079"
  },
  {
    "text": "want to add a syn or add a source right uh I want to add a syn you want to add a syn you just to change the pipeline spec",
    "start": "2560079",
    "end": "2565960"
  },
  {
    "text": "and apply it again that's it ah okay but you actually you know it's you know my",
    "start": "2565960",
    "end": "2571160"
  },
  {
    "text": "answer to this question is not 100% correct it actually depends on what kind of use case you have so for example you",
    "start": "2571160",
    "end": "2578040"
  },
  {
    "text": "actually adding some uh new topal for the pipeline but actually or updating or removing some pipe some you know noes",
    "start": "2578040",
    "end": "2585720"
  },
  {
    "text": "for for the pipeline it depends on if you have any um Legacy data or backlog",
    "start": "2585720",
    "end": "2592160"
  },
  {
    "text": "in the in in the in the pipeline if you're new veres actually does not recognize they do not recognize the the",
    "start": "2592160",
    "end": "2599880"
  },
  {
    "text": "um the backlog the data and then it's going to be a problem so you need to make sure those kind of things are not a",
    "start": "2599880",
    "end": "2605640"
  },
  {
    "text": "problem for you oh okay thanks",
    "start": "2605640",
    "end": "2610200"
  },
  {
    "text": "yeah I think we're out of time um if you have any question I will stay here",
    "start": "2611119",
    "end": "2618119"
  },
  {
    "text": "and we'll answer your questions over there okay thank you",
    "start": "2618119",
    "end": "2624520"
  }
]
[
  {
    "text": "my name is Alessandro falgartia I'm a Senior Solutions engineer in the nginx",
    "start": "0",
    "end": "5040"
  },
  {
    "text": "community analysis team and I also happen to be the main slash only",
    "start": "5040",
    "end": "10559"
  },
  {
    "text": "internal developer for two of our most popular open source projects one of them",
    "start": "10559",
    "end": "16440"
  },
  {
    "text": "is the docker nginx and privileged image and the other one is the ansible nginx",
    "start": "16440",
    "end": "22740"
  },
  {
    "text": "role gets a little you know I was keeping before I get",
    "start": "22740",
    "end": "28560"
  },
  {
    "text": "started proper you can find my contact details down there in the slide I'm sure you have any questions after the session",
    "start": "28560",
    "end": "35280"
  },
  {
    "text": "feel free if I don't get to them here feel free to shoot me an email get in touch via Twitter or GitHub",
    "start": "35280",
    "end": "41640"
  },
  {
    "text": "and just to set expectations a little bit more I don't think any of the",
    "start": "41640",
    "end": "46920"
  },
  {
    "text": "lessons that I'm gonna be covering here or necessarily going to be groundbreaking but hopefully they confirm things that you're already doing",
    "start": "46920",
    "end": "53219"
  },
  {
    "text": "in your pipelines nowadays or they provide some guidance on how you could improve some of your workflows",
    "start": "53219",
    "end": "60180"
  },
  {
    "text": "and with that being said and done let's move to you",
    "start": "60180",
    "end": "65338"
  },
  {
    "text": "the beginning chapter one The grade nginx so you probably already know what nginx is",
    "start": "65339",
    "end": "73260"
  },
  {
    "text": "but just in case just sea level set expectation what level said you know a little bit of what engine X is about and",
    "start": "73260",
    "end": "79140"
  },
  {
    "text": "just two people that might be actually tuning to the recording later down the line let me give you all a brief recap about",
    "start": "79140",
    "end": "85259"
  },
  {
    "text": "nginx nginx is well it started as a web server in 2004",
    "start": "85259",
    "end": "90500"
  },
  {
    "text": "the main goal back when it was first created or the problem it was trying to solve was the world famous c10k problem",
    "start": "90500",
    "end": "97640"
  },
  {
    "text": "which The Cliff Notes version of that problem is that no server before nginx could handle 10K concurrent connections",
    "start": "97640",
    "end": "105299"
  },
  {
    "text": "then engine X came along and it was able to handle them there's a little bit more Nuance behind it obviously but I'm not",
    "start": "105299",
    "end": "111000"
  },
  {
    "text": "going to delve into it right now as of April 2023 it's the most used web server",
    "start": "111000",
    "end": "116700"
  },
  {
    "text": "in the world and in the almost 20 years since it first got created it's been you",
    "start": "116700",
    "end": "123420"
  },
  {
    "text": "know a bunch of new features that have been added these days in addition to being able to use nginx as a web server",
    "start": "123420",
    "end": "128700"
  },
  {
    "text": "you can use it as a reverse proxy it's an API Gateway a certain content cache it's CDN as a wife and the list goes on",
    "start": "128700",
    "end": "136440"
  },
  {
    "text": "you can pretty much do everything with financial X well not everything but you know you get the gist and there's very very good reason for",
    "start": "136440",
    "end": "143760"
  },
  {
    "text": "its increasing performance you could say that engine xcst Formula One car of web servers it has a very performant engine",
    "start": "143760",
    "end": "150239"
  },
  {
    "text": "hence the name engine X that's probably a joke I actually don't know what it came from but it also has a very",
    "start": "150239",
    "end": "157260"
  },
  {
    "text": "lightweight encasing it's around 8 megabytes on Alpine Linux if you're using other distributions Debian Rel",
    "start": "157260",
    "end": "162540"
  },
  {
    "text": "whatever it's not going to be eight megabytes but it's still pretty small combine those two things together you",
    "start": "162540",
    "end": "168780"
  },
  {
    "text": "get a place only fast web server well you know reverse proxy API Gateway depends on how you want to use it",
    "start": "168780",
    "end": "176280"
  },
  {
    "text": "moving on chapter two Loft GitHub projects so now that you covered a little bit about nginx and we",
    "start": "176280",
    "end": "182519"
  },
  {
    "text": "move on to the two projects that I'm going to be talking about today the first one is the",
    "start": "182519",
    "end": "187980"
  },
  {
    "text": "docker engine accent privilege image this project is fundamentally a part of",
    "start": "187980",
    "end": "194159"
  },
  {
    "text": "the Upstream Docker nginx repository which you'll probably have used at some stage in your life",
    "start": "194159",
    "end": "200700"
  },
  {
    "text": "and the only major difference well there's two main differences the first one is that uh",
    "start": "200700",
    "end": "206580"
  },
  {
    "text": "it obviously makes some changes to the docker image to be able to run nginx and on a privileged environment the second",
    "start": "206580",
    "end": "212519"
  },
  {
    "text": "main difference is that it has its own pipeline see build and push those images the Upstream Docker engine X repo",
    "start": "212519",
    "end": "221340"
  },
  {
    "text": "as part of the official Docker engineer Docker Library so all the pipelines are",
    "start": "221340",
    "end": "226620"
  },
  {
    "text": "maintained and you know supported by docker for various reasons that I'm not going to delve into here TM privilege",
    "start": "226620",
    "end": "234000"
  },
  {
    "text": "image is not part of the official Library which means all the title the building pushing all the CD",
    "start": "234000",
    "end": "239580"
  },
  {
    "text": "pipelines have to be run locally by well not by me not luckily I guess but",
    "start": "239580",
    "end": "245040"
  },
  {
    "text": "you know definitely be integrated with into people run bios by insurance",
    "start": "245040",
    "end": "250379"
  },
  {
    "text": "and then there's the ancible engine Lex role um she'll note there's a bunch of other nginx roles out there and several World",
    "start": "250379",
    "end": "256799"
  },
  {
    "text": "Series one for configuring nginx there's one for nginx approject which is our commercial life offering there's an",
    "start": "256799",
    "end": "262380"
  },
  {
    "text": "ansible collection for nginx a bunch of sensible stuff out there but all of the",
    "start": "262380",
    "end": "269100"
  },
  {
    "text": "Innovative so to speak or any of the new developments that get done in t or catd pipelines or usually first made on the",
    "start": "269100",
    "end": "276180"
  },
  {
    "text": "main nginx role and then they can report it across all over all other roles and collections",
    "start": "276180",
    "end": "282620"
  },
  {
    "text": "everyone I'm sure knows about Docker ansible just in case you don't know just uh tldr it's a configuration management",
    "start": "282620",
    "end": "288120"
  },
  {
    "text": "Tool It's not that it's similar from Puppet who is here for example it's one of the sponsors",
    "start": "288120",
    "end": "293699"
  },
  {
    "text": "and with that let me move on to chapter three Moby Dick or the docker",
    "start": "293699",
    "end": "298800"
  },
  {
    "text": "unprivileged nginx image I'm gonna be covering now some of the lessons that I've learned they're mostly in",
    "start": "298800",
    "end": "305280"
  },
  {
    "text": "chronological order T when they were implemented not always but just to give you a little bit of a guidance on how",
    "start": "305280",
    "end": "310800"
  },
  {
    "text": "things are going to be presented and I'll start with the first lesson just to",
    "start": "310800",
    "end": "316139"
  },
  {
    "text": "implement a cicd pipeline as soon as you can not four years later which is how long",
    "start": "316139",
    "end": "322800"
  },
  {
    "text": "it took me to implement a chcd pipeline for the for the docker engine X and privilege image",
    "start": "322800",
    "end": "328620"
  },
  {
    "text": "for the first four years I was building everything locally using a local script",
    "start": "328620",
    "end": "333740"
  },
  {
    "text": "uh needless to say local scripts for CD are not great this script took an",
    "start": "333740",
    "end": "340560"
  },
  {
    "text": "average about 30 hours to run on my laptop every time I had to like do a new",
    "start": "340560",
    "end": "345900"
  },
  {
    "text": "release or an ecbe came around and you know had to rebuild everything from scratch uh",
    "start": "345900",
    "end": "352380"
  },
  {
    "text": "it's not that common for a build script to last 30 hours but it can last even",
    "start": "352380",
    "end": "358320"
  },
  {
    "text": "longer than that you don't want to have your local laptop or your local environment being set up",
    "start": "358320",
    "end": "363660"
  },
  {
    "text": "to such yeah you know tremendous amount of effort for so long also in this case",
    "start": "363660",
    "end": "368880"
  },
  {
    "text": "it took like help from my laptops Ram basically made it unusable say your laptop crashes",
    "start": "368880",
    "end": "374820"
  },
  {
    "text": "uh or you know whatever many issues your local laptop can have and will crash the",
    "start": "374820",
    "end": "380940"
  },
  {
    "text": "script you have to start again not fun times and as it turns out it probably took me longer to actually write this",
    "start": "380940",
    "end": "386639"
  },
  {
    "text": "batch script then it took me to implement catd in first place on GitHub so you know just",
    "start": "386639",
    "end": "392699"
  },
  {
    "text": "as soon as you can just Implement your chdd pipelines whether it does yeah GitHub actions or",
    "start": "392699",
    "end": "399900"
  },
  {
    "text": "you know whatever other tool out there that you want to use just make it one of your first priorities",
    "start": "399900",
    "end": "407120"
  },
  {
    "text": "uh second lesson figure out when to best publish new artifacts",
    "start": "407360",
    "end": "412860"
  },
  {
    "text": "that are especially relevant if you're pushing something like Docker images to an option repository it also can apply",
    "start": "412860",
    "end": "418440"
  },
  {
    "text": "to any amount of packages there's some expectations or like some Unwritten rules around publishing",
    "start": "418440",
    "end": "424800"
  },
  {
    "text": "packages one of them for example is that you never published something new on a Friday because if things break people",
    "start": "424800",
    "end": "430680"
  },
  {
    "text": "are gonna have to say over the weekend that's not fun so it's up to you you gotta figure out",
    "start": "430680",
    "end": "435780"
  },
  {
    "text": "what makes the most sense for for your project for the docker engine accent privilege project what we ended up",
    "start": "435780",
    "end": "441599"
  },
  {
    "text": "settling on it doesn't make the most sense it's on a weekly basis every Sunday night or Monday morning at",
    "start": "441599",
    "end": "447539"
  },
  {
    "text": "midnight I think it's CST I don't know I think that's the default get up actions timing uh or time zone new packages well",
    "start": "447539",
    "end": "455819"
  },
  {
    "text": "new Docker images or build and published but gee Docker Hub to the GitHub internal registry and T the Amazon ECR",
    "start": "455819",
    "end": "463819"
  },
  {
    "text": "registry and then there's also the option which is very neat that Kita Plexi do which is he said this flag",
    "start": "463819",
    "end": "471180"
  },
  {
    "text": "called workflow dispatch which lets you manually trigger to build Standalone which for example if say it's Wednesday",
    "start": "471180",
    "end": "477720"
  },
  {
    "text": "and someone finds and there's a new CDE and then there's a fix gets released for",
    "start": "477720",
    "end": "482759"
  },
  {
    "text": "the SUV and you want to you know publish that fix before next week you can just",
    "start": "482759",
    "end": "487979"
  },
  {
    "text": "go manually trigger the new build next lesson integrate one delivery",
    "start": "487979",
    "end": "495120"
  },
  {
    "text": "Target at a time if once it works move on to the next Target this is what I did when I was",
    "start": "495120",
    "end": "501240"
  },
  {
    "text": "implementing Docker Hub and the GitHub container registry and Amazon ECR",
    "start": "501240",
    "end": "507840"
  },
  {
    "text": "even if you have the code done from the beginning and you're pretty sure it works and you may be tested in",
    "start": "507840",
    "end": "513479"
  },
  {
    "text": "development and it works when you're once you when you're publishing it to your production it's just way better to",
    "start": "513479",
    "end": "518880"
  },
  {
    "text": "still make sure that one target works at a time you push your bills to you Docker Hub you",
    "start": "518880",
    "end": "524520"
  },
  {
    "text": "give it a couple weeks make sure that there's no fires to put out then you know you implement",
    "start": "524520",
    "end": "530700"
  },
  {
    "text": "let's say get up yeah to get a container registry wait another couple weeks make sure there's no fires to put out and",
    "start": "530700",
    "end": "536220"
  },
  {
    "text": "then you go on to the next step and so on this fundamentally helps you if things go wrong to just be able to",
    "start": "536220",
    "end": "542399"
  },
  {
    "text": "address one issue at a time instead of having like I don't know 10 new issues over a week targeting three different",
    "start": "542399",
    "end": "548940"
  },
  {
    "text": "platforms the next lesson is that caching can be",
    "start": "548940",
    "end": "554220"
  },
  {
    "text": "cool better be wary of potential pitfalls why do I say this when I first found out",
    "start": "554220",
    "end": "560339"
  },
  {
    "text": "about caching and Docker using GitHub actions well for Docker images it's in GitHub actions I thought this is cool my",
    "start": "560339",
    "end": "567060"
  },
  {
    "text": "builds now on average and get up actions still take like four or five hours let's try to make it a little bit you",
    "start": "567060",
    "end": "573540"
  },
  {
    "text": "know faster turns out that did work quite nicely actually my build times went from like",
    "start": "573540",
    "end": "579060"
  },
  {
    "text": "four or five hours to 30 minutes 20 minutes 10 minutes sometimes",
    "start": "579060",
    "end": "584459"
  },
  {
    "text": "but I did not take into account that cashing uh the way it's implemented at",
    "start": "584459",
    "end": "589620"
  },
  {
    "text": "least for Docker and get up actions it fundamentally does not detect package",
    "start": "589620",
    "end": "595800"
  },
  {
    "text": "updates within your internal Docker file unless they're very explicitly said",
    "start": "595800",
    "end": "600899"
  },
  {
    "text": "so dependencies of dependencies and so on are not really flagged as being outdated",
    "start": "600899",
    "end": "606420"
  },
  {
    "text": "and what that means is that when an ecbe happened and you know newfix was released sometimes rebuilding the full",
    "start": "606420",
    "end": "613920"
  },
  {
    "text": "image will not actually Force the rebuild of the cache and the CVS will",
    "start": "613920",
    "end": "618959"
  },
  {
    "text": "not get fixed that can be a huge pain in the ass to put it nicely fundamental and there's",
    "start": "618959",
    "end": "625200"
  },
  {
    "text": "also the small issue that the GitHub actions cache to this day",
    "start": "625200",
    "end": "630660"
  },
  {
    "text": "it's not fully quite there yet where it should be if you want to delete a cache",
    "start": "630660",
    "end": "637920"
  },
  {
    "text": "you have to go through the manual to do entries manually they let them be at the ux if you want to use the GitHub CLI",
    "start": "637920",
    "end": "644100"
  },
  {
    "text": "it's a little bit better but it's still a little bit of a process so you know caching can work out in your project but",
    "start": "644100",
    "end": "650459"
  },
  {
    "text": "before you implement caching make sure that you're taking into account all the possible things that could were wrong",
    "start": "650459",
    "end": "655980"
  },
  {
    "text": "with the cache and be ready to potentially having to dig certain",
    "start": "655980",
    "end": "661860"
  },
  {
    "text": "caches and you know going through that process which again it's still not quite there yet",
    "start": "661860",
    "end": "667620"
  },
  {
    "text": "and the final and very obvious lesson uh that I've learned over time for the",
    "start": "667620",
    "end": "673980"
  },
  {
    "text": "docker and genetics and privilege repository SD Network write tags I made",
    "start": "673980",
    "end": "679560"
  },
  {
    "text": "a Once Upon a Time decided to rewrite a little tag because I made a small change",
    "start": "679560",
    "end": "684959"
  },
  {
    "text": "and I thought it was going to be a huge quality of life Improvement for everyone",
    "start": "684959",
    "end": "690120"
  },
  {
    "text": "using the repository and using well using the docker image turns out people were not happy about it and since then",
    "start": "690120",
    "end": "697800"
  },
  {
    "text": "obviously I learned my lesson third way you just never write any tags no matter how minor changes doesn't matter if it's",
    "start": "697800",
    "end": "703140"
  },
  {
    "text": "just American update people expect their attacks for good reason obviously to be",
    "start": "703140",
    "end": "709019"
  },
  {
    "text": "immutable and they should be mutable so yeah no matter how tempted you might be just don't do",
    "start": "709019",
    "end": "715019"
  },
  {
    "text": "it and with that we can move on to chapter four from the Earth to the ansible Galaxy which is some of the lessons I've",
    "start": "715019",
    "end": "721620"
  },
  {
    "text": "learned while I was developing the ansible nginx role ansible Galaxy for those of you that I don't know it's the",
    "start": "721620",
    "end": "728100"
  },
  {
    "text": "ansible open source Marketplace as the little uh joke",
    "start": "728100",
    "end": "734040"
  },
  {
    "text": "all right lesson number one avoid a pipeline vendor login as much as possible when I first started working on",
    "start": "734040",
    "end": "740399"
  },
  {
    "text": "this project the go to default for ansible workflows were of course both",
    "start": "740399",
    "end": "746160"
  },
  {
    "text": "for CI and CD was Travis it was the recommended tool by ansible it actually even came with some built-in",
    "start": "746160",
    "end": "751860"
  },
  {
    "text": "Integrations as we all know by now Travis open source is no longer a thing",
    "start": "751860",
    "end": "757380"
  },
  {
    "text": "for better or worse so that's obviously not a good candidate",
    "start": "757380",
    "end": "762480"
  },
  {
    "text": "for any open source project so I had team migrated to GitHub actions",
    "start": "762480",
    "end": "767639"
  },
  {
    "text": "you could fill in any other pipeline tool out there GitHub actions just make the most sense to me and fundamentally",
    "start": "767639",
    "end": "774779"
  },
  {
    "text": "it was relatively easy for me because all I was doing in Travis was a bunch of scripts reporting scripts is easy but",
    "start": "774779",
    "end": "781440"
  },
  {
    "text": "you got to be careful not to try to lock yourself too much with that pipeline a good example for example if you're using",
    "start": "781440",
    "end": "787500"
  },
  {
    "text": "GitHub action stuff like that can happen is if your entire workflow depends on external early support data pipeline",
    "start": "787500",
    "end": "794700"
  },
  {
    "text": "actions and you're just using pipeline action supported by other persons if you want to migrate from data some time down",
    "start": "794700",
    "end": "801360"
  },
  {
    "text": "the line it's going to be quite hard which does not mean that you should not be using external GitHub actions uh",
    "start": "801360",
    "end": "807300"
  },
  {
    "text": "supported by other people just make sure it's a conscious decision and you know you know what you're doing when you choose to use one of those instead of",
    "start": "807300",
    "end": "813720"
  },
  {
    "text": "your own scripts running on whatever platform lesson number T optimize your pipelines",
    "start": "813720",
    "end": "820320"
  },
  {
    "text": "runtime and efficiency this is one of the most important things honestly this day and age and so far as",
    "start": "820320",
    "end": "827100"
  },
  {
    "text": "pipelines go especially if it's part of your automated workflows",
    "start": "827100",
    "end": "834300"
  },
  {
    "text": "it just makes your life so much easier developer productivity it goes up to roof it stores an issue with your code you're going to be able to find it as",
    "start": "834300",
    "end": "840660"
  },
  {
    "text": "soon as you can you know there's multiple ways to do it there's no right or wrong way for",
    "start": "840660",
    "end": "846480"
  },
  {
    "text": "example in my case I used to run a bunch of molecule tests molecules sensibles native testing suit but you still run",
    "start": "846480",
    "end": "853380"
  },
  {
    "text": "them in order at the same workflow what that meant is that fundamentally running a full test a full Suite of tests could",
    "start": "853380",
    "end": "861300"
  },
  {
    "text": "take easily about eight hours something like that and that's when I learned",
    "start": "861300",
    "end": "866459"
  },
  {
    "text": "about using build major Tech build matrixes and I mean Travis supported them so those get up actions I am seeing",
    "start": "866459",
    "end": "873240"
  },
  {
    "text": "other tools that their support empty you can create a workflow Matrix and then you just run a bunch of tests at the",
    "start": "873240",
    "end": "880320"
  },
  {
    "text": "same time you know run like 10 jobs concurrently and they will hopefully it'll be done",
    "start": "880320",
    "end": "886920"
  },
  {
    "text": "within an rot instead of having to wait like 10 hours just to have a single test of well suit of tests to run get",
    "start": "886920",
    "end": "894240"
  },
  {
    "text": "yourself right or wrong way to do this but traditionally there's always some way you can optimize your runtimes",
    "start": "894240",
    "end": "902480"
  },
  {
    "text": "the next lesson is split your pipeline into this Tanked workflows",
    "start": "902880",
    "end": "908339"
  },
  {
    "text": "so when you're starting it tells us a little bit like you know uh versus microservices when you're starting",
    "start": "908339",
    "end": "914100"
  },
  {
    "text": "having something in the same workflow file can ease development speed it might make sense depending on your whole",
    "start": "914100",
    "end": "920880"
  },
  {
    "text": "ecosystem infrastructure and the complexity of your project but as you keep developing it you keep adding more",
    "start": "920880",
    "end": "926279"
  },
  {
    "text": "use cases to you and you know things that your workflows can accomplish it's a good idea to start spraying them into",
    "start": "926279",
    "end": "932279"
  },
  {
    "text": "unique and distinct UH responsibilities for example in my case I have one",
    "start": "932279",
    "end": "938760"
  },
  {
    "text": "pipeline that's for testing one pipeline that's for deploying a new ansible",
    "start": "938760",
    "end": "944279"
  },
  {
    "text": "releases into ansible Galaxy and then I have one pipeline that's for creating release notes and it could get even more",
    "start": "944279",
    "end": "951540"
  },
  {
    "text": "demand that it could have like a pipeline that's for testing software for testing PRS and then for testing",
    "start": "951540",
    "end": "957839"
  },
  {
    "text": "external and internal PR's different pipelines you could have a more complex pipeline that runs once a week and",
    "start": "957839",
    "end": "963720"
  },
  {
    "text": "there's like a full range of unit an integration tests for instance more simple pipeline for external PRS",
    "start": "963720",
    "end": "971339"
  },
  {
    "text": "that fundamentally depends on your use case again just keep in mind that it's usually a good idea to over time split",
    "start": "971339",
    "end": "977820"
  },
  {
    "text": "your pipeline into testing workflows and there's actually ties into the other",
    "start": "977820",
    "end": "983699"
  },
  {
    "text": "lesson figure out when it makes most sense to run each workflow if it's a workload that just publishes TSA ansible",
    "start": "983699",
    "end": "990959"
  },
  {
    "text": "Galaxy maybe you only need to run it when you're creating a new release maybe instead if you have a pipeline that is",
    "start": "990959",
    "end": "997800"
  },
  {
    "text": "creating a Docker build artifact you want to publish it on you know you want",
    "start": "997800",
    "end": "1003560"
  },
  {
    "text": "200 on every external PR policy to your development environment and test data works if you have a pipeline that only",
    "start": "1003560",
    "end": "1010699"
  },
  {
    "text": "does release notes maybe you only want to run it when you're doing lose notes and so on again it depends bad you gotta",
    "start": "1010699",
    "end": "1015800"
  },
  {
    "text": "figure it out and you've got a good idea to spend some time thinking about it",
    "start": "1015800",
    "end": "1021199"
  },
  {
    "text": "let's listen depend upon is depend about it's great and you should enable it this is very GitHub specific",
    "start": "1021199",
    "end": "1027980"
  },
  {
    "text": "um but it's a great tool it will tell you exactly what packages you have automated it will open PRS for you",
    "start": "1027980",
    "end": "1034000"
  },
  {
    "text": "automatically it will save you a lot of time that you should you will be spending otherwise so if you were",
    "start": "1034000",
    "end": "1039980"
  },
  {
    "text": "hunting for those updates yourself there's a little issue with it though",
    "start": "1039980",
    "end": "1045860"
  },
  {
    "text": "and that's that it can also be overwhelming if you I mean at least as of two years ago things might have",
    "start": "1045860",
    "end": "1052100"
  },
  {
    "text": "changed but two years ago the defaults meant that dependable will open a PR anytime a new release uh for any package",
    "start": "1052100",
    "end": "1059120"
  },
  {
    "text": "got you know released they are and sometimes like in this",
    "start": "1059120",
    "end": "1065299"
  },
  {
    "text": "series of peers that I have here basically results that over a week maybe you have like five six PRS being opened",
    "start": "1065299",
    "end": "1071840"
  },
  {
    "text": "at random times over different days suddenly you know half your job becomes to be a dependable maintainer",
    "start": "1071840",
    "end": "1078559"
  },
  {
    "text": "so it's a good idea to ease Dependable but tweak the objects to your consistent and same frequency what I did and what",
    "start": "1078559",
    "end": "1085580"
  },
  {
    "text": "made the most sense to me is that now every Monday because depending on let's see this and you know not a lot of",
    "start": "1085580",
    "end": "1091580"
  },
  {
    "text": "people know about it then basically what it is every Monday at midnight or Sunday night",
    "start": "1091580",
    "end": "1096820"
  },
  {
    "text": "depend about search at the same time for any new updates it opens a bunch of PRS",
    "start": "1096820",
    "end": "1102260"
  },
  {
    "text": "and then every morning every Monday morning when I log on to GitHub I can see any PRS deal with them or at once if",
    "start": "1102260",
    "end": "1108860"
  },
  {
    "text": "there's any issues with one of the PRS I can deal with it over the week and so on but I only have to worry about depending",
    "start": "1108860",
    "end": "1114440"
  },
  {
    "text": "about it once a week fundamentally all right let's listen how are code",
    "start": "1114440",
    "end": "1120860"
  },
  {
    "text": "package versions in all your Pipelines this is something that has been on me quite a few times it still does spare me",
    "start": "1120860",
    "end": "1127460"
  },
  {
    "text": "uh to this day with some packages like last week just more recently",
    "start": "1127460",
    "end": "1134000"
  },
  {
    "text": "a lot it's not uncommon especially in some more Dynamic ecosystems such as",
    "start": "1134000",
    "end": "1139400"
  },
  {
    "text": "node or python to have multiple packages being released week after week those",
    "start": "1139400",
    "end": "1144679"
  },
  {
    "text": "packages sometimes include well do usually include a bunch of dependencies those dependencies in turn",
    "start": "1144679",
    "end": "1152600"
  },
  {
    "text": "you know every once in a while might have breaking changes it's not uncommon for you know your workflow to you just",
    "start": "1152600",
    "end": "1159140"
  },
  {
    "text": "randomly stopped working from one day to another that's and that's again not great it's not the first time that's",
    "start": "1159140",
    "end": "1165440"
  },
  {
    "text": "happened to me that I've had to spend like a full day just trying to debug why my pipeline stopped working only to",
    "start": "1165440",
    "end": "1171679"
  },
  {
    "text": "eventually find out the issue was that one of my dependencies got a major",
    "start": "1171679",
    "end": "1177860"
  },
  {
    "text": "breaking change over an overnight update and I did not realize hardcoding those",
    "start": "1177860",
    "end": "1183200"
  },
  {
    "text": "package versions helps with that you will always know what version is being used and if there's any update to that",
    "start": "1183200",
    "end": "1188600"
  },
  {
    "text": "package it'll be found by Dependable depending level will open up ER and you'll be able to fix the issue that",
    "start": "1188600",
    "end": "1195440"
  },
  {
    "text": "depends about PR specifically instead of your whole pipeline failing",
    "start": "1195440",
    "end": "1200720"
  },
  {
    "text": "the next lesson is that pipelines will randomly fail and it's good to find ways to avoid a hard restart uh why do I say",
    "start": "1200720",
    "end": "1208640"
  },
  {
    "text": "it will randomly fail if you're using anything that relies on a potential HTTP endpoint",
    "start": "1208640",
    "end": "1214640"
  },
  {
    "text": "whether it's downloading a package from somewhere or creating an API time outside payment internet goes out",
    "start": "1214640",
    "end": "1220640"
  },
  {
    "text": "there's always a chance that something will randomly fail if you use networking or you know anything like that in any",
    "start": "1220640",
    "end": "1227299"
  },
  {
    "text": "way or shape you'll know what I mean there's a very by default GitHub has",
    "start": "1227299",
    "end": "1232760"
  },
  {
    "text": "this option get of action has this option called fail you can read it from a size filter failsafe",
    "start": "1232760",
    "end": "1239360"
  },
  {
    "text": "fast fail it's said to true that means that if one of your jobs in your machine your Matrix",
    "start": "1239360",
    "end": "1246020"
  },
  {
    "text": "fails everything will fail automatically I'm not a big fan of that for because",
    "start": "1246020",
    "end": "1251179"
  },
  {
    "text": "again titles randomly fail I always suggest people to set it to false so",
    "start": "1251179",
    "end": "1256400"
  },
  {
    "text": "that if one of the job fails of the other jobs will still continue and ideally if it was just random failure",
    "start": "1256400",
    "end": "1262940"
  },
  {
    "text": "all the other jobs will succeed then you can go to the job that failed dig into it see why it failed if the issue is",
    "start": "1262940",
    "end": "1269240"
  },
  {
    "text": "something to do with your code obviously you go fix it and you know push the new camera that if it's just a random",
    "start": "1269240",
    "end": "1274640"
  },
  {
    "text": "failure which happens about it happens more than like I don't know after time",
    "start": "1274640",
    "end": "1279919"
  },
  {
    "text": "it happens more frequently than it does not you can just re-run the job that failed",
    "start": "1279919",
    "end": "1287020"
  },
  {
    "text": "the next lesson very briefly uh certainly something that you know you develop over time it's just whatever",
    "start": "1288080",
    "end": "1294980"
  },
  {
    "text": "possible Consolidated pipeline tools and steps she did this properly you usually you",
    "start": "1294980",
    "end": "1300799"
  },
  {
    "text": "have to keep actively checking for updates and tools that you're using an example for this for example is one of",
    "start": "1300799",
    "end": "1307880"
  },
  {
    "text": "the ansible lint objects that came out in the past couple years added yamlint",
    "start": "1307880",
    "end": "1313220"
  },
  {
    "text": "as a dependency and started running gamma lint natively within ansible lint what this means is that well what this",
    "start": "1313220",
    "end": "1320059"
  },
  {
    "text": "meant is that I was fundamentally able to get rid of yamlant in my workflows and have an simple lean deal with that",
    "start": "1320059",
    "end": "1325760"
  },
  {
    "text": "it's not as small it's not a big time saving but over time if a bunch of these",
    "start": "1325760",
    "end": "1330919"
  },
  {
    "text": "little changes happen to some of the tools you're using you're going to be saving some time and it goes back to you up to my single workflows be able to run",
    "start": "1330919",
    "end": "1336860"
  },
  {
    "text": "to workflows as fast as you can as often as you can",
    "start": "1336860",
    "end": "1342200"
  },
  {
    "text": "there's also beyond that there's also just as you keep you know developing workflows the more you learn how your",
    "start": "1342200",
    "end": "1348320"
  },
  {
    "text": "software works and you know how the workplace work there's always opportunities to optimize some of those",
    "start": "1348320",
    "end": "1354740"
  },
  {
    "text": "workflows a little bit more and consolidate steps probably",
    "start": "1354740",
    "end": "1359740"
  },
  {
    "text": "next lesson is enabling contributors to develop PRS Verizon software",
    "start": "1359900",
    "end": "1364940"
  },
  {
    "text": "I'm not going to talk too much into this because it's one of those there's no right or wrong ways and it depends on",
    "start": "1364940",
    "end": "1370100"
  },
  {
    "text": "your use case but fundamentally if your tool has like an open source component and maybe an Enterprise component like",
    "start": "1370100",
    "end": "1376039"
  },
  {
    "text": "nginx does engine acceptance service and engine X plus it's a good idea to let users have a way to test those nginx one",
    "start": "1376039",
    "end": "1385159"
  },
  {
    "text": "of those Enterprise features by letting them have an opportunity if the 40 repo",
    "start": "1385159",
    "end": "1390559"
  },
  {
    "text": "provide some licenses some Secrets be able to test that software instead of doing what I initially did here which",
    "start": "1390559",
    "end": "1396140"
  },
  {
    "text": "was to fundamentally block any Enterprise tests from running on the on",
    "start": "1396140",
    "end": "1402260"
  },
  {
    "text": "any four core external PR and the last major lesson is integrate",
    "start": "1402260",
    "end": "1409159"
  },
  {
    "text": "all deployment Target destroys in your pipeline as well as your target architectures now this",
    "start": "1409159",
    "end": "1416539"
  },
  {
    "text": "seems like it makes a lot of sense but I've seen a bunch of times where people don't properly test",
    "start": "1416539",
    "end": "1422840"
  },
  {
    "text": "all the platforms that are part of the that your server is supposed to Target or they don't",
    "start": "1422840",
    "end": "1429260"
  },
  {
    "text": "tests probably all the architectures that their software is supposed to be running in it's very obvious it just saves you a",
    "start": "1429260",
    "end": "1435440"
  },
  {
    "text": "lot of headaches even if it has some of these things locally and they're not part of your pipeline",
    "start": "1435440",
    "end": "1440539"
  },
  {
    "text": "and you think you're going to be doing locally every major release it's only a matter of time until something slips and you stop doing that so just integrate",
    "start": "1440539",
    "end": "1447440"
  },
  {
    "text": "everything in your you know pipeline in your automated pipelines really and with that for the final few minutes",
    "start": "1447440",
    "end": "1454640"
  },
  {
    "text": "we can move on to chapter five 100 Years of collaboration also known as white",
    "start": "1454640",
    "end": "1459919"
  },
  {
    "text": "pipeline as code is great you know pros and cons fundamentally",
    "start": "1459919",
    "end": "1465860"
  },
  {
    "text": "so there's a good there's the Version Control side of things when you're using pipeline soda thcds code",
    "start": "1465860",
    "end": "1472360"
  },
  {
    "text": "version control everything is checked into gear or Mercurial or whatever tool",
    "start": "1472360",
    "end": "1478159"
  },
  {
    "text": "you're using I would hope most people reason get the stakes um you have automated PR",
    "start": "1478159",
    "end": "1485419"
  },
  {
    "text": "I don't know not necessarily only PR automatically ICD is very easy if you use pipeline's code you can foster",
    "start": "1485419",
    "end": "1493039"
  },
  {
    "text": "continuous improvements by knowledge sharing between amongst other open source users out there in the world",
    "start": "1493039",
    "end": "1499159"
  },
  {
    "text": "you can reduce false positive bug reports this size a little bit into the whole you know make sure that you are",
    "start": "1499159",
    "end": "1505700"
  },
  {
    "text": "record all your package dependencies and what not it helps people know if the issue is an issue on their end maybe",
    "start": "1505700",
    "end": "1512659"
  },
  {
    "text": "they're using some packages that are not the packages the package versions that they're not the persons this should be using",
    "start": "1512659",
    "end": "1518240"
  },
  {
    "text": "on or whether it's an issue with the source code it's an actual bug it also helps because people can then look at",
    "start": "1518240",
    "end": "1523880"
  },
  {
    "text": "your CI CD be like hey this is being tested this way maybe I'm producing the software or the tool the right way and",
    "start": "1523880",
    "end": "1531740"
  },
  {
    "text": "maybe there's this flag or something that's not documented but it's an TCI CD pipeline it does help quite a bit with",
    "start": "1531740",
    "end": "1538220"
  },
  {
    "text": "that and then the last part is both the source code and the chcd code left",
    "start": "1538220",
    "end": "1543559"
  },
  {
    "text": "together that says quite important because as a user as an open source Caesar I know for",
    "start": "1543559",
    "end": "1550460"
  },
  {
    "text": "example I myself love when all things are in the same place where I don't actually navigate through three different websites to find everything",
    "start": "1550460",
    "end": "1557059"
  },
  {
    "text": "related to the software I'm using so that it's the same way why you probably would want to have ducks in your repo in",
    "start": "1557059",
    "end": "1563779"
  },
  {
    "text": "your source code too this makes your life makes the life of external developers and internal developers too",
    "start": "1563779",
    "end": "1569960"
  },
  {
    "text": "all too much easier then there's the bar which is not necessarily bad it's just things you",
    "start": "1569960",
    "end": "1575659"
  },
  {
    "text": "need to think about you know what do you do with Secrets if you're gonna if it's an open source project and it requires secrecy run",
    "start": "1575659",
    "end": "1582700"
  },
  {
    "text": "do you enable them for external PRS if now do you provide an easy way for external PRC access to your secrets",
    "start": "1582700",
    "end": "1590539"
  },
  {
    "text": "it's stuff that you need to think about there's no right or wrong answer again the defensive use case but you need to",
    "start": "1590539",
    "end": "1596059"
  },
  {
    "text": "consider data centers when do you run your CD pipeline or on for example who or who triggers the CD pipeline does the",
    "start": "1596059",
    "end": "1604520"
  },
  {
    "text": "CD pipeline get run on every PR uh you know get push to development repository",
    "start": "1604520",
    "end": "1611120"
  },
  {
    "text": "does the CD pipeline only get run on a new release as the CD pipeline",
    "start": "1611120",
    "end": "1616700"
  },
  {
    "text": "automatically triggered do you need like a maintainer to come along and run the CD pipeline",
    "start": "1616700",
    "end": "1622880"
  },
  {
    "text": "all food for thought that is not necessarily bad it's just the things that you really need to keep into account",
    "start": "1622880",
    "end": "1628279"
  },
  {
    "text": "and then there's the ugly which is the cons there's really no accounts that I can think of or that I've ever really",
    "start": "1628279",
    "end": "1633860"
  },
  {
    "text": "been able to find with pipeline s code there might be some I don't know if there are uh just give me a fruit",
    "start": "1633860",
    "end": "1640279"
  },
  {
    "text": "session and I will make some amends but you know just no bad reason to start your journey with pipeline's code",
    "start": "1640279",
    "end": "1646779"
  },
  {
    "text": "and with that that's the end you can find those little synthesized later I'm not going to spend too much time here",
    "start": "1646779",
    "end": "1652760"
  },
  {
    "text": "but after we have a Twitter account YouTube account with a bunch of videos LinkedIn whatever and then there's the",
    "start": "1652760",
    "end": "1660320"
  },
  {
    "text": "little eplog which is basically the Q a uh but before I think I have like two",
    "start": "1660320",
    "end": "1665360"
  },
  {
    "text": "minutes for questions not a lot of time I just wanted to do a quick call to action we have an nginx Community slack",
    "start": "1665360",
    "end": "1671320"
  },
  {
    "text": "if you it's quite recent only like T months three months old maybe a little",
    "start": "1671320",
    "end": "1676460"
  },
  {
    "text": "broader than that no longer than half a year old but we are all hanging out there it's been growing quite steadily",
    "start": "1676460",
    "end": "1682580"
  },
  {
    "text": "in population if you have any questions if you want to interact with any of us engine extras out there in the world this is a great place to do it and your",
    "start": "1682580",
    "end": "1690500"
  },
  {
    "text": "secure code there they're just still linked down it enters my contact details again if you want to reach out to some",
    "start": "1690500",
    "end": "1696020"
  },
  {
    "text": "stage and I don't know if we have time for questions but if you do someone have any questions by any chance",
    "start": "1696020",
    "end": "1703279"
  },
  {
    "text": "no no yes",
    "start": "1703279",
    "end": "1706720"
  },
  {
    "text": "yes there is a tool called Act it's a little bit of a",
    "start": "1710480",
    "end": "1717158"
  },
  {
    "text": "it's not the easiest tool to use it has its quirks better it does the job good",
    "start": "1717320",
    "end": "1723020"
  },
  {
    "text": "enough",
    "start": "1723020",
    "end": "1725200"
  },
  {
    "text": "decides yeah they'll be it should be on my if you look at my session profile",
    "start": "1734480",
    "end": "1739520"
  },
  {
    "text": "thing on schedule app whatever I upload in my slides there should be a way for you to get access to them I honestly",
    "start": "1739520",
    "end": "1746299"
  },
  {
    "text": "don't know how that works because I've never done it uh but there should be a way",
    "start": "1746299",
    "end": "1751720"
  },
  {
    "text": "oh for publication uh that's not maybe a little bit more involved this say around later you can shoot me an email or",
    "start": "1754279",
    "end": "1760220"
  },
  {
    "text": "something and we can look at that yeah right one more question",
    "start": "1760220",
    "end": "1766898"
  },
  {
    "text": "yes you actually do use that for all my Docker builds yeah",
    "start": "1767720",
    "end": "1773720"
  },
  {
    "text": "yeah I should mentioned Docker I built for all sorts of architectures using Docker ideas Docker Kimu now and GitHub",
    "start": "1773720",
    "end": "1780620"
  },
  {
    "text": "actions I don't know anyways um way back when I did use Docker build decks",
    "start": "1780620",
    "end": "1786260"
  },
  {
    "text": "natively on my GitHub when I run the scripts locally and when these days by",
    "start": "1786260",
    "end": "1791779"
  },
  {
    "text": "default if you use the docker build action on GitHub actions it does use build X behind the scenes",
    "start": "1791779",
    "end": "1798140"
  },
  {
    "text": "and you mentioned qmu so you are supporting exotic architectures like yeah",
    "start": "1798140",
    "end": "1804380"
  },
  {
    "text": "yeah I do that for the docker engine X images they're built for all the architectures the ansible rule gets",
    "start": "1804380",
    "end": "1811520"
  },
  {
    "text": "tested on AMD arm64 and s39x actually it has three nine zero X",
    "start": "1811520",
    "end": "1820000"
  },
  {
    "text": "the names they come off with these days all right any more questions",
    "start": "1820220",
    "end": "1826700"
  },
  {
    "text": "no I think that's it then thank you for coming along [Applause]",
    "start": "1826700",
    "end": "1833400"
  }
]
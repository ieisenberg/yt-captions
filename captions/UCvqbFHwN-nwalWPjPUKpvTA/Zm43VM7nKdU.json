[
  {
    "start": "0",
    "end": "76000"
  },
  {
    "text": "good afternoon everyone my name is Nandu Kumar from what my name is dawn she I'm",
    "start": "60",
    "end": "9570"
  },
  {
    "text": "Ronald yeah welcome to yet another permitted stock we have seen a lot of",
    "start": "9570",
    "end": "14820"
  },
  {
    "text": "talks around promises it's pretty exciting to see the community going on",
    "start": "14820",
    "end": "19890"
  },
  {
    "text": "per mitosis so before I go on so we are from old how many of you know what is",
    "start": "19890",
    "end": "28019"
  },
  {
    "text": "what Wow",
    "start": "28019",
    "end": "34170"
  },
  {
    "text": "yep I'll catch up with you later I'll get you a swag yeah so as he said oldest",
    "start": "34170",
    "end": "42989"
  },
  {
    "text": "a company created by Verizon when it acquired Yahoo and it also matched with",
    "start": "42989",
    "end": "48270"
  },
  {
    "text": "AOL and Tumblr TechCrunch and all other products we are from both specifically",
    "start": "48270",
    "end": "55289"
  },
  {
    "text": "we work from work on a core platform which provides the parameter kubernetes",
    "start": "55289",
    "end": "61440"
  },
  {
    "text": "set up for all our media products which supports Yahoo Finance Yahoo fantasy and",
    "start": "61440",
    "end": "68310"
  },
  {
    "text": "you know front page news and all these applications run on our kubernetes cluster I would like to take you to",
    "start": "68310",
    "end": "79200"
  },
  {
    "start": "76000",
    "end": "76000"
  },
  {
    "text": "journey of how we achieved a good visibility on our monitoring system very",
    "start": "79200",
    "end": "84810"
  },
  {
    "text": "specifically around the kubernetes clusters so before I go there I want to",
    "start": "84810",
    "end": "90659"
  },
  {
    "text": "just show you how we started with the kubernetes itself right so we started with the simple cluster in a single data",
    "start": "90659",
    "end": "96930"
  },
  {
    "text": "center and the first the next question comes always hey how is your monitoring looking yes we started with the",
    "start": "96930",
    "end": "105229"
  },
  {
    "text": "kubernetes dashboard it gives you a nice feeling about the CPU usage the deployment usage the memory percentage",
    "start": "105229",
    "end": "112920"
  },
  {
    "text": "and and also the node pressure details like how many parts can be allocated and all these details is this sufficient for",
    "start": "112920",
    "end": "119880"
  },
  {
    "text": "us probably not so we wanted to address",
    "start": "119880",
    "end": "126030"
  },
  {
    "text": "this problem in a better way so we looked at couple of operations we have so we traditionally we monitor yeah",
    "start": "126030",
    "end": "133220"
  },
  {
    "text": "in the business for 20 years right so we have been monitoring all our components using our one agents so we have open TS",
    "start": "133220",
    "end": "140120"
  },
  {
    "text": "to be pretty solid database out there for monitoring so we have an agent",
    "start": "140120",
    "end": "145430"
  },
  {
    "text": "running it runs the CPU collects of emeriti network details and all these details are sent to the central",
    "start": "145430",
    "end": "151520"
  },
  {
    "text": "monitoring system so we pretty much we did the same for our kubernetes clusters too we were happy because we were able",
    "start": "151520",
    "end": "156860"
  },
  {
    "text": "to get good health about the the external system metrics why we keep",
    "start": "156860",
    "end": "164360"
  },
  {
    "text": "getting questions right are we monitoring really the kubernetes ecosystem rightly probably not yet so",
    "start": "164360",
    "end": "170750"
  },
  {
    "text": "then we looked at the search hey what's the best way to monitor kubernetes citizens back in 2016 i'm talking about",
    "start": "170750",
    "end": "177890"
  },
  {
    "text": "so the first result you get in the Google is hipster right so we looked at",
    "start": "177890",
    "end": "183890"
  },
  {
    "text": "yes the queue kubernetes dashboard is powered by hipster we looked at the option to persist that data does",
    "start": "183890",
    "end": "190190"
  },
  {
    "text": "kubernetes desk was real-time there's no long-term storage right we tried with influx DB we had definitely good success",
    "start": "190190",
    "end": "196490"
  },
  {
    "text": "with that not going into much details about it at the same time Prometheus one",
    "start": "196490",
    "end": "201650"
  },
  {
    "text": "point X was there we've used Prometheus one prometheus operator to get started immediately and just sorry to say that",
    "start": "201650",
    "end": "209840"
  },
  {
    "text": "Prometheus is one point I did had some performances you could not meet our scale so we were seeing a memories are",
    "start": "209840",
    "end": "217489"
  },
  {
    "text": "falling down and the disk space gets filled up very quickly so we were trying alternate approach that promises also",
    "start": "217489",
    "end": "225680"
  },
  {
    "text": "supports the remote write plug-in so we take that plug in and try to send the data to our in our system so you know we",
    "start": "225680",
    "end": "232400"
  },
  {
    "text": "were doing a lot of experiment with that but definitely we are missing some insight into our kubernetes cluster so",
    "start": "232400",
    "end": "237860"
  },
  {
    "text": "I'm going to talk about it so on the other hand so the business is growing",
    "start": "237860",
    "end": "244519"
  },
  {
    "start": "240000",
    "end": "240000"
  },
  {
    "text": "right that we were success with the kubernetes set up on one data center so",
    "start": "244519",
    "end": "249799"
  },
  {
    "text": "now we wanted to proceed on multiple data center so as as the cluster grows",
    "start": "249799",
    "end": "257390"
  },
  {
    "text": "and it is our footprint looked like so we have twelve independent clusters two",
    "start": "257390",
    "end": "262669"
  },
  {
    "text": "key workers nodes and you know 12k pause and 50k containers all the stacks right so we keep getting",
    "start": "262669",
    "end": "270560"
  },
  {
    "start": "270000",
    "end": "270000"
  },
  {
    "text": "questions hey how is your cluster visibility looks like how much CPU",
    "start": "270560",
    "end": "276560"
  },
  {
    "text": "allocations is still available do you have a capacity to take more applications on board so who is the",
    "start": "276560",
    "end": "283850"
  },
  {
    "text": "biggest consumer like we we have a name space based isolation so who is the biggest consumer in our cluster to",
    "start": "283850",
    "end": "294080"
  },
  {
    "start": "294000",
    "end": "294000"
  },
  {
    "text": "answer this question we sat back and we came up with a bunch of requirements",
    "start": "294080",
    "end": "299240"
  },
  {
    "text": "within ourselves we in order to be be successful monitoring your kubernetes infrastructure we have we need to have",
    "start": "299240",
    "end": "305900"
  },
  {
    "text": "an answer to all these questions so we need to have an ax we need to be monitoring or control plane components",
    "start": "305900",
    "end": "310970"
  },
  {
    "text": "at CD API server and you know any atoms you name it like we wanted to grab all",
    "start": "310970",
    "end": "317360"
  },
  {
    "text": "the dashboards our metrics and get a visualization out of it at the same time so this the the applications we are",
    "start": "317360",
    "end": "324620"
  },
  {
    "text": "getting more applications we wanted to make sure we have a good control over our our users like how much you know how",
    "start": "324620",
    "end": "331940"
  },
  {
    "text": "much how is the deployment doing how is the pod doing even the namespace level utilization I just want to call out I",
    "start": "331940",
    "end": "339950"
  },
  {
    "start": "336000",
    "end": "336000"
  },
  {
    "text": "don't want to repeat some of the presentation from keynote fabian mentioned about the prometheus to find X",
    "start": "339950",
    "end": "345950"
  },
  {
    "text": "it's pretty great so just I'm just put those numbers here it's only so",
    "start": "345950",
    "end": "352360"
  },
  {
    "text": "parameters we read about the blocks Prometheus to point X was pretty great and attack ATX implement the storage and",
    "start": "352360",
    "end": "358880"
  },
  {
    "text": "some computing improvement as well so we we wanted to take a good step on it and",
    "start": "358880",
    "end": "364790"
  },
  {
    "text": "we really spend a good amount of time understanding how Prometheus works and",
    "start": "364790",
    "end": "369860"
  },
  {
    "text": "and how we can really go further and achieve over achieve our goal of",
    "start": "369860",
    "end": "375110"
  },
  {
    "text": "monitoring of kubernetes ecosystem so next to focus is of course I think there",
    "start": "375110",
    "end": "383120"
  },
  {
    "text": "was a talk from Bob cotton yesterday about all the monitoring equals all the",
    "start": "383120",
    "end": "388550"
  },
  {
    "text": "promises metrics available and kubernetes ecosystem so pretty much I listed the same so we have a net CD C",
    "start": "388550",
    "end": "396080"
  },
  {
    "text": "advisor Kuebler API server cube state matrix from pretty these are the pretty important",
    "start": "396080",
    "end": "401540"
  },
  {
    "text": "metrics so we said and focused on grabbing all of them not to mention the promises has a really great service",
    "start": "401540",
    "end": "409040"
  },
  {
    "text": "discovery built in so we use that to scrape you know any services you have",
    "start": "409040",
    "end": "415820"
  },
  {
    "text": "you have any services if you want to scrape all the end points we just need to set one on allocation so we use that",
    "start": "415820",
    "end": "421340"
  },
  {
    "text": "to scrape all the kubernetes metrics into the Prometheus's not to mention",
    "start": "421340",
    "end": "428120"
  },
  {
    "text": "about the file based discover which i'm going to show you right now so so we now",
    "start": "428120",
    "end": "433160"
  },
  {
    "start": "430000",
    "end": "430000"
  },
  {
    "text": "we started with we listed so many components there right so we started with each and every component one by one",
    "start": "433160",
    "end": "439190"
  },
  {
    "text": "we grabbed all the metrics started with the API server so we kind of we used here the file based discovery which is",
    "start": "439190",
    "end": "445610"
  },
  {
    "text": "not bad so we have multiple environments it's a bare metal server so we have a luxury to you know hardcore the server",
    "start": "445610",
    "end": "452600"
  },
  {
    "text": "name so we put them in the server server list here we use the service account token credential so parameters let's",
    "start": "452600",
    "end": "458300"
  },
  {
    "text": "scrape it so the one another thing is you can see here so this is how we add",
    "start": "458300",
    "end": "464720"
  },
  {
    "text": "the data center label I is pretty cool so we have multiple data center if you",
    "start": "464720",
    "end": "470780"
  },
  {
    "text": "want to label as well as part of the scraping itself this is one way of doing it so this is going to be useful when we",
    "start": "470780",
    "end": "477289"
  },
  {
    "text": "see in the in the in the Federation world so after we collected the metrics",
    "start": "477289",
    "end": "485450"
  },
  {
    "text": "of the API server now we move on to other control plane components like HDD and cube scheduler and the Control",
    "start": "485450",
    "end": "490820"
  },
  {
    "text": "Manager we have some challenge there so HCD is a huge restriction we have that",
    "start": "490820",
    "end": "496490"
  },
  {
    "text": "the ports are only accessible only from master as you can see in the diagram so",
    "start": "496490",
    "end": "502070"
  },
  {
    "text": "we wrote a simple proxies so far reverse proxy it listen on five four four three and any call comes to that proxy it only",
    "start": "502070",
    "end": "510139"
  },
  {
    "text": "receives slash metrics and it forwards to the local porter so in this case if h-series running on two three seven nine",
    "start": "510139",
    "end": "516050"
  },
  {
    "text": "is going to forward then what should write here yeah so as you can see here",
    "start": "516050",
    "end": "522709"
  },
  {
    "start": "520000",
    "end": "520000"
  },
  {
    "text": "it's it's a parameter two three seven nine to the metrics API so the metrics",
    "start": "522709",
    "end": "528620"
  },
  {
    "text": "proxy will just intercept the call and forward it to the localhost two three seven nine it's less metrics and points or so we",
    "start": "528620",
    "end": "534790"
  },
  {
    "text": "collect at City matrix very similarly we collect the controller scheduler so this",
    "start": "534790",
    "end": "540459"
  },
  {
    "start": "537000",
    "end": "537000"
  },
  {
    "text": "is this way what we have done is B basically we collected all these metrics into the into the into the committees so",
    "start": "540459",
    "end": "549730"
  },
  {
    "text": "so I'm going to candle what the lung she's want to talk about what we have achieved with this matrix so how we came",
    "start": "549730",
    "end": "556870"
  },
  {
    "text": "up with the Federation six tanda so as",
    "start": "556870",
    "end": "566319"
  },
  {
    "text": "we mentioned earlier we have twelve clusters we have production environment",
    "start": "566319",
    "end": "572230"
  },
  {
    "text": "Canaveral environment each of them has six clusters total we have more than 2000 notes so these are big clusters",
    "start": "572230",
    "end": "580079"
  },
  {
    "text": "even Prometheus is very performant one single promising server will not be able",
    "start": "580079",
    "end": "585579"
  },
  {
    "text": "to handle all the data in these clusters so how do we solve this problem I think",
    "start": "585579",
    "end": "592600"
  },
  {
    "text": "the the answer is simple we need to use Federation right so permit is offer this",
    "start": "592600",
    "end": "597610"
  },
  {
    "text": "nice feature called Federation the concept of order of Federation is simple",
    "start": "597610",
    "end": "603310"
  },
  {
    "text": "it's just a hierarchical structure we're in each cluster you can set up one",
    "start": "603310",
    "end": "608589"
  },
  {
    "text": "primitive server and that promise server will be responsible for scraping data in that cluster and you know teaching to",
    "start": "608589",
    "end": "616600"
  },
  {
    "text": "that you can pick one cluster and set up your federated the provision server and",
    "start": "616600",
    "end": "622660"
  },
  {
    "text": "your favorite provinces will be responsible for scrubbing data from all other individual promises server so this",
    "start": "622660",
    "end": "631089"
  },
  {
    "text": "is how we make it scale but in order to",
    "start": "631089",
    "end": "636160"
  },
  {
    "text": "do that there's still a couple of things that need need to be done so the first thing we do is that we aggregate our",
    "start": "636160",
    "end": "642880"
  },
  {
    "text": "data wherever get our test series so why do we why do we need to aggregate it",
    "start": "642880",
    "end": "649079"
  },
  {
    "text": "because by aggregation we can reduce the amount of storage of our data and in the",
    "start": "649079",
    "end": "656230"
  },
  {
    "text": "federated the promises server we only scrape those aggregated the data",
    "start": "656230",
    "end": "662069"
  },
  {
    "text": "so and of course another benefit is that if you Eric your data wherever you're needed you",
    "start": "662069",
    "end": "668920"
  },
  {
    "text": "just need to call your location metric and then your data will be showing up",
    "start": "668920",
    "end": "675939"
  },
  {
    "text": "it's super fast so okay the next thing is since we",
    "start": "675939",
    "end": "682239"
  },
  {
    "text": "reduce the amount of the storage space of our data and you know federated from",
    "start": "682239",
    "end": "688689"
  },
  {
    "text": "its server we can have longer retention period I think for us in our federated",
    "start": "688689",
    "end": "696399"
  },
  {
    "text": "formation server we set the retention period to be one year so so if you want",
    "start": "696399",
    "end": "703600"
  },
  {
    "text": "to debug for something or just for visualization perverse you can just pull",
    "start": "703600",
    "end": "708970"
  },
  {
    "text": "data up to one year and the next thing",
    "start": "708970",
    "end": "714249"
  },
  {
    "text": "is that since we we have our federated for missus server so this becomes the",
    "start": "714249",
    "end": "719739"
  },
  {
    "text": "most important server we have right so therefore we need to secure our our data",
    "start": "719739",
    "end": "726220"
  },
  {
    "text": "in the Federated four basis server so we add a permanent storage e to that so in",
    "start": "726220",
    "end": "733029"
  },
  {
    "text": "case there's anything wrong goes in your federated Prometheus server the pal crash you might want to delete the part",
    "start": "733029",
    "end": "739809"
  },
  {
    "text": "and after you bring back the part your data won't won't be lost so they will",
    "start": "739809",
    "end": "745209"
  },
  {
    "text": "still be there and now of course with",
    "start": "745209",
    "end": "750249"
  },
  {
    "text": "the federated server you have unified it display for all your data you don't need",
    "start": "750249",
    "end": "755799"
  },
  {
    "text": "to go to one provision server to see your data you want in one particular",
    "start": "755799",
    "end": "761799"
  },
  {
    "text": "cluster and then go to another one to see data in another cluster so this is a",
    "start": "761799",
    "end": "767110"
  },
  {
    "text": "another benefit of using Federation so",
    "start": "767110",
    "end": "774100"
  },
  {
    "start": "772000",
    "end": "772000"
  },
  {
    "text": "this is our Federation configuration I think actually we in a federated",
    "start": "774100",
    "end": "780309"
  },
  {
    "text": "provision server we script two kinds of data one is the irrigation data that we just",
    "start": "780309",
    "end": "786009"
  },
  {
    "text": "mentioned earlier the the other kind of data is the important community",
    "start": "786009",
    "end": "794399"
  },
  {
    "text": "components control plan components so I think in the red box you can",
    "start": "794399",
    "end": "800450"
  },
  {
    "text": "see that we script data for like Kobe is cool scheduler Cooper FBI server",
    "start": "800450",
    "end": "807430"
  },
  {
    "text": "EDC the all those important component control and components so these are so",
    "start": "807430",
    "end": "814400"
  },
  {
    "text": "important so we don't want to lose any data for for them and you can also see",
    "start": "814400",
    "end": "820910"
  },
  {
    "text": "that we scrape the data with the name starts with either cluster or colo-colo",
    "start": "820910",
    "end": "828710"
  },
  {
    "text": "means the colocation it's just referred to our data center so these are the",
    "start": "828710",
    "end": "834680"
  },
  {
    "text": "irrigation rule that we created so we also script than here so let's look at",
    "start": "834680",
    "end": "845900"
  },
  {
    "start": "843000",
    "end": "843000"
  },
  {
    "text": "some of the equation rules we have so to start with we take some of the rigid",
    "start": "845900",
    "end": "852950"
  },
  {
    "text": "rules from premises operator if you are interested you can just search it and",
    "start": "852950",
    "end": "858200"
  },
  {
    "text": "you can grab a couple of nice rules there so it's gonna be a good starting",
    "start": "858200",
    "end": "863720"
  },
  {
    "text": "point so in addition to that we also build our own aggregation rule so mostly",
    "start": "863720",
    "end": "871070"
  },
  {
    "text": "they are for CPU and the memory because these are two most important resource we",
    "start": "871070",
    "end": "877520"
  },
  {
    "text": "have in our community clusters so this",
    "start": "877520",
    "end": "884630"
  },
  {
    "start": "883000",
    "end": "883000"
  },
  {
    "text": "is this is an example of our aggregation rule so this is for CPU utilization",
    "start": "884630",
    "end": "892020"
  },
  {
    "text": "[Music] although the rule looks complicated but we can let's first focus on the metrics",
    "start": "892020",
    "end": "899570"
  },
  {
    "text": "we use on the top we use container CPU usage seconds total this is the CPU",
    "start": "899570",
    "end": "906500"
  },
  {
    "text": "usage for our container and the label",
    "start": "906500",
    "end": "911660"
  },
  {
    "text": "replace is just a function to create a another label in this case we create a label called controller from the",
    "start": "911660",
    "end": "919780"
  },
  {
    "text": "controller is basically the sales deployment and we sang up all the CPU",
    "start": "919780",
    "end": "926420"
  },
  {
    "text": "usage for all containers in one you can see in the end of the expression",
    "start": "926420",
    "end": "932830"
  },
  {
    "text": "on the top we group them by color so in",
    "start": "932830",
    "end": "938050"
  },
  {
    "text": "the bottom we use matrix called containers back CPU shares this is a",
    "start": "938050",
    "end": "943630"
  },
  {
    "text": "metric that give us give us CPU allocated to a container so similarly we",
    "start": "943630",
    "end": "951520"
  },
  {
    "text": "sang up all these for all the containers in one Colo and then with all these and",
    "start": "951520",
    "end": "959140"
  },
  {
    "text": "we came there if the CPU solution this",
    "start": "959140",
    "end": "966610"
  },
  {
    "start": "964000",
    "end": "964000"
  },
  {
    "text": "is similar to the previous rule the difference is just it gives us the different level of the specialization",
    "start": "966610",
    "end": "973410"
  },
  {
    "text": "this is the namespace level or you can see we preserve two labels Colo and the",
    "start": "973410",
    "end": "979300"
  },
  {
    "text": "namespace this is one more example this",
    "start": "979300",
    "end": "986170"
  },
  {
    "start": "983000",
    "end": "983000"
  },
  {
    "text": "is for controller level we have three labels here : M space and the controller",
    "start": "986170",
    "end": "993510"
  },
  {
    "text": "this gives us the pad level and this is give us the container level so with all",
    "start": "993510",
    "end": "1000570"
  },
  {
    "start": "997000",
    "end": "997000"
  },
  {
    "text": "these irrigation rules no matter whatever you want to see you want to see a civilization for deployment or for a",
    "start": "1000570",
    "end": "1007590"
  },
  {
    "text": "pod for a container for name space or for a cluster you can use this area",
    "start": "1007590",
    "end": "1015120"
  },
  {
    "text": "Shapiro's so now now we have all the",
    "start": "1015120",
    "end": "1023160"
  },
  {
    "start": "1021000",
    "end": "1021000"
  },
  {
    "text": "data information servers right so what's next what should we do with all those",
    "start": "1023160",
    "end": "1028770"
  },
  {
    "text": "data we want to monitor our system right so we want to get alert if there's",
    "start": "1028770",
    "end": "1035880"
  },
  {
    "text": "anything goes wrong in the cluster we can get a notification and then we can fix the problem so to that end we use a",
    "start": "1035880",
    "end": "1043110"
  },
  {
    "text": "lotta manager then the manager is a separate library you can deploy separately and it offers nice feature to",
    "start": "1043110",
    "end": "1051300"
  },
  {
    "text": "help you to manage your alerts for example you can you can use it to group your alerts you",
    "start": "1051300",
    "end": "1059010"
  },
  {
    "text": "can silence your alerts if you need some time to debug or you can use inhibition",
    "start": "1059010",
    "end": "1064520"
  },
  {
    "text": "so it has a nice UI like the pictures you're showing here so it's pretty",
    "start": "1064520",
    "end": "1072110"
  },
  {
    "text": "straightforward to use so that's that",
    "start": "1072110",
    "end": "1078900"
  },
  {
    "start": "1076000",
    "end": "1076000"
  },
  {
    "text": "took a take a look of example of the other two rules that we have an example this is for no not ready so we used",
    "start": "1078900",
    "end": "1087000"
  },
  {
    "text": "metric metric called coop know the status condition this matrix tells us",
    "start": "1087000",
    "end": "1093480"
  },
  {
    "text": "which node is going down we also add some useful labels there for example",
    "start": "1093480",
    "end": "1098880"
  },
  {
    "text": "severity in this case it's warning and a Colo environment with color and",
    "start": "1098880",
    "end": "1105090"
  },
  {
    "text": "environment we can tell which alert it is coming from this is another example",
    "start": "1105090",
    "end": "1113820"
  },
  {
    "text": "of whatever rule we have in example we use the irrigation rule we mentioned",
    "start": "1113820",
    "end": "1119429"
  },
  {
    "text": "earlier this is for CPU utilization if the CPU decision for a namespace goes",
    "start": "1119429",
    "end": "1125160"
  },
  {
    "text": "beyond 75% then we will get this alert you can see that the severity is",
    "start": "1125160",
    "end": "1130410"
  },
  {
    "text": "critical in this case so with the severity you can t always alert it",
    "start": "1130410",
    "end": "1136140"
  },
  {
    "text": "differently for example if it's a warning you may just receive email notification if it's critical alert you",
    "start": "1136140",
    "end": "1144510"
  },
  {
    "text": "may want to page your uncle and fix the problem immediately so this is the alert",
    "start": "1144510",
    "end": "1152910"
  },
  {
    "text": "template basically this if you have used",
    "start": "1152910",
    "end": "1158370"
  },
  {
    "text": "email notification it's gonna be the same as you can see your email lists all",
    "start": "1158370",
    "end": "1163740"
  },
  {
    "text": "the labels and it also description summary you can basically you can some",
    "start": "1163740",
    "end": "1169610"
  },
  {
    "text": "basic the park steps there and we will receive this notification pretty much",
    "start": "1169610",
    "end": "1175980"
  },
  {
    "text": "you have everything to deal with this alert so of course we couldn't miss the",
    "start": "1175980",
    "end": "1185130"
  },
  {
    "text": "most important alert which is to alert our primitive server obviously this server",
    "start": "1185130",
    "end": "1192100"
  },
  {
    "text": "goes down none of this will work so to do this we set up alerting our federated",
    "start": "1192100",
    "end": "1199270"
  },
  {
    "text": "parameters server and if there's and if any individual committed server goes down a lotta will be triggered in the",
    "start": "1199270",
    "end": "1207100"
  },
  {
    "text": "Federated premier server and we will receive the notification as for the",
    "start": "1207100",
    "end": "1212980"
  },
  {
    "text": "Federated appointment server we can have a simple cron job that was periodically",
    "start": "1212980",
    "end": "1218650"
  },
  {
    "text": "to check the status of our federated from Asus server if there's anything",
    "start": "1218650",
    "end": "1224290"
  },
  {
    "text": "wrong in our federated fermius server you can receive notification for this so",
    "start": "1224290",
    "end": "1234220"
  },
  {
    "text": "next I'm gonna head over to nada to talk about the dashboards yeah thanks long she before I actually done",
    "start": "1234220",
    "end": "1242080"
  },
  {
    "text": "want to the dashboards any guess so we have we mentioned that we have 2,000 servers and he guess how many outlets we",
    "start": "1242080",
    "end": "1249100"
  },
  {
    "text": "must be we may be getting in a week all in there that is my manager he knows",
    "start": "1249100",
    "end": "1256630"
  },
  {
    "text": "everything yes how much 50 it's pretty close not",
    "start": "1256630",
    "end": "1265150"
  },
  {
    "text": "too close oh so we get close to four alerts a week we have 2000 bare-metal servers like servers keep going every",
    "start": "1265150",
    "end": "1272500"
  },
  {
    "text": "day at least one or two servers keep doing keep going down so some of the concept in the let manage at lunch it",
    "start": "1272500",
    "end": "1278590"
  },
  {
    "text": "cover that you can so we set the severity to warning if one node goes down so we don't get a lot paged for",
    "start": "1278590",
    "end": "1284890"
  },
  {
    "text": "that of course so if there's critical alerts we get page so so we come up with",
    "start": "1284890",
    "end": "1290230"
  },
  {
    "text": "a complex alerting rule say you know if there's one node goes down don't alert if there's a 10 node or 10 percent of",
    "start": "1290230",
    "end": "1296380"
  },
  {
    "text": "the node goes in a cluster goes down then page me so all these things possible with a lot managed it's it's a",
    "start": "1296380",
    "end": "1301990"
  },
  {
    "text": "similar explore expression we use for dashboarding also yeah thank you so I really want so now we have as many",
    "start": "1301990",
    "end": "1310540"
  },
  {
    "text": "as as he mentioned that one application of using the data is alert for alerting the other application is yes we wanted",
    "start": "1310540",
    "end": "1317440"
  },
  {
    "text": "to use these data for dashboarding that was our initial goal so not to bore it's going to be exciting",
    "start": "1317440",
    "end": "1324080"
  },
  {
    "text": "I'm hoping that this is we really got a good product out of it yeah so the first",
    "start": "1324080",
    "end": "1333320"
  },
  {
    "start": "1332000",
    "end": "1332000"
  },
  {
    "text": "dashboard so you came up with the executive stats on our cluster shows how many nodes how many deployments you know",
    "start": "1333320",
    "end": "1339590"
  },
  {
    "text": "how many namespaces so this is all a federated dashboard you can drop down in",
    "start": "1339590",
    "end": "1344630"
  },
  {
    "text": "in a drop-down you can choose a particular data center you will be able to get in a single data center test stats the next one is the cluster view",
    "start": "1344630",
    "end": "1352580"
  },
  {
    "start": "1350000",
    "end": "1350000"
  },
  {
    "text": "it's pretty cool right so we within a single single spill single from single",
    "start": "1352580",
    "end": "1358400"
  },
  {
    "text": "place we are able to achieve what's happening on the entire cluster so so",
    "start": "1358400",
    "end": "1363830"
  },
  {
    "text": "this gives us this this dashboard helps us with the capacity planning is basically shows how much Headroom we",
    "start": "1363830",
    "end": "1369950"
  },
  {
    "text": "have for suborning new applications and also what is the current utilization of the cluster this is pretty cool and I",
    "start": "1369950",
    "end": "1376880"
  },
  {
    "text": "think some of the all these dashboards are derived from the alerting rules",
    "start": "1376880",
    "end": "1382280"
  },
  {
    "text": "so the aggregation rules we rewrote the",
    "start": "1382280",
    "end": "1389120"
  },
  {
    "text": "next one is the namespace in a multi-tenant environment so we have close to 8200 namespace and we wanted to",
    "start": "1389120",
    "end": "1397789"
  },
  {
    "text": "be able to figure out who is our biggest user and how are they performing in terms of usage like are they consuming",
    "start": "1397789",
    "end": "1405080"
  },
  {
    "text": "are they are they being a good citizen getting a good CP utilization so all",
    "start": "1405080",
    "end": "1410419"
  },
  {
    "text": "these things we were able to track it from a single place so this is pretty cool so this is one of my favorite",
    "start": "1410419",
    "end": "1417980"
  },
  {
    "start": "1416000",
    "end": "1416000"
  },
  {
    "text": "dashboard it's a deployment so as you can see here there's a green and a yellow so that",
    "start": "1417980",
    "end": "1423980"
  },
  {
    "text": "shows that previous release and the current release so from a single plane",
    "start": "1423980",
    "end": "1429409"
  },
  {
    "text": "we were able to observe the differences the the memory difference and the CPU",
    "start": "1429409",
    "end": "1435409"
  },
  {
    "text": "utilization difference over the week you know is there any previous releases sorry current release cost any code",
    "start": "1435409",
    "end": "1442760"
  },
  {
    "text": "issue or anything like that and and then application users able to enjoy watching",
    "start": "1442760",
    "end": "1448130"
  },
  {
    "text": "the auto-scale happening and container restart councils pretty useful for our application team",
    "start": "1448130",
    "end": "1454840"
  },
  {
    "text": "not to mention we have a lot of kubernetes control plane components here so we the controller scheduler we pretty",
    "start": "1454840",
    "end": "1462070"
  },
  {
    "text": "much you know watch all these dashboards like in is for controller we have a CPU",
    "start": "1462070",
    "end": "1467380"
  },
  {
    "text": "sage we have each and every controller amid some metrics Rozonda part autoscaler deployment controller you",
    "start": "1467380",
    "end": "1474370"
  },
  {
    "text": "know demon set controller you can pretty much watch how these controllers are performing scheduler right so the we",
    "start": "1474370",
    "end": "1484450"
  },
  {
    "start": "1481000",
    "end": "1481000"
  },
  {
    "text": "have something similar for api server so in api server is the core here right",
    "start": "1484450",
    "end": "1489760"
  },
  {
    "text": "like you have all the clients talking to api server via other Beaman sets or a deployment or a controller cubelet even",
    "start": "1489760",
    "end": "1496600"
  },
  {
    "text": "your custom controllers they all talk to api server we had ran into couple of issues where the api server was rattling",
    "start": "1496600",
    "end": "1504040"
  },
  {
    "text": "from the go client so we saw a flat line on this QPS for a particular client so",
    "start": "1504040",
    "end": "1510400"
  },
  {
    "text": "we were able to catch it pretty nicely from these dashboards so a cube lat",
    "start": "1510400",
    "end": "1516670"
  },
  {
    "text": "we have thousand two thousand nodes so drop down and select a node and observe how is the darker latency how's the",
    "start": "1516670",
    "end": "1523360"
  },
  {
    "text": "runtime latency everything thanks to I think Tom also showed this dashboard and",
    "start": "1523360",
    "end": "1529870"
  },
  {
    "text": "so we just grabbed shamelessly from the core OS repo and and we were able to get",
    "start": "1529870",
    "end": "1535000"
  },
  {
    "text": "a good view about Thea its CD metrics this is one of the interesting dashboard",
    "start": "1535000",
    "end": "1541090"
  },
  {
    "text": "so we had a we had a war room for alert alerting session so one of the challenge",
    "start": "1541090",
    "end": "1549100"
  },
  {
    "text": "we had was we have so many systems is hard to track which machine has which",
    "start": "1549100",
    "end": "1554230"
  },
  {
    "start": "1554000",
    "end": "1554000"
  },
  {
    "text": "package version so we came up with a tool we just read Ron wrote a simple scrip which labels a node with the",
    "start": "1554230",
    "end": "1561100"
  },
  {
    "text": "darker version or Debus version or RPC find some critical demons so from from a",
    "start": "1561100",
    "end": "1567940"
  },
  {
    "text": "graph on with a pie-chart plugin we were able to get a good you know miss realization around it not to mention so",
    "start": "1567940",
    "end": "1575920"
  },
  {
    "start": "1574000",
    "end": "1574000"
  },
  {
    "text": "the scale at which we operate is that we have 25 million time series flowing on to the promises and and it's we be we be",
    "start": "1575920",
    "end": "1584200"
  },
  {
    "text": "very careful about this is the ELA linus the promises federación time-series so even though",
    "start": "1584200",
    "end": "1591880"
  },
  {
    "text": "put together we have close to 25 million excuse me Federation just have three million so we",
    "start": "1591880",
    "end": "1599460"
  },
  {
    "text": "get what gets into the Prometheus Federation so that way as he mentioned",
    "start": "1599460",
    "end": "1605860"
  },
  {
    "text": "we were able to provide a long long retention yeah so that's it from us so I",
    "start": "1605860",
    "end": "1613570"
  },
  {
    "text": "can be reached on Twitter and the dashboards we have demoed here it's all",
    "start": "1613570",
    "end": "1618760"
  },
  {
    "text": "available on the Mike github repo yes Thomas is working on a good approach of",
    "start": "1618760",
    "end": "1625750"
  },
  {
    "text": "how to share the dashboards eventually we will try to use the case on net over",
    "start": "1625750",
    "end": "1631300"
  },
  {
    "text": "lattice mix in so right now these are plain J sounds out there and feel free to try out thank you",
    "start": "1631300",
    "end": "1644910"
  },
  {
    "text": "we got a question there yeah that's a",
    "start": "1644910",
    "end": "1654160"
  },
  {
    "text": "great question so we have two data centers so the one we shown in one data",
    "start": "1654160",
    "end": "1659560"
  },
  {
    "text": "center the diagram was simplified version so we chose two we have six data centers totally we chose two data center",
    "start": "1659560",
    "end": "1665500"
  },
  {
    "text": "for a Federation so yeah we were just",
    "start": "1665500",
    "end": "1676720"
  },
  {
    "text": "discussing this morning I should have got some picture of what our TV sees so we have a we have a 15 member team and",
    "start": "1676720",
    "end": "1683800"
  },
  {
    "text": "we have a couple of TVs so these dashboards just revolves there and of",
    "start": "1683800",
    "end": "1689230"
  },
  {
    "text": "course we have our thing too we have a slack integration so we get a lot so but when we come to an office we get a good",
    "start": "1689230",
    "end": "1695200"
  },
  {
    "text": "view of our cluster status",
    "start": "1695200",
    "end": "1698460"
  },
  {
    "text": "right everything is independent graph on our dashboards right now but you can just drop down and get to a different",
    "start": "1714360",
    "end": "1720550"
  },
  {
    "text": "dashboard I believe graph owner has a drill down version of getting into a dashboard I think we should be working",
    "start": "1720550",
    "end": "1726670"
  },
  {
    "text": "on that hi can you repeat yeah so the",
    "start": "1726670",
    "end": "1740560"
  },
  {
    "text": "question the do you have any redundancy on the federated we have two data centers scraping the federated metrics",
    "start": "1740560",
    "end": "1747370"
  },
  {
    "text": "so if one goes down we have another one yeah Prometheus is a single server one",
    "start": "1747370",
    "end": "1754360"
  },
  {
    "text": "so for federated we just have two servers running in two data centers so",
    "start": "1754360",
    "end": "1761340"
  },
  {
    "text": "right the question is why don't we use that yeah so we did try with with",
    "start": "1770610",
    "end": "1777490"
  },
  {
    "text": "primitives one point X so that time we were not able to permit is one point was",
    "start": "1777490",
    "end": "1783670"
  },
  {
    "text": "X was not able to scale over need we were filling out disk so we went on another route of trying with remote",
    "start": "1783670",
    "end": "1788920"
  },
  {
    "text": "right and now with the two pi X we don't see any issue like a TX improvement the",
    "start": "1788920",
    "end": "1793930"
  },
  {
    "text": "performance so right now our X the storage is able to handle one year worth",
    "start": "1793930",
    "end": "1799990"
  },
  {
    "text": "of retention I was just talking to Gautham in the afternoon we would probably try Thanos or couple of",
    "start": "1799990",
    "end": "1806470"
  },
  {
    "text": "contacts right so the couple of plugins they are working on so we would be trying with that for a long-term storage",
    "start": "1806470",
    "end": "1813990"
  },
  {
    "text": "hey-ya as a question is how do we secure so we have multiple data center how do",
    "start": "1830559",
    "end": "1836600"
  },
  {
    "text": "we secure the federated parameter scraping so it's a big organization some",
    "start": "1836600",
    "end": "1844010"
  },
  {
    "text": "of these problems are solved for us so we have an ingress controller sitting in front of every kubernetes cluster so we",
    "start": "1844010",
    "end": "1851029"
  },
  {
    "text": "were able to jump onto that securely so in in in Yahoo we have internal ports",
    "start": "1851029",
    "end": "1856399"
  },
  {
    "text": "it's not publicly or publicly open when it travels through a Colo to Colo a data",
    "start": "1856399",
    "end": "1862429"
  },
  {
    "text": "center to data center we have a data center level encryption so it's taken care for by the infrastructure team",
    "start": "1862429",
    "end": "1869590"
  },
  {
    "text": "thank you so much you so much [Applause]",
    "start": "1876309",
    "end": "1882758"
  }
]
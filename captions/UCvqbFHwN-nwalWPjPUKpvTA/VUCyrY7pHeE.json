[
  {
    "text": "all right we're gonna get started so what we're gonna do mark and I are",
    "start": "0",
    "end": "6540"
  },
  {
    "text": "gonna do here today is Mark and I spent an afternoon a couple",
    "start": "6540",
    "end": "12840"
  },
  {
    "text": "months ago or a month ago kind of whiteboarding out the problem that they had with surface discovery inside of",
    "start": "12840",
    "end": "18480"
  },
  {
    "text": "PayPal inside of zoom and kind of came up with a pretty good",
    "start": "18480",
    "end": "24119"
  },
  {
    "text": "solution of the problem and what I'm going to do is I'm going to kind of talk through just the foundations of",
    "start": "24119",
    "end": "29760"
  },
  {
    "text": "kubernetes surface discovery and how it works and Mark is gonna talk through how",
    "start": "29760",
    "end": "35430"
  },
  {
    "text": "they went and built on top of those primitives and on top of those extension points to achieve and remain compatible",
    "start": "35430",
    "end": "43710"
  },
  {
    "text": "with their internal service discovery system so I think it was labeled as a",
    "start": "43710",
    "end": "49140"
  },
  {
    "text": "panel but it's not a panel it's two talks I'm laying foundation marks building on the foundation",
    "start": "49140",
    "end": "55219"
  },
  {
    "text": "all right so I'm Brandon Phillips I'm the CTO and co-founder of core OS Kouros builds a bunch of open source projects",
    "start": "55219",
    "end": "61739"
  },
  {
    "text": "and also enterprise products in this entire in this ecosystem tectonic is a pure upstream kubernetes",
    "start": "61739",
    "end": "69990"
  },
  {
    "text": "distribution of kubernetes with a bunch of additional utilities packaged together that make it",
    "start": "69990",
    "end": "77610"
  },
  {
    "text": "possible for enterprises to adopt kubernetes and quasar container build and hosting service",
    "start": "77610",
    "end": "82759"
  },
  {
    "text": "so what I'm gonna be doing is walking through a few examples going through",
    "start": "82759",
    "end": "87990"
  },
  {
    "text": "very practical service discovery it's gonna take about 15 minutes or so very",
    "start": "87990",
    "end": "93060"
  },
  {
    "text": "practical services discover examples on top of kubernetes this is kind of a one on one 101 level foundation setting in",
    "start": "93060",
    "end": "101850"
  },
  {
    "text": "all of these I'm going to be using this tool called mini cube which allows you to build or bring up simple single node",
    "start": "101850",
    "end": "109110"
  },
  {
    "text": "at CD or simple single node kubernetes clusters on your laptop",
    "start": "109110",
    "end": "114890"
  },
  {
    "text": "there's a QuickStart guide available here if you search for github.com slash",
    "start": "114890",
    "end": "120960"
  },
  {
    "text": "kubernetes slash mini tube it talks through just how to bring it up under Windows Linux and OS X and",
    "start": "120960",
    "end": "127429"
  },
  {
    "text": "then if you're interested in trying out the rocket container engine there's a",
    "start": "127429",
    "end": "132820"
  },
  {
    "text": "couple of flags that change and you can bring up under rocket once you get everything working essentially it should",
    "start": "132820",
    "end": "138940"
  },
  {
    "text": "look something like this coop cuddle get nodes and you should have a single mini",
    "start": "138940",
    "end": "144850"
  },
  {
    "text": "tube and since running all right so that's what I'll be using",
    "start": "144850",
    "end": "149920"
  },
  {
    "text": "for all the demonstrations Wow don't want to go into auto advanced",
    "start": "149920",
    "end": "156040"
  },
  {
    "text": "mode I'm gonna cover that quickly so the first thing is we'll talk through kubernetes label service discovery",
    "start": "156040",
    "end": "163650"
  },
  {
    "text": "so kubernetes has this really powerful concept of labels that you can apply to essentially every single resource and",
    "start": "163650",
    "end": "169870"
  },
  {
    "text": "object inside of kubernetes and these resources or these labels are",
    "start": "169870",
    "end": "177370"
  },
  {
    "text": "concept inside of the kubernetes api server the api server you can think of",
    "start": "177370",
    "end": "184630"
  },
  {
    "text": "it's just any other web application that's not really any magic or anything fancy it's a container that",
    "start": "184630",
    "end": "191130"
  },
  {
    "text": "stores all this data and persistent data store called Etsy D it is hosted at a well-known URL so",
    "start": "191130",
    "end": "199540"
  },
  {
    "text": "generally you'll have like kubernetes dot internal dot Corp or whatever and",
    "start": "199540",
    "end": "204550"
  },
  {
    "text": "that'll be protected by TLS assets or TLS certs or by some sort of other identity like Open ID Connect or",
    "start": "204550",
    "end": "211980"
  },
  {
    "text": "something else so the API server is what your laptop",
    "start": "211980",
    "end": "218500"
  },
  {
    "text": "talks to and it's also what the applications running in the cluster talked to when they need to resolve a",
    "start": "218500",
    "end": "224530"
  },
  {
    "text": "label or any other service discovery information inside of kubernetes so the idea of this label is that when I",
    "start": "224530",
    "end": "233890"
  },
  {
    "text": "do something like coop cuddle and I create a new replica set or a new",
    "start": "233890",
    "end": "239739"
  },
  {
    "text": "application that I want deployed inside of kubernetes various labels will be applied to it and these are used",
    "start": "239739",
    "end": "246220"
  },
  {
    "text": "throughout the system not just for service discovery so let's say that I deploy an application this application",
    "start": "246220",
    "end": "252010"
  },
  {
    "text": "is going to have a couple of labels like a people's web and environment environment equals prod I'll deploy a",
    "start": "252010",
    "end": "258700"
  },
  {
    "text": "replica set say I want to have three copies of that application running perhaps only one is running so the the",
    "start": "258700",
    "end": "265490"
  },
  {
    "text": "cassette the software that manages is that replica set is inside of a component in kubernetes called the",
    "start": "265490",
    "end": "271310"
  },
  {
    "text": "controller manager that controller manager essentially is doing service discovery at via the labels inside of",
    "start": "271310",
    "end": "277310"
  },
  {
    "text": "the API finding what is the current state based on that label query saying",
    "start": "277310",
    "end": "283039"
  },
  {
    "text": "all right well based on the label query the current state of the system is one I've been told that I need to move the",
    "start": "283039",
    "end": "289190"
  },
  {
    "text": "system to three and then it goes through and launches new pods on site on top of",
    "start": "289190",
    "end": "294650"
  },
  {
    "text": "the cluster so this idea of labels and this idea of service discovery is fundamental throughout the entire",
    "start": "294650",
    "end": "299720"
  },
  {
    "text": "kubernetes system so what we'll do is just give a",
    "start": "299720",
    "end": "306410"
  },
  {
    "text": "practical example using the command line tool of how this works so the first thing we're gonna do is use coop cuttle",
    "start": "306410",
    "end": "312590"
  },
  {
    "text": "run launch an engine X server and then we're going to apply a label to that deployment which will apply the label to",
    "start": "312590",
    "end": "320389"
  },
  {
    "text": "the replica set which will apply a label to the pod so let's go ahead and look through there",
    "start": "320389",
    "end": "325539"
  },
  {
    "text": "so all I'll do cout cuddle run engine X etc",
    "start": "325539",
    "end": "331970"
  },
  {
    "text": "I've already done this because it takes a couple of seconds to download the container and one conference Wi-Fi and I",
    "start": "331970",
    "end": "338330"
  },
  {
    "text": "don't want to bore you all so the the application is already running now what",
    "start": "338330",
    "end": "343400"
  },
  {
    "text": "we can do is we can find all right well we're all the replica sets were all the instances of this application so if we",
    "start": "343400",
    "end": "349940"
  },
  {
    "text": "do a cube cuddle get replica set which shouldn't be shortened is our s and then do a query",
    "start": "349940",
    "end": "357590"
  },
  {
    "text": "where we say give me all the replica sets the match label PAP equals index it returns one and similarly we can do the",
    "start": "357590",
    "end": "364340"
  },
  {
    "text": "same thing for the pod which finds the actual concrete running",
    "start": "364340",
    "end": "369729"
  },
  {
    "text": "process inside of the cluster so again that whole chain of commands is like",
    "start": "369729",
    "end": "374990"
  },
  {
    "text": "we're able to find the deployment the deployment is the thing that could kind of run created for us to tell us to run",
    "start": "374990",
    "end": "381740"
  },
  {
    "text": "this engine X service the deployment then creates replica sets this is how",
    "start": "381740",
    "end": "387199"
  },
  {
    "text": "rolling updates happen in deployments so the replica set says alright I want to have one copy of this running and then",
    "start": "387199",
    "end": "393349"
  },
  {
    "text": "finally we go down and we see that the pod that same label at people's engine X and",
    "start": "393349",
    "end": "399250"
  },
  {
    "text": "we find the concrete running process that concrete running container any questions on that so far good",
    "start": "399250",
    "end": "409289"
  },
  {
    "text": "so you can start to imagine this doing other things you can the concept of a",
    "start": "410490",
    "end": "417159"
  },
  {
    "text": "service is that concrete load balancer inside of the system so if I want to put this engine X service behind a load",
    "start": "417159",
    "end": "424030"
  },
  {
    "text": "balancer I say I want a IP address allocated I want this IP address to be the central",
    "start": "424030",
    "end": "430599"
  },
  {
    "text": "incoming load balancer that'll may be put into DNS or whatever for my service",
    "start": "430599",
    "end": "435849"
  },
  {
    "text": "that that load balancer will then use label queries to find all the pods that are running that can service that",
    "start": "435849",
    "end": "442569"
  },
  {
    "text": "service so it's very hierarchical and then maybe you put that service behind that in ELB",
    "start": "442569",
    "end": "448750"
  },
  {
    "text": "or behind a load balancer inside of your datacenter like an f5 or maybe you put",
    "start": "448750",
    "end": "455229"
  },
  {
    "text": "that service directly on a network like inside of a Google cloud application",
    "start": "455229",
    "end": "461370"
  },
  {
    "text": "okay and the way that we do this with mini cube is because mini coop doesn't have a load balancer we don't have an f5",
    "start": "461370",
    "end": "467710"
  },
  {
    "text": "we don't have anything fancy is that we just directly expose the service via thing called a node port",
    "start": "467710",
    "end": "475949"
  },
  {
    "text": "so that happened really fast but what we're telling it is all right I have internet running I want you to expose",
    "start": "475949",
    "end": "482830"
  },
  {
    "text": "that nginx deployment I want you to expose port 80 I want to give it a node",
    "start": "482830",
    "end": "488439"
  },
  {
    "text": "port so what is a node port if we go in and get the service cube cut' we'll get service",
    "start": "488439",
    "end": "494250"
  },
  {
    "text": "nginx - oh yeah mul what we'll see here is that there's a",
    "start": "494250",
    "end": "501159"
  },
  {
    "text": "thing called a node port that's been assigned along with the port that was that we want to target for this the port",
    "start": "501159",
    "end": "508629"
  },
  {
    "text": "that we want to target for this load balancer and what this node port does is it says on every single node in our node",
    "start": "508629",
    "end": "515169"
  },
  {
    "text": "in our cluster and if we remember every single node in our cluster is this single node the single mini cube node",
    "start": "515169",
    "end": "521828"
  },
  {
    "text": "every single node in the cluster we want to expose a port that is going to route to this",
    "start": "521829",
    "end": "529060"
  },
  {
    "text": "application and that port in particular is going to be thirty thousand nine hundred and eighty five and it just randomly assigns",
    "start": "529060",
    "end": "535540"
  },
  {
    "text": "it so if you remember back before the world of kubernetes is how we all did sort of internal service discovery right",
    "start": "535540",
    "end": "541780"
  },
  {
    "text": "we had like single IP addresses for servers the single servers when we need to expose a port we go into our next",
    "start": "541780",
    "end": "548320"
  },
  {
    "text": "Excel spreadsheet we'd record hey I'm reserving port 4098 for the reddest cash",
    "start": "548320",
    "end": "553930"
  },
  {
    "text": "or whatever it is and then we would we tell network operations all right I need to use this port for that and all the",
    "start": "553930",
    "end": "560470"
  },
  {
    "text": "application developers would hard code that into their configuration this is allowing us to go back to that port",
    "start": "560470",
    "end": "565840"
  },
  {
    "text": "mapping world where we may not have sophisticated load balancers or networking so after we get that placed",
    "start": "565840",
    "end": "573630"
  },
  {
    "text": "mini to the tool that we're using to run this has a convenience application",
    "start": "573630",
    "end": "578890"
  },
  {
    "text": "called mini cube service a lot mini cube service will do is it will figure out",
    "start": "578890",
    "end": "584530"
  },
  {
    "text": "what operating system I'm on on OS X or Windows or Linux it'll run the correct",
    "start": "584530",
    "end": "589870"
  },
  {
    "text": "command to launch my browser and actually open up that service on that port so what happens is that you'll see",
    "start": "589870",
    "end": "596590"
  },
  {
    "text": "this is the IP address of my mini cube one seven two sixteen something",
    "start": "596590",
    "end": "602110"
  },
  {
    "text": "something and then it opened up port three thirty thousand nine hundred eighty five right so immediately we're",
    "start": "602110",
    "end": "609160"
  },
  {
    "text": "able to kind of simulate the idea of a load balancer here on our laptop",
    "start": "609160",
    "end": "615570"
  },
  {
    "text": "any questions on that yes",
    "start": "617370",
    "end": "622440"
  },
  {
    "text": "yeah great question so the question was if node port always load balances - like",
    "start": "630290",
    "end": "636259"
  },
  {
    "text": "the local machine or if it load balances across the cluster and so what's actually happening behind the scenes is",
    "start": "636259",
    "end": "642079"
  },
  {
    "text": "that there's a thing called the coop proxy and every single machine the cluster is going to expose that node port once you",
    "start": "642079",
    "end": "649100"
  },
  {
    "text": "define a node port so if you have five workers all five workers will begin listening on thirty thousand nine",
    "start": "649100",
    "end": "654679"
  },
  {
    "text": "hundred eighty five and then you'll when they hit that machine it will essentially do round-robin eight through",
    "start": "654679",
    "end": "661729"
  },
  {
    "text": "the iptables system inside of the kernel to hit random hosts and so generally",
    "start": "661729",
    "end": "668269"
  },
  {
    "text": "what you'll want to do is you'll want to like if you have an e lb or something or you have an f5 you'll want to have that",
    "start": "668269",
    "end": "674119"
  },
  {
    "text": "f5 load balanced across your entire cluster and then essentially you have a",
    "start": "674119",
    "end": "679669"
  },
  {
    "text": "second like application tier that load balances through kubernetes this is all like just one way of doing load",
    "start": "679669",
    "end": "685519"
  },
  {
    "text": "balancing obviously there are more kubernetes native ways but this is super convenient particularly we see a lot of",
    "start": "685519",
    "end": "691399"
  },
  {
    "text": "people as they're getting early adopting early adopting kubernetes inside of",
    "start": "691399",
    "end": "696559"
  },
  {
    "text": "their environment or inside of their companies they'll use node port as a way of not",
    "start": "696559",
    "end": "702230"
  },
  {
    "text": "having to engage the network operations team right from the beginning great question any other questions",
    "start": "702230",
    "end": "708609"
  },
  {
    "text": "ok ok so this is all about V API the",
    "start": "708609",
    "end": "714529"
  },
  {
    "text": "kubernetes api we're using labels we're using services we're using deployments and these are fundamental parts of the",
    "start": "714529",
    "end": "721730"
  },
  {
    "text": "kubernetes api now above the api there are a lot of conveniences that kubernetes provides",
    "start": "721730",
    "end": "729069"
  },
  {
    "text": "the dns addon is one of those conveniences so dns is not built into",
    "start": "729069",
    "end": "734509"
  },
  {
    "text": "kubernetes is an extension point it is something that is a convenience offered by kubernetes but something that's",
    "start": "734509",
    "end": "740179"
  },
  {
    "text": "pluggable and that's what Mark is going to be talking about is plugging into dns",
    "start": "740179",
    "end": "745419"
  },
  {
    "text": "so the dns addon what it does is on every single machine in your system you",
    "start": "745419",
    "end": "752389"
  },
  {
    "text": "provide this IP address via the cluster dns flag of the couplet and what happens",
    "start": "752389",
    "end": "758059"
  },
  {
    "text": "is that every single pod launch on that machine or on that machine with that flag",
    "start": "758059",
    "end": "763730"
  },
  {
    "text": "we'll get injected into its @c resolve cough the IP address that's provided and",
    "start": "763730",
    "end": "769130"
  },
  {
    "text": "this IP address is a IP that's exists that exists on top of the kubernetes",
    "start": "769130",
    "end": "775639"
  },
  {
    "text": "network so it's going to be a ten dot network or whatever you defined as your kubernetes service network so it gets a",
    "start": "775639",
    "end": "781699"
  },
  {
    "text": "little bit of meta and recursive here so we're telling every single pod on the network this is the IP address you",
    "start": "781699",
    "end": "788149"
  },
  {
    "text": "should use and that is part of the kubernetes network and so when a dns query comes in it gets ratted over the",
    "start": "788149",
    "end": "795290"
  },
  {
    "text": "kubernetes network hits another service the Kubb dns service inside of kubernetes that's running dns mask or",
    "start": "795290",
    "end": "802160"
  },
  {
    "text": "whatever and actually resolves that so if we if we look into",
    "start": "802160",
    "end": "808240"
  },
  {
    "text": "kubernetes on this mini tube cluster we'll run a query that says describe the",
    "start": "808240",
    "end": "815380"
  },
  {
    "text": "describe the service cube DNS that's running inside a cube system namespace",
    "start": "815380",
    "end": "820430"
  },
  {
    "text": "and what we'll see is that there is a service that's running at 10.0 at 0.10",
    "start": "820430",
    "end": "827260"
  },
  {
    "text": "and it's exposing port 53 both UDP and TCP and this again this IP address is",
    "start": "827260",
    "end": "834860"
  },
  {
    "text": "injected into the at sea resolve comp of every pod running in the cluster so this is where they go to to get their dns",
    "start": "834860",
    "end": "841399"
  },
  {
    "text": "resolution service so the basics of this service what",
    "start": "841399",
    "end": "848899"
  },
  {
    "text": "happens is that there's this piece of software called the cube DNS pod it runs",
    "start": "848899",
    "end": "856010"
  },
  {
    "text": "as a deployment in your kubernetes cluster it synchronizes with the API server so it's asking the API server",
    "start": "856010",
    "end": "862880"
  },
  {
    "text": "give me all the services that have been defined give me all the pods that have been defined and it's creating",
    "start": "862880",
    "end": "868430"
  },
  {
    "text": "essentially a cache of all those things that it can resolve as DNS requests and",
    "start": "868430",
    "end": "873500"
  },
  {
    "text": "then it's exposing the service 10.0.0.0 or to go on to one of the pods and the",
    "start": "873500",
    "end": "881089"
  },
  {
    "text": "system and run dig you'd say dig at this IP address and you could say resolve",
    "start": "881089",
    "end": "888790"
  },
  {
    "text": "the DNS surface itself which runs at Kubb - d and ask that Kubb system that",
    "start": "888790",
    "end": "894350"
  },
  {
    "text": "service that cluster dot local straightforward now it's kind of",
    "start": "894350",
    "end": "899600"
  },
  {
    "text": "annoying to constantly have to be as staying in the cluster if you want to understand the system so I'll post these",
    "start": "899600",
    "end": "905629"
  },
  {
    "text": "slides later but if he is Google like kubernetes network troubleshooting core OS we have this one-liner here that will",
    "start": "905629",
    "end": "914329"
  },
  {
    "text": "port forward the kubernetes dns server to your local machine so I'll go ahead and run that",
    "start": "914329",
    "end": "922540"
  },
  {
    "text": "and so what this will do is kubernetes is going to run its DNS server port for",
    "start": "922540",
    "end": "928970"
  },
  {
    "text": "its DNS server to port 5300 on my laptop",
    "start": "928970",
    "end": "934449"
  },
  {
    "text": "alright by doing that what I can do is I can start to play around with the",
    "start": "935589",
    "end": "940699"
  },
  {
    "text": "kubernetes DNS server so I can run dig and I can see oops",
    "start": "940699",
    "end": "948350"
  },
  {
    "text": "I can run dig and I can see ask a question like the cluster about local sub domain which is the top-level domain",
    "start": "948350",
    "end": "954259"
  },
  {
    "text": "of the cluster and it gives me back that SOA record with the name server the next",
    "start": "954259",
    "end": "961100"
  },
  {
    "text": "thing I could do is I can start to resolve services so I have a service inside of",
    "start": "961100",
    "end": "968949"
  },
  {
    "text": "my cluster if we do coop cuddle get service I have a service inside my",
    "start": "968949",
    "end": "975410"
  },
  {
    "text": "cluster called at CD dash cluster 0 0 1 and if I do a dig",
    "start": "975410",
    "end": "982089"
  },
  {
    "text": "for that service for an a record I'll get back the cluster IP",
    "start": "982089",
    "end": "988480"
  },
  {
    "text": "so if I do at CD cluster Asadero zero zero one dot default service that",
    "start": "988480",
    "end": "995749"
  },
  {
    "text": "cluster local I'll see here that I get the exact same service IP back that is",
    "start": "995749",
    "end": "1001929"
  },
  {
    "text": "listed here inside of the service list and similarly you can do serve records",
    "start": "1001929",
    "end": "1008769"
  },
  {
    "text": "as well it will if you have a service that like the the DNS service that",
    "start": "1008769",
    "end": "1014410"
  },
  {
    "text": "expose a TCP and UDP port you can dig for service records and find out what port number it is based on the protocol",
    "start": "1014410",
    "end": "1023040"
  },
  {
    "text": "there's a bunch of other features that the DNS Adhan has one of the most convenient is that",
    "start": "1025049",
    "end": "1031329"
  },
  {
    "text": "it will automatically put a search prefix for the DMS so for an individual",
    "start": "1031329",
    "end": "1036730"
  },
  {
    "text": "pod but let's assume that you want a hard code inside of your application I want to be able to reach Postgres you",
    "start": "1036730",
    "end": "1043209"
  },
  {
    "text": "can just say Postgres you can expose a post service called Postgres in your namespace and that will just",
    "start": "1043209",
    "end": "1048490"
  },
  {
    "text": "automatically resolve and you won't have to do any of the prefixing like adding cluster that local or anything that I'm",
    "start": "1048490",
    "end": "1055929"
  },
  {
    "text": "having to do here because the etsy resolve comps or FX will already be in",
    "start": "1055929",
    "end": "1061330"
  },
  {
    "text": "there there's there's some really good Doc's",
    "start": "1061330",
    "end": "1066909"
  },
  {
    "text": "or at least some passable Doc's that I helped to write of about kubernetes and the DNS add-on and",
    "start": "1066909",
    "end": "1073419"
  },
  {
    "text": "a lot of the default functionality its kubernetes the IO slash doc slash admin / DNS and it describes all the different",
    "start": "1073419",
    "end": "1080590"
  },
  {
    "text": "types of records and all the different types of queries that you can make against the",
    "start": "1080590",
    "end": "1086679"
  },
  {
    "text": "DNS server that is the end of part 1 so what I'll",
    "start": "1086679",
    "end": "1092529"
  },
  {
    "text": "ask next is I'll ask mark to come up and start setting up and meanwhile I'll take",
    "start": "1092529",
    "end": "1098889"
  },
  {
    "text": "a few questions if anybody has some on how this all works yes",
    "start": "1098889",
    "end": "1104190"
  },
  {
    "text": "sure so the question was what do you get back for SRB queries so on a service what",
    "start": "1107700",
    "end": "1114730"
  },
  {
    "text": "you'll get back on a SRV queries you can do things like underscore dns underscore tcp dot",
    "start": "1114730",
    "end": "1122250"
  },
  {
    "text": "service will give you back the port and then the rest of the SRV record there",
    "start": "1122250",
    "end": "1129100"
  },
  {
    "text": "are I'll have to look again I believe that it will often look I think on some",
    "start": "1129100",
    "end": "1136059"
  },
  {
    "text": "of them if you have multiple IPS it'll return all the IPS as well for the service they'll have to check on that",
    "start": "1136059",
    "end": "1143279"
  },
  {
    "text": "it's true ok",
    "start": "1143279",
    "end": "1149370"
  },
  {
    "text": "yep yeah yep yep hey sorry person yeah",
    "start": "1158200",
    "end": "1164540"
  },
  {
    "text": "please yes so the question was how quickly did",
    "start": "1164540",
    "end": "1170630"
  },
  {
    "text": "your services get registered generally it's it's sub-second registration the the",
    "start": "1170630",
    "end": "1176860"
  },
  {
    "text": "Kubb dns add-on is doing a thing called a watch on the api so look at this",
    "start": "1176860",
    "end": "1181970"
  },
  {
    "text": "streaming update essentially as soon as new stuff shows up yeah",
    "start": "1181970",
    "end": "1187420"
  },
  {
    "text": "yeah so it doesn't modify at sea house so this is an actual real DNS server a",
    "start": "1190090",
    "end": "1197330"
  },
  {
    "text": "caching forwarding DNS server and so this essentially will do the recursive",
    "start": "1197330",
    "end": "1204020"
  },
  {
    "text": "resolution and it runs DNS mask in front of it Etsy house is completely untouched",
    "start": "1204020",
    "end": "1211600"
  },
  {
    "text": "essentially only only does the Etsy resolve comp and resolution",
    "start": "1211600",
    "end": "1216610"
  },
  {
    "text": "all right with that I will hand it over to mark thanks so much oh",
    "start": "1216610",
    "end": "1223090"
  },
  {
    "text": "no need a mic",
    "start": "1223090",
    "end": "1226450"
  },
  {
    "text": "okay Thank You Brandon my name is Mark Petrovich I'm an engineer at PayPal more",
    "start": "1251410",
    "end": "1259640"
  },
  {
    "text": "specifically I'm an engineer at a company called zoom which is a PayPal company we were acquired late last year",
    "start": "1259640",
    "end": "1266480"
  },
  {
    "text": "and the zoom is a money service whereby we help folks living in the",
    "start": "1266480",
    "end": "1273680"
  },
  {
    "text": "United States send money back home every payday to their families back home in",
    "start": "1273680",
    "end": "1278810"
  },
  {
    "text": "any number of any one country among dozens of countries that we service so",
    "start": "1278810",
    "end": "1285170"
  },
  {
    "text": "we are about a hundred some-odd engineers and we're in the process of container izing all of our micro",
    "start": "1285170",
    "end": "1292010"
  },
  {
    "text": "services as well as vacating our legacy monolith",
    "start": "1292010",
    "end": "1298270"
  },
  {
    "text": "so i'll tell you how we're doing that in a second",
    "start": "1298270",
    "end": "1304600"
  },
  {
    "text": "briefly on the matter of what challenges we've",
    "start": "1305150",
    "end": "1311120"
  },
  {
    "text": "faced along the way some specific to integrating our legacy service discovery",
    "start": "1311120",
    "end": "1316670"
  },
  {
    "text": "some not but if you've started down the path of container izing your",
    "start": "1316670",
    "end": "1322550"
  },
  {
    "text": "applications you probably have noticed that it touches everything your builds",
    "start": "1322550",
    "end": "1328400"
  },
  {
    "text": "are affected your CI pipeline is affected how you deploy is affected how",
    "start": "1328400",
    "end": "1333530"
  },
  {
    "text": "you talk about deploying is affected if you haven't started container izing your",
    "start": "1333530",
    "end": "1339350"
  },
  {
    "text": "applications then you can expect to rediscover how container izing will",
    "start": "1339350",
    "end": "1345440"
  },
  {
    "text": "touch everything so under that umbrella of a lot of my tooling is going to",
    "start": "1345440",
    "end": "1351410"
  },
  {
    "text": "change and my language is going to change language about how it is how I talk about deployments will change there",
    "start": "1351410",
    "end": "1358730"
  },
  {
    "text": "are a couple of interesting things that we discovered along the way unrelated to service discovery but I'll",
    "start": "1358730",
    "end": "1364880"
  },
  {
    "text": "mention them anyway because I think it's worth it for example if you have logging",
    "start": "1364880",
    "end": "1371810"
  },
  {
    "text": "dashboards or metrics collection dashboards and the folks who read those dashboards if",
    "start": "1371810",
    "end": "1379850"
  },
  {
    "text": "they're accustomed based upon how you deploy to seeing they're accustomed to seeing a",
    "start": "1379850",
    "end": "1386290"
  },
  {
    "text": "particular application always logging from a particular host or a particular",
    "start": "1386290",
    "end": "1391450"
  },
  {
    "text": "IP address then you should visit with them now because",
    "start": "1391450",
    "end": "1398010"
  },
  {
    "text": "container IPs and container host names are not persistent things every time you",
    "start": "1398010",
    "end": "1403090"
  },
  {
    "text": "restart a container it gets a new IP address it gets a new host name so if",
    "start": "1403090",
    "end": "1408220"
  },
  {
    "text": "your container if your logging framework or your metrics collection of framework has customers internal customers who are",
    "start": "1408220",
    "end": "1415930"
  },
  {
    "text": "used to seeing artifacts of your deployment whereby applications always log from the same host go visit with",
    "start": "1415930",
    "end": "1422590"
  },
  {
    "text": "those folks and tell them that with containers an application will retain",
    "start": "1422590",
    "end": "1428260"
  },
  {
    "text": "its identity but it will be logging from a different host every single time the different IP address every time that",
    "start": "1428260",
    "end": "1434380"
  },
  {
    "text": "application is deployed we're also facing the challenge of",
    "start": "1434380",
    "end": "1439600"
  },
  {
    "text": "crafting developer environments for our developers a hundred some-odd developers",
    "start": "1439600",
    "end": "1446430"
  },
  {
    "text": "currently developers at zoom will deploy their dependencies onto their laptops",
    "start": "1446430",
    "end": "1451810"
  },
  {
    "text": "and then begin to develop against those locally running dependencies what we",
    "start": "1451810",
    "end": "1457120"
  },
  {
    "text": "want to do is to give developers their own kubernetes cluster a small cluster so that they can begin to deploy in the",
    "start": "1457120",
    "end": "1464170"
  },
  {
    "text": "same way that their counterparts in QA and production will deploy applications",
    "start": "1464170",
    "end": "1469360"
  },
  {
    "text": "so that we can all talk about deployment in the same way not in terms of",
    "start": "1469360",
    "end": "1477150"
  },
  {
    "text": "puppet configurations puppet modules ansible scripts but instead speak in",
    "start": "1477150",
    "end": "1483760"
  },
  {
    "text": "terms of kubernetes first principles like replication controllers deployments",
    "start": "1483760",
    "end": "1489840"
  },
  {
    "text": "namespaces secrets things like that so we want to give",
    "start": "1489840",
    "end": "1495730"
  },
  {
    "text": "developers their own clusters and we're working on a couple of ways to do that if you are currently doing that or you",
    "start": "1495730",
    "end": "1502900"
  },
  {
    "text": "have solved this problem I would like to talk to you in the hallway maybe we can share notes",
    "start": "1502900",
    "end": "1508320"
  },
  {
    "text": "so developers are going to have to become familiar with how coop control works which is the command line tool",
    "start": "1508320",
    "end": "1513670"
  },
  {
    "text": "with which you control a cluster as well the staff in QA and production will also",
    "start": "1513670",
    "end": "1519490"
  },
  {
    "text": "become familiar with coop control so kubernetes and its control mechanisms",
    "start": "1519490",
    "end": "1525039"
  },
  {
    "text": "will be part of the vocabulary of how we talk about deployment which is an educational problem across the",
    "start": "1525039",
    "end": "1531369"
  },
  {
    "text": "organization you'll have to teach yourselves how to do this finally the challenge we face is",
    "start": "1531369",
    "end": "1537299"
  },
  {
    "text": "integrating our legacy service discovery design into kubernetes so that some",
    "start": "1537299",
    "end": "1543100"
  },
  {
    "text": "applications can run inside the cluster on day one and some will be continued to",
    "start": "1543100",
    "end": "1549580"
  },
  {
    "text": "run outside the cluster we're going to production with kubernetes sometime next",
    "start": "1549580",
    "end": "1554799"
  },
  {
    "text": "year we're preparing with our plan to do so so we want to start slowly deploy one",
    "start": "1554799",
    "end": "1563470"
  },
  {
    "text": "or two applications into kubernetes and have everything else continue to run outside but these applications can't",
    "start": "1563470",
    "end": "1570190"
  },
  {
    "text": "know that they're running inside the cluster nor can applications that need them know that they're running in the",
    "start": "1570190",
    "end": "1576340"
  },
  {
    "text": "cluster that would be counterproductive so I'll share with you how a couple of designs that we came up with that lets",
    "start": "1576340",
    "end": "1583330"
  },
  {
    "text": "us move applications into the cluster seamlessly so we've been in business for 10 some",
    "start": "1583330",
    "end": "1590470"
  },
  {
    "text": "odd years and we have legacy that we're dealing with we have traditionally run a",
    "start": "1590470",
    "end": "1595779"
  },
  {
    "text": "monolith that manifested all of our business logic new functionality we're porting we're",
    "start": "1595779",
    "end": "1603580"
  },
  {
    "text": "implementing in micro services immediately and we're setting aside time to vacate our monolith of its",
    "start": "1603580",
    "end": "1609909"
  },
  {
    "text": "functionality this so that someday we'll have just a set of cooperating micro services we are container izing",
    "start": "1609909",
    "end": "1617200"
  },
  {
    "text": "everything we have started down this path a good year ago and if you are just",
    "start": "1617200",
    "end": "1623649"
  },
  {
    "text": "starting this or you're contemplate starting it you will discover that it takes you you and your organization many",
    "start": "1623649",
    "end": "1632139"
  },
  {
    "text": "many months to surface how you work how",
    "start": "1632139",
    "end": "1637539"
  },
  {
    "text": "what is your docker file what should your docker file contain or your AC build file",
    "start": "1637539",
    "end": "1643529"
  },
  {
    "text": "what is my container entry point look like for all of these micro services and hopefully you'll come up with a model",
    "start": "1643529",
    "end": "1650139"
  },
  {
    "text": "where all of my micro services have pretty much the same dockerfile hopefully the same dockerfile",
    "start": "1650139",
    "end": "1656609"
  },
  {
    "text": "not the same instance but they read the same and hopefully you'll find that your",
    "start": "1656609",
    "end": "1661929"
  },
  {
    "text": "applications all can use the exact same entry point which in our case is a shell",
    "start": "1661929",
    "end": "1668440"
  },
  {
    "text": "script we found that shell scripts are universally sort of the the entry point",
    "start": "1668440",
    "end": "1673989"
  },
  {
    "text": "that just falls out of most designs so your entry point will read a certain way",
    "start": "1673989",
    "end": "1679690"
  },
  {
    "text": "your docker file will read a certain way and if you're an organization of any size it will take you many months to",
    "start": "1679690",
    "end": "1686649"
  },
  {
    "text": "surface what those patterns are so that you can move on to the next problem so",
    "start": "1686649",
    "end": "1692440"
  },
  {
    "text": "we also need an orchestration framework we've decided to use kubernetes some many many many many months ago and",
    "start": "1692440",
    "end": "1699779"
  },
  {
    "text": "I'll tell you how we've integrated our service discovery into this thing so we currently run our micro services on",
    "start": "1699779",
    "end": "1707109"
  },
  {
    "text": "bare metal or VMs and we don't know what IP address a micro service will",
    "start": "1707109",
    "end": "1714399"
  },
  {
    "text": "take on when it begins to run by design we don't know where clients",
    "start": "1714399",
    "end": "1720549"
  },
  {
    "text": "future clients of that micro service don't know the IP address of that micro service running right now in production",
    "start": "1720549",
    "end": "1726929"
  },
  {
    "text": "intentionally we want to develop a way where clients that need that micro service can discover its address just in",
    "start": "1726929",
    "end": "1735639"
  },
  {
    "text": "time so we need a service discovery framework a couple of years ago we were",
    "start": "1735639",
    "end": "1741429"
  },
  {
    "text": "inspired by Airbnb s smart stack technology to write our own",
    "start": "1741429",
    "end": "1747089"
  },
  {
    "text": "side car application that we call service proxy so service proxy is",
    "start": "1747089",
    "end": "1753159"
  },
  {
    "text": "designed to run on every host on which applications run",
    "start": "1753159",
    "end": "1758639"
  },
  {
    "text": "so in the future we're going to be forklifting our own service proxy out of",
    "start": "1758639",
    "end": "1764919"
  },
  {
    "text": "the design and we're going to swap in linker d-- which does better load balancing and it does request tracing",
    "start": "1764919",
    "end": "1772289"
  },
  {
    "text": "changing out service proxy for linker D should be transparent and just a drop-in replacement for us",
    "start": "1772289",
    "end": "1778889"
  },
  {
    "text": "but nonetheless service proxy rests on a DNA trick",
    "start": "1778889",
    "end": "1784559"
  },
  {
    "text": "whereby when our applications come up and register they assert their name and",
    "start": "1784559",
    "end": "1791669"
  },
  {
    "text": "the IP address at which they currently run they post that to service proxy and",
    "start": "1791669",
    "end": "1797500"
  },
  {
    "text": "service proxy remembers that binding so that when clients come calling for that name service proxy knows where to find",
    "start": "1797500",
    "end": "1804490"
  },
  {
    "text": "it so the big blue box is a physical host this",
    "start": "1804490",
    "end": "1811600"
  },
  {
    "text": "is how we currently run big blue blocks a big blue box as a physical host on every host as a service proxy instance",
    "start": "1811600",
    "end": "1818620"
  },
  {
    "text": "which is an HTTP proxy so on this particular host there's an",
    "start": "1818620",
    "end": "1824500"
  },
  {
    "text": "application foo and bar running so when bar comes up it posts a request to",
    "start": "1824500",
    "end": "1831549"
  },
  {
    "text": "service dot one dot zoom API we've hijacked the top-level domains M",
    "start": "1831549",
    "end": "1837370"
  },
  {
    "text": "API to return one 27001 in response to any question asked on it so service dot",
    "start": "1837370",
    "end": "1845590"
  },
  {
    "text": "one one is the version number service not one gotta zoom API resolves to 127",
    "start": "1845590",
    "end": "1851169"
  },
  {
    "text": "zero zero one which finds bar posting to the local host service proxy with an assertion",
    "start": "1851169",
    "end": "1858309"
  },
  {
    "text": "that my name is bar and my IP address is such-and-such please record me in the",
    "start": "1858309",
    "end": "1864309"
  },
  {
    "text": "system of record as being there when someone comes calling for me so someone is foo foo comes up and it",
    "start": "1864309",
    "end": "1873880"
  },
  {
    "text": "needs to consume bar it forms the URL with bar dot one dot zoom API is the",
    "start": "1873880",
    "end": "1880210"
  },
  {
    "text": "host name part that name also resolves to one 27001",
    "start": "1880210",
    "end": "1886110"
  },
  {
    "text": "service proxy running on the node gets a hold of the request looks at the",
    "start": "1886110",
    "end": "1892659"
  },
  {
    "text": "host header and says this is for bar I know where bar is bar registered a",
    "start": "1892659",
    "end": "1898179"
  },
  {
    "text": "moment ago I will proxy that request and to end on behalf of the caller foo food",
    "start": "1898179",
    "end": "1905620"
  },
  {
    "text": "doesn't know the service proxy is there all it knows is that it got an answer from something going by the name bar dot",
    "start": "1905620",
    "end": "1912820"
  },
  {
    "text": "one dot zoom API barr√© doesn't know service proxy is there either the tricks of DNS service",
    "start": "1912820",
    "end": "1919150"
  },
  {
    "text": "proxy is insinuated into the call path for both of these clients for bar during",
    "start": "1919150",
    "end": "1924940"
  },
  {
    "text": "registration for foo to consume bar so if you want to port this pattern into",
    "start": "1924940",
    "end": "1932560"
  },
  {
    "text": "kubernetes the first thing that comes to mind is I'm going to bundle a service proxy into every application pod",
    "start": "1932560",
    "end": "1940380"
  },
  {
    "text": "because the way that the kubernetes pod networking works is such that",
    "start": "1940380",
    "end": "1948330"
  },
  {
    "text": "containers within a pod can address each other on localhost by port alone",
    "start": "1948330",
    "end": "1955170"
  },
  {
    "text": "so without changing how my DNS returns one 27001 to every question I can move a",
    "start": "1955170",
    "end": "1963220"
  },
  {
    "text": "service proxy into the pod and when foo or bar wants to interact with",
    "start": "1963220",
    "end": "1968980"
  },
  {
    "text": "any name on zoom' api its returned again the answer 127 0 0 1 and lo and behold",
    "start": "1968980",
    "end": "1976420"
  },
  {
    "text": "there's a service proxy in that pod with that application that can be addressed",
    "start": "1976420",
    "end": "1981810"
  },
  {
    "text": "at localhost and the well-known port of service proxy so this does work",
    "start": "1981810",
    "end": "1988950"
  },
  {
    "text": "this works very well it works exactly as it was intended to work with respect to",
    "start": "1988950",
    "end": "1994600"
  },
  {
    "text": "the localhost trick inside of a kubernetes pod we could stop here if we had gobs of",
    "start": "1994600",
    "end": "2000780"
  },
  {
    "text": "memory we could stop here but we always want more we don't have gobs",
    "start": "2000780",
    "end": "2007650"
  },
  {
    "text": "of memory we want to see if we can advance this model to improve it the",
    "start": "2007650",
    "end": "2014310"
  },
  {
    "text": "reason that you don't want this model long-term is because if you have many pods or many applications every",
    "start": "2014310",
    "end": "2021930"
  },
  {
    "text": "application will have many replicas you end up having that number of service proxy instances on your network and for",
    "start": "2021930",
    "end": "2029850"
  },
  {
    "text": "us service proxy is a java application so a java application that has been",
    "start": "2029850",
    "end": "2035640"
  },
  {
    "text": "warmed up in doing production work will typically want hundreds of megabytes of memory to run so you don't want to have",
    "start": "2035640",
    "end": "2042600"
  },
  {
    "text": "to consume hundreds of megabytes per pod on your network",
    "start": "2042600",
    "end": "2047929"
  },
  {
    "text": "so there are a number of ways forward from",
    "start": "2047929",
    "end": "2053429"
  },
  {
    "text": "here to improve this model this is the model that we've come up with and it",
    "start": "2053429",
    "end": "2058560"
  },
  {
    "text": "reads like this it depends on three things the first trick is to pull",
    "start": "2058560",
    "end": "2065669"
  },
  {
    "text": "service proxy out of the pod and run it as a daemon set on each node daemon set",
    "start": "2065669",
    "end": "2072898"
  },
  {
    "text": "with a capital D as a kubernetes thing whereby you can get a pod to run on on a per node basis",
    "start": "2072899",
    "end": "2079370"
  },
  {
    "text": "useful for things that need to run as classic daemons on a host I need one of these things running on every host it's",
    "start": "2079370",
    "end": "2086100"
  },
  {
    "text": "the standard UNIX daemon model so you pull service proxy out of the pod",
    "start": "2086100",
    "end": "2092940"
  },
  {
    "text": "put it on the node run it in the host namespace",
    "start": "2092940",
    "end": "2099470"
  },
  {
    "text": "the second piece of the solution is to run DNS mask as a daemon set also in the",
    "start": "2099470",
    "end": "2108630"
  },
  {
    "text": "host network Dennis mask if you don't know is a lightweight name server",
    "start": "2108630",
    "end": "2114920"
  },
  {
    "text": "we program DNS mask in its entry point which I'll show you in a second to",
    "start": "2114920",
    "end": "2121140"
  },
  {
    "text": "return the node IP as the answer to any question on the domain zoom API so I'm",
    "start": "2121140",
    "end": "2128880"
  },
  {
    "text": "hi I've hijacked the top-level domain again in a slightly different way using DNS mask as a mildly programmable web",
    "start": "2128880",
    "end": "2137100"
  },
  {
    "text": "server or DNS server the third leg is to configure your",
    "start": "2137100",
    "end": "2142920"
  },
  {
    "text": "couplet on every node to deposit the nodes own IP address as a name",
    "start": "2142920",
    "end": "2150900"
  },
  {
    "text": "server inside of each containers are resolved on file so now when the",
    "start": "2150900",
    "end": "2157020"
  },
  {
    "text": "container goes to look up any name it's directed to the node IP",
    "start": "2157020",
    "end": "2163460"
  },
  {
    "text": "which is directed which turns out to be DNS mask running on that node in the",
    "start": "2163460",
    "end": "2170340"
  },
  {
    "text": "hosts network namespace returning the node IP itself in response to any",
    "start": "2170340",
    "end": "2175980"
  },
  {
    "text": "question on zoom' API which you want to interact with a host in that domain",
    "start": "2175980",
    "end": "2181910"
  },
  {
    "text": "sends the request to service proxy running on the node in the hosts network",
    "start": "2181910",
    "end": "2188760"
  },
  {
    "text": "namespace so this is the functional equivalent of",
    "start": "2188760",
    "end": "2193980"
  },
  {
    "text": "locating a service proxy inside of every pot and this works and",
    "start": "2193980",
    "end": "2200119"
  },
  {
    "text": "the advantage of this model over the previous model is that now I have one",
    "start": "2200119",
    "end": "2206250"
  },
  {
    "text": "service proxy instance running on my node rather than one in each pod the downside is is that I have to run",
    "start": "2206250",
    "end": "2213359"
  },
  {
    "text": "DNS mask is a daemon set which is not a big deal DNS mask is not",
    "start": "2213359",
    "end": "2219750"
  },
  {
    "text": "resource-hungry yes",
    "start": "2219750",
    "end": "2223339"
  },
  {
    "text": "say that again I'm sorry",
    "start": "2229059",
    "end": "2232660"
  },
  {
    "text": "DNS mask is a way that I can figure out where the service proxy is running",
    "start": "2239680",
    "end": "2247660"
  },
  {
    "text": "to direct clients to interact with service proxy on the node instead of service",
    "start": "2247660",
    "end": "2254780"
  },
  {
    "text": "proxy on localhost which is what the previous DNS answers were returning in",
    "start": "2254780",
    "end": "2260270"
  },
  {
    "text": "the old world order not better",
    "start": "2260270",
    "end": "2266710"
  },
  {
    "text": "if I make a request for any name inside of one of those pods the name",
    "start": "2269560",
    "end": "2275810"
  },
  {
    "text": "server for that pod is DNS mask running on the node I'll show you the entry point for DNS",
    "start": "2275810",
    "end": "2282740"
  },
  {
    "text": "mask shortly to show you how it discriminates between questions on zoom' API and all other questions but it gets",
    "start": "2282740",
    "end": "2290690"
  },
  {
    "text": "ahold of the name server query request so that it can do the right thing with",
    "start": "2290690",
    "end": "2296300"
  },
  {
    "text": "the request based upon the domain of the request",
    "start": "2296300",
    "end": "2301000"
  },
  {
    "text": "here is the entry point the shell script entry point for DNS mask itself the",
    "start": "2302680",
    "end": "2308240"
  },
  {
    "text": "three dots I have deleted but constitute",
    "start": "2308240",
    "end": "2313340"
  },
  {
    "text": "but consists basically of parsing",
    "start": "2313340",
    "end": "2317740"
  },
  {
    "text": "sorry ah",
    "start": "2320800",
    "end": "2326700"
  },
  {
    "text": "in order to get the note IP address here for DNS mask if you're familiar with DNS",
    "start": "2330920",
    "end": "2336020"
  },
  {
    "text": "mask and how its configured this - - address flag says for any requests on",
    "start": "2336020",
    "end": "2341210"
  },
  {
    "text": "the domain zoom API return the note IP I acquire the note IP just above this line",
    "start": "2341210",
    "end": "2347840"
  },
  {
    "text": "by parsing the output of if config on each 0 that's how I come up with my note IP and because DNS mask is running in",
    "start": "2347840",
    "end": "2356390"
  },
  {
    "text": "the host namespace this is the same IP the service proxy is running on because",
    "start": "2356390",
    "end": "2361940"
  },
  {
    "text": "it - is running in the hosts namespace so there's a github repository that's",
    "start": "2361940",
    "end": "2368060"
  },
  {
    "text": "associated with these slides you can find in the conference proceedings that show how I acquire the note IP but it's",
    "start": "2368060",
    "end": "2374900"
  },
  {
    "text": "basically parse the output of if config I also want to mention briefly that our",
    "start": "2374900",
    "end": "2380900"
  },
  {
    "text": "pod IPS are fully routable there are a lot of different ways that you can",
    "start": "2380900",
    "end": "2386630"
  },
  {
    "text": "arrange for pods to be networked amongst each other but we're using the Calico networks",
    "start": "2386630",
    "end": "2393580"
  },
  {
    "text": "network tooling to make our pod ip's fully routable on the network so that",
    "start": "2393580",
    "end": "2400750"
  },
  {
    "text": "when i address any one of my micro services by IP address that routing",
    "start": "2400750",
    "end": "2407420"
  },
  {
    "text": "doesn't have to traverse encapsulation or NAT or special ingress controllers to",
    "start": "2407420",
    "end": "2413420"
  },
  {
    "text": "make its way to the destination it's fully rounded pod IPS are fully routed on the network so it's not that's not",
    "start": "2413420",
    "end": "2421100"
  },
  {
    "text": "central to how we're doing service discovery but it it certainly helps us",
    "start": "2421100",
    "end": "2426470"
  },
  {
    "text": "to land some micro services inside the cluster keep some outside the cluster on",
    "start": "2426470",
    "end": "2432530"
  },
  {
    "text": "day one and have all of these entities being routable for each other without",
    "start": "2432530",
    "end": "2438770"
  },
  {
    "text": "doing special encapsulation or NAT or ingress controllers",
    "start": "2438770",
    "end": "2445030"
  },
  {
    "text": "so that's how we have ported our legacy service discovery into kubernetes within",
    "start": "2445030",
    "end": "2451010"
  },
  {
    "text": "none of the technology that brandon was originally describing that's for a different use case we'll probably use",
    "start": "2451010",
    "end": "2456080"
  },
  {
    "text": "some of that stuff but not for this purpose so thank you very kindly I think",
    "start": "2456080",
    "end": "2461360"
  },
  {
    "text": "we have time for a couple questions yes",
    "start": "2461360",
    "end": "2466570"
  },
  {
    "text": "sir [Music]",
    "start": "2469900",
    "end": "2475880"
  },
  {
    "text": "the reason we don't use any of the kubernetes native service discovery is because we didn't want to introduce that",
    "start": "2481779",
    "end": "2490309"
  },
  {
    "text": "much change to our existing design the way our services currently find each",
    "start": "2490309",
    "end": "2496369"
  },
  {
    "text": "other we're suffering enough change as it is porting our applications into",
    "start": "2496369",
    "end": "2502039"
  },
  {
    "text": "kubernetes and changing our organization's tooling so we have settled on let's port the existing",
    "start": "2502039",
    "end": "2508099"
  },
  {
    "text": "service discovery mechanism into kubernetes and don't touch the other kubernetes magic service discovery at",
    "start": "2508099",
    "end": "2514490"
  },
  {
    "text": "all",
    "start": "2514490",
    "end": "2516730"
  },
  {
    "text": "yes",
    "start": "2520890",
    "end": "2523489"
  },
  {
    "text": "[Music]",
    "start": "2531770",
    "end": "2534940"
  },
  {
    "text": "nothing",
    "start": "2538440",
    "end": "2541440"
  },
  {
    "text": "three the third piece was the couplet which has been told to deposit the nodes",
    "start": "2546160",
    "end": "2552620"
  },
  {
    "text": "IP address into the resolved comp of every container that's the last piece of",
    "start": "2552620",
    "end": "2557780"
  },
  {
    "text": "glue to direct containers to use DNS mask on the node for their name server",
    "start": "2557780",
    "end": "2563860"
  },
  {
    "text": "so thank you very kindly I love kubernetes the community is super welcoming",
    "start": "2563860",
    "end": "2569290"
  },
  {
    "text": "imminently competent and I learned something every day I deal with these folks thank you so much",
    "start": "2569290",
    "end": "2576360"
  },
  {
    "text": "[Applause]",
    "start": "2576360",
    "end": "2581729"
  }
]
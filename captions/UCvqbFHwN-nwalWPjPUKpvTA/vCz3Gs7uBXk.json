[
  {
    "text": "all right awesome cool hi everyone today",
    "start": "719",
    "end": "3520"
  },
  {
    "text": "we're going to be talking about applying",
    "start": "3520",
    "end": "5120"
  },
  {
    "text": "observability to machine learning so",
    "start": "5120",
    "end": "7359"
  },
  {
    "text": "figuring out how you can use",
    "start": "7359",
    "end": "8480"
  },
  {
    "text": "observability to debug your machine",
    "start": "8480",
    "end": "10400"
  },
  {
    "text": "learning models that are deployed on the",
    "start": "10400",
    "end": "12080"
  },
  {
    "text": "edge",
    "start": "12080",
    "end": "13920"
  },
  {
    "text": "so first just as an introduction natalie",
    "start": "13920",
    "end": "16800"
  },
  {
    "text": "and i",
    "start": "16800",
    "end": "18080"
  },
  {
    "text": "we are principal engineers at new relic",
    "start": "18080",
    "end": "20640"
  },
  {
    "text": "and we work primarily on pixi which is",
    "start": "20640",
    "end": "23279"
  },
  {
    "text": "an open source cncf sandbox project for",
    "start": "23279",
    "end": "26640"
  },
  {
    "text": "kubernetes observability and you'll",
    "start": "26640",
    "end": "28640"
  },
  {
    "text": "learn a little bit more about pixi later",
    "start": "28640",
    "end": "30560"
  },
  {
    "text": "on in our talk",
    "start": "30560",
    "end": "33679"
  },
  {
    "text": "so why is this important we see today",
    "start": "35360",
    "end": "37520"
  },
  {
    "text": "that a bunch of products and software",
    "start": "37520",
    "end": "39920"
  },
  {
    "text": "are moving their ml to the edge so for",
    "start": "39920",
    "end": "42719"
  },
  {
    "text": "example here you see with cruz the",
    "start": "42719",
    "end": "44559"
  },
  {
    "text": "self-driving car it's collecting a bunch",
    "start": "44559",
    "end": "46480"
  },
  {
    "text": "of information using its sensors cameras",
    "start": "46480",
    "end": "49280"
  },
  {
    "text": "to figure out you know am i driving in",
    "start": "49280",
    "end": "51120"
  },
  {
    "text": "the lane correctly",
    "start": "51120",
    "end": "52800"
  },
  {
    "text": "am i about to hit something an obstacle",
    "start": "52800",
    "end": "55199"
  },
  {
    "text": "and it collects all that information and",
    "start": "55199",
    "end": "57199"
  },
  {
    "text": "does it locally so it stores it locally",
    "start": "57199",
    "end": "59359"
  },
  {
    "text": "and then runs some inference on it to",
    "start": "59359",
    "end": "61039"
  },
  {
    "text": "figure out what action it should do next",
    "start": "61039",
    "end": "63359"
  },
  {
    "text": "and then similarly you know you have the",
    "start": "63359",
    "end": "65198"
  },
  {
    "text": "amazon echo and that does the same thing",
    "start": "65199",
    "end": "67520"
  },
  {
    "text": "it collects input from the environment",
    "start": "67520",
    "end": "69760"
  },
  {
    "text": "you know what whatever you're saying at",
    "start": "69760",
    "end": "71200"
  },
  {
    "text": "the time in your home and tries to",
    "start": "71200",
    "end": "72799"
  },
  {
    "text": "figure out should i do something with",
    "start": "72799",
    "end": "74479"
  },
  {
    "text": "this information",
    "start": "74479",
    "end": "77200"
  },
  {
    "text": "and what does this exactly look like",
    "start": "78400",
    "end": "80000"
  },
  {
    "text": "right so the traditional model that you",
    "start": "80000",
    "end": "81840"
  },
  {
    "text": "see on your left before a lot of how",
    "start": "81840",
    "end": "84560"
  },
  {
    "text": "things were being done was all these",
    "start": "84560",
    "end": "86159"
  },
  {
    "text": "sensors were collecting information and",
    "start": "86159",
    "end": "87920"
  },
  {
    "text": "then in order to make an inference on it",
    "start": "87920",
    "end": "89759"
  },
  {
    "text": "it will send it off to some cloud this",
    "start": "89759",
    "end": "91680"
  },
  {
    "text": "model is running in the cloud it",
    "start": "91680",
    "end": "93360"
  },
  {
    "text": "receives that information and then sends",
    "start": "93360",
    "end": "95040"
  },
  {
    "text": "back okay here's what you should do with",
    "start": "95040",
    "end": "96479"
  },
  {
    "text": "this",
    "start": "96479",
    "end": "97280"
  },
  {
    "text": "and then now as things are moving",
    "start": "97280",
    "end": "98479"
  },
  {
    "text": "towards the edge you're seeing a lot",
    "start": "98479",
    "end": "100079"
  },
  {
    "text": "more of this sensor is collecting this",
    "start": "100079",
    "end": "101920"
  },
  {
    "text": "information it's storing it potentially",
    "start": "101920",
    "end": "104079"
  },
  {
    "text": "in memory and then it runs the model",
    "start": "104079",
    "end": "105920"
  },
  {
    "text": "directly on the device itself",
    "start": "105920",
    "end": "109600"
  },
  {
    "text": "tell me to flip for you",
    "start": "109600",
    "end": "112399"
  },
  {
    "text": "so there's a lot of benefits to this",
    "start": "112399",
    "end": "113759"
  },
  {
    "text": "right you can see immediately here from",
    "start": "113759",
    "end": "115119"
  },
  {
    "text": "this picture you get a lot less network",
    "start": "115119",
    "end": "117600"
  },
  {
    "text": "bandwidth and egress especially if your",
    "start": "117600",
    "end": "119040"
  },
  {
    "text": "sensor is collecting tons of information",
    "start": "119040",
    "end": "121439"
  },
  {
    "text": "now you're not sending out to some other",
    "start": "121439",
    "end": "122880"
  },
  {
    "text": "cloud that you potentially don't even",
    "start": "122880",
    "end": "124560"
  },
  {
    "text": "own and so that's really nice because",
    "start": "124560",
    "end": "126320"
  },
  {
    "text": "you get the data and you can immediately",
    "start": "126320",
    "end": "128160"
  },
  {
    "text": "start processing running your models on",
    "start": "128160",
    "end": "130080"
  },
  {
    "text": "it",
    "start": "130080",
    "end": "130879"
  },
  {
    "text": "and then second of all the nice thing",
    "start": "130879",
    "end": "132879"
  },
  {
    "text": "about it is you get some really good",
    "start": "132879",
    "end": "134480"
  },
  {
    "text": "security privacy benefits right so think",
    "start": "134480",
    "end": "136400"
  },
  {
    "text": "about the amazon echo case your echo",
    "start": "136400",
    "end": "138640"
  },
  {
    "text": "sitting on your",
    "start": "138640",
    "end": "139680"
  },
  {
    "text": "your counter",
    "start": "139680",
    "end": "140959"
  },
  {
    "text": "and it feels a little bit weird to be",
    "start": "140959",
    "end": "143120"
  },
  {
    "text": "like oh it's listening to me and like",
    "start": "143120",
    "end": "144720"
  },
  {
    "text": "sending all like whatever i'm saying all",
    "start": "144720",
    "end": "146640"
  },
  {
    "text": "the way directly to amazon right it's",
    "start": "146640",
    "end": "148239"
  },
  {
    "text": "nice to think about like okay it's",
    "start": "148239",
    "end": "149760"
  },
  {
    "text": "actually doing edge compute whatever i'm",
    "start": "149760",
    "end": "151760"
  },
  {
    "text": "saying it's storing it locally it's",
    "start": "151760",
    "end": "153120"
  },
  {
    "text": "probably expiring it out after some",
    "start": "153120",
    "end": "154800"
  },
  {
    "text": "point because that's a ton of data that",
    "start": "154800",
    "end": "156160"
  },
  {
    "text": "it's collecting and all of it is just",
    "start": "156160",
    "end": "158000"
  },
  {
    "text": "stored within the edge device itself",
    "start": "158000",
    "end": "160319"
  },
  {
    "text": "and then finally there's scalability so",
    "start": "160319",
    "end": "163040"
  },
  {
    "text": "before if you have millions of connected",
    "start": "163040",
    "end": "165440"
  },
  {
    "text": "devices and all these are streaming",
    "start": "165440",
    "end": "167200"
  },
  {
    "text": "their data to your cloud you're going to",
    "start": "167200",
    "end": "168879"
  },
  {
    "text": "have to be able to handle",
    "start": "168879",
    "end": "170480"
  },
  {
    "text": "all this input from a bunch of these",
    "start": "170480",
    "end": "171840"
  },
  {
    "text": "different devices but now all these",
    "start": "171840",
    "end": "173680"
  },
  {
    "text": "models are running individually on the",
    "start": "173680",
    "end": "175760"
  },
  {
    "text": "device itself and so they're just",
    "start": "175760",
    "end": "177519"
  },
  {
    "text": "responsible for dealing with their own",
    "start": "177519",
    "end": "179200"
  },
  {
    "text": "set of inferences",
    "start": "179200",
    "end": "182080"
  },
  {
    "text": "so how does this actually look like how",
    "start": "183760",
    "end": "185280"
  },
  {
    "text": "do you start go to go and deploy your",
    "start": "185280",
    "end": "187680"
  },
  {
    "text": "models to your edge devices and how it",
    "start": "187680",
    "end": "190239"
  },
  {
    "text": "usually happens is that the first part",
    "start": "190239",
    "end": "192319"
  },
  {
    "text": "is pretty much the same right you need",
    "start": "192319",
    "end": "193519"
  },
  {
    "text": "to go and you train your model you have",
    "start": "193519",
    "end": "195360"
  },
  {
    "text": "a bunch of training data you go and you",
    "start": "195360",
    "end": "197200"
  },
  {
    "text": "make sure you tune all your parameters",
    "start": "197200",
    "end": "199360"
  },
  {
    "text": "and make sure your accuracy is correct",
    "start": "199360",
    "end": "200800"
  },
  {
    "text": "like you have an image classification",
    "start": "200800",
    "end": "202400"
  },
  {
    "text": "you're trying to classify what kind of",
    "start": "202400",
    "end": "204080"
  },
  {
    "text": "dog breed is this you train this in the",
    "start": "204080",
    "end": "206159"
  },
  {
    "text": "cloud and you ensure it's like okay any",
    "start": "206159",
    "end": "208319"
  },
  {
    "text": "input i give it it looks about you know",
    "start": "208319",
    "end": "210319"
  },
  {
    "text": "about right and then you go and you can",
    "start": "210319",
    "end": "212319"
  },
  {
    "text": "deploy these to all these different edge",
    "start": "212319",
    "end": "214080"
  },
  {
    "text": "devices so i",
    "start": "214080",
    "end": "216000"
  },
  {
    "text": "wanted to make it very clear that all",
    "start": "216000",
    "end": "217920"
  },
  {
    "text": "these are just like potentially",
    "start": "217920",
    "end": "219040"
  },
  {
    "text": "different hardwares environments so i",
    "start": "219040",
    "end": "220799"
  },
  {
    "text": "just made these boxes of the edge",
    "start": "220799",
    "end": "222480"
  },
  {
    "text": "devices different colors because you",
    "start": "222480",
    "end": "224159"
  },
  {
    "text": "know one could be an iphone one could be",
    "start": "224159",
    "end": "227120"
  },
  {
    "text": "an android device so it's just like very",
    "start": "227120",
    "end": "229200"
  },
  {
    "text": "clear that these models are now going to",
    "start": "229200",
    "end": "231599"
  },
  {
    "text": "a very different set of environments",
    "start": "231599",
    "end": "235519"
  },
  {
    "text": "and what actually can happen here what",
    "start": "235760",
    "end": "237439"
  },
  {
    "text": "could go wrong right it works perfectly",
    "start": "237439",
    "end": "239280"
  },
  {
    "text": "in the cloud and keep in mind that your",
    "start": "239280",
    "end": "241599"
  },
  {
    "text": "cloud it's running it has as many",
    "start": "241599",
    "end": "243840"
  },
  {
    "text": "resources as you want to give it right",
    "start": "243840",
    "end": "245280"
  },
  {
    "text": "you can give it as much memory you want",
    "start": "245280",
    "end": "246799"
  },
  {
    "text": "you give it as much",
    "start": "246799",
    "end": "248720"
  },
  {
    "text": "cpu that you want and as long as you're",
    "start": "248720",
    "end": "251040"
  },
  {
    "text": "willing to pay but then now you're going",
    "start": "251040",
    "end": "252640"
  },
  {
    "text": "to these edge devices and like i",
    "start": "252640",
    "end": "254400"
  },
  {
    "text": "mentioned before you have phones but you",
    "start": "254400",
    "end": "255680"
  },
  {
    "text": "might be deploying to just like you know",
    "start": "255680",
    "end": "257600"
  },
  {
    "text": "some little thing running a sensor or",
    "start": "257600",
    "end": "259359"
  },
  {
    "text": "something and you're going to be limited",
    "start": "259359",
    "end": "261120"
  },
  {
    "text": "by your resource requirements your uh",
    "start": "261120",
    "end": "263280"
  },
  {
    "text": "your memory requirements so a bunch of",
    "start": "263280",
    "end": "265120"
  },
  {
    "text": "things could go wrong so the first case",
    "start": "265120",
    "end": "266800"
  },
  {
    "text": "up on top is you've deployed to your",
    "start": "266800",
    "end": "268880"
  },
  {
    "text": "edge device and then",
    "start": "268880",
    "end": "270880"
  },
  {
    "text": "you know things seem to run",
    "start": "270880",
    "end": "272720"
  },
  {
    "text": "but then you get the completely wrong",
    "start": "272720",
    "end": "274240"
  },
  {
    "text": "results you're noticing a huge drop in",
    "start": "274240",
    "end": "276320"
  },
  {
    "text": "accuracy so before maybe when you had 80",
    "start": "276320",
    "end": "279440"
  },
  {
    "text": "90 accuracy you're seeing that your",
    "start": "279440",
    "end": "281600"
  },
  {
    "text": "model that's been deployed somewhere",
    "start": "281600",
    "end": "283040"
  },
  {
    "text": "else is giving you like maybe even 30",
    "start": "283040",
    "end": "285440"
  },
  {
    "text": "accuracy and the second case where",
    "start": "285440",
    "end": "287440"
  },
  {
    "text": "something could go wrong",
    "start": "287440",
    "end": "288960"
  },
  {
    "text": "is your model seems to run fine it's",
    "start": "288960",
    "end": "291199"
  },
  {
    "text": "giving you the right inferences",
    "start": "291199",
    "end": "293199"
  },
  {
    "text": "but it's taking a really really long",
    "start": "293199",
    "end": "295040"
  },
  {
    "text": "time and so it's like okay it used to",
    "start": "295040",
    "end": "298639"
  },
  {
    "text": "work no it doesn't what can i do to go",
    "start": "298639",
    "end": "300800"
  },
  {
    "text": "and debug this and i think a lot of the",
    "start": "300800",
    "end": "302800"
  },
  {
    "text": "things that we turn to i'm sure many",
    "start": "302800",
    "end": "305280"
  },
  {
    "text": "people here are familiar with are like i",
    "start": "305280",
    "end": "306960"
  },
  {
    "text": "need to figure out how to solve this",
    "start": "306960",
    "end": "308479"
  },
  {
    "text": "problem i'm gonna go and just like put a",
    "start": "308479",
    "end": "310400"
  },
  {
    "text": "bunch of print statements and just",
    "start": "310400",
    "end": "311919"
  },
  {
    "text": "figure out where exactly in this",
    "start": "311919",
    "end": "313759"
  },
  {
    "text": "pipeline are things going wrong and",
    "start": "313759",
    "end": "315840"
  },
  {
    "text": "obviously that's a very tedious problem",
    "start": "315840",
    "end": "317440"
  },
  {
    "text": "because there's especially in a like a",
    "start": "317440",
    "end": "319280"
  },
  {
    "text": "deep learning model there's a lot of",
    "start": "319280",
    "end": "320720"
  },
  {
    "text": "stuff going on in there right you",
    "start": "320720",
    "end": "323039"
  },
  {
    "text": "you're going to like print a bunch of",
    "start": "323039",
    "end": "324080"
  },
  {
    "text": "things you have to make sense of all",
    "start": "324080",
    "end": "325360"
  },
  {
    "text": "that information",
    "start": "325360",
    "end": "326960"
  },
  {
    "text": "and that is where ml x-ray comes in",
    "start": "326960",
    "end": "330080"
  },
  {
    "text": "so ml x-ray is a project that came out",
    "start": "330080",
    "end": "332400"
  },
  {
    "text": "of a stanford research project so huge",
    "start": "332400",
    "end": "335440"
  },
  {
    "text": "credits goes to all these people that",
    "start": "335440",
    "end": "336960"
  },
  {
    "text": "i've listed on the bottom who came up",
    "start": "336960",
    "end": "338800"
  },
  {
    "text": "with the original idea for mlx rate and",
    "start": "338800",
    "end": "340720"
  },
  {
    "text": "all the great work that they've done so",
    "start": "340720",
    "end": "342080"
  },
  {
    "text": "far on it",
    "start": "342080",
    "end": "343199"
  },
  {
    "text": "and essentially what ml x-ray is is that",
    "start": "343199",
    "end": "345600"
  },
  {
    "text": "it's an end-to-end framework for",
    "start": "345600",
    "end": "347680"
  },
  {
    "text": "debugging your cloud-to-edge deployment",
    "start": "347680",
    "end": "350560"
  },
  {
    "text": "and let's dive a little bit into more",
    "start": "350560",
    "end": "352639"
  },
  {
    "text": "about what that actually means",
    "start": "352639",
    "end": "355840"
  },
  {
    "text": "so first mlrxa gives you this api and",
    "start": "355840",
    "end": "359120"
  },
  {
    "text": "you basically invoke that api and it",
    "start": "359120",
    "end": "360960"
  },
  {
    "text": "starts collecting a ton of information",
    "start": "360960",
    "end": "362639"
  },
  {
    "text": "for you as you run your model so up on",
    "start": "362639",
    "end": "365199"
  },
  {
    "text": "top we have an example of the python api",
    "start": "365199",
    "end": "367759"
  },
  {
    "text": "you start the",
    "start": "367759",
    "end": "369600"
  },
  {
    "text": "uh the inference you stop the inference",
    "start": "369600",
    "end": "372160"
  },
  {
    "text": "using the mlx ray api",
    "start": "372160",
    "end": "374560"
  },
  {
    "text": "and during each part",
    "start": "374560",
    "end": "376319"
  },
  {
    "text": "in your",
    "start": "376319",
    "end": "377600"
  },
  {
    "text": "model pipeline it just records tons of",
    "start": "377600",
    "end": "380000"
  },
  {
    "text": "information so it's like the",
    "start": "380000",
    "end": "381199"
  },
  {
    "text": "pre-processing step the individual",
    "start": "381199",
    "end": "383039"
  },
  {
    "text": "layers down to the final output that it",
    "start": "383039",
    "end": "385360"
  },
  {
    "text": "gets in the end so you don't have to go",
    "start": "385360",
    "end": "387199"
  },
  {
    "text": "in and actually add you know whatever",
    "start": "387199",
    "end": "389360"
  },
  {
    "text": "logging that you yourself want",
    "start": "389360",
    "end": "392800"
  },
  {
    "text": "so what kind of information does it get",
    "start": "393440",
    "end": "395039"
  },
  {
    "text": "it really gets a bunch of things so just",
    "start": "395039",
    "end": "396880"
  },
  {
    "text": "like a bunch of baseline debug data so",
    "start": "396880",
    "end": "399199"
  },
  {
    "text": "like what are the inputs and outputs of",
    "start": "399199",
    "end": "401360"
  },
  {
    "text": "your model and then for each individual",
    "start": "401360",
    "end": "403440"
  },
  {
    "text": "layer inside your model pipeline it also",
    "start": "403440",
    "end": "405440"
  },
  {
    "text": "gets the input and output of that",
    "start": "405440",
    "end": "407360"
  },
  {
    "text": "and you know for the case where it's",
    "start": "407360",
    "end": "409440"
  },
  {
    "text": "like things start running very slowly it",
    "start": "409440",
    "end": "410880"
  },
  {
    "text": "will track your end to end latency for",
    "start": "410880",
    "end": "413120"
  },
  {
    "text": "running the entire inference but also in",
    "start": "413120",
    "end": "414800"
  },
  {
    "text": "between each layer itself and just",
    "start": "414800",
    "end": "417120"
  },
  {
    "text": "resource information so it's like what",
    "start": "417120",
    "end": "418560"
  },
  {
    "text": "was the memory when my model was running",
    "start": "418560",
    "end": "420639"
  },
  {
    "text": "and for devices like android it also",
    "start": "420639",
    "end": "422560"
  },
  {
    "text": "collects just other sensor information",
    "start": "422560",
    "end": "424880"
  },
  {
    "text": "so it's like your android knows what how",
    "start": "424880",
    "end": "426880"
  },
  {
    "text": "it's rotated what the lighting",
    "start": "426880",
    "end": "428319"
  },
  {
    "text": "conditions are like and that just helps",
    "start": "428319",
    "end": "430080"
  },
  {
    "text": "give more context to just how the model",
    "start": "430080",
    "end": "432319"
  },
  {
    "text": "is running",
    "start": "432319",
    "end": "434000"
  },
  {
    "text": "on your device",
    "start": "434000",
    "end": "435599"
  },
  {
    "text": "and you can go ahead and use the mlx",
    "start": "435599",
    "end": "437840"
  },
  {
    "text": "rate api to just add whatever other",
    "start": "437840",
    "end": "439840"
  },
  {
    "text": "fields you might want to log so more",
    "start": "439840",
    "end": "441759"
  },
  {
    "text": "information that you might want to",
    "start": "441759",
    "end": "442720"
  },
  {
    "text": "collect that are specific to your model",
    "start": "442720",
    "end": "444479"
  },
  {
    "text": "itself",
    "start": "444479",
    "end": "446800"
  },
  {
    "text": "but now you have this all this data",
    "start": "447199",
    "end": "448800"
  },
  {
    "text": "coming in right so you're like all right",
    "start": "448800",
    "end": "450000"
  },
  {
    "text": "cool i've instrumented my stuff",
    "start": "450000",
    "end": "452080"
  },
  {
    "text": "but what do you do with it right now",
    "start": "452080",
    "end": "453759"
  },
  {
    "text": "you're like okay i know it takes this",
    "start": "453759",
    "end": "455280"
  },
  {
    "text": "long i know that at this point my output",
    "start": "455280",
    "end": "457759"
  },
  {
    "text": "looks like this",
    "start": "457759",
    "end": "459520"
  },
  {
    "text": "what am i supposed to do now and so the",
    "start": "459520",
    "end": "461759"
  },
  {
    "text": "idea behind ml x-ray is that you compare",
    "start": "461759",
    "end": "464319"
  },
  {
    "text": "this to a reference pipeline so you have",
    "start": "464319",
    "end": "467440"
  },
  {
    "text": "your model that you've trained in the",
    "start": "467440",
    "end": "468960"
  },
  {
    "text": "cloud you know this is your like",
    "start": "468960",
    "end": "470400"
  },
  {
    "text": "baseline model this thing runs the best",
    "start": "470400",
    "end": "472560"
  },
  {
    "text": "that you can imagine the best accuracy",
    "start": "472560",
    "end": "474720"
  },
  {
    "text": "that you can get it runs at the speed",
    "start": "474720",
    "end": "476319"
  },
  {
    "text": "that you want and so what you do here is",
    "start": "476319",
    "end": "478720"
  },
  {
    "text": "you collect logs from that baseline",
    "start": "478720",
    "end": "480479"
  },
  {
    "text": "model and then you have the you know the",
    "start": "480479",
    "end": "482960"
  },
  {
    "text": "one that you've deployed to your edge",
    "start": "482960",
    "end": "484240"
  },
  {
    "text": "device you collect the logs from that",
    "start": "484240",
    "end": "485680"
  },
  {
    "text": "one and essentially you combine them",
    "start": "485680",
    "end": "487919"
  },
  {
    "text": "together to figure out you know what are",
    "start": "487919",
    "end": "489199"
  },
  {
    "text": "the differences here and that's what we",
    "start": "489199",
    "end": "490800"
  },
  {
    "text": "call a debug report so you compare the",
    "start": "490800",
    "end": "493120"
  },
  {
    "text": "differences and try to figure out where",
    "start": "493120",
    "end": "494720"
  },
  {
    "text": "exactly in my model are things going",
    "start": "494720",
    "end": "496879"
  },
  {
    "text": "wrong",
    "start": "496879",
    "end": "499120"
  },
  {
    "text": "and what does this flow kind of look",
    "start": "499440",
    "end": "500960"
  },
  {
    "text": "like when you're debugging so the first",
    "start": "500960",
    "end": "502639"
  },
  {
    "text": "is in accuracy validation is the model",
    "start": "502639",
    "end": "505360"
  },
  {
    "text": "that's deployed on your edge device is",
    "start": "505360",
    "end": "507039"
  },
  {
    "text": "it doing as well as the cloud model that",
    "start": "507039",
    "end": "509520"
  },
  {
    "text": "you originally trained",
    "start": "509520",
    "end": "510960"
  },
  {
    "text": "and so if it is that's great maybe you",
    "start": "510960",
    "end": "513440"
  },
  {
    "text": "know they have comparable performance",
    "start": "513440",
    "end": "514959"
  },
  {
    "text": "and you're you're done it's like all",
    "start": "514959",
    "end": "516399"
  },
  {
    "text": "right great i've deployed to this",
    "start": "516399",
    "end": "517680"
  },
  {
    "text": "android i'm good everything looks good i",
    "start": "517680",
    "end": "519760"
  },
  {
    "text": "can move on to you know whatever the",
    "start": "519760",
    "end": "520959"
  },
  {
    "text": "next device device i want to deploy to",
    "start": "520959",
    "end": "523599"
  },
  {
    "text": "but a lot of the times it's gonna be",
    "start": "523599",
    "end": "524959"
  },
  {
    "text": "like okay no my accuracy has dropped a",
    "start": "524959",
    "end": "527519"
  },
  {
    "text": "lot and so that's when you look into the",
    "start": "527519",
    "end": "530880"
  },
  {
    "text": "accuracy or the output between each",
    "start": "530880",
    "end": "532880"
  },
  {
    "text": "layer and what you might see here is",
    "start": "532880",
    "end": "534560"
  },
  {
    "text": "like oh okay this particular layer the",
    "start": "534560",
    "end": "537200"
  },
  {
    "text": "output is very very different from the",
    "start": "537200",
    "end": "539040"
  },
  {
    "text": "output that i was getting in my",
    "start": "539040",
    "end": "542160"
  },
  {
    "text": "in my baseline reference model and so",
    "start": "542160",
    "end": "544240"
  },
  {
    "text": "then there you can go and look into okay",
    "start": "544240",
    "end": "545760"
  },
  {
    "text": "my maybe i have some pre-processing",
    "start": "545760",
    "end": "547519"
  },
  {
    "text": "issues maybe there's something wrong",
    "start": "547519",
    "end": "548959"
  },
  {
    "text": "with the weights and biases in this",
    "start": "548959",
    "end": "550560"
  },
  {
    "text": "model when you know when you try to",
    "start": "550560",
    "end": "552320"
  },
  {
    "text": "quantize it so that it runs better on an",
    "start": "552320",
    "end": "554320"
  },
  {
    "text": "edge device so that gives you indication",
    "start": "554320",
    "end": "556320"
  },
  {
    "text": "about just which layer you should",
    "start": "556320",
    "end": "557680"
  },
  {
    "text": "actually look into",
    "start": "557680",
    "end": "559200"
  },
  {
    "text": "and then finally mlx ray has this thing",
    "start": "559200",
    "end": "561200"
  },
  {
    "text": "called custom search or custom assertion",
    "start": "561200",
    "end": "563680"
  },
  {
    "text": "checks and so what actually happens",
    "start": "563680",
    "end": "565600"
  },
  {
    "text": "there is that you can tell mlx-ray as",
    "start": "565600",
    "end": "567600"
  },
  {
    "text": "you're running through my model and",
    "start": "567600",
    "end": "568640"
  },
  {
    "text": "collecting all these logs just run some",
    "start": "568640",
    "end": "570480"
  },
  {
    "text": "assertions that i know like always need",
    "start": "570480",
    "end": "572320"
  },
  {
    "text": "to be the case so that if it fails i",
    "start": "572320",
    "end": "574720"
  },
  {
    "text": "know there's already something in my",
    "start": "574720",
    "end": "576720"
  },
  {
    "text": "pipeline that is wrong and so an example",
    "start": "576720",
    "end": "578640"
  },
  {
    "text": "of this is going back to the lane",
    "start": "578640",
    "end": "580480"
  },
  {
    "text": "detection case like you know that",
    "start": "580480",
    "end": "582800"
  },
  {
    "text": "when it detects a lane in a picture it",
    "start": "582800",
    "end": "585120"
  },
  {
    "text": "has to be this wide for example and so",
    "start": "585120",
    "end": "587360"
  },
  {
    "text": "you can add an assertion to be like",
    "start": "587360",
    "end": "588880"
  },
  {
    "text": "whenever you detect a lane always make",
    "start": "588880",
    "end": "591040"
  },
  {
    "text": "sure it's this width and then if it",
    "start": "591040",
    "end": "592720"
  },
  {
    "text": "isn't then it will trigger a failure and",
    "start": "592720",
    "end": "594959"
  },
  {
    "text": "can be like okay so there's something",
    "start": "594959",
    "end": "596399"
  },
  {
    "text": "wrong potentially here",
    "start": "596399",
    "end": "599360"
  },
  {
    "text": "and so how natalie i kind of got",
    "start": "600640",
    "end": "602320"
  },
  {
    "text": "involved in mlx right so all the work i",
    "start": "602320",
    "end": "604240"
  },
  {
    "text": "just presented before was work that was",
    "start": "604240",
    "end": "606240"
  },
  {
    "text": "done by those people i mentioned at the",
    "start": "606240",
    "end": "607680"
  },
  {
    "text": "stanford research group was that we got",
    "start": "607680",
    "end": "610320"
  },
  {
    "text": "in contact with these people and we",
    "start": "610320",
    "end": "611600"
  },
  {
    "text": "found there's a lot of limitations with",
    "start": "611600",
    "end": "613120"
  },
  {
    "text": "mlx ray that pixie which we'll talk",
    "start": "613120",
    "end": "615440"
  },
  {
    "text": "about about in a little bit could",
    "start": "615440",
    "end": "616880"
  },
  {
    "text": "potentially solve so the first is you",
    "start": "616880",
    "end": "618880"
  },
  {
    "text": "have to make code changes to enable this",
    "start": "618880",
    "end": "620560"
  },
  {
    "text": "instrumentation it's not a lot of code",
    "start": "620560",
    "end": "622640"
  },
  {
    "text": "right you go and you start your",
    "start": "622640",
    "end": "623920"
  },
  {
    "text": "inference you stop your inference you",
    "start": "623920",
    "end": "625440"
  },
  {
    "text": "invoke the mlx ray logging and it's not",
    "start": "625440",
    "end": "628240"
  },
  {
    "text": "that bad but it can be cumbersome so",
    "start": "628240",
    "end": "630160"
  },
  {
    "text": "it's like you have to remember to go and",
    "start": "630160",
    "end": "631360"
  },
  {
    "text": "add that in",
    "start": "631360",
    "end": "632480"
  },
  {
    "text": "you have to remember to take it out",
    "start": "632480",
    "end": "633839"
  },
  {
    "text": "because you know whenever you're ready",
    "start": "633839",
    "end": "635440"
  },
  {
    "text": "to finally deploy to prod you don't want",
    "start": "635440",
    "end": "637360"
  },
  {
    "text": "to keep just logging all this",
    "start": "637360",
    "end": "638640"
  },
  {
    "text": "information all of the time",
    "start": "638640",
    "end": "640560"
  },
  {
    "text": "and it has a slight performance impact",
    "start": "640560",
    "end": "642160"
  },
  {
    "text": "sometimes as well plus memory because",
    "start": "642160",
    "end": "643760"
  },
  {
    "text": "now you're keeping all this data in a",
    "start": "643760",
    "end": "646480"
  },
  {
    "text": "log stored on your device so you can",
    "start": "646480",
    "end": "648160"
  },
  {
    "text": "pull it out later to analyze it",
    "start": "648160",
    "end": "650480"
  },
  {
    "text": "and the third thing which i didn't show",
    "start": "650480",
    "end": "652399"
  },
  {
    "text": "as much but there's just not a lot of",
    "start": "652399",
    "end": "654560"
  },
  {
    "text": "ways to visualize this data so mlx rate",
    "start": "654560",
    "end": "656959"
  },
  {
    "text": "it gives you an api for collecting the",
    "start": "656959",
    "end": "658480"
  },
  {
    "text": "data and parsing it and it gives you",
    "start": "658480",
    "end": "660399"
  },
  {
    "text": "some simple operations so it's like okay",
    "start": "660399",
    "end": "662000"
  },
  {
    "text": "i can plot these two different like",
    "start": "662000",
    "end": "664480"
  },
  {
    "text": "layer accuracies against each other but",
    "start": "664480",
    "end": "666560"
  },
  {
    "text": "there's no way to actually go and like",
    "start": "666560",
    "end": "668320"
  },
  {
    "text": "play around with this data and try",
    "start": "668320",
    "end": "670320"
  },
  {
    "text": "exploring different correlations and so",
    "start": "670320",
    "end": "672160"
  },
  {
    "text": "then that's where pixi comes in so i",
    "start": "672160",
    "end": "674240"
  },
  {
    "text": "will hand that over to natalie to",
    "start": "674240",
    "end": "676160"
  },
  {
    "text": "explain what that's about",
    "start": "676160",
    "end": "678880"
  },
  {
    "text": "all right thanks michelle so as michelle",
    "start": "678880",
    "end": "681279"
  },
  {
    "text": "said uh you know as contributors to the",
    "start": "681279",
    "end": "683279"
  },
  {
    "text": "pixie project we were really inspired",
    "start": "683279",
    "end": "685519"
  },
  {
    "text": "when we saw what mlxray could do and",
    "start": "685519",
    "end": "688079"
  },
  {
    "text": "what we wanted to do is try to take some",
    "start": "688079",
    "end": "691040"
  },
  {
    "text": "of its concepts and see how we could use",
    "start": "691040",
    "end": "694320"
  },
  {
    "text": "pixi which is an observability platform",
    "start": "694320",
    "end": "697120"
  },
  {
    "text": "for kubernetes to apply some of these",
    "start": "697120",
    "end": "699440"
  },
  {
    "text": "concepts",
    "start": "699440",
    "end": "700720"
  },
  {
    "text": "in a kubernetes native environment",
    "start": "700720",
    "end": "702959"
  },
  {
    "text": "so just a little bit about pixie before",
    "start": "702959",
    "end": "705279"
  },
  {
    "text": "we jump into the demo",
    "start": "705279",
    "end": "707519"
  },
  {
    "text": "pixi provides autotelemetry to your",
    "start": "707519",
    "end": "709600"
  },
  {
    "text": "kubernetes cluster using ebpf so it can",
    "start": "709600",
    "end": "712880"
  },
  {
    "text": "automatically collect a lot of app data",
    "start": "712880",
    "end": "714639"
  },
  {
    "text": "from your application without any code",
    "start": "714639",
    "end": "716399"
  },
  {
    "text": "changes",
    "start": "716399",
    "end": "718240"
  },
  {
    "text": "pixi runs on the edge which makes it a",
    "start": "718240",
    "end": "720240"
  },
  {
    "text": "good uh you know off option for",
    "start": "720240",
    "end": "723360"
  },
  {
    "text": "edge-based",
    "start": "723360",
    "end": "725200"
  },
  {
    "text": "deployments because the compute and the",
    "start": "725200",
    "end": "727600"
  },
  {
    "text": "data collection and all that stuff",
    "start": "727600",
    "end": "729279"
  },
  {
    "text": "actually lives on the node on which it's",
    "start": "729279",
    "end": "731600"
  },
  {
    "text": "collected",
    "start": "731600",
    "end": "732880"
  },
  {
    "text": "and then finally pixi has a very",
    "start": "732880",
    "end": "735519"
  },
  {
    "text": "customizable scriptable interface so",
    "start": "735519",
    "end": "737680"
  },
  {
    "text": "that allows us to build custom",
    "start": "737680",
    "end": "739680"
  },
  {
    "text": "dashboards for specific use cases that",
    "start": "739680",
    "end": "741839"
  },
  {
    "text": "we have",
    "start": "741839",
    "end": "743040"
  },
  {
    "text": "and as she said before pixi is a cncf",
    "start": "743040",
    "end": "746000"
  },
  {
    "text": "sandbox project totally open source so",
    "start": "746000",
    "end": "749200"
  },
  {
    "text": "anyone can use it",
    "start": "749200",
    "end": "752000"
  },
  {
    "text": "so i think the way we think about pixi",
    "start": "752800",
    "end": "754880"
  },
  {
    "text": "is progressive instrumentation which",
    "start": "754880",
    "end": "757360"
  },
  {
    "text": "means you start with a baseline of a",
    "start": "757360",
    "end": "759920"
  },
  {
    "text": "certain amount of visibility into your",
    "start": "759920",
    "end": "761519"
  },
  {
    "text": "system and you can extend that",
    "start": "761519",
    "end": "763360"
  },
  {
    "text": "visibility",
    "start": "763360",
    "end": "765200"
  },
  {
    "text": "in areas that you're interested in so",
    "start": "765200",
    "end": "767760"
  },
  {
    "text": "pixi right out of the gate has",
    "start": "767760",
    "end": "770000"
  },
  {
    "text": "things like resource utilization",
    "start": "770000",
    "end": "772399"
  },
  {
    "text": "flame graph showing which functions are",
    "start": "772399",
    "end": "774000"
  },
  {
    "text": "taking a long time in your application",
    "start": "774000",
    "end": "776160"
  },
  {
    "text": "it shows the raw requests in and out of",
    "start": "776160",
    "end": "777920"
  },
  {
    "text": "your application",
    "start": "777920",
    "end": "779680"
  },
  {
    "text": "but we also have the ability to",
    "start": "779680",
    "end": "781920"
  },
  {
    "text": "once pixie's deployed in the cluster to",
    "start": "781920",
    "end": "784160"
  },
  {
    "text": "add additional user-specific",
    "start": "784160",
    "end": "786000"
  },
  {
    "text": "instrumentation for your application so",
    "start": "786000",
    "end": "788639"
  },
  {
    "text": "we can use uprobes which is a user space",
    "start": "788639",
    "end": "791440"
  },
  {
    "text": "bpf probe to trace particular functions",
    "start": "791440",
    "end": "794079"
  },
  {
    "text": "in your application that you're",
    "start": "794079",
    "end": "795040"
  },
  {
    "text": "interested in without requiring a",
    "start": "795040",
    "end": "796800"
  },
  {
    "text": "redeploy or anything like that",
    "start": "796800",
    "end": "799279"
  },
  {
    "text": "you can write custom scripts and custom",
    "start": "799279",
    "end": "800880"
  },
  {
    "text": "dashboards and soon it's going to",
    "start": "800880",
    "end": "802880"
  },
  {
    "text": "support things like supporting arbitrary",
    "start": "802880",
    "end": "805120"
  },
  {
    "text": "data sources from open telemetry ingest",
    "start": "805120",
    "end": "807519"
  },
  {
    "text": "and things like that",
    "start": "807519",
    "end": "810079"
  },
  {
    "text": "in the diagram below we just have an",
    "start": "810079",
    "end": "811519"
  },
  {
    "text": "example of how a upro works in your",
    "start": "811519",
    "end": "813279"
  },
  {
    "text": "system so you can say i'm going to trace",
    "start": "813279",
    "end": "815839"
  },
  {
    "text": "this particular function",
    "start": "815839",
    "end": "818639"
  },
  {
    "text": "the function will then run and then the",
    "start": "818639",
    "end": "820959"
  },
  {
    "text": "u probe will actually read the values in",
    "start": "820959",
    "end": "823040"
  },
  {
    "text": "and out of the application or in and out",
    "start": "823040",
    "end": "825040"
  },
  {
    "text": "of the function if that's what you're",
    "start": "825040",
    "end": "826160"
  },
  {
    "text": "telling it to trace you can collect",
    "start": "826160",
    "end": "828000"
  },
  {
    "text": "things like latency arguments return",
    "start": "828000",
    "end": "830000"
  },
  {
    "text": "values and things like that using you",
    "start": "830000",
    "end": "831440"
  },
  {
    "text": "probes",
    "start": "831440",
    "end": "833680"
  },
  {
    "text": "so",
    "start": "833680",
    "end": "834800"
  },
  {
    "text": "next i'll show a demo",
    "start": "834800",
    "end": "836560"
  },
  {
    "text": "you know this is just the beginning of",
    "start": "836560",
    "end": "837920"
  },
  {
    "text": "using pixi to apply some of the ml x-ray",
    "start": "837920",
    "end": "840160"
  },
  {
    "text": "concepts but want to show it on",
    "start": "840160",
    "end": "842240"
  },
  {
    "text": "application and show you know ml",
    "start": "842240",
    "end": "844320"
  },
  {
    "text": "observability on the edge using pixi",
    "start": "844320",
    "end": "848240"
  },
  {
    "text": "so",
    "start": "853600",
    "end": "856600"
  },
  {
    "text": "okay well",
    "start": "856720",
    "end": "858160"
  },
  {
    "text": "i was warned that this might happen",
    "start": "858160",
    "end": "861759"
  },
  {
    "text": "oh it's back okay great so i just made a",
    "start": "865760",
    "end": "868800"
  },
  {
    "text": "quick little github project to run a you",
    "start": "868800",
    "end": "870959"
  },
  {
    "text": "know kubernetes object detection so you",
    "start": "870959",
    "end": "872880"
  },
  {
    "text": "can check it out if you want to test it",
    "start": "872880",
    "end": "874160"
  },
  {
    "text": "out yourself",
    "start": "874160",
    "end": "875839"
  },
  {
    "text": "i have that application running on my",
    "start": "875839",
    "end": "878720"
  },
  {
    "text": "kubernetes cluster",
    "start": "878720",
    "end": "880639"
  },
  {
    "text": "so",
    "start": "880639",
    "end": "881360"
  },
  {
    "text": "this is the pixie ui you can see that",
    "start": "881360",
    "end": "885040"
  },
  {
    "text": "um it's showing me the traffic between",
    "start": "885040",
    "end": "887279"
  },
  {
    "text": "different you know applications in my",
    "start": "887279",
    "end": "888800"
  },
  {
    "text": "cluster",
    "start": "888800",
    "end": "889839"
  },
  {
    "text": "things like the nodes and the name",
    "start": "889839",
    "end": "891040"
  },
  {
    "text": "spaces",
    "start": "891040",
    "end": "892560"
  },
  {
    "text": "and specifically what i'm interested in",
    "start": "892560",
    "end": "894560"
  },
  {
    "text": "is this model server which is running my",
    "start": "894560",
    "end": "897839"
  },
  {
    "text": "uh tensorflow application which is an",
    "start": "897839",
    "end": "899839"
  },
  {
    "text": "image classifier",
    "start": "899839",
    "end": "902399"
  },
  {
    "text": "so right off the bat we can see things",
    "start": "902399",
    "end": "904880"
  },
  {
    "text": "like what's the cpu usage what are the",
    "start": "904880",
    "end": "907120"
  },
  {
    "text": "containers that are running what are the",
    "start": "907120",
    "end": "908880"
  },
  {
    "text": "processes bites in and out things like",
    "start": "908880",
    "end": "911760"
  },
  {
    "text": "that",
    "start": "911760",
    "end": "913279"
  },
  {
    "text": "so",
    "start": "913279",
    "end": "914240"
  },
  {
    "text": "what i want to do is i want to trigger",
    "start": "914240",
    "end": "917199"
  },
  {
    "text": "some load on this",
    "start": "917199",
    "end": "919120"
  },
  {
    "text": "application",
    "start": "919120",
    "end": "920560"
  },
  {
    "text": "and what i want to do is i'm going to",
    "start": "920560",
    "end": "922399"
  },
  {
    "text": "apply custom u probes using a pixel",
    "start": "922399",
    "end": "924720"
  },
  {
    "text": "script and that's going to allow me to",
    "start": "924720",
    "end": "926639"
  },
  {
    "text": "trace model execution in terms of the",
    "start": "926639",
    "end": "929199"
  },
  {
    "text": "number of times that it's run and also",
    "start": "929199",
    "end": "931680"
  },
  {
    "text": "the latency of the model execution",
    "start": "931680",
    "end": "935440"
  },
  {
    "text": "so i'm going to go to",
    "start": "936399",
    "end": "940160"
  },
  {
    "text": "my scratch pad i'm starting some load",
    "start": "940160",
    "end": "942560"
  },
  {
    "text": "over here",
    "start": "942560",
    "end": "944000"
  },
  {
    "text": "we're going to need to re-forward this",
    "start": "944000",
    "end": "946240"
  },
  {
    "text": "port",
    "start": "946240",
    "end": "949240"
  },
  {
    "text": "taking a little bit of time",
    "start": "957199",
    "end": "958959"
  },
  {
    "text": "demo gods be with me",
    "start": "958959",
    "end": "962160"
  },
  {
    "text": "but basically what i'm going to try to",
    "start": "963839",
    "end": "965360"
  },
  {
    "text": "do here is say hey pixie's already",
    "start": "965360",
    "end": "967199"
  },
  {
    "text": "collecting a lot of information about my",
    "start": "967199",
    "end": "969040"
  },
  {
    "text": "application but i specifically want to",
    "start": "969040",
    "end": "970800"
  },
  {
    "text": "trace particular functions that are",
    "start": "970800",
    "end": "972959"
  },
  {
    "text": "running my model so that's the goal of",
    "start": "972959",
    "end": "974480"
  },
  {
    "text": "what i'm about to do",
    "start": "974480",
    "end": "978199"
  },
  {
    "text": "still struggling let's try",
    "start": "984720",
    "end": "988800"
  },
  {
    "text": "i do have a video of this if it fails to",
    "start": "990160",
    "end": "993279"
  },
  {
    "text": "work",
    "start": "993279",
    "end": "995360"
  },
  {
    "text": "do you think i should go to the video or",
    "start": "995360",
    "end": "996480"
  },
  {
    "text": "do you think i should",
    "start": "996480",
    "end": "999040"
  },
  {
    "text": "okay",
    "start": "1001440",
    "end": "1002480"
  },
  {
    "text": "stand",
    "start": "1002480",
    "end": "1003519"
  },
  {
    "text": "stand by",
    "start": "1003519",
    "end": "1005920"
  },
  {
    "text": "while we",
    "start": "1005920",
    "end": "1009240"
  },
  {
    "text": "i just have to pull this out of my files",
    "start": "1017279",
    "end": "1021560"
  },
  {
    "text": "okay",
    "start": "1031199",
    "end": "1033520"
  },
  {
    "text": "okay great",
    "start": "1037280",
    "end": "1040640"
  },
  {
    "text": "so as you can see kind of the same thing",
    "start": "1040959",
    "end": "1042720"
  },
  {
    "text": "that we showed earlier",
    "start": "1042720",
    "end": "1044558"
  },
  {
    "text": "i'm just going to jump ahead",
    "start": "1044559",
    "end": "1046480"
  },
  {
    "text": "to",
    "start": "1046480",
    "end": "1048240"
  },
  {
    "text": "the um",
    "start": "1048240",
    "end": "1050640"
  },
  {
    "text": "the part where i'm going to deploy the",
    "start": "1050640",
    "end": "1052000"
  },
  {
    "text": "pro so basically as i said we're",
    "start": "1052000",
    "end": "1054559"
  },
  {
    "text": "basically going to",
    "start": "1054559",
    "end": "1056240"
  },
  {
    "text": "instrument this application using a",
    "start": "1056240",
    "end": "1058400"
  },
  {
    "text": "custom script this is deploying you",
    "start": "1058400",
    "end": "1060559"
  },
  {
    "text": "probes that i have written in",
    "start": "1060559",
    "end": "1063039"
  },
  {
    "text": "bpf trace and it's basically going to",
    "start": "1063039",
    "end": "1065600"
  },
  {
    "text": "show me the latency and the number of",
    "start": "1065600",
    "end": "1067760"
  },
  {
    "text": "times this model was executed over time",
    "start": "1067760",
    "end": "1070240"
  },
  {
    "text": "in my cluster without any redeploys so",
    "start": "1070240",
    "end": "1072720"
  },
  {
    "text": "by using things like this we're able to",
    "start": "1072720",
    "end": "1075120"
  },
  {
    "text": "add additional observability into our",
    "start": "1075120",
    "end": "1076960"
  },
  {
    "text": "models once they're deployed when",
    "start": "1076960",
    "end": "1078559"
  },
  {
    "text": "they're running on kubernetes",
    "start": "1078559",
    "end": "1080799"
  },
  {
    "text": "so the trace point is being deployed",
    "start": "1080799",
    "end": "1083760"
  },
  {
    "text": "and soon we'll see a plot of latency as",
    "start": "1083760",
    "end": "1086320"
  },
  {
    "text": "well as number of implications over time",
    "start": "1086320",
    "end": "1088480"
  },
  {
    "text": "for my model",
    "start": "1088480",
    "end": "1091880"
  },
  {
    "text": "just giving it a little time to collect",
    "start": "1101600",
    "end": "1103280"
  },
  {
    "text": "some additional data",
    "start": "1103280",
    "end": "1106919"
  },
  {
    "text": "uh",
    "start": "1117440",
    "end": "1120440"
  },
  {
    "text": "okay there we go we can see model",
    "start": "1123840",
    "end": "1125919"
  },
  {
    "text": "requests over time that's the top chart",
    "start": "1125919",
    "end": "1128400"
  },
  {
    "text": "and then the model latency we have the",
    "start": "1128400",
    "end": "1130160"
  },
  {
    "text": "p50 p90 and p99 for how long the model",
    "start": "1130160",
    "end": "1133679"
  },
  {
    "text": "is taking to execute",
    "start": "1133679",
    "end": "1136480"
  },
  {
    "text": "so",
    "start": "1136480",
    "end": "1137280"
  },
  {
    "text": "you might think okay it's taking about a",
    "start": "1137280",
    "end": "1139120"
  },
  {
    "text": "second to execute that might be a little",
    "start": "1139120",
    "end": "1140880"
  },
  {
    "text": "bit long",
    "start": "1140880",
    "end": "1142960"
  },
  {
    "text": "i need more information about what's",
    "start": "1142960",
    "end": "1144480"
  },
  {
    "text": "happening i need to debug this and",
    "start": "1144480",
    "end": "1146080"
  },
  {
    "text": "figure out where the bottleneck is",
    "start": "1146080",
    "end": "1148160"
  },
  {
    "text": "so i mentioned before that pixi has",
    "start": "1148160",
    "end": "1150240"
  },
  {
    "text": "flame graphs that it captures about the",
    "start": "1150240",
    "end": "1153120"
  },
  {
    "text": "you know most cpu intensive functions",
    "start": "1153120",
    "end": "1154799"
  },
  {
    "text": "that your application's running",
    "start": "1154799",
    "end": "1156720"
  },
  {
    "text": "it might be a little hard to see here",
    "start": "1156720",
    "end": "1158320"
  },
  {
    "text": "but you can basically see the entire",
    "start": "1158320",
    "end": "1160320"
  },
  {
    "text": "call stack of what's running",
    "start": "1160320",
    "end": "1162799"
  },
  {
    "text": "and",
    "start": "1162799",
    "end": "1163600"
  },
  {
    "text": "what i'm going to discover looking at",
    "start": "1163600",
    "end": "1165280"
  },
  {
    "text": "this is that most of the time here is",
    "start": "1165280",
    "end": "1167760"
  },
  {
    "text": "spent parsing json and serializing json",
    "start": "1167760",
    "end": "1171039"
  },
  {
    "text": "it's not actually spent on the model",
    "start": "1171039",
    "end": "1172480"
  },
  {
    "text": "itself and this is a really common",
    "start": "1172480",
    "end": "1174240"
  },
  {
    "text": "problem without the ability to attribute",
    "start": "1174240",
    "end": "1176640"
  },
  {
    "text": "the latency you actually might blame the",
    "start": "1176640",
    "end": "1179360"
  },
  {
    "text": "model when it isn't actually the model's",
    "start": "1179360",
    "end": "1180880"
  },
  {
    "text": "fault",
    "start": "1180880",
    "end": "1182080"
  },
  {
    "text": "but there is a particular part in here",
    "start": "1182080",
    "end": "1184559"
  },
  {
    "text": "that it's going to highlight soon which",
    "start": "1184559",
    "end": "1186559"
  },
  {
    "text": "is basically a layer of the model that",
    "start": "1186559",
    "end": "1189200"
  },
  {
    "text": "is taking a really long time in",
    "start": "1189200",
    "end": "1190720"
  },
  {
    "text": "comparison to what we'd expect",
    "start": "1190720",
    "end": "1193360"
  },
  {
    "text": "and that's underneath this parent",
    "start": "1193360",
    "end": "1195280"
  },
  {
    "text": "function",
    "start": "1195280",
    "end": "1196799"
  },
  {
    "text": "we can see the different ops that are",
    "start": "1196799",
    "end": "1198240"
  },
  {
    "text": "running the gather op a concat op",
    "start": "1198240",
    "end": "1201440"
  },
  {
    "text": "and then finally we're going to see",
    "start": "1201440",
    "end": "1203440"
  },
  {
    "text": "a non-max suppression op",
    "start": "1203440",
    "end": "1207280"
  },
  {
    "text": "now this is a particular operation that",
    "start": "1207280",
    "end": "1209600"
  },
  {
    "text": "we expect to be really really fast it's",
    "start": "1209600",
    "end": "1211919"
  },
  {
    "text": "basically just saying i have a bunch of",
    "start": "1211919",
    "end": "1213919"
  },
  {
    "text": "different bounding boxes which ones are",
    "start": "1213919",
    "end": "1216080"
  },
  {
    "text": "the ones that i should actually output",
    "start": "1216080",
    "end": "1218240"
  },
  {
    "text": "so it's kind of a surprise that this",
    "start": "1218240",
    "end": "1220159"
  },
  {
    "text": "would even show up at all especially in",
    "start": "1220159",
    "end": "1221840"
  },
  {
    "text": "comparison to the other ops",
    "start": "1221840",
    "end": "1224080"
  },
  {
    "text": "but as as we establish we have the",
    "start": "1224080",
    "end": "1226080"
  },
  {
    "text": "ability to do custom tracing of whatever",
    "start": "1226080",
    "end": "1227919"
  },
  {
    "text": "function that we want",
    "start": "1227919",
    "end": "1229280"
  },
  {
    "text": "so what i'm going to do here in the last",
    "start": "1229280",
    "end": "1231440"
  },
  {
    "text": "part of the video is basically trace",
    "start": "1231440",
    "end": "1233600"
  },
  {
    "text": "arguments to this",
    "start": "1233600",
    "end": "1235840"
  },
  {
    "text": "non-max suppression operation and try to",
    "start": "1235840",
    "end": "1238240"
  },
  {
    "text": "figure out based on the arguments that",
    "start": "1238240",
    "end": "1240000"
  },
  {
    "text": "it's receiving why it might be taking a",
    "start": "1240000",
    "end": "1241600"
  },
  {
    "text": "long time",
    "start": "1241600",
    "end": "1244080"
  },
  {
    "text": "so i'm going to run another script",
    "start": "1244640",
    "end": "1249240"
  },
  {
    "text": "and it's basically going to trace that",
    "start": "1249440",
    "end": "1251200"
  },
  {
    "text": "particular operation",
    "start": "1251200",
    "end": "1254320"
  },
  {
    "text": "and let's see if we can figure out a",
    "start": "1255520",
    "end": "1256960"
  },
  {
    "text": "little bit about why it's taking longer",
    "start": "1256960",
    "end": "1258960"
  },
  {
    "text": "than we think",
    "start": "1258960",
    "end": "1262200"
  },
  {
    "text": "okay it's a little hard to see here",
    "start": "1273600",
    "end": "1275360"
  },
  {
    "text": "because it's small text but what we see",
    "start": "1275360",
    "end": "1277679"
  },
  {
    "text": "is that there are actually thousands of",
    "start": "1277679",
    "end": "1279679"
  },
  {
    "text": "bounding boxes being passed into this",
    "start": "1279679",
    "end": "1281760"
  },
  {
    "text": "function 2 000 in fact that is a lot",
    "start": "1281760",
    "end": "1284880"
  },
  {
    "text": "higher than i might expect from my",
    "start": "1284880",
    "end": "1286559"
  },
  {
    "text": "reference pipeline so this has allowed",
    "start": "1286559",
    "end": "1288720"
  },
  {
    "text": "me to get to the part of the issue which",
    "start": "1288720",
    "end": "1291120"
  },
  {
    "text": "is why is this particular",
    "start": "1291120",
    "end": "1293520"
  },
  {
    "text": "layer of my model slow it's because it's",
    "start": "1293520",
    "end": "1296880"
  },
  {
    "text": "receiving an outsized input it's an",
    "start": "1296880",
    "end": "1298720"
  },
  {
    "text": "input that we wouldn't actually expect",
    "start": "1298720",
    "end": "1301120"
  },
  {
    "text": "so",
    "start": "1301120",
    "end": "1301840"
  },
  {
    "text": "you know we have kind of gotten to the",
    "start": "1301840",
    "end": "1303679"
  },
  {
    "text": "root of the performance issues",
    "start": "1303679",
    "end": "1305919"
  },
  {
    "text": "using some of the principles that we got",
    "start": "1305919",
    "end": "1307440"
  },
  {
    "text": "from mlxray",
    "start": "1307440",
    "end": "1310679"
  },
  {
    "text": "uh okay it looks like michelle's mic is",
    "start": "1326320",
    "end": "1328159"
  },
  {
    "text": "off now so i guess uh you know resources",
    "start": "1328159",
    "end": "1332320"
  },
  {
    "text": "um the ml x-ray repo it's on github you",
    "start": "1332320",
    "end": "1335679"
  },
  {
    "text": "can just search for it and see kind of",
    "start": "1335679",
    "end": "1337600"
  },
  {
    "text": "what they've been able to do it's very",
    "start": "1337600",
    "end": "1339360"
  },
  {
    "text": "well targeted for mobile deployments",
    "start": "1339360",
    "end": "1341840"
  },
  {
    "text": "the ml x-ray paper uh which has been",
    "start": "1341840",
    "end": "1344240"
  },
  {
    "text": "accepted into ml mlsys so if you are",
    "start": "1344240",
    "end": "1346480"
  },
  {
    "text": "kind of part of both worlds you can",
    "start": "1346480",
    "end": "1347760"
  },
  {
    "text": "check them out at mlsys",
    "start": "1347760",
    "end": "1349919"
  },
  {
    "text": "and then finally you can check out you",
    "start": "1349919",
    "end": "1352320"
  },
  {
    "text": "know pixi's github repo",
    "start": "1352320",
    "end": "1354559"
  },
  {
    "text": "it's pixi dash i o slash pixie if you",
    "start": "1354559",
    "end": "1357919"
  },
  {
    "text": "want to check it out on your edge",
    "start": "1357919",
    "end": "1359520"
  },
  {
    "text": "devices",
    "start": "1359520",
    "end": "1361840"
  },
  {
    "text": "and that's it thank you",
    "start": "1362320",
    "end": "1364800"
  },
  {
    "text": "[Applause]",
    "start": "1364800",
    "end": "1369020"
  }
]
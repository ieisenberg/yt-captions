[
  {
    "text": "good okay hi hi everyone thanks for",
    "start": "0",
    "end": "3060"
  },
  {
    "text": "coming",
    "start": "3060",
    "end": "3929"
  },
  {
    "text": "my name is one and down there",
    "start": "3929",
    "end": "6450"
  },
  {
    "text": "this is the Jaeger deep dive session so",
    "start": "6450",
    "end": "10349"
  },
  {
    "text": "both me and prefeer both and I are",
    "start": "10349",
    "end": "12990"
  },
  {
    "text": "software engineers at uber and more",
    "start": "12990",
    "end": "15000"
  },
  {
    "text": "importantly we're both maintainer of the",
    "start": "15000",
    "end": "16800"
  },
  {
    "text": "Jaeger project so before we get started",
    "start": "16800",
    "end": "19470"
  },
  {
    "text": "how many people here have actually used",
    "start": "19470",
    "end": "21180"
  },
  {
    "text": "here okay okay I'm not sure why there",
    "start": "21180",
    "end": "27449"
  },
  {
    "text": "are so many people at the deep dive okay",
    "start": "27449",
    "end": "29130"
  },
  {
    "text": "go so here's a brief overview of the",
    "start": "29130",
    "end": "31289"
  },
  {
    "text": "agenda so hopefully a majority of you on",
    "start": "31289",
    "end": "34230"
  },
  {
    "text": "attended the introduction to Jaeger",
    "start": "34230",
    "end": "36630"
  },
  {
    "text": "yesterday so we'll go ahead and skip the",
    "start": "36630",
    "end": "38910"
  },
  {
    "text": "demo and start with the architecture",
    "start": "38910",
    "end": "41070"
  },
  {
    "text": "then we'll look at how you can tune the",
    "start": "41070",
    "end": "44040"
  },
  {
    "text": "performance of Jaeger and gain",
    "start": "44040",
    "end": "45539"
  },
  {
    "text": "observability into it then pretty we'll",
    "start": "45539",
    "end": "47940"
  },
  {
    "text": "go into detail over the new Jaeger",
    "start": "47940",
    "end": "49500"
  },
  {
    "text": "features look at our roadmap and then",
    "start": "49500",
    "end": "51840"
  },
  {
    "text": "cover some administrative topics we'll",
    "start": "51840",
    "end": "54750"
  },
  {
    "text": "try to get through these as quickly as",
    "start": "54750",
    "end": "56550"
  },
  {
    "text": "possible to leave time for a lot of",
    "start": "56550",
    "end": "58890"
  },
  {
    "text": "questions okay so let's just jog our",
    "start": "58890",
    "end": "61920"
  },
  {
    "text": "memory of and recall why we need this",
    "start": "61920",
    "end": "64018"
  },
  {
    "text": "retracing in the first place so firstly",
    "start": "64019",
    "end": "66750"
  },
  {
    "text": "rather than monitoring individual",
    "start": "66750",
    "end": "69030"
  },
  {
    "text": "components of the architecture like you",
    "start": "69030",
    "end": "71100"
  },
  {
    "text": "can with metrics and logs we can use",
    "start": "71100",
    "end": "73260"
  },
  {
    "text": "distributed tracing to monitor",
    "start": "73260",
    "end": "75000"
  },
  {
    "text": "distributed transactions across multiple",
    "start": "75000",
    "end": "77280"
  },
  {
    "text": "components additionally we can use",
    "start": "77280",
    "end": "80490"
  },
  {
    "text": "traces to do root cause analysis which",
    "start": "80490",
    "end": "83130"
  },
  {
    "text": "is integral for companies like uber",
    "start": "83130",
    "end": "84659"
  },
  {
    "text": "where sometimes a request can fan out",
    "start": "84659",
    "end": "87210"
  },
  {
    "text": "and get hundreds of different services",
    "start": "87210",
    "end": "89750"
  },
  {
    "text": "we can also use traces to detect the",
    "start": "89750",
    "end": "93210"
  },
  {
    "text": "critical path and do performance and",
    "start": "93210",
    "end": "95460"
  },
  {
    "text": "latency optimizations so the critical",
    "start": "95460",
    "end": "97650"
  },
  {
    "text": "path is composed of the shortest path",
    "start": "97650",
    "end": "99570"
  },
  {
    "text": "from the start of the trace to the end",
    "start": "99570",
    "end": "101729"
  },
  {
    "text": "of the trace so if we were to optimize",
    "start": "101729",
    "end": "103770"
  },
  {
    "text": "and speed up all the spans along this",
    "start": "103770",
    "end": "105509"
  },
  {
    "text": "critical path we can reduce the overall",
    "start": "105509",
    "end": "107490"
  },
  {
    "text": "latency of the entire distributed",
    "start": "107490",
    "end": "109890"
  },
  {
    "text": "transaction so if you recall the demo",
    "start": "109890",
    "end": "112079"
  },
  {
    "text": "that proof he gave yesterday if there",
    "start": "112079",
    "end": "115890"
  },
  {
    "text": "was a my sequel span in our trace we're",
    "start": "115890",
    "end": "117689"
  },
  {
    "text": "about 90% of our time was being wasted",
    "start": "117689",
    "end": "120540"
  },
  {
    "text": "so using that information you could",
    "start": "120540",
    "end": "122640"
  },
  {
    "text": "easily have gone in there and optimized",
    "start": "122640",
    "end": "124320"
  },
  {
    "text": "that my sequel read by adding like the",
    "start": "124320",
    "end": "126810"
  },
  {
    "text": "bigger thread pool or perhaps even",
    "start": "126810",
    "end": "128459"
  },
  {
    "text": "adding a cache in front of it and",
    "start": "128459",
    "end": "129869"
  },
  {
    "text": "reducing the overall time spent on that",
    "start": "129869",
    "end": "132120"
  },
  {
    "text": "read",
    "start": "132120",
    "end": "133129"
  },
  {
    "text": "so I recall that there was a study at",
    "start": "133129",
    "end": "135560"
  },
  {
    "text": "Amazon that said if you were to increase",
    "start": "135560",
    "end": "137840"
  },
  {
    "text": "latency by 100 milliseconds it would",
    "start": "137840",
    "end": "140840"
  },
  {
    "text": "cost them 1% of profit so think of all",
    "start": "140840",
    "end": "143629"
  },
  {
    "text": "the money your company could save by",
    "start": "143629",
    "end": "145069"
  },
  {
    "text": "using distributed tracing and figuring",
    "start": "145069",
    "end": "147019"
  },
  {
    "text": "out where to optimize correctly so",
    "start": "147019",
    "end": "149629"
  },
  {
    "text": "getting back on topic with some",
    "start": "149629",
    "end": "152239"
  },
  {
    "text": "post-processing we can use this - should",
    "start": "152239",
    "end": "154189"
  },
  {
    "text": "be tracing to generate dependency",
    "start": "154189",
    "end": "155780"
  },
  {
    "text": "diagrams that allow engineers to better",
    "start": "155780",
    "end": "157969"
  },
  {
    "text": "understand the system that they're",
    "start": "157969",
    "end": "159349"
  },
  {
    "text": "working on and finally distributed",
    "start": "159349",
    "end": "162139"
  },
  {
    "text": "tracing provides a generic distributed",
    "start": "162139",
    "end": "164989"
  },
  {
    "text": "context propagation functionality which",
    "start": "164989",
    "end": "167629"
  },
  {
    "text": "everything else is built upon ok but you",
    "start": "167629",
    "end": "170389"
  },
  {
    "text": "guys knew all that so let's just take a",
    "start": "170389",
    "end": "172219"
  },
  {
    "text": "deeper look at Jaeger so I'm gonna fly",
    "start": "172219",
    "end": "175939"
  },
  {
    "text": "through the sidecut it was here",
    "start": "175939",
    "end": "177230"
  },
  {
    "text": "yesterday so Jaeger is primarily written",
    "start": "177230",
    "end": "180019"
  },
  {
    "text": "in golang and we have a couple new",
    "start": "180019",
    "end": "181669"
  },
  {
    "text": "components in Java we allow pluggable",
    "start": "181669",
    "end": "184459"
  },
  {
    "text": "storage like Cassandra elasticsearch and",
    "start": "184459",
    "end": "187459"
  },
  {
    "text": "in memory storage to persist traces",
    "start": "187459",
    "end": "189439"
  },
  {
    "text": "there is also an ongoing effort to add",
    "start": "189439",
    "end": "191750"
  },
  {
    "text": "support for other storage engines the UI",
    "start": "191750",
    "end": "194719"
  },
  {
    "text": "is written and react and we support many",
    "start": "194719",
    "end": "196909"
  },
  {
    "text": "different languages with different our",
    "start": "196909",
    "end": "198799"
  },
  {
    "text": "clients we currently support the 8 that",
    "start": "198799",
    "end": "201199"
  },
  {
    "text": "you see at the bottom of the screen so",
    "start": "201199",
    "end": "204049"
  },
  {
    "text": "here's what the architecture looked like",
    "start": "204049",
    "end": "206030"
  },
  {
    "text": "in 2017 when we first open sourced the",
    "start": "206030",
    "end": "208909"
  },
  {
    "text": "project so the light gray box on the",
    "start": "208909",
    "end": "211519"
  },
  {
    "text": "left side is the host your application",
    "start": "211519",
    "end": "213919"
  },
  {
    "text": "is running in so your application is",
    "start": "213919",
    "end": "216290"
  },
  {
    "text": "instrumented with the open tracing API",
    "start": "216290",
    "end": "218239"
  },
  {
    "text": "and you use the Jaeger client library as",
    "start": "218239",
    "end": "220879"
  },
  {
    "text": "a concrete implementation of that API so",
    "start": "220879",
    "end": "223939"
  },
  {
    "text": "the Jaeger client batches bans and then",
    "start": "223939",
    "end": "226819"
  },
  {
    "text": "force the spans to the local Jaeger",
    "start": "226819",
    "end": "228889"
  },
  {
    "text": "agent over UDP the Jaeger agent also",
    "start": "228889",
    "end": "231829"
  },
  {
    "text": "runs on the same host as your",
    "start": "231829",
    "end": "233419"
  },
  {
    "text": "application but as a separate process",
    "start": "233419",
    "end": "235609"
  },
  {
    "text": "the agent then buffers the spans for all",
    "start": "235609",
    "end": "238849"
  },
  {
    "text": "the other application also running on",
    "start": "238849",
    "end": "240680"
  },
  {
    "text": "the same host and then it forwards all",
    "start": "240680",
    "end": "242900"
  },
  {
    "text": "of them to the Jager collector which is",
    "start": "242900",
    "end": "245150"
  },
  {
    "text": "the blue box in the middle over TCP so",
    "start": "245150",
    "end": "248209"
  },
  {
    "text": "we chose to have an agent per host",
    "start": "248209",
    "end": "250699"
  },
  {
    "text": "rather than having every client emit",
    "start": "250699",
    "end": "253069"
  },
  {
    "text": "spans directly to the Jager collectors",
    "start": "253069",
    "end": "254959"
  },
  {
    "text": "to reduce the number of incoming collect",
    "start": "254959",
    "end": "257060"
  },
  {
    "text": "connections to the collectors since the",
    "start": "257060",
    "end": "259759"
  },
  {
    "text": "number of applications far outnumber the",
    "start": "259759",
    "end": "262310"
  },
  {
    "text": "number of physical hosts also we want to",
    "start": "262310",
    "end": "264710"
  },
  {
    "text": "take advantage of using you",
    "start": "264710",
    "end": "266250"
  },
  {
    "text": "to reduce the amount of overhead that",
    "start": "266250",
    "end": "269250"
  },
  {
    "text": "the clients have on your application",
    "start": "269250",
    "end": "271260"
  },
  {
    "text": "so speaking of overhead so this is a",
    "start": "271260",
    "end": "274020"
  },
  {
    "text": "common question that I get all the time",
    "start": "274020",
    "end": "275490"
  },
  {
    "text": "so I'm just gonna address it here so how",
    "start": "275490",
    "end": "277560"
  },
  {
    "text": "much overhead does tracing actually add",
    "start": "277560",
    "end": "279780"
  },
  {
    "text": "to your application so the answer is",
    "start": "279780",
    "end": "282450"
  },
  {
    "text": "unfortunately it depends so if your",
    "start": "282450",
    "end": "285330"
  },
  {
    "text": "application has a lot of complex",
    "start": "285330",
    "end": "286920"
  },
  {
    "text": "business logic and takes in the order of",
    "start": "286920",
    "end": "289230"
  },
  {
    "text": "hundreds of milliseconds to complete",
    "start": "289230",
    "end": "290910"
  },
  {
    "text": "then the overhead from tracing will be",
    "start": "290910",
    "end": "293880"
  },
  {
    "text": "negligible compared to the amount of",
    "start": "293880",
    "end": "295980"
  },
  {
    "text": "work being done by your application",
    "start": "295980",
    "end": "297810"
  },
  {
    "text": "however if your application is super",
    "start": "297810",
    "end": "300480"
  },
  {
    "text": "simple and only takes microseconds to",
    "start": "300480",
    "end": "302669"
  },
  {
    "text": "finish then tracing will add a lot added",
    "start": "302669",
    "end": "305190"
  },
  {
    "text": "a lot more overhead relative to your",
    "start": "305190",
    "end": "306900"
  },
  {
    "text": "application so essentially what I'm",
    "start": "306900",
    "end": "308550"
  },
  {
    "text": "trying to get at is that the overhead",
    "start": "308550",
    "end": "310320"
  },
  {
    "text": "for tracing is relative to the",
    "start": "310320",
    "end": "313530"
  },
  {
    "text": "application so in my personal opinion",
    "start": "313530",
    "end": "315810"
  },
  {
    "text": "people really ask about the overhead of",
    "start": "315810",
    "end": "318419"
  },
  {
    "text": "omitting metrics and logs and I believe",
    "start": "318419",
    "end": "320669"
  },
  {
    "text": "tracing is as important as though as",
    "start": "320669",
    "end": "322530"
  },
  {
    "text": "though so any overhead is justified but",
    "start": "322530",
    "end": "325230"
  },
  {
    "text": "okay but I digress so we can chat about",
    "start": "325230",
    "end": "327630"
  },
  {
    "text": "this after as well so the collector",
    "start": "327630",
    "end": "329640"
  },
  {
    "text": "which is the blue box in the center of",
    "start": "329640",
    "end": "331290"
  },
  {
    "text": "the screen is in charge of buffering the",
    "start": "331290",
    "end": "333360"
  },
  {
    "text": "spans in memory sanitizing them and then",
    "start": "333360",
    "end": "336570"
  },
  {
    "text": "storing the spans in a data store like",
    "start": "336570",
    "end": "338760"
  },
  {
    "text": "Cassandra we have a separate Yaeger",
    "start": "338760",
    "end": "341310"
  },
  {
    "text": "query service which is on the right side",
    "start": "341310",
    "end": "343440"
  },
  {
    "text": "and that is used to read traces from the",
    "start": "343440",
    "end": "346229"
  },
  {
    "text": "data store and then present them to the",
    "start": "346229",
    "end": "348150"
  },
  {
    "text": "user through the Yagyu i additionally",
    "start": "348150",
    "end": "350880"
  },
  {
    "text": "Jager collectors are in charge of",
    "start": "350880",
    "end": "352520"
  },
  {
    "text": "configuration distribution this means",
    "start": "352520",
    "end": "355110"
  },
  {
    "text": "that the sampling probabilities and all",
    "start": "355110",
    "end": "357180"
  },
  {
    "text": "other configurations for applications",
    "start": "357180",
    "end": "359070"
  },
  {
    "text": "are all stored in the collector and then",
    "start": "359070",
    "end": "361410"
  },
  {
    "text": "forwarded to the Jager clients via the",
    "start": "361410",
    "end": "363690"
  },
  {
    "text": "Jager agent so this is shown as the red",
    "start": "363690",
    "end": "366240"
  },
  {
    "text": "arrows in the diagram so yeah the red",
    "start": "366240",
    "end": "368790"
  },
  {
    "text": "arrows show the controls laughter okay",
    "start": "368790",
    "end": "371100"
  },
  {
    "text": "so we also had an apache spark job which",
    "start": "371100",
    "end": "375060"
  },
  {
    "text": "did very basic post-processing of our",
    "start": "375060",
    "end": "377700"
  },
  {
    "text": "traces and it generated dependency",
    "start": "377700",
    "end": "379830"
  },
  {
    "text": "diagrams okay and this is what the",
    "start": "379830",
    "end": "382890"
  },
  {
    "text": "architecture looks like today there",
    "start": "382890",
    "end": "384630"
  },
  {
    "text": "hasn't been much change on the clients",
    "start": "384630",
    "end": "386700"
  },
  {
    "text": "and agents most of the changes have",
    "start": "386700",
    "end": "388770"
  },
  {
    "text": "occurred in the backend so first of all",
    "start": "388770",
    "end": "390900"
  },
  {
    "text": "our architecture back in 2017 just gone",
    "start": "390900",
    "end": "393810"
  },
  {
    "text": "back was all based on was everything was",
    "start": "393810",
    "end": "396690"
  },
  {
    "text": "a sari everything was a synchronous the",
    "start": "396690",
    "end": "399810"
  },
  {
    "text": "meant that during a load spikes we were",
    "start": "399810",
    "end": "402120"
  },
  {
    "text": "not able to keep up with the traffic and",
    "start": "402120",
    "end": "404570"
  },
  {
    "text": "therefore we had to drop and lose data",
    "start": "404570",
    "end": "407340"
  },
  {
    "text": "right so we now have an asynchronous",
    "start": "407340",
    "end": "409620"
  },
  {
    "text": "ingestion pipeline that allows us to",
    "start": "409620",
    "end": "411930"
  },
  {
    "text": "better deal with these load spikes so",
    "start": "411930",
    "end": "413790"
  },
  {
    "text": "essentially we traded data loss for",
    "start": "413790",
    "end": "415770"
  },
  {
    "text": "increase the ingestion latency so we now",
    "start": "415770",
    "end": "418830"
  },
  {
    "text": "buffer spans in Kafka and have a",
    "start": "418830",
    "end": "421320"
  },
  {
    "text": "separate and jester service that handles",
    "start": "421320",
    "end": "423930"
  },
  {
    "text": "writing the actual spans to Cassandra",
    "start": "423930",
    "end": "426330"
  },
  {
    "text": "so in addition since now we're buffering",
    "start": "426330",
    "end": "428610"
  },
  {
    "text": "spans in Kafka internally over at least",
    "start": "428610",
    "end": "431430"
  },
  {
    "text": "we've been able to run a span processing",
    "start": "431430",
    "end": "433740"
  },
  {
    "text": "job in apache flink that generates",
    "start": "433740",
    "end": "436560"
  },
  {
    "text": "dependency diagrams and extracts other",
    "start": "436560",
    "end": "438810"
  },
  {
    "text": "features pretty we'll be going into more",
    "start": "438810",
    "end": "441120"
  },
  {
    "text": "detail about this new enzyme a",
    "start": "441120",
    "end": "442530"
  },
  {
    "text": "synchronous ingestion pipeline and the",
    "start": "442530",
    "end": "444690"
  },
  {
    "text": "new Jaeger streaming pipeline as well in",
    "start": "444690",
    "end": "447720"
  },
  {
    "text": "a bit sorry so additionally we now added",
    "start": "447720",
    "end": "450030"
  },
  {
    "text": "support for Jaeger clients to directly",
    "start": "450030",
    "end": "452430"
  },
  {
    "text": "submit spans to the collectors over HTTP",
    "start": "452430",
    "end": "455520"
  },
  {
    "text": "rather than going through the Jaeger",
    "start": "455520",
    "end": "457530"
  },
  {
    "text": "agents so this feature is super useful",
    "start": "457530",
    "end": "460110"
  },
  {
    "text": "for applications that may be deployed to",
    "start": "460110",
    "end": "462690"
  },
  {
    "text": "hosts where you can't run the Jaeger",
    "start": "462690",
    "end": "464910"
  },
  {
    "text": "agent and you still need a way to get",
    "start": "464910",
    "end": "466950"
  },
  {
    "text": "the spans to the collectors so for",
    "start": "466950",
    "end": "469140"
  },
  {
    "text": "example if your application is running",
    "start": "469140",
    "end": "470760"
  },
  {
    "text": "on a user's desktop emitting spans over",
    "start": "470760",
    "end": "473520"
  },
  {
    "text": "HTTP is the only option you have because",
    "start": "473520",
    "end": "475560"
  },
  {
    "text": "you can't install the Jaeger agent and",
    "start": "475560",
    "end": "478289"
  },
  {
    "text": "run it on their host ok so now let's",
    "start": "478289",
    "end": "481080"
  },
  {
    "text": "take a brief look at the model for",
    "start": "481080",
    "end": "483419"
  },
  {
    "text": "Jaeger this is the current data model",
    "start": "483419",
    "end": "485640"
  },
  {
    "text": "and it's based on Apache thrift it's",
    "start": "485640",
    "end": "487860"
  },
  {
    "text": "written in Apache first but there's",
    "start": "487860",
    "end": "489810"
  },
  {
    "text": "currently ongoing work to move it to a",
    "start": "489810",
    "end": "492090"
  },
  {
    "text": "protobuf so the most basic unit of data",
    "start": "492090",
    "end": "495180"
  },
  {
    "text": "is the span which is the big blob right",
    "start": "495180",
    "end": "497070"
  },
  {
    "text": "in the middle it contains a start time",
    "start": "497070",
    "end": "499470"
  },
  {
    "text": "duration logs and tags each span belongs",
    "start": "499470",
    "end": "503130"
  },
  {
    "text": "to a trace and is identified by the",
    "start": "503130",
    "end": "505080"
  },
  {
    "text": "trace ID additionally each span kind of",
    "start": "505080",
    "end": "508530"
  },
  {
    "text": "references which can be used to model",
    "start": "508530",
    "end": "510690"
  },
  {
    "text": "causality between spans so for example",
    "start": "510690",
    "end": "513630"
  },
  {
    "text": "if one span could be a child of another",
    "start": "513630",
    "end": "516240"
  },
  {
    "text": "span this simply means that the child",
    "start": "516240",
    "end": "518610"
  },
  {
    "text": "span was initially initiated by the",
    "start": "518610",
    "end": "520950"
  },
  {
    "text": "parents man so we then combine all these",
    "start": "520950",
    "end": "523560"
  },
  {
    "text": "spans into something called a batch",
    "start": "523560",
    "end": "525089"
  },
  {
    "text": "which is the structure you see on the",
    "start": "525089",
    "end": "526950"
  },
  {
    "text": "left side of the screen a batch is just",
    "start": "526950",
    "end": "528990"
  },
  {
    "text": "the simple collection of spans for the",
    "start": "528990",
    "end": "530910"
  },
  {
    "text": "same process so you can think of a",
    "start": "530910",
    "end": "532650"
  },
  {
    "text": "process as a server",
    "start": "532650",
    "end": "533680"
  },
  {
    "text": "or an application the batch data",
    "start": "533680",
    "end": "535750"
  },
  {
    "text": "structure is not exposed to the users",
    "start": "535750",
    "end": "537640"
  },
  {
    "text": "it's just used internally as a",
    "start": "537640",
    "end": "539260"
  },
  {
    "text": "normalization tool so that we can",
    "start": "539260",
    "end": "541360"
  },
  {
    "text": "duplicate the amount of data we send",
    "start": "541360",
    "end": "543310"
  },
  {
    "text": "over the wire so to break that down a",
    "start": "543310",
    "end": "545620"
  },
  {
    "text": "bit",
    "start": "545620",
    "end": "545920"
  },
  {
    "text": "each span in the same batch all are",
    "start": "545920",
    "end": "548760"
  },
  {
    "text": "associated with the same process so",
    "start": "548760",
    "end": "551230"
  },
  {
    "text": "rather than duplicating a process for",
    "start": "551230",
    "end": "552880"
  },
  {
    "text": "each span we just have a batch that just",
    "start": "552880",
    "end": "555100"
  },
  {
    "text": "contains one process so great so now",
    "start": "555100",
    "end": "559209"
  },
  {
    "text": "let's say you want to check out Jaeger",
    "start": "559209",
    "end": "560589"
  },
  {
    "text": "and run it for yourself how do you go",
    "start": "560589",
    "end": "562660"
  },
  {
    "text": "about configuring the Collector's the in",
    "start": "562660",
    "end": "564700"
  },
  {
    "text": "gestures and other components so we use",
    "start": "564700",
    "end": "567550"
  },
  {
    "text": "a open source project called Viper which",
    "start": "567550",
    "end": "570279"
  },
  {
    "text": "allows us to configure Jaeger with both",
    "start": "570279",
    "end": "572380"
  },
  {
    "text": "command line flags and environment",
    "start": "572380",
    "end": "574330"
  },
  {
    "text": "variables we also support kubernetes",
    "start": "574330",
    "end": "576640"
  },
  {
    "text": "config Maps for those of you guys",
    "start": "576640",
    "end": "578410"
  },
  {
    "text": "deploying with Cuban Ares",
    "start": "578410",
    "end": "580240"
  },
  {
    "text": "so additionally the UI is highly",
    "start": "580240",
    "end": "582670"
  },
  {
    "text": "customizable and it's all driven by",
    "start": "582670",
    "end": "584640"
  },
  {
    "text": "configuration you can easily adjust the",
    "start": "584640",
    "end": "587680"
  },
  {
    "text": "items shown in the UI header add Google",
    "start": "587680",
    "end": "590649"
  },
  {
    "text": "Analytics token to get usage information",
    "start": "590649",
    "end": "593830"
  },
  {
    "text": "and also configure spans with contextual",
    "start": "593830",
    "end": "596560"
  },
  {
    "text": "links so contextual links are a new",
    "start": "596560",
    "end": "598930"
  },
  {
    "text": "feature that was contributed by one of",
    "start": "598930",
    "end": "601060"
  },
  {
    "text": "our open source users so as a concrete",
    "start": "601060",
    "end": "603190"
  },
  {
    "text": "example of what you can do with it is",
    "start": "603190",
    "end": "604690"
  },
  {
    "text": "let's say you click a log in one of the",
    "start": "604690",
    "end": "607089"
  },
  {
    "text": "spans you can configure it to take you",
    "start": "607089",
    "end": "609339"
  },
  {
    "text": "to the logging system are you a company",
    "start": "609339",
    "end": "611230"
  },
  {
    "text": "like Cabana so you can actually search",
    "start": "611230",
    "end": "613690"
  },
  {
    "text": "for other related logs",
    "start": "613690",
    "end": "615339"
  },
  {
    "text": "another example is perhaps you could add",
    "start": "615339",
    "end": "617860"
  },
  {
    "text": "the add a tag to your span with the",
    "start": "617860",
    "end": "620740"
  },
  {
    "text": "build version that you're using and have",
    "start": "620740",
    "end": "623020"
  },
  {
    "text": "the contextual link directly link you to",
    "start": "623020",
    "end": "625360"
  },
  {
    "text": "the actual build so you can see the",
    "start": "625360",
    "end": "627250"
  },
  {
    "text": "latest changes or from the UI so this",
    "start": "627250",
    "end": "629980"
  },
  {
    "text": "feature has a lot of potential and we're",
    "start": "629980",
    "end": "631630"
  },
  {
    "text": "very interested in seeing what the",
    "start": "631630",
    "end": "633040"
  },
  {
    "text": "community can do with it ok cool and so",
    "start": "633040",
    "end": "636940"
  },
  {
    "text": "Yaeger also provides some knobs for",
    "start": "636940",
    "end": "639640"
  },
  {
    "text": "configuration for configuring",
    "start": "639640",
    "end": "642040"
  },
  {
    "text": "performance so if you believe that your",
    "start": "642040",
    "end": "644529"
  },
  {
    "text": "Cassandra can take more writes and your",
    "start": "644529",
    "end": "646720"
  },
  {
    "text": "because collectors are actually your",
    "start": "646720",
    "end": "648310"
  },
  {
    "text": "bottleneck you can either add more",
    "start": "648310",
    "end": "650170"
  },
  {
    "text": "collectors or you can configure the",
    "start": "650170",
    "end": "652029"
  },
  {
    "text": "number of workers and the queue size of",
    "start": "652029",
    "end": "653829"
  },
  {
    "text": "the individual collectors and yet expect",
    "start": "653829",
    "end": "656860"
  },
  {
    "text": "and extract more performance out of each",
    "start": "656860",
    "end": "658450"
  },
  {
    "text": "one of them rather than adding more",
    "start": "658450",
    "end": "660250"
  },
  {
    "text": "hosts and then increase the throughput",
    "start": "660250",
    "end": "661570"
  },
  {
    "text": "this way additionally you can do the",
    "start": "661570",
    "end": "664390"
  },
  {
    "text": "same thing at the agent",
    "start": "664390",
    "end": "665740"
  },
  {
    "text": "these are all configurations so we have",
    "start": "665740",
    "end": "668680"
  },
  {
    "text": "configurations at every level of the",
    "start": "668680",
    "end": "670330"
  },
  {
    "text": "architecture so you can easily find tune",
    "start": "670330",
    "end": "672460"
  },
  {
    "text": "the performance to fit your hardware",
    "start": "672460",
    "end": "674560"
  },
  {
    "text": "specifications these configurations here",
    "start": "674560",
    "end": "677440"
  },
  {
    "text": "that we listed I'll just just example",
    "start": "677440",
    "end": "681160"
  },
  {
    "text": "number of them but we also have a lot",
    "start": "681160",
    "end": "684160"
  },
  {
    "text": "more and our documentation provides more",
    "start": "684160",
    "end": "687190"
  },
  {
    "text": "knobs at your disposal so let's say",
    "start": "687190",
    "end": "690400"
  },
  {
    "text": "you're now running Jaeger and you",
    "start": "690400",
    "end": "691750"
  },
  {
    "text": "fine-tuned everything for your exact",
    "start": "691750",
    "end": "693190"
  },
  {
    "text": "needs and have it running how do you",
    "start": "693190",
    "end": "695110"
  },
  {
    "text": "observe that it's actually doing the",
    "start": "695110",
    "end": "696550"
  },
  {
    "text": "right thing so we expose metrics and we",
    "start": "696550",
    "end": "699430"
  },
  {
    "text": "are working on creating a generic graph",
    "start": "699430",
    "end": "701410"
  },
  {
    "text": "on a dashboard with graphs that we think",
    "start": "701410",
    "end": "703810"
  },
  {
    "text": "are representative of Yeager's health we",
    "start": "703810",
    "end": "706540"
  },
  {
    "text": "provide both a Prometheus and X far",
    "start": "706540",
    "end": "709360"
  },
  {
    "text": "metrics back in additionally each",
    "start": "709360",
    "end": "712060"
  },
  {
    "text": "component in the stack has its own",
    "start": "712060",
    "end": "714040"
  },
  {
    "text": "scraper or endpoint for metrics if you",
    "start": "714040",
    "end": "716200"
  },
  {
    "text": "want to do a quick spot check so for",
    "start": "716200",
    "end": "717940"
  },
  {
    "text": "example you could hit the collector at",
    "start": "717940",
    "end": "720100"
  },
  {
    "text": "port 14 2 6 8 and you can get all the",
    "start": "720100",
    "end": "723640"
  },
  {
    "text": "live metrics for the collector and that",
    "start": "723640",
    "end": "726340"
  },
  {
    "text": "is it for me and pretty will take over",
    "start": "726340",
    "end": "728380"
  },
  {
    "text": "and go over new features and our roadmap",
    "start": "728380",
    "end": "732660"
  },
  {
    "text": "thank you one for that introduction so",
    "start": "735180",
    "end": "737950"
  },
  {
    "text": "my part of the talk would be composed of",
    "start": "737950",
    "end": "740020"
  },
  {
    "text": "the new features and then we'd go over",
    "start": "740020",
    "end": "742180"
  },
  {
    "text": "the roadmap and then we'd have time for",
    "start": "742180",
    "end": "744070"
  },
  {
    "text": "Q&A at the end so here we go",
    "start": "744070",
    "end": "748300"
  },
  {
    "text": "so one of the things that we've",
    "start": "748300",
    "end": "749770"
  },
  {
    "text": "introduced asou of these new features",
    "start": "749770",
    "end": "751510"
  },
  {
    "text": "are out and released they've been at use",
    "start": "751510",
    "end": "754210"
  },
  {
    "text": "at uber for about an year some some such",
    "start": "754210",
    "end": "757120"
  },
  {
    "text": "and the first one is adaptive sampling",
    "start": "757120",
    "end": "760030"
  },
  {
    "text": "now in any given API any service you're",
    "start": "760030",
    "end": "763180"
  },
  {
    "text": "running you have differences in terms of",
    "start": "763180",
    "end": "765430"
  },
  {
    "text": "what traffic hits water endpoint what",
    "start": "765430",
    "end": "769480"
  },
  {
    "text": "that means is a get endpoint for a user",
    "start": "769480",
    "end": "772210"
  },
  {
    "text": "might get a lot more traffic than a post",
    "start": "772210",
    "end": "774370"
  },
  {
    "text": "endpoint now the problem with this is",
    "start": "774370",
    "end": "777760"
  },
  {
    "text": "that sampling works like this something",
    "start": "777760",
    "end": "779890"
  },
  {
    "text": "sampling is a decision to steal the",
    "start": "779890",
    "end": "782080"
  },
  {
    "text": "trace and it is taken at the first edge",
    "start": "782080",
    "end": "785920"
  },
  {
    "text": "so whenever the request comes to your",
    "start": "785920",
    "end": "789460"
  },
  {
    "text": "application a sampling decision is made",
    "start": "789460",
    "end": "791770"
  },
  {
    "text": "and this sampling decision is propagated",
    "start": "791770",
    "end": "793900"
  },
  {
    "text": "throughout your application so this is",
    "start": "793900",
    "end": "796540"
  },
  {
    "text": "made at the head and so far it's been",
    "start": "796540",
    "end": "798490"
  },
  {
    "text": "made as a call",
    "start": "798490",
    "end": "799379"
  },
  {
    "text": "in probability you might do it you might",
    "start": "799379",
    "end": "801359"
  },
  {
    "text": "say that sample one in every 10,000",
    "start": "801359",
    "end": "803879"
  },
  {
    "text": "traces or 10,000 requests so when you",
    "start": "803879",
    "end": "807359"
  },
  {
    "text": "are seeing a distribution like this",
    "start": "807359",
    "end": "808349"
  },
  {
    "text": "meaning one endpoint has lot more",
    "start": "808349",
    "end": "810989"
  },
  {
    "text": "traffic than another endpoint what ends",
    "start": "810989",
    "end": "814410"
  },
  {
    "text": "up happening is that you get lot more",
    "start": "814410",
    "end": "816449"
  },
  {
    "text": "traces for that endpoint that receives",
    "start": "816449",
    "end": "818489"
  },
  {
    "text": "more traffic and the endpoint that",
    "start": "818489",
    "end": "820079"
  },
  {
    "text": "receives less traffic has less traces so",
    "start": "820079",
    "end": "822869"
  },
  {
    "text": "you're collecting different amounts of",
    "start": "822869",
    "end": "824249"
  },
  {
    "text": "observability data based on the traffic",
    "start": "824249",
    "end": "826229"
  },
  {
    "text": "your application is receiving adaptive",
    "start": "826229",
    "end": "828569"
  },
  {
    "text": "sampling helps with that so adaptive",
    "start": "828569",
    "end": "832109"
  },
  {
    "text": "sampling works by setting a trial target",
    "start": "832109",
    "end": "834089"
  },
  {
    "text": "GPS so we do some magic talk to us like",
    "start": "834089",
    "end": "838499"
  },
  {
    "text": "do you figure out what that magic is",
    "start": "838499",
    "end": "840329"
  },
  {
    "text": "it's essentially a proportional integral",
    "start": "840329",
    "end": "842639"
  },
  {
    "text": "differential controller that takes in",
    "start": "842639",
    "end": "844979"
  },
  {
    "text": "the target key PS and the sample QPS and",
    "start": "844979",
    "end": "847369"
  },
  {
    "text": "dynamically figures out the sampling",
    "start": "847369",
    "end": "849539"
  },
  {
    "text": "probability and this is done fairly",
    "start": "849539",
    "end": "853529"
  },
  {
    "text": "quickly like it's updated every minute",
    "start": "853529",
    "end": "856169"
  },
  {
    "text": "or so and it's tunable how quickly you",
    "start": "856169",
    "end": "859139"
  },
  {
    "text": "want this up these updates and this will",
    "start": "859139",
    "end": "862559"
  },
  {
    "text": "lead to a constant sampling rate so that",
    "start": "862559",
    "end": "865019"
  },
  {
    "text": "you observability data per endpoint is",
    "start": "865019",
    "end": "867419"
  },
  {
    "text": "roughly the same the next thing that we",
    "start": "867419",
    "end": "871799"
  },
  {
    "text": "have introduced this asynchronous",
    "start": "871799",
    "end": "873149"
  },
  {
    "text": "injection so this feature essentially",
    "start": "873149",
    "end": "876659"
  },
  {
    "text": "puts Kafka queue between the collectors",
    "start": "876659",
    "end": "881100"
  },
  {
    "text": "and the writers so we are focusing on",
    "start": "881100",
    "end": "884579"
  },
  {
    "text": "this part of the architecture right in",
    "start": "884579",
    "end": "886679"
  },
  {
    "text": "the middle so we've added calf kind",
    "start": "886679",
    "end": "888389"
  },
  {
    "text": "between so what this allows us to do is",
    "start": "888389",
    "end": "891499"
  },
  {
    "text": "when we get load spikes of this nature",
    "start": "891499",
    "end": "894119"
  },
  {
    "text": "we just put it into Kafka and we read",
    "start": "894119",
    "end": "897600"
  },
  {
    "text": "out at nearly a constant rate so if",
    "start": "897600",
    "end": "900569"
  },
  {
    "text": "you're running a storage engine like",
    "start": "900569",
    "end": "901919"
  },
  {
    "text": "Cassandra",
    "start": "901919",
    "end": "902519"
  },
  {
    "text": "which can only take a limited amount of",
    "start": "902519",
    "end": "905909"
  },
  {
    "text": "QPS in the sense the storage engine",
    "start": "905909",
    "end": "908549"
  },
  {
    "text": "itself doesn't have any protection from",
    "start": "908549",
    "end": "910529"
  },
  {
    "text": "load spikes this architecture enables",
    "start": "910529",
    "end": "912869"
  },
  {
    "text": "you to control the rate at which you are",
    "start": "912869",
    "end": "914939"
  },
  {
    "text": "actually writing to your storage you can",
    "start": "914939",
    "end": "917339"
  },
  {
    "text": "control the amount of ingest instances",
    "start": "917339",
    "end": "920549"
  },
  {
    "text": "you can also separate it out so that you",
    "start": "920549",
    "end": "923069"
  },
  {
    "text": "write only some of the spans into",
    "start": "923069",
    "end": "925549"
  },
  {
    "text": "Cassandra or like you can do lots of",
    "start": "925549",
    "end": "927989"
  },
  {
    "text": "advanced logic on the receiving end so",
    "start": "927989",
    "end": "930359"
  },
  {
    "text": "as of now like we split our rights to",
    "start": "930359",
    "end": "933350"
  },
  {
    "text": "span rights and to index rights so these",
    "start": "933350",
    "end": "936050"
  },
  {
    "text": "are handled by separate processes and we",
    "start": "936050",
    "end": "938330"
  },
  {
    "text": "tune them independently at uber so this",
    "start": "938330",
    "end": "942080"
  },
  {
    "text": "is also out and released the third",
    "start": "942080",
    "end": "944960"
  },
  {
    "text": "feature is trace comparisons so if you",
    "start": "944960",
    "end": "949790"
  },
  {
    "text": "recall from the demo yesterday we have",
    "start": "949790",
    "end": "951590"
  },
  {
    "text": "like a timeline view of traces so we've",
    "start": "951590",
    "end": "954590"
  },
  {
    "text": "taken that concept and advanced it a bit",
    "start": "954590",
    "end": "957110"
  },
  {
    "text": "and we have views like this so here",
    "start": "957110",
    "end": "961340"
  },
  {
    "text": "you're looking at comparisons between",
    "start": "961340",
    "end": "962930"
  },
  {
    "text": "two different traces boxes that are in",
    "start": "962930",
    "end": "966020"
  },
  {
    "text": "red boxes or services which didn't occur",
    "start": "966020",
    "end": "969860"
  },
  {
    "text": "in the first trace but are present in",
    "start": "969860",
    "end": "971630"
  },
  {
    "text": "the second trace and on green and sorry",
    "start": "971630",
    "end": "974990"
  },
  {
    "text": "it's why she wears a red are the trace",
    "start": "974990",
    "end": "977150"
  },
  {
    "text": "other services that have been removed",
    "start": "977150",
    "end": "979160"
  },
  {
    "text": "and green are the services that have",
    "start": "979160",
    "end": "981050"
  },
  {
    "text": "been added services and endpoints so at",
    "start": "981050",
    "end": "983720"
  },
  {
    "text": "a glance when you take two traces you",
    "start": "983720",
    "end": "985940"
  },
  {
    "text": "can compare the shapes of these traces",
    "start": "985940",
    "end": "987770"
  },
  {
    "text": "to see that whether they've been any new",
    "start": "987770",
    "end": "990230"
  },
  {
    "text": "requests made by your architecture so in",
    "start": "990230",
    "end": "992930"
  },
  {
    "text": "this particular example we see a lot of",
    "start": "992930",
    "end": "994880"
  },
  {
    "text": "green at the bottom which says that this",
    "start": "994880",
    "end": "997100"
  },
  {
    "text": "trace contains new calls that were not",
    "start": "997100",
    "end": "998960"
  },
  {
    "text": "made in the previous trace and this view",
    "start": "998960",
    "end": "1000880"
  },
  {
    "text": "allows you to visualize that in a really",
    "start": "1000880",
    "end": "1003130"
  },
  {
    "text": "user-friendly manner also the other",
    "start": "1003130",
    "end": "1009400"
  },
  {
    "text": "thing you could do is you could look at",
    "start": "1009400",
    "end": "1011050"
  },
  {
    "text": "trace durations so instead of looking at",
    "start": "1011050",
    "end": "1013360"
  },
  {
    "text": "just the number of calls that have been",
    "start": "1013360",
    "end": "1015850"
  },
  {
    "text": "added or removed we can look at the",
    "start": "1015850",
    "end": "1018280"
  },
  {
    "text": "duration differences like in this",
    "start": "1018280",
    "end": "1020350"
  },
  {
    "text": "particular case the highlighted node has",
    "start": "1020350",
    "end": "1022600"
  },
  {
    "text": "an additional 815 milliseconds and we",
    "start": "1022600",
    "end": "1026170"
  },
  {
    "text": "also do a percentage duration of that so",
    "start": "1026170",
    "end": "1028839"
  },
  {
    "text": "these are comparison tools for traces",
    "start": "1028840",
    "end": "1031800"
  },
  {
    "text": "finally we also have a yeegar",
    "start": "1031800",
    "end": "1034750"
  },
  {
    "text": "operator so it makes your deploys and",
    "start": "1034750",
    "end": "1036939"
  },
  {
    "text": "updates into cuban entities really easy",
    "start": "1036940",
    "end": "1041490"
  },
  {
    "text": "so next we go on to the roadmap so one",
    "start": "1041490",
    "end": "1046270"
  },
  {
    "text": "of the things that I mentioned earlier",
    "start": "1046270",
    "end": "1047800"
  },
  {
    "text": "with adaptive sampling is that the",
    "start": "1047800",
    "end": "1049540"
  },
  {
    "text": "sampling decision is made when a request",
    "start": "1049540",
    "end": "1052030"
  },
  {
    "text": "hits your service so we want to make it",
    "start": "1052030",
    "end": "1056050"
  },
  {
    "text": "such that this sampling decision is not",
    "start": "1056050",
    "end": "1058030"
  },
  {
    "text": "made at the beginning but it's made at",
    "start": "1058030",
    "end": "1060130"
  },
  {
    "text": "the end so what this allows us to do is",
    "start": "1060130",
    "end": "1062950"
  },
  {
    "text": "collect all traces in all spans forgiven",
    "start": "1062950",
    "end": "1065350"
  },
  {
    "text": "trees and then decide whether we want",
    "start": "1065350",
    "end": "1067420"
  },
  {
    "text": "to stow the trace a lot so instead of",
    "start": "1067420",
    "end": "1069700"
  },
  {
    "text": "making the decision at the beginning and",
    "start": "1069700",
    "end": "1071470"
  },
  {
    "text": "throwing away spans that we do not need",
    "start": "1071470",
    "end": "1073630"
  },
  {
    "text": "like oh here we collect all the spans",
    "start": "1073630",
    "end": "1075520"
  },
  {
    "text": "and then we figure out based on any sort",
    "start": "1075520",
    "end": "1078220"
  },
  {
    "text": "of heuristics so this is on the roadmap",
    "start": "1078220",
    "end": "1081690"
  },
  {
    "text": "data pipeline is something we are using",
    "start": "1081690",
    "end": "1084010"
  },
  {
    "text": "we haven't yet open sourced it we use it",
    "start": "1084010",
    "end": "1086170"
  },
  {
    "text": "internally so data pipeline is just",
    "start": "1086170",
    "end": "1089350"
  },
  {
    "text": "reading spans from Kafka we create",
    "start": "1089350",
    "end": "1091990"
  },
  {
    "text": "recession eyes to spans into traces and",
    "start": "1091990",
    "end": "1094960"
  },
  {
    "text": "then we run algorithms on it to figure",
    "start": "1094960",
    "end": "1097420"
  },
  {
    "text": "out interesting data so as of now we do",
    "start": "1097420",
    "end": "1100090"
  },
  {
    "text": "dependency diagrams and on the roadmap",
    "start": "1100090",
    "end": "1103030"
  },
  {
    "text": "is latency histograms so if you're",
    "start": "1103030",
    "end": "1105910"
  },
  {
    "text": "interested in a dependency diagram this",
    "start": "1105910",
    "end": "1107980"
  },
  {
    "text": "is what it looks like for uber so we",
    "start": "1107980",
    "end": "1110710"
  },
  {
    "text": "have about 3000 micro services so it's a",
    "start": "1110710",
    "end": "1114460"
  },
  {
    "text": "large amount of data like zoomed out so",
    "start": "1114460",
    "end": "1120149"
  },
  {
    "text": "another thing we are working on we have",
    "start": "1121020",
    "end": "1123370"
  },
  {
    "text": "an open pool request for this an open",
    "start": "1123370",
    "end": "1125920"
  },
  {
    "text": "issue is the ability to store and",
    "start": "1125920",
    "end": "1129250"
  },
  {
    "text": "retrieve incomplete spans so in a this",
    "start": "1129250",
    "end": "1131860"
  },
  {
    "text": "architecture today spans are only",
    "start": "1131860",
    "end": "1133780"
  },
  {
    "text": "written to storage when they are",
    "start": "1133780",
    "end": "1135100"
  },
  {
    "text": "complete so if an application is",
    "start": "1135100",
    "end": "1136930"
  },
  {
    "text": "processing something for a very long",
    "start": "1136930",
    "end": "1138550"
  },
  {
    "text": "time we do not get any observability",
    "start": "1138550",
    "end": "1140800"
  },
  {
    "text": "information from that application until",
    "start": "1140800",
    "end": "1142630"
  },
  {
    "text": "that process is completed imagine",
    "start": "1142630",
    "end": "1144880"
  },
  {
    "text": "something that imagine an application",
    "start": "1144880",
    "end": "1147400"
  },
  {
    "text": "that runs over multiple days and mate",
    "start": "1147400",
    "end": "1149890"
  },
  {
    "text": "requests over multiple days now these",
    "start": "1149890",
    "end": "1151810"
  },
  {
    "text": "sort of workflows don't really show up",
    "start": "1151810",
    "end": "1153940"
  },
  {
    "text": "in the yaga UI today until it is",
    "start": "1153940",
    "end": "1156400"
  },
  {
    "text": "complete and enabling incomplete span",
    "start": "1156400",
    "end": "1159340"
  },
  {
    "text": "support allows us to visualize this as",
    "start": "1159340",
    "end": "1161440"
  },
  {
    "text": "and when they are happening finally if",
    "start": "1161440",
    "end": "1165130"
  },
  {
    "text": "we go into this section about project",
    "start": "1165130",
    "end": "1166600"
  },
  {
    "text": "and community it's mainly a bunch of",
    "start": "1166600",
    "end": "1168850"
  },
  {
    "text": "links it's it's fairly simple most of",
    "start": "1168850",
    "end": "1171340"
  },
  {
    "text": "our code isn't go all of the clients are",
    "start": "1171340",
    "end": "1173680"
  },
  {
    "text": "in the specific client languages the",
    "start": "1173680",
    "end": "1175600"
  },
  {
    "text": "data pipeline is in Java so we look for",
    "start": "1175600",
    "end": "1178570"
  },
  {
    "text": "100% test coverage and signed commits",
    "start": "1178570",
    "end": "1180940"
  },
  {
    "text": "all of this is on our github page so",
    "start": "1180940",
    "end": "1183340"
  },
  {
    "text": "feel free and these are these are useful",
    "start": "1183340",
    "end": "1186700"
  },
  {
    "text": "links finally QA",
    "start": "1186700",
    "end": "1191399"
  },
  {
    "text": "that down on the side if you want to ask",
    "start": "1209130",
    "end": "1210870"
  },
  {
    "text": "me questions on the side so you have you",
    "start": "1210870",
    "end": "1213330"
  },
  {
    "text": "work on like me and Warren work on you",
    "start": "1213330",
    "end": "1215310"
  },
  {
    "text": "get full-time so any any sort of gnarly",
    "start": "1215310",
    "end": "1218640"
  },
  {
    "text": "questions you have be happy to answer it",
    "start": "1218640",
    "end": "1222200"
  },
  {
    "text": "yes I said Niko a new home got now a",
    "start": "1222200",
    "end": "1240780"
  },
  {
    "text": "twenty one weights Johnson oh sure yes",
    "start": "1240780",
    "end": "1279380"
  },
  {
    "text": "so in the future we're gonna provide a",
    "start": "1282410",
    "end": "1285540"
  },
  {
    "text": "new configuration so that you can just",
    "start": "1285540",
    "end": "1288150"
  },
  {
    "text": "use that then you just set a one target",
    "start": "1288150",
    "end": "1290760"
  },
  {
    "text": "QPS right and that target QPS is set for",
    "start": "1290760",
    "end": "1293790"
  },
  {
    "text": "all your services so that all operations",
    "start": "1293790",
    "end": "1296160"
  },
  {
    "text": "will be sampled at that QPS right and",
    "start": "1296160",
    "end": "1298650"
  },
  {
    "text": "that's all you have to provide in the",
    "start": "1298650",
    "end": "1299880"
  },
  {
    "text": "future so it won't be a static anymore",
    "start": "1299880",
    "end": "1302370"
  },
  {
    "text": "it'll be dynamic but you don't have to",
    "start": "1302370",
    "end": "1303990"
  },
  {
    "text": "provide per service samples I just saw",
    "start": "1303990",
    "end": "1317730"
  },
  {
    "text": "because from your diagram you have a",
    "start": "1317730",
    "end": "1319650"
  },
  {
    "text": "like Jagger stream ingestion",
    "start": "1319650",
    "end": "1323850"
  },
  {
    "text": "most of the time took today we talked",
    "start": "1323850",
    "end": "1325620"
  },
  {
    "text": "about a lot of the in gesture for the",
    "start": "1325620",
    "end": "1327540"
  },
  {
    "text": "streaming like what's the purpose for",
    "start": "1327540",
    "end": "1330390"
  },
  {
    "text": "that streaming because that's a new",
    "start": "1330390",
    "end": "1331790"
  },
  {
    "text": "architecture compared to the old one so",
    "start": "1331790",
    "end": "1334770"
  },
  {
    "text": "what's that streaming can be used like",
    "start": "1334770",
    "end": "1336510"
  },
  {
    "text": "can we do like back and forth to search",
    "start": "1336510",
    "end": "1339480"
  },
  {
    "text": "different streams for something",
    "start": "1339480",
    "end": "1341730"
  },
  {
    "text": "I could take that so the streaming",
    "start": "1341730",
    "end": "1344070"
  },
  {
    "text": "essentially reads from the Kafka topic",
    "start": "1344070",
    "end": "1346440"
  },
  {
    "text": "and so we add the data Jaeger output",
    "start": "1346440",
    "end": "1349860"
  },
  {
    "text": "expands so full like it converts bands",
    "start": "1349860",
    "end": "1353790"
  },
  {
    "text": "into traces a trace is a collection of",
    "start": "1353790",
    "end": "1355980"
  },
  {
    "text": "spans but is only forgiven requests now",
    "start": "1355980",
    "end": "1358740"
  },
  {
    "text": "that is difficult to do in a non",
    "start": "1358740",
    "end": "1360600"
  },
  {
    "text": "streaming architecture because we do not",
    "start": "1360600",
    "end": "1362100"
  },
  {
    "text": "know when the request completes so like",
    "start": "1362100",
    "end": "1365130"
  },
  {
    "text": "we do not data might still be arriving",
    "start": "1365130",
    "end": "1367050"
  },
  {
    "text": "so we use the streaming job firstly to",
    "start": "1367050",
    "end": "1369000"
  },
  {
    "text": "convert this pans into traces and once",
    "start": "1369000",
    "end": "1372180"
  },
  {
    "text": "we do that we can run any sort of",
    "start": "1372180",
    "end": "1373860"
  },
  {
    "text": "algorithms on that trace itself so as of",
    "start": "1373860",
    "end": "1377130"
  },
  {
    "text": "now what we do is like two dependencies",
    "start": "1377130",
    "end": "1379050"
  },
  {
    "text": "so what that means is we compute service",
    "start": "1379050",
    "end": "1382350"
  },
  {
    "text": "a called service B service we call",
    "start": "1382350",
    "end": "1384150"
  },
  {
    "text": "service C and then we aggregated so we",
    "start": "1384150",
    "end": "1386280"
  },
  {
    "text": "get a call count so we can do things",
    "start": "1386280",
    "end": "1387960"
  },
  {
    "text": "like in in one hour how many times that",
    "start": "1387960",
    "end": "1391020"
  },
  {
    "text": "service a call service B and we can run",
    "start": "1391020",
    "end": "1395220"
  },
  {
    "text": "any sort of heuristic jobs of that",
    "start": "1395220",
    "end": "1397020"
  },
  {
    "text": "nature you can reset the stream in time",
    "start": "1397020",
    "end": "1399990"
  },
  {
    "text": "but we haven't you we haven't yet",
    "start": "1399990",
    "end": "1402810"
  },
  {
    "text": "written any code that does that or makes",
    "start": "1402810",
    "end": "1405000"
  },
  {
    "text": "use of that functionality like because",
    "start": "1405000",
    "end": "1407370"
  },
  {
    "text": "we are reading from Kafka you can say",
    "start": "1407370",
    "end": "1408780"
  },
  {
    "text": "read spans from some previous time or",
    "start": "1408780",
    "end": "1412260"
  },
  {
    "text": "any such comprehensive like that is like",
    "start": "1412260",
    "end": "1415710"
  },
  {
    "text": "the video stream I can go like some like",
    "start": "1415710",
    "end": "1420870"
  },
  {
    "text": "old information search I can kind of",
    "start": "1420870",
    "end": "1423270"
  },
  {
    "text": "compare them without going to the",
    "start": "1423270",
    "end": "1425130"
  },
  {
    "text": "database itself right if you really want",
    "start": "1425130",
    "end": "1428550"
  },
  {
    "text": "to you can but we don't really do that",
    "start": "1428550",
    "end": "1430680"
  },
  {
    "text": "today because most of the times you're",
    "start": "1430680",
    "end": "1432720"
  },
  {
    "text": "right you're reading from cough can",
    "start": "1432720",
    "end": "1434010"
  },
  {
    "text": "you've already written it down but if",
    "start": "1434010",
    "end": "1435480"
  },
  {
    "text": "your database goes away oh it's dead you",
    "start": "1435480",
    "end": "1437940"
  },
  {
    "text": "can always reset and load it back thank",
    "start": "1437940",
    "end": "1441210"
  },
  {
    "text": "you",
    "start": "1441210",
    "end": "1443360"
  },
  {
    "text": "[Music]",
    "start": "1455420",
    "end": "1458489"
  },
  {
    "text": "I just may be interested in say",
    "start": "1458919",
    "end": "1463190"
  },
  {
    "text": "combining your red part with the UI and",
    "start": "1463190",
    "end": "1467690"
  },
  {
    "text": "I want to ingest my data like confirm is",
    "start": "1467690",
    "end": "1471409"
  },
  {
    "text": "your date format so is that possible",
    "start": "1471409",
    "end": "1474909"
  },
  {
    "text": "could you repeat the question please",
    "start": "1474909",
    "end": "1477049"
  },
  {
    "text": "I mean maybe I can produce my own like",
    "start": "1477049",
    "end": "1483610"
  },
  {
    "text": "informations and I do myself to inject",
    "start": "1484210",
    "end": "1487700"
  },
  {
    "text": "those data into Kafka then I want to use",
    "start": "1487700",
    "end": "1490610"
  },
  {
    "text": "your I mean the right part of your you",
    "start": "1490610",
    "end": "1493610"
  },
  {
    "text": "and also analysis part so I mean is that",
    "start": "1493610",
    "end": "1497389"
  },
  {
    "text": "possible as long as you write it in the",
    "start": "1497389",
    "end": "1500330"
  },
  {
    "text": "same format so the format meaning the",
    "start": "1500330",
    "end": "1504559"
  },
  {
    "text": "data model that one showed earlier so as",
    "start": "1504559",
    "end": "1506960"
  },
  {
    "text": "long as you follow that data model and",
    "start": "1506960",
    "end": "1508940"
  },
  {
    "text": "you supply deserialize err we should be",
    "start": "1508940",
    "end": "1511760"
  },
  {
    "text": "able to do it so the serialization and",
    "start": "1511760",
    "end": "1514700"
  },
  {
    "text": "deserialization is pluggable so it's an",
    "start": "1514700",
    "end": "1516679"
  },
  {
    "text": "interface you can add whatever you want",
    "start": "1516679",
    "end": "1518480"
  },
  {
    "text": "and if you are able to write a DC",
    "start": "1518480",
    "end": "1521059"
  },
  {
    "text": "realizer",
    "start": "1521059",
    "end": "1521570"
  },
  {
    "text": "and then you can just put it in whatever",
    "start": "1521570",
    "end": "1523700"
  },
  {
    "text": "format you want and yeah the other",
    "start": "1523700",
    "end": "1526070"
  },
  {
    "text": "pipeline should work thank you I wonder",
    "start": "1526070",
    "end": "1533690"
  },
  {
    "text": "if we can take the trays with some more",
    "start": "1533690",
    "end": "1537019"
  },
  {
    "text": "tacking you can tag individual spans the",
    "start": "1537019",
    "end": "1541370"
  },
  {
    "text": "tags are tied on the span itself and the",
    "start": "1541370",
    "end": "1543409"
  },
  {
    "text": "collection of spans is the trees the on",
    "start": "1543409",
    "end": "1546139"
  },
  {
    "text": "the trace itself like I I'm not sure",
    "start": "1546139",
    "end": "1548630"
  },
  {
    "text": "what tagging is like we don't we don't",
    "start": "1548630",
    "end": "1551269"
  },
  {
    "text": "yet to that but you own the individual",
    "start": "1551269",
    "end": "1553909"
  },
  {
    "text": "spans you can add as many tags as you",
    "start": "1553909",
    "end": "1555830"
  },
  {
    "text": "want",
    "start": "1555830",
    "end": "1558010"
  },
  {
    "text": "hey hey",
    "start": "1565520",
    "end": "1568529"
  },
  {
    "text": "so when you talk about like moving the",
    "start": "1568529",
    "end": "1570240"
  },
  {
    "text": "like simple race thing to the end of the",
    "start": "1570240",
    "end": "1572760"
  },
  {
    "text": "pipeline yeah certainly like new policy",
    "start": "1572760",
    "end": "1575429"
  },
  {
    "text": "you have to tease out whether you want",
    "start": "1575429",
    "end": "1576840"
  },
  {
    "text": "to keep this man or not yeah pretty much",
    "start": "1576840",
    "end": "1579059"
  },
  {
    "text": "so it's still very much in the Alpha",
    "start": "1579059",
    "end": "1581460"
  },
  {
    "text": "sort of like weird we haven't yet",
    "start": "1581460",
    "end": "1583409"
  },
  {
    "text": "started work on it but ideally we'd have",
    "start": "1583409",
    "end": "1585960"
  },
  {
    "text": "users determine whatever they want so",
    "start": "1585960",
    "end": "1588360"
  },
  {
    "text": "any sort of policy so if you want to do",
    "start": "1588360",
    "end": "1590279"
  },
  {
    "text": "things like stir this pan if there's an",
    "start": "1590279",
    "end": "1593549"
  },
  {
    "text": "editor or store this pan if this service",
    "start": "1593549",
    "end": "1595440"
  },
  {
    "text": "was involved and the latency was greater",
    "start": "1595440",
    "end": "1597960"
  },
  {
    "text": "than 400 milliseconds or any sort of",
    "start": "1597960",
    "end": "1600029"
  },
  {
    "text": "very fine grained settings you should be",
    "start": "1600029",
    "end": "1602669"
  },
  {
    "text": "able to apply that policy because out",
    "start": "1602669",
    "end": "1604860"
  },
  {
    "text": "works is it collects everything and then",
    "start": "1604860",
    "end": "1606809"
  },
  {
    "text": "the policies evaluated before story",
    "start": "1606809",
    "end": "1608840"
  },
  {
    "text": "thank you questions is what's your",
    "start": "1608840",
    "end": "1619799"
  },
  {
    "text": "recommended way to installing the",
    "start": "1619799",
    "end": "1622020"
  },
  {
    "text": "plugger now I said no we have an",
    "start": "1622020",
    "end": "1624809"
  },
  {
    "text": "official hem check and operator I would",
    "start": "1624809",
    "end": "1634140"
  },
  {
    "text": "recommend the Jaeger operator I don't",
    "start": "1634140",
    "end": "1639690"
  },
  {
    "text": "have a reason to recommend it though but",
    "start": "1639690",
    "end": "1642779"
  },
  {
    "text": "I think that's what most users are using",
    "start": "1642779",
    "end": "1647120"
  },
  {
    "text": "cool",
    "start": "1654919",
    "end": "1657200"
  },
  {
    "text": "step off to the side and you can come in",
    "start": "1657200",
    "end": "1658940"
  },
  {
    "text": "you can ask questions we have begun to",
    "start": "1658940",
    "end": "1661309"
  },
  {
    "text": "hang out here for the next 5-10 minutes",
    "start": "1661309",
    "end": "1664990"
  }
]
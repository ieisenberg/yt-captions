[
  {
    "start": "0",
    "end": "0"
  },
  {
    "text": "so who are we and Ramaiah I'm a structural engineer at pivotal my name",
    "start": "570",
    "end": "7020"
  },
  {
    "text": "is Mariam I'm also a software engineer at pivotal so what is release",
    "start": "7020",
    "end": "12480"
  },
  {
    "text": "engineering in our context so our product is made up of many different",
    "start": "12480",
    "end": "17550"
  },
  {
    "text": "teams and each of these teams contributes specific parts of the code",
    "start": "17550",
    "end": "22560"
  },
  {
    "text": "to us and then the release engineering team takes the scored and runs them",
    "start": "22560",
    "end": "28650"
  },
  {
    "text": "through pipelines which are called test Suites also called a stress test Suites and then base them into a product and",
    "start": "28650",
    "end": "35420"
  },
  {
    "text": "serves it to the customer what does this mean in terms of kubernetes we are",
    "start": "35420",
    "end": "42270"
  },
  {
    "text": "talking about different integrations like harbor at CD & Flu nd etc so teams",
    "start": "42270",
    "end": "47670"
  },
  {
    "text": "integrate with these and share code with us and then the rail and team runs them",
    "start": "47670",
    "end": "53610"
  },
  {
    "text": "through pipelines or test Suites an example of which is on the slide there",
    "start": "53610",
    "end": "59120"
  },
  {
    "text": "to create a product called pivotal container service and then that's the one that we shipped to customers few",
    "start": "59120",
    "end": "67560"
  },
  {
    "start": "66000",
    "end": "66000"
  },
  {
    "text": "things before we proceed what is concourse concourse is a open",
    "start": "67560",
    "end": "74040"
  },
  {
    "text": "source tool it's a way in which you can write tests into different jobs you can",
    "start": "74040",
    "end": "79890"
  },
  {
    "text": "combine them into different jobs and then create a pipeline this is an example of a pipeline and you can have",
    "start": "79890",
    "end": "85590"
  },
  {
    "text": "different jobs sequenced one after another and you can have light resources",
    "start": "85590",
    "end": "91049"
  },
  {
    "text": "resource types and inputs and outputs to this job so it's just a way of having",
    "start": "91049",
    "end": "96630"
  },
  {
    "text": "your test suite it's anonymous to that and it's a pretty cool tool you should",
    "start": "96630",
    "end": "101880"
  },
  {
    "text": "check it out at Concord CI dot all will be referencing this frequently through our talk few more terminologies that we",
    "start": "101880",
    "end": "110610"
  },
  {
    "start": "108000",
    "end": "108000"
  },
  {
    "text": "will be using interchangeably in our talk when we save fly we mean running a",
    "start": "110610",
    "end": "117540"
  },
  {
    "text": "pipeline or running a test suite a pipeline is equal into a test suite and a lock implies an environment or a test",
    "start": "117540",
    "end": "125130"
  },
  {
    "text": "bed and a pool is a group of environments which are configured the",
    "start": "125130",
    "end": "130890"
  },
  {
    "text": "same so we're going to tell the story of our",
    "start": "130890",
    "end": "136020"
  },
  {
    "text": "release engineering team and our story starts in April 2018 Anu team had just",
    "start": "136020",
    "end": "141599"
  },
  {
    "text": "started and they wanted a fresh start and we were facing two main problems we",
    "start": "141599",
    "end": "146849"
  },
  {
    "text": "were shipping too slowly and we had a lot of bugs in our code so naturally we asked ourselves why is",
    "start": "146849",
    "end": "154620"
  },
  {
    "text": "this the state that we're in right now well one of the things is that all of",
    "start": "154620",
    "end": "160110"
  },
  {
    "text": "the scripts and things that we were using had worked at a certain point but the teams that were integrating with",
    "start": "160110",
    "end": "165150"
  },
  {
    "text": "kubernetes have been growing and we've been supporting more and more integrations the size of this rel inch",
    "start": "165150",
    "end": "170160"
  },
  {
    "text": "team itself had stayed the same so we no longer had enough people to keep up with all of the work and we had done a lot of",
    "start": "170160",
    "end": "176190"
  },
  {
    "text": "things super like duct tape so now we had a lot of technical debt that we had accrued and this was resulting in us",
    "start": "176190",
    "end": "182519"
  },
  {
    "text": "releasing slowly and so our customers were unhappy we broke it down into these",
    "start": "182519",
    "end": "188599"
  },
  {
    "text": "particular issues that we had we had written a lot of scripts that were not being tested we had a lot of llam√≥ that",
    "start": "188599",
    "end": "195540"
  },
  {
    "text": "was duplicated everywhere our environments that were being used for tests were in high demand and we didn't",
    "start": "195540",
    "end": "201660"
  },
  {
    "text": "have enough of them our pipelines were taking way too long we didn't have a varied well-defined integration process",
    "start": "201660",
    "end": "208319"
  },
  {
    "text": "and we still needed to sort out our open source licensing so the first thing that",
    "start": "208319",
    "end": "217380"
  },
  {
    "text": "we want to talk about is no testing one of the problems that we had so why",
    "start": "217380",
    "end": "222720"
  },
  {
    "start": "222000",
    "end": "222000"
  },
  {
    "text": "didn't we have any testing in place when we look closely we found that we had a lot of batch scripts written in order to",
    "start": "222720",
    "end": "229319"
  },
  {
    "text": "do our testing and bash is really hard to you know test drive or even just to",
    "start": "229319",
    "end": "235380"
  },
  {
    "text": "write tests even after you write the script it's also intermixed with Linux",
    "start": "235380",
    "end": "240870"
  },
  {
    "text": "commands here and there so it's hard to notice bugs it's hard in general to just",
    "start": "240870",
    "end": "245880"
  },
  {
    "text": "program in in bash so we decided to",
    "start": "245880",
    "end": "251430"
  },
  {
    "text": "tackle that first and as a team we decided to change it into programming languages so what could we go for it the",
    "start": "251430",
    "end": "258810"
  },
  {
    "text": "two options were either Ruby Ruby and go lang and the reasons for these were",
    "start": "258810",
    "end": "265200"
  },
  {
    "text": "because the team prior experience in these areas there",
    "start": "265200",
    "end": "270750"
  },
  {
    "text": "are a lot of Ruby experience in the team and there were a lot of go line experience in the team also Ruby is more",
    "start": "270750",
    "end": "277199"
  },
  {
    "text": "testable or test-driven and golang is also useful for concurrency and",
    "start": "277199",
    "end": "282870"
  },
  {
    "text": "parallelism which we could really make use of so here is an example of how our",
    "start": "282870",
    "end": "289740"
  },
  {
    "text": "scripts looked before for example we had an environment metadata file and let's",
    "start": "289740",
    "end": "296009"
  },
  {
    "text": "say we had to connect to this environment right so we had all of these properties in maybe like Yammer and we",
    "start": "296009",
    "end": "301680"
  },
  {
    "text": "had to read through it and find out the proxy and the username and password in order to connect to it and this is how",
    "start": "301680",
    "end": "308069"
  },
  {
    "text": "we were writing it in bash and as you can see there's like yq-- or awk I said and there are other commands that we",
    "start": "308069",
    "end": "314159"
  },
  {
    "text": "were using interchangeably this as you can see is untestable because we have to",
    "start": "314159",
    "end": "320729"
  },
  {
    "text": "test we have a marker a lot of things for these so then we decided to do bash",
    "start": "320729",
    "end": "326219"
  },
  {
    "text": "in Ruby and this was an intermediate step so what we were doing was reading the",
    "start": "326219",
    "end": "331889"
  },
  {
    "text": "environment metadata by opening files reading it into a hash and then getting",
    "start": "331889",
    "end": "338430"
  },
  {
    "text": "properties out of it doing whatever processing we wanted to do and then closing the file and this was happening",
    "start": "338430",
    "end": "345240"
  },
  {
    "text": "pretty much everywhere in wherever we were referencing the environment for testing this is somewhat testable like",
    "start": "345240",
    "end": "353699"
  },
  {
    "text": "you can still mark out a few things and get away with it but not completely testable like for example there's like",
    "start": "353699",
    "end": "359250"
  },
  {
    "text": "splitting on colon and then expecting that the first array of an item is going to be present etc so it's quite",
    "start": "359250",
    "end": "365310"
  },
  {
    "text": "error-prone so we decided to completely change it a ruby and what we mean by",
    "start": "365310",
    "end": "371819"
  },
  {
    "text": "this is try to think of the the things that you manipulate in your test Suites",
    "start": "371819",
    "end": "377009"
  },
  {
    "text": "as objects that you pass around for example the environment environment",
    "start": "377009",
    "end": "382440"
  },
  {
    "text": "metadata could actually be a lock file class which hide properties that you can",
    "start": "382440",
    "end": "388169"
  },
  {
    "text": "fill in and this is super testable in Ruby so we try to think of it as in an",
    "start": "388169",
    "end": "393870"
  },
  {
    "text": "abstract way and started creating classes for log files and pipelines and it was easier this way to test driver",
    "start": "393870",
    "end": "401899"
  },
  {
    "text": "all right so the next problem that our team was facing was having a lot of",
    "start": "402380",
    "end": "407670"
  },
  {
    "text": "llamo duplication doing a quick Google search showed that everyone else was",
    "start": "407670",
    "end": "413400"
  },
  {
    "text": "also struggling with the same problem so",
    "start": "413400",
    "end": "418710"
  },
  {
    "start": "418000",
    "end": "418000"
  },
  {
    "text": "why is duplicate llamo a problem so we were getting a lot of llamo from",
    "start": "418710",
    "end": "423740"
  },
  {
    "text": "kubernetes configuration in general and our CI CD tool that we were using Concours is completely configured by",
    "start": "423740",
    "end": "430650"
  },
  {
    "text": "llamo so we were dealing with a lot of llamo that looked very similar and was slightly different and the process of",
    "start": "430650",
    "end": "437610"
  },
  {
    "text": "looking at a bunch of files and trying to figure out what was different between these files that created a lot of",
    "start": "437610",
    "end": "443460"
  },
  {
    "text": "cognitive overhead the second part is that we were as part of our process we",
    "start": "443460",
    "end": "449100"
  },
  {
    "text": "were copying and pasting a lot of files and then we would just change one or two keys and sometimes our team which is",
    "start": "449100",
    "end": "454860"
  },
  {
    "text": "human like forgot to go back and change these keys so we had like mistakes like that the team was very unhappy",
    "start": "454860",
    "end": "461670"
  },
  {
    "text": "anytime we needed to add pipelines modify pipelines to do anything everyone got very sad about it and it's always",
    "start": "461670",
    "end": "467250"
  },
  {
    "text": "important to try to have happy tubs I was taking a lot of time to make these changes and because we were sometimes",
    "start": "467250",
    "end": "474350"
  },
  {
    "text": "copying and pasting and forgetting things or were indenting in different ways the pipeline's were becoming",
    "start": "474350",
    "end": "479640"
  },
  {
    "text": "inconsistent we decided that we really needed clarity if we go in and change a",
    "start": "479640",
    "end": "486690"
  },
  {
    "text": "pipeline we need to know exactly what makes this pipeline special from others which part do we really need to change",
    "start": "486690",
    "end": "492240"
  },
  {
    "text": "and did we do it correctly so the first step is that we had gotten used to",
    "start": "492240",
    "end": "497430"
  },
  {
    "start": "494000",
    "end": "494000"
  },
  {
    "text": "having really long EML files like our llamo files were almost a thousand lines and we had a lot of them and it was",
    "start": "497430",
    "end": "504240"
  },
  {
    "text": "really really overwhelming to constantly be searching a thousand file a thousand lines so we decided to divide it into as",
    "start": "504240",
    "end": "512430"
  },
  {
    "text": "many small pieces as we can and that way we can just see what we're dealing with",
    "start": "512430",
    "end": "518450"
  },
  {
    "start": "518000",
    "end": "518000"
  },
  {
    "text": "after this the slide cutoff that says embedded Ruby but after this we decided",
    "start": "518450",
    "end": "524280"
  },
  {
    "text": "to use ARB so er B is basically a way of using Ruby in yellow so this is an",
    "start": "524280",
    "end": "532380"
  },
  {
    "text": "example where for as we were doing testing and we were testing kubernetes against all these",
    "start": "532380",
    "end": "537600"
  },
  {
    "text": "different infrastructures and so instead of just repeating AWS AWS AWS gcpd CP",
    "start": "537600",
    "end": "543660"
  },
  {
    "text": "DCP we now can just use like these four loops and so that was really helpful and it really dried up our mo but there was",
    "start": "543660",
    "end": "553050"
  },
  {
    "start": "552000",
    "end": "552000"
  },
  {
    "text": "still a problem with this and the problem is that when we had Ruby inside of llamo llamo cares a lot about",
    "start": "553050",
    "end": "558930"
  },
  {
    "text": "indentation but Ruby doesn't and so every time we were actually putting llamo inside of IRB we actually needed",
    "start": "558930",
    "end": "566399"
  },
  {
    "text": "to make sure that the indentation matched and so we were having a really hard time making sure that the",
    "start": "566399",
    "end": "571680"
  },
  {
    "text": "indentation where we were actually taking this and moving this had the same indentation as the other place and this",
    "start": "571680",
    "end": "578399"
  },
  {
    "text": "was really hard for us so we decided we wanted to try something else",
    "start": "578399",
    "end": "585170"
  },
  {
    "text": "and this time we went with anchors and aliases so if any of you are familiar",
    "start": "585170",
    "end": "590819"
  },
  {
    "text": "with the MMO itself has this notion of an an anchor and when you define an",
    "start": "590819",
    "end": "596519"
  },
  {
    "text": "anchor you can just reference in other places so we would start having one resource type defined in one place and",
    "start": "596519",
    "end": "602459"
  },
  {
    "text": "then we would just use it in a lot of other pipelines so this did a really",
    "start": "602459",
    "end": "608279"
  },
  {
    "start": "607000",
    "end": "607000"
  },
  {
    "text": "good job of drying up but we noticed that it wasn't taking care of the cognitive overhead we were still",
    "start": "608279",
    "end": "613860"
  },
  {
    "text": "spending a lot of time opening up a lot of different files to figure out what we were actually including in the pipeline",
    "start": "613860",
    "end": "619319"
  },
  {
    "text": "and specifically for us we were seeing that certain parts depended on other parts but we couldn't even tell that",
    "start": "619319",
    "end": "624870"
  },
  {
    "text": "they used each other because now we dried up everything so much that we couldn't tell what was even failing or",
    "start": "624870",
    "end": "630300"
  },
  {
    "text": "why was failing the other part of this also is that we needed a tool that would actually go in and understand DML",
    "start": "630300",
    "end": "636149"
  },
  {
    "text": "anchors and aliases and so we actually built a CLI which is always a bad idea and that was hard to maintain and",
    "start": "636149",
    "end": "642269"
  },
  {
    "text": "everyone was grumpy about it we decided for attempt number three that we were",
    "start": "642269",
    "end": "647970"
  },
  {
    "start": "644000",
    "end": "644000"
  },
  {
    "text": "just looking at it the wrong way we were splitting this up based on how it was configured in Concours and what we",
    "start": "647970",
    "end": "653910"
  },
  {
    "text": "should do instead is just look at how our pipelines are split up we noticed",
    "start": "653910",
    "end": "659639"
  },
  {
    "text": "that there's a lot of parts of our pipeline where like at the top we would dry up something and that thing was",
    "start": "659639",
    "end": "664709"
  },
  {
    "text": "referencing something at the bottom and in this case resource type that's being used by a job so we were looking closely at our",
    "start": "664709",
    "end": "672250"
  },
  {
    "start": "670000",
    "end": "670000"
  },
  {
    "text": "pipelines and sometimes we would have a configuration like this we had the infrastructure layer so vSphere 6/7 in",
    "start": "672250",
    "end": "678730"
  },
  {
    "text": "this case and then we had the networking layer which is NSX and then we had the version of whatever software we're",
    "start": "678730",
    "end": "684130"
  },
  {
    "text": "testing and then the scenarios like in this case an install and we decided to have these templates these templated",
    "start": "684130",
    "end": "691270"
  },
  {
    "text": "files and we're going to just have all of these dependencies in one file and then when you actually come to make a",
    "start": "691270",
    "end": "697630"
  },
  {
    "text": "new pipeline all you need is a file like this and it's completely empty and just based on the name of that file you can",
    "start": "697630",
    "end": "703720"
  },
  {
    "text": "figure out which templates you need to use ok so the next problem we had was",
    "start": "703720",
    "end": "711460"
  },
  {
    "text": "environment contention now to explain what we mean by environment contention we as a relaunch team we're testing on",
    "start": "711460",
    "end": "718360"
  },
  {
    "start": "714000",
    "end": "714000"
  },
  {
    "text": "many different guises some were public like AWS Azure and GC P and then we also",
    "start": "718360",
    "end": "723610"
  },
  {
    "text": "had like a private ones that we make sure to test on like we sphere and then NSX pipelines Nimbus here is an internal",
    "start": "723610",
    "end": "731920"
  },
  {
    "text": "tool that VMware uses to spin up NSX environments so basically we cover all",
    "start": "731920",
    "end": "737860"
  },
  {
    "text": "of this in our testing so why is this a problem if you don't have these",
    "start": "737860",
    "end": "743320"
  },
  {
    "text": "environments around first of all for public I asses like we had many",
    "start": "743320",
    "end": "748960"
  },
  {
    "text": "different pipelines but the number of environments that we had was very little so the ratio was really skewed we had 50",
    "start": "748960",
    "end": "755680"
  },
  {
    "text": "plus testing configurations to test but there was no automation around environments so we were basically going",
    "start": "755680",
    "end": "761320"
  },
  {
    "text": "to the console and then by creating them manually and like making all these configurations and forgetting some parts",
    "start": "761320",
    "end": "767170"
  },
  {
    "text": "of it for privatizes there is there were other issues like Nimbus like I",
    "start": "767170",
    "end": "773020"
  },
  {
    "text": "explained before is based on a quota system so whoever requests for an environment",
    "start": "773020",
    "end": "780190"
  },
  {
    "text": "first gets that environment and let's say the quota for an entire organizations over you wouldn't be able",
    "start": "780190",
    "end": "786610"
  },
  {
    "text": "to request for another one so you just have to wait till someone cleans it up and then you have access to it so",
    "start": "786610",
    "end": "793710"
  },
  {
    "text": "basically we were really sad again this was causing a lot of human errors and",
    "start": "793710",
    "end": "800260"
  },
  {
    "text": "configuration errors and made us sad like the dog of the picture so how do we",
    "start": "800260",
    "end": "806560"
  },
  {
    "text": "fix it we used terraform which is an open-source tool which can create",
    "start": "806560",
    "end": "813459"
  },
  {
    "text": "environments on the fly so we started having a pipeline for creating an environment and destroying an",
    "start": "813459",
    "end": "819160"
  },
  {
    "text": "environment and this was third eye as so it was like a one-click solution and we",
    "start": "819160",
    "end": "824830"
  },
  {
    "text": "just automated it so we never had a bother about like creating it again unless just going to a pipeline and",
    "start": "824830",
    "end": "831010"
  },
  {
    "text": "clicking on a button also the pipeline's were recycled sorry the environments were recycled after 24 hours if they",
    "start": "831010",
    "end": "837339"
  },
  {
    "text": "weren't used for the private I asses that is Nimbus specifically our",
    "start": "837339",
    "end": "843940"
  },
  {
    "text": "infrastructure team from VMware came up with this tool called Shepherd which pre-made environments and then",
    "start": "843940",
    "end": "849990"
  },
  {
    "text": "preserved it for the Vilanch team and we basically started having a shared pool for all the teams that were going to",
    "start": "849990",
    "end": "856540"
  },
  {
    "text": "test on vSphere NSX so this way we had on-demand environments and lesser",
    "start": "856540",
    "end": "862450"
  },
  {
    "text": "contention because now we were at least we were high priority ok so another",
    "start": "862450",
    "end": "870250"
  },
  {
    "text": "problem that we had is that our pipelines were taking way too long so we",
    "start": "870250",
    "end": "876370"
  },
  {
    "start": "875000",
    "end": "875000"
  },
  {
    "text": "were watching a lot of our deadlines pass us by and we were missing them and were like why are we always missing our",
    "start": "876370",
    "end": "881890"
  },
  {
    "text": "deadlines and also I totally screwed up the formatting and all of these it's",
    "start": "881890",
    "end": "887140"
  },
  {
    "start": "883000",
    "end": "883000"
  },
  {
    "text": "fine you didn't notice you didn't notice so we looked at pipelines that are time consuming and we saw that they're time",
    "start": "887140",
    "end": "893709"
  },
  {
    "text": "consuming for two reasons the first is that they're really slow and the second is that a lot of them were really flaky",
    "start": "893709",
    "end": "900360"
  },
  {
    "text": "so we wanted to look at the ones that were slow first first of all our pipelines were doing a lot of tasks",
    "start": "900360",
    "end": "906459"
  },
  {
    "start": "901000",
    "end": "901000"
  },
  {
    "text": "serially that could be paralyzed and most people on our team were comfortable with Ruby but we decided maybe it's time",
    "start": "906459",
    "end": "913150"
  },
  {
    "text": "we actually start rewriting these and going and actually use go routines and by being able to leverage concurrency",
    "start": "913150",
    "end": "920080"
  },
  {
    "text": "and parallelism we were able to get a job that ran in every single pipeline from two hours to 15 minutes another",
    "start": "920080",
    "end": "928750"
  },
  {
    "text": "thing that we wanted to tackle is that in a lot of our test Suites we were spinning up a cluster and then we were",
    "start": "928750",
    "end": "934510"
  },
  {
    "text": "running tests against that workload and then we were destroying the cluster and then this was happening also in serial",
    "start": "934510",
    "end": "940810"
  },
  {
    "text": "so we decided let's just have one job create a cluster and passed the",
    "start": "940810",
    "end": "946270"
  },
  {
    "text": "information for that cluster to all the jobs that need it and have those jobs run in parallel so this this resulted in",
    "start": "946270",
    "end": "953050"
  },
  {
    "text": "our pipelines being sped up by four times the next thing is we wanted to",
    "start": "953050",
    "end": "959170"
  },
  {
    "text": "look at our pipelines that were flaky so we knew that this was the flow that we were experiencing that was causing us",
    "start": "959170",
    "end": "965560"
  },
  {
    "text": "pain we would have a PR get merged and we would build the product and then we",
    "start": "965560",
    "end": "970780"
  },
  {
    "text": "would try to run it through almost 39 pipelines against different infrastructures and we would have to",
    "start": "970780",
    "end": "976480"
  },
  {
    "text": "trigger this many many times same exact inputs until it went green and we could ship it what we really",
    "start": "976480",
    "end": "984550"
  },
  {
    "text": "wanted is to be able to merge it run it through all the pipelines once and then see it go green so one person on our",
    "start": "984550",
    "end": "994450"
  },
  {
    "start": "992000",
    "end": "992000"
  },
  {
    "text": "team was like licious run a pipeline let's just call it run run run and this pipelines gonna do exactly what it",
    "start": "994450",
    "end": "1000480"
  },
  {
    "text": "sounds like it's just going to run over and over again with the same commits and we're just going to keep this pipeline",
    "start": "1000480",
    "end": "1007020"
  },
  {
    "text": "around and use it to just get a sense of how flaky certain jobs are so we did 112",
    "start": "1007020",
    "end": "1016290"
  },
  {
    "text": "runs took about four weeks and we realized that our pipelines were succeeding fifty-five percent of the",
    "start": "1016290",
    "end": "1021930"
  },
  {
    "text": "time so after some very complicated analysis is very small here we actually",
    "start": "1021930",
    "end": "1031140"
  },
  {
    "text": "realized that there were certain jobs that were failing a lot certain jobs that weren't failing as much and we decided to prioritize these jobs by",
    "start": "1031140",
    "end": "1037920"
  },
  {
    "text": "failure rate this was actually really successful because we discovered a lot",
    "start": "1037920",
    "end": "1043890"
  },
  {
    "text": "of random errors that really hadn't been looking into apparently running out of disk apparently sometimes we were",
    "start": "1043890",
    "end": "1050280"
  },
  {
    "text": "retrying and it was failing and by being able to really look for these were able to look for those specific teams that",
    "start": "1050280",
    "end": "1057270"
  },
  {
    "text": "were in charge of wherever that integration was failing and they were able to fix these things and this made a",
    "start": "1057270",
    "end": "1062640"
  },
  {
    "text": "big difference to her speed overall",
    "start": "1062640",
    "end": "1066170"
  },
  {
    "text": "so the next problem we had was no integration process so at this point we",
    "start": "1068610",
    "end": "1074340"
  },
  {
    "start": "1070000",
    "end": "1070000"
  },
  {
    "text": "had all these pipelines all the teams had access to these pipelines and we had no idea who was triggering what pipeline",
    "start": "1074340",
    "end": "1081120"
  },
  {
    "text": "at what time so this was the like really initially before we had any processes in place we would come to work in the",
    "start": "1081120",
    "end": "1088200"
  },
  {
    "text": "morning one day and find pipelines past or pipelines run our pipelines deleted",
    "start": "1088200",
    "end": "1093230"
  },
  {
    "text": "and also teams had no way to test their code they were pushing changes to master",
    "start": "1093230",
    "end": "1100410"
  },
  {
    "text": "directly and actually debugging after shipping it because they had no way of knowing where their tests were failing",
    "start": "1100410",
    "end": "1106410"
  },
  {
    "text": "or they had no way to run their tests in the first place so we could fix some of these issues like restrict our concourse",
    "start": "1106410",
    "end": "1113400"
  },
  {
    "text": "access like we created we made it more private and only the rail ang team could access it and we started introducing",
    "start": "1113400",
    "end": "1119220"
  },
  {
    "text": "code reviews and PR processes but it still doesn't fix the issue of the teams",
    "start": "1119220",
    "end": "1124650"
  },
  {
    "text": "not having a way to test it so the teams were making pull request to master and we were running it in production",
    "start": "1124650",
    "end": "1130290"
  },
  {
    "text": "concourse but every time there was a problem with your code the only way they would know it was through the Lynch",
    "start": "1130290",
    "end": "1136590"
  },
  {
    "text": "because master was broken and we had access to this so this is where Relan as",
    "start": "1136590",
    "end": "1143760"
  },
  {
    "start": "1142000",
    "end": "1142000"
  },
  {
    "text": "a service comes in so basically what the rail ang team did was created an exact",
    "start": "1143760",
    "end": "1149820"
  },
  {
    "text": "same concourse that was available to the teams and each of them had their own",
    "start": "1149820",
    "end": "1155730"
  },
  {
    "text": "separate buckets and own separate places to host their code so basically what",
    "start": "1155730",
    "end": "1161730"
  },
  {
    "text": "they would do was they had access to our code so they would run those pipelines in the separate concourse and they could",
    "start": "1161730",
    "end": "1167910"
  },
  {
    "text": "also run only what was relevant to them like let's say they wanted to test only vSphere and AWS they had access to the",
    "start": "1167910",
    "end": "1175080"
  },
  {
    "text": "amyl files and they all they had to do was run it in this concours and test it out so this way we just had a script which",
    "start": "1175080",
    "end": "1182220"
  },
  {
    "text": "made this configuration the teams were changed the location of their buckets and their repositories run the pipeline",
    "start": "1182220",
    "end": "1188340"
  },
  {
    "text": "in the separate Raskin course fail and see if it fails if any job failed they",
    "start": "1188340",
    "end": "1194340"
  },
  {
    "text": "would fix it and then PR it to us and then we would we would have it green in our production concours so this",
    "start": "1194340",
    "end": "1200430"
  },
  {
    "text": "way both sides had more confidence the teams had more confidence because they tested their code and we had more",
    "start": "1200430",
    "end": "1206400"
  },
  {
    "text": "confidence because we know that they had a way to test it the last part is open",
    "start": "1206400",
    "end": "1212460"
  },
  {
    "text": "source licensing so at this point we are we have pretty much sped up most of our",
    "start": "1212460",
    "end": "1219030"
  },
  {
    "text": "processes but there's still one last hiccup so whatever we are shipping is",
    "start": "1219030",
    "end": "1224760"
  },
  {
    "text": "this legal and one of the biggest problems of shipping open source software is knowing whether it's legal",
    "start": "1224760",
    "end": "1230820"
  },
  {
    "text": "or not whether it have you acknowledged for every open source software that you have included so who's responsible for",
    "start": "1230820",
    "end": "1237510"
  },
  {
    "text": "this at this point it was the rel inch team so what does this mean when we're",
    "start": "1237510",
    "end": "1244740"
  },
  {
    "start": "1242000",
    "end": "1242000"
  },
  {
    "text": "talking about open source licensing and why is it hard we were talking about",
    "start": "1244740",
    "end": "1249750"
  },
  {
    "text": "kubernetes especially we're talking about containers and containers are made up of software packages they are made up",
    "start": "1249750",
    "end": "1256470"
  },
  {
    "text": "of base OSS and it's pretty early right now for us to know what is included or",
    "start": "1256470",
    "end": "1262950"
  },
  {
    "text": "how how do we scan these containers is hard containers can either be on the",
    "start": "1262950",
    "end": "1268050"
  },
  {
    "text": "internet or they can either be created by the teams themselves and we need to",
    "start": "1268050",
    "end": "1273540"
  },
  {
    "text": "know what's included in each of those containers so we started scanning them",
    "start": "1273540",
    "end": "1279990"
  },
  {
    "text": "by ourselves we take each of the we take each of the component teams call we scan",
    "start": "1279990",
    "end": "1285240"
  },
  {
    "text": "them we wrote scripts to scan these containers and find what software was included in that find a software",
    "start": "1285240",
    "end": "1291180"
  },
  {
    "text": "packages find their licensing through open source tools and then create OSL we",
    "start": "1291180",
    "end": "1297540"
  },
  {
    "text": "also became smarter on what to OSL and what not for example we started asking the teams",
    "start": "1297540",
    "end": "1304140"
  },
  {
    "text": "to do their own part for the OSL because the teams know what containers they include we also did OSL only for GA",
    "start": "1304140",
    "end": "1311760"
  },
  {
    "text": "bills and not for only for general availability bills or not for all dev bills that we were like producing we",
    "start": "1311760",
    "end": "1317910"
  },
  {
    "text": "also started doing this much earlier in the process when we knew that something was a candidate for a build and also",
    "start": "1317910",
    "end": "1323850"
  },
  {
    "text": "started providing teams with early access to the bills so they could scan it after and verify that they had",
    "start": "1323850",
    "end": "1330570"
  },
  {
    "text": "included the containers that they were or scan the containers that they were including",
    "start": "1330570",
    "end": "1336590"
  },
  {
    "text": "so at this point in time we had tested code our llamo had gotten dried up our",
    "start": "1336590",
    "end": "1342299"
  },
  {
    "text": "process was more defined we've automated a lot of the environment creation and our pipelines were faster and we",
    "start": "1342299",
    "end": "1348630"
  },
  {
    "text": "actually had we were in good legal standing that's always good at the",
    "start": "1348630",
    "end": "1354630"
  },
  {
    "text": "beginning of this when the team had started we were shipping every six months and now we were shipping and you",
    "start": "1354630",
    "end": "1360539"
  },
  {
    "text": "build every 10 days our pipelines went from 12 hours to four hours a large part",
    "start": "1360539",
    "end": "1365970"
  },
  {
    "text": "of that was parallelization and we were able to even have a turnaround for bugs see bees patches of 48 hours I release",
    "start": "1365970",
    "end": "1376500"
  },
  {
    "text": "time for one of our builds one 300 was 35 hours from start to finish that was from testing to OSL we got it down for",
    "start": "1376500",
    "end": "1386669"
  },
  {
    "text": "release 1 for 0 to about 10 hours now the OSL is not included in that word but yeah OSL actually always is not OSL is",
    "start": "1386669",
    "end": "1394320"
  },
  {
    "text": "not included is this is just testing part I'm so sorry it takes all the time so release",
    "start": "1394320",
    "end": "1402059"
  },
  {
    "text": "engineering as a service it's doing kubernetes the hard way but it's worth it one of the best parts about all of",
    "start": "1402059",
    "end": "1409650"
  },
  {
    "text": "this is that someone made us pie because we made a lot faster thank you so much",
    "start": "1409650",
    "end": "1417120"
  },
  {
    "text": "are there any questions [Applause]",
    "start": "1417120",
    "end": "1424880"
  },
  {
    "text": "I'm very interesting what's scanning - are you using the scan so we develop",
    "start": "1441390",
    "end": "1451140"
  },
  {
    "text": "some scripts internally we used bash but it's actually a really hard process we",
    "start": "1451140",
    "end": "1458580"
  },
  {
    "text": "did not find any tools that are reliable in the market so we had to develop it in-house but like the basic idea it's",
    "start": "1458580",
    "end": "1466920"
  },
  {
    "text": "it's it's little manual at the moment but at least mostly roll it in bash yeah",
    "start": "1466920",
    "end": "1473970"
  },
  {
    "text": "we didn't we be used for actually scanning the rest of the product we used for Saleh G and forget the other one",
    "start": "1473970",
    "end": "1483980"
  },
  {
    "text": "yeah license finder and pathology but they don't do container scanning for",
    "start": "1483980",
    "end": "1489000"
  },
  {
    "text": "containers we did it ourselves okay thank you",
    "start": "1489000",
    "end": "1494240"
  },
  {
    "text": "during that infrastructure is the code part you mentioned or the test tutor",
    "start": "1511950",
    "end": "1517710"
  },
  {
    "text": "will be decommissioned after four hours if they are not used how do you decide",
    "start": "1517710",
    "end": "1523380"
  },
  {
    "text": "how do you know if that piece of infrastructure or not so we have a",
    "start": "1523380",
    "end": "1531210"
  },
  {
    "text": "github repo that has the actual lock files in them the credentials are stored",
    "start": "1531210",
    "end": "1537180"
  },
  {
    "text": "elsewhere but it basically the act of claiming an environment you actually move it from one folder in the github",
    "start": "1537180",
    "end": "1543480"
  },
  {
    "text": "repo to another folder so we look at the time that it was claimed that it was basically moved to that folder and",
    "start": "1543480",
    "end": "1549390"
  },
  {
    "text": "that's the time that it was claimed so we have a pipeline that runs every hour it looks at all of the locks that were",
    "start": "1549390",
    "end": "1555480"
  },
  {
    "text": "claimed from that repo within the past like 24 hours or more and then it moves them into the destroy pool so like every",
    "start": "1555480",
    "end": "1562920"
  },
  {
    "text": "we basically use github and like we look at commits everything's like automated through commits so that's how we figure",
    "start": "1562920",
    "end": "1568410"
  },
  {
    "text": "out how long in environments being used great thanks",
    "start": "1568410",
    "end": "1573950"
  },
  {
    "text": "you just mentioned a third party dependency management I'm not sure that",
    "start": "1586290",
    "end": "1591370"
  },
  {
    "text": "we have more information about it are you asking around OSL or about another",
    "start": "1591370",
    "end": "1598720"
  },
  {
    "text": "aspect yeah I mean since you project rely on some sort of party dependencies",
    "start": "1598720",
    "end": "1603750"
  },
  {
    "text": "either Java also IPM fails or some other fails if you if your project has lots of",
    "start": "1603750",
    "end": "1611410"
  },
  {
    "text": "micro services what projects all of these stories should rely on some sort",
    "start": "1611410",
    "end": "1617950"
  },
  {
    "text": "of party dependencies then how do you project all these project managed sort",
    "start": "1617950",
    "end": "1623950"
  },
  {
    "text": "party dependencies is this for OSL or in",
    "start": "1623950",
    "end": "1629230"
  },
  {
    "text": "general are you asking please go back to",
    "start": "1629230",
    "end": "1635170"
  },
  {
    "text": "your slice third party dependencies just",
    "start": "1635170",
    "end": "1640780"
  },
  {
    "text": "tell me when to stop",
    "start": "1640780",
    "end": "1643650"
  },
  {
    "text": "Oh next Oh dependencies in fire this one",
    "start": "1660920",
    "end": "1670130"
  },
  {
    "text": "yeah okay how do you manage this it's a",
    "start": "1670130",
    "end": "1677150"
  },
  {
    "text": "good question so okay so what we do on",
    "start": "1677150",
    "end": "1683330"
  },
  {
    "text": "our team is every time we make a change to any integration in kubernetes what we",
    "start": "1683330",
    "end": "1688790"
  },
  {
    "text": "do is we build our product with that change and we have to get an environment",
    "start": "1688790",
    "end": "1694730"
  },
  {
    "text": "that's configured with this configuration so what you're looking at here right now these are all configurations and for vSphere like for",
    "start": "1694730",
    "end": "1702980"
  },
  {
    "text": "VC or 6/7 for example like we actually have our own like set of servers locally that we're using to test for nsx we're",
    "start": "1702980",
    "end": "1709730"
  },
  {
    "text": "actually like deploying that networking layer on top we do this for public infrastructure as well like for GCP for",
    "start": "1709730",
    "end": "1716750"
  },
  {
    "text": "example but with GCP we would just do flannel for the networking layer and the OEM that part is sort of a that's sort",
    "start": "1716750",
    "end": "1724970"
  },
  {
    "text": "of a product that's like we're also testing against and the scenarios are just install is like we're just trying",
    "start": "1724970",
    "end": "1731540"
  },
  {
    "text": "to see that we can get it deployed get a cluster get it to pass against tests for",
    "start": "1731540",
    "end": "1736580"
  },
  {
    "text": "upgrades we're just trying to make sure that we can go from one version to the version after it so for all of these we",
    "start": "1736580",
    "end": "1742580"
  },
  {
    "text": "basically are using a lot of environment management like all of these are just environments I don't know if that answered your question looks like maybe",
    "start": "1742580",
    "end": "1750560"
  },
  {
    "text": "I didn't I'm sorry",
    "start": "1750560",
    "end": "1753070"
  },
  {
    "text": "oh yeah okay so we do have so we have",
    "start": "1758400",
    "end": "1763860"
  },
  {
    "text": "something we brought up and where did we bring it up okay",
    "start": "1763860",
    "end": "1772830"
  },
  {
    "text": "like just for these environments I just wanted the ones on the right hand side those are all public infrastructures so",
    "start": "1772830",
    "end": "1780150"
  },
  {
    "text": "we're using like terraform to be able to deploy everything on those environments for the left hand side we have like",
    "start": "1780150",
    "end": "1787470"
  },
  {
    "text": "internal tooling and we're using that to be able to specify like which configure",
    "start": "1787470",
    "end": "1793110"
  },
  {
    "text": "like which specific in integrations we want in it if we like have I don't know",
    "start": "1793110",
    "end": "1798360"
  },
  {
    "text": "like Viera lie or harbor or something then we're specifying it that way but I guess a lot of these are right now",
    "start": "1798360",
    "end": "1804210"
  },
  {
    "text": "they're internal I don't think that we've made them available yet but some of these things maybe someday when",
    "start": "1804210",
    "end": "1809760"
  },
  {
    "text": "they're like ready we could share them did you ask in terms of Yammer files or",
    "start": "1809760",
    "end": "1815580"
  },
  {
    "text": "were you asking in terms of environment oh okay awesome",
    "start": "1815580",
    "end": "1822500"
  },
  {
    "text": "all right thank you you can find us after if you have any more questions [Applause]",
    "start": "1834370",
    "end": "1842180"
  }
]
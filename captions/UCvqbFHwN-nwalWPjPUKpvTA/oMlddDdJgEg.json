[
  {
    "text": "good afternoon everybody we're here to talk about a year of democratizing machine learning was criminais dias and",
    "start": "3560",
    "end": "10559"
  },
  {
    "text": "kupo my name is Faye and I'm a customer engineer at Google I'm David on check",
    "start": "10559",
    "end": "15930"
  },
  {
    "text": "I'm product manager and co-founder of the cube flow project so I guess this is",
    "start": "15930",
    "end": "23550"
  },
  {
    "text": "it okay so with that you know this is a really awesome if occasion I'm this is",
    "start": "23550",
    "end": "30779"
  },
  {
    "text": "the first obviously cube con in China this is my first talk in China I've been",
    "start": "30779",
    "end": "35940"
  },
  {
    "text": "representing kubernetes for since January of 2015 and and this is really",
    "start": "35940",
    "end": "41429"
  },
  {
    "text": "really I can't tell you how many people have come up to me asking to have talks in China about kubernetes and cube flow",
    "start": "41429",
    "end": "48449"
  },
  {
    "text": "and ml and so I hope I do y'all proud but I'm very very excited about this",
    "start": "48449",
    "end": "53510"
  },
  {
    "text": "excuse so um you know we kind of gave away in the the talk but you know a year",
    "start": "53510",
    "end": "60569"
  },
  {
    "text": "ago we started the cube flow project and the idea was that we had heard all the",
    "start": "60569",
    "end": "66210"
  },
  {
    "text": "time this question what is machine learning and it's really a hard question",
    "start": "66210",
    "end": "72080"
  },
  {
    "text": "you know so many people have so many different takes on it is it's something just incredibly basic like advanced",
    "start": "72080",
    "end": "78600"
  },
  {
    "text": "linear regression is it something that's gonna take over the world who knows but",
    "start": "78600",
    "end": "83700"
  },
  {
    "text": "the reality is is that at Google and across the machine learning industry we think largely it's this it's a way of",
    "start": "83700",
    "end": "91260"
  },
  {
    "text": "solving problems without explicitly knowing how to create a solution where",
    "start": "91260",
    "end": "96330"
  },
  {
    "text": "you have data and features and sources for so many different things and your",
    "start": "96330",
    "end": "101880"
  },
  {
    "text": "look what you're really looking to do is get to an answer yet you're not exactly sure how two things correlate and that's",
    "start": "101880",
    "end": "108750"
  },
  {
    "text": "a really powerful thing and we went into cute flow thinking this very thing at",
    "start": "108750",
    "end": "113940"
  },
  {
    "text": "Google everything at Google it is touched by AI in some way and one of the",
    "start": "113940",
    "end": "119550"
  },
  {
    "text": "most profound ways is this example that we have here with Google data center operations at you know obviously data",
    "start": "119550",
    "end": "127080"
  },
  {
    "text": "centers are one of our most expensive most costly most important things that we do and for us we hire great engineers",
    "start": "127080",
    "end": "135209"
  },
  {
    "text": "we think about problems very very deep when we took at that knowledge when we",
    "start": "135209",
    "end": "140340"
  },
  {
    "text": "took all the data that we collected and we applied machine learning to it we found out a really amazing thing that",
    "start": "140340",
    "end": "146879"
  },
  {
    "text": "even though these people were great they were the best data center engineers arguably in the world we were able to",
    "start": "146879",
    "end": "152489"
  },
  {
    "text": "make huge progress against them and you can see it here this is a way to measure data center effectiveness it's called",
    "start": "152489",
    "end": "159290"
  },
  {
    "text": "power usage effectiveness where you measure the amount of power going in and and the amount of computation that you",
    "start": "159290",
    "end": "166260"
  },
  {
    "text": "get out the other side ideally you want to be as low as possible meaning you have the lowest possible power going in and you're getting the most power",
    "start": "166260",
    "end": "172709"
  },
  {
    "text": "powerful computation out of it in this case it started out very high we simply",
    "start": "172709",
    "end": "179549"
  },
  {
    "text": "applied ml and that wasn't simple by any stretch but we applied ml to the problem instantly cut it up cut down our power",
    "start": "179549",
    "end": "186540"
  },
  {
    "text": "usage and then turn it off and it came back and we saved literally hundreds of millions of dollars doing this and",
    "start": "186540",
    "end": "192870"
  },
  {
    "text": "there's a great blog post on Google comm that talks about all the ways that we're saving energy and and this is really",
    "start": "192870",
    "end": "200640"
  },
  {
    "text": "important right it's not that our data center engineers didn't know all these elements of launching your app having a",
    "start": "200640",
    "end": "207510"
  },
  {
    "text": "data center of how to make it efficient and all these things they they had all the data but they just didn't know how",
    "start": "207510",
    "end": "213690"
  },
  {
    "text": "to approach the problem and machine learning was able to do that for now the problem is is that ml is hard those",
    "start": "213690",
    "end": "220079"
  },
  {
    "text": "people those excellent data center engineers they didn't know how to go and approach this from an L perspective we",
    "start": "220079",
    "end": "226169"
  },
  {
    "text": "had to get brand new data set an engineer or a data scientist to get in and the reason it's hard is because of",
    "start": "226169",
    "end": "232319"
  },
  {
    "text": "something that kubernetes helps to solve which is all the steps around setup and",
    "start": "232319",
    "end": "237599"
  },
  {
    "text": "management and declarative deployment and all these things that data scientists don't want to think about",
    "start": "237599",
    "end": "242669"
  },
  {
    "text": "they want to just think about models and pipelines and things like that and the reality is is that you know they had to",
    "start": "242669",
    "end": "249030"
  },
  {
    "text": "think about it and so what we wanted to do was think about changing the game with machine learning in the same way",
    "start": "249030",
    "end": "256440"
  },
  {
    "text": "that containers and kubernetes changed it for overall deployment and create something called cloud native apps now",
    "start": "256440",
    "end": "262470"
  },
  {
    "text": "the question is could we get to cloud native ml what would it even look like",
    "start": "262470",
    "end": "267690"
  },
  {
    "text": "for us it looks kind of like the following when people think about machine learning today they really think about a single",
    "start": "267690",
    "end": "274349"
  },
  {
    "text": "element right they think about building a model are you gonna use paddle paddle or tensorflow or psyche it you know",
    "start": "274349",
    "end": "279720"
  },
  {
    "text": "what's the how quickly does it converge what's the accuracy level and so on but the reality is is that a machine",
    "start": "279720",
    "end": "285810"
  },
  {
    "text": "learning pipeline looks a lot more like this where you have lots of micro-services loosely coupled together",
    "start": "285810",
    "end": "292110"
  },
  {
    "text": "and what you're trying to do is get to a solution that that involves actual",
    "start": "292110",
    "end": "297360"
  },
  {
    "text": "production readiness even if you're a data scientist working at the beginning and and this is what that data scientist",
    "start": "297360",
    "end": "304199"
  },
  {
    "text": "experience looks like whereas the first one might be relative to the platform and the various services a data scientist wants to do something",
    "start": "304199",
    "end": "310169"
  },
  {
    "text": "completely separately they want to just be at Jupiter level or docker they want to train their model they want to deploy",
    "start": "310169",
    "end": "316080"
  },
  {
    "text": "it and they want to integrate it into their app as quickly as they can and and",
    "start": "316080",
    "end": "321719"
  },
  {
    "text": "worse than that even with that complex pipeline I haven't even started to get to that where the real problems are",
    "start": "321719",
    "end": "327210"
  },
  {
    "text": "which is around the entire stack end to end you start at the model and you walk",
    "start": "327210",
    "end": "332430"
  },
  {
    "text": "all the way down webinars you axe tooling storage runtimes these are all things that you're gonna have to deal",
    "start": "332430",
    "end": "337889"
  },
  {
    "text": "with and in that entire pipeline that I was talking about that's just the very",
    "start": "337889",
    "end": "343050"
  },
  {
    "text": "top of it all the other things kind of sit under the hood and now to make it",
    "start": "343050",
    "end": "348150"
  },
  {
    "text": "even more complicated it doesn't just sit into the hood in one environment it sends over the hood in multi cloud",
    "start": "348150",
    "end": "353580"
  },
  {
    "text": "environments where you not have to replicate that entire thing over and over again in this case 81% of",
    "start": "353580",
    "end": "359669"
  },
  {
    "text": "enterprises have more than one cloud and they don't just have more than one they have up to five which makes your problem",
    "start": "359669",
    "end": "367440"
  },
  {
    "text": "much much more complicated whereas this might be your experimentation one you go one step further and have to replicate",
    "start": "367440",
    "end": "372870"
  },
  {
    "text": "that it's same environment for training and then finally your same environment for cloud so this is a very very",
    "start": "372870",
    "end": "378180"
  },
  {
    "text": "complicated problem and this right here is why we introduced cube flow in",
    "start": "378180",
    "end": "383430"
  },
  {
    "text": "December of 2017 at cube con Austin we introduced this portable framework that",
    "start": "383430",
    "end": "389669"
  },
  {
    "text": "let you declaratively describe a very complicated machine learning framework and then pipeline what using the",
    "start": "389669",
    "end": "397979"
  },
  {
    "text": "elements of kubernetes to make your deployment and management much easier our",
    "start": "397979",
    "end": "403169"
  },
  {
    "text": "mission remains the same a year in we want to make it easy for everyone to develop deploy and manage portable",
    "start": "403169",
    "end": "410310"
  },
  {
    "text": "distributed ml on kubernetes and what that looks like is this you have that",
    "start": "410310",
    "end": "415770"
  },
  {
    "text": "base layer kubernetes you know that it runs the same everywhere as dan cone talked about earlier the investments",
    "start": "415770",
    "end": "421680"
  },
  {
    "text": "that the CN CF and kubernetes projects make in conformance means that you know no matter where you go you're gonna be",
    "start": "421680",
    "end": "428639"
  },
  {
    "text": "able to plug into a rich kubernetes deployment that has a minimum bar for the api's and other objects available",
    "start": "428639",
    "end": "435029"
  },
  {
    "text": "and then on the left you describe your pipeline using cube flow and cube flow",
    "start": "435029",
    "end": "440699"
  },
  {
    "text": "is something that you can stamp out in each one of those locations in a in a declarative way knowing that because you",
    "start": "440699",
    "end": "448020"
  },
  {
    "text": "have kubernetes to base it on you're gonna be able to replicate that very quickly and what that means is we now do",
    "start": "448020",
    "end": "453629"
  },
  {
    "text": "have cloud native ml we have a portable framework which operates at the cloud level loosely coupled together micro",
    "start": "453629",
    "end": "460560"
  },
  {
    "text": "service-oriented in the years since we've launched we have a tremendous amount of momentum 1900 commits over a",
    "start": "460560",
    "end": "468000"
  },
  {
    "text": "hundred community contributors with 30 different community companies contributing including the list you see",
    "start": "468000",
    "end": "474629"
  },
  {
    "text": "here and many more and when I say what it means to have a",
    "start": "474629",
    "end": "479820"
  },
  {
    "text": "rich community it looks like the following when you think about one of the most successful communities in the world kubernetes it",
    "start": "479820",
    "end": "486420"
  },
  {
    "text": "looks something like this and I know that's a lot of different companies contributing in a lot of different ways let me kind of simplify it for you it",
    "start": "486420",
    "end": "493170"
  },
  {
    "text": "looks like this that's Google and this is not Google and that's really important right we are not we at Google",
    "start": "493170",
    "end": "499890"
  },
  {
    "text": "are not the number one contributors everyone else is that is so important and it took us years to get here you",
    "start": "499890",
    "end": "506700"
  },
  {
    "text": "know the first year second year it we were the over 50% that was incredibly important for us to get to that point",
    "start": "506700",
    "end": "513000"
  },
  {
    "text": "where other people could find the place in the ecosystem to make it then around 4q flow it looks like this here's two",
    "start": "513000",
    "end": "520530"
  },
  {
    "text": "different companies contributing and to simplify it again Google and not move and we're already over 50% of our",
    "start": "520530",
    "end": "528180"
  },
  {
    "text": "contributions come from non Google this is what healthy community looks like and let me take it one step further",
    "start": "528180",
    "end": "534330"
  },
  {
    "text": "they aren't folks just aren't working on bugs and I'm not saying bugs aren't incredibly important they are we know we",
    "start": "534330",
    "end": "539880"
  },
  {
    "text": "want to get to stability but the reality is it's really significant contributions that move our platform forward very very",
    "start": "539880",
    "end": "546630"
  },
  {
    "text": "quickly for example we have a great framework in the core of the platform called cat tube it helps do hyper",
    "start": "546630",
    "end": "552690"
  },
  {
    "text": "parameter optimization it's plugged in and in particular something PHA will show in just a minute we make it very",
    "start": "552690",
    "end": "559140"
  },
  {
    "text": "very easy to do this even with very little code and that came from NTT and we couldn't have been happier about it",
    "start": "559140",
    "end": "565380"
  },
  {
    "text": "second we have a brand new serving framework which literally just launched two months ago I believe it is at this",
    "start": "565380",
    "end": "571440"
  },
  {
    "text": "point from Nvidia it's called tensor RT and it makes serving on GPUs much much more efficient including multiple models",
    "start": "571440",
    "end": "578400"
  },
  {
    "text": "per GPU per node heterogeneous GPUs and and environments and it integrates with",
    "start": "578400",
    "end": "584790"
  },
  {
    "text": "the underlying auto scalars and latency and Health metrics again external company contributing to the core of cube",
    "start": "584790",
    "end": "590640"
  },
  {
    "text": "flow this is incredibly important one more example is our go from Intuit I",
    "start": "590640",
    "end": "597120"
  },
  {
    "text": "mentioned that our go is already in the box this is an incredibly powerful system for workflow and and",
    "start": "597120",
    "end": "603020"
  },
  {
    "text": "orchestration and pipelines we'll touch on that and it really allows for doing",
    "start": "603020",
    "end": "608520"
  },
  {
    "text": "get ops you might have heard for launching it excuse me for it for declaratively",
    "start": "608520",
    "end": "613850"
  },
  {
    "text": "rolling out your machine learning pipeline so that's everything now I'd like to hand off the fade to talk about cue flow 0.3 which we're happy to",
    "start": "613850",
    "end": "620779"
  },
  {
    "text": "announce",
    "start": "620779",
    "end": "622960"
  },
  {
    "text": "so we recently really use cube flow 0 point 3 and the zero point 3 there are",
    "start": "626130",
    "end": "631259"
  },
  {
    "text": "two major seams that we really invested a lot in so once around how to make you",
    "start": "631259",
    "end": "636959"
  },
  {
    "text": "flow easier to deploy so you can have a much better getting to started experience the other part we want to",
    "start": "636959",
    "end": "643829"
  },
  {
    "text": "make investment in was how to make the development experience on cue flow more powerful and able to use in different",
    "start": "643829",
    "end": "650910"
  },
  {
    "text": "use cases so on the deployment side we released a new deployment CLI called a",
    "start": "650910",
    "end": "656910"
  },
  {
    "text": "KF controlled sh it's a bash script where you can use to install all the Q",
    "start": "656910",
    "end": "662910"
  },
  {
    "text": "full components just from one command I'm gonna show more of that later as well the second thing for deployment is",
    "start": "662910",
    "end": "670259"
  },
  {
    "text": "that we're having a much much simpler set up and later I'm going to show a one-click to deploy of how you can",
    "start": "670259",
    "end": "677190"
  },
  {
    "text": "provision the infrastructure as well as install all the Q point deployment was just one simple click on the deploy one",
    "start": "677190",
    "end": "685319"
  },
  {
    "text": "development side we are also making a lot of different investment and I won't just want to highlight two of them one",
    "start": "685319",
    "end": "692160"
  },
  {
    "text": "is our PI torch operator when we first got started we focused on TF job and now",
    "start": "692160",
    "end": "698100"
  },
  {
    "text": "we're look we're listening to the community and we're hearing that people care about using PI torch on cue flow",
    "start": "698100",
    "end": "704160"
  },
  {
    "text": "and now our PI torch operator has feature parity with TF job",
    "start": "704160",
    "end": "709950"
  },
  {
    "text": "while the biggest obstacles to getting quality models is to make sure that you",
    "start": "709950",
    "end": "715740"
  },
  {
    "text": "have the proper hyper parameters for your models and that's why hyper parameter tuning it's super super",
    "start": "715740",
    "end": "721790"
  },
  {
    "text": "important to us and as part of cue flow 0.3 we announced a hyper parameter",
    "start": "721790",
    "end": "727860"
  },
  {
    "text": "tuning CRD it's called study job that enables you to do hyper parameter tuning",
    "start": "727860",
    "end": "733050"
  },
  {
    "text": "and searching without needing to write any code so I talked about the general themes of what we have in kill queue",
    "start": "733050",
    "end": "739860"
  },
  {
    "text": "flow 0.3 let's double click on some of the things and I'll show a couple demos",
    "start": "739860",
    "end": "745910"
  },
  {
    "text": "so the first one is for deploy we have something called quick to deploy we've",
    "start": "745910",
    "end": "751770"
  },
  {
    "text": "been hearing from the community that it's very difficult to get started with queue flow because you need to install",
    "start": "751770",
    "end": "757550"
  },
  {
    "text": "packaging libraries and then you need to download and install the different components that comes with SKU flow we",
    "start": "757550",
    "end": "764220"
  },
  {
    "text": "want to make that getting started experience much much easier so what we came up with is a one-click installation",
    "start": "764220",
    "end": "771270"
  },
  {
    "text": "tool it is available to you with a very clean web interface so it's a web app and the way you would use it is",
    "start": "771270",
    "end": "778220"
  },
  {
    "text": "basically it uses a bootstrap container and there's this one bash script that",
    "start": "778220",
    "end": "783960"
  },
  {
    "text": "you can use and it has all the necessary dependencies included was a bash script you can then use it in any",
    "start": "783960",
    "end": "791850"
  },
  {
    "text": "infrastructure deployment tool so that would be deployment manager on GCP or CloudFormation IDs and finally what",
    "start": "791850",
    "end": "800700"
  },
  {
    "text": "you're seeing we're gonna see now has Note happening to need it at all it's really just one click to deploy and also",
    "start": "800700",
    "end": "807600"
  },
  {
    "text": "provision all the infrastructure that you need for cue flow so let's take a look at what it means",
    "start": "807600",
    "end": "815690"
  },
  {
    "text": "so what you're seeing now is our cue flow clip to deploy interface on GCP",
    "start": "816480",
    "end": "824510"
  },
  {
    "text": "all you need to do is specify what project you want to deploy in the name of the deployment and some security",
    "start": "829220",
    "end": "836360"
  },
  {
    "text": "configurations then the click to deploy it will actually provision the",
    "start": "836360",
    "end": "842000"
  },
  {
    "text": "infrastructure on top of GCP meaning that there will actually be a cluster the spinning up that will host your cube",
    "start": "842000",
    "end": "849890"
  },
  {
    "text": "flow components so as you can see after I did the click to deploy now I have AQ flow cluster it's",
    "start": "849890",
    "end": "858010"
  },
  {
    "text": "provisioned through the click to deploy on GCP why go to the workloads pad",
    "start": "858010",
    "end": "863500"
  },
  {
    "text": "workflows page and i refresh to see what actually happened on the cluster",
    "start": "863500",
    "end": "870130"
  },
  {
    "text": "all the deployment and pod that comes out of the box for people in this remember all what you just seen is one",
    "start": "872060",
    "end": "880730"
  },
  {
    "text": "click to deploy so you're not using any templating tool like case on it",
    "start": "880730",
    "end": "886990"
  },
  {
    "text": "you",
    "start": "887070",
    "end": "889130"
  },
  {
    "text": "you",
    "start": "893649",
    "end": "895709"
  },
  {
    "text": "the second thing that we want to highlight is Q plop I clients this was announced very recently and what we see",
    "start": "900050",
    "end": "908270"
  },
  {
    "text": "and noticed the community is that machine learning solutions are often multi-staged there are a lot of",
    "start": "908270",
    "end": "914750"
  },
  {
    "text": "components currently in Q flow that deals with each of the stage but it was very difficult to pull all the different",
    "start": "914750",
    "end": "920870"
  },
  {
    "text": "stage and components together and that's why we have to flow pipelines it is a micro service platform it is designed to",
    "start": "920870",
    "end": "928459"
  },
  {
    "text": "enable reusable components and workflow orchestration so it is a one place where",
    "start": "928459",
    "end": "934010"
  },
  {
    "text": "you can orchestrate all the different components and run machine learning and to end what it is is that is a Python",
    "start": "934010",
    "end": "941540"
  },
  {
    "text": "SDK and you can use the Python SDK to describe and containerize your machine learning tasks we choose Python because",
    "start": "941540",
    "end": "948290"
  },
  {
    "text": "this is very natural to data scientists so that they can read we can really meet",
    "start": "948290",
    "end": "954200"
  },
  {
    "text": "where they are so that they can themselves describe what they're trying to do with their whole machine learning",
    "start": "954200",
    "end": "959950"
  },
  {
    "text": "task after they describe their pipeline in the Python SDK we will compile it to",
    "start": "959950",
    "end": "967560"
  },
  {
    "text": "argl which is coming already in the box from Q flow and we also as pipelines we",
    "start": "967560",
    "end": "975040"
  },
  {
    "text": "offer a front-end GUI to do experiment logging as well as analytics what's",
    "start": "975040",
    "end": "981430"
  },
  {
    "text": "really important about this is that all of these steps are containerized what",
    "start": "981430",
    "end": "986709"
  },
  {
    "text": "that means is that you all the data scientists will be able to compose what they're trying to do to their knees to",
    "start": "986709",
    "end": "994209"
  },
  {
    "text": "form the pipeline they're looking for let me show you how that looks like in action",
    "start": "994209",
    "end": "1001670"
  },
  {
    "text": "so let's start by looking at a very simple pipeline",
    "start": "1003990",
    "end": "1009950"
  },
  {
    "text": "so in this pipeline we will use a very simple training example that utilizes",
    "start": "1011570",
    "end": "1017790"
  },
  {
    "text": "GPUs so in this Python script as you can see we have two main operators the first",
    "start": "1017790",
    "end": "1024390"
  },
  {
    "text": "operator is the training operator and the second operator is the post-processing operator in the training",
    "start": "1024390",
    "end": "1030630"
  },
  {
    "text": "operator because this is all container base we're getting a image this is where",
    "start": "1030630",
    "end": "1036689"
  },
  {
    "text": "our images is a very simple straightforward Minnis example and we are using GPU to Train it as each step",
    "start": "1036690",
    "end": "1044130"
  },
  {
    "text": "of pipelines it has a series of the input parameters as well as output so",
    "start": "1044130",
    "end": "1050250"
  },
  {
    "text": "for example in this training container it has three inputs that we're giving it",
    "start": "1050250",
    "end": "1057090"
  },
  {
    "text": "so the first one is learning rate second one is number of layers so basically how many layers you have in your neural",
    "start": "1057090",
    "end": "1063270"
  },
  {
    "text": "network and the third one is what kind of optimizer you're choosing so that constructs a single operator the",
    "start": "1063270",
    "end": "1072420"
  },
  {
    "text": "second operator is supposed processing is just like vanilla post-processing step and here is where we're actually",
    "start": "1072420",
    "end": "1079440"
  },
  {
    "text": "chaining those two together so the first training step we get put in our input",
    "start": "1079440",
    "end": "1085470"
  },
  {
    "text": "parameters and then we chain the output from this step to the post processing operator so that we actually forms a dad",
    "start": "1085470",
    "end": "1092760"
  },
  {
    "text": "and after you have chained everything your graph you then compile your Python",
    "start": "1092760",
    "end": "1099090"
  },
  {
    "text": "script it will actually form a yellow file",
    "start": "1099090",
    "end": "1103670"
  },
  {
    "text": "so the second Sep I will actually compile my pie so script here is the yellow file that I",
    "start": "1104380",
    "end": "1110470"
  },
  {
    "text": "generated so as I mentioned the whole point is that we want to meet data scientists where they are and in this",
    "start": "1110470",
    "end": "1117130"
  },
  {
    "text": "case is actually Python and from the Python we generate the yellow file and that can be consumed actually by cube",
    "start": "1117130",
    "end": "1123820"
  },
  {
    "text": "flow and kubernetes",
    "start": "1123820",
    "end": "1126600"
  },
  {
    "text": "as you can see the yellow file generated is quite long so here what you see here",
    "start": "1132920",
    "end": "1139790"
  },
  {
    "text": "is the actual pipeline GUI it comes out of the box today with cube flow on the",
    "start": "1139790",
    "end": "1147200"
  },
  {
    "text": "left side you can see that we offer pipelines experiments and on the right side it comes out of the box with a",
    "start": "1147200",
    "end": "1154220"
  },
  {
    "text": "series of sample pipelines that you can explore into so let's click into one of",
    "start": "1154220",
    "end": "1160790"
  },
  {
    "text": "those sample pipelines and look at what it looks like so in this sample file",
    "start": "1160790",
    "end": "1165800"
  },
  {
    "text": "each steps in the graph in the in the dag is a container right step and this",
    "start": "1165800",
    "end": "1172430"
  },
  {
    "text": "one goes all the way from validation to pre-processing to training enter",
    "start": "1172430",
    "end": "1177680"
  },
  {
    "text": "prediction",
    "start": "1177680",
    "end": "1180220"
  },
  {
    "text": "as I mentioned each step is a container right step it has a series of inputs in",
    "start": "1183430",
    "end": "1188710"
  },
  {
    "text": "series the output the graph really makes it easy to show the data scientists what",
    "start": "1188710",
    "end": "1194560"
  },
  {
    "text": "the steps are whether the inputs are and how they're connected to each other",
    "start": "1194560",
    "end": "1200340"
  },
  {
    "text": "okay after we saw the sample steps let's take what we just saw the Python file",
    "start": "1206030",
    "end": "1211640"
  },
  {
    "text": "and the llamo they compiled we can upload the Yamaha into the pipeline's UI",
    "start": "1211640",
    "end": "1218410"
  },
  {
    "text": "and now you have a new pipeline that's on the you on the GUI so we have the",
    "start": "1218990",
    "end": "1226010"
  },
  {
    "text": "concepts of experiment and runs because the goal of the pipelines is to make",
    "start": "1226010",
    "end": "1232070"
  },
  {
    "text": "sure that you you can reuse your component as much as possible so each",
    "start": "1232070",
    "end": "1237080"
  },
  {
    "text": "experiment can have multiple runs each with different input parameters",
    "start": "1237080",
    "end": "1243460"
  },
  {
    "text": "here you can see those are the three parameters that we specified for the training step",
    "start": "1243820",
    "end": "1250110"
  },
  {
    "text": "what you can do now is actually to start an experiment meaning that you will run",
    "start": "1252990",
    "end": "1258059"
  },
  {
    "text": "at one time so let's say we run it for the first time the name will be pipeline",
    "start": "1258059",
    "end": "1264150"
  },
  {
    "text": "run one and here are the parameters that we put in",
    "start": "1264150",
    "end": "1269480"
  },
  {
    "text": "so right here you can also track where your experiments are and see some of the",
    "start": "1272520",
    "end": "1278130"
  },
  {
    "text": "parameters so those are the things that I want to show you for pipelines",
    "start": "1278130",
    "end": "1284030"
  },
  {
    "text": "let's go to the next components that we want to highlight so this is we want to",
    "start": "1284030",
    "end": "1291230"
  },
  {
    "text": "talk about auto scaling and the reason we want to talk about it is that today if you want a data scientist in the",
    "start": "1291230",
    "end": "1298310"
  },
  {
    "text": "organization wants to have something once after they have a model working and",
    "start": "1298310",
    "end": "1303560"
  },
  {
    "text": "when they want to train things in scale they have to talk to somebody else in the organization the IT ops person so",
    "start": "1303560",
    "end": "1311690"
  },
  {
    "text": "our data scientist say my motto is working great but I need six nodes the IT ops person is there to help but she",
    "start": "1311690",
    "end": "1319070"
  },
  {
    "text": "is really pretty busy so it's gonna take some time for this to actually happen in the mean time data scientist",
    "start": "1319070",
    "end": "1325130"
  },
  {
    "text": "kind of is welcome what's going on so when the IT ops person yes to it she",
    "start": "1325130",
    "end": "1330140"
  },
  {
    "text": "provisioned six note the data scientist is happy and continues to do her work and after doing lots of work all the",
    "start": "1330140",
    "end": "1337640"
  },
  {
    "text": "training is done she is kind of wanting to move on to other things to finish her",
    "start": "1337640",
    "end": "1343190"
  },
  {
    "text": "job in the meantime both people it's very likely that the most people forget",
    "start": "1343190",
    "end": "1348590"
  },
  {
    "text": "to turn off the nose that provision and that's really bad because a lot of these",
    "start": "1348590",
    "end": "1355250"
  },
  {
    "text": "cases these involve GPUs and it's going to cost lots of money",
    "start": "1355250",
    "end": "1360330"
  },
  {
    "text": "so that's why we have integrated jobs with auto-scaling feature so our goal is",
    "start": "1360330",
    "end": "1367080"
  },
  {
    "text": "that the data scientist just needs to describe the job crewmen ATIS will take",
    "start": "1367080",
    "end": "1372480"
  },
  {
    "text": "care of the rest so that that includes the CPUs are looking for the memory as well as any accelerator that's needed so",
    "start": "1372480",
    "end": "1380220"
  },
  {
    "text": "be a GPU CPU FPGA TPU what-have-you when the job is done the resources themself",
    "start": "1380220",
    "end": "1386880"
  },
  {
    "text": "are going to be automatically deleted so things will scale down by themselves and",
    "start": "1386880",
    "end": "1392840"
  },
  {
    "text": "these resources you can also have a maxed maximum skilled parameters so your",
    "start": "1392840",
    "end": "1399750"
  },
  {
    "text": "data scientists wouldn't be asking about asking for like ten thousand GPUs all",
    "start": "1399750",
    "end": "1404910"
  },
  {
    "text": "the time so in this scenario what will happen is that your data scientists have their",
    "start": "1404910",
    "end": "1411580"
  },
  {
    "text": "model ready she wants to train things that scale she then writes a file to specify what",
    "start": "1411580",
    "end": "1418240"
  },
  {
    "text": "things what resources she is really looking for so in this case she wants six replicas",
    "start": "1418240",
    "end": "1425460"
  },
  {
    "text": "the GPUs are provisioned automatically with cue flow and kubernetes when the",
    "start": "1425490",
    "end": "1430860"
  },
  {
    "text": "job is done the resource are gone automatically so they don't need to worry about over provisioning or",
    "start": "1430860",
    "end": "1437159"
  },
  {
    "text": "overspending or resources sitting idle and our IT ops people she will be happy",
    "start": "1437159",
    "end": "1442649"
  },
  {
    "text": "because now she has free cycles to do things that matter or it may be talked about YouTube",
    "start": "1442649",
    "end": "1449460"
  },
  {
    "text": "so let me show you what that looks like in practice",
    "start": "1449460",
    "end": "1455520"
  },
  {
    "text": "so this is going to continue what we were just looking at in pipelines so",
    "start": "1455630",
    "end": "1460820"
  },
  {
    "text": "remember when we first provisioned our gke cluster we only had one node pool",
    "start": "1460820",
    "end": "1466100"
  },
  {
    "text": "and that no pool is CPU only but the training step in my pipeline actually",
    "start": "1466100",
    "end": "1472010"
  },
  {
    "text": "requires a GPU so what's going to happen there when we look at the workloads we see our",
    "start": "1472010",
    "end": "1479180"
  },
  {
    "text": "pipeline is currently initially unscheduled and when we go there we can",
    "start": "1479180",
    "end": "1484460"
  },
  {
    "text": "actually see the reason behind it is that there is not enough GPUs that's required to do the training so there is",
    "start": "1484460",
    "end": "1492320"
  },
  {
    "text": "a feature called knowled ultra provisioning that's able to detect the reason why the drop is not being",
    "start": "1492320",
    "end": "1498590"
  },
  {
    "text": "able to scheduled and now it is working to spin up a new node pool that's able",
    "start": "1498590",
    "end": "1507110"
  },
  {
    "text": "to accommodate your job so what you're seeing right now is that because we have the pipeline job that requires the GPU",
    "start": "1507110",
    "end": "1513440"
  },
  {
    "text": "now instead of one node pool and three nodes we have two node poles with the",
    "start": "1513440",
    "end": "1518750"
  },
  {
    "text": "second node pool have the GPU to accommodate the pipeline",
    "start": "1518750",
    "end": "1524350"
  },
  {
    "text": "okay now when we refresh that we could see that the training is done but in this scenario we could see that the",
    "start": "1527380",
    "end": "1534940"
  },
  {
    "text": "validation accuracy is only around 10% so that's not very ideal earlier we",
    "start": "1534940",
    "end": "1541419"
  },
  {
    "text": "talked about how hyper parameter chaining is super important to how data scientists do their work and now I'm",
    "start": "1541419",
    "end": "1548260"
  },
  {
    "text": "going to show you how this will work in the Q blow scenario so in Q flow 0.3 we",
    "start": "1548260",
    "end": "1555880"
  },
  {
    "text": "a now study job which is the CR D for hyper parameter tuning what you can do",
    "start": "1555880",
    "end": "1561520"
  },
  {
    "text": "here is that you want to have a piper parameter tuning job to make sure that we have the right input parameters for",
    "start": "1561520",
    "end": "1568090"
  },
  {
    "text": "your training job and here I've applied a yellow file you can see that this is",
    "start": "1568090",
    "end": "1573159"
  },
  {
    "text": "our study job spinning up and we could have a quick look at what",
    "start": "1573159",
    "end": "1580070"
  },
  {
    "text": "that study job looks like so this would be how I describe my hyper",
    "start": "1580070",
    "end": "1587860"
  },
  {
    "text": "parameter tuning in this case you can see that I'm actually trying to",
    "start": "1587860",
    "end": "1595080"
  },
  {
    "text": "tune three different things the first thing I'm trying to tune is the learning rate the second thing is the number of",
    "start": "1595080",
    "end": "1601559"
  },
  {
    "text": "new or network layers and the third thing is what kind of optimizer I'm looking for",
    "start": "1601559",
    "end": "1608330"
  },
  {
    "text": "and again we want the hyper parameter tuning job to use GP us while to",
    "start": "1611160",
    "end": "1616200"
  },
  {
    "text": "maximize performance again you can see that in the beginning",
    "start": "1616200",
    "end": "1622910"
  },
  {
    "text": "there was not enough GPUs because we are looking for more GPUs for high performance training but eventually",
    "start": "1622910",
    "end": "1628460"
  },
  {
    "text": "expense of two more GPU no to accommodate this job as well",
    "start": "1628460",
    "end": "1634330"
  },
  {
    "text": "you as part of catted our hyper parameter",
    "start": "1640550",
    "end": "1648400"
  },
  {
    "text": "chaining component it comes with its own component called mono dB",
    "start": "1648400",
    "end": "1653410"
  },
  {
    "text": "so this is a front-end UI that shows it will help you visualize and analyze the",
    "start": "1653410",
    "end": "1660430"
  },
  {
    "text": "results of your hyper parameter tuning jobs so in this example you can see on",
    "start": "1660430",
    "end": "1665560"
  },
  {
    "text": "top so the y axis is a validation accuracy and each of these dots",
    "start": "1665560",
    "end": "1671680"
  },
  {
    "text": "represent a new run of job we're trying to see so you can see that some of the",
    "start": "1671680",
    "end": "1680350"
  },
  {
    "text": "runs are have very low accuracy around 10% and some of them have higher accuracy around 99%",
    "start": "1680350",
    "end": "1689580"
  },
  {
    "text": "so naturally you want to be able to analyze why you have such a difference",
    "start": "1690530",
    "end": "1698180"
  },
  {
    "text": "and model DB will help you do that",
    "start": "1698180",
    "end": "1702520"
  },
  {
    "text": "you so the first thing we try to do is we",
    "start": "1708400",
    "end": "1714539"
  },
  {
    "text": "try to do a group buy on the different optimizers and we want to see their",
    "start": "1714539",
    "end": "1721740"
  },
  {
    "text": "average validation accuracy so as I mentioned we have we're looking at three",
    "start": "1721740",
    "end": "1727289"
  },
  {
    "text": "different optimizers and from this graph we could tell immediately that one optimizer was trouble so we could either",
    "start": "1727289",
    "end": "1734580"
  },
  {
    "text": "select the Adam operator or the SGD operator and furthermore we want to do a",
    "start": "1734580",
    "end": "1739950"
  },
  {
    "text": "little more drill down so let's say we only filter on the runs that uses SGD as",
    "start": "1739950",
    "end": "1745590"
  },
  {
    "text": "the optimizer and then from the model DB UI",
    "start": "1745590",
    "end": "1752330"
  },
  {
    "text": "you'll be able to group by on the different metric so this time let's say group by a number of layers and in this",
    "start": "1752730",
    "end": "1761100"
  },
  {
    "text": "case you can see either it's either two layers or three layers doesn't really make a difference your accuracy so that",
    "start": "1761100",
    "end": "1766530"
  },
  {
    "text": "doesn't matter and then have a look at learning rate and similar things apply so after we have the insight into our",
    "start": "1766530",
    "end": "1774030"
  },
  {
    "text": "hyper parameters we can go into our pipeline and then do a second run this time we know what to put in for the",
    "start": "1774030",
    "end": "1780330"
  },
  {
    "text": "optimizers so instead of the previous one we will put stochastic gradient descent because we know that's the one",
    "start": "1780330",
    "end": "1786540"
  },
  {
    "text": "that's gonna give the best result now we run the pipeline for the second time go",
    "start": "1786540",
    "end": "1793200"
  },
  {
    "text": "back to the graph you can see that the training drop is running at the moment this time you were able to achieve more",
    "start": "1793200",
    "end": "1799400"
  },
  {
    "text": "than 99% of validation accuracy and again because this",
    "start": "1799400",
    "end": "1805789"
  },
  {
    "text": "say dag runner we're able to do the post-processing immediately after the training",
    "start": "1805789",
    "end": "1812649"
  },
  {
    "text": "and what's most is that you can see now we used to have",
    "start": "1813510",
    "end": "1818869"
  },
  {
    "text": "six notes to note pools with three different GPUs but after we run our two",
    "start": "1818869",
    "end": "1825019"
  },
  {
    "text": "pipelines as well as a hyper prompt there's opportunity job we're back to three notes this is exactly where we",
    "start": "1825019",
    "end": "1831349"
  },
  {
    "text": "started instead of having to manually tune down or spin down your nose that",
    "start": "1831349",
    "end": "1837139"
  },
  {
    "text": "has a lot of resources hash to it we ended up spinning it down automatically for you so you don't",
    "start": "1837139",
    "end": "1843649"
  },
  {
    "text": "really have to worry about any of that the auto scaling really comes to the rescue so that concludes my demo I'm gonna hand",
    "start": "1843649",
    "end": "1851149"
  },
  {
    "text": "it back to David to talk about roadmap",
    "start": "1851149",
    "end": "1854859"
  },
  {
    "text": "so thank you so much Faye we are just getting started we are quickly marching",
    "start": "1861470",
    "end": "1869779"
  },
  {
    "text": "towards 1.0 and would love to hear your feedback what are the things that are missing what are critical particularly",
    "start": "1869779",
    "end": "1876139"
  },
  {
    "text": "around enterprise requirements things like upgrades integration with I am and our back one of the things we've heard a",
    "start": "1876139",
    "end": "1882230"
  },
  {
    "text": "lot about is how to be more closely tied with Jupiter we know that Jupiter is the",
    "start": "1882230",
    "end": "1887240"
  },
  {
    "text": "place where data scientists are working right now and we want to make it very very easy to tie those together and",
    "start": "1887240",
    "end": "1893090"
  },
  {
    "text": "provide a much richer pipeline experimentation and model management these are core things that we've already",
    "start": "1893090",
    "end": "1898730"
  },
  {
    "text": "heard about we're trying to get to them by 1.0 but we'd really love to hear what you would like next and I really want to",
    "start": "1898730",
    "end": "1904700"
  },
  {
    "text": "stress this it is a brand-new world the people in this room the people watching this on the video you have the ability",
    "start": "1904700",
    "end": "1911240"
  },
  {
    "text": "to make huge changes in industry I strongly ask you all to think deeply",
    "start": "1911240",
    "end": "1917509"
  },
  {
    "text": "about ethical sustainable ml that can",
    "start": "1917509",
    "end": "1922970"
  },
  {
    "text": "help the world move forward because we really do have a chance to make an enormous change and things we hope that",
    "start": "1922970",
    "end": "1928129"
  },
  {
    "text": "things like cube flow will help enable that and give the power to two data scientists to make that happen quickly",
    "start": "1928129",
    "end": "1934960"
  },
  {
    "text": "we are open open you know in every way it's possible to be open community",
    "start": "1934960",
    "end": "1940009"
  },
  {
    "text": "design open source come to github this is not by any stretch a Google only",
    "start": "1940009",
    "end": "1945320"
  },
  {
    "text": "project we want to continually meet your needs so you don't have to go out and build your own bespoke platforms and",
    "start": "1945320",
    "end": "1952429"
  },
  {
    "text": "with that off we go any questions yeah",
    "start": "1952429",
    "end": "1960850"
  },
  {
    "text": "so we are in the midst of we already have some governance proposals right now we hope to I don't know by the end of",
    "start": "1966240",
    "end": "1973920"
  },
  {
    "text": "the year have a more formal external governance proposal that is absolutely a core goal",
    "start": "1973920",
    "end": "1980059"
  },
  {
    "text": "any other questions",
    "start": "1982520",
    "end": "1985540"
  },
  {
    "text": "okay oh yeah",
    "start": "1987590",
    "end": "1991028"
  },
  {
    "text": "you",
    "start": "1993880",
    "end": "1995940"
  },
  {
    "text": "so the question was if I understood during the hyper parameter tuning we",
    "start": "2010990",
    "end": "2017620"
  },
  {
    "text": "store the outputs of the various choices that the hyper parameter optimizer was",
    "start": "2017620",
    "end": "2023529"
  },
  {
    "text": "using we don't store the artifacts of the model we're just doing a cat tib is",
    "start": "2023529",
    "end": "2029679"
  },
  {
    "text": "is storing the the metadata related to the model in model DB and that's what's allowing the comparison in order to do a",
    "start": "2029679",
    "end": "2036399"
  },
  {
    "text": "full model run you would then do exactly I faded on the board you would take that metadata put it back into your pipeline",
    "start": "2036399",
    "end": "2043330"
  },
  {
    "text": "and then that would do a full training run does that answer your question okay",
    "start": "2043330",
    "end": "2049260"
  },
  {
    "text": "yeah last question yeah",
    "start": "2049260",
    "end": "2056500"
  },
  {
    "text": "yeah",
    "start": "2060099",
    "end": "2063099"
  },
  {
    "text": "you yes so the question was if you are new",
    "start": "2067410",
    "end": "2073620"
  },
  {
    "text": "to machine learning should you use cube flow to get started and is it feasible",
    "start": "2073620",
    "end": "2079770"
  },
  {
    "text": "to use it on a single computer the direct answer is you can certainly experiment Jupiter and Conda and these",
    "start": "2079770",
    "end": "2085830"
  },
  {
    "text": "things are great and there are great ways to try out machine learning and we recommend it that said the purpose the",
    "start": "2085830",
    "end": "2092639"
  },
  {
    "text": "design behind cube flow is to work great all across the spectrum whether or not you're on a single laptop like this all",
    "start": "2092640",
    "end": "2099120"
  },
  {
    "text": "the way up to a must multi cluster deployment and the benefit is because you're describing your entire machine",
    "start": "2099120",
    "end": "2105060"
  },
  {
    "text": "learning pipeline using very standard tools that run great anywhere including mini cube on your laptop it means",
    "start": "2105060",
    "end": "2112140"
  },
  {
    "text": "there's very little change when you decide to graduate to larger and larger machine sizes it'll work fine no matter",
    "start": "2112140",
    "end": "2118650"
  },
  {
    "text": "where it is now to be clear on your local laptop you're not gonna want to download a petabyte of data and you know",
    "start": "2118650",
    "end": "2125130"
  },
  {
    "text": "do a full training run it's great for experimentation jupiter comes in the box tensorflow job comes in the box",
    "start": "2125130",
    "end": "2131610"
  },
  {
    "text": "pi torch comes in the box --cat tube comes in the box these are all things that are very trivial or they may not",
    "start": "2131610",
    "end": "2136800"
  },
  {
    "text": "all come into the box very trivial to install and you can get it running even locally and see all the richness that",
    "start": "2136800",
    "end": "2142770"
  },
  {
    "text": "you saw here it is explicitly to be clear with everyone it is explicitly our",
    "start": "2142770",
    "end": "2147960"
  },
  {
    "text": "goal to be as easy or easier than just going and doing pip install foo to get",
    "start": "2147960",
    "end": "2155430"
  },
  {
    "text": "starting with machine learning and we know we're not there yet but with the investments that we made around you know KF control and other things like that",
    "start": "2155430",
    "end": "2161280"
  },
  {
    "text": "we're hoping to get there very quickly right thank you all thanks everybody",
    "start": "2161280",
    "end": "2168880"
  },
  {
    "text": "[Applause]",
    "start": "2168880",
    "end": "2174479"
  }
]
[
  {
    "text": "who's your first time in observability day please raise your hand wow wow okay",
    "start": "40",
    "end": "6839"
  },
  {
    "text": "we should done that in the morning so we try to do this event in very very",
    "start": "6839",
    "end": "12080"
  },
  {
    "text": "Community Based so what is really important from this event is around the networking and hey meet good and cool",
    "start": "12080",
    "end": "20480"
  },
  {
    "text": "people learn from each other so when you get this time breaks for lunch for",
    "start": "20480",
    "end": "25560"
  },
  {
    "text": "coffee hey introduce each other I work here I do this I do that and you will",
    "start": "25560",
    "end": "30640"
  },
  {
    "text": "see that you will get ton of value and the goal of this event is to build also Community around the observability space",
    "start": "30640",
    "end": "37960"
  },
  {
    "text": "so everybody's join to is welcome to join us to learn and share knowledge",
    "start": "37960",
    "end": "44079"
  },
  {
    "text": "okay so with this I'm going to introduce our next speaker speaker Ian Ryan he comes",
    "start": "44079",
    "end": "50960"
  },
  {
    "text": "from grafana Labs he introduced himself as somebody who knows a lot of grafana projects and products so you can talk to",
    "start": "50960",
    "end": "58719"
  },
  {
    "text": "him after the the session and he's going to talk Us in this presentation called but wait there's still more",
    "start": "58719",
    "end": "65000"
  },
  {
    "text": "observability data volumes and strategies for Mone to them let's welcome demon",
    "start": "65000",
    "end": "71680"
  },
  {
    "text": "Ryan thank you hi folks uh very nice to be able to",
    "start": "71680",
    "end": "79400"
  },
  {
    "text": "speak to you today about this very fun topic um I had to do a mad scramble uh",
    "start": "79400",
    "end": "85759"
  },
  {
    "text": "in the last little Gap there because during the opening session I realized that uh you couldn't read any of the",
    "start": "85759",
    "end": "91799"
  },
  {
    "text": "dark screenshots in the presentations and my whole deck is in a dark theme uh so that was fun so that's why these two",
    "start": "91799",
    "end": "98520"
  },
  {
    "text": "rows of lights are now out so uh thanks very much to the venue for accommodating that otherwise um I would have to guide",
    "start": "98520",
    "end": "105399"
  },
  {
    "text": "you through all of the slides verbally and that wouldn't have been fun for anybody uh so my name is aan Ryan as",
    "start": "105399",
    "end": "113079"
  },
  {
    "text": "Ardo said uh I'm a senior principal field engineer at graffan Labs I've been there for over 4 and A2 years now",
    "start": "113079",
    "end": "120600"
  },
  {
    "text": "uh which is a very long time in grafana time frame uh it's only been a company for we just passed 10 years actually um",
    "start": "120600",
    "end": "127960"
  },
  {
    "text": "so we got some cool 10e swag for that and that was really cool um but I'm on the field engineering team as you might",
    "start": "127960",
    "end": "133800"
  },
  {
    "text": "guess uh which is had a really fun intersection of engineering and uh",
    "start": "133800",
    "end": "139640"
  },
  {
    "text": "customers and prospective customers at grafana so I'm regularly talking to all kinds of folks about their like their",
    "start": "139640",
    "end": "147280"
  },
  {
    "text": "whole observability problems and their data volume and what they can do about that kind of thing so I wanted to bring",
    "start": "147280",
    "end": "152959"
  },
  {
    "text": "some of that uh knowledge here and even if it's only for people to be like yes",
    "start": "152959",
    "end": "158640"
  },
  {
    "text": "that is a big problem for me too and you know then we can all commiserate about it afterwards so a little bit of uh history",
    "start": "158640",
    "end": "166720"
  },
  {
    "text": "so we go back in time slightly uh apologies if I don't have all the details of this entirely right uh but in",
    "start": "166720",
    "end": "173640"
  },
  {
    "text": "the past metrics if you had them at all they were coming from your",
    "start": "173640",
    "end": "180480"
  },
  {
    "text": "uh probably your bare metal servers uh you maybe had some virtual machines but",
    "start": "180480",
    "end": "186040"
  },
  {
    "text": "we're talking about like early days so if you were using them you probably didn't have them in production you were probably sending",
    "start": "186040",
    "end": "192799"
  },
  {
    "text": "data into a tool like zabic or nagios nagios I don't actually know how to say",
    "start": "192799",
    "end": "198040"
  },
  {
    "text": "it properly one of those uh maybe you were grabbing SNMP data maybe you were",
    "start": "198040",
    "end": "203840"
  },
  {
    "text": "running scripts remotely uh on the machines and sending certain bits of information back and it worked",
    "start": "203840",
    "end": "210519"
  },
  {
    "text": "but the scale of things was a lot different back in those times like zabic first came out in",
    "start": "210519",
    "end": "217360"
  },
  {
    "text": "2001 and uh nagios came out in 2002 and for just to make everybody feel really",
    "start": "217360",
    "end": "224200"
  },
  {
    "text": "old that was 23 years ago uh so that certainly makes me feel old as",
    "start": "224200",
    "end": "230720"
  },
  {
    "text": "well this of course was pre AWS preu",
    "start": "230720",
    "end": "236000"
  },
  {
    "text": "Cloud uh pre Cloud native uh a or Amazon ec2 only left beta in 2008 which is a",
    "start": "236000",
    "end": "242920"
  },
  {
    "text": "whole six years later than these tools uh launching so you know it was a",
    "start": "242920",
    "end": "248239"
  },
  {
    "text": "simpler time uh a better time perhaps",
    "start": "248239",
    "end": "253799"
  },
  {
    "text": "maybe maybe we'll save that argument for the bar so what do metrics look like now",
    "start": "253799",
    "end": "260840"
  },
  {
    "text": "well you still have your bare metal servers but most people are abstracting",
    "start": "260840",
    "end": "265960"
  },
  {
    "text": "on top of that so it's virtual machines uh it's you know running ec2 which uh or",
    "start": "265960",
    "end": "273440"
  },
  {
    "text": "Google Google compute engine or Azure compute and uh if you weren't aware those instances are virtual machines uh",
    "start": "273440",
    "end": "280479"
  },
  {
    "text": "running on top of hypervisors in those data centers you just don't see them uh or you might be running Vere I'm well",
    "start": "280479",
    "end": "287160"
  },
  {
    "text": "acquainted with Vere spent eight years at VMware uh so that was that was my my bread and butter for many",
    "start": "287160",
    "end": "293800"
  },
  {
    "text": "years uh and then you have containers so you know Docker containers pod and uh",
    "start": "293800",
    "end": "300759"
  },
  {
    "text": "you might be orchestrating containers uh using kubernetes uh or something else",
    "start": "300759",
    "end": "306560"
  },
  {
    "text": "and that'll runs great um it's a but basically it's abstractions all the way",
    "start": "306560",
    "end": "311919"
  },
  {
    "text": "down so it's not just containers or VMS or ver metal if you're running containers you're probably running",
    "start": "311919",
    "end": "317120"
  },
  {
    "text": "containers on VMS which are running on bare metal so lot of abstractions and",
    "start": "317120",
    "end": "324400"
  },
  {
    "text": "all of those layers can produce metrics designed to both show you how workloads",
    "start": "324400",
    "end": "329440"
  },
  {
    "text": "are running but also even just to help you distinguish what layer problems are even occurring at uh so it's complicated",
    "start": "329440",
    "end": "337160"
  },
  {
    "text": "and it's voluminous and most people are capturing",
    "start": "337160",
    "end": "342319"
  },
  {
    "text": "and sending sending metrics in in the open source world to tools like Prometheus uh or one of its cousins many",
    "start": "342319",
    "end": "349800"
  },
  {
    "text": "compatible cousins uh Thanos cortex mimir there's a bunch more um or they're",
    "start": "349800",
    "end": "355680"
  },
  {
    "text": "sending it to something like influx DB and dealing with the metric that way um",
    "start": "355680",
    "end": "361720"
  },
  {
    "text": "or they might also be doing something that's instrumented for otel and sending their otel format metrics to any one of",
    "start": "361720",
    "end": "369240"
  },
  {
    "text": "the tons of compatible backends which may include Prometheus as well as you probably know uh but the tool itself the metrics",
    "start": "369240",
    "end": "376720"
  },
  {
    "text": "tool isn't really important for this talk the point is that the workload",
    "start": "376720",
    "end": "382080"
  },
  {
    "text": "quantities have grown uh the complexity has grown in order to try to manage",
    "start": "382080",
    "end": "387599"
  },
  {
    "text": "those workloads more flexibly and efficiently and then consequently uh the metric data volumes",
    "start": "387599",
    "end": "394960"
  },
  {
    "text": "have ballooned massively tracking metric data can easily be on the order of terabytes per",
    "start": "394960",
    "end": "402599"
  },
  {
    "text": "month uh or per week or even day if you're large enough for some",
    "start": "402599",
    "end": "408960"
  },
  {
    "text": "Enterprises on the log side uh again people you know they're pulling logs from their uh bare metal servers though",
    "start": "408960",
    "end": "416360"
  },
  {
    "text": "things did get a bit more complicated as um oper systems evolved and you started to get logs from different processes",
    "start": "416360",
    "end": "422479"
  },
  {
    "text": "that were separated different functions of the system uh different like just segregation pieces and then people",
    "start": "422479",
    "end": "428680"
  },
  {
    "text": "needed to aggregate those different log streams together and that's how we ended up with tools like CIS log NG that came",
    "start": "428680",
    "end": "434319"
  },
  {
    "text": "out in '98 and our CIS log that came out in 2004 uh but what does it look like now",
    "start": "434319",
    "end": "440560"
  },
  {
    "text": "well you have all those same layers so I won't build that out again but each of these of course just like metrics",
    "start": "440560",
    "end": "446240"
  },
  {
    "text": "produces all of their own data uh but what else happened so over time storage",
    "start": "446240",
    "end": "452639"
  },
  {
    "text": "got cheaper and uh developers leaned towards writing uh statements for to",
    "start": "452639",
    "end": "459039"
  },
  {
    "text": "print new log lines more than not so computers got faster more powerful cheaper uh the storage itself got much",
    "start": "459039",
    "end": "466159"
  },
  {
    "text": "cheaper and then that resulted in a situation where now every little service that people write is just spewing log",
    "start": "466159",
    "end": "473759"
  },
  {
    "text": "lines constantly even when things are working totally fine and we all know",
    "start": "473759",
    "end": "479280"
  },
  {
    "text": "that like log levels exist but of course everyone always adheres to log levels right everyone puts everyone puts you",
    "start": "479280",
    "end": "486840"
  },
  {
    "text": "know the important stuff in the in the severe or critical and you know the in the info stuff would never be littered",
    "start": "486840",
    "end": "492360"
  },
  {
    "text": "with debug messages ever no one would ever do otherwise so",
    "start": "492360",
    "end": "498840"
  },
  {
    "text": "tracking log data can easily be on the order of pedabytes per month uh easily",
    "start": "498840",
    "end": "504280"
  },
  {
    "text": "terabytes per day uh for some Enterprises",
    "start": "504280",
    "end": "510280"
  },
  {
    "text": "uh I should have clicked that through but I didn't anyway uh tracing is an interesting one",
    "start": "510479",
    "end": "516320"
  },
  {
    "text": "because tracing uh has existed for a long time uh single threaded processes",
    "start": "516320",
    "end": "522719"
  },
  {
    "text": "could could be traced uh through non-distributed applications that was something that you could do not",
    "start": "522719",
    "end": "527959"
  },
  {
    "text": "everybody did it but once we got into microservices land it became a much bigger deal because being able to figure",
    "start": "527959",
    "end": "534120"
  },
  {
    "text": "out what part of your service was causing a problem was suddenly really really important because everything that",
    "start": "534120",
    "end": "539440"
  },
  {
    "text": "used to be a monolith was now 200 different pieces and you know looked like this uh obviously this is a very",
    "start": "539440",
    "end": "546920"
  },
  {
    "text": "extreme example from Uber but I'm sure if you built out service maps of applications that you run at your jobs",
    "start": "546920",
    "end": "553680"
  },
  {
    "text": "they are probably somewhat similarly scary uh but weirdly you can still find",
    "start": "553680",
    "end": "561160"
  },
  {
    "text": "lots of companies today who haven't touched distributor tracing at all um I",
    "start": "561160",
    "end": "566360"
  },
  {
    "text": "regularly speak to ones who like they're interested in it and they think it's a cool idea but because it's not like",
    "start": "566360",
    "end": "572279"
  },
  {
    "text": "hooking up your logs to a log tool or deploying a Prometheus exporter it requires you to go in and change the",
    "start": "572279",
    "end": "578079"
  },
  {
    "text": "code of your apps varying levels of that depending on whether you're doing Auto or manual instrumentation people are",
    "start": "578079",
    "end": "583680"
  },
  {
    "text": "locked in to do it because it's going to consume time but those that do add it what they find is that very very quickly they they",
    "start": "583680",
    "end": "590800"
  },
  {
    "text": "can have an instant explosion of data volume uh which immediately jumps into",
    "start": "590800",
    "end": "596240"
  },
  {
    "text": "like the terabyte level territory on a regular basis uh since tracing is just so rapid and so frequent and so every",
    "start": "596240",
    "end": "603200"
  },
  {
    "text": "little thing you add just explodes everything immediately uh profiles so I started to",
    "start": "603200",
    "end": "609720"
  },
  {
    "text": "write like a little history thing for profiles but then I realized this one already existed so I didn't write one uh",
    "start": "609720",
    "end": "616240"
  },
  {
    "text": "this is very helpful uh profile is really interesting because it's existed for some time uh I know there was just a",
    "start": "616240",
    "end": "621920"
  },
  {
    "text": "session about profile so hopefully you got some good info there um I was unfortunately busy furiously trying to",
    "start": "621920",
    "end": "627279"
  },
  {
    "text": "figure out if I had to change all my slides to light mode um so I didn't get to watch it but uh",
    "start": "627279",
    "end": "633360"
  },
  {
    "text": "though Google talked about continuous profiling uh back in 2010 uh a lot of",
    "start": "633360",
    "end": "638560"
  },
  {
    "text": "people really hadn't gotten into it in a big way until much more recently it feels like uh even though it can really",
    "start": "638560",
    "end": "644560"
  },
  {
    "text": "help narrow down performance bottlenecks so some of the big uh OSS uh profiling",
    "start": "644560",
    "end": "651120"
  },
  {
    "text": "tools obviously polar signals that you saw this morning uh Pixie uh pyroscope",
    "start": "651120",
    "end": "656680"
  },
  {
    "text": "those are like the ones I hear about most often in those spaces but overall still storing any",
    "start": "656680",
    "end": "663000"
  },
  {
    "text": "kind of continuous data means that it consumes space uh so the more of it you do the more storage you need uh I don't",
    "start": "663000",
    "end": "670519"
  },
  {
    "text": "have as much data on how big the volumes of profiling uh people are running are just because it seems to be the one that",
    "start": "670519",
    "end": "677079"
  },
  {
    "text": "people are doing the least so far so there's not really enough data quite yet but still does consume a bunch of",
    "start": "677079",
    "end": "684360"
  },
  {
    "text": "data so where do we land so I know it looks like I'm about to break these volumes out out by Telemetry uh but I'm",
    "start": "684360",
    "end": "691240"
  },
  {
    "text": "actually not because overall the answer is mostly the same uh for all of them so",
    "start": "691240",
    "end": "697480"
  },
  {
    "text": "volumes these days depending on your application estate size can be anything from terabytes to pedabytes per month uh",
    "start": "697480",
    "end": "705959"
  },
  {
    "text": "or uh gigabytes to terabytes per week or even day and this is a ton of data and",
    "start": "705959",
    "end": "713880"
  },
  {
    "text": "it comes with its own downsides other than just what it costs which is what I'm going to get to next",
    "start": "713880",
    "end": "721240"
  },
  {
    "text": "large volume problems so the first problem uh with",
    "start": "721720",
    "end": "727040"
  },
  {
    "text": "large Telemetry volumes is storage so storage may have gotten cheaper uh over",
    "start": "727040",
    "end": "732880"
  },
  {
    "text": "the years uh especially given the rising popularity of object storage uh but it's",
    "start": "732880",
    "end": "739240"
  },
  {
    "text": "not free nothing's free if you're in your own data center uh your storage can",
    "start": "739240",
    "end": "744720"
  },
  {
    "text": "become full pretty quickly uh at the volume levels I previously described",
    "start": "744720",
    "end": "750320"
  },
  {
    "text": "and then what you're down to either rejecting new data or pruning old data",
    "start": "750320",
    "end": "758440"
  },
  {
    "text": "indiscriminately and neither of those is really ideal is it the second problem is",
    "start": "758440",
    "end": "767440"
  },
  {
    "text": "rights even if you could store all of that data cheaply it isn't free to get",
    "start": "767440",
    "end": "773199"
  },
  {
    "text": "it into your system of choice so you also have to do any necessary",
    "start": "773199",
    "end": "778440"
  },
  {
    "text": "compression and processing before it's written to a long-term storage then you write it to storage and all of those",
    "start": "778440",
    "end": "784760"
  },
  {
    "text": "activities they burn processing power uh they burn memory they burn uh Network",
    "start": "784760",
    "end": "791519"
  },
  {
    "text": "bandwidth and dis usage even if it's like temper usage for while things are going through different",
    "start": "791519",
    "end": "797800"
  },
  {
    "text": "stages the more data that you need to receive and store the more expensive it is to receive and store it if you're in",
    "start": "797800",
    "end": "806360"
  },
  {
    "text": "your own data center you're probably not paying the same for uh Network costs because you're not being charged by the gigabyte but you're",
    "start": "806360",
    "end": "814399"
  },
  {
    "text": "still paying for the max throughput you still have to buy those devices and you're paying for the CPU and the memory",
    "start": "814399",
    "end": "820560"
  },
  {
    "text": "and the dis and they all cost money either way whether it's public or private granted it's capex versus Opex",
    "start": "820560",
    "end": "826279"
  },
  {
    "text": "but you're paying for it either way on a private uh data center maxing",
    "start": "826279",
    "end": "832399"
  },
  {
    "text": "out means rejecting new data and in on public Cloud it means either you're rejecting new data because you don't",
    "start": "832399",
    "end": "838560"
  },
  {
    "text": "you're Del liely not scaling or uh you do scale and the public Cloud lets you",
    "start": "838560",
    "end": "844160"
  },
  {
    "text": "scale as far as you need to go but now your costs have become absolutely",
    "start": "844160",
    "end": "849360"
  },
  {
    "text": "ridiculous the third problem is reads so even if you could store all of that data",
    "start": "849360",
    "end": "855079"
  },
  {
    "text": "cheaply and even if you could write it and compress it cheaply you still need",
    "start": "855079",
    "end": "860519"
  },
  {
    "text": "to actually read it back out uh for it to be useful so indexing data traversing it",
    "start": "860519",
    "end": "868279"
  },
  {
    "text": "splitting big qu iies into multiple smaller ones so that you can run them in parallel and get people their actual",
    "start": "868279",
    "end": "874600"
  },
  {
    "text": "query result faster uh with a lower execution time uh all of those",
    "start": "874600",
    "end": "880720"
  },
  {
    "text": "activities just like wrs uh burn processing power they burn memory the burn Network bandwidth and disk usage",
    "start": "880720",
    "end": "887560"
  },
  {
    "text": "and the more data that you stored the more expensive it is to iterate over it index it query it and so on network",
    "start": "887560",
    "end": "895279"
  },
  {
    "text": "traffic is less of a concern sometimes on the read side at least if you're within like a single a uh on like a",
    "start": "895279",
    "end": "902800"
  },
  {
    "text": "public Cloud but whether it's public or private running these huge volumes means that you're paying more for CPU and",
    "start": "902800",
    "end": "908519"
  },
  {
    "text": "memory and dis to do the necessary work to make the data useful if you run out of capacity now your reads fail or they",
    "start": "908519",
    "end": "916000"
  },
  {
    "text": "become unacceptably slow uh and the users get really unhappy because their query takes 45 seconds to",
    "start": "916000",
    "end": "924000"
  },
  {
    "text": "return uh I should have had this plan and I didn't so the fourth problem is on",
    "start": "924959",
    "end": "930279"
  },
  {
    "text": "the expertise side uh the larger your Telemetry volumes the larger the systems",
    "start": "930279",
    "end": "936079"
  },
  {
    "text": "that you have to run to handle them uh so that's either massive clusters or it's too many clusters or too many",
    "start": "936079",
    "end": "944240"
  },
  {
    "text": "massive clusters if you're really in a bind all of this requires more and more",
    "start": "944240",
    "end": "949959"
  },
  {
    "text": "expertise so we end up hiring more and more nerds like me and you uh to help run",
    "start": "949959",
    "end": "957880"
  },
  {
    "text": "these massive systems uh at immense cost and you know job security",
    "start": "957880",
    "end": "963560"
  },
  {
    "text": "notwithstanding or you end up paying you know a vendor to take this whole problem off your hands uh but still those",
    "start": "963560",
    "end": "970079"
  },
  {
    "text": "massive volumes are going to cost you since any you know SAS observability vendor is charging my volume",
    "start": "970079",
    "end": "976440"
  },
  {
    "text": "anyway so what do people do uh people often take uh the very",
    "start": "976440",
    "end": "983680"
  },
  {
    "text": "Hasty and harsh approach of well this cost too much uh so stop doing it",
    "start": "983680",
    "end": "989440"
  },
  {
    "text": "so you know shut it all down this is obviously bad since it reduces",
    "start": "989440",
    "end": "995040"
  },
  {
    "text": "visibility indiscriminately or they might slice things up and only send their most",
    "start": "995040",
    "end": "1002440"
  },
  {
    "text": "critical metrics to their uh good expensive system and for example keep",
    "start": "1002440",
    "end": "1007959"
  },
  {
    "text": "like their test metrics or their Dev metrics on a cheaper slower uh more cost effective system that maybe works but",
    "start": "1007959",
    "end": "1015639"
  },
  {
    "text": "far less well and uh with a different user experience to the good system uh",
    "start": "1015639",
    "end": "1021319"
  },
  {
    "text": "this is bad since it means that users have to know two two two totally separate uh user experiences with",
    "start": "1021319",
    "end": "1027678"
  },
  {
    "text": "different feature sets uh all their data isn't in the one place uh they're less used to both systems and so",
    "start": "1027679",
    "end": "1034880"
  },
  {
    "text": "on or they just abandon ship and they",
    "start": "1034880",
    "end": "1040240"
  },
  {
    "text": "jump to another solution entirely uh thinking that it will be magically immensely cheaper somehow and while this",
    "start": "1040240",
    "end": "1047640"
  },
  {
    "text": "can somewhat work if you were for example paying a SAS vendor since one might give you a drastically different",
    "start": "1047640",
    "end": "1053559"
  },
  {
    "text": "uh price to another one that's not what we're talking about here we're talking about OSS Solutions and the reality is",
    "start": "1053559",
    "end": "1059679"
  },
  {
    "text": "everything requires as I already said CPU memory dis uh and network so another",
    "start": "1059679",
    "end": "1065640"
  },
  {
    "text": "tool isn't going to be magically 10 times cheaper than another one uh unless",
    "start": "1065640",
    "end": "1070760"
  },
  {
    "text": "you were completely using the wrong tool for the type of data you were trying to store in it the underlying backends any",
    "start": "1070760",
    "end": "1077320"
  },
  {
    "text": "kinds of databases uh they tend to gravitate towards similar performance levels over time if somebody makes a",
    "start": "1077320",
    "end": "1083559"
  },
  {
    "text": "leap and figures out a much better way to do something the others will follow in some Due Time",
    "start": "1083559",
    "end": "1088880"
  },
  {
    "text": "eventually but you certainly will incur cost spending the effort to keep jumping tools all the time uh ultimately costing",
    "start": "1088880",
    "end": "1096600"
  },
  {
    "text": "you more in the end so what should people do so on the metric side there's a few",
    "start": "1096600",
    "end": "1104919"
  },
  {
    "text": "major things that you can do uh the first is on the scraping interval now I",
    "start": "1104919",
    "end": "1110520"
  },
  {
    "text": "know scrape interval is somewhat specific to Prometheus uh it doesn't have to be scrape interval I really just",
    "start": "1110520",
    "end": "1115919"
  },
  {
    "text": "mean like the sample rate so whether you're doing push or pull like with otel and you're pushing data the meaning is",
    "start": "1115919",
    "end": "1121640"
  },
  {
    "text": "kind of the same you're reducing the frequency at which you store data points uh which means there's less to store so",
    "start": "1121640",
    "end": "1128440"
  },
  {
    "text": "you might not need the Fidelity you're currently configured for but you may so this is going to be your decision and",
    "start": "1128440",
    "end": "1133880"
  },
  {
    "text": "it's not binary either you might have higher intervals and lower intervals depending on the metric in",
    "start": "1133880",
    "end": "1140000"
  },
  {
    "text": "question the second thing you can do is down sampling and this is kind of the same thing as scrape intervals just done",
    "start": "1140000",
    "end": "1146440"
  },
  {
    "text": "a little later uh because you're still just reducing the sample rate of what you're storing so you might be doing",
    "start": "1146440",
    "end": "1152760"
  },
  {
    "text": "this via like Prometheus recording rules or some other method before it gets to the long-term storage or maybe you're",
    "start": "1152760",
    "end": "1158600"
  },
  {
    "text": "down downsampling older data on the back end akin to something uh like like to",
    "start": "1158600",
    "end": "1163919"
  },
  {
    "text": "something what Thanos can do um but it's worth noting that if you do this for example example to stock Prometheus data",
    "start": "1163919",
    "end": "1171559"
  },
  {
    "text": "uh you can make it incompatible with other Prometheus type Solutions because Prometheus natively itself doesn't",
    "start": "1171559",
    "end": "1178080"
  },
  {
    "text": "support down sampling so now you're modifying the original blocks and when you try to move them to another tool",
    "start": "1178080",
    "end": "1183760"
  },
  {
    "text": "it'll be like I don't know what that data is that looks strange third thing you can do is",
    "start": "1183760",
    "end": "1189000"
  },
  {
    "text": "retention periods so this might be like really obvious but I'm going to point it out if you don't need to store longer or",
    "start": "1189000",
    "end": "1194799"
  },
  {
    "text": "data longer than a given period of time then don't there are ways to manage this somewhat",
    "start": "1194799",
    "end": "1200640"
  },
  {
    "text": "more granularly on certain systems it doesn't have to be All or Nothing uh some systems um like the different",
    "start": "1200640",
    "end": "1207320"
  },
  {
    "text": "Prometheus cousins uh have are multi-tenanted and so you can say tenant a is 3 months tenant B is 6 months",
    "start": "1207320",
    "end": "1214480"
  },
  {
    "text": "tenant C is 12 months and you can send data to the ones that is appropriate for how long you want to store that",
    "start": "1214480",
    "end": "1221200"
  },
  {
    "text": "data uh the fourth thing you can do here is drop unused metrics now probably sounds simple in theory but hard in",
    "start": "1221200",
    "end": "1228440"
  },
  {
    "text": "practice ice because how can you be sure it's actually unused uh but uh graan actually provides",
    "start": "1228440",
    "end": "1234960"
  },
  {
    "text": "a tool to help you with this if you're in Prometheus world so we have a CLI tool called mimir tool and it does not",
    "start": "1234960",
    "end": "1241480"
  },
  {
    "text": "require you to be using mimir to use it the name is a a bit misleading in that way but it has a sub command called",
    "start": "1241480",
    "end": "1248120"
  },
  {
    "text": "analyze and what it can do is look at your Prometheus compatible back end and look at your graffan instance and it'll",
    "start": "1248120",
    "end": "1254640"
  },
  {
    "text": "say hey these are all the uh these are all the metrics that you store that you don't query based off of what's in your dashboards",
    "start": "1254640",
    "end": "1261280"
  },
  {
    "text": "what's in your alerts uh what's in your recording rules so that you can have an easy view of well what do I not need and",
    "start": "1261280",
    "end": "1267520"
  },
  {
    "text": "just strip those out via uh relabel rules the fifth thing here one of the",
    "start": "1267520",
    "end": "1274520"
  },
  {
    "text": "more technically like intelligent ones to do is uh to do aggregation so uh",
    "start": "1274520",
    "end": "1281400"
  },
  {
    "text": "Beyond dropping metrics in series that you don't use you could aggregate away labels that you never query Dimensions",
    "start": "1281400",
    "end": "1287799"
  },
  {
    "text": "you never look at uh this is a more uh complex operation though since you can't just drop labels",
    "start": "1287799",
    "end": "1293559"
  },
  {
    "text": "willy-nilly without causing series conflicts hence the aggregation piece but uh even though there I wasn't aware",
    "start": "1293559",
    "end": "1301120"
  },
  {
    "text": "of um a particular tool to do this in OSS land lately um I did notice that",
    "start": "1301120",
    "end": "1306880"
  },
  {
    "text": "there is a talk later on today at 4:30 p.m. around uh IBM and Red Hats ovm tool",
    "start": "1306880",
    "end": "1312200"
  },
  {
    "text": "which does have aggregation listed as one of its features so I'm not going to steal there thunder but maybe attend",
    "start": "1312200",
    "end": "1318039"
  },
  {
    "text": "that at 4 30 cuz I'm going to um so check that out uh on the log side we'll",
    "start": "1318039",
    "end": "1324880"
  },
  {
    "text": "start with the one that everybody laugh at which is use log levels correctly uh if you're logging literally everything",
    "start": "1324880",
    "end": "1330919"
  },
  {
    "text": "to info instead of separating things correctly then you're just storing tons of logs that you don't need um so get",
    "start": "1330919",
    "end": "1336400"
  },
  {
    "text": "this sorted has an enormous impact the second thing you can do is sampling and",
    "start": "1336400",
    "end": "1341440"
  },
  {
    "text": "I mean sampling as the logs are being produced so a logger component of a service can know how often it is",
    "start": "1341440",
    "end": "1347480"
  },
  {
    "text": "producing certain logs lines so instead of it producing the same error 2,000",
    "start": "1347480",
    "end": "1352600"
  },
  {
    "text": "times in the space of 10 seconds you could have it not do that and just say this line has been repeated 2,000 times",
    "start": "1352600",
    "end": "1360039"
  },
  {
    "text": "and not actually spew it out and consume a bunch of data that is a thing people can do uh the next one is again retention",
    "start": "1360039",
    "end": "1369320"
  },
  {
    "text": "already covered it don't store logs for longer than you need if you do have compliance requirements here though which I know comes up a lot in the",
    "start": "1369320",
    "end": "1375120"
  },
  {
    "text": "logging world then send the compliance data to a back end with one retention policy and other data to a back end with",
    "start": "1375120",
    "end": "1381279"
  },
  {
    "text": "a different one or you might have a tool that lets you do per stream retention so you can say if it has label X stored for",
    "start": "1381279",
    "end": "1387760"
  },
  {
    "text": "longer that's totally a thing that you can do uh the fourth one here is on policies",
    "start": "1387760",
    "end": "1393240"
  },
  {
    "text": "so establishing clear logging policies for developers I've seen some companies who they've established really rigid",
    "start": "1393240",
    "end": "1399480"
  },
  {
    "text": "policies for developers on what they're allowed to write log lines for so for example a log line has to always provide",
    "start": "1399480",
    "end": "1405840"
  },
  {
    "text": "a particular level of information and be useful useful in diagnosing a problem if",
    "start": "1405840",
    "end": "1411159"
  },
  {
    "text": "it's Superfluous or it's something that you generally ignore then it shouldn't be a log line at all on the tracing side remove un needed",
    "start": "1411159",
    "end": "1419799"
  },
  {
    "text": "attributes people often add tons of extra attributes to their traces both span attributes and resource attributes",
    "start": "1419799",
    "end": "1425600"
  },
  {
    "text": "this these then increase your span size and since tracing is such a high volume uh data stream the effect multiplies",
    "start": "1425600",
    "end": "1432279"
  },
  {
    "text": "like very very quickly so you strip your attributes down to only what you actually need to query by and have in",
    "start": "1432279",
    "end": "1438039"
  },
  {
    "text": "your results if it doesn't help you remove it if it's better suited to another signal move it over to that maybe it should be",
    "start": "1438039",
    "end": "1444799"
  },
  {
    "text": "logs uh sampling uh people generally don't capture 100% of their traces as",
    "start": "1444799",
    "end": "1450080"
  },
  {
    "text": "the volume would be crippling uh so deciding exactly what to sample though is the challenge you've got head sampling and you've got tail sampling",
    "start": "1450080",
    "end": "1457080"
  },
  {
    "text": "head sampling is simpler you're just on on on the face of it on the front end you're basically saying oh just I only",
    "start": "1457080",
    "end": "1463039"
  },
  {
    "text": "want 5% of the data but that's indiscriminate and you can miss a lot of important uh information so generally",
    "start": "1463039",
    "end": "1469080"
  },
  {
    "text": "what you'd like to do is tail sampling which takes in the context of the whole Trace uh and then it you can decide you",
    "start": "1469080",
    "end": "1476080"
  },
  {
    "text": "know I only want to capture errors or I want to cap capture based on some attributes or based on certain latencies",
    "start": "1476080",
    "end": "1481240"
  },
  {
    "text": "it's a much more uh logical way to do it and we'll make sure that you're not missing data that is important there are",
    "start": "1481240",
    "end": "1487399"
  },
  {
    "text": "some OSS tools that work well for doing this uh otel collector can do this honeycom Refinery can do this graan",
    "start": "1487399",
    "end": "1493360"
  },
  {
    "text": "alloy can do this probably more retention period already covered it",
    "start": "1493360",
    "end": "1498440"
  },
  {
    "text": "don't store what you don't need uh remove useless spans so some people uh",
    "start": "1498440",
    "end": "1503760"
  },
  {
    "text": "have things instrumented that they shouldn't you should only really be uh instrumenting things that are meaningful bits of work that you need to know how",
    "start": "1503760",
    "end": "1510480"
  },
  {
    "text": "they are performing if something is always like really quick and isn't likely to ever cause a problem then you don't need a span for that and you can",
    "start": "1510480",
    "end": "1517399"
  },
  {
    "text": "also break up long long spans large spans into smaller ones for very large",
    "start": "1517399",
    "end": "1523200"
  },
  {
    "text": "complex operations and this can make your tracing perform more efficiently and also you have a lower vol",
    "start": "1523200",
    "end": "1528840"
  },
  {
    "text": "volume I'm going to try and run through the very end of this uh for profiles there's two things you can do uh you can",
    "start": "1528840",
    "end": "1535200"
  },
  {
    "text": "reduce how many targets you're sampling uh if you're running many copies of an app it's very likely that they're going",
    "start": "1535200",
    "end": "1540360"
  },
  {
    "text": "to perform somewhat similar because it's the same code so you could sample less things there and again retention period",
    "start": "1540360",
    "end": "1546720"
  },
  {
    "text": "reducing how long you're storing the profiling data for uh on the future side",
    "start": "1546720",
    "end": "1551919"
  },
  {
    "text": "there's a couple of things so what people really want is a solution that just looks at what they're sending and figures all this out for them",
    "start": "1551919",
    "end": "1558799"
  },
  {
    "text": "uh and does all these things without them having to worry about it either either automatically or via approvable",
    "start": "1558799",
    "end": "1564120"
  },
  {
    "text": "recommendations though anything getting automatically run is going to require tuning to some extent it's hard to make",
    "start": "1564120",
    "end": "1569640"
  },
  {
    "text": "something that suits everybody because priorities differ across companies cost over visibility visibility over cost uh",
    "start": "1569640",
    "end": "1576360"
  },
  {
    "text": "some even favor speed over exact correctness some favor correctness Above All Else some workloads are prioritized",
    "start": "1576360",
    "end": "1583200"
  },
  {
    "text": "over others and so on so again do take a look at that talk at 4:30 on ovm cuz I",
    "start": "1583200",
    "end": "1588360"
  },
  {
    "text": "think it'll be really interesting and uh I already saw that and cool so I'm at the end here um I run",
    "start": "1588360",
    "end": "1594640"
  },
  {
    "text": "right up into the time almost exactly so I'm very proud of that uh links here QR code if you want to rate it and also",
    "start": "1594640",
    "end": "1601520"
  },
  {
    "text": "come to the graan booth uh it'll be open tomorrow so thanks very [Applause]",
    "start": "1601520",
    "end": "1612189"
  },
  {
    "text": "much thanks Amon and we we have some two minutes for questions if you have",
    "start": "1612480",
    "end": "1619039"
  },
  {
    "text": "anything for aim on maybe it's the right time so the lady just me one",
    "start": "1619039",
    "end": "1625679"
  },
  {
    "text": "second we have only one mic you have a",
    "start": "1626559",
    "end": "1631398"
  },
  {
    "text": "mic hi there hi uh so you talked about establishing clear logging policies to",
    "start": "1632279",
    "end": "1638399"
  },
  {
    "text": "kind of help um guide users or guide engineers and creating good logs um are",
    "start": "1638399",
    "end": "1643760"
  },
  {
    "text": "you aware of any ways to kind of um systematically do this because I feel",
    "start": "1643760",
    "end": "1650120"
  },
  {
    "text": "like when I create documentation it doesn't get read it gets ignored um and we're kind of facing this issue where we're trying to Rin things in there so",
    "start": "1650120",
    "end": "1657919"
  },
  {
    "text": "depending on the tool you're using you can do things like that there there are ways to for example look for certain uh",
    "start": "1657919",
    "end": "1663679"
  },
  {
    "text": "labels in the logs and if they're not there just drop them um but that assumes you're looking for specific labels for",
    "start": "1663679",
    "end": "1669519"
  },
  {
    "text": "for specific log content you can do a bunch of processing there again depending on the tool in your kind of",
    "start": "1669519",
    "end": "1675320"
  },
  {
    "text": "logging pipeline but the more of that you're doing the slower you're going to make your pipeline so if you're doing a bunch of like Rex matching on every line",
    "start": "1675320",
    "end": "1682880"
  },
  {
    "text": "that flows through that's going to consume a bunch of resources as well which is you know fine if you want to throw more resources at it to do that",
    "start": "1682880",
    "end": "1689720"
  },
  {
    "text": "but of course anytime as I was going over like anytime you're processing stuff that's more cost now maybe it",
    "start": "1689720",
    "end": "1695159"
  },
  {
    "text": "works out in the end because processing up front means less data stored later that that then costs you more but it's",
    "start": "1695159",
    "end": "1701519"
  },
  {
    "text": "going to be like a balance is figuring out like what can you map for and is it going to be worth the extra resources",
    "start": "1701519",
    "end": "1706559"
  },
  {
    "text": "you have to run to filter in in that like very very uh meticulous",
    "start": "1706559",
    "end": "1712200"
  },
  {
    "text": "way thank you we have space for one more question anybody",
    "start": "1712880",
    "end": "1721000"
  },
  {
    "text": "there good exercise to hi uh I'm PA from cloud views um I",
    "start": "1721399",
    "end": "1728159"
  },
  {
    "text": "had a question regarding uh so you mentioned in metrics and also in like uh",
    "start": "1728159",
    "end": "1733519"
  },
  {
    "text": "PES there are ways in which we can reduce the data right by removing unused",
    "start": "1733519",
    "end": "1739080"
  },
  {
    "text": "metrics or removing attributes from spans but how do we know that it's not",
    "start": "1739080",
    "end": "1744320"
  },
  {
    "text": "blocking uh the discovery process like if somebody wants to build a dashboard for example and just looking for",
    "start": "1744320",
    "end": "1750760"
  },
  {
    "text": "multiple metrics that they could build off of uh would be be not preventing them uh by removing things that are not",
    "start": "1750760",
    "end": "1757240"
  },
  {
    "text": "currently being used yeah so if you if you do drop metrics early on in in the",
    "start": "1757240",
    "end": "1762679"
  },
  {
    "text": "pipeline or you aggregate uh certain things away your end users might not know that you did that and so they don't",
    "start": "1762679",
    "end": "1769440"
  },
  {
    "text": "know why they're missing and that's not ideal because they might expect those things to be there and then they can't",
    "start": "1769440",
    "end": "1774720"
  },
  {
    "text": "build dashboards and they can't build alerts uh there is there's there's a way",
    "start": "1774720",
    "end": "1779880"
  },
  {
    "text": "that we've done this for example in in uh our Cloud feature for this um not",
    "start": "1779880",
    "end": "1785600"
  },
  {
    "text": "trying to sell anybody anything sorry I'm just giving an example but what we've done is we never drop a metric",
    "start": "1785600",
    "end": "1791640"
  },
  {
    "text": "completely we only aggregate away a bunch of the labels so that means that when you try to query it you can see that the metric exists and we actually",
    "start": "1791640",
    "end": "1798480"
  },
  {
    "text": "store as a label all the labels that we aggregated away so you can tell by",
    "start": "1798480",
    "end": "1803600"
  },
  {
    "text": "looking that this has been aggregated and exactly what dimensions have been aggregated away and that means that a",
    "start": "1803600",
    "end": "1809679"
  },
  {
    "text": "user can go in and go oh well we we stripped it out uh and I want to get it recovered and then they can follow",
    "start": "1809679",
    "end": "1816240"
  },
  {
    "text": "whatever process they need to get it back but at least then it's not just missing and so that's how we handle that",
    "start": "1816240",
    "end": "1823120"
  },
  {
    "text": "um and that's yeah that's one way you can do it",
    "start": "1823120",
    "end": "1827720"
  }
]
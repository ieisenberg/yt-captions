[
  {
    "start": "0",
    "end": "51000"
  },
  {
    "text": "hi i'm yuki and today i'll be talking",
    "start": "1599",
    "end": "3360"
  },
  {
    "text": "about how tinder implemented envoy",
    "start": "3360",
    "end": "4960"
  },
  {
    "text": "global rate limiting at scale",
    "start": "4960",
    "end": "6720"
  },
  {
    "text": "i'm a software engineer at tinder in the",
    "start": "6720",
    "end": "8559"
  },
  {
    "text": "cloud infrastructure team",
    "start": "8559",
    "end": "10080"
  },
  {
    "text": "and in my day-to-day i work on",
    "start": "10080",
    "end": "12000"
  },
  {
    "text": "kubernetes and envoy",
    "start": "12000",
    "end": "13759"
  },
  {
    "text": "so in particular i've implemented the",
    "start": "13759",
    "end": "16080"
  },
  {
    "text": "xts control plane for our service mesh",
    "start": "16080",
    "end": "18560"
  },
  {
    "text": "which all our envoys talk to and today",
    "start": "18560",
    "end": "20880"
  },
  {
    "text": "i'm going to be going into detail about",
    "start": "20880",
    "end": "22720"
  },
  {
    "text": "the rate limiting platform i built there",
    "start": "22720",
    "end": "24640"
  },
  {
    "text": "which is also based on envoy",
    "start": "24640",
    "end": "27599"
  },
  {
    "text": "so in summary i'll be talking about",
    "start": "27599",
    "end": "28960"
  },
  {
    "text": "these things first of all our service",
    "start": "28960",
    "end": "30960"
  },
  {
    "text": "mesh journey how we implemented",
    "start": "30960",
    "end": "32800"
  },
  {
    "text": "envoy across all our services the",
    "start": "32800",
    "end": "35200"
  },
  {
    "text": "problems with our previous rate limiting",
    "start": "35200",
    "end": "36880"
  },
  {
    "text": "implementations",
    "start": "36880",
    "end": "38320"
  },
  {
    "text": "envoy rate milling why it's good how",
    "start": "38320",
    "end": "40800"
  },
  {
    "text": "envoy rate limiting works in detail how",
    "start": "40800",
    "end": "43200"
  },
  {
    "text": "tinder's rate limiting",
    "start": "43200",
    "end": "45039"
  },
  {
    "text": "works how we've extended upon it and",
    "start": "45039",
    "end": "46960"
  },
  {
    "text": "just some tips on if you want to try it",
    "start": "46960",
    "end": "49039"
  },
  {
    "text": "out yourself",
    "start": "49039",
    "end": "51039"
  },
  {
    "start": "51000",
    "end": "51000"
  },
  {
    "text": "so tinder's service mesh journey we were",
    "start": "51039",
    "end": "53280"
  },
  {
    "text": "fully on kubernetes before starting",
    "start": "53280",
    "end": "55360"
  },
  {
    "text": "a service method migration so we started",
    "start": "55360",
    "end": "58800"
  },
  {
    "text": "the",
    "start": "58800",
    "end": "59120"
  },
  {
    "text": "service mesh migration about a year ago",
    "start": "59120",
    "end": "61120"
  },
  {
    "text": "in 2019 it took about",
    "start": "61120",
    "end": "62559"
  },
  {
    "text": "a full year for all our services fully",
    "start": "62559",
    "end": "65119"
  },
  {
    "text": "to be on",
    "start": "65119",
    "end": "65680"
  },
  {
    "text": "envoy it was definitely a very big",
    "start": "65680",
    "end": "67840"
  },
  {
    "text": "effort took many people in the",
    "start": "67840",
    "end": "69600"
  },
  {
    "text": "organization to achieve it and",
    "start": "69600",
    "end": "72479"
  },
  {
    "text": "today about 1.6 million requests per",
    "start": "72479",
    "end": "74799"
  },
  {
    "text": "second",
    "start": "74799",
    "end": "75600"
  },
  {
    "text": "are meshed you know in our service mesh",
    "start": "75600",
    "end": "77920"
  },
  {
    "text": "at peak",
    "start": "77920",
    "end": "78640"
  },
  {
    "text": "and there's about 200 000 containers in",
    "start": "78640",
    "end": "81040"
  },
  {
    "text": "our service mesh",
    "start": "81040",
    "end": "83439"
  },
  {
    "text": "so this is just a chart of how our",
    "start": "83439",
    "end": "85439"
  },
  {
    "text": "infrastructure works",
    "start": "85439",
    "end": "86799"
  },
  {
    "text": "on the left is a user it's using the",
    "start": "86799",
    "end": "89200"
  },
  {
    "text": "tinder app",
    "start": "89200",
    "end": "90400"
  },
  {
    "text": "the request gets routed to one of our",
    "start": "90400",
    "end": "92560"
  },
  {
    "text": "three clusters so we have a cluster per",
    "start": "92560",
    "end": "95119"
  },
  {
    "text": "availability zone in aws there's dns",
    "start": "95119",
    "end": "98400"
  },
  {
    "text": "round robin that routes the request to",
    "start": "98400",
    "end": "100320"
  },
  {
    "text": "one of these clusters",
    "start": "100320",
    "end": "101759"
  },
  {
    "text": "and each cluster is isolated so they do",
    "start": "101759",
    "end": "104479"
  },
  {
    "text": "not talk to each other",
    "start": "104479",
    "end": "105920"
  },
  {
    "text": "this gives us a lot of like benefits in",
    "start": "105920",
    "end": "107840"
  },
  {
    "text": "terms of performance",
    "start": "107840",
    "end": "108960"
  },
  {
    "text": "as well as like traffic bandwidth cost",
    "start": "108960",
    "end": "112000"
  },
  {
    "text": "savings",
    "start": "112000",
    "end": "113119"
  },
  {
    "text": "we have an ingress layer which used to",
    "start": "113119",
    "end": "114880"
  },
  {
    "text": "be nginx but now we might get the envoy",
    "start": "114880",
    "end": "117520"
  },
  {
    "text": "and once the request makes it into a",
    "start": "117520",
    "end": "119600"
  },
  {
    "text": "kubernetes cluster of course",
    "start": "119600",
    "end": "121360"
  },
  {
    "text": "the request is routed to the correct",
    "start": "121360",
    "end": "124320"
  },
  {
    "text": "service",
    "start": "124320",
    "end": "126399"
  },
  {
    "text": "so we tried out envoy because",
    "start": "126399",
    "end": "130000"
  },
  {
    "text": "initially the default kubernetes elb",
    "start": "130000",
    "end": "132160"
  },
  {
    "text": "routing was not that great",
    "start": "132160",
    "end": "133599"
  },
  {
    "text": "it was very uneven and resulted in uh",
    "start": "133599",
    "end": "136879"
  },
  {
    "text": "hotpot issues where pods some pods got a",
    "start": "136879",
    "end": "138959"
  },
  {
    "text": "lot more requests than others",
    "start": "138959",
    "end": "141200"
  },
  {
    "text": "but eventually you know we started",
    "start": "141200",
    "end": "142720"
  },
  {
    "text": "trying out a lot of the other great",
    "start": "142720",
    "end": "145120"
  },
  {
    "text": "features envoy has like these requests",
    "start": "145120",
    "end": "147840"
  },
  {
    "text": "routing first of all right",
    "start": "147840",
    "end": "149599"
  },
  {
    "text": "uh there's retries circuit breakers",
    "start": "149599",
    "end": "151680"
  },
  {
    "text": "timeouts that you",
    "start": "151680",
    "end": "152800"
  },
  {
    "text": "essentially get for free now you're not",
    "start": "152800",
    "end": "155120"
  },
  {
    "text": "having to do all this network",
    "start": "155120",
    "end": "157040"
  },
  {
    "text": "automation inside the application it's",
    "start": "157040",
    "end": "160080"
  },
  {
    "text": "all on the envoy network layer",
    "start": "160080",
    "end": "162000"
  },
  {
    "text": "now we're exploring like the redis full",
    "start": "162000",
    "end": "164239"
  },
  {
    "text": "red filter",
    "start": "164239",
    "end": "165519"
  },
  {
    "text": "dynamodb filter where you're proxying",
    "start": "165519",
    "end": "168080"
  },
  {
    "text": "database requests through envoy",
    "start": "168080",
    "end": "170160"
  },
  {
    "text": "that way you get like metrics for free",
    "start": "170160",
    "end": "172400"
  },
  {
    "text": "uh now we're",
    "start": "172400",
    "end": "173440"
  },
  {
    "text": "uh of course we're doing observability",
    "start": "173440",
    "end": "175760"
  },
  {
    "text": "where",
    "start": "175760",
    "end": "176640"
  },
  {
    "text": "all our envoy metrics are being scraped",
    "start": "176640",
    "end": "179440"
  },
  {
    "text": "through prometheus and then charted on",
    "start": "179440",
    "end": "181680"
  },
  {
    "text": "grafana so previous rate limiting",
    "start": "181680",
    "end": "184560"
  },
  {
    "start": "183000",
    "end": "183000"
  },
  {
    "text": "implementations",
    "start": "184560",
    "end": "185680"
  },
  {
    "text": "a tinder used nginx at the ingress layer",
    "start": "185680",
    "end": "188720"
  },
  {
    "text": "problem with this is uh there was really",
    "start": "188720",
    "end": "190879"
  },
  {
    "text": "no visibility you would need to like",
    "start": "190879",
    "end": "192480"
  },
  {
    "text": "tell logs to figure out if the rate",
    "start": "192480",
    "end": "194239"
  },
  {
    "text": "limiting was even working or you know",
    "start": "194239",
    "end": "195840"
  },
  {
    "text": "what's being rate limited",
    "start": "195840",
    "end": "197599"
  },
  {
    "text": "um so that's not ideal it was all done",
    "start": "197599",
    "end": "200400"
  },
  {
    "text": "locally",
    "start": "200400",
    "end": "201200"
  },
  {
    "text": "as in it was based on the number of",
    "start": "201200",
    "end": "203280"
  },
  {
    "text": "requests uh",
    "start": "203280",
    "end": "204879"
  },
  {
    "text": "certain nginx hosts saw not on the on",
    "start": "204879",
    "end": "207440"
  },
  {
    "text": "the global request count",
    "start": "207440",
    "end": "208879"
  },
  {
    "text": "it was also very difficult to update the",
    "start": "208879",
    "end": "210560"
  },
  {
    "text": "rate limits because you need to you know",
    "start": "210560",
    "end": "211920"
  },
  {
    "text": "roll",
    "start": "211920",
    "end": "212319"
  },
  {
    "text": "all the nginx hosts",
    "start": "212319",
    "end": "216080"
  },
  {
    "text": "and then secondly there were",
    "start": "216080",
    "end": "217840"
  },
  {
    "text": "implementations inside the application",
    "start": "217840",
    "end": "220159"
  },
  {
    "text": "so a lot of teams would like roll their",
    "start": "220159",
    "end": "221920"
  },
  {
    "text": "own rate limiting code",
    "start": "221920",
    "end": "224000"
  },
  {
    "text": "so there's a lot of different",
    "start": "224000",
    "end": "225440"
  },
  {
    "text": "implementations across the org",
    "start": "225440",
    "end": "227440"
  },
  {
    "text": "there's little visibility into how they",
    "start": "227440",
    "end": "230239"
  },
  {
    "text": "were working",
    "start": "230239",
    "end": "231280"
  },
  {
    "text": "or how they were configured and often",
    "start": "231280",
    "end": "233280"
  },
  {
    "text": "there was redundant infrastructure",
    "start": "233280",
    "end": "235840"
  },
  {
    "text": "you know because a lot of teams would",
    "start": "235840",
    "end": "237040"
  },
  {
    "text": "use reddish caches for the rate limiting",
    "start": "237040",
    "end": "238959"
  },
  {
    "text": "and there were duplicates of those",
    "start": "238959",
    "end": "241280"
  },
  {
    "start": "241000",
    "end": "241000"
  },
  {
    "text": "basically serving the same purpose so",
    "start": "241280",
    "end": "245040"
  },
  {
    "text": "why is envoy rate limiting good we were",
    "start": "245040",
    "end": "247360"
  },
  {
    "text": "able to move all the rate limiting logic",
    "start": "247360",
    "end": "249360"
  },
  {
    "text": "to the envoy layer so we have a uniform",
    "start": "249360",
    "end": "251840"
  },
  {
    "text": "implementation across the company we",
    "start": "251840",
    "end": "254080"
  },
  {
    "text": "have",
    "start": "254080",
    "end": "254640"
  },
  {
    "text": "global rate limiting where the rate",
    "start": "254640",
    "end": "257840"
  },
  {
    "text": "limit is based on a global request count",
    "start": "257840",
    "end": "260320"
  },
  {
    "text": "and this is really important for our",
    "start": "260320",
    "end": "262000"
  },
  {
    "text": "cluster per ac model",
    "start": "262000",
    "end": "263680"
  },
  {
    "text": "it's got granular configuration such as",
    "start": "263680",
    "end": "266160"
  },
  {
    "text": "you can",
    "start": "266160",
    "end": "267120"
  },
  {
    "text": "rate limit on multiple headers or one",
    "start": "267120",
    "end": "268880"
  },
  {
    "text": "header or you know even no headers",
    "start": "268880",
    "end": "271520"
  },
  {
    "text": "you have monitoring and visibility",
    "start": "271520",
    "end": "273520"
  },
  {
    "text": "through the prometheus",
    "start": "273520",
    "end": "274720"
  },
  {
    "text": "metrics it offers and overall we're able",
    "start": "274720",
    "end": "277919"
  },
  {
    "text": "to prevent system failure",
    "start": "277919",
    "end": "279600"
  },
  {
    "text": "patch concurrency issues and due to",
    "start": "279600",
    "end": "282880"
  },
  {
    "text": "you know stopping like spot traffic we",
    "start": "282880",
    "end": "285040"
  },
  {
    "text": "have a lot of cost savings",
    "start": "285040",
    "end": "286639"
  },
  {
    "text": "and right now it polices about you know",
    "start": "286639",
    "end": "289280"
  },
  {
    "text": "200 000 requests per second at tinder",
    "start": "289280",
    "end": "292320"
  },
  {
    "text": "so this is a chart of onward rate",
    "start": "292320",
    "end": "293840"
  },
  {
    "text": "limiting it's a request flow of",
    "start": "293840",
    "end": "296880"
  },
  {
    "text": "service a making a request to service b",
    "start": "296880",
    "end": "298720"
  },
  {
    "text": "so let's start at one a makes a request",
    "start": "298720",
    "end": "300639"
  },
  {
    "text": "to b",
    "start": "300639",
    "end": "301680"
  },
  {
    "text": "and service a has an envoy sidecar right",
    "start": "301680",
    "end": "304479"
  },
  {
    "text": "so the envoy sidecar asks the rate limit",
    "start": "304479",
    "end": "306720"
  },
  {
    "text": "service",
    "start": "306720",
    "end": "308000"
  },
  {
    "text": "should we rate limit this request or not",
    "start": "308000",
    "end": "310240"
  },
  {
    "text": "if the answer is yes",
    "start": "310240",
    "end": "311600"
  },
  {
    "text": "a 429 status code is returned to the",
    "start": "311600",
    "end": "314400"
  },
  {
    "text": "service a",
    "start": "314400",
    "end": "315280"
  },
  {
    "text": "container otherwise the request is let",
    "start": "315280",
    "end": "318320"
  },
  {
    "text": "through",
    "start": "318320",
    "end": "318800"
  },
  {
    "text": "and a successfully makes a request to b",
    "start": "318800",
    "end": "322160"
  },
  {
    "text": "and you can notice here that on the very",
    "start": "322160",
    "end": "324240"
  },
  {
    "text": "right the rate limit service is",
    "start": "324240",
    "end": "326800"
  },
  {
    "text": "uh storing all the request count",
    "start": "326800",
    "end": "329280"
  },
  {
    "text": "information in a redis cache",
    "start": "329280",
    "end": "332880"
  },
  {
    "start": "332000",
    "end": "332000"
  },
  {
    "text": "okay so let's talk about the rate limit",
    "start": "333360",
    "end": "334800"
  },
  {
    "text": "service it is a go project",
    "start": "334800",
    "end": "336800"
  },
  {
    "text": "and deploy it in kubernetes pause with",
    "start": "336800",
    "end": "338720"
  },
  {
    "text": "an envoy site card",
    "start": "338720",
    "end": "340400"
  },
  {
    "text": "and this way we can proxy requests",
    "start": "340400",
    "end": "343600"
  },
  {
    "text": "to redis through envoy which gives us",
    "start": "343600",
    "end": "346400"
  },
  {
    "text": "metrics for free",
    "start": "346400",
    "end": "348000"
  },
  {
    "text": "as well as being able to tweak some",
    "start": "348000",
    "end": "349919"
  },
  {
    "text": "redis connection settings",
    "start": "349919",
    "end": "351520"
  },
  {
    "text": "we have two separate rate limiting",
    "start": "351520",
    "end": "353360"
  },
  {
    "text": "clusters one for internal routes",
    "start": "353360",
    "end": "355600"
  },
  {
    "text": "another for external routes and then you",
    "start": "355600",
    "end": "358319"
  },
  {
    "text": "might be wondering what happens if the",
    "start": "358319",
    "end": "359759"
  },
  {
    "text": "rate from the service is down or if it's",
    "start": "359759",
    "end": "361360"
  },
  {
    "text": "slowing down",
    "start": "361360",
    "end": "363120"
  },
  {
    "text": "there is a 20 millisecond default",
    "start": "363120",
    "end": "364880"
  },
  {
    "text": "timeout to request",
    "start": "364880",
    "end": "366479"
  },
  {
    "text": "to the rate limit service if it is",
    "start": "366479",
    "end": "368319"
  },
  {
    "text": "exceeded there is a fail",
    "start": "368319",
    "end": "369680"
  },
  {
    "text": "open meaning that the requests will be",
    "start": "369680",
    "end": "372639"
  },
  {
    "text": "allowed through by default",
    "start": "372639",
    "end": "374160"
  },
  {
    "text": "and what's nice is that just by updating",
    "start": "374160",
    "end": "376560"
  },
  {
    "text": "the rate limit",
    "start": "376560",
    "end": "377759"
  },
  {
    "text": "service comic map it is hot reloaded so",
    "start": "377759",
    "end": "380479"
  },
  {
    "text": "if you're changing from say like",
    "start": "380479",
    "end": "382720"
  },
  {
    "text": "uh rate limit from five requests per",
    "start": "382720",
    "end": "384639"
  },
  {
    "text": "second to 10 requests per second just",
    "start": "384639",
    "end": "386479"
  },
  {
    "text": "update the config map",
    "start": "386479",
    "end": "387840"
  },
  {
    "text": "and it will reload automatically so",
    "start": "387840",
    "end": "390880"
  },
  {
    "start": "390000",
    "end": "390000"
  },
  {
    "text": "let's look at the configuration",
    "start": "390880",
    "end": "392960"
  },
  {
    "text": "it's important to note all the envoy",
    "start": "392960",
    "end": "394800"
  },
  {
    "text": "configuration is done in the caller",
    "start": "394800",
    "end": "397039"
  },
  {
    "text": "so here with this route you're attaching",
    "start": "397039",
    "end": "400160"
  },
  {
    "text": "a descriptor key called foo",
    "start": "400160",
    "end": "402960"
  },
  {
    "text": "if that request has a header name of foo",
    "start": "402960",
    "end": "405840"
  },
  {
    "text": "if it has a request with a header",
    "start": "405840",
    "end": "407759"
  },
  {
    "text": "called foo that is and then",
    "start": "407759",
    "end": "412000"
  },
  {
    "text": "with that descriptor it is sent to the",
    "start": "412000",
    "end": "413919"
  },
  {
    "text": "rate limit service and here's the",
    "start": "413919",
    "end": "415120"
  },
  {
    "text": "corresponding weight limit service",
    "start": "415120",
    "end": "416639"
  },
  {
    "text": "config",
    "start": "416639",
    "end": "417840"
  },
  {
    "text": "you can see here that it has a nested",
    "start": "417840",
    "end": "419680"
  },
  {
    "text": "structure which allows for pretty",
    "start": "419680",
    "end": "421360"
  },
  {
    "text": "complex uh rate limiting logic",
    "start": "421360",
    "end": "424000"
  },
  {
    "text": "and then here for the food key there is",
    "start": "424000",
    "end": "426960"
  },
  {
    "text": "a corresponding",
    "start": "426960",
    "end": "428000"
  },
  {
    "text": "two weeks two requests per minute",
    "start": "428000",
    "end": "430000"
  },
  {
    "text": "specified so",
    "start": "430000",
    "end": "431199"
  },
  {
    "text": "in the rate limit service config is",
    "start": "431199",
    "end": "432639"
  },
  {
    "text": "where you define the thresholds",
    "start": "432639",
    "end": "437120"
  },
  {
    "start": "437000",
    "end": "437000"
  },
  {
    "text": "so let's talk about one use case at",
    "start": "437120",
    "end": "438880"
  },
  {
    "text": "tinder which is",
    "start": "438880",
    "end": "440240"
  },
  {
    "text": "sms request rate limiting so what",
    "start": "440240",
    "end": "442880"
  },
  {
    "text": "happens is we have a lot of bots",
    "start": "442880",
    "end": "444639"
  },
  {
    "text": "requesting a lot of",
    "start": "444639",
    "end": "445759"
  },
  {
    "text": "sms codes which is very expensive",
    "start": "445759",
    "end": "447919"
  },
  {
    "text": "because twilios is",
    "start": "447919",
    "end": "449360"
  },
  {
    "text": "twilio is expensive which is our",
    "start": "449360",
    "end": "450960"
  },
  {
    "text": "third-party sms provider",
    "start": "450960",
    "end": "453120"
  },
  {
    "text": "and initially we did have this lately",
    "start": "453120",
    "end": "455440"
  },
  {
    "text": "winning built into",
    "start": "455440",
    "end": "456720"
  },
  {
    "text": "our applications but it was brittle hard",
    "start": "456720",
    "end": "458960"
  },
  {
    "text": "to update every time you want to add a",
    "start": "458960",
    "end": "460639"
  },
  {
    "text": "new rate limit you'd have to write",
    "start": "460639",
    "end": "462000"
  },
  {
    "text": "additional code",
    "start": "462000",
    "end": "463120"
  },
  {
    "text": "was not ideal so we migrated all of it",
    "start": "463120",
    "end": "465599"
  },
  {
    "text": "to envoy which",
    "start": "465599",
    "end": "467199"
  },
  {
    "text": "had uh millions of dollars in savings",
    "start": "467199",
    "end": "469840"
  },
  {
    "text": "and we had these very adaptive",
    "start": "469840",
    "end": "472000"
  },
  {
    "text": "rate limits so for each ip it had a per",
    "start": "472000",
    "end": "475440"
  },
  {
    "text": "day and a per second quota",
    "start": "475440",
    "end": "477360"
  },
  {
    "text": "and we could rate limit on a combination",
    "start": "477360",
    "end": "479520"
  },
  {
    "text": "of headers",
    "start": "479520",
    "end": "480400"
  },
  {
    "text": "so if one user had an ip of one one one",
    "start": "480400",
    "end": "483520"
  },
  {
    "text": "one the country is us devices ios",
    "start": "483520",
    "end": "487440"
  },
  {
    "text": "they would have like a five request per",
    "start": "487440",
    "end": "489280"
  },
  {
    "text": "second rate limit",
    "start": "489280",
    "end": "490639"
  },
  {
    "text": "while if they had a different ip address",
    "start": "490639",
    "end": "492639"
  },
  {
    "text": "their country is in japan the devices",
    "start": "492639",
    "end": "494879"
  },
  {
    "text": "is a web they would have a lower rate",
    "start": "494879",
    "end": "498160"
  },
  {
    "text": "limit",
    "start": "498160",
    "end": "500319"
  },
  {
    "text": "so on top of this we also built in a",
    "start": "500319",
    "end": "503199"
  },
  {
    "text": "analytics module",
    "start": "503199",
    "end": "504879"
  },
  {
    "text": "into the rate limit service so every",
    "start": "504879",
    "end": "506960"
  },
  {
    "text": "time there is a rate limit event it is",
    "start": "506960",
    "end": "508800"
  },
  {
    "text": "sent to s3 for processing",
    "start": "508800",
    "end": "510879"
  },
  {
    "text": "and long term storage so what we can do",
    "start": "510879",
    "end": "513279"
  },
  {
    "text": "is automated block listing",
    "start": "513279",
    "end": "515200"
  },
  {
    "text": "so if like a user was rate limited three",
    "start": "515200",
    "end": "518000"
  },
  {
    "text": "days in a row",
    "start": "518000",
    "end": "519039"
  },
  {
    "text": "we may ban them we may ban them for like",
    "start": "519039",
    "end": "521120"
  },
  {
    "text": "30 days",
    "start": "521120",
    "end": "522240"
  },
  {
    "text": "uh and now we can also analyze long-term",
    "start": "522240",
    "end": "524560"
  },
  {
    "text": "behavior",
    "start": "524560",
    "end": "525279"
  },
  {
    "text": "we can you know say you know how did the",
    "start": "525279",
    "end": "527680"
  },
  {
    "text": "rate limiting",
    "start": "527680",
    "end": "528560"
  },
  {
    "text": "perform like 90 days ago who got rate",
    "start": "528560",
    "end": "530560"
  },
  {
    "text": "limited on what routes",
    "start": "530560",
    "end": "532240"
  },
  {
    "text": "now we're also starting to be like",
    "start": "532240",
    "end": "533519"
  },
  {
    "text": "machine learning on this data",
    "start": "533519",
    "end": "535360"
  },
  {
    "text": "to enrich our existing bot detection so",
    "start": "535360",
    "end": "538160"
  },
  {
    "text": "we're finding a lot of value in this",
    "start": "538160",
    "end": "540160"
  },
  {
    "text": "weight limiting data so this is just a",
    "start": "540160",
    "end": "543680"
  },
  {
    "start": "542000",
    "end": "542000"
  },
  {
    "text": "cool little chart i made so i got all",
    "start": "543680",
    "end": "546560"
  },
  {
    "text": "the",
    "start": "546560",
    "end": "546959"
  },
  {
    "text": "requests that got rate limited got their",
    "start": "546959",
    "end": "549040"
  },
  {
    "text": "geo locational data and put it on this",
    "start": "549040",
    "end": "551120"
  },
  {
    "text": "world map",
    "start": "551120",
    "end": "552480"
  },
  {
    "text": "you can see that there's really bots",
    "start": "552480",
    "end": "554240"
  },
  {
    "text": "coming from everywhere",
    "start": "554240",
    "end": "556240"
  },
  {
    "text": "particularly around where aws data",
    "start": "556240",
    "end": "559200"
  },
  {
    "text": "centers are located",
    "start": "559200",
    "end": "560560"
  },
  {
    "text": "as you can see there's a couple big dots",
    "start": "560560",
    "end": "562800"
  },
  {
    "text": "in virginia where",
    "start": "562800",
    "end": "564480"
  },
  {
    "text": "aws usc 1 is",
    "start": "564480",
    "end": "567680"
  },
  {
    "text": "and then just lastly some tips i would",
    "start": "567680",
    "end": "570399"
  },
  {
    "start": "568000",
    "end": "568000"
  },
  {
    "text": "scale your",
    "start": "570399",
    "end": "571120"
  },
  {
    "text": "infrastructure so that your p99 9",
    "start": "571120",
    "end": "573279"
  },
  {
    "text": "latency to the rate limit service is",
    "start": "573279",
    "end": "575200"
  },
  {
    "text": "20 milliseconds and not much more than",
    "start": "575200",
    "end": "577360"
  },
  {
    "text": "that otherwise you're going to have a",
    "start": "577360",
    "end": "578800"
  },
  {
    "text": "lot of fail opens",
    "start": "578800",
    "end": "580880"
  },
  {
    "text": "5 000 quests per second per rate in the",
    "start": "580880",
    "end": "582880"
  },
  {
    "text": "service pod is a pretty good benchmark",
    "start": "582880",
    "end": "585440"
  },
  {
    "text": "i would use the envoy redis filter to",
    "start": "585440",
    "end": "587440"
  },
  {
    "text": "make your life a lot easier",
    "start": "587440",
    "end": "590240"
  },
  {
    "text": "particularly because this gives you",
    "start": "590240",
    "end": "592080"
  },
  {
    "text": "redis performance metrics",
    "start": "592080",
    "end": "593760"
  },
  {
    "text": "and how redis performs is going to",
    "start": "593760",
    "end": "596240"
  },
  {
    "text": "affect how",
    "start": "596240",
    "end": "597040"
  },
  {
    "text": "your p99 latency is so if you want to",
    "start": "597040",
    "end": "600000"
  },
  {
    "text": "just try it out on your laptop clone",
    "start": "600000",
    "end": "601839"
  },
  {
    "text": "this repo",
    "start": "601839",
    "end": "602640"
  },
  {
    "text": "run this docker compose command and you",
    "start": "602640",
    "end": "605519"
  },
  {
    "text": "can just curl your local host",
    "start": "605519",
    "end": "607600"
  },
  {
    "text": "and you should get a 429 response",
    "start": "607600",
    "end": "611040"
  },
  {
    "text": "like you see here on the bottom right",
    "start": "611040",
    "end": "614320"
  },
  {
    "text": "thank you that was all shoot me some",
    "start": "614320",
    "end": "616480"
  },
  {
    "text": "questions on twitter if you got any",
    "start": "616480",
    "end": "618079"
  },
  {
    "text": "but thanks for listening",
    "start": "618079",
    "end": "621600"
  }
]
[
  {
    "text": "testing it's on",
    "start": "10000",
    "end": "14440"
  },
  {
    "text": "all right this is going to be my clicker so that's why i'm holding this mouse",
    "start": "25359",
    "end": "30720"
  },
  {
    "text": "all right just a second",
    "start": "30720",
    "end": "34239"
  },
  {
    "text": "hola bienvenido a todos um thank you all so much for coming out",
    "start": "36160",
    "end": "41600"
  },
  {
    "text": "today i know it's been a long week probably for all of you um and it's a long day and i'm so flattered that you",
    "start": "41600",
    "end": "48239"
  },
  {
    "text": "chose to come to my session for your last session of the day so just to make sure we're all in the",
    "start": "48239",
    "end": "53360"
  },
  {
    "text": "same room my talk is why how to and issues tail-based sampling in the open",
    "start": "53360",
    "end": "59280"
  },
  {
    "text": "telemetry collector and yes i'm pretty sure i maxed out the number of letters allowed for a kubecon",
    "start": "59280",
    "end": "65760"
  },
  {
    "text": "topic oh no why are you not clicking",
    "start": "65760",
    "end": "72920"
  },
  {
    "text": "oh that's weird okay well i'm gonna have to stand here",
    "start": "76720",
    "end": "82159"
  },
  {
    "text": "all right to start i'm gonna take you through our agenda for the session i'm going to start with a brief refresher on",
    "start": "82159",
    "end": "89040"
  },
  {
    "text": "open telemetry collector and distribute tracing then we'll get into a sampling overview where i'll",
    "start": "89040",
    "end": "95439"
  },
  {
    "text": "cover not just what is sampling but also why sampling and then we'll see sampling",
    "start": "95439",
    "end": "101680"
  },
  {
    "text": "in action with a live demo by yours truly and we will wrap up with concerns",
    "start": "101680",
    "end": "106880"
  },
  {
    "text": "and limitations so that you are aware of the challenges",
    "start": "106880",
    "end": "111439"
  },
  {
    "text": "the first question i'm going to answer for you today is who am i my name is rhys lee i am a developer",
    "start": "111920",
    "end": "118479"
  },
  {
    "text": "relations engineer on the open telemetry community team at new relic i am based",
    "start": "118479",
    "end": "123840"
  },
  {
    "text": "in vancouver washington i am passionate about helping observability end users get and",
    "start": "123840",
    "end": "130560"
  },
  {
    "text": "understand useful data from their systems so i'm very pleased to share this presentation with you today",
    "start": "130560",
    "end": "137840"
  },
  {
    "text": "okay a first a quick refresher on these core concepts as i'm sure most of you are",
    "start": "138319",
    "end": "143760"
  },
  {
    "text": "already familiar with these at this point if you do want more information i'll have some resources at the end that you",
    "start": "143760",
    "end": "149200"
  },
  {
    "text": "can check out what is open telemetry",
    "start": "149200",
    "end": "154560"
  },
  {
    "text": "in 2019 two competing open source instrumentation projects one called open",
    "start": "154560",
    "end": "159599"
  },
  {
    "text": "census and then called open tracing will emerge forming open telemetry it is",
    "start": "159599",
    "end": "165760"
  },
  {
    "text": "now the second most active cncf project after kubernetes and it is a unified standard for",
    "start": "165760",
    "end": "173519"
  },
  {
    "text": "instrumenting generating collecting and exporting telemetry so metrics logs and traces",
    "start": "173519",
    "end": "180400"
  },
  {
    "text": "to help you analyze your softwares performance and behavior",
    "start": "180400",
    "end": "186239"
  },
  {
    "text": "and it does so by providing a set of apis sdks and tools",
    "start": "186239",
    "end": "191760"
  },
  {
    "text": "including a component called a collector what is the collector",
    "start": "191760",
    "end": "197280"
  },
  {
    "text": "it is essentially an extremely configurable system for processing telemetry data it's made of",
    "start": "197280",
    "end": "203840"
  },
  {
    "text": "the there's three main components that access that telemetry data receivers processors and exporters",
    "start": "203840",
    "end": "211280"
  },
  {
    "text": "and some of the things that a collector can be configured to do include sampling collecting host metrics",
    "start": "211280",
    "end": "217760"
  },
  {
    "text": "scrubbing data and normalizing data what is distributed tracing",
    "start": "217760",
    "end": "224480"
  },
  {
    "text": "distributed tracing is the method of observing requests as they move from one service to another in a distributed",
    "start": "224480",
    "end": "230560"
  },
  {
    "text": "system and it's important for helping us understand our systems such as our service connections",
    "start": "230560",
    "end": "237519"
  },
  {
    "text": "like how our services are interconnected and can be useful for diagnosing problems such as where latency is",
    "start": "237519",
    "end": "243680"
  },
  {
    "text": "occurring also what is a trace",
    "start": "243680",
    "end": "249200"
  },
  {
    "text": "a trace is made up of spans spans represent logical units of work",
    "start": "249200",
    "end": "254480"
  },
  {
    "text": "within a request uh during a specific period of time so an example of a span would be http call",
    "start": "254480",
    "end": "261919"
  },
  {
    "text": "or a database call and in this very intricate diagram that i created",
    "start": "261919",
    "end": "267919"
  },
  {
    "text": "here you can see a trace a request as it moves through three different services",
    "start": "267919",
    "end": "274720"
  },
  {
    "text": "the first span of any given request or trace is going to refer to as the root span",
    "start": "274720",
    "end": "280720"
  },
  {
    "text": "and the next slide here i'm going to show you an example of what",
    "start": "280720",
    "end": "286080"
  },
  {
    "text": "a request will look like in a tracing backend that we send our chase data to such as jager",
    "start": "286080",
    "end": "292560"
  },
  {
    "text": "so jaeger i'm sure most of you are already aware what it is it's an open source distributed tracing platform that",
    "start": "293680",
    "end": "300400"
  },
  {
    "text": "visualizes your service requests as traces and there are also other open source tools and",
    "start": "300400",
    "end": "306560"
  },
  {
    "text": "multiple back-end vendors that you can send your trace data to as well let me get my mouse over",
    "start": "306560",
    "end": "313039"
  },
  {
    "text": "so each of these lines here represents a span and all of these bands make up a trace",
    "start": "313039",
    "end": "320639"
  },
  {
    "text": "you can also see the duration of time that each span has taken along with",
    "start": "320639",
    "end": "326320"
  },
  {
    "text": "the total duration of the entire trace",
    "start": "326320",
    "end": "331120"
  },
  {
    "text": "so so far distributed tracing sounds great right however there are some things that",
    "start": "333199",
    "end": "340639"
  },
  {
    "text": "you need to take into consideration",
    "start": "340639",
    "end": "344080"
  },
  {
    "text": "if your system is producing thousands of traces per minute and you haven't set up any kind of sampling strategy",
    "start": "345840",
    "end": "353840"
  },
  {
    "text": "so that it is to say you are capturing storing and indexing every span of every",
    "start": "353840",
    "end": "359520"
  },
  {
    "text": "request well one the cost of tracing could become higher",
    "start": "359520",
    "end": "365280"
  },
  {
    "text": "than the cost of running a service and two it can make it difficult to see if any issues are occurring within your",
    "start": "365280",
    "end": "371120"
  },
  {
    "text": "system so what can we do not at a question",
    "start": "371120",
    "end": "377840"
  },
  {
    "text": "we can sample",
    "start": "377840",
    "end": "382800"
  },
  {
    "text": "okay before we get into the sampling overview can i get a quick show of hands is anyone currently using trace sampling",
    "start": "386400",
    "end": "392319"
  },
  {
    "text": "in your organization or know anyone who or know what your organization is",
    "start": "392319",
    "end": "398319"
  },
  {
    "text": "excellent okay so it looks like some of you are probably",
    "start": "398479",
    "end": "403919"
  },
  {
    "text": "really familiar with sampling but in any case i will cover what is",
    "start": "403919",
    "end": "409120"
  },
  {
    "text": "sampling why we might want to sample and then we'll talk about head and tilde sampling",
    "start": "409120",
    "end": "415520"
  },
  {
    "text": "excuse me what is sampling to keep or not to keep a span our trace",
    "start": "420319",
    "end": "428639"
  },
  {
    "text": "that is the question that sampling answers for us the idea behind sampling is to reduce",
    "start": "428639",
    "end": "433840"
  },
  {
    "text": "the number of created or sampled spans and",
    "start": "433840",
    "end": "439599"
  },
  {
    "text": "next i'll talk about why we might want to sample oh and sampling can be implemented at",
    "start": "439599",
    "end": "445520"
  },
  {
    "text": "different stages of span processing so the earliest is before a span is even created otherwise known as head-based",
    "start": "445520",
    "end": "450720"
  },
  {
    "text": "sampling or after all the spans have ended which is the latest stage",
    "start": "450720",
    "end": "456400"
  },
  {
    "text": "also known as tail-based sampling so earlier i showed you a meme that i",
    "start": "456400",
    "end": "463919"
  },
  {
    "text": "created of a human with a firehose of spans to illustrate how not having a sampling strategy in place could",
    "start": "463919",
    "end": "469919"
  },
  {
    "text": "negatively impact your organization but why exactly do i want to sample",
    "start": "469919",
    "end": "475919"
  },
  {
    "text": "so different organizations will have different reasons for not just what they want to sample but also why they want to sample",
    "start": "475919",
    "end": "481840"
  },
  {
    "text": "um some teams they want to see only interesting traces or they might want to filter out noise",
    "start": "481840",
    "end": "487199"
  },
  {
    "text": "such as health checks and i'm going to pause you for a second to explain what i mean by interesting",
    "start": "487199",
    "end": "492319"
  },
  {
    "text": "traces you'll also hear me use the term traces of interest i'm just referring to the specific trace",
    "start": "492319",
    "end": "498240"
  },
  {
    "text": "data that you or your teams might be interested in for example as an app developer i might",
    "start": "498240",
    "end": "503280"
  },
  {
    "text": "be only interested in error traces for debugging purposes my front-end team might be interested in",
    "start": "503280",
    "end": "508639"
  },
  {
    "text": "traces with specific attributes",
    "start": "508639",
    "end": "512479"
  },
  {
    "text": "another way to think about sampling is if 99 of the traces that your system is",
    "start": "515760",
    "end": "523200"
  },
  {
    "text": "producing are 200s and finished without errors or latency",
    "start": "523200",
    "end": "529279"
  },
  {
    "text": "do you really need all that data so the thing is you don't always need a",
    "start": "529279",
    "end": "534720"
  },
  {
    "text": "ton of data to find the right insights you need the right sampling of data",
    "start": "534720",
    "end": "541279"
  },
  {
    "text": "so now we're going to talk about a couple um hip sampling strategies starting with head-based sampling and they'll get into",
    "start": "541279",
    "end": "547279"
  },
  {
    "text": "tail-based sampling head-based sampling is simply where the sampling decision is made before span is",
    "start": "547279",
    "end": "554160"
  },
  {
    "text": "even created or at the start of a trace which makes it simple it's efficient",
    "start": "554160",
    "end": "559600"
  },
  {
    "text": "because the sampling decision gets propagated down to all child spans",
    "start": "559600",
    "end": "564959"
  },
  {
    "text": "um so it never has to wait until all spins and requests have finished and it's",
    "start": "564959",
    "end": "570000"
  },
  {
    "text": "unbiased because it never looks at the trace to make a sampling decision today open telemetry sdks ship with a",
    "start": "570000",
    "end": "577440"
  },
  {
    "text": "number of built-in head-based samplers we've got parent-based always-on trace",
    "start": "577440",
    "end": "584480"
  },
  {
    "text": "id ratio based and there's also always off i'm going to talk about the built-in",
    "start": "584480",
    "end": "590399"
  },
  {
    "text": "samplers a little bit now so the open telemetry default sampler is actually a composite of two of the",
    "start": "590399",
    "end": "597279"
  },
  {
    "text": "samplers we have the parent-based sampler which takes a required parameter for what you",
    "start": "597279",
    "end": "602480"
  },
  {
    "text": "want to use for your root spans so that's why it says root is always on because we are using the",
    "start": "602480",
    "end": "608720"
  },
  {
    "text": "always on sampler as the name suggests we will always sample the span of the root span",
    "start": "608720",
    "end": "615120"
  },
  {
    "text": "and the way the sampler works is by asking a few questions of every span first",
    "start": "615120",
    "end": "620640"
  },
  {
    "text": "are you root span of yes well guess what i'm always going to sample you if you're not a root span",
    "start": "620640",
    "end": "626480"
  },
  {
    "text": "that means hey you have a parent span and i was going to ask okay was your parents sampled if yes hop on the train",
    "start": "626480",
    "end": "633200"
  },
  {
    "text": "you're getting sampled and if not you're not getting sampled and in other words the sampling decision",
    "start": "633200",
    "end": "638399"
  },
  {
    "text": "gets propagated down to all the child spans so in this way this is how the",
    "start": "638399",
    "end": "644320"
  },
  {
    "text": "default sampler works to collect every span of every request in your system assuming all your",
    "start": "644320",
    "end": "650000"
  },
  {
    "text": "services are instrumented with open telemetry and using the default",
    "start": "650000",
    "end": "655680"
  },
  {
    "text": "okay this diagram which i also created painstakingly lovingly created for you all uh shows an example of what we might",
    "start": "656079",
    "end": "663279"
  },
  {
    "text": "see in our tracing back end that we're using the blue dots represent the root spans",
    "start": "663279",
    "end": "669120"
  },
  {
    "text": "and the blue rectangle represents where the sampling decision is made the green dots represent sample spans",
    "start": "669120",
    "end": "675440"
  },
  {
    "text": "and you can see um the entire trace is sampled and for some flavor we have the red dots",
    "start": "675440",
    "end": "682240"
  },
  {
    "text": "which represent error spans expands with errors and",
    "start": "682240",
    "end": "687519"
  },
  {
    "text": "you can see we get a full view of all the traces our system produces",
    "start": "687519",
    "end": "693120"
  },
  {
    "text": "next i want to talk about the trace id ratio based sampler but hold on a second",
    "start": "693519",
    "end": "700600"
  },
  {
    "text": "okay the name of this sampler is a mouthful for me so this sampler uses the trace id to make a",
    "start": "702160",
    "end": "708240"
  },
  {
    "text": "sampling decision with respect to the sampling rate that you configure",
    "start": "708240",
    "end": "713279"
  },
  {
    "text": "in open telemetry when we combine this sampler with the standard random trace id generator we get a mechanism by which",
    "start": "713279",
    "end": "720480"
  },
  {
    "text": "to do probabilistic or random sampling",
    "start": "720480",
    "end": "725680"
  },
  {
    "text": "essentially this diagram kind of gives a general high overview of how the sampler works",
    "start": "726560",
    "end": "732399"
  },
  {
    "text": "on this side it's randomly decided okay i'm going to sample everything with trace id one so all spans for trace id1",
    "start": "732399",
    "end": "739360"
  },
  {
    "text": "you're getting sampled on the other side you see it's decided okay i've not i'm not going to sample",
    "start": "739360",
    "end": "745839"
  },
  {
    "text": "trace id2 and therefore all those spans will get discarded",
    "start": "745839",
    "end": "750959"
  },
  {
    "text": "i do want to note here that if you have multiple connected services instrumented with",
    "start": "750959",
    "end": "756079"
  },
  {
    "text": "a variety of language sdks because they're in different languages the open telemetry specification recommends that",
    "start": "756079",
    "end": "762399"
  },
  {
    "text": "you use this only for root spans and so how earlier we saw",
    "start": "762399",
    "end": "768240"
  },
  {
    "text": "um the route takes in the os on sampler we'll just simply switch it out for the",
    "start": "768240",
    "end": "773839"
  },
  {
    "text": "trace id ratio based sampler so we'll see that example in the demo coming up",
    "start": "773839",
    "end": "779760"
  },
  {
    "text": "so here's the diagram showing an example of what we might see in our chasing back end if we're using trace id ratio based sampler",
    "start": "780240",
    "end": "788320"
  },
  {
    "text": "essentially a random sampling of traces we may or may not always see our traces of interest in which case",
    "start": "788320",
    "end": "796240"
  },
  {
    "text": "in the in this case being the error trace",
    "start": "796240",
    "end": "801839"
  },
  {
    "text": "okay so that's all i wanted to cover for head-based sampling let's talk about tail-based sampling",
    "start": "802079",
    "end": "808160"
  },
  {
    "text": "the biggest difference between head-based sampling and tilde sampling is that hotel-based sampling as the name suggests the sampling decision is made",
    "start": "808160",
    "end": "815200"
  },
  {
    "text": "only after all the spans in a request have finished this means we're able to filter traces",
    "start": "815200",
    "end": "821440"
  },
  {
    "text": "based on specific criteria it is useful for efficiently",
    "start": "821440",
    "end": "827040"
  },
  {
    "text": "seeing those traces of interest and it's optimal because we get to keep all our spams in context and don't lose",
    "start": "827040",
    "end": "834160"
  },
  {
    "text": "and don't get broken traces when we need the most today to do tail sampling using open",
    "start": "834160",
    "end": "840639"
  },
  {
    "text": "telemetry you have to stand up a collector which i mentioned at the beginning",
    "start": "840639",
    "end": "845680"
  },
  {
    "text": "and implement the component called the tail sampling processor",
    "start": "845680",
    "end": "850720"
  },
  {
    "text": "multiple policies exist today and you also have the flexibility to add more if you like this is just a short list of",
    "start": "850720",
    "end": "857279"
  },
  {
    "text": "the policies that you can use today i'm going to take you through the",
    "start": "857279",
    "end": "863279"
  },
  {
    "text": "screenshot here so this shows an example configuration for the tail sampling processor in our",
    "start": "863279",
    "end": "868800"
  },
  {
    "text": "collector config email file so here we've got our tail sampling processor that's the name of it",
    "start": "868800",
    "end": "875199"
  },
  {
    "text": "the first three lines here are all optional configurable",
    "start": "875199",
    "end": "880320"
  },
  {
    "text": "settings you can use or not a decision weight is the time to wait from the beginning of",
    "start": "880320",
    "end": "887440"
  },
  {
    "text": "the span or beginning of the trace to make a sampling decision numb traces is number of traces kept in",
    "start": "887440",
    "end": "893120"
  },
  {
    "text": "memory and expected new traces per sec is expected new traces per sec",
    "start": "893120",
    "end": "900160"
  },
  {
    "text": "and finally we have the policy section here there is no default so you will have to define at least one policy to use the",
    "start": "900160",
    "end": "907120"
  },
  {
    "text": "tail sampling processor in this example i have two policies set up i've got a",
    "start": "907120",
    "end": "912800"
  },
  {
    "text": "status code policy and a probabilistic policy and this will essentially get me all my",
    "start": "912800",
    "end": "918480"
  },
  {
    "text": "error traces as well as a random sampling of remaining traces",
    "start": "918480",
    "end": "925199"
  },
  {
    "text": "this is an example of what we might see in our tracing backend using the exact configuration i just showed you our",
    "start": "925760",
    "end": "931199"
  },
  {
    "text": "error trace as well as a random sampled a random sampling of remaining traces",
    "start": "931199",
    "end": "937759"
  },
  {
    "text": "if we decide to only use the status code policy this is what we would see just",
    "start": "937759",
    "end": "942880"
  },
  {
    "text": "the error traces okay so how is everyone feeling about",
    "start": "942880",
    "end": "950000"
  },
  {
    "text": "sampling good great awesome thank you",
    "start": "950000",
    "end": "955759"
  },
  {
    "text": "so if you have any lingering questions um please hold on to them and i'll try to get to them during the q a or hopefully some of them will be cleared",
    "start": "955759",
    "end": "962000"
  },
  {
    "text": "up with this live demo i'm about to show you okay so first i'll give you the context",
    "start": "962000",
    "end": "968480"
  },
  {
    "text": "of the demo and then i'll walk you through this uh scenarios that we're gonna see and then we'll do a quick demo",
    "start": "968480",
    "end": "973600"
  },
  {
    "text": "reflection so for the demo i have three services",
    "start": "973600",
    "end": "979920"
  },
  {
    "text": "that always call each other and what i mean by that is just service one always calls service two and service",
    "start": "979920",
    "end": "985199"
  },
  {
    "text": "two always call service three i have a load generator that makes 20 calls to",
    "start": "985199",
    "end": "990399"
  },
  {
    "text": "the first service and each time it is run it produces exactly one error",
    "start": "990399",
    "end": "995600"
  },
  {
    "text": "and for the purposes of this demo i've decided that my choices of interest whoops are choices with errors and we're going",
    "start": "995600",
    "end": "1002800"
  },
  {
    "text": "to be exporting all our choices to jager so we'll be uh looking at our traces of jager and my goal here is to find out which",
    "start": "1002800",
    "end": "1010560"
  },
  {
    "text": "sampling strategy is optimal for getting me what i want",
    "start": "1010560",
    "end": "1015600"
  },
  {
    "text": "first we're going to start with a couple of head-based sampling scenarios we're going to take a look at using the default",
    "start": "1016800",
    "end": "1022800"
  },
  {
    "text": "and then the trace id ratio based sampler and then we'll wrap up with a couple",
    "start": "1022800",
    "end": "1028240"
  },
  {
    "text": "tail sampling scenarios where we use the status quo policy and then adding in the probabilistic policy",
    "start": "1028240",
    "end": "1035678"
  },
  {
    "text": "all right let me see if this is gonna work",
    "start": "1035679",
    "end": "1040558"
  },
  {
    "text": "okay i think that worked oh oh boy what's happening",
    "start": "1042640",
    "end": "1048799"
  },
  {
    "text": "okay",
    "start": "1048799",
    "end": "1051799"
  },
  {
    "text": "so i'm going to be switching between three separate windows",
    "start": "1054320",
    "end": "1060559"
  },
  {
    "text": "we're going to have our jaeger ui over here i'll have my text editor here where i'll",
    "start": "1060559",
    "end": "1066480"
  },
  {
    "text": "show you the sdk configuration and finally i will have my terminal",
    "start": "1066480",
    "end": "1072000"
  },
  {
    "text": "where we are going to restart our services after making changes and",
    "start": "1072000",
    "end": "1077200"
  },
  {
    "text": "also running our load generator okay so",
    "start": "1077200",
    "end": "1083440"
  },
  {
    "text": "we don't need that you can stay there",
    "start": "1083440",
    "end": "1087440"
  },
  {
    "text": "all right so we're set up to do to use the open slump to default so i'm going to go ahead and run my load",
    "start": "1089919",
    "end": "1096720"
  },
  {
    "text": "generator and i'm going to come into the jager ui",
    "start": "1096720",
    "end": "1101919"
  },
  {
    "text": "and let's see what we got",
    "start": "1101919",
    "end": "1106679"
  },
  {
    "text": "oh boy please hold you know they warned me about doing live",
    "start": "1109200",
    "end": "1115600"
  },
  {
    "text": "demos and i said i'm gonna do it anyways",
    "start": "1115600",
    "end": "1122280"
  },
  {
    "text": "why are you not showing up",
    "start": "1124480",
    "end": "1128600"
  },
  {
    "text": "okay please hold",
    "start": "1141600",
    "end": "1144480"
  },
  {
    "text": "so if i'm using the telemetry open telemetry default and my load generator is making",
    "start": "1147520",
    "end": "1154240"
  },
  {
    "text": "20 calls to the first service how many traces do you think i'm going to see",
    "start": "1154240",
    "end": "1160000"
  },
  {
    "text": "when i want my load generator",
    "start": "1160000",
    "end": "1163720"
  },
  {
    "text": "someone just flashed out 20 you are absolutely 100 correct",
    "start": "1166880",
    "end": "1172160"
  },
  {
    "text": "now i would love to show you if i can figure out why this is",
    "start": "1172160",
    "end": "1179799"
  },
  {
    "text": "okay to 100 yay",
    "start": "1185919",
    "end": "1191120"
  },
  {
    "text": "okay so for those of you who are not familiar with jaeger on the left hand side is a",
    "start": "1191120",
    "end": "1198160"
  },
  {
    "text": "filter nav menu we are primarily going to be focused on the right side where we'll see our traces",
    "start": "1198160",
    "end": "1203440"
  },
  {
    "text": "so here we have 20 traces you're so correct and as i'm scrolling through here so each of",
    "start": "1203440",
    "end": "1210159"
  },
  {
    "text": "these lines is a trace if i click on one this might look familiar it was in the screenshot that i",
    "start": "1210159",
    "end": "1216159"
  },
  {
    "text": "showed you earlier these are all spans and you can see like the different services",
    "start": "1216159",
    "end": "1221840"
  },
  {
    "text": "and if i scroll down a little bit more hey look there's my error trace that i wanted",
    "start": "1222000",
    "end": "1227600"
  },
  {
    "text": "along with a lot of not so interesting traces let's see what happens if i run my load",
    "start": "1227600",
    "end": "1234400"
  },
  {
    "text": "generator a couple more times",
    "start": "1234400",
    "end": "1238080"
  },
  {
    "text": "now when i come in here if you guessed that we will now see 60 traces",
    "start": "1239840",
    "end": "1245120"
  },
  {
    "text": "you are correct i'm so glad that worked just now okay so 60 traces",
    "start": "1245120",
    "end": "1250799"
  },
  {
    "text": "and if i scroll down i will see hey there's one of my ear traces and i should see one more",
    "start": "1250799",
    "end": "1257760"
  },
  {
    "text": "there you are and then our third one which was from the first time we ran the load generator perfect there we go so i've got all my",
    "start": "1257760",
    "end": "1264640"
  },
  {
    "text": "error traces which is what i wanted but i'm having to kind of sift through a lot of uninteresting data to get to them",
    "start": "1264640",
    "end": "1272080"
  },
  {
    "text": "so now i want to try probabilistic sampling because i'm getting too many traces",
    "start": "1272080",
    "end": "1278320"
  },
  {
    "text": "so now i'm going to come into my first service which is a javascript service so we're going to go into the tracing.js",
    "start": "1278320",
    "end": "1284080"
  },
  {
    "text": "file and here i already have it written out so i'm just simply going to uncomment it",
    "start": "1284080",
    "end": "1291520"
  },
  {
    "text": "so now i'm passing in the sampler as you can see i'm only using on bootspans per the open telemetry",
    "start": "1291520",
    "end": "1298000"
  },
  {
    "text": "specification recommendation that was a lot of multi-syllable words at once",
    "start": "1298000",
    "end": "1303520"
  },
  {
    "text": "all right and now i'm going to do it for my second service which is a.net service",
    "start": "1303520",
    "end": "1308559"
  },
  {
    "text": "and finally i'm going to do the same thing for my third service which is a python service",
    "start": "1308559",
    "end": "1314720"
  },
  {
    "text": "and also you can see here that the sampling rate that i've configured is 25 percent",
    "start": "1314799",
    "end": "1321440"
  },
  {
    "text": "so now i'm going to go into my terminal and restart",
    "start": "1321440",
    "end": "1327760"
  },
  {
    "text": "my first two services for the changes to take effect the python one auto reload so i have to",
    "start": "1327760",
    "end": "1333600"
  },
  {
    "text": "worry about that one okay so now let's run my load generator",
    "start": "1333600",
    "end": "1341679"
  },
  {
    "text": "okay so pay attention to this top number here 60.",
    "start": "1341760",
    "end": "1347840"
  },
  {
    "text": "what do you think we're gonna get maybe",
    "start": "1347919",
    "end": "1354159"
  },
  {
    "text": "so close seven so we have seven new traces",
    "start": "1354159",
    "end": "1360240"
  },
  {
    "text": "and hey look i got an error trace that's cool and a random sampling of all other",
    "start": "1360240",
    "end": "1366720"
  },
  {
    "text": "traces and you can see here too so this right here it says a few seconds ago and this was two minutes ago so all the ones",
    "start": "1366720",
    "end": "1373280"
  },
  {
    "text": "above this are my new traces so let me go ahead and run this a couple more times",
    "start": "1373280",
    "end": "1380799"
  },
  {
    "text": "and let's see what we see okay so the number 67",
    "start": "1381280",
    "end": "1386880"
  },
  {
    "text": "and it updates to 74. seven new traces",
    "start": "1386880",
    "end": "1392080"
  },
  {
    "text": "yes i think my math is correct actually that seems a little low 74",
    "start": "1392080",
    "end": "1398799"
  },
  {
    "text": "choices okay",
    "start": "1398799",
    "end": "1402200"
  },
  {
    "text": "oh and that's so interesting so i actually got using the trace id ratio base sampler this time",
    "start": "1405120",
    "end": "1411200"
  },
  {
    "text": "it looks like i got two of my error traces which is interesting i've run this demo and had zero of the error traces show up",
    "start": "1411200",
    "end": "1417919"
  },
  {
    "text": "i've had like one air trade show up so it really is randomized as you can see",
    "start": "1417919",
    "end": "1423440"
  },
  {
    "text": "however i want to more efficiently see my error traces so",
    "start": "1423440",
    "end": "1429360"
  },
  {
    "text": "now i'm going to go ahead and try using the tail based sampling processor",
    "start": "1429360",
    "end": "1434799"
  },
  {
    "text": "so in order to do that i'm going to come into my services i'm going to comment the chase",
    "start": "1434799",
    "end": "1440480"
  },
  {
    "text": "id ratio base sampler back out and i'm actually going to use the always-on",
    "start": "1440480",
    "end": "1446320"
  },
  {
    "text": "sampler because i want to be doubly sure that all my spans are getting sampled",
    "start": "1446320",
    "end": "1451840"
  },
  {
    "text": "you could use the default as well um i want to be extra sure so that's why i'm using the",
    "start": "1451840",
    "end": "1457120"
  },
  {
    "text": "always on sampler so i'm going to go ahead and",
    "start": "1457120",
    "end": "1462480"
  },
  {
    "text": "comment out the old one and go ahead",
    "start": "1462480",
    "end": "1466960"
  },
  {
    "text": "and now i want to show you what that looks like in the hotel collector config email file",
    "start": "1467679",
    "end": "1473919"
  },
  {
    "text": "so you'll remember the screenshot that i showed you of the example configuration so here i'm using the decision weight",
    "start": "1473919",
    "end": "1481279"
  },
  {
    "text": "optional setting and i've already got a policy here that will get me all air traces",
    "start": "1481279",
    "end": "1488240"
  },
  {
    "text": "and the cool thing is i can have it set up and if i don't want to use it i simply don't have to include it in the",
    "start": "1488240",
    "end": "1493520"
  },
  {
    "text": "pipelines section for my traces as soon as i'm ready all i have to do is add it into my pipeline",
    "start": "1493520",
    "end": "1501039"
  },
  {
    "text": "save it and let's not forget to restart our collector",
    "start": "1501039",
    "end": "1507360"
  },
  {
    "text": "and then also restart two of my services",
    "start": "1509200",
    "end": "1514520"
  },
  {
    "text": "all right looks like she's ready okay so now i want to run my load generator",
    "start": "1516240",
    "end": "1521360"
  },
  {
    "text": "what do you think we're going to see in jager",
    "start": "1521360",
    "end": "1525039"
  },
  {
    "text": "yes i heard one and you'll see since i restarted the collector this number here",
    "start": "1527440",
    "end": "1532640"
  },
  {
    "text": "is gonna reset so one error trace that's awesome",
    "start": "1532640",
    "end": "1538720"
  },
  {
    "text": "let's run it a couple more times and",
    "start": "1538720",
    "end": "1544799"
  },
  {
    "text": "we will now see three traces and they're all my air traces so this is great i'm seeing the traces i",
    "start": "1544799",
    "end": "1551039"
  },
  {
    "text": "wanted but now i'm thinking maybe this isn't quite enough information because it can be useful to have a random",
    "start": "1551039",
    "end": "1556960"
  },
  {
    "text": "sampling of all your other traces to see whether anything else might be occurring or if you want to improve",
    "start": "1556960",
    "end": "1563440"
  },
  {
    "text": "typical operations within a given service so now i'm going to go back in here and",
    "start": "1563440",
    "end": "1568640"
  },
  {
    "text": "i already have a probabilistic policy defined here so i will uncomment that out",
    "start": "1568640",
    "end": "1574320"
  },
  {
    "text": "and let's restart my collector",
    "start": "1574320",
    "end": "1578000"
  },
  {
    "text": "and let's see what this new configuration gives us",
    "start": "1580480",
    "end": "1587760"
  },
  {
    "text": "all right so this is going to reset and i have four choices now",
    "start": "1587760",
    "end": "1593360"
  },
  {
    "text": "so i've got my error trace and a random sampling of all other traces if i run",
    "start": "1593360",
    "end": "1598720"
  },
  {
    "text": "this a couple more times",
    "start": "1598720",
    "end": "1602000"
  },
  {
    "text": "it's going to go from 4 to 15 so i've got 9 new traces",
    "start": "1603840",
    "end": "1609279"
  },
  {
    "text": "hey there's my error trace there's another one and there's my third one from the first",
    "start": "1609279",
    "end": "1614960"
  },
  {
    "text": "time we ran the load generator and this is great now i've got my error traces",
    "start": "1614960",
    "end": "1620640"
  },
  {
    "text": "and a random sampling of all other traces okay now i have to",
    "start": "1620640",
    "end": "1627840"
  },
  {
    "text": "it's gonna be a little bit anticlimactic hold on a second",
    "start": "1628000",
    "end": "1632320"
  },
  {
    "text": "where is the how do i stop the mirroring no",
    "start": "1633360",
    "end": "1641799"
  },
  {
    "text": "oh did i lose it okay well i appear to have lost the",
    "start": "1643120",
    "end": "1650240"
  },
  {
    "text": "display window never mind that's okay",
    "start": "1650240",
    "end": "1654840"
  },
  {
    "text": "so yay that's what you were supposed to see right",
    "start": "1657919",
    "end": "1663120"
  },
  {
    "text": "[Applause] after you",
    "start": "1663120",
    "end": "1669600"
  },
  {
    "text": "so now you've seen how to implement tail-based sampling using open telemetry and also how tail sampling can be",
    "start": "1669600",
    "end": "1676559"
  },
  {
    "text": "optimal for getting us what we want efficiently and i apologize i keep hitting my mic i'll stop doing that",
    "start": "1676559",
    "end": "1682880"
  },
  {
    "text": "let's see how are we on time um just to do a quick demo reflection",
    "start": "1682880",
    "end": "1690559"
  },
  {
    "text": "so using our open telemetry default we always saw our traces of interest but we also saw everything else",
    "start": "1690559",
    "end": "1697679"
  },
  {
    "text": "so then we wanted to do to get fewest traces so we used the trace id ratio based sampler for our",
    "start": "1697679",
    "end": "1703760"
  },
  {
    "text": "root spans and now we got a random sampling we didn't always see our traces of interest",
    "start": "1703760",
    "end": "1709440"
  },
  {
    "text": "so then we wanted to try the tail-based sampling processor when we used the status quo policy we",
    "start": "1709440",
    "end": "1715279"
  },
  {
    "text": "only saw our errors we decided hey it is useful to get a random sampling of all other traces and so i added in the",
    "start": "1715279",
    "end": "1722240"
  },
  {
    "text": "probabilistic policy and we saw that we got all our error traces plus our random",
    "start": "1722240",
    "end": "1727279"
  },
  {
    "text": "sampling which was awesome and now that i've talked up tail",
    "start": "1727279",
    "end": "1733520"
  },
  {
    "text": "sampling so much and hyped it up i'm going to bring the mood down a little bit by talking about the challenges",
    "start": "1733520",
    "end": "1739200"
  },
  {
    "text": "we'll start with some general concerns around tail sampling and then we'll get into some open telemetry specific limitations",
    "start": "1739200",
    "end": "1746480"
  },
  {
    "text": "so the first one is probably the one we see the most consistently and that is performance consideration",
    "start": "1747679",
    "end": "1754799"
  },
  {
    "text": "since tail-based sampling um since with taillight sampling we have to",
    "start": "1754799",
    "end": "1760320"
  },
  {
    "text": "wait until all the spans that are crossed are finished we have to hold those spans in memory somewhere before the last band has",
    "start": "1760320",
    "end": "1766399"
  },
  {
    "text": "finished and this of course can eat up application resources if the",
    "start": "1766399",
    "end": "1771679"
  },
  {
    "text": "um if the spans are stored locally or additional network bandwidth",
    "start": "1771679",
    "end": "1777679"
  },
  {
    "text": "if your choices aren't stored locally additionally determining the interesting traces",
    "start": "1777679",
    "end": "1783679"
  },
  {
    "text": "so earlier i said you don't need a ton of data to find the right insights you just need the right sampling",
    "start": "1783679",
    "end": "1789919"
  },
  {
    "text": "well there's going to be some work involved with figuring out what exactly that means for your team",
    "start": "1789919",
    "end": "1795200"
  },
  {
    "text": "you're going to have to ask them questions to know what to sample data egress and storage costs so",
    "start": "1795200",
    "end": "1802159"
  },
  {
    "text": "sampling is supposed to help us manage these costs right however let's say you are using the tail",
    "start": "1802159",
    "end": "1808000"
  },
  {
    "text": "simply processor to get you only latency traces",
    "start": "1808000",
    "end": "1813360"
  },
  {
    "text": "well if you're suddenly experiencing severe network congestion and your tracing solution is now exporting up a",
    "start": "1813360",
    "end": "1820240"
  },
  {
    "text": "ton of traces of latency you're going to see a spike during that period um",
    "start": "1820240",
    "end": "1825760"
  },
  {
    "text": "in data egress storage costs and potentially data ingest depending on how your back-end vendor",
    "start": "1825760",
    "end": "1833050"
  },
  {
    "text": "[Music] depending on their pricing model",
    "start": "1833050",
    "end": "1837840"
  },
  {
    "text": "and with open telemetry specifically so to use tail sampling using open",
    "start": "1838480",
    "end": "1844240"
  },
  {
    "text": "telemetry today you have to stand up a collector there's no way to get around it at this time and while it is",
    "start": "1844240",
    "end": "1852640"
  },
  {
    "text": "while the collector can be really useful and practical in terms of centralizing configuration",
    "start": "1852640",
    "end": "1857760"
  },
  {
    "text": "and performing a wide range of data processing duties it is the walmart piece in your environment to implement",
    "start": "1857760",
    "end": "1864559"
  },
  {
    "text": "maintain and consider additionally all the traces",
    "start": "1864559",
    "end": "1871360"
  },
  {
    "text": "need to be full so all spans of a particular trace need to end up in the same collector for tail sampling to work",
    "start": "1871360",
    "end": "1877200"
  },
  {
    "text": "properly which brings me to the scalability issue so for a simple setup like what i showed",
    "start": "1877200",
    "end": "1883679"
  },
  {
    "text": "you with the demo where i had three dummy services not a lot of traffic one collector sufficient",
    "start": "1883679",
    "end": "1890320"
  },
  {
    "text": "however the more traces you have been kept in memory the more memory you're going to",
    "start": "1890320",
    "end": "1895600"
  },
  {
    "text": "need and the more computing and processing power you're going to need to look at each span to see if it fits to",
    "start": "1895600",
    "end": "1902159"
  },
  {
    "text": "see if any of them fit your bill for an interesting trace after certain load one collector",
    "start": "1902159",
    "end": "1908159"
  },
  {
    "text": "is not going to cut it so now you have to look at collect a deployment pattern and think about load balancing",
    "start": "1908159",
    "end": "1915120"
  },
  {
    "text": "there's like no like smooth transition to getting water hold on",
    "start": "1915120",
    "end": "1921840"
  },
  {
    "text": "so since one collector is not going to be enough you're going to want to implement a two",
    "start": "1923600",
    "end": "1928799"
  },
  {
    "text": "layer system in which the collector is deployed in an agent collector configuration",
    "start": "1928799",
    "end": "1934960"
  },
  {
    "text": "and since all spans of a particular trace like i said need to end up in the",
    "start": "1934960",
    "end": "1940159"
  },
  {
    "text": "same collector which is to say each collector needs a full view of all the traces it receives",
    "start": "1940159",
    "end": "1946320"
  },
  {
    "text": "and this is because if you have spans going to different collectors and you know they're each getting sampled",
    "start": "1946320",
    "end": "1952399"
  },
  {
    "text": "you're going to end up with firemen to traces which means you're going to get traces with lots of gaps and you may not",
    "start": "1952399",
    "end": "1958320"
  },
  {
    "text": "necessarily know you know where exactly a problem is occurring or which service has an issue",
    "start": "1958320",
    "end": "1965600"
  },
  {
    "text": "there does exist today an exporter called the load balancing exporter that you can use if you're",
    "start": "1965600",
    "end": "1971200"
  },
  {
    "text": "running multiple instances of the collector with the tail sampling processor so there is hope",
    "start": "1971200",
    "end": "1977279"
  },
  {
    "text": "and finally the future of the tail summing processor it sounds a little ominous but it's",
    "start": "1977279",
    "end": "1983120"
  },
  {
    "text": "simply referring to there's an open issue right now in the collector contrib repository around",
    "start": "1983120",
    "end": "1990080"
  },
  {
    "text": "replacing the tail sampling processor the conversation is more around",
    "start": "1990080",
    "end": "1995519"
  },
  {
    "text": "will breaking up some of the policies and building them out into their own processors be more performance than or",
    "start": "1995519",
    "end": "2003120"
  },
  {
    "text": "be more or as performant as using the tail sampling processor if you're interested in this discussion",
    "start": "2003120",
    "end": "2009039"
  },
  {
    "text": "um i encourage you to reach out to jurassic crowling he is for the grana and he is kind of the mastermind behind",
    "start": "2009039",
    "end": "2015519"
  },
  {
    "text": "this idea and i think",
    "start": "2015519",
    "end": "2021519"
  },
  {
    "text": "we've arrived so in summary tail sampling is great for",
    "start": "2021519",
    "end": "2026799"
  },
  {
    "text": "efficiently getting you what you want but there's going to be a lot of challenges with figuring out what exactly that means for your team as well",
    "start": "2026799",
    "end": "2032720"
  },
  {
    "text": "as implementing it a couple of quick feature-ish things i wanted to to touch on um",
    "start": "2032720",
    "end": "2039120"
  },
  {
    "text": "so there's work being done right now to add probabilistic log sampling to the open",
    "start": "2039120",
    "end": "2044559"
  },
  {
    "text": "telemetry specification which is pretty cool i encourage you to head to the collector",
    "start": "2044559",
    "end": "2049760"
  },
  {
    "text": "contrib repository to find out more and also wanted to talk about contributing if you're interested in",
    "start": "2049760",
    "end": "2056398"
  },
  {
    "text": "getting involved with open telemetry that is a very exciting time whether you want to do co-contributions or help",
    "start": "2056399",
    "end": "2061760"
  },
  {
    "text": "improve docs i know the community team is very excited to have",
    "start": "2061760",
    "end": "2067440"
  },
  {
    "text": "all your great minds involved so definitely head to um oh actually i have",
    "start": "2067440",
    "end": "2072800"
  },
  {
    "text": "the slides a slide at the end that will have some links for you to check out",
    "start": "2072800",
    "end": "2078319"
  },
  {
    "text": "and big shout out to everyone that is on this list and all of you who came today",
    "start": "2078720",
    "end": "2083919"
  },
  {
    "text": "and for anyone watching the recording i appreciate you all so much for being",
    "start": "2083919",
    "end": "2089200"
  },
  {
    "text": "here and all right if anyone has questions um please head",
    "start": "2089200",
    "end": "2094878"
  },
  {
    "text": "to the mic it looks like i am right on time but um",
    "start": "2094879",
    "end": "2099920"
  },
  {
    "text": "i see a gentleman back there so let me leave this slide here for you um",
    "start": "2099920",
    "end": "2105119"
  },
  {
    "text": "this bar code here if you have feedback that you would like to share with the open telemetry community team about your",
    "start": "2105119",
    "end": "2110640"
  },
  {
    "text": "experience um whether you've used it or like what's stopping you from using it we would love to know and yes what is",
    "start": "2110640",
    "end": "2117040"
  },
  {
    "text": "your question that i can hopefully answer thank you for your presentation first of all i have a question so how does",
    "start": "2117040",
    "end": "2123760"
  },
  {
    "text": "collector know when all these ones have been collected that is a great question",
    "start": "2123760",
    "end": "2131838"
  },
  {
    "text": "and it might so",
    "start": "2132160",
    "end": "2138560"
  },
  {
    "text": "i think that's one of the the challenges right um patel based sampling in general",
    "start": "2138880",
    "end": "2144400"
  },
  {
    "text": "there is that um configuration setting decision weight",
    "start": "2144400",
    "end": "2150320"
  },
  {
    "text": "so you can't have it set to a longer period of time i think the default is 30 seconds which is like",
    "start": "2150320",
    "end": "2156320"
  },
  {
    "text": "a pretty long period of time i think the problem of course will be if",
    "start": "2156320",
    "end": "2162480"
  },
  {
    "text": "you have spans that are finishing really late or taking really long so i don't have a great answer for you",
    "start": "2162480",
    "end": "2169359"
  },
  {
    "text": "about that at the moment um i do encourage you to",
    "start": "2169359",
    "end": "2175040"
  },
  {
    "text": "you know have this discussion um in the open telemetry slack channel or feel free to come to one of the special",
    "start": "2175040",
    "end": "2180880"
  },
  {
    "text": "interest group meetings but i'm also actually curious about that so if you want to hang around i'm going to grab",
    "start": "2180880",
    "end": "2186240"
  },
  {
    "text": "your contact info and then if i find out the answer if you found out the answer first like let's share that",
    "start": "2186240",
    "end": "2191839"
  },
  {
    "text": "so it's time based basically right so what is it so it's time out based we are",
    "start": "2191839",
    "end": "2197040"
  },
  {
    "text": "waiting for specific time okay thank you yeah thank you you're so welcome",
    "start": "2197040",
    "end": "2202400"
  },
  {
    "text": "okay we have one more so um there's a lot of talks today and well",
    "start": "2202400",
    "end": "2207680"
  },
  {
    "text": "yesterday and going to be tomorrow about ebpa for it bppf lease and bp of that and it seems that",
    "start": "2207680",
    "end": "2214960"
  },
  {
    "text": "ebpf can do all this magic like how much did you call take time and how much each",
    "start": "2214960",
    "end": "2220720"
  },
  {
    "text": "function took and all of that and it seems to be replacing like distributed",
    "start": "2220720",
    "end": "2226720"
  },
  {
    "text": "tracing in that way so do you see ebpf as a distributed tracing killer because",
    "start": "2226720",
    "end": "2234240"
  },
  {
    "text": "you said that distributed racing its implementation of a telemetry it has overheads and like",
    "start": "2234240",
    "end": "2241359"
  },
  {
    "text": "performance implications and ebpf is advertising itself as like something it",
    "start": "2241359",
    "end": "2246400"
  },
  {
    "text": "comes practically for free because it's only in kernel space and it's very lightweight and all of that so how do",
    "start": "2246400",
    "end": "2252160"
  },
  {
    "text": "you see this competing that is a great question and i'm wondering if anyone from the pixie team",
    "start": "2252160",
    "end": "2260079"
  },
  {
    "text": "would like to answer that question because do we have pixel team here yes",
    "start": "2260079",
    "end": "2268200"
  },
  {
    "text": "thank you omad all right",
    "start": "2270400",
    "end": "2275520"
  },
  {
    "text": "um you can join as well i was just going to chime in and say yeah i mean there's a lot of things that",
    "start": "2275520",
    "end": "2281280"
  },
  {
    "text": "ebpf can do bpf is great at capturing spans at least in the context of pixie",
    "start": "2281280",
    "end": "2287280"
  },
  {
    "text": "but just to be completely like fair on both sides there's pros and cons right and so",
    "start": "2287280",
    "end": "2292640"
  },
  {
    "text": "one thing that ebpf doesn't do is that you can't really um throw in for me or at least when",
    "start": "2292640",
    "end": "2299440"
  },
  {
    "text": "you're trying to observe you can't really throw tags into requests and so trying to trace something across",
    "start": "2299440",
    "end": "2304640"
  },
  {
    "text": "multiple hops like distributed tracing like what reese is showing is actually a little bit more difficult to do with ebpf right",
    "start": "2304640",
    "end": "2312800"
  },
  {
    "text": "so you're good at capturing spans with ebpf but getting distributed traces that's something that actually open",
    "start": "2312800",
    "end": "2317839"
  },
  {
    "text": "telemetry is very good at right and so there's pros and cons with these things um it's not just one",
    "start": "2317839",
    "end": "2323680"
  },
  {
    "text": "one tool fits all right so just a quick lever on that",
    "start": "2323680",
    "end": "2329520"
  },
  {
    "text": "thank you oh i'm so excited that you're here and that is all i have for you today",
    "start": "2329520",
    "end": "2335359"
  },
  {
    "text": "thank you all so much for being here hope you enjoy your stay in valencia if you're visiting",
    "start": "2335359",
    "end": "2342920"
  }
]
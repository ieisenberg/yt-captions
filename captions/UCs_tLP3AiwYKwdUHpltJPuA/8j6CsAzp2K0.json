[
  {
    "start": "0",
    "end": "59000"
  },
  {
    "text": "Welcome to our session harnessing Eda and workflows to build real world generative vaa applications my name is",
    "start": "12000",
    "end": "18480"
  },
  {
    "text": "Umar ramadas I'm a Solutions architect at AWS I help customers build and",
    "start": "18480",
    "end": "24359"
  },
  {
    "text": "Implement workflow related applications and even driven architectures and today",
    "start": "24359",
    "end": "30720"
  },
  {
    "text": "I'm joined by vaa hey everybody thanks for joining us I know this is the really",
    "start": "30720",
    "end": "35960"
  },
  {
    "text": "last session and I hope we keep this interesting and fun if not more than the",
    "start": "35960",
    "end": "41280"
  },
  {
    "text": "happy hour um I'm an AIML Solutions architect at AWS I was a serverless Solutions",
    "start": "41280",
    "end": "48160"
  },
  {
    "text": "architect now I um I help customers build AIML uh Solutions uh using our",
    "start": "48160",
    "end": "55160"
  },
  {
    "text": "services and also the serverless services all right um a quick look uh so",
    "start": "55160",
    "end": "61399"
  },
  {
    "start": "59000",
    "end": "141000"
  },
  {
    "text": "we're going to be talking about this new thing called generative AI if you don't didn't know what that is um then we're",
    "start": "61399",
    "end": "68479"
  },
  {
    "text": "going to look at event driven architectures um and then we're going to talk about a specific prompt engineering",
    "start": "68479",
    "end": "76040"
  },
  {
    "text": "technique called prompt chaining and how you can um build prompt chain uh",
    "start": "76040",
    "end": "81960"
  },
  {
    "text": "applications using prompt chaining um for your already existing",
    "start": "81960",
    "end": "87000"
  },
  {
    "text": "application and then we're going to see how you can can use a human in that",
    "start": "87000",
    "end": "92040"
  },
  {
    "text": "workflow to make decisions um before you launch or",
    "start": "92040",
    "end": "97200"
  },
  {
    "text": "release the product to your the market and then we're going to look at how to get start get started so we're here",
    "start": "97200",
    "end": "104159"
  },
  {
    "text": "today to explore these three ideas so first thing we want to see is how do we",
    "start": "104159",
    "end": "109960"
  },
  {
    "text": "use event driven architectures to build a new generative",
    "start": "109960",
    "end": "115040"
  },
  {
    "text": "AI capability in an in our existing application and then then we're going to",
    "start": "115040",
    "end": "120479"
  },
  {
    "text": "see how we can use prompt engineering together with human in the loop um to",
    "start": "120479",
    "end": "128319"
  },
  {
    "text": "build a safe and efficient uh gen capability in our existing",
    "start": "128319",
    "end": "135000"
  },
  {
    "text": "application and then uh we're going to see how Ed and workflows fit into this geni world so quick show of hands how",
    "start": "135000",
    "end": "142599"
  },
  {
    "start": "141000",
    "end": "699000"
  },
  {
    "text": "many of you have used generative AI llms our building applications",
    "start": "142599",
    "end": "149959"
  },
  {
    "text": "W awesome so over the last two years I would say geni has been the answer for",
    "start": "149959",
    "end": "157640"
  },
  {
    "text": "everything right but what was the question why why should we use geni what",
    "start": "157640",
    "end": "164519"
  },
  {
    "text": "is it right generative AI has been a truly transformative technology um probably since the",
    "start": "164519",
    "end": "171560"
  },
  {
    "text": "internet you know at the same scale right organizations um both large and small",
    "start": "171560",
    "end": "178440"
  },
  {
    "text": "are uh trying trying to build applications using this generative AI",
    "start": "178440",
    "end": "183840"
  },
  {
    "text": "technology um to enhance customer experiences uh to make their employees",
    "start": "183840",
    "end": "190040"
  },
  {
    "text": "and developers more productive and bring uh products faster to Market so um what",
    "start": "190040",
    "end": "196159"
  },
  {
    "text": "is generative Ai and why is it so popular so generative AI is uh a class",
    "start": "196159",
    "end": "203319"
  },
  {
    "text": "of AI or a type of AI which can generate new content and that new content can be",
    "start": "203319",
    "end": "209879"
  },
  {
    "text": "new stories text video audio and it can even continue a conversation just like a",
    "start": "209879",
    "end": "216760"
  },
  {
    "text": "human would with you right and and generative AI is powered by um machine",
    "start": "216760",
    "end": "224760"
  },
  {
    "text": "learning models and these are machine learning models that are really really large",
    "start": "224760",
    "end": "229799"
  },
  {
    "text": "models right but machine learning is not new to us we've been doing machine learning for more than a decade now so",
    "start": "229799",
    "end": "237360"
  },
  {
    "text": "what is different and why is geni so popular now what is different in this",
    "start": "237360",
    "end": "243400"
  },
  {
    "text": "machine learning technique so if you look on the left here the traditional",
    "start": "243400",
    "end": "248439"
  },
  {
    "text": "machine learning models that we built you know we started off with a task",
    "start": "248439",
    "end": "253599"
  },
  {
    "text": "right say for example you wanted to have a machine learning capability that can summarize documents for you or you want",
    "start": "253599",
    "end": "260880"
  },
  {
    "text": "to extract information from documents so you would start off with that task and",
    "start": "260880",
    "end": "266600"
  },
  {
    "text": "start collecting data sets labeled data sets right and use those labeled data",
    "start": "266600",
    "end": "273000"
  },
  {
    "text": "sets to build a machine learning model and that resulting machine learning model could only perform that task so if",
    "start": "273000",
    "end": "281199"
  },
  {
    "text": "you were creating a machine learning model to summarize documents It could only summarize the documents it could",
    "start": "281199",
    "end": "287520"
  },
  {
    "text": "not do anything else so if you had to build a new capability where you can extract information then you had to",
    "start": "287520",
    "end": "294600"
  },
  {
    "text": "start the process all over again collect the data set build a machine learning model train it and then you would get",
    "start": "294600",
    "end": "300680"
  },
  {
    "text": "that model so contrasting to that what is happening in the geni space is um",
    "start": "300680",
    "end": "307560"
  },
  {
    "text": "we're performing the same process of building machine learning model but we're starting with large quantities of",
    "start": "307560",
    "end": "313800"
  },
  {
    "text": "unlabeled data sets and this unlabeled data set is huge imagine half the size",
    "start": "313800",
    "end": "319440"
  },
  {
    "text": "of the internet so these model providers um you know the model sizes are growing",
    "start": "319440",
    "end": "325400"
  },
  {
    "text": "day by day and the model providers use trillions and trillions of tokens um to train these large models called",
    "start": "325400",
    "end": "332520"
  },
  {
    "text": "Foundation models and of course the model size is also extremely large compared to the",
    "start": "332520",
    "end": "339560"
  },
  {
    "text": "traditional models and as we saw that we trained these really large models the model started exhibiting behavior that a",
    "start": "339560",
    "end": "347400"
  },
  {
    "text": "human the way that a human will think and generate content right and the the",
    "start": "347400",
    "end": "352600"
  },
  {
    "text": "resulting model was so general purpose in nature that it could be easily adapted to perform any task so we didn't",
    "start": "352600",
    "end": "359919"
  },
  {
    "text": "have to train retrain the machine learning models for each task so such is the general purpose nature of these",
    "start": "359919",
    "end": "365960"
  },
  {
    "text": "Foundation models and I attribute that to these three things that happened",
    "start": "365960",
    "end": "371720"
  },
  {
    "text": "right the first is um the advancement of the machine learning techniques itself and if you have heard the Transformer",
    "start": "371720",
    "end": "379000"
  },
  {
    "text": "architecture right back in 2017 I think um there was a paper launched called attention is all you need and this",
    "start": "379000",
    "end": "386599"
  },
  {
    "text": "attention mechanism really Revolution how we train machine learning models",
    "start": "386599",
    "end": "391759"
  },
  {
    "text": "especially in the text and the video space and the image space right so this attention mechanism made it highly",
    "start": "391759",
    "end": "399520"
  },
  {
    "text": "parallelizable the training was very parallelizable and the second is the",
    "start": "399520",
    "end": "405960"
  },
  {
    "text": "readily available compute capacity to train the machine learning models needed",
    "start": "405960",
    "end": "411160"
  },
  {
    "text": "a lot of gpus and the cloud made it happen to train these machine learning",
    "start": "411160",
    "end": "416680"
  },
  {
    "text": "models these machine learning models are trailed over several several days right one cycle of training can take over a",
    "start": "416680",
    "end": "423759"
  },
  {
    "text": "month and and third is the availability of Digital Data you know we are adding",
    "start": "423759",
    "end": "429680"
  },
  {
    "text": "more and more data Digital Data and the readily available Digital Data made it possible these three three things made",
    "start": "429680",
    "end": "436800"
  },
  {
    "text": "machine learn uh Foundation models in gen possible but gen doesn't really exist in",
    "start": "436800",
    "end": "442840"
  },
  {
    "text": "a vacuum we want to use this amazing technology in our existing",
    "start": "442840",
    "end": "448360"
  },
  {
    "text": "applications and and enhance the customer experiences we want to use this",
    "start": "448360",
    "end": "454039"
  },
  {
    "text": "um in existing applications so that we can bring the products faster to Market",
    "start": "454039",
    "end": "459160"
  },
  {
    "text": "and to show you how to do that uh we'll pick an example application already",
    "start": "459160",
    "end": "464280"
  },
  {
    "text": "existing application and see how we can build that gen capability right and V said we are going",
    "start": "464280",
    "end": "472560"
  },
  {
    "text": "to walk you through the process of building an extension to an existing application and add some generative a",
    "start": "472560",
    "end": "480120"
  },
  {
    "text": "capability imagine that you uh we have an online platform and that platform",
    "start": "480120",
    "end": "485720"
  },
  {
    "text": "supports customers to browse through products and purchase products and also",
    "start": "485720",
    "end": "491560"
  },
  {
    "text": "allows customers to post product reviews many of us here would have left",
    "start": "491560",
    "end": "498120"
  },
  {
    "text": "reviews when you purchase products right and how did you feel when you heard back from the seller when I did I certainly",
    "start": "498120",
    "end": "506159"
  },
  {
    "text": "felt heard and so whether it is a positive review or a negative review hearing back",
    "start": "506159",
    "end": "513640"
  },
  {
    "text": "from the seller creates bonding it earns tress it builds most importantly the",
    "start": "513640",
    "end": "520839"
  },
  {
    "text": "brand loyalty and so our application or the functionality that we are going to",
    "start": "520839",
    "end": "527120"
  },
  {
    "text": "introduce into our online platform is to automatically generate the review",
    "start": "527120",
    "end": "533720"
  },
  {
    "text": "response through generative AI here here is our existing application",
    "start": "533720",
    "end": "541279"
  },
  {
    "text": "it's a classic three tier application as you can see there is a UI customers",
    "start": "541279",
    "end": "547519"
  },
  {
    "text": "browse through product catalog Place orders and they also enter product reviews through that on online platform",
    "start": "547519",
    "end": "555839"
  },
  {
    "text": "and that goes to the backend which manages the order data it not only",
    "start": "555839",
    "end": "561040"
  },
  {
    "text": "serves the ordering UI it also serves other applications including the product",
    "start": "561040",
    "end": "566519"
  },
  {
    "text": "review dashboard and that's used by the customer experience team who goes",
    "start": "566519",
    "end": "571920"
  },
  {
    "text": "through all the product reviews and they create summaries and Trends Etc and we",
    "start": "571920",
    "end": "577640"
  },
  {
    "text": "have a database a monolitic database that contains all the data as you can",
    "start": "577640",
    "end": "583600"
  },
  {
    "text": "see there are a few challenges with the application right we have all seen monolithic application we have all seen",
    "start": "583600",
    "end": "590800"
  },
  {
    "text": "challenges with it with respect to this application there is currently there is no response generated for product review",
    "start": "590800",
    "end": "598720"
  },
  {
    "text": "actually no response from the customer experience team whenever a review is posted and that causes the Shoppers to",
    "start": "598720",
    "end": "605880"
  },
  {
    "text": "wonder what's happening with this platform is it even legitimate and there are multiple applications which uses the",
    "start": "605880",
    "end": "613160"
  },
  {
    "text": "on the back end and that causes some down times you've seen with applications of this kind like when they are used by",
    "start": "613160",
    "end": "619959"
  },
  {
    "text": "multiple different applications you need different kind of scalings and so this causes some some uh",
    "start": "619959",
    "end": "626600"
  },
  {
    "text": "downtimes and this backend is a is a combination of several functionalities",
    "start": "626600",
    "end": "632959"
  },
  {
    "text": "so it's highly coupled so if you want to make a change and you want to go to market it's a little bit difficult and",
    "start": "632959",
    "end": "640160"
  },
  {
    "text": "that's what happening with this application so in order to improve that",
    "start": "640160",
    "end": "645360"
  },
  {
    "text": "brand loyalty we are bringing in a new requirement and that requirement is to",
    "start": "645360",
    "end": "650880"
  },
  {
    "text": "adding or generating a response to the product review as soon as the review is",
    "start": "650880",
    "end": "656920"
  },
  {
    "text": "posted and so if we are generating the response we also have to moderate the",
    "start": "656920",
    "end": "662200"
  },
  {
    "text": "review right because we don't want to show the review in a public platform",
    "start": "662200",
    "end": "667399"
  },
  {
    "text": "without moderating it right that content could be unsafe to be posted so we need to also do a Content moderation and we",
    "start": "667399",
    "end": "675760"
  },
  {
    "text": "don't want to rely entirely on moderation everything on Genera AI",
    "start": "675760",
    "end": "681120"
  },
  {
    "text": "because sometimes Genera VA may not be able to give you the decision that this",
    "start": "681120",
    "end": "686560"
  },
  {
    "text": "content is safe or unsafe and so we want it involves some human decision making as well and above all Number One",
    "start": "686560",
    "end": "694639"
  },
  {
    "text": "requirement is to timely up lades to the Shoppers feedback and so you know if you think",
    "start": "694639",
    "end": "701440"
  },
  {
    "start": "699000",
    "end": "1347000"
  },
  {
    "text": "about it posting a review or getting back the response is naturally asynchronous nobody wants to wait for",
    "start": "701440",
    "end": "707760"
  },
  {
    "text": "the review response to the review come back so we decided to do event driven architectures and an architecture style",
    "start": "707760",
    "end": "715040"
  },
  {
    "text": "that allows you to Build extensible architecture there is a there there are a couple of",
    "start": "715040",
    "end": "721279"
  },
  {
    "text": "ways that you could go build this application one we could have done a big bang approach completely modernize the",
    "start": "721279",
    "end": "728800"
  },
  {
    "text": "entire application but we did not have the budget that's typically a big bang approach it's good it's a good idea but",
    "start": "728800",
    "end": "736199"
  },
  {
    "text": "it's a little bit disruptive and can also be risky so we decided to just take",
    "start": "736199",
    "end": "741920"
  },
  {
    "text": "out that review part of it and add that functionality and",
    "start": "741920",
    "end": "747519"
  },
  {
    "text": "so the Str fig is a fascinating example of how",
    "start": "747519",
    "end": "753839"
  },
  {
    "text": "plants could Thrive or survive in different environments when where birds or animals",
    "start": "753839",
    "end": "760519"
  },
  {
    "text": "eat the figs fruit they drop the seeds onto the branches of the trees and these",
    "start": "760519",
    "end": "766360"
  },
  {
    "text": "seeds grow into big plants they absorb the nutrition they absorb the sunlight",
    "start": "766360",
    "end": "772000"
  },
  {
    "text": "eventually overshadows the host tree and strangle it's a host tree and that strangling s this is what we are going",
    "start": "772000",
    "end": "778760"
  },
  {
    "text": "to build that's a product review response this pattern Strangler F pattern deres the",
    "start": "778760",
    "end": "784519"
  },
  {
    "text": "name from it and it's coined by Martin Fowler and so we decided to apply this",
    "start": "784519",
    "end": "789680"
  },
  {
    "text": "triangular fig pattern and we went back to our diagram again and we put this",
    "start": "789680",
    "end": "797320"
  },
  {
    "text": "together we decided to create a new service we take out some functionality",
    "start": "797320",
    "end": "802800"
  },
  {
    "text": "from the backend process create a new review uh service along with other",
    "start": "802800",
    "end": "808720"
  },
  {
    "text": "components will go into those components we want to have our own database a review database that has all the",
    "start": "808720",
    "end": "815839"
  },
  {
    "text": "everything that related to the review and we also have to create a fan because the ordering UI has to call review",
    "start": "815839",
    "end": "822920"
  },
  {
    "text": "servers and the product review has to call a review service the way that we go for it is create FSR API",
    "start": "822920",
    "end": "830519"
  },
  {
    "text": "Gateway that gives a URL for our dashboard and also the ordering UI to",
    "start": "830519",
    "end": "837480"
  },
  {
    "text": "call and the next thing is because we are",
    "start": "837480",
    "end": "843920"
  },
  {
    "text": "taking away some pieces of the code from the ordering platform we needed to",
    "start": "843920",
    "end": "849720"
  },
  {
    "text": "understand the existing application the host tree and that ex the way one way to",
    "start": "849720",
    "end": "855560"
  },
  {
    "text": "understand existing application is applying domain driven design and so we went back to the drawing board and",
    "start": "855560",
    "end": "862560"
  },
  {
    "text": "looked at all the subdomains and especially in our use case in customers",
    "start": "862560",
    "end": "869120"
  },
  {
    "text": "place an order and they get the order delivered and they get notifications",
    "start": "869120",
    "end": "874199"
  },
  {
    "text": "that we need a feedback for the order then customer goes and enters the product review and product review comes",
    "start": "874199",
    "end": "880920"
  },
  {
    "text": "back to the customer experience team and they create summaries and Trends and the",
    "start": "880920",
    "end": "887480"
  },
  {
    "text": "content marketing team take the summaries and Trends and create new ideas for the product and so these are",
    "start": "887480",
    "end": "893240"
  },
  {
    "text": "the subdomains that were involved and we also understood all the domain events",
    "start": "893240",
    "end": "898440"
  },
  {
    "text": "and everything so in our use case especially generating",
    "start": "898440",
    "end": "903560"
  },
  {
    "text": "a response to the product review that belonged to the customer experience subdomain and so we went ahead and",
    "start": "903560",
    "end": "910000"
  },
  {
    "text": "looked at all the bounded contexts some of them already existed some of them are born new because of the exercise we did",
    "start": "910000",
    "end": "916680"
  },
  {
    "text": "like for example review existed but it was part of the backend application and the review response is completely new",
    "start": "916680",
    "end": "923440"
  },
  {
    "text": "and so we came up with the microservices and also some of the events that were",
    "start": "923440",
    "end": "929160"
  },
  {
    "text": "going through these microservices some of them generated within the bounded context some of them were outside the",
    "start": "929160",
    "end": "934800"
  },
  {
    "text": "bounded context and we used a technique called event storming so if you want to learn more about domain driven design or",
    "start": "934800",
    "end": "942040"
  },
  {
    "text": "event storming there are some so many articles and books available and we are",
    "start": "942040",
    "end": "947079"
  },
  {
    "text": "sharing couple of them towards the end of it and so now going back to our diagram",
    "start": "947079",
    "end": "953720"
  },
  {
    "text": "and you can see that there are a number of services that we have identified a review service that manages a review a",
    "start": "953720",
    "end": "960360"
  },
  {
    "text": "review response service that manages all the response generation process and you",
    "start": "960360",
    "end": "965880"
  },
  {
    "text": "can see that events going in and going out like um across these services so we",
    "start": "965880",
    "end": "971440"
  },
  {
    "text": "need naturally a way to facilitate these events one way to facilitate the events",
    "start": "971440",
    "end": "978639"
  },
  {
    "text": "is to apply some kind of an event router pattern there are many implementations of event router available you at AWS you",
    "start": "978639",
    "end": "986319"
  },
  {
    "text": "can see Amazon SNS a simple notific ation service and Amazon even Bridge as",
    "start": "986319",
    "end": "991759"
  },
  {
    "text": "event routers and we choose Amazon even Bridge Amazon even Bridge is a",
    "start": "991759",
    "end": "997360"
  },
  {
    "text": "serverless event bus service that allows you to decouple a producer and consumer",
    "start": "997360",
    "end": "1004240"
  },
  {
    "text": "through events it's a fully managed service you don't really have to manage",
    "start": "1004240",
    "end": "1009720"
  },
  {
    "text": "the event inje process error handling retries security authorization a lot of",
    "start": "1009720",
    "end": "1016240"
  },
  {
    "text": "those pieces or puzzles and it um fully manages all of that so we use",
    "start": "1016240",
    "end": "1022240"
  },
  {
    "text": "Amazon event rge for it it receives events from AWS Services",
    "start": "1022240",
    "end": "1028600"
  },
  {
    "text": "it can also receive from SAS applications like Salesforce what is most interesting for us is the custom",
    "start": "1028600",
    "end": "1036360"
  },
  {
    "text": "events so our custom application like review service review response",
    "start": "1036360",
    "end": "1042038"
  },
  {
    "text": "generation service can all publish events to event bridge if youve used",
    "start": "1042039",
    "end": "1047199"
  },
  {
    "text": "cues or streams in the past you know there will be consumers of the cues or",
    "start": "1047199",
    "end": "1052440"
  },
  {
    "text": "the streams they consume everything that comes of the cues comes out of the cues and services even if they are not",
    "start": "1052440",
    "end": "1058640"
  },
  {
    "text": "interested in right sometimes you might be interested as a consumer be interested in only 10 percentage of the",
    "start": "1058640",
    "end": "1065120"
  },
  {
    "text": "events in the cues how do you make sure that you only process",
    "start": "1065120",
    "end": "1070240"
  },
  {
    "text": "10% but with even Bridge the consumer can apply some rules and then the",
    "start": "1070240",
    "end": "1076679"
  },
  {
    "text": "consumer can say what events they want to be listening into for example the",
    "start": "1076679",
    "end": "1082320"
  },
  {
    "text": "review response service does not want to listen to All of the events that is generated in the application it wants to",
    "start": "1082320",
    "end": "1089120"
  },
  {
    "text": "listen just to the review posted event and review response service itself generate a lot of the event so it can",
    "start": "1089120",
    "end": "1096120"
  },
  {
    "text": "just put a rule on the event router saying I want to be just listening to",
    "start": "1096120",
    "end": "1102400"
  },
  {
    "text": "event or review created event and then it will receive only that event",
    "start": "1102400",
    "end": "1109640"
  },
  {
    "text": "all right so going back to our drawing board we replace this event router with",
    "start": "1109640",
    "end": "1114919"
  },
  {
    "text": "Amazon event bridge and the next thing we wanted to do is to build out that review response",
    "start": "1114919",
    "end": "1121039"
  },
  {
    "text": "service and if you think about the review response service it's not really simple at first it has to subscribe to",
    "start": "1121039",
    "end": "1128159"
  },
  {
    "text": "the event that's natural the other thing that is involved with the review response Services it has",
    "start": "1128159",
    "end": "1134360"
  },
  {
    "text": "to find out if the data that's coming in is safe enough you have to find the",
    "start": "1134360",
    "end": "1140440"
  },
  {
    "text": "toxicity of it if it's toxic it has to send an even that this message is toxic",
    "start": "1140440",
    "end": "1146880"
  },
  {
    "text": "we don't want to post it in the uh site it also has to find out sentiment of the",
    "start": "1146880",
    "end": "1153799"
  },
  {
    "text": "of the review we want to store that sentiment whether it's a positive sentiment or the negative sentiment in our database we also want to generate a",
    "start": "1153799",
    "end": "1161240"
  },
  {
    "text": "response everything through generative AI we also wanted to verify if the",
    "start": "1161240",
    "end": "1166799"
  },
  {
    "text": "response that is generated by the gener R AI model is meeting some of the",
    "start": "1166799",
    "end": "1172760"
  },
  {
    "text": "expectation you would want to do an evaluation and vaa will talk about how do you how you evaluate and so that",
    "start": "1172760",
    "end": "1179559"
  },
  {
    "text": "requires some human reviewer If the message is found is not able to decide",
    "start": "1179559",
    "end": "1185200"
  },
  {
    "text": "if it's toxic or not or the the response does not meet the expectation we want to",
    "start": "1185200",
    "end": "1191240"
  },
  {
    "text": "involve a human reviewer so this process some some process happen",
    "start": "1191240",
    "end": "1197760"
  },
  {
    "text": "sequentially some process happens in parallel and some of them I have to do",
    "start": "1197760",
    "end": "1203120"
  },
  {
    "text": "retrive for example when I call an API to detect toxicity and that AP that service might",
    "start": "1203120",
    "end": "1210640"
  },
  {
    "text": "have some issues like some networking problem I want to retry when I call a Genera VA model that might throttle and",
    "start": "1210640",
    "end": "1218640"
  },
  {
    "text": "I want to catch that error I want to retry and I want to also involve a human",
    "start": "1218640",
    "end": "1223679"
  },
  {
    "text": "in the loop so all of this if you are going to build to yourself you would be",
    "start": "1223679",
    "end": "1228840"
  },
  {
    "text": "building a mini monolithic application again so we wanted to use a cloud native",
    "start": "1228840",
    "end": "1236200"
  },
  {
    "text": "service AWS step functions how many of you used AWS step",
    "start": "1236200",
    "end": "1241320"
  },
  {
    "text": "functions how many of you use AWS step functions in your generated VA",
    "start": "1241320",
    "end": "1248200"
  },
  {
    "text": "application all right so AWS step functions is a visual",
    "start": "1248679",
    "end": "1253880"
  },
  {
    "text": "workflow service it allows you to build your workflows visually",
    "start": "1253880",
    "end": "1259520"
  },
  {
    "text": "it integrates with over 11,000 plus apas across AWS uh 220 plus AWS",
    "start": "1259520",
    "end": "1266679"
  },
  {
    "text": "Services it allows you to connect to on-premise services through uh cu's it",
    "start": "1266679",
    "end": "1272919"
  },
  {
    "text": "allows you to call third party API if your generative vaa model is not in AWS",
    "start": "1272919",
    "end": "1278520"
  },
  {
    "text": "it's outside AWS and it is hosted in a third party you can still invoke them",
    "start": "1278520",
    "end": "1284520"
  },
  {
    "text": "through step functions directly you can apply authorization connect them to your",
    "start": "1284520",
    "end": "1289600"
  },
  {
    "text": "workflow through the third party API integation what I really like about step functions is the observability it brings",
    "start": "1289600",
    "end": "1296480"
  },
  {
    "text": "in and especially for Genera vaa workflows when you're giving a question",
    "start": "1296480",
    "end": "1302200"
  },
  {
    "text": "you want to know what's happening in order to when it gives you the answer",
    "start": "1302200",
    "end": "1307360"
  },
  {
    "text": "what happening in this workflow how did it come up with that answer with uh step functions you get",
    "start": "1307360",
    "end": "1316400"
  },
  {
    "text": "that explainability you get that interpret ability to your generative Ai workflows and that's something that we",
    "start": "1316400",
    "end": "1322080"
  },
  {
    "text": "really really like about and and V will talk about prom chaining uh later in the",
    "start": "1322080",
    "end": "1328120"
  },
  {
    "text": "session and prom chaining along with this explainability gives you gives you",
    "start": "1328120",
    "end": "1334080"
  },
  {
    "text": "reason why you should be using a step functions all right now going back to",
    "start": "1334080",
    "end": "1339279"
  },
  {
    "text": "our diagram and so we replace that review response service with AWS",
    "start": "1339279",
    "end": "1344600"
  },
  {
    "text": "functions now our next part is build out that workflow in which will talk about building that workflow all right um so",
    "start": "1344600",
    "end": "1352919"
  },
  {
    "start": "1347000",
    "end": "2036000"
  },
  {
    "text": "let's go back to the example right um so we want to build this new capability um and here is the prompt um",
    "start": "1352919",
    "end": "1362600"
  },
  {
    "text": "that we want to send to our llm um so first in this given review we want to",
    "start": "1362600",
    "end": "1368640"
  },
  {
    "text": "find the toxicity and if the review is not toxic um find the sentiment of the",
    "start": "1368640",
    "end": "1375279"
  },
  {
    "text": "review and if the sentiment is positive use a particular template uh to generate a response or if it's negative use a",
    "start": "1375279",
    "end": "1382080"
  },
  {
    "text": "different template and so on so this is a big prompt that we want to send it to the llm um so that it can do all of the",
    "start": "1382080",
    "end": "1390360"
  },
  {
    "text": "these things for us but if you actually think about it depending on what llm you",
    "start": "1390360",
    "end": "1396520"
  },
  {
    "text": "choose um you know some llms are known to drop tasks if it's a fairly huge",
    "start": "1396520",
    "end": "1401760"
  },
  {
    "text": "prompt as your prompt grow the accuracy of the response that the llms generate",
    "start": "1401760",
    "end": "1407279"
  },
  {
    "text": "could not be up to the maret Mark where you need it so you can actually if you look at the The Prompt that we have you",
    "start": "1407279",
    "end": "1414120"
  },
  {
    "text": "can actually break it down into multiple subtasks so here if we break it down we",
    "start": "1414120",
    "end": "1419600"
  },
  {
    "text": "first want to find the toxicity and if we find that the toxicity of the review that our customer",
    "start": "1419600",
    "end": "1426039"
  },
  {
    "text": "has left um is high meaning it's very toxic we want to probably notify",
    "start": "1426039",
    "end": "1432679"
  },
  {
    "text": "somebody um so that the review can be taken down from our website immediately",
    "start": "1432679",
    "end": "1437960"
  },
  {
    "text": "right um and then uh after that if you find it that it's not toxic it's a genuine",
    "start": "1437960",
    "end": "1443840"
  },
  {
    "text": "review a genuine product review um then we want to the next step is to find a",
    "start": "1443840",
    "end": "1449799"
  },
  {
    "text": "sentiment and we want to find out if the customer is happy with our product not",
    "start": "1449799",
    "end": "1455520"
  },
  {
    "text": "happy with our product and so on um and the reason we want to find a sentiment as a separate task here is",
    "start": "1455520",
    "end": "1463240"
  },
  {
    "text": "maybe we want to write the sentiment back to a database so that we can further do an analysis on all of the",
    "start": "1463240",
    "end": "1470320"
  },
  {
    "text": "sentiments that we get from the product review and figure out how our Market is doing in the uh how our product is doing",
    "start": "1470320",
    "end": "1477360"
  },
  {
    "text": "in the market right and then the next task is to finally uh ask the llm to",
    "start": "1477360",
    "end": "1483080"
  },
  {
    "text": "generate a response to the product review um and then after the llm",
    "start": "1483080",
    "end": "1488799"
  },
  {
    "text": "generates a response we want to validate the response right the we want to",
    "start": "1488799",
    "end": "1494240"
  },
  {
    "text": "validate against some criteria maybe the criteria could be is the llm um you know",
    "start": "1494240",
    "end": "1500919"
  },
  {
    "text": "addressing the customer by the customer's name in the response is the llm providing our phone number so that",
    "start": "1500919",
    "end": "1508600"
  },
  {
    "text": "the customer can reach out to our customer support um for further um you",
    "start": "1508600",
    "end": "1514600"
  },
  {
    "text": "know help uh for the product uh for the customer and so on and then also detect",
    "start": "1514600",
    "end": "1520600"
  },
  {
    "text": "if the response itself from the llm the the review response is also toxic um and",
    "start": "1520600",
    "end": "1526720"
  },
  {
    "text": "if you find that any of these valid ation criteria is not met we want to involve actually a human to decide if we",
    "start": "1526720",
    "end": "1533600"
  },
  {
    "text": "can post that response or not right so this this process of taking these big",
    "start": "1533600",
    "end": "1541440"
  },
  {
    "text": "large prompt that we were initially going to send to the llm and breaking them down into logical flow of smaller",
    "start": "1541440",
    "end": "1548679"
  },
  {
    "text": "tasks or smaller prompts all linked together by a an orchestration layer is",
    "start": "1548679",
    "end": "1553720"
  },
  {
    "text": "called prompt decomposition right and and again for the orchestration layer we know we want",
    "start": "1553720",
    "end": "1560440"
  },
  {
    "text": "to pick step functions because it provides us the observability we write less code of course you can do all of",
    "start": "1560440",
    "end": "1566399"
  },
  {
    "text": "this breaking down the tasks and everything in your code itself but again",
    "start": "1566399",
    "end": "1571480"
  },
  {
    "text": "you're building a monolithic application when you do it in your code and we all know the disadvantages of Monolithic",
    "start": "1571480",
    "end": "1577919"
  },
  {
    "text": "application so we want to break it down using step functions",
    "start": "1577919",
    "end": "1583000"
  },
  {
    "text": "workflow so in addition you know PR you know I told you prompt decomposition because L why do we want to decompose",
    "start": "1583000",
    "end": "1589200"
  },
  {
    "text": "prompts because llms are you know are known to drop tasks if the prompt gets too big but",
    "start": "1589200",
    "end": "1596120"
  },
  {
    "text": "there are also several other advantages of decomposing The Prompt so as you build your gen capability when you go",
    "start": "1596120",
    "end": "1603520"
  },
  {
    "text": "start from po all the way to production you know your prompts can start growing",
    "start": "1603520",
    "end": "1609440"
  },
  {
    "text": "in the size and I've seen customers um you know when they go from POC to",
    "start": "1609440",
    "end": "1614799"
  },
  {
    "text": "production the prompts start becoming bigger and bigger as they test more edge",
    "start": "1614799",
    "end": "1620440"
  },
  {
    "text": "cases or you know as they go from POC to production the scope can increase the",
    "start": "1620440",
    "end": "1626000"
  },
  {
    "text": "scope of the project itself can increase they'll start adding more capabilities into it and so your prompt will start",
    "start": "1626000",
    "end": "1632120"
  },
  {
    "text": "growing bigger and bigger and bigger just like how your monolithic",
    "start": "1632120",
    "end": "1637600"
  },
  {
    "text": "code can start growing bigger prompts also as they grow bigger has some",
    "start": "1637600",
    "end": "1644000"
  },
  {
    "text": "disadvantages right you know each change as your prompt go grow could potentially",
    "start": "1644000",
    "end": "1649799"
  },
  {
    "text": "impact other parts of the prompt each change that you make as in when you test",
    "start": "1649799",
    "end": "1655440"
  },
  {
    "text": "the prompts against your test cases you know each change you want to say hey I want to tweak this prompt over here and",
    "start": "1655440",
    "end": "1661760"
  },
  {
    "text": "that change could potentially impact the rest of the prompt and you have to again test the entire prompt against all of",
    "start": "1661760",
    "end": "1667320"
  },
  {
    "text": "the test cases and as your prompt also grows there'll be dead zones depending on the input that you're getting from",
    "start": "1667320",
    "end": "1673240"
  },
  {
    "text": "the user some parts of the prompt will never be used because it just doesn't",
    "start": "1673240",
    "end": "1678960"
  },
  {
    "text": "makes sense to use that part of the prompt and especially when you have a large prompt most of the part of the",
    "start": "1678960",
    "end": "1684840"
  },
  {
    "text": "prompt is not used for certain inputs and also longer the longer the",
    "start": "1684840",
    "end": "1691039"
  },
  {
    "text": "prompts get it is harder for the llms to process it make sense of it and provide",
    "start": "1691039",
    "end": "1696279"
  },
  {
    "text": "outputs um for the llms and longer proms are slower because llm has to process",
    "start": "1696279",
    "end": "1702559"
  },
  {
    "text": "the entire prompt to produce a response so to do that you will need to have bigger llm",
    "start": "1702559",
    "end": "1709159"
  },
  {
    "text": "and this is also expensive most llm providers most foundational model providers charge you based on how many",
    "start": "1709159",
    "end": "1716200"
  },
  {
    "text": "input tokens you send into the model and how many output tokens it generates so as you have bigger promps your send and",
    "start": "1716200",
    "end": "1724559"
  },
  {
    "text": "you have dead zones in the prompt you're using the entire context space and uh you know it get it can get expensive as",
    "start": "1724559",
    "end": "1730880"
  },
  {
    "text": "your input tokens increase so here's an actual example where we actually ran a huge promp",
    "start": "1730880",
    "end": "1738120"
  },
  {
    "text": "prompt um a 30k token prompt um against a bigger llm because we we needed a",
    "start": "1738120",
    "end": "1744960"
  },
  {
    "text": "bigger llm for it to understand the big prompt and one call took 45 seconds for",
    "start": "1744960",
    "end": "1751600"
  },
  {
    "text": "the llm to start responding on the other hand when we broke it down to smaller",
    "start": "1751600",
    "end": "1757240"
  },
  {
    "text": "tasks so we had smaller prompts we could do those smaller tasks",
    "start": "1757240",
    "end": "1762279"
  },
  {
    "text": "in parallel so in parallel each one it took 30 uh I mean sorry 3 seconds and we",
    "start": "1762279",
    "end": "1768640"
  },
  {
    "text": "could also use a smaller llm because of the smaller prompt and then we aggregated the",
    "start": "1768640",
    "end": "1775000"
  },
  {
    "text": "results to produce the final result with another call and together when you see although we took four calls four API",
    "start": "1775000",
    "end": "1782159"
  },
  {
    "text": "calls to the llm it only took 7 Seconds to to uh produce the results and we",
    "start": "1782159",
    "end": "1789240"
  },
  {
    "text": "could also use smaller llms which was 85% cheaper than the initial big prompt",
    "start": "1789240",
    "end": "1795600"
  },
  {
    "text": "so that's the power of decomposing your prompt PRS um and running them with an",
    "start": "1795600",
    "end": "1800640"
  },
  {
    "text": "orchestration layer so going back to our example um so",
    "start": "1800640",
    "end": "1806519"
  },
  {
    "text": "in our example we want to First detect the toxicity um and because we broke down the promps we can also use different",
    "start": "1806519",
    "end": "1813480"
  },
  {
    "text": "llms for different tasks we can use purpose-built llms so here to detect the",
    "start": "1813480",
    "end": "1819240"
  },
  {
    "text": "toxicity we using a model within Amazon comprehend service um to detect the",
    "start": "1819240",
    "end": "1825039"
  },
  {
    "text": "toxicity and it has a direct API and it'll give us a score right and once we do that we want to",
    "start": "1825039",
    "end": "1832159"
  },
  {
    "text": "check the score and check the toxicity and all of that next thing we want to do is find a sentiment and to find the",
    "start": "1832159",
    "end": "1839399"
  },
  {
    "text": "sentiment it's just a classifying task classify this review into positive or negative or neutral sentiment and to do",
    "start": "1839399",
    "end": "1846399"
  },
  {
    "text": "that we um used a um Bedrock uh in an nlm in Amazon Bedrock which is anthropic",
    "start": "1846399",
    "end": "1853640"
  },
  {
    "text": "CLA 2 um we use that llm uh because it was just a classif ing task um and",
    "start": "1853640",
    "end": "1859600"
  },
  {
    "text": "anthropic claw to did a good job for us and finally to generate the response",
    "start": "1859600",
    "end": "1866480"
  },
  {
    "text": "um we used another large language model with an Amazon Bedrock which is uh",
    "start": "1866480",
    "end": "1871559"
  },
  {
    "text": "anthropic Claud 3 Haiku um because we wanted the llm to be more safer U we",
    "start": "1871559",
    "end": "1878279"
  },
  {
    "text": "found that the latest theories of Amazon uh you know anthropic Cloud models were",
    "start": "1878279",
    "end": "1883880"
  },
  {
    "text": "U relatively safer outputs so we used that so and if if you see in my prompt",
    "start": "1883880",
    "end": "1889039"
  },
  {
    "text": "here to generate the response I'm actually using uh what is called a Persona pattern um in in the prompt so",
    "start": "1889039",
    "end": "1898639"
  },
  {
    "text": "uh we're telling you're a humble product review responder we giving the llm a",
    "start": "1898639",
    "end": "1904000"
  },
  {
    "text": "Persona and then you're going to write a response to a product review left by the customer and we giving it the product",
    "start": "1904000",
    "end": "1911720"
  },
  {
    "text": "review and then we're also asking the llm to recheck the sentiment so that we",
    "start": "1911720",
    "end": "1917600"
  },
  {
    "text": "want want it to be more accurate right you had earlier classified the review to be uh this sentiment recheck your",
    "start": "1917600",
    "end": "1924880"
  },
  {
    "text": "earlier sentiment classification then I Write a response based on the",
    "start": "1924880",
    "end": "1929919"
  },
  {
    "text": "sentiment and so finally when we get the response back um we will then look at",
    "start": "1929919",
    "end": "1935240"
  },
  {
    "text": "how we can do human uh in the loop but before that you know um I mentioned Amazon Bedrock the models in Amazon",
    "start": "1935240",
    "end": "1941679"
  },
  {
    "text": "Bedrock so a quick note on Amazon Bedrock Amazon Bedrock is again a serverless service um which was launched",
    "start": "1941679",
    "end": "1949240"
  },
  {
    "text": "last year um it is the easiest way to build and scale geni applications with",
    "start": "1949240",
    "end": "1955000"
  },
  {
    "text": "Foundation models with an AWS and with bedrock you have a choice",
    "start": "1955000",
    "end": "1960360"
  },
  {
    "text": "of using different Foundation models um and you can use all of these Foundation",
    "start": "1960360",
    "end": "1966159"
  },
  {
    "text": "models through one single API so the Bedrock API through that one single API",
    "start": "1966159",
    "end": "1971519"
  },
  {
    "text": "you can choose any of the foundation model um for your job and you don't have have to host the",
    "start": "1971519",
    "end": "1978360"
  },
  {
    "text": "models yourself the models are hosted for you and you're charged only by the number of input tokens you send and the",
    "start": "1978360",
    "end": "1984440"
  },
  {
    "text": "output tokens the models generate you can easily customize the models to your own domain if you want to do fine-tuning",
    "start": "1984440",
    "end": "1991240"
  },
  {
    "text": "you can do that as well through bedrock uh you can build retrieval augmented generation applications",
    "start": "1991240",
    "end": "1997440"
  },
  {
    "text": "meaning if you want the generative AI application to be able to access your data and answer questions based on your",
    "start": "1997440",
    "end": "2004679"
  },
  {
    "text": "organization's data you can easily build that you can also build um workflows",
    "start": "2004679",
    "end": "2009960"
  },
  {
    "text": "using uh agents um wherein the foundation models take actions um",
    "start": "2009960",
    "end": "2015440"
  },
  {
    "text": "meaning calling your apis for example and all of this can be done through the",
    "start": "2015440",
    "end": "2020960"
  },
  {
    "text": "Bedrock apis while remaining completely secure your data is completely secure your data",
    "start": "2020960",
    "end": "2026960"
  },
  {
    "text": "is not used to train the models and uh your data is completely under your",
    "start": "2026960",
    "end": "2033919"
  },
  {
    "text": "access so AI can create content it can summarize",
    "start": "2034600",
    "end": "2040840"
  },
  {
    "start": "2036000",
    "end": "2213000"
  },
  {
    "text": "beautifully on huge documents it can give you more concise digestable",
    "start": "2040840",
    "end": "2046639"
  },
  {
    "text": "information but when it comes to Safety and Security of the generated",
    "start": "2046639",
    "end": "2053000"
  },
  {
    "text": "information and that and that is crucial human decision making plays a vital",
    "start": "2053000",
    "end": "2060280"
  },
  {
    "text": "role and so in our use case as vaa mentioned we needed to involve human",
    "start": "2060280",
    "end": "2067118"
  },
  {
    "text": "decision making in two different places one when the Amazon comprehend API is",
    "start": "2067119",
    "end": "2075240"
  },
  {
    "text": "not able to find whether this is information is toxic or not toxic what I",
    "start": "2075240",
    "end": "2080280"
  },
  {
    "text": "really like about that API it gives me a toxicity score and I can decide based on",
    "start": "2080280",
    "end": "2085520"
  },
  {
    "text": "the toxicity score whether this text is toxic or not when it gives me a score",
    "start": "2085520",
    "end": "2091480"
  },
  {
    "text": "between certain limits and I know that okay so this is not it's not able to detect it I can involve a human decision",
    "start": "2091480",
    "end": "2098599"
  },
  {
    "text": "making I also involve a human decision making process when the uh in the where",
    "start": "2098599",
    "end": "2104520"
  },
  {
    "text": "the output generated by the llm does not um does not meet the expectations that",
    "start": "2104520",
    "end": "2111920"
  },
  {
    "text": "we have we know that including a human in the loop process is going to improve",
    "start": "2111920",
    "end": "2119240"
  },
  {
    "text": "increase the latency the end to end latency to post a response back but improves the confidence and accuracy the",
    "start": "2119240",
    "end": "2126760"
  },
  {
    "text": "way we implemented the human decision making process with step functions",
    "start": "2126760",
    "end": "2132560"
  },
  {
    "text": "workflow is using a pattern called wait for callback pattern so when you use",
    "start": "2132560",
    "end": "2137800"
  },
  {
    "text": "wait for call back pattern the task that you integrate with WIS out a token and",
    "start": "2137800",
    "end": "2144480"
  },
  {
    "text": "that token is sent to that external service and your task will go to a",
    "start": "2144480",
    "end": "2149560"
  },
  {
    "text": "weight State until that token comes back and it can wait for like week it can",
    "start": "2149560",
    "end": "2155760"
  },
  {
    "text": "wait for month it can even wait for for a year and so in our example we send",
    "start": "2155760",
    "end": "2161560"
  },
  {
    "text": "that token the wait for call back token to an external service here we send it",
    "start": "2161560",
    "end": "2168520"
  },
  {
    "text": "we send an email to the human reviewer and the human reviewer gets an email",
    "start": "2168520",
    "end": "2174079"
  },
  {
    "text": "they get the review text they also get the toxicity score and then they can decide whether to flag it as toxic or",
    "start": "2174079",
    "end": "2181079"
  },
  {
    "text": "not and then when they say it's Flag when they flag it we send the token back",
    "start": "2181079",
    "end": "2186359"
  },
  {
    "text": "to the step functions work flow and that workflow resumes and based on what they decided we'll make a decision whether to",
    "start": "2186359",
    "end": "2193800"
  },
  {
    "text": "move to create the sentiment and generate the response or to send toxic",
    "start": "2193800",
    "end": "2199200"
  },
  {
    "text": "information found event and so with the wait for call back token um pattern you can involve human",
    "start": "2199200",
    "end": "2206920"
  },
  {
    "text": "decision making you can also include a legacy applications with your workflows and so we don't have the",
    "start": "2206920",
    "end": "2214000"
  },
  {
    "start": "2213000",
    "end": "2522000"
  },
  {
    "text": "entire application as the demo but we have at least the review response generation as a demo we wanted to show",
    "start": "2214000",
    "end": "2220359"
  },
  {
    "text": "you in action so this is a step functions console and you see that St",
    "start": "2220359",
    "end": "2225839"
  },
  {
    "text": "functions product review response automation um is our workflow now I click on the workflow you can see that",
    "start": "2225839",
    "end": "2234200"
  },
  {
    "text": "you know when I edit it it shows that workflow studio and I told you before that workflow uh Studio offers you to",
    "start": "2234200",
    "end": "2241680"
  },
  {
    "text": "build visual workflow so I can you know zoom in and see all the task in there I",
    "start": "2241680",
    "end": "2247400"
  },
  {
    "text": "can can drag and drop and create uh everything so the first step here is a detecting toxicity and based on that",
    "start": "2247400",
    "end": "2253640"
  },
  {
    "text": "toxicity score we decide to create the generate the response if the toxicity",
    "start": "2253640",
    "end": "2259200"
  },
  {
    "text": "score is high we'll just send this is a harmful text if it's not not able to",
    "start": "2259200",
    "end": "2265920"
  },
  {
    "text": "decide we involve a human uh decision making in that um in the product review",
    "start": "2265920",
    "end": "2272040"
  },
  {
    "text": "and so now so what happens is and I've already um executed this work flow um",
    "start": "2272040",
    "end": "2278200"
  },
  {
    "text": "before so I'm going to show you couple of um executions and so then now I went back",
    "start": "2278200",
    "end": "2285119"
  },
  {
    "text": "and I'm looking at uh one of those executions I can look at what ex input I sent I sent a harmful content as an",
    "start": "2285119",
    "end": "2293720"
  },
  {
    "text": "input and as I expected it detected that there is toxicity in the um in the text",
    "start": "2293720",
    "end": "2300720"
  },
  {
    "text": "and it promptly send that event out and another one I sent something this is",
    "start": "2300720",
    "end": "2305800"
  },
  {
    "text": "also kind of toxic but but it's a little bit it's not able to decide whether it's",
    "start": "2305800",
    "end": "2310839"
  },
  {
    "text": "toxic or not so what happened was it gave me a score that was like point4 or",
    "start": "2310839",
    "end": "2317240"
  },
  {
    "text": "something that you know was um between the limit that I had and we went sent to",
    "start": "2317240",
    "end": "2322560"
  },
  {
    "text": "a human and then you see that task token that's the wait for call back token I was talking about so in this place you",
    "start": "2322560",
    "end": "2330599"
  },
  {
    "text": "know I use the wait for call back token it sends a token out it sent an email",
    "start": "2330599",
    "end": "2335839"
  },
  {
    "text": "with all the links and then you know I just had to click on the link as a reviewer I said like just go ahead and",
    "start": "2335839",
    "end": "2342960"
  },
  {
    "text": "approve it and it just approved um the information approved the um workflow and",
    "start": "2342960",
    "end": "2350760"
  },
  {
    "text": "then after it evaluated uh in fact I think I clicked on reject it again send",
    "start": "2350760",
    "end": "2356359"
  },
  {
    "text": "the harmful uh content detected event and so that ends our",
    "start": "2356359",
    "end": "2362880"
  },
  {
    "text": "demo and now I wanted to summarize on what we",
    "start": "2362880",
    "end": "2367920"
  },
  {
    "text": "spoke in the session",
    "start": "2367920",
    "end": "2373720"
  },
  {
    "text": "um in the first thing when you build generative a with even driven",
    "start": "2375599",
    "end": "2382079"
  },
  {
    "text": "architectures like this is it gives you that extensibility and in our application we use a step functions",
    "start": "2382079",
    "end": "2390079"
  },
  {
    "text": "workflow to invoke a Genera VA model you can use AWS Lambda or you can use another compute to call a generated VA",
    "start": "2390079",
    "end": "2397119"
  },
  {
    "text": "model model by abstracting the way that you call a generative VA model you gain",
    "start": "2397119",
    "end": "2403760"
  },
  {
    "text": "the ability to switch to newer models like models come up like mushrooms right",
    "start": "2403760",
    "end": "2410800"
  },
  {
    "text": "you you you know as the new models come up and you find them like sophisticated",
    "start": "2410800",
    "end": "2416680"
  },
  {
    "text": "meet your requirements you want to use those models and so when you use this",
    "start": "2416680",
    "end": "2422079"
  },
  {
    "text": "abstraction you can easily drop in a new model and as when you use workflows like",
    "start": "2422079",
    "end": "2427960"
  },
  {
    "text": "step function and gives you visibility into what is happening you don't want your application to be a blackbox you",
    "start": "2427960",
    "end": "2434280"
  },
  {
    "text": "don't want to send a question and get an answer don't know what happened inside so when you use step functions when you",
    "start": "2434280",
    "end": "2440040"
  },
  {
    "text": "use like prom chaining with step functions workflow it gives you complete visibility into what is happening when",
    "start": "2440040",
    "end": "2446400"
  },
  {
    "text": "you use cues for example generative a models have a limited context window and",
    "start": "2446400",
    "end": "2452520"
  },
  {
    "text": "they also have limited request per second and so when you use cues between between your generative a model and your",
    "start": "2452520",
    "end": "2459839"
  },
  {
    "text": "compute you gain the ability to scale you know the services differently um so that and and then when",
    "start": "2459839",
    "end": "2467640"
  },
  {
    "text": "you use like um event routers like event Bridge or like streams you can build",
    "start": "2467640",
    "end": "2474280"
  },
  {
    "text": "evolutionary architecture an architecture that is extensible as you explore the space as",
    "start": "2474280",
    "end": "2481960"
  },
  {
    "text": "you find new and emerging use cases and also when you solidify your requirement",
    "start": "2481960",
    "end": "2487359"
  },
  {
    "text": "in the governance phas or auditing or reporting in generative AA landscape",
    "start": "2487359",
    "end": "2493760"
  },
  {
    "text": "you're going to come up with new use cases and you don't want to re architect the entire application every time you",
    "start": "2493760",
    "end": "2500839"
  },
  {
    "text": "when you build evolutionary architecture with event driven architectures you can",
    "start": "2500839",
    "end": "2506040"
  },
  {
    "text": "easily create these smaller applications and plug in to existing applications",
    "start": "2506040",
    "end": "2511640"
  },
  {
    "text": "through events and above all you know when you use event driven architectures",
    "start": "2511640",
    "end": "2516920"
  },
  {
    "text": "with serverless it gives you FastTrack development with that I wanted to share",
    "start": "2516920",
    "end": "2523319"
  },
  {
    "start": "2522000",
    "end": "2547000"
  },
  {
    "text": "you some resources and this page is going to take you to another page that's",
    "start": "2523319",
    "end": "2528800"
  },
  {
    "text": "going to have a list of resources I have a book on domain driven design event",
    "start": "2528800",
    "end": "2535000"
  },
  {
    "text": "storming and also the the sample of the demo that I showed you is all in that",
    "start": "2535000",
    "end": "2541680"
  },
  {
    "text": "resources page thank you so much for your time and",
    "start": "2541680",
    "end": "2547760"
  },
  {
    "start": "2547000",
    "end": "2572000"
  },
  {
    "text": "we really appreciate you um being here we hope you found the session helpful so",
    "start": "2547760",
    "end": "2553960"
  },
  {
    "text": "don't forget to V for the session in the goto Guide app",
    "start": "2553960",
    "end": "2559359"
  }
]
[
  {
    "text": "okay so Mike is on yeah thank you for the wonderful introduction",
    "start": "8300",
    "end": "13740"
  },
  {
    "text": "um so I want to thank you all uh for uh coming here to this session you know",
    "start": "13740",
    "end": "18960"
  },
  {
    "text": "um as you might imagine uh or as you may have guessed you know I'm not from Australia I'm not australia-based I came",
    "start": "18960",
    "end": "24300"
  },
  {
    "text": "here from Croatia Europe uh and as you probably may I guess it's like a pretty long trip uh here it took me like",
    "start": "24300",
    "end": "30720"
  },
  {
    "text": "something like 24 hours in total maybe a little bit more uh and still somehow it feels like it took me much longer to get",
    "start": "30720",
    "end": "36480"
  },
  {
    "text": "like from the main conference hallway to this room you know and so I want to thank you all for coming down under here",
    "start": "36480",
    "end": "42719"
  },
  {
    "text": "to the Blue Room you know uh to talk on concurrency and uh uh as a thank you",
    "start": "42719",
    "end": "48420"
  },
  {
    "text": "gift you know I'm going to give you a lot of information you know I prepared a lot of stuff for you so I'm gonna speak",
    "start": "48420",
    "end": "53460"
  },
  {
    "text": "very fast and I apologize about that but I hope you know like this is done because I'm hoping that I'm going to",
    "start": "53460",
    "end": "59219"
  },
  {
    "text": "give you more value you know uh for uh for your time so concurrency is the main character of this session of this stock",
    "start": "59219",
    "end": "66420"
  },
  {
    "text": "and this is a topic which is I would say like pretty painful traumatic in software development you know as",
    "start": "66420",
    "end": "72720"
  },
  {
    "text": "Engineers we have developed like this large uh Collective I would even say",
    "start": "72720",
    "end": "77880"
  },
  {
    "text": "rational fear of concurrency and you're going to hear many developers saying that like you know concurrency is difficult it's hard especially more",
    "start": "77880",
    "end": "84479"
  },
  {
    "text": "experienced ones and they're gonna you know they're gonna caution you against using it they're going to tell you that",
    "start": "84479",
    "end": "89640"
  },
  {
    "text": "like hereby dragons don't go down that path they're going to tell you the stories about race conditions and they're going to tell the stories about",
    "start": "89640",
    "end": "95159"
  },
  {
    "text": "Deadlocks and whatnot you know and talk about their own painful experiences and this is all rooted in Practical",
    "start": "95159",
    "end": "101340"
  },
  {
    "text": "experiences of many many many people you know so this is real real advice but still you know with this talk I want to",
    "start": "101340",
    "end": "107280"
  },
  {
    "text": "propose a somewhat different Theory I want to seek a somewhat different truth if you will that you know perhaps the",
    "start": "107280",
    "end": "112619"
  },
  {
    "text": "problem is not in concurrence itself but that like the concurrence is not really as difficult or nearly as difficult as",
    "start": "112619",
    "end": "119460"
  },
  {
    "text": "we can be led to Believers we can be conditioned into thinking but rather that the tools that we are typically given to work with it are pretty basic",
    "start": "119460",
    "end": "125880"
  },
  {
    "text": "pretty Elementary you know they don't really rise up to the challenge and as a result of that our job of working with",
    "start": "125880",
    "end": "131700"
  },
  {
    "text": "concurrency becomes way more difficult than it could or should be you know and so in my experience like if we actually",
    "start": "131700",
    "end": "137760"
  },
  {
    "text": "have a good tool in our hand the ones like that has been designed and built for this job uh then you know this",
    "start": "137760",
    "end": "144180"
  },
  {
    "text": "challenge of managing currency becomes fairly straightforward mundane I think if you will it becomes something you can",
    "start": "144180",
    "end": "150239"
  },
  {
    "text": "do and still keep your sanity in the process it can become something that you can like use extensively and still be",
    "start": "150239",
    "end": "156540"
  },
  {
    "text": "able to reason about the correctness and the behavior of your programs and it can even become a job that you can enjoy uh",
    "start": "156540",
    "end": "163080"
  },
  {
    "text": "perhaps most importantly uh like when you have a good tool then your fear from concurrency will uh diminish or",
    "start": "163080",
    "end": "169620"
  },
  {
    "text": "completely Fade Out and as a result you're going to see a lot of potential for concurrency in the places you haven't seen before you do not have to",
    "start": "169620",
    "end": "175920"
  },
  {
    "text": "be like this tall or that wide to have the need for concurrency or to profit from it and this is perhaps the most",
    "start": "175920",
    "end": "181080"
  },
  {
    "text": "important point on trying to drive with the stock so for me this tool has been the thing which is called beam which is",
    "start": "181080",
    "end": "188040"
  },
  {
    "text": "the erlang virtual machine and this is the runtime home to programs written in languages such as erlang Elixir gleam",
    "start": "188040",
    "end": "194940"
  },
  {
    "text": "and others and this thing has been built since its Inception like more than 30 years ago with a strong focus on massive",
    "start": "194940",
    "end": "202680"
  },
  {
    "text": "lightweight concurrency done insane in an approachable way this is the challenge it has been solving in",
    "start": "202680",
    "end": "207840"
  },
  {
    "text": "production in large companies as you have heard in announcement uh you know for uh like three decades so it's like",
    "start": "207840",
    "end": "214260"
  },
  {
    "text": "pretty mature battle tested stable technology but make no mistake it's also quite usable and applicable in simpler",
    "start": "214260",
    "end": "221220"
  },
  {
    "text": "smaller situations you do not again you don't have to be like super super scalable or operating on a large scale",
    "start": "221220",
    "end": "226680"
  },
  {
    "text": "to have the use of it and so what I'm going to do today today's agenda is I'm",
    "start": "226680",
    "end": "231840"
  },
  {
    "text": "going to give you a quick intro to beam style concurrency and then the main course is going to be a set of",
    "start": "231840",
    "end": "237299"
  },
  {
    "text": "explorations of uh beam concurrency in practice so we're going to take a look at a couple of examples uh taken from",
    "start": "237299",
    "end": "244080"
  },
  {
    "text": "the real life projects that I've had the pleasure of working on and these examples are going to fall like on the simpler side of things or in the lower",
    "start": "244080",
    "end": "250860"
  },
  {
    "text": "scale side of things with the intention of showing you that even in such situations there's a lot of room for concurrency that it can be done in the",
    "start": "250860",
    "end": "257100"
  },
  {
    "text": "same way and that we can profit from being concurrent so buckle up a lot of stuff ahead of us and let's kick off",
    "start": "257100",
    "end": "263639"
  },
  {
    "text": "with a basic intro to being concurrency in five slides so the central idea here",
    "start": "263639",
    "end": "268979"
  },
  {
    "text": "is a thing which is called process and the process here means a beam level concept it's not an always process it's",
    "start": "268979",
    "end": "275340"
  },
  {
    "text": "not a noise thread I'm going to clarify this uh like in a couple of slides essentially process is a sequential",
    "start": "275340",
    "end": "280680"
  },
  {
    "text": "program you know just a bunch of instructions or Expressions executed one by one and at runtime level like you know when",
    "start": "280680",
    "end": "288120"
  },
  {
    "text": "you use Sunbeam language every piece of code runs inside some process and from within a single process you can start or",
    "start": "288120",
    "end": "294660"
  },
  {
    "text": "spawn additional processes right so here we have like a sketch of one sequential program we invoke some standard Library",
    "start": "294660",
    "end": "301080"
  },
  {
    "text": "function we spawn another sequential program pass it a function which is going to run independently in that other process and that's it two nodes that I",
    "start": "301080",
    "end": "308520"
  },
  {
    "text": "want to say here so this code sketch and all the code sketches are going to be done in Elixir but doesn't really matter",
    "start": "308520",
    "end": "314220"
  },
  {
    "text": "it could be any other beam language such as erlang I'm talking about runtime level properties here note number two",
    "start": "314220",
    "end": "320580"
  },
  {
    "text": "I'm going to stick to the lowest level Primitives such as spawn we rarely use those things in production directly we",
    "start": "320580",
    "end": "326820"
  },
  {
    "text": "use some higher level abstractions that make like the whole code look a little bit more declarative and take care of some special cases for us you know but",
    "start": "326820",
    "end": "333419"
  },
  {
    "text": "again I'm trying to drive like the fundamental principles here and so I'm sticking to the lowest level abstractions",
    "start": "333419",
    "end": "338940"
  },
  {
    "text": "okay so we have spawned one process and as a result of spawning of invoking this one function you're going to get a thing",
    "start": "338940",
    "end": "345660"
  },
  {
    "text": "called PID or process ID and this is a piece of data which somehow uniquely identifies the process inside your",
    "start": "345660",
    "end": "351720"
  },
  {
    "text": "system and once you have the PID you can interact with the process you can send it messages this is also known as",
    "start": "351720",
    "end": "357539"
  },
  {
    "text": "message passing concurrency so these processes they are logically speaking independent programs they share no",
    "start": "357539",
    "end": "362820"
  },
  {
    "text": "memory we don't use like shared memory unlocks and whatnot you know so they're like completely isolated from each other",
    "start": "362820",
    "end": "369360"
  },
  {
    "text": "and uh the only way they can cooperate coordinate is by sending themselves messages so to send a message you need a PID of",
    "start": "369360",
    "end": "376620"
  },
  {
    "text": "the target process and the message is an arbitrary piece of data you know whatever term you can construct you",
    "start": "376620",
    "end": "382020"
  },
  {
    "text": "invoke the function send and uh as a result the message content is placed",
    "start": "382020",
    "end": "387419"
  },
  {
    "text": "into the mailbox of the receiver process so each process is at random level associated with the mailbox which is a",
    "start": "387419",
    "end": "392940"
  },
  {
    "text": "50q so the message goes to the end of that queue and uh then immediately you",
    "start": "392940",
    "end": "398039"
  },
  {
    "text": "move on so the send doesn't really wait for anything else uh you move on to the next instruction on the receiver side",
    "start": "398039",
    "end": "403979"
  },
  {
    "text": "you can use this receiver expression to pull one message from your queue or to wait for it if it's not there and that's",
    "start": "403979",
    "end": "410759"
  },
  {
    "text": "it that's that's your uh those are your Primitives for implementing cooperating processes at the runtime level what's",
    "start": "410759",
    "end": "417900"
  },
  {
    "text": "going to happen is uh so you're going to have like a project you know a folder structure of files in whichever language",
    "start": "417900",
    "end": "423720"
  },
  {
    "text": "you're using like elixir or erlang you're going to somehow compile this project and somehow start it and at this",
    "start": "423720",
    "end": "428880"
  },
  {
    "text": "point a single OS process is started this is the instance of beam and inside its single OS process everything is",
    "start": "428880",
    "end": "435360"
  },
  {
    "text": "running so inside that process you're going to have a bunch of these little yellow boxes I call them these processes this small sequential programs which you",
    "start": "435360",
    "end": "442740"
  },
  {
    "text": "spawn on your own from within your code and you're typically going to have a lot of that like in smaller Pro in smaller",
    "start": "442740",
    "end": "449280"
  },
  {
    "text": "systems it's easily going to be like a few hundreds medium to large distance like hundreds of thousands or even",
    "start": "449280",
    "end": "454380"
  },
  {
    "text": "Millions these things are like very lightweight super cheap in terms of startup time and memory overhead and",
    "start": "454380",
    "end": "460020"
  },
  {
    "text": "we're not afraid of using them we use them like in abundance this is to me what I would call a beam style or beam",
    "start": "460020",
    "end": "466080"
  },
  {
    "text": "concurrent philosophy you know and I'm going to try to demonstrate this we don't use them randomly though so there is like some logic behind it so either",
    "start": "466080",
    "end": "472919"
  },
  {
    "text": "way you're going to have like a bunch of these processes and then in turn generally behind the scene the beam itself is going to spread the execution",
    "start": "472919",
    "end": "479699"
  },
  {
    "text": "of those processes across available Hardware so like a very simplified version is you're going to have a couple of os threads called schedulers which",
    "start": "479699",
    "end": "487380"
  },
  {
    "text": "are executing your processes by default there's one scheduler per available CPU core and like in a naive version you can",
    "start": "487380",
    "end": "493680"
  },
  {
    "text": "think about it as if each scheduler picks one process runs it for a little while then puts it back to the queue",
    "start": "493680",
    "end": "499080"
  },
  {
    "text": "takes another one and so on and so forth right so this makes your system immediately multiple capable and",
    "start": "499080",
    "end": "504180"
  },
  {
    "text": "vertical scalable but again we don't care really about thread pulling or such stuff we don't think about that we think about processes and so that's it that's",
    "start": "504180",
    "end": "512520"
  },
  {
    "text": "all we have like uh pretty simple stuff obviously of course I didn't tell you everything I can drop a couple of more",
    "start": "512520",
    "end": "518219"
  },
  {
    "text": "features down the line but it's like fairly fairly simple stuff yet super powerful or very versatile and so we're",
    "start": "518219",
    "end": "524279"
  },
  {
    "text": "going to take a look at a couple of examples and uh as a warm-up I'm gonna take something pretty simple I'm going",
    "start": "524279",
    "end": "529620"
  },
  {
    "text": "to take a scenario of execution of a long running task so uh this would be like a class of",
    "start": "529620",
    "end": "537060"
  },
  {
    "text": "examples or class of situations where uh like you'd need concurrency irrespective of your scale or complexity so in a",
    "start": "537060",
    "end": "543540"
  },
  {
    "text": "particular case I'm going to present we were building a data analytics or privacy sensitive data analytics system",
    "start": "543540",
    "end": "549720"
  },
  {
    "text": "so in like this diagram that would be the thing in the middle which I'm calling app here you know just for the",
    "start": "549720",
    "end": "554820"
  },
  {
    "text": "sake of brevity essentially our clients or our customers were companies that",
    "start": "554820",
    "end": "560220"
  },
  {
    "text": "built their own product and people were using that product and as a result of using that product there was some",
    "start": "560220",
    "end": "565620"
  },
  {
    "text": "database with a bunch of data and they're wanting to do some analytics on top of or from this data like gather",
    "start": "565620",
    "end": "570779"
  },
  {
    "text": "some insights correlations and whatnot uh but they didn't want to invade privacy of the people uh who like use",
    "start": "570779",
    "end": "577860"
  },
  {
    "text": "their own product and this is where we came into play so basically our system would be installed on client premises",
    "start": "577860",
    "end": "583620"
  },
  {
    "text": "between the analytics uh so the people who were like actually using or trying",
    "start": "583620",
    "end": "588779"
  },
  {
    "text": "to gather some insight and the database on the other side and so the analytics would like uh send us an SQL query and",
    "start": "588779",
    "end": "596459"
  },
  {
    "text": "we would uh basically uh return the result of that query making sure that nothing in this result reveals anything",
    "start": "596459",
    "end": "602640"
  },
  {
    "text": "sensitive about any individual you can ask me after the talk how we did this it's like pretty pretty interesting and uh very you know smart thing uh you know",
    "start": "602640",
    "end": "610560"
  },
  {
    "text": "but either way like executing this query now becomes uh like a pretty potentially",
    "start": "610560",
    "end": "615899"
  },
  {
    "text": "long-running activity right so like in simpler cases it was taking for a couple of minutes uh it could easily",
    "start": "615899",
    "end": "622440"
  },
  {
    "text": "occasionally take like over an hour and this is an example of stuff you don't want to run sequentially together with",
    "start": "622440",
    "end": "627600"
  },
  {
    "text": "everything else because if you do then everything else is blocked and no one can like interact with your system for",
    "start": "627600",
    "end": "632820"
  },
  {
    "text": "single hour or so right so that doesn't work so you need a concurrency no matter your scale like r scale was per",
    "start": "632820",
    "end": "640740"
  },
  {
    "text": "installation a handful of analysts using the system issuing a handful of queries",
    "start": "640740",
    "end": "645839"
  },
  {
    "text": "per day this is by all means ultra low scale yet we need concurrency you know",
    "start": "645839",
    "end": "651019"
  },
  {
    "text": "so uh let's see the process structure I'm going to focus on two processes in this",
    "start": "651019",
    "end": "656940"
  },
  {
    "text": "implementation so the one which I'm calling calling analyst kind of models or holds the",
    "start": "656940",
    "end": "662880"
  },
  {
    "text": "connection or a session of an analyst to our system like you can think of it as it like owns a network connection",
    "start": "662880",
    "end": "668339"
  },
  {
    "text": "literally like the websocket connection for example and so uh whenever it",
    "start": "668339",
    "end": "673560"
  },
  {
    "text": "receives a request from the browser or like from the remote clients typically it would be a browser like do this do that then it's going to do something so",
    "start": "673560",
    "end": "680279"
  },
  {
    "text": "when it receives a request to do the query to run the query then it's going to spawn the query process right so",
    "start": "680279",
    "end": "685920"
  },
  {
    "text": "we're not going to run query inside the same sequential program as the analyst running it separately computer is out",
    "start": "685920",
    "end": "691440"
  },
  {
    "text": "there do our magic there and then return the result as a message to the analyst which then ships it over the wire to the",
    "start": "691440",
    "end": "697079"
  },
  {
    "text": "other side and by doing this we liberate or detach decouple the execution flows",
    "start": "697079",
    "end": "702720"
  },
  {
    "text": "of these two programs right so the analyst can still interact with the system while the query is running and",
    "start": "702720",
    "end": "708300"
  },
  {
    "text": "perhaps they can start additional queries which was occasionally the case of course and just like that of course the other analysts May interact with the",
    "start": "708300",
    "end": "715380"
  },
  {
    "text": "system while some long activity is running this is the basic motivation behind separating things into processes",
    "start": "715380",
    "end": "721500"
  },
  {
    "text": "you want to separate their execution flows so let's take a look at some code",
    "start": "721500",
    "end": "726540"
  },
  {
    "text": "like it's pretty straightforward stuff right so you want to run the query separately in a separate process you spawn the process you run the query a",
    "start": "726540",
    "end": "733680"
  },
  {
    "text": "lot of magic obviously happening there either way you compute the result somehow and then you send the result to",
    "start": "733680",
    "end": "739019"
  },
  {
    "text": "the analyst bit and now you're done this process is now done and so this run",
    "start": "739019",
    "end": "745079"
  },
  {
    "text": "query thing uh one important thing to note about that is that like a lot of stuff is happening there and it's both i",
    "start": "745079",
    "end": "751680"
  },
  {
    "text": "o and CPU bound somehow at the same time so we need to fetch the stuff from the database and we need to do some of smart",
    "start": "751680",
    "end": "758160"
  },
  {
    "text": "mathematical post-processing calculations to provide our guarantees and we cannot do this like sequentially",
    "start": "758160",
    "end": "763800"
  },
  {
    "text": "we can like fetch stuff and then do our magic because there's a lot of data in the database so we're streaming the data",
    "start": "763800",
    "end": "769019"
  },
  {
    "text": "and processing it and you know I O and CPU bonus is intertwined and we don't care like so we use spawn to separate",
    "start": "769019",
    "end": "776760"
  },
  {
    "text": "this separate activity from everything else unlike in many other Technologies where you have to choose like am I doing",
    "start": "776760",
    "end": "782760"
  },
  {
    "text": "IO bound thing or am I doing CPU bound thing and then either go for like future promises versus some sort of thread pooling and",
    "start": "782760",
    "end": "790620"
  },
  {
    "text": "this is like you know wouldn't even work here you know so we don't care we have like one abstraction that does the job for us I want to separate the execution",
    "start": "790620",
    "end": "796980"
  },
  {
    "text": "of two things I'm going to use that abstraction right very important Point makes my job much much easier",
    "start": "796980",
    "end": "802620"
  },
  {
    "text": "so uh the analyst process that one is going to be written in the following",
    "start": "802620",
    "end": "807899"
  },
  {
    "text": "style this is like a very simplified sketch again very low level sketch typically we would use some higher level",
    "start": "807899",
    "end": "813180"
  },
  {
    "text": "abstraction that makes this stuff more declarative but the gist of it is this is what we call a server process very",
    "start": "813180",
    "end": "819420"
  },
  {
    "text": "important thing it's like the style in which we write most of our processes it's like a reactive style of or events",
    "start": "819420",
    "end": "825300"
  },
  {
    "text": "driven style of programming if you will essentially a server process Loops in each type of the loop it awaits for the",
    "start": "825300",
    "end": "831360"
  },
  {
    "text": "message and then does something with the message then rinse and repeat you know wait for the next message and so it's",
    "start": "831360",
    "end": "837240"
  },
  {
    "text": "like a single threaded or sequential server where requests are sent as these messages right and uh as a this process",
    "start": "837240",
    "end": "846180"
  },
  {
    "text": "may also maintain some State you know some arbitrary piece of data which changes over time as a result of",
    "start": "846180",
    "end": "852120"
  },
  {
    "text": "handling these messages so yeah that's a little bit quick and generic so we're going to take a look at",
    "start": "852120",
    "end": "857160"
  },
  {
    "text": "some examples of what kind of messages are we handling in the analyst process so for example this will be one kind of",
    "start": "857160",
    "end": "862920"
  },
  {
    "text": "message you know we are receiving the message receive is also kind of like a switch case statement so if the message",
    "start": "862920",
    "end": "868500"
  },
  {
    "text": "has like this shape run me some query then we're going to do some logic and uh you know basically we're going to",
    "start": "868500",
    "end": "874800"
  },
  {
    "text": "receive this message as a result of decoding bytes which will receive via websocket you know we somehow decode",
    "start": "874800",
    "end": "880560"
  },
  {
    "text": "them into this structured message and then we do the switch case like if the messages run query then I'm going to run",
    "start": "880560",
    "end": "886500"
  },
  {
    "text": "a query running a query means I'm going to spawn the process and do all that stuff that I've shown you before the",
    "start": "886500",
    "end": "892199"
  },
  {
    "text": "result of that is the pit of the query process I store the PID in my own internal state I'm keeping the track of",
    "start": "892199",
    "end": "897959"
  },
  {
    "text": "the queries I have started and then I Loop to wait for the next message that's a that's all",
    "start": "897959",
    "end": "904500"
  },
  {
    "text": "um another kind of message is the result of the query right so the query process is going to send me the result back",
    "start": "904500",
    "end": "909800"
  },
  {
    "text": "typically it's going to contain at the very least the PID of the query process",
    "start": "909800",
    "end": "915000"
  },
  {
    "text": "itself together with the actual payload or the result and now I can report the result I can remove the query bit for",
    "start": "915000",
    "end": "921839"
  },
  {
    "text": "from my state and I can resume the loop and wait for the next message and that's your happy pad for doing a synchronous",
    "start": "921839",
    "end": "927839"
  },
  {
    "text": "query execution or long running task execution um crashes right things will go wrong",
    "start": "927839",
    "end": "934320"
  },
  {
    "text": "from time to time so again you know we're doing a lot of i o for a long amount of time we may lose the",
    "start": "934320",
    "end": "940199"
  },
  {
    "text": "connection to the database uh in the process uh we are doing a lot of fancy",
    "start": "940199",
    "end": "945240"
  },
  {
    "text": "computations so we may like have some bugs do like division by zero square root of a negative number stuff like",
    "start": "945240",
    "end": "951660"
  },
  {
    "text": "that you know when those things happen an unhandle exception happens and like in any other program a program crashes",
    "start": "951660",
    "end": "958260"
  },
  {
    "text": "when it's an unhandled exception but the thing about beam is that this crash is confined to that single concurrent small",
    "start": "958260",
    "end": "964860"
  },
  {
    "text": "program right and so a crash is not an Abrupt event and this is your basic primitive for implementing fault",
    "start": "964860",
    "end": "971639"
  },
  {
    "text": "tolerant programs or systems which are resilient to individual failures like the overarching idea is the more",
    "start": "971639",
    "end": "978779"
  },
  {
    "text": "aggressive you are in splitting your job into small semi-dependent or independent",
    "start": "978779",
    "end": "984060"
  },
  {
    "text": "processes the less of negative effects there are when some things go wrong you know because the thing is not too big to",
    "start": "984060",
    "end": "989519"
  },
  {
    "text": "fail right so the you mitigate the negative effects of failures you're going to see an example of this a little bit later on but either way the crash is",
    "start": "989519",
    "end": "996720"
  },
  {
    "text": "not an Abrupt event and yet at the same time it's also not a silent event so any other process in the system may be",
    "start": "996720",
    "end": "1003320"
  },
  {
    "text": "notified if some other processes crash or terminate right and this is how we write fault tolerant programs you know",
    "start": "1003320",
    "end": "1009019"
  },
  {
    "text": "you write one thing to do the job another thing to respond to the failure of that thing right so in our particular",
    "start": "1009019",
    "end": "1014480"
  },
  {
    "text": "case the analyst process is somehow gonna ask from the runtime you know you invoke some function I'm not showing you",
    "start": "1014480",
    "end": "1020240"
  },
  {
    "text": "this there are like a couple of different ways but doors like mechanics the principle is relevant right so the",
    "start": "1020240",
    "end": "1025339"
  },
  {
    "text": "analyst process is gonna when it spawns the query it's going to ask the runtime like let me know when this thing stops",
    "start": "1025339",
    "end": "1031819"
  },
  {
    "text": "and then you're going to get the message the process with the pit fool has terminated because of the reason bar",
    "start": "1031819",
    "end": "1037459"
  },
  {
    "text": "right and then you do the conditional logic and you do something while handing this message so like this exit reason or",
    "start": "1037459",
    "end": "1042980"
  },
  {
    "text": "termination reason it can be normal you know the process has ran its course we have exhausted all of the instructions",
    "start": "1042980",
    "end": "1049220"
  },
  {
    "text": "um and then we're not going to report anything because we have already done this like two slides ago uh if the",
    "start": "1049220",
    "end": "1054320"
  },
  {
    "text": "reason is not normal then it's abnormal so some crashes happen typically this piece of data is going to contain like",
    "start": "1054320",
    "end": "1059900"
  },
  {
    "text": "an exception message and a stack trace and we report this like a generic message for the user more detailed one",
    "start": "1059900",
    "end": "1065660"
  },
  {
    "text": "for the operator and you're good to go irrespective of the reason this is the place where I would remove the query",
    "start": "1065660",
    "end": "1071480"
  },
  {
    "text": "from the state not like the two slides ago the happy pad because here we end up",
    "start": "1071480",
    "end": "1076700"
  },
  {
    "text": "no matter what right so this is where I'm removing the query it's not running anymore and again I resume the loop and",
    "start": "1076700",
    "end": "1082280"
  },
  {
    "text": "I wait for the next message and this small example demonstrates what to me is",
    "start": "1082280",
    "end": "1087320"
  },
  {
    "text": "the gist of concurrent thinking in beam how we split things into processes right we split things to separate their",
    "start": "1087320",
    "end": "1093200"
  },
  {
    "text": "execution flows and and Order their failures basically like if you have two functions full and bar and you're",
    "start": "1093200",
    "end": "1099980"
  },
  {
    "text": "wondering like do I need two processes or one uh like the guideline would be uh",
    "start": "1099980",
    "end": "1105320"
  },
  {
    "text": "if you don't want the duration of food to affect the duration of bar and or you don't want the potential failure of food",
    "start": "1105320",
    "end": "1111980"
  },
  {
    "text": "to affect the success of bar two processes else one process like there",
    "start": "1111980",
    "end": "1117020"
  },
  {
    "text": "are going to be some exceptions but this is like a very good guideline to start with on a more higher level of thinking I'd like to describe this as you want to",
    "start": "1117020",
    "end": "1124039"
  },
  {
    "text": "run separate activities of your system logical activities in different processes that's the general idea and",
    "start": "1124039",
    "end": "1130340"
  },
  {
    "text": "now we're going to take a look at a little bit more involved example of that style of thinking in this scenario which",
    "start": "1130340",
    "end": "1135919"
  },
  {
    "text": "is data processing pipeline or ingestion Pipeline and this is like a class of problems where I think that beam and",
    "start": "1135919",
    "end": "1143000"
  },
  {
    "text": "beam language is really shine that they're like a really really good choice of technology for those kind of things",
    "start": "1143000",
    "end": "1148460"
  },
  {
    "text": "so in particular case what we were doing we were building like this service again",
    "start": "1148460",
    "end": "1154880"
  },
  {
    "text": "it's the thing in the middle that consumed a stream of events from a bunch",
    "start": "1154880",
    "end": "1160280"
  },
  {
    "text": "of different data sources and these events were describing sport matches which are currently taking place",
    "start": "1160280",
    "end": "1166280"
  },
  {
    "text": "and you know we would have to interpret each event and continues to maintain our own view of the world our own model uh",
    "start": "1166280",
    "end": "1173000"
  },
  {
    "text": "you know that fits our purposes and as a result of each update to our own model we would have to make some updates to",
    "start": "1173000",
    "end": "1180320"
  },
  {
    "text": "our own internal database which was used by a bunch of other services as well as ship this data this new model to the",
    "start": "1180320",
    "end": "1187160"
  },
  {
    "text": "remote web server that serves this data to the users right so this is like a small example of your typical consume",
    "start": "1187160",
    "end": "1195440"
  },
  {
    "text": "process produce service which you've probably seen if you've done some event driven microservices",
    "start": "1195440",
    "end": "1202640"
  },
  {
    "text": "and so how do we implement this pipeline in uh in the beam language it's like this you know basically you want to have",
    "start": "1202640",
    "end": "1209000"
  },
  {
    "text": "like one uh one process it's good these are going to be server processes right all of them you're going to start them",
    "start": "1209000",
    "end": "1214400"
  },
  {
    "text": "statically during your boot time and each process basically waits for the message from the previous in the",
    "start": "1214400",
    "end": "1219799"
  },
  {
    "text": "pipeline then when it gets the message it does its own job produces the outcome sends it as a message down the line and",
    "start": "1219799",
    "end": "1226460"
  },
  {
    "text": "you're good to go right and so at the top we have these feed processes so these are the processes which connect to",
    "start": "1226460",
    "end": "1232340"
  },
  {
    "text": "the remote external services and they receiving feed of events they literally",
    "start": "1232340",
    "end": "1238340"
  },
  {
    "text": "receive bytes and their job is to convert bytes into structured messages which we can understand right and then",
    "start": "1238340",
    "end": "1245480"
  },
  {
    "text": "you have the model process which interprets each message applies it to our own model and this is our point of",
    "start": "1245480",
    "end": "1251419"
  },
  {
    "text": "synchronization our point of consistency remember again that the process is a sequential thing write a sequential",
    "start": "1251419",
    "end": "1257780"
  },
  {
    "text": "program so this is where we handle one message at a time and once we do that then we spread out",
    "start": "1257780",
    "end": "1263360"
  },
  {
    "text": "we can spread it out again and do our updates to the database independently from uh sending this stuff down the wire",
    "start": "1263360",
    "end": "1269600"
  },
  {
    "text": "to the server so in terms of boundness again like this feed there will be a combination of IO bound plus CPU bound",
    "start": "1269600",
    "end": "1276260"
  },
  {
    "text": "work uh database pure i o bound mostly server sending to server CPU plus IO",
    "start": "1276260",
    "end": "1282200"
  },
  {
    "text": "because we have to encode the Json then send it down the wire uh model pure CPU bound stuff we don't care we just use",
    "start": "1282200",
    "end": "1288799"
  },
  {
    "text": "you know I don't care about these things that's like way too technical for me if I want to run things separately I'm",
    "start": "1288799",
    "end": "1293960"
  },
  {
    "text": "going to use separate processes this is all I care and the runtime does the rest for me as it should the model thing",
    "start": "1293960",
    "end": "1300440"
  },
  {
    "text": "itself so that's an interesting stuff the model is uh basically for us a",
    "start": "1300440",
    "end": "1306140"
  },
  {
    "text": "collection of mass of matches sport matches and these are like completely independent of each other and so rather",
    "start": "1306140",
    "end": "1311720"
  },
  {
    "text": "than having one Mega model we're going to have like per match model we're going to have like these dynamical processes",
    "start": "1311720",
    "end": "1317720"
  },
  {
    "text": "which are like pretty straightforward to do essentially when I get the first message for a particular match I'm going",
    "start": "1317720",
    "end": "1324140"
  },
  {
    "text": "to start the match process and I'm going to keep it alive for as long as I'm receiving messages for that match",
    "start": "1324140",
    "end": "1329419"
  },
  {
    "text": "and somehow I'm gonna then you know wire or forward the proper event from the feed to the corresponding match I'm",
    "start": "1329419",
    "end": "1335780"
  },
  {
    "text": "going to come back to this in the next slide and so now like because this this update to the model is CPU bound work",
    "start": "1335780",
    "end": "1341960"
  },
  {
    "text": "now I'm like have a lot of potential for spreading the work across available CPU cores uh but even on a single core",
    "start": "1341960",
    "end": "1348140"
  },
  {
    "text": "machine this is going to work like much much more efficient because uh for each event the active data set I'm working on",
    "start": "1348140",
    "end": "1354559"
  },
  {
    "text": "is much smaller you know it's just a single match rather than a bunch of them uh so in particular the garbage",
    "start": "1354559",
    "end": "1360500"
  },
  {
    "text": "collector is going to be much more efficient right so in beam GC is done on a per process level not on the World",
    "start": "1360500",
    "end": "1366620"
  },
  {
    "text": "level and what this means is uh that like when the process is in the scheduler and uh it has you know it has",
    "start": "1366620",
    "end": "1374059"
  },
  {
    "text": "a scheduling time and it runs instructions if it needs to expand memory if it needs more Heap then prior",
    "start": "1374059",
    "end": "1379100"
  },
  {
    "text": "to that a GC is going to be done for that process alone and that GC is going to analyze just the active data of that",
    "start": "1379100",
    "end": "1384860"
  },
  {
    "text": "process and this is just a single match right so it's much faster it's going to be way more efficient and you're going to have less latency and you're going to",
    "start": "1384860",
    "end": "1391039"
  },
  {
    "text": "be like way more efficient in keeping up with real time most importantly a failure when",
    "start": "1391039",
    "end": "1397039"
  },
  {
    "text": "processing a single match is going to affect that match alone right and we had that situation we had a bug as you do of",
    "start": "1397039",
    "end": "1402799"
  },
  {
    "text": "course it happens from time to time uh so like there was like a particular set of constellations of circumstances where",
    "start": "1402799",
    "end": "1408980"
  },
  {
    "text": "like a single event applied to a single match would trigger a crash and that match crashed we weren't able to proceed",
    "start": "1408980",
    "end": "1415520"
  },
  {
    "text": "forward until a human came and fixed the bug but in the meantime all of the other matches are still working and if you",
    "start": "1415520",
    "end": "1421280"
  },
  {
    "text": "have like 100 matches you still have 99 of your service which is way better than nothing right so this is how you build",
    "start": "1421280",
    "end": "1427159"
  },
  {
    "text": "fault tolerant programs or systems um how do we discover a particular match",
    "start": "1427159",
    "end": "1433460"
  },
  {
    "text": "right so this is the registry pattern which you may have seen if you've done like service oriented architecture",
    "start": "1433460",
    "end": "1439340"
  },
  {
    "text": "especially microservices and I'm showing it here as an example of how we do those",
    "start": "1439340",
    "end": "1444559"
  },
  {
    "text": "things like at a much finer grain level actually you could say like pick or Nano Services directly in our language",
    "start": "1444559",
    "end": "1450140"
  },
  {
    "text": "without needing to use like Head CD or stuff like that basically you're gonna start like a single process which acts",
    "start": "1450140",
    "end": "1456140"
  },
  {
    "text": "as a registry which has like a mapping of a logical role of the process to its",
    "start": "1456140",
    "end": "1461840"
  },
  {
    "text": "physical address which is the pit you know and you're not going to have to implement this yourself right so you're going to use an off-the-shelf",
    "start": "1461840",
    "end": "1467360"
  },
  {
    "text": "obstruction which is of course like in Elixir it's available in standard library and then what's going to happen is",
    "start": "1467360",
    "end": "1473600"
  },
  {
    "text": "you're going to start the match process it's going to announce itself to the registry like I'm the process responsible for the match one two three",
    "start": "1473600",
    "end": "1479900"
  },
  {
    "text": "register stores this mapping on the other side the feed process decodes the incoming message reads up some match ID",
    "start": "1479900",
    "end": "1487100"
  },
  {
    "text": "field then asks the registry like who is responsible for this process gets the it and now it can talk to that process",
    "start": "1487100",
    "end": "1493220"
  },
  {
    "text": "right so that's it you know your basic registry pattern or service oriented pattern directly here in your language",
    "start": "1493220",
    "end": "1498919"
  },
  {
    "text": "of choice managing the load in this data pipeline is uh also an interesting thing so I",
    "start": "1498919",
    "end": "1504260"
  },
  {
    "text": "would say that like load control is the essential challenge of any sort of data pipeline so here we have like one",
    "start": "1504260",
    "end": "1509780"
  },
  {
    "text": "example of that um we have like these match processes and again every time we update the match",
    "start": "1509780",
    "end": "1515480"
  },
  {
    "text": "we have to send something to the remote server it's uh depicted here as a dispatch process right uh so basically",
    "start": "1515480",
    "end": "1522500"
  },
  {
    "text": "what we're sending is like the new state of the model together with the divs that bring the previous state for to the next",
    "start": "1522500",
    "end": "1528080"
  },
  {
    "text": "one right and this is what we need so we can serve the data to the users you know that uses stuff via browser so",
    "start": "1528080",
    "end": "1534559"
  },
  {
    "text": "dispatching this basically means we need to encode to Json and then send it down the wire over the network right this is",
    "start": "1534559",
    "end": "1541100"
  },
  {
    "text": "a potential long-running activity and when we did this like on every single incoming message we would quickly fall",
    "start": "1541100",
    "end": "1547760"
  },
  {
    "text": "behind the reality this wasn't really efficient you know even on a smaller load so like I would say this service",
    "start": "1547760",
    "end": "1553100"
  },
  {
    "text": "was moderately loaded we had to deal with uh in normal modes of operation like few dozen messages per second big",
    "start": "1553100",
    "end": "1559700"
  },
  {
    "text": "times few hundred messages per second this isn't small but it isn't exactly what I would call like super high you",
    "start": "1559700",
    "end": "1565400"
  },
  {
    "text": "know but still even with that load uh very quickly we would fall behind you know we weren't able to like ship the",
    "start": "1565400",
    "end": "1570500"
  },
  {
    "text": "stuff one the time the solution to this problem is batching efficiently essentially because like",
    "start": "1570500",
    "end": "1578000"
  },
  {
    "text": "handling and things at once is way more efficient than end times handling a single thing you know that's usually the",
    "start": "1578000",
    "end": "1583640"
  },
  {
    "text": "case when you have networking involved and so you know to do the batching here you just split the process into two",
    "start": "1583640",
    "end": "1589940"
  },
  {
    "text": "right and you have like two distinct activities you have the Bachelor and the dispatcher so the bachelor batches it",
    "start": "1589940",
    "end": "1595279"
  },
  {
    "text": "accepts incoming or sorry it accepts outgoing messages it Aggregates them occasionally hands them off to the",
    "start": "1595279",
    "end": "1602419"
  },
  {
    "text": "dispatcher now that this Patcher does its magic like in codes sends it down a wire concurrently to that dispatcher May",
    "start": "1602419",
    "end": "1609559"
  },
  {
    "text": "accept more work okay just you know you establish two processes and send them messages the main challenge here is how",
    "start": "1609559",
    "end": "1616520"
  },
  {
    "text": "do we how often do we hand off this data this batch right and like typically",
    "start": "1616520",
    "end": "1622039"
  },
  {
    "text": "people go for the approach of picking the number X of like at most text messages Plus at most y seconds the",
    "start": "1622039",
    "end": "1630260"
  },
  {
    "text": "problem with this is that like what sort of numbers should they choose so like if my parameters X and Y are too small then",
    "start": "1630260",
    "end": "1636620"
  },
  {
    "text": "my batch is going to be too small and as a result I'm going to end up with the same problem I'm going to do like two frequent deployments or dispatches to",
    "start": "1636620",
    "end": "1643820"
  },
  {
    "text": "the other side and I'm going to fall back behind the reality on the other hand uh if these numbers are too large",
    "start": "1643820",
    "end": "1649220"
  },
  {
    "text": "then I'm going to wait for too long until I complete the patch and again I'm going to introduce an unwanted latency",
    "start": "1649220",
    "end": "1654980"
  },
  {
    "text": "right so I don't like these approaches and what I like to do instead is the thing the technique I called adaptive",
    "start": "1654980",
    "end": "1660740"
  },
  {
    "text": "patching which would be a sort of variation of uh demand driven producer consumer",
    "start": "1660740",
    "end": "1666919"
  },
  {
    "text": "relationship so we're going to focus on The Bachelor and the dispatcher here to explain this so the better here is like",
    "start": "1666919",
    "end": "1672860"
  },
  {
    "text": "the producer for the dispatcher okay now the way this works is the dispatcher is going to come to the Batcher it's going",
    "start": "1672860",
    "end": "1678679"
  },
  {
    "text": "to say like I'm available give me some work please and it gets from the batch for whatever it has at this point unless",
    "start": "1678679",
    "end": "1685159"
  },
  {
    "text": "it has nothing in which case the Batcher awaits for the very first message and immediately forwards it forwards it to",
    "start": "1685159",
    "end": "1690500"
  },
  {
    "text": "the dispatcher okay and now that this picture again does its magic the Batcher collects the subsequent outgoing work",
    "start": "1690500",
    "end": "1697279"
  },
  {
    "text": "once the dispatcher is done it comes back to the Batcher like I'm ready again what do you have for me and it gets the",
    "start": "1697279",
    "end": "1703640"
  },
  {
    "text": "next batch okay and as a result of this like if the dispatcher is faster than",
    "start": "1703640",
    "end": "1708799"
  },
  {
    "text": "the incoming rate of messages then we're actually going to have the batch size of one and it's going to work perfectly",
    "start": "1708799",
    "end": "1714799"
  },
  {
    "text": "fine when the circumstances change which they will most typically when the incoming rate increases perhaps not so",
    "start": "1714799",
    "end": "1722600"
  },
  {
    "text": "frequently but still happens like when the Network becomes slower on the re or the remote service becomes overloaded",
    "start": "1722600",
    "end": "1728179"
  },
  {
    "text": "less responsive so that you know we cannot dispatch as fast as we are receiving new stuff the batch is",
    "start": "1728179",
    "end": "1733640"
  },
  {
    "text": "automatically increased to adapt to the circumstances once the circumstances clear up the batch is automatically",
    "start": "1733640",
    "end": "1739520"
  },
  {
    "text": "shrunk and you don't have to worry about those numbers now the reason why I'm showing you this is because like coming up with this algorithm and uh reasoning",
    "start": "1739520",
    "end": "1747020"
  },
  {
    "text": "about Its Behavior is like super trivial you know it makes me feel smart but the reality is that like the tool the good",
    "start": "1747020",
    "end": "1752720"
  },
  {
    "text": "tool dumbs down the problem right so I basically draw these two boxes I draw some arrows and obviously of course I",
    "start": "1752720",
    "end": "1758779"
  },
  {
    "text": "spend like a few minutes thinking about it maybe discussing it with someone and that's it you know I can convince myself that this stuff works I can reason about",
    "start": "1758779",
    "end": "1765440"
  },
  {
    "text": "such things in a way that I couldn't when I was doing like classical multi-threading okay",
    "start": "1765440",
    "end": "1771020"
  },
  {
    "text": "so uh the final thing I'm going to talk about is cancellation right and so this",
    "start": "1771020",
    "end": "1776179"
  },
  {
    "text": "is the feature that in my view is like an essential feature of any sort of concurrency technology and it's",
    "start": "1776179",
    "end": "1782240"
  },
  {
    "text": "surprisingly overlooked by many especially the ones aspiring to you know compete for the same spaces uh beam",
    "start": "1782240",
    "end": "1788480"
  },
  {
    "text": "languages and it's also I think frequently overlooked by the developers assessing those Technologies so like I I",
    "start": "1788480",
    "end": "1795080"
  },
  {
    "text": "don't want just the ability to start the program I want the ability to stop it you know it's needed almost all the",
    "start": "1795080",
    "end": "1800840"
  },
  {
    "text": "times so we're going to take a look at two examples uh so the simpler one I'm going to go back to that data analytics query",
    "start": "1800840",
    "end": "1807200"
  },
  {
    "text": "execution so if you remember we have like this long running query you know we're running it and we obviously want",
    "start": "1807200",
    "end": "1813320"
  },
  {
    "text": "to allow people to stop the query to cancel the query right like the analysts you know may have decided like oh this",
    "start": "1813320",
    "end": "1819080"
  },
  {
    "text": "query is wrong I'm not going to wait for like one hour until it finishes I'm going to hit the cancel button and then I'm going to start the next one and so",
    "start": "1819080",
    "end": "1825200"
  },
  {
    "text": "how do we do that it's as simple as one liner you know you need the pit of your process and then",
    "start": "1825200",
    "end": "1831020"
  },
  {
    "text": "you ask the runtime can you please stop me this thing and what's going to happen is then that process is going to stop",
    "start": "1831020",
    "end": "1836539"
  },
  {
    "text": "with the given reason that we have supplied here it can be an arbitrary reason there are like a few special ones but it can also be arbitrary so this",
    "start": "1836539",
    "end": "1843500"
  },
  {
    "text": "shutdown doesn't really mean anything to the runtime it's going to stop the process and we're going to get the message",
    "start": "1843500",
    "end": "1848600"
  },
  {
    "text": "process or this query has stopped with a recent shutdown and now we do the conditional logic that we already had so",
    "start": "1848600",
    "end": "1854960"
  },
  {
    "text": "I'm if there is a shutdown I'm going to report the successful cancellation if the reason is normal I'm not going to do",
    "start": "1854960",
    "end": "1860120"
  },
  {
    "text": "anything otherwise I'm going to report the crash and I'm good to go this is your cancellation and I'm showing you this here because like again in many",
    "start": "1860120",
    "end": "1866600"
  },
  {
    "text": "other technology Technologies especially the ones based on CSP concurrency model you're not going to have this like in",
    "start": "1866600",
    "end": "1872600"
  },
  {
    "text": "CSP your concurrent activities are Anonymous they are nameless right and so you cannot test this you can test the",
    "start": "1872600",
    "end": "1879140"
  },
  {
    "text": "runtime to stop the thing which you can obtain right and so as a result you're going to have to devise your own manual",
    "start": "1879140",
    "end": "1884899"
  },
  {
    "text": "implementation of cancellation typically we're going to build like a communication Channel and then you're going to pass it around or something",
    "start": "1884899",
    "end": "1890419"
  },
  {
    "text": "which is called context or sometimes a cancellation token and you pass it from function to function and every now and",
    "start": "1890419",
    "end": "1896059"
  },
  {
    "text": "then you manually just ask like in the worker process which like runs this query am I being canceled am I being",
    "start": "1896059",
    "end": "1901340"
  },
  {
    "text": "canceled they have been canceled and if you are then you have to manually unwind your stacked like it's very very tedious",
    "start": "1901340",
    "end": "1907580"
  },
  {
    "text": "and error prone and I don't see myself like doing that kind of work especially not in this case so like running this",
    "start": "1907580",
    "end": "1913880"
  },
  {
    "text": "query this analytical query with our guarantees was a huge like super complex piece of functionality a lot of micro",
    "start": "1913880",
    "end": "1920000"
  },
  {
    "text": "functions involved there and like this this won't really work uh now this is all well and fine but in",
    "start": "1920000",
    "end": "1926899"
  },
  {
    "text": "many cases you know uh you want to also allow the process being terminated to say some final last words like uh to",
    "start": "1926899",
    "end": "1933260"
  },
  {
    "text": "drain whatever work is currently doing as well as uh clean up whatever resources it has to and so this is also",
    "start": "1933260",
    "end": "1939320"
  },
  {
    "text": "perfectly possible Right essentially you know just I'm going to go back one slide so I did this process exiting uh",
    "start": "1939320",
    "end": "1945559"
  },
  {
    "text": "technically speaking we say we send an exit signal to the process and by default that process is just stopped in",
    "start": "1945559",
    "end": "1951860"
  },
  {
    "text": "its tracks but each process may decide to trap exits basically you know you invoke this function and you ask the",
    "start": "1951860",
    "end": "1957980"
  },
  {
    "text": "runtime convert the exit into a message and so now when someone tries to cancel me I get this at the end of my mailbox",
    "start": "1957980",
    "end": "1965120"
  },
  {
    "text": "as a message and I handle this message you know by cleaning up my work and then",
    "start": "1965120",
    "end": "1970159"
  },
  {
    "text": "you know stopping myself with a given reason and that's basically it most of the times you're not going to really",
    "start": "1970159",
    "end": "1975380"
  },
  {
    "text": "have to do this so as an aside like everything is process oriented in beams so like Memories uh connected to the",
    "start": "1975380",
    "end": "1982520"
  },
  {
    "text": "process when the process stops it immediately reclaim doesn't even go through the GC file handles network sockets all stuff immediately you know",
    "start": "1982520",
    "end": "1989299"
  },
  {
    "text": "released however there are like some things that been cannot track like if a process created some folder on the disk",
    "start": "1989299",
    "end": "1995360"
  },
  {
    "text": "then you're going to have to clean it clean it up manually and we're going to see a more involved example of that the",
    "start": "1995360",
    "end": "2000640"
  },
  {
    "text": "final one which is the custom implementation or proprietary implementation of the continuous",
    "start": "2000640",
    "end": "2005799"
  },
  {
    "text": "integration right so like when we were building our products specifically that data analytics thing we implemented our",
    "start": "2005799",
    "end": "2012519"
  },
  {
    "text": "CI an Elixir rather than choosing something off the shelf so not as a product right just for us internally we",
    "start": "2012519",
    "end": "2019360"
  },
  {
    "text": "did it because we believed in a personal strength still strongly believe that uh like uh doing a CI with the language",
    "start": "2019360",
    "end": "2026799"
  },
  {
    "text": "which is Turing complete which like has a well good support with tooling which has a rich support for massive",
    "start": "2026799",
    "end": "2032740"
  },
  {
    "text": "concurrency and deep integration with the underlying operating system is way better than choosing yaml to deal with",
    "start": "2032740",
    "end": "2039340"
  },
  {
    "text": "CI right much more flexible much more powerful and this is what we did and it was by far the most enjoyable CI that I",
    "start": "2039340",
    "end": "2045340"
  },
  {
    "text": "have ever had the pleasure of working with now uh we're going to take a look at the process structure of this CI",
    "start": "2045340",
    "end": "2051158"
  },
  {
    "text": "so at the top we have like what we call a root process this is the first process that that started right like your main",
    "start": "2051159",
    "end": "2057280"
  },
  {
    "text": "process or main function if you will and from within that process you're going to start additional processes like your",
    "start": "2057280",
    "end": "2062500"
  },
  {
    "text": "children those children are going to have their own children and so on and so forth and this is what we call a process hierarchy or process tree supervision",
    "start": "2062500",
    "end": "2069339"
  },
  {
    "text": "three more precisely and it's I like to think of it as a top-down view of the activities of your",
    "start": "2069339",
    "end": "2075220"
  },
  {
    "text": "system like your top-down service manager or systemd if you will and so I'm going to focus on the hierarchy of a",
    "start": "2075220",
    "end": "2080980"
  },
  {
    "text": "couple of important processes so we have like this main process here and it's going to have these children which we",
    "start": "2080980",
    "end": "2086800"
  },
  {
    "text": "call builds a build is basically an instance of an execution of a single CI",
    "start": "2086800",
    "end": "2092200"
  },
  {
    "text": "right so like I push something to the main branch that's one build you push something to your feature Branch that's",
    "start": "2092200",
    "end": "2097540"
  },
  {
    "text": "another build okay so those are like very Dynamic processes and just by looking at this diagram we can tell that",
    "start": "2097540",
    "end": "2102820"
  },
  {
    "text": "like builds are running independently concurrently separately from each other in parallel if you will right so a",
    "start": "2102820",
    "end": "2109420"
  },
  {
    "text": "single build is further divided into projects essentially you know our whole product was the divided or organized as",
    "start": "2109420",
    "end": "2116020"
  },
  {
    "text": "a service oriented stuff not micro services but we had like a couple of independently deployed services and and",
    "start": "2116020",
    "end": "2122260"
  },
  {
    "text": "those are of course residing separate projects and we kept them all in a single mono repo because this is the way",
    "start": "2122260",
    "end": "2128380"
  },
  {
    "text": "uh and so when we will have to build you know we would have to build multiple projects again you can tell from the",
    "start": "2128380",
    "end": "2133660"
  },
  {
    "text": "diagram that it's all done concurrently uh now uh just as an aside you know we",
    "start": "2133660",
    "end": "2138880"
  },
  {
    "text": "wouldn't always be building all of the projects right so like this is an example of what you get when you own your CI in a proper language you know we",
    "start": "2138880",
    "end": "2145420"
  },
  {
    "text": "would like remember the last known State like in a cache so when something new is pushed we do a git diff and figure out",
    "start": "2145420",
    "end": "2151359"
  },
  {
    "text": "which projects we have to actually build so typically it will be like one or two of them at the most like in most cases",
    "start": "2151359",
    "end": "2156400"
  },
  {
    "text": "so it has to reduce star CI build and as a result you know increase our feedback loop",
    "start": "2156400",
    "end": "2162300"
  },
  {
    "text": "so what does it take to build a single project and this is the meat of the CI right so basically you know you're going",
    "start": "2162300",
    "end": "2168760"
  },
  {
    "text": "to run a bunch of commands like fetch window dependencies uh compile this thing run some tests run the linter and",
    "start": "2168760",
    "end": "2174520"
  },
  {
    "text": "so on and so forth uh for us it was all containerized and so this is the process structure or an example like if I want",
    "start": "2174520",
    "end": "2181060"
  },
  {
    "text": "to start a container I'm going to start the process let's start the container and keeps it alive if I want to run the",
    "start": "2181060",
    "end": "2186099"
  },
  {
    "text": "command I'm going to start the process which runs the command you know like compile this thing that's going to be one process and again what you can see",
    "start": "2186099",
    "end": "2191560"
  },
  {
    "text": "from this diagram that it's such a fine grain level we had support for concurrency because we could because",
    "start": "2191560",
    "end": "2197380"
  },
  {
    "text": "it's super trivial stuff to do now the challenge here is how do we cancel single build this is like a very",
    "start": "2197380",
    "end": "2202839"
  },
  {
    "text": "frequent Challenge in a CI right like I push something to the main branch or whatever Branch it started in building I",
    "start": "2202839",
    "end": "2208660"
  },
  {
    "text": "put something else and now I don't want the previous build to be running anymore it doesn't really make sense right I want to cancel that build and I want to",
    "start": "2208660",
    "end": "2215140"
  },
  {
    "text": "cancel all this entire three subtree of the build because if I don't I might",
    "start": "2215140",
    "end": "2220720"
  },
  {
    "text": "fail to start another build if there is like some lock on the like the global things such as Docker container name or",
    "start": "2220720",
    "end": "2226359"
  },
  {
    "text": "I might have some strange race conditions if they are both running at the same time or like in the best case scenario my new build is going to be",
    "start": "2226359",
    "end": "2232240"
  },
  {
    "text": "running slower because the previous one is running and I'm not using its result anyway right so like I want to cancel this stuff before I start the new build",
    "start": "2232240",
    "end": "2239020"
  },
  {
    "text": "this is the essential challenge here so the way we're going to do this is again all of these processes server",
    "start": "2239020",
    "end": "2245079"
  },
  {
    "text": "style processes very reactive event driven style of concurrency and we're basically going to have custom",
    "start": "2245079",
    "end": "2251260"
  },
  {
    "text": "termination in each of them like the way typically you're going to do with a higher level obstruction you're just going to implement some function which",
    "start": "2251260",
    "end": "2257320"
  },
  {
    "text": "is called terminated and it's kind of like a Destructor of your process and you're going to do your cleanup there and so the cleanup happens before the",
    "start": "2257320",
    "end": "2263380"
  },
  {
    "text": "process itself stops so for each process which is a parent of other children",
    "start": "2263380",
    "end": "2269079"
  },
  {
    "text": "you want to stop your children before you stop yourself and you want to stop them in the opposite order of the",
    "start": "2269079",
    "end": "2274599"
  },
  {
    "text": "startup right because the younger children may depend on their older siblings right and so you're not going",
    "start": "2274599",
    "end": "2280420"
  },
  {
    "text": "to have to do this manually you're going to just use some of the abstraction and it's going to happen magically and so when I ask the build process to stop",
    "start": "2280420",
    "end": "2286980"
  },
  {
    "text": "what's going to happen behind the scene without me doing practically you know zero work we're going to walk",
    "start": "2286980",
    "end": "2293260"
  },
  {
    "text": "recursively to the bottom to the right and then we're going to unwind stop in one process at a time until we reach the",
    "start": "2293260",
    "end": "2298599"
  },
  {
    "text": "top so this is the shutdown order which again you get practically for free and this is what you want to get right you",
    "start": "2298599",
    "end": "2304060"
  },
  {
    "text": "don't want to leave dangling stuff behind now in those Leaf processes the command and the container This Is Where",
    "start": "2304060",
    "end": "2309820"
  },
  {
    "text": "You're Gonna Wanna Have custom termination logic so command is like associated with an external OS process",
    "start": "2309820",
    "end": "2315880"
  },
  {
    "text": "it started like Docker exec something something command and you want to stop that thing a container started the",
    "start": "2315880",
    "end": "2321579"
  },
  {
    "text": "docker container and you want to stop that thing before you stop the process and so this is going to be like a five liner something like that in each",
    "start": "2321579",
    "end": "2327820"
  },
  {
    "text": "process and you're going to implement that and then canceling the entire build is a straightforward as sending an exit",
    "start": "2327820",
    "end": "2334599"
  },
  {
    "text": "signal to the build process and then what I'm doing in the next line I'm waiting for the confirmation that",
    "start": "2334599",
    "end": "2341140"
  },
  {
    "text": "the build process has stopped because it takes a while until you know this whole structure is taken down so I'm waiting",
    "start": "2341140",
    "end": "2346180"
  },
  {
    "text": "until it stops and now I know that after this point my build is not running none of the associated",
    "start": "2346180",
    "end": "2352540"
  },
  {
    "text": "activities of these commands containers whatever I have started none of the stuff exists anymore and I can start the",
    "start": "2352540",
    "end": "2358720"
  },
  {
    "text": "new build and I can you know be confident that it's going to work as it's supposed to be working and you're not even going to have to write this",
    "start": "2358720",
    "end": "2364540"
  },
  {
    "text": "code you're going to use like a wrapper which is going to be one liner like stop in this process please okay so that",
    "start": "2364540",
    "end": "2371020"
  },
  {
    "text": "concludes my talk more or less uh I've shown you a bunch of examples uh I think",
    "start": "2371020",
    "end": "2376300"
  },
  {
    "text": "or at least a couple of them like different kind of examples for Bim concurrency can be used it's a very versatile thing",
    "start": "2376300",
    "end": "2382440"
  },
  {
    "text": "and I have barely scratched the surface you know to be clear so uh no obviously we don't have the time for more examples",
    "start": "2382440",
    "end": "2388300"
  },
  {
    "text": "yeah oh okay wow I I was pretty fast but either way",
    "start": "2388300",
    "end": "2394540"
  },
  {
    "text": "you know like you may find uh you may find uh more time perhaps to look at some other talks so like two years ago I",
    "start": "2394540",
    "end": "2400780"
  },
  {
    "text": "did a virtual one on Yahoo Lambda uh and that's like pretty much the same style",
    "start": "2400780",
    "end": "2405940"
  },
  {
    "text": "as this talk except the examples are completely different you know so it uses examples more from the web server uh",
    "start": "2405940",
    "end": "2412660"
  },
  {
    "text": "domain uh and so you may want to check that one out and then there's a sort of",
    "start": "2412660",
    "end": "2418119"
  },
  {
    "text": "spiritual predecessor or some some sort of foundation it's this talk from go to",
    "start": "2418119",
    "end": "2423420"
  },
  {
    "text": "where I go into details about features of beam concurrency into more details than I gave you today it's very demo",
    "start": "2423420",
    "end": "2430180"
  },
  {
    "text": "driven right so a lot of stuff I can try to Showcase to make them more tangible uh so you may want to take a look at",
    "start": "2430180",
    "end": "2435760"
  },
  {
    "text": "that one as well if you can find the time I'm also the author of the book called elixir in action which",
    "start": "2435760",
    "end": "2441880"
  },
  {
    "text": "specifically is focused on you know showing you how you can manage concurrence in beam using Elixir as a",
    "start": "2441880",
    "end": "2447820"
  },
  {
    "text": "programming language it's discounted with a given code at manning.com and this code is also worked for the entire",
    "start": "2447820",
    "end": "2453700"
  },
  {
    "text": "Manning catalog I believe so uh I'm not sure how long it's going to be valid so grab that while you can",
    "start": "2453700",
    "end": "2459780"
  },
  {
    "text": "I'm also giving away a couple of copies of the book so I have one printed version and a few coupons for free ebook",
    "start": "2459780",
    "end": "2467320"
  },
  {
    "text": "version so if you want that grab me or find me immediately after the talk you",
    "start": "2467320",
    "end": "2472780"
  },
  {
    "text": "can find my contacts down on the bottom Twitter and on the more recently I'm trying to go for Mastodon but I'm still",
    "start": "2472780",
    "end": "2478660"
  },
  {
    "text": "active on Twitter as well open for DMS so if you have questions let me know and",
    "start": "2478660",
    "end": "2484119"
  },
  {
    "text": "this is all I had prepared for you so thank you very much",
    "start": "2484119",
    "end": "2488760"
  },
  {
    "text": "thank you Sasha this is the time for Q a so yeah",
    "start": "2492940",
    "end": "2499380"
  },
  {
    "text": "I thought it was a great talk I have a question about the state you maintain uh",
    "start": "2502900",
    "end": "2508960"
  },
  {
    "text": "is that generally in in memory or are you generally making somewhere else if",
    "start": "2508960",
    "end": "2516040"
  },
  {
    "text": "there is somewhere else what sort of storage you recommend for system Library yeah so this is like a very low level uh",
    "start": "2516040",
    "end": "2523060"
  },
  {
    "text": "stuff and the state is maintained in memory it's a data structure you may decide of course if you want like to",
    "start": "2523060",
    "end": "2528640"
  },
  {
    "text": "store it in a wherever you want but nothing out of the box particularly is offered although I mean like the whole",
    "start": "2528640",
    "end": "2535060"
  },
  {
    "text": "standard Library especially of Verlin Elixir is built on top of erlang right so it relies on its standard Library it's not an implementation detail you",
    "start": "2535060",
    "end": "2541300"
  },
  {
    "text": "can use it so erlang itself ships with a kind of an embedded database key key",
    "start": "2541300",
    "end": "2546400"
  },
  {
    "text": "value database if you will so you don't even have to start that on the side you can like start this thing and uh",
    "start": "2546400",
    "end": "2552060"
  },
  {
    "text": "Storyteller I actually talked about this in the uh not about like a lightweight version of that in this talk I have an",
    "start": "2552060",
    "end": "2558220"
  },
  {
    "text": "example where I'm actually persisting the state uh uh on the disk you know so you could take a look at that but yeah",
    "start": "2558220",
    "end": "2564760"
  },
  {
    "text": "whatever you want pretty flexible by default in memory",
    "start": "2564760",
    "end": "2569640"
  },
  {
    "text": "what is the uh experience of trying to debug one of these multi-process beam programs just because I can see",
    "start": "2570880",
    "end": "2579040"
  },
  {
    "text": "from the start if even something as simple as a single command as a completely separate process trying to",
    "start": "2579040",
    "end": "2585099"
  },
  {
    "text": "track thread States across several processes and how they interleave this",
    "start": "2585099",
    "end": "2592359"
  },
  {
    "text": "is an excellent question yeah thank you very much so uh yeah like there is some",
    "start": "2592359",
    "end": "2597400"
  },
  {
    "text": "sort of a debugger in Orlando and I think more recently even like elixir has some of its own kind of Quasi debugging",
    "start": "2597400",
    "end": "2603700"
  },
  {
    "text": "tools which I've never used and I've been doing this stuff for like more than 10 years in production right so this is",
    "start": "2603700",
    "end": "2609220"
  },
  {
    "text": "essentially you know I didn't talk about it this is distributed system we're talking about here in erlang concurrency",
    "start": "2609220",
    "end": "2615220"
  },
  {
    "text": "and distribution are running the same I didn't talk about support for like true distribution multiple machines but it uses the exact same mechanism like you",
    "start": "2615220",
    "end": "2621819"
  },
  {
    "text": "can connect multiple beams into the distributed cluster and you use those same Primitives like I'm going to spawn",
    "start": "2621819",
    "end": "2627280"
  },
  {
    "text": "I'm going to send doesn't matter where the pit points are like is it the local stuff or remote stuff now I'm saying",
    "start": "2627280",
    "end": "2632619"
  },
  {
    "text": "this because you're dealing with distributed problem and then the solution to this is you know observability right and metrics so you",
    "start": "2632619",
    "end": "2639880"
  },
  {
    "text": "want to log you want to make sure that you have like as much as information as possible so you can figure it out like",
    "start": "2639880",
    "end": "2645339"
  },
  {
    "text": "what happens because this stuff runs independent I can't debug like one process while all others are you know",
    "start": "2645339",
    "end": "2650380"
  },
  {
    "text": "waiting",
    "start": "2650380",
    "end": "2652799"
  },
  {
    "text": "so yes you could say like that but it's like all integrated so you have much much easier time like to me this is way",
    "start": "2656380",
    "end": "2661900"
  },
  {
    "text": "Superior to microservices although it doesn't cover exactly the same scenario there are like some overlaps but this is",
    "start": "2661900",
    "end": "2668260"
  },
  {
    "text": "first and foremost more aggressive I don't think you would be doing microservices like having one microservice per mesh for example or",
    "start": "2668260",
    "end": "2673540"
  },
  {
    "text": "dynamically started microservice this goes like into much finer Grant stuff but there are essentially the same set",
    "start": "2673540",
    "end": "2679420"
  },
  {
    "text": "of challenges uh if you think about them except everything is here like available in your language so it's nothing much",
    "start": "2679420",
    "end": "2684760"
  },
  {
    "text": "easier to wield compared to microservices so I want to say again because you have this with microservices",
    "start": "2684760",
    "end": "2690099"
  },
  {
    "text": "unlike with microservices you don't have to be this tall to use this stuff",
    "start": "2690099",
    "end": "2695619"
  },
  {
    "text": "yeah yeah debugging approach definitely I kind of trailed off to some other rambling story yeah okay",
    "start": "2695619",
    "end": "2703500"
  },
  {
    "text": "any other questions oh yeah behind behind you have behind you",
    "start": "2704800",
    "end": "2709859"
  },
  {
    "text": "thanks for the presentation uh may I know whether this model is only available in this language or is it like",
    "start": "2712359",
    "end": "2719859"
  },
  {
    "text": "a common model that's available in other languages as as fast you know sorry can you repeat this I didn't quite",
    "start": "2719859",
    "end": "2726339"
  },
  {
    "text": "understand this message model that you uh showed us today is it only available in the language or is it like a common",
    "start": "2726339",
    "end": "2733839"
  },
  {
    "text": "model available in other languages so this messaging model is exclusive to erlang uh yeah no no no no so there are",
    "start": "2733839",
    "end": "2740920"
  },
  {
    "text": "like uh first and foremost there are like some implementations that are inspired by erlang uh most notably akka",
    "start": "2740920",
    "end": "2746440"
  },
  {
    "text": "for example which you have in a Java and uh I think you have even a.net something like that right uh so did that one is",
    "start": "2746440",
    "end": "2754300"
  },
  {
    "text": "completely inspired by it it is sometimes said that this SRI lank style concurrency is uh actor style",
    "start": "2754300",
    "end": "2760300"
  },
  {
    "text": "concurrency I used to say this myself in my early days but the thing is that like the inventors of erlang they said",
    "start": "2760300",
    "end": "2767260"
  },
  {
    "text": "explicitly they didn't know about actor concurrency when they invented this stuff back in the late 80s on the other",
    "start": "2767260",
    "end": "2773500"
  },
  {
    "text": "hand I also found some place that the inventor of actor model explicitly say that erlang isn't actor implementation",
    "start": "2773500",
    "end": "2779339"
  },
  {
    "text": "so I'm not saying that but it's often referred to as an actor style concurrency either way as far as go is",
    "start": "2779339",
    "end": "2787180"
  },
  {
    "text": "concerned or other CSP concurrency it's a somewhat different style so in there you have like a Communication channel",
    "start": "2787180",
    "end": "2793960"
  },
  {
    "text": "has the identity but your concurrent activity doesn't you can simulate one or the other uh one with the other or vice",
    "start": "2793960",
    "end": "2801579"
  },
  {
    "text": "versa to some extent but I gotta say to me uh and I'm not in invested in this",
    "start": "2801579",
    "end": "2806859"
  },
  {
    "text": "Technologies I'm just a user I did a little bit of go I did a lot of erlang Elixir and to me this model is more far",
    "start": "2806859",
    "end": "2813640"
  },
  {
    "text": "superior or you know writing concurrent fault tolerant systems then what gold does yeah or what CSP does you know I",
    "start": "2813640",
    "end": "2820540"
  },
  {
    "text": "want my activity to have an identity but either way it is kind of similar because it's still like this user space",
    "start": "2820540",
    "end": "2825700"
  },
  {
    "text": "concurrency uh massive lightweight style concurrency yeah",
    "start": "2825700",
    "end": "2830760"
  },
  {
    "text": "in the example of the child process cancellation it works fairly simply in a stateless process but when you have side",
    "start": "2832960",
    "end": "2839980"
  },
  {
    "text": "effects on that child process before the cancellation occurs how do you normally deal with it",
    "start": "2839980",
    "end": "2845020"
  },
  {
    "text": "uh when you have the side effects before the cancer relation occurs what do you want to deal with like do you want to clean them up or",
    "start": "2845020",
    "end": "2851920"
  },
  {
    "text": "so that's what I did with this CI uh thing so that was like pure side effect if you will right so like running a",
    "start": "2851920",
    "end": "2858339"
  },
  {
    "text": "single CI instance means like we're starting some Docker container that's a side effect we're creating some folders",
    "start": "2858339",
    "end": "2864040"
  },
  {
    "text": "for the cache and whatnot that's another side effect right so we will definitely be implementing custom termination to",
    "start": "2864040",
    "end": "2870579"
  },
  {
    "text": "you know clean up whatever garbage we had in particular for caches we actually drained the current command so we will",
    "start": "2870579",
    "end": "2877599"
  },
  {
    "text": "have even if the build is canceled whatever we have come up with at this point we would keep in the cache unlike",
    "start": "2877599",
    "end": "2883540"
  },
  {
    "text": "most other CIS because you know it's stuff on the disk so if anything has changed it's going to be recompiled anyway right but we like we're again",
    "start": "2883540",
    "end": "2890380"
  },
  {
    "text": "this is what you get like when you use a proper language for CI rather than a black box driven by yaml you know",
    "start": "2890380",
    "end": "2898140"
  },
  {
    "text": "mutation on a message to somebody else oh okay so if you send a message to",
    "start": "2900339",
    "end": "2905560"
  },
  {
    "text": "someone else on the remote server like a remote service or whatever like if it's a database of course you want to keep it in transaction for example so that's",
    "start": "2905560",
    "end": "2910839"
  },
  {
    "text": "going to work fine you know as a result of just terminating the process as I said the sockets are process owned so",
    "start": "2910839",
    "end": "2917380"
  },
  {
    "text": "the socket is closed and then the transaction automatically aborts if you're sent to some messaging like said",
    "start": "2917380",
    "end": "2922960"
  },
  {
    "text": "to Kafka then you've sent it you know basically you need to do like a saga pattern right so it's a classical",
    "start": "2922960",
    "end": "2928900"
  },
  {
    "text": "distributed uh problem that you have done right but you have them in beam languages you have them already early on",
    "start": "2928900",
    "end": "2935200"
  },
  {
    "text": "in a good way I would say like so it becomes easier to think about it but yeah if you did a side effect you got a",
    "start": "2935200",
    "end": "2941260"
  },
  {
    "text": "reward the side effect then right somehow yeah",
    "start": "2941260",
    "end": "2945780"
  }
]
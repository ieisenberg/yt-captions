[
  {
    "start": "0",
    "end": "34000"
  },
  {
    "text": "[Music]",
    "start": "980",
    "end": "7849"
  },
  {
    "text": "and I'm talking about production model deployment today so I wanted to give a",
    "start": "13770",
    "end": "20770"
  },
  {
    "text": "bit of context about why why this is",
    "start": "20770",
    "end": "26230"
  },
  {
    "text": "what I chose to talk about why I think this is interesting there we go",
    "start": "26230",
    "end": "35200"
  },
  {
    "start": "34000",
    "end": "312000"
  },
  {
    "text": "why I think this is interesting and this has a lot to do with my background so when I was an undergrad I studied math",
    "start": "35200",
    "end": "42129"
  },
  {
    "text": "and physics and I thought the combination that she was super interesting particularly in classical mechanics and thinking about gravity and",
    "start": "42129",
    "end": "48940"
  },
  {
    "text": "so when I wanted to go to grad school I was debating the merits of doing theoretical physics or applied math and",
    "start": "48940",
    "end": "55089"
  },
  {
    "text": "I had a very wise professor who told me I would have a lot more flexibility with opportunities if I went and studied",
    "start": "55089",
    "end": "61269"
  },
  {
    "text": "applied math and the things I was interested in was numerical simulations of physical systems anyway so same",
    "start": "61269",
    "end": "68770"
  },
  {
    "text": "difference in terms of what I would actually be doing in a theoretical physics program or applied math so I go and I started studying numerical partial",
    "start": "68770",
    "end": "75280"
  },
  {
    "text": "differential equations how to solve them and pretty quickly I get introduced to ideas from machine learning and dimensionality reduction techniques",
    "start": "75280",
    "end": "81430"
  },
  {
    "text": "applied to partial differential equations I thought that was amazing and I got more and more excited about",
    "start": "81430",
    "end": "87310"
  },
  {
    "text": "statistics of machine learning and realized that that is a way in which I wanted to apply my mathematical mind but",
    "start": "87310",
    "end": "97829"
  },
  {
    "text": "despite the name applied math applied math did not feel very applied to me every fluid asked questions why how",
    "start": "97829",
    "end": "104350"
  },
  {
    "text": "would I take this model and actually put it in this system and so I was in a ph.d program and decided to leave and I",
    "start": "104350",
    "end": "110590"
  },
  {
    "text": "wanted to go work in industry and figure out how do you deploy a model what does it mean to deploy a model how do you",
    "start": "110590",
    "end": "116710"
  },
  {
    "text": "actually take this thing that you've built and make it practical and used in a system right so I went interviewed a",
    "start": "116710",
    "end": "123670"
  },
  {
    "text": "bunch hate interviewing and I ended up at a tiny startup that at the time was",
    "start": "123670",
    "end": "129850"
  },
  {
    "text": "called OD hago and quickly became renamed Wiebe data who here's watched Silicon Valley",
    "start": "129850",
    "end": "134920"
  },
  {
    "text": "I lost my mind laughing when I heard motto because it really reminded me of",
    "start": "134920",
    "end": "141370"
  },
  {
    "text": "my first job so we be data ended up being a company that built a real time",
    "start": "141370",
    "end": "147700"
  },
  {
    "text": "machine learning platform particularly for recommendations built on top of patchy HBase and when they hired me they",
    "start": "147700",
    "end": "153579"
  },
  {
    "text": "were like well you kind of know how to code but you're not a software engineer we know we want your math skills eventually how about we pair you up with",
    "start": "153579",
    "end": "160060"
  },
  {
    "text": "someone and teach you engineering and working there and working with my mentor Keon was one of the best experiences",
    "start": "160060",
    "end": "166989"
  },
  {
    "text": "especially first experiences in tech I could imagine so I got to understand what people were doing when they were",
    "start": "166989",
    "end": "173680"
  },
  {
    "text": "thinking about certain types of machine learning problems and putting those into systems I also worked at another failed",
    "start": "173680",
    "end": "179620"
  },
  {
    "text": "startup so none of these things really exist anymore that's about three years of my life of lots of learning and",
    "start": "179620",
    "end": "184780"
  },
  {
    "text": "interesting projects and then I decided to go work at a company that has a name",
    "start": "184780",
    "end": "189790"
  },
  {
    "text": "that people might recognize there's something like called the halo effect right where you work at a company that's",
    "start": "189790",
    "end": "195250"
  },
  {
    "text": "successful people like oh you must have had something to do with it I don't agree with it but it's real and so I",
    "start": "195250",
    "end": "201819"
  },
  {
    "text": "found myself working at Cloudera working with some of our big customers and doing a mix of working on",
    "start": "201819",
    "end": "207609"
  },
  {
    "text": "open-source projects doing things like this going to be talk and come and doing consulting with big customers about what",
    "start": "207609",
    "end": "215139"
  },
  {
    "text": "sort of data science tooling they should have what it means to integrate that into the business how they should be deploying different sorts of models and",
    "start": "215139",
    "end": "222879"
  },
  {
    "text": "I'm now data platform engineer at stitch fix so I will use this as an example of",
    "start": "222879",
    "end": "230230"
  },
  {
    "text": "an example pretty frequently so I'm going to briefly describe what stitch fix does stitch fix is a personal",
    "start": "230230",
    "end": "236560"
  },
  {
    "text": "styling service you fill out a survey with your sizes your preferences things you like or don't like and will",
    "start": "236560",
    "end": "243849"
  },
  {
    "text": "send you a box with five five items either on a schedule or on demand and",
    "start": "243849",
    "end": "249150"
  },
  {
    "text": "behind the scenes we use data absolutely everywhere we have a recommendation algorithm that feeds what items get",
    "start": "249150",
    "end": "256209"
  },
  {
    "text": "shown to stylists that are actually doing the styling for you so it's a mixture of humans and algorithms we have",
    "start": "256209",
    "end": "262360"
  },
  {
    "text": "algorithm algorithm algorithmic buying Andry buying we decide when the clearance items we have good operational",
    "start": "262360",
    "end": "269889"
  },
  {
    "text": "discipline in our warehouse isn't try to optimize that process lots of different things going on here so the algorithms team that",
    "start": "269889",
    "end": "276320"
  },
  {
    "text": "stitch fix is more than a hundred people there's about 80 in data science and",
    "start": "276320",
    "end": "281420"
  },
  {
    "text": "about 20 or so maybe 15 and Data Platform and I've been working on very close very",
    "start": "281420",
    "end": "289100"
  },
  {
    "text": "closely with data scientists building tools for them a good example of using",
    "start": "289100",
    "end": "294980"
  },
  {
    "text": "stitch fix is a frequent question when I give talks while working stitch fix nails am I wearing stitch fix items so",
    "start": "294980",
    "end": "301480"
  },
  {
    "text": "ahead of a bunch of boxes give it an April I order to fix and I was like hey I'm getting ready to give a bunch of",
    "start": "301480",
    "end": "306830"
  },
  {
    "text": "talk send me some things I might want to wear one of the things I got was this necklace smart stylist great so the",
    "start": "306830",
    "end": "314270"
  },
  {
    "start": "312000",
    "end": "363000"
  },
  {
    "text": "agenda today is talking a little bit about the model lifecycle so this entire track that I've been speaking in has",
    "start": "314270",
    "end": "320990"
  },
  {
    "text": "been split up into what the machine learning model building lifecycle looks like and I'm talking about production",
    "start": "320990",
    "end": "326240"
  },
  {
    "text": "deployment but I want to explain how it fits in because production deployment is a really complicated topic and once we",
    "start": "326240",
    "end": "335450"
  },
  {
    "text": "have an understanding of what the lifecycle looks like and what deployment means at least in the context that I'll",
    "start": "335450",
    "end": "340610"
  },
  {
    "text": "be talking about it then I'm gonna talk about some of the deployment challenges and of course solutions to those",
    "start": "340610",
    "end": "345800"
  },
  {
    "text": "challenges that are themselves very challenging but their solutions to those",
    "start": "345800",
    "end": "352520"
  },
  {
    "text": "two and those are also pretty hard and",
    "start": "352520",
    "end": "357830"
  },
  {
    "text": "so hopefully the message that you'll take away from this is not that this is too hard to be done but I'll hopefully",
    "start": "357830",
    "end": "363710"
  },
  {
    "text": "give you a framework to ask questions about your production model deployment and help you understand what places to",
    "start": "363710",
    "end": "371330"
  },
  {
    "text": "dig in and look because there's a huge variety of types of models and types of requirements you have her systems but",
    "start": "371330",
    "end": "377600"
  },
  {
    "text": "there's consistent questions that you can ask across those systems to figure out if you are accurately covering your",
    "start": "377600",
    "end": "384620"
  },
  {
    "text": "bases in your deployment so the lifecycle I like to think of data",
    "start": "384620",
    "end": "389840"
  },
  {
    "start": "386000",
    "end": "403000"
  },
  {
    "text": "scientist support as black boxes you put it in and services and dashboards come",
    "start": "389840",
    "end": "396170"
  },
  {
    "text": "out we're gonna focus on the process of putting data in and a",
    "start": "396170",
    "end": "402789"
  },
  {
    "text": "model coming out and perhaps fine I admit we won't actually talk about them",
    "start": "402789",
    "end": "408520"
  },
  {
    "start": "403000",
    "end": "424000"
  },
  {
    "text": "as black boxes I just kind of like that as a joke for what they do I like to imagine that inside of that mysterious",
    "start": "408520",
    "end": "414580"
  },
  {
    "text": "world of model building that's just a lot of writing on chalkboards and dream of dreaming about equations in reality",
    "start": "414580",
    "end": "422110"
  },
  {
    "text": "that's not actually the process what we've been talking about today is this whole process of there's a bunch of data",
    "start": "422110",
    "end": "428560"
  },
  {
    "start": "424000",
    "end": "481000"
  },
  {
    "text": "and in a large organization we'll be inside of a data warehouse there is some sort of feature ization where you're",
    "start": "428560",
    "end": "434710"
  },
  {
    "text": "taking the state of warehouse and building up enough information for you to apply our models to you're doing",
    "start": "434710",
    "end": "440020"
  },
  {
    "text": "model training should I go okay yeah no",
    "start": "440020",
    "end": "459280"
  },
  {
    "text": "I feel pretty cozy this part of it this",
    "start": "459280",
    "end": "464409"
  },
  {
    "text": "part of the video is gonna be really exciting for people watching so right",
    "start": "464409",
    "end": "470349"
  },
  {
    "text": "these feature is it Jen you do training where you produce a model you're then gonna apply that model in this sort of",
    "start": "470349",
    "end": "475750"
  },
  {
    "text": "batch model building process and do a model validation so fabulous we've built",
    "start": "475750",
    "end": "484060"
  },
  {
    "text": "a model we're gonna deploy it time for liftoff we're putting this thing in production what does that mean well I",
    "start": "484060",
    "end": "492729"
  },
  {
    "start": "491000",
    "end": "499000"
  },
  {
    "text": "think of deployment as sharing you've built some sort of artifact and you need to share it with other people so the",
    "start": "492729",
    "end": "499270"
  },
  {
    "start": "499000",
    "end": "596000"
  },
  {
    "text": "question is then in what method will you be sharing this model I think that there's three types of model deployment",
    "start": "499270",
    "end": "506190"
  },
  {
    "text": "mechanisms one is building a service so putting the model inside of an API you",
    "start": "506190",
    "end": "512770"
  },
  {
    "text": "give it some data it gives you your your predicted response so in the case of stitch fix recommendations we might say",
    "start": "512770",
    "end": "519399"
  },
  {
    "text": "here's a client ID or here's a bunch of information about a client tell us what items they might be interested in you",
    "start": "519399",
    "end": "525760"
  },
  {
    "text": "can also share a model by sharing this output written to a file and so",
    "start": "525760",
    "end": "531260"
  },
  {
    "text": "is an example of something that I'd seen in situations where you have really long",
    "start": "531260",
    "end": "536830"
  },
  {
    "text": "turnaround times and it's not important that the model is super reactive so a",
    "start": "536830",
    "end": "542000"
  },
  {
    "text": "good example is a telecom companies I've seen churn models be put into production",
    "start": "542000",
    "end": "547580"
  },
  {
    "text": "by having a reliable pipeline that applies a model in a batch that even writes out a file of here's the churn",
    "start": "547580",
    "end": "553760"
  },
  {
    "text": "propensity score for each of our customers and the reason that that doesn't really need to be put behind a",
    "start": "553760",
    "end": "559220"
  },
  {
    "text": "service is that they basically have a cron job that's gonna email people every day or set off some other sort of batch",
    "start": "559220",
    "end": "565490"
  },
  {
    "text": "process at the highest churn likelihood of customers and so it's not really important that this is behind the",
    "start": "565490",
    "end": "570860"
  },
  {
    "text": "service and being reactive and web application of any of any kind it's more important that there's just a big list",
    "start": "570860",
    "end": "575990"
  },
  {
    "text": "that some process can look at and then the third way which is probably the least common that's still possible and",
    "start": "575990",
    "end": "583040"
  },
  {
    "text": "I've seen it happen is through a software package so you can imagine having built a model and putting",
    "start": "583040",
    "end": "589250"
  },
  {
    "text": "parameters in it and then deploying it to some package repository where someone else can download that model and use it",
    "start": "589250",
    "end": "596050"
  },
  {
    "start": "596000",
    "end": "759000"
  },
  {
    "text": "well I keep talking about models like it means something and I think that there's",
    "start": "596050",
    "end": "601850"
  },
  {
    "text": "actually a lot of terms in machine learning data science AI that are pretty",
    "start": "601850",
    "end": "608300"
  },
  {
    "text": "poorly defined and I think model is one of them there's lots of context we'd use the phrase model and so when I'm gonna",
    "start": "608300",
    "end": "614060"
  },
  {
    "text": "be talking about models here and deploying models what do I actually mean well in the context of this talk when I",
    "start": "614060",
    "end": "621980"
  },
  {
    "text": "say model I mean it's the thing that that knows enough about itself to know",
    "start": "621980",
    "end": "628220"
  },
  {
    "text": "how to apply itself so let's say I've trained a linear regression model and",
    "start": "628220",
    "end": "633260"
  },
  {
    "text": "what's happened here is I go from a CSV which is a bunch of strings and features it's not quite in the right format to",
    "start": "633260",
    "end": "639650"
  },
  {
    "text": "have regression applied to it yet there needs to be maybe some encoding of variables or transformations and then",
    "start": "639650",
    "end": "646880"
  },
  {
    "text": "there actually needs to be an application of that train model like you've learned all of the weights for",
    "start": "646880",
    "end": "653000"
  },
  {
    "text": "your different put all the weights or different coefficients in your model and you need to know how to apply that and",
    "start": "653000",
    "end": "658160"
  },
  {
    "text": "so I would say that models are the feature is Asian steps maybe the",
    "start": "658160",
    "end": "665190"
  },
  {
    "text": "type of model the learned weights and all of the logic that you need to apply that so how do you actually take a model",
    "start": "665190",
    "end": "674580"
  },
  {
    "text": "and move it from this training process up at the top to an application process",
    "start": "674580",
    "end": "680190"
  },
  {
    "text": "so you get a new observation you then need to apply this model through doing that the same sort of feature ization",
    "start": "680190",
    "end": "685920"
  },
  {
    "text": "you did in your model training steps and then take the model that you've learned and apply it to the end of that future",
    "start": "685920",
    "end": "692550"
  },
  {
    "text": "ization and reply with the response you move models through serialization this",
    "start": "692550",
    "end": "699300"
  },
  {
    "text": "is perpetually my favorite joke because it's kind of makes my mouth water a little bit but also thanks my teeth hurt",
    "start": "699300",
    "end": "705930"
  },
  {
    "text": "just looking at the picture so serialization ends up being really important we need some way of transporting this information between",
    "start": "705930",
    "end": "712530"
  },
  {
    "text": "two different workflows and processes when you're applying a model you're not also simultaneously training it so what",
    "start": "712530",
    "end": "721190"
  },
  {
    "text": "what can this mean and what is it that we're gonna be doing in serialization to make this reasonable for us so I said",
    "start": "721190",
    "end": "727680"
  },
  {
    "text": "we're gonna focus on one type of one of these types of model deployment we're gonna focus on a building a service that",
    "start": "727680",
    "end": "734670"
  },
  {
    "text": "responds in an API so this is extremely common you see a ton of companies you're",
    "start": "734670",
    "end": "739890"
  },
  {
    "text": "gonna build a service it's gonna be a model app model scoring service and that",
    "start": "739890",
    "end": "745260"
  },
  {
    "text": "determines how we want to serialize our model and how we want to serialize our",
    "start": "745260",
    "end": "750930"
  },
  {
    "text": "model and what sort of format that serialization takes because then we need",
    "start": "750930",
    "end": "756810"
  },
  {
    "text": "to be able to load it into our service so I claim we need to do some sort of",
    "start": "756810",
    "end": "763110"
  },
  {
    "start": "759000",
    "end": "776000"
  },
  {
    "text": "serialization and then we need to be able to load that serialization in a web",
    "start": "763110",
    "end": "768750"
  },
  {
    "text": "server and that is deployment it seems easy enough right it's mostly a problem serialization well",
    "start": "768750",
    "end": "777050"
  },
  {
    "start": "776000",
    "end": "860000"
  },
  {
    "text": "once you come to the point that you know you've made a model and you know you need to write it out somewhere and then",
    "start": "777050",
    "end": "782460"
  },
  {
    "text": "read it in again you need to think beyond that simple",
    "start": "782460",
    "end": "788220"
  },
  {
    "text": "interface as there's three classes of questions that I think we should be in",
    "start": "788220",
    "end": "793420"
  },
  {
    "text": "so first is does your model do what you",
    "start": "793420",
    "end": "798970"
  },
  {
    "text": "need both at a very basic level of does this thing function does this but then",
    "start": "798970",
    "end": "805210"
  },
  {
    "text": "beyond that does this same function as you expect it to when you did your validation offline it seemed effective",
    "start": "805210",
    "end": "810850"
  },
  {
    "text": "but is it actually making you more money now is it actually getting you more clicks whatever it is you're trying to",
    "start": "810850",
    "end": "816040"
  },
  {
    "text": "optimize for it does it meet your engineering requirements so this could be things like throughput and latency",
    "start": "816040",
    "end": "822840"
  },
  {
    "text": "common concerns and is your team actually organized to build and support",
    "start": "822840",
    "end": "828130"
  },
  {
    "text": "this type of model and I think this last question is really interesting because data-driven capabilities at the scale",
    "start": "828130",
    "end": "834910"
  },
  {
    "text": "that we're seeing are relatively new in the industry and I think we're still trying to figure out how to best build",
    "start": "834910",
    "end": "841660"
  },
  {
    "text": "teams that know how to build these capabilities and to actually support them and I think that team structure is",
    "start": "841660",
    "end": "848530"
  },
  {
    "text": "very very intertwined with the types of systems that we end up being capable of building especially when there's so many",
    "start": "848530",
    "end": "854710"
  },
  {
    "text": "diverse get sets of skills that are required to build these services so does",
    "start": "854710",
    "end": "860920"
  },
  {
    "start": "860000",
    "end": "911000"
  },
  {
    "text": "it function well beyond unit testing where you've built a server and you're like okay I know how to load the",
    "start": "860920",
    "end": "866050"
  },
  {
    "text": "serialize model in some way you now have the service up is it functioning at the",
    "start": "866050",
    "end": "872620"
  },
  {
    "text": "very most basic level this is the same thing you would do for any other service you need to make sure that there's",
    "start": "872620",
    "end": "878230"
  },
  {
    "text": "logging you need to make sure that you're doing monitoring on it are you having really spiky memory usage are you",
    "start": "878230",
    "end": "888090"
  },
  {
    "text": "like is your CPU CPU load too high sometimes things like that relatively",
    "start": "888090",
    "end": "893620"
  },
  {
    "text": "simple straightforward if you've done any other web service related work it's the same thing set up pager duty have",
    "start": "893620",
    "end": "900670"
  },
  {
    "text": "things alert there's a question of what exactly you want to learn even when but",
    "start": "900670",
    "end": "906010"
  },
  {
    "text": "pretty straightforward answer - does this thing function does it continue to work after you've set it up a more",
    "start": "906010",
    "end": "913060"
  },
  {
    "start": "911000",
    "end": "960000"
  },
  {
    "text": "interesting question to ask that's a little more close to the mathematical end of it and the sort of responsive Dre",
    "start": "913060",
    "end": "918880"
  },
  {
    "text": "data driven capability they're trying to provide is is this thing that you've built actually useful so there's a quote",
    "start": "918880",
    "end": "926110"
  },
  {
    "text": "that's maybe it's more of an aphorism treated as a quote people repeated a lot but I",
    "start": "926110",
    "end": "931170"
  },
  {
    "text": "don't he was ever quite said succinctly but the summarization of a lot of things that George box has said of the famous",
    "start": "931170",
    "end": "938550"
  },
  {
    "text": "box plots is all models are wrong and some are useful so the question is we",
    "start": "938550",
    "end": "945900"
  },
  {
    "text": "built this model we sterilized it in some format I'll talk about once we",
    "start": "945900",
    "end": "954630"
  },
  {
    "text": "start using it in our systems is it doing what we need there's really only",
    "start": "954630",
    "end": "960930"
  },
  {
    "start": "960000",
    "end": "1008000"
  },
  {
    "text": "one standard best practice way to determine that and that is to do a/b",
    "start": "960930",
    "end": "966270"
  },
  {
    "text": "testing to do an experiment and so what happens here is that we split this we split the things are making predictions",
    "start": "966270",
    "end": "973140"
  },
  {
    "text": "on so let's say we're making recommendations of clothing between clients and people between clients and",
    "start": "973140",
    "end": "980040"
  },
  {
    "text": "items we would split our clients into a control group and an experiment group so",
    "start": "980040",
    "end": "986040"
  },
  {
    "text": "two different treatments and some people would get one set of recommendations when other people would get a different",
    "start": "986040",
    "end": "991920"
  },
  {
    "text": "set and we would compare those two to see if there's a statistical difference that's all well and good there are",
    "start": "991920",
    "end": "998310"
  },
  {
    "text": "standard ways to go about doing that that's absolutely something that every company that I've heard of that treats",
    "start": "998310",
    "end": "1003620"
  },
  {
    "text": "machine learning in the serious way does before they were allotted a new model what about forever right a B testing is",
    "start": "1003620",
    "end": "1013190"
  },
  {
    "start": "1008000",
    "end": "1135000"
  },
  {
    "text": "good you take the small e put it into production do you leave it there for a month and just wait to see if Pedro Duty",
    "start": "1013190",
    "end": "1018560"
  },
  {
    "text": "rings and figure it's kind of working all right I think there's this interesting long-term view of model",
    "start": "1018560",
    "end": "1029329"
  },
  {
    "text": "quality that is pretty hard to approach I think so if you think about it as a/b testing you could say well if we want to",
    "start": "1029329",
    "end": "1035780"
  },
  {
    "text": "see if this model continues to do as well as it did at during the a/b test into the future what we do is we run",
    "start": "1035780",
    "end": "1041180"
  },
  {
    "text": "this a B test forever we never stop someone is always some population is always in a control group",
    "start": "1041180",
    "end": "1048050"
  },
  {
    "text": "and this is something that you can do and I've heard of companies doing this so if you are on an app and it never",
    "start": "1048050",
    "end": "1053660"
  },
  {
    "text": "changes and all of your friends have a different one this might be happening to you you might be the control but it's also relatively",
    "start": "1053660",
    "end": "1060360"
  },
  {
    "text": "uncommon because when there's product managers or product minded people around they're pretty hesitant to say that",
    "start": "1060360",
    "end": "1066090"
  },
  {
    "text": "there's gonna be some group of users that never see any changes because if you think you're actually improving the",
    "start": "1066090",
    "end": "1071130"
  },
  {
    "text": "quality of what you're building you want people to be able to see that to use that so permanent and infinite a be test",
    "start": "1071130",
    "end": "1079919"
  },
  {
    "text": "is a possibility it happens sometimes but there may be other things that you can do to look at your model in",
    "start": "1079919",
    "end": "1087150"
  },
  {
    "text": "production and see if it's actually doing what you need it to do so you can look at things like distributions of",
    "start": "1087150",
    "end": "1092460"
  },
  {
    "text": "features distributions of predictions and these might change based on the population coming in changing but it gives you some",
    "start": "1092460",
    "end": "1099570"
  },
  {
    "text": "sense of what might be going on in the model and some sort of way to catch and",
    "start": "1099570",
    "end": "1104880"
  },
  {
    "text": "debug things in production what is maybe",
    "start": "1104880",
    "end": "1110600"
  },
  {
    "text": "what is maybe useful in thinking about this is measuring things that tell you",
    "start": "1110929",
    "end": "1116580"
  },
  {
    "text": "how often you need to refresh your model so you can imagine that instead of",
    "start": "1116580",
    "end": "1123240"
  },
  {
    "text": "building a single model that you then throw into production and is there forever what you're actually needed to",
    "start": "1123240",
    "end": "1129090"
  },
  {
    "text": "determine is figure out how frequently you need to to rebuild these models so I",
    "start": "1129090",
    "end": "1136559"
  },
  {
    "start": "1135000",
    "end": "1193000"
  },
  {
    "text": "would claim that when you deploy a machine learning model into production you're not actually saying I have built",
    "start": "1136559",
    "end": "1142049"
  },
  {
    "text": "one model it is the best model this model is now this thing that is in production and we shall use it forever",
    "start": "1142049",
    "end": "1149240"
  },
  {
    "text": "more likely deploying a model into production means deploying the entire",
    "start": "1149240",
    "end": "1154260"
  },
  {
    "text": "pipeline of model building and making that much more repeatable and rigorous",
    "start": "1154260",
    "end": "1159660"
  },
  {
    "text": "so in the case of recommendations that stitch fix which again I said repeat we",
    "start": "1159660",
    "end": "1167130"
  },
  {
    "text": "have new clients coming in every day and we have new items coming in every day and so it's useful for us to rebuild our",
    "start": "1167130",
    "end": "1173940"
  },
  {
    "text": "recommendation models on a daily basis because we need to include both of those in them there might be other reasons you",
    "start": "1173940",
    "end": "1180690"
  },
  {
    "text": "want to be rebuilding your models you get more information about behavior and",
    "start": "1180690",
    "end": "1186679"
  },
  {
    "text": "more information that goes into your density s2 that are feeding into your machine learning models so would you mind",
    "start": "1186679",
    "end": "1196040"
  },
  {
    "start": "1193000",
    "end": "1277000"
  },
  {
    "text": "holding it to the end of the talk thank you so when you deploy a model you are",
    "start": "1196040",
    "end": "1204680"
  },
  {
    "text": "deploying you are deploying pipelines you're not necessarily deploying that single model that you've actually made",
    "start": "1204680",
    "end": "1211030"
  },
  {
    "text": "so this pipeline you need to set up in some sort of schedule you need to figure out what that schedule is and so going",
    "start": "1211030",
    "end": "1218300"
  },
  {
    "text": "back to this does this model continue to be useful question I think useful things",
    "start": "1218300",
    "end": "1224540"
  },
  {
    "text": "to begin to monitor here that feed into how frequently you rebuild your model",
    "start": "1224540",
    "end": "1230030"
  },
  {
    "text": "and how regularly you need this pipeline to run it's very related to how you get",
    "start": "1230030",
    "end": "1235100"
  },
  {
    "text": "shift in your estimated features in your estimated predictions and so that's one",
    "start": "1235100",
    "end": "1240320"
  },
  {
    "text": "way you can begin to debug or answer the question of how frequently does this model need to be retrained I've",
    "start": "1240320",
    "end": "1246380"
  },
  {
    "text": "definitely seen daily I've seen a weekly I've seen monthly in some cases I've seen never because people have forgotten",
    "start": "1246380",
    "end": "1252140"
  },
  {
    "text": "how they built the model in the first place which is a fascinating and real thing that happens so deploy machinery",
    "start": "1252140",
    "end": "1261560"
  },
  {
    "text": "modeler production means deploying the entire pipeline and building this the whole like every piece of the step",
    "start": "1261560",
    "end": "1267710"
  },
  {
    "text": "hopefully did some validation still at the end to catch if you somehow introduced a bug or there's something weird happening in the data and then you",
    "start": "1267710",
    "end": "1274310"
  },
  {
    "text": "get a new serialize model it goes into your systems so when are you doing this I would say you can do this on some",
    "start": "1274310",
    "end": "1281420"
  },
  {
    "start": "1277000",
    "end": "1298000"
  },
  {
    "text": "regular cadence and I talked about nightly because that's extremely common but think of nightly as any type of",
    "start": "1281420",
    "end": "1288020"
  },
  {
    "text": "regular cadence so it's a cron job that rebuilds your models or you could be",
    "start": "1288020",
    "end": "1293870"
  },
  {
    "text": "doing this continuously and these are two very different modes of model deployment so when you're doing",
    "start": "1293870",
    "end": "1299510"
  },
  {
    "start": "1298000",
    "end": "1341000"
  },
  {
    "text": "something on a regular schedule every night for every six hours you're",
    "start": "1299510",
    "end": "1304520"
  },
  {
    "text": "essentially using cron or some sort of time-based system lots of data scientists don't like using cron because",
    "start": "1304520",
    "end": "1312080"
  },
  {
    "text": "it's not that fun to use and also these machine learning pipelines end up being really complicated there's multiple",
    "start": "1312080",
    "end": "1319100"
  },
  {
    "text": "steps you get fan-out Shannon and to to work on this to have an easier",
    "start": "1319100",
    "end": "1325720"
  },
  {
    "text": "interface for these complex model building pipelines people have developed tools so in the past I've used",
    "start": "1325720",
    "end": "1332049"
  },
  {
    "text": "luzie Luigi was popular for a while airflow seems to be popular now these are tools for orchestrating complex",
    "start": "1332049",
    "end": "1338500"
  },
  {
    "text": "pipelines and then scheduling them to run on a regular basis so this is",
    "start": "1338500",
    "end": "1347860"
  },
  {
    "start": "1341000",
    "end": "1409000"
  },
  {
    "text": "missing its title but what this is a representation of is the lambda architecture and so this is an example",
    "start": "1347860",
    "end": "1353770"
  },
  {
    "text": "of how you can continuously train your model I don't want to discuss this in",
    "start": "1353770",
    "end": "1360010"
  },
  {
    "text": "detail but I do want to show you the drawing because you can see that there's a lot going on in this picture so what",
    "start": "1360010",
    "end": "1366669"
  },
  {
    "text": "is happening here is that the lambda architecture provides a framework for thinking about how to take in data about",
    "start": "1366669",
    "end": "1374410"
  },
  {
    "text": "your client behavior about your user behavior and update model parameters as",
    "start": "1374410",
    "end": "1379650"
  },
  {
    "text": "new information comes in and use that continuously updated model to apply to",
    "start": "1379650",
    "end": "1388270"
  },
  {
    "text": "whatever predictions you're trying to make and so you can you can think of this as as keeping partial estimates of",
    "start": "1388270",
    "end": "1397390"
  },
  {
    "text": "the entire model and updating those continuously so it's possible to do this",
    "start": "1397390",
    "end": "1403630"
  },
  {
    "text": "but as you can see it is more complicated than running an ETL pipeline you're familiar with every night so if",
    "start": "1403630",
    "end": "1413049"
  },
  {
    "start": "1409000",
    "end": "1531000"
  },
  {
    "text": "we know that it does what we want it to it runs it's accurate do we actually",
    "start": "1413049",
    "end": "1420940"
  },
  {
    "text": "know that it meets our requirements so this gets into the what are our engineering requirements and what are we",
    "start": "1420940",
    "end": "1426730"
  },
  {
    "text": "actually aiming to optimize I think frequently people don't take a step back and ask themselves what are the things",
    "start": "1426730",
    "end": "1433390"
  },
  {
    "text": "that are hard about this what do we actually need to optimize for and they can get pretty astray in what they're",
    "start": "1433390",
    "end": "1440530"
  },
  {
    "text": "focusing on and so I strongly recommend before you think about building a",
    "start": "1440530",
    "end": "1446260"
  },
  {
    "text": "machine learning model asking yourself what kind of latency requirements do you have how fast is this modeling to be",
    "start": "1446260",
    "end": "1451450"
  },
  {
    "text": "applied kind of throughput is required and do you need a system that is built nightly",
    "start": "1451450",
    "end": "1458240"
  },
  {
    "text": "or does the freshness of the model really need to be baked into the way",
    "start": "1458240",
    "end": "1464630"
  },
  {
    "text": "that you're applying the model itself so something like the lamda architecture an",
    "start": "1464630",
    "end": "1469640"
  },
  {
    "text": "example of the system that needed something like this what's continuously updating its own model is Google News so",
    "start": "1469640",
    "end": "1478220"
  },
  {
    "text": "there's a really great paper called Google News scalable online",
    "start": "1478220",
    "end": "1484030"
  },
  {
    "text": "personalization I believe and they talk about the system that they built and why they needed it so news articles are",
    "start": "1484030",
    "end": "1490160"
  },
  {
    "text": "coming in quickly and they need to be able to incorporate new news art news articles into their systems and as",
    "start": "1490160",
    "end": "1496850"
  },
  {
    "text": "people are clicking around and looking at different items they need to be able to surface rising stories and so that's",
    "start": "1496850",
    "end": "1503570"
  },
  {
    "text": "a very time constraint and they need to be able to incorporate those new articles into their systems quickly so",
    "start": "1503570",
    "end": "1510440"
  },
  {
    "text": "they needed something that has intense latency requirements in terms of updating the model itself not in terms",
    "start": "1510440",
    "end": "1516830"
  },
  {
    "text": "of just the model application so taking a step back before you ever dig into",
    "start": "1516830",
    "end": "1524320"
  },
  {
    "text": "thinking about building the data during capability and building these types of systems helps you focus on what it is",
    "start": "1524320",
    "end": "1529940"
  },
  {
    "text": "you need to do so throughput if you have a relatively simple model meaning a",
    "start": "1529940",
    "end": "1537500"
  },
  {
    "start": "1531000",
    "end": "1630000"
  },
  {
    "text": "stateless model you've sterilized some Watson like a linear regression model you have a server that knows how to load that serialize regression model and",
    "start": "1537500",
    "end": "1543830"
  },
  {
    "text": "apply it to new data it's relatively easy to have that account for higher",
    "start": "1543830",
    "end": "1550910"
  },
  {
    "text": "throughput what we do at stitch fix is we put things behind we put these models behind a load balancer and we just add",
    "start": "1550910",
    "end": "1556760"
  },
  {
    "text": "more instances beautiful wonderful",
    "start": "1556760",
    "end": "1562010"
  },
  {
    "text": "simple and a lot of the way that our Cyril is serialization works currently is that this state store is something",
    "start": "1562010",
    "end": "1569870"
  },
  {
    "text": "that's being read by the server every time it's about States for itself is updated so this is you can imagine as a",
    "start": "1569870",
    "end": "1577190"
  },
  {
    "text": "database of parameters for models let's say you want to deploy a new regression model you say hey my regression model",
    "start": "1577190",
    "end": "1582800"
  },
  {
    "text": "name is blank and these are the features that I'm using here are the weights for them and",
    "start": "1582800",
    "end": "1588320"
  },
  {
    "text": "then in the server the server's know how to reload based on new data their update",
    "start": "1588320",
    "end": "1595400"
  },
  {
    "text": "the parameters that are being used in during model application and we can just add as many service as we need if there",
    "start": "1595400",
    "end": "1602000"
  },
  {
    "text": "is a lot of need for it if you have something more complicated so not these",
    "start": "1602000",
    "end": "1609520"
  },
  {
    "text": "relatively stateless servers something more like this lambda architecture and",
    "start": "1609520",
    "end": "1615860"
  },
  {
    "text": "then like Google News made the question of throughput is a lot more complicated I don't feel the need to talk about it",
    "start": "1615860",
    "end": "1621320"
  },
  {
    "text": "right now but there are there are huge trade-offs in working with a system like this or deciding that that's the system",
    "start": "1621320",
    "end": "1628669"
  },
  {
    "text": "that you need then the question is okay sure is your model fast enough having a",
    "start": "1628669",
    "end": "1635960"
  },
  {
    "text": "goal ahead of time before you start optimizing it to make it the fat as fast as possible is absolutely a great idea",
    "start": "1635960",
    "end": "1643040"
  },
  {
    "text": "otherwise you can go indefinitely in optimizations that get you relatively little one approach for making your",
    "start": "1643040",
    "end": "1651110"
  },
  {
    "text": "models faster is to use approximation methods and different tricks so there",
    "start": "1651110",
    "end": "1656929"
  },
  {
    "text": "are things like hashing tricks and the dimensionality reduction projection tricks seeing the shadow of a data stud",
    "start": "1656929",
    "end": "1663080"
  },
  {
    "text": "and building a model off that instead and we're generally working with smaller data at application time those are",
    "start": "1663080",
    "end": "1670040"
  },
  {
    "text": "interesting but specialized and seeing the patterns of how those mapped to certain types of problems and certain",
    "start": "1670040",
    "end": "1676400"
  },
  {
    "text": "types of models are again beyond the scope of this talk well there are also",
    "start": "1676400",
    "end": "1681650"
  },
  {
    "start": "1679000",
    "end": "1784000"
  },
  {
    "text": "other relatively straightforward ways to make things faster one is materializing data that you need at application time",
    "start": "1681650",
    "end": "1689110"
  },
  {
    "text": "so a really really common technique is to have something called a feature store",
    "start": "1689110",
    "end": "1695419"
  },
  {
    "text": "where when we said we were taking that section of the model pipeline or we do",
    "start": "1695419",
    "end": "1700790"
  },
  {
    "text": "future ization a model applicate application and that was going to be the thing that we serialized and deployed",
    "start": "1700790",
    "end": "1706100"
  },
  {
    "text": "into production we can think of splitting what we're deploying into production as two things there's a",
    "start": "1706100",
    "end": "1712010"
  },
  {
    "text": "feature ization step and a model application step features a ssin if let's say the only",
    "start": "1712010",
    "end": "1717479"
  },
  {
    "text": "thing that we're getting in is a client ID or a user ID if what we needed to do",
    "start": "1717479",
    "end": "1722789"
  },
  {
    "text": "was go out to a database and join together a bunch of tables to get all of the information about a user and then do",
    "start": "1722789",
    "end": "1729929"
  },
  {
    "text": "some processing to get it to the point that it now looks like a feature vector and apply our model to it that could be",
    "start": "1729929",
    "end": "1735419"
  },
  {
    "text": "extremely slow you can think of a future store as pre materializing the feature",
    "start": "1735419",
    "end": "1741899"
  },
  {
    "text": "information for a user or a client so that once you get a new client ID you don't have to do a bunch of computation",
    "start": "1741899",
    "end": "1747720"
  },
  {
    "text": "you can just look up what features are associated with your model and then take your model and the parameters that",
    "start": "1747720",
    "end": "1753059"
  },
  {
    "text": "you've learned and apply it of course this itself is challenging because you could have a futurist or",
    "start": "1753059",
    "end": "1760409"
  },
  {
    "text": "that is out of sync with your model you need to be pretty careful about deployments to things and having a few",
    "start": "1760409",
    "end": "1765929"
  },
  {
    "text": "things match up in terms of what version of it you're using you could imagine that you change the type of model that",
    "start": "1765929",
    "end": "1770999"
  },
  {
    "text": "you're using but you still look up the data that you used in different model training steps so that's a bug that I",
    "start": "1770999",
    "end": "1777809"
  },
  {
    "text": "had seen happen before so this is the solution to latency problems but it comes with its own challenges another",
    "start": "1777809",
    "end": "1785940"
  },
  {
    "start": "1784000",
    "end": "1843000"
  },
  {
    "text": "way to do this is to materialise model output ahead of time so thinking back to",
    "start": "1785940",
    "end": "1791729"
  },
  {
    "text": "the churn example if you have not huge",
    "start": "1791729",
    "end": "1796950"
  },
  {
    "text": "numbers of customers and you want to be able to predict churn based on features",
    "start": "1796950",
    "end": "1804299"
  },
  {
    "text": "that are not changing very quickly every night you could just run you could just",
    "start": "1804299",
    "end": "1810539"
  },
  {
    "text": "run a job that outputs the predictions to a file and then one see or to a database and then once you need the",
    "start": "1810539",
    "end": "1816509"
  },
  {
    "text": "prediction you look up what that is this is extremely fast the challenge here is",
    "start": "1816509",
    "end": "1821700"
  },
  {
    "text": "it only really works with problems that have bounded domains and are not",
    "start": "1821700",
    "end": "1826879"
  },
  {
    "text": "extremely responsive to new inputs so if what you need is that person and what",
    "start": "1826879",
    "end": "1833729"
  },
  {
    "text": "time of day it is right now to get to your prediction then this is not a system that will work for you or not have sort of trick for speeding things",
    "start": "1833729",
    "end": "1839879"
  },
  {
    "text": "up that will actually function adequately and the Evergreen solution to speeding",
    "start": "1839879",
    "end": "1847450"
  },
  {
    "start": "1843000",
    "end": "1911000"
  },
  {
    "text": "things up here's what we'll do we'll take the model and where we write it in C this is actually extremely common so",
    "start": "1847450",
    "end": "1859500"
  },
  {
    "text": "yeah this is extremely common when I was working at Cloudera with a lot of",
    "start": "1861480",
    "end": "1867630"
  },
  {
    "text": "different companies and seeing how their systems work and how they're integrating data science into their businesses",
    "start": "1867630",
    "end": "1875000"
  },
  {
    "text": "frequently there would be a team of data scientists that would build some kind of model that they wanted to put new production and then once they had the",
    "start": "1875000",
    "end": "1882000"
  },
  {
    "text": "model that was ready they would take it to a bunch of engineers and say hey built this thing it's your job to go",
    "start": "1882000",
    "end": "1889350"
  },
  {
    "text": "implement it now this has the potential to be straightforward and fast but",
    "start": "1889350",
    "end": "1896730"
  },
  {
    "text": "instead what I've seen is that the handoff this process of taking a team of engineers and having team of engineers",
    "start": "1896730",
    "end": "1904019"
  },
  {
    "text": "at end one data scientist having a strong split between the results in a",
    "start": "1904019",
    "end": "1909149"
  },
  {
    "text": "really really slow process and a really error-prone process so",
    "start": "1909149",
    "end": "1917629"
  },
  {
    "start": "1911000",
    "end": "1957000"
  },
  {
    "text": "frequently an engineer will sit down for an hour talk about this model that's",
    "start": "1922130",
    "end": "1928970"
  },
  {
    "text": "been built I think they understand it go off and coat it we come back a week",
    "start": "1928970",
    "end": "1934789"
  },
  {
    "text": "later and if the predictions are different why great question you feel",
    "start": "1934789",
    "end": "1941240"
  },
  {
    "text": "like you're in a comfortable place but you're a little bit stuck and so predictions being different not",
    "start": "1941240",
    "end": "1946280"
  },
  {
    "text": "being able to actually implement the model as it's specified also extremely",
    "start": "1946280",
    "end": "1952429"
  },
  {
    "text": "common and this I think then gets to the",
    "start": "1952429",
    "end": "1959419"
  },
  {
    "start": "1957000",
    "end": "1992000"
  },
  {
    "text": "point that I've brought up about data science being a pretty new field and",
    "start": "1959419",
    "end": "1966080"
  },
  {
    "text": "people not quite understanding what it means to have a certain structure of a team and how that then translates into",
    "start": "1966080",
    "end": "1971929"
  },
  {
    "text": "the software that they build so Conway's law is accurate and just once I learned",
    "start": "1971929",
    "end": "1977929"
  },
  {
    "text": "it I started seeing it everywhere which i think is a type of bias but that's fine the way it's stated is that",
    "start": "1977929",
    "end": "1983929"
  },
  {
    "text": "organizations which design systems are constrained to produce designs which are copies of the communication structures",
    "start": "1983929",
    "end": "1990470"
  },
  {
    "text": "of those organizations so thinking back to having a team where you have software",
    "start": "1990470",
    "end": "1998450"
  },
  {
    "start": "1992000",
    "end": "2012000"
  },
  {
    "text": "engineers that are split off from data scientist you need you necessarily need this handoff where there's model",
    "start": "1998450",
    "end": "2005110"
  },
  {
    "text": "building on one side a model deployment on the other side so typical data",
    "start": "2005110",
    "end": "2014380"
  },
  {
    "start": "2012000",
    "end": "2028000"
  },
  {
    "text": "science departments look something like this we have data engineers that produce features for data scientists data",
    "start": "2014380",
    "end": "2020260"
  },
  {
    "text": "scientists produce models for software engineers and then data infrastructure engineers are providing infrastructure",
    "start": "2020260",
    "end": "2026260"
  },
  {
    "text": "that all of them use so for a certain date data-driven capability building",
    "start": "2026260",
    "end": "2032280"
  },
  {
    "text": "recommendation engine or fraud detection you have all of these people with different skill sets working together",
    "start": "2032280",
    "end": "2038370"
  },
  {
    "text": "but not necessarily on the same parts of it right data finds its responsible for model building somehow that gets handed",
    "start": "2038370",
    "end": "2044980"
  },
  {
    "text": "off to data engineers this is something that actually makes a lot of sense if",
    "start": "2044980",
    "end": "2050320"
  },
  {
    "start": "2046000",
    "end": "2101000"
  },
  {
    "text": "you have an architecture as complex as the land architecture you need a lot of skill in machine",
    "start": "2050320",
    "end": "2058179"
  },
  {
    "text": "learning and in buildings complex services and using different types of",
    "start": "2058179",
    "end": "2063669"
  },
  {
    "text": "data systems for communication to build a system that looks like this and so that so what I'm about to say about the",
    "start": "2063669",
    "end": "2070868"
  },
  {
    "text": "way stitch picks that does things does not necessarily relate to this right like we're never building systems that",
    "start": "2070869",
    "end": "2076779"
  },
  {
    "text": "look like they look like a lamb to architecture and there are certain cases where this kind of tightly coupled team",
    "start": "2076779",
    "end": "2083648"
  },
  {
    "text": "and maybe a little bit of hopefully not too much handoff but the type of machine",
    "start": "2083649",
    "end": "2089349"
  },
  {
    "text": "learning experience that you need to work in this team tends to be very engineering heavy and so tightly coupled",
    "start": "2089349",
    "end": "2095739"
  },
  {
    "text": "teams can work for systems like this but it's also hard expensive slow there's a",
    "start": "2095739",
    "end": "2100809"
  },
  {
    "text": "lot of communication that needs to happen and so this whole process of building a model having some sort of",
    "start": "2100809",
    "end": "2107589"
  },
  {
    "start": "2101000",
    "end": "2114000"
  },
  {
    "text": "serialize version of it and then actually having a thing in production that makes it needs to be owned by the same team and sort of couples together",
    "start": "2107589",
    "end": "2114599"
  },
  {
    "start": "2114000",
    "end": "2173000"
  },
  {
    "text": "so that makes sense 60 model handoff in the land architecture case means iron data",
    "start": "2114599",
    "end": "2120339"
  },
  {
    "text": "scientist with the right skills and having them work very closely and be strong and engineering work closely with",
    "start": "2120339",
    "end": "2125680"
  },
  {
    "text": "engineers to build something that's complex like that kind of system another way to think about it is what if the",
    "start": "2125680",
    "end": "2134049"
  },
  {
    "text": "models that you're building and the models need to deploy are not nearly as complex what are the requirements that",
    "start": "2134049",
    "end": "2139569"
  },
  {
    "text": "you have can you have data scientists own this capabilities end-to-end and so this is one of the interesting things",
    "start": "2139569",
    "end": "2145029"
  },
  {
    "text": "that I think about a my job where I build tools for a data scientist it stitch fix to use for building their",
    "start": "2145029",
    "end": "2151539"
  },
  {
    "text": "models and deploying their models into production is what if data scientists own a capability so capability a is",
    "start": "2151539",
    "end": "2159279"
  },
  {
    "text": "merchandising capability B is matching stylus to fixes and people that they're",
    "start": "2159279",
    "end": "2164859"
  },
  {
    "text": "gonna style capability C is matching clients to items and how that shows up in our internal styling application and",
    "start": "2164859",
    "end": "2175440"
  },
  {
    "start": "2173000",
    "end": "2199000"
  },
  {
    "text": "when I think about that I try to think about it in terms of clean interfaces",
    "start": "2175440",
    "end": "2181539"
  },
  {
    "text": "between different steps of their process so again what we're interested in",
    "start": "2181539",
    "end": "2187180"
  },
  {
    "text": "it's the serialized model so we have some sort of process that is generating",
    "start": "2187180",
    "end": "2193150"
  },
  {
    "text": "our model and we need to take our model and turn it into a system that knows how",
    "start": "2193150",
    "end": "2198430"
  },
  {
    "text": "to apply it and so having a clean interface there ends up being very important there's a few different ways",
    "start": "2198430",
    "end": "2205030"
  },
  {
    "start": "2199000",
    "end": "2259000"
  },
  {
    "text": "you can think about this right so I said we need some sort of serialization standard forms of any type of",
    "start": "2205030",
    "end": "2211780"
  },
  {
    "text": "serialization you know json xml text-based realization there are things that exist that can output that for",
    "start": "2211780",
    "end": "2219069"
  },
  {
    "text": "models of course you want something on the other side that knows how to read xml and json and apply it and then",
    "start": "2219069",
    "end": "2226869"
  },
  {
    "text": "there's also more custom serialization so who here has used scikit-learn to",
    "start": "2226869",
    "end": "2232359"
  },
  {
    "text": "build models yeah exactly so if I could learn one of the ways you can do model",
    "start": "2232359",
    "end": "2237700"
  },
  {
    "text": "serialization and in fact the way that they recommend it on their interim their documentation is using pickle or a",
    "start": "2237700",
    "end": "2244839"
  },
  {
    "text": "particularly job Liv and pickle to serialize models so that you have the entire pipeline that you view your",
    "start": "2244839",
    "end": "2250930"
  },
  {
    "text": "scikit-learn pipeline that you specified and learn parameters stuffed into a binary file that you can then load a",
    "start": "2250930",
    "end": "2256720"
  },
  {
    "text": "later in a different process during serving so there exist open standards",
    "start": "2256720",
    "end": "2262480"
  },
  {
    "start": "2259000",
    "end": "2307000"
  },
  {
    "text": "for these text-based serialization formats there's a thing called PM ml",
    "start": "2262480",
    "end": "2267780"
  },
  {
    "text": "predictive modeling markup language this is an XML format for specifying your",
    "start": "2267780",
    "end": "2273970"
  },
  {
    "text": "model pipelines and the type of model you're using and feet in the learned weights that you're using in the model",
    "start": "2273970",
    "end": "2279010"
  },
  {
    "text": "and to go along with that there are the there are the scoring sides of these",
    "start": "2279010",
    "end": "2284859"
  },
  {
    "text": "things so there's a pretty cool system called open scoring which is it pretty",
    "start": "2284859",
    "end": "2291730"
  },
  {
    "text": "easy to use web server that uses a JPM ml so i java-based PMML scoring scoring",
    "start": "2291730",
    "end": "2299530"
  },
  {
    "text": "library to allow you to deploy models and then apply models to data coming in",
    "start": "2299530",
    "end": "2307859"
  },
  {
    "text": "so what this ends up looking like is that your model training pipelines output a sterilised model and PMML",
    "start": "2307859",
    "end": "2314140"
  },
  {
    "text": "format and then open scoring which is a Java based web server that's really to",
    "start": "2314140",
    "end": "2319660"
  },
  {
    "text": "please it has a REST API that's defined over here can be used to do your application",
    "start": "2319660",
    "end": "2326990"
  },
  {
    "text": "of feature ization and your application and model parameters to any new data that you have coming in so this is",
    "start": "2326990",
    "end": "2332930"
  },
  {
    "text": "actually a pretty great toolset there's lots of libraries that know how that do",
    "start": "2332930",
    "end": "2339800"
  },
  {
    "text": "model training they know how to output models in PMML one of the drawbacks and",
    "start": "2339800",
    "end": "2345770"
  },
  {
    "start": "2343000",
    "end": "2384000"
  },
  {
    "text": "the main one that I hear pointed out about PMML is that there are limited choices for the types of models it",
    "start": "2345770",
    "end": "2351440"
  },
  {
    "text": "supports and there's actually so this link I give at the bottom here is KML",
    "start": "2351440",
    "end": "2359030"
  },
  {
    "text": "related libraries and what model types they support and in this case this is",
    "start": "2359030",
    "end": "2364730"
  },
  {
    "text": "for open squaring the REST API and what models can it score with beyond just the",
    "start": "2364730",
    "end": "2371810"
  },
  {
    "text": "limitations of open scoring or other systems like this there's some limitations in what PMML can describe in",
    "start": "2371810",
    "end": "2377600"
  },
  {
    "text": "the future ization pipelines so it can be a little bit for a limb is not nearly as flexible as I didn't like scikit-learn pipelines so another way to",
    "start": "2377600",
    "end": "2386990"
  },
  {
    "text": "do this is to take your take your",
    "start": "2386990",
    "end": "2393290"
  },
  {
    "text": "infrastructure or model training infrastructure and think about your serialized model as data and decouple it",
    "start": "2393290",
    "end": "2400580"
  },
  {
    "text": "entire almost entirely from this metadata around it that says this is my model that is this type this is a",
    "start": "2400580",
    "end": "2406970"
  },
  {
    "text": "decision tree this is a regression model and instead just write the parameters",
    "start": "2406970",
    "end": "2412370"
  },
  {
    "text": "out somewhere and then assume that you have written it in your your service",
    "start": "2412370",
    "end": "2417770"
  },
  {
    "text": "that is actually applying this model the logic that correctly maps together the parameters to the actual model you're",
    "start": "2417770",
    "end": "2425780"
  },
  {
    "text": "trying to apply this is the most common thing that I see everywhere there are",
    "start": "2425780",
    "end": "2432430"
  },
  {
    "text": "obvious drawbacks you can easily get out of sync in the model that you think",
    "start": "2432430",
    "end": "2439010"
  },
  {
    "text": "you're applying in the service and the model that you're actually writing data to in the data store that you're reading from but it works in people thing to use",
    "start": "2439010",
    "end": "2448820"
  },
  {
    "text": "in so the the general questions that I try",
    "start": "2448820",
    "end": "2456070"
  },
  {
    "start": "2449000",
    "end": "2506000"
  },
  {
    "text": "to ask when I'm thinking about the types of problems that happen when trying to build production model deployments means",
    "start": "2456070",
    "end": "2463180"
  },
  {
    "text": "is first does the model do the thing that it's supposed to do does the",
    "start": "2463180",
    "end": "2468520"
  },
  {
    "text": "service itself function of you know how to monitor for it is it useful do you do AV testing does that work like did it",
    "start": "2468520",
    "end": "2474790"
  },
  {
    "text": "actually help your business make more money or have more clicks and can you",
    "start": "2474790",
    "end": "2482200"
  },
  {
    "text": "answer both of those questions about functionality of the service and the usefulness of the service continuously",
    "start": "2482200",
    "end": "2488020"
  },
  {
    "text": "through time which itself relates back to logging and monitoring in these systems and then doesn't meet your",
    "start": "2488020",
    "end": "2494170"
  },
  {
    "text": "requirements so hopefully you know if you decide it ahead of time I'm gonna specify what requirements I have for",
    "start": "2494170",
    "end": "2500050"
  },
  {
    "text": "this system and you have these numbers in mind that's doesn't meet that and",
    "start": "2500050",
    "end": "2505800"
  },
  {
    "text": "more the most interesting to me is is the team organized in such a way that",
    "start": "2505800",
    "end": "2512080"
  },
  {
    "start": "2506000",
    "end": "2549000"
  },
  {
    "text": "you can actually support the systems that you need to build and have you optimized your team and your systems for",
    "start": "2512080",
    "end": "2517570"
  },
  {
    "text": "what it is you're hiring for so if you're building a complex system lambda architecture it needs to be super fast",
    "start": "2517570",
    "end": "2523750"
  },
  {
    "text": "in near-real-time then the way that you would structure that team is probably ml",
    "start": "2523750",
    "end": "2529690"
  },
  {
    "text": "engineers working really closely with other software engineers if you're building something that has less latency",
    "start": "2529690",
    "end": "2536440"
  },
  {
    "text": "requirements or less throughput with throughput requirements can you get tools and systems it gets engineers out",
    "start": "2536440",
    "end": "2542080"
  },
  {
    "text": "of the way so they've left hand off and there's no one that says like here's my model I'm done please rewrite this and see so thank you that's nice to say",
    "start": "2542080",
    "end": "2551890"
  },
  {
    "start": "2549000",
    "end": "2733000"
  },
  {
    "text": "about",
    "start": "2551890",
    "end": "2553920"
  },
  {
    "text": "I guess we had a question over here to begin with",
    "start": "2557480",
    "end": "2562730"
  },
  {
    "text": "oh yes thank you yeah thanks for your patience with me as I so you were",
    "start": "2562730",
    "end": "2572119"
  },
  {
    "text": "mentioning something about the rebuilding a model like a once in a while what exactly it means it means to",
    "start": "2572119",
    "end": "2578450"
  },
  {
    "text": "train the model from the scratch using all the data including the previous or just most recent data or can you go more",
    "start": "2578450",
    "end": "2585950"
  },
  {
    "text": "in detail in this some models want the",
    "start": "2585950",
    "end": "2591410"
  },
  {
    "text": "most recent view of the world so maybe you only want to train a model on users that have been active in the",
    "start": "2591410",
    "end": "2596750"
  },
  {
    "text": "last 12 months on your system and so if you do that weekly the users that meet",
    "start": "2596750",
    "end": "2603380"
  },
  {
    "text": "that condition will change and so sometimes you want it to retrain our model on the most recent snapshot sometimes you want as much history as",
    "start": "2603380",
    "end": "2609859"
  },
  {
    "text": "possible and there's no correct answer it's really dependent on what each case",
    "start": "2609859",
    "end": "2615910"
  },
  {
    "text": "thank you any other questions oh well he",
    "start": "2615910",
    "end": "2628730"
  },
  {
    "text": "reads I'm happy to pitch that sit fix is always hiring um somebody asked through",
    "start": "2628730",
    "end": "2636020"
  },
  {
    "text": "the app if you mainly use standard machine learning model so if you use any deep learning models for your work its",
    "start": "2636020",
    "end": "2641510"
  },
  {
    "text": "districts so most models depends what",
    "start": "2641510",
    "end": "2649609"
  },
  {
    "text": "you mean by deep learning most models are standard in some sense like they",
    "start": "2649609",
    "end": "2655700"
  },
  {
    "text": "exist in library is somewhere I think my my definition of standard is this thing exists in a library and I can just use",
    "start": "2655700",
    "end": "2661670"
  },
  {
    "text": "it there are there's some experiments with AI tools and bigger models most of",
    "start": "2661670",
    "end": "2670160"
  },
  {
    "text": "the AI tools work has around factorization machines a little daddy Anna's coming out of factorization machines I think there's been a little",
    "start": "2670160",
    "end": "2676590"
  },
  {
    "text": "bit of computer vision with deep learning to do color identification on clothing which is actually pretty hard",
    "start": "2676590",
    "end": "2682310"
  },
  {
    "text": "we have our merchandisers and the people that determine what items were going to buy label like oh this shirt is someone",
    "start": "2682310",
    "end": "2692609"
  },
  {
    "text": "with a pattern the gentleman in the back in the plaid with the red yeah he's",
    "start": "2692609",
    "end": "2698070"
  },
  {
    "text": "wearing a red plaid shirt is his shirt red or a slightly different shade of red",
    "start": "2698070",
    "end": "2703530"
  },
  {
    "text": "or this off-white color you probably want to actually capture what percentage of different colors are in there and",
    "start": "2703530",
    "end": "2711090"
  },
  {
    "text": "maybe even the pattern and so being able to automatically get computer understandable information out of images",
    "start": "2711090",
    "end": "2718320"
  },
  {
    "text": "that we have of merchandise ends up being an interesting more complex deep learning a neural network kind of model",
    "start": "2718320",
    "end": "2725359"
  },
  {
    "text": "cool then please remember to rate this session and thanks for now",
    "start": "2725359",
    "end": "2731050"
  },
  {
    "text": "[Applause]",
    "start": "2731050",
    "end": "2735519"
  }
]
[
  {
    "start": "0",
    "end": "16000"
  },
  {
    "text": "[Music] so welcome to cloud native data",
    "start": "6990",
    "end": "13110"
  },
  {
    "text": "pipelines I'm Sid Anand a little bit about me over the last 16 or so years I",
    "start": "13110",
    "end": "18660"
  },
  {
    "start": "16000",
    "end": "66000"
  },
  {
    "text": "work on end-to-end data infrastructure most of my time has been spent at companies that are typically consumer",
    "start": "18660",
    "end": "25920"
  },
  {
    "text": "facing high scale traffic high traffic companies like LinkedIn Netflix eBay and",
    "start": "25920",
    "end": "31140"
  },
  {
    "text": "Etsy about two and a half years ago I joined an enterprise task company that",
    "start": "31140",
    "end": "37590"
  },
  {
    "text": "works in the security space called gari and they're doing some interesting work with data in the cloud and I'll talk to",
    "start": "37590",
    "end": "46020"
  },
  {
    "text": "you about that today in my spare time I'm a co-chair for Q con San Francisco",
    "start": "46020",
    "end": "51480"
  },
  {
    "text": "and London I'm a committer on the Apache airflow project and I have my father of",
    "start": "51480",
    "end": "57870"
  },
  {
    "text": "two rambunctious four and a half year old boy and a seven month old girl so a",
    "start": "57870",
    "end": "64920"
  },
  {
    "text": "Gauri what do we do so we make email safe again for those of you not familiar",
    "start": "64920",
    "end": "70619"
  },
  {
    "start": "66000",
    "end": "295000"
  },
  {
    "text": "with it now the thing is email has actually never been safe since the 1970s",
    "start": "70619",
    "end": "76830"
  },
  {
    "text": "with the advent of the SMTP protocol it's only been more recently that security protocols like SPF D Kim and",
    "start": "76830",
    "end": "84990"
  },
  {
    "text": "Demark have been developed many of which were developed by members of my team and",
    "start": "84990",
    "end": "90799"
  },
  {
    "text": "it's not in widespread use at this time so you still encounter these sort of",
    "start": "90799",
    "end": "96900"
  },
  {
    "text": "scenarios right you can email from your bank or credit card saying there's some sort of suspicious charge and you need",
    "start": "96900",
    "end": "103320"
  },
  {
    "text": "to be you need to log in immediately and verify the charges or you know maybe",
    "start": "103320",
    "end": "109950"
  },
  {
    "text": "your account will be closed and essentially you will get fished in most cases because your bank tries not to",
    "start": "109950",
    "end": "116790"
  },
  {
    "text": "send you things like that via email and most people don't realize it so what",
    "start": "116790",
    "end": "121799"
  },
  {
    "text": "do we do our first product which was launched a few years before I even joined was to protect consumers in a b2c",
    "start": "121799",
    "end": "129840"
  },
  {
    "text": "company so most of my former companies LinkedIn eBay PayPal Netflix use the",
    "start": "129840",
    "end": "135930"
  },
  {
    "text": "gari to protect to secure the email channel between them and their customers so that it reduces the chance of their",
    "start": "135930",
    "end": "143370"
  },
  {
    "text": "customers being fished by an email that looked like it was from Netflix when I joined about two and a half years ago we",
    "start": "143370",
    "end": "149819"
  },
  {
    "text": "try to take this technology and apply it to the enterprise so that enterprises could also be safeguarded in this way",
    "start": "149819",
    "end": "156750"
  },
  {
    "text": "from inbound email so you might have heard many years ago LinkedIn sort of",
    "start": "156750",
    "end": "162180"
  },
  {
    "text": "lost 17 million passwords didn't really lose them they just that other people have them and you know there was some",
    "start": "162180",
    "end": "169590"
  },
  {
    "text": "discussion of an email born route for that attack and that's sort of the case",
    "start": "169590",
    "end": "176100"
  },
  {
    "text": "that you know we're trying to prevent right you know more and more loss of data at",
    "start": "176100",
    "end": "182970"
  },
  {
    "text": "the enterprise level so our first version of our product was a batch",
    "start": "182970",
    "end": "188310"
  },
  {
    "text": "product so enterprise customers deployed one of our sensors in their data center",
    "start": "188310",
    "end": "194250"
  },
  {
    "text": "and every 15 minutes they would send us a file which contained email headers and",
    "start": "194250",
    "end": "203250"
  },
  {
    "text": "we would analyze that data in the cloud we would use the subset of it to train models and for the most part we would",
    "start": "203250",
    "end": "210810"
  },
  {
    "text": "score that data so we could you know assign a trust score on a range from",
    "start": "210810",
    "end": "216569"
  },
  {
    "text": "cluster to untrusted for each email and we would provide a visibility dashboard to our customers which would show",
    "start": "216569",
    "end": "223200"
  },
  {
    "text": "statistics on their mail flow are about",
    "start": "223200",
    "end": "229470"
  },
  {
    "text": "a year ago we started developing a near real-time product in the near real-time use case mail flow is coming in and our",
    "start": "229470",
    "end": "238769"
  },
  {
    "text": "cloud-based service is applying those trust models or in some cases building",
    "start": "238769",
    "end": "244889"
  },
  {
    "text": "some on the fly and again showing a visibility dashboard which now is a",
    "start": "244889",
    "end": "251370"
  },
  {
    "text": "real-time dashboard but in addition we're also basically executing a control",
    "start": "251370",
    "end": "256829"
  },
  {
    "text": "flow where based on some policy we can send a signal back to our sensor to",
    "start": "256829",
    "end": "262890"
  },
  {
    "text": "either quarantine the email label it or allow it to pass through and in most",
    "start": "262890",
    "end": "268080"
  },
  {
    "text": "cases we're running essentially three nines between the sensor and back to the",
    "start": "268080",
    "end": "273750"
  },
  {
    "text": "sensor with three seconds of latency and majority of that time is actually spent",
    "start": "273750",
    "end": "279060"
  },
  {
    "text": "over the public Internet that we don't control so within our cloud deployment",
    "start": "279060",
    "end": "284250"
  },
  {
    "text": "we're actually you know in many cases sub-second so what's the reason that",
    "start": "284250",
    "end": "291840"
  },
  {
    "text": "this is called cloud native data pipelines so if you work at you know big",
    "start": "291840",
    "end": "297180"
  },
  {
    "start": "295000",
    "end": "386000"
  },
  {
    "text": "data companies like LinkedIn or Facebook or Twitter or Google their data engineering teams are huge you know 500",
    "start": "297180",
    "end": "303810"
  },
  {
    "text": "is not a unknown number right and they're running their own custom data pipelines on hardware and for if you",
    "start": "303810",
    "end": "311129"
  },
  {
    "text": "remember Dean stock you know there was a reference architecture with lots of open source technologies typically in a large",
    "start": "311129",
    "end": "317039"
  },
  {
    "text": "company each of those teams would be supported each of those boxes will be supported by a different team you know",
    "start": "317039",
    "end": "324659"
  },
  {
    "text": "whether you're running Kafka you need a team on hand to you know patch it if it needs to be patched to do some",
    "start": "324659",
    "end": "330090"
  },
  {
    "text": "operations on it to configure it all of that stuff now if you work at a startup you don't have hundreds of engineers you",
    "start": "330090",
    "end": "336180"
  },
  {
    "text": "may have one engineer working on the data pipeline our company has about 10 total the total company size of 20",
    "start": "336180",
    "end": "343229"
  },
  {
    "text": "engineers ten of which are working on the data pipeline and data science side and in and they're running in the cloud",
    "start": "343229",
    "end": "349740"
  },
  {
    "text": "in most cases so are there things that these small companies can do so that",
    "start": "349740",
    "end": "355020"
  },
  {
    "text": "they get the same sort of comparable pipelines that you would expect at a Facebook or Twitter and the answer is",
    "start": "355020",
    "end": "361050"
  },
  {
    "text": "yes if you adopt some cloud native techniques and some open source technology is in a certain way you",
    "start": "361050",
    "end": "366900"
  },
  {
    "text": "should be able to get highly available highly scalable loli and C data pipelines to do interesting things like",
    "start": "366900",
    "end": "373889"
  },
  {
    "text": "predictions so before I well I guess before we get",
    "start": "373889",
    "end": "380430"
  },
  {
    "text": "into an architecture we should define what are some desirable qualities of a resilient data pipeline and for us there",
    "start": "380430",
    "end": "388500"
  },
  {
    "start": "386000",
    "end": "623000"
  },
  {
    "text": "are four aspects correctness timeliness operability and cost so correctness",
    "start": "388500",
    "end": "396270"
  },
  {
    "text": "essentially means that we should have data integrity and to end in our data pipeline we",
    "start": "396270",
    "end": "401370"
  },
  {
    "text": "shouldn't lose any data we should incur upped any data and since we're building like the type of pipeline we're working",
    "start": "401370",
    "end": "408360"
  },
  {
    "text": "on as a predictive data pipeline is generating predictions and and ranks and",
    "start": "408360",
    "end": "413790"
  },
  {
    "text": "scores the data distribution out of the pipeline should be as expected we",
    "start": "413790",
    "end": "419760"
  },
  {
    "text": "shouldn't all of a sudden find that 99% of the messages were generating are considered fish or untrusted in terms of",
    "start": "419760",
    "end": "427500"
  },
  {
    "text": "time eunice whether you're running a daily hourly or near real-time pipeline",
    "start": "427500",
    "end": "432830"
  },
  {
    "text": "what's really important is that it's the SLA czar met whatever the SLA is are",
    "start": "432830",
    "end": "438030"
  },
  {
    "text": "they need to be met because in our case we may be holding an email in a in",
    "start": "438030",
    "end": "443910"
  },
  {
    "text": "someone's mailbox until we've analyzed it and and said it's safe to deliver in",
    "start": "443910",
    "end": "449430"
  },
  {
    "text": "terms of operability if you work if you've worked in these large data teams you'll find that a very common problem",
    "start": "449430",
    "end": "457170"
  },
  {
    "text": "is operational fatigue majority of the time or most of in a data engineer's",
    "start": "457170",
    "end": "463110"
  },
  {
    "text": "time at these companies is just keeping things up and fixing data problems and I'll talk about quick recoverability but",
    "start": "463110",
    "end": "470700"
  },
  {
    "text": "one major problem that happens in data pipelines is that if there's a bug once",
    "start": "470700",
    "end": "475980"
  },
  {
    "text": "you fix the bug you have to fix all of the data that's that that flow downstream and contact all of those",
    "start": "475980",
    "end": "481620"
  },
  {
    "text": "teams and basically fix all of the data that you've corrupted all the way down stream and that resolves in a lot of",
    "start": "481620",
    "end": "487830"
  },
  {
    "text": "operational fatigue because every bug has a large blast radius another thing",
    "start": "487830",
    "end": "493620"
  },
  {
    "text": "that's important for operability is that we have some sort of fine-grained monitoring and alerting so that we can",
    "start": "493620",
    "end": "498960"
  },
  {
    "text": "check that we're meeting our correctness and timeliness like Ethel ease and then",
    "start": "498960",
    "end": "504600"
  },
  {
    "text": "quick recoverability so there are two aspects of designing a system for",
    "start": "504600",
    "end": "512250"
  },
  {
    "text": "reliability one is called mean time between failure and one is MTTR mean",
    "start": "512250",
    "end": "517469"
  },
  {
    "text": "time to recovery so I haven't included a side here but there is interesting thing",
    "start": "517470",
    "end": "525270"
  },
  {
    "text": "in my talk I gave last year this conference you know there's this comparison of a jeep to a rolls-royce",
    "start": "525270",
    "end": "531320"
  },
  {
    "text": "rolls-royce is designed to operate really well within its operational boundaries like",
    "start": "531320",
    "end": "538050"
  },
  {
    "text": "nice rose and on the Autobahn right but if we take it off roading it's going to break down and then you're going to",
    "start": "538050",
    "end": "543870"
  },
  {
    "text": "spend a considerable time fixing it whereas a jeep was designed to buy by",
    "start": "543870",
    "end": "549870"
  },
  {
    "text": "the people who created it to be taken outside of its design boundaries they",
    "start": "549870",
    "end": "554910"
  },
  {
    "text": "don't really need to know what you're going to do with the Jeep but the expect that you will break it and when you break it it should be really easy to fix",
    "start": "554910",
    "end": "560820"
  },
  {
    "text": "so on YouTube if you search for a Marine Corps team reassembles Jeep in four",
    "start": "560820",
    "end": "566010"
  },
  {
    "text": "minutes you'll see what I mean so that's sort of what we want in our data",
    "start": "566010",
    "end": "571320"
  },
  {
    "text": "pipeline bugs will happen we just need to quickly recover when that happens and finally since we're",
    "start": "571320",
    "end": "577620"
  },
  {
    "text": "running in the cloud one of the promises of the cloud was pay-as-you-go so we can",
    "start": "577620",
    "end": "582660"
  },
  {
    "text": "leverage some aspects of auto scaling and maybe lambdas to to reduce our cost",
    "start": "582660",
    "end": "587970"
  },
  {
    "text": "of running a data pipeline something you can't really do in your own data center",
    "start": "587970",
    "end": "593330"
  },
  {
    "text": "so what do predictive analytic analytics look like at agari so we have two",
    "start": "593330",
    "end": "600600"
  },
  {
    "text": "classes of predictive analytics one is in a building and training models and the other one is applying those models",
    "start": "600600",
    "end": "607140"
  },
  {
    "text": "in either a batch or near real-time pipeline to score them and today's talk",
    "start": "607140",
    "end": "612450"
  },
  {
    "text": "is mostly going to focus on applying the models so let's look at an example of",
    "start": "612450",
    "end": "621210"
  },
  {
    "text": "our batch pipeline architecture so we have say three companies Enterprise A B",
    "start": "621210",
    "end": "628050"
  },
  {
    "start": "623000",
    "end": "778000"
  },
  {
    "text": "and C and they're getting mail coming to them all of the time and they've deployed a sensor and a gauri sensor in",
    "start": "628050",
    "end": "633750"
  },
  {
    "text": "their data centers and in our our first version of our product which was batch every 15 minutes our sensor would upload",
    "start": "633750",
    "end": "642180"
  },
  {
    "text": "a file into s3 at the top of the hour",
    "start": "642180",
    "end": "648180"
  },
  {
    "text": "we'd have and we use air flow for our workflow engine and I'll talk a little bit more about that later but we",
    "start": "648180",
    "end": "654840"
  },
  {
    "text": "essentially have a workflow engine called air flow that will will run a spark job to score that data and",
    "start": "654840",
    "end": "661410"
  },
  {
    "text": "generate some aggregate statistics once an hour and it will output that data into a",
    "start": "661410",
    "end": "668470"
  },
  {
    "text": "different path in s3 we've set up as three with what's called SNS",
    "start": "668470",
    "end": "675160"
  },
  {
    "text": "notifications so as data lands in f3 in this output bucket notifications are",
    "start": "675160",
    "end": "681220"
  },
  {
    "text": "sent on simple notification service SNS which will queue them in simple queue",
    "start": "681220",
    "end": "686320"
  },
  {
    "text": "service so SMS it's a push based topic queue and essentially what it does is",
    "start": "686320",
    "end": "692620"
  },
  {
    "text": "for every event it guess it'll notify a bunch of subscribers and SQS is a queue",
    "start": "692620",
    "end": "700420"
  },
  {
    "text": "service that will actually retain all of those messages but it allows a single",
    "start": "700420",
    "end": "706240"
  },
  {
    "text": "message consumption and if you want to learn more about this I you can have a",
    "start": "706240",
    "end": "712540"
  },
  {
    "text": "look at last rest talk we're actually going to details of how do you two work together but I'm sort of assuming that",
    "start": "712540",
    "end": "717970"
  },
  {
    "text": "just to get a raise of hand how many people are familiar with SNS and SQS okay that's very good",
    "start": "717970",
    "end": "725410"
  },
  {
    "text": "now as messages flow into sqs we scale out what we call our importer layer",
    "start": "725410",
    "end": "731230"
  },
  {
    "text": "so our importers are Ruby jobs that will",
    "start": "731230",
    "end": "736240"
  },
  {
    "text": "read these these messages and import them into our Postgres database so s3",
    "start": "736240",
    "end": "742480"
  },
  {
    "text": "contains all of our data all the input data all the intermediate data all the output data but our Postgres database is",
    "start": "742480",
    "end": "750490"
  },
  {
    "text": "used to feed a subset of the data to our web app so that it's only the subset of",
    "start": "750490",
    "end": "755590"
  },
  {
    "text": "the data that we need to show in our visibility product and the importer job is to efficiently insert all of that",
    "start": "755590",
    "end": "762310"
  },
  {
    "text": "data into the PostScript database and we have airflow basically managing this",
    "start": "762310",
    "end": "769630"
  },
  {
    "text": "entire process also checking the quality and and loss characteristics of the data on each step in this pipeline so let's",
    "start": "769630",
    "end": "778690"
  },
  {
    "start": "778000",
    "end": "1015000"
  },
  {
    "text": "look at some of the architectural components here right the first one is s 3 S 3 is where we are essentially",
    "start": "778690",
    "end": "785560"
  },
  {
    "text": "building our data Lake its scalable available performance its server less we",
    "start": "785560",
    "end": "792970"
  },
  {
    "text": "don't need to manage it it's used to store all of our data as I mentioned our input intermediate and",
    "start": "792970",
    "end": "799420"
  },
  {
    "text": "output data and all of our data science processing goes against s3 so",
    "start": "799420",
    "end": "805420"
  },
  {
    "text": "essentially it's like HDFS but we don't really need to worry about scaling it for data growth for messaging we're",
    "start": "805420",
    "end": "812980"
  },
  {
    "text": "using a combination of SNS plus sqs together by using them together we get",
    "start": "812980",
    "end": "818560"
  },
  {
    "text": "the benefits of both and essentially we get a reliable transactional pub/sub so",
    "start": "818560",
    "end": "824740"
  },
  {
    "text": "what that essentially means is we get the benefits of pub/sub such as multiple topic listeners but we also get",
    "start": "824740",
    "end": "830890"
  },
  {
    "text": "transactions when you consume a message you actually have to send an act to let sqs know that you've consumed it again",
    "start": "830890",
    "end": "838300"
  },
  {
    "text": "it's surveillance and it's infinitely scalable and performant we have two",
    "start": "838300",
    "end": "843520"
  },
  {
    "text": "cases of processing so for our data science processing which in this case is",
    "start": "843520",
    "end": "848680"
  },
  {
    "text": "scoring aggregations model building we use SPARC and we've we've used it in",
    "start": "848680",
    "end": "855370"
  },
  {
    "text": "both flavors both EMR and also running our own and it spun up in both cases by",
    "start": "855370",
    "end": "862210"
  },
  {
    "text": "airflow airflow will spin up a cluster whether it's EMR or our own image by running on easy to do whatever",
    "start": "862210",
    "end": "869110"
  },
  {
    "text": "processing is required and then spin it down and spark has a very nice programming model but it's like very",
    "start": "869110",
    "end": "876130"
  },
  {
    "text": "complex to debug and I think one of the speakers in this track later will sort of go into the details of spark and you",
    "start": "876130",
    "end": "883540"
  },
  {
    "text": "haven't used it you'll get it you'll get an appreciation of how complex it is and",
    "start": "883540",
    "end": "890050"
  },
  {
    "text": "I mean a powerful of course and for general processing sort of like some business logic we just take whatever",
    "start": "890050",
    "end": "897730"
  },
  {
    "text": "type of service we have and we encapsulate it in an auto scaling group and we just let Amazon manage that auto",
    "start": "897730",
    "end": "903340"
  },
  {
    "text": "scaling group so it's always up and scaling for traffic the workflow engine",
    "start": "903340",
    "end": "908950"
  },
  {
    "text": "were using is airflow so it coordinates all the spark jobs and other complex",
    "start": "908950",
    "end": "914260"
  },
  {
    "text": "tasks it's lightweight it treats DAGs as",
    "start": "914260",
    "end": "919810"
  },
  {
    "text": "code so config as code if you've used other type of workflow engines like Ozzy",
    "start": "919810",
    "end": "925150"
  },
  {
    "text": "or Azkaban you basically wrestle with you know llamó and zip files of llamó and and xml files and the approach that",
    "start": "925150",
    "end": "933850"
  },
  {
    "text": "systems like Luigi and an airflow take our guests treat this as normal code and",
    "start": "933850",
    "end": "939730"
  },
  {
    "text": "use your development processes to manage them it does have a little bit of a steep learning curve especially around",
    "start": "939730",
    "end": "946120"
  },
  {
    "text": "operations and that's because airflow is not very opinionated about how you run",
    "start": "946120",
    "end": "952150"
  },
  {
    "text": "it it just sort of gives you a sense of how to run it on one box and you sort of have to make it scale and finally the",
    "start": "952150",
    "end": "958870"
  },
  {
    "text": "database we use is Postgres for no better reason than our web developers",
    "start": "958870",
    "end": "964330"
  },
  {
    "text": "picked that and so we're using it and since there are rails people like real people of Postgres and vice-versa",
    "start": "964330",
    "end": "971860"
  },
  {
    "text": "so in this model write like three of our services are not managed by us and three",
    "start": "971860",
    "end": "978670"
  },
  {
    "text": "of them are and that informs you a little bit about how we run we are such",
    "start": "978670",
    "end": "984070"
  },
  {
    "text": "a small team we can afford to run everything ourselves and when we have a choice we will always pick something",
    "start": "984070",
    "end": "991630"
  },
  {
    "text": "provided by the Amazon and when we don't find an adequate solution there we will choose to manage it ourselves and in",
    "start": "991630",
    "end": "997840"
  },
  {
    "text": "this case there was no real good workflow engine provided by Amazon and you know to some extent like as I",
    "start": "997840",
    "end": "1004590"
  },
  {
    "text": "mentioned we sometimes we use EMR and sometimes we don't because their downsides of using it so let's talk",
    "start": "1004590",
    "end": "1013290"
  },
  {
    "text": "about cost and timeliness right when we were running every day right for 23",
    "start": "1013290",
    "end": "1020490"
  },
  {
    "start": "1015000",
    "end": "1389000"
  },
  {
    "text": "hours of the day are we only paid for the ec2 instances that ran airflow our",
    "start": "1020490",
    "end": "1027089"
  },
  {
    "text": "database and our web app and at the end of the day we ran a full daily run at that point we paid for running AMR for",
    "start": "1027089",
    "end": "1035310"
  },
  {
    "text": "an hour and the importers for an hour and any messages that we had to pay for on SNS and SQS",
    "start": "1035310",
    "end": "1041069"
  },
  {
    "text": "so we were very cost efficient so we built in you know an infrastructure that was you know didn't have just a bunch of",
    "start": "1041070",
    "end": "1049740"
  },
  {
    "text": "standing nodes that we were paying for even if they were reserved instances",
    "start": "1049740",
    "end": "1055340"
  },
  {
    "text": "when we went to hourly things changed we",
    "start": "1055730",
    "end": "1061230"
  },
  {
    "text": "actually were whether we ran for a minute five minutes or an hour",
    "start": "1061230",
    "end": "1067260"
  },
  {
    "text": "easy to basically charges us for the full hour so we were actually not saving any money with this architecture we were",
    "start": "1067260",
    "end": "1073860"
  },
  {
    "text": "when we were daily but once we went hourly we were saving nothing so one idea was for us who just moved to lamda",
    "start": "1073860",
    "end": "1080340"
  },
  {
    "text": "lamda charges you up to 100 milliseconds rather than up to the hour so we you",
    "start": "1080340",
    "end": "1087450"
  },
  {
    "text": "know we found it in general with some back of the envelope calculations to save us about 100x the cost so what",
    "start": "1087450",
    "end": "1093210"
  },
  {
    "text": "one-hundredth of the cost of running the equivalent load even continuously on ec2 would be you know running on Lambert",
    "start": "1093210",
    "end": "1100380"
  },
  {
    "text": "it's like you know a penny over to the dollar so it's quite a good cost savings",
    "start": "1100380",
    "end": "1106380"
  },
  {
    "text": "if you're considering lamda what about timeliness right so in the",
    "start": "1106380",
    "end": "1113039"
  },
  {
    "text": "batch world we're running every hour and sometimes as new customers come online our data",
    "start": "1113039",
    "end": "1118889"
  },
  {
    "text": "volume is growing and our smart jobs take longer to run and our importers",
    "start": "1118889",
    "end": "1124769"
  },
  {
    "text": "take longer to import that data and the challenge we have is completing all of it within an hour all the time so",
    "start": "1124769",
    "end": "1132769"
  },
  {
    "text": "airflow since it manages the spin-up of spark we can just configure to an",
    "start": "1132769",
    "end": "1138419"
  },
  {
    "text": "airflow variable the number of workers and the instance type which defines the",
    "start": "1138419",
    "end": "1143909"
  },
  {
    "text": "memory and CPU characteristics of that spark cluster right before the next hourly run and the next hourly run will",
    "start": "1143909",
    "end": "1151169"
  },
  {
    "text": "automatically spin up a bigger stronger larger cluster for spark what about the",
    "start": "1151169",
    "end": "1158720"
  },
  {
    "text": "importers right what how do we scale the importers out so we adopted the thing",
    "start": "1158720",
    "end": "1166559"
  },
  {
    "text": "called auto scaling how many of you just is here you know show of hands use auto",
    "start": "1166559",
    "end": "1171690"
  },
  {
    "text": "scaling okay it's about 10 people right so what auto scaling gives us and I'll",
    "start": "1171690",
    "end": "1178470"
  },
  {
    "text": "tell you why this is important so we have an hour budget to finish our workload and sometimes spark will take",
    "start": "1178470",
    "end": "1184139"
  },
  {
    "text": "50 minutes and what that essentially means is we have 10 minutes or less to import all of the data into our database",
    "start": "1184139",
    "end": "1190470"
  },
  {
    "text": "and we need some way to make a cost performance trade-off and an auto scalar",
    "start": "1190470",
    "end": "1197039"
  },
  {
    "text": "and auto scaling group lets us define a Max and min of this of the group and if we're finding our",
    "start": "1197039",
    "end": "1202710"
  },
  {
    "text": "spark jobs are just taking longer and longer we just raised the max we pay a little extra and we get the importer",
    "start": "1202710",
    "end": "1210180"
  },
  {
    "text": "will take a lifetime and I'm going to talk to you a little bit about the autoscaler now but essentially what it",
    "start": "1210180",
    "end": "1216330"
  },
  {
    "text": "does is it listens to an sqs cue and it will scale out based on some characteristics of that cue to get a",
    "start": "1216330",
    "end": "1223920"
  },
  {
    "text": "higher throughput as needed so our first approach at auto-scaling use what's",
    "start": "1223920",
    "end": "1231780"
  },
  {
    "text": "called a cpu metric so i'm going to sort of talk about that right now so as I mentioned we have these",
    "start": "1231780",
    "end": "1237720"
  },
  {
    "text": "importers and one way to scale a cluster of importers in or out is based on the average CPU of the cluster of importers",
    "start": "1237720",
    "end": "1245520"
  },
  {
    "text": "and this is a common first step for anyone using auto scaling as they'll say",
    "start": "1245520",
    "end": "1250680"
  },
  {
    "text": "ok I want to scale this easy to resource maybe CPU is a good measure so let's use",
    "start": "1250680",
    "end": "1256290"
  },
  {
    "text": "the average CPU so what I have here on the left or on the orange graph is the",
    "start": "1256290",
    "end": "1261540"
  },
  {
    "text": "messages that are coming into SQS from you know sparks slash s3 and in the",
    "start": "1261540",
    "end": "1267000"
  },
  {
    "text": "beginning there are no importers so this green curve which is the number of",
    "start": "1267000",
    "end": "1272070"
  },
  {
    "text": "messages process from sqs the counter is kind of low here and we already we",
    "start": "1272070",
    "end": "1277710"
  },
  {
    "text": "actually have just one instance all the time but for this demonstration just assume that's kind of zero and then this",
    "start": "1277710",
    "end": "1283500"
  },
  {
    "text": "blue line is the total CPU of the cluster and you can see some steps here the autoscaler keeps adding more and more nodes so",
    "start": "1283500",
    "end": "1290460"
  },
  {
    "text": "what's happening essentially is the autoscaler is increasing the pool and as it does so the processing processing",
    "start": "1290460",
    "end": "1298230"
  },
  {
    "text": "increases the processing rate increases until there are no more messages to process and it completes processing of",
    "start": "1298230",
    "end": "1304920"
  },
  {
    "text": "all the sqs messages and as I mentioned so the the metric that is used for auto",
    "start": "1304920",
    "end": "1311490"
  },
  {
    "text": "scaling to scale out is average CPU so our scaling policy is that we tell the",
    "start": "1311490",
    "end": "1316920"
  },
  {
    "text": "autoscaler never let the average CPU go higher than 40 percent if it does add",
    "start": "1316920",
    "end": "1323700"
  },
  {
    "text": "more machines and so what it does is it'll keep adding machines to keep that",
    "start": "1323700",
    "end": "1328910"
  },
  {
    "text": "CPU at around 40% you can see that it does a really great job of doing that so it's always getting ahead of the",
    "start": "1328910",
    "end": "1334530"
  },
  {
    "text": "there is one problem with this approach CP is actually not a great metric when",
    "start": "1334530",
    "end": "1341610"
  },
  {
    "text": "you get down to the last message in sqs let's say you've scale up to 20 nodes 19",
    "start": "1341610",
    "end": "1347790"
  },
  {
    "text": "of the nodes are idle and they're CP is basically around 2% and then one node is",
    "start": "1347790",
    "end": "1353090"
  },
  {
    "text": "like processing the last batch and the and our scaling policy is something like",
    "start": "1353090",
    "end": "1358980"
  },
  {
    "text": "when this when the average CPU falls below 10% hey autoscaler start killing nodes and that's what happens the",
    "start": "1358980",
    "end": "1365940"
  },
  {
    "text": "autoscaler doesn't know which note is the one processing the last message it just starts killing notes and sometimes",
    "start": "1365940",
    "end": "1371970"
  },
  {
    "text": "it kills the the you know the importer that's processing the last message and",
    "start": "1371970",
    "end": "1377130"
  },
  {
    "text": "what happens is we get this really long tail of processing the last message and it takes a really long time so this is",
    "start": "1377130",
    "end": "1383280"
  },
  {
    "text": "called premature scaling so the idea was CP is not really a good measure so we",
    "start": "1383280",
    "end": "1390090"
  },
  {
    "start": "1389000",
    "end": "1480000"
  },
  {
    "text": "tried a different one and it's called the queue based approach so when you're reading messages from sqs messages are",
    "start": "1390090",
    "end": "1397530"
  },
  {
    "text": "in two states they're either visible or they're in flight if they're visible it",
    "start": "1397530",
    "end": "1402900"
  },
  {
    "text": "means a get request on that queue will give you a message if it's invisible",
    "start": "1402900",
    "end": "1407970"
  },
  {
    "text": "it means no get request which it will give you that message it's invisible for a certain time out period so what we",
    "start": "1407970",
    "end": "1414750"
  },
  {
    "text": "have here is this first blue curve right here is the is a count of visible",
    "start": "1414750",
    "end": "1420600"
  },
  {
    "text": "messages on the queue so as spark is working in producing messages the number of visible messages increase and our",
    "start": "1420600",
    "end": "1427620"
  },
  {
    "text": "scalar policy is as long as that that value is greater than zero scale the",
    "start": "1427620",
    "end": "1432930"
  },
  {
    "text": "cluster out make it larger and at this point what happens is the cluster starts",
    "start": "1432930",
    "end": "1438390"
  },
  {
    "text": "processing messages that and they go in flight that's the orange curve these are inside messages and spark stops you know",
    "start": "1438390",
    "end": "1445110"
  },
  {
    "text": "creating new messages here and now we're just we're just basically consuming them so this drops to zero and we hit zero we",
    "start": "1445110",
    "end": "1451170"
  },
  {
    "text": "stop scaling out then the cluster is now at its maximum size and then we wait",
    "start": "1451170",
    "end": "1456990"
  },
  {
    "text": "until all the in-flight messages go to 0 which means that they've all been processed and then we magically just",
    "start": "1456990",
    "end": "1462990"
  },
  {
    "text": "immediately scale in our entire cluster and this works very well for us we no longer has",
    "start": "1462990",
    "end": "1468390"
  },
  {
    "text": "long tail we essentially scaled out while there was you know messages to be",
    "start": "1468390",
    "end": "1473910"
  },
  {
    "text": "processed and we scaled in when there were no invite messages left so some",
    "start": "1473910",
    "end": "1481140"
  },
  {
    "start": "1480000",
    "end": "1653000"
  },
  {
    "text": "people ask like how do we what's the cloud native approach to building these auto scaling groups so we",
    "start": "1481140",
    "end": "1487170"
  },
  {
    "text": "we've adopted three major tooling like three major tooling languages or tools",
    "start": "1487170",
    "end": "1493560"
  },
  {
    "text": "so the first one is called terraform how many of you have used either terraform and support packer excellent so",
    "start": "1493560",
    "end": "1500940"
  },
  {
    "text": "terraform is the way to to allocate resources like SQS Kinesis etq they",
    "start": "1500940",
    "end": "1507510"
  },
  {
    "text": "basically in a you know declarative model they're actually all configured code but they essentially give you you",
    "start": "1507510",
    "end": "1515190"
  },
  {
    "text": "know a sqs resource and that's essentially the tool to to allocate",
    "start": "1515190",
    "end": "1521010"
  },
  {
    "text": "these Amazon or you know GCP resources once you get an ec2 machine you have to",
    "start": "1521010",
    "end": "1528270"
  },
  {
    "text": "install probably some of one two packages and some like Python packages to make it useful for you for example",
    "start": "1528270",
    "end": "1534480"
  },
  {
    "text": "our data sign like our spark cluster that we build we build the ami is using ansible and parker and essentially those",
    "start": "1534480",
    "end": "1541550"
  },
  {
    "text": "we have to basically we get a vanilla instance and then we install like sci-fi or psychic scikit-learn",
    "start": "1541550",
    "end": "1548430"
  },
  {
    "text": "or like other packages maybe Java and so",
    "start": "1548430",
    "end": "1554580"
  },
  {
    "text": "ansible is the way that you would provision a single ECG machine with all the packages you know OS and and Python",
    "start": "1554580",
    "end": "1560370"
  },
  {
    "text": "that you need to run your application and finally Packer is a this tool also",
    "start": "1560370",
    "end": "1567000"
  },
  {
    "text": "by Hoshi Corp that will generate an ami for you and an Amazon machine image from",
    "start": "1567000",
    "end": "1573990"
  },
  {
    "text": "everything that you've got so let's let's have an example let's look an example so step one we run packer and",
    "start": "1573990",
    "end": "1580200"
  },
  {
    "text": "Packer will in like create an ec2 instance with basically it's a blank",
    "start": "1580200",
    "end": "1586440"
  },
  {
    "text": "canvas just like a very some like blank basic Ubuntu 1404 image on it and really",
    "start": "1586440",
    "end": "1595530"
  },
  {
    "text": "nothing that your application needs and then we will run an answerable playbook to provision you know whatever your app",
    "start": "1595530",
    "end": "1602279"
  },
  {
    "text": "like if it's a Python app it's going to need like a lot of pit install packages and and maybe a couple of less packages",
    "start": "1602279",
    "end": "1609139"
  },
  {
    "text": "and then we will Packer will take a snapshot of that machine and register",
    "start": "1609139",
    "end": "1614669"
  },
  {
    "text": "the ami with Amazon and then it will destroy the machine it really doesn't need the machine beyond just baking this",
    "start": "1614669",
    "end": "1620639"
  },
  {
    "text": "ami and finally a terraform along with this ami will in a like a Bluegreen",
    "start": "1620639",
    "end": "1628229"
  },
  {
    "text": "fashion will spin up a new auto scaling group and launch config with this ami and replace your existing auto scaling",
    "start": "1628229",
    "end": "1635549"
  },
  {
    "text": "group so it does Bluegreen deployments and this is essentially how we deploy",
    "start": "1635549",
    "end": "1641549"
  },
  {
    "text": "all of our auto scaling groups today so this sort of covers the timeliness and",
    "start": "1641549",
    "end": "1648059"
  },
  {
    "text": "and costs aspects of our batch pipeline what about operability and correctness",
    "start": "1648059",
    "end": "1653299"
  },
  {
    "start": "1653000",
    "end": "1707000"
  },
  {
    "text": "so when we first started our data science team was essentially you know",
    "start": "1653299",
    "end": "1658589"
  },
  {
    "text": "writing cron jobs to run our like spark jobs and you know it's not ideal in many",
    "start": "1658589",
    "end": "1665700"
  },
  {
    "text": "ways so we needed a better way to author configure and manage workflows and we",
    "start": "1665700",
    "end": "1672269"
  },
  {
    "text": "you know also needed visual insight into the performance and correctness and state of our workflows like for example",
    "start": "1672269",
    "end": "1679409"
  },
  {
    "text": "was a given task failing a lot and constantly being retried is that why our SLA is were taking longer and longer to",
    "start": "1679409",
    "end": "1686399"
  },
  {
    "text": "complete right and also we needed some really good integration with our existing alerting so we get played an",
    "start": "1686399",
    "end": "1692879"
  },
  {
    "text": "on-call engineer to have a look at one of our failing workflows and the best",
    "start": "1692879",
    "end": "1698789"
  },
  {
    "text": "solution we found this is probably about two years ago was Apache airflow which was just starting at that time it wasn't",
    "start": "1698789",
    "end": "1705239"
  },
  {
    "text": "even in Apache and so this is what it looks like so given a you know a given",
    "start": "1705239",
    "end": "1710909"
  },
  {
    "start": "1707000",
    "end": "1736000"
  },
  {
    "text": "workflow or a dag it's nothing but Python code it's just very simple Python code and when visualized it looks like",
    "start": "1710909",
    "end": "1719489"
  },
  {
    "text": "this right and and the dag that you're looking at essentially manages the batch",
    "start": "1719489",
    "end": "1726029"
  },
  {
    "text": "workflow or the batch architecture shown on the lower right and say you want to",
    "start": "1726029",
    "end": "1731669"
  },
  {
    "text": "you know you want an insight into the running of your of your pipeline so you get a Gantt",
    "start": "1731669",
    "end": "1738220"
  },
  {
    "start": "1736000",
    "end": "1875000"
  },
  {
    "text": "chart for each and every run and what this shows you is that the lar the longest step and we sort of talked about",
    "start": "1738220",
    "end": "1744490"
  },
  {
    "text": "it the longest step is the SPARC aggregation and scoring that happens and then after the ablution is done and this",
    "start": "1744490",
    "end": "1752500"
  },
  {
    "text": "data is sort of being pumped into s3 the importers will complete it so this takes",
    "start": "1752500",
    "end": "1757539"
  },
  {
    "text": "about ten minutes this takes about one minute right all right and then we also have sort of a wait for s3 thing here",
    "start": "1757539",
    "end": "1763480"
  },
  {
    "text": "because after we have known like consistency like eventual consistency issue so to avoid it we actually do kind",
    "start": "1763480",
    "end": "1771100"
  },
  {
    "text": "of just a time to wait and essentially this whole thing takes around 20 minutes or less to run and what if you know you",
    "start": "1771100",
    "end": "1778269"
  },
  {
    "text": "want to know that hey this is pretty fast for an hourly pipeline where we're completing it within the first twenty",
    "start": "1778269",
    "end": "1783850"
  },
  {
    "text": "minutes of every hour of course we're paying for the full hour but is it always running efficiently and and then",
    "start": "1783850",
    "end": "1790809"
  },
  {
    "text": "you can get sort of a task duration chart which will give you a historic",
    "start": "1790809",
    "end": "1796299"
  },
  {
    "text": "view of the running of your pipeline and each of these lines represents a",
    "start": "1796299",
    "end": "1802779"
  },
  {
    "text": "different task so again this is the most expensive test this is the aggregate SPARC job and what we find is the first",
    "start": "1802779",
    "end": "1811059"
  },
  {
    "text": "month of thing last year it was just getting linearly slower and there was a",
    "start": "1811059",
    "end": "1817330"
  },
  {
    "text": "bug and the data science team found it fixed it and then we got basically over",
    "start": "1817330",
    "end": "1823990"
  },
  {
    "text": "the next four weeks a consistent run times of our SPARC job I mean at this point is taking over a half an hour to",
    "start": "1823990",
    "end": "1829360"
  },
  {
    "text": "run it and they brought it back down to around ten minutes then they did another optimization and they brought the time down even further so one thing that",
    "start": "1829360",
    "end": "1836590"
  },
  {
    "text": "happens at least in data science is that it's like a virtuous cycle right they're using new features and and sometimes",
    "start": "1836590",
    "end": "1843220"
  },
  {
    "text": "those features are not performing like they would expect and king of get slower and then they have to do some like",
    "start": "1843220",
    "end": "1850630"
  },
  {
    "text": "cleanup to bring the times back into alignment and essentially this is a new feature then these are two optimizations",
    "start": "1850630",
    "end": "1856899"
  },
  {
    "text": "and then you add another feature and again time went up so things like air flow give you that ability to to",
    "start": "1856899",
    "end": "1863620"
  },
  {
    "text": "maintain this virtual cycle of new feature development you know new",
    "start": "1863620",
    "end": "1869010"
  },
  {
    "text": "data science like models development as well as like performance optimization",
    "start": "1869010",
    "end": "1875210"
  },
  {
    "start": "1875000",
    "end": "2009000"
  },
  {
    "text": "now what happens when your pipeline takes longer than an hour or what if",
    "start": "1875210",
    "end": "1880350"
  },
  {
    "text": "your pipeline generates some sort of errors in that case we have integration with slack and we use like add off some",
    "start": "1880350",
    "end": "1887160"
  },
  {
    "text": "slack ups air flow basically like we'll dump into here like this says we're missing our hourly",
    "start": "1887160",
    "end": "1893040"
  },
  {
    "text": "SLA and this one says you know guess what we've lost data and then we'll",
    "start": "1893040",
    "end": "1898530"
  },
  {
    "text": "actually page or on call with intubation with Victor ops or whatever you know",
    "start": "1898530",
    "end": "1904860"
  },
  {
    "text": "pager duty and then they'll be notified that something's wrong with the pipeline and air flow meets all of those needs",
    "start": "1904860",
    "end": "1910080"
  },
  {
    "text": "for us so essentially this is how our batch pipeline runs and with air flow we",
    "start": "1910080",
    "end": "1917190"
  },
  {
    "text": "get you know the correctness and operability that we need how about our near real-time pipeline so the way our",
    "start": "1917190",
    "end": "1925980"
  },
  {
    "text": "near real-time pipeline runs again we have three customers they are dumping",
    "start": "1925980",
    "end": "1931350"
  },
  {
    "text": "data as they get it into Kinesis Kinesis is amazon's answer to Kafka and we have",
    "start": "1931350",
    "end": "1939120"
  },
  {
    "text": "an auto scaling group of scorers that are getting the data within you know microseconds in most most cases of when",
    "start": "1939120",
    "end": "1946350"
  },
  {
    "text": "they were actually dumped on to you when a customer's about them and we score the",
    "start": "1946350",
    "end": "1951510"
  },
  {
    "text": "data and write the scored data out to another Kinesis stream we're importers",
    "start": "1951510",
    "end": "1957900"
  },
  {
    "text": "will read it and import it into our Postgres database and then they will",
    "start": "1957900",
    "end": "1963120"
  },
  {
    "text": "also send it to another Kinesis stream which will be read by our lurchers and our lurchers are responsible for look",
    "start": "1963120",
    "end": "1972060"
  },
  {
    "text": "doing a matching on customer policies to see if an alert condition has been met and if they have been met they may take",
    "start": "1972060",
    "end": "1978720"
  },
  {
    "text": "an action like quarantine in the email on the sensor across the net across the internet and this is a you know our",
    "start": "1978720",
    "end": "1985650"
  },
  {
    "text": "real-time pipeline for our control system similar to this we also have some",
    "start": "1985650",
    "end": "1991380"
  },
  {
    "text": "upgrades to this pipeline this side already was kind of busy but you can",
    "start": "1991380",
    "end": "1997440"
  },
  {
    "text": "imagine that we also we also have elasticsearch in this mix it's a",
    "start": "1997440",
    "end": "2002780"
  },
  {
    "text": "another Kinesis cream downstream of the importers and i'll talk a little bit about that now when we talk about the",
    "start": "2002780",
    "end": "2010160"
  },
  {
    "start": "2009000",
    "end": "2350000"
  },
  {
    "text": "components so again s3 is our data Lake okay it stores even though data is coming",
    "start": "2010160",
    "end": "2016640"
  },
  {
    "text": "into Kinesis we use firehose to write that data to s3 because our model",
    "start": "2016640",
    "end": "2022310"
  },
  {
    "text": "building will go against the data in s3 we still do full model bills every night",
    "start": "2022310",
    "end": "2028180"
  },
  {
    "text": "instead of SNF SQL we actually we could have stuck with it for a messaging but",
    "start": "2028180",
    "end": "2033490"
  },
  {
    "text": "because the whole world uses Kafka and we didn't want to be so innovative we",
    "start": "2033490",
    "end": "2039650"
  },
  {
    "text": "decided okay let's go with something that's a hosted Casca we went with Kinesis here and you know again it's",
    "start": "2039650",
    "end": "2045440"
  },
  {
    "text": "server list something we don't manage and it's work fine for us in retrospect",
    "start": "2045440",
    "end": "2050540"
  },
  {
    "text": "I think we might have been able to do as soon as sqs and it might have actually been better but one thing we looked at",
    "start": "2050540",
    "end": "2055669"
  },
  {
    "text": "was the message size and we at that time we were concerned the 64 KB size limit",
    "start": "2055669",
    "end": "2061580"
  },
  {
    "text": "on sqs messages might have been too restrictive and the Kinesis you get I think 1 MB so that was one of the",
    "start": "2061580",
    "end": "2067669"
  },
  {
    "text": "reasons we went with Kinesis for general processing we started moving everything",
    "start": "2067669",
    "end": "2074419"
  },
  {
    "text": "to lambda for the cost reason that I mentioned but lambda only supports like",
    "start": "2074419",
    "end": "2080000"
  },
  {
    "text": "Python node and Java we still have a bunch of stuff in Ruby and for that",
    "start": "2080000",
    "end": "2085429"
  },
  {
    "text": "reason we still run a the the auto scalars and sometimes there's also a",
    "start": "2085429",
    "end": "2091790"
  },
  {
    "text": "limit of memory the largest lamb that you can get is that 1.5 gigs of memory and some things we do may require more",
    "start": "2091790",
    "end": "2100280"
  },
  {
    "text": "than that because we'll map a huge model into memory and we might end up using more memory so that's like the second",
    "start": "2100280",
    "end": "2105680"
  },
  {
    "text": "use case for using an auto scaler over lambda spark so this is an interesting",
    "start": "2105680",
    "end": "2111560"
  },
  {
    "text": "point our first implementation of the of our real-time system just took our spark",
    "start": "2111560",
    "end": "2119390"
  },
  {
    "text": "jobs for scoring and just change the interface to use the the micro batch",
    "start": "2119390",
    "end": "2125120"
  },
  {
    "text": "approach and the you know the job was",
    "start": "2125120",
    "end": "2130640"
  },
  {
    "text": "written to run in 10 minutes so it still ran in 10 minutes but that didn't really help us for",
    "start": "2130640",
    "end": "2137670"
  },
  {
    "text": "near-real-time so we found the performance of the job was not better",
    "start": "2137670",
    "end": "2142740"
  },
  {
    "text": "just because we had micro batches because some of the operations in the spaghetti code that became our spark",
    "start": "2142740",
    "end": "2148559"
  },
  {
    "text": "code with doing some really inefficient things and the amount of time to rewrite that job would have taken probably a",
    "start": "2148559",
    "end": "2155339"
  },
  {
    "text": "year because you know given you know I'm not saying the data times where folks were not like following best practices",
    "start": "2155339",
    "end": "2162420"
  },
  {
    "text": "but they were sort of you know writing code with a free hand and you know data's means they had to get stuff done",
    "start": "2162420",
    "end": "2168089"
  },
  {
    "text": "in 10 to 20 minutes and that code didn't translate well to running in the near",
    "start": "2168089",
    "end": "2173880"
  },
  {
    "text": "real-time streaming model so we took a scoring and aggregation out and we just",
    "start": "2173880",
    "end": "2181650"
  },
  {
    "text": "use Park now for model building and we've actually moved the scoring",
    "start": "2181650",
    "end": "2186720"
  },
  {
    "text": "directly into a lambda and I'll talk about the aggregation next we still use",
    "start": "2186720",
    "end": "2194130"
  },
  {
    "text": "airflow for certain things like the nightly model build we're still using the database to hold some data but what",
    "start": "2194130",
    "end": "2200490"
  },
  {
    "text": "we've done is so because we went near real-time we could no longer do this aggregation",
    "start": "2200490",
    "end": "2205740"
  },
  {
    "text": "every hour our users want real-time aggregation and the other problem with doing hourly aggregation is what you're",
    "start": "2205740",
    "end": "2213180"
  },
  {
    "text": "essentially doing is a pre aggregate some data lamps in a details table in",
    "start": "2213180",
    "end": "2218430"
  },
  {
    "text": "Postgres and then your airflow job is saying compute a pre aggregate for that one",
    "start": "2218430",
    "end": "2223559"
  },
  {
    "text": "hour and data comes late and when data comes late you're advocates are completely wrong so",
    "start": "2223559",
    "end": "2229200"
  },
  {
    "text": "what we did was we just killed pre aggregation altogether and we we put",
    "start": "2229200",
    "end": "2236029"
  },
  {
    "text": "elasticsearch downstream of our database reading off a change capture stream and",
    "start": "2236029",
    "end": "2241700"
  },
  {
    "text": "we just do on the fly our vacations 500 million data points and it turns out our",
    "start": "2241700",
    "end": "2247740"
  },
  {
    "text": "web app is 100x faster and it's more accurate so we actually you know we",
    "start": "2247740",
    "end": "2253259"
  },
  {
    "text": "follow this approach over like polyglot persistence where we say your relational database doesn't have to do everything",
    "start": "2253259",
    "end": "2258569"
  },
  {
    "text": "if you have a relational database and a change capture stream downstream you can put whatever you want",
    "start": "2258569",
    "end": "2263880"
  },
  {
    "text": "it could be a graph engine it could be a search engine it could be whatever and we currently put Alaska",
    "start": "2263880",
    "end": "2269770"
  },
  {
    "text": "search downstream to do both search and also abrogation on-the-fly and that's been a huge win for us so what sort of",
    "start": "2269770",
    "end": "2279070"
  },
  {
    "text": "other innovations have we come up with when we started building this NRT pipeline oh I should I should mention",
    "start": "2279070",
    "end": "2285370"
  },
  {
    "text": "that the elasticsearch that we're using is the hosted Amazon Elastic search we",
    "start": "2285370",
    "end": "2290410"
  },
  {
    "text": "again don't manage it so it's completely serverless I don't know why I said managed we should actually say service for that and",
    "start": "2290410",
    "end": "2297340"
  },
  {
    "text": "we also did one other thing our spark jobs for scoring needed to do some",
    "start": "2297340",
    "end": "2302380"
  },
  {
    "text": "windowing functions and what we actually do is we store data in ElastiCache again",
    "start": "2302380",
    "end": "2307900"
  },
  {
    "text": "the Amazon ElastiCache and instead of going you know to Postgres or you know",
    "start": "2307900",
    "end": "2314830"
  },
  {
    "text": "writing some complex spark code right so how many of you use a burl okay not a",
    "start": "2314830",
    "end": "2323170"
  },
  {
    "text": "huge amount how many do you know whatever is okay still not a huge number of people and I how many of you work in",
    "start": "2323170",
    "end": "2329710"
  },
  {
    "text": "finance okay well interesting you the one who raised his hand ever since I met okay so",
    "start": "2329710",
    "end": "2334840"
  },
  {
    "text": "um I've talked to a couple people about this and typically the people in finance don't have this exact requirement that",
    "start": "2334840",
    "end": "2341740"
  },
  {
    "text": "you find in Silicon Valley which is that you know the market closes they have a down time and so I'll talk",
    "start": "2341740",
    "end": "2349420"
  },
  {
    "text": "about that right now so Apache Avro is the self-describing serialization format so think about when",
    "start": "2349420",
    "end": "2357340"
  },
  {
    "start": "2350000",
    "end": "2438000"
  },
  {
    "text": "you put data in a database and you access that data there's a schema around that data and there's some sort of and",
    "start": "2357340",
    "end": "2363100"
  },
  {
    "text": "is some sort of code that's validating that all data in or out matches the schema but what happens when",
    "start": "2363100",
    "end": "2369520"
  },
  {
    "text": "you have a data pipeline and two processes are communicating through a file on the file system right or they're",
    "start": "2369520",
    "end": "2376960"
  },
  {
    "text": "communicating through a pipe or data streaming through what guarantee do they have that the reader and writer are",
    "start": "2376960",
    "end": "2382510"
  },
  {
    "text": "using the same schema like do they do they agree on the types of the fields in",
    "start": "2382510",
    "end": "2387820"
  },
  {
    "text": "that data to degree in the cardinality of the fields this is the problem that Avro solves right Avro is applies a",
    "start": "2387820",
    "end": "2395380"
  },
  {
    "text": "schema on top of data at rest or streaming so that there's a contract and",
    "start": "2395380",
    "end": "2400480"
  },
  {
    "text": "data doesn't get corrupt so it supports Prem of data types into on boolean float",
    "start": "2400480",
    "end": "2405850"
  },
  {
    "text": "string that sort of stuff complex nested data types records arrays unions maps and it has language bindings",
    "start": "2405850",
    "end": "2412900"
  },
  {
    "text": "to various languages at least until recently I would say it was the most",
    "start": "2412900",
    "end": "2418660"
  },
  {
    "text": "common a structure format we like used for big data you know but now I guess",
    "start": "2418660",
    "end": "2426670"
  },
  {
    "text": "we're seeing more and more parkade right but it was definitely for a long period of time the the format of choice and it",
    "start": "2426670",
    "end": "2434830"
  },
  {
    "text": "supports schema evolution so why is it useful alright so a gari is an IOT",
    "start": "2434830",
    "end": "2440080"
  },
  {
    "start": "2438000",
    "end": "2603000"
  },
  {
    "text": "company ok we have sensors deployed in our customer sites those sensors are",
    "start": "2440080",
    "end": "2446940"
  },
  {
    "text": "upgraded at different times we have no control over when a customer will",
    "start": "2446940",
    "end": "2452290"
  },
  {
    "text": "upgrade their sensor so they're all running different versions of the code and they're actually sending different",
    "start": "2452290",
    "end": "2458020"
  },
  {
    "text": "versions of the format to us right so maybe version one is sending three fields version two is have added two",
    "start": "2458020",
    "end": "2465280"
  },
  {
    "text": "more fields to the data sent to us and version three has added two fields and drop two fields right and at any given",
    "start": "2465280",
    "end": "2472060"
  },
  {
    "text": "time that mix of data formats is coming over Kinesis to us and to make matters",
    "start": "2472060",
    "end": "2477610"
  },
  {
    "text": "slightly more complicated the the version that we're expecting on our side is a different version as well so very",
    "start": "2477610",
    "end": "2486490"
  },
  {
    "text": "early on before we even had our first customer we pick Avro as our serialization format to support this",
    "start": "2486490",
    "end": "2493600"
  },
  {
    "text": "specific use case we should never know the format of the data coming over the wire it should be transparent and the",
    "start": "2493600",
    "end": "2501250"
  },
  {
    "text": "way this is done is the code in the server is sort of compiled against version v4 and the code running and all",
    "start": "2501250",
    "end": "2508150"
  },
  {
    "text": "these consumers is compiled against different versions we call one a writer schema version and one a reader schema",
    "start": "2508150",
    "end": "2514390"
  },
  {
    "text": "version the readers on the you know is on V 4 and the writers on V 1 V 2 V 3",
    "start": "2514390",
    "end": "2519870"
  },
  {
    "text": "and when the reader has to read the code it hands in both the reader and writer",
    "start": "2519870",
    "end": "2524920"
  },
  {
    "text": "schema and it gets a clean union of that data and never need to worry about it so",
    "start": "2524920",
    "end": "2530320"
  },
  {
    "text": "as long as the reader the writer schema is passed with every message over the",
    "start": "2530320",
    "end": "2536200"
  },
  {
    "text": "pipe and the and a got like the the cloud-based service has access to it it",
    "start": "2536200",
    "end": "2541720"
  },
  {
    "text": "can do this schema resolution and we never have to worry about backward compatibility and we do we do enforce",
    "start": "2541720",
    "end": "2548350"
  },
  {
    "text": "backward compatibility in a Jenkins job if you have questions I can talk about that afterwards so it became so useful",
    "start": "2548350",
    "end": "2555370"
  },
  {
    "text": "as a tool to shield us from data format issues with our customers we used it",
    "start": "2555370",
    "end": "2560500"
  },
  {
    "text": "inside our pipeline for every step so all our processes are decoupled from each other not just by virtue of using",
    "start": "2560500",
    "end": "2567730"
  },
  {
    "text": "cues like Kinesis but also because the data format supports automatic schema",
    "start": "2567730",
    "end": "2572800"
  },
  {
    "text": "evolution and because we're a Silicon Valley company you know of 20 engineers",
    "start": "2572800",
    "end": "2578470"
  },
  {
    "text": "we need to have at least four different languages so everything is written in a different language rails Python and Java",
    "start": "2578470",
    "end": "2586840"
  },
  {
    "text": "are all involved in decoding and encoding stuff and setting stuff in the",
    "start": "2586840",
    "end": "2592360"
  },
  {
    "text": "pipeline and we have no J's now so unluckily that also supports Averell so",
    "start": "2592360",
    "end": "2597520"
  },
  {
    "text": "there are language bindings for all of these languages so as an example this is",
    "start": "2597520",
    "end": "2603910"
  },
  {
    "start": "2603000",
    "end": "2633000"
  },
  {
    "text": "a schema an average schema you have a record type we calling that a guru user",
    "start": "2603910",
    "end": "2611050"
  },
  {
    "text": "is a user record and the user record has the name as well as the user's favorite",
    "start": "2611050",
    "end": "2616750"
  },
  {
    "text": "number and the users favorite color and the first field is a required field the",
    "start": "2616750",
    "end": "2622090"
  },
  {
    "text": "name is required and the second two fields favorite number and favorite color you'll see it has this weird notation looks like an array of int and",
    "start": "2622090",
    "end": "2629830"
  },
  {
    "text": "nan or string and L it just means it's an optional field so as I mentioned Avro",
    "start": "2629830",
    "end": "2635950"
  },
  {
    "start": "2633000",
    "end": "2666000"
  },
  {
    "text": "is very common in the big data world and is typically used to write large files at rest on like HDFS where the block",
    "start": "2635950",
    "end": "2643450"
  },
  {
    "text": "size is like 64 MB and and the schema is placed at the top of the file as JSON",
    "start": "2643450",
    "end": "2650440"
  },
  {
    "text": "and then there are just datum in binary written below it and when you have a",
    "start": "2650440",
    "end": "2657190"
  },
  {
    "text": "million or billion of these records the overhead of the schema is tiny like 0.001 percent it's like very very common",
    "start": "2657190",
    "end": "2664120"
  },
  {
    "text": "as an overhead for the schema but what happens if you're streaming one record at a time over Kinesis",
    "start": "2664120",
    "end": "2670619"
  },
  {
    "start": "2666000",
    "end": "2701000"
  },
  {
    "text": "right or Kafka in that case the schemas 99% of your data you actually don't want",
    "start": "2670619",
    "end": "2676799"
  },
  {
    "text": "to send the schema with every single message that you sent this is overhead",
    "start": "2676799",
    "end": "2682369"
  },
  {
    "text": "so one thing that we've I think the last time I gave this talk I promised out",
    "start": "2682369",
    "end": "2687390"
  },
  {
    "text": "open-source this and I haven't got around to it so I promise you yet again that we're going to open source this is a schema registry",
    "start": "2687390",
    "end": "2694140"
  },
  {
    "text": "it comes with Alec confluent there is like an implementation we've implemented something on a lambda that is like very",
    "start": "2694140",
    "end": "2700559"
  },
  {
    "text": "effective very lightweight essentially we have a lambda and it has two",
    "start": "2700559",
    "end": "2707249"
  },
  {
    "start": "2701000",
    "end": "3107000"
  },
  {
    "text": "functions so sometimes people talk about it's a function as a service we we actually don't follow that model we",
    "start": "2707249",
    "end": "2713339"
  },
  {
    "text": "actually dispatch to multiple functions in a lambda and so one of the functions is register schema so in this case our",
    "start": "2713339",
    "end": "2719400"
  },
  {
    "text": "producer before it sends a message down the pipe will register a schema and we'll get back a unique ID",
    "start": "2719400",
    "end": "2725400"
  },
  {
    "text": "in fact UUID and it will then send that UUID plus a datum across the wire and",
    "start": "2725400",
    "end": "2731210"
  },
  {
    "text": "the consumer will get the ID and the datum so the problem is it's got this",
    "start": "2731210",
    "end": "2736680"
  },
  {
    "text": "data it doesn't have the writer schema yet it has an ID to get a writer schema it will then do a lookup by get schema",
    "start": "2736680",
    "end": "2743670"
  },
  {
    "text": "by ID get the writer schema and cache it and then it will use that along with its",
    "start": "2743670",
    "end": "2750059"
  },
  {
    "text": "you know what it compiled against the reader schema to decode it on the fly and that's essentially how we use it so",
    "start": "2750059",
    "end": "2756269"
  },
  {
    "text": "in every place we use kinases we have this lambda schema registry and we cut down on all hours all the time taking to",
    "start": "2756269",
    "end": "2763109"
  },
  {
    "text": "process this data we you know all the time send in transmission and processing",
    "start": "2763109",
    "end": "2768980"
  },
  {
    "text": "so um I think at this point I'm actually ready for questions of course none of",
    "start": "2768980",
    "end": "2775079"
  },
  {
    "text": "what we've done is a single man effort multiple people in my team have been helping and you know any questions yes",
    "start": "2775079",
    "end": "2785480"
  },
  {
    "text": "yes the question is was I talking about a diverse number like a Java lambda functional number of you right AWS",
    "start": "2790420",
    "end": "2795710"
  },
  {
    "text": "lambda thank you sure okay so the way",
    "start": "2795710",
    "end": "2807319"
  },
  {
    "text": "Kinesis works is that you get it's very much a kafka you get sharp partitions",
    "start": "2807319",
    "end": "2813230"
  },
  {
    "text": "and each partition is provisioned with a very strict IO limit and let's say so",
    "start": "2813230",
    "end": "2819380"
  },
  {
    "text": "for a given partition you can do a thousand put a second and five reads a",
    "start": "2819380",
    "end": "2825289"
  },
  {
    "text": "second okay so what happens is what happens when you exceed that well you",
    "start": "2825289",
    "end": "2830390"
  },
  {
    "text": "get throttled by Amazon right so you have to so when that happens you have to",
    "start": "2830390",
    "end": "2836480"
  },
  {
    "text": "scale out your shards okay the problem with the scale out of these shards is that the way Amazon they do",
    "start": "2836480",
    "end": "2845119"
  },
  {
    "text": "what's called a split of shards the way they split the shard is they put an end of shard marker in the old shard and and",
    "start": "2845119",
    "end": "2852440"
  },
  {
    "text": "create two new ones splitting the shot the the key space they don't actually cut the the amount of data on the two in",
    "start": "2852440",
    "end": "2859910"
  },
  {
    "text": "half they don't like divide the shard move the data in half so so what they do is they just put it they just and the",
    "start": "2859910",
    "end": "2865640"
  },
  {
    "text": "current chart and they create two empty sure to empty shards now that's what a shard split is in in Amazon are you",
    "start": "2865640",
    "end": "2872690"
  },
  {
    "text": "following that yep right so now what happens it typically is but you find",
    "start": "2872690",
    "end": "2879710"
  },
  {
    "text": "that your when you find that you're in trouble with a shard is typically on the reading side you're you're falling",
    "start": "2879710",
    "end": "2886460"
  },
  {
    "text": "behind in processing on the reading side and there's a huge you're like behind by",
    "start": "2886460",
    "end": "2891769"
  },
  {
    "text": "let's say eight hours or a couple hours you just behind by a couple hours splitting the shard doesn't help you",
    "start": "2891769",
    "end": "2897200"
  },
  {
    "text": "you're still behind you don't get you don't magically get to X the read capacity that you need it so that's one",
    "start": "2897200",
    "end": "2905239"
  },
  {
    "text": "problem you know they say that shot splits are very cheap and fast and this",
    "start": "2905239",
    "end": "2910249"
  },
  {
    "text": "is why they're cheap and trusts they're not moving the data round the second problem is no one should have to worry",
    "start": "2910249",
    "end": "2916309"
  },
  {
    "text": "about this right with SMS and SQS you get magical automatic horizontal scaling it",
    "start": "2916309",
    "end": "2924390"
  },
  {
    "text": "shouldn't be provisioned io and so had we stuck with it we could just process",
    "start": "2924390",
    "end": "2929550"
  },
  {
    "text": "everything in parallel and never have to worry about oh you know this is our",
    "start": "2929550",
    "end": "2935820"
  },
  {
    "text": "expected capacity and this is how much we've provisioned and so what we currently have is an air flow job that",
    "start": "2935820",
    "end": "2942330"
  },
  {
    "text": "does like like pre-emptive scaling when we're close to meet it like hitting a boundary we start adding shards and and",
    "start": "2942330",
    "end": "2950340"
  },
  {
    "text": "we need a job to maintain that in the SMSs qf model it is automatically scales",
    "start": "2950340",
    "end": "2955770"
  },
  {
    "text": "under the hood Amazon itself keeps adding instances when it internally it's",
    "start": "2955770",
    "end": "2961200"
  },
  {
    "text": "hitting 80 percent capacity on any one of the sqs partitions that's what we would like I hope to the answer",
    "start": "2961200",
    "end": "2967740"
  },
  {
    "text": "your version okay in the back okay so his question is in our implementation of",
    "start": "2967740",
    "end": "2973590"
  },
  {
    "text": "the schema registry are we always caching the writer schema on the consumer side or is it a lookup per",
    "start": "2973590",
    "end": "2980790"
  },
  {
    "text": "object so the answer is yeah we're always caching and interestingly enough it's a half of our functions that moved",
    "start": "2980790",
    "end": "2987420"
  },
  {
    "text": "to lambdas and those lambdas are calling this lambda and we find this is how we",
    "start": "2987420",
    "end": "2993750"
  },
  {
    "text": "found out our lambdas are very long-lived because they're all lambdas reading from Kinesis they live for three",
    "start": "2993750",
    "end": "2999330"
  },
  {
    "text": "days so so they're the hits to the schema registry lambda from one of our",
    "start": "2999330",
    "end": "3005540"
  },
  {
    "text": "normal processing chain lambdas are very low they cache for like few days the",
    "start": "3005540",
    "end": "3011210"
  },
  {
    "text": "answer cooking ok good ok so that's a really good question this question is what is the scale that we are seeing the",
    "start": "3011210",
    "end": "3019310"
  },
  {
    "text": "scale that we are seeing is tens of millions an hour sometimes more depends",
    "start": "3019310",
    "end": "3026330"
  },
  {
    "text": "on the hour of the day and some things that we do like we can some parts of our",
    "start": "3026330",
    "end": "3031490"
  },
  {
    "text": "code we have to reprocess and we can push 400 million through in about a day",
    "start": "3031490",
    "end": "3037790"
  },
  {
    "text": "like on a reprocessing use case if you have to if we have to make a change to our scoring algorithm or something we",
    "start": "3037790",
    "end": "3043820"
  },
  {
    "text": "sometimes reprocess I mentioned we have elastic search if I add a new field and",
    "start": "3043820",
    "end": "3049340"
  },
  {
    "text": "we maintain 60 days of data security the data for us or 500 million records so",
    "start": "3049340",
    "end": "3054500"
  },
  {
    "text": "if we add a new field for that one Kinesis hop we have to basically push 500 million records in and it takes",
    "start": "3054500",
    "end": "3060920"
  },
  {
    "text": "about like a day any other questions perfect great question so his question",
    "start": "3060920",
    "end": "3067340"
  },
  {
    "text": "is what's the trade-off of EMR versus self-hosted so it took us like an hour to so the palm with EMR is we cannot",
    "start": "3067340",
    "end": "3074450"
  },
  {
    "text": "specify our own am i right so we would get the EMR ami and then we start",
    "start": "3074450",
    "end": "3080420"
  },
  {
    "text": "installing like tons of Python packages that would take 40 minutes and then we're ready to use it right so then you",
    "start": "3080420",
    "end": "3087170"
  },
  {
    "text": "know so so that was a major problem like that spin up time so that's why we moved",
    "start": "3087170",
    "end": "3093200"
  },
  {
    "text": "away from the EMR thank you",
    "start": "3093200",
    "end": "3099630"
  },
  {
    "text": "[Applause]",
    "start": "3099630",
    "end": "3106018"
  }
]
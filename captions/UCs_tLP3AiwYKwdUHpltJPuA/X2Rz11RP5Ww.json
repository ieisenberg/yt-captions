[
  {
    "text": "so first i'm gonna of course before i share the use cases and what hadoop can do for you",
    "start": "7040",
    "end": "13440"
  },
  {
    "text": "a little background is good so i'm going to talk about why hadoop is important and what",
    "start": "13440",
    "end": "19920"
  },
  {
    "text": "problems in the industry has led to this technology being so hot i'm also going to talk about a high",
    "start": "19920",
    "end": "26320"
  },
  {
    "text": "level the hadoop ecosystem all the components but trying to explain them",
    "start": "26320",
    "end": "32480"
  },
  {
    "text": "in pure english and then i'm going to talk about the actual use cases the most typical ones",
    "start": "32480",
    "end": "38559"
  },
  {
    "text": "that our customers deploy in production today and also my favorite part of this talk",
    "start": "38559",
    "end": "44719"
  },
  {
    "text": "i hope we get to it is to talk about my top five favorite use cases that are a",
    "start": "44719",
    "end": "50559"
  },
  {
    "text": "little bit more advanced than the common one",
    "start": "50559",
    "end": "55440"
  },
  {
    "text": "so our industry is data challenged what what do i mean by that well first of all",
    "start": "56320",
    "end": "61920"
  },
  {
    "text": "the volume of data is growing exponentially pushing our traditional",
    "start": "61920",
    "end": "66960"
  },
  {
    "text": "storage and processing systems to the banks many organizations can't really cost",
    "start": "66960",
    "end": "73600"
  },
  {
    "text": "efficiently scale with the traditional storage systems it will break their i.t budgets",
    "start": "73600",
    "end": "79200"
  },
  {
    "text": "if they have to invest in as much data storage and processing systems that",
    "start": "79200",
    "end": "85200"
  },
  {
    "text": "should actually host all the data they need to save and store and process this",
    "start": "85200",
    "end": "91680"
  },
  {
    "text": "means that many organizations are forced to prematurely archive data which then",
    "start": "91680",
    "end": "98560"
  },
  {
    "text": "limits the timely access to such data it also forces organizations to choose what data",
    "start": "98560",
    "end": "105040"
  },
  {
    "text": "to save in the first place keeping only the necessary which then",
    "start": "105040",
    "end": "110320"
  },
  {
    "text": "limits the chances of getting back and getting bigger insights across that data at a later point in",
    "start": "110320",
    "end": "115840"
  },
  {
    "text": "time if your business needs happen to change",
    "start": "115840",
    "end": "121040"
  },
  {
    "text": "this volume also puts pressure on you know coming up with more efficient",
    "start": "121520",
    "end": "128080"
  },
  {
    "text": "ways to process the data you still might have the same slas and",
    "start": "128080",
    "end": "133280"
  },
  {
    "text": "same fixed time window and imagine them pushing more data through that time window you need a system that can scale",
    "start": "133280",
    "end": "139840"
  },
  {
    "text": "out the actual processing phase how do you do that and also",
    "start": "139840",
    "end": "145280"
  },
  {
    "text": "in today's society we we generate more data in a faster pace than we've ever done before so there's this",
    "start": "145280",
    "end": "152640"
  },
  {
    "text": "rapid pace of data coming in in systems need to scale out as well",
    "start": "152640",
    "end": "159280"
  },
  {
    "text": "the third challenge in today's industry is around the new types of data this might be the",
    "start": "159280",
    "end": "165440"
  },
  {
    "text": "most hot topic and most talked about you know what value can we actually extract from",
    "start": "165440",
    "end": "171920"
  },
  {
    "text": "twitter data or geographical location from your cell phones text messages or",
    "start": "171920",
    "end": "180080"
  },
  {
    "text": "you know all these new forms of data that we generate in faster pace like images and videos and",
    "start": "180080",
    "end": "187440"
  },
  {
    "text": "even voice recordings what can we extract from all this information to better get to know our customers",
    "start": "187440",
    "end": "195040"
  },
  {
    "text": "our patients our clients or our society environment in general",
    "start": "195040",
    "end": "202720"
  },
  {
    "text": "traditional systems here again suffer from the pain of being a little bit",
    "start": "202720",
    "end": "208239"
  },
  {
    "text": "inflexible traditional systems require you to define what structure this data should be",
    "start": "208239",
    "end": "214560"
  },
  {
    "text": "stored with up front so in a database you need to decide the table",
    "start": "214560",
    "end": "220080"
  },
  {
    "text": "and the columns and the you know different fields and data types you're going to save there",
    "start": "220080",
    "end": "225680"
  },
  {
    "text": "and that basically means it arrogantly assumes that you know all the questions",
    "start": "225680",
    "end": "230879"
  },
  {
    "text": "you can ask on that data up front it makes you ignore the business might",
    "start": "230879",
    "end": "236319"
  },
  {
    "text": "change down the road and need to aggregate twitter data with you know traditional customer",
    "start": "236319",
    "end": "242560"
  },
  {
    "text": "records or something else so how do you efficiently and cost",
    "start": "242560",
    "end": "247840"
  },
  {
    "text": "you know within cost reasonably sized budgets handle this new type of data remodeling",
    "start": "247840",
    "end": "256160"
  },
  {
    "text": "is not easy and it's impacting your data center and operations costs",
    "start": "256160",
    "end": "263520"
  },
  {
    "text": "so those are the challenges in today's industry around data and what what has that led",
    "start": "263520",
    "end": "269919"
  },
  {
    "text": "to well organizations are striving to rethink data what if we don't have to",
    "start": "269919",
    "end": "280240"
  },
  {
    "text": "fit into traditional systems are there other alternatives that are more cost efficient um what if we can find",
    "start": "280240",
    "end": "287759"
  },
  {
    "text": "other technologies that doesn't force this structure up front and there are many different you know",
    "start": "287759",
    "end": "294320"
  },
  {
    "text": "ideas and innovation over the last years out there in this area of problem right the two drivers that",
    "start": "294320",
    "end": "303520"
  },
  {
    "text": "has emerged at least from my perspective in my experience are we want to do the same",
    "start": "303520",
    "end": "310000"
  },
  {
    "text": "thing we usually do in our traditional environment within the same fixed time window",
    "start": "310000",
    "end": "318320"
  },
  {
    "text": "but over larger sets of data or we want to do more complex queries",
    "start": "318320",
    "end": "325759"
  },
  {
    "text": "because we have more complex business needs but those queries take too long to even",
    "start": "325759",
    "end": "331680"
  },
  {
    "text": "respond or the data is located in archived systems so we have to pull it back and",
    "start": "331680",
    "end": "338160"
  },
  {
    "text": "that takes four weeks in our organization so i can't really wait for that anymore",
    "start": "338160",
    "end": "343199"
  },
  {
    "text": "so this access immediate access to data and also cost efficient system to enable",
    "start": "343199",
    "end": "348880"
  },
  {
    "text": "that is one core driver in organizations that i see that are wait for it looking at hadoop",
    "start": "348880",
    "end": "355919"
  },
  {
    "text": "but i'm going to get into a dupe very very soon another big driver is more on the",
    "start": "355919",
    "end": "364000"
  },
  {
    "text": "visionary side what's next what new competitive solutions or offerings or business ideas can we",
    "start": "364000",
    "end": "371120"
  },
  {
    "text": "provide to win in a more and more competitive market where services",
    "start": "371120",
    "end": "376880"
  },
  {
    "text": "start to be more important than sometimes the actual product you know how can we optimize our",
    "start": "376880",
    "end": "383039"
  },
  {
    "text": "processes in our organizations how can we provide customer support how can we",
    "start": "383039",
    "end": "388800"
  },
  {
    "text": "you know meet the customer where they are when they need us to meet us there is",
    "start": "388800",
    "end": "394720"
  },
  {
    "text": "there anything hidden in all this new data that we can extract to help us get there faster",
    "start": "394720",
    "end": "401280"
  },
  {
    "text": "and this part is actually where i burn the most for this technology",
    "start": "401280",
    "end": "406400"
  },
  {
    "text": "because this is where new innovation can truly happen i've seen some fantastic use cases and",
    "start": "406400",
    "end": "412720"
  },
  {
    "text": "i'm going to talk about them at the end but basically the concept of this",
    "start": "412720",
    "end": "418080"
  },
  {
    "text": "new data what can we aggregate old data with new data what insights can we get from it",
    "start": "418080",
    "end": "423919"
  },
  {
    "text": "is hidden in the sentence of there's no longer a box there is no box we can think",
    "start": "423919",
    "end": "431680"
  },
  {
    "text": "about questions across all our data we don't have to limit ourselves to",
    "start": "431840",
    "end": "437280"
  },
  {
    "text": "think in that predetermined table of databases and data warehouses that we've been forced to",
    "start": "437280",
    "end": "443599"
  },
  {
    "text": "limit ourselves to so hadoop comes around five or so years ago and saves the day",
    "start": "443599",
    "end": "452000"
  },
  {
    "text": "well smiley i mean no solution is perfect right there is no",
    "start": "452000",
    "end": "457680"
  },
  {
    "text": "silver bullet but it's a promising technology and it's already been adopted",
    "start": "457680",
    "end": "462960"
  },
  {
    "text": "worldwide in big companies fortune 500 companies are running this in production today",
    "start": "462960",
    "end": "468080"
  },
  {
    "text": "and they have shown real value and it's here to stay so yeah comes to save the day",
    "start": "468080",
    "end": "475280"
  },
  {
    "text": "why well on a very very high level these are the key promising features",
    "start": "475280",
    "end": "481840"
  },
  {
    "text": "of hadoop and its ecosystem scalable storage and processing weave together through",
    "start": "481840",
    "end": "489680"
  },
  {
    "text": "the simple architecture of taking the data split it up into equally sized chunks",
    "start": "489680",
    "end": "495840"
  },
  {
    "text": "laid out beautifully across commodity hardware no special sauce then put a framework on",
    "start": "495840",
    "end": "502960"
  },
  {
    "text": "top of it let that framework contain the logic and also the capability of extracting",
    "start": "502960",
    "end": "510720"
  },
  {
    "text": "that information you want to do something with all done in parallel on these equally sized",
    "start": "510720",
    "end": "516880"
  },
  {
    "text": "chunks allows this technology to scale linearly if you have equally sized",
    "start": "516880",
    "end": "525200"
  },
  {
    "text": "chunks that all are executed logic upon in parallel",
    "start": "525200",
    "end": "530560"
  },
  {
    "text": "there's no stopping adding more nodes to it and expanding the processing capacity",
    "start": "530560",
    "end": "535760"
  },
  {
    "text": "in a linear way the other beauty of hadoop is",
    "start": "535760",
    "end": "543120"
  },
  {
    "text": "the structure at query time you don't have to decide up front what",
    "start": "543120",
    "end": "549279"
  },
  {
    "text": "structure you're going to apply what questions you're going to answer with that form of data",
    "start": "549279",
    "end": "555920"
  },
  {
    "text": "and you can easily change your mind down the road and apply structure whenever you want to",
    "start": "555920",
    "end": "562399"
  },
  {
    "text": "find out something new you design a new structure and apply it onto the data at query time",
    "start": "562399",
    "end": "568640"
  },
  {
    "text": "so structure is separately stored and hosted from the data in traditional systems",
    "start": "568640",
    "end": "576080"
  },
  {
    "text": "it's weaved together so this brings a lot of flexibility to ask",
    "start": "576080",
    "end": "581440"
  },
  {
    "text": "any questions when your business needs",
    "start": "581440",
    "end": "586800"
  },
  {
    "text": "change a common deployment model moving into a little bit closer to reality now",
    "start": "588839",
    "end": "596240"
  },
  {
    "text": "is to deploy and use hadoop as an enterprise data hub this is a new architectural concept that",
    "start": "596320",
    "end": "602640"
  },
  {
    "text": "came around last year so it's very fresh to put a name to this concept it's a landing zone for all your data",
    "start": "602640",
    "end": "609920"
  },
  {
    "text": "where you can store it forever cost efficiently and then as new use cases comes up new",
    "start": "609920",
    "end": "615680"
  },
  {
    "text": "needs for scale you can either bring those workloads into work natively on where data is stored inside",
    "start": "615680",
    "end": "622959"
  },
  {
    "text": "this enterprise data hub or you can pro pre-process it there and then serve it",
    "start": "622959",
    "end": "628880"
  },
  {
    "text": "through specialized systems elsewhere in your data park so the enterprise data hub is the",
    "start": "628880",
    "end": "635040"
  },
  {
    "text": "landing zone for data it allows scalable and cost efficient",
    "start": "635040",
    "end": "640560"
  },
  {
    "text": "processing some workloads operate natively",
    "start": "640560",
    "end": "646079"
  },
  {
    "text": "for other use cases you serve it through expert systems",
    "start": "646079",
    "end": "650959"
  },
  {
    "text": "so the ecosystem i talked about hadoop what is it well it's a distributed file system storage",
    "start": "653040",
    "end": "659920"
  },
  {
    "text": "layer with a framework that allows you to implement arbitrary logic first identify what",
    "start": "659920",
    "end": "668000"
  },
  {
    "text": "data you want to extract from your entire data set or specific data set inside your file system and then",
    "start": "668000",
    "end": "676000"
  },
  {
    "text": "what logic to apply onto that data that you extracted that framework is called map reduce",
    "start": "676000",
    "end": "683360"
  },
  {
    "text": "mapping out the data you want to do something with reduce it down to the results your your",
    "start": "683360",
    "end": "689279"
  },
  {
    "text": "want to ask your data for so a framework to operate",
    "start": "689279",
    "end": "695120"
  },
  {
    "text": "in parallel and a distributed file system and then fair enough i need to mention yarn yarn is a fairly new piece in",
    "start": "695120",
    "end": "703839"
  },
  {
    "text": "hadoop that enables you more efficient resource scheduling",
    "start": "703839",
    "end": "709200"
  },
  {
    "text": "so as you bring more and more workload to this platform you need to be aware that each workload",
    "start": "709200",
    "end": "715839"
  },
  {
    "text": "takes resources cpu memory and divide that in a in a you know fairway or a better",
    "start": "715839",
    "end": "723279"
  },
  {
    "text": "scheduling or workloads on the same cluster right so that's an improvement",
    "start": "723279",
    "end": "728399"
  },
  {
    "text": "around resource scheduling",
    "start": "728399",
    "end": "731839"
  },
  {
    "text": "to process data in the cluster you need to actually get the data into the cluster",
    "start": "734079",
    "end": "740240"
  },
  {
    "text": "the most common ways of doing that is using either scoop or flume scoop is the connector that brings",
    "start": "740240",
    "end": "747279"
  },
  {
    "text": "structure data into the platform and where which you can also use to export",
    "start": "747279",
    "end": "752480"
  },
  {
    "text": "structure data back to your optimized systems for serving if you want to it's a",
    "start": "752480",
    "end": "759360"
  },
  {
    "text": "bi-directional structure connector flume is designed to handle more",
    "start": "759360",
    "end": "764959"
  },
  {
    "text": "continuously generated events such as log events or twitter feeds or sensor",
    "start": "764959",
    "end": "770160"
  },
  {
    "text": "data something continuously populated that needs to quickly land in your cluster for immediate and",
    "start": "770160",
    "end": "778320"
  },
  {
    "text": "long-term processing next of course you want to do something",
    "start": "778320",
    "end": "785200"
  },
  {
    "text": "more than just code java right there are other users of data out there",
    "start": "785200",
    "end": "790800"
  },
  {
    "text": "some with sql expertise around hadoop there were other projects",
    "start": "790800",
    "end": "796399"
  },
  {
    "text": "popping up such as hive and pig allowing you to use more traditional query languages so hive",
    "start": "796399",
    "end": "804000"
  },
  {
    "text": "is the sql translator from sql to mapreduce allowing you for batch",
    "start": "804000",
    "end": "810320"
  },
  {
    "text": "oriented sql queries onto your data still stored",
    "start": "810320",
    "end": "815519"
  },
  {
    "text": "as files pig is a more process oriented query",
    "start": "815519",
    "end": "822560"
  },
  {
    "text": "language it allows you flexibility in how to query on your data also translates to mapreduce processing",
    "start": "822560",
    "end": "830240"
  },
  {
    "text": "the data in parallel and returning the results back to you",
    "start": "830240",
    "end": "835519"
  },
  {
    "text": "and then we have a bunch of pre-implemented libraries built for mapreduce these",
    "start": "835519",
    "end": "842480"
  },
  {
    "text": "mentioned here are machine learning libraries providing algorithms as mapreduce jobs",
    "start": "842480",
    "end": "850720"
  },
  {
    "text": "such as clustering or categorization or if you want to build a recommendation engine it's already a set of neat functions to",
    "start": "850720",
    "end": "858240"
  },
  {
    "text": "build that out for you then last year last year i say",
    "start": "858240",
    "end": "866639"
  },
  {
    "text": "was the year where where hadoop was taken seriously this is where big banks and governments",
    "start": "866639",
    "end": "873519"
  },
  {
    "text": "and and telcos and healthcare started putting this into production",
    "start": "873519",
    "end": "879040"
  },
  {
    "text": "this is when the technology was that mature and enough production management tools",
    "start": "879040",
    "end": "884240"
  },
  {
    "text": "around it was ready to safely bring customers into production",
    "start": "884240",
    "end": "890720"
  },
  {
    "text": "that's where also other needs came around which required more real-time interaction",
    "start": "890720",
    "end": "895760"
  },
  {
    "text": "remember we talked in the beginning about not only providing storage and",
    "start": "895760",
    "end": "900880"
  },
  {
    "text": "processing capacity but also providing the access you don't want a stale archive you want",
    "start": "900880",
    "end": "907199"
  },
  {
    "text": "interactive archive so these real-time workloads came around impala is the real-time query engine",
    "start": "907199",
    "end": "916320"
  },
  {
    "text": "not batch real-time still sql based just as hive",
    "start": "916320",
    "end": "923120"
  },
  {
    "text": "still supporting jdbc and odbc and all the bi tools but it's real time then we have",
    "start": "923120",
    "end": "930800"
  },
  {
    "text": "taken an effort to integrate solar a well established and mature search engine",
    "start": "930800",
    "end": "937519"
  },
  {
    "text": "with the rest of the platform so you can enable search across all your data free text search",
    "start": "937519",
    "end": "943839"
  },
  {
    "text": "just like google and then we integrated most recently spark",
    "start": "943839",
    "end": "949680"
  },
  {
    "text": "which is a real time processing framework that operates on data in memory instead of on disk so it's a faster version of",
    "start": "949680",
    "end": "958399"
  },
  {
    "text": "mapreduce if you will",
    "start": "958399",
    "end": "961759"
  },
  {
    "text": "and then a side note there are also other storage forms hbase it's a column oriented key value store",
    "start": "964639",
    "end": "972399"
  },
  {
    "text": "so that you can easily store for a specific key sparsely populated data okay what does",
    "start": "972399",
    "end": "978880"
  },
  {
    "text": "that mean well maybe you can envision all the visitors to website",
    "start": "978880",
    "end": "985360"
  },
  {
    "text": "they are the keys their session ids or their you know if you can identify them",
    "start": "985360",
    "end": "990480"
  },
  {
    "text": "they're cookies and then every click they did in that website session that's sparsely populated",
    "start": "990480",
    "end": "998079"
  },
  {
    "text": "because every visitor do not click every link and it can easily help you",
    "start": "998079",
    "end": "1004000"
  },
  {
    "text": "scan out what users clicked on a certain link or what users stopped visiting my site",
    "start": "1004000",
    "end": "1011440"
  },
  {
    "text": "after visiting this particular location in my web experience a lot of click stream analytics are",
    "start": "1011440",
    "end": "1018480"
  },
  {
    "text": "built on top of hps zookeeper is kind of a background animal",
    "start": "1018480",
    "end": "1024558"
  },
  {
    "text": "it's taking care of the process failover hbase for instance is a distributed",
    "start": "1024559",
    "end": "1031600"
  },
  {
    "text": "service on the cluster so is solar when one node goes down of this service",
    "start": "1031600",
    "end": "1038079"
  },
  {
    "text": "someone takes to need to take over that workload zookeeper manages that failover and also keeps the configurations up to",
    "start": "1038079",
    "end": "1045038"
  },
  {
    "text": "date then we introduce sentry this is also along the lines of",
    "start": "1045039",
    "end": "1051120"
  },
  {
    "text": "bringing customers into production for real when you do that especially in sensitive",
    "start": "1051120",
    "end": "1057360"
  },
  {
    "text": "environments you need to provide access control now that you bring all these audiences",
    "start": "1057360",
    "end": "1062480"
  },
  {
    "text": "to the same platform access to all your data don't you want",
    "start": "1062480",
    "end": "1067520"
  },
  {
    "text": "to control it for what user group needs to access what part of that data that's sentry",
    "start": "1067520",
    "end": "1074720"
  },
  {
    "text": "then we have hugh and uzi which is kind of the end user facing component uzi is a workflow",
    "start": "1076480",
    "end": "1082720"
  },
  {
    "text": "scheduler almost like an orchestration tool where you can schedule",
    "start": "1082720",
    "end": "1088320"
  },
  {
    "text": "a workflow of jobs for instance you ingest some data you want to etl process that",
    "start": "1088320",
    "end": "1094640"
  },
  {
    "text": "cleanse it you want to aggregate that data with another data set and then you want to do some high batch",
    "start": "1094640",
    "end": "1100720"
  },
  {
    "text": "queries on that and then you want to report that to some bi tool that is a workflow",
    "start": "1100720",
    "end": "1107120"
  },
  {
    "text": "those kind of workflows on top of hadoop you can do through uzi and then we have",
    "start": "1107120",
    "end": "1112720"
  },
  {
    "text": "hue which is the user interface the graphical web app where there are",
    "start": "1112720",
    "end": "1118400"
  },
  {
    "text": "many different applications that allows you to interact with every component in hadoop",
    "start": "1118400",
    "end": "1123760"
  },
  {
    "text": "we have the file browser we have the query application we have the uzi workflow designer we",
    "start": "1123760",
    "end": "1130880"
  },
  {
    "text": "have in you know search application if you want all these applications allow end users",
    "start": "1130880",
    "end": "1137120"
  },
  {
    "text": "to interact with the data and that's it hadoop in",
    "start": "1137120",
    "end": "1143280"
  },
  {
    "text": "i don't know 10 minutes 15 maybe and here for your records is hadoop in",
    "start": "1143280",
    "end": "1150320"
  },
  {
    "text": "english now we're finally at the part that i",
    "start": "1150320",
    "end": "1156799"
  },
  {
    "text": "love talking about what time do i have 30 minutes",
    "start": "1156799",
    "end": "1162840"
  },
  {
    "text": "perfect all right so i can go as long or as short as you want",
    "start": "1162840",
    "end": "1169520"
  },
  {
    "text": "you know when you get tired of me talking about this part start asking questions",
    "start": "1169520",
    "end": "1176480"
  },
  {
    "text": "not on the first slide though um so there are three typical use cases",
    "start": "1176720",
    "end": "1183440"
  },
  {
    "text": "that you know i spent a lot of time thinking about this before this talk",
    "start": "1183440",
    "end": "1188880"
  },
  {
    "text": "um it's hard to define but i've i've distilled it to some top level",
    "start": "1188880",
    "end": "1194320"
  },
  {
    "text": "categories of use cases the two most common ones number one",
    "start": "1194320",
    "end": "1199919"
  },
  {
    "text": "etl offload this is where remember i talked in the beginning about the",
    "start": "1199919",
    "end": "1204960"
  },
  {
    "text": "customers wanting to do what they used to do but over larger data sets to meet that",
    "start": "1204960",
    "end": "1210559"
  },
  {
    "text": "fixed time window sla so this is addressing that of like okay",
    "start": "1210559",
    "end": "1216640"
  },
  {
    "text": "i want to cleanse my data but now i have twice the financial transactions",
    "start": "1216640",
    "end": "1222320"
  },
  {
    "text": "to process within the same from you know market closing time to market",
    "start": "1222320",
    "end": "1227840"
  },
  {
    "text": "open time fixed window how am i going to do that or 10 times the transaction load",
    "start": "1227840",
    "end": "1233440"
  },
  {
    "text": "because people are trading on their cell phones it's not like they only did it when they",
    "start": "1233440",
    "end": "1239120"
  },
  {
    "text": "came home and sat at their home pc anymore they do it online all the time",
    "start": "1239120",
    "end": "1244400"
  },
  {
    "text": "so the trading records that needs to be compliant with u.s regulations still needs to be",
    "start": "1244400",
    "end": "1251760"
  },
  {
    "text": "processed in the same fixed time window how do you do that without you know exploding your i.t budget",
    "start": "1251760",
    "end": "1259360"
  },
  {
    "text": "that's what people do with hadoop they offload that processing that etl",
    "start": "1259360",
    "end": "1267440"
  },
  {
    "text": "or decorating of data i want to combine two data says before i store them in the database because the combination",
    "start": "1267440",
    "end": "1274159"
  },
  {
    "text": "of those data sets allows me of a more optimized infrastructure or it saves manual processing time",
    "start": "1274159",
    "end": "1281679"
  },
  {
    "text": "i can streamlab that aggregation on hadoop through a mapreduce job or a spark job",
    "start": "1281679",
    "end": "1288240"
  },
  {
    "text": "and just scale that better than in traditions traditional systems i i think this first",
    "start": "1288240",
    "end": "1294720"
  },
  {
    "text": "one yeah is great it saves a lot of money but it doesn't",
    "start": "1294720",
    "end": "1300559"
  },
  {
    "text": "it's boring you know yeah okay you can do that and that's what most customers do it's a",
    "start": "1300720",
    "end": "1306960"
  },
  {
    "text": "safe bet to show value on hadoop but it's not that inspiring what can you",
    "start": "1306960",
    "end": "1312640"
  },
  {
    "text": "do with new data right that's lurking around the corners that at least for an",
    "start": "1312640",
    "end": "1318640"
  },
  {
    "text": "innovator like myself makes me drool you know this is just standard etl but at larger",
    "start": "1318640",
    "end": "1325200"
  },
  {
    "text": "scale second one is for organizations with challenges around keeping silo",
    "start": "1325200",
    "end": "1332000"
  },
  {
    "text": "data around so you have one system for billing one system for customer record patient",
    "start": "1332000",
    "end": "1339360"
  },
  {
    "text": "records let's switch business patient records and then you have various blood values",
    "start": "1339360",
    "end": "1346480"
  },
  {
    "text": "in some other system and then you have nurses notes and the medical history all",
    "start": "1346480",
    "end": "1351520"
  },
  {
    "text": "these copies of data perhaps the treatment data is also in the billing system",
    "start": "1351520",
    "end": "1357440"
  },
  {
    "text": "you know it gets hard to get an overview what really is going on once a mistreatment happens or once",
    "start": "1357440",
    "end": "1366400"
  },
  {
    "text": "some insurance claims goes you know escalates and gets really really",
    "start": "1366400",
    "end": "1372400"
  },
  {
    "text": "difficult to solve you know you want to quickly get the full view what really happened",
    "start": "1372400",
    "end": "1378799"
  },
  {
    "text": "in today's system you have to go to all these different systems to extract information and kind of manually almost manually",
    "start": "1378799",
    "end": "1386159"
  },
  {
    "text": "leave that inside together what those customers that have all these various data sets",
    "start": "1386159",
    "end": "1393200"
  },
  {
    "text": "do with hadoop is to put that all in into hadoop serve the different",
    "start": "1393200",
    "end": "1399280"
  },
  {
    "text": "audiences from there you have free text search for nurses",
    "start": "1399280",
    "end": "1404400"
  },
  {
    "text": "you have uh you know impala the real time query engine for",
    "start": "1404400",
    "end": "1410240"
  },
  {
    "text": "medical reports over the last three months of you know medical usage of component a",
    "start": "1410240",
    "end": "1416880"
  },
  {
    "text": "you have mapreduce for extracting or combining data doing dedupe of",
    "start": "1416880",
    "end": "1423520"
  },
  {
    "text": "patient names or weaving together two different identities that should be the same person because it was spelled",
    "start": "1423520",
    "end": "1430480"
  },
  {
    "text": "differently at two different hospitals you know all those workloads can be done",
    "start": "1430480",
    "end": "1435679"
  },
  {
    "text": "on the same platform just storing the data once and you can still serve all those audiences and give",
    "start": "1435679",
    "end": "1442480"
  },
  {
    "text": "access to that data and a better full view that's what people do with hadoop",
    "start": "1442480",
    "end": "1448080"
  },
  {
    "text": "that's more interesting but where i really enjoy myself",
    "start": "1448080",
    "end": "1455600"
  },
  {
    "text": "is when i get to talk about the third part so that's what i'm going to focus on now",
    "start": "1455600",
    "end": "1461760"
  },
  {
    "text": "i don't really have a label for it as you see it's like a i don't know what to call it advanced analytics doesn't really cover what i",
    "start": "1461760",
    "end": "1469360"
  },
  {
    "text": "mean but it's more it's more about combining all these data sets",
    "start": "1469360",
    "end": "1475440"
  },
  {
    "text": "not only to serve that use case but actually to do something new and different",
    "start": "1475440",
    "end": "1481600"
  },
  {
    "text": "here are some examples on a high level maybe it doesn't look",
    "start": "1483039",
    "end": "1489600"
  },
  {
    "text": "different but i think it's cool when you go into a little bit more detail so that's",
    "start": "1489600",
    "end": "1494720"
  },
  {
    "text": "what i'm gonna do and i need some water before i do that",
    "start": "1494720",
    "end": "1501840"
  },
  {
    "text": "are you with me so far good",
    "start": "1504799",
    "end": "1509440"
  },
  {
    "text": "so i picked a few here event prediction what if we could predict the future it",
    "start": "1512159",
    "end": "1518799"
  },
  {
    "text": "would be exciting that's what i do on a daily basis um so here we had a customer who",
    "start": "1518799",
    "end": "1526480"
  },
  {
    "text": "or many customers actually but i'm going to have one example in my head when explaining this use case this was a",
    "start": "1526480",
    "end": "1534159"
  },
  {
    "text": "component provider and sometimes components fail",
    "start": "1534159",
    "end": "1540559"
  },
  {
    "text": "and if they happen to fail in a region where there aren't any stock components around",
    "start": "1540559",
    "end": "1546240"
  },
  {
    "text": "the weight for new components can be very long so the question was how do we optimize",
    "start": "1546240",
    "end": "1553120"
  },
  {
    "text": "our replacement logistics like how do we make sure the components",
    "start": "1553120",
    "end": "1559440"
  },
  {
    "text": "are there when the customer component fails or the customer using that component when the",
    "start": "1559440",
    "end": "1564960"
  },
  {
    "text": "component fails so what they did was extract all the phone home",
    "start": "1564960",
    "end": "1570080"
  },
  {
    "text": "files or logs from all their customers over the last 10 years",
    "start": "1570080",
    "end": "1576799"
  },
  {
    "text": "all of it in the same platform and trying to extract patterns",
    "start": "1576799",
    "end": "1584320"
  },
  {
    "text": "like okay if component a fails and then component b fails then it seems more often",
    "start": "1584320",
    "end": "1592159"
  },
  {
    "text": "like component x fails too that's what i mean with a pattern or",
    "start": "1592159",
    "end": "1598880"
  },
  {
    "text": "it seems like if we install a new component x five months later that fails",
    "start": "1598880",
    "end": "1606559"
  },
  {
    "text": "five months later that fails so extracting these patterns over phone home logs to to",
    "start": "1606559",
    "end": "1613679"
  },
  {
    "text": "come up with better logistics of okay now this customer set has had",
    "start": "1613679",
    "end": "1620320"
  },
  {
    "text": "component x installed for four months and 20 days we're going to send out a",
    "start": "1620320",
    "end": "1625360"
  },
  {
    "text": "replacement component right now while we in another part of our organization",
    "start": "1625360",
    "end": "1631200"
  },
  {
    "text": "also look at improving the process and the durability of component x",
    "start": "1631200",
    "end": "1637039"
  },
  {
    "text": "so this insight across 10 years of phone home log data and component failure just one use case",
    "start": "1637039",
    "end": "1644720"
  },
  {
    "text": "on that data led to a lot of improvements and saving them a lot of money",
    "start": "1644720",
    "end": "1650320"
  },
  {
    "text": "and also increasing the customer satisfaction because their customers experienced less",
    "start": "1650320",
    "end": "1655360"
  },
  {
    "text": "downtime because the component arrived before it failed makes sense made sense to them",
    "start": "1655360",
    "end": "1662880"
  },
  {
    "text": "they were very happy saved millions",
    "start": "1662880",
    "end": "1668559"
  },
  {
    "text": "anomaly detection this is something really hot in the uh in the fraud you know claims fraud",
    "start": "1668559",
    "end": "1675679"
  },
  {
    "text": "departments in the insurance industry or in the infosec departments in many",
    "start": "1675679",
    "end": "1683120"
  },
  {
    "text": "high-tech companies or banks you know that one little outlier that doesn't match the",
    "start": "1683120",
    "end": "1690480"
  },
  {
    "text": "normal behavior but how do you extract normal behavior",
    "start": "1690480",
    "end": "1695760"
  },
  {
    "text": "well another customer example you use mapreduce over lots and lots of",
    "start": "1695760",
    "end": "1702000"
  },
  {
    "text": "data from you know three years back to extract patterns again or",
    "start": "1702000",
    "end": "1709600"
  },
  {
    "text": "calculate distributions and then from the very same platform",
    "start": "1709600",
    "end": "1714799"
  },
  {
    "text": "where you fuel ingest this data in you match incoming data with that",
    "start": "1714799",
    "end": "1719919"
  },
  {
    "text": "distribution in the very same platform and you trigger an alert once incoming",
    "start": "1719919",
    "end": "1725120"
  },
  {
    "text": "values are not within the distribution or not meeting that pattern that you've also calculated on the very same platform",
    "start": "1725120",
    "end": "1732720"
  },
  {
    "text": "and you can immediately drill down and look at that either through impala or search and address the problem",
    "start": "1732720",
    "end": "1738960"
  },
  {
    "text": "validate that it's real and do something about it along that",
    "start": "1738960",
    "end": "1744960"
  },
  {
    "text": "you get the log storage to cost efficiently scale you can do more accurate you know",
    "start": "1744960",
    "end": "1752240"
  },
  {
    "text": "extractions of fraud patterns over 10 years of data instead of three months of data",
    "start": "1752240",
    "end": "1758640"
  },
  {
    "text": "right you can go and find those tiny anomalies that isn't evident to the human eye",
    "start": "1758640",
    "end": "1767520"
  },
  {
    "text": "this is the capacity of storing such and executing such a use case on hadoop",
    "start": "1767520",
    "end": "1774960"
  },
  {
    "text": "customer profiling i'm 50 50 around this because i don't i",
    "start": "1776480",
    "end": "1783120"
  },
  {
    "text": "kind of don't want to companies to know too much about me but on the other hand it's very nice",
    "start": "1783120",
    "end": "1789440"
  },
  {
    "text": "when you know i get the best big discount on something i really want so it's like good and bad",
    "start": "1789440",
    "end": "1795200"
  },
  {
    "text": "but this is a funny story",
    "start": "1795200",
    "end": "1800240"
  },
  {
    "text": "and it's a good example of what kind of value you can get from looking at unstructured data so",
    "start": "1800480",
    "end": "1808640"
  },
  {
    "text": "this company had a food product and they were planning their investment",
    "start": "1808640",
    "end": "1815840"
  },
  {
    "text": "budgets for next year and they wanted to know what flavor",
    "start": "1815840",
    "end": "1820880"
  },
  {
    "text": "should we invest more in marketing wise right to increase our sales the most",
    "start": "1820880",
    "end": "1827039"
  },
  {
    "text": "and all their traditional systems where they've stored all their data show them that vanilla is the thing you",
    "start": "1827039",
    "end": "1833600"
  },
  {
    "text": "should go for vanilla is what customers buy the most so there was a plan in place to go",
    "start": "1833600",
    "end": "1839440"
  },
  {
    "text": "and invest more in vanilla it's just that some tiny department in this company",
    "start": "1839440",
    "end": "1845120"
  },
  {
    "text": "went and also ingested tons of twitter data and extracted their brand name",
    "start": "1845120",
    "end": "1852799"
  },
  {
    "text": "from that data processed any tweet that had the brand name right and looked at is there any",
    "start": "1853200",
    "end": "1859440"
  },
  {
    "text": "adjective here that what what kind of taste names can we extract and they knew their tastes you",
    "start": "1859440",
    "end": "1867039"
  },
  {
    "text": "know all the production ones and all the trial ones that were popular to have tasting events in",
    "start": "1867039",
    "end": "1873519"
  },
  {
    "text": "different regions and believe it or not what really trended on twitter was",
    "start": "1873519",
    "end": "1878960"
  },
  {
    "text": "pineapple where can i find pineapple i can't buy it turns out pineapple taste",
    "start": "1878960",
    "end": "1885840"
  },
  {
    "text": "was a trial run in one region and then it just spread",
    "start": "1885840",
    "end": "1890880"
  },
  {
    "text": "like a fire on twitter everybody wanted pineapple while the traditional store data showed them",
    "start": "1890880",
    "end": "1896880"
  },
  {
    "text": "vanilla so what did they do they invested a little bit in both and guess what pineapples sold much more",
    "start": "1896880",
    "end": "1905200"
  },
  {
    "text": "that's what you can find out if you get to combine traditional you know",
    "start": "1905200",
    "end": "1911600"
  },
  {
    "text": "the store data the data you have access to in your um you know all the transactions from",
    "start": "1911600",
    "end": "1917120"
  },
  {
    "text": "your customers all the orders with external data that can give you additional input",
    "start": "1917120",
    "end": "1924720"
  },
  {
    "text": "then we have a common question like why do customers not like us anymore",
    "start": "1927279",
    "end": "1935278"
  },
  {
    "text": "how do we prevent customers from turning away from our service that was a big question asked and of",
    "start": "1935679",
    "end": "1942640"
  },
  {
    "text": "course the reports showed yeah hey your customers are declining in",
    "start": "1942640",
    "end": "1948880"
  },
  {
    "text": "number but it didn't explain why and here we go into what i think is the",
    "start": "1948880",
    "end": "1956640"
  },
  {
    "text": "one key takeaway if you want to understand what hadoop can do for you",
    "start": "1956640",
    "end": "1961679"
  },
  {
    "text": "is that when you get that alert of like something is wrong you can go in in and understand more",
    "start": "1961679",
    "end": "1970399"
  },
  {
    "text": "in this platform so how how did they do that well they had all the information stored",
    "start": "1970399",
    "end": "1976480"
  },
  {
    "text": "in hadoop they had the emails with customer support they had the transactions",
    "start": "1976480",
    "end": "1982080"
  },
  {
    "text": "whatever and they also had the voice recordings from their support service",
    "start": "1982080",
    "end": "1987200"
  },
  {
    "text": "voice recordings what did they do they used hadoop's cost efficient scale processing power",
    "start": "1987200",
    "end": "1993279"
  },
  {
    "text": "and measured extracted the decibel level in the support calls to extract the",
    "start": "1993279",
    "end": "2001279"
  },
  {
    "text": "subset of calls where people obviously were upset and then they went",
    "start": "2001279",
    "end": "2008000"
  },
  {
    "text": "and drilled down into they used those customer ids to go and look at their data their",
    "start": "2008000",
    "end": "2015760"
  },
  {
    "text": "support data and they realized in that study what happened just before was that they",
    "start": "2015760",
    "end": "2023039"
  },
  {
    "text": "had gone through very very awkward you know phone choose many calls",
    "start": "2023039",
    "end": "2031200"
  },
  {
    "text": "like maybe five ten calls and many options through their call process and then were",
    "start": "2031200",
    "end": "2036880"
  },
  {
    "text": "met with this really simplistic support service script and it",
    "start": "2036880",
    "end": "2043279"
  },
  {
    "text": "got just so much frustration i can relate i mean you want to get help you don't want to",
    "start": "2043279",
    "end": "2049118"
  },
  {
    "text": "you know have to make 10 calls and get weird you know can you provide your customer service number",
    "start": "2049119",
    "end": "2054960"
  },
  {
    "text": "it's the 10th time you know don't you already have this in your system no they didn't",
    "start": "2054960",
    "end": "2060320"
  },
  {
    "text": "so what they did was to optimize that path and believe it or not their customer",
    "start": "2060320",
    "end": "2066638"
  },
  {
    "text": "number was adjusted they did some other things too but you",
    "start": "2066639",
    "end": "2073280"
  },
  {
    "text": "get the point last one how am i doing on time",
    "start": "2073280",
    "end": "2081839"
  },
  {
    "text": "i'm good perfect then i get to do a bonus part as well",
    "start": "2081839",
    "end": "2088720"
  },
  {
    "text": "so how do we increase our online sales okay did it make the cut of interesting",
    "start": "2088720",
    "end": "2096320"
  },
  {
    "text": "maybe it did what they did was save all the you know click streams in age space they looked at",
    "start": "2096320",
    "end": "2104079"
  },
  {
    "text": "they extracted from hbase the ones where people left left the site after",
    "start": "2104079",
    "end": "2111040"
  },
  {
    "text": "starting a transaction path putting items into their cart but then leaving the cart",
    "start": "2111040",
    "end": "2119920"
  },
  {
    "text": "why well it turns out sometimes options are bad",
    "start": "2119920",
    "end": "2128480"
  },
  {
    "text": "it turns out they they looked at these customers they had other similarities in their profile too",
    "start": "2128480",
    "end": "2135520"
  },
  {
    "text": "frequent frequency of visits other sales in the past",
    "start": "2135520",
    "end": "2140880"
  },
  {
    "text": "but it turns out their ad placement had actually put multiple ads around similar um you know",
    "start": "2140880",
    "end": "2148800"
  },
  {
    "text": "let's say it's a it's a table and there were three or four paths to go",
    "start": "2148800",
    "end": "2155359"
  },
  {
    "text": "to the next level around table but there were duplicates and there were very similar items it wasn't clear to",
    "start": "2155359",
    "end": "2161599"
  },
  {
    "text": "the end user what to do it was not easy to go to the next step because it they had",
    "start": "2161599",
    "end": "2167200"
  },
  {
    "text": "actually too many options so the end user got confused and instead left the cart hanging what they did was",
    "start": "2167200",
    "end": "2174640"
  },
  {
    "text": "simplify only present two options not six or seven or whatever it was",
    "start": "2174640",
    "end": "2181680"
  },
  {
    "text": "and thereby streamline the process to a finished sale over prioritizing like they had in the",
    "start": "2181680",
    "end": "2188480"
  },
  {
    "text": "past of presenting more opportunity to buy so those all those more opportunity to",
    "start": "2188480",
    "end": "2195200"
  },
  {
    "text": "buy options confuse the customers instead of streamlining it to close of deal",
    "start": "2195200",
    "end": "2201599"
  },
  {
    "text": "so they changed their online revenue because of this insight through agespace",
    "start": "2201599",
    "end": "2210640"
  },
  {
    "text": "bonus part five minutes",
    "start": "2211760",
    "end": "2216160"
  },
  {
    "text": "prepare yourself how do we solve this",
    "start": "2220560",
    "end": "2229359"
  },
  {
    "text": "well there's a company these are extremes you realize i work in",
    "start": "2229359",
    "end": "2235359"
  },
  {
    "text": "this business day in and day out i have all these big data use cases in my head",
    "start": "2235359",
    "end": "2241040"
  },
  {
    "text": "these are the extremes that i love so there's a company who takes",
    "start": "2241040",
    "end": "2247599"
  },
  {
    "text": "images from low altitude little satellites the quality of those images",
    "start": "2247599",
    "end": "2255040"
  },
  {
    "text": "aren't perfect but they use hadoop to store all images and then they do some",
    "start": "2255040",
    "end": "2260960"
  },
  {
    "text": "advanced magic image processing of over laying images to get clear views",
    "start": "2260960",
    "end": "2268400"
  },
  {
    "text": "using such a technology using such parallelized image processing around",
    "start": "2268960",
    "end": "2276640"
  },
  {
    "text": "a very very large set of images can help rescue teams to understand",
    "start": "2276640",
    "end": "2283680"
  },
  {
    "text": "where it's most safe to land to help pick up people or provide medicare",
    "start": "2283680",
    "end": "2291280"
  },
  {
    "text": "they cannot do this in real time or in enough quick time if they didn't have",
    "start": "2291359",
    "end": "2298880"
  },
  {
    "text": "this kind of capacity platform to process that image size like i don't know",
    "start": "2298880",
    "end": "2307040"
  },
  {
    "text": "exactly the number but we're talking about terabytes of images right",
    "start": "2307040",
    "end": "2313839"
  },
  {
    "text": "but they help people by doing this and that makes me really happy",
    "start": "2314480",
    "end": "2321280"
  },
  {
    "text": "another one how do we prevent suicide so it turns out the suicide rate among",
    "start": "2321359",
    "end": "2328160"
  },
  {
    "text": "veterans is very high but there's no research or there's no",
    "start": "2328160",
    "end": "2334960"
  },
  {
    "text": "not much information why like for some there's suicide on the agenda and",
    "start": "2334960",
    "end": "2341040"
  },
  {
    "text": "some are not and this is a very depressing topic i know but the ending is good so bear with me so there was this",
    "start": "2341040",
    "end": "2348800"
  },
  {
    "text": "company who worked several years to get permission to look at 10 years of",
    "start": "2348800",
    "end": "2356560"
  },
  {
    "text": "medical data for suicide victims and this is sensitive information right",
    "start": "2356560",
    "end": "2363920"
  },
  {
    "text": "it's not easy to get permission from those families affected but in the end",
    "start": "2363920",
    "end": "2369760"
  },
  {
    "text": "persistence helped so this guy created some natural",
    "start": "2369760",
    "end": "2376560"
  },
  {
    "text": "pros natural language processing algorithms in mapreduce and stored all",
    "start": "2376560",
    "end": "2383280"
  },
  {
    "text": "these 10 years of data nurses notes phone calls whatever medical records i don't have",
    "start": "2383280",
    "end": "2390000"
  },
  {
    "text": "insight in all of the types there but he did natural language processing and extracted the most",
    "start": "2390000",
    "end": "2396079"
  },
  {
    "text": "common terms used by suicide victims in their communication",
    "start": "2396079",
    "end": "2402160"
  },
  {
    "text": "and then he created an application that people who wanted to be part of this program could opt in to install on their",
    "start": "2402160",
    "end": "2410160"
  },
  {
    "text": "cell phone to capture facebook messages text messages",
    "start": "2410160",
    "end": "2416480"
  },
  {
    "text": "any kind of communication phone calls and get mapped to these patterns these",
    "start": "2416480",
    "end": "2423200"
  },
  {
    "text": "frequency of usage of word words for instance i'm fine",
    "start": "2423200",
    "end": "2428240"
  },
  {
    "text": "you know or or the um you know i all these little reports of daily",
    "start": "2428240",
    "end": "2433920"
  },
  {
    "text": "activities whatever patterns he extracted he could match incoming communication",
    "start": "2433920",
    "end": "2440800"
  },
  {
    "text": "against that and actually mathematically prove there's an eighty percent likelihood of",
    "start": "2440800",
    "end": "2447920"
  },
  {
    "text": "this person committing suicide soon so that medical efforts could be put in place to",
    "start": "2447920",
    "end": "2454640"
  },
  {
    "text": "help that individual and i'm not saying this particular part",
    "start": "2454640",
    "end": "2460079"
  },
  {
    "text": "that i'm going to share now is related but i heard it on the radio the other day and i know this went into production you know uh",
    "start": "2460079",
    "end": "2467920"
  },
  {
    "text": "last year or so suicide rates among veterans this year",
    "start": "2467920",
    "end": "2474160"
  },
  {
    "text": "has gone down with 20 i'm not saying it's related but i think it is",
    "start": "2474160",
    "end": "2479520"
  },
  {
    "text": "because this guy could figure that out",
    "start": "2479520",
    "end": "2483200"
  },
  {
    "text": "so how do we reduce world hunger i mean seriously are you looking at these questions do",
    "start": "2486160",
    "end": "2491520"
  },
  {
    "text": "you realize why i'm excited about this technology here we're looking at an increase in",
    "start": "2491520",
    "end": "2498640"
  },
  {
    "text": "people being born in people's health we live longer and we eat more and we have a",
    "start": "2498640",
    "end": "2505839"
  },
  {
    "text": "limited set of resources and nature is changing so how do you make crops more",
    "start": "2505839",
    "end": "2512079"
  },
  {
    "text": "sustainable so that you can feed humanity forward well",
    "start": "2512079",
    "end": "2518079"
  },
  {
    "text": "one company is looking at images of crops weaving in external data weather data",
    "start": "2518079",
    "end": "2525520"
  },
  {
    "text": "what's in the soil what equipment was used at that time for that kind of",
    "start": "2525520",
    "end": "2531520"
  },
  {
    "text": "harvest which geolocation and saving all that data into hadoop and then doing",
    "start": "2531520",
    "end": "2539599"
  },
  {
    "text": "analytics and insights across that to help more sustainable crops",
    "start": "2539599",
    "end": "2546880"
  },
  {
    "text": "in parts of the world where basically nothing can grow and that's a pretty good cause i think",
    "start": "2546880",
    "end": "2555119"
  },
  {
    "text": "and it's amazing to see technology i work on helping that",
    "start": "2555119",
    "end": "2561680"
  },
  {
    "text": "so do we want to solve cancer yes please one use case here",
    "start": "2563440",
    "end": "2571440"
  },
  {
    "text": "is in research there's so many varieties so much data",
    "start": "2571440",
    "end": "2576880"
  },
  {
    "text": "everyone is an individual how do we actually do proper research well if you have a large enough data set you",
    "start": "2576880",
    "end": "2583760"
  },
  {
    "text": "can actually make better conclusions quicker so a lot of cancer tumor",
    "start": "2583760",
    "end": "2589920"
  },
  {
    "text": "dna data pumped into hadoop with other medical data and suddenly",
    "start": "2589920",
    "end": "2596160"
  },
  {
    "text": "processing results that used to take 11 months to get like some new test result",
    "start": "2596160",
    "end": "2603440"
  },
  {
    "text": "over that particular algorithm of processing that kind of tumor dna data",
    "start": "2603440",
    "end": "2609359"
  },
  {
    "text": "went down to a month or six weeks that's the scale we're talking about",
    "start": "2609359",
    "end": "2621838"
  },
  {
    "text": "and then global warming it's nice it's warm no it's not nice what am i",
    "start": "2622480",
    "end": "2629760"
  },
  {
    "text": "talking about um and energy company decided to extract",
    "start": "2629760",
    "end": "2637440"
  },
  {
    "text": "information about all their customers and make it on a neighborhood basis and",
    "start": "2637440",
    "end": "2643200"
  },
  {
    "text": "send that back to the customers with a comparison on how much you use compared to your neighbors",
    "start": "2643200",
    "end": "2649119"
  },
  {
    "text": "and using the psychology of human mind of group pressure to lower your costs",
    "start": "2649119",
    "end": "2655920"
  },
  {
    "text": "lower your usage and becoming a greener member of this earth",
    "start": "2655920",
    "end": "2661359"
  },
  {
    "text": "that correlation and processing happen in hadoop",
    "start": "2661359",
    "end": "2666880"
  },
  {
    "text": "how do we improve education well here's where you extract where students struggle with online",
    "start": "2667920",
    "end": "2673920"
  },
  {
    "text": "education right you can have the traditional reports on yeah these many students",
    "start": "2673920",
    "end": "2681520"
  },
  {
    "text": "failed is it the teacher is it the content",
    "start": "2681520",
    "end": "2686960"
  },
  {
    "text": "what is it you can do surveys but it's always subjective what if you can get objective data",
    "start": "2686960",
    "end": "2694480"
  },
  {
    "text": "like actually measuring for every student taking a course how much time they spent on each",
    "start": "2694480",
    "end": "2700160"
  },
  {
    "text": "assignment if they failed that particular question at the test and then extract that over maybe seven",
    "start": "2700160",
    "end": "2707359"
  },
  {
    "text": "years of online students then you can get reliable insights and do corrections of the course material",
    "start": "2707359",
    "end": "2715359"
  },
  {
    "text": "to speed up more people getting educated",
    "start": "2715359",
    "end": "2720480"
  },
  {
    "text": "of course these are just tiny examples under these umbrellas there's so much more unfortunately i'm running",
    "start": "2720800",
    "end": "2727200"
  },
  {
    "text": "out of time so my last comments are just for the road which is why hadoop well it's scalable",
    "start": "2727200",
    "end": "2736079"
  },
  {
    "text": "it's cost efficient it's flexible and it's fun",
    "start": "2736079",
    "end": "2741519"
  },
  {
    "text": "and why should you think twice well do you have the right knowledge maybe",
    "start": "2742880",
    "end": "2748640"
  },
  {
    "text": "you need to go and take a training or get certified or build a team around it before you actually dive in and do something",
    "start": "2748640",
    "end": "2755599"
  },
  {
    "text": "recommendation number one maybe you don't have a big data problem",
    "start": "2755599",
    "end": "2762079"
  },
  {
    "text": "not everybody does but remember this it's not about the size of the data",
    "start": "2762079",
    "end": "2768319"
  },
  {
    "text": "sometimes it's about combining data types and traditional systems aren't really",
    "start": "2768319",
    "end": "2773520"
  },
  {
    "text": "capable doing that very well so you might have a big data problem all the big isn't the relevant part",
    "start": "2773520",
    "end": "2780800"
  },
  {
    "text": "okay and is your company ready do you have actual investments",
    "start": "2780800",
    "end": "2787520"
  },
  {
    "text": "around building a whole team around it the successful companies i've seen implementing hadoop successfully start",
    "start": "2787520",
    "end": "2795680"
  },
  {
    "text": "small they start often with the offload etl use case to show value to the rest of",
    "start": "2795680",
    "end": "2800880"
  },
  {
    "text": "the company to get more investment to build out a team but once you open the door to that",
    "start": "2800880",
    "end": "2808079"
  },
  {
    "text": "innovative part trust me there's no turning back you can",
    "start": "2808079",
    "end": "2813680"
  },
  {
    "text": "do anything with data there is no box",
    "start": "2813680",
    "end": "2818960"
  },
  {
    "text": "some recommendations to learn more for your reference and thank you",
    "start": "2819200",
    "end": "2831839"
  },
  {
    "text": "you",
    "start": "2837440",
    "end": "2839520"
  }
]
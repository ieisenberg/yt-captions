[
  {
    "start": "0",
    "end": "207000"
  },
  {
    "text": "thanks very much that's the best introduction I've had in a while wow I'm not going to live up to that um as a",
    "start": "2159",
    "end": "7279"
  },
  {
    "text": "pantheist I believe that God walks among and inside all of us so uh that's that's my position",
    "start": "7279",
    "end": "14040"
  },
  {
    "text": "um this talk is actually about um observability for platforms generally",
    "start": "14040",
    "end": "20680"
  },
  {
    "text": "so I I kind of put a dad Drake title which I now regret um so it's not about helping you understand why your app slow",
    "start": "20680",
    "end": "26800"
  },
  {
    "text": "it's about if you're in platform engineering how do you like find out that your platforms slow and and and",
    "start": "26800",
    "end": "33320"
  },
  {
    "text": "debug those issues so if you wanted to do if you wanted to talk on app latency",
    "start": "33320",
    "end": "38800"
  },
  {
    "text": "debugging this is not it please go and see one the other talks don't stay here and be like oh I didn't really want to see this but I'm a bit embarrassed to",
    "start": "38800",
    "end": "44680"
  },
  {
    "text": "leave like use your legs go for it it's uh no problem at all I don't want you to sit in a talk that you don't want to see",
    "start": "44680",
    "end": "51079"
  },
  {
    "text": "um having said that this is what I'm going to talk about um I want to acknowledge there's actually a ton of",
    "start": "51079",
    "end": "57359"
  },
  {
    "text": "this is not me this is not my work this is the work of a ton of other people people uh this is the SR team that I",
    "start": "57359",
    "end": "62399"
  },
  {
    "text": "work on um who's who's heard of SRE okay most of you but not all of you",
    "start": "62399",
    "end": "70080"
  },
  {
    "text": "so SRE is site reliability engineering site reliability engineering is applying",
    "start": "70080",
    "end": "75240"
  },
  {
    "text": "engineering principles to operations to managing systems and so the idea is that",
    "start": "75240",
    "end": "82439"
  },
  {
    "text": "instead of doing like uh click Ops where you're clicking through stuff you solve problems using engineering approaches",
    "start": "82439",
    "end": "88560"
  },
  {
    "text": "like code and talking developers um and well that that's the approach we take we",
    "start": "88560",
    "end": "94799"
  },
  {
    "text": "do still hold a Pedra so half of this team is in San Francisco half of this team is in London uh my our shifts 10: a.m. to 10",
    "start": "94799",
    "end": "102960"
  },
  {
    "text": "p.m. in San Francisco then we hand the pager over to London where at 6:00 a.m. they hold the pag to 6",
    "start": "102960",
    "end": "108840"
  },
  {
    "text": "p.m. um and when we get paged we get told like something very cryptic and then we have to go and work out firstly",
    "start": "108840",
    "end": "116240"
  },
  {
    "text": "how bad is it is it something bad how many people impacted then create an inent if it's something that is bad",
    "start": "116240",
    "end": "122079"
  },
  {
    "text": "that's impacting uh customers and then try and get that fixed as quickly as we can um so that's that's the main part of",
    "start": "122079",
    "end": "129119"
  },
  {
    "text": "the job but the rest of the job is engineering and and trying to make our systems more operable more resilient uh",
    "start": "129119",
    "end": "135800"
  },
  {
    "text": "more scalable uh and and do the best thing fundamentally for our",
    "start": "135800",
    "end": "140879"
  },
  {
    "text": "customers so all these people have helped in putting together this material and operationalizing it so I'm talking",
    "start": "140879",
    "end": "147680"
  },
  {
    "text": "about a technique or an approach to thinking about platform reliability but none of that stuff is any good unless it",
    "start": "147680",
    "end": "153680"
  },
  {
    "text": "actually helps people in real life so um other people have talked about the importance of uh treating platform as",
    "start": "153680",
    "end": "161159"
  },
  {
    "text": "product and these are my customers as well they're the people who actually if it doesn't help them do their job then",
    "start": "161159",
    "end": "167840"
  },
  {
    "text": "why am I even doing it there's also a team called Kraken here this is the team",
    "start": "167840",
    "end": "173720"
  },
  {
    "text": "that uh is is part of SRE that helps try new approaches and design or come up",
    "start": "173720",
    "end": "178959"
  },
  {
    "text": "with new ways of thinking about reliability um two of the people here uh Jeff and uh created some of the slides",
    "start": "178959",
    "end": "186959"
  },
  {
    "text": "that I've used in this presentation uh there's a bunch of other people uh at Google and outside Google who've also",
    "start": "186959",
    "end": "192560"
  },
  {
    "text": "given feedback on on these ideas um and uh will Patterson here uh",
    "start": "192560",
    "end": "199599"
  },
  {
    "text": "is the person who operationalized and implemented a bunch of the tools that I'm going to show you",
    "start": "199599",
    "end": "206239"
  },
  {
    "text": "today so IMS re for the serverless platform or this Sr team runs the",
    "start": "206239",
    "end": "213360"
  },
  {
    "start": "207000",
    "end": "472000"
  },
  {
    "text": "serverless platform what's the serverless platform so you know kuber noes is great but who here has uh",
    "start": "213360",
    "end": "220280"
  },
  {
    "text": "actually managed or operated or been in charge of a kubernetes platform okay a bunch of you so it's",
    "start": "220280",
    "end": "227040"
  },
  {
    "text": "really hard work and uh there's all kinds of things that require a lot of uh engineering and and Ops work uh what if",
    "start": "227040",
    "end": "234360"
  },
  {
    "text": "we didn't have to do that what if you could just scale up and scale down to zero uh without having to worry worry",
    "start": "234360",
    "end": "239879"
  },
  {
    "text": "about any of that well that's what the serverless platform is you can just deploy a container and the platform takes care of",
    "start": "239879",
    "end": "246439"
  },
  {
    "text": "scaling up as much as you want or scaling it down to zero so it's uh",
    "start": "246439",
    "end": "251560"
  },
  {
    "text": "pretty great actually uh I have a lot of fun working on it um because it's uh",
    "start": "251560",
    "end": "257560"
  },
  {
    "text": "when it you know when it's doing that it's really amazing to watch",
    "start": "257560",
    "end": "262759"
  },
  {
    "text": "however we're basically giving our customers the ability to create enormous amounts of stress on this platform",
    "start": "262759",
    "end": "269240"
  },
  {
    "text": "that's our business model that's how we make money by letting people come in and scale up to thousands tens of thousands",
    "start": "269240",
    "end": "274960"
  },
  {
    "text": "of instances in seconds so it's a shared platform we see that we feel that impact",
    "start": "274960",
    "end": "281919"
  },
  {
    "text": "we have customers where that's actually part of their business model if they're advertising sporting events for example",
    "start": "281919",
    "end": "287320"
  },
  {
    "text": "the sporting event starts suddenly you've got enormous amounts of traffic coming onto your platform that has an",
    "start": "287320",
    "end": "293520"
  },
  {
    "text": "impact um and there's a whole bunch of tools we use to see that and and manage",
    "start": "293520",
    "end": "298560"
  },
  {
    "text": "it but it's it's it's actually a complex problem to to deal with before I go any",
    "start": "298560",
    "end": "304960"
  },
  {
    "text": "further I want to talk at a high level about our architecture just so you kind of understand the the context for this",
    "start": "304960",
    "end": "312320"
  },
  {
    "text": "problem so we have the these are end users right these are users who are",
    "start": "312320",
    "end": "317880"
  },
  {
    "text": "using apps deployed onto our platform uh we also have customers who",
    "start": "317880",
    "end": "323400"
  },
  {
    "text": "are actually the people deploying the apps uh we have a control plane so when you push a new container",
    "start": "323400",
    "end": "330080"
  },
  {
    "text": "live on cloud run or you deploy an app or a cloud function um that gets built",
    "start": "330080",
    "end": "336000"
  },
  {
    "text": "if necessary or at least put in storage and then we have a data plane that is",
    "start": "336000",
    "end": "341639"
  },
  {
    "text": "responsible as traffic comes in for spinning up instances so uh we have jobs running on",
    "start": "341639",
    "end": "348639"
  },
  {
    "text": "Bor uh most of this stuff runs on Borg Borg is uh Google's internal uh",
    "start": "348639",
    "end": "355039"
  },
  {
    "text": "scheduling system for workloads and so we're running what's called app servers which are jobs that host containers that",
    "start": "355039",
    "end": "362280"
  },
  {
    "text": "host instances on Shar Borg uh we've got a ton of those this is not to scale and",
    "start": "362280",
    "end": "367880"
  },
  {
    "text": "so once you've deployed a container or a function or whatever and traffic starts coming in this is where those containers",
    "start": "367880",
    "end": "374720"
  },
  {
    "text": "start spinning up and uh serving traffic when traffic comes in it first",
    "start": "374720",
    "end": "381080"
  },
  {
    "text": "of all goes to a networking component near the user so the user may be in a completely different part of the world",
    "start": "381080",
    "end": "387560"
  },
  {
    "text": "from the container that's going to serve their traffic so firstly their request is going to go to this networking",
    "start": "387560",
    "end": "392759"
  },
  {
    "text": "component near the user and then it's going to be rooted to another traffic component here a networking component",
    "start": "392759",
    "end": "400039"
  },
  {
    "text": "here that's near the app and then this component here is in charge of actually working out where to send it so if",
    "start": "400039",
    "end": "407960"
  },
  {
    "text": "there's no instance currently running to serve that traffic there's going to be some negotiation while a container starts up um and then traffic gets sens",
    "start": "407960",
    "end": "415160"
  },
  {
    "text": "to that instance if there's a whole bunch of instances it'll pick one if that particular app server is overloaded",
    "start": "415160",
    "end": "420479"
  },
  {
    "text": "it might push back so that the traffic get S into a different one so there's actually quite a lot of work done in",
    "start": "420479",
    "end": "425879"
  },
  {
    "text": "negotiating where to send traffic and and how it gets served and so forth so it's a ton of complexity in actually how",
    "start": "425879",
    "end": "431840"
  },
  {
    "text": "this this platform Works um and for you as a customer of the platform you know my instance is here it's like the total",
    "start": "431840",
    "end": "438360"
  },
  {
    "text": "perspective vortex in the hitri skies of the Galaxy it's one little point in this enormous uh amount of stuff but it's",
    "start": "438360",
    "end": "444599"
  },
  {
    "text": "very important to you which means that it's very important to us too",
    "start": "444599",
    "end": "451240"
  },
  {
    "text": "who here has worked on uh a platform and you've had one of the customers of your platform deploying apps say oh my app",
    "start": "451240",
    "end": "458120"
  },
  {
    "text": "slow can you help me does anyone had that yeah and I can see those people",
    "start": "458120",
    "end": "463199"
  },
  {
    "text": "going yes I had that problem and now I'm very tired um because it's really hard",
    "start": "463199",
    "end": "469520"
  },
  {
    "text": "to diagnose like there's so many things that could go wrong with your app um and",
    "start": "469520",
    "end": "474759"
  },
  {
    "start": "472000",
    "end": "596000"
  },
  {
    "text": "in some cases it's cuz you changed something right you might have changed some code you might have changed some config uh that might had caused the",
    "start": "474759",
    "end": "479840"
  },
  {
    "text": "problem but there's many things that could be that are nothing to do with the customer so there might be some I mean",
    "start": "479840",
    "end": "486240"
  },
  {
    "text": "there's always dependencies right your instance is talking to a bunch of stuff the platform your instance is running on",
    "start": "486240",
    "end": "492080"
  },
  {
    "text": "is talking to a bunch of stuff those things can change their behavior um that happens all the time in complex systems",
    "start": "492080",
    "end": "498560"
  },
  {
    "text": "if that's not happening that's actually a sign that something's wrong um there might be a change in traffic buttons to",
    "start": "498560",
    "end": "504280"
  },
  {
    "text": "apps or other apps running on the same app servers or in the same region and that can cause uh a lot of slushing",
    "start": "504280",
    "end": "510280"
  },
  {
    "text": "around that can change latency as well we make changes to the platform all the",
    "start": "510280",
    "end": "515320"
  },
  {
    "text": "time um other teams make changes to the dependencies of our stuff on on other parts of Google's platform um and and",
    "start": "515320",
    "end": "522680"
  },
  {
    "text": "those confli changes uh might par all the unit tests but actually cause disruption uh down the train because",
    "start": "522680",
    "end": "529279"
  },
  {
    "text": "complex systems have emerging behavior and even if your components behaving fine interactions with other components",
    "start": "529279",
    "end": "534920"
  },
  {
    "text": "can cause problems that you couldn't have predicted we did do have uh issues where",
    "start": "534920",
    "end": "541800"
  },
  {
    "text": "if uh an an instance on an app server gets a ton of traffic that's going to impact the behavior of the other",
    "start": "541800",
    "end": "547279"
  },
  {
    "text": "instances on the same job potentially um or even in the same cell uh that happens",
    "start": "547279",
    "end": "552440"
  },
  {
    "text": "in the case of deny of service attacks for example and we have very robust protections for denial of service attacks but you can while those are",
    "start": "552440",
    "end": "559399"
  },
  {
    "text": "kicking in that might cause problems um abuse is one example of where that happens uh abusive workloads can cause",
    "start": "559399",
    "end": "567040"
  },
  {
    "text": "similar problems um and even the way that we bin pack the app servers and uh",
    "start": "567040",
    "end": "573040"
  },
  {
    "text": "put instances in different places if that's suboptimal uh traffic shifts can cause that to become suboptimal um over",
    "start": "573040",
    "end": "579720"
  },
  {
    "text": "time uh in fact that's pretty normal and so that can cause shifts in Behavior as well",
    "start": "579720",
    "end": "586079"
  },
  {
    "text": "so when that comes in you're like well there's this huge menu of things that it could possibly be how do I even know",
    "start": "586079",
    "end": "593279"
  },
  {
    "text": "which one of them it is so the main thing we care about",
    "start": "593279",
    "end": "598519"
  },
  {
    "start": "596000",
    "end": "766000"
  },
  {
    "text": "fundamentally is our signal is customer tickets so as a customer you're you're",
    "start": "598519",
    "end": "604680"
  },
  {
    "text": "going to find some problem and if you can't work out what it is yourself you're going to create a ticket so as an",
    "start": "604680",
    "end": "612000"
  },
  {
    "text": "on call I'm not just looking at Pages I'm also looking at customer tickets coming in and if I get one customer",
    "start": "612000",
    "end": "617320"
  },
  {
    "text": "ticket then my first response is going to be well let's make sure they haven't pushed a new version or there isn't",
    "start": "617320",
    "end": "623959"
  },
  {
    "text": "something in the customers configuration that might have caused this problem but once you start getting a whole bunch of pages coming in or a whole bunch of",
    "start": "623959",
    "end": "629800"
  },
  {
    "text": "customer tickets coming in um at that point you start to think well it's probably not a customer problem that's",
    "start": "629800",
    "end": "635200"
  },
  {
    "text": "likely to be a platform problem and so at that point you really are starting to",
    "start": "635200",
    "end": "642560"
  },
  {
    "text": "think maybe I should create an incident uh once you have a bunch of customers who are giving you tickets you're going",
    "start": "642560",
    "end": "647720"
  },
  {
    "text": "to create an incident um and at that point you got to go to your observability so we have a",
    "start": "647720",
    "end": "654200"
  },
  {
    "text": "ton of logging in Google this is one of the things that as someone who worked for industry for 20 years before joining",
    "start": "654200",
    "end": "660680"
  },
  {
    "text": "Google um coming to Google and just seeing the enormous amount of data available for me to use was really great",
    "start": "660680",
    "end": "668079"
  },
  {
    "text": "so we don't just have like regular logs our logs are stuffed full of uh structured data in the form of protuff",
    "start": "668079",
    "end": "674880"
  },
  {
    "text": "so a single request that comes through our system is going to create an enormous amount of structured data uh",
    "start": "674880",
    "end": "680880"
  },
  {
    "text": "with time stamps for every part of the system that it's passed through uh information like what version of the app",
    "start": "680880",
    "end": "686360"
  },
  {
    "text": "server was running when that request was served um and tons of other metadata so we have just an enormous amount of",
    "start": "686360",
    "end": "692240"
  },
  {
    "text": "metadata in our logs we have this thing called F1 this query engine that we can just query all those different data",
    "start": "692240",
    "end": "698959"
  },
  {
    "text": "sources from logs to other systems of record within Google and join across them and and and um run requests or run",
    "start": "698959",
    "end": "705920"
  },
  {
    "text": "queries against huge amounts of data so it's actually very powerful",
    "start": "705920",
    "end": "711200"
  },
  {
    "text": "but in a sense it's kind of overwhelming um we have not only those log files",
    "start": "711200",
    "end": "716839"
  },
  {
    "text": "every job that's running on Bor emits large amounts of metadata that gets put into Monarch which is our inmemory",
    "start": "716839",
    "end": "723120"
  },
  {
    "text": "Global time series database and that data gets um used or consumed by automon",
    "start": "723120",
    "end": "730519"
  },
  {
    "text": "which is our monitoring system where we can go and get lots of graphs and see what's going on but that's kind of",
    "start": "730519",
    "end": "735720"
  },
  {
    "text": "overwhelming so what do you even look at when something like that comes",
    "start": "735720",
    "end": "741560"
  },
  {
    "text": "in slos are typically seen as the answer to this problem of how to find there's a",
    "start": "742000",
    "end": "747360"
  },
  {
    "text": "problem so um slos is basically saying well you know we don't want to go below",
    "start": "747360",
    "end": "753639"
  },
  {
    "text": "a certain level of availability once we're below a certain level of availability that's going to page us and",
    "start": "753639",
    "end": "758800"
  },
  {
    "text": "tell us something's going wrong but slos are actually problematic in the context particularly of latency so I actually",
    "start": "758800",
    "end": "765360"
  },
  {
    "text": "went and got some data from all the stuff running on the um on the",
    "start": "765360",
    "end": "770639"
  },
  {
    "start": "766000",
    "end": "866000"
  },
  {
    "text": "serverless platform and this is looking at latency so latency is along the x-axis here and this is the number of",
    "start": "770639",
    "end": "776720"
  },
  {
    "text": "requests on the y-axis and you can see this is logarithmic so the highest frequency for request latency is between",
    "start": "776720",
    "end": "784279"
  },
  {
    "text": "1 seconds and 10 seconds but then we've got these buckets um below this um and",
    "start": "784279",
    "end": "789440"
  },
  {
    "text": "there's this bucket right at the ends of requests that are between one 1 millisecond and 10 millisecond and then we've got this long tail here of uh",
    "start": "789440",
    "end": "796240"
  },
  {
    "text": "requests that take you know over 100 seconds so just the enormous amount of variability that a request might take",
    "start": "796240",
    "end": "803240"
  },
  {
    "text": "end to end um and this is measured from when you get to the networking component in the cell",
    "start": "803240",
    "end": "809440"
  },
  {
    "text": "where the request is being served to when the response to that request exits so the request gets to the cell where",
    "start": "809440",
    "end": "817480"
  },
  {
    "text": "the instance is the instance does whatever you're doing in your app and sends the request back and it exits back",
    "start": "817480",
    "end": "822920"
  },
  {
    "text": "to the user so that's the latency we're measuring here just an enormous amount of variance so you can't put a threshold",
    "start": "822920",
    "end": "830360"
  },
  {
    "text": "for an SLO that's just impossible so even detecting when",
    "start": "830360",
    "end": "836639"
  },
  {
    "text": "there's a problem is is already an issue cuz what are you going to do um you know",
    "start": "836639",
    "end": "842240"
  },
  {
    "text": "something might go up in one of these buckets but that could just be a shift in in traffic right there could be more traffic coming to a particular Endo um",
    "start": "842240",
    "end": "849279"
  },
  {
    "text": "which might show up here but it might have nothing to do with actually the platform Behavior so our first attempt",
    "start": "849279",
    "end": "855480"
  },
  {
    "text": "to think about uh latency and and platform Behavior we took just one subset or one phase of that full",
    "start": "855480",
    "end": "864000"
  },
  {
    "text": "endtoend latency so we look at this thing called request delivery latency so this is the time from when the request",
    "start": "864000",
    "end": "870680"
  },
  {
    "start": "866000",
    "end": "972000"
  },
  {
    "text": "enters the the cell where it's being served to when your app starts",
    "start": "870680",
    "end": "875920"
  },
  {
    "text": "processing that request and so already here we can get some interesting data so",
    "start": "875920",
    "end": "881240"
  },
  {
    "text": "you can see um the y- AIS here is the number of projects that are seeing uh a",
    "start": "881240",
    "end": "889079"
  },
  {
    "text": "latency above the threshold that we've chosen um for that request delivery",
    "start": "889079",
    "end": "895199"
  },
  {
    "text": "latency uh the different colors are different cells within that region so A cell is like a logical partition in um a",
    "start": "895199",
    "end": "903320"
  },
  {
    "text": "set of data centers so we have data centers in a region those are logically partitioned into logically independent",
    "start": "903320",
    "end": "909480"
  },
  {
    "text": "sections um and because serus is a regional platform apps are hosted in",
    "start": "909480",
    "end": "916399"
  },
  {
    "text": "potentially multiple different logical cells so that if one of them goes down for some reason we can still serve",
    "start": "916399",
    "end": "921600"
  },
  {
    "text": "traffic from other cells within the same region so these different colors are different cells within the same region",
    "start": "921600",
    "end": "927079"
  },
  {
    "text": "and you can see here's an Excursion here where it's impacting multiple cells so if I see that I'm already thinking okay",
    "start": "927079",
    "end": "934240"
  },
  {
    "text": "this might be a dependency within the region that is causing some kind of problem it gives you some kind of clue",
    "start": "934240",
    "end": "939560"
  },
  {
    "text": "as to what's going on but it's only still telling you about some subsection of those things that could possibly go",
    "start": "939560",
    "end": "946279"
  },
  {
    "text": "wrong it's not telling you anything about for example if there's a change in the behavior of the um of the gvisor the",
    "start": "946279",
    "end": "954079"
  },
  {
    "text": "the container technology that we use maybe that might have changed Behavior it's not going to tell you anything about depending tendencies that your app",
    "start": "954079",
    "end": "960040"
  },
  {
    "text": "might rely on because you know that's not captured in this particular phase of the end to end uh latency so this is",
    "start": "960040",
    "end": "967000"
  },
  {
    "text": "good it gives you some information but it's it's not giving you everything and in particular it's not actually",
    "start": "967000",
    "end": "972199"
  },
  {
    "start": "972000",
    "end": "1127000"
  },
  {
    "text": "representing the customer experience one of the things that we really want to do when we're thinking of of a platform is",
    "start": "972199",
    "end": "978199"
  },
  {
    "text": "some kind of metric or measure that actually represents the customer experience end to end are we measuring",
    "start": "978199",
    "end": "983639"
  },
  {
    "text": "something that's actually a good proxy for what customers are seeing because we don't want to be looking at graphs that",
    "start": "983639",
    "end": "989600"
  },
  {
    "text": "are telling us different things from the customer experience because we don't know if customers are feeling it this is the problem with cause-based",
    "start": "989600",
    "end": "996279"
  },
  {
    "text": "alerts which is we have a lot of and we have a lot of information on particular components of the system and you see",
    "start": "996279",
    "end": "1002160"
  },
  {
    "text": "this all the time like who who works in Ops and gets paged for stuff in this room okay like a few of you you get",
    "start": "1002160",
    "end": "1009160"
  },
  {
    "text": "paged for something you're like oh well the CPU is really bad on this set of boxes is it impacting customers no zero",
    "start": "1009160",
    "end": "1015759"
  },
  {
    "text": "impact on customers they're not noticing at all so if if you're getting these Pages all the time and half of them you",
    "start": "1015759",
    "end": "1021680"
  },
  {
    "text": "know you don't even know if it's got an impact on customer experience it's very painful to actually work out if you",
    "start": "1021680",
    "end": "1026720"
  },
  {
    "text": "should be doing anything about it or if you should just go back to bed um I mean we don't do night shifts because we have",
    "start": "1026720",
    "end": "1032120"
  },
  {
    "text": "London and San Francisco but you know go back to dinner let's say so you want something that actually",
    "start": "1032120",
    "end": "1037558"
  },
  {
    "text": "tells you if customers are experiencing pain that's the first thing that we want to do a second thing we want is to have",
    "start": "1037559",
    "end": "1043839"
  },
  {
    "text": "a signal that we can combine across projects so we can detect if it's how many project is impacting that's the",
    "start": "1043839",
    "end": "1049919"
  },
  {
    "text": "most important measure we care about when we're looking at the impacts for an incident how many customers are",
    "start": "1049919",
    "end": "1056000"
  },
  {
    "text": "experiencing a problem um that that severity is going to uh influence how we",
    "start": "1056000",
    "end": "1061080"
  },
  {
    "text": "respond to that particular incident we want to be able to combine it across across projects we want to be able to see if it's within a particular cell or",
    "start": "1061080",
    "end": "1067480"
  },
  {
    "text": "if it's impacting multiple cells or you know the worst case scenario if it's something that's impacting multiple regions so this signal has got to be",
    "start": "1067480",
    "end": "1074360"
  },
  {
    "text": "combinable across projects across cells and across regions so we can can reason about the global behavior of the",
    "start": "1074360",
    "end": "1081360"
  },
  {
    "text": "service uh as I say we particularly care about anomalies that impacts multiple",
    "start": "1081360",
    "end": "1087600"
  },
  {
    "text": "customers because that's what's telling us that it's a platform problem rather than just a customer problem we want",
    "start": "1087600",
    "end": "1094360"
  },
  {
    "text": "something that's cheap to compute as you can imagine we get enormous amount of traffic and so it's got to be super",
    "start": "1094360",
    "end": "1100280"
  },
  {
    "text": "cheap to compute this thing we can't do things that are computationally complex because it's just going to be overwhelming and it's going to cost us a",
    "start": "1100280",
    "end": "1106640"
  },
  {
    "text": "lot of money uh in terms of the result ources we're conceiving to process the data um so so that's a problem and",
    "start": "1106640",
    "end": "1112559"
  },
  {
    "text": "fundamentally we also want it to be principle based like when you look at this graph what's this number this number is based on basically it's",
    "start": "1112559",
    "end": "1119760"
  },
  {
    "text": "empirical it's based on experience it's not based on any particular principles",
    "start": "1119760",
    "end": "1124840"
  },
  {
    "text": "so what are the principles that we care about as a platform engineer there's kind of three things that we think are",
    "start": "1124840",
    "end": "1131360"
  },
  {
    "start": "1127000",
    "end": "1466000"
  },
  {
    "text": "important components of liability firstly obviously availability is the service there um availability is",
    "start": "1131360",
    "end": "1139440"
  },
  {
    "text": "typically kind of a yes or no thing but it can be pretty great as well but you want the service to be there and for",
    "start": "1139440",
    "end": "1145360"
  },
  {
    "text": "customers to be able customer traffic to be able to be served and then the second thing is how effectively is that done is",
    "start": "1145360",
    "end": "1151600"
  },
  {
    "text": "that done in a way um that customers actually are satisfied with or or not",
    "start": "1151600",
    "end": "1157880"
  },
  {
    "text": "and then correctness is is the service behaving in the way that meets the",
    "start": "1157880",
    "end": "1163360"
  },
  {
    "text": "specification um is the service behaving as specified uh or are unusual things",
    "start": "1163360",
    "end": "1168400"
  },
  {
    "text": "happening um not because it's not available but because it's fully available and and Performing really well",
    "start": "1168400",
    "end": "1173799"
  },
  {
    "text": "but doing weird stuff and so we have a number of different ways to validate each of these",
    "start": "1173799",
    "end": "1179600"
  },
  {
    "text": "different components of reliability for availability there's a very simple thing you can do which is",
    "start": "1179600",
    "end": "1185679"
  },
  {
    "text": "counting the number of failed requests versus the number of successful requests and the proportion tells you how",
    "start": "1185679",
    "end": "1191320"
  },
  {
    "text": "available is your service for performance what we typically do is we have probers so probers are known",
    "start": "1191320",
    "end": "1198880"
  },
  {
    "text": "workloads we just have an app that sends traffic to another app that we have both",
    "start": "1198880",
    "end": "1205159"
  },
  {
    "text": "created and both manage and those will typically be simple user Journeys with",
    "start": "1205159",
    "end": "1210240"
  },
  {
    "text": "predictable performance and because the performance is predictable we can look at like the",
    "start": "1210240",
    "end": "1215320"
  },
  {
    "text": "P99 latency and see if there's an Excursion there and then we know that there's something wrong so probers are",
    "start": "1215320",
    "end": "1221880"
  },
  {
    "text": "really useful that's the first thing we do when we spin up a new region is create probers uh and that'll help us",
    "start": "1221880",
    "end": "1228520"
  },
  {
    "text": "check performance and correctness and availability as well but that's our main way of validating performance because",
    "start": "1228520",
    "end": "1234400"
  },
  {
    "text": "the workloads are predictable in the way they behave and then correctness we have a",
    "start": "1234400",
    "end": "1240039"
  },
  {
    "text": "lot of tests so testing is super important in Google if as a developer I",
    "start": "1240039",
    "end": "1246400"
  },
  {
    "text": "send uh a poll request or a CL as we call it in Google to someone else to",
    "start": "1246400",
    "end": "1251880"
  },
  {
    "text": "review if it hasn't got any tests and I'm actually making a change uh that's not refactoring I'm going to a comment",
    "start": "1251880",
    "end": "1257480"
  },
  {
    "text": "back saying hey hey you know please write a test to cover this so we have a lot of tests a lot of unit tests a lot",
    "start": "1257480",
    "end": "1262840"
  },
  {
    "text": "of integration tests that's very important to us but uh we also have Canary analysis so when a change goes",
    "start": "1262840",
    "end": "1268880"
  },
  {
    "text": "out into production we do Canary analysis as it goes through preprod and then starts rolling out progressively to",
    "start": "1268880",
    "end": "1274919"
  },
  {
    "text": "different cells we do caner analysis to make sure that there's not a change in behavior um that that we weren't",
    "start": "1274919",
    "end": "1281200"
  },
  {
    "text": "expecting however these can't capture all the possible problems so for",
    "start": "1281200",
    "end": "1287039"
  },
  {
    "text": "availability what is actually an error so there's 400s versus 500s but",
    "start": "1287039",
    "end": "1295320"
  },
  {
    "text": "sometimes you get a 500 because of like a customer problem such as you know a malformed URL or something like that um",
    "start": "1295320",
    "end": "1302200"
  },
  {
    "text": "sometimes that can cause a 500 where you were expecting a 400 errors are fundamentally subjective and the",
    "start": "1302200",
    "end": "1308799"
  },
  {
    "text": "subjectivity of that is expressed in multiple places throughout the stack so as a request is popping back through",
    "start": "1308799",
    "end": "1314000"
  },
  {
    "text": "different layers of the stack something you have to do a translation you get an error back from from some other layer you have to work out if it's a user",
    "start": "1314000",
    "end": "1320320"
  },
  {
    "text": "error or a system error that happens multiple times as the request propagates back up through the stack and each time",
    "start": "1320320",
    "end": "1325919"
  },
  {
    "text": "a subjective decision is made which might not be what you're expecting so I think the idea that you can cleanly",
    "start": "1325919",
    "end": "1331840"
  },
  {
    "text": "separate platform errors versus user errors in practice is actually much harder than",
    "start": "1331840",
    "end": "1337080"
  },
  {
    "text": "that also we have deadlines and timeouts we have circuit breakers and so a time out could cause the 500 but that could",
    "start": "1337080",
    "end": "1343559"
  },
  {
    "text": "not be due to actually a system error it could just be due to like a latency problem um malformed requests as I say that can",
    "start": "1343559",
    "end": "1351559"
  },
  {
    "text": "cause issues in terms of the subjectivity of the errors and then if people are retrying or if our systems are retrying that can magnify errors and",
    "start": "1351559",
    "end": "1358520"
  },
  {
    "text": "cause the proportion of 500s to go way up that's actually disproportionate to the proportion of errors that are",
    "start": "1358520",
    "end": "1365039"
  },
  {
    "text": "actually happening in the system so just to say there's all these other issues that make this signal not as clean as",
    "start": "1365039",
    "end": "1370919"
  },
  {
    "text": "you would perhaps like it to be in terms of performance um those slos",
    "start": "1370919",
    "end": "1378039"
  },
  {
    "text": "are very much workload dependent and we only have a very small coverage in terms of the total behavior of the platform",
    "start": "1378039",
    "end": "1384159"
  },
  {
    "text": "necessarily probers are testing a known path through the system that's very narrow but actually most user workloads",
    "start": "1384159",
    "end": "1391120"
  },
  {
    "text": "are using a whole bunch of different features and those features can combine in unpredictable ways that where",
    "start": "1391120",
    "end": "1396679"
  },
  {
    "text": "actually you'll see problems that couldn't be caught by any individual prober so it only covers a very small",
    "start": "1396679",
    "end": "1403400"
  },
  {
    "text": "part of the state space in terms of the behavior of the system as a whole and then in terms of",
    "start": "1403400",
    "end": "1409760"
  },
  {
    "text": "correctness yes pre-prod tests are vitally important you know a lot of people talk about testing in prod for uh",
    "start": "1409760",
    "end": "1416600"
  },
  {
    "text": "production systems uh but testing in prod on its own is terribly dangerous and you shouldn't do it you need to have",
    "start": "1416600",
    "end": "1422400"
  },
  {
    "text": "pre-prod tests as well but they can't capture everything production systems necessarily um there's emergent behavior",
    "start": "1422400",
    "end": "1429240"
  },
  {
    "text": "um those systems interact in unpredictable ways uh you're not going to be able to cover all the possible scenarios again for the same reasons",
    "start": "1429240",
    "end": "1435520"
  },
  {
    "text": "that your probe is Covered N scenarios units test cover Nar narrow scenarios as well uh so you will definitely find",
    "start": "1435520",
    "end": "1441679"
  },
  {
    "text": "problems in prod that you could not have captured easily certainly using unit tests and in many cases using",
    "start": "1441679",
    "end": "1447600"
  },
  {
    "text": "integration tests as well and as we say in Sr hope is not a",
    "start": "1447600",
    "end": "1453720"
  },
  {
    "text": "strategy so with this in mind how can we think about latency regressions in the context",
    "start": "1454440",
    "end": "1462279"
  },
  {
    "text": "of platforms from the perspective of a platform operator what I have is just a",
    "start": "1462279",
    "end": "1468440"
  },
  {
    "start": "1466000",
    "end": "1569000"
  },
  {
    "text": "ton of events and those events in the case of the serverless platform are requests so",
    "start": "1468440",
    "end": "1476080"
  },
  {
    "text": "user requests to apps running on the platform so these are all our requests this x-axis is time and this Y axis is",
    "start": "1476080",
    "end": "1484240"
  },
  {
    "text": "latency and this is not meaningful or tractable in any way that's useful to me",
    "start": "1484240",
    "end": "1491880"
  },
  {
    "text": "as a platform operator but if you think of the perspective of the customer it absolutely is so a customer workload",
    "start": "1491880",
    "end": "1499840"
  },
  {
    "text": "often will have a very predictable signal certainly if my app is uh",
    "start": "1499840",
    "end": "1506520"
  },
  {
    "text": "predictable in how it behaves which you know is often a nice characteristic and",
    "start": "1506520",
    "end": "1514120"
  },
  {
    "text": "so platform you platform customers who are who are running these workloads will",
    "start": "1514120",
    "end": "1519320"
  },
  {
    "text": "have often a very clear idea if their workload is behaving as",
    "start": "1519320",
    "end": "1524520"
  },
  {
    "text": "expected and you can look at all of these different workloads",
    "start": "1524520",
    "end": "1530039"
  },
  {
    "text": "and they'll have different patterns but those patterns will be consistent over time they'll be",
    "start": "1530039",
    "end": "1536200"
  },
  {
    "text": "self-similar so that is really the key to thinking about how do we model um",
    "start": "1536200",
    "end": "1542600"
  },
  {
    "text": "detection for latency regressions is thinking about the customer perspective customers have workloads that behave in",
    "start": "1542600",
    "end": "1549559"
  },
  {
    "text": "a predictable way and what you want as a customer is fundamentally that my workload behaves the same way tomorrow",
    "start": "1549559",
    "end": "1556919"
  },
  {
    "text": "that it did today I want my workload to behave the same way consistently over time that's what I",
    "start": "1556919",
    "end": "1563080"
  },
  {
    "text": "want as a customer and so we can actually model that using statistics so",
    "start": "1563080",
    "end": "1568240"
  },
  {
    "text": "for each workload what we can do is we can look at um their latency here this",
    "start": "1568240",
    "end": "1574559"
  },
  {
    "start": "1569000",
    "end": "1640000"
  },
  {
    "text": "is bend on the x- axis and this is frequency um this is actually a real workload and what we can do is we can",
    "start": "1574559",
    "end": "1581320"
  },
  {
    "text": "fit a curve to that workload so this is a log normal curve",
    "start": "1581320",
    "end": "1586919"
  },
  {
    "text": "um and we an log normal is actually a pretty good way to model customer workloads to give you uh good coverage",
    "start": "1586919",
    "end": "1592360"
  },
  {
    "text": "which I'll talk about in more detail later but the important thing I want to emphasize over time is that characteristic sorry the important thing",
    "start": "1592360",
    "end": "1598520"
  },
  {
    "text": "I want to emphasize for this diagram is that characteristic which is that the workload behaves tomorrow the same way",
    "start": "1598520",
    "end": "1604320"
  },
  {
    "text": "as it does today what we want is the shape of this curve to stay the",
    "start": "1604320",
    "end": "1609840"
  },
  {
    "text": "same that in statistics is known as stationarity so that property is",
    "start": "1609840",
    "end": "1615039"
  },
  {
    "text": "stationarity that the curve that I fit to to those events stays the same shape",
    "start": "1615039",
    "end": "1620399"
  },
  {
    "text": "over time and so what we can do is we can take the parameters for this curve which is going to be like a mean and a",
    "start": "1620399",
    "end": "1626520"
  },
  {
    "text": "standard deviation and we can look at we can model the workloads and then we can",
    "start": "1626520",
    "end": "1632559"
  },
  {
    "text": "look at Future requests and see if they fit this distribution or not the way we do this at scale with",
    "start": "1632559",
    "end": "1640880"
  },
  {
    "start": "1640000",
    "end": "2012000"
  },
  {
    "text": "this goal of detecting platform latency regressions is called the two Sigma technique for reasons that will become",
    "start": "1640880",
    "end": "1647240"
  },
  {
    "text": "clear shortly and I just want to emphasize like we didn't invent the idea of Statistics applying to events um you",
    "start": "1647240",
    "end": "1653320"
  },
  {
    "text": "know it's not some massive kind of Google invention hey we discovered statistics um what's novel is the",
    "start": "1653320",
    "end": "1659799"
  },
  {
    "text": "application of this technique to uh latency regression in the context of",
    "start": "1659799",
    "end": "1664880"
  },
  {
    "text": "platform engineering so I gave a talk before about this and and got told off for um",
    "start": "1664880",
    "end": "1672640"
  },
  {
    "text": "people thinking I was claiming that Google invented statistics which obviously we didn't um so to Sigma",
    "start": "1672640",
    "end": "1679159"
  },
  {
    "text": "technique fundamentally our hypothesis is that workloads that behave predictively should continue to behave",
    "start": "1679159",
    "end": "1686000"
  },
  {
    "text": "in the same way over time their performance should be consistent so how we actually um",
    "start": "1686000",
    "end": "1693760"
  },
  {
    "text": "operationalize this hypothesis is we take all our workloads and we partition them into cohorts and the way we",
    "start": "1693760",
    "end": "1699919"
  },
  {
    "text": "partition them into cohorts is we want that the cohort should be self-similar over time so how do we take our",
    "start": "1699919",
    "end": "1706000"
  },
  {
    "text": "workloads and break them down in such way that we have some kind of grouping some some group of uh events that will",
    "start": "1706000",
    "end": "1713799"
  },
  {
    "text": "behave in this way and so depending on your application what your cohorts are",
    "start": "1713799",
    "end": "1718960"
  },
  {
    "text": "is going to be very different and then for each cohort you build a performance Baseline you",
    "start": "1718960",
    "end": "1724519"
  },
  {
    "text": "basically I mean the first prototype of this that we did we just did this in SQL we like selected all the events we",
    "start": "1724519",
    "end": "1731519"
  },
  {
    "text": "grouped it by um at verion in fact and then we took all the requests over the",
    "start": "1731519",
    "end": "1737039"
  },
  {
    "text": "last 30 days and we computed the mean and the standard deviation and that's just some like",
    "start": "1737039",
    "end": "1743120"
  },
  {
    "text": "basic SQL and then you can store those parameters the uh mean and the standard",
    "start": "1743120",
    "end": "1748640"
  },
  {
    "text": "deviation in a database with like an identifier for that cohort and that's all the information you really need for",
    "start": "1748640",
    "end": "1755200"
  },
  {
    "text": "actually modeling the the baselines uh uh identify for the cohort what's the mean what's the standard",
    "start": "1755200",
    "end": "1761919"
  },
  {
    "text": "deviation and then as new events come in you can take a bucket of those events over like 15 minutes and compare the",
    "start": "1761919",
    "end": "1769679"
  },
  {
    "text": "distribution of the events in that bucket to that um Baseline that you've got for that cohort and say is it the",
    "start": "1769679",
    "end": "1776080"
  },
  {
    "text": "same or has it shifted so that's the basic technique and then the result is as requests come",
    "start": "1776080",
    "end": "1782720"
  },
  {
    "text": "in each of those requests you can score it with a predicted likelihood which is called the uh zcore uh or Zed score I",
    "start": "1782720",
    "end": "1789559"
  },
  {
    "text": "can say Zed score finally um and then what you've got is a Time series of",
    "start": "1789559",
    "end": "1795279"
  },
  {
    "text": "those statistics where you can model the behavior over time and see if it's uh regressing",
    "start": "1795279",
    "end": "1800399"
  },
  {
    "text": "or diverging or not so here's our historical dat service",
    "start": "1800399",
    "end": "1805760"
  },
  {
    "text": "data as I say this is all in logs we can query those logs using SQL uh we also have that data in Monarch so we can",
    "start": "1805760",
    "end": "1812200"
  },
  {
    "text": "query it uh using time series tools as well but what we're fundamentally doing is we partition it into cohorts our",
    "start": "1812200",
    "end": "1819159"
  },
  {
    "text": "cohorts are app versions so every time you deploy a new version of your app that's a new cohort for",
    "start": "1819159",
    "end": "1825600"
  },
  {
    "text": "us and those cohort s are going to behave in different ways so here's a cohort here where you can model it quite",
    "start": "1825600",
    "end": "1831799"
  },
  {
    "text": "nicely with uh a normal distribution in fact here's something with a bimodal distribution um and we actually",
    "start": "1831799",
    "end": "1840120"
  },
  {
    "text": "originally discarded workloads that behaved like this because you can't model them with a normal distribution",
    "start": "1840120",
    "end": "1845760"
  },
  {
    "text": "we've just implemented something on the team where you use something called a box Cox transformation and you can actually transform multimodal",
    "start": "1845760",
    "end": "1852120"
  },
  {
    "text": "distributions into a log normal distribution or in fact a normal distribution so that you can still still",
    "start": "1852120",
    "end": "1857360"
  },
  {
    "text": "score it in the same way uh so there are statistics to deal with that but then you also have just very messy things",
    "start": "1857360",
    "end": "1862639"
  },
  {
    "text": "that don't really fit anything at all um and we basically discard those if your behavior if the behavior of your app",
    "start": "1862639",
    "end": "1868639"
  },
  {
    "text": "isn't predictable then you can't really have any expectation of it is our thinking and so we kind of you know we",
    "start": "1868639",
    "end": "1876440"
  },
  {
    "text": "just ignore it because it's unpredictable you can't know if it's behaving well so we can't know if it's",
    "start": "1876440",
    "end": "1882159"
  },
  {
    "text": "behaving well either so you compute the baselines you do the trans information to log normal",
    "start": "1882159",
    "end": "1888720"
  },
  {
    "text": "you take the parameters the mean and the standard deviation you put that with a cohort identifier into the database",
    "start": "1888720",
    "end": "1894960"
  },
  {
    "text": "that's your baselines and then in as as events come",
    "start": "1894960",
    "end": "1900279"
  },
  {
    "text": "in you've got current service data and for each event that comes in you basically compare it to uh the metric",
    "start": "1900279",
    "end": "1907600"
  },
  {
    "text": "that you've got and you compute the The Zed score so what's the Zed score the",
    "start": "1907600",
    "end": "1912679"
  },
  {
    "text": "Zed score is basically how many standard deviations away from the mean is the",
    "start": "1912679",
    "end": "1917960"
  },
  {
    "text": "latency for that request that's a z score so a z score of one is one",
    "start": "1917960",
    "end": "1923880"
  },
  {
    "text": "standard deviation away from the mean a z score of two is two standard deviations away from the",
    "start": "1923880",
    "end": "1929480"
  },
  {
    "text": "mean and then you can combine those Z scores into buckets and the buckets um",
    "start": "1929480",
    "end": "1935279"
  },
  {
    "text": "are a collection of events over time and you compute the proportion of those",
    "start": "1935279",
    "end": "1940960"
  },
  {
    "text": "events that are over some threshold which for the purposes of this we choose",
    "start": "1940960",
    "end": "1946880"
  },
  {
    "text": "two Sigma as the threshold so if the Z score is above two that's a bad event if",
    "start": "1946880",
    "end": "1952480"
  },
  {
    "text": "the Z score is below two that's a good event and a jcore is basically the proportion of events in your bucket",
    "start": "1952480",
    "end": "1959760"
  },
  {
    "text": "that's bad so a jcore of 0.1 10% that means 10% of your events are bad which",
    "start": "1959760",
    "end": "1966519"
  },
  {
    "text": "means they're above your threshold that you've chosen for bad versus good and the cool thing about this is by",
    "start": "1966519",
    "end": "1975480"
  },
  {
    "text": "transforming those lat into Z scores we now have a signal that's combinable",
    "start": "1975480",
    "end": "1983080"
  },
  {
    "text": "because we can combine Zed scores across projects we can combine Z scores across cells we can aggregate them across cells",
    "start": "1983080",
    "end": "1989600"
  },
  {
    "text": "and regions we've got something which is telling us what proportion of our",
    "start": "1989600",
    "end": "1994799"
  },
  {
    "text": "requests are bad versus good that's completely combinable so we're no longer having to worry about setting absolute",
    "start": "1994799",
    "end": "2001000"
  },
  {
    "text": "latency thresholds instead we can set Z score thresholds and and have an idea of what's good and bad that's combinable",
    "start": "2001000",
    "end": "2007440"
  },
  {
    "text": "across across projects across cells across",
    "start": "2007440",
    "end": "2012200"
  },
  {
    "start": "2012000",
    "end": "2090000"
  },
  {
    "text": "regions so just to recap the aggregating z z scores across",
    "start": "2018600",
    "end": "2024919"
  },
  {
    "text": "workloads we know the fraction of those workloads with Z scores that are above two in Windows based on times we use 15",
    "start": "2024919",
    "end": "2031960"
  },
  {
    "text": "minute buckets um we use Project based buckets at 15 minutes as our basic um",
    "start": "2031960",
    "end": "2037720"
  },
  {
    "text": "unit and then we can combine those we expect statistically about two",
    "start": "2037720",
    "end": "2043639"
  },
  {
    "text": "to 5% of events will be outliers based on just the statistics of a normal",
    "start": "2043639",
    "end": "2050200"
  },
  {
    "text": "distribution if we see a jcore above 10% that's a sign that something is",
    "start": "2050200",
    "end": "2056280"
  },
  {
    "text": "bad so that's our kind of basic signal if we're looking at a cell and we see",
    "start": "2056280",
    "end": "2061440"
  },
  {
    "text": "that the the day score goes above 10% that's a sign that something's bad because the St statistics of the",
    "start": "2061440",
    "end": "2068040"
  },
  {
    "text": "requests coming in are diverging significantly from the statistics we expect based on our",
    "start": "2068040",
    "end": "2074280"
  },
  {
    "text": "baselines and the detection again like the SLO equivalent if you like is the",
    "start": "2074639",
    "end": "2079878"
  },
  {
    "text": "proportion of workflows that are exhibiting some kind of latency regression in terms of our graphs on our",
    "start": "2079879",
    "end": "2087320"
  },
  {
    "text": "on our monitoring dashboards uh this is the graph that we initially look at when we get an alert based on this particular",
    "start": "2087320",
    "end": "2093960"
  },
  {
    "start": "2090000",
    "end": "2245000"
  },
  {
    "text": "data product so what we're looking at here is is this thing here this is the",
    "start": "2093960",
    "end": "2099160"
  },
  {
    "text": "what what we do basically is we take that per project J score and then we",
    "start": "2099160",
    "end": "2105640"
  },
  {
    "text": "turn that into a distribution so we've got a distribution of project J scores",
    "start": "2105640",
    "end": "2111359"
  },
  {
    "text": "and then we look at the 50th percentile of that and see if the 50th percentile of that is",
    "start": "2111359",
    "end": "2117160"
  },
  {
    "text": "moving and so here what you can see is the 50th percentile project J score is moving above 5% that's a sign that",
    "start": "2117160",
    "end": "2125160"
  },
  {
    "text": "something is is quite bad um um the buckets the the duration of the buckets is important because a lot of our",
    "start": "2125160",
    "end": "2132640"
  },
  {
    "text": "projects are pretty low QPS so in a low QPS project in a 50-minute bucket you're going to get a",
    "start": "2132640",
    "end": "2138760"
  },
  {
    "text": "lot of projects that are going to give you zero or one and so that's why we do the Distribution on a per project basis uh",
    "start": "2138760",
    "end": "2146320"
  },
  {
    "text": "and then if in that distribution you see it go above five that's like a pretty clear signal that PE customers are",
    "start": "2146320",
    "end": "2153440"
  },
  {
    "text": "detecting pain and then we also have this C 70th percentile uh sorry this is",
    "start": "2153440",
    "end": "2159160"
  },
  {
    "text": "a 30th percentile line as well um that 30% of projects are experiencing J",
    "start": "2159160",
    "end": "2164480"
  },
  {
    "text": "scores of at least 30 so there's a smaller group of projects that are experiencing this really high latency",
    "start": "2164480",
    "end": "2170000"
  },
  {
    "text": "regression so that's a a clear kind of confirmation that we've got a real",
    "start": "2170000",
    "end": "2175960"
  },
  {
    "text": "problem um and like like the reason I like giving these presentations is because I like to actually snapshot",
    "start": "2175960",
    "end": "2181440"
  },
  {
    "text": "graphs from our monitoring and put them on slides um so this is super fun for me I hope it's fun for you too",
    "start": "2181440",
    "end": "2187240"
  },
  {
    "text": "um the next thing we want to do when we know there's a problem is work out how many projects are being impacted what's the severity of this thing should I be",
    "start": "2187240",
    "end": "2194200"
  },
  {
    "text": "declaring an incident how severe is that incident um and that's going to",
    "start": "2194200",
    "end": "2199400"
  },
  {
    "text": "determine what actions I take in response to that you know sometimes if we um we can just add capacity in fact",
    "start": "2199400",
    "end": "2205960"
  },
  {
    "text": "we have systems that automatically add capacity that's what we prefer to do um we really very rarely will like cap",
    "start": "2205960",
    "end": "2213359"
  },
  {
    "text": "projects because you know we like money um and our whole business proposition is",
    "start": "2213359",
    "end": "2218480"
  },
  {
    "text": "serving customer requests so capping projects is really bad we we very rarely want to do that unless we find it's an",
    "start": "2218480",
    "end": "2224319"
  },
  {
    "text": "abusive workload we want to add capacity wherever possible our systems will do that automatically um but sometimes we",
    "start": "2224319",
    "end": "2230680"
  },
  {
    "text": "can't do that because there's no capacity left in particular cell or some particular cells Behaving Badly we need to drain the cell so that we can keep",
    "start": "2230680",
    "end": "2237800"
  },
  {
    "text": "the rest of the workloads running so the severity is very important for us to be able to work out what the appropriate",
    "start": "2237800",
    "end": "2243400"
  },
  {
    "text": "action is to take and so impact analysis is the next thing that you care about as a non caller we got a problem what's the",
    "start": "2243400",
    "end": "2249960"
  },
  {
    "start": "2245000",
    "end": "2316000"
  },
  {
    "text": "impact of that problem and so here what we can look at is there's this kind of noise floor that you can see of projects",
    "start": "2249960",
    "end": "2256359"
  },
  {
    "text": "um so this is the number of projects on the y- AIS if I hadn't had to blur that out for you um and then this is time and",
    "start": "2256359",
    "end": "2262800"
  },
  {
    "text": "you can see there's kind of a noise floor of projects and this is basically because like we're fitting a curve so",
    "start": "2262800",
    "end": "2268920"
  },
  {
    "text": "the curve that we fit is an approximation it doesn't actually match the the exact event distribution and we",
    "start": "2268920",
    "end": "2275400"
  },
  {
    "text": "discard work CLS as I say that are not predictable but it's still never going to be a perfect match with the distribution and that's what you're",
    "start": "2275400",
    "end": "2281640"
  },
  {
    "text": "seeing here and we have actually just recently developed a technique that helps us uh kind of get rid of that noise floor but it's actually pretty",
    "start": "2281640",
    "end": "2287599"
  },
  {
    "text": "complex in practice and I don't have time to talk about it now anyway but it doesn't kind of matter really because",
    "start": "2287599",
    "end": "2292680"
  },
  {
    "text": "what you can look at is the Delta between the noise floor and what you see is the peak and that's the number of projects impact it so that's the next",
    "start": "2292680",
    "end": "2299119"
  },
  {
    "text": "graph we come and look at how many projects are being impacted then we work out the severity",
    "start": "2299119",
    "end": "2304240"
  },
  {
    "text": "of the event so this point I just need to i' like to go through a few FAQs this",
    "start": "2304240",
    "end": "2309480"
  },
  {
    "text": "isn't the end of the presentation this is just like I know you're thinking some things I want to get ahead of that um",
    "start": "2309480",
    "end": "2315640"
  },
  {
    "text": "firstly people ask you know do performance metrics actually follow normal distributions no they don't um",
    "start": "2315640",
    "end": "2321839"
  },
  {
    "start": "2316000",
    "end": "2445000"
  },
  {
    "text": "what we found with normal distributions is we' got about 45% coverage um using normal distributions when we move to log",
    "start": "2321839",
    "end": "2328480"
  },
  {
    "text": "normal distributions it goes up to about 60% and then with the Box Cox transformation you can get up to about",
    "start": "2328480",
    "end": "2333839"
  },
  {
    "text": "70% of coverage and you know people worry about that from the point of for",
    "start": "2333839",
    "end": "2339200"
  },
  {
    "text": "the problem we're trying to solve which is do we have a latency regression on the platform that is plenty you can do",
    "start": "2339200",
    "end": "2344760"
  },
  {
    "text": "that with like 10 15% coverage for that particular problem if you wanted to give stuff to customers then you might want",
    "start": "2344760",
    "end": "2351319"
  },
  {
    "text": "higher coverage and that's great but for our purposes 60% coverage is is more than enough and even with um that lower",
    "start": "2351319",
    "end": "2358480"
  },
  {
    "text": "normal base distribution of 45% coverage that was totally fine so no they don't",
    "start": "2358480",
    "end": "2363599"
  },
  {
    "text": "but as long as enough of them do you're fine secondly how do you know if the",
    "start": "2363599",
    "end": "2370119"
  },
  {
    "text": "approximations hold well I'll come to that in a minute basically we we we back test it um uh and we validate it against",
    "start": "2370119",
    "end": "2377280"
  },
  {
    "text": "the distributions how do you Define cohorts that varies so for example this technique was pioneered with big query",
    "start": "2377280",
    "end": "2384160"
  },
  {
    "text": "big query is a service where you send SQL and you get back result sets and you would think how would you even Define",
    "start": "2384160",
    "end": "2389920"
  },
  {
    "text": "cohorts and so that's kind of an interesting problem but they actually basically use combinations of features on the platform to Define goorts and",
    "start": "2389920",
    "end": "2396440"
  },
  {
    "text": "were able to actually get this to work really well and that's where it was pioneered before it was um used uh on",
    "start": "2396440",
    "end": "2402319"
  },
  {
    "text": "the serverless platform so it varies according to application I think this technique is very widely applicable to",
    "start": "2402319",
    "end": "2408160"
  },
  {
    "text": "all kinds of domains so we're using it in serverless but anytime you've got uh workloads where you can model them",
    "start": "2408160",
    "end": "2414640"
  },
  {
    "text": "statistically and then aggregate to detect regressions you're going to be able to apply this technique so it's",
    "start": "2414640",
    "end": "2420079"
  },
  {
    "text": "very widely applicable but how you Define cohorts is going to be very domain",
    "start": "2420079",
    "end": "2425359"
  },
  {
    "text": "dependent how do you deal with Singleton or infrequent workloads we discard them",
    "start": "2425359",
    "end": "2430400"
  },
  {
    "text": "if your workload is getting less than 20 QPS in a month we ignore",
    "start": "2430400",
    "end": "2435720"
  },
  {
    "text": "it and then finally the question that I care most about that sounds great jez",
    "start": "2435720",
    "end": "2441119"
  },
  {
    "text": "it's a lot of stats words does it really work um so we went and back tested it and this is always the coolest thing",
    "start": "2441119",
    "end": "2447319"
  },
  {
    "start": "2445000",
    "end": "2527000"
  },
  {
    "text": "when you write like some enormous amount of SQL and then get a bunch of stuff out and then you put you put a graph up and",
    "start": "2447319",
    "end": "2452920"
  },
  {
    "text": "then you look at another graph you got and you're like wow that's totally the same thing amazing it works um so we",
    "start": "2452920",
    "end": "2458680"
  },
  {
    "text": "basically got a list of all the incidents from the last few months and we took the graphs that we had from them for things like request delivery latency",
    "start": "2458680",
    "end": "2465160"
  },
  {
    "text": "and then we lined it up against the stuff we produced in the Prototype using the SQL um and it it totally works and",
    "start": "2465160",
    "end": "2470560"
  },
  {
    "text": "there was times when we detected things using this technique and they weren't there on these graphs and we went and looked into it and we found there was",
    "start": "2470560",
    "end": "2476680"
  },
  {
    "text": "actually something going on and that actually as we kind of expected the graphs we had were kind of the the top",
    "start": "2476680",
    "end": "2484119"
  },
  {
    "text": "of the iceberg above the ocean and they was this big part of the iceberg below the ocean of things that were happening",
    "start": "2484119",
    "end": "2489760"
  },
  {
    "text": "that we didn't know about because we didn't have a way to detect these latency regressions from a customer",
    "start": "2489760",
    "end": "2494960"
  },
  {
    "text": "perspective so bad news things are worse than we thought good news we actually know when it's happening now that's",
    "start": "2494960",
    "end": "2500280"
  },
  {
    "text": "really great right um yeah it's like saying we're not going",
    "start": "2500280",
    "end": "2505800"
  },
  {
    "text": "to test for covid because uh you know we don't want to know if it's actually happening Well turns out that's not a",
    "start": "2505800",
    "end": "2511880"
  },
  {
    "text": "good approach for public health um and it's also not a good approach to detecting regressions on your platform",
    "start": "2511880",
    "end": "2518160"
  },
  {
    "text": "um so we got data um it finds problems we knew we had it also finds problems we didn't know we had so that's",
    "start": "2518160",
    "end": "2526680"
  },
  {
    "text": "great there are limitations to this um firstly you need stats words like if",
    "start": "2526839",
    "end": "2532880"
  },
  {
    "start": "2527000",
    "end": "2644000"
  },
  {
    "text": "you've been paged and it's 6:00 in the morning in the UK which is when the shift starts you know and you can't",
    "start": "2532880",
    "end": "2538960"
  },
  {
    "text": "remember what a jcore is but you've got being paged like five times you know that's not great in terms of incident",
    "start": "2538960",
    "end": "2544760"
  },
  {
    "text": "response so that is a dis Advantage like I still have to do that I'm like oh what does this graph actually mean uh oh it's",
    "start": "2544760",
    "end": "2551520"
  },
  {
    "text": "a j score and it's the 50% tile okay that's bad right so there's that kind of mental thing that you got to overcome um",
    "start": "2551520",
    "end": "2559400"
  },
  {
    "text": "when you're trying to interpret the graphs and so a lot of that is training and just kind of getting used to it but",
    "start": "2559400",
    "end": "2566160"
  },
  {
    "text": "you have to invest in that to make sure it works because you know as an operator you've already got so much information",
    "start": "2566160",
    "end": "2571480"
  },
  {
    "text": "in your head you're oh great a completely new set of terms and graphs that I've got to learn when I get paged",
    "start": "2571480",
    "end": "2577599"
  },
  {
    "text": "that's never popular um so that's something you got to be aware of um the",
    "start": "2577599",
    "end": "2583119"
  },
  {
    "text": "co the cohort coverage um 40 sorry excuse me 40% to 60% that's totally fine",
    "start": "2583119",
    "end": "2589680"
  },
  {
    "text": "not 100% doesn't matter in this application and then a feature not a bug",
    "start": "2589680",
    "end": "2595000"
  },
  {
    "text": "but this is symptom based it's telling you customers are experiencing a problem",
    "start": "2595000",
    "end": "2600160"
  },
  {
    "text": "doesn't tell you why you then have to go and start looking at all the other graphs and start evaluating hypotheses",
    "start": "2600160",
    "end": "2606559"
  },
  {
    "text": "one by one is it this let's look at the graphs no is it this let's look at the graphs no and you know typically you'll",
    "start": "2606559",
    "end": "2612800"
  },
  {
    "text": "have a set of things that you know you got to evaluate and it's always the same things is it dependencies is it this",
    "start": "2612800",
    "end": "2618240"
  },
  {
    "text": "thing uh you know is there a change is there a new binary release is there a new configuration change so those are",
    "start": "2618240",
    "end": "2623880"
  },
  {
    "text": "the your first set of things and and and you can typically find out within a few minutes if that's the case because you",
    "start": "2623880",
    "end": "2629400"
  },
  {
    "text": "know where all those graphs are and if it's not any of those things you know you're in for a long day um but you know",
    "start": "2629400",
    "end": "2635319"
  },
  {
    "text": "we're building tooling as well to look at correlations um I Got 5 minutes I think right um so it's a feature but",
    "start": "2635319",
    "end": "2643559"
  },
  {
    "text": "it's going to ca you problems so just briefly I'm going to look at a couple of other applications um what the big query",
    "start": "2643559",
    "end": "2650520"
  },
  {
    "start": "2644000",
    "end": "2691000"
  },
  {
    "text": "team have done which is cool is break up those phases and independently model each of them so for example if you get a",
    "start": "2650520",
    "end": "2656000"
  },
  {
    "text": "regression they can see very easily oh it's IO time that's dominating this this must be an IO problem so being able to",
    "start": "2656000",
    "end": "2662319"
  },
  {
    "text": "break down the phases and model those independently is a the next step on this journey if you like uh you can also actually build uh",
    "start": "2662319",
    "end": "2670359"
  },
  {
    "text": "do ab tests using cohorts so um one team used this to model the behavior of",
    "start": "2670359",
    "end": "2675960"
  },
  {
    "text": "workloads on different CPUs and see how different workloads behave on different CPUs which is kind of interesting as",
    "start": "2675960",
    "end": "2681640"
  },
  {
    "text": "well so my point is there's tons of applications of this this is just the beginning um but anytime where you've",
    "start": "2681640",
    "end": "2687040"
  },
  {
    "text": "got a problem similar to this uh it's a great go-to uh that's it oh yeah sorry",
    "start": "2687040",
    "end": "2692640"
  },
  {
    "start": "2691000",
    "end": "2807000"
  },
  {
    "text": "just some key things um we have a way to reliably detect and measure me the impact of platform regressions that's",
    "start": "2692640",
    "end": "2698200"
  },
  {
    "text": "been transformational for us we can now predict customer tickets coming in like that's always what you want you don't",
    "start": "2698200",
    "end": "2704400"
  },
  {
    "text": "want to find out that you have problems because your customers are opening tickets you want to find out you have problems because you know you've got",
    "start": "2704400",
    "end": "2710359"
  },
  {
    "text": "problems so when customer tickets come in you can say oh yeah we know that's happening this is what we're doing customers want to find out by looking at",
    "start": "2710359",
    "end": "2716920"
  },
  {
    "text": "your dashboard that something's wrong not have to raise tickets um reliability fundamentally is a shared",
    "start": "2716920",
    "end": "2723440"
  },
  {
    "text": "property and so being able to reconstruct End to End customer behavior is really important we have a way of",
    "start": "2723440",
    "end": "2728680"
  },
  {
    "text": "making those metrics combinable so that we can analyze at the project level at the cell level at the region level um",
    "start": "2728680",
    "end": "2734160"
  },
  {
    "text": "what customers care about is not the actual Behavior but is that behavior changing which is what this technique models um distributed systems one of the",
    "start": "2734160",
    "end": "2742400"
  },
  {
    "text": "characteristics of them is produce they produce decorrelation where there's not decorrelation that's a problem and we",
    "start": "2742400",
    "end": "2749760"
  },
  {
    "text": "can measure that which is a great way of finding out if you've got something going wrong uh and we can use that",
    "start": "2749760",
    "end": "2755000"
  },
  {
    "text": "correlation to identify if y approximate causes when we get this signal in so this method incorporates user intent we",
    "start": "2755000",
    "end": "2763359"
  },
  {
    "text": "can produce data products that we can compare over time and combine and then we can use these to actually find out",
    "start": "2763359",
    "end": "2769359"
  },
  {
    "text": "when our systems are behaving badly work out the duration and severity and impact of those things which is really useful",
    "start": "2769359",
    "end": "2774680"
  },
  {
    "text": "when you're doing post-mortems or critical when you're doing postmortem uh we can we can compare Behavior over time",
    "start": "2774680",
    "end": "2781319"
  },
  {
    "text": "and chop it up over different dimensions if we need to do that uh and actually directly measure decorrelation across",
    "start": "2781319",
    "end": "2787680"
  },
  {
    "text": "different parts of our systems and we have insights now that are not based on like randomly chosen thresholds but",
    "start": "2787680",
    "end": "2792960"
  },
  {
    "text": "based on actual principle principled analysis of the behavior of the platform",
    "start": "2792960",
    "end": "2798599"
  },
  {
    "text": "um we've found invariants we can track them over time uh and we can have these building blocks that we can reprocess in",
    "start": "2798599",
    "end": "2804119"
  },
  {
    "text": "many different ways um I work at Google we have books they're free go check them",
    "start": "2804119",
    "end": "2811240"
  },
  {
    "start": "2807000",
    "end": "2820000"
  },
  {
    "text": "out we're hiring thanks very much for your time",
    "start": "2811240",
    "end": "2817800"
  }
]
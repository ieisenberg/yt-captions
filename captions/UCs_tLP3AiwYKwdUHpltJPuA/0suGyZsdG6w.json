[
  {
    "start": "0",
    "end": "52000"
  },
  {
    "text": "[Music]",
    "start": "5870",
    "end": "10049"
  },
  {
    "text": "so I'm I'm Andy Bennett I'm the I'm the CTO at a company called skipjack and we're a we're a fairly fairly newly",
    "start": "13440",
    "end": "20080"
  },
  {
    "text": "funded company um last year and we're looking to use machine learning guided",
    "start": "20080",
    "end": "25560"
  },
  {
    "text": "techniques in order to um work out how to deploy existing workloads into into",
    "start": "25560",
    "end": "31960"
  },
  {
    "text": "cloud services so I'm going to tell you um what what what what it is we're doing",
    "start": "31960",
    "end": "37200"
  },
  {
    "text": "and and how we how we're doing that and kind of some of the learnings that we that we've come across while we've been doing that um I'm going to it's going to",
    "start": "37200",
    "end": "44719"
  },
  {
    "text": "be quite a technical talk hopefully um you won't feel like I've I've pitched you at all and that's not the intention",
    "start": "44719",
    "end": "50600"
  },
  {
    "text": "um so um the underlying problem that that we're solving is that it turns out",
    "start": "50600",
    "end": "55840"
  },
  {
    "start": "52000",
    "end": "165000"
  },
  {
    "text": "that big big Enterprises have or even even much smaller companies days have a lot of apps they",
    "start": "55840",
    "end": "62440"
  },
  {
    "text": "um they they write an app for something that and then it it never goes away so",
    "start": "62440",
    "end": "69799"
  },
  {
    "text": "um people tend to even even the the devops movement is is making a lot of",
    "start": "69799",
    "end": "75600"
  },
  {
    "text": "traction and still there's kind of this attitude where the developers will",
    "start": "75600",
    "end": "81680"
  },
  {
    "text": "build an app and then they'll throw it over the wall to operations and then it'll stay in operations for a very long",
    "start": "81680",
    "end": "87360"
  },
  {
    "text": "time the um often the workload will change over time",
    "start": "87360",
    "end": "94040"
  },
  {
    "text": "and Ops basically end up with a lot of poorly understood apps or apps that they don't understand very well and apps that",
    "start": "94040",
    "end": "100119"
  },
  {
    "text": "are kind of doing things that they didn't weren't intended to do when they when they were first delivered and",
    "start": "100119",
    "end": "106159"
  },
  {
    "text": "despite all of this they need to have kind of flexibility to deploy this app in the right environment and um they've",
    "start": "106159",
    "end": "112960"
  },
  {
    "text": "still got to be effective in in their work even if they even if they haven't got the developers on hand who built the app and who understand the app so um you",
    "start": "112960",
    "end": "121079"
  },
  {
    "text": "know they need this flexibility to control the spending like the cost of cost of running the infrastructure and",
    "start": "121079",
    "end": "127280"
  },
  {
    "text": "um the vast majority of the stuff they're looking after is is Legacy apps um so um apps tend to appear and then",
    "start": "127280",
    "end": "136160"
  },
  {
    "text": "they disappear at a slower rate than the new apps are appearing so it turns out that any one point in time whatever technology you're using the vast",
    "start": "136160",
    "end": "142280"
  },
  {
    "text": "majority of what you have is it's older stuff and Legacy stuff that you have to keep running for some reason",
    "start": "142280",
    "end": "148239"
  },
  {
    "text": "so they have to as I said they have to um still be effective in their work and it turns out",
    "start": "148239",
    "end": "154080"
  },
  {
    "text": "that the best way to do this is to over provision over provisioning is the norm it cost a little bit more money but it allows them to um it allows them to get",
    "start": "154080",
    "end": "162040"
  },
  {
    "text": "it done quickly and move on to the next thing so Ops Ops departments in general they they kind of want to be agile so",
    "start": "162040",
    "end": "169200"
  },
  {
    "start": "165000",
    "end": "214000"
  },
  {
    "text": "two of the things that we we're trying to help them be is more agile and more lean um I'm not really going to cover any rugged stuff this afternoon but",
    "start": "169200",
    "end": "175959"
  },
  {
    "text": "they're um they're interested in being agile and what they want to do is get their apps that they've been sent into",
    "start": "175959",
    "end": "181200"
  },
  {
    "text": "production quickly without manually tuning them without a lot of manual work and automating as much as possible and",
    "start": "181200",
    "end": "188000"
  },
  {
    "text": "the other thing that Ops want to be is that they want to be lean so they in general Ops departments are still",
    "start": "188000",
    "end": "193640"
  },
  {
    "text": "considered as a cost center in the business and um they're kind of a necessary part of the business but they",
    "start": "193640",
    "end": "200400"
  },
  {
    "text": "don't they're not often contributing to the core the core product of the business and the core business value",
    "start": "200400",
    "end": "205959"
  },
  {
    "text": "that the the company's product is offering so so they want to reduce their cost and and keep their cost down as",
    "start": "205959",
    "end": "211200"
  },
  {
    "text": "much as possible um so we've been we've been trying to apply some machine learning in this in this area and our",
    "start": "211200",
    "end": "218480"
  },
  {
    "start": "214000",
    "end": "248000"
  },
  {
    "text": "customers tend to have lots of java workloads in the jvm a few a few net workloads in the common language runtime",
    "start": "218480",
    "end": "225480"
  },
  {
    "text": "they're deploying on Windows and Linux and they've got a wide variety of app servers and and containers and servlets",
    "start": "225480",
    "end": "231519"
  },
  {
    "text": "and this kind of thing that they that they're using um so I'm going to talk um",
    "start": "231519",
    "end": "236720"
  },
  {
    "text": "I'm I'm going to illustrate what we're doing with the example of of a small microservice that that you might deploy in Amazon ec2 for",
    "start": "236720",
    "end": "244120"
  },
  {
    "text": "example and um what what we'll do is we we'll take your microservice and we will",
    "start": "244120",
    "end": "251120"
  },
  {
    "text": "um we will send a a test workload to it and characterize it for performance and",
    "start": "251120",
    "end": "256519"
  },
  {
    "text": "then we will work out how much it costs to run on different size um Cloud",
    "start": "256519",
    "end": "262520"
  },
  {
    "text": "instances so here's a is the kind of output that we might produce and each one of these bar graphs is is one um one",
    "start": "262520",
    "end": "269800"
  },
  {
    "text": "type of instance type maybe an Amazon ec2 um like a T2 small or M3 large or a",
    "start": "269800",
    "end": "277199"
  },
  {
    "text": "aure um A1 basic or maybe even a private cloud in in Venter or something and the",
    "start": "277199",
    "end": "284280"
  },
  {
    "text": "the darker bars are the um uh what we benchmarked your app at on that instance",
    "start": "284280",
    "end": "289639"
  },
  {
    "text": "with your with your test load at at the at the Baseline as you as you provided it and then the the blue bars on top of",
    "start": "289639",
    "end": "295960"
  },
  {
    "text": "that are the extra performance that we managed to get out of your app after we tuned it with um with with our with our",
    "start": "295960",
    "end": "302600"
  },
  {
    "text": "software so what we do is we're choosing um we're doing a blackbox optimization so we don't know much about your source",
    "start": "302600",
    "end": "308360"
  },
  {
    "text": "code or your workload we don't know um we don't change anything inside your your app but we what we're trying to do",
    "start": "308360",
    "end": "313400"
  },
  {
    "text": "is offer tuning settings to for example the jvm or the OS or or the platform in",
    "start": "313400",
    "end": "318720"
  },
  {
    "text": "some way and so we vary these in in different ways based on the feedback from the test and we also vary them",
    "start": "318720",
    "end": "324759"
  },
  {
    "text": "based on what we know about different type how different types of app respond to different amounts of resources in different areas so the um the blue bar",
    "start": "324759",
    "end": "334319"
  },
  {
    "text": "is is what happens when we apply the best settings that we found on that particular instance type and so you can",
    "start": "334319",
    "end": "340960"
  },
  {
    "text": "see this this guy here this guy is a um is a T2 micro so T2 T2 medium running in",
    "start": "340960",
    "end": "346520"
  },
  {
    "text": "Amazon and you're getting approximately uh performance rating of 432 which is uh",
    "start": "346520",
    "end": "353319"
  },
  {
    "text": "is kind of an arbitrary measure relative to all all the others in that um in that test so there's no particular particular",
    "start": "353319",
    "end": "359759"
  },
  {
    "text": "units for that um but it's kind of transactions per second whatever your transaction happen to be and that costs",
    "start": "359759",
    "end": "366039"
  },
  {
    "text": "if you get a reserve instance pricing for Amazon one one of those instance will cost you about",
    "start": "366039",
    "end": "371680"
  },
  {
    "text": "$326 a year to run uh check the price this afternoon so that that's their current price and it's approximately",
    "start": "371680",
    "end": "378120"
  },
  {
    "text": "this after optimization it's approximately the same height as this bar which is actually an awsm 3 medium",
    "start": "378120",
    "end": "383639"
  },
  {
    "text": "which cost um cost about 25% more to run",
    "start": "383639",
    "end": "389039"
  },
  {
    "text": "and you only get a 15% uplift in actual performance so depending on where your",
    "start": "389039",
    "end": "394120"
  },
  {
    "text": "performance Target actually is you might be able to move that workload from an M3 medium into a T2 medium and still um",
    "start": "394120",
    "end": "400520"
  },
  {
    "text": "meet all your slas and and requirements and if you can do that without really any outlay of effort on the part of the",
    "start": "400520",
    "end": "406560"
  },
  {
    "text": "Ops Team then then then you've got a win um the idea with a microservice is that",
    "start": "406560",
    "end": "411680"
  },
  {
    "text": "you can deploy lots of these so you can reap that that 25% saving across all of",
    "start": "411680",
    "end": "416800"
  },
  {
    "text": "the um all of the deployments of that particular microservice in in the cloud",
    "start": "416800",
    "end": "423280"
  },
  {
    "text": "um so how how what we do is we we do these tests for all the different types",
    "start": "423280",
    "end": "428479"
  },
  {
    "text": "of instance and in order to get a Optimal Performance Reading for each one of these gra um bar charts we're going",
    "start": "428479",
    "end": "435919"
  },
  {
    "text": "to do a a series of um a series of different tests under different conditions on that particular instance",
    "start": "435919",
    "end": "441919"
  },
  {
    "text": "and so this is what a a search for um one of those bars looks like each one of",
    "start": "441919",
    "end": "448000"
  },
  {
    "text": "these red lines is a test that's currently running and um it's going to",
    "start": "448000",
    "end": "454360"
  },
  {
    "text": "have a performance metric depending on how high the bar is and we're going to be varying things like maybe the garbage",
    "start": "454360",
    "end": "459680"
  },
  {
    "text": "collector um settings or or maybe um maybe the way the TCP stack is configured in the kernel or something",
    "start": "459680",
    "end": "465560"
  },
  {
    "text": "like this um so we we we deploy the test we do all the all the settings and then",
    "start": "465560",
    "end": "471319"
  },
  {
    "text": "we take the best run with the best settings as the it's the best optimal configuration for that particular",
    "start": "471319",
    "end": "477680"
  },
  {
    "text": "platform um now it turns out that it's really",
    "start": "477960",
    "end": "483520"
  },
  {
    "start": "479000",
    "end": "590000"
  },
  {
    "text": "difficult to do this this um automatically I've had a lot of conversations with a lot of customers",
    "start": "483520",
    "end": "488560"
  },
  {
    "text": "and they're pretty excited about this when you go and talk to a developer about this they get less excited um",
    "start": "488560",
    "end": "495680"
  },
  {
    "text": "they they will tell you that well you know I I design my algorithm and I know exactly how much memory it uses so I",
    "start": "495680",
    "end": "501479"
  },
  {
    "text": "know how to choose the Heap sizes in the jvm and and I know the access pattern and like and so I understand how it",
    "start": "501479",
    "end": "507240"
  },
  {
    "text": "interacts with the garbage collector and they they believe that they have a really good understanding of of their workload and I think it's Pro probably",
    "start": "507240",
    "end": "513560"
  },
  {
    "text": "true in the case where they they designed their workload and send it to Ops what tends to happen after the after",
    "start": "513560",
    "end": "519680"
  },
  {
    "text": "the workload goes into production is that the workload changes over time maybe it grows over time maybe the the",
    "start": "519680",
    "end": "526320"
  },
  {
    "text": "visitors are doing slightly different things with it over time and so as the as the lifetime of the app continues the",
    "start": "526320",
    "end": "532720"
  },
  {
    "text": "the way it was used when it was first deployed and the and the amount of resources when it's first deployed is actually quite a lot different from what",
    "start": "532720",
    "end": "538320"
  },
  {
    "text": "it can end up using over time and it turns out that actually um even if they",
    "start": "538320",
    "end": "544200"
  },
  {
    "text": "have quite good feel for the parameter bait is actually massive um we we this is just an example we can",
    "start": "544200",
    "end": "552519"
  },
  {
    "text": "um we can tune most of the jvm parameters there's about 18 or 20 of them um maybe like Tomcat or web spere",
    "start": "552519",
    "end": "560279"
  },
  {
    "text": "or something has a handful of parameters that you're going to trans um that you're going to tune as well maybe your",
    "start": "560279",
    "end": "565760"
  },
  {
    "text": "underlying operating system has like TCP Q sizes and and swap space and different CPU and IO schedulers that you can that",
    "start": "565760",
    "end": "572480"
  },
  {
    "text": "you can try out as well and it turns out if you work out how many different configuration permutations there are",
    "start": "572480",
    "end": "578839"
  },
  {
    "text": "then there's um even with those there's there's just 28 different dimensions",
    "start": "578839",
    "end": "584360"
  },
  {
    "text": "there and there's there's a lot of a lot of scope for for exploring this space um",
    "start": "584360",
    "end": "590279"
  },
  {
    "start": "590000",
    "end": "624000"
  },
  {
    "text": "and even if um this is the example of the um characterizing the performance on",
    "start": "590279",
    "end": "596959"
  },
  {
    "text": "just one of the types of instance um Amazon for example here we're doing",
    "start": "596959",
    "end": "602640"
  },
  {
    "text": "about 100 tests and even that isn't going to possibly cover all or anywhere",
    "start": "602640",
    "end": "608440"
  },
  {
    "text": "near to that my marketing guide tells me we can we can explore a quintilian quintilian different possibilities and",
    "start": "608440",
    "end": "615120"
  },
  {
    "text": "so it's just not reasonable to to try them all out and it's not Fe it's it's not um cost effective in time or money",
    "start": "615120",
    "end": "621640"
  },
  {
    "text": "to do that to do that so how do we do that then so if I'm going to do an",
    "start": "621640",
    "end": "627600"
  },
  {
    "text": "example here with just a pair of PR parameters if you have um a parameter two parameters with two values each or",
    "start": "627600",
    "end": "634560"
  },
  {
    "text": "well you have you have two parameters with a range of values each and you want a sample just two different values of each of them and so that that involves",
    "start": "634560",
    "end": "641399"
  },
  {
    "text": "four tests and if you want to do two more test if you want to um sample two",
    "start": "641399",
    "end": "646959"
  },
  {
    "text": "more parameters for parameter two more values for parameter one you end up with four more tests that you have to do and",
    "start": "646959",
    "end": "652120"
  },
  {
    "text": "each each time you add a at a dimension you you're kind of having this explosion of of combinations and so um",
    "start": "652120",
    "end": "659680"
  },
  {
    "text": "there's there's two things we do one is we can kind of take quite a coarse um coar granularity over the entire search",
    "start": "659680",
    "end": "666160"
  },
  {
    "text": "space and another one is we can kind of limit that further by kind of cleverly choosing the intersection points between",
    "start": "666160",
    "end": "672720"
  },
  {
    "text": "the different dimensions so that we can um work out one dimension against",
    "start": "672720",
    "end": "678200"
  },
  {
    "text": "another as an independent variable and then work out the correlation between all of the different um parameters that",
    "start": "678200",
    "end": "683600"
  },
  {
    "text": "you can set so this is this here is what's called a a Latin hyper Cube and it's a little bit like the eight Queens",
    "start": "683600",
    "end": "690519"
  },
  {
    "start": "689000",
    "end": "731000"
  },
  {
    "text": "problem I don't know if anyone's familiar with the eight Queens problem but the idea is that on a on a chessboard you have to put you have",
    "start": "690519",
    "end": "697160"
  },
  {
    "text": "eight eight rows and eight columns and you have to place on there eight Queens such that none of them are attacking any",
    "start": "697160",
    "end": "702680"
  },
  {
    "text": "of the other ones and there's a there's a whole bunch of different solutions for this and um what it what it means is",
    "start": "702680",
    "end": "708880"
  },
  {
    "text": "basically you end up with at least one Queen in every row and every column so you get an an intersection between those two parameters at that point and that's",
    "start": "708880",
    "end": "716480"
  },
  {
    "text": "the um without any other training data that's the that's the bare minimum number of parameters that you can use in",
    "start": "716480",
    "end": "722519"
  },
  {
    "text": "order to kind of get a rough idea of the extent of the performance over that entire um entire",
    "start": "722519",
    "end": "729320"
  },
  {
    "text": "space um so we do a bunch of tests about we we",
    "start": "729320",
    "end": "736880"
  },
  {
    "start": "731000",
    "end": "783000"
  },
  {
    "text": "try and we try and limit it to 100 or or 200 per per instance type and we plot",
    "start": "736880",
    "end": "742079"
  },
  {
    "text": "them for performance so we work out what what what they um how well they did on",
    "start": "742079",
    "end": "747920"
  },
  {
    "text": "your on your on the customers metric of what they're trying to do with um with their workload and then we fit a um we",
    "start": "747920",
    "end": "755000"
  },
  {
    "text": "fit a curve to that to try and work out how it changes over over the area that",
    "start": "755000",
    "end": "760079"
  },
  {
    "text": "you can that you can perform the test Sim and um from that we can kind of predict other points and maybe run a",
    "start": "760079",
    "end": "766440"
  },
  {
    "text": "couple of other tests to kind of verify or falsify hypothesis we have about how the performance changes in certain areas",
    "start": "766440",
    "end": "772440"
  },
  {
    "text": "and um on top of that we then can apply some hill climbing algorithms to try and",
    "start": "772440",
    "end": "777639"
  },
  {
    "text": "maximize the performance that you you get for for that particular instance um but it turns out there's",
    "start": "777639",
    "end": "784680"
  },
  {
    "start": "783000",
    "end": "841000"
  },
  {
    "text": "there's no there's no Silver Bullet here the um the the Hope was that maybe you know",
    "start": "784680",
    "end": "790560"
  },
  {
    "text": "if you set the Heap size to maximum maybe everything will go faster always um and it turns out this isn't the case",
    "start": "790560",
    "end": "797120"
  },
  {
    "text": "we did some one of our one of our statistics guys did some regressions and we found that for most most workloads in",
    "start": "797120",
    "end": "804040"
  },
  {
    "text": "most situations you can come up with five or six parameters Each of which contribute a little bit though maybe 10",
    "start": "804040",
    "end": "810399"
  },
  {
    "text": "or 15% to the to the uplift that you can give on a particular um on a particular",
    "start": "810399",
    "end": "815560"
  },
  {
    "text": "workload and so the the bad news is",
    "start": "815560",
    "end": "820880"
  },
  {
    "text": "that it's not really possible to to do this manually it's something that you have to automate and the good news is",
    "start": "820880",
    "end": "828519"
  },
  {
    "text": "that you can um you can actually automate it so",
    "start": "828519",
    "end": "835079"
  },
  {
    "text": "um it also turns out that setting things to The Big Numbers doesn't always get you the best results like um there's",
    "start": "835079",
    "end": "842880"
  },
  {
    "start": "841000",
    "end": "1002000"
  },
  {
    "text": "there's a number of counterintuitive results which turn up I mean perhaps there perhaps they're kind of a bit more",
    "start": "842880",
    "end": "848160"
  },
  {
    "text": "obvious to people who have done a done a lot in this area but often you have to know quite a bit about the the app",
    "start": "848160",
    "end": "853680"
  },
  {
    "text": "specifically to work out the implications of certain um certain parameters so not um it's often the case",
    "start": "853680",
    "end": "861279"
  },
  {
    "text": "that if you increase the um number of threads available you'd",
    "start": "861279",
    "end": "866320"
  },
  {
    "text": "think that it would be able to do more stuff at once and it turns out that often if you if you decrease the number of threads under high load it brings in",
    "start": "866320",
    "end": "873480"
  },
  {
    "text": "the amount of time that it takes for each each resource and so the system ends up less busy and I can actually get more work done because it's doing it's",
    "start": "873480",
    "end": "880800"
  },
  {
    "text": "doing less concurrently so it's not sharing as much stuff and",
    "start": "880800",
    "end": "887240"
  },
  {
    "text": "um there's also quite a lot of easy wins to be had with with a lot of applications because most of them has never actually been optimized at all um",
    "start": "887519",
    "end": "895480"
  },
  {
    "text": "often they're they're written for de by by developer and then they they're deployed for a very specific use case and O over time it",
    "start": "895480",
    "end": "902880"
  },
  {
    "text": "grows into something else it becomes it becomes an important app in your business and people start making demands for it that that they never did before",
    "start": "902880",
    "end": "909560"
  },
  {
    "text": "so it becomes a it becomes used in a case where it's never that it's never been optimized for and so you can end up",
    "start": "909560",
    "end": "915519"
  },
  {
    "text": "with a lot lot of apps that you've never never optimized and so there's often quite a large gain you can make by by",
    "start": "915519",
    "end": "921040"
  },
  {
    "text": "doing anything at all let alone guaranteeing that you had the optimal result and it's also the case that um",
    "start": "921040",
    "end": "928160"
  },
  {
    "text": "that the that the um the scalability of an app is is limited and so there's a there's a",
    "start": "928160",
    "end": "935800"
  },
  {
    "text": "theoretical maximum that a particular app can scale up to on a on a on a machine and if you give it a bigger",
    "start": "935800",
    "end": "942199"
  },
  {
    "text": "machine than that then it won't get any faster because of inherent limits in in the architecture of the app and the way it was written",
    "start": "942199",
    "end": "948399"
  },
  {
    "text": "and there's often um there's often theories about where there is where this limit is but it's kind of often unknown",
    "start": "948399",
    "end": "954959"
  },
  {
    "text": "until you reach that limit and so if you if you're able to do some automated",
    "start": "954959",
    "end": "960680"
  },
  {
    "text": "testing you can discover where that limit is before you reach it and it helps you to do capacity planning and and and cost management and and",
    "start": "960680",
    "end": "967319"
  },
  {
    "text": "prioritize the right kind of development and um and and so you don't end up in a situation where where you're",
    "start": "967319",
    "end": "974240"
  },
  {
    "text": "firefighting so that's the kind of a quick overview of the of the machine learning side and how we how we apply it",
    "start": "976360",
    "end": "982120"
  },
  {
    "text": "and the kind of um benefits that we can get from doing it um obviously some of",
    "start": "982120",
    "end": "987319"
  },
  {
    "text": "you are sat there thinking well he's he's running like 200 tests that's that's that's not a small uh that's not",
    "start": "987319",
    "end": "994000"
  },
  {
    "text": "a small number to to run in a conventional way and and this is where we can really take advantage of some of the things that the the kind of the more",
    "start": "994000",
    "end": "1000279"
  },
  {
    "text": "cloudy offerings have to offer so kind of the um software defined infrastructure where you can spin up and",
    "start": "1000279",
    "end": "1006040"
  },
  {
    "start": "1002000",
    "end": "1248000"
  },
  {
    "text": "down Ser servers with with apis and this kind of thing um and I I'll also go into",
    "start": "1006040",
    "end": "1012360"
  },
  {
    "text": "a bit more detail about how we how we actually run the test itself so this is a graph of um",
    "start": "1012360",
    "end": "1019480"
  },
  {
    "text": "of one particular test the the um horizontal axis is is time we tests run",
    "start": "1019480",
    "end": "1025120"
  },
  {
    "text": "for just over an hour and and the vertical axis is the on the vertical axis on the left is the transactions per",
    "start": "1025120",
    "end": "1030400"
  },
  {
    "text": "second in performance and the vertical axis on the right is in bytes um so this this red curve is the",
    "start": "1030400",
    "end": "1037199"
  },
  {
    "text": "important one the red curve is the number of transactions per second that our app was doing or our microservice was doing at a particular point in time",
    "start": "1037199",
    "end": "1044480"
  },
  {
    "text": "and it's got It's got three main features one is the little ramp at the start and then we're on onto the plateau",
    "start": "1044480",
    "end": "1050440"
  },
  {
    "text": "and then the four main features then the ramp at the end and then it Go the decline at the end is the fourth feature",
    "start": "1050440",
    "end": "1056840"
  },
  {
    "text": "so this is a um this is this is a javer workload and what what happens at the start is that the",
    "start": "1056840",
    "end": "1064720"
  },
  {
    "text": "um the green line is the um load that we're presenting to it from the the um",
    "start": "1064720",
    "end": "1069880"
  },
  {
    "text": "from the thing that's generating the test load and the red thing is the um number of transactions per second the",
    "start": "1069880",
    "end": "1075640"
  },
  {
    "text": "application under under the test is doing and what you can see is that it takes some time to kind of warm up and",
    "start": "1075640",
    "end": "1081120"
  },
  {
    "text": "this is a a well-known characteristic of of um jit compiled workloads in that",
    "start": "1081120",
    "end": "1086600"
  },
  {
    "text": "what the Java compiler does is it it um as the as it works out what the hot",
    "start": "1086600",
    "end": "1092440"
  },
  {
    "text": "paths through the application are it it compiles them into native machine code for that particular platform and it it",
    "start": "1092440",
    "end": "1098320"
  },
  {
    "text": "makes them go faster and so this can really Um this can really hurt your um measure of performance if you measure it",
    "start": "1098320",
    "end": "1104400"
  },
  {
    "text": "at the wrong time because if if you just leave the load stable for a bit you you can find that your app suddenly gets",
    "start": "1104400",
    "end": "1109720"
  },
  {
    "text": "faster without having done anything so the the the jvm itself is quite good at good at self-tuning and this this blue",
    "start": "1109720",
    "end": "1116360"
  },
  {
    "text": "curve is showing you the size of the the size of the region that the jvm is storing the compiled code in and you can",
    "start": "1116360",
    "end": "1123400"
  },
  {
    "text": "see that when the region fills up it's about set to about 100 megabytes here um when it fills up the performance levels",
    "start": "1123400",
    "end": "1129799"
  },
  {
    "text": "out and and that is the um that's the optimal",
    "start": "1129799",
    "end": "1136080"
  },
  {
    "text": "um that that's the optimal um processing rate for that that",
    "start": "1136080",
    "end": "1142360"
  },
  {
    "text": "particular load that was given in green and so when we're sure that that phase is complete we can move on to the next",
    "start": "1142360",
    "end": "1148000"
  },
  {
    "text": "phase which is to gradually ramp the load up until we can find where the peak is so as I as I alluded to a little bit",
    "start": "1148000",
    "end": "1154039"
  },
  {
    "text": "earlier if you if you overload the system actually the the um the response will go down again because things end up",
    "start": "1154039",
    "end": "1160360"
  },
  {
    "text": "um stuck in cues and waiting for things and so the um the contention increases and then the",
    "start": "1160360",
    "end": "1166679"
  },
  {
    "text": "um the um the response of any the latency of any particular response goes down so as we increase the load we find",
    "start": "1166679",
    "end": "1173679"
  },
  {
    "text": "a we find a peak Point here which is which is the um",
    "start": "1173679",
    "end": "1180000"
  },
  {
    "text": "which is the optimal um point for this particular machine with those particular settings that's as fast as it goes and",
    "start": "1180000",
    "end": "1186559"
  },
  {
    "text": "if you continue to increase the load still it then it starts to tail off again and what you find is there's a bit of a there's a bit of a cliff there",
    "start": "1186559",
    "end": "1194159"
  },
  {
    "text": "um where basically is when you when you get to the machine to saturation point point it's it forms really poorly and",
    "start": "1194159",
    "end": "1200120"
  },
  {
    "text": "also it has quite a lot of Jitter you see when it was in the stable point before it was nice and flat and um got",
    "start": "1200120",
    "end": "1207320"
  },
  {
    "text": "um the the variance in the blobs was quite small that's quite a nice place for the machine to be running whereas if",
    "start": "1207320",
    "end": "1212880"
  },
  {
    "text": "you're running it up here then you're not really that sure what's going to be happening to your workload it could be some things could start to take a really",
    "start": "1212880",
    "end": "1218480"
  },
  {
    "text": "long time and what what you'll find is that these averages un plaing here but what you'll find is that probably if if",
    "start": "1218480",
    "end": "1225679"
  },
  {
    "text": "we um this because this is a normal mean average 50% of your your users are getting worse",
    "start": "1225679",
    "end": "1232600"
  },
  {
    "text": "um a worse worse experience than that so if you keep that variance nice and small",
    "start": "1232600",
    "end": "1237679"
  },
  {
    "text": "you can make better guarantees about the fact that you're delivering a good service to everyone so the idea is to",
    "start": "1237679",
    "end": "1243600"
  },
  {
    "text": "pick pick the optimal point and not not give too much load um this graph here goes into a bit",
    "start": "1243600",
    "end": "1251080"
  },
  {
    "start": "1248000",
    "end": "1370000"
  },
  {
    "text": "more detail about that the GRE the red again is the the performance the transactions per second that the that",
    "start": "1251080",
    "end": "1256520"
  },
  {
    "text": "the service is doing and and the green is the the latency um the average latency for that request so the the",
    "start": "1256520",
    "end": "1263120"
  },
  {
    "text": "length of time it takes for a particular request to happen so the the red is the",
    "start": "1263120",
    "end": "1269159"
  },
  {
    "text": "number of the number of requests that are finishing per second and the green is the number of the length of time the",
    "start": "1269159",
    "end": "1275360"
  },
  {
    "text": "average length of time that each request takes um so it assumes that there's more",
    "start": "1275360",
    "end": "1280480"
  },
  {
    "text": "than one in flight at a time so if you um take the point where you're getting",
    "start": "1280480",
    "end": "1286360"
  },
  {
    "text": "the most throughput you can find that the latest see is um not the smallest so",
    "start": "1286360",
    "end": "1292279"
  },
  {
    "text": "you can you can actually trade this off you can say actually I want to I want my service to be more Snappy for my um for",
    "start": "1292279",
    "end": "1298120"
  },
  {
    "text": "my user and so you can pick an arbitrary point that you that you want for your your service level agreement on the",
    "start": "1298120",
    "end": "1304120"
  },
  {
    "text": "latency curve and you can move the um you can move the bar back so that you",
    "start": "1304120",
    "end": "1309320"
  },
  {
    "text": "say the Optimal Performance is not just how much throughput I'm getting but it's it's a certain amount of throughput with",
    "start": "1309320",
    "end": "1315600"
  },
  {
    "text": "a guarantee that most of the request quests are completing in 50 milliseconds or something and so you can move it move",
    "start": "1315600",
    "end": "1322360"
  },
  {
    "text": "it back to there if you pick a point roughly there you can move the the line back to there and then your um your",
    "start": "1322360",
    "end": "1329039"
  },
  {
    "text": "maximum performance for that particular configuration becomes that and So you you're trading off a little bit of um",
    "start": "1329039",
    "end": "1335039"
  },
  {
    "text": "throughput for much better response time for each of those and kind of much better quality of service for each of those",
    "start": "1335039",
    "end": "1341520"
  },
  {
    "text": "users um any questions so far you've been very quiet am I going too fast or too slow okay so that's just the that's",
    "start": "1341520",
    "end": "1351360"
  },
  {
    "text": "kind of the life cycle of a single test what when when we actually doing a test you have to get a machine from somewhere",
    "start": "1351360",
    "end": "1357440"
  },
  {
    "text": "and it turns out that if you get one from for example Amazon you can you can buy an instance on demand and then they",
    "start": "1357440",
    "end": "1363120"
  },
  {
    "text": "will bill you at a 1 hour um they'll Bild you in 1 hour increments for that",
    "start": "1363120",
    "end": "1368159"
  },
  {
    "text": "so um you've got to spend some time starting your machine up and that cost you money and you've got to spend some",
    "start": "1368159",
    "end": "1373520"
  },
  {
    "start": "1370000",
    "end": "1480000"
  },
  {
    "text": "time installing the thing you want to test on there and then you need to actually do a test",
    "start": "1373520",
    "end": "1378960"
  },
  {
    "text": "and the rest of that time until the billing tick happens at the end of the hour is wasted so if you if you only spend 20 minutes doing the test you're",
    "start": "1378960",
    "end": "1385600"
  },
  {
    "text": "paying for 40 minutes that you didn't use if you spend 61 minutes doing a test you go into the next billing period and",
    "start": "1385600",
    "end": "1390919"
  },
  {
    "text": "you you waste 59 minutes um and there's there's there's various ways of of",
    "start": "1390919",
    "end": "1396720"
  },
  {
    "text": "solving this you can maybe you can reuse the machine for another test um because basically the green bits",
    "start": "1396720",
    "end": "1403720"
  },
  {
    "text": "the way you're doing the testing and that's that's the actual value for the application and all the rest of the time that that machine is doing things is is",
    "start": "1403720",
    "end": "1410120"
  },
  {
    "text": "just overhead and cost for for the testing and like I said we're doing",
    "start": "1410120",
    "end": "1415960"
  },
  {
    "text": "approximately 100 or 200 tests on a particular machine with different configurations at each time and you can",
    "start": "1415960",
    "end": "1423039"
  },
  {
    "text": "trade off the length of time it takes to do that entire search against the cost of that search because if you you can",
    "start": "1423039",
    "end": "1429559"
  },
  {
    "text": "you can spin up a 100 of those machines individually and you can do one test on each and you get your result in an hour",
    "start": "1429559",
    "end": "1435159"
  },
  {
    "text": "because that's approximately how long we test for and you waste 33 50% of your um",
    "start": "1435159",
    "end": "1441799"
  },
  {
    "text": "of your money on on Compu power that you never used or you can um you can",
    "start": "1441799",
    "end": "1446840"
  },
  {
    "text": "basically double the length of time it takes and and do two tests per machine one after the other and then you can you",
    "start": "1446840",
    "end": "1452960"
  },
  {
    "text": "wait two hours but it cost you about half as much I mean there's quite a lot of quantization here because the",
    "start": "1452960",
    "end": "1458679"
  },
  {
    "text": "billing period on Amazon is an hour you you it ends up being quite a cliff when you go over into the next hour you you",
    "start": "1458679",
    "end": "1465240"
  },
  {
    "text": "have this kind of big extra overhead on other Cloud such as um such as the Microsoft they have a much finer",
    "start": "1465240",
    "end": "1471520"
  },
  {
    "text": "granularity of billing so they charge you for the first hour and then after that they charge you only for the",
    "start": "1471520",
    "end": "1476840"
  },
  {
    "text": "minutes that you use in in that period so um part of what we've built is is",
    "start": "1476840",
    "end": "1482360"
  },
  {
    "start": "1480000",
    "end": "1606000"
  },
  {
    "text": "some some schedulers to um to to to deal with this kind of thing if if you go and",
    "start": "1482360",
    "end": "1488080"
  },
  {
    "text": "read the um the literature quite a lot of people like Google and Facebook and people are talking about how to schedule",
    "start": "1488080",
    "end": "1494600"
  },
  {
    "text": "where um how to schedule workloads on kind of what they're calling warehouse scale computer computers where they where they own all the computers they",
    "start": "1494600",
    "end": "1500039"
  },
  {
    "text": "can place the workload where they want and they they have control over everything the kind of schedu we've had to build is is is about placing",
    "start": "1500039",
    "end": "1507240"
  },
  {
    "text": "different workloads on a variety of different clouds in both public clouds and things like like Venter that",
    "start": "1507240",
    "end": "1512320"
  },
  {
    "text": "customers own where other other users are on the hosts so we we we might have noisy neighbors and also um we we get um",
    "start": "1512320",
    "end": "1522440"
  },
  {
    "text": "we we get build um per in this um example just given so so",
    "start": "1522440",
    "end": "1529120"
  },
  {
    "text": "it's it's kind of a slightly different type of scheduler and um the example I've just given is just for one assume",
    "start": "1529120",
    "end": "1535120"
  },
  {
    "text": "it's just one host and one test but actually what happens is often you you'll spin up a a host for the",
    "start": "1535120",
    "end": "1540640"
  },
  {
    "text": "microservice and you'll spin up a host to deliver the test load and you might spin up a host for the database server",
    "start": "1540640",
    "end": "1546240"
  },
  {
    "text": "or the message queue or something like this and so you end up with quite a complicated scheduling um scenario where",
    "start": "1546240",
    "end": "1553240"
  },
  {
    "text": "you might have a host ready that can be the database but you don't have the host that's can be the um the the the message",
    "start": "1553240",
    "end": "1558320"
  },
  {
    "text": "queue and you have to kind of try and pack the work in as efficiently as you can and try and optimize for the conflicting things which are length of",
    "start": "1558320",
    "end": "1564919"
  },
  {
    "text": "time it takes to do the test and price of the test um but it works pretty well for",
    "start": "1564919",
    "end": "1570559"
  },
  {
    "text": "microservices because you can um you can typically get quite a good um saving",
    "start": "1570559",
    "end": "1575960"
  },
  {
    "text": "overall and the cost of the test is generally significantly less than um the",
    "start": "1575960",
    "end": "1582080"
  },
  {
    "text": "cost of one instance and with a microservice you tend to be scaling out a number of those over a longer period",
    "start": "1582080",
    "end": "1587240"
  },
  {
    "text": "of time so the cost of test ends up being being quite efficient and quite small um so that's the material I have",
    "start": "1587240",
    "end": "1595480"
  },
  {
    "text": "and I'll be interested to take some questions and I'd like if you could go on the app and let me know what your thought of the talk thank",
    "start": "1595480",
    "end": "1602080"
  },
  {
    "text": "[Applause]",
    "start": "1602080",
    "end": "1608159"
  },
  {
    "start": "1606000",
    "end": "1705000"
  },
  {
    "text": "you okay so I'm going to look on here for some questions in the meantime does",
    "start": "1608159",
    "end": "1613320"
  },
  {
    "text": "anyone have a question they would like to inject",
    "start": "1613320",
    "end": "1619120"
  },
  {
    "text": "do you always use um do you always just use random parameters or do you ever use",
    "start": "1619120",
    "end": "1624480"
  },
  {
    "text": "things like profiling or Garbage Collection log analysis that sort of thing to help inform your sort of",
    "start": "1624480",
    "end": "1630720"
  },
  {
    "text": "initial set of parameters so um at at at the moment we we can do two things one",
    "start": "1630720",
    "end": "1638120"
  },
  {
    "text": "is is like I said a course um a course examination of the entire",
    "start": "1638120",
    "end": "1644440"
  },
  {
    "text": "surface so if you've got a continuous property like Heap size we might we might try from 0 to 4 gbt in 100",
    "start": "1644440",
    "end": "1652200"
  },
  {
    "text": "megabyte chunks or something um the other thing and and that's quite quite naive the the other thing we do is try",
    "start": "1652200",
    "end": "1658799"
  },
  {
    "text": "and fit these in using the Latin hyper Cube to pick points that work well with the other dimensions and that that's not",
    "start": "1658799",
    "end": "1664880"
  },
  {
    "text": "particularly amable to forcing a lot of choice on a particular parameter um you",
    "start": "1664880",
    "end": "1670840"
  },
  {
    "text": "can typically choose one or two and then the others kind of tend to fall in in in particular places or requireing an",
    "start": "1670840",
    "end": "1676320"
  },
  {
    "text": "orderly large amount of computer time to work out where to put them um another thing that we we're trying to do as we",
    "start": "1676320",
    "end": "1682559"
  },
  {
    "text": "collect data is actually mine the data for different apps and so classify the apps into you know this looks like an IO",
    "start": "1682559",
    "end": "1689120"
  },
  {
    "text": "kind of workload this looks like a a CPU kind of workload this is a database this is a message passing system and if we",
    "start": "1689120",
    "end": "1695240"
  },
  {
    "text": "can classify the apps like that then it's we can apply the learnings from optimizing those apps and kind of",
    "start": "1695240",
    "end": "1700279"
  },
  {
    "text": "amortize the cost of exploring the parameter space across a kind of a whole Suite of apps so um the number of tests that are",
    "start": "1700279",
    "end": "1708480"
  },
  {
    "start": "1705000",
    "end": "1863000"
  },
  {
    "text": "required to execute uh to you know to get to a certain level of",
    "start": "1708480",
    "end": "1713919"
  },
  {
    "text": "optimization uh is it is it totally dependent on the number of parameters that you uh that you have or there is",
    "start": "1713919",
    "end": "1721600"
  },
  {
    "text": "some kind of optimization over there there also like you know if if I have 10 parameters 10 into 10 is like in fact 10",
    "start": "1721600",
    "end": "1729840"
  },
  {
    "text": "to the^ of 10 yeah true we talking about hell lot of tests right so how do you so",
    "start": "1729840",
    "end": "1736000"
  },
  {
    "text": "yeah every time you add a dimension or so a parameter is one dimension or add a",
    "start": "1736000",
    "end": "1741480"
  },
  {
    "text": "a new value to the parameter um you basically have a um a power relationship",
    "start": "1741480",
    "end": "1749200"
  },
  {
    "text": "so you explode the parameter space and so it's infeasible to test that many number of parameters um using a lot of",
    "start": "1749200",
    "end": "1756559"
  },
  {
    "text": "this kind of um search methods because this kind of search method tries to distribute the points evenly throughout",
    "start": "1756559",
    "end": "1761760"
  },
  {
    "text": "the space and when that space gets bigger you need a lot more points to fill it up the hyper Cube method",
    "start": "1761760",
    "end": "1767120"
  },
  {
    "text": "actually work the other way around you tell it how many points you want and then it tries to put them in the best",
    "start": "1767120",
    "end": "1772480"
  },
  {
    "text": "place and so you can fix the number of points and it will try and distribute",
    "start": "1772480",
    "end": "1777720"
  },
  {
    "text": "them fairly regularly throughout the space but also try and get specific points where it thinks they going to be interesting based on parameters how",
    "start": "1777720",
    "end": "1784200"
  },
  {
    "text": "parameters might interact so so essentially if I start with like let's say 100 m of Heap size",
    "start": "1784200",
    "end": "1792880"
  },
  {
    "text": "if I increment it by like let's say 10 m each so the number of test that I need",
    "start": "1792880",
    "end": "1798039"
  },
  {
    "text": "to do is totally like the number of in that I want to have to reach that yeah",
    "start": "1798039",
    "end": "1803240"
  },
  {
    "text": "in in in the in the kind of the square the course method that's the case in the um in the hypercube method you can say",
    "start": "1803240",
    "end": "1810120"
  },
  {
    "text": "don't put the points closer than 10 megab megabytes apart but it might not put them that close it'll probably",
    "start": "1810120",
    "end": "1815880"
  },
  {
    "text": "spread them out further if it thinks that's not a very interesting Dimension I typically you'll find um the",
    "start": "1815880",
    "end": "1822960"
  },
  {
    "text": "Heap size kind of isn't isn't very smooth so like varying it between 0 and",
    "start": "1822960",
    "end": "1828159"
  },
  {
    "text": "100 megabytes or Z and half a gigabyte isn't very interesting but varying it between 3 GB and 4 GB might be quite",
    "start": "1828159",
    "end": "1835080"
  },
  {
    "text": "interesting for a particular workload and so what you can do is you can kind of put the points fairly coarsely and",
    "start": "1835080",
    "end": "1842039"
  },
  {
    "text": "fairly sparely to start with and then go back and and um when you fit the when you fit the surface like this you can",
    "start": "1842039",
    "end": "1848039"
  },
  {
    "text": "see a discontinuity and then you can do another set of tests to have a look in the place where you think the discontinuity is to see what where where",
    "start": "1848039",
    "end": "1854240"
  },
  {
    "text": "the inflection point is so I've got some uh some questions from",
    "start": "1854240",
    "end": "1860240"
  },
  {
    "text": "the app I'll come to you in a second um so there's nice qualifier with this says",
    "start": "1860240",
    "end": "1865679"
  },
  {
    "start": "1863000",
    "end": "2175000"
  },
  {
    "text": "how do you handle predictions if you have things like cluster management software like kubernetes or misos that are maybe moving workloads around while",
    "start": "1865679",
    "end": "1872360"
  },
  {
    "text": "you're sampling and then immediately followed by if this is NDA please ignore",
    "start": "1872360",
    "end": "1879360"
  },
  {
    "text": "um so you don't have to tell us it's tough it is tough like part of the stuff",
    "start": "1879360",
    "end": "1884760"
  },
  {
    "text": "in the scheduler at the end was to do with the fact that we're trying to place workloads on public clouds and when you",
    "start": "1884760",
    "end": "1890399"
  },
  {
    "text": "have a when you're at Google or Facebook doing the warehouse scale schedulers you can place those things based on I mean",
    "start": "1890399",
    "end": "1896960"
  },
  {
    "text": "it's kind of a hard problem anyway but at least you have all the data that you can um you can solve for the things",
    "start": "1896960",
    "end": "1902159"
  },
  {
    "text": "you're interested in there's a lot of things we can't solve for and no noisy neighbors is something that we try to minimize um and certainly the different",
    "start": "1902159",
    "end": "1909960"
  },
  {
    "text": "clouds give you different abilities so Amazon are kind of um offering some of",
    "start": "1909960",
    "end": "1915200"
  },
  {
    "text": "the best features on some of their larger instance you can now select um to be on the same land segment so that when",
    "start": "1915200",
    "end": "1921639"
  },
  {
    "text": "you're squirting the test load at the machine you're not going to be subject to as many um as much Jitter in the",
    "start": "1921639",
    "end": "1927080"
  },
  {
    "text": "network as if you just got a two random placements in the same region and so that yeah that's that's something we",
    "start": "1927080",
    "end": "1932720"
  },
  {
    "text": "have to control for and and it's it's part of the work we do when we when we write a new driver for a new new type of",
    "start": "1932720",
    "end": "1938600"
  },
  {
    "text": "cloud part of our our kind of productization process there there's a there's a how",
    "start": "1938600",
    "end": "1944679"
  },
  {
    "text": "does it work question so just if the machine learning part of this is using genetic algorithms or something smarter",
    "start": "1944679",
    "end": "1950559"
  },
  {
    "text": "to find Optimal configurations so what does it do what",
    "start": "1950559",
    "end": "1955679"
  },
  {
    "text": "does it do I see that's a good question um how long have you got so the the the genetic algorithm",
    "start": "1955679",
    "end": "1963159"
  },
  {
    "text": "works by uh kind of quite a um qu quite a small number of tests and then quite a",
    "start": "1963159",
    "end": "1969919"
  },
  {
    "text": "long lot of iterations we try and work we try and work the other way around so that we'll do more tests up front and",
    "start": "1969919",
    "end": "1976000"
  },
  {
    "text": "then only maybe a couple of rounds of iteration to um to mine the um the the",
    "start": "1976000",
    "end": "1983279"
  },
  {
    "text": "local areas we think are interesting because it turns out for our customers that time to time to gratification is",
    "start": "1983279",
    "end": "1990039"
  },
  {
    "text": "quite important so they they're happy to wait maybe two",
    "start": "1990039",
    "end": "1995519"
  },
  {
    "text": "hours or three hours they're not happy to wait a week so there's kind of a limit to the amount of feedback we can have between tests so most of our most",
    "start": "1995519",
    "end": "2002519"
  },
  {
    "text": "of our machine learning is on the analytics side where we're kind of mining mining the information um that we",
    "start": "2002519",
    "end": "2008240"
  },
  {
    "text": "already have and kind of doing some big data analytics on the on the Telemetry that we have from kind of lots and lots",
    "start": "2008240",
    "end": "2013360"
  },
  {
    "text": "of tests over time cool excellent I'm going to go running over here with the",
    "start": "2013360",
    "end": "2019000"
  },
  {
    "text": "microphone so my question is have you ever had any really big surprises when you initially had a fairly sparse uh",
    "start": "2019000",
    "end": "2025360"
  },
  {
    "text": "test space with some broadly separated parameters and then tighten that up by",
    "start": "2025360",
    "end": "2030679"
  },
  {
    "text": "saying order of magnitude and sudden you found a major optimization point on something uh where performance is",
    "start": "2030679",
    "end": "2036159"
  },
  {
    "text": "radically improved which you wouldn't have found had you not tightened that up yeah it turns out um I don't know if I'm",
    "start": "2036159",
    "end": "2041480"
  },
  {
    "text": "going to really answer the question you might have to ask ask me again where it's important but turns out the the best wins come from when you discover",
    "start": "2041480",
    "end": "2047799"
  },
  {
    "text": "bugs in the application so a lot of the stuff that's not been tested before when you test it in this kind of this kind of",
    "start": "2047799",
    "end": "2054158"
  },
  {
    "text": "intensive manner you end up finding a concurrency bug quite a lot and or you end up finding a a scaling bug in some",
    "start": "2054159",
    "end": "2060679"
  },
  {
    "text": "some minor code that generates the HTML table or something and you pull that out and you get you know thousands of",
    "start": "2060679",
    "end": "2066520"
  },
  {
    "text": "percent and you've had your big wins after that um often of often we've got some quite",
    "start": "2066520",
    "end": "2073520"
  },
  {
    "text": "good um often we've had some quite good wins",
    "start": "2073520",
    "end": "2079000"
  },
  {
    "text": "by kind of making compromises like the um of often you'll find a workload is",
    "start": "2079000",
    "end": "2084919"
  },
  {
    "text": "provisioned for over provisioned or provisioned for its peak load and and what that Peak load may be a completely",
    "start": "2084919",
    "end": "2092040"
  },
  {
    "text": "different kind of workload that happens overnight and so you can it completely ignore it optimize for the the common",
    "start": "2092040",
    "end": "2098839"
  },
  {
    "text": "case which happens during the day and then either reprovision at night or add something if possible maybe add a swap",
    "start": "2098839",
    "end": "2104480"
  },
  {
    "text": "space that allows it to complete in the nighttime period but maybe it takes a bit longer than it did before or",
    "start": "2104480",
    "end": "2109640"
  },
  {
    "text": "something like that so yeah the big wins are more more",
    "start": "2109640",
    "end": "2115760"
  },
  {
    "text": "lucky than you think they're not they're not that technical the smaller wins are kind of more gradual and you kind of tease more",
    "start": "2115760",
    "end": "2121560"
  },
  {
    "text": "out of the data and have to look at the crosscorrelation between the parameters and how they influence each other",
    "start": "2121560",
    "end": "2128400"
  },
  {
    "text": "fantastic um and then we have one more do you see the same cost savings for services using non jvm Stacks is it is",
    "start": "2128400",
    "end": "2133960"
  },
  {
    "text": "it specifically in the jvm that your work so most of our work is on the jvm and on the on the common language run time they're both pretty similar um both",
    "start": "2133960",
    "end": "2141280"
  },
  {
    "text": "pretty similar and that's where most of our data is at the moment so what about things like if you",
    "start": "2141280",
    "end": "2146359"
  },
  {
    "text": "had something like go that's a statically linked binary and carries its own VM with it I don't think we've",
    "start": "2146359",
    "end": "2151760"
  },
  {
    "text": "tested any go I'm afraid that' be fun okay um thanks very much indeed that's fantastic uh we're",
    "start": "2151760",
    "end": "2158599"
  },
  {
    "text": "going to take a short break and then everyone's back here at 5:00 for the closing keynote so thank you thank",
    "start": "2158599",
    "end": "2165650"
  },
  {
    "text": "[Applause]",
    "start": "2165650",
    "end": "2170288"
  },
  {
    "text": "you",
    "start": "2174200",
    "end": "2177200"
  }
]
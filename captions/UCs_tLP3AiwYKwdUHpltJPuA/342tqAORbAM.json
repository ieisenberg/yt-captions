[
  {
    "text": "[Music]",
    "start": "3550",
    "end": "7840"
  },
  {
    "text": "[Applause] good good morning yes still morning",
    "start": "11080",
    "end": "17460"
  },
  {
    "text": "right so the title is events storage in Axum server how does it work and I'm",
    "start": "17460",
    "end": "24539"
  },
  {
    "text": "pretty sure you're well you might be curious and why are you here otherwise I don't know how does it work but the",
    "start": "24539",
    "end": "30750"
  },
  {
    "text": "question that I'm asking myself to be honest over and over again but the question we asked ourselves in the",
    "start": "30750",
    "end": "36510"
  },
  {
    "text": "beginning is why would we want to build a in the end it's a database that we've",
    "start": "36510",
    "end": "43079"
  },
  {
    "text": "been we've been building and there's a few stupid things you can do in the",
    "start": "43079",
    "end": "48389"
  },
  {
    "text": "field of software engineering and building yet another type of database is definitely one of them",
    "start": "48389",
    "end": "53519"
  },
  {
    "text": "so we asked ourselves the question and we keep on asking to ourselves why would we want to do this so that's why I'm",
    "start": "53519",
    "end": "59789"
  },
  {
    "text": "trying going to try to to answer to myself but as I'm using a microphone you",
    "start": "59789",
    "end": "65580"
  },
  {
    "text": "might hear it as well and hopefully you get some inspiration out of it the",
    "start": "65580",
    "end": "71810"
  },
  {
    "text": "philosophy behind basically acts on and everything that we build is that of the the microservices journey right we",
    "start": "71810",
    "end": "78750"
  },
  {
    "text": "believe that to get to a successful microservices implementation you need to",
    "start": "78750",
    "end": "84840"
  },
  {
    "text": "take a journey that starts with a structured monolith right and then",
    "start": "84840",
    "end": "90630"
  },
  {
    "text": "slowly evolve that into into micro services and to be able to do that we",
    "start": "90630",
    "end": "97380"
  },
  {
    "text": "need a concept called location transparency which is that the components within that structured",
    "start": "97380",
    "end": "102600"
  },
  {
    "text": "monoliths should not be aware of their location compared to the other components they interact with and that",
    "start": "102600",
    "end": "109320"
  },
  {
    "text": "allows us to evolve those components without changing much of the logic inside of them right I'm not going to",
    "start": "109320",
    "end": "118620"
  },
  {
    "text": "dive into too much detail but that is done in through explicit messaging or",
    "start": "118620",
    "end": "124560"
  },
  {
    "text": "one way to achieve that is through explicit messaging in action we",
    "start": "124560",
    "end": "129950"
  },
  {
    "text": "distinguish between three types of messages commands events and queries so",
    "start": "129950",
    "end": "135420"
  },
  {
    "text": "commands are describe an intent to make a change to the system they are routed to a single",
    "start": "135420",
    "end": "141879"
  },
  {
    "text": "components queries describe the desire for information and then the events they",
    "start": "141879",
    "end": "147370"
  },
  {
    "text": "describe a facts that happened something happened in the system and we raise in",
    "start": "147370",
    "end": "152379"
  },
  {
    "text": "events which can be picked up by any component to to act on that and if you",
    "start": "152379",
    "end": "157450"
  },
  {
    "text": "use these api's if you use these types of messages then it doesn't really matter where the other where the",
    "start": "157450",
    "end": "162970"
  },
  {
    "text": "recipient is you can just route that message either through network if needed or within in our case the JVM within the",
    "start": "162970",
    "end": "170739"
  },
  {
    "text": "same JVM boundaries is pretty easy to route it to to a destination but there's",
    "start": "170739",
    "end": "176260"
  },
  {
    "text": "something special about these events and the thing is that these events they",
    "start": "176260",
    "end": "181510"
  },
  {
    "text": "retain value over time right so the fact that something happened might be",
    "start": "181510",
    "end": "187170"
  },
  {
    "text": "valuable to remember even several years from now right we'll get to see why and",
    "start": "187170",
    "end": "196239"
  },
  {
    "text": "there is some some challenges how can you guarantee that when you publish an event and have a state change in your",
    "start": "196239",
    "end": "201370"
  },
  {
    "text": "system so this event represents a change in the system how can you be sure that",
    "start": "201370",
    "end": "206889"
  },
  {
    "text": "both the publication of that event as well as the change in the system both",
    "start": "206889",
    "end": "212350"
  },
  {
    "text": "have happened you don't want to accidentally make a change and then send an event or send an event and not make",
    "start": "212350",
    "end": "219010"
  },
  {
    "text": "the change so you want to that this this history of events the stream of events",
    "start": "219010",
    "end": "225100"
  },
  {
    "text": "that you've been publishing in the past you want that to be reliable otherwise there's no value anymore in those in",
    "start": "225100",
    "end": "231519"
  },
  {
    "text": "those events and that's where the concept of event sourcing comes in now",
    "start": "231519",
    "end": "237730"
  },
  {
    "text": "event sourcing is you could say a subset of of event-driven architecture right so",
    "start": "237730",
    "end": "243760"
  },
  {
    "text": "using events does not mean you our event sourcing if you have two components let's say a and B a publishes events and",
    "start": "243760",
    "end": "251769"
  },
  {
    "text": "B handles them you are not doing event sourcing that's just well just that is event processing if an publication event",
    "start": "251769",
    "end": "260709"
  },
  {
    "text": "sourcing is something where the events are the number one element actually the only element to describe state changes",
    "start": "260709",
    "end": "267370"
  },
  {
    "text": "in your system and everything else all the other states you have completely derived from those events and",
    "start": "267370",
    "end": "277120"
  },
  {
    "text": "that makes event sourcing really about capturing the truth the whole truth and nothing but the truth so how does that",
    "start": "277120",
    "end": "285400"
  },
  {
    "text": "work when you store States you can imagine there's a certain order in our",
    "start": "285400",
    "end": "291340"
  },
  {
    "text": "system and it has a state it has had states earlier but we don't know those",
    "start": "291340",
    "end": "297310"
  },
  {
    "text": "states anymore we just know the current state because every change that happens replace that states by whatever it is",
    "start": "297310",
    "end": "304510"
  },
  {
    "text": "whatever it became right so the only thing we can now deduce is that somebody ordered a chair for 399 euros and while",
    "start": "304510",
    "end": "314800"
  },
  {
    "text": "the status says return shipments received so that person probably returned the chair didn't like it if we",
    "start": "314800",
    "end": "321850"
  },
  {
    "text": "were to use event sourcing we would not store the state at all our application would store everything that happened",
    "start": "321850",
    "end": "329860"
  },
  {
    "text": "that brought us to that state instead and to to load an object we recalculate",
    "start": "329860",
    "end": "335470"
  },
  {
    "text": "the state of an object by loading all the events that happen in the past so we",
    "start": "335470",
    "end": "340840"
  },
  {
    "text": "know an order was created at some point in time and two chairs were added to that order that's already something we",
    "start": "340840",
    "end": "347770"
  },
  {
    "text": "could not deduce from the state then he removes one order that explains where",
    "start": "347770",
    "end": "352870"
  },
  {
    "text": "there's only one over there then the order was confirmed then it was shipped then it was cancelled by the user but it",
    "start": "352870",
    "end": "358330"
  },
  {
    "text": "was cancelled after it was shipped so we have to wait for the return shipment to come now there's a bit of a storyline",
    "start": "358330",
    "end": "366490"
  },
  {
    "text": "there there's a lot of information in that process that we've lost with state",
    "start": "366490",
    "end": "372460"
  },
  {
    "text": "storage and you can imagine there might be value there might be a certain pattern of people putting two items in",
    "start": "372460",
    "end": "378940"
  },
  {
    "text": "their shopping baskets and then only one and then submitting that might be maybe you need to delay the shipment or get in",
    "start": "378940",
    "end": "385540"
  },
  {
    "text": "touch with them and I don't know what's but that's a problem for for retail so",
    "start": "385540",
    "end": "393640"
  },
  {
    "text": "why would we use event sourcing and there's a there's a couple of business reasons to do that so some of our",
    "start": "393640",
    "end": "399790"
  },
  {
    "text": "clients use it for editing reasons all the thing is a pretty strong requirement right it's basically a law it just says you",
    "start": "399790",
    "end": "406530"
  },
  {
    "text": "have to do this there's compliance somewhat similar but a lot of organizations that use it for the thing",
    "start": "406530",
    "end": "411900"
  },
  {
    "text": "they just want internal transparency they just want to get a better understanding of what an application has been doing what what decisions have been",
    "start": "411900",
    "end": "418470"
  },
  {
    "text": "made and that information is really useful for data mining or analytics",
    "start": "418470",
    "end": "424080"
  },
  {
    "text": "right it's it's as time series events describing exactly what happened we can",
    "start": "424080",
    "end": "429120"
  },
  {
    "text": "derive a lot of information from there and there's a lot of technical reasons",
    "start": "429120",
    "end": "434300"
  },
  {
    "text": "there's also some soft reasons some people say it's pretty cool so that's why I use it it's not a particularly",
    "start": "434300",
    "end": "440700"
  },
  {
    "text": "good reason so that's why it's not on the slide but there are some some",
    "start": "440700",
    "end": "446610"
  },
  {
    "text": "technical reasons as well but they are not as important I would say as the business reasons the business reasons",
    "start": "446610",
    "end": "451890"
  },
  {
    "text": "are generally the stronger drivers to use event sourcing or not but if you use",
    "start": "451890",
    "end": "457650"
  },
  {
    "text": "event sourcing you need something called an event store you need a place to store these events now Aksum framework was",
    "start": "457650",
    "end": "466410"
  },
  {
    "text": "started about 10 years ago and we use relational databases as an event store",
    "start": "466410",
    "end": "472470"
  },
  {
    "text": "to store these these events and that has",
    "start": "472470",
    "end": "477600"
  },
  {
    "text": "proven to be a pretty good implementation of it but there's a few categories so we started off with the relational databases at the time it",
    "start": "477600",
    "end": "485010"
  },
  {
    "text": "doesn't mean really matter which specific implementation you use they're all pretty generic in their core let's",
    "start": "485010",
    "end": "493800"
  },
  {
    "text": "say then there's a bunch of no sequel technologies out there as well and at",
    "start": "493800",
    "end": "500250"
  },
  {
    "text": "first glance they seem very useful as an event store but we'll find out that",
    "start": "500250",
    "end": "505640"
  },
  {
    "text": "that's not and lately there's a bunch of specialized events or technologies of",
    "start": "505640",
    "end": "512760"
  },
  {
    "text": "course there's axonal server and there's a reason we've we started building that not because we really like to inflict",
    "start": "512760",
    "end": "518909"
  },
  {
    "text": "pain on ourselves by implementing another database but we felt that we we",
    "start": "518910",
    "end": "523950"
  },
  {
    "text": "had to and the fact that there's more than one probably also indicates there's",
    "start": "523950",
    "end": "529470"
  },
  {
    "text": "a need for it at least that's what we're trying to tell ourselves so let's put that event story in context and let's",
    "start": "529470",
    "end": "535380"
  },
  {
    "text": "see what what this events or really means or what to do so imagine there's an application and it can read past events from the",
    "start": "535380",
    "end": "542610"
  },
  {
    "text": "events tour to rebuild its states to when there's a command coming in we need",
    "start": "542610",
    "end": "548550"
  },
  {
    "text": "to validate that command we probably need some states to decide whether or",
    "start": "548550",
    "end": "553620"
  },
  {
    "text": "not to accept that command whether we should do one thing or the other etc and those decisions are then",
    "start": "553620",
    "end": "561210"
  },
  {
    "text": "confirmed as using events again we publish more events to tell the rest of",
    "start": "561210",
    "end": "566640"
  },
  {
    "text": "the world what kind of decisions we've made now this works quite well for",
    "start": "566640",
    "end": "573180"
  },
  {
    "text": "processing these commands so I've got a command to confirm an order well that's great let's load the events of that",
    "start": "573180",
    "end": "579750"
  },
  {
    "text": "specific order we recreate it we see based on the state whether it's sensible",
    "start": "579750",
    "end": "585240"
  },
  {
    "text": "to confirm it at this point in time and if yes we publish the new events but if you want to get all orders with the",
    "start": "585240",
    "end": "592380"
  },
  {
    "text": "total value of more than 100 euros that's pretty problematic we don't need to read all the events and we'll start",
    "start": "592380",
    "end": "600660"
  },
  {
    "text": "discarding them if we find out that the total value became more than 100 that's not very efficient and that's why the",
    "start": "600660",
    "end": "609060"
  },
  {
    "text": "combination of event sourcing with secure ice is so popular because cqs allows us to create projections that",
    "start": "609060",
    "end": "615600"
  },
  {
    "text": "allow us to more efficiently answer these questions so the command handler",
    "start": "615600",
    "end": "620970"
  },
  {
    "text": "on top it will directly use the event store and load these specific events of",
    "start": "620970",
    "end": "626010"
  },
  {
    "text": "an order to to reconstruct the state to make decisions whereas for queries we create different",
    "start": "626010",
    "end": "632040"
  },
  {
    "text": "projections we project the event stream to a different model typically a data",
    "start": "632040",
    "end": "637050"
  },
  {
    "text": "model that allows us to efficiently answer these these queries and the",
    "start": "637050",
    "end": "646910"
  },
  {
    "text": "reason or the the way the events are is being used drives certain requirements",
    "start": "646910",
    "end": "652320"
  },
  {
    "text": "there are certain expectations we have of what an event store should do or what it should not do so let's quickly go",
    "start": "652320",
    "end": "659670"
  },
  {
    "text": "through them so an event store needs to read and write and we need to be able to",
    "start": "659670",
    "end": "665580"
  },
  {
    "text": "read events and we need to be able to write events now reading events there's a few use cases one is",
    "start": "665580",
    "end": "671730"
  },
  {
    "text": "we want to read all events for a single aggregate and an aggregate is a consistency boundary for example in",
    "start": "671730",
    "end": "678089"
  },
  {
    "text": "order right we want an order in itself to be fully consistent if there's a",
    "start": "678089",
    "end": "683549"
  },
  {
    "text": "change to an order it should not really conflict with any other changes in that order right that doesn't make sense so",
    "start": "683549",
    "end": "689579"
  },
  {
    "text": "we need to be able to efficiently retrieve all the events that were part",
    "start": "689579",
    "end": "695489"
  },
  {
    "text": "of the history of that specific order but we also need to be able to read all",
    "start": "695489",
    "end": "701669"
  },
  {
    "text": "events that happen since a specific point in time because we want to be able to create those projections right so for",
    "start": "701669",
    "end": "708480"
  },
  {
    "text": "the projections we basically want to read the events of all the orders and just more or less in the order they",
    "start": "708480",
    "end": "714029"
  },
  {
    "text": "actually occurred and then protect that that information and we want to be able",
    "start": "714029",
    "end": "721559"
  },
  {
    "text": "to read the events in the order they were actual so written if we start swapping events around one before the",
    "start": "721559",
    "end": "727889"
  },
  {
    "text": "other things get messy quite quickly and then there's always a desire to hack the",
    "start": "727889",
    "end": "735809"
  },
  {
    "text": "database right to go into the database and see what's in there there's a problem we want to be able to see what's",
    "start": "735809",
    "end": "741720"
  },
  {
    "text": "stored in there so that's one of the one of the requirements as well on the",
    "start": "741720",
    "end": "747059"
  },
  {
    "text": "writing side we want to be able to append events new events can happen we want to append those to the stream we",
    "start": "747059",
    "end": "753749"
  },
  {
    "text": "don't really need to insert the events at the random point things will only happen now right or in a few minutes but",
    "start": "753749",
    "end": "760919"
  },
  {
    "text": "then it only happens in a few minutes when now is at that point in time there's nothing we can do in the past",
    "start": "760919",
    "end": "766739"
  },
  {
    "text": "right so if we made a mistake in the past the only thing we can do it if fix it now we can't go back in time not yet",
    "start": "766739",
    "end": "774539"
  },
  {
    "text": "at least we don't need to update events all right same story if it happens",
    "start": "774539",
    "end": "780569"
  },
  {
    "text": "before too bad it happened there's nothing you can do about it anymore well other than compensate right now and",
    "start": "780569",
    "end": "787069"
  },
  {
    "text": "deleting events is generally also not something we we want to do we didn't generally don't want to ignore things",
    "start": "787069",
    "end": "793410"
  },
  {
    "text": "away just pretend they didn't happen because they did and again we need to correct so really we just need to append",
    "start": "793410",
    "end": "800549"
  },
  {
    "text": "defense but there's a few requirements we have when when a pending events as well",
    "start": "800549",
    "end": "808480"
  },
  {
    "text": "because reading back in the same order we write is important what what we need",
    "start": "808750",
    "end": "815420"
  },
  {
    "text": "at least conceptually is for every identifier so for every unique in this",
    "start": "815420",
    "end": "821330"
  },
  {
    "text": "case and in our account and the investment account even fancy we have a",
    "start": "821330",
    "end": "826970"
  },
  {
    "text": "sequence number to make sure that the events this is the order in which the events happened for that specific",
    "start": "826970",
    "end": "832370"
  },
  {
    "text": "investment account and because the investment account is a consistency boundary we can have full sequential",
    "start": "832370",
    "end": "839960"
  },
  {
    "text": "ordering within that accounts not across accounts but within one we can so the",
    "start": "839960",
    "end": "846350"
  },
  {
    "text": "next event will have sequence 1 and what we would want is when we we add sequence",
    "start": "846350",
    "end": "851570"
  },
  {
    "text": "number 2 and it happens on two nodes",
    "start": "851570",
    "end": "856670"
  },
  {
    "text": "simultaneously for whatever reason we want to be able to detect that as a",
    "start": "856670",
    "end": "861680"
  },
  {
    "text": "conflict we do not want this to happen because both these operations are legal",
    "start": "861680",
    "end": "867560"
  },
  {
    "text": "right we can deduct six hundred from a thousand and we can deduct seven hundred from a thousand but we cannot deduct 600",
    "start": "867560",
    "end": "875150"
  },
  {
    "text": "and 700 from a thousand that will not work so one of these will at least have",
    "start": "875150",
    "end": "881390"
  },
  {
    "text": "to fail one of these operations and preferably we would have the events or",
    "start": "881390",
    "end": "886760"
  },
  {
    "text": "to be able to do that for us because it is responsible for storing the information and just please don't store",
    "start": "886760",
    "end": "892010"
  },
  {
    "text": "information that is conflicting so when we append event we want to be able to",
    "start": "892010",
    "end": "897980"
  },
  {
    "text": "get these aggregate sequence numbers validated right we want some consistency",
    "start": "897980",
    "end": "904810"
  },
  {
    "text": "now the other one is when there is a transaction that publishes more than one event and this is just an example use",
    "start": "905589",
    "end": "912560"
  },
  {
    "text": "case is probably not very practical in this example because a transfer is",
    "start": "912560",
    "end": "919220"
  },
  {
    "text": "typically not a single transaction but let's assume it is right there is this transaction that publishes two events",
    "start": "919220",
    "end": "924920"
  },
  {
    "text": "now we either want both of them added to the event store or none of them right we",
    "start": "924920",
    "end": "930800"
  },
  {
    "text": "don't want the money to be withdrawn and then the shares never to be added that's",
    "start": "930800",
    "end": "935990"
  },
  {
    "text": "if so in consistency rather than eventual consistency so whoops wrong way so when",
    "start": "935990",
    "end": "943009"
  },
  {
    "text": "we append events we also want this atomicity we want to be able to append multiple entries and for the outside",
    "start": "943009",
    "end": "948529"
  },
  {
    "text": "world it's either the state before or the state after that they observe",
    "start": "948529",
    "end": "954699"
  },
  {
    "text": "related to that we only want to read committed offense right if one is in their wall so we need proper isolation",
    "start": "955779",
    "end": "961759"
  },
  {
    "text": "as well while we're doing a transaction we need to to not show that to the",
    "start": "961759",
    "end": "969199"
  },
  {
    "text": "outside world you can probably imagine what the next letter will be in red yes",
    "start": "969199",
    "end": "975559"
  },
  {
    "text": "durability so of course we want events that have occurred to stay there to not",
    "start": "975559",
    "end": "981410"
  },
  {
    "text": "suddenly disappear right you can get beautiful bugs and it's really fun",
    "start": "981410",
    "end": "986929"
  },
  {
    "text": "debugging if you find out events disappeared just out of nowhere then",
    "start": "986929",
    "end": "993139"
  },
  {
    "text": "there's some other problems that we saw with with customers they've been using this software even they've been using",
    "start": "993139",
    "end": "1000519"
  },
  {
    "text": "event sourcing for a vote for up to a decade right now and there's a lot of",
    "start": "1000519",
    "end": "1005619"
  },
  {
    "text": "events for single aggregates so that of accounts has been used for quite a while and to reload it states that will take a",
    "start": "1005619",
    "end": "1013360"
  },
  {
    "text": "long time oh it's only two almost ten thousand in this case but you know you can imagine if it's millions it will",
    "start": "1013360",
    "end": "1019839"
  },
  {
    "text": "take too long so for that we need a concept called snapshotting and so preferably our event",
    "start": "1019839",
    "end": "1025750"
  },
  {
    "text": "store is also capable of using snapshots and understand what the meaning of snapshot is so instead of reading all",
    "start": "1025750",
    "end": "1032350"
  },
  {
    "text": "the events up to ninety eighty nine thousand eighty we want to read the",
    "start": "1032350",
    "end": "1038168"
  },
  {
    "text": "snapshot and then the events that happened after that that should give us the same state for for resourcing or for",
    "start": "1038169",
    "end": "1047589"
  },
  {
    "text": "sourcing that specific bank account so",
    "start": "1047589",
    "end": "1052600"
  },
  {
    "text": "we want to be able to read offence and snapshots and an append events and snapshots and with that we have the",
    "start": "1052600",
    "end": "1058809"
  },
  {
    "text": "operation of pen snapshots and when we read the events for an aggregate what we want is to be able to read events for an",
    "start": "1058809",
    "end": "1065260"
  },
  {
    "text": "aggregate from the latest snapshots onwards as well as get all the events for an aggregate because that's snapshot",
    "start": "1065260",
    "end": "1072160"
  },
  {
    "text": "it's not always useful for every use case so and then we have a problem okay",
    "start": "1072160",
    "end": "1079240"
  },
  {
    "text": "over all of these bank accounts we've been using it for ten years so we've just got billions of events right so how",
    "start": "1079240",
    "end": "1088420"
  },
  {
    "text": "do we deal with that and we don't want the system to slow down as we have more events in there right so we want a",
    "start": "1088420",
    "end": "1095830"
  },
  {
    "text": "consistent performance as a function of storage size so it doesn't matter how many events we've got in there adding",
    "start": "1095830",
    "end": "1101950"
  },
  {
    "text": "more to them should be equally fast but when reading events we are much more",
    "start": "1101950",
    "end": "1108040"
  },
  {
    "text": "likely to read recent events than we are to read old events so we want the data",
    "start": "1108040",
    "end": "1113590"
  },
  {
    "text": "store to be optimized to read the recent ones as fast as we can does that make sense so far then there's",
    "start": "1113590",
    "end": "1122410"
  },
  {
    "text": "a few other other things so imagine we've got two nodes right one node contains the command Handler and we're using CQRS here where the C and the Q",
    "start": "1122410",
    "end": "1129790"
  },
  {
    "text": "are are deployed separately so we have these two nodes and then there's an",
    "start": "1129790",
    "end": "1135490"
  },
  {
    "text": "event story in between we want to be able to append events but how do we get",
    "start": "1135490",
    "end": "1141760"
  },
  {
    "text": "those events to the read store or a remodel how do we get the events from",
    "start": "1141760",
    "end": "1147280"
  },
  {
    "text": "the events or to the read model one way is to do polling right so that node can go to the event store and ask do you",
    "start": "1147280",
    "end": "1153490"
  },
  {
    "text": "have new events for me and that is possible with any type of events or",
    "start": "1153490",
    "end": "1158890"
  },
  {
    "text": "technology unfortunately it's not very efficient it adds to the latency of of that read model so another option is to",
    "start": "1158890",
    "end": "1168370"
  },
  {
    "text": "put some message bus in between say well let's stream all the new events to that",
    "start": "1168370",
    "end": "1173560"
  },
  {
    "text": "read model and this is what we've done for a long time in in acts on up until acts on - but then there's a problem how",
    "start": "1173560",
    "end": "1181030"
  },
  {
    "text": "do you guarantee again that publishing it to the event store and publishing it on the message bus is an atomic",
    "start": "1181030",
    "end": "1186820"
  },
  {
    "text": "operation that has proven to be difficult and there's another issue like",
    "start": "1186820",
    "end": "1192160"
  },
  {
    "text": "old events come from the event store and recent events come from the message bus so if we want to do a replay or create a",
    "start": "1192160",
    "end": "1199030"
  },
  {
    "text": "model a new model that we rehydrate from from data and event",
    "start": "1199030",
    "end": "1204850"
  },
  {
    "text": "store we have to swap over from from historic events to live events swapping",
    "start": "1204850",
    "end": "1210070"
  },
  {
    "text": "over is pretty difficult how can you guarantee you don't miss an event I accidentally between the two so",
    "start": "1210070",
    "end": "1217809"
  },
  {
    "text": "preferably we would have an event store that's capable of pushing new events so if there is a read model interested in",
    "start": "1217809",
    "end": "1224679"
  },
  {
    "text": "events it would just open a stream and whether there are old events or new ones it would just get them and as new ones",
    "start": "1224679",
    "end": "1230919"
  },
  {
    "text": "are added it would get them straight away when it's safe right when they're committed and and readable so we want to",
    "start": "1230919",
    "end": "1240429"
  },
  {
    "text": "be able to push new new ones so this is our our checklist so what we need to do",
    "start": "1240429",
    "end": "1246970"
  },
  {
    "text": "is put check boxes in front of them and pass some checks um some existing",
    "start": "1246970",
    "end": "1252610"
  },
  {
    "text": "technologies and this is a comparison we did a little while ago so some of that",
    "start": "1252610",
    "end": "1258220"
  },
  {
    "text": "information well there's one specific issue a thing that has become obsolete and now identify it later on but there's",
    "start": "1258220",
    "end": "1266289"
  },
  {
    "text": "some well technology that has been around our DBMS cetera and there's",
    "start": "1266289",
    "end": "1271510"
  },
  {
    "text": "some some contenders some technologies that have been associated with event sourcing in different areas that we also",
    "start": "1271510",
    "end": "1278470"
  },
  {
    "text": "compare and then there's built for purpose nowadays pumpkin to be being a pretty new one I don't think is GA yet",
    "start": "1278470",
    "end": "1285299"
  },
  {
    "text": "and there's Gregg's young event store which is slightly older than excellent",
    "start": "1285299",
    "end": "1290440"
  },
  {
    "text": "excellent event store so the relational database is one that we started off with",
    "start": "1290440",
    "end": "1296380"
  },
  {
    "text": "this is the very first implementation of the event store for a four axon as well was on the relational database and the",
    "start": "1296380",
    "end": "1304080"
  },
  {
    "text": "obvious example of a relational database is that's a very well established technology it has been around there",
    "start": "1304080",
    "end": "1310299"
  },
  {
    "text": "people know how to operate it if it breaks down we know how to get it fixed right and it has really good",
    "start": "1310299",
    "end": "1317200"
  },
  {
    "text": "transactional support transactions are like baked into those the problem though",
    "start": "1317200",
    "end": "1323710"
  },
  {
    "text": "is that the right throughput as the events or grows get slower and this is",
    "start": "1323710",
    "end": "1329169"
  },
  {
    "text": "actual benchmark results that we've been running the line goes on for at least the",
    "start": "1329169",
    "end": "1335110"
  },
  {
    "text": "that we've been running goes on for four longer but it didn't change anything it just slowly degraded and there's a bit",
    "start": "1335110",
    "end": "1342190"
  },
  {
    "text": "of a lump there there's some some areas where you see some more slightly more sudden changes and that has to do with",
    "start": "1342190",
    "end": "1349380"
  },
  {
    "text": "the memory so up until a certain moment everything fits in memory and then after",
    "start": "1349380",
    "end": "1355570"
  },
  {
    "text": "a while it doesn't anymore and then there's page swapping going on and the problem here is that the b-tree index",
    "start": "1355570",
    "end": "1361840"
  },
  {
    "text": "that is generally used to to make sure everything stays consistent they get",
    "start": "1361840",
    "end": "1368110"
  },
  {
    "text": "larger and larger and after a while they don't fit into memory anymore and then you get page swapping so there's a few",
    "start": "1368110",
    "end": "1376330"
  },
  {
    "text": "downsides there is that it doesn't scale right it doesn't scale to the volumes anymore and they don't have a way to",
    "start": "1376330",
    "end": "1384460"
  },
  {
    "text": "push events right some databases have some database specific implementation",
    "start": "1384460",
    "end": "1389500"
  },
  {
    "text": "for notifications you could use those too to do sort of long polling that kind",
    "start": "1389500",
    "end": "1394990"
  },
  {
    "text": "of stuff but then it becomes database specific and it feels still feels like a band-aid solution right there's enough",
    "start": "1394990",
    "end": "1402220"
  },
  {
    "text": "band-aids in most software already so let's try to avoid that so you know",
    "start": "1402220",
    "end": "1408429"
  },
  {
    "text": "checkmarks we see three three issues here it's not optimized for recent events databases you know they're",
    "start": "1408429",
    "end": "1414460"
  },
  {
    "text": "they're built to access any data at any time right and that's probably the cause",
    "start": "1414460",
    "end": "1420250"
  },
  {
    "text": "of the slowdown when when there's there's large amounts of events so a",
    "start": "1420250",
    "end": "1427000"
  },
  {
    "text": "common reaction that we saw is okay why not look at scalability is your problem when I look at no sequel okay so we did",
    "start": "1427000",
    "end": "1435040"
  },
  {
    "text": " was one of them and oh it's very scalable right but then we had a",
    "start": "1435040",
    "end": "1442510"
  },
  {
    "text": "challenge where doesn't work with events it works for documents so how does that relate and initially we",
    "start": "1442510",
    "end": "1448299"
  },
  {
    "text": "thought well an event is a document we just store every event as a document",
    "start": "1448299",
    "end": "1453360"
  },
  {
    "text": "however at the time if you if you had multiple events you would need two",
    "start": "1453360",
    "end": "1459160"
  },
  {
    "text": "documents and how do you guarantee that in a single transaction you couldn't nowadays you can since the",
    "start": "1459160",
    "end": "1466750"
  },
  {
    "text": "latest manga version they added support for or some support for transactions but at",
    "start": "1466750",
    "end": "1472940"
  },
  {
    "text": "the time they didn't so what we decided to do is okay if there's multiple events in a transaction we have one document",
    "start": "1472940",
    "end": "1479450"
  },
  {
    "text": "describing multiple events that sort of worked around that problem it gave some other problems on the reading side if",
    "start": "1479450",
    "end": "1485690"
  },
  {
    "text": "you look for a specific events it might be inside documents making queries more harder to do",
    "start": "1485690",
    "end": "1490940"
  },
  {
    "text": "making analysis of what's in my events or harder to do etc so it was not an ideal solution so document transactions",
    "start": "1490940",
    "end": "1499669"
  },
  {
    "text": "at the time were a problem they're not really anymore because we can now append",
    "start": "1499669",
    "end": "1505090"
  },
  {
    "text": "multiple documents into transactions however it still doesn't have easy push",
    "start": "1505090",
    "end": "1511220"
  },
  {
    "text": "there's a way to stream the the logs in one go and then you get all the append entries but then it's still kind of a",
    "start": "1511220",
    "end": "1518659"
  },
  {
    "text": "band-aid solution to to read the offence",
    "start": "1518659",
    "end": "1523700"
  },
  {
    "text": "and there's no way to get a sort of a global sequence so there's no way to ensure that reading events from",
    "start": "1523700",
    "end": "1529639"
  },
  {
    "text": "different consumers gives you it gives you the the same order in which events appear so there's a few red and we made",
    "start": "1529639",
    "end": "1541370"
  },
  {
    "text": "some of them yellow because they are kind of solved nowadays but and then",
    "start": "1541370",
    "end": "1547039"
  },
  {
    "text": "there's Kafka so event sourcing and Kafka is an interesting combination interesting as in hmm interesting but",
    "start": "1547039",
    "end": "1555679"
  },
  {
    "text": "we'll get to that so the pros of Kafka was it's focused on messaging right it's very obvious if you were in this room",
    "start": "1555679",
    "end": "1562340"
  },
  {
    "text": "before you'll know it's very scalable right so that's that's not a problem",
    "start": "1562340",
    "end": "1569899"
  },
  {
    "text": "however there there are a few few issues and imagine that we have a number of",
    "start": "1569899",
    "end": "1575149"
  },
  {
    "text": "aggregates and these represents events for aggregate a B C and D apparently now",
    "start": "1575149",
    "end": "1582200"
  },
  {
    "text": "if we have a single stream if we we all publish those to the same topic then if",
    "start": "1582200",
    "end": "1589159"
  },
  {
    "text": "we want to read events for aggregate B we would have to swim everything and filter out the ones for B that's not",
    "start": "1589159",
    "end": "1595880"
  },
  {
    "text": "extremely efficient so a reaction is okay let's create a",
    "start": "1595880",
    "end": "1601449"
  },
  {
    "text": "topic for every aggregates right how hard could that be then we have this guarantee well now there's a problem if",
    "start": "1601449",
    "end": "1607329"
  },
  {
    "text": "you want to read it events across angrier it's been okay let's that's another problem to solve later on so now",
    "start": "1607329",
    "end": "1614499"
  },
  {
    "text": "we have this four four topics and that's great but if we're looking at how topics",
    "start": "1614499",
    "end": "1619839"
  },
  {
    "text": "work topics are logical things and then we have partitions every topic will have",
    "start": "1619839",
    "end": "1625119"
  },
  {
    "text": "one or more partitions they are physical they are represented as physical files",
    "start": "1625119",
    "end": "1630669"
  },
  {
    "text": "on on on disk and then they have segments right there's there's a login",
    "start": "1630669",
    "end": "1637179"
  },
  {
    "text": "an index file for every segment in that partition so as we write the events there's segmentation going on now",
    "start": "1637179",
    "end": "1643749"
  },
  {
    "text": "because there is a physical there's actually something physical happening on our disk for those for those topics it",
    "start": "1643749",
    "end": "1651789"
  },
  {
    "text": "doesn't scale to millions of aggregates you can't just create topics as they are free right they're not so you you need",
    "start": "1651789",
    "end": "1659289"
  },
  {
    "text": "to have a limited set of of topics so",
    "start": "1659289",
    "end": "1666369"
  },
  {
    "text": "then there's there's these middle grounds where they say well you can do a hashing algorithm and have you don't have a bit of both it's like yeah you've",
    "start": "1666369",
    "end": "1672759"
  },
  {
    "text": "got two evils let's pick a bit of both evils and then feel better I don't know that's again a big band-aid solution so",
    "start": "1672759",
    "end": "1680199"
  },
  {
    "text": "it's very scalable in total numbers of events but it's not scalable in a number of aggregates and for event sourcing",
    "start": "1680199",
    "end": "1687219"
  },
  {
    "text": "systems this is essential so there's a few downsides there as well and there's",
    "start": "1687219",
    "end": "1693129"
  },
  {
    "text": "one that I didn't emphasize yet but Kafka doesn't care about sequence number it if you publish two events then that's",
    "start": "1693129",
    "end": "1699579"
  },
  {
    "text": "great then you publish two events so it's really up to you to decide whether or not you want to publish that so",
    "start": "1699579",
    "end": "1704859"
  },
  {
    "text": "you'll need to read consistently from Kafka in that case I'm not sure if",
    "start": "1704859",
    "end": "1710169"
  },
  {
    "text": "that's even possible and then there's Cassandra also very",
    "start": "1710169",
    "end": "1715419"
  },
  {
    "text": "scalable well scalable across data centers it uses a peer-to-peer",
    "start": "1715419",
    "end": "1721509"
  },
  {
    "text": "networking so that's you know it's on the surface it's really awesome but",
    "start": "1721509",
    "end": "1726849"
  },
  {
    "text": "there's this problem remember Cassandra doesn't really help you with that Cassandra does not to sum to to an",
    "start": "1726849",
    "end": "1735730"
  },
  {
    "text": "extent does not support capturing this this issue so what if node a gets an",
    "start": "1735730",
    "end": "1742780"
  },
  {
    "text": "update and node B in Cassandra gets and updates and these updates are conflicting well Cassandra will resolve",
    "start": "1742780",
    "end": "1749860"
  },
  {
    "text": "that conflict normally by throwing one away one will overwrite the other that's",
    "start": "1749860",
    "end": "1756670"
  },
  {
    "text": "not really what we want now fortunately Cassandra does supports sort of if not exists there is support for this",
    "start": "1756670",
    "end": "1763590"
  },
  {
    "text": "consistent append however taken from the website of data sex is this piece of",
    "start": "1763590",
    "end": "1770470"
  },
  {
    "text": "text that says just don't use it you can use it sort of incidentally but it does",
    "start": "1770470",
    "end": "1777370"
  },
  {
    "text": "for round trips so it does not really perform right so they basically say if",
    "start": "1777370",
    "end": "1783670"
  },
  {
    "text": "this is your use case don't use Cassandra because it's not designed to do that it's done designed to do an incidental check but not all the time if",
    "start": "1783670",
    "end": "1794620"
  },
  {
    "text": "a vendor says don't use our tool for this then they're probably right so just don't so we have a consistency problem",
    "start": "1794620",
    "end": "1802440"
  },
  {
    "text": "and again you can work around those consistency problems there are some some event sourcing frameworks out there that",
    "start": "1802440",
    "end": "1810580"
  },
  {
    "text": "we do work with Cassandra they require you to have this consistency checks in the application so putting some data",
    "start": "1810580",
    "end": "1817360"
  },
  {
    "text": "validation in the application itself that's possible but I don't think mrit",
    "start": "1817360",
    "end": "1823510"
  },
  {
    "text": "--all so what about the bills for purpose events or so of course they",
    "start": "1823510",
    "end": "1828670"
  },
  {
    "text": "check all the boxes right they because they're designed to actually do that there's the events are by by greg young",
    "start": "1828670",
    "end": "1834820"
  },
  {
    "text": "and even though that existed why did we still decide to build our own the event",
    "start": "1834820",
    "end": "1840220"
  },
  {
    "text": "store was was built internet which is not particularly a problem you can no interacts with net and and and java",
    "start": "1840220",
    "end": "1847140"
  },
  {
    "text": "without too much problems but they made some design choices that not everybody agrees with where a lot of rejection",
    "start": "1847140",
    "end": "1853690"
  },
  {
    "text": "logic is done in the event store in javascript so if you're not a pl/sql fan",
    "start": "1853690",
    "end": "1860770"
  },
  {
    "text": "you're probably also not a fan of putting javascript in the database it creates a type of locking vendor",
    "start": "1860770",
    "end": "1867240"
  },
  {
    "text": "lock-in that we wouldn't we wouldn't be comfortable with implementing pumpkin DB",
    "start": "1867240",
    "end": "1873450"
  },
  {
    "text": "is a relatively new player it's not GA yet as far as I know and they came up",
    "start": "1873450",
    "end": "1878909"
  },
  {
    "text": "with pumpkin scripts so who's a pumpkin script developer oh yeah okay well that",
    "start": "1878909",
    "end": "1886049"
  },
  {
    "text": "might be anything so let's have a look at what we did with with accent server",
    "start": "1886049",
    "end": "1891950"
  },
  {
    "text": "we built it from scratch all right not entirely for scrap we use some existing frameworks in there but at least we're",
    "start": "1891950",
    "end": "1898889"
  },
  {
    "text": "not using existing database technology to you were to work with it right we purpose-built it for event sourcing so",
    "start": "1898889",
    "end": "1905370"
  },
  {
    "text": "if you want to use it for something else don't it's it's useful for event sourcing we we manage files directly as",
    "start": "1905370",
    "end": "1913649"
  },
  {
    "text": "any database does that etc and it has interfaces with based on HTTP and JSON",
    "start": "1913649",
    "end": "1919470"
  },
  {
    "text": "or a G RPC and especially the gr PC one is very interesting because it gives you a two-way connection right you can",
    "start": "1919470",
    "end": "1926220"
  },
  {
    "text": "stream two ways so that's a very easy way to to get the the push overwrite you",
    "start": "1926220",
    "end": "1932549"
  },
  {
    "text": "just have a fixed connection and you can generate stubs in any language that you would even want to interact with with",
    "start": "1932549",
    "end": "1939090"
  },
  {
    "text": "actual server obviously it's a drop-in replacement if you use actual framework which is obvious so it's append only by",
    "start": "1939090",
    "end": "1947460"
  },
  {
    "text": "design right we've designed this datastore to not be able to do updates",
    "start": "1947460",
    "end": "1952620"
  },
  {
    "text": "or deletes there are ways if you really really messed up our ways to do that but",
    "start": "1952620",
    "end": "1960330"
  },
  {
    "text": "don't tell anyone please cut that out of the recording as well but you know essentially by design",
    "start": "1960330",
    "end": "1967019"
  },
  {
    "text": "it sits there - only append new events and because appending everything to a",
    "start": "1967019",
    "end": "1973289"
  },
  {
    "text": "single file is not a very sensible thing to do what we do is we create segments",
    "start": "1973289",
    "end": "1978899"
  },
  {
    "text": "and when a segment is full and basically you decide what full means it might be",
    "start": "1978899",
    "end": "1984360"
  },
  {
    "text": "it's by default 500 Meg's it should be a size that you are comfortable with shipping to your backup environments",
    "start": "1984360",
    "end": "1991320"
  },
  {
    "text": "right so we can change these segments and when more events arrive it just",
    "start": "1991320",
    "end": "1996570"
  },
  {
    "text": "creates new segments that continue writing right so that's the core of how events are written now it has snapshots",
    "start": "1996570",
    "end": "2004580"
  },
  {
    "text": "and snapshots are stored in segments besides the event stream and every snapshot basically points to the event",
    "start": "2004580",
    "end": "2010940"
  },
  {
    "text": "that's the last event included in that snapshot so when we found this snapshot",
    "start": "2010940",
    "end": "2016760"
  },
  {
    "text": "to be a relevant snapshot for us to to optimize reading we know exactly where",
    "start": "2016760",
    "end": "2021769"
  },
  {
    "text": "to continue reading for for the events now still we would have to stream all",
    "start": "2021769",
    "end": "2028039"
  },
  {
    "text": "the events and filter them out which is something I said but it was inefficient with with Kafka so it's inefficient with",
    "start": "2028039",
    "end": "2034519"
  },
  {
    "text": "accent server as well if it weren't for the fact that every segment contains well obviously the data itself but it",
    "start": "2034519",
    "end": "2042860"
  },
  {
    "text": "also contains an index it contains a very small description of what we have where in that specific file and to",
    "start": "2042860",
    "end": "2050690"
  },
  {
    "text": "prevent we even need to inspect the index we also have a bloom filter that can tell us relatively reliably whether",
    "start": "2050690",
    "end": "2058010"
  },
  {
    "text": "an aggregate is in there might be in there or is definitely not right so",
    "start": "2058010",
    "end": "2063950"
  },
  {
    "text": "bloom filters give you an absolute no or a maybe yes right so it might be that",
    "start": "2063950",
    "end": "2069888"
  },
  {
    "text": "according to the bloom filter the data is in there but it happened not to be which is good that's on the safe side",
    "start": "2069889",
    "end": "2076280"
  },
  {
    "text": "we'd rather open an index file and not find any relevant events then skipping",
    "start": "2076280",
    "end": "2081530"
  },
  {
    "text": "an index file that describes relevant events for us and then index files tells us exactly which positions in that file",
    "start": "2081530",
    "end": "2087770"
  },
  {
    "text": "we need to be reading so we can very quickly find events for a specific",
    "start": "2087770",
    "end": "2093230"
  },
  {
    "text": "aggregate so when reading through we're very fast at finding those but if we",
    "start": "2093230",
    "end": "2100760"
  },
  {
    "text": "want to search events from so let's say we want to load events for specific aggregates we want to optimize for",
    "start": "2100760",
    "end": "2107030"
  },
  {
    "text": "recent events to be faster so what we do inspecting those files is start at the",
    "start": "2107030",
    "end": "2112490"
  },
  {
    "text": "end and go back in time so we take the last segment file check those index",
    "start": "2112490",
    "end": "2118760"
  },
  {
    "text": "files if it's not there go back go back go back until we found the the the",
    "start": "2118760",
    "end": "2125390"
  },
  {
    "text": "aggregate and sequence number that that we found we we were looking for and to optimize it",
    "start": "2125390",
    "end": "2134090"
  },
  {
    "text": "even more we keep the recent segments very aggressively in memory as well as",
    "start": "2134090",
    "end": "2139610"
  },
  {
    "text": "on disk right that your ability is important there on disk but we keep those files in memory because we know the likelihood of those events being",
    "start": "2139610",
    "end": "2146210"
  },
  {
    "text": "being accessed is so much higher so there's an index in memory as well that",
    "start": "2146210",
    "end": "2152510"
  },
  {
    "text": "is a lot faster than index on file obviously and that's the way that's how",
    "start": "2152510",
    "end": "2157850"
  },
  {
    "text": "we optimize the loading time for aggregates that are relatively active at",
    "start": "2157850",
    "end": "2164000"
  },
  {
    "text": "that point in time so we ran some benchmarks or we ran the same benchmarks",
    "start": "2164000",
    "end": "2171590"
  },
  {
    "text": "with accent server and obviously because it was designed to do that this was more",
    "start": "2171590",
    "end": "2177260"
  },
  {
    "text": "of a validation for us does it do what we designed it for and as I said the",
    "start": "2177260",
    "end": "2182390"
  },
  {
    "text": "test ran a lot longer we had to stop well we didn't actually physically stop",
    "start": "2182390",
    "end": "2187640"
  },
  {
    "text": "the process but the line stopped for the red one because appending became so slow that if couldn't get to 200 million",
    "start": "2187640",
    "end": "2194450"
  },
  {
    "text": "within what we thought was a reasonable time I think we ran it to over a billion",
    "start": "2194450",
    "end": "2199700"
  },
  {
    "text": "and the line just stayed there it even went a bit up here so it got faster over",
    "start": "2199700",
    "end": "2205280"
  },
  {
    "text": "time but there was actually one test run where we saw this go up significantly",
    "start": "2205280",
    "end": "2211100"
  },
  {
    "text": "and we thought well we we couldn't explain that so we checked some some logs on server and this was running on",
    "start": "2211100",
    "end": "2218120"
  },
  {
    "text": "Google cloud and we actually Google had a bug that accidentally they gave us a",
    "start": "2218120",
    "end": "2223490"
  },
  {
    "text": "lot more I ops so he became a lot faster suddenly so we discarded that test and run it again that was an interesting but",
    "start": "2223490",
    "end": "2232640"
  },
  {
    "text": "then there's the the the query problem a very common problem is okay you've got this obscure database we've got all this",
    "start": "2232640",
    "end": "2239600"
  },
  {
    "text": "tooling to access existing databases how do we get a fence out of your event store how can we see what's in there",
    "start": "2239600",
    "end": "2245660"
  },
  {
    "text": "right so the storage forum we're not particularly secretive about the storage formats of all these event files in fact",
    "start": "2245660",
    "end": "2252980"
  },
  {
    "text": "there it's open source so you can just you know see the source code of how the files are actually stored but it's not",
    "start": "2252980",
    "end": "2260300"
  },
  {
    "text": "very user friendly so there is an a di na you I to do queries and we we came up with a query language if you can call",
    "start": "2260300",
    "end": "2267530"
  },
  {
    "text": "it that that takes into account that this is a streaming thing right there's an event stream so you can do filters",
    "start": "2267530",
    "end": "2274850"
  },
  {
    "text": "you can describe a certain filter in this case the aggregate identifier needs to be that and then it will give you",
    "start": "2274850",
    "end": "2281600"
  },
  {
    "text": "everything all the events that have that aggregates identifier you can keep that query running so at real time you'll see",
    "start": "2281600",
    "end": "2287840"
  },
  {
    "text": "new new events being added if you want to if you're trying to copy/paste something that might be annoying so you",
    "start": "2287840",
    "end": "2295790"
  },
  {
    "text": "can you can stop it as well but you can do a slightly more advanced stuff you can say well the payload data must",
    "start": "2295790",
    "end": "2302000"
  },
  {
    "text": "contain something and then I want to select specific information and even inspect using XPath in this case because",
    "start": "2302000",
    "end": "2308060"
  },
  {
    "text": "the payload was XML it's not actual servers fault it's your choice what you",
    "start": "2308060",
    "end": "2313310"
  },
  {
    "text": "want to store but if it's XML you can use XPath expressions to get specific data out of it you can do group by and",
    "start": "2313310",
    "end": "2321410"
  },
  {
    "text": "that kind of that kind of thing as well so you can do some let's say easy analysis on on the event store don't",
    "start": "2321410",
    "end": "2329210"
  },
  {
    "text": "create projections using these queries and then say well this is a result it's not what the event store was designed to",
    "start": "2329210",
    "end": "2336020"
  },
  {
    "text": "do if you want to create a projection just read the events and use code your in your own environment to to create",
    "start": "2336020",
    "end": "2342920"
  },
  {
    "text": "these predictions so to make sure that everything is durable we don't lose data",
    "start": "2342920",
    "end": "2349360"
  },
  {
    "text": "we implemented clustering based on the raft consensus protocol so that means",
    "start": "2349360",
    "end": "2355340"
  },
  {
    "text": "there's a master and it's a slough the floating master in this case if it's on",
    "start": "2355340",
    "end": "2360620"
  },
  {
    "text": "node 3 if and it will replicate to node 1 and 2 and it wait for a majority to",
    "start": "2360620",
    "end": "2366950"
  },
  {
    "text": "acknowledge the transaction before it's considered ok committed so if that node",
    "start": "2366950",
    "end": "2372080"
  },
  {
    "text": "fails another node will be elected as master the client will automatically reconnect to that master and as no three",
    "start": "2372080",
    "end": "2381110"
  },
  {
    "text": "comes back it will be automatically replicated again but the cluster of two is able to run because there's still a",
    "start": "2381110",
    "end": "2388070"
  },
  {
    "text": "majority able to acknowledge transactions so how do you get started",
    "start": "2388070",
    "end": "2395530"
  },
  {
    "text": "for yourself as I said everything is open source so most of the stuff you can if you want axon framework I want to use",
    "start": "2395530",
    "end": "2401080"
  },
  {
    "text": "axon server their stuff on github obviously the Enterprise Edition which is our commercial offering is not on",
    "start": "2401080",
    "end": "2406990"
  },
  {
    "text": "github well it is but in a private repository you can use maven docker etc",
    "start": "2406990",
    "end": "2412000"
  },
  {
    "text": "to to get access to those essentially if you go to a Chronicle IO and slash",
    "start": "2412000",
    "end": "2417070"
  },
  {
    "text": "downloads you can just try it for yourself I just got the five minute sign that means we should have five minutes",
    "start": "2417070",
    "end": "2424270"
  },
  {
    "text": "left for questions thank you [Applause]",
    "start": "2424270",
    "end": "2433790"
  }
]
[
  {
    "text": "so um I'm the head of engineering for a part of the bank called analytics and",
    "start": "4319",
    "end": "10080"
  },
  {
    "text": "information where uh we sit underneath one of the architecture areas in the bank and effectively we look after the",
    "start": "10080",
    "end": "16760"
  },
  {
    "text": "hudo platforms and the Big Data uh sorry the warehouse and some of the analytics tools SAS and visualization",
    "start": "16760",
    "end": "24240"
  },
  {
    "text": "Etc and my engineering teams kind of uh span from application Level engineering",
    "start": "24240",
    "end": "30679"
  },
  {
    "text": "uh data scientists all the way through to systems engineers and today the teams that rack the servers in the data center",
    "start": "30679",
    "end": "36760"
  },
  {
    "text": "also report up into me so we started off a journey of very much focusing on the",
    "start": "36760",
    "end": "42600"
  },
  {
    "text": "uh data science outcomes and over time we've had to get further and further into the infrastructure space simply",
    "start": "42600",
    "end": "48199"
  },
  {
    "text": "because the solutions below us were affecting us so badly so the talk today",
    "start": "48199",
    "end": "53480"
  },
  {
    "text": "is to describe a portion of that Journey um that Journey doesn't necessarily resonate for you or it's not necessarily",
    "start": "53480",
    "end": "60320"
  },
  {
    "text": "a problem space that you have because a lot of you exist inside public cloud and I'll talk about why that isn't necessarily a solution for us and so",
    "start": "60320",
    "end": "67759"
  },
  {
    "text": "there's a portion of our problem space which potentially could be solved by public Cloud but there's also a portion of us of our problem space that you have",
    "start": "67759",
    "end": "74479"
  },
  {
    "text": "to solve regardless of the hosting environment so to kind of give you a bit",
    "start": "74479",
    "end": "79640"
  },
  {
    "text": "of background on this um the warehouse that we've got is a fairly large teradata instance we've",
    "start": "79640",
    "end": "85880"
  },
  {
    "text": "had it for about 12 years and it's gone through various Generations as you'd expect and and we've had her dupe in",
    "start": "85880",
    "end": "91240"
  },
  {
    "text": "production sitting in front of the warehouse for about 4 years now and over that time there's been various",
    "start": "91240",
    "end": "96520"
  },
  {
    "text": "generations of those technology platforms but also various generations of Hosting that those platforms sit on",
    "start": "96520",
    "end": "102880"
  },
  {
    "text": "uh and so the overall Story coming into Circ a year ago was not a very nice one",
    "start": "102880",
    "end": "108280"
  },
  {
    "text": "from a hosting point of view before I get there let me just talk a little bit about the workload so like I said terod",
    "start": "108280",
    "end": "113560"
  },
  {
    "text": "data and hudo uh Hadoop actually came along the journey mostly as an experiment into machine learning for a",
    "start": "113560",
    "end": "120200"
  },
  {
    "text": "bank as opposed to uh standing up a replacement for the warehouse as most a lot of people kind of reach for uh ETL",
    "start": "120200",
    "end": "127039"
  },
  {
    "text": "workload migration we reached for Hadoop in order to do machine learning for the bank and we built some models together",
    "start": "127039",
    "end": "133840"
  },
  {
    "text": "with the guys from nicta and that worked out fairly well and before we knew it we had to productionize these things and as",
    "start": "133840",
    "end": "140599"
  },
  {
    "text": "you guys will have heard this morning from Mark and Ben building a machine Learning System is quite different to",
    "start": "140599",
    "end": "145959"
  },
  {
    "text": "just doing machine learning and part of that problem is about acquiring and integrating data and so that becomes a",
    "start": "145959",
    "end": "152879"
  },
  {
    "text": "cost or a commercial discussion of do I ask every single project to load to the warehouse and to the hop instance so in",
    "start": "152879",
    "end": "159120"
  },
  {
    "text": "order to solve that problem we put her doop in front of the warehouse treat it as a landing zone for the warehouse and",
    "start": "159120",
    "end": "164400"
  },
  {
    "text": "what we get out of that then is we have all the data in one place and we get to leverage it that that cost of",
    "start": "164400",
    "end": "170120"
  },
  {
    "text": "integration many times over for analytic purposes and the warehouse keeps doing what the warehouse is good at which is",
    "start": "170120",
    "end": "176319"
  },
  {
    "text": "self-service bi uh 1500 users doing at par queries and uh Financial",
    "start": "176319",
    "end": "182040"
  },
  {
    "text": "reconciliation Etc and so we go down this journey of uh moving all of the analytic workload onto Hadoop and then",
    "start": "182040",
    "end": "188920"
  },
  {
    "text": "once you've built models and you're getting fairly good at operationalizing models and uh starting to show business",
    "start": "188920",
    "end": "194519"
  },
  {
    "text": "value the business wants this integrated into the product systems and so you move into the space where you've got workload",
    "start": "194519",
    "end": "200159"
  },
  {
    "text": "coming from users and you've also got workload where you integrate it directly into the product systems so uh as",
    "start": "200159",
    "end": "205840"
  },
  {
    "text": "examples of when you do certain things within netbank um a portion of that is",
    "start": "205840",
    "end": "211360"
  },
  {
    "text": "making API calls back into the Hadoop infrastructure and a portion of that is just in the web tier so where we are today thousands of",
    "start": "211360",
    "end": "219439"
  },
  {
    "text": "batch jobs uh all fairly complex or you know from fairly simple data loads through to fairly complex uh upward of",
    "start": "219439",
    "end": "226319"
  },
  {
    "text": "six pyes of states and growing we grow at about 60% year on- year at the moment rather large amount of Open",
    "start": "226319",
    "end": "232799"
  },
  {
    "text": "Source and this is kind of grown organically uh we've got hbas our",
    "start": "232799",
    "end": "237920"
  },
  {
    "text": "original feature store for machine learning is still based on hbas but a lot of our uh read based workload is",
    "start": "237920",
    "end": "243760"
  },
  {
    "text": "moving increasingly to Cassandra hdfs is obviously the base state store uh influx",
    "start": "243760",
    "end": "249920"
  },
  {
    "text": "and elastic search more for operational monitoring and then etcd zookeeper Etc come along the journey because of",
    "start": "249920",
    "end": "256160"
  },
  {
    "text": "cluster management of course we also have all the relational databases and lots of them um no good reason for this",
    "start": "256160",
    "end": "262840"
  },
  {
    "text": "it just is it's what happens in large organizations over time that's my excuse uh hundreds of services lots of",
    "start": "262840",
    "end": "270240"
  },
  {
    "text": "different execution environments lots of environments uh 1500 users querying the",
    "start": "270240",
    "end": "276000"
  },
  {
    "text": "warehouse and working with a dupe and upward to 400 developers building loads both into the warehouse and on top of a",
    "start": "276000",
    "end": "283000"
  },
  {
    "text": "dup so fair amount of complexity fair amount of Open Source fair amount of data broad set of use cases from kind of",
    "start": "283000",
    "end": "290120"
  },
  {
    "text": "credit scoring all the way through to how you interact with personal financial management on in netbank and the hosting",
    "start": "290120",
    "end": "296720"
  },
  {
    "text": "environment I've used explicitly a very simplistic picture because it is quite a simplistic hosting environment that we",
    "start": "296720",
    "end": "302840"
  },
  {
    "text": "started off with uh trodat we treat as a black box there's 40 racks of what is",
    "start": "302840",
    "end": "308759"
  },
  {
    "text": "essentially commodity Hardware with a fairly good network but we treat it as a blackbox uh from a commercial point of",
    "start": "308759",
    "end": "315120"
  },
  {
    "text": "view but also from an operational point of view it's inside our data center but someone else is looking after it similar",
    "start": "315120",
    "end": "320960"
  },
  {
    "text": "sort of idea with data stage so I'll largely ignore those too um the Hadoop space it's just x86 so cladera hop",
    "start": "320960",
    "end": "328440"
  },
  {
    "text": "running directly on x86 you've got a bunch of servers Linux running on it and you've blasted a bunch of CDH on top of",
    "start": "328440",
    "end": "334400"
  },
  {
    "text": "these Linux boxes and then off to the side in the generic hosting we've got an esxi A Fairly large esxi instance 40,000",
    "start": "334400",
    "end": "342479"
  },
  {
    "text": "odd VMS and all the other workload gets hosted there and all we have in that space or we had traditionally in that",
    "start": "342479",
    "end": "348840"
  },
  {
    "text": "space was Linux VMS so what what you're looking at is a fair amount of disparate",
    "start": "348840",
    "end": "355360"
  },
  {
    "text": "hosting environments and also a very poor coverage of um what you expect in a",
    "start": "355360",
    "end": "362080"
  },
  {
    "text": "mature hosting environment in terms of the developer experience so if I want to build a build and host a service",
    "start": "362080",
    "end": "368080"
  },
  {
    "text": "something simple like a dashboard I have to spin up a Linux VM which takes a lot longer than API call because it's a very",
    "start": "368080",
    "end": "374120"
  },
  {
    "text": "controlled environment as you'd expect in a inside a regulated environment a lot of that is because of manual process",
    "start": "374120",
    "end": "380840"
  },
  {
    "text": "and then I don't have monitoring I don't have alerting I don't have logging I have to go and figure out how to",
    "start": "380840",
    "end": "386080"
  },
  {
    "text": "integrate all of those things myself as a developer and so I'm sitting in a hosting environment that's expensive",
    "start": "386080",
    "end": "392160"
  },
  {
    "text": "it's slow to get started and it doesn't have all of the infrastructure contract that I expect as a developer or that",
    "start": "392160",
    "end": "397639"
  },
  {
    "text": "I've grown to expect as a developer if I've come from Heroku or AWS and so the NN environment has quite",
    "start": "397639",
    "end": "405199"
  },
  {
    "text": "a few had quite a few hosting issues so I mentioned uh the developer experience",
    "start": "405199",
    "end": "410440"
  },
  {
    "text": "was really really poor the other major thing is unit cost when you when you start off down a journey for scale",
    "start": "410440",
    "end": "416360"
  },
  {
    "text": "systems you do the simplest possible thing you can in our case we just border reference architecture for Hado and that",
    "start": "416360",
    "end": "421879"
  },
  {
    "text": "was fine for 10 nodes for 20 nodes when you get up to where we are now in the the 330 node Mark and getting up to the",
    "start": "421879",
    "end": "428599"
  },
  {
    "text": "Thousand note Mark soon um the unit costs all the unit costs that you",
    "start": "428599",
    "end": "433840"
  },
  {
    "text": "accepted up front you can no longer accept because the commercials have flipped on their head they've reached this infliction point and not only that",
    "start": "433840",
    "end": "440960"
  },
  {
    "text": "but cost the change so we've lived with these systems for 12 years or four years in either case and there's a huge amount",
    "start": "440960",
    "end": "446440"
  },
  {
    "text": "of applications built on top of those things and it becomes really hard to move Ford uh underneath all of the applications and underneath all of that",
    "start": "446440",
    "end": "452759"
  },
  {
    "text": "state and so the first time you do a major platform upgrade it costs a certain amount of money the next time it's double the time after that it's",
    "start": "452759",
    "end": "458919"
  },
  {
    "text": "double and you get this nonlinear increase of cost and in each case it's quite it's not only expensive but it's",
    "start": "458919",
    "end": "464520"
  },
  {
    "text": "risky because you're doing these really large upgrade events so over and above that those",
    "start": "464520",
    "end": "470159"
  },
  {
    "text": "those are the concrete problems that we were trying to address we also had a bunch of architectural goals that we",
    "start": "470159",
    "end": "475199"
  },
  {
    "text": "wanted to try and bring into the environment so codification is kind of the primary for me absolutely everything",
    "start": "475199",
    "end": "480680"
  },
  {
    "text": "is code and the main reason for doing that is that automation then becomes inherently simple um and there's a huge",
    "start": "480680",
    "end": "487639"
  },
  {
    "text": "amount that you can go after in terms of operational cost through manual process if you just have absolutely everything",
    "start": "487639",
    "end": "493000"
  },
  {
    "text": "is code so this is firmware is code operating system is code change is code",
    "start": "493000",
    "end": "498280"
  },
  {
    "text": "absolutely everything is code continuous delivery kind of falls out of that naturally we wanted to retain State",
    "start": "498280",
    "end": "504960"
  },
  {
    "text": "locality so a lot of people when face with this problem space will go let's just grab internal cloud or a public",
    "start": "504960",
    "end": "511000"
  },
  {
    "text": "cloud and when you take a look at the kind of workload that we're dealing with these distributed systems are inherently resource aware so uh the typical",
    "start": "511000",
    "end": "518760"
  },
  {
    "text": "approach for something like Hadoop is you'll go spin up a essentially a stateless Hadoop cluster inside Amazon",
    "start": "518760",
    "end": "525040"
  },
  {
    "text": "and you'll dump all of your state into S3 and you'll nuk the cluster again and that works relatively well inside Amazon",
    "start": "525040",
    "end": "531720"
  },
  {
    "text": "for two reasons the one is that they've got a really really large and complex Network team they spent a huge amount of",
    "start": "531720",
    "end": "538839"
  },
  {
    "text": "money net uh optimizing their network but also over-provisioning their Network and so the non-locality is okay for them",
    "start": "538839",
    "end": "544959"
  },
  {
    "text": "because of the semantics of their Network and that's not true typically inside a data center the second part is",
    "start": "544959",
    "end": "550800"
  },
  {
    "text": "that you can deal with the lack of efficiency given the remote reads by simply over-provisioning right if I",
    "start": "550800",
    "end": "555839"
  },
  {
    "text": "could do something with 300 nodes I use 600 nodes and I can deal with the fact that my performance is pretty poor on a",
    "start": "555839",
    "end": "562079"
  },
  {
    "text": "node by node basis and those two things don't hold true inside a data center purely because those two things are held",
    "start": "562079",
    "end": "568200"
  },
  {
    "text": "true through economic model through aggregate economic models which a public cloud provider can maintain so we wanted",
    "start": "568200",
    "end": "575120"
  },
  {
    "text": "to retain State locality that we have a simple network but also so that our performance is good and that's just",
    "start": "575120",
    "end": "581480"
  },
  {
    "text": "purely an economic thing uh workload non-locality we want to drive out the cost of of each of our",
    "start": "581480",
    "end": "588279"
  },
  {
    "text": "servers so we don't want any particular service pinned to a server storage control TI absolutely anything I want to",
    "start": "588279",
    "end": "595120"
  },
  {
    "text": "be able to take a sledgehammer to any server inside my data center and not really worry about it",
    "start": "595120",
    "end": "600399"
  },
  {
    "text": "uh workload coverage this is just the developer experience issues and we want all of the things that you usually get",
    "start": "600399",
    "end": "606640"
  },
  {
    "text": "in a PA in terms of monitoring logging integration with the rest of the corporate environment more or less for",
    "start": "606640",
    "end": "611880"
  },
  {
    "text": "free as the developer I shouldn't have to worry about how I do certificates where I store my keys where I Source my",
    "start": "611880",
    "end": "617839"
  },
  {
    "text": "logs from how I do alerting those things should all be inherent in the contract between me and the infrastructure",
    "start": "617839",
    "end": "623959"
  },
  {
    "text": "internally so to address the question around why not public Cloud the",
    "start": "623959",
    "end": "629839"
  },
  {
    "text": "basis here is that we do use public Cloud for certain subsets of our workload for certain subsets of our",
    "start": "629839",
    "end": "635959"
  },
  {
    "text": "workload we can't use public Cloud simply because you can't get a Mainframe or certain types of Hosting inside the",
    "start": "635959",
    "end": "641320"
  },
  {
    "text": "public Cloud it's all x86 Centric and given that we have an ongoing investment",
    "start": "641320",
    "end": "647360"
  },
  {
    "text": "in our data centers and when you have a data center as a large organization you can choose to leverage that asset or you",
    "start": "647360",
    "end": "653480"
  },
  {
    "text": "can choose to ignore it it's not a choice that you have if you're in a small organization or a medium siiz and so in a small organization you're not",
    "start": "653480",
    "end": "660000"
  },
  {
    "text": "going to build a data center or go to an expensive hosting provider public cloud is the absolute default well when you've",
    "start": "660000",
    "end": "665360"
  },
  {
    "text": "got a data center the commercials don't necessarily stack up so if I purchase if",
    "start": "665360",
    "end": "670760"
  },
  {
    "text": "I've got a reasonable balance sheet and I purchase servers uh the price of doing that versus running at a high",
    "start": "670760",
    "end": "676279"
  },
  {
    "text": "utilization and ec2 over time just don't compare if I've got a stable workload and I've got a sunk cost in the data",
    "start": "676279",
    "end": "683480"
  },
  {
    "text": "center it's significantly cheaper to run my workload in my data center than in the public Cloud unless it's bursty my",
    "start": "683480",
    "end": "689519"
  },
  {
    "text": "utilization rates are extremely low so if I'm running at 20% utilization no points in buying the servers if I'm",
    "start": "689519",
    "end": "695600"
  },
  {
    "text": "running it 60% or above it it makes absolute sense to purchase service so",
    "start": "695600",
    "end": "700720"
  },
  {
    "text": "there's a commercial aspect to this that you have to be cognizant of and it's um it makes a huge difference not over days",
    "start": "700720",
    "end": "708120"
  },
  {
    "text": "or months but over years the next part to this is risk we have a a strong",
    "start": "708120",
    "end": "714720"
  },
  {
    "text": "requirement to be reliable but also we're under a highly regulated environment and the way the regulator",
    "start": "714720",
    "end": "720920"
  },
  {
    "text": "treats us is they've got this concept of risk and the way we treat ourselves internally uh too is we've got this",
    "start": "720920",
    "end": "726120"
  },
  {
    "text": "concept of risk which I identify all the things that could impact our customers or the fundamental liquidity for the",
    "start": "726120",
    "end": "732320"
  },
  {
    "text": "country and we try identify each of those things and put controls around them they could be automatic controls",
    "start": "732320",
    "end": "737360"
  },
  {
    "text": "manual controls Etc and the process of lift of moving some of our workload into",
    "start": "737360",
    "end": "743560"
  },
  {
    "text": "the public cloud is actually quite risky having our own data centers takes a huge amount of risk out because there's erent",
    "start": "743560",
    "end": "749440"
  },
  {
    "text": "portion of physical security that you lose in a shared hosting environment and as a result you've got to address those",
    "start": "749440",
    "end": "754519"
  },
  {
    "text": "potential risks in different ways and that has a real concrete cost opportunity cost and direct",
    "start": "754519",
    "end": "759920"
  },
  {
    "text": "cost the next one is when you think about public Cloud if you just use ec2",
    "start": "759920",
    "end": "765160"
  },
  {
    "text": "infrastructure as a service you lose a fair portion of the value proposition there's a huge amount that the public Cloud providers are doing in terms of",
    "start": "765160",
    "end": "771800"
  },
  {
    "text": "other types of services on top of the base infrastructure as a service so think Dynamo and other things and those",
    "start": "771800",
    "end": "778040"
  },
  {
    "text": "are uh um they take a fair amount of operational complexity away from you but they also bring a bunch of coupling with",
    "start": "778040",
    "end": "784440"
  },
  {
    "text": "it uh it kind of gets into that space of um what what is a public Cloud if you",
    "start": "784440",
    "end": "789920"
  },
  {
    "text": "were a youngster and you ask I've seen this cartoon of a youngster asking his dad what's the cloud and his dad's",
    "start": "789920",
    "end": "795720"
  },
  {
    "text": "response is we used to pay IBM now we pay Amazon and there's this there's this",
    "start": "795720",
    "end": "801199"
  },
  {
    "text": "real uh trade-off that you have to make with open eyes around how coupled you get to certain providers because",
    "start": "801199",
    "end": "807600"
  },
  {
    "text": "typically inside a large organization once you coupled you're not you're not getting off those things even if you had the will and the funding it takes a",
    "start": "807600",
    "end": "814440"
  },
  {
    "text": "really long time to do it and so any coupling decision you're making You' you've got to really take account of of",
    "start": "814440",
    "end": "820639"
  },
  {
    "text": "that decision the other one that people kind of miss a lot about public cloud is that it actually introduces quite a lot of",
    "start": "820639",
    "end": "826519"
  },
  {
    "text": "complexity especially if already if you've already got a data center every data center that you add into your",
    "start": "826519",
    "end": "831959"
  },
  {
    "text": "operational uh environment is actually it adds a huge amount of complexity if I want to do Disaster Recovery testing and",
    "start": "831959",
    "end": "838279"
  },
  {
    "text": "I have to uh if I'm testing across two data centers it's fairly complex if I'm testing across three data centers it's",
    "start": "838279",
    "end": "845279"
  },
  {
    "text": "far more complex what happens when this data center fails not those two or these two and not that one or this one and not",
    "start": "845279",
    "end": "851480"
  },
  {
    "text": "those two and those basic scenarios add a huge amount of complexity to your delivery process and your operational",
    "start": "851480",
    "end": "859360"
  },
  {
    "text": "processes finally moving from one hosting environment to another just introduces a huge amount of opportunity",
    "start": "859360",
    "end": "865480"
  },
  {
    "text": "costs and so as a result of those basic uh um problems spases or basic",
    "start": "865480",
    "end": "871079"
  },
  {
    "text": "constraints for us we can't necessarily use public Cloud wholeheartedly there's portions of our workload that we do and",
    "start": "871079",
    "end": "876120"
  },
  {
    "text": "portions of our workload that for some time will stay with us and as a result",
    "start": "876120",
    "end": "881279"
  },
  {
    "text": "we can't just accept a PO hosting environment internally we have to stare into and solve this problem otherwise",
    "start": "881279",
    "end": "887160"
  },
  {
    "text": "our costs are getting too high at at the wrong rate and our developer experience is getting",
    "start": "887160",
    "end": "892240"
  },
  {
    "text": "horrible so we stayed into this problem and we decided we were going to uh adopt a couple of principles the first one is",
    "start": "892240",
    "end": "899079"
  },
  {
    "text": "we wanted to use open source top to bottom we wanted to drive out license as far as possible we wanted to go for",
    "start": "899079",
    "end": "905160"
  },
  {
    "text": "effectively entirely commodity Hardware so uh the way we're going to we're doing",
    "start": "905160",
    "end": "910279"
  },
  {
    "text": "that is to uh make sure that we're not stuck on a single Hardware provider so we purchase from three or four even",
    "start": "910279",
    "end": "915440"
  },
  {
    "text": "though it's the same effectively the same hardware and they're sitting next to each other in the same racks um and we wanted to add continuous",
    "start": "915440",
    "end": "923079"
  },
  {
    "text": "delivery top to bottom so the stack we have is open stack which gives us an effectively API addressable servers so",
    "start": "923079",
    "end": "929920"
  },
  {
    "text": "we're not spinning up virtual machines but we're making API calls to effectively reprovision servers so we're",
    "start": "929920",
    "end": "935560"
  },
  {
    "text": "treating our internal metal in the same way as we treat an internal Cloud on top of that effectively all of our hosting",
    "start": "935560",
    "end": "941560"
  },
  {
    "text": "is docco based and we use Calico for lib network and on top of that our base",
    "start": "941560",
    "end": "946720"
  },
  {
    "text": "resource scheduling is done with misos and our p is enabled through Marathon so",
    "start": "946720",
    "end": "952079"
  },
  {
    "text": "Marathon plus doco plus Calico give you this fairly nice combination of um a",
    "start": "952079",
    "end": "957759"
  },
  {
    "text": "nice way to host immutable workload but also it brings a lot of nice attributes along from a networking point of view so",
    "start": "957759",
    "end": "964000"
  },
  {
    "text": "service Discovery comes out of the box if I launch some workload through Marathon uh Marathon DNS deals with the",
    "start": "964000",
    "end": "969800"
  },
  {
    "text": "dynamic delegation of the of the DNS request and you effectively get service Discovery out of the box um your Docker",
    "start": "969800",
    "end": "977360"
  },
  {
    "text": "containers all get their own IP address their own DNS entry so it has this really nice set of a nice combination of",
    "start": "977360",
    "end": "983199"
  },
  {
    "text": "attributes and each of those elements of that stack is not opinionated and is quite simple and is readily customized",
    "start": "983199",
    "end": "989079"
  },
  {
    "text": "able and we quite liked choosing things that weren't highly opinionated up front because our workload is not necessarily",
    "start": "989079",
    "end": "996839"
  },
  {
    "text": "stereotypical so on top of that we've integrated yan yan is the resource scheduler for Hadoop uh so we've got a",
    "start": "996839",
    "end": "1002240"
  },
  {
    "text": "resource schedul sitting on top of a resource scheduler it sounds slightly wasteful but in inband of the actual",
    "start": "1002240",
    "end": "1008720"
  },
  {
    "text": "workload the resource schedulers don't do anything they're out of band they only have any real impact on your workload at schedule time that they're",
    "start": "1008720",
    "end": "1016040"
  },
  {
    "text": "not involved in Band of your workload so it doesn't actually represent concrete overhead secondly we need to be able to",
    "start": "1016040",
    "end": "1021480"
  },
  {
    "text": "do a kind of course gra and fine gra scheduling and those two together give us that and then on top we host all of",
    "start": "1021480",
    "end": "1028880"
  },
  {
    "text": "the stereotypical hop workload and or Docker containers just running directly inside the misau marathon",
    "start": "1028880",
    "end": "1035720"
  },
  {
    "text": "environment the other major thing to call out about this architecture diagram is that absolutely everything is continuous delivery so if I want to do a",
    "start": "1035720",
    "end": "1042918"
  },
  {
    "text": "firmware upgrade it's a pull request if I want to change a folder permission on a host it's a pull request uh",
    "start": "1042919",
    "end": "1049400"
  },
  {
    "text": "if I uh if I want to uh deploy a new package or upgrade a package it's a pull",
    "start": "1049400",
    "end": "1055120"
  },
  {
    "text": "request there is no SSH into the hosts and in fact each of the hosts operating systems are running on a readon file",
    "start": "1055120",
    "end": "1062160"
  },
  {
    "text": "system so we've pushed the notion of codification continuous delivery and immutable as far as we possibly can in",
    "start": "1062160",
    "end": "1068840"
  },
  {
    "text": "this environment uh so I think I've covered all of those the only other things that",
    "start": "1068840",
    "end": "1074960"
  },
  {
    "text": "are worth pointing out uh elastic search and CES dig is our story story for log",
    "start": "1074960",
    "end": "1080360"
  },
  {
    "text": "and for monitoring and alerting soig is a fairly nice open source product plugs into the Linux kernel gives you some",
    "start": "1080360",
    "end": "1086360"
  },
  {
    "text": "fairly good visibility into what's going on inside your containers and the other thing that's worth calling out is Vault",
    "start": "1086360",
    "end": "1091960"
  },
  {
    "text": "Hashi cor Vault and this we use for as as a certificate Authority but also as a",
    "start": "1091960",
    "end": "1097120"
  },
  {
    "text": "key management solution and it's act it's got a really nice API well a pretty reasonable API and is therefore quite",
    "start": "1097120",
    "end": "1103720"
  },
  {
    "text": "easy to integrate into the continuous delivery process which gives us a bunch of nice attributes like if we wanted do",
    "start": "1103720",
    "end": "1108960"
  },
  {
    "text": "workload to workload Mutual authentic authentication you can inject uh certificates into that workload at",
    "start": "1108960",
    "end": "1114799"
  },
  {
    "text": "launch time and your certificate life cycle management is simply unque the workload this gives you a nice",
    "start": "1114799",
    "end": "1121520"
  },
  {
    "text": "certificate life cycle management story but it also gives you a nice operational story which is you don't want workload",
    "start": "1121520",
    "end": "1127320"
  },
  {
    "text": "to exist for any lengthy period of time because then it becomes a pet so our Docker containers as soon as they've lived for a week they get nuked and",
    "start": "1127320",
    "end": "1135320"
  },
  {
    "text": "redeployed and naturally get a new certificate so it's got a fairly has got a fairly nice story both from an",
    "start": "1135320",
    "end": "1140520"
  },
  {
    "text": "operational point of view but also from a security point of view so I mentioned that we do physicals and not VMS and the",
    "start": "1140520",
    "end": "1147000"
  },
  {
    "text": "reason for that is a few fold the first one is that these distributed systems a VM is quite an uncomfortable abstraction",
    "start": "1147000",
    "end": "1153440"
  },
  {
    "text": "it takes you quite far from the dis and it assumes non-local dis which has quite an impact on your iops uh the second one",
    "start": "1153440",
    "end": "1160159"
  },
  {
    "text": "is that when you want to do truly immutable things a VM is a really large abstraction right if I have to bake an",
    "start": "1160159",
    "end": "1165400"
  },
  {
    "text": "entirely immutable Ami or VM of some kind I'm talking talking about hundreds of Megs to gigs of image that I have to",
    "start": "1165400",
    "end": "1172240"
  },
  {
    "text": "now roll out across an increasingly large cluster and so that brings in a whole lot of image distribution problems",
    "start": "1172240",
    "end": "1177960"
  },
  {
    "text": "but also it's just fundamentally wasteful and you're not really getting anything for it uh especially given the",
    "start": "1177960",
    "end": "1183159"
  },
  {
    "text": "style of workload that we're after so we really wanted to have physicals and Docker as opposed to physicals VMS and",
    "start": "1183159",
    "end": "1189960"
  },
  {
    "text": "Docker we wanted to remove this middle portion of the abstraction and the downside would have been that we were",
    "start": "1189960",
    "end": "1196320"
  },
  {
    "text": "stuck with a non-api addressable layer some where and so we went with open stack ironic to solve that problem what",
    "start": "1196320",
    "end": "1203200"
  },
  {
    "text": "ironic does is it gives you a Nova API which looks pretty similar to ec2 but under the covers all it's doing is",
    "start": "1203200",
    "end": "1208520"
  },
  {
    "text": "wrapping up a bunch of automation around ipmi and pixie boot ipmi is the outof band management controller standard for",
    "start": "1208520",
    "end": "1215640"
  },
  {
    "text": "servers it's very old uh can't remember what year it's 15 odd years old now uh",
    "start": "1215640",
    "end": "1221520"
  },
  {
    "text": "it's a very open protocol not secure so you have to do a bunch of things on the networking side to segregate it but",
    "start": "1221520",
    "end": "1228200"
  },
  {
    "text": "effectively I can go to a server and ask it to reboot in a network boot mode or in local boot mode and I can get out of",
    "start": "1228200",
    "end": "1234440"
  },
  {
    "text": "band uh management details from the server from the board management controller so the the underlying process",
    "start": "1234440",
    "end": "1241280"
  },
  {
    "text": "for rebooting a server and making it feel like a VM is you go to you make an ipmi call and you say please reboot in",
    "start": "1241280",
    "end": "1246840"
  },
  {
    "text": "pixie mode the server comes up goes and grabs a temporary image through tftp and",
    "start": "1246840",
    "end": "1252360"
  },
  {
    "text": "it it discovers where that image is through proxy DHCP calls uh broadcasts",
    "start": "1252360",
    "end": "1257760"
  },
  {
    "text": "it goes and downloads an interim image which goes and fetches the Ultimate Image in DS it onto the local dis and",
    "start": "1257760",
    "end": "1263840"
  },
  {
    "text": "then it reboots in local mode and so you've got a bunch of reboots in there you've got a bit of network traffic but",
    "start": "1263840",
    "end": "1269159"
  },
  {
    "text": "effectively the machine is rebooted a few times and has come up with a new operating system you've effectively",
    "start": "1269159",
    "end": "1275240"
  },
  {
    "text": "treated the physical server in the same way as you're treating a VM it's entirely",
    "start": "1275240",
    "end": "1280919"
  },
  {
    "text": "immutable of course the next thing you're going to say to me is that's great but what about the storage like",
    "start": "1280919",
    "end": "1286480"
  },
  {
    "text": "are the servers entirely immutable or is there some persistence storage somewhere so the way we deal with this is our",
    "start": "1286480",
    "end": "1292679"
  },
  {
    "text": "Hardware profiles are uh kind of array one primary set of ssds for the",
    "start": "1292679",
    "end": "1298159"
  },
  {
    "text": "operating system itself and this is the portion of the uh server that we treat in an entirely immutable manner but then",
    "start": "1298159",
    "end": "1304600"
  },
  {
    "text": "there's a bunch of discs that actually host all of our stateful services so the the bulk of the servers are kind of",
    "start": "1304600",
    "end": "1310200"
  },
  {
    "text": "running either 10 or 14 uh three 3 and 1 half in discs either SSD or spinning",
    "start": "1310200",
    "end": "1316840"
  },
  {
    "text": "rust and somewhere between three 8 terab per drive and every time we roll out a",
    "start": "1316840",
    "end": "1322679"
  },
  {
    "text": "new image onto one of these boxes we only touch the primary partitions and we leave the state on those uh state for",
    "start": "1322679",
    "end": "1328840"
  },
  {
    "text": "portions of the of the device alone so there's some portion of the box that's entirely IM mutable and another portion",
    "start": "1328840",
    "end": "1334400"
  },
  {
    "text": "of the box that's actually hosting State the other major reason for doing this is if you think",
    "start": "1334400",
    "end": "1340880"
  },
  {
    "text": "about um separating out the computer and storage I've spoken about from from an",
    "start": "1340880",
    "end": "1347120"
  },
  {
    "text": "Ado point of view but even in a cloud situation if I've got an object store somewhere that object store has to be",
    "start": "1347120",
    "end": "1352720"
  },
  {
    "text": "hosted and so your fundamental thing of block storage or object storage or",
    "start": "1352720",
    "end": "1358000"
  },
  {
    "text": "database at some point is just the process running on in inside a box talking to a bunch of spindles or ssds",
    "start": "1358000",
    "end": "1365679"
  },
  {
    "text": "and our fundamental element is servers not necessarily these high level services but uh even when we do use",
    "start": "1365679",
    "end": "1372760"
  },
  {
    "text": "those high level Services we're just hosting them on our servers and so we have to we want to try and Achieve immutability top the bottom but we also",
    "start": "1372760",
    "end": "1379480"
  },
  {
    "text": "have to host these stateful workloads that typically people would just rely on we have to host",
    "start": "1379480",
    "end": "1385480"
  },
  {
    "text": "them from a networking point of view we were the intent was to try and keep the",
    "start": "1385480",
    "end": "1391520"
  },
  {
    "text": "environment as simple as possible from a networking point of view so we don't have a large networking team I've got",
    "start": "1391520",
    "end": "1396720"
  },
  {
    "text": "three Engineers who look after the network um the and our scale is growing",
    "start": "1396720",
    "end": "1402720"
  },
  {
    "text": "at a rate that we can't necessarily predict so I said 60% year on year but we don't have the ability either the",
    "start": "1402720",
    "end": "1409159"
  },
  {
    "text": "skills the ability or the funding to go off and simulate when we're going to start running into Network infliction problems and so we're trying to keep our",
    "start": "1409159",
    "end": "1416400"
  },
  {
    "text": "Network as simple as possible so that as we scale it's the least likely problem that we have the other thing that we try",
    "start": "1416400",
    "end": "1424320"
  },
  {
    "text": "to do is when when you're dealing with either VMS or Docker networks uh Docker networking you can choose to use overlay",
    "start": "1424320",
    "end": "1430600"
  },
  {
    "text": "networking or you can choose to just do service Discovery with Port mapping Port mapping is very uncomfortable with",
    "start": "1430600",
    "end": "1436440"
  },
  {
    "text": "workloads unless you're building all your workloads yourself so you probably have to at some point start to lean on",
    "start": "1436440",
    "end": "1442720"
  },
  {
    "text": "uh container based networking and that brings a overlay Network along with you and we were quite uncomfortable with",
    "start": "1442720",
    "end": "1448679"
  },
  {
    "text": "introducing the overlay Network so we chose Calico specifically so that we landed up with a traditional layer 3",
    "start": "1448679",
    "end": "1454279"
  },
  {
    "text": "Network and what Calico does is it essentially gives you a software defined router on each of the hosts it",
    "start": "1454279",
    "end": "1459559"
  },
  {
    "text": "integrates nicely with misos and marathon and what's going out onto the physical wire is a traditional layer",
    "start": "1459559",
    "end": "1465679"
  },
  {
    "text": "three packet there's no layer four Layer Two layer for encapsulation going on whatsoever all it's doing is Route",
    "start": "1465679",
    "end": "1472080"
  },
  {
    "text": "distribution IP table configurations and as the packets go out over the wire it's",
    "start": "1472080",
    "end": "1477240"
  },
  {
    "text": "using an internal router effectively snet per host um this integrates nicely with the",
    "start": "1477240",
    "end": "1483640"
  },
  {
    "text": "net rest of your networking uh infrastructure because it's just doing bgp route propagation so your existing",
    "start": "1483640",
    "end": "1490039"
  },
  {
    "text": "switches work nicely your existing monitoring tools work nicely Etc and you know it scales because of s traditional",
    "start": "1490039",
    "end": "1496799"
  },
  {
    "text": "uh IP networking the config there is ETC driven and all",
    "start": "1496799",
    "end": "1501960"
  },
  {
    "text": "of our etcd config is just sitting in gets and as part of the continuous delivery process so security profiles uh",
    "start": "1501960",
    "end": "1508760"
  },
  {
    "text": "Docker networks Etc they're all just declarative aspects inside source control and I'll talk about the workflow",
    "start": "1508760",
    "end": "1514240"
  },
  {
    "text": "there a little bit later so this is introduces a couple of interesting problems though when uh the",
    "start": "1514240",
    "end": "1521039"
  },
  {
    "text": "first one is how do you migrate right so we've got a couple hundred servers they're sitting there running Linx and",
    "start": "1521039",
    "end": "1526520"
  },
  {
    "text": "Hadoop and effectively we're going to replace red hat with auntu open stack",
    "start": "1526520",
    "end": "1532880"
  },
  {
    "text": "Docker Calico and a bunch of other stuff and we're doing it to the cluster that we're busy hosting in production we're",
    "start": "1532880",
    "end": "1538760"
  },
  {
    "text": "going to make this change in production we're effectively ripping out the engines and replacing the midf flight",
    "start": "1538760",
    "end": "1543840"
  },
  {
    "text": "and so there's a lot of ways that you can reduce the risk one of them is fundamentally having network separation and so you can take on one node using",
    "start": "1543840",
    "end": "1551159"
  },
  {
    "text": "the new software stack then another one and slowly accept more risk of course there has to be some level of isolation",
    "start": "1551159",
    "end": "1557880"
  },
  {
    "text": "as you do this roll out the way we chose to implement that was vrfs and vrfs with",
    "start": "1557880",
    "end": "1563399"
  },
  {
    "text": "r very explicit sets of rout leakage so instead of having very very strong segregation at layer 2 we introduced a",
    "start": "1563399",
    "end": "1570159"
  },
  {
    "text": "certain amount of R leakage and we could control that quite uh quite carefully to say these are the routes that we're",
    "start": "1570159",
    "end": "1575799"
  },
  {
    "text": "going to prepare to see rout leakage through and that allowed us to have the two clusters interact with each other",
    "start": "1575799",
    "end": "1581520"
  },
  {
    "text": "but also have a certain level of isolation that we are comfortable with um we do VLAN separation at the",
    "start": "1581520",
    "end": "1588520"
  },
  {
    "text": "ipmi level so we don't do physical separation of the network it's all logical writing um and we use Tag VLAN",
    "start": "1588520",
    "end": "1595440"
  },
  {
    "text": "so that we don't have to have any nodes that are specially management nodes if you think about a normal open stack",
    "start": "1595440",
    "end": "1600640"
  },
  {
    "text": "implementation your uh Network control nodes typically have three Nicks so they can exist on the data Lan and also on",
    "start": "1600640",
    "end": "1608080"
  },
  {
    "text": "the ipmi Lan as a physically separate thing we didn't want to do that otherwise we've got some special nodes within our Fleet and then we don't have",
    "start": "1608080",
    "end": "1614880"
  },
  {
    "text": "workload non locality so we used uh V tagging in order to achieve that and so",
    "start": "1614880",
    "end": "1620520"
  },
  {
    "text": "given VLAN tagging we can move a box just for switch configuration uh into and out of the management Network and",
    "start": "1620520",
    "end": "1626799"
  },
  {
    "text": "it's purely a logical construct so the workflow for this I",
    "start": "1626799",
    "end": "1632240"
  },
  {
    "text": "said that everything is a pull request and we we did that very explicitly if you think about um organizations like",
    "start": "1632240",
    "end": "1638480"
  },
  {
    "text": "GitHub they talk about chat Ops and the reason chat Ops works well from from the outside my perspective on why chat Ops",
    "start": "1638480",
    "end": "1644960"
  },
  {
    "text": "Works in an organization like that is that they've got a very constraint set of use cases and it's because they're a",
    "start": "1644960",
    "end": "1650559"
  },
  {
    "text": "fundamentally distributed team everyone is there in the chat room and so you've got all this context and all the",
    "start": "1650559",
    "end": "1655760"
  },
  {
    "text": "deployments are done from there all of the Ops is done within that chat environment we don't have the same",
    "start": "1655760",
    "end": "1661159"
  },
  {
    "text": "luxury in that our use cases are significantly broader but also we've got lots of other teams that interact with",
    "start": "1661159",
    "end": "1666360"
  },
  {
    "text": "us and they all don't use chat so for us we have to drive collaboration but we",
    "start": "1666360",
    "end": "1671960"
  },
  {
    "text": "have to do it in a way that fits into devops automation codification Etc and the P the pull request is an ideal way",
    "start": "1671960",
    "end": "1677600"
  },
  {
    "text": "to do this so it it gives us a centralized collaboration Point everything is a pull",
    "start": "1677600",
    "end": "1683559"
  },
  {
    "text": "request and developers are fairly comfortable with this I can take anyone who's written open source off the street and say the way you deploy something is",
    "start": "1683559",
    "end": "1689679"
  },
  {
    "text": "a pull request it'll feel uncomfortable for about half an hour and then it will feel natural to them uh it's automation",
    "start": "1689679",
    "end": "1695039"
  },
  {
    "text": "friendly and also it fundamentally gives us reproducibility because we drive everything as being declarative it's",
    "start": "1695039",
    "end": "1700799"
  },
  {
    "text": "very easy for me to recreate an environment my Dev environment is sitting on my production infrastructure",
    "start": "1700799",
    "end": "1706559"
  },
  {
    "text": "and I can issue a pull request and exactly recreate some version of Dev or some version of prod on any portion of",
    "start": "1706559",
    "end": "1712240"
  },
  {
    "text": "my infrastructure given any history of time so the way we allow out the repos",
    "start": "1712240",
    "end": "1718039"
  },
  {
    "text": "to do this is it's very much microservice Centric so everything has a separate repo so if I've got a bunch of",
    "start": "1718039",
    "end": "1724279"
  },
  {
    "text": "containers with some workload a dashboard or a yarn container whatever",
    "start": "1724279",
    "end": "1729840"
  },
  {
    "text": "it is it has its own repo even operating system images have their own repos um",
    "start": "1729840",
    "end": "1735320"
  },
  {
    "text": "and these things go through a bull test deployment process and land up with images being stored inside Auto Factory we've also then got",
    "start": "1735320",
    "end": "1742720"
  },
  {
    "text": "repos that have the environment config in them but it's declarative environment config and so at the point that I want",
    "start": "1742720",
    "end": "1748399"
  },
  {
    "text": "to deploy something I'm effectively going from one version of Dev one version of prod to another in a",
    "start": "1748399",
    "end": "1753799"
  },
  {
    "text": "declarative form so think of cloud formation templates very much in that Spirit except we use we've written our",
    "start": "1753799",
    "end": "1759679"
  },
  {
    "text": "own DSL for it and so by issuing a poll request the CI environment uh",
    "start": "1759679",
    "end": "1765720"
  },
  {
    "text": "effectively can look at what is the pre version the Clara version of the environment what's the next version what",
    "start": "1765720",
    "end": "1771159"
  },
  {
    "text": "are the differences and therefore what changes do I need to apply to the environment on your behalf and as a",
    "start": "1771159",
    "end": "1776519"
  },
  {
    "text": "result of that no one has to touch a server ever for any reason obviously there's debugging but you don't need",
    "start": "1776519",
    "end": "1781840"
  },
  {
    "text": "pseudo rights for debugging It generally you don't need to log into a server for debugging so what does that look like",
    "start": "1781840",
    "end": "1787360"
  },
  {
    "text": "from a Version Control perspective Master represents the environment so if you think about that repo which is a",
    "start": "1787360",
    "end": "1793000"
  },
  {
    "text": "declarative form of the environment Master represents what's running right now if I want to make a change I branch",
    "start": "1793000",
    "end": "1800399"
  },
  {
    "text": "that I make my changes and then I issue a pull request onto deploy which is just a another designated uh branch that we",
    "start": "1800399",
    "end": "1808039"
  },
  {
    "text": "run and at that point the Jenkins or drone we run both at the moment will do a build process and generate a change",
    "start": "1808039",
    "end": "1815120"
  },
  {
    "text": "plan and attach that to the pull request and I'll show you how that looks now and if I'm comfortable and everyone approves",
    "start": "1815120",
    "end": "1821120"
  },
  {
    "text": "the pull request when it merges Jenkins goes off and actually applies that set of changes to the environment once the",
    "start": "1821120",
    "end": "1827480"
  },
  {
    "text": "changes of succeeded the smoke tests have succeeded then it goes and merges those changes onto master and so what's",
    "start": "1827480",
    "end": "1833640"
  },
  {
    "text": "on Master is guarant be guaranteed to be what's in the environment no one has the right to push onto Master except for the",
    "start": "1833640",
    "end": "1840000"
  },
  {
    "text": "CI service account so this gives you a really nice situation where what if I",
    "start": "1840000",
    "end": "1845559"
  },
  {
    "text": "want to know what's running inside the environment right now I just go to Source control and have a look if the deployment fails for some reason which",
    "start": "1845559",
    "end": "1851600"
  },
  {
    "text": "is increasingly unlikely over time I can just look at what's in deployer versus what's in master versus what's in the",
    "start": "1851600",
    "end": "1857320"
  },
  {
    "text": "deployment law and I've got a good idea of what my state is currently and I can always roll back to the previous",
    "start": "1857320",
    "end": "1863679"
  },
  {
    "text": "state so let me color this a little bit because all of that sounds a little bit abstract so let's get specific this is a",
    "start": "1863679",
    "end": "1870320"
  },
  {
    "text": "host operating system this is the definition of a host operating system we don't go to a box uh install an ISO",
    "start": "1870320",
    "end": "1878120"
  },
  {
    "text": "image configure it a little bit and then create an outer band snapshot we literally build a Docker image which",
    "start": "1878120",
    "end": "1883200"
  },
  {
    "text": "represents our host using standard Docker tooling and then we following a build process process we convert that",
    "start": "1883200",
    "end": "1888880"
  },
  {
    "text": "into a host image which is then which we can then DD onto disk using ironic so",
    "start": "1888880",
    "end": "1894840"
  },
  {
    "text": "absolutely everything even the source even the host operating system is just a",
    "start": "1894840",
    "end": "1899919"
  },
  {
    "text": "file sitting in Source control and using very familiar tooling of Docker so",
    "start": "1899919",
    "end": "1905360"
  },
  {
    "text": "you'll see here we're just extending from our base image we're setting up a bunch of repos uh and then we're",
    "start": "1905360",
    "end": "1911760"
  },
  {
    "text": "installing a bunch of packages very familiar you do the same thing in Docker except now you're doing it for the",
    "start": "1911760",
    "end": "1917240"
  },
  {
    "text": "underlying post operating system why don't we use things like puppet and Chef and salt stack Etc uh",
    "start": "1917240",
    "end": "1924760"
  },
  {
    "text": "all of those Stacks fundamentally assume all of those tools fundamentally assume mutation of the server and we very",
    "start": "1924760",
    "end": "1931240"
  },
  {
    "text": "explicitly don't want to M mutate anything uh so the reason for not using",
    "start": "1931240",
    "end": "1936279"
  },
  {
    "text": "those tools is that we don't want to accept mutation I don't want anable to SSH into the box and go and mutate",
    "start": "1936279",
    "end": "1942159"
  },
  {
    "text": "something for me even if it's in a semi- disciplined manner I only want to the only time a a host can change is if I do",
    "start": "1942159",
    "end": "1949159"
  },
  {
    "text": "a buard process and then I overwrite the previous image so it's actually mutable top to bottom so how does the testing process",
    "start": "1949159",
    "end": "1956159"
  },
  {
    "text": "look effectively for a host we do the docker build we do some level of uh",
    "start": "1956159",
    "end": "1961320"
  },
  {
    "text": "image verification we just use server specs here so it's like unit testing for the for the OS uh we run it through dib",
    "start": "1961320",
    "end": "1968960"
  },
  {
    "text": "which produces a c Car 2 image uh we stand up a a virtualized cluster",
    "start": "1968960",
    "end": "1974279"
  },
  {
    "text": "environment with virtualized networking we run functional tests and if all of those things pass then we land up with a",
    "start": "1974279",
    "end": "1980159"
  },
  {
    "text": "host image inside artifactory from there we roll it through the dev environment Etc before it lands up in production so",
    "start": "1980159",
    "end": "1986679"
  },
  {
    "text": "standard pipeline continuous delivery approach this is an example of uh just",
    "start": "1986679",
    "end": "1992720"
  },
  {
    "text": "ver verifying that appropriate versions of packages have been installed and you'll note strong versioning on all",
    "start": "1992720",
    "end": "1997840"
  },
  {
    "text": "packages there's no just app get update everything is a specific version of a package in order to drive absolute",
    "start": "1997840",
    "end": "2004240"
  },
  {
    "text": "reproducibility there's no snapshots flying around the environment and this is an example of a functional",
    "start": "2004240",
    "end": "2009760"
  },
  {
    "text": "test really really simple generate some random value stick them into the Zookeeper Quorum nuer portion of the",
    "start": "2009760",
    "end": "2015200"
  },
  {
    "text": "Quorum and make sure the that the Quorum re uh reestablishes itself and chooses a",
    "start": "2015200",
    "end": "2020480"
  },
  {
    "text": "master so we can do fairly uh fairly good functional testing as part of the",
    "start": "2020480",
    "end": "2025679"
  },
  {
    "text": "build process but then also part of the uh actual pipeline testing processes so our source control we use",
    "start": "2025679",
    "end": "2033399"
  },
  {
    "text": "GitHub Enterprise internally uh amusingly the way we host GitHub Enterprise is it's a do container hosting KVM which runs GitHub Enterprise",
    "start": "2033399",
    "end": "2041240"
  },
  {
    "text": "so misos we go to Marathon and we ask it to run a DOA container which is hosting KVM which is hosting GitHub Enterprise",
    "start": "2041240",
    "end": "2048638"
  },
  {
    "text": "uh and so we use GitHub Enterprise to make the changes to the hosting environment which hosts GitHub",
    "start": "2048639",
    "end": "2053800"
  },
  {
    "text": "Enterprise Turtles all the way down uh this gives you an example of what a pull",
    "start": "2053800",
    "end": "2059200"
  },
  {
    "text": "request would look like and so you'll see you've got your standard uh commit you can look at your files changed what",
    "start": "2059200",
    "end": "2065720"
  },
  {
    "text": "what from the diff from one version to another but you'll also see a build plan summary so in this case drone has taken",
    "start": "2065720",
    "end": "2071200"
  },
  {
    "text": "a look at that pull request it's done some background build processes and it's said you wanted to change the cluster in",
    "start": "2071200",
    "end": "2076240"
  },
  {
    "text": "this form and so I'm going to tell you what the changes look like uh so it it says you're adding you're deleting Etc",
    "start": "2076240",
    "end": "2082720"
  },
  {
    "text": "that basic level but it also derives a change plan for us so in this example uh",
    "start": "2082720",
    "end": "2087919"
  },
  {
    "text": "it's about removing images removing previous servers uploading new images into glass and rolling out new images",
    "start": "2087919",
    "end": "2094800"
  },
  {
    "text": "underneath the cluster so this has gone and taken look at the two declarative versions of my environment derive the",
    "start": "2094800",
    "end": "2100599"
  },
  {
    "text": "change plan for me similar in concept to something like terraform except it's integrated into all the standard tooling",
    "start": "2100599",
    "end": "2107160"
  },
  {
    "text": "and it's fundamentally not mutable anywhere and it's derived a set a execution plan for me and this execution",
    "start": "2107160",
    "end": "2114560"
  },
  {
    "text": "plan is entirely cluster aware so if I need to roll out changes underneath a stateful service like hdfs or Swift this",
    "start": "2114560",
    "end": "2121839"
  },
  {
    "text": "is aware that there stateful workload running on top and isn't is going to avoid obvious operational failure cases",
    "start": "2121839",
    "end": "2128000"
  },
  {
    "text": "like it's not going to take out two hdfs nodes that have the same partition with the the same block Shard on",
    "start": "2128000",
    "end": "2134440"
  },
  {
    "text": "them so the way we do that is we make uh our tooling cluster",
    "start": "2134440",
    "end": "2139599"
  },
  {
    "text": "aware um the we've got basic concept of uh Masters and agents uh this is the not",
    "start": "2139599",
    "end": "2147440"
  },
  {
    "text": "a misource master and a misource agent and in order for us to create a misource agent we b a new operating system image",
    "start": "2147440",
    "end": "2153000"
  },
  {
    "text": "which defaults the start misos master and we just talk ironic and roll it out and it forms a part of the Quorum for us",
    "start": "2153000",
    "end": "2159040"
  },
  {
    "text": "if we want to add a new worker we just build a a agent image which has got a misau slave uh starting up and it'll",
    "start": "2159040",
    "end": "2168480"
  },
  {
    "text": "discover the misos master and add itself to the cluster so there's no overall orchestration you you effectively just",
    "start": "2168480",
    "end": "2174880"
  },
  {
    "text": "bake images and roll them out and they form quorums quite comfortably so this gives you a flavor of some of the",
    "start": "2174880",
    "end": "2181119"
  },
  {
    "text": "metadata that we capture around the Clusters and because we've got uh the concept of a cluster we can start to",
    "start": "2181119",
    "end": "2187640"
  },
  {
    "text": "build the Automation in a way that it avoids obvious operational failure cases for clusters so stateful things like I",
    "start": "2187640",
    "end": "2193359"
  },
  {
    "text": "say hdfs and other things but also work uh other more custom workload like load balances Etc we can roll out changes",
    "start": "2193359",
    "end": "2200880"
  },
  {
    "text": "underneath those workloads in a way that avoids basic failure cases so this is just a video which uh",
    "start": "2200880",
    "end": "2208119"
  },
  {
    "text": "shows you more or less what that workflow looks like so this is just a emx environment so simple test here or",
    "start": "2208119",
    "end": "2215000"
  },
  {
    "text": "simple example here I'm just going to update the image uh so go from one image version to another do a",
    "start": "2215000",
    "end": "2222240"
  },
  {
    "text": "commit um push that to get then raise a pull request and you",
    "start": "2222240",
    "end": "2230280"
  },
  {
    "text": "can see the diff there so it's showing you've gone from one version of the image to another and if you go back to the pull",
    "start": "2230280",
    "end": "2236880"
  },
  {
    "text": "request conversation you can see what are the proposed changes to the cluster so it's doing kind of a diff at a",
    "start": "2236880",
    "end": "2242640"
  },
  {
    "text": "cluster level as opposed to at a file level and then once you scroll a little bit further down in the pull request",
    "start": "2242640",
    "end": "2248720"
  },
  {
    "text": "you'll see the proposed build plan for the cluster and we have the same oper the same workflow for firmware for",
    "start": "2248720",
    "end": "2256119"
  },
  {
    "text": "operating system for doer images for deploying apps for mutating the cloud",
    "start": "2256119",
    "end": "2261280"
  },
  {
    "text": "data cluster absolutely everything is simply a declarative form in Source control uh and then the build automation",
    "start": "2261280",
    "end": "2267640"
  },
  {
    "text": "is integrated into GitHub Enterprise so that workflow is pervasive up and down",
    "start": "2267640",
    "end": "2273319"
  },
  {
    "text": "the stack and as a result automating anything is is exceptionally trivial increasingly trivial even things like",
    "start": "2273319",
    "end": "2280359"
  },
  {
    "text": "Ser uh capacity management is just part of the pull request process if Jenkins takes a look at the cluster and decides",
    "start": "2280359",
    "end": "2286160"
  },
  {
    "text": "there's not enough capacity to roll out the app it rejects the pull request so",
    "start": "2286160",
    "end": "2291200"
  },
  {
    "text": "automation through codification and through this top to bottom codification automation is just amazingly trivial",
    "start": "2291200",
    "end": "2297240"
  },
  {
    "text": "from here on out so the results that we've seen so far uh because we introduced lots of",
    "start": "2297240",
    "end": "2304720"
  },
  {
    "text": "different Hardware stereotypes how am I doing for time five uh because we introduced lots of different Hardware",
    "start": "2304720",
    "end": "2311000"
  },
  {
    "text": "suppliers we are kind of our rack purchases are about a third of the price of what they were so our infrastructure",
    "start": "2311000",
    "end": "2316359"
  },
  {
    "text": "was pretty cheap compared to public Cloud but it's significantly cheaper now um and that's largely because we moved",
    "start": "2316359",
    "end": "2323560"
  },
  {
    "text": "away from the proprietary out of band protocols like dra and Alo and stuck to ipmi and figured out some of the",
    "start": "2323560",
    "end": "2329359"
  },
  {
    "text": "security implications behind ipmi through our automation we've also got a much better Dev experience if a data scientist wants",
    "start": "2329359",
    "end": "2336760"
  },
  {
    "text": "to play with a uh a deep learning cluster um it",
    "start": "2336760",
    "end": "2342640"
  },
  {
    "text": "takes him minutes or hours to set up the environment appropriately roll it out and move that forward into production if",
    "start": "2342640",
    "end": "2348839"
  },
  {
    "text": "we want to stand up uh Dev environments and shut them down and have those be representative of production it's",
    "start": "2348839",
    "end": "2353920"
  },
  {
    "text": "deterministic we can recreate it it's really really simple and so the we've",
    "start": "2353920",
    "end": "2359400"
  },
  {
    "text": "driven down the unit cost the dev experience is significantly better what we don't feel we've proven yet is cost",
    "start": "2359400",
    "end": "2365000"
  },
  {
    "text": "of change a lot of people uh of sing vitory they kind of go we've implemented something new and shiny and we're moving",
    "start": "2365000",
    "end": "2371800"
  },
  {
    "text": "really really fast and we feel like that too on our new and shiny thing but we've only had our new and shiny thing for six",
    "start": "2371800",
    "end": "2378079"
  },
  {
    "text": "months what I want is when I look back over 18 months or 24 months I want to",
    "start": "2378079",
    "end": "2383440"
  },
  {
    "text": "see significantly more workload and are still moving as fast as we were in month one and then I think we would sing",
    "start": "2383440",
    "end": "2389280"
  },
  {
    "text": "Victory around cost of change or speed uh for the moment we haven't seen that but we believe we've set up everything",
    "start": "2389280",
    "end": "2395040"
  },
  {
    "text": "in the appropriate manner to get there continue delivery top to bottom um so I think that's it from me",
    "start": "2395040",
    "end": "2402160"
  },
  {
    "text": "moving over to questions",
    "start": "2402160",
    "end": "2405960"
  }
]
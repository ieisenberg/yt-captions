[
  {
    "start": "0",
    "end": "50000"
  },
  {
    "text": "[Music]",
    "start": "3510",
    "end": "6640"
  },
  {
    "text": "so if you think about astronomers maybe you think this is what we do or did",
    "start": "13759",
    "end": "19199"
  },
  {
    "text": "so not really but what we do actually this is more what we do we we",
    "start": "19199",
    "end": "25519"
  },
  {
    "text": "sit behind the screen stare at the screen and we're almost like programmer slash data scientist",
    "start": "25519",
    "end": "32800"
  },
  {
    "text": "so um this is kind of the data set that we had which was so small that it's even",
    "start": "32800",
    "end": "39120"
  },
  {
    "text": "printed in a pdf file like the date the tabular data you can just like read it from a pdf file",
    "start": "39120",
    "end": "45600"
  },
  {
    "text": "it's really small it's like a hundred thousand stars and that's all we had that completely changed",
    "start": "45600",
    "end": "51840"
  },
  {
    "start": "50000",
    "end": "320000"
  },
  {
    "text": "so the gaia mission is it's a satellite that scans the milky",
    "start": "51840",
    "end": "57760"
  },
  {
    "text": "way for the positions distances and velocities of stars in a",
    "start": "57760",
    "end": "63680"
  },
  {
    "text": "milky way and it does this for a lot of stars",
    "start": "63680",
    "end": "68720"
  },
  {
    "text": "so we went from like 100 000 stars we went to",
    "start": "68720",
    "end": "74799"
  },
  {
    "text": "uh now something like 1.8 billion stars with 100 columns for uh for each star so",
    "start": "74799",
    "end": "81920"
  },
  {
    "text": "100 features for each stars so we had to deal with a 10 000 times",
    "start": "81920",
    "end": "87360"
  },
  {
    "text": "increase in data volume and what we actually need to do our science is interactive exploration of",
    "start": "87360",
    "end": "93840"
  },
  {
    "text": "this data visualization but also statistical analysis and the requirement because we are like",
    "start": "93840",
    "end": "100960"
  },
  {
    "text": "uh astronomers is it has to be a like a low barrier of entry it has to be accessible",
    "start": "100960",
    "end": "106960"
  },
  {
    "text": "and money is also an uh issue so it has to be affordable",
    "start": "106960",
    "end": "112560"
  },
  {
    "text": "so as i said an easy setup and that means uh preferably not a cluster",
    "start": "112560",
    "end": "118479"
  },
  {
    "text": "so if i take this previous data set that we had and just visualize the data in a simple way some what i'm showing here is",
    "start": "118479",
    "end": "125119"
  },
  {
    "text": "just sky coordinates of this data set and you see here you see two of our neighboring galaxies",
    "start": "125119",
    "end": "132080"
  },
  {
    "text": "um large and small magellanic clouds and you see we live in a disky",
    "start": "132080",
    "end": "137120"
  },
  {
    "text": "galaxy this gives you an idea what the sky coverage is in this case it's from a",
    "start": "137120",
    "end": "142319"
  },
  {
    "text": "satellite so we see all the stars but we we have to deal with like 10 times 10",
    "start": "142319",
    "end": "149840"
  },
  {
    "text": "000 times as much data so can we scale this up so if we had like a million stars and we",
    "start": "149840",
    "end": "156400"
  },
  {
    "text": "would do the same visualization we would have this if we had 10 million stars we would have this going to 100 million",
    "start": "156400",
    "end": "162959"
  },
  {
    "text": "stars if you could actually plot it would look like this and if you were to plot the full catalog you would see",
    "start": "162959",
    "end": "168720"
  },
  {
    "text": "nothing so that doesn't really work so it's not only a problem of of like",
    "start": "168720",
    "end": "174239"
  },
  {
    "text": "the amount of data but also how do you work with it so instead if we",
    "start": "174239",
    "end": "180480"
  },
  {
    "text": "create like a simple aggregation so what we do here is we calculate a histogram",
    "start": "180480",
    "end": "185519"
  },
  {
    "text": "so in each bin on the sky we calculate how many stars there are and a color according",
    "start": "185519",
    "end": "191440"
  },
  {
    "text": "to how many stars are in this bin so i do this now for this previous data set and now we can see if we can still scale",
    "start": "191440",
    "end": "197920"
  },
  {
    "text": "this up so if we now use more data and we go to like 100 million a billion we actually",
    "start": "197920",
    "end": "204080"
  },
  {
    "text": "instead of like losing detail we gain a lot of uh detail so what we see here is",
    "start": "204080",
    "end": "209120"
  },
  {
    "text": "again the lmc in the smc are neighboring galaxies we see in high details you see dust features in the milky way so this",
    "start": "209120",
    "end": "216000"
  },
  {
    "text": "is really meaningful to us we also see stripes so this is a quality control issue",
    "start": "216000",
    "end": "222640"
  },
  {
    "text": "but kind of the point here is that you want a visualization like this not just a scatter plot",
    "start": "222640",
    "end": "230799"
  },
  {
    "text": "so can we do this like do we need a cluster for this does this to make a visualization like",
    "start": "231280",
    "end": "237040"
  },
  {
    "text": "this do we need to run this overnight do we need to run this at lunch time or can we do this interactively so just to get",
    "start": "237040",
    "end": "244239"
  },
  {
    "text": "a rough estimate of what's possible and what's not let's do a back on the back of the envelope calculation",
    "start": "244239",
    "end": "250720"
  },
  {
    "text": "so let's take a look at the memory use so we're assuming double precision for the two columns we have so it's eight",
    "start": "250720",
    "end": "257600"
  },
  {
    "text": "bytes per value two columns and one billion rows so if you multiply that you get 15",
    "start": "257600",
    "end": "264160"
  },
  {
    "text": "gigabytes of data is that a lot well if you look at the memory bandwidth of a",
    "start": "264160",
    "end": "270160"
  },
  {
    "text": "older or more modern computer it's actually",
    "start": "270160",
    "end": "275520"
  },
  {
    "text": "doable to transfer this to the cpu in about a second and actually if you have a fast ssd like",
    "start": "275520",
    "end": "281360"
  },
  {
    "text": "in this laptop you can do this in a few seconds as well so you can read this amount of data in",
    "start": "281360",
    "end": "287520"
  },
  {
    "text": "just a few seconds so memory and io shouldn't be a limitation so what about",
    "start": "287520",
    "end": "293120"
  },
  {
    "text": "the cpu so take one cpu four gigahertz something like this but",
    "start": "293120",
    "end": "299120"
  },
  {
    "text": "you can of course have multiple cores so in total if you want to do this in say a second what we call interactive",
    "start": "299120",
    "end": "305520"
  },
  {
    "text": "you would need between at four or 100 cycles per row so you cannot",
    "start": "305520",
    "end": "311919"
  },
  {
    "text": "draw like complicated objects per star you need to do something simple like what i showed this histograming",
    "start": "311919",
    "end": "320960"
  },
  {
    "start": "320000",
    "end": "374000"
  },
  {
    "text": "so that that kind of culminated in the library uh facts that uh that i started creating",
    "start": "322080",
    "end": "328160"
  },
  {
    "text": "to to to try out this id we knew it was possible can we actually like make these these uh visualizations or aggregations",
    "start": "328160",
    "end": "336320"
  },
  {
    "text": "so that i created the library called fix so it's a high performance out of core data",
    "start": "336320",
    "end": "341680"
  },
  {
    "text": "frame library so that basically means you can work with data data that's larger than ram",
    "start": "341680",
    "end": "348639"
  },
  {
    "text": "and it works like on something like a billion samples on a single computer for instance this laptop as we will demonstrate it has a",
    "start": "348639",
    "end": "355840"
  },
  {
    "text": "pandas-like api for familiar rarity but it's not built on top of pandas it",
    "start": "355840",
    "end": "361840"
  },
  {
    "text": "just feels like it simple to install just pip install and you're ready to go no",
    "start": "361840",
    "end": "367759"
  },
  {
    "text": "like servers to set up or services to start and it's open source",
    "start": "367759",
    "end": "374960"
  },
  {
    "start": "374000",
    "end": "476000"
  },
  {
    "text": "so i want to go a bit over the concept that that actually enable us to get to this this",
    "start": "374960",
    "end": "380240"
  },
  {
    "text": "performance so let's talk about memory mapping so if you do a normal discrete what is actually happening",
    "start": "380240",
    "end": "386720"
  },
  {
    "text": "so you first need to allocate a piece of memory so you allocate i don't know eight gigs of ram",
    "start": "386720",
    "end": "394400"
  },
  {
    "text": "then you need to read from disk into this buffer but actually the operating system caches that so it first goes into",
    "start": "394400",
    "end": "400000"
  },
  {
    "text": "cache and then it gets copied into your private piece of memory and then it gets transferred to the",
    "start": "400000",
    "end": "407600"
  },
  {
    "text": "cpu so you're actually wasting memory memory that cannot be like taken back by the operating system to do something else",
    "start": "407600",
    "end": "414400"
  },
  {
    "text": "and you're doing memory copying well if you do memory mapping and i'm not going to go into the details",
    "start": "414400",
    "end": "420080"
  },
  {
    "text": "but you basically you get a pointer to the same buffer that the operating system has",
    "start": "420080",
    "end": "425360"
  },
  {
    "text": "so you're not making a memory copy and the operating system can just say",
    "start": "425360",
    "end": "430479"
  },
  {
    "text": "like hey i'm out of memory i'm just going to flush this cache this piece of cache and i will read it again if you",
    "start": "430479",
    "end": "435599"
  },
  {
    "text": "need it so you're basically outsourcing the complexities of what to read what to cast to the operating system",
    "start": "435599",
    "end": "442000"
  },
  {
    "text": "and there's some more benefits for instance you basically have shared memory",
    "start": "442000",
    "end": "447440"
  },
  {
    "text": "for all your processes so if you run for instance a python server you may be running flask",
    "start": "447440",
    "end": "453759"
  },
  {
    "text": "or dash using g unicorn you have like 10 processors or you have a jupyter notebook you have five kernels open with",
    "start": "453759",
    "end": "460160"
  },
  {
    "text": "the same data set they all share the same memory so no memory explosions anymore",
    "start": "460160",
    "end": "465840"
  },
  {
    "text": "one downside is that you need to store it on disk as you would keep it in memory you can get around that but then you",
    "start": "465840",
    "end": "472080"
  },
  {
    "text": "would need to make another you basically do a deserialization pass",
    "start": "472080",
    "end": "477440"
  },
  {
    "start": "476000",
    "end": "577000"
  },
  {
    "text": "column base storage it's really important so why so maybe you've noticed but we focus on",
    "start": "477440",
    "end": "482720"
  },
  {
    "text": "analytical workloads that basically means you're going to use a few columns and focus on these columns calculate",
    "start": "482720",
    "end": "487759"
  },
  {
    "text": "aggregations statistics on that and sequential access is ideal for disks and",
    "start": "487759",
    "end": "494960"
  },
  {
    "text": "ram cpu this reading is always block based so you can just read a lot of blocks should be",
    "start": "494960",
    "end": "500879"
  },
  {
    "text": "really fast and it's cache friendly so we have support for a few felf",
    "start": "500879",
    "end": "507599"
  },
  {
    "text": "formats so we started with hdf5 it's a it's a container format so you",
    "start": "507599",
    "end": "513839"
  },
  {
    "text": "can store anything in it so the way we store it is is our way of storing it",
    "start": "513839",
    "end": "518880"
  },
  {
    "text": "there's no standard on how you store tabular dataset in hdf5 but it's really simple it's stored in a",
    "start": "518880",
    "end": "525519"
  },
  {
    "text": "simple way if i give you an htfi file and you just use an explorer you'll probably find how you can access the",
    "start": "525519",
    "end": "531600"
  },
  {
    "text": "data we also support apache arrow which is specialized for tabular data so it's",
    "start": "531600",
    "end": "537360"
  },
  {
    "text": "really easy to like if you give you an arrow file it will be you can read it with r uh",
    "start": "537360",
    "end": "544000"
  },
  {
    "text": "java any any other language and you know how to access the data",
    "start": "544000",
    "end": "551360"
  },
  {
    "text": "all of these formats use like native storage so it is on disk as it is a memory which is ideal in combination",
    "start": "551760",
    "end": "557360"
  },
  {
    "text": "with memory mapping so we also support uh parquet via aero",
    "start": "557360",
    "end": "563440"
  },
  {
    "text": "so it's an industry standard but it's not native it's compressed so you need have some",
    "start": "563440",
    "end": "568959"
  },
  {
    "text": "deserialization so it's a bit slower compared to these other if at least when it fits into",
    "start": "568959",
    "end": "575519"
  },
  {
    "text": "your operating system cache",
    "start": "575519",
    "end": "578959"
  },
  {
    "start": "577000",
    "end": "650000"
  },
  {
    "text": "this guy a data set is one terabyte in size so if we want to do filtering like",
    "start": "580560",
    "end": "586399"
  },
  {
    "text": "take a subset of that maybe a subset that is 90 of the data we would we cannot make a copy of that so",
    "start": "586399",
    "end": "594000"
  },
  {
    "text": "to explain you like how we do not make copies let me give you this conceptual model of what a data frame is",
    "start": "594000",
    "end": "601760"
  },
  {
    "text": "um and it consists of data so in this case uh two arrays",
    "start": "601760",
    "end": "607120"
  },
  {
    "text": "and a state and now we're gonna filter it we're gonna say give me a new data frame that contains",
    "start": "607120",
    "end": "613600"
  },
  {
    "text": "only the values where i y is smaller than 10.",
    "start": "613600",
    "end": "618959"
  },
  {
    "text": "so instead of copying the data we simply store this expression in the state",
    "start": "618959",
    "end": "624000"
  },
  {
    "text": "and we we find out how to like give you only the data that you",
    "start": "624000",
    "end": "629760"
  },
  {
    "text": "need and the same for if you want to add a new column so here i'm adding a new column z",
    "start": "629760",
    "end": "637360"
  },
  {
    "text": "which is x plus y times 10. so instead of eagerly computing this",
    "start": "637360",
    "end": "643440"
  },
  {
    "text": "we just store the expression in a data frame and that basically allows us to not take up any memory",
    "start": "643440",
    "end": "650640"
  },
  {
    "start": "650000",
    "end": "743000"
  },
  {
    "text": "um so then you have your data and you want to like compute in that do aggregation",
    "start": "651680",
    "end": "656800"
  },
  {
    "text": "so we use your streaming algorithm so we go in like one or maybe two passes over the data",
    "start": "656800",
    "end": "663120"
  },
  {
    "text": "it is basically a map mostly map reduced so it's multi-threaded then you get into the issue of the python interpreter lock",
    "start": "663120",
    "end": "671360"
  },
  {
    "text": "but because we use c plus under the hood you use basically use all the cores of your your machine",
    "start": "671360",
    "end": "678560"
  },
  {
    "text": "and i already talked a bit about the expression system but let me go a bit bit more into detail",
    "start": "678560",
    "end": "686399"
  },
  {
    "text": "of the expression system so if you take two columns and you multiply them together you",
    "start": "686399",
    "end": "692160"
  },
  {
    "text": "eagerly compute the result and it takes memory like in this example",
    "start": "692160",
    "end": "698240"
  },
  {
    "text": "in fact if you multiply two columns you build an expression which is basically",
    "start": "698240",
    "end": "704079"
  },
  {
    "text": "the mathematical formula that you that that can give you the result if you",
    "start": "704079",
    "end": "709600"
  },
  {
    "text": "print this out we'll give you the first values and the last values just to give you an idea of like is this the right",
    "start": "709600",
    "end": "715519"
  },
  {
    "text": "equation like what's going on but um this is not taking up any memory it's just this string x times y",
    "start": "715519",
    "end": "723120"
  },
  {
    "text": "and the power of this is like this has more information than the the output right we know what the equation",
    "start": "723120",
    "end": "729440"
  },
  {
    "text": "is and we can optimize it for instance we can just in time compile this using uh number",
    "start": "729440",
    "end": "734480"
  },
  {
    "text": "um python or if the gpu gpu works with it we can actually run this",
    "start": "734480",
    "end": "741519"
  },
  {
    "text": "some of this on the gpu so um",
    "start": "741519",
    "end": "746959"
  },
  {
    "start": "743000",
    "end": "810000"
  },
  {
    "text": "this was all happening in in astronomy so both me and jovan left astronomy and",
    "start": "746959",
    "end": "753250"
  },
  {
    "text": "[Music] we now have a company and we basically we had this we solved",
    "start": "753250",
    "end": "758320"
  },
  {
    "text": "the problem in astronomy but we realized that this is actually a broader problem and it can be applied to like like many",
    "start": "758320",
    "end": "765279"
  },
  {
    "text": "industry uh issues so we continued with the more features like fast string",
    "start": "765279",
    "end": "770399"
  },
  {
    "text": "support was one of the first things we did massive performance improvements there",
    "start": "770399",
    "end": "776639"
  },
  {
    "text": "group buys join ml integrations etc but basically what what what we want to like",
    "start": "776639",
    "end": "782160"
  },
  {
    "text": "give you is like a tool to uncluster your data science probably you don't need a cluster in many cases",
    "start": "782160",
    "end": "788639"
  },
  {
    "text": "or at least postpone as long as possible so",
    "start": "788639",
    "end": "794879"
  },
  {
    "text": "i hope i convince you that facts can be fast but i think it's it's also useful to show",
    "start": "796000",
    "end": "801519"
  },
  {
    "text": "actually like live what you can do and um it's not wise but uh so that's why i",
    "start": "801519",
    "end": "807040"
  },
  {
    "text": "asked jovan to do this so jovan let's go ahead shall i switch yeah please",
    "start": "807040",
    "end": "815839"
  },
  {
    "start": "810000",
    "end": "1952000"
  },
  {
    "text": "thanks martin hello everyone can you see the screen behind me okay my blocking part of it",
    "start": "820720",
    "end": "828160"
  },
  {
    "text": "okay good great so martin did a really good job explaining the concepts of x and how it works",
    "start": "828160",
    "end": "834639"
  },
  {
    "text": "behind the scenes but we thought it would be really good idea to just show you like how it works in practice",
    "start": "834639",
    "end": "839680"
  },
  {
    "text": "instead of just showing you like bunch of numbers it runs in a second and so on so here",
    "start": "839680",
    "end": "845040"
  },
  {
    "text": "we're gonna go over a little demo how it works in practice with with a bit of a more kind of everyday data set that we",
    "start": "845040",
    "end": "850560"
  },
  {
    "text": "found available online so this is a jupiter notebook this is going to be available after the talk so",
    "start": "850560",
    "end": "855760"
  },
  {
    "text": "you can like play around and experiment with both the data set notebook on your own computer to convince yourself that",
    "start": "855760",
    "end": "861199"
  },
  {
    "text": "this is like legit basically so let's import the the libraries",
    "start": "861199",
    "end": "866639"
  },
  {
    "text": "so for this demo we're using this newer taxi data set it has bunch of",
    "start": "866639",
    "end": "871920"
  },
  {
    "text": "information regarding taxi trips in new york city and we have some versions of it but you",
    "start": "871920",
    "end": "876959"
  },
  {
    "text": "see they're generally quite big and today we're going to use this file that's basically 110 almost gigabytes on",
    "start": "876959",
    "end": "884240"
  },
  {
    "text": "disk and this computer has what 16 or 32 gigabytes of ram so using standard",
    "start": "884240",
    "end": "889360"
  },
  {
    "text": "techniques it's definitely not possible to even open it but with vx and the power of memory",
    "start": "889360",
    "end": "894639"
  },
  {
    "text": "mapping this actually is like instantaneous so now it's open",
    "start": "894639",
    "end": "899680"
  },
  {
    "text": "you don't believe me let's access the data here it is you see",
    "start": "899680",
    "end": "904880"
  },
  {
    "text": "on the your left that it has over billion rows and i can",
    "start": "904880",
    "end": "911199"
  },
  {
    "text": "access it again and again and again and it's instantaneous and this is the power of membrane mapping basically we know",
    "start": "911199",
    "end": "916720"
  },
  {
    "text": "exactly how the data looks on disk we know where it is and we know exactly what to read and here we're not we don't",
    "start": "916720",
    "end": "922320"
  },
  {
    "text": "really need to read everything we just need to give you a little preview so the first five rows in the last five rows",
    "start": "922320",
    "end": "928240"
  },
  {
    "text": "and all of the columns so that's instantaneous any laptop can do it no need to have fancy memory",
    "start": "928240",
    "end": "934240"
  },
  {
    "text": "uh requirements and we have access to some metadata let's say the data types",
    "start": "934240",
    "end": "939680"
  },
  {
    "text": "it's very simple to to do if you're familiar with pandas or pandas like data frames it should you should feel right",
    "start": "939680",
    "end": "945680"
  },
  {
    "text": "at home the next of the core concepts that martin explained is shallow copies so let's say we want to explore this data a",
    "start": "945680",
    "end": "952320"
  },
  {
    "text": "bit and there are some meaningful columns like pickup locations date time how many passengers in a taxi but there",
    "start": "952320",
    "end": "958480"
  },
  {
    "text": "are also some maybe not yet useful columns for the first pass when we explore this data like some taxes",
    "start": "958480",
    "end": "964639"
  },
  {
    "text": "some columns with unclear names with lots of missing values so we don't really want to kind of overburden ourselves",
    "start": "964639",
    "end": "970240"
  },
  {
    "text": "we want to filter that out and only focus on the columns we want so we have a list of columns that we",
    "start": "970240",
    "end": "976079"
  },
  {
    "text": "want to keep and just basically making a copy of this is a shallow copy",
    "start": "976079",
    "end": "982240"
  },
  {
    "text": "meaning that we're only going to focus on this on this parts of the data that we want we're not",
    "start": "982240",
    "end": "987839"
  },
  {
    "text": "actually making a separate copy but just referencing the data that's relevant to us again no extra memory usage just",
    "start": "987839",
    "end": "994000"
  },
  {
    "text": "pointing the operate system to like focus focus on this in particular the rest doesn't matter",
    "start": "994000",
    "end": "999920"
  },
  {
    "text": "we can also instead of accessing the full data frame access particular columns or we call them expressions",
    "start": "999920",
    "end": "1006320"
  },
  {
    "text": "just like you would do in pandas for example super fast again we know exactly where they are on disk we can read it",
    "start": "1006320",
    "end": "1011680"
  },
  {
    "text": "immediately we just give a preview it doesn't matter if it's 1 billion 10 billion 100 billion it's all the same",
    "start": "1011680",
    "end": "1018240"
  },
  {
    "text": "and the fun part starts when we try to actually do some mathematics or arithmetics so as martin explained",
    "start": "1018240",
    "end": "1024558"
  },
  {
    "text": "if we have a simple arithmetic operation like this what we get is a preview of the",
    "start": "1024559",
    "end": "1030720"
  },
  {
    "text": "expression we don't at this point we don't really need to evaluate everything we just want to make a preview to make sure that our operation makes sense and",
    "start": "1030720",
    "end": "1038000"
  },
  {
    "text": "this is one of the core of the vex and how it how it actually looks like so this expression we can assign it to a",
    "start": "1038000",
    "end": "1045120"
  },
  {
    "text": "data frame just like you would normally do here it is we get a simple preview",
    "start": "1045120",
    "end": "1050960"
  },
  {
    "text": "and we get it at the end just as a normal column like the rest of it so there actually this there is no physical",
    "start": "1050960",
    "end": "1056720"
  },
  {
    "text": "data behind it we're just storing the equation but the data frame doesn't know this so when you need it you evaluate it",
    "start": "1056720",
    "end": "1062720"
  },
  {
    "text": "on the fly when you don't need it to just store it as an expression takes zero memory",
    "start": "1062720",
    "end": "1068480"
  },
  {
    "text": "so okay that's great how about we do some aggregations now when we do an aggregation which is something like",
    "start": "1068480",
    "end": "1074000"
  },
  {
    "text": "computing the count the mean standard deviation and so on we cannot get away with just doing lazy",
    "start": "1074000",
    "end": "1079520"
  },
  {
    "text": "right we have to actually compute the expression so we have a billion columns and this is how long it takes",
    "start": "1079520",
    "end": "1085280"
  },
  {
    "text": "and this is well maybe may sound quite fast but it's actually like the first time it's a bit slow the third it needs",
    "start": "1085280",
    "end": "1092400"
  },
  {
    "text": "the operating system needs to like figure it out where the data is coming from the second time it's much faster oh",
    "start": "1092400",
    "end": "1097840"
  },
  {
    "text": "but there is an n this is kind of okay we divide by zero somewhere so we can just filter it out let's filter",
    "start": "1097840",
    "end": "1103840"
  },
  {
    "text": "distances that are bigger than zero and this is how long it takes to do",
    "start": "1103840",
    "end": "1108880"
  },
  {
    "text": "simple operations with vex on like over a billion columns like basically real time and uh you can at this point say yeah",
    "start": "1108880",
    "end": "1115760"
  },
  {
    "text": "this is great but it's like super simple operation right just some mean that's like streaming algorithms have been doing it for a while so okay let's try",
    "start": "1115760",
    "end": "1122720"
  },
  {
    "text": "something more challenging we have this fancy expression basically calculating the distance between two",
    "start": "1122720",
    "end": "1128480"
  },
  {
    "text": "points on a sphere it's lots of trigonometry like arithmetic it's it's quite",
    "start": "1128480",
    "end": "1134640"
  },
  {
    "text": "computationally expensive so let's try it out without any special magic out of the box vex will use numpy to do this",
    "start": "1134640",
    "end": "1141679"
  },
  {
    "text": "calculation and yeah it's a bit slow because it does well you can maybe hear the laptop",
    "start": "1141679",
    "end": "1147280"
  },
  {
    "text": "trying to work so it's fully parallelized it's going to use all the cores available and yeah i mean",
    "start": "1147280",
    "end": "1154720"
  },
  {
    "text": "i would like to know what you think after the talk whether this is impressive or not we're doing 1.1 billion points in about 30 seconds for",
    "start": "1154720",
    "end": "1161280"
  },
  {
    "text": "some really really challenging computation but you may think yeah but i want to go faster then you can actually",
    "start": "1161280",
    "end": "1166960"
  },
  {
    "text": "so we support just in time computation if you happen to have a gpu you can actually use cuda to pre-compile it to",
    "start": "1166960",
    "end": "1173200"
  },
  {
    "text": "cuda otherwise you can use things like number and part run to pre-compile it and now",
    "start": "1173200",
    "end": "1178559"
  },
  {
    "text": "it's basically gonna cut your cut your runtime in half so even for complicated",
    "start": "1178559",
    "end": "1183840"
  },
  {
    "text": "expressions you can evaluate them like on a simple off-the-shelf laptop basically nearly in real time",
    "start": "1183840",
    "end": "1191600"
  },
  {
    "text": "and we're done but wherever x really shines what it was originally built for is to",
    "start": "1191600",
    "end": "1198400"
  },
  {
    "text": "create uh basically aggregations so let's demonstrate this so the simplest aggregation what we call",
    "start": "1198400",
    "end": "1204720"
  },
  {
    "text": "zero dimensions it's just a single statistics we already did this it's um well stand something like count or mean",
    "start": "1204720",
    "end": "1211600"
  },
  {
    "text": "and this basically gives us though the one uh one second or less per run",
    "start": "1211600",
    "end": "1217280"
  },
  {
    "text": "especially when the operating system knows where to look at so we can execute this again and again",
    "start": "1217280",
    "end": "1223440"
  },
  {
    "text": "we get the result nearly immediately but this count method that's a property of this data frame is is kind of fancy",
    "start": "1223440",
    "end": "1229440"
  },
  {
    "text": "because we think okay count maybe sounds kind of silly and and simple but it's actually the foundation of many of the statistical",
    "start": "1229440",
    "end": "1236240"
  },
  {
    "text": "methods if you think about mean standard deviation skew or other fancy metrics they're basically underneath like deep down they're just",
    "start": "1236240",
    "end": "1242720"
  },
  {
    "text": "counting so instead of counting a single expression we can say okay we want to count but we",
    "start": "1242720",
    "end": "1249200"
  },
  {
    "text": "want a bin bias expression so basically we can build a histogram and say along this expression",
    "start": "1249200",
    "end": "1255039"
  },
  {
    "text": "count how many samples you get in a particular bin and this is basically a foundation of a histogram that we can",
    "start": "1255039",
    "end": "1261440"
  },
  {
    "text": "plot with your favorite uh favorite plotting library and of course vex has a friendly apis to do this in",
    "start": "1261440",
    "end": "1267760"
  },
  {
    "text": "one step but this is just to illustrate we can extend this to n dimensions for example two dimensions i can choose",
    "start": "1267760",
    "end": "1273440"
  },
  {
    "text": "let's say pickup location and well longitude and latitude and uh now it's going to be in by two",
    "start": "1273440",
    "end": "1279919"
  },
  {
    "text": "dimensions effectively creating a heat map then i can visualize again currently with modbully but you can just",
    "start": "1279919",
    "end": "1286480"
  },
  {
    "text": "use whatever whatever you're comfortable with so this is the basics and from here we can basically",
    "start": "1286480",
    "end": "1293280"
  },
  {
    "text": "use it to build fancy visualizations work interactively with data and we'll just do data science for the next part",
    "start": "1293280",
    "end": "1300640"
  },
  {
    "text": "actually i would like us to go together through this data set and just like simulate how a simple first pass",
    "start": "1300640",
    "end": "1306400"
  },
  {
    "text": "exploration would look like especially if you have like a billion points or something so in this data set there is a column",
    "start": "1306400",
    "end": "1313039"
  },
  {
    "text": "called passenger account and this is maybe my favorite my favorite method value counts probably",
    "start": "1313039",
    "end": "1319760"
  },
  {
    "text": "if you know pandas you know what it is you get for each individual unique uh sample you know how many entries there",
    "start": "1319760",
    "end": "1326240"
  },
  {
    "text": "are in your data frame so here we can see it's kind of dirty there well you know typical tax you",
    "start": "1326240",
    "end": "1332080"
  },
  {
    "text": "expect we have maybe four or five people most but here you see there's like lots of erroneous data maybe maybe some",
    "start": "1332080",
    "end": "1337919"
  },
  {
    "text": "something wrong and there's also like lots of passengers lots of trips like zero",
    "start": "1337919",
    "end": "1343039"
  },
  {
    "text": "so we just wanna like filter it but if we execute this again maybe when you're data scientist you do this",
    "start": "1343039",
    "end": "1349200"
  },
  {
    "text": "interactively because the operating system has cached part of the data like the second and third time",
    "start": "1349200",
    "end": "1355520"
  },
  {
    "text": "it's much faster so okay let's filter this out simple filter passengers like less than less",
    "start": "1355520",
    "end": "1361120"
  },
  {
    "text": "than seven more than zero we don't want them to trips let's let's do another example let's say",
    "start": "1361120",
    "end": "1367280"
  },
  {
    "text": "with with the distance average typical distance that a taxi does so this is another value counts",
    "start": "1367280",
    "end": "1373679"
  },
  {
    "text": "method and i do it again because i want to show you a case with like much higher cardinality because just like just distances",
    "start": "1373679",
    "end": "1379679"
  },
  {
    "text": "and you see it's again quite fast couple of seconds billion points laptop kind of",
    "start": "1379679",
    "end": "1384880"
  },
  {
    "text": "thing this is interesting guess you can see what the common distances are i guess new york's is kind of a grid so you",
    "start": "1384880",
    "end": "1390480"
  },
  {
    "text": "expect the same things to happen again and again interesting thing lots of taxi trips with where is it",
    "start": "1390480",
    "end": "1397840"
  },
  {
    "text": "with zero distance that's kind of funny we probably want to clean it but let's look at the distribution",
    "start": "1397840",
    "end": "1403840"
  },
  {
    "text": "so we can plot a histogram again quite fast weird histogram first of all negative",
    "start": "1403840",
    "end": "1409760"
  },
  {
    "text": "distances something's very wrong and a very massive tail on the positive side so we can i just for fun explore this",
    "start": "1409760",
    "end": "1417520"
  },
  {
    "text": "and if we find what the maximum distance is if we believe this at face value it's like wow almost six times the distance",
    "start": "1417520",
    "end": "1423919"
  },
  {
    "text": "to the moon so this has to be cleaned so let's do some more sensible histogram simple range okay this maybe sounds more",
    "start": "1423919",
    "end": "1431360"
  },
  {
    "text": "believable and we can filter this out so you might be thinking like at least i",
    "start": "1431360",
    "end": "1436720"
  },
  {
    "text": "was thinking wow some simple columns crazy outliers what what about what about the actual pickup and drop",
    "start": "1436720",
    "end": "1442559"
  },
  {
    "text": "off location because that's really defines what new york city is and now we're kind of going in two dimensions how do you cross filter this",
    "start": "1442559",
    "end": "1449279"
  },
  {
    "text": "well because we really care about kind of interactivity and",
    "start": "1449279",
    "end": "1454960"
  },
  {
    "text": "like interactive exploration for data scientists we actually have this widget out of the box for you to explore",
    "start": "1454960",
    "end": "1461200"
  },
  {
    "text": "basically heat maps interactively so it takes a bit to start because of",
    "start": "1461200",
    "end": "1467440"
  },
  {
    "text": "the javascript things and this is basically a map of new york city just traced by the pickup locations",
    "start": "1467440",
    "end": "1474240"
  },
  {
    "text": "well it's dominated by outliers so it doesn't like you don't see much but we can zoom in",
    "start": "1474240",
    "end": "1479520"
  },
  {
    "text": "zoom into this red spot and this happens in real time actually",
    "start": "1479520",
    "end": "1485039"
  },
  {
    "text": "i'm just not very good at zooming so every time i stop scrolling this basically to the histogram the",
    "start": "1485039",
    "end": "1491200"
  },
  {
    "text": "account method recomputes with new limits",
    "start": "1491200",
    "end": "1495279"
  },
  {
    "text": "and we can see new york city here",
    "start": "1496240",
    "end": "1502320"
  },
  {
    "text": "and you can zoom in zooming out i have never been to new york city so i don't know like what things are",
    "start": "1505440",
    "end": "1512000"
  },
  {
    "text": "which places are interesting to look at but basically yeah you can",
    "start": "1512000",
    "end": "1518799"
  },
  {
    "text": "you can uh interactively focus on the area that you like the most or just find like",
    "start": "1518799",
    "end": "1524480"
  },
  {
    "text": "which area is basically your definition of new york city without well needing any fence equipment or any",
    "start": "1524480",
    "end": "1531919"
  },
  {
    "text": "like well many lines of code basically so let's say we've just",
    "start": "1531919",
    "end": "1537120"
  },
  {
    "text": "agreed on what our bounding boxes again simple filter and",
    "start": "1537120",
    "end": "1543200"
  },
  {
    "text": "and we can continue with this with this process a bit more i've included some more cells exploring different features",
    "start": "1543200",
    "end": "1550320"
  },
  {
    "text": "like trip velocity like fares and so on this is going to be all on github",
    "start": "1550320",
    "end": "1555520"
  },
  {
    "text": "available to you along with the data so i'll just not bore you with the same things again and",
    "start": "1555520",
    "end": "1560880"
  },
  {
    "text": "again but i welcome you to try to explore it and just see how it works but i would like to focus on some",
    "start": "1560880",
    "end": "1566880"
  },
  {
    "text": "interesting features um that vex has so let's extract um",
    "start": "1566880",
    "end": "1574559"
  },
  {
    "text": "from the pickup hour from a pickup date time like the hour and day and month",
    "start": "1574559",
    "end": "1579679"
  },
  {
    "text": "and what vx can do we can say okay i want to treat certain features as basically as categories",
    "start": "1579679",
    "end": "1586159"
  },
  {
    "text": "and that will allow us to when visualizing them instead of treating them as numbers and just do normal",
    "start": "1586159",
    "end": "1591840"
  },
  {
    "text": "binning the x will know like oh this is a category so each category gets its own bin and then i can count and this is",
    "start": "1591840",
    "end": "1598880"
  },
  {
    "text": "quite convenient for doing plots like this for example now we've marked the pickup hour and day of week is",
    "start": "1598880",
    "end": "1604320"
  },
  {
    "text": "categorical so when we do make a histogram or two dimensional histogram it's a heat map",
    "start": "1604320",
    "end": "1609919"
  },
  {
    "text": "it will count each individual category as a bin so then we can count",
    "start": "1609919",
    "end": "1615520"
  },
  {
    "text": "how many trips there are in each combination of then and hour of the day and this kind of",
    "start": "1615520",
    "end": "1621440"
  },
  {
    "text": "makes sense so the blue is low number and radius high number early in the morning not many trips",
    "start": "1621440",
    "end": "1628720"
  },
  {
    "text": "around nine o'clock in the morning a bit more people kind of go to work the absolute peak happens it's here at",
    "start": "1628720",
    "end": "1634880"
  },
  {
    "text": "the very end of the day friday night saturday night uh where i guess most people take they taxes after their their",
    "start": "1634880",
    "end": "1641200"
  },
  {
    "text": "night out so super easy to make again billion points took 12 seconds which is double the time",
    "start": "1641200",
    "end": "1646720"
  },
  {
    "text": "because it's a demo so the laptop is nervous um so this has been like kind of binning",
    "start": "1646720",
    "end": "1653279"
  },
  {
    "text": "two-dimensional we do a conventional group by i'm just going to show it for posterity but there is a very cool",
    "start": "1653279",
    "end": "1659120"
  },
  {
    "text": "feature here that i want to show you so usually kind of if you're familiar with pandas or sql kind of similar in concept",
    "start": "1659120",
    "end": "1666880"
  },
  {
    "text": "you've been by something you group by something and then you do an aggregation but sometimes you're like",
    "start": "1666880",
    "end": "1672399"
  },
  {
    "text": "okay i want to do an aggregation and in this case i want to do an aggregation with an additional filter so think about",
    "start": "1672399",
    "end": "1677440"
  },
  {
    "text": "it if you need to do this in pandas you would have okay my first aggregation is one data frame",
    "start": "1677440",
    "end": "1682480"
  },
  {
    "text": "if i want to do a filter i need to filter out my data frame do an aggregation and do and do a join in vx we allow you to have a filter on",
    "start": "1682480",
    "end": "1690480"
  },
  {
    "text": "per aggregation basis so you can have let's say the tip amount for the whole data the average and then",
    "start": "1690480",
    "end": "1697520"
  },
  {
    "text": "a tip amount but according to some filter that says okay i just want four trips that have",
    "start": "1697520",
    "end": "1703360"
  },
  {
    "text": "two passengers like a couple and want to compare maybe those tip more or differently than the rest then you can",
    "start": "1703360",
    "end": "1708960"
  },
  {
    "text": "plot this favorite floating library and say okay they're kind of the same some variations",
    "start": "1708960",
    "end": "1714480"
  },
  {
    "text": "but yeah the idea is that you can do more with less line of codes less lines of code",
    "start": "1714480",
    "end": "1719520"
  },
  {
    "text": "again we can have join standard operation just big data small laptop kind of thing",
    "start": "1719520",
    "end": "1725440"
  },
  {
    "text": "um now we're joining the original data frame that we just discussed with this group uh group by data frame that we",
    "start": "1725440",
    "end": "1731840"
  },
  {
    "text": "that we did it takes a bit of time but yeah here it is and if you scroll to the right you get the new columns that",
    "start": "1731840",
    "end": "1739279"
  },
  {
    "text": "we that we just added so just before i wrap things up maybe you're inspired like wow taxis are cool",
    "start": "1739279",
    "end": "1745279"
  },
  {
    "text": "maybe i can have a side castle but where what where should i start if i wanna like have a side castle okay first",
    "start": "1745279",
    "end": "1752480"
  },
  {
    "text": "uh we can do another one of our favorite heat maps just uh see okay what which locations are are great for for picking",
    "start": "1752480",
    "end": "1758880"
  },
  {
    "text": "up passengers normal heat map would do right okay so manhattan pretty popular place",
    "start": "1758880",
    "end": "1765360"
  },
  {
    "text": "this can you see my pointer yep this is one of the airports another airport popular place but maybe you're thinking",
    "start": "1765360",
    "end": "1771440"
  },
  {
    "text": "okay yeah quantity like quality over quantity i don't care about number of passengers i care how much money you",
    "start": "1771440",
    "end": "1777840"
  },
  {
    "text": "earn so instead of just plotting counts we can actually tell vex what to plot which",
    "start": "1777840",
    "end": "1783600"
  },
  {
    "text": "is why this keyword argument is called what um and instead of just counting now we can",
    "start": "1783600",
    "end": "1789600"
  },
  {
    "text": "say we want for each little bin we want the mean of the fair amounts like how much how much money uh taxi",
    "start": "1789600",
    "end": "1796559"
  },
  {
    "text": "driver is earning on average and then we get a little bit of a different map see these avenues are very popular",
    "start": "1796559",
    "end": "1803360"
  },
  {
    "text": "charging taxi people charge a lot and of course the well the airports and some some docks or",
    "start": "1803360",
    "end": "1809360"
  },
  {
    "text": "whatever this area is but if you think about it maybe the raw amount is not",
    "start": "1809360",
    "end": "1815120"
  },
  {
    "text": "always a good indicator you have costs maybe you need to go to a remote location and you need to drive back waste time waste",
    "start": "1815120",
    "end": "1821360"
  },
  {
    "text": "petrol so yeah and maybe a better metric is to actually use this expression we",
    "start": "1821360",
    "end": "1827520"
  },
  {
    "text": "evaluated earlier so far divided by distance it's kind of like normalizing your costs",
    "start": "1827520",
    "end": "1832640"
  },
  {
    "text": "and with this we can we can get slightly different picture",
    "start": "1832640",
    "end": "1837760"
  },
  {
    "text": "and i guess my main point behind showing you all these slightly different versions of each other is just to show you how fast things are and you can like",
    "start": "1837760",
    "end": "1844240"
  },
  {
    "text": "almost forget that you're working with 100 gigabyte file and yeah here here is like maybe what",
    "start": "1844240",
    "end": "1849679"
  },
  {
    "text": "you would actually be interested in if you're running a toxic company get a slightly different picture now you see like okay this airport kind of",
    "start": "1849679",
    "end": "1856000"
  },
  {
    "text": "disappeared which just makes sense fixed price no matter where you go and manhattan is is like where you would go",
    "start": "1856000",
    "end": "1862399"
  },
  {
    "text": "if you want to pick the lucrative passengers so just to wrap things up",
    "start": "1862399",
    "end": "1867600"
  },
  {
    "text": "nice little features we know vex is made to work with big data sets but sometimes like",
    "start": "1867600",
    "end": "1874399"
  },
  {
    "text": "data storage hard drives on laptops can come in premium so actually vex works",
    "start": "1874399",
    "end": "1879840"
  },
  {
    "text": "really well with cloud so you can put your data hdf5 parquet aero on a public",
    "start": "1879840",
    "end": "1885279"
  },
  {
    "text": "cloud like s3 google cloud your favorite public cloud and you can open it straight away from",
    "start": "1885279",
    "end": "1891039"
  },
  {
    "text": "it and what vex will do it will connect to your cloud and stream the data and cache it directly",
    "start": "1891039",
    "end": "1898559"
  },
  {
    "text": "directly to the lab to your laptop so again this is uh well",
    "start": "1898559",
    "end": "1904000"
  },
  {
    "text": "it's not doesn't take very long because we're only accessing part of it we don't need full the full data but if if we",
    "start": "1904000",
    "end": "1910080"
  },
  {
    "text": "needed the full data it will first download the full data only the part of what we need so in this particular case",
    "start": "1910080",
    "end": "1915440"
  },
  {
    "text": "just a single column and evaluate that in this case it's quite fast because we already have it cached",
    "start": "1915440",
    "end": "1921360"
  },
  {
    "text": "from our previous executions also in a nutshell that's how it looks and feels to use vex pandas-like but",
    "start": "1921360",
    "end": "1928159"
  },
  {
    "text": "hopefully faster and hopefully it will you'll find it useful so thanks and back to you martin",
    "start": "1928159",
    "end": "1934480"
  },
  {
    "text": "[Applause]",
    "start": "1934480",
    "end": "1941130"
  },
  {
    "text": "thank you jofan so i forgot to mention this is my lucky slide and it worked again i think",
    "start": "1944240",
    "end": "1950480"
  },
  {
    "text": "that that's nice so um so jovan showed you how to use it for",
    "start": "1950480",
    "end": "1955600"
  },
  {
    "start": "1952000",
    "end": "2063000"
  },
  {
    "text": "like data exploration but what we see a lot is that people want to move like putting it into production and what do i",
    "start": "1955600",
    "end": "1961360"
  },
  {
    "text": "mean by that so um what what we see a lot is people making dashboards so they they start with large",
    "start": "1961360",
    "end": "1968320"
  },
  {
    "text": "data sets start exploring it and then they want to make a dashboard",
    "start": "1968320",
    "end": "1974399"
  },
  {
    "text": "also web apis uh or deploying ml models and we think fax is also like really ideal there so",
    "start": "1974399",
    "end": "1981360"
  },
  {
    "text": "what what i told you about this memory mapping of uh is that you share data with like g",
    "start": "1981360",
    "end": "1987200"
  },
  {
    "text": "unicorn like multiple processors that you have a lot in python you're not wasting any memory something",
    "start": "1987200",
    "end": "1994000"
  },
  {
    "text": "we didn't talk about but also like for instance like if you have a dashboard the first page is always the same so",
    "start": "1994000",
    "end": "2000159"
  },
  {
    "text": "it's the same query so using a caching system we can accelerate a lot of the like common queries",
    "start": "2000159",
    "end": "2006000"
  },
  {
    "text": "um and it's well tested with these frameworks like we tested we use it a lot a lot with the",
    "start": "2006000",
    "end": "2012480"
  },
  {
    "text": "dash flask and fast api and if you deploy this in the cloud you don't have",
    "start": "2012480",
    "end": "2018720"
  },
  {
    "text": "to worry about like how do i get the data on my node you just have an s3 url",
    "start": "2018720",
    "end": "2023760"
  },
  {
    "text": "and you still get like really good performance because we we do cache it lazily on the machine you're using",
    "start": "2023760",
    "end": "2031279"
  },
  {
    "text": "um so actually effects consists of like lots of sub packages and we do that so",
    "start": "2031279",
    "end": "2036960"
  },
  {
    "text": "you don't have so much dependencies so uh what we're showing you most of it is vex score we have fxml for machine",
    "start": "2036960",
    "end": "2043919"
  },
  {
    "text": "learning things and jovan was doing the visualizations with the effects fix fish",
    "start": "2043919",
    "end": "2051200"
  },
  {
    "text": "but it's basically like mud plot lip is not a dependency of fact scores if you just run something that just computes",
    "start": "2051200",
    "end": "2057440"
  },
  {
    "text": "and doesn't do visualization you of course don't want to have have to install modpod lib",
    "start": "2057440",
    "end": "2063118"
  },
  {
    "start": "2063000",
    "end": "2100000"
  },
  {
    "text": "so it's being used in the wild so we work with bioscribe and accelerating like their visualization of a genomics",
    "start": "2063119",
    "end": "2071919"
  },
  {
    "text": "dashboard with a quite decent performance increase i would say we work with the space telescope on",
    "start": "2071919",
    "end": "2078320"
  },
  {
    "text": "something i didn't talk about like remote data frames so actually you have a local python object but it actually",
    "start": "2078320",
    "end": "2085839"
  },
  {
    "text": "queries the data remotely and we work closely with plotly helping them with a",
    "start": "2085839",
    "end": "2091520"
  },
  {
    "text": "product they just launched despot engine where fex is the default backend to do",
    "start": "2091520",
    "end": "2096960"
  },
  {
    "text": "the their computations just to give you an example of uh",
    "start": "2096960",
    "end": "2105200"
  },
  {
    "start": "2100000",
    "end": "2202000"
  },
  {
    "text": "of that you can really like build such a dashboard we wrote an article and a so",
    "start": "2106160",
    "end": "2111440"
  },
  {
    "text": "let me refresh this um so you can go to this url if you can",
    "start": "2111440",
    "end": "2118240"
  },
  {
    "text": "read it it's dash.fix.io and there is a link here to the article",
    "start": "2118240",
    "end": "2124160"
  },
  {
    "text": "explaining like how we built this but this is basically processing in this case 120 million rows so it's a not a",
    "start": "2124160",
    "end": "2130880"
  },
  {
    "text": "billion because you we expect like multiple users so you want to have like really fast interaction if you have like",
    "start": "2130880",
    "end": "2136640"
  },
  {
    "text": "multiple users so and just to show that it's more than heat maps so with the aggregations and some fantasy you can create like these",
    "start": "2136640",
    "end": "2143680"
  },
  {
    "text": "maps where you click so i can click on a particular region and get statistics on this particular",
    "start": "2143680",
    "end": "2151520"
  },
  {
    "text": "this particular bureau it's called so i can for instance click on jfk airport",
    "start": "2151520",
    "end": "2158720"
  },
  {
    "text": "and see from the symbols diagram where everybody is going or the sync diagram",
    "start": "2158720",
    "end": "2165200"
  },
  {
    "text": "so actually let me move to the trip plan and maybe you want to like go from",
    "start": "2165200",
    "end": "2171280"
  },
  {
    "text": "this area to this area",
    "start": "2171280",
    "end": "2177599"
  },
  {
    "text": "and see how much does it take and how much does it cost so we have an overview of like how much in general this cost",
    "start": "2177599",
    "end": "2184480"
  },
  {
    "text": "how long it takes but maybe you're worried like okay i'm a return i need to go there on a wednesday particular hour",
    "start": "2184480",
    "end": "2190480"
  },
  {
    "text": "you can filter so this is all interactive nothing precomputed all done on the flight just to show you that this",
    "start": "2190480",
    "end": "2196720"
  },
  {
    "text": "this is this is possible",
    "start": "2196720",
    "end": "2200920"
  },
  {
    "start": "2202000",
    "end": "2233000"
  },
  {
    "text": "so um also joven and i need to eat so we have this company and uh so we're not",
    "start": "2202160",
    "end": "2207680"
  },
  {
    "text": "just doing like open source development we we help with like companies that need particular features",
    "start": "2207680",
    "end": "2213200"
  },
  {
    "text": "for like developing those or speeding this dose up with support retainers so we're on like speed dial helping with",
    "start": "2213200",
    "end": "2220480"
  },
  {
    "text": "performance and training and and uh um we hope to like flow that that uh back",
    "start": "2220480",
    "end": "2227040"
  },
  {
    "text": "to the the open source development so we can continue to support and maintain uh maintain effects",
    "start": "2227040",
    "end": "2233200"
  },
  {
    "start": "2233000",
    "end": "2278000"
  },
  {
    "text": "so uh i want to end with the summary so i hope i convince you that that operating on something like one billion",
    "start": "2233200",
    "end": "2238960"
  },
  {
    "text": "rows in one second is possible on this laptop even",
    "start": "2238960",
    "end": "2244160"
  },
  {
    "text": "so i explained how we do this and we use some techniques memory mapping",
    "start": "2244480",
    "end": "2249599"
  },
  {
    "text": "column based storage for id for sequential access fast sequential access multi-threading and c-plus plus",
    "start": "2249599",
    "end": "2256800"
  },
  {
    "text": "to avoid the python interpreter lock and the expression system uh",
    "start": "2256800",
    "end": "2262560"
  },
  {
    "text": "not to waste memory basically and i think we showed you it's ideal for interactive exploration like in the",
    "start": "2262560",
    "end": "2268400"
  },
  {
    "text": "jupyter notebook but also for building back ends especially uh dashboards and uh basically the takeaway is that",
    "start": "2268400",
    "end": "2275920"
  },
  {
    "text": "maybe you don't need a cluster you can get in touch with us",
    "start": "2275920",
    "end": "2282320"
  },
  {
    "start": "2278000",
    "end": "2305000"
  },
  {
    "text": "there also the last link is a link to the it's not up yet we'll push this tonight the the notebook and the slides",
    "start": "2282320",
    "end": "2290320"
  },
  {
    "text": "and don't forget to vote for this this session thank you",
    "start": "2290320",
    "end": "2296119"
  },
  {
    "text": "you",
    "start": "2303760",
    "end": "2305839"
  }
]
[
  {
    "start": "0",
    "end": "25000"
  },
  {
    "text": "today I'm going to talk about deep",
    "start": "5359",
    "end": "8099"
  },
  {
    "text": "learning a very popular words these days",
    "start": "8099",
    "end": "10400"
  },
  {
    "text": "you probably have already heard about",
    "start": "10400",
    "end": "12719"
  },
  {
    "text": "some other buzzwords like machine",
    "start": "12719",
    "end": "14580"
  },
  {
    "text": "learning artificial intelligence Etc",
    "start": "14580",
    "end": "18060"
  },
  {
    "text": "anyone still confused about the",
    "start": "18060",
    "end": "20220"
  },
  {
    "text": "definitions of those terms and the",
    "start": "20220",
    "end": "22140"
  },
  {
    "text": "relationship of their terms",
    "start": "22140",
    "end": "25400"
  },
  {
    "start": "25000",
    "end": "142000"
  },
  {
    "text": "none or a few",
    "start": "25619",
    "end": "27539"
  },
  {
    "text": "all right let's just figure out",
    "start": "27539",
    "end": "30240"
  },
  {
    "text": "so amount of three terms we have ai",
    "start": "30240",
    "end": "33840"
  },
  {
    "text": "artificial intelligence which is the",
    "start": "33840",
    "end": "36000"
  },
  {
    "text": "biggest domain that covers pretty much",
    "start": "36000",
    "end": "37800"
  },
  {
    "text": "everything around enabling computers to",
    "start": "37800",
    "end": "40320"
  },
  {
    "text": "mimic human behavior so Recreation of",
    "start": "40320",
    "end": "42960"
  },
  {
    "text": "human thoughts and we have mercenary",
    "start": "42960",
    "end": "45360"
  },
  {
    "text": "which is actually a subset of AI that",
    "start": "45360",
    "end": "48300"
  },
  {
    "text": "aims at making machines to understand",
    "start": "48300",
    "end": "50300"
  },
  {
    "text": "underlying pattern of the existing data",
    "start": "50300",
    "end": "52860"
  },
  {
    "text": "so that you can apply what it has",
    "start": "52860",
    "end": "54660"
  },
  {
    "text": "learned to some new observations",
    "start": "54660",
    "end": "56760"
  },
  {
    "text": "and then deep learning is actually a",
    "start": "56760",
    "end": "59940"
  },
  {
    "text": "special subset of machine learning",
    "start": "59940",
    "end": "61500"
  },
  {
    "text": "algorithms that using artificial neural",
    "start": "61500",
    "end": "63960"
  },
  {
    "text": "networks of very complex and deep",
    "start": "63960",
    "end": "66060"
  },
  {
    "text": "architecture",
    "start": "66060",
    "end": "67380"
  },
  {
    "text": "so probably some of you only heard about",
    "start": "67380",
    "end": "70460"
  },
  {
    "text": "artificial neural network or deep",
    "start": "70460",
    "end": "72299"
  },
  {
    "text": "learning since Google's Alpha group is",
    "start": "72299",
    "end": "74700"
  },
  {
    "text": "humor right but",
    "start": "74700",
    "end": "77700"
  },
  {
    "text": "if you know deep learning you must know",
    "start": "77700",
    "end": "81000"
  },
  {
    "text": "the well-known",
    "start": "81000",
    "end": "82619"
  },
  {
    "text": "CNN convolutional neural networks but",
    "start": "82619",
    "end": "85920"
  },
  {
    "text": "sorry I'm not going to talk about CNN at",
    "start": "85920",
    "end": "88619"
  },
  {
    "text": "all today",
    "start": "88619",
    "end": "89640"
  },
  {
    "text": "but",
    "start": "89640",
    "end": "92220"
  },
  {
    "text": "another variant of deep neural network",
    "start": "92220",
    "end": "94680"
  },
  {
    "text": "which is called grapheneal Network so",
    "start": "94680",
    "end": "97020"
  },
  {
    "text": "the highlight of such approach is",
    "start": "97020",
    "end": "99119"
  },
  {
    "text": "actually it can be used to model data",
    "start": "99119",
    "end": "101460"
  },
  {
    "text": "that are very complex relationship and",
    "start": "101460",
    "end": "104100"
  },
  {
    "text": "hierarchy between that objects",
    "start": "104100",
    "end": "107220"
  },
  {
    "text": "so today I'm going to start from some",
    "start": "107220",
    "end": "110640"
  },
  {
    "text": "Basics about the other representation",
    "start": "110640",
    "end": "112680"
  },
  {
    "text": "and then introduce to you a powerful",
    "start": "112680",
    "end": "115560"
  },
  {
    "text": "data representation called graph of",
    "start": "115560",
    "end": "117360"
  },
  {
    "text": "graphs and then talk about the learning",
    "start": "117360",
    "end": "121079"
  },
  {
    "text": "algorithms of the graph neural network",
    "start": "121079",
    "end": "123060"
  },
  {
    "text": "which is used to encode graph of graphs",
    "start": "123060",
    "end": "125880"
  },
  {
    "text": "and followed by some real world examples",
    "start": "125880",
    "end": "128459"
  },
  {
    "text": "of using graph of graphs and graph",
    "start": "128459",
    "end": "130920"
  },
  {
    "text": "neural networks so some of you probably",
    "start": "130920",
    "end": "133319"
  },
  {
    "text": "feel a little bit scary because I",
    "start": "133319",
    "end": "135720"
  },
  {
    "text": "mentioned learning algorithms but I will",
    "start": "135720",
    "end": "138239"
  },
  {
    "text": "make sure there is no formulas in my",
    "start": "138239",
    "end": "140459"
  },
  {
    "text": "slides",
    "start": "140459",
    "end": "142760"
  },
  {
    "start": "142000",
    "end": "302000"
  },
  {
    "text": "all right so let's have a quick look at",
    "start": "143040",
    "end": "145860"
  },
  {
    "text": "on the data representations",
    "start": "145860",
    "end": "148080"
  },
  {
    "text": "so no matter what kind of problems you",
    "start": "148080",
    "end": "150239"
  },
  {
    "text": "are trying to solve",
    "start": "150239",
    "end": "151800"
  },
  {
    "text": "um say tax documents classification user",
    "start": "151800",
    "end": "155280"
  },
  {
    "text": "clustering speech recognition it will",
    "start": "155280",
    "end": "158160"
  },
  {
    "text": "involve one or more data types and in",
    "start": "158160",
    "end": "161160"
  },
  {
    "text": "order to use artificial neural networks",
    "start": "161160",
    "end": "162900"
  },
  {
    "text": "to encode such data we have to transform",
    "start": "162900",
    "end": "166019"
  },
  {
    "text": "the data into a machine readable",
    "start": "166019",
    "end": "167940"
  },
  {
    "text": "representation",
    "start": "167940",
    "end": "169379"
  },
  {
    "text": "so the most the simplest one the",
    "start": "169379",
    "end": "171420"
  },
  {
    "text": "simplest one is the plain Vector so we",
    "start": "171420",
    "end": "174300"
  },
  {
    "text": "have a set of numbers but in such",
    "start": "174300",
    "end": "178200"
  },
  {
    "text": "representation the the context the",
    "start": "178200",
    "end": "180480"
  },
  {
    "text": "relationship among those individual",
    "start": "180480",
    "end": "182220"
  },
  {
    "text": "numbers actually completely ignored",
    "start": "182220",
    "end": "186180"
  },
  {
    "text": "so we have sequences introduced for",
    "start": "186180",
    "end": "188760"
  },
  {
    "text": "modeling sequential data time series of",
    "start": "188760",
    "end": "192180"
  },
  {
    "text": "data so for example like we can use it",
    "start": "192180",
    "end": "194280"
  },
  {
    "text": "to describe user events for sensor data",
    "start": "194280",
    "end": "198060"
  },
  {
    "text": "and also speech",
    "start": "198060",
    "end": "201560"
  },
  {
    "text": "and then we have a three representations",
    "start": "201599",
    "end": "204080"
  },
  {
    "text": "usually used to describe as structured",
    "start": "204080",
    "end": "207000"
  },
  {
    "text": "data say structured documents for",
    "start": "207000",
    "end": "209400"
  },
  {
    "text": "example like XML documents because we",
    "start": "209400",
    "end": "211440"
  },
  {
    "text": "have this XML tree",
    "start": "211440",
    "end": "213080"
  },
  {
    "text": "or any other data objects that a feature",
    "start": "213080",
    "end": "216239"
  },
  {
    "text": "in say hierarchical relationship among",
    "start": "216239",
    "end": "218459"
  },
  {
    "text": "different dot objects",
    "start": "218459",
    "end": "221360"
  },
  {
    "text": "and then you may notice that both",
    "start": "221879",
    "end": "223500"
  },
  {
    "text": "sequences and trees actually special",
    "start": "223500",
    "end": "226500"
  },
  {
    "text": "case of graphs where in a general graph",
    "start": "226500",
    "end": "230060"
  },
  {
    "text": "it actually contains a set of nodes that",
    "start": "230060",
    "end": "233700"
  },
  {
    "text": "connected via any types of links so the",
    "start": "233700",
    "end": "236700"
  },
  {
    "text": "links could be directed could be",
    "start": "236700",
    "end": "238799"
  },
  {
    "text": "undirected could be bi-directed or there",
    "start": "238799",
    "end": "243239"
  },
  {
    "text": "will be self-loops or",
    "start": "243239",
    "end": "245879"
  },
  {
    "text": "um",
    "start": "245879",
    "end": "246480"
  },
  {
    "text": "uh yeah self-connections",
    "start": "246480",
    "end": "250379"
  },
  {
    "text": "but",
    "start": "251879",
    "end": "253319"
  },
  {
    "text": "there could be some learning problems of",
    "start": "253319",
    "end": "256260"
  },
  {
    "text": "which the node in the graph can be",
    "start": "256260",
    "end": "258900"
  },
  {
    "text": "described by another graph so is of more",
    "start": "258900",
    "end": "262500"
  },
  {
    "text": "complicated relationship among those",
    "start": "262500",
    "end": "264479"
  },
  {
    "text": "nodes",
    "start": "264479",
    "end": "265800"
  },
  {
    "text": "and then this will result in a data",
    "start": "265800",
    "end": "268500"
  },
  {
    "text": "representation a graph structure that",
    "start": "268500",
    "end": "270900"
  },
  {
    "text": "have a node in the graph described by",
    "start": "270900",
    "end": "273780"
  },
  {
    "text": "another graph or a tree",
    "start": "273780",
    "end": "275880"
  },
  {
    "text": "and theoretically such structure can be",
    "start": "275880",
    "end": "279000"
  },
  {
    "text": "extended to be to with like infinite",
    "start": "279000",
    "end": "282180"
  },
  {
    "text": "depth so it could be like a graph of",
    "start": "282180",
    "end": "285660"
  },
  {
    "text": "graph of graph of graph if I keep saying",
    "start": "285660",
    "end": "287699"
  },
  {
    "text": "that no probably will reach the end of",
    "start": "287699",
    "end": "289380"
  },
  {
    "text": "the day uh so that's just theoretically",
    "start": "289380",
    "end": "292080"
  },
  {
    "text": "uh in fact we need to optimize the",
    "start": "292080",
    "end": "294660"
  },
  {
    "text": "representation uh to make sure that we",
    "start": "294660",
    "end": "297240"
  },
  {
    "text": "only include as deep context as we need",
    "start": "297240",
    "end": "301580"
  },
  {
    "text": "so one more thing is why we need the",
    "start": "302820",
    "end": "305699"
  },
  {
    "text": "graph representation so we usually use",
    "start": "305699",
    "end": "308160"
  },
  {
    "text": "graph representation to describe a more",
    "start": "308160",
    "end": "310440"
  },
  {
    "text": "complicated relationship amount data",
    "start": "310440",
    "end": "312540"
  },
  {
    "text": "objects so for example like the data for",
    "start": "312540",
    "end": "315720"
  },
  {
    "text": "social network data on Facebook Twitter",
    "start": "315720",
    "end": "318240"
  },
  {
    "text": "or if like Pathos in the city Etc",
    "start": "318240",
    "end": "323060"
  },
  {
    "text": "so next I will give you some examples of",
    "start": "323460",
    "end": "326039"
  },
  {
    "text": "the real world graph of graphs",
    "start": "326039",
    "end": "328620"
  },
  {
    "text": "so the first one is web spam detection",
    "start": "328620",
    "end": "331919"
  },
  {
    "text": "so in such example we have a collection",
    "start": "331919",
    "end": "335160"
  },
  {
    "text": "of web pages",
    "start": "335160",
    "end": "336539"
  },
  {
    "text": "so how are we going to represent such",
    "start": "336539",
    "end": "338400"
  },
  {
    "text": "domain",
    "start": "338400",
    "end": "339740"
  },
  {
    "text": "web pages actually connected by",
    "start": "339740",
    "end": "342240"
  },
  {
    "text": "hyperlinks so first we can define a",
    "start": "342240",
    "end": "344820"
  },
  {
    "text": "graph describe the web domain where the",
    "start": "344820",
    "end": "347639"
  },
  {
    "text": "nodes in such graph are documents and",
    "start": "347639",
    "end": "349979"
  },
  {
    "text": "the links are actually hyperlinks and",
    "start": "349979",
    "end": "352919"
  },
  {
    "text": "each node in such graph can be described",
    "start": "352919",
    "end": "355740"
  },
  {
    "text": "by say a feature Vector that contains",
    "start": "355740",
    "end": "358320"
  },
  {
    "text": "some content-based or linked based",
    "start": "358320",
    "end": "360180"
  },
  {
    "text": "information to describe such page",
    "start": "360180",
    "end": "362940"
  },
  {
    "text": "and then we know that in such graph some",
    "start": "362940",
    "end": "366060"
  },
  {
    "text": "pages are labeled as normal pages and",
    "start": "366060",
    "end": "369479"
  },
  {
    "text": "some pages are labeled as spam pages and",
    "start": "369479",
    "end": "372539"
  },
  {
    "text": "some pages actually unlabeled then we",
    "start": "372539",
    "end": "374940"
  },
  {
    "text": "can use machine learning approach to",
    "start": "374940",
    "end": "376740"
  },
  {
    "text": "reps to encode such representation and",
    "start": "376740",
    "end": "379800"
  },
  {
    "text": "then predict the result for those",
    "start": "379800",
    "end": "381479"
  },
  {
    "text": "unlabeled pages",
    "start": "381479",
    "end": "384380"
  },
  {
    "start": "385000",
    "end": "431000"
  },
  {
    "text": "and then similarly for the web document",
    "start": "385560",
    "end": "388800"
  },
  {
    "text": "categorization problem",
    "start": "388800",
    "end": "390600"
  },
  {
    "text": "we can Define the web page we have",
    "start": "390600",
    "end": "393120"
  },
  {
    "text": "defined a web graph too at the beginning",
    "start": "393120",
    "end": "395220"
  },
  {
    "text": "so the web graph will have nodes uh",
    "start": "395220",
    "end": "398819"
  },
  {
    "text": "represent the documents and the links",
    "start": "398819",
    "end": "400560"
  },
  {
    "text": "represent the link have a links between",
    "start": "400560",
    "end": "402960"
  },
  {
    "text": "the pages",
    "start": "402960",
    "end": "404520"
  },
  {
    "text": "but in addition to the feature Vector",
    "start": "404520",
    "end": "408680"
  },
  {
    "text": "described that particular node in the",
    "start": "408680",
    "end": "410940"
  },
  {
    "text": "web graph we can attach another graph",
    "start": "410940",
    "end": "413520"
  },
  {
    "text": "structure to further describe that",
    "start": "413520",
    "end": "415380"
  },
  {
    "text": "document",
    "start": "415380",
    "end": "416400"
  },
  {
    "text": "so for example like for XML documents we",
    "start": "416400",
    "end": "419580"
  },
  {
    "text": "can use a tree representation to",
    "start": "419580",
    "end": "421919"
  },
  {
    "text": "describe that particular document so a",
    "start": "421919",
    "end": "424620"
  },
  {
    "text": "node in that tree can be probably an an",
    "start": "424620",
    "end": "428100"
  },
  {
    "text": "element in the XML document say a block",
    "start": "428100",
    "end": "430259"
  },
  {
    "text": "of text",
    "start": "430259",
    "end": "431639"
  },
  {
    "text": "and if we extend that even further",
    "start": "431639",
    "end": "434940"
  },
  {
    "text": "the block of text within a particular",
    "start": "434940",
    "end": "437759"
  },
  {
    "text": "pair of XML tags can be described with",
    "start": "437759",
    "end": "441479"
  },
  {
    "text": "another text graph which can model the",
    "start": "441479",
    "end": "444900"
  },
  {
    "text": "word tokens or associations among those",
    "start": "444900",
    "end": "447539"
  },
  {
    "text": "tokens",
    "start": "447539",
    "end": "448680"
  },
  {
    "text": "so here we have this three level graph",
    "start": "448680",
    "end": "451560"
  },
  {
    "text": "of graphs which is a web graph of",
    "start": "451560",
    "end": "454139"
  },
  {
    "text": "document graphs of text graphs",
    "start": "454139",
    "end": "457139"
  },
  {
    "text": "so such graph of graph representation",
    "start": "457139",
    "end": "459240"
  },
  {
    "text": "actually encapsulate the content of the",
    "start": "459240",
    "end": "462240"
  },
  {
    "text": "page and also the contextual information",
    "start": "462240",
    "end": "465000"
  },
  {
    "text": "at different level in such text document",
    "start": "465000",
    "end": "468000"
  },
  {
    "text": "domain",
    "start": "468000",
    "end": "470419"
  },
  {
    "text": "all right so how about some other data",
    "start": "471840",
    "end": "474479"
  },
  {
    "text": "type rather than text documents",
    "start": "474479",
    "end": "477800"
  },
  {
    "text": "imagine that we're trying to classify",
    "start": "477800",
    "end": "481199"
  },
  {
    "text": "YouTube videos into predefined",
    "start": "481199",
    "end": "483419"
  },
  {
    "text": "categories",
    "start": "483419",
    "end": "484440"
  },
  {
    "text": "based on the Human Action detected in",
    "start": "484440",
    "end": "486599"
  },
  {
    "text": "the video",
    "start": "486599",
    "end": "487380"
  },
  {
    "text": "so how could we approach do you",
    "start": "487380",
    "end": "489300"
  },
  {
    "text": "represent such domain first we need to",
    "start": "489300",
    "end": "492240"
  },
  {
    "text": "understand what actually forms a video",
    "start": "492240",
    "end": "494880"
  },
  {
    "text": "so video is actually time series of",
    "start": "494880",
    "end": "497340"
  },
  {
    "text": "images",
    "start": "497340",
    "end": "499080"
  },
  {
    "text": "and then for each image what we can do",
    "start": "499080",
    "end": "501240"
  },
  {
    "text": "is to extract some features to describe",
    "start": "501240",
    "end": "503460"
  },
  {
    "text": "that image",
    "start": "503460",
    "end": "504660"
  },
  {
    "text": "and for example like some interest",
    "start": "504660",
    "end": "506699"
  },
  {
    "text": "points and interest points are usually",
    "start": "506699",
    "end": "509520"
  },
  {
    "text": "associated with one or more the",
    "start": "509520",
    "end": "512399"
  },
  {
    "text": "significant change of one or more image",
    "start": "512399",
    "end": "514560"
  },
  {
    "text": "Properties or the significant change",
    "start": "514560",
    "end": "516959"
  },
  {
    "text": "amount adjacent images",
    "start": "516959",
    "end": "519180"
  },
  {
    "text": "and then based on those interest points",
    "start": "519180",
    "end": "520979"
  },
  {
    "text": "we can build some common visual",
    "start": "520979",
    "end": "523380"
  },
  {
    "text": "descriptors to describe that particular",
    "start": "523380",
    "end": "525300"
  },
  {
    "text": "image",
    "start": "525300",
    "end": "526320"
  },
  {
    "text": "and you may see that um the interest",
    "start": "526320",
    "end": "528540"
  },
  {
    "text": "Point may look a bit independent on this",
    "start": "528540",
    "end": "531600"
  },
  {
    "text": "image but actually there is context",
    "start": "531600",
    "end": "534060"
  },
  {
    "text": "amount of Interest points so what we can",
    "start": "534060",
    "end": "536820"
  },
  {
    "text": "do is to connect those interest points",
    "start": "536820",
    "end": "539220"
  },
  {
    "text": "to form a graph",
    "start": "539220",
    "end": "540839"
  },
  {
    "text": "to retain such spatial context among",
    "start": "540839",
    "end": "543779"
  },
  {
    "text": "those interest points so let's have a",
    "start": "543779",
    "end": "546000"
  },
  {
    "text": "look what's the representation now",
    "start": "546000",
    "end": "548760"
  },
  {
    "text": "this is actually a sequence of graphs",
    "start": "548760",
    "end": "551519"
  },
  {
    "text": "which is a two level graph of graphs",
    "start": "551519",
    "end": "554279"
  },
  {
    "text": "where the level one graph is a sequence",
    "start": "554279",
    "end": "557220"
  },
  {
    "text": "represents the time series of images and",
    "start": "557220",
    "end": "560459"
  },
  {
    "text": "the second level graph provides a",
    "start": "560459",
    "end": "563040"
  },
  {
    "text": "structure to describe individual image",
    "start": "563040",
    "end": "565440"
  },
  {
    "text": "frames",
    "start": "565440",
    "end": "566519"
  },
  {
    "text": "so now we have several graph of graphs",
    "start": "566519",
    "end": "570540"
  },
  {
    "text": "but how could we use this graph of graph",
    "start": "570540",
    "end": "573440"
  },
  {
    "text": "so the regular artificial neural network",
    "start": "573440",
    "end": "576180"
  },
  {
    "text": "can only handle plane vectors as inputs",
    "start": "576180",
    "end": "579480"
  },
  {
    "text": "this is",
    "start": "579480",
    "end": "580860"
  },
  {
    "text": "um the common sense right and we have",
    "start": "580860",
    "end": "584580"
  },
  {
    "text": "recursive neural networks and recurrent",
    "start": "584580",
    "end": "586860"
  },
  {
    "text": "neural networks can be used to handle",
    "start": "586860",
    "end": "589620"
  },
  {
    "text": "say sequences or trees",
    "start": "589620",
    "end": "592440"
  },
  {
    "start": "592000",
    "end": "738000"
  },
  {
    "text": "however if the dependency between the",
    "start": "592440",
    "end": "595500"
  },
  {
    "text": "nose in the representation is more",
    "start": "595500",
    "end": "598500"
  },
  {
    "text": "complicated say for example it can form",
    "start": "598500",
    "end": "601019"
  },
  {
    "text": "a psychos a self-connections then",
    "start": "601019",
    "end": "603660"
  },
  {
    "text": "recursive networks can't really deal",
    "start": "603660",
    "end": "605640"
  },
  {
    "text": "with this case",
    "start": "605640",
    "end": "606899"
  },
  {
    "text": "and not mention if the representation is",
    "start": "606899",
    "end": "609779"
  },
  {
    "text": "graph of graphs",
    "start": "609779",
    "end": "611339"
  },
  {
    "text": "so how could we encode graph of graph",
    "start": "611339",
    "end": "613500"
  },
  {
    "text": "structure using neural networks",
    "start": "613500",
    "end": "617279"
  },
  {
    "text": "introducing graph neural network",
    "start": "617279",
    "end": "620339"
  },
  {
    "text": "so I will start from a very basic",
    "start": "620339",
    "end": "623100"
  },
  {
    "text": "architecture of a graph neural network",
    "start": "623100",
    "end": "624959"
  },
  {
    "text": "which is used to encode a very special",
    "start": "624959",
    "end": "628140"
  },
  {
    "text": "graph of graphs the one level graph of",
    "start": "628140",
    "end": "630300"
  },
  {
    "text": "graphs which is actually graph",
    "start": "630300",
    "end": "633000"
  },
  {
    "text": "um",
    "start": "633000",
    "end": "633920"
  },
  {
    "text": "yes and so the architecture of such",
    "start": "633920",
    "end": "637620"
  },
  {
    "text": "basic network has certain similarities",
    "start": "637620",
    "end": "641240"
  },
  {
    "text": "to the recursive multi-layer perceptual",
    "start": "641240",
    "end": "644399"
  },
  {
    "text": "Network I think everyone heard about it",
    "start": "644399",
    "end": "647220"
  },
  {
    "text": "right",
    "start": "647220",
    "end": "648899"
  },
  {
    "text": "um well anyway in that both feature four",
    "start": "648899",
    "end": "652440"
  },
  {
    "text": "main layers so the input layered hidden",
    "start": "652440",
    "end": "655320"
  },
  {
    "text": "layer the the state layer and the output",
    "start": "655320",
    "end": "658440"
  },
  {
    "text": "layer so you may notice that in addition",
    "start": "658440",
    "end": "660540"
  },
  {
    "text": "to those common three layers input here",
    "start": "660540",
    "end": "663300"
  },
  {
    "text": "and output we have a special layer here",
    "start": "663300",
    "end": "665579"
  },
  {
    "text": "is called State I will talk about the",
    "start": "665579",
    "end": "669000"
  },
  {
    "text": "state layer a bit more later",
    "start": "669000",
    "end": "671160"
  },
  {
    "text": "so the graph is actually processed by",
    "start": "671160",
    "end": "673980"
  },
  {
    "text": "the grapheneal network node by node in",
    "start": "673980",
    "end": "676860"
  },
  {
    "text": "the random order",
    "start": "676860",
    "end": "678360"
  },
  {
    "text": "and and for a node in a graph we",
    "start": "678360",
    "end": "681660"
  },
  {
    "text": "actually at the output from the network",
    "start": "681660",
    "end": "684000"
  },
  {
    "text": "for a node in the graph depends on the",
    "start": "684000",
    "end": "686820"
  },
  {
    "text": "state outputs for all its neighboring",
    "start": "686820",
    "end": "689339"
  },
  {
    "text": "nodes",
    "start": "689339",
    "end": "690779"
  },
  {
    "text": "so here we what we did is to compute a",
    "start": "690779",
    "end": "694440"
  },
  {
    "text": "sum of the state vectors of all its",
    "start": "694440",
    "end": "696899"
  },
  {
    "text": "neighboring nodes for a node",
    "start": "696899",
    "end": "698640"
  },
  {
    "text": "and then concatenate to its own say",
    "start": "698640",
    "end": "701700"
  },
  {
    "text": "input label vectors",
    "start": "701700",
    "end": "703920"
  },
  {
    "text": "so you may notice that the most critical",
    "start": "703920",
    "end": "707339"
  },
  {
    "text": "part in this process is to ensure the",
    "start": "707339",
    "end": "711000"
  },
  {
    "text": "sum of states can reach a very stable",
    "start": "711000",
    "end": "713640"
  },
  {
    "text": "point",
    "start": "713640",
    "end": "714720"
  },
  {
    "text": "and this is achieved through an",
    "start": "714720",
    "end": "717240"
  },
  {
    "text": "iterative procedure so we repeat the",
    "start": "717240",
    "end": "720720"
  },
  {
    "text": "feed forward session several times and",
    "start": "720720",
    "end": "723240"
  },
  {
    "text": "to the changes to the state vectors",
    "start": "723240",
    "end": "726420"
  },
  {
    "text": "converge",
    "start": "726420",
    "end": "727800"
  },
  {
    "text": "and the backward phase is dissimilar so",
    "start": "727800",
    "end": "731220"
  },
  {
    "text": "we need to like iterate that until we",
    "start": "731220",
    "end": "734640"
  },
  {
    "text": "reach the state stable point",
    "start": "734640",
    "end": "738320"
  },
  {
    "start": "738000",
    "end": "805000"
  },
  {
    "text": "so in a case that we want to process a",
    "start": "738779",
    "end": "741959"
  },
  {
    "text": "graph of graphs with two or more levels",
    "start": "741959",
    "end": "744660"
  },
  {
    "text": "we introduced some more Network",
    "start": "744660",
    "end": "747600"
  },
  {
    "text": "components so here we have this encoding",
    "start": "747600",
    "end": "750959"
  },
  {
    "text": "Network and output Network so the",
    "start": "750959",
    "end": "753720"
  },
  {
    "text": "encoding network is actually for",
    "start": "753720",
    "end": "755720"
  },
  {
    "text": "processing the the graphs that used to",
    "start": "755720",
    "end": "759959"
  },
  {
    "text": "describe a node in the upper level graph",
    "start": "759959",
    "end": "763200"
  },
  {
    "text": "and an output network will be used to",
    "start": "763200",
    "end": "765980"
  },
  {
    "text": "encode the top level graphs",
    "start": "765980",
    "end": "769139"
  },
  {
    "text": "so the encoded Network actually can be",
    "start": "769139",
    "end": "771540"
  },
  {
    "text": "enfolded according to the structure of",
    "start": "771540",
    "end": "774480"
  },
  {
    "text": "the graph of graphs so the depth of the",
    "start": "774480",
    "end": "776160"
  },
  {
    "text": "graph of graphs and also the size of the",
    "start": "776160",
    "end": "778860"
  },
  {
    "text": "graph at each level in the graph of",
    "start": "778860",
    "end": "780660"
  },
  {
    "text": "graphs and also the network structure",
    "start": "780660",
    "end": "784320"
  },
  {
    "text": "um and then feed forward and a back",
    "start": "784320",
    "end": "785820"
  },
  {
    "text": "proposition a back propagation actually",
    "start": "785820",
    "end": "788279"
  },
  {
    "text": "is through",
    "start": "788279",
    "end": "789899"
  },
  {
    "text": "um also the structure of the graph of",
    "start": "789899",
    "end": "792000"
  },
  {
    "text": "graphs the size of the graph at each",
    "start": "792000",
    "end": "794880"
  },
  {
    "text": "level and also the network structure so",
    "start": "794880",
    "end": "797160"
  },
  {
    "text": "you probably can imagine how deep it",
    "start": "797160",
    "end": "799500"
  },
  {
    "text": "will be if we really train such Network",
    "start": "799500",
    "end": "803899"
  },
  {
    "start": "805000",
    "end": "889000"
  },
  {
    "text": "so a bit more information about the",
    "start": "805680",
    "end": "809100"
  },
  {
    "text": "learning process",
    "start": "809100",
    "end": "810720"
  },
  {
    "text": "so for example here we have this two",
    "start": "810720",
    "end": "813779"
  },
  {
    "text": "level graph of graphs",
    "start": "813779",
    "end": "815940"
  },
  {
    "text": "so we will start from fitting the",
    "start": "815940",
    "end": "819480"
  },
  {
    "text": "information of the node at the deepest",
    "start": "819480",
    "end": "823200"
  },
  {
    "text": "level",
    "start": "823200",
    "end": "824220"
  },
  {
    "text": "into the encoding Network and password",
    "start": "824220",
    "end": "826920"
  },
  {
    "text": "the hidden",
    "start": "826920",
    "end": "828380"
  },
  {
    "text": "arriving State layer compute the state",
    "start": "828380",
    "end": "831899"
  },
  {
    "text": "output and then we",
    "start": "831899",
    "end": "834779"
  },
  {
    "text": "repeat that process until we can produce",
    "start": "834779",
    "end": "837839"
  },
  {
    "text": "very stable States for all the nodes in",
    "start": "837839",
    "end": "839940"
  },
  {
    "text": "the graph",
    "start": "839940",
    "end": "841260"
  },
  {
    "text": "and at that point we can produce the",
    "start": "841260",
    "end": "844500"
  },
  {
    "text": "final outputs for a particular graph and",
    "start": "844500",
    "end": "846959"
  },
  {
    "text": "the search output from the encoding",
    "start": "846959",
    "end": "848579"
  },
  {
    "text": "network will be used as the improved",
    "start": "848579",
    "end": "851160"
  },
  {
    "text": "label when we're processing the upper",
    "start": "851160",
    "end": "853560"
  },
  {
    "text": "level graph",
    "start": "853560",
    "end": "856160"
  },
  {
    "text": "and the process in the encoding in the",
    "start": "857220",
    "end": "860519"
  },
  {
    "text": "output network is not very different so",
    "start": "860519",
    "end": "863519"
  },
  {
    "text": "it's the same we repeat the feed",
    "start": "863519",
    "end": "865440"
  },
  {
    "text": "forwarding process multiple times until",
    "start": "865440",
    "end": "867360"
  },
  {
    "text": "we reach the stable points but the only",
    "start": "867360",
    "end": "870540"
  },
  {
    "text": "difference is that at the output layer",
    "start": "870540",
    "end": "872519"
  },
  {
    "text": "here we're trying to generate the final",
    "start": "872519",
    "end": "874980"
  },
  {
    "text": "output for the whole graph of graphs",
    "start": "874980",
    "end": "879000"
  },
  {
    "text": "and at the output layer we can compute",
    "start": "879000",
    "end": "882480"
  },
  {
    "text": "the error between the actual output and",
    "start": "882480",
    "end": "885839"
  },
  {
    "text": "also the expected output",
    "start": "885839",
    "end": "889040"
  },
  {
    "start": "889000",
    "end": "968000"
  },
  {
    "text": "so to sum up this process",
    "start": "889980",
    "end": "893040"
  },
  {
    "text": "oh sorry the iterative back propagation",
    "start": "893040",
    "end": "895620"
  },
  {
    "text": "uh is after the feed forward session",
    "start": "895620",
    "end": "898680"
  },
  {
    "text": "so the error has been computed and will",
    "start": "898680",
    "end": "901440"
  },
  {
    "text": "be propagated from the output Network to",
    "start": "901440",
    "end": "904680"
  },
  {
    "text": "the encoding Network",
    "start": "904680",
    "end": "906680"
  },
  {
    "text": "and you will see the number of",
    "start": "906680",
    "end": "909300"
  },
  {
    "text": "iterations that a back propagation we're",
    "start": "909300",
    "end": "911399"
  },
  {
    "text": "going through",
    "start": "911399",
    "end": "912360"
  },
  {
    "text": "is actually same as the number of",
    "start": "912360",
    "end": "914579"
  },
  {
    "text": "iterations that um the feed for war",
    "start": "914579",
    "end": "917820"
  },
  {
    "text": "session required before to reach the",
    "start": "917820",
    "end": "920100"
  },
  {
    "text": "Sable point",
    "start": "920100",
    "end": "922699"
  },
  {
    "text": "all right so the learning of graph of",
    "start": "924120",
    "end": "926880"
  },
  {
    "text": "graphs with a graph neural network is",
    "start": "926880",
    "end": "929880"
  },
  {
    "text": "actually with a very specific order",
    "start": "929880",
    "end": "932639"
  },
  {
    "text": "so the information will be fed into the",
    "start": "932639",
    "end": "934620"
  },
  {
    "text": "network from the deepest level",
    "start": "934620",
    "end": "938120"
  },
  {
    "text": "and until the top level",
    "start": "938120",
    "end": "941160"
  },
  {
    "text": "and the the back propagation process is",
    "start": "941160",
    "end": "944880"
  },
  {
    "text": "actually in the Reversed order so it's",
    "start": "944880",
    "end": "947339"
  },
  {
    "text": "propagate error from the topmost level",
    "start": "947339",
    "end": "949860"
  },
  {
    "text": "until we reach the deepest level",
    "start": "949860",
    "end": "953279"
  },
  {
    "text": "and the network parameters will be",
    "start": "953279",
    "end": "956339"
  },
  {
    "text": "updated according to the gradients that",
    "start": "956339",
    "end": "959339"
  },
  {
    "text": "we computed and accumulated",
    "start": "959339",
    "end": "962839"
  },
  {
    "text": "it seems like a bit boring right",
    "start": "963480",
    "end": "967279"
  },
  {
    "text": "but",
    "start": "967680",
    "end": "969540"
  },
  {
    "start": "968000",
    "end": "1062000"
  },
  {
    "text": "so what are the applications",
    "start": "969540",
    "end": "971639"
  },
  {
    "text": "of using grapheneal network and graph of",
    "start": "971639",
    "end": "975720"
  },
  {
    "text": "graphs I hope this has already provided",
    "start": "975720",
    "end": "979079"
  },
  {
    "text": "you some basic ideas about such learning",
    "start": "979079",
    "end": "982740"
  },
  {
    "text": "algorithm",
    "start": "982740",
    "end": "984720"
  },
  {
    "text": "um and then the applications of graph",
    "start": "984720",
    "end": "987000"
  },
  {
    "text": "neural networks and a graph of graphs as",
    "start": "987000",
    "end": "989880"
  },
  {
    "text": "I mentioned earlier we have this web",
    "start": "989880",
    "end": "991500"
  },
  {
    "text": "spam detection thing",
    "start": "991500",
    "end": "993660"
  },
  {
    "text": "um so for this task we actually created",
    "start": "993660",
    "end": "996300"
  },
  {
    "text": "a one level graph of graphs",
    "start": "996300",
    "end": "998940"
  },
  {
    "text": "um for the properties of individual",
    "start": "998940",
    "end": "1001100"
  },
  {
    "text": "pages and the relationship among pages",
    "start": "1001100",
    "end": "1003860"
  },
  {
    "text": "so in such web graph we have nodes",
    "start": "1003860",
    "end": "1006380"
  },
  {
    "text": "represents the documents and the links",
    "start": "1006380",
    "end": "1008060"
  },
  {
    "text": "represents hyperlinks and each note is",
    "start": "1008060",
    "end": "1011180"
  },
  {
    "text": "described by a feature Vector that",
    "start": "1011180",
    "end": "1013940"
  },
  {
    "text": "contains some content-based and linked",
    "start": "1013940",
    "end": "1015980"
  },
  {
    "text": "based information so content-based",
    "start": "1015980",
    "end": "1017540"
  },
  {
    "text": "information such as number of words in",
    "start": "1017540",
    "end": "1019880"
  },
  {
    "text": "the document the average length of the",
    "start": "1019880",
    "end": "1023660"
  },
  {
    "text": "word and also at the fraction of the",
    "start": "1023660",
    "end": "1026839"
  },
  {
    "text": "anchor text fraction of the visible tags",
    "start": "1026839",
    "end": "1029298"
  },
  {
    "text": "Etc and the link based feature like the",
    "start": "1029299",
    "end": "1032720"
  },
  {
    "text": "in degree our degree of the documents",
    "start": "1032720",
    "end": "1034699"
  },
  {
    "text": "page rank value trust rank value Etc",
    "start": "1034699",
    "end": "1039260"
  },
  {
    "text": "um and our gnm method actually",
    "start": "1039260",
    "end": "1042199"
  },
  {
    "text": "has shown some Advanced like Advantage",
    "start": "1042199",
    "end": "1045199"
  },
  {
    "text": "compared to other approaches that using",
    "start": "1045199",
    "end": "1048140"
  },
  {
    "text": "only those flame Vector feature vectors",
    "start": "1048140",
    "end": "1051140"
  },
  {
    "text": "as the inputs so it was able to generate",
    "start": "1051140",
    "end": "1054380"
  },
  {
    "text": "some competitive generalization",
    "start": "1054380",
    "end": "1056240"
  },
  {
    "text": "performance on web spam detection in",
    "start": "1056240",
    "end": "1059179"
  },
  {
    "text": "some Benchmark data set",
    "start": "1059179",
    "end": "1062320"
  },
  {
    "start": "1062000",
    "end": "1155000"
  },
  {
    "text": "and for this task that",
    "start": "1062840",
    "end": "1065740"
  },
  {
    "text": "humor action recognition task we try to",
    "start": "1065740",
    "end": "1068720"
  },
  {
    "text": "recognize the Human Action in and",
    "start": "1068720",
    "end": "1070520"
  },
  {
    "text": "constrained videos we have built this",
    "start": "1070520",
    "end": "1073100"
  },
  {
    "text": "sequence of graphs so we have this two",
    "start": "1073100",
    "end": "1075980"
  },
  {
    "text": "level graph of graphs and in the second",
    "start": "1075980",
    "end": "1078080"
  },
  {
    "text": "level what we did is to extract the",
    "start": "1078080",
    "end": "1080600"
  },
  {
    "text": "interest point and then based on those",
    "start": "1080600",
    "end": "1082640"
  },
  {
    "text": "interest points we built uh some common",
    "start": "1082640",
    "end": "1085460"
  },
  {
    "text": "common used visual descriptors such as",
    "start": "1085460",
    "end": "1088520"
  },
  {
    "text": "histogram of gradient histogram of",
    "start": "1088520",
    "end": "1090860"
  },
  {
    "text": "optical flow motion boundary histogram",
    "start": "1090860",
    "end": "1093980"
  },
  {
    "text": "Etc",
    "start": "1093980",
    "end": "1094760"
  },
  {
    "text": "to describe the interest point and we",
    "start": "1094760",
    "end": "1097580"
  },
  {
    "text": "have adopted a delonly triangulation",
    "start": "1097580",
    "end": "1100280"
  },
  {
    "text": "technique to describe the relationship",
    "start": "1100280",
    "end": "1103940"
  },
  {
    "text": "between those interest points on one",
    "start": "1103940",
    "end": "1106100"
  },
  {
    "text": "frame",
    "start": "1106100",
    "end": "1107960"
  },
  {
    "text": "and on the approach",
    "start": "1107960",
    "end": "1111640"
  },
  {
    "text": "and and graph on neural network and the",
    "start": "1112039",
    "end": "1114440"
  },
  {
    "text": "graph of graphs",
    "start": "1114440",
    "end": "1115880"
  },
  {
    "text": "um the the approach of this the",
    "start": "1115880",
    "end": "1117740"
  },
  {
    "text": "combination of these two actually helped",
    "start": "1117740",
    "end": "1120080"
  },
  {
    "text": "us achieve some good results uh in some",
    "start": "1120080",
    "end": "1122480"
  },
  {
    "text": "Benchmark video data sets but I think",
    "start": "1122480",
    "end": "1125840"
  },
  {
    "text": "the more significant contribution from",
    "start": "1125840",
    "end": "1127640"
  },
  {
    "text": "it is actually this deep learning",
    "start": "1127640",
    "end": "1129799"
  },
  {
    "text": "framework",
    "start": "1129799",
    "end": "1130880"
  },
  {
    "text": "for this particular problem because you",
    "start": "1130880",
    "end": "1133039"
  },
  {
    "text": "will see it's very flexible to replace",
    "start": "1133039",
    "end": "1135220"
  },
  {
    "text": "the say the the lonely triangulation",
    "start": "1135220",
    "end": "1138080"
  },
  {
    "text": "graph with some other contextual",
    "start": "1138080",
    "end": "1139700"
  },
  {
    "text": "representations or you can use even more",
    "start": "1139700",
    "end": "1142760"
  },
  {
    "text": "powerful visual descriptors to describe",
    "start": "1142760",
    "end": "1144980"
  },
  {
    "text": "the coordinates on the frame or even you",
    "start": "1144980",
    "end": "1147020"
  },
  {
    "text": "can extend the graph of graphs with more",
    "start": "1147020",
    "end": "1149240"
  },
  {
    "text": "levels when necessary",
    "start": "1149240",
    "end": "1152860"
  },
  {
    "start": "1155000",
    "end": "1271000"
  },
  {
    "text": "all right so a few words at the end",
    "start": "1155720",
    "end": "1159620"
  },
  {
    "text": "um so the approach of a graph of graphs",
    "start": "1159620",
    "end": "1162440"
  },
  {
    "text": "and graph neural networks actually is",
    "start": "1162440",
    "end": "1165320"
  },
  {
    "text": "providing a framework for modeling data",
    "start": "1165320",
    "end": "1168380"
  },
  {
    "text": "that are featuring a very complex",
    "start": "1168380",
    "end": "1170419"
  },
  {
    "text": "relationship and hierarchy without",
    "start": "1170419",
    "end": "1172760"
  },
  {
    "text": "abstracting the intrinsic connections",
    "start": "1172760",
    "end": "1174799"
  },
  {
    "text": "amount and the power of the graph neural",
    "start": "1174799",
    "end": "1178100"
  },
  {
    "text": "network algorithm is that it can encode",
    "start": "1178100",
    "end": "1180740"
  },
  {
    "text": "all the elements in the graph of graphs",
    "start": "1180740",
    "end": "1182539"
  },
  {
    "text": "as a whole",
    "start": "1182539",
    "end": "1183919"
  },
  {
    "text": "uh however according to my experience",
    "start": "1183919",
    "end": "1187640"
  },
  {
    "text": "I found out the main problem of the",
    "start": "1187640",
    "end": "1191539"
  },
  {
    "text": "graph neural network is actually it's",
    "start": "1191539",
    "end": "1194419"
  },
  {
    "text": "actually the difficulty for us to find",
    "start": "1194419",
    "end": "1196640"
  },
  {
    "text": "out a very good Network architecture for",
    "start": "1196640",
    "end": "1199039"
  },
  {
    "text": "a particular data domain",
    "start": "1199039",
    "end": "1201520"
  },
  {
    "text": "so we did experiment a lot and try to",
    "start": "1201520",
    "end": "1204919"
  },
  {
    "text": "identify a good model for different",
    "start": "1204919",
    "end": "1207799"
  },
  {
    "text": "problems see how many layers required",
    "start": "1207799",
    "end": "1210620"
  },
  {
    "text": "for this problem how many neurons in",
    "start": "1210620",
    "end": "1212600"
  },
  {
    "text": "each layer I think that's probably a",
    "start": "1212600",
    "end": "1214640"
  },
  {
    "text": "common problem but I believe this could",
    "start": "1214640",
    "end": "1218120"
  },
  {
    "text": "be some really potential future work",
    "start": "1218120",
    "end": "1220400"
  },
  {
    "text": "that can Empower GNN even further and",
    "start": "1220400",
    "end": "1223880"
  },
  {
    "text": "also the computational cost of a graph",
    "start": "1223880",
    "end": "1226400"
  },
  {
    "text": "of graphs and the GNN can be very high",
    "start": "1226400",
    "end": "1228880"
  },
  {
    "text": "especially you can increase as the",
    "start": "1228880",
    "end": "1231980"
  },
  {
    "text": "complexity of the graph of graphs and",
    "start": "1231980",
    "end": "1234559"
  },
  {
    "text": "the depth of the graph neural network",
    "start": "1234559",
    "end": "1235940"
  },
  {
    "text": "grows",
    "start": "1235940",
    "end": "1237140"
  },
  {
    "text": "but without the the proper",
    "start": "1237140",
    "end": "1240500"
  },
  {
    "text": "infrastructure or the scalable",
    "start": "1240500",
    "end": "1242780"
  },
  {
    "text": "implementation it will be very difficult",
    "start": "1242780",
    "end": "1245960"
  },
  {
    "text": "to put it into production",
    "start": "1245960",
    "end": "1248179"
  },
  {
    "text": "however I think deep learning has been",
    "start": "1248179",
    "end": "1250940"
  },
  {
    "text": "behind many advances in AI",
    "start": "1250940",
    "end": "1253660"
  },
  {
    "text": "which I think in the near future we",
    "start": "1253660",
    "end": "1256760"
  },
  {
    "text": "should be able to see more deep learning",
    "start": "1256760",
    "end": "1258919"
  },
  {
    "text": "real world deep learning applications",
    "start": "1258919",
    "end": "1260620"
  },
  {
    "text": "with the Advanced Hardware and advanced",
    "start": "1260620",
    "end": "1263780"
  },
  {
    "text": "development framework thank you",
    "start": "1263780",
    "end": "1268120"
  },
  {
    "text": "thank you",
    "start": "1268400",
    "end": "1270520"
  }
]
[
  {
    "start": "0",
    "end": "37000"
  },
  {
    "text": "good afternoon everybody uh I'm Anand uh and I'm a senior actor at CBA I'm a",
    "start": "6919",
    "end": "12599"
  },
  {
    "text": "contributor to apach Apex and my contributions have been primarily with the Cassandra connectors for Apex and",
    "start": "12599",
    "end": "18199"
  },
  {
    "text": "also the kurudu connectors uh recently I've been putting together the python connector and in this context I'd like",
    "start": "18199",
    "end": "25000"
  },
  {
    "text": "to share some design patterns which can be implemented for model scoring um on",
    "start": "25000",
    "end": "30640"
  },
  {
    "text": "uh on these data processing platforms using aex epex as the engine for low Laten",
    "start": "30640",
    "end": "35840"
  },
  {
    "text": "discovering uh uh basically what I'll try to quickly summarize what others",
    "start": "35840",
    "end": "40920"
  },
  {
    "start": "37000",
    "end": "65000"
  },
  {
    "text": "have spoken uh today as well as uh what Rob spoke uh sorry Bob spoke yesterday",
    "start": "40920",
    "end": "46480"
  },
  {
    "text": "uh we are quickly uh in in the world uh Landing in the world of you know using machine learning more or less for many",
    "start": "46480",
    "end": "53320"
  },
  {
    "text": "um so as a solution for many business problems and this requires both the engineering community to come together",
    "start": "53320",
    "end": "60000"
  },
  {
    "text": "and the data scientist uh Community to come together and build a real world application now the problem with this",
    "start": "60000",
    "end": "67040"
  },
  {
    "start": "65000",
    "end": "116000"
  },
  {
    "text": "approach is that uh sorry the problem with the current uh stack uh Technologies is that you don't always",
    "start": "67040",
    "end": "72520"
  },
  {
    "text": "get all the requirements uh in a single framework today um there are various",
    "start": "72520",
    "end": "78280"
  },
  {
    "text": "process related issues and a whole lot of other things which which don't act well together and uh for example if you",
    "start": "78280",
    "end": "83759"
  },
  {
    "text": "take the machine learning Stacks which are available today uh they are not really GED for low latency as the",
    "start": "83759",
    "end": "89439"
  },
  {
    "text": "primary construct they're more about modeling or scoring the model uh and as opposed to the other data processing",
    "start": "89439",
    "end": "96000"
  },
  {
    "text": "primes U which basically will solve some bits and pieces of it uh primarily this",
    "start": "96000",
    "end": "101079"
  },
  {
    "text": "becomes more complicated if it is a streaming solution kind of thing um",
    "start": "101079",
    "end": "106640"
  },
  {
    "text": "where you want to take the same uh model which is being developed for example in r or Python and convert it into the",
    "start": "106640",
    "end": "112719"
  },
  {
    "text": "scoring component in in a jvm world right so as part of today's agenda I'll",
    "start": "112719",
    "end": "118600"
  },
  {
    "start": "116000",
    "end": "130000"
  },
  {
    "text": "be covering uh uh aex uh introducing Apex to to this forum uh I'll also be",
    "start": "118600",
    "end": "123719"
  },
  {
    "text": "covering a few bit of data processing patterns uh and also some model scoring patterns which we can build using",
    "start": "123719",
    "end": "130160"
  },
  {
    "start": "130000",
    "end": "206000"
  },
  {
    "text": "apex apex is uh is is primarily defined can be defined as a low latency distributed streaming engine uh",
    "start": "130160",
    "end": "136920"
  },
  {
    "text": "basically it has got some other uh highly appealing features like it's a customiz it allows a highly customizable",
    "start": "136920",
    "end": "142560"
  },
  {
    "text": "dag it uh provides checkpointing end to end exactly on semantics security and",
    "start": "142560",
    "end": "148519"
  },
  {
    "text": "it's enabled out of the box uh I'll walk through the various uh facets of epex by uh by a few use cases",
    "start": "148519",
    "end": "156480"
  },
  {
    "text": "here uh first is uh what do we mean by a low leny streaming engine I think the primary differentiator is that you are",
    "start": "156480",
    "end": "162920"
  },
  {
    "text": "looking at a tle based processing as opposed to a mini batch based processing Paradigm in the sense that uh the in the",
    "start": "162920",
    "end": "169920"
  },
  {
    "text": "lower section of uh of the processing model you're actually optimizing for throughput typically Sparks kind of",
    "start": "169920",
    "end": "175599"
  },
  {
    "text": "thing are really good at doing this they really do it really really uh well whereas the uh streaming Frameworks tend",
    "start": "175599",
    "end": "182319"
  },
  {
    "text": "to look at a topple at a point of view that means they're optimizing for latencies as opposed to throughputs",
    "start": "182319",
    "end": "187400"
  },
  {
    "text": "right that is the primary differentiator and these kind of engines uh Mak sense when you're looking at some use cases",
    "start": "187400",
    "end": "194000"
  },
  {
    "text": "like fraud prevention kind of use cases wherein the processing sits in between the transaction and The Human Experience",
    "start": "194000",
    "end": "200120"
  },
  {
    "text": "as opposed to you know fraud detection which happens post post the",
    "start": "200120",
    "end": "205959"
  },
  {
    "text": "transaction once of course uh once we once we choose our the engine we want to",
    "start": "205959",
    "end": "211680"
  },
  {
    "text": "build our stack on the next problem would be I want to turn it into a distributed kind of thing as well",
    "start": "211680",
    "end": "216959"
  },
  {
    "text": "because one single node might not be able to meet all your uh compute needs right and so Apex uh is uh is is is just",
    "start": "216959",
    "end": "225439"
  },
  {
    "text": "like other swimming engines does provide uh a Yar enabled compute model wherein your containers are scaled up and down",
    "start": "225439",
    "end": "231920"
  },
  {
    "text": "or scale up and scale out kind of paradigms that means a single node can uh you know can can do a scale out scale",
    "start": "231920",
    "end": "237920"
  },
  {
    "text": "up problems and a multi cluster sorry multi note cluster can do a scale out Paradigm as well there's no missile",
    "start": "237920",
    "end": "244159"
  },
  {
    "text": "support yet for Apex and it's uh still on the road map uh this slide talks about the",
    "start": "244159",
    "end": "249760"
  },
  {
    "start": "248000",
    "end": "322000"
  },
  {
    "text": "typical application layout of Apex which is basically Apex is nothing but a collection of uh containers Yar",
    "start": "249760",
    "end": "257079"
  },
  {
    "text": "containers and what we have is an application Master which is highly available and the compute nodes which do",
    "start": "257079",
    "end": "263639"
  },
  {
    "text": "the business processing logic and they're distributed across your cluster they sit on your typical Hadoop and you",
    "start": "263639",
    "end": "269199"
  },
  {
    "text": "can go go share this cluster with your spark jobs or typical map reduce jobs and uh and have a streaming engine which",
    "start": "269199",
    "end": "276160"
  },
  {
    "text": "will meet your latency needs um and each of this is uh is aware of failures in",
    "start": "276160",
    "end": "282759"
  },
  {
    "text": "the sense that Master can fail and epex master can be uh reprovisioned on another physical node if the physical",
    "start": "282759",
    "end": "288360"
  },
  {
    "text": "node fails and those those use cases are also managed on the left you'll see the typical layout of of the Apex",
    "start": "288360",
    "end": "295320"
  },
  {
    "text": "application framework wherein at the at the lower most you have the bare metal or the cloud or virtual whatever your uh",
    "start": "295320",
    "end": "300960"
  },
  {
    "text": "your your mechanism is to provision the OS and on top of it you have your Hado nodes the data processing nodes and on",
    "start": "300960",
    "end": "308600"
  },
  {
    "text": "top the Hadoop Yan constructs you have the aex streaming engine which provides high performance for tolerant and in",
    "start": "308600",
    "end": "315120"
  },
  {
    "text": "memory processing semantics and on top of FX you build your application with to get all these",
    "start": "315120",
    "end": "321960"
  },
  {
    "text": "benefits uh this is a typical uh example of an apex application develop model development model wherein you uh",
    "start": "321960",
    "end": "328800"
  },
  {
    "start": "322000",
    "end": "454000"
  },
  {
    "text": "basically first try to build the logical model of your application in this example we uh we are seeing we we are",
    "start": "328800",
    "end": "336720"
  },
  {
    "text": "streaming something from Kafka it can be a TCP socket as well whatever our choice is and then we are using uh the tle",
    "start": "336720",
    "end": "344280"
  },
  {
    "text": "which is which is R out from a Kafka partition and look at say for example Cassandra store to to enrich the",
    "start": "344280",
    "end": "350560"
  },
  {
    "text": "transaction to define a feature or maybe a collection of features and use this feature and perhaps run it through a",
    "start": "350560",
    "end": "356319"
  },
  {
    "text": "model which scores the transaction in some way and and then perhaps write it to another store like kudu which will",
    "start": "356319",
    "end": "362240"
  },
  {
    "text": "help me put a you know relational engine on top of kudu so that I can query like an SQL query kind of things this is a",
    "start": "362240",
    "end": "368680"
  },
  {
    "text": "basic simple example uh so in this example what we see is is is the arrows there which represent the stream of tles",
    "start": "368680",
    "end": "375880"
  },
  {
    "text": "going in from one version of the operator to the next stage it's it's a uh it's a it's a it's a flow going from",
    "start": "375880",
    "end": "382039"
  },
  {
    "text": "left to right the circles you see are can be uh SE can be defined as operators",
    "start": "382039",
    "end": "387880"
  },
  {
    "text": "uh this is nothing but a jvm instance which holds the business logic specific to your U component of the problem",
    "start": "387880",
    "end": "394280"
  },
  {
    "text": "you're trying to solve in that piece so in the first piece you have a uh the business logic of it's not business",
    "start": "394280",
    "end": "399919"
  },
  {
    "text": "logic but at least the data data problem of reading from Kafka scaling it to perhaps multiple partitions and topics",
    "start": "399919",
    "end": "407080"
  },
  {
    "text": "or clusters or whatever it is and then the second stage you have the problem of reading from Cassandra it is its own",
    "start": "407080",
    "end": "412120"
  },
  {
    "text": "operator the model is is is the third operator and so on so forth all of this in unision makes up a",
    "start": "412120",
    "end": "418560"
  },
  {
    "text": "dag wherein it's a d directed e graph between left to right as a flow so it's",
    "start": "418560",
    "end": "425120"
  },
  {
    "text": "it's the entire thing which is the collection of the stream and operators",
    "start": "425120",
    "end": "430160"
  },
  {
    "text": "make up the dag and that's what make an apex application Apex comes out of the",
    "start": "430160",
    "end": "435759"
  },
  {
    "text": "box with a lot of uh colle uh connectors out of the box you know it's uh basically the time to value or time to",
    "start": "435759",
    "end": "442960"
  },
  {
    "text": "Market is really uh low because you have so many connectors ready made out of the box so that you can basically Piggy back",
    "start": "442960",
    "end": "449720"
  },
  {
    "text": "on that and try to extend it in the way you want it to be um so but that the next uh problem",
    "start": "449720",
    "end": "460039"
  },
  {
    "text": "you might hit is yes that's all fine but when I build my application my application might might itself have",
    "start": "460039",
    "end": "465560"
  },
  {
    "text": "different compute needs for example reading from from Kafka might be pretty pretty uh latency uh uh low low low",
    "start": "465560",
    "end": "473400"
  },
  {
    "text": "latency because Kafka is really optimized for a streaming consumption point of view but for example if it's a",
    "start": "473400",
    "end": "479080"
  },
  {
    "text": "you know Cassandra lookup wherein I'm doing multiple keys or multiple tables in Cassandra doing lookup I might end up",
    "start": "479080",
    "end": "486280"
  },
  {
    "text": "with a disio access pattern which might be slower as compared to Kafka streaming uh and uh and going down the path you",
    "start": "486280",
    "end": "494039"
  },
  {
    "text": "might have a model scoring which is highly needing more compute because your scoring function is really rich and you",
    "start": "494039",
    "end": "499360"
  },
  {
    "text": "you need more compute kind of thing so Apex provides the ability to uh",
    "start": "499360",
    "end": "505680"
  },
  {
    "text": "configure or fine-tune your um loads basing on the pro part of the problem",
    "start": "505680",
    "end": "510720"
  },
  {
    "text": "you're trying to say in in this example you're looking at Kafka has just three three operators perhaps Cassandra is",
    "start": "510720",
    "end": "516919"
  },
  {
    "text": "also not not really having so much load so we still went with three operators but model scoring is really computer",
    "start": "516919",
    "end": "523320"
  },
  {
    "text": "intensive so we went with a deployment of six operators and kudu was handling you know perhaps with just two operators",
    "start": "523320",
    "end": "530399"
  },
  {
    "text": "what what epex allows is used to you code for The Logical model on the left which is represented by four circles",
    "start": "530399",
    "end": "537360"
  },
  {
    "text": "connected the straight dag there but while deploying you can just make it as a configuration aspect to actually turn",
    "start": "537360",
    "end": "543200"
  },
  {
    "text": "it into a model which meets your meets your latency needs and to right and the entire thing is configurable in terms of",
    "start": "543200",
    "end": "550200"
  },
  {
    "text": "uh a stream CeX so for example you can fine-tune your tle routing patterns across this operators from each vertical",
    "start": "550200",
    "end": "556800"
  },
  {
    "text": "pH to other by defining your own stream CC uh if you if you if you're coming from the world of storm basic basically",
    "start": "556800",
    "end": "563800"
  },
  {
    "text": "you'll find that there's a lot of similarity in this in this architectures in that way right",
    "start": "563800",
    "end": "570760"
  },
  {
    "start": "570000",
    "end": "620000"
  },
  {
    "text": "um the next problem you'll you'll hit when when you try to build some of these low latency uh thing is that of course I",
    "start": "570760",
    "end": "577680"
  },
  {
    "text": "might have six model scoring operators and three Cassandra operators or three Kafka",
    "start": "577680",
    "end": "582760"
  },
  {
    "text": "operators because there is a uneven distribution of operators and most of",
    "start": "582760",
    "end": "587800"
  },
  {
    "text": "these um you know the the the that result most of these patterns might result in a back pressure on some of",
    "start": "587800",
    "end": "594480"
  },
  {
    "text": "these because there's an imbalance of computes uh in the individual operator level Apex provides the concept of",
    "start": "594480",
    "end": "599880"
  },
  {
    "text": "unifiers wherein you will see that if there is if the problem were to be flipped other way around for example we",
    "start": "599880",
    "end": "605480"
  },
  {
    "text": "had six cassand operators in the lower block of the diagram there and we had only had two model scoring operators you",
    "start": "605480",
    "end": "610800"
  },
  {
    "text": "can actually build unifiers to uh to to make sure that it is uh the back",
    "start": "610800",
    "end": "616240"
  },
  {
    "text": "pressure is handled properly as well another interesting problem space I",
    "start": "616240",
    "end": "622480"
  },
  {
    "start": "620000",
    "end": "661000"
  },
  {
    "text": "think with the for people who have worked in spark uh this might be very well is that uh you can avoid Network",
    "start": "622480",
    "end": "628720"
  },
  {
    "text": "Shuffles where in for example uh in the in the scoring pipeline you might read from a",
    "start": "628720",
    "end": "634480"
  },
  {
    "text": "tle coming from CF TCP socket Cassandra model scoring but you essentially need",
    "start": "634480",
    "end": "639600"
  },
  {
    "text": "not or if the application design does not require a shuffle across the nodes you can put a parallel partitioning",
    "start": "639600",
    "end": "646079"
  },
  {
    "text": "construct wherein you you only merge when you want to merge so you you you can Define your dag to actually to avoid",
    "start": "646079",
    "end": "651720"
  },
  {
    "text": "shuffles all the way till the point you actually need it and that that a uh that is a building block in in in the load",
    "start": "651720",
    "end": "658320"
  },
  {
    "text": "agency processing world as well another interesting feature which",
    "start": "658320",
    "end": "664360"
  },
  {
    "start": "661000",
    "end": "740000"
  },
  {
    "text": "Apex provides for is the concept of dynamic partitioning for example if we",
    "start": "664360",
    "end": "669639"
  },
  {
    "text": "have this traffic or transactions which we're doing as a you know as a fraud as an example I might realize that you know",
    "start": "669639",
    "end": "676560"
  },
  {
    "text": "during the day the transactions are running into say millions of transactions but at the night they're only 2 million as opposed to 20 million",
    "start": "676560",
    "end": "683680"
  },
  {
    "text": "uh Apex allows for dynamic partitioning in the sense that the same application without getting down can scale up or",
    "start": "683680",
    "end": "688880"
  },
  {
    "text": "scale down down basing on your uh basing on your configuration it provides us construct so that you can scale up and",
    "start": "688880",
    "end": "694200"
  },
  {
    "text": "scale down basing on your business logic or any other logic like you know so the stats for example the number of TPL",
    "start": "694200",
    "end": "699920"
  },
  {
    "text": "coming in through the CFA partition are where 100 in the previous instance window and now there are 20 you can",
    "start": "699920",
    "end": "706680"
  },
  {
    "text": "actually scale down the code the application can the framework can automatically scale down so daytime topology you will have something like on",
    "start": "706680",
    "end": "712519"
  },
  {
    "text": "the left on the night time you can turn it into something like this uh if you want and you can use that additional",
    "start": "712519",
    "end": "718200"
  },
  {
    "text": "compute which you gain by doing this Dynamic partitioning at night for say for example your other bad job so you're",
    "start": "718200",
    "end": "723920"
  },
  {
    "text": "investing in a fixed constant Hardware kind of profile and your streaming needs are changing at night perhaps and you",
    "start": "723920",
    "end": "730279"
  },
  {
    "text": "can use the resources released on a nightly fashion to do the batch for example some model development or",
    "start": "730279",
    "end": "736880"
  },
  {
    "text": "whatever these bad jobs you can do uh another interesting feature that",
    "start": "736880",
    "end": "742360"
  },
  {
    "start": "740000",
    "end": "832000"
  },
  {
    "text": "is provided by aex is U Pub up for recoverability so machines do fail and",
    "start": "742360",
    "end": "748720"
  },
  {
    "text": "this is a this is a this is a hard hard reality we have today but how does uh",
    "start": "748720",
    "end": "754720"
  },
  {
    "text": "how Apex differs from other streaming engin is that it only fails part of the dag not the entire application if",
    "start": "754720",
    "end": "760680"
  },
  {
    "text": "something goes wrong so uh it's it's it's a it's a powerful Constructor differs uh from some of the streaming in",
    "start": "760680",
    "end": "766560"
  },
  {
    "text": "the aspect that if for example if you see on the rightmost there if if the part of the operator which is Downstream",
    "start": "766560",
    "end": "772639"
  },
  {
    "text": "dies the Upstream operator knows how to reprovision or resend those stles in",
    "start": "772639",
    "end": "778279"
  },
  {
    "text": "case of failure to the Downstream operator and this is a building block of Apex because this is a uh this provides",
    "start": "778279",
    "end": "787079"
  },
  {
    "text": "for a couple of things one is item potency in the sense that the Upstream operator will make sure that your tles",
    "start": "787079",
    "end": "792800"
  },
  {
    "text": "are resent in the same sequence as they were sent earlier and this is this is a very important construct when you build",
    "start": "792800",
    "end": "799279"
  },
  {
    "text": "applications because um if you want to do end to end exactly once and if you're",
    "start": "799279",
    "end": "804480"
  },
  {
    "text": "dealing with stores like Cassandra which don't have transactional or two-phase",
    "start": "804480",
    "end": "809880"
  },
  {
    "text": "commit protocols what will happen is you end up corrupting your data and this is this forms a very important building",
    "start": "809880",
    "end": "815800"
  },
  {
    "text": "block which we will cover in a few minutes it also has the capacity to spill to disc just like your Sparks",
    "start": "815800",
    "end": "822519"
  },
  {
    "text": "wherein uh you you can configure to spill to disk if the memories is is",
    "start": "822519",
    "end": "827560"
  },
  {
    "text": "getting filled up this kind of constructs do exist in Apex as well um so Apex also provides for a",
    "start": "827560",
    "end": "835199"
  },
  {
    "start": "832000",
    "end": "978000"
  },
  {
    "text": "checkpointing mechanism which is um at certain time window the framework ensures that a checkpoint",
    "start": "835199",
    "end": "843160"
  },
  {
    "text": "is created for that state of the operator at that point in time and this checkpoint is specific to the operator",
    "start": "843160",
    "end": "850120"
  },
  {
    "text": "and each operator might might be uh or traversing it it in its own time Windows",
    "start": "850120",
    "end": "855160"
  },
  {
    "text": "when the checkpoint is happening the the example you see here is is is the uh jvm",
    "start": "855160",
    "end": "861720"
  },
  {
    "text": "where the Tes are flowing through it and each set of tles are bounded by a Time",
    "start": "861720",
    "end": "867360"
  },
  {
    "text": "window that's a streaming window um and uh this is the processing time uh you can also do even times in aex but this",
    "start": "867360",
    "end": "874160"
  },
  {
    "text": "is this represent the processing time and once once this tles reach that time",
    "start": "874160",
    "end": "880120"
  },
  {
    "text": "boundary then end tle is generated end tle marker is injected into the stream using which there can be operate a",
    "start": "880120",
    "end": "887120"
  },
  {
    "text": "business logic which you can use to do anything which you want to do at an end window or a begin window kind of construct you can also do a",
    "start": "887120",
    "end": "893600"
  },
  {
    "text": "checkpointing in the sense that uh Apex by default uses the htfs store for checkpointing that means you have a",
    "start": "893600",
    "end": "899839"
  },
  {
    "text": "highly available store for uh for for for storing the checkpoint itself suppose if the operator dies and the",
    "start": "899839",
    "end": "906560"
  },
  {
    "text": "operator is is is provision on some other container that hdfs checkpoint can",
    "start": "906560",
    "end": "911839"
  },
  {
    "text": "is since it's available distributed store you can actually use that checkpointing metadata on the second instance of the operator and con",
    "start": "911839",
    "end": "918600"
  },
  {
    "text": "continue from the checkpoint State itself the checkpointing itself has got highly uh highly optimized to the",
    "start": "918600",
    "end": "925959"
  },
  {
    "text": "operator itself for example in in case of Kafka the checkpointing metadata can be like the cluster name the topic name",
    "start": "925959",
    "end": "931800"
  },
  {
    "text": "and the partition which this operator was was reading information from and offset so using this four metadata",
    "start": "931800",
    "end": "937839"
  },
  {
    "text": "points I can actually re reprovision an operator on some other container or or physical metal and ensure that I can",
    "start": "937839",
    "end": "944639"
  },
  {
    "text": "cons I can resume from a certain offset of a given topic and a given partition for a given Kafka cluster epex provides",
    "start": "944639",
    "end": "950920"
  },
  {
    "text": "for very Vari patterns in the sense that uh you can you can stream from multiple",
    "start": "950920",
    "end": "956480"
  },
  {
    "text": "clusters of Kafka to multiple and multiple topics within each of these clusters uh and all in one single",
    "start": "956480",
    "end": "962800"
  },
  {
    "text": "application so for example you can think of use cases like there are multiple data centers of Kafka multiple clusters",
    "start": "962800",
    "end": "968519"
  },
  {
    "text": "of Kafka and multiple data centers you want your application to process uh by consuming from multiple data centers",
    "start": "968519",
    "end": "974160"
  },
  {
    "text": "that kind of patterns is also available here uh there are uh various processing",
    "start": "974160",
    "end": "980360"
  },
  {
    "start": "978000",
    "end": "1079000"
  },
  {
    "text": "guarantees that Apex provides uh one is the at least once guarantee in this we",
    "start": "980360",
    "end": "986079"
  },
  {
    "text": "are we you can the downstream operator which is is receiving these tles uh can",
    "start": "986079",
    "end": "991240"
  },
  {
    "text": "be guaranteed that the Tuple which is being sent from the Upstream is sent at least once that means there's a",
    "start": "991240",
    "end": "997000"
  },
  {
    "text": "possibility of duplicates uh that is good for some use cases wherein for example uh say log activity data",
    "start": "997000",
    "end": "1003639"
  },
  {
    "text": "something which you not really care about if there's a duplicate for a small sequence of Windows or sequence of tles",
    "start": "1003639",
    "end": "1009639"
  },
  {
    "text": "the other processing guarantee it can provide is at most once in the sense you configure I'm okay to lose some data uh",
    "start": "1009639",
    "end": "1016079"
  },
  {
    "text": "for example uh say hardbeat monitors coming from some device and it's okay to lose a few tles it doesn't really matter",
    "start": "1016079",
    "end": "1022959"
  },
  {
    "text": "because your lat and sa and uh you're what you're losing is for a small time window say couple of seconds then that",
    "start": "1022959",
    "end": "1029280"
  },
  {
    "text": "if that's fine that's another Paradigm you can get as a pressing guarantee the third is also supported which is exactly",
    "start": "1029280",
    "end": "1035038"
  },
  {
    "text": "once and I think this is the most powerful because it's very difficult to achieve exactly once end to end and",
    "start": "1035039",
    "end": "1042400"
  },
  {
    "text": "support a whole lot of stores for example we have seen Cassandra talk yesterday right and and Aaron was",
    "start": "1042400",
    "end": "1047558"
  },
  {
    "text": "mentioning about uh C provides only something called as lightweight transactions in in the sparks in in some",
    "start": "1047559",
    "end": "1054840"
  },
  {
    "text": "of the other other worlds um there is the there there are caveats and what do we mean by n to and exactly once and I",
    "start": "1054840",
    "end": "1061120"
  },
  {
    "text": "believe n to and exactly once is difficult to achieve and even in the Apex world it's actually a combination",
    "start": "1061120",
    "end": "1066559"
  },
  {
    "text": "of compromises are done in a in a in a different way what end to end exactly wants is is is basically happening for",
    "start": "1066559",
    "end": "1074400"
  },
  {
    "text": "example this is the logic implemented for the Cassandra operator or the Kudo operators wherein when an operator gets",
    "start": "1074400",
    "end": "1080919"
  },
  {
    "text": "resumed after a crash or an application uh shut down what happens is that uh I'm",
    "start": "1080919",
    "end": "1086799"
  },
  {
    "text": "getting a replay of the tles uh for example in this case the the operator crashed at the second window at the",
    "start": "1086799",
    "end": "1093480"
  },
  {
    "text": "second tle and the operator gets reprovisioned on some other instance because of the checkpointing mechanism",
    "start": "1093480",
    "end": "1099320"
  },
  {
    "text": "tles in the first window are reprovisioned that means they resent into the second instance of the operator",
    "start": "1099320",
    "end": "1104799"
  },
  {
    "text": "but the operator logic is is intelligent enough to detect that it's a duplicate",
    "start": "1104799",
    "end": "1109960"
  },
  {
    "text": "window hence it will skip those windows it will not even write to Cassandra orus but in the second window it's really",
    "start": "1109960",
    "end": "1116960"
  },
  {
    "text": "difficult to tell because the operator got a handle only at the begin and and window logic handlers so what in this",
    "start": "1116960",
    "end": "1123840"
  },
  {
    "text": "case we do is we give a call back as a business function call back which an engineer can Implement to really say",
    "start": "1123840",
    "end": "1130679"
  },
  {
    "text": "this tle is is a duplicate that's being processed or Not by looking at an external store or looking at the same custom store and decide it's a duplicate",
    "start": "1130679",
    "end": "1137720"
  },
  {
    "text": "or not um that's how this is being solved in the Apex World wherein we want",
    "start": "1137720",
    "end": "1142919"
  },
  {
    "text": "to uh achieve exactly one semantics and it's difficult to achieve and to and exactly one semantics for systems which",
    "start": "1142919",
    "end": "1149520"
  },
  {
    "text": "don't have a two-phase coming protocol kind of things um I'll move on to the next part",
    "start": "1149520",
    "end": "1156159"
  },
  {
    "start": "1154000",
    "end": "1210000"
  },
  {
    "text": "of of of of of the talk which is uh these are what we saw till now is the basic building blocks of epex and what",
    "start": "1156159",
    "end": "1162520"
  },
  {
    "text": "we seeing now is something which will help the uh the data scientist and the",
    "start": "1162520",
    "end": "1167760"
  },
  {
    "text": "engineering community to build applications on top of of apex apex comes with a lot of operators as I was",
    "start": "1167760",
    "end": "1173880"
  },
  {
    "text": "saying uh one of it is our operator uh currently the python operator uh that's",
    "start": "1173880",
    "end": "1179080"
  },
  {
    "text": "currently in progress which I'm implementing is going to come soon in the next release there's already support",
    "start": "1179080",
    "end": "1184840"
  },
  {
    "text": "for H2O um Samoa and Del for example um some of these patterns uh might be not",
    "start": "1184840",
    "end": "1192520"
  },
  {
    "text": "really um not really used in all use cases for example s integration is more about streaming machine learning as",
    "start": "1192520",
    "end": "1199039"
  },
  {
    "text": "opposed to building your model on a batch batch mode and then trying to use that model in in the scoring thing I",
    "start": "1199039",
    "end": "1205360"
  },
  {
    "text": "believe some of these cases are redu cases for some more but nevertheless it's",
    "start": "1205360",
    "end": "1210640"
  },
  {
    "start": "1210000",
    "end": "1274000"
  },
  {
    "text": "integrated uh here is the typical uh flow of of of tles in the r operator",
    "start": "1210640",
    "end": "1216919"
  },
  {
    "text": "which Apex provides for um what what is done inside the r operator is you basically the the uh the uh the engineer",
    "start": "1216919",
    "end": "1226360"
  },
  {
    "text": "who is trying to implement uh the model as developed by say the data scientist can actually make sure that uh certain R",
    "start": "1226360",
    "end": "1234120"
  },
  {
    "text": "script is loaded as part of the operator so when the operator launches into the jvm uh as a jvm instance what typically",
    "start": "1234120",
    "end": "1240280"
  },
  {
    "text": "it happens in happens in the r operator is that it reads the script and then",
    "start": "1240280",
    "end": "1246080"
  },
  {
    "text": "creates an R engine within the memory of the jvm and then what you have is the stles",
    "start": "1246080",
    "end": "1252080"
  },
  {
    "text": "which are flowing through this through this jvm operator they get called back",
    "start": "1252080",
    "end": "1257240"
  },
  {
    "text": "to the r script or r function which is enabled as part of the r operat configuration and hence you can",
    "start": "1257240",
    "end": "1264360"
  },
  {
    "text": "score your tles uh in as uh if an r r script is your model scoring function",
    "start": "1264360",
    "end": "1271720"
  },
  {
    "text": "right um similar model uh is being developed",
    "start": "1271720",
    "end": "1277120"
  },
  {
    "start": "1274000",
    "end": "1422000"
  },
  {
    "text": "for python wherein it's it's got some more interesting features uh I think uh one of the interesting features uh is uh",
    "start": "1277120",
    "end": "1285000"
  },
  {
    "text": "is the nump integration uh basically what we have is a sequence of tles f to",
    "start": "1285000",
    "end": "1291320"
  },
  {
    "text": "the python epex operator jvm and each of this tle is is to be scored using the",
    "start": "1291320",
    "end": "1297600"
  },
  {
    "text": "python uh script for example someone developed a model and the model can be",
    "start": "1297600",
    "end": "1303880"
  },
  {
    "text": "serialized by the data scientist and put into the class path of the Apex",
    "start": "1303880",
    "end": "1309600"
  },
  {
    "text": "application the Apex application then it boots up is taking that serialized version deserializing it and uh and then",
    "start": "1309600",
    "end": "1318720"
  },
  {
    "text": "uh just before deing it creates a python interpreter within the memory space of the jvm so it's basically a mini",
    "start": "1318720",
    "end": "1325200"
  },
  {
    "text": "interpreter within the jvm itself we're taking this decentralized motion model from whatever has been done by the data",
    "start": "1325200",
    "end": "1331760"
  },
  {
    "text": "scientist and basically uh we're using the same python code to plug it into the",
    "start": "1331760",
    "end": "1337240"
  },
  {
    "text": "python interpreter within which is within the jvm and then we assume or we engineer the Upstream operator to do the",
    "start": "1337240",
    "end": "1343919"
  },
  {
    "text": "feature engineering for example uh the Upstream operator is in our example like aandra operator which is reading from",
    "start": "1343919",
    "end": "1350400"
  },
  {
    "text": "Cassandra and transforming the data which it enriched from Cassandra into a feature definition it comes back into",
    "start": "1350400",
    "end": "1355679"
  },
  {
    "text": "this python operator and this python operator then takes this feature engineering vector and pushes it as a",
    "start": "1355679",
    "end": "1361679"
  },
  {
    "text": "for example as a numi entry and uh the interesting feature which is happening here is that uh both",
    "start": "1361679",
    "end": "1369799"
  },
  {
    "text": "the jvm side of of things and the uh the the python interpret side of things are",
    "start": "1369799",
    "end": "1376039"
  },
  {
    "text": "referring to the same memory structures as as uh NPI structures that means we",
    "start": "1376039",
    "end": "1381120"
  },
  {
    "text": "are not wasting time in trying to convert a Java data structure into a NPI data structure and and forth and so",
    "start": "1381120",
    "end": "1387400"
  },
  {
    "text": "forth it's basically an optimized version for low latency as well I think the another interesting another",
    "start": "1387400",
    "end": "1393880"
  },
  {
    "text": "interesting thing which is coming here is the better Jill Global Inter Lock",
    "start": "1393880",
    "end": "1399600"
  },
  {
    "text": "which I think Julia mentioned a few few minutes back it's it's very uh it the",
    "start": "1399600",
    "end": "1405679"
  },
  {
    "text": "Java embeded python instance releases the Gill lock eagerly as opposed to other python implementations that's one",
    "start": "1405679",
    "end": "1411600"
  },
  {
    "text": "of the reasons why we're thinking of uh uh embedding the Java embedded python",
    "start": "1411600",
    "end": "1416919"
  },
  {
    "text": "within the JM process to actually to speed up scoring uh there are other interesting",
    "start": "1416919",
    "end": "1424240"
  },
  {
    "start": "1422000",
    "end": "1470000"
  },
  {
    "text": "um Integrations which are which come out of the box there's nothing more we had to do as a part of the framework because for example if you take some of us might",
    "start": "1424240",
    "end": "1430960"
  },
  {
    "text": "be familiar with h2os um wherein you can use the H2O ex data framework uh to to",
    "start": "1430960",
    "end": "1437120"
  },
  {
    "text": "to develop your models and that framework allows you to export just like python allows you to export a Model A",
    "start": "1437120",
    "end": "1442799"
  },
  {
    "text": "calized version or RS allow you to do that uh his also has got a mechanism to export your model which you have built",
    "start": "1442799",
    "end": "1448799"
  },
  {
    "text": "using history framework and this model comes on two versions The Mojo and the pojo they call it that's their version",
    "start": "1448799",
    "end": "1454400"
  },
  {
    "text": "of uh model export uh this comes um out of the box support from Apex because all",
    "start": "1454400",
    "end": "1460120"
  },
  {
    "text": "it does is it it it basically knows how to serialize and deserialize within the operator there's nothing fancy that's being done it's it it can be done as a",
    "start": "1460120",
    "end": "1466880"
  },
  {
    "text": "basic implementation in uh so we have seen three programming",
    "start": "1466880",
    "end": "1473559"
  },
  {
    "text": "language constructs transformed into a streaming engine in the sense that what we have done is each the data scientists",
    "start": "1473559",
    "end": "1480760"
  },
  {
    "text": "are not being forced to you know to change their choice of language they're",
    "start": "1480760",
    "end": "1486120"
  },
  {
    "text": "still coding in their own in their own uh resources they have and we're taking",
    "start": "1486120",
    "end": "1491600"
  },
  {
    "text": "that output which is the model scoring component pushing it into the jvm and then intermixing it with a low latency",
    "start": "1491600",
    "end": "1497799"
  },
  {
    "text": "streaming engine which will deal with feature engineering scalability resource management and a whole lot of other",
    "start": "1497799",
    "end": "1503559"
  },
  {
    "text": "things and embed this both of these as one unified framework and uh this allows",
    "start": "1503559",
    "end": "1509120"
  },
  {
    "text": "us to do a lot of different things for example um um yesterday uh Bob was",
    "start": "1509120",
    "end": "1514200"
  },
  {
    "text": "mentioning about you know candid deployment at the dark Channel I think what was the term used you can do some",
    "start": "1514200",
    "end": "1520240"
  },
  {
    "text": "of these deployments because what I can do is Implement a stream CC which goes",
    "start": "1520240",
    "end": "1525520"
  },
  {
    "text": "which takes the tles of a certain section of the streams to go into only this this new version of the operator",
    "start": "1525520",
    "end": "1533200"
  },
  {
    "text": "and rest of the traffic goes into the the production version so you can actually stream your subset of your",
    "start": "1533200",
    "end": "1539240"
  },
  {
    "text": "population into for example the first two instances of the model scoring and rest of it can go into the thing which",
    "start": "1539240",
    "end": "1545600"
  },
  {
    "text": "was the current production model version you can also do things like dorment models uh this is very interesting",
    "start": "1545600",
    "end": "1552080"
  },
  {
    "start": "1548000",
    "end": "1618000"
  },
  {
    "text": "because you can actually score uh you'll see here you have you have taken the input from Kafka and scoring which is",
    "start": "1552080",
    "end": "1558919"
  },
  {
    "text": "the lower scoring and is going back into TCP socket which is returning to the channel which made the call but you can",
    "start": "1558919",
    "end": "1564840"
  },
  {
    "text": "also do ad dorment model which is up which means that you're still doing two scorings only one is being used to uh",
    "start": "1564840",
    "end": "1572000"
  },
  {
    "text": "return a response the end Channel but the other is still being scored and being put into store interesting thing",
    "start": "1572000",
    "end": "1577720"
  },
  {
    "text": "is uh people might question this there's data collisions but you can the Cassandra operator which comes out of",
    "start": "1577720",
    "end": "1582919"
  },
  {
    "text": "Apex you can do interesting things like non- Collision data modeling out of the box um by just prepending or prefixing",
    "start": "1582919",
    "end": "1590720"
  },
  {
    "text": "your column name is something which is specific to the candry model there you can also do other interesting patterns",
    "start": "1590720",
    "end": "1596720"
  },
  {
    "text": "where like you know you have an ensemble model kind of pattern where in there's multiple operators which are which are part of your pipeline in ter in terms of",
    "start": "1596720",
    "end": "1603679"
  },
  {
    "text": "scoring and you can build one operator which takes the input of multiple scores",
    "start": "1603679",
    "end": "1608960"
  },
  {
    "text": "done in parallel and apply a basic assemble approach to it and then give the score as the response to the channel",
    "start": "1608960",
    "end": "1614919"
  },
  {
    "text": "at the end of the day that that kind of patterns is also possible um this is another interesting thing I",
    "start": "1614919",
    "end": "1620799"
  },
  {
    "start": "1618000",
    "end": "1692000"
  },
  {
    "text": "think which I believe is is a bit different than other streaming engin is is a command line client interface for",
    "start": "1620799",
    "end": "1626600"
  },
  {
    "text": "example you have a you have a certain threshold parameter which you deployed",
    "start": "1626600",
    "end": "1632159"
  },
  {
    "text": "as part of the application deployment right and then you can you can use that you can change the deployment or the the",
    "start": "1632159",
    "end": "1639080"
  },
  {
    "text": "threshold parameter at runtime without getting the application down for example if the value of a boundary or threshold",
    "start": "1639080",
    "end": "1645000"
  },
  {
    "text": "is four and you want to change it to five that can be done by using the application client uh command line",
    "start": "1645000",
    "end": "1650120"
  },
  {
    "text": "client you you launch your client and say I'm connecting to this application the application is still running after you connect to the application you say I",
    "start": "1650120",
    "end": "1656600"
  },
  {
    "text": "want to change this property of that operator that can be done you can also change the logical model of a dag and",
    "start": "1656600",
    "end": "1663120"
  },
  {
    "text": "that means if we to say that application came with a default set of say say for example tracing operator which traces",
    "start": "1663120",
    "end": "1669840"
  },
  {
    "text": "the performance of an operator thing you can inject a new operator into the dag",
    "start": "1669840",
    "end": "1675320"
  },
  {
    "text": "without getting the application down that means you can trace the performance of your application perhaps in a few minutes of a day by just launching your",
    "start": "1675320",
    "end": "1682039"
  },
  {
    "text": "command line client alter the dag and then let It capture some metrics alter",
    "start": "1682039",
    "end": "1687240"
  },
  {
    "text": "the dag again and come out and your application is still running this uh streaming engine as is without getting",
    "start": "1687240",
    "end": "1692519"
  },
  {
    "text": "it done I want to the last use case I want to touch base is the uh",
    "start": "1692519",
    "end": "1697880"
  },
  {
    "text": "customization power of Apex right so what we have seen is this set of operators and um and someone asked how",
    "start": "1697880",
    "end": "1706440"
  },
  {
    "text": "can I make sure I can ver this I know versioning is is a deeper subject I agree with what Jill mentioned",
    "start": "1706440",
    "end": "1713000"
  },
  {
    "text": "but uh there's also use cases for example when you have a dorment operator",
    "start": "1713000",
    "end": "1718039"
  },
  {
    "text": "model or candry model which are okay to experiment with and uh you would like to",
    "start": "1718039",
    "end": "1723240"
  },
  {
    "text": "not you know change a lot of things um but you still need to so version it and",
    "start": "1723240",
    "end": "1728880"
  },
  {
    "text": "get it out you can extend for example any of these operators in this case we are extending the python operator and",
    "start": "1728880",
    "end": "1734399"
  },
  {
    "text": "give it a Git Version aware python operator that means you have the basic python operator you're taking that",
    "start": "1734399",
    "end": "1740679"
  },
  {
    "text": "operator which came out of Apex or basic default implementation you wrapped it around with a construct of jit aw git",
    "start": "1740679",
    "end": "1746880"
  },
  {
    "text": "awareness in the sense that because all our models are serialized if a data",
    "start": "1746880",
    "end": "1752159"
  },
  {
    "text": "scientist to work in his own world and then commit his model by checking into git you want this Git Version to be",
    "start": "1752159",
    "end": "1759200"
  },
  {
    "text": "pulled every say for example every 20 minutes or whatever and then you want to get it out and use that as a model for",
    "start": "1759200",
    "end": "1764320"
  },
  {
    "text": "the next from the next window those kind of patterns can be implemented uh this is just an example to say that",
    "start": "1764320",
    "end": "1771960"
  },
  {
    "text": "customizability and extensibility is is is something which is given by Apex in in a really good way not that that that",
    "start": "1771960",
    "end": "1779159"
  },
  {
    "text": "that this comes out of the box you can do this what what is in here uh here are",
    "start": "1779159",
    "end": "1784279"
  },
  {
    "start": "1782000",
    "end": "1852000"
  },
  {
    "text": "some production references um uh Jeep used aex and they basically claim U sub",
    "start": "1784279",
    "end": "1789880"
  },
  {
    "text": "millisecond this this this is the content I took from from this from one of the marketing references so I can't",
    "start": "1789880",
    "end": "1797519"
  },
  {
    "text": "claim but what what I can definitely claim is I was uh previous to CB I was part of a company called thir metric and",
    "start": "1797519",
    "end": "1803480"
  },
  {
    "text": "we did we were doing 200 not Cassandra cluster kind of traffic at 240 countries",
    "start": "1803480",
    "end": "1808679"
  },
  {
    "text": "kind of thing and uh Apex really did well for the fraud visualization pipelines datal pipelines to a very good",
    "start": "1808679",
    "end": "1815120"
  },
  {
    "text": "extent it was pretty pretty low latency it was a single digit millisecond which I can V for um and I think there are",
    "start": "1815120",
    "end": "1822360"
  },
  {
    "text": "some other use cases in the community which talk about aex as power to connect to multiple sources anding like terad",
    "start": "1822360",
    "end": "1828679"
  },
  {
    "text": "datas and Vaas and Hadoop and S3 file systems which which refers to the lower",
    "start": "1828679",
    "end": "1834200"
  },
  {
    "text": "time to market value kind of um offerings U that's all I have for today",
    "start": "1834200",
    "end": "1841840"
  },
  {
    "text": "any questions [Applause]",
    "start": "1841840",
    "end": "1849990"
  }
]
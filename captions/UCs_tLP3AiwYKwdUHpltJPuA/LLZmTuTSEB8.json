[
  {
    "text": "foreign",
    "start": "8700",
    "end": "11700"
  },
  {
    "text": "thank you Dave and it's my pleasure to be here at Yao Brisbane",
    "start": "14759",
    "end": "20279"
  },
  {
    "text": "I'd like to start with the story of Deep dive performance analysis",
    "start": "20279",
    "end": "25800"
  },
  {
    "text": "this was a major microservice at Netflix and normally we analyze microservices",
    "start": "25800",
    "end": "33059"
  },
  {
    "text": "through a cloud-wide monitoring tool called Atlas Atlas gives us one minute averages of",
    "start": "33059",
    "end": "39719"
  },
  {
    "text": "metrics such as CPU utilization we have another open source instance",
    "start": "39719",
    "end": "45300"
  },
  {
    "text": "analysis tool called vector and since Atlas was so important I'd moved to Vector to look at the instances",
    "start": "45300",
    "end": "52320"
  },
  {
    "text": "for this microservice the graph of per second CPU utilization",
    "start": "52320",
    "end": "58140"
  },
  {
    "text": "for this microservice and you can see that it varies sometimes we're at 80 percent and sometimes CPU utilization",
    "start": "58140",
    "end": "64619"
  },
  {
    "text": "drops down to 30 percent this is interesting like I said this is a very important microservice Netflix",
    "start": "64619",
    "end": "70740"
  },
  {
    "text": "and it could be a sign of a performance issue but it could also just be a sign of natural load variation Netflix has",
    "start": "70740",
    "end": "79080"
  },
  {
    "text": "many customers on the internet and from one second to the next there may simply",
    "start": "79080",
    "end": "84780"
  },
  {
    "text": "be fewer clicks so I'm not really sure but it is quite interesting to have gone",
    "start": "84780",
    "end": "90420"
  },
  {
    "text": "down from a one minute average down to a one second average get more information on this I wanted to",
    "start": "90420",
    "end": "97320"
  },
  {
    "text": "go down further and I've called this before the one second problem of how do we drill down and visualize",
    "start": "97320",
    "end": "105000"
  },
  {
    "text": "less than one second but how would you do this if I said I would like to see this graph this metric",
    "start": "105000",
    "end": "113180"
  },
  {
    "text": "in tenths of a second or one hundredths of a second do you have a go-to visualization that",
    "start": "113180",
    "end": "120180"
  },
  {
    "text": "would solve this problem",
    "start": "120180",
    "end": "123079"
  },
  {
    "text": "many years ago I created subsequent offset heat maps to solve this problem it's only one solution and you might",
    "start": "125700",
    "end": "132420"
  },
  {
    "text": "come up with one that's better but I'd like to show you how this works hands up if you've already used subsequent offset heat Maps",
    "start": "132420",
    "end": "140220"
  },
  {
    "text": "that is one person so you'll all get to learn something",
    "start": "140220",
    "end": "145379"
  },
  {
    "text": "what I'm doing is I am painting from bottom to top each column is one",
    "start": "145379",
    "end": "151739"
  },
  {
    "text": "second and when I get to the top of a column I paint the next column from bottom to top",
    "start": "151739",
    "end": "159000"
  },
  {
    "text": "the color depth indicates in this case how many CPUs were busy for that time",
    "start": "159000",
    "end": "165900"
  },
  {
    "text": "range time is on both axes there's about 50 rows from top to bottom",
    "start": "165900",
    "end": "172140"
  },
  {
    "text": "and so the size of each of these buckets or pixels is about 20 milliseconds",
    "start": "172140",
    "end": "177840"
  },
  {
    "text": "this is great because I can now look at patterns within a second and also in",
    "start": "177840",
    "end": "183120"
  },
  {
    "text": "Computing things are often repetitive things happen at the same offset each second and I'll see a line that spreads",
    "start": "183120",
    "end": "190260"
  },
  {
    "text": "across this visualization this was the result the subsequent offset heat map for the microservice and",
    "start": "190260",
    "end": "197640"
  },
  {
    "text": "I could see that every so often there is these white columns that",
    "start": "197640",
    "end": "205500"
  },
  {
    "text": "stretch for about 50 sorry 500 milliseconds",
    "start": "205500",
    "end": "211200"
  },
  {
    "text": "so what might they be",
    "start": "211200",
    "end": "216360"
  },
  {
    "text": "that's quite interesting because previously when we looked at the line graph and we saw that CPU utilization",
    "start": "216360",
    "end": "221760"
  },
  {
    "text": "dropped we didn't know exactly what was going on maybe load was just lighter a little bit",
    "start": "221760",
    "end": "227879"
  },
  {
    "text": "for that second but now we have more information load isn't lighter loading fact goes to zero for 500 milliseconds",
    "start": "227879",
    "end": "234480"
  },
  {
    "text": "now I'm really interested in this problem because this really starts to sound like a performance issue",
    "start": "234480",
    "end": "240540"
  },
  {
    "text": "looking at this visualization the one I created I can Mouse over pixels and it gives me more information and I",
    "start": "240540",
    "end": "246959"
  },
  {
    "text": "discovered that for these 500 millisecond runs the CPU utilization was not zero",
    "start": "246959",
    "end": "254459"
  },
  {
    "text": "but one thread was active one CPU was active ah now this is getting even more",
    "start": "254459",
    "end": "260100"
  },
  {
    "text": "interesting so one thread is active but all the other threads stop that's an indication of perhaps a",
    "start": "260100",
    "end": "267060"
  },
  {
    "text": "locking issue where one thread is holding a global lock and a pool of thread workers can't make forward",
    "start": "267060",
    "end": "272759"
  },
  {
    "text": "progress until it's released the lock I looked at this using puff that's our",
    "start": "272759",
    "end": "281880"
  },
  {
    "text": "Linux standard profiler and that's generating the samples",
    "start": "281880",
    "end": "286919"
  },
  {
    "text": "and browsing the output of what was running I could even see it in text",
    "start": "286919",
    "end": "293580"
  },
  {
    "text": "the column I've circled shows the CPU that was active and normally because of interrupt latency I will get these",
    "start": "293580",
    "end": "299940"
  },
  {
    "text": "samples happening out of order across the many CPUs on the box and so I'm sampling usually at well in",
    "start": "299940",
    "end": "306840"
  },
  {
    "text": "this case it's 99 Hertz so I'm not sampling in lockstep with some periodic activity",
    "start": "306840",
    "end": "312300"
  },
  {
    "text": "but instead of just seeing these samples come in at random order for each of those 99 Hertz I see cpu19 is stuck on",
    "start": "312300",
    "end": "319560"
  },
  {
    "text": "at sample after sample after sample and nobody else is running I would think that cpu19 is holding the",
    "start": "319560",
    "end": "327780"
  },
  {
    "text": "lock everyone's blocked on so I'd love to know more about what is cpu19 doing",
    "start": "327780",
    "end": "334880"
  },
  {
    "text": "another visualization I've created previously is called C plane graphs particularly CPU flame graphs as anyone",
    "start": "334919",
    "end": "341160"
  },
  {
    "text": "used flame grafts before okay much better so we've got like 20 people I wanted to know this as a flame graph",
    "start": "341160",
    "end": "348300"
  },
  {
    "text": "I'll go through flame graphs later in this Keynote this was the flame graph I generated",
    "start": "348300",
    "end": "354240"
  },
  {
    "text": "just for those single thread or single CPU runs",
    "start": "354240",
    "end": "359759"
  },
  {
    "text": "a flame graph is a visualization of profiled Stack traces and explains the code responsible and straight away I",
    "start": "359759",
    "end": "365460"
  },
  {
    "text": "could look at this and say aha we are in code cash cleanup",
    "start": "365460",
    "end": "371960"
  },
  {
    "text": "this is Java this is the jvm it is a micro service that had about a gigabyte",
    "start": "372000",
    "end": "377520"
  },
  {
    "text": "of instruction text the way Java was compiling things and compiling things and compiling things and the code cash and job was getting so",
    "start": "377520",
    "end": "384539"
  },
  {
    "text": "large it had to do its own garbage collect the code cash garbage collector is not multi-threaded it's single threaded and it's blocking the rest of",
    "start": "384539",
    "end": "391560"
  },
  {
    "text": "java so this is definitely a performance problem that we can fix and we worked on that at Netflix",
    "start": "391560",
    "end": "398160"
  },
  {
    "text": "so that the code cache there's various tunables that come with it and also with the",
    "start": "398160",
    "end": "403380"
  },
  {
    "text": "microservice we were able to reduce the amount of code it had that's great that's an example of going",
    "start": "403380",
    "end": "409560"
  },
  {
    "text": "from a line graph of one second CPU utilization right down to the root cause",
    "start": "409560",
    "end": "415020"
  },
  {
    "text": "of those dips but at Netflix if I show this to other people the",
    "start": "415020",
    "end": "420900"
  },
  {
    "text": "reaction is that's nice but how do you get other people to do this as well",
    "start": "420900",
    "end": "426060"
  },
  {
    "text": "I accomplished this by sshing under systems and at Netflix we have so many instances that's not really feasible for",
    "start": "426060",
    "end": "432780"
  },
  {
    "text": "engineers instances come and go they Auto scale and so we're always interested in",
    "start": "432780",
    "end": "439380"
  },
  {
    "text": "being able to share our skills by as an expert in an area I should create a self-service gooey stuff and other",
    "start": "439380",
    "end": "445500"
  },
  {
    "text": "developers can do this as well with mouse clicks and so this became a",
    "start": "445500",
    "end": "452699"
  },
  {
    "text": "internal tool called flamescope that we have open sourced and with flame scope we can go through the same process of",
    "start": "452699",
    "end": "458940"
  },
  {
    "text": "clicking and starting an ending point and then looking at a flank graph for that range",
    "start": "458940",
    "end": "464460"
  },
  {
    "text": "in fact I'll do since it's so visual and a lot of what I do is not so visual a lot of what I do is Linux kernel",
    "start": "464460",
    "end": "470280"
  },
  {
    "text": "internals and the command line I would love to actually show this briefly",
    "start": "470280",
    "end": "475220"
  },
  {
    "text": "here is a flame scope and I can see in this example",
    "start": "479699",
    "end": "485580"
  },
  {
    "text": "we have some activity that's waking up every second for a little bit of time",
    "start": "485580",
    "end": "490740"
  },
  {
    "text": "and then going to sleep for a full second and then waking up again it's creating these diagonal lines",
    "start": "490740",
    "end": "498060"
  },
  {
    "text": "what might that be so again on the y-axis I've got the sub",
    "start": "498060",
    "end": "503340"
  },
  {
    "text": "second and each column is a full second and then I paint the next column",
    "start": "503340",
    "end": "508740"
  },
  {
    "text": "I see these diagonal lines that's a case where the programmer has said do some work and then sleep for 1.0 seconds and",
    "start": "508740",
    "end": "516899"
  },
  {
    "text": "then do some work again and what happens is you end up waking up at a progressively later offset each second",
    "start": "516899",
    "end": "523080"
  },
  {
    "text": "If instead you set up a high resolution timer to always wake up at the same Offset you get a horizontal line",
    "start": "523080",
    "end": "531440"
  },
  {
    "text": "there's some other patterns visible in here as well I have some perturbations on the right",
    "start": "531480",
    "end": "536580"
  },
  {
    "text": "and with flame scope we can click on any of these so I can just click on the background",
    "start": "536580",
    "end": "541980"
  },
  {
    "text": "what was happening over here and then I get a flame graph that shows",
    "start": "541980",
    "end": "547980"
  },
  {
    "text": "in that case we're doing that's right this particular flame scope I was looking at the startup of a micro",
    "start": "547980",
    "end": "554519"
  },
  {
    "text": "service we wanted to take this the startup time from 10 minutes down to one minute if possible",
    "start": "554519",
    "end": "560399"
  },
  {
    "text": "and so early on we are doing OS pre-touch memory Java is creating its",
    "start": "560399",
    "end": "567000"
  },
  {
    "text": "Heap and I can see that but I could also click on these",
    "start": "567000",
    "end": "573000"
  },
  {
    "text": "perturbations like over here just that and say what is that",
    "start": "573000",
    "end": "578100"
  },
  {
    "text": "okay at that point the application is running and we're starting to do some garbage collection",
    "start": "578100",
    "end": "585080"
  },
  {
    "text": "so you can imagine you can navigate a profile these are flame graphs I'll explain them in a moment you can",
    "start": "586380",
    "end": "591420"
  },
  {
    "text": "navigate everything that's going on and since I've always wanted to do this we added a button called enhance",
    "start": "591420",
    "end": "600260"
  },
  {
    "text": "wow all I'm doing is I'm setting the palette for the very low samples to be blue so",
    "start": "600420",
    "end": "607260"
  },
  {
    "text": "that they pop out but you can now see that there's actually this is the jvm starting up pre-touching",
    "start": "607260",
    "end": "614519"
  },
  {
    "text": "memory so it's allocating its Heap and now we're starting to run the application here's our garbage collect kicking in we've still got this diagonal",
    "start": "614519",
    "end": "621300"
  },
  {
    "text": "line and I can debug that by just clicking on it let's click on one of these",
    "start": "621300",
    "end": "626959"
  },
  {
    "text": "if you look closely you see orc Chone run this is a crunk this is a shell script",
    "start": "628740",
    "end": "636120"
  },
  {
    "text": "that's actually doing a sleep one and then doing some shell commands it was actually a misconfigured start script",
    "start": "636120",
    "end": "642360"
  },
  {
    "text": "that was trying to do something failing and then sleeping for one second and trying again",
    "start": "642360",
    "end": "647519"
  },
  {
    "text": "so I can disable that and get some CPU Cycles back",
    "start": "647519",
    "end": "652339"
  },
  {
    "text": "so that's flame scope and sometimes unless just perturbations",
    "start": "654600",
    "end": "659940"
  },
  {
    "text": "sometimes it's very interesting patterns that you can browse and explore and and they pop out in ways that they would not",
    "start": "659940",
    "end": "667019"
  },
  {
    "text": "in line graphs",
    "start": "667019",
    "end": "669920"
  },
  {
    "text": "there are three factors for successful root cause analysis in an environment like Netflix",
    "start": "678000",
    "end": "683399"
  },
  {
    "text": "there's observability there's having access to the metrics and the stack traces and the symbols so that we can do",
    "start": "683399",
    "end": "688920"
  },
  {
    "text": "things like this in this case when I started at Netflix we couldn't run a system profiler on",
    "start": "688920",
    "end": "696180"
  },
  {
    "text": "Java because Java didn't have the frame pointer and we couldn't walk at stacks and that's now been fixed so we can do",
    "start": "696180",
    "end": "702240"
  },
  {
    "text": "things like flame scope where we can analyze Java and node.js and other languages as well",
    "start": "702240",
    "end": "707880"
  },
  {
    "text": "there's methodology which is what do you do now that you're given all of this these metrics and information",
    "start": "707880",
    "end": "713940"
  },
  {
    "text": "and the final one is velocity and velocity at Netflix is about developing features as quickly as",
    "start": "713940",
    "end": "721079"
  },
  {
    "text": "possible getting out of the way of the developers empowering the developers to be more effective and faster",
    "start": "721079",
    "end": "727620"
  },
  {
    "text": "and whenever I work on the performance and operating systems team whenever I",
    "start": "727620",
    "end": "733260"
  },
  {
    "text": "develop tools that go deep it's then about enabling the other developers how can I create a self-service GUI so they",
    "start": "733260",
    "end": "739800"
  },
  {
    "text": "can do it as well this keynote is about root cause analysis and Netflix I've drawn a",
    "start": "739800",
    "end": "745380"
  },
  {
    "text": "diagram to show the Netflix stack and various tools I'll summarize",
    "start": "745380",
    "end": "750480"
  },
  {
    "text": "this talk is about exposure you aren't expected to learn all of these tools but it's helpful to know that they exist",
    "start": "750480",
    "end": "757440"
  },
  {
    "text": "and then sometime later you might think ah there was a tool I saw this keynote by Brendan I can look up the slides",
    "start": "757440",
    "end": "763740"
  },
  {
    "text": "online and remember what that is practically everything I'm talking about is open source and so you can read about",
    "start": "763740",
    "end": "769980"
  },
  {
    "text": "you can read about them you can fetch the source and run it yourself",
    "start": "769980",
    "end": "775160"
  },
  {
    "text": "this is this is two this is four talks in one I",
    "start": "777060",
    "end": "782579"
  },
  {
    "text": "will summarize the Netflix Cloud I will talk about methodologies I'll then do",
    "start": "782579",
    "end": "787800"
  },
  {
    "text": "Cloud analysis and show you the tools we're using right now at Netflix and then instance analysis",
    "start": "787800",
    "end": "794839"
  },
  {
    "text": "I only gave this talk once before in 2014 and there's an old screenshot of Atlas our cloudwide monitoring tool",
    "start": "795180",
    "end": "801720"
  },
  {
    "text": "that's changed and so is many things so we've moved from Asgard to Spinnaker",
    "start": "801720",
    "end": "806880"
  },
  {
    "text": "for doing Cloud deployments our internal tools soap we're now rolling out Zipkin we're starting to adopt grpc and so on",
    "start": "806880",
    "end": "814200"
  },
  {
    "text": "and so on the last three I worked on myself the Java frame pointer ebpf and pmcs and I'm excited to be able to share",
    "start": "814200",
    "end": "820680"
  },
  {
    "text": "some of the things I did with you to summarize Netflix who has Netflix who",
    "start": "820680",
    "end": "826920"
  },
  {
    "text": "who has Netflix at home that's pretty much everyone so thank you very much for being Netflix members",
    "start": "826920",
    "end": "835040"
  },
  {
    "text": "we have a very large ec2 Cloud over 150",
    "start": "835040",
    "end": "840600"
  },
  {
    "text": "000 instances and we're hitting 34 of the US internet traffic at night",
    "start": "840600",
    "end": "847500"
  },
  {
    "text": "and we have over 130 000 members",
    "start": "847500",
    "end": "852740"
  },
  {
    "text": "the satisfaction so that when you log in you're using the interface it's fast there's not buffering and it's also",
    "start": "854579",
    "end": "860459"
  },
  {
    "text": "about Netflix cost so that it's not too expensive for the rest of Netflix to be running all the",
    "start": "860459",
    "end": "866639"
  },
  {
    "text": "wonderful things we run these slides will be shared online and I have a slide in there for the acronyms",
    "start": "866639",
    "end": "872820"
  },
  {
    "text": "in case I don't explain them so the first section is on the Netflix",
    "start": "872820",
    "end": "878040"
  },
  {
    "text": "cloud just to summarize this we're deployed on ec2 I mentioned that",
    "start": "878040",
    "end": "884399"
  },
  {
    "text": "we're also using elastic load balancers in S3 on ec2 we have a lot of Cassandra",
    "start": "884399",
    "end": "890220"
  },
  {
    "text": "elasticsearch EV cache and of course the applications which are microservices",
    "start": "890220",
    "end": "897139"
  },
  {
    "text": "the microservices we have include authentication user data personalization viewing history",
    "start": "897360",
    "end": "904500"
  },
  {
    "text": "and there's two main apis the client devices access them from",
    "start": "904500",
    "end": "910079"
  },
  {
    "text": "we also have apart from the Amazon ec2 Cloud we also have a CDN called the open",
    "start": "910079",
    "end": "917339"
  },
  {
    "text": "connect appliance which are physical boxes running FreeBSD when you first log into Netflix and",
    "start": "917339",
    "end": "923160"
  },
  {
    "text": "browse around you're coming from the Amazon ec2 Cloud and when you hit play you're coming from a physical BSD box",
    "start": "923160",
    "end": "930300"
  },
  {
    "text": "that's hopefully very close to you that's at the ISP",
    "start": "930300",
    "end": "935060"
  },
  {
    "text": "we have a culture of freedom and responsibility the culture memo is true used to be a",
    "start": "936600",
    "end": "942120"
  },
  {
    "text": "deck that's had 18 million views and for developers you have development",
    "start": "942120",
    "end": "948480"
  },
  {
    "text": "Freedom you can purchase and use cloud instances without approvals you can try out new technologies and prototype them",
    "start": "948480",
    "end": "954540"
  },
  {
    "text": "it makes my job at Netflix exciting because there's always new things people are trying out and they want my help with to do performance evaluations and",
    "start": "954540",
    "end": "961800"
  },
  {
    "text": "Analysis the cloud technologies that we use",
    "start": "961800",
    "end": "967139"
  },
  {
    "text": "they're usually open source so Linux Java Cassandra we also write and publish",
    "start": "967139",
    "end": "973139"
  },
  {
    "text": "things ourselves so on netflix.github.io",
    "start": "973139",
    "end": "978300"
  },
  {
    "text": "here's an idea of a typical base Ami instance",
    "start": "979500",
    "end": "985380"
  },
  {
    "text": "the microservice teams can customize them of course and so some of them don't run Java they're running node.js or",
    "start": "985380",
    "end": "991019"
  },
  {
    "text": "they're running golang but a typical one would look like this with Linux Java and",
    "start": "991019",
    "end": "996240"
  },
  {
    "text": "various standard things that we ship with it for root cause analysis on the bottom",
    "start": "996240",
    "end": "1002120"
  },
  {
    "text": "left that includes things like f Trace Perth BCC and ebpf and I'll summarize them later",
    "start": "1002120",
    "end": "1009279"
  },
  {
    "text": "another way to understand Netflix is to go through five key issues and how the Netflix cloud is already architected to",
    "start": "1009560",
    "end": "1016040"
  },
  {
    "text": "solve them the first is load if load increases",
    "start": "1016040",
    "end": "1022519"
  },
  {
    "text": "we're using Auto scaling groups a lot of you may be already doing this",
    "start": "1022519",
    "end": "1027558"
  },
  {
    "text": "so we have a custom scaling policy that might be based on load average CPU utilization latency and that can",
    "start": "1027559",
    "end": "1036558"
  },
  {
    "text": "automatically add instances as load increases this is great for customers because if there is a load increase",
    "start": "1036559",
    "end": "1043280"
  },
  {
    "text": "then we're already deploying the work around to improve performance it's also good for engineers since if there is a",
    "start": "1043280",
    "end": "1050299"
  },
  {
    "text": "load increase in the middle of the night Netflix can often Auto scale itself out of the problem and so as an engineer",
    "start": "1050299",
    "end": "1057020"
  },
  {
    "text": "that may avoid getting paged and so you come into work the next morning at nine o'clock and then you deal with it",
    "start": "1057020",
    "end": "1062960"
  },
  {
    "text": "Netflix has paid a bit more money to Auto scale up but all the engineers have got to sleep through the night so that's",
    "start": "1062960",
    "end": "1068720"
  },
  {
    "text": "a great thing another important aspect is",
    "start": "1068720",
    "end": "1074179"
  },
  {
    "text": "what happens with a bad push so we have red black Auto scaling groups",
    "start": "1074179",
    "end": "1079220"
  },
  {
    "text": "and they were always rolling out new software versions as a new auto scaling group and",
    "start": "1079220",
    "end": "1086240"
  },
  {
    "text": "then we'll use the elastic load balancers to slowly siphon off traffic from the current active one to the new one",
    "start": "1086240",
    "end": "1092900"
  },
  {
    "text": "while the engineers are looking at metrics and dashboards and if things look bad they can simply",
    "start": "1092900",
    "end": "1098059"
  },
  {
    "text": "roll back to the old ASG those instances are still there they're warm Java's still running the Heap is allocated",
    "start": "1098059",
    "end": "1104480"
  },
  {
    "text": "but if things look okay they can keep moving the traffic over and then eventually shut down the old ASG",
    "start": "1104480",
    "end": "1110720"
  },
  {
    "text": "we can also use canaries and automated Canary analysis to create a single instance and then see how that performs",
    "start": "1110720",
    "end": "1119080"
  },
  {
    "text": "instance failures we have histrix for timeouts plus many many other features and also ribbon",
    "start": "1119299",
    "end": "1126440"
  },
  {
    "text": "which is our internal tool or grpc which provides more redundancy",
    "start": "1126440",
    "end": "1131900"
  },
  {
    "text": "if something bad happens to an instance and I've done this myself at Netflix by accidentally panicking instances it's",
    "start": "1131900",
    "end": "1139400"
  },
  {
    "text": "not a big problem the requests that have gone to that instance automatically time out higher up in in",
    "start": "1139400",
    "end": "1146000"
  },
  {
    "text": "the Netflix Cloud stack and go to backup instances so as a customer of Netflix",
    "start": "1146000",
    "end": "1153620"
  },
  {
    "text": "you may you may have a 100 millisecond latency as you're browsing the UI you may not notice that but what's happened",
    "start": "1153620",
    "end": "1159679"
  },
  {
    "text": "is the instance has been terminated or is panicked or something very bad happened so it's a fault tolerant architecture",
    "start": "1159679",
    "end": "1167740"
  },
  {
    "text": "we also survive faults at the region level or the audit the availability Zone level",
    "start": "1167780",
    "end": "1174140"
  },
  {
    "text": "and we've got Zool 2 which is our proxy and we can redirect all traffic from one",
    "start": "1174140",
    "end": "1180020"
  },
  {
    "text": "region to another and we simulate this many times so that we can check that",
    "start": "1180020",
    "end": "1185720"
  },
  {
    "text": "everything works that simulation is part of chaos engineering",
    "start": "1185720",
    "end": "1191539"
  },
  {
    "text": "which is the last key part of the Netflix architecture of why things work so well",
    "start": "1191539",
    "end": "1199160"
  },
  {
    "text": "with chaos engineering we have software that will automatically terminate instances",
    "start": "1199160",
    "end": "1204200"
  },
  {
    "text": "we'll do the available simulate availability Zone failures we'll simulate High latency on dependencies",
    "start": "1204200",
    "end": "1210380"
  },
  {
    "text": "as a developer you have to write your code to deal with these situations because they will happen",
    "start": "1210380",
    "end": "1217100"
  },
  {
    "text": "and if you don't believe it will happen when you start deploying applications it happens so it becomes a reality real",
    "start": "1217100",
    "end": "1224120"
  },
  {
    "text": "quick and so when I joined Netflix and I started deploying my my own applications",
    "start": "1224120",
    "end": "1229240"
  },
  {
    "text": "I was manually setting things up and I'll just SSH on and do this config file I haven't really saved it in the right",
    "start": "1229240",
    "end": "1236299"
  },
  {
    "text": "repositories I know but it should be okay and then you get the email saying your instance has been terminated by the",
    "start": "1236299",
    "end": "1242299"
  },
  {
    "text": "chaos by chaos engineering and it's like wait I should have saved my config I should",
    "start": "1242299",
    "end": "1248000"
  },
  {
    "text": "have done all these things so quickly you'll learn that you have to take this seriously and you have to design your",
    "start": "1248000",
    "end": "1254059"
  },
  {
    "text": "application to be fault tolerant so you learn that the hard way so I've redrawn that diagram of the",
    "start": "1254059",
    "end": "1260960"
  },
  {
    "text": "Netflix stack and here's the highlighted in bold the areas that make us fault",
    "start": "1260960",
    "end": "1267140"
  },
  {
    "text": "tolerant so elastic load balances Auto scaling clusters Auto scaling groups availability zones and at the top of the",
    "start": "1267140",
    "end": "1273919"
  },
  {
    "text": "stack the different libraries we can use to provide fault tolerance as well",
    "start": "1273919",
    "end": "1279160"
  },
  {
    "text": "in the second section I want to summarize methodology like I said earlier it's great to have",
    "start": "1281539",
    "end": "1286820"
  },
  {
    "text": "access to all the metrics and but the problem then becomes what do you do with them",
    "start": "1286820",
    "end": "1293480"
  },
  {
    "text": "to start with why do we do Rico's performance analysis",
    "start": "1293480",
    "end": "1298240"
  },
  {
    "text": "High latency is a common reason I get pulled into doing this with high latency there is some logical",
    "start": "1298940",
    "end": "1305840"
  },
  {
    "text": "issue and auto scaling often doesn't work it is a type of issue you can't always",
    "start": "1305840",
    "end": "1312620"
  },
  {
    "text": "Auto scale yourself out of so with high latency often we do need to get to the bottom of it",
    "start": "1312620",
    "end": "1318620"
  },
  {
    "text": "growth or cost at Netflix is another reason we want to do this so that their costs don't get out of",
    "start": "1318620",
    "end": "1324260"
  },
  {
    "text": "hand and also upgrades you can't stay on the same Linux kernel",
    "start": "1324260",
    "end": "1329840"
  },
  {
    "text": "version forever you can't stay on the same Java version forever you can't say stay on the same Cassandra version forever and with new versions often",
    "start": "1329840",
    "end": "1338059"
  },
  {
    "text": "performance regresses because they've changed how things are configured and you have to update your configuration file or maybe there's just a software",
    "start": "1338059",
    "end": "1344240"
  },
  {
    "text": "regression with a new version and so that's another case where we are often doing root cause analysis",
    "start": "1344240",
    "end": "1351020"
  },
  {
    "text": "because we know we need to upgrade to the next version but it's 10 slower so",
    "start": "1351020",
    "end": "1356120"
  },
  {
    "text": "we'd like to identify why and work with the developers and get that fixed",
    "start": "1356120",
    "end": "1361360"
  },
  {
    "text": "for cloud methodologies there's a number you can use one of them",
    "start": "1362059",
    "end": "1369740"
  },
  {
    "text": "is resource analysis and that's where you check if any of the physical instance resources are",
    "start": "1369740",
    "end": "1375799"
  },
  {
    "text": "exhausted like CPU disk and Network there's metric and event correlations dashboards are great for this where",
    "start": "1375799",
    "end": "1382159"
  },
  {
    "text": "you're putting the same time series over top of each other and you try and see when latency went up what else happened",
    "start": "1382159",
    "end": "1389600"
  },
  {
    "text": "there's latency drill downs I'm looking at my application request I want to decompose it into into the weight States",
    "start": "1389600",
    "end": "1395780"
  },
  {
    "text": "and then keep drilling down until I get to the bottom the root cause of why that",
    "start": "1395780",
    "end": "1400820"
  },
  {
    "text": "application request was so long and the last one to put there is the red method that's microservice focused",
    "start": "1400820",
    "end": "1408919"
  },
  {
    "text": "and that's a great methodology where you list out your micro services and you say",
    "start": "1408919",
    "end": "1414380"
  },
  {
    "text": "for each micro service I just want three metrics the rate the request rate the",
    "start": "1414380",
    "end": "1419840"
  },
  {
    "text": "errors and the duration and you can imagine you can create a red method dashboard where you list your",
    "start": "1419840",
    "end": "1425120"
  },
  {
    "text": "microservices and you have those three key metrics we're often drowning in metrics as many",
    "start": "1425120",
    "end": "1430159"
  },
  {
    "text": "many metrics so having a methodology that whittles it down to three but also encourages you to not Overlook",
    "start": "1430159",
    "end": "1437659"
  },
  {
    "text": "anything is really useful so you make sure you you do have red coverage for every micro service",
    "start": "1437659",
    "end": "1444820"
  },
  {
    "text": "going down to the instances log analysis micro benchmarking drill",
    "start": "1444860",
    "end": "1450380"
  },
  {
    "text": "down analysis A methodology I came up with a while ago is the use method",
    "start": "1450380",
    "end": "1455900"
  },
  {
    "text": "and that's where you draw a functional diagram of the system cpu's memory disk controllers Network controllers disks",
    "start": "1455900",
    "end": "1462500"
  },
  {
    "text": "all of the components where data flows including the buses and then for each of those components",
    "start": "1462500",
    "end": "1468799"
  },
  {
    "text": "you only want three metrics utilization saturation and errors",
    "start": "1468799",
    "end": "1474080"
  },
  {
    "text": "again this is a useful methodology because you don't have blind spots you instead",
    "start": "1474080",
    "end": "1479360"
  },
  {
    "text": "of just consuming what the system gives you it's posing questions you ask of the system",
    "start": "1479360",
    "end": "1484580"
  },
  {
    "text": "and also it is whittling it down to just three metrics for each of those components",
    "start": "1484580",
    "end": "1490280"
  },
  {
    "text": "now I've recourse many issues because I'm reminded to go and check the buses and discover that we have a memory bus",
    "start": "1490280",
    "end": "1497240"
  },
  {
    "text": "saturation or CPU interconnect saturation",
    "start": "1497240",
    "end": "1501639"
  },
  {
    "text": "and finally just as an example of a anti-methodology the bad instance anti-method",
    "start": "1503900",
    "end": "1510919"
  },
  {
    "text": "this is something I see from time to time I can understand the motivation for doing it that's where you have an",
    "start": "1510919",
    "end": "1516140"
  },
  {
    "text": "instance that has high latency and you think I'll just terminate it and hope the problem goes away",
    "start": "1516140",
    "end": "1521240"
  },
  {
    "text": "and so sometimes that might be cost effective but I just want to remind people that can be an early warning of a",
    "start": "1521240",
    "end": "1527659"
  },
  {
    "text": "bigger issue and so it can be helpful to root cause these whenever possible so that next time this happens",
    "start": "1527659",
    "end": "1535340"
  },
  {
    "text": "it's not 10 instances instead of one",
    "start": "1535340",
    "end": "1539559"
  },
  {
    "text": "now summarize the cloud analysis tools",
    "start": "1543039",
    "end": "1547960"
  },
  {
    "text": "since I'm going to go through many tools that we use at Netflix I've drawn this flow diagram or a mental",
    "start": "1550220",
    "end": "1556039"
  },
  {
    "text": "map to show how they fit together so that we don't get too lost and again this is just for exposure you may be",
    "start": "1556039",
    "end": "1562220"
  },
  {
    "text": "doing very similar tools I might mention a tool you don't have something for and so that can be a gap that you might want",
    "start": "1562220",
    "end": "1568400"
  },
  {
    "text": "to explore and so we often start with Atlas alerts",
    "start": "1568400",
    "end": "1573700"
  },
  {
    "text": "where it will give us an issue that we need to investigate and then we start going through the other tools",
    "start": "1573700",
    "end": "1581440"
  },
  {
    "text": "the main metric we keep we alert on at Netflix is streams per second and that",
    "start": "1582380",
    "end": "1588260"
  },
  {
    "text": "is how many times members are hitting play this is a daily graph of stream streams",
    "start": "1588260",
    "end": "1594559"
  },
  {
    "text": "per second and it follows a certain pattern and if that deviates even by a small tiny tiny amount it will create",
    "start": "1594559",
    "end": "1600620"
  },
  {
    "text": "alerts so there's a tiny deviation over here that's almost certainly created alerts and then I get them in my mailbox",
    "start": "1600620",
    "end": "1608720"
  },
  {
    "text": "this is my Atlas alerts it's a little hard to read here but I",
    "start": "1608720",
    "end": "1615200"
  },
  {
    "text": "can show you the makeup of an atlas alert this is one from a few days ago",
    "start": "1615200",
    "end": "1621140"
  },
  {
    "text": "so I'm showing you the the very latest Netflix internal tools how they how they",
    "start": "1621140",
    "end": "1626419"
  },
  {
    "text": "look like right now we start off with a new",
    "start": "1626419",
    "end": "1632059"
  },
  {
    "text": "tool that we've developed called Winston there's a Netflix Tech blog on it for automated diagnosis and Remediation",
    "start": "1632059",
    "end": "1638840"
  },
  {
    "text": "and that can look at an alert and can say maybe it's related to this fast",
    "start": "1638840",
    "end": "1645140"
  },
  {
    "text": "property change or a new ASG has been deployed it has programmable run books",
    "start": "1645140",
    "end": "1651559"
  },
  {
    "text": "and so our core SRE team and other teams were following the same mental methodology when alerts were happening",
    "start": "1651559",
    "end": "1658580"
  },
  {
    "text": "and this is a way for them to program it and then get that in the email Kronos is our event logging tool these",
    "start": "1658580",
    "end": "1664760"
  },
  {
    "text": "are possible related events and then links to Atlas dashboards",
    "start": "1664760",
    "end": "1670400"
  },
  {
    "text": "and Atlas dashboards and metrics helps us lets us drill down it's really great to get them the actual pngs in the email",
    "start": "1670400",
    "end": "1678620"
  },
  {
    "text": "because when you get this alert you may not be connected to the Netflix VPN and",
    "start": "1678620",
    "end": "1684080"
  },
  {
    "text": "it might take you a minute to connect to the VPN and in that minute you can start looking at the graphs and start mentally",
    "start": "1684080",
    "end": "1690440"
  },
  {
    "text": "working on the issue and then you connect to the VPN and then you you can click on the links so it's great to get those images in the email",
    "start": "1690440",
    "end": "1698620"
  },
  {
    "text": "many of them will link to dashboards we make every every service team has dashboards make big use of dashboards",
    "start": "1698659",
    "end": "1705200"
  },
  {
    "text": "here's an example of the Netflix performance vitals dashboard where we go through different metrics",
    "start": "1705200",
    "end": "1710539"
  },
  {
    "text": "that's one I tend to use a lot dashboards themselves are another",
    "start": "1710539",
    "end": "1717440"
  },
  {
    "text": "example of a methodology a checklist methodology because when you're building it you're choosing what am I going to",
    "start": "1717440",
    "end": "1723620"
  },
  {
    "text": "show people first what am I going to show people second and you're making that evaluation of what's most important and what's the",
    "start": "1723620",
    "end": "1729980"
  },
  {
    "text": "sequence you want people to look through we've been developing a new more",
    "start": "1729980",
    "end": "1736220"
  },
  {
    "text": "flexible dashboard approach a tool called Lumen and there's a Netflix Tech",
    "start": "1736220",
    "end": "1741260"
  },
  {
    "text": "blog on it that showed that they've got a lumen dashboard to tell us when it's Burger day in the Netflix kitchen so we",
    "start": "1741260",
    "end": "1747559"
  },
  {
    "text": "can go to go slash Burger they can do more things than the older Atlas dashboard",
    "start": "1747559",
    "end": "1753679"
  },
  {
    "text": "metrics looks like this so there's ways to select the application the",
    "start": "1753679",
    "end": "1759980"
  },
  {
    "text": "metrics I want to view the presentation some min max average and then I've got my interactive graph",
    "start": "1759980",
    "end": "1767860"
  },
  {
    "text": "our Atlas metric system is one of the largest Micro Services we have at one point it was reaching to 10 of the",
    "start": "1768200",
    "end": "1774919"
  },
  {
    "text": "Netflix footprint which is a little bit amazing to think about it means that for every nine or ten",
    "start": "1774919",
    "end": "1781399"
  },
  {
    "text": "instances you deploy you have to deploy one more instance just to monitor the other nine or ten",
    "start": "1781399",
    "end": "1787100"
  },
  {
    "text": "and the reason is atlas is storing millions and millions of metrics in memory so that we can",
    "start": "1787100",
    "end": "1793940"
  },
  {
    "text": "pull up these graphs for anything I'm going to pull up this graph for SPS for this region for this application for",
    "start": "1793940",
    "end": "1799460"
  },
  {
    "text": "this device type and it's it's immediately fast for this time range",
    "start": "1799460",
    "end": "1805179"
  },
  {
    "text": "and we put all the metrics in one system system metrics application metrics",
    "start": "1805940",
    "end": "1811360"
  },
  {
    "text": "Kronos is then how we coord we communicate changes that have happened",
    "start": "1813200",
    "end": "1819398"
  },
  {
    "text": "so I can select my scope time range event log and then I can filter so the GUI is",
    "start": "1819919",
    "end": "1826340"
  },
  {
    "text": "interactive I can quickly filter down and just look at events that are most interesting",
    "start": "1826340",
    "end": "1832100"
  },
  {
    "text": "we've debugged many issues just from Kronos because you can pull up the event that's caused the issue and the Times",
    "start": "1832100",
    "end": "1837620"
  },
  {
    "text": "line up so very important and all service teams need to publish through Kronos",
    "start": "1837620",
    "end": "1843679"
  },
  {
    "text": "so a really great tool slalom is our tool for doing dependency",
    "start": "1843679",
    "end": "1848960"
  },
  {
    "text": "graphing and have got an application and you can see the flow of traffic going to",
    "start": "1848960",
    "end": "1854059"
  },
  {
    "text": "dependencies and their dependencies and so on",
    "start": "1854059",
    "end": "1858220"
  },
  {
    "text": "and the traffic volume this used to be based on the Netflix sulp which was our dependency Tracer but",
    "start": "1859100",
    "end": "1867260"
  },
  {
    "text": "we've now switched it to be Zipkin based and Zipkin has its own UI",
    "start": "1867260",
    "end": "1873080"
  },
  {
    "text": "so that we can look at dependency latency as well and the final internal tool",
    "start": "1873080",
    "end": "1881120"
  },
  {
    "text": "that we've developed is pixel that's for AWS usage and the other tools are great for",
    "start": "1881120",
    "end": "1888559"
  },
  {
    "text": "customer satisfaction resolving latency this one is for Netflix cost so that we",
    "start": "1888559",
    "end": "1894200"
  },
  {
    "text": "can understand our cost and growth and then Target resources to where applications are growing",
    "start": "1894200",
    "end": "1900620"
  },
  {
    "text": "this is the site had to redact the most so I've had to put gray boxes on it because it actually has the Netflix",
    "start": "1900620",
    "end": "1906740"
  },
  {
    "text": "Amazon bill as as part of this UI so quick way to find out where the where",
    "start": "1906740",
    "end": "1913520"
  },
  {
    "text": "that money is going there is one more tool although we didn't develop it and that's Slack",
    "start": "1913520",
    "end": "1921080"
  },
  {
    "text": "and I used to be on I did some SRE on call for Netflix",
    "start": "1921080",
    "end": "1926179"
  },
  {
    "text": "and I found a a quick Diagnostics methodology was to say in slack late in",
    "start": "1926179",
    "end": "1934880"
  },
  {
    "text": "the main core chat room that everyone looks at latency is high in this region for their service and quite often the",
    "start": "1934880",
    "end": "1942020"
  },
  {
    "text": "engineers would then confess and say oh yeah that's my fault I pushed a change I'll roll it back",
    "start": "1942020",
    "end": "1948200"
  },
  {
    "text": "so it turns out just communicating with everyone can be a great Diagnostics tool",
    "start": "1948200",
    "end": "1955240"
  },
  {
    "text": "so there's the Netflix Cloud analysis process including Slack and I've redrawn it so that it's generic",
    "start": "1955580",
    "end": "1962480"
  },
  {
    "text": "so you can think about how that might apply to your environment",
    "start": "1962480",
    "end": "1966880"
  },
  {
    "text": "instance analysis",
    "start": "1971240",
    "end": "1974440"
  },
  {
    "text": "now these are the tools we use to understand an instance",
    "start": "1977419",
    "end": "1982640"
  },
  {
    "text": "I've drawn a generic diagram of the Linux kernel so that I could",
    "start": "1982640",
    "end": "1988580"
  },
  {
    "text": "decorate it with all the tools that we can use I forget these tools I have this printed",
    "start": "1988580",
    "end": "1994100"
  },
  {
    "text": "out on my wall at work so I can refer to it myself and if you're using these if I'm using",
    "start": "1994100",
    "end": "2000220"
  },
  {
    "text": "these tools to solve problems at Netflix it then becomes a problem of velocity we don't actually want Engineers sshing",
    "start": "2000220",
    "end": "2006399"
  },
  {
    "text": "onto instances to run all of these Linux tools we want to then turn it into a GUI a UI that Engineers can click on that's",
    "start": "2006399",
    "end": "2013840"
  },
  {
    "text": "self-service the first one to mention is statistics",
    "start": "2013840",
    "end": "2020940"
  },
  {
    "text": "and vmstat pidstatsar and so on these work mostly normally when we run them in",
    "start": "2021580",
    "end": "2028600"
  },
  {
    "text": "the ec2 cloud from The Host and if we can't see something because",
    "start": "2028600",
    "end": "2033940"
  },
  {
    "text": "it's in the hypervisor or as part of the network we can do some micro benchmarking to get information",
    "start": "2033940",
    "end": "2040980"
  },
  {
    "text": "there is an exception to Linux statistics and that's containers currently the links can turn the Linux",
    "start": "2041799",
    "end": "2047620"
  },
  {
    "text": "kernel Performance Tools are not all Container aware so if you run tools within a container",
    "start": "2047620",
    "end": "2053500"
  },
  {
    "text": "some of them are showing you the just the container and some of them are showing you the full host it's getting better there's always lots and lots of",
    "start": "2053500",
    "end": "2058839"
  },
  {
    "text": "work happening in Linux c groups are adding metrics",
    "start": "2058839",
    "end": "2063878"
  },
  {
    "text": "so over time we'll get to the point where you can log into a lynx container and run everything and it will be scoped",
    "start": "2063879",
    "end": "2070240"
  },
  {
    "text": "just for that container but at the moment be aware that that may not be the case we work around",
    "start": "2070240",
    "end": "2075700"
  },
  {
    "text": "it at Netflix by we have an agent in the host and that agent is reading C group",
    "start": "2075700",
    "end": "2080980"
  },
  {
    "text": "metrics and we expose it through our Vector UI so that we can look at per",
    "start": "2080980",
    "end": "2086138"
  },
  {
    "text": "container metrics but I just want to mention if you log into a container and run vmstat and top",
    "start": "2086139",
    "end": "2092138"
  },
  {
    "text": "and uptime it's not a given that all the metrics are going to be scoped for that container",
    "start": "2092139",
    "end": "2098920"
  },
  {
    "text": "so I've mentioned Vector number of times Spinnaker is our main deployment tool anyone using Spinnaker",
    "start": "2098920",
    "end": "2105460"
  },
  {
    "text": "so some people so we go from Spinnaker I can click on insight and go straight to vector and I'm looking at a particular",
    "start": "2105460",
    "end": "2110680"
  },
  {
    "text": "instance profiling",
    "start": "2110680",
    "end": "2116820"
  },
  {
    "text": "so I'll start with a story this was a issue I worked on where",
    "start": "2117400",
    "end": "2123700"
  },
  {
    "text": "the microservice team said ZFS is eating my CPUs I worked on zfets at Sun Microsystems I",
    "start": "2123700",
    "end": "2131980"
  },
  {
    "text": "worked on the code and also performance analysis and I don't think ZFS is eating your CPUs I did a lot of work on ZFS and",
    "start": "2131980",
    "end": "2139960"
  },
  {
    "text": "this is probably not the case but I'll help you out anyway and I'll check it out",
    "start": "2139960",
    "end": "2145619"
  },
  {
    "text": "so to prove to them that ZFS was not eating the CPUs I thought I would create a",
    "start": "2145660",
    "end": "2152260"
  },
  {
    "text": "sepia flame graph which I'll explain in a moment",
    "start": "2152260",
    "end": "2157320"
  },
  {
    "text": "and the CPU flame graph look like this the application of color Java in green",
    "start": "2157480",
    "end": "2164200"
  },
  {
    "text": "and then kernel time of colored in Orange and with the kernel type I can see wait",
    "start": "2164200",
    "end": "2170500"
  },
  {
    "text": "a minute we are in CFS we've got SPL and we've got the arc Arc reclaim",
    "start": "2170500",
    "end": "2178119"
  },
  {
    "text": "they're actually right we are in zfus is eating the CPUs 38 of Kernel time is",
    "start": "2178119",
    "end": "2183700"
  },
  {
    "text": "eating the CPS oh I know this is a misconfiguration it's not that ZFS is doing anything",
    "start": "2183700",
    "end": "2190540"
  },
  {
    "text": "wrong is because I bet they misconfigured it I bet they're using a small Arc record size and it's trying to",
    "start": "2190540",
    "end": "2197320"
  },
  {
    "text": "do Arc reclaim it has to walk through metadata that's huge that's why so I tell them okay you're right GFS is",
    "start": "2197320",
    "end": "2204160"
  },
  {
    "text": "eating your CPUs quite a lot of it 38 for the entire system but it's because you've misconfigured it I bet you've",
    "start": "2204160",
    "end": "2209980"
  },
  {
    "text": "picked a small Arc size what they told me was even more surprising they said we're not even using CFS",
    "start": "2209980",
    "end": "2218760"
  },
  {
    "text": "it's like I don't think so you are using user doesn't just eat CPU because it feels like it because it's hungry you're",
    "start": "2220000",
    "end": "2226960"
  },
  {
    "text": "definitely using ZFS I can see that you're using CFS so that I know I will log into the instance and I'll pull up",
    "start": "2226960",
    "end": "2233140"
  },
  {
    "text": "the metrics and I'll prove to them with Beyond a doubt that they are using ZFS",
    "start": "2233140",
    "end": "2238240"
  },
  {
    "text": "and I go into the process slash Arc stats and it was true they were all zero they",
    "start": "2238240",
    "end": "2246339"
  },
  {
    "text": "weren't actually using ZFS so what the heck is going on",
    "start": "2246339",
    "end": "2251980"
  },
  {
    "text": "so I can zoom in with the flame graph and have a look and",
    "start": "2251980",
    "end": "2257099"
  },
  {
    "text": "looking at the arc reclaimed thread and I'm familiar with this I worked on it the arc recla Arc is the Adaptive",
    "start": "2257680",
    "end": "2263560"
  },
  {
    "text": "replacement cache that's the main file system cache for ZFS for reclaim it is cleaning up memory",
    "start": "2263560",
    "end": "2270520"
  },
  {
    "text": "and it's picking it has it saves memory in",
    "start": "2270520",
    "end": "2276099"
  },
  {
    "text": "different lists and it's choosing which list to free memory from by",
    "start": "2276099",
    "end": "2282579"
  },
  {
    "text": "get random bites and extract entropy it turns out there was a ZFS change",
    "start": "2282579",
    "end": "2288900"
  },
  {
    "text": "where the instead of doing a round robin through their lists to free memory the",
    "start": "2288900",
    "end": "2295000"
  },
  {
    "text": "engineer thought wouldn't it be cool if we picked a list at random but I don't mean simple random I mean like really random",
    "start": "2295000",
    "end": "2301839"
  },
  {
    "text": "I mean like really cryptographically secure random and so 38 of system time",
    "start": "2301839",
    "end": "2307599"
  },
  {
    "text": "is because ZFS is deciding which empty list to free from",
    "start": "2307599",
    "end": "2313599"
  },
  {
    "text": "using brand they they must secure cryptographic random algorithm so we've",
    "start": "2313599",
    "end": "2320980"
  },
  {
    "text": "I filed a ticket with ZFS and to get that fixed pretty quick so if the if the",
    "start": "2320980",
    "end": "2327160"
  },
  {
    "text": "lists are empty don't iterate through them to free them there's nothing to free so it should be an easy fix it's an",
    "start": "2327160",
    "end": "2333460"
  },
  {
    "text": "example of CPU flame graphs are great and profiling is great because you can quickly exonerate or prove issues and hypotheses",
    "start": "2333460",
    "end": "2341079"
  },
  {
    "text": "and see what's really going on when I started Netflix CPU profiling",
    "start": "2341079",
    "end": "2347619"
  },
  {
    "text": "look like this though Java profilers and let me look at Java and system profilers",
    "start": "2347619",
    "end": "2352660"
  },
  {
    "text": "but Java was all broken because we couldn't look at their system stack Trace",
    "start": "2352660",
    "end": "2358000"
  },
  {
    "text": "and the reason was that Java did not honor the frame planer and that's how system profilers typically walk stacks",
    "start": "2358000",
    "end": "2364359"
  },
  {
    "text": "Java use that frame pointer for performance optimization that made sense many many years ago but doesn't really",
    "start": "2364359",
    "end": "2370540"
  },
  {
    "text": "make sense today I worked on openjdk and I came up with a",
    "start": "2370540",
    "end": "2377920"
  },
  {
    "text": "patch to fix the frame pointer Oracle were nice enough to take that patch and rewrite it and get it included and",
    "start": "2377920",
    "end": "2383500"
  },
  {
    "text": "that's now the preserved frame pointer option and now we can do mixed mode flame graph so we can see Java and we",
    "start": "2383500",
    "end": "2389260"
  },
  {
    "text": "can see garbage collect I can see the jvm kernel I'm coloring different code types in colors to make it easy to",
    "start": "2389260",
    "end": "2395859"
  },
  {
    "text": "browse so secret flame graphs I've zoomed in a",
    "start": "2395859",
    "end": "2400900"
  },
  {
    "text": "bit since most of you said you hadn't used them before I'll explain how they",
    "start": "2400900",
    "end": "2407320"
  },
  {
    "text": "work the y-axis is the stack depth the x-axis is just the passage of is",
    "start": "2407320",
    "end": "2414700"
  },
  {
    "text": "sorry the x-axis is just the population all of the samples",
    "start": "2414700",
    "end": "2420520"
  },
  {
    "text": "the x-axis is not the passage of time the x-axis is actually the alphabet and",
    "start": "2420520",
    "end": "2426460"
  },
  {
    "text": "I picked the alphabet so that I could reorder samples and then merge the frames more easily",
    "start": "2426460",
    "end": "2433420"
  },
  {
    "text": "this is what happens if I use the passage of time on the x-axis so you end up with hair and grass",
    "start": "2433420",
    "end": "2440020"
  },
  {
    "text": "and I can't really read the frames there's one exception that gets away with this and that is if your",
    "start": "2440020",
    "end": "2446140"
  },
  {
    "text": "application is single threaded like the problem here is the application is multi-threaded each the samples they're",
    "start": "2446140",
    "end": "2451900"
  },
  {
    "text": "doing different things we can't merge the boxes an example of a single threaded application is V8 in Chrome",
    "start": "2451900",
    "end": "2459640"
  },
  {
    "text": "and so in Chrome devtools they use this they call it flame charts and they do",
    "start": "2459640",
    "end": "2464740"
  },
  {
    "text": "have the passage of time on the x-axis and they kind of get away with it because it's single threaded since I'm working on multi-threaded",
    "start": "2464740",
    "end": "2471220"
  },
  {
    "text": "systems I need to use flame graphs where I throw away the passage of time and I just have",
    "start": "2471220",
    "end": "2476800"
  },
  {
    "text": "the alphabet to maximize merging so to read them if this was my sample",
    "start": "2476800",
    "end": "2482320"
  },
  {
    "text": "flame graph the top Edge is what's on CPU so let's",
    "start": "2482320",
    "end": "2487960"
  },
  {
    "text": "see that function G was on CPU the most function e was on it a little bit I was on a little bit a fraction of D was on",
    "start": "2487960",
    "end": "2494440"
  },
  {
    "text": "CPU directly a little bit but its children were also on CPU and the y-axis is the stack depth",
    "start": "2494440",
    "end": "2502019"
  },
  {
    "text": "I've summarized flying graphs in one slide so zero is at the bottom for the stack",
    "start": "2502240",
    "end": "2508300"
  },
  {
    "text": "depth some people like to flip them and put them upside down icicle graphs if the x-axis is time that's a flame",
    "start": "2508300",
    "end": "2515079"
  },
  {
    "text": "chart and so I've colored there that's who's running on CPU is the top Edge",
    "start": "2515079",
    "end": "2522420"
  },
  {
    "text": "our primary approach for doing application profiling at Netflix is these CPU flame graphs",
    "start": "2523300",
    "end": "2530680"
  },
  {
    "text": "mixed mode flame graphs it's important to see the kernel as well like when I was debugging that CFS issue",
    "start": "2530680",
    "end": "2536079"
  },
  {
    "text": "because there are many application profilers but they only show you the application content",
    "start": "2536079",
    "end": "2541119"
  },
  {
    "text": "you may need frame pointers for this to work you may also need a supplemental symbol file if you're doing flame graphs",
    "start": "2541119",
    "end": "2547240"
  },
  {
    "text": "on node or golang or anything if you do an internet search you'll probably find someone's posted the instructions or",
    "start": "2547240",
    "end": "2553000"
  },
  {
    "text": "I've posted the instructions and if not figure out the instructions and then post the instructions so that",
    "start": "2553000",
    "end": "2559119"
  },
  {
    "text": "other people can find them if that doesn't work we will then use application profilers or application",
    "start": "2559119",
    "end": "2564880"
  },
  {
    "text": "logs but our preference is push button flame graphs we have them in vector so",
    "start": "2564880",
    "end": "2571300"
  },
  {
    "text": "that you can say start capture for 20 seconds CPU flame graph and then I'm looking at it",
    "start": "2571300",
    "end": "2577180"
  },
  {
    "text": "straight away the way flame graphs are currently generated",
    "start": "2577180",
    "end": "2583300"
  },
  {
    "text": "looks like this on Linux 2.6",
    "start": "2583300",
    "end": "2588400"
  },
  {
    "text": "onwards we would run perf record that would write to a perf.data file per script would process it I would then",
    "start": "2588400",
    "end": "2596500"
  },
  {
    "text": "run it through stack collapse to summarize those samples and then flame",
    "start": "2596500",
    "end": "2602200"
  },
  {
    "text": "graph it's a little bit inefficient because we're writing to the file system we've got CPU time and we're dumping",
    "start": "2602200",
    "end": "2607900"
  },
  {
    "text": "every sample out a more efficient way is coming in Linux 4.9 onwards and that's a new tool I've",
    "start": "2607900",
    "end": "2614079"
  },
  {
    "text": "written called profile.py although it's based on Code by many other people and that's able to summarize sample and",
    "start": "2614079",
    "end": "2621339"
  },
  {
    "text": "summarize Stacks in kernel and just write the summary straight out so that flame graph can consume it",
    "start": "2621339",
    "end": "2627400"
  },
  {
    "text": "so I just want to mention this because plane graphs are going to become even cheaper to run",
    "start": "2627400",
    "end": "2633099"
  },
  {
    "text": "and there should be even more commonplace profiling actually solves I would have",
    "start": "2633099",
    "end": "2639339"
  },
  {
    "text": "to say most of the performance issues at Netflix CPU profiling and part of the reason why is we're deploying changes so",
    "start": "2639339",
    "end": "2645640"
  },
  {
    "text": "often and so developers can bring up a CPU flame graph and see what happened",
    "start": "2645640",
    "end": "2651839"
  },
  {
    "text": "to get down deeper there is tracing",
    "start": "2651880",
    "end": "2657599"
  },
  {
    "text": "I'll explain these but I want to preface with the following sections get into software",
    "start": "2658180",
    "end": "2663579"
  },
  {
    "text": "and Hardware very deep you should think about that as I'm showing you an x-ray",
    "start": "2663579",
    "end": "2668800"
  },
  {
    "text": "machine you don't all need to know how to operate an x-ray machine you just need to know that it exists so",
    "start": "2668800",
    "end": "2675579"
  },
  {
    "text": "that if the time comes then you either learn or you find someone who knows how to do it if I fell off this stage and",
    "start": "2675579",
    "end": "2681640"
  },
  {
    "text": "broke my foot and I was walking around thinking my foot hurts oh my foot really really hurts you'd all probably tell me go and",
    "start": "2681640",
    "end": "2688720"
  },
  {
    "text": "get an x-ray and that's what what I want to get to you with these tracing tools and",
    "start": "2688720",
    "end": "2694359"
  },
  {
    "text": "hardware tools so that you know that if that time comes and your application stack breaks its",
    "start": "2694359",
    "end": "2700480"
  },
  {
    "text": "foot you then go and find the tool",
    "start": "2700480",
    "end": "2704460"
  },
  {
    "text": "in Linux has been really difficult to understand and get our head around",
    "start": "2705819",
    "end": "2711099"
  },
  {
    "text": "because there's been so many different tracing tools my partner Deidra strong who does many",
    "start": "2711099",
    "end": "2716800"
  },
  {
    "text": "things and amazing things in technology has also drawn Pony cons for each of the Linux traces",
    "start": "2716800",
    "end": "2723579"
  },
  {
    "text": "and some of them have been adopted as the official mascots and so we've got the f-trace ponycon",
    "start": "2723579",
    "end": "2729460"
  },
  {
    "text": "perf evpf we have too many traces this has been a big problem in Linux for a while we have so many polycons we can",
    "start": "2729460",
    "end": "2736839"
  },
  {
    "text": "make a really terrible children's show on the driest topic ever Linux tracing",
    "start": "2736839",
    "end": "2743640"
  },
  {
    "text": "just to summarize it what I like to do is to say what Linux traces are in the",
    "start": "2745000",
    "end": "2750819"
  },
  {
    "text": "kernel a core that are available and so they are ftrace perf and ebpf all",
    "start": "2750819",
    "end": "2756040"
  },
  {
    "text": "the other ones are add-ons if Trace has been if trace and perfect been around for a long time so you should have access to them ftrace has",
    "start": "2756040",
    "end": "2763000"
  },
  {
    "text": "these great custom tracing views ebpf is the newer technology it's a program programmatic engine and we can",
    "start": "2763000",
    "end": "2771940"
  },
  {
    "text": "we've been adding complex tools and short scripts using a couple of Open Source projects",
    "start": "2771940",
    "end": "2778240"
  },
  {
    "text": "to explain how these fit together here's an example issue the service team told me their disk",
    "start": "2778240",
    "end": "2784420"
  },
  {
    "text": "became busy our disc PC went up to 80 what's going",
    "start": "2784420",
    "end": "2790240"
  },
  {
    "text": "on this is a screenshot from Atlas okay so I log into the instance and have",
    "start": "2790240",
    "end": "2795640"
  },
  {
    "text": "a look using i o stat just to confirm it it's true their disk is 87 utilized",
    "start": "2795640",
    "end": "2803140"
  },
  {
    "text": "I want to know more information let's drill down further so I can understand what's causing it to be busy",
    "start": "2803200",
    "end": "2812338"
  },
  {
    "text": "this is a Perth based tool using one of the older tracers and it's showing me a latency",
    "start": "2813339",
    "end": "2821859"
  },
  {
    "text": "distribution where I can see that we have two modes of latency one mode is zero to one",
    "start": "2821859",
    "end": "2828400"
  },
  {
    "text": "milliseconds and the other is eight to sixteen milliseconds I see this all the time for disk analysis the first mode is cache hits",
    "start": "2828400",
    "end": "2835359"
  },
  {
    "text": "and the second is cache misses this doesn't actually look that unusual",
    "start": "2835359",
    "end": "2840819"
  },
  {
    "text": "this just looks like a problem of load then I don't see any ridiculous outliers I don't see modes in a place I'm not",
    "start": "2840819",
    "end": "2846700"
  },
  {
    "text": "expecting them this is this is normal for say a 7200 RPM disk",
    "start": "2846700",
    "end": "2852280"
  },
  {
    "text": "so this points to a problem of workload not the problem of the hardware",
    "start": "2852280",
    "end": "2858339"
  },
  {
    "text": "I then used another tracing tool this is like TCP dump but for disks it's another one I wrote and I can see that",
    "start": "2858339",
    "end": "2865960"
  },
  {
    "text": "the Java is doing these is it playing the disk IO I can see the latency for",
    "start": "2865960",
    "end": "2871240"
  },
  {
    "text": "each of them but just by getting some more information just like you do when you TCP dump and you're not sure about an",
    "start": "2871240",
    "end": "2878020"
  },
  {
    "text": "issue and you just want to see if something stands out something did stand out these were metadata IO",
    "start": "2878020",
    "end": "2885220"
  },
  {
    "text": "metadata I had not well I think m stands for",
    "start": "2885220",
    "end": "2892420"
  },
  {
    "text": "metadata this is actually this r this this field called",
    "start": "2892420",
    "end": "2897599"
  },
  {
    "text": "rwbs in the kernel and the kernel actually saves it as the character string and I'm just fetching that character string and printing it out and",
    "start": "2897599",
    "end": "2904300"
  },
  {
    "text": "I kind of figure out what the characters stand for though I saw there was a thread once on the internet where someone was asking about what do the",
    "start": "2904300",
    "end": "2911380"
  },
  {
    "text": "letters stand for and what does m stand for on this and that and I thought it'd be helpful and I'd reply and I'd say hey",
    "start": "2911380",
    "end": "2917440"
  },
  {
    "text": "it's not documented you have to read the kernel code to understand what those characters mean",
    "start": "2917440",
    "end": "2922480"
  },
  {
    "text": "they replied to me and they said no it is documented it's in a man page I thought well I feel like an idiot I",
    "start": "2922480",
    "end": "2928240"
  },
  {
    "text": "should have read that man page huh so it actually was documented in the main page it's like all right thanks for that I",
    "start": "2928240",
    "end": "2934480"
  },
  {
    "text": "guess I should have read it which man page which man page documented this because I swear I've never seen",
    "start": "2934480",
    "end": "2940180"
  },
  {
    "text": "this document in a man page so go and find the main page I wrote the main page it's my own man",
    "start": "2940180",
    "end": "2947020"
  },
  {
    "text": "page I've written so many tools if you do forget from time to time so then I felt",
    "start": "2947020",
    "end": "2952720"
  },
  {
    "text": "really embarrassed like all right so I I have actually documented these before metadata",
    "start": "2952720",
    "end": "2960040"
  },
  {
    "text": "so I can trace just the metadata using perf and I find out that",
    "start": "2960040",
    "end": "2965380"
  },
  {
    "text": "so now I'm going to trace when we're doing metadata disk IO show me the stack trace of who's causing it",
    "start": "2965380",
    "end": "2971680"
  },
  {
    "text": "and it's all this stat stuff stat",
    "start": "2971680",
    "end": "2975720"
  },
  {
    "text": "and it's coming from java and it turns out that they had installed",
    "start": "2977380",
    "end": "2983260"
  },
  {
    "text": "a new app called disk usage monitor to find out the usage of their",
    "start": "2983260",
    "end": "2988839"
  },
  {
    "text": "application and that disk usage monitor was just calling stat all the time in a loop so disk usage monitor was also disk",
    "start": "2988839",
    "end": "2996400"
  },
  {
    "text": "performance problem creator so I said why don't you turn it off and like this new app you've installed",
    "start": "2996400",
    "end": "3002940"
  },
  {
    "text": "so they turned it off and the problem went away so just as an example of using some",
    "start": "3002940",
    "end": "3008880"
  },
  {
    "text": "tracing tools to understand what's going on as an example of a more modern tracing",
    "start": "3008880",
    "end": "3014400"
  },
  {
    "text": "tool here's biosloop which is from using ebpf it's similar to what we saw earlier but the point I want to make here is",
    "start": "3014400",
    "end": "3020640"
  },
  {
    "text": "it's more efficient I'm doing these lengthy calculations in kernel that's using abpf",
    "start": "3020640",
    "end": "3027780"
  },
  {
    "text": "ebpf who's heard of ebpf so a few people it is extended",
    "start": "3027780",
    "end": "3034980"
  },
  {
    "text": "Berkeley packet filter at the Linux plumbers conference recently in Vancouver there were 24",
    "start": "3034980",
    "end": "3040619"
  },
  {
    "text": "talks on evpf is becoming huge",
    "start": "3040619",
    "end": "3045780"
  },
  {
    "text": "what it is is a virtual machine technology which really like superpowers it's a",
    "start": "3045780",
    "end": "3052020"
  },
  {
    "text": "virtual machine technology where in use of space I can define a program and then the kernel can run that program",
    "start": "3052020",
    "end": "3058640"
  },
  {
    "text": "previously anytime you wanted the colonel to do something fancy you either had to modify the kernel code or write a",
    "start": "3058640",
    "end": "3065339"
  },
  {
    "text": "loadable module now if you come to Netflix and you're trying to sell me some application you've written that requires a root",
    "start": "3065339",
    "end": "3071400"
  },
  {
    "text": "Daemon or a loadable module we get a bit nervous about that because your code could crash Netflix",
    "start": "3071400",
    "end": "3079319"
  },
  {
    "text": "with abpf however if you write your application in ebpf it's running in a",
    "start": "3079319",
    "end": "3085740"
  },
  {
    "text": "virtual machine that's sandboxed and known to be safe so now when people are trying to sell me",
    "start": "3085740",
    "end": "3091980"
  },
  {
    "text": "some product they've developed I tell them is it ebpf it needs to be ebpf that's the sandbox machine",
    "start": "3091980",
    "end": "3099660"
  },
  {
    "text": "EPF is being used for many things it was originally developed as a software-defined networking technology but it's being used for DDOS mitigation",
    "start": "3099660",
    "end": "3106800"
  },
  {
    "text": "intrusion detection container security I'm using it for observability and it",
    "start": "3106800",
    "end": "3112020"
  },
  {
    "text": "can take events from many sources and then run a mini program when that event",
    "start": "3112020",
    "end": "3118079"
  },
  {
    "text": "happens I've been developing many BCC many ebpf",
    "start": "3118079",
    "end": "3123960"
  },
  {
    "text": "based Performance Tools so another one of my diagrams where I've been writing all of the Performance Tools",
    "start": "3123960",
    "end": "3129720"
  },
  {
    "text": "the point here is like yes we have this amazing x-ray machine so you can see",
    "start": "3129720",
    "end": "3135900"
  },
  {
    "text": "inside anything you want if you thought you had a problem with virtual memory or if you thought you had a problem with",
    "start": "3135900",
    "end": "3141079"
  },
  {
    "text": "TCP or VFS there's probably a tracing tool that will give you more insight",
    "start": "3141079",
    "end": "3148520"
  },
  {
    "text": "and BCC he's one of my favorite tracing tools the idea of this came from Julia Evans",
    "start": "3149040",
    "end": "3154440"
  },
  {
    "text": "who said I want a tool that's just I can say show me who's connecting to this port like which application is",
    "start": "3154440",
    "end": "3159960"
  },
  {
    "text": "connecting to the port this is really efficient it's not doing packet tracing I'm just tracing when TCP",
    "start": "3159960",
    "end": "3166619"
  },
  {
    "text": "connections are established and when they close by tracing those kernel functions and then I'm doing a summary where I'm printing out the process the",
    "start": "3166619",
    "end": "3174000"
  },
  {
    "text": "IP addresses the how many kilobytes were transferred in the duration",
    "start": "3174000",
    "end": "3179099"
  },
  {
    "text": "so it lets us write these new great tools that are also efficient and production safe",
    "start": "3179099",
    "end": "3184760"
  },
  {
    "text": "and I want to mention there's one more called BPF Trace apart from BCC BPF Trace is a",
    "start": "3185160",
    "end": "3191099"
  },
  {
    "text": "new one we only launched a month ago which you can write the similar tools but the source code is very small it's a",
    "start": "3191099",
    "end": "3197400"
  },
  {
    "text": "high level language for doing tracing again whenever we're looking at this if I showed this other people at Netflix",
    "start": "3197400",
    "end": "3203339"
  },
  {
    "text": "they'll say that's great but it needs to be a self-service GUI so in the future",
    "start": "3203339",
    "end": "3208500"
  },
  {
    "text": "many of these ebpf things need to be self-service guis so there's an example from",
    "start": "3208500",
    "end": "3214980"
  },
  {
    "text": "Linux when we were developing this which has a latency heat map so I can identify",
    "start": "3214980",
    "end": "3220559"
  },
  {
    "text": "multimodal latency and outliers and that's based on ebpf it's efficient",
    "start": "3220559",
    "end": "3226460"
  },
  {
    "text": "the last deep dive tools I want to mention for exposure is processor analysis",
    "start": "3226980",
    "end": "3235520"
  },
  {
    "text": "and this is becoming the number one performance problem we're exposed to",
    "start": "3236220",
    "end": "3241260"
  },
  {
    "text": "that is if you see the CPUs are 90 busy you might think they're busy and then",
    "start": "3241260",
    "end": "3246359"
  },
  {
    "text": "they're waiting idle for 10 what it typically means on the",
    "start": "3246359",
    "end": "3251700"
  },
  {
    "text": "Netflix cloud is most of the time is waiting stalled on stall Cycles",
    "start": "3251700",
    "end": "3257339"
  },
  {
    "text": "and the reason is that CPUs the clock speed has become very fast they've also become they've added more cores and",
    "start": "3257339",
    "end": "3263040"
  },
  {
    "text": "Hyper threads but the memory subsystem has not been scaling as fast it's now",
    "start": "3263040",
    "end": "3269099"
  },
  {
    "text": "we're just blocked waiting on memory and when there's instructions are blocked they call it stall Cycles where",
    "start": "3269099",
    "end": "3274559"
  },
  {
    "text": "the CPU is not making forward progress to debug this",
    "start": "3274559",
    "end": "3279720"
  },
  {
    "text": "it when I started Netflix there was no way to debug this because we didn't have performance monitoring counters on the",
    "start": "3279720",
    "end": "3285540"
  },
  {
    "text": "cloud and that's what you need to get information out recently Amazon have been turning them",
    "start": "3285540",
    "end": "3290819"
  },
  {
    "text": "on and so for the Zen hypervisor for the very large instances you get the architectural set which is great",
    "start": "3290819",
    "end": "3298020"
  },
  {
    "text": "there are hundreds and hundreds and hundreds of pmcs this is just seven that they've turned on for those instance types I also believe pmcs there's such a",
    "start": "3298020",
    "end": "3305520"
  },
  {
    "text": "narrow deep topic I don't think Amazon has documented them so this is a undocumented feature on ec2 the",
    "start": "3305520",
    "end": "3312240"
  },
  {
    "text": "documentation is my slides that I'm showing you so you can use these in particular",
    "start": "3312240",
    "end": "3317880"
  },
  {
    "text": "instruction retired and reference Cycles let you calculate IPC ipc's instructions",
    "start": "3317880",
    "end": "3324420"
  },
  {
    "text": "per cycle if you haven't encountered this before it's similar to like a miles per gallon miles per gallon tells you",
    "start": "3324420",
    "end": "3330720"
  },
  {
    "text": "how efficient what what are you getting out of the gallons you're putting into a car actually I'm in Australia so this is",
    "start": "3330720",
    "end": "3336839"
  },
  {
    "text": "going to be kilometers per leader kilometers per liter phew so kilometers per liter",
    "start": "3336839",
    "end": "3344760"
  },
  {
    "text": "and with IPC it's the instructions we're getting out",
    "start": "3344760",
    "end": "3349800"
  },
  {
    "text": "of these cycles that we put into the CPUs you can actually go beyond 1.0 because",
    "start": "3349800",
    "end": "3355680"
  },
  {
    "text": "we have a super scalar architecture and the CPU deep composes instructions into Micro Ops and we can can retire more",
    "start": "3355680",
    "end": "3361920"
  },
  {
    "text": "than one at once so we can actually go up to 4.0 on a four wide processor but just to give you an idea of a spectrum",
    "start": "3361920",
    "end": "3368400"
  },
  {
    "text": "if you're over two that's good your returning instructions really quickly if it's less than 0.2 that's really bad",
    "start": "3368400",
    "end": "3374460"
  },
  {
    "text": "you're stored on Main memory you should be measuring IPC along with other metrics along with percent super",
    "start": "3374460",
    "end": "3380520"
  },
  {
    "text": "utilization so you can understand where you are in this spectrum and if you are down at the bad end then instead of",
    "start": "3380520",
    "end": "3387059"
  },
  {
    "text": "buying faster processors you should be looking at memory",
    "start": "3387059",
    "end": "3392099"
  },
  {
    "text": "how are you dealing with memory how you're using memory you use less memory can you do zero copy and so on",
    "start": "3392099",
    "end": "3399200"
  },
  {
    "text": "that's how it looks like to measure it using perfstat so I can see my instructions per cycle I also read a",
    "start": "3399660",
    "end": "3404819"
  },
  {
    "text": "tool called PMC Arch which printed out line by line for IPC and I want to mention in the new Nitro",
    "start": "3404819",
    "end": "3411660"
  },
  {
    "text": "hypervisor by Amazon they've enabled many more pmcs which is great because I use them for doing the translation looks",
    "start": "3411660",
    "end": "3419579"
  },
  {
    "text": "like buffer analysis for the Meltdown kpti patches that Linux had to include and so I can see the we're spending so",
    "start": "3419579",
    "end": "3427020"
  },
  {
    "text": "many times in store cycles for data and instruction tlb pagewalks",
    "start": "3427020",
    "end": "3433079"
  },
  {
    "text": "it's great to actually when people tell you may have heard earlier in a year when those patches came in that Linux",
    "start": "3433079",
    "end": "3439619"
  },
  {
    "text": "could run much slower because of the the security effects we can actually measure it and we can see it we can quantify it",
    "start": "3439619",
    "end": "3445500"
  },
  {
    "text": "for our workloads it's great to have that low level insight and the last low level Insight that I",
    "start": "3445500",
    "end": "3452940"
  },
  {
    "text": "like to use as msrs model specific registers that's an example from",
    "start": "3452940",
    "end": "3458880"
  },
  {
    "text": "an instance that that we debugged last week where the megahertz was not running",
    "start": "3458880",
    "end": "3464099"
  },
  {
    "text": "as fast as it should do it was supposed to be running at 2500 megahertz it's actually running at 130. and",
    "start": "3464099",
    "end": "3471359"
  },
  {
    "text": "yeah the Netflix Engineers showed it to me it's like because I wrote show boost this is a great tool Bernie you've debugged this issue I'm like have I",
    "start": "3471359",
    "end": "3478079"
  },
  {
    "text": "debugged this issue that is so low I wonder if there's a mistake in my tool the CPS shouldn't be running at 130",
    "start": "3478079",
    "end": "3484319"
  },
  {
    "text": "megahertz so we did some other debugging and it was actually true so there was a problem with that instance",
    "start": "3484319",
    "end": "3490200"
  },
  {
    "text": "which we got fixed so more insight just double checking that the clock rate is running as it",
    "start": "3490200",
    "end": "3496260"
  },
  {
    "text": "should in summary so I've given you exposure to many",
    "start": "3496260",
    "end": "3502200"
  },
  {
    "text": "different tools but if there were three takeaways I would say that's CPU flame graphs for",
    "start": "3502200",
    "end": "3510180"
  },
  {
    "text": "looking at all the Cycles where it's going make sure they work for kernel and user space",
    "start": "3510180",
    "end": "3517079"
  },
  {
    "text": "check out the ebpf perf tools you'll be hearing more about this in the future particularly at Netflix part of my job",
    "start": "3517079",
    "end": "3524280"
  },
  {
    "text": "is now build uis on it to enable other Engineers to use it quickly and of course we open source pretty much",
    "start": "3524280",
    "end": "3530760"
  },
  {
    "text": "everything we do and for super utilization you should be measuring IPC as well so you can",
    "start": "3530760",
    "end": "3536040"
  },
  {
    "text": "understand what that is whether it is instruction bound or store cycle bound",
    "start": "3536040",
    "end": "3542760"
  },
  {
    "text": "I began by saying observability methodology and velocity and I think we're in it's an exciting",
    "start": "3542760",
    "end": "3550400"
  },
  {
    "text": "stage when I started Netflix we didn't have evpf we didn't have pmcs on the",
    "start": "3550400",
    "end": "3555660"
  },
  {
    "text": "cloud now we have all these things so you can come up with great methodologies and some great new guise",
    "start": "3555660",
    "end": "3561240"
  },
  {
    "text": "so that we can use them and root cause analyze our systems",
    "start": "3561240",
    "end": "3565760"
  },
  {
    "text": "these slides will be online and I've got resources and there's also the Netflix Tech blog which is a great resource for",
    "start": "3566400",
    "end": "3572819"
  },
  {
    "text": "what we do and thank you very much [Applause]",
    "start": "3572819",
    "end": "3582929"
  }
]
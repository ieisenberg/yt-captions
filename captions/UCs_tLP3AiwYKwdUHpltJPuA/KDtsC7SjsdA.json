[
  {
    "start": "0",
    "end": "38000"
  },
  {
    "text": "Hi, everybody, and welcome to \"GOTO \nUnscripted.\" My name's James Beswick   and I lead the Serverless Developer Advocacy \nteam here at AWS, and I'm joined by Julian  ",
    "start": "13960",
    "end": "23720"
  },
  {
    "text": "Wood on my team. Julian, how are you doing?\nHey, James. We've been doing this developer  ",
    "start": "23720",
    "end": "30359"
  },
  {
    "text": "advocacy thing for a few years and \nplaying the serverless beforehand. Super   keen to chat all things serverless as always.\nWhat for you is top of mind serverless these days? ",
    "start": "30360",
    "end": "43520"
  },
  {
    "start": "38000",
    "end": "358000"
  },
  {
    "text": "Well, I think that's an interesting \nquestion because everything is serverless,   yet there's still a long way to go. And so \nof course, the title of this video, you know,  ",
    "start": "43520",
    "end": "51840"
  },
  {
    "text": "are we post-serverless is, of course, slightly \nclick-baity. See we need to do that kind of thing.  ",
    "start": "51840",
    "end": "57160"
  },
  {
    "text": "We needed to put some GenAI goodness into that \nas well to make it even more buzz-worthy. But,  ",
    "start": "57160",
    "end": "62680"
  },
  {
    "text": "you know, what do we mean by post-serverless?\nWell, first thing I think of is like, serverless  ",
    "start": "62680",
    "end": "68160"
  },
  {
    "text": "is actually a silly term. It means that there's \na lack of servers, but what does it actually mean  ",
    "start": "68160",
    "end": "74920"
  },
  {
    "text": "that's of a benefit? But serverless has caught on, \nas an industry term, as a really good way to build  ",
    "start": "74920",
    "end": "81880"
  },
  {
    "text": "applications, to scale things out, to run things \nin a cloud-native way or native way in the cloud.  ",
    "start": "81880",
    "end": "88720"
  },
  {
    "text": "And so the premise of this chat is to say we're in \na post-serverless world because serverless is just  ",
    "start": "88720",
    "end": "95360"
  },
  {
    "text": "the normal, and so many companies, big and small, \nare building serverless applications that in a   way it's not a stage anymore or a point in time \nthat we did something. It's just an accepted way  ",
    "start": "95360",
    "end": "106360"
  },
  {
    "text": "of running applications with some great benefits.\nI was wondering about this. It is an interesting  ",
    "start": "106360",
    "end": "112120"
  },
  {
    "text": "headline, but I was trying to think about where \nit was five years ago when I started this job,  ",
    "start": "112120",
    "end": "117240"
  },
  {
    "text": "or seven or eight years ago when I first saw it \nreally started using it in earnest in applications  ",
    "start": "117240",
    "end": "123240"
  },
  {
    "text": "and where we are today. What do you think \nis the big shift just over that time period? ",
    "start": "123240",
    "end": "128560"
  },
  {
    "text": "I think it's a natural evolution. I think \nLambda's actually 10 years old at the end   of the year this year. I mean, that's also \ncrazy when you think of it. When sometimes  ",
    "start": "129600",
    "end": "136760"
  },
  {
    "text": "you think cloud is happening so quickly and you \nthink, well, you know, Lambda's already 10 years   old. And Lambda's sort of, in a way, started the \nserverless movement, even though when it came out,  ",
    "start": "136760",
    "end": "145640"
  },
  {
    "text": "there was actually no mention of serverless. It \nwas just run your code in the cloud and we'll   look after you. And it was the initial mental \nmodel of running code without managing servers  ",
    "start": "145640",
    "end": "154760"
  },
  {
    "text": "or infrastructure. And that was super attractive.\nBefore then, you had to set up EC2 instances or  ",
    "start": "154760",
    "end": "159840"
  },
  {
    "text": "maybe container workloads, but still, that was the \nearly days of that. And it was tough to scale and   manage and patch and look after all these kind of \nthings. And so Lambda really was groundbreaking in  ",
    "start": "159840",
    "end": "168760"
  },
  {
    "text": "terms of, you know, throw your code up in the \ncloud and we will look after a whole bunch of   stuff for you. And in this sort of 10 years since \nwe've been doing this, it's now moved beyond just  ",
    "start": "168760",
    "end": "179280"
  },
  {
    "text": "running code to much, much more. And now it's \nsort of a mental model of delivering value to  ",
    "start": "179280",
    "end": "185040"
  },
  {
    "text": "customers without having to manage complex \ninfrastructure capabilities. So it's not   just code, but it can be things like databases or \nqueues or messaging or application architectures. ",
    "start": "185040",
    "end": "196360"
  },
  {
    "text": "And funny, if you have a mental model of some of \nour, sort of, big serverless services, our S3 and  ",
    "start": "196360",
    "end": "202160"
  },
  {
    "text": "SQS, and S3 and SQS were two of the original \nservices at AWS. And so, you know, actually,  ",
    "start": "202160",
    "end": "208800"
  },
  {
    "text": "they were the original serverless services. And \nI like to say that the cloud was actually born  ",
    "start": "208800",
    "end": "213920"
  },
  {
    "text": "serverless because it started in this way of \njust being able to connect to an endpoint over   the internet, upload a file, do something on a \nqueue. That's not AWS-specific as well, you know,  ",
    "start": "213920",
    "end": "223200"
  },
  {
    "text": "lots of the other clouds, and, you know, at that \nstage, some of them were called pauses. That was   the whole idea of just behind an end-point, \nsend your code up, and off you're gonna go. ",
    "start": "223200",
    "end": "232720"
  },
  {
    "text": "Now, using that model of SQS and S3, that's \nwhat it has evolved in. In the 10 years,   we've got many more databases. We've got many \nmore services, not just AWS ones, but we've got,  ",
    "start": "232720",
    "end": "242400"
  },
  {
    "text": "you know, some other companies also building on \ntop of AWS things that come to mind. You know,   companies like Snowflake, also companies \nlike Confluent for Kafka. So it really  ",
    "start": "242400",
    "end": "250920"
  },
  {
    "text": "is an evolution of not just the code now, but \nrunning any kind of service in a serverless way,  ",
    "start": "250920",
    "end": "257400"
  },
  {
    "text": "which you could just access via behind an API.\nI think back to when it was launched at re:Invent  ",
    "start": "257400",
    "end": "263800"
  },
  {
    "text": "10 years Lambda, and I think that's why Lambda is \noften equated to serverless because it was sort  ",
    "start": "263800",
    "end": "269400"
  },
  {
    "text": "of the big shift in the compute side. And I fast \nforward to now, and obviously serverless is just   so much broader, but yeah, many of our customers \ndon't realize just how big the service is. I mean,  ",
    "start": "269400",
    "end": "279759"
  },
  {
    "text": "internally, Lambda's now being used for nearly \n50% of all internal applications at amazon.com  ",
    "start": "279760",
    "end": "286040"
  },
  {
    "text": "and there's trillions of indications every month, \nand it's all over the world in all these different   regions. But of course, one of the things we don't \ntalk about much in our group actually is Fargate.  ",
    "start": "286040",
    "end": "295199"
  },
  {
    "text": "And Fargate is something that's grown really \nequally fast. It's also 10 years old, I believe.",
    "start": "295200",
    "end": "299640"
  },
  {
    "text": "That's the sort of interesting way the industry \nsort of moves and comes back. And when Lambda  ",
    "start": "300840",
    "end": "306480"
  },
  {
    "text": "came out, containers were, you know, very early \ndays and they were, you know, difficult to use,   difficult to understand. But as the industry \nhas moved on, containers have become really,  ",
    "start": "306480",
    "end": "315400"
  },
  {
    "text": "you know, simple to use, amazing tooling, and all \nthese kind of things. But also there was a lot of   infrastructure to deal with for containers, \na lot of the compute infrastructure where,  ",
    "start": "315400",
    "end": "325000"
  },
  {
    "text": "sure, you had a control plane, but all \nthose servers you had to manage yourself.  And so Fargate is a AWS service, which just has \na control plane, which is called ECS, Elastic  ",
    "start": "325000",
    "end": "336080"
  },
  {
    "text": "Container Service, does all the orchestration, \nbut behind the scenes, all those spinning up   of the containers on the actual servers is \nhandled by Fargate, entirely serverlessly,  ",
    "start": "336080",
    "end": "343960"
  },
  {
    "text": "you don't need to manage or think about any of \nthe scaling for that. And yeah, a really sort   of powerful benefits of, sure, you've got Lambda \nfor, you know, short-running functions and Fargate  ",
    "start": "343960",
    "end": "353160"
  },
  {
    "text": "you can use for long-running functions and, \nyou know, maybe some small stateful workloads.",
    "start": "353160",
    "end": "359200"
  },
  {
    "start": "358000",
    "end": "541000"
  },
  {
    "text": "What do you think is the line though between \nserverless in this very vague way with sort of,  ",
    "start": "359200",
    "end": "364520"
  },
  {
    "text": "the industry's gone with it and SaaS? You know, \nif I'm using a SaaS provider, is it serverless or  ",
    "start": "364520",
    "end": "370879"
  },
  {
    "text": "is it just a service that I'm integrating?\nYAn interesting question. I think there're  ",
    "start": "370880",
    "end": "376840"
  },
  {
    "text": "probably purists on both sides who will argue \neither point. For me, I'm thinking from a  ",
    "start": "376840",
    "end": "382280"
  },
  {
    "text": "consumption model, I think SaaS is more just \na service you use over the internet. However,  ",
    "start": "382280",
    "end": "387880"
  },
  {
    "text": "the SaaS provider itself is probably running in \na sort of more serverless kind of way where they  ",
    "start": "387880",
    "end": "393720"
  },
  {
    "text": "can be multi-tenanted, they can have, you know, \nmultiple customers doing various kind of things,   and they obviously want to run...they manage their \nSaaS service in a more serverless way because  ",
    "start": "393720",
    "end": "403440"
  },
  {
    "text": "it'll be more scalable and, you know, more secure \nand more resilient as well. I think just the  ",
    "start": "403440",
    "end": "411120"
  },
  {
    "text": "consumption model, if you're just pointing your \nbrowser or your API at a website, I don't even  ",
    "start": "411120",
    "end": "416800"
  },
  {
    "text": "think you care whether it's serverless or not. \nAnd so you're just using a SaaS service. I mean,  ",
    "start": "416800",
    "end": "422120"
  },
  {
    "text": "that's my personal take. There's nuance \nin that and I'm sure there are different   ways people can think about it.\nThe thing that attracted me to serverless  ",
    "start": "422120",
    "end": "430840"
  },
  {
    "text": "before I worked here was the idea that you could \ndo a lot more with a lot less work. And so I've  ",
    "start": "430840",
    "end": "436160"
  },
  {
    "text": "always been the sort of developer when you're \nrunning teams of people trying to build things   that I wanna move as fast as possible just because \nthere's so much work to do. And so in many ways,  ",
    "start": "436160",
    "end": "445919"
  },
  {
    "text": "I'm less worried about if I plug in a service \nlike Adobe or Stripe or Zendesk on these sort of  ",
    "start": "445920",
    "end": "451960"
  },
  {
    "text": "third-party applications and more about \nhow much time did it save my team and what   sort of resiliency it gave the application.\nThe tenants of serverless are still entirely  ",
    "start": "451960",
    "end": "462920"
  },
  {
    "text": "true today because, you know, in the serverless \nyou've got lots of complexities of, you know,  ",
    "start": "462920",
    "end": "468800"
  },
  {
    "text": "managing large fleets of various kind of things. \nAnd there's storage that's gonna go in and out   on a virtual capacity. And you've got, you \nknow, network connectivity between various  ",
    "start": "468800",
    "end": "476720"
  },
  {
    "text": "resources and their permission constructs and \neverything that sort of comes with it. And,   you know, all of that takes expertise. \nYou've gotta learn storage and networking. ",
    "start": "476720",
    "end": "484280"
  },
  {
    "text": "I come from an infrastructure background. I know \nyou come from an app dev background, and there's   a whole bunch of stuff you needed to do. \nBut that's not the job. That's not the job  ",
    "start": "484280",
    "end": "492919"
  },
  {
    "text": "of your company. You know, you don't need \nto be networking or storage or, you know,   packaging experts. You wanna deliver value to your \ncustomers. And so that's sort of the serverless  ",
    "start": "492920",
    "end": "500919"
  },
  {
    "text": "mindset is to be able to, what I sometimes \nthink of as sort of smart delegation where  ",
    "start": "500920",
    "end": "506240"
  },
  {
    "text": "you delegate smartly things to cloud providers or, \nyou know, other services to just handle things for  ",
    "start": "506240",
    "end": "512880"
  },
  {
    "text": "you because that's not called your business.\nNow, it's smart delegation because you need   to be clever about things. You need to \nunderstand it. It's not saying you just,  ",
    "start": "512880",
    "end": "519800"
  },
  {
    "text": "you know, ignore the operational overhead. \nThere is some stuff you need to do,   but it certainly makes it a lot easier and you can \nuse, you know, AWS and, you know, even other cloud  ",
    "start": "519800",
    "end": "527880"
  },
  {
    "text": "providers' expertise to just run these things \non your behalf. But it does take a mindset in,  ",
    "start": "527880",
    "end": "535040"
  },
  {
    "text": "so you have to evolve the sort of building blocks \nyou're building with to a more cloud-first way.",
    "start": "535040",
    "end": "542240"
  },
  {
    "start": "541000",
    "end": "881000"
  },
  {
    "text": "Given your background, what do you think \nabout the platform engineering side in terms   of what you've seen, how serverless \nevolved? If we are post-serverless,  ",
    "start": "542240",
    "end": "550760"
  },
  {
    "text": "what does that look like from the \npoint of view of platform engineering? I think sort of moving back to my earlier comments \nabout how you now compose new applications. In an  ",
    "start": "550760",
    "end": "563600"
  },
  {
    "text": "old infrastructure world that I was in when it \nwas at networking, that storage and the firewall   rules and everything, when you're building \nmore, sort of, applications in the cloud,  ",
    "start": "563600",
    "end": "572080"
  },
  {
    "text": "that evolves to different kind of constructs. \nAnd instead of, you know, load balances,   storage networking, as I mentioned, and \ninstance types, now you're sort of looking  ",
    "start": "572080",
    "end": "579960"
  },
  {
    "text": "at the application constructs. And these can be \nfunctions or databases, queues and workflows. ",
    "start": "579960",
    "end": "585200"
  },
  {
    "text": "That distinction is actually where some people \nmiss the full proposition of serverless when it's   about less infrastructure to manage. Because a lot \nof developers think, well, I don't look after the  ",
    "start": "586120",
    "end": "593560"
  },
  {
    "text": "infrastructure anyway. That is a platform team or \nan operations team responsibility. I just handle  ",
    "start": "593560",
    "end": "599320"
  },
  {
    "text": "at the application level. But your infrastructure \nteam certainly cares. And part of the rim to  ",
    "start": "600520",
    "end": "605880"
  },
  {
    "text": "serverless is that you don't need to just throw \nit over all a whole platform team internally,  ",
    "start": "605880",
    "end": "609880"
  },
  {
    "text": "there's more important stuff that you can do.\nBut when you're a cloud developer and you're   building applications, there's a lot more that you \nthen need to take on because now if you are having  ",
    "start": "611000",
    "end": "621040"
  },
  {
    "text": "to decide how you're gonna wire a queue or a \nfunction or a database altogether, you know,  ",
    "start": "621040",
    "end": "626519"
  },
  {
    "text": "there's a lot of cognitive overhead you need to \ndo. A lot of those best practices for, you know,  ",
    "start": "626520",
    "end": "631600"
  },
  {
    "text": "database or still some network connectivity \nis still there. So I think the whole platform   engineering thing recognizes that, that, you \nknow, you can't be a 10x engineer, full stack  ",
    "start": "631600",
    "end": "640840"
  },
  {
    "text": "10x engineer developer doing everything. If you're \na big enough company or even medium-sized company,  ",
    "start": "640840",
    "end": "646480"
  },
  {
    "text": "there are gonna be ways that you've learned \nhow to build things that are gonna be secure   and resilient and, you know, at scale and \npowerful. And you wanna be able to package  ",
    "start": "646480",
    "end": "654240"
  },
  {
    "text": "those up so that your developers can use. And so \nplatform engineering can really help with that.  ",
    "start": "654240",
    "end": "659399"
  },
  {
    "text": "But platform engineering, I think is an evolution \nfrom the sort of infrastructure days of having,   you know, DBAs and network and storage \npeople to people who can package up  ",
    "start": "659400",
    "end": "667760"
  },
  {
    "text": "these application constructs to be able \nto allow your developers to do more. ",
    "start": "667760",
    "end": "673640"
  },
  {
    "text": "I think one of the best things in the job \nwe have actually is just be able to see the   huge number of customers and what they're doing \nand talking to them about how they're trying to  ",
    "start": "673640",
    "end": "681720"
  },
  {
    "text": "solve various problems. I think over the years, \nwe must have spoken to, you know, thousands of   different people. But what are a couple of \nyour favorite customer stories about how  ",
    "start": "681720",
    "end": "691680"
  },
  {
    "text": "they've used serverless and what the impact \nhas been? Any that really stand out for you? ",
    "start": "691680",
    "end": "697520"
  },
  {
    "text": "I think there's some of the obvious ones where \nit's just cost and availability. You know,  ",
    "start": "697520",
    "end": "702560"
  },
  {
    "text": "Amazon is sponsoring Red Nose Day. If you're in \nthe UK it is a, you know, massive charity drive.  ",
    "start": "702560",
    "end": "708400"
  },
  {
    "text": "And, you know, they had to keep a whole bunch \nof servers running for a whole bunch of time.   And their infrastructure and their operations, \neverything used to cost them a whole bunch. But if  ",
    "start": "708400",
    "end": "716400"
  },
  {
    "text": "you think if you're running a big charity drive, \nyou've gotta raise money in, you know, I think   it's 24 hours or something, some sort of time \nthing. But you can't afford anything to go wrong  ",
    "start": "716400",
    "end": "724920"
  },
  {
    "text": "because literally, if people can't, you know, \ngive you money, you're just gonna lose money.  And so Red Nose Day is a really good example \nof...I mean, they slash their bills dramatically.  ",
    "start": "724920",
    "end": "734720"
  },
  {
    "text": "I can't think of the exact number, but it was \nsort of 80%, 90% I think it was. When Red Nose  ",
    "start": "734720",
    "end": "742600"
  },
  {
    "text": "Day rolls on each following year, they have to do \nvery little, you know, setting up infrastructure  ",
    "start": "742600",
    "end": "748000"
  },
  {
    "text": "or doing things. The applications that they were \nrunning last year are gonna work this year. Yes,  ",
    "start": "748000",
    "end": "753040"
  },
  {
    "text": "they may need to bump up some versions, \nbut it's so much simpler to just not have   to worry about all that kind of scale. So, \nthat's my sort of use case on the, you know,  ",
    "start": "753040",
    "end": "763120"
  },
  {
    "text": "spiky workloads, things that need to happen where \nyou just don't have to do other kind of things. ",
    "start": "763120",
    "end": "767640"
  },
  {
    "text": "But, you know, the premise of this is other \ncompanies who are doing amazing things. I mean,  ",
    "start": "768160",
    "end": "772879"
  },
  {
    "text": "the Nationwide Children's Hospital, which \nwe've spoken about a number of times,   who are literally running amazing machine learning \nworkloads to help discover and do kind of things  ",
    "start": "773480",
    "end": "784720"
  },
  {
    "text": "with cancer for kids. And you would think that \nwould regulate the environment, it's healthcare,  ",
    "start": "784720",
    "end": "789879"
  },
  {
    "text": "this is kids, this is important genomic data \nthat you've gotta wrestle with. And they've  ",
    "start": "789880",
    "end": "795920"
  },
  {
    "text": "picked serverless because, you know, it was just \nway easier for them and way more productive. ",
    "start": "795920",
    "end": "801279"
  },
  {
    "text": "I mean, they're a great example and certainly \nsome of the nicest people you meet doing some   of the most important work. And they've been \nfairly innovative in how they've used both  ",
    "start": "801280",
    "end": "809640"
  },
  {
    "text": "Lambda and Fargate and used the orchestration \ntools to really accelerate, especially,   as you say, in a regulated environment.\nJulian Wood:  I mean, just other examples,  ",
    "start": "809640",
    "end": "819840"
  },
  {
    "text": "you know, even Lego talk about, you know, their \nbackend infrastructure and how they're doing   kind of things. So many companies are doing data \nprocessing, Kafka is huge, and so many companies  ",
    "start": "819840",
    "end": "830320"
  },
  {
    "text": "are able to just process data from Kafka at high \nscale without having to worry about writing all  ",
    "start": "830320",
    "end": "836520"
  },
  {
    "text": "your producers in Java and complexities with \nscaling, all of that. Yes, the data processing,  ",
    "start": "836520",
    "end": "842640"
  },
  {
    "text": "IoT workloads are huge. Just being able to \nget data that comes from many devices all  ",
    "start": "842640",
    "end": "848560"
  },
  {
    "text": "across the world, you don't even know where it's \ncoming from, and just to be able to manage that. ",
    "start": "848560",
    "end": "852480"
  },
  {
    "text": "I know people can accuse me of slight bias \nbecause I work within the service team,   but I actually very rarely hear customers \nwho adopt serverless and, you know,  ",
    "start": "854320",
    "end": "863880"
  },
  {
    "text": "do spend the time to learn it and do it \nsuccessfully go, \"No, this was a waste   of time.\" Once people get the benefits and they \ngo with it, it's just a sort of land and expand  ",
    "start": "863880",
    "end": "875040"
  },
  {
    "text": "within their organization. And once they do the \ninternal learning and training, off they go.",
    "start": "875040",
    "end": "881399"
  },
  {
    "start": "881000",
    "end": "1441000"
  },
  {
    "text": "I suppose the next thing I have to ask is really \nthe big change in the industry that everybody's  ",
    "start": "881400",
    "end": "886720"
  },
  {
    "text": "talking about is around generative AI. And so, \nobviously, in this very short space of time,   GenAI has come in and really it's revolutionizing \nthis entire space. And certainly internally we  ",
    "start": "886720",
    "end": "897040"
  },
  {
    "text": "can see enormous growth across products like \nBedrock and Q and just the industry moving  ",
    "start": "897040",
    "end": "902959"
  },
  {
    "text": "at a huge pace. But don't you think there's a \nreally interesting fit between GenAI workloads  ",
    "start": "902960",
    "end": "908440"
  },
  {
    "text": "and what we've been doing with serverless?\nCompletely. I mean, it's sort of hand and   glove. In fact, you can't think of any other way \nreally to do it. And that's from two perspectives.  ",
    "start": "908440",
    "end": "919960"
  },
  {
    "text": "One is the actual just using these models, \nbecause what are they? They're just an API   call over the internet, and whether you are \nusing AWS models or even other kind of models,  ",
    "start": "919960",
    "end": "928600"
  },
  {
    "text": "it is just an API call over the internet. So in \na way it is that sort of SaaS service that you  ",
    "start": "928600",
    "end": "934160"
  },
  {
    "text": "can run. And, you know, the consumption model from \nthat is purely serverless. And you can, you know,   write code that runs in a Lambda function or \non a Fargate instance or anywhere, and just  ",
    "start": "934160",
    "end": "943600"
  },
  {
    "text": "the model of being able to interact with these \nmodels, it's just really simple. So that's on   the one side of the consumption where serverless \nis just so easy to be able to query these models  ",
    "start": "943600",
    "end": "953320"
  },
  {
    "text": "and build amazing capabilities for companies.\nEven internally, I was working on something with  ",
    "start": "953320",
    "end": "959320"
  },
  {
    "text": "a colleague recently where we had a whole bunch \nof feedback items that we needed to summarize and,  ",
    "start": "959320",
    "end": "964360"
  },
  {
    "text": "you know, hundreds and hundreds of feedback \nitems, all really good, to go through. I,   you know, started initially going through them \nall, going, are we gonna categorize them? How  ",
    "start": "964360",
    "end": "971520"
  },
  {
    "text": "are we gonna do all that? GenAI to the rescue, \nhello, here is all our feedback items. Can you   give me the top 10 ones with the originals? And \nthere it was. And it was just what a fantastic  ",
    "start": "971520",
    "end": "982040"
  },
  {
    "text": "use case rather than crawling through the data \nmanually. So that's on the consumption side.  And then on the production side, well, GenAI \nis, of course, great at creating code. Now,  ",
    "start": "982040",
    "end": "990720"
  },
  {
    "text": "part of the whole serverless thing is we want \nyou to write as little code as possible, which   is a good thing. But the code that you do need to \nwrite, GenAI is really good at producing that. And  ",
    "start": "990720",
    "end": "1000000"
  },
  {
    "text": "if you are writing code in, you know, sort of any \nnumber of languages, you know, GenAI in services  ",
    "start": "1000000",
    "end": "1006000"
  },
  {
    "text": "like Amazon Code Whisperer, which is in your \nIDE, so if you're using VS Code or other IDEs,  ",
    "start": "1006000",
    "end": "1011040"
  },
  {
    "text": "and Amazon Q is also another GenAI service. And \nI've been using that recently where you've just  ",
    "start": "1011040",
    "end": "1016639"
  },
  {
    "text": "got a little box that comes up in your IDE and you \nsay, oh, please write me a Python Lambda function  ",
    "start": "1016640",
    "end": "1022200"
  },
  {
    "text": "that is going to consume messages from a queue and \nuse an idempotency token based on this, and just,  ",
    "start": "1022200",
    "end": "1028920"
  },
  {
    "text": "you know, 95% of all that code, boilerplate \ncode is just written for you. And it's amazing.",
    "start": "1028920",
    "end": "1034600"
  },
  {
    "text": "I think it's really gonna accelerate developers \nto be able to write the code. And once they have  ",
    "start": "1034600",
    "end": "1039679"
  },
  {
    "text": "the code, that whole operational simplicity \nof the service, they can take that code that's   generated. Obviously, they've got to sanity check \nit. The GenAI can, you know, write the test for  ",
    "start": "1039680",
    "end": "1048400"
  },
  {
    "text": "it as well, which is even better. And they can \njust, you know, upload that to a serverless like   Lambda or build a container image for Fargate, \nand off they go. Just the whole cognitive load  ",
    "start": "1048400",
    "end": "1056720"
  },
  {
    "text": "of writing the code and then also running their \ncode in production makes your life so much easier. ",
    "start": "1056720",
    "end": "1062320"
  },
  {
    "text": "I think about the things that we build in our \nteam where we're trying to create realistic   workloads for customers like serverlesspresso and \nserverless video. And when we built serverless  ",
    "start": "1062320",
    "end": "1070800"
  },
  {
    "text": "video last re:Invent, and this has all just \nstarted, we were trying to think of interesting   and clever ways to process video with GenAI. That \nwas my awakening to this, because when you look  ",
    "start": "1070800",
    "end": "1080200"
  },
  {
    "text": "at the process of managing these async requests, \nwhere you have to manage retries, error handling,  ",
    "start": "1080200",
    "end": "1086120"
  },
  {
    "text": "potentially pulling back and amalgamating \ndifferent data from different models, it was   amazing to watch how we could use step functions \nto do a lot of this with really very little code  ",
    "start": "1086120",
    "end": "1095280"
  },
  {
    "text": "and really how reliable it was. We built this \napplication and took it to re:Invent. It's used   by thousands of customers and it just works, you \nknow, really with very little code from our side. ",
    "start": "1095280",
    "end": "1105480"
  },
  {
    "text": "Well, I think that's sort of the next revolution \nin serverless that people are about to jump onto.  ",
    "start": "1105480",
    "end": "1112440"
  },
  {
    "text": "Some have already. The revolutions that \npeople have already taken to heart is the   running code in the cloud, you know, a lot of \ndata, databases, all this kind of thing. But  ",
    "start": "1112440",
    "end": "1120480"
  },
  {
    "text": "the actual orchestration and workflows, I think \npeople quite haven't grasped how powerful that  ",
    "start": "1120480",
    "end": "1126640"
  },
  {
    "text": "is. When instead of running all your code, \nyou use a managed service. And this can be,  ",
    "start": "1126640",
    "end": "1131720"
  },
  {
    "text": "as you mentioned, step functions, but there are \nother services out there like Apache Airflow   where you can just write your workflows in Python.\nMaybe that's attractive to you. It's not quite as  ",
    "start": "1131720",
    "end": "1139440"
  },
  {
    "text": "serverless, but something like step functions \nis literally amazing because if you think of   a lot of applications, what are they generally \ndoing? They are writing some custom logic and,  ",
    "start": "1139440",
    "end": "1148640"
  },
  {
    "text": "sure, it's gonna be some code that needs to \ndo some analysis or pulling in some data and   some transformation. But a lot of your code, \nyou're right, is the boring stuff of retries  ",
    "start": "1148640",
    "end": "1156960"
  },
  {
    "text": "and branching logic and SDK calls and all this \nkind of boilerplate kind of stuff. So imagine  ",
    "start": "1156960",
    "end": "1163159"
  },
  {
    "text": "if you had a service that could just orchestrate \nthose retries with exponential back off and jitter  ",
    "start": "1163160",
    "end": "1168720"
  },
  {
    "text": "and all these sort of fancy distributed computing \nterms where you don't have to think about that,   it's just done before you, you've got branching \nlogic. So a response from an API is blue or  ",
    "start": "1168720",
    "end": "1177960"
  },
  {
    "text": "green or orange or yellow, or different kind of \nvalues. And you can just go down another part of  ",
    "start": "1177960",
    "end": "1183279"
  },
  {
    "text": "a workflow. You need to write configuration code, \nnot application code. So it never ages out, never  ",
    "start": "1183280",
    "end": "1188400"
  },
  {
    "text": "needs to be patched, never needs to be tweaked.\nThen the SDK part of it is fascinating because  ",
    "start": "1188400",
    "end": "1194400"
  },
  {
    "text": "step functions has built in the AWS SDK. And \nthat is, sort of, 11,000 or 12,000 SDK calls.  ",
    "start": "1194400",
    "end": "1201760"
  },
  {
    "text": "It's ridiculous. So if you need to write to a \ndatabase, read to a database, you need to call a   machine learning model to do something, you wanna \nintegrate with Bedrock to do some generative AI,  ",
    "start": "1201760",
    "end": "1211360"
  },
  {
    "text": "you literally just fill in some configuration code \nas part of a step function state, and it's gonna  ",
    "start": "1211360",
    "end": "1216600"
  },
  {
    "text": "call this API and then respond to it. And you're \nnot having to write and maintain that code. Once   the response comes back, again, you can use the \nbranching logic to do things with it. You can run  ",
    "start": "1216600",
    "end": "1225800"
  },
  {
    "text": "parallel workflows. Yeah, it is exceptional. And \nagain, this is one of the services that customers  ",
    "start": "1225800",
    "end": "1231880"
  },
  {
    "text": "don't necessarily know super well, but once they \nstart with it, it's actually addictive and you  ",
    "start": "1231880",
    "end": "1237560"
  },
  {
    "text": "can't stop because you find so many ways that you \ncan just run these services at scale in the cloud. ",
    "start": "1237560",
    "end": "1243400"
  },
  {
    "text": "We've spent many years building these primitives \nthat are really extraordinarily reliable and   highly scalable. You've got, you know, queues \nwith SQS, notifications, SNS, event messaging,  ",
    "start": "1243400",
    "end": "1253040"
  },
  {
    "text": "buses with EventBridge workflows with step \nfunctions. The list goes on and on. These  ",
    "start": "1253040",
    "end": "1258600"
  },
  {
    "text": "are very well established services and all these \nprimitives, but if this is post-serverless, where  ",
    "start": "1258600",
    "end": "1263840"
  },
  {
    "text": "do we go from just the primitives that we've built \nto the next stage? Where do you see that going? ",
    "start": "1263840",
    "end": "1270279"
  },
  {
    "text": "I think that's a fascinating space at the \nmoment because, you know, we often talk about   infrastructure as code. That's always been a term. \nWe've talked about infrastructure as a code is  ",
    "start": "1270280",
    "end": "1277720"
  },
  {
    "text": "where you define your infrastructure instead of \nclicking around in a console or doing API calls  ",
    "start": "1277720",
    "end": "1282799"
  },
  {
    "text": "that you actually have a template, which is what \nyour infrastructure's gonna be. And, you know,   in the EC2 world, this will be EC2 instances \nand load balances and all these kind of things,  ",
    "start": "1282800",
    "end": "1292280"
  },
  {
    "text": "but it's called the infrastructures code.\nAnd actually, when you're building service   applications, you've got far less infrastructure \nto worry about. But you're actually setting up,  ",
    "start": "1292280",
    "end": "1300240"
  },
  {
    "text": "as I mentioned before, you know, databases \nor queues or events or you connected to a  ",
    "start": "1300240",
    "end": "1306080"
  },
  {
    "text": "database to get streaming data for CDC data. \nThose are actually application constructs,  ",
    "start": "1306080",
    "end": "1312159"
  },
  {
    "text": "even though we call them infrastructure. And so \na lot of developers are sort of scratching their   heads going, is setting up a messaging queue as \na buffer between two applications infrastructure,  ",
    "start": "1312160",
    "end": "1322520"
  },
  {
    "text": "or is it application code? And the fact \nis it's actually merging of both of them.  And so in a post-serverless world, we are \nactually moving away from assembling these  ",
    "start": "1322520",
    "end": "1331600"
  },
  {
    "text": "infrastructure bits, but it's actually about \ncomposing different parts of an application   using programmable cloud constructs. And those \nare gonna be done in various different ways. And  ",
    "start": "1331600",
    "end": "1342360"
  },
  {
    "text": "there's obviously been the rise of more general \nlanguages, which are things like when you write  ",
    "start": "1342360",
    "end": "1348880"
  },
  {
    "text": "your infrastructure/architecture application \ncode in the same language as your business   logic. So you've got things like the CDK from AWS, \nit's a cloud development kit, but also Pulumi,  ",
    "start": "1348880",
    "end": "1359360"
  },
  {
    "text": "which is a sort of infrastructures code, \nbut, you know, written in Python or Node  ",
    "start": "1359360",
    "end": "1365400"
  },
  {
    "text": "or Go or JavaScript and everything. So that's \nsuper attractive for developers to be able to   build their applications in the same code.\nBut what's also happening is there's sort  ",
    "start": "1365400",
    "end": "1373640"
  },
  {
    "text": "of even an elevation above that where you \nno longer even know or have to worry about   what infrastructure is being built. And so the \ncompany's called Winglang and Ampt, for example,  ",
    "start": "1373640",
    "end": "1383640"
  },
  {
    "text": "where you actually just write your application \ncode and it figures it out and goes, oh, well,  ",
    "start": "1383640",
    "end": "1388960"
  },
  {
    "text": "in order to achieve this, we are gonna build you \na Lambda function, or we are gonna build you a   step function, or sometimes a step function's \nworkflow, although I'm not quite sure if that's  ",
    "start": "1388960",
    "end": "1397440"
  },
  {
    "text": "quite ready there yet, or we are gonna build, \nsay, a Lambda function and a Fargate task.  And then if you code in your application code that \nmaybe you need some rate limiting, for example,  ",
    "start": "1397440",
    "end": "1408920"
  },
  {
    "text": "it's gonna maybe, you know, put in the weeds for \nLambda, but some concurrency, or it's gonna say,   well, actually it'll make sense to put a queue in \nfront of that as well. That's all written as part  ",
    "start": "1408920",
    "end": "1417679"
  },
  {
    "text": "of your application and these tools are gonna \ninfer from your application and build these new  ",
    "start": "1417680",
    "end": "1423040"
  },
  {
    "text": "composable constructs. And so in a way, we're way \nelevated even above the application constructs,  ",
    "start": "1423040",
    "end": "1428400"
  },
  {
    "text": "let alone infrastructure constructs. Again, \nthat's gonna be a super interesting space   where developers are just gonna, you know, \nwrite the sort of pseudocode of what they  ",
    "start": "1428400",
    "end": "1435960"
  },
  {
    "text": "need and then the business logic and the cloud is \njust gonna figure out how to put it all together.",
    "start": "1435960",
    "end": "1441200"
  },
  {
    "start": "1441000",
    "end": "1780000"
  },
  {
    "text": "Now, you are famous at this point for creating \none of the most popular sessions at re:Invent,  ",
    "start": "1441920",
    "end": "1448080"
  },
  {
    "text": "where you've essentially pulled together \neverything that's happened in this space over   a year.  I know you focus primarily on Lambda, but \nyou do look at all this sort of broader picture in  ",
    "start": "1448080",
    "end": "1457400"
  },
  {
    "text": "what you do. And you've built this presentation \nthat, you know, I think it's 1000 slides at this  ",
    "start": "1457400",
    "end": "1462840"
  },
  {
    "text": "point now, but if you think about the last...I \nthink it takes four years to put this together,   but if you think about the, the last one, and go \nback to the Lambda side of it and the compute side  ",
    "start": "1462840",
    "end": "1473080"
  },
  {
    "text": "of this, what are some of the things last year \nthat stuck out to you as being, you know, really   some remarkable things that have changed that \nnow give you some superpowers in what you build? ",
    "start": "1473080",
    "end": "1482759"
  },
  {
    "text": "I think it's this merging, as we were \nspeaking about earlier, between containers   and serverless. And I'm talking specifically \nabout serverless functions and containers,  ",
    "start": "1483520",
    "end": "1492320"
  },
  {
    "text": "because before there was this maybe unwritten, \nI was never part of it, but some unwritten,   there had to be some war between containers and \nserverless that they were mutually exclusive. And  ",
    "start": "1492320",
    "end": "1501000"
  },
  {
    "text": "that never made sense to me because fantastic \nuse cases for containers, fantastic use cases   for functions, but there was a bit of a divide \nbetween the two of how the two are gonna coexist. ",
    "start": "1501000",
    "end": "1511840"
  },
  {
    "text": "And now actually since Lambda has come \nout with being able to build Lambda   functions from container images, wow, that's \nfantastic developer fullness because you're  ",
    "start": "1511840",
    "end": "1522080"
  },
  {
    "text": "used to building Docker files for your other \napplications. Well, you can just use a Docker   file to build your Lambda function. We still \ntake a lot of operational overhead of actually  ",
    "start": "1522080",
    "end": "1530040"
  },
  {
    "text": "building that and running it for you. But yeah, \nthat's really cool that you can do that. And   it's not just being able to run a Docker file, \nlike, massive amounts of innovation that goes  ",
    "start": "1530040",
    "end": "1538760"
  },
  {
    "text": "on behind the scenes to make that super fast.\nPeople worry about cold starts. That's where,  ",
    "start": "1538760",
    "end": "1543840"
  },
  {
    "text": "you know, functions need to start up. But actually \nwhen you are using container images for Lambda,   we cache so much of that information within \nthe actual service that cold starts are really  ",
    "start": "1544440",
    "end": "1552960"
  },
  {
    "text": "negligible. And in actually in many cases, cold \nstarts can even be faster with bigger images than   they would with a previous way of doing Lambda. \nYeah. So, you know, that's an amazing innovation  ",
    "start": "1552960",
    "end": "1564440"
  },
  {
    "text": "where we do things before you, where we meet you \nwhere you are doing container imaging and then do   a whole bunch of innovation behind the scenes to \nmake that actually realistically work. But yeah,  ",
    "start": "1565440",
    "end": "1574400"
  },
  {
    "text": "I mean, Lambda is continuing to evolve.\nI mean, there's no post-serverless that   means nothing stops with Lambda. You know, Lambda \nis becoming so broad that it handles so many use  ",
    "start": "1574400",
    "end": "1582679"
  },
  {
    "text": "cases. If you think it runs for 15 minutes, \n10 gigs of memory, 10 gigs of local storage,   6 virtual CPUs, you know, that's a huge amount you \ncan do in that. And that's just one invocation,  ",
    "start": "1582680",
    "end": "1592240"
  },
  {
    "text": "these scale out ridiculously. At re:Invent \nthis past year we even changed the scaling  ",
    "start": "1592240",
    "end": "1598320"
  },
  {
    "text": "model for Lambda on its head that previously we \nbasically 12xed to Lambda scaling. So Lambda can  ",
    "start": "1598320",
    "end": "1604080"
  },
  {
    "text": "scale up to, you know...1000 functions \ncan run every 10 seconds. So I mean,   there are massive use cases and massive \nworkloads that you could just do on Lambda. ",
    "start": "1604080",
    "end": "1612960"
  },
  {
    "text": "And again, you know, that figure for \nthe scaling 1000 every 10 seconds,   but you don't need to worry how that actually \nhappens or if there's capacity or what goes on.  ",
    "start": "1612960",
    "end": "1620559"
  },
  {
    "text": "So yeah, lots of innovation still going \non in Lambda and we'll continue where we   just chip away if there's use cases. And, you \nknow, Lambda was founded on this, let's build  ",
    "start": "1620560",
    "end": "1630640"
  },
  {
    "text": "best practices in the cloud. So we talk about \nwell-architected, it's a term we use at AWS,   which is just baking in the best practices of \nall the years of we doing running distributed  ",
    "start": "1630640",
    "end": "1638679"
  },
  {
    "text": "applications. And we just gonna build more of that \nin Lambda so you don't have to. And so you can run   these massive distributed applications without \nneeding to know about distributed applications. ",
    "start": "1638680",
    "end": "1647880"
  },
  {
    "text": "So even though this has really been around for \na decade, we still see lots of customers who are   very new in this space coming to Lambda and ECS \nFargate, all of these tools. If you could distill  ",
    "start": "1648440",
    "end": "1658480"
  },
  {
    "text": "down, like, what are the two or three things that \nare good pieces of advice you can give so they can  ",
    "start": "1658480",
    "end": "1665120"
  },
  {
    "text": "get started quickly building in this environment?\nI think first of all, try not to get overwhelmed  ",
    "start": "1665120",
    "end": "1671200"
  },
  {
    "text": "because serverless is everywhere and can be \neverywhere. I think find a small use case   and then play and iterate. And a lot of \nour serverless services have huge amounts  ",
    "start": "1671200",
    "end": "1681720"
  },
  {
    "text": "of functionality because they could do a lot. \nBut I would start small and start simple. Now,  ",
    "start": "1681720",
    "end": "1687480"
  },
  {
    "text": "think of a use case that you're gonna do. Maybe \nit's just running some code that's gonna respond   to an API request. So you can connect up an API \nwith Lambda really easily. It can either be native  ",
    "start": "1687480",
    "end": "1697799"
  },
  {
    "text": "with something called function URLs or behind a \nmore fully featured API service, like API Gateway.  ",
    "start": "1697800",
    "end": "1703520"
  },
  {
    "text": "And you basically hit the API Gateway endpoint \nevery time you do a get, post, delete or whatever,   it's just gonna run a Lambda function. And that \nis very cognitively easily to set up. You iterate  ",
    "start": "1703520",
    "end": "1713039"
  },
  {
    "text": "really quickly on it and you can understand \nevery time you hit that API endpoint, your   code is going to return some response. That's a \nreally easy way to just understand how that works. ",
    "start": "1713040",
    "end": "1722200"
  },
  {
    "text": "Another one is data processing as well \nbecause so many companies are using data   processing. If you are using, you know, Kafka \nor Kinesis in AWS, which is specific there,  ",
    "start": "1722800",
    "end": "1733680"
  },
  {
    "text": "or queues like RabbitMQ or SQS or these kind of \nthings, to process data asynchronous from these  ",
    "start": "1733680",
    "end": "1740560"
  },
  {
    "text": "queues is just one of the wonders of Lambda. And \nLambda runs a polar for you. It's even free. And  ",
    "start": "1740560",
    "end": "1746240"
  },
  {
    "text": "so you can very simply just write some code that \nis gonna iterate over the messages in that and,   you know, maybe persist it to a database, \nmaybe write some GenAI, who knows. ",
    "start": "1746240",
    "end": "1754399"
  },
  {
    "text": "Those are sort of two easy use cases to think of, \nbut also recommend that, you know, people, look,   we've got a site called serverlessland.com. If \nyou've go to the learn page we've got so many use  ",
    "start": "1754400",
    "end": "1764279"
  },
  {
    "text": "cases there, you've got serverlessland.com/lambda. \nWe've got videos and learning guides and training   material and everything. So yeah, try not \nto get overwhelmed because Lambda and other  ",
    "start": "1764280",
    "end": "1772880"
  },
  {
    "text": "services can do a lot. Find a little use \ncase you've got and there'll certainly   be some example code out there that you can at \nleast learn and understand how it fits together.",
    "start": "1772880",
    "end": "1781400"
  },
  {
    "start": "1780000",
    "end": "2494000"
  },
  {
    "text": "Another topic I was thinking about for really \narchitects and for CTOs and people who are making  ",
    "start": "1781400",
    "end": "1786600"
  },
  {
    "text": "these decisions, and yeah, increasingly developers \njust because there's more responsibility coming to   that space, is around cost. I think it's \nsomething we haven't really talked that  ",
    "start": "1786600",
    "end": "1796200"
  },
  {
    "text": "much about because we always, you know, look at \nLambda as being relatively inexpensive if you get,   you know, 1 million implications, 20 cents and \nso forth, and sort of very generous free tier. ",
    "start": "1796200",
    "end": "1805000"
  },
  {
    "text": "When you think about production level scale, \nthere's so many aspects of cost that come into   this. And I think there's still some confusion \nabout this because, yeah, there's a lot of sunk  ",
    "start": "1805000",
    "end": "1815040"
  },
  {
    "text": "costs in on-prem IT, and, you know, there's \nlots of different ways of measuring things,  ",
    "start": "1815040",
    "end": "1820760"
  },
  {
    "text": "but what are some ways you can think of where we \ncan...a simple way to look at the cost of running  ",
    "start": "1820760",
    "end": "1826120"
  },
  {
    "text": "workloads in this environment where you can make \ndecisions that are, you know, is it a good fit   for serverless or should you do something else?\nI think one of the benefits of serverless is  ",
    "start": "1826120",
    "end": "1835680"
  },
  {
    "text": "because it is small pieces loosely joined that \nyou actually have way more visibility, at least  ",
    "start": "1835680",
    "end": "1841320"
  },
  {
    "text": "first of all, into your costs. Because you may \nbe running different Lambda functions or you are   using a message queue or using an orchestration \nservice like step functions, the pricing for all  ",
    "start": "1841320",
    "end": "1850360"
  },
  {
    "text": "of these is, you know, per function that runs, \nper state transition, so it's extremely granular.  ",
    "start": "1850360",
    "end": "1857120"
  },
  {
    "text": "And that's super attractive to companies because \npreviously they would have something on an EC2   instance or a whole bunch of stuff in a container, \nand that just runs, and they've got no idea of the  ",
    "start": "1857120",
    "end": "1866800"
  },
  {
    "text": "actual costs of what's running in that.\nAnd so with a serverless model, yes,   it's gonna take some work to understand the \ndifferent cost dimensions, but you can be able to  ",
    "start": "1866800",
    "end": "1874120"
  },
  {
    "text": "model your application in a far more granular way. \nAnd you're gonna be able to find out, for example,  ",
    "start": "1874120",
    "end": "1880040"
  },
  {
    "text": "my front-facing API that is, you know, returning \nitems to buy on my shopping cart or to my website.  ",
    "start": "1880040",
    "end": "1886000"
  },
  {
    "text": "Well, that's really, really critical. So you are \ngonna be willing to, you know, ensure that that   is as performant as possible. And the cool \nthings with serverless, the quicker it runs,  ",
    "start": "1886000",
    "end": "1894400"
  },
  {
    "text": "the cheaper it's gonna be. A lot of optimizations \nyou can do on all these kind of services to make  ",
    "start": "1894400",
    "end": "1900000"
  },
  {
    "text": "things fast. But, you know, then that's \nwhere you can spend your amount of time   because that's making money for your business.\nBut if you've got some asynchronous task that is  ",
    "start": "1900000",
    "end": "1908480"
  },
  {
    "text": "doing, you know, backups or putting something into \na compliance database or all these kind of things,  ",
    "start": "1908480",
    "end": "1914000"
  },
  {
    "text": "you can look at that and go, oh, I've actually \nspotted the Lambda function that's running that   it's costing me, you know, an arm and a leg, \nwhat's going on here? And you can look at your  ",
    "start": "1914000",
    "end": "1921000"
  },
  {
    "text": "code just for that example and say, oh, wow, \nI didn't realize there were some optimizations   we could do. Or, you know, splitting things up \nor using another service. And just being able  ",
    "start": "1921000",
    "end": "1929120"
  },
  {
    "text": "to iterate quickly and optimize individual \ncosts within your application can be super  ",
    "start": "1929120",
    "end": "1934200"
  },
  {
    "text": "important rather than, you know, all of that \ncodes in one big kind of thing and you just,   you don't know really where to look at.\nI think that's one thing I wish we would,  ",
    "start": "1934200",
    "end": "1942920"
  },
  {
    "text": "you know, in our group talk about more actually \nover time is about asynchronous development   because, you know, a lot of developers are used \nto working in a server in a single memory space  ",
    "start": "1942920",
    "end": "1952320"
  },
  {
    "text": "and just doing a job where you take some \ndata from an API, put it into a database,   running scripts and so forth. But as this evolves, \nreally to me, the asynchronous development is the  ",
    "start": "1952320",
    "end": "1962360"
  },
  {
    "text": "magic behind the whole thing that gives you the \nscale and the control and significantly more  ",
    "start": "1962360",
    "end": "1969120"
  },
  {
    "text": "visibility into what the application is doing. And \nif you look at, you know, Amazon's applications,   like when we have Prime Day, this is all \nbeing powered by asynchronous processes,  ",
    "start": "1969120",
    "end": "1977120"
  },
  {
    "text": "then it gives the company that enormous scale \nfor these events. But it definitely, when I talk   to developers, it seems to be something that \nisn't that well understood in many circles. ",
    "start": "1977120",
    "end": "1986240"
  },
  {
    "text": "That is true. I's a shame and it's slightly odd \nbecause specifically for JavaScript developers,  ",
    "start": "1987640",
    "end": "1994480"
  },
  {
    "text": "if you're using Node.js and you're familiar \nwith the event loop, ultimately that is partly  ",
    "start": "1994480",
    "end": "1999760"
  },
  {
    "text": "an asynchronous process where you just, you \nknow, do a promise or that kind of thing,   and eventually that code's gonna run somewhere \nand come back and tell you when it's finished.  ",
    "start": "1999760",
    "end": "2008120"
  },
  {
    "text": "And that, sort of, asynchronicity can be expanded \ninto the whole, sort of, world of cloud. And yeah,  ",
    "start": "2008120",
    "end": "2014920"
  },
  {
    "text": "just super important and such a great building \nblock for building applications because separating  ",
    "start": "2014920",
    "end": "2021040"
  },
  {
    "text": "two different services in a smart way where \nthere's less coupling and you're not overwhelming  ",
    "start": "2021040",
    "end": "2026560"
  },
  {
    "text": "a downstream service or you're able to handle, you \nknow, spikes and downtime and issues and that kind  ",
    "start": "2026560",
    "end": "2032560"
  },
  {
    "text": "of thing is super effective. And a lot of these \nasynchronous services, that's just built in.  I mean, if you talk about even Lambda or \nEventBridge or these kind of serverless services,  ",
    "start": "2032560",
    "end": "2041159"
  },
  {
    "text": "step functions we mentioned before, they're \nmulti-AZ by default. You're not deploying   Lambda functions in specific availability zones \nor having to, you know, failover EventBridge  ",
    "start": "2041160",
    "end": "2050120"
  },
  {
    "text": "or some other kind of thing. And so, you know, \nputting a message onto an EventBridge event bus,  ",
    "start": "2050120",
    "end": "2055280"
  },
  {
    "text": "it's gonna be there, it's gonna have retries \nand error logic built into it, so much more  ",
    "start": "2055280",
    "end": "2060800"
  },
  {
    "text": "available and you're gonna be able to send those \nmessages onto other kind of services. And yeah,   I think you'd be surprised also the \nperformance characteristics of these. ",
    "start": "2060800",
    "end": "2068319"
  },
  {
    "text": "Because a lot of people think, oh, well, I \nmust use my synchronous workloads as for my   really fast workloads and then anything async, \noh, well, you know, that's batch processing,  ",
    "start": "2068320",
    "end": "2076560"
  },
  {
    "text": "or that's stuff that's gonna take a long time. I \ncan wait for in the order of, you know, minutes  ",
    "start": "2076560",
    "end": "2082040"
  },
  {
    "text": "to hours. But asynchronous can be super fast. And \nit's surprising. Even when you were talking about  ",
    "start": "2082040",
    "end": "2088000"
  },
  {
    "text": "the serverless video and serverlesspresso, those \nare a mix of sync and async applications, but all  ",
    "start": "2088000",
    "end": "2094120"
  },
  {
    "text": "of the frontend notifications from the application \nare all actually started asynchronously. And there's a whole process, you know, \nsomething will happen in the backend,  ",
    "start": "2094120",
    "end": "2101360"
  },
  {
    "text": "which calls a notification and that sends it using \nIoT core over to the front-end via an async Lambda  ",
    "start": "2101360",
    "end": "2107360"
  },
  {
    "text": "function. And you're sitting on your mobile \nphone ordering your coffee or watching a video,   and you have no idea that this is, you know, \nan async process that you would expect to be  ",
    "start": "2107360",
    "end": "2116360"
  },
  {
    "text": "really slow. And, yeah, it's as fast as you \ncan write a message. So, I think that's also  ",
    "start": "2116360",
    "end": "2122160"
  },
  {
    "text": "the model that's gonna evolve is building these \nasynchronous processes, but understanding that   they can be as performant to synchronous ones.\nI think Lambda functions, the name might be a  ",
    "start": "2122160",
    "end": "2132920"
  },
  {
    "text": "little bit misleading because, it's not just \na function really, a Lambda function can be an   entire microservice.\nMini app. ",
    "start": "2132920",
    "end": "2139240"
  },
  {
    "text": "You can scale up to the Lambdalith, where in some \ncases it can be even an entire application. And so   there's been this debate for years about how big \nshould your Lambda function be. Luca Mesalero had  ",
    "start": "2139240",
    "end": "2150360"
  },
  {
    "text": "a really good article in the Compute Blog earlier \nthis week about this, where we see customers start  ",
    "start": "2150360",
    "end": "2155640"
  },
  {
    "text": "with the Lambdalith, where it's just basically \nlift and shift everything into one big function   to do everything. Or they go and start with one \nfunction per purpose, which is where I started,  ",
    "start": "2155640",
    "end": "2166200"
  },
  {
    "text": "where you have lots of tiny functions all \ncompletely independently, and you tend to   then find problems whichever way you started and \ngo violently opposite direction, go Lambdalith to  ",
    "start": "2166200",
    "end": "2175520"
  },
  {
    "text": "single function or vice versa. And he proposed a \nthird way, which I thought was interesting around  ",
    "start": "2175520",
    "end": "2180800"
  },
  {
    "text": "how you can dissect this. But that, to me, is \npart of the evolution of the post-serverless   idea about the architecture of applications.\nDefinitely. And I think that sort of evolution  ",
    "start": "2180800",
    "end": "2191160"
  },
  {
    "text": "is natural and healthy. And I think fantastic. \nAnd in fact, even the term Lambdalith is something  ",
    "start": "2191160",
    "end": "2196880"
  },
  {
    "text": "I've sort of tried to avoid speaking about anymore \nbecause customers previously have been building  ",
    "start": "2196880",
    "end": "2201960"
  },
  {
    "text": "applications on EC2 instances, and maybe they've \neven been using containers. And then that is a  ",
    "start": "2201960",
    "end": "2207720"
  },
  {
    "text": "proper monolith, we're talking big applications \nover here and they've wisely decided maybe we're   gonna use Lambda. And they then will take even \na Flask application or an Express application  ",
    "start": "2207720",
    "end": "2218480"
  },
  {
    "text": "or some sort of application that's got 7, 8, 9, 10 \ndifferent code functions within their function and  ",
    "start": "2218480",
    "end": "2226240"
  },
  {
    "text": "they've moved it to Lambda and it's working.\nAnd then we've come up to them and said,   well you know, the story is really, you should \nbe using Lambda for, you know, a single-purpose  ",
    "start": "2226240",
    "end": "2235920"
  },
  {
    "text": "workload and doing all these kind of things. \nIf you're not doing that, you're building a   Lambdalith. And they're like, hang on, hang on, \nhang on, I've just gone from a monolith over  ",
    "start": "2235920",
    "end": "2242480"
  },
  {
    "text": "there. I've moved to Lambda. That's a great thing. \nWhy are you still calling it a lith? You know,   this is freaking me out. And so I think we maybe \nput some people off in terms of the terming, using  ",
    "start": "2242480",
    "end": "2253800"
  },
  {
    "text": "the term of a Lambdalith, that's a bad thing. \nAnd as you say, it's two different approaches  ",
    "start": "2253800",
    "end": "2259640"
  },
  {
    "text": "to it. You either get very granular, you've got \nsuper tight permission, you've got super control  ",
    "start": "2259640",
    "end": "2264799"
  },
  {
    "text": "over everything, but a lot of Lambda functions \nto run, and that's gonna be a hassle operation.  Or you put everything in a single Lambda \nfunction and then you haven't got as much  ",
    "start": "2264800",
    "end": "2273360"
  },
  {
    "text": "control over their kind of things. And so, as with \nall consultants, they say it depends and there's  ",
    "start": "2273360",
    "end": "2278440"
  },
  {
    "text": "gonna be a sweet spot for you somewhere in the \nmiddle. And, you know, Luca's post had a really   good idea of, well, if you're gonna have a whole, \nyou know, separate your writes and your reads,  ",
    "start": "2278440",
    "end": "2287079"
  },
  {
    "text": "for example. Your writes and your reads are gonna \nhave different database permissions, you're gonna   be able to set up, maybe you've got a relational \ndatabase that you can optimize where it's gonna  ",
    "start": "2287080",
    "end": "2296160"
  },
  {
    "text": "write and you're gonna have read caches somewhere \nelse for reading from it, or you're gonna have   a separate cache service like Elastic Cache and \nyeah. So you can, you know, group your functions,  ",
    "start": "2296160",
    "end": "2304720"
  },
  {
    "text": "have a function for read and a function for write.\nYou've got all the permissions, the granularity  ",
    "start": "2304720",
    "end": "2310520"
  },
  {
    "text": "and still high performance, and yet you're \nnot managing so many Lambda functions that   that becomes unwieldy. So yeah, that is \nthe evolution. And I actually love how  ",
    "start": "2310520",
    "end": "2317840"
  },
  {
    "text": "the architectural practices are evolving and we \ndon't wanna be too pragmatic and say, you know,   there are any wrong or right ways because, you \nknow, customers do awesome things. And we want  ",
    "start": "2317840",
    "end": "2326800"
  },
  {
    "text": "to sort of give you, here are the tools, you can \nuse it and we are gonna try and help you make the   best choices. And hopefully actually try with the \nservice way, reduce the mistakes you can make. ",
    "start": "2326800",
    "end": "2337720"
  },
  {
    "text": "I think what's fascinating about this space, \nand one of the great things again about our job  ",
    "start": "2337720",
    "end": "2342760"
  },
  {
    "text": "is we've got this amazing community. So, you \nknow, you think about the millions of people   who use Lambda every day, within this, there's \nthis huge community of builders and heroes who  ",
    "start": "2342760",
    "end": "2353720"
  },
  {
    "text": "are very vocal and having these debates. And for \nus, it's interesting I think, to stand back and  ",
    "start": "2353720",
    "end": "2358800"
  },
  {
    "text": "watch what they're building and why they land on \nthese certain decision points. But over the years,  ",
    "start": "2358800",
    "end": "2364400"
  },
  {
    "text": "a lot of things oscillate between one direction or \nanother. And I think about things like the runtime   choice, you know, that right now there's a big \npush around what sort of runtimes you can choose  ",
    "start": "2364400",
    "end": "2373320"
  },
  {
    "text": "for optimizing performance. But many respects, \nI'm not sure it matters. Lambda works incredibly  ",
    "start": "2373320",
    "end": "2378640"
  },
  {
    "text": "well with really a choice of runtime and, you \nknow, your own expertise should probably be the   driving choice. But at the same time, it's just \nfascinating to see how fast it can get when people  ",
    "start": "2378640",
    "end": "2388120"
  },
  {
    "text": "use Rust or Go or some of these newer runtimes.\nJulian Wood:  Well I think that's sort of,  ",
    "start": "2388120",
    "end": "2393520"
  },
  {
    "text": "you know, just showing how evolved and how mature \nthe platform is, where yeah. I mean, some of these  ",
    "start": "2393520",
    "end": "2399840"
  },
  {
    "text": "runtimes are, you know, low single millisecond \nlatency for a Lambda function to run. I mean,  ",
    "start": "2399840",
    "end": "2405200"
  },
  {
    "text": "it's exceptional. And so you think all of the \npower and all of the scale for so many millions   of customers behind the scenes. And yet you can \nrun a Lambda function with up to 10-giga RAM,  ",
    "start": "2405200",
    "end": "2415319"
  },
  {
    "text": "as I said, six virtual CPUs in, I don't know \nhow many regions across the world. I mean,   it's the world's biggest, you know, distributed \nsupercomputer and it's available in millisecond  ",
    "start": "2415320",
    "end": "2423839"
  },
  {
    "text": "latency. So it's actually incredible.\nWhen you get into the optimization side   of things, it's really fascinating. Because \nobviously, you know, you can fine-tune Lambda  ",
    "start": "2423840",
    "end": "2432160"
  },
  {
    "text": "functions to be incredibly fast with all these \nlevels that you have available. But then when   I look at some of the things we've built, \nactually, you know, you can sometimes just  ",
    "start": "2432160",
    "end": "2439720"
  },
  {
    "text": "remove the Lambda function completely. And again, \nnothing's faster than no compute. So, you know,  ",
    "start": "2439720",
    "end": "2446440"
  },
  {
    "text": "when I look at API gateway integrations and \nhow those play into these asynchronous designs,  ",
    "start": "2446440",
    "end": "2452359"
  },
  {
    "text": "I'm starting to see more of that, more \npopular...it seems to me a really clever way  ",
    "start": "2452360",
    "end": "2457760"
  },
  {
    "text": "of getting that scale and that throughput really \nwithout any sort of code maintenance at all. ",
    "start": "2457760",
    "end": "2463560"
  },
  {
    "text": "That's one of the big pushes of serverless when \nyou started this conversation about it started   being run your code in the cloud. Well, you know, \nwe wanna encourage you to run and write as little  ",
    "start": "2464320",
    "end": "2473760"
  },
  {
    "text": "code as possible. And so with step functions, \nand it's SDK integrations and API gateways,   you mentioned with direct integrations with \na whole bunch of services. Yeah, I mean,  ",
    "start": "2473760",
    "end": "2483800"
  },
  {
    "text": "I'm certainly not the world's best coder. I \ndon't wanna run my code in production. So some   other service can run my, you know, business \nfunctionality on my behalf, yeah, bring it on.",
    "start": "2483800",
    "end": "2494160"
  },
  {
    "start": "2494000",
    "end": "2655000"
  },
  {
    "text": "So, now you've been doing this...I mean, \nyou've been here as long as I have,   working on these things, and we think about \npost-serverless in the years to come. If you  ",
    "start": "2494160",
    "end": "2502040"
  },
  {
    "text": "fast forward five years from now, what do you \nsee customers doing in the serverless space  ",
    "start": "2502040",
    "end": "2507776"
  },
  {
    "text": "as different, or maybe just the same, but, \nyou know, how do you think it would evolve? ",
    "start": "2507776",
    "end": "2512240"
  },
  {
    "text": "I hope that it just becomes more of the new \nnormal and some of the operational practices  ",
    "start": "2513560",
    "end": "2519360"
  },
  {
    "text": "just are embedded with companies. I'd like \nto see more of the platform evolution,  ",
    "start": "2519360",
    "end": "2527920"
  },
  {
    "text": "you know, a lot of companies building platform \nengineering teams, and they're still taking a lot  ",
    "start": "2528760",
    "end": "2533920"
  },
  {
    "text": "of heavy lifting at the moment, specifically \nwhen they're running container workloads.   A little bit less so with Lambda. But as \nthose two worlds converge in the future,  ",
    "start": "2533920",
    "end": "2542599"
  },
  {
    "text": "I'd love to see just best practices built in, \nplatforms that companies can just use and run  ",
    "start": "2542600",
    "end": "2550720"
  },
  {
    "text": "services codes with observability and all the \nmetrics and all the cool cloud stuff built in. ",
    "start": "2550720",
    "end": "2558920"
  },
  {
    "text": "It's gonna be interesting to see if there are \ngonna be any groundbreaking new approaches or   new changes. We have been speaking about some \nof the inferring architecture from the code.  ",
    "start": "2558920",
    "end": "2567680"
  },
  {
    "text": "That's exciting. Yeah, it's gonna be exciting \nto see what AWS and even our ecosystem partners  ",
    "start": "2567680",
    "end": "2573240"
  },
  {
    "text": "are gonna be able to build in the future. But \nI think the post-serverless world is, sort of,   here and is gonna continue, and there's \njust gonna be more and more iterations and  ",
    "start": "2573240",
    "end": "2580040"
  },
  {
    "text": "more and more improvement and yeah, good for it.\nI think if people are listening, what you might  ",
    "start": "2580040",
    "end": "2587000"
  },
  {
    "text": "not realize is that you're responsible for the \nfuture. So the way you get built here is that you  ",
    "start": "2587000",
    "end": "2592720"
  },
  {
    "text": "tell us what you want and we build it, and in AWS \nthat's entirely how our roadmaps are put together  ",
    "start": "2592720",
    "end": "2598800"
  },
  {
    "text": "is with the ideas that customers have. So the \nfuture is not set in terms of AWS's vision. It's  ",
    "start": "2598800",
    "end": "2605360"
  },
  {
    "text": "very influenceable by what customers are building. \nSo to me, it's gonna be amazing to see what's  ",
    "start": "2605360",
    "end": "2610480"
  },
  {
    "text": "coming out in the next five years or so.\nWe are just talking about serverless and   functions, you know, the whole web space is \ngrowing and going, you know, crazy with so  ",
    "start": "2610480",
    "end": "2618799"
  },
  {
    "text": "much innovation over there. So yeah, watch the \nspace. Let us know what we should build. I mean,   we'd love to do it. That's what we \nare here for is to make your life  ",
    "start": "2618800",
    "end": "2626600"
  },
  {
    "text": "easier. Let us know and we'll try and get on it.\nYou can always contact any of us in the BA team.  ",
    "start": "2626600",
    "end": "2632400"
  },
  {
    "text": "If you go to Serverlessland, we have a number of \nrepos, number of contact sites there, or you can   reach out to us on LinkedIn or email, but we're \nalways interested in hearing what your ideas are. ",
    "start": "2632400",
    "end": "2642480"
  },
  {
    "text": "Some of those are product ideas, but also if there \nare things you don't understand or want explained   in a different way, yeah, let us know. You know, \nthat's what we love doing is to be able to,  ",
    "start": "2642480",
    "end": "2650240"
  },
  {
    "text": "you know, bridge the gap between, you know, what \npeople need to understand and what we can create. ",
    "start": "2650240",
    "end": "2654600"
  },
  {
    "start": "2655000",
    "end": "2694000"
  },
  {
    "text": "Well, it's a really exciting world of \nexperimentation that even though it's   10 years old still feels very new to me \nand it's really exciting to see people,  ",
    "start": "2655800",
    "end": "2663640"
  },
  {
    "text": "what they're doing. So, Julian, it's always a \npleasure to chat with you. You've always got   some really interesting insights and what we've \ngone with serverless and where we're going, but  ",
    "start": "2663640",
    "end": "2671720"
  },
  {
    "text": "I think we're at time now. So thank you very much. \nMy name's James Beswick and this is Julian Wood,   and we'll see you all again soon.\nBye-bye.",
    "start": "2671720",
    "end": "2693400"
  }
]
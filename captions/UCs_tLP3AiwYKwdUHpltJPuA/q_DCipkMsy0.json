[
  {
    "text": "okay So welcome to this afternoon and I'm going to talk about designing systems that are responsive in this",
    "start": "7520",
    "end": "13880"
  },
  {
    "text": "track and I spend a lot of time in finance space big data space different",
    "start": "13880",
    "end": "19199"
  },
  {
    "text": "things where we need to respond in a timely manner which is an interesting part of performance So performance is",
    "start": "19199",
    "end": "24680"
  },
  {
    "text": "typically something that people say but it means one of two things typically it's throughput or latency So the",
    "start": "24680",
    "end": "30080"
  },
  {
    "text": "latency or response time is what this is all going to be about And when we design our applications if we don't respond in",
    "start": "30080",
    "end": "38320"
  },
  {
    "text": "a timely manner things don't happen so well So take this poor person here They",
    "start": "38320",
    "end": "44000"
  },
  {
    "text": "haven't reacted quick enough and that's going to cause a lot of pain A lot of our applications end up the same way And",
    "start": "44000",
    "end": "50879"
  },
  {
    "text": "a lot of people talk about how things need to be real time these days I want to clarify a little bit about what real",
    "start": "50879",
    "end": "57120"
  },
  {
    "text": "time means And I like to think of real time in one of three ways It's either",
    "start": "57120",
    "end": "62160"
  },
  {
    "text": "what's known as hard real time So this is typically what you'll find when",
    "start": "62160",
    "end": "67600"
  },
  {
    "text": "you're programming in sort of things that are very very time constrained You must be so deterministic that if you're",
    "start": "67600",
    "end": "74640"
  },
  {
    "text": "not deterministic it is a catastrophic failure This example here is a gun that",
    "start": "74640",
    "end": "80400"
  },
  {
    "text": "you'll find on a British warship called the goalkeeper And its job is at that",
    "start": "80400",
    "end": "85520"
  },
  {
    "text": "very last instant when a ship is being attacked it has to defend it Whenever all of your outer defenses have been got",
    "start": "85520",
    "end": "93000"
  },
  {
    "text": "passed there's a missile or some plane coming in and it's really close moving really fast What stops it it's not a",
    "start": "93000",
    "end": "100320"
  },
  {
    "text": "person driving this It's a piece of software being guided by radar operates this sort of gun Now if the software on",
    "start": "100320",
    "end": "107759"
  },
  {
    "text": "this does not respond people die That's the extreme of real",
    "start": "107759",
    "end": "113240"
  },
  {
    "text": "time But many of us aren't at that extreme But we're at other ends of to",
    "start": "113240",
    "end": "119040"
  },
  {
    "text": "the spectrum And one of the things is like I call soft real time So financial markets are typically like this And in",
    "start": "119040",
    "end": "126560"
  },
  {
    "text": "this if you don't respond in a timely manner you end up losing money Maybe not a lot of money sometimes a lot of money",
    "start": "126560",
    "end": "132720"
  },
  {
    "text": "Night capital being a good example of a lot of money But so we have to be fairly responsive in this And if we don't we've",
    "start": "132720",
    "end": "139200"
  },
  {
    "text": "failed But more typically this is the sort of app that most of us end up writing and",
    "start": "139200",
    "end": "145040"
  },
  {
    "text": "we have users who need to sort of use our systems that must be responsive I",
    "start": "145040",
    "end": "150239"
  },
  {
    "text": "call this the squidgy end of it but it's really important that we get this right We get too lazy about this and we end up with frustrated users I'm sure all of us",
    "start": "150239",
    "end": "157599"
  },
  {
    "text": "are aware that if we're frustrated using an application we don't want to use it so much more We don't want to explore it",
    "start": "157599",
    "end": "163040"
  },
  {
    "text": "So getting this right starts to become critical And actually as we get involved in this",
    "start": "163040",
    "end": "168400"
  },
  {
    "text": "subject I've often found that typically users of these sorts of systems when we we develop them and users are meaning",
    "start": "168400",
    "end": "175040"
  },
  {
    "text": "the developers who are sort of building these sorts of things are in this sort of situation They're building stuff and",
    "start": "175040",
    "end": "181599"
  },
  {
    "text": "they're very much unaware of what's going on We're happily working away and",
    "start": "181599",
    "end": "187040"
  },
  {
    "text": "we don't know what we're about to just dig into whenever we go live So I want to try and avoid us getting into this",
    "start": "187040",
    "end": "193200"
  },
  {
    "text": "situation by giving you some knowledge for what to be prepared for So we're going to cover a number of",
    "start": "193200",
    "end": "198360"
  },
  {
    "text": "subjects One of them is how do we test and measure i'm going to go into a little bit of theory about what goes on",
    "start": "198360",
    "end": "204319"
  },
  {
    "text": "in these sorts of systems a little bit of practice some some stuff I'm going to share from a client of mine that allow",
    "start": "204319",
    "end": "210159"
  },
  {
    "text": "me to share some of this some pitfalls that most people fall into And I'm going to finish off by talking about some",
    "start": "210159",
    "end": "216080"
  },
  {
    "text": "algorithms and techniques you can take away because I don't want you leaving this being all depressed and this is all hard There's stuff we can take away",
    "start": "216080",
    "end": "222640"
  },
  {
    "text": "There's stuff we can get better at So first of all let's talk about how do we test and measure This becomes critical",
    "start": "222640",
    "end": "228640"
  },
  {
    "text": "in some of our systems So let's start off and imagine I'm Darth Vader I've taken delivery of a new Death Star How",
    "start": "228640",
    "end": "235519"
  },
  {
    "text": "do I know how it's going to perform well I've got to test this at this stage And",
    "start": "235519",
    "end": "240560"
  },
  {
    "text": "so simply I'm going to load it up going to test it by some types of agents that",
    "start": "240560",
    "end": "246640"
  },
  {
    "text": "are going to run against it This could be a nice simple means But our world has changed radically We have automated",
    "start": "246640",
    "end": "253519"
  },
  {
    "text": "clients now It's not just users pushing buttons Sometimes some of our clients can throw a lot of load at systems In",
    "start": "253519",
    "end": "259919"
  },
  {
    "text": "finance world this happens a lot So testing with small numbers or even individual very large clients that can",
    "start": "259919",
    "end": "267199"
  },
  {
    "text": "throw a lot of load at our system starts becoming really important It's also important to test with a large number of",
    "start": "267199",
    "end": "274320"
  },
  {
    "text": "smaller users that are not doing so often but just it's another dimension So we find things like well I'm",
    "start": "274320",
    "end": "281040"
  },
  {
    "text": "concentrated on one point or actually just having large numbers bre algorithms in other ways So we we got to do that in",
    "start": "281040",
    "end": "286479"
  },
  {
    "text": "two different ways But really importantly is how we measure these systems We should not be measuring from",
    "start": "286479",
    "end": "293520"
  },
  {
    "text": "the load generation side Because if we're looking up here and if these guys",
    "start": "293520",
    "end": "298560"
  },
  {
    "text": "are generating the load plus you're also using those to measure you get the wrong",
    "start": "298560",
    "end": "304160"
  },
  {
    "text": "results Like what happens if they taking GC pauses what if they get swapped out they run out of their quantum in the",
    "start": "304160",
    "end": "309280"
  },
  {
    "text": "operating system They start skewing the results So we need a third party observer to observe this and it's",
    "start": "309280",
    "end": "316000"
  },
  {
    "text": "usually best by capturing network traffic Now this could be at the extreme of you buy some really expensive",
    "start": "316000",
    "end": "321440"
  },
  {
    "text": "hardware that hardware will capture everything and can time stamp all the packets and you can later on analyze it",
    "start": "321440",
    "end": "328320"
  },
  {
    "text": "You don't have to go to that extreme This could be as simple as using something like wireshark or TCP dump to",
    "start": "328320",
    "end": "333919"
  },
  {
    "text": "capture the packets You then analyze them later and you can see the true performance of your system from a",
    "start": "333919",
    "end": "340240"
  },
  {
    "text": "latency perspective because we're capturing on the wire We're not just relying on the load generation units to",
    "start": "340240",
    "end": "345919"
  },
  {
    "text": "do that So to start bearing that in mind we also got to set this up in continuous",
    "start": "345919",
    "end": "351520"
  },
  {
    "text": "integration If we're going to do performance testing we need to be doing it all the time Because if we're doing this all of the time we then find out",
    "start": "351520",
    "end": "358960"
  },
  {
    "text": "when things go wrong as soon as they go wrong Not later not six months later or a year later Whenever we try to work out",
    "start": "358960",
    "end": "365280"
  },
  {
    "text": "how we fix that it gets really complicated We learn much more by short feedback cycles just like we do with the",
    "start": "365280",
    "end": "370880"
  },
  {
    "text": "rest of agile we have to do this with performance And also let's record",
    "start": "370880",
    "end": "376759"
  },
  {
    "text": "everything If we just sample a system it hides all manner of ills And here's a",
    "start": "376759",
    "end": "382000"
  },
  {
    "text": "really good example of I'm going to capture everything on a system and store it in a histogram And so what is the",
    "start": "382000",
    "end": "387520"
  },
  {
    "text": "histogram at this stage well for any given time period I'm going to record the number of observations I've seen for",
    "start": "387520",
    "end": "394720"
  },
  {
    "text": "that given latency So this example here is a chart that is got a log scale along",
    "start": "394720",
    "end": "400880"
  },
  {
    "text": "the x-axis And so it's going greater out in time but the majority of our",
    "start": "400880",
    "end": "406319"
  },
  {
    "text": "observations are up here So typically this system is responding in less than",
    "start": "406319",
    "end": "411440"
  },
  {
    "text": "one millisecond which is great but it's also responding in a much slower fashion",
    "start": "411440",
    "end": "416639"
  },
  {
    "text": "further on So capturing and getting this sort of visual image is so powerful So",
    "start": "416639",
    "end": "421759"
  },
  {
    "text": "histograms are a great way to do this So they record the number of observations at any given point in time Now let's",
    "start": "421759",
    "end": "428240"
  },
  {
    "text": "look into how a statistician will look at this and we often use terms like what's the average response time what's",
    "start": "428240",
    "end": "434880"
  },
  {
    "text": "the standard deviation well this is how nonsense this can become So let's look at the mode The mode is the most common",
    "start": "434880",
    "end": "441520"
  },
  {
    "text": "occurrence that we find Our mode is there on the graph That's interesting That's typical It's actually it's the",
    "start": "441520",
    "end": "447280"
  },
  {
    "text": "one of the few measures that is kind of useful median So that's imagine we line",
    "start": "447280",
    "end": "452639"
  },
  {
    "text": "up all of our observations and we pick the middle point It's not actually telling me that interesting things here",
    "start": "452639",
    "end": "458800"
  },
  {
    "text": "This is a really silly one The mean the average the one we always talk about That is telling me really nothing about",
    "start": "458800",
    "end": "465919"
  },
  {
    "text": "what's going on It doesn't tell me the most typical case and it doesn't tell me about what's going on out here It's",
    "start": "465919",
    "end": "472319"
  },
  {
    "text": "actually in the middle of a wasteland telling me nothing useful at all So don't use means don't use averages when",
    "start": "472319",
    "end": "478879"
  },
  {
    "text": "you start describing your system and don't talk about standard deviation because look at that That is not a",
    "start": "478879",
    "end": "484479"
  },
  {
    "text": "normal distribution It's multimodal It's very skewed It's got",
    "start": "484479",
    "end": "489680"
  },
  {
    "text": "high krytosis It's from so many levels It is not something you want to use standard deviation to describe So",
    "start": "489680",
    "end": "495840"
  },
  {
    "text": "capture all this data and put it in histograms Now let's take a simple example from a system So let's say I",
    "start": "495840",
    "end": "503280"
  },
  {
    "text": "have a system I want to run it at a thousand transactions a second and the mean response time at that is 50",
    "start": "503280",
    "end": "510000"
  },
  {
    "text": "microsconds This would be a trading system You could easily just translate this into any other type of system and",
    "start": "510000",
    "end": "515760"
  },
  {
    "text": "scale the number So that could be five milliseconds It could be 50 milliseconds It's just a unit of time But typically",
    "start": "515760",
    "end": "523120"
  },
  {
    "text": "in finance we're looking at around this So we're looking at 50 micros in this case That all looks really good Well",
    "start": "523120",
    "end": "530800"
  },
  {
    "text": "what if we're generating quite a lot of garbage and we're seeing a young generational garbage collection",
    "start": "530800",
    "end": "536080"
  },
  {
    "text": "happening once every millisecond and the or every second and that takes a 25",
    "start": "536080",
    "end": "541839"
  },
  {
    "text": "millisecond pause Well if you think if you've been putting them in at one a millisecond we got an interesting effect",
    "start": "541839",
    "end": "547440"
  },
  {
    "text": "goes on here because you put something in and it's going to wait 25 milliseconds and but around that period",
    "start": "547440",
    "end": "553920"
  },
  {
    "text": "you're still injecting other load So something's taking 25 next one's taking 24 next one's taking 23 This continues",
    "start": "553920",
    "end": "560320"
  },
  {
    "text": "right down until you're back at the 50 microsconds level again So 12.5 on",
    "start": "560320",
    "end": "566000"
  },
  {
    "text": "average is what's happening during that pause You end up with an average mean",
    "start": "566000",
    "end": "572880"
  },
  {
    "text": "latency of 300 microsconds See it's kind of crazy You just mix in a GC pause and",
    "start": "572880",
    "end": "578080"
  },
  {
    "text": "all of a sudden your average makes no sense Now imagine you're offering this to a customer and you've got a service",
    "start": "578080",
    "end": "583600"
  },
  {
    "text": "level agreement on it and you're expecting 50 microsconds and you can't explain these 25s or whether you're a",
    "start": "583600",
    "end": "591120"
  },
  {
    "text": "were or were not You try to explain it to your boss you end up feeling a bit like this because it's not making any sense",
    "start": "591120",
    "end": "598320"
  },
  {
    "text": "You've been using averages and it's crazy So forget these averages start talking about",
    "start": "598320",
    "end": "604040"
  },
  {
    "text": "percentiles Gil Tenny has sent me this graph and it's kind of really interesting So rather than looking at",
    "start": "604040",
    "end": "610240"
  },
  {
    "text": "our distribution let's add things up as quantiles or percentiles So let's have a percentile distribution And so as we go",
    "start": "610240",
    "end": "617760"
  },
  {
    "text": "along the x-axis we're going up in nines 90% 99.9 And we can see what's happening to",
    "start": "617760",
    "end": "626000"
  },
  {
    "text": "our distribution over time There's an interesting effect in here So go back to my example about the GC if you were not",
    "start": "626000",
    "end": "633959"
  },
  {
    "text": "capturing those 24 additional requests because your system is generating load",
    "start": "633959",
    "end": "639200"
  },
  {
    "text": "as your system is measuring this maybe even blocked by what's going on is it suffers from a thing called coordinated",
    "start": "639200",
    "end": "644800"
  },
  {
    "text": "omission and what that means is the 24 samples that you should have had when that when that GC pause is going on",
    "start": "644800",
    "end": "651760"
  },
  {
    "text": "where you're running at one a millisecond they're lost that skews all your results so things look better than",
    "start": "651760",
    "end": "658959"
  },
  {
    "text": "what they are and the real giveaway in these sorts of things is you don't get nice smooth curves you get these jagged",
    "start": "658959",
    "end": "664079"
  },
  {
    "text": "jumps And if you start catching things like this you can see it by looking at the graphs but you got to be measuring",
    "start": "664079",
    "end": "669920"
  },
  {
    "text": "it to do it So I recommend you look at a thing called HDR histogram and start",
    "start": "669920",
    "end": "675680"
  },
  {
    "text": "capturing your data and put this in this So don't deceive yourself We got to",
    "start": "675680",
    "end": "680800"
  },
  {
    "text": "measure We got to know what's going on We got to be able to read this And if we start doing this we start behaving like",
    "start": "680800",
    "end": "686000"
  },
  {
    "text": "proper scientists and we won't deceive ourselves So let's get into a little bit of theory now to explain a little bit of",
    "start": "686000",
    "end": "693200"
  },
  {
    "text": "what's going on and why systems become unresponsive Who all seen the J curve",
    "start": "693200",
    "end": "698240"
  },
  {
    "text": "typically the response time of systems end up looking something like this where as we increase load and we use our",
    "start": "698240",
    "end": "704959"
  },
  {
    "text": "system more and more so we increase utilization response time starts to go up this curve This is very typical to",
    "start": "704959",
    "end": "711040"
  },
  {
    "text": "what's going on There's a lot of interesting characteristics but most systems follow this J curve where",
    "start": "711040",
    "end": "716720"
  },
  {
    "text": "response gets unresponsive over time Well let's look into this a little bit Why does that happen and how can I work",
    "start": "716720",
    "end": "723839"
  },
  {
    "text": "this out well what we're talking about if you start looking this up is a thing called Kendall notation is a good way of",
    "start": "723839",
    "end": "730240"
  },
  {
    "text": "describing this So you characterize the system for how things queue up at it using this notation And what the",
    "start": "730240",
    "end": "736880"
  },
  {
    "text": "notation here is showing you is three parts It's the arrival rate to the",
    "start": "736880",
    "end": "742000"
  },
  {
    "text": "system which is the M the service time itself for the behavior of that and then how many instances of your service So",
    "start": "742000",
    "end": "749040"
  },
  {
    "text": "MD1 means it's a mar covian arrival rate The service itself behaves in a",
    "start": "749040",
    "end": "754160"
  },
  {
    "text": "deterministic way and we have one instance of that service If you describe your systems in these sorts of fashions",
    "start": "754160",
    "end": "760320"
  },
  {
    "text": "you can then pick the equation you need to work out what it's going to do under",
    "start": "760320",
    "end": "765440"
  },
  {
    "text": "load as you increase utilization Arrival rates can be different that could be completely uniform that could be",
    "start": "765440",
    "end": "771200"
  },
  {
    "text": "marovian that could be Erlang there could be very many other different options in this but it's a very interesting thing to look into A lot of",
    "start": "771200",
    "end": "778079"
  },
  {
    "text": "what I'm going to show you in the talk is that it kind of will inspire hopefully some wiki walks and a bit of googling to find out what some of these",
    "start": "778079",
    "end": "783519"
  },
  {
    "text": "things are I don't want to spend a lot of time on exactly what these things are but for an MD1 I get this formula So for",
    "start": "783519",
    "end": "791600"
  },
  {
    "text": "this formula I can work out what my mean response time is going to be plug it into this formula for the service time",
    "start": "791600",
    "end": "797839"
  },
  {
    "text": "and the utilization and I can then plot that graph The really interesting thing",
    "start": "797839",
    "end": "803120"
  },
  {
    "text": "is what is utilization well utilization is a function of service time again So the",
    "start": "803120",
    "end": "810560"
  },
  {
    "text": "how fast our service runs becomes really really critical to how responsive it is",
    "start": "810560",
    "end": "816079"
  },
  {
    "text": "That may seem kind of obvious but it's much worse than you actually think So if we go back to this graph let's say I'm",
    "start": "816079",
    "end": "823360"
  },
  {
    "text": "running here at the 90% utilization point So normally when my system's not loaded it's responding at about one unit",
    "start": "823360",
    "end": "830240"
  },
  {
    "text": "of time When I'm running at 90% utilization it's running in more than 10 units of time whatever that unit happens",
    "start": "830240",
    "end": "836240"
  },
  {
    "text": "to be Now if I take my service and I profile it and I work out how to make it",
    "start": "836240",
    "end": "842079"
  },
  {
    "text": "faster and I take it down from whatever it was to being 50% of what it was",
    "start": "842079",
    "end": "847519"
  },
  {
    "text": "before your system doesn't have an average response time of 50% better",
    "start": "847519",
    "end": "852720"
  },
  {
    "text": "because that response time goes into utilization What actually happens is you come right down this curve to about here",
    "start": "852720",
    "end": "860160"
  },
  {
    "text": "and your system now is 10 times more responsive So understanding the mathematics behind",
    "start": "860160",
    "end": "866399"
  },
  {
    "text": "this is so powerful and it gives you great results in your system So relatively small changes can have a",
    "start": "866399",
    "end": "871920"
  },
  {
    "text": "massive impact and this applies to anything you do Anything that's a service we are a service to the projects",
    "start": "871920",
    "end": "879040"
  },
  {
    "text": "we work on If we're used at greater than 70% utilization we become unresponsive",
    "start": "879040",
    "end": "886079"
  },
  {
    "text": "So there's any project managers in the room Please pay heed Don't try to use people at 100% utilization or even more",
    "start": "886079",
    "end": "893600"
  },
  {
    "text": "because they will not be responsive We have to have slack in our systems this to",
    "start": "893600",
    "end": "899240"
  },
  {
    "text": "work So we've got to make sure we've got sufficient capacity This is a key part",
    "start": "899240",
    "end": "904639"
  },
  {
    "text": "in how we work Now the original queueing theory is 100 years old But about 50",
    "start": "904639",
    "end": "911839"
  },
  {
    "text": "years ago John Little made an interesting observation on this in that for any system that's in steady state",
    "start": "911839",
    "end": "918320"
  },
  {
    "text": "and that's where the number of arrivals is equal to the number that are leaving the system in that nice steady state as",
    "start": "918320",
    "end": "924480"
  },
  {
    "text": "it's flowing through These properties hold true regardless of the service time",
    "start": "924480",
    "end": "930639"
  },
  {
    "text": "regardless of the arrival rates And so we can easily work out one of these if",
    "start": "930639",
    "end": "936639"
  },
  {
    "text": "we know the other two This is a very useful property of the system So looking into the work of John Little and",
    "start": "936639",
    "end": "942639"
  },
  {
    "text": "Little's law gives us a good way forward And the way I like to use this is if I",
    "start": "942639",
    "end": "948000"
  },
  {
    "text": "bound my cues I can limit the service time So if I want to have a response",
    "start": "948000",
    "end": "954160"
  },
  {
    "text": "time that I'm going to always honor if I bound my queue I can then make sure I",
    "start": "954160",
    "end": "959839"
  },
  {
    "text": "don't exceed that response time My system can stay responsive Well people go \"Well what if you're getting more",
    "start": "959839",
    "end": "965600"
  },
  {
    "text": "load than you've got at that point?\" Well you reject input It is really that simple You do not want to keep taking",
    "start": "965600",
    "end": "973120"
  },
  {
    "text": "input And as you keep taking input your system keeps growing and growing and growing in its cues and eventually run",
    "start": "973120",
    "end": "979519"
  },
  {
    "text": "out of memory and you crash Which one's better say \"Sorry we're busy Please come",
    "start": "979519",
    "end": "985120"
  },
  {
    "text": "back again later and give a really good service to everybody who's already arrived or let in more load Let the cues",
    "start": "985120",
    "end": "991920"
  },
  {
    "text": "all build up Have the system crash People who are in don't get a good service Nobody can get a good service",
    "start": "991920",
    "end": "997360"
  },
  {
    "text": "afterwards because your system's down That's a much more professional approach It feels we should be thinking in these",
    "start": "997360",
    "end": "1003759"
  },
  {
    "text": "ways So if you've got unbounded cues in your system you have a real problem So what's one of the other things we can",
    "start": "1003759",
    "end": "1010240"
  },
  {
    "text": "use to speed up well we can go parallel And the common way people look at going",
    "start": "1010240",
    "end": "1015440"
  },
  {
    "text": "parallel is Amdal's law What's really interesting about Amdall's law is people",
    "start": "1015440",
    "end": "1020639"
  },
  {
    "text": "think Amdal's law is all about encouraging parallelism If you read Amdal's original paper you'll very",
    "start": "1020639",
    "end": "1026160"
  },
  {
    "text": "quickly realize he was not encouraging parallelism He was trying to discourage it He was showing how difficult it",
    "start": "1026160",
    "end": "1032558"
  },
  {
    "text": "actually is He wanted to pedal mainframes He wanted to sell you one of his big main frames and not buy one of",
    "start": "1032559",
    "end": "1038240"
  },
  {
    "text": "these new mid-range systems that had many processors in them because he was pointing out that it's actually very",
    "start": "1038240",
    "end": "1043839"
  },
  {
    "text": "hard to do parallel programming And so what his argument is about is if I've",
    "start": "1043839",
    "end": "1048960"
  },
  {
    "text": "got any task I can split it up in some ways Now which bits of it can I split up to run in parallel so in this case if I",
    "start": "1048960",
    "end": "1056799"
  },
  {
    "text": "can split up A I can get a nice speed up if I applied over four",
    "start": "1056799",
    "end": "1062039"
  },
  {
    "text": "cores But if B is the only thing I can split I don't get the same speed up So",
    "start": "1062039",
    "end": "1067360"
  },
  {
    "text": "it becomes critical how much of your algorithm you can actually make run in parallel to make this work",
    "start": "1067360",
    "end": "1073480"
  },
  {
    "text": "better And so we start graphing this and we look at what speed ups possible Look",
    "start": "1073480",
    "end": "1079280"
  },
  {
    "text": "at you start going up these cases So even if I just have 5% of my algorithm",
    "start": "1079280",
    "end": "1084480"
  },
  {
    "text": "that's the sequential component I can never get greater than a 20x speed up In",
    "start": "1084480",
    "end": "1089520"
  },
  {
    "text": "fact I'll never even get to 20x speed up because I can topically approach it but I never get there This makes a really",
    "start": "1089520",
    "end": "1096080"
  },
  {
    "text": "interesting challenge Like if your algorithm is 50% parallel you're only ever looking at 2x speed up no matter",
    "start": "1096080",
    "end": "1103520"
  },
  {
    "text": "how many cores we throw at this So it becomes really critical to work out what is the sequential component of your",
    "start": "1103520",
    "end": "1109600"
  },
  {
    "text": "algorithm And many people don't even know But you know what amdall had the",
    "start": "1109600",
    "end": "1114640"
  },
  {
    "text": "hoppycloppy view of the world It's actually much worse than that Neil Gunther discovered from real worlds",
    "start": "1114640",
    "end": "1121120"
  },
  {
    "text": "measurement that actually you could not even achieve Al's law from a speed up perspective What he discovered is that",
    "start": "1121120",
    "end": "1128960"
  },
  {
    "text": "contention point is really important but Al hadn't talked about the coherence side of things So you have to plug in",
    "start": "1128960",
    "end": "1135440"
  },
  {
    "text": "the contention and the coherence values into your equations to work out what is your possible speedups Now if I apply uh",
    "start": "1135440",
    "end": "1143600"
  },
  {
    "text": "the contention and coherence what I end up with is with this graph So if I",
    "start": "1143600",
    "end": "1148720"
  },
  {
    "text": "assume it takes 250 microsconds to make any state I have as part of my",
    "start": "1148720",
    "end": "1153760"
  },
  {
    "text": "contention coherent among those threads or processes after a while you start to",
    "start": "1153760",
    "end": "1158799"
  },
  {
    "text": "find out that the coherence cost starts to dominate And if we look at this graph it's kind of looks kind of nice at the",
    "start": "1158799",
    "end": "1165440"
  },
  {
    "text": "two and four and eight processors but look what starts to happen beyond 16 processors 32 processors We start to",
    "start": "1165440",
    "end": "1171840"
  },
  {
    "text": "diverge and then it actually starts to get worse And we're now in a world whereby we're getting more and more",
    "start": "1171840",
    "end": "1178080"
  },
  {
    "text": "cores and the light has been shown on algorithms to the point that these things are starting to appear and we",
    "start": "1178080",
    "end": "1183919"
  },
  {
    "text": "have to be aware of that So going in parallel is not necessarily an easy thing We have to be aware of what we can",
    "start": "1183919",
    "end": "1191039"
  },
  {
    "text": "do what we can't do and what are our limitations in how this works So let's come back again to that",
    "start": "1191039",
    "end": "1198080"
  },
  {
    "text": "So we looked at we can queue on things we can make things go in parallel but it's all about the service time itself",
    "start": "1198080",
    "end": "1204000"
  },
  {
    "text": "because if the service time itself is not deterministic it gets really really tricky And this is purely about",
    "start": "1204000",
    "end": "1210880"
  },
  {
    "text": "algorithms at this stage We have to go back to basic algorithm theory We cannot wait a year and get a faster CPU We",
    "start": "1210880",
    "end": "1218240"
  },
  {
    "text": "can't even wait 10 years to get a significantly faster CPU anymore We will get more CPUs We will get a marginal",
    "start": "1218240",
    "end": "1224080"
  },
  {
    "text": "speed up But we cannot just do that We have to go back and learn about algorithms like we did in the past and",
    "start": "1224080",
    "end": "1230480"
  },
  {
    "text": "start taking these seriously again So you've got to know the order of your algorithms big O notation back to",
    "start": "1230480",
    "end": "1236240"
  },
  {
    "text": "university stuff again and start applying this And if you've got algorithms that are n squared or n cubed",
    "start": "1236240",
    "end": "1242080"
  },
  {
    "text": "or whatever interesting on input you're going to get catastrophic behavior as we start to scale up We need to stop doing",
    "start": "1242080",
    "end": "1248640"
  },
  {
    "text": "that And that can be as simple as I go to the database I read out some data and then within a loop as I mediterating",
    "start": "1248640",
    "end": "1254720"
  },
  {
    "text": "over that I go back to the database again You just get an N squ algorithm People need to start thinking like this",
    "start": "1254720",
    "end": "1260559"
  },
  {
    "text": "and realize what's going on Otherwise we're not responsive So that's the theory over",
    "start": "1260559",
    "end": "1266000"
  },
  {
    "text": "with for a bit Let's look at a bit of practice and see what can actually happen So one of my clients has kindly",
    "start": "1266000",
    "end": "1271919"
  },
  {
    "text": "let me share some data where I came in for a consulting engagement over a week",
    "start": "1271919",
    "end": "1277679"
  },
  {
    "text": "and the goal was to make their trading system more predictable from a latency perspective but also lower the latency",
    "start": "1277679",
    "end": "1284159"
  },
  {
    "text": "if we can The main goal was actually to increase predictability and latency and how it happened There's what was really",
    "start": "1284159",
    "end": "1291919"
  },
  {
    "text": "interesting is is these were really really good folk and they were very good at what they' done and most of the",
    "start": "1291919",
    "end": "1297600"
  },
  {
    "text": "obvious mistakes that people make they had already corrected You're working here at the level of microsconds tens of",
    "start": "1297600",
    "end": "1304880"
  },
  {
    "text": "microsconds for response time I know not everyone works at that but this is where these guys were What I found really",
    "start": "1304880",
    "end": "1310640"
  },
  {
    "text": "interesting in coming back into this is you when you start dealing with really really good people it's not that you",
    "start": "1310640",
    "end": "1316720"
  },
  {
    "text": "have to be better than them You can come in and help people by coaching And I find that our industry really suffers",
    "start": "1316720",
    "end": "1322080"
  },
  {
    "text": "from the fact that we don't apply coaching so often I used to come from a sports background and I had coaches who",
    "start": "1322080",
    "end": "1329600"
  },
  {
    "text": "I was faster than them I could do all sorts of interesting because I was younger and able to but they could still coach We can do that in our industry as",
    "start": "1329600",
    "end": "1336640"
  },
  {
    "text": "well and we just don't do it enough So I I really enjoyed this engagement because I was able to get these guys to be",
    "start": "1336640",
    "end": "1342120"
  },
  {
    "text": "better just by coaching and following them through stuff So what did we discover well we measured their system",
    "start": "1342120",
    "end": "1349200"
  },
  {
    "text": "on the first data and this was a scatter plot of the response time of their system for a whole given set of inputs",
    "start": "1349200",
    "end": "1357440"
  },
  {
    "text": "And this is where you start seeing again averages mean absolutely nothing There's lots of really interesting things going",
    "start": "1357440",
    "end": "1362880"
  },
  {
    "text": "on here There's a warm-up period over here There's all of these interesting spikes and there's a lot of activity",
    "start": "1362880",
    "end": "1370480"
  },
  {
    "text": "around So it's it's kind of fascinating to what's going on So you do this you start profiling you profile in a number",
    "start": "1370480",
    "end": "1377120"
  },
  {
    "text": "of different ways you start realizing where your costs are And one of the first things we discovered in this is",
    "start": "1377120",
    "end": "1383280"
  },
  {
    "text": "there was a contention problem with multiple producers into the system causing thread contention As I worked",
    "start": "1383280",
    "end": "1389440"
  },
  {
    "text": "through the codebase I discovered they're using the disruptor They're using an older version of the disruptor that had a particular problem with",
    "start": "1389440",
    "end": "1396159"
  },
  {
    "text": "multiple producers I know that version three onwards had that corrected and",
    "start": "1396159",
    "end": "1401200"
  },
  {
    "text": "improved So we upgraded to that That's what happened So software upgrade Boom",
    "start": "1401200",
    "end": "1408320"
  },
  {
    "text": "We've actually got a bit better and we've got a bit faster So that's one change But again notice like we measure",
    "start": "1408320",
    "end": "1415760"
  },
  {
    "text": "we apply science we create an experiment to test something out Then we go ahead and make a change and we measure it",
    "start": "1415760",
    "end": "1421919"
  },
  {
    "text": "again And so we've got faster but we still got some interesting artifacts",
    "start": "1421919",
    "end": "1427760"
  },
  {
    "text": "Once we've taken out that other thing there's some very interesting artifacts like what is going on here i find that",
    "start": "1427760",
    "end": "1433440"
  },
  {
    "text": "sort of stuff fascinating So be curious dig into it You learn so much Well if I",
    "start": "1433440",
    "end": "1438480"
  },
  {
    "text": "zoom into that this is what it looks like in some detail So it's clearly this",
    "start": "1438480",
    "end": "1444640"
  },
  {
    "text": "is a normal sort of case Some things are taking longer Then all of a sudden I get a gap jump up another gap and a jump",
    "start": "1444640",
    "end": "1452120"
  },
  {
    "text": "down So what can be causing that you start asking the questions again Let's go back to apply science I have a theory",
    "start": "1452120",
    "end": "1459840"
  },
  {
    "text": "How do I test something to see if that theory is correct so I design an experiment for that I then measure and I",
    "start": "1459840",
    "end": "1466640"
  },
  {
    "text": "check the results So one of the things I had a theory about was that this was a data structure resize issue and",
    "start": "1466640",
    "end": "1473679"
  },
  {
    "text": "potentially a garbage collection problem Now the garbage collection problem is easy because you output the GC logs and",
    "start": "1473679",
    "end": "1480320"
  },
  {
    "text": "you correlate the GC logs with the time of these events And guess what there was a GC event here and a GC event here So",
    "start": "1480320",
    "end": "1488240"
  },
  {
    "text": "okay that told me something that was a cause of a number of things but it didn't tell me what went on up here Now",
    "start": "1488240",
    "end": "1494640"
  },
  {
    "text": "I've seen a lot of these sorts of graphs This is another thing is humans are great at pattern matching So visualizing this stuff is so important Collect your",
    "start": "1494640",
    "end": "1501200"
  },
  {
    "text": "data put it in graphs put it in histograms scatter plots sort of percentile burnups all this sort of",
    "start": "1501200",
    "end": "1506480"
  },
  {
    "text": "stuff is really useful because you start spotting patterns and you start realizing what this is So this screams out to me data structure resizing So how",
    "start": "1506480",
    "end": "1514400"
  },
  {
    "text": "do I test that i wrote an aspect I use aspectoriented programming to go and",
    "start": "1514400",
    "end": "1520400"
  },
  {
    "text": "intercept anytime some of my structures had a resize method And if that resize method was called I logged it and I",
    "start": "1520400",
    "end": "1527120"
  },
  {
    "text": "logged where it was happening in the code And guess what these were hashmap resizes",
    "start": "1527120",
    "end": "1533440"
  },
  {
    "text": "And interesting the hashmap resize was actually the cause of the GC because as you resize a hashmap it creates it",
    "start": "1533440",
    "end": "1540960"
  },
  {
    "text": "copies all of its internal structures and allocates them in a bigger space So it's resizing upwards and that was",
    "start": "1540960",
    "end": "1547120"
  },
  {
    "text": "interesting because then whenever it finish copying all of this it lets it all go and end up with another GC event",
    "start": "1547120",
    "end": "1552880"
  },
  {
    "text": "later on And so that's just doing some analysis digging in finding out you understand so much about your system",
    "start": "1552880",
    "end": "1559279"
  },
  {
    "text": "It's really quite good fun So we did that and that's what our graph looked",
    "start": "1559279",
    "end": "1565200"
  },
  {
    "text": "like afterwards So we don't have those stepups anymore We don't have some of those weird effects but yet there's",
    "start": "1565200",
    "end": "1570320"
  },
  {
    "text": "still lots of interesting things going on Why have we got these big like hills",
    "start": "1570320",
    "end": "1576480"
  },
  {
    "text": "and spikes in the in the curve so we try to work out what some of that was What's",
    "start": "1576480",
    "end": "1581840"
  },
  {
    "text": "the cause use uh performance counters to find out what the CPUs are doing and",
    "start": "1581840",
    "end": "1587279"
  },
  {
    "text": "find out there's lots of bursts of cash missing But they were almost metronomic",
    "start": "1587279",
    "end": "1593039"
  },
  {
    "text": "We dig into it again Oh it looks suspiciously like the time whenever you get loose time slices quantums who give",
    "start": "1593039",
    "end": "1599840"
  },
  {
    "text": "up on the CPU So we track the counters for that It was definitely all the cash",
    "start": "1599840",
    "end": "1605200"
  },
  {
    "text": "misses according to that How can we stop that from happening well if you're constantly just moving around threads",
    "start": "1605200",
    "end": "1611360"
  },
  {
    "text": "whenever things happen you will get those cash misses because your cash isn't warm So we wrote a script that",
    "start": "1611360",
    "end": "1617360"
  },
  {
    "text": "after the application has been running for a little while Also we let it actually run for a while and then we pin",
    "start": "1617360",
    "end": "1623279"
  },
  {
    "text": "threads to cores so they're not allowed to move around That's what",
    "start": "1623279",
    "end": "1628760"
  },
  {
    "text": "happened See we get into the Oops We get into the run a little bit then we apply",
    "start": "1628760",
    "end": "1635279"
  },
  {
    "text": "the script Now it's much more stable All those migrations all this stuff up here has",
    "start": "1635279",
    "end": "1643600"
  },
  {
    "text": "gone away It's gone down again And you start seeing like oh there's interesting cash effects and what's going on and",
    "start": "1643600",
    "end": "1650000"
  },
  {
    "text": "this is just fun analysis What's all this other stuff well that didn't take too long to dig",
    "start": "1650000",
    "end": "1655200"
  },
  {
    "text": "into That was GC Young generation GC So if we cleaned up the GC this almost becomes a straight",
    "start": "1655200",
    "end": "1662320"
  },
  {
    "text": "line And then you've got a nice soft realtime system So that's just like over a week doing a lot of analysis finding",
    "start": "1662320",
    "end": "1668640"
  },
  {
    "text": "out what's going on and we can greatly improve the system At the end of this it's a lot faster than it was but it's a",
    "start": "1668640",
    "end": "1674080"
  },
  {
    "text": "lot more predictable in its response time So that's part",
    "start": "1674080",
    "end": "1680398"
  },
  {
    "text": "two Let's talk about pitfalls What can go wrong along the west you're digging along and you don't want to end up into",
    "start": "1680440",
    "end": "1686240"
  },
  {
    "text": "that big pile of the brown stuff Start at the bottom Our modern",
    "start": "1686240",
    "end": "1691279"
  },
  {
    "text": "CPUs are doing lots of really interesting things but the most important thing that they're driving towards is energy usage They want to",
    "start": "1691279",
    "end": "1698399"
  },
  {
    "text": "reduce energy usage as much as possible So as they're running they will come",
    "start": "1698399",
    "end": "1703679"
  },
  {
    "text": "down into lower PAR states They will speed up speed down all sorts of interesting things And these have a big",
    "start": "1703679",
    "end": "1710000"
  },
  {
    "text": "impact on the responsiveness of your system You can end up turning some of",
    "start": "1710000",
    "end": "1715440"
  },
  {
    "text": "these states on turning some of them off But you got to be aware that this is becoming more and more of a feature So",
    "start": "1715440",
    "end": "1721039"
  },
  {
    "text": "if you're using lots of CPUs very intensely you can guarantee that the frequency overall of your socket is",
    "start": "1721039",
    "end": "1727679"
  },
  {
    "text": "going to go down If most of your CPUs are quiet and one or two are running fast it will rebalance and actually",
    "start": "1727679",
    "end": "1733600"
  },
  {
    "text": "allow you much higher clock frequencies and what's going on You can control some of this stuff at a lower level So things",
    "start": "1733600",
    "end": "1739760"
  },
  {
    "text": "like turbo boost P states C states these are all very interesting things that control what's going on We've also got",
    "start": "1739760",
    "end": "1746080"
  },
  {
    "text": "things like hyperthreading where within the same core we can have multiple threads going through the same core and",
    "start": "1746080",
    "end": "1752240"
  },
  {
    "text": "in some cases that's faster in some cases it's slower You have to measure to work out what's the right thing for your",
    "start": "1752240",
    "end": "1758600"
  },
  {
    "text": "application But even more interesting is things like SMI So system management",
    "start": "1758600",
    "end": "1763760"
  },
  {
    "text": "inter interrupts So your stuff that you can't do anything about at an operating system level where your CPU will stop",
    "start": "1763760",
    "end": "1770480"
  },
  {
    "text": "occasionally and take its temperature check for faults do all sorts of interesting things to see what state",
    "start": "1770480",
    "end": "1775760"
  },
  {
    "text": "it's in I see looking at some of the latest CPUs this is getting even more scary because they're doing things like",
    "start": "1775760",
    "end": "1781520"
  },
  {
    "text": "maybe checking things and sending data to the NSA Looking for AMT and you'll get",
    "start": "1781520",
    "end": "1787360"
  },
  {
    "text": "scared This sort of stuff is happening But so lots of stuff is happening at this sort of level As we go up a level",
    "start": "1787360",
    "end": "1793760"
  },
  {
    "text": "to the bigger box on the whole we'll see that our CPUs and our systems have",
    "start": "1793760",
    "end": "1799200"
  },
  {
    "text": "become very complex They're in fact networks now where we've got multiple cores inside our machines with layers of",
    "start": "1799200",
    "end": "1805960"
  },
  {
    "text": "caches shared caches but they're on separate sockets with memory connected",
    "start": "1805960",
    "end": "1811120"
  },
  {
    "text": "directly to them So if I have a core up here and it's talking to memory down here it's a different cost than talking",
    "start": "1811120",
    "end": "1817279"
  },
  {
    "text": "to memory over here because you have to cross a network on your motherboard between sockets and that adds additional",
    "start": "1817279",
    "end": "1824320"
  },
  {
    "text": "cost We're now in the world of non-uniform memory access So knowing how you access memory becomes really",
    "start": "1824320",
    "end": "1829960"
  },
  {
    "text": "important But one thing to take away from all of this is like close to the CPU things are very fast The further",
    "start": "1829960",
    "end": "1836720"
  },
  {
    "text": "away they are they start getting significantly slower But there's three bets are being taken One is the temporal",
    "start": "1836720",
    "end": "1842640"
  },
  {
    "text": "bet So if you've used something recently it's likely to be in cash for you using it again soon The second bet is a",
    "start": "1842640",
    "end": "1849360"
  },
  {
    "text": "spatial bet So things that are close together will be used together So your CPUs are doing lots of things for that",
    "start": "1849360",
    "end": "1855360"
  },
  {
    "text": "And the third bet is a pattern based bet So if you use things in a predictable",
    "start": "1855360",
    "end": "1860960"
  },
  {
    "text": "pattern hardware will prefetch your memory for you If you don't do one of those three things you're going to be",
    "start": "1860960",
    "end": "1867760"
  },
  {
    "text": "getting a lot of cache misses and very unresponsive memory How extreme this is",
    "start": "1867760",
    "end": "1873520"
  },
  {
    "text": "it's actually faster to stream data sequentially off an SSD than it is to randomly access",
    "start": "1873520",
    "end": "1880279"
  },
  {
    "text": "memory Now it's called random access memory It's a complete misnome It does not give you random characteristics It",
    "start": "1880279",
    "end": "1887600"
  },
  {
    "text": "behaves quite like tape The more you work with different memory subsystems you start to realize that it does not",
    "start": "1887600",
    "end": "1893520"
  },
  {
    "text": "matter what type of memory subsystem be it main memory be it storage be it whatever And that could be spinning",
    "start": "1893520",
    "end": "1899039"
  },
  {
    "text": "discs it could be SSDs could be anything If you deal with them in a sequential fashion they're very fast You deal with",
    "start": "1899039",
    "end": "1905120"
  },
  {
    "text": "them in a random fashion or you try to have arbitrary access they get a lot slower Everything is tape And you got to",
    "start": "1905120",
    "end": "1911600"
  },
  {
    "text": "start thinking that way So we come up from the hardware into the operating system",
    "start": "1911600",
    "end": "1917919"
  },
  {
    "text": "So many teams programmers do not talk to systems people and vice versa and things are so misconfigured We need to work",
    "start": "1917919",
    "end": "1925519"
  },
  {
    "text": "better together because there's a number of things at the operating system level need to be configured and set up or have",
    "start": "1925519",
    "end": "1931279"
  },
  {
    "text": "a massive impact on performance The virtual memory systems one thing how we set up buffers for networking how we set",
    "start": "1931279",
    "end": "1938080"
  },
  {
    "text": "up buffers for dealing with storage If these are misconfigured it's like three fourx difference in performance",
    "start": "1938080",
    "end": "1944720"
  },
  {
    "text": "sometimes 10x difference in performance in how this stuff's set up And most people don't even do any work in this",
    "start": "1944720",
    "end": "1950000"
  },
  {
    "text": "area So we could be spending weeks optimizing our code but all we needed is",
    "start": "1950000",
    "end": "1955440"
  },
  {
    "text": "a kernel parameter change and we could have had a three or 4x speed up We will not get that unless we start working",
    "start": "1955440",
    "end": "1961200"
  },
  {
    "text": "together So we have to start doing that with our teams and going forward We get up into our VMs and there's lots of",
    "start": "1961200",
    "end": "1968159"
  },
  {
    "text": "things going on One of the most horrible things in our VMs are these things called safe points Now many people",
    "start": "1968159",
    "end": "1975200"
  },
  {
    "text": "probably won't be aware of what a safe point is but there are operations whereby within our JVMs and this happens",
    "start": "1975200",
    "end": "1981840"
  },
  {
    "text": "across other virtual machines as well is that under certain conditions the world",
    "start": "1981840",
    "end": "1987440"
  },
  {
    "text": "must be stopped to perform that action So that action may be garbage collection It may be sort of inflating a lock from",
    "start": "1987440",
    "end": "1994480"
  },
  {
    "text": "bias lock into a full lock and all sorts of interesting things Whenever these things happen all threads have to be",
    "start": "1994480",
    "end": "2000559"
  },
  {
    "text": "brought to safe point and then that action goes forward That starts to really impede progress inside our VMs",
    "start": "2000559",
    "end": "2008240"
  },
  {
    "text": "And going back to Amdal's law that starts becoming the sequential component in our algorithms I see systems whereby",
    "start": "2008240",
    "end": "2015279"
  },
  {
    "text": "you throw lots of cores and you think your code is even completely parallel and having no contention but because it",
    "start": "2015279",
    "end": "2022000"
  },
  {
    "text": "contains on things within the VM like having a lot of having a lot of allocation or having a lot of locks it",
    "start": "2022000",
    "end": "2030159"
  },
  {
    "text": "just chokes to the point that you don't get utilization up on the box We have to be aware of this and how we move",
    "start": "2030159",
    "end": "2036360"
  },
  {
    "text": "forward Virtualization is another good one Whenever we go to the virtualized",
    "start": "2036360",
    "end": "2041760"
  },
  {
    "text": "world when we make a system call we call into a guest operating system It then has to call into the host operating",
    "start": "2041760",
    "end": "2048158"
  },
  {
    "text": "system And depending on how that's set up this can be a massive cost in what's going on This is one of the ones where I",
    "start": "2048159",
    "end": "2054800"
  },
  {
    "text": "have seen a 10x difference between reading data off a network that's well configured in a virtual environment",
    "start": "2054800",
    "end": "2061679"
  },
  {
    "text": "through uh compared to working in a native environment Then that can be as simple as seeing sort of a few thousand",
    "start": "2061679",
    "end": "2068240"
  },
  {
    "text": "messages a second come in to jumping to 70,000 messages a second Getting this stuff configured and getting it right",
    "start": "2068240",
    "end": "2074560"
  },
  {
    "text": "really matters People say you throw virtualization at the problem it only adds a few percentage points That is not",
    "start": "2074560",
    "end": "2080240"
  },
  {
    "text": "true in many cases When you start going out of your virtual machine to go to disk or go to network or do things like",
    "start": "2080240",
    "end": "2087520"
  },
  {
    "text": "get a lock it makes a massive difference because you're calling out through multiple layers and there's a large tax",
    "start": "2087520",
    "end": "2093280"
  },
  {
    "text": "for that Many of us have to write code and we're sharing between threads And so whenever",
    "start": "2093280",
    "end": "2100320"
  },
  {
    "text": "we've done work on one thread we need to hand it off to another thread How we typically do that is with a lock And",
    "start": "2100320",
    "end": "2106079"
  },
  {
    "text": "then within the lock we use a condition variable So in Java that could be wait notify It could be signal await with a",
    "start": "2106079",
    "end": "2112880"
  },
  {
    "text": "condition variable If you're using Java util concurrent five These sort of things happen across all languages What",
    "start": "2112880",
    "end": "2119680"
  },
  {
    "text": "you're basically doing is getting the operating system involved in notifying from one thread to another This is a",
    "start": "2119680",
    "end": "2125839"
  },
  {
    "text": "very expensive operation typically for what's going on And once you do this quite often your thread will be",
    "start": "2125839",
    "end": "2132000"
  },
  {
    "text": "suspended and it will not run for quite a large time in the future This is a nightmare in trading applications if",
    "start": "2132000",
    "end": "2139119"
  },
  {
    "text": "you're in games or audio is really noticeable but it's starting to become a problem just even in normal applications",
    "start": "2139119",
    "end": "2145760"
  },
  {
    "text": "because again it comes down to that sequential component It chokes algorithms It ties threads together and",
    "start": "2145760",
    "end": "2151839"
  },
  {
    "text": "you don't get the throughput You won't scale up with multiple cores You basically end up playing roulette with",
    "start": "2151839",
    "end": "2157680"
  },
  {
    "text": "your latency and your throughput when you start doing these sorts of things We got to unentangle these",
    "start": "2157680",
    "end": "2163800"
  },
  {
    "text": "things So Joe Spoly has this law of abstraction It's really interesting the",
    "start": "2163800",
    "end": "2169839"
  },
  {
    "text": "leaky abstraction problem and this has become a serious problem is we keep layering these things and we call them",
    "start": "2169839",
    "end": "2176119"
  },
  {
    "text": "abstractions they are not abstractions they're layers of crap in many cases if we go back to what Dystra said about",
    "start": "2176119",
    "end": "2183280"
  },
  {
    "text": "abstraction and abstraction has to be introduced to make something more precise note the word precise whenever",
    "start": "2183280",
    "end": "2190720"
  },
  {
    "text": "you put a layer of abstraction on and make something more vague that is not a good abstraction it's back to my point",
    "start": "2190720",
    "end": "2196800"
  },
  {
    "text": "again it is a layer of crap And yet we keep doing this and we keep talking about we're adding abstractions All",
    "start": "2196800",
    "end": "2204160"
  },
  {
    "text": "we're doing is making things vague unclear and giving ourselves bad performance and bugs in many cases I I I",
    "start": "2204160",
    "end": "2211599"
  },
  {
    "text": "got this thing where I hate frameworks And I think libraries is the way we should go Frameworks impose ways of",
    "start": "2211599",
    "end": "2217760"
  },
  {
    "text": "working that we've got to stop doing So uh Dave Thomas has this expression that frameworks are the ways of injecting",
    "start": "2217760",
    "end": "2224160"
  },
  {
    "text": "your dependencies into other people's code It shouldn't be like that What we should be doing is writing nice",
    "start": "2224160",
    "end": "2230079"
  },
  {
    "text": "libraries that pay for themselves So when you include the library it makes your life better and you include it",
    "start": "2230079",
    "end": "2235920"
  },
  {
    "text": "because you want to but you shouldn't be forced to do that And our abstractions is one way of looking at that because",
    "start": "2235920",
    "end": "2242480"
  },
  {
    "text": "many of these things are non-trivial and they have to deal with the complexity in the right way I like to think of this as",
    "start": "2242480",
    "end": "2249520"
  },
  {
    "text": "mechanical sympathy We have to understand what's going on below but just in sufficient detail so we can get",
    "start": "2249520",
    "end": "2255920"
  },
  {
    "text": "the best out of it don't have to become experts in it but we got to have a reasonable idea so we're using it in the",
    "start": "2255920",
    "end": "2261359"
  },
  {
    "text": "right way And don't hide behind the excuse of we have an abstraction layer It hides that It should be making it",
    "start": "2261359",
    "end": "2267280"
  },
  {
    "text": "more precise and easier to use If it's not doing that it's doing it wrongly Interestingly if we want to be",
    "start": "2267280",
    "end": "2275320"
  },
  {
    "text": "responsive what happens when our systems start to fail well as our systems get bigger and more complex and distributed",
    "start": "2275320",
    "end": "2282320"
  },
  {
    "text": "things are failing all the time In fact in any significantly large system there's always something in a state of",
    "start": "2282320",
    "end": "2288480"
  },
  {
    "text": "being broken but you got to continue on And I love this sort of thing Anybody seen this scene it's wonderful It's like",
    "start": "2288480",
    "end": "2294560"
  },
  {
    "text": "you keep going on It's only a flesh wound Lost a leg lost an arm keep going",
    "start": "2294560",
    "end": "2299599"
  },
  {
    "text": "Our software needs to do that as well And hopefully not pause and give poor response time as it does",
    "start": "2299599",
    "end": "2307200"
  },
  {
    "text": "it So we get into our algorithms at this stage What can we do what can we go",
    "start": "2308040",
    "end": "2314240"
  },
  {
    "text": "forward with well first thing you should do is if we're going to do science we're going to measure I'm going to do things",
    "start": "2314240",
    "end": "2319920"
  },
  {
    "text": "right We have to do clean experiments If you're doing chemistry you would not use",
    "start": "2319920",
    "end": "2325839"
  },
  {
    "text": "all of your little utensils that are dirty I want to check a chemical reaction I'm going to put two agents",
    "start": "2325839",
    "end": "2331200"
  },
  {
    "text": "together I'm not going to do it in a dirty test tube because it's not going to give me the right results We've got",
    "start": "2331200",
    "end": "2336320"
  },
  {
    "text": "to start doing this in our software So we need to work out how to isolate our tests how to take all the noise out of",
    "start": "2336320",
    "end": "2342320"
  },
  {
    "text": "what's going on so we're measuring the right sort of things I'm not going to go into the detail whenever the slides are",
    "start": "2342320",
    "end": "2347680"
  },
  {
    "text": "available You can go off and you can Google for some of these sorts of things But one thing I would really recommend",
    "start": "2347680",
    "end": "2352960"
  },
  {
    "text": "is looking at J Hiccup on this So just Google for a J hiccup if you get the chance It's a lovely little agent that",
    "start": "2352960",
    "end": "2359040"
  },
  {
    "text": "runs inside your process or can run outside your process And what it will do is it'll tell you that a thread was not",
    "start": "2359040",
    "end": "2365680"
  },
  {
    "text": "able to run at any given point in time And that tells you an awful lot about why you've got pauses in your",
    "start": "2365680",
    "end": "2370800"
  },
  {
    "text": "applications You can start identifying when and where and you can correlate with what your applications are actually",
    "start": "2370800",
    "end": "2377240"
  },
  {
    "text": "doing So we've got this clean environment We've now got to run tests and we got to measure And quite often we",
    "start": "2377240",
    "end": "2383440"
  },
  {
    "text": "got a profile Who here has used J visual VM anyone use your kit J profiler all of",
    "start": "2383440",
    "end": "2391880"
  },
  {
    "text": "those as profilers they lie They do not tell you what's going on in",
    "start": "2391880",
    "end": "2397920"
  },
  {
    "text": "your code They're reasonable for a certain class of problem Like that class of problem is typically where you're",
    "start": "2397920",
    "end": "2403359"
  },
  {
    "text": "going to network or you're breaking out of your program to do something else If you get something that's CPU intensive",
    "start": "2403359",
    "end": "2408800"
  },
  {
    "text": "or memory intensive they do not find it because back to those evil safe points I",
    "start": "2408800",
    "end": "2413920"
  },
  {
    "text": "talked before about that is when they sample your program They only sample at safe point not in the highly optimized",
    "start": "2413920",
    "end": "2421119"
  },
  {
    "text": "code that your jet has made for you It's no good You need to use profilers like",
    "start": "2421119",
    "end": "2426320"
  },
  {
    "text": "the new Jrocket mission control with the flight recorder built in SLARS performance studio analyzer Intel Vtune",
    "start": "2426320",
    "end": "2433040"
  },
  {
    "text": "These sorts of profilers actually do proper sampling and they will tell you where the real issues are in your code",
    "start": "2433040",
    "end": "2438720"
  },
  {
    "text": "You got to move forward to that level and stop using some of those other profilers So one of the other things I",
    "start": "2438720",
    "end": "2445440"
  },
  {
    "text": "like to do is incorporate histograms So as as I said before histograms are a great way of measuring if you put them",
    "start": "2445440",
    "end": "2451200"
  },
  {
    "text": "into your code So like whenever you're getting requests in and stuff record the time of stuff Record it in these",
    "start": "2451200",
    "end": "2456480"
  },
  {
    "text": "histograms They're really cheap They're really simple You can get a real good view of what's going on HDR histogram is",
    "start": "2456480",
    "end": "2463520"
  },
  {
    "text": "one of the best for that It stands for high dynamic range It works quite like floatingoint numbers So you don't have",
    "start": "2463520",
    "end": "2469040"
  },
  {
    "text": "to work out what all the bins are in advance It's very very efficient So what can I do to get off",
    "start": "2469040",
    "end": "2475119"
  },
  {
    "text": "this J curve even as my utilization goes up well there's a really old boring",
    "start": "2475119",
    "end": "2480720"
  },
  {
    "text": "technique that works really well that's so misunderstood and that's batching Everyone thinks that batching",
    "start": "2480720",
    "end": "2486480"
  },
  {
    "text": "is this thing that slows you down and adds latency Well if it's done well it actually improves latency How can it do",
    "start": "2486480",
    "end": "2493040"
  },
  {
    "text": "that well most people batch by waiting for a timeout and then applying a batch Don't wait for timeouts with a batch",
    "start": "2493040",
    "end": "2499599"
  },
  {
    "text": "What you do is soon as something is available you perform the action you go back and next time you pick up as much",
    "start": "2499599",
    "end": "2504800"
  },
  {
    "text": "as you can And you do that by introducing something in between So if I want to use a resource in this case",
    "start": "2504800",
    "end": "2511599"
  },
  {
    "text": "let's say I have got multiple threads Let's say I have 10 threads want to write something to disk If they start",
    "start": "2511599",
    "end": "2516800"
  },
  {
    "text": "queuing up to do it because they're going to have to do it under a lock One thing's going to take one unit of time",
    "start": "2516800",
    "end": "2522000"
  },
  {
    "text": "to do it The next thing is going to take two units of time Write up to 10 units of time So you're going to mean response",
    "start": "2522000",
    "end": "2527839"
  },
  {
    "text": "time or five units of time Now if I take a different approach and I put them all",
    "start": "2527839",
    "end": "2533839"
  },
  {
    "text": "onto a data structure and have a separate thread writing them down to the storage my worst case scenario is I pick",
    "start": "2533839",
    "end": "2540960"
  },
  {
    "text": "up one thing off the queue to begin with I write it down to storage I come back to the queue again and I take off the",
    "start": "2540960",
    "end": "2547359"
  },
  {
    "text": "next nine and write them down to storage I've completed the whole operation in two units of time My mean is less than",
    "start": "2547359",
    "end": "2553760"
  },
  {
    "text": "two units of time And that is the worst case scenario You often find in these burst scenarios that you get all 10 and",
    "start": "2553760",
    "end": "2559680"
  },
  {
    "text": "you put them down in one go This massively improves your utilization and you don't go up the J curve anywhere",
    "start": "2559680",
    "end": "2566000"
  },
  {
    "text": "near as quickly So my tip is start looking for things that you canize and",
    "start": "2566000",
    "end": "2571040"
  },
  {
    "text": "once you start thinking about this you start finding them all over the place It's a really useful way of looking at",
    "start": "2571040",
    "end": "2576520"
  },
  {
    "text": "them But the thing that stands out from that is you have to learn to go asynchronous And once you start going",
    "start": "2576520",
    "end": "2582760"
  },
  {
    "text": "asynchronous you can have cues through your system you can measure your cues",
    "start": "2582760",
    "end": "2587839"
  },
  {
    "text": "and you can start applying back pressure by bounding them If people think they don't have cues in their system they're",
    "start": "2587839",
    "end": "2593760"
  },
  {
    "text": "so wrong because if you use locks if you use an IO most things that you come",
    "start": "2593760",
    "end": "2599040"
  },
  {
    "text": "across will have a lock in front of it it will have a mutex of some means And guess what when two or more threads go",
    "start": "2599040",
    "end": "2605680"
  },
  {
    "text": "for something at the same time is one gets it and the rest join a queue So cues become something that are",
    "start": "2605680",
    "end": "2611359"
  },
  {
    "text": "everywhere through your code Make them first class concepts start dealing with them start measuring them apply Little's",
    "start": "2611359",
    "end": "2618160"
  },
  {
    "text": "law to what's going on Now got a much better view of what's going on in my system So back to my thing I said",
    "start": "2618160",
    "end": "2623760"
  },
  {
    "text": "earlier about applying back pressure and not letting other things in So let's say my storage is not keeping up Well these",
    "start": "2623760",
    "end": "2630920"
  },
  {
    "text": "threads won't be able to do any more work If they don't do any more work they don't take stuff in from the queue That",
    "start": "2630920",
    "end": "2636560"
  },
  {
    "text": "will back up to the network We won't be able to put any more data on the network that will back up these threads which",
    "start": "2636560",
    "end": "2643040"
  },
  {
    "text": "will cause that queue to back up which will cause the cues or these threads here to back up that are receiving",
    "start": "2643040",
    "end": "2648640"
  },
  {
    "text": "network traffic from the clients So that way I can apply back pressure all the way through the system Well what's that",
    "start": "2648640",
    "end": "2654240"
  },
  {
    "text": "look like well let's say these guys are making HTTP requests on the front end",
    "start": "2654240",
    "end": "2659440"
  },
  {
    "text": "Well once your threads are all busy and your cues are all full return a 403",
    "start": "2659440",
    "end": "2665119"
  },
  {
    "text": "server busy or 503 server busy at this stage Don't keep accepting new requests",
    "start": "2665119",
    "end": "2670480"
  },
  {
    "text": "It's a much more friendly way to be working So now we've done that we're now",
    "start": "2670480",
    "end": "2676800"
  },
  {
    "text": "going to run all asynchronous And it's so important to run as synchronous I like to think this is a way of getting",
    "start": "2676800",
    "end": "2683440"
  },
  {
    "text": "out of your own way We've got to be non-blocking We've got to go forward We've got to keep things nice and efficient Get off the synchronous way of",
    "start": "2683440",
    "end": "2692119"
  },
  {
    "text": "working And we can do this by stop hoging stuff So the synchronous methods ends up with us hogging We get stuck we",
    "start": "2692119",
    "end": "2698720"
  },
  {
    "text": "get doing that we can also start operating in some interesting ways So now that I'm not hogging now that I'm",
    "start": "2698720",
    "end": "2705280"
  },
  {
    "text": "running asynchronous and now that I'm not using the operating system I can start using things like lock free algorithms kind of specialist ways of",
    "start": "2705280",
    "end": "2711520"
  },
  {
    "text": "working interesting ways of going forward We can start doing these sorts of things Kind of going to rush through",
    "start": "2711520",
    "end": "2717119"
  },
  {
    "text": "a little bit to the end here So let's say now I've got all my state I'm running in this nice way that's all free",
    "start": "2717119",
    "end": "2723599"
  },
  {
    "text": "You get the nice big scary TCP state diagram I'm not expecting you to know this but the important thing is for any",
    "start": "2723599",
    "end": "2729839"
  },
  {
    "text": "given state machine What if you could just read where you're currently at you make them observable Your state machine",
    "start": "2729839",
    "end": "2736640"
  },
  {
    "text": "becomes observable Then you can easily make progress to next steps by targeting",
    "start": "2736640",
    "end": "2742000"
  },
  {
    "text": "where you're at and making decisions You can start batching up your operations You can start monitoring You can profile",
    "start": "2742000",
    "end": "2747119"
  },
  {
    "text": "You can tune So as we make our systems and we design our code make it observable put the current state in a",
    "start": "2747119",
    "end": "2753440"
  },
  {
    "text": "volatile variable that you can read it This lets you make your things observable make good progress keep going",
    "start": "2753440",
    "end": "2760839"
  },
  {
    "text": "So here's a really simple thing that we can do to get a lot of work through our systems make them simple make them fast",
    "start": "2760839",
    "end": "2767599"
  },
  {
    "text": "whenever they're now as sync Let's say I now sequence data into my system So I introduce a sequencer I get lots of",
    "start": "2767599",
    "end": "2774400"
  },
  {
    "text": "traffic coming in Once that's sequenced I can send the same sequence to two or more services those services can respond",
    "start": "2774400",
    "end": "2782800"
  },
  {
    "text": "If you're responding back in an item potent fashion what happens to the first one to",
    "start": "2782800",
    "end": "2788160"
  },
  {
    "text": "respond you process it If it's item potent you get another message back Well that's absolutely cool It doesn't matter",
    "start": "2788160",
    "end": "2793599"
  },
  {
    "text": "You throw away the second one Let's say one of these dies I've got a very responsive system because it doesn't",
    "start": "2793599",
    "end": "2800520"
  },
  {
    "text": "matter Start playing around with this You can run things on different memory settings different processors start",
    "start": "2800520",
    "end": "2806480"
  },
  {
    "text": "doing that and then all of a sudden I'm whizzing back and it doesn't matter if one's slower one's faster we still get",
    "start": "2806480",
    "end": "2813359"
  },
  {
    "text": "responsive really quickly and the first one to get there is there and it's fast If you want to read you replicate to",
    "start": "2813359",
    "end": "2819359"
  },
  {
    "text": "many other sites and that lets us go forward and lets us go forward really quickly Final bit I'll tell you on",
    "start": "2819359",
    "end": "2826480"
  },
  {
    "text": "techniques and algorithms is please go back and learn data structures There's one thing that will stick with us",
    "start": "2826480",
    "end": "2831760"
  },
  {
    "text": "through our careers is data structures will not go away There's more to the world than maps and lists You start",
    "start": "2831760",
    "end": "2838160"
  },
  {
    "text": "getting into loads of wonderful things like bloom filters skip lists all sorts of interesting tree structures and stuff",
    "start": "2838160",
    "end": "2843440"
  },
  {
    "text": "that's out there These things are dead useful for how we end up working They will stay with you for your career much",
    "start": "2843440",
    "end": "2849440"
  },
  {
    "text": "better than the latest version of some library that's just out and that's trendy So I'm going to wind up quickly",
    "start": "2849440",
    "end": "2856160"
  },
  {
    "text": "in closing Something's coming It's kind of interesting world that we're now living",
    "start": "2856160",
    "end": "2861440"
  },
  {
    "text": "in to use a common meme Is winter coming what's really coming is the internet of",
    "start": "2861440",
    "end": "2868440"
  },
  {
    "text": "things last year for the first time we passed the point where the number of",
    "start": "2868440",
    "end": "2873680"
  },
  {
    "text": "devices on the internet is greater than the number of people on the planet Connected devices is now greater than",
    "start": "2873680",
    "end": "2879920"
  },
  {
    "text": "the number of people This is continuing to go up We could be anywhere up to 75",
    "start": "2879920",
    "end": "2885440"
  },
  {
    "text": "billion depending on your point of view by 2020 So that's going to keep happening So what that means is we",
    "start": "2885440",
    "end": "2891920"
  },
  {
    "text": "cannot control our arrival rates The fact that we can control them we don't want to because we want this business to",
    "start": "2891920",
    "end": "2898880"
  },
  {
    "text": "come we've got to deal with it So we got to and when we design our applications",
    "start": "2898880",
    "end": "2905280"
  },
  {
    "text": "if we don't respond in a timely manner things don't happen so well So take this",
    "start": "2905280",
    "end": "2910880"
  },
  {
    "text": "poor person here They haven't reacted quick enough and that's going to cause a lot of pain Really think about how we",
    "start": "2910880",
    "end": "2917040"
  },
  {
    "text": "start improving our service times We just cannot keep expecting to have our systems work the way they used to and",
    "start": "2917040",
    "end": "2923280"
  },
  {
    "text": "not perform or other choices to go parallel But that's hard It's really difficult",
    "start": "2923280",
    "end": "2930000"
  },
  {
    "text": "It's much easier to try and improve service times Is much easier to focus in on what we've got And on that point I'll",
    "start": "2930000",
    "end": "2936160"
  },
  {
    "text": "finish off [Applause]",
    "start": "2936160",
    "end": "2945380"
  }
]
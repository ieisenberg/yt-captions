[
  {
    "start": "0",
    "end": "57000"
  },
  {
    "text": "thank you Graham for that wonderful introduction I'm very happy to be at Melbourne this is my first time in",
    "start": "11059",
    "end": "17100"
  },
  {
    "text": "Australia and I'm very pleased to be here um I'm I got a call yesterday so I think I'm projecting quite well but if for",
    "start": "17100",
    "end": "23640"
  },
  {
    "text": "some reason you can't hear me just raise your hand and I'll speak a bit louder um so as Graham mentioned I'm going to",
    "start": "23640",
    "end": "28680"
  },
  {
    "text": "talk to you today about Big Data fast data at PayPal just a show of hands how many of you work in the data field",
    "start": "28680",
    "end": "35460"
  },
  {
    "text": "okay now keep your hands up if you've been in this field for more than five years",
    "start": "35460",
    "end": "40500"
  },
  {
    "text": "okay so most people are somewhat new it sounds like to to data and it's good because I'll cover some Basics",
    "start": "40500",
    "end": "47640"
  },
  {
    "text": "um and there'll be time at the end for questions if anything sort of flies past you that you'd like to learn more about so as Graham mentioned uh I work at",
    "start": "47640",
    "end": "54480"
  },
  {
    "text": "PayPal I've been there for about a year and a half before joining PayPal I worked at a series of different",
    "start": "54480",
    "end": "59879"
  },
  {
    "start": "57000",
    "end": "303000"
  },
  {
    "text": "companies in the uh in the Bay Area San Francisco Bay Area I'm also co-chair for",
    "start": "59879",
    "end": "65280"
  },
  {
    "text": "qcon and a maintainer of Apache airflow Apache airflow how many of you have heard of it raise your hand great",
    "start": "65280",
    "end": "72659"
  },
  {
    "text": "um so maybe like a tenth of you it's essentially a workflow engine that you can use for data processing and mo",
    "start": "72659",
    "end": "78119"
  },
  {
    "text": "pipelines and we're entering the graduation phase right now as as I speak and I'm also the father of two",
    "start": "78119",
    "end": "84060"
  },
  {
    "text": "rambunctious young kids a six-year-old and a two-year-old so just to show events how many of you",
    "start": "84060",
    "end": "89640"
  },
  {
    "text": "use PayPal okay great um so most of you are aware of what",
    "start": "89640",
    "end": "96420"
  },
  {
    "text": "PayPal does but you may not be aware of its scale so let's talk about that um we so as of 2017 we were handling 200",
    "start": "96420",
    "end": "105600"
  },
  {
    "text": "plus different markets countries and territories and over 100 currencies",
    "start": "105600",
    "end": "111060"
  },
  {
    "text": "we closed out the year with 227 million active customer accounts an active",
    "start": "111060",
    "end": "117420"
  },
  {
    "text": "customer account is any account that um that has done you know a transaction in the last 12 months and those accounts",
    "start": "117420",
    "end": "125280"
  },
  {
    "text": "uh worked they transacted with each other to the tune of 7.8 billion payment transactions",
    "start": "125280",
    "end": "131039"
  },
  {
    "text": "this all ran on a service fabric that supported 2700 microservices",
    "start": "131039",
    "end": "137879"
  },
  {
    "text": "written by and built and written by uh you know 4 500 Engineers who completed",
    "start": "137879",
    "end": "143099"
  },
  {
    "text": "17 000 releases that year and this software fabric runs in data",
    "start": "143099",
    "end": "148379"
  },
  {
    "text": "centers that have 200 000 servers that consumed 27 megawatts of Power 92",
    "start": "148379",
    "end": "155700"
  },
  {
    "text": "percent of which is green power and they use or consume 238 petabytes of",
    "start": "155700",
    "end": "162060"
  },
  {
    "text": "storage so that uh you know petabytes is a large number so let's put that in perspective",
    "start": "162060",
    "end": "168239"
  },
  {
    "text": "if you were to take all your DVDs and stack them up in a column that would be seven times the height of Mount Everest",
    "start": "168239",
    "end": "175080"
  },
  {
    "text": "if you were to put it on laptops you'd have 500 000 laptops and if you put it on tablets you'd have",
    "start": "175080",
    "end": "181140"
  },
  {
    "text": "2 million tablets worth of data so we continue to grow",
    "start": "181140",
    "end": "186720"
  },
  {
    "text": "we continue to enter new currencies and territories we just passed the 250",
    "start": "186720",
    "end": "191819"
  },
  {
    "text": "million Mark of active customer accounts which would make us the fifth largest country if we were a country",
    "start": "191819",
    "end": "197879"
  },
  {
    "text": "and those customers are continuing to interact with each other so we see payment volume increase and all sorts of",
    "start": "197879",
    "end": "203940"
  },
  {
    "text": "metrics are continuing to go up and for this to happen we have to build",
    "start": "203940",
    "end": "209340"
  },
  {
    "text": "a data infrastructure that can support it so today our oltp databases uh",
    "start": "209340",
    "end": "215459"
  },
  {
    "text": "account for about 2 000 of our servers they handle 116 billion queries a day",
    "start": "215459",
    "end": "222180"
  },
  {
    "text": "and they consume 74 petabytes of storage",
    "start": "222180",
    "end": "227700"
  },
  {
    "text": "on the messaging side we have multiple solutions to our homegrown the one of Interest here is the one that's open",
    "start": "227700",
    "end": "233280"
  },
  {
    "text": "source it's our newest one and it's Kafka it currently supports 3000 plus",
    "start": "233280",
    "end": "239040"
  },
  {
    "text": "topics spread out over 50 clusters and handles 400 plus billion messages a day",
    "start": "239040",
    "end": "246599"
  },
  {
    "text": "and it also consumes a decent amount of storage and then on the Hadoop side we have 32",
    "start": "246599",
    "end": "253260"
  },
  {
    "text": "Hadoop clusters the largest clusters we have max out at about 5 000 nodes I",
    "start": "253260",
    "end": "259680"
  },
  {
    "text": "think the largest I've heard about in the industry is like a 10 000 node cluster the name node is really the",
    "start": "259680",
    "end": "264840"
  },
  {
    "text": "thing to worry about here and these Hadoop clusters handle 200 000 jobs a day",
    "start": "264840",
    "end": "269880"
  },
  {
    "text": "and they have generated over the you know lifetime of this company 250 petabytes of storage",
    "start": "269880",
    "end": "276960"
  },
  {
    "text": "so a little interlude since I'm in Australia I thought this was a very interesting fun fact so there are about",
    "start": "276960",
    "end": "282300"
  },
  {
    "text": "25 million of you of which 19 million of you are eligible for PayPal based on age for example",
    "start": "282300",
    "end": "289580"
  },
  {
    "text": "and I think I asked everyone to raise their hands right who had a PayPal account so you account for the largest",
    "start": "289580",
    "end": "295440"
  },
  {
    "text": "penetrated Market that we have so you know keep it up and I might come back next year so I'm very excited to be here for that reason",
    "start": "295440",
    "end": "302400"
  },
  {
    "text": "so scale is only half of our story we're a 20 year old company",
    "start": "302400",
    "end": "307680"
  },
  {
    "start": "303000",
    "end": "443000"
  },
  {
    "text": "the rest of our story has to do with the fact that requirements have changed over time and over 20 years technology has",
    "start": "307680",
    "end": "314160"
  },
  {
    "text": "changed and if I just show you a snapshot of our infrastructure it may not make a lot of sense so I thought it would make more",
    "start": "314160",
    "end": "320759"
  },
  {
    "text": "sense if I kind of walked you through how a modern website would be built today and how it would evolve into a",
    "start": "320759",
    "end": "327539"
  },
  {
    "text": "complex data infrastructure that matches what we have at PayPal so let's start with the fact that you",
    "start": "327539",
    "end": "333419"
  },
  {
    "text": "have some sort of app that needs to work on a mobile phone or a desktop",
    "start": "333419",
    "end": "338759"
  },
  {
    "text": "and most startups start in the cloud so you'll probably be running on ec2 if",
    "start": "338759",
    "end": "344639"
  },
  {
    "text": "you're on Amazon and maybe you're a python person and you'll use flask or Django or you're a ruby person and",
    "start": "344639",
    "end": "350160"
  },
  {
    "text": "you'll run rails and at some point you have to figure out the persistence problem you have to store your data somewhere",
    "start": "350160",
    "end": "355800"
  },
  {
    "text": "so the cloud providers have range of managed options right you can you can run on any like postgres managed or",
    "start": "355800",
    "end": "362400"
  },
  {
    "text": "something like this as traffic grows it's common that you'll need to scale out and if you're running",
    "start": "362400",
    "end": "368759"
  },
  {
    "text": "on ec2 the solution typically is like an auto scaler plus an elb elastic load",
    "start": "368759",
    "end": "373860"
  },
  {
    "text": "balancer but at some point um your data volume is going to increase",
    "start": "373860",
    "end": "378960"
  },
  {
    "text": "and if you're a small startup of a couple people you don't really have time to scale out your database because that",
    "start": "378960",
    "end": "385500"
  },
  {
    "text": "takes a lot of resources so one thing I've seen people do over the lifetime of working at these startups is they shift",
    "start": "385500",
    "end": "391919"
  },
  {
    "text": "load off of those databases so postgres for example is a wonderful database it does databasy things it does search",
    "start": "391919",
    "end": "398759"
  },
  {
    "text": "things so when I was at Etsy we used it for both but our biggest heavy hitter queries were always search on the",
    "start": "398759",
    "end": "405479"
  },
  {
    "text": "jewelry category and it was like 40 of our CPU so it made more sense in that",
    "start": "405479",
    "end": "410580"
  },
  {
    "text": "case rather than scale up postgres to move search off onto a search engine at",
    "start": "410580",
    "end": "415800"
  },
  {
    "text": "that time it was solar it was like many years ago elastic I think is more prevalent but now you have a problem",
    "start": "415800",
    "end": "421860"
  },
  {
    "text": "how do you keep these two in sync so we'll get into uh changing the",
    "start": "421860",
    "end": "428160"
  },
  {
    "text": "capture later on you know some people will try an X8 transaction and that sort of stuff but the fact is search doesn't",
    "start": "428160",
    "end": "434220"
  },
  {
    "text": "understand transactions it doesn't know how to roll back anything if there's a problem so a common approach is to use what's",
    "start": "434220",
    "end": "440400"
  },
  {
    "text": "called change data capture you essentially mine the commit log as it's being written and stream it to this",
    "start": "440400",
    "end": "447180"
  },
  {
    "start": "443000",
    "end": "838000"
  },
  {
    "text": "little pink box and the job of the pink box is essentially read a record out of",
    "start": "447180",
    "end": "452220"
  },
  {
    "text": "this commit log and convert it to a search document and index it but let's say you're at Facebook",
    "start": "452220",
    "end": "457979"
  },
  {
    "text": "LinkedIn or or maybe a Marketplace you have images where do you store those images in the past",
    "start": "457979",
    "end": "464940"
  },
  {
    "text": "20 years ago when I started filers you store all of these images on filers but filers don't really scale that well and",
    "start": "464940",
    "end": "471660"
  },
  {
    "text": "in the last 20 years a host of object stores have come online either hosted ones like S3 or or manage or things you",
    "start": "471660",
    "end": "478620"
  },
  {
    "text": "can buy off the shelf or open source ones so you'll have a media store probably built on object storage for all",
    "start": "478620",
    "end": "483900"
  },
  {
    "text": "of your images and of course any company that needs funding has to put AI somewhere in its",
    "start": "483900",
    "end": "490319"
  },
  {
    "text": "title right and what it is mission statement so you'll hire some data scientists and you'll you'll excite them",
    "start": "490319",
    "end": "496199"
  },
  {
    "text": "and tell them that they're going to rebuild the world and they're going to build awesome personalization features",
    "start": "496199",
    "end": "501419"
  },
  {
    "text": "for the customers like maybe Spotify or Netflix needs to personalize the content that you see or Amazon or Ebay have to",
    "start": "501419",
    "end": "508160"
  },
  {
    "text": "give you some item to item recommendations if you bought this buy this one unfortunately all of your data is in an",
    "start": "508160",
    "end": "515159"
  },
  {
    "text": "oltp data store so what are these poor data scientists to do they're going to run large scanning workloads against",
    "start": "515159",
    "end": "520860"
  },
  {
    "text": "your database is that a good idea I mean uh is that what an oltp database",
    "start": "520860",
    "end": "527700"
  },
  {
    "text": "was built for so very soon you find out there's some sort of impedance mismatch between your",
    "start": "527700",
    "end": "533459"
  },
  {
    "text": "use cases your your website is has very well defined",
    "start": "533459",
    "end": "538980"
  },
  {
    "text": "workloads and oltp databases have b style B3 style indexes like B plus trees",
    "start": "538980",
    "end": "545399"
  },
  {
    "text": "and they pick and choose which indexes to build and which indexes to use if",
    "start": "545399",
    "end": "550740"
  },
  {
    "text": "they add too many indexes it slows down the rights on the on the other hand analytics likes to they don't know what",
    "start": "550740",
    "end": "557160"
  },
  {
    "text": "their workloads are they want to query by any column essentially they want to index every column and that's really",
    "start": "557160",
    "end": "562680"
  },
  {
    "text": "going to hurt um your your database for serving needs so the typical solution to this is two",
    "start": "562680",
    "end": "570300"
  },
  {
    "text": "different databases let's use the oltp database for well-defined workloads and",
    "start": "570300",
    "end": "575700"
  },
  {
    "text": "be judicious about the indexes that we build and on the olap side we'll use bitmap",
    "start": "575700",
    "end": "580860"
  },
  {
    "text": "indexes but they're not updatable but that's fine it's a trade-off we'll we'll do an elt process every so often to",
    "start": "580860",
    "end": "587640"
  },
  {
    "text": "handle it so you'll buy a teradata or a vertica or maybe you use bigquery or um",
    "start": "587640",
    "end": "593820"
  },
  {
    "text": "or redshift and that will be your olap database and now you have this challenge syncing",
    "start": "593820",
    "end": "599700"
  },
  {
    "text": "the two so as mentioned bitmap indexes are not updatable but you can run a job every",
    "start": "599700",
    "end": "606660"
  },
  {
    "text": "hour or every day that will extract the data from your oltp database maybe transform it and",
    "start": "606660",
    "end": "613620"
  },
  {
    "text": "load it into the target but you need to you need a scheduler for that I I think you guys say scheduler",
    "start": "613620",
    "end": "619380"
  },
  {
    "text": "but I'm not sure um so so you need a scheduler to actually do this kind of work",
    "start": "619380",
    "end": "625680"
  },
  {
    "text": "and then you realize what you've actually done is you've taken this big scanning workload off of your expensive",
    "start": "625680",
    "end": "631800"
  },
  {
    "text": "Oracle database and just moved it to your expensive teradata it's still not the right fit",
    "start": "631800",
    "end": "637860"
  },
  {
    "text": "um so people realized that why don't we just use hdfs for the big scans right it",
    "start": "637860",
    "end": "643620"
  },
  {
    "text": "doesn't need really indexes it's scanning all of the data so we build a data Lake and that data lake is built",
    "start": "643620",
    "end": "650160"
  },
  {
    "text": "off of hdfs and now you move your data processing and ml workflow uh right off onto your",
    "start": "650160",
    "end": "657000"
  },
  {
    "text": "data Lake and you update your elt pipeline to hit two Targets",
    "start": "657000",
    "end": "662959"
  },
  {
    "text": "but now your data scientists say that they want to query that data because they need to look at the data shape and",
    "start": "663240",
    "end": "669000"
  },
  {
    "text": "they need to look for outliers and so now they need a SQL on Hadoop solution so Cloudera has one called Impala",
    "start": "669000",
    "end": "676399"
  },
  {
    "text": "Facebook created something called presto some people still use hive",
    "start": "676399",
    "end": "681660"
  },
  {
    "text": "um so that is another thing that you need to add to your mix but we've only talked about data that's",
    "start": "681660",
    "end": "688200"
  },
  {
    "text": "committed to a database what about engagement metrics like page Impressions or clicks that's never written to a",
    "start": "688200",
    "end": "695339"
  },
  {
    "text": "database instead apps write it down into Kafka and Kafka consumers like another",
    "start": "695339",
    "end": "701279"
  },
  {
    "text": "pink box you do aggregate or can like collect that data and collate it and",
    "start": "701279",
    "end": "706800"
  },
  {
    "text": "write it every 30 minutes or so to hdfs it can be real time because the Hadoop",
    "start": "706800",
    "end": "712860"
  },
  {
    "text": "name node has this problem of small files and we all live in a connected world",
    "start": "712860",
    "end": "718200"
  },
  {
    "text": "right so if you work for say Twitter or or Facebook or LinkedIn you'll see that",
    "start": "718200",
    "end": "723720"
  },
  {
    "text": "you someone in your group is building people you should follow or who you should connect with and that's a graph",
    "start": "723720",
    "end": "730019"
  },
  {
    "text": "triangle closing problem which means you need graph processing like Graphics or if you work at a fintech company like I",
    "start": "730019",
    "end": "736500"
  },
  {
    "text": "do we we have to look out for collusion detection and that's another triangle closing problem",
    "start": "736500",
    "end": "742740"
  },
  {
    "text": "and what about caches everyone has caches right that's the best way to gain",
    "start": "742740",
    "end": "747959"
  },
  {
    "text": "Headroom in your database you offload the reads and last but not least real-time Ola if",
    "start": "747959",
    "end": "754980"
  },
  {
    "text": "you um were on LinkedIn recently and you posted something you kind of want to get the views the count of views or the",
    "start": "754980",
    "end": "761880"
  },
  {
    "text": "likes or comments and and that's served by linkedin's Pinot project which has recently been put into Apache",
    "start": "761880",
    "end": "768720"
  },
  {
    "text": "or you can use Apache Druid for this so any modern uh website you built today",
    "start": "768720",
    "end": "775019"
  },
  {
    "text": "it has something like this it has all of these components and I've actually left some off so a question for you what are",
    "start": "775019",
    "end": "782160"
  },
  {
    "text": "one or two things that I might have left off foreign",
    "start": "782160",
    "end": "788399"
  },
  {
    "text": "so stream processing is one I don't even have it on this list there was just no space but we'll be talking about it a",
    "start": "791459",
    "end": "797100"
  },
  {
    "text": "little later so I like to categorize things in this space in three categories you don't have",
    "start": "797100",
    "end": "804660"
  },
  {
    "text": "to read this this is mostly for your own reference later online serving needs offline analytics",
    "start": "804660",
    "end": "810240"
  },
  {
    "text": "needs and data movement right so all the pink boxes are things that move data",
    "start": "810240",
    "end": "815760"
  },
  {
    "text": "from online to offline or back all the green boxes have to serve high availability reads and writes and all",
    "start": "815760",
    "end": "823620"
  },
  {
    "text": "the Yellow Boxes have to serve very complex needs but don't need that availability right",
    "start": "823620",
    "end": "829100"
  },
  {
    "text": "so when I started my career 20 years ago it was a database and a Filer and in 20",
    "start": "829100",
    "end": "835019"
  },
  {
    "text": "years this is what we have so what are some takeaways from this",
    "start": "835019",
    "end": "841019"
  },
  {
    "start": "838000",
    "end": "930000"
  },
  {
    "text": "um many startups I've been in right everyone's frantically working on stuff and then you get paged at 2AM in the",
    "start": "841019",
    "end": "847560"
  },
  {
    "text": "morning and they're like the databases under load what do we do so obviously if you're in a startup you kind of want to",
    "start": "847560",
    "end": "853500"
  },
  {
    "text": "build shiny new bottles right so you you think about hey I'm going to replace this with this cool thing I just read about or let's scale this out but that's",
    "start": "853500",
    "end": "860459"
  },
  {
    "text": "a very hard problem to solve why not instead look at the workload on",
    "start": "860459",
    "end": "866160"
  },
  {
    "text": "those databases and partition the workload take some of that work off of your database don't be too quick to try",
    "start": "866160",
    "end": "873360"
  },
  {
    "text": "to scale up or scale out your database instead move it off to other systems maybe hire people to manage those",
    "start": "873360",
    "end": "880260"
  },
  {
    "text": "systems and have the systems communicate with one another in using well-defined protocols and interfaces",
    "start": "880260",
    "end": "887220"
  },
  {
    "text": "this is really the microservice approach and over the last few years I've seen that the microservice approach and",
    "start": "887220",
    "end": "893519"
  },
  {
    "text": "Conway's law completely fits in this space right it's what you used to have before",
    "start": "893519",
    "end": "899459"
  },
  {
    "text": "was a complex set of workloads on one database with very crazy trade-offs and",
    "start": "899459",
    "end": "904740"
  },
  {
    "text": "you weren't getting anything out of it but once you move those workloads to well-designed specific systems that are good for that",
    "start": "904740",
    "end": "911699"
  },
  {
    "text": "workload then you get your system actually behaves much better and your",
    "start": "911699",
    "end": "916980"
  },
  {
    "text": "teams now interface with each other using these protocols and interfaces so now we've talked about how it would",
    "start": "916980",
    "end": "923820"
  },
  {
    "text": "look like to build your own system from scratch but what is PayPal's data",
    "start": "923820",
    "end": "928860"
  },
  {
    "text": "architecture look like so to start with we serve data to our",
    "start": "928860",
    "end": "934019"
  },
  {
    "start": "930000",
    "end": "1348000"
  },
  {
    "text": "customers out of two data centers one in Salt Lake City the other one in Phoenix",
    "start": "934019",
    "end": "940079"
  },
  {
    "text": "when you type in paypal.com on your mobile phone or your web page we use",
    "start": "940079",
    "end": "945899"
  },
  {
    "text": "Akamai routing to route you to one of the the closest data centers to you and when you land in that data center",
    "start": "945899",
    "end": "952440"
  },
  {
    "text": "your request hits a routing tier each data center has multiple availability zones just like in the cloud",
    "start": "952440",
    "end": "959459"
  },
  {
    "text": "and I mentioned earlier we have 2700 web server like microservices",
    "start": "959459",
    "end": "965399"
  },
  {
    "text": "each of these azs has that number of microservices",
    "start": "965399",
    "end": "971060"
  },
  {
    "text": "and at some point one of your microservices wants to hit a database so we have one horizontal AZ",
    "start": "972420",
    "end": "978959"
  },
  {
    "text": "for all of the databases and this easy has to be much higher availability like",
    "start": "978959",
    "end": "984060"
  },
  {
    "text": "say five nines than the then the the vertical ones but if you remember I mentioned we have",
    "start": "984060",
    "end": "990560"
  },
  {
    "text": "2700 microservices each microservice we have a hundred",
    "start": "990560",
    "end": "995699"
  },
  {
    "text": "servers each server may have a hundred connections now each server if they were talking to",
    "start": "995699",
    "end": "1001040"
  },
  {
    "text": "a database is going to generate like this is going to generate hundreds of thousands of connections into any",
    "start": "1001040",
    "end": "1006079"
  },
  {
    "text": "database that's a lot of connections so we can't handle that so we wrote something in golang that",
    "start": "1006079",
    "end": "1012980"
  },
  {
    "text": "multiplexes connections it's called OCC into our database it's reactive it does",
    "start": "1012980",
    "end": "1018139"
  },
  {
    "text": "back pressure and sometime this year we're going to open source it so keep on the lookout for that",
    "start": "1018139",
    "end": "1024380"
  },
  {
    "text": "outside of our serving data centers we have an analytics Data Center",
    "start": "1024380",
    "end": "1030500"
  },
  {
    "text": "in this data center we have two types of data stores we have teradata which",
    "start": "1030500",
    "end": "1036260"
  },
  {
    "text": "handles all our like query loads it's like an MPP shared nothing database and we have Hadoop and our three use",
    "start": "1036260",
    "end": "1044298"
  },
  {
    "text": "cases the ones I mentioned earlier are spread over these two types of data stores are reporting essentially goes to",
    "start": "1044299",
    "end": "1051980"
  },
  {
    "text": "teradata but the other two hit a mix of both Hadoop and teradita and the reason",
    "start": "1051980",
    "end": "1058520"
  },
  {
    "text": "for this is our data is at such a scale we can't have all our data in any one",
    "start": "1058520",
    "end": "1064039"
  },
  {
    "text": "data store we kind of have to pick so some of our data is only entire data and",
    "start": "1064039",
    "end": "1069860"
  },
  {
    "text": "some of our data is only in Hadoop and how do we sync these two data data",
    "start": "1069860",
    "end": "1075440"
  },
  {
    "text": "stores the online one with the offline one so I mentioned uh change data capture that is what we use we use something",
    "start": "1075440",
    "end": "1082220"
  },
  {
    "text": "called Golden Gate it's an oracle product how many of you have actually heard of Golden Gate a few of you it supports sources like",
    "start": "1082220",
    "end": "1089960"
  },
  {
    "text": "Oracle and MySQL and we use a Golden Gate to stream the commit log to two",
    "start": "1089960",
    "end": "1096080"
  },
  {
    "text": "Targets uh one target is called ois that's used for batch so any tables that",
    "start": "1096080",
    "end": "1103640"
  },
  {
    "text": "we want to land in teradata we we target for ois and this thing is called a pump",
    "start": "1103640",
    "end": "1109280"
  },
  {
    "text": "that I show here the pump is essentially a router that uses table specific logic",
    "start": "1109280",
    "end": "1114320"
  },
  {
    "text": "if like it knows which table needs to go to one target versus another so anything that goes to ois will be",
    "start": "1114320",
    "end": "1120620"
  },
  {
    "text": "scheduled via an elt or ETL job to land in teradata and then the bottom one is",
    "start": "1120620",
    "end": "1126620"
  },
  {
    "text": "called cdhr I'm going to talk about that more it's our streaming Target so any",
    "start": "1126620",
    "end": "1132260"
  },
  {
    "text": "tables that hit cdhr are going to be live streamed um to streaming consumers but also it'll",
    "start": "1132260",
    "end": "1138080"
  },
  {
    "text": "be aggregated in Hadoop for for those users and we have a scheduler and of course we",
    "start": "1138080",
    "end": "1143240"
  },
  {
    "text": "don't just have one we have three right and why not have three right it adds",
    "start": "1143240",
    "end": "1148400"
  },
  {
    "text": "complexity it confuses everybody it makes your life a living hell right um so it's not by Design right it's",
    "start": "1148400",
    "end": "1154400"
  },
  {
    "text": "eventually we would like to shrink this down to one or two and we're trying Apache airflow for for some of these",
    "start": "1154400",
    "end": "1159559"
  },
  {
    "text": "needs and we have a project called steam donkey okay",
    "start": "1159559",
    "end": "1165559"
  },
  {
    "text": "um it's a terrible name and no one in that team likes to say they're on this team but it does a very critical job and",
    "start": "1165559",
    "end": "1170660"
  },
  {
    "text": "it moves data sets off of teradata into Hadoop so we can start moving the ml jobs all into the data Lake right rather",
    "start": "1170660",
    "end": "1177679"
  },
  {
    "text": "than hitting teradata so the rest of this talk is going to focus on the stream stream processing",
    "start": "1177679",
    "end": "1182780"
  },
  {
    "text": "part and a little on the analytics side so to get a sense of uh the use case we",
    "start": "1182780",
    "end": "1189200"
  },
  {
    "text": "need to to handle let's let's look at one the hardest use case so let's say I want to send my wife money how many of",
    "start": "1189200",
    "end": "1195559"
  },
  {
    "text": "you have sent money to someone using PayPal raise your hand Okay cool so you still realize that paper was originally made for that use",
    "start": "1195559",
    "end": "1201980"
  },
  {
    "text": "case uh now it's mostly used for merchant payments but it started out as the way to pay your friends",
    "start": "1201980",
    "end": "1208280"
  },
  {
    "text": "um and then I go to the second screen I fill out some reason for giving my wife only a dollar in one cent I have to explain why I gave her so little",
    "start": "1208280",
    "end": "1215660"
  },
  {
    "text": "um and then I see a confirmation page and after I see the confirmation page I I go back to my home screen and on the",
    "start": "1215660",
    "end": "1222440"
  },
  {
    "text": "home screen I see that my activity shows that I've given her a dollar and one cent but what's interesting about this",
    "start": "1222440",
    "end": "1229100"
  },
  {
    "text": "well the first three pages are part of a synchronous flow with respect to the",
    "start": "1229100",
    "end": "1234559"
  },
  {
    "text": "data store and the last page is asynchronous now what do I mean by this",
    "start": "1234559",
    "end": "1239660"
  },
  {
    "text": "the first three pages talk to One database the last page talks to a different database and we have to solve the",
    "start": "1239660",
    "end": "1246440"
  },
  {
    "text": "problem of synchronizing these two in a very short period of time and we can't lose any data that's very",
    "start": "1246440",
    "end": "1252860"
  },
  {
    "text": "critical because we don't just have consumer activity Merchants also use this to see the money that they've been",
    "start": "1252860",
    "end": "1258980"
  },
  {
    "text": "paid there's also a merchant activity screen so what's happening behind the scenes",
    "start": "1258980",
    "end": "1264559"
  },
  {
    "text": "so behind the scenes um you will talk to our you know Myriad of microservices by the way 2700 is not",
    "start": "1264559",
    "end": "1270980"
  },
  {
    "text": "something to be proud of I think we know that um we have way too many microservices",
    "start": "1270980",
    "end": "1276500"
  },
  {
    "text": "and these microservices talk to our database and as mentioned earlier we have this change data capture thing",
    "start": "1276500",
    "end": "1283100"
  },
  {
    "text": "that sucks data out live and streams it and the important thing here is the",
    "start": "1283100",
    "end": "1289400"
  },
  {
    "text": "first component in this pipeline it's called the replicant the job of the replicat is to read this Oracle",
    "start": "1289400",
    "end": "1296659"
  },
  {
    "text": "proprietary binary format called the the it's called the trail file format and",
    "start": "1296659",
    "end": "1304280"
  },
  {
    "text": "convert it to something that all our consumers can read and for us we pick Avro how many of you have heard of Avro",
    "start": "1304280",
    "end": "1310159"
  },
  {
    "text": "Apache avra okay great um and I'll explain why we picked Avro over things like protobuf or or or",
    "start": "1310159",
    "end": "1317380"
  },
  {
    "text": "what's the other one that Facebook has went to Thrift so the goal is that as each record is",
    "start": "1317380",
    "end": "1324980"
  },
  {
    "text": "written the replicant will actually update the schema in a schema registry",
    "start": "1324980",
    "end": "1330500"
  },
  {
    "text": "and it will get an ID back and that ID is the ID of the published schema in the",
    "start": "1330500",
    "end": "1336200"
  },
  {
    "text": "schema registry it'll compose a message the header of the message will have the ID and the payload of the message will",
    "start": "1336200",
    "end": "1342919"
  },
  {
    "text": "be the Avro encoded record from the database and we we send it on",
    "start": "1342919",
    "end": "1348080"
  },
  {
    "start": "1348000",
    "end": "1499000"
  },
  {
    "text": "decaska on the other side we have a router that we wrote in storm",
    "start": "1348080",
    "end": "1354080"
  },
  {
    "text": "and Storm's job is to read the message header extract the ID",
    "start": "1354080",
    "end": "1359539"
  },
  {
    "text": "and now it has the ID it can go to the schema registry and pull down the writer",
    "start": "1359539",
    "end": "1365299"
  },
  {
    "text": "schema it can then use that schema to decode the payload so now it actually has data",
    "start": "1365299",
    "end": "1372080"
  },
  {
    "text": "in memory in its own object model and there's one more challenge so with",
    "start": "1372080",
    "end": "1378620"
  },
  {
    "text": "change data capture the default way that things work is you're reading from a commit log so if you update two columns",
    "start": "1378620",
    "end": "1384980"
  },
  {
    "text": "in a 10 column Row the commit log only has those two columns but people Downstream want the full",
    "start": "1384980",
    "end": "1392059"
  },
  {
    "text": "record so we need to go and hydrate the the record from the database",
    "start": "1392059",
    "end": "1398179"
  },
  {
    "text": "so we go ahead and hydrate and we get the full row and the next challenge we have is",
    "start": "1398179",
    "end": "1403400"
  },
  {
    "text": "because we're in fintech we have a lot of regulatory requirements and lots of",
    "start": "1403400",
    "end": "1408679"
  },
  {
    "text": "columns are sensitive columns like let's say the credit card pen or the CVC code",
    "start": "1408679",
    "end": "1413840"
  },
  {
    "text": "we can just send that to any destination we have multiple destinations some are sensitive than others so we need to mask",
    "start": "1413840",
    "end": "1420200"
  },
  {
    "text": "or filter certain columns based on the destination we're sending it to and we then send end messages down in",
    "start": "1420200",
    "end": "1426440"
  },
  {
    "text": "this case we're sending it to the activity Services the activity service does the same kind of thing of decoding",
    "start": "1426440",
    "end": "1433340"
  },
  {
    "text": "um the the Avro message payload it does some Transformations and then writes it to its own database",
    "start": "1433340",
    "end": "1440000"
  },
  {
    "text": "so that when you actually visit your activity page it's updated so it seems like a lot is happening here right",
    "start": "1440000",
    "end": "1447559"
  },
  {
    "text": "but this works quite well it handles hundreds of millions of events per day",
    "start": "1447559",
    "end": "1453860"
  },
  {
    "text": "it does it within 60 Seconds it does it within 60 seconds 99 of the",
    "start": "1453860",
    "end": "1459740"
  },
  {
    "text": "time rain or shine and it's 100 correct and when people talk about stream processing",
    "start": "1459740",
    "end": "1465380"
  },
  {
    "text": "they typically use it for logging or other non-bus business critical use cases but this is very business critical",
    "start": "1465380",
    "end": "1470960"
  },
  {
    "text": "a merchant wants to know that it was paid it cannot data can never be missing",
    "start": "1470960",
    "end": "1476240"
  },
  {
    "text": "in this pipeline so we're using these components for business critical use case",
    "start": "1476240",
    "end": "1481880"
  },
  {
    "text": "so what are some takeaways I mentioned that we use change data capture and when",
    "start": "1481880",
    "end": "1487280"
  },
  {
    "text": "I gave this talk at Sydney someone came up and asked why don't I use event sourcing and I thought that was a really",
    "start": "1487280",
    "end": "1493400"
  },
  {
    "text": "good question so what are some of the options on the market right what do people look at",
    "start": "1493400",
    "end": "1498740"
  },
  {
    "text": "all right if you use XA transactions how many of you have heard of the cap theorem",
    "start": "1498740",
    "end": "1504679"
  },
  {
    "start": "1499000",
    "end": "1737000"
  },
  {
    "text": "okay good so the cap theorem plays here with an X8 transaction where or also",
    "start": "1504679",
    "end": "1511820"
  },
  {
    "text": "known as a two-phase commit I have to write to multiple targets if one of them is down I can write anywhere so",
    "start": "1511820",
    "end": "1518000"
  },
  {
    "text": "essentially if one of them is down or there's a network partition which is the p and I can't talk to one of the",
    "start": "1518000",
    "end": "1523400"
  },
  {
    "text": "databases involved in the transaction I can write to any of the databases so I've lost availability for P I give up a",
    "start": "1523400",
    "end": "1529940"
  },
  {
    "text": "we can't do that here because when you make a payment to",
    "start": "1529940",
    "end": "1535100"
  },
  {
    "text": "someone it needs to be written somewhere before you can show the end user a confirmation page and nobody's going to",
    "start": "1535100",
    "end": "1540919"
  },
  {
    "text": "say I want to see a 500 on their screen that oh I couldn't pay someone right no one wants to see that",
    "start": "1540919",
    "end": "1546620"
  },
  {
    "text": "the other option is event sourcing so in event sourcing I actually have the app",
    "start": "1546620",
    "end": "1551659"
  },
  {
    "text": "send something to Kafka and I've got a worker pool reading from Kafka and",
    "start": "1551659",
    "end": "1556940"
  },
  {
    "text": "reliably writing the data to two Targets it could take any amount of time right like I said there could be a network",
    "start": "1556940",
    "end": "1562520"
  },
  {
    "text": "partition happening all right the problem here is you give up read your right consistency when",
    "start": "1562520",
    "end": "1567679"
  },
  {
    "text": "people are interacting with a payment service it needs to be fast reliable and always reliable means it always works",
    "start": "1567679",
    "end": "1574580"
  },
  {
    "text": "and does what it says it does and it can be async like this so this also doesn't work for our",
    "start": "1574580",
    "end": "1580340"
  },
  {
    "text": "industry so we go with change data capture what what does change data capture give us",
    "start": "1580340",
    "end": "1585740"
  },
  {
    "text": "you write to one database it's committed and you get an instant confirmation that it was fine",
    "start": "1585740",
    "end": "1591620"
  },
  {
    "text": "if the downstream is broken it'll eventually be fixed when it is fixed the stream that updates it will resume and",
    "start": "1591620",
    "end": "1599000"
  },
  {
    "text": "your activity screen will pop up so we meet all our requirements in this in this fashion",
    "start": "1599000",
    "end": "1605140"
  },
  {
    "text": "uh we talked about Apache Avril why Apache Avro so",
    "start": "1605419",
    "end": "1610820"
  },
  {
    "text": "how many of you have used databases all right so we take databases for",
    "start": "1610820",
    "end": "1617900"
  },
  {
    "text": "granted right it does a lot of stuff for us and we always like complaining about them because they're not the one it's not the coolest stuff but one of the",
    "start": "1617900",
    "end": "1624380"
  },
  {
    "text": "things it does is it gives you a contract between a reader and a writer a reader and writer have the same the",
    "start": "1624380",
    "end": "1632720"
  },
  {
    "text": "contract in this case is the types of the columns the names of the columns their their optionality their",
    "start": "1632720",
    "end": "1638240"
  },
  {
    "text": "cardinality all of that stuff so if I write to a database and you read from it the contract is the schema",
    "start": "1638240",
    "end": "1645260"
  },
  {
    "text": "that's enforced by the central Authority which is called your database so that's the contract that we get but",
    "start": "1645260",
    "end": "1651860"
  },
  {
    "text": "what if I'm sending you a message over Kafka is it possible as the writer that I",
    "start": "1651860",
    "end": "1657860"
  },
  {
    "text": "break that contract and screw you Downstream because I didn't let you know so we need something in this space that",
    "start": "1657860",
    "end": "1664460"
  },
  {
    "text": "maintains those contracts I should not be able to make a change to a column like from an integer to a string all of",
    "start": "1664460",
    "end": "1670100"
  },
  {
    "text": "a sudden and you're expecting an integer you get a string all of a sudden and you break this is where Avro comes in",
    "start": "1670100",
    "end": "1676580"
  },
  {
    "text": "Avro is a schema self-describing data serialization format it was built for things like Hadoop and streams",
    "start": "1676580",
    "end": "1683360"
  },
  {
    "text": "and it in in this case there's no Central Authority it's two clients talking to each other but it imposes",
    "start": "1683360",
    "end": "1689659"
  },
  {
    "text": "some rules and how you can evolve a schema so it supports schema evolution it's got good support in most languages",
    "start": "1689659",
    "end": "1695240"
  },
  {
    "text": "I've used it in node python Ruby Java Scala it's widely accepted as the lingua",
    "start": "1695240",
    "end": "1703159"
  },
  {
    "text": "Franca and all of the Big Data stuff Google in fact for bigquery supports Avro not protobuf as an ingest format",
    "start": "1703159",
    "end": "1710240"
  },
  {
    "text": "and it's used as the general data interchange in in all of these systems so that's why we use Avril",
    "start": "1710240",
    "end": "1716480"
  },
  {
    "text": "so we've talked about a use case that a compelling use case for why we have to build these reliable streams",
    "start": "1716480",
    "end": "1722539"
  },
  {
    "text": "but what about the architecture behind it right we've sort of talked about the data plane but there that's only half of",
    "start": "1722539",
    "end": "1728779"
  },
  {
    "text": "the story we're missing one half so imagine this we have 60 000 tables",
    "start": "1728779",
    "end": "1734419"
  },
  {
    "text": "this is how many tables we have 60 000. and we just can't turn on 60 000 streams",
    "start": "1734419",
    "end": "1740360"
  },
  {
    "start": "1737000",
    "end": "1966000"
  },
  {
    "text": "just like that what if some of the streams are never used it's extremely wasteful also we have 4 500 engineers in the",
    "start": "1740360",
    "end": "1747320"
  },
  {
    "text": "company but my team only has six Engineers so how does this you know team of six",
    "start": "1747320",
    "end": "1752900"
  },
  {
    "text": "um like there's two there's two questions here right we want to support on-demand enablement of a flow we can't",
    "start": "1752900",
    "end": "1758539"
  },
  {
    "text": "have 4 500 Engineers creating jira tickets for Six Engineers to do that right that'll be completely nuts",
    "start": "1758539",
    "end": "1764960"
  },
  {
    "text": "um and once they're running eventually we're running 60 000 how do we automatically manage this this is kind",
    "start": "1764960",
    "end": "1770360"
  },
  {
    "text": "of crazy so we had to build our own control plane so that's the other half of this story",
    "start": "1770360",
    "end": "1776779"
  },
  {
    "text": "so the control plane has kind of two major features first of all like the data plane is",
    "start": "1776779",
    "end": "1783260"
  },
  {
    "text": "built out of Open Source components you see something here that looks like a kraken well that's called Kraken so we",
    "start": "1783260",
    "end": "1789320"
  },
  {
    "text": "open source that it's a node.js framework and also skubes which is an AKA streams based framework that we open",
    "start": "1789320",
    "end": "1795140"
  },
  {
    "text": "source so a user will come here and come to our web portal and enable a",
    "start": "1795140",
    "end": "1801620"
  },
  {
    "text": "pipeline and when that happens they essentially write a request into it",
    "start": "1801620",
    "end": "1807020"
  },
  {
    "text": "into a metadata table and the request says that they want this pipeline enabled and we you know respond to them",
    "start": "1807020",
    "end": "1813559"
  },
  {
    "text": "that we will do this for you when we have a chance we then have an orchestration layer and the orchestration layer layer has to",
    "start": "1813559",
    "end": "1820820"
  },
  {
    "text": "reliably create uh that pipeline",
    "start": "1820820",
    "end": "1826100"
  },
  {
    "text": "and what that involves is basically spinning up Kafka spinning up Storm allocating slots uh and partitions",
    "start": "1826100",
    "end": "1832940"
  },
  {
    "text": "connecting everything together um and then starting the flow and this happens within 60 seconds this is a",
    "start": "1832940",
    "end": "1839240"
  },
  {
    "text": "system that we built and it's a system you can build given these components what are some design principles behind",
    "start": "1839240",
    "end": "1846740"
  },
  {
    "text": "this method so first of all it's built from OSS components all of it running on",
    "start": "1846740",
    "end": "1851779"
  },
  {
    "text": "containers so we have container orchestration to make sure it's ha running over uh six of our availability",
    "start": "1851779",
    "end": "1856940"
  },
  {
    "text": "zones in two data centers separation of concerns is very interesting",
    "start": "1856940",
    "end": "1862460"
  },
  {
    "text": "so the intent capture of the user is separate from the actual orchestration",
    "start": "1862460",
    "end": "1868399"
  },
  {
    "text": "task because the orchestration task has to be reliable but can take a really long amount of time but the intent",
    "start": "1868399",
    "end": "1874820"
  },
  {
    "text": "capture has to be highly available have the fewest dependencies on other systems",
    "start": "1874820",
    "end": "1879880"
  },
  {
    "text": "and just immediately get back to the user that don't worry we'll take care of it and what does the orchestration layer do",
    "start": "1879880",
    "end": "1887120"
  },
  {
    "text": "it does self-healing of the data plane it does Auto scaling of the data plane it does Fault tolerant long-running",
    "start": "1887120",
    "end": "1894200"
  },
  {
    "text": "actions and it's also maintenance aware so when we're actually doing a deployment and",
    "start": "1894200",
    "end": "1899419"
  },
  {
    "text": "I'll get into this a little later when we do a deployment it stops all self-healing because that would",
    "start": "1899419",
    "end": "1904880"
  },
  {
    "text": "interfere with the deployment it stops Auto scaling because that would interfere with the with the deployment so it's got all of the brains inside of",
    "start": "1904880",
    "end": "1911840"
  },
  {
    "text": "it so to build a system what are some",
    "start": "1911840",
    "end": "1917240"
  },
  {
    "text": "requirements they're actually quite easy they're quite simple uh don't lose any data don't corrupt any",
    "start": "1917240",
    "end": "1923240"
  },
  {
    "text": "data and get everything done within one minute whether I'm doing a deployment or",
    "start": "1923240",
    "end": "1929360"
  },
  {
    "text": "any rain or shine whatever's going on it has to even self-healing has to take care of everything within one minute if a system goes down",
    "start": "1929360",
    "end": "1935539"
  },
  {
    "text": "the orchestrator needs to rebalance it or remove the storm task storm job onto another node",
    "start": "1935539",
    "end": "1941240"
  },
  {
    "text": "and always be available this is the data plane the data plane can never go down it has to meet all the requirements of",
    "start": "1941240",
    "end": "1947120"
  },
  {
    "text": "our customers so I don't know if anyone saw this meme this is the Revelation I got when I was",
    "start": "1947120",
    "end": "1953059"
  },
  {
    "text": "building the system scratching my head thinking this is probably not a good good job to have",
    "start": "1953059",
    "end": "1958279"
  },
  {
    "text": "right now all right so this is a bit of an eye chart but the way I look at this is in order to",
    "start": "1958279",
    "end": "1965059"
  },
  {
    "text": "see if I can fulfill this requirement I think about what is standing in my way",
    "start": "1965059",
    "end": "1971419"
  },
  {
    "start": "1966000",
    "end": "2042000"
  },
  {
    "text": "so for example for data loss there are usually two things that cause it one is that you deploy buggy code you",
    "start": "1971419",
    "end": "1979100"
  },
  {
    "text": "just weren't able to test it it didn't show up in your test environment you deploy some code and it's buggy so our",
    "start": "1979100",
    "end": "1984799"
  },
  {
    "text": "test environment for example runs about six flows our production environment runs 300 flows we can run all of those",
    "start": "1984799",
    "end": "1991279"
  },
  {
    "text": "flows in the test environment so we don't get the variability of data so when we deploy we may actually find that",
    "start": "1991279",
    "end": "1998480"
  },
  {
    "text": "there's a data Corner case we didn't handle so we need to handle that oh and then there's data Corner cases what is a",
    "start": "1998480",
    "end": "2004179"
  },
  {
    "text": "data Corner case I deployed deployed code like a month ago but the data that came in changes it's a latent bug I",
    "start": "2004179",
    "end": "2010720"
  },
  {
    "text": "never knew about it and it takes our takes our whole site down what about latency",
    "start": "2010720",
    "end": "2016059"
  },
  {
    "text": "so I Define latency as data is arriving but it is delayed and there's two causes",
    "start": "2016059",
    "end": "2021640"
  },
  {
    "text": "of this either scalability bottlenecks or performance bottlenecks and availability means that no data is",
    "start": "2021640",
    "end": "2028840"
  },
  {
    "text": "arriving and I probably would qualify that in like in the last five minutes no data has arrived and again this could be caused by buggy",
    "start": "2028840",
    "end": "2036039"
  },
  {
    "text": "code or single points of failure in the architecture",
    "start": "2036039",
    "end": "2040620"
  },
  {
    "text": "so let's talk about some of the most interesting ones so when you saw this picture you",
    "start": "2041919",
    "end": "2048339"
  },
  {
    "start": "2042000",
    "end": "2200000"
  },
  {
    "text": "probably thought yourself hydration is a terrible idea right and you'd be right it takes 20 to 40 milliseconds at best",
    "start": "2048339",
    "end": "2056440"
  },
  {
    "text": "to hydrate a query but without it storm was processing a",
    "start": "2056440",
    "end": "2061540"
  },
  {
    "text": "record in 500 microseconds so this hydration was a major scalability issue for us",
    "start": "2061540",
    "end": "2068980"
  },
  {
    "text": "and we just got rid of it and and the basic idea behind this is that we put",
    "start": "2068980",
    "end": "2074200"
  },
  {
    "text": "more load on the on the commit log side right so the commit log which only had",
    "start": "2074200",
    "end": "2079658"
  },
  {
    "text": "say two columns out of ten that were updated we actually forced it to write all of the columns so that puts pressure",
    "start": "2079659",
    "end": "2085300"
  },
  {
    "text": "on our storage subsystem the sand but it's a feature that you can turn on in Golden Gate and we did it it took a year",
    "start": "2085300",
    "end": "2092560"
  },
  {
    "text": "to test it all out but after we did this we get very fast streams",
    "start": "2092560",
    "end": "2099480"
  },
  {
    "text": "all right um how many of you like type safety raise",
    "start": "2100900",
    "end": "2106119"
  },
  {
    "text": "your hand if you think type safety is good that's it why isn't everyone raising their hands you're all the software",
    "start": "2106119",
    "end": "2111940"
  },
  {
    "text": "Engineers right everyone should love type safety so type safety and type conversions",
    "start": "2111940",
    "end": "2117160"
  },
  {
    "text": "actually turns out to be one of the reasons that you have outages in these in these kind of systems",
    "start": "2117160",
    "end": "2123460"
  },
  {
    "text": "um and so when I joined I looked at it and I'm like fire whoever worked on this because everything was a string so this",
    "start": "2123460",
    "end": "2128980"
  },
  {
    "text": "is the most ridiculous thing I've ever seen all your consumers now have to know the scheme of the database they're",
    "start": "2128980",
    "end": "2134260"
  },
  {
    "text": "handling and it's like the worst idea ever and I said I'm going to change this that's my job",
    "start": "2134260",
    "end": "2139420"
  },
  {
    "text": "um and it turns out I couldn't how many of you have heard of the number field in Oracle so Oracle has 23 types this one",
    "start": "2139420",
    "end": "2146320"
  },
  {
    "text": "of them is called a number field raise your hand if you know about the number field okay so number without any",
    "start": "2146320",
    "end": "2152619"
  },
  {
    "text": "other qualifiers like 10 37 you just say number that column can have an integer or can have a floating point with any",
    "start": "2152619",
    "end": "2159579"
  },
  {
    "text": "amount of precision so how do you like map that to your type system in one of your languages",
    "start": "2159579",
    "end": "2165640"
  },
  {
    "text": "you can't um you can put it in average there so I could read a row and it could be an",
    "start": "2165640",
    "end": "2171040"
  },
  {
    "text": "integer and the next row I read could be 27 digits of precision and the one after that could have one digitive position I",
    "start": "2171040",
    "end": "2177339"
  },
  {
    "text": "have no control over it so we had to stick with strings and because of that the upside is we have no auditors",
    "start": "2177339",
    "end": "2183820"
  },
  {
    "text": "um our Downstream consumers have more of a challenge but we have no outages",
    "start": "2183820",
    "end": "2189220"
  },
  {
    "text": "um and also we don't replicate lob fields and we don't do any transformation today",
    "start": "2189220",
    "end": "2194859"
  },
  {
    "text": "but we will in the future and here's the more most interesting",
    "start": "2194859",
    "end": "2200320"
  },
  {
    "start": "2200000",
    "end": "2336000"
  },
  {
    "text": "thing I found so how many of you have worked in stream processing at some point in your careers",
    "start": "2200320",
    "end": "2205900"
  },
  {
    "text": "okay great so like maybe a tenth of you so um one of the challenges this might",
    "start": "2205900",
    "end": "2211240"
  },
  {
    "text": "you know you might feel this pain with me is that um so I'll give you a story so almost every system I work a company",
    "start": "2211240",
    "end": "2217300"
  },
  {
    "text": "I worked at that was running at scale LinkedIn being one we spent all of our time",
    "start": "2217300",
    "end": "2223000"
  },
  {
    "text": "um on one problem and the problem is this we deploy code it's buggy we roll back the code but we've published in",
    "start": "2223000",
    "end": "2230140"
  },
  {
    "text": "that amount of time it took us to detect and roll back the code a huge volume of data that's got garbage in it it was",
    "start": "2230140",
    "end": "2236260"
  },
  {
    "text": "consumed by other teams that generated derived data that had garbage in it and then they",
    "start": "2236260",
    "end": "2242859"
  },
  {
    "text": "generated data that had garbage in it and now we spend all of our time tracking everyone down and rolling it back and it's a complete nightmare so in",
    "start": "2242859",
    "end": "2250839"
  },
  {
    "text": "a system like this which can not have any outage for more than a minute we we have to do something in a more",
    "start": "2250839",
    "end": "2256300"
  },
  {
    "text": "automated fashion so what we do is we first tell our orchestrator hey stop",
    "start": "2256300",
    "end": "2261760"
  },
  {
    "text": "doing anything smart we're going to do a deployment so we set maintenance mode on",
    "start": "2261760",
    "end": "2266800"
  },
  {
    "text": "then we stop storm we back up the Kafka checkpoint we deploy the new code",
    "start": "2266800",
    "end": "2273280"
  },
  {
    "text": "we restart storm and then we check for errors and this is happening in a scripted",
    "start": "2273280",
    "end": "2278980"
  },
  {
    "text": "deployment the script is checking this and if there are any errors detected we immediately stop roll back the code",
    "start": "2278980",
    "end": "2285760"
  },
  {
    "text": "roll back the checkpoint and restart so now our scripted deployment is taking care of all of these replays so that's a",
    "start": "2285760",
    "end": "2294579"
  },
  {
    "text": "requirement and it's weird that I've not seen it outside in Industry um it's very strange because this really",
    "start": "2294579",
    "end": "2300640"
  },
  {
    "text": "solves a huge pain point for us automatic rollback and replay on any error in a stream processing system",
    "start": "2300640",
    "end": "2306599"
  },
  {
    "text": "patent pending um but yeah this is this has been a huge",
    "start": "2306599",
    "end": "2311619"
  },
  {
    "text": "Boon for us and then we turn maintenance mode off and orchestration can resume",
    "start": "2311619",
    "end": "2316720"
  },
  {
    "text": "so we gave this in August we handle 2.2 terabytes uh per day in our streams and",
    "start": "2316720",
    "end": "2324280"
  },
  {
    "text": "so far 300 plus streams have been enabled by end consumers",
    "start": "2324280",
    "end": "2330280"
  },
  {
    "text": "now I'm kind of getting to the end of the talk which is good timing um so what are some closing thoughts",
    "start": "2330280",
    "end": "2335920"
  },
  {
    "text": "here so first of all when building any infrastructure don't be afraid of the complexity complexity that you think",
    "start": "2335920",
    "end": "2342099"
  },
  {
    "start": "2336000",
    "end": "2448000"
  },
  {
    "text": "you're introducing by putting multiple components that do their job really well because that's not complexity complexity",
    "start": "2342099",
    "end": "2349359"
  },
  {
    "text": "is telling one thing to do a myriad of jobs it's not fit for and it's a",
    "start": "2349359",
    "end": "2355119"
  },
  {
    "text": "trade-off you'll never win so go back to your uh companies and say that you know the shiny new ball",
    "start": "2355119",
    "end": "2360880"
  },
  {
    "text": "approach is not that bad an idea let's try it and here's why and then when possible",
    "start": "2360880",
    "end": "2367420"
  },
  {
    "text": "um this is a pretty big thing like favor OSS so as the chief data engineer for PayPal I'm always paying to look at a",
    "start": "2367420",
    "end": "2373960"
  },
  {
    "text": "proprietary product and I always ask is it open source and if it's not it's not good for me right because",
    "start": "2373960",
    "end": "2380220"
  },
  {
    "text": "I don't know how much I can say on stage but maybe later I can um oftentimes some of our vendors take",
    "start": "2380220",
    "end": "2386140"
  },
  {
    "text": "forever to fix a bug and it's not in our hands to do it and they've got the",
    "start": "2386140",
    "end": "2391240"
  },
  {
    "text": "requirements of other customers to deal with so it doesn't fit our business agility needs",
    "start": "2391240",
    "end": "2396760"
  },
  {
    "text": "and then the other thing I would say is in stream processing no Ops right so when I took over the",
    "start": "2396760",
    "end": "2402099"
  },
  {
    "text": "stream processing project we had four outages a day and um the Ops team was not supporting",
    "start": "2402099",
    "end": "2409480"
  },
  {
    "text": "us because there's no way they could have met any SLA with human intervention so",
    "start": "2409480",
    "end": "2414760"
  },
  {
    "text": "the amazing thing is we basically took them out of the loop made everything automated and now they do want to support us and",
    "start": "2414760",
    "end": "2421119"
  },
  {
    "text": "I'm like why what are you going to get out of this um and also",
    "start": "2421119",
    "end": "2426700"
  },
  {
    "text": "um I guess the last thing I would say is everything that we're doing we're putting back into the open source we open source three major projects this",
    "start": "2426700",
    "end": "2431859"
  },
  {
    "text": "year they're in the Big Data space so come check them out um finally I couldn't have done this without a hundred people helping me",
    "start": "2431859",
    "end": "2439599"
  },
  {
    "text": "and that's it thank you",
    "start": "2439599",
    "end": "2446820"
  }
]
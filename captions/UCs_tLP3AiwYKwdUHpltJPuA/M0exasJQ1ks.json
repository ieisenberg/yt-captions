[
  {
    "start": "0",
    "end": "602000"
  },
  {
    "text": "[Applause] uh we are going to be discussing generative artificial intelligence and",
    "start": "11760",
    "end": "18080"
  },
  {
    "text": "large language models uh we are not going to be discussing them in a context",
    "start": "18080",
    "end": "23880"
  },
  {
    "text": "of generating a smooth uh code that runs without any errors and we won't be",
    "start": "23880",
    "end": "29320"
  },
  {
    "text": "discussing the doomsday scenarios of them replacing programmers any other professions taking over the humanity we",
    "start": "29320",
    "end": "35640"
  },
  {
    "text": "will just focus on the basics of trying to understand this topic I hope that's all right with you my name is Daria I",
    "start": "35640",
    "end": "41960"
  },
  {
    "text": "come here from Czech Republic and I've spent last nine years in the field of uh",
    "start": "41960",
    "end": "47039"
  },
  {
    "text": "AI research development and then application uh so I've been in the field for quite a while and long before it has",
    "start": "47039",
    "end": "53960"
  },
  {
    "text": "become a sexy topic and it used to be called statistics at some point in this journey uh now it's basically a over",
    "start": "53960",
    "end": "60160"
  },
  {
    "text": "than news uh and my professional uh path in the field has been somewhat counterintuitive because I started out",
    "start": "60160",
    "end": "67000"
  },
  {
    "text": "as a project manager in an R&D uh privately run lab that was focused on the research of artificial general",
    "start": "67000",
    "end": "73880"
  },
  {
    "text": "intelligence which is like the biggest metat Topic in the field and then has progressed towards uh applying AI models",
    "start": "73880",
    "end": "80560"
  },
  {
    "text": "in the industrial landscape and Industrial Automation in particular uh then having run into the major",
    "start": "80560",
    "end": "86520"
  },
  {
    "text": "bottleneck of the lack of talent specifically on the check Market that led me to becoming uh one of the",
    "start": "86520",
    "end": "93159"
  },
  {
    "text": "founders of a nonprofit school for programmers called 42 prog uh which is requalifying people into eventually full",
    "start": "93159",
    "end": "100360"
  },
  {
    "text": "stack software developers within the course of three years completely for free and this is a part of a Global",
    "start": "100360",
    "end": "105600"
  },
  {
    "text": "Network of schools that's represented here in beautiful Amsterdam by school C kodam uh so the reason I'm telling you",
    "start": "105600",
    "end": "113320"
  },
  {
    "text": "all that is to give you a bit of a background uh but also to show that throughout uh my professional career I",
    "start": "113320",
    "end": "121200"
  },
  {
    "text": "have experienced multiple moments when I was like okay this is huge how do I break it down to little pieces and how",
    "start": "121200",
    "end": "127079"
  },
  {
    "text": "can I do something with it right now so that's what I'm going to try to focus on uh",
    "start": "127079",
    "end": "134160"
  },
  {
    "text": "today here um from um the mainstream media we can get an impression that",
    "start": "136640",
    "end": "143440"
  },
  {
    "text": "something EXT incredibly huge has happened in the field of uh AI R&D over",
    "start": "143440",
    "end": "148959"
  },
  {
    "text": "the last year like there was nothing nothing nothing and then boom we have a lot of generative AI that is all of a",
    "start": "148959",
    "end": "154160"
  },
  {
    "text": "sudden extremely smart and when I try to talk to people uh not only from the software development areas but from",
    "start": "154160",
    "end": "159720"
  },
  {
    "text": "different professional Fields I have sometimes an impression that this is something that they imagine behind the",
    "start": "159720",
    "end": "165920"
  },
  {
    "text": "generative Ai and large language models right that there is a group of people that are creating some sort of",
    "start": "165920",
    "end": "171159"
  },
  {
    "text": "intelligence pre-programming something as a platform then they're feeding it with reliable data and boom profit is",
    "start": "171159",
    "end": "176720"
  },
  {
    "text": "there the magic is working now today we'll try try to disentangle on why this is not exactly the case why there is no",
    "start": "176720",
    "end": "184720"
  },
  {
    "text": "magic behind the creating intelligence in the beginning and how large language models are excellent at processing",
    "start": "184720",
    "end": "190599"
  },
  {
    "text": "language and working with natural language related tasks but are really not suitable for all possible tasks in",
    "start": "190599",
    "end": "197840"
  },
  {
    "text": "the future uh so large language models are",
    "start": "197840",
    "end": "203200"
  },
  {
    "text": "deep learning models that are essentially pre-trained to generate content to produce text to be more specific and with this impressive",
    "start": "203200",
    "end": "210120"
  },
  {
    "text": "ability they have become the backbone of natural language processing uh and uh",
    "start": "210120",
    "end": "216000"
  },
  {
    "text": "that has become quite a massive topic over the last years large language models are also frequently being",
    "start": "216000",
    "end": "222000"
  },
  {
    "text": "referred to as Foundation or foundational models these are the models that utilize deep learning in natural",
    "start": "222000",
    "end": "228360"
  },
  {
    "text": "language processing and natural language generation tasks uh and they do that",
    "start": "228360",
    "end": "233879"
  },
  {
    "text": "because they are pre-trained on a large amount of data using very specific techniques to this field such as",
    "start": "233879",
    "end": "239920"
  },
  {
    "text": "fine-tuning in context learning one short or few shorts learning these models can be adapted for practical for",
    "start": "239920",
    "end": "246879"
  },
  {
    "text": "down uh stream tasks and you can see some of the examples over here they can",
    "start": "246879",
    "end": "252040"
  },
  {
    "text": "be pre-trained and fine-tuned to answer specific questions to do the sentiment analysis of the text to extract some",
    "start": "252040",
    "end": "258040"
  },
  {
    "text": "information to recognize objects Etc uh as to those techniques zero uh means",
    "start": "258040",
    "end": "264759"
  },
  {
    "text": "that a model can learn to recognize things it hasn't been specifically seen during training things it hasn't seen",
    "start": "264759",
    "end": "272280"
  },
  {
    "text": "yeah uh few shots refers to the practice of training model with some input data but with very minimal amount of data and",
    "start": "272280",
    "end": "279360"
  },
  {
    "text": "traditionally what we have seen in the landscape is that uh these large language models have been pre-trained by",
    "start": "279360",
    "end": "285080"
  },
  {
    "text": "either academic institutions or big tech companies such as uh Microsoft Nvidia",
    "start": "285080",
    "end": "290320"
  },
  {
    "text": "open AI being uh a newcomer to that market quite a while ago but still having access to significant amount of",
    "start": "290320",
    "end": "297080"
  },
  {
    "text": "resources at hand and most of those models uh after being pre-trained and prepared are then available for public",
    "start": "297080",
    "end": "303600"
  },
  {
    "text": "use and this Plug and Play approach sort of is an important step towards large",
    "start": "303600",
    "end": "308639"
  },
  {
    "text": "scale AI adoption because instead of spending huge resources on training models with generic linguistic knowledge",
    "start": "308639",
    "end": "315880"
  },
  {
    "text": "uh individuals companies and businesses can focus on basically taking what has been created and fine-tuning it for very",
    "start": "315880",
    "end": "322520"
  },
  {
    "text": "specific use cases uh what's specific about large",
    "start": "322520",
    "end": "328440"
  },
  {
    "text": "language models we are seeing right now all over is that those are essentially Transformer based uh architectures",
    "start": "328440",
    "end": "334759"
  },
  {
    "text": "models the GPT St uh as a shortcut stands for generative pre-trained Transformer and Transformer is a name of",
    "start": "334759",
    "end": "340880"
  },
  {
    "text": "a very specific type of architecture of large language models that has been uh not exactly discovered but brought to",
    "start": "340880",
    "end": "347840"
  },
  {
    "text": "public uh back in 2017 so quite a while ago already definitely before covid uh",
    "start": "347840",
    "end": "353600"
  },
  {
    "text": "and that happened in this paper which was called attention is all you need uh this is a paper that was uh created and",
    "start": "353600",
    "end": "360680"
  },
  {
    "text": "issued by a group of researchers coming from Google and uh they describe a new",
    "start": "360680",
    "end": "366680"
  },
  {
    "text": "approach uh which is characterized by a huge capability of parallelization",
    "start": "366680",
    "end": "372520"
  },
  {
    "text": "meaning these uh models are able to process incredible amounts of data in parallel at the same time and this way",
    "start": "372520",
    "end": "379440"
  },
  {
    "text": "um they are able to sort of generate a prediction of the text that's likely to come next so you can imagine in an",
    "start": "379440",
    "end": "386639"
  },
  {
    "text": "oversimplification you can imagine a large language model based on Transformer architecture as something",
    "start": "386639",
    "end": "392639"
  },
  {
    "text": "that's generating text that is most likely to be the right answer to the question you're putting to the system",
    "start": "392639",
    "end": "399919"
  },
  {
    "text": "then the sophistication and the performance level of accuracy of uh statistical probability of that reply is",
    "start": "399919",
    "end": "406960"
  },
  {
    "text": "something that can be judged by uh how many parameters this model has and the",
    "start": "406960",
    "end": "412000"
  },
  {
    "text": "model parameters is the number of factors basically that it's considering when generating its output that's why",
    "start": "412000",
    "end": "418680"
  },
  {
    "text": "what you have definit ly also seen over the news there is now sort of a fight of creating bigger and bigger and more",
    "start": "418680",
    "end": "424520"
  },
  {
    "text": "powerful large language models competing uh across the number of parameters that",
    "start": "424520",
    "end": "430000"
  },
  {
    "text": "comes out from the hypothesis that was brought up in that paper and that basically everything that open AI was",
    "start": "430000",
    "end": "436319"
  },
  {
    "text": "doing up to the very recent months were trying to prove is that the bigger the better the more parameters you put in",
    "start": "436319",
    "end": "441800"
  },
  {
    "text": "the picture the more factors you consider the more compute power and training data you put in the system the",
    "start": "441800",
    "end": "447759"
  },
  {
    "text": "better it becomes and on a surface level that seems to be right definitely on a consumer and a business level uh it has",
    "start": "447759",
    "end": "454759"
  },
  {
    "text": "shown great progress and we will talk about the specific examples and use cases later on but what I want to",
    "start": "454759",
    "end": "460639"
  },
  {
    "text": "highlight is that we have already seen the proof that just making those models",
    "start": "460639",
    "end": "465759"
  },
  {
    "text": "bigger does not say uh solve all of the problems because uh there are certain problems that were part of the langar",
    "start": "465759",
    "end": "472319"
  },
  {
    "text": "language models when they were smaller when they scaled up and then now even in the super huge GPT 4 about which we",
    "start": "472319",
    "end": "478680"
  },
  {
    "text": "actually funnily enough don't even know how many parameters it does have we still see those problems persisting",
    "start": "478680",
    "end": "485039"
  },
  {
    "text": "there um so large swich models can be",
    "start": "485039",
    "end": "491080"
  },
  {
    "text": "basically pre-trained with three objectives one is auto regression the second one is auto encoding and then",
    "start": "491080",
    "end": "496759"
  },
  {
    "text": "it's sequence to sequence and the cool fun generative tasks that have popularized AI in the last months are",
    "start": "496759",
    "end": "503440"
  },
  {
    "text": "conversation uh question answering yeah content generation those tasks uh where the model needs to generate the new text",
    "start": "503440",
    "end": "510599"
  },
  {
    "text": "the new token and the sentence these are the tasks that are best carried out by autor regressive models which are",
    "start": "510599",
    "end": "516800"
  },
  {
    "text": "currently including everything in the GPT uh family as well as a bunch of other open- source models outter coding",
    "start": "516800",
    "end": "523839"
  },
  {
    "text": "models which are better suited for the tasks like information instruction distillation and some analytical tasks",
    "start": "523839",
    "end": "531120"
  },
  {
    "text": "are now sort of resting in the background uh even though they were the ones to make the initial breakthrough in",
    "start": "531120",
    "end": "537399"
  },
  {
    "text": "2017 and for builders for practitioners this means that the popular Auto regressive models can be used for",
    "start": "537399",
    "end": "543880"
  },
  {
    "text": "everything that's connected uh to content generation and the more content the longer the content the better",
    "start": "543880",
    "end": "549839"
  },
  {
    "text": "however for analytical tasks uh Auto regressive llms uh are not the ones",
    "start": "549839",
    "end": "555279"
  },
  {
    "text": "which will generate the most satisfying result and considering different types of models Auto encoding models or even",
    "start": "555279",
    "end": "560600"
  },
  {
    "text": "more traditional NLP M uh more traditional NLP methods could be helpful",
    "start": "560600",
    "end": "566360"
  },
  {
    "text": "in that case so summing this up to very practical uh output is that auto",
    "start": "566360",
    "end": "571839"
  },
  {
    "text": "regression models are something that you see behind the family of GPT large language models also uh here you can see",
    "start": "571839",
    "end": "579320"
  },
  {
    "text": "a brief overview over the most popular L large language models but this is a very Dynamic list so please take this with a",
    "start": "579320",
    "end": "586279"
  },
  {
    "text": "grain on salt of salt because it might happen that in a month two or three yeah this landscape would be completely",
    "start": "586279",
    "end": "591839"
  },
  {
    "text": "different so uh this is the best of of the knowledge up uh to May of 2023 and",
    "start": "591839",
    "end": "597720"
  },
  {
    "text": "even over the last couple of weeks we have seen some exciting breakthroughs uh now if it seems like",
    "start": "597720",
    "end": "605399"
  },
  {
    "start": "602000",
    "end": "1014000"
  },
  {
    "text": "lar sandwich models are something extremely new or something that was created in uh",
    "start": "605399",
    "end": "611240"
  },
  {
    "text": "2017 I'm sorry if I gave you that impression because that's not fully accurate either large language models in",
    "start": "611240",
    "end": "617800"
  },
  {
    "text": "different shape of form have actually a very long and not so sophisticated but quite a long history uh taking it from a",
    "start": "617800",
    "end": "625200"
  },
  {
    "text": "step back uh you definitely know that artificial intelligence is S as a research field as a subfield of computer",
    "start": "625200",
    "end": "631640"
  },
  {
    "text": "science is has been around since 1950s yeah uh and this is also roughly the",
    "start": "631640",
    "end": "638079"
  },
  {
    "text": "time when the first considerations of how do we approach the tasks of natural",
    "start": "638079",
    "end": "643120"
  },
  {
    "text": "language processing and generation natural language generating natural language those were the first questions",
    "start": "643120",
    "end": "648680"
  },
  {
    "text": "to be addressed because when the researchers and scientists uh working on conceptualizing the field of AI we're",
    "start": "648680",
    "end": "654839"
  },
  {
    "text": "trying to think of like what could be the cool things that humans can do what could be the actual tasks that we can",
    "start": "654839",
    "end": "661600"
  },
  {
    "text": "try to put inside the machine put into the form of zero and ones uh to try to",
    "start": "661600",
    "end": "666639"
  },
  {
    "text": "imitate something that might work like a human they obviously bumped into the idea of uh text and uh conversation",
    "start": "666639",
    "end": "674320"
  },
  {
    "text": "being sort of one of the possible markers of the human intelligence uh that also gave for",
    "start": "674320",
    "end": "679839"
  },
  {
    "text": "example the foundation and the idea of the INF famous touring test right which is about uh trying to find out if a",
    "start": "679839",
    "end": "687560"
  },
  {
    "text": "panel of juries consist of a humans would find out if they are conversing with a real human or with a computer on",
    "start": "687560",
    "end": "694040"
  },
  {
    "text": "the other side uh of the test uh this uh is a very complex and rather",
    "start": "694040",
    "end": "700040"
  },
  {
    "text": "philosophical topic because uh as you have seen many times in your own lives having conversation with somebody who",
    "start": "700040",
    "end": "707160"
  },
  {
    "text": "appears intelligent just through the speaking just through the layer of language does not necessarily mean that",
    "start": "707160",
    "end": "712399"
  },
  {
    "text": "that's the case so language is definitely an important but not the only judging factor in this whole complexity",
    "start": "712399",
    "end": "719760"
  },
  {
    "text": "but so all of that led to the moment of time back in 1967 when a researcher in MIT named Joan",
    "start": "719760",
    "end": "727040"
  },
  {
    "text": "wisen bom has decided to run an experiment and has created the first uh",
    "start": "727040",
    "end": "732839"
  },
  {
    "text": "historical chatbot so to say which was based uh on like a PR PR PR uh father or",
    "start": "732839",
    "end": "740639"
  },
  {
    "text": "mother or something of the large language models that we see nowadays it was called Eliza and the name was",
    "start": "740639",
    "end": "747199"
  },
  {
    "text": "referring to pigmalion story right uh and uh also to the story of Eliza DL that we see depicted in My Fair",
    "start": "747199",
    "end": "754279"
  },
  {
    "text": "Lady which was about trying to uh train a model yeah or something to converse",
    "start": "754279",
    "end": "760240"
  },
  {
    "text": "smoothly in a human language uh the purpose of this experiment was to see",
    "start": "760240",
    "end": "766839"
  },
  {
    "text": "how uh how humans are going to be interacting with such interfaces and what wisen bound did was essentially",
    "start": "766839",
    "end": "773600"
  },
  {
    "text": "very simple if we look at it from our modern perspective yeah he created a very simple conversation interface which",
    "start": "773600",
    "end": "780199"
  },
  {
    "text": "would uh have just a very limited amount of operations available and it would",
    "start": "780199",
    "end": "785279"
  },
  {
    "text": "take you would put your input there as in uh hi I'm Dar I'm having a bad day",
    "start": "785279",
    "end": "790320"
  },
  {
    "text": "and you will receive a variation of replies which would basically rephrase your stuff and add a couple of words on",
    "start": "790320",
    "end": "796560"
  },
  {
    "text": "top of that the goal was to imitate the notion of a therapist conversing to their patient so I would say I'm Dar I'm",
    "start": "796560",
    "end": "803600"
  },
  {
    "text": "having a bad day and the answer would be Dar I'm sad that you're having a bad day or why are you having a that day yeah uh",
    "start": "803600",
    "end": "810399"
  },
  {
    "text": "and the whole conversational uh logic was built within those terms uh what",
    "start": "810399",
    "end": "816839"
  },
  {
    "text": "wisen Bal didn't expect was that this moment gave birth uh to uh a lot of",
    "start": "816839",
    "end": "823079"
  },
  {
    "text": "sociological research afterwards because now even there is something that's being referred to as Eliza effect because he",
    "start": "823079",
    "end": "828839"
  },
  {
    "text": "could see a lot of people coming from all over MIT trying to converse to Eliza about their personal issues they did a",
    "start": "828839",
    "end": "835360"
  },
  {
    "text": "press release as the tech universities tend to do when something seems interesting for the general public and they started receiving letters from all",
    "start": "835360",
    "end": "841839"
  },
  {
    "text": "over the US where people would be sharing their own personal stuff with Eliza asking for an advice and uh",
    "start": "841839",
    "end": "849639"
  },
  {
    "text": "initially wison bom was hoping to prove uh that you know these are just silly models we are far far away from actually",
    "start": "849639",
    "end": "856800"
  },
  {
    "text": "having something useful but in the end of this experiment he actually retired from MIT didn't return to the field and",
    "start": "856800",
    "end": "863040"
  },
  {
    "text": "said yeah well people will tend to think that something is much more intelligent than it actually is uh if it's able to",
    "start": "863040",
    "end": "869720"
  },
  {
    "text": "converse the ways human does uh so in this case Eliza was a simple program",
    "start": "869720",
    "end": "876360"
  },
  {
    "text": "that was using pattern recognition to simulate human uh conversation and uh",
    "start": "876360",
    "end": "882959"
  },
  {
    "text": "despite it being far from perfect it's being taken as a historical Milestone of the first point of research into the",
    "start": "882959",
    "end": "888959"
  },
  {
    "text": "natural language processing and develop development of the more sophisticated large language models and then over the",
    "start": "888959",
    "end": "895680"
  },
  {
    "text": "years several significant Innovations have propelled in the field and one of the such Innovations was the",
    "start": "895680",
    "end": "901040"
  },
  {
    "text": "introduction of long shortterm memory or lstm networks in 1997 which allowed for",
    "start": "901040",
    "end": "907680"
  },
  {
    "text": "the creation of first neural networks which were a little bit more well definitely more sophisticated uh and",
    "start": "907680",
    "end": "913240"
  },
  {
    "text": "capable of having more scientific amount of data being stored in them and providing some context for the textual",
    "start": "913240",
    "end": "919079"
  },
  {
    "text": "conversations and then another pivotal moment came with Stanford Co core NLP suit which was introduced in 2010 and uh",
    "start": "919079",
    "end": "926600"
  },
  {
    "text": "it provided a set of tools and algorithms that enabled the researchers uh working in the other fields to also",
    "start": "926600",
    "end": "932560"
  },
  {
    "text": "tackle complex NLP tasks such as sentiment analysis and uh recognition in",
    "start": "932560",
    "end": "938440"
  },
  {
    "text": "2011 Google uh brain was launched which uh enabled researchers to have access to",
    "start": "938440",
    "end": "944199"
  },
  {
    "text": "powerful Computing resources and to the advanced features such as word embeddings that allowed natural language",
    "start": "944199",
    "end": "950480"
  },
  {
    "text": "processing systems to better understand the context of world of word sorry",
    "start": "950480",
    "end": "956000"
  },
  {
    "text": "because the general development was going in a sense of just recognizing one word is enough you need to understand",
    "start": "956000",
    "end": "962000"
  },
  {
    "text": "the is not enough excuse me you need to understand the context of word a little bit better to generate the result which",
    "start": "962000",
    "end": "968880"
  },
  {
    "text": "was more likely to appear more human so to say and that leads us to the point",
    "start": "968880",
    "end": "973920"
  },
  {
    "text": "where we see that the introduction of the Transformer architecture in 2017 which allowed for incredible amount of",
    "start": "973920",
    "end": "980240"
  },
  {
    "text": "parallel processing was something that allowed the systems to go through a lot of context and try to um try to select",
    "start": "980240",
    "end": "987880"
  },
  {
    "text": "the most appropriate one uh then uh the Transformer architecture enabled the creation of",
    "start": "987880",
    "end": "994319"
  },
  {
    "text": "larger and more sophisticated llms uh open AI have come to the market and joined the race and in",
    "start": "994319",
    "end": "1000680"
  },
  {
    "text": "2023 uh they launched uh or made available to public gpt3 which is sort",
    "start": "1000680",
    "end": "1007560"
  },
  {
    "text": "of I think the starting point of the frenzy that we're seeing now um all over",
    "start": "1007560",
    "end": "1012680"
  },
  {
    "text": "the market after that this year in Spring we saw the release uh of GPT 4",
    "start": "1012680",
    "end": "1019160"
  },
  {
    "start": "1014000",
    "end": "1556000"
  },
  {
    "text": "also coming from open Ai and that has been a turning point for the field and for the large language models for",
    "start": "1019160",
    "end": "1025600"
  },
  {
    "text": "various reasons well yeah first of all this system was had much more parameters uh much better capacities for",
    "start": "1025600",
    "end": "1032798"
  },
  {
    "text": "understanding the context and much better results in generating the output than the previous models also open AI uh",
    "start": "1032799",
    "end": "1041760"
  },
  {
    "text": "up until that point used to be the company that was promoting open sharing of information in this field but with",
    "start": "1041760",
    "end": "1048520"
  },
  {
    "text": "the release of GPT 4 uh they also have released the documentation which had nearly 100 pages but didn't feature any",
    "start": "1048520",
    "end": "1055880"
  },
  {
    "text": "of the technical information as in how many parameters does this system have what is the data that is trained on how",
    "start": "1055880",
    "end": "1062000"
  },
  {
    "text": "much data was needed how much of the computing power was needed to do that and that has put uh both practitioners",
    "start": "1062000",
    "end": "1069240"
  },
  {
    "text": "uh and the researchers in a very difficult situation right where we're looking at something big something interesting but we don't know what's",
    "start": "1069240",
    "end": "1075520"
  },
  {
    "text": "behind it if it's proving the hypothesis or or otherwise another interesting thing with",
    "start": "1075520",
    "end": "1081960"
  },
  {
    "text": "uh GPT 4 was the release of Chad GPT which is sort of a conversational interface which allows you to have",
    "start": "1081960",
    "end": "1089360"
  },
  {
    "text": "interactions with that model directly I'm betting mostly all of you have had your fun trying to interact through chat",
    "start": "1089360",
    "end": "1096320"
  },
  {
    "text": "GPT can I get a brief feel yeah well I would expect it here thank you but so uh",
    "start": "1096320",
    "end": "1103799"
  },
  {
    "text": "this was I like to think of it as a moment in history when some something uh",
    "start": "1103799",
    "end": "1109080"
  },
  {
    "text": "a technology that was previously surrounding us but always hidden under the hood so to say yeah it was uh in our",
    "start": "1109080",
    "end": "1116880"
  },
  {
    "text": "phones it was in our car navigation AI has been everywhere for quite a while but it was always in this black box and",
    "start": "1116880",
    "end": "1123360"
  },
  {
    "text": "we didn't have a chance to interact with it directly and then boom we're looking at the moment when it's becoming a",
    "start": "1123360",
    "end": "1128400"
  },
  {
    "text": "consumer technology so to say far from perfect but getting incredible traction and incredible amount of users uh",
    "start": "1128400",
    "end": "1135240"
  },
  {
    "text": "interacting with it immediately uh and given the context of little context to that release that's",
    "start": "1135240",
    "end": "1142080"
  },
  {
    "text": "putting us as a society in a difficult but interesting situation",
    "start": "1142080",
    "end": "1147960"
  },
  {
    "text": "um in the absence of data on the topic uh it's important to see how can we",
    "start": "1147960",
    "end": "1154039"
  },
  {
    "text": "evaluate that this model is actually smart yeah it's generating text but how good is text uh so one of the",
    "start": "1154039",
    "end": "1160720"
  },
  {
    "text": "interesting moves that uh open AI decided to do in that paper was releasing a set of uh they were testing",
    "start": "1160720",
    "end": "1167039"
  },
  {
    "text": "their model against the academic benchmarks obviously but they also decided to test this uh model against",
    "start": "1167039",
    "end": "1173600"
  },
  {
    "text": "the set of traditional exams the exams that we as humans do in our Universities",
    "start": "1173600",
    "end": "1179200"
  },
  {
    "text": "at schools and they tried uh it on a variety of exams starting from uh lawyer",
    "start": "1179200",
    "end": "1185080"
  },
  {
    "text": "bar exam to the theoretical part of somar exam yeah and the model has",
    "start": "1185080",
    "end": "1190559"
  },
  {
    "text": "reached very impressive results most importantly if you see the the comparison with the previous versions of",
    "start": "1190559",
    "end": "1197360"
  },
  {
    "text": "gpta you can also see that the progress from one to another was very very significant now the mainstream",
    "start": "1197360",
    "end": "1204919"
  },
  {
    "text": "conclusion that one might take out of it is that uh natural language processing models are smarter than humans humans",
    "start": "1204919",
    "end": "1212679"
  },
  {
    "text": "are done these models are very very smart that's really not the case and I'd",
    "start": "1212679",
    "end": "1218039"
  },
  {
    "text": "really like to try to take some time in my talk later on to explain you and why is that but now that you know how it",
    "start": "1218039",
    "end": "1223840"
  },
  {
    "text": "works right that they generate the text that's statistically likely to be true imag yourself uh as a student facing the",
    "start": "1223840",
    "end": "1231400"
  },
  {
    "text": "tasks that you don't know on an exam and trying to uh excuse me but your way around it yeah generate the text",
    "start": "1231400",
    "end": "1238320"
  },
  {
    "text": "that would somehow look reliable have some keywords connected to the topic to get a satisfactory Mark to pass the exam",
    "start": "1238320",
    "end": "1245320"
  },
  {
    "text": "that's how um I like to think about what those models are doing but then also",
    "start": "1245320",
    "end": "1251200"
  },
  {
    "text": "given that they are focused on the uh language tasks the models didn't do well in the technical tasks they are really",
    "start": "1251200",
    "end": "1257760"
  },
  {
    "text": "not good in maths for example because more complex operations require much more memory and it's just not task uh",
    "start": "1257760",
    "end": "1264440"
  },
  {
    "text": "which is suited for getting the most probable answer which looks trustworthy",
    "start": "1264440",
    "end": "1269679"
  },
  {
    "text": "because yeah it might be something else completely so um as to the exam",
    "start": "1269679",
    "end": "1275799"
  },
  {
    "text": "situation um I also want to add that I think this marked the point where we",
    "start": "1275799",
    "end": "1281600"
  },
  {
    "text": "might realize that the system of exams and the system of traditional education we have as humans is also getting",
    "start": "1281600",
    "end": "1287640"
  },
  {
    "text": "slightly outdated right because there are so many interesting ways to learn skills which are going to be more and",
    "start": "1287640",
    "end": "1293440"
  },
  {
    "text": "more important in our lives like critical thinking yeah the ability to uh check sources and make our own",
    "start": "1293440",
    "end": "1299679"
  },
  {
    "text": "conclusions but then if all of that is tested against multiple choice test for which you can optimize a language model",
    "start": "1299679",
    "end": "1306880"
  },
  {
    "text": "and get impressive results then I hope it's sort of a wakeup call uh to try to change the scene a little",
    "start": "1306880",
    "end": "1313480"
  },
  {
    "text": "bit uh when we are talking about large Sage models being traditionally developed by",
    "start": "1313480",
    "end": "1320360"
  },
  {
    "text": "the big players on the market in the beginning remember right uh we're talking about that mostly in connection",
    "start": "1320360",
    "end": "1326039"
  },
  {
    "text": "with the Steep costs of development those costs come from two sides essentially the cost of development",
    "start": "1326039",
    "end": "1331840"
  },
  {
    "text": "themselves are uh quite big uh back in 2020 there's very limited data amount",
    "start": "1331840",
    "end": "1337200"
  },
  {
    "text": "about that available in public of course unfortunately but there's a 2020 study from AI 21 Labs which packed the",
    "start": "1337200",
    "end": "1343559"
  },
  {
    "text": "expenses for developing a TX generating model with 1.5 billion parameters at as",
    "start": "1343559",
    "end": "1348760"
  },
  {
    "text": "much as $1.6 million and then if you think of the inference the cost of actually running the model it's also",
    "start": "1348760",
    "end": "1355480"
  },
  {
    "text": "another drain and there are estimates of a cost of running gbt 3 on a single AWS",
    "start": "1355480",
    "end": "1361159"
  },
  {
    "text": "instance at a minimum of 87,000 per year which means it is",
    "start": "1361159",
    "end": "1368039"
  },
  {
    "text": "expensive it's still not expensive enough to be prohibitive for larger corporations and that's why now we see a",
    "start": "1368039",
    "end": "1374679"
  },
  {
    "text": "lot of players entering that field Adobe creating uh their generative uh AI",
    "start": "1374679",
    "end": "1380799"
  },
  {
    "text": "systems etc etc but it is quite costly for a new player just to come on the market and do something on their own and",
    "start": "1380799",
    "end": "1388480"
  },
  {
    "text": "also fairly expensive for a company to decide that they want to create their own internal large language model and to",
    "start": "1388480",
    "end": "1394279"
  },
  {
    "text": "develop that at the same time uh what I want you to keep in mind is that the costs are already dropping and are",
    "start": "1394279",
    "end": "1401440"
  },
  {
    "text": "likely to drop significantly because the research and development is going forward and training and inference cost",
    "start": "1401440",
    "end": "1407440"
  },
  {
    "text": "for a mod with comparable performance to gpt3 have fallen almost 80% since gpt3",
    "start": "1407440",
    "end": "1412679"
  },
  {
    "text": "is released two and a half years ago so now I really think that we can expect that Trend to go even further however",
    "start": "1412679",
    "end": "1419760"
  },
  {
    "text": "data uh is being the emerging bottleneck for large language models performance",
    "start": "1419760",
    "end": "1424799"
  },
  {
    "text": "because when you're increasing model parameters when you're making the model bigger um that requires more data uh and",
    "start": "1424799",
    "end": "1433400"
  },
  {
    "text": "uh we can actually get to the point funnily enough when we will be running out of training data because we can",
    "start": "1433400",
    "end": "1439520"
  },
  {
    "text": "assume that GPT 4 uh is already being given access to the massive amount of",
    "start": "1439520",
    "end": "1444760"
  },
  {
    "text": "data and the more important questions coming now when we don't have the transparency about that is are people",
    "start": "1444760",
    "end": "1451120"
  },
  {
    "text": "actually okay with giving access to that data so by running out of data I don't",
    "start": "1451120",
    "end": "1456760"
  },
  {
    "text": "mean running out of data yet generally in the world but running out of data which would be appropriate for training those",
    "start": "1456760",
    "end": "1462360"
  },
  {
    "text": "models uh at the same time what we can see is uh that large l models powered",
    "start": "1462360",
    "end": "1468760"
  },
  {
    "text": "businesses are becoming highly profitable for example one of the examples are notion AI Jasper AI yeah or",
    "start": "1468760",
    "end": "1475640"
  },
  {
    "text": "a lots of other businesses that start to incorporate that in their business model and Jasper which generates copyrighting",
    "start": "1475640",
    "end": "1481679"
  },
  {
    "text": "with large language models uh has they uh software as a service type of gross",
    "start": "1481679",
    "end": "1487480"
  },
  {
    "text": "margins of 75% plus so this is a very interesting way of monetizing yeah the",
    "start": "1487480",
    "end": "1492760"
  },
  {
    "text": "potential development in that field uh and and of course as something",
    "start": "1492760",
    "end": "1499399"
  },
  {
    "text": "that is being initially brought To Us by uh big companies by corporations there",
    "start": "1499399",
    "end": "1504640"
  },
  {
    "text": "is an alternative movement in the field and there is a lot of open source resource uh open source attempts and",
    "start": "1504640",
    "end": "1511159"
  },
  {
    "text": "efforts and research and development going on to try to make large language models available uh to public in an open",
    "start": "1511159",
    "end": "1516960"
  },
  {
    "text": "source format and in shortterm commercial companies with large budgets and access to a lot of computing power",
    "start": "1516960",
    "end": "1523840"
  },
  {
    "text": "have been ahead in the AI race however in the long term even big companies like Google and open AI are concerned with",
    "start": "1523840",
    "end": "1529600"
  },
  {
    "text": "the potential of uh open source AI both of those communities have been making",
    "start": "1529600",
    "end": "1534840"
  },
  {
    "text": "progress somewhat independently but now their advancements are starting to merge",
    "start": "1534840",
    "end": "1540120"
  },
  {
    "text": "uh because what open- source Community is logically focused on is being more resource efficient right doing more with",
    "start": "1540120",
    "end": "1547200"
  },
  {
    "text": "less and this is something that can make Ai and specifically large language models more affordable and more",
    "start": "1547200",
    "end": "1554000"
  },
  {
    "text": "environmentally sustainable because this is one more graph that I want to to show you just for the content",
    "start": "1554000",
    "end": "1560720"
  },
  {
    "start": "1556000",
    "end": "1916000"
  },
  {
    "text": "um this is the heaviest carbon emitter by far gpt3 and even the relatively more",
    "start": "1560720",
    "end": "1567559"
  },
  {
    "text": "efficient Bloom model took the amount of power to train which is enough to power the average American home for 41 years",
    "start": "1567559",
    "end": "1573679"
  },
  {
    "text": "yeah so this is an additional cost behind the inference and the development which is now bringing the toll to the",
    "start": "1573679",
    "end": "1580720"
  },
  {
    "text": "society so uh fingers crossed and big fan of the open- source Community trying",
    "start": "1580720",
    "end": "1586320"
  },
  {
    "text": "now to drive the development of those models into a more sustainable Direction by all means and currently there are",
    "start": "1586320",
    "end": "1593039"
  },
  {
    "text": "roughly well many but uh I estimate roughly three ways to make AI more efficient the first one is using less",
    "start": "1593039",
    "end": "1600000"
  },
  {
    "text": "compute power and memory and there are new algorithms like flesh attention that help reduce the amount of computing and",
    "start": "1600000",
    "end": "1605799"
  },
  {
    "text": "memory needed which make it faster and more memory efficient then it's using fewer parameters and instead of",
    "start": "1605799",
    "end": "1612159"
  },
  {
    "text": "retraining the whole model weights parameter efficient fine-tuning sort of identifies the most important points the",
    "start": "1612159",
    "end": "1618520"
  },
  {
    "text": "most important ways reducing resource usage while maintaining performance and finally by using less training data by",
    "start": "1618520",
    "end": "1625600"
  },
  {
    "text": "providing more specific data more specific instructions during training AI models can learn faster and require less",
    "start": "1625600",
    "end": "1632279"
  },
  {
    "text": "data this approach is called instruction fine-tuning and this has been quite successful in narrowing down the",
    "start": "1632279",
    "end": "1638919"
  },
  {
    "text": "training space but on the other hand commercial AI offerings are currently more dominant in terms of the output",
    "start": "1638919",
    "end": "1645559"
  },
  {
    "text": "quality because they have larger models they have more data and longer training times but uh concerns here as I briefly",
    "start": "1645559",
    "end": "1651600"
  },
  {
    "text": "mentioned are of course governments and regulations because uh powerful AI models that are being developed by",
    "start": "1651600",
    "end": "1657120"
  },
  {
    "text": "commercial companies might serve their own objectives and we might uh not be able to know that one interesting aspect",
    "start": "1657120",
    "end": "1664960"
  },
  {
    "text": "of AI development on such scale is the phenomenon of emergence where the um",
    "start": "1664960",
    "end": "1671559"
  },
  {
    "text": "quantitative changes lead to qualitative changes in the behavior and AI models",
    "start": "1671559",
    "end": "1676679"
  },
  {
    "text": "can inquire can acquire unexpected capabilities during the training that were not part of the original scope and",
    "start": "1676679",
    "end": "1683399"
  },
  {
    "text": "that has happened uh quite a few times that is not uh something metaphysical or",
    "start": "1683399",
    "end": "1689039"
  },
  {
    "text": "the emergence of its own mind in a sense it's rather uh the byproduct of using",
    "start": "1689039",
    "end": "1694480"
  },
  {
    "text": "neural networks at the core of the game because the whole mechanism is essentially blackbox and that can also",
    "start": "1694480",
    "end": "1699880"
  },
  {
    "text": "lead to some interesting results uh which is one of the reasons why we can",
    "start": "1699880",
    "end": "1704919"
  },
  {
    "text": "uh we cannot certainly say that just increasing the amount of parameters and compute is going to lead to the progress",
    "start": "1704919",
    "end": "1711960"
  },
  {
    "text": "like that um yeah so in this way it's often",
    "start": "1711960",
    "end": "1717880"
  },
  {
    "text": "recommended to start with commercial AI models to quickly validate the business model of the case you're working on of a",
    "start": "1717880",
    "end": "1724080"
  },
  {
    "text": "product and then perhaps transition to open source models to find a way to leverage that however this transition",
    "start": "1724080",
    "end": "1730440"
  },
  {
    "text": "can be challenging because different AI models excel in different tasks and there is a risk that open source models",
    "start": "1730440",
    "end": "1736519"
  },
  {
    "text": "might not that mean the requirements that were originally set based on the use of the commercial big model uh but",
    "start": "1736519",
    "end": "1743919"
  },
  {
    "text": "uh narrowing it down to a practical advice uh it definitely makes sense to try out and play with the models come",
    "start": "1743919",
    "end": "1749919"
  },
  {
    "text": "coming from the big players before investing your time and resources into going into this a little further this",
    "start": "1749919",
    "end": "1756640"
  },
  {
    "text": "we've seen already um another thing that we are seeing with the emergence of these uh",
    "start": "1756640",
    "end": "1763840"
  },
  {
    "text": "large language models are the implications for the Builder of apps of businesses of software uh because there",
    "start": "1763840",
    "end": "1771640"
  },
  {
    "text": "is uh now there is an possibility to communicate with large language models with the GPT in particular via apis VIA",
    "start": "1771640",
    "end": "1779360"
  },
  {
    "text": "different Frameworks fora different agents and on one hand that boosts the potential of large language models with",
    "start": "1779360",
    "end": "1785000"
  },
  {
    "text": "inter with external data but also with agency with the ability to actually do",
    "start": "1785000",
    "end": "1790440"
  },
  {
    "text": "stuff and perform stuff because large language models by themselves they are a tool they have no agency or the ability",
    "start": "1790440",
    "end": "1797080"
  },
  {
    "text": "at to be connected on the Internet or performing some sort of task but by merging uh and plugging in so to say llm",
    "start": "1797080",
    "end": "1804799"
  },
  {
    "text": "into something else that you're building this can get very interesting yeah um",
    "start": "1804799",
    "end": "1811799"
  },
  {
    "text": "but the rise of this Frameworks also has the implications for the llm layer by itself because it's now hidden under",
    "start": "1811799",
    "end": "1819480"
  },
  {
    "text": "This Hood yeah it's hidden behind an additional abstraction and any abstraction requires very high awareness",
    "start": "1819480",
    "end": "1825200"
  },
  {
    "text": "and discipline in order to be leveraged a sustainable way and When developing applications for the production I mean I",
    "start": "1825200",
    "end": "1831840"
  },
  {
    "text": "don't have to be the one to tell that to you because I'm sure that has been a topic over the last days yeah but it's",
    "start": "1831840",
    "end": "1837559"
  },
  {
    "text": "important to follow structured process where you evaluate things in this case where you select a specific large",
    "start": "1837559",
    "end": "1843720"
  },
  {
    "text": "language model which is most suitable for the task at hand and many companies even now many startups calling",
    "start": "1843720",
    "end": "1850240"
  },
  {
    "text": "themselves AI startups already now skipping this step just assuming that what open AI has to offer in the GPT",
    "start": "1850240",
    "end": "1856440"
  },
  {
    "text": "framework is the best thing available on the market which may not always be true secondly When selecting an llm it's",
    "start": "1856440",
    "end": "1864000"
  },
  {
    "text": "important to consider the desired behavior of the application and if the desired behavior is complex and flexible",
    "start": "1864000",
    "end": "1870440"
  },
  {
    "text": "then the chosen large language model should be capable of Performing well having the high degree of accuracy and",
    "start": "1870440",
    "end": "1876440"
  },
  {
    "text": "making the right decision from a a wide range of options right and uh lastly",
    "start": "1876440",
    "end": "1883679"
  },
  {
    "text": "once the application is in development it's crucial to have ml machine learning operations pipeline in place which will",
    "start": "1883679",
    "end": "1890679"
  },
  {
    "text": "ensure that the large language model when put into action does not deviate too much from changing data",
    "start": "1890679",
    "end": "1897120"
  },
  {
    "text": "distributions and user preferences over time because we are talking about the architecture that is learning things",
    "start": "1897120",
    "end": "1903399"
  },
  {
    "text": "that is learning from data and it's important to set process in place to avoid that to ensure a robust and",
    "start": "1903399",
    "end": "1909840"
  },
  {
    "text": "continuously optimized operation that wouldn't uh allow for issues such as model",
    "start": "1909840",
    "end": "1915919"
  },
  {
    "text": "shift on on top of issues such as model shift if you have ever built an AI",
    "start": "1915919",
    "end": "1921440"
  },
  {
    "start": "1916000",
    "end": "2030000"
  },
  {
    "text": "product you will know that a end users are often very sensible to AI failures",
    "start": "1921440",
    "end": "1927200"
  },
  {
    "text": "and users are prone to something as a negativity bias even if your system achieves a high overall accuracy which",
    "start": "1927200",
    "end": "1932880"
  },
  {
    "text": "is a case for large language models now then the occasional but unavoidable errors will be scrutinized with sort of",
    "start": "1932880",
    "end": "1939320"
  },
  {
    "text": "a magnifying glass with large language models the situation is different they",
    "start": "1939320",
    "end": "1944679"
  },
  {
    "text": "do fail like any other AI system but what's special about them is that they fail in a silent way the large",
    "start": "1944679",
    "end": "1951799"
  },
  {
    "text": "language model is not going to tell you the output that I generated might be right but is not necessarily right it",
    "start": "1951799",
    "end": "1958840"
  },
  {
    "text": "will just keep generating the output which looks uh like it's true but it will be your responsibility as a user to",
    "start": "1958840",
    "end": "1966240"
  },
  {
    "text": "actually check for the sources and see how reliable the output is the linguistic experiment by Noam Chomsky",
    "start": "1966240",
    "end": "1972039"
  },
  {
    "text": "quiet a while ago has already shown an example of a sentence here that's grammatically correct but semantically",
    "start": "1972039",
    "end": "1977840"
  },
  {
    "text": "nonsensical and this is what we can see now when we're trying to run llms against the specific technical tasks",
    "start": "1977840",
    "end": "1984440"
  },
  {
    "text": "because as we discussed before that's not always yeah the best uh way to use it so fact checking of large language",
    "start": "1984440",
    "end": "1992279"
  },
  {
    "text": "models is a big topic now but it also becomes very difficult once we get into the more specialized domains that are",
    "start": "1992279",
    "end": "1998840"
  },
  {
    "text": "the domains of high expertise which don't allow the margin for error and then there the risk of undetected",
    "start": "1998840",
    "end": "2005120"
  },
  {
    "text": "so-called hallucinations is relatively High especially in the long term um but again this is a little bit",
    "start": "2005120",
    "end": "2012919"
  },
  {
    "text": "more of a philosophical conversation again what I wanted to bring your attention on is that the failures uh",
    "start": "2012919",
    "end": "2018720"
  },
  {
    "text": "from the user side the failures of large language models are silent because it doesn't indicate what's 100% right what",
    "start": "2018720",
    "end": "2025960"
  },
  {
    "text": "isn't um and yeah this way uh what are large language",
    "start": "2025960",
    "end": "2033639"
  },
  {
    "start": "2030000",
    "end": "2130000"
  },
  {
    "text": "models actually good for these are the tasks that are mostly connected with processing text surprise surprise it's",
    "start": "2033639",
    "end": "2040320"
  },
  {
    "text": "summarizing a lot of information uh Into A Brief Review a brief short summary uh",
    "start": "2040320",
    "end": "2046320"
  },
  {
    "text": "of text for example it's simplifying the process of creating content in a particular style it's very good with",
    "start": "2046320",
    "end": "2052560"
  },
  {
    "text": "working with context in terms of style so if you want to have text generated that looks like it came uh from a",
    "start": "2052560",
    "end": "2059440"
  },
  {
    "text": "specific person yeah from a specific marketing department that has a certain tone of voice this is your go-to tool it",
    "start": "2059440",
    "end": "2066040"
  },
  {
    "text": "generally has a lot of potential in automating writing the the manual writing of the content however at the",
    "start": "2066040",
    "end": "2073040"
  },
  {
    "text": "current State ofth art of large language models it works most beautifully as a co- ideation tool yeah because if you go",
    "start": "2073040",
    "end": "2080480"
  },
  {
    "text": "in with a prompt of help me create five different names or five different ideas",
    "start": "2080480",
    "end": "2085520"
  },
  {
    "text": "for something that's where it can bring to you the value but then the fine-tuning this model into a very",
    "start": "2085520",
    "end": "2091158"
  },
  {
    "text": "specific tone of voice that your company uses in its communication is uh really a",
    "start": "2091159",
    "end": "2096480"
  },
  {
    "text": "very traumatic task rather than efficient one uh it can improve the",
    "start": "2096480",
    "end": "2101599"
  },
  {
    "text": "response uh to specific technical queries it can be very useful as a first line of help in the chatting interfaces",
    "start": "2101599",
    "end": "2108119"
  },
  {
    "text": "and the technical support for example and uh in the visual side of things it can be good it it is actually very very",
    "start": "2108119",
    "end": "2115480"
  },
  {
    "text": "good as you have seen in the last uh versions of M journey and stable diffusion it's very good at creating",
    "start": "2115480",
    "end": "2120960"
  },
  {
    "text": "realistic representations of people so the tasks like creating prototypes sketches are also something that's very",
    "start": "2120960",
    "end": "2127839"
  },
  {
    "text": "compatible with large language models uh what it is bad for uh is the",
    "start": "2127839",
    "end": "2134839"
  },
  {
    "start": "2130000",
    "end": "2200000"
  },
  {
    "text": "reliability of the content for the reasons we just spoke about uh it doesn't always identify the source of",
    "start": "2134839",
    "end": "2140520"
  },
  {
    "text": "content uh specifically if we talk about uh chat GPT its data is cut at 2021 so",
    "start": "2140520",
    "end": "2147760"
  },
  {
    "text": "anything that happened after that uh it won't tell you that it doesn't know the answer but it will once again silently",
    "start": "2147760",
    "end": "2154079"
  },
  {
    "text": "generate something that might not be entirely true but but generally tracking down the sources is something that is on",
    "start": "2154079",
    "end": "2160000"
  },
  {
    "text": "your uh side as an user's responsibility side uh maths and calculus are difficult",
    "start": "2160000",
    "end": "2165359"
  },
  {
    "text": "due to the contextual memory notion uh it can be difficult how to to understand",
    "start": "2165359",
    "end": "2170800"
  },
  {
    "text": "how to fine-tune the model for the new circumstances you can basically either try to fine-tune the model itself if you",
    "start": "2170800",
    "end": "2177480"
  },
  {
    "text": "have access like for example for the playground for uh GPT uh but there is a very limited amount of parameters you",
    "start": "2177480",
    "end": "2183960"
  },
  {
    "text": "can change as a user the different approaches which will will look at in a little bit is you can try to use",
    "start": "2183960",
    "end": "2190040"
  },
  {
    "text": "prompting as a tool to do that but uh also this is sort of a new land of trial and error so it can really be very",
    "start": "2190040",
    "end": "2197079"
  },
  {
    "text": "difficult uh and then the issues that we face as a society in terms of bias in",
    "start": "2197079",
    "end": "2202520"
  },
  {
    "start": "2200000",
    "end": "2312000"
  },
  {
    "text": "terms of unbalanced uh approach to things this is obviously projected into the tools we",
    "start": "2202520",
    "end": "2209599"
  },
  {
    "text": "create um things that you need to keep in mind in terms of the safety of L language",
    "start": "2209599",
    "end": "2216480"
  },
  {
    "text": "model models um I feel like I'm doing a bad sort of advertising here but not",
    "start": "2216480",
    "end": "2221760"
  },
  {
    "text": "only those were the things for which it's bad for there's also a number of things that you need to keep in mind and",
    "start": "2221760",
    "end": "2226880"
  },
  {
    "text": "that's obviously sensitive personal and corporate data you might have seen in use the cases uh of lawsuits with",
    "start": "2226880",
    "end": "2233359"
  },
  {
    "text": "Samsung when some of the employees were trying to use uh Chad GPT for the corrections in their code and this way",
    "start": "2233359",
    "end": "2240079"
  },
  {
    "text": "has leaked sensitive information outside of the company um in general uh for as",
    "start": "2240079",
    "end": "2246319"
  },
  {
    "text": "long as we are talking about those models uh being under the hoood and the",
    "start": "2246319",
    "end": "2251480"
  },
  {
    "text": "ownership of the data being in the hands of a conrete concrete company that has created the large language model we have",
    "start": "2251480",
    "end": "2257839"
  },
  {
    "text": "very little cont uh control over what is the data that we put there so sort of a",
    "start": "2257839",
    "end": "2263160"
  },
  {
    "text": "safe approach is the less uh personal and sensitive stuff you put into it the",
    "start": "2263160",
    "end": "2268680"
  },
  {
    "text": "better uh as opposed to the non-api use the open AI API data is currently not",
    "start": "2268680",
    "end": "2274760"
  },
  {
    "text": "used for training purposes and there are also cases where you can opt out of your",
    "start": "2274760",
    "end": "2279800"
  },
  {
    "text": "data being used for those purposes uh but most importantly the legislation is hopefully now catching up with the",
    "start": "2279800",
    "end": "2286079"
  },
  {
    "text": "situation seeing how much uh risks can be created this way so specifically EU",
    "start": "2286079",
    "end": "2291319"
  },
  {
    "text": "is now creating the so-called AI act uh which is the regulation uh a lot",
    "start": "2291319",
    "end": "2296560"
  },
  {
    "text": "concerning those models and identifying the Scopes of risks uh in which uh",
    "start": "2296560",
    "end": "2302880"
  },
  {
    "text": "certain measures have to be put in place and the companies have the burden of proving that they have made this effort",
    "start": "2302880",
    "end": "2309319"
  },
  {
    "text": "to make their models compliant and safe um so the last text Heavy slide and then",
    "start": "2309319",
    "end": "2317800"
  },
  {
    "start": "2312000",
    "end": "2432000"
  },
  {
    "text": "it's going to be a little bit more light I promise is I try to put together a little bit of the general guidelines uh",
    "start": "2317800",
    "end": "2324440"
  },
  {
    "text": "to my best knowledge up to this very date for the selection and deployment of large language models which will sum up",
    "start": "2324440",
    "end": "2330280"
  },
  {
    "text": "things we talked about before uh ideally to align with your Downstream task that you are now trying to solve with the",
    "start": "2330280",
    "end": "2336720"
  },
  {
    "text": "help of AI or generative AI the AI team should create sort of a short list of models that are based on the following",
    "start": "2336720",
    "end": "2343119"
  },
  {
    "text": "criteria uh which are benchmarking results in the academic literature with",
    "start": "2343119",
    "end": "2348920"
  },
  {
    "text": "a focus on your specific task that are exploring the alignment between the objective of the task that you're are",
    "start": "2348920",
    "end": "2354960"
  },
  {
    "text": "trying to solve uh and the type of the model of the large language model that you're looking at and the previous",
    "start": "2354960",
    "end": "2360920"
  },
  {
    "text": "experience uh reported for this model and task combination in general the large language model Trends uh are",
    "start": "2360920",
    "end": "2368520"
  },
  {
    "text": "emerging and some of them go again away yeah they are very shortlived in a sense so when you're using uh language models",
    "start": "2368520",
    "end": "2375400"
  },
  {
    "text": "keep an eye on their life cycle and the overall uh activity in the llm landscape",
    "start": "2375400",
    "end": "2380760"
  },
  {
    "text": "and watch out for the opportunities to step up your game of course uh and then",
    "start": "2380760",
    "end": "2386800"
  },
  {
    "text": "again in the beginning it might be a good idea to experiment with something that's already available um while those models have",
    "start": "2386800",
    "end": "2394839"
  },
  {
    "text": "this amazing humanlike uh ability to produce language their overall cognitive",
    "start": "2394839",
    "end": "2400000"
  },
  {
    "text": "power away uh is uh again not really comparable to anything we think about when we think about humans because their",
    "start": "2400000",
    "end": "2406839"
  },
  {
    "text": "reasoning capabilities are limited to the information that they find on the surface of the language level yeah so if",
    "start": "2406839",
    "end": "2413240"
  },
  {
    "text": "you're building an application that relies on generating upto-date or even original knowledge consider if llm is in",
    "start": "2413240",
    "end": "2420240"
  },
  {
    "text": "general at all the direction you want to pursue or perhaps combining your large language model with the additional",
    "start": "2420240",
    "end": "2426920"
  },
  {
    "text": "multimodal uh or dynamic knowledge",
    "start": "2426920",
    "end": "2432079"
  },
  {
    "start": "2432000",
    "end": "2726000"
  },
  {
    "text": "Source um now to a more practical side of things in terms of playing with those",
    "start": "2432079",
    "end": "2438119"
  },
  {
    "text": "models as a user or trying to prototype yeah uh this is something we can do with",
    "start": "2438119",
    "end": "2444319"
  },
  {
    "text": "the help of so-called prompting or prompt engineering and on the surface natural language interface offered by",
    "start": "2444319",
    "end": "2450920"
  },
  {
    "text": "prompting seems to be like too good to be true right it's an ideal gap between AI experts and lay people because most",
    "start": "2450920",
    "end": "2458480"
  },
  {
    "text": "of us know at least one language and we do use it with communication so we might just do the same and use it for",
    "start": "2458480",
    "end": "2463720"
  },
  {
    "text": "communication with a large language models but uh prompting is a fine craft",
    "start": "2463720",
    "end": "2468800"
  },
  {
    "text": "that we don't fully understand yet and successful prompting that goes beyond the trivia of trying to guess the Right",
    "start": "2468800",
    "end": "2475640"
  },
  {
    "text": "Mix doesn't only require strong linguistic instin uh instincts but also",
    "start": "2475640",
    "end": "2480720"
  },
  {
    "text": "knowledge about how large language models work if you are the type of people who like some home work or try to",
    "start": "2480720",
    "end": "2487240"
  },
  {
    "text": "dig into the topic here are some interesting sources that you can look into the first paper uh outlines the",
    "start": "2487240",
    "end": "2494359"
  },
  {
    "text": "usual pitfalls of people trying to fine-tune the models VI are prompting uh",
    "start": "2494359",
    "end": "2500000"
  },
  {
    "text": "and then in general with the prompts we can see a lot of different approaches to them emerging right we can see a prompts",
    "start": "2500000",
    "end": "2505680"
  },
  {
    "text": "marketplaces where you can just buy uh a prompt that somebody else created for a task for a couple of dollars and then",
    "start": "2505680",
    "end": "2512200"
  },
  {
    "text": "change it for your own purposes uh you can try this this way you can try",
    "start": "2512200",
    "end": "2517720"
  },
  {
    "text": "learning and understanding the way how to craft a prompt but I think we can also expect the user interface of large",
    "start": "2517720",
    "end": "2524920"
  },
  {
    "text": "language models to change a lot in the upcoming years too so it might as well happen that the next edition of GPT",
    "start": "2524920",
    "end": "2531839"
  },
  {
    "text": "would just you know have uh the toos and sidebars instead of the actual text input so investing a lot of your time",
    "start": "2531839",
    "end": "2538160"
  },
  {
    "text": "and energy into getting one of those brand new master degrees in prompt engineering might be not uh the best",
    "start": "2538160",
    "end": "2545880"
  },
  {
    "text": "choice uh there is one resource I specifically like uh not only because it's open",
    "start": "2545880",
    "end": "2551160"
  },
  {
    "text": "source but because it's very Dynamic it's called learn prompting dotorg on the right you can see sort of a thematic",
    "start": "2551160",
    "end": "2557240"
  },
  {
    "text": "interface that's there and this is something that's being continuously built and improved by the community of",
    "start": "2557240",
    "end": "2562559"
  },
  {
    "text": "practitioners it offers a bunch of learning paths where you can start from a very basic introductory level to the",
    "start": "2562559",
    "end": "2568440"
  },
  {
    "text": "more uh Advanced frequence requests you might have like prompt tuning or prompt hacking trying to work around the",
    "start": "2568440",
    "end": "2575119"
  },
  {
    "text": "limitations of the model those smth prompts so definitely look into that for those of you who have no idea what I was",
    "start": "2575119",
    "end": "2582280"
  },
  {
    "text": "talking about when I was talking about prompt here is a quick detour right you usually inter uh interact with the chat",
    "start": "2582280",
    "end": "2590240"
  },
  {
    "text": "interface of a large language model by putting in a prompt a textual query which uh can be a question or request",
    "start": "2590240",
    "end": "2597200"
  },
  {
    "text": "and you get an answer out of it uh however when you are structuring your prompt you can approach it with all",
    "start": "2597200",
    "end": "2603720"
  },
  {
    "text": "the creativity possible one of the approaches that has proven very popular with the older GPT models is role",
    "start": "2603720",
    "end": "2610040"
  },
  {
    "text": "prompting where you uh use essentially roleplay and assign to the language model a role of somebody that you want",
    "start": "2610040",
    "end": "2616920"
  },
  {
    "text": "to interact to and on a very simple level it can be like yeah generating something that looks like Shakespeare",
    "start": "2616920",
    "end": "2623160"
  },
  {
    "text": "but this can be also extremely useful when you are for example preparing uh for an interview and want to assign a",
    "start": "2623160",
    "end": "2629800"
  },
  {
    "text": "role of be a recruiter in a technical company in this specific domain and let's have a conversation uh when when",
    "start": "2629800",
    "end": "2636160"
  },
  {
    "text": "I'm trying to apply for this role give me challenging questions let's have this interaction right you can uh you can use",
    "start": "2636160",
    "end": "2644040"
  },
  {
    "text": "this uh and I've been a witness of a few exciting sort of trial use cases of uh",
    "start": "2644040",
    "end": "2649319"
  },
  {
    "text": "using the publicly available chat GPT interfaces for the onboarding of new employees because when there is a",
    "start": "2649319",
    "end": "2655640"
  },
  {
    "text": "limited amount of knowledge of input data that you know are sort of the answers to the frequently asked",
    "start": "2655640",
    "end": "2661200"
  },
  {
    "text": "questions you can put uh if you're coming from the business side you can put your new salesp person and yet to",
    "start": "2661200",
    "end": "2666480"
  },
  {
    "text": "interact with the model uh and give it a task of playing a role of a challenging customer that wants to challenge your",
    "start": "2666480",
    "end": "2674119"
  },
  {
    "text": "salesperson right uh so this is generally useful for",
    "start": "2674119",
    "end": "2681240"
  },
  {
    "text": "Education um something an approach that's called few shorts prompting similar to few shorts learning that we",
    "start": "2681400",
    "end": "2687559"
  },
  {
    "text": "briefly discussed in the beginning is about giving more examples giving more context for the model output and that's",
    "start": "2687559",
    "end": "2694160"
  },
  {
    "text": "one of the approaches of uh how you can make uh the output a little bit closer",
    "start": "2694160",
    "end": "2699400"
  },
  {
    "text": "to what you actually expect um what else is useful to know is that",
    "start": "2699400",
    "end": "2706240"
  },
  {
    "text": "perhaps you can experiment with the output formats too with the chat GPT interface you can directly request it to",
    "start": "2706240",
    "end": "2711920"
  },
  {
    "text": "give you an output in the form of an Excel table for example soared by a certain",
    "start": "2711920",
    "end": "2717800"
  },
  {
    "text": "parameter uh one more thing that I want to give you the inspiration for today is",
    "start": "2717800",
    "end": "2723839"
  },
  {
    "text": "that if you try to be a bit more creative ative and look into the ways how to enrich your prompts with some",
    "start": "2723839",
    "end": "2730359"
  },
  {
    "start": "2726000",
    "end": "2760000"
  },
  {
    "text": "educational techniques that are not maybe obvious from the first try it's actually a very very fun thing to do the",
    "start": "2730359",
    "end": "2736359"
  },
  {
    "text": "fainman technique which is about uh if you're on you're all on Reddit right you all know explain it like I'm five so",
    "start": "2736359",
    "end": "2742400"
  },
  {
    "text": "this is sort of a thing you can try uh to do with a large language models uh try to get it to explain A New Concept",
    "start": "2742400",
    "end": "2748920"
  },
  {
    "text": "to you in a simple terms uh ask it to generate series of challenging questions uh to analyze how well did did you",
    "start": "2748920",
    "end": "2756319"
  },
  {
    "text": "understand the topic review and simplify and on and on uh additional uh inspiration goes to",
    "start": "2756319",
    "end": "2764040"
  },
  {
    "start": "2760000",
    "end": "2793000"
  },
  {
    "text": "the Peta principle which is also sort of a black box right uh it's a notion that",
    "start": "2764040",
    "end": "2769079"
  },
  {
    "text": "20% of effort is usually accountable for 80% of results but we never know which exactly right so it's actually a fun",
    "start": "2769079",
    "end": "2775680"
  },
  {
    "text": "thing to combine those two black boxes and again back at home in Czech Republic",
    "start": "2775680",
    "end": "2781119"
  },
  {
    "text": "uh I know a very successive uh successful Venture Capital company that's Now using that",
    "start": "2781119",
    "end": "2786520"
  },
  {
    "text": "uh in a form of just prompting with the chat GPT to try to work on analyzing new markets and the potential of new",
    "start": "2786520",
    "end": "2791960"
  },
  {
    "text": "products so give it a go it can be helpful in anything from trying to",
    "start": "2791960",
    "end": "2797559"
  },
  {
    "start": "2793000",
    "end": "2834000"
  },
  {
    "text": "create interesting stories uh to make you learn something better or to generate a bedtime story for your kid I",
    "start": "2797559",
    "end": "2805079"
  },
  {
    "text": "am guilty I have a small daughter and I don't always have energy to generate interesting stories for her but when I",
    "start": "2805079",
    "end": "2811079"
  },
  {
    "text": "want to do that and incorporate some Easter egg as an uh uh the main point of",
    "start": "2811079",
    "end": "2816319"
  },
  {
    "text": "the story being vegetables is good this is also large language models are also you know the thing that you can go to",
    "start": "2816319",
    "end": "2823200"
  },
  {
    "text": "now we're also looking at the integration of the text language models and the visual language models so you",
    "start": "2823200",
    "end": "2828400"
  },
  {
    "text": "can essentially even get you know the illustrations for those stories if you'd",
    "start": "2828400",
    "end": "2834000"
  },
  {
    "start": "2834000",
    "end": "2891000"
  },
  {
    "text": "like uh on a more practical way if you're looking at trying to play with",
    "start": "2834000",
    "end": "2840200"
  },
  {
    "text": "these interfaces for your company uh this is an actual factual scheme of",
    "start": "2840200",
    "end": "2845800"
  },
  {
    "text": "using an integrating GPT interface for a marketing agency that's operating in Czech Republic uh they use uh something",
    "start": "2845800",
    "end": "2853079"
  },
  {
    "text": "called AI assistance there is also a Marketplace of those those are like a little bit pre-trained uh GPT uh based",
    "start": "2853079",
    "end": "2860960"
  },
  {
    "text": "tools which you can use uh to work with the database of leads to process them uh",
    "start": "2860960",
    "end": "2866040"
  },
  {
    "text": "to give them to the marketing manager which will then task the aid driven copywriters to create specific",
    "start": "2866040",
    "end": "2871559"
  },
  {
    "text": "personalized types of text for each leads uh send it back back and then see",
    "start": "2871559",
    "end": "2876880"
  },
  {
    "text": "how they respond how they react yeah so the potential for that is generally huge",
    "start": "2876880",
    "end": "2882000"
  },
  {
    "text": "there is uh a lot of those applications hiding the simple API under the hood and",
    "start": "2882000",
    "end": "2887880"
  },
  {
    "text": "doing interesting things uh three of my favorites that I just wanted to share",
    "start": "2887880",
    "end": "2893359"
  },
  {
    "start": "2891000",
    "end": "3106000"
  },
  {
    "text": "out of the top of the head the Practical use cases where you can start using it right now uh are the applications like",
    "start": "2893359",
    "end": "2899680"
  },
  {
    "text": "oter AI which act as the transcriber of your video calls and video meetings you",
    "start": "2899680",
    "end": "2904760"
  },
  {
    "text": "can just plog them on your Zoom call you get a transcript you can get a summary of uh your call and even connect it with",
    "start": "2904760",
    "end": "2910880"
  },
  {
    "text": "a further automation tool likees up here to actually do stuff that follows up on it uh there is a lot of tools that uh",
    "start": "2910880",
    "end": "2918760"
  },
  {
    "text": "leverage the ability of large language models to uh generate the summaries and",
    "start": "2918760",
    "end": "2924720"
  },
  {
    "text": "the PDF GPT or chat with PDF anything you'd like to use are the tools that enable you to load up a complicated",
    "start": "2924720",
    "end": "2931599"
  },
  {
    "text": "contract and actually chat with it as in uh when does this cont contract expire or like what do they mean by this and",
    "start": "2931599",
    "end": "2938280"
  },
  {
    "text": "this and that so this is a very practical way to use that",
    "start": "2938280",
    "end": "2943359"
  },
  {
    "text": "um yeah so to sort of sum this up I think now uh in the evolution of our",
    "start": "2943359",
    "end": "2950079"
  },
  {
    "text": "productivity we're standing at the point where the first thing we can start doing",
    "start": "2950079",
    "end": "2955559"
  },
  {
    "text": "when when interacting with large language models in our everyday life is using those AI productivity tools still",
    "start": "2955559",
    "end": "2961520"
  },
  {
    "text": "it requires a lot of our internal discipline and skill to out Source things to delegate things because that's",
    "start": "2961520",
    "end": "2967920"
  },
  {
    "text": "what I think we're actually not ready to do to Define that the task of transcribing the meetings and making follow-ups is something that I don't",
    "start": "2967920",
    "end": "2974720"
  },
  {
    "text": "want to do anymore and I'm ready to give it further to the tool right uh if we",
    "start": "2974720",
    "end": "2980240"
  },
  {
    "text": "want to go further and go under this black hood not only to Outsource our tasks but to actually improve ourselves",
    "start": "2980240",
    "end": "2986400"
  },
  {
    "text": "to become more relevant to stay in the context we can use AI tools for learning",
    "start": "2986400",
    "end": "2991520"
  },
  {
    "text": "for explaining different context for having more personalized learning path and we can see for example du lingual",
    "start": "2991520",
    "end": "2997240"
  },
  {
    "text": "okan Academy doing very exciting work with integrating gbt 4 into their learning",
    "start": "2997240",
    "end": "3002760"
  },
  {
    "text": "mechanisms uh further on on this imaginary stairs of self-development I",
    "start": "3002760",
    "end": "3008319"
  },
  {
    "text": "put the AI power self-development tools the uh AI power chatbots that uh allow",
    "start": "3008319",
    "end": "3014599"
  },
  {
    "text": "for uh coaching for the self-improvement that is obviously very personal and delicate to everyone",
    "start": "3014599",
    "end": "3021160"
  },
  {
    "text": "because that requires assuming the notion of accepting um the feedack back from something that is not human this",
    "start": "3021160",
    "end": "3028200"
  },
  {
    "text": "feedback might be objective and objective and might be useful but that again clashes with the notion of trying",
    "start": "3028200",
    "end": "3033920"
  },
  {
    "text": "not to put personal details into the models which we don't exactly know are coming where they are coming from right",
    "start": "3033920",
    "end": "3041359"
  },
  {
    "text": "uh I have a couple of minutes left not really okay I uh we'll just jump to this",
    "start": "3041359",
    "end": "3051160"
  },
  {
    "text": "slide as sort of a conclusion because um what you are seeing think right now is",
    "start": "3051160",
    "end": "3056559"
  },
  {
    "text": "also a lot of discussion about generative AI taking jobs replacing certain professions and I hope after",
    "start": "3056559",
    "end": "3062319"
  },
  {
    "text": "hearing all this you realize that just by the way the systems work this is really not the case but the people who",
    "start": "3062319",
    "end": "3069079"
  },
  {
    "text": "use uh large language models for their productivity are likely to be the ones that are more you know in a better",
    "start": "3069079",
    "end": "3075319"
  },
  {
    "text": "position on the uh labor market as opposed to those who don't uh and increasing the labor productivity in",
    "start": "3075319",
    "end": "3082040"
  },
  {
    "text": "general across the market will require significant investment to support people",
    "start": "3082040",
    "end": "3087200"
  },
  {
    "text": "retraining uh and the willingness of us as a people do that because what is clear now is that all of us are doomed",
    "start": "3087200",
    "end": "3093720"
  },
  {
    "text": "to learn continuously throughout our whole life to be scrolling those news and seeing the new architectures and new",
    "start": "3093720",
    "end": "3099200"
  },
  {
    "text": "models coming up every month or two and learning how to make the best out of",
    "start": "3099200",
    "end": "3104559"
  },
  {
    "text": "them for our advantage thank you very [Applause]",
    "start": "3104559",
    "end": "3114359"
  },
  {
    "start": "3106000",
    "end": "3123000"
  },
  {
    "text": "much",
    "start": "3114359",
    "end": "3117359"
  }
]
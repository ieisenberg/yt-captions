[
  {
    "start": "0",
    "end": "33000"
  },
  {
    "text": "um first of all thanks for coming I know most of you are stuck here because your",
    "start": "10110",
    "end": "16180"
  },
  {
    "text": "flights are tomorrow and the people who could leave took the train home but I'm just joking thank you very much for",
    "start": "16180",
    "end": "21369"
  },
  {
    "text": "coming to this talk resilient predictive data pipelines just to get a show of hands how many of you actually work on",
    "start": "21369",
    "end": "27340"
  },
  {
    "text": "data pipelines ok so like looks like ten percent not bad so a little bit up about",
    "start": "27340",
    "end": "34360"
  },
  {
    "start": "33000",
    "end": "201000"
  },
  {
    "text": "me I work at a small software startup in samma-tee-oh called agari and before",
    "start": "34360",
    "end": "40420"
  },
  {
    "text": "let's say about a year ago I worked at LinkedIn Netflix ebay and etsy and that",
    "start": "40420",
    "end": "46690"
  },
  {
    "text": "those companies i work in roles mostly dealing with scaling and scaling of data i'm also a co-chair for q con san",
    "start": "46690",
    "end": "54070"
  },
  {
    "text": "francisco and in my spare time i am a committer on a new newly incubating",
    "start": "54070",
    "end": "60360"
  },
  {
    "text": "project called air flow apache air flow and i also report to a little three",
    "start": "60360",
    "end": "66009"
  },
  {
    "text": "nature and his mom in that picture below so you might be asking yourself why is a",
    "start": "66009",
    "end": "72280"
  },
  {
    "text": "data pipeline talk in this always availability are always available track so mostly you know always on work has",
    "start": "72280",
    "end": "80470"
  },
  {
    "text": "like traditionally focused on the availability of serving systems and serving systems are like typically",
    "start": "80470",
    "end": "86710"
  },
  {
    "text": "synchronous or semi synchronous by semi synchronous i mean there's some sort of asynchronous aspect to it but it's",
    "start": "86710",
    "end": "93850"
  },
  {
    "text": "usually time-bound they're often transactional and their most often",
    "start": "93850",
    "end": "98950"
  },
  {
    "text": "latency sensitive and why is that these tracks not represented more of the you",
    "start": "98950",
    "end": "105130"
  },
  {
    "text": "know the data pipeline community and it's mostly because you know outages are big news right in 2007 it was a little",
    "start": "105130",
    "end": "113020"
  },
  {
    "text": "bit of a badge of honor I around the time in the bay area for your site to go down because it meant that you had a you",
    "start": "113020",
    "end": "119530"
  },
  {
    "text": "know the thinking was that you had a lot of traffic and your site went down and",
    "start": "119530",
    "end": "124540"
  },
  {
    "text": "you know I think given one of the pitches that AWS made at the time was",
    "start": "124540",
    "end": "129759"
  },
  {
    "text": "you're a startup you can't afford all this infrastructure just for being on",
    "start": "129759",
    "end": "134830"
  },
  {
    "text": "techCrunch's front page for you know two days so use ec2 to scale up and the reality was in 2007-2008 cuz",
    "start": "134830",
    "end": "143170"
  },
  {
    "text": "nine a lot of sites that are stable today we're not so stable back then and they actually thought about their down",
    "start": "143170",
    "end": "150580"
  },
  {
    "text": "page like they redesigned it many times to have the coolest my site is down page and you know the problem with that is",
    "start": "150580",
    "end": "158890"
  },
  {
    "text": "after a while your site being down actually becomes your brand and for the first few years of Twitter people really",
    "start": "158890",
    "end": "165640"
  },
  {
    "text": "recognize the fail whale and how many of you have used etsy raise your hand if you have or heard of it okay so um does",
    "start": "165640",
    "end": "173740"
  },
  {
    "text": "anyone recognize who this is raise your hand if you'd recognize now so he's one of the founders his name is Haim and he",
    "start": "173740",
    "end": "182830"
  },
  {
    "text": "was the like DBA / sysadmin for at C&S he was going on quite a lot around 2007",
    "start": "182830",
    "end": "189430"
  },
  {
    "text": "and then it became like a cultural movement in the community of makers to craft stuff about it being down and it",
    "start": "189430",
    "end": "196390"
  },
  {
    "text": "became like one of the popular categories on etsy now as I mentioned",
    "start": "196390",
    "end": "202480"
  },
  {
    "start": "201000",
    "end": "230000"
  },
  {
    "text": "you know this track is usually about synchronous systems or in a semi synchronous systems but I would say that",
    "start": "202480",
    "end": "209590"
  },
  {
    "text": "it's more important to most of the modern web sites that we start focusing",
    "start": "209590",
    "end": "214870"
  },
  {
    "text": "on data flow systems because data flow systems are arguably more important to most online businesses today and and you",
    "start": "214870",
    "end": "222910"
  },
  {
    "text": "know they have these features that they're asynchronous and they're not really latency sensitive but they are throughput sensitive and and why do i",
    "start": "222910",
    "end": "229660"
  },
  {
    "text": "make the statement right so if you go to your favorite sites right for example netflix on the top left or even spotify",
    "start": "229660",
    "end": "237580"
  },
  {
    "start": "230000",
    "end": "370000"
  },
  {
    "text": "there are data pipelines that are building personalization models to to",
    "start": "237580",
    "end": "243070"
  },
  {
    "text": "predict what you'll like to watch or listen to and keep you engaged with the site and in the case of things like",
    "start": "243070",
    "end": "248890"
  },
  {
    "text": "Pandora or I should not really kind of a most like Netflix that have a subscription model that leads to churn",
    "start": "248890",
    "end": "255270"
  },
  {
    "text": "reduction right because they don't want people leaving leaving the site for",
    "start": "255270",
    "end": "260380"
  },
  {
    "text": "social networking sites like LinkedIn or Facebook you'll often find those people",
    "start": "260380",
    "end": "266530"
  },
  {
    "text": "you may know widget right and it's super important to you to these social",
    "start": "266530",
    "end": "272050"
  },
  {
    "text": "networking sites to continue you to grow the edge of their social network and for example in the case of",
    "start": "272050",
    "end": "278830"
  },
  {
    "text": "of LinkedIn right linkedin makes sixty percent of its money from recruiters",
    "start": "278830",
    "end": "284440"
  },
  {
    "text": "finding you and something like seventy percent of the profiles had nothing",
    "start": "284440",
    "end": "290289"
  },
  {
    "text": "beyond the name right so by adding more of your friends like Lincoln hopes to",
    "start": "290289",
    "end": "296080"
  },
  {
    "text": "shame you a little bit into filling out your profile so that recruiters will find you and and then you know they can",
    "start": "296080",
    "end": "301930"
  },
  {
    "text": "sort of get more you know profit from from that from that side so it's it's very important that you know the network",
    "start": "301930",
    "end": "307870"
  },
  {
    "text": "grows for these sort of companies on the upper right you'll recognize amazon and the people who bought ex bought y and",
    "start": "307870",
    "end": "315340"
  },
  {
    "text": "people bought x and y together and again you know lots of clicks and purchases",
    "start": "315340",
    "end": "320590"
  },
  {
    "text": "happen through that route for amazon and lower down below ebay so seven years ago",
    "start": "320590",
    "end": "327759"
  },
  {
    "text": "i actually built help build the ranking algorithm that's still the default on ebay called best match and what that",
    "start": "327759",
    "end": "334509"
  },
  {
    "text": "essentially does is it will rank results by what's being purchased like right now",
    "start": "334509",
    "end": "341860"
  },
  {
    "text": "or in the last ten minutes in order to prioritize like make make it a higher",
    "start": "341860",
    "end": "348520"
  },
  {
    "text": "probability that what you click on will actually get bought and linked to look I mean II VA will get a larger chunk of",
    "start": "348520",
    "end": "353590"
  },
  {
    "text": "that profit so all of these businesses you know depend on these pipelines and in an e base case it's like a live",
    "start": "353590",
    "end": "359830"
  },
  {
    "text": "pipeline or whatever you're buying watching bidding on that sort of stuff and it's like changing the ranking order",
    "start": "359830",
    "end": "366729"
  },
  {
    "text": "of the results on the fly so I hope I've made the case why you know it's",
    "start": "366729",
    "end": "373240"
  },
  {
    "start": "370000",
    "end": "485000"
  },
  {
    "text": "important to have an always-on data pipeline and in a modern systems today",
    "start": "373240",
    "end": "378729"
  },
  {
    "text": "it's slowly architectures that that provide both provide a serving",
    "start": "378729",
    "end": "384490"
  },
  {
    "text": "architecture that's always on and a data pipeline architecture that's always on and this is sort of a design you could",
    "start": "384490",
    "end": "392800"
  },
  {
    "text": "say for these systems on the left you've got the typical serving like stack or serving architecture you'll have fun and",
    "start": "392800",
    "end": "398889"
  },
  {
    "text": "load balancers followed by web servers followed by a micro services layer then",
    "start": "398889",
    "end": "404050"
  },
  {
    "text": "you'll have some sort of data layer which is essentially databases seek search Eric search engines caching",
    "start": "404050",
    "end": "410150"
  },
  {
    "text": "machines graphs all of that sort of stuff and the one mistake I feel it's",
    "start": "410150",
    "end": "415220"
  },
  {
    "text": "sort of like a stumbling point that every company's what it makes is you know they start hiring couple of data scientists and maybe you've seen this in",
    "start": "415220",
    "end": "421520"
  },
  {
    "text": "your experience and then you know the data scientists start running these expensive scan queries on the oil TB",
    "start": "421520",
    "end": "426860"
  },
  {
    "text": "database and it soon becomes like a problem availability so you know as like",
    "start": "426860",
    "end": "433040"
  },
  {
    "text": "a step forward like LinkedIn maybe seven eight years ago had had decoupled",
    "start": "433040",
    "end": "438139"
  },
  {
    "text": "they're like oltp database from all their analytics and and product like",
    "start": "438139",
    "end": "445100"
  },
  {
    "text": "like data product stuff and essentially there was a data integration layer at that point at that time it was something",
    "start": "445100",
    "end": "451580"
  },
  {
    "text": "called data bus now it's Kafka essentially by separating these two architectures you can you can keep both",
    "start": "451580",
    "end": "458750"
  },
  {
    "text": "of them available and that's sort of the goal of of this of this slide so what",
    "start": "458750",
    "end": "466430"
  },
  {
    "text": "are some of the challenges you know with keeping a data pipeline up I mean you're probably very familiar with keeping a",
    "start": "466430",
    "end": "473510"
  },
  {
    "text": "high availability side up right avoid like single points of failure that sort of stuff but what do you do for data",
    "start": "473510",
    "end": "478910"
  },
  {
    "text": "pipelines so one of the problems is called a blast radius problem so let's",
    "start": "478910",
    "end": "485090"
  },
  {
    "start": "485000",
    "end": "731000"
  },
  {
    "text": "say you have a someone in your jaw in at work who writes some code for a data pipeline job let's call it job one and",
    "start": "485090",
    "end": "491590"
  },
  {
    "text": "job one reads data a and writes data be and say your developer introduces a bug",
    "start": "491590",
    "end": "499390"
  },
  {
    "text": "there's another job called job to that reads that data be and writes out data sea and I think you get the point",
    "start": "499390",
    "end": "505789"
  },
  {
    "text": "there's another job that reads that output and input and writes another output and finally some output makes it",
    "start": "505789",
    "end": "511970"
  },
  {
    "text": "to a serving system because at the end it like LinkedIn widgets have to surface some of that data and that's probably",
    "start": "511970",
    "end": "518810"
  },
  {
    "text": "where you're going to catch the bug and if it's like a recommender system you're probably not going to catch it for a long time I remember walking along the",
    "start": "518810",
    "end": "525710"
  },
  {
    "text": "halls and Netflix a few years ago and ran into one of the VPS he said we found a bug I'm like great it's like it's been",
    "start": "525710",
    "end": "531800"
  },
  {
    "text": "around for two years I said yeah well that's recommender systems there are probably many bugs you don't even know about and essentially you know",
    "start": "531800",
    "end": "541430"
  },
  {
    "text": "the reason this is called a like a blast radius right is that a bug that was created in an upstream job corrupted",
    "start": "541430",
    "end": "548450"
  },
  {
    "text": "data downstream and it affected a huge swath of services and what I show it was",
    "start": "548450",
    "end": "555170"
  },
  {
    "text": "just one path but in reality there are many jobs that depend on the output of the first job and so forth there many",
    "start": "555170",
    "end": "561740"
  },
  {
    "text": "jobs that depend on the output of that that line of jobs so it's actually a whole bunch of jobs in a pyramid that",
    "start": "561740",
    "end": "567740"
  },
  {
    "text": "are essentially affected by corrupt data at at the nucleus so why is this an",
    "start": "567740",
    "end": "573589"
  },
  {
    "text": "acute pain point in in companies like LinkedIn Facebook and such well first of",
    "start": "573589",
    "end": "579920"
  },
  {
    "text": "all you've detected the bug right so you the next step is to go about identifying the cause so first you look in your like",
    "start": "579920",
    "end": "586490"
  },
  {
    "text": "serving database and say okay here's this data is bad what wrote to this data oh this job let me go and look at this",
    "start": "586490",
    "end": "591770"
  },
  {
    "text": "job let me look at its code let me look at its input and out its various inputs and then you get into this situation",
    "start": "591770",
    "end": "597920"
  },
  {
    "text": "which is like awesome if you're my three-year-old boy but it's not so much fun for me right lifting every rock and",
    "start": "597920",
    "end": "606170"
  },
  {
    "text": "looking for the bug and eventually if you still have a job and your sanity you'll come to the point where you",
    "start": "606170",
    "end": "611450"
  },
  {
    "text": "identify with the bug is right yay we found the bug so now what do we need to do we just need to deploy a fix but wait",
    "start": "611450",
    "end": "617810"
  },
  {
    "text": "that's only going to fix data going forward and this bug has been around for weeks so it's probably corrupted a whole",
    "start": "617810",
    "end": "623839"
  },
  {
    "text": "bunch of historical data and I need to find out who to contact so let me contact all the teams that own all of",
    "start": "623839",
    "end": "630770"
  },
  {
    "text": "the jobs that care about this output and then they need to do the same for everyone that uses their output and",
    "start": "630770",
    "end": "638110"
  },
  {
    "text": "basically this is what you get into right you're hurting tasks you're trying to figure out what's affected how do you",
    "start": "638110",
    "end": "644660"
  },
  {
    "text": "let everyone know all of that sort of stuff and they all run on different cadences so it's bit of a pain so",
    "start": "644660",
    "end": "651140"
  },
  {
    "text": "essentially after all of this is done you've rerun all of the jobs all over data is clean and then the next bug",
    "start": "651140",
    "end": "656720"
  },
  {
    "text": "comes right so very quickly in this field you learn that there's a there's a",
    "start": "656720",
    "end": "663140"
  },
  {
    "text": "high cost in people time and morale people get burnout so what can you do",
    "start": "663140",
    "end": "669079"
  },
  {
    "text": "about it right someone will come and say I have a great idea let's let's do more testing right testing is going to solve",
    "start": "669079",
    "end": "674089"
  },
  {
    "text": "this problem testing doesn't always solve this problem actually the in in reality it more often than not doesn't solve this",
    "start": "674089",
    "end": "680810"
  },
  {
    "text": "problem because in data pipelines bugs are either in the logic or if you",
    "start": "680810",
    "end": "686660"
  },
  {
    "text": "haven't changed the code for like a year it could still break because something in the input changed and the data is",
    "start": "686660",
    "end": "692030"
  },
  {
    "text": "typically semi-structured or unstructured and for you to mimic all of the ways it could possibly go bad to",
    "start": "692030",
    "end": "697640"
  },
  {
    "text": "create a test corpus and maintain that test corpus it's a huge investment so a better option is more like detect that",
    "start": "697640",
    "end": "705320"
  },
  {
    "text": "there's a problem and roll back or fix forward like an automation solution so",
    "start": "705320",
    "end": "713270"
  },
  {
    "text": "what you really want is at any stage of your pipeline to be able to detect it there's a problem that helps you",
    "start": "713270",
    "end": "719420"
  },
  {
    "text": "essentially identify what's wrong and then fix it forward or roll it back in an automated fashion another problem",
    "start": "719420",
    "end": "726950"
  },
  {
    "text": "with data pipelines has to do with timeliness so imagine that I have these",
    "start": "726950",
    "end": "732380"
  },
  {
    "start": "731000",
    "end": "1252000"
  },
  {
    "text": "three jobs that I talked about before job one job to job three so the output",
    "start": "732380",
    "end": "737540"
  },
  {
    "text": "of job one is going to be read by job to the output of job tools may be read by",
    "start": "737540",
    "end": "742670"
  },
  {
    "text": "job three and job three is going to push something to a serving system and in my definition here a job is equal to a",
    "start": "742670",
    "end": "747980"
  },
  {
    "text": "workflow and these are directed acyclic graph of tasks now let's say I'm going",
    "start": "747980",
    "end": "754070"
  },
  {
    "text": "to run this on a daily schedule so I run it on Monday I run it on Tuesday I run it on Wednesday and everything that's",
    "start": "754070",
    "end": "759620"
  },
  {
    "text": "fine Thursday let's go to and hey it's Friday it's time to head out to the bars right but something is not looking great",
    "start": "759620",
    "end": "766970"
  },
  {
    "text": "because my first job is taking double the time and then it's the weekend",
    "start": "766970",
    "end": "772520"
  },
  {
    "text": "you're with your family and all of a sudden job one is taking 3x the amount of time and you're getting paged and",
    "start": "772520",
    "end": "778400"
  },
  {
    "text": "what was supposed to be a daily job doesn't complete in the day your auto vessel a and you have to go in on Sunday",
    "start": "778400",
    "end": "784220"
  },
  {
    "text": "and fix it because if you can't finish a day's job in a day you're never going to catch up right so now you have a problem",
    "start": "784220",
    "end": "790460"
  },
  {
    "text": "so the question becomes why do jobs especially the big data space gets lower",
    "start": "790460",
    "end": "796180"
  },
  {
    "text": "right why do they get slower so I'm going to give you in an actual example",
    "start": "796180",
    "end": "801670"
  },
  {
    "text": "so what you're seeing here is time like",
    "start": "801670",
    "end": "806870"
  },
  {
    "text": "performance of as overtime so the x-axis is about two months of data at hourly points the",
    "start": "806870",
    "end": "815209"
  },
  {
    "text": "y-axis is the task duration the time durations expressed here as a fraction",
    "start": "815209",
    "end": "820550"
  },
  {
    "text": "of an hour so we're running an hourly job in this case so essentially what",
    "start": "820550",
    "end": "827120"
  },
  {
    "text": "you're seeing is a large variance of one of our jobs this one in maroon it's actually a spark task and the spark task",
    "start": "827120",
    "end": "833240"
  },
  {
    "text": "it's actually smart job or task in our dag it's it's taking up to a more than half an hour to complete so why does",
    "start": "833240",
    "end": "840800"
  },
  {
    "text": "that happen so it turns out in the first week of January one of our data science folks started computing some new",
    "start": "840800",
    "end": "846949"
  },
  {
    "text": "features and that's perfectly acceptable because that's what he's supposed to do compute some new features for some sort",
    "start": "846949",
    "end": "852439"
  },
  {
    "text": "of prediction model but what's not okay is over the next four weeks it starts",
    "start": "852439",
    "end": "858199"
  },
  {
    "text": "getting progressively slower and it turns out that his model building or",
    "start": "858199",
    "end": "863809"
  },
  {
    "text": "future building code was looking at an increasingly growing window of data",
    "start": "863809",
    "end": "868850"
  },
  {
    "text": "instead of like a sliding window of data and as a result it was doing longer and longer scans and it was just taking",
    "start": "868850",
    "end": "875029"
  },
  {
    "text": "longer to complete so he fixed it and then he made a couple other bug fixes it",
    "start": "875029",
    "end": "881360"
  },
  {
    "text": "took a few weeks but you know we're all in good territory and we got back down to 9 minutes and we all took a deep",
    "start": "881360",
    "end": "887059"
  },
  {
    "text": "breath and like they push new code five days later and we're back to it where we",
    "start": "887059",
    "end": "892670"
  },
  {
    "text": "were before and essentially there's a regression once again and if you've worked in the web space you would have",
    "start": "892670",
    "end": "899059"
  },
  {
    "text": "noticed over the last few years right this tension between ops and and developers right where devs are like",
    "start": "899059",
    "end": "905720"
  },
  {
    "text": "writing code and then also have to maintain it getting burnt out and then there's like this like kind of tension between them well that sort of thing is",
    "start": "905720",
    "end": "912170"
  },
  {
    "text": "playing out in the data space you have data scientists you know these guys from like academia like check out this new",
    "start": "912170",
    "end": "917660"
  },
  {
    "text": "algorithm I'm going to run it and then the data engineers are like why are you doing this to me I'm like so tired out",
    "start": "917660",
    "end": "923059"
  },
  {
    "text": "by now so it's it's actually coming to a",
    "start": "923059",
    "end": "928189"
  },
  {
    "text": "point where people are realizing this and data science and data engineers are forming single teams of call like data",
    "start": "928189",
    "end": "935360"
  },
  {
    "text": "science and engineering where they can work together because the effect of a new algorithm will be a regression and",
    "start": "935360",
    "end": "941000"
  },
  {
    "text": "there's a virtuous cycle that we should all accept essentially that you will compute new features stuff will get slower your",
    "start": "941000",
    "end": "947510"
  },
  {
    "text": "data size will grow stuff will get slower then stop look back and try to like trim it optimize and then continue",
    "start": "947510",
    "end": "954920"
  },
  {
    "text": "and that's essentially the virtuous cycle in in the world of big data today and also latency matters a bit right",
    "start": "954920",
    "end": "961459"
  },
  {
    "text": "because we're a throughput based system but if you can't finish yourself in a day you're in trouble so given these you",
    "start": "961459",
    "end": "969140"
  },
  {
    "text": "know to kind of problems I've talked about one has to do with correctness having a large blast radius if you have",
    "start": "969140",
    "end": "974149"
  },
  {
    "text": "an a bug that affects correctness it's going to affect a lot of jobs downstream and also timeliness right um what sort",
    "start": "974149",
    "end": "981320"
  },
  {
    "text": "of desirable qualities or design criteria can we come up with so we have",
    "start": "981320",
    "end": "987560"
  },
  {
    "text": "for correctness timeliness operability and cost and first cause something I",
    "start": "987560",
    "end": "995060"
  },
  {
    "text": "threw in because I'm gonna start up and we have finite amount of money so correctness is all about like data",
    "start": "995060",
    "end": "1000730"
  },
  {
    "text": "integrity don't lose data don't corrupt it don't duplicate it if you're doing predictive stuff the output distribution",
    "start": "1000730",
    "end": "1007510"
  },
  {
    "text": "shouldn't change too much time unless we talked about operability is about putting in tooling that does fine grain",
    "start": "1007510",
    "end": "1013720"
  },
  {
    "text": "monitoring and alerting we also need something like quick cover ability and",
    "start": "1013720",
    "end": "1019480"
  },
  {
    "text": "for cost we want to build something that's pay-as-you-go we don't want a bunch of standing infrastructure that",
    "start": "1019480",
    "end": "1024579"
  },
  {
    "text": "we're paying for when we're not using it so I'll make one point here how many people have seen this before this sort",
    "start": "1024579",
    "end": "1031329"
  },
  {
    "text": "of raise your hand if you've seen this specific graph or this image yeah um so",
    "start": "1031329",
    "end": "1036699"
  },
  {
    "text": "I actually saw this at a talk and a guy from etsy gave many many years ago it's about MPT r & MTBF so m TT RS mean time",
    "start": "1036699",
    "end": "1045490"
  },
  {
    "text": "to recovery MTBF is as you've heard in this hurt today it's mean time between",
    "start": "1045490",
    "end": "1052300"
  },
  {
    "text": "failures right and you know Rolls Royces are built slightly differently from",
    "start": "1052300",
    "end": "1057760"
  },
  {
    "text": "Jeeps so jeeps are built to be abused right there owners abuse them out of",
    "start": "1057760",
    "end": "1063100"
  },
  {
    "text": "love of course but it's still abuse and they break down a lot right but they're also super easy to fix and they're",
    "start": "1063100",
    "end": "1071590"
  },
  {
    "text": "designed that way they're designed to be used out side of their design boundaries a",
    "start": "1071590",
    "end": "1077260"
  },
  {
    "text": "rolls-royce works great on the country roads and in front of hotel but if you",
    "start": "1077260",
    "end": "1082420"
  },
  {
    "text": "take it up a hill it's going to spend like two months in a shop so the idea is how should you build your website or how",
    "start": "1082420",
    "end": "1089290"
  },
  {
    "text": "should you build a data pipeline should you build it to never feel like have in like a lot of tests to catch every",
    "start": "1089290",
    "end": "1095710"
  },
  {
    "text": "possible problem that can happen or do you just roll with it write a bug happens it's in production you hit a",
    "start": "1095710",
    "end": "1101830"
  },
  {
    "text": "button you roll back immediately you have all the tooling in place to recover quickly and the point I'll make is data",
    "start": "1101830",
    "end": "1109240"
  },
  {
    "text": "pipelines in the past have been treated in the NPPF way and you know coming like",
    "start": "1109240",
    "end": "1114280"
  },
  {
    "text": "I personally came from the high scale web world I actually believe mttr is the way to go and if you go online there's a",
    "start": "1114280",
    "end": "1122020"
  },
  {
    "text": "youtube video of a set of Marines taking a jeep apart and putting it back together and four minutes so it's quite",
    "start": "1122020",
    "end": "1128770"
  },
  {
    "text": "impressive so how can we use some commonly available tools right to meet",
    "start": "1128770",
    "end": "1134650"
  },
  {
    "text": "our design goals what are some things available to us and and available to my company is basically amazon so we we",
    "start": "1134650",
    "end": "1143050"
  },
  {
    "text": "started looking at some of the technologies so just to get a sense of the room how many people here use Amazon Web Services that's excellent how many",
    "start": "1143050",
    "end": "1150670"
  },
  {
    "text": "of you keep your hand up if you use SQS oh cool ok very good so it looks about",
    "start": "1150670",
    "end": "1155800"
  },
  {
    "text": "like half of you actually use amazon so SQS for the others is a low latency",
    "start": "1155800",
    "end": "1161679"
  },
  {
    "text": "highly scalable hi available message queue it's a queue but it's not exactly",
    "start": "1161679",
    "end": "1168880"
  },
  {
    "text": "50 and it's pull based so actually so I",
    "start": "1168880",
    "end": "1175210"
  },
  {
    "text": "think I'm on this side up right so here's an example to teach you sort of how it works so imagine that you have",
    "start": "1175210",
    "end": "1181900"
  },
  {
    "text": "producers and they're producing messages message one through five on this queue and you have some consumers that are",
    "start": "1181900",
    "end": "1187360"
  },
  {
    "text": "waiting to consume these messages so the first thing that happens is a consumer will read a message from SQS and as soon",
    "start": "1187360",
    "end": "1194920"
  },
  {
    "text": "as it does so SQS will make that message invisible and they'll start a timer then",
    "start": "1194920",
    "end": "1201970"
  },
  {
    "text": "the consumer in question will write the message or commit the contents of that message to a database and finally it",
    "start": "1201970",
    "end": "1208900"
  },
  {
    "text": "will the message which will result in deleting the message and canceling the timer and this is how it works in normal",
    "start": "1208900",
    "end": "1215260"
  },
  {
    "text": "operation now imagine the same scenario where a consumer reads this message and",
    "start": "1215260",
    "end": "1220540"
  },
  {
    "text": "it takes a bit of time to write the message to the database during that time",
    "start": "1220540",
    "end": "1225700"
  },
  {
    "text": "period the timer goes off and the message now becomes visible and available for some other consumer to",
    "start": "1225700",
    "end": "1230920"
  },
  {
    "text": "read it and so the consumer the bottom picks it up commits it an accent so this",
    "start": "1230920",
    "end": "1237340"
  },
  {
    "text": "is these are like the semantics of SQS based on this model you can actually",
    "start": "1237340",
    "end": "1242470"
  },
  {
    "text": "implement transactions quite well because as long as you're right to the",
    "start": "1242470",
    "end": "1247900"
  },
  {
    "text": "database or idempotent and one interesting feature of SQS is this thing",
    "start": "1247900",
    "end": "1254710"
  },
  {
    "start": "1252000",
    "end": "1372000"
  },
  {
    "text": "called a dead letter cues that that was mentioned earlier in a dead-letter queue essentially is so imagine I have this",
    "start": "1254710",
    "end": "1261520"
  },
  {
    "text": "message one and there's a problem with it and my code can't parse it so rather than have message one clogging up the",
    "start": "1261520",
    "end": "1268540"
  },
  {
    "text": "queue you can configure SQS to bounce the message into a dead-letter queue",
    "start": "1268540",
    "end": "1274750"
  },
  {
    "text": "after n tries and the benefit of this is that you can maintain high throughput in",
    "start": "1274750",
    "end": "1282880"
  },
  {
    "text": "your queue and you also never lose a message and your code itself doesn't need to handle the transactional writing",
    "start": "1282880",
    "end": "1289150"
  },
  {
    "text": "of this message to another place which could have its own bugs SQS has handles",
    "start": "1289150",
    "end": "1294310"
  },
  {
    "text": "it for you and similarly you can have an alert enabled on that cue so that",
    "start": "1294310",
    "end": "1300250"
  },
  {
    "text": "whenever the dead-letter queue has anything in it you're paged and then you know there's some sort of bug you fix the bug and then you drain the queue and",
    "start": "1300250",
    "end": "1306280"
  },
  {
    "text": "you never lost a message another thing that we use is SNS and again a show of",
    "start": "1306280",
    "end": "1312970"
  },
  {
    "text": "hands who uses SNS here so about 78 people may be kind of great so SNS and",
    "start": "1312970",
    "end": "1318760"
  },
  {
    "text": "how many of you were the CAF guitar anyhow Kafka talked yesterday okay so um this is similar to Kafka except it's",
    "start": "1318760",
    "end": "1326830"
  },
  {
    "text": "push-based it's it's also a topic but it's push-based rather than pull based",
    "start": "1326830",
    "end": "1332640"
  },
  {
    "text": "so the benefits of this are you can when you publish to SNS it will reliably send",
    "start": "1332640",
    "end": "1340600"
  },
  {
    "text": "it to all consumers unlike s yes ask us will only send it to one consumer but the downside is it will",
    "start": "1340600",
    "end": "1346960"
  },
  {
    "text": "make some number of attempts to send it and if it can't the message is lost so is there a way we can leverage this",
    "start": "1346960",
    "end": "1354070"
  },
  {
    "text": "beautiful like transactional multi push feature with what SQS had which is the",
    "start": "1354070",
    "end": "1361059"
  },
  {
    "text": "ability to reliably save and write data and there is am i off by one slide I",
    "start": "1361059",
    "end": "1368940"
  },
  {
    "text": "think I actually I'm off by one slide alright so this is actually the pattern",
    "start": "1368940",
    "end": "1374950"
  },
  {
    "start": "1372000",
    "end": "1502000"
  },
  {
    "text": "that that we have the the idea is basically that you have a topic and the",
    "start": "1374950",
    "end": "1383259"
  },
  {
    "text": "topic in this case is an SNS topic and you have two messages in it message one and message to and you also you can",
    "start": "1383259",
    "end": "1391110"
  },
  {
    "text": "amazon allows you to register two different s q SQ s or multiple SQ s qs",
    "start": "1391110",
    "end": "1396820"
  },
  {
    "text": "as subscribers to a SNS topic so in this case we have two SQ s qs subscribe to",
    "start": "1396820",
    "end": "1402519"
  },
  {
    "text": "the SNS topic and whenever we publish messages do the SNS topic its reliably",
    "start": "1402519",
    "end": "1407919"
  },
  {
    "text": "multi pushed to the SQ s qs then we can",
    "start": "1407919",
    "end": "1412929"
  },
  {
    "text": "have services downstream consumers downstream of each SQ SQ to reliably write the data I mean you read the data",
    "start": "1412929",
    "end": "1419980"
  },
  {
    "text": "and committed to a back-end to drive this home let's say that we wanted all of our data to be written to an elastic",
    "start": "1419980",
    "end": "1426549"
  },
  {
    "text": "search cluster oh and also to our like Cassandra DB we can't really do that in",
    "start": "1426549",
    "end": "1431830"
  },
  {
    "text": "a consumer in a transactional way but one way we can do it is through this model we have producers producing",
    "start": "1431830",
    "end": "1438610"
  },
  {
    "text": "messages to us and s topics they get pushed to each of these two cues we have",
    "start": "1438610",
    "end": "1444009"
  },
  {
    "text": "separate consumer groups the purple group and the green group the purple groups responsible for elasticsearch updates and the the green group is",
    "start": "1444009",
    "end": "1452019"
  },
  {
    "text": "responsible for like a standard dbi print and this model like works really well for us so now let's put these",
    "start": "1452019",
    "end": "1459909"
  },
  {
    "text": "different sort of technologies together to build an actual fault-tolerant pipeline but before I go there I should",
    "start": "1459909",
    "end": "1467740"
  },
  {
    "text": "give you some context about what agari does so first of all we don't steal your passwords we try to prevent others from",
    "start": "1467740",
    "end": "1473889"
  },
  {
    "text": "doing so and we've been operating in the consumer space for about five years so like eighty percent of consumer in boxes",
    "start": "1473889",
    "end": "1482710"
  },
  {
    "text": "at like gmail hotmail yahoo offer g65 are protected by some of the technology",
    "start": "1482710",
    "end": "1489370"
  },
  {
    "text": "that AG re-built you won't even see a fish email in most cases because it'll",
    "start": "1489370",
    "end": "1494559"
  },
  {
    "text": "be filtered out by the inbox provider we are now focusing on like solving this problem for the enterprise space and",
    "start": "1494559",
    "end": "1501039"
  },
  {
    "text": "what that means is we we put these like collector like appliances in each of our",
    "start": "1501039",
    "end": "1507309"
  },
  {
    "start": "1502000",
    "end": "2002000"
  },
  {
    "text": "enterprise customers data centers and every time they receive an e an email they send us the headers for that email",
    "start": "1507309",
    "end": "1515649"
  },
  {
    "text": "what we do is we use a trust model to analyze the email to determine if it's",
    "start": "1515649",
    "end": "1520929"
  },
  {
    "text": "fish or not and now this is not a spam problem it's like we're looking for fish fish it's something more malicious and",
    "start": "1520929",
    "end": "1527580"
  },
  {
    "text": "then we score the email and and then we you know our current product shows it in",
    "start": "1527580",
    "end": "1533320"
  },
  {
    "text": "a web UI our future product will actually be in line and eliminate such",
    "start": "1533320",
    "end": "1538600"
  },
  {
    "text": "email from getting through so let's put this together in an actual framework",
    "start": "1538600",
    "end": "1545340"
  },
  {
    "text": "this is our current batch pipeline later or not we talking about a real time pipeline but this is our current batch",
    "start": "1545340",
    "end": "1551259"
  },
  {
    "text": "pipeline so what we currently have is these collectors in the in the in the in the wild they're sending data to s3",
    "start": "1551259",
    "end": "1560730"
  },
  {
    "text": "every hour or so we create an EMR spark cluster which is an elastic MapReduce",
    "start": "1560730",
    "end": "1567039"
  },
  {
    "text": "par cluster we spin it up we suck in all of that data for the hour we will score",
    "start": "1567039",
    "end": "1572799"
  },
  {
    "text": "it and also generate some statistics write it to a different s3 path that s",
    "start": "1572799",
    "end": "1577870"
  },
  {
    "text": "three paths will trigger off a series of SNS and SQS alerts or events and we'll",
    "start": "1577870",
    "end": "1584950"
  },
  {
    "text": "have what's called an auto scalar which starts off with the size of zero spin up",
    "start": "1584950",
    "end": "1590049"
  },
  {
    "text": "and start rapidly ingesting that data into our database so that the web UI can",
    "start": "1590049",
    "end": "1595840"
  },
  {
    "text": "see it so there are some benefits to this model let's first talk about how we",
    "start": "1595840",
    "end": "1602190"
  },
  {
    "text": "solve the the cost and timeliness problem so",
    "start": "1602190",
    "end": "1608830"
  },
  {
    "text": "what I just mentioned happens during runs but between runs we don't pay a",
    "start": "1608830",
    "end": "1616000"
  },
  {
    "text": "dime I mean what we what we essentially have running between our hourly runs is",
    "start": "1616000",
    "end": "1621010"
  },
  {
    "text": "just an s3 bucket where our customers can continue to send data and we also",
    "start": "1621010",
    "end": "1626799"
  },
  {
    "text": "have a database at Postgres database that's sitting around it has data from",
    "start": "1626799",
    "end": "1632110"
  },
  {
    "text": "the previous runs and a web UI that hits it and we also have a one box that hosts",
    "start": "1632110",
    "end": "1637179"
  },
  {
    "text": "air flow which I'll talk about a bit later so let's say it's the end of the hour and it's time for the next run air",
    "start": "1637179",
    "end": "1643360"
  },
  {
    "text": "flow will spin up EMR and it'll execute that whole thing where everything gets spun up just for that in jest so this is",
    "start": "1643360",
    "end": "1650019"
  },
  {
    "text": "sort of how we tackle the cost problem what about timeliness so I've kind of",
    "start": "1650019",
    "end": "1655840"
  },
  {
    "text": "mentioned auto scaling a little bit so again I'm going to ask the crowd how many people use auto scaling here okay",
    "start": "1655840",
    "end": "1663190"
  },
  {
    "text": "three four okay cool so yeah we use auto scaling an auto scaling is essentially",
    "start": "1663190",
    "end": "1668679"
  },
  {
    "text": "Amazon solution to cluster management given some rules it can scale a cluster",
    "start": "1668679",
    "end": "1674320"
  },
  {
    "text": "in or out a variable size to deal with variable load so it's typically good for feeds i getta feeds it can also be used",
    "start": "1674320",
    "end": "1681730"
  },
  {
    "text": "to just keep a cluster of fixed size up all the time so that's another use for it and as I mentioned we use it for for",
    "start": "1681730",
    "end": "1688840"
  },
  {
    "text": "this case so one of the challenges with using auto scaling is picking the right",
    "start": "1688840",
    "end": "1694330"
  },
  {
    "text": "metric for scaling in and scale and scaling in and out so our first pass at",
    "start": "1694330",
    "end": "1700779"
  },
  {
    "text": "this was to use cpu we thought let's use cpu on the importer box to tell us",
    "start": "1700779",
    "end": "1706529"
  },
  {
    "text": "whether the cluster is overwhelmed and needs to be scaled out or if it's",
    "start": "1706529",
    "end": "1711669"
  },
  {
    "text": "underwhelmed and underused and should be scaled in so that was our first pass at this so I'll explain sort of what's",
    "start": "1711669",
    "end": "1718750"
  },
  {
    "text": "happening here so we have an orange graph and that orange graph is throughput of messages landing in SQ s",
    "start": "1718750",
    "end": "1726820"
  },
  {
    "text": "right these are like published messages per second and because there's nothing in the auto scale group the green curve",
    "start": "1726820",
    "end": "1734889"
  },
  {
    "text": "which is consumption of those messages starts off at zero and slowly starts ramping up",
    "start": "1734889",
    "end": "1741480"
  },
  {
    "text": "blue curve which is like right at the bottom it sort of looks like a little line that's CPU but really think of it",
    "start": "1741480",
    "end": "1748500"
  },
  {
    "text": "as a proxy for the size of the scaling group that's essentially what it is its total cpu so it's a proxy for the size",
    "start": "1748500",
    "end": "1755400"
  },
  {
    "text": "of the the auto scaling group so what's happening is the auto scaling group is",
    "start": "1755400",
    "end": "1762030"
  },
  {
    "text": "growing right it's expanding and as it expands the consumption rate starts",
    "start": "1762030",
    "end": "1767429"
  },
  {
    "text": "increasing and eventually it crosses the production rate of messages because after a spark is done essentially",
    "start": "1767429",
    "end": "1774480"
  },
  {
    "text": "there's at some point there's nothing left to produce and then it catches up and drops down right the green curve",
    "start": "1774480",
    "end": "1780929"
  },
  {
    "text": "drops down so and the curve at the bottom it shows sort of like a little",
    "start": "1780929",
    "end": "1786660"
  },
  {
    "text": "Mesa that that's like the effectiveness of our auto scaling so what we're doing",
    "start": "1786660",
    "end": "1793020"
  },
  {
    "text": "is we're using forty percent CPU average forty percent CPU as the signal for",
    "start": "1793020",
    "end": "1799110"
  },
  {
    "text": "scaling out so we tell aah trees if the CPU on average in the cluster goes above",
    "start": "1799110",
    "end": "1805020"
  },
  {
    "text": "forty percent add more machine to the cluster and when it drops below",
    "start": "1805020",
    "end": "1810299"
  },
  {
    "text": "something like ten percent or five percent then start scaling in because we consider I think five percent noise now",
    "start": "1810299",
    "end": "1817919"
  },
  {
    "text": "this should work right but it doesn't and the reason is sort of shown here so",
    "start": "1817919",
    "end": "1824070"
  },
  {
    "text": "what happens is when you get just a few messages left on the SQ SQ that are now in flight and being processed ninety",
    "start": "1824070",
    "end": "1831090"
  },
  {
    "text": "percent of the machines are doing nothing and their CPU drops to noise levels and then the average drops below",
    "start": "1831090",
    "end": "1837299"
  },
  {
    "text": "the five percent trigger and then all of a sudden it aw sends the ASG scale in",
    "start": "1837299",
    "end": "1843360"
  },
  {
    "text": "events it says start scaling in but it's not smart about which one percent of the",
    "start": "1843360",
    "end": "1849000"
  },
  {
    "text": "machines are currently doing stuff is just killing machines like this and the machines that are actually working on",
    "start": "1849000",
    "end": "1854940"
  },
  {
    "text": "the last five messages never complete essentially there's a you know because they're being scaled in randomly without",
    "start": "1854940",
    "end": "1860940"
  },
  {
    "text": "any knowledge so there are a couple machines that keep trying to get the next message from SQS like okay I'm going to process it and the autoscaler",
    "start": "1860940",
    "end": "1867030"
  },
  {
    "text": "tells it die right so we had to find sort of a better we means to do scaling",
    "start": "1867030",
    "end": "1873950"
  },
  {
    "text": "and the more obvious thing to do was actually to use the queue depth so if you remember from my earlier sort of",
    "start": "1873950",
    "end": "1879260"
  },
  {
    "text": "design the messages can be visible or they can be invisible so we what we do",
    "start": "1879260",
    "end": "1884840"
  },
  {
    "text": "is we use two separate scaling triggers we use a scale-out trigger based on the",
    "start": "1884840",
    "end": "1890299"
  },
  {
    "text": "number of visible messages in a queue and we use a scale in trigger based on",
    "start": "1890299",
    "end": "1895340"
  },
  {
    "text": "the number of invisible messages in the queue so what does this mean in practice so as messages are added to the queue",
    "start": "1895340",
    "end": "1901519"
  },
  {
    "text": "the number of visible messages grows and we just keep growing the cluster like a balloon until there's nothing left in",
    "start": "1901519",
    "end": "1906980"
  },
  {
    "text": "the visible Q message queue and then we're at fixed fixed size and we just",
    "start": "1906980",
    "end": "1912740"
  },
  {
    "text": "start consuming all the messages and at that point the orange curve which is the number of visible messages are all at",
    "start": "1912740",
    "end": "1917809"
  },
  {
    "text": "this point they've all been consumed and then we're waiting to write them to the DB once that goes to zero and there's",
    "start": "1917809",
    "end": "1923480"
  },
  {
    "text": "that means there's no message left to be consumed and we act there's no message",
    "start": "1923480",
    "end": "1929299"
  },
  {
    "text": "left to be act it's safe to scale in we scale the whole cluster in and this",
    "start": "1929299",
    "end": "1934429"
  },
  {
    "text": "works really well for us so with this model we can actually figure out both",
    "start": "1934429",
    "end": "1940669"
  },
  {
    "text": "our timeliness and cost we can actually solve those two design goals I will",
    "start": "1940669",
    "end": "1946010"
  },
  {
    "text": "mention one thing with EMR spark we can actually predict before the run how many",
    "start": "1946010",
    "end": "1952429"
  },
  {
    "text": "spar tree saw resources we need for that next run based on some metrics so we can actually scale it out to so that it",
    "start": "1952429",
    "end": "1958970"
  },
  {
    "text": "doesn't run into bottlenecks but if you want to know more about that you can come and talk to me how about",
    "start": "1958970",
    "end": "1964820"
  },
  {
    "text": "operability and correctness so for operability we were essentially looking for some sort of automation that can",
    "start": "1964820",
    "end": "1972110"
  },
  {
    "text": "manage all of our workflows we wanted something that was easy to manage easy to author like we want to author",
    "start": "1972110",
    "end": "1977990"
  },
  {
    "text": "workflows we wanted to get visual insight that could tell us about the state of our workflows and the",
    "start": "1977990",
    "end": "1984440"
  },
  {
    "text": "performance and the performance and we also wanted something that integrated with all our existing monitoring and",
    "start": "1984440",
    "end": "1989929"
  },
  {
    "text": "alerting so we found Apache were airflow actually back then it was called Airbnb",
    "start": "1989929",
    "end": "1995539"
  },
  {
    "text": "airflow and just very recently it became an Apache project so we started",
    "start": "1995539",
    "end": "2001179"
  },
  {
    "text": "leveraging that and essentially what you get is this is my this is not meant for you to read but this is a sense",
    "start": "2001179",
    "end": "2007049"
  },
  {
    "start": "2002000",
    "end": "2065000"
  },
  {
    "text": "a workflow written in Python and essentially you write your workflows in Python before this at like LinkedIn we",
    "start": "2007049",
    "end": "2015029"
  },
  {
    "text": "use azkaban which was essentially a zip file of a bunch of cause if of a bunch",
    "start": "2015029",
    "end": "2020669"
  },
  {
    "text": "of con files config files and uzi which was used heavily at Yahoo was like a",
    "start": "2020669",
    "end": "2026129"
  },
  {
    "text": "gigantic XML file and those are horrible things to deal with and a few years ago",
    "start": "2026129",
    "end": "2032610"
  },
  {
    "text": "a Spotify came up something called Luigi which is also based on Python but the UI",
    "start": "2032610",
    "end": "2038070"
  },
  {
    "text": "was not very good and is also not very stable so when I saw this a pop up about",
    "start": "2038070",
    "end": "2044580"
  },
  {
    "text": "a year ago I was like very excited and then when your code is parsed it'll actually show you the graph the dag the",
    "start": "2044580",
    "end": "2051720"
  },
  {
    "text": "workflow for it and the the workflow on the left is actually used to manage the the whole pipeline on the right and you",
    "start": "2051720",
    "end": "2059898"
  },
  {
    "text": "can manage multiple DAGs very easily we have something like ten most of them are model building and you can see for any",
    "start": "2059899",
    "end": "2067260"
  },
  {
    "start": "2065000",
    "end": "2090000"
  },
  {
    "text": "given run what the slow parts of it are right you don't need to dig into it it just it shows you and in this case it",
    "start": "2067260",
    "end": "2073648"
  },
  {
    "text": "tells us I run a given run to 20 minutes and the slowest part was the spark job that took like 10 minutes and you can",
    "start": "2073649",
    "end": "2081388"
  },
  {
    "text": "also see as we saw before a historical trending for all of the tasks in a given dag given workflow on the alerting side",
    "start": "2081389",
    "end": "2090720"
  },
  {
    "start": "2090000",
    "end": "2153000"
  },
  {
    "text": "we use like we use a combination of pagerduty and victor ops both solve the",
    "start": "2090720",
    "end": "2095790"
  },
  {
    "text": "same problem if there's an issue on the side it'll page the first on call and try a couple times and then start",
    "start": "2095790",
    "end": "2102270"
  },
  {
    "text": "escalating to follow on on calls it integrates well with air flow so we get",
    "start": "2102270",
    "end": "2108359"
  },
  {
    "text": "a certain types of alarms like if the workflow is slow it misses SLE or it's",
    "start": "2108359",
    "end": "2113849"
  },
  {
    "text": "encountering data loss and when it does that it'll page us and more interestingly we integrated with slack",
    "start": "2113849",
    "end": "2120049"
  },
  {
    "text": "what you see here is the you know airflow telling a slack that you've",
    "start": "2120049",
    "end": "2125339"
  },
  {
    "text": "missed your time SLA you missed your time SLA and then further down on it says hey this run finished but it lost",
    "start": "2125339",
    "end": "2132059"
  },
  {
    "text": "data and there's a link in it you click on it and the link will take you right to airflow and show you hey there's a",
    "start": "2132059",
    "end": "2137790"
  },
  {
    "text": "data loss that's happening right now and it works really well so with this combination we're sort of able to hit",
    "start": "2137790",
    "end": "2143700"
  },
  {
    "text": "all our targets that's sort of our bash pipeline the next sort of thing that",
    "start": "2143700",
    "end": "2150150"
  },
  {
    "text": "we're working on is our stream processing pipeline so this must look kind of overwhelming I mean it's",
    "start": "2150150",
    "end": "2158100"
  },
  {
    "start": "2153000",
    "end": "2350000"
  },
  {
    "text": "actually funny to have like the title that says you know architecture and then show something like I threw up on this",
    "start": "2158100",
    "end": "2163740"
  },
  {
    "text": "slide and depending on how all your kids are you may recognize like Richard",
    "start": "2163740",
    "end": "2168870"
  },
  {
    "text": "Scarry's like Busytown and basically looks like a busy town design but there",
    "start": "2168870",
    "end": "2175860"
  },
  {
    "text": "is some you know no there's something to this madness and actually it's a pattern and the pattern is that we essentially",
    "start": "2175860",
    "end": "2183150"
  },
  {
    "text": "have Auto scale compute followed by Kinesis which is sort of like Kafka so",
    "start": "2183150",
    "end": "2189150"
  },
  {
    "text": "anything that does compute will read from a kanisa stream do some computer on it and will be auto scale so that we you",
    "start": "2189150",
    "end": "2196230"
  },
  {
    "text": "know its scale for compute and then they'll publish its data downstream to Kinesis and then something on the other",
    "start": "2196230",
    "end": "2202590"
  },
  {
    "text": "side of kinases will read it and do the same so essentially everything is built of these repeatable pattern of compute",
    "start": "2202590",
    "end": "2208890"
  },
  {
    "text": "with Kinesis in between and the computers auto scaled and we call this elastic stream processing essentially",
    "start": "2208890",
    "end": "2214800"
  },
  {
    "text": "because Kinesis and and the compute can be elastically elastically scaled and",
    "start": "2214800",
    "end": "2222570"
  },
  {
    "text": "i'll talk about that a little bit a little later on and then there's this other thing on top called a schema",
    "start": "2222570",
    "end": "2228090"
  },
  {
    "text": "registry so how many of you have heard of a schema registry before especially if you've used Kafka you would know",
    "start": "2228090",
    "end": "2233700"
  },
  {
    "text": "about this awesome all right so I'm going to talk a little about a little",
    "start": "2233700",
    "end": "2239520"
  },
  {
    "text": "bit about a bro how many of you know either Admiral or protobuf or thrift awesome okay so a lot of you so we use",
    "start": "2239520",
    "end": "2246900"
  },
  {
    "text": "Avril um so just like you have data in a database right and that data is protected by a schema and some sort of",
    "start": "2246900",
    "end": "2253200"
  },
  {
    "text": "schema enforcement what about data in files or data on streams that should also be protected by some sort of schema",
    "start": "2253200",
    "end": "2260070"
  },
  {
    "text": "and Avro provides so do the others it provides typed types cardinality",
    "start": "2260070",
    "end": "2266450"
  },
  {
    "text": "optionality and also does nesting which is even better than most databases to you",
    "start": "2266450",
    "end": "2271470"
  },
  {
    "text": "and it also supports is very cool thing called a schema evolution so you're in",
    "start": "2271470",
    "end": "2277800"
  },
  {
    "text": "our case we have ten customers that all have different versions of our collector they all upgraded at different times and",
    "start": "2277800",
    "end": "2284760"
  },
  {
    "text": "they're all sending slightly different schemas to us like the data is coming in binary but with slightly different",
    "start": "2284760",
    "end": "2289800"
  },
  {
    "text": "schemas and then we're pushing code on our readers like at will and you know to",
    "start": "2289800",
    "end": "2296390"
  },
  {
    "text": "one of the best practices is this decoupling model right so we have q's to decouple but then they would be coupled",
    "start": "2296390",
    "end": "2302700"
  },
  {
    "text": "by schema and we want to be couple that even further so data coming in is we use",
    "start": "2302700",
    "end": "2309180"
  },
  {
    "text": "this concept called schema resolution which will take a reader and writer schema and figure out what's common between them to be able to read any",
    "start": "2309180",
    "end": "2316650"
  },
  {
    "text": "input that we can so this is kind of an example of a bro ok did you guys not see",
    "start": "2316650",
    "end": "2323369"
  },
  {
    "text": "that all right so this is an example of a row so it's a self-describing schema it's your anization format and as i",
    "start": "2323369",
    "end": "2330990"
  },
  {
    "text": "mentioned it has types and nesting now typically when you're working in sort of",
    "start": "2330990",
    "end": "2336000"
  },
  {
    "text": "do you store the schema that the data was written written with with the file",
    "start": "2336000",
    "end": "2343560"
  },
  {
    "text": "and and that's because the data files are so large the schema overhead is like tiny but in the world of streaming the",
    "start": "2343560",
    "end": "2351150"
  },
  {
    "start": "2350000",
    "end": "2453000"
  },
  {
    "text": "overhead is like ninety-nine percent of the data you're sending so it's not a good idea to send the writer schema",
    "start": "2351150",
    "end": "2358830"
  },
  {
    "text": "appended on the top of the actual data packet that's being sent so instead the",
    "start": "2358830",
    "end": "2364020"
  },
  {
    "text": "thing that LinkedIn came up with many years ago was to strip out the schema send the payload without a schema but",
    "start": "2364020",
    "end": "2371670"
  },
  {
    "text": "just an identifier and then on the consumer side to look up the schema use that to decode the binary and the only",
    "start": "2371670",
    "end": "2379740"
  },
  {
    "text": "problem with that is it's very tightly coupled to the kafka project so what we did is twofold we decouple it from the",
    "start": "2379740",
    "end": "2386640"
  },
  {
    "text": "kafka project and we also made it a like something that works perfectly well in the cloud and essentially we're going to",
    "start": "2386640",
    "end": "2393390"
  },
  {
    "text": "open source it in a few weeks it's it's basically a Gradle script that you can use to publish a zip file which has two",
    "start": "2393390",
    "end": "2400859"
  },
  {
    "text": "lambda functions in it and the lambda functions either take a register FEMA call or a get schema by ID call and",
    "start": "2400859",
    "end": "2407940"
  },
  {
    "text": "whenever you call the register schema call it will validate your schema to make sure it's backward and forward",
    "start": "2407940",
    "end": "2412980"
  },
  {
    "text": "compatible both as a reader and writer schema before it accepts it and you also",
    "start": "2412980",
    "end": "2419279"
  },
  {
    "text": "pass it on the fly in the URL a JDBC connection URL URI to the database",
    "start": "2419279",
    "end": "2427740"
  },
  {
    "text": "that's backing it and on every call you can change it if you wish but in you",
    "start": "2427740",
    "end": "2432839"
  },
  {
    "text": "know so for example you can pass it a JDBC URL to a dynamo on that call and",
    "start": "2432839",
    "end": "2438240"
  },
  {
    "text": "what it will do is it'll it'll validate it if it works it'll registered at that URL and then return success to you and it'll return an ID to you and then that",
    "start": "2438240",
    "end": "2444869"
  },
  {
    "text": "ID you pass down the stream and the consumer will read it and look it up and be able to decode on the fly so we'll be",
    "start": "2444869",
    "end": "2451140"
  },
  {
    "text": "open sourcing this in a few weeks and of course for those of you have not used lambda it's basically the next evolution",
    "start": "2451140",
    "end": "2458250"
  },
  {
    "start": "2453000",
    "end": "2514000"
  },
  {
    "text": "of survey lists it's it's essentially the next evolution of auto scaling",
    "start": "2458250",
    "end": "2463319"
  },
  {
    "text": "you're given a hosted execution environment all we need to do is upload zip in you know python node Java now I",
    "start": "2463319",
    "end": "2471630"
  },
  {
    "text": "think Ruby and then when you upload it all you do is you pick sort of a profile like medium memory I'm sorry medium CPU",
    "start": "2471630",
    "end": "2479490"
  },
  {
    "text": "high CPU super eyes review and 256 gig ram or one terabyte RAM or whatever I",
    "start": "2479490",
    "end": "2485099"
  },
  {
    "text": "didn't exactly know how large gets and then soon as you do that you get a new version and the beauty of this thing is",
    "start": "2485099",
    "end": "2492630"
  },
  {
    "text": "if you have a bug and you want to roll back all you do is in the UI you say dollar latest equals v1 and you've just",
    "start": "2492630",
    "end": "2499230"
  },
  {
    "text": "rolled back your code about your bad code so it's actually a very useful",
    "start": "2499230",
    "end": "2504440"
  },
  {
    "text": "innovation and I think I'm going a little bit over time but i'll just",
    "start": "2504440",
    "end": "2510119"
  },
  {
    "text": "mention this we're also creating a tool for elastic stream processing currently if you use Kafka or Kinesis your",
    "start": "2510119",
    "end": "2518579"
  },
  {
    "start": "2514000",
    "end": "2550000"
  },
  {
    "text": "scalability is / shard if you have three shards you have an exact provision limit what happens if your producer starts",
    "start": "2518579",
    "end": "2525299"
  },
  {
    "text": "producing more data so what we do is we will detect that there's such a problem",
    "start": "2525299",
    "end": "2531480"
  },
  {
    "text": "and automatically add new shards and auto scale the compute to handle it",
    "start": "2531480",
    "end": "2538619"
  },
  {
    "text": "and then detect when it's below provisioning and do the opposite and this also uses dynamo behind the scenes",
    "start": "2538619",
    "end": "2544499"
  },
  {
    "text": "so it'll also auto like automatically scale dynamo up to the next provision limit and scale it down both of these",
    "start": "2544499",
    "end": "2550019"
  },
  {
    "start": "2550000",
    "end": "2558000"
  },
  {
    "text": "will be open source if you guys want to follow it feel free to follow these two",
    "start": "2550019",
    "end": "2555180"
  },
  {
    "text": "Twitter IDs and I guess this really probably no time for questions but if",
    "start": "2555180",
    "end": "2560640"
  },
  {
    "start": "2558000",
    "end": "2564000"
  },
  {
    "text": "you have any oh they have five minutes for questions there is one question in",
    "start": "2560640",
    "end": "2566539"
  },
  {
    "start": "2564000",
    "end": "2729000"
  },
  {
    "text": "from the app and it is what was the VP's response when you told him there were",
    "start": "2566539",
    "end": "2572190"
  },
  {
    "text": "many books in the recommendation system know so um I didn't tell him I was not",
    "start": "2572190",
    "end": "2578579"
  },
  {
    "text": "from the others from the infrastructure team at Netflix I name was actually a mer the recommendations team who told me",
    "start": "2578579",
    "end": "2584549"
  },
  {
    "text": "and you know I I think there was some frustration but having worked I've",
    "start": "2584549",
    "end": "2590940"
  },
  {
    "text": "worked in recommendations for a long time and the beauty is you never get bugs and you know if you want a good",
    "start": "2590940",
    "end": "2597359"
  },
  {
    "text": "work-life balance I would work in recommender systems I one more question",
    "start": "2597359",
    "end": "2604559"
  },
  {
    "text": "remember to vote I can say that while I walk down here can you go back to the",
    "start": "2604559",
    "end": "2613739"
  },
  {
    "text": "slide that shows the Twitter feeds to follow I think it's the second to last",
    "start": "2613739",
    "end": "2619799"
  },
  {
    "text": "second to last oh the Twitter yeah sure here sorry",
    "start": "2619799",
    "end": "2626239"
  },
  {
    "text": "right any other comments or the slides you want to see you all any questions okay great so I am had a brief moment of",
    "start": "2628430",
    "end": "2639990"
  },
  {
    "text": "Terror when you showed the using the the Q offset and lag 2dr auto scaling groups",
    "start": "2639990",
    "end": "2646340"
  },
  {
    "text": "and wondering what means you have to prevent say a totally stalled cue from",
    "start": "2646340",
    "end": "2652470"
  },
  {
    "text": "just creating servers on infinitum are you watching it are you setting hard caps do you have stall detection or some",
    "start": "2652470",
    "end": "2659040"
  },
  {
    "text": "combination so your if I answer your question when we move to the Q based auto scaling you're saying how do we",
    "start": "2659040",
    "end": "2665580"
  },
  {
    "text": "keep so with all the scaling you provide a min and max size so we take steps so",
    "start": "2665580",
    "end": "2672330"
  },
  {
    "text": "every five minutes we check a rule in the rule is is the visible message depth still greater than zero yes step by four",
    "start": "2672330",
    "end": "2679050"
  },
  {
    "text": "so we take steps of for up to 40 or something and we're capped at 40 and then we scaled in after we keep them all",
    "start": "2679050",
    "end": "2686220"
  },
  {
    "text": "around until the last message drops off the the in flight q and then we're safe",
    "start": "2686220",
    "end": "2693570"
  },
  {
    "text": "to bring it in and we love SQS and SNS but we couldn't really use it for stream",
    "start": "2693570",
    "end": "2699480"
  },
  {
    "text": "processing because it'll never stop right messages never stop and there's never a scale in you kind of would never",
    "start": "2699480",
    "end": "2705900"
  },
  {
    "text": "scale in but it's definitely got some benefits over yeah kinesis good question",
    "start": "2705900",
    "end": "2715130"
  },
  {
    "text": "right no more questions I think we should call it a conference and thank you one more time said thank you and",
    "start": "2716170",
    "end": "2722680"
  },
  {
    "text": "here come up",
    "start": "2722680",
    "end": "2725400"
  }
]
[
  {
    "start": "0",
    "end": "15000"
  },
  {
    "text": "um some considerations for scaling sort of what we did at New Relic um and you could sort of subtitle this talk 17",
    "start": "2720",
    "end": "9040"
  },
  {
    "text": "things we did so if you're keeping score at home you know when you get to 17 you'll know the talk is done um so just",
    "start": "9040",
    "end": "16278"
  },
  {
    "start": "15000",
    "end": "108000"
  },
  {
    "text": "uh a brief this isn't trying to be a sales pitch but you got to know something about what we do to understand some of the things that we did to make",
    "start": "16279",
    "end": "22439"
  },
  {
    "text": "this work so we do web application performance monitoring so we monitor the performance of people who have websites",
    "start": "22439",
    "end": "29080"
  },
  {
    "text": "typically people who are selling something so they want to pay us money to monitor it we monitor the real user",
    "start": "29080",
    "end": "34559"
  },
  {
    "text": "performance by injecting JavaScript in the browser and it sends data back for every single page that every single one",
    "start": "34559",
    "end": "39840"
  },
  {
    "text": "of our customers customers views um we monitor servers you know at the server",
    "start": "39840",
    "end": "45039"
  },
  {
    "text": "level we monitor applications and the intercon connectivity applications um you know it monitors the full stack it",
    "start": "45039",
    "end": "51559"
  },
  {
    "text": "has short-term reports and long-term reports and alerts and all that kind of thing um the the more interesting thing",
    "start": "51559",
    "end": "59440"
  },
  {
    "text": "for the sake of this talk is what's the architecture underneath that and what we've got is we've got um your C our",
    "start": "59440",
    "end": "65640"
  },
  {
    "text": "customer out there puts a little agent that's the little logo there sitting on the servers um into their application if",
    "start": "65640",
    "end": "72640"
  },
  {
    "text": "it's a Java application it's a jar file if it's a ruby application it's a gem Etc that instruments automatically",
    "start": "72640",
    "end": "78360"
  },
  {
    "text": "instruments and collects the data and sends it once a minute over to our data center where we collect it and store it",
    "start": "78360",
    "end": "83840"
  },
  {
    "text": "on lots of databases and then we have a couple web servers where you can then go to our application and view that data so",
    "start": "83840",
    "end": "89920"
  },
  {
    "text": "it's complete software as a service solution so you don't have to do anything or our customers don't have to do anything on their um servers other",
    "start": "89920",
    "end": "96280"
  },
  {
    "text": "than install this little agent so it you know it looks in in the sort of marketing speak here like a fairly",
    "start": "96280",
    "end": "102880"
  },
  {
    "text": "simple architecture we use Ruby we use Java we use myql pretty pretty standard stuff the interesting thing for the sake",
    "start": "102880",
    "end": "110159"
  },
  {
    "start": "108000",
    "end": "184000"
  },
  {
    "text": "of of this talk is that in the four and a half years the customer that the company's been existence we've gone from",
    "start": "110159",
    "end": "115640"
  },
  {
    "text": "zero accounts obviously when we started to 30,000 accounts um out there and every account has between one and our",
    "start": "115640",
    "end": "122960"
  },
  {
    "text": "largest account has 17,000 servers reporting data to us and they report data to us every minute from every",
    "start": "122960",
    "end": "130119"
  },
  {
    "text": "server and actually actually every application on every server reports data to us every minute so we're collecting",
    "start": "130119",
    "end": "136280"
  },
  {
    "text": "over 40 40 um million metrics a minute which is over 58 billion metrics a day",
    "start": "136280",
    "end": "143640"
  },
  {
    "text": "or 5 terabytes a day now this is much much less data than the Large Hadron com",
    "start": "143640",
    "end": "149319"
  },
  {
    "text": "Collider we learned about this morning collects in one instant of time in a collision but that's okay um now another",
    "start": "149319",
    "end": "158480"
  },
  {
    "text": "thing you'll find um in this particular talk is I've put footnotes on my slides because I'm I'm tired of going to talks",
    "start": "158480",
    "end": "164640"
  },
  {
    "text": "where people make arbitrary claims and don't have anything to back them up so if you have a a computer handy you could",
    "start": "164640",
    "end": "171040"
  },
  {
    "text": "type in that little bitly link and look up the the data that I'm talking about in every one of these slides um so",
    "start": "171040",
    "end": "176120"
  },
  {
    "text": "anyway we we grew you know to 30,000 accounts and we continuing to grow rapidly and so how do we do this um the",
    "start": "176120",
    "end": "184120"
  },
  {
    "start": "184000",
    "end": "224000"
  },
  {
    "text": "interesting thing is you know it's New Relic has been a startup and so if you know anything about the Steve blank um",
    "start": "184120",
    "end": "190799"
  },
  {
    "text": "customer uh verification stuff or The Lean Startup and so on the the way that",
    "start": "190799",
    "end": "196519"
  },
  {
    "text": "the the model of a startup is first you prove that you've got a business model and then you scale that business model",
    "start": "196519",
    "end": "202640"
  },
  {
    "text": "so at the beginning New Relic was over there in the scalable startup thing where we're trying to find a business",
    "start": "202640",
    "end": "208560"
  },
  {
    "text": "model and now we're transitioning over into the cash flow Break Even profitable",
    "start": "208560",
    "end": "213680"
  },
  {
    "text": "we're actually a company and growing side of the business but since we were started over there in the scalable",
    "start": "213680",
    "end": "219799"
  },
  {
    "text": "startup we had no customers we had no Revenue we had nothing we needed to build a system that was we're able to",
    "start": "219799",
    "end": "227879"
  },
  {
    "start": "224000",
    "end": "272000"
  },
  {
    "text": "build very rapidly and get out there and get people to start using so we hosted our initial system at engine yard on",
    "start": "227879",
    "end": "234560"
  },
  {
    "text": "their their platform as a service system which they had a bunch of virtual machines we ended up being on eight physical machines there we wrote",
    "start": "234560",
    "end": "241079"
  },
  {
    "text": "everything in Ruby our our web application was Ruby on Rails our collector application that collected data from customers was was Ruby on",
    "start": "241079",
    "end": "247959"
  },
  {
    "text": "Rails we had a homegrown load balancer based on top of ha proxy um and we had",
    "start": "247959",
    "end": "255159"
  },
  {
    "text": "separate processes um for each one of the activities that we did and so this",
    "start": "255159",
    "end": "260320"
  },
  {
    "text": "was a great way to quickly build this this solution so that we could search for that business model we could find",
    "start": "260320",
    "end": "266360"
  },
  {
    "text": "out whether people would actually pay for this service that we thought was valuable um and that perhaps they thought was",
    "start": "266360",
    "end": "271800"
  },
  {
    "text": "valuable now of course this wasn't going to be able to grow to the size we are",
    "start": "271800",
    "end": "277240"
  },
  {
    "text": "now where we collecting 5 terabytes of Daya to day but it was a great place to start so then how do we move from a",
    "start": "277240",
    "end": "282479"
  },
  {
    "text": "great place to start to something that works today with the size that we are today well a couple of the",
    "start": "282479",
    "end": "288440"
  },
  {
    "start": "288000",
    "end": "425000"
  },
  {
    "text": "characteristics that's important to know about our software is well first of all like I said every app instance of every",
    "start": "288440",
    "end": "294960"
  },
  {
    "text": "customer sends us data every minute and sometimes more often than that um so",
    "start": "294960",
    "end": "300800"
  },
  {
    "text": "that's not just every server but it's every app instance so if you're running for instance unicorn on your as your",
    "start": "300800",
    "end": "306919"
  },
  {
    "text": "Ruby um service you're sending you know 20 or 30 packets of data to us per",
    "start": "306919",
    "end": "312280"
  },
  {
    "text": "server if you have 50 Apache workers on a PHP process you're sending 50 data",
    "start": "312280",
    "end": "317680"
  },
  {
    "text": "packets to us every minute Etc um now that's the data that's being sent to us",
    "start": "317680",
    "end": "323479"
  },
  {
    "text": "uh only a subset of our customers view the data on any at any given time right",
    "start": "323479",
    "end": "328560"
  },
  {
    "text": "so some of them log on to our website and view the data but most of them aren't um you know here we are in Denmark at the moment most of the",
    "start": "328560",
    "end": "335120"
  },
  {
    "text": "American customers at the moment are still asleep right and so they're not looking on at the website but um",
    "start": "335120",
    "end": "340680"
  },
  {
    "text": "European customers are our data has a very steep Half-Life um the most",
    "start": "340680",
    "end": "345960"
  },
  {
    "text": "interesting data is mere seconds old people really care about how their website is performing right now you know",
    "start": "345960",
    "end": "352039"
  },
  {
    "text": "is it slow at this exact moment they care a lot less about whether it was slow an hour ago or two hours ago or",
    "start": "352039",
    "end": "357600"
  },
  {
    "text": "last week now we keep the data for long periods of time so that you can look at",
    "start": "357600",
    "end": "362880"
  },
  {
    "text": "the data from a week or two week or 3 months or sometimes even a year ago depending on you know which subscription",
    "start": "362880",
    "end": "368400"
  },
  {
    "text": "plan you're willing to pay us for but for the most part the the customers are interested in the data that's right now",
    "start": "368400",
    "end": "375120"
  },
  {
    "text": "um and they also care that the accuracy is essential what's interesting is we find our customers write to us and say",
    "start": "375120",
    "end": "381440"
  },
  {
    "text": "things like I was looking at your chart and I don't believe that our web response time was 250 milliseconds I was",
    "start": "381440",
    "end": "388800"
  },
  {
    "text": "timing it with some other stuff and it's 247 milliseconds I'm like geez guys 3",
    "start": "388800",
    "end": "394199"
  },
  {
    "text": "milliseconds but they actually care to make it this really really accurate measurement of these things and so we",
    "start": "394199",
    "end": "399479"
  },
  {
    "text": "take a lot of care to make sure that our agents are measuring things accurately but it also means that we can't use an",
    "start": "399479",
    "end": "405840"
  },
  {
    "text": "eventual consistency style database where we for instance had all the data feeding into some sort of um nosql",
    "start": "405840",
    "end": "412840"
  },
  {
    "text": "database that when eventually get all of the data in one place and then query it and tell the user what the numbers are",
    "start": "412840",
    "end": "419039"
  },
  {
    "text": "because they care about the data being accurate right there right there in that short period of time so let's talk about",
    "start": "419039",
    "end": "426120"
  },
  {
    "start": "425000",
    "end": "488000"
  },
  {
    "text": "the basics that we're going to go through I've got five Basics that you go through and sort of we went through in",
    "start": "426120",
    "end": "431440"
  },
  {
    "text": "in putting this together um many of you who run big web applications you already",
    "start": "431440",
    "end": "436479"
  },
  {
    "text": "know this basic stuff so number one is um you want to reduce the number of",
    "start": "436479",
    "end": "441800"
  },
  {
    "text": "connections to your servers so typically when one of these processes one of these agent processes or or a website goes and",
    "start": "441800",
    "end": "449000"
  },
  {
    "text": "connects to one one of our servers it may take a while to make that connection and have the response come back and that",
    "start": "449000",
    "end": "455440"
  },
  {
    "text": "that holds a socket open or worker open on the on the application server so",
    "start": "455440",
    "end": "460800"
  },
  {
    "text": "especially um since you have lots and lots of people trying to do that we use um front-end servers we happen to use",
    "start": "460800",
    "end": "466919"
  },
  {
    "text": "F5s as our as our big switches to handle SSA SSL and it buffers the requests and it just makes sure that the you know it",
    "start": "466919",
    "end": "474280"
  },
  {
    "text": "it the F5s are very welld designed for doing that kind of thing and then they buffer up the requests and send them off to our to our application servers and",
    "start": "474280",
    "end": "480680"
  },
  {
    "text": "our collectors and reduces the number of connections to servers which means each of the servers can handle more customers",
    "start": "480680",
    "end": "486520"
  },
  {
    "text": "pretty basic stuff um we also moved off of the platform as a service at engine",
    "start": "486520",
    "end": "492560"
  },
  {
    "start": "488000",
    "end": "551000"
  },
  {
    "text": "yard onto our own bare metal and our own data center um we found that virtual machines didn't work particularly well",
    "start": "492560",
    "end": "499000"
  },
  {
    "text": "for our our type of data throughput um we found that when we had a virtualized",
    "start": "499000",
    "end": "505280"
  },
  {
    "text": "set of servers which has lots of good benefits but for the type of collection we're doing didn't work particularly",
    "start": "505280",
    "end": "511080"
  },
  {
    "text": "well because we had these IO latency problems when we're doing shared IO in a virtualized machine um we saw bandwidth",
    "start": "511080",
    "end": "517240"
  },
  {
    "text": "Jitter and some of the virtualized instances that we that we tried to use um we tried putting some of our stuff at",
    "start": "517240",
    "end": "523680"
  },
  {
    "text": "Amazon for a while which is great for lots of things but it's not good for High throughput um rights to databases",
    "start": "523680",
    "end": "530360"
  },
  {
    "text": "sort of thing um and Ruby on Rails which is what our applications are written in is very memory heavy and we believe that",
    "start": "530360",
    "end": "537160"
  },
  {
    "text": "the virtual machine infrastructures just doesn't handle memory mapping as well as it could and so you get a lot sort of",
    "start": "537160",
    "end": "543279"
  },
  {
    "text": "lower execution speed on your rails on a virtual machine or so we found um so we",
    "start": "543279",
    "end": "549720"
  },
  {
    "text": "went to Bare Metal um we used direct attached storage in our data center instead of a a sand",
    "start": "549720",
    "end": "556480"
  },
  {
    "start": "551000",
    "end": "627000"
  },
  {
    "text": "um we found that MySQL which is the database that we use depends on a really fast right commit which means that you",
    "start": "556480",
    "end": "562680"
  },
  {
    "text": "want the cash to be as close to the CPU as possible and you're thinking well",
    "start": "562680",
    "end": "568320"
  },
  {
    "text": "yeah in the sand the cas es out in the disc array and it's only you know a few feet away from the CPU but it turns out",
    "start": "568320",
    "end": "573680"
  },
  {
    "text": "the speed of light matters and we got a huge amount of performance gain by using",
    "start": "573680",
    "end": "578959"
  },
  {
    "text": "direct attached storage instead of a storage Network even though these are all in the same rack in the same D Data",
    "start": "578959",
    "end": "584440"
  },
  {
    "text": "Center and we're talking about wires that are just a couple feet long we we got a big benefit about going with the",
    "start": "584440",
    "end": "589760"
  },
  {
    "text": "direct attach storage um now when you use direct attach storage you you have",
    "start": "589760",
    "end": "594839"
  },
  {
    "text": "this problem where you end up with silos of data because you can only access the data from from the machine that it's",
    "start": "594839",
    "end": "600240"
  },
  {
    "text": "attached to but our architecture is such that we don't have that problem we're able to to Shard our customers very",
    "start": "600240",
    "end": "607360"
  },
  {
    "text": "effectively to separate shards so that when for instance Sam is accessing the site we get he only goes to the one",
    "start": "607360",
    "end": "613959"
  },
  {
    "text": "server and doesn't have to look at the data on the other servers because we don't mix the data from different customers across servers like that so",
    "start": "613959",
    "end": "620680"
  },
  {
    "text": "all of his data would be say on server number four um so the director attached storage worked pretty well",
    "start": "620680",
    "end": "627480"
  },
  {
    "start": "627000",
    "end": "682000"
  },
  {
    "text": "um we don't use app servers a lot actually so we have you know remember in",
    "start": "627480",
    "end": "633240"
  },
  {
    "text": "our my architecture diagram we had our collector tier that collects data and then we have our app server tier that",
    "start": "633240",
    "end": "638880"
  },
  {
    "text": "actually serves up the the application when you go to the pages and The Collector tier is just um Native Java",
    "start": "638880",
    "end": "645639"
  },
  {
    "text": "applications um as an old Assembly Language Pro programmer it's sort of weird to say native Java but it is",
    "start": "645639",
    "end": "650959"
  },
  {
    "text": "native Java there's no web server in front of that it just opens a socket it has an embedded Jetty in there so that",
    "start": "650959",
    "end": "657959"
  },
  {
    "text": "it does the HTTP stuff really it's just native Java um very high throughput you",
    "start": "657959",
    "end": "663040"
  },
  {
    "text": "can see I I took a snapshot to put it on the slide here we're looking at a million requests a minute on our Beacon which is the collector that collects",
    "start": "663040",
    "end": "669959"
  },
  {
    "text": "data from our customers customers webpage visits so that's that front end",
    "start": "669959",
    "end": "675480"
  },
  {
    "text": "data with the JavaScript every time one of our customers like Groupon has a customer who goes to a page",
    "start": "675480",
    "end": "682320"
  },
  {
    "start": "682000",
    "end": "747000"
  },
  {
    "text": "that that's too many levels of indirection anyway it sends a hit back to our Beacon and so we're looking at a million page requests there and these",
    "start": "682320",
    "end": "688639"
  },
  {
    "text": "are just actually the the sort of average requests of when I snapshotted that the peak requests are about 50%",
    "start": "688639",
    "end": "695200"
  },
  {
    "text": "higher than this so we need to be able to handle uh a fairly high throughput on these things um we have one Beacon",
    "start": "695200",
    "end": "700920"
  },
  {
    "text": "machine we have uh eight aggregator machines and they're look you know you're looking at 3 millisecond or 170",
    "start": "700920",
    "end": "707839"
  },
  {
    "text": "or 170 microsc response times on those processes so that's pretty fast um on uh",
    "start": "707839",
    "end": "714639"
  },
  {
    "text": "on the Ruby on Rails side for our our main application we switched to unicorn um",
    "start": "714639",
    "end": "719800"
  },
  {
    "text": "if if you do Ruby on Rails uh development you know that unicorn has this advantage that it doesn't have a",
    "start": "719800",
    "end": "725160"
  },
  {
    "text": "dispatcher that dispatches the requests because they all share a common socket all the workers share a common socket so",
    "start": "725160",
    "end": "730760"
  },
  {
    "text": "that takes a little bit of the delay out of the whole process um unicorn also happens to be easier to do live deploy",
    "start": "730760",
    "end": "736279"
  },
  {
    "text": "of code too you don't have to take them down quite as much and restart them the way that we did um previously um and so",
    "start": "736279",
    "end": "742519"
  },
  {
    "text": "it helps with with continuous deployment um so those are the basics so",
    "start": "742519",
    "end": "748279"
  },
  {
    "start": "747000",
    "end": "876000"
  },
  {
    "text": "now once you've dealt with the basics let's go and deal with The Usual Suspects that aren't quite as basic but",
    "start": "748279",
    "end": "754399"
  },
  {
    "text": "things that you can do a little bit more they take a little bit more knowledge about what the application actually looks like um to tweak so the first one",
    "start": "754399",
    "end": "762279"
  },
  {
    "text": "is let's look at the agent protocol now the agent is a little piece of code that sits in your application and sends data",
    "start": "762279",
    "end": "768920"
  },
  {
    "text": "over to our aggregators and so our first agent was really simple the first agent protocol was really simple because we",
    "start": "768920",
    "end": "775120"
  },
  {
    "text": "were originally a Ruby on Rails monitoring shop and we had Ruby on Rails in our data center doing the collection",
    "start": "775120",
    "end": "781199"
  },
  {
    "text": "and so we just used um Ruby object serialization to send the data over send",
    "start": "781199",
    "end": "786399"
  },
  {
    "text": "it over no problem um allowed us to get up fast and quick and prove whether we had a good business model now as soon as",
    "start": "786399",
    "end": "793199"
  },
  {
    "text": "we extended from just doing rubby to doing Java we could either duplicate the Ruby object um serialization in Java",
    "start": "793199",
    "end": "801240"
  },
  {
    "text": "code to get that or we could come up with a better protocol and so since we now realize that we might have a",
    "start": "801240",
    "end": "807079"
  },
  {
    "text": "business in place when we were going from Ruby to Ruby and Java we said okay great let's make up a new protocol and",
    "start": "807079",
    "end": "812800"
  },
  {
    "text": "we designed a new protocol that was more optimized for sending the data over and it happens to use Json um but a couple",
    "start": "812800",
    "end": "819199"
  },
  {
    "text": "other things it did is it reduced the round trips um uh uh previously when we sent we sent metric data in one round",
    "start": "819199",
    "end": "826199"
  },
  {
    "text": "trip and error data in one round trip and transaction traces in one round trip and configuration data in one round trip",
    "start": "826199",
    "end": "831880"
  },
  {
    "text": "and so the agent was making four or five different requests to The Collector every minute and that was fine when we",
    "start": "831880",
    "end": "837720"
  },
  {
    "text": "had 16 customers but you know when we got to about 10,000 customers we're starting to see a significant load of",
    "start": "837720",
    "end": "843519"
  },
  {
    "text": "round trips onto the server so we changed the protocol so that it packages all up into as few round trips as possible does it keep alive on that so",
    "start": "843519",
    "end": "850440"
  },
  {
    "text": "that the round trips aren't actually closing the socket on every round trip and and so on um of course we were also",
    "start": "850440",
    "end": "856839"
  },
  {
    "text": "very careful in our protocol design to put a version number in there so that we could continue to support old versions",
    "start": "856839",
    "end": "862279"
  },
  {
    "text": "of the agents out there as we continue to evolve didn't have to insist that everybody update all their agents every",
    "start": "862279",
    "end": "867399"
  },
  {
    "text": "time we're currently supporting 12 different versions of the protocol out there as we've evolved it um as we've",
    "start": "867399",
    "end": "873079"
  },
  {
    "text": "grown the company um so another thing we did which",
    "start": "873079",
    "end": "878759"
  },
  {
    "start": "876000",
    "end": "965000"
  },
  {
    "text": "we found very important in in scaling the business is that if one of our services is temporarily unavailable we",
    "start": "878759",
    "end": "885600"
  },
  {
    "text": "accumulate the data and retry we don't double up and retry but we accumulate it",
    "start": "885600",
    "end": "891000"
  },
  {
    "text": "so for example if if the agent is trying to report to the aggregator this minute",
    "start": "891000",
    "end": "896040"
  },
  {
    "text": "and it finds that the aggregator is too busy to take the data it says okay well too busy this time and it continues to",
    "start": "896040",
    "end": "902680"
  },
  {
    "text": "aggre to accumulate data from the from the um customer's website and then the next minute tries again with two minutes",
    "start": "902680",
    "end": "909079"
  },
  {
    "text": "worth of data it doesn't try again with two separate requests in that second minute it tries with two minutes worth",
    "start": "909079",
    "end": "915240"
  },
  {
    "text": "of data and we do that at every one of the levels at the agent level we actually do that at the aggregator itself so that if we're trying to write",
    "start": "915240",
    "end": "921320"
  },
  {
    "text": "to the databases and the databases are temporarily too busy to take the data we accumulate the data for a couple minutes",
    "start": "921320",
    "end": "927360"
  },
  {
    "text": "or you know a couple interations which might be 30 seconds and then write the accumulated data the second time it's",
    "start": "927360",
    "end": "934480"
  },
  {
    "text": "really important to do that that accumulation because otherwise you end up swamping the service when it comes",
    "start": "934480",
    "end": "939720"
  },
  {
    "text": "back up again and especially in a situation like ours where you're running at a very Peak load inside the service",
    "start": "939720",
    "end": "945759"
  },
  {
    "text": "already I mean you know we have a very constant High throughput rights to our databases and to our services you can't",
    "start": "945759",
    "end": "951959"
  },
  {
    "text": "sort of double that load a minute later and expect the service to be able to handle that or I suppose you could if",
    "start": "951959",
    "end": "957040"
  },
  {
    "text": "you put a lot more Hardware in but we didn't want to do that so anyway we've got that at all the levels and and this was a a good win for scaling the system",
    "start": "957040",
    "end": "965079"
  },
  {
    "start": "965000",
    "end": "1027000"
  },
  {
    "text": "up another thing we did is you know originally when we started the company our customers were all small companies",
    "start": "965079",
    "end": "971199"
  },
  {
    "text": "like ourselves in fact to be honest they were all friends of ours who thought that it might be nice to try out what we",
    "start": "971199",
    "end": "976480"
  },
  {
    "text": "were doing um little by little we started getting bigger and bigger customers uh you saw my slide earlier",
    "start": "976480",
    "end": "981800"
  },
  {
    "text": "that our biggest customer has over 17,000 um servers we have uh for instance at lassan is one of our",
    "start": "981800",
    "end": "987959"
  },
  {
    "text": "customers and they have uh 20,000 different applications each running on a subset of their servers and",
    "start": "987959",
    "end": "994199"
  },
  {
    "text": "so when they would go to our web page that show listed all your applications running it was great when our customers",
    "start": "994199",
    "end": "1000160"
  },
  {
    "text": "had three applications didn't work so well when our customers had a thousand applications it was just too much data",
    "start": "1000160",
    "end": "1005480"
  },
  {
    "text": "showing up there so again a design decision that we made early on to make the company uh to give the company a",
    "start": "1005480",
    "end": "1010759"
  },
  {
    "text": "start we needed to modify and so we did things like paging and smart sorting and searching um smart sorting is just you",
    "start": "1010759",
    "end": "1017079"
  },
  {
    "text": "know if you have a thousand applications that you're trying to view you obviously don't care about a thousand of them you care about the two that are slow so we",
    "start": "1017079",
    "end": "1023680"
  },
  {
    "text": "sort those to the top and that sort of thing um we use Ruby on Rails which uh",
    "start": "1023680",
    "end": "1029959"
  },
  {
    "start": "1027000",
    "end": "1126000"
  },
  {
    "text": "you know for our main web application which has certain advantages it's it's a great system for building certain types of applications but um since it has this",
    "start": "1029959",
    "end": "1037360"
  },
  {
    "text": "built-in omm you know rails um it can be very scary so there's your your Halloween pumpkin from the United States",
    "start": "1037360",
    "end": "1043480"
  },
  {
    "text": "with these scary rails on it the scary part of the OM is that if you're not careful about you design it you can",
    "start": "1043480",
    "end": "1050080"
  },
  {
    "text": "bring in a lot of objects when you try and trans uh walk over the database using what seems like innocuous pieces",
    "start": "1050080",
    "end": "1056240"
  },
  {
    "text": "of code um and so what we did was you know first of all wrote wrote the code",
    "start": "1056240",
    "end": "1062400"
  },
  {
    "text": "in rails and and it worked fine when we're looking at small sets and then as we got more and more accounts and more and more applications on those accounts",
    "start": "1062400",
    "end": "1068720"
  },
  {
    "text": "and more and more servers on those applications things started to bog down so we cleverly used our own software to",
    "start": "1068720",
    "end": "1075159"
  },
  {
    "text": "look at what the slow transactions were in there so we'd find something in there oh that page is taking 2.2 seconds to",
    "start": "1075159",
    "end": "1081640"
  },
  {
    "text": "load that's pretty unacceptable we want everything to be less than half a second so we could dive in with our software",
    "start": "1081640",
    "end": "1087280"
  },
  {
    "text": "and If This Were a product demo I could show you exactly how you dive in with the software and find out how many",
    "start": "1087280",
    "end": "1092480"
  },
  {
    "text": "incorrect objects are being loaded and then we would go in and we would fix the omm mappings or we would add an index or",
    "start": "1092480",
    "end": "1098480"
  },
  {
    "text": "something so that it would be faster and but you know the the lesson here is that if you're using something clever like an",
    "start": "1098480",
    "end": "1104600"
  },
  {
    "text": "omm to make your development faster there's a certain cost to it and at the beginning uh of the company's life that",
    "start": "1104600",
    "end": "1111080"
  },
  {
    "text": "was a cost we're willing to pay because we had a very small set of data and as the company's gotten bigger and our data sets have gotten bigger we've had to",
    "start": "1111080",
    "end": "1117600"
  },
  {
    "text": "move away from that automatic um mapping to objects and do more and more of the queries manually",
    "start": "1117600",
    "end": "1124320"
  },
  {
    "text": "ourselves okay so those were the usual suspects now let's go on to what I what I consider the clever things um I've got",
    "start": "1124320",
    "end": "1131720"
  },
  {
    "start": "1126000",
    "end": "1133000"
  },
  {
    "text": "six of these um starting with one of the clever things we do is we precompute",
    "start": "1131720",
    "end": "1137720"
  },
  {
    "start": "1133000",
    "end": "1237000"
  },
  {
    "text": "some of the queries now if you went went to Nathan um mans's Talk yesterday about",
    "start": "1137720",
    "end": "1143000"
  },
  {
    "text": "the way Twitter does things and calls it the Lambda architecture this is a very similar sort of thing although we're not",
    "start": "1143000",
    "end": "1148080"
  },
  {
    "text": "nearly at the same data scale they are but for example since um you can send",
    "start": "1148080",
    "end": "1154240"
  },
  {
    "text": "your data from one of your applications to multiple named applications on our site so you use this to do rollups so",
    "start": "1154240",
    "end": "1161280"
  },
  {
    "text": "for instance in our case we have two servers um a hot one and a standby one that collect Beacon data and we report",
    "start": "1161280",
    "end": "1168400"
  },
  {
    "text": "them in our dashboard as Beacon one Beacon 2 and a rolled up one called Beacon which is a combination of those",
    "start": "1168400",
    "end": "1174880"
  },
  {
    "text": "two and so in the database this is stored again remember we're using MySQL just straight native MySQL this is",
    "start": "1174880",
    "end": "1181880"
  },
  {
    "text": "stored as lots of different rows um by server and by application and by customer and so to do a query on Beacon",
    "start": "1181880",
    "end": "1189440"
  },
  {
    "text": "one we'd have to query a bunch of rows and to do a query on Beacon 2 and Beacon we'd have to query a bunch of rows so",
    "start": "1189440",
    "end": "1194960"
  },
  {
    "text": "instead what we do in the aggregator is we know that these are standard IES that occur in our application and we",
    "start": "1194960",
    "end": "1201760"
  },
  {
    "text": "pre-compute those on the aggregation side because we can do it faster as the data comes in then we can by writing it",
    "start": "1201760",
    "end": "1207840"
  },
  {
    "text": "to the database and then querying it out of the database and so by knowing some of the characteristics of the way our",
    "start": "1207840",
    "end": "1214080"
  },
  {
    "text": "web application accesses the data we can pre-compute some of those rows and write them into the database and then go get",
    "start": "1214080",
    "end": "1219480"
  },
  {
    "text": "the pre-computed row and show it and by robustly building the software if we can't find the pre-computed row we can",
    "start": "1219480",
    "end": "1226159"
  },
  {
    "text": "actually though then go and compute it um the slow way in our application so if for some reason the the pre-computed row",
    "start": "1226159",
    "end": "1233400"
  },
  {
    "text": "didn't get written um we're still in good shape uh we had a similar problem with",
    "start": "1233400",
    "end": "1239159"
  },
  {
    "start": "1237000",
    "end": "1328000"
  },
  {
    "text": "our background jobs uh we have we have our data in a number of different tables",
    "start": "1239159",
    "end": "1244640"
  },
  {
    "text": "it at first it's in we store it in tables that store things by the minute and then we roll those up and store things by the hour and then we roll",
    "start": "1244640",
    "end": "1250880"
  },
  {
    "text": "those up and store things by the day so that when you look at data farther in the past you can look at things at at a",
    "start": "1250880",
    "end": "1256679"
  },
  {
    "text": "different granularity um and we can get that data more quickly and so when we first built the the the software we had",
    "start": "1256679",
    "end": "1264000"
  },
  {
    "text": "each of these background jobs was written in Ruby and once an hour there's a background job that took all the",
    "start": "1264000",
    "end": "1269440"
  },
  {
    "text": "minute data and rolled it up to hour data and it all made sense and it worked great except that we eventually discovered that the rollup process was",
    "start": "1269440",
    "end": "1275799"
  },
  {
    "text": "taking more than an hour to complete and we were starting to fall behind and rolling up the data it's like okay well",
    "start": "1275799",
    "end": "1280960"
  },
  {
    "text": "we got to fix that problem and so we did the same sort of thing that we did with the precomputing the data except that in",
    "start": "1280960",
    "end": "1286880"
  },
  {
    "text": "this case what we have is we have the collect which wres to both the minute table and it collects data and wres to the hour",
    "start": "1286880",
    "end": "1292640"
  },
  {
    "text": "table so once an hour it does a few extra rights to write to that hour table and essentially pre-computing that",
    "start": "1292640",
    "end": "1297960"
  },
  {
    "text": "background job and again if that collector were for instance to die because it's just a Java process and it",
    "start": "1297960",
    "end": "1303400"
  },
  {
    "text": "you know you might kill nine it or it might run out of memory it might die and restart it would lose that hour data",
    "start": "1303400",
    "end": "1309320"
  },
  {
    "text": "that it was starting to write so we've still got that background job sitting around and if it notices that the that",
    "start": "1309320",
    "end": "1314600"
  },
  {
    "text": "the rollup for that hour didn't happen it'll trigger it and start to do it and so as long as the collector is doing most",
    "start": "1314600",
    "end": "1320640"
  },
  {
    "text": "of the rollups we're fine because the background job even if it takes more than an hour to do one hour we're still in good",
    "start": "1320640",
    "end": "1326679"
  },
  {
    "text": "shape um another thing we did is we used",
    "start": "1326679",
    "end": "1332000"
  },
  {
    "start": "1328000",
    "end": "1423000"
  },
  {
    "text": "different databases for different types of data now we actually are using MySQL underneath the whole system so it's not",
    "start": "1332000",
    "end": "1339840"
  },
  {
    "text": "that we're using you know MySQL for one set of data and and say Cassandra for a different set of data we're actually",
    "start": "1339840",
    "end": "1344960"
  },
  {
    "text": "using MySQL in all these cases but we're using a relational tuned my SQL for our",
    "start": "1344960",
    "end": "1350320"
  },
  {
    "text": "account data like have you paid us this month and what's your account name and who's all the users who can use it and",
    "start": "1350320",
    "end": "1356760"
  },
  {
    "text": "we use a a right only tuned um or right once tuned database for our time slice",
    "start": "1356760",
    "end": "1362880"
  },
  {
    "text": "data because all of the time slace data is effectively immutable right it comes in once the data is recorded it has it",
    "start": "1362880",
    "end": "1369760"
  },
  {
    "text": "doesn't change again and it has this characteristic where you can you can um",
    "start": "1369760",
    "end": "1375159"
  },
  {
    "text": "you can change the way the tuning parameters on the MySQL the different buffer pools and so on so you get the",
    "start": "1375159",
    "end": "1380240"
  },
  {
    "text": "maximum um uh speed there and so you know if if you know something W about",
    "start": "1380240",
    "end": "1385279"
  },
  {
    "text": "memory allocators are implemented in C you know Malik and so on there's a an algorithm called buddy memory allocation",
    "start": "1385279",
    "end": "1391360"
  },
  {
    "text": "where you you make blocks of different size blocks um so that if you're allocating small lots of small blocks of",
    "start": "1391360",
    "end": "1398240"
  },
  {
    "text": "memory they come out of this chunk and if the lots of large blocks they come out of this chunk this basically what",
    "start": "1398240",
    "end": "1403480"
  },
  {
    "text": "we're trying to do with our databases here by separating the databases according to the characteristics of the",
    "start": "1403480",
    "end": "1408559"
  },
  {
    "text": "data that goes into them and if you're if you were at the large hedron compiler uh collider talk this morning that they",
    "start": "1408559",
    "end": "1415320"
  },
  {
    "text": "were basically doing the same thing of course again they're not using just straight MySQL but they're separating the data by the different",
    "start": "1415320",
    "end": "1421200"
  },
  {
    "text": "characteristics that that it writes out um another thing we did is we use a",
    "start": "1421200",
    "end": "1426679"
  },
  {
    "start": "1423000",
    "end": "1525000"
  },
  {
    "text": "non-garbage collector garbage collector solution for our databases so you know",
    "start": "1426679",
    "end": "1432039"
  },
  {
    "text": "when people are sending us data we're writing rows into the database we're writing 58 um 58 billion in rows a day",
    "start": "1432039",
    "end": "1439279"
  },
  {
    "text": "into the database and since we write it in a on a minute basis and then we roll it up to an hour basis after some time",
    "start": "1439279",
    "end": "1445679"
  },
  {
    "text": "the minute data is no longer useful and we can throw it out so how do you garbage collect that well a standard way is you'd go into the database and you",
    "start": "1445679",
    "end": "1451720"
  },
  {
    "text": "just delete all those minute rows but it turns out if you do that in MySQL at least using some of the standard MySQL",
    "start": "1451720",
    "end": "1458000"
  },
  {
    "text": "backends it gets pretty slow because it locks up the table or locks up rows you're trying to use and just jams the",
    "start": "1458000",
    "end": "1463480"
  },
  {
    "text": "whole thing up so instead what we did is we said well let's just make a different table for every account for every time",
    "start": "1463480",
    "end": "1471480"
  },
  {
    "text": "size um and then when that time that's no longer used we'll just delete that table just do a drop table so instead of",
    "start": "1471480",
    "end": "1479039"
  },
  {
    "text": "deleting the rows one by one we're deleting the whole table um now I I worked in Amazon 1999 2201 and uh we had",
    "start": "1479039",
    "end": "1487640"
  },
  {
    "text": "a big executable there that was written in C this is before the Amazon switched to doing a Services model and we had a",
    "start": "1487640",
    "end": "1494000"
  },
  {
    "text": "real memory allocation problem because people would allocate memory all over and we're trying to decide well should we make a garbage collector or whatever",
    "start": "1494000",
    "end": "1499880"
  },
  {
    "text": "and we decide nope the simplest solution is just run 100 requests through the through the executable and then restart",
    "start": "1499880",
    "end": "1505840"
  },
  {
    "text": "it so the memory collection consisted of using the operating system to zero out all the pages because it was extremely",
    "start": "1505840",
    "end": "1511480"
  },
  {
    "text": "efficient at doing that and just start all over again and we're using a very similar model in our database here we're",
    "start": "1511480",
    "end": "1516720"
  },
  {
    "text": "just using the operating system dropping a table is effectively as simple in my SQL as deleting a file from the dis and",
    "start": "1516720",
    "end": "1523360"
  },
  {
    "text": "the thing works very quickly that way uh another thing we do is we do",
    "start": "1523360",
    "end": "1528440"
  },
  {
    "start": "1525000",
    "end": "1624000"
  },
  {
    "text": "computation in the database instead of in rails um Ruby is a is a nice language",
    "start": "1528440",
    "end": "1533840"
  },
  {
    "text": "to work in for making changes quickly but it's not a particularly efficient language in terms of execution speed",
    "start": "1533840",
    "end": "1539840"
  },
  {
    "text": "this is why we moved our um backend colle or front-end collector from Ruby to Java because we could the the Java",
    "start": "1539840",
    "end": "1546880"
  },
  {
    "text": "process was much more efficient and the jits on in Java are very efficient and we got really high throughput um",
    "start": "1546880",
    "end": "1552919"
  },
  {
    "text": "response time there but we we don't we don't want to take the the cost of writing in Java if for main web",
    "start": "1552919",
    "end": "1558760"
  },
  {
    "text": "application we're all happy writing in rails so we want to do as little computation in rails as we can because it's just it's not that efficient as a",
    "start": "1558760",
    "end": "1565120"
  },
  {
    "text": "computation language the MySQL um back end actually computes a lot of the things that we need very efficiently if",
    "start": "1565120",
    "end": "1572039"
  },
  {
    "text": "you look at you know again the sort of data that we gather We Gather time slice data for your application and then we",
    "start": "1572039",
    "end": "1578120"
  },
  {
    "text": "provide you averages of that over periods of time whether that's a period of a minute or 5 minutes or 10 minutes",
    "start": "1578120",
    "end": "1583679"
  },
  {
    "text": "or something well average is a computation that my SQL can compute very efficiently over in the table and so we",
    "start": "1583679",
    "end": "1589799"
  },
  {
    "text": "do that in the database and then send a few rows over to the Ruby side to",
    "start": "1589799",
    "end": "1595840"
  },
  {
    "text": "display on the on the screen now this is opposite of the sort of the classical advice of doing nothing in the database",
    "start": "1595840",
    "end": "1601960"
  },
  {
    "text": "and there's a there's a famous paper from eBay in the 2006 SD Forum where they explained about how they managed to",
    "start": "1601960",
    "end": "1607799"
  },
  {
    "text": "scale eBay out so well and one of the things they said is don't do anything in the database don't do anything at all in",
    "start": "1607799",
    "end": "1613120"
  },
  {
    "text": "the database and so we're we're not doing that we're actually doing stuff in the database we just happen to be doing",
    "start": "1613120",
    "end": "1618240"
  },
  {
    "text": "computation we're still not we still don't have any business logic in the database but we do do some computation there and then we move to ssds and the",
    "start": "1618240",
    "end": "1627720"
  },
  {
    "start": "1624000",
    "end": "1746000"
  },
  {
    "text": "interesting thing about ssds and hard and just and spinning rust in this case",
    "start": "1627720",
    "end": "1632880"
  },
  {
    "text": "for for our data set is that when when we get data from",
    "start": "1632880",
    "end": "1638440"
  },
  {
    "text": "customers we get every minute we get from every customer a piece of data and",
    "start": "1638440",
    "end": "1643559"
  },
  {
    "text": "so we could either write those all sequentially into the database and then when you to view your data we'd have to",
    "start": "1643559",
    "end": "1650279"
  },
  {
    "text": "go pick your piece of data from this page and your piece of data from this page and your piece of data from this page so we could either get sequential",
    "start": "1650279",
    "end": "1656039"
  },
  {
    "text": "wrs and random reads which of course would thrash the database to bits because that random read means it's",
    "start": "1656039",
    "end": "1661279"
  },
  {
    "text": "going to have to fetch basically every page across those tables or we could do it the other way where when we do the wrs we write here we write here we write",
    "start": "1661279",
    "end": "1668600"
  },
  {
    "text": "here and then when we do the read we can read it sequentially but again in the wrs case we're going to we're going to be writing all over the disc um so we",
    "start": "1668600",
    "end": "1675799"
  },
  {
    "text": "were constantly running our discs very hot and we tried to do things like put in our aggregators where we would prech",
    "start": "1675799",
    "end": "1681279"
  },
  {
    "text": "Unk huge writs all together and then write them out all at once so that they could do as much sequential writing as",
    "start": "1681279",
    "end": "1687120"
  },
  {
    "text": "possible even though we were gathering it um randomly and so on so then we decided Well let's try switching to ssds",
    "start": "1687120",
    "end": "1693039"
  },
  {
    "text": "now ssds have certain characteristics they're they're supposed to be very fast and they are typically very fast they're",
    "start": "1693039",
    "end": "1698559"
  },
  {
    "text": "actually a little slower on the right side at least the ssds we chose they're a little slower to to write than the",
    "start": "1698559",
    "end": "1705360"
  },
  {
    "text": "hard diss but there's no seek time on the reads and so we can do random reads",
    "start": "1705360",
    "end": "1713120"
  },
  {
    "text": "and sequential wrs on the ssds which we couldn't do on the hard Diss and we got a huge performance win out of the",
    "start": "1713120",
    "end": "1719320"
  },
  {
    "text": "characteristics of our data because of this so we can write the data as it comes in just straight across the disc",
    "start": "1719320",
    "end": "1725080"
  },
  {
    "text": "and then when we go and do the read we get the random read with no seat cost at all um by using the SSD so this is a",
    "start": "1725080",
    "end": "1731760"
  },
  {
    "text": "good win we actually continue to use hard diss for the longer term storage because people again don't access it",
    "start": "1731760",
    "end": "1737080"
  },
  {
    "text": "that much so we have process that takes the SSD data and moves it off to the hard drives um on a regular basis and",
    "start": "1737080",
    "end": "1743720"
  },
  {
    "text": "then we get it from whichever place it is in um so a couple more things uh here's",
    "start": "1743720",
    "end": "1749480"
  },
  {
    "start": "1746000",
    "end": "1880000"
  },
  {
    "text": "a three-dimensional bin packing problem which I think is is great for the two further optimizations that we're doing",
    "start": "1749480",
    "end": "1755000"
  },
  {
    "text": "to continue um moving towards becoming a larger and larger company one of the things we did was when we first started",
    "start": "1755000",
    "end": "1761640"
  },
  {
    "text": "out we just plopped all of process Type X on one machine and all of process type y on another machine and it was because",
    "start": "1761640",
    "end": "1768519"
  },
  {
    "text": "we had lots of machine resources we started we started with zero customers and eight physical machines so we had",
    "start": "1768519",
    "end": "1773720"
  },
  {
    "text": "plenty of machine resources to handle everything um but each one of these processes has a different characteristic",
    "start": "1773720",
    "end": "1779159"
  },
  {
    "text": "in the amount of memory it uses the amount of IO it uses the amount of CPU it uses and so on and we've discovered",
    "start": "1779159",
    "end": "1785200"
  },
  {
    "text": "that by moving a few of the X's here and a few of the Y's on the same machine we can optimize the characteristics so that",
    "start": "1785200",
    "end": "1791240"
  },
  {
    "text": "we're using as much of that machine CPU and as much of that machine's memory as possible without causing any thrashing",
    "start": "1791240",
    "end": "1797559"
  },
  {
    "text": "this at the the moment is a manual process where we just sort of go ah well looks like we can move a couple of those onto this machine and look at the curves",
    "start": "1797559",
    "end": "1803679"
  },
  {
    "text": "and make sure it works but we're getting more and more performance out of our same Hardware because we've gone from",
    "start": "1803679",
    "end": "1810120"
  },
  {
    "text": "eight physical machines to 10 physical machines when we've gone from zero customers to 5 terabytes a day of data",
    "start": "1810120",
    "end": "1817840"
  },
  {
    "text": "right so we really haven't added any machines we've just been continually optimizing it um the other optimization",
    "start": "1817840",
    "end": "1824159"
  },
  {
    "text": "we do is that we move customers around between our shards um we we made an early architecture decision when we're",
    "start": "1824159",
    "end": "1830440"
  },
  {
    "text": "building the system to allow um customers to be switched between sh to",
    "start": "1830440",
    "end": "1835679"
  },
  {
    "text": "be split between shards now obviously we made an early decision to have shards in the first place but once you'd made that",
    "start": "1835679",
    "end": "1840799"
  },
  {
    "text": "you know you normally put all of a customer on one Shard and all of another customer on another Shard but we thought that you know we might want to move them",
    "start": "1840799",
    "end": "1846720"
  },
  {
    "text": "somay so we have the ability to put some of some customer data on one Shard another so that we can gradually move",
    "start": "1846720",
    "end": "1851960"
  },
  {
    "text": "them over to another um Shard without having to do a giant copy of all of the data of that customer because there's",
    "start": "1851960",
    "end": "1857519"
  },
  {
    "text": "quite a bit of data um so we've been balancing the customers and this is automated between the shards so that all",
    "start": "1857519",
    "end": "1863600"
  },
  {
    "text": "the shards remain about the same level of of um load um regardless of the size",
    "start": "1863600",
    "end": "1869039"
  },
  {
    "text": "of the customers so in effect each one of our big Shard shards has one of our big customers on it and a bunch of our",
    "start": "1869039",
    "end": "1875519"
  },
  {
    "text": "smaller customers right so that you know as we're growing we continue to do that so A couple um lessons takeaways from",
    "start": "1875519",
    "end": "1884519"
  },
  {
    "text": "this um you you can sort of go back over the talk and think what's going to say well number one do the basics right um",
    "start": "1884519",
    "end": "1892159"
  },
  {
    "text": "there there's Basics things you can do about you know putting switches in front and setting up your Hardware correctly",
    "start": "1892159",
    "end": "1898240"
  },
  {
    "text": "so on number two when you're building a business like this design in some scalability you don't have to design in",
    "start": "1898240",
    "end": "1903559"
  },
  {
    "text": "all the scalability you don't have to make a magic solution that has all the possible you know nosql buzzwords or",
    "start": "1903559",
    "end": "1909159"
  },
  {
    "text": "whatever it is I mean we've built this business that does 58 billion metrics a day and we're still running on MySQL",
    "start": "1909159",
    "end": "1916039"
  },
  {
    "text": "just straight MySQL and we're running on you know generic Linux and we're running on you rout rails 1 N2 you know there",
    "start": "1916039",
    "end": "1924880"
  },
  {
    "text": "there's nothing we didn't do anything magic to get here we just designed in some scalability and then and then",
    "start": "1924880",
    "end": "1930240"
  },
  {
    "text": "iterated to get there what we did do is we used the unique characteristics of our application to optimize what we're",
    "start": "1930240",
    "end": "1935799"
  },
  {
    "text": "doing for instance um when we have our database tables we've got two types of",
    "start": "1935799",
    "end": "1940919"
  },
  {
    "text": "data like I said we've got our rate relational data like our account data and we've got our time slice data we",
    "start": "1940919",
    "end": "1946159"
  },
  {
    "text": "actually designed our time slice data so that all the information in the time slice is actually stored in the keys of",
    "start": "1946159",
    "end": "1951639"
  },
  {
    "text": "the index so much like when you use a hash table where you have the keys have some value and then you don't actually",
    "start": "1951639",
    "end": "1957480"
  },
  {
    "text": "care what the value in the hash is because all you care was whether a key exists or not we're doing the same thing in the database for the time slice data",
    "start": "1957480",
    "end": "1963720"
  },
  {
    "text": "so that means that in my SQL what we're using is we're using the B tree of the index and not the Onis data storage and",
    "start": "1963720",
    "end": "1970960"
  },
  {
    "text": "as a consequence you never actually have to seek the head over to where the data is stored you just look in the index and",
    "start": "1970960",
    "end": "1976639"
  },
  {
    "text": "so we're using some of those unique characteristics of our data to optimize the way our our um application works and",
    "start": "1976639",
    "end": "1983200"
  },
  {
    "text": "how it stores and accesses the data so um I I know that as the company",
    "start": "1983200",
    "end": "1988480"
  },
  {
    "text": "continues to grow you know we intend to double this number in the next year um we're going to continue scaling",
    "start": "1988480",
    "end": "1993799"
  },
  {
    "text": "horizontally We'll add a few more shards um we're also going to probably have to make some architecture changes so this",
    "start": "1993799",
    "end": "1999080"
  },
  {
    "text": "isn't the end all Beall we we'll probably have to change that using just MySQL to using MySQL and some",
    "start": "1999080",
    "end": "2004600"
  },
  {
    "text": "specialized database underneath and you know there's there's some other changes we'll have to make but that's what I",
    "start": "2004600",
    "end": "2010399"
  },
  {
    "text": "wanted to say and I'm happy to answer questions yes say you boxes presumably",
    "start": "2010399",
    "end": "2016960"
  },
  {
    "start": "2013000",
    "end": "2180000"
  },
  {
    "text": "those processes can't be accessing data in kind of sharded direct data stores",
    "start": "2016960",
    "end": "2022039"
  },
  {
    "text": "because then you have to move the data over as well so what kind of prices allow to move between boxes um well they",
    "start": "2022039",
    "end": "2028399"
  },
  {
    "text": "can they just have to do it indirectly through some service so it's not going to be as efficient um but um you know we",
    "start": "2028399",
    "end": "2034320"
  },
  {
    "text": "have our background processes move and you know as long as they they don't have to be real-time access then we're still",
    "start": "2034320",
    "end": "2039760"
  },
  {
    "text": "fine right um I mean we suffer a little bit because we don't have the stor the storage is direct access so you have to",
    "start": "2039760",
    "end": "2045440"
  },
  {
    "text": "go through that machine but it turns out not to be such a big problem so you do allow access to data on other boxes",
    "start": "2045440",
    "end": "2051118"
  },
  {
    "text": "faros yeah you about excuse me you talked",
    "start": "2051119",
    "end": "2057079"
  },
  {
    "text": "about doing computation in a database you just using some simple store props and figur and things yeah the",
    "start": "2057079",
    "end": "2062280"
  },
  {
    "text": "computation we do in the Bas database is really simple right it's just what you can do with SQL statements right and",
    "start": "2062280",
    "end": "2067560"
  },
  {
    "text": "again it's a characteristic of our application which lets us do that we're not we're not doing sophisticated computation it's just that rather than",
    "start": "2067560",
    "end": "2074200"
  },
  {
    "text": "just selecting the raw data and doing the computation on the on the app server side which is sort of a standard model",
    "start": "2074200",
    "end": "2080000"
  },
  {
    "text": "we we chose to do as much computation as we can get away with in the database layer to reduce the number of rows we",
    "start": "2080000",
    "end": "2085440"
  },
  {
    "text": "have to bring over reduce the memory turn of the Ruby garbage collector and that sort of thing given the that you",
    "start": "2085440",
    "end": "2091440"
  },
  {
    "text": "you have hit some issues around the Ruby memory management and all those sorts of things if you're starting you again",
    "start": "2091440",
    "end": "2097280"
  },
  {
    "text": "today would you have picked Ruby as your platform for Building initi Services well it's it's an interesting",
    "start": "2097280",
    "end": "2104599"
  },
  {
    "text": "question because we've managed to get to where we are today using Ruby right so the question is is there a way to have",
    "start": "2104599",
    "end": "2111960"
  },
  {
    "text": "gotten here without using Ruby and yes but not with the people that we have",
    "start": "2111960",
    "end": "2118200"
  },
  {
    "text": "right I mean we've got a bunch of people who are very good at doing Ruby and so continuing to do Ruby is a good model",
    "start": "2118200",
    "end": "2124560"
  },
  {
    "text": "there now you know as we've grown and we've specialized certain Services the new Services we are choosing some other",
    "start": "2124560",
    "end": "2130800"
  },
  {
    "text": "language and we hire people who are good at that particular thing to do to do that um you know you know would I if I",
    "start": "2130800",
    "end": "2137880"
  },
  {
    "text": "was starting over would I use Ruby um I guess it depends a lot with the people that I was starting with because at the",
    "start": "2137880",
    "end": "2143599"
  },
  {
    "text": "beginning of the company's existence the real question was would anybody pay for this right was it was it a reasonable",
    "start": "2143599",
    "end": "2148680"
  },
  {
    "text": "business model and so optimizing for scale or performance and so on at that point would would have been a stupid move we needed to optimize for getting",
    "start": "2148680",
    "end": "2155400"
  },
  {
    "text": "the idea out in front of people and finding out whether people would pay now um you know like when I worked at Amazon",
    "start": "2155400",
    "end": "2161079"
  },
  {
    "text": "we had the whole thing was in C and it's now you know a bunch of services that are in a wide variety of languages and they've done a good job with that and so",
    "start": "2161079",
    "end": "2167599"
  },
  {
    "text": "I expect that sometime in new relics life in the not too distant future we're going to have to do a similar breakup",
    "start": "2167599",
    "end": "2172760"
  },
  {
    "text": "where we're breaking the services up to be not just a Ruby system but a number of different systems we just haven't",
    "start": "2172760",
    "end": "2178400"
  },
  {
    "text": "gotten to that point yet yeah so the more General uh version",
    "start": "2178400",
    "end": "2183680"
  },
  {
    "start": "2180000",
    "end": "2620000"
  },
  {
    "text": "of of that question is uh what um you should you talk about about some things that you did that you think were good",
    "start": "2183680",
    "end": "2191280"
  },
  {
    "text": "parts of growing business and scaling what what got in the way what choices you make early on that you're like man",
    "start": "2191280",
    "end": "2197599"
  },
  {
    "text": "should not have done that like that was just",
    "start": "2197599",
    "end": "2204400"
  },
  {
    "text": "um well there's certainly some Personnel decisions we made that we wish we hadn't made um but",
    "start": "2204480",
    "end": "2212280"
  },
  {
    "text": "technically you know again I'm going to sort of waffle on this question of what things wouldn't we have done technically",
    "start": "2212280",
    "end": "2219000"
  },
  {
    "text": "because again we wouldn't be here if we hadn't done things the way we did so so the question you know could we have",
    "start": "2219000",
    "end": "2225760"
  },
  {
    "text": "gotten here by not making some of the decisions um the decision I think early",
    "start": "2225760",
    "end": "2230800"
  },
  {
    "text": "on to use MySQL and only MySQL has cost us a lot more development time than we",
    "start": "2230800",
    "end": "2236440"
  },
  {
    "text": "probably would have preferred right but once we'd started down that path the sunk cost of continu you know of",
    "start": "2236440",
    "end": "2243280"
  },
  {
    "text": "continuing was better than redoing it again um but perhaps if I did it again I",
    "start": "2243280",
    "end": "2249200"
  },
  {
    "text": "you know I would choose to do um a different technology for the time slice data perhaps um but but overall I think",
    "start": "2249200",
    "end": "2256680"
  },
  {
    "text": "we're pretty happy with the technical decisions that we made and there's there's nothing out there that's really",
    "start": "2256680",
    "end": "2261920"
  },
  {
    "text": "causing us a lot of pain technically in the product right now yeah so since you",
    "start": "2261920",
    "end": "2267839"
  },
  {
    "text": "kind of briefly mentioned that maybe you would be using another database below is that you been considering toku Tech",
    "start": "2267839",
    "end": "2274720"
  },
  {
    "text": "because they actually turn sequential ACC es into random accesses into sequential",
    "start": "2274720",
    "end": "2281839"
  },
  {
    "text": "accesses yeah um I think what we'll end up doing is uh writing our own because a",
    "start": "2281839",
    "end": "2288280"
  },
  {
    "text": "number of the people we have in the company have done that in the past for exactly this data problem um in previous",
    "start": "2288280",
    "end": "2294000"
  },
  {
    "text": "companies and so we we really have a lot of experience in exactly the piece that we need there um I I think that's what",
    "start": "2294000",
    "end": "2301400"
  },
  {
    "text": "we end up I I don't actually know at the moment yeah so you mentioned uh that VMS were hurting you or virtualization was",
    "start": "2301400",
    "end": "2308520"
  },
  {
    "text": "hurting it was that when running in in a",
    "start": "2308520",
    "end": "2313680"
  },
  {
    "text": "in an elastic environment like Amazon or is that when running virtual machines on",
    "start": "2313680",
    "end": "2319000"
  },
  {
    "text": "top of physical your own physical Hardware where you actually do know all",
    "start": "2319000",
    "end": "2326240"
  },
  {
    "text": "the yeah so the the virtualization was hurting us with our particular performance characteristics whether it",
    "start": "2326240",
    "end": "2332280"
  },
  {
    "text": "was our own Hardware or whether it was Amazon's Hardware or whether it was re space or you know any one of these",
    "start": "2332280",
    "end": "2337599"
  },
  {
    "text": "virtualization providers um there's just a number of characteristics that just don't fit well with this High throughput",
    "start": "2337599",
    "end": "2343880"
  },
  {
    "text": "data right model right and if you look at some other people who've done this they've used a hybrid model where they",
    "start": "2343880",
    "end": "2349920"
  },
  {
    "text": "have a raw metal version of their right throughput data and then they have a virtualized layer to do the application",
    "start": "2349920",
    "end": "2356359"
  },
  {
    "text": "server and we could easily do that except that we you know we we just chose put on Raw metal um instead we I mean we",
    "start": "2356359",
    "end": "2362280"
  },
  {
    "text": "still use virtualization for a number of the things in the in the company but not the the main application and it didn't",
    "start": "2362280",
    "end": "2368560"
  },
  {
    "text": "matter whether it was our own or or whatever Rel question I've seen that",
    "start": "2368560",
    "end": "2374160"
  },
  {
    "text": "before where virtualization especially with packet ingestion the next step in not is",
    "start": "2374160",
    "end": "2380160"
  },
  {
    "text": "actually pin your CPUs and choose where your IO is going to the CPUs and CPUs are consuming that and you can see",
    "start": "2380160",
    "end": "2387160"
  },
  {
    "text": "magnitude difference have you gone to doing that we didn't try that um but",
    "start": "2387160",
    "end": "2392280"
  },
  {
    "text": "that that would be something to try him yeah com to see that you can do",
    "start": "2392280",
    "end": "2398960"
  },
  {
    "text": "large big data and don't have little big data",
    "start": "2398960",
    "end": "2404599"
  },
  {
    "text": "that but using no not using no because it's not e you to do it with just",
    "start": "2404960",
    "end": "2411599"
  },
  {
    "text": "content don't have to do high yeah I mean you know it's it's not",
    "start": "2411599",
    "end": "2416720"
  },
  {
    "text": "that it's uh trivial I mean we' spent a lot of time building this stuff and and optimizing these things and and looking",
    "start": "2416720",
    "end": "2423560"
  },
  {
    "text": "at the characteristics of our application and tuning my SQL and so on but you know there's there's a lot of",
    "start": "2423560",
    "end": "2428599"
  },
  {
    "text": "solutions to these problems and you don't you don't have to go and um build something custom you can sort of evolve",
    "start": "2428599",
    "end": "2433880"
  },
  {
    "text": "your way there yeah no so so your your your",
    "start": "2433880",
    "end": "2440040"
  },
  {
    "text": "question there and I'm repeating it for the video is um in ssds you know don't",
    "start": "2440040",
    "end": "2445240"
  },
  {
    "text": "you have a charact don't you have a problem where there's an only a certain number of Cycles you can do before the dis dies um and the answer to that is",
    "start": "2445240",
    "end": "2452079"
  },
  {
    "text": "two parts one is um it's the number of writs that you do that costs you not the number of reads um and so one of the",
    "start": "2452079",
    "end": "2458319"
  },
  {
    "text": "nice things about our data is it's write once and read many times and so it fits very naturally with the SSD model um and",
    "start": "2458319",
    "end": "2465280"
  },
  {
    "text": "the second is that the um the cost tradeoff in the business of even let's",
    "start": "2465280",
    "end": "2471400"
  },
  {
    "text": "say the ssds only last us for a year before we have to replace them it's still such a win in terms of not having",
    "start": "2471400",
    "end": "2477040"
  },
  {
    "text": "to do other things in the application that we would be willing to pay for ssds that only lasted a year um it turns out",
    "start": "2477040",
    "end": "2482960"
  },
  {
    "text": "it looks like from our modeling and our testing that the ssds are going to last us about three years each and by then",
    "start": "2482960",
    "end": "2488119"
  },
  {
    "text": "you know who knows what the technology will be Quantum discs or something so so the your your question is do we maintain",
    "start": "2488119",
    "end": "2494160"
  },
  {
    "text": "decent performance in the back end when we have these large customers like 17,000 applications um I guess it depends on what you mean by the back end",
    "start": "2494160",
    "end": "2501079"
  },
  {
    "text": "right so right so we've we've spent some time so the nice thing about um being the customer who's who has 177,000",
    "start": "2501079",
    "end": "2507280"
  },
  {
    "text": "servers is that you're paying us a lot of money and so we spend a lot of time paying attention to you um and uh so",
    "start": "2507280",
    "end": "2515000"
  },
  {
    "text": "we've spent a fair amount of time optimizing our application to deal with the case of like 17,000 servers so",
    "start": "2515000",
    "end": "2521040"
  },
  {
    "text": "things like pre-computing some of those queries so that on the disc instead of having or on the database instead of",
    "start": "2521040",
    "end": "2526920"
  },
  {
    "text": "having to go to 177,000 rows to get a minute's worth of data we don't have to go to one row to get a minute's worth of data because we've pre-computed the fact",
    "start": "2526920",
    "end": "2533520"
  },
  {
    "text": "that we know we're going to have to do that particular query and so a lot of these these um application optimizations",
    "start": "2533520",
    "end": "2540240"
  },
  {
    "text": "have been because of our large customers and you know we monitor our own site and we go gosh looks like customer X is",
    "start": "2540240",
    "end": "2546040"
  },
  {
    "text": "starting to have a a bad experience what can we do to go in and and fix that up and and make the performance better",
    "start": "2546040",
    "end": "2551680"
  },
  {
    "text": "there and you know it's not just adding an index to a database table it's well you might actually have to modify the application to do things differently",
    "start": "2551680",
    "end": "2558000"
  },
  {
    "text": "like move a computation to a different layer of the of the service or something so do you that the data is like a",
    "start": "2558000",
    "end": "2564280"
  },
  {
    "text": "massive serialized object or something and then pull that out like say the information fall one",
    "start": "2564280",
    "end": "2571319"
  },
  {
    "text": "minute um so we actually just store all the data in the same database tables um just with a different types of keys that",
    "start": "2571319",
    "end": "2577720"
  },
  {
    "text": "you know are sort of magic keys that we've said well this is a roll up row and it rolls up the following types of",
    "start": "2577720",
    "end": "2583000"
  },
  {
    "text": "information um and so it's just all stored in the same table and so then it's easy to do that non-garbage",
    "start": "2583000",
    "end": "2588119"
  },
  {
    "text": "collection garbage collection when you it's no longer a rent needed and so on um it's just we we actually just store",
    "start": "2588119",
    "end": "2594480"
  },
  {
    "text": "it in the same table we don't we don't build special because our our aggregations um are just producing",
    "start": "2594480",
    "end": "2599640"
  },
  {
    "text": "aggregations or pre-computations of this the same data output right it's not it's not an aggregation that looks different",
    "start": "2599640",
    "end": "2605559"
  },
  {
    "text": "it's just a pre-computation of the same result that you would get if you'd done the query um live well thank you very",
    "start": "2605559",
    "end": "2612160"
  },
  {
    "text": "much appreciate your time",
    "start": "2612160",
    "end": "2616680"
  }
]
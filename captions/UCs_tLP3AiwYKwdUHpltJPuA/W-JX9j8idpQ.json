[
  {
    "start": "0",
    "end": "147000"
  },
  {
    "text": "[Music]",
    "start": "3500",
    "end": "7820"
  },
  {
    "text": "good to see everyone uh big room so hopefully you guys can hear me at the back with the mic um move forward if you",
    "start": "12400",
    "end": "19720"
  },
  {
    "text": "if you have any issues but uh I'm going to talk to you about prompt engineering and it's a field that you know has only",
    "start": "19720",
    "end": "26199"
  },
  {
    "text": "really existed for like four years maybe I started to get interesting uh but I've",
    "start": "26199",
    "end": "31359"
  },
  {
    "text": "been in the field for all four of those years uh cuz I uh come from a marketing",
    "start": "31359",
    "end": "36440"
  },
  {
    "text": "background uh you know I I basically got into AI when gpt3 came out and uh was",
    "start": "36440",
    "end": "42680"
  },
  {
    "text": "like kicking around with nothing to do and just uh messed around with it and and now I'm working in it full-time so",
    "start": "42680",
    "end": "48480"
  },
  {
    "text": "hopefully I'll be able to give you guys a bit of a flavor of uh how it actually gets into production because I think",
    "start": "48480",
    "end": "55000"
  },
  {
    "text": "that talking to a bunch of people um there's a lot of hype in AI and um you",
    "start": "55000",
    "end": "61039"
  },
  {
    "text": "know there's a lot of cool demos that you can do but it's a really big difference between a demo or a prototype",
    "start": "61039",
    "end": "66159"
  },
  {
    "text": "and then something that's actually working you know with real users so that's what I'm going to try and focus on try to make it as practical as",
    "start": "66159",
    "end": "72280"
  },
  {
    "text": "possible sharing some of the insights that I've had uh working on some of these projects um so like we was saying",
    "start": "72280",
    "end": "77840"
  },
  {
    "text": "before uh if you guys download the app if you haven't already uh then you can submit questions through there and then",
    "start": "77840",
    "end": "84159"
  },
  {
    "text": "also give me a rating at the end uh whether you're happy or not right um so",
    "start": "84159",
    "end": "89240"
  },
  {
    "text": "I come from a marketing background I left my marketing agency in 2020 which is why I had a bit of time to mess",
    "start": "89240",
    "end": "95399"
  },
  {
    "text": "around uh really good timing uh it was during covid lockdowns in the UK um I",
    "start": "95399",
    "end": "100600"
  },
  {
    "text": "know that uh there's kind of various uh situations in the US but uh for us uh",
    "start": "100600",
    "end": "106000"
  },
  {
    "text": "had nothing to do but mess around with AI which was quite nice um and then um you know since then I've created online",
    "start": "106000",
    "end": "112040"
  },
  {
    "text": "courses about Ai and and marketing uh seen by 400,000 people I think it's",
    "start": "112040",
    "end": "117280"
  },
  {
    "text": "450,000 now uh so we have the top udemy course on prompt engineering 120,000",
    "start": "117280",
    "end": "123520"
  },
  {
    "text": "people have taken that one specifically um and then I just published a book with O'Reilly which is pretty cool because uh",
    "start": "123520",
    "end": "130080"
  },
  {
    "text": "I learned how to code by reading O'Reilly book so that was quite a fun experience I know there's a bunch of O'Reilly authors here as well um so I",
    "start": "130080",
    "end": "137760"
  },
  {
    "text": "actually have a workshop tomorrow where um you know if you attend that I think there's some spaces left you get a free",
    "start": "137760",
    "end": "143599"
  },
  {
    "text": "copy of the book um so check that out if you're interested uh so what are we going to cover I got the jup notebook here so you",
    "start": "143599",
    "end": "151280"
  },
  {
    "start": "147000",
    "end": "265000"
  },
  {
    "text": "guys can take a look at this afterwards if you code and you want to um you know kind of mess around with some of this stuff uh so don't feel like you have to",
    "start": "151280",
    "end": "157720"
  },
  {
    "text": "take a bunch of notes um I'm going to share these slides afterwards with bente so you guys should get this um and uh",
    "start": "157720",
    "end": "164319"
  },
  {
    "text": "you know also I'll put uh some way to contact me and there if uh if you have any questions or you want me to elaborate on anything we're going to go",
    "start": "164319",
    "end": "171120"
  },
  {
    "text": "through the five principles of prompting this is kind of like a checklist I had to develop uh when I was writing the book Because when you're writing about",
    "start": "171120",
    "end": "177800"
  },
  {
    "text": "Ai and it's going to print uh and then everything changes every single week that's a real problem um you know so",
    "start": "177800",
    "end": "184120"
  },
  {
    "text": "what we had to do is really think about what are the things that worked back when gpt3 was around and still worked",
    "start": "184120",
    "end": "190080"
  },
  {
    "text": "after GPT 4 came out and then plot ahead and kind of say what are the things that will continue to work um you know with",
    "start": "190080",
    "end": "196239"
  },
  {
    "text": "GPT 5 GPT 6 Etc or whatever model we're using in the future and the the really interesting thing is that uh a lot of",
    "start": "196239",
    "end": "203760"
  },
  {
    "text": "the insights we found through that process um really applied from back when I was running a marketing agency",
    "start": "203760",
    "end": "209280"
  },
  {
    "text": "managing 50 people uh the same sort of things that make you a good manager uh also make you a good prompt engineer",
    "start": "209280",
    "end": "215480"
  },
  {
    "text": "which um we'll talk about a little bit more detail so going to run through those and you can kind of treat that as a you know actionable checklist you can",
    "start": "215480",
    "end": "222080"
  },
  {
    "text": "go away today and make your prompt uh ready for production uh once you run through these five steps I'm also going",
    "start": "222080",
    "end": "227560"
  },
  {
    "text": "to talk about what happens after you get to production so these are three kind of um recurring uh Day in the Life type",
    "start": "227560",
    "end": "234439"
  },
  {
    "text": "activities AB testing prompts uh using DSP like an automated optim ER I'm going",
    "start": "234439",
    "end": "240319"
  },
  {
    "text": "to kind of show you an example there um and then also doing fine tuning uh of your you know to create a new model uh",
    "start": "240319",
    "end": "246720"
  },
  {
    "text": "that you can use in production uh and then we're going to finish on the business case for prompting hopefully kind of convince you guys that it's not",
    "start": "246720",
    "end": "253439"
  },
  {
    "text": "all about building these Foundation models actually a lot of the heavy lifting and a lot of the stuff that",
    "start": "253439",
    "end": "258680"
  },
  {
    "text": "makes you know uh AI products work in production is really at the prompting",
    "start": "258680",
    "end": "264479"
  },
  {
    "text": "level cool so what is prompt engineering uh this is a naive prompt is it's what I",
    "start": "264479",
    "end": "269759"
  },
  {
    "start": "265000",
    "end": "674000"
  },
  {
    "text": "always start with if you're trying to do a task like in this case a summarization task um you want to basically start with",
    "start": "269759",
    "end": "276800"
  },
  {
    "text": "the simplest possible prompt like what would uh you you just type into chat gbt",
    "start": "276800",
    "end": "282759"
  },
  {
    "text": "and if that works uh then great you're finished you don't need prompt engineering and actually 80 90% of the",
    "start": "282759",
    "end": "288039"
  },
  {
    "text": "time you don't need prompt engineering um it's it might be Overkill especially because these models are so good now you",
    "start": "288039",
    "end": "293840"
  },
  {
    "text": "know back when we used gpt3 I had to use all sorts of tricks and hacks to get it working and I would say that as the",
    "start": "293840",
    "end": "299919"
  },
  {
    "text": "models get better the you know more often it just works out of the box um when you need prompt engineering is when",
    "start": "299919",
    "end": "305960"
  },
  {
    "text": "you're going to be running this a lot of times so you're going to run it thousands of times hundred you know millions of times in some cases in",
    "start": "305960",
    "end": "312320"
  },
  {
    "text": "production um and you need it to be able to work reliably every time so just a",
    "start": "312320",
    "end": "317360"
  },
  {
    "text": "kind of a little hack here by the way it's quite fun if you put um r.g. in",
    "start": "317360",
    "end": "323000"
  },
  {
    "text": "front of a URL it gives you um uh a nice uh markdown uh text uh from the URL so",
    "start": "323000",
    "end": "330280"
  },
  {
    "text": "it scrapes the URL and gives you the text um so it's really good for AI inputs like if you're going to be um",
    "start": "330280",
    "end": "336319"
  },
  {
    "text": "kind of reading different landing pages uh so uh so that's that's what we've done here so we're just getting this is",
    "start": "336319",
    "end": "342240"
  },
  {
    "text": "an an article that we wanted to summarize um and we're just getting the markdown text that we can then put into",
    "start": "342240",
    "end": "348199"
  },
  {
    "text": "the prompt and um you know when when it comes to prompt engineering typically",
    "start": "348199",
    "end": "354039"
  },
  {
    "text": "I'm doing that in a jupyter notebook um I know that you know a lot of people will use chat GPT and call that prompt",
    "start": "354039",
    "end": "361000"
  },
  {
    "text": "engineering um uh I think I would say that um that's just prompting right like",
    "start": "361000",
    "end": "366680"
  },
  {
    "text": "if you're not uh running a script um or you're not kind of doing it at scale for something that you want to put into",
    "start": "366680",
    "end": "371759"
  },
  {
    "text": "production whether it's an internal tool or an external tool um you know it's using principles of prompt engineering",
    "start": "371759",
    "end": "377280"
  },
  {
    "text": "potentially um and a lot of the stuff is actually useful for non-technical people um but I try and Reserve that term like",
    "start": "377280",
    "end": "384520"
  },
  {
    "text": "if it's got the word Engineering in it you kind of need to be you know doing it at scale um or at least making",
    "start": "384520",
    "end": "390199"
  },
  {
    "text": "uh the the thing you're doing more scalable um so uh I start with jup notebooks um I usually write simple",
    "start": "390199",
    "end": "396680"
  },
  {
    "text": "script just to call the base native API I don't use a lot of Frameworks like Lang chain a few others uh they are good",
    "start": "396680",
    "end": "403759"
  },
  {
    "text": "and they do have their place but um I would say you want to really keep the you know keep the thing simple at first",
    "start": "403759",
    "end": "410280"
  },
  {
    "text": "um and then once you know what works then you can go for the abstractions uh that you might want to be using in production um because uh these models",
    "start": "410280",
    "end": "418000"
  },
  {
    "text": "change so often and because you're tool will probably change quite a bit uh on the path to production you want to keep",
    "start": "418000",
    "end": "423560"
  },
  {
    "text": "this Tex stack as simple as possible when you're doing R&D um so this is just",
    "start": "423560",
    "end": "428720"
  },
  {
    "text": "a simple uh you know uh function that I wrote um actually I didn't even write",
    "start": "428720",
    "end": "433800"
  },
  {
    "text": "these functions anymore I I used to trying to keep one and keep using in every project and now I just use cursor",
    "start": "433800",
    "end": "440720"
  },
  {
    "text": "it's an AI kind of um version Fork of vs code uh if you guys have used that and I",
    "start": "440720",
    "end": "446560"
  },
  {
    "text": "just say you know at open AI document mentation cuz you can pull in the documentation with that tool and then",
    "start": "446560",
    "end": "453400"
  },
  {
    "text": "I'll say just write me a function to call open AI so I don't even have to think about this anymore it's not",
    "start": "453400",
    "end": "458479"
  },
  {
    "text": "something I worry about um and and you know for throwaway code like this when you're doing R&D is not something you really need to think about that's one of",
    "start": "458479",
    "end": "465039"
  },
  {
    "text": "the like when you're not in production don't adopt all of the uh overheads that come with production right when you're",
    "start": "465039",
    "end": "470840"
  },
  {
    "text": "doing R&D you want to keep it really Scrappy um so here we're just putting in the naive prompt um and then that's",
    "start": "470840",
    "end": "477120"
  },
  {
    "text": "going of be our Baseline and this is what the response looks like uh so the summaries are actually pretty decent um",
    "start": "477120",
    "end": "484560"
  },
  {
    "text": "one problem that you have with summarization tasks is that you tend to lose all of the intent of the original",
    "start": "484560",
    "end": "490639"
  },
  {
    "text": "author um so it sounds very boring it sounds like AI uh if you read that right",
    "start": "490639",
    "end": "495800"
  },
  {
    "text": "um and this article was quite politically um motivated right and um we're not going to get into politics I",
    "start": "495800",
    "end": "501759"
  },
  {
    "text": "know the election is like a few uh weeks away um so I wouldn't want",
    "start": "501759",
    "end": "507400"
  },
  {
    "text": "to uh get into that topic but uh but in particular um you know what one thing",
    "start": "507400",
    "end": "513959"
  },
  {
    "text": "that is bad is if you lose some of that semantic information um you know if the original article was really in favor of",
    "start": "513959",
    "end": "520518"
  },
  {
    "text": "one candidate um or really against another candidate you actually want to maintain that in the summary because uh",
    "start": "520519",
    "end": "526680"
  },
  {
    "text": "you know this is this is actually a bad thing I think if you if you debias some text um uh then uh then you're losing",
    "start": "526680",
    "end": "533880"
  },
  {
    "text": "some of the initial intent of the what the author was trying to get across um so whichever side uh you're on uh so",
    "start": "533880",
    "end": "541120"
  },
  {
    "text": "this is an example of what we're going to work towards this is a you know prompt engineered example like can optimized response um and this took",
    "start": "541120",
    "end": "548440"
  },
  {
    "text": "several iterations uh but it's already much better so uh you can see that a lot of the bias of the original article uh",
    "start": "548440",
    "end": "556279"
  },
  {
    "text": "is now maintained so you know this is um kind of keeping a lot of the intent and",
    "start": "556279",
    "end": "561480"
  },
  {
    "text": "the semantics and the words that were used in the original article um but it's also adding a couple of other layers",
    "start": "561480",
    "end": "568000"
  },
  {
    "text": "here so we have some checking right like we have some kind of lookups being done",
    "start": "568000",
    "end": "573200"
  },
  {
    "text": "um you know with another AI service which I'm going to kind of talk to you about um so this is a much better",
    "start": "573200",
    "end": "578560"
  },
  {
    "text": "summary for the use case that I was working on this for um obviously I'm not sharing the exact use case for this",
    "start": "578560",
    "end": "584160"
  },
  {
    "text": "client I'm you know ndas Etc but um but you know this is kind of like a you know a toy version of the problem that we're",
    "start": "584160",
    "end": "590279"
  },
  {
    "text": "solving so uh you know how do we get from the first example that we saw the naive response uh which sounded like Ai",
    "start": "590279",
    "end": "597320"
  },
  {
    "text": "and wasn't that great uh to this response where we have multiple layers of things happening um well the answer",
    "start": "597320",
    "end": "603560"
  },
  {
    "text": "is prompt engineering and and typically when uh someone looks at AI uh on social",
    "start": "603560",
    "end": "609600"
  },
  {
    "text": "media and they say wow that prototype looks great uh but I'm not getting those results myself I tried it and it doesn't",
    "start": "609600",
    "end": "615800"
  },
  {
    "text": "work um it's usually because I'm not using prompt engineering that's usually the major difference between these wow",
    "start": "615800",
    "end": "622600"
  },
  {
    "text": "kind of demos that you see um and then what uh you know in papers in you know on on Twitter Etc um and uh and like the",
    "start": "622600",
    "end": "629880"
  },
  {
    "text": "first time you try the tool and don't get the same results uh so uh you my definition here",
    "start": "629880",
    "end": "636040"
  },
  {
    "text": "is that basically prompt engineering is this process it's um it's you know where you're trying to discover a prompt that",
    "start": "636040",
    "end": "643240"
  },
  {
    "text": "reliably yields results and reliability is uh the key here because when you're",
    "start": "643240",
    "end": "649800"
  },
  {
    "text": "having a prompt in production uh because AI always gives you a different result",
    "start": "649800",
    "end": "654880"
  },
  {
    "text": "every time you run it um and those results can sometimes be really bad uh and and and things that your users would",
    "start": "654880",
    "end": "661800"
  },
  {
    "text": "complain about uh you might have legislative um responsibilities and ethical concerns um so it's really",
    "start": "661800",
    "end": "668680"
  },
  {
    "text": "really important that you've tested this prompt thoroughly before you deploy it with real users uh so what are the five principles",
    "start": "668680",
    "end": "675680"
  },
  {
    "start": "674000",
    "end": "696000"
  },
  {
    "text": "of prompting this is uh my checklist I run through every time um thankfully",
    "start": "675680",
    "end": "680839"
  },
  {
    "text": "most of the time you don't have to go through all five uh because these models are so good and getting better all the",
    "start": "680839",
    "end": "686720"
  },
  {
    "text": "time like every 3 to 6 months uh we see a major lead forward uh you you hopefully only need to do one or two of",
    "start": "686720",
    "end": "693040"
  },
  {
    "text": "these before you get uh good results um but the first one I always try is to",
    "start": "693040",
    "end": "698240"
  },
  {
    "start": "696000",
    "end": "822000"
  },
  {
    "text": "give the uh give some direction give some instructions um in the prompt um and this is the easiest to do um because",
    "start": "698240",
    "end": "705639"
  },
  {
    "text": "typically you have some idea of what is wrong uh when you run that naive prompt",
    "start": "705639",
    "end": "710920"
  },
  {
    "text": "um so straight away I can just say hey the thing that's wrong here is that it's not preserving the Nuance of the",
    "start": "710920",
    "end": "716720"
  },
  {
    "text": "author's intended tone um so that that's the instruction I added in it doesn't have to be super complicated obviously",
    "start": "716720",
    "end": "723639"
  },
  {
    "text": "you get different results uh when you word this in different ways and uh you can spend a lot of time really just",
    "start": "723639",
    "end": "729519"
  },
  {
    "text": "writing and rewriting instructions uh in order to get to something that actually kind of follows what you're what you're",
    "start": "729519",
    "end": "735480"
  },
  {
    "text": "hoping to get um but you know in in general um you know this is a case of just iterating and saying okay well",
    "start": "735480",
    "end": "741920"
  },
  {
    "text": "what's wrong with it and then let let's add that let's address that in the initial instructions uh quite often",
    "start": "741920",
    "end": "748519"
  },
  {
    "text": "you're doing role prompting in this step uh so you could say like you know as a journalist uh you know I didn't do this",
    "start": "748519",
    "end": "755279"
  },
  {
    "text": "in uh in this section but you could say like as a famous journalist like maybe you can specifically name the journalist",
    "start": "755279",
    "end": "761440"
  },
  {
    "text": "uh someone that the AI would know about um I I want you to summarize this article um so if you said like as Rachel",
    "start": "761440",
    "end": "767519"
  },
  {
    "text": "madow potentially it would preserve some of her initial kind of uh tone or if you said you know um as brat bear you know",
    "start": "767519",
    "end": "775639"
  },
  {
    "text": "something you could get a completely different uh tone uh so that's kind of a shortcut but what I like to do is I like",
    "start": "775639",
    "end": "782399"
  },
  {
    "text": "to describe specifically what I like about say Rachel matow or Brett bear um like what what is it about their style",
    "start": "782399",
    "end": "789079"
  },
  {
    "text": "that um the AI should emulate uh because uh if you're just copying someone's",
    "start": "789079",
    "end": "794120"
  },
  {
    "text": "style specifically they might have some aspects that you don't like that you don't want uh so if you break that style",
    "start": "794120",
    "end": "799360"
  },
  {
    "text": "down um then I I tend to find you have a little bit more flexibility uh cool so uh with just that",
    "start": "799360",
    "end": "805959"
  },
  {
    "text": "change uh this is the response that we're getting um and it is much better I won't you know make you read a block of",
    "start": "805959",
    "end": "811440"
  },
  {
    "text": "text uh but you can trust me or you can read it afterwards um you know when you get the PDF um but it actually does uh",
    "start": "811440",
    "end": "818480"
  },
  {
    "text": "keep a little bit more of the initial intent of the author so the next thing I move on to",
    "start": "818480",
    "end": "824079"
  },
  {
    "start": "822000",
    "end": "1014000"
  },
  {
    "text": "and this is the most important one I think for production uh is the format uh you want to Output a specific structure",
    "start": "824079",
    "end": "832040"
  },
  {
    "text": "data structure you want to Output a specific um you know set of uh things uh",
    "start": "832040",
    "end": "838199"
  },
  {
    "text": "maybe variables that you can be using uh dumping into your database or you know saving their spreadsheet or um",
    "start": "838199",
    "end": "844800"
  },
  {
    "text": "displaying on a web page uh so uh you know that tends to be the next thing that people work on and thankfully this",
    "start": "844800",
    "end": "850560"
  },
  {
    "text": "has gotten a lot easier uh models like the foundation models uh the latest state-of-the-art models are really good",
    "start": "850560",
    "end": "856959"
  },
  {
    "text": "at following these instructions now they have things like Json mode where you can guarantee that it's always going to give",
    "start": "856959",
    "end": "862279"
  },
  {
    "text": "you back Json uh so that's um a little bit less uh difficult but um where I use",
    "start": "862279",
    "end": "868920"
  },
  {
    "text": "the the specified format principle is in really kind of guiding the model to um",
    "start": "868920",
    "end": "874720"
  },
  {
    "text": "you know the way I want it to think about the specific problem uh so in this case I'm using somewhat of a Chain of",
    "start": "874720",
    "end": "881360"
  },
  {
    "text": "Thought method if you guys have heard that technique um it's it's what powers the latest model with uh chat GPT the o1",
    "start": "881360",
    "end": "889199"
  },
  {
    "text": "preview model uh the reasoning model uh is that that's kind of been trained into it but before that it was a prompt",
    "start": "889199",
    "end": "894800"
  },
  {
    "text": "engineering technique you tell it to think step by step through the problem first kind of make a plan do some",
    "start": "894800",
    "end": "900680"
  },
  {
    "text": "thinking first before answering the question and uh this is a very generalizable technique that you can use",
    "start": "900680",
    "end": "906240"
  },
  {
    "text": "in pretty much any prompt and the reason it works is the same reason it works with me and you right like I didn't just",
    "start": "906240",
    "end": "912720"
  },
  {
    "text": "Wing this presentation I came up with a plan of what I'm going to tell you first and uh that made sure that I was very",
    "start": "912720",
    "end": "918759"
  },
  {
    "text": "comprehensive with my results um you know it helped me make sure that it was going to be an interesting presentation",
    "start": "918759",
    "end": "924920"
  },
  {
    "text": "hopefully uh you will agree um and uh and you know because that works with does we spend some thinking Time ahead",
    "start": "924920",
    "end": "930800"
  },
  {
    "text": "of time to plan out what we're going to do and how we're going to approach a problem um then you know that also works for llms CU they are in effect trying to",
    "start": "930800",
    "end": "938079"
  },
  {
    "text": "simulate the way that we think uh although imperfectly uh so the way that I",
    "start": "938079",
    "end": "943240"
  },
  {
    "text": "specifically implemented this here is I just asked it to list three to five key takeaways I found that that maintained a",
    "start": "943240",
    "end": "949440"
  },
  {
    "text": "bit more of the semantic information the main points otherwise the summary kind of condenses and you lose some of the",
    "start": "949440",
    "end": "954920"
  },
  {
    "text": "important things that um you know that the article was saying so when it list the three to five key takeaways first um",
    "start": "954920",
    "end": "962519"
  },
  {
    "text": "then the summary ended up being much better much more comprehensive which is really helpful and uh you can see in the",
    "start": "962519",
    "end": "969279"
  },
  {
    "text": "response here we are getting Json we're getting the key points first and then we get the summary and this is also really",
    "start": "969279",
    "end": "975160"
  },
  {
    "text": "helpful for debugging uh because you know llm is really hard to debug in general like you don't want to read a",
    "start": "975160",
    "end": "980360"
  },
  {
    "text": "block of text every time who knows whether that summary is good or this summary is good you get really bored of looking at these things after a while",
    "start": "980360",
    "end": "987040"
  },
  {
    "text": "and you've be doing it for days um so one of the things I found is just looking at the key points I can see if",
    "start": "987040",
    "end": "992720"
  },
  {
    "text": "it captured the main intent of the article um even if I don't know that much about that article allowed me to",
    "start": "992720",
    "end": "999160"
  },
  {
    "text": "kind of test a wider diverse set of test cases which was really helpful because I could quickly scan the key points and go",
    "start": "999160",
    "end": "1005600"
  },
  {
    "text": "it's done something really stupid here uh and therefore or it's missed this completely and therefore I know that the rest of the response is invalid so",
    "start": "1005600",
    "end": "1012560"
  },
  {
    "text": "that's really helpful uh third principle here and this is the most impactful one if you",
    "start": "1012560",
    "end": "1018279"
  },
  {
    "start": "1014000",
    "end": "1229000"
  },
  {
    "text": "remember literally nothing else from this presentation uh the main thing you should know is you should give examples",
    "start": "1018279",
    "end": "1024319"
  },
  {
    "text": "of the task that you're trying to do uh to the llm in the prompt so um you know",
    "start": "1024319",
    "end": "1030918"
  },
  {
    "text": "this is you know there's a ton of literature on this even pregenerative AI uh you know AI researchers or you know",
    "start": "1030919",
    "end": "1038000"
  },
  {
    "text": "machine learning Engineers would always uh look at the results of their models uh based on zero shot or F shot is the",
    "start": "1038000",
    "end": "1045600"
  },
  {
    "text": "terminology they use right so zero shot is could it answer a question without you giving it any examples of how to",
    "start": "1045600",
    "end": "1051720"
  },
  {
    "text": "answer the question um and F shot is where you give it maybe a handful of examples and uh with every AI model",
    "start": "1051720",
    "end": "1059600"
  },
  {
    "text": "including the best AI models uh their zero shot score is always much worse than their few shot score like if you",
    "start": "1059600",
    "end": "1066000"
  },
  {
    "text": "give it a handful of examples it can interpolate between them and kind of understand what it is you like about",
    "start": "1066000",
    "end": "1072080"
  },
  {
    "text": "those responses um and therefore it can guide it uh into doing a better job um",
    "start": "1072080",
    "end": "1077679"
  },
  {
    "text": "and it doesn't have to be the full input and output is one thing I found uh you can actually learn a lot just by giving",
    "start": "1077679",
    "end": "1083640"
  },
  {
    "text": "the output um and this is um you know something that um you know most um you",
    "start": "1083640",
    "end": "1090080"
  },
  {
    "text": "most of the gains I think when you when you see a prompt that's really had a double digigit increase in performance",
    "start": "1090080",
    "end": "1096039"
  },
  {
    "text": "most of the gains come from just adding a lot of few shot examples and working with the domain expert uh to to manually",
    "start": "1096039",
    "end": "1102440"
  },
  {
    "text": "create them um I think that that is usually like the vast majority of the work um because you know if you can give",
    "start": "1102440",
    "end": "1109080"
  },
  {
    "text": "it a few examples it's often a lot easier uh to communicate all of the Nuance of what you want because can you",
    "start": "1109080",
    "end": "1115360"
  },
  {
    "text": "imagine like describing exactly what you like about every single summary and then putting all of that in the instructions",
    "start": "1115360",
    "end": "1121400"
  },
  {
    "text": "it's very manual work quite often you could just select a few examples of summaries that you like um and then",
    "start": "1121400",
    "end": "1127400"
  },
  {
    "text": "stick those into the prompt so um you know that is that is quite helpful uh in this case um I specifically just wrote",
    "start": "1127400",
    "end": "1134039"
  },
  {
    "text": "These manually myself um you know I I generated a couple of examples",
    "start": "1134039",
    "end": "1139360"
  },
  {
    "text": "um from other articles um and then I rewrote them I just kind of edited them to be closer to what I liked um so",
    "start": "1139360",
    "end": "1146159"
  },
  {
    "text": "that's typically what a prompt engineer is doing early on um they might create a few examples themselves based on the",
    "start": "1146159",
    "end": "1151400"
  },
  {
    "text": "brief from the client but typically you want to get a domain expert in there someone who's an expert in summarization",
    "start": "1151400",
    "end": "1156880"
  },
  {
    "text": "or you know maybe even just like the you know the product manager or the CEO uh someone who understands the business",
    "start": "1156880",
    "end": "1163480"
  },
  {
    "text": "case uh for what this product needs to do um or maybe a few of the end users can specifically tell you what's good",
    "start": "1163480",
    "end": "1170120"
  },
  {
    "text": "what's bad about you know here are a handful of good examples here are a handful of bad",
    "start": "1170120",
    "end": "1175200"
  },
  {
    "text": "examples cool um the other thing that this does is really helps it nail the formatting as well so if you're",
    "start": "1175200",
    "end": "1180760"
  },
  {
    "text": "struggling with that second step um if you just provide even just one or two examples uh of that formatting being",
    "start": "1180760",
    "end": "1187919"
  },
  {
    "text": "used uh then um you know it does a much better job at adhering to that um so",
    "start": "1187919",
    "end": "1193400"
  },
  {
    "text": "here it's doing a good job here with the key points um and um you know just in general I think think the semantic tone",
    "start": "1193400",
    "end": "1199919"
  },
  {
    "text": "is starting to get much better um I I specifically made those other examples more biased right and that was how I",
    "start": "1199919",
    "end": "1206960"
  },
  {
    "text": "kind of communicated that I wanted that political bias in the summarization as well um and and I did you know both",
    "start": "1206960",
    "end": "1213480"
  },
  {
    "text": "sides as well so uh so it has like a diverse set of uh of understanding it",
    "start": "1213480",
    "end": "1218559"
  },
  {
    "text": "knows that it's not just going to create like left leaning bias or right leaning bias it's going to be you know bias that",
    "start": "1218559",
    "end": "1225280"
  },
  {
    "text": "matches the original tone of the of the article itself um then uh usually it's working by now",
    "start": "1225280",
    "end": "1233080"
  },
  {
    "start": "1229000",
    "end": "1514000"
  },
  {
    "text": "like usually it's working pretty well and you would see at least from a you know Vibe check standpoint uh you've",
    "start": "1233080",
    "end": "1239360"
  },
  {
    "text": "looked at it and you're like hey this is actually kind of good I'm pretty happy with this um and now it's time to formalize that evaluation because uh it",
    "start": "1239360",
    "end": "1246799"
  },
  {
    "text": "can't just be you manually checking everything every time it's going to be too slow um you know good luck getting",
    "start": "1246799",
    "end": "1252720"
  },
  {
    "text": "your CEO to manually check hundreds of examples when you're doing an AB test right or um you know hiring a domain",
    "start": "1252720",
    "end": "1258679"
  },
  {
    "text": "expert is very expensive they're usually very busy um so you know it might take weeks for them to come back to you with",
    "start": "1258679",
    "end": "1264400"
  },
  {
    "text": "some labeled responses so uh typically you want to formalize um your evaluation",
    "start": "1264400",
    "end": "1270320"
  },
  {
    "text": "metrics uh in some way uh that can run uh every time uh you run an experiment",
    "start": "1270320",
    "end": "1275760"
  },
  {
    "text": "and and and conclude in you know less than a couple of minutes um because otherwise it's just going to be very very slow to run experiments and then",
    "start": "1275760",
    "end": "1283039"
  },
  {
    "text": "you're kind of losing one of the major benefits that you have with llms you know when a human is doing this task",
    "start": "1283039",
    "end": "1289320"
  },
  {
    "text": "uh you know might take days weeks months you can't AB test with humans very easily they don't like that right it's",
    "start": "1289320",
    "end": "1294960"
  },
  {
    "text": "what I found um you know so if you're trying to uh give one set of instructions to one team member and",
    "start": "1294960",
    "end": "1300440"
  },
  {
    "text": "another set of instructions to another team member we have a sense of fairness and it really annoys us um you know and",
    "start": "1300440",
    "end": "1306159"
  },
  {
    "text": "uh I wouldn't suggest that but with llms you can do that and you can run these experiments you can actually kind of see",
    "start": "1306159",
    "end": "1312279"
  },
  {
    "text": "okay well when I describe it this way it actually does much better and actually I'm seeing with a lot of my clients um",
    "start": "1312279",
    "end": "1318960"
  },
  {
    "text": "as they get better and better at evaluating the performance of uh of these llm pipelines and as they get",
    "start": "1318960",
    "end": "1324559"
  },
  {
    "text": "better at describing uh the task uh it is to do that that we need to do and",
    "start": "1324559",
    "end": "1329840"
  },
  {
    "text": "adding examples building that kind of database of good examples uh it's actually a little bit of a you know a",
    "start": "1329840",
    "end": "1337159"
  },
  {
    "text": "gateway drug into actually doing a better job managing their employees which I think is a hopeful message um",
    "start": "1337159",
    "end": "1343720"
  },
  {
    "text": "because you can take some of the lessons that uh work with llms and then apply them back into to your human workers as",
    "start": "1343720",
    "end": "1350080"
  },
  {
    "text": "well for those parts of the pipeline that you can't uh readily automate with AI yet right um so uh you know typically",
    "start": "1350080",
    "end": "1357840"
  },
  {
    "text": "there are a few different types of evaluation functions the best ones to run are ones that are deterministic um",
    "start": "1357840",
    "end": "1364000"
  },
  {
    "text": "so if you can code it right like if you can it can be a function um that you run",
    "start": "1364000",
    "end": "1369600"
  },
  {
    "text": "uh that like that classifies the result um you know that's that's perfect because then you can ab test all day",
    "start": "1369600",
    "end": "1375159"
  },
  {
    "text": "long even if it's not direct you know even if it's not like 100% ACC urate it doesn't 100% agree with the human domain",
    "start": "1375159",
    "end": "1381320"
  },
  {
    "text": "expert it's still good directionally to rapidly AB test and then you can go validate those results with the domain",
    "start": "1381320",
    "end": "1386880"
  },
  {
    "text": "expert um so in this case I've chosen uh rcore which is you know used for summarization um and again you know when",
    "start": "1386880",
    "end": "1394120"
  },
  {
    "text": "you're in cursor or you're using you know CLA or or chat gbt you can just ask it like how would I evaluate this and it",
    "start": "1394120",
    "end": "1400320"
  },
  {
    "text": "can actually usually come up with uh some precedent for how people tend to evaluate these things obviously you want",
    "start": "1400320",
    "end": "1405640"
  },
  {
    "text": "to fact check that um but uh you know you could it could get it to write the code for you to calculate the Rouge",
    "start": "1405640",
    "end": "1411279"
  },
  {
    "text": "score if you've never heard of that for example so um you know the other thing I",
    "start": "1411279",
    "end": "1417080"
  },
  {
    "text": "do kind of an additional lay here is I'm using an llm judge uh which um you know is really helpful uh when you don't have",
    "start": "1417080",
    "end": "1424320"
  },
  {
    "text": "that um access directly to a domain expert all the time uh and then you know",
    "start": "1424320",
    "end": "1429520"
  },
  {
    "text": "you want to kind of speed things up uh so in this case I'm calculating the roof score and then I'm passing that to an",
    "start": "1429520",
    "end": "1434559"
  },
  {
    "text": "llm judge uh which is again just another prompt that you can optimize as as well um and I'm just asking it to interpret",
    "start": "1434559",
    "end": "1441000"
  },
  {
    "text": "these scores and choose a winner um so again I'm being very lazy here like I'm not even I'm calculating the rof score",
    "start": "1441000",
    "end": "1448279"
  },
  {
    "text": "um and then I'm passing those rof scores uh across to an llm uh judge to choose between them right so um I don't even",
    "start": "1448279",
    "end": "1455200"
  },
  {
    "text": "have to look at the scores and interpret them myself um and and you can you can really extend that concept out quite a",
    "start": "1455200",
    "end": "1461240"
  },
  {
    "text": "bit uh there's uh there's a lot you can do with llm judges again I would say that um you know because uh it is",
    "start": "1461240",
    "end": "1468520"
  },
  {
    "text": "another prompt uh you still have to optimize that prompt and check whether that agrees with the human you know",
    "start": "1468520",
    "end": "1473880"
  },
  {
    "text": "human judges um and you know there's kind of starting this whole cycle again",
    "start": "1473880",
    "end": "1478919"
  },
  {
    "text": "and uh you can see here this is kind of example response that we get um again you want to use Chain of Thought here so",
    "start": "1478919",
    "end": "1485360"
  },
  {
    "text": "in this case um I've asked it to kind of you know it's it's explaining the reasoning a little bit first before",
    "start": "1485360",
    "end": "1491039"
  },
  {
    "text": "choosing a winner you want it to choose the winner at the very end uh because that's going to give it much less biased",
    "start": "1491039",
    "end": "1496640"
  },
  {
    "text": "um answers um and much more repeatable reliable answers so every time you run this it's going to say winner two with",
    "start": "1496640",
    "end": "1503200"
  },
  {
    "text": "the exact same inputs um you don't want it to be fluctuating and sometimes choosing winner one with those same",
    "start": "1503200",
    "end": "1509120"
  },
  {
    "text": "inputs right um but now we've kind of gotten on to what I think is the fifth principle here uh which is dividing",
    "start": "1509120",
    "end": "1516320"
  },
  {
    "start": "1514000",
    "end": "1702000"
  },
  {
    "text": "labor it's very very rare I don't think I've ever seen it that um a an AI system",
    "start": "1516320",
    "end": "1522039"
  },
  {
    "text": "in production is only using one prompt right that almost never happens uh you",
    "start": "1522039",
    "end": "1527159"
  },
  {
    "text": "you can't get you can get a good demo but you can't get great reliable results only using one prompt usually it's a",
    "start": "1527159",
    "end": "1534000"
  },
  {
    "text": "chain of prompts strung together uh or in some cases an agent although a lot of them are pretty unreliable um so uh I",
    "start": "1534000",
    "end": "1541320"
  },
  {
    "text": "would say typically you want to kind of chain multiple responses together where the inputs um of uh the next prompt in",
    "start": "1541320",
    "end": "1548720"
  },
  {
    "text": "the chain are the outputs of the previous prompt in the chain a good example of this is um you know in this",
    "start": "1548720",
    "end": "1555919"
  },
  {
    "text": "case uh we wanted to add ations uh to uh the summaries we've already solved the",
    "start": "1555919",
    "end": "1562279"
  },
  {
    "text": "initial problem of maintaining uh the political bias uh of the original article which is good that's now we've",
    "start": "1562279",
    "end": "1568799"
  },
  {
    "text": "kind of kept that semantic information uh but the other additional thing we wanted to know here is like did it get",
    "start": "1568799",
    "end": "1574520"
  },
  {
    "text": "the facts correct right because that's different from political bias although they are kind of intermingled um so I'm",
    "start": "1574520",
    "end": "1580320"
  },
  {
    "text": "using another AI system here called tavali there's a bunch of these um but essentially that would go and do a web",
    "start": "1580320",
    "end": "1587480"
  },
  {
    "text": "search so if you're used to perplexity if you guys have used that app similar sort of concept to that they also have",
    "start": "1587480",
    "end": "1593320"
  },
  {
    "text": "an API you could have used here um but essentially it will do a web search and then uh take the results of that web",
    "start": "1593320",
    "end": "1600279"
  },
  {
    "text": "search you know scrape those uh URLs and then put the text into the prompt and",
    "start": "1600279",
    "end": "1605559"
  },
  {
    "text": "then you can kind of choose a question to ask uh based on that context um so it's a really great kind of General way",
    "start": "1605559",
    "end": "1612279"
  },
  {
    "text": "to fact check stuff um and is to and get upto-date information um is to kind of",
    "start": "1612279",
    "end": "1617679"
  },
  {
    "text": "give it to to one of these web search agents that can kind of then summarize that information and give you back a response specifically on that key point",
    "start": "1617679",
    "end": "1624480"
  },
  {
    "text": "that was made um so uh you can see this is the type of response we're getting here and",
    "start": "1624480",
    "end": "1630279"
  },
  {
    "text": "um it's looked up a couple of the specific key points uh and then I've given it that context at the end and",
    "start": "1630279",
    "end": "1635679"
  },
  {
    "text": "said okay now rewrite the summary uh but with the citations so that's how I'm",
    "start": "1635679",
    "end": "1640720"
  },
  {
    "text": "getting like the number one and the number two in here this is kind of choosing uh the best place to put",
    "start": "1640720",
    "end": "1646480"
  },
  {
    "text": "them cool so um that is you know that that's quite a you know involved process took a couple",
    "start": "1646480",
    "end": "1653679"
  },
  {
    "text": "of days um you know I would say the the amount of prompt engineering you need uh",
    "start": "1653679",
    "end": "1659120"
  },
  {
    "text": "you know you're probably not going to know ahead of time it's a very you know it's an R&D type task uh where you could",
    "start": "1659120",
    "end": "1665480"
  },
  {
    "text": "be working on it for a month and and find out that you basically you know can't crack the solution um or you might",
    "start": "1665480",
    "end": "1672080"
  },
  {
    "text": "be doing it for an hour and then you happen upon a good prompt and you're like okay great this is working which is nice um so i' would say it's a creative",
    "start": "1672080",
    "end": "1678679"
  },
  {
    "text": "task just like any other creative task you can't really schedule it that well um what I would try and do is time box",
    "start": "1678679",
    "end": "1684559"
  },
  {
    "text": "it and say we're going to try and spend two days on this and see how far we can get um and then based on how far we can",
    "start": "1684559",
    "end": "1691360"
  },
  {
    "text": "get we can revise our plan and kind of say okay maybe we need to try another solution um or maybe this isn't good to",
    "start": "1691360",
    "end": "1696679"
  },
  {
    "text": "do with AI right now um and we can put that in the Box for later when the next model comes",
    "start": "1696679",
    "end": "1701720"
  },
  {
    "text": "out cool so what do you do when you get into production so say say everything goes really well um you know what is a",
    "start": "1701720",
    "end": "1707480"
  },
  {
    "start": "1702000",
    "end": "1905000"
  },
  {
    "text": "prompt engineer in prompt engineer doing then like uh you know they're not just kind of",
    "start": "1707480",
    "end": "1713360"
  },
  {
    "text": "creating new prompts for new tasks they're also optimizing existing ones uh and that tends to fall into three",
    "start": "1713360",
    "end": "1720279"
  },
  {
    "text": "buckets and um I would say the first of those buckets is AB testing uh quite",
    "start": "1720279",
    "end": "1725799"
  },
  {
    "text": "often uh you know now you have an evaluation metric now you have kind of a a general system uh and you know what",
    "start": "1725799",
    "end": "1732399"
  },
  {
    "text": "the output should be um you can you can try a new prompt and you can see what the results are against your evaluation",
    "start": "1732399",
    "end": "1739159"
  },
  {
    "text": "you can try a new model and see how well that model does um you know from a different vendor perhaps um you can",
    "start": "1739159",
    "end": "1745799"
  },
  {
    "text": "actually AB test to decrease costs as well so you know you get it working with gp4 um and then you try and get it",
    "start": "1745799",
    "end": "1751720"
  },
  {
    "text": "working with gp4 mini right which is you know 100th of the cost or something um",
    "start": "1751720",
    "end": "1757480"
  },
  {
    "text": "I'm seeing a lot of uh people particularly from the machine learning engineer kind of background uh doing",
    "start": "1757480",
    "end": "1763159"
  },
  {
    "text": "optimization work with some of these Frameworks that are coming out like Microsoft has one called ammo the most popular one is DSP um and the nice thing",
    "start": "1763159",
    "end": "1770600"
  },
  {
    "text": "about this is that if you give it an evaluation metric um that it can run and",
    "start": "1770600",
    "end": "1775679"
  },
  {
    "text": "um if you give it the initial instructions uh then it can rewrite the prompt for you uh so it will choose what",
    "start": "1775679",
    "end": "1782399"
  },
  {
    "text": "few shot examples to put in the prompt the ones that pass the evaluation the most um and then it can also rewrite the",
    "start": "1782399",
    "end": "1788440"
  },
  {
    "text": "actual instructions uh in a way that um you know an llm will give better results",
    "start": "1788440",
    "end": "1793559"
  },
  {
    "text": "from and that is um it's unusual that that works but I guess uh in in a way like prompt Engineers are not immune to",
    "start": "1793559",
    "end": "1801159"
  },
  {
    "text": "being automated out of a job either you know like that's what we're doing for other people I guess I don't know uh but",
    "start": "1801159",
    "end": "1807200"
  },
  {
    "text": "um you know DS DSP like because uh AI models are good at um you know most like",
    "start": "1807200",
    "end": "1814279"
  },
  {
    "text": "a lot of human tasks uh it makes sense that it would also be good at doing prompt engineering um uh I would say",
    "start": "1814279",
    "end": "1820360"
  },
  {
    "text": "that uh this tends to work better for specific types of classification tasks uh where the evaluation is quick and",
    "start": "1820360",
    "end": "1827320"
  },
  {
    "text": "cheap to run uh and and less good for larger tasks like uh like actually",
    "start": "1827320",
    "end": "1832919"
  },
  {
    "text": "summarization um where you know it's very expensive to run it a 100 or a thousand times um and in that case I",
    "start": "1832919",
    "end": "1839760"
  },
  {
    "text": "think humans have better intuition for uh getting to a good prompt uh with with",
    "start": "1839760",
    "end": "1844880"
  },
  {
    "text": "less tests uh and then there's also fine-tuning and uh this is a last step",
    "start": "1844880",
    "end": "1850000"
  },
  {
    "text": "um not a first step a lot of people try and Skip straight to fine tuning because I think uh investors like it when you",
    "start": "1850000",
    "end": "1856200"
  },
  {
    "text": "say you have your own model um you know but but but honestly I would say that",
    "start": "1856200",
    "end": "1861559"
  },
  {
    "text": "you know if you go through all these other steps first then you'll have the database ready for fine tuning because",
    "start": "1861559",
    "end": "1866799"
  },
  {
    "text": "you have your evaluation metric you can run the prompt a bunch of times and then generate say 2,000 responses that pass",
    "start": "1866799",
    "end": "1873399"
  },
  {
    "text": "your evaluation metric right so like you can build that data set very quickly once you've gone through these necessary steps um and with fine tuning you're",
    "start": "1873399",
    "end": "1880080"
  },
  {
    "text": "going to find that um you need you know hundreds maybe thousands of examples uh before the model gets really noticeably",
    "start": "1880080",
    "end": "1887120"
  },
  {
    "text": "better fine tuning is also not always available like GT4 uh was only generally",
    "start": "1887120",
    "end": "1893200"
  },
  {
    "text": "available for fine tuning a year after it came out so um you know like tends to be something that people are using more",
    "start": "1893200",
    "end": "1900000"
  },
  {
    "text": "for smaller tasks that work on the smaller open source models so dive in a little bit um deeper",
    "start": "1900000",
    "end": "1907159"
  },
  {
    "start": "1905000",
    "end": "1989000"
  },
  {
    "text": "into these and um yeah I'm not sure how much time we have left but we can kind of uh about 5 minutes okay so we'll just",
    "start": "1907159",
    "end": "1914279"
  },
  {
    "text": "cover a few of these um relatively quickly um but you'll also have these slides afterwards there's an example of",
    "start": "1914279",
    "end": "1919799"
  },
  {
    "text": "an AB test it's literally just a simple function that calls the one I talked about earlier uh where you call open AI",
    "start": "1919799",
    "end": "1925840"
  },
  {
    "text": "um the the key is that it's uh uh the the um you want to try and run it um asynchronously quite often um because",
    "start": "1925840",
    "end": "1933440"
  },
  {
    "text": "otherwise when you're running 10 20 30 times uh it's going to be really slow if you're doing it one after another uh you",
    "start": "1933440",
    "end": "1939679"
  },
  {
    "text": "want to be able to do multiple uh batches at the same time um you know in",
    "start": "1939679",
    "end": "1944760"
  },
  {
    "text": "this uh with with these types of prompts I tend to run it between 10 30 times each because that just removes some of",
    "start": "1944760",
    "end": "1950320"
  },
  {
    "text": "the randomness out of the responses and if you can average the evaluation scores then you're just um decreasing the",
    "start": "1950320",
    "end": "1956840"
  },
  {
    "text": "chance that you just got unlucky with that training run right um you might find that you're throwing away a good",
    "start": "1956840",
    "end": "1962440"
  },
  {
    "text": "prompt by accident because the first few times you ran it it was bad right um I I",
    "start": "1962440",
    "end": "1968600"
  },
  {
    "text": "tend to look at prompt engineering papers for good ideas um if you don't want to read prompt engineering papers",
    "start": "1968600",
    "end": "1974000"
  },
  {
    "text": "uh or you know you don't have enough time then you can also use uh chat gbt and Claude to read those papers for you",
    "start": "1974000",
    "end": "1980039"
  },
  {
    "text": "and tell you what is the prompt they used here and then you could just try that for yourself right so again we're",
    "start": "1980039",
    "end": "1985200"
  },
  {
    "text": "using AI every step of the way which is quite fun uh dpy is or DS Pi is like",
    "start": "1985200",
    "end": "1991399"
  },
  {
    "start": "1989000",
    "end": "2060000"
  },
  {
    "text": "really interesting it's it's I'd say it's still relatively new and and like changing a lot it's like more in Alpha",
    "start": "1991399",
    "end": "1998519"
  },
  {
    "text": "than than beta but um I wouldn't use that in production but what I would do is take your prompt out run it you know",
    "start": "1998519",
    "end": "2005200"
  },
  {
    "text": "recreate it in DSP um and then run some testing kind of optimize it um and see",
    "start": "2005200",
    "end": "2010919"
  },
  {
    "text": "what results you can get at the very least it will give you some ideas of different prompts you could try um and",
    "start": "2010919",
    "end": "2016399"
  },
  {
    "text": "good ideas of uh what few shot examples to include uh typically I wouldn't try it without uh having like at least 50",
    "start": "2016399",
    "end": "2023840"
  },
  {
    "text": "data points um and I try it more on classification tasks like you know uh where where there is a right answer um",
    "start": "2023840",
    "end": "2030480"
  },
  {
    "text": "it tends to work a lot better than more creative tasks like write a blog post or write a social media post be careful of",
    "start": "2030480",
    "end": "2036600"
  },
  {
    "text": "costs because and you can calculate this ahead of time but um you know if you use something like Meo which is um testing",
    "start": "2036600",
    "end": "2043679"
  },
  {
    "text": "both the instructions and the few shot examples and you're using gp4 instead of gp4 mini uh you could easily spend a few",
    "start": "2043679",
    "end": "2050158"
  },
  {
    "text": "hundred or maybe even a thousand bucks uh on that training run so um you know",
    "start": "2050159",
    "end": "2055560"
  },
  {
    "text": "that might be more or less consequential depending on the resources you're using for that project um and then fine tuning",
    "start": "2055560",
    "end": "2061960"
  },
  {
    "start": "2060000",
    "end": "2287000"
  },
  {
    "text": "thankfully is like very easy to run although very complicated to understand uh what's happening uh so if you don't",
    "start": "2061960",
    "end": "2068839"
  },
  {
    "text": "have a you know machine learning background or you don't have anyone on the team that understands this stuff or",
    "start": "2068839",
    "end": "2073878"
  },
  {
    "text": "can spend you know some time digging in um then I would just stick with the defaults follow a tutorial uh see if it",
    "start": "2073879",
    "end": "2081158"
  },
  {
    "text": "works if it doesn't work then decide whether you want to go deeper with it um and I found that uh on average uh it",
    "start": "2081159",
    "end": "2088839"
  },
  {
    "text": "tends to work when I've got more like 2,000 examples uh of uh inputs and",
    "start": "2088839",
    "end": "2094118"
  },
  {
    "text": "outputs um so I'll do all the prompt engineering stuff first and then I'll try a fine-tuning run um and if that",
    "start": "2094119",
    "end": "2100440"
  },
  {
    "text": "doesn't work uh you know then I'll kind of reconsider uh my strategies um you know typically uh you",
    "start": "2100440",
    "end": "2107280"
  },
  {
    "text": "know the model vendors themselves uh control this right so you know you can't just train gp4 without permission uh",
    "start": "2107280",
    "end": "2114640"
  },
  {
    "text": "right you don't have the model weights to update um so actually I tried to do fine tuning on this data set um and",
    "start": "2114640",
    "end": "2121800"
  },
  {
    "text": "opening eyes told me no because I mentioned the word Donald Trump too many times in my in my data right so uh so I",
    "start": "2121800",
    "end": "2128640"
  },
  {
    "text": "mean you do run into some kind of limitations there you know if it's not your weights you know it's not your model right so what a lot of people do",
    "start": "2128640",
    "end": "2136440"
  },
  {
    "text": "the pattern I'm seeing is distillation uh where you use gp4 to generate lots of",
    "start": "2136440",
    "end": "2142240"
  },
  {
    "text": "really great examples um that that are working and passing your evaluation um and then you go and use like an open",
    "start": "2142240",
    "end": "2148560"
  },
  {
    "text": "source model that's cheaper to run uh that can be selfhosted on your aure",
    "start": "2148560",
    "end": "2153680"
  },
  {
    "text": "setup or or AWS um and then uh and then you just train that with those examples",
    "start": "2153680",
    "end": "2159280"
  },
  {
    "text": "um and that does work pretty well quite often you can get a much smaller model up to the same same standard as gp4 um",
    "start": "2159280",
    "end": "2166920"
  },
  {
    "text": "with a few thousand examples uh so it could cost as little as a few hundred bucks and then and then you have like",
    "start": "2166920",
    "end": "2173000"
  },
  {
    "text": "you know a smaller cheaper model that costs like less than a a penny per you know uh per 100,000 tokens so that that",
    "start": "2173000",
    "end": "2180880"
  },
  {
    "text": "is quite a quite a a common use case you don't have to run these models locally on your computer um you know if you have",
    "start": "2180880",
    "end": "2187720"
  },
  {
    "text": "privacy uh or sensitive data issues then obviously you want to work with your",
    "start": "2187720",
    "end": "2193160"
  },
  {
    "text": "organizations to self-host um or use you know Bedrock or one of the other kind of trusted platform providers um but uh I I",
    "start": "2193160",
    "end": "2201480"
  },
  {
    "text": "often use uh tool called replicate just because it's quite simple they kind of host these models for you and they have",
    "start": "2201480",
    "end": "2207240"
  },
  {
    "text": "good tutorials for how to do fine fine tuning um and then last thing is just",
    "start": "2207240",
    "end": "2212720"
  },
  {
    "text": "like other things that help um adding more eval metrics just having one eval metric is good but having multiple ones",
    "start": "2212720",
    "end": "2218960"
  },
  {
    "text": "that cover different things that people complain about that's better um working with domain experts to get more examples",
    "start": "2218960",
    "end": "2224520"
  },
  {
    "text": "so you know don't just stop when you got the prompt working you can always make it better um adding more test cases uh",
    "start": "2224520",
    "end": "2230839"
  },
  {
    "text": "whenever something fails in production you want to add that as a test case um so you can check if it's regressing and",
    "start": "2230839",
    "end": "2236560"
  },
  {
    "text": "you can check when you up update to the new model uh whether it's still passing all of your test cases and those test",
    "start": "2236560",
    "end": "2242200"
  },
  {
    "text": "cases are just input and output pairs uh you want to train an llm judge we talked about uh if you can a at the expert",
    "start": "2242200",
    "end": "2248160"
  },
  {
    "text": "feedback and it agrees enough like 80% accuracy versus the human expert um then",
    "start": "2248160",
    "end": "2253520"
  },
  {
    "text": "you can run AB tests much much faster um and then uh you can create like a self",
    "start": "2253520",
    "end": "2258720"
  },
  {
    "text": "uh improving Loop there especially if the feedback is coming in directly from production like people can click on an",
    "start": "2258720",
    "end": "2264720"
  },
  {
    "text": "answer and say thumbs up uh that that tends to be quite helpful um and then really after that you're talking about",
    "start": "2264720",
    "end": "2271079"
  },
  {
    "text": "things outside of AI like connecting it to other systems like databases where it can do searches um and and kind of",
    "start": "2271079",
    "end": "2277520"
  },
  {
    "text": "pulling in the right context uh for the AI to do a better job and kind of splitting that up into multiple um",
    "start": "2277520",
    "end": "2284000"
  },
  {
    "text": "multiple tasks that maybe all run in parallel as well cool so um I have a few",
    "start": "2284000",
    "end": "2290880"
  },
  {
    "start": "2287000",
    "end": "2309000"
  },
  {
    "text": "different things here um that we're not going to go through but these are just individual papers that might be worth",
    "start": "2290880",
    "end": "2295960"
  },
  {
    "text": "looking at uh the main one is that uh prompting tends to beat fine tuning under 2,000 data points which is really",
    "start": "2295960",
    "end": "2301839"
  },
  {
    "text": "helpful and then kind of like a road map uh for what this is what open AI recommends in terms of how you should",
    "start": "2301839",
    "end": "2307160"
  },
  {
    "text": "approach this cool thanks for listening [Applause]",
    "start": "2307160",
    "end": "2317239"
  }
]
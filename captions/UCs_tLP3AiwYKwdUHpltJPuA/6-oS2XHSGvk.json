[
  {
    "text": "in fact with a nice cozy audience like this we can add even see if there's",
    "start": "60",
    "end": "7589"
  },
  {
    "text": "special interests or people actually you know as an in general that you're interested in the the actual subject is",
    "start": "7589",
    "end": "13889"
  },
  {
    "text": "low-latency Java in the real world with actual experiences of the Xing JVM it's",
    "start": "13889",
    "end": "19770"
  },
  {
    "text": "a product we make at L max at the L max exchange and we've been doing stuff",
    "start": "19770",
    "end": "26849"
  },
  {
    "text": "there for a couple years now how many of you actually deal with low latency systems okay how about doing that in",
    "start": "26849",
    "end": "35520"
  },
  {
    "text": "Java well I know what you do good okay so it's in that world the others are you",
    "start": "35520",
    "end": "41040"
  },
  {
    "text": "interested in low latency in Java hopefully you're here yeah okay so that",
    "start": "41040",
    "end": "47640"
  },
  {
    "text": "that's what I'm going to cover in I actually put this presentation together with L max and I'm really really happy",
    "start": "47640",
    "end": "56520"
  },
  {
    "text": "that we have this material because it's really rare for us to have a financial services customer that is willing to",
    "start": "56520",
    "end": "63239"
  },
  {
    "text": "openly talk about their experiences with our products usually our customers won't talk",
    "start": "63239",
    "end": "69210"
  },
  {
    "text": "Azul is installed in seven out of the top ten financial investment banks for",
    "start": "69210",
    "end": "75450"
  },
  {
    "text": "example in the world running various systems but none of them would let us say who they are",
    "start": "75450",
    "end": "80759"
  },
  {
    "text": "notice I didn't say ten of the top ten so I can still say that right but L max exchange actually is fairly",
    "start": "80759",
    "end": "88770"
  },
  {
    "text": "open and they'll talk and they'll describe what they actually do and you've seen results with open source as well",
    "start": "88770",
    "end": "94020"
  },
  {
    "text": "so it's about low latency Java in the",
    "start": "94020",
    "end": "99509"
  },
  {
    "text": "real world so low latency we know hopefully don't that you know this is like things that take low tens of",
    "start": "99509",
    "end": "107490"
  },
  {
    "text": "microseconds to maybe milliseconds and Java we hopefully know what that is and",
    "start": "107490",
    "end": "112740"
  },
  {
    "text": "the real world is important this is not theory this is actual experience over two years of actual deployments so we",
    "start": "112740",
    "end": "118829"
  },
  {
    "text": "could talk about what happened and I'll cover some of the some of the lessons learned as well what would we do",
    "start": "118829",
    "end": "125100"
  },
  {
    "text": "differently had we started today for example you know I'll talk about me and",
    "start": "125100",
    "end": "130530"
  },
  {
    "text": "then I'll show you who I stand in for I'm the CTO diesel so it's all my fault",
    "start": "130530",
    "end": "137580"
  },
  {
    "text": "I've been working on all kinds of things including garbage collection for a decade plus around JVMs and this is some",
    "start": "137580",
    "end": "145050"
  },
  {
    "text": "evidence of me doing garbage collection in my kitchen it's a broken trash compactor fragments are falling off the",
    "start": "145050",
    "end": "150780"
  },
  {
    "text": "back the compaction function wasn't working right so I had to fix it in debug it I thought it'd be cool to take a picture with a book this is in 2004 so",
    "start": "150780",
    "end": "159810"
  },
  {
    "text": "it's stale and I really need a new picture I have a long history of",
    "start": "159810",
    "end": "165300"
  },
  {
    "text": "building all kinds of things physical machines virtual machines kernels a lot",
    "start": "165300",
    "end": "171150"
  },
  {
    "text": "of systems programming applications distributed across many systems for millions of subscribers and firewalls",
    "start": "171150",
    "end": "177600"
  },
  {
    "text": "and switches and lots of stuff I'm a little older than I look or maybe it started you know catching up with me but",
    "start": "177600",
    "end": "185460"
  },
  {
    "text": "I've been working with computers since about 1982 so I have a long memory now I",
    "start": "185460",
    "end": "191310"
  },
  {
    "text": "also have pet hobby of scaring people about latency not about the length of it",
    "start": "191310",
    "end": "197460"
  },
  {
    "text": "but about what they know or don't know about it and irresponsible things they do when they measure it if you're",
    "start": "197460",
    "end": "202500"
  },
  {
    "text": "interested in a topic you know look up how not to measure latency or things of that sort and there's some useful things",
    "start": "202500",
    "end": "209040"
  },
  {
    "text": "around that so that's me now I'm also standing in for Mark Price who is an L",
    "start": "209040",
    "end": "215370"
  },
  {
    "text": "max engineer and we actually build this presentation together but he's in London right now so instead of him there's me",
    "start": "215370",
    "end": "223100"
  },
  {
    "text": "this this is a scary picture that I took when taking a really really scary ride",
    "start": "223100",
    "end": "228450"
  },
  {
    "text": "and you could see my reaction to it this is the Dumbo ride in Disneyland it really is you know it's taken from",
    "start": "228450",
    "end": "235170"
  },
  {
    "text": "another Dumbo and we were making a face I like the picture anyway mark is a finger developer at L max he",
    "start": "235170",
    "end": "243510"
  },
  {
    "text": "has focused on performance not just in his job but in general he just likes performance things he's he's touched",
    "start": "243510",
    "end": "252840"
  },
  {
    "text": "pretty much everything at L max because he's been there for I think about eight years and and right now he's focusing on",
    "start": "252840",
    "end": "261209"
  },
  {
    "text": "performance and monitoring but he's touched not just performance things he's actually built a lot of parts one of my",
    "start": "261209",
    "end": "266789"
  },
  {
    "text": "favorite thing about howdy describes his job is he used to be this guy the guy who everybody",
    "start": "266789",
    "end": "274870"
  },
  {
    "text": "came to like the psychiatrist here with their GC logs and they told him their troubles and he had to console them and",
    "start": "274870",
    "end": "281319"
  },
  {
    "text": "try and help him through the problems and you know teach him how to do better with their life and you know live within",
    "start": "281319",
    "end": "286930"
  },
  {
    "text": "the environment they have to live with and such so GC tuning and garbage",
    "start": "286930",
    "end": "292449"
  },
  {
    "text": "collection knowledge was one of his central perfuse and you know he was the go-to guy around that l max in general",
    "start": "292449",
    "end": "301110"
  },
  {
    "text": "and again I'm not l max but oh I forgot to do a really important thing here right here see when they do this we're",
    "start": "301110",
    "end": "309039"
  },
  {
    "text": "gonna do this experiment when I'm mark I'll do that and when I'm Gil I won't",
    "start": "309039",
    "end": "316060"
  },
  {
    "text": "have that on we'll see how that works okay so here's me going through our cool discussion and at El Max and I'm not",
    "start": "316060",
    "end": "324370"
  },
  {
    "text": "speaking for el max but this is their material L max is basically a venue for",
    "start": "324370",
    "end": "329770"
  },
  {
    "text": "low latency trading they are the first regulated MTF that's a multilateral",
    "start": "329770",
    "end": "335889"
  },
  {
    "text": "trading facility I believe for transparent order driven FX trading I'm",
    "start": "335889",
    "end": "341830"
  },
  {
    "text": "sorry I'm reading the points because it's not mine and need to be careful not to say wrong things they have all kinds",
    "start": "341830",
    "end": "348250"
  },
  {
    "text": "of accolades and awards for example they were they won first place in a tech",
    "start": "348250",
    "end": "353919"
  },
  {
    "text": "track 100 and in general they aim to be the world's fastest FX trading exchange",
    "start": "353919",
    "end": "361659"
  },
  {
    "text": "so they compare themselves to other they actually put up things on their website to talk about their latency behavior",
    "start": "361659",
    "end": "367569"
  },
  {
    "text": "over the last 30 days things like that they're amazingly transparent for what the industry usually is which which I",
    "start": "367569",
    "end": "374139"
  },
  {
    "text": "like a lot because at all not not only do we like them as a customer and that what we get to see their improvement and",
    "start": "374139",
    "end": "380129"
  },
  {
    "text": "the fact that we can share that with the world is great now the openness of them is also",
    "start": "380129",
    "end": "388919"
  },
  {
    "text": "relatively rare not only are we here talking about what they do with their material they are also they've embraced",
    "start": "388919",
    "end": "396819"
  },
  {
    "text": "open source quite a bit and you probably know them from 4l MX disruptor which is a common",
    "start": "396819",
    "end": "403199"
  },
  {
    "text": "pattern used in low latency or high throughput systems today that came out of L max okay so zing yeah we talked a",
    "start": "403199",
    "end": "417539"
  },
  {
    "text": "little about L max what is things zing is a JVM for Linux x86 it's",
    "start": "417539",
    "end": "422699"
  },
  {
    "text": "basically good for not just being fast but being fast all the time we actually",
    "start": "422699",
    "end": "429060"
  },
  {
    "text": "think that the decision probably about 20 years ago to build this runtime that's so popular now but allow it to go",
    "start": "429060",
    "end": "436440"
  },
  {
    "text": "out to lunch anytime it wants to was just a fundamental mistake computers didn't behave like that before it wasn't",
    "start": "436440",
    "end": "442050"
  },
  {
    "text": "acceptable and the fact that we've evolved into something that is so ingrained and fundamental and productive",
    "start": "442050",
    "end": "447389"
  },
  {
    "text": "and good but goes and stops anytime it wants to and doesn't run continuously is just wrong so we roll the clock back on",
    "start": "447389",
    "end": "454889"
  },
  {
    "text": "that I said JVMs are not supposed to stop it's okay for your application to do whatever bugs you have but the JVM",
    "start": "454889",
    "end": "461400"
  },
  {
    "text": "needs to keep running and keep her hanging and it shouldn't be stopping you at least not for noticeable amounts of time so we start off by basically",
    "start": "461400",
    "end": "469110"
  },
  {
    "text": "eliminating garbage collection as a concern we don't eliminate garbage collection we just do it right I mean we",
    "start": "469110",
    "end": "475530"
  },
  {
    "text": "do it without stopping the application or stopping an application for any perceivable amount of time from the",
    "start": "475530",
    "end": "481560"
  },
  {
    "text": "applications point of view for an enterprise environments that's a complete elimination and we're not just",
    "start": "481560",
    "end": "487409"
  },
  {
    "text": "talking about the big bad G C's we're talking about any of the GC effects small bad newgen all gen they're all",
    "start": "487409",
    "end": "494970"
  },
  {
    "text": "gone and whether it's low latency or human scale response time the effect is very noticeable in low latency systems",
    "start": "494970",
    "end": "502320"
  },
  {
    "text": "people think that multi millisecond positives are deadly humans would love it if that's all they had right and in",
    "start": "502320",
    "end": "509669"
  },
  {
    "text": "human applications when you're you know doing interactive analytics with a 50 gigabyte data cube and it works pretty",
    "start": "509669",
    "end": "516870"
  },
  {
    "text": "well most of the time but then when it wants to do something you need to go get a cup of coffee and come back right and",
    "start": "516870",
    "end": "522990"
  },
  {
    "text": "then there's the annoying you know online retail level of people just don't like waiting more than a fraction of a second to see the next shirt or dress or",
    "start": "522990",
    "end": "530459"
  },
  {
    "text": "something or TV so it across all that small large memory high throughput low",
    "start": "530459",
    "end": "536190"
  },
  {
    "text": "throughput GC no longer bothers you you don't longer think about it and you know",
    "start": "536190",
    "end": "541200"
  },
  {
    "text": "it's a self problem and I'm I talk about it a lot but we really should just stop",
    "start": "541200",
    "end": "547230"
  },
  {
    "text": "talking about it it's done let's move on to actual engineering we don't need to reinvent that wheel over and over and",
    "start": "547230",
    "end": "553680"
  },
  {
    "text": "over again anymore and I think other people will solve this - let's just sing right now is the only one that does",
    "start": "553680",
    "end": "559380"
  },
  {
    "text": "now the key quality of this is that idiomatic Java code actually works you",
    "start": "559380",
    "end": "565920"
  },
  {
    "text": "don't need to start writing non idiomatic things just to work around things that are broken in your system",
    "start": "565920",
    "end": "571950"
  },
  {
    "text": "the system works smoothly even when you write regular Java code the way you would naturally gravitate to using it",
    "start": "571950",
    "end": "578100"
  },
  {
    "text": "and that means that you know even if you can't afford any kind of blips that are",
    "start": "578100",
    "end": "584850"
  },
  {
    "text": "noticeable things still work well now at",
    "start": "584850",
    "end": "593430"
  },
  {
    "text": "Lmax it's very important to stay responsive and a good example of that is",
    "start": "593430",
    "end": "598949"
  },
  {
    "text": "a recent event that happened in a market you might have heard about the change in a Swiss franc pricing and how it",
    "start": "598949",
    "end": "605070"
  },
  {
    "text": "decoupled from other things and that change came as an event a surprising",
    "start": "605070",
    "end": "611070"
  },
  {
    "text": "event to some people in a market causing some interesting spikes in volume that went right along with it so even when",
    "start": "611070",
    "end": "618300"
  },
  {
    "text": "the traffic pattern changes and even if when it changes as a surprise you still need to stay responsive in fact this is",
    "start": "618300",
    "end": "624269"
  },
  {
    "text": "the most critical time to stay responsive if you look through news elements a right after this that play",
    "start": "624269",
    "end": "630990"
  },
  {
    "text": "the trading systems and exchanges that made it through unscathed mate put our press releases on the fact that they did",
    "start": "630990",
    "end": "636690"
  },
  {
    "text": "because that's something to be proud of the guys who didn't put out press releases well you know you can think of",
    "start": "636690",
    "end": "642899"
  },
  {
    "text": "what happened there they probably just didn't draw attention to what happened Lmax made it completely unscathed with",
    "start": "642899",
    "end": "648750"
  },
  {
    "text": "this they should be very proud we should be very proud of our participation in part a small part of doing that now when",
    "start": "648750",
    "end": "656279"
  },
  {
    "text": "you look at the traffic the real world traffic that changes all the time this is a very interesting data point we got",
    "start": "656279",
    "end": "662060"
  },
  {
    "text": "and and this is actually looking at what a second behaves like a",
    "start": "662060",
    "end": "668410"
  },
  {
    "text": "across the day so this is every milli second of the second left is zero there",
    "start": "668410",
    "end": "674830"
  },
  {
    "text": "is a thousand but repeated over a day so this is the average of when things",
    "start": "674830",
    "end": "679870"
  },
  {
    "text": "happen during a second what you see here is an interesting set of patterns there",
    "start": "679870",
    "end": "684970"
  },
  {
    "text": "are four spikes every second and something happens four times a second",
    "start": "684970",
    "end": "691810"
  },
  {
    "text": "that changes information and people react to it by trading and they don't wait half a second they don't smear it",
    "start": "691810",
    "end": "698530"
  },
  {
    "text": "doesn't happen randomly over time they concentrate very hard if you just measured rates per second you get this",
    "start": "698530",
    "end": "705120"
  },
  {
    "text": "red line over there but if you are only able to handle the red line or two or",
    "start": "705120",
    "end": "710590"
  },
  {
    "text": "three or five times that you and come close to being able to handle this without blips in fact this is the",
    "start": "710590",
    "end": "715690"
  },
  {
    "text": "average across an entire day you can imagine that the bad seconds in the day have spikes they're an order of",
    "start": "715690",
    "end": "721420"
  },
  {
    "text": "magnitude bigger than this now the message here is when you design the system to handle load it needs to handle",
    "start": "721420",
    "end": "728710"
  },
  {
    "text": "the worst load you actually need to handle which is the top of this speak times 10 or whatever it is in the bad",
    "start": "728710",
    "end": "736090"
  },
  {
    "text": "seconds and that number is nowhere close to an average working on the average",
    "start": "736090",
    "end": "742510"
  },
  {
    "text": "means dying most of the time it's not a good business proposition so you need to",
    "start": "742510",
    "end": "748120"
  },
  {
    "text": "stay responsive at the top of the top of the peaks and statistics don't help you",
    "start": "748120",
    "end": "756580"
  },
  {
    "text": "know when bad things happen in the phone rings with upset customers right looking",
    "start": "756580",
    "end": "762130"
  },
  {
    "text": "at the architecture and the some of the key pieces of the execution venue at L",
    "start": "762130",
    "end": "767140"
  },
  {
    "text": "max these are block diagrams of pretty much you know gateways talking to",
    "start": "767140",
    "end": "773440"
  },
  {
    "text": "external things market makers on one side and brokers and customers on the other you have flows going into matching",
    "start": "773440",
    "end": "780790"
  },
  {
    "text": "engines and a secondary for redundancy and some journaling and it's the predate risk and credit things that happen in in",
    "start": "780790",
    "end": "789070"
  },
  {
    "text": "English English a this is called a",
    "start": "789070",
    "end": "794200"
  },
  {
    "text": "packet of chips so this is funny in England we'll take a packet and move it",
    "start": "794200",
    "end": "799750"
  },
  {
    "text": "through the system right we did the presentation in first and basically you'll have packets going in",
    "start": "799750",
    "end": "806730"
  },
  {
    "text": "coming in from market makers in this case going through a disruptor each one of these circles is a disruptor going",
    "start": "806730",
    "end": "813690"
  },
  {
    "text": "through the gateways doing whatever protocol conversions and such that happen they're going into the actual",
    "start": "813690",
    "end": "819570"
  },
  {
    "text": "execution matching engine performing the actual matching but since you need to get good records of this this goes both",
    "start": "819570",
    "end": "826200"
  },
  {
    "text": "into a journal into a second there in case failure as their joins back in when we know that both of them actually taken",
    "start": "826200",
    "end": "832860"
  },
  {
    "text": "thing whatever output formatting and processing and other things need to happen sent back through the gateway for",
    "start": "832860",
    "end": "839490"
  },
  {
    "text": "whatever conversion and sending there and then go back out to the market makers that is the typical classic path",
    "start": "839490",
    "end": "846990"
  },
  {
    "text": "of latency through the system from taking the message to getting the message back out that's the latency that",
    "start": "846990",
    "end": "853140"
  },
  {
    "text": "we're really interested in and as you see it goes through multiple hops through multiple systems in the case of",
    "start": "853140",
    "end": "858450"
  },
  {
    "text": "non market makers there is additional hops going through and that's because there's additional steps that need to happen as well now that's the picture",
    "start": "858450",
    "end": "866970"
  },
  {
    "text": "and system in Lmax looking at from an",
    "start": "866970",
    "end": "873180"
  },
  {
    "text": "Azul perspective and as a perspective the general world of Java and low latency first question we often ask is",
    "start": "873180",
    "end": "879500"
  },
  {
    "text": "really I mean why are people using Java and low latency don't you know what's",
    "start": "879500",
    "end": "885449"
  },
  {
    "text": "gonna happen right alright this is a platform that wasn't designed to pause but in practice just pauses a lot and",
    "start": "885449",
    "end": "892199"
  },
  {
    "text": "that should would seem like a contradiction and the interesting thing is the answer comes back is yes we know",
    "start": "892199",
    "end": "899040"
  },
  {
    "text": "that and we still use it and there are reasons for that for example time to stability of the platform from the day",
    "start": "899040",
    "end": "906060"
  },
  {
    "text": "we need to do something until we have it stable in people's hands running in production Java is provably better than",
    "start": "906060",
    "end": "913019"
  },
  {
    "text": "others empirically better than others across many many organizations and that's not limited to enterprise web",
    "start": "913019",
    "end": "920519"
  },
  {
    "text": "facing applications it includes low latency systems there are good proven things when people actually do this where they just get there quicker time",
    "start": "920519",
    "end": "928199"
  },
  {
    "text": "to market goes right along with that so not only do you get a good stable product you can basically ship earlier",
    "start": "928199",
    "end": "933360"
  },
  {
    "text": "not just stability but actual completeness is there quicker in one of the very important ones and",
    "start": "933360",
    "end": "938730"
  },
  {
    "text": "people underestimate this is time to performance so people might think Java might be fast might be slow and we think",
    "start": "938730",
    "end": "945720"
  },
  {
    "text": "it's pretty fast can you do faster probably but what can you do in the next",
    "start": "945720",
    "end": "952740"
  },
  {
    "text": "three months and if you start today who's gonna have a faster system in the",
    "start": "952740",
    "end": "957779"
  },
  {
    "text": "market three months from now it's almost invariably that Java beats other environments well when I mean",
    "start": "957779",
    "end": "963630"
  },
  {
    "text": "other environments I mean non run time based environments for example C C++ in doing that eventually you might be",
    "start": "963630",
    "end": "970889"
  },
  {
    "text": "faster otherwise but if you need to get there quickly for example if you have an alcohol or something yeah or you actually want to be in the",
    "start": "970889",
    "end": "978360"
  },
  {
    "text": "market quickly the amount of effort and the time to get there is shorter these are all things that we hear from",
    "start": "978360",
    "end": "984000"
  },
  {
    "text": "multiple customers not just Lmax in the actual java world as the reason that they actually code in java for low",
    "start": "984000",
    "end": "990420"
  },
  {
    "text": "latency this is the why now that way is there even without zing before we came",
    "start": "990420",
    "end": "996870"
  },
  {
    "text": "along and change the picture a little now overall productivity and delivery and everything just trump the downsides",
    "start": "996870",
    "end": "1003620"
  },
  {
    "text": "there are downsides people are aware of them but the benefit outweighs the bad so when we look at this things like Lmax",
    "start": "1003620",
    "end": "1011810"
  },
  {
    "text": "every single step we just showed you is pure Java there's an any native code in",
    "start": "1011810",
    "end": "1016880"
  },
  {
    "text": "any of these systems and this is the way it was designed from the start it was delivered and it's a poster child it is",
    "start": "1016880",
    "end": "1023089"
  },
  {
    "text": "the fastest FX trading venue out there better than whatever else there is and",
    "start": "1023089",
    "end": "1029808"
  },
  {
    "text": "it's written all in Java and this was true before Xing was started there this is purely a Java benefit now Java has",
    "start": "1029809",
    "end": "1038240"
  },
  {
    "text": "good as I said but it also comes with some bad in some uglies right so the",
    "start": "1038240",
    "end": "1043548"
  },
  {
    "text": "good is you know fast it's productive you can get really good code out of it and you know if you saw Charlie's talk",
    "start": "1043549",
    "end": "1050660"
  },
  {
    "text": "which I didn't but I've seen versions of it the the compiler isn't optimized to",
    "start": "1050660",
    "end": "1055730"
  },
  {
    "text": "do an amazing job at getting good machine code out yes you could do a little bit better in a various ways but",
    "start": "1055730",
    "end": "1061700"
  },
  {
    "text": "you get damn close to to do there so the",
    "start": "1061700",
    "end": "1066710"
  },
  {
    "text": "way I think about it is if you have good developers they will get good stuff out of anything they'll get stuff",
    "start": "1066710",
    "end": "1073680"
  },
  {
    "text": "on a machine code out of C out of C++ out of Java and most of the good developers actually no most multiple",
    "start": "1073680",
    "end": "1079020"
  },
  {
    "text": "languages and they'll choose whatever it's the right tool for their job usually it'll be whatever gets them there quicker or whatever makes it",
    "start": "1079020",
    "end": "1085620"
  },
  {
    "text": "easier and more stable whatever they're aiming for so when people I see in low latency choose Java that's not because",
    "start": "1085620",
    "end": "1091830"
  },
  {
    "text": "that's all they know most of the people I know in low latency Java are actually really good seeing C++ programmers that",
    "start": "1091830",
    "end": "1098580"
  },
  {
    "text": "choose to use Java and she tells you something the same is true in Reverse bad developers are gonna give you bad",
    "start": "1098580",
    "end": "1106260"
  },
  {
    "text": "slow code no matter what they write in you can't help that and that means you need to get good developers if you want",
    "start": "1106260",
    "end": "1113040"
  },
  {
    "text": "good code especially if performance is a hyper critical kind of thing now the",
    "start": "1113040",
    "end": "1118410"
  },
  {
    "text": "simple truth is there are more Java developers than C and C++ developers out there the hiring pool is larger by an",
    "start": "1118410",
    "end": "1126060"
  },
  {
    "text": "order of magnitude or more that's not to say that the Java guys are smarter or less smart they're just more of them so",
    "start": "1126060",
    "end": "1133560"
  },
  {
    "text": "if you're out there hiring for developers to deliver something it is easier to find people to do this it's",
    "start": "1133560",
    "end": "1139350"
  },
  {
    "text": "easier to find them and or train them to get there there's are all the good things",
    "start": "1139350",
    "end": "1145340"
  },
  {
    "text": "however JVMs are not continually fast they just weren't built that way from",
    "start": "1145340",
    "end": "1151320"
  },
  {
    "text": "the start and and we don't think of this as a design criteria of Java it's just an accidental artifact of history people",
    "start": "1151320",
    "end": "1158760"
  },
  {
    "text": "didn't think it will be used in places that are so sensitive so they didn't design that into how the runtimes work",
    "start": "1158760",
    "end": "1164400"
  },
  {
    "text": "and when you actually look at it the key things are GC but there's a lot more",
    "start": "1164400",
    "end": "1170850"
  },
  {
    "text": "than GC out there there's lions and tigers and bears and the lion is the GC",
    "start": "1170850",
    "end": "1177660"
  },
  {
    "text": "there are other things JVM do's JVMs do that's stall that even if you solve GC they will come back and bite you in a",
    "start": "1177660",
    "end": "1185520"
  },
  {
    "text": "zoo we actually look at all of them we don't think that solving GC is we're done the goal is to not blip and pause",
    "start": "1185520",
    "end": "1193310"
  },
  {
    "text": "whatever that is whatever causes that right now low latency Java and I use",
    "start": "1193310",
    "end": "1199650"
  },
  {
    "text": "quotes to describe that is usually John but written differently you use the Java syntax you write in Java but you avoid",
    "start": "1199650",
    "end": "1207790"
  },
  {
    "text": "using idiomatic Java because it's the idiomatic Java things that then make the environment eventually do the blips and",
    "start": "1207790",
    "end": "1213940"
  },
  {
    "text": "pauses and bad things so in some cases it means don't load and unload classes a lot that's I think that's fairly",
    "start": "1213940",
    "end": "1220480"
  },
  {
    "text": "reasonable but in some cases it means don't allocate objects or you still have",
    "start": "1220480",
    "end": "1225640"
  },
  {
    "text": "a key to a lot of them try to allocate so slowly that there won't be a GC and all a full GC or a knowledge in GC today",
    "start": "1225640",
    "end": "1231490"
  },
  {
    "text": "and maybe just an agent very rarely it's a very common practice and how do you do that by not being idiomatic you can't",
    "start": "1231490",
    "end": "1239650"
  },
  {
    "text": "you can either do nothing and then it's easy but if you actually do work and you're doing idiomatic Java you will be",
    "start": "1239650",
    "end": "1246190"
  },
  {
    "text": "generating lots of temporary objects that's just a side effect of idiomatic Java work if you want to do it",
    "start": "1246190",
    "end": "1251830"
  },
  {
    "text": "differently you're gonna code differently and the first step in coding differently is not using anybody else's code because everybody else's code was",
    "start": "1251830",
    "end": "1260200"
  },
  {
    "text": "written in idiomatic Java so it doesn't just matter what you do there's this nice protocol engine over there it can",
    "start": "1260200",
    "end": "1265480"
  },
  {
    "text": "parse things for you and you don't have to write it but unfortunately it allocates objects so you can't use that",
    "start": "1265480",
    "end": "1270790"
  },
  {
    "text": "and there's a nice journaling system there's nice messaging system all the",
    "start": "1270790",
    "end": "1275980"
  },
  {
    "text": "things that other people have built in Java are not directly usable if you are trying to do very low on location Java",
    "start": "1275980",
    "end": "1281830"
  },
  {
    "text": "which means you write everything yourself and you lose a lot of leverage but this does work and that's what",
    "start": "1281830",
    "end": "1288310"
  },
  {
    "text": "people tend to do so with that you know let's look at what Xing does to low",
    "start": "1288310",
    "end": "1295210"
  },
  {
    "text": "latency Java Xing is basically a JVM that values consistency we put a high",
    "start": "1295210",
    "end": "1302260"
  },
  {
    "text": "value or a high price on being inconsistent and GC noise in Xing and",
    "start": "1302260",
    "end": "1310150"
  },
  {
    "text": "other noise too has been reduced to the level where it's below the operating system noise we are not at zero we",
    "start": "1310150",
    "end": "1318190"
  },
  {
    "text": "actually do pause four times for each GC cycle but the pauses are so short",
    "start": "1318190",
    "end": "1323320"
  },
  {
    "text": "they're not perceptible for most systems even when the system is well tuned the natural noise the operating system has",
    "start": "1323320",
    "end": "1330100"
  },
  {
    "text": "is higher and more frequent than the noise we generate at this point we can improve it better",
    "start": "1330100",
    "end": "1335670"
  },
  {
    "text": "we can do better but it's becoming hard to measure because we are not the signal",
    "start": "1335670",
    "end": "1340770"
  },
  {
    "text": "we are just the noise on top of the signal at that point in the correlation is very low now that means we keep all",
    "start": "1340770",
    "end": "1348510"
  },
  {
    "text": "the good and we get rid of the bad and ugly parts so you get all the",
    "start": "1348510",
    "end": "1353700"
  },
  {
    "text": "productivity you'll get all the leverage you get to use other people's code and you get to write an idiomatic Java and",
    "start": "1353700",
    "end": "1359970"
  },
  {
    "text": "you don't have to think of those GC saving let's not pressure the GV VC let's not hurt it let's not scare it",
    "start": "1359970",
    "end": "1366240"
  },
  {
    "text": "because we're sensitive to latency if the GC just works right the way it was supposed to work from the start",
    "start": "1366240",
    "end": "1372480"
  },
  {
    "text": "regular idiomatic work shouldn't hurt and we're saying it doesn't so basically",
    "start": "1372480",
    "end": "1378000"
  },
  {
    "text": "you could just take away all the weird things people do to get around or avoid",
    "start": "1378000",
    "end": "1383190"
  },
  {
    "text": "stuff I often have debates with people that say you want high performance you gotta allocate less that's and",
    "start": "1383190",
    "end": "1390559"
  },
  {
    "text": "and some of those people are will debate it hard with me right I have a simple",
    "start": "1390559",
    "end": "1396929"
  },
  {
    "text": "proof for that on a regular hot spot GV I'm not saying I can have 20 gigabytes",
    "start": "1396929",
    "end": "1402690"
  },
  {
    "text": "per second of allocation done on a couple of threads sustained with noise",
    "start": "1402690",
    "end": "1407730"
  },
  {
    "text": "that's no bigger than 5 millisecond that's big for us but you know if there's absolutely nothing in the heap",
    "start": "1407730",
    "end": "1413400"
  },
  {
    "text": "if all you do is generate junk you can allocate that fast allocation is not a",
    "start": "1413400",
    "end": "1418530"
  },
  {
    "text": "hard thing and garbage collection behind allocation is nearly free it gets more",
    "start": "1418530",
    "end": "1424260"
  },
  {
    "text": "and more expensive in blips time to blip if you actually have objects and the",
    "start": "1424260",
    "end": "1430200"
  },
  {
    "text": "pauses get better but the efficiency is there allocation doesn't slow things down I know people think that but we",
    "start": "1430200",
    "end": "1439230"
  },
  {
    "text": "have proof that it doesn't it slows things down by creating unacceptable",
    "start": "1439230",
    "end": "1444270"
  },
  {
    "text": "blips which makes you say I can't go there and that's design differently not because you're inefficient not because",
    "start": "1444270",
    "end": "1449850"
  },
  {
    "text": "you're spending 30 percent of your time on something or your takes longer to do stuff in fact allocation is often the",
    "start": "1449850",
    "end": "1455010"
  },
  {
    "text": "fastest thing you could do in Java or in any language it's faster than object",
    "start": "1455010",
    "end": "1460590"
  },
  {
    "text": "point for example mathematically you can't do an object poll this as fast as a as an unhip allocator",
    "start": "1460590",
    "end": "1468419"
  },
  {
    "text": "so at the Lmax exchange what do we do with thing so Xing started deployment",
    "start": "1468419",
    "end": "1476019"
  },
  {
    "text": "about two years ago at L max we we did the dance and other things together but",
    "start": "1476019",
    "end": "1481240"
  },
  {
    "text": "about two years ago is when we actually started deploying in we went to an interesting and long road in deploying",
    "start": "1481240",
    "end": "1486639"
  },
  {
    "text": "it with some lessons learned we started off from incremental deployments from the most critical systems to the least",
    "start": "1486639",
    "end": "1493539"
  },
  {
    "text": "critical systems across the board and where things are now is you know we went",
    "start": "1493539",
    "end": "1498970"
  },
  {
    "text": "from a cross layton secret sensitive systems and then filled up throughput",
    "start": "1498970",
    "end": "1505029"
  },
  {
    "text": "sensitive systems that are not even latency sensitive so the expansion is now fairly wide I wouldn't say",
    "start": "1505029",
    "end": "1511090"
  },
  {
    "text": "everything is running in xing but most critical services end up being in sync as a default know the latency critical",
    "start": "1511090",
    "end": "1517179"
  },
  {
    "text": "path is obvious why you would apply it if you care about the jitter and the spikes and the stalls and the hiccups",
    "start": "1517179",
    "end": "1522549"
  },
  {
    "text": "and the noise and Elayne see path thing is simply an easy way to address those in addition to whatever other",
    "start": "1522549",
    "end": "1528309"
  },
  {
    "text": "engineering am i doing it or as a boat is a replacement for it but the",
    "start": "1528309",
    "end": "1533980"
  },
  {
    "text": "throughput critical path gets very interesting and the throughput critical path it's about speed and you need to",
    "start": "1533980",
    "end": "1540460"
  },
  {
    "text": "keep going fast so why would a blip matter if it's not an a' latency critical path what happens is if a stall",
    "start": "1540460",
    "end": "1546399"
  },
  {
    "text": "is big enough in the throughput side for example in historic market data",
    "start": "1546399",
    "end": "1551820"
  },
  {
    "text": "capturing or in gateways that transmit things to people that are not that sensitive to the latency but can't lose",
    "start": "1551820",
    "end": "1558879"
  },
  {
    "text": "stuff then you get back pressure and the back pressure says oh wait a minute I am",
    "start": "1558879",
    "end": "1564519"
  },
  {
    "text": "behind by a lot I need you to stop install and you do knocks into the critical system and you see outliers",
    "start": "1564519",
    "end": "1571269"
  },
  {
    "text": "that come from multi second or half second level things not milliseconds in",
    "start": "1571269",
    "end": "1576549"
  },
  {
    "text": "the three-foot path starting to blip the latency path so unless you have truly decoupled unbound and queues or they",
    "start": "1576549",
    "end": "1585100"
  },
  {
    "text": "built the acceptance of loss in the throughput critical side you end up affecting the latency critical side too",
    "start": "1585100",
    "end": "1590799"
  },
  {
    "text": "so that's why solving blips that are higher magnitude down there becomes important",
    "start": "1590799",
    "end": "1596940"
  },
  {
    "text": "some of them are streaming for example market data capture and journaling of stuff like that some of them are just",
    "start": "1600060",
    "end": "1607970"
  },
  {
    "text": "think of it as well I guess it'll be streaming too it's just broadcast",
    "start": "1607970",
    "end": "1613230"
  },
  {
    "text": "systems of some sort right you know I got it forward it get it to other people reformat it whatever it is but yeah so",
    "start": "1613230",
    "end": "1621570"
  },
  {
    "text": "that's an interesting thing we learned because we didn't think we'd be going after the throughput critical at the",
    "start": "1621570",
    "end": "1626580"
  },
  {
    "text": "beginning and it turned out okay there was some good value there too now if we look at the systems on the latency path",
    "start": "1626580",
    "end": "1632820"
  },
  {
    "text": "we started off with the center the heart the most important part and work to",
    "start": "1632820",
    "end": "1639000"
  },
  {
    "text": "address that in in deployed there and from there we expanded to additional pieces on the latency critical path in",
    "start": "1639000",
    "end": "1645990"
  },
  {
    "text": "that order and now we cover all those was saying and then we expanded to these other latency non latency but throughput",
    "start": "1645990",
    "end": "1653370"
  },
  {
    "text": "sensitive junk systems that could back pressure this or in general need to be happy so that's that's the order of",
    "start": "1653370",
    "end": "1660740"
  },
  {
    "text": "deployment and we'll discuss some of the lessons learned about that in in a little while",
    "start": "1660740",
    "end": "1665960"
  },
  {
    "text": "now if you look at development practices at all max I think there's a lot to learn from there in general but also how",
    "start": "1665960",
    "end": "1674430"
  },
  {
    "text": "it helped us here there's a heavy focus on test-driven development in continuous",
    "start": "1674430",
    "end": "1679980"
  },
  {
    "text": "integration at L max they're the acceptance tests that they have a very",
    "start": "1679980",
    "end": "1685200"
  },
  {
    "text": "wide and robust they have a good discipline around not doing just ad hoc testing and not retaining them for",
    "start": "1685200",
    "end": "1690330"
  },
  {
    "text": "regression and such and then if every test systems for test generation performance is tested like correctness",
    "start": "1690330",
    "end": "1698490"
  },
  {
    "text": "news and that's a very very important thing to understand and it was extremely valuable in going through this process",
    "start": "1698490",
    "end": "1704690"
  },
  {
    "text": "because the performance regression is considered a failure which a lot of",
    "start": "1704690",
    "end": "1710670"
  },
  {
    "text": "systems fail to do they'll have a side thing that gives them performance but they don't treat it the same way and",
    "start": "1710670",
    "end": "1716220"
  },
  {
    "text": "they treated extremely in extreme ways in a sense of like that is a breakage",
    "start": "1716220",
    "end": "1722220"
  },
  {
    "text": "you just don't go any forward from that you don't kind of keep going and hope to fix it later and that's a very very",
    "start": "1722220",
    "end": "1728310"
  },
  {
    "text": "healthy way to look at it for you'd need to have the test and then you need to actually treat them seriously",
    "start": "1728310",
    "end": "1734170"
  },
  {
    "text": "confidence you get confidence out of that to create large changes because you",
    "start": "1734170",
    "end": "1739970"
  },
  {
    "text": "have the coverage you actually have a feel for what it'll be like when you deploy it rather than you got this nice",
    "start": "1739970",
    "end": "1746270"
  },
  {
    "text": "functional thing that seems to work well but you know we don't quite know what the performance will be like because we",
    "start": "1746270",
    "end": "1752450"
  },
  {
    "text": "don't have a good robust set of tests for performance the fact that there's a good set of tests for it and a good modeling system for you know packet",
    "start": "1752450",
    "end": "1758840"
  },
  {
    "text": "arrivals and stuff like that allows you to say what if we deployed this and get relatively high confidence in doing this",
    "start": "1758840",
    "end": "1764690"
  },
  {
    "text": "the real world is always the real world but those thing in Lmax",
    "start": "1764690",
    "end": "1770260"
  },
  {
    "text": "produces some benefits we would like to see first of all we see improved latency",
    "start": "1770260",
    "end": "1775580"
  },
  {
    "text": "behaviors and that that's that's obviously one of the key features we",
    "start": "1775580",
    "end": "1780650"
  },
  {
    "text": "would look for right actually measureable improved latency behaviors but interesting Lee probably the most",
    "start": "1780650",
    "end": "1787430"
  },
  {
    "text": "important or the more important value over time is not the improvement in latency because in reality give good",
    "start": "1787430",
    "end": "1794180"
  },
  {
    "text": "engineers a task of improving latency they will find a way to do it it's a reduction in the engineering",
    "start": "1794180",
    "end": "1799940"
  },
  {
    "text": "effort in general and engineering effort aimed at reducing and keeping latency healthy that is the real benefit it's",
    "start": "1799940",
    "end": "1806780"
  },
  {
    "text": "not the thing is the only way to get this you can rewrite the whole thing in not Java and maybe get better latency",
    "start": "1806780",
    "end": "1811820"
  },
  {
    "text": "consistency that would just take a lot of work and hurt your productivity and time to market but it's doable the",
    "start": "1811820",
    "end": "1818120"
  },
  {
    "text": "actual measurable things are how much efforts do you spend on these problems and how much time do you save from that",
    "start": "1818120",
    "end": "1823910"
  },
  {
    "text": "I wouldn't say that we have specific numbers from that or at least not ones that you could share am i running no I",
    "start": "1823910",
    "end": "1832700"
  },
  {
    "text": "don't think I'm gonna think I'm running behind I think that was just early good okay hopefully come looking at the clock",
    "start": "1832700",
    "end": "1838640"
  },
  {
    "text": "and saying Wow 35 minutes in the RT clap Wow you can clap for me if you wanted but we",
    "start": "1838640",
    "end": "1848540"
  },
  {
    "text": "will continue good okay so look not only do you get better latency behavior but",
    "start": "1848540",
    "end": "1854810"
  },
  {
    "text": "you no longer battle this stuff and know battling means you don't have to think",
    "start": "1854810",
    "end": "1860930"
  },
  {
    "text": "about it performance unit go through three weeks of the new thing is there and it regressed them we're fixing it",
    "start": "1860930",
    "end": "1866309"
  },
  {
    "text": "every time so it's not just the numbers it's the time to get those numbers in the effort and the cost to get those",
    "start": "1866309",
    "end": "1872550"
  },
  {
    "text": "numbers idiomatic Java and being able to use it or use it again or not stop using",
    "start": "1872550",
    "end": "1879300"
  },
  {
    "text": "it it's a big deal and this all of those have happened here so there are places where there are new functionality needed",
    "start": "1879300",
    "end": "1886800"
  },
  {
    "text": "and oh you can use the DI Matic Java and other people's code to do it there are places where you're able to keep using",
    "start": "1886800",
    "end": "1894240"
  },
  {
    "text": "it because the alternative to getting what you want was to re-engineer away from it and they're places where it was",
    "start": "1894240",
    "end": "1899250"
  },
  {
    "text": "engineer the way and now you could go back to using it all of these have",
    "start": "1899250",
    "end": "1905010"
  },
  {
    "text": "happened within the systems right at various degrees so you can avoid doing special practices you can avoid easing",
    "start": "1905010",
    "end": "1912840"
  },
  {
    "text": "up an allocation style so you can avoid you know not using other people's code",
    "start": "1912840",
    "end": "1917850"
  },
  {
    "text": "so you can go back to good productive things and that gives more leverage it makes the Java choice even more right",
    "start": "1917850",
    "end": "1924840"
  },
  {
    "text": "than it was before Zee Java was right to begin with but I think we we we kind of",
    "start": "1924840",
    "end": "1930510"
  },
  {
    "text": "tipped the scales much more now let's look at some specific things or yeah",
    "start": "1930510",
    "end": "1943850"
  },
  {
    "text": "let's talk about actual numbers so I I asked yeah okay you're right",
    "start": "1943850",
    "end": "1949309"
  },
  {
    "text": "exactly I asked for actual numbers these are the numbers that Lmax was willing to",
    "start": "1949309",
    "end": "1955470"
  },
  {
    "text": "share and here's some interesting things so Xing helped tame new Jenji C's which",
    "start": "1955470",
    "end": "1962610"
  },
  {
    "text": "is most of what they dealt with keys remember this is highly tuned code across across the spectrum and for",
    "start": "1962610",
    "end": "1969690"
  },
  {
    "text": "example in a previously highly engineered system this is systems that you know the center of the center the",
    "start": "1969690",
    "end": "1975059"
  },
  {
    "text": "thing all the engineers were were looking at thing was already highly tuned the improvement was from four",
    "start": "1975059",
    "end": "1980730"
  },
  {
    "text": "milli second blips which is amazingly good every 30 million every 30 seconds",
    "start": "1980730",
    "end": "1986070"
  },
  {
    "text": "to a one millisecond blip every two hours so we took a really good system",
    "start": "1986070",
    "end": "1991500"
  },
  {
    "text": "and maybe it made it a lot better so okay the magnitude is much smaller for the blip right 1/4",
    "start": "1991500",
    "end": "1998979"
  },
  {
    "text": "but the frequency is dramatically slower this is hundreds of times less frequent for outliers so multiple orders of",
    "start": "1998979",
    "end": "2006809"
  },
  {
    "text": "magnitude of betterness from a latency outlier and glitch and people being angry at the performance point of view",
    "start": "2006809",
    "end": "2013159"
  },
  {
    "text": "now in a less well tuned system this is still low latency but just not that much",
    "start": "2013159",
    "end": "2018389"
  },
  {
    "text": "attention like a formula it can give hey these guys are excellent right somebody who could get an actual Java system",
    "start": "2018389",
    "end": "2024570"
  },
  {
    "text": "running in production do not bleed from more than 4 millisecond without saying hats off to them thank you",
    "start": "2024570",
    "end": "2032450"
  },
  {
    "text": "but in in the normal ones lips that were 50 milliseconds roughly every 30 seconds",
    "start": "2032450",
    "end": "2038700"
  },
  {
    "text": "went down to 3 every 15 so in order of magnitude reduction in magnitude in the",
    "start": "2038700",
    "end": "2044609"
  },
  {
    "text": "size and an order of magnitude reduction in frequency at the same time these are",
    "start": "2044609",
    "end": "2050309"
  },
  {
    "text": "actual impacts on actual systems measured from before saying deployment to after overtime right so where are we",
    "start": "2050309",
    "end": "2057480"
  },
  {
    "text": "to think anything and these did not involve engineering to work around you see quite the opposite right now that",
    "start": "2057480",
    "end": "2064108"
  },
  {
    "text": "was new gen alchun also happens not in the latency critical path so much except",
    "start": "2064109",
    "end": "2071220"
  },
  {
    "text": "when you have you know surprising bandwidth and surprising volumes because if you actually look at how low latency",
    "start": "2071220",
    "end": "2078059"
  },
  {
    "text": "systems avoid doing all gen anything they just have a big enough audience so",
    "start": "2078059",
    "end": "2083099"
  },
  {
    "text": "the promotion throughout the day or the week in an FX system doesn't fill it up so it never needs to collect that works",
    "start": "2083099",
    "end": "2089429"
  },
  {
    "text": "great until you have a higher volume event where this week has five times the volume of a regular weekend maybe you do",
    "start": "2089429",
    "end": "2095579"
  },
  {
    "text": "have to collect it right in the list these critical systems this happens even",
    "start": "2095579",
    "end": "2101160"
  },
  {
    "text": "more because people just haven't spent the engineering to avoid allocating enough and promoting enough they just",
    "start": "2101160",
    "end": "2107640"
  },
  {
    "text": "have real-world things there and in those cases the CMS this is a concurrent",
    "start": "2107640",
    "end": "2113160"
  },
  {
    "text": "mark-sweep collector that most people in a latency a response time sensitive environment in Java would use on hotspot",
    "start": "2113160",
    "end": "2119700"
  },
  {
    "text": "today generally they've had you know 1/2 second level blips intraday and there's",
    "start": "2119700",
    "end": "2125369"
  },
  {
    "text": "a completely gone that means you know there's no more back pressure on from the throughput critical",
    "start": "2125369",
    "end": "2132809"
  },
  {
    "text": "system into the latency critical systems and that helped now Priya's ill these would occur less",
    "start": "2132809",
    "end": "2140670"
  },
  {
    "text": "predictably but multiple times right they would happen all over the place and you'd have to hunt them down and be",
    "start": "2140670",
    "end": "2145680"
  },
  {
    "text": "quiet kind of depends on traffic patterns and the behaviors I guess now after they deployed zing this only",
    "start": "2145680",
    "end": "2152730"
  },
  {
    "text": "happens if somebody forgets to turn singh on or to use thing because hey they're still using stuff every once in",
    "start": "2152730",
    "end": "2158490"
  },
  {
    "text": "a while for everything's okay so let's look at some lessons learned from this and I would say I could wear the hat or",
    "start": "2158490",
    "end": "2166349"
  },
  {
    "text": "not these are lessons learned together now first of all what would we do a",
    "start": "2166349",
    "end": "2171869"
  },
  {
    "text": "little different in this deployment it's a natural thing to do we went after the",
    "start": "2171869",
    "end": "2177900"
  },
  {
    "text": "problem by attacking the critical problem first this is the the hardest",
    "start": "2177900",
    "end": "2183089"
  },
  {
    "text": "thing to do in the system right we went after the heart of the exchange the execution venue this is the thing that",
    "start": "2183089",
    "end": "2190079"
  },
  {
    "text": "was only pausing for four milliseconds it was extremely well engineered this is",
    "start": "2190079",
    "end": "2195630"
  },
  {
    "text": "where people had focused all their effort and engineering effort and we went to go and make that better now",
    "start": "2195630",
    "end": "2200640"
  },
  {
    "text": "obviously it's the heart and it's the highest value point but it's also the one that's had the most effort put into",
    "start": "2200640",
    "end": "2205920"
  },
  {
    "text": "it it's also the one that's the riskiest the most conservative from a decision",
    "start": "2205920",
    "end": "2211230"
  },
  {
    "text": "point of view right if you go and do that you know you need to beat the engineering effort and you'll have",
    "start": "2211230",
    "end": "2216660"
  },
  {
    "text": "smaller games and you'll have to gain confidence on the bet the business part",
    "start": "2216660",
    "end": "2222059"
  },
  {
    "text": "of the thing right that's what we did and we did and we made it through but it was a long time to get there because you",
    "start": "2222059",
    "end": "2229770"
  },
  {
    "text": "know you need to show the numbers achieve the numbers and get a lot of confidence that the real will will",
    "start": "2229770",
    "end": "2234809"
  },
  {
    "text": "happen before you cut over we succeeded in doing that and from there we expanded",
    "start": "2234809",
    "end": "2239849"
  },
  {
    "text": "to them much easier systems right but with hindsight we could have started either backwards or concurrently don't",
    "start": "2239849",
    "end": "2247470"
  },
  {
    "text": "take the biggest bully on the playground and go punch him in the nose and take on the fight and when you win that let's",
    "start": "2247470",
    "end": "2253260"
  },
  {
    "text": "let's deal with other people just let's play with everybody else first let's get a coalition going that's good talk to",
    "start": "2253260",
    "end": "2260010"
  },
  {
    "text": "the altogether right we could have taken the things that took us a day or two to show",
    "start": "2260010",
    "end": "2266020"
  },
  {
    "text": "extreme value in that are not as critical that could be converted easily",
    "start": "2266020",
    "end": "2271120"
  },
  {
    "text": "with high confidence or without that much confidence just to show that we have confidence develop confidence there",
    "start": "2271120",
    "end": "2277480"
  },
  {
    "text": "there are food good practices there get a lot of value there places where what",
    "start": "2277480",
    "end": "2282490"
  },
  {
    "text": "we did is remove a 500 milli second instead of formula second live and with that take out potentially a lot of",
    "start": "2282490",
    "end": "2289390"
  },
  {
    "text": "engineering that wasn't yet done so a lot of value to be saved as opposed to here where you know it's less value and",
    "start": "2289390",
    "end": "2296320"
  },
  {
    "text": "then after we did those go after that critical thing so ending in the exact same total deployment picture we could",
    "start": "2296320",
    "end": "2302230"
  },
  {
    "text": "probably have gotten there faster by starting from the easier first things or at least working concurrently not see",
    "start": "2302230",
    "end": "2307840"
  },
  {
    "text": "early through them so we probably would have seen quicker ROI quicker time to",
    "start": "2307840",
    "end": "2314170"
  },
  {
    "text": "gain and and quicker confidence in the delivery of what we do obviously the",
    "start": "2314170",
    "end": "2320410"
  },
  {
    "text": "choice to go with us was done based on what everybody believed we could do but",
    "start": "2320410",
    "end": "2327250"
  },
  {
    "text": "showing that that actually happens getting to a point where two years later they just know it's right there's no",
    "start": "2327250",
    "end": "2333580"
  },
  {
    "text": "point in doing the other in if you're latency-sensitive getting there takes time takes actual",
    "start": "2333580",
    "end": "2339880"
  },
  {
    "text": "showing real production stability quality and actual delivery okay so we",
    "start": "2339880",
    "end": "2347860"
  },
  {
    "text": "could have gone in a different order other lessons learned she sees not the",
    "start": "2347860",
    "end": "2352900"
  },
  {
    "text": "only problem she's just the biggest blip that makes you think but you take that",
    "start": "2352900",
    "end": "2358060"
  },
  {
    "text": "out there are other things there for example you do have dominated outliers",
    "start": "2358060",
    "end": "2363580"
  },
  {
    "text": "so it's natural to think everything is there to pay most attention to it but",
    "start": "2363580",
    "end": "2368590"
  },
  {
    "text": "once it's gone other problems surface so some of the harder things page cache",
    "start": "2368590",
    "end": "2373990"
  },
  {
    "text": "lock contention certain Linux kernels have extremely bad locking behavior around emptying page caches so in",
    "start": "2373990",
    "end": "2381520"
  },
  {
    "text": "systems Journal where a lot of loneliness this doesn't have to journal because they're dealing with money then",
    "start": "2381520",
    "end": "2387820"
  },
  {
    "text": "when the kernel stalls to write a whole bunch of stuff it orphans actually locks and stops progress and",
    "start": "2387820",
    "end": "2393130"
  },
  {
    "text": "systems parts and even the lower the the the things there's an outside of latency",
    "start": "2393130",
    "end": "2398680"
  },
  {
    "text": "critical path going to disk might stall other things that are latency critical power management tuning bias and OS lots",
    "start": "2398680",
    "end": "2405250"
  },
  {
    "text": "of tuning things were very important air map file access and page faults and safe",
    "start": "2405250",
    "end": "2410920"
  },
  {
    "text": "points in the interaction between them which are not unique to you know did they apparent they apparently happened",
    "start": "2410920",
    "end": "2416440"
  },
  {
    "text": "on all runtimes zing and nuns in could come in and create some interesting issues now one of the big lessons",
    "start": "2416440",
    "end": "2424750"
  },
  {
    "text": "learned was to proactively not reactively but proactively override Linux defaults Linux has a whole bunch",
    "start": "2424750",
    "end": "2432400"
  },
  {
    "text": "of things that are just bad defaults if you care about latency behavior they're there to save power in the data center",
    "start": "2432400",
    "end": "2438880"
  },
  {
    "text": "not to make your application behave well and if you care about your application behavior more than you care about the",
    "start": "2438880",
    "end": "2445000"
  },
  {
    "text": "power in the data center did the wrong choice so you know examples let's go to",
    "start": "2445000",
    "end": "2451299"
  },
  {
    "text": "specifics this goes this way it's my second yeah the page cache tends to be",
    "start": "2451299",
    "end": "2458859"
  },
  {
    "text": "dramatically miss configured by default on on Linux and this specific parameter",
    "start": "2458859",
    "end": "2464980"
  },
  {
    "text": "is the distance from filling all the memory before the page guest starts flushing things out how much empty",
    "start": "2464980",
    "end": "2471069"
  },
  {
    "text": "memory is it aiming to keep in the system for things like I don't know allocating memory with Malik's right now",
    "start": "2471069",
    "end": "2477430"
  },
  {
    "text": "interestingly the choice of the number for that was chosen about 20 years ago I",
    "start": "2477430",
    "end": "2483430"
  },
  {
    "text": "think around to 1995 or 96 and it was modeled according to size of servers",
    "start": "2483430",
    "end": "2489430"
  },
  {
    "text": "back then 20 years ago and then they didn't fix it at a constant they had a",
    "start": "2489430",
    "end": "2495490"
  },
  {
    "text": "model for it growing but it doesn't grow linearly it grows to the square root of the system size so we have 20 years of",
    "start": "2495490",
    "end": "2502599"
  },
  {
    "text": "accumulated system size which roughly translates to if 20 years around Moore's",
    "start": "2502599",
    "end": "2508210"
  },
  {
    "text": "law is probably under five to ten thousand X capacity but instead of",
    "start": "2508210",
    "end": "2513339"
  },
  {
    "text": "growing the buffer from the edge of memory by five thousand x over time it was the square root of 5,000 X which is",
    "start": "2513339",
    "end": "2519400"
  },
  {
    "text": "much smaller number and what that in practice means is that the filesystem runs into the edge of memory all the",
    "start": "2519400",
    "end": "2524740"
  },
  {
    "text": "time creating situations where you have no empty memory and it has to get rid of stuff but it takes time to get rid of",
    "start": "2524740",
    "end": "2530920"
  },
  {
    "text": "stuff therefore you have a blip on a simple memory allocation or an expansion",
    "start": "2530920",
    "end": "2537150"
  },
  {
    "text": "transparent huge pages a really really really cool feature for efficiency that is really really really bad for any",
    "start": "2537150",
    "end": "2543820"
  },
  {
    "text": "latency measurement this thing should be turned off it is turned on by default",
    "start": "2543820",
    "end": "2549060"
  },
  {
    "text": "without expanding on it here the simple",
    "start": "2549060",
    "end": "2554530"
  },
  {
    "text": "behavior you could experience if this feature is on is that your thread because it's doing some malloc or",
    "start": "2554530",
    "end": "2562170"
  },
  {
    "text": "expanding a stack or something else might be the one that stalls to defragment all memory in the system for",
    "start": "2562170",
    "end": "2569380"
  },
  {
    "text": "the next second and which thread gets hit with that is just Russian Roulette",
    "start": "2569380",
    "end": "2575610"
  },
  {
    "text": "the more I owe you do in your system the more fragmented large pages are into small pages the more likely this is to",
    "start": "2575610",
    "end": "2582100"
  },
  {
    "text": "happen unfortunately there's a lot of journaling IO happening in most of these systems so it's very easy at all sois",
    "start": "2582100",
    "end": "2589690"
  },
  {
    "text": "penis needs to be set to zero for some reason it's not I don't know why people",
    "start": "2589690",
    "end": "2595450"
  },
  {
    "text": "with a hundred gigabyte system needed to gigabytes swap file except for to make the latency bad I don't know what it's",
    "start": "2595450",
    "end": "2601780"
  },
  {
    "text": "good for other than that but you know should be off and off and then this is",
    "start": "2601780",
    "end": "2607210"
  },
  {
    "text": "an interesting play mode it turns out that by default at least in some kernels",
    "start": "2607210",
    "end": "2614230"
  },
  {
    "text": "when you have multi node systems like a two socket system as a multi node system you could be turning you could have swap",
    "start": "2614230",
    "end": "2623170"
  },
  {
    "text": "off on swap set off but if you end up in",
    "start": "2623170",
    "end": "2629260"
  },
  {
    "text": "a case where one of the nodes is out of memory but the other one has memory it will still fall so unless you turn this",
    "start": "2629260",
    "end": "2636520"
  },
  {
    "text": "zone reclaim on to zero you your swap eNOS could still not take effect and",
    "start": "2636520",
    "end": "2643660"
  },
  {
    "text": "their other around the page caching to you as well so each and every one of these if you don't set it right can and",
    "start": "2643660",
    "end": "2650860"
  },
  {
    "text": "will cause multi hundred milliseconds in your Linux system without Java being",
    "start": "2650860",
    "end": "2656470"
  },
  {
    "text": "involved so if you don't take them out proactively you and wait until they happen you're just",
    "start": "2656470",
    "end": "2662650"
  },
  {
    "text": "gonna have a big mess to try and figure out so it's really hard to prove that it's one of those when they happen it's",
    "start": "2662650",
    "end": "2668200"
  },
  {
    "text": "really hard to point a finger to them each one of them has been built through experience of accidentally running into",
    "start": "2668200",
    "end": "2673570"
  },
  {
    "text": "a proof that one of these did something so think the lessons learned from a big",
    "start": "2673570",
    "end": "2679350"
  },
  {
    "text": "industry that you know has run into things and there are other sets but these are good examples to start with",
    "start": "2679350",
    "end": "2686190"
  },
  {
    "text": "okay some more lessons learned measure measure everything measure everywhere",
    "start": "2686190",
    "end": "2692320"
  },
  {
    "text": "you can you know we you know at L max measurement was already been done to a",
    "start": "2692320",
    "end": "2698470"
  },
  {
    "text": "lot of things but measurement of things like jitter and hiccups and",
    "start": "2698470",
    "end": "2703570"
  },
  {
    "text": "inconsistencies is a hard thing because of what you tend to summarize data so you have a good average as good maxes",
    "start": "2703570",
    "end": "2709810"
  },
  {
    "text": "maybe but when and how much and what the spread is is hard so it's really hard to collect this and it's worth spending the",
    "start": "2709810",
    "end": "2716320"
  },
  {
    "text": "efforts to put an infrastructure collected not just within parts but across multiple hops you saw the kind of",
    "start": "2716320",
    "end": "2722710"
  },
  {
    "text": "hops that a critical path for this measuring it not just at every point but across them with consistent time is",
    "start": "2722710",
    "end": "2728260"
  },
  {
    "text": "important the other one is if you want detailed latency distribution measurements that means you can't sample",
    "start": "2728260",
    "end": "2734860"
  },
  {
    "text": "and you can't average and you have to keep either keep a lot of information or",
    "start": "2734860",
    "end": "2740380"
  },
  {
    "text": "record it in a way that supports doing that and if you have information about",
    "start": "2740380",
    "end": "2746020"
  },
  {
    "text": "the latency outliers at every step and across the whole that really helps you triage where to look so if you have a",
    "start": "2746020",
    "end": "2752350"
  },
  {
    "text": "blip on the end-to-end latency but you don't have a record of where other where what the spread is on latency on",
    "start": "2752350",
    "end": "2757840"
  },
  {
    "text": "different nodes you don't know where to start looking within them the averages are good everywhere it's a blip so you",
    "start": "2757840",
    "end": "2764020"
  },
  {
    "text": "need to know which one's had blips and look for correlations if you don't record enough information for tracking",
    "start": "2764020",
    "end": "2769090"
  },
  {
    "text": "blips it's their full percentile spectrum histograms are very useful for this I've actually built an open source",
    "start": "2769090",
    "end": "2774910"
  },
  {
    "text": "library that's very useful for that call HDR histogram Michael Barker from L max",
    "start": "2774910",
    "end": "2779920"
  },
  {
    "text": "created the seaport of the same library so it's now in Java and C there's a c-sharp port a python port a go port in",
    "start": "2779920",
    "end": "2788680"
  },
  {
    "text": "Erlang port I'm waiting for the JavaScript port you want to do a ruby one well you can just use the Java one from",
    "start": "2788680",
    "end": "2795500"
  },
  {
    "text": "JRuby so you don't care yeah so it's it's it's become a very popular library",
    "start": "2795500",
    "end": "2800690"
  },
  {
    "text": "for doing exactly that if you're interested in measurement I recommend you do that and I'm also doing a",
    "start": "2800690",
    "end": "2806180"
  },
  {
    "text": "full-day workshop on it on Thursday if you're really interested and not on HD or Instagram but latency measurement and",
    "start": "2806180",
    "end": "2812090"
  },
  {
    "text": "coordination is general recording system level hiccups at all levels is extremely",
    "start": "2812090",
    "end": "2818510"
  },
  {
    "text": "useful for triaging there's a tool again I I actually created it three years ago",
    "start": "2818510",
    "end": "2824300"
  },
  {
    "text": "and open source is called J hiccup and all it does is basically measures whether your process experienced the",
    "start": "2824300",
    "end": "2829700"
  },
  {
    "text": "hiccup meaning it was supposed to be able to actually couldn't couldn't it measures every milliseconds so anything",
    "start": "2829700",
    "end": "2834920"
  },
  {
    "text": "bigger than a millisecond of blip for whatever reason can't hide from it you run one of those in your JVM to see if",
    "start": "2834920",
    "end": "2841490"
  },
  {
    "text": "your JVM is blipping you run one of those idle in another process to see if the system is blipping and you keep",
    "start": "2841490",
    "end": "2847040"
  },
  {
    "text": "records forever for that well for weeks not because you need to know all the",
    "start": "2847040",
    "end": "2852710"
  },
  {
    "text": "time but because somebody calls you up and says there was a bad transaction with a blip and you try and figure out",
    "start": "2852710",
    "end": "2857750"
  },
  {
    "text": "where the blip happen and whether it was a system blip or JVM flip an application code blip if you find that your system blip for",
    "start": "2857750",
    "end": "2864560"
  },
  {
    "text": "the same magnitude as the complaint you don't need to look at application code there's nothing wrong with the application code something in the OS or",
    "start": "2864560",
    "end": "2871310"
  },
  {
    "text": "in the hardware or something blipped if you find that the system was fine but",
    "start": "2871310",
    "end": "2876680"
  },
  {
    "text": "the GPM blipped well then you know the system's fine and go look at the JVM",
    "start": "2876680",
    "end": "2882080"
  },
  {
    "text": "itself maybe the tuning is wrong maybe you're just not using sync then if both of these are nice and quiet and you have",
    "start": "2882080",
    "end": "2888650"
  },
  {
    "text": "a blip then some things go look in your code maybe you have a cue maybe you have some other thing that happened maybe the",
    "start": "2888650",
    "end": "2894470"
  },
  {
    "text": "latency on the wire is wrong maybe of bad wires but the triage ability of that slicing which parser system to go hunt",
    "start": "2894470",
    "end": "2900710"
  },
  {
    "text": "down are critical for evolving good latency over time now if you look at",
    "start": "2900710",
    "end": "2906430"
  },
  {
    "text": "observation points that lmax is used yep I'll wrap up in two minutes",
    "start": "2906430",
    "end": "2913370"
  },
  {
    "text": "observation points you can see across here there are multiple points that",
    "start": "2913370",
    "end": "2918500"
  },
  {
    "text": "latency numbers or time stamping numbers are collected an interesting thing is",
    "start": "2918500",
    "end": "2923870"
  },
  {
    "text": "the more points you add the more it becomes interesting to think of how you collect the data and where you put it so you take the message and you",
    "start": "2923870",
    "end": "2931250"
  },
  {
    "text": "track it through and you want to know when and where things happen and if it's a handful of things then okay you can",
    "start": "2931250",
    "end": "2937220"
  },
  {
    "text": "often add it to the payload that a lot of people will do that that's a good starting point but if you actually go",
    "start": "2937220",
    "end": "2942559"
  },
  {
    "text": "through and start wanting to have many many data points of where things were at",
    "start": "2942559",
    "end": "2948260"
  },
  {
    "text": "what time for a message it starts being a challenge to put that data in the messages it goes through there might not",
    "start": "2948260",
    "end": "2953809"
  },
  {
    "text": "be room for 50 data points in the payload or you're strongly affect the system at that point it becomes nicer",
    "start": "2953809",
    "end": "2961250"
  },
  {
    "text": "and better and probably much more scalable to start logging the latency points as metadata on a side stream so",
    "start": "2961250",
    "end": "2968390"
  },
  {
    "text": "the messages are going through and you don't carry that when I was where on the actual payload you just log to the side",
    "start": "2968390",
    "end": "2975500"
  },
  {
    "text": "message ID this was here at this time and that's a stream of metadata going to the side not latency critical you just",
    "start": "2975500",
    "end": "2981140"
  },
  {
    "text": "need to get it somewhere either a journal or another system and later you go and correlate them all that becomes a",
    "start": "2981140",
    "end": "2987680"
  },
  {
    "text": "post processing streaming thing again the purpose of this is for knowing what",
    "start": "2987680",
    "end": "2993020"
  },
  {
    "text": "when you need to know you can look at it or you could do samples and monitoring with it too but it's a very very useful",
    "start": "2993020",
    "end": "2999890"
  },
  {
    "text": "thing and it's worthwhile investing in that investing a lot I think because if",
    "start": "2999890",
    "end": "3005829"
  },
  {
    "text": "you don't do that you're gonna invest a lot in debugging in the dark so let's",
    "start": "3005829",
    "end": "3011170"
  },
  {
    "text": "look at summary and wrap up Java is viable and profitable in low latency these are often things that people",
    "start": "3011170",
    "end": "3017710"
  },
  {
    "text": "challenge it is viable people do it anyway and it's profitable to do it you",
    "start": "3017710",
    "end": "3024040"
  },
  {
    "text": "can show numbers of why economically this is a good choice from a development effort from a cost perspective from a",
    "start": "3024040",
    "end": "3029619"
  },
  {
    "text": "profitability a time to perform it's time to profit kind of thing with regular JVMs you have to jump through a",
    "start": "3029619",
    "end": "3036880"
  },
  {
    "text": "lot of Hoops to get there but it's still profitable and viable people do this all over the world and thing basically helps",
    "start": "3036880",
    "end": "3042910"
  },
  {
    "text": "in that well to make it even more profitable and even more viable right so",
    "start": "3042910",
    "end": "3048250"
  },
  {
    "text": "it's easier to do it and it's as easy and low latency in other languages so",
    "start": "3048250",
    "end": "3055329"
  },
  {
    "text": "think of it as it's the speed of Java which is similar to speed of other languages now",
    "start": "3055329",
    "end": "3062230"
  },
  {
    "text": "with the consistency of other languages too now once you stop dealing with j-b a related issue you can actually go and",
    "start": "3062230",
    "end": "3069490"
  },
  {
    "text": "take your smartest people and apply them to the interesting and good stuff think",
    "start": "3069490",
    "end": "3075010"
  },
  {
    "text": "to that opening slide where Mark showed what he used to do on a regular basis",
    "start": "3075010",
    "end": "3081130"
  },
  {
    "text": "people would come to him with GC longus and try to figure out together what to do about them he doesn't do that anymore",
    "start": "3081130",
    "end": "3087640"
  },
  {
    "text": "he hasn't done this in a long time the answer to a bad GC log is wiring out",
    "start": "3087640",
    "end": "3092650"
  },
  {
    "text": "running in Z and we don't get bad GC logs from saying or we haven't seen them",
    "start": "3092650",
    "end": "3098260"
  },
  {
    "text": "at least so that's that's a simple summary with that so with that I you",
    "start": "3098260",
    "end": "3104770"
  },
  {
    "text": "know do we have a little time for Q&A or we have to go okay well well yeah we",
    "start": "3104770",
    "end": "3112869"
  },
  {
    "text": "started five minutes late so I think we're even but if you guys want to I mean I think we're last year and we can go out but if you guys want to ask me or",
    "start": "3112869",
    "end": "3120369"
  },
  {
    "text": "me a question I'd be happy to answer",
    "start": "3120369",
    "end": "3125038"
  }
]
[
  {
    "text": "thank you everybody for joining us today my name is Adam Wagner I'm a principal serverless Solutions architect at AWS",
    "start": "11679",
    "end": "18840"
  },
  {
    "text": "I'm joined by Uma my name is Umar ramadas I am also a Solutions architect at AWS and I focused on Silver lless so",
    "start": "18840",
    "end": "26840"
  },
  {
    "text": "today we are going to talk about some of the pain points point of processing data",
    "start": "26840",
    "end": "32040"
  },
  {
    "text": "and especially large scale data and how those pain points can be alleviated by",
    "start": "32040",
    "end": "39000"
  },
  {
    "text": "soes and so we'll go through some of the benefits of soes data processing and",
    "start": "39000",
    "end": "44840"
  },
  {
    "text": "we'll also show you how to accelerate that data processing when you're using services such as AWS step functions and",
    "start": "44840",
    "end": "51239"
  },
  {
    "text": "AWS Lambda we'll show you a demo and leave you with some best practices and key",
    "start": "51239",
    "end": "56520"
  },
  {
    "text": "takeaways the goal of the session is to leave you with an understanding that how you can process data with AWS step",
    "start": "56520",
    "end": "64080"
  },
  {
    "text": "functions and AWS Lambda and how to get quickly started when you build it",
    "start": "64080",
    "end": "70920"
  },
  {
    "text": "yourself when you are presented with large scale data processing problem you",
    "start": "71159",
    "end": "76320"
  },
  {
    "text": "come up with some Design Technology choices based on some traits of data like for example type of data volume of",
    "start": "76320",
    "end": "83240"
  },
  {
    "text": "data I have given here some common traits that you would use to come up with that design uh choice",
    "start": "83240",
    "end": "90600"
  },
  {
    "text": "the first of all is scale in many aspects of our life you know whether from business intera",
    "start": "90600",
    "end": "97280"
  },
  {
    "text": "business operations to personal interactions we use digital platform and",
    "start": "97280",
    "end": "102360"
  },
  {
    "text": "these digital platforms or digital Transformations has led to generation of vast amount of data so understanding the",
    "start": "102360",
    "end": "109840"
  },
  {
    "text": "scale and growth of the data will help you choose the right technology that you are going to use timeliness most data",
    "start": "109840",
    "end": "117719"
  },
  {
    "text": "processing jobs are scheduled jobs so when you have a schedule job scheduling jobs it introduces delay in",
    "start": "117719",
    "end": "124960"
  },
  {
    "text": "understanding the meaning of the data so if you want to understand the meaning of the data quickly go to market faster you",
    "start": "124960",
    "end": "131560"
  },
  {
    "text": "want to look at technologies that offer you real time or even driven data processing Solutions or even microbatch",
    "start": "131560",
    "end": "138560"
  },
  {
    "text": "processing Solutions variability fluctuations in data volume is common",
    "start": "138560",
    "end": "144720"
  },
  {
    "text": "due to season seasonality of the trend or or like say sales events like Black",
    "start": "144720",
    "end": "151519"
  },
  {
    "text": "Friday variability means you also have to have scalable infrastructure and",
    "start": "151519",
    "end": "156840"
  },
  {
    "text": "resources being able to scale up and scale down when you know data uh spikes",
    "start": "156840",
    "end": "163120"
  },
  {
    "text": "happens integration data processing is not a single task most often it consists",
    "start": "163120",
    "end": "169879"
  },
  {
    "text": "of a multiple distinct steps from cleansing to formatting",
    "start": "169879",
    "end": "176080"
  },
  {
    "text": "transforming um you know aggregating reporting Etc and sometimes these",
    "start": "176080",
    "end": "181680"
  },
  {
    "text": "distinct task happen in purpose built Services you need a way to coordinate",
    "start": "181680",
    "end": "187000"
  },
  {
    "text": "all of these different tasks to achieve your business process and manage all the interactions let me explain it with an",
    "start": "187000",
    "end": "194519"
  },
  {
    "text": "example invoice processing is a common use case for many business organization",
    "start": "194519",
    "end": "199760"
  },
  {
    "text": "if you are part of a supply chain company that might be the bread and butter of what you do invoices come in",
    "start": "199760",
    "end": "205640"
  },
  {
    "text": "variety of formats variety of types you know some are scanned some are electronic manual so in know when you",
    "start": "205640",
    "end": "213680"
  },
  {
    "text": "process these invoices you know you need to extract the data it contains informations about suppliers vendors",
    "start": "213680",
    "end": "220760"
  },
  {
    "text": "purchase orders even like thousands of purchase orders within a single invoice and you need to verify the sales order",
    "start": "220760",
    "end": "228680"
  },
  {
    "text": "quantity send it to payment and sometimes involve human in the loop if you know if a payment amount goes beyond",
    "start": "228680",
    "end": "235360"
  },
  {
    "text": "a certain amount which means you have got lots and lots of interactions within this invoice processing let's assume you",
    "start": "235360",
    "end": "242200"
  },
  {
    "text": "have got this invoice processing for like 500,000 invoices daily and there's",
    "start": "242200",
    "end": "248519"
  },
  {
    "text": "there's going to be some fluctuations in the you know data based on seasonality of the trend so as any application",
    "start": "248519",
    "end": "256120"
  },
  {
    "text": "developer do what I would do is like I might look into processing it using a for Loop and I know that it's not going",
    "start": "256120",
    "end": "262680"
  },
  {
    "text": "to work for half a million records and so I do need follow loes but I do have",
    "start": "262680",
    "end": "267880"
  },
  {
    "text": "to process them in parallel you know so I I would go with like multi-threading",
    "start": "267880",
    "end": "273479"
  },
  {
    "text": "so I would run multiple threads in parallel so I can process records in",
    "start": "273479",
    "end": "279160"
  },
  {
    "text": "parallel but then when I deploy it I will vertically scale that machine add more horsepower add more CPU add more",
    "start": "279160",
    "end": "286639"
  },
  {
    "text": "memory thinking that I can increase the thread count that will in turn improve the performance sometimes I will also",
    "start": "286639",
    "end": "294039"
  },
  {
    "text": "look into rep platforming going to a more performing or up-to-date Hardware",
    "start": "294039",
    "end": "299600"
  },
  {
    "text": "now what happens is I will soon realize the performance is not going to improve",
    "start": "299600",
    "end": "305080"
  },
  {
    "text": "think about when we add more CPU right thread count is actually relational to",
    "start": "305080",
    "end": "310360"
  },
  {
    "text": "the um CPU which means you know I think adding more CPU will increase the thread count which in turn increase the",
    "start": "310360",
    "end": "316840"
  },
  {
    "text": "performance but at some point performance graph is going to be very very flat so for half a million records",
    "start": "316840",
    "end": "323280"
  },
  {
    "text": "I might even look at like days to achieve it but as as an application developer now I'm instead of focusing on",
    "start": "323280",
    "end": "330400"
  },
  {
    "text": "business logic I am right I am looking into right sizing threads right sizing",
    "start": "330400",
    "end": "335720"
  },
  {
    "text": "servers now what happens is I end up might I might end up over provisioning",
    "start": "335720",
    "end": "341440"
  },
  {
    "text": "or underprovision this overs so there is a better approach and in fact the right",
    "start": "341440",
    "end": "348240"
  },
  {
    "text": "approach to do this you know large scale data processing which is distributed",
    "start": "348240",
    "end": "353280"
  },
  {
    "text": "computing the underlying business logic that you're writing is not going to change you're going to write the same",
    "start": "353280",
    "end": "359199"
  },
  {
    "text": "business bus logic instead of running in multiple threads you're going to run it in multiple processes and these",
    "start": "359199",
    "end": "365600"
  },
  {
    "text": "processes are going to run in a completely different distinct compute nodes and you will have some something",
    "start": "365600",
    "end": "372319"
  },
  {
    "text": "like a coordinator component to divide up this large data set and distribute it to these multiple machines and get the",
    "start": "372319",
    "end": "379840"
  },
  {
    "text": "work done and Co and do all those interactions like client Communications Etc so the overarching goal is actually",
    "start": "379840",
    "end": "387319"
  },
  {
    "text": "break down this large data set which requires significantly larger me you",
    "start": "387319",
    "end": "392880"
  },
  {
    "text": "know CPU and memory are sometimes infeasible to be done in a one single B",
    "start": "392880",
    "end": "398120"
  },
  {
    "text": "instance to a smaller manageable data sets that can be allocated to multiple",
    "start": "398120",
    "end": "404759"
  },
  {
    "text": "compute nodes Those computer notes that we see in green um in the",
    "start": "404759",
    "end": "411240"
  },
  {
    "text": "diagram now this technique this technique provides multiple benefits one of them is of",
    "start": "411440",
    "end": "418960"
  },
  {
    "text": "course faster time to Market you able to process like 500 million record 500,000",
    "start": "418960",
    "end": "425919"
  },
  {
    "text": "records within maybe um hours instead of waiting for days to do it and it is also",
    "start": "425919",
    "end": "432879"
  },
  {
    "text": "scalable if there is a sales event and you got like 2 million records today to",
    "start": "432879",
    "end": "439039"
  },
  {
    "text": "process you really don't have to rearchitecturing",
    "start": "439039",
    "end": "443039"
  },
  {
    "text": "processing everything in one single big machine we are Distributing the data set across multiple compute nodes so we have",
    "start": "449360",
    "end": "457479"
  },
  {
    "text": "partial failures we're not having complete failure and the coordinator component can be designed to handle",
    "start": "457479",
    "end": "464759"
  },
  {
    "text": "these partial failures and last but not the least the solution is not is also",
    "start": "464759",
    "end": "470759"
  },
  {
    "text": "cost effective because we are processing much faster and that is the main reason",
    "start": "470759",
    "end": "476560"
  },
  {
    "text": "it is it is um cost effective and we are also shutting down the compute nodes",
    "start": "476560",
    "end": "482520"
  },
  {
    "text": "when everything is done instead of maintaining one beefy instance so this is also cost",
    "start": "482520",
    "end": "489240"
  },
  {
    "text": "effective so though this one uh this technique is really",
    "start": "489240",
    "end": "495520"
  },
  {
    "text": "attractive it also introduces some challenges one of them is managing",
    "start": "495520",
    "end": "501080"
  },
  {
    "text": "concurrency now as an application developer you are responsible for",
    "start": "501080",
    "end": "506520"
  },
  {
    "text": "setting up provisioning and managing all of those clusters because these you know",
    "start": "506520",
    "end": "512599"
  },
  {
    "text": "U computer instances typically run in a sful environment now as an application",
    "start": "512599",
    "end": "518159"
  },
  {
    "text": "developer you might also have to learn a completely new technology like distributed um processing",
    "start": "518159",
    "end": "525040"
  },
  {
    "text": "Frameworks and that is a big learning curve and sometimes in some organizations there can be specialized",
    "start": "525040",
    "end": "532680"
  },
  {
    "text": "teams like infrastructure team networking team so you may have to go coordinate back and forth between",
    "start": "532680",
    "end": "539200"
  },
  {
    "text": "between the teams to achieve the the you know the processing applications um to",
    "start": "539200",
    "end": "545680"
  },
  {
    "text": "complete in in time so balancing or striking that balance between cost",
    "start": "545680",
    "end": "551040"
  },
  {
    "text": "security and speed is also challenging now how do",
    "start": "551040",
    "end": "557200"
  },
  {
    "text": "we have the faster development velocity and operational efficiency without going",
    "start": "557200",
    "end": "564560"
  },
  {
    "text": "through all of this uh sful responsive you know what we call it as like heavy",
    "start": "564560",
    "end": "570480"
  },
  {
    "text": "lifting right operational burden how do we do that I'm going to talk about how soes",
    "start": "570480",
    "end": "578640"
  },
  {
    "text": "can benefit especially application developers without going through all of",
    "start": "578640",
    "end": "584200"
  },
  {
    "text": "this operational burden we all know there is no service to manage with serverless seress also",
    "start": "584200",
    "end": "592120"
  },
  {
    "text": "integrate very well with rest of the AWS services and outside AWS Services easily",
    "start": "592120",
    "end": "598680"
  },
  {
    "text": "and ly and so that increases your development velocity next whether you are processing",
    "start": "598680",
    "end": "606480"
  },
  {
    "text": "100,000 records or 1 million records you really don't have to deal with you know",
    "start": "606480",
    "end": "612600"
  },
  {
    "text": "in increasing the server capacity or anything it naturally scales to the",
    "start": "612600",
    "end": "618240"
  },
  {
    "text": "demand and just shuts down when you're not using it so you handle that",
    "start": "618240",
    "end": "623519"
  },
  {
    "text": "variability with ease and you can also go to from I take",
    "start": "623519",
    "end": "628800"
  },
  {
    "text": "your idea to implementation within days sometimes within weeks and with pay as youo model so",
    "start": "628800",
    "end": "637120"
  },
  {
    "text": "you're also lowering the cost with serus the heart of serus is AWS Lambda a",
    "start": "637120",
    "end": "646079"
  },
  {
    "text": "in AWS Lambda you write your code in your favorite programming language and",
    "start": "646079",
    "end": "651959"
  },
  {
    "text": "you deploy it you really don't have to worry about soers and when you can run your your",
    "start": "651959",
    "end": "659240"
  },
  {
    "text": "Lambda function or the function that you write in your Lambda in response to changes in state or response to changes",
    "start": "659240",
    "end": "666200"
  },
  {
    "text": "in resource state for example you can upload a file to S3 I you can have",
    "start": "666200",
    "end": "671320"
  },
  {
    "text": "Lambda function trigger in response to that event you can have your Lambda function",
    "start": "671320",
    "end": "677600"
  },
  {
    "text": "run in response to an API that gets invoked from your user interface Lambda",
    "start": "677600",
    "end": "683320"
  },
  {
    "text": "function can call other AWS services and also services and API that you have in",
    "start": "683320",
    "end": "690720"
  },
  {
    "text": "onr for data processing workloads you require or you will do compute intensive",
    "start": "690720",
    "end": "698320"
  },
  {
    "text": "memory intensive work so Lambda functions support up to 10 gab of memory",
    "start": "698320",
    "end": "703560"
  },
  {
    "text": "and some data processing work also requir some local storage for example if",
    "start": "703560",
    "end": "709079"
  },
  {
    "text": "you are doing video processing you might store some data locally and if you are extracting data from a large invoice uh",
    "start": "709079",
    "end": "716519"
  },
  {
    "text": "file which is a PDF file you might need some local storage so Lambda function also offers 10 GB of local or temporary",
    "start": "716519",
    "end": "725320"
  },
  {
    "text": "storage as I said earlier you just write your code and deploy it what you need to",
    "start": "725320",
    "end": "730639"
  },
  {
    "text": "do is package it as a zip archive your code as well as your dependencies if you",
    "start": "730639",
    "end": "737560"
  },
  {
    "text": "have large libraries or you have some reusable code that you want to share with other Lambda functions you can",
    "start": "737560",
    "end": "744199"
  },
  {
    "text": "package them as layers in the there are um some public layers available and",
    "start": "744199",
    "end": "750399"
  },
  {
    "text": "talking about layers I realize there are lots of public layers available especially for data processing and if",
    "start": "750399",
    "end": "756360"
  },
  {
    "text": "you want to use um pandas you can use AWS SDK for pandas um if you're video",
    "start": "756360",
    "end": "762000"
  },
  {
    "text": "processing you can use ffmpeg um if you're using numpy you can use you can use sci-fi so these public",
    "start": "762000",
    "end": "768639"
  },
  {
    "text": "layers are already available so you don't really have to create your custom private layers and manage it yourself if",
    "start": "768639",
    "end": "776240"
  },
  {
    "text": "you're somebody who is from a container um background and you are familiar with",
    "start": "776240",
    "end": "782720"
  },
  {
    "text": "containers tooling you can also deploy Lambda function as a container image you write your Docker image and you package",
    "start": "782720",
    "end": "789800"
  },
  {
    "text": "them and deploy it in Lambda and you be able to run your code container packaging is also advantages because",
    "start": "789800",
    "end": "796600"
  },
  {
    "text": "data processing workloads sometimes require custom libraries that can go beyond the 250 megabytes of dotzip um",
    "start": "796600",
    "end": "804880"
  },
  {
    "text": "format they support up to 10 gigabyt of Packaging",
    "start": "804880",
    "end": "810759"
  },
  {
    "text": "now in our earlier diagram that we saw now I've replaced those green compute",
    "start": "813120",
    "end": "818680"
  },
  {
    "text": "nodes with Lambda function right I hope that makes sense now now let's move on",
    "start": "818680",
    "end": "824399"
  },
  {
    "text": "to that coordinator component so the invoice processing use",
    "start": "824399",
    "end": "830519"
  },
  {
    "text": "case that I talked about earlier if you remember there is uh lots of",
    "start": "830519",
    "end": "835959"
  },
  {
    "text": "inequations there is a process that you need to to do extract that data and",
    "start": "835959",
    "end": "841079"
  },
  {
    "text": "verify the quantities and also send for payment as any good developer do you",
    "start": "841079",
    "end": "847399"
  },
  {
    "text": "would write them as microservices and if you write them as microservices how would you manage that",
    "start": "847399",
    "end": "854040"
  },
  {
    "text": "interaction coordinate all those microservices to achieve your invoice",
    "start": "854040",
    "end": "860000"
  },
  {
    "text": "processing business use case or as a business process how do you visualize what's",
    "start": "860000",
    "end": "867199"
  },
  {
    "text": "going on how do you trouble isoot or inspect erors if there is something wrong with it and that's where I think",
    "start": "867199",
    "end": "874880"
  },
  {
    "text": "the step functions as a coordinator comes into play it is a low code servess",
    "start": "874880",
    "end": "880399"
  },
  {
    "text": "visual workflow servus as you can see in that um video you can just drag and drop",
    "start": "880399",
    "end": "887680"
  },
  {
    "text": "any AWS Services up to 10,000 plus AWS apis into that Designer studio and then",
    "start": "887680",
    "end": "894839"
  },
  {
    "text": "create your workflow it could be a Lambda function it can be an ECS step task it can be an EMR job or a glue job",
    "start": "894839",
    "end": "902240"
  },
  {
    "text": "you can just drag and drop them and create your workflows you can add payload you can configure retries you",
    "start": "902240",
    "end": "909360"
  },
  {
    "text": "can also handle errors through that um designer tool also you can create design",
    "start": "909360",
    "end": "916320"
  },
  {
    "text": "uh you can create decision trees you can run task in parallel you can iterate on",
    "start": "916320",
    "end": "921680"
  },
  {
    "text": "arrays ad them later we'll talk about like iterating arrays it's it's not just iterating arrays in a traditional sense",
    "start": "921680",
    "end": "928040"
  },
  {
    "text": "you iterate reason each iteration can run in parallel as well there are also other reasons to use",
    "start": "928040",
    "end": "936399"
  },
  {
    "text": "step functions someone somewhere said source code is a liability not an asset",
    "start": "936399",
    "end": "942560"
  },
  {
    "text": "maintaining and managing source code is a lot of work it's time consuming you need an ongoing",
    "start": "942560",
    "end": "950360"
  },
  {
    "text": "effort what I mean by that is if you're you responsible for your source code and",
    "start": "950360",
    "end": "955800"
  },
  {
    "text": "you have your source code as you as well as your dependent encies so you need to manage your source code is secure not",
    "start": "955800",
    "end": "964240"
  },
  {
    "text": "vulnerable and so you do uh security scanning you need to make sure the",
    "start": "964240",
    "end": "969600"
  },
  {
    "text": "dependencies that you have are like right dependencies if you're upgrading it you also have to make sure the back",
    "start": "969600",
    "end": "976959"
  },
  {
    "text": "they are Backward Compatible so all of those you need to do in your Source score step functions is a low code",
    "start": "976959",
    "end": "984920"
  },
  {
    "text": "service so if you can reduce all those code that you need to write to fewer",
    "start": "984920",
    "end": "990560"
  },
  {
    "text": "lines and you can write it in Json or yamal like step functions definitions is",
    "start": "990560",
    "end": "996160"
  },
  {
    "text": "expressed in ASO Amazon States language step function also offers",
    "start": "996160",
    "end": "1003319"
  },
  {
    "text": "additional visual capabilities to observe everything going on and so that",
    "start": "1003319",
    "end": "1008480"
  },
  {
    "text": "is another reason for application developers to use step functions now let",
    "start": "1008480",
    "end": "1013720"
  },
  {
    "text": "me show you with an example I've taken here a a very classic",
    "start": "1013720",
    "end": "1019519"
  },
  {
    "text": "example of how uh retrieving some data from a",
    "start": "1019519",
    "end": "1024720"
  },
  {
    "text": "database our data is stored in Amazon Dynamo DB and so in order to connect to the",
    "start": "1024720",
    "end": "1030839"
  },
  {
    "text": "Dynamo DB I need to use an API it's you know really integrates very well with",
    "start": "1030839",
    "end": "1035918"
  },
  {
    "text": "the Lambda function you just have to call an API so I use the Dynamo DB API",
    "start": "1035919",
    "end": "1044280"
  },
  {
    "text": "client and then I need to configure some table information where my data is and",
    "start": "1044280",
    "end": "1049799"
  },
  {
    "text": "also some keys like by by which I'm querying the data and then actually I'm",
    "start": "1049799",
    "end": "1055480"
  },
  {
    "text": "calling Dynamo DB and I'm wrapping up with some retries in y handling in fact",
    "start": "1055480",
    "end": "1061600"
  },
  {
    "text": "like my retries is not a graceful retries either in fact like just actually catching the",
    "start": "1061600",
    "end": "1068919"
  },
  {
    "text": "others um in your real life code you may have graceful retries in your real life code you may",
    "start": "1068919",
    "end": "1074880"
  },
  {
    "text": "also have logging some kind of structured logging in incl logging framework so there's 20 lines of code",
    "start": "1074880",
    "end": "1081960"
  },
  {
    "text": "and Bug can occur in any of these 20 lines of code if I want to convert this",
    "start": "1081960",
    "end": "1087799"
  },
  {
    "text": "to an workflow I'll just add one step to it Dynamo DB get item I don't have to",
    "start": "1087799",
    "end": "1095000"
  },
  {
    "text": "worry about library that I need to use I don't have to worry about version upgrades I just add Dynamo DB get item",
    "start": "1095000",
    "end": "1102679"
  },
  {
    "text": "and configure the table name and the keys and then I can configure",
    "start": "1102679",
    "end": "1109000"
  },
  {
    "text": "R and if things fail I can send it to a dlq a dead letter Q which is you know in",
    "start": "1109000",
    "end": "1116000"
  },
  {
    "text": "here I use Amazon sqs visually you know I can see",
    "start": "1116000",
    "end": "1121480"
  },
  {
    "text": "everything in the in the console itself now anybody can look at this and see no",
    "start": "1121480",
    "end": "1127520"
  },
  {
    "text": "what's going on you know whereas on the other side only nodejs developer would be able to understand what is going",
    "start": "1127520",
    "end": "1134080"
  },
  {
    "text": "on during development we all going to have like so many you know back and",
    "start": "1134080",
    "end": "1139840"
  },
  {
    "text": "forth with writing code and step functions offers you a complete visibility into what is happening you",
    "start": "1139840",
    "end": "1147120"
  },
  {
    "text": "can look into errors you can look into what is the input that went to the state what is the output what error you got",
    "start": "1147120",
    "end": "1153960"
  },
  {
    "text": "without writing single line of logging code so now our Yer diagram I've",
    "start": "1153960",
    "end": "1161200"
  },
  {
    "text": "replaced it with awep functions as a coordinator and Lambda as a",
    "start": "1161200",
    "end": "1167240"
  },
  {
    "text": "compute let's look at how you can schedule this workflow you can schedule it and you can also run it event driven",
    "start": "1167240",
    "end": "1176120"
  },
  {
    "text": "and know running it event like I said it's easy um it is easy to get the",
    "start": "1176120",
    "end": "1181799"
  },
  {
    "text": "meaning out of the data immediately whereas a scheduled workflows um introduces some",
    "start": "1181799",
    "end": "1187799"
  },
  {
    "text": "delays step functions integrate really well with like 10,000 plus AWS apis and",
    "start": "1187799",
    "end": "1193919"
  },
  {
    "text": "we saw that earlier in that video step functions can also be triggered in multiple different ways one of the",
    "start": "1193919",
    "end": "1201120"
  },
  {
    "text": "common ways is using Amazon event Bridge event Bridge is a serverless event",
    "start": "1201120",
    "end": "1206440"
  },
  {
    "text": "router it it decouples a producer and consumer even brid has a component",
    "start": "1206440",
    "end": "1213120"
  },
  {
    "text": "called a schedular you can use that scheduler to schedule your",
    "start": "1213120",
    "end": "1219360"
  },
  {
    "text": "workflows you can also call step functions workflow with uh from Step",
    "start": "1219360",
    "end": "1224799"
  },
  {
    "text": "functions it's a kind of a nice way to write reusable work workflows you can",
    "start": "1224799",
    "end": "1230080"
  },
  {
    "text": "mix and match uh different flavors of workflows Adam will talk about it later",
    "start": "1230080",
    "end": "1235520"
  },
  {
    "text": "you can also have the workflow run in response to apis from your user interface and there are many other ways",
    "start": "1235520",
    "end": "1242039"
  },
  {
    "text": "to invoke workflows so if you're doing a batch data processing you would be writing your schedule in your Amazon",
    "start": "1242039",
    "end": "1248679"
  },
  {
    "text": "eventbridge schuer and run your step functions then step functions in our case where we had the invoice processing",
    "start": "1248679",
    "end": "1255840"
  },
  {
    "text": "use case our invoices will exist in Amazon S3 which is a cloud storage where",
    "start": "1255840",
    "end": "1261440"
  },
  {
    "text": "you can store and retrieve any amount of data from anywhere so our invoices on an Amazon S3 step functions list all these",
    "start": "1261440",
    "end": "1269000"
  },
  {
    "text": "objects and then orchestrate those multiple data sets we have with Lambda",
    "start": "1269000",
    "end": "1274799"
  },
  {
    "text": "functions this can be Lambda function this can be ECS task or this can be any",
    "start": "1274799",
    "end": "1281240"
  },
  {
    "text": "of the 10,000 plus AWS apis you can also trigger the workflows",
    "start": "1281240",
    "end": "1289360"
  },
  {
    "text": "near real time no real time for example if you want to kick",
    "start": "1289360",
    "end": "1295120"
  },
  {
    "text": "your workflow when a file lands an S3 um you can set up an S3 even notification",
    "start": "1295120",
    "end": "1302799"
  },
  {
    "text": "and that can Target Amazon even Bridge S3 even notification has many targets one of them is Amazon even Bridge an",
    "start": "1302799",
    "end": "1310240"
  },
  {
    "text": "even Bridge can Target a functions workflow directly so now your workflow can be kicked off immediately when a",
    "start": "1310240",
    "end": "1317159"
  },
  {
    "text": "file is uploaded you can also kick off your workflow in response to events in your unpromised",
    "start": "1317159",
    "end": "1323600"
  },
  {
    "text": "systems for example if you have Kafka and you have events coming in from Kafka",
    "start": "1323600",
    "end": "1328640"
  },
  {
    "text": "or you have um Amazon mq or sqs you want to trigger your workflow in response to",
    "start": "1328640",
    "end": "1334880"
  },
  {
    "text": "events coming from there you can connect Amazon even Bridge pipes with them so",
    "start": "1334880",
    "end": "1340480"
  },
  {
    "text": "even Bridge pipe is a peer-to-peer inaguration service that connects the uh",
    "start": "1340480",
    "end": "1346000"
  },
  {
    "text": "Source event sources to event Target in our case even Target is a workflow all",
    "start": "1346000",
    "end": "1351240"
  },
  {
    "text": "right so far we talked about how do data processing at Large",
    "start": "1351240",
    "end": "1356720"
  },
  {
    "text": "Scale is challenging and how sis can help um Adam is going to talk about how",
    "start": "1356720",
    "end": "1363760"
  },
  {
    "text": "you can actually do the data processing I'm going to step aside thank you all right cool so uh if you know we",
    "start": "1363760",
    "end": "1373679"
  },
  {
    "text": "take a look at that diagram again and we see we now have the data being processed by Lambda the coordination Happening by",
    "start": "1373679",
    "end": "1381039"
  },
  {
    "text": "step functions and then we're going to store the results out in S3 so that they're they're durably stored so let's",
    "start": "1381039",
    "end": "1387679"
  },
  {
    "text": "get into the details of how we do this with step functions so one of the many task states",
    "start": "1387679",
    "end": "1395960"
  },
  {
    "text": "that you have in uh step functions is a a functionality called map and the map",
    "start": "1395960",
    "end": "1402120"
  },
  {
    "text": "functionality had been around for a little while it allowed you to do kind of arbitrary parallelism right so send",
    "start": "1402120",
    "end": "1408880"
  },
  {
    "text": "in a list of objects that you want to operate over and that could be 100 items",
    "start": "1408880",
    "end": "1415559"
  },
  {
    "text": "it could be 10 items it could be variable and this was loved by customers",
    "start": "1415559",
    "end": "1420679"
  },
  {
    "text": "used in a lot of cool ways but it had some limitations It could only scale out to process 40 things in parallel so I",
    "start": "1420679",
    "end": "1427360"
  },
  {
    "text": "could send in that list of 100 but there would only be 40 of them operating at the same",
    "start": "1427360",
    "end": "1433799"
  },
  {
    "text": "time and so last year we came out with a version of that map state that we called",
    "start": "1433799",
    "end": "1439279"
  },
  {
    "text": "distributed map and with distributed map we scale way out we can scan out scale",
    "start": "1439279",
    "end": "1445640"
  },
  {
    "text": "out to process 10,000 Things in parallel",
    "start": "1445640",
    "end": "1451080"
  },
  {
    "text": "and it allows you to process lots of data it also integrates with S3 so if",
    "start": "1451080",
    "end": "1457360"
  },
  {
    "text": "you have hundreds of thousands of objects in S3 we can iterate over those",
    "start": "1457360",
    "end": "1463880"
  },
  {
    "text": "objects you might also have one really large object in S3 maybe you have a",
    "start": "1463880",
    "end": "1469480"
  },
  {
    "text": "monster CSV file with a million rows in it we can point at that file and iterate",
    "start": "1469480",
    "end": "1476799"
  },
  {
    "text": "on those individual rows of that CSV file so really really powerful way to do",
    "start": "1476799",
    "end": "1485039"
  },
  {
    "text": "distributed data processing without having to manage servers uh learn new",
    "start": "1485039",
    "end": "1491279"
  },
  {
    "text": "Frameworks things like that and so if we go back to that invoice processing use",
    "start": "1491279",
    "end": "1497399"
  },
  {
    "text": "case that that Uma started with early on if you think about the logic that you have to write you can now just think",
    "start": "1497399",
    "end": "1504279"
  },
  {
    "text": "about a single invoice what do I need to do with a single invoice well it might come in as a PDF I'm going to convert",
    "start": "1504279",
    "end": "1510480"
  },
  {
    "text": "that PDF to text once I have that text I'm going to do that actual processing",
    "start": "1510480",
    "end": "1515720"
  },
  {
    "text": "and you don't have to think about the scalability of this because step functions and distributed map is going",
    "start": "1515720",
    "end": "1521000"
  },
  {
    "text": "to take care of scaling that out you just focus on your business logic keep it simple then at the end when we're",
    "start": "1521000",
    "end": "1528200"
  },
  {
    "text": "done processing all of them we go off and we we trigger some",
    "start": "1528200",
    "end": "1533840"
  },
  {
    "text": "reporting so just another view of this another look at what distributed map",
    "start": "1534120",
    "end": "1540480"
  },
  {
    "text": "looks like and and how it works on the left hand side here we have S3 as our",
    "start": "1540480",
    "end": "1545760"
  },
  {
    "text": "input source and so we're going to point at S3 and let's say we have the 500,000",
    "start": "1545760",
    "end": "1551960"
  },
  {
    "text": "invoices we're going to say hey step functions distribute a map look here in S3 set functions distributed map is",
    "start": "1551960",
    "end": "1559240"
  },
  {
    "text": "going to look at all that make a big list of all of those objects in S3 all",
    "start": "1559240",
    "end": "1564440"
  },
  {
    "text": "of those files that we need to process then it's going to execute a child",
    "start": "1564440",
    "end": "1570039"
  },
  {
    "text": "workflow so distributed map actually has this child workflow concept where that",
    "start": "1570039",
    "end": "1576399"
  },
  {
    "text": "data processing whatever steps you want to do are within this child workflow and there's some advantages to that that",
    "start": "1576399",
    "end": "1582720"
  },
  {
    "text": "I'll I'll talk about in a moment and we've talked about that data processing as being being done by Lambda but you",
    "start": "1582720",
    "end": "1589520"
  },
  {
    "text": "can do anything you can do within a step functions within that child workflow within distributed map so you could be",
    "start": "1589520",
    "end": "1595679"
  },
  {
    "text": "calling AWS sdks be calling uh ECS uh AWS batch anything you want within there",
    "start": "1595679",
    "end": "1604679"
  },
  {
    "text": "and then optionally we can write out the summarized results out to S3 because if",
    "start": "1604679",
    "end": "1609880"
  },
  {
    "text": "we're processing 500,000 objects like it's we got to put all of that resulting",
    "start": "1609880",
    "end": "1615399"
  },
  {
    "text": "data somewhere allows you to easily write that out to S3 and so I'll now transition away from",
    "start": "1615399",
    "end": "1623919"
  },
  {
    "text": "the slides and let's just go over to the step functions console and I'll show you",
    "start": "1623919",
    "end": "1629720"
  },
  {
    "text": "what this looks like in another example so here we are in the step functions",
    "start": "1629720",
    "end": "1634799"
  },
  {
    "text": "console but before I get into the details of this step function I want to",
    "start": "1634799",
    "end": "1640000"
  },
  {
    "text": "talk about the the use case that we're going to use so we're going to move a little ways away from invoice processing",
    "start": "1640000",
    "end": "1646640"
  },
  {
    "text": "we're actually Gra grabbed some data from the national oceanographic and Atmospheric Administration Noah uh which",
    "start": "1646640",
    "end": "1653720"
  },
  {
    "text": "is a a US organization that gathers all sorts of climate and weather data they",
    "start": "1653720",
    "end": "1660320"
  },
  {
    "text": "have this really interesting um data set that is weather",
    "start": "1660320",
    "end": "1665360"
  },
  {
    "text": "data that goes all the way back to 1929 and it's from all over the world so",
    "start": "1665360",
    "end": "1671360"
  },
  {
    "text": "weather stations from all over the world report this data and they have this data",
    "start": "1671360",
    "end": "1677000"
  },
  {
    "text": "summed up in CSV files and if I look at one of these individual CSV files each",
    "start": "1677000",
    "end": "1684320"
  },
  {
    "text": "one is data from a single uh weather station so this one is from I'm going to",
    "start": "1684320",
    "end": "1691559"
  },
  {
    "text": "butcher the name I'm sure um hakal in Norway there's anyone from Norway you",
    "start": "1691559",
    "end": "1697039"
  },
  {
    "text": "can tell me after how that's actually pronounced um but so this is all this data from Norway uh and it's basically",
    "start": "1697039",
    "end": "1706080"
  },
  {
    "text": "uh you know one piece of data per day for the year of 1960 and so there's a",
    "start": "1706080",
    "end": "1714000"
  },
  {
    "text": "lot of these files there's 500,000 little more of these files and in total",
    "start": "1714000",
    "end": "1720519"
  },
  {
    "text": "it's over 40 gigabytes of data so it's a lot of data but it's not huge huge huge",
    "start": "1720519",
    "end": "1725679"
  },
  {
    "text": "amounts of data but it's a lot of small files and if you look at a lot of data processing ways to process data like",
    "start": "1725679",
    "end": "1733120"
  },
  {
    "text": "this a lot of them struggle with this small file use case all right so let's go and take a look at",
    "start": "1733120",
    "end": "1741039"
  },
  {
    "text": "the step function that we're going to use to to process this data and I I",
    "start": "1741039",
    "end": "1746080"
  },
  {
    "text": "didn't mention yet what we're going to do right how we're going to process this data so the idea is let's look through",
    "start": "1746080",
    "end": "1752880"
  },
  {
    "text": "all this data worldwide weather data going back to 1929 and for every month",
    "start": "1752880",
    "end": "1759399"
  },
  {
    "text": "from 1929 until now let's find the place on the planet with the highest temperature and we'll record what that",
    "start": "1759399",
    "end": "1765799"
  },
  {
    "text": "temperature is and and where it was recorded and we'll write that out into a",
    "start": "1765799",
    "end": "1771200"
  },
  {
    "text": "Dynamo DB table so let's go take a look at the the",
    "start": "1771200",
    "end": "1776600"
  },
  {
    "text": "state machine itself so this is that visual workflow Builder that you saw earlier so you can drag and drop you",
    "start": "1776600",
    "end": "1784200"
  },
  {
    "text": "know different states in here to uh you know create your state machines so in",
    "start": "1784200",
    "end": "1791000"
  },
  {
    "text": "this case it's a fairly straightforward State machine we have our distributed map here where we're going to going to",
    "start": "1791000",
    "end": "1797840"
  },
  {
    "text": "process through all those 500,000 files and then we have this Lambda function at",
    "start": "1797840",
    "end": "1803039"
  },
  {
    "text": "the end that we call a reducer so if you think about each individual Lambda",
    "start": "1803039",
    "end": "1808080"
  },
  {
    "text": "function that's going to process a subset of those 500,000 files it's going to find lots of local maximums right so",
    "start": "1808080",
    "end": "1816360"
  },
  {
    "text": "it's looking at you know 50 weather stations and saying oh out of these",
    "start": "1816360",
    "end": "1821679"
  },
  {
    "text": "weather stations for each month this was the high temperature but we're going to get lots of those and we need to",
    "start": "1821679",
    "end": "1827679"
  },
  {
    "text": "correlate them at the end and say okay this was actually the highest temperature of the the whole um the",
    "start": "1827679",
    "end": "1834919"
  },
  {
    "text": "whole world and then write them to Dynamo DB and so that's what that reducer function is going to do so let's",
    "start": "1834919",
    "end": "1843559"
  },
  {
    "text": "take a look at the distributed map configuration and what's in there make",
    "start": "1843559",
    "end": "1849399"
  },
  {
    "text": "this a little bigger all right so over here in the distributed map uh the first",
    "start": "1849399",
    "end": "1855120"
  },
  {
    "text": "thing you'll notice is that we're using the distributed version of map so that original map that I talked about has",
    "start": "1855120",
    "end": "1860960"
  },
  {
    "text": "that limitation of of uh 40 it's still there uh but we're using distributed map",
    "start": "1860960",
    "end": "1866440"
  },
  {
    "text": "in this case I choose the input source so again we're going to use S3 as our",
    "start": "1866440",
    "end": "1873519"
  },
  {
    "text": "input source this is really great because you don't have to think about kind of loading the data in the data is",
    "start": "1873519",
    "end": "1879720"
  },
  {
    "text": "in S3 and we're just going to point step functions distributed map at that uh",
    "start": "1879720",
    "end": "1885039"
  },
  {
    "text": "bucket so I'm pointing it at the bucket in this case I'm not even pointing it at a specific you know subfolder within the",
    "start": "1885039",
    "end": "1891840"
  },
  {
    "text": "bucket I'm just pointing it at the whole bucket and then a very important feature",
    "start": "1891840",
    "end": "1897880"
  },
  {
    "text": "is the ability to batch so I could send one of these CSV v files to that Lambda",
    "start": "1897880",
    "end": "1904880"
  },
  {
    "text": "function and just run that Lambda function 500,000 times but I showed you those files right each file is pretty",
    "start": "1904880",
    "end": "1911960"
  },
  {
    "text": "small and so I can actually get some efficiency by sending a batch of messages",
    "start": "1911960",
    "end": "1917760"
  },
  {
    "text": "to that Lambda function this is a great way to tune performance and to tune cost",
    "start": "1917760",
    "end": "1924399"
  },
  {
    "text": "of your uh step function that you're using for data processing so definitely a good uh a good value to play around",
    "start": "1924399",
    "end": "1932320"
  },
  {
    "text": "with and you know figure out where's that sweet spot from a performance and a cost",
    "start": "1932320",
    "end": "1939518"
  },
  {
    "text": "perspective you can also limit it by the kind of size of the overall batch versus",
    "start": "1939760",
    "end": "1945279"
  },
  {
    "text": "the number of items as well another Knob that I have is the",
    "start": "1945279",
    "end": "1951960"
  },
  {
    "text": "concurrency that that distributed map is going to use and so in this case I have it set to a thousand 10,000 concurrency",
    "start": "1951960",
    "end": "1960679"
  },
  {
    "text": "is really big and not all AWS Services can handle scaling from zero to 10,000",
    "start": "1960679",
    "end": "1969799"
  },
  {
    "text": "really quickly and so you need to think about the services that you're going to call within that distributed map and",
    "start": "1969799",
    "end": "1976159"
  },
  {
    "text": "whether they can you know uh like meet that that scale the other thing that I",
    "start": "1976159",
    "end": "1981880"
  },
  {
    "text": "chose is the child execution type so remember I said the iterations of this",
    "start": "1981880",
    "end": "1988639"
  },
  {
    "text": "distributed map are actually step functions workflows themselves and I can",
    "start": "1988639",
    "end": "1993960"
  },
  {
    "text": "choose to use either a standard workflow which is what you use for most step",
    "start": "1993960",
    "end": "1999039"
  },
  {
    "text": "functions workflows long running workflows uh or I can use what's called an Express workflow Express workflows",
    "start": "1999039",
    "end": "2006279"
  },
  {
    "text": "are really good for shortlived workflows that are going to be high volume and so",
    "start": "2006279",
    "end": "2012760"
  },
  {
    "text": "in this case it fits perfectly for within that distributed map because each",
    "start": "2012760",
    "end": "2018000"
  },
  {
    "text": "one of those Lambda functions it's not going to run for very long it runs pretty",
    "start": "2018000",
    "end": "2023159"
  },
  {
    "text": "quickly and then lastly I'm going to choose an export location so I'm going to say hey at the end of my distributed",
    "start": "2023159",
    "end": "2030039"
  },
  {
    "text": "map write out the results of that distributed map to this location in S3",
    "start": "2030039",
    "end": "2037240"
  },
  {
    "text": "whole bunch of of things about that that I'll I'll talk about uh in a moment one",
    "start": "2037240",
    "end": "2042919"
  },
  {
    "text": "other thing I wanted to to touch on before we run this and and show how it works you know the Uma earlier talked",
    "start": "2042919",
    "end": "2050480"
  },
  {
    "text": "about kind of uh you know moving away from code right and the the low code",
    "start": "2050480",
    "end": "2056040"
  },
  {
    "text": "nature one of the great things here is the error handling so if I look at the details of this Lambda function I have",
    "start": "2056040",
    "end": "2064560"
  },
  {
    "text": "very uh easy to configure error handling on all these different error exceptions",
    "start": "2064560",
    "end": "2071520"
  },
  {
    "text": "I can decide how many times do I want to retry if I run into an error do I want to retry once do I want to retry twice",
    "start": "2071520",
    "end": "2079079"
  },
  {
    "text": "in this case I'm actually retrying eight times I can choose my back off rate I",
    "start": "2079079",
    "end": "2084200"
  },
  {
    "text": "can add Jitter I can choose like a max amount that I want to back off and retry",
    "start": "2084200",
    "end": "2089638"
  },
  {
    "text": "for and so this is great this is code you don't have to write it's code that doesn't differentiate you right I don't",
    "start": "2089639",
    "end": "2096358"
  },
  {
    "text": "think anyone one in this room if we did a survey my guess is no one would say oh the the thing that is key to my business",
    "start": "2096359",
    "end": "2102839"
  },
  {
    "text": "is our retry logic right probably not that's not the key thing that you need to be thinking about so if it's not the",
    "start": "2102839",
    "end": "2109480"
  },
  {
    "text": "key thing you need to be thinking about offload it to step functions and let it do it for you so enough talking let's",
    "start": "2109480",
    "end": "2116320"
  },
  {
    "text": "run the actual uh distributed map so I'm going to execute this this is the input",
    "start": "2116320",
    "end": "2122760"
  },
  {
    "text": "to the step function in this case I don't need to give it any specific inputs so I'm just going to leave the",
    "start": "2122760",
    "end": "2127880"
  },
  {
    "text": "default uh input there so when you run a step function you get this great",
    "start": "2127880",
    "end": "2134160"
  },
  {
    "text": "operator experience you get a visual view of what's happening in your step",
    "start": "2134160",
    "end": "2139760"
  },
  {
    "text": "function so the blue here indicates that this is what's in progress currently",
    "start": "2139760",
    "end": "2145720"
  },
  {
    "text": "this is the step that's running in progress and because that step that's running is a distributed map I have this",
    "start": "2145720",
    "end": "2153440"
  },
  {
    "text": "special map run console which we'll go into and in the map run console I have a",
    "start": "2153440",
    "end": "2159720"
  },
  {
    "text": "bunch of the um configurations that we looked at earlier things like what's the",
    "start": "2159720",
    "end": "2165760"
  },
  {
    "text": "batch size what's the concurrency when did it start running and then I have the item",
    "start": "2165760",
    "end": "2172319"
  },
  {
    "text": "processing stats and so the first thing that it's going to do is it's listing out all those objects in S3 and getting",
    "start": "2172319",
    "end": "2179119"
  },
  {
    "text": "all the things that it's going to iterate over and so it's doing that right now pulling in those 500,000 plus",
    "start": "2179119",
    "end": "2185800"
  },
  {
    "text": "objects and then it's going to start executing them it just started executing",
    "start": "2185800",
    "end": "2191079"
  },
  {
    "text": "them and one of the things I want to point out here is that some of them failed trying to make this a real kind",
    "start": "2191079",
    "end": "2197000"
  },
  {
    "text": "of real world uh example I wanted some of them to fail very often if you have these large",
    "start": "2197000",
    "end": "2204400"
  },
  {
    "text": "data sets not every piece of data is going to process perfectly and so a great feature that we have here is this",
    "start": "2204400",
    "end": "2211319"
  },
  {
    "text": "tolerated failure threshold and that tolerated failure threshold allows me to say hey I want x% of failures to be okay",
    "start": "2211319",
    "end": "2220200"
  },
  {
    "text": "without failing the whole workflow and the great thing is it's going to write out all those objects that did fail it's",
    "start": "2220200",
    "end": "2227119"
  },
  {
    "text": "going to put them in a separate failed results file for me in the end so it's really easy for me to rerun them or",
    "start": "2227119",
    "end": "2234680"
  },
  {
    "text": "report out on what items failed what items need to",
    "start": "2234680",
    "end": "2239760"
  },
  {
    "text": "do if I look here I have all the individual child executions of uh the workflow that are",
    "start": "2239760",
    "end": "2247960"
  },
  {
    "text": "running so a whole bunch of these are running right now I refresh it again I should get some that I have",
    "start": "2247960",
    "end": "2254319"
  },
  {
    "text": "succeeded I can click into those I can see the input that went in I can see the",
    "start": "2254319",
    "end": "2260400"
  },
  {
    "text": "output that came out in terms of the stations the weather stations it found",
    "start": "2260400",
    "end": "2265480"
  },
  {
    "text": "that had the highest temperature values for a given month and",
    "start": "2265480",
    "end": "2270560"
  },
  {
    "text": "year so if I go back over here to the overall workflow oops",
    "start": "2270560",
    "end": "2277119"
  },
  {
    "text": "go here the distributed map finished and now the reducer finished as well and so",
    "start": "2277119",
    "end": "2284000"
  },
  {
    "text": "in less than two and a half minutes we processed 500,000 plus files and 40 gig",
    "start": "2284000",
    "end": "2290319"
  },
  {
    "text": "of data if you think about traditional data processing if you were going to spin up a cluster to do this you would",
    "start": "2290319",
    "end": "2297960"
  },
  {
    "text": "wouldn't even be done spinning up the cluster and we'd already be finished processing that data so this really",
    "start": "2297960",
    "end": "2303760"
  },
  {
    "text": "works great as a way to quickly process process data and now I'll go over to our",
    "start": "2303760",
    "end": "2309839"
  },
  {
    "text": "results table here this is the Dynamo DB table that has the results data in it",
    "start": "2309839",
    "end": "2317359"
  },
  {
    "text": "and so we can click into uh month in 19 uh so may in",
    "start": "2317359",
    "end": "2323040"
  },
  {
    "text": "1945 and we can see that the max temperature was 112.",
    "start": "2323040",
    "end": "2328640"
  },
  {
    "text": "three in def I don't know what that is in in some place that uh I'm not sure what",
    "start": "2328640",
    "end": "2335960"
  },
  {
    "text": "that town is and so uh I hope that gives you a good idea of Step functions and specifically",
    "start": "2335960",
    "end": "2344800"
  },
  {
    "text": "distributed map and what it's like to process data with distributed map uh lot",
    "start": "2344800",
    "end": "2350880"
  },
  {
    "text": "of real power here to be able to build these workflows and process large",
    "start": "2350880",
    "end": "2357319"
  },
  {
    "text": "amounts of data we see use cases for distributed map and processing data in",
    "start": "2357319",
    "end": "2363880"
  },
  {
    "text": "these ways across a a wide variet iety of uh different Industries and use cases",
    "start": "2363880",
    "end": "2370440"
  },
  {
    "text": "uh large scale unstructured file processing uh data modeling for like",
    "start": "2370440",
    "end": "2375599"
  },
  {
    "text": "financial institutions we have a great case study uh up on um our website about",
    "start": "2375599",
    "end": "2381599"
  },
  {
    "text": "that uh I had a great customer that did really cool data migration using",
    "start": "2381599",
    "end": "2387280"
  },
  {
    "text": "distributed map where they were moving all the data related to some users that",
    "start": "2387280",
    "end": "2392400"
  },
  {
    "text": "were based in Europe from an American system to a new Europe European system",
    "start": "2392400",
    "end": "2397680"
  },
  {
    "text": "all they had to do was just code how to move one user and then they just fed it giant lists of users quickly move them",
    "start": "2397680",
    "end": "2404640"
  },
  {
    "text": "over uh really really cool use case we have a bunch of resources this",
    "start": "2404640",
    "end": "2412119"
  },
  {
    "text": "is actually a resource page for a talk that Uma and I are going to do at reinvent but there's a bunch of great",
    "start": "2412119",
    "end": "2419160"
  },
  {
    "text": "resources Learning Materials uh links to serverless land.com and a pattern",
    "start": "2419160",
    "end": "2426000"
  },
  {
    "text": "reposit atory that has that example that I showed along with many other step",
    "start": "2426000",
    "end": "2431040"
  },
  {
    "text": "function examples so a great place to go and get uh you know resources to start",
    "start": "2431040",
    "end": "2437000"
  },
  {
    "text": "learning more about this try things out play with it uh all that sort of stuff one of those main places that it points",
    "start": "2437000",
    "end": "2443760"
  },
  {
    "text": "you is serverless land.com which has a a bunch of great uh resources on",
    "start": "2443760",
    "end": "2449680"
  },
  {
    "text": "that uh but with that I'll just say thank you for taking the time um and I really really appreciate it uh we have",
    "start": "2449680",
    "end": "2456119"
  },
  {
    "text": "our our details up there if you want to reach out to us ask questions uh always happy to to answer questions and please",
    "start": "2456119",
    "end": "2464480"
  },
  {
    "text": "don't forget to uh go and vote for this session in your go-to",
    "start": "2464480",
    "end": "2469670"
  },
  {
    "text": "[Applause]",
    "start": "2469670",
    "end": "2475749"
  },
  {
    "text": "guide",
    "start": "2483560",
    "end": "2486560"
  }
]
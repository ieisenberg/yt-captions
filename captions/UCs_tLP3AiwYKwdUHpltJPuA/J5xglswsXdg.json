[
  {
    "start": "0",
    "end": "60000"
  },
  {
    "text": "so um what I'm aiming to convey",
    "start": "4640",
    "end": "11920"
  },
  {
    "text": "today is that as Enterprise developers and given that most of you have used",
    "start": "11920",
    "end": "18400"
  },
  {
    "text": "spring I'm assuming you are mostly Enterprise developers Enterprise developers have a really important role",
    "start": "18400",
    "end": "25320"
  },
  {
    "text": "in making geni usable gen is a very real",
    "start": "25320",
    "end": "30480"
  },
  {
    "text": "thing it's not going to go away but it is something that is extremely difficult",
    "start": "30480",
    "end": "36320"
  },
  {
    "text": "to use in business applications so you know the importance",
    "start": "36320",
    "end": "41680"
  },
  {
    "text": "is uncontestable but you read a vast number of blog",
    "start": "41680",
    "end": "46800"
  },
  {
    "text": "posts that are very very far removed from reality so what I want to talk",
    "start": "46800",
    "end": "53199"
  },
  {
    "text": "about is how hopefully all of us in this room can use the skills we have to get closer to reality so I want to show some",
    "start": "53199",
    "end": "62160"
  },
  {
    "start": "60000",
    "end": "88000"
  },
  {
    "text": "of the Core Concepts of building or gen applications or gen enabling existing",
    "start": "62160",
    "end": "69799"
  },
  {
    "text": "applications I want to show that you can do this in the jvm and that the jvm is",
    "start": "69799",
    "end": "75960"
  },
  {
    "text": "competitive with python for building gen apps and also I want to show you both",
    "start": "75960",
    "end": "81920"
  },
  {
    "text": "some of what I consider to be best practices and also some of the",
    "start": "81920",
    "end": "87360"
  },
  {
    "text": "challenges but before we get there let's let's um think about spring spring has",
    "start": "87360",
    "end": "92960"
  },
  {
    "start": "88000",
    "end": "495000"
  },
  {
    "text": "been around for a very long time I have the beach ball of death this is not good",
    "start": "92960",
    "end": "99560"
  },
  {
    "text": "okay spring has been around for a very long time it in fact dates back to the",
    "start": "99560",
    "end": "105320"
  },
  {
    "text": "beginning of this Century um so yet it's still around and",
    "start": "105320",
    "end": "111759"
  },
  {
    "text": "it's still thriving let's think about why that is and I think there's really",
    "start": "111759",
    "end": "117000"
  },
  {
    "text": "three fundamental reasons one is that the spring team is awesome and",
    "start": "117000",
    "end": "125079"
  },
  {
    "text": "certainly you know one of the things that I'm most proud of in my career is that I assembled the Genesis of that",
    "start": "125079",
    "end": "131840"
  },
  {
    "text": "team which has continued to be involved in Spring and led spring for decades the",
    "start": "131840",
    "end": "137560"
  },
  {
    "text": "spring Community is awesome and that obviously you know overlaps with the spring team because the spring team is",
    "start": "137560",
    "end": "143720"
  },
  {
    "text": "part of the spring community and comes out of the spring Community but thirdly",
    "start": "143720",
    "end": "150360"
  },
  {
    "text": "spring is built on some very solid core Concepts and those Core Concepts have",
    "start": "150360",
    "end": "157319"
  },
  {
    "text": "stood up incredibly well over two decades so if any of you have been",
    "start": "157319",
    "end": "164080"
  },
  {
    "text": "involved in the spring Community since the beginning you'll probably remember something that we used to talk about",
    "start": "164080",
    "end": "169720"
  },
  {
    "text": "called the Spring triangle that was the three key ideas that have always been",
    "start": "169720",
    "end": "175480"
  },
  {
    "text": "called a spring they are dependency injection",
    "start": "175480",
    "end": "181680"
  },
  {
    "text": "as portable service abstractions and aspect oriented programming dependency injection is",
    "start": "181680",
    "end": "188599"
  },
  {
    "text": "obviously how spring at components get to know about each other and get to know about",
    "start": "188599",
    "end": "194239"
  },
  {
    "text": "infrastructure portable service abstractions are how spring apps can",
    "start": "194239",
    "end": "200959"
  },
  {
    "text": "work with underlying resources and capabilities for example one of the first killer things that spring did was",
    "start": "200959",
    "end": "209080"
  },
  {
    "text": "enable you to write an application that could provide transactions either in say a tomcat environment or a web spere web",
    "start": "209080",
    "end": "216560"
  },
  {
    "text": "logic distributed transaction environment IOP enables you to combine",
    "start": "216560",
    "end": "224560"
  },
  {
    "text": "those two things so for example if you're using spring you've probably used or seen the transaction",
    "start": "224560",
    "end": "231239"
  },
  {
    "text": "Interceptor where you have at transactional annotations on your",
    "start": "231239",
    "end": "237120"
  },
  {
    "text": "methods that is enabled with spr aop which intercepts calls to those methods",
    "start": "237120",
    "end": "244920"
  },
  {
    "text": "and applies transaction management so it turns out that these three Core Concepts",
    "start": "244920",
    "end": "251720"
  },
  {
    "text": "have been a gift that has kept giving for decades and it turns out that as",
    "start": "251720",
    "end": "256799"
  },
  {
    "text": "hopefully I'll be able to convince you they are extremely powerful and suited",
    "start": "256799",
    "end": "262240"
  },
  {
    "text": "to dealing with the challenges of building gen applications if you've thought about gen",
    "start": "262240",
    "end": "271039"
  },
  {
    "text": "or um worked with it there's a pretty high probability that you've used",
    "start": "271039",
    "end": "276759"
  },
  {
    "text": "python certainly there is undoubtedly a python Affinity in machine",
    "start": "276759",
    "end": "283440"
  },
  {
    "text": "learning and it has reached the point where I truly believe that every",
    "start": "283440",
    "end": "289240"
  },
  {
    "text": "developer needs to know python I think it is the one language that every",
    "start": "289240",
    "end": "294600"
  },
  {
    "text": "developer is going to need to know so if you don't if you're not already fluent in python I would strongly encourage you",
    "start": "294600",
    "end": "301880"
  },
  {
    "text": "to get fluent because I really think that's important and get by getting",
    "start": "301880",
    "end": "306960"
  },
  {
    "text": "fluent I also mean getting fluent in current python python has improved a whole lot in the last few years if you",
    "start": "306960",
    "end": "313840"
  },
  {
    "text": "look at say 312 it has rules kind of like a type system type hints are really",
    "start": "313840",
    "end": "320919"
  },
  {
    "text": "quite good it's certainly way better than python 2 Inc comparably better than python 2 and it's even significantly",
    "start": "320919",
    "end": "327199"
  },
  {
    "text": "better than early python three so I would say you know as a um just side",
    "start": "327199",
    "end": "334880"
  },
  {
    "text": "piece of advice you should know python you should be able to read it however",
    "start": "334880",
    "end": "340160"
  },
  {
    "text": "that is absolutely not the same thing as saying that you should be building",
    "start": "340160",
    "end": "345560"
  },
  {
    "text": "applications in Python rather than Java or net or whatever else you're",
    "start": "345560",
    "end": "351120"
  },
  {
    "text": "using I think it's important to be able to read Python and write python because there is a lot of work in machine",
    "start": "351120",
    "end": "357960"
  },
  {
    "text": "learning and gen that's done in in Python and if you want to keep up with all the experiments that people are",
    "start": "357960",
    "end": "363520"
  },
  {
    "text": "doing it's really important to be fluent but I really believe that if you're building Enterprise applications and",
    "start": "363520",
    "end": "370919"
  },
  {
    "text": "that need geni you're better to stick with the stack that you're presently",
    "start": "370919",
    "end": "377240"
  },
  {
    "text": "using and the gni capabilities that are now growing on that stack so in this",
    "start": "377240",
    "end": "385240"
  },
  {
    "text": "presentation I'm going to do live coding using spring um AI and you'll be able to see that Java or",
    "start": "385240",
    "end": "392520"
  },
  {
    "text": "cotland or whatever language you use on the jvm is really quite competitive now in J okay now we get to the exciting",
    "start": "392520",
    "end": "400280"
  },
  {
    "text": "point where this demo is cursed I have given this talk or a variant of this",
    "start": "400280",
    "end": "405599"
  },
  {
    "text": "talk twice before each time has been accompanied by disasters and clearly the",
    "start": "405599",
    "end": "412960"
  },
  {
    "text": "like internet not working one talk that I gave in San Francisco three wireless",
    "start": "412960",
    "end": "418919"
  },
  {
    "text": "mics ran out of battery while I was trying to talk this time our challenge is the beach ball of death so yep",
    "start": "418919",
    "end": "427199"
  },
  {
    "text": "intellig is really dead Okay so yep it's just intellig okay",
    "start": "427199",
    "end": "434120"
  },
  {
    "text": "let us try for squit yep it's",
    "start": "434120",
    "end": "439599"
  },
  {
    "text": "intellig okay H",
    "start": "439599",
    "end": "444240"
  },
  {
    "text": "interesting well if I can get intell up we will get get to look at woo okay H",
    "start": "446400",
    "end": "452919"
  },
  {
    "text": "this is what it was doing this morning when I couldn't work out why intellig was not it just started and minimized",
    "start": "452919",
    "end": "462840"
  },
  {
    "text": "itself I tried rebooting this morning didn't fix this problem unfortunately I don't remember what did fix it um it I",
    "start": "471360",
    "end": "479720"
  },
  {
    "text": "had this exact problem this morning um what if",
    "start": "479720",
    "end": "485120"
  },
  {
    "text": "I has anyone seen this where whoa okay that's",
    "start": "485120",
    "end": "491919"
  },
  {
    "text": "fascinating um okay so we have intell up",
    "start": "491919",
    "end": "497800"
  },
  {
    "start": "495000",
    "end": "2420000"
  },
  {
    "text": "um so what I have started by doing is creating a new um spring boot app and I",
    "start": "497800",
    "end": "504759"
  },
  {
    "text": "did that by going to start. spring.io so with the spring initializer",
    "start": "504759",
    "end": "511360"
  },
  {
    "text": "you can see on the right the packages that I took open AI olama which are from",
    "start": "511360",
    "end": "517479"
  },
  {
    "text": "Spring AI the Neo for J Vector database spring data Neo for J and the spring",
    "start": "517479",
    "end": "522839"
  },
  {
    "text": "boot actuator so by the way the project that I have is on my GitHub um so",
    "start": "522839",
    "end": "531320"
  },
  {
    "text": "Johnson R is my GitHub ID and this repo is currently pinned is spring AI demo so",
    "start": "531320",
    "end": "538920"
  },
  {
    "text": "very important to know that if intell crashes completely you can still actually get to see the code but I will",
    "start": "538920",
    "end": "544279"
  },
  {
    "text": "endeavor to show you some of the code now so what I'm going to do is build a",
    "start": "544279",
    "end": "550760"
  },
  {
    "text": "simple chatbot and demonstrate how we go about this in um Java so the first thing",
    "start": "550760",
    "end": "558959"
  },
  {
    "text": "that we need to do is have fundamental um kind of table stake setup",
    "start": "558959",
    "end": "564519"
  },
  {
    "text": "so there are two Core Concepts that spring AI has in accessing Geno models",
    "start": "564519",
    "end": "570519"
  },
  {
    "text": "one is called a chat model which is essentially an llm like one of the open AI llms like",
    "start": "570519",
    "end": "577600"
  },
  {
    "text": "gp4 the other is an embedding model embedding models are used for Vector",
    "start": "577600",
    "end": "583320"
  },
  {
    "text": "similarity search and they are a very important part of um the whole setup so",
    "start": "583320",
    "end": "591839"
  },
  {
    "text": "you can get your chat model setup using spring AI is simply by importing a starter so if you import a spring boot",
    "start": "591839",
    "end": "599720"
  },
  {
    "text": "stter for open AI you will automatically get a chat model in this case one of the",
    "start": "599720",
    "end": "605560"
  },
  {
    "text": "things that I want to show is that you can use more than one chat model in the same application so I'm explicitly",
    "start": "605560",
    "end": "612800"
  },
  {
    "text": "configuring it so I am explicitly configuring it using um spring and at spr Spring at",
    "start": "612800",
    "end": "620040"
  },
  {
    "text": "configuration class and you can see here I've got two chat model",
    "start": "620040",
    "end": "626720"
  },
  {
    "text": "beans I've given them um separate names but you can see that I've used the prim",
    "start": "626720",
    "end": "632560"
  },
  {
    "text": "at primary annotation on one of them so if I just inject the chat model anywhere I get the default chat model so the",
    "start": "632560",
    "end": "639440"
  },
  {
    "text": "default chat model is the default um open AI chat model which I think is GPT",
    "start": "639440",
    "end": "644800"
  },
  {
    "text": "40 currently in Spring AI but I've also set up a local chat model which is an",
    "start": "644800",
    "end": "652480"
  },
  {
    "text": "olama chat model has anybody used o Lama o Ma",
    "start": "652480",
    "end": "659560"
  },
  {
    "text": "olur is a very cool open- source project that enables you to work with open",
    "start": "659560",
    "end": "666160"
  },
  {
    "text": "source models potentially locally so there's been really a lot of evolution",
    "start": "666160",
    "end": "671720"
  },
  {
    "text": "in the world of llms in the last year say 18 months ago even 12 months ago",
    "start": "671720",
    "end": "680680"
  },
  {
    "text": "open-source models were not that you could run on your local machine with not a whole lot of use for most things now",
    "start": "680680",
    "end": "688200"
  },
  {
    "text": "they are definitely quite usable for certain things and that's that's kind of a game Cher because remember if you look",
    "start": "688200",
    "end": "696480"
  },
  {
    "text": "at the at the resources consumed by models like",
    "start": "696480",
    "end": "701639"
  },
  {
    "text": "gp4 they are so inconceivably massive that your you know your laptop can't not",
    "start": "701639",
    "end": "708279"
  },
  {
    "text": "only could it not possibly do training or fine tuning it can't remotely do",
    "start": "708279",
    "end": "713760"
  },
  {
    "text": "inference and it also means of course that these big models have a very high Environmental footprint they use a lot",
    "start": "713760",
    "end": "720720"
  },
  {
    "text": "of electricity and they use a lot of water so you know one of the things that I would say in terms of best",
    "start": "720720",
    "end": "727720"
  },
  {
    "text": "practice is use the smallest chat model that you can use for any purpose that",
    "start": "727720",
    "end": "734399"
  },
  {
    "text": "gives you two benefits one is it means that the planet might last a little bit longer but secondly it means that you",
    "start": "734399",
    "end": "743839"
  },
  {
    "text": "have more ability to explain what's happening let's suppose that in theory",
    "start": "743839",
    "end": "750399"
  },
  {
    "text": "big models were able to eventually do anything we wanted to do that would",
    "start": "750399",
    "end": "755560"
  },
  {
    "text": "still be pretty scary for a business application you know why was a particular response generated I don't",
    "start": "755560",
    "end": "763240"
  },
  {
    "text": "know there's you know 1.2 trillion parameters in the model clearly some combination of them said this is the",
    "start": "763240",
    "end": "769639"
  },
  {
    "text": "response we should have that's really not adequate so if you can think of your",
    "start": "769639",
    "end": "776639"
  },
  {
    "text": "applications in terms of potentially breaking them up into smaller interactions you have a greater",
    "start": "776639",
    "end": "785000"
  },
  {
    "text": "ability to explain so you know unfortunately to the best of our",
    "start": "785000",
    "end": "790480"
  },
  {
    "text": "knowledge at this point llms are probably always going to be black boxes neural networks have always been black",
    "start": "790480",
    "end": "797199"
  },
  {
    "text": "boxes but there's a difference between an application that's wholly reliant on a giant black box and an application",
    "start": "797199",
    "end": "804560"
  },
  {
    "text": "that uses a number of much smaller black boxes and potentially makes decisions between the invocations so remember the",
    "start": "804560",
    "end": "812880"
  },
  {
    "text": "spring triangle which parts of the spring triangle are relevant to using multiple llms well there's clearly two",
    "start": "812880",
    "end": "821399"
  },
  {
    "text": "one is the portable service abstractions so when we inject these things the chat",
    "start": "821399",
    "end": "830040"
  },
  {
    "text": "model interface will be the same so we will get a high degree of portability",
    "start": "830040",
    "end": "835759"
  },
  {
    "text": "between these different things that is something the framework provides for us",
    "start": "835759",
    "end": "840920"
  },
  {
    "text": "another thing of course that is relevant is dependency injection we're going to be able to inject our chat",
    "start": "840920",
    "end": "846639"
  },
  {
    "text": "models here of course I should say that getting portability between llms and embedding models is not unique to Spring",
    "start": "846639",
    "end": "854519"
  },
  {
    "text": "obviously this is something that python Frameworks like Lang chain and Lama index have done for some time there's",
    "start": "854519",
    "end": "860440"
  },
  {
    "text": "also Lang chain for J but the point I would make is that naturally you would expect spring AI to do it and it now",
    "start": "860440",
    "end": "867480"
  },
  {
    "text": "does it very very well so portable service abstractions we've got that now",
    "start": "867480",
    "end": "873399"
  },
  {
    "text": "we have set up our configuration we can inject um chat models so here is our",
    "start": "873399",
    "end": "879800"
  },
  {
    "text": "application it's just a very um straightforward spring boot application the most interesting thing is the chat",
    "start": "879800",
    "end": "888680"
  },
  {
    "text": "Service chat service uses something called a conversation session which is a",
    "start": "888680",
    "end": "895279"
  },
  {
    "text": "session scope component not particularly relevant to gen but just an example of how you know if you're building this app",
    "start": "895279",
    "end": "901399"
  },
  {
    "text": "you can kind of app you can use all the things that are um given for you in the",
    "start": "901399",
    "end": "906480"
  },
  {
    "text": "spring um spring framework like transparent management of uh conversation sessions this is the most",
    "start": "906480",
    "end": "915160"
  },
  {
    "text": "interesting thing so here we have simply injected our chat model which chat model do we get when we inject the chat model",
    "start": "915160",
    "end": "922720"
  },
  {
    "text": "by default we get the primary one I've also injected an oama chat model in the",
    "start": "922720",
    "end": "928040"
  },
  {
    "text": "next Milestone of spring AI there's some really nice stuff that is going to be available around injecting multiple chat",
    "start": "928040",
    "end": "934279"
  },
  {
    "text": "models but in this case I'm differentiating them by the type I could also differentiate by using an app",
    "start": "934279",
    "end": "940639"
  },
  {
    "text": "qualifier annotation so once I've got a chat model",
    "start": "940639",
    "end": "946040"
  },
  {
    "text": "I can build a number of chat clients so",
    "start": "946040",
    "end": "951720"
  },
  {
    "text": "the way to think about this in um spring AI Concepts is you have your provider",
    "start": "951720",
    "end": "960440"
  },
  {
    "text": "like olama or um open Ai and you have",
    "start": "960440",
    "end": "965920"
  },
  {
    "text": "one or more very often one chat model that talks to a particular model from that",
    "start": "965920",
    "end": "971759"
  },
  {
    "text": "provider and that takes care of the low-level transport right the core connectivity however when you use that",
    "start": "971759",
    "end": "979600"
  },
  {
    "text": "chat model in a particular application context you may want to um use a",
    "start": "979600",
    "end": "985440"
  },
  {
    "text": "different system prompt for example you may want to have different observability different um you know interactions in",
    "start": "985440",
    "end": "993360"
  },
  {
    "text": "the use of that model so that is where the chat client um sits as a higher level concept so you can typically have",
    "start": "993360",
    "end": "1000199"
  },
  {
    "text": "one chat model and a number of chat clients so chat clients typically use a",
    "start": "1000199",
    "end": "1007920"
  },
  {
    "text": "system prompt in this case the system prompt comes from system prompt.",
    "start": "1007920",
    "end": "1013199"
  },
  {
    "text": "MD and what this um",
    "start": "1013199",
    "end": "1019000"
  },
  {
    "text": "does is set up ba the basis of every interaction so the messages that will be",
    "start": "1019000",
    "end": "1026280"
  },
  {
    "text": "exchanged in a conversation typically start with a system prompt and then are an exchange of user messages and",
    "start": "1026280",
    "end": "1033760"
  },
  {
    "text": "assistant messages an assistant message is a response from a chatbot um and the",
    "start": "1033760",
    "end": "1038798"
  },
  {
    "text": "system prompt is kind of sets up the whole conversation so in this case the",
    "start": "1038799",
    "end": "1043880"
  },
  {
    "text": "system prompt says um that the chatbots a helpful assistant working for classical Music Emporium and it helps",
    "start": "1043880",
    "end": "1050520"
  },
  {
    "text": "users discover classical music and learn about composers okay let's run this and",
    "start": "1050520",
    "end": "1057600"
  },
  {
    "text": "see what it does so we will start it up um and all de the zombie one see demo",
    "start": "1057600",
    "end": "1067559"
  },
  {
    "text": "um the zombie one is still using that Port from the previous oh God how do I",
    "start": "1067559",
    "end": "1075840"
  },
  {
    "text": "kill oh dver",
    "start": "1075840",
    "end": "1082960"
  },
  {
    "text": "um I've got to kill whatever's on Port 80 you know what there is an easy",
    "start": "1082960",
    "end": "1088400"
  },
  {
    "text": "command for this but we're just going to totally avoid that and we're going to do this um so our demo is now on Port 8081",
    "start": "1088400",
    "end": "1096760"
  },
  {
    "text": "no oh there's another one on 81 81 seriously um see I said this demo is",
    "start": "1096760",
    "end": "1104000"
  },
  {
    "text": "cursed what 883 cannot be in use",
    "start": "1104000",
    "end": "1110559"
  },
  {
    "text": "okay I have absolutely no idea what is going on here um I have never put",
    "start": "1115799",
    "end": "1121440"
  },
  {
    "text": "anything in my life on Port 8087 so if this is not going to start",
    "start": "1121440",
    "end": "1128320"
  },
  {
    "text": "up",
    "start": "1129720",
    "end": "1132720"
  },
  {
    "text": "okay there is nothing on 887 oh what is it",
    "start": "1135919",
    "end": "1141880"
  },
  {
    "text": "um oh there is something in 887 okay okay 894 this is no this going to be",
    "start": "1142120",
    "end": "1149480"
  },
  {
    "text": "fun uh we got to find something",
    "start": "1149480",
    "end": "1153480"
  },
  {
    "text": "somewhere 994 sounds like a good",
    "start": "1158080",
    "end": "1162960"
  },
  {
    "text": "part how can this be running on every single port",
    "start": "1164840",
    "end": "1170720"
  },
  {
    "text": "what I am utterly baffled okay we're going to work backwards we're going to find right 3,000 which is normally used",
    "start": "1173480",
    "end": "1180240"
  },
  {
    "text": "by node I'm not running any node projects so let's be sneaky let's get in",
    "start": "1180240",
    "end": "1187120"
  },
  {
    "text": "here okay okay let's see if it's any better",
    "start": "1189720",
    "end": "1196679"
  },
  {
    "text": "if I run it this way",
    "start": "1196679",
    "end": "1200440"
  },
  {
    "text": "I have absolutely no idea how to it's yeah it is but what started",
    "start": "1207240",
    "end": "1215559"
  },
  {
    "text": "it I think this has to be intellig okay I'm going to quit intellig and will",
    "start": "1223559",
    "end": "1228960"
  },
  {
    "text": "presumably kill all [Music]",
    "start": "1228960",
    "end": "1235080"
  },
  {
    "text": "those yes thank you that is the one that I can never remember okay so okay so now",
    "start": "1235080",
    "end": "1241360"
  },
  {
    "text": "we're going to go back to well let's go back to",
    "start": "1241360",
    "end": "1249039"
  },
  {
    "text": "8080 8080 okay actuated Health end points not up nothing's up okay let's",
    "start": "1249039",
    "end": "1254840"
  },
  {
    "text": "try come on it's has to be intellig doing something evil",
    "start": "1254840",
    "end": "1260600"
  },
  {
    "text": "um now 880 is there but intellig has died okay I'm going to use okay 80 81",
    "start": "1261120",
    "end": "1269200"
  },
  {
    "text": "okay I'm going to use 80 81 and I'm not going to use intellig I'm going to use",
    "start": "1269200",
    "end": "1275720"
  },
  {
    "text": "the springbird Run okay",
    "start": "1275720",
    "end": "1281039"
  },
  {
    "text": "so I have absolutely I'm sorry I have absolutely no idea what's happening I",
    "start": "1286279",
    "end": "1291320"
  },
  {
    "text": "think it has to be intellig but exactly what it's doing I don't know so how",
    "start": "1291320",
    "end": "1298400"
  },
  {
    "text": "can so 8082 okay so well well we we're just going to go through all ports in",
    "start": "1298400",
    "end": "1305279"
  },
  {
    "text": "turn um and hope we can actually show you something so we're going to if this",
    "start": "1305279",
    "end": "1311679"
  },
  {
    "text": "comes up we'll it be something on 882 as we burn each Port something's on 882 so",
    "start": "1311679",
    "end": "1317520"
  },
  {
    "text": "let's have a look at it okay so who are you so this is going to",
    "start": "1317520",
    "end": "1324400"
  },
  {
    "text": "go to the um chat model in the sky and you can see that it has used the system",
    "start": "1324400",
    "end": "1331480"
  },
  {
    "text": "prompt so it's a helpful assistant so now let's ask it do do you have does",
    "start": "1331480",
    "end": "1339120"
  },
  {
    "text": "your business have physical",
    "start": "1339120",
    "end": "1343919"
  },
  {
    "text": "stores so what happens when a llm doesn't know the",
    "start": "1344640",
    "end": "1351159"
  },
  {
    "text": "answer so there are two things that can happen yes it can either say it doesn't",
    "start": "1351159",
    "end": "1357039"
  },
  {
    "text": "know the answer or it can just make it up in this case it kind of made it up I mean it's quite possible that could be",
    "start": "1357039",
    "end": "1364080"
  },
  {
    "text": "right but it it is clearly not something we can depend upon in our applications so the system prompt did succeed in that",
    "start": "1364080",
    "end": "1372320"
  },
  {
    "text": "it helped us you know direct the user towards interactions around classical",
    "start": "1372320",
    "end": "1377440"
  },
  {
    "text": "music but it didn't succeed in grounding the response in anything um sensible so",
    "start": "1377440",
    "end": "1384919"
  },
  {
    "text": "if we wanted to answer questions we need to change our chat service and we need",
    "start": "1384919",
    "end": "1393919"
  },
  {
    "text": "to essentially provide um what is called retrieval augmented generation retrieval",
    "start": "1393919",
    "end": "1401880"
  },
  {
    "text": "augmented generation is a core technique for avoiding",
    "start": "1401880",
    "end": "1407080"
  },
  {
    "text": "hallucinations so so what this means is that we when we are asked a question we",
    "start": "1407080",
    "end": "1415360"
  },
  {
    "text": "look up the materials that might be relevant to answering that question how",
    "start": "1415360",
    "end": "1422200"
  },
  {
    "text": "do we do that so clearly we've got to have a database that is storing potentially relevant materials and",
    "start": "1422200",
    "end": "1429240"
  },
  {
    "text": "secondly we have to have a strategy for querying that database the normal data",
    "start": "1429240",
    "end": "1434400"
  },
  {
    "text": "store that we use is a vector database and the way this works is we've taken a",
    "start": "1434400",
    "end": "1439960"
  },
  {
    "text": "lot of content for example text content we have embedded that content so we've",
    "start": "1439960",
    "end": "1446240"
  },
  {
    "text": "done Vector indexing so each chunk of content in the database has a vector",
    "start": "1446240",
    "end": "1452120"
  },
  {
    "text": "associated with it and when a question is asked or we need to find something",
    "start": "1452120",
    "end": "1458559"
  },
  {
    "text": "relevant to a conversation we go to that database and say what do you think is the most similar um content that is",
    "start": "1458559",
    "end": "1465760"
  },
  {
    "text": "relevant to answering this question so the way in which I've",
    "start": "1465760",
    "end": "1471480"
  },
  {
    "text": "enabled this involves two things the first thing is that we put a question answer",
    "start": "1471480",
    "end": "1476960"
  },
  {
    "text": "advisor um in this is something that comes from Spring Ai and spring AI gives",
    "start": "1476960",
    "end": "1483000"
  },
  {
    "text": "us a simple outof thebox implementation of retrieval augmented",
    "start": "1483000",
    "end": "1489399"
  },
  {
    "text": "generation so what this does is actually behind the scenes it's going to edit our",
    "start": "1489399",
    "end": "1498520"
  },
  {
    "text": "um prompt to include this so the user",
    "start": "1498520",
    "end": "1504000"
  },
  {
    "text": "message will be extended by adding this so what this",
    "start": "1504000",
    "end": "1512240"
  },
  {
    "text": "question answer advisor will do is go to the vector store say what is most",
    "start": "1512240",
    "end": "1517640"
  },
  {
    "text": "similar to what the user asked put it in here and then the model",
    "start": "1517640",
    "end": "1523520"
  },
  {
    "text": "may be able to answer the question obviously we need a ve needed a vector store door as well if you recall in the",
    "start": "1523520",
    "end": "1533960"
  },
  {
    "text": "um the way we set this up we use the spring AI Neo Vector store starter so",
    "start": "1533960",
    "end": "1541559"
  },
  {
    "text": "again we come back to Portable service abstractions spring AI supports pretty much all the popular Vector stores there",
    "start": "1541559",
    "end": "1548480"
  },
  {
    "text": "are two fundamental skills of thought on Vector stores one is that you use a",
    "start": "1548480",
    "end": "1553679"
  },
  {
    "text": "dedicated Vector store like pine cone another is that you use the Vector",
    "start": "1553679",
    "end": "1558919"
  },
  {
    "text": "capabilities that are being added to pretty much every database so in this case because I'm using Neo for J for",
    "start": "1558919",
    "end": "1565080"
  },
  {
    "text": "other things I'm using Neo for J's Vector capabilities which are quite good if you are for example using postgress",
    "start": "1565080",
    "end": "1572720"
  },
  {
    "text": "PG Vector is really really very good so for example if you're using a spring jpa",
    "start": "1572720",
    "end": "1578760"
  },
  {
    "text": "application using postgress you really your first um first",
    "start": "1578760",
    "end": "1585480"
  },
  {
    "text": "instinct should be to use PG vector and add Vector capabilities to post postest",
    "start": "1585480",
    "end": "1591960"
  },
  {
    "text": "so we're going to restart this and this is truly exciting because I have absolutely no idea what's going to",
    "start": "1591960",
    "end": "1597559"
  },
  {
    "text": "happen um so we have um well actually I'm pretty sure it's going to fail um",
    "start": "1597559",
    "end": "1605080"
  },
  {
    "text": "okay so we're only used Port 8082 let's go to 8083 mind you it shows you how easy it is to configure spring",
    "start": "1605080",
    "end": "1611799"
  },
  {
    "text": "applications um so we restart this go to 8083",
    "start": "1611799",
    "end": "1618440"
  },
  {
    "text": "and hopefully it's the right 83 8083 we're going to we have I in some setup",
    "start": "1618440",
    "end": "1624840"
  },
  {
    "text": "code which you can find in the repo um you can see that I have indexed some",
    "start": "1624840",
    "end": "1630200"
  },
  {
    "text": "existing documentation so this tells us about the stores um so you we we've put",
    "start": "1630200",
    "end": "1636200"
  },
  {
    "text": "in a little bit of data that hopefully will make this work do you have physical",
    "start": "1636200",
    "end": "1643200"
  },
  {
    "text": "stores so very different response we have been able to ground the response in",
    "start": "1645720",
    "end": "1653240"
  },
  {
    "text": "solid um fact in this case so that's one of the",
    "start": "1653240",
    "end": "1659600"
  },
  {
    "text": "fundamental um techniques of you know making llms useful in production and as",
    "start": "1659600",
    "end": "1666360"
  },
  {
    "text": "you can see it was very easy to set up basic rag using spring AI if we go back",
    "start": "1666360",
    "end": "1671960"
  },
  {
    "text": "to the chat service you can see the way I configured this so we've got",
    "start": "1671960",
    "end": "1679159"
  },
  {
    "text": "default advisors which include the message Chat",
    "start": "1679159",
    "end": "1685279"
  },
  {
    "text": "memory advisor which is where we store all the messages and that as you would expect in Spring is pluggable U portable",
    "start": "1685279",
    "end": "1691919"
  },
  {
    "text": "service abstractions and we have the question answer advisor anybody remember",
    "start": "1691919",
    "end": "1698399"
  },
  {
    "text": "the term advisor it's an aop term isn't it so this is you know essentially an",
    "start": "1698399",
    "end": "1704159"
  },
  {
    "text": "application of aop Concepts um to chat so the advisors are essentially a",
    "start": "1704159",
    "end": "1711080"
  },
  {
    "text": "pipeline of interceptors that are involved in generating chat",
    "start": "1711080",
    "end": "1718960"
  },
  {
    "text": "responses okay let's have a look at what else we could do with advisors remember",
    "start": "1718960",
    "end": "1724279"
  },
  {
    "text": "what is IOP good for aop is good for addressing crosscutting concerns IOP is",
    "start": "1724279",
    "end": "1731799"
  },
  {
    "text": "also good for having like really really off-putting terminology like join point",
    "start": "1731799",
    "end": "1737080"
  },
  {
    "text": "and cross cutting concerns but essentially what aop enables us to do is",
    "start": "1737080",
    "end": "1742360"
  },
  {
    "text": "to apply consistent Behavior across multiple things so for example transaction management what kind of",
    "start": "1742360",
    "end": "1749200"
  },
  {
    "text": "consistent Behavior might we like to apply across multiple chat interactions",
    "start": "1749200",
    "end": "1754880"
  },
  {
    "text": "well one pretty obvious one is a toxicity guard right if we want to guard",
    "start": "1754880",
    "end": "1760440"
  },
  {
    "text": "against prompt injection guard against you know toxic um interactions um that's a very obvious",
    "start": "1760440",
    "end": "1768200"
  },
  {
    "text": "example and it means that you potentially have the ability to build components that are reusable across",
    "start": "1768200",
    "end": "1775360"
  },
  {
    "text": "multiple applications okay now let us build a or I'll show you",
    "start": "1775360",
    "end": "1782880"
  },
  {
    "text": "a out of the uh uh advisor that is not out of the box which is one that I have",
    "start": "1782880",
    "end": "1789039"
  },
  {
    "text": "authored myself so let's have a look here at the topic guard so I hasten to",
    "start": "1789039",
    "end": "1797679"
  },
  {
    "text": "point out that this is not something that um is production gr it's just an",
    "start": "1797679",
    "end": "1803799"
  },
  {
    "text": "illustration and what I'm going to do is guard against",
    "start": "1803799",
    "end": "1810080"
  },
  {
    "text": "unpleasant or irrelevant topics so in order to do that we need to classify the",
    "start": "1810080",
    "end": "1816559"
  },
  {
    "text": "topic that the user seems to be talking about how are we going to do that we're going to use another llm we could of",
    "start": "1816559",
    "end": "1823720"
  },
  {
    "text": "course use a much smaller model for a classification model but in this case we're using the local llm so here when",
    "start": "1823720",
    "end": "1833039"
  },
  {
    "text": "we create this we're giving it a chat model in the Constructor and we're going",
    "start": "1833039",
    "end": "1838640"
  },
  {
    "text": "to classify the topics very simple cotland um data class as you can see I'm",
    "start": "1838640",
    "end": "1845559"
  },
  {
    "text": "using cotland rather than Java I do find cotlin an extremely um Pleasant language",
    "start": "1845559",
    "end": "1851360"
  },
  {
    "text": "to work in and it works brilliantly with um spring but you know you could write this in Java and it would work exactly",
    "start": "1851360",
    "end": "1857000"
  },
  {
    "text": "the same way so we're going to classify the topic and the topics that we have",
    "start": "1857000",
    "end": "1862039"
  },
  {
    "text": "are sport religion politics or other and I think as you can guess we probably don't want to talk about um politics or",
    "start": "1862039",
    "end": "1870000"
  },
  {
    "text": "religion so to do the actual classification we will use a different",
    "start": "1870000",
    "end": "1876760"
  },
  {
    "text": "chat client remember I said that chat clients are kind of essentially lighter",
    "start": "1876760",
    "end": "1882240"
  },
  {
    "text": "weight than chat models we can have multiple chat clients in this case we're going to use",
    "start": "1882240",
    "end": "1888919"
  },
  {
    "text": "a quite different prompt which is topic guard which looks like this there's a",
    "start": "1888919",
    "end": "1895360"
  },
  {
    "text": "couple of things that are different about this prompt to the other one one is that I happen to use a Convention of",
    "start": "1895360",
    "end": "1902919"
  },
  {
    "text": "um XML like convention to delimit the content it's usually a good idea to try",
    "start": "1902919",
    "end": "1909480"
  },
  {
    "text": "to be very clear about what things are like you know being assessed versus what",
    "start": "1909480",
    "end": "1914919"
  },
  {
    "text": "is kind of system prompt doesn't need to be XML style but you know this concept of delimiting um something that should",
    "start": "1914919",
    "end": "1922039"
  },
  {
    "text": "be assessed by the model is important um and also notice here that we've got",
    "start": "1922039",
    "end": "1928279"
  },
  {
    "text": "curly brackets so this is actually a template it's not going to be a literal string we're going to replace that",
    "start": "1928279",
    "end": "1935360"
  },
  {
    "text": "dynamically with the value that we have at runtime so in this case we're using",
    "start": "1935360",
    "end": "1941080"
  },
  {
    "text": "the default out of the box uh prompt template syntax which spring AI provides",
    "start": "1941080",
    "end": "1946559"
  },
  {
    "text": "which is compatible with p F strings this um makes sense because",
    "start": "1946559",
    "end": "1952519"
  },
  {
    "text": "python is obviously as I mentioned a very popular language in the world of gen AI the next Milestone of spring AI",
    "start": "1952519",
    "end": "1961480"
  },
  {
    "text": "is going to probably have additional uh prompt templates like possibly Ginger",
    "start": "1961480",
    "end": "1967000"
  },
  {
    "text": "and mustache so um additional um templating Technologies so here we've",
    "start": "1967000",
    "end": "1974120"
  },
  {
    "text": "also set a parameter um to say that the user content is going to be passed um to",
    "start": "1974120",
    "end": "1981720"
  },
  {
    "text": "that but we've done something quite different here remember that this interaction is not about generating a",
    "start": "1981720",
    "end": "1987600"
  },
  {
    "text": "response to the user this interaction is about returning a jvm object this",
    "start": "1987600",
    "end": "1995080"
  },
  {
    "text": "interaction is about returning this object turns out that particularly when",
    "start": "1995080",
    "end": "2001000"
  },
  {
    "text": "you're building business applications a lot of the interactions that you have with llms are not just",
    "start": "2001000",
    "end": "2008000"
  },
  {
    "text": "generating free text they're generating structured output again this is the kind of thing",
    "start": "2008000",
    "end": "2014799"
  },
  {
    "text": "you would expect a framework to help you with and in fact spring AI does so see",
    "start": "2014799",
    "end": "2021559"
  },
  {
    "text": "when we make the call here previously we asked for just the response and we got text back here we're asking for an",
    "start": "2021559",
    "end": "2029120"
  },
  {
    "text": "entity and specifying the type of that",
    "start": "2029120",
    "end": "2034320"
  },
  {
    "text": "entity that causes spring AI to do some magic under the covers what it does is",
    "start": "2034320",
    "end": "2040639"
  },
  {
    "text": "it introspects the topic classification class and add some text to the model",
    "start": "2040639",
    "end": "2047519"
  },
  {
    "text": "interaction saying when you return please use Json to return this structure so it",
    "start": "2047519",
    "end": "2055638"
  },
  {
    "text": "generates a Json schema and passes it up to the model the models have all been",
    "start": "2055639",
    "end": "2061480"
  },
  {
    "text": "trained these days on returning um structured data in Json um so you know",
    "start": "2061480",
    "end": "2067398"
  },
  {
    "text": "it's highly probable that even a local model like the small one that I'm using here is going to do that correctly but",
    "start": "2067399",
    "end": "2074280"
  },
  {
    "text": "notice we didn't have to write any low-level code for marshalling that Json",
    "start": "2074280",
    "end": "2080398"
  },
  {
    "text": "response the model that I'm going to use here is an O Lama model running on my",
    "start": "2080399",
    "end": "2086200"
  },
  {
    "text": "machine it's much smaller so these are the local models I've got um so this",
    "start": "2086200",
    "end": "2092200"
  },
  {
    "text": "model is Gemma 22b",
    "start": "2092200",
    "end": "2097880"
  },
  {
    "text": "and this is now up and running on my my machine tell me something about",
    "start": "2097880",
    "end": "2105960"
  },
  {
    "text": "Brisbane this is running on my machine and it's not terrible so as you can see",
    "start": "2105960",
    "end": "2112359"
  },
  {
    "text": "there are certain things that this could be good for like for example translation tasks summarization tasks potentially",
    "start": "2112359",
    "end": "2119079"
  },
  {
    "text": "this kind of classification task it would not be capable of doing the um rag",
    "start": "2119079",
    "end": "2124960"
  },
  {
    "text": "enabled chatbot task that I have tried it and the results were really quite bad",
    "start": "2124960",
    "end": "2131800"
  },
  {
    "text": "okay so now we've got this up here I'm trying to remember which Port we're up",
    "start": "2131800",
    "end": "2137680"
  },
  {
    "text": "to now so why don't we go to let's go to we haven't burnt 8084 yet have we let's",
    "start": "2137680",
    "end": "2143440"
  },
  {
    "text": "burn Port 884 and see what we get this is the first talk I've ever had to do",
    "start": "2143440",
    "end": "2149200"
  },
  {
    "text": "this this is this is fascinating um so hopefully the topic guard will be in",
    "start": "2149200",
    "end": "2157000"
  },
  {
    "text": "place so if we run it despite it lying to me it's still up do you like duosi it'll probably tell",
    "start": "2157000",
    "end": "2165400"
  },
  {
    "text": "me it's an AI but it loves classical music I don't have personal preferences okay fair enough um do you like Donald",
    "start": "2165400",
    "end": "2175200"
  },
  {
    "text": "Trump I'm sorry but I can only help you with classical music notice that response was really fast as well let's",
    "start": "2175920",
    "end": "2182800"
  },
  {
    "text": "look at how that happened that came from the topic guard advisor where we use",
    "start": "2182800",
    "end": "2191119"
  },
  {
    "text": "this isban topic method so in the um advis request we firstly asked if the",
    "start": "2191119",
    "end": "2197839"
  },
  {
    "text": "topic was banned we did this using a retry template because the local models",
    "start": "2197839",
    "end": "2202920"
  },
  {
    "text": "a little bit more flaky but guess what we're still saving the planet if the local model doesn't work 100% of the",
    "start": "2202920",
    "end": "2208760"
  },
  {
    "text": "time and we have to reinvoke it it's still better than um using all that water from um open Ai and if the topic",
    "start": "2208760",
    "end": "2216839"
  },
  {
    "text": "is banned we kind of short circuit the response to say I sorry I can only help you with classical music so there's one",
    "start": "2216839",
    "end": "2224119"
  },
  {
    "text": "other thing that um I wanted to show which I think I'm just going to show the",
    "start": "2224119",
    "end": "2229640"
  },
  {
    "text": "code in the two minutes I have remaining rather than run it but we've seen one",
    "start": "2229640",
    "end": "2234800"
  },
  {
    "text": "core technique for grounding llm responses and avoiding hallucinations",
    "start": "2234800",
    "end": "2239960"
  },
  {
    "text": "that is rag retrieval augmented generation there is another really important um technique and that's called",
    "start": "2239960",
    "end": "2247000"
  },
  {
    "text": "function calling so at modern models have been trained to be able to know",
    "start": "2247000",
    "end": "2253680"
  },
  {
    "text": "when they should call functions so the way this works is you pass up to the",
    "start": "2253680",
    "end": "2258839"
  },
  {
    "text": "model A String saying by the way you might find these functions useful and so",
    "start": "2258839",
    "end": "2265240"
  },
  {
    "text": "for example if the user um wants to update their mailing address call this",
    "start": "2265240",
    "end": "2270720"
  },
  {
    "text": "function and by the way here are the arguments so the way in which this looks",
    "start": "2270720",
    "end": "2276520"
  },
  {
    "text": "in Spring a i is rather consistent so",
    "start": "2276520",
    "end": "2282440"
  },
  {
    "text": "let's go to the chat service and put some function calling magic in there so",
    "start": "2282440",
    "end": "2289640"
  },
  {
    "text": "we would simply do this so we would",
    "start": "2289640",
    "end": "2295680"
  },
  {
    "text": "add default functions um in this case the functions",
    "start": "2295680",
    "end": "2301160"
  },
  {
    "text": "have been injected remember that in Spring you can inject a list um and as",
    "start": "2301160",
    "end": "2307760"
  },
  {
    "text": "well as a simple type so this is going to say anything that implements spring function callback in my context injected",
    "start": "2307760",
    "end": "2315760"
  },
  {
    "text": "here and make it available so let's look at where they come from they're in a file called",
    "start": "2315760",
    "end": "2321839"
  },
  {
    "text": "functions um and we're using the Builder pattern to build um function callbacks",
    "start": "2321839",
    "end": "2330520"
  },
  {
    "text": "notice that this enables us to implement functions with full access to the",
    "start": "2330520",
    "end": "2336240"
  },
  {
    "text": "resources managed by the spring container so in this case I've injected the Neo forj template and these",
    "start": "2336240",
    "end": "2341720"
  },
  {
    "text": "functions are actually interacting with Neo forj so in this case it's actually",
    "start": "2341720",
    "end": "2347079"
  },
  {
    "text": "doing a database query and returning the response so you know another benefit of",
    "start": "2347079",
    "end": "2352720"
  },
  {
    "text": "using um spring AI is that you can really leverage everything you already",
    "start": "2352720",
    "end": "2359079"
  },
  {
    "text": "have in your spring um applications so look I'm sorry I really",
    "start": "2359079",
    "end": "2365640"
  },
  {
    "text": "did want to illustrate the function calling um but I'll leave you with a few",
    "start": "2365640",
    "end": "2371760"
  },
  {
    "text": "of what I think are best practices and a few challenges best practices use",
    "start": "2371760",
    "end": "2378520"
  },
  {
    "text": "cotland Spring today is really economical it is very concise you don't",
    "start": "2378520",
    "end": "2385520"
  },
  {
    "text": "really have to do a lot of configuration a lot of duplication when you see spring apps using cotland you realize that",
    "start": "2385520",
    "end": "2391760"
  },
  {
    "text": "whatever duplication is in most spring applications today comes from java not spring secondly externalize your prompts",
    "start": "2391760",
    "end": "2399160"
  },
  {
    "text": "rather than burying them in strings it really drives me crazy when I see people burying prompts in Python F strings or",
    "start": "2399160",
    "end": "2406520"
  },
  {
    "text": "um Java strings um thirdly um consider the use of multiple",
    "start": "2406520",
    "end": "2414440"
  },
  {
    "text": "models because you should be able to use the most appropriate model for your",
    "start": "2414440",
    "end": "2420160"
  },
  {
    "start": "2420000",
    "end": "2433000"
  },
  {
    "text": "scenario okay well if you want to see the full code including the um function calling remember Johnson r on GitHub and",
    "start": "2420160",
    "end": "2427680"
  },
  {
    "text": "it's pinned is spring AI demo",
    "start": "2427680",
    "end": "2432720"
  }
]
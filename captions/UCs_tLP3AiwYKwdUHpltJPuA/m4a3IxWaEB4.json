[
  {
    "text": "[Music] good afternoon everyone as a first thing",
    "start": "6990",
    "end": "13840"
  },
  {
    "text": "I wanted to show you this is a robot this photo is from two months ago it's a",
    "start": "13840",
    "end": "19090"
  },
  {
    "text": "robot conducting the Philharmonic Orchestra in Italy so this is just to give us a bit of a taste of where we are",
    "start": "19090",
    "end": "25840"
  },
  {
    "text": "in terms of Technology and if you've been to the artificial intelligence track you would have seen a lot of those",
    "start": "25840",
    "end": "32910"
  },
  {
    "text": "artificial intelligence revolutionary things that we have at the moment as well but let's take a step back right",
    "start": "32910",
    "end": "38200"
  },
  {
    "text": "not even robots running orchestras if you go to Google right now and I landed",
    "start": "38200",
    "end": "43870"
  },
  {
    "text": "in Berlin yesterday and I went to Google and I googled where to eat in Berlin and",
    "start": "43870",
    "end": "49570"
  },
  {
    "text": "then I thought maybe I could try this in German and then I had no idea how to pronounce that someone helped me so it's",
    "start": "49570",
    "end": "55960"
  },
  {
    "text": "something like MOOC and money in Berlin Essen there are 17 million results to",
    "start": "55960",
    "end": "62469"
  },
  {
    "text": "that question right and Google even humiliates us saying that it calculated that in 0.43 seconds and in which of",
    "start": "62469",
    "end": "72010"
  },
  {
    "text": "those results do we click ninety one point five percent of people end up clicking on the results from the first",
    "start": "72010",
    "end": "78340"
  },
  {
    "text": "page of a Google search so do we think that that decision was us or was it",
    "start": "78340",
    "end": "84430"
  },
  {
    "text": "Google who actually helped us make that decision for us if out of 17 million",
    "start": "84430",
    "end": "89770"
  },
  {
    "text": "results if we click on the results from the first page I will turn of us enough from that decision or was that the",
    "start": "89770",
    "end": "96220"
  },
  {
    "text": "algorithms of search from Google that actually influenced us to make that decision so that's what I want to talk",
    "start": "96220",
    "end": "102880"
  },
  {
    "text": "to you about I call this digital nudge and it's about these hidden forces that actually shape our digital decisions",
    "start": "102880",
    "end": "109410"
  },
  {
    "text": "please ask questions through the app and we'll try to answer them at the end this",
    "start": "109410",
    "end": "115840"
  },
  {
    "text": "number 35,000 what does this mean this is the average number of decisions that",
    "start": "115840",
    "end": "121510"
  },
  {
    "text": "every human makes every single day so that's probably a decision every two seconds",
    "start": "121510",
    "end": "126880"
  },
  {
    "text": "so think about it one two you've just made a decision right that I hope it's",
    "start": "126880",
    "end": "132040"
  },
  {
    "text": "to keep paying attention to the presentation but I want to tell you about an experiment that experiment is",
    "start": "132040",
    "end": "137799"
  },
  {
    "text": "actually what changed my life about seven years ago someone told me about this experiment and my life has changed completely the",
    "start": "137799",
    "end": "144430"
  },
  {
    "text": "way I see the decisions I make and the way I see the decisions that others make has changed completely I don't know if",
    "start": "144430",
    "end": "150010"
  },
  {
    "text": "anyone knows this experiment here it's the economists experiment this magazine actually presented the subscribers with",
    "start": "150010",
    "end": "156220"
  },
  {
    "text": "three options for subscription one option was the digital version for $59",
    "start": "156220",
    "end": "161800"
  },
  {
    "text": "the other option was the print version for $125 and there was an option for a",
    "start": "161800",
    "end": "167290"
  },
  {
    "text": "combo of print plus digital for 125 what happened was that everyone most of the",
    "start": "167290",
    "end": "174459"
  },
  {
    "text": "people actually bought the combo for 125 no one actually got the option in the middle and a few people got the digital",
    "start": "174459",
    "end": "180459"
  },
  {
    "text": "version but the majority of people actually got the combo and then they said hang on let's actually present",
    "start": "180459",
    "end": "186660"
  },
  {
    "text": "these options in another way let's remove the option in the middle since no one bought it why should we even bother",
    "start": "186660",
    "end": "193030"
  },
  {
    "text": "presenting something that no one buys so if you only present the digital version and the combo version what happens is",
    "start": "193030",
    "end": "199750"
  },
  {
    "text": "that the majority of the people end up buying the digital version so I saw that experiment and something inside of me",
    "start": "199750",
    "end": "206019"
  },
  {
    "text": "went like I wouldn't fall for that because I'm totally rational and I make rational decisions so that wouldn't",
    "start": "206019",
    "end": "212230"
  },
  {
    "text": "happen to me I would buy whatever I want to buy regardless of what I see and then I ended up starting to study these",
    "start": "212230",
    "end": "218620"
  },
  {
    "text": "things right and there is actually a name for this option in the middle it's called decoy it's an option that is put",
    "start": "218620",
    "end": "225220"
  },
  {
    "text": "into an equation to influence you to make a decision there is even a formula if you have two options a and B and if",
    "start": "225220",
    "end": "231730"
  },
  {
    "text": "you want people to select option B you actually give them an option minus B that makes B look better so pretty much",
    "start": "231730",
    "end": "238840"
  },
  {
    "text": "someone would say why am I gonna pay $125 on the print version only if I can",
    "start": "238840",
    "end": "244840"
  },
  {
    "text": "pay $125 or both and then suddenly this option looks so much better that we",
    "start": "244840",
    "end": "249970"
  },
  {
    "text": "don't even look at the other option of course that happens to a majority of people it doesn't happen to everyone and",
    "start": "249970",
    "end": "256079"
  },
  {
    "text": "then something inside of me really wanted to understand why that happens right and one TED talk actually helped",
    "start": "256079",
    "end": "262570"
  },
  {
    "text": "me understand this and it was a TED talk that compared these things to optical illusions so as we all know we have",
    "start": "262570",
    "end": "269100"
  },
  {
    "text": "problems in our brain when we see things our vision is not perfect so when we look at an image like that",
    "start": "269100",
    "end": "275080"
  },
  {
    "text": "the blue circle on the left looks slightly bigger than the blue circle on the right right but they're actually the same size",
    "start": "275080",
    "end": "281310"
  },
  {
    "text": "what happens is what's around it actually influences the way we see things so because what's around",
    "start": "281310",
    "end": "287550"
  },
  {
    "text": "something influences the way we see things what's around a decision also influences what we will decide this",
    "start": "287550",
    "end": "295470"
  },
  {
    "text": "optical illusion here is really creepy because it makes me think that I'm really problematic the square a and the",
    "start": "295470",
    "end": "302220"
  },
  {
    "text": "square B are actually the same color it's the same gray color so when you do",
    "start": "302220",
    "end": "307860"
  },
  {
    "text": "that you actually see they are the same color so I actually opened on Photoshop and copied the little square from the a",
    "start": "307860",
    "end": "313430"
  },
  {
    "text": "and then pasted it on top of B and it's actually the same color what happens is what's around a is light so a seems",
    "start": "313430",
    "end": "321440"
  },
  {
    "text": "darker because what's around it is light what's around B is shade and then that's",
    "start": "321440",
    "end": "326910"
  },
  {
    "text": "why B looks a bit brighter but they are actually the same color basically what's around something influences the way we",
    "start": "326910",
    "end": "332940"
  },
  {
    "text": "see it so the same way that we have optical illusions we have what we call",
    "start": "332940",
    "end": "339900"
  },
  {
    "text": "cognitive biases the like optical illusions but they are optical illusions of behavior and we call them cognitive",
    "start": "339900",
    "end": "346710"
  },
  {
    "text": "illusions or cognitive biases so I'll refer to these things throughout the talk and they're pretty much these",
    "start": "346710",
    "end": "352050"
  },
  {
    "text": "little bugs that exist in our brain when we make decisions and to give a bit of a",
    "start": "352050",
    "end": "357120"
  },
  {
    "text": "background in terms of where they come from think about psychology and usually when I talk about this I say that it's the",
    "start": "357120",
    "end": "363060"
  },
  {
    "text": "psychology behind the decisions we make and people go like but is it like the psychology of Freud of like it's it like",
    "start": "363060",
    "end": "370530"
  },
  {
    "text": "when we lay down and we talked about a problem so it's not that type of psychology psychology is that big blue",
    "start": "370530",
    "end": "377040"
  },
  {
    "text": "circle inside that big blue circle there is cognitive psychology that understands",
    "start": "377040",
    "end": "382050"
  },
  {
    "text": "a bit of how we see things and how we how we learn things language and other",
    "start": "382050",
    "end": "387480"
  },
  {
    "text": "things and there is an area called behavioral economics which actually uses cognitive psychology and neuroscience to",
    "start": "387480",
    "end": "394110"
  },
  {
    "text": "understand economic decisions and public choice dan Ariely I was actually",
    "start": "394110",
    "end": "399780"
  },
  {
    "text": "mentioned by the previous talk here I don't know if someone was here he's one of the main authors on that on that area",
    "start": "399780",
    "end": "408390"
  },
  {
    "text": "he wrote this book predict irrational and it was actually through this book and through one of his TED",
    "start": "408390",
    "end": "414130"
  },
  {
    "text": "talks that I got to understand a lot more of our irrationality and there is also another very nice book called nudge",
    "start": "414130",
    "end": "420220"
  },
  {
    "text": "from Richard Thaler and Cass sustain and interestingly enough last month on 9th",
    "start": "420220",
    "end": "425620"
  },
  {
    "text": "of October we were all really happy like everyone who likes behavior economics was really happy because Richard Taylor",
    "start": "425620",
    "end": "431470"
  },
  {
    "text": "actually got the Nobel Prize from 2017 in economics for combining psychology",
    "start": "431470",
    "end": "437260"
  },
  {
    "text": "and economics that was just like a month and a month ago so to bring this a bit",
    "start": "437260",
    "end": "443050"
  },
  {
    "text": "you to our reality in technology I want to bring to you a case study I was working on a project it was an insurance",
    "start": "443050",
    "end": "449340"
  },
  {
    "text": "project we wanted to sell insurance straight to the customers usually we buy insurance through a broker but in this",
    "start": "449340",
    "end": "455560"
  },
  {
    "text": "case they wanted to sell it straight to the customer and I don't know if you've ever bought insurance here but you buy",
    "start": "455560",
    "end": "460690"
  },
  {
    "text": "insurance you have a lot of options right you have to take that and take that and then there's many many options you can buy those two options or those",
    "start": "460690",
    "end": "466660"
  },
  {
    "text": "three or those two and then basically there was a situation where to buy an insurance we had 51 511 options to buy",
    "start": "466660",
    "end": "475390"
  },
  {
    "text": "that insurance what we did was how can we simplify that interface so that users don't have all those options and we",
    "start": "475390",
    "end": "482410"
  },
  {
    "text": "actually simplified their lives so people on the project actually decided to do what we call digital",
    "start": "482410",
    "end": "487800"
  },
  {
    "text": "personalization but when we do digital personalization we have to think about based on what will personalize in that",
    "start": "487800",
    "end": "494740"
  },
  {
    "text": "case it was based on profession and other characteristics as well so if the person was a photographer they would see",
    "start": "494740",
    "end": "500920"
  },
  {
    "text": "those three options if the person was a mechanic then they would see those other three options it was during that moment",
    "start": "500920",
    "end": "507220"
  },
  {
    "text": "when I combined the knowledge I was learning from behavior economics and what I saw on that project that I really",
    "start": "507220",
    "end": "513520"
  },
  {
    "text": "realized that there is a lot of power in the hands of people who actually personalize that and personalization is",
    "start": "513520",
    "end": "520390"
  },
  {
    "text": "a big pillar in the digital world because we can only we can personalize",
    "start": "520390",
    "end": "525970"
  },
  {
    "text": "it to the extreme that each person will see a different digital interface in the physical world that's quite difficult",
    "start": "525970",
    "end": "531670"
  },
  {
    "text": "because we can't just say if someone walks into a room I will set up this whole room personalized for each and",
    "start": "531670",
    "end": "537760"
  },
  {
    "text": "every one of you but a mobile lab can be personalized to each and every one you and then I realized that there is a",
    "start": "537760",
    "end": "543170"
  },
  {
    "text": "lot of power in the hands of UX people I don't know if there's anyone here who works with UX user experience or",
    "start": "543170",
    "end": "549200"
  },
  {
    "text": "experience design but those roles on projects are quite important because",
    "start": "549200",
    "end": "554870"
  },
  {
    "text": "these people they actually define how this environment in which users will",
    "start": "554870",
    "end": "560090"
  },
  {
    "text": "make decisions is designed in behavior economics there is a name for people who actually design physical environments",
    "start": "560090",
    "end": "566990"
  },
  {
    "text": "they're called choice architects so I actually call UX people digital choice architects because they are designing",
    "start": "566990",
    "end": "573620"
  },
  {
    "text": "the environments which are digital in which users will make the decisions",
    "start": "573620",
    "end": "579040"
  },
  {
    "text": "there's a number when I saw that research is quite interesting because there is a number that in Austria it's",
    "start": "579040",
    "end": "585320"
  },
  {
    "text": "99 percent and in Denmark it's 4 percent I asked in one of my talks if anyone",
    "start": "585320",
    "end": "590960"
  },
  {
    "text": "knew what that was and someone said it's the number of Austrians could be but in",
    "start": "590960",
    "end": "599510"
  },
  {
    "text": "this case is the number of organ donors and it's quite interesting so I when I saw that research I understood that in",
    "start": "599510",
    "end": "606140"
  },
  {
    "text": "Austria you already are a an organ donor you have to ask to leave it's an opt-out version and in Denmark you are not an",
    "start": "606140",
    "end": "614000"
  },
  {
    "text": "organ donor you have to ask to be an organ donor so just by having what is called the default changes everything",
    "start": "614000",
    "end": "620960"
  },
  {
    "text": "because by default you already asked something so humans are lazy we just",
    "start": "620960",
    "end": "626150"
  },
  {
    "text": "have a tendency to remain on whatever default is so pretty much it's quite important to define what is the default",
    "start": "626150",
    "end": "632930"
  },
  {
    "text": "because if you define what's the default people the majority of the people will remain on whatever the default is",
    "start": "632930",
    "end": "638450"
  },
  {
    "text": "I actually looked up as well the research to see why Germany was and on",
    "start": "638450",
    "end": "643550"
  },
  {
    "text": "that research it was 12% but we try to use the max and the minimum numbers here",
    "start": "643550",
    "end": "649160"
  },
  {
    "text": "so quite interesting this is one of the most representative behavior economics research to explain the power of default",
    "start": "649160",
    "end": "655580"
  },
  {
    "text": "and default is actually one of these biases so one of these things we have in our brains that actually make us decide",
    "start": "655580",
    "end": "662180"
  },
  {
    "text": "one way or another the default bias is one of one of them it's called status quo bias when I",
    "start": "662180",
    "end": "669620"
  },
  {
    "text": "learned about these things I suddenly I started to visualize them in the day because I worked with technology and",
    "start": "669620",
    "end": "676240"
  },
  {
    "text": "then I started to see things you know when you learn something you start to see something that you didn't see before so I was filling out my Netflix",
    "start": "676240",
    "end": "683700"
  },
  {
    "text": "subscription and then suddenly I saw that please do not email me Netflix",
    "start": "683700",
    "end": "688990"
  },
  {
    "text": "special offers so pretty much the default was to email me and then if I",
    "start": "688990",
    "end": "694060"
  },
  {
    "text": "don't want to receive I have to check so by default they will send me the offers basically someone made a decision on my",
    "start": "694060",
    "end": "701500"
  },
  {
    "text": "behalf that I want the email office and then if I don't want I have to do something it's quite interesting I",
    "start": "701500",
    "end": "707620"
  },
  {
    "text": "opened an uber and then suddenly there was something pre-selected the uber pool",
    "start": "707620",
    "end": "712839"
  },
  {
    "text": "I don't know if there is uber pool here but recently they've they released that and then pretty much the uber pool",
    "start": "712839",
    "end": "718990"
  },
  {
    "text": "allows you to share your car with another passenger so you can pay less but then you have to go to wherever the",
    "start": "718990",
    "end": "724720"
  },
  {
    "text": "other person is going as well and then it was already pre-selected so pretty much someone from uber decided",
    "start": "724720",
    "end": "730360"
  },
  {
    "text": "that the uber pool was the decision that I wanted to take in that case I actually went and I tried the uber pool because",
    "start": "730360",
    "end": "736990"
  },
  {
    "text": "he was already selected but it was quite interesting because once that I know that now I'm aware of the fact that",
    "start": "736990",
    "end": "742690"
  },
  {
    "text": "people are doing this to me so I can be manipulated but I can be consciously manipulated right so it's like I'm I",
    "start": "742690",
    "end": "749860"
  },
  {
    "text": "want to be manipulated I know you manipulating me but I want to do that it's very different from being",
    "start": "749860",
    "end": "754959"
  },
  {
    "text": "manipulated and not even knowing about that right so when I was actually talking to an uber driver and he said",
    "start": "754959",
    "end": "760360"
  },
  {
    "text": "that there was this lady who approached the car and she had selected the car pool and then there was another passenger in the car and the lady was",
    "start": "760360",
    "end": "767050"
  },
  {
    "text": "like so what's with the other passenger and the the driver said you selected the pool and the lady went like I selected",
    "start": "767050",
    "end": "774160"
  },
  {
    "text": "the what so she didn't even know that she had selected something because he",
    "start": "774160",
    "end": "779410"
  },
  {
    "text": "was pretty much pre-selected for her that's the power of the defaults and with the default there is a lot of power",
    "start": "779410",
    "end": "785800"
  },
  {
    "text": "right but there's a lot of responsibilities as well that's why I want to talk to you about a few things you will have received an email from go",
    "start": "785800",
    "end": "792790"
  },
  {
    "text": "to conference and in the email there was something that said when you signed up",
    "start": "792790",
    "end": "798160"
  },
  {
    "text": "to go to Berlin you accepted to delegate all your decisions to the members of the organizing committee did anyone read",
    "start": "798160",
    "end": "804490"
  },
  {
    "text": "that no you actually didn't have that so four",
    "start": "804490",
    "end": "810390"
  },
  {
    "text": "go to Berlin I actually didn't do this but I gave a TEDx talk the other day and for the TEDx I actually organized with",
    "start": "810390",
    "end": "816600"
  },
  {
    "text": "the committee beforehand and we actually did that so we put that on the text for everyone who received and then that was",
    "start": "816600",
    "end": "824160"
  },
  {
    "text": "the text at all in Portuguese so you'll have to agree with me that that's what it means it said that every everyone who",
    "start": "824160",
    "end": "830010"
  },
  {
    "text": "signed up for TEDx was already delegating all the decisions of their lives an hour of 400 people only 13 of",
    "start": "830010",
    "end": "837660"
  },
  {
    "text": "them actually asked to leave they only opted out so pretty much almost 400",
    "start": "837660",
    "end": "843000"
  },
  {
    "text": "people have taken a decision without even knowing there is a very nice",
    "start": "843000",
    "end": "848640"
  },
  {
    "text": "website called dark patents it's from Harry brignall he actually catalogued a",
    "start": "848640",
    "end": "853770"
  },
  {
    "text": "few of these things and he called them dark patents one of them that I really like it's the one that says sneak into",
    "start": "853770",
    "end": "860400"
  },
  {
    "text": "basket pretty much there are some ecommerce websites that if you buy let's say tablet they actually put a tablet",
    "start": "860400",
    "end": "867810"
  },
  {
    "text": "case inside your your trolley because you might as well want to buy one so",
    "start": "867810",
    "end": "874140"
  },
  {
    "text": "they already shove it into your trolley and then if you if you want to get it that's okay if you don't want you have to remove it right and that's an",
    "start": "874140",
    "end": "880920"
  },
  {
    "text": "anti-pattern or a dark patent that Harry calls sneak into basket sometimes I",
    "start": "880920",
    "end": "885990"
  },
  {
    "text": "imagine in the real physical world we wouldn't accept that right can you imagine you're in the supermarket and",
    "start": "885990",
    "end": "891960"
  },
  {
    "text": "then suddenly someone comes and put something in your like we would never accept that so why is it that we accept",
    "start": "891960",
    "end": "897870"
  },
  {
    "text": "that in the digital world it's because we behave differently in the digital world but to bring you to some to bring",
    "start": "897870",
    "end": "903600"
  },
  {
    "text": "you the level of awareness that I really wish someone had I want to show you a few of the digital default every time",
    "start": "903600",
    "end": "910500"
  },
  {
    "text": "you see one of these things there is a default already decided for you every time you see a checkbox if it's checked",
    "start": "910500",
    "end": "916920"
  },
  {
    "text": "if it's not checked every time it time you see a drop-down it might have been selected or someone might have chosen",
    "start": "916920",
    "end": "922260"
  },
  {
    "text": "like what's the order that we have this drop-down if we have it alphabetic order then you will be more likely to select",
    "start": "922260",
    "end": "928050"
  },
  {
    "text": "the one on top if it's not alphabetic then of course there is someone who thought about the order any time you see",
    "start": "928050",
    "end": "933780"
  },
  {
    "text": "an order complete if you actually start typing something it autocompletes for you you are more likely to select what",
    "start": "933780",
    "end": "940290"
  },
  {
    "text": "come the autocomplete then to actually keep filling it search results any default settings that comes on any mobile device",
    "start": "940290",
    "end": "946790"
  },
  {
    "text": "that you buy someone has already pre-selected that timelines as well when",
    "start": "946790",
    "end": "953029"
  },
  {
    "text": "you go on Facebook or Instagram or anything that has a timeline you actually are seen what they chose you",
    "start": "953029",
    "end": "961040"
  },
  {
    "text": "for you to see because what has been rendered over there it's based on whatever rules that Facebook or",
    "start": "961040",
    "end": "967310"
  },
  {
    "text": "Instagram or any other timeline like LinkedIn they actually decided to render for you so those are all defaults so",
    "start": "967310",
    "end": "974390"
  },
  {
    "text": "when I talk to you about a concept called nudge which is the name of that book I actually went yesterday and try to translate it so it translated to subs",
    "start": "974390",
    "end": "981709"
  },
  {
    "text": "or shoobs I don't know how to say that but hopefully it's shoobs so I was going to translate it to shoobs",
    "start": "981709",
    "end": "988670"
  },
  {
    "text": "but then I translated it back you know when you translate and you're going on the way back so actually translate it back and shoobs",
    "start": "988670",
    "end": "994310"
  },
  {
    "text": "actually means job so I was like that should be wrong so let's stick to nudge and just so we understand nudge it's not",
    "start": "994310",
    "end": "1001660"
  },
  {
    "text": "a push it's not a shove it's just a tiny push so I will actually ask you to give",
    "start": "1001660",
    "end": "1008019"
  },
  {
    "text": "it a bit of a nudge to the person on your side even if you don't know them it's a great way of getting to know someone right so yeah cool don't drop",
    "start": "1008019",
    "end": "1016329"
  },
  {
    "text": "them from the chair okay cool so that's a nudge and what I want to talk to you",
    "start": "1016329",
    "end": "1021940"
  },
  {
    "text": "about is what I call digital nudge which is pretty much understanding all these little nudges that happen in the",
    "start": "1021940",
    "end": "1028418"
  },
  {
    "text": "physical world and how can we adapt them to the digital world so we understand how we behave in the digital world and",
    "start": "1028419",
    "end": "1034870"
  },
  {
    "text": "we are actually more aware of that I'll ask you a question and I want everyone",
    "start": "1034870",
    "end": "1041980"
  },
  {
    "text": "to actually respond that so can you give me a thumbs up that you will respond that helps because if you don't do that",
    "start": "1041980",
    "end": "1048308"
  },
  {
    "text": "you usually don't respond so that's also a bit of a trick so it has to be very quick right so I'll ask you a question",
    "start": "1048309",
    "end": "1054970"
  },
  {
    "text": "and the first thing that comes to your mind please just say it out loud say it really loud could be anything be careful but it could be anything like",
    "start": "1054970",
    "end": "1061740"
  },
  {
    "text": "related to the question just say it out loud cool you have a bat and a ball and",
    "start": "1061740",
    "end": "1068740"
  },
  {
    "text": "the bat and the bow together cost $1 10 the best the bat costs $1",
    "start": "1068740",
    "end": "1074419"
  },
  {
    "text": "more than the ball how much is the ball cool 10/10 a lot of people said 10/10",
    "start": "1074419",
    "end": "1082549"
  },
  {
    "text": "good how much at the ball ten cents someone already thought it's five cents so that's really good so let's let's",
    "start": "1082549",
    "end": "1089779"
  },
  {
    "text": "slow down for a bit because we did it fast and now let's do it slow so when we",
    "start": "1089779",
    "end": "1094999"
  },
  {
    "text": "when we think fast it's 10 cents of course like there's usually one or two people don't worry",
    "start": "1094999",
    "end": "1100039"
  },
  {
    "text": "like more than 50% of Stanford and Harvard students always make this mistake so don't worry I also made it so",
    "start": "1100039",
    "end": "1107090"
  },
  {
    "text": "we're all on the same here except for one person who said 5 cents which is really good talk to me afterwards",
    "start": "1107090",
    "end": "1113799"
  },
  {
    "text": "maybe we can do some stuff together so if the bat is actually if the ball is 10",
    "start": "1113799",
    "end": "1120379"
  },
  {
    "text": "cents then the batchest $1 more expensive then it would be 1/10 the total is 120 so when we think better",
    "start": "1120379",
    "end": "1127399"
  },
  {
    "text": "then the ball is 5 cents because the bat is 105 and then it's 110 cool so pretty",
    "start": "1127399",
    "end": "1132919"
  },
  {
    "text": "much what happens is and if you want to understand a bit more about this have a look at this book it's called Thinking",
    "start": "1132919",
    "end": "1138739"
  },
  {
    "text": "Fast and Slow Daniel Kahneman who's also a Nobel Prize winner has discovered",
    "start": "1138739",
    "end": "1143869"
  },
  {
    "text": "through a lot of research that we have two brains not really physically hypothetically it's like hardware and",
    "start": "1143869",
    "end": "1150679"
  },
  {
    "text": "software it's like we have to to software running one runs really fast the other run runs a bit slower and when",
    "start": "1150679",
    "end": "1157279"
  },
  {
    "text": "we think fast we make mistakes when we think slow we make less mistakes than",
    "start": "1157279",
    "end": "1162440"
  },
  {
    "text": "when we think fast but we can't think slow all the time can you imagine if I'm just walking I go like should I walk",
    "start": "1162440",
    "end": "1168859"
  },
  {
    "text": "with my left leg or with my right leg maybe if I walk with the left leg oh we",
    "start": "1168859",
    "end": "1174379"
  },
  {
    "text": "can't right so some things we just do automatically and that's how we actually build habits because habits are some",
    "start": "1174379",
    "end": "1180080"
  },
  {
    "text": "things that we do thinking fast I actually think about this concept not",
    "start": "1180080",
    "end": "1186289"
  },
  {
    "text": "just about Thinking Fast and Slow but I think about it in the way of scrolling and clicking fast and slow so can you",
    "start": "1186289",
    "end": "1193700"
  },
  {
    "text": "imagine when you are scrolling on Facebook or Instagram when you're liking things when you disliking them when",
    "start": "1193700",
    "end": "1200629"
  },
  {
    "text": "you're commenting on Facebook on Instagram you imagine if you're thinking fast or slow this is actually a bit of",
    "start": "1200629",
    "end": "1207470"
  },
  {
    "text": "some data that came out recently this is what happens in one minute on the internet there's pretty much sixteen million text",
    "start": "1207470",
    "end": "1214310"
  },
  {
    "text": "messages sent there are nine hundred thousand logins on Facebook 3.5 million search queries 7,000 hours watched on",
    "start": "1214310",
    "end": "1222650"
  },
  {
    "text": "Netflix so it's quite interesting like the number of things that we've been doing and the insight I had was how many",
    "start": "1222650",
    "end": "1229610"
  },
  {
    "text": "of those things do we do thinking fast and how many of them do we do thinking slow so when you comment on a Facebook",
    "start": "1229610",
    "end": "1236630"
  },
  {
    "text": "do we think or do we just comment the first thing that comes to your mind as if we were saying the 10 cents that we",
    "start": "1236630",
    "end": "1241880"
  },
  {
    "text": "just said now think about that so I've lived in Australia for for about 8 years",
    "start": "1241880",
    "end": "1247520"
  },
  {
    "text": "I work for this company called thought works and we also have offices here in Germany we have four offices in Berlin",
    "start": "1247520",
    "end": "1254890"
  },
  {
    "text": "Hamburg Cologne and Munich no yeah so",
    "start": "1254890",
    "end": "1260450"
  },
  {
    "text": "we're hiring for those we're also recruiting for those four offices all around here so if you want there's a",
    "start": "1260450",
    "end": "1265670"
  },
  {
    "text": "booth upstairs so I worked fourth always and when I joined the company about ten years ago there was a this reputation",
    "start": "1265670",
    "end": "1274130"
  },
  {
    "text": "that working for the company was really fun and then I moved to Australia I'm originally Brazilian and then I was like",
    "start": "1274130",
    "end": "1280760"
  },
  {
    "text": "so I'm gonna go to Australia and then I'm here I'm gonna see a lot of kangaroos and koalas everywhere and then",
    "start": "1280760",
    "end": "1286070"
  },
  {
    "text": "I was like am I thinking with my fast brain or slow brain and that's really true like there was a lot of koalas and",
    "start": "1286070",
    "end": "1291680"
  },
  {
    "text": "kangaroos and everything and there is also a lot of fun at the company but",
    "start": "1291680",
    "end": "1297440"
  },
  {
    "text": "also because I'm Brazilian when I was living in Australia people would think that I would play soccer and that Brazil",
    "start": "1297440",
    "end": "1304760"
  },
  {
    "text": "would be full of peaches and everything so the beach side is actually really true but the soccer thing is actually",
    "start": "1304760",
    "end": "1310760"
  },
  {
    "text": "not very true because I'm a horrible player in fact there's a friend of mine jewel sitting over there who's a much",
    "start": "1310760",
    "end": "1315950"
  },
  {
    "text": "better soccer player than me and he's Welsh so you see how sometimes our thinking fast brain makes mistakes",
    "start": "1315950",
    "end": "1323260"
  },
  {
    "text": "this Fabio here is actually in Australia there's only one named Fabio and it's",
    "start": "1323260",
    "end": "1329540"
  },
  {
    "text": "this one so so everytime I said my name was Fabio this is what people pictured in their",
    "start": "1329540",
    "end": "1335850"
  },
  {
    "text": "mind with their fast brain because there is no slow brain their Thinking Fast and",
    "start": "1335850",
    "end": "1347940"
  },
  {
    "text": "Slow is another big concept from behavior economics and the conversion",
    "start": "1347940",
    "end": "1353669"
  },
  {
    "text": "from the physical world into the digital world is what I mentioned before the clicking and scrolling fast and flow",
    "start": "1353669",
    "end": "1359250"
  },
  {
    "text": "but speaking of Brazil and all that let me bring some data to you Brazil is the first country to have more than one",
    "start": "1359250",
    "end": "1364830"
  },
  {
    "text": "mobile per person it has one point 38 Mobile's per person 90% of all today's data has been created",
    "start": "1364830",
    "end": "1372929"
  },
  {
    "text": "two years ago 10% of all digital photos have been taken in the last 45 days and",
    "start": "1372929",
    "end": "1379190"
  },
  {
    "text": "there are about 16 billion things connected to the internet right now so",
    "start": "1379190",
    "end": "1386700"
  },
  {
    "text": "given all that those stats do you think that those 35,000 decisions that we make",
    "start": "1386700",
    "end": "1392340"
  },
  {
    "text": "every day how many of those decisions are digital decisions what I've defined as digital decisions are decisions that",
    "start": "1392340",
    "end": "1398730"
  },
  {
    "text": "we either use one of our digital devices to make the decision or it's a decision",
    "start": "1398730",
    "end": "1404070"
  },
  {
    "text": "that we fully delegate to a digital device how many of those they've been increasing more and more",
    "start": "1404070",
    "end": "1410270"
  },
  {
    "text": "can you imagine you you see that headline for it some news people around",
    "start": "1410270",
    "end": "1415830"
  },
  {
    "text": "you control your mind when I saw that for the first time I actually thought that was not true right but then it was",
    "start": "1415830",
    "end": "1421620"
  },
  {
    "text": "from the Washington Post so I clicked on it it wasn't fake news and then pretty much the research said that there was",
    "start": "1421620",
    "end": "1429029"
  },
  {
    "text": "this news that has been had been scientifically proven that if you come into an airplane let's say that you and",
    "start": "1429029",
    "end": "1435690"
  },
  {
    "text": "the person sitting next to you actually buy something your chances of buying",
    "start": "1435690",
    "end": "1441419"
  },
  {
    "text": "jumps by 30% so you're thirty percent more likely to buy something just because the person",
    "start": "1441419",
    "end": "1446669"
  },
  {
    "text": "sitting next to you bought something and my brother is a flight attendant so I actually thought how did they run that",
    "start": "1446669",
    "end": "1452399"
  },
  {
    "text": "research right did they partner with all the airlines and then they got people to observe where people were sitting I",
    "start": "1452399",
    "end": "1458309"
  },
  {
    "text": "actually thought it was like a physical research but it turns out it was a digital research what happened was they",
    "start": "1458309",
    "end": "1464490"
  },
  {
    "text": "grabbed all the data from almost 2,000 flights from 257 thousand passengers and 65,000",
    "start": "1464490",
    "end": "1472289"
  },
  {
    "text": "transactions with that customer behavior data they ran thousands of mini",
    "start": "1472289",
    "end": "1478409"
  },
  {
    "text": "experiments just with the data and then there was a data insight that came out of the data that your chances of buying",
    "start": "1478409",
    "end": "1486029"
  },
  {
    "text": "jumps by 30% if someone next to you buys it so this is what I believe it's data",
    "start": "1486029",
    "end": "1492299"
  },
  {
    "text": "science helping us understand better how humans behave so when we understand how better we behave we can actually adjust",
    "start": "1492299",
    "end": "1498690"
  },
  {
    "text": "and be more aware as anyone here heard about this some insurance company called",
    "start": "1498690",
    "end": "1504570"
  },
  {
    "text": "lemonade it's supposed to be the world's first peer-to-peer insurance carrier",
    "start": "1504570",
    "end": "1511039"
  },
  {
    "text": "it's got a 13 million dollar budget to",
    "start": "1511039",
    "end": "1516059"
  },
  {
    "text": "actually reinvent p2p insurance it's like uber for insurance basically what",
    "start": "1516059",
    "end": "1521549"
  },
  {
    "text": "happened recently was that they've had the fastest claim I don't know if anyone here had to have to lodge a claim but it",
    "start": "1521549",
    "end": "1528419"
  },
  {
    "text": "just takes ages for any type of claim to be returned so they actually had a claim all paid in three seconds so pretty much",
    "start": "1528419",
    "end": "1536850"
  },
  {
    "text": "that was the fastest claim ever paid in the whole world they have this thing",
    "start": "1536850",
    "end": "1542309"
  },
  {
    "text": "called behavior lab where they try to understand how people behave it says",
    "start": "1542309",
    "end": "1547350"
  },
  {
    "text": "it's something that happens inside lemonade so they treat human behavior really seriously it's very similar to",
    "start": "1547350",
    "end": "1553260"
  },
  {
    "text": "something we do as always called Innovation Lab where we actually go to where people are actually doing what",
    "start": "1553260",
    "end": "1558419"
  },
  {
    "text": "they are supposed to be doing and we run experiments with them and the interesting thing is do you remember",
    "start": "1558419",
    "end": "1563639"
  },
  {
    "text": "that guy Dan Ariely who I spoke about the predictably irrational he was made the chief behavioral officer at lemonade",
    "start": "1563639",
    "end": "1570960"
  },
  {
    "text": "so this is the overlap between a digital company it's an insurance company that",
    "start": "1570960",
    "end": "1576139"
  },
  {
    "text": "is hiring a behavior economist to understand how humans behave to create a",
    "start": "1576139",
    "end": "1581279"
  },
  {
    "text": "better digital product I actually got the privilege to meet and a really the",
    "start": "1581279",
    "end": "1587760"
  },
  {
    "text": "other day in 2015 a friend of mine bumped into him at a coffee shop and",
    "start": "1587760",
    "end": "1593279"
  },
  {
    "text": "then we've actually been in touch since then he's been a bit of a digital mentor for me so it's a big",
    "start": "1593279",
    "end": "1598440"
  },
  {
    "text": "big privilege I have so it's really changed the way I see things and it's really changed my way of visualizing the",
    "start": "1598440",
    "end": "1605370"
  },
  {
    "text": "teach the world so I just want to share with you if you read about then you will know that he actually burned like a lot",
    "start": "1605370",
    "end": "1611580"
  },
  {
    "text": "of his body when he was quite young on an explosion and then he doesn't type when he emails so he sends audios so",
    "start": "1611580",
    "end": "1618450"
  },
  {
    "text": "it's quite good because this is more on one of the and one of the emails that we were exchanging then he sent me this",
    "start": "1618450",
    "end": "1625019"
  },
  {
    "text": "advice on the on the book that I've been writing so I just want to share that with you I think there is some audio",
    "start": "1625019",
    "end": "1631950"
  },
  {
    "text": "which is the audio on",
    "start": "1631950",
    "end": "1636830"
  },
  {
    "text": "is it not no cool so let's skip that it's just a bit",
    "start": "1642800",
    "end": "1649269"
  },
  {
    "text": "of an advice on the book so what I wanted to tell you is that I was thinking about writing a book on one",
    "start": "1649269",
    "end": "1654669"
  },
  {
    "text": "area and then actually changed in one like 30-second audio he actually expanded my mind into writing a book",
    "start": "1654669",
    "end": "1661389"
  },
  {
    "text": "completely different so I'm working on this book right now which is called digital nudge and it's the overlap",
    "start": "1661389",
    "end": "1667210"
  },
  {
    "text": "between behavioral science and the digital world and it's really based on the concept of nudging so if you want to",
    "start": "1667210",
    "end": "1674139"
  },
  {
    "text": "if you want it's coming soon please go to that website Digital noise org and then you get you get a free chapter as",
    "start": "1674139",
    "end": "1680559"
  },
  {
    "text": "soon as it comma comes out so a lot of people come to me and they ask Fabio by",
    "start": "1680559",
    "end": "1686259"
  },
  {
    "text": "knowing a lot of these things of how humans behave can someone be manipulated and I say yes there is a lot of ways to",
    "start": "1686259",
    "end": "1693340"
  },
  {
    "text": "manipulate people there are two types of influence there is persuasion and",
    "start": "1693340",
    "end": "1698590"
  },
  {
    "text": "coercion persuasion is getting people to do the things that they want and that they need to do and coercion is actually",
    "start": "1698590",
    "end": "1705159"
  },
  {
    "text": "getting people to do things they do not want and that they do not need so I believe we need more persuasion and we",
    "start": "1705159",
    "end": "1711429"
  },
  {
    "text": "need last coercion we need to help people do what they already need to do and what they want to do that's why I",
    "start": "1711429",
    "end": "1717369"
  },
  {
    "text": "started the digital nudges for good movement it's a movement where we try to understand in the digital space which",
    "start": "1717369",
    "end": "1723460"
  },
  {
    "text": "products and which digital services are actually helping people do what they need to do so for example there is a",
    "start": "1723460",
    "end": "1729549"
  },
  {
    "text": "continuous glucose meter that helps people understand when they need to take insulin if they have diabetes diabetes",
    "start": "1729549",
    "end": "1737259"
  },
  {
    "text": "is a huge issue in the world one in 12 people have diabetes now in the world this company called ayuda heuristics is",
    "start": "1737259",
    "end": "1744669"
  },
  {
    "text": "a very nice company that's using machine learning to actually help someone with diabetes with most of the decisions that",
    "start": "1744669",
    "end": "1751359"
  },
  {
    "text": "they have today on that day to day lives well understanding what they need to eat when they need to sleep what happens",
    "start": "1751359",
    "end": "1757479"
  },
  {
    "text": "when they sleep more what happens when they sleep less what happens when they do this and when they exercise and so",
    "start": "1757479",
    "end": "1762970"
  },
  {
    "text": "it's it's this is a digital nudge for good so we can influence someone to eat something and that's persuasion it's not",
    "start": "1762970",
    "end": "1769809"
  },
  {
    "text": "coercion this is a project from Australia called smart cap it's",
    "start": "1769809",
    "end": "1777190"
  },
  {
    "text": "truckdrivers where that you prevent microsleeps so when they're about to",
    "start": "1777190",
    "end": "1782440"
  },
  {
    "text": "have a microsleep the smart cap actually measures their brainwaves to give them a",
    "start": "1782440",
    "end": "1787539"
  },
  {
    "text": "little nudge to wake them up and prevent an accident that's another digital noise for good",
    "start": "1787539",
    "end": "1793350"
  },
  {
    "text": "but I want to bring another perspective to you as well this is a face",
    "start": "1793350",
    "end": "1799270"
  },
  {
    "text": "recognition software so I think we've",
    "start": "1799270",
    "end": "1807580"
  },
  {
    "text": "all seen one of these face recognition software you look at it and it recognizes your face and there is a very",
    "start": "1807580",
    "end": "1813700"
  },
  {
    "text": "good TEDx talk from this woman called joy she actually found out that this very specific face recognition software",
    "start": "1813700",
    "end": "1820029"
  },
  {
    "text": "doesn't recognize her face and why because there is a process in face",
    "start": "1820029",
    "end": "1826659"
  },
  {
    "text": "recognition which is the training process where the they actually give a lot of photos to the algorithm so the",
    "start": "1826659",
    "end": "1832929"
  },
  {
    "text": "algorithm learns what's a face and what's not a face and unfortunately for this specific piece of software no",
    "start": "1832929",
    "end": "1840700"
  },
  {
    "text": "photos of black people have been given to the algorithm so because no one thought about that no one thought about",
    "start": "1840700",
    "end": "1846820"
  },
  {
    "text": "diversity when they were actually training that algorithm then we end up creating an algorithm with prejudice",
    "start": "1846820",
    "end": "1853630"
  },
  {
    "text": "right we end up creating an algorithm that's not inclusive we end up creating a computer that ends up not recognizing",
    "start": "1853630",
    "end": "1860409"
  },
  {
    "text": "someone's face as a face because it hasn't learned that that's really a face so joy actually has a movement called",
    "start": "1860409",
    "end": "1866950"
  },
  {
    "text": "encoding which is supposed to have inclusive coding where inclusivity and diversity is part of what we do when we",
    "start": "1866950",
    "end": "1874299"
  },
  {
    "text": "are training algorithms it's quite interesting because I read that news on the other day after I had seen that TED",
    "start": "1874299",
    "end": "1881529"
  },
  {
    "text": "talk from joy I read those news and recently they had an AI algorithm judge",
    "start": "1881529",
    "end": "1887320"
  },
  {
    "text": "someone just from their faces to tell if they were guilty or innocent and that's",
    "start": "1887320",
    "end": "1892659"
  },
  {
    "text": "quite revolutionary right you have you have someone who looks at a lot of faces and then they learned that whoever is",
    "start": "1892659",
    "end": "1899649"
  },
  {
    "text": "guilty or whoever is innocent and in the article that actually said different from a human judge the computation of",
    "start": "1899649",
    "end": "1906159"
  },
  {
    "text": "vision algorithm has absolutely no subjectivity emotion or prejudice I agree with the emotion part",
    "start": "1906159",
    "end": "1912940"
  },
  {
    "text": "but the prejudice it depends on how that algorithm actually learned what's a guilty face and what's an innocent face",
    "start": "1912940",
    "end": "1920200"
  },
  {
    "text": "interestingly enough on that result for that algorithm it found out that people",
    "start": "1920200",
    "end": "1925960"
  },
  {
    "text": "with a smaller mouth are more likely to be guilty on a crime because it's",
    "start": "1925960",
    "end": "1931330"
  },
  {
    "text": "decided that the size of the mouth is a relevant dimension to actually understand that because the algorithm",
    "start": "1931330",
    "end": "1937750"
  },
  {
    "text": "shows by himself now the algorithms are making the decisions on which dimensions they should be looking to create their own",
    "start": "1937750",
    "end": "1944230"
  },
  {
    "text": "prejudices I quite like that quote from the the conference mind the product",
    "start": "1944230",
    "end": "1949480"
  },
  {
    "text": "recently that says the machines only know what we feed them so we have to be really conscious about feeding computers",
    "start": "1949480",
    "end": "1955930"
  },
  {
    "text": "with whatever we feed them and also when we decide which dimensions matter we have to decide them carefully this is a",
    "start": "1955930",
    "end": "1964990"
  },
  {
    "text": "video from Tesla in San Francisco I don't know if anyone has seen that but",
    "start": "1964990",
    "end": "1970630"
  },
  {
    "text": "that's a autonomous vehicle the vision",
    "start": "1970630",
    "end": "1976000"
  },
  {
    "text": "from this car is much better than any drivers vision it can see things from a",
    "start": "1976000",
    "end": "1981220"
  },
  {
    "text": "distance that no one in this room can see I'm sure unless someone here is a",
    "start": "1981220",
    "end": "1986260"
  },
  {
    "text": "superhero so what you've seen there is everything that it's actually detecting objects road lights and everything so",
    "start": "1986260",
    "end": "1995260"
  },
  {
    "text": "and it's driving by itself right we know that these cars exist we know that they",
    "start": "1995260",
    "end": "2000540"
  },
  {
    "text": "are already being trialed in a few places but when we see that video it kind of changes a few things of course",
    "start": "2000540",
    "end": "2009870"
  },
  {
    "text": "we have these cars driving around cars are making decisions on our behalf right so there are a lot of digital decisions",
    "start": "2009870",
    "end": "2016740"
  },
  {
    "text": "being made by cars right now we make a decision to actually turn left and right you actually accelerate your to actually",
    "start": "2016740",
    "end": "2024360"
  },
  {
    "text": "break a car like that's a human decision that we are delegating to a car so it's becoming a digital decision there is a",
    "start": "2024360",
    "end": "2031620"
  },
  {
    "text": "website called Mauro machine mit.edu that actually comes up with a few",
    "start": "2031620",
    "end": "2037080"
  },
  {
    "text": "challenges ethical challenges that to which we don't know the answers yet so pretty much if there is a car coming",
    "start": "2037080",
    "end": "2042930"
  },
  {
    "text": "with three people inside the car it's coming at our speed that there is no way that they will not like if it cup",
    "start": "2042930",
    "end": "2051108"
  },
  {
    "text": "if it keeps going straight it will kill these three people so it's already calculated that if I keep going straight",
    "start": "2051109",
    "end": "2057138"
  },
  {
    "text": "I will kill these three people there is no way to stop because it does that calculation very quickly and if it turns",
    "start": "2057139",
    "end": "2063849"
  },
  {
    "text": "here it will crash on a wall and it will for sure kill these three people so",
    "start": "2063849",
    "end": "2069050"
  },
  {
    "text": "which decision should that car make should the car kill these three people or should the car kill these three",
    "start": "2069050",
    "end": "2075710"
  },
  {
    "text": "people so we are having decisions that computers are making to who they will",
    "start": "2075710",
    "end": "2081079"
  },
  {
    "text": "kill and there is no ethical code there is no ethical moral or anything around",
    "start": "2081079",
    "end": "2086839"
  },
  {
    "text": "that that tells us what we should be doing or what people writing those algorithms should be doing the world of",
    "start": "2086839",
    "end": "2093500"
  },
  {
    "text": "Economic Forum has released what they call the moral dilemmas of the fourth Industrial Revolution and that is",
    "start": "2093500",
    "end": "2098780"
  },
  {
    "text": "definitely one of them so I want to bring that to our awareness as well it's called ethics 2.0 so if you are working",
    "start": "2098780",
    "end": "2104869"
  },
  {
    "text": "on an application if you are working on anything that has digital decisions think about what are the ethics behind",
    "start": "2104869",
    "end": "2111589"
  },
  {
    "text": "that today I spoke to you about one and a few others of these biases that we",
    "start": "2111589",
    "end": "2118130"
  },
  {
    "text": "have in our brains one of them is called status quo bias which is the tendency we have to stay on the default those are",
    "start": "2118130",
    "end": "2125660"
  },
  {
    "text": "the mapped biases that we have now in behavior economics so just understanding",
    "start": "2125660",
    "end": "2130700"
  },
  {
    "text": "each and every one of those biases that we have in our brains just helps us become more aware of how we behave in",
    "start": "2130700",
    "end": "2136339"
  },
  {
    "text": "how we make decisions and just a quick thing I want to ask you is that a chihuahua or a muffin is this a",
    "start": "2136339",
    "end": "2143839"
  },
  {
    "text": "labradoodle or a fried chicken sheep dog or mop parrot or guacamole it's very",
    "start": "2143839",
    "end": "2152990"
  },
  {
    "text": "hard right it's very hard so that's that's part of an article that actually",
    "start": "2152990",
    "end": "2158450"
  },
  {
    "text": "highlighted that in 2010 algorithms",
    "start": "2158450",
    "end": "2163520"
  },
  {
    "text": "would look at a database of images and they would actually know what the images",
    "start": "2163520",
    "end": "2169130"
  },
  {
    "text": "are with an error rate of almost 30 percent in 2010 recently last year that",
    "start": "2169130",
    "end": "2175640"
  },
  {
    "text": "number has dropped to 4% right and what's 5% humans so last year",
    "start": "2175640",
    "end": "2183650"
  },
  {
    "text": "for the first time we have algorithms detecting images better than humans that's where we are right now we have",
    "start": "2183650",
    "end": "2189860"
  },
  {
    "text": "computers actually better than humans on a lot of things including detecting what's a parrot or guacamole there is a",
    "start": "2189860",
    "end": "2198020"
  },
  {
    "text": "new type of intelligence right now we should question ourselves what is that matters right now there is an",
    "start": "2198020",
    "end": "2203870"
  },
  {
    "text": "intelligence called DQ it's been defined by the DQ Institute if you want to know",
    "start": "2203870",
    "end": "2208940"
  },
  {
    "text": "more go to DQ institute.org it's its claim to dit to be the new IQ and the",
    "start": "2208940",
    "end": "2214010"
  },
  {
    "text": "new EQ it's pretty much the type of intelligence that we need right now in the digital space and it's it's been",
    "start": "2214010",
    "end": "2221030"
  },
  {
    "text": "separated into a few capabilities around privacy critical thinking footprints",
    "start": "2221030",
    "end": "2226190"
  },
  {
    "text": "empathy cyber bullying screen time management cyber security and digital",
    "start": "2226190",
    "end": "2231740"
  },
  {
    "text": "citizenship identity that's the type of skill that we should be learning right now to become better and more aware in",
    "start": "2231740",
    "end": "2237560"
  },
  {
    "text": "the digital world so to take a few of takeaways from you if you are a digital",
    "start": "2237560",
    "end": "2242780"
  },
  {
    "text": "choice architect if you are a UX person or if you know anyone if you work on your team with someone who designs",
    "start": "2242780",
    "end": "2248060"
  },
  {
    "text": "interfaces design them for good if you have behavioral data if you work for a",
    "start": "2248060",
    "end": "2253880"
  },
  {
    "text": "company that actually has a lot of data around how people behave run digital experiments to understand how your users",
    "start": "2253880",
    "end": "2260060"
  },
  {
    "text": "behave and to help us understand how we behave as humans and if you are a digital citizen as I think we all are",
    "start": "2260060",
    "end": "2266530"
  },
  {
    "text": "let's improve our consciousness let's become more aware of how we make these decisions in the digital world there's a",
    "start": "2266530",
    "end": "2274070"
  },
  {
    "text": "number that in 2016 was 144 billion do",
    "start": "2274070",
    "end": "2280160"
  },
  {
    "text": "you know what that number is other than the fact that I forgot to translate it",
    "start": "2280160",
    "end": "2286040"
  },
  {
    "text": "from Portuguese that's the number of steps that Pokemon",
    "start": "2286040",
    "end": "2292559"
  },
  {
    "text": "Go users actually had so 144 billion steps have been taken by Pokemon Go",
    "start": "2292559",
    "end": "2299670"
  },
  {
    "text": "users right so Pokemon go is a game that uses augmented reality it's just an",
    "start": "2299670",
    "end": "2305309"
  },
  {
    "text": "example of how these things are actually taking over the world where we are right now augmented reality virtual reality",
    "start": "2305309",
    "end": "2311880"
  },
  {
    "text": "machine learning autonomous cars all these things are just part of our day-to-day lives and they will just be",
    "start": "2311880",
    "end": "2317640"
  },
  {
    "text": "more and more part of our day-to-day lives and I truly believe that if we understand how our brains work we will",
    "start": "2317640",
    "end": "2323760"
  },
  {
    "text": "create about a digital environment for all of us thank you Duncan",
    "start": "2323760",
    "end": "2329359"
  },
  {
    "text": "[Applause] thanks Fabio they're not a lot of food",
    "start": "2336400",
    "end": "2341940"
  },
  {
    "text": "they're not a lot of questions actually maybe people were just so immersed in the presentation the first one I think",
    "start": "2341940",
    "end": "2347400"
  },
  {
    "text": "is more of a comment something around conceptual manipulation and marriage so I don't think it's a question it",
    "start": "2347400",
    "end": "2353430"
  },
  {
    "text": "actually ends with a good exclamation point and then there's one comment on",
    "start": "2353430",
    "end": "2358500"
  },
  {
    "text": "the autonomously driving cars about the trolley problem so surely when it comes",
    "start": "2358500",
    "end": "2363750"
  },
  {
    "text": "to the trolley problem the ethical in quotes thing to do is for the car to",
    "start": "2363750",
    "end": "2368819"
  },
  {
    "text": "drive defensively so not to not drive at a speed where it cannot safely stop or",
    "start": "2368819",
    "end": "2374339"
  },
  {
    "text": "swerve which is what human drivers are already doing so I'm not sure there's a",
    "start": "2374339",
    "end": "2380220"
  },
  {
    "text": "question in there so that you yeah cool",
    "start": "2380220",
    "end": "2387349"
  },
  {
    "text": "so the person in the audience was saying that he was wondering if they were ever gonna be any non-digital decisions",
    "start": "2394309",
    "end": "2400890"
  },
  {
    "text": "anymore what I believe in and it's always a belief and if you came to the previous talk like you know that it's",
    "start": "2400890",
    "end": "2406859"
  },
  {
    "text": "always like we believe in something there is no such thing as real truth because we don't even know if we are in",
    "start": "2406859",
    "end": "2411869"
  },
  {
    "text": "the lane and if this is reality what I believe is that we will switch our",
    "start": "2411869",
    "end": "2417000"
  },
  {
    "text": "decisions what we do is I think will delegate more and more decisions to digital devices and then we will we will",
    "start": "2417000",
    "end": "2424349"
  },
  {
    "text": "switch we'll start making different decisions than decisions we make right now just like right now we make very",
    "start": "2424349",
    "end": "2429809"
  },
  {
    "text": "different decisions from what we used to make 500 years ago like we in 50 years",
    "start": "2429809",
    "end": "2435000"
  },
  {
    "text": "from now we'll make different decisions but I don't believe that we will ever like become non decision-makers on",
    "start": "2435000",
    "end": "2441690"
  },
  {
    "text": "anything but that's that's a belief and in terms of the what the car should do",
    "start": "2441690",
    "end": "2446910"
  },
  {
    "text": "if feel free to go to moral machines or mit.edu and actually say that because what they're doing is they're",
    "start": "2446910",
    "end": "2452339"
  },
  {
    "text": "crowdsourcing what people believe the car should be doing to actually inform some sort of ethical code that will be",
    "start": "2452339",
    "end": "2457770"
  },
  {
    "text": "decided when those algorithms are written there's actually one of the German ministries had an Ethics",
    "start": "2457770",
    "end": "2464099"
  },
  {
    "text": "Commission put together twenty-eighth occur rules about autonomous driving I think that so",
    "start": "2464099",
    "end": "2469340"
  },
  {
    "text": "one of the first list of those things - the first attempt at that but they left me with a lot of questions but maybe",
    "start": "2469340",
    "end": "2475430"
  },
  {
    "text": "something to look up if you're interested in this yeah that's great thank you I'll actually look up look that up and include it to the book and",
    "start": "2475430",
    "end": "2481880"
  },
  {
    "text": "the presentations and all that thank you anything else yeah that's a wrap then",
    "start": "2481880",
    "end": "2488840"
  },
  {
    "text": "that's a wrap thanks everyone [Applause]",
    "start": "2488840",
    "end": "2499380"
  }
]
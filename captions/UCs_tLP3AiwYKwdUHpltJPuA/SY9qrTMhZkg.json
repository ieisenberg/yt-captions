[
  {
    "start": "0",
    "end": "30000"
  },
  {
    "text": "[Music]",
    "start": "2540",
    "end": "11480"
  },
  {
    "text": "so I'm going to be talking about uh a lot about the Apache msos project kind of start off a little bit with some",
    "start": "11480",
    "end": "17119"
  },
  {
    "text": "containerization thoughts and kind of the microservices um trends that are happening but most of the presentation",
    "start": "17119",
    "end": "22680"
  },
  {
    "text": "is going to be about Apache mesos and then at the end a little bit I'm going to talk about some of the work that we're doing at uh at",
    "start": "22680",
    "end": "28359"
  },
  {
    "text": "mesosphere so um there an emerging Trend that I think we're all seeing that's really kind of",
    "start": "28359",
    "end": "33640"
  },
  {
    "start": "30000",
    "end": "163000"
  },
  {
    "text": "cyclical upon itself and that's a lot of organizations are moving to microservices and a lot of organizations",
    "start": "33640",
    "end": "40120"
  },
  {
    "text": "are adopting ideas behind containerization and um when I say",
    "start": "40120",
    "end": "46680"
  },
  {
    "text": "microservices here you know one of the things that really interesting about microservices is it really gets us back",
    "start": "46680",
    "end": "52520"
  },
  {
    "text": "to building applications with a couple of really really nice properties one is that we can kind of focus our our",
    "start": "52520",
    "end": "58600"
  },
  {
    "text": "applications these services on doing one thing and doing it well which is really the the Unix philosophy um that lets us",
    "start": "58600",
    "end": "64439"
  },
  {
    "text": "compose these things really really nicely it also lets us as an organization build applications uh",
    "start": "64439",
    "end": "70840"
  },
  {
    "text": "commit individual applications code in isolation be able to test the individual pieces in isolation be able to actually",
    "start": "70840",
    "end": "77159"
  },
  {
    "text": "deploy them in isolation roll back individual pieces in isolation um and that really captures a lot of the",
    "start": "77159",
    "end": "82560"
  },
  {
    "text": "organizational structure that a lot of teams have either working in a distributed way or in parallel really well um it doesn't mean that it's a",
    "start": "82560",
    "end": "89479"
  },
  {
    "text": "Freel launch there's still quite a bit of work that you have to do as you start to move to micro organizations uh but a lot of the",
    "start": "89479",
    "end": "95399"
  },
  {
    "text": "benefits outweigh uh the cons and so most organizations are doing it um one of the things I think is pretty",
    "start": "95399",
    "end": "100920"
  },
  {
    "text": "interesting about microservices in particular is that the service oriented architecture um which kind of predated",
    "start": "100920",
    "end": "107159"
  },
  {
    "text": "microservices had a lot of these same ideas this is kind of the as we always see in computer science this the",
    "start": "107159",
    "end": "112680"
  },
  {
    "text": "Regeneration of of of a lot of those ideas so an organization that I was at uh that did the did the big shift to",
    "start": "112680",
    "end": "119920"
  },
  {
    "text": "microservices was Twitter where we used to run the opposite of a microservice and not a service ared architecture a",
    "start": "119920",
    "end": "126439"
  },
  {
    "text": "giant monolithic application that was written in uh Ruby on Rails that we affectionately dubbed the monil and the",
    "start": "126439",
    "end": "133040"
  },
  {
    "text": "monil kind of did everything from the routing presentation logic pretty much everything but storage that was the only",
    "start": "133040",
    "end": "138400"
  },
  {
    "text": "other service that that the monreal was really communicating with and the transition that we did at Twitter was we",
    "start": "138400",
    "end": "143760"
  },
  {
    "text": "went from this giant monolithic rails application to a bunch of microservices that were all communicating amongst one",
    "start": "143760",
    "end": "149440"
  },
  {
    "text": "another a majority of these things were actually written in uh in in Scola Java Su as well and kind of at the same time",
    "start": "149440",
    "end": "158280"
  },
  {
    "text": "what started to to to take shape at a place like Twitter and then now that's happening in the General Industry is",
    "start": "158280",
    "end": "163760"
  },
  {
    "start": "163000",
    "end": "252000"
  },
  {
    "text": "people started transitioning less and less from the way that they configure and manage their individual machines is",
    "start": "163760",
    "end": "169720"
  },
  {
    "text": "with things like RPM or when you go to launch your application using something like git to actually pull your repo and",
    "start": "169720",
    "end": "174840"
  },
  {
    "text": "build it and they're moving more and more to uh uh to things that have less moving parts so just entire jars the jar",
    "start": "174840",
    "end": "182000"
  },
  {
    "text": "is your entire your entire bundle that that you deploy or tarball the tarball is everything you need all your",
    "start": "182000",
    "end": "187280"
  },
  {
    "text": "dependencies a static binary that's my little static binary GIF um or um or",
    "start": "187280",
    "end": "193840"
  },
  {
    "text": "using things like Docker and I think what's really interesting here is you know in the days of using things like",
    "start": "193840",
    "end": "199840"
  },
  {
    "text": "RPM and git for doing a lot of our configuration package management deployment um there were a lot more",
    "start": "199840",
    "end": "205000"
  },
  {
    "text": "moving parts so when things failed they were hard to debug and they failed more often because there's just just more",
    "start": "205000",
    "end": "210360"
  },
  {
    "text": "more moving parts and this movement in this containerization realm is really about less moving Parts uh When there's",
    "start": "210360",
    "end": "216840"
  },
  {
    "text": "less moving parts here's more uh deterministic guarantees I think one of",
    "start": "216840",
    "end": "221959"
  },
  {
    "text": "the things that's pretty interesting here is the static binary uh uh approach is one that doesn't get a lot of love",
    "start": "221959",
    "end": "228280"
  },
  {
    "text": "but for those of you that are writing and go um obviously you get static binaries out of the box uh and that's",
    "start": "228280",
    "end": "233879"
  },
  {
    "text": "because at Google um with the way that they were actually deploying their applications they weren't using RPM they",
    "start": "233879",
    "end": "239120"
  },
  {
    "text": "weren't using G they weren't using Docker they were using static binaries and so they were actually when go first",
    "start": "239120",
    "end": "244400"
  },
  {
    "text": "created they said well let's just make sure that we can build static binaries but by default okay so um the interesting thing",
    "start": "244400",
    "end": "251519"
  },
  {
    "text": "about sort of microservices containerization is that they're creating this reinforcing trend on more organizations not just using",
    "start": "251519",
    "end": "257840"
  },
  {
    "start": "252000",
    "end": "364000"
  },
  {
    "text": "microservices and containerization but also starting to do cluster management um so cluster Management in",
    "start": "257840",
    "end": "265680"
  },
  {
    "text": "quotes at Twitter in 2010 uh really consisted of uh using Technologies like",
    "start": "265680",
    "end": "272000"
  },
  {
    "text": "puppet for doing the configuration and package management and tools like Capistrano for doing our deployment um",
    "start": "272000",
    "end": "277919"
  },
  {
    "text": "we actually built a tool on top of Capistrano that we called Murder uh referring to a murder a murder of crows",
    "start": "277919",
    "end": "284240"
  },
  {
    "text": "um and uh it was to actually get Capistrano to scale to the number of of of machines that we were actually using",
    "start": "284240",
    "end": "290720"
  },
  {
    "text": "so there's one really really missing important part in cluster management here and that's why I put the words cluster management and it was people uh",
    "start": "290720",
    "end": "298479"
  },
  {
    "text": "people were the ones that were actually writing a lot of the scripts to to to run puppet doing a lot of the operations",
    "start": "298479",
    "end": "303720"
  },
  {
    "text": "very very manually and it wasn't just a few people it was a lot of people there were a lot of people that were were",
    "start": "303720",
    "end": "309280"
  },
  {
    "text": "doing cluster Management in the early days at Twitter so why did we have to have so many people basically at at",
    "start": "309280",
    "end": "316039"
  },
  {
    "text": "Twitter what what what we look like is we'd take all our machines and we'd effectively go and we'd statically partition the machines humans would go",
    "start": "316039",
    "end": "321800"
  },
  {
    "text": "and they'd statically partition and manage the clusters by saying okay let's take this collection of machines and",
    "start": "321800",
    "end": "327919"
  },
  {
    "text": "let's go ahead and run MySQL on them let's take some other collection of machines let's go ahead and run",
    "start": "327919",
    "end": "333960"
  },
  {
    "text": "mcash let's take yet another section of machines we'll go ahead and run run rails there um you know finally",
    "start": "333960",
    "end": "341400"
  },
  {
    "text": "Cassandra and hendo right so this is this is the standard thing that that we were doing is we were going we're statically partitioning collecting our",
    "start": "341400",
    "end": "347160"
  },
  {
    "text": "machines and saying okay these are the machines that are just going to be used for running these applications and this is where as an",
    "start": "347160",
    "end": "353199"
  },
  {
    "text": "organization at Twitter we started to run into a bunch of challenges and why cluster management really evolved at Twitter so the first one one was just",
    "start": "353199",
    "end": "360759"
  },
  {
    "text": "dealing with failures um so this is a this is actually a a real email from",
    "start": "360759",
    "end": "367479"
  },
  {
    "start": "364000",
    "end": "414000"
  },
  {
    "text": "2010 um where somebody had to reboot a machine in one of the data centers and they ask a very natural question which",
    "start": "367479",
    "end": "374280"
  },
  {
    "text": "is hey were there any Production Services running on this machine so this is a this is humans doing cluster",
    "start": "374280",
    "end": "379639"
  },
  {
    "text": "management dealing with failures and another humans actually figuring out how to how to get the services back up and running okay um so you know what does",
    "start": "379639",
    "end": "386960"
  },
  {
    "text": "that look like in the data center well machines fail for all sorts of reasons all the time uh and uh humans had to",
    "start": "386960",
    "end": "393800"
  },
  {
    "text": "actually actually account for that the next big challenge that that uh um we as",
    "start": "393800",
    "end": "399120"
  },
  {
    "text": "an organization at Twitter really had to deal with was maintenance uh and maintenance I really like to call Planned failures uh because effectively",
    "start": "399120",
    "end": "406440"
  },
  {
    "text": "you're inducing a failure in the system you just know exactly when that failure is going to occur and so you can plan for",
    "start": "406440",
    "end": "411960"
  },
  {
    "text": "it um there's a lot of Maintenance that actually happens in our data centers not just in a a a private on-prem data",
    "start": "411960",
    "end": "419120"
  },
  {
    "start": "414000",
    "end": "553000"
  },
  {
    "text": "centers but also in the cloud one of the biggest ones is actually upgrading the kernel we all at some point need to upgrade the kernel which means we're",
    "start": "419120",
    "end": "425080"
  },
  {
    "text": "going to be shutting down our machines bringing up other machines or bringing that machine back up with an upgraded",
    "start": "425080",
    "end": "430160"
  },
  {
    "text": "kernel but of course there's replacing machines there's replacing switches pdus",
    "start": "430160",
    "end": "435479"
  },
  {
    "text": "uh moving regions if you're in the public Cloud there's lots of different maintenance like events that you might be doing um that cause can cause a lot",
    "start": "435479",
    "end": "443039"
  },
  {
    "text": "of humans to be running around communicating with one another to try to figure out how they can actually do this so at an organization like Twitter um",
    "start": "443039",
    "end": "450160"
  },
  {
    "text": "folks unfortunately had the experience where they did maintenance on say the",
    "start": "450160",
    "end": "456400"
  },
  {
    "text": "racks the topper rack switches that were on the Far Far Side of this diagram bringing down all the M caches and of",
    "start": "456400",
    "end": "463080"
  },
  {
    "text": "course that means that uh nobody's tweeting okay um the last challenge that",
    "start": "463080",
    "end": "468919"
  },
  {
    "text": "I want to address is really utilization so for some organizations this is not nearly as important one but for a bunch",
    "start": "468919",
    "end": "475400"
  },
  {
    "text": "of organizations especially as they start to scale to more and more machines it becomes ever more uh uh",
    "start": "475400",
    "end": "481039"
  },
  {
    "text": "important so me just grab some more",
    "start": "481039",
    "end": "486919"
  },
  {
    "text": "water okay from the utilization perspective when applications are",
    "start": "486960",
    "end": "493000"
  },
  {
    "text": "running they have different uh requirements for the needs uh the computational resources that they need",
    "start": "493000",
    "end": "499000"
  },
  {
    "text": "over the course of them actually running their applications so um when we kind of do the static partitioning and we divide",
    "start": "499000",
    "end": "504879"
  },
  {
    "text": "the resources up amongst the different uh uh types of systems that we're trying to run",
    "start": "504879",
    "end": "509960"
  },
  {
    "text": "we end up getting a situation like this so here I've just divided 100% up into to to a third each so mcash gets a third",
    "start": "509960",
    "end": "516240"
  },
  {
    "text": "Hadoop gets a third and rails gets a third and this is now you know rails using um you know during during certain",
    "start": "516240",
    "end": "521959"
  },
  {
    "text": "parts of the day when not as many people are tweeting there's all those there free resources that potentially be used for some other application like say",
    "start": "521959",
    "end": "527640"
  },
  {
    "text": "Hadoop uh and mcash kind of follows a similar cycle to to something like rails",
    "start": "527640",
    "end": "532680"
  },
  {
    "text": "so really what we'd like to do and what humans end up doing is they end up going and say okay well how can we optimize the number of resources that we should",
    "start": "532680",
    "end": "538680"
  },
  {
    "text": "be allocating these applications over either different periods of the day or or different times so we could get to",
    "start": "538680",
    "end": "544160"
  },
  {
    "text": "something like this so Hadoop could say scale up and use those resources which ultimately means that we could buy less",
    "start": "544160",
    "end": "549560"
  },
  {
    "text": "machines or or or run more applications so I think what's really interesting about these challenges is",
    "start": "549560",
    "end": "554760"
  },
  {
    "start": "553000",
    "end": "568000"
  },
  {
    "text": "less that they exist and more that um to deal with these things uh humans end up",
    "start": "554760",
    "end": "559959"
  },
  {
    "text": "actually playing a big part of the process so humans come in and they start having to plan for failure you know how do we want to actually run our",
    "start": "559959",
    "end": "565320"
  },
  {
    "text": "application so we can plan for failure and here's another email uh internal email from Twitter where I've scrubbed again some names um and the important",
    "start": "565320",
    "end": "572440"
  },
  {
    "start": "568000",
    "end": "691000"
  },
  {
    "text": "part is really at the bottom where it says you know someone is saying hey preferably this thing I'm trying to run is on different rack switches and power",
    "start": "572440",
    "end": "577519"
  },
  {
    "text": "feeds that they are fully redundant right so this is humans basically effectively doing scheduling of applications to try to figure out how to",
    "start": "577519",
    "end": "583360"
  },
  {
    "text": "deal with and plan for for for failure for the challenges they have in um running stuff and utilization is even",
    "start": "583360",
    "end": "589480"
  },
  {
    "text": "harder because it's one thing to think about how we can share machines between different poll machines between",
    "start": "589480",
    "end": "595640"
  },
  {
    "text": "different applications um it's another thing to think about how we can actually share a couple of of resources on an",
    "start": "595640",
    "end": "601800"
  },
  {
    "text": "individual machine so an individual machine can be truly multi-tenant be running applications uh from from from",
    "start": "601800",
    "end": "607839"
  },
  {
    "text": "multiple applications on the same machine at the same time so in about 2010 um at Twitter we",
    "start": "607839",
    "end": "614640"
  },
  {
    "text": "looked into actually getting a cluster manager not having cluster management being done by humans but actually having",
    "start": "614640",
    "end": "620320"
  },
  {
    "text": "soft software cluster manager so cluster management um to me there's really two",
    "start": "620320",
    "end": "626240"
  },
  {
    "text": "things that really uh uh uh identify what cluster cluster management is all about and the first one is it's when you",
    "start": "626240",
    "end": "632160"
  },
  {
    "text": "do cluster management via software you start to stop treating your machines as c as pets but you just treat them as",
    "start": "632160",
    "end": "637839"
  },
  {
    "text": "cattle they're arbitrary machines you put a base a small and simple base operating system on all of them and",
    "start": "637839",
    "end": "643560"
  },
  {
    "text": "ultimately you end up running these containerized applications where containerized application might be a full-blown Docker image or it might just",
    "start": "643560",
    "end": "649680"
  },
  {
    "text": "be a tar ball or a jar that has everything that you actually need okay and the second really most important",
    "start": "649680",
    "end": "655040"
  },
  {
    "text": "thing is that you start to automate uh everything you do in the in the the data center with software and",
    "start": "655040",
    "end": "660399"
  },
  {
    "text": "not humans so you deal with uh you let software schedule other software you",
    "start": "660399",
    "end": "665600"
  },
  {
    "text": "deal you handle failures improve utilization management it's all that stuff you do it you do it with um with software one of the things that I think",
    "start": "665600",
    "end": "672160"
  },
  {
    "text": "is really interesting about cluster management is that it's not an old sorry it's not a new topic at all it's a very old topic um there's been a lot of",
    "start": "672160",
    "end": "679079"
  },
  {
    "text": "cluster managers that existed uh some of the ones some have still been been used since the early 1990s things like U Moab",
    "start": "679079",
    "end": "686360"
  },
  {
    "text": "uh torque um uh PBS port batch scheduling system uh one of the reasons",
    "start": "686360",
    "end": "691680"
  },
  {
    "start": "691000",
    "end": "850000"
  },
  {
    "text": "for that was that in Academia uh the kind of applications that were being built and run in Academia were things like message passing interface um where",
    "start": "691680",
    "end": "699120"
  },
  {
    "text": "they wanted to run that on a large number of machines whereas the kind of applications we were running in Industry tended to be some web servers maybe some",
    "start": "699120",
    "end": "705160"
  },
  {
    "text": "other one-off servers and in Academia they already had hundreds of machines that they were able",
    "start": "705160",
    "end": "710240"
  },
  {
    "text": "to work with to actually run these things and in Industry we're kind of working with t tens of machines and",
    "start": "710240",
    "end": "715959"
  },
  {
    "text": "ultimately this led to a bunch of cluster management like Technologies being built in sort of the academic and the lab space around the world um and in",
    "start": "715959",
    "end": "724480"
  },
  {
    "text": "Industry we kind of used SSH or other tools that we developed um which help solve the problems like puppet Chef uh",
    "start": "724480",
    "end": "731079"
  },
  {
    "text": "Capistrano and anible but these days what I think is interesting is that we're all converging",
    "start": "731079",
    "end": "736279"
  },
  {
    "text": "more and more both between Academia and Industry on running similar numbers of machines we're all running more and more",
    "start": "736279",
    "end": "741959"
  },
  {
    "text": "and more machines and in general even if we're not running as many machines in in Industry as some government Labs or",
    "start": "741959",
    "end": "747480"
  },
  {
    "text": "super supercomputers are running we're running enough machines that it's enough of a pain in the butt to actually manage them",
    "start": "747480",
    "end": "753440"
  },
  {
    "text": "ourselves now one of the things that that's especially interesting about cluster management as it was done",
    "start": "753440",
    "end": "759720"
  },
  {
    "text": "in excuse me in Academia was that uh uh the Clusters managers they were really",
    "start": "759720",
    "end": "765560"
  },
  {
    "text": "focused on batch computation so they were really meant to to make it easier to run batch computations so what what",
    "start": "765560",
    "end": "773000"
  },
  {
    "text": "what we did at at at Twitter was we ended up building out a new a new cluster manager called Apache MOS which",
    "start": "773000",
    "end": "779199"
  },
  {
    "text": "is really a modern general purpose cluster manager that's not just focused on batch computation but it's actually",
    "start": "779199",
    "end": "784480"
  },
  {
    "text": "focused on running any kinds of distributed systems or applications containerized workloads whatever it is that you want to run um so what I mean",
    "start": "784480",
    "end": "791760"
  },
  {
    "text": "by that is I mean that MOS was designed to run these kinds of distributed systems as native applications on top of",
    "start": "791760",
    "end": "798240"
  },
  {
    "text": "mos now I'm not going to spend too much time in the in the presentation at least not right now right now talking about",
    "start": "798240",
    "end": "804160"
  },
  {
    "text": "what it takes to to run something like these systems on msos but I am going to spend a little bit of time talking about",
    "start": "804160",
    "end": "809880"
  },
  {
    "text": "specifically the kind of system that we built on top of msos to run uh uh the",
    "start": "809880",
    "end": "815480"
  },
  {
    "text": "Twitter application which is all these uh uh different microservices okay so sure right so so",
    "start": "815480",
    "end": "822600"
  },
  {
    "text": "what was particularly interesting about the the the Twitter application is if you kind of looked at this picture again",
    "start": "822600",
    "end": "828320"
  },
  {
    "text": "there was a bunch of things that we wanted to run which were these stateless services that kind of sat in between the",
    "start": "828320",
    "end": "835639"
  },
  {
    "text": "stateful stuff the storage applications and kind of some of the very very front end stuff stuff and there were tons of",
    "start": "835639",
    "end": "840759"
  },
  {
    "text": "them and they was growing every day because new new uh developers in the organization were building a new microservice all the time okay so we",
    "start": "840759",
    "end": "848519"
  },
  {
    "text": "introduced msos so what is msos kind of from 100,000 ft so uh msos is a cluster",
    "start": "848519",
    "end": "853920"
  },
  {
    "start": "850000",
    "end": "880000"
  },
  {
    "text": "manager um it's got a Master Slave architecture so the idea is that there's a some collection of Masters that run",
    "start": "853920",
    "end": "860639"
  },
  {
    "text": "and they manage all of the uh they manage all the machines in the Data Center and they run an agent process on",
    "start": "860639",
    "end": "866120"
  },
  {
    "text": "on each of the individual machines okay now a really really important part of mos that distinguishes it from other",
    "start": "866120",
    "end": "872959"
  },
  {
    "text": "cluster managers um uh especially those of the past is this idea that MOS has",
    "start": "872959",
    "end": "879680"
  },
  {
    "text": "this notion of things called schedulers that connect to the Masters",
    "start": "879680",
    "end": "884920"
  },
  {
    "start": "880000",
    "end": "916000"
  },
  {
    "text": "they register with the Masters and they're the things that are responsible for actually uh running the jobs and the",
    "start": "884920",
    "end": "891120"
  },
  {
    "text": "tasks in the data center okay and I've got a couple of other slides later that talks a little bit about about about how",
    "start": "891120",
    "end": "896680"
  },
  {
    "text": "this works okay so these sched though is a really really critical point that really really differentiates it as an",
    "start": "896680",
    "end": "902480"
  },
  {
    "text": "architectural uh uh technology from some of the other ones okay so again we're getting back to these stateless services",
    "start": "902480",
    "end": "908920"
  },
  {
    "text": "so what we did in in um at Twitter was we built a very specific scheduler that",
    "start": "908920",
    "end": "914399"
  },
  {
    "text": "we run on top of msos um a service scheduler so a service scheduler uh that",
    "start": "914399",
    "end": "919720"
  },
  {
    "start": "916000",
    "end": "1006000"
  },
  {
    "text": "we built was really responsible for being able to orchestrate all these microservices that people were trying to run in the data center okay so um I'm",
    "start": "919720",
    "end": "927920"
  },
  {
    "text": "going to differentiate here out what I mean between orchestration and scheduling so um when you build",
    "start": "927920",
    "end": "934279"
  },
  {
    "text": "something like a schuer on top of mos there's a programmatic API that that piece of software uses to actually",
    "start": "934279",
    "end": "940560"
  },
  {
    "text": "communicate with mos in order to run its applications in order to run its tasks so service scheduler is some software",
    "start": "940560",
    "end": "946959"
  },
  {
    "text": "which communicates with other software msos in order to actually run its applications above that the service",
    "start": "946959",
    "end": "953120"
  },
  {
    "text": "scheduler exposes a higher level API that either a human consumes or uh some",
    "start": "953120",
    "end": "959000"
  },
  {
    "text": "continuous integration job consumes and that's where somebody would say write a a specification about the kinds of jobs",
    "start": "959000",
    "end": "965839"
  },
  {
    "text": "they want to run and then submit that effectively say to the service schedule here orchestrate this job for me and",
    "start": "965839",
    "end": "972000"
  },
  {
    "text": "then it uses msos to actually schedule those jobs okay so um one of the",
    "start": "972000",
    "end": "978440"
  },
  {
    "text": "orchestrators that I want to talk about first is um uh one one that we build at at at mesosphere uh called called",
    "start": "978440",
    "end": "985160"
  },
  {
    "text": "Marathon so these kind of these kind of service schedulers that they've got a couple of roles that they have to focus",
    "start": "985160",
    "end": "990399"
  },
  {
    "text": "on but the two that I'm going to I'm going to explicitly call out here is really you know how you're going to do your configuration and package",
    "start": "990399",
    "end": "996319"
  },
  {
    "text": "management to actually run your application and um and then you know what actually what does deployment",
    "start": "996319",
    "end": "1001880"
  },
  {
    "text": "actually look like so if you use something like marathon on on msos as a developer what you do is you go build",
    "start": "1001880",
    "end": "1008079"
  },
  {
    "start": "1006000",
    "end": "1175000"
  },
  {
    "text": "your application and then you containerize it so again you either containerize it by sticking it in a tar",
    "start": "1008079",
    "end": "1013440"
  },
  {
    "text": "ball um or using something like a like like Docker to actually uh uh create an image a docker image that you can then",
    "start": "1013440",
    "end": "1019839"
  },
  {
    "text": "then run later okay after you do that then you have to put the bits that you want to run someplace so um you take",
    "start": "1019839",
    "end": "1026720"
  },
  {
    "text": "either your tall bar or your Docker image uh if you're on something like AWS you can throw it in S3 um if you've got",
    "start": "1026720",
    "end": "1032720"
  },
  {
    "text": "something like htfs running or some other distributed file system you can throw it in the distributed file system",
    "start": "1032720",
    "end": "1038280"
  },
  {
    "text": "um and then uh uh or if you're using Docker of course you can you can use the registry okay so that's that's kind of",
    "start": "1038280",
    "end": "1044160"
  },
  {
    "text": "the first step you do configuration package management um when you're trying to run services so the second step step",
    "start": "1044160",
    "end": "1049360"
  },
  {
    "text": "is then is then deployment and what this looks like is that again the developer goes and they describe this application",
    "start": "1049360",
    "end": "1056440"
  },
  {
    "text": "that they're trying to run uh when in Marathon using a Json specification you",
    "start": "1056440",
    "end": "1061679"
  },
  {
    "text": "write out that Json specification uh and then you submit that J Json specification to Marathon which Marathon",
    "start": "1061679",
    "end": "1068799"
  },
  {
    "text": "then uses to orchestrate the actual uh running of of your application by communicating uh uh uh and scheduling",
    "start": "1068799",
    "end": "1075480"
  },
  {
    "text": "jobs directly with msos so in Marathon case there's a there's a rest some rest endpoints you",
    "start": "1075480",
    "end": "1081799"
  },
  {
    "text": "can use there's also a CLI okay and this is just kind of a quick example of what uh an example a a a running a Docker",
    "start": "1081799",
    "end": "1089480"
  },
  {
    "text": "container uh via Marathon looks like here's the Json uh spec and um uh it's",
    "start": "1089480",
    "end": "1096200"
  },
  {
    "text": "PR pretty simple you effectively are describing the container um if there are particular volumes local volumes you'd",
    "start": "1096200",
    "end": "1101559"
  },
  {
    "text": "want to get mounted in um you know resources you're consuming and then finally at the bottom uh uh the actual",
    "start": "1101559",
    "end": "1107480"
  },
  {
    "text": "command that that you're going to run okay so one of the things that's really interesting about what we're doing at",
    "start": "1107480",
    "end": "1113000"
  },
  {
    "text": "mesosphere and the way that the msos was actually built is that um there are",
    "start": "1113000",
    "end": "1118120"
  },
  {
    "text": "different ways in which you might want to orchestrate your containers and that's a great thing so in the same way",
    "start": "1118120",
    "end": "1124000"
  },
  {
    "text": "that you can use something like Marathon uh to run um to to run run your containers um on on on top of mesos you",
    "start": "1124000",
    "end": "1130400"
  },
  {
    "text": "could also use kubernetes so I know the kubernetes talk was just before me so uh so so that's great so in that case the",
    "start": "1130400",
    "end": "1136880"
  },
  {
    "text": "way it works again the two things that it's a developer have to think about is how you're going to do your configuration and package management and then what's your deployment look like um",
    "start": "1136880",
    "end": "1143799"
  },
  {
    "text": "the biggest difference here is that uh for configuration package management um you are just creating Docker images or",
    "start": "1143799",
    "end": "1150600"
  },
  {
    "text": "soon uh uh uh appy specs um uh and then you're you're writing you're writing",
    "start": "1150600",
    "end": "1156520"
  },
  {
    "text": "your deployment script also in this case in Json and then submitting that to kubernetes and then kubernetes is",
    "start": "1156520",
    "end": "1161640"
  },
  {
    "text": "communicating directly with msos again to schedule those uh those those tasks throughout the uh throughout your data",
    "start": "1161640",
    "end": "1167480"
  },
  {
    "text": "center okay um so one of the things that's really interesting about msos and the way that",
    "start": "1167480",
    "end": "1173600"
  },
  {
    "text": "mesos is actually built is this idea that you could actually run multiple of these schedulers at the same time so",
    "start": "1173600",
    "end": "1179280"
  },
  {
    "start": "1175000",
    "end": "1357000"
  },
  {
    "text": "across the same data center you could both be running marathon and you could be running kubernetes so why on Earth would you possibly want to be doing",
    "start": "1179280",
    "end": "1185280"
  },
  {
    "text": "something like this uh so um there's a bunch of reasons why why why you might want to do it um the people that we know",
    "start": "1185280",
    "end": "1191960"
  },
  {
    "text": "that are doing it is because they've got some part of the organization that has decided they're going to be building some things using one one specification",
    "start": "1191960",
    "end": "1198320"
  },
  {
    "text": "language and another part of the organization that's going to be using a different specification language um from our perspective we kind of see it like",
    "start": "1198320",
    "end": "1204200"
  },
  {
    "text": "uh browsers there's Chrome and there's Firefox and there's Internet Explorer I",
    "start": "1204200",
    "end": "1210440"
  },
  {
    "text": "think and um uh uh if if if you guys want to use any different kinds of of um",
    "start": "1210440",
    "end": "1217480"
  },
  {
    "text": "um these orchestration layers on top that's great for us so uh one of the specific reasons though why a lot of",
    "start": "1217480",
    "end": "1223559"
  },
  {
    "text": "people end up using something uh like like mes here is to actually is when you",
    "start": "1223559",
    "end": "1228919"
  },
  {
    "text": "actually um want to run multiple of the same instances of um of a particular uh",
    "start": "1228919",
    "end": "1235240"
  },
  {
    "text": "uh scheduler on top so there's a bunch of reasons why organizations do this as well um in in that place mesos ends up",
    "start": "1235240",
    "end": "1241960"
  },
  {
    "text": "kind of becoming like a private Cloud for your data center uh either because people want very very hard guarantees to",
    "start": "1241960",
    "end": "1248400"
  },
  {
    "text": "different organizations for the individual um uh service schedules that they're providing on top the other one",
    "start": "1248400",
    "end": "1254919"
  },
  {
    "text": "that we've seen people do though as well is just because they want to run multiple versions of it so uh they'll start running one version",
    "start": "1254919",
    "end": "1260960"
  },
  {
    "text": "of of of of the system and then they'll start running the newer version of the system and once that one's hardened then they can just start moving everything",
    "start": "1260960",
    "end": "1266679"
  },
  {
    "text": "over to the newer version and this way you didn't have to go and spin up a whole new cluster to try to run the new version you could just use whatever were",
    "start": "1266679",
    "end": "1272279"
  },
  {
    "text": "available resources in in in the existing a cluster that you'd already brought up so um from uh uh from the the M",
    "start": "1272279",
    "end": "1282960"
  },
  {
    "text": "perspective um the thing that we see more and more often though is less people running multiple schedules this",
    "start": "1282960",
    "end": "1288159"
  },
  {
    "text": "way and more people running multiple schedules this way where the kinds of applications that they're building on top uh and running on top are things",
    "start": "1288159",
    "end": "1293880"
  },
  {
    "text": "like say analytics stateful services and so now I'm going to go even deeper into",
    "start": "1293880",
    "end": "1299440"
  },
  {
    "text": "the presentation and into how MOS Works to describe how this stuff all how this stuff all fits together okay so we're",
    "start": "1299440",
    "end": "1306480"
  },
  {
    "text": "going deeper so I've got a couple slides where we go deeper and at some point we get pretty deep into how MOS actually",
    "start": "1306480",
    "end": "1311799"
  },
  {
    "text": "works um and so I hope I don't lose everybody but I think it's really interesting stuff uh when it comes to the actual architecture of the system",
    "start": "1311799",
    "end": "1318760"
  },
  {
    "text": "okay so going deeper multiple schedulers so uh in order to actually make this",
    "start": "1318760",
    "end": "1323799"
  },
  {
    "text": "work in MOS MOS has built around a concept called two-level scheduling so",
    "start": "1323799",
    "end": "1329120"
  },
  {
    "text": "uh MOS itself is really influenced by the multi-level scheduling ideas that existed in traditional host operating",
    "start": "1329120",
    "end": "1335320"
  },
  {
    "text": "systems uh for things like user user level scheduling and schedular activations and in that way MOS was",
    "start": "1335320",
    "end": "1342400"
  },
  {
    "text": "really designed less like a cluster manager and actually more like an operating system kernel and and that's",
    "start": "1342400",
    "end": "1348840"
  },
  {
    "text": "actually why we call msos a distributed systems kernel uh or or really a data",
    "start": "1348840",
    "end": "1354240"
  },
  {
    "text": "center kernel so what do I mean by that well as a data center kernel these schedulers when they actually want to",
    "start": "1354240",
    "end": "1360559"
  },
  {
    "start": "1357000",
    "end": "1429000"
  },
  {
    "text": "run their applications they use the CIS call like API programmatically to actually launch their applications to",
    "start": "1360559",
    "end": "1367120"
  },
  {
    "text": "actually run run whatever it is they're trying to run in the uh data center so",
    "start": "1367120",
    "end": "1372159"
  },
  {
    "text": "what's interesting about putting this level of indirection in between the schedulers and and all the resources in in the data center is first well it",
    "start": "1372159",
    "end": "1379279"
  },
  {
    "text": "makes it easy for us to actually run multiple distributed systems at the same time right and if you again if you think",
    "start": "1379279",
    "end": "1385120"
  },
  {
    "text": "back to some of the challenges that we wanted to overcome with software it's that software can schedule other software software can manage software we",
    "start": "1385120",
    "end": "1391279"
  },
  {
    "text": "can actually drive up the the the resource utilization in in our cluster and one of the ways in which we can do that is by having this level of",
    "start": "1391279",
    "end": "1397039"
  },
  {
    "text": "indirection which is Mas Us in the DAT in the data center to be able to run multiple distributed systems at the same",
    "start": "1397039",
    "end": "1402760"
  },
  {
    "text": "time and do it dynamically okay so the other thing though that we really get by",
    "start": "1402760",
    "end": "1408559"
  },
  {
    "text": "sticking this level of indirection msos uh in between the the the schedulers and",
    "start": "1408559",
    "end": "1414559"
  },
  {
    "text": "the um the machines themselves is that mesos can now start to provide common",
    "start": "1414559",
    "end": "1420080"
  },
  {
    "text": "functionality uh Primitives that for the most part every new distributed system that gets built ends up reimplementing",
    "start": "1420080",
    "end": "1427120"
  },
  {
    "text": "right and and by primi is one of the things I'm talking about so exposing up Concepts like principles users and roles",
    "start": "1427120",
    "end": "1433600"
  },
  {
    "start": "1429000",
    "end": "1766000"
  },
  {
    "text": "exposing up uh uh Advanced first level um scheduling and and and Fair sharing",
    "start": "1433600",
    "end": "1439559"
  },
  {
    "text": "algorithms um enabling things like high availability to be done more easily for the distributed systems that are running",
    "start": "1439559",
    "end": "1445039"
  },
  {
    "text": "on top uh doing things like resource monitoring uh introducing Concepts like preemption and revocation um volume",
    "start": "1445039",
    "end": "1452200"
  },
  {
    "text": "management reservations there's a whole bunch of Primitives that we can actually provide the simplest ones honestly are",
    "start": "1452200",
    "end": "1457480"
  },
  {
    "text": "just run this task somewhere in the data center you take care of getting this task from here to there and launching it",
    "start": "1457480",
    "end": "1463360"
  },
  {
    "text": "and when it fails telling me when that thing is actually launched excuse me has actually failed okay okay so one of the",
    "start": "1463360",
    "end": "1469679"
  },
  {
    "text": "really interesting things when we were first building msos was we were recognizing that you know pretty much everybody when they build a new",
    "start": "1469679",
    "end": "1474880"
  },
  {
    "text": "distributed system they all end up Reinventing the wheel and we really wanted to provide for from from the meso",
    "start": "1474880",
    "end": "1480640"
  },
  {
    "text": "substraction layer a way to make it so people didn't have to reinvent the wheel but they could build their new distributed systems directly on",
    "start": "1480640",
    "end": "1487080"
  },
  {
    "text": "top okay um and I just I love this picture I I just love the idea of actually trying to use a bicycle like",
    "start": "1487080",
    "end": "1493279"
  },
  {
    "text": "that okay so um uh the the the other thing that that's really interesting about actually building your distributed systems on top of msos is that um it",
    "start": "1493279",
    "end": "1501080"
  },
  {
    "text": "makes it it can make it much easier for people to actually use your your software um so what do I mean by this",
    "start": "1501080",
    "end": "1507320"
  },
  {
    "text": "well uh we're probably all familiar with stuff like this we go and we try to use some distributed system that's been",
    "start": "1507320",
    "end": "1513000"
  },
  {
    "text": "built by some organization and it's so complicated to use and so complicated to set up and the software can't do a lot",
    "start": "1513000",
    "end": "1518880"
  },
  {
    "text": "of its stuff itself because we got to set it up on each machine if one machine goes down we got to come in and deal with the next pieces that we end up",
    "start": "1518880",
    "end": "1525520"
  },
  {
    "text": "getting a whole industry of of of books about how to actually run run run run",
    "start": "1525520",
    "end": "1530559"
  },
  {
    "text": "the software so um um if you can actually leverage an API and you can",
    "start": "1530559",
    "end": "1535679"
  },
  {
    "text": "actually build the software directly on top we can make it easier for people to actually run your applications in the exact same way that it's pretty easy",
    "start": "1535679",
    "end": "1542480"
  },
  {
    "text": "these days to actually download an application uh on our on our desktop machines and and uh and just run it okay",
    "start": "1542480",
    "end": "1549520"
  },
  {
    "text": "so there's been a there's been a uh uh quite a few of these kinds of distributed systems that have been built directly on top of msos uh spark um is a",
    "start": "1549520",
    "end": "1558720"
  },
  {
    "text": "big data analytics framework Apache Aurora was actually the the orchestration service scheder that we",
    "start": "1558720",
    "end": "1565279"
  },
  {
    "text": "built at Twitter um that we open sourced a couple years ago marathon's the one I mentioned uh Kronos is uh a distributed",
    "start": "1565279",
    "end": "1572399"
  },
  {
    "text": "cron with dependencies like scheduler so it's uh very similar to Kon on a single machine except Kon across your entire",
    "start": "1572399",
    "end": "1578720"
  },
  {
    "text": "Data Center and then there's also been a whole bunch of these Frameworks that have been ported on top of mos um so uh",
    "start": "1578720",
    "end": "1585360"
  },
  {
    "text": "things like Hadoop uh storm Jenkins and uh we're actively working on um making a",
    "start": "1585360",
    "end": "1590440"
  },
  {
    "text": "cassan report uh uh work work really well and then of course uh mesus is actually being used at a bunch of these",
    "start": "1590440",
    "end": "1596120"
  },
  {
    "text": "organizations that are using a handful of these these these different distributed systems on top um obviously",
    "start": "1596120",
    "end": "1601840"
  },
  {
    "text": "I was chatting about about uh uh Twitter um there's been other organizations as well the one that I'll call out more",
    "start": "1601840",
    "end": "1606919"
  },
  {
    "text": "recently is Apple uh Apple actually recently announced that they've been using msos to run all of Siri on top and",
    "start": "1606919",
    "end": "1613000"
  },
  {
    "text": "they actually built a brand new distributed system on top of msos to manage exactly how how they want to run",
    "start": "1613000",
    "end": "1618720"
  },
  {
    "text": "run Siri internally okay going even",
    "start": "1618720",
    "end": "1624200"
  },
  {
    "text": "deeper okay I'll get some more",
    "start": "1624200",
    "end": "1630440"
  },
  {
    "text": "water okay so going even deeper so the way mesos actually works onto the hood",
    "start": "1630440",
    "end": "1635480"
  },
  {
    "text": "so uh uh in in in MOS if you're actually building one of these distributed systems on top um uh the the actual uh",
    "start": "1635480",
    "end": "1643000"
  },
  {
    "text": "the API um the the API that most people end up using is what's called a request offer API and so that the way it works",
    "start": "1643000",
    "end": "1650000"
  },
  {
    "text": "is that when a Scher wants to actually run an application he can first make a request for resource he can say these",
    "start": "1650000",
    "end": "1655399"
  },
  {
    "text": "are some resources I would like to use to actually be able to run my application okay and request is really",
    "start": "1655399",
    "end": "1660440"
  },
  {
    "text": "it's a simplified subset of kind of a specification for what it wants to run it's just the resources that it needs at",
    "start": "1660440",
    "end": "1666480"
  },
  {
    "text": "that point in time okay now uh what what the what mesos then",
    "start": "1666480",
    "end": "1672760"
  },
  {
    "text": "does is it takes all the requests in the system and it takes whatever other information that it knows about and it creates what are called offers and",
    "start": "1672760",
    "end": "1678519"
  },
  {
    "text": "offers are effectively allocations that it makes back to schedulers So based on",
    "start": "1678519",
    "end": "1683760"
  },
  {
    "text": "on on what some schedulers might need to run their applications uh the mesos Masters specifically the allocator in",
    "start": "1683760",
    "end": "1689559"
  },
  {
    "text": "the mesos master says okay great here's some resources I can allocate to you so you can actually use these to run your",
    "start": "1689559",
    "end": "1695080"
  },
  {
    "text": "applications and of course we're not just making a single offer we're making many many offers at at at the same time",
    "start": "1695080",
    "end": "1701919"
  },
  {
    "text": "so what the schedule then does is it uses these offers it uses these allocations to decide what tasks it",
    "start": "1701919",
    "end": "1707480"
  },
  {
    "text": "actually wants to to run and this really is where this two-level scheduling comes in So at the first level msos is really",
    "start": "1707480",
    "end": "1714640"
  },
  {
    "text": "making the allocation decisions about about resources to individual Frameworks it could be the same kind of framework",
    "start": "1714640",
    "end": "1720080"
  },
  {
    "text": "just multiple instances of it and then and then those those Frameworks specifically the the schedules in the",
    "start": "1720080",
    "end": "1725120"
  },
  {
    "text": "Frameworks are deciding what uh what tasks they they they actually going to run what jobs they're actually going to",
    "start": "1725120",
    "end": "1730240"
  },
  {
    "text": "run based on the available resources uh that that they can use okay once uh once",
    "start": "1730240",
    "end": "1736320"
  },
  {
    "text": "they pick a task that they want to run and and say okay this is the task I want to run then they'll um submit that task",
    "start": "1736320",
    "end": "1742000"
  },
  {
    "text": "back to to mesus and say Here's the task I want to run and again this is where most distributed systems end up having",
    "start": "1742000",
    "end": "1747240"
  },
  {
    "text": "to build this piece in where they they you know if they want to run some task on some other machine they've had to",
    "start": "1747240",
    "end": "1752919"
  },
  {
    "text": "build in the the component Tre to get the task to the other machine have the machine take that task and actually",
    "start": "1752919",
    "end": "1758279"
  },
  {
    "text": "start start to run whatever it is that it needs to run in this case they can just say here here's my task run it and",
    "start": "1758279",
    "end": "1763799"
  },
  {
    "text": "go okay um so there's a couple different ways you can actually run run tasks in msos so you can just give a task with a",
    "start": "1763799",
    "end": "1770240"
  },
  {
    "start": "1766000",
    "end": "1805000"
  },
  {
    "text": "command uh an arbitrary uh uh uh shell command and depending on how you've",
    "start": "1770240",
    "end": "1775440"
  },
  {
    "text": "actually set up the base image on across your data center that command may or may not work um uh if you run a task with a",
    "start": "1775440",
    "end": "1782720"
  },
  {
    "text": "command it's pretty simple it says here here's the task I want to run uh there's again as I mentioned there's an agent process on each of the machines that uh",
    "start": "1782720",
    "end": "1790279"
  },
  {
    "text": "gets the task when it gets assigned to it and then just just uh launches the task okay and of course you can run",
    "start": "1790279",
    "end": "1796559"
  },
  {
    "text": "multiple tasks on the same machine um you can also though you can you can launch tasks uh uh through what we call",
    "start": "1796559",
    "end": "1802960"
  },
  {
    "text": "an executive in mesos so it's this extra level of indirection that lets that lets you as somebody who's trying to build a",
    "start": "1802960",
    "end": "1808840"
  },
  {
    "start": "1805000",
    "end": "1874000"
  },
  {
    "text": "a distributed system be able to specify exactly how you want your task to actually run so the way that works is",
    "start": "1808840",
    "end": "1815559"
  },
  {
    "text": "again you go to launch a task but you specify an Executor an Executor is is the first thing that we actually execute",
    "start": "1815559",
    "end": "1821600"
  },
  {
    "text": "and then we pass the task to the executive and the executive can decide how it actually wants to run its tasks",
    "start": "1821600",
    "end": "1826760"
  },
  {
    "text": "and again an ex Compu can have multiple tasks so the reason why this is really really interesting is because it allows",
    "start": "1826760",
    "end": "1832320"
  },
  {
    "text": "you to actually uh uh send tasks to something on an individual machine that",
    "start": "1832320",
    "end": "1838320"
  },
  {
    "text": "don't require a complete Fork exact so if you wanted to say build a distributed system where you want to just do more",
    "start": "1838320",
    "end": "1845360"
  },
  {
    "text": "things by say spawning threads or allocating memory you could do something like that in this model so we specifically wanted to build something",
    "start": "1845360",
    "end": "1851480"
  },
  {
    "text": "so if you were trying to build a sophisticated distributed system which didn't want to have to completely say fork exact to do a very very small task",
    "start": "1851480",
    "end": "1858120"
  },
  {
    "text": "like um say pull something off a queue and and process it that you could actually do something like that okay um",
    "start": "1858120",
    "end": "1865120"
  },
  {
    "text": "so again if you're running if you're running uh with executors uh that you can also be on the same machine running just just uh top level tasks okay so",
    "start": "1865120",
    "end": "1873039"
  },
  {
    "text": "what we end up doing on each of the individual machines is we isolate with a container um we isolate the individual",
    "start": "1873039",
    "end": "1879120"
  },
  {
    "start": "1874000",
    "end": "1980000"
  },
  {
    "text": "executors or tasks okay so what this looks like is here um we've launched one",
    "start": "1879120",
    "end": "1884480"
  },
  {
    "text": "executor it's got one task running one top level task and we've put a container around each of these different things so",
    "start": "1884480",
    "end": "1890440"
  },
  {
    "text": "that they're they're isolated from a resource perspective from using uh one another's resources and the technology",
    "start": "1890440",
    "end": "1896799"
  },
  {
    "text": "that we actually actually use to do that is the same technology that's underlined Docker uh Linux control groups and uh",
    "start": "1896799",
    "end": "1903279"
  },
  {
    "text": "name spaces so before Docker existed um this is the way that we did it and and that's one of the reasons why I",
    "start": "1903279",
    "end": "1908399"
  },
  {
    "text": "mentioned at the beginning uh a lot of people that use msos in the early days they just had tar balls or jar files cuz",
    "start": "1908399",
    "end": "1915000"
  },
  {
    "text": "there wasn't a whole image that they needed they just had their bits in that form we constructed the container around them",
    "start": "1915000",
    "end": "1920039"
  },
  {
    "text": "and then they unpacked their tarball okay one of the things that's really interesting about this model",
    "start": "1920039",
    "end": "1925519"
  },
  {
    "text": "though specifically with with with executors is that since we put these containers around them um you can easily",
    "start": "1925519",
    "end": "1932080"
  },
  {
    "text": "pass more tasks to the executor and as we actually pass more task to the executor we'll scale up the size of the",
    "start": "1932080",
    "end": "1938480"
  },
  {
    "text": "container dynamically so we'll actually add more resources to to The Container so for those of you that are really",
    "start": "1938480",
    "end": "1943679"
  },
  {
    "text": "familiar with vertical versus hor horizontal scaling it actually lets you do vertical scaling directly on the machines as as well as of course scale",
    "start": "1943679",
    "end": "1950639"
  },
  {
    "text": "to other machines okay um and of course as the machines go down we actually vertically scale scale the containers down okay um",
    "start": "1950639",
    "end": "1958760"
  },
  {
    "text": "and then finally uh of course if you don't if you're not sending us a tarball or or or a gzip um you can send us a",
    "start": "1958760",
    "end": "1964799"
  },
  {
    "text": "Docker image and we'll just run the docker image directly okay um so one of the things that that that that comes up",
    "start": "1964799",
    "end": "1970720"
  },
  {
    "text": "a lot when people really dive into to the depths of of how MOS works is uh what does high availab high availability",
    "start": "1970720",
    "end": "1976519"
  },
  {
    "text": "actually look like in the system so it was designed from day one to let all the different components of the",
    "start": "1976519",
    "end": "1981720"
  },
  {
    "start": "1980000",
    "end": "2013000"
  },
  {
    "text": "system fail independently and there's really not that many components the core components again as I mentioned are the",
    "start": "1981720",
    "end": "1986880"
  },
  {
    "text": "Masters and the slaves and the one other component is um zookeeper which we currently use for leader election but",
    "start": "1986880",
    "end": "1992960"
  },
  {
    "text": "those are the three Three core components you need to actually be running a a mesos cluster so uh when something like a a",
    "start": "1992960",
    "end": "1999559"
  },
  {
    "text": "master fails however the scheduler will just get rerouted through zookeeper to communicate with another Master that's",
    "start": "1999559",
    "end": "2005480"
  },
  {
    "text": "elected and all the tasks that have been run everything that's been launched will just keep keep running okay um the same",
    "start": "2005480",
    "end": "2012919"
  },
  {
    "text": "thing with auler if a scheduler happens to go down um uh then uh another",
    "start": "2012919",
    "end": "2017960"
  },
  {
    "start": "2013000",
    "end": "2105000"
  },
  {
    "text": "scheduler can be elected and uh and it'll it will reconnect to the Masters and it will find out about any of its",
    "start": "2017960",
    "end": "2023519"
  },
  {
    "text": "tasks that might have say failed while it was down um so this is actually a pretty pretty interesting pretty",
    "start": "2023519",
    "end": "2029039"
  },
  {
    "text": "interesting thing that we built in when we first built in the notion of schedu failover um we actually gave a timeout",
    "start": "2029039",
    "end": "2035120"
  },
  {
    "text": "that you could specify when a scheder first registered to decide uh you know how long you wanted to wait to",
    "start": "2035120",
    "end": "2041000"
  },
  {
    "text": "potentially fail over and if that amount of time elapsed then we would just clean up for you and we would kind of kill all",
    "start": "2041000",
    "end": "2046799"
  },
  {
    "text": "of your uh all of your tasks under the covers so what was really interesting about this was the first time that that",
    "start": "2046799",
    "end": "2053320"
  },
  {
    "text": "um we put it in place uh at Twitter when we were running the the Aurora service schedu on top um I think we had I think",
    "start": "2053320",
    "end": "2060200"
  },
  {
    "text": "we had like a 5H hour uh failover timeout and then we had a uh we had an outage that was like 4 hours and 30",
    "start": "2060200",
    "end": "2066398"
  },
  {
    "text": "minutes and so we almost killed every single task in the cluster because we didn't have the scheduler reconnect to",
    "start": "2066399",
    "end": "2071480"
  },
  {
    "text": "the master within the 5 hours and so the failover would have been El lapsed we would have killed everything so then",
    "start": "2071480",
    "end": "2077000"
  },
  {
    "text": "after that we said oh well let's make it 24 hours so we bumped it up to 24 hours and then a couple weeks later we had a",
    "start": "2077000",
    "end": "2082800"
  },
  {
    "text": "failover we couldn't get the schedule to reconnect within about 22 hours and after that we just bumped it up to double Max so um at at this point uh the",
    "start": "2082800",
    "end": "2090720"
  },
  {
    "text": "way schedule fail over really works for most people in the organizations is either always keep it running or when",
    "start": "2090720",
    "end": "2097920"
  },
  {
    "text": "when it first disconnects shut down all my tasks that are running but still we have the functionality and and and and you can decide what what you want to do",
    "start": "2097920",
    "end": "2104119"
  },
  {
    "text": "there so the last uh uh uh uh type of high high availability um that we have",
    "start": "2104119",
    "end": "2110440"
  },
  {
    "start": "2105000",
    "end": "2248000"
  },
  {
    "text": "in the system is what we actually call slave failover so again we've got this agent process that's running that's managing the slaves and we actually have",
    "start": "2110440",
    "end": "2116960"
  },
  {
    "text": "the ability to let that process that manages the task go away and if the task",
    "start": "2116960",
    "end": "2123160"
  },
  {
    "text": "if that that process goes away and a new one comes up then it will refind or it will reconnect any of the other tasks or",
    "start": "2123160",
    "end": "2129079"
  },
  {
    "text": "any of the other containers or any of the other other uh uh uh Docker containers that it's actually launched",
    "start": "2129079",
    "end": "2135440"
  },
  {
    "text": "so this was really really critical to us because the kinds of services that people actually want to end up running in production are things like",
    "start": "2135440",
    "end": "2141960"
  },
  {
    "text": "mcash or redis or other services where if every single time that our process",
    "start": "2141960",
    "end": "2148560"
  },
  {
    "text": "died we actually killed all the containers that were running that would be really really unfortunate now of course we don't want our process to die",
    "start": "2148560",
    "end": "2154560"
  },
  {
    "text": "very much because we're going to make it as robust as possible but there's one time when we're always going to be bringing down the process and that's",
    "start": "2154560",
    "end": "2160359"
  },
  {
    "text": "when we're actually doing maintenance or an upgrade of the msos layer itself and",
    "start": "2160359",
    "end": "2165880"
  },
  {
    "text": "so what we were running into was we're running into to the case where we would want to upgrade mesos in the data center",
    "start": "2165880",
    "end": "2171680"
  },
  {
    "text": "and what we'd have to do is we'd have to go to a machine we'd have to drain the tasks off of it effectively kill the tasks and then upgrade the uh um the um",
    "start": "2171680",
    "end": "2179720"
  },
  {
    "text": "uh you know upgrade the machine and and so and then put put put put put put the new uh the new binary on and then you",
    "start": "2179720",
    "end": "2186200"
  },
  {
    "text": "know stuff can get res scheduled on that box which is fine when you have a handful of machines but when you start to get into hundreds of machines to",
    "start": "2186200",
    "end": "2192760"
  },
  {
    "text": "guarantee the slas that you want for when you start killing tasks and have them migrate to other machines uh it can",
    "start": "2192760",
    "end": "2197920"
  },
  {
    "text": "start to take days if not weeks if not months to actually upgrade a cluster so",
    "start": "2197920",
    "end": "2203000"
  },
  {
    "text": "this was a a pretty critical feature we put in okay um",
    "start": "2203000",
    "end": "2208359"
  },
  {
    "text": "so I'm going to uh go a little bit further down the rabbit",
    "start": "2208359",
    "end": "2213440"
  },
  {
    "text": "hole but I'm going to I'm going to skip ahead a little bit um",
    "start": "2213440",
    "end": "2218480"
  },
  {
    "text": "because we get pretty deep in we get pretty deep in the rabbit hole with with a different different mesos features um",
    "start": "2218480",
    "end": "2225040"
  },
  {
    "text": "so I'm going to skip talking about how we actually do our first level allocation and I'm going to jump",
    "start": "2225040",
    "end": "2231520"
  },
  {
    "text": "to some other higher level Concepts Okay so we've got some other great great",
    "start": "2231520",
    "end": "2237160"
  },
  {
    "text": "great uh Concepts in mesos that we've had to introduce specifically for running this stuff in production the couple that I want to mention briefly",
    "start": "2237160",
    "end": "2243040"
  },
  {
    "text": "are uh uh the first couple ones I want to mention is really resource reservations so it's this basic concept that you can",
    "start": "2243040",
    "end": "2249599"
  },
  {
    "start": "2248000",
    "end": "2283000"
  },
  {
    "text": "go in and you can say you know what for some Frameworks that are running for some schedules that are running I actually want to make sure that",
    "start": "2249599",
    "end": "2254920"
  },
  {
    "text": "resources are guaranteed to be allocated to these Frameworks so you can get gu so you can you know feel good at night when",
    "start": "2254920",
    "end": "2260240"
  },
  {
    "text": "you go to sleep and you know that there's going to be a bunch of failures that uh at least if there's this many resources this many resources will be",
    "start": "2260240",
    "end": "2265920"
  },
  {
    "text": "guaranteed to to different applications so the way reservations actually work in in msos is you can specify the",
    "start": "2265920",
    "end": "2272520"
  },
  {
    "text": "reservations uh uh on the individual machines and you can say you know I want to create some pre-specified container",
    "start": "2272520",
    "end": "2279000"
  },
  {
    "text": "sizes for uh for some of the jobs that I I want to run on top so you can do that",
    "start": "2279000",
    "end": "2284599"
  },
  {
    "start": "2283000",
    "end": "2340000"
  },
  {
    "text": "statically which is great um what that really gives you is this notion of strong guarantees but the unfortunate",
    "start": "2284599",
    "end": "2290599"
  },
  {
    "text": "part about it is that it has to be set up by an operator when they're starting when they're starting the slave for the first time and it's actually immutable",
    "start": "2290599",
    "end": "2296440"
  },
  {
    "text": "because once you set the reservations you actually have to drain everything off if you want you want to change reservations so what we've recently",
    "start": "2296440",
    "end": "2302280"
  },
  {
    "text": "introduced in mesos is this concept of dynamic reservations which are pretty cool it's this basic idea that when a",
    "start": "2302280",
    "end": "2308160"
  },
  {
    "text": "framework when when a schedule inside a framework is trying to run an application and the first time that it gets resources that are allocated to it",
    "start": "2308160",
    "end": "2314800"
  },
  {
    "text": "when it goes to actually run its tasks it can not just say launch these tasks but it can also say reserve those",
    "start": "2314800",
    "end": "2320520"
  },
  {
    "text": "resources for me so that I'm guaranteed that those resources will be reallocated to me no matter what after the machine",
    "start": "2320520",
    "end": "2326440"
  },
  {
    "text": "goes down for maintenance after I fail after there's a network partition for a long period of time and eventually you know you shut my process down whatever",
    "start": "2326440",
    "end": "2333319"
  },
  {
    "text": "it is so once we actually get the the the resources and the Tas to the individual machines we do the",
    "start": "2333319",
    "end": "2339440"
  },
  {
    "text": "reservations there um so reservations are great because they provide the nice guarantees that that we all want when",
    "start": "2339440",
    "end": "2345720"
  },
  {
    "start": "2340000",
    "end": "2523000"
  },
  {
    "text": "we're actually running in a in a in a production setting but really at the cost of utilization so you know when you",
    "start": "2345720",
    "end": "2351319"
  },
  {
    "text": "end up having a big chunk of resources that are reserve for for particular uh for a particular organization they might",
    "start": "2351319",
    "end": "2357800"
  },
  {
    "text": "be using very little of those resources which kind of goes against the whole idea of well we're using a cluster manager to actually be able to drive up",
    "start": "2357800",
    "end": "2364359"
  },
  {
    "text": "to drive up resource utilization so to to with that we have this other Concept in msos that we actually call revocable",
    "start": "2364359",
    "end": "2371680"
  },
  {
    "text": "resources and the concept behind revocable resources is there's resources that can be used by different Frameworks",
    "start": "2371680",
    "end": "2377280"
  },
  {
    "text": "on top that can actually be taken back from uh uh the uh uh schedulers that",
    "start": "2377280",
    "end": "2382560"
  },
  {
    "text": "have launched tasks with them so it this ends up introducing a really really nice property for people that are trying to",
    "start": "2382560",
    "end": "2387680"
  },
  {
    "text": "build new distributed systems which is the way that they can think about preemption in their head is that",
    "start": "2387680",
    "end": "2393119"
  },
  {
    "text": "preemption actually occurs through uh revocation so we don't have the no of priorities in the system we don't have",
    "start": "2393119",
    "end": "2399040"
  },
  {
    "text": "to like guess who's a slightly higher priority and what semantics that's going to mean it basically means that if you're using resources that are either",
    "start": "2399040",
    "end": "2405560"
  },
  {
    "text": "reserved to you or not marked as revocable we're not going to take them from you and if you're using resources that are revocable you you it's it's",
    "start": "2405560",
    "end": "2412920"
  },
  {
    "text": "it's highly likely that your task will be preempted to to get the resources back okay um so one of the really really",
    "start": "2412920",
    "end": "2419720"
  },
  {
    "text": "cool things that we're actually working on uh with Ral resources right now is over subscription so what ends up happening in a lot of these",
    "start": "2419720",
    "end": "2425280"
  },
  {
    "text": "organizations is they start running their task s and users come in and they say my task requires 8 CPUs and 8 gigs",
    "start": "2425280",
    "end": "2431160"
  },
  {
    "text": "of RAM and it uses two CPUs and 2 gigs of RAM and now we've got all these resources that have been allocated but",
    "start": "2431160",
    "end": "2437240"
  },
  {
    "text": "are actually not being used so what we can do is we can take that remaining six CPUs and six gigs of RAM and we can",
    "start": "2437240",
    "end": "2442760"
  },
  {
    "text": "offer them out out to uh to other things that are trying to run in in in the data center as revocable they can use those",
    "start": "2442760",
    "end": "2449560"
  },
  {
    "text": "resources and of course if that first application that was trying to use all eight uh CPUs and 8 gigs of RAM scales",
    "start": "2449560",
    "end": "2454920"
  },
  {
    "text": "up uh then it'll actually get the resources back okay",
    "start": "2454920",
    "end": "2462880"
  },
  {
    "text": "um so again excuse me this revocation guarantee that we",
    "start": "2462880",
    "end": "2468920"
  },
  {
    "text": "really provide though which is that the tasks will not be killed unless I'm using revocable resources it's tough to",
    "start": "2468920",
    "end": "2474480"
  },
  {
    "text": "always provide that uh one of the trickiest places when when it's tough to provide that is when we might want to",
    "start": "2474480",
    "end": "2480280"
  },
  {
    "text": "say defrag the cluster because the way that stuff has gotten scheduled over time it leads to a",
    "start": "2480280",
    "end": "2486480"
  },
  {
    "text": "less useful utilization than if we could actually pack some things together and shut some machines down or specifically",
    "start": "2486480",
    "end": "2492800"
  },
  {
    "text": "when we want when when we want to actually do maintenance so some of the last uh uh",
    "start": "2492800",
    "end": "2497960"
  },
  {
    "text": "Primitives that we've been introducing into mesos recently are are uh Primitives for actually doing deallocation so that we can we can",
    "start": "2497960",
    "end": "2504560"
  },
  {
    "text": "introduce maintenance as a software Concept in the system so um you know one",
    "start": "2504560",
    "end": "2509640"
  },
  {
    "text": "way in which we can actually do maintenance is we can again go around and we can kill machines or shut down machines or drain drain drain a a a Tas",
    "start": "2509640",
    "end": "2516960"
  },
  {
    "text": "for machines and then they won't know about it they'll just think that there was a failure and then we'll go from there but we can actually do better so",
    "start": "2516960",
    "end": "2522440"
  },
  {
    "text": "we got this really interesting Concept in in MOS that we call an inverse offer where an offer is an allocation of",
    "start": "2522440",
    "end": "2527960"
  },
  {
    "start": "2523000",
    "end": "2593000"
  },
  {
    "text": "resources that's made to you an inverse offer is a deallocation of resources where we say hey we'd like these",
    "start": "2527960",
    "end": "2533760"
  },
  {
    "text": "resources back specifically we'd like these resources back at this period of at this point in time and for this period of time because say we're going",
    "start": "2533760",
    "end": "2540559"
  },
  {
    "text": "to shut down the machine uh during that period And so you can't run any tasks on it okay so um so that's pretty cool uh",
    "start": "2540559",
    "end": "2548119"
  },
  {
    "text": "we can send out an inverse offer and then the framewor can say great yep um uh I acknowledge that you're going to take my resources away and and I'll shut",
    "start": "2548119",
    "end": "2554440"
  },
  {
    "text": "down my resources so that that lets us introduce something like maintenance in a really",
    "start": "2554440",
    "end": "2559480"
  },
  {
    "text": "programmatic way so we start off by sending out inverse offers um then we actually once we we've sent out all the",
    "start": "2559480",
    "end": "2565839"
  },
  {
    "text": "the inverse offers we can continue to send out other allocations but just Mark the resources that are that are for use there as",
    "start": "2565839",
    "end": "2571800"
  },
  {
    "text": "revocable and then finally once all the tasks have stopped running on the machines we can remove them from the",
    "start": "2571800",
    "end": "2577400"
  },
  {
    "text": "cluster and do whatever uh maintenance that we actually want to do okay so um",
    "start": "2577400",
    "end": "2582880"
  },
  {
    "text": "you know this comes up often when we talk about cluster management but what about my persistent data how do I run my",
    "start": "2582880",
    "end": "2588280"
  },
  {
    "text": "stateful services on on on cluster managers and so for that we also introduced a concept recently that we",
    "start": "2588280",
    "end": "2594440"
  },
  {
    "start": "2593000",
    "end": "2734000"
  },
  {
    "text": "call persistent volumes so the idea behind persistent volumes is again that one of these Frameworks through the programmatic API so software can go in",
    "start": "2594440",
    "end": "2602160"
  },
  {
    "text": "it can create uh persistent volume for for uh um whatever task that's trying to",
    "start": "2602160",
    "end": "2607480"
  },
  {
    "text": "run okay and so it does that when it gets an allocation of resources through an offer when it goes to to to launch",
    "start": "2607480",
    "end": "2613000"
  },
  {
    "text": "any tasks it can say by the way I also want you to create a persistent volume for this task on this machine and of",
    "start": "2613000",
    "end": "2618720"
  },
  {
    "text": "course tell me about it in the future if the machine ever fails or my task fails or or any of those other things happen",
    "start": "2618720",
    "end": "2626240"
  },
  {
    "text": "and again we we propagate the persistent volume information all the way down to the slave so it can uh um so it can",
    "start": "2626240",
    "end": "2631359"
  },
  {
    "text": "record that information and we can deal with all the uh failure scenarios that I talked about earlier so what persistent",
    "start": "2631359",
    "end": "2637440"
  },
  {
    "text": "volumes end up looking like on the individual machine it's just like kind of dynamic reservations have preset out containers we have these containers set",
    "start": "2637440",
    "end": "2644800"
  },
  {
    "text": "up with things like volumes that are preset for those containers so when a task goes to run it",
    "start": "2644800",
    "end": "2650079"
  },
  {
    "text": "can actually use any of the persistent volumes that have been allocated for it but then of course if the task fails",
    "start": "2650079",
    "end": "2656000"
  },
  {
    "text": "then uh then the persistent volume is going to stick around and the next time that you try to run a task using that persistent volume it'll still be there",
    "start": "2656000",
    "end": "2663240"
  },
  {
    "text": "so I think that the bigger picture of a lot of these features is that uh we're trying to build these things and specifically so we can run Long Live",
    "start": "2663240",
    "end": "2670079"
  },
  {
    "text": "State full Frameworks so not just uh all the state list services that I really talked about earlier the things we went",
    "start": "2670079",
    "end": "2676280"
  },
  {
    "text": "after and attacked when we first started doing this at Twitter but the stateful stuff as well and really this combination of reservations inverse",
    "start": "2676280",
    "end": "2682599"
  },
  {
    "text": "offers and persistent volumes really gives us The Primitives to to do something like that okay so Ju Just A",
    "start": "2682599",
    "end": "2688480"
  },
  {
    "text": "couple more slides um and then I'll take some questions so you know these days it's a pretty fun time all of our other",
    "start": "2688480",
    "end": "2695280"
  },
  {
    "text": "computers are effectively data centers we can spin up uh data centers worth of resources very very easily on any of the",
    "start": "2695280",
    "end": "2701319"
  },
  {
    "text": "public clouds or we just have them at our disposal at our at our existing organizations and you know here by data",
    "start": "2701319",
    "end": "2707040"
  },
  {
    "text": "center I really just mean some collection of physical or virtual machines that we're grouping together and and and treating as as one one big",
    "start": "2707040",
    "end": "2714040"
  },
  {
    "text": "data center computer because really the the data center should just be another form factor uh just like our laptops a form",
    "start": "2714040",
    "end": "2720720"
  },
  {
    "text": "factor and and the tablets are form factor and uh the the cell phones are form factors if mesos is really this",
    "start": "2720720",
    "end": "2727800"
  },
  {
    "text": "data center kernel that that we're trying to build the natural question is is well what's the data center operating",
    "start": "2727800",
    "end": "2733359"
  },
  {
    "text": "system look like and that's actually what we're what we're doing at at at mesosphere is trying to build what what what we call the uh mesosphere data",
    "start": "2733359",
    "end": "2740359"
  },
  {
    "start": "2734000",
    "end": "2792000"
  },
  {
    "text": "center operating system so to look at that stack to look at everything that I talked about earlier in the presentation",
    "start": "2740359",
    "end": "2745640"
  },
  {
    "text": "what that ends up looking like is you got this kernel like layer that we call msos and then um you've got sort of this",
    "start": "2745640",
    "end": "2751079"
  },
  {
    "text": "API layer on top and then again you can either directly use something like Marathon to launch your apps or Kronos",
    "start": "2751079",
    "end": "2756760"
  },
  {
    "text": "to launch your apps um or uh uh you can go and you can build your own Schuler uh",
    "start": "2756760",
    "end": "2762559"
  },
  {
    "text": "uh and distribute system by using the mesos SDK on top and one of the nice things here is that you know when you",
    "start": "2762559",
    "end": "2768400"
  },
  {
    "text": "end up when you end up building your software on top of this you're abstracted away from if you're running on bare metal or if you're running on on",
    "start": "2768400",
    "end": "2773800"
  },
  {
    "text": "any of the clouds and again as I mentioned before Marathon really it ends up being sort of the init for the data",
    "start": "2773800",
    "end": "2779400"
  },
  {
    "text": "center operating system it's the thing that you use to to launch your first tasks um and Kronos really ends up being",
    "start": "2779400",
    "end": "2785440"
  },
  {
    "text": "sort of the cron for the for the for the data center operating system okay one of the things we built when when we're when",
    "start": "2785440",
    "end": "2791280"
  },
  {
    "text": "I actually building this this is open source the the dcos CLI um so the one of",
    "start": "2791280",
    "end": "2796400"
  },
  {
    "start": "2792000",
    "end": "3190000"
  },
  {
    "text": "the first things that we actually built was was a CLI which is just for interacting with this data center computer obviously data center operating",
    "start": "2796400",
    "end": "2802040"
  },
  {
    "text": "systems operating systems need uh user interfaces so the first thing we built is a CLI um and it's pretty cool um you",
    "start": "2802040",
    "end": "2808559"
  },
  {
    "text": "can hook into it with any of the the distributed systems you're trying to run on top like something like Cassandra uh and you can actually do something like",
    "start": "2808559",
    "end": "2814720"
  },
  {
    "text": "dcos package install Cassandra and actually get uh uh an implementation of cassander running up on the data center",
    "start": "2814720",
    "end": "2821599"
  },
  {
    "text": "without having to actually touch uh uh anything which is uh which is very very cool and at the same time we've got some",
    "start": "2821599",
    "end": "2827400"
  },
  {
    "text": "even tighter uh hooks uh in our CLI with certain applications things like spark",
    "start": "2827400",
    "end": "2832440"
  },
  {
    "text": "as well um so if you want to run a spark job you don't even have to install spark you can just go ahead and do a a DCS",
    "start": "2832440",
    "end": "2838000"
  },
  {
    "text": "Spark Run to to to run run spark applications directly on um on your data center okay so I've uh spoken for about",
    "start": "2838000",
    "end": "2845599"
  },
  {
    "text": "46 minutes I'll um I'll stop now and I'd love to take any",
    "start": "2845599",
    "end": "2851480"
  },
  {
    "text": "questions yeah so I'll repeat I'll I'll repeat the question sure everybody heard so I talked about actually being able to",
    "start": "2851960",
    "end": "2857599"
  },
  {
    "text": "do vertical scaling on on an individual machine that obviously we can reach reach a peak of our resources so you",
    "start": "2857599",
    "end": "2865200"
  },
  {
    "text": "can't you can't just arbitrarily take more resources on the machine um you have to actually schedule tasks inside",
    "start": "2865200",
    "end": "2871000"
  },
  {
    "text": "of the container that you've actually launched to uh uh uh to for us to actually vertically scale up the uh the",
    "start": "2871000",
    "end": "2877880"
  },
  {
    "text": "container so um if there are no if all the resources are actually allocated to other containers or other tasks or other",
    "start": "2877880",
    "end": "2884119"
  },
  {
    "text": "Executives that are running then we won't they won't be allocatable they they won't be usable so you won't",
    "start": "2884119",
    "end": "2889520"
  },
  {
    "text": "actually be able to run anything inside that container so the resources are accounted so the tldrs that the resources are accounted for in exactly",
    "start": "2889520",
    "end": "2895559"
  },
  {
    "text": "the same way as um as if they were running outside the container um we just let you run the task inside and then",
    "start": "2895559",
    "end": "2901960"
  },
  {
    "text": "scale up the the container from there does that answer the question",
    "start": "2901960",
    "end": "2907760"
  },
  {
    "text": "uh I I see so so the question is is um could you if the if the resources are",
    "start": "2907760",
    "end": "2913319"
  },
  {
    "text": "heterogeneous which by the way is almost always the case that there's a heterogeneous collection of you know",
    "start": "2913319",
    "end": "2919760"
  },
  {
    "text": "basic machine shapes um can uh can you and so then the question is can you if",
    "start": "2919760",
    "end": "2926559"
  },
  {
    "text": "you're running a machine can you kind of like so so so usually what end up",
    "start": "2926559",
    "end": "2931680"
  },
  {
    "text": "happening is if you're running a task on a machine and actually you wanted to vertically scale up but you just could never fit on that individual machine",
    "start": "2931680",
    "end": "2938000"
  },
  {
    "text": "you'd have to shut the task down and then run the task on a on a different",
    "start": "2938000",
    "end": "2943440"
  },
  {
    "text": "machine but if there're the resources available then you can vertically scale up and at the same time once you've used",
    "start": "2943440",
    "end": "2948680"
  },
  {
    "text": "those resources you can vertically scale down so the applications which end up taking advantage of this the most tend",
    "start": "2948680",
    "end": "2955280"
  },
  {
    "text": "to be things like analytics um continuous integration things things that are you know compilers that are",
    "start": "2955280",
    "end": "2961680"
  },
  {
    "text": "building things um often times they're these shorter lived applications that",
    "start": "2961680",
    "end": "2966839"
  },
  {
    "text": "excuse me could take advantage of the fact that you've already started doing some computation someplace and so if you",
    "start": "2966839",
    "end": "2972359"
  },
  {
    "text": "can just run some more stuff there right now you're going to be able to do it far faster than uh than if you were to bring",
    "start": "2972359",
    "end": "2978000"
  },
  {
    "text": "up another one horizontally someplace else and then and then go from there and so that's that's that's specifically why",
    "start": "2978000",
    "end": "2984200"
  },
  {
    "text": "why why we built we built the things in so things like spark for example explicitly take advantage of this when",
    "start": "2984200",
    "end": "2989440"
  },
  {
    "text": "it runs on MOS and when you go to run another task and Spark already has some of the data in memory on that particular",
    "start": "2989440",
    "end": "2995640"
  },
  {
    "text": "machine it run the task on that machine it'll vertically scale up it'll use the stuff in memory and then when it's done it'll vertically scale down and uh and",
    "start": "2995640",
    "end": "3002440"
  },
  {
    "text": "then you know the resources are free again and you know that's saves you significant uh time in running your jobs",
    "start": "3002440",
    "end": "3009559"
  },
  {
    "text": "than bringing it up someplace else other questions great",
    "start": "3009559",
    "end": "3016520"
  },
  {
    "text": "question how do you prioritize different workloads on the same mesos cluster it",
    "start": "3016520",
    "end": "3021920"
  },
  {
    "text": "do spark jobs less prior than Marathon or per perhaps",
    "start": "3021920",
    "end": "3027280"
  },
  {
    "text": "also within theu yeah the single schu okay great so um some of the slides I I",
    "start": "3027280",
    "end": "3033079"
  },
  {
    "text": "skipped in the The Rabbit Hole part was uh specifically how we do the first",
    "start": "3033079",
    "end": "3038480"
  },
  {
    "text": "level of allocation in msos and that first level allocation is how we choose what resources to allocate to some of",
    "start": "3038480",
    "end": "3044480"
  },
  {
    "text": "the different schedulers that are running on top um so the the basic idea in the system is we um uh the first",
    "start": "3044480",
    "end": "3051240"
  },
  {
    "text": "level schedule or the default first level schedule that we have is something that we call a dominant resource fairness",
    "start": "3051240",
    "end": "3057160"
  },
  {
    "text": "and um and it's a fair sharing algorithm but it has weights so you can actually",
    "start": "3057160",
    "end": "3062319"
  },
  {
    "text": "attach weights to things like a spark instance or Hadoop instance or Marathon",
    "start": "3062319",
    "end": "3067440"
  },
  {
    "text": "or uh kubernetes or whatever it is that you're trying to run to uh to preferentially give those Frameworks",
    "start": "3067440",
    "end": "3073400"
  },
  {
    "text": "that are running more resources um uh so you know for example you can in fact you can run three",
    "start": "3073400",
    "end": "3080119"
  },
  {
    "text": "instances of something like uh like spark and you can run one instance with a really really high weight and the",
    "start": "3080119",
    "end": "3085640"
  },
  {
    "text": "other ones with really really low weights and um and uh what that effectively enables is you know the one",
    "start": "3085640",
    "end": "3091319"
  },
  {
    "text": "with the high weight can kind of be your production one which always gets the resources and the one with the low weights can just be the you know ones",
    "start": "3091319",
    "end": "3096520"
  },
  {
    "text": "that that you throw away um so this is only part of it though um uh because uh",
    "start": "3096520",
    "end": "3103599"
  },
  {
    "text": "uh there can still be circumstances where things get scheduled in this Fair sharing way uh that doesn't actually",
    "start": "3103599",
    "end": "3108760"
  },
  {
    "text": "meet the the needs of the organization and that's specifically why we introduced the concept of reservations",
    "start": "3108760",
    "end": "3114680"
  },
  {
    "text": "is because reservations really let an operator that's running the cluster uh be able to say to some part of its",
    "start": "3114680",
    "end": "3120480"
  },
  {
    "text": "organization I want to guarantee you're going to get at least 300 CPUs and 400",
    "start": "3120480",
    "end": "3127680"
  },
  {
    "text": "gigs of RAM and so I'm going to put this reservation in place um or you're going",
    "start": "3127680",
    "end": "3132760"
  },
  {
    "text": "to I'm going to put this reservation in place but you're going to fill it up dynamically based on when you actually run things and effectively what that",
    "start": "3132760",
    "end": "3139079"
  },
  {
    "text": "does is is it just gives better guarantees than um than you know Fair sharing with with weights so that's why",
    "start": "3139079",
    "end": "3146079"
  },
  {
    "text": "we' introduced those other Concepts yeah and and a lot a lot of the",
    "start": "3146079",
    "end": "3153480"
  },
  {
    "text": "the the things that have influenced these decisions have specifically been going and looking at the way our",
    "start": "3153480",
    "end": "3158960"
  },
  {
    "text": "traditional host operating systems perform these same roles and then and then introducing Concepts that are uh",
    "start": "3158960",
    "end": "3165880"
  },
  {
    "text": "amenable to the data center environment to the distributed system environment or in some cases are are exactly exactly",
    "start": "3165880",
    "end": "3171319"
  },
  {
    "text": "the same [Applause]",
    "start": "3171319",
    "end": "3180540"
  },
  {
    "text": "[Music]",
    "start": "3180540",
    "end": "3190469"
  }
]
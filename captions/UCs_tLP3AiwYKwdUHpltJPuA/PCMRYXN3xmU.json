[
  {
    "start": "0",
    "end": "170000"
  },
  {
    "text": "um so i'm going to talk about the liquid metal project this is a project at the uh from a team of us who we have up here",
    "start": "3360",
    "end": "10080"
  },
  {
    "text": "we're at the t.j watson research center in yorktown heights new york this is the main ibm research lab um so i'll start",
    "start": "10080",
    "end": "17119"
  },
  {
    "text": "by telling you something which you already know which is in the last decade or in the last eight or nine years ago frequency scaling",
    "start": "17119",
    "end": "23760"
  },
  {
    "text": "pretty much came to a stop clock speeds on computer chips are not getting faster very much anymore and so",
    "start": "23760",
    "end": "30160"
  },
  {
    "text": "the only way to um improve performance with chips going forward to exploit the more transistors is to",
    "start": "30160",
    "end": "36960"
  },
  {
    "text": "exploit parallelism and so we entered the multi-core area era which we're all familiar with so let me just start by",
    "start": "36960",
    "end": "42399"
  },
  {
    "text": "asking a question how many people here have explicitly programmed for a multi-core with threads or any other parallel",
    "start": "42399",
    "end": "48640"
  },
  {
    "text": "so almost everybody in the room has programmed for multi-core and i assume by multi-core you mean something like",
    "start": "48640",
    "end": "55760"
  },
  {
    "text": "intel x86 bunch of cores small scale multi-cores one thing which you might be",
    "start": "55760",
    "end": "61120"
  },
  {
    "text": "aware of is in the last few years become very hot is that there are much more high degree multi-cores called graphics",
    "start": "61120",
    "end": "67360"
  },
  {
    "text": "chips uh gpus and over the last especially in the last three or four years these have become",
    "start": "67360",
    "end": "73040"
  },
  {
    "text": "very popular here instead of having a few two or four or eight cores we have several hundred cores perhaps thousands",
    "start": "73040",
    "end": "80080"
  },
  {
    "text": "of hardware threads which can run uh concurrently and people have realized that for lots of workloads you know it's",
    "start": "80080",
    "end": "85520"
  },
  {
    "text": "much more efficient and you can get much better speed and parallelism by programming with the gpu and so we've seen the birth of gp gpu",
    "start": "85520",
    "end": "92880"
  },
  {
    "text": "using uh gpus for general purpose computing how many people in the room have done gp gpu programming program",
    "start": "92880",
    "end": "98720"
  },
  {
    "text": "general purpose computation on gpu all right we have one um well so gpus are",
    "start": "98720",
    "end": "106159"
  },
  {
    "text": "a fairly radical solution then perhaps for you but if you want to get even more radical than a gpu",
    "start": "106159",
    "end": "111360"
  },
  {
    "text": "in the world where we have you know very hard power constraints and difficulties",
    "start": "111360",
    "end": "116640"
  },
  {
    "text": "with scaling you can actually design your own hardware so if you actually want to design your own asic your own chip you need a lot of money and a lot",
    "start": "116640",
    "end": "123280"
  },
  {
    "text": "of time and a lot of expertise fpgas are field programmable gate arrays this is hardware basically programmable hardware",
    "start": "123280",
    "end": "130080"
  },
  {
    "text": "where you can create a hardware design and dynamically load it onto a chip and effectively",
    "start": "130080",
    "end": "135920"
  },
  {
    "text": "it's a lower entry barrier to design your own hardware and it doesn't run as fast and it's not as dense",
    "start": "135920",
    "end": "142480"
  },
  {
    "text": "as a custom asic but it is a way to quickly prototype hardware and once you can design your own hardware you have",
    "start": "142480",
    "end": "147760"
  },
  {
    "text": "your freedom you can exploit extremely massive bit parallel structures if you can do them you can get rid of a lot of interpretive overhead you don't have to",
    "start": "147760",
    "end": "154239"
  },
  {
    "text": "worry about memory system hierarchies and things if you so if you can design the hardware to",
    "start": "154239",
    "end": "159280"
  },
  {
    "text": "match your application you can get much better performance has anyone in the room programmed enough using fpgas",
    "start": "159280",
    "end": "165360"
  },
  {
    "text": "three so this is actually i would have expected more doing gpus and fpgas but not in this room",
    "start": "165360",
    "end": "171680"
  },
  {
    "start": "170000",
    "end": "260000"
  },
  {
    "text": "so this is the world we're going into for those of you who haven't used gpus or fpgas you may be wondering do you",
    "start": "171680",
    "end": "178080"
  },
  {
    "text": "really need to worry about this why do you need to worry about it let me start by a few motivating examples that we're seeing from a lot of our customers and i",
    "start": "178080",
    "end": "184879"
  },
  {
    "text": "believe you'll be seeing more and more over the first few years so there are a few models of how we might want to use these ex use these specialized devices",
    "start": "184879",
    "end": "192319"
  },
  {
    "text": "perhaps the easiest one to understand is using a gpu or an fpga as an accelerator so the idea here is that there's some",
    "start": "192319",
    "end": "198560"
  },
  {
    "text": "part of your workload which for some reason perhaps it's massively parallel you know data parallel floating point computation",
    "start": "198560",
    "end": "205040"
  },
  {
    "text": "which the gpu is is can be done very efficiently can do at higher performance lower power per flop",
    "start": "205040",
    "end": "211440"
  },
  {
    "text": "or perhaps there's some other kind of specialized processing which an fpga can just do more efficiently than your cpu",
    "start": "211440",
    "end": "216879"
  },
  {
    "text": "and so a natural thing to do is just take part of your calculation which is running on your cpu ship it over to use",
    "start": "216879",
    "end": "222560"
  },
  {
    "text": "the device as an accelerator run faster or run more power efficient ship the results back and so forth so effectively",
    "start": "222560",
    "end": "228400"
  },
  {
    "text": "you're using this as an engine to offload some part of your calculation this is extremely popular in the hpc",
    "start": "228400",
    "end": "234879"
  },
  {
    "text": "world for things like oil companies doing seismic simulations also in financial world if you look at the top 500 super",
    "start": "234879",
    "end": "241760"
  },
  {
    "text": "computer list many of the of the highest performing hpc super computers now include gpus at",
    "start": "241760",
    "end": "248720"
  },
  {
    "text": "every node simply because they're the most powerful data parallel floating point engines uh",
    "start": "248720",
    "end": "254879"
  },
  {
    "text": "that are available today and we see lots of other applications which can exploit fpgas as",
    "start": "254879",
    "end": "259919"
  },
  {
    "text": "well when we start talking about fpgas there are they have other advantages for which",
    "start": "259919",
    "end": "265680"
  },
  {
    "start": "260000",
    "end": "391000"
  },
  {
    "text": "lend themselves to other kinds of deployment models so one which is very popular is using fpgas in what we call a",
    "start": "265680",
    "end": "272639"
  },
  {
    "text": "network appliance platform so fpgas you can plug your i o such as your ethernet or serial",
    "start": "272639",
    "end": "279600"
  },
  {
    "text": "bus or let's say your network straight into the fpga and now you can design your hardware so you can design your own",
    "start": "279600",
    "end": "285919"
  },
  {
    "text": "network protocol to exploit very low level structure you don't have to worry about say running a custom operating",
    "start": "285919",
    "end": "292160"
  },
  {
    "text": "system stack and so forth so you can get extremely low latency uh turnaround and very high",
    "start": "292160",
    "end": "298880"
  },
  {
    "text": "throughput at the network uh bandwidth level as long as you can basically by moving your computation very close to",
    "start": "298880",
    "end": "304639"
  },
  {
    "text": "your own custom network interface and so there are a lot of the fpgas are used very much in telecom industries",
    "start": "304639",
    "end": "310960"
  },
  {
    "text": "financial industries networking applications effectively for low latency and high",
    "start": "310960",
    "end": "317120"
  },
  {
    "text": "throughput network applications the idea here is that most of the most of the computation will come in and off the",
    "start": "317120",
    "end": "322639"
  },
  {
    "text": "network directly into the fpga occasionally perhaps some general pump purpose computation or control logic",
    "start": "322639",
    "end": "328639"
  },
  {
    "text": "will will execute on the main system but the fpga is the main locus of control",
    "start": "328639",
    "end": "334400"
  },
  {
    "text": "of your calculation another model which is sort of the same idea as using what we call storage appliance so in this",
    "start": "334400",
    "end": "340240"
  },
  {
    "text": "case the idea is if you can put an fpga very close to your storage and if you can architect your system to have much",
    "start": "340240",
    "end": "346080"
  },
  {
    "text": "higher bandwidth between your storage devices say your flash or or a solid state disk or even your regular disk you",
    "start": "346080",
    "end": "352960"
  },
  {
    "text": "can by putting processing logic very close to that you can get higher bandwidth and so if you can do some of",
    "start": "352960",
    "end": "358880"
  },
  {
    "text": "your query processing very close to the storage you can reduce the bandwidth demands on your system bus and you can",
    "start": "358880",
    "end": "365039"
  },
  {
    "text": "basically offload a lot of your data processing in your big data world very cl uh very close to storage so this",
    "start": "365039",
    "end": "371520"
  },
  {
    "text": "is what we call the storage appliance uh platform this is very popular right now in big data",
    "start": "371520",
    "end": "377360"
  },
  {
    "text": "database applications and so forth and it just has advantages ibm certainly has some offerings in this as well as other",
    "start": "377360",
    "end": "383199"
  },
  {
    "text": "companies so i hope i've convinced you that there are good reasons and to use uh these",
    "start": "383199",
    "end": "388479"
  },
  {
    "text": "architectures and we're seeing more and more of these coming along yet most of you in the room had very",
    "start": "388479",
    "end": "394960"
  },
  {
    "start": "391000",
    "end": "452000"
  },
  {
    "text": "little or no experience with this one of the reasons why is because",
    "start": "394960",
    "end": "400000"
  },
  {
    "text": "doing this kind of heterogeneous programming is not very accessible to mainstream software engineers today",
    "start": "400000",
    "end": "406240"
  },
  {
    "text": "one of the reasons is that each of these devices demands a different programming model right now we're all very happy programming in",
    "start": "406240",
    "end": "412800"
  },
  {
    "text": "high-level languages like java or python or whatever for our cpus and they",
    "start": "412800",
    "end": "417919"
  },
  {
    "text": "provide a very high level of abstraction if you want to program general purpose gpus",
    "start": "417919",
    "end": "423039"
  },
  {
    "text": "the current state of the art is to use something like cuda or opencl these are fairly low level",
    "start": "423039",
    "end": "428479"
  },
  {
    "text": "c apis and subsets of c which allow you to use the gpu but you",
    "start": "428479",
    "end": "433759"
  },
  {
    "text": "still have to program at a much lower level of abstraction you have to learn a new programming model you have to manually manage communication between",
    "start": "433759",
    "end": "441199"
  },
  {
    "text": "devices you have to be very careful about structuring your calculation to use the gpu effectively so it's",
    "start": "441199",
    "end": "447039"
  },
  {
    "text": "relatively painful especially compared to our experiences in programming general purpose processors however programming",
    "start": "447039",
    "end": "453680"
  },
  {
    "start": "452000",
    "end": "552000"
  },
  {
    "text": "gpus makes is like heaven compared to programming fpgas those of you who have done this",
    "start": "453680",
    "end": "459599"
  },
  {
    "text": "know you know so first of all programming fpgas most of the people who program fpgas they actually don't say",
    "start": "459599",
    "end": "465039"
  },
  {
    "text": "they program so you don't actually program hardware you design it you're a hardware designer and you create a",
    "start": "465039",
    "end": "470560"
  },
  {
    "text": "design and you load the design onto the chip and we don't even think of it and that's why these are design languages vhdl and verilog and there's a very",
    "start": "470560",
    "end": "478400"
  },
  {
    "text": "these are very extremely low level uh basically circuit design languages",
    "start": "478400",
    "end": "483599"
  },
  {
    "text": "that describe your computation you don't have any benefits on the fpga of an operating system or device drivers or",
    "start": "483599",
    "end": "490800"
  },
  {
    "text": "memory managers or any of the things we expect you know the the system software which makes writing",
    "start": "490800",
    "end": "496000"
  },
  {
    "text": "programs easy so it's really a very low level uh very painful experience compared to writing software to be able",
    "start": "496000",
    "end": "502560"
  },
  {
    "text": "to uh use an fpga in a heterogeneous system um so what we're trying to do is see how",
    "start": "502560",
    "end": "510720"
  },
  {
    "text": "much we can do to fix this so the goal of our project it's called liquid metal and we have a programming language called lime and our",
    "start": "510720",
    "end": "517919"
  },
  {
    "text": "goal really is to try to make using heterogeneous systems with a mix of these kinds of devices accessible",
    "start": "517919",
    "end": "524000"
  },
  {
    "text": "to a mainstream software engineer programmer so that programming a heterogeneous system with a gpu or fpga",
    "start": "524000",
    "end": "531279"
  },
  {
    "text": "is not that much harder than as it is programming in a high-level language on a cpu today and",
    "start": "531279",
    "end": "537440"
  },
  {
    "text": "we think that if we're able to do this you know we can make these platforms more accessible and uh the platforms are coming right",
    "start": "537440",
    "end": "543360"
  },
  {
    "text": "now a very small elite of uh customers are using them we expect that due to the",
    "start": "543360",
    "end": "550240"
  },
  {
    "text": "trends in physics and the the the the just benefits of using these architectures there'll be more and more",
    "start": "550240",
    "end": "556080"
  },
  {
    "start": "552000",
    "end": "597000"
  },
  {
    "text": "demand we see this coming along so we're going to try to make it more accessible and more like mainstream programming so",
    "start": "556080",
    "end": "562320"
  },
  {
    "text": "our strategy is we have a single language called lime which i'm going to describe in some detail which looks very much like java",
    "start": "562320",
    "end": "569360"
  },
  {
    "text": "we have a pretty rich tool chain to try to make programming in lime resemble programming in java as far as",
    "start": "569360",
    "end": "575920"
  },
  {
    "text": "the richness of the tools and we'll show you some of the details of how we go that and also we try to provide especially runtime systems",
    "start": "575920",
    "end": "582240"
  },
  {
    "text": "uh to on which the system runs to hide many of the low-level details so that'll be the the content of the talk is",
    "start": "582240",
    "end": "588320"
  },
  {
    "text": "describing our approach to this before i go on that slide i was i'll skip any questions before i get into the",
    "start": "588320",
    "end": "594959"
  },
  {
    "text": "details of the programming model all right so let's talk about liquid metal so our philosophy",
    "start": "594959",
    "end": "601600"
  },
  {
    "start": "597000",
    "end": "679000"
  },
  {
    "text": "is that there is a single programming language lime but we're not going to guarantee that we can compile all of lime to every device",
    "start": "601600",
    "end": "609200"
  },
  {
    "text": "so there'll be different subsets of the language that can be compiled to each device depending on the constraints of",
    "start": "609200",
    "end": "614560"
  },
  {
    "text": "the device so what we have is the line compiler will spit out",
    "start": "614560",
    "end": "620240"
  },
  {
    "text": "more than one version of different it's a task-based program model of different tasks",
    "start": "620240",
    "end": "626160"
  },
  {
    "text": "depending on what sort of devices it can exploit for each piece of code so all the code",
    "start": "626160",
    "end": "631440"
  },
  {
    "text": "can be implemented to run on a jvm we have a we can spit out jvm byte code and run on a cpu so you can write a full",
    "start": "631440",
    "end": "637760"
  },
  {
    "text": "program using any of the language constructs and it'll run on byte code if you want to run a particular task or",
    "start": "637760",
    "end": "643200"
  },
  {
    "text": "a particular routine or a particular part of code on a device such as a gpu or an fpga",
    "start": "643200",
    "end": "649760"
  },
  {
    "text": "the compiler may or may not be able to generate code and so the philosophy is that the compiler you can write general",
    "start": "649760",
    "end": "656720"
  },
  {
    "text": "code and then the compiler has exclusions the compiler will give a lot of feedback on reasons why",
    "start": "656720",
    "end": "662720"
  },
  {
    "text": "it's not being able to compile a particular piece of code down to a device and we try to make it as easy possible then for you to refactor your",
    "start": "662720",
    "end": "669279"
  },
  {
    "text": "code to satisfy the compiler to tell the compiler more information that it needs to know in order to",
    "start": "669279",
    "end": "675600"
  },
  {
    "text": "generate good code for a particular device and i'll get into some details of what this looks like so what is lime",
    "start": "675600",
    "end": "681680"
  },
  {
    "text": "lime at a very high level is very much like java but we add a couple of other constructs which allow us to compile",
    "start": "681680",
    "end": "687920"
  },
  {
    "text": "down to these devices which basically fall into two categories one is isolation so isolation is extra",
    "start": "687920",
    "end": "694320"
  },
  {
    "text": "information to java code which allows us to move computation around and i'll show you uh some of the lime constructs the",
    "start": "694320",
    "end": "700720"
  },
  {
    "text": "local keyword and immutable types which uh enforce isolation on parts of the language",
    "start": "700720",
    "end": "706480"
  },
  {
    "text": "which allow us to accelerate it and then a lot of it's about abstract parallelism so we",
    "start": "706480",
    "end": "711600"
  },
  {
    "text": "in order for the compiler to exploit highly parallel hardware and to move and schedule",
    "start": "711600",
    "end": "717600"
  },
  {
    "text": "computation around it needs to have a very good idea of the parallelism so we're not taking a",
    "start": "717600",
    "end": "723440"
  },
  {
    "text": "super compiler approach we're not asking the compiler to infer parallelism from sequential code or",
    "start": "723440",
    "end": "729120"
  },
  {
    "text": "anything like that instead what we have are fairly high level constructs into the language that the programmer can use",
    "start": "729120",
    "end": "735360"
  },
  {
    "text": "to tell the compiler this is this style of parallelism and once things type check the compiler knows okay",
    "start": "735360",
    "end": "741519"
  },
  {
    "text": "it it's a way for the programmer to communicate parallel structures to the compiler and then the compiler can map",
    "start": "741519",
    "end": "747200"
  },
  {
    "text": "them down to the hardware so i'll describe these in a little more detail so our development experience as i said",
    "start": "747200",
    "end": "754800"
  },
  {
    "start": "751000",
    "end": "789000"
  },
  {
    "text": "is the idea is we're very big on an incremental migration incremental refactoring so the idea is you would",
    "start": "754800",
    "end": "761040"
  },
  {
    "text": "prototype uh your code basically in java so you could start by just getting a functional version which works in java and to do",
    "start": "761040",
    "end": "768000"
  },
  {
    "text": "this it's it's we have an id which is an eclipse-based id gives you all the benefits of the",
    "start": "768000",
    "end": "773920"
  },
  {
    "text": "java development environment including editors and debugging and so forth and then we want you to incrementally",
    "start": "773920",
    "end": "779680"
  },
  {
    "text": "migrate the parts of your code you want to accelerate by adding these lime language constructs",
    "start": "779680",
    "end": "785200"
  },
  {
    "text": "which express the parallelism the compiler needs to know any questions yet before i dive into the",
    "start": "785200",
    "end": "790800"
  },
  {
    "text": "details one question some of these isolation balance based they look like the ones",
    "start": "790800",
    "end": "795839"
  },
  {
    "text": "that were present in x10 this is quite different from x10",
    "start": "795839",
    "end": "801440"
  },
  {
    "text": "yeah i can get to more details i used to work on x10 as well um",
    "start": "801440",
    "end": "806480"
  },
  {
    "text": "it's a let me present what we have than i could describe one thing at a very high level",
    "start": "806480",
    "end": "814320"
  },
  {
    "text": "we're not trying to solve distributed computing problem we're not trying to express uh clust distributed memory cluster",
    "start": "814320",
    "end": "821200"
  },
  {
    "text": "computing which is the main focus of x10 so we're not trying to scale out to a cluster of workstations our constructs are really",
    "start": "821200",
    "end": "827279"
  },
  {
    "text": "designed the idea is you have a single node with devices attached and managing the details of particular",
    "start": "827279",
    "end": "834240"
  },
  {
    "text": "devices we're not solving the problem of how you would communicate across nodes to do that you would use message passing",
    "start": "834240",
    "end": "840079"
  },
  {
    "text": "or x10 or some or some other model but that's outside the scope of what we're trying to solve any other questions",
    "start": "840079",
    "end": "847519"
  },
  {
    "text": "go ahead so you said you can incrementally move stuff say to the gpu or into fpga so you do you need standard",
    "start": "849040",
    "end": "857120"
  },
  {
    "text": "hardware for that that you have standard where your system works or is this flexible",
    "start": "857120",
    "end": "863600"
  },
  {
    "text": "um so it's different for for different platforms basically there'll be a set of",
    "start": "863600",
    "end": "868639"
  },
  {
    "text": "platforms which we support and we can handle those so for the gpus we basically compile down to opencl",
    "start": "868639",
    "end": "875600"
  },
  {
    "text": "which is a standard for uh gpu hardware which is supported more or less by nvidia and ati and intel and",
    "start": "875600",
    "end": "885040"
  },
  {
    "text": "all the vendors for fpgas there are really only two vendors that dominate the market which are xilinx and altera",
    "start": "885040",
    "end": "890880"
  },
  {
    "text": "and we have support for both their tool chains so as far as gpus and fpgas are concerned we've got most of the world",
    "start": "890880",
    "end": "896839"
  },
  {
    "text": "covered yeah but the integration of the path so the cpu has to talk to your fpga in some",
    "start": "896839",
    "end": "903360"
  },
  {
    "text": "way yeah that's our problem so that's what we do for for for a living yeah that's what that's that's that's",
    "start": "903360",
    "end": "909440"
  },
  {
    "text": "what what what we do for the rest of my life is any other",
    "start": "909440",
    "end": "916160"
  },
  {
    "text": "all right so let's try to i'm going to try to out so i think the best way to try to describe",
    "start": "917040",
    "end": "922399"
  },
  {
    "text": "at least the flavor of the programming language in a very short talk is just by walking through an example so i'm just going to walk through a",
    "start": "922399",
    "end": "928399"
  },
  {
    "text": "simple example which is an n-body simulation um i'll show a demo later",
    "start": "928399",
    "end": "934240"
  },
  {
    "text": "so we'll just consider one iteration of an n-body simulation the idea is here we have a bunch of particles perhaps you're",
    "start": "934240",
    "end": "940480"
  },
  {
    "text": "familiar with these kind of computations these particles might be think of say stars in a galaxy or maybe they're molecules in a fluid and they interact",
    "start": "940480",
    "end": "947040"
  },
  {
    "text": "by some force gravity or some other physical force and we basically have an n squared calculation",
    "start": "947040",
    "end": "952880"
  },
  {
    "text": "where in each time step each particle will exert force on every other particle according to a physical law and so",
    "start": "952880",
    "end": "959120"
  },
  {
    "text": "there's two there's basically three steps in the calculation you generate the positions of the particles you compute the force on each",
    "start": "959120",
    "end": "966160"
  },
  {
    "text": "on each particle and this is the expensive part of the calculation this is the naive algorithms are n squared so",
    "start": "966160",
    "end": "971279"
  },
  {
    "text": "each particle affects every other particle and then there's a force accumulator once you've computed all the forces you sum them up and then you'll",
    "start": "971279",
    "end": "977600"
  },
  {
    "text": "move the particles to their new position and then repeat so if we wanted to do the accelerator model it certainly makes",
    "start": "977600",
    "end": "983440"
  },
  {
    "text": "sense very at a high level since the force computation is the n squared computation the rest of them are linear we'll want to we'll",
    "start": "983440",
    "end": "989680"
  },
  {
    "text": "start off by saying we want to accelerate the computationally the force calculation and that's what i'll walk you through",
    "start": "989680",
    "end": "996160"
  },
  {
    "start": "995000",
    "end": "1469000"
  },
  {
    "text": "so you start as i said you would start so we'll imagine that we already had java code to do this and started with something that looks like",
    "start": "996160",
    "end": "1002240"
  },
  {
    "text": "java code the end body class um the first thing we do is we need to tell the compiler all right we're going to have a task parallel structure so",
    "start": "1002240",
    "end": "1010320"
  },
  {
    "text": "we need to tell the line compiler okay we've got three tasks here this is the structure of our our computation and",
    "start": "1010320",
    "end": "1016320"
  },
  {
    "text": "these are are the boundaries at which we're going to want to move code around so the way we do that in lime is we",
    "start": "1016320",
    "end": "1022240"
  },
  {
    "text": "apply a task operator which is a new keyword to a method declaration of a java method so",
    "start": "1022240",
    "end": "1028240"
  },
  {
    "text": "the code highlighted in green here is saying what we're doing is we're setting up three tasks we're going to turn the",
    "start": "1028240",
    "end": "1033438"
  },
  {
    "text": "particle generator method into a task the force computation method into a task and the force accumulator method into a",
    "start": "1033439",
    "end": "1040000"
  },
  {
    "text": "task and these are just regular java methods ignore some of the strange array stuff",
    "start": "1040000",
    "end": "1046000"
  },
  {
    "text": "for now and then we have the connect operator which is the equals greater than sign this virtualizes uh",
    "start": "1046000",
    "end": "1051679"
  },
  {
    "text": "communication so this is saying that the output of the first task the particle generator will be fed as the input to",
    "start": "1051679",
    "end": "1057200"
  },
  {
    "text": "the second task force computation the output of that task will be uh fed into the third test which is the force com",
    "start": "1057200",
    "end": "1064080"
  },
  {
    "text": "accumulator now so so what we have here is very much a test parallel coarse grained data flow programming model and",
    "start": "1064080",
    "end": "1070720"
  },
  {
    "text": "that's at least the outer level of parallelism by which you'll express your computation um so",
    "start": "1070720",
    "end": "1076799"
  },
  {
    "text": "for the rest of talk i think at least on this example i'm going to focus a bit on the gpu model of doing the data parallel",
    "start": "1076799",
    "end": "1082799"
  },
  {
    "text": "force computation but one thing i want to point out at this point is this task parallel model is very much in the spirit of",
    "start": "1082799",
    "end": "1089520"
  },
  {
    "text": "hardware design where you lay out data flow graphs of blocks and there are constructs in the language to do splits",
    "start": "1089520",
    "end": "1096640"
  },
  {
    "text": "and joins and matching and rate matching and so forth so very often for hardware what you'll do",
    "start": "1096640",
    "end": "1102880"
  },
  {
    "text": "is you'll set up a very a fairly rich task graph which maps down to hardware and this is the kind of thing that runs",
    "start": "1102880",
    "end": "1108720"
  },
  {
    "text": "well in hardware because basically each task if it's in a pipeline like this uh corresponds to a you know a pipeline",
    "start": "1108720",
    "end": "1114880"
  },
  {
    "text": "cycle and a pipeline design and so it's very much in the style of how people do hardware design",
    "start": "1114880",
    "end": "1121200"
  },
  {
    "text": "um i hope that's clear i'll go through a few more slides and then clarify anything that needs to be",
    "start": "1121200",
    "end": "1126640"
  },
  {
    "text": "clarified so once you've identified the task graph which is what we've done here um the",
    "start": "1126640",
    "end": "1132960"
  },
  {
    "text": "programmer will tell the compiler that i want to relocate a particular task and we do that with these relocation",
    "start": "1132960",
    "end": "1138799"
  },
  {
    "text": "brackets and that's basically telling the compiler that in this case i want this force computation task to be",
    "start": "1138799",
    "end": "1144559"
  },
  {
    "text": "accelerated and then depending on how i've configured the the compiler toolchain it'll decide which which back",
    "start": "1144559",
    "end": "1149760"
  },
  {
    "text": "end it's going to try to so let's assume for the moment for this thing that i've i've configured my tool chain so that",
    "start": "1149760",
    "end": "1155039"
  },
  {
    "text": "accelerated tasks the compiler is just going to assume try to send the accelerated task to the gpu",
    "start": "1155039",
    "end": "1160799"
  },
  {
    "text": "now what happens is once you start to use these in shore brass brackets",
    "start": "1160799",
    "end": "1165840"
  },
  {
    "text": "some of these stricter type checking rules come into play so at this point the compiler",
    "start": "1165840",
    "end": "1171600"
  },
  {
    "text": "will start to check that this force computation task not only that it's",
    "start": "1171600",
    "end": "1177600"
  },
  {
    "text": "line but that it actually obeys the constraints that it needs to know in order to ship it off to the gpu so in",
    "start": "1177600",
    "end": "1182960"
  },
  {
    "text": "particular the the properties i mentioned before about isolation and parallelism and so",
    "start": "1182960",
    "end": "1188880"
  },
  {
    "text": "in particular you'll have to start telling the compiler information about the force computation task so i'll get",
    "start": "1188880",
    "end": "1194559"
  },
  {
    "text": "into a little that over the over the next few slides but just to show you um the method declaration in particular",
    "start": "1194559",
    "end": "1200720"
  },
  {
    "text": "i've said local this is going to basically enforce that this forced computation is isolated so we don't have",
    "start": "1200720",
    "end": "1206559"
  },
  {
    "text": "a general shared memory model each task runs in an isolated address space so they can't read and write",
    "start": "1206559",
    "end": "1213360"
  },
  {
    "text": "random access memory across it the only sharing of state between tasks is through the inputs and outputs",
    "start": "1213360",
    "end": "1219440"
  },
  {
    "text": "and so the local qualifier guarantees checks tells the compiler to check that",
    "start": "1219440",
    "end": "1225840"
  },
  {
    "text": "that property holds we also have these immutability constructs which i'll describe a bit on the next slide i",
    "start": "1225840",
    "end": "1231520"
  },
  {
    "text": "believe yeah so let's look at the code a little bit more so what do we need to do in order to get this computation running on",
    "start": "1231520",
    "end": "1237200"
  },
  {
    "text": "a gpu so i mentioned the local local says this is an isolated task what that means is basically the compiler at this",
    "start": "1237200",
    "end": "1243679"
  },
  {
    "text": "point is going to check that the inputs and outputs to this task are values that is they're",
    "start": "1243679",
    "end": "1249200"
  },
  {
    "text": "immutable so that they can't be written in writing written or read",
    "start": "1249200",
    "end": "1254799"
  },
  {
    "text": "or observed changing by other parts of the system while it's in transit",
    "start": "1254799",
    "end": "1261200"
  },
  {
    "text": "we're going to enforce immutability which basically tells us this value property for the inputs and outputs so",
    "start": "1261200",
    "end": "1266720"
  },
  {
    "text": "that funny array syntax we have on the inputs and outputs of force computation basically this is",
    "start": "1266720",
    "end": "1271840"
  },
  {
    "text": "saying that the input to the force computation method which we're turning into a task is an array of four tuples of floats so",
    "start": "1271840",
    "end": "1279120"
  },
  {
    "text": "it's a two-dimensional array but it's immutable so nobody else is going to be scribbling into it while this task is running and it's",
    "start": "1279120",
    "end": "1284880"
  },
  {
    "text": "going to return an array of three tuples which is the forces which is also immutable the local",
    "start": "1284880",
    "end": "1290559"
  },
  {
    "text": "keyword also tells compower to check that this this calculation is transitively isolated so in particular can't read or",
    "start": "1290559",
    "end": "1297280"
  },
  {
    "text": "write any uh global mutable state so with that information the compiler knows",
    "start": "1297280",
    "end": "1302880"
  },
  {
    "text": "that it's safe to relocate this task and that it won't change the semantics of the program in any way",
    "start": "1302880",
    "end": "1308480"
  },
  {
    "text": "now we also have in this case using the map operator the at sign so what we're going to do is",
    "start": "1308480",
    "end": "1315600"
  },
  {
    "text": "this is a data parallel application of a function it's the same as map if familiar with map and list",
    "start": "1315600",
    "end": "1321520"
  },
  {
    "text": "or any other functional languages which is basically saying take this function in this case the force function and",
    "start": "1321520",
    "end": "1326960"
  },
  {
    "text": "apply it to each particle to each element of in this case an array",
    "start": "1326960",
    "end": "1332159"
  },
  {
    "text": "so basically this tells the compiler that we have a data parallel computation and by once again using the same sort of",
    "start": "1332159",
    "end": "1337919"
  },
  {
    "text": "annotations local and immutability we guarantee that there are no in effect loop carried dependencies we guarantee",
    "start": "1337919",
    "end": "1344480"
  },
  {
    "text": "that this actually is a data parallel computation and that we can exec effectively if we were running on a cpu",
    "start": "1344480",
    "end": "1349760"
  },
  {
    "text": "we could execute these in any order and that means that we can use the gpu hardware we can fire it off in parallel",
    "start": "1349760",
    "end": "1354880"
  },
  {
    "text": "and we don't have to worry about sharing or the semantics so this is basically the type checking here",
    "start": "1354880",
    "end": "1361760"
  },
  {
    "text": "tells the compiler okay this is safe to paralyze and it won't change semantics now if you violated these type checking",
    "start": "1361760",
    "end": "1367280"
  },
  {
    "text": "you'll get feedback during the ide saying this this this method needs to be local or this parameter is not a value",
    "start": "1367280",
    "end": "1373520"
  },
  {
    "text": "or so forth and so the process of of going from vanilla java code to something like this that can tell that",
    "start": "1373520",
    "end": "1380320"
  },
  {
    "text": "can be accelerated is effectively a dialogue with the compiler where the compiler starts to give you warnings and you can",
    "start": "1380320",
    "end": "1386720"
  },
  {
    "text": "go in and fix them and it's really not usually if your algorithm is parallel uh we think it's not not too burdensome to",
    "start": "1386720",
    "end": "1393200"
  },
  {
    "text": "do that so i mentioned the map operator this is a way of describing data parallel",
    "start": "1393200",
    "end": "1399760"
  },
  {
    "text": "operations we have you know fairly rich well the syntax is really pretty simple",
    "start": "1399760",
    "end": "1406240"
  },
  {
    "text": "but it allows us to express a bunch of patterns of data parallel operations so we can map an",
    "start": "1406240",
    "end": "1412240"
  },
  {
    "text": "operator so when we say that c equals a at plus b this is mapping the plus operator to over each of the arrays a",
    "start": "1412240",
    "end": "1419120"
  },
  {
    "text": "plus b and this does what you expect as as illustrated here is that we'll do an element wise addition",
    "start": "1419120",
    "end": "1425039"
  },
  {
    "text": "of the arrays a and b producing an array c there are many other patterns you can use to do data parallel",
    "start": "1425039",
    "end": "1431280"
  },
  {
    "text": "so you can do you can apply methods uh in parallel so this float c equals map the add function",
    "start": "1431280",
    "end": "1437440"
  },
  {
    "text": "a and b is exactly the same as mapping the operator and then you can also do lift lifting or promotion or carrying",
    "start": "1437440",
    "end": "1444480"
  },
  {
    "text": "which is for example you can add one to each element of array and by using this pound sign",
    "start": "1444480",
    "end": "1449520"
  },
  {
    "text": "it's basically saying lift this scalar value into array as an argument to the map function",
    "start": "1449520",
    "end": "1455520"
  },
  {
    "text": "so that's the basics of data parallel computation i hope that was clear any questions before i go on",
    "start": "1455520",
    "end": "1463440"
  },
  {
    "text": "right so what we have here i i showed you the code for the end body calculation those are if you had",
    "start": "1464799",
    "end": "1470880"
  },
  {
    "start": "1469000",
    "end": "1686000"
  },
  {
    "text": "programmed with opencl or cuda you know that this is much higher level and much more abstract than the current state of",
    "start": "1470880",
    "end": "1477520"
  },
  {
    "text": "the art of programming uh using in this case opencl where you have to do a lot of",
    "start": "1477520",
    "end": "1483200"
  },
  {
    "text": "system level queue setup and compiling and management and manual communication",
    "start": "1483200",
    "end": "1488320"
  },
  {
    "text": "you know we're programming a much higher level of abstraction for the gpu um if we're programmed for the fpga it's",
    "start": "1488320",
    "end": "1495200"
  },
  {
    "text": "if we're somewhat higher level of obstruction for gpus we're in incred several orders of magnitude much",
    "start": "1495200",
    "end": "1501200"
  },
  {
    "text": "higher level of abstraction than you would write for an fpga um if you're programming in hdl or verilog",
    "start": "1501200",
    "end": "1508480"
  },
  {
    "text": "um you know even very very simple user logic which you would express in java expands to very complicated",
    "start": "1508480",
    "end": "1514880"
  },
  {
    "text": "state machines with low level driving wires and concurrency and checking signals and",
    "start": "1514880",
    "end": "1520559"
  },
  {
    "text": "timing constraints in in verilog it's really a very low level program model just to express the user",
    "start": "1520559",
    "end": "1526240"
  },
  {
    "text": "logic and expressing the user logic in a heterogeneous system is not really the hard part",
    "start": "1526240",
    "end": "1531360"
  },
  {
    "text": "the hard part is managing the communication between the fpga and the host computer um it's not like",
    "start": "1531360",
    "end": "1537840"
  },
  {
    "text": "you take an fpga and plug it into your usb and and the and the operating system recognizes the device and and you start",
    "start": "1537840",
    "end": "1544320"
  },
  {
    "text": "using it transparently you know this is really a raw hunk of silicon it doesn't come with an operating system doesn't",
    "start": "1544320",
    "end": "1549440"
  },
  {
    "text": "come with anything so you have to write or find or acquire the ip",
    "start": "1549440",
    "end": "1554559"
  },
  {
    "text": "to implement the device the intimate the drivers on the hardware and to have some sort of runtime system on the hardware",
    "start": "1554559",
    "end": "1560880"
  },
  {
    "text": "to do all the routing between that and so it's really a tremendous amount of work just to build the basic",
    "start": "1560880",
    "end": "1566000"
  },
  {
    "text": "communication infrastructure between a device and a cpu and",
    "start": "1566000",
    "end": "1571919"
  },
  {
    "text": "so the gentleman asked a question you know this is the kind of thing that we have done and we've done it once and we can do it",
    "start": "1571919",
    "end": "1578480"
  },
  {
    "text": "once and then our compiler can reuse it so we have built the runtime system which",
    "start": "1578480",
    "end": "1584159"
  },
  {
    "text": "manages the communication our compiler knows how to use it uh so basically the programmer doesn't have to worry about",
    "start": "1584159",
    "end": "1589279"
  },
  {
    "text": "it and doesn't have to know it and this is we think a tremendous value compared to the alternative of doing this from scratch yes",
    "start": "1589279",
    "end": "1597960"
  },
  {
    "text": "so we're compiling verilog we're compiling directly down to hardware and then our hardware our circuits",
    "start": "1609200",
    "end": "1614720"
  },
  {
    "text": "basically our runtime system is calling it a virtual machine is perhaps",
    "start": "1614720",
    "end": "1619840"
  },
  {
    "text": "a little too glorious it's a bunch of cues with control signals and and arbitration logic",
    "start": "1619840",
    "end": "1626400"
  },
  {
    "text": "basically to route data from the pins to user logic so you would take our user",
    "start": "1626400",
    "end": "1631679"
  },
  {
    "text": "logic which basically exposes the number of wires and then this is what our compiler does i mean the programmer never sees this",
    "start": "1631679",
    "end": "1638000"
  },
  {
    "text": "the programmer just writes local into fubar what happens to the compiler you know generates verilog which exposes a",
    "start": "1638000",
    "end": "1643120"
  },
  {
    "text": "bunch of wires our tool chain hooks up those wires to the wires of our internal cues and then our our queues",
    "start": "1643120",
    "end": "1651120"
  },
  {
    "text": "talk a protocol over say pcie to our host we have drivers that know how to",
    "start": "1651120",
    "end": "1656640"
  },
  {
    "text": "talk the same protocol",
    "start": "1656640",
    "end": "1659600"
  },
  {
    "text": "yeah that's right i mean it's really a bus and and control logic",
    "start": "1664640",
    "end": "1671120"
  },
  {
    "text": "any other questions so we think you know",
    "start": "1671440",
    "end": "1677919"
  },
  {
    "text": "compared to the alternatives of programming fpgas we think we have a very compelling story as far as productivity we're saving a tremendous",
    "start": "1677919",
    "end": "1684640"
  },
  {
    "text": "amount of work um just in writing the code but a lot of the story here is not just",
    "start": "1684640",
    "end": "1690240"
  },
  {
    "start": "1686000",
    "end": "1802000"
  },
  {
    "text": "about the code it's really the tool chain as well which",
    "start": "1690240",
    "end": "1696159"
  },
  {
    "text": "especially for fpgas uh but even even for for for gpus where the tools",
    "start": "1696159",
    "end": "1701840"
  },
  {
    "text": "and the tool chain and the the process by where you use these devices right now the state of the art is you know very",
    "start": "1701840",
    "end": "1707440"
  },
  {
    "text": "primitive compared to what we're used to with software it's almost like going back in time before the before the",
    "start": "1707440",
    "end": "1712720"
  },
  {
    "text": "invention of fortran and try to show you you know what some of our tools do and what the alternative would be",
    "start": "1712720",
    "end": "1718159"
  },
  {
    "text": "uh with the current practice so for example compiling the code you know in our system basically compiling the code",
    "start": "1718159",
    "end": "1724720"
  },
  {
    "text": "we have eclipse uh windows and launchers so you would open up a in our id you would open up a",
    "start": "1724720",
    "end": "1730799"
  },
  {
    "text": "specialized uh compiler wizard and which would walk you through how to configure your compiling",
    "start": "1730799",
    "end": "1736559"
  },
  {
    "text": "for the fpga and then you hit compile you know the alternative using the tool chain that as people do right",
    "start": "1736559",
    "end": "1743039"
  },
  {
    "text": "now is really relatively painful you have to use multiple tools it's all vendor specific",
    "start": "1743039",
    "end": "1748720"
  },
  {
    "text": "you have to write a lot of logic and test bench just to drive your logic to test it work with simulators and and so",
    "start": "1748720",
    "end": "1755200"
  },
  {
    "text": "forth and you know it's a very long tedious process that takes a lot of",
    "start": "1755200",
    "end": "1760640"
  },
  {
    "text": "expertise and this is part of the reason this is a large part of the reason why it's very hard to get started using",
    "start": "1760640",
    "end": "1766399"
  },
  {
    "text": "fpgas you know it takes a lot of expertise just to learn a particular vendor's tool chain and then if you learn the xylinks toolchain that's not",
    "start": "1766399",
    "end": "1772559"
  },
  {
    "text": "necessarily going to help you with learning the altera toolchain or if intel's going to come out with something so it's all you know completely",
    "start": "1772559",
    "end": "1779200"
  },
  {
    "text": "different from what we're used to uh in software where it's almost like going back in time to",
    "start": "1779200",
    "end": "1785360"
  },
  {
    "text": "to the days before programming languages so once again as far as productivity i think you know we're making it much much",
    "start": "1785360",
    "end": "1792320"
  },
  {
    "text": "easier you things that would take at least days if not more to learn how to do and to to configure and get working",
    "start": "1792320",
    "end": "1798080"
  },
  {
    "text": "you know we hide behind a wizard and the system drives automatically debugging",
    "start": "1798080",
    "end": "1803600"
  },
  {
    "start": "1802000",
    "end": "1879000"
  },
  {
    "text": "is a similar story you know in our system if our if our system is implemented correctly",
    "start": "1803600",
    "end": "1809360"
  },
  {
    "text": "the semantics of the program do not change whether you run them whether you run it on the bytecode backend or whether you run it",
    "start": "1809360",
    "end": "1815600"
  },
  {
    "text": "on an accelerator the program should produce the exact same answers as long as our system is correct which",
    "start": "1815600",
    "end": "1821760"
  },
  {
    "text": "we hope it is so you can debug your user logic simply by debugging it as if you were debugging java code so we have a",
    "start": "1821760",
    "end": "1828480"
  },
  {
    "text": "eclipse debugger integrated into eclipse where you can set breakpoints and introspect and do all the nice things as if you were debugging java code you know",
    "start": "1828480",
    "end": "1835600"
  },
  {
    "text": "what people do with hardware design today basically is they look at waveforms and this is the level of debugging which",
    "start": "1835600",
    "end": "1842000"
  },
  {
    "text": "is the alternative today so you know we're at a fairly much higher level than that now we do",
    "start": "1842000",
    "end": "1847600"
  },
  {
    "text": "our tooling will allow you to um run on a simulator very easy and produce",
    "start": "1847600",
    "end": "1852640"
  },
  {
    "text": "waveforms so if you want to for example look at performance or look at what's going on you can get to this low-level",
    "start": "1852640",
    "end": "1857679"
  },
  {
    "text": "information but for the vast majority of programmers we anticipate they would never have to know that you know that there are things",
    "start": "1857679",
    "end": "1864640"
  },
  {
    "text": "such as clocks and signals and times and they could do the debugging at a much higher level of abstraction",
    "start": "1864640",
    "end": "1871120"
  },
  {
    "text": "uh once again the whole theme here is trying to bring current practice in this world much",
    "start": "1871120",
    "end": "1876480"
  },
  {
    "text": "closer to what a mainstream audience would be comfortable with running code is is much the similar story you know",
    "start": "1876480",
    "end": "1883120"
  },
  {
    "start": "1879000",
    "end": "1905000"
  },
  {
    "text": "running hitting a run button the ide as opposed to learning yet another tool which is what you have to do to to",
    "start": "1883120",
    "end": "1889360"
  },
  {
    "text": "load bit files onto an fpga and execute them and and so forth so there's just a",
    "start": "1889360",
    "end": "1895760"
  },
  {
    "text": "tremendous gap in the experience of using a modern tool chain versus what the current state of",
    "start": "1895760",
    "end": "1900960"
  },
  {
    "text": "the art is and using these devices today synthesis",
    "start": "1900960",
    "end": "1906960"
  },
  {
    "start": "1905000",
    "end": "2045000"
  },
  {
    "text": "um so in order to compile a verilog file or",
    "start": "1906960",
    "end": "1913039"
  },
  {
    "text": "vhdl file down to a circuit you you run a synthesis tool this is a vendor supply tool which basically lays",
    "start": "1913039",
    "end": "1919679"
  },
  {
    "text": "out the logic does the the design and tries to obey tries to satisfy clock",
    "start": "1919679",
    "end": "1924799"
  },
  {
    "text": "constraints and and layout constraints and floor planning and come up with a design so this is learning yet another",
    "start": "1924799",
    "end": "1930159"
  },
  {
    "text": "tool uh this takes a very long time to to to run synthesis on even smallest",
    "start": "1930159",
    "end": "1936000"
  },
  {
    "text": "user logic modules takes many minutes uh running for big designs can take hours",
    "start": "1936000",
    "end": "1942000"
  },
  {
    "text": "often you'll run a synthesis and it will just fail because the tool wasn't able to satisfy some timing constraints or",
    "start": "1942000",
    "end": "1948480"
  },
  {
    "text": "some clock constraints so this is yet another area where we can try to raise the level and the",
    "start": "1948480",
    "end": "1953600"
  },
  {
    "text": "experience we've decided to do this by a cloud service we call lime forge so our now for regular development you can",
    "start": "1953600",
    "end": "1960240"
  },
  {
    "text": "develop simply on your desktop you can run in a simulator on your desktop and and do all your development when you're",
    "start": "1960240",
    "end": "1965600"
  },
  {
    "text": "actually ready to deploy onto a physical device you need to run the synthesis tool you need to generate the the",
    "start": "1965600",
    "end": "1970880"
  },
  {
    "text": "physical uh bit file to load onto the device and now you have to do synthesis what we do",
    "start": "1970880",
    "end": "1977120"
  },
  {
    "text": "is to make this payphones we've implemented a cloud service which basically you submit your job",
    "start": "1977120",
    "end": "1982559"
  },
  {
    "text": "where you ship your logic and the the program over to the cloud and our cloud will now run",
    "start": "1982559",
    "end": "1989039"
  },
  {
    "text": "whatever it takes to try to synthesize this so basically it will in the background the cloud will spawn out a",
    "start": "1989039",
    "end": "1994640"
  },
  {
    "text": "bunch of different synthesis jobs and search for different clock frequencies try to maximize your clock frequency",
    "start": "1994640",
    "end": "2001039"
  },
  {
    "text": "there are lots of ways of tuning constraints to the synthesis tool so our cloud will search through different constraints and apply expertise",
    "start": "2001039",
    "end": "2008320"
  },
  {
    "text": "which our the experts on our team have learned over the years on how to drive these tools so basically we try to have",
    "start": "2008320",
    "end": "2015120"
  },
  {
    "text": "a somewhat intelligent intelligence maybe not the right word but a pretty advanced",
    "start": "2015120",
    "end": "2022159"
  },
  {
    "text": "system in the background using a lot of resources to try to get the best results from the synthesis tool and once again",
    "start": "2022159",
    "end": "2027360"
  },
  {
    "text": "take the burden of learning how to drive this tool correctly and how to optimize this tool away from the programmer and",
    "start": "2027360",
    "end": "2033840"
  },
  {
    "text": "try to do it automatically and we do this in the cloud because this is very resource intensive and so that's why we",
    "start": "2033840",
    "end": "2039279"
  },
  {
    "text": "farm it off as well as licensing issues it's easier to just install one copy of the vendor tools",
    "start": "2039279",
    "end": "2046080"
  },
  {
    "start": "2045000",
    "end": "2242000"
  },
  {
    "text": "so that's it i've at least i've tried to give you a flavor of what we're going for at least for developer experience",
    "start": "2046080",
    "end": "2051118"
  },
  {
    "text": "and what the system's like i could talk a little bit about the implementation um any questions at this point before i go on",
    "start": "2051119",
    "end": "2056960"
  },
  {
    "text": "you said um",
    "start": "2056960",
    "end": "2060520"
  },
  {
    "text": "you know the skill of the people who do fph nowadays with these tools they just will let go away you think or",
    "start": "2073119",
    "end": "2080638"
  },
  {
    "text": "will it still be relevant well it would be a bit like assembly",
    "start": "2080639",
    "end": "2086158"
  },
  {
    "text": "programming or you could think of it i'd like to say yes we'll put them all",
    "start": "2086159",
    "end": "2092079"
  },
  {
    "text": "out of business you know will and i think for the vast majority if we're successful",
    "start": "2092079",
    "end": "2097440"
  },
  {
    "text": "we will there there'll always be i think reasons why you want to go down to the",
    "start": "2097440",
    "end": "2103280"
  },
  {
    "text": "to low level design for some parts of your code or for some applications um",
    "start": "2103280",
    "end": "2108320"
  },
  {
    "text": "as far as our system is concerned there's a few reasons why you might want to so we've got a very high level programming language we've made it very",
    "start": "2108320",
    "end": "2114720"
  },
  {
    "text": "easy and safe to express parallelism but we've taken away some of the power to express arbitrary forms of parallelism",
    "start": "2114720",
    "end": "2122000"
  },
  {
    "text": "from the programmer so you can't express arbitrary concurrent structures um in our language so if you want to",
    "start": "2122000",
    "end": "2128880"
  },
  {
    "text": "write an arbitrary design with cues which are communicating on a clock by clock level and be very",
    "start": "2128880",
    "end": "2134480"
  },
  {
    "text": "careful you can't express it online in our language so for that you'll have to drop down",
    "start": "2134480",
    "end": "2139839"
  },
  {
    "text": "uh to a lower level and that's for example how we implement our own runtime system we don't uh",
    "start": "2139839",
    "end": "2146480"
  },
  {
    "text": "our own crossbar queues we we don't dog food it we we drop down the other thing is just the question of uh what's the",
    "start": "2146480",
    "end": "2153440"
  },
  {
    "text": "maturity of the compiler right now there's a tremendous gap between our source language and what we're",
    "start": "2153440",
    "end": "2158480"
  },
  {
    "text": "compiling to and the compiler is still relatively immature compared to compiling to assembly language on uh",
    "start": "2158480",
    "end": "2166000"
  },
  {
    "text": "on a cpu where even that took basically 30 years of development you know we're",
    "start": "2166000",
    "end": "2172400"
  },
  {
    "text": "solving a much harder problem our compiler is just not that mature yet so you're definitely going to give up",
    "start": "2172400",
    "end": "2177920"
  },
  {
    "text": "something probably if you use our our compiler either performance in terms of clock cycle or throughput or area more",
    "start": "2177920",
    "end": "2183680"
  },
  {
    "text": "likely our designs may not be quite so space efficient one thing we do have in our system is",
    "start": "2183680",
    "end": "2189920"
  },
  {
    "text": "what we call lni native interface so we do export interfaces whereby you can write your",
    "start": "2189920",
    "end": "2196000"
  },
  {
    "text": "own logic and link it in to our system so one possible use model",
    "start": "2196000",
    "end": "2201119"
  },
  {
    "text": "is uh if there's a write everything and if there are less performance critical parts of your",
    "start": "2201119",
    "end": "2206480"
  },
  {
    "text": "design perhaps logging or some control structure or some debugging code or ras code you might want to write that in our",
    "start": "2206480",
    "end": "2211920"
  },
  {
    "text": "system but for something which is really super performance critical you would write that by hand and then link it into our system just like you would do",
    "start": "2211920",
    "end": "2217920"
  },
  {
    "text": "perhaps native code into java today we can also go the other way we can simply export verilog from our tool",
    "start": "2217920",
    "end": "2224320"
  },
  {
    "text": "chain and you can take that verilog and do with it what you want so you can use our compiler basically as a like a c to",
    "start": "2224320",
    "end": "2229520"
  },
  {
    "text": "gates just as a higher level verilog design thing and then you can plug it into your own infrastructure and worry",
    "start": "2229520",
    "end": "2234560"
  },
  {
    "text": "about so it can go either way it depends on",
    "start": "2234560",
    "end": "2239680"
  },
  {
    "text": "how much pain and how much performance you want um so let me talk oh yeah i should get to a demo shouldn't i so",
    "start": "2239680",
    "end": "2246240"
  },
  {
    "start": "2242000",
    "end": "2283000"
  },
  {
    "text": "well i don't know i might regret saying that um so as i said our um",
    "start": "2246240",
    "end": "2252160"
  },
  {
    "text": "the implementation is something we call a lime virtual machine the line virtual machine",
    "start": "2252160",
    "end": "2257520"
  },
  {
    "text": "basically is our abstraction of a virtual machine of an operating system and parts of it will run on the cpu and",
    "start": "2257520",
    "end": "2263520"
  },
  {
    "text": "parts of it will run on each device and basically the job of the virtual machine is to take code load it run it and",
    "start": "2263520",
    "end": "2269119"
  },
  {
    "text": "manage the communication between different tasks and so this is basically our whole runtime system this is a lot of the",
    "start": "2269119",
    "end": "2275200"
  },
  {
    "text": "effort we put in i think i'll switch to a demo at this point",
    "start": "2275200",
    "end": "2281760"
  },
  {
    "start": "2283000",
    "end": "2374000"
  },
  {
    "text": "um so actually that end body calculation which i described has actually been running",
    "start": "2283599",
    "end": "2288720"
  },
  {
    "text": "while i've been giving the talk so here running the n-body calculation i'm actually right now running it",
    "start": "2288720",
    "end": "2295040"
  },
  {
    "text": "on the jvm and i guess the key number to look at right now is i'm getting about a gigaflop a second and if you look at the",
    "start": "2295040",
    "end": "2302320"
  },
  {
    "text": "you probably can barely discern the motion of the particles it's going pretty slow so i can tell the runtime",
    "start": "2302320",
    "end": "2307359"
  },
  {
    "text": "system migrate the force calculation which in my code was this compute forces method i can this is a panel exported by",
    "start": "2307359",
    "end": "2314640"
  },
  {
    "text": "a runtime system and if we tell the runtime system migrate it to gpu so what our system just did was take all the",
    "start": "2314640",
    "end": "2320480"
  },
  {
    "text": "state of that running task ship it over to the gpu connect all the all the cues and data",
    "start": "2320480",
    "end": "2325839"
  },
  {
    "text": "motions so that the data is now going over to the gpu and back for the force calculation task and now we're running",
    "start": "2325839",
    "end": "2331040"
  },
  {
    "text": "on the gpu uh i'm getting i guess about five gigaflops now hopefully you can at least uh see the data moving of course would",
    "start": "2331040",
    "end": "2337920"
  },
  {
    "text": "be much better on a machine with a much better gpu but the point i wanted to show you is that the",
    "start": "2337920",
    "end": "2344000"
  },
  {
    "text": "the runtime system is very dynamic it can move tests around because we have isolation things can move and everything just gets managed uh transparently this",
    "start": "2344000",
    "end": "2351839"
  },
  {
    "text": "is all the same code which happens to be running depending on where you want to run it if i had an fpga attached to the",
    "start": "2351839",
    "end": "2357680"
  },
  {
    "text": "system i could move it there as well so i just want to show you a demo that you know it's that easy to test moving things around",
    "start": "2357680",
    "end": "2365119"
  },
  {
    "text": "and to write code which works across different systems",
    "start": "2365119",
    "end": "2369838"
  },
  {
    "text": "um so in particular when we're using the gpu such as the demo i just showed you the real structure of the virtual machine",
    "start": "2375680",
    "end": "2381680"
  },
  {
    "text": "looks like this we've got part of the when i was running on the gpu just now part of the code was running in java",
    "start": "2381680",
    "end": "2386960"
  },
  {
    "text": "byte code we have uh a c glue layer which both talks jni to the jvm to get",
    "start": "2386960",
    "end": "2392960"
  },
  {
    "text": "data from there also manages the gpu device using the opencl api so data will get shipped from the jvm to this c",
    "start": "2392960",
    "end": "2399760"
  },
  {
    "text": "wrapper layer which is then managing the opencl kernel on the device and handling all the low-level protocols",
    "start": "2399760",
    "end": "2405760"
  },
  {
    "text": "and things used in opencl uh so that's what it looks like for for the gpu you could imagine similar structures",
    "start": "2405760",
    "end": "2412480"
  },
  {
    "text": "although it takes a lot more work for the fpga i won't get too much into",
    "start": "2412480",
    "end": "2418480"
  },
  {
    "start": "2416000",
    "end": "2529000"
  },
  {
    "text": "details of performance i guess i'll just try to say the bottom line of performance so you know i think we have a very good",
    "start": "2418480",
    "end": "2424079"
  },
  {
    "text": "story as far as productivity i think we i think we make a pretty convincing claim that you can be much more",
    "start": "2424079",
    "end": "2429520"
  },
  {
    "text": "productive at doing this kind of programming using our system uh the question is how much are you going to what what are the performance",
    "start": "2429520",
    "end": "2436240"
  },
  {
    "text": "consequences of doing that because using these devices in the end is all about performance or power performance uh so",
    "start": "2436240",
    "end": "2441760"
  },
  {
    "text": "there are two ways to ask this one question to answer this question one is to say if you're a java programmer and you start to use the system how much",
    "start": "2441760",
    "end": "2448000"
  },
  {
    "text": "faster than your original java are you going to get that is how effective can you be in using these accelerators or",
    "start": "2448000",
    "end": "2453440"
  },
  {
    "text": "perhaps if you're an expert you're the question you want to know is how much slower is my program going to be if i use this system than if i had done it",
    "start": "2453440",
    "end": "2458640"
  },
  {
    "text": "all by hand uh by an expert so we have to evaluate both uh just",
    "start": "2458640",
    "end": "2463680"
  },
  {
    "text": "i have numbers i probably won't go into them in two details the current status you know we're not trying to build a",
    "start": "2463680",
    "end": "2468720"
  },
  {
    "text": "magical super compiler our compiler is fairly sophisticated i think our group at ibm is very strong in compilers and",
    "start": "2468720",
    "end": "2475200"
  },
  {
    "text": "we'll do about as well as as we can um but you know on some benchmarks lime performs just as well as",
    "start": "2475200",
    "end": "2481839"
  },
  {
    "text": "a hand coated alternative and some not we have to worry a lot about communication computation ratio in particular so this is what we're working",
    "start": "2481839",
    "end": "2488400"
  },
  {
    "text": "on all the time i think our performance story in the gpu right now is pretty good",
    "start": "2488400",
    "end": "2493760"
  },
  {
    "text": "i won't go into these in too much detail but there was a paper we published this year at pldi programming language design",
    "start": "2493760",
    "end": "2499359"
  },
  {
    "text": "implementation conference and you know for a suite of gpu benchmarks",
    "start": "2499359",
    "end": "2505040"
  },
  {
    "text": "um you know we're able to get the dramatic speed speed ups that other people have reported on using a gpu",
    "start": "2505040",
    "end": "2511040"
  },
  {
    "text": "uh using our lime program for a variety of benchmarks and uh",
    "start": "2511040",
    "end": "2516560"
  },
  {
    "text": "at least for opencl for the gpu on these benchmarks were within a ballpark of what you could expect of",
    "start": "2516560",
    "end": "2522240"
  },
  {
    "text": "what hand tuned code would do so we think for the gpu uh for a pretty large number of codes we",
    "start": "2522240",
    "end": "2528400"
  },
  {
    "text": "have a pretty good performance story the fpga we're still working on on the performance story i don't have any",
    "start": "2528400",
    "end": "2533920"
  },
  {
    "start": "2529000",
    "end": "2623000"
  },
  {
    "text": "numbers to show for basic combinatorial circuits basically things which don't involve loops or state i think our",
    "start": "2533920",
    "end": "2540560"
  },
  {
    "text": "performance although maybe not necessary area is as well as you can get in this effect that we can get single pipe single cycle pipelining",
    "start": "2540560",
    "end": "2547359"
  },
  {
    "text": "um of the circuits so we can for uh any tree of combinatorial logic or our",
    "start": "2547359",
    "end": "2552720"
  },
  {
    "text": "compiler will produce a pipeline design that can produce one output per cycle which is as good as you can get we might not get this we might use more space but",
    "start": "2552720",
    "end": "2559680"
  },
  {
    "text": "we're getting closer uh for complex circuits right now the compiler is is",
    "start": "2559680",
    "end": "2564960"
  },
  {
    "text": "worse about a factor of 10 so we're doing a lot of work on i o pipelining and we're pretty hopeful that we're",
    "start": "2564960",
    "end": "2570880"
  },
  {
    "text": "going to be able to get this down to within the ballpark within within a factor of two or four of what a hand",
    "start": "2570880",
    "end": "2576400"
  },
  {
    "text": "tuned of what a expert programmer could do within the you know the within the foreseeable future so",
    "start": "2576400",
    "end": "2583680"
  },
  {
    "text": "and then you know you'll have to decide whether or not that the productivity versus performance trade-off is worth it",
    "start": "2583680",
    "end": "2588800"
  },
  {
    "text": "for you right now i think these numbers will just get better over time as our compilers mature",
    "start": "2588800",
    "end": "2594400"
  },
  {
    "text": "we also are working on there's a lot of issues which i won't go into here as far as supporting high level languages",
    "start": "2594400",
    "end": "2600480"
  },
  {
    "text": "features such as dynamic memory allocation or virtual method or object oriented dispatch or things like that",
    "start": "2600480",
    "end": "2606000"
  },
  {
    "text": "we're working on ways to support these these language features on the devices we had one paper",
    "start": "2606000",
    "end": "2612480"
  },
  {
    "text": "recently describing how we're going to do garbage collection on the fpga which is an excellent paper that also was in",
    "start": "2612480",
    "end": "2617920"
  },
  {
    "text": "the pldi conference so that's definitely worth checking out if you're into this kind of design thing um so martin s",
    "start": "2617920",
    "end": "2625280"
  },
  {
    "start": "2623000",
    "end": "2672000"
  },
  {
    "text": "what's the summary um as i said i think we have a pretty good story on",
    "start": "2625280",
    "end": "2631200"
  },
  {
    "text": "productivity we've shown uh that we can have high level concise abstractions for parallelism that map to",
    "start": "2631200",
    "end": "2636800"
  },
  {
    "text": "different devices we've shown i believe or at least our experience is that the experience of using this is not much",
    "start": "2636800",
    "end": "2642319"
  },
  {
    "text": "harder than java and so orders of magnitude better than the current",
    "start": "2642319",
    "end": "2647839"
  },
  {
    "text": "alternatives um and i think we have a good chance of of delivering on our goal which was the",
    "start": "2647839",
    "end": "2653680"
  },
  {
    "text": "general solution for mainstream programming of these systems now of course as i said there's no magic you know we're not going to",
    "start": "2653680",
    "end": "2660000"
  },
  {
    "text": "design a parallel algorithm for you this is not a parallelizing compiler you still have to be able to design your",
    "start": "2660000",
    "end": "2665599"
  },
  {
    "text": "algorithm in a way that's amenable to parallelism we're not going to pretend that one version of the program runs well on all devices you might have to",
    "start": "2665599",
    "end": "2672880"
  },
  {
    "text": "write different versions of a method in order to satisfy the constraints of different devices we're not trying to run vanilla java programs on accelerator",
    "start": "2672880",
    "end": "2679839"
  },
  {
    "text": "you do have to go through a migration step dialogue with the compiler this is an internal research",
    "start": "2679839",
    "end": "2685760"
  },
  {
    "text": "project right now so this is not yet available to the public i'm not prepared right now to make any announcements of this i'm",
    "start": "2685760",
    "end": "2692240"
  },
  {
    "text": "hopeful that this will be available in one form or the other relatively soon but for the moment this is an internal research project we're",
    "start": "2692240",
    "end": "2699040"
  },
  {
    "text": "piloting it with various groups within ibm to get experience and harden the system and we're hopeful that this",
    "start": "2699040",
    "end": "2704880"
  },
  {
    "text": "experience will validate our hypothesis that this is a productive way to go so i'm done and",
    "start": "2704880",
    "end": "2710880"
  },
  {
    "text": "i'll stop here and answer any other questions you have",
    "start": "2710880",
    "end": "2714880"
  },
  {
    "text": "is there any way to participate from outside um not yet if you're an ibm customer",
    "start": "2716960",
    "end": "2723760"
  },
  {
    "text": "we might be talk to us we might be willing to do some sort of one-off first of a kind agreement",
    "start": "2723760",
    "end": "2730880"
  },
  {
    "text": "if it made sense so we're willing we are doing this or we're in discussions of this with several",
    "start": "2730880",
    "end": "2736000"
  },
  {
    "text": "customers there's no reason why we couldn't do more so we're happy to engage as",
    "start": "2736000",
    "end": "2741520"
  },
  {
    "text": "as i said though it's not open public so it has to be done under the appropriate legal agreements",
    "start": "2741520",
    "end": "2747838"
  },
  {
    "text": "yes",
    "start": "2748640",
    "end": "2750880"
  },
  {
    "text": "right so for right now both the gpus so let's see for the gpus right now they plug into pci",
    "start": "2756480",
    "end": "2762400"
  },
  {
    "text": "uh things now both intel and amd have integrated gpus on the same core",
    "start": "2762400",
    "end": "2768960"
  },
  {
    "text": "so the fpgas there's a number of ways to communicate right now yes our main system is communicating over pcie",
    "start": "2768960",
    "end": "2775200"
  },
  {
    "text": "there's also ethernet is a possibility we also have for prototyping we have a uart",
    "start": "2775200",
    "end": "2780960"
  },
  {
    "text": "serial connection so there's many different ways to talk to fpgas there are also vendors that do memory bus attached to fpga designs",
    "start": "2780960",
    "end": "2788319"
  },
  {
    "text": "either with ibm or with intel so there's a number of ways but yes our our primary platform right now is pcie",
    "start": "2788319",
    "end": "2796240"
  },
  {
    "text": "other than the demo that you showed are there any interesting stories of some applications that have been tried",
    "start": "2798480",
    "end": "2807359"
  },
  {
    "text": "um benchmarks also so we have seven benchmarks",
    "start": "2807359",
    "end": "2812318"
  },
  {
    "text": "interesting story as well one thing we have fun with internally is that it seems that most of our",
    "start": "2814000",
    "end": "2819280"
  },
  {
    "text": "compelling applications are evil so we have a lot of stories from",
    "start": "2819280",
    "end": "2824560"
  },
  {
    "text": "uh you know applications from high speed trade frequency high frequency trading from wall street and weapons and uh",
    "start": "2824560",
    "end": "2833760"
  },
  {
    "text": "you know so i guess that's the story with all sorts of high performance bleeding edge technology the early adopters tend to",
    "start": "2833760",
    "end": "2839680"
  },
  {
    "text": "be people with a lot of money and power i i try to concentrate on the non-evil",
    "start": "2839680",
    "end": "2845280"
  },
  {
    "text": "applications but um do you see",
    "start": "2845280",
    "end": "2851920"
  },
  {
    "text": "do you see it as an alternative to classic",
    "start": "2851920",
    "end": "2858760"
  },
  {
    "text": "some pure ega projects in this",
    "start": "2870960",
    "end": "2876319"
  },
  {
    "text": "language about without the attached yeah so",
    "start": "2876319",
    "end": "2882240"
  },
  {
    "text": "i think of the scenarios i started at the beginning of the talk with my personal opinion is the one that's",
    "start": "2882240",
    "end": "2888160"
  },
  {
    "text": "most attractive is this is network attached and in this case basically",
    "start": "2888160",
    "end": "2893920"
  },
  {
    "text": "in the common case all the uh computation will be done in the fpga and i guess in theory you could cut the cord",
    "start": "2893920",
    "end": "2899599"
  },
  {
    "text": "and just detach the fpga but in practice it's usually attached to a hose because you have to boot the device and load",
    "start": "2899599",
    "end": "2906160"
  },
  {
    "text": "things by that but yes in in most of these applications the idea is and",
    "start": "2906160",
    "end": "2911680"
  },
  {
    "text": "you know we've been we've been doing some of these applications especially encryption encryption is an interesting one i'm sorry um zipping gzip gzip's a",
    "start": "2911680",
    "end": "2918559"
  },
  {
    "text": "very interesting application um but the idea here is that we're doing some filtering directly on the wire at the",
    "start": "2918559",
    "end": "2924240"
  },
  {
    "text": "speed of the wire ignoring the whole software stack on the cpu for very low latency high throughput now gzip is an",
    "start": "2924240",
    "end": "2930160"
  },
  {
    "text": "interesting um application there are stat i don't know if you're familiar with the out the the algorithms but",
    "start": "2930160",
    "end": "2935760"
  },
  {
    "text": "there are static and dynamic versions of the huffman algorithm and people are doing fpga compression",
    "start": "2935760",
    "end": "2942720"
  },
  {
    "text": "apps but their compression algorithms generally speaking that you do in software which use dynamic huffman",
    "start": "2942720",
    "end": "2949200"
  },
  {
    "text": "schemes are more effective with compression but they're extremely difficult to map to hardware because they use dynamic",
    "start": "2949200",
    "end": "2955760"
  },
  {
    "text": "structures yet this is the kind of code that in theory well actually in practice that we",
    "start": "2955760",
    "end": "2960800"
  },
  {
    "text": "can express in our language and if our compiler is able to uh code it is able to implement it well",
    "start": "2960800",
    "end": "2966240"
  },
  {
    "text": "we can actually use a better algorithm so i think this is an example of the possibilities of we're using higher",
    "start": "2966240",
    "end": "2972880"
  },
  {
    "text": "level abstractions perhaps not counter-intuitively you can perhaps get better performance",
    "start": "2972880",
    "end": "2978640"
  },
  {
    "text": "by using a better algorithm even if the operation by operation code generation",
    "start": "2978640",
    "end": "2985119"
  },
  {
    "text": "for very low level stuff is not as good as doing it by hand the ability to use a smarter algorithm at a high level may",
    "start": "2985119",
    "end": "2991680"
  },
  {
    "text": "actually be more productive as far as the bottom line story so that's one application which we're pretty uh",
    "start": "2991680",
    "end": "2998640"
  },
  {
    "text": "pretty pretty happy with going on in the fpga and there are a number of others",
    "start": "2998640",
    "end": "3005078"
  }
]
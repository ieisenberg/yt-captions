[
  {
    "start": "0",
    "end": "6000"
  },
  {
    "text": "One of the things that I like to do to start \noff is to lay the groundwork so that we're all  ",
    "start": "3600",
    "end": "9440"
  },
  {
    "start": "6000",
    "end": "102000"
  },
  {
    "text": "on the same plane here. Kelly Shortridge, for \nthose that are just starting out conceptually   with chaos, what is chaos engineering?\nYes, I would hope that everybody knows about the  ",
    "start": "9440",
    "end": "19119"
  },
  {
    "text": "scientific method. You generate a hypothesis and \nyou tested and you look at the evidence and then   you analyze it to confirm or deny the hypothesis. \nThat's ultimately what chaos engineering is.  ",
    "start": "19120",
    "end": "28400"
  },
  {
    "text": "So in the security context, you're coming up \nwith hypotheses about the safety of your systems.   So that could be whether a security control \nworks, whether a certain type of attack  ",
    "start": "28960",
    "end": "37360"
  },
  {
    "text": "is going to succeed against your systems.\nYou can inject a little chaos to test  ",
    "start": "37360",
    "end": "42960"
  },
  {
    "text": "that invalidates or does not \nconfirm that hypothesis, which  ",
    "start": "42960",
    "end": "48160"
  },
  {
    "text": "is powerful and something we haven't \nseen very much in information security. When you say inject, you mean go into the \nsystem and inject an issue into the system? ",
    "start": "48160",
    "end": "57839"
  },
  {
    "text": "Yes, and we do that because it's like we Kelly \nShortridge kind of said we're trying that case.  ",
    "start": "58720",
    "end": "64720"
  },
  {
    "text": "Engineering sounds provocative as it. Right. But \nreally, we're not creating the chaos that the  ",
    "start": "64720",
    "end": "70560"
  },
  {
    "text": "problem is. Is that because of the \nspeed, scale, and complexity of modern   systems we're already dealing with the chaos \nwe're trying to do is create order proactively. ",
    "start": "70560",
    "end": "79920"
  },
  {
    "text": "All we're doing is presenting the system with the \nconditions we expected to successfully operate  ",
    "start": "81280",
    "end": "86960"
  },
  {
    "text": "under. Right. So we believe that under X Y will \nhappen. So we're proactive instead of finding out  ",
    "start": "86960",
    "end": "93760"
  },
  {
    "text": "randomly what didn't work. \nProactively saying, hey,   computer, do you do what you're supposed \nto do? And that's what we're doing.",
    "start": "94320",
    "end": "100240"
  },
  {
    "text": "And is that the genesis of this book? What was the \npurpose of the book? What are you trying to do? ",
    "start": "100880",
    "end": "106799"
  },
  {
    "start": "102000",
    "end": "357000"
  },
  {
    "text": "Actually, the purpose of the book is to bring \ninformation security into not just the modern era,   but also a realistic era. So we're not just \ntalking about what perfect security is and  ",
    "start": "107360",
    "end": "117759"
  },
  {
    "text": "textbook security and all of that stuff. \nIt's like, OK, you know, you have a mental   model of how you think your security is and \nhow you think the safety of your systems is. ",
    "start": "117760",
    "end": "125920"
  },
  {
    "text": "How does that match up with reality? We \nare looking at the difference between that   there and as I said, I think most computer \nsystems these days are complex systems  ",
    "start": "125920",
    "end": "134000"
  },
  {
    "text": "and complex systems inherently have \nunexpected interactions. We can either  ",
    "start": "134000",
    "end": "139760"
  },
  {
    "text": "uncover those when there's a successful attack \nor we can uncover those through experimentation.  ",
    "start": "139760",
    "end": "145040"
  },
  {
    "text": "So really, the book is not just about this \nexperimentation, though that is powerful.  It's also about all of the underlying \nphilosophy around resilience, that  ",
    "start": "145040",
    "end": "153760"
  },
  {
    "text": "ability to recover gracefully. How do you adapt? \nHow do you evolve as a complex or when you're   kind of building and maintaining \nand securing these complex systems,  ",
    "start": "153760",
    "end": "161280"
  },
  {
    "text": "which is a radical departure from the old \nway of doing security? So we could have just   talked about the experimental part, but we're \ntrying to do something much bigger as well. ",
    "start": "161280",
    "end": "170160"
  },
  {
    "text": "It's interesting, if you think \nabout it you're trying to   overlay a mental map on top of a physical one, \nwhat is the relationship between the two maps? ",
    "start": "170160",
    "end": "181840"
  },
  {
    "text": "You have kind of your mental model of here's how \nthe system is going to behave. Under certain kinds   of stress, right? So you have that mental \nmodel, then you have the physical reality,  ",
    "start": "183920",
    "end": "192880"
  },
  {
    "text": "which, you look at, let's say the supply chain \nattack thing, which is very popular right now.  You have this actual interconnection that \nmay be between two components you had no  ",
    "start": "192880",
    "end": "201760"
  },
  {
    "text": "idea were connected. Then an attacker laterally \nmoves in. You're like, oh, my goodness, this   is completely shattered. Kind of this mental \nmodel of reality. It also can manifest actually  ",
    "start": "201760",
    "end": "210240"
  },
  {
    "text": "when you're performing incident response, you may \nhave assumptions about how your systems behave,   where you kind of overlook things, maybe \nactually this is the problem because that's  ",
    "start": "210240",
    "end": "218640"
  },
  {
    "text": "not even in your mental model of reality.\nThat's really what you're trying to do is   you can almost think of it in those old school \nmovies, forgive me, which where you do like the  ",
    "start": "218640",
    "end": "228480"
  },
  {
    "text": "rubbings on a rock, it's almost like that. \nYou're like uncovering and excavating, like,   OK, here's how it looks. Not just \nwhatever your preconceived sketches.",
    "start": "228480",
    "end": "235760"
  },
  {
    "text": "I want to play off of that, too. So it takes \na while. I don't know if you feel this way.   It takes a while when you start doing this and be \nable to explain the right words, and the message,  ",
    "start": "236480",
    "end": "247440"
  },
  {
    "text": "you're much better at that than \nall the good writing in the book.  But it's one of the greatest and the best \nexamples that I really kind of honed in on  ",
    "start": "247440",
    "end": "257199"
  },
  {
    "text": "is the concept of a legacy system. So what does \nit mean? Give me legacy typically means it's  ",
    "start": "257200",
    "end": "264800"
  },
  {
    "text": "mission-critical. Right. That it's typically the \nflagship application or some derivative of that  ",
    "start": "264800",
    "end": "270879"
  },
  {
    "text": "or usually some kind of mainframe.\nIt's legacy. We call it legacy because we would  ",
    "start": "271440",
    "end": "278720"
  },
  {
    "text": "have gotten rid of it. It's tech that we need. \nIt's critical to the business. Legacy systems  ",
    "start": "278720",
    "end": "288400"
  },
  {
    "text": "will often associate with things like stability? \nRight. That we know how the systems work. The  ",
    "start": "288400",
    "end": "293600"
  },
  {
    "text": "engineers that are working on it feel somewhat \nconfident and competent in how it functions and   it kinda has incidents rather than just issues\nBut the question I ask is, was it always that way?  ",
    "start": "293600",
    "end": "304160"
  },
  {
    "text": "Right. So we learn. The answer is \nit wasn't right. We learned through  ",
    "start": "304160",
    "end": "309280"
  },
  {
    "text": "a series of unforeseen surprises, incidents, \nand outages. Right. Achilles that we learned  ",
    "start": "309280",
    "end": "316240"
  },
  {
    "text": "what we thought the system was versus what \nit was through a series of surprise events. ",
    "start": "316240",
    "end": "322639"
  },
  {
    "text": "Now, those surprise events when we said, \nhey, oh, this works differently. So we need  ",
    "start": "322640",
    "end": "327680"
  },
  {
    "text": "to go back and fix it. But remember, \nthe surprises are reflective of pain,   right? Customer pain, user pain people, and the \noperating system people are using system pain.  ",
    "start": "327680",
    "end": "337039"
  },
  {
    "text": "Chaos engineering and security chaos engineering \nyou could think about as a proactive way  ",
    "start": "338080",
    "end": "343599"
  },
  {
    "text": "of accelerating that process.\nOf warning about the system  ",
    "start": "344480",
    "end": "348080"
  },
  {
    "text": "before you encounter pain. There's a couple of things to unravel there. \nOne is why do people keep legacy systems  ",
    "start": "349840",
    "end": "360640"
  },
  {
    "start": "357000",
    "end": "558000"
  },
  {
    "text": "when everybody's saying, oh, you should be \nreplacing that with the latest and greatest?   Usually, it's because those systems are critical. \nIt's a critical system that is functioning  ",
    "start": "360640",
    "end": "370160"
  },
  {
    "text": "and the business doesn't want to replace them. \nBut what happens with those systems is exactly  ",
    "start": "371040",
    "end": "376320"
  },
  {
    "text": "what you said is that there's a corporate \nmemory that's attached to that system.",
    "start": "376320",
    "end": "383360"
  },
  {
    "text": "When you say surprise, surprises \nhappen, I like that. Surprises happen  ",
    "start": "385200",
    "end": "390720"
  },
  {
    "text": "as part of Chaos Engineering. Where \nis the corporate memory? Where's the   documentation for these surprises?\nWell, I think that's ul thing about  ",
    "start": "391600",
    "end": "400560"
  },
  {
    "text": "security. Engineering is it generates a lot \nof that kind of shared memory. And ideally,   we'll talk about this. Ideally, it should be \nwidely shared and transparent. So it's not you.",
    "start": "400560",
    "end": "409120"
  },
  {
    "text": "Now, ideally, yes, in reality. No. But the beautiful thing about security \nclass engineering is, again, rather, you know,  ",
    "start": "409120",
    "end": "415680"
  },
  {
    "text": "incidents eventually fade into memory. \nRight. It's a memory of the past. And   people stop kind of learning the lessons of those. \nBut if you're kind of continually practicing, like  ",
    "start": "415680",
    "end": "424080"
  },
  {
    "text": "conducting these experiments, like \nconfirming, checking your hypotheses,   challenging your assumptions, if you're doing that \ncontinuously, which is what security engineering  ",
    "start": "424960",
    "end": "433840"
  },
  {
    "text": "is all about, then you're kind of continually \ngenerating this new kind of shared knowledge.  You're continually keeping that memory \nfresh, which is important. I think to  ",
    "start": "433840",
    "end": "442720"
  },
  {
    "text": "your point. Part of the reason why people \ndo stick with legacy systems is that they   do understand them. I think it's a very, very \nunderstandable natural human tendency. We want  ",
    "start": "442720",
    "end": "450800"
  },
  {
    "text": "to understand the world around us. It makes us \nfeel safer. It makes us feel more in control. And again, with security, chaos, \nengineering, rather than, you know,  ",
    "start": "450800",
    "end": "457840"
  },
  {
    "text": "having that long lifespan of the legacy system, \nwhich is one way to kind of understand, again,   all of the different interactions, the way \nthe system works, you can conduct experiments  ",
    "start": "457840",
    "end": "466080"
  },
  {
    "text": "and generate that same understanding.\nEven though chaos sounds like there's   not a lot of control, it can, at least in \npart, give you a greater feeling of control  ",
    "start": "466080",
    "end": "473919"
  },
  {
    "text": "because you have that greater understanding \nof how your system behaves in practice.  Furthermore, for the moment, like is that when \nwe're doing this, the proactive so during an  ",
    "start": "473920",
    "end": "483040"
  },
  {
    "text": "active event or surprise event, right? Because \nif it wasn't a surprise, you would just fix it   before a surprise. Right. But during an active \nincident, that is not a good time to alert people.  ",
    "start": "483040",
    "end": "494880"
  },
  {
    "text": "People are you worry people are worried \nabout being named, blamed, shamed. I knew I should push that code. I knew I \nshould have done it. I'm going to get fired,  ",
    "start": "494880",
    "end": "503360"
  },
  {
    "text": "right? Like people are freaking out. \nWell, when you're under or the world,   the world around you is on fire. You don't think? \nBut the world is not on fire when we're doing  ",
    "start": "503360",
    "end": "511840"
  },
  {
    "text": "chaos engineering or security chaos engineering.\nWe're proactively trying to understand the system.  ",
    "start": "511840",
    "end": "517360"
  },
  {
    "text": "We can learn. We don't have the blinders on. \nWe're not looking back. A lot of times when an   incident or an outage happens, we expand on a lot \nof these concepts around hindsight bias and the  ",
    "start": "517360",
    "end": "528080"
  },
  {
    "text": "sharp end versus the blunt end of...and a lot of \nit comes from Sidney Dekker's 20 years of airline  ",
    "start": "528080",
    "end": "534640"
  },
  {
    "text": "accident investigations. We go into the world \nof cognitive science and safety engineering.  ",
    "start": "534640",
    "end": "538480"
  },
  {
    "text": "If you know the outcome of the event, you look \nat the events that unfolded up until the outcome,   completely different, right. But \nwhat we're doing is proactively  ",
    "start": "542320",
    "end": "551680"
  },
  {
    "text": "trying to understand the system with \neyes wide open, if that makes sense.",
    "start": "551680",
    "end": "555279"
  },
  {
    "text": "As you both were talking, it came to me \nthat if documentation is done properly if  ",
    "start": "556960",
    "end": "564160"
  },
  {
    "start": "558000",
    "end": "948000"
  },
  {
    "text": "the documentation of these surprise events is done \nproperly, it becomes part of the system itself  ",
    "start": "564160",
    "end": "570959"
  },
  {
    "text": "and is a way for the system to \nrespond to future incidents of  ",
    "start": "572000",
    "end": "577680"
  },
  {
    "text": "the same thing. Is that part of the process here?\nYes. The way we characterize it is, like, building  ",
    "start": "577680",
    "end": "583120"
  },
  {
    "text": "muscle memory for incidents. You can almost \nthink of it, as training montages. Where you get  ",
    "start": "583120",
    "end": "588400"
  },
  {
    "text": "people fighting you, so, for the real \nboss fight, like, you're all ready.   It's very similar to that. You're building \nthat muscle memory and making sure that when  ",
    "start": "589760",
    "end": "596720"
  },
  {
    "text": "a real surprise happens, not these \nkinds of injected chaos surprises,  ",
    "start": "596720",
    "end": "601199"
  },
  {
    "text": "you have a much greater sense of how to handle \nit and how to respond gracefully and not   experience the burnout and stress I think \nmost responders go through, whether that's  ",
    "start": "602160",
    "end": "610640"
  },
  {
    "text": "performance incidents or security incidents, most \nof the experience, that kinda burnout is stress.  ",
    "start": "610640",
    "end": "614400"
  },
  {
    "text": "Still, though, if you're thinking \nof humans as part of that process,   that's the problem. And I'm thinking that \nif chaos engineering is done properly,  ",
    "start": "617280",
    "end": "628240"
  },
  {
    "text": "the system is the one that \nresponds, not the humans respond. ",
    "start": "628880",
    "end": "633680"
  },
  {
    "text": "Completely disagree.\nOkay. Good.  I don't think humans are the problem. I think \nthat's kind of like Aaron was saying. We can  ",
    "start": "634960",
    "end": "641200"
  },
  {
    "text": "see this across all sorts of disciplines. \nI think there was one incident where the  ",
    "start": "641200",
    "end": "647120"
  },
  {
    "text": "relevant alert...this might've been in a nuclear \nplant. Maybe you remember. The relevant alert was   on the backside of one of those,  old-school big \npanels at the very bottom flashing. And they said,  ",
    "start": "647120",
    "end": "655840"
  },
  {
    "text": "\"Well, the operator should've known.\" It's like, \n\"Really? Because 100 other lights were flashing.   They should've known that the correct one was, \nlike, on the other side?\" It's ridiculous, right.  ",
    "start": "655840",
    "end": "663200"
  },
  {
    "text": "You can see in other industries \nwhere they blame an operator for   not knowing that there was, like, a truck whose \nbeepy thing backing up was broken. Not realizing  ",
    "start": "663920",
    "end": "673840"
  },
  {
    "text": "that it was broken and looking around to see…\nWe love to blame operators because we're removed   from it. We're not in the situation and I think \nit's very much part of the just-world hypothesis.  ",
    "start": "673840",
    "end": "681680"
  },
  {
    "text": "We don't like the idea that random, terrible \nsurprises can happen and so it makes us feel   better to say, \"Well, actually, it wasn't \nrandom and terrible. It was because this  ",
    "start": "681680",
    "end": "690240"
  },
  {
    "text": "operator did this dumb human thing.\" I think if \nwe look at the history of incidents, humans are  ",
    "start": "690240",
    "end": "695839"
  },
  {
    "text": "ultimately often a source of strengths \nbecause computers are largely not entirely  ",
    "start": "695840",
    "end": "701280"
  },
  {
    "text": "very deterministic, right. Humans are the ones \nthat can be innovative, they can be nimble,   they can be flexible in their thinking, \nand they can respond in very adaptive ways.",
    "start": "701280",
    "end": "708960"
  },
  {
    "text": "So part of what we're trying to promote with \ninformation security...information security,   right, has blamed the human most of the time. \nDumb users clicking on links, all that stuff.  ",
    "start": "709520",
    "end": "717520"
  },
  {
    "text": "But what we're saying is actually, \"Well, \nhumans behave in very human ways. Maybe we   should be designing our information security \nsystems and our processes and procedures  ",
    "start": "717520",
    "end": "725840"
  },
  {
    "text": "in a way that understands that \nhumans can be very adaptive   but also they have finite attention, they \nhave finite time, they have all these sorts  ",
    "start": "725840",
    "end": "733200"
  },
  {
    "text": "of production pressures and constraints.\" You \nhave to ship software quickly, all that stuff.  We need to be very empathetic with humans. We also \nneed to view the human as a source of strength.  ",
    "start": "733200",
    "end": "742880"
  },
  {
    "text": "How can we make sure during incidents they \ndo feel empowered to have a nimble response?   I'm sure Aaron can talk about some of what we've \nseen kinda more in the wild on that front too. ",
    "start": "742880",
    "end": "751840"
  },
  {
    "text": "That was a great answer. I can echo it even more. \nI mean, we read a lot about this. Humans are the  ",
    "start": "751840",
    "end": "761600"
  },
  {
    "text": "solution. I don't think we're ever gonna have \nmachines writing all of our software for us.  ",
    "start": "761600",
    "end": "767920"
  },
  {
    "text": "It's one of the ironies of automation also that, \nlike, you can't think that when you...when you  ",
    "start": "768720",
    "end": "774639"
  },
  {
    "text": "write automation, you need fewer humans, you need \nmore because somebody's gotta maintain the code,   somebody's gotta write new code, right. \nKelly said the word adaptive,  ",
    "start": "774640",
    "end": "784000"
  },
  {
    "text": "right. There's this term in resiliency \nengineering called adaptive capacity. Humans  ",
    "start": "784000",
    "end": "791520"
  },
  {
    "text": "have more ability to look at different things and \nfigure out what's going on and make decisions. ",
    "start": "793520",
    "end": "798880"
  },
  {
    "text": "We need to empower people. Part of the chaos \nengineering where it began at Netflix was to  ",
    "start": "798880",
    "end": "804560"
  },
  {
    "text": "put better information in front of engineers, \nright. Turns out if engineers have better  ",
    "start": "805600",
    "end": "811040"
  },
  {
    "text": "context...so over control, right. The \nmore context you have about a problem,  ",
    "start": "811040",
    "end": "819199"
  },
  {
    "text": "it's more likely you can solve it, right. I \nthink Charles Kettering once said, a problem   well defined is half solved, right. That's \nwhat engineers do. They solve small problems.",
    "start": "819200",
    "end": "830800"
  },
  {
    "text": "And I think there's an important distinction \nhere also between uncertainty and ambiguity.   Computers could often be good at resolving \nuncertainty. That's just a lack of information,  ",
    "start": "830800",
    "end": "838400"
  },
  {
    "text": "like, collecting all the relevant data points. \nBut there's also ambiguity and that's you can   have the same set of data points but there \nare two different ways to interpret them.  ",
    "start": "838400",
    "end": "846000"
  },
  {
    "text": "And what's the right interpretation and context? \nThat depends. That's not something at least yet  ",
    "start": "846000",
    "end": "851040"
  },
  {
    "text": "we've taught computers how to solve. For \ninstance, take an intensive care unit,  ",
    "start": "851040",
    "end": "856160"
  },
  {
    "text": "right. A doctor sees that there are two different \npatients. One maybe needs palliative care. One  ",
    "start": "856160",
    "end": "862959"
  },
  {
    "text": "is facing something terminal. The other maybe \ncould be cured but the other one came in later.  How is a computer supposed to decide that? I \ndon't think we want necessarily computers, like,  ",
    "start": "864400",
    "end": "872320"
  },
  {
    "text": "making those kinds of decisions, right. That's \nambiguous. You have all the data that you could   have but what is the right decision? It's very \nunclear. And in a lot of these incidents...again,  ",
    "start": "872320",
    "end": "881360"
  },
  {
    "text": "you see across industries and certainly in \nthe, what I call, like, computer system realm,   we see that roughly what we call human error \nis because we think that the human operator  ",
    "start": "881360",
    "end": "892560"
  },
  {
    "text": "should've resolved that ambiguity in a different \nway, that there is the right way but maybe not  ",
    "start": "892560",
    "end": "898080"
  },
  {
    "text": "in context. So, I think we have to be careful \nthat more information won't necessarily solve  ",
    "start": "898080",
    "end": "903280"
  },
  {
    "text": "things because a lot of these choices are not \njust...you know, there's one right answer.  It could be the same data points, again, \nin a slightly different context could  ",
    "start": "903280",
    "end": "912720"
  },
  {
    "text": "result in a completely different outcome. We \nneed to empower the operators to make the best  ",
    "start": "912720",
    "end": "917920"
  },
  {
    "text": "decisions that they can with as much context as \npossible but they aren't the problem. There are  ",
    "start": "917920",
    "end": "924079"
  },
  {
    "text": "always gonna be mistakes. I don't think we're ever \ngonna be able to resolve ambiguity, ever. That's  ",
    "start": "924080",
    "end": "931360"
  },
  {
    "text": "a judgment problem and I think we see...not to \nget too philosophical, but I think we see across   society a lot of times we do try to solve kind of \nproblems of judgment with metrics and I'm not sure  ",
    "start": "931360",
    "end": "940959"
  },
  {
    "text": "how well that's working out because we just gain \nthe metrics. Is that better? I don't think so but…",
    "start": "940960",
    "end": "945360"
  },
  {
    "text": "All right. You have both used the term security \nchaos engineering several times already.  ",
    "start": "946960",
    "end": "954880"
  },
  {
    "start": "948000",
    "end": "1325000"
  },
  {
    "text": "Is it a coincidence that that's \nthe name of your new book?  No. We recognize that there is a branding part of \nit, right. If we're introducing or trying to usher  ",
    "start": "956160",
    "end": "967440"
  },
  {
    "text": "in this new era of information security which \nwe think is more pragmatic, and more aligned to   the realistic models of how systems \nand humans in those systems work,  ",
    "start": "967440",
    "end": "975839"
  },
  {
    "text": "we need a catchy name. And security chaos gets \npeople's attention. Like Aaron was saying chaos,   it's a pithy name, it's one that people \nare like, \"Wait, do we want chaos?\" And  ",
    "start": "976400",
    "end": "984560"
  },
  {
    "text": "the answer is yes. So that's one part of it.\nWe also thought it was really important to extend  ",
    "start": "984560",
    "end": "989840"
  },
  {
    "text": "that underlying discipline of chaos engineering \njust because that has been well-practiced  ",
    "start": "989840",
    "end": "995040"
  },
  {
    "text": "more on the broader DevOps community side \nwhich is relevant to our conversation.  ",
    "start": "995040",
    "end": "1000079"
  },
  {
    "text": "So, we're bringing it and looking very much at \nhow it applies to information security as well.  ",
    "start": "1000080",
    "end": "1004640"
  },
  {
    "text": "So, we could've called it, you know, \nsomething like human sensitive, you know,   resilience engineering for system safety but \nsecurity chaos engineering is much pithier. ",
    "start": "1005200",
    "end": "1015200"
  },
  {
    "text": "So, who called who?\nI think I was already writing a book   because that's just what I do in \nmy free time. I just love writing.  ",
    "start": "1015200",
    "end": "1022320"
  },
  {
    "text": "And I think Aaron reached out to me because he \nhad seen I was talking about security chaos…  There was a lot in that talk. It was the keynote \nyou did. I think I came up to New York and we  ",
    "start": "1022960",
    "end": "1035439"
  },
  {
    "text": "talked about, we had all these things we would \nwrite about and I think I must've filled up   several pages of notes. I was like, \"Okay. We have \nmaybe several books here.\" There's so much depth  ",
    "start": "1036320",
    "end": "1050399"
  },
  {
    "text": "beyond the practice of security chaos engineering. \nSo, one of the things I was wondering early on   with...so I wrote the first open-source tool \nthat applied Netflix's chaos engineering to  ",
    "start": "1050400",
    "end": "1058960"
  },
  {
    "text": "cybersecurity.\nAnd that tool was?  ChaoSlingr. Still out on GitHub but it's \ndeprecated. UnitedHealth Group has their  ",
    "start": "1059520",
    "end": "1065040"
  },
  {
    "text": "version of it and I'm no longer there. One of the \nthings that I was trying to figure out also was  ",
    "start": "1065040",
    "end": "1072560"
  },
  {
    "text": "what allow me to deeper understand \nwhy are these chaotic experiments  ",
    "start": "1073920",
    "end": "1079840"
  },
  {
    "text": "always unsuccessful, right. Because we only do \nchaos engineering experiments, security or not,  ",
    "start": "1080400",
    "end": "1086240"
  },
  {
    "text": "for...under conditions we expect \nthe system...we think we're right.   We're introducing the conditions we expect the \nsystem can handle, right. We're not trying to  ",
    "start": "1086960",
    "end": "1096320"
  },
  {
    "text": "introduce randomness or trying to introduce...it's \nnot a monkey in a data center pulling cables.  ",
    "start": "1096320",
    "end": "1101759"
  },
  {
    "text": "Everybody loves to use that example. That's \nnot...that is chaos, right. That's mayhem, right.  What we're trying to do is introduce the \nconditions we expect the system to operate under  ",
    "start": "1101760",
    "end": "1110000"
  },
  {
    "text": "by sort of doing that, and the system rarely did \nwhat we expected it to, right. So why are we wrong  ",
    "start": "1110000",
    "end": "1118400"
  },
  {
    "text": "about how our system...because we were basing \nall of our engineering practice on hope and luck,  ",
    "start": "1118400",
    "end": "1123680"
  },
  {
    "text": "right. As engineers, we don't believe in \nhope and luck. We believe in instrumentation,   feedback loops, and data. We believe \nin those sorts of... measurements,  ",
    "start": "1123680",
    "end": "1131360"
  },
  {
    "text": "these things that tell us it did work, why \nit didn't work and how we can improve it. ",
    "start": "1131360",
    "end": "1135360"
  },
  {
    "text": "I started following some of the work being done \nat London University and with Casey Rosenthal  ",
    "start": "1138560",
    "end": "1144880"
  },
  {
    "text": "and Nora Jones and about resilience engineering \nand safety engineering, the cognitive sciences.  ",
    "start": "1144880",
    "end": "1149600"
  },
  {
    "text": "There's a human brain behind these computers, \nright. And they interpret things differently. ",
    "start": "1150560",
    "end": "1155760"
  },
  {
    "text": "We've been reading a lot about \nthese concepts and trying to   extend some of the great work being done by \nDr. David Woods or Richard Cook and, you know,  ",
    "start": "1159040",
    "end": "1168480"
  },
  {
    "text": "these people that have been...David Woods \ncreated Resilience Engineering, I think, from… Essentially, because the way I came about it \nwas slightly different, I started actually  ",
    "start": "1168480",
    "end": "1176480"
  },
  {
    "text": "with earthquake resilience, of all things, to look \nat how buildings were designed. And there's this  ",
    "start": "1176480",
    "end": "1182559"
  },
  {
    "text": "one quote that still sticks with me and it's \nDr. Elizabeth, I think, Hau, who's a geologist  ",
    "start": "1182560",
    "end": "1190080"
  },
  {
    "text": "from what I remember. And she says, \"A building \ndoesn't care if the earthquake was predicted or  ",
    "start": "1190080",
    "end": "1195200"
  },
  {
    "text": "not. It's either gonna stand up or it's gonna \nfall, right.\" And I thought that summarized so   well or pattern matching to information security, \nit summarized so well at the time...it's a  ",
    "start": "1195200",
    "end": "1204080"
  },
  {
    "text": "little less now but at the time there was so much \neffort put into how do we predict breaches. Like,   how can we predict what's going on and all \nthis data science going into it and it's, like,  ",
    "start": "1204080",
    "end": "1211200"
  },
  {
    "text": "it doesn't matter. Either your system is going \nto be resilient against an attacker or it's not. ",
    "start": "1211200",
    "end": "1216559"
  },
  {
    "text": "Either you're going to experience a breach \nor you're not or you're gonna experience   downtime or you're not. But there was no one \ntalking about it in those terms. The information  ",
    "start": "1216560",
    "end": "1225120"
  },
  {
    "text": "security side delved more into kind of natural \ndisaster resilience. I ended up also going into  ",
    "start": "1225120",
    "end": "1230400"
  },
  {
    "text": "David Woods because he kind of spans a bunch \nof disciplines and looks into resilience across   all these different domains and quite late I \ndiscovered that, \"Oh, this has already been  ",
    "start": "1230400",
    "end": "1238400"
  },
  {
    "text": "kind of described on the chaos engineering \nside.\" And I found that fascinating. But I   think there is that kind of underlying issue in \ninformation security which I'm not sure how often  ",
    "start": "1238400",
    "end": "1248560"
  },
  {
    "text": "the software engineering community more broadly \nunderstands but in information security,   it's very difficult to measure what success is.\nAs a result, it means that we have stuck with  ",
    "start": "1249600",
    "end": "1258800"
  },
  {
    "text": "strategies for decades that just don't work. But \nthat's the folk wisdom and that's how it's always   been done. And if we can't measure success, we're \nnever going to improve. And it seemed like being  ",
    "start": "1258800",
    "end": "1268080"
  },
  {
    "text": "able to conduct these experiments...which, by \nthe way, computer people are very lucky, we can't   conduct these sorts of experiments with nuclear \npower, right. It's unethical and there are a bunch  ",
    "start": "1268080",
    "end": "1277360"
  },
  {
    "text": "of domains...even in macroeconomics, we can't \njust inject a financial crisis to see what happens   across the system. So, in computer science, we \nwere incredibly lucky that we can kind of inject  ",
    "start": "1277360",
    "end": "1287840"
  },
  {
    "text": "this kind of, again, what I call controlled \nchaos in a way to understand better how our   systems are gonna behave in information security \nthat is so powerful because we can finally see,  ",
    "start": "1287840",
    "end": "1297360"
  },
  {
    "text": "\"Hey, our strategy is actually effective.\"\nDo they operate the way we think they're gonna  ",
    "start": "1297360",
    "end": "1302400"
  },
  {
    "text": "operate? Can we again build this muscle \nmemory to respond to incidents better?   So that's why we think it has the opportunity \nto start...we can start to see an information  ",
    "start": "1302400",
    "end": "1312560"
  },
  {
    "text": "security industry that maybe is a little more \npragmatic and constructive rather than just, hand   waving and kind of, like, the shamanism of old.\nAI is not gonna solve all your problems. ",
    "start": "1312560",
    "end": "1321200"
  },
  {
    "text": "Correct, yes.\nStop that. Let's talk then about specifics.\nSure. ",
    "start": "1321200",
    "end": "1327120"
  },
  {
    "start": "1325000",
    "end": "1731000"
  },
  {
    "text": "We've talked in generalities about what's going \non. How has this been applied? I think in the  ",
    "start": "1327840",
    "end": "1332880"
  },
  {
    "text": "book you've got two examples to start with, right.\nWe have a few. We have quite a few case studies.   We've been lucky that there are a bunch of people \nworking on this. Aaron has seen a lot of these up  ",
    "start": "1332880",
    "end": "1344080"
  },
  {
    "text": "close. One of my favorite ones is actually...I \nbelieve it's an open door in the book talking   about logging pipelines. I think it was the…\nThat's Prima Virani, ",
    "start": "1344080",
    "end": "1352240"
  },
  {
    "text": "Prima Virani, yes. I think it may have been \nthe Census Bureau had a breach and what  ",
    "start": "1352240",
    "end": "1364320"
  },
  {
    "text": "they discovered is that logs had been sent \nnowhere I think for 18 months, maybe more.  ",
    "start": "1364320",
    "end": "1369759"
  },
  {
    "text": "Logs have been sent nowhere?\nNowhere. They were being sent down   to a...I believe it was a SIM that had been \ndecommissioned or something like that. So,  ",
    "start": "1370720",
    "end": "1376640"
  },
  {
    "text": "they were broken for 18 months. They had no \nidea and that was one of the recommendations   obviously in their report. They were...I \nthought they were a little too shamey again  ",
    "start": "1376640",
    "end": "1383520"
  },
  {
    "text": "of human error but they were like, \"Probably you \nshould have your logs going somewhere real.\" So,   in this case, a study by Prima, it's basically, \nlog pipelines are the lifeblood whether that's  ",
    "start": "1383520",
    "end": "1393919"
  },
  {
    "text": "site reliability engineering or \nobviously on the security operation side,   responding to an incident. You need \nyour logs. You need that visibility. ",
    "start": "1394640",
    "end": "1400480"
  },
  {
    "text": "You can test like, \"Hey. Are log pipelines \ngoing to continue operating under these various  ",
    "start": "1401120",
    "end": "1407120"
  },
  {
    "text": "scenarios?\" You wanna be able to validate, \"Yes, \nwe can be confident that our log pipelines are   gonna be able to provide us that.\"\nBut isn't that a one-off? ",
    "start": "1407120",
    "end": "1413519"
  },
  {
    "text": "If someone's gonna spend time on security chaos \nengineering, I think control validation's a good   one. It's a response to observability in general. \nObservability in my opinion is the other half of  ",
    "start": "1418960",
    "end": "1430000"
  },
  {
    "text": "this big problem Kelly and I are kind of \nattacking with security chaos engineering.   Observability and software security suck. \nIt's horrible. It's horrific, right.  ",
    "start": "1430000",
    "end": "1439200"
  },
  {
    "text": "We put all this time and effort into a detective \nand preventative kinds of things hoping that when   they happen that the technology works, the \nhumans repair it, all these sorts of things.  ",
    "start": "1446000",
    "end": "1454640"
  },
  {
    "text": "Well, with chaos engineering, once you \ndo see those conditions, that signal,   did...okay, as soon as we interject that condition \nfor the preventative or detective kind of logic to  ",
    "start": "1454640",
    "end": "1464320"
  },
  {
    "text": "fire upon, we can look at the technology. Did \nthe technology work the way it was supposed to?  But other things we can look at \nnow that we're looking at it from  ",
    "start": "1464320",
    "end": "1471360"
  },
  {
    "text": "the other angle...we're not looking at it after \nthe fact, we're looking at it proactively,   we can see did the systems give us to log \nand doc data, event data that we could read  ",
    "start": "1472320",
    "end": "1482880"
  },
  {
    "text": "and make sense of to...had this been a real \nproblem, would we have known what to look at? ",
    "start": "1482880",
    "end": "1488880"
  },
  {
    "text": "Well, still, go back to the point where if \nyou have never seen a problem where logs are  ",
    "start": "1489440",
    "end": "1496879"
  },
  {
    "text": "being sent nowhere, you have no way to look for \nthat. You wouldn't even know to look for that. ",
    "start": "1496880",
    "end": "1503200"
  },
  {
    "text": "I don't think that's necessarily true because \nwe have a case study in the book of like, \"Hey,   you should worry about this.\" I think there's \nalso a great database that GitHub provides, for  ",
    "start": "1504400",
    "end": "1514000"
  },
  {
    "text": "postmortems, and things going wrong. Part of \nwhat's in the book is we recommend a whole   boatload of experiments to conduct as well. But \nI think Aaron's point is really...again, it's the  ",
    "start": "1514000",
    "end": "1524560"
  },
  {
    "text": "scientific method. I think it's very reasonable \nfor people...you can give your hypotheses: when  ",
    "start": "1524560",
    "end": "1530000"
  },
  {
    "text": "this port is opened up, we expect, the security \nengineering team Slack channel to receive an  ",
    "start": "1530800",
    "end": "1537120"
  },
  {
    "text": "alert. That's something I think you're just \ndocumenting, like, here's your expectation. What may happen in practice when you experiment \nis like, \"Huh, the alert didn't show up. Why is  ",
    "start": "1537120",
    "end": "1545760"
  },
  {
    "text": "that?\" And then when you go and investigate, maybe \nit's because something's messed up in your log,  ",
    "start": "1545760",
    "end": "1550880"
  },
  {
    "text": "like, your logging pipelines. I think it's \nalways good to come back to that scientific  ",
    "start": "1550880",
    "end": "1556720"
  },
  {
    "text": "method where you don't necessarily have to know \nthe counterfactual of like, \"log pipelines can  ",
    "start": "1556720",
    "end": "1561840"
  },
  {
    "text": "be broken.\" What you do know is you do expect to \nreceive an alert. And from there you can kind of   untangle and that's, again, the beauty of security \nchaos engineering is it's about that mental model.  ",
    "start": "1561840",
    "end": "1572240"
  },
  {
    "text": "You have this mental model of how your system's \ngoing to behave end to end and how that measure  ",
    "start": "1572240",
    "end": "1578320"
  },
  {
    "text": "up in practice. So, you don't need to specifically \ntest like, \"Hey, are our logs being sent nowhere?\"  But you can test, do we have alerts? And to \nAaron's point, if we wanna investigate deeper, can  ",
    "start": "1578320",
    "end": "1588400"
  },
  {
    "text": "we access the logs? And then maybe you're like, \n\"Huh, we can access the logs. That's interesting.\"   Again, it is much better to do it in this kind of \ncontrolled chaos experiment rather than when you  ",
    "start": "1588400",
    "end": "1598799"
  },
  {
    "text": "have an attacker that's up in your systems, right.\nA real-world example, meaning  ",
    "start": "1598800",
    "end": "1603840"
  },
  {
    "text": "the situation where the HVA system was hooked up \nto the point of sales systems and nobody knew it.  ",
    "start": "1605680",
    "end": "1611840"
  },
  {
    "text": "That example. Would chaos have done anything \nabout that or notified anything about that? ",
    "start": "1612960",
    "end": "1619120"
  },
  {
    "text": "It depends on the experiment but a lot of times \nit can, again, excavate that kind of flow and  ",
    "start": "1622720",
    "end": "1627840"
  },
  {
    "text": "it can be like...if you think of tributaries \nunderneath once you kind of unearth a system,   I think, very similar to, you know, you have \ncontrol flow within a particular program.  ",
    "start": "1627840",
    "end": "1635679"
  },
  {
    "text": "You also have kind of interaction flows and \ndata flows within your application, within your   systems. I think in theory, you might've been able \nto see \"Huh, there's relatively tight coupling.\"  ",
    "start": "1636640",
    "end": "1645120"
  },
  {
    "text": "Because if you injected some sort of fault into \none system or the other, maybe you would've seen,  ",
    "start": "1645120",
    "end": "1651120"
  },
  {
    "text": "\"We're getting some sort of reaction in this \nother system but there shouldn't be, right.\"  I think it's certainly possible. \nAgain, our view is that you  ",
    "start": "1651680",
    "end": "1658720"
  },
  {
    "text": "shouldn't just do a one-off experiment. That's \na good way to start but ideally, you're trying   to automate some of this, you're trying to \ncontinually test your hypotheses and eventually  ",
    "start": "1660640",
    "end": "1669600"
  },
  {
    "text": "get a little more sophisticated over time. My \nview is certainly if those systems matter to you   and you want to conduct...I would imagine you \nwould wanna conduct experiments in them, then  ",
    "start": "1670640",
    "end": "1680960"
  },
  {
    "text": "probably that coupling would've been uncovered. \nBut I don't know. What do you think, Aaron? ",
    "start": "1680960",
    "end": "1684080"
  },
  {
    "text": "That's a good answer. This is not magic stuff. \nThis is rooted in the core components of  ",
    "start": "1686960",
    "end": "1696640"
  },
  {
    "text": "all science and engineering. We're providing a \nmethod for instrumentation. As Kelly said over  ",
    "start": "1696640",
    "end": "1702110"
  },
  {
    "text": "time with these experiments, it depends on the \nexperiment itself but you will...because how   often are you actually, looking at the system with \nthat kind of perception or that kind of angle?  ",
    "start": "1702110",
    "end": "1710320"
  },
  {
    "text": "We're always looking at it after something bad \nhappened and we're worried about damage control.  ",
    "start": "1710960",
    "end": "1716559"
  },
  {
    "text": "We're not worried about what happened and we \nalways love to believe there's a root cause. What we're trying to do is proactively \nunderstand the system so that you'd  ",
    "start": "1717760",
    "end": "1723840"
  },
  {
    "text": "be able to understand where is this error \ncoming from? It looks like an HVAC system.\"",
    "start": "1723840",
    "end": "1728960"
  },
  {
    "text": "The problem, though, at this time in \nhistory is the complexity and scale.  ",
    "start": "1729600",
    "end": "1736640"
  },
  {
    "start": "1731000",
    "end": "2188000"
  },
  {
    "text": "At the enterprise level with problems like this,   it's inconceivable with that complexity \nas it's grown beyond human comprehension.  ",
    "start": "1737600",
    "end": "1746640"
  },
  {
    "text": "Where does chaos fit in to make this, I would say, \npalatable but it's...that's not the right word. ",
    "start": "1747840",
    "end": "1753919"
  },
  {
    "text": "That's the whole point of chaos engineering. \nSo, if we had perfectly linear systems, you   probably wouldn't need chaos engineering so much \nbecause ultimately what chaos engineering is doing  ",
    "start": "1754640",
    "end": "1762080"
  },
  {
    "text": "is looking at the interactions in the systems. I \nthink the hard part about complex systems is that  ",
    "start": "1762080",
    "end": "1769279"
  },
  {
    "text": "you can't reason about them as well, you can't \nbuild that mental model once it reaches a certain   level of complexity. In large part kind of like \nyour HVAC system with the point-of-sale system,  ",
    "start": "1769280",
    "end": "1777440"
  },
  {
    "text": "it's because of those interactions between \ncomponents. So, another is...traditional   security is not going to catch that either, right, \nbecause it's looking does each component have,  ",
    "start": "1777440",
    "end": "1785600"
  },
  {
    "text": "like...from this list of vulnerabilities, \nthey're not looking at those interactions. What chaos engineering is saying is like, \"Okay, \nthat's not enough. What we need to do is again  ",
    "start": "1785600",
    "end": "1793200"
  },
  {
    "text": "build that better mental model about how our \nsystems are behaving.\" That's precisely what   you do when you experiment is you were able to \nuncover, \"There seems to be coupling over here  ",
    "start": "1793200",
    "end": "1802720"
  },
  {
    "text": "and coupling over here and some sort of fault in \nthis component ends up kind of trickling through  ",
    "start": "1802720",
    "end": "1807760"
  },
  {
    "text": "to all these other components.\" That's not \nsomething you can do with basically any of the   kind of security testing methodologies today but \nyou can do it when you conduct chaos experiments. ",
    "start": "1807760",
    "end": "1816480"
  },
  {
    "text": "We're certainly not saying it's a silver \nbullet. In your first chaos experiment,   you're going to have this beautiful, \nnew architecture diagram of all of the  ",
    "start": "1816480",
    "end": "1822000"
  },
  {
    "text": "interactions in a complex system. The point is, \nthough, over time, I like to view it as, like,   you're piecing together this, like, mosaic in a \nway that you couldn't before and that's powerful. ",
    "start": "1822000",
    "end": "1831600"
  },
  {
    "text": "One of my missions in speaking about this stuff \nand writing about it is trying to educate the  ",
    "start": "1832480",
    "end": "1838400"
  },
  {
    "text": "security world about complex systems. The depth \nbehind the security chaos engineering helps with  ",
    "start": "1838400",
    "end": "1844560"
  },
  {
    "text": "resilience engineering, and safety engineering \nkind of sciences. If we don't get...if we don't   start to understand this problem, everything we're \ndoing today is almost irrelevant. It was okay  ",
    "start": "1844560",
    "end": "1855680"
  },
  {
    "text": "when we had, like, the three-tier app, right, \nand we had far fewer components but now with  ",
    "start": "1857280",
    "end": "1862720"
  },
  {
    "text": "microservices, public cloud computing, \ncontinuous delivery, you know, continuous  ",
    "start": "1862720",
    "end": "1868240"
  },
  {
    "text": "integration, DevOps, we're delivering value \nto customers faster than we ever had before. ",
    "start": "1868240",
    "end": "1873840"
  },
  {
    "text": "But also, the software never decreases in \ncomplexity because of its changeability.  ",
    "start": "1873840",
    "end": "1881840"
  },
  {
    "text": "If you see a complex system, a software system and \nyou want to make it simple, how do you do that?  ",
    "start": "1883360",
    "end": "1890000"
  },
  {
    "text": "You have to change it, right, to make it simple. \nWell, the act of changing it...remember, the   relationship between change and complexity, right. \nSo, you're just moving the complexity around. So,  ",
    "start": "1890720",
    "end": "1900240"
  },
  {
    "text": "it's not about complexity and removing it and it's \nabout learning how to navigate the complexity and  ",
    "start": "1900240",
    "end": "1906640"
  },
  {
    "text": "understand it. That's what we're doing with this \nstuff, because if we don't get better, I mean,  ",
    "start": "1906640",
    "end": "1912480"
  },
  {
    "text": "this problem is a gnarly one to tackle.\nI think that's a really good point.  ",
    "start": "1912480",
    "end": "1918000"
  },
  {
    "text": "That complex system, we're in... computer \nsystems aren't the only complex system,   right. It kinda goes back to my point, in some \nways, computer people are kind of spoiled in  ",
    "start": "1918000",
    "end": "1926559"
  },
  {
    "text": "that we can wrangle this complexity in a way \nyou just can't in other disciplines because   it's unethical or it's just very...one of my \nfavorite anecdotes is in nuclear power plants  ",
    "start": "1926560",
    "end": "1936240"
  },
  {
    "text": "they have to...in their pipelines, like, literal \npipelines, they have to deal with the fact that   clams will start to grow. We don't have to deal \nwith stuff like that in computer systems but it's  ",
    "start": "1936240",
    "end": "1944480"
  },
  {
    "text": "just mind-blowing that this system that, if it \nexperiences a catastrophic accident, could kill  ",
    "start": "1944480",
    "end": "1949760"
  },
  {
    "text": "potentially hundreds of thousands of people, one \nof the ways that that could happen, the root cause   could be clams growing in the pipelines, right.\nI think again it's not like we're inventing  ",
    "start": "1949760",
    "end": "1958640"
  },
  {
    "text": "this concept of complex systems. Computer \nsystems aren't the first time we've had to   deal with complexity. We can draw on all this \nincredibly rich research over decades now  ",
    "start": "1958640",
    "end": "1967200"
  },
  {
    "text": "of complexity whether that's in ecosystems, \nnuclear power plants, healthcare,   mining, marine systems, or air transportation. \nIt's just everywhere. Even human brains. We can  ",
    "start": "1967200",
    "end": "1976400"
  },
  {
    "text": "leverage all of that expertise and very hard \nthought, kind of lessons learned to improve,  ",
    "start": "1976400",
    "end": "1982640"
  },
  {
    "text": "in this case, the discipline of information \nsecurity as it pertains to computer systems.  You brought up the human...I was thinking about \nthe human body when you were talking about  ",
    "start": "1982640",
    "end": "1989440"
  },
  {
    "text": "nuclear. The human body's also a complex adaptive \nsystem. I had recently recommended to a security  ",
    "start": "1989440",
    "end": "1996879"
  },
  {
    "text": "researcher to read \"How Complex Systems Fail\" \nby Richard Cook. It's only two pages. When you  ",
    "start": "1996880",
    "end": "2003360"
  },
  {
    "text": "read it, you think it's about a computer, right. \nIt's actually about the human body. He's writing  ",
    "start": "2003360",
    "end": "2010160"
  },
  {
    "text": "about the human body but it makes total sense for \ncomputers, right. Both people's minds...because   after she...this woman had read it, she reached \nout to me, \"That's an amazing paper.\" I said,  ",
    "start": "2010160",
    "end": "2022320"
  },
  {
    "text": "\"Okay. Did you know that he's talking about the \nhuman body?\" And she was...mind was blown, right.",
    "start": "2022320",
    "end": "2026799"
  },
  {
    "text": "I guess what Kelly and I are trying to relay \nhere is that we're going back, we're looking   at what other people have done, to tackle \nthese problems as we walk into this world  ",
    "start": "2028880",
    "end": "2039280"
  },
  {
    "text": "in the world of technology. And now \narguably, the powers have shifted.   Technology now is facilitating a lot of these \ncore components and we have a responsibility,  ",
    "start": "2039280",
    "end": "2048400"
  },
  {
    "text": "as stewards of them, to manage them effectively.  One of the dilemmas, though, as part of the whole \nprocess of complexity is you mentioned speed,  ",
    "start": "2049520",
    "end": "2061679"
  },
  {
    "text": "Aaron. Things have to be faster and faster. \nBut there's a tradeoff there because there's a  ",
    "start": "2061680",
    "end": "2069760"
  },
  {
    "text": "creation of potential vulnerabilities because \nof the speed that which things are changing. ",
    "start": "2069760",
    "end": "2075360"
  },
  {
    "text": "I am not sure I agree.\nYou never agree with me.  I know, I know. That's me as a person. One of the \nthings Dr. Nicole Forsgren uncovered...and this  ",
    "start": "2075360",
    "end": "2086240"
  },
  {
    "text": "was looking at the accelerate metrics or DORA \nmetrics so the four golden signals for DevOps.  ",
    "start": "2086240",
    "end": "2092800"
  },
  {
    "text": "What she found is that speed and stability \nare correlated. Think about a very simple   case in information security with patching. \nOne of the root causes of a lot of breaches  ",
    "start": "2092800",
    "end": "2101039"
  },
  {
    "text": "is that a patch didn't happen, for 18 months \nor some egregious amount of time after the   patch was released. Why is that? Because they \ncouldn't ship software quickly. If you can ship  ",
    "start": "2101040",
    "end": "2109760"
  },
  {
    "text": "changes on-demand on your software, \nyou can ship patches on demand.   That flexibility and that speed are vital to \nbe able to implement security changes as well. ",
    "start": "2109760",
    "end": "2118160"
  },
  {
    "text": "This is similar in other disciplines too, that \nspeed and stability are often correlated. Not  ",
    "start": "2119840",
    "end": "2125280"
  },
  {
    "text": "always. If you look at, like, seatbelts in \na way and brakes...I think Sounil Yu has  ",
    "start": "2125280",
    "end": "2131440"
  },
  {
    "text": "mentioned this if you look at brakes, it \nallows us to go faster in a safe way. So,   I would certainly argue that we shouldn't view \nspeed as inherently bad for safety. I think  ",
    "start": "2131440",
    "end": "2141680"
  },
  {
    "text": "sometimes safety is necessary to go fast. But \nI think the bigger issue is around the mental  ",
    "start": "2141680",
    "end": "2147599"
  },
  {
    "text": "models. If we're going quickly and if we're \nable to kind of build things at a scale that we  ",
    "start": "2147600",
    "end": "2152320"
  },
  {
    "text": "can't reason about in our brains, that's where the \nmental models start to break down because you're   having to iterate on your mental model constantly. \nThat's again a vital kind of benefit of security  ",
    "start": "2152960",
    "end": "2163920"
  },
  {
    "text": "chaos engineering is it allows you to keep \nevolving your mental model, it keeps, you know...  After a year of changes in a high kind of velocity \norganization, that the way your system behaved at  ",
    "start": "2163920",
    "end": "2174080"
  },
  {
    "text": "day...you know, January 1st to December 31st is \ngonna be radically different. If your mental model   is the same as it was on January 1st, that's \na huge problem. If you're kind of continuously  ",
    "start": "2174080",
    "end": "2182960"
  },
  {
    "text": "conducting these experiments, then your mental \nmodel's also evolving along the important way. You've used the term mental model \nnumerous times here. How is a mental model  ",
    "start": "2182960",
    "end": "2194640"
  },
  {
    "start": "2188000",
    "end": "2355000"
  },
  {
    "text": "actualized? What does it look like?\nI think that's different in everyone's brains   but I think when it's actualized, I think \narchitecture diagrams do a great example  ",
    "start": "2194640",
    "end": "2202640"
  },
  {
    "text": "of...that is very much the software architect or \ndesigner's notion of here's how the system looks.  ",
    "start": "2202640",
    "end": "2208640"
  },
  {
    "text": "Maybe behaves if they have flowed between them as \nwell depending on the architecture diagram. If you  ",
    "start": "2208640",
    "end": "2213920"
  },
  {
    "text": "looked, and some tools help with this security \nchaos engineering helps uncover this as well.  ",
    "start": "2213920",
    "end": "2218559"
  },
  {
    "text": "If you look in practice, though, \nprobably after a year in production,   that architecture diagram doesn't reflect reality. \nLike, there are other things that you would  ",
    "start": "2219120",
    "end": "2227520"
  },
  {
    "text": "have to extend it to include other systems, \nwhere it's talking to, all that good stuff.  You're smiling. You just like hearing her talk.\nI do. She's brilliant. Before my current role at  ",
    "start": "2227520",
    "end": "2242080"
  },
  {
    "text": "Verica, I was the Chief Security Architect \nat UnitedHealth Group and that's where I   started doing a lot of this stuff \nwith security chaos engineering. So,  ",
    "start": "2242080",
    "end": "2248800"
  },
  {
    "text": "she's so right. When people come to me...a \nsolutions architect and a data architect   would come to me for the same system and \nshow me two different diagrams, right.  ",
    "start": "2248800",
    "end": "2256880"
  },
  {
    "text": "Often the system never actually reflected that. \nThat was just how they believe the system to   work. So, there is a...and...I'll get to that \nin a second but...is that...so it's that neither   one of them are correct but, like...and when we \nsay mental model too, think about the number of  ",
    "start": "2256880",
    "end": "2266560"
  },
  {
    "text": "mental models you have running through...that \nwere humans and their perceptions of things.  So let's say you have 10 microservices in a modern \napplication, right. You've got payments, you've  ",
    "start": "2266560",
    "end": "2275760"
  },
  {
    "text": "got billing, you have reported, you've got 10 of \nthem, right. You don't have 10, but usually, for  ",
    "start": "2275760",
    "end": "2280960"
  },
  {
    "text": "each service, there's a team of engineers, right. \nThere's an engineering manager and probably some   engineers as part of that, right. And sometimes \none team will handle two but usually just one. So,  ",
    "start": "2280960",
    "end": "2290560"
  },
  {
    "text": "you have 10 sets of humans working on individual \nmicroservices. Those microservices are not  ",
    "start": "2290560",
    "end": "2297280"
  },
  {
    "text": "independent. They're dependent upon each other for \nfunctionality. So, all these things have to work   together. And let's say they're doing things like \nCI and CD in DevOps. They're making, let's say,  ",
    "start": "2297280",
    "end": "2308320"
  },
  {
    "text": "five changes a day per microservice. Maybe they're \nnot on the same schedule, maybe they're not.  They're all the vital changes that affect each \nother, right, in this post-appointment world.  ",
    "start": "2308320",
    "end": "2317920"
  },
  {
    "text": "So, just imagine the number of changes in \nsystems impacting each other. All these teams  ",
    "start": "2317920",
    "end": "2325040"
  },
  {
    "text": "see their world of the system post-appointment \ndifferently, right. So, like, it's a shared  ",
    "start": "2325040",
    "end": "2332160"
  },
  {
    "text": "mental model. So, if the humans that are \noperating the system don't understand   the system in their mental model, \nit's hard. Complex systems are hard,  ",
    "start": "2332160",
    "end": "2343600"
  },
  {
    "text": "right. But, like, we have to get these engineers \nthat are operating these critical complex systems  ",
    "start": "2343600",
    "end": "2349280"
  },
  {
    "text": "better information and better context so they can \nbe more effective with what they're trying to do.",
    "start": "2349280",
    "end": "2353840"
  },
  {
    "text": "Let's put that in the context of the book. \nYou've got a 90-page book here and you have  ",
    "start": "2354800",
    "end": "2361600"
  },
  {
    "start": "2355000",
    "end": "2665000"
  },
  {
    "text": "another one coming out. What's the purpose \nof the first book here, the first 90 pages? ",
    "start": "2361600",
    "end": "2367280"
  },
  {
    "text": "I would say it's something bigger than an \nappetizer but maybe not a big steak sort of meal,  ",
    "start": "2368160",
    "end": "2375440"
  },
  {
    "text": "introduction to security chaos engineering. The \nidea is you get a bitesize into the underlying  ",
    "start": "2375440",
    "end": "2381440"
  },
  {
    "text": "philosophy, enough to get you started and to \nrethink kind of your security programs and   practices, procedures, all the good stuff \nas well as to be able to get started with  ",
    "start": "2381440",
    "end": "2389360"
  },
  {
    "text": "how to conduct experiments, which Aaron \nvery much led, as well as some examples   of experiments that might work for kind \nof the way most systems are built. So,  ",
    "start": "2389920",
    "end": "2398880"
  },
  {
    "text": "for instance, like, thinking about, automation \nservers, orchestration control plains, just  ",
    "start": "2398880",
    "end": "2406160"
  },
  {
    "text": "vanilla sort of Linux servers. We have \na bunch of cool experiments there.  So, it's a how-to guide for, \"Okay, you're early \nin your journey. You would think maybe...\" More  ",
    "start": "2406160",
    "end": "2415120"
  },
  {
    "text": "realistically, you know that something is off \nin your security program. You don't seem to be   getting results. Why is that? We talk about that a \nlittle bit because we compare what I call security  ",
    "start": "2415120",
    "end": "2424400"
  },
  {
    "text": "theater, which is kind of the traditional way, \nwhere you just do things for the sake of feeling   like you're doing things about the security \nproblem, then the security chaos engineering  ",
    "start": "2424400",
    "end": "2431839"
  },
  {
    "text": "way. So, it's enough for you to see, \"Okay, here \nare some of the reasons why it's not working   today. Here's maybe how we can reimagine \nit both from an organizational and kind of  ",
    "start": "2431840",
    "end": "2440319"
  },
  {
    "text": "cultural perspective as well as the philosophies \nbehind practices. Then here's how we can get   started in practice with some experiments.\"\nWhat the phonebook's going to do is going to  ",
    "start": "2440320",
    "end": "2448800"
  },
  {
    "text": "extend that. It adds much more depth. It's \ngoing to be a full-fledged just guide for  ",
    "start": "2448800",
    "end": "2453760"
  },
  {
    "text": "not just how to build a brand-new modern security \nprogram that works for this modern era of complex  ",
    "start": "2454640",
    "end": "2460880"
  },
  {
    "text": "systems we're talking about but also many more \ncase studies because that's the one thing that   is very clear from kind of the audience is they \nwanna hear more from a diversity of industries  ",
    "start": "2460880",
    "end": "2471599"
  },
  {
    "text": "and organizational types. How has it worked \nfor you? There's going to be a large, chunky  ",
    "start": "2471600",
    "end": "2477280"
  },
  {
    "text": "part of the book that's dedicated to that too.\nOne of the ways that you and I have talked about,  ",
    "start": "2477280",
    "end": "2482480"
  },
  {
    "text": "Aaron, when we were together in Singapore, maybe \neven Sydney, is that people learn from failure,  ",
    "start": "2482480",
    "end": "2489440"
  },
  {
    "text": "other people's failures, hopefully. Where does \nthat fit into what you guys are working on here?",
    "start": "2490400",
    "end": "2495279"
  },
  {
    "text": "The underlying philosophy of \nsecurity chaos engineering is   that failure is a great teacher \nand that failure is inevitable  ",
    "start": "2496000",
    "end": "2502240"
  },
  {
    "text": "so we might as well learn from it.\nThat is the first opening…  I think it might be the first sentence.\nPlease, Yoda, Yoda, teacher...failure...the  ",
    "start": "2502240",
    "end": "2509031"
  },
  {
    "text": "best is...whatever's Yoda teaching, is it?\nWhatever it is..  Somebody who was...Steve...I \nforget. Dr. Steve...one  ",
    "start": "2509031",
    "end": "2516319"
  },
  {
    "text": "of Gene Kim’s friends said that failure \nis the default state of the system. ",
    "start": "2516320",
    "end": "2523600"
  },
  {
    "text": "Oh, that's Dr. David Woods.\nOkay. You're right.  And that's what's...one of many Woodsisms. But \nhe loves to say the system was never broken.  ",
    "start": "2523600",
    "end": "2534319"
  },
  {
    "text": "It was designed that way, right. Right? \nFailure is a visible component in all human  ",
    "start": "2534320",
    "end": "2540320"
  },
  {
    "text": "evolution. It's how we learn. I \nmean, we fall, we get up. Failure is  ",
    "start": "2540960",
    "end": "2550160"
  },
  {
    "text": "a core component of how we grow and build \nbetter systems. What we're doing...that's   why we opened up the first book with it. \nProbably going to open up the second book  ",
    "start": "2551840",
    "end": "2558800"
  },
  {
    "text": "with something similar just because we need \nto...people need to understand that we're   not very good at this stuff we're doing, right. \nWe're trying to get better and this is a way you  ",
    "start": "2558800",
    "end": "2568400"
  },
  {
    "text": "can...this is a methodology, this is a discipline \nyou can adopt to help you get better at it. ",
    "start": "2568400",
    "end": "2575119"
  },
  {
    "text": "So, what I love about chaos engineering as \nan engineer is the confidence you built,  ",
    "start": "2575120",
    "end": "2580800"
  },
  {
    "text": "right. Like, I'm not just putting something \nout in the ether in some system, some control,  ",
    "start": "2580800",
    "end": "2586080"
  },
  {
    "text": "some firewall, some whatever hoping that \nit works when I need it to work. I'm  ",
    "start": "2586080",
    "end": "2590640"
  },
  {
    "text": "actively introducing a problem it's supposed to \nwork under. I know it works. Knowing it works  ",
    "start": "2591200",
    "end": "2596480"
  },
  {
    "text": "creates just a level of confidence when something \nbad does happen in the wild that you know that  ",
    "start": "2596480",
    "end": "2603760"
  },
  {
    "text": "you're not fully covered but you have confidence \nthat you can handle those sorts of conditions.  There's also a meta point that maybe gets into \nthe more cold corporate territory. But most  ",
    "start": "2603760",
    "end": "2615359"
  },
  {
    "text": "traditional security strategy today is based \non trying to prevent impossible failure, as   David would say. So, one, you're wasting a lot of \nmoney, what...in the economic experience known as  ",
    "start": "2615360",
    "end": "2625040"
  },
  {
    "text": "opportunity cost, both the time and money that \nyou're spending on trying to prevent failure   from happening, which is impossible, could be \nspent on actually preparing for that inevitable  ",
    "start": "2625040",
    "end": "2633360"
  },
  {
    "text": "failure and making sure that you're recovering \ngracefully and that the impact to the business   is minimized. That's not where the focus is. \nToday it's trying to minimize risk, which  ",
    "start": "2633360",
    "end": "2642240"
  },
  {
    "text": "is very nebulous, to zero and it doesn't work.\nSo again, from that cold corporate perspective,   we're just wasting a boatload of money right now \non trying to prevent failure, which is impossible.  ",
    "start": "2642240",
    "end": "2651840"
  },
  {
    "text": "The meta point here is that it results in \nfailures of security programs. By trying   to prevent failure, we're introducing failure at \nthe macro level in our security programs, which is  ",
    "start": "2651840",
    "end": "2660640"
  },
  {
    "text": "slightly poetic but very unfortunate for the \nusers whose data we're not protecting very well.",
    "start": "2660640",
    "end": "2665200"
  },
  {
    "start": "2665000",
    "end": "2759000"
  },
  {
    "text": "You both have mentioned Sounil \nYu a couple of times here.   Who else should people be following? Sounil \nis an obvious one. He does great stuff. ",
    "start": "2665840",
    "end": "2674000"
  },
  {
    "text": "I think certainly following people who helped \npioneer chaos engineering, one, the kind of,   like, the performance side of things.\nWho would that be? ",
    "start": "2675040",
    "end": "2681600"
  },
  {
    "text": "Well, some of Aaron Rinehart's colleagues.\nCasey for one. I mean, Casey's obvious…  Casey Rosenthal created chaos engineering \nat Netflix. And then there's Nora Jones.  ",
    "start": "2681600",
    "end": "2690320"
  },
  {
    "text": "She did the keynote for Reinvent years ago. \nThere is also David Woods, and Richard Cook.  ",
    "start": "2690960",
    "end": "2696720"
  },
  {
    "text": "For security chaos engineering, you've got \nJamie Dicken. She's doing some amazing work.",
    "start": "2699360",
    "end": "2704320"
  },
  {
    "text": "Absolutely.\nShe wrote the Cardinal Health   pieces there. Mario Platt. \nYeah, Mario Platt for sure. Some  ",
    "start": "2705280",
    "end": "2714560"
  },
  {
    "text": "people are in an adjacent space which again \nwe're...security chaos engineering isn't just   about the experiments. That's an important part \nof it but that's also the underlying philosophy.  ",
    "start": "2714560",
    "end": "2722320"
  },
  {
    "text": "I would say Bea Hughes is someone who I know. She \ngave a talk, I think, back...gosh, in 2013. It was  ",
    "start": "2722320",
    "end": "2728560"
  },
  {
    "text": "all about like, \"Hey, maybe we should actually \nbe working with the humans in our systems and   maybe they matter and maybe that...just telling \nthem hey, you made a mistake and you're wrong  ",
    "start": "2728560",
    "end": "2736480"
  },
  {
    "text": "isn't particularly helpful and how can we become \nmore confident during an incident response.\" I know she's also continued to publish \nand talk about, I would say, contrarian,  ",
    "start": "2736480",
    "end": "2746720"
  },
  {
    "text": "takes to traditional security which I think \nis an important thing because, again, security   chaos engineering is all about challenging our \nassumptions. I think it's important to follow  ",
    "start": "2746720",
    "end": "2753440"
  },
  {
    "text": "thinkers who are challenging those assumptions \nabout what I would call status quo security.",
    "start": "2753440",
    "end": "2757520"
  },
  {
    "text": "To kind of close the loop here,   what are you hoping to accomplish? What do you \nhope people will do once they've read the book? ",
    "start": "2758840",
    "end": "2770800"
  },
  {
    "start": "2759000",
    "end": "3018000"
  },
  {
    "text": "I have a very long wish list but getting away with \nhuman error as a reason for incidents, as a root  ",
    "start": "2775760",
    "end": "2782000"
  },
  {
    "text": "cause of incidents I think would be huge because \nfrom that trickles so many different changes.   If we stop thinking that it's an individual \nhuman who caused this massive incident...if  ",
    "start": "2782000",
    "end": "2790160"
  },
  {
    "text": "you assume that, then you aren't looking at the \ndesign, you aren't looking...you're completely   ignoring the fact that your mental model may be \noff. You just think, \"Well, we need to just, like,  ",
    "start": "2791840",
    "end": "2799760"
  },
  {
    "text": "punish the human or create more restrictions \naround the human.\" Nothing's ever gonna get   better. So that's one of the key items there.\nAt a broader level other than world peace and  ",
    "start": "2799760",
    "end": "2809760"
  },
  {
    "text": "harmony, I think it's...ultimately, we \nwant...information security right now is  ",
    "start": "2809760",
    "end": "2814960"
  },
  {
    "text": "honestly letting down the modern discipline of \nsoftware engineering. I think that's safe to   say. We would very much like to kind of usher \ninformation security into the 21st century in a  ",
    "start": "2814960",
    "end": "2825440"
  },
  {
    "text": "way that's going to make systems more resilient, \nnot just keep spending money and making a lot of  ",
    "start": "2825440",
    "end": "2830800"
  },
  {
    "text": "people kind of very well off and, you know, give \nthem more importance than thought leaders. We want   information security that works, not that just \ndoes something for the sake of doing something. ",
    "start": "2830800",
    "end": "2840319"
  },
  {
    "text": "I'm glad you said the human error bit. \nThat was gonna be mine. I would also add   root cause to that because root cause does not \nexist. It never has. It's a fallacy, right.  ",
    "start": "2842000",
    "end": "2850640"
  },
  {
    "text": "Take this example. Name one reason why you \nas a person...root cause, are successful,  ",
    "start": "2852000",
    "end": "2858240"
  },
  {
    "text": "right. You can't, right. If you can't name one \nreason why something's successful, you can't  ",
    "start": "2859040",
    "end": "2863520"
  },
  {
    "text": "do the same for why it's not, right. If you, \nand then human error as the root cause of an  ",
    "start": "2864400",
    "end": "2872160"
  },
  {
    "text": "incident or a problem, that's the beginning \nof your investigation, not the end, right. ",
    "start": "2872160",
    "end": "2877520"
  },
  {
    "text": "So, I challenge more discipline in that role. I \nwant to just build off what Kelly said too. It's  ",
    "start": "2877520",
    "end": "2884320"
  },
  {
    "text": "not that there are humans that cannot try, \nright. Passionate people are trying...in this  ",
    "start": "2885440",
    "end": "2891520"
  },
  {
    "text": "craft trying to do good things. What we're trying \nto do is lead them in a direction, I think, that  ",
    "start": "2891520",
    "end": "2897440"
  },
  {
    "text": "targets the real problem at heart which \nis complex systems. And I think what  ",
    "start": "2898720",
    "end": "2904640"
  },
  {
    "text": "we're trying to also achieve is give them away \none...the philosophy of thinking about a...think   about what we do differently and not...this \nis not Kelly and Aaron just making stuff up,  ",
    "start": "2904640",
    "end": "2914480"
  },
  {
    "text": "right. This comes from the world of safety \nengineering, how they've been able to pioneer   and transform how they handle airline accident \ninvestigations or nuclear power plant incidents. ",
    "start": "2914480",
    "end": "2923920"
  },
  {
    "text": "We bring that strength in too from the philosophy \nof why we're saying you should think about doing  ",
    "start": "2926560",
    "end": "2931600"
  },
  {
    "text": "this differently for this reason. Furthermore, \nwe follow that up with...in the larger book  ",
    "start": "2931600",
    "end": "2938320"
  },
  {
    "text": "that's coming towards the end of the year \nis a deep how-to, how to write these things.  ",
    "start": "2938320",
    "end": "2943840"
  },
  {
    "text": "This is not super advanced engineering, this \nis not AI, this is not the blockchain, this is  ",
    "start": "2944480",
    "end": "2949520"
  },
  {
    "text": "not some magic engineering that you pour on your \nstuff and it'll solve everything. This is a basic  ",
    "start": "2949520",
    "end": "2955040"
  },
  {
    "text": "level of instrumentation similar to testing. We're \ngonna walk through some of the different examples,  ",
    "start": "2955040",
    "end": "2961120"
  },
  {
    "text": "different kinds of systems. We have case studies \nfrom the government, and we have case studies from   healthcare, banking, and startups, so everybody \nhas an idea of how this stuff could be applied and  ",
    "start": "2961120",
    "end": "2971280"
  },
  {
    "text": "how to write them. And, you know, we look forward \nto seeing more stories unfold in the community. ",
    "start": "2971280",
    "end": "2977440"
  },
  {
    "text": "Importantly, it's gonna be inclusive. This is not \na movement that can be solved just by information  ",
    "start": "2977440",
    "end": "2982640"
  },
  {
    "text": "security professionals, which I agree with, they \njust need a kind of better way to conceive the   problem. It's also for software architects, \nsoftware engineers, you know, whether that's  ",
    "start": "2982640",
    "end": "2990560"
  },
  {
    "text": "leaders or people kind of, you know, building \nsystems day today. We actually will have chapters   covering each kind of phase of the software \ndelivery lifecycle. So, if you're just, like,  ",
    "start": "2990560",
    "end": "2998320"
  },
  {
    "text": "architecting your system, you can open up the \narchitect thing and designing chapter and be,   like, how can security chaos engineering help me \nmake this system more resilient against attackers. ",
    "start": "2998320",
    "end": "3006800"
  },
  {
    "text": "So, we want it to be both practical, grounded in \nprinciples, and have ample examples so people feel  ",
    "start": "3006800",
    "end": "3011840"
  },
  {
    "text": "confident about, I guess, interestingly enough, \nbeing more confident in their systems so… ",
    "start": "3012400",
    "end": "3017520"
  },
  {
    "start": "3018000",
    "end": "3079000"
  },
  {
    "text": "The book is out, \"Security Chaos Engineering\".\nThe slim book is.  The slim book is out.\nAnd then the full book with  ",
    "start": "3018480",
    "end": "3023760"
  },
  {
    "text": "the animal on the cover, which is TBD, we're very \nexcited to see what will be given with the animal,  ",
    "start": "3023760",
    "end": "3029840"
  },
  {
    "text": "that will be out I think later this year.\nYeah. And then the first book is written more   to be, like...to be read from end to end whereas \nI think the larger book is much larger and it's  ",
    "start": "3029840",
    "end": "3041200"
  },
  {
    "text": "the reference [inaudible 00:51:23] As Kelly \nsaid, you can open up if you're an architect,   the architecture section.\nRight. Thanks to you both.  Thank you for having us.\nThat was great.  Thank you.\nYeah. Thank you.",
    "start": "3041200",
    "end": "3046480"
  }
]
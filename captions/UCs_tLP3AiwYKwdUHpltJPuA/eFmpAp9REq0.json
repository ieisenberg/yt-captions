[
  {
    "start": "0",
    "end": "147000"
  },
  {
    "text": "okay so my session is called fail happens my name is Martin svage I'm Community builder in serverless area",
    "start": "12280",
    "end": "19279"
  },
  {
    "text": "apart from that I'm running User Group uh in broa in my hometown and today I'm",
    "start": "19279",
    "end": "24640"
  },
  {
    "text": "going to talk about the failures that can happen in the event driven architectures so I'm going to talk about",
    "start": "24640",
    "end": "29720"
  },
  {
    "text": "inte ation with the sqs and and the kesis and all bad things that can happen to your system also how we can monitor",
    "start": "29720",
    "end": "36680"
  },
  {
    "text": "that situations some pinch of the cost and the chaos engineering so first let's",
    "start": "36680",
    "end": "43120"
  },
  {
    "text": "understand how it happens that our Lambda is getting message from the queue so basically it's getting into our",
    "start": "43120",
    "end": "49160"
  },
  {
    "text": "Handler then we can call our third party so it might be database third party system through API whatever and then we",
    "start": "49160",
    "end": "55280"
  },
  {
    "text": "are acknowledging that you have processed the item and we are deleting that and it's considered a",
    "start": "55280",
    "end": "61480"
  },
  {
    "text": "success so how it happens that this message is going in general to our Lambda so we have our sources of the",
    "start": "61480",
    "end": "68240"
  },
  {
    "text": "events and we have the component that lives inside the AWS Lambda itself is",
    "start": "68240",
    "end": "73320"
  },
  {
    "text": "not our function it's some part of the AWS Lambda service that will pull that",
    "start": "73320",
    "end": "78400"
  },
  {
    "text": "sources it can also then filter them it can budge them so we can have processing",
    "start": "78400",
    "end": "84119"
  },
  {
    "text": "um of bigger parts of the events from uh from our source and in case of some some",
    "start": "84119",
    "end": "90280"
  },
  {
    "text": "of the sources it can do a lot of heavy lifting like bisecting running tumble Windows controlling your concurrency",
    "start": "90280",
    "end": "96560"
  },
  {
    "text": "doing retries and so on so this service is great and uh in general if you are",
    "start": "96560",
    "end": "102000"
  },
  {
    "text": "working with the Lambda and you're consuming these sources most probably you don't even know what is the API or",
    "start": "102000",
    "end": "107200"
  },
  {
    "text": "sdks for the loading those informations from those services like for example how to integrate with Kinesis data streams",
    "start": "107200",
    "end": "114240"
  },
  {
    "text": "and then this event Source mapping is sending synchronously that payload to your Lambda",
    "start": "114240",
    "end": "120840"
  },
  {
    "text": "but life is not always happy right sometimes we have failures and in that situation what might happen if you have",
    "start": "120840",
    "end": "127200"
  },
  {
    "text": "the Mal from item and we know that it's Mal because it's for example there's wrong contract on it processing that",
    "start": "127200",
    "end": "133680"
  },
  {
    "text": "message over and over it's insane right so what we have to do is that we have to do something to not repeat that failure",
    "start": "133680",
    "end": "142000"
  },
  {
    "text": "over and over so what we can do with such message we can either drop it we",
    "start": "142000",
    "end": "147400"
  },
  {
    "start": "147000",
    "end": "656000"
  },
  {
    "text": "can retry it or we can send it to the letter q for further investigation or",
    "start": "147400",
    "end": "152560"
  },
  {
    "text": "handling another way so first of all let's take a look at the drop situation",
    "start": "152560",
    "end": "158360"
  },
  {
    "text": "so we are taking this message from the queue it's getting into our Handler and we know that it is malr because for",
    "start": "158360",
    "end": "163920"
  },
  {
    "text": "example it's invalid or contract is not matching whatever we are expecting so try repeating that message doesn't make",
    "start": "163920",
    "end": "171440"
  },
  {
    "text": "lot of sense so what we can do is that we can just drop this message so we are returning okay from our Lambda hander",
    "start": "171440",
    "end": "177200"
  },
  {
    "text": "and even Source mapping will remove that message from from the sqsq but we need to be make sure that it is audited and",
    "start": "177200",
    "end": "183599"
  },
  {
    "text": "that this message is for sure useless what we have another option to",
    "start": "183599",
    "end": "189319"
  },
  {
    "text": "do is running that on that letter queue so in that case how we are configuring that we are send setting up on the sqs",
    "start": "189319",
    "end": "196959"
  },
  {
    "text": "information about how many receive counts our message will be sent over to the dead letter then we are ret trying",
    "start": "196959",
    "end": "204519"
  },
  {
    "text": "and repeating processing of that message because let's say that there is some temporary issue or something wrong is",
    "start": "204519",
    "end": "211159"
  },
  {
    "text": "happening not always that message is malformed and after uh reaching that Max receive counts sqs on our behalf we send",
    "start": "211159",
    "end": "218400"
  },
  {
    "text": "that message to the dead letter Q usually it is for the unknown issues what also might happen is that we have a",
    "start": "218400",
    "end": "225799"
  },
  {
    "text": "message we are picking it from the queue and let's say that it's malr and we know about it we know that we W can do",
    "start": "225799",
    "end": "231879"
  },
  {
    "text": "anything and we don't want to drop it maybe you want to send it to the letter CU because our that letter policy is",
    "start": "231879",
    "end": "237480"
  },
  {
    "text": "that someone will pick it up and for example something manually or we need to investigate that case in that situation",
    "start": "237480",
    "end": "243720"
  },
  {
    "text": "we can send that message on ourselves to that letter because let's imagine the situation that we have Max receive count",
    "start": "243720",
    "end": "250680"
  },
  {
    "text": "200 repeating that scenario that we know that is failed for 200 times makes no",
    "start": "250680",
    "end": "255920"
  },
  {
    "text": "sense and might be costly the same situation might happen if we are processing this message and based on the",
    "start": "255920",
    "end": "262639"
  },
  {
    "text": "response from our integration that we have with our third party we know that it will not better will be better",
    "start": "262639",
    "end": "268520"
  },
  {
    "text": "anytime soon right because it's just the way that processing is working so um key",
    "start": "268520",
    "end": "275800"
  },
  {
    "text": "things about the that letter when message is going to the letter we have up to 14 days to pick it up after that",
    "start": "275800",
    "end": "283000"
  },
  {
    "text": "there is a retention period it expires on that message and this message will be deleted from the queue and we will lose",
    "start": "283000",
    "end": "288120"
  },
  {
    "text": "it so what we have to do before that time is that we have to store it and",
    "start": "288120",
    "end": "293360"
  },
  {
    "text": "potentially replay it in the future or even right now but we have to be uh we",
    "start": "293360",
    "end": "299919"
  },
  {
    "text": "have to remember about few things one temporal coupling so in case that we are loading this message we are loading data",
    "start": "299919",
    "end": "305840"
  },
  {
    "text": "from some third party system and we are doing some action based on that it might change over time so if you're reping",
    "start": "305840",
    "end": "311960"
  },
  {
    "text": "that it might be changed for example it might be tax value or something like that another thing is versioning so our",
    "start": "311960",
    "end": "318440"
  },
  {
    "text": "events has to be versioned if we are playing that after a long time and something has changed with our service it might be not processed for example or",
    "start": "318440",
    "end": "325199"
  },
  {
    "text": "processed in a different way if we are not having versioning on our event so it's critical another thing is ownership so every que",
    "start": "325199",
    "end": "332680"
  },
  {
    "text": "must have an owner someone has to pick up that messages and someone has to be responsible for it might be Department",
    "start": "332680",
    "end": "338440"
  },
  {
    "text": "might be team might be person whatever but someone some entity has to be responsible for it and also it's",
    "start": "338440",
    "end": "346479"
  },
  {
    "text": "important to have alerts on it in distributed systems have plenty of that that letter cues because we have plenty",
    "start": "346479",
    "end": "352120"
  },
  {
    "text": "of cues and our architectures might be quite complicated so we want don't want to have dashboards and watching them",
    "start": "352120",
    "end": "357759"
  },
  {
    "text": "over and over right we just want to be alerted that something bad happened and what we have to watch in my opinion in",
    "start": "357759",
    "end": "363639"
  },
  {
    "text": "the DAT cues there's there are two key things one is how many messages are there so we won't have zero messages on",
    "start": "363639",
    "end": "369759"
  },
  {
    "text": "the DAT obviously and also for how long these messages are there so if message",
    "start": "369759",
    "end": "375199"
  },
  {
    "text": "is going d d generously close to the retention period we might lose that",
    "start": "375199",
    "end": "380680"
  },
  {
    "text": "message and lose that information so it's something that we can't can have in our system okay but to",
    "start": "380680",
    "end": "388160"
  },
  {
    "text": "make sure that someone will get this even we have we have set it up imagine the scenario following on the screen so",
    "start": "388160",
    "end": "394520"
  },
  {
    "text": "on the very beginning we have failure that started at the end it got resolved but to make sure that this failure was",
    "start": "394520",
    "end": "400840"
  },
  {
    "text": "resolved over the time we need to make sure that someone will be alerted and will do some action if in the meantime",
    "start": "400840",
    "end": "407960"
  },
  {
    "text": "we had some attacks outages uh someone has set up to eager alarm and our inbox",
    "start": "407960",
    "end": "413039"
  },
  {
    "text": "is full of the messages most probably developers what they do nothing they are just skipping those messages they're in",
    "start": "413039",
    "end": "419879"
  },
  {
    "text": "them and they don't care so what we can do for that situation is that what we",
    "start": "419879",
    "end": "425680"
  },
  {
    "text": "can set up is that after alarm we have information about on the event Bridge what we can do then is to we can start a",
    "start": "425680",
    "end": "431919"
  },
  {
    "text": "function that can periodically go and check if our alarm is already in the okay state or it's still in alarm state",
    "start": "431919",
    "end": "439360"
  },
  {
    "text": "in case our alarm is still in the alarm State what we can do is that we can retrigger the alarm actions and remember",
    "start": "439360",
    "end": "446160"
  },
  {
    "text": "people that who are responsible for that theor que that they have to do do something about it and it's super",
    "start": "446160",
    "end": "451759"
  },
  {
    "text": "important to always have dead letters remember about it whenever you're setting any even driven system that has",
    "start": "451759",
    "end": "457960"
  },
  {
    "text": "option to put the that letter do it in my opinion it should be not even",
    "start": "457960",
    "end": "463000"
  },
  {
    "text": "optional okay but even if you have that letter Q are you safe is there no chance",
    "start": "463000",
    "end": "468240"
  },
  {
    "text": "that you will lose your message there is but let's start slowly",
    "start": "468240",
    "end": "474240"
  },
  {
    "text": "so uh if you have even Source mapping that I have described at the very beginning it works in a way that it's po",
    "start": "474240",
    "end": "479720"
  },
  {
    "text": "that messages from the sqs and then it's evoking our function and we can control",
    "start": "479720",
    "end": "484879"
  },
  {
    "text": "here two things regarding the concurrency of processing One Is Res concurrency so it's the cap of the how",
    "start": "484879",
    "end": "490960"
  },
  {
    "text": "many concurrent executions on uh our Lambda is available for AWS to invoke",
    "start": "490960",
    "end": "497280"
  },
  {
    "text": "and other thing is maximum concurrency so in that way we are saying to the even Source mapping how many invocations on",
    "start": "497280",
    "end": "504479"
  },
  {
    "text": "our Lambda at the same time might be invoked Okay so",
    "start": "504479",
    "end": "510319"
  },
  {
    "text": "back in the days there was only option to have reserved concurrency control so if you have cap on processing because",
    "start": "510319",
    "end": "516959"
  },
  {
    "text": "you didn't want to too quickly process some stuff um some let's say have some",
    "start": "516959",
    "end": "523000"
  },
  {
    "text": "we're calling some third party and we didn't want to put too many requests at the same time we could control it over reserved concurrency and how it works",
    "start": "523000",
    "end": "529959"
  },
  {
    "text": "that when our invent Source mapping is taking messages from the queue it's trying to assign to the function but if",
    "start": "529959",
    "end": "536040"
  },
  {
    "text": "you have Reserve concurrency to 10 like in this example in this article then what might happen is that there is no",
    "start": "536040",
    "end": "542680"
  },
  {
    "text": "free Lambda to assign it to then this message is going back to the queue and it's treated like a normal failure so it",
    "start": "542680",
    "end": "548920"
  },
  {
    "text": "might happen that your message in the worst case scenario was not even processed once on your Lambda and it's",
    "start": "548920",
    "end": "555079"
  },
  {
    "text": "landing on the the letter q but it's not that bad scenario because there might be something worse in case if you have lots",
    "start": "555079",
    "end": "562000"
  },
  {
    "text": "of messages to be processed and those messages can be assigned to this Lambda all the time and we are not reaching the",
    "start": "562000",
    "end": "568240"
  },
  {
    "text": "this Max receive count so it's not going to the letter queue this message might be gone so there is a in theory",
    "start": "568240",
    "end": "575200"
  },
  {
    "text": "situation that even you have the letter your message will be gone okay and what we can do here we can",
    "start": "575200",
    "end": "582320"
  },
  {
    "text": "add maximum concurrency so it works in a way that our EV Source mapping is",
    "start": "582320",
    "end": "587560"
  },
  {
    "text": "understanding that it what is our maximum uh cap on the concurrent execution and it will be processed",
    "start": "587560",
    "end": "593680"
  },
  {
    "text": "everything will be fine but there's one uh exception here that if you have um",
    "start": "593680",
    "end": "599480"
  },
  {
    "text": "not enough um free executions on your whole account level then it might happen that",
    "start": "599480",
    "end": "605399"
  },
  {
    "text": "your message will be have the same problem that we're we're just describing with the reserve concurrency right because it still can't invoke the",
    "start": "605399",
    "end": "611680"
  },
  {
    "text": "function it's still going back to the queue and the same situation might happen the retention so my two advises here don't",
    "start": "611680",
    "end": "619240"
  },
  {
    "text": "skip on retention if you want to have some kind of limitation of retries or",
    "start": "619240",
    "end": "624880"
  },
  {
    "text": "you can have some want to have some limitations regarding the um time of processing that message you can put it",
    "start": "624880",
    "end": "630959"
  },
  {
    "text": "on the contract level and it is really important right now so this is the article from last year if we resum in",
    "start": "630959",
    "end": "638279"
  },
  {
    "text": "then at the last R rain event it scaling of our uh event sour mapping has changed",
    "start": "638279",
    "end": "644760"
  },
  {
    "text": "so previously it was 60 concurrent executions up to 1,250 uh concurrent executions but right",
    "start": "644760",
    "end": "650880"
  },
  {
    "text": "now it's 300 concurrent executions every",
    "start": "650880",
    "end": "655920"
  },
  {
    "text": "minute okay and right now let's talk about the retries so before going to the retries",
    "start": "655920",
    "end": "663680"
  },
  {
    "start": "656000",
    "end": "1368000"
  },
  {
    "text": "how it happens that this message is retried so whenever our message is going to the Handler then clock starts and",
    "start": "663680",
    "end": "671880"
  },
  {
    "text": "we're calculating this visibility timeout after it elapses the message is visible to the any other consumer so",
    "start": "671880",
    "end": "677880"
  },
  {
    "text": "message is going back to the to the queue and it can be picked up by the other instance of the Lambda so it is",
    "start": "677880",
    "end": "684440"
  },
  {
    "text": "validated only on the even Source mapping updates and it's not validated if someone will change the configuration",
    "start": "684440",
    "end": "690480"
  },
  {
    "text": "of the queue so it's super important to keep an eye on it and whenever you're retrying those",
    "start": "690480",
    "end": "697480"
  },
  {
    "text": "messages what we are hoping to is that this third party at some point will be up maybe we were throttled maybe it was",
    "start": "697480",
    "end": "704279"
  },
  {
    "text": "some temporary issue maybe something changed on the network which was something small change but what also",
    "start": "704279",
    "end": "711240"
  },
  {
    "text": "might happen that we are calling this third party and it's not getting any better it's just having severe outage so",
    "start": "711240",
    "end": "718760"
  },
  {
    "text": "what we might do then is that we can as a first idea try to implement back off",
    "start": "718760",
    "end": "725639"
  },
  {
    "text": "so it works that instead of retrying the same message in a fixed periods of time we can calculate this back off",
    "start": "725639",
    "end": "732000"
  },
  {
    "text": "exponentially and do it in the more and longer and longer period and it's also important to apply",
    "start": "732000",
    "end": "739399"
  },
  {
    "text": "Jeter here so what we are doing is that we are applying randomization component to calculation of our next retry without",
    "start": "739399",
    "end": "746079"
  },
  {
    "text": "Jer what we are what we are having that we are having the spikes of request in the fixed amount of time with the Jitter",
    "start": "746079",
    "end": "752000"
  },
  {
    "text": "we are trying to uniformly distribute it over time and um trying to reduce the",
    "start": "752000",
    "end": "757800"
  },
  {
    "text": "risk that the this failure will happen again after next retry how we can do it",
    "start": "757800",
    "end": "763320"
  },
  {
    "text": "so on the sqs record that we are getting we have filled with attributes we have",
    "start": "763320",
    "end": "768560"
  },
  {
    "text": "the information about approximate receive count so how many times this message was try to be processed then",
    "start": "768560",
    "end": "775440"
  },
  {
    "text": "what we can do that we can just take it from these attributes and can compute it so we can compute this uh exponential",
    "start": "775440",
    "end": "783000"
  },
  {
    "text": "value of the next retry we can add a Jeter to limit the chance of doing that in this the same period and what also is",
    "start": "783000",
    "end": "789639"
  },
  {
    "text": "important to add the max value in there because since we are calculating this uh next periods with the exponential",
    "start": "789639",
    "end": "795000"
  },
  {
    "text": "component it might grow really really fast and then on the same record we are",
    "start": "795000",
    "end": "800360"
  },
  {
    "text": "getting the receipt handle and this is the value that we can use in the sqs SDK",
    "start": "800360",
    "end": "805639"
  },
  {
    "text": "to change message visibility so this is how we're overriding and having those um",
    "start": "805639",
    "end": "811040"
  },
  {
    "text": "increased periods of time of the next retry but we might ask ourself have we",
    "start": "811040",
    "end": "817079"
  },
  {
    "text": "changed anything right now what we have improved is that we have better rri distribution we have lower risk of",
    "start": "817079",
    "end": "823320"
  },
  {
    "text": "reaching those Max rri and does this message send to that letter q but we are",
    "start": "823320",
    "end": "828360"
  },
  {
    "text": "still calling our third party heart on because we have highly distributed system we are calling it a lot and what",
    "start": "828360",
    "end": "834800"
  },
  {
    "text": "is worse that we have this kind of respon time",
    "start": "834800",
    "end": "839959"
  },
  {
    "text": "distribution so it's up to our timeout and we are paying lots of money for it as we are charged for GP hours when we",
    "start": "839959",
    "end": "846120"
  },
  {
    "text": "are consuming Lambda so what we might introduce in at that point is to add the",
    "start": "846120",
    "end": "851680"
  },
  {
    "text": "circuit breaker it's the approach that basically when we are",
    "start": "851680",
    "end": "856759"
  },
  {
    "text": "calling our API and everything is working fine we are just calling it as soon as it started to fail we are not",
    "start": "856759",
    "end": "862160"
  },
  {
    "text": "calling our thir party anymore and from time to time we are switching to this half open state so this is the state in",
    "start": "862160",
    "end": "868800"
  },
  {
    "text": "which we are sending those Scout requests that will check if our depend dependency is up or down if it's up then",
    "start": "868800",
    "end": "875839"
  },
  {
    "text": "we're getting back to the business but in case that it's still down what we are doing we are tripping this circuit",
    "start": "875839",
    "end": "881120"
  },
  {
    "text": "breaker open and we are not calling it anymore what is an effect of that is that response time distribution so on",
    "start": "881120",
    "end": "888120"
  },
  {
    "text": "the maximum obviously it will be the worst case scenario but in the higher percentiles in this kind of lots of",
    "start": "888120",
    "end": "894959"
  },
  {
    "text": "requests we won't be waiting and paying for it and also what is better we are not killing our third",
    "start": "894959",
    "end": "902800"
  },
  {
    "text": "party okay and how we can Implement that so my recommendation is to use this",
    "start": "902800",
    "end": "908880"
  },
  {
    "text": "general purpose circuit breaker so it's like normal circuit breaker implementation but with a distributed",
    "start": "908880",
    "end": "914160"
  },
  {
    "text": "State it's super gr it has fallback support because we are doing that in our code we can even have backup system it's",
    "start": "914160",
    "end": "921440"
  },
  {
    "text": "very versatile because we can use it in any type of the integration and if you want to keep your storage somewhere you",
    "start": "921440",
    "end": "927639"
  },
  {
    "text": "have to be aware of one thing since it is based on the rate of the failures we have to do do the Persistence of uh",
    "start": "927639",
    "end": "935040"
  },
  {
    "text": "failures after every request because it's based on the rate right so in case that we have high throughput system",
    "start": "935040",
    "end": "941560"
  },
  {
    "text": "there are two ways that if we are having VPC we can use elastic cash if not we can use momento cach in case of low uh",
    "start": "941560",
    "end": "949079"
  },
  {
    "text": "throughput system we can use momento or Dynamo DB but we have to be aware that Dynamo DB might get costly in case that",
    "start": "949079",
    "end": "954880"
  },
  {
    "text": "our traffic will grow and also we can use momental or elastic as",
    "start": "954880",
    "end": "960279"
  },
  {
    "text": "there's another way that we can do it and is this way of uh what I call it",
    "start": "960279",
    "end": "965360"
  },
  {
    "text": "special purpose circuit breakers so it works in the way that we are implementing our ccle Breaker by manipulating our Event Source mapping so",
    "start": "965360",
    "end": "973600"
  },
  {
    "text": "basically it works in the way that we are observing metric emitted by our um Lambda function it can be picked up by",
    "start": "973600",
    "end": "980560"
  },
  {
    "text": "the even bridge and then we can run Lambda that will modify our Event Source mapping there is one risk here that it",
    "start": "980560",
    "end": "987880"
  },
  {
    "text": "can be potentially expensive ensive in case that we are not using the metrics that are given to us by the AWS for free",
    "start": "987880",
    "end": "994079"
  },
  {
    "text": "in the high resolution but if you want to have some custom metrics okay so the idea is that we will",
    "start": "994079",
    "end": "1001360"
  },
  {
    "text": "use the cloudwatch alarm State as our state of our circuit breaker so in case that everything is okay our secret is",
    "start": "1001360",
    "end": "1008120"
  },
  {
    "text": "closed we are calling our um third party as the full speed as we have enabled esm",
    "start": "1008120",
    "end": "1014040"
  },
  {
    "text": "in case that we our system will start to fail we our alarm will be in alarm State",
    "start": "1014040",
    "end": "1019480"
  },
  {
    "text": "then we are disabling events mapping so we are not taking any messages anymore and we are not calling our third party",
    "start": "1019480",
    "end": "1026438"
  },
  {
    "text": "at that point we have no metrics if we have no metrics we are going to the insufficient data State and then we can",
    "start": "1026439",
    "end": "1032760"
  },
  {
    "text": "enable our event sour mapping again but we can put the maximum scaling to the minimum value of two so that would be our Scout requests it will be rate based",
    "start": "1032760",
    "end": "1040038"
  },
  {
    "text": "there is no storage there's only one risk in case that our third party will be uh for a really long time down as",
    "start": "1040039",
    "end": "1047079"
  },
  {
    "text": "long as our retention period we can lose those messages and this is how it looks like on the cloudwatch so as you can see",
    "start": "1047079",
    "end": "1053520"
  },
  {
    "text": "if our alarm is in the um alarm state so those are this red areas then it's going",
    "start": "1053520",
    "end": "1059679"
  },
  {
    "text": "to the insufficient data State we are having some kind of calls then we have again alarm and and so on and so on and",
    "start": "1059679",
    "end": "1065960"
  },
  {
    "text": "at the point that we are disabling the failure our alarm is getting in okay and we are back to",
    "start": "1065960",
    "end": "1071559"
  },
  {
    "text": "business so right now I was talking about um processing of um different",
    "start": "1071559",
    "end": "1076960"
  },
  {
    "text": "types of the processing but right now let's take a look look at the pressing that in messages in the batches so what",
    "start": "1076960",
    "end": "1082120"
  },
  {
    "text": "we can do is that we can have batch size equals to one it's really not bad decision it's low throughput but it's",
    "start": "1082120",
    "end": "1088360"
  },
  {
    "text": "super easy implementation if you don't have competences in your team that's really not bad decision you can embrace",
    "start": "1088360",
    "end": "1093720"
  },
  {
    "text": "the scaling of the cloud and it won't be nothing bad will happen but what can",
    "start": "1093720",
    "end": "1100039"
  },
  {
    "text": "happen bad is that you are going to the BGE processing and you can do it so if",
    "start": "1100039",
    "end": "1105360"
  },
  {
    "text": "you will take a look at the animation how it works it works in a way that we if our Lambda is getting on the uh input",
    "start": "1105360",
    "end": "1113159"
  },
  {
    "text": "from the even Source mapping the batch of the request and even one of the items is malformed failed invalid whatever",
    "start": "1113159",
    "end": "1119679"
  },
  {
    "text": "error will happen in there we are retrying the whole batch in that case we are paying for all that executions we",
    "start": "1119679",
    "end": "1126799"
  },
  {
    "text": "are trying on successes and if you are using some third party that is expensive regarding calls that might be really",
    "start": "1126799",
    "end": "1134120"
  },
  {
    "text": "costly item potency is always important in the event driven architectures but if",
    "start": "1134120",
    "end": "1139240"
  },
  {
    "text": "you don't have em poten in this kind of situation it will be really bad for your system so what we can do in that case is",
    "start": "1139240",
    "end": "1146520"
  },
  {
    "text": "that we can switch the partial failures we are no more no longer returning errors from our Handler we are reporting",
    "start": "1146520",
    "end": "1153799"
  },
  {
    "text": "failed items there is a contract that you have to follow that is given to you by the EV Source mapping if you will",
    "start": "1153799",
    "end": "1160280"
  },
  {
    "text": "break it then the whole batch will be calculated as a success or a failure we are losing errors metric",
    "start": "1160280",
    "end": "1166799"
  },
  {
    "text": "because we are no longer returning errors from from our Lambda that is something that is critical to understand",
    "start": "1166799",
    "end": "1171840"
  },
  {
    "text": "and we need to make sure that it's on I know it sounds silly but it's really important from even Source mapping point",
    "start": "1171840",
    "end": "1177600"
  },
  {
    "text": "of view it's you are returning some response it doesn't care what it is but",
    "start": "1177600",
    "end": "1182640"
  },
  {
    "text": "in case that you will turn on this feature it knows that it has to understand your contract and to only",
    "start": "1182640",
    "end": "1188559"
  },
  {
    "text": "delete those messages that you won't Mark as a failures and here is how we are reporting the failures we just",
    "start": "1188559",
    "end": "1194480"
  },
  {
    "text": "passing simple uh object with the array of item identifiers of the failed items",
    "start": "1194480",
    "end": "1200840"
  },
  {
    "text": "so how this implementation might look like so we have some uh Lambda in go we",
    "start": "1200840",
    "end": "1205919"
  },
  {
    "text": "are first passing records we are validating records we are processing them and we are returning failures looks",
    "start": "1205919",
    "end": "1212159"
  },
  {
    "text": "very silly uh simple but the problem with this implementation is that it's completely wrong so what we are having",
    "start": "1212159",
    "end": "1218360"
  },
  {
    "text": "here that we have exactly same issue that we had before so if any message is malformed and the message is invalid you",
    "start": "1218360",
    "end": "1224880"
  },
  {
    "text": "are failing the whole badge what we have to do is that we need to introduce some kind of funnel like processing so we are",
    "start": "1224880",
    "end": "1231919"
  },
  {
    "text": "paring records and we are pro moving further in the processing only items that are not mal from then we are",
    "start": "1231919",
    "end": "1237919"
  },
  {
    "text": "validating we are passing only valid items to the processing and so on and so on right and we reporting files on every",
    "start": "1237919",
    "end": "1245919"
  },
  {
    "text": "stage and since we are processing items in batches then usually we are processing item in batches also when we",
    "start": "1245919",
    "end": "1253280"
  },
  {
    "text": "we are sending data over what might be also another option is that if you are doing that in parallel but but assuming",
    "start": "1253280",
    "end": "1259280"
  },
  {
    "text": "that we have some we are using some kind of B API or SDK it works exactly as we",
    "start": "1259280",
    "end": "1264760"
  },
  {
    "text": "describe with a partial fun with the partial failures so it works in a way that we are always getting 200 okay so",
    "start": "1264760",
    "end": "1271880"
  },
  {
    "text": "I've seen way too much this kind of implementation that developers are only uh reacting to the errors in case of",
    "start": "1271880",
    "end": "1278520"
  },
  {
    "text": "using bat SD case it's not working that way in case of the Dynamo DB you are getting unprocessed items in the",
    "start": "1278520",
    "end": "1284480"
  },
  {
    "text": "response it won't be an error or will mean that for example there is some major failure on the on the service",
    "start": "1284480",
    "end": "1290480"
  },
  {
    "text": "itself but you will get unprocessed items that you have to handle specially and in case of the services like sqs SNS",
    "start": "1290480",
    "end": "1296679"
  },
  {
    "text": "and um all shapes of forms of the kesis you will get the information about the",
    "start": "1296679",
    "end": "1301880"
  },
  {
    "text": "either identifier of item in the batch request or its",
    "start": "1301880",
    "end": "1308200"
  },
  {
    "text": "ID even if you have this partial failures there is still one issue that",
    "start": "1308559",
    "end": "1313600"
  },
  {
    "text": "might happen that will fail whole batch and you will reprocess items all the",
    "start": "1313600",
    "end": "1318720"
  },
  {
    "text": "Time Imagine the scenario that you are consuming some kind of batch SDK and it has some",
    "start": "1318720",
    "end": "1324880"
  },
  {
    "text": "Maximum value like for example it can process up to one megabyte right and if we are sending there over the items it",
    "start": "1324880",
    "end": "1332640"
  },
  {
    "text": "works fine everything was tested we're going to the production but then what it happens that you are adding one field to",
    "start": "1332640",
    "end": "1338279"
  },
  {
    "text": "your payload one another field to your payload yet another and yet another and at some point these messages are so big",
    "start": "1338279",
    "end": "1344880"
  },
  {
    "text": "that your batch is just overflowing this limit of the the batch SDK so what you",
    "start": "1344880",
    "end": "1350320"
  },
  {
    "text": "can do is if you take a look at the right animation that whenever we are seeing that our uh whole batch is",
    "start": "1350320",
    "end": "1356840"
  },
  {
    "text": "failing we can try to bict that um elements from the the badge and try to",
    "start": "1356840",
    "end": "1363120"
  },
  {
    "text": "process it again there is no support for that kind of processing in the sqs it is in the",
    "start": "1363120",
    "end": "1369080"
  },
  {
    "start": "1368000",
    "end": "1731000"
  },
  {
    "text": "kesis I mentioned before that our processing has to be it poent but item potency is not everything sometimes it's",
    "start": "1369080",
    "end": "1376080"
  },
  {
    "text": "also about the order so let's take a look at the scenario of the procing fifo it gives us order and the",
    "start": "1376080",
    "end": "1384159"
  },
  {
    "text": "duplication but also what it gives us is the limited bat size of 10 so our throughput is um hit by by that if you",
    "start": "1384159",
    "end": "1392720"
  },
  {
    "text": "will take a look carefully at the animation you can see that our items are not processed in the order because what",
    "start": "1392720",
    "end": "1399000"
  },
  {
    "text": "we are doing that we are we are just with the same the same implementation we are just reporting failures but then if",
    "start": "1399000",
    "end": "1406679"
  },
  {
    "text": "we are not pring those items in the ordered queue out of order it makes totally no sense so what we can do as an",
    "start": "1406679",
    "end": "1413600"
  },
  {
    "text": "idea is we can fail fast on first item in the B that will fail but what will happen then is that we will lose items",
    "start": "1413600",
    "end": "1421320"
  },
  {
    "text": "because if you are failing on the first item and we are not processing uh consecutive items in the batch then then",
    "start": "1421320",
    "end": "1427760"
  },
  {
    "text": "they are treated as a failures because we are reporting failures right now so what we have to do that we have to after",
    "start": "1427760",
    "end": "1433600"
  },
  {
    "text": "first failure item in the batch in theing sqs 5 for batches fail all the",
    "start": "1433600",
    "end": "1439320"
  },
  {
    "text": "consecutive items and we might ask ourself does it make sense to have this kind of small budges with this kind of",
    "start": "1439320",
    "end": "1445200"
  },
  {
    "text": "limitations because maybe not what we can do is we can switch to the Kinesis Kinesis provides us order previously in",
    "start": "1445200",
    "end": "1452360"
  },
  {
    "text": "the sqs 5o scenario it was based on the message group ID here we have the partition key and we can budge those",
    "start": "1452360",
    "end": "1458360"
  },
  {
    "text": "items up to 10,000 items and we have one consumer per chart it works in a way",
    "start": "1458360",
    "end": "1463799"
  },
  {
    "text": "that not like previously in the sqs we are let's say reading something from the Que and we blocking this item in the",
    "start": "1463799",
    "end": "1469679"
  },
  {
    "text": "processing here we have this consumer per chart and it has cursor and is trying to iterate Over The Shard",
    "start": "1469679",
    "end": "1476200"
  },
  {
    "text": "Whenever there is a failure we are repeating the processing of the item in case there is Success we are proc",
    "start": "1476200",
    "end": "1481440"
  },
  {
    "text": "progressing and all of that is kept for us in the Event Source mapping so we don't have to care about",
    "start": "1481440",
    "end": "1488159"
  },
  {
    "text": "it but what might happen is we have again M item or invalid item or",
    "start": "1488159",
    "end": "1493600"
  },
  {
    "text": "something is wrong with this item and this item will be reprocessed all the time for its retention period by default",
    "start": "1493600",
    "end": "1501080"
  },
  {
    "text": "it's 24 hours it's up to one year so in that case you have blocked chart but",
    "start": "1501080",
    "end": "1507080"
  },
  {
    "text": "what is worse in this scenario that if our item is expiring and our shart will be unblocked after it will be removed",
    "start": "1507080",
    "end": "1514679"
  },
  {
    "text": "from the uh from the from the stream the every item that is behind it most",
    "start": "1514679",
    "end": "1521480"
  },
  {
    "text": "probably will also expired and we lose everything behind that item so again",
    "start": "1521480",
    "end": "1526799"
  },
  {
    "text": "it's super important to have that letter cues setup and you have to be aware that",
    "start": "1526799",
    "end": "1532279"
  },
  {
    "text": "those that letter cues are working a little bit different with the sqs in sqs we had just item on the on the on the",
    "start": "1532279",
    "end": "1538799"
  },
  {
    "text": "Queue here what we are getting is that we are getting pointer to the stream uh to The Shard with this failed",
    "start": "1538799",
    "end": "1546760"
  },
  {
    "text": "item so what we can do in that situation is that we can report item uh failure",
    "start": "1546760",
    "end": "1552600"
  },
  {
    "text": "destination and it might be sqs or SNS in case of the failure it will be",
    "start": "1552600",
    "end": "1557679"
  },
  {
    "text": "invoked um either message on the sqs or it will be request to the SNS and it can be",
    "start": "1557679",
    "end": "1562720"
  },
  {
    "text": "picked up for example by our Lambda in Lambda what we can do is that we can we have to process this failure we can send",
    "start": "1562720",
    "end": "1569480"
  },
  {
    "text": "it over to another compute service we can send it to over sqs SNS we can put",
    "start": "1569480",
    "end": "1575039"
  },
  {
    "text": "it on as free it's up to our dead letter policy it doesn't matter but we have to",
    "start": "1575039",
    "end": "1580320"
  },
  {
    "text": "do it before its retention so this it's not like it can be on the on this SK and",
    "start": "1580320",
    "end": "1587000"
  },
  {
    "text": "rot in there no we have up to time of the retention and how to read this items we are getting the information on the",
    "start": "1587000",
    "end": "1593880"
  },
  {
    "text": "the letter event about the uh request context blah blah blah and we have also shart ID start sequence number and",
    "start": "1593880",
    "end": "1600679"
  },
  {
    "text": "stream Arn API is using stream name but doesn't matter we have to just pick",
    "start": "1600679",
    "end": "1605799"
  },
  {
    "text": "shart iterator and then we have information about how many items were failed in this badge and load all of",
    "start": "1605799",
    "end": "1611640"
  },
  {
    "text": "them it's real right that we have items how many items were there right and this",
    "start": "1611640",
    "end": "1616760"
  },
  {
    "text": "is because that is how Works processing items in the batches so if you will take",
    "start": "1616760",
    "end": "1622120"
  },
  {
    "text": "a look at the screen when you are getting the batch of size eight and item number five will be failing then what we",
    "start": "1622120",
    "end": "1628320"
  },
  {
    "text": "will get after rri that we have set up on the letter Q we'll have the pointer",
    "start": "1628320",
    "end": "1633720"
  },
  {
    "text": "to all of that items in this batch even the items that were successful and items that were not processed so it's really",
    "start": "1633720",
    "end": "1640840"
  },
  {
    "text": "important to keep that in mind what you can do with a single",
    "start": "1640840",
    "end": "1646000"
  },
  {
    "text": "Boolean is to add the Bice section so it mean that on the failure we are splitting in half our batch and trying",
    "start": "1646000",
    "end": "1653240"
  },
  {
    "text": "process again but we are not having to implement that uh ourselves like with the sqs but it's given to us by The",
    "start": "1653240",
    "end": "1659960"
  },
  {
    "text": "Event Source mapping and right now it since it would be uh splitting up to one item we have",
    "start": "1659960",
    "end": "1666240"
  },
  {
    "text": "badge size one in case of the failure obviously we can also add",
    "start": "1666240",
    "end": "1672159"
  },
  {
    "text": "partial failures right it works in the same way as was with the sqs with all everything more or less the same there's",
    "start": "1672159",
    "end": "1678600"
  },
  {
    "text": "a different contract doesn't means a bit different things but I will go that to that in the second but if you if you",
    "start": "1678600",
    "end": "1684799"
  },
  {
    "text": "will look at this animation and the animation that was previously displayed for the B section they're not that different right but only because of this",
    "start": "1684799",
    "end": "1691360"
  },
  {
    "text": "example it's only 10 items but the difference is crucial if you have B size",
    "start": "1691360",
    "end": "1696640"
  },
  {
    "text": "of size 100 and item number 90 will fail in case of the bisection what we will do",
    "start": "1696640",
    "end": "1702760"
  },
  {
    "text": "you will split that in half and we process first 50 items and so on and so on weing a lot of successful items in",
    "start": "1702760",
    "end": "1709960"
  },
  {
    "text": "case of bsection we are saying okay 89 items were successful let's keep",
    "start": "1709960",
    "end": "1716320"
  },
  {
    "text": "processing again starting from uh item number 90 and here's our contract we are just reporting the um sequence number of",
    "start": "1716320",
    "end": "1724640"
  },
  {
    "text": "the failed items and what is important here it will just pick the lowest value and start from",
    "start": "1724640",
    "end": "1731279"
  },
  {
    "start": "1731000",
    "end": "1870000"
  },
  {
    "text": "there if you have implemented that everything correctly we have implemented that we are not sure if it's working or",
    "start": "1731279",
    "end": "1737640"
  },
  {
    "text": "not so what we have to do that we have to test it right now and how we can force third party to fail it's kind of",
    "start": "1737640",
    "end": "1744440"
  },
  {
    "text": "hard right so what we can do that we can do caves engineering with the AWS Fe",
    "start": "1744440",
    "end": "1749880"
  },
  {
    "text": "service in this article just describe this approach with using layer that is based on the extension uh extensions API",
    "start": "1749880",
    "end": "1757760"
  },
  {
    "text": "and it works in a way that it's adding layer to your Lambda then it in it injects some kind of failure and it's",
    "start": "1757760",
    "end": "1765519"
  },
  {
    "text": "keeping there for some time and then it's just removing this layer what we have in control here we can um just",
    "start": "1765519",
    "end": "1772760"
  },
  {
    "text": "enable some part some type of the experiment so either response fault or latency fault we can also add the",
    "start": "1772760",
    "end": "1779760"
  },
  {
    "text": "probability of how probable is that this will be injected or not and in case of the latency we can set the value for the",
    "start": "1779760",
    "end": "1785960"
  },
  {
    "text": "latency in case of the response we can override the response it might be tricky in case of the partial failures because",
    "start": "1785960",
    "end": "1791919"
  },
  {
    "text": "it won't be dynamic so we will only uh fail the whole bash right so it might be tricky to test it what also we can do if",
    "start": "1791919",
    "end": "1799200"
  },
  {
    "text": "we don't want to override delay or other the response is that what we can we can um inject simulator failure to the I am",
    "start": "1799200",
    "end": "1808200"
  },
  {
    "text": "so in this article um there is described way of doing so we are in PH we are",
    "start": "1808200",
    "end": "1814880"
  },
  {
    "text": "executing SSM documents so what we can do here in case of such experiment that we can say which role we want to uh",
    "start": "1814880",
    "end": "1822399"
  },
  {
    "text": "Target what is the policy that we want to inject and it will be policy with explicit deny so it it has like",
    "start": "1822399",
    "end": "1829799"
  },
  {
    "text": "precedence over all of other rules and we can just block some type of the communication we are saying for how long",
    "start": "1829799",
    "end": "1836240"
  },
  {
    "text": "we want to run this kind of failure and rule that we execute it then we have the steps and we are attaching policy",
    "start": "1836240",
    "end": "1843159"
  },
  {
    "text": "running experiment and the touching policy right quite simple but what if we want to do something else maybe we want",
    "start": "1843159",
    "end": "1849519"
  },
  {
    "text": "to send malr message to our stream or or queue what we can do there is that we",
    "start": "1849519",
    "end": "1855960"
  },
  {
    "text": "can have special step that it will based on the python code since it's based on",
    "start": "1855960",
    "end": "1861880"
  },
  {
    "text": "the python code you can do anything in there and it can be also parameterized so you can write it once and just",
    "start": "1861880",
    "end": "1867080"
  },
  {
    "text": "parameterize it for your different workloads if you want to check if our",
    "start": "1867080",
    "end": "1874600"
  },
  {
    "start": "1870000",
    "end": "2165000"
  },
  {
    "text": "during our test what is going on in our system we need to have some observability the signal that will work",
    "start": "1874600",
    "end": "1881039"
  },
  {
    "text": "best in here are traces we have the service map it's since we have highly distributed systems that is the perfect",
    "start": "1881039",
    "end": "1887600"
  },
  {
    "text": "choice we have information about the status we have information about the details of the execution we can see how",
    "start": "1887600",
    "end": "1893080"
  },
  {
    "text": "it was connected and how it was flowing through our systems what is more we can add the attributes there so this is like",
    "start": "1893080",
    "end": "1899159"
  },
  {
    "text": "your domain values that you will put there something that is related to your only your system and it's just the way",
    "start": "1899159",
    "end": "1906320"
  },
  {
    "text": "of having the conversation with your application what is else in in the",
    "start": "1906320",
    "end": "1911960"
  },
  {
    "text": "tracing that you can add their span events so we can add the full details of the exception that were happening and I",
    "start": "1911960",
    "end": "1918480"
  },
  {
    "text": "don't know feature flags that were evaluated maybe circuit breaker stat that was changed or anything else that",
    "start": "1918480",
    "end": "1924360"
  },
  {
    "text": "you want doing there but to have this beautiful workflows how this communication is going through the",
    "start": "1924360",
    "end": "1930039"
  },
  {
    "text": "systems we need to propagate the information somehow so one way of doing so is to um use the w3c standard for for",
    "start": "1930039",
    "end": "1938720"
  },
  {
    "text": "doing so and it's even supported by the cloud events so in the cloud events",
    "start": "1938720",
    "end": "1944120"
  },
  {
    "text": "standard there is a place to put the information about the uh extension and there is also module for um",
    "start": "1944120",
    "end": "1951120"
  },
  {
    "text": "distributed tracing so that way if we are saying that over the payload we can just pick it up on the consumer and just",
    "start": "1951120",
    "end": "1957039"
  },
  {
    "text": "continue tracing from there but it's not always the scenario because sometimes we have contracts that we can't break what",
    "start": "1957039",
    "end": "1963679"
  },
  {
    "text": "we can do in such situations that we can add this context of the processing to",
    "start": "1963679",
    "end": "1968720"
  },
  {
    "text": "our attributes in case of the sqs for example so first we can just pick it up",
    "start": "1968720",
    "end": "1973880"
  },
  {
    "text": "from our current processing we can add it to the message attributes U in in case of the single or B request and then",
    "start": "1973880",
    "end": "1980120"
  },
  {
    "text": "on the consumer end we are picking those values up and continue our trace this is exactly how aw's implemented that in for",
    "start": "1980120",
    "end": "1987159"
  },
  {
    "text": "example in the X-ray so now let's consider some scenario we have producer that is",
    "start": "1987159",
    "end": "1992840"
  },
  {
    "text": "scheduling multiple tasks then we have some flow and every X message will fail x times if we'll do it in the way that I",
    "start": "1992840",
    "end": "2001159"
  },
  {
    "text": "just described what we can see that you have really huge trades with everything in there right with all of those",
    "start": "2001159",
    "end": "2006440"
  },
  {
    "text": "failures for every message in case that our badge size would be 50 100 then it",
    "start": "2006440",
    "end": "2012240"
  },
  {
    "text": "might be crazy right that we will have the whole uh all of those items in the",
    "start": "2012240",
    "end": "2017399"
  },
  {
    "text": "same trace it will be barely useful and every time we look for some domain value we will see the same Trace what you can",
    "start": "2017399",
    "end": "2023519"
  },
  {
    "text": "do that we can separate those spans and those traces so we can start the new",
    "start": "2023519",
    "end": "2028639"
  },
  {
    "text": "Trace before sending every message and sending adding new attributes then what we can have in our system that we can",
    "start": "2028639",
    "end": "2035240"
  },
  {
    "text": "have separate traces for for all of that messages that were",
    "start": "2035240",
    "end": "2041919"
  },
  {
    "text": "scheduled and there is one benefit as well so if we are having everything sent",
    "start": "2042080",
    "end": "2047880"
  },
  {
    "text": "as once we have sampled nothing or hold processing in case of doing splitting that per task we can have sample of it",
    "start": "2047880",
    "end": "2055839"
  },
  {
    "text": "of course not always we can split it if it's the same big process that has to be",
    "start": "2055839",
    "end": "2061720"
  },
  {
    "text": "um tracked together don't split it right the instrumentation of your code in with",
    "start": "2061720",
    "end": "2067839"
  },
  {
    "text": "the open Telemetry is just a matter of telling good story that will be understandable and useful for your",
    "start": "2067839",
    "end": "2074919"
  },
  {
    "text": "team but we can't base our operations on the traces because we will have to wash",
    "start": "2074919",
    "end": "2080240"
  },
  {
    "text": "them and no one has time to do it we we have better things to do during our day so what we have to do that we can set up",
    "start": "2080240",
    "end": "2087158"
  },
  {
    "text": "alarms for the processing what I would recommend to watch is the processing clack in case of the sqs and the K will",
    "start": "2087159",
    "end": "2093040"
  },
  {
    "text": "be approximate AG of all this message or iterator AG milliseconds for our business values that that have some kpis",
    "start": "2093040",
    "end": "2100800"
  },
  {
    "text": "that to follow right and some slos so another thing is to having this alarms",
    "start": "2100800",
    "end": "2106800"
  },
  {
    "text": "for the retention to just make sure that we won't lose any method because that is critical just a reminder to set up those",
    "start": "2106800",
    "end": "2114599"
  },
  {
    "text": "uh alarms for the dead letter cues and alarm for the throttles but only for the severe ones if we will have alarm that",
    "start": "2114599",
    "end": "2121359"
  },
  {
    "text": "will informing us that on every any throttle in our system it will be alarm fatigue and no one will care about those",
    "start": "2121359",
    "end": "2127280"
  },
  {
    "text": "alarms for sure so it's important to have proper setups based on the multiple observ observations and to make sure",
    "start": "2127280",
    "end": "2133839"
  },
  {
    "text": "that this issue is severe and also we have to have alarms on the scaling issues in case of the kesis for example",
    "start": "2133839",
    "end": "2140920"
  },
  {
    "text": "based on the read provision throughput it means that for example if you have stream and you have more and more consumers of it it might happen that it",
    "start": "2140920",
    "end": "2147960"
  },
  {
    "text": "will be throttled because of the limitations on the shart in that case what we have to do is that you can add enhanced fun out there's also",
    "start": "2147960",
    "end": "2154680"
  },
  {
    "text": "polarization Factor but it will be more related to the uh iterator H milliseconds so to make sure",
    "start": "2154680",
    "end": "2160520"
  },
  {
    "text": "that we are effectively consuming our streams and apart from that there's",
    "start": "2160520",
    "end": "2167079"
  },
  {
    "start": "2165000",
    "end": "2210000"
  },
  {
    "text": "auditability so what I would recommend to use is the K data firose with this",
    "start": "2167079",
    "end": "2172400"
  },
  {
    "text": "service what we can do from our compute we can just send the request to the Kine data fire hose in case of the kinetic",
    "start": "2172400",
    "end": "2178319"
  },
  {
    "text": "data streams we can connect it directly to the data fire hose and it's great service what it gives us is gives us",
    "start": "2178319",
    "end": "2184880"
  },
  {
    "text": "transforming to parket to the columnar format it can budge data for us partition it send it to the S3 for",
    "start": "2184880",
    "end": "2191440"
  },
  {
    "text": "example where we can control data life cycle Access Control through KMS and",
    "start": "2191440",
    "end": "2197119"
  },
  {
    "text": "encrypted address and also do analysis and also if you have the system",
    "start": "2197119",
    "end": "2202200"
  },
  {
    "text": "that you are building based on the event sourcing you might have better option to do so but if not I would advise to add",
    "start": "2202200",
    "end": "2209359"
  },
  {
    "text": "this kind of audit and the last thing that can be considered a failure is a",
    "start": "2209359",
    "end": "2214400"
  },
  {
    "start": "2210000",
    "end": "2316000"
  },
  {
    "text": "cost so if our service is eating the whole margin",
    "start": "2214400",
    "end": "2220240"
  },
  {
    "text": "then it might be you know problematic for the business right if you will take",
    "start": "2220240",
    "end": "2225640"
  },
  {
    "text": "a look at the screen this is on the x axis we have request per second on the y- axis we have cost of the solution so",
    "start": "2225640",
    "end": "2231560"
  },
  {
    "text": "as you can see for the low throughput systems Kines on demand and also an on demand with the enhanced fan out might",
    "start": "2231560",
    "end": "2238520"
  },
  {
    "text": "be more expensive than sqs but situation is way different in the when our system",
    "start": "2238520",
    "end": "2245720"
  },
  {
    "text": "is scaling so if we are getting hrut the cost comparison is on the U it's way",
    "start": "2245720",
    "end": "2253440"
  },
  {
    "text": "better for the kesis so it's not like the K is expensive because I've heard it also many times from the developers and",
    "start": "2253440",
    "end": "2260000"
  },
  {
    "text": "sqs is cheap it depends on your use case so do it wisely and observe your cost",
    "start": "2260000",
    "end": "2265280"
  },
  {
    "text": "always this is situation that uh was in one of the services that in my",
    "start": "2265280",
    "end": "2271119"
  },
  {
    "text": "team so we had a service this is this comparison on the level of about 40",
    "start": "2271119",
    "end": "2276280"
  },
  {
    "text": "Millions requests a day so the cost comparison is way better with the Kinesis so we have better",
    "start": "2276280",
    "end": "2282359"
  },
  {
    "text": "service to to process our data we can have much more consumers we are paying",
    "start": "2282359",
    "end": "2287800"
  },
  {
    "text": "for it less and it's just a better service that we have so please watch",
    "start": "2287800",
    "end": "2293000"
  },
  {
    "text": "your cost always if you don't want to how to do it there's article about under",
    "start": "2293000",
    "end": "2298119"
  },
  {
    "text": "that QR code when I'm writing in comparing sqs with the kesis and also there is a website that I have created",
    "start": "2298119",
    "end": "2303520"
  },
  {
    "text": "with this calculator where you can put your true put in your system and it can show you what is the more or less",
    "start": "2303520",
    "end": "2309800"
  },
  {
    "text": "comparison of the cost of different approaches with the sqs and the kesis so you can pick your choice so kit",
    "start": "2309800",
    "end": "2317640"
  },
  {
    "start": "2316000",
    "end": "2361000"
  },
  {
    "text": "takeaways something that you can do um I just picked a couple of things that",
    "start": "2317640",
    "end": "2323520"
  },
  {
    "text": "are low or no code actually and it can improve greatly your processing so first",
    "start": "2323520",
    "end": "2328839"
  },
  {
    "text": "of all setting up the DAT cues for all of your sqss failure destinations for all all your stream consumers what you",
    "start": "2328839",
    "end": "2335839"
  },
  {
    "text": "can also do is that you can uh put alarms for the processing CL especially including the retention",
    "start": "2335839",
    "end": "2341720"
  },
  {
    "text": "values on your cues and on any message on the those that letters that you have created or the one that you have apart",
    "start": "2341720",
    "end": "2348280"
  },
  {
    "text": "from that alarm for the severe trotting on your lambdas and concurrent executions on your account and turning",
    "start": "2348280",
    "end": "2353839"
  },
  {
    "text": "on bsection it's a single Boolean that you can just add and just put add the heavy lifting to uh AWS thank you for",
    "start": "2353839",
    "end": "2361880"
  },
  {
    "start": "2361000",
    "end": "2380000"
  },
  {
    "text": "your time let's get in touch for",
    "start": "2361880",
    "end": "2370359"
  }
]
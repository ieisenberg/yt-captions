[
  {
    "text": "all right it's really great to be here thank you very much for the for the warm welcome all right oh I probably have to",
    "start": "11400",
    "end": "18320"
  },
  {
    "text": "unlock my laptop all right there we go okay I'm",
    "start": "18320",
    "end": "27000"
  },
  {
    "text": "here to talk to you about running machine learning applications on on kubernetes using a platform called Cube",
    "start": "27000",
    "end": "32920"
  },
  {
    "text": "flow and my personal background is in natural language processing so that's the lens we're going to be viewing things from today but a lot of the",
    "start": "32920",
    "end": "39480"
  },
  {
    "text": "concepts are much broader and they apply to most any machine learning application a bit of context I have a",
    "start": "39480",
    "end": "45879"
  },
  {
    "text": "few housekeeping items context on myself uh so I'm Michelle kasban I'm an engineer at Google I'm based in San",
    "start": "45879",
    "end": "53199"
  },
  {
    "text": "Francisco I've been there since the beginning of the year and I've been working on the cow project ever since",
    "start": "53199",
    "end": "58519"
  },
  {
    "text": "well prior to that I was at a startup called Cordoba where I was director of data science building machine learning",
    "start": "58519",
    "end": "64640"
  },
  {
    "text": "applications on Google's kubernetes engine and prior to that I was a data science engineer at a different startup",
    "start": "64640",
    "end": "71439"
  },
  {
    "text": "called idibon and I was building machine learning applications on AWS for about a",
    "start": "71439",
    "end": "77000"
  },
  {
    "text": "decade before that I was a data engineer working in the Enterprise so that gives you a sense for my background where I'm",
    "start": "77000",
    "end": "82720"
  },
  {
    "text": "coming from and why I was really excited to start building a platform um that basically gave me the tools that I never",
    "start": "82720",
    "end": "88720"
  },
  {
    "text": "had when I was building things from scratch so a couple of the things that we'll talk about I want to go over some",
    "start": "88720",
    "end": "94799"
  },
  {
    "text": "of the biggest challenges in building machine learning applications and how they've informed some of the project",
    "start": "94799",
    "end": "100200"
  },
  {
    "text": "goals we'll take a look at what's inside what comes in the box of uh in a default",
    "start": "100200",
    "end": "105280"
  },
  {
    "text": "Cube flow install we'll see it in action and then we'll wrap up by talking about what's next for the project and what's",
    "start": "105280",
    "end": "111520"
  },
  {
    "text": "on the road map the requisite disclaimer slide uh before you start any machine learning",
    "start": "111520",
    "end": "117600"
  },
  {
    "text": "project there are two questions that you should ask self number one do you have a very clearly defined problem and number",
    "start": "117600",
    "end": "124240"
  },
  {
    "text": "two is there any way that it can be solved in a deterministic way because if there is that's what you should do um",
    "start": "124240",
    "end": "131720"
  },
  {
    "text": "machine learning is not always the answer despite what you may have heard on the internet and if my decade as a",
    "start": "131720",
    "end": "136800"
  },
  {
    "text": "data engineer taught me anything it's that counting things is still really hard so let's look at an example of a",
    "start": "136800",
    "end": "143599"
  },
  {
    "text": "very clearly defined problem that can't be solved in a deterministic way we're",
    "start": "143599",
    "end": "148840"
  },
  {
    "text": "going to build an application together today and that was inspired by one of my favorite NLP researchers from Stanford",
    "start": "148840",
    "end": "154879"
  },
  {
    "text": "so he wrote this book uh the language of food it's very approachable it doesn't go too deep into a lot of the",
    "start": "154879",
    "end": "160959"
  },
  {
    "text": "implementation details but it does explain things in a very interesting way now Dan drai's done some really",
    "start": "160959",
    "end": "166879"
  },
  {
    "text": "sophisticated research on the language behind food uh our application is not nearly as sophisticated it's a very",
    "start": "166879",
    "end": "173840"
  },
  {
    "text": "straightforward and what we're going to look at is identifying sentiment for restaurant reviews so given a review",
    "start": "173840",
    "end": "181280"
  },
  {
    "text": "from Yelp determine whether it's positive or negative we're going to be looking at a lot of code uh don't worry",
    "start": "181280",
    "end": "187799"
  },
  {
    "text": "too much about it because it's all on GitHub you can view it afterwards with all the instructions for you to run it yourself if you'd like but we'll start",
    "start": "187799",
    "end": "194720"
  },
  {
    "text": "off by looking at so I prepared a recording today because we're going to be training some models and provisioning nodes a lot of that has some dead time",
    "start": "194720",
    "end": "202000"
  },
  {
    "text": "and watching neural Nets converge is about as exciting as watching grass grow so I thought it would spare us we're",
    "start": "202000",
    "end": "207239"
  },
  {
    "text": "going to start out with the application that we intend to build we start out with a deterministic approach this is uh",
    "start": "207239",
    "end": "215000"
  },
  {
    "text": "this is a very simple this a flask app and what we have here is a review the",
    "start": "215000",
    "end": "220879"
  },
  {
    "text": "ramen was awful was Bland and mushy and after a few bites I couldn't handle eating anymore so really straightforward",
    "start": "220879",
    "end": "226840"
  },
  {
    "text": "something that you would find on Yelp and we have a button for predicting the sentiment and what's powering that",
    "start": "226840",
    "end": "232239"
  },
  {
    "text": "button right now is a JavaScript function where we look at the group of words um we have a list of negative ones",
    "start": "232239",
    "end": "239519"
  },
  {
    "text": "if we find one we mark it as negative if we don't we mark it as positive very straightforward and if we run that",
    "start": "239519",
    "end": "247480"
  },
  {
    "text": "function against this review we get something that's not very accurate it's not very useful um this is something",
    "start": "247480",
    "end": "255519"
  },
  {
    "text": "that machine learning can do much better because we can expand that list of negative words to our heart's content",
    "start": "255519",
    "end": "260519"
  },
  {
    "text": "but we'll never get up to 100% accuracy we'll always have some sort of Gap because of the way different languages",
    "start": "260519",
    "end": "265880"
  },
  {
    "text": "work and sometimes the negative words are at the beginning of the sentence language which has way too much Nuance",
    "start": "265880",
    "end": "271560"
  },
  {
    "text": "so we can do better let's throw some machine learning at it instead of using instead of starting from scratch we're",
    "start": "271560",
    "end": "277520"
  },
  {
    "text": "going to use a platform and that's what qlow is for it's a curated set of compatible tools and artifacts that lays",
    "start": "277520",
    "end": "284120"
  },
  {
    "text": "a foundation for running production machine learning apps cow enables consistency across",
    "start": "284120",
    "end": "289919"
  },
  {
    "text": "deployments by providing kubernetes object templates that bring together disparate",
    "start": "289919",
    "end": "295440"
  },
  {
    "text": "components now throughout the talk I'll be referencing several different layers we have our application layer that's the",
    "start": "295440",
    "end": "302320"
  },
  {
    "text": "sentiment analyzer that we just saw that UI and then we have our Q flow layer",
    "start": "302320",
    "end": "307479"
  },
  {
    "text": "these are the tools that enable us to build our application and then we have our infrastructure layer we have our",
    "start": "307479",
    "end": "312800"
  },
  {
    "text": "servers um this is where our kubernetes cluster lives our storage layer and any services that we're accessing throughout",
    "start": "312800",
    "end": "319880"
  },
  {
    "text": "the platform and what you'll see up here is this little icon and most of it'll be grayed out but I'll highlight the",
    "start": "319880",
    "end": "325319"
  },
  {
    "text": "sections that I'm talking about to make it a bit clear about which section uh which layer we referring to okay with",
    "start": "325319",
    "end": "331759"
  },
  {
    "text": "all that out of the way let's look at some of the major challenges in building machine learning",
    "start": "331759",
    "end": "336840"
  },
  {
    "text": "applications I want everyone to visualize their favorite piece of production code you know the one I'm talking about",
    "start": "336840",
    "end": "344280"
  },
  {
    "text": "it's out there running it's doing something very well defined doing its thing doing it well maybe you wrote it",
    "start": "344280",
    "end": "350840"
  },
  {
    "text": "maybe you didn't but think about how it got there it wasn't conceived in",
    "start": "350840",
    "end": "356560"
  },
  {
    "text": "production it didn't just appear there one day it came from somewhere maybe a staging",
    "start": "356560",
    "end": "363360"
  },
  {
    "text": "environment how did it get into that staging environment a Dev environment probably",
    "start": "363360",
    "end": "370880"
  },
  {
    "text": "hopefully at some point in that process there was a human pressing keys in front",
    "start": "370880",
    "end": "375960"
  },
  {
    "text": "of a computer and every time you move code from one physical environment to another you introduce risk our friend",
    "start": "375960",
    "end": "384479"
  },
  {
    "text": "the uh forklift driver Claus he's familiar with that risk he knows that moving from one environment to another",
    "start": "384479",
    "end": "391280"
  },
  {
    "text": "can introduce death and destruction can be kind of scary so what we need is a",
    "start": "391280",
    "end": "396759"
  },
  {
    "text": "solution that gives us portability that allows us to forklift our code from one place to another even if that's just",
    "start": "396759",
    "end": "402759"
  },
  {
    "text": "from local into production directly something that gives us some portability",
    "start": "402759",
    "end": "407919"
  },
  {
    "text": "and we don't just want to move our application but we want to be able to package all of those infrastructure components together to reduce the",
    "start": "407919",
    "end": "414280"
  },
  {
    "text": "variability to reduce the risk because there's fun there's a fundamental difference between running code on a",
    "start": "414280",
    "end": "419680"
  },
  {
    "text": "laptop versus in production in a data center another big challenge is",
    "start": "419680",
    "end": "427000"
  },
  {
    "text": "complexity you get all those pieces running together and it can turn into a big ball of mud so think back to that",
    "start": "427000",
    "end": "433800"
  },
  {
    "text": "piece of production code that you had in your head if it was a machine learning piece of code it probably looked",
    "start": "433800",
    "end": "439840"
  },
  {
    "text": "something like this we tend to have this outsized vision of the me of the machine learning",
    "start": "439840",
    "end": "446199"
  },
  {
    "text": "components in our system that doesn't always reflect reality usually it looks something closer to this there are a ton",
    "start": "446199",
    "end": "453120"
  },
  {
    "text": "of different components that support those machine learning pieces uh before you can even think about building models",
    "start": "453120",
    "end": "458800"
  },
  {
    "text": "you need to have some data generating that data ingesting it um exploring it",
    "start": "458800",
    "end": "465120"
  },
  {
    "text": "slicing it separating it between training and test um transforming it all",
    "start": "465120",
    "end": "470520"
  },
  {
    "text": "of that takes a lot of code a lot of work once we have that we can turn it",
    "start": "470520",
    "end": "476120"
  },
  {
    "text": "into a format that our models understand we extract features from it take things that are going to inform our predictions",
    "start": "476120",
    "end": "482400"
  },
  {
    "text": "and once we've built our models we have to do something with them hopefully we're validating them but we're storing them we're auditing them we're",
    "start": "482400",
    "end": "488639"
  },
  {
    "text": "versioning them and if we have a model that can't run on a single node we may be spraying",
    "start": "488639",
    "end": "494560"
  },
  {
    "text": "that out against several nodes updating it every time there's new data all this takes code those models live somewhere",
    "start": "494560",
    "end": "502759"
  },
  {
    "text": "they live within an application this was our flas app this was our restaurant uh our Resturant predictor and that can",
    "start": "502759",
    "end": "509800"
  },
  {
    "text": "involve a ton of business logic you have a UI you have to load balance that application it also has to",
    "start": "509800",
    "end": "516680"
  },
  {
    "text": "live somewhere lives on a platform and all of the components that support that like monitoring logging NCD components",
    "start": "516680",
    "end": "524480"
  },
  {
    "text": "there's a lot involved so that little model building piece it's just one of many so what we want is something that",
    "start": "524480",
    "end": "531240"
  },
  {
    "text": "can support all that complexity and allow us to form these smaller logical",
    "start": "531240",
    "end": "536680"
  },
  {
    "text": "groups that we can then sort of uh turn into these modular components that we can reuse that's",
    "start": "536680",
    "end": "544519"
  },
  {
    "text": "important we have all of those different pieces coming together um it's hard to",
    "start": "544519",
    "end": "549600"
  },
  {
    "text": "maintain this may seem obvious because this is sort of a generic software development conference but in the",
    "start": "549600",
    "end": "554640"
  },
  {
    "text": "Machining machine learning world like all of this stuff is pretty new and we don't really have the tools yet for",
    "start": "554640",
    "end": "561120"
  },
  {
    "text": "maintaining these complex systems because machine learning applications have a very different footprint there",
    "start": "561120",
    "end": "567079"
  },
  {
    "text": "are different pieces and the resource requirements are just there's so much more variability in it um just being",
    "start": "567079",
    "end": "573920"
  },
  {
    "text": "able to discover errors to identify it when they come up is not always straightforward because neural Nets can",
    "start": "573920",
    "end": "579680"
  },
  {
    "text": "be complicated we don't always understand why they make the decisions that they make so once we can find",
    "start": "579680",
    "end": "586200"
  },
  {
    "text": "errors can we recover from them and can we prevent them from happening in the future not all errors are preventable we",
    "start": "586200",
    "end": "593079"
  },
  {
    "text": "still don't know how to solve bias in our models once we if if we can identify and",
    "start": "593079",
    "end": "599640"
  },
  {
    "text": "if we do have a solution how quickly can we patch it and can we roll back to",
    "start": "599640",
    "end": "604920"
  },
  {
    "text": "versions that didn't have that bug so what we need is something that can shorten that development life cycle that",
    "start": "604920",
    "end": "610959"
  },
  {
    "text": "can automate much of these processes similar to the way we've resolved that in traditional uh traditional software",
    "start": "610959",
    "end": "619160"
  },
  {
    "text": "development capacity planning is huge because of that variability in resource requirements so the usage patterns uh",
    "start": "619160",
    "end": "626959"
  },
  {
    "text": "even the sort of um even the ones that we can identify the the common ones so",
    "start": "626959",
    "end": "632800"
  },
  {
    "text": "the one that our system that we always see even those can be very hard uh very hard to work around and accommodate but",
    "start": "632800",
    "end": "639720"
  },
  {
    "text": "when the demand spikes whether that's receiving more data or receiving more requests from the user side that can be",
    "start": "639720",
    "end": "645639"
  },
  {
    "text": "challenging to accommodate and being able to utilize your resources efficiently is non-trivial with machine",
    "start": "645639",
    "end": "652040"
  },
  {
    "text": "learning so what we need is something that's scalable uh kubernetes handles a ton of that so we want to run on top of",
    "start": "652040",
    "end": "658040"
  },
  {
    "text": "kubernetes and and we want something that can automatically provision nodes so that our application doesn't have to think about it it just requests",
    "start": "658040",
    "end": "664240"
  },
  {
    "text": "resources and it receives them they become allocated those challenges are some of",
    "start": "664240",
    "end": "671519"
  },
  {
    "text": "what's informed the main goals for the project uh main fundamental to the qill",
    "start": "671519",
    "end": "678200"
  },
  {
    "text": "project is to make it easy for everyone to develop deploy and manage portable scalable machine learning everywhere so",
    "start": "678200",
    "end": "685720"
  },
  {
    "text": "portability very important not just our application but the entire stack we care",
    "start": "685720",
    "end": "691079"
  },
  {
    "text": "about scalability this is why it's native to kubernetes uh this is what allows us to reduce the variability",
    "start": "691079",
    "end": "697920"
  },
  {
    "text": "between our physical environments um and not just that but between our microservices as well we don't have to",
    "start": "697920",
    "end": "704560"
  },
  {
    "text": "care about where services are running because we can just call it by name we don't have to worry about ports um and",
    "start": "704560",
    "end": "710320"
  },
  {
    "text": "any of the any of the networking details so third is composability uh we want",
    "start": "710320",
    "end": "716320"
  },
  {
    "text": "that we want a way to put it all together wrap it up tie a nice neat bow",
    "start": "716320",
    "end": "721760"
  },
  {
    "text": "on it um and reuse it and use it for very common processes that you see a lot",
    "start": "721760",
    "end": "727000"
  },
  {
    "text": "of machine learning and we don't want to just support the production instantiation of",
    "start": "727000",
    "end": "732079"
  },
  {
    "text": "that application but the full product life cycle from exploration development",
    "start": "732079",
    "end": "737240"
  },
  {
    "text": "all the way through to production and then patching and maintaining it over time what's also important is",
    "start": "737240",
    "end": "743320"
  },
  {
    "text": "specialized Hardware like gpus and tpus because if you know what you're doing",
    "start": "743320",
    "end": "748839"
  },
  {
    "text": "you can use these for training uh reduce your costs and improve your model performance in ways that you couldn't",
    "start": "748839",
    "end": "755560"
  },
  {
    "text": "otherwise so cow is entirely open source you can find it on GitHub it has been from the very beginning and it's for",
    "start": "755560",
    "end": "762440"
  },
  {
    "text": "anyone who's involved in the creation of machine learning applications we have a quarterly release Cadence uh the the",
    "start": "762440",
    "end": "770040"
  },
  {
    "text": "most brand new release branch is what you'll see today it's the o34",
    "start": "770040",
    "end": "775600"
  },
  {
    "text": "release and uh it's so it's still a release candidate there might be a few rough edges um but we should be rolling",
    "start": "775600",
    "end": "782079"
  },
  {
    "text": "a new one pretty soon we'll be moving to the od. 4 and fundamental to CU flow is that it",
    "start": "782079",
    "end": "788800"
  },
  {
    "text": "runs anywhere you run kubernetes that could be Google Cloud that could be your own cluster on Prem mini Cube wherever",
    "start": "788800",
    "end": "796079"
  },
  {
    "text": "uses open source kubernetes apis to manage some of your machine learning tasks some of the common ones and it",
    "start": "796079",
    "end": "801959"
  },
  {
    "text": "does this by providing custom resource definitions for doing things like Distributing your",
    "start": "801959",
    "end": "807760"
  },
  {
    "text": "training oh it adopts some of those kubernetes patterns some of those familiar patterns like the model of",
    "start": "807760",
    "end": "814920"
  },
  {
    "text": "having Loosely coupled microservices and managing your infrastructure declaratively qlow uses an open source",
    "start": "814920",
    "end": "821680"
  },
  {
    "text": "tool called case on it which is essentially a templating language for kubernetes and this is how we can package things up and move them from one",
    "start": "821680",
    "end": "828240"
  },
  {
    "text": "environment to another we have support for lots of different machine learning Frameworks uh tensorflow and pytorch are",
    "start": "828240",
    "end": "834920"
  },
  {
    "text": "the ones we see most commonly used but you're welcome to use whatever you would like now let's take a look at what's in the",
    "start": "834920",
    "end": "842120"
  },
  {
    "text": "box so you may still be asking yourself okay what exactly is this uh well it's a",
    "start": "842120",
    "end": "847600"
  },
  {
    "text": "framework for running machine learning Frameworks on the kubernetes framework you get the idea this is why",
    "start": "847600",
    "end": "854519"
  },
  {
    "text": "we have the layers at the top in the icon so let's revisit our definition slide it's a curated set of compatible",
    "start": "854519",
    "end": "861240"
  },
  {
    "text": "tools and artifacts that lay the foundation for running production machine learning apps it enables",
    "start": "861240",
    "end": "866560"
  },
  {
    "text": "consistency across deployments by providing kuber object templates that bring together all of these disparate",
    "start": "866560",
    "end": "874720"
  },
  {
    "text": "components okay here's a diagram everything in blue is what was added",
    "start": "874720",
    "end": "879800"
  },
  {
    "text": "since version o.2 and we start with so there's a lot behind this I've just",
    "start": "879800",
    "end": "885839"
  },
  {
    "text": "lumped it together into a general Ingress container I think there was a talk earlier that went into a lot more",
    "start": "885839",
    "end": "891759"
  },
  {
    "text": "detail uh cow supports a lot of that but I'm just going to call that Ingress we have things like Ambassador which is a",
    "start": "891759",
    "end": "898040"
  },
  {
    "text": "reverse http P proxy and this provides a single point of entry into your cluster",
    "start": "898040",
    "end": "903160"
  },
  {
    "text": "which means that you can map out a single external URL and then you can route it to anything running inside the",
    "start": "903160",
    "end": "908920"
  },
  {
    "text": "cluster so from there we have our Central dashboard you can think of this as a single pane of glass where all the",
    "start": "908920",
    "end": "915440"
  },
  {
    "text": "uis for each of the internal components uh it sort of Cates all them together and gives you a place to access it so",
    "start": "915440",
    "end": "921639"
  },
  {
    "text": "Jupiter hob uh we have this for running notebooks and a tensorflow job dashboard",
    "start": "921639",
    "end": "927000"
  },
  {
    "text": "for viewing statistics about the job that you're running uh through the tensorflow job operator now there's also",
    "start": "927000",
    "end": "933720"
  },
  {
    "text": "these three new components all uis one of them for Argo if you're not familiar with that it's a kubernetes native",
    "start": "933720",
    "end": "940959"
  },
  {
    "text": "workflow engine we have a hyperparameter tuning component called KB this is uh",
    "start": "940959",
    "end": "946680"
  },
  {
    "text": "this was this is new it was based on vizir if you read the white paper a few years ago that Google put out it's a",
    "start": "946680",
    "end": "952079"
  },
  {
    "text": "method for performing hyper parameter tuning and we'll see that later so I'll explain a little bit more what that is if you haven't done that before and then",
    "start": "952079",
    "end": "959040"
  },
  {
    "text": "our pipeline dashboard so this uses Argo under the hood but it's a way of",
    "start": "959040",
    "end": "964600"
  },
  {
    "text": "creating workflows from python there's a nice gooey there's a lot of kind of goodies we'll talk about that a little bit later each one of those components",
    "start": "964600",
    "end": "971759"
  },
  {
    "text": "has its own uh has corresponding controllers that execute everything that's happening that comes in from the",
    "start": "971759",
    "end": "978000"
  },
  {
    "text": "front end and then we also have job operators we have one for tensorflow one for",
    "start": "978000",
    "end": "983279"
  },
  {
    "text": "pytorch um pytorch is pretty new I believe it existed before but uh one of",
    "start": "983279",
    "end": "989399"
  },
  {
    "text": "the big changes is to bring it up to speed with tensor flows so there are a lot of common processes between the two",
    "start": "989399",
    "end": "996639"
  },
  {
    "text": "and oops there's a lot of common processes between the two and so we've brought the apis in line with each other",
    "start": "996639",
    "end": "1002600"
  },
  {
    "text": "so that when you're writing code in one it makes sense uh they're sort of in line now this is not the full Suite of",
    "start": "1002600",
    "end": "1009839"
  },
  {
    "text": "components there's a lot more that you can uh sort of install on your own but these are the this is part of the",
    "start": "1009839",
    "end": "1015279"
  },
  {
    "text": "default install Okay so click to deploy is one of the most exciting things particularly",
    "start": "1015279",
    "end": "1020639"
  },
  {
    "text": "for me this is brand new uh something that was added very recently and this is",
    "start": "1020639",
    "end": "1026480"
  },
  {
    "text": "a way to deploy a cluster uh entirely from a GUI so I used to have to do this",
    "start": "1026480",
    "end": "1032280"
  },
  {
    "text": "manually and it was a total pain so we're going to start out from an empty Google Cloud project there's nothing in",
    "start": "1032280",
    "end": "1038880"
  },
  {
    "text": "here we don't have any clusters uh you'll see it's totally empty we're going to go to that click to deploy tool",
    "start": "1038880",
    "end": "1046000"
  },
  {
    "text": "it's an open URL anyone here can visit it and what it's going to do for us is",
    "start": "1046000",
    "end": "1051600"
  },
  {
    "text": "basically set up an entire cow cluster for us so we enter in our project",
    "start": "1051600",
    "end": "1057679"
  },
  {
    "text": "name and we're going to skip I AP what that does is it generates an external URL which we're not going to use we're",
    "start": "1057679",
    "end": "1064200"
  },
  {
    "text": "just going to port forward into our container into our Ingress but that's it we specify the release branch that we",
    "start": "1064200",
    "end": "1070799"
  },
  {
    "text": "want and we click create the create deployment so what that's doing is behind the scenes it's generating all of",
    "start": "1070799",
    "end": "1076760"
  },
  {
    "text": "the objects that we need that includes includes project permiss permissions to enable apis that means creating service",
    "start": "1076760",
    "end": "1083559"
  },
  {
    "text": "accounts uh generating all of the objects so the cluster itself and",
    "start": "1083559",
    "end": "1089480"
  },
  {
    "text": "deploying all of the cube flow manifests onto it so here we have a brand new nice shiny",
    "start": "1089480",
    "end": "1095440"
  },
  {
    "text": "cluster and if we take a look at the workloads we'll see that CU flow is actually being installed into the",
    "start": "1095440",
    "end": "1102799"
  },
  {
    "text": "cluster this is this is significant I don't know if you've ever tried this on your own but it is super painful because",
    "start": "1102799",
    "end": "1107880"
  },
  {
    "text": "they are just so many pieces okay so that's click to",
    "start": "1107880",
    "end": "1113679"
  },
  {
    "text": "deploy that's one of the new things as part of the latest release what else is new not just a guey deployment tool but",
    "start": "1113679",
    "end": "1121480"
  },
  {
    "text": "there's also a command line tool that's KFL it's sort of an analog to CBE C and",
    "start": "1121480",
    "end": "1127280"
  },
  {
    "text": "that does something similar uh but you'll notice that click to deploy right now is just uh it's very specific to",
    "start": "1127280",
    "end": "1132480"
  },
  {
    "text": "Google Cloud it uses deployment manager which I'm not sure if that exists on other clouds um but the command tool",
    "start": "1132480",
    "end": "1139559"
  },
  {
    "text": "that's where you can use whatever backend you want and it splits up the cluster creation from the CU flow",
    "start": "1139559",
    "end": "1145559"
  },
  {
    "text": "install so that you can make changes in between you can script all of this out and when you're creating your",
    "start": "1145559",
    "end": "1151440"
  },
  {
    "text": "environment you can customize it to whatever you need now Auto provisioning is also a really neat feature it's",
    "start": "1151440",
    "end": "1157720"
  },
  {
    "text": "actually a gke feature but it's important for Q flow because it's it's a beta feature um but it's important for",
    "start": "1157720",
    "end": "1164320"
  },
  {
    "text": "qlow because it means that when we're running jobs we can just request resource ources we can say give me a GPU",
    "start": "1164320",
    "end": "1170600"
  },
  {
    "text": "or hit me up with a bunch of CPU and we don't have to worry about what's available in the cluster and likewise",
    "start": "1170600",
    "end": "1175799"
  },
  {
    "text": "when that job finishes and that request disappears uh all of those resources get spun down they don't exist which helps",
    "start": "1175799",
    "end": "1182919"
  },
  {
    "text": "with your billing and utilizing your resources more efficiently a couple of the other things",
    "start": "1182919",
    "end": "1189559"
  },
  {
    "text": "that we talked about Argo this is that workflow controller um this is uh this",
    "start": "1189559",
    "end": "1196240"
  },
  {
    "text": "was developed I think by the Intel team and it's again kubernetes native it's not only a workflow operator but there's",
    "start": "1196240",
    "end": "1202799"
  },
  {
    "text": "also a really cool CD tool they have something called Argo CD that lets you um it lets you basically install C flow",
    "start": "1202799",
    "end": "1210400"
  },
  {
    "text": "and maintain C flow in a in a continuous delivery situation um but also your own",
    "start": "1210400",
    "end": "1216120"
  },
  {
    "text": "application you can sort of use that Custom Tool and uh has a c flow",
    "start": "1216120",
    "end": "1221960"
  },
  {
    "text": "integration uh so native to the platform and then pytorch we talked about that",
    "start": "1221960",
    "end": "1227080"
  },
  {
    "text": "there's a lot of ongoing development in that space uh as as well as tensorflow that development is ongoing hyper",
    "start": "1227080",
    "end": "1234840"
  },
  {
    "text": "parameter tuning so the new thing is a study job so we'll look at that in our demo we'll see that in action um but the",
    "start": "1234840",
    "end": "1241320"
  },
  {
    "text": "idea behind hyperparameter tuning is that if you have uh a lot of times we'll",
    "start": "1241320",
    "end": "1247120"
  },
  {
    "text": "have a model and there will be certain parameters like the number of layers or the optimizer that we want to use and in",
    "start": "1247120",
    "end": "1254080"
  },
  {
    "text": "order we don't really know which parameters to start with but we'll start with anything thing and then as we uh we",
    "start": "1254080",
    "end": "1262080"
  },
  {
    "text": "can if we run that training job several different times with different parameters we'll get different results and hyperparameter tuning is sort of an",
    "start": "1262080",
    "end": "1268120"
  },
  {
    "text": "umbrella term for running that training job over and over again and swapping out different combinations of parameters so",
    "start": "1268120",
    "end": "1275200"
  },
  {
    "text": "the the qlow component basically lets you give it limits so like uh I want to",
    "start": "1275200",
    "end": "1280919"
  },
  {
    "text": "explore this parameter Within These limits and it will run all those jobs for you and keep track of it and help",
    "start": "1280919",
    "end": "1286679"
  },
  {
    "text": "you more quickly determine the best set of parameters so there a lot of people",
    "start": "1286679",
    "end": "1291720"
  },
  {
    "text": "really excited about that we'll take a look at it and then there's pipelines the KE pipelines is probably the biggest",
    "start": "1291720",
    "end": "1297760"
  },
  {
    "text": "release the biggest part of this most recent release and this is a way of running our endtoend ml workflows so uh",
    "start": "1297760",
    "end": "1306400"
  },
  {
    "text": "not just a single job with training and serving um and any",
    "start": "1306400",
    "end": "1312200"
  },
  {
    "text": "post-processing but the whole life cycle so running training several times seeing",
    "start": "1312200",
    "end": "1317679"
  },
  {
    "text": "how it changes over time seeing when things uh when things get updated",
    "start": "1317679",
    "end": "1322960"
  },
  {
    "text": "basically keeping track of it being able to monitor it and orchestrating that between different pipelines being able",
    "start": "1322960",
    "end": "1328360"
  },
  {
    "text": "to reuse some of those components uh and being integrated with all the other services both within qf flow and",
    "start": "1328360",
    "end": "1334840"
  },
  {
    "text": "throughout your platform your infrastructure it's a there's a python",
    "start": "1334840",
    "end": "1340000"
  },
  {
    "text": "SDK which means that you can create libraries so it makes it a lot easier to share and to operate from within a",
    "start": "1340000",
    "end": "1346120"
  },
  {
    "text": "notebook or just generally within an IDE or a GUI and uh yeah so we'll see a",
    "start": "1346120",
    "end": "1352960"
  },
  {
    "text": "little bit more of that as part of our demo okay I've talked a lot about it let's see it in action so this is what",
    "start": "1352960",
    "end": "1359279"
  },
  {
    "text": "we saw before this is after click to deploy this is what we have it's an empty cluster with Q flow installed this",
    "start": "1359279",
    "end": "1366320"
  },
  {
    "text": "is the the default installation and again all of the code is out on GitHub the first thing we'll do is we'll run",
    "start": "1366320",
    "end": "1372360"
  },
  {
    "text": "our training job so what we have is some tensor flow code that would normally run on a single node but what we do is we",
    "start": "1372360",
    "end": "1379480"
  },
  {
    "text": "send it to that TF job operator that qflow provides and it splits it up it turns it into uh a master a TF Master a",
    "start": "1379480",
    "end": "1388039"
  },
  {
    "text": "parameter server and several workers and we can configure how many workers in our case we'll have three we'll run that",
    "start": "1388039",
    "end": "1394039"
  },
  {
    "text": "against CPUs and then we'll switch over to using tpus so a tensor processing",
    "start": "1394039",
    "end": "1400480"
  },
  {
    "text": "unit if you're not familiar with it it's a hardware accelerator that was built specifically for Google Dat data centers",
    "start": "1400480",
    "end": "1407120"
  },
  {
    "text": "it's a network attached device which is uh distinct from gpus which are",
    "start": "1407120",
    "end": "1412600"
  },
  {
    "text": "attached to a physical node we'll talk a little bit more about that when we use it once we have a train model we create",
    "start": "1412600",
    "end": "1418240"
  },
  {
    "text": "a container for serving it so that we can call it for predictions and then a",
    "start": "1418240",
    "end": "1423279"
  },
  {
    "text": "UI which is that website that we saw for interacting with those predictions and seeing them from there we'll move into a",
    "start": "1423279",
    "end": "1430840"
  },
  {
    "text": "notebook that's attached to gpus and we'll do some customization of our model",
    "start": "1430840",
    "end": "1436320"
  },
  {
    "text": "and then we'll go into we'll create an example pipe plan also using gpus and then we'll perform hyperparameter",
    "start": "1436320",
    "end": "1442320"
  },
  {
    "text": "tuning all right so here's our cluster we have everything",
    "start": "1442320",
    "end": "1448320"
  },
  {
    "text": "installed all the default keyf flow components and we can list those we can",
    "start": "1448320",
    "end": "1453360"
  },
  {
    "text": "see what's in there so we have this is everything that we had on that chart but we have a few extra things so we have a",
    "start": "1453360",
    "end": "1459919"
  },
  {
    "text": "serving component a UI component and then some training jobs we're using something called tensor to tensor which",
    "start": "1459919",
    "end": "1466640"
  },
  {
    "text": "is a library of preconfig configured tensor flow models and we're running the same code but we have it in three",
    "start": "1466640",
    "end": "1472919"
  },
  {
    "text": "different versions We have one that runs on CPUs one against gpus and one against tpus we'll run the CPU version",
    "start": "1472919",
    "end": "1481120"
  },
  {
    "text": "First this is our case on it tool we're running an apply command which generates",
    "start": "1481120",
    "end": "1486399"
  },
  {
    "text": "our manifests and applies them onto our cluster simple as that if we take a look",
    "start": "1486399",
    "end": "1491679"
  },
  {
    "text": "at the pods because we just applied it we should be able to see all of the different pieces running",
    "start": "1491679",
    "end": "1499679"
  },
  {
    "text": "here we go so we have just like on our slide we have our Master parameter server and three workers so we'll take a",
    "start": "1499679",
    "end": "1506720"
  },
  {
    "text": "look at the logs and see what's going on inside and this should look familiar if",
    "start": "1506720",
    "end": "1512880"
  },
  {
    "text": "you've used tensorflow code before but it's pretty slow so we'd rather run that",
    "start": "1512880",
    "end": "1518520"
  },
  {
    "text": "against tpus so we'll run the same command issuing it's running the same code but",
    "start": "1518520",
    "end": "1524440"
  },
  {
    "text": "it's running it against tpus and we'll take a look at the pods that cre",
    "start": "1524440",
    "end": "1530320"
  },
  {
    "text": "creates now this is a little bit different because we're Distributing it",
    "start": "1536320",
    "end": "1541480"
  },
  {
    "text": "to our Hardware to our TPU so we don't have extra pods It also says that it's pending it",
    "start": "1541480",
    "end": "1547559"
  },
  {
    "text": "doesn't kick off right away remember that we talked about tpus as being network attached so what we've done with",
    "start": "1547559",
    "end": "1554399"
  },
  {
    "text": "our Cas oned apply command is we've issued a resource request so we've said I would like a TPU attached to this pod",
    "start": "1554399",
    "end": "1560840"
  },
  {
    "text": "please and what happens is in Google data center um we issue a request and",
    "start": "1560840",
    "end": "1567240"
  },
  {
    "text": "that uh that piece of Hardware running in some data center in maybe Iowa",
    "start": "1567240",
    "end": "1573000"
  },
  {
    "text": "somewhere um gets attached and we can then access that piece of Hardware that takes a little while to spin up but this",
    "start": "1573000",
    "end": "1580000"
  },
  {
    "text": "is distinct again from gpus and this is important because it means that we're only paying for the use of this hardware",
    "start": "1580000",
    "end": "1586679"
  },
  {
    "text": "for the duration of our job instead of for the lifetime of the node like you would with with",
    "start": "1586679",
    "end": "1592840"
  },
  {
    "text": "gpus okay so it took us about 5 minutes in this case and now we can watch it",
    "start": "1592840",
    "end": "1598799"
  },
  {
    "text": "running again same code AS running against CPUs so it should look pretty",
    "start": "1598799",
    "end": "1604559"
  },
  {
    "text": "familiar but it'll be quite a bit",
    "start": "1604559",
    "end": "1609080"
  },
  {
    "text": "faster yeah this looks much better so you see a few of the TPU specific",
    "start": "1610480",
    "end": "1616799"
  },
  {
    "text": "commands um those logs kind of scroll by quickly but we'll take a look at the the",
    "start": "1616799",
    "end": "1621919"
  },
  {
    "text": "numbers we'll look at the speed in more detail but first we'll look at the numbers with a",
    "start": "1621919",
    "end": "1628039"
  },
  {
    "text": "CPU and then we'll compare that against",
    "start": "1628039",
    "end": "1632120"
  },
  {
    "text": "TPU all right so obviously this depends on the type of code that you're running the type of job that you're doing um",
    "start": "1637039",
    "end": "1643760"
  },
  {
    "text": "there are inefficient ways to utilize tpus of course but in this particular case we see about 10 to 15x speed up so",
    "start": "1643760",
    "end": "1650240"
  },
  {
    "text": "that's pretty good considering it's the same exact code okay now that we have a train model we're going to add our",
    "start": "1650240",
    "end": "1656159"
  },
  {
    "text": "serving and UI containers that's our familiar apply",
    "start": "1656159",
    "end": "1663720"
  },
  {
    "text": "command and we can view these pods being",
    "start": "1665120",
    "end": "1670760"
  },
  {
    "text": "created we'll check our workloads tab we have two new pods and those will",
    "start": "1673200",
    "end": "1679320"
  },
  {
    "text": "take a bit to spin up but we didn't request any specific Hardware so they're pretty fast okay so we have serving and",
    "start": "1679320",
    "end": "1686720"
  },
  {
    "text": "UI so now that we've created those we've Port forwarded into our cluster so we can access them directly so we're going",
    "start": "1686720",
    "end": "1693360"
  },
  {
    "text": "into our UI container this is the same uh this is the same thing that we saw earlier but now instead of running",
    "start": "1693360",
    "end": "1700279"
  },
  {
    "text": "locally now it's running inside our cluster so this is our naive uh this is our naive function this is that",
    "start": "1700279",
    "end": "1705960"
  },
  {
    "text": "JavaScript function that we saw before now we're going to point it at our serving container the one that's running",
    "start": "1705960",
    "end": "1711480"
  },
  {
    "text": "inside of our cluster the one that we trained the one that's providing predictions and this see it's much more",
    "start": "1711480",
    "end": "1718320"
  },
  {
    "text": "accurate okay but so so what we used to generate that was an off-the-shelf model",
    "start": "1718320",
    "end": "1724279"
  },
  {
    "text": "was tensor to tensor preconfigured if we want to do something a bit more uh if we",
    "start": "1724279",
    "end": "1729760"
  },
  {
    "text": "want a bit more control over that let's say we need higher accuracies or we just want to do something a bit more",
    "start": "1729760",
    "end": "1735840"
  },
  {
    "text": "sophisticated this is where we might do a model and to do that we'll go into our",
    "start": "1735840",
    "end": "1741440"
  },
  {
    "text": "uh jupyter Hub instance so to get there we go to our Central dashboard and we'll just quickly show you what the TF job",
    "start": "1741440",
    "end": "1746760"
  },
  {
    "text": "dashboard looks like these are the two jobs we just ran these are some details about it um but what we really care",
    "start": "1746760",
    "end": "1751840"
  },
  {
    "text": "about is Jupiter Hub so we connect there and we can spawn our own instance so",
    "start": "1751840",
    "end": "1757480"
  },
  {
    "text": "we're choosing tensorflow 17 a one with support for gpus and we're requesting a",
    "start": "1757480",
    "end": "1763200"
  },
  {
    "text": "bunch of memory way more than I have on my laptop and requesting two gpus",
    "start": "1763200",
    "end": "1768440"
  },
  {
    "text": "so when we click on spawn what that does is behind the scenes it's creating all",
    "start": "1768440",
    "end": "1773919"
  },
  {
    "text": "these resources within our cluster and we can see that happening so we can see a new pod that's my pod and if we click",
    "start": "1773919",
    "end": "1780480"
  },
  {
    "text": "on it we can see that insufficient GPU so what's happening here uh this is so",
    "start": "1780480",
    "end": "1787640"
  },
  {
    "text": "we requested gpus not tpus but if you see right here it says it triggered a",
    "start": "1787640",
    "end": "1792799"
  },
  {
    "text": "scale up now this is node Auto provisioning this is the the kubernetes feature that the gke featured that if",
    "start": "1792799",
    "end": "1799640"
  },
  {
    "text": "you request something that the cluster doesn't already have then a node will automatically be provisioned for you and",
    "start": "1799640",
    "end": "1805080"
  },
  {
    "text": "you don't have to think about it so imagine that any data scientist can just request whatever resource they need you",
    "start": "1805080",
    "end": "1811240"
  },
  {
    "text": "can set up your cluster to have limits to that obviously so that your billing doesn't get out of control but we",
    "start": "1811240",
    "end": "1817120"
  },
  {
    "text": "started with three nodes and now because we've requested gpus you'll see another",
    "start": "1817120",
    "end": "1823519"
  },
  {
    "text": "node was created we didn't have to think about that and now that our note is ready take a",
    "start": "1823519",
    "end": "1830240"
  },
  {
    "text": "look at our pod our pod started pulling the images",
    "start": "1830240",
    "end": "1836600"
  },
  {
    "text": "um and here we go it's running now we can use it that means we can access a notebook with all these extra resources",
    "start": "1836600",
    "end": "1843039"
  },
  {
    "text": "that we requested of this familiar jupyter Hub",
    "start": "1843039",
    "end": "1849760"
  },
  {
    "text": "uh interface um there's nothing really custom here you can customize more of this if you'd like we're just going to",
    "start": "1849760",
    "end": "1856039"
  },
  {
    "text": "use a sort of standard Yelp not",
    "start": "1856039",
    "end": "1859919"
  },
  {
    "text": "book and qflow publishes images that you can use but you could also specify your",
    "start": "1861559",
    "end": "1867080"
  },
  {
    "text": "own so in this case uh we have the option between Python 2 and Python 3 cels we're going to make sure that we're",
    "start": "1867080",
    "end": "1872639"
  },
  {
    "text": "running the right one python 2 and then we're going to run",
    "start": "1872639",
    "end": "1878080"
  },
  {
    "text": "everything this particular image that Q publishes is missing a library that we need so the first thing we do we have",
    "start": "1878080",
    "end": "1883840"
  },
  {
    "text": "the ability to pip install whatever we need so we do that and then we download that data set all of that Yelp data so",
    "start": "1883840",
    "end": "1890919"
  },
  {
    "text": "all those reviews that powered our very first model we download that and we load it up",
    "start": "1890919",
    "end": "1900480"
  },
  {
    "text": "into memory now you can imagine that uh that this sort of interactive uh usually",
    "start": "1900480",
    "end": "1907880"
  },
  {
    "text": "people will use a notebook kind of separately from the rest of their application um but having it in the same",
    "start": "1907880",
    "end": "1914399"
  },
  {
    "text": "cluster means that you can access in cluster resources can have persistent discs so that you can share data between",
    "start": "1914399",
    "end": "1921600"
  },
  {
    "text": "notebooks um and lots of lots of really interesting features that are not part of C flow yet but the plan is to",
    "start": "1921600",
    "end": "1927519"
  },
  {
    "text": "integrate a lot more with notebooks so we've sliced off 100,000 from the top",
    "start": "1927519",
    "end": "1933519"
  },
  {
    "text": "and we're separating those out into positive and negative sets of words I think there's 5 and a half",
    "start": "1933519",
    "end": "1939399"
  },
  {
    "text": "million which is just way too many to be working with in a notebook but we could because we have the resources for it so",
    "start": "1939399",
    "end": "1945919"
  },
  {
    "text": "we can view the histograms for each of those groups um do some Exploration with it",
    "start": "1945919",
    "end": "1952799"
  },
  {
    "text": "and build our one hot encoding vectors we won't go into too much detail if you want to run the whole notebook you can",
    "start": "1952799",
    "end": "1959360"
  },
  {
    "text": "it's out there um but this is how we would generate a new model and then swap it out for that tensor to tensor",
    "start": "1959360",
    "end": "1966679"
  },
  {
    "text": "one okay so what we want to do now is uh",
    "start": "1966679",
    "end": "1971960"
  },
  {
    "text": "look at a a pipeline so this is what you see when you first go into the pipelines interface there are a few samples in",
    "start": "1971960",
    "end": "1978399"
  },
  {
    "text": "here you can take a look and run any of these they work out of the box but what we're going to do is generate our own",
    "start": "1978399",
    "end": "1984679"
  },
  {
    "text": "Pipeline and we're going to run gpus with it oh I mentioned that there's a python SDK so the way we're going to do",
    "start": "1984679",
    "end": "1991880"
  },
  {
    "text": "that is we'll switch to the console and uh we have we have a python file we'll",
    "start": "1991880",
    "end": "1998679"
  },
  {
    "text": "take a look inside where we're defining each of those steps so we're using the",
    "start": "1998679",
    "end": "2004159"
  },
  {
    "text": "SDK and we have a training step a post-processing step and here we are we're defining our",
    "start": "2004159",
    "end": "2010799"
  },
  {
    "text": "pipeline as just those two and this the SDK allows you to",
    "start": "2010799",
    "end": "2016559"
  },
  {
    "text": "basically just run that file and what it generates is a tar file inside that tar",
    "start": "2016559",
    "end": "2022559"
  },
  {
    "text": "file there is a bunch of really complicated yaml uh that that the the",
    "start": "2022559",
    "end": "2028919"
  },
  {
    "text": "SDK is translating into Argo speak so Argo knows how to run that um Argo has its own sort of VMO format that it",
    "start": "2028919",
    "end": "2035720"
  },
  {
    "text": "expects but we can take that tar file and upload it directly into the",
    "start": "2035720",
    "end": "2041480"
  },
  {
    "text": "UI so that's what we'll do and then we'll watch it",
    "start": "2041480",
    "end": "2047560"
  },
  {
    "text": "run so if we upload it knows what to do it can interpret everything inside and",
    "start": "2047560",
    "end": "2052878"
  },
  {
    "text": "we have our two steps so we have a few different parameters and we want to start an",
    "start": "2052879",
    "end": "2060520"
  },
  {
    "text": "experiment and then we want to kick off a run so an experiment is lots of",
    "start": "2060520",
    "end": "2065839"
  },
  {
    "text": "different runs together so you you can see how things change over time and we're just taking the default parameters",
    "start": "2065839",
    "end": "2071720"
  },
  {
    "text": "we don't really know what the right values are so we're just going to run it as",
    "start": "2071720",
    "end": "2077319"
  },
  {
    "text": "is oh this is an example that's using gpus and enough time has passed between",
    "start": "2077679",
    "end": "2084520"
  },
  {
    "text": "the last GPU job that we ran and this one so those nodes have disappeared so we're going to check to see what's",
    "start": "2084520",
    "end": "2089839"
  },
  {
    "text": "happening when we created that run it created a pod and that pod requested",
    "start": "2089839",
    "end": "2096320"
  },
  {
    "text": "resources requested GPU resources so we can see our pod it's unschedulable",
    "start": "2096320",
    "end": "2101880"
  },
  {
    "text": "because those GPU nodes have disappeared so if we go and look at our",
    "start": "2101880",
    "end": "2107400"
  },
  {
    "text": "nodes autoprovisioning will create a new one for",
    "start": "2107400",
    "end": "2113519"
  },
  {
    "text": "us and once that's ready then our job can",
    "start": "2120599",
    "end": "2125880"
  },
  {
    "text": "run so all of this is happening sort of behind the scenes and all you have to think about is what's happening in the",
    "start": "2125880",
    "end": "2132400"
  },
  {
    "text": "pipelines UI that generally don't usually have to pay much attention to that so now our job kicks off and we can",
    "start": "2132400",
    "end": "2139960"
  },
  {
    "text": "view the logs we can see the output and you'll see that the what we care about here is this uh this",
    "start": "2139960",
    "end": "2147640"
  },
  {
    "text": "validation accuracy it's pretty low um 0.11 that basically means that 11% of",
    "start": "2147640",
    "end": "2155680"
  },
  {
    "text": "the time will get an accurate prediction uh we could get better results by just flipping a coin so this really isn't a",
    "start": "2155680",
    "end": "2161640"
  },
  {
    "text": "useful model this is an instance where we would want to because we just use the default parameters this is where we want",
    "start": "2161640",
    "end": "2168680"
  },
  {
    "text": "to go and perform some hyperparameter tuning to figure out uh a better set of",
    "start": "2168680",
    "end": "2174800"
  },
  {
    "text": "parameters so this is where we go into our ctii and I talked about um I talked",
    "start": "2174800",
    "end": "2182000"
  },
  {
    "text": "about what's going on behind the scenes we're essentially defining the parameters that we care about the metric",
    "start": "2182000",
    "end": "2187880"
  },
  {
    "text": "that we care about and the parameters and the boundaries for those so there's an example that you can find in the C",
    "start": "2187880",
    "end": "2193960"
  },
  {
    "text": "repo that's what we're going to create what that does we're just applying that to our cluster and what that looks like",
    "start": "2193960",
    "end": "2200920"
  },
  {
    "text": "it's called a study job it's a again a custom resource definition but if we look inside we're defining our",
    "start": "2200920",
    "end": "2209119"
  },
  {
    "text": "metric so it kicked off three different jobs right off the bat um and up here",
    "start": "2209119",
    "end": "2216960"
  },
  {
    "text": "all right so here's our metric validation accuracy that's what we care about and we care about maximizing it so",
    "start": "2216960",
    "end": "2222800"
  },
  {
    "text": "we've defined those and then we list the parameters that we care about",
    "start": "2222800",
    "end": "2227839"
  },
  {
    "text": "the um the learning rate we've said we want it to be somewhere between 01",
    "start": "2227839",
    "end": "2233400"
  },
  {
    "text": "and3 the optimizer type I think the number of layers was in there as well so",
    "start": "2233400",
    "end": "2239520"
  },
  {
    "text": "we already have three jobs running and uh remember that each of these These are",
    "start": "2239520",
    "end": "2244839"
  },
  {
    "text": "running gpus so if we take a look our UI has uh",
    "start": "2244839",
    "end": "2250880"
  },
  {
    "text": "it's seen that these jobs are running and it's collecting all the information so you can see the three parameters that we're looking",
    "start": "2250880",
    "end": "2257240"
  },
  {
    "text": "at but those jobs take a while to run it's running a full set of training for",
    "start": "2257240",
    "end": "2262440"
  },
  {
    "text": "each one of those jobs so that's going to take a while and as those jobs start completing we'll see values in this",
    "start": "2262440",
    "end": "2268680"
  },
  {
    "text": "chart we'll see validation accuracy filling in so let's take a look at the",
    "start": "2268680",
    "end": "2275119"
  },
  {
    "text": "nodes um so Auto provision because we requested because we kicked off three",
    "start": "2275119",
    "end": "2281040"
  },
  {
    "text": "jobs where each of them are requesting gpus we've created three new nodes all with gpus",
    "start": "2281040",
    "end": "2288200"
  },
  {
    "text": "attached and if we take a look at our UI a few results have come in one of them good one of them not so good but we want",
    "start": "2289800",
    "end": "2296880"
  },
  {
    "text": "a few more so we're going to wait until we have about a dozen all right we can do something with",
    "start": "2296880",
    "end": "2302599"
  },
  {
    "text": "this now a lot more results have come so what we see here is is we're",
    "start": "2302599",
    "end": "2308480"
  },
  {
    "text": "looking at the validation accuracy column we see a few that stand out as very low against others that are very",
    "start": "2308480",
    "end": "2315200"
  },
  {
    "text": "high so we're looking for commonalities among those and it looks like they're all using Following the regularized",
    "start": "2315200",
    "end": "2321359"
  },
  {
    "text": "Leader so we don't want to use that that Optimizer so we're going to clone that",
    "start": "2321359",
    "end": "2326400"
  },
  {
    "text": "pipeline job that we already ran and we'll use a different set of parameters we'll get rid of that Optimizer we'll",
    "start": "2326400",
    "end": "2331839"
  },
  {
    "text": "try something different we'll increase the learning rate and use a gradient descent",
    "start": "2331839",
    "end": "2338319"
  },
  {
    "text": "stochastic gradient descent is very common it's a pretty safe choice so if we run",
    "start": "2338319",
    "end": "2346599"
  },
  {
    "text": "that it's running the same job but just with different parameters and we can view the logs for",
    "start": "2351440",
    "end": "2359040"
  },
  {
    "text": "that container as well all right so this already looks better it's at the very beginning of the",
    "start": "2359040",
    "end": "2365000"
  },
  {
    "text": "training run so I would expect it to improve but it's already at 76% and like 80 84 86 that that's much",
    "start": "2365000",
    "end": "2373400"
  },
  {
    "text": "better that's an actually usable model so that's why hyper perimeter tuning is kind of so exciting because you don't",
    "start": "2373400",
    "end": "2378440"
  },
  {
    "text": "have to run all these training jobs separately and keep track of all the results um and in the in that UI there",
    "start": "2378440",
    "end": "2384760"
  },
  {
    "text": "are different graphs that you can add to make it even more obvious especially if you have lots of different metrics that you're tracking and a lot of different",
    "start": "2384760",
    "end": "2390720"
  },
  {
    "text": "parameters it can get a bit uh a bit tangly so there are lots of different ways you can visualize",
    "start": "2390720",
    "end": "2396319"
  },
  {
    "text": "that all right so uh don't just take my word for it if you want to run any of",
    "start": "2396319",
    "end": "2402359"
  },
  {
    "text": "that yourself there's a couple of options uh deploy qf flow. Cloud that's that click to deploy thing that we saw",
    "start": "2402359",
    "end": "2407680"
  },
  {
    "text": "you can give it your own project name and you too can have your own qflow cluster Cod labs. developers.google.com",
    "start": "2407680",
    "end": "2415119"
  },
  {
    "text": "there are a few different walkthroughs there and you can use that again on your own project quick laabs will actually",
    "start": "2415119",
    "end": "2420800"
  },
  {
    "text": "give you the resources you need kataka same thing uh if you just want markdown",
    "start": "2420800",
    "end": "2426839"
  },
  {
    "text": "and you want to walk through it on your own that's there as well on GitHub so where is C flow headed next",
    "start": "2426839",
    "end": "2433480"
  },
  {
    "text": "what does the future Direction look like so with a quarterly release Cadence our",
    "start": "2433480",
    "end": "2438839"
  },
  {
    "text": "od. 4 is coming out within the next few weeks we'll have the first release candidate and we'll probably finalize",
    "start": "2438839",
    "end": "2445040"
  },
  {
    "text": "that just after the holidays U but the intention with our o.4 release is to get",
    "start": "2445040",
    "end": "2450079"
  },
  {
    "text": "ready for that one. release and 1.0 is really designed for some of the",
    "start": "2450079",
    "end": "2455680"
  },
  {
    "text": "Enterprise features that people expect like apis that are supported longterm",
    "start": "2455680",
    "end": "2461400"
  },
  {
    "text": "and we don't expect to change I think by the time we get to 1.0 we'll have had enough people using it that we feel",
    "start": "2461400",
    "end": "2466480"
  },
  {
    "text": "pretty confident about the decisions that we've made another important thing is uh for",
    "start": "2466480",
    "end": "2473560"
  },
  {
    "text": "Ingress so identity access management and security um so not allowing access",
    "start": "2473560",
    "end": "2480000"
  },
  {
    "text": "to all of the components in a cluster but just very specific ones giving people more granular control and",
    "start": "2480000",
    "end": "2485359"
  },
  {
    "text": "providing a really clean upgrade process um so good cicd processes in the machine",
    "start": "2485359",
    "end": "2491240"
  },
  {
    "text": "learning space are hard to come by U but we want to be able to support that and we want to sort of push the boundaries",
    "start": "2491240",
    "end": "2497200"
  },
  {
    "text": "of that and adding more notebook integration so from that notebook during",
    "start": "2497200",
    "end": "2502960"
  },
  {
    "text": "that exploration phase we want to be able to run pipelines we want to be able to um kick off tensorflow jobs lots of",
    "start": "2502960",
    "end": "2510640"
  },
  {
    "text": "different things so that you that a data scientist doesn't ever have to get down to that sort of console kubernetes level",
    "start": "2510640",
    "end": "2517680"
  },
  {
    "text": "um it's not really realistic to expect everyone to understand all the kubernetes details but we still want you",
    "start": "2517680",
    "end": "2523160"
  },
  {
    "text": "to be able to build machine learning applications and so moving towards more notebook integration and generally a",
    "start": "2523160",
    "end": "2529240"
  },
  {
    "text": "more UIC Centric workflow so along with that lots of new",
    "start": "2529240",
    "end": "2534599"
  },
  {
    "text": "features in the pipelines UI see you you can expect to see a lot of changes um in",
    "start": "2534599",
    "end": "2540280"
  },
  {
    "text": "that interface as well and being able to manage your models so storing them in a",
    "start": "2540280",
    "end": "2545760"
  },
  {
    "text": "central location in them auditing them sharing them among your team your",
    "start": "2545760",
    "end": "2551680"
  },
  {
    "text": "organization uh the world and then adding a lot of test infrastructure so",
    "start": "2551680",
    "end": "2557400"
  },
  {
    "text": "supporting a good cicd release process oh if there's something that's missing from this list uh please speak up we're",
    "start": "2557400",
    "end": "2564920"
  },
  {
    "text": "happy to include it maybe not in o.4 but in a future release because C flow is not just open source but it's very it's",
    "start": "2564920",
    "end": "2571680"
  },
  {
    "text": "very open in terms of community and ideas and design so if you'd like to get involved you know join the slack team uh",
    "start": "2571680",
    "end": "2578680"
  },
  {
    "text": "join our calls we try and keep them at uh at times that are friendly to",
    "start": "2578680",
    "end": "2583760"
  },
  {
    "text": "different areas we're a very Global team we have a lot of people a lot of contributors in Asia we have some here",
    "start": "2583760",
    "end": "2589680"
  },
  {
    "text": "in Australia we had our contributor Summit just a few months ago in Sunnyvale um and there was someone",
    "start": "2589680",
    "end": "2596240"
  },
  {
    "text": "attending from Sydney like via Hangouts uh so we're not just supportive and and",
    "start": "2596240",
    "end": "2601720"
  },
  {
    "text": "plenty of people flew in as well there were about 70 people there um but we have a live stream for for it and we",
    "start": "2601720",
    "end": "2607680"
  },
  {
    "text": "have Hangouts for all the breakout sessions and so it is pretty easy to attend from this continent so please",
    "start": "2607680",
    "end": "2613400"
  },
  {
    "text": "join us if you're interested and uh I think that's that's all I had so if anyone has any questions if you'd like",
    "start": "2613400",
    "end": "2619200"
  },
  {
    "text": "for me to go into more detail about anything I'm more than happy to also if you'd like a laptop sticker I have a few",
    "start": "2619200",
    "end": "2625319"
  },
  {
    "text": "of those down here [Applause]",
    "start": "2625319",
    "end": "2634980"
  }
]
[
  {
    "start": "0",
    "end": "152000"
  },
  {
    "text": "hi I'm Cliff um okay I want to talk about Big Data uh and I guess the the",
    "start": "1800",
    "end": "8200"
  },
  {
    "text": "first thing to do is qualify with people uh what big is because everyone has a",
    "start": "8200",
    "end": "13759"
  },
  {
    "text": "different notion of big so um I guess I'll open up by asking a question here",
    "start": "13759",
    "end": "19240"
  },
  {
    "text": "so how many people here work with big data so uh like two so what do the rest",
    "start": "19240",
    "end": "25160"
  },
  {
    "text": "of y'all do why are you in this talk so how many people here let's let's try again here how many people here work",
    "start": "25160",
    "end": "30640"
  },
  {
    "text": "with data sets that are typically a gigabyte or larger in size oh okay fine",
    "start": "30640",
    "end": "36200"
  },
  {
    "text": "okay how many people work with with 10 gig data sets en larger okay 100 Gig uh terabyte en larger uh now we're getting",
    "start": "36200",
    "end": "43600"
  },
  {
    "text": "down to okay how about 10 terabytes uh uh say 100 terabytes okay now you're getting up to what I would call Big so",
    "start": "43600",
    "end": "49520"
  },
  {
    "text": "petabyte right and and on up I'll stop here so there's a couple guys go go all the way up to pedabytes and then there's",
    "start": "49520",
    "end": "55280"
  },
  {
    "text": "probably Google people who will keep going to exabytes so um for uh what",
    "start": "55280",
    "end": "60680"
  },
  {
    "text": "we're doing uh big well that was very exciting let's try again there we go big",
    "start": "60680",
    "end": "67360"
  },
  {
    "text": "is somewhere between gigabytes and terabytes um in the sense that Beyond",
    "start": "67360",
    "end": "72520"
  },
  {
    "text": "terabytes uh uh uh that's too big for an inmemory solution conveniently so we're",
    "start": "72520",
    "end": "79080"
  },
  {
    "text": "building a platform um it's pure Java open source you can get it straight off GitHub uh and the website has got a jar",
    "start": "79080",
    "end": "86040"
  },
  {
    "text": "file that you can download and go it just takes one jar and it often runs and it's doing it's a platform for doing",
    "start": "86040",
    "end": "92720"
  },
  {
    "text": "parallel distributed math and then given a platform for parallel distributed math what does that mean well besides being",
    "start": "92720",
    "end": "99159"
  },
  {
    "text": "do sort of any kind of generic math you want um we're building high-end math uh machine learning algorithms uh logistic",
    "start": "99159",
    "end": "105439"
  },
  {
    "text": "regression uh generaliz lineal modeling gradiate boosted method random Force deep learning neural Nets on and on and",
    "start": "105439",
    "end": "111000"
  },
  {
    "text": "on bunch of stuff um so I guess I'll go hand in hand with that how many people here are uh are using machine learning",
    "start": "111000",
    "end": "118119"
  },
  {
    "text": "um at all or looking at it or about doing anything with machine learning okay some amount and how many",
    "start": "118119",
    "end": "123920"
  },
  {
    "text": "people are using machine learning on sort of a daily basis now like like you're sitting at your desk and you're",
    "start": "123920",
    "end": "129280"
  },
  {
    "text": "building models on a regular basis so not any youbody here have plans to go",
    "start": "129280",
    "end": "134720"
  },
  {
    "text": "there where you're going to build these models and try to apply them in production so a couple people so so people are out there making their plans",
    "start": "134720",
    "end": "140920"
  },
  {
    "text": "okay so this talk is actually um I'm not going to go deep into machine learning algorithms and the math side I'm going",
    "start": "140920",
    "end": "147280"
  },
  {
    "text": "to talk about building a systems platform for allowing machine learning algorithms to be",
    "start": "147280",
    "end": "153840"
  },
  {
    "start": "152000",
    "end": "274000"
  },
  {
    "text": "built um okay so I said this is a platform for doing big data work so what does that",
    "start": "153840",
    "end": "160640"
  },
  {
    "text": "mean in this context it means um almost any Java you want on a big",
    "start": "160640",
    "end": "165879"
  },
  {
    "text": "two-dimensional table so uh anything that reads or writes a single observation in your data set a single",
    "start": "165879",
    "end": "172200"
  },
  {
    "text": "row plus maybe some nearby rows uh and maybe computes a reduction or produces a big data output um within that",
    "start": "172200",
    "end": "179120"
  },
  {
    "text": "constraint uh the speed is interesting because it's big and the speed is typically data",
    "start": "179120",
    "end": "185159"
  },
  {
    "text": "volume divided by your memory bandwidth it's limited by memory bandwidth frequently um which is like 50 gbt a",
    "start": "185159",
    "end": "192200"
  },
  {
    "text": "second per node and it varies by hardware and by your original setup and some of the algorithms require more",
    "start": "192200",
    "end": "197440"
  },
  {
    "text": "Network traffic and some you that's the bottleneck instead of memory bandwidth but we typically see numbers uh that are",
    "start": "197440",
    "end": "203560"
  },
  {
    "text": "you know a thousand times faster than anything you can do on a Hadoop um it's a pretty low bar but we're still seeing numbers that are 10 times faster than",
    "start": "203560",
    "end": "209519"
  },
  {
    "text": "anyone else in the planet it's it's really fast stuff so that opens up the the door to doing interesting things um",
    "start": "209519",
    "end": "216920"
  },
  {
    "text": "I mentioned the data is compressed I'll talk more about that later um it's typically much better compressed than what you get from like gzip on disk and",
    "start": "216920",
    "end": "223799"
  },
  {
    "text": "that goes straight to the memory bandwidth data volume trade-off for Speed uh in in the good direction um I'm",
    "start": "223799",
    "end": "230000"
  },
  {
    "text": "doing math so I'm limited to data that is math likee numbers and times and",
    "start": "230000",
    "end": "235120"
  },
  {
    "text": "simple strings um and then I said two- dimensional table how big is the table uh tables that are less than a th000",
    "start": "235120",
    "end": "241560"
  },
  {
    "text": "columns wide are going to be really fast like too fast that you can hardly care uh up to 10,000 columns work still",
    "start": "241560",
    "end": "247439"
  },
  {
    "text": "fairly well and 100,000 or bigger still works but the loops are paralyzed the",
    "start": "247439",
    "end": "252560"
  },
  {
    "text": "wrong way and it's not as fast as maybe you'd like um but the length of the table's limited memory and can be",
    "start": "252560",
    "end": "258959"
  },
  {
    "text": "Millions to billions to trillions long it can be very very very long so so more",
    "start": "258959",
    "end": "264600"
  },
  {
    "text": "or less uh you know couple terabytes of cluster will turn into uh you know tens",
    "start": "264600",
    "end": "270080"
  },
  {
    "text": "of billions hundreds of billions of rows and that's fine and it will all go fast okay so what can you do with it I'm",
    "start": "270080",
    "end": "276280"
  },
  {
    "start": "274000",
    "end": "409000"
  },
  {
    "text": "going to step through some examples here from a developer point of view and the most common thing we do is a map reduced",
    "start": "276280",
    "end": "281800"
  },
  {
    "text": "Paradigm it's not the only Paradigm we support but it's the common one because it scales out just completely nicely so",
    "start": "281800",
    "end": "287560"
  },
  {
    "text": "uh a map produce will take something of a type A in the map call and produce something of a type B in this case it's",
    "start": "287560",
    "end": "292880"
  },
  {
    "text": "double to double and I'm just Computing a square and then a reduction will take two of the B types and make one and here",
    "start": "292880",
    "end": "298160"
  },
  {
    "text": "I'm doing a simple add and so this is just sum of squares and I write this Java code exactly like this and I say do",
    "start": "298160",
    "end": "305320"
  },
  {
    "text": "all on my data and it's going to run memory bandwidth speeds so this will take a terabyte and you know under a",
    "start": "305320",
    "end": "311720"
  },
  {
    "text": "second and and you know some some tens hundreds of millions depending on how big your cluster is um it just like",
    "start": "311720",
    "end": "319080"
  },
  {
    "text": "that so I have a scolar version in development it's still uh being whacked on it's not 100% complete but it's it's",
    "start": "319080",
    "end": "326680"
  },
  {
    "text": "clearly about half the lines of code um and you can get the not really quick that you're just doing sums of squares",
    "start": "326680",
    "end": "331759"
  },
  {
    "text": "here so it's kind of a a slick thing so I said before uh uh you know",
    "start": "331759",
    "end": "338639"
  },
  {
    "text": "have as a map on reduce the map is from a type A to a type B where the type A is your big data it's your input it's",
    "start": "338639",
    "end": "345440"
  },
  {
    "text": "however many columns you've selected out or how many thousands and hundreds of thousands of columns you have that's your type A and you can treat it as a",
    "start": "345440",
    "end": "352680"
  },
  {
    "text": "struct if you will but it's an array of structs versus struct of arrays the two Notions are sort of interchangeable here",
    "start": "352680",
    "end": "358960"
  },
  {
    "text": "um you know a is your big data but row by row by row and your type B is your",
    "start": "358960",
    "end": "365319"
  },
  {
    "text": "output and there's two types of output there's big and small uh big data has to go right back into the cluster because",
    "start": "365319",
    "end": "371800"
  },
  {
    "text": "by definition the big is too big to fit on one node so if you have a big output that is on the order of magnitude of",
    "start": "371800",
    "end": "378240"
  },
  {
    "text": "your original input it's going to be a distributed output it's going to live in the Clusters memory same way as your",
    "start": "378240",
    "end": "383319"
  },
  {
    "text": "input is um you can also have a small data output which is a plain old Java object um and the reduction will take",
    "start": "383319",
    "end": "389080"
  },
  {
    "text": "two such pojos and produce one I'll do update and place for possible uh and",
    "start": "389080",
    "end": "394400"
  },
  {
    "text": "ultimately you simply make a new instance of a map ruce task override map and reduce and say do all and your",
    "start": "394400",
    "end": "401240"
  },
  {
    "text": "original instance comes back with whatever your reduction was asking for uh right back in that instance after",
    "start": "401240",
    "end": "406800"
  },
  {
    "text": "it's visited your terabyte of data so here's some examples of that",
    "start": "406800",
    "end": "412520"
  },
  {
    "text": "here my type A is a double pair X and Y and my type B is the this pointer an",
    "start": "412520",
    "end": "417639"
  },
  {
    "text": "instance of linear regression pass one um which is Computing sums and sums of squares again um and you can see it's",
    "start": "417639",
    "end": "423960"
  },
  {
    "text": "simply uh adding directly into the Java object and calling R uh reduction takes of this and of that which are two of the",
    "start": "423960",
    "end": "430280"
  },
  {
    "text": "same type thing and folds them together there's a scol version it's about half the lines of code a little uglier on a",
    "start": "430280",
    "end": "436039"
  },
  {
    "start": "432000",
    "end": "459000"
  },
  {
    "text": "slide but when I say it goes right back into the original object I made a Fu object and I can directly use it in the next line of code to go compute things",
    "start": "436039",
    "end": "443280"
  },
  {
    "text": "straight off of Fu and then usually that feeds into the next pass I just write the next piece in this case of linear",
    "start": "443280",
    "end": "449160"
  },
  {
    "text": "regression and there's three passes and you would say pass one do all pass two do all pass three do all a little bit of",
    "start": "449160",
    "end": "454440"
  },
  {
    "text": "algebra in and around the passes and it's a done deal um so there's an efficiency thing",
    "start": "454440",
    "end": "463080"
  },
  {
    "start": "459000",
    "end": "527000"
  },
  {
    "text": "here and you know to get my memory band with speeds out I have to actually Dodge all kinds of overheads so under the hood",
    "start": "463080",
    "end": "470240"
  },
  {
    "text": "whenever I say map there's actually a for Loop that's running over some chunk of data uh I'll get more into what a",
    "start": "470240",
    "end": "475479"
  },
  {
    "text": "chunk is here in a minute but it's some collection of a thousand to a million of your elements that one core is going to do something with and there's a simple",
    "start": "475479",
    "end": "481400"
  },
  {
    "text": "for Loop that you can write yourself or you can let the system throw in for you over your own map call the chunk at uh",
    "start": "481400",
    "end": "489000"
  },
  {
    "text": "CX at cxy that's the decompression step talk some more about that in a minute because it counts for Speed so so much",
    "start": "489000",
    "end": "496120"
  },
  {
    "text": "and then you do your standard math and reduction the way I showed it a minute ago and those are all just the same um because you have a for Loop here",
    "start": "496120",
    "end": "503800"
  },
  {
    "text": "if you have uh interesting complicated map functions you can haul Loop and",
    "start": "503800",
    "end": "508919"
  },
  {
    "text": "variance out yourself you if the jit's not going to do that for you you can do it yourself uh and when we do our own",
    "start": "508919",
    "end": "514599"
  },
  {
    "text": "internal math algorithms we will often have map F functions which are thousand lines or more of java code and we'll be",
    "start": "514599",
    "end": "520680"
  },
  {
    "text": "doing a lot of sort of manual optimizations to haul Loop and variance out and things like",
    "start": "520680",
    "end": "526560"
  },
  {
    "text": "that okay so here's another uh quick kind of thing I can do I'm going to count somebody instead of uh uh uh",
    "start": "526600",
    "end": "534800"
  },
  {
    "start": "527000",
    "end": "556000"
  },
  {
    "text": "computer math and this is just a filter uh you know if your if your input data passes some particular",
    "start": "534800",
    "end": "540040"
  },
  {
    "text": "uh filtering condition count as a one or a zero and the reductions add them up and the scolar syntax is again a little",
    "start": "540040",
    "end": "545800"
  },
  {
    "text": "bit uh it's a lot shorter and a little bit cleaner and uh you know I'll get counts that way sort of uh however long",
    "start": "545800",
    "end": "553600"
  },
  {
    "text": "it takes to shove the data through the memory bus in addition to doing uh counts I can",
    "start": "553600",
    "end": "559320"
  },
  {
    "start": "556000",
    "end": "593000"
  },
  {
    "text": "also collect sets and this is a big data output where I've made a new output vector and I've said do all passing in",
    "start": "559320",
    "end": "565480"
  },
  {
    "text": "my inputs and my outputs and then I can use it immediately in the next step and somewhere in the body of the map call",
    "start": "565480",
    "end": "571959"
  },
  {
    "text": "I've picked some condition and then set a pinned and that collected an output set that's too big to fit on one machine",
    "start": "571959",
    "end": "578079"
  },
  {
    "text": "typically you know what whatever the percentage of people who's passed the filter they got shoved into the output",
    "start": "578079",
    "end": "583560"
  },
  {
    "text": "set but I might have an output set that's a terabyte in size and if I'm filtering hugely maybe it's small but if it's big it's going to be too big to fit",
    "start": "583560",
    "end": "589920"
  },
  {
    "text": "on one machine so just the output just has to be distributed um so this is a little bit",
    "start": "589920",
    "end": "596519"
  },
  {
    "start": "593000",
    "end": "636000"
  },
  {
    "text": "more about the coding style here's a basically grp group bu or I'm going to ask a question how many cars do people",
    "start": "596519",
    "end": "602320"
  },
  {
    "text": "own at different ages in their life and the more interesting thing here is I've done an allocation in the map call and",
    "start": "602320",
    "end": "607800"
  },
  {
    "text": "the key trick with that is it's a private uh private allocation it's privately done by one core it's single-",
    "start": "607800",
    "end": "613959"
  },
  {
    "text": "threaded access so in particular that plus plus out on the end it doesn't have to be synchronized this is one core",
    "start": "613959",
    "end": "619760"
  },
  {
    "text": "doing one piece of work and there's no synchronization involved but then every core is running on a different chunk of",
    "start": "619760",
    "end": "624839"
  },
  {
    "text": "the data and so you have whole lots of these little car ages arrays so you have to have a reduction to roll the up and I",
    "start": "624839",
    "end": "630279"
  },
  {
    "text": "have a little utility that's going to help uh just to you know array element ad",
    "start": "630279",
    "end": "635800"
  },
  {
    "text": "there um here's uniques this case the difference is I done a new in the Constructor instead of",
    "start": "635800",
    "end": "642279"
  },
  {
    "start": "636000",
    "end": "681000"
  },
  {
    "text": "in the map call and that meant at the time I called new uniques right here I made an instance of an object and when I",
    "start": "642279",
    "end": "647440"
  },
  {
    "text": "said do all that object got replicated around the cluster with everyone sharing as much as possible the one instance I",
    "start": "647440",
    "end": "652760"
  },
  {
    "text": "just made that's very useful for readon sets but if it's writable then you have",
    "start": "652760",
    "end": "657839"
  },
  {
    "text": "to handle currency in this case it's a non-blocking it's a concurrent safe hash set um so I can have everyone just write",
    "start": "657839",
    "end": "664399"
  },
  {
    "text": "in so the map function simply Jam something into the hash set where the hash's going to filter for dupes and the",
    "start": "664399",
    "end": "670040"
  },
  {
    "text": "reduction moves things together and that's called whenever uh I have to move these hash sets ACR the wire but in so",
    "start": "670040",
    "end": "675839"
  },
  {
    "text": "many lines of code I can compute uniques in my data set across the",
    "start": "675839",
    "end": "680920"
  },
  {
    "start": "681000",
    "end": "765000"
  },
  {
    "text": "cluster okay so that was sort of the quick Whirlwind tour I'm going to summarize the the limitations here and",
    "start": "681160",
    "end": "688079"
  },
  {
    "text": "the main one is you know I can't do any uh any Machine level resource allocation",
    "start": "688079",
    "end": "693760"
  },
  {
    "text": "uh because that won't be cluster wide so no IO uh in particular every member of",
    "start": "693760",
    "end": "699320"
  },
  {
    "text": "the cluster might have a different file system view so you can't read or write files uh sort of meaningfully there no",
    "start": "699320",
    "end": "705519"
  },
  {
    "text": "no new threads no locks there's no distributed locks here no calling system exit um you don't have any Global",
    "start": "705519",
    "end": "711120"
  },
  {
    "text": "variables per se uh instead any Global or static variable becomes node local",
    "start": "711120",
    "end": "717360"
  },
  {
    "text": "now if you actually need Global state then if it's readable you put it in the Constructor and it'll be cloned around",
    "start": "717360",
    "end": "723120"
  },
  {
    "text": "as a readon thing for every uh every member of the clust every thread to use and if it's writable you're going to",
    "start": "723120",
    "end": "728360"
  },
  {
    "text": "have to use a reduction call to get the results to roll back up and come back to you as a truly Global uh written result",
    "start": "728360",
    "end": "734639"
  },
  {
    "text": "and for the big state um you just read and write straight into the the uh the Big Data uh same as you saw reading you",
    "start": "734639",
    "end": "742519"
  },
  {
    "text": "can write to it as well and the typical Paradigm here is you're going to run in one map reduce step and then do a little",
    "start": "742519",
    "end": "748360"
  },
  {
    "text": "bit of algebra and then and another one and another and another where the key here is that the typical time to do a",
    "start": "748360",
    "end": "754680"
  },
  {
    "text": "tire pass of the data is in the in the modest number of milliseconds so it's it's a different",
    "start": "754680",
    "end": "760639"
  },
  {
    "text": "story than your typical you know map reduced Paradigm okay the strength here is that",
    "start": "760639",
    "end": "767480"
  },
  {
    "start": "765000",
    "end": "827000"
  },
  {
    "text": "the code's running sort of distributed in parallel without any more effort the code I was showing here it actually works just as written um you just say",
    "start": "767480",
    "end": "775519"
  },
  {
    "text": "you know new map reduce task override map reduce bang done um you can write in a single-threaded",
    "start": "775519",
    "end": "781720"
  },
  {
    "text": "coding style so you don't have to there's no synchronization and there's no talking to uh the cluster mechanics",
    "start": "781720",
    "end": "788399"
  },
  {
    "text": "somehow to do uh whatever setup there's no concurrency issues there's no",
    "start": "788399",
    "end": "793920"
  },
  {
    "text": "Resource Management knobs you have to turn uh once the cluster's up and running uh you know all your Maps",
    "start": "793920",
    "end": "799440"
  },
  {
    "text": "ructions just do the right thing immediately there's no knobs needed for GC or CPUs or network or data placement",
    "start": "799440",
    "end": "806079"
  },
  {
    "text": "there's no hot blocks or hot locks um you know that that's all taken care of under the hood and and actually it works",
    "start": "806079",
    "end": "811920"
  },
  {
    "text": "really well okay so so that was like the r one",
    "start": "811920",
    "end": "817320"
  },
  {
    "text": "tour of what I can do with it here let let me stop and see if anyone has any questions about what I just",
    "start": "817320",
    "end": "825079"
  },
  {
    "text": "said yeah so does H2 run on static data sets or can I kind of feed data into",
    "start": "825560",
    "end": "831480"
  },
  {
    "text": "this data set light so right now we're running on static data sets where one of",
    "start": "831480",
    "end": "837959"
  },
  {
    "text": "the first steps to do is load um that said the core architectur totally support streaming um and we just",
    "start": "837959",
    "end": "844880"
  },
  {
    "text": "had had enough users asking for it to put streaming down so we add algorithms",
    "start": "844880",
    "end": "850800"
  },
  {
    "text": "and features based on what we have customers pay for and as soon as you get a quorum of people said I'll pay for",
    "start": "850800",
    "end": "856000"
  },
  {
    "text": "streaming then we put it in um it's getting there streaming will probably be",
    "start": "856000",
    "end": "861040"
  },
  {
    "text": "here uh before the year uh before next year you know a year from now we'll have the streaming support in",
    "start": "861040",
    "end": "867720"
  },
  {
    "text": "there okay so let's take a look at what how it actually works um it this is an",
    "start": "867839",
    "end": "873519"
  },
  {
    "start": "868000",
    "end": "1010000"
  },
  {
    "text": "instance of fork join but it I want to say distributed Fork join so it's similar to Dougley Fork join work um I'm",
    "start": "873519",
    "end": "880000"
  },
  {
    "text": "just I'm actually using his Fork join work sort of directly within a node and I've extended it to work cross node uh",
    "start": "880000",
    "end": "885639"
  },
  {
    "text": "and and the way you look here's an eight node cluster somebody somewhere is driving this and has said you know make",
    "start": "885639",
    "end": "890880"
  },
  {
    "text": "me a new map reduce task and do all on some data and then I do the sort of obvious",
    "start": "890880",
    "end": "895959"
  },
  {
    "text": "log tree fan out where I I pipe the in of this object after the constructor's run it's all set up to to his two",
    "start": "895959",
    "end": "902560"
  },
  {
    "text": "neighbors and they send it to their two neighbors and so on until the whole cluster has got an instance of this task",
    "start": "902560",
    "end": "907880"
  },
  {
    "text": "now as soon as the task hits a note it also goes on the fork draing work cues and then they do what you know Fork",
    "start": "907880",
    "end": "912959"
  },
  {
    "text": "dra's been doing all along which they start making clones of themselves as long as the data set they referring to is too large and they do a divide and",
    "start": "912959",
    "end": "919000"
  },
  {
    "text": "conquer and they split make another task and so on until uh the amount of work assigned to individual task corresponds",
    "start": "919000",
    "end": "925519"
  },
  {
    "text": "to you know one chunk of data and then they all do par map calls across the data and fortron is really good at doing",
    "start": "925519",
    "end": "932000"
  },
  {
    "text": "load balancing uh and you know sort of on on the on the work on the data so this will slam all the cores on the box",
    "start": "932000",
    "end": "938639"
  },
  {
    "text": "you'll go 100% CPU load they'll all do their thing and then uh when they're done each of the objects will have the",
    "start": "938639",
    "end": "945079"
  },
  {
    "text": "small data pojos left in the task objects the Clones of the task objects that have been made all along and then",
    "start": "945079",
    "end": "950959"
  },
  {
    "text": "there's a reduction step starts going in reverse where Pair by pair as soon as uh two guys have uh completed their mapping",
    "start": "950959",
    "end": "958040"
  },
  {
    "text": "steps you to immediate reduction in place uh and then those log tree roll up",
    "start": "958040",
    "end": "963279"
  },
  {
    "text": "make another reduction until you get with a single top level instance per node and then you run the cluster wide",
    "start": "963279",
    "end": "968560"
  },
  {
    "text": "log Tree in Reverse going backwards where the poor fellow at the long end of the log Tree on the right reduces up to",
    "start": "968560",
    "end": "974079"
  },
  {
    "text": "his one friend and the other two guys are going reduce to their friend they got their task from uh and then in the",
    "start": "974079",
    "end": "979480"
  },
  {
    "text": "next step you know the reductions continue back through the cluster until you come down with the final reduction",
    "start": "979480",
    "end": "984720"
  },
  {
    "text": "into the original instance and it's done so the time to run this is typically log",
    "start": "984720",
    "end": "990639"
  },
  {
    "text": "tree fan out through the cluster parallel execute on the nodes log tree fan in from the cluster and that turns",
    "start": "990639",
    "end": "996720"
  },
  {
    "text": "into some you know count of milliseconds depending on how complicated your maths and reductions",
    "start": "996720",
    "end": "1003160"
  },
  {
    "text": "are okay so it's pretty straightforward nod maybe some okay fine so let's look",
    "start": "1004480",
    "end": "1010360"
  },
  {
    "start": "1010000",
    "end": "1063000"
  },
  {
    "text": "at the data layout so this is an interesting problem because people I don't know seem to sweat a lot about",
    "start": "1010360",
    "end": "1015399"
  },
  {
    "text": "data placement data layout and we're sort of doing something that's very straightforward and uh has been working",
    "start": "1015399",
    "end": "1020560"
  },
  {
    "text": "quite well in practice so the abstract API is that I have a collection of",
    "start": "1020560",
    "end": "1025600"
  },
  {
    "text": "vectors um for my data that's the two-dimensional table thing where a vector is one column and the column is",
    "start": "1025600",
    "end": "1032240"
  },
  {
    "text": "um treated like an array uh but it can be longer than a an an in in length you know can be billions of elements in",
    "start": "1032240",
    "end": "1038240"
  },
  {
    "text": "lengths right and there's fast random access to any given element although if one node asks for all elements he'll get",
    "start": "1038240",
    "end": "1044120"
  },
  {
    "text": "drowned in the data it's too much right but he can pick individual elements for free um there's notion of the missing",
    "start": "1044120",
    "end": "1049600"
  },
  {
    "text": "value that's an is and a it's very key to the machine learning math algorithms to have a notion of missing your algorithms do something different on",
    "start": "1049600",
    "end": "1055640"
  },
  {
    "text": "that uh and you can write it or a pin so you could uh muck with the size of the data sets or change them in place it's",
    "start": "1055640",
    "end": "1061840"
  },
  {
    "text": "all fine um so like I said I have a single large Vector um it conceptually it's",
    "start": "1061840",
    "end": "1068679"
  },
  {
    "start": "1063000",
    "end": "1125000"
  },
  {
    "text": "full of typically Java uh Java Primitives however that's the conceptual view it's actually compression is",
    "start": "1068679",
    "end": "1074320"
  },
  {
    "text": "whatever it's going to be um and it's all geared for fast uh linear access",
    "start": "1074320",
    "end": "1079640"
  },
  {
    "text": "it's striped across a cluster so here I have a four node cluster I'm showing uh chunks of the data will be on every",
    "start": "1079640",
    "end": "1085159"
  },
  {
    "text": "member of the cluster so it's not striped with one vector holding uh one jvm holding whole Vector instead it's",
    "start": "1085159",
    "end": "1090400"
  },
  {
    "text": "distributed across the vector um and it is in fully in the Java Heap so the data is actually in the Java Heap and we do a",
    "start": "1090400",
    "end": "1097200"
  },
  {
    "text": "lot of work with GC to watch the size of the Heap and we spill a disc on demand um and do a bunch of stuff there but the",
    "start": "1097200",
    "end": "1104080"
  },
  {
    "text": "end result is if you take the default collector and you set it as large as you want will not have a GC problem we don't",
    "start": "1104080",
    "end": "1112000"
  },
  {
    "text": "see like like we routinely run with 250 gig GC uh xmx 250 gigs on a 256 gig",
    "start": "1112000",
    "end": "1118840"
  },
  {
    "text": "machine with Max GC pauses in one to two seconds every now and then uh you don't get these giant GC",
    "start": "1118840",
    "end": "1125159"
  },
  {
    "text": "pauses okay so I said I had a vector typically actually have a bunch of them and they're all aligned and they're aligned this way so that one core and",
    "start": "1125159",
    "end": "1131919"
  },
  {
    "text": "one jvm can access all members of a of a set of an observation going across at",
    "start": "1131919",
    "end": "1137919"
  },
  {
    "text": "you know memory speed s so while you can get out the data with random access on any row any jvm um",
    "start": "1137919",
    "end": "1144320"
  },
  {
    "text": "you're fastest if you're doing it in sort of uh uh one core going across in a row and the reason it's set up like this",
    "start": "1144320",
    "end": "1150799"
  },
  {
    "text": "of course is that your data sets represents some real world feature set um and here I'm showing you know age sex zip code ID car whatever it's going to",
    "start": "1150799",
    "end": "1157280"
  },
  {
    "text": "be and you know conceptually this is a a an array of structs or struct of array",
    "start": "1157280",
    "end": "1162919"
  },
  {
    "text": "model and it kind of you flip back and forth in your head which way you want to view it and I can hand the data to you in either way um similar to an R data",
    "start": "1162919",
    "end": "1170480"
  },
  {
    "text": "frame so we can add or subtract columns uh sort of for free it's like a pointer change to do that so a common setup is",
    "start": "1170480",
    "end": "1176960"
  },
  {
    "text": "to uh collect in however many thousand columns you have and decide what you're going to columns you're going to work with and you probably drop a bunch of",
    "start": "1176960",
    "end": "1183039"
  },
  {
    "text": "columns out and then you probably filter and hack on a bunch of columns to build out more uh features and then you pass",
    "start": "1183039",
    "end": "1188120"
  },
  {
    "text": "it on to the the heavyweight math alos but all the adding and dropping of columns is all sort of for",
    "start": "1188120",
    "end": "1193400"
  },
  {
    "text": "free okay within a column there's this thing called a chunk I mentioned earlier it's it's just the unit of parallel",
    "start": "1193400",
    "end": "1200440"
  },
  {
    "start": "1194000",
    "end": "1240000"
  },
  {
    "text": "access um a chunk is typically a thousand to a million elements in size it's stored in bite arrays in the Java",
    "start": "1200440",
    "end": "1206840"
  },
  {
    "text": "Heat so plain old bite arrays uh and it's where we do compression and we vary the compression strategy by the kind of",
    "start": "1206840",
    "end": "1212799"
  },
  {
    "text": "data we're observing in that chunk um but the guarantee is that get or put of Any Given element is just a few clock",
    "start": "1212799",
    "end": "1219000"
  },
  {
    "text": "Cycles including the compression step in this case the the compression is",
    "start": "1219000",
    "end": "1224360"
  },
  {
    "text": "one of the key fun things we do for Speed uh because we're moving the compressed state of the memory hierarchy",
    "start": "1224360",
    "end": "1229440"
  },
  {
    "text": "and decompressing it in machine registers on the Fly uh it's sort of completely free to decompress because we",
    "start": "1229440",
    "end": "1234720"
  },
  {
    "text": "can't pull data in fast enough anyhow we're all blocked behind the memory bus um so more compression is actually better and then of course every uh a row",
    "start": "1234720",
    "end": "1242840"
  },
  {
    "text": "across is sort of owned by a single core at a given point in time so that core can access every member of the row uh",
    "start": "1242840",
    "end": "1249159"
  },
  {
    "text": "like he's single threaded like he has a Java object in fact I'll just build you a Java object if you want one um and",
    "start": "1249159",
    "end": "1254440"
  },
  {
    "text": "then you know he can just scribble at it at full Java speeds so so it's it's his private data structure that he can just",
    "start": "1254440",
    "end": "1260280"
  },
  {
    "text": "mangle as he wants and then I said that single threaded on that set of rows um",
    "start": "1260280",
    "end": "1265679"
  },
  {
    "text": "there's enough uh uh chunk work there to cover the cost of launching enough uh",
    "start": "1265679",
    "end": "1270720"
  },
  {
    "text": "enough threads to get everything busy but that's small enough that I get good fine grain data parallelism so it's this",
    "start": "1270720",
    "end": "1276159"
  },
  {
    "text": "sort of you know good blend of just big enough to cover the cost of launching more threads just small enough to get good uh parallelism and so of course",
    "start": "1276159",
    "end": "1283840"
  },
  {
    "text": "what really happens is every core lights Up all In Parallel all at once how yeah",
    "start": "1283840",
    "end": "1290120"
  },
  {
    "start": "1288000",
    "end": "1342000"
  },
  {
    "text": "that how do I make sure the data is aligned I I load it that way so so when I inhale the data sets um I will uh",
    "start": "1290120",
    "end": "1298080"
  },
  {
    "text": "start selecting what rows are going to go on what machine across the data so you know a common thing to do is read in",
    "start": "1298080",
    "end": "1304360"
  },
  {
    "text": "uh uh you know terabyte CSV file so CSV means it's variable length on every row it's all kind of mish mashed up I'll",
    "start": "1304360",
    "end": "1310640"
  },
  {
    "text": "parse through that and and build my compressed format and uh and then make a decision about what rows are going to go",
    "start": "1310640",
    "end": "1316640"
  },
  {
    "text": "what places and I'll group them together but I'll I'll carefully arrange them all uh node by node by node that you have a",
    "start": "1316640",
    "end": "1322440"
  },
  {
    "text": "compatible set of rows across on a single node and then there'll be one network Shuffle so you load a terabyte and it came from disk so the network is",
    "start": "1322440",
    "end": "1329120"
  },
  {
    "text": "you know thousand times faster than disc so the network shuffles essentially free now and you're limited by disc speeds right so to get the data in so I'll do",
    "start": "1329120",
    "end": "1335720"
  },
  {
    "text": "one Shuffle under the hood to get the data where I want it and then it doesn't move again",
    "start": "1335720",
    "end": "1342200"
  },
  {
    "start": "1342000",
    "end": "1384000"
  },
  {
    "text": "okay okay so there's a you know quick summary uh a data frame is a collection",
    "start": "1342200",
    "end": "1347559"
  },
  {
    "text": "of vectors it's really distributed data frame it's it's all the data throughout the whole cluster um and and then you",
    "start": "1347559",
    "end": "1353360"
  },
  {
    "text": "know the vectors are themselves a collection of these chunks which is my unit of parallel access a chunks a",
    "start": "1353360",
    "end": "1358640"
  },
  {
    "text": "thousand to a million elements it kind of varies according to all kinds of funny factors and then an elements conceptually Java double although it's",
    "start": "1358640",
    "end": "1364520"
  },
  {
    "text": "actually how it's represented under the hood varies by compression strategy and like I said I have like 15 different",
    "start": "1364520",
    "end": "1369679"
  },
  {
    "text": "compression strategies that I use right now and then a single row is a single sort of observation or instance or or",
    "start": "1369679",
    "end": "1376880"
  },
  {
    "text": "conceptually a Java structure of those columns um those are things that you",
    "start": "1376880",
    "end": "1381960"
  },
  {
    "text": "manipulate directly in your map calls okay so is there any any more",
    "start": "1381960",
    "end": "1387120"
  },
  {
    "start": "1384000",
    "end": "1800000"
  },
  {
    "text": "questions on on this step bam okay so",
    "start": "1387120",
    "end": "1393919"
  },
  {
    "text": "um let me let me break for a second and do a",
    "start": "1393919",
    "end": "1398960"
  },
  {
    "text": "demo and then I'll come back around to to a few other odds and ends and and and that's actually most of the talk so see",
    "start": "1398960",
    "end": "1405720"
  },
  {
    "text": "if I can get a a demo going here so somewhere in the world I'm going to",
    "start": "1405720",
    "end": "1411960"
  },
  {
    "text": "launch Java djar xmx okay my cluster came up it's a cluster of one on my laptop here",
    "start": "1411960",
    "end": "1419880"
  },
  {
    "text": "um let me get this going so I didn't talk anything about um deployment but",
    "start": "1419880",
    "end": "1426440"
  },
  {
    "text": "it's a standard single jar file so it runs fine on my laptop and I can cluster up on my laptop by saying Java Dash jar",
    "start": "1426440",
    "end": "1433520"
  },
  {
    "text": "you know Amper sand the background run it two or three times I get a cluster of however many I won on my laptop um it'll run the cloud running ec2 uh it'll run",
    "start": "1433520",
    "end": "1440640"
  },
  {
    "text": "on your own private cluster it'll run on Hadoop it'll run not on Hadoop it'll read from hdfs or S3 or wherever it it",
    "start": "1440640",
    "end": "1446440"
  },
  {
    "text": "because it's a simple jar file you can just go pretty much anywhere uh with it so I'm going to start by loading a",
    "start": "1446440",
    "end": "1452440"
  },
  {
    "text": "data set here um I'm going to pick uh what do we got here data",
    "start": "1452440",
    "end": "1459200"
  },
  {
    "text": "sets um let's pick the nice UCI so we're going to pick a thing called cover type",
    "start": "1459200",
    "end": "1465200"
  },
  {
    "text": "which is a forest cover type a pretty old data set that Us in machine learning a lot as a demonstration data set i'm",
    "start": "1465200",
    "end": "1471880"
  },
  {
    "text": "parsing a CSV file I'm going to see the breakout of the initial lines",
    "start": "1471880",
    "end": "1477360"
  },
  {
    "text": "um so the the data set is about 75 megabytes on disk um as you can see if",
    "start": "1477360",
    "end": "1483200"
  },
  {
    "text": "you read up there it's about half a million rows 55 columns about 10 megabytes in Ram that's the compression",
    "start": "1483200",
    "end": "1489760"
  },
  {
    "text": "ratio between disc and RAM going on there and then I've got a just a quick view overview of the data set uh and it",
    "start": "1489760",
    "end": "1496760"
  },
  {
    "text": "goes out you know 55 columns wide and whatever um for this particular data set",
    "start": "1496760",
    "end": "1502600"
  },
  {
    "text": "the column one is meters of elevation where they took the sample and column",
    "start": "1502600",
    "end": "1507720"
  },
  {
    "text": "two is like meters distance to nearest water source and the far right hand column is the forest cover type is a",
    "start": "1507720",
    "end": "1514799"
  },
  {
    "text": "number from 1 to seven those are the digits on the right there that say you know 55 225 whatever it's going to be um",
    "start": "1514799",
    "end": "1522000"
  },
  {
    "text": "that's like Alpine uh forest or pinewoods or Meadow or you know Marsh or",
    "start": "1522000",
    "end": "1527760"
  },
  {
    "text": "whatever it's going to be and then there's 50 other features floating around it's a big pile of data",
    "start": "1527760",
    "end": "1534000"
  },
  {
    "text": "um I'm going to run because it's you know it's a forest cover top random",
    "start": "1534000",
    "end": "1539520"
  },
  {
    "text": "Forest is a good thing here so this is a machine learning algorithm this is called random Forest uh I'm not going to",
    "start": "1539520",
    "end": "1545279"
  },
  {
    "text": "go into a lot of details but I'm going to build trees decision trees with random weaknesses so I have a collection",
    "start": "1545279",
    "end": "1552039"
  },
  {
    "text": "of 50 odd here I'll just hit the go button here take all the defaults uh 50",
    "start": "1552039",
    "end": "1557080"
  },
  {
    "text": "odd sort of weak learners where each learner is a decision tree a cart tree and then",
    "start": "1557080",
    "end": "1563360"
  },
  {
    "text": "uh uh the sum of them they vote together uh does actually a really good job of uh",
    "start": "1563360",
    "end": "1569080"
  },
  {
    "text": "finding and uh being able to run predictions on the data set so if I run down here no he's not",
    "start": "1569080",
    "end": "1576200"
  },
  {
    "text": "going to do this one's speed so I have to wait till this guy runs to the end um so we take like another 30 seconds here and I'll have something done",
    "start": "1576200",
    "end": "1585000"
  },
  {
    "text": "um so while we're waiting here to kind of answer any questions about what this means or why you would care what machine",
    "start": "1589760",
    "end": "1596360"
  },
  {
    "text": "learning is doing here see okay so the you know the general notion is this predictive",
    "start": "1596360",
    "end": "1602480"
  },
  {
    "text": "modeling I'm going to build a model of the real world based on my input data",
    "start": "1602480",
    "end": "1607799"
  },
  {
    "text": "set with the hopes that the model will let me predict new things",
    "start": "1607799",
    "end": "1612880"
  },
  {
    "text": "uh with sort of high high degree of accuracy so I'm get this guy a little bit longer here and then we'll we'll",
    "start": "1612880",
    "end": "1618320"
  },
  {
    "text": "stop and take a look at him um so these predictive models are used by lots of people for different",
    "start": "1618320",
    "end": "1624520"
  },
  {
    "text": "things but for instance it can predict uh whether or not this credit card transaction is fraud or not whether or",
    "start": "1624520",
    "end": "1630039"
  },
  {
    "text": "not I'm looking at a some sort of DDOS attack whether or not I'm looking at a blob of cancer on an X-ray or not uh you",
    "start": "1630039",
    "end": "1637640"
  },
  {
    "text": "know what is my uh uh you know estimated costs to ensure the city of Chicago from",
    "start": "1637640",
    "end": "1645799"
  },
  {
    "text": "uh you know the next hail storm that comes through is going to wreck some percentage of roofs in a neighborhood um",
    "start": "1645799",
    "end": "1651480"
  },
  {
    "text": "you know what's the lifetime uh Insurance costs of a particular population of people there's all kinds",
    "start": "1651480",
    "end": "1656919"
  },
  {
    "text": "of things you do with machine learning algorithms um and and they can be very highly predictive so let me explain this chart here real quick uh going down is",
    "start": "1656919",
    "end": "1664399"
  },
  {
    "text": "the actual type of the you know the observation made on the data set of of",
    "start": "1664399",
    "end": "1669960"
  },
  {
    "text": "uh what the person found when they did their ground truth going across is what the model predicts so the diagonals",
    "start": "1669960",
    "end": "1676200"
  },
  {
    "text": "where the prediction was correct and of where the prediction was incorrect so in about a minute here or less I have",
    "start": "1676200",
    "end": "1681720"
  },
  {
    "text": "something a model that's about 90% accurate you can see about 10% fail rate way over there on the right um done on uh you know half a",
    "start": "1681720",
    "end": "1689039"
  },
  {
    "text": "million observations in a few seconds on my laptop and that's a you know that's a reasonable result for not much work",
    "start": "1689039",
    "end": "1696279"
  },
  {
    "text": "actually uh if I was to have a you know cluster machines I could go a lot faster or a lot bigger or both um and I have a",
    "start": "1696279",
    "end": "1704320"
  },
  {
    "text": "model that does something interesting if I were to run random Forest a little bit longer longer here I'd get a you know",
    "start": "1704320",
    "end": "1709559"
  },
  {
    "text": "more highly predictive model um and and you know it's the general trade-off is",
    "start": "1709559",
    "end": "1714679"
  },
  {
    "text": "some of the models uh will build are very fast to build with less predictive accuracy and some are slower to build",
    "start": "1714679",
    "end": "1721080"
  },
  {
    "text": "with more accuracy random force is kind of in the middle um the other thing going on here is that some of the models",
    "start": "1721080",
    "end": "1726320"
  },
  {
    "text": "are more uh call interpretable so yeah here's my mean squ era by trees it",
    "start": "1726320",
    "end": "1731679"
  },
  {
    "text": "probably didn't have any other numbers in there yeah was built too fast it's fine so that's that's a unit used to",
    "start": "1731679",
    "end": "1737159"
  },
  {
    "text": "decide when to stop trees that you're not getting any better um random Forest",
    "start": "1737159",
    "end": "1742679"
  },
  {
    "text": "is sort of in the middle of being interpretable and what does interpretable mean it means I can look at the model understand why it's predicting what it predicts uh like",
    "start": "1742679",
    "end": "1750320"
  },
  {
    "text": "logistic regression is very interpretable although it's a weaker model but you can read off the the",
    "start": "1750320",
    "end": "1755880"
  },
  {
    "text": "different coefficients on a a generalized linear model logistic regression sort of directly understand",
    "start": "1755880",
    "end": "1761159"
  },
  {
    "text": "why it's making predictions and that actually turns into like government regulations uh people do um say FICO",
    "start": "1761159",
    "end": "1767080"
  },
  {
    "text": "scorecard models if you're getting credit allowed or denied in the US um you have to be told",
    "start": "1767080",
    "end": "1772919"
  },
  {
    "text": "why you were denied credit and so the government basically mandated you do logistic aggression or variant thereof",
    "start": "1772919",
    "end": "1779120"
  },
  {
    "text": "um because you can explain the results of it to the in consumer that they got denied credit because of",
    "start": "1779120",
    "end": "1785760"
  },
  {
    "text": "something you goes to deep learning model and it's highly opaque you don't know why it predicts but it's also by",
    "start": "1785760",
    "end": "1791360"
  },
  {
    "text": "far the best predictor deep learning models are like his magical oracles that will with extremely high accuracy make",
    "start": "1791360",
    "end": "1796559"
  },
  {
    "text": "all kinds of fun predictions these models they're built in or are they custom so this is the model I just built",
    "start": "1796559",
    "end": "1802919"
  },
  {
    "text": "right now it's sitting in the memory in my jvm um if I want to pull the model out and do something with it I'm going",
    "start": "1802919",
    "end": "1810519"
  },
  {
    "text": "to do something bad here it's going to take a second um or a few I'm going to torture my browser I'm going to pull the model out as a piece of java code so",
    "start": "1810519",
    "end": "1817159"
  },
  {
    "text": "it's a straight up plain old pojo but it's big enough that when I display it in the browser is piece of code is a giant pile of text the browser is going",
    "start": "1817159",
    "end": "1823240"
  },
  {
    "text": "to barf here for a second there it goes um okay so here is border plate we've",
    "start": "1823240",
    "end": "1828480"
  },
  {
    "text": "all automatically you know generated including instructions on how to compile it and how to use the model but the goal",
    "start": "1828480",
    "end": "1833919"
  },
  {
    "text": "here is to let you take this model and go into a production setting so somewhere way down here after all the",
    "start": "1833919",
    "end": "1839200"
  },
  {
    "text": "boiler plate here's a tree so I said it was a decision tree here's a decision tree float prediction is equal to uh",
    "start": "1839200",
    "end": "1847200"
  },
  {
    "text": "well if you're missing that's the Nan check else if column 13 is or column 14",
    "start": "1847200",
    "end": "1852399"
  },
  {
    "text": "is whatever less than this and next and d d somewhere down here at the bottom",
    "start": "1852399",
    "end": "1858240"
  },
  {
    "text": "there's an answer it comes out okay it must have been you know I'm going to pick two or or one or whatever it's going to be this is class two out of my",
    "start": "1858240",
    "end": "1865480"
  },
  {
    "text": "seven classes right so it's a decision tree",
    "start": "1865480",
    "end": "1870480"
  },
  {
    "text": "um here it rolls on rolls on rolls on okay so the decision trees get big and",
    "start": "1870960",
    "end": "1876639"
  },
  {
    "text": "somewhere there's a second and a third and a fourth and a fifth and there's 50 decision trees all buried in here and and what it amounts to is if you run",
    "start": "1876639",
    "end": "1883399"
  },
  {
    "text": "this code with 90% accuracy it will predict the correct for for cover type",
    "start": "1883399",
    "end": "1889039"
  },
  {
    "text": "and if I do the same thing for like credit card data I'll have a model out that if I run with some level of",
    "start": "1889039",
    "end": "1894360"
  },
  {
    "text": "accuracy it'll tell me I got a fraud or not a fraud um this particular all these",
    "start": "1894360",
    "end": "1900279"
  },
  {
    "text": "models do no allocation in their core inter Loops they run sort of finite fixed amount of codes so you can time",
    "start": "1900279",
    "end": "1905440"
  },
  {
    "text": "them and know exactly how long they take so if you have a time sensitive scoring issue like a credit card swipe the guy's waiting at Starbucks for his answer",
    "start": "1905440",
    "end": "1912360"
  },
  {
    "text": "right you have some number of milliseconds you're supposed to report you know thumbs up thumbs down at you can count the number of milliseconds",
    "start": "1912360",
    "end": "1918679"
  },
  {
    "text": "this guy runs at and that's what it runs at uh it's just sort of ready to go in prediction right like that so yeah the",
    "start": "1918679",
    "end": "1924120"
  },
  {
    "text": "model runs on and on and on but it's all sort of straightforwardly stuff I've do a logistic regression the model's tiny",
    "start": "1924120",
    "end": "1930039"
  },
  {
    "text": "it's very very simple um and you you can see we can run a logistic regression",
    "start": "1930039",
    "end": "1935720"
  },
  {
    "text": "here when we do that uh let's go new tab browser so I'm",
    "start": "1935720",
    "end": "1942360"
  },
  {
    "text": "doing this from the browser um there's a number of apis we support",
    "start": "1942360",
    "end": "1949080"
  },
  {
    "text": "uh rest and Json is an obvious one and then the browser is built over the rest and Json um let's do",
    "start": "1949080",
    "end": "1957559"
  },
  {
    "text": "that get a parse going okay yeah come on",
    "start": "1957559",
    "end": "1963000"
  },
  {
    "text": "done so that was uh much smaller data sets only you know two Megs in Ram 50,000 row 40,000",
    "start": "1963000",
    "end": "1969600"
  },
  {
    "text": "rows uh generalize Lear modeling well we'll do generalize Lear modeling okay",
    "start": "1969600",
    "end": "1976159"
  },
  {
    "text": "so here is an airline data set subfraction thereof and the question is can I predict whether or not my air",
    "start": "1976159",
    "end": "1982480"
  },
  {
    "text": "flight will be delayed or not this particular data set has a lot of what we call answer columns an answer column is",
    "start": "1982480",
    "end": "1989240"
  },
  {
    "text": "something that you got after the fact it's typically added onto data sets that's not available before you get on",
    "start": "1989240",
    "end": "1995080"
  },
  {
    "text": "the airplane so for instance whether or not you're canceled in the middle here is only available till after you showed",
    "start": "1995080",
    "end": "2000799"
  },
  {
    "text": "up the airport and discovered the flight was canceled right so if you predict with that the model will immediately",
    "start": "2000799",
    "end": "2007120"
  },
  {
    "text": "discover that every time the flight was canceled you were delayed so it's kind of useless so I'm going to exclude that",
    "start": "2007120",
    "end": "2013799"
  },
  {
    "text": "um except I just did the wrong thing here uh let's get rid of all of these",
    "start": "2013799",
    "end": "2018919"
  },
  {
    "text": "there we go no okay fine let me try again here me easier to do it this",
    "start": "2018919",
    "end": "2026000"
  },
  {
    "text": "way if I do my shift click the correct way here I'm looking for looking for",
    "start": "2026000",
    "end": "2032720"
  },
  {
    "text": "control click that's I'm looking for there it goes um don't want diverted or cancel I do want distance and the origin",
    "start": "2032720",
    "end": "2039240"
  },
  {
    "text": "and dust that's makes sense clearly don't want arrival delays CRS is the",
    "start": "2039240",
    "end": "2044840"
  },
  {
    "text": "planed lapse time that I want to keep um actual lapse time I need to catch",
    "start": "2044840",
    "end": "2050000"
  },
  {
    "text": "because if the actual lapse time is really long then somewhere I got delayed um I want to get rid of tail num",
    "start": "2050000",
    "end": "2055800"
  },
  {
    "text": "num and flight number because tail num is a unique identifier on most of the",
    "start": "2055800",
    "end": "2061200"
  },
  {
    "text": "flights for this small of a data set and then we'll simply predict if you got on a plane with this following tail number",
    "start": "2061200",
    "end": "2066760"
  },
  {
    "text": "your flight was delayed or not because there's not enough flights for that one plane to to have it not be able to tell",
    "start": "2066760",
    "end": "2072839"
  },
  {
    "text": "otherwise and again get rid of the actuals and keep the plan times and it'll just go for the time of the day of",
    "start": "2072839",
    "end": "2078000"
  },
  {
    "text": "the week the carrier what time your flight was supposed to take off your source and dust and so on so forth come",
    "start": "2078000",
    "end": "2083398"
  },
  {
    "text": "down here this is generalized linear modeling covers lots of interesting cases but binomial turns into logistic",
    "start": "2083399",
    "end": "2088480"
  },
  {
    "text": "regression which is a way to uh you know do true or false I'm going to uh just",
    "start": "2088480",
    "end": "2093560"
  },
  {
    "text": "take the defaults there um so logistic regression I don't know people want to go into how much math okay we're done so",
    "start": "2093560",
    "end": "2099599"
  },
  {
    "text": "logistic regression is one of ones is actually pretty fast and scales very strongly so that you can get a logistic",
    "start": "2099599",
    "end": "2104680"
  },
  {
    "text": "regression done on a terabyte in and you know under a minute um it's it's a",
    "start": "2104680",
    "end": "2110280"
  },
  {
    "text": "really fast model building uh it has an easy to understand model but it's less predictive so here instead of a 90%",
    "start": "2110280",
    "end": "2117400"
  },
  {
    "text": "prediction I'm getting around you know 70% and you can see sort of the you know the red line represents a 50/50 die roll",
    "start": "2117400",
    "end": "2123839"
  },
  {
    "text": "and I'm better than 50/50 so I'm getting some predictive quality out but not huge amount um but the other side I can go up",
    "start": "2123839",
    "end": "2130280"
  },
  {
    "text": "here and look and see what do these numbers mean and and what happens here is that the coefficients that are",
    "start": "2130280",
    "end": "2137400"
  },
  {
    "text": "positive Drive the the the equation above the yal 1 over 1 plus math blah",
    "start": "2137400",
    "end": "2143400"
  },
  {
    "text": "blah blah BL blah towards a one and negative coefficients drive it toward a zero and so is delayed being a one says",
    "start": "2143400",
    "end": "2151119"
  },
  {
    "text": "the more likely that you are to be uh you know the higher the coefficient the more likely these delayed so taking off",
    "start": "2151119",
    "end": "2157359"
  },
  {
    "text": "or arriving at this particular airport I don't know what that is or taking off from this other guy are both highly indicative of whether you're delayed or",
    "start": "2157359",
    "end": "2163400"
  },
  {
    "text": "not and if I run through here there's your Chicago oops here you go Chicago Midway is right there",
    "start": "2163400",
    "end": "2168839"
  },
  {
    "text": "um uh there's a few other ones that come out pretty quick that are kind of interesting destination Austin that's",
    "start": "2168839",
    "end": "2175280"
  },
  {
    "text": "interesting okay fine I'll quit looking at it but you can sort through and immediately start picking out you know",
    "start": "2175280",
    "end": "2180599"
  },
  {
    "text": "uh on the on the full size data set SFO shows up right away as like a bad airport to take off or land at um so",
    "start": "2180599",
    "end": "2187160"
  },
  {
    "text": "does at and then certain airlines like suck that you don't want to ever be on this Airline and other airlines are perfectly",
    "start": "2187160",
    "end": "2193000"
  },
  {
    "text": "good so you can you can get something out of the a bigger data set here this little data set doesn't have enough data to pick up all those",
    "start": "2193000",
    "end": "2198520"
  },
  {
    "text": "features um but the equation is this this is the that that is the model right there so that's one line of java code um",
    "start": "2198520",
    "end": "2205920"
  },
  {
    "text": "you just drop that in and in your you know predictive in your mobile phone app",
    "start": "2205920",
    "end": "2211280"
  },
  {
    "text": "and right away you get an answer out um okay so that's sort of the quick",
    "start": "2211280",
    "end": "2217839"
  },
  {
    "text": "pass through the demo um maybe I should stop and take questions on this before I",
    "start": "2217839",
    "end": "2223400"
  },
  {
    "text": "I flip back to slides no okay fine we're gonna we're",
    "start": "2223400",
    "end": "2229280"
  },
  {
    "text": "going to go we're going to go on here uh okay so um so we've been very",
    "start": "2229280",
    "end": "2235240"
  },
  {
    "start": "2232000",
    "end": "2602000"
  },
  {
    "text": "busy here uh and the latest thing we're messing around with here is spark integration so we're doing big data",
    "start": "2235240",
    "end": "2240960"
  },
  {
    "text": "stuff and so is spark although we have very different sort of models of data and execution um it's clear that that",
    "start": "2240960",
    "end": "2247800"
  },
  {
    "text": "you know there's an interesting integration going on here um so uh uh",
    "start": "2247800",
    "end": "2252960"
  },
  {
    "text": "we're able now to move data back and forth between spark and h2o's data frames uh and it's in process in memory",
    "start": "2252960",
    "end": "2260760"
  },
  {
    "text": "so it's actually pretty quick to go back and forth and then um uh you can take an",
    "start": "2260760",
    "end": "2265839"
  },
  {
    "text": "HTO data frame and turn it into a spark ad and run spark jobs on it sort of directly like the one line of code got",
    "start": "2265839",
    "end": "2272119"
  },
  {
    "text": "there and in addition the the H data frames now support a Scala collection notation so you can say for each and put",
    "start": "2272119",
    "end": "2279079"
  },
  {
    "text": "you know some kind of map kind of code right in there and the codes on GitHub uh you need the the dev version of H2O",
    "start": "2279079",
    "end": "2285760"
  },
  {
    "text": "uh and then perier is sparkling water it's our combo this will probably go away in another month or two all we",
    "start": "2285760",
    "end": "2292640"
  },
  {
    "text": "needed out of spark was a a hook to call h2o at startup time in the right places",
    "start": "2292640",
    "end": "2297880"
  },
  {
    "text": "um and which we put a juror request at spark people and they've taken some version of it and so won't be too long",
    "start": "2297880",
    "end": "2304040"
  },
  {
    "text": "before we don't actually need a spark build um Okay so can move back and forth",
    "start": "2304040",
    "end": "2309119"
  },
  {
    "text": "um between the two and it's all in memory it's all in process there's no external tooling needed mostly data",
    "start": "2309119",
    "end": "2315240"
  },
  {
    "text": "doesn't move it is does change shape because it's going to be in Sparks format and H2O format and then there's a",
    "start": "2315240",
    "end": "2320800"
  },
  {
    "text": "difference between eager and lazy I'll cover in a second um we do make a data copy but the HTO data is typically very",
    "start": "2320800",
    "end": "2326520"
  },
  {
    "text": "highly compressed over the spark data so that if you're running a successful spark cluster right now um and you make",
    "start": "2326520",
    "end": "2332760"
  },
  {
    "text": "a copy of the data the extra memory you need isn't a whole lot over what you're already consuming for spark",
    "start": "2332760",
    "end": "2339440"
  },
  {
    "text": "um the you know this is a little bit of the layout spark builds up from blocks",
    "start": "2340200",
    "end": "2345720"
  },
  {
    "text": "they call partitions these are structures that are limited to a single jvm they don't cross a machine boundary",
    "start": "2345720",
    "end": "2350839"
  },
  {
    "text": "um and H2 uses these chunks and collections for every column um you can have lots of these in any given Java",
    "start": "2350839",
    "end": "2356440"
  },
  {
    "text": "Heap uh limited only by memory and then you know looking at it this way an rdd",
    "start": "2356440",
    "end": "2363359"
  },
  {
    "text": "is all of the memory all the data an H2 data frame is all of it but were broken up by columns in the pink for the",
    "start": "2363359",
    "end": "2369520"
  },
  {
    "text": "vectors and rdds are broken up by chunks there'll be a couple chunks for every jvm it's a little different format but",
    "start": "2369520",
    "end": "2375359"
  },
  {
    "text": "we'll go back and forth between the two different layouts with just a Java call to go hack the data",
    "start": "2375359",
    "end": "2380760"
  },
  {
    "text": "around um when we convert the H2O data frames the conversion happens",
    "start": "2380760",
    "end": "2386920"
  },
  {
    "text": "immediately it's essentially same as a spark uh checkpoint you're going to run",
    "start": "2386920",
    "end": "2391960"
  },
  {
    "text": "the you know rdds are typically lazy until you demand an output H2 will demand an output get its data in H2O",
    "start": "2391960",
    "end": "2398560"
  },
  {
    "text": "format then you can do something with an H2O all those things you do in H2O are all eagerly done on the spot um when",
    "start": "2398560",
    "end": "2405960"
  },
  {
    "text": "you're done you want to go back to spark ID uh and you say give me a two rdd you get a you get a wrapper object so it's",
    "start": "2405960",
    "end": "2411560"
  },
  {
    "text": "lazy at that point um but you've checkpointed in H2O and then you can add rdds all all along you'll build up your",
    "start": "2411560",
    "end": "2417680"
  },
  {
    "text": "pipeline of computation and when you ask for the spark result it'll pull the data out of H2O convert in spark format and",
    "start": "2417680",
    "end": "2423160"
  },
  {
    "text": "then carry through the spark pipeline sort of the way spark normally does things okay so that's that's it I'm just going",
    "start": "2423160",
    "end": "2429520"
  },
  {
    "text": "to wrap up here um we have a couple different use cases people use the system for so no distribution coding is",
    "start": "2429520",
    "end": "2437440"
  },
  {
    "text": "basically whole algorithms or whole Vector math kind of things uh often this is the rest and Json style interface and",
    "start": "2437440",
    "end": "2444000"
  },
  {
    "text": "you're doing something like loaded data set run a logistic regression get results just what I demoed a minute ago",
    "start": "2444000",
    "end": "2449200"
  },
  {
    "text": "um and you can drive this from R python web base that was the browser you saw there bash curl scripting however you",
    "start": "2449200",
    "end": "2454720"
  },
  {
    "text": "want to run it we do have an active R community who uses H2O as a way to get big data on R and they can type their R",
    "start": "2454720",
    "end": "2461960"
  },
  {
    "text": "expressions like they always have been doing an r and the work's all done on the cluster on the cloud and the data set sizes are you know thousandfold",
    "start": "2461960",
    "end": "2468240"
  },
  {
    "text": "bigger than what they can do in R um you can dive under the hood and write code in uh you know map reduce style and",
    "start": "2468240",
    "end": "2475480"
  },
  {
    "text": "that's pretty much good for any sort of dense linear algebra anytime I'm going to pass over all the data and do something and passing over all the data",
    "start": "2475480",
    "end": "2481880"
  },
  {
    "text": "and doing something is often on the order of you know modest millisecond counts so it's it's fast enough you can",
    "start": "2481880",
    "end": "2487079"
  },
  {
    "text": "do interesting things with a bunch of passes uh it's not the standard you know Hado map reduce for Speed it's much much",
    "start": "2487079",
    "end": "2493160"
  },
  {
    "text": "faster and then we support a bunch more complicated stuff I'm not going to talk about today um but there's a full-fledged key Value Store under the",
    "start": "2493160",
    "end": "2499440"
  },
  {
    "text": "hood and you can do kind of interesting graph algorithms and stuff with that so in summary most simple Java just",
    "start": "2499440",
    "end": "2506359"
  },
  {
    "text": "works uh I write we have map functions that go to the thousands and thousands",
    "start": "2506359",
    "end": "2512000"
  },
  {
    "text": "of lines of java code and they all just work and they look like Java code and it runs like Java code and it all feels right um you know it's fast uh and and",
    "start": "2512000",
    "end": "2520520"
  },
  {
    "text": "people everyone says fast but we're running as the same speed as Java code would run on AR raise Java arrays so",
    "start": "2520520",
    "end": "2525839"
  },
  {
    "text": "it's as fast as you could get out of java which is pretty much CPU bound or memory bandwith Bound in most cases is",
    "start": "2525839",
    "end": "2531680"
  },
  {
    "text": "as fast as the hardware is going to go you can write uh Big Data as well and it's a little bit slower but not much um",
    "start": "2531680",
    "end": "2538440"
  },
  {
    "text": "because we're doing compression as you do writes um and like I said we're typically memory bandwidth limited um we",
    "start": "2538440",
    "end": "2544079"
  },
  {
    "text": "support the full Java memory model in a distributed cluster uh there's no lazy consistency it's all exact uh and it's",
    "start": "2544079",
    "end": "2550280"
  },
  {
    "text": "all actually fairly fast exact um although if you do conflicting rights you're going to follow the the Java",
    "start": "2550280",
    "end": "2555440"
  },
  {
    "text": "memory model which will not necessarily give you the answer you want because it's pretty Loosey Goosey about ordering",
    "start": "2555440",
    "end": "2561880"
  },
  {
    "text": "um we can do transactional updates uh which you do internally a lot for command and control kinds of",
    "start": "2561880",
    "end": "2568640"
  },
  {
    "text": "things and then we writing you know Big Data distributed analytics um lots and lots of algorithms",
    "start": "2568640",
    "end": "2575680"
  },
  {
    "text": "we've written we're working on more um we're solidly working on 100 Gig data set that's the nightly Jenkins test so",
    "start": "2575680",
    "end": "2581960"
  },
  {
    "text": "actually each post push test is now doing something on that order magnitude um we're looking at terabyte scale stuff",
    "start": "2581960",
    "end": "2587880"
  },
  {
    "text": "now we definitely have customers using terabyte scale data right now and we have paying customers in production and it's all open source and free so go",
    "start": "2587880",
    "end": "2595160"
  },
  {
    "text": "download and play for for Big Data yeah two questions um so you're",
    "start": "2595160",
    "end": "2603520"
  },
  {
    "start": "2602000",
    "end": "3026000"
  },
  {
    "text": "working on this also these uh models uh forest and right Forest Etc and on",
    "start": "2603520",
    "end": "2611559"
  },
  {
    "text": "making more of those yes so the current you know interesting new model coming coming out is Cox proportional hazards",
    "start": "2611559",
    "end": "2618960"
  },
  {
    "text": "which is used typically for survival analysis or lifetime analysis out of a collection of a million people in your",
    "start": "2618960",
    "end": "2625119"
  },
  {
    "text": "insurance pool some people die off at a steady rate after they've aged out enough and while maybe be harsh to think",
    "start": "2625119",
    "end": "2631800"
  },
  {
    "text": "about people dying it's what the insurance company does for living for the last 100 years and so they look at the large pool of people and they say",
    "start": "2631800",
    "end": "2637359"
  },
  {
    "text": "how many people are old old or old or di dead and then you know we have insurance payouts and what's the set of money and",
    "start": "2637359",
    "end": "2643040"
  },
  {
    "text": "how much do we need to track based on the age of our pool and that's Cox survival analysis same thing actually",
    "start": "2643040",
    "end": "2648240"
  },
  {
    "text": "works for um lifetime analysis of anything that you have and then it breaks and you don't so iPhones what's",
    "start": "2648240",
    "end": "2656200"
  },
  {
    "text": "the insurance coverage cost for the collection of people with you know iPhones on the planet when they die and",
    "start": "2656200",
    "end": "2661480"
  },
  {
    "text": "you drop it the screen broke the longer you have it the more likely it is that you drop in the screen breaks and you go in and get your insurance payout so the",
    "start": "2661480",
    "end": "2668319"
  },
  {
    "text": "guy's doing those Insurance run that kind of analysis on this on your car on",
    "start": "2668319",
    "end": "2674040"
  },
  {
    "text": "you know I don't know there's there's there's actually a lot of uses for that particular one yeah another question what happens",
    "start": "2674040",
    "end": "2680319"
  },
  {
    "text": "if a not goes down so we're not an ha solution so we looked hard at that um and we thought about it for a long time",
    "start": "2680319",
    "end": "2686599"
  },
  {
    "text": "um and we know how to do it but it's not worth the effort right now so instead we went for sort of raw speed and most",
    "start": "2686599",
    "end": "2694119"
  },
  {
    "text": "operations are all done with in seconds to minutes and so if a node goes down reboot the",
    "start": "2694119",
    "end": "2699880"
  },
  {
    "text": "cluster so the cluster will come up in seconds loading the data will take longer it's whatever you know count of",
    "start": "2699880",
    "end": "2705520"
  },
  {
    "text": "discs divided by Max Max disc bandwidth we we can hit most disc drives to 80% of",
    "start": "2705520",
    "end": "2711520"
  },
  {
    "text": "their rated throughput and a parallel data load so without any trouble uh and then and you're up again so if a node",
    "start": "2711520",
    "end": "2718079"
  },
  {
    "text": "goes down it's like a big calculator and if a node goes down you shut the calculator off and you turn it back on again and you go again so it it's in",
    "start": "2718079",
    "end": "2726200"
  },
  {
    "text": "that in that sense deployment model is very simple and straightforward if we get to the point where people are running jobs that take",
    "start": "2726200",
    "end": "2732760"
  },
  {
    "text": "uh weeks or a week two weeks on clusters of 100 or more in size uh we'll probably",
    "start": "2732760",
    "end": "2739280"
  },
  {
    "text": "need ha solution and like I said I know how to do it from the technology standpoint hasn't been worth to do it right",
    "start": "2739280",
    "end": "2744960"
  },
  {
    "text": "yet yeah uh one from the Q is any thoughts about uh running H2O on bare",
    "start": "2744960",
    "end": "2751200"
  },
  {
    "text": "metal versus a VM oh any thoughts on H2 and bare metal versus VM yeah so this is sort of the obvious story about VMS",
    "start": "2751200",
    "end": "2757920"
  },
  {
    "text": "versus H2O we've been looking at that actually right now a lot of people um",
    "start": "2757920",
    "end": "2763400"
  },
  {
    "text": "usually VMS add some amount of overhead uh H2O will burn all your cores and all",
    "start": "2763400",
    "end": "2768800"
  },
  {
    "text": "your memories sort of easily uh and so if you add overhead you just slow yourself down um it it's not like it",
    "start": "2768800",
    "end": "2775200"
  },
  {
    "text": "makes sense to have it share nicely with somebody else on a neighbor because H2 is not actually a nice neighbor when you",
    "start": "2775200",
    "end": "2781400"
  },
  {
    "text": "say go it's going to take everything and go um and so it doesn't work well it's not that it doesn't work at all you can",
    "start": "2781400",
    "end": "2788319"
  },
  {
    "text": "work fine it just it's not a nice neighbor for having you know being on the same Hardware we do test and we run",
    "start": "2788319",
    "end": "2793839"
  },
  {
    "text": "that way all the time it's because it happens you know people do it that way um but it's it's perhaps not the best",
    "start": "2793839",
    "end": "2801000"
  },
  {
    "text": "way to set up a cluster for running H2O that that said we run an ec2 all the",
    "start": "2801000",
    "end": "2807720"
  },
  {
    "text": "time um that's a very standard setup for us and those are all obviously",
    "start": "2807720",
    "end": "2813040"
  },
  {
    "text": "virtualized you mentioned theop and hdfs on the way what a connection yeah okay",
    "start": "2813040",
    "end": "2818240"
  },
  {
    "text": "so it's complicated um there's essentially no connection but it looks like there's a really big connection so the the the connection is",
    "start": "2818240",
    "end": "2826200"
  },
  {
    "text": "um most people's big data is in Hadoop htfs so we'll read from htfs as a",
    "start": "2826200",
    "end": "2833160"
  },
  {
    "text": "parallel file Source just fine we'll read from S3 we'll read from local drivve we'll read from all these sources",
    "start": "2833160",
    "end": "2838359"
  },
  {
    "text": "including hdfs um but we don't need to be on a Hadoop cluster um but we can so",
    "start": "2838359",
    "end": "2844559"
  },
  {
    "text": "we'll play nicely in the Hadoop ecosystem um as a funny kind of a mapper job if you want to run us on Hadoop",
    "start": "2844559",
    "end": "2850040"
  },
  {
    "text": "where the map sticks around forever it never goes away uh and then you know Burns all cores when it goes and is idle",
    "start": "2850040",
    "end": "2855640"
  },
  {
    "text": "when you're not running it so it's a kind of a weird mapper job um it's not very efficient in that sense but it's",
    "start": "2855640",
    "end": "2862960"
  },
  {
    "text": "not too bad and and what really happens is we go into uh somebody who's interested you know in putting H2O in",
    "start": "2862960",
    "end": "2869520"
  },
  {
    "text": "production and they already have a big Hadoop cluster lying around but they don't have a a spare bare metal cluster",
    "start": "2869520",
    "end": "2874880"
  },
  {
    "text": "lying around so we'll run on the Hado cluster because that's the quickest way to get a cluster operation going now",
    "start": "2874880",
    "end": "2880520"
  },
  {
    "text": "that said most Hado clusters have machines that are uh spindle heavy and CPU and memory light and we exactly want",
    "start": "2880520",
    "end": "2887559"
  },
  {
    "text": "the CPU and memory uh and and so it's it's a you get a giant collection of",
    "start": "2887559",
    "end": "2892800"
  },
  {
    "text": "tiny machines uh and and that's sort of not necessarily the optimal way to run H2O so you're frequently better off with",
    "start": "2892800",
    "end": "2899319"
  },
  {
    "text": "uh uh fewer fatter nodes",
    "start": "2899319",
    "end": "2904079"
  },
  {
    "text": "is it going to come back but not that it says anything in so um you know along the line of",
    "start": "2907280",
    "end": "2913280"
  },
  {
    "text": "fewer fatter nodes um the the the what is you what a configuration for machine",
    "start": "2913280",
    "end": "2920119"
  },
  {
    "text": "looks like that is sort of interesting or or Works while or doesn't varies by what you want to do with it uh the",
    "start": "2920119",
    "end": "2926720"
  },
  {
    "text": "logistic aggression is strongly scaling and so you really can get away with uh a large sea of smaller machines and it",
    "start": "2926720",
    "end": "2933720"
  },
  {
    "text": "will do great um random Forest typically has more uh Network bandwidth",
    "start": "2933720",
    "end": "2940160"
  },
  {
    "text": "and as the trees get deeper you have to build these histograms they get exponentially bigger as the tree gets deeper and suddenly you have very large",
    "start": "2940160",
    "end": "2946200"
  },
  {
    "text": "data sets are getting SCH slopped around between nodes and so your network throughput becomes an interesting bottleneck and you're better off with",
    "start": "2946200",
    "end": "2952839"
  },
  {
    "text": "fewer nodes simply because there's less Network traffic you go to deep learning the Deep learning uh runs or neural Nets",
    "start": "2952839",
    "end": "2960200"
  },
  {
    "text": "runs these neural net algorithms that within a node are extremely efficient using this Hog Wild algorithm they're racy and and and like sort of crazy fast",
    "start": "2960200",
    "end": "2969480"
  },
  {
    "text": "um but the models all Drift from each other independently uh because there's no x86 coherency Hardware across a node",
    "start": "2969480",
    "end": "2977040"
  },
  {
    "text": "and so that has to be taken care of by shipping the models across the wire to resync them back up or they drift too far from each other when you resync them",
    "start": "2977040",
    "end": "2983119"
  },
  {
    "text": "they sort of cancel each other out so you want to keep resyncing them and that turns into a network latency as opposed",
    "start": "2983119",
    "end": "2988240"
  },
  {
    "text": "to bandwidth issue so some of the algorithms are sort of network tolerant and some are less Network tolerant and",
    "start": "2988240",
    "end": "2995240"
  },
  {
    "text": "so you kind of varies by algorithm whether you want to have uh you know whether you you can get away with fatter",
    "start": "2995240",
    "end": "3000720"
  },
  {
    "text": "nodes or or skinnier nodes and more of them or fatter nodes and fewer of them all right well that's actually you know",
    "start": "3000720",
    "end": "3006960"
  },
  {
    "text": "it's about time and and I'm done with slides I have a lot of little fun extra add-on slides that can go through people",
    "start": "3006960",
    "end": "3012760"
  },
  {
    "text": "want but why don't we call this the official end and I'll be around for a little while for Q&A",
    "start": "3012760",
    "end": "3018920"
  },
  {
    "text": "here thank you",
    "start": "3018920",
    "end": "3023078"
  }
]
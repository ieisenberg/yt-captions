[
  {
    "start": "0",
    "end": "35000"
  },
  {
    "text": "[Music]",
    "start": "3550",
    "end": "7840"
  },
  {
    "text": "thank you all for being here is it working properly yeah okay thanks",
    "start": "12289",
    "end": "17520"
  },
  {
    "text": "so yeah we are here to share our journey to this very nice project we've done this all started with legal a legal",
    "start": "17520",
    "end": "24990"
  },
  {
    "text": "requirement like like it's very normal in banks but we we decided to have a positive approach to it and that's what",
    "start": "24990",
    "end": "30390"
  },
  {
    "text": "we're going to tell the story here and we made the best of it we did and that's the goal a little bit about ourselves",
    "start": "30390",
    "end": "36659"
  },
  {
    "start": "35000",
    "end": "90000"
  },
  {
    "text": "and my name is Marcos Maia I'm from Brazil I'm here for like four and a half years right now I really loved this",
    "start": "36659",
    "end": "43649"
  },
  {
    "text": "country my background is in engineering and I've been doing this for 23 years now mostly working in finance and as a",
    "start": "43649",
    "end": "50699"
  },
  {
    "text": "consultant in distributed computing like application servers all these platforms and messaging systems and now I'm",
    "start": "50699",
    "end": "57809"
  },
  {
    "text": "working investments at ING a few years it's a great place to work at and yeah we're here to set our story yes",
    "start": "57809",
    "end": "65070"
  },
  {
    "text": "my name is Steve Furber some three years with ing now worked in different areas",
    "start": "65070",
    "end": "71250"
  },
  {
    "text": "but focused mainly on beca developing developments I'm really a fan of spring",
    "start": "71250",
    "end": "76680"
  },
  {
    "text": "spring boot in general and I fell in love with Kafka let's say three years ago so we are going to share our story",
    "start": "76680",
    "end": "82560"
  },
  {
    "text": "today here I really like to work with the offender in architecture so little bits of that is also part of this",
    "start": "82560",
    "end": "88320"
  },
  {
    "text": "presentation but you have a lot of ground to cover so let's let's start yeah so a little bit just the context",
    "start": "88320",
    "end": "93480"
  },
  {
    "start": "90000",
    "end": "135000"
  },
  {
    "text": "for ing I think most of you know about ing but it's really important for us ing is growing a lot and it's this amazing",
    "start": "93480",
    "end": "100950"
  },
  {
    "text": "journey we're going through now to build a global platform ing it's it's it's really trying to focus on being more",
    "start": "100950",
    "end": "107280"
  },
  {
    "text": "like an IT company that has a banking license so the goal is to have a global platform in the end so we're or in this",
    "start": "107280",
    "end": "114150"
  },
  {
    "text": "journey to like onboarding countries in a single platform for investments in our case and but the whole bank is doing the",
    "start": "114150",
    "end": "120510"
  },
  {
    "text": "same and this is really amazing what we are going to and of course there's a lot",
    "start": "120510",
    "end": "125670"
  },
  {
    "text": "of open jobs we need all these new people so you can check out the decide if you're interested it's really a",
    "start": "125670",
    "end": "131700"
  },
  {
    "text": "really nice place to work really I I recommend it a little bit about today",
    "start": "131700",
    "end": "138170"
  },
  {
    "start": "135000",
    "end": "190000"
  },
  {
    "text": "so we're going to talk about the use case that that start out this journey that we're going to show I'll started if a regulation like I",
    "start": "138170",
    "end": "144200"
  },
  {
    "text": "mentioned the mid feet - we're going to explain a bit about it just a small part of it of course that's what we cover here we're going to show bit about our",
    "start": "144200",
    "end": "150859"
  },
  {
    "text": "mobile investments up we also have a website we also have the normal application on web browser but we're",
    "start": "150859",
    "end": "155930"
  },
  {
    "text": "going to show that the mobile app we're going to talk a bit about the over architecture and do a demo we're going",
    "start": "155930",
    "end": "162139"
  },
  {
    "text": "to talk a lot about which is really important to us observability that we're really on top of what's going on so we",
    "start": "162139",
    "end": "167750"
  },
  {
    "text": "talked a lot about a bit about metrics and monitoring how we use graphical streams to leverage to leverage what we",
    "start": "167750",
    "end": "174560"
  },
  {
    "text": "need and we're gonna show you how we do our local development how we can isolate and be productive doing local",
    "start": "174560",
    "end": "181730"
  },
  {
    "text": "development Africa because it requires many components and in the end we're going to share some lessons learned and",
    "start": "181730",
    "end": "186919"
  },
  {
    "text": "we're going to be open for questions if we have time yeah exactly Thanks yeah just before we",
    "start": "186919",
    "end": "193250"
  },
  {
    "start": "190000",
    "end": "225000"
  },
  {
    "text": "start we're working in investments we're working in a bank so I hope you understand we cannot show any real",
    "start": "193250",
    "end": "199220"
  },
  {
    "text": "prediction call today but we didn't want to come here on stage and only show slides we will work like to do a real demo showing real code so we decided to",
    "start": "199220",
    "end": "208129"
  },
  {
    "text": "basically make a lab project inspired by the work we did within investments so I promise you it's not boring it's it's",
    "start": "208129",
    "end": "214519"
  },
  {
    "text": "maybe even more advanced that we have in production but it will show you exactly what we do in our daily jobs so that's a",
    "start": "214519",
    "end": "223040"
  },
  {
    "text": "disclaimer before we actually start also one thing to remember the investment",
    "start": "223040",
    "end": "228620"
  },
  {
    "start": "225000",
    "end": "250000"
  },
  {
    "text": "domain is a quite complex domain right so we don't want to overload you with a lot of business lingo today but I think",
    "start": "228620",
    "end": "234229"
  },
  {
    "text": "one thing you should remember from this slide if we talk about a tick it's basically a price update from the stock",
    "start": "234229",
    "end": "240139"
  },
  {
    "text": "market we trades a lot of stocks for our customers around 40,000 40,000 if I'm",
    "start": "240139",
    "end": "245180"
  },
  {
    "text": "correct so we use this term constantly during the presentation okay Marcus",
    "start": "245180",
    "end": "252530"
  },
  {
    "start": "250000",
    "end": "328000"
  },
  {
    "text": "already talks a little bit about the method to regulation regulation sounds really boring right but for us it was",
    "start": "252530",
    "end": "258650"
  },
  {
    "text": "really a kick start of a really cool project so the method to regulation",
    "start": "258650",
    "end": "263870"
  },
  {
    "text": "basically is a really big regulation and just to sighs not only ing had to implement this",
    "start": "263870",
    "end": "270350"
  },
  {
    "text": "regulation but all European banks offering investment services to customers need had to do this it came",
    "start": "270350",
    "end": "277580"
  },
  {
    "text": "into effect already two years ago and and basically the goal is to protect our",
    "start": "277580",
    "end": "284510"
  },
  {
    "text": "customers in losing losing money so for us we focus on the on our use case the method regulations said we have",
    "start": "284510",
    "end": "292190"
  },
  {
    "text": "to inform customers at the end of the day if a stock in their portfolio drops ten percent in price so we went into a",
    "start": "292190",
    "end": "301010"
  },
  {
    "text": "couple of meetings with the business and yeah basically that was our requirement to start this project but yeah we talked",
    "start": "301010",
    "end": "307160"
  },
  {
    "text": "about them say yeah at the end of the day that's a bit yeah that's not really",
    "start": "307160",
    "end": "312620"
  },
  {
    "text": "good enough right you're probably already lost a lot of money maybe more than ten percent so why not do it in",
    "start": "312620",
    "end": "319520"
  },
  {
    "text": "real time that will be fine right at least the customer can act accordingly",
    "start": "319520",
    "end": "325450"
  },
  {
    "text": "so we started to we started there to give you a little bit of context we",
    "start": "325450",
    "end": "331400"
  },
  {
    "start": "328000",
    "end": "455000"
  },
  {
    "text": "would like to show you a couple of screens of our mobile investment app that customers are using so besides",
    "start": "331400",
    "end": "337550"
  },
  {
    "text": "their whole portfolio they can basically create alerts so for example if they have an ING stock in their portfolio and",
    "start": "337550",
    "end": "343790"
  },
  {
    "text": "say the price drops between or below ten",
    "start": "343790",
    "end": "349040"
  },
  {
    "text": "euros i would like to receive an alert so they can see their alerts they can create alerts and they can basically",
    "start": "349040",
    "end": "355340"
  },
  {
    "text": "list alerts that's that's pretty straightforward but during those meetings with the business they come up with yeah next to",
    "start": "355340",
    "end": "362900"
  },
  {
    "text": "their legal requirements from the regulation to have the ten percent drop in price also let's maybe take a",
    "start": "362900",
    "end": "368840"
  },
  {
    "text": "positive approach maybe I would like to set an alert when the price goes up because I might want to sell it sell a",
    "start": "368840",
    "end": "374990"
  },
  {
    "text": "stock right maybe also want a specific price when the stock reaches a certain",
    "start": "374990",
    "end": "381680"
  },
  {
    "text": "price I would like to receive an alert as well how about recurring alerts if and although it is matched we don't want",
    "start": "381680",
    "end": "388490"
  },
  {
    "text": "to have the customer walking in again on the phone and create another alert so maybe we can do recurring alerts",
    "start": "388490",
    "end": "394250"
  },
  {
    "text": "automatically so you see a lot of headaches Copas brother and brother and new features came in along the way",
    "start": "394250",
    "end": "400599"
  },
  {
    "text": "and then the biggest challenge was yeah you have to do with a lot of price",
    "start": "400599",
    "end": "406479"
  },
  {
    "text": "updates from the stock market right between two thousand and twelve thousand seconds so okay that was really a nice",
    "start": "406479",
    "end": "413740"
  },
  {
    "text": "challenge too to get to get started so yeah we did a lot of pcs we use",
    "start": "413740",
    "end": "420939"
  },
  {
    "text": "different technologies we tried out elasticsearch we did something with Cassandra but sooner or later we",
    "start": "420939",
    "end": "427419"
  },
  {
    "text": "realized we really need a streaming platform to tackle this and yeah we are",
    "start": "427419",
    "end": "433059"
  },
  {
    "text": "on the left side we are spring booth developers Java developers back-end developers and we didn't want to",
    "start": "433059",
    "end": "438580"
  },
  {
    "text": "maintain a copper cluster and we found out that in ing there is a really mature team that already runs a kafka cluster",
    "start": "438580",
    "end": "445479"
  },
  {
    "text": "for many years so that was really a great match and from that time on we started our kafka journey and that was",
    "start": "445479",
    "end": "452139"
  },
  {
    "text": "around three years ago now before we go into the demos and the more in-depth",
    "start": "452139",
    "end": "458199"
  },
  {
    "start": "455000",
    "end": "570000"
  },
  {
    "text": "code walkthroughs we would like to show you at least a little bit of the of the overall architecture I - to show you the",
    "start": "458199",
    "end": "465309"
  },
  {
    "text": "components because we're also going to start those components on our machine here so let's start with the end goal in",
    "start": "465309",
    "end": "471939"
  },
  {
    "text": "the ends we would like to send out the customer or notify the customer as soon as possible when we match a price so",
    "start": "471939",
    "end": "480219"
  },
  {
    "text": "that's our end goal the customer can create alerts and we also have advisors",
    "start": "480219",
    "end": "485740"
  },
  {
    "text": "in call centers creating alerts on behalf of customers right because there are still people calling that's fine but",
    "start": "485740",
    "end": "492610"
  },
  {
    "text": "they should be able to do to do this as well and so that's basically the input for the alerts that we store in the",
    "start": "492610",
    "end": "499149"
  },
  {
    "text": "database we have a spring boots micro service there and that's primarily focused yeah listing creating and",
    "start": "499149",
    "end": "507219"
  },
  {
    "text": "deleting alerts on the other end we have the constant stream of data coming in",
    "start": "507219",
    "end": "512318"
  },
  {
    "text": "from the stock markets and if the Amsterdam Stock Exchange closes another one will open right so it's it's the",
    "start": "512319",
    "end": "518860"
  },
  {
    "text": "whole day it's going yeah 24/7 and there is another service that's basically",
    "start": "518860",
    "end": "525970"
  },
  {
    "text": "responsible for putting this on Kafka so that's the first cover topic luckily",
    "start": "525970",
    "end": "531420"
  },
  {
    "text": "zookeeper and the schema registry we will talk a little bit about that later is managed by this team within within ing so we",
    "start": "531420",
    "end": "538930"
  },
  {
    "text": "don't have to worry about that part that's really nice and the heavy lifting is basically done in the matching",
    "start": "538930",
    "end": "544870"
  },
  {
    "text": "surface that's going to match the alerts created in a database by the customers against the constant flow of ticks",
    "start": "544870",
    "end": "551950"
  },
  {
    "text": "coming in from the stock markets and if there is a match we have another service that's responsible for sending out the",
    "start": "551950",
    "end": "558130"
  },
  {
    "text": "actual notification to the customer either via push or SMS so that's in a nutshell really simplified view on our",
    "start": "558130",
    "end": "565120"
  },
  {
    "text": "overall architecture and in the end the customer is notified yeah so let's let's",
    "start": "565120",
    "end": "571270"
  },
  {
    "start": "570000",
    "end": "923000"
  },
  {
    "text": "start a quick demo yeah what team prepared the demo just to align a bit",
    "start": "571270",
    "end": "576550"
  },
  {
    "text": "more on the challenge we have it's not only about processing those sticks that they never stop and you have to extend",
    "start": "576550",
    "end": "581620"
  },
  {
    "text": "betrayed over 40,000 instruments like I mentioned from different stock exchanges around the world so for instance in the",
    "start": "581620",
    "end": "587200"
  },
  {
    "text": "morning we have the Amsterdam Stock Exchange working at 3:00 in the afternoon starts the New York Stock Exchange so this never stops and",
    "start": "587200",
    "end": "593820"
  },
  {
    "text": "continues and we also have almost a million customers in investments and",
    "start": "593820",
    "end": "599020"
  },
  {
    "text": "every customer has multiple investments sometimes and they can create alerts for every specific instruments that are",
    "start": "599020",
    "end": "605320"
  },
  {
    "text": "trading so the real challenge is to process those thousands of ticks per",
    "start": "605320",
    "end": "610990"
  },
  {
    "text": "second and at the same time do the matching with thousands of alerts that exist in real time and we cannot we",
    "start": "610990",
    "end": "617260"
  },
  {
    "text": "cannot get behind because it never stops if you start to get behind one second after a few hours we're really behind",
    "start": "617260",
    "end": "622720"
  },
  {
    "text": "and this how this is extremely important for us is really critical so thanks yeah",
    "start": "622720",
    "end": "629170"
  },
  {
    "text": "so we started basically all the components we showed in the high-level architecture so we have Kafka running",
    "start": "629170",
    "end": "634360"
  },
  {
    "text": "here in docker we have our spring boot applications running in docker we have sue keeper the whole thing is it's",
    "start": "634360",
    "end": "639490"
  },
  {
    "text": "running now so let's pray the demo God says well it's well work we are lazy back-end developers right so we didn't",
    "start": "639490",
    "end": "644950"
  },
  {
    "text": "put a lot of effort in creating a nice UI for you today but we're using a swagger struggle UI this works pretty",
    "start": "644950",
    "end": "650860"
  },
  {
    "text": "fine so this is our front end today and I will play one of our biggest customers",
    "start": "650860",
    "end": "656350"
  },
  {
    "text": "rides it's a customer one two three four five and yeah everybody wants to have an",
    "start": "656350",
    "end": "662410"
  },
  {
    "text": "apple stock right so just looked up the current price of an apple stock one thing to remember is a",
    "start": "662410",
    "end": "669380"
  },
  {
    "text": "stock is more or less uniquely identified by by a symbol and we use",
    "start": "669380",
    "end": "674390"
  },
  {
    "text": "that today so a APL is an Apple stock and it's roughly at $200 at the moment",
    "start": "674390",
    "end": "680300"
  },
  {
    "text": "so let's say the base price is sorry it's $200 and we really would like to",
    "start": "680300",
    "end": "687320"
  },
  {
    "text": "get rich today right so if the price will be $3,000 or more",
    "start": "687320",
    "end": "692840"
  },
  {
    "text": "I would like to receive an SMS right now so I might want to sell it right to get",
    "start": "692840",
    "end": "697910"
  },
  {
    "text": "rich okay so this is of course really simplified but this represents the user",
    "start": "697910",
    "end": "704270"
  },
  {
    "text": "using his mobile phone or the website of course - crane alert so just to show you",
    "start": "704270",
    "end": "711260"
  },
  {
    "text": "that we don't trick you here we created this alerts and it's there if",
    "start": "711260",
    "end": "716990"
  },
  {
    "text": "that's the status created is it visible in the back that's better yeah so now",
    "start": "716990",
    "end": "725570"
  },
  {
    "text": "it's waiting for the stock exchange to open right we don't want to keep you",
    "start": "725570",
    "end": "731839"
  },
  {
    "text": "waiting all day so also for local development we would like to be in control in setting etic",
    "start": "731839",
    "end": "738710"
  },
  {
    "text": "from the market just mimicking to test our functionality so we created actually",
    "start": "738710",
    "end": "745250"
  },
  {
    "text": "a spring boot command line starter that's we give some input so it's a JSON",
    "start": "745250",
    "end": "751430"
  },
  {
    "text": "file we say for an Apple stock this is now the price and we were really lucky",
    "start": "751430",
    "end": "756620"
  },
  {
    "text": "it's more than $3,000 at the moment so we're going to make some money today but basically what we would like to do is",
    "start": "756620",
    "end": "762170"
  },
  {
    "text": "now send the stick to two Kafka right and to start a whole matching process and in the end would like to receive the",
    "start": "762170",
    "end": "769010"
  },
  {
    "text": "notification so let's see if that will work so let's do it should start up so",
    "start": "769010",
    "end": "780290"
  },
  {
    "text": "the spring bootie application will start up publish the thing on Kafka and you shut down it's not a web application",
    "start": "780290",
    "end": "785960"
  },
  {
    "text": "it's just a simple command line ringing yeah",
    "start": "785960",
    "end": "791930"
  },
  {
    "text": "so let's see there is it's in real time",
    "start": "791930",
    "end": "798750"
  },
  {
    "text": "right so we published a tick on the market there wasn't match because I wanted to have a notification it reaches",
    "start": "798750",
    "end": "805290"
  },
  {
    "text": "the price of a little bit more than 3000 euro so now the customers is notified so this in a nutshell shows basically the",
    "start": "805290",
    "end": "812670"
  },
  {
    "text": "whole demo and I would like to restart now for the for the next part right",
    "start": "812670",
    "end": "819300"
  },
  {
    "text": "yeah so let's go a bit about because this is it's really a presentation that",
    "start": "819300",
    "end": "824339"
  },
  {
    "text": "we want to show you how we did it in the code and how we leveraged Kafka so we're going to show some code right now tim is",
    "start": "824339",
    "end": "829980"
  },
  {
    "text": "restarting the whole engine because for this demo he simulated 1:1 alert but we",
    "start": "829980",
    "end": "835589"
  },
  {
    "text": "do have like we do have a simulation here that we are constantly generating ticks like many thousands of ticks per",
    "start": "835589",
    "end": "842430"
  },
  {
    "text": "second of course it's just a Macbook here but it does the trick because Kafka is really lightweight in",
    "start": "842430",
    "end": "847560"
  },
  {
    "text": "that sense and we're start we're going to start generating a few thousands of ticks and at the same time we're going",
    "start": "847560",
    "end": "852690"
  },
  {
    "text": "to start creating alerts using an API and we're going to show you how we monitor more or less and how we",
    "start": "852690",
    "end": "858930"
  },
  {
    "text": "integrate Kafka to get the this data from the applications and and we can",
    "start": "858930",
    "end": "864839"
  },
  {
    "text": "have a like a dashboard where we can see everything we really kind of observability over what's going on yeah",
    "start": "864839",
    "end": "873930"
  },
  {
    "text": "it's a bit slow but we're gonna get there so let's imagine one thing I need",
    "start": "873930",
    "end": "879180"
  },
  {
    "text": "to tell you so when there's a tick in the stock exchange it's just the data it's just a tick that says Apple stock",
    "start": "879180",
    "end": "884550"
  },
  {
    "text": "is ten ten dollars and at this exactly time so that's what you got you get but",
    "start": "884550",
    "end": "889950"
  },
  {
    "text": "this is not really useful for us you have to understand that we have to ingest that data but we have to make sense of that data we have business",
    "start": "889950",
    "end": "896190"
  },
  {
    "text": "people working all the time with with the customers and watching the stock",
    "start": "896190",
    "end": "901290"
  },
  {
    "text": "market and doing the how the planning and our internal systems they need to make sense of that data so we need to",
    "start": "901290",
    "end": "907320"
  },
  {
    "text": "basically join some data some metadata from our internal systems to that tick so that tick makes sense for our our",
    "start": "907320",
    "end": "913980"
  },
  {
    "text": "internal systems so that's the first step we need to do and this is work",
    "start": "913980",
    "end": "920300"
  },
  {
    "text": "yeah so basically we connect to the stock exchange we start to start receiving this constant flow of ticks",
    "start": "922870",
    "end": "928940"
  },
  {
    "start": "923000",
    "end": "1078000"
  },
  {
    "text": "from from the stock exchange and and we",
    "start": "928940",
    "end": "935360"
  },
  {
    "text": "do for instance let's let's see a little bit how we do the monitoring first that but and we need first thing we need to",
    "start": "935360",
    "end": "941779"
  },
  {
    "text": "do because we need to be really long time we cannot get behind we cannot start to lag behind the first thing is",
    "start": "941779",
    "end": "948260"
  },
  {
    "text": "to really be on top of the time so when there is a trait there is a time stamp on the trade on the stock exchange",
    "start": "948260",
    "end": "953269"
  },
  {
    "text": "when we ingest that tick we want to immediately know how much behind we are are we one second behind I read three",
    "start": "953269",
    "end": "958579"
  },
  {
    "text": "seconds behind that's the first step and because we use spring boot we okay we",
    "start": "958579",
    "end": "964339"
  },
  {
    "text": "took a look investigated micrometer was a really good match for us to do that because it's really well integrated with",
    "start": "964339",
    "end": "969740"
  },
  {
    "text": "spring boot and then we we decided to use some micrometer to do that and",
    "start": "969740",
    "end": "977170"
  },
  {
    "text": "micrometer is a library it's it's like a cell 4j as you know it and we also want",
    "start": "977170",
    "end": "983630"
  },
  {
    "text": "to make sense of business matrix it's not only about the instrumentation of environment it's about the business",
    "start": "983630",
    "end": "989600"
  },
  {
    "text": "matrix as well alright so just for to contextualize a little bit more this is more or less than an example here you",
    "start": "989600",
    "end": "996200"
  },
  {
    "text": "see number one is when the trade is it happens on the stock market number two is when we receive the tea can we ingest",
    "start": "996200",
    "end": "1002589"
  },
  {
    "text": "and we put the wrought tick as it is on the stock market in Kafka but now we",
    "start": "1002589",
    "end": "1007660"
  },
  {
    "text": "need to make sense of that tick so we need to take out the metadata from our internal systems and and join that date",
    "start": "1007660",
    "end": "1013089"
  },
  {
    "text": "that data and that's the stock code metadata here that you see is the data that actually our business people",
    "start": "1013089",
    "end": "1019240"
  },
  {
    "text": "maintain for over 40,000 instruments that we trade on our platform so the first thing we do is now that the data",
    "start": "1019240",
    "end": "1025540"
  },
  {
    "text": "is in the Kafka topic here when we have another topic that's fed by other systems and update by the business",
    "start": "1025540",
    "end": "1031780"
  },
  {
    "text": "people whenever there is an update it automatically picks up and now we need to join this data and then we produce to",
    "start": "1031780",
    "end": "1038168"
  },
  {
    "text": "a third topic we're now applications internal applications can read that topic because now it makes sense the",
    "start": "1038169",
    "end": "1043928"
  },
  {
    "text": "data that is there can be properly ingest by our systems and they can make sense of that data and of course then we",
    "start": "1043929",
    "end": "1050440"
  },
  {
    "text": "go to the match once we do that we do the match because now we can do the match because data makes sense we can associate that",
    "start": "1050440",
    "end": "1056180"
  },
  {
    "text": "this torment with internal instruments we do the match with the thousands of",
    "start": "1056180",
    "end": "1061670"
  },
  {
    "text": "alerts created by the customers for every tick and that's the big challenge here remember it's 12,000 per second",
    "start": "1061670",
    "end": "1068270"
  },
  {
    "text": "sometimes with thousands of alerts right this needs to be really good and when the match happens we send the alert to",
    "start": "1068270",
    "end": "1075920"
  },
  {
    "text": "the customer right let me I'm gonna go to the join now and",
    "start": "1075920",
    "end": "1082460"
  },
  {
    "start": "1078000",
    "end": "1253000"
  },
  {
    "text": "then I'm going to show all the code that of these I just diamond to you guys so let's see how we do the first drink",
    "start": "1082460",
    "end": "1087740"
  },
  {
    "text": "Africa has this concept of a duality between a topic I stream and a table",
    "start": "1087740",
    "end": "1093560"
  },
  {
    "text": "basically every entry in a Kafka topic can have a key and that key can be used to to join with other topics so if you",
    "start": "1093560",
    "end": "1101690"
  },
  {
    "text": "have the same key in multiple topics you can basically do a join this is quite simple and it's quite powerful and what",
    "start": "1101690",
    "end": "1107540"
  },
  {
    "text": "happens to us then is that there's a really important thing here it's Kafka",
    "start": "1107540",
    "end": "1113900"
  },
  {
    "text": "streams or Kafka the CAF declines they run together in the same JVM co-located",
    "start": "1113900",
    "end": "1119510"
  },
  {
    "text": "with your sprint boot application there's a there is a very very big difference if you talk about spark or",
    "start": "1119510",
    "end": "1125570"
  },
  {
    "text": "flink because spark or flink they have their own custom it's managed it's a managed cluster with workers that you",
    "start": "1125570",
    "end": "1131330"
  },
  {
    "text": "deploy and if you if you if you write the streams for that you deploy but then your business application usually",
    "start": "1131330",
    "end": "1137060"
  },
  {
    "text": "separate from that so you have to get the data there's a wired network with Kafka streams on the other side it's",
    "start": "1137060",
    "end": "1142670"
  },
  {
    "text": "running inside the same process so this is the first thing and this is important",
    "start": "1142670",
    "end": "1148430"
  },
  {
    "text": "to realize because we really really low latencies here remember representing thousands of ticks so we need really low",
    "start": "1148430",
    "end": "1154450"
  },
  {
    "text": "really low times so we have the the first stream so we have the right stop",
    "start": "1154450",
    "end": "1159830"
  },
  {
    "text": "code as I explained you cannot make sense of that data is just a tick from the market we have a case stream that's constantly reading that in the",
    "start": "1159830",
    "end": "1166070"
  },
  {
    "text": "application right on the other side we have our metadata that makes sense that's business up visit information",
    "start": "1166070",
    "end": "1171290"
  },
  {
    "text": "from applications and what we do there because this data doesn't change so much because we have 40 40 40 few thousands",
    "start": "1171290",
    "end": "1180020"
  },
  {
    "text": "instruments being there we use a global kt or global k table will read out the",
    "start": "1180020",
    "end": "1185420"
  },
  {
    "text": "data from all the partitions of a Kafka topic and for us and the performance here it doesn't it's really in light-weight for",
    "start": "1185420",
    "end": "1192060"
  },
  {
    "text": "Kafka so it's quite okay and we have all this data also co-located with the application and what what Kafka streams",
    "start": "1192060",
    "end": "1199200"
  },
  {
    "text": "automatically does when you're using the high-level DSL it and you do a global k",
    "start": "1199200",
    "end": "1204210"
  },
  {
    "text": "table it basically creates a rocks DB automatically for you on the on the application side and this rocks to be I",
    "start": "1204210",
    "end": "1210600"
  },
  {
    "text": "always have the most up-to-date data for that specific key so that's automatically you don't have to insert",
    "start": "1210600",
    "end": "1217020"
  },
  {
    "text": "in the rocks to be unless use the processor which is a more low-level API but that's not the case the high level",
    "start": "1217020",
    "end": "1222150"
  },
  {
    "text": "API really gives you basically for free is just a configuration and the rocks DB is extremely performant for SSDs so it",
    "start": "1222150",
    "end": "1229170"
  },
  {
    "text": "does the trick really really well here and then we have this metadata on one side we do a join and we publish to the",
    "start": "1229170",
    "end": "1235440"
  },
  {
    "text": "audit topic right and then we publish to the topic where it makes sense and now we can plug in any applications that we",
    "start": "1235440",
    "end": "1242160"
  },
  {
    "text": "need because now the death data makes sense for internal business so now you can just read that data and and start on",
    "start": "1242160",
    "end": "1249450"
  },
  {
    "text": "making sense of them and then we can do the match for that for instance I'm going to show some code how we do that a",
    "start": "1249450",
    "end": "1255180"
  },
  {
    "start": "1253000",
    "end": "1493000"
  },
  {
    "text": "bit to show you got to understand how it exactly works yeah so let's see first",
    "start": "1255180",
    "end": "1265760"
  },
  {
    "text": "the intercept right the first thing is the monitoring so maybe I do a little bit like this so first thing is how we",
    "start": "1265760",
    "end": "1278640"
  },
  {
    "text": "get the data so how we we get the Kafka data and and put that to be monitored so",
    "start": "1278640",
    "end": "1283740"
  },
  {
    "text": "Kafka provides a very nice interface called metrics report that you can plug",
    "start": "1283740",
    "end": "1290190"
  },
  {
    "text": "in your client you can just create a class for that and there will be a callback that every metric that is from",
    "start": "1290190",
    "end": "1295440"
  },
  {
    "text": "the Kafka client it's really important to understand it's not the broker metric here it's the client metric is what",
    "start": "1295440",
    "end": "1301320"
  },
  {
    "text": "we're running on the owned or on our spring booty applications right so if I have a producer or a stream I can I can",
    "start": "1301320",
    "end": "1307830"
  },
  {
    "text": "use the metrics interceptor and basically what it does for every new metric it calls it calls this method and",
    "start": "1307830",
    "end": "1314940"
  },
  {
    "text": "we think this method we can just inject that data to micrometer and that's how easy it is so now we pass it to micron",
    "start": "1314940",
    "end": "1321940"
  },
  {
    "text": "and then we can configure micrometer to to basically push that data to permit",
    "start": "1321940",
    "end": "1327970"
  },
  {
    "text": "use every minute or every two minutes depending on how how much you needed that data and it's extremely simply",
    "start": "1327970",
    "end": "1333520"
  },
  {
    "text": "simple to integrate no JMX here because I worked a lot of jmx in the past it can be quite cumbersome you can bypass gmx",
    "start": "1333520",
    "end": "1340180"
  },
  {
    "text": "basically you can also you plug-in with two jmx if you want but in Kafka JMX is",
    "start": "1340180",
    "end": "1345640"
  },
  {
    "text": "also an another layer on top of the matrix reporter the matrix bore importer is it is the official matrix from a",
    "start": "1345640",
    "end": "1353890"
  },
  {
    "text": "yamir matrix for Kafka right then we",
    "start": "1353890",
    "end": "1359500"
  },
  {
    "text": "want for every tick we produce we want to calculate that difference in time right we want them to know how how how",
    "start": "1359500",
    "end": "1366070"
  },
  {
    "text": "far it is and then what you can do because we don't want this code to be invasive in our business code or",
    "start": "1366070",
    "end": "1371200"
  },
  {
    "text": "business code this is very complex if we're talking about trading and then there's a lot of rules so what we want",
    "start": "1371200",
    "end": "1377170"
  },
  {
    "text": "to do is to find a way to have this so-called cross-cutting concerns being",
    "start": "1377170",
    "end": "1382480"
  },
  {
    "text": "taken care outside of our business or business quote and what we do here then it's Kafka has has the same as many",
    "start": "1382480",
    "end": "1390670"
  },
  {
    "text": "other api's you can do an interceptor so what will happen here for every tick",
    "start": "1390670",
    "end": "1396400"
  },
  {
    "text": "that's produced it will it will pass through this interceptor in that interceptor you can calculate the time",
    "start": "1396400",
    "end": "1401560"
  },
  {
    "text": "and update the time stamps so we basically know when we have everything monitor monitored",
    "start": "1401560",
    "end": "1407290"
  },
  {
    "text": "let's see how this works work a little bit let's know that's before we go back",
    "start": "1407290",
    "end": "1413200"
  },
  {
    "text": "to that take a look at this stream because it's it makes sense here so now go back to that slide where you see the",
    "start": "1413200",
    "end": "1419080"
  },
  {
    "text": "raw data in the metadata and now we're going to the join right and that's how simple cough cough cough does it",
    "start": "1419080",
    "end": "1425220"
  },
  {
    "text": "basically we create a global K table from the metadata we create a Kafka",
    "start": "1425220",
    "end": "1431020"
  },
  {
    "text": "stream from the ticks and we do a join here and once you do the join you just",
    "start": "1431020",
    "end": "1438010"
  },
  {
    "text": "sent to another topic and that's how simple it is and this happens in real time I'm going to show some statistics",
    "start": "1438010",
    "end": "1444160"
  },
  {
    "text": "of how fast this is not a very interesting thing here it's that Kafka also enables you to externalize that",
    "start": "1444160",
    "end": "1451720"
  },
  {
    "text": "data so it in turn creates a key value store that you can call from an endpoint exposed to an API so if you want the",
    "start": "1451720",
    "end": "1457240"
  },
  {
    "text": "most up-to-date price for a stock you can just call that endpoint and because you're co-located JVM the latest is",
    "start": "1457240",
    "end": "1463360"
  },
  {
    "text": "really it's below milliseconds it's nanoseconds it's extremely fast so here we're doing a lot of things in just a",
    "start": "1463360",
    "end": "1470080"
  },
  {
    "text": "few lines of code right so there's a bit of configuration of course but the actual code it's just this it's written",
    "start": "1470080",
    "end": "1476590"
  },
  {
    "text": "from a key table read from stream joining and publishing to a new topic and at the same time we are exposing",
    "start": "1476590",
    "end": "1482080"
  },
  {
    "text": "this data when we do this line here and now you can do a get it's a hash map",
    "start": "1482080",
    "end": "1488050"
  },
  {
    "text": "kind of a structure you can go get in any symbol unit get that value the most up-to-date value for that let's let's",
    "start": "1488050",
    "end": "1497560"
  },
  {
    "text": "take a look at Agra funnel board where we should to make sense how we can",
    "start": "1497560",
    "end": "1504730"
  },
  {
    "text": "monitor all these so again as I explained that interceptors integrates",
    "start": "1504730",
    "end": "1509860"
  },
  {
    "text": "with micrometer micrometer is configured to sync that matrix every minute or you can of course configure the frequency",
    "start": "1509860",
    "end": "1516880"
  },
  {
    "text": "there and then we have a graph on the board on top of that so we just",
    "start": "1516880",
    "end": "1522520"
  },
  {
    "text": "restarted the whole stack right so we're now mimicking the stock markets up to I think three or four thousand takes a",
    "start": "1522520",
    "end": "1527770"
  },
  {
    "text": "second so just it's it's running and we also mimicking customers creating our",
    "start": "1527770",
    "end": "1533020"
  },
  {
    "text": "loads on the fly right so we put some load on this thing it's not a data center of course it's just our local",
    "start": "1533020",
    "end": "1538120"
  },
  {
    "text": "mech yes but it will work yeah here on there just an example here on the left",
    "start": "1538120",
    "end": "1543370"
  },
  {
    "text": "side you see how many ticks per second we occur in generating we were generating four thousand and four hundred per second more or less this is",
    "start": "1543370",
    "end": "1550360"
  },
  {
    "text": "something very important for us there is a bandwidth for when you connect to the stock exchange there's a lot of volume",
    "start": "1550360",
    "end": "1555400"
  },
  {
    "text": "so we have to constantly monitor the bandwidth that's being used so we also know the the the traffic the size of the",
    "start": "1555400",
    "end": "1562630"
  },
  {
    "text": "the payload at any single time here's the average size of the messages and",
    "start": "1562630",
    "end": "1568030"
  },
  {
    "text": "here if there is an error anything so we are perfect programming so does",
    "start": "1568030",
    "end": "1573750"
  },
  {
    "text": "that's fine but if there is an error e to show them if it starts do these sections and things did will show",
    "start": "1573750",
    "end": "1579490"
  },
  {
    "text": "they're here it's just a local environment of course there are on the left side you can see that alerts are",
    "start": "1579490",
    "end": "1585610"
  },
  {
    "text": "being created all the time here it's a slow process because let's let's put more effort on the ticks in the",
    "start": "1585610",
    "end": "1591070"
  },
  {
    "text": "presentation because it makes more sense and we generate alerts but they match all the processes running in all the",
    "start": "1591070",
    "end": "1596320"
  },
  {
    "text": "micro serves is the whole structure is running and you can see here that you can basically monitor remember 1 2 2 4 5",
    "start": "1596320",
    "end": "1602170"
  },
  {
    "text": "so basically here you can see exactly the time it takes between those steps of course the first step here is taking",
    "start": "1602170",
    "end": "1608290"
  },
  {
    "text": "zero milliseconds now because it's local and then it's but in a real scenario",
    "start": "1608290",
    "end": "1613690"
  },
  {
    "text": "this takes a few milliseconds and between this for instance when we do the",
    "start": "1613690",
    "end": "1618910"
  },
  {
    "text": "Rorty congestion which taking 6 milliseconds we do the match is another 126 milliseconds and then we finally",
    "start": "1618910",
    "end": "1625630"
  },
  {
    "text": "send the alert and the total time here to send an alert it's like 50 milliseconds or so it's extremely",
    "start": "1625630",
    "end": "1631780"
  },
  {
    "text": "performant and for the volume of data and and what we are doing here in the",
    "start": "1631780",
    "end": "1637030"
  },
  {
    "text": "real time of course in the real production environment we have more or less 10 seconds 10 milliseconds Leyton's",
    "start": "1637030",
    "end": "1642280"
  },
  {
    "text": "between our or application servers and our infrastructure broker so you can add",
    "start": "1642280",
    "end": "1647650"
  },
  {
    "text": "that time around there to have an idea but it's really around 100 200",
    "start": "1647650",
    "end": "1652930"
  },
  {
    "text": "milliseconds in average even in the real system right and yeah that's basically",
    "start": "1652930",
    "end": "1658900"
  },
  {
    "text": "it here you can also see the the percentiles of the performance of the",
    "start": "1658900",
    "end": "1664030"
  },
  {
    "text": "creation of alerts in the api's right no",
    "start": "1664030",
    "end": "1671140"
  },
  {
    "text": "I think it's back to you and to show bit",
    "start": "1671140",
    "end": "1676900"
  },
  {
    "start": "1673000",
    "end": "1788000"
  },
  {
    "text": "about our develop environment exactly yeah so this is quite a fun stuff right",
    "start": "1676900",
    "end": "1682510"
  },
  {
    "text": "after streams Kafka joins but yeah how to start right so I we would like to",
    "start": "1682510",
    "end": "1688480"
  },
  {
    "text": "take you back let's say 3 years ago where did we start what were the pitfalls for us what did we learn",
    "start": "1688480",
    "end": "1693940"
  },
  {
    "text": "so maybe you got too inspired by our talk and go back to work on Monday and",
    "start": "1693940",
    "end": "1699340"
  },
  {
    "text": "would like to start to try out Kafka where do you start right so that's what we would like to do discuss of course",
    "start": "1699340",
    "end": "1705790"
  },
  {
    "text": "within ing a calf recluse is running on tests and and therefore fireman's but yeah let's",
    "start": "1705790",
    "end": "1711270"
  },
  {
    "text": "say if Marcus is putting a lot of ticks on a topic I might receive them as well so we're constantly stepping on each",
    "start": "1711270",
    "end": "1717750"
  },
  {
    "text": "other's toes so at some point we decided okay let's run a small calf cluster locally it can be just one broker that",
    "start": "1717750",
    "end": "1723210"
  },
  {
    "text": "that's fine to start with but at least we are basically both in control of testing our own features and developing",
    "start": "1723210",
    "end": "1729600"
  },
  {
    "text": "them and get feedback fast so in the beginning we started out with creating our own dr. Kafka images later on the",
    "start": "1729600",
    "end": "1737220"
  },
  {
    "text": "confluent the complete commercially behind the Kafka nowadays provided really nice docker images so we replaced",
    "start": "1737220",
    "end": "1743460"
  },
  {
    "text": "all our custom ones with with with those from confluence and they were maintaining it and it's also really nice",
    "start": "1743460",
    "end": "1749130"
  },
  {
    "text": "because when the team within ING updates the clusters we can update our docker",
    "start": "1749130",
    "end": "1754440"
  },
  {
    "text": "images and we are on the same page basically and that really helps us to move on so we don't have to care about",
    "start": "1754440",
    "end": "1760890"
  },
  {
    "text": "those images yeah the command line runner that's something we already discussed so we can",
    "start": "1760890",
    "end": "1767760"
  },
  {
    "text": "for sticks we can force matches to basically test certain parts of the flows and this whole thing basically",
    "start": "1767760",
    "end": "1774600"
  },
  {
    "text": "grew into a lab project that we are still using in ing ourselves to try out",
    "start": "1774600",
    "end": "1779730"
  },
  {
    "text": "new stuff of reading new versions of micrometer string boat and then in the end bring it back to to the real project",
    "start": "1779730",
    "end": "1786330"
  },
  {
    "text": "within ninety so that's really cool so maybe it's time to show some more code",
    "start": "1786330",
    "end": "1791520"
  },
  {
    "start": "1788000",
    "end": "2126000"
  },
  {
    "text": "rights so we would like to focus a bit on on spring boots and also a spring",
    "start": "1791520",
    "end": "1797820"
  },
  {
    "text": "Kafka of course so let me quickly show you the dopest file and make it a little",
    "start": "1797820",
    "end": "1808530"
  },
  {
    "text": "bit bigger it's quite a big one right because we really quite a lot of stuff here we are running a Kafka we are",
    "start": "1808530",
    "end": "1815790"
  },
  {
    "text": "running a schema registry that can be really a lifesaver because a schema is",
    "start": "1815790",
    "end": "1821790"
  },
  {
    "text": "basically a contract between the producer and the consumer so you cannot basically publish data that's not in the",
    "start": "1821790",
    "end": "1829290"
  },
  {
    "text": "correct format of course you can still send the wrong data but at least it's it's it's matching the contract that's",
    "start": "1829290",
    "end": "1835740"
  },
  {
    "text": "basically defined in an effort schema we can probably do an all talk on that as well",
    "start": "1835740",
    "end": "1840990"
  },
  {
    "text": "but that's really a lifesaver for us in in production so we run the confluent schema registry here we have a Kafka",
    "start": "1840990",
    "end": "1848220"
  },
  {
    "text": "manager to see locally the the topics what data is flowing over those topics so we get a feeling what's going on in",
    "start": "1848220",
    "end": "1855480"
  },
  {
    "text": "this case we're using a Postgres database to store the alerts in and we'd authorized all our spring good",
    "start": "1855480",
    "end": "1860909"
  },
  {
    "text": "applications which is pretty straightforward so yeah this is where we",
    "start": "1860909",
    "end": "1867090"
  },
  {
    "text": "started out for local developments we're really big fans of spring Spring boots",
    "start": "1867090",
    "end": "1872720"
  },
  {
    "text": "and we actually started out without using a spring Kafka in the in the beginning just to learn the Kafka API is",
    "start": "1872720",
    "end": "1879690"
  },
  {
    "text": "themselves can be a bit low level but it's quite nice to know exactly what's going on under the hood before you might",
    "start": "1879690",
    "end": "1886590"
  },
  {
    "text": "want to start with with spring caca so let's take a look maybe at one of the applications let's use the",
    "start": "1886590",
    "end": "1893720"
  },
  {
    "text": "customer-facing web application that offers the REST API so FA rest controller and at some point",
    "start": "1893720",
    "end": "1903870"
  },
  {
    "text": "we would like to to send offense on Kafka right so when a customer creates an alert or the leads on alert we",
    "start": "1903870",
    "end": "1910470"
  },
  {
    "text": "basically sent out offence on Kafka topic so we have a customer that's yeah",
    "start": "1910470",
    "end": "1917059"
  },
  {
    "text": "let's let's go to the code that talks more easily we quickly look it up maybe",
    "start": "1917059",
    "end": "1926280"
  },
  {
    "text": "it's good to show you at least one F Rho schema and let's say this is the effort",
    "start": "1926280",
    "end": "1933330"
  },
  {
    "text": "schema of of an alert sorry for a create defense so we say an alert has been",
    "start": "1933330",
    "end": "1940380"
  },
  {
    "text": "created by this customer it's for this symbol and it has this price and it has a base price that's a an event that goes",
    "start": "1940380",
    "end": "1946950"
  },
  {
    "text": "on on Kafka out of this FR schema we can",
    "start": "1946950",
    "end": "1952650"
  },
  {
    "text": "generate automatically java calls and we have an object to to send out and then of course we need we need a producer",
    "start": "1952650",
    "end": "1958890"
  },
  {
    "text": "because we need to push this data on Kafka and that's where spring Kafka can can come in of course we have to",
    "start": "1958890",
    "end": "1966600"
  },
  {
    "text": "configure configure it so if you're",
    "start": "1966600",
    "end": "1972330"
  },
  {
    "text": "using a spring Kafka you can leverage the out configuration so we say we have a sterilizer for the forky so in this case",
    "start": "1972330",
    "end": "1979890"
  },
  {
    "text": "it can be a PL for the for the for the stock and we have a serial Iser to",
    "start": "1979890",
    "end": "1986190"
  },
  {
    "text": "serialize the data on Kafka right because of Kafka everything is just bytes and all the other ends we have a consumer that's consuming the data and",
    "start": "1986190",
    "end": "1992850"
  },
  {
    "text": "that's just the other way around it's the DC realizers and we point to the schema registry so we know about about",
    "start": "1992850",
    "end": "1998700"
  },
  {
    "text": "the contract between the consumer and the producer and that's basically the basic basic you need to to get started",
    "start": "1998700",
    "end": "2005860"
  },
  {
    "text": "if you're familiar with what spring you might know a JDBC template",
    "start": "2005860",
    "end": "2011899"
  },
  {
    "text": "rest template so also here spring Kafka provides you with a Kafka template and",
    "start": "2011899",
    "end": "2018440"
  },
  {
    "text": "that's just really convenient to sense in this case a alert created defense or",
    "start": "2018440",
    "end": "2024019"
  },
  {
    "text": "alert the little defense on to a Kafka topic so this is more or less all you",
    "start": "2024019",
    "end": "2029240"
  },
  {
    "text": "need to create something on a Kafka topic so we basically say hey Kafka template send this event to a topic and",
    "start": "2029240",
    "end": "2037010"
  },
  {
    "text": "and that's it underneath spring Kafka will take care",
    "start": "2037010",
    "end": "2042080"
  },
  {
    "text": "of creating any action the actual Kafka producers to basically really send out",
    "start": "2042080",
    "end": "2047510"
  },
  {
    "text": "the data to Kafka yeah then maybe the consuming part and this is really a",
    "start": "2047510",
    "end": "2055820"
  },
  {
    "text": "really simplified example of a consumer you just annotate a method with a cough",
    "start": "2055820",
    "end": "2060858"
  },
  {
    "text": "knish ler you can see this as an event listener yeah you receive an alert and",
    "start": "2060859",
    "end": "2066349"
  },
  {
    "text": "in this case we just count the number of incoming create defense or delete",
    "start": "2066349",
    "end": "2073398"
  },
  {
    "text": "defense with micrometer it's really simplified example right but you this shows how you can consume an offense",
    "start": "2073399",
    "end": "2079730"
  },
  {
    "text": "from Kafka so you basically say this is the topic this is the consumer group and",
    "start": "2079730",
    "end": "2084950"
  },
  {
    "text": "I would like to have three concurrent Kafka consumers underneath so spring",
    "start": "2084950",
    "end": "2090589"
  },
  {
    "text": "Kafka will spin up basically three different threads consuming the topic together in a group you can leverage",
    "start": "2090589",
    "end": "2098510"
  },
  {
    "text": "payload validation that's not part of spring Kafka but it's just there in in spring so you can also of course there's",
    "start": "2098510",
    "end": "2105319"
  },
  {
    "text": "another input to your application right so you should be able to further incoming data although its might matching the schema it can still contain",
    "start": "2105319",
    "end": "2114670"
  },
  {
    "text": "data that you would like to keep out of your application so you can leverage that as well yeah I think that's more or",
    "start": "2114670",
    "end": "2122319"
  },
  {
    "text": "less in a really short explanation what you can do at this is recover so",
    "start": "2122319",
    "end": "2127869"
  },
  {
    "start": "2126000",
    "end": "2631000"
  },
  {
    "text": "simplified version to be more indeed attic and understand but I think that those are the key components yeah let's",
    "start": "2127869",
    "end": "2133989"
  },
  {
    "text": "talk a little bit about the lessons learned right first thing is that we really really like docker compose for a",
    "start": "2133989",
    "end": "2141789"
  },
  {
    "text": "local developer I think most developers these days use it it's really in this case it's really recommended and basically the main difference between",
    "start": "2141789",
    "end": "2147609"
  },
  {
    "text": "using like confluence CLI tools or or running it directly from the docker line",
    "start": "2147609",
    "end": "2153430"
  },
  {
    "text": "is that you it's you can do the configuration on the compost file so if you need to do some configuration on the",
    "start": "2153430",
    "end": "2158470"
  },
  {
    "text": "broker that needs to be shared with fellow developers is just pushed normally with your source code to the repository this is really key for us so",
    "start": "2158470",
    "end": "2165400"
  },
  {
    "text": "for instance if you want to do exactly one semantics you need to do configuration on the broker side so you",
    "start": "2165400",
    "end": "2170440"
  },
  {
    "text": "can just configure specifically that docker compose 5 and of course when you're a fellow developers check out the",
    "start": "2170440",
    "end": "2176019"
  },
  {
    "text": "code and start working it will be working as well for them so also you share that configuration for the infrastructure part it's really really",
    "start": "2176019",
    "end": "2183880"
  },
  {
    "text": "important and we've seen this a lot that if you're a sprint developer and you start working with CAFTA of course you",
    "start": "2183880",
    "end": "2189759"
  },
  {
    "text": "have to you can use the spring API for that but really it's really important to understand what Kafka does behind the",
    "start": "2189759",
    "end": "2195970"
  },
  {
    "text": "scenes Kafka has it's a distributed system right it's built to be able to produce a booted systems it has all the",
    "start": "2195970",
    "end": "2202119"
  },
  {
    "text": "concepts of partitioning you need to understand how that works because when you configure your clients or producers",
    "start": "2202119",
    "end": "2207730"
  },
  {
    "text": "it's related to that how many partitions you have how you're going to handle that how much can you scale your",
    "start": "2207730",
    "end": "2214869"
  },
  {
    "text": "microservices to parallelize the processing all these you need to keep in mind and this is if you go directly for",
    "start": "2214869",
    "end": "2221799"
  },
  {
    "text": "spring Kafka you might lose that part and then you might have strange strange",
    "start": "2221799",
    "end": "2227109"
  },
  {
    "text": "things were happening in production or that find that so this is really important if we're handling it's",
    "start": "2227109",
    "end": "2232450"
  },
  {
    "text": "something really key if we're not using Avro it's very easy for a producer to push an invalid message to the topic and",
    "start": "2232450",
    "end": "2239769"
  },
  {
    "text": "then when you consume consumes that message you start to get a lot of exceptions and cough gets extremely fast so you're gonna have a",
    "start": "2239769",
    "end": "2245550"
  },
  {
    "text": "really fast log full of exceptions if you have that case and of course you have to configure to avoid that in Avro",
    "start": "2245550",
    "end": "2253080"
  },
  {
    "text": "it's really interesting here because it if the producer tries to push an invalid message it it gives an error immediately",
    "start": "2253080",
    "end": "2258870"
  },
  {
    "text": "so it doesn't end up in your topic it really helps on consuming on the other side and sanitizing what we are",
    "start": "2258870",
    "end": "2264420"
  },
  {
    "text": "ingesting on that side a lifesaver because we had issues that in the couple of seconds the whole disk was was full",
    "start": "2264420",
    "end": "2270660"
  },
  {
    "text": "right because of the law it's trying to consume the message it cannot do anything with it because it doesn't",
    "start": "2270660",
    "end": "2276020"
  },
  {
    "text": "understand how to deserialize it you just end up and you should be able to recover from that and do the exactly",
    "start": "2276020",
    "end": "2283500"
  },
  {
    "text": "there's no soever handlers that you can hook up but anyway it's important that try to avoid the producer to actually",
    "start": "2283500",
    "end": "2289890"
  },
  {
    "text": "producing valid messages and I will give you that monitoring is extremely important of course in our applications",
    "start": "2289890",
    "end": "2295680"
  },
  {
    "text": "this day is special you're talking about the bank trading system so we need to be on top of this micro materially integrates really well with spring boot",
    "start": "2295680",
    "end": "2303930"
  },
  {
    "text": "unfortunately micro meter provides out-of-the-box matrix for Kafka only for CAFTA consumers it doesn't provide for",
    "start": "2303930",
    "end": "2309540"
  },
  {
    "text": "producers and streams but as I showed here earlier you can use the matrix reporter to do that so using the matrix",
    "start": "2309540",
    "end": "2316260"
  },
  {
    "text": "reporter you can just easily integrate as well thank you very much this is",
    "start": "2316260",
    "end": "2324420"
  },
  {
    "text": "really interesting for us Kafka clients are backwards compatible with brokers this is as a developer I really love",
    "start": "2324420",
    "end": "2330150"
  },
  {
    "text": "that because when like a new version of Kafka let's last week they release a two two two two one and even if my broker is",
    "start": "2330150",
    "end": "2337830"
  },
  {
    "text": "in version 2.0 I can still take my client side and upgrade the language because Kafka clients are I are clever",
    "start": "2337830",
    "end": "2344610"
  },
  {
    "text": "enough to downgrade to the specific protocol of the oldest version so it's usually backwards compatible of course",
    "start": "2344610",
    "end": "2350280"
  },
  {
    "text": "there's a limit there if you try to use Kafka zero wait with the client to point to it will not work sorry but in most",
    "start": "2350280",
    "end": "2355770"
  },
  {
    "text": "cases you can do this upgrade so basically on the clients I don't know your application side as a developer",
    "start": "2355770",
    "end": "2361020"
  },
  {
    "text": "that what we matter most for us we can basically upgrade and get the benefits",
    "start": "2361020",
    "end": "2366120"
  },
  {
    "text": "of the new because the release cycle is really constant especially for user streams there's a lot of new and",
    "start": "2366120",
    "end": "2371760"
  },
  {
    "text": "interesting things being developed all the time and and this really helps so we can",
    "start": "2371760",
    "end": "2377010"
  },
  {
    "text": "really update the clients without worrying too much because it's backwards-compatible Kafka streams provides high life for streams a DSL and",
    "start": "2377010",
    "end": "2386070"
  },
  {
    "text": "also a low-level API to processors in our experience 95% of the time you don't",
    "start": "2386070",
    "end": "2391380"
  },
  {
    "text": "need the low-level processor unless you really have to want to have fine control",
    "start": "2391380",
    "end": "2396450"
  },
  {
    "text": "really small like control a lot what you do if the ticks on the client side but",
    "start": "2396450",
    "end": "2401520"
  },
  {
    "text": "most of the cases you can just do with the high level API and this is quite interesting you have the concept of K",
    "start": "2401520",
    "end": "2407490"
  },
  {
    "text": "tables global K tables interactive queries it's really interesting that you take a look at that it really simplifies your model we used a lot in the past",
    "start": "2407490",
    "end": "2415200"
  },
  {
    "text": "like memory grids because of the performance we need I don't know if you're familiar with like gem Phi or or",
    "start": "2415200",
    "end": "2420240"
  },
  {
    "text": "extreme scale from from IBM or coherence from go it's a distributed memory grid",
    "start": "2420240",
    "end": "2425430"
  },
  {
    "text": "but basically we can replace that with the CAF with the kafka structures here",
    "start": "2425430",
    "end": "2430620"
  },
  {
    "text": "and this is again very interesting for us because it simplifies our programming model a lot and we really want to focus",
    "start": "2430620",
    "end": "2437940"
  },
  {
    "text": "on business and this helps it really helps when we simplify Kafka by de for",
    "start": "2437940",
    "end": "2443190"
  },
  {
    "text": "creates our rocks to be when you create a K table or a global K table on the client side it does this for you out of",
    "start": "2443190",
    "end": "2449160"
  },
  {
    "text": "the box automatically you just have to do the configurations for that and rocks DB is extremely performant for for SSDs",
    "start": "2449160",
    "end": "2456330"
  },
  {
    "text": "so if we're deploying to unknown assess the environment be careful you should try to deploy your client to an SSD",
    "start": "2456330",
    "end": "2461760"
  },
  {
    "text": "storage because they're rocks the B's really built for that they F sink on the low level it's it's coordinated to work",
    "start": "2461760",
    "end": "2467280"
  },
  {
    "text": "with SSDs so you have to be that entire to be on that in mind if we have",
    "start": "2467280",
    "end": "2473160"
  },
  {
    "text": "problems with our streams there is a really nice feature it's a describe you can do streams dot describe and what it",
    "start": "2473160",
    "end": "2479490"
  },
  {
    "text": "does it's going to print in your a lot the whole topology that it's built from the streams it really helps you to troubleshoot you understand how these",
    "start": "2479490",
    "end": "2485400"
  },
  {
    "text": "streams are being merged and how the things are flow in the system because the high level DSL it puts some magic in",
    "start": "2485400",
    "end": "2491610"
  },
  {
    "text": "there so sometimes you don't understand but it's extremely easy so doing development using the scribe really helps and this is really amazing is the",
    "start": "2491610",
    "end": "2499530"
  },
  {
    "text": "processing guarantee exactly once configuration that you can do in Kafka streams it's a single configuration that",
    "start": "2499530",
    "end": "2504570"
  },
  {
    "text": "gives you exactly over distributed environment remember you have multiple Microsoft's instance",
    "start": "2504570",
    "end": "2509780"
  },
  {
    "text": "we are talking about the scalability Horizonte scalability multiple instances all in all those nodes and you have that",
    "start": "2509780",
    "end": "2517460"
  },
  {
    "text": "I think Kafka was it's probably the only one so far I think flink or spark was trying to do that but it was exactly it",
    "start": "2517460",
    "end": "2524360"
  },
  {
    "text": "was at least once and not exactly once but kapha gives you that to a configuration if you need of course we",
    "start": "2524360",
    "end": "2531470"
  },
  {
    "text": "also recommend you to take a look on the Kafka topology you can do big topologies when I mean topologies when you join",
    "start": "2531470",
    "end": "2536810"
  },
  {
    "text": "multiple streams so have multiple topics you're doing joins and joins but if you make it too big you have to remember",
    "start": "2536810",
    "end": "2542540"
  },
  {
    "text": "that that stream is a unit of deployment so if you need to resort to scale if you need to break up that if you have a",
    "start": "2542540",
    "end": "2547700"
  },
  {
    "text": "large topology have to rewrite code if you make it smaller topology sink to another topic and then start another",
    "start": "2547700",
    "end": "2553070"
  },
  {
    "text": "topology from the new topic this is really lightweight in Kafka it gives you more flexibility but you have to",
    "start": "2553070",
    "end": "2559130"
  },
  {
    "text": "evaluate that case-by-case yeah and that's it I think we have some time for questions maybe maybe one thing",
    "start": "2559130",
    "end": "2566420"
  },
  {
    "text": "to address because this is really a quite technical talk but but also the business now realized that we can do things in real time or at least near",
    "start": "2566420",
    "end": "2573440"
  },
  {
    "text": "real time right I mean this is not a really it's an important part of our applications but it's not let's say",
    "start": "2573440",
    "end": "2578900"
  },
  {
    "text": "mission-critical but now they see that we prove to do this that there are also more business opportunities to deliver",
    "start": "2578900",
    "end": "2585260"
  },
  {
    "text": "cool features to our customers using Kafka so that's another lessons learned from this project yeah good point like",
    "start": "2585260",
    "end": "2592340"
  },
  {
    "text": "you understand that when we get those sticks we sink we sink to cough and cough comics it's very easy to plug in",
    "start": "2592340",
    "end": "2597860"
  },
  {
    "text": "new application the same stream is very lightweight for Kafka so basically that data can be reused if you want to do",
    "start": "2597860",
    "end": "2603730"
  },
  {
    "text": "anything you want to do like add business intelligence if you want to do machine learning on top of the data so",
    "start": "2603730",
    "end": "2608810"
  },
  {
    "text": "Kafka really makes it very easy and it really helps us now to develop new features I think that's it I don't know",
    "start": "2608810",
    "end": "2616220"
  },
  {
    "text": "if it's time for questions we are at the boot after the presentation we have some ice ng kafka stickers so come and grab them",
    "start": "2616220",
    "end": "2623140"
  },
  {
    "text": "and you",
    "start": "2623140",
    "end": "2628050"
  }
]
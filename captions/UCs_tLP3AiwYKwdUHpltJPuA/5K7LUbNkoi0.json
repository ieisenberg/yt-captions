[
  {
    "text": "[Music]",
    "start": "2540",
    "end": "9880"
  },
  {
    "text": "so I'm going to talk about elastic search um it started as a talk about the",
    "start": "9880",
    "end": "15200"
  },
  {
    "text": "apis and how we evolve the apis in nastic search but then I found that a big reason why the apis are so",
    "start": "15200",
    "end": "21000"
  },
  {
    "text": "successful in nastic search is that you know how does it work also in the internal systems of it like how does",
    "start": "21000",
    "end": "26880"
  },
  {
    "text": "elch Works internally and how it exposes and how how it Works internally and then through that what what does it reflects",
    "start": "26880",
    "end": "34079"
  },
  {
    "text": "when it comes to using the apis themselves um and I always like the to give the more technical talks here so it",
    "start": "34079",
    "end": "40239"
  },
  {
    "text": "will be a bit more technical now um so let's start elastic search",
    "start": "40239",
    "end": "45280"
  },
  {
    "text": "what does it do um by the way how many people here use elastic search how many",
    "start": "45280",
    "end": "51360"
  },
  {
    "text": "people here use Lucine okay cool um",
    "start": "51360",
    "end": "57519"
  },
  {
    "text": "so um elastic search what is it it's a real- Time distributed search and",
    "start": "57519",
    "end": "63280"
  },
  {
    "text": "analytics system very very simple um we're not going to exactly talk about",
    "start": "63280",
    "end": "70360"
  },
  {
    "text": "how to use it uh we're going to talk about how does it work in practice and through that we're going to understand",
    "start": "70360",
    "end": "75759"
  },
  {
    "text": "why the features that we expose in as search how do they work and why is it so beneficial to some use cases obviously",
    "start": "75759",
    "end": "81159"
  },
  {
    "text": "that you try to uh do with your data so obviously the first step that uh",
    "start": "81159",
    "end": "86439"
  },
  {
    "text": "elastic search uh does is to uh make make text searchable right it's a search",
    "start": "86439",
    "end": "92720"
  },
  {
    "text": "engine this is how text looks like right",
    "start": "92720",
    "end": "98119"
  },
  {
    "text": "uh so if I want to go and try to search across that text typically what people do is you know it's in my database",
    "start": "98119",
    "end": "105439"
  },
  {
    "text": "that's great I'll just do a like query and just run it and everything will be okay but that's effectively slow and",
    "start": "105439",
    "end": "112079"
  },
  {
    "text": "inflexible inflexible right it's um it's it has to go and Traverse the full text",
    "start": "112079",
    "end": "118240"
  },
  {
    "text": "in order to try to find matches and it doesn't take relevance into account at all right if one document is",
    "start": "118240",
    "end": "124880"
  },
  {
    "text": "more relevant than another one for my search term I would love to see it appear higher in my search response so",
    "start": "124880",
    "end": "132520"
  },
  {
    "text": "let's take this text and see what a te what a search engine actually does the first step that a search engine does is",
    "start": "132520",
    "end": "139599"
  },
  {
    "text": "it takes the text and breaks it down into tokens or terms um if you're familiar with lucino",
    "start": "139599",
    "end": "145959"
  },
  {
    "text": "anic search this is the effectively the analysis process right take that text and break it somehow into terms that's a",
    "start": "145959",
    "end": "151560"
  },
  {
    "text": "whole big topic obviously language stemming things along those lines comes into play but once it has those terms it",
    "start": "151560",
    "end": "159760"
  },
  {
    "text": "effectively builds uh a table and that table consists of the terms on the left",
    "start": "159760",
    "end": "165640"
  },
  {
    "text": "hand side uh sorted by the way you see that they are effectively sorted and where do they occur occur in",
    "start": "165640",
    "end": "173159"
  },
  {
    "text": "the document uh so uh exactly the the the document IDs that they occur",
    "start": "173159",
    "end": "178720"
  },
  {
    "text": "internally within with within uh the search engine and then how do we execute a",
    "start": "178720",
    "end": "184799"
  },
  {
    "text": "search uh well it's very simple we just go and find the relevant terms that",
    "start": "184799",
    "end": "190400"
  },
  {
    "text": "we're searching for and through them find the relevant documents that matched it this is effectively an inverted index",
    "start": "190400",
    "end": "198599"
  },
  {
    "text": "and this is the wonderful things that people don't necessarily immediately understand what happens in a search",
    "start": "198599",
    "end": "203879"
  },
  {
    "text": "engine uh which is effectively it counts almost everything right like if you",
    "start": "203879",
    "end": "209920"
  },
  {
    "text": "think about a system it counts everything uh uh what is the term frequencies in order for example to do",
    "start": "209920",
    "end": "216200"
  },
  {
    "text": "relevance what is the text length in order to do dock weight which plays uh a role obviously uh a heavy role when it",
    "start": "216200",
    "end": "223000"
  },
  {
    "text": "comes to uh relevancy uh terms position again in order to do things like phrase",
    "start": "223000",
    "end": "229080"
  },
  {
    "text": "queries right find me a query that matches this term next to that term um",
    "start": "229080",
    "end": "234720"
  },
  {
    "text": "and obviously Char offsets in order to do highlighting but inverted index is not",
    "start": "234720",
    "end": "241200"
  },
  {
    "text": "just for search um an inverted index specifically Lucine uh also support",
    "start": "241200",
    "end": "247040"
  },
  {
    "text": "indexing numbers dates which are effectively numbers bullion bullion enams geop points Geo shapes what have",
    "start": "247040",
    "end": "253640"
  },
  {
    "text": "you right I mean you can build a whole ecosystem of uh um a type of data sets",
    "start": "253640",
    "end": "259959"
  },
  {
    "text": "that you have that will play A Part uh in that inverted index and one",
    "start": "259959",
    "end": "265240"
  },
  {
    "text": "interesting aspect that uh that people don't necessarily realize is the fact",
    "start": "265240",
    "end": "270520"
  },
  {
    "text": "that um everything is effectively indexed in Lucine or in elastic search by default so for example if you take a",
    "start": "270520",
    "end": "277479"
  },
  {
    "text": "document that has 100 fields in it all of them are",
    "start": "277479",
    "end": "282759"
  },
  {
    "text": "indexed uh think about taking a database H with a a database table",
    "start": "282759",
    "end": "288560"
  },
  {
    "text": "having a 100 columns and putting an index on all of them that's pretty much right you're not going to do that the",
    "start": "288560",
    "end": "295560"
  },
  {
    "text": "other part that is interesting with the way that a search engine works and inverted index specifically when you do",
    "start": "295560",
    "end": "301600"
  },
  {
    "text": "a search across multiple Fields all of those indexes comes into play That's Another very important aspect of why an",
    "start": "301600",
    "end": "308199"
  },
  {
    "text": "inverted index and why search engine is so fast right it doesn't if you look at typical",
    "start": "308199",
    "end": "313720"
  },
  {
    "text": "databases um and you execute a a query uh against multiple columns not all of",
    "start": "313720",
    "end": "319759"
  },
  {
    "text": "those indexes will come into play maybe one maybe two but that's typically it so",
    "start": "319759",
    "end": "324800"
  },
  {
    "text": "this is another big big reason why when you execute searches on elastic search even complex searches that involves",
    "start": "324800",
    "end": "330280"
  },
  {
    "text": "multiple multiple Fields searches are still extremely",
    "start": "330280",
    "end": "335680"
  },
  {
    "text": "fast but searches is not enough um or you know full Tech search or numeric",
    "start": "335880",
    "end": "341400"
  },
  {
    "text": "searches or something along those lines uh and this is very core to what we believe in elastic search this is not",
    "start": "341400",
    "end": "347720"
  },
  {
    "text": "enough or why we view search as more to be completely honest I think search encompasses within it analytics and the",
    "start": "347720",
    "end": "354800"
  },
  {
    "text": "reason is very simple um imagine uh indexing Twitter yeah very easy example",
    "start": "354800",
    "end": "360960"
  },
  {
    "text": "to Gro um and you're executing some sort of a search let's say go to Amsterdam",
    "start": "360960",
    "end": "366199"
  },
  {
    "text": "and everybody here are profilic uh Twitter users obviously you use the go to Amsterdam hashtag a lot uh and uh you",
    "start": "366199",
    "end": "374000"
  },
  {
    "text": "execute a search and you find a billion documents now you can go and present",
    "start": "374000",
    "end": "379960"
  },
  {
    "text": "those Tweets in a list with a page and you can people can scroll through it but that's not very beneficial right I'm not",
    "start": "379960",
    "end": "386199"
  },
  {
    "text": "going to be able to go and click next next next next trying to understand what's going on you want to present it",
    "start": "386199",
    "end": "392120"
  },
  {
    "text": "in a more digestible manner for example take all of those tweet and show them on a graph so I can see how they tweet over",
    "start": "392120",
    "end": "398680"
  },
  {
    "text": "you know an hour by hour or a minute by minute or something along those lines so this is a big big part with it as a big",
    "start": "398680",
    "end": "406080"
  },
  {
    "text": "big part when it comes to executing to building a good search engine actually providing this",
    "start": "406080",
    "end": "411360"
  },
  {
    "text": "functionality um so how do we do analytics in elastic search um if you remember before we took",
    "start": "411360",
    "end": "418919"
  },
  {
    "text": "terms and map them to Doc IDs right or values and map them to Doc IDs the",
    "start": "418919",
    "end": "424840"
  },
  {
    "text": "actual doc ID that match for analytics we actually need the other side of the",
    "start": "424840",
    "end": "430160"
  },
  {
    "text": "equation we need the ability to map doc IDs to values so as we search in Lucine",
    "start": "430160",
    "end": "435720"
  },
  {
    "text": "for example and Lucine tells us oh this doc ID matched we need to go and now run analytics on top of it some sort of an",
    "start": "435720",
    "end": "442199"
  },
  {
    "text": "aggregation uh and that aggregation will will have to take the doc ID and map it back back to values in order to do that",
    "start": "442199",
    "end": "449039"
  },
  {
    "text": "this is a if you think about it the process of un inverting the inverted Index right exactly taking what it has",
    "start": "449039",
    "end": "454919"
  },
  {
    "text": "and building the opposite of it um today in atic search uh uh the",
    "start": "454919",
    "end": "461919"
  },
  {
    "text": "default behavior is to cach those values in memory uh and uh we call it field",
    "start": "461919",
    "end": "467800"
  },
  {
    "text": "data so this is how we we treat it uh we take all of values cach it into memory to have a very very fast access imagine",
    "start": "467800",
    "end": "474319"
  },
  {
    "text": "executing a search request across a billion documents and as you map them you have",
    "start": "474319",
    "end": "479720"
  },
  {
    "text": "to be able to perform those operations super fast because you're going to do them billion times right gets to a point",
    "start": "479720",
    "end": "485520"
  },
  {
    "text": "where even taking using a regular hashmap it's just too slow to do that and obviously too memory extensive so we",
    "start": "485520",
    "end": "492039"
  },
  {
    "text": "have specific data structures specialized data structures in order to do all of those type of aggregations um just as a side note",
    "start": "492039",
    "end": "499440"
  },
  {
    "text": "there's also another option which is a Lucine feature to store those that data that uninverted data effectively on disk",
    "start": "499440",
    "end": "505560"
  },
  {
    "text": "it's called doc values uh so if you look at typical databases that's a columnar store right storing in a columnar manner",
    "start": "505560",
    "end": "513479"
  },
  {
    "text": "in order to be able to access it if you want on disk so you won't have to Lo load it to memory obviously a bit slower",
    "start": "513479",
    "end": "520120"
  },
  {
    "text": "but you it might be beneficial if you don't have enough memory so as I mentioned data access",
    "start": "520120",
    "end": "526480"
  },
  {
    "text": "from Ram again it's very very fast but also very very important it's in the context of the user's",
    "start": "526480",
    "end": "532480"
  },
  {
    "text": "query so for example imagine providing that Twitter example that I gave and was",
    "start": "532480",
    "end": "537880"
  },
  {
    "text": "showing all the the graph of tweets that you have and putting a text box on the",
    "start": "537880",
    "end": "543320"
  },
  {
    "text": "top so people can as they type for example execute searches and see what matches immediately reflected in the",
    "start": "543320",
    "end": "549760"
  },
  {
    "text": "graphs this is what we're aspiring to right I mean that quick interactions even when you're doing this heavy duty",
    "start": "549760",
    "end": "556160"
  },
  {
    "text": "analytics on top of potentially large volumes of data so it actually bring brings you",
    "start": "556160",
    "end": "563399"
  },
  {
    "text": "into being able to build relevant analytics for each users right if you look at typical ways that",
    "start": "563399",
    "end": "570000"
  },
  {
    "text": "um uh people build analytic systems today they say I'm going to predict what",
    "start": "570000",
    "end": "575480"
  },
  {
    "text": "the user wants and I'm going to build the data structures in order to build that analytics right I'm I I know that",
    "start": "575480",
    "end": "581640"
  },
  {
    "text": "the user might want to do a hashtag so I'll try to find the hashtags within Twitter and maybe index them in one",
    "start": "581640",
    "end": "587399"
  },
  {
    "text": "specific way in order to do that uh maybe geop points maybe something along those lines but then it becomes almost",
    "start": "587399",
    "end": "594079"
  },
  {
    "text": "unmanageable right imagine someone wanting to do a geopoint with a hashtag with a list of uh user IDs in Twitter",
    "start": "594079",
    "end": "603240"
  },
  {
    "text": "that want to do that right and then they want to see the analytics results of it so slowly and slowly it becomes a bit",
    "start": "603240",
    "end": "608959"
  },
  {
    "text": "unmanageable to try to build a very effective and efficient uh analytics engineer to do that and this is",
    "start": "608959",
    "end": "615160"
  },
  {
    "text": "effectively the bread and butter of elastic search right that freedom to slice and dice the data however you want",
    "start": "615160",
    "end": "621040"
  },
  {
    "text": "and being being able to aggregate it that's effectively what we do well so what type of aggregations we call them",
    "start": "621040",
    "end": "627360"
  },
  {
    "text": "aggregations by the way in elasic search uh do we have the typical metrics that you can think about count mean Max sum",
    "start": "627360",
    "end": "634240"
  },
  {
    "text": "average or numeric values um recently we added percentiles and",
    "start": "634240",
    "end": "639720"
  },
  {
    "text": "cardinality um which are pretty cool uh obviously standard variation sum of ques",
    "start": "639720",
    "end": "645279"
  },
  {
    "text": "all of those um another type of aggregations that we have are effectively Group by aggregations or we",
    "start": "645279",
    "end": "651320"
  },
  {
    "text": "call them bucket aggregations uh so for example you can have popular terms uh",
    "start": "651320",
    "end": "656680"
  },
  {
    "text": "significant terms ranges States geolocation and other stuff um just is a side note",
    "start": "656680",
    "end": "663760"
  },
  {
    "text": "how many people here are familiar with significant terms okay so I can I can have a quick",
    "start": "663760",
    "end": "671079"
  },
  {
    "text": "sideline about what significant terms does because I think that's quite cool and it shows about the power that inverted index has um so how how did the",
    "start": "671079",
    "end": "679639"
  },
  {
    "text": "significant terms came to be um uh Mark who works with our company uh",
    "start": "679639",
    "end": "685000"
  },
  {
    "text": "implemented this feature and what he saw is that uh for for example imagine",
    "start": "685000",
    "end": "690200"
  },
  {
    "text": "taking the UK crime database and the UK crime database includes a lot of data",
    "start": "690200",
    "end": "695720"
  },
  {
    "text": "but the most important one is the fact that it includes the crime type and the geolocation that it happened um and",
    "start": "695720",
    "end": "702040"
  },
  {
    "text": "imagine taking the UK and using our geohash aggregation in order to break it into areas and trying to find what are",
    "start": "702040",
    "end": "709440"
  },
  {
    "text": "the most popular crimes that happen in the UK now if you run that aggregation that means you're running popular",
    "start": "709440",
    "end": "715600"
  },
  {
    "text": "terms that's not interesting if you look at it you'll see that the top five",
    "start": "715600",
    "end": "721200"
  },
  {
    "text": "crimes are exactly the same regardless of location right theft or something along those",
    "start": "721200",
    "end": "726240"
  },
  {
    "text": "lines on the other hand we want to find the interesting crimes that happen in",
    "start": "726240",
    "end": "731320"
  },
  {
    "text": "locations uh we fondly call it uncommonly common the uncommonly common crimes within that area um and how does",
    "start": "731320",
    "end": "739120"
  },
  {
    "text": "that work once you change it and by the way that's a simple change from terms to significant terms you'll start to see",
    "start": "739120",
    "end": "744399"
  },
  {
    "text": "interesting data starts to Bubble Up from uh from elastic search for example",
    "start": "744399",
    "end": "749480"
  },
  {
    "text": "when we ran this we saw that there's an area in the UK that has a high proportional U and",
    "start": "749480",
    "end": "756120"
  },
  {
    "text": "unproportional uh commonality of bike thefts compared to the rest of the UK",
    "start": "756120",
    "end": "762079"
  },
  {
    "text": "and if you zoom into that location and try to understand why you see that it's Cambridge so people ride a lot of bikes",
    "start": "762079",
    "end": "768040"
  },
  {
    "text": "and people steal them uh we uh we uh saw that in another area there was a high",
    "start": "768040",
    "end": "775279"
  },
  {
    "text": "again unproportional amount of C of bike theft uh sorry of uh of gun possessions",
    "start": "775279",
    "end": "781800"
  },
  {
    "text": "that happened in the UK uh and when we zoomed in we saw that it was an airport so people get searched on and I have no",
    "start": "781800",
    "end": "789000"
  },
  {
    "text": "idea why people bring a lot of guns to an airport but apparently they do um and",
    "start": "789000",
    "end": "795279"
  },
  {
    "text": "if you can imagine this type of of ability it's only possible we because actually Lucine does the heavy duty for",
    "start": "795279",
    "end": "802399"
  },
  {
    "text": "us which is counting everything so you can easily take what matched in a",
    "start": "802399",
    "end": "807680"
  },
  {
    "text": "specific area and check check it against the backdrop right the background no background data that you have and try to",
    "start": "807680",
    "end": "813800"
  },
  {
    "text": "find that un commonly common situation um another interesting example",
    "start": "813800",
    "end": "818920"
  },
  {
    "text": "we took that and tried to find fraud in credit cards so um imagine you know you",
    "start": "818920",
    "end": "825519"
  },
  {
    "text": "have a lot a lot of credit swipes happening you know your your credit card company or something along those lines",
    "start": "825519",
    "end": "831360"
  },
  {
    "text": "and there's a few people I don't know around this area that reported that their credit card was stolen so if you",
    "start": "831360",
    "end": "837720"
  },
  {
    "text": "look at their credit card history you'll see a lot of transactions that they don't understand what what what is it",
    "start": "837720",
    "end": "844000"
  },
  {
    "text": "right someone stole the credit card and went you know crazy on it um but if you",
    "start": "844000",
    "end": "849040"
  },
  {
    "text": "try to find the the top terms the most common uh places where they interacted",
    "start": "849040",
    "end": "854440"
  },
  {
    "text": "with that's going to be iTunes or that's going to be Netflix or taspo or something on those lines right uh uh on",
    "start": "854440",
    "end": "862880"
  },
  {
    "text": "the other hand what I want to find here is actually that bike shop on the end of the street that every all of them Happ",
    "start": "862880",
    "end": "869320"
  },
  {
    "text": "to go there and someone installed a credit card um I don't know theft thingy",
    "start": "869320",
    "end": "875000"
  },
  {
    "text": "um so if you run significant terms you can actually find that right you want to find the uncommonly common uh data sets",
    "start": "875000",
    "end": "881399"
  },
  {
    "text": "out of that um so I'm I'm super excited about that and it shows you like how we think about data there's a whole talk",
    "start": "881399",
    "end": "888040"
  },
  {
    "text": "about it that Mike uh that Mark gave on qon um highly recommended I'll",
    "start": "888040",
    "end": "894600"
  },
  {
    "text": "continue um one of the interesting aspects that we we did with aggregations uh is that",
    "start": "894600",
    "end": "903120"
  },
  {
    "text": "aggregations can actually have subgroups and subgroups within them so if you're familiar with elastic search there's a",
    "start": "903120",
    "end": "909639"
  },
  {
    "text": "lot of freedom that you have with its query DSL it's very verbos if you try to type it with uh with Jason but the",
    "start": "909639",
    "end": "916680"
  },
  {
    "text": "ability to compose queries together it's a very um you know very enriching capability you can actually decide oh",
    "start": "916680",
    "end": "923320"
  },
  {
    "text": "here's one query I'll wrap it in another query and then filter something and I'll wrap it in another query and filter it",
    "start": "923320",
    "end": "928800"
  },
  {
    "text": "with something else and so on and so forth um if you remember in elastic search way back the facets facets module",
    "start": "928800",
    "end": "936319"
  },
  {
    "text": "that was used for analytics you couldn't do it so aggregations actually allow you to do that allow you to",
    "start": "936319",
    "end": "942759"
  },
  {
    "text": "compose uh different aggregations together so you can actually for you can for example in the UK crime example that",
    "start": "942759",
    "end": "949000"
  },
  {
    "text": "I gave you can actually run a gooh grid aggregation that includes within it a significant terms aggregation so you can",
    "start": "949000",
    "end": "956160"
  },
  {
    "text": "find the significant terms within each area in the UK okay but how does it work in practice",
    "start": "956160",
    "end": "964360"
  },
  {
    "text": "how does it work you know internally in Lucine let's start from Lucine so first of all this is an inverted index somehow",
    "start": "964360",
    "end": "971560"
  },
  {
    "text": "we have a set of documents um you know Json documents for example and they have to end up being uh in an inverted index",
    "start": "971560",
    "end": "979360"
  },
  {
    "text": "so the first thing that you need to understand is that that portion of the inverted index is immutable and that's very very",
    "start": "979360",
    "end": "986800"
  },
  {
    "text": "important uh first of all it's very cash friendly right we don't trash the shame the same uh file system location or",
    "start": "986800",
    "end": "993800"
  },
  {
    "text": "something along those lines um um the operating system can cash the hell out of it into the file system cach or what",
    "start": "993800",
    "end": "999399"
  },
  {
    "text": "have you um reads from Ram a lot of the data um has very Advanced data",
    "start": "999399",
    "end": "1005920"
  },
  {
    "text": "structures internally in Lucine in order to to do that very very efficiently both in terms of memory usage and execution",
    "start": "1005920",
    "end": "1012959"
  },
  {
    "text": "times if you cach things that are associated with it for for example our field data from back when we're doing",
    "start": "1012959",
    "end": "1019839"
  },
  {
    "text": "analytics they never change so we don't have we don't have to worry about how do you maintain cache",
    "start": "1019839",
    "end": "1026640"
  },
  {
    "text": "coherency it's effectively immutable obviously it's compressible",
    "start": "1026640",
    "end": "1032079"
  },
  {
    "text": "because once we have all the data we can actually do interesting things about compressing uh common data sets um and",
    "start": "1032079",
    "end": "1040319"
  },
  {
    "text": "it has no locking because it's immutable effectively when you search over it there's no locks you don't need to lock",
    "start": "1040319",
    "end": "1046360"
  },
  {
    "text": "because it's only it's read only but it's",
    "start": "1046360",
    "end": "1052919"
  },
  {
    "text": "immutable so how do you dynamically add documents to it so here's how it works",
    "start": "1052919",
    "end": "1059799"
  },
  {
    "text": "um first thing is that there's uh an in-memory buffer that's in theine itself",
    "start": "1059799",
    "end": "1064880"
  },
  {
    "text": "and as you add documents to it they exist in that inmemory buffer eventually you can issue a commit",
    "start": "1064880",
    "end": "1071760"
  },
  {
    "text": "in Lucin and that commit will",
    "start": "1071760",
    "end": "1077840"
  },
  {
    "text": "sorry that commit will generate a segment in",
    "start": "1077840",
    "end": "1083679"
  },
  {
    "text": "luine that's the mini inverted index that we saw before right and now we have a commit point and",
    "start": "1083679",
    "end": "1091320"
  },
  {
    "text": "this is searchable we add more documents we issue a",
    "start": "1091320",
    "end": "1097440"
  },
  {
    "text": "commit another segment now both of them are searchable okay another another set of documents",
    "start": "1097440",
    "end": "1104240"
  },
  {
    "text": "another commit and we make them searchable so how does do Lucine commit",
    "start": "1104240",
    "end": "1110880"
  },
  {
    "text": "works it writes a new segment as we saw writes a new commit point it f syns all",
    "start": "1110880",
    "end": "1116280"
  },
  {
    "text": "the files that are relevant for that segment because that's the persistent storage of it and it clears the inmemory",
    "start": "1116280",
    "end": "1122240"
  },
  {
    "text": "buffer in order to be able to accept new documents what's expensive",
    "start": "1122240",
    "end": "1128240"
  },
  {
    "text": "here everything that's a pretty heavy duty file system type operations right",
    "start": "1128240",
    "end": "1134600"
  },
  {
    "text": "it needs to go the file system now if it does any any uh file optimization or doesn't go to dis or you have slow uh",
    "start": "1134600",
    "end": "1141640"
  },
  {
    "text": "spinning disc or something along those lines now you have to go on each one and wait till it gets acknowledged by the",
    "start": "1141640",
    "end": "1148360"
  },
  {
    "text": "operating system potentially hopefully by the device driver to make sure that it's there and everything is fully",
    "start": "1148360",
    "end": "1155440"
  },
  {
    "text": "pisted so how can we make it more lightweight this is the near realtime search aspect still in lenland by the",
    "start": "1155440",
    "end": "1162159"
  },
  {
    "text": "way so we have an inmemory buffer but now we do flush we don't do commit uh",
    "start": "1162159",
    "end": "1168880"
  },
  {
    "text": "and create a segments make it searchable but again we do flushes searchable",
    "start": "1168880",
    "end": "1174720"
  },
  {
    "text": "another round make it",
    "start": "1174720",
    "end": "1179760"
  },
  {
    "text": "searchable what's and now we commit the data okay so now we can make it like",
    "start": "1179760",
    "end": "1185200"
  },
  {
    "text": "fully persistent on disk so what is a Lucen flush what does",
    "start": "1185200",
    "end": "1190559"
  },
  {
    "text": "it do it's very very similar to a commit it writes a new segment clears the buffer reopen the index for",
    "start": "1190559",
    "end": "1197640"
  },
  {
    "text": "searches but there's no fsync involved right because it's it doesn't guarantee",
    "start": "1197640",
    "end": "1203320"
  },
  {
    "text": "that if you do a looseing flush that you'll be able to later on come back and reopen the index at this point only a",
    "start": "1203320",
    "end": "1210159"
  },
  {
    "text": "commit guarantees it so this is relatively lightweight right",
    "start": "1210159",
    "end": "1216880"
  },
  {
    "text": "cool but data is not safe until it's get F sync so how do we make sure that we",
    "start": "1216880",
    "end": "1223799"
  },
  {
    "text": "don't lose data we use a transaction log very common in in in databases WR ahead",
    "start": "1223799",
    "end": "1230760"
  },
  {
    "text": "log transaction log both are very popular names for it so we have that",
    "start": "1230760",
    "end": "1235960"
  },
  {
    "text": "inmemory buffer with all the documents that we want to have they go into the transaction log as well we do a flush we",
    "start": "1235960",
    "end": "1242520"
  },
  {
    "text": "have a new segment that's searchable now another set of documents come in go into transaction as well we do a",
    "start": "1242520",
    "end": "1249679"
  },
  {
    "text": "flash that's great searchable now all of that is searchable you have a transaction log in case of a",
    "start": "1249679",
    "end": "1256320"
  },
  {
    "text": "crash by the way El will come up and and then we'll Replay that transaction log uh uh on top of based on the last commit",
    "start": "1256320",
    "end": "1263640"
  },
  {
    "text": "point And now when we issue a commit we can actually have a proper Lucine commit",
    "start": "1263640",
    "end": "1270080"
  },
  {
    "text": "point and we clear the transaction log so we can start a process new data",
    "start": "1270080",
    "end": "1275240"
  },
  {
    "text": "sets this is called an elastic search refresh so that refresh in elastic search happens every 1 second relatively",
    "start": "1275240",
    "end": "1282640"
  },
  {
    "text": "lightweight um and executes a Lucine flush makes all the changes searchable",
    "start": "1282640",
    "end": "1287720"
  },
  {
    "text": "and as I mentioned and very very lightweight an elastic search flush",
    "start": "1287720",
    "end": "1293159"
  },
  {
    "text": "which is a poorly chosen word because there's a Lucine flush that does something else effectively does a Lucine",
    "start": "1293159",
    "end": "1299480"
  },
  {
    "text": "commit like properly commits everything clears the transaction log persistent persist all the changes in Lucine itself",
    "start": "1299480",
    "end": "1306440"
  },
  {
    "text": "and it's relatively heavy and elastic search itself manages in the background all the process of issuing those flushes",
    "start": "1306440",
    "end": "1312720"
  },
  {
    "text": "periodically to make sure that the transaction log is kept at Bay okay",
    "start": "1312720",
    "end": "1320520"
  },
  {
    "text": "let's go let's continue but we have many segments right if you",
    "start": "1321600",
    "end": "1327720"
  },
  {
    "text": "can imagine we keep on adding documents and documents and documents into the system segments keeps on being created",
    "start": "1327720",
    "end": "1334320"
  },
  {
    "text": "when a search executes it search across all the segments in Lucin if you have a",
    "start": "1334320",
    "end": "1340360"
  },
  {
    "text": "thousand segments that's going to be slow um so let's let's see how segments",
    "start": "1340360",
    "end": "1346880"
  },
  {
    "text": "gets reduced so here we have one segment segment",
    "start": "1346880",
    "end": "1352640"
  },
  {
    "text": "properly searchable that's great create another segment properly searchable that's great another segment proper",
    "start": "1352640",
    "end": "1357720"
  },
  {
    "text": "searchable perfect maybe we have too many now so there's a process now that",
    "start": "1357720",
    "end": "1362919"
  },
  {
    "text": "is called merge that takes those three segments and merge them into a new segment that includes all of the",
    "start": "1362919",
    "end": "1370159"
  },
  {
    "text": "different uh data that you have in those three segment just in a new new segment now remember that this also helps with",
    "start": "1370159",
    "end": "1376960"
  },
  {
    "text": "compression if the term dog existed three times now in those three segments",
    "start": "1376960",
    "end": "1383200"
  },
  {
    "text": "it will only exist once in the new segment so it also helps to reduce the index",
    "start": "1383200",
    "end": "1389720"
  },
  {
    "text": "size and once the merge happens and it happens in the background uh um B Lucine",
    "start": "1389720",
    "end": "1396559"
  },
  {
    "text": "and elastic which also manages it with Lucine together um then make sure that",
    "start": "1396559",
    "end": "1402120"
  },
  {
    "text": "make it searchable and then those three segments can be thrown away there's a lot of trickiness involved in making",
    "start": "1402120",
    "end": "1407440"
  },
  {
    "text": "sure that we keep that three segments around for existing searches and only new searches can view the the previous",
    "start": "1407440",
    "end": "1414039"
  },
  {
    "text": "ones but all of that is managed by by elas itself um again we add uh three",
    "start": "1414039",
    "end": "1420600"
  },
  {
    "text": "segments now we have two big ones and potentially at the end we can end with",
    "start": "1420600",
    "end": "1426360"
  },
  {
    "text": "one big segments so merge process what does it",
    "start": "1426360",
    "end": "1431840"
  },
  {
    "text": "do it takes many many small segments merges them into one big segment removes deleted docks the deletes are always",
    "start": "1431840",
    "end": "1439200"
  },
  {
    "text": "tricky uh in Lucine it's effectively a bat set that says this this document ID is deleted this document ID is deleted",
    "start": "1439200",
    "end": "1445760"
  },
  {
    "text": "this document ID is deleted uh but deletes are still around they're not being treated as part of the search when",
    "start": "1445760",
    "end": "1452039"
  },
  {
    "text": "you execute a delete and a refresh happens but they're still hanging hanging around the only process that",
    "start": "1452039",
    "end": "1457960"
  },
  {
    "text": "actually throws them away is by doing this merge that effectively uh U as it",
    "start": "1457960",
    "end": "1465480"
  },
  {
    "text": "merges just doesn't take them into account during the merge process",
    "start": "1465480",
    "end": "1470360"
  },
  {
    "text": "but even a single luine index can just become too big right um I've seen cases",
    "start": "1472320",
    "end": "1478440"
  },
  {
    "text": "where the locen index of 250 gabt or something along those lines that's that's pretty much pushing it but you",
    "start": "1478440",
    "end": "1486039"
  },
  {
    "text": "single index can just becomes uh too big sometimes you just need another",
    "start": "1486039",
    "end": "1491440"
  },
  {
    "text": "one so this is the process of actually scaling up and not necessarily uh scaling out and not necessarily up and",
    "start": "1491440",
    "end": "1498000"
  },
  {
    "text": "that's obvously by shorting your data just take a single Lucine index that would have had I don't know 1 billion",
    "start": "1498000",
    "end": "1504760"
  },
  {
    "text": "documents and break it down into five of those so this is effectively a process",
    "start": "1504760",
    "end": "1510880"
  },
  {
    "text": "that is relatively transparent in elastic search and if you can think about it many segments or single index",
    "start": "1510880",
    "end": "1517039"
  },
  {
    "text": "is one Shard and many shards in elastic search is one",
    "start": "1517039",
    "end": "1522120"
  },
  {
    "text": "index okay so this is the terminology that we use in elastic search andas itself a node is a effectively a running",
    "start": "1522120",
    "end": "1529159"
  },
  {
    "text": "instance of elastic search that's effectively typically a one one server that runs it and it's just a container",
    "start": "1529159",
    "end": "1534640"
  },
  {
    "text": "of shards right charge just go around and flow between them um and that's the",
    "start": "1534640",
    "end": "1540679"
  },
  {
    "text": "physical worker unit that's the Lucine index that executes the searches distributed searches what have you and",
    "start": "1540679",
    "end": "1546279"
  },
  {
    "text": "everything the index itself is just a logical namespace it just points to one or more shards uh potentially having",
    "start": "1546279",
    "end": "1552840"
  },
  {
    "text": "copies of the data how do we calculate The Shard itself um it's effectively we take the",
    "start": "1552840",
    "end": "1559799"
  },
  {
    "text": "ID of the document we hash it and we point it at a specific uh sh that maps",
    "start": "1559799",
    "end": "1567360"
  },
  {
    "text": "to it um note that um you can also overwrite it so you can provide elas",
    "start": "1567360",
    "end": "1573679"
  },
  {
    "text": "with a routing value if you want to control that specific documents should live in the same Shard",
    "start": "1573679",
    "end": "1579880"
  },
  {
    "text": "together so how does it look when it comes to actually doing executing an API if you put a document with Doc id1 for",
    "start": "1579880",
    "end": "1587279"
  },
  {
    "text": "example uh will end up for example in Shard two thanks to because of its ID and the hashing algorithm if you try to",
    "start": "1587279",
    "end": "1594240"
  },
  {
    "text": "get a document with do id1 again same hashing will work and you go back to the",
    "start": "1594240",
    "end": "1599360"
  },
  {
    "text": "relevant one searches on the other hand typically goes to all the shards in",
    "start": "1599360",
    "end": "1604679"
  },
  {
    "text": "order to provide it so how do you scale with elastic",
    "start": "1604679",
    "end": "1609760"
  },
  {
    "text": "search um there's a lot of effort in elastic search to start small I've seen a lot of cases where people just start",
    "start": "1609760",
    "end": "1615880"
  },
  {
    "text": "with one node right if us the gastic search for logging a lot of times you just start to take your Apache web logs",
    "start": "1615880",
    "end": "1621440"
  },
  {
    "text": "and start to stream it into elastic search and maybe visualize it with kibana you you don't have enough data to",
    "start": "1621440",
    "end": "1627720"
  },
  {
    "text": "justify starting a 50 node cluster or something like that and that's fine elastic should grow with you as you have",
    "start": "1627720",
    "end": "1633679"
  },
  {
    "text": "more data and you find it valuable um so easily just start another node and as you add more",
    "start": "1633679",
    "end": "1640399"
  },
  {
    "text": "nodes Elish will automatically start to balance those shards around so it will take some shards and move them around to",
    "start": "1640399",
    "end": "1646960"
  },
  {
    "text": "the new nodes in order to make uh your data um uh properly balanced across all",
    "start": "1646960",
    "end": "1652360"
  },
  {
    "text": "the new nodes that you have uh if you add a new uh uh if you",
    "start": "1652360",
    "end": "1658399"
  },
  {
    "text": "add a new index then uh there's those relevant shards also exist and the again",
    "start": "1658399",
    "end": "1664440"
  },
  {
    "text": "properly allocated across now three nodes instead of only one node but more",
    "start": "1664440",
    "end": "1672080"
  },
  {
    "text": "Hardware most chances for Hardware failures right for example at 3:00 a.m. on a Sunday",
    "start": "1672080",
    "end": "1679159"
  },
  {
    "text": "you lose one node um so what do you do you add redundancy up until now we",
    "start": "1679159",
    "end": "1687519"
  },
  {
    "text": "had only one copy of the data so let's make another copy of the data in the",
    "start": "1687519",
    "end": "1692600"
  },
  {
    "text": "last ex there's a notion of a primary Shard that actually that's the main Shard the ones that um all the the",
    "start": "1692600",
    "end": "1699679"
  },
  {
    "text": "indexing request goes through and replica shards which are effectively copies of the primary Shard so if you",
    "start": "1699679",
    "end": "1707039"
  },
  {
    "text": "start with one node uh all the shards are primary if you add another node then if you have",
    "start": "1707039",
    "end": "1714279"
  },
  {
    "text": "replication enabled then elas will automatically go and allocate those replicas they'll recover their data from",
    "start": "1714279",
    "end": "1720279"
  },
  {
    "text": "the primary and properly be allocated if you add another node now you have",
    "start": "1720279",
    "end": "1725760"
  },
  {
    "text": "another rebalancing Factor right I mean we can now take some of the uh replicas",
    "start": "1725760",
    "end": "1731640"
  },
  {
    "text": "around and move them on top of just taking primaries and move them right they're just",
    "start": "1731640",
    "end": "1736919"
  },
  {
    "text": "shards and and if a note",
    "start": "1736919",
    "end": "1740679"
  },
  {
    "text": "fails then effectively the first thing that we do",
    "start": "1742760",
    "end": "1747880"
  },
  {
    "text": "is you saw we lost a primary over there so we go and elect a new primary uh to make sure that you can actually go and",
    "start": "1747880",
    "end": "1755559"
  },
  {
    "text": "uh continuously ingest documents on this new primary and we allocate replicas of",
    "start": "1755559",
    "end": "1761320"
  },
  {
    "text": "the data the new replica so anas will actively go and try to maintain whatever",
    "start": "1761320",
    "end": "1766440"
  },
  {
    "text": "number of replicas you've configured to have uh so you don't have to come back and say oh you know um my my you know my",
    "start": "1766440",
    "end": "1775000"
  },
  {
    "text": "my database uh back up or something went down I need to go and actively start it up in order to make sure that still",
    "start": "1775000",
    "end": "1780559"
  },
  {
    "text": "replicated or something along those lines uh elas will go and based on the number of nodes that we it has we'll",
    "start": "1780559",
    "end": "1786559"
  },
  {
    "text": "make try to make sure that you still have the the amount of copies that you've configured it to",
    "start": "1786559",
    "end": "1792080"
  },
  {
    "text": "have and then it's effectively rebalanced back to into two nodes so so primary Shard as I mentioned",
    "start": "1792080",
    "end": "1799480"
  },
  {
    "text": "it's just a roll uh it all the dock changes that happens go through the primary shards you know to maintain",
    "start": "1799480",
    "end": "1807039"
  },
  {
    "text": "consistency um and it forwards all the new Doc updates to the replicas in parallel uh the number of primaries is",
    "start": "1807039",
    "end": "1813679"
  },
  {
    "text": "fixed so you cannot change the number of paries that you started with in a single",
    "start": "1813679",
    "end": "1819000"
  },
  {
    "text": "index um this is an intentional design decision there's a whole new talk a",
    "start": "1819000",
    "end": "1824120"
  },
  {
    "text": "whole other talk if you want to go uh online that talks about how to design an to scale even beyond that limit",
    "start": "1824120",
    "end": "1830840"
  },
  {
    "text": "effectively of a single uh of uh of uh the fact that the number of parameters",
    "start": "1830840",
    "end": "1836880"
  },
  {
    "text": "is effectively fixed uh for one very very popular example is time based data",
    "start": "1836880",
    "end": "1842159"
  },
  {
    "text": "like Twitter where people just create an index per day so you can actually grow with the volume as well uh maybe today",
    "start": "1842159",
    "end": "1849679"
  },
  {
    "text": "you're ingesting 1,000 tweets if tomorrow you're ingesting I don't know 5,000 tweets actually maybe tomorrow's",
    "start": "1849679",
    "end": "1855720"
  },
  {
    "text": "index might make sense to have more copies of more replicas and be even further",
    "start": "1855720",
    "end": "1862398"
  },
  {
    "text": "partitioned replica Shard it's a copy of the primary Shard serves read and searches as well and by the way so if",
    "start": "1862960",
    "end": "1870000"
  },
  {
    "text": "you add them uh uh you can actually add more search capacity uh but it's only if you have",
    "start": "1870000",
    "end": "1877039"
  },
  {
    "text": "more Hardware right it's like if you're just going to add more replicas on a fully balanc elastic search cluster",
    "start": "1877039",
    "end": "1883679"
  },
  {
    "text": "you're not really going to add more read capacity you need to add more Hardware so those replic will go and be allocated",
    "start": "1883679",
    "end": "1889760"
  },
  {
    "text": "there to make make use of it um the number of replicas can be changed dynamically so you can go to an",
    "start": "1889760",
    "end": "1896840"
  },
  {
    "text": "existing index and change the number of replicas from one to two um a very common design uh use case in elastic",
    "start": "1896840",
    "end": "1904480"
  },
  {
    "text": "search for example when ingesting data or doing reindexing or something along those lines is you start with an index",
    "start": "1904480",
    "end": "1909720"
  },
  {
    "text": "with zero replicas so you don't incur the cost of indexing in other copies and",
    "start": "1909720",
    "end": "1915120"
  },
  {
    "text": "when you're once you're done with the indexing just increase the number of replicas and this this simple this",
    "start": "1915120",
    "end": "1921559"
  },
  {
    "text": "simple tip uh uh just Hales the time that it takes to index your data uh",
    "start": "1921559",
    "end": "1928919"
  },
  {
    "text": "typically but uh who controls all of this so in an as search there's uh",
    "start": "1929120",
    "end": "1934720"
  },
  {
    "text": "effectively a an elected Master node um and the node is effectively a",
    "start": "1934720",
    "end": "1941919"
  },
  {
    "text": "running instance of an existing elastic search cluster um if you're starting node a",
    "start": "1941919",
    "end": "1948960"
  },
  {
    "text": "um and you have one or more nodes with the same cluster name working together then whether it's with multicast or",
    "start": "1948960",
    "end": "1955559"
  },
  {
    "text": "unicast as you add more nodes they get joined to the cluster and with multicast and unicast then those nodes join and",
    "start": "1955559",
    "end": "1962480"
  },
  {
    "text": "one of them is always elected as a master the nice bit about it is that elas makes makes sure to share all the",
    "start": "1962480",
    "end": "1969840"
  },
  {
    "text": "cluster States between all the nodes so this means that wh whichever node you",
    "start": "1969840",
    "end": "1975320"
  },
  {
    "text": "hit will know where to redirect those that request something",
    "start": "1975320",
    "end": "1983200"
  },
  {
    "text": "is we'll know how to re forward the request to the relevant node",
    "start": "1983200",
    "end": "1990399"
  },
  {
    "text": "okay how does it do it so every NOS where every node knows where each document exists this is the cluster",
    "start": "1990399",
    "end": "1997000"
  },
  {
    "text": "state that I mentioned so uh it's a cluster level information it includes the indexes that it has the shards the",
    "start": "1997000",
    "end": "2004120"
  },
  {
    "text": "nodes if you're using elastic search we actually expose all of that data through our a API so you can actually go to ask",
    "start": "2004120",
    "end": "2009240"
  },
  {
    "text": "search and get a full list and an understanding of where data exists where",
    "start": "2009240",
    "end": "2014519"
  },
  {
    "text": "um and it that's the part that can only be updated by the master node so changing the cluster State adding a node",
    "start": "2014519",
    "end": "2020919"
  },
  {
    "text": "being added uh creating an index something along those lines has to be only managed by the cluster State U it's",
    "start": "2020919",
    "end": "2029159"
  },
  {
    "text": "elected when a cluster forms if you have single node then you have uh one node that is elected as",
    "start": "2029159",
    "end": "2036720"
  },
  {
    "text": "master if you add another node it joins the cluster if another if again you join",
    "start": "2036720",
    "end": "2043200"
  },
  {
    "text": "another node then he joins and identifies that there's another master in the cluster and joins it it's just a",
    "start": "2043200",
    "end": "2048520"
  },
  {
    "text": "role and if the master fails another another",
    "start": "2048520",
    "end": "2054679"
  },
  {
    "text": "Master will be elected automatically so as I mentioned the master node only manages cluster level",
    "start": "2054679",
    "end": "2061638"
  },
  {
    "text": "changes uh so it doesn't manage things like dock level changes or something like that so now you don't with don't",
    "start": "2061639",
    "end": "2067878"
  },
  {
    "text": "have to go through the master for every every operations that we do what is the result is distributed real time search",
    "start": "2067879",
    "end": "2073679"
  },
  {
    "text": "and analytics which works the same way on your laptop this is one thing that we try to make it very very easy to use is",
    "start": "2073679",
    "end": "2079520"
  },
  {
    "text": "just get started with elastic search but also in your cluster and I've seen quite",
    "start": "2079520",
    "end": "2085480"
  },
  {
    "text": "quite significant sizable um uh clusters that are being used with elastic search",
    "start": "2085480",
    "end": "2093040"
  },
  {
    "text": "um just as a side note one of the um recommendation that we have I don't know",
    "start": "2093040",
    "end": "2098240"
  },
  {
    "text": "why we didn't have it here but um because the the master itself is just a",
    "start": "2098240",
    "end": "2103599"
  },
  {
    "text": "role in the cluster in order to create a more uh resilient uh cluster itself we",
    "start": "2103599",
    "end": "2109599"
  },
  {
    "text": "recommend that you run dedicated Master nodes once your cluster becomes bigger uh so dedicated Master nodes is three",
    "start": "2109599",
    "end": "2116240"
  },
  {
    "text": "nodes that only responsible for master elections and then have a lot of other data nodes that are uh you know just",
    "start": "2116240",
    "end": "2122400"
  },
  {
    "text": "handling data and have shards alloca them on them on them so who's using it uh Wikipedia uses",
    "start": "2122400",
    "end": "2130040"
  },
  {
    "text": "elastic search very very proud very humbling uh full TCH search highlighting search uh snippet search as you type",
    "start": "2130040",
    "end": "2137000"
  },
  {
    "text": "working very closely with them uh one of the Wikipedia developers has been an amazing contributor to elastic search",
    "start": "2137000",
    "end": "2143839"
  },
  {
    "text": "helps push elastic forward uh the guardian if you're going to watch uh the",
    "start": "2143839",
    "end": "2149640"
  },
  {
    "text": "talk I highly recommended how elastic can be used as an analytics platform uh it happens today I don't remember which",
    "start": "2149640",
    "end": "2156520"
  },
  {
    "text": "time to be honest um stack Overflow uses elastic search to search across uh um obviously all the",
    "start": "2156520",
    "end": "2163720"
  },
  {
    "text": "relevant stock overflow questions uh that you have GitHub uses elastic search as you every time you uh search on",
    "start": "2163720",
    "end": "2170440"
  },
  {
    "text": "GitHub you'll uh you you effectively executing a search across elastic search",
    "start": "2170440",
    "end": "2176359"
  },
  {
    "text": "uh Gman sax uses elastic search to index an and analyze you know close to five terabytes of log data every day um by",
    "start": "2176359",
    "end": "2185160"
  },
  {
    "text": "the way uh log is very very interestings uh as a as a concept and arure started",
    "start": "2185160",
    "end": "2191640"
  },
  {
    "text": "to effectively become um uh or being used a lot in the context of logs which",
    "start": "2191640",
    "end": "2197880"
  },
  {
    "text": "I find very very fascinating um and I think the reason why it happens is that log have transition into something more",
    "start": "2197880",
    "end": "2204760"
  },
  {
    "text": "than just operational logs so people now expect from logs to be more than just uh",
    "start": "2204760",
    "end": "2210359"
  },
  {
    "text": "try to find my application errors that happen very rarely what we see today in logs is that people index or put into",
    "start": "2210359",
    "end": "2217200"
  },
  {
    "text": "elastic SE logs of um the application itself logs of the web server that talks",
    "start": "2217200",
    "end": "2224359"
  },
  {
    "text": "to the application logs of potentially some important metrics that happens on each machine into elastic search and",
    "start": "2224359",
    "end": "2231359"
  },
  {
    "text": "then you can answer very interesting questions for example can I correlate a specific error to a high to an increase",
    "start": "2231359",
    "end": "2238599"
  },
  {
    "text": "in my load on my on specific machines that comes from a specific geolocation that hit my website those are very very interesting",
    "start": "2238599",
    "end": "2245520"
  },
  {
    "text": "questions that you can now answer if you put all of that that data together in elastic search uh and I think that this",
    "start": "2245520",
    "end": "2250640"
  },
  {
    "text": "is one of the main reasons why elastic search is being used so much for logging uh as",
    "start": "2250640",
    "end": "2256800"
  },
  {
    "text": "well so um that's it um thank you very much uh short talk relatively short I",
    "start": "2256800",
    "end": "2264200"
  },
  {
    "text": "don't know yeah 40 minutes um any questions very good question how does up",
    "start": "2264200",
    "end": "2269280"
  },
  {
    "text": "how do updates happen uh so updates effectively in Lucin itself it's a delete or Mark as deleted the previous",
    "start": "2269280",
    "end": "2276599"
  },
  {
    "text": "document and uh index the new document so it is a",
    "start": "2276599",
    "end": "2282920"
  },
  {
    "text": "reindex um what is important to remember it's actually tends to be not that",
    "start": "2282920",
    "end": "2288079"
  },
  {
    "text": "expensive anyhow you need to reanalyze your data or something along those lines um and if uh Lucine tries tried to solve",
    "start": "2288079",
    "end": "2296319"
  },
  {
    "text": "in place updates like you know databases do with bites or something along those lines it will lose all the benefits that",
    "start": "2296319",
    "end": "2302240"
  },
  {
    "text": "it has with immutability so there's tons of benefits that you get from the fact that luum works that way that actually",
    "start": "2302240",
    "end": "2309880"
  },
  {
    "text": "people don't necessarily understand immediately understanding the immutability aspect that actually you want that to happen you want Lucine to",
    "start": "2309880",
    "end": "2317040"
  },
  {
    "text": "reindex the data so you can execute searches with no locks so you can do you can create caches that has don't have to",
    "start": "2317040",
    "end": "2323200"
  },
  {
    "text": "worry about cash coherency there's tons of stuff that comes with it yes is elastic sech aware of location",
    "start": "2323200",
    "end": "2332760"
  },
  {
    "text": "more geographical location yes uh well first of all we don't recommend running elastic",
    "start": "2332760",
    "end": "2338119"
  },
  {
    "text": "between data centers um I we recommend running elas within the same data center um uh",
    "start": "2338119",
    "end": "2346560"
  },
  {
    "text": "typically between data centers people put like message cues or something along those lines and we potentially might",
    "start": "2346560",
    "end": "2352200"
  },
  {
    "text": "work in the future to have a different type of replication model that will work well between data centers which will not",
    "start": "2352200",
    "end": "2359079"
  },
  {
    "text": "work well today",
    "start": "2359079",
    "end": "2363839"
  },
  {
    "text": "my need go so that that part we recommend to run",
    "start": "2364200",
    "end": "2370880"
  },
  {
    "text": "something like a message CU between them and and replicate the operations on the other hand if you're running elas for example with rack awareness or within in",
    "start": "2370880",
    "end": "2378480"
  },
  {
    "text": "Amazon between availability zones then you can configure elastic search and we call it um awareness allocation",
    "start": "2378480",
    "end": "2385119"
  },
  {
    "text": "awareness you can configure elastic to make sure that it places copies of the data across availability zones so if one",
    "start": "2385119",
    "end": "2392599"
  },
  {
    "text": "availability Zone goes down then uh you still have the copies of the data actually goes even a step further and",
    "start": "2392599",
    "end": "2398599"
  },
  {
    "text": "says if one availability Zone goes down you can configure it not to go and allocate all the copies of that",
    "start": "2398599",
    "end": "2403800"
  },
  {
    "text": "availability zones in the existing cluster because that might crumble your cluster uh and wait until it comes back",
    "start": "2403800",
    "end": "2409720"
  },
  {
    "text": "up and resync many languages yes um uh the",
    "start": "2409720",
    "end": "2418480"
  },
  {
    "text": "support mainly comes from Lucin Itself by the way uh there's a lot of work in Luc to support multiple languages uh",
    "start": "2418480",
    "end": "2424760"
  },
  {
    "text": "mainly around the analysis process so how do you take that piece of text that I showed and break it correctly for",
    "start": "2424760",
    "end": "2430359"
  },
  {
    "text": "different languages because different languages have different different rules on how to break it can just break based on white",
    "start": "2430359",
    "end": "2436000"
  },
  {
    "text": "spaces uh so each language has its own analyzer some of them are really good",
    "start": "2436000",
    "end": "2441079"
  },
  {
    "text": "some of them not as much and you if you have a very and coming out",
    "start": "2441079",
    "end": "2448800"
  },
  {
    "text": "how yes um so um from 1.x we we uh",
    "start": "2448800",
    "end": "2456720"
  },
  {
    "text": "guarantee that uh the the protocol within nodes will be Backward Compatible",
    "start": "2456720",
    "end": "2462800"
  },
  {
    "text": "so in 1.1 1.2 um you uh you can run one 1.2 node",
    "start": "2462800",
    "end": "2469480"
  },
  {
    "text": "next to 1.1 cluster uh so you can do a rolling restart today in elastic search",
    "start": "2469480",
    "end": "2475359"
  },
  {
    "text": "the rolling restart can be expensive because even if you disable allocation like you go and tellas search okay I",
    "start": "2475359",
    "end": "2481960"
  },
  {
    "text": "just shut down a node but don't go and try to allocate all the shards that were on it because I'm going to bring it back",
    "start": "2481960",
    "end": "2487040"
  },
  {
    "text": "up again um we we over um over copy some data that exists",
    "start": "2487040",
    "end": "2495359"
  },
  {
    "text": "between the primary and the replica of that node so it can take more time than you know we would have loved it to be",
    "start": "2495359",
    "end": "2501960"
  },
  {
    "text": "we're working on making that process a bit faster and then effectively a rolling restart will be hopefully you",
    "start": "2501960",
    "end": "2508119"
  },
  {
    "text": "know very very quick and you won't have to wait a long time so the question is how do how do how does updating nested",
    "start": "2508119",
    "end": "2514599"
  },
  {
    "text": "documents work in last when you have ajon structure that is complex and have so there's there's two ways to do that",
    "start": "2514599",
    "end": "2521400"
  },
  {
    "text": "in antic search the first one is nested documents or the nested Concepts and um",
    "start": "2521400",
    "end": "2527640"
  },
  {
    "text": "it's taking the internal uh objects in a Json structure and and creating",
    "start": "2527640",
    "end": "2534000"
  },
  {
    "text": "documents and external Lucine documents next to it so one document might end up being five or six documents then you can",
    "start": "2534000",
    "end": "2541319"
  },
  {
    "text": "perform searches that are bit more advanced when it comes to relationship between Fields within those objects um",
    "start": "2541319",
    "end": "2547559"
  },
  {
    "text": "so because there uh because it ends up being five or 10 documents or something like that there's a few guarantees that",
    "start": "2547559",
    "end": "2554280"
  },
  {
    "text": "happen for example there's a guarantee that all of those will always happen within the same",
    "start": "2554280",
    "end": "2560040"
  },
  {
    "text": "segment so even uh during a segment merge or something like that you have the guarantees that they will never",
    "start": "2560040",
    "end": "2566559"
  },
  {
    "text": "split between segments so that means that you can make sure that when you update something you",
    "start": "2566559",
    "end": "2573480"
  },
  {
    "text": "do have to reindex all of that nested documents but at least you won't have get into a situation where you see partial results or something like that",
    "start": "2573480",
    "end": "2581040"
  },
  {
    "text": "um if you um on the other hand because they exist within a single segment searches are super super fast right it's",
    "start": "2581040",
    "end": "2588200"
  },
  {
    "text": "like even even faster than joins in a database because it's like it goes just on a bit set and finds the matching ones",
    "start": "2588200",
    "end": "2595400"
  },
  {
    "text": "um there's another feature in called parent child where you can have a a parent document and a different document",
    "start": "2595400",
    "end": "2602319"
  },
  {
    "text": "not internally that have a relationship of a parent child relationship and when you have that in elastic search elastic",
    "start": "2602319",
    "end": "2608640"
  },
  {
    "text": "makes sure that the parent and the child exist within the same Shard uh using the routing mechanism",
    "start": "2608640",
    "end": "2614720"
  },
  {
    "text": "automatically and then when you do searches you can execute searches that uh says whether this parent has this",
    "start": "2614720",
    "end": "2620880"
  },
  {
    "text": "child whether this child has this parent and then you can update them regardless",
    "start": "2620880",
    "end": "2626160"
  },
  {
    "text": "uh you can go and update the parent or you go and update the child um uh this",
    "start": "2626160",
    "end": "2631440"
  },
  {
    "text": "is a bit more expensive though so searches using parent child will be slower compared to searches using nest",
    "start": "2631440",
    "end": "2637240"
  },
  {
    "text": "documents but you gain the ability to only update portions of that documents instead of having to reindex the whole",
    "start": "2637240",
    "end": "2643079"
  },
  {
    "text": "document we no we uh we hope to address Security in a future versions of elastic",
    "start": "2643079",
    "end": "2648559"
  },
  {
    "text": "search but uh I you'll see how how we work we we when we address security we",
    "start": "2648559",
    "end": "2654319"
  },
  {
    "text": "want to make sure that we add all the features that comes with security uh including ACLS as well uh for now what",
    "start": "2654319",
    "end": "2661960"
  },
  {
    "text": "we recommend and we always recommend to put a proxy in front of elastic search and thanks to the fact that it's rest",
    "start": "2661960",
    "end": "2667480"
  },
  {
    "text": "then you can I've seen people create rules in that proxy in NX or something like that that allows specific users to",
    "start": "2667480",
    "end": "2673760"
  },
  {
    "text": "access specific indexes based on the URL pattern that they have thank you very [Applause]",
    "start": "2673760",
    "end": "2682020"
  },
  {
    "text": "[Music]",
    "start": "2682020",
    "end": "2689800"
  },
  {
    "text": "much",
    "start": "2689800",
    "end": "2692800"
  }
]
[
  {
    "text": "[Music] so have you ever sat down in front of a",
    "start": "6990",
    "end": "14490"
  },
  {
    "text": "streaming service like Netflix and you thought hey you know I wonder what needs to actually get done to prepare this",
    "start": "14490",
    "end": "19680"
  },
  {
    "text": "content for streaming to my TV and okay Sam has but I totally like I never did",
    "start": "19680",
    "end": "27529"
  },
  {
    "text": "the reality is though that there's actually quite a lot of stuff that needs to happen to video content to actually",
    "start": "27529",
    "end": "34860"
  },
  {
    "text": "make it available to you and that's what the talk is about today something that",
    "start": "34860",
    "end": "40230"
  },
  {
    "text": "the stuffs that needs to happen to your video in order to make it available for you and what we actually did to make",
    "start": "40230",
    "end": "45600"
  },
  {
    "text": "that happen for the entire ABC catalog so again full disclosure I work for",
    "start": "45600",
    "end": "51270"
  },
  {
    "text": "Amazon I'm actually working at Amazon fresh now which is grocery deliveries and it's available in Chicago if you",
    "start": "51270",
    "end": "56670"
  },
  {
    "text": "want to try it but I'm not here representing Amazon today I'm representing myself for a previous role",
    "start": "56670",
    "end": "63390"
  },
  {
    "text": "that I did at the ABC so I really want",
    "start": "63390",
    "end": "69930"
  },
  {
    "text": "to introduce you to the ABC first it's a public broadcaster in Australia and it's",
    "start": "69930",
    "end": "75240"
  },
  {
    "text": "actually a really great national treasure it's really well known for TV",
    "start": "75240",
    "end": "81000"
  },
  {
    "text": "we've got a lot of different own broadcasting services and shows that we",
    "start": "81000",
    "end": "86280"
  },
  {
    "text": "create it's also hugely important source of news radio regional programming and I",
    "start": "86280",
    "end": "93329"
  },
  {
    "text": "like to think of it a bit like an old-school PBS it's publicly funded there aren't any ads during the shows",
    "start": "93329",
    "end": "100140"
  },
  {
    "text": "and it's actually one of the rare channels that appeals to both kids and you know senior citizens so it's kind of",
    "start": "100140",
    "end": "106979"
  },
  {
    "text": "a got an audience that's a really big spectrum and one of the iconic shows",
    "start": "106979",
    "end": "112619"
  },
  {
    "text": "that we have is a show called at playschool and if you're a kid in Australia you grow up with these",
    "start": "112619",
    "end": "118290"
  },
  {
    "text": "characters you seriously know everything about this show and it's kind of our equivalent of",
    "start": "118290",
    "end": "124860"
  },
  {
    "text": "Sesame Street and in my first week at the ABC this was me getting to meet my",
    "start": "124860",
    "end": "131370"
  },
  {
    "text": "childhood heroes in giant form I just wanted to show you this to just show you",
    "start": "131370",
    "end": "137340"
  },
  {
    "text": "the love I have it here and how hugely excited I was at the opportunity to work on a system like",
    "start": "137340",
    "end": "143890"
  },
  {
    "text": "this for a company like this so the ABC",
    "start": "143890",
    "end": "149709"
  },
  {
    "text": "has a product called a via and it's the front end of the system that I'll be talking about today that's what we",
    "start": "149709",
    "end": "155739"
  },
  {
    "text": "produce all the video is for and it's a TV on demand service it's free",
    "start": "155739",
    "end": "161250"
  },
  {
    "text": "everything that gets broadcast on the ABC gets made available on ibew",
    "start": "161250",
    "end": "166330"
  },
  {
    "text": "and it serves millions of viewers every single week so to make these shows",
    "start": "166330",
    "end": "172720"
  },
  {
    "text": "available on iview we have to process them right we have to transcode them into formats that are actually suitable",
    "start": "172720",
    "end": "179769"
  },
  {
    "text": "for streaming so today's talk is a system we built to do that our scale in",
    "start": "179769",
    "end": "185950"
  },
  {
    "text": "a cost-efficient way we called our new system Metro so things that I would like",
    "start": "185950",
    "end": "196569"
  },
  {
    "text": "to cover today one is what do I actually mean when I say video transcoding right",
    "start": "196569",
    "end": "202299"
  },
  {
    "text": "what why do we need it what does it do I'm gonna walk through a transcode to",
    "start": "202299",
    "end": "207430"
  },
  {
    "text": "kind of show you the whole process of what that's actually doing to is what",
    "start": "207430",
    "end": "213190"
  },
  {
    "text": "did we end up building to handle the volume of content that we produce at the ABC how did we take one transcode and",
    "start": "213190",
    "end": "219790"
  },
  {
    "text": "actually repeat it reliably so I'm gonna give you a higher high-level overview of the architecture that we built and AWS",
    "start": "219790",
    "end": "226540"
  },
  {
    "text": "services that we use here language choices that we made and also the benefits of arts using small services",
    "start": "226540",
    "end": "233410"
  },
  {
    "text": "and dividing asset our system up this is",
    "start": "233410",
    "end": "238480"
  },
  {
    "text": "my favorite part of the system it is how do we scale our transcoders transcoding",
    "start": "238480",
    "end": "244120"
  },
  {
    "text": "is the most expensive part of our system so how do we actually scale to handle",
    "start": "244120",
    "end": "249730"
  },
  {
    "text": "fluctuating demand but also optimize for cost how much does Metro actually cost",
    "start": "249730",
    "end": "258250"
  },
  {
    "text": "to run right how does it compare to the commercial transcoding systems and you",
    "start": "258250",
    "end": "263889"
  },
  {
    "text": "know what does it actually cost for us to run for a typical day or a typical year of content for the ABC",
    "start": "263889",
    "end": "270659"
  },
  {
    "text": "and last this is kind of a bit of fun these what kind of optimizations could we actually do in future because this",
    "start": "271770",
    "end": "278500"
  },
  {
    "text": "project actually started as a really small team of like an average of three people that ran for about six months",
    "start": "278500",
    "end": "284560"
  },
  {
    "text": "this is the resulting system that we ended up with and so there's definitely some things that we can do in future",
    "start": "284560",
    "end": "291039"
  },
  {
    "text": "that will help to improve the throughput and optimizations so first off what is",
    "start": "291039",
    "end": "299319"
  },
  {
    "text": "transcoding sorry I just realize I hadn't started my time off thank you",
    "start": "299319",
    "end": "307680"
  },
  {
    "text": "so our transcoding is a process right we start with an initial input file which",
    "start": "310259",
    "end": "316090"
  },
  {
    "text": "is either an audio or a video file of some kind and we convert it to a variety of different output formats which we",
    "start": "316090",
    "end": "321940"
  },
  {
    "text": "call renditions I'm going to be referring to renditions throughout this talk quite often because it's a really",
    "start": "321940",
    "end": "327400"
  },
  {
    "text": "important part of our system so we create a lot of different renditions for",
    "start": "327400",
    "end": "333729"
  },
  {
    "text": "each video and in tradition is slightly different so what changes are we actually making to these videos we can",
    "start": "333729",
    "end": "340810"
  },
  {
    "text": "do things like adjust the resolution like the size of the video we can adjust",
    "start": "340810",
    "end": "345909"
  },
  {
    "text": "the actual format of it so that you know the encoding of it we can change the bitrate so the quality of the video",
    "start": "345909",
    "end": "353409"
  },
  {
    "text": "higher bitrate is a higher quality and we can add things like watermarks so",
    "start": "353409",
    "end": "358539"
  },
  {
    "text": "like logos on the bottom of the screen that kind of stuff and our goal is",
    "start": "358539",
    "end": "363729"
  },
  {
    "text": "really to take a video that could come from any source and produce a standard",
    "start": "363729",
    "end": "369969"
  },
  {
    "text": "set of renditions from it we want a predictable set of renditions for us to",
    "start": "369969",
    "end": "377740"
  },
  {
    "text": "use on iView and so this video here on the left is the single video that will receive and through the transcoding",
    "start": "377740",
    "end": "384789"
  },
  {
    "text": "process we're going to end up turning it into the multiple standard renditions that are on the right and we do this for",
    "start": "384789",
    "end": "391509"
  },
  {
    "text": "every video so why would we have so many sizes one is we want to optimize the",
    "start": "391509",
    "end": "398820"
  },
  {
    "text": "video for your device so if you're watching it on a",
    "start": "398820",
    "end": "403969"
  },
  {
    "text": "machine or a TV we want to give you a better quality video versus if you're on",
    "start": "403969",
    "end": "408979"
  },
  {
    "text": "a mobile you really don't need something that's so big and the other thing is",
    "start": "408979",
    "end": "414529"
  },
  {
    "text": "that we actually want to adjust it so that it suits the network speed that you've got so if you are what so every",
    "start": "414529",
    "end": "422449"
  },
  {
    "text": "rendition has a different bitrate and that's the amount of data that you're downloading per second in order to view",
    "start": "422449",
    "end": "428539"
  },
  {
    "text": "the videos so if you want a high network connection that's great we'll give you the highest bitrate that we've got",
    "start": "428539",
    "end": "433579"
  },
  {
    "text": "otherwise if you're on a lower version like I mean if you're on mobile on the go we'll give you a low quality rendition so that you can actually play",
    "start": "433579",
    "end": "440719"
  },
  {
    "text": "that it won't really affect your viewing quality the player the video player that",
    "start": "440719",
    "end": "447199"
  },
  {
    "text": "you're watching it with is actually responsible for selecting which one of these renditions to play so our job is",
    "start": "447199",
    "end": "452689"
  },
  {
    "text": "just to ensure that we produce the full set of renditions so that when it comes",
    "start": "452689",
    "end": "457909"
  },
  {
    "text": "to your player it can select whichever one is the most appropriate for you so",
    "start": "457909",
    "end": "465079"
  },
  {
    "text": "we convert everything to h.264 mp4 we receive a lot of different input formats",
    "start": "465079",
    "end": "471079"
  },
  {
    "text": "but it makes such a lot easier to output this in one format and that's because",
    "start": "471079",
    "end": "476779"
  },
  {
    "text": "it's a standard format for HLS streaming the player doesn't have to worry about you know different codecs we don't have",
    "start": "476779",
    "end": "483319"
  },
  {
    "text": "to do QA across a whole bunch of different formats and also you know we're not doubling up on storage of",
    "start": "483319",
    "end": "489919"
  },
  {
    "text": "multiple different renditions so I'm",
    "start": "489919",
    "end": "495709"
  },
  {
    "text": "going to walk through an example here so you get a good idea of what we're doing first we have to prepare the watermark",
    "start": "495709",
    "end": "501529"
  },
  {
    "text": "that actually gets put on the bottom of each video so we make it transparent and then we put it resizing it down and that",
    "start": "501529",
    "end": "509419"
  },
  {
    "text": "size is a relative relative to each rendition size so you know you'll get a",
    "start": "509419",
    "end": "515448"
  },
  {
    "text": "larger renditions we're just going to have a larger logo but when you watch it back on your screen it'll look the same",
    "start": "515449",
    "end": "521680"
  },
  {
    "text": "relative we then take this input video that we've got this is an episode of a",
    "start": "521680",
    "end": "530720"
  },
  {
    "text": "show called utopia that is an Australian show produced by the ABC and the format",
    "start": "530720",
    "end": "536720"
  },
  {
    "text": "that we've got this in something called gxf it's a broadcast format and you can see it's got this",
    "start": "536720",
    "end": "542780"
  },
  {
    "text": "black bar at the top here and and that's used during broadcast it's got timecode information in it and",
    "start": "542780",
    "end": "548270"
  },
  {
    "text": "it's also got captions in it but the thing is is that you know you're not going to use those when you're streaming",
    "start": "548270",
    "end": "554270"
  },
  {
    "text": "online so we crop that off next you'll",
    "start": "554270",
    "end": "559850"
  },
  {
    "text": "notice that it's actually in 4:3 format and we want to show it to you in",
    "start": "559850",
    "end": "564920"
  },
  {
    "text": "widescreen 16 by 9 so for historical reasons it's actually more space",
    "start": "564920",
    "end": "571130"
  },
  {
    "text": "efficient to kind of store it in 4:3 and there's a whole bunch of like systems in the ABC they're good to producing",
    "start": "571130",
    "end": "578030"
  },
  {
    "text": "content and dealing with content in 4:3 so that's what I get saved in but we",
    "start": "578030",
    "end": "583760"
  },
  {
    "text": "adjust it the ratio and save it in the header file so that you know the video player will know yeah it's actually",
    "start": "583760",
    "end": "589910"
  },
  {
    "text": "supposed to be a widescreen format we then add the watermark that we've produced earlier and again you just want",
    "start": "589910",
    "end": "597440"
  },
  {
    "text": "to make sure that if you're switching renditions in the middle of streaming but the logo doesn't look like it's",
    "start": "597440",
    "end": "602990"
  },
  {
    "text": "moving around we also have to process the audio of this video sorry this is",
    "start": "602990",
    "end": "610280"
  },
  {
    "text": "the audio track for the original half-hour version of that show and it shows you the audio intensity so the",
    "start": "610280",
    "end": "617720"
  },
  {
    "text": "higher the bars the louder the volume and we go through a process of audio",
    "start": "617720",
    "end": "623810"
  },
  {
    "text": "normalization because we want to bring everything to a consistent volume across all the different videos and we do this",
    "start": "623810",
    "end": "631130"
  },
  {
    "text": "because if you have a show a and show B here and they've actually recorded different volumes or have different",
    "start": "631130",
    "end": "638270"
  },
  {
    "text": "volumes on their tracks when you watch it back on your player you don't want to have to keep adjusting the volume but as you as you change",
    "start": "638270",
    "end": "645080"
  },
  {
    "text": "shows so we normalize everything so that you don't notice the difference so after",
    "start": "645080",
    "end": "652250"
  },
  {
    "text": "the video and the audio of both processed and the video is now ready to stream and it actually gets split up",
    "start": "652250",
    "end": "658220"
  },
  {
    "text": "into a whole bunch of 10 second chunks and so when you play your video you",
    "start": "658220",
    "end": "663470"
  },
  {
    "text": "receive a series of these small chunks together and they form a you know smooth continuous video for you",
    "start": "663470",
    "end": "669700"
  },
  {
    "text": "and the those little files can come from any of the different magicians and that's how your video player there gets",
    "start": "669700",
    "end": "676540"
  },
  {
    "text": "the ability to stream and to change the quality you know dynamically without you having to really worry about where it",
    "start": "676540",
    "end": "682570"
  },
  {
    "text": "comes from so that's a lot of different changes that we've made to these videos",
    "start": "682570",
    "end": "689050"
  },
  {
    "text": "right we've we've changed it encoding and cropping and bit rates and stuff like that how do we actually keep track",
    "start": "689050",
    "end": "694540"
  },
  {
    "text": "of all of this stuff right we ideally want all of those changes in one place because we get a lot of different",
    "start": "694540",
    "end": "702790"
  },
  {
    "text": "formats the kind of steps that we need to do for each of the files is going to be different and we don't want to have",
    "start": "702790",
    "end": "708970"
  },
  {
    "text": "to think too hard about what we're going to do there so we save the list of",
    "start": "708970",
    "end": "714670"
  },
  {
    "text": "changes for every single video type into something called a profile and that's",
    "start": "714670",
    "end": "720820"
  },
  {
    "text": "it's a set of instructions that we can look up whenever we get a new file in our system it looks a little like this",
    "start": "720820",
    "end": "727480"
  },
  {
    "text": "stylistic use this so our metrics got a source location where all the files are dropped and to start with we just kind",
    "start": "727480",
    "end": "734230"
  },
  {
    "text": "of map a folder to a profile and that serves all videos dropped in this folder",
    "start": "734230",
    "end": "739270"
  },
  {
    "text": "I have this set of instructions on them and so this folder holds GSF gxf content this is the stuff that will do to a gxf",
    "start": "739270",
    "end": "746440"
  },
  {
    "text": "file and we end up with a transcoding example we just saw before but if we get",
    "start": "746440",
    "end": "752470"
  },
  {
    "text": "some other type of content like mouth file Perez Apple ProRes format there's",
    "start": "752470",
    "end": "759100"
  },
  {
    "text": "actually less stuff to do we don't we don't get that content with the black bar we don't actually get that content",
    "start": "759100",
    "end": "764440"
  },
  {
    "text": "we in the wrong ratio it's already it's already done for us so there's less instructions that we actually need to do",
    "start": "764440",
    "end": "770110"
  },
  {
    "text": "to finish that and so to actually do all of that to execute all of that video",
    "start": "770110",
    "end": "777100"
  },
  {
    "text": "copying the scaling etc we use ffmpeg which is an open source media",
    "start": "777100",
    "end": "782230"
  },
  {
    "text": "transcoding tool it's incredibly powerful and it's been around for about 15 years this is an example of a sample",
    "start": "782230",
    "end": "790120"
  },
  {
    "text": "command that to run something in ffmpeg and it makes a lot of assumptions about",
    "start": "790120",
    "end": "795250"
  },
  {
    "text": "the input format about the quality you want about the output formats that you want",
    "start": "795250",
    "end": "801420"
  },
  {
    "text": "this is the real thing that we end up using for hours and it's linked to the",
    "start": "801420",
    "end": "807010"
  },
  {
    "text": "profile so if we're producing six different renditions we'll have six different versions of this command and",
    "start": "807010",
    "end": "812920"
  },
  {
    "text": "the command will show you things like what the encoding is that we want as an",
    "start": "812920",
    "end": "818080"
  },
  {
    "text": "output the cropping deinterlacing this is the scaling aspect ratio some stuff",
    "start": "818080",
    "end": "824680"
  },
  {
    "text": "with the watermark things that are controlling video quality and audio and just some other options and there's a",
    "start": "824680",
    "end": "833140"
  },
  {
    "text": "lot of different stuff that's in here I'm not going to be able to cover it in detail but ffmpeg the community is",
    "start": "833140",
    "end": "840610"
  },
  {
    "text": "really active and helpful and it's very well documented so it is an amazing",
    "start": "840610",
    "end": "846280"
  },
  {
    "text": "piece of software we really could not have built Metro without this so that's",
    "start": "846280",
    "end": "853420"
  },
  {
    "text": "kind of an overview of how the transcoding process works and our goal is to really take that input video and",
    "start": "853420",
    "end": "858850"
  },
  {
    "text": "produce the standard set of videos output videos that we will use for our thrive you so we want to now take a look",
    "start": "858850",
    "end": "868660"
  },
  {
    "text": "at how we actually run that at scale",
    "start": "868660",
    "end": "872399"
  },
  {
    "text": "Metro is a workflow so all the content that goes in will follow these high-level steps so we get a file and we",
    "start": "876330",
    "end": "884380"
  },
  {
    "text": "transfer it into AWS we then queue the content and we make sure that it's ready",
    "start": "884380",
    "end": "890080"
  },
  {
    "text": "for processing we'll transcode it by running ffmpeg over it we move the",
    "start": "890080",
    "end": "896350"
  },
  {
    "text": "resulting renditions out to our CDN and then tell live you hate all your renditions are now ready and you can",
    "start": "896350",
    "end": "902980"
  },
  {
    "text": "publish and here's what it looks like some an architecture point of view so",
    "start": "902980",
    "end": "909580"
  },
  {
    "text": "first the input file is uploaded to an s3 bucket and when it's finished uploading we use s3 xin built",
    "start": "909580",
    "end": "915610"
  },
  {
    "text": "notifications to put a message on to an amazon SQS queue so we've written",
    "start": "915610",
    "end": "922360"
  },
  {
    "text": "several small services we call queue Lissa's and one of them will monitor",
    "start": "922360",
    "end": "928480"
  },
  {
    "text": "this queue and it's single job is to messages going onto that queue and to",
    "start": "928480",
    "end": "933890"
  },
  {
    "text": "tell another component that this has happened so as soon as it as soon as the message gets added there it will send",
    "start": "933890",
    "end": "940040"
  },
  {
    "text": "that message to and another component in our system called the orchestrator to",
    "start": "940040",
    "end": "946430"
  },
  {
    "text": "say that if jobs been added and the orchestrator is kind of the brains of our operation it's the only component",
    "start": "946430",
    "end": "954530"
  },
  {
    "text": "that's actually state aware the only component that has a data store it's responsible for tracking where",
    "start": "954530",
    "end": "960590"
  },
  {
    "text": "everything is in the system and it controls it also controls the number of transcoders that we have according to",
    "start": "960590",
    "end": "967520"
  },
  {
    "text": "the number of jobs that we've gone in flight so that gets saved and then while",
    "start": "967520",
    "end": "975500"
  },
  {
    "text": "it's saving the job it will also look up that list of profiles and it will match",
    "start": "975500",
    "end": "982010"
  },
  {
    "text": "this video to a profile and that profile will tell us how many renditions we're",
    "start": "982010",
    "end": "987620"
  },
  {
    "text": "trying to create and it will also tell us the ffmpeg command for those",
    "start": "987620",
    "end": "994250"
  },
  {
    "text": "renditions and the input and the output locations so that's like three really",
    "start": "994250",
    "end": "1000310"
  },
  {
    "text": "important things that we get we actually get more information that we send along with that profile but for us to do our",
    "start": "1000310",
    "end": "1005380"
  },
  {
    "text": "transcode those are the three things we really need and so at this stage we've",
    "start": "1005380",
    "end": "1012190"
  },
  {
    "text": "actually got enough information to begin our transcode the orchestrator will in",
    "start": "1012190",
    "end": "1017350"
  },
  {
    "text": "queue a message for a rendition on to our transmitting queue so if we say",
    "start": "1017350",
    "end": "1022660"
  },
  {
    "text": "we're producing six different renditions then we into six messages here and well",
    "start": "1022660",
    "end": "1028930"
  },
  {
    "text": "the orchestrator will also calculate whether we need more transcoding ec2 instances to actually meet the number of",
    "start": "1028930",
    "end": "1035890"
  },
  {
    "text": "jobs in the system so if we do it spins up new instances an external I will actually now spin them down so all of",
    "start": "1035890",
    "end": "1045730"
  },
  {
    "text": "our transcoding instances are marshaling this queue with the trance code messages on it each transcoder will take one",
    "start": "1045730",
    "end": "1052990"
  },
  {
    "text": "message at a time one transcode at a time and do its work and this is where",
    "start": "1052990",
    "end": "1058360"
  },
  {
    "text": "the most intensive part with ffmpeg is actually done now system so that it takes the most time",
    "start": "1058360",
    "end": "1065010"
  },
  {
    "text": "it's like 90% of the time in the system is inside this machine here and the time to transfer is also going to be",
    "start": "1065010",
    "end": "1070900"
  },
  {
    "text": "dependent a lot on the type of content that you're transcoding so if it's a",
    "start": "1070900",
    "end": "1076120"
  },
  {
    "text": "long piece of content they will obviously take a long time also if it's a high quality piece of content it's",
    "start": "1076120",
    "end": "1081309"
  },
  {
    "text": "going to take much longer than a lower quality piece of content so once that transcoding is done the file is saved to",
    "start": "1081309",
    "end": "1088600"
  },
  {
    "text": "a an s output s3 bucket that we also use the orchestrator is told and then it",
    "start": "1088600",
    "end": "1095110"
  },
  {
    "text": "will save the status of this job now so that we move those renditions out ready for the CDN so the transfer process",
    "start": "1095110",
    "end": "1104710"
  },
  {
    "text": "takes the finished renditions and sends them to the CDN and that means that they actually become ready to publish on I",
    "start": "1104710",
    "end": "1111159"
  },
  {
    "text": "view sorry yes okay so the orchestrator",
    "start": "1111159",
    "end": "1117700"
  },
  {
    "text": "will mark that rendition as complete and it will notify I view so that the videos can be published at this point also it",
    "start": "1117700",
    "end": "1125440"
  },
  {
    "text": "says hey is there anything else in the system and if not it's going to turn off all the transcoders so that we're not running machines when we're actually not",
    "start": "1125440",
    "end": "1131380"
  },
  {
    "text": "doing any work on average it takes around 8 and a half minutes to actually",
    "start": "1131380",
    "end": "1137530"
  },
  {
    "text": "go through the pipeline and that's that figure is everything from file upload to",
    "start": "1137530",
    "end": "1142809"
  },
  {
    "text": "s3 all the way to notifying I view and as I said we've got a variety of content",
    "start": "1142809",
    "end": "1148870"
  },
  {
    "text": "from you know five minute videos that are kind of like really short to documentaries that can be 90 minutes or",
    "start": "1148870",
    "end": "1156010"
  },
  {
    "text": "two hours and so the timer system really depends on how long it is here's a bit",
    "start": "1156010",
    "end": "1165070"
  },
  {
    "text": "of information on some averages of how long it takes so the lowest quality rendition we produce which is actually",
    "start": "1165070",
    "end": "1171580"
  },
  {
    "text": "an audio track and that tends to take around 7% or 12% of the original content",
    "start": "1171580",
    "end": "1177700"
  },
  {
    "text": "time in the system and our highest quality button tends to take around 70% of real time so if a one hour piece of",
    "start": "1177700",
    "end": "1184539"
  },
  {
    "text": "content goes in audio will take around seven minutes to come out and a higher bitrate content will take 40 to",
    "start": "1184539",
    "end": "1192059"
  },
  {
    "text": "in terms of technology that we use to pick to build this system the things we built ourselves are actually written in",
    "start": "1193140",
    "end": "1199260"
  },
  {
    "text": "two different languages we use node and we use go so the first of those is the",
    "start": "1199260",
    "end": "1205350"
  },
  {
    "text": "orchestrator it's the brains of our system that's the only one that we wrote in node it's because it's quick and easy",
    "start": "1205350",
    "end": "1212460"
  },
  {
    "text": "to write an API for it basically and the team already kind of knew what was going",
    "start": "1212460",
    "end": "1217830"
  },
  {
    "text": "on with node so most in smarts lives here we have what's in flight",
    "start": "1217830",
    "end": "1224520"
  },
  {
    "text": "how many transcoders do I need what's the state of each job and you know looking out information that I need to",
    "start": "1224520",
    "end": "1231990"
  },
  {
    "text": "know about each of the renditions that's going through in the profile these",
    "start": "1231990",
    "end": "1237929"
  },
  {
    "text": "services the ones that are sitting on the end of the queue and actually aren't aren't very stateful they're written and",
    "start": "1237929",
    "end": "1243690"
  },
  {
    "text": "go and so they're really small they're independent long live services and their",
    "start": "1243690",
    "end": "1249120"
  },
  {
    "text": "job is basically to monitor these events that come in and do something with them and so those steps there's three of them",
    "start": "1249120",
    "end": "1255540"
  },
  {
    "text": "those steps are to register a new media file here to transcribe the content and",
    "start": "1255540",
    "end": "1260760"
  },
  {
    "text": "also to transfer the content out to the CDN so they've been really stable and",
    "start": "1260760",
    "end": "1267350"
  },
  {
    "text": "really easy to deploy because they're just a they get built into a binary and we just drop that down and that's been",
    "start": "1267350",
    "end": "1274410"
  },
  {
    "text": "fantastic so we don't need a special runtime or anything like that for go and it's also been great for piping large",
    "start": "1274410",
    "end": "1280470"
  },
  {
    "text": "files out through to our CDN go can use",
    "start": "1280470",
    "end": "1286410"
  },
  {
    "text": "a ghost streaming you can use basically a files of any size and it'll use a constant amount of memory disk space and",
    "start": "1286410",
    "end": "1293760"
  },
  {
    "text": "send anything through so that's that's actually being super beneficial in terms",
    "start": "1293760",
    "end": "1300120"
  },
  {
    "text": "of infrastructure our whole stack is built on AWS so going to cover these",
    "start": "1300120",
    "end": "1306179"
  },
  {
    "text": "really briefly use them in a fairly standard fashion and we've also just just talked about in terms of architecture we use MySQL on RDS just to",
    "start": "1306179",
    "end": "1314400"
  },
  {
    "text": "store all our jobs and allows us to do some pretty simple stuff in terms of analysis we've got some auto-scaling ec2",
    "start": "1314400",
    "end": "1323850"
  },
  {
    "text": "groups feature for four different services and that's great because we can scale them independently and particularly here",
    "start": "1323850",
    "end": "1332700"
  },
  {
    "text": "our trans coders are the ones that we scale in an unusual fashion so we frequently changed the number of",
    "start": "1332700",
    "end": "1339000"
  },
  {
    "text": "instances running at any given time to meet demand and I'm going to be explaining a lot more about this in the",
    "start": "1339000",
    "end": "1345120"
  },
  {
    "text": "next section we use s3 for input and output storage and keep content for",
    "start": "1345120",
    "end": "1351420"
  },
  {
    "text": "seven days and purge otherwise and we're using queuing here as qsr queues for",
    "start": "1351420",
    "end": "1358550"
  },
  {
    "text": "reliable retry messaging between our components so that's basically so we don't lose anything in the middle of",
    "start": "1358550",
    "end": "1364560"
  },
  {
    "text": "processing so you know if something gets dark or we can't contact the CDN to actually put stuff on there and no big",
    "start": "1364560",
    "end": "1372060"
  },
  {
    "text": "deal stuff we'll just sit in a queue waiting until everything's available again the same thing applies if we're",
    "start": "1372060",
    "end": "1377370"
  },
  {
    "text": "actually redeploying one of our services queues what messages we'll just sit there waiting till there everything's up",
    "start": "1377370",
    "end": "1383820"
  },
  {
    "text": "and ready to receive them again so the only kind of unusual thing for us is",
    "start": "1383820",
    "end": "1389460"
  },
  {
    "text": "that transcoders can take up to two hours to actually do do their work and",
    "start": "1389460",
    "end": "1395370"
  },
  {
    "text": "that's kind of a long time to be processing a message so we have to periodically report back and say",
    "start": "1395370",
    "end": "1402060"
  },
  {
    "text": "actually yes I'm still working on this still working on this otherwise we found that some other transcode it would pick",
    "start": "1402060",
    "end": "1409620"
  },
  {
    "text": "up a piece of work and we would duplicate effort and yeah that's not really ideal so we have to make sure",
    "start": "1409620",
    "end": "1417210"
  },
  {
    "text": "that only one piece of content is being handled by one transcoder at any one time some of the advantages about design",
    "start": "1417210",
    "end": "1427560"
  },
  {
    "text": "as a small service new deployments are really easy we like like I said we don't",
    "start": "1427560",
    "end": "1434520"
  },
  {
    "text": "have any loss of data messaging because we're using their cues messages to just",
    "start": "1434520",
    "end": "1439680"
  },
  {
    "text": "wait there until everything's up and ready to handle them another thing that",
    "start": "1439680",
    "end": "1444960"
  },
  {
    "text": "we've really found beneficial is the ability they skew to scale things independently",
    "start": "1444960",
    "end": "1450740"
  },
  {
    "text": "and you'll see that very shortly in the transcoding section as well we can have dozens of transcripts running hundreds",
    "start": "1450740",
    "end": "1456650"
  },
  {
    "text": "if you really wanted to and that would not be a problem it's also really easy",
    "start": "1456650",
    "end": "1463130"
  },
  {
    "text": "for us to add new pieces without affecting any of the existing ones we",
    "start": "1463130",
    "end": "1468440"
  },
  {
    "text": "have been talking about doing caption extraction so that black bar that was at the top of the video content before that",
    "start": "1468440",
    "end": "1475070"
  },
  {
    "text": "we actually crop off one thing that we'd love to do is to actually extract that ourselves and the thing is that it",
    "start": "1475070",
    "end": "1481640"
  },
  {
    "text": "happens to be in a very unique format and for us to do that ourselves would actually be no big problem create a new",
    "start": "1481640",
    "end": "1489020"
  },
  {
    "text": "service do that we can actually run it in parallel along with all the other transcoding machines and that would be",
    "start": "1489020",
    "end": "1495920"
  },
  {
    "text": "fine I also really love the deferred",
    "start": "1495920",
    "end": "1502070"
  },
  {
    "text": "responsibility to kind of individual services so having one source of data",
    "start": "1502070",
    "end": "1507590"
  },
  {
    "text": "for our system has actually been great because if we do any schema changes or anything like that and the blast radius",
    "start": "1507590",
    "end": "1514580"
  },
  {
    "text": "for that is very limited right there's only one services actually bothered and the other ones it actually doesn't they",
    "start": "1514580",
    "end": "1520940"
  },
  {
    "text": "don't really have to have state they get messages in everything they need is in that message they do some work and then",
    "start": "1520940",
    "end": "1527270"
  },
  {
    "text": "they tell something else that I've done so we really we don't have to worry about synchronizing things if we're",
    "start": "1527270",
    "end": "1533930"
  },
  {
    "text": "deploying everything can can go independently whenever it wants to",
    "start": "1533930",
    "end": "1539380"
  },
  {
    "text": "things that we found challenging deployments making sure all the services",
    "start": "1539380",
    "end": "1545420"
  },
  {
    "text": "are actually wired together correctly has been challenging so to that end",
    "start": "1545420",
    "end": "1551240"
  },
  {
    "text": "we've had to really concentrate on automating stuff as much as possible we use CloudFormation templates AWS",
    "start": "1551240",
    "end": "1557690"
  },
  {
    "text": "CloudFormation templates to make everything repeatable and consistent and",
    "start": "1557690",
    "end": "1562720"
  },
  {
    "text": "95% of our system is actually templated we and we also deploy by a CI we make",
    "start": "1562720",
    "end": "1568730"
  },
  {
    "text": "sure that everything is you know has as little human involvement as possible",
    "start": "1568730",
    "end": "1574250"
  },
  {
    "text": "because we have staging dev prod and there's no way that we wanted to manually configure any of that by",
    "start": "1574250",
    "end": "1579920"
  },
  {
    "text": "ourselves it's obviously more work to build and",
    "start": "1579920",
    "end": "1586190"
  },
  {
    "text": "develop small services independently than to just put it all in one big thing",
    "start": "1586190",
    "end": "1591490"
  },
  {
    "text": "but for us they're really the big thing that we gained out of this was the",
    "start": "1591490",
    "end": "1597440"
  },
  {
    "text": "ability to have independent scaling particularly for our transcoders and that's what made it worth doing in small",
    "start": "1597440",
    "end": "1603800"
  },
  {
    "text": "services so that's an overview of you",
    "start": "1603800",
    "end": "1610130"
  },
  {
    "text": "know what our architecture was on AWS the fact that we're using ffmpeg and",
    "start": "1610130",
    "end": "1615380"
  },
  {
    "text": "using our small independent services there so now we're going to look at one of the really interesting pieces which",
    "start": "1615380",
    "end": "1621080"
  },
  {
    "text": "is how to transcode all the content in a timely manner so as I said earlier we",
    "start": "1621080",
    "end": "1628100"
  },
  {
    "text": "frequently change the number of transcoders that we're running and that's because if we've got a lot of content to process you know we can spin",
    "start": "1628100",
    "end": "1634700"
  },
  {
    "text": "up a lot of instances but if we've got nothing then you know we don't have to run anything so when should you actually",
    "start": "1634700",
    "end": "1644390"
  },
  {
    "text": "spin up or tear down these instances it's not a simple question to answer",
    "start": "1644390",
    "end": "1649550"
  },
  {
    "text": "this there's actually a lot of different factors that come into play so the first",
    "start": "1649550",
    "end": "1654830"
  },
  {
    "text": "of them is how quickly does the content need to be available we get a lot of content far in advance but live shows",
    "start": "1654830",
    "end": "1663620"
  },
  {
    "text": "are an exception so if you have the new news broadcast we're gonna have that in advance once",
    "start": "1663620",
    "end": "1669710"
  },
  {
    "text": "the show is done it gets sent to us through our transcoding pipeline and we need to try and make that available as",
    "start": "1669710",
    "end": "1675050"
  },
  {
    "text": "quickly as possible we actually Envy pede with one cue that",
    "start": "1675050",
    "end": "1682970"
  },
  {
    "text": "was a conscious choice so if both high priority and regular priority content",
    "start": "1682970",
    "end": "1688280"
  },
  {
    "text": "goes in this queue so if if we get a high priority piece of content we kind of need to drain the queue you know we",
    "start": "1688280",
    "end": "1694640"
  },
  {
    "text": "need to process everything in there to make sure that that high priority piece of content is also being processed we",
    "start": "1694640",
    "end": "1703010"
  },
  {
    "text": "also don't know when people put content into our pipeline if there was a set",
    "start": "1703010",
    "end": "1708200"
  },
  {
    "text": "pattern we could run transcoders at the same time every day so you know they put it",
    "start": "1708200",
    "end": "1713309"
  },
  {
    "text": "in between 3 & 8 p.m. and their problem yeah well we'll start 10 strands produce 20 transcoders just leave in there but",
    "start": "1713309",
    "end": "1719940"
  },
  {
    "text": "we don't get that so content comes through at random and we really don't want to leave them running well there's",
    "start": "1719940",
    "end": "1726720"
  },
  {
    "text": "nothing to process we also got a variety of different content lengths so we've",
    "start": "1726720",
    "end": "1733200"
  },
  {
    "text": "got these you know five-minute videos that are very short and we've got these documentaries that are sort of 90 minutes long so you can actually process",
    "start": "1733200",
    "end": "1740850"
  },
  {
    "text": "a lot of five-minute videos in an hour but a 90-minute documentary might take a",
    "start": "1740850",
    "end": "1746070"
  },
  {
    "text": "whole hour on a transcoder by itself in",
    "start": "1746070",
    "end": "1751260"
  },
  {
    "text": "terms of AWS considerations for scaling it has hourly billing so as soon as you",
    "start": "1751260",
    "end": "1759210"
  },
  {
    "text": "started in the instance for two minutes you've basically paid for an hour you might as well kind of leave it running",
    "start": "1759210",
    "end": "1765770"
  },
  {
    "text": "but there's also a balance between cost and speed so you might start off a very",
    "start": "1765770",
    "end": "1771059"
  },
  {
    "text": "fast instance and you could transcribe this piece of content in two minutes but",
    "start": "1771059",
    "end": "1776580"
  },
  {
    "text": "then it will be idle for fifty eight of them so you're actually better off in that instance is to buy a slower",
    "start": "1776580",
    "end": "1783450"
  },
  {
    "text": "instance and pay less for it and you know maybe take 40 minutes or something instead to transcode Amazon scaling",
    "start": "1783450",
    "end": "1792150"
  },
  {
    "text": "metrics for an auto scaling group kind of normally around five minutes monitoring right I take around five",
    "start": "1792150",
    "end": "1798960"
  },
  {
    "text": "minutes to react so you know in a normal scaling thing you can say hey if all my instances here hit this memory threshold",
    "start": "1798960",
    "end": "1805799"
  },
  {
    "text": "I'd really like you to take an action and spin up some more instances so that I can spread the load for us and if",
    "start": "1805799",
    "end": "1813240"
  },
  {
    "text": "there's hot something high-priority coming through we actually want to we want to try and react faster than that",
    "start": "1813240",
    "end": "1818990"
  },
  {
    "text": "so easy to instances as well will take a few minutes it's been up so the whole",
    "start": "1818990",
    "end": "1825150"
  },
  {
    "text": "whole thing going from zero to two this is maybe around seven or eight minutes",
    "start": "1825150",
    "end": "1831470"
  },
  {
    "text": "we want to react fast enough and at the time we built this we",
    "start": "1831470",
    "end": "1837920"
  },
  {
    "text": "actually didn't have control over which instances in an auto scaling group got turned off Amazon would pick the oldest",
    "start": "1837920",
    "end": "1844730"
  },
  {
    "text": "ones and shut them down and that would not be good if it was actually running a",
    "start": "1844730",
    "end": "1850220"
  },
  {
    "text": "transcode at the time we'd have to redo all that work it is worth saying that they now have instance protection",
    "start": "1850220",
    "end": "1856910"
  },
  {
    "text": "available so you know you can say hey this is this is busy doing work please don't turn it off but this was done in",
    "start": "1856910",
    "end": "1862910"
  },
  {
    "text": "late 2015 and we didn't have that available so instead of trying to",
    "start": "1862910",
    "end": "1868760"
  },
  {
    "text": "address everything here we focused just on our MVP don't make things way too",
    "start": "1868760",
    "end": "1874549"
  },
  {
    "text": "long for a variety of reasons we chose to have one queue so we have both",
    "start": "1874549",
    "end": "1881270"
  },
  {
    "text": "regular and high-priority stuff in there don't make things wait too long in this queue in order to make that that queue",
    "start": "1881270",
    "end": "1890600"
  },
  {
    "text": "drain - to actually flow we've got to be proactive about supplying enough",
    "start": "1890600",
    "end": "1895760"
  },
  {
    "text": "capacity to handle everything in the queue at any given time so we know it's going to be processed within a",
    "start": "1895760",
    "end": "1901730"
  },
  {
    "text": "predictable time frame so proactive supply is needed in two cases one if",
    "start": "1901730",
    "end": "1908540"
  },
  {
    "text": "it's high quality because that's going to take a long time it's going to block stuff behind it two is if it's",
    "start": "1908540",
    "end": "1914510"
  },
  {
    "text": "high-priority content so things like the news that we really want to get up as as as soon as possible",
    "start": "1914510",
    "end": "1919780"
  },
  {
    "text": "so if you remember this profile from Elia it actually tells us those",
    "start": "1919780",
    "end": "1925280"
  },
  {
    "text": "conditions right it can tell us when it's high-priority or when it's high high quality so if it's high quality",
    "start": "1925280",
    "end": "1932480"
  },
  {
    "text": "content it's going to take a long time to transcode start a new transcoder for",
    "start": "1932480",
    "end": "1938390"
  },
  {
    "text": "each high quality instance that we're actually trying here if it's high-priority content most high priority",
    "start": "1938390",
    "end": "1948260"
  },
  {
    "text": "content has only for lower quality renditions this is a weird business quirk but it's actually super fast for",
    "start": "1948260",
    "end": "1955040"
  },
  {
    "text": "us to transcribe those for lower quality on on there in a single instance so we only spin up one to handle it so there's",
    "start": "1955040",
    "end": "1961669"
  },
  {
    "text": "two cases they're high quality high priority we're specifically starting out new Transpo",
    "start": "1961669",
    "end": "1966960"
  },
  {
    "text": "to handle those situations if it's a neither high priority nor high quality",
    "start": "1966960",
    "end": "1973020"
  },
  {
    "text": "we want to check the ratio of jobs in the system - how many transporters we've",
    "start": "1973020",
    "end": "1978120"
  },
  {
    "text": "got running and if that ratio is fine we leave it otherwise if the ratio is too",
    "start": "1978120",
    "end": "1984210"
  },
  {
    "text": "high we'll spin up a new instance so that we can handle that if there are no",
    "start": "1984210",
    "end": "1989309"
  },
  {
    "text": "transcoders running then we want to spin one up to ensure that the pipeline is moving so there should never be a time",
    "start": "1989309",
    "end": "1996179"
  },
  {
    "text": "when there's a queue content without a transcoded running one thing I should",
    "start": "1996179",
    "end": "2003649"
  },
  {
    "text": "also mention here is that we we do get different numbers of renditions",
    "start": "2003649",
    "end": "2010000"
  },
  {
    "text": "producing from each individual video that comes in so the reason why we might",
    "start": "2010000",
    "end": "2016070"
  },
  {
    "text": "only have two renditions coming from a particular file is it might come from a different source so we'll look we can take to high",
    "start": "2016070",
    "end": "2022700"
  },
  {
    "text": "quality renditions from something and for high quality or addition lower quality renditions from a different thing and stitch those together and",
    "start": "2022700",
    "end": "2029000"
  },
  {
    "text": "those are the six that will actually end up putting live on I view so to adjust",
    "start": "2029000",
    "end": "2037100"
  },
  {
    "text": "the number of transcoders that we've got running it is one line of code the",
    "start": "2037100",
    "end": "2042590"
  },
  {
    "text": "orchestrator decides how many instances is the ideal number to have and it will set the capacity on the group and AWS",
    "start": "2042590",
    "end": "2050388"
  },
  {
    "text": "processes that request and we'll have our new instances starting pretty much immediately so it's very it's much",
    "start": "2050389",
    "end": "2056960"
  },
  {
    "text": "pressure a little more preferable for us to do this instead of waiting for auto scaling metrics to kick in so the next",
    "start": "2056960",
    "end": "2066679"
  },
  {
    "text": "question is what ec2 instance size do we actually want transcoding is pretty CPU",
    "start": "2066679",
    "end": "2073128"
  },
  {
    "text": "heavy and so we also want to think about cost versus speed of these so we wanted",
    "start": "2073129",
    "end": "2081138"
  },
  {
    "text": "to look at the c4 series of instances from AWS which have the best price to",
    "start": "2081139",
    "end": "2086750"
  },
  {
    "text": "compute power ratio in them and this is a graph of the analysis that we did to",
    "start": "2086750",
    "end": "2092839"
  },
  {
    "text": "show amount of time to transfer to a one-hour piece of content versus how",
    "start": "2092839",
    "end": "2097910"
  },
  {
    "text": "much those instances we're going to cast and you can see that inverse relationship you know between",
    "start": "2097910",
    "end": "2103040"
  },
  {
    "text": "cost and speed we wanted to find an instance type that was going to suit our requirements the best the majority of",
    "start": "2103040",
    "end": "2111240"
  },
  {
    "text": "our content isn't time pressures if it takes a little longer to transcode it",
    "start": "2111240",
    "end": "2116580"
  },
  {
    "text": "that's kind of okay again this is kind of a balancing what do we need for the majority of everything versus how can we",
    "start": "2116580",
    "end": "2123300"
  },
  {
    "text": "produce stuff that's going to make our high high priority content flow through",
    "start": "2123300",
    "end": "2128910"
  },
  {
    "text": "that I'm going to remind you that we are",
    "start": "2128910",
    "end": "2134160"
  },
  {
    "text": "publicly funded for cost efficiencies actually really important so we actually",
    "start": "2134160",
    "end": "2140160"
  },
  {
    "text": "decided to go with the C for extra-large since the majority of our content isn't",
    "start": "2140160",
    "end": "2145380"
  },
  {
    "text": "speed driven that we really wanted to save save the difference the next is to size up to double the cost the last",
    "start": "2145380",
    "end": "2155880"
  },
  {
    "text": "question is when do you decide to decrease capacity so scaling up is",
    "start": "2155880",
    "end": "2160890"
  },
  {
    "text": "pretty easy if you get a lot of content and you don't have capacity you can add more instances but scaling down requires",
    "start": "2160890",
    "end": "2168690"
  },
  {
    "text": "knowing when the instances are busy that's you know you don't want to stop a",
    "start": "2168690",
    "end": "2174060"
  },
  {
    "text": "transcode that's in process so at the time we built this if you decrease the",
    "start": "2174060",
    "end": "2180900"
  },
  {
    "text": "number of instances Amazon would just choose the oldest ones and kill them so to start with we needed to actually wait",
    "start": "2180900",
    "end": "2187710"
  },
  {
    "text": "until the entire pipeline was clear before we could shut everything down and",
    "start": "2187710",
    "end": "2193170"
  },
  {
    "text": "if you think that sounds really inefficient it kind of is so here's an example of that in action right this is",
    "start": "2193170",
    "end": "2200040"
  },
  {
    "text": "the number of transcode is running in a four-hour window so you can see quite a lot of scaling up and down activity here",
    "start": "2200040",
    "end": "2205950"
  },
  {
    "text": "but you can see the inefficiency of waiting until all those content was done",
    "start": "2205950",
    "end": "2213090"
  },
  {
    "text": "before we turned off everything off so you can see these these cliffs and you",
    "start": "2213090",
    "end": "2218910"
  },
  {
    "text": "can also see the effect of us tearing down things immediately there are time so we've spun everything down only to start it up literally at two minutes",
    "start": "2218910",
    "end": "2225600"
  },
  {
    "text": "later and so ideally we really only want to tear down our was up to get the most out of our",
    "start": "2225600",
    "end": "2232160"
  },
  {
    "text": "instances this is another view of those same transcoding instances that we",
    "start": "2232160",
    "end": "2238130"
  },
  {
    "text": "created earlier this is a graph of lifetime instance in that four-hour",
    "start": "2238130",
    "end": "2243260"
  },
  {
    "text": "window so this is not just what's currently running but this is this is everything that was there so it's heavily skewed to short-lived instances",
    "start": "2243260",
    "end": "2250000"
  },
  {
    "text": "that's that's pretty inefficient you know we're paying for a whole hour of compute time but we're in the using a",
    "start": "2250000",
    "end": "2255380"
  },
  {
    "text": "fraction of what's there so the ones in blue are the ones using more than 30",
    "start": "2255380",
    "end": "2260780"
  },
  {
    "text": "minutes of an hour and everything else is is underutilized this is this is a",
    "start": "2260780",
    "end": "2266660"
  },
  {
    "text": "worse than average picture all right I'm kind of showing it to us as an extreme example it's highly dependent on when",
    "start": "2266660",
    "end": "2272900"
  },
  {
    "text": "content gets put into the pipeline so a regular consistent feed will produce",
    "start": "2272900",
    "end": "2278930"
  },
  {
    "text": "well utilized machines but a huge dump of content in there is going to spin up a whole bunch at once and then shut",
    "start": "2278930",
    "end": "2286940"
  },
  {
    "text": "things down so the auto scaling here I'm",
    "start": "2286940",
    "end": "2292760"
  },
  {
    "text": "gonna pause the content and it sounds like we left things in a really weird",
    "start": "2292760",
    "end": "2298040"
  },
  {
    "text": "state here but we're gonna look at costs and that will explain why we've stopped",
    "start": "2298040",
    "end": "2303770"
  },
  {
    "text": "so right now we've got a pretty minimal approach and that's kind of based on profiles and it roughly tells us how",
    "start": "2303770",
    "end": "2310520"
  },
  {
    "text": "long a time it takes to transcode a piece of content or if it's a high-priority piece of content and we",
    "start": "2310520",
    "end": "2315830"
  },
  {
    "text": "react based on that so it's an area of the system where anything we do is going",
    "start": "2315830",
    "end": "2322100"
  },
  {
    "text": "to anything we tweak or change it's going to have a huge impact on costs so",
    "start": "2322100",
    "end": "2329240"
  },
  {
    "text": "we're now going to look at how much it costs to actually run this a common",
    "start": "2329240",
    "end": "2335000"
  },
  {
    "text": "question that I get asked is why would you build your own system when there are some commercial transcoders available",
    "start": "2335000",
    "end": "2343540"
  },
  {
    "text": "let's look at a few so if you are going to use a full service transcoding",
    "start": "2343750",
    "end": "2349870"
  },
  {
    "text": "profile provider you're going to get a nice neat front-end you're gonna get",
    "start": "2349870",
    "end": "2355520"
  },
  {
    "text": "some stuff you'll be able to call them with stuff things go wrong you'll have everything transcoded as quickly as",
    "start": "2355520",
    "end": "2361430"
  },
  {
    "text": "possible so you submit jobs the whole the whole thing is geared towards giving it to you as soon as you've dropped it",
    "start": "2361430",
    "end": "2367080"
  },
  {
    "text": "in the thing is we know for most of our content we actually don't really need a",
    "start": "2367080",
    "end": "2373350"
  },
  {
    "text": "ASAP so we've started with this model where we are producing everything ASAP",
    "start": "2373350",
    "end": "2379050"
  },
  {
    "text": "but we have the ability to actually not transcode everything immediately quickly so we don't necessarily need to pay for",
    "start": "2379050",
    "end": "2386910"
  },
  {
    "text": "a service that's going to give us everything as quickly as possible it's like quite a lot of money a",
    "start": "2386910",
    "end": "2394670"
  },
  {
    "text": "six-figure figure number that I don't even know what it was but to transcode the volume of content that we produced",
    "start": "2394670",
    "end": "2400140"
  },
  {
    "text": "at the ABC it was a large number there's also some do-it-yourself kind of",
    "start": "2400140",
    "end": "2410030"
  },
  {
    "text": "transcoding options available things like elastic transcoder from AWS and so",
    "start": "2410720",
    "end": "2416820"
  },
  {
    "text": "there's that's a service where you can submit files you you have to do a bit of configuration you still have to write a",
    "start": "2416820",
    "end": "2421890"
  },
  {
    "text": "bit of code to actually make this work you'll probably be debugging issues if they're going wrong and it still kind of",
    "start": "2421890",
    "end": "2429090"
  },
  {
    "text": "doesn't meet some of our strange requirements so this black bar at the top here with asymmetric cropping it's",
    "start": "2429090",
    "end": "2436590"
  },
  {
    "text": "actually kind of it's not a super common requirement to want to crop a video in",
    "start": "2436590",
    "end": "2442800"
  },
  {
    "text": "an asymmetric way and when we were building this it wasn't actually",
    "start": "2442800",
    "end": "2448050"
  },
  {
    "text": "supported by a lot of transcoders so that was a reason why we couldn't do this we also have our captions format",
    "start": "2448050",
    "end": "2455820"
  },
  {
    "text": "which is slightly obscure again it's an ABC quark it's it's it's in a it's in",
    "start": "2455820",
    "end": "2462570"
  },
  {
    "text": "the format called Opie 47 and it's not really used by a lot of different things so it's actually not supported by a lot of places so again if we wanted to try",
    "start": "2462570",
    "end": "2469680"
  },
  {
    "text": "and expand our system to do more things we couldn't use some of these roll-your-own or DIY systems to do that",
    "start": "2469680",
    "end": "2479850"
  },
  {
    "text": "through elastic transcoder it's about 45 K",
    "start": "2479850",
    "end": "2484610"
  },
  {
    "text": "from metro what does it cost for a whole year of iview content remember we've",
    "start": "2485640",
    "end": "2492269"
  },
  {
    "text": "solved the problem of paying for ASCAP content in a cost-efficient way and we",
    "start": "2492269",
    "end": "2498450"
  },
  {
    "text": "can handle these odd requirements like asymmetric cropping and we've got the ability to be able to handle things like",
    "start": "2498450",
    "end": "2503849"
  },
  {
    "text": "captions in the future so for Metro in 2016 our whole year costs we're 11 point",
    "start": "2503849",
    "end": "2511680"
  },
  {
    "text": "2 K and that's yet partly because we skew to some lower end renditions we are",
    "start": "2511680",
    "end": "2518039"
  },
  {
    "text": "a public broadcaster we are cheap but in 2017 you know with where things publish a whole bunch of high-quality renditions",
    "start": "2518039",
    "end": "2525960"
  },
  {
    "text": "and that means that our costs are going to be higher but we're actually we've",
    "start": "2525960",
    "end": "2533069"
  },
  {
    "text": "paid for that we've already invested in being able to scale for that by building",
    "start": "2533069",
    "end": "2538859"
  },
  {
    "text": "this new system so here's a sample day",
    "start": "2538859",
    "end": "2545279"
  },
  {
    "text": "as an example for our system we get a variety of different usage patterns I'm",
    "start": "2545279",
    "end": "2550289"
  },
  {
    "text": "just going to show you a couple this is a view of renditions completed per hour",
    "start": "2550289",
    "end": "2555859"
  },
  {
    "text": "it's 24 hours and so you can see most of the works done during the day here but",
    "start": "2555859",
    "end": "2561180"
  },
  {
    "text": "we still have a lot of transcoding running later into the 9th so there's news there's shows like a QA",
    "start": "2561180",
    "end": "2567509"
  },
  {
    "text": "and this particular day costs $42 and 86",
    "start": "2567509",
    "end": "2573210"
  },
  {
    "text": "cents and the breakdown of it was that 90% of our cost is related to easy to",
    "start": "2573210",
    "end": "2579769"
  },
  {
    "text": "database is 6% storage file storage is 4% and because you're paying for sqs",
    "start": "2579769",
    "end": "2587220"
  },
  {
    "text": "messages by the millions you know we know register on that scale it'll to",
    "start": "2587220",
    "end": "2595710"
  },
  {
    "text": "show you the varied nature of our output this is literally the next day this is a",
    "start": "2595710",
    "end": "2601380"
  },
  {
    "text": "bunch of content that ended up being scheduled at 3:00 in the morning by some person or system and so it kind of just",
    "start": "2601380",
    "end": "2609660"
  },
  {
    "text": "illustrates the we don't know when things get put in we we can't run things at particular set times and so the",
    "start": "2609660",
    "end": "2616319"
  },
  {
    "text": "flexibility for our transcode is to actually scale according to content in flight is",
    "start": "2616319",
    "end": "2622650"
  },
  {
    "text": "super beneficial $25 so I said that you",
    "start": "2622650",
    "end": "2630270"
  },
  {
    "text": "know these costs are actually a massive deal for us the ABC is a public broadcaster we love",
    "start": "2630270",
    "end": "2636060"
  },
  {
    "text": "that we love the fact that we get the flexibility that we want but we can still do this in a really cost-efficient",
    "start": "2636060",
    "end": "2641369"
  },
  {
    "text": "way and we actually got to the point where the costs are so small that we couldn't justify spending more dev",
    "start": "2641369",
    "end": "2647730"
  },
  {
    "text": "effort on it and so that's why we have left our now transcoding algorithm as it",
    "start": "2647730",
    "end": "2654930"
  },
  {
    "text": "is exactly as it is so we withhold in efficiencies it is still doing the work that we need in a",
    "start": "2654930",
    "end": "2660420"
  },
  {
    "text": "really cost efficient way so having just",
    "start": "2660420",
    "end": "2667980"
  },
  {
    "text": "said that we can't justify optimizations it's super fun to theorize about what you can actually do so I'm going to do a",
    "start": "2667980",
    "end": "2673740"
  },
  {
    "text": "couple quickly so an obvious thing we can do is actually introduce a priority",
    "start": "2673740",
    "end": "2680040"
  },
  {
    "text": "queue here right in addition to our regular queue and our priority queue you could transcode on a much larger",
    "start": "2680040",
    "end": "2685230"
  },
  {
    "text": "instance that gets spun up immediately and the regular content that doesn't need to be transcoded immediately can",
    "start": "2685230",
    "end": "2691170"
  },
  {
    "text": "actually just sit waiting until there's enough to produce yeah to produce a more",
    "start": "2691170",
    "end": "2698460"
  },
  {
    "text": "constant transfer and full transcode so that we can avoid this graph where we've got all these underutilized instances",
    "start": "2698460",
    "end": "2705859"
  },
  {
    "text": "another thing we can do is actually transcode in segments so we can divide the source file into those chunks and",
    "start": "2705859",
    "end": "2712530"
  },
  {
    "text": "then we can use ffmpeg to actually help us do that and that means that our time",
    "start": "2712530",
    "end": "2718410"
  },
  {
    "text": "to transcribe for a particular file is going to be constant it doesn't matter if you give us a five-minute video or a",
    "start": "2718410",
    "end": "2723450"
  },
  {
    "text": "two-hour documentary we farm it out somewhere and send it off we can do that",
    "start": "2723450",
    "end": "2730260"
  },
  {
    "text": "in a constant time so this was a prime candidate for something like lambda",
    "start": "2730260",
    "end": "2735560"
  },
  {
    "text": "didn't exist in the Sydney region at the appointment we were building it we actually did a cost analysis to you know",
    "start": "2735560",
    "end": "2741240"
  },
  {
    "text": "ship everything over to the US transferred it there in lambda and come back but we ended up building it in a",
    "start": "2741240",
    "end": "2747660"
  },
  {
    "text": "situ so the last thing we can do is actually remove our reliance",
    "start": "2747660",
    "end": "2752700"
  },
  {
    "text": "on hard-coded profiles so we can use FF probe we you know we use profiles at the",
    "start": "2752700",
    "end": "2760710"
  },
  {
    "text": "moment kind of hard-coded it's not great instead we should examine each file as",
    "start": "2760710",
    "end": "2766320"
  },
  {
    "text": "it comes in and actually see the attributes on the file using FF probe and so we can see here that we've got",
    "start": "2766320",
    "end": "2774510"
  },
  {
    "text": "information about the resolution we can we know that that's not a standard size",
    "start": "2774510",
    "end": "2779700"
  },
  {
    "text": "so we know we actually have to crop it we can see that it's got 50 frames a second that we want an output at 25",
    "start": "2779700",
    "end": "2786420"
  },
  {
    "text": "frames a second so we know we have to run a merge filter down to to fix that",
    "start": "2786420",
    "end": "2793109"
  },
  {
    "text": "and here if we get a stream an audio",
    "start": "2793109",
    "end": "2798420"
  },
  {
    "text": "stream that's our caption stream this unknown stream here so ffmpeg doesn't",
    "start": "2798420",
    "end": "2804060"
  },
  {
    "text": "immediately recognize it but if we see that we know that's captions hey we can we can actually extract them as part of",
    "start": "2804060",
    "end": "2810300"
  },
  {
    "text": "our process so just to wrap up right",
    "start": "2810300",
    "end": "2816630"
  },
  {
    "text": "transcoding is a really important part of preparing content for streaming on",
    "start": "2816630",
    "end": "2822359"
  },
  {
    "text": "services like eye view so our new system was designed specifically to be speedy",
    "start": "2822359",
    "end": "2828660"
  },
  {
    "text": "but cost-efficient we have small services that we ended up building in",
    "start": "2828660",
    "end": "2834000"
  },
  {
    "text": "node and in gold and we use ffmpeg to handle our transcript in work and we rely on AWS services for resiliency and",
    "start": "2834000",
    "end": "2842550"
  },
  {
    "text": "scale so in terms of scaling you know we take advantage of different techniques",
    "start": "2842550",
    "end": "2848520"
  },
  {
    "text": "here so that we can meet changing levels of demand but save on costs when we're actually not doing anything with those",
    "start": "2848520",
    "end": "2854670"
  },
  {
    "text": "instances and we really aim to deliver all of that within a very reasonable time frame and with reasonable cost so I",
    "start": "2854670",
    "end": "2862650"
  },
  {
    "text": "really hope you've enjoyed this overview of transcoding and how our transcript in system works thanks very much for your",
    "start": "2862650",
    "end": "2869730"
  },
  {
    "text": "time I really encourage you to please rate or ask questions on the app and",
    "start": "2869730",
    "end": "2875579"
  },
  {
    "text": "I'll be able to answer them in the arrested Dibble section next Thanks you",
    "start": "2875579",
    "end": "2882500"
  }
]
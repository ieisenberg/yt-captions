[
  {
    "start": "0",
    "end": "256000"
  },
  {
    "text": "[Music]",
    "start": "970",
    "end": "7838"
  },
  {
    "text": "i walked down in or fell down into the rabbit hole 2014 when i started to work at cloud",
    "start": "13280",
    "end": "18560"
  },
  {
    "text": "amqp where we provide rabbitmq as a service my goal when i started work at cloudy",
    "start": "18560",
    "end": "25599"
  },
  {
    "text": "mqp was that i wanted to make it make it more easy for everyone to get started with rabbitmq",
    "start": "25599",
    "end": "31199"
  },
  {
    "text": "i wanted to bring simple use cases to the public and also point out all the benefits of using rapidmq",
    "start": "31199",
    "end": "37040"
  },
  {
    "text": "so i started to write technical documentations update code examples write blog posts",
    "start": "37040",
    "end": "43680"
  },
  {
    "text": "more blog posts tutorials i answered questions at stack overflow",
    "start": "43680",
    "end": "49840"
  },
  {
    "text": "and i also created two ebooks so today sometimes",
    "start": "49840",
    "end": "55600"
  },
  {
    "text": "when when i'm at a bar having a beer or when i talk to unfamiliar people i ironically call myself an",
    "start": "55600",
    "end": "63120"
  },
  {
    "text": "influencer and the life of a blogger and an influencer of this kind is almost as",
    "start": "63120",
    "end": "68479"
  },
  {
    "text": "glamorous as you might think you get spoiled with spoiled with all kinds of luxury and you gotta hang out",
    "start": "68479",
    "end": "74720"
  },
  {
    "text": "with important people and i don't know if you can see it but it's a dog trying to disturb me um because i work",
    "start": "74720",
    "end": "81439"
  },
  {
    "text": "from home a lot i have during my time at cloud amqp replied to more than 3 000 emails about",
    "start": "81439",
    "end": "88320"
  },
  {
    "text": "rabbitmq and i have as you on you said been part of the urgent support team",
    "start": "88320",
    "end": "94479"
  },
  {
    "text": "where we respond to urgent support issues which could be when when a client need attention",
    "start": "94479",
    "end": "99920"
  },
  {
    "text": "directly when a server is running out of memory or when a rabbit mq is under heavy load",
    "start": "99920",
    "end": "106720"
  },
  {
    "text": "with all this writing many things were documented i met up with different customers to see how they are using",
    "start": "107119",
    "end": "112479"
  },
  {
    "text": "wrapped mq i and i wrote down lots of common use cases we collected",
    "start": "112479",
    "end": "117600"
  },
  {
    "text": "anti-patterns errors we see in setups configuration mistakes and all sorts of common mistakes that we",
    "start": "117600",
    "end": "123439"
  },
  {
    "text": "see things that can go wrong and things that works out well",
    "start": "123439",
    "end": "128959"
  },
  {
    "text": "so what kind of issues are we dealing with then first of all we have client-side problems where users like",
    "start": "128959",
    "end": "136400"
  },
  {
    "text": "you and me or client libraries are using rabbitmq in a bad way and then we have situations where things",
    "start": "136400",
    "end": "142800"
  },
  {
    "text": "are just not done in an optimal way way and then of course we have the",
    "start": "142800",
    "end": "148000"
  },
  {
    "text": "server side uh service running old versions misconfigured servers or when the setup of the server is not",
    "start": "148000",
    "end": "154239"
  },
  {
    "text": "configured for a selected use case so i will today spread the knowledge and",
    "start": "154239",
    "end": "159280"
  },
  {
    "text": "talk about what we have learned from running thousands of rabbit mq nodes but before we go into all the",
    "start": "159280",
    "end": "164879"
  },
  {
    "text": "things i have already written down all over the internet my name is lavista and i'm from umu",
    "start": "164879",
    "end": "170879"
  },
  {
    "text": "sweden um i i do work at 84 codes which is the",
    "start": "170879",
    "end": "176560"
  },
  {
    "text": "provider of cloud amqp i work as marketing manager and support engineer and lots in between",
    "start": "176560",
    "end": "185200"
  },
  {
    "text": "i have a growing family of lovely colleagues and many of them are with me here today",
    "start": "185200",
    "end": "190480"
  },
  {
    "text": "and they are always happy to talk so come by and talk to us in our booth downstairs 84 codes",
    "start": "190480",
    "end": "197680"
  },
  {
    "text": "is also the provider of three other services cloud kerafka which is apache have as a service",
    "start": "197680",
    "end": "203599"
  },
  {
    "text": "elephant sql postgresql as a service and the hosted message broker for am",
    "start": "203599",
    "end": "209120"
  },
  {
    "text": "i iot which is named the cloud mqtt we work remote from all over the world",
    "start": "209120",
    "end": "216239"
  },
  {
    "text": "and we also have customers from all over the world but we have our headquarters in stockholm",
    "start": "216239",
    "end": "223200"
  },
  {
    "text": "we are today the largest provider of manuscript mq servers with",
    "start": "223920",
    "end": "229120"
  },
  {
    "text": "lots of run thousands of running instances in seven clouds in 75 regions",
    "start": "229120",
    "end": "236400"
  },
  {
    "text": "and i will now give some recommendations where sum is equal to 16",
    "start": "236400",
    "end": "241760"
  },
  {
    "text": "and i will also give a summary of all these recommendations in the end of this presentation and i know i will repeat lots of things",
    "start": "241760",
    "end": "249120"
  },
  {
    "text": "that has already been said today but i did not really have time to rewrite my slides",
    "start": "249120",
    "end": "255920"
  },
  {
    "text": "so recommendation number one try to keep a connection and channel",
    "start": "255920",
    "end": "261440"
  },
  {
    "start": "256000",
    "end": "293000"
  },
  {
    "text": "count low each connection uses about 100 kilobyte of ram and of course even more if tls is used",
    "start": "261440",
    "end": "268479"
  },
  {
    "text": "so thousands of connection could be a could be a heavy burden on a on a rabbitmq server",
    "start": "268479",
    "end": "274479"
  },
  {
    "text": "so especially if you're running on a small instance and believe it or not",
    "start": "274479",
    "end": "281120"
  },
  {
    "text": "connection and channel leaks is one of the most common errors that we see but luckily it's mostly on staging and",
    "start": "281120",
    "end": "287759"
  },
  {
    "text": "dev servers number two make sure you don't open and",
    "start": "287759",
    "end": "294880"
  },
  {
    "start": "293000",
    "end": "397000"
  },
  {
    "text": "close connections or channels repeatedly doing that give you a higher latency as",
    "start": "294880",
    "end": "300160"
  },
  {
    "text": "more tcp packages has to be sent and received and the handshake process of an amqp",
    "start": "300160",
    "end": "305360"
  },
  {
    "text": "connection is as mentioned before quite involved and requires at least 70 cp packages and",
    "start": "305360",
    "end": "311199"
  },
  {
    "text": "again even more if tls is used rebedengu is optimized for a long-lived",
    "start": "311199",
    "end": "317600"
  },
  {
    "text": "connection so keep connections if you are able to and re keep them open and",
    "start": "317600",
    "end": "324960"
  },
  {
    "text": "reuse them if you are able to channels can be opened and closed more frequently",
    "start": "325120",
    "end": "330160"
  },
  {
    "text": "but even channels should try to be long-lived if possible and this is to not open a channel every",
    "start": "330160",
    "end": "336960"
  },
  {
    "text": "time you're publishing each process should ideally only create one tcp connection and use multiple",
    "start": "336960",
    "end": "343280"
  },
  {
    "text": "channels in that connection for different threads and we deal with servers that are under",
    "start": "343280",
    "end": "349280"
  },
  {
    "text": "heavy load due to opening and closing off connections almost every week",
    "start": "349280",
    "end": "354880"
  },
  {
    "text": "some clients can't keep long-lived connection to the server and this has as i said before an impact of latency",
    "start": "356160",
    "end": "363440"
  },
  {
    "text": "one way to avoid connection churn is to use a proxy that pulls connections and channels for reuse",
    "start": "363440",
    "end": "369039"
  },
  {
    "text": "and we have developed an amqp proxy for this and our benchmarking showed that that",
    "start": "369039",
    "end": "375199"
  },
  {
    "text": "proxy is increasing publishing speed with a magnitude or more and there is a",
    "start": "375199",
    "end": "381039"
  },
  {
    "text": "link to the github repo in the slides we are developing in many different",
    "start": "381039",
    "end": "387440"
  },
  {
    "text": "languages and this practice developing crystal which we are also really proud sponsor of",
    "start": "387440",
    "end": "395840"
  },
  {
    "start": "397000",
    "end": "485000"
  },
  {
    "text": "number three one should always separate connections for publish and consume",
    "start": "398880",
    "end": "404160"
  },
  {
    "text": "first of all imagine what will happen if you are using the same connection for publisher and consumer when the",
    "start": "404160",
    "end": "409520"
  },
  {
    "text": "connection is in flow control the flow control connection a flow",
    "start": "409520",
    "end": "414960"
  },
  {
    "text": "controlled connection is a connection that is being blocked and unblocked several times press again in order to keep the rate of",
    "start": "414960",
    "end": "420560"
  },
  {
    "text": "messages at a speed that the rest of the server can handle a publisher and consumer on the same",
    "start": "420560",
    "end": "426479"
  },
  {
    "text": "connection might worsen this pro this flow control since you might not be",
    "start": "426479",
    "end": "432240"
  },
  {
    "text": "able to consume messages when the connection is being blocked secondly rabbit mq can apply back pressure on the",
    "start": "432240",
    "end": "439039"
  },
  {
    "text": "tcp connection when the publisher is sending too much too many messages to the server",
    "start": "439039",
    "end": "444639"
  },
  {
    "text": "and if you can see zoom on the same tcp connection the server might not receive the message",
    "start": "444639",
    "end": "449680"
  },
  {
    "text": "acknowledgement from the from the client and so the consumer performance is affected too",
    "start": "449680",
    "end": "456160"
  },
  {
    "text": "and with lower consumer speed the server might be overwhelmed after a while i will start to speak",
    "start": "456160",
    "end": "461680"
  },
  {
    "text": "swedish as i said swedish and if you know something about sweden",
    "start": "461680",
    "end": "467440"
  },
  {
    "text": "except swedish fika then it might be that we love queuing what we don't like is large",
    "start": "467440",
    "end": "473680"
  },
  {
    "text": "queues or when people in some way try to squeeze in before you in the line",
    "start": "473680",
    "end": "478720"
  },
  {
    "text": "so recommendation number four comes straight from my heart uh if it's use your use case try keeping",
    "start": "478720",
    "end": "486560"
  },
  {
    "start": "485000",
    "end": "601000"
  },
  {
    "text": "your queue as short as possible a message published to an empty queue will go straight up to",
    "start": "486560",
    "end": "491680"
  },
  {
    "text": "the consumer as soon as the key receives the message and of course a persistent message also",
    "start": "491680",
    "end": "497360"
  },
  {
    "text": "will be written to disk",
    "start": "497360",
    "end": "500400"
  },
  {
    "text": "it's recommended to have less than ten thousand messages in a queue and many messages in a queue",
    "start": "503520",
    "end": "509199"
  },
  {
    "text": "can also put a heavy load on the ram usage and in order to free up ram rapid temp",
    "start": "509199",
    "end": "514399"
  },
  {
    "text": "you start flashing or page out messages to disk and this paycheck process usually takes time and",
    "start": "514399",
    "end": "521200"
  },
  {
    "text": "blocks the queue from processing messages when there are many messages to page out",
    "start": "521200",
    "end": "527519"
  },
  {
    "text": "another thing that is bad with with large queues is that it's time consuming to restart",
    "start": "527519",
    "end": "533040"
  },
  {
    "text": "a cluster with many queues since the index has to be rebuilt and it's also it also",
    "start": "533040",
    "end": "539680"
  },
  {
    "text": "it's also time consuming to sync messages between nodes in the cluster",
    "start": "539680",
    "end": "544720"
  },
  {
    "text": "large queues is also a very very common error that we have for our that our customers have uh",
    "start": "544720",
    "end": "551760"
  },
  {
    "text": "a queue is just piling up due to missing consumers or due to that clients are publishing",
    "start": "551760",
    "end": "558800"
  },
  {
    "text": "messages faster than the consumers able to handle the messages and then eventually the server is",
    "start": "558800",
    "end": "564880"
  },
  {
    "text": "overloaded and killed and when this happens we usually add up more power to those",
    "start": "564880",
    "end": "571680"
  },
  {
    "text": "machines and but it still takes time to restart the cluster because yeah because of the rebuilding of the indexes",
    "start": "571680",
    "end": "578320"
  },
  {
    "text": "etc it's sometimes recommended for",
    "start": "578320",
    "end": "584399"
  },
  {
    "text": "applications that often get hit by spikes of messages and where throughput is more important than anything else",
    "start": "584399",
    "end": "590480"
  },
  {
    "text": "to set the max length on the queue because this key keeps the queue short by discarding messages",
    "start": "590480",
    "end": "596240"
  },
  {
    "text": "from the from the head of the queue",
    "start": "596240",
    "end": "600080"
  },
  {
    "start": "601000",
    "end": "669000"
  },
  {
    "text": "number five uh a feature called acq was added in reptimq 3.6 and lazyq",
    "start": "602320",
    "end": "610079"
  },
  {
    "text": "writes messages immediately to disk and so spreading the work out over time",
    "start": "610079",
    "end": "615760"
  },
  {
    "text": "instead of taking a risk of a performance hit somewhere down the road messages are only loaded into memory",
    "start": "615760",
    "end": "622079"
  },
  {
    "text": "when they are needed and thereby the ram usage is minimized but this report time will be longer",
    "start": "622079",
    "end": "628640"
  },
  {
    "text": "with lasik use so lazy qs gives you a more predictable and smooth performance curve",
    "start": "628640",
    "end": "634240"
  },
  {
    "text": "without any sudden drops but at the cost of a little overhead",
    "start": "634240",
    "end": "639600"
  },
  {
    "text": "and if you're sending many messages at once like if you're processing batch jobs or",
    "start": "639600",
    "end": "645200"
  },
  {
    "text": "if you think that your consumer will not keep up with the speed of the publisher all the",
    "start": "645200",
    "end": "651200"
  },
  {
    "text": "time then we recommend to enable lazy queues and we think that you can ignore",
    "start": "651200",
    "end": "658079"
  },
  {
    "text": "lasik use if you require high performance or if you know that your queue will always stay short due to",
    "start": "658079",
    "end": "664000"
  },
  {
    "text": "a max links policy or something like that",
    "start": "664000",
    "end": "668480"
  },
  {
    "start": "669000",
    "end": "695000"
  },
  {
    "text": "number six the repdemq management interface collects and calculates",
    "start": "669600",
    "end": "674640"
  },
  {
    "text": "metrics for every queue connection and channel in the cluster and setting revenue management statistic",
    "start": "674640",
    "end": "681279"
  },
  {
    "text": "rate mode to detailed could have a serious performance impact and should not be used in production if",
    "start": "681279",
    "end": "688079"
  },
  {
    "text": "you have thousands upon thousands of active queues or consumers",
    "start": "688079",
    "end": "693680"
  },
  {
    "start": "695000",
    "end": "823000"
  },
  {
    "text": "recommendation number seven",
    "start": "695279",
    "end": "698959"
  },
  {
    "text": "accused are single threaded in rabbit mq and one queue can handle up to 50 000",
    "start": "700720",
    "end": "706480"
  },
  {
    "text": "messages a second yeah you will i'm losing my voice",
    "start": "706480",
    "end": "717839"
  },
  {
    "text": "you will therefore get better performance if you split your queues over different cores and nodes and if you route messages between",
    "start": "719120",
    "end": "725600"
  },
  {
    "text": "multiple multiple queues",
    "start": "725600",
    "end": "731839"
  },
  {
    "text": "and queues are bound to the node where they are first declared so all messages routed to specific queue will end up on",
    "start": "731839",
    "end": "737360"
  },
  {
    "text": "the node where that q resides and you can of course manually split queues evenly between nodes but the",
    "start": "737360",
    "end": "743279"
  },
  {
    "text": "downside is that you need to remember where where that queue is located and we recommend two plugins that can",
    "start": "743279",
    "end": "749600"
  },
  {
    "text": "help you if you have multiple nodes or or a single node cluster with with multiple cores",
    "start": "749600",
    "end": "755920"
  },
  {
    "text": "and it's the consistent hash exchange plugin and ribbon view sharding",
    "start": "755920",
    "end": "762000"
  },
  {
    "text": "the consistent exchange plugin has been mentioned a lot today",
    "start": "762959",
    "end": "769120"
  },
  {
    "text": "and the plugin allows you to use an exchange to load balance messages between cues so messages sent to an exchange are",
    "start": "769120",
    "end": "775760"
  },
  {
    "text": "consistently and equally distributed across many bounded queues and it could quickly",
    "start": "775760",
    "end": "781920"
  },
  {
    "text": "become hard to do this manually without adding too much information about number of queues and their bindings into the publishers",
    "start": "781920",
    "end": "789600"
  },
  {
    "text": "and note that it's important to consume from all queues bounded to the exchange when when using this plugin",
    "start": "789920",
    "end": "797680"
  },
  {
    "text": "the sharding plugin arrow attempt your sharding does the partitioning of cues",
    "start": "799200",
    "end": "804399"
  },
  {
    "text": "automatically for you so once you have defined and exchanges sharded the supporting cues are",
    "start": "804399",
    "end": "810240"
  },
  {
    "text": "automatically created on every cluster node and message messages are sharded across them",
    "start": "810240",
    "end": "816399"
  },
  {
    "text": "and sharding shows one queue to the consumer but it could be manic used running behind it in the background",
    "start": "816399",
    "end": "823519"
  },
  {
    "start": "823000",
    "end": "916000"
  },
  {
    "text": "and then we have priorities cues can have zero or more priorities and behind the",
    "start": "823600",
    "end": "829680"
  },
  {
    "text": "scenes of a priority queue a new backing queue is created so each priority level uses an internal",
    "start": "829680",
    "end": "835600"
  },
  {
    "text": "queue on the airline virtual machine which takes up some resources and using 255 or even thousands of priorities",
    "start": "835600",
    "end": "843519"
  },
  {
    "text": "means you will have resource usage usage similar to having close to that many cues",
    "start": "843519",
    "end": "849920"
  },
  {
    "text": "and in most use cases it's sufficient to have no more than five priority levels",
    "start": "850320",
    "end": "857839"
  },
  {
    "text": "this is fixed in reps mq 3.7.6",
    "start": "858079",
    "end": "863680"
  },
  {
    "text": "the max priority cap for queues is now enforced and set to 255 and applications",
    "start": "863680",
    "end": "871600"
  },
  {
    "text": "that rely on a higher number of priorities will break and such applications must be updated to use no no more than 255 priorities because",
    "start": "871600",
    "end": "879839"
  },
  {
    "text": "um we had like two weeks ago or maybe three weeks ago a case where",
    "start": "879839",
    "end": "885519"
  },
  {
    "text": "two consumers were starting up rabbit mq and it took really long time and memory usage just exploded",
    "start": "885519",
    "end": "892000"
  },
  {
    "text": "as you can see there and this was despite few cues and few",
    "start": "892000",
    "end": "898800"
  },
  {
    "text": "messages which is the common common error when it takes long time to restart the broker",
    "start": "898800",
    "end": "904959"
  },
  {
    "text": "but this time it was due to many priorities priority levels",
    "start": "904959",
    "end": "913839"
  },
  {
    "start": "916000",
    "end": "961000"
  },
  {
    "text": "everyone needs to be prepared for broker restart broker hardware failure or server crashes and to ensure that",
    "start": "916959",
    "end": "923760"
  },
  {
    "text": "messages and broker definitions survive restarts we know to we need to know that ensure that they are on disk",
    "start": "923760",
    "end": "930639"
  },
  {
    "text": "and messages exchanges and cues that are not durable and persistent are lost during a broker restart so make",
    "start": "930639",
    "end": "938240"
  },
  {
    "text": "sure that your queue is declared as durable and messages are just are sent with delivery mode persistent",
    "start": "938240",
    "end": "945440"
  },
  {
    "text": "and remember persistent messages are heavier as they have to be has to be written to",
    "start": "945440",
    "end": "950800"
  },
  {
    "text": "disk so for high performance it's better to use transit messages and temporary or non",
    "start": "950800",
    "end": "955920"
  },
  {
    "text": "non-durable cues",
    "start": "955920",
    "end": "959040"
  },
  {
    "start": "961000",
    "end": "1165000"
  },
  {
    "text": "and then we have the prefetch which is used to specify how many messages that is sent to the consumer",
    "start": "961680",
    "end": "968720"
  },
  {
    "text": "and cached by the repdemke client library how many messages the client can receive before acknowledging a message",
    "start": "968720",
    "end": "975440"
  },
  {
    "text": "and it's used to get as much out of the consumer as possible and rep thank you default prefetch",
    "start": "975440",
    "end": "980839"
  },
  {
    "text": "setting gives clients an unlimited buffer meaning that rival timecube by default",
    "start": "980839",
    "end": "986320"
  },
  {
    "text": "send as many messages as it can to any consumer that looks ready to receive them or accept them and",
    "start": "986320",
    "end": "993360"
  },
  {
    "text": "messages that are sent or cached by the yes i said the revenue client library in the consumer",
    "start": "993360",
    "end": "998720"
  },
  {
    "text": "until it has been processed so not setting in prefetch can lead to clients running out of memory and makes",
    "start": "998720",
    "end": "1004880"
  },
  {
    "text": "it impossible to scale out with more consumers in rabbit mq we got uh wrestling q 3.7",
    "start": "1004880",
    "end": "1013279"
  },
  {
    "text": "we got a new option to adjust the default prefetch value and this value is by default set 2000 on",
    "start": "1013279",
    "end": "1019520"
  },
  {
    "text": "[Music] on all new cloud and qp servers",
    "start": "1019520",
    "end": "1025038"
  },
  {
    "text": "with version 3.7 or or higher or it doesn't really exist yet but soon",
    "start": "1025039",
    "end": "1032880"
  },
  {
    "text": "a too small prefetch count may hurt performance since it's of the time of the time waiting for",
    "start": "1033679",
    "end": "1038720"
  },
  {
    "text": "permissions to send more messages and this figure is illustrating a long idling time",
    "start": "1038720",
    "end": "1045360"
  },
  {
    "text": "in the example we have a prefetch setting of one and this means that rapidmq won't send out the next message",
    "start": "1045360",
    "end": "1051039"
  },
  {
    "text": "until the round trip completes where round trip is deliver process and acknowledge and we have in",
    "start": "1051039",
    "end": "1058559"
  },
  {
    "text": "this image and a total round trip time of 125 milliseconds with a processing time of",
    "start": "1058559",
    "end": "1063840"
  },
  {
    "text": "only 5 milliseconds so a too low value will keep the consuming",
    "start": "1063840",
    "end": "1069440"
  },
  {
    "text": "consumer idling a lot since since they need to wait for messages to arrive",
    "start": "1069440",
    "end": "1075840"
  },
  {
    "text": "a large prefix account on the other hand uh could deliver lots of messages to one single consumer",
    "start": "1077919",
    "end": "1083679"
  },
  {
    "text": "and keep that consumer busy while other consumers are held in idling state and in this image",
    "start": "1083679",
    "end": "1089679"
  },
  {
    "text": "we have um one client that is has a lot to do and one that is just waiting",
    "start": "1089679",
    "end": "1095760"
  },
  {
    "text": "and has nothing to do",
    "start": "1095760",
    "end": "1098799"
  },
  {
    "text": "so if you have one single or a few consumers and are processing message quickly we recommend prefetching",
    "start": "1101520",
    "end": "1107360"
  },
  {
    "text": "man and messy messages at once and try to keep your client as busy as possible",
    "start": "1107360",
    "end": "1112480"
  },
  {
    "text": "and if you have about the same processing time all the time and the network behavior remains the",
    "start": "1112480",
    "end": "1117600"
  },
  {
    "text": "same you can use the total round trip time divided by processing time on the client for each message to",
    "start": "1117600",
    "end": "1124080"
  },
  {
    "text": "get the estimated prefetch value for each message",
    "start": "1124080",
    "end": "1129039"
  },
  {
    "text": "and if you have many consumers and short processing time we recommend the lower prefetch value",
    "start": "1131440",
    "end": "1136720"
  },
  {
    "text": "than for a single or few consumer and finally if you have many consumers and or long processing time",
    "start": "1136720",
    "end": "1145679"
  },
  {
    "text": "we recommend setting prefetch count to one so that messages are evenly distributed among all your workers and here's another",
    "start": "1147280",
    "end": "1154559"
  },
  {
    "text": "thing that you should remember that's it's that your client if your client outright messages the pre-patch value have no",
    "start": "1154559",
    "end": "1162720"
  },
  {
    "text": "effect hype uh increases servers throughput",
    "start": "1162840",
    "end": "1169120"
  },
  {
    "start": "1165000",
    "end": "1210000"
  },
  {
    "text": "at the cost of increased startup time so when you enable hype rabbit mq is compiled at startup and this throughput increases with 20 to",
    "start": "1169120",
    "end": "1176960"
  },
  {
    "text": "80 according to benchmark tests the drawback of hype is that it's that",
    "start": "1176960",
    "end": "1182960"
  },
  {
    "text": "startup time increases quite a lot too one to three minutes and it's therefore not recommended",
    "start": "1182960",
    "end": "1189520"
  },
  {
    "text": "if you require high availability due to this long startup time",
    "start": "1189520",
    "end": "1194880"
  },
  {
    "text": "we don't consider hypes experimental any longer six percent of our clusters has hype",
    "start": "1195440",
    "end": "1202000"
  },
  {
    "text": "enabled and we haven't seen issues with hype for a really long time",
    "start": "1202000",
    "end": "1208640"
  },
  {
    "start": "1210000",
    "end": "1283000"
  },
  {
    "text": "acknowledgements let the server and client know if the message has to be re-transmitted",
    "start": "1210480",
    "end": "1215520"
  },
  {
    "text": "again and the client can either act a message when it receives it or when the client",
    "start": "1215520",
    "end": "1221039"
  },
  {
    "text": "has completely processed the message so pay attention to where in your",
    "start": "1221039",
    "end": "1228080"
  },
  {
    "text": "consumer logic you are acknowledging messages by consuming a application that receives",
    "start": "1228080",
    "end": "1235360"
  },
  {
    "text": "essential messages should not acknowledge messages until it has finished whatever it needs to do with them so that unprocessed messages don't",
    "start": "1235360",
    "end": "1243360"
  },
  {
    "text": "go missing in case of worker crashes exceptions etc and the",
    "start": "1243360",
    "end": "1248880"
  },
  {
    "text": "acknowledgement has a performance impact so for the fastest possible throughput",
    "start": "1248880",
    "end": "1254559"
  },
  {
    "text": "manual x should be disabled publish confirm is the same thing but",
    "start": "1254559",
    "end": "1260880"
  },
  {
    "text": "for publishing and the server acts when it has received a message from the publisher",
    "start": "1260880",
    "end": "1266880"
  },
  {
    "text": "publish confirm also has a performance impact but however once you keep in mind that",
    "start": "1266880",
    "end": "1273600"
  },
  {
    "text": "it's required if the publisher needs messages to be processed at least once",
    "start": "1273600",
    "end": "1281200"
  },
  {
    "start": "1283000",
    "end": "1445000"
  },
  {
    "text": "thanks to the rapidmq team great improvements are made all the time which is really great in 3.7 we go to",
    "start": "1285120",
    "end": "1292559"
  },
  {
    "text": "the default prefetch as i just mentioned and this will probably completely remove cases where the consumer",
    "start": "1292559",
    "end": "1298559"
  },
  {
    "text": "has been killed due to uh to a too large message delivery due to an unlimited unlimited prefetch",
    "start": "1298559",
    "end": "1304720"
  },
  {
    "text": "value and individual we host message stores are now available and this helps us at cloud and qpa a lot because",
    "start": "1304720",
    "end": "1313280"
  },
  {
    "text": "we have two subscription plans that are shared plans which gives a customer a single v-host",
    "start": "1313280",
    "end": "1318799"
  },
  {
    "text": "on a multi-tenant server and this means that our share plans can be even more",
    "start": "1318799",
    "end": "1324559"
  },
  {
    "text": "more stable and even if you have multiple v-hosts on a dedicated plan it will also be more",
    "start": "1324559",
    "end": "1330840"
  },
  {
    "text": "stable rabbit mq 3.6 had the new feature lazy",
    "start": "1330840",
    "end": "1337360"
  },
  {
    "text": "qs that gave many of our customers a more predictable and stable cluster and we found the laci q feature so good",
    "start": "1337360",
    "end": "1345280"
  },
  {
    "text": "that all our new clusters with reptimq version 3.6 or larger are has",
    "start": "1345280",
    "end": "1353840"
  },
  {
    "text": "lazy queues enabled by default many of our customers with issues are",
    "start": "1353840",
    "end": "1360320"
  },
  {
    "text": "running old versions or or documented unstable versions",
    "start": "1360320",
    "end": "1365440"
  },
  {
    "text": "and 3.6 i had many memory problems up to version 3.6.14",
    "start": "1365440",
    "end": "1371440"
  },
  {
    "text": "and 3.5.7 was good but lacks some good features like like the lazy queue feature",
    "start": "1371440",
    "end": "1378720"
  },
  {
    "text": "and we still have lots of servers running 3.5 and this is the image is a",
    "start": "1384080",
    "end": "1390320"
  },
  {
    "text": "reptime q version distribution between cloud and qp customers and it's nice to see that so many has",
    "start": "1390320",
    "end": "1396559"
  },
  {
    "text": "upgraded to 3.7 because it's always something we try to push to",
    "start": "1396559",
    "end": "1402000"
  },
  {
    "text": "like we want our customers to run old stable new stable versions",
    "start": "1402000",
    "end": "1409120"
  },
  {
    "text": "and we always test new versions before that we set them as available versions in cloud amqp",
    "start": "1409440",
    "end": "1417760"
  },
  {
    "text": "so uh the the menu that is selected in our drop-down menu in",
    "start": "1417760",
    "end": "1423120"
  },
  {
    "text": "on the page where you select which version you want to run that that that is the version we recommend at the",
    "start": "1423120",
    "end": "1428880"
  },
  {
    "text": "moment so this recommendation is stay up to date with things that is happening in",
    "start": "1428880",
    "end": "1434400"
  },
  {
    "text": "rapid mq and say use a stable version and also a stable airline version and a stable",
    "start": "1434400",
    "end": "1441120"
  },
  {
    "text": "client library version some plugins might be super nice to have",
    "start": "1441120",
    "end": "1447760"
  },
  {
    "start": "1445000",
    "end": "1477000"
  },
  {
    "text": "but on the other hand they might consume a lot of resources therefore they are not recommended in",
    "start": "1447760",
    "end": "1454159"
  },
  {
    "text": "production servers so make sure to disable plugins that you are not using an example of a plugin that we are",
    "start": "1454159",
    "end": "1461600"
  },
  {
    "text": "using a lot but that we are disabling every time every time we are finished using it is the top plugin",
    "start": "1461600",
    "end": "1467120"
  },
  {
    "text": "which we are using when we are troubleshooting rabbit and raped mq servers for our customers",
    "start": "1467120",
    "end": "1473840"
  },
  {
    "text": "number 15 even unused queues takes up some resources q index management statistics etc",
    "start": "1476240",
    "end": "1484880"
  },
  {
    "start": "1477000",
    "end": "1503000"
  },
  {
    "text": "and leaving temporary cues can eventually cause that reptile mq runs out of memory so make",
    "start": "1484880",
    "end": "1490880"
  },
  {
    "text": "sure that you don't leave unused cues left behind and the set temporary rare cues is how to delete",
    "start": "1490880",
    "end": "1496480"
  },
  {
    "text": "exclusive or auto expire",
    "start": "1496480",
    "end": "1501840"
  },
  {
    "start": "1503000",
    "end": "1540000"
  },
  {
    "text": "many of our customers are creating v-hosts a custom vhost and then they forgot to add",
    "start": "1503039",
    "end": "1509120"
  },
  {
    "text": "hi policy and then the newbie host and which costs message lost during netsplits um",
    "start": "1509120",
    "end": "1515270"
  },
  {
    "text": "[Music] and we also we have an hi policy on all",
    "start": "1515270",
    "end": "1520559"
  },
  {
    "text": "our clusters even single node clusters because we're using that when when customers are",
    "start": "1520559",
    "end": "1526320"
  },
  {
    "text": "upgrading upgrading to new versions or if they want to change from",
    "start": "1526320",
    "end": "1531360"
  },
  {
    "text": "to node cluster to three node cluster we use that and if they want to upgrade the wrap them q versions etc",
    "start": "1531360",
    "end": "1538400"
  },
  {
    "start": "1540000",
    "end": "1628000"
  },
  {
    "text": "and here is a summary of it all uh try to have short cues use long live",
    "start": "1540240",
    "end": "1546080"
  },
  {
    "text": "connection have limited use of priority queues use multiple queues",
    "start": "1546080",
    "end": "1551120"
  },
  {
    "text": "consumers and split your queues over different use a stable airline and webdmq version",
    "start": "1551120",
    "end": "1558159"
  },
  {
    "text": "and also client library version disable plugins you're not using have channels on all your connections",
    "start": "1558159",
    "end": "1566799"
  },
  {
    "text": "and separate connections for publisher and consumer don't set management statistic rate mode",
    "start": "1566960",
    "end": "1574159"
  },
  {
    "text": "mode to detail in production delete you unused queues and set temporary cues s out to delete",
    "start": "1574159",
    "end": "1582080"
  },
  {
    "text": "how to delete and for those of you who are interested in recommendation for",
    "start": "1582080",
    "end": "1587120"
  },
  {
    "text": "high performance then we it's even more important which with your short queues and use the max length",
    "start": "1587120",
    "end": "1594080"
  },
  {
    "text": "if you're pos if possible do not use lazy queues send transit messages",
    "start": "1594080",
    "end": "1599360"
  },
  {
    "text": "disable manual x and publish confirms avoid multiple nodes enable revit mq hype",
    "start": "1599360",
    "end": "1607919"
  },
  {
    "text": "and for those who are more interested in high availability enable lasik use have two nodes and",
    "start": "1607919",
    "end": "1613600"
  },
  {
    "text": "don't forget to add the hi policy use persistent messages to durable cues",
    "start": "1613600",
    "end": "1619039"
  },
  {
    "text": "and do not enable hype and the last one is due to",
    "start": "1619039",
    "end": "1624080"
  },
  {
    "text": "this long startup time we have created a diagnostic tool that",
    "start": "1624080",
    "end": "1629600"
  },
  {
    "start": "1628000",
    "end": "1765000"
  },
  {
    "text": "is available from the cloudinequi control panel where customers can validate the setup",
    "start": "1629600",
    "end": "1634880"
  },
  {
    "text": "repeat setup and get a score of this setup and it's been used by many customers and",
    "start": "1634880",
    "end": "1640720"
  },
  {
    "text": "it's nice to have when we when we get a support request we could check this one first and then always get",
    "start": "1640720",
    "end": "1646559"
  },
  {
    "text": "back to customers say you need to fix this this this and this and then the server is all usually running",
    "start": "1646559",
    "end": "1652640"
  },
  {
    "text": "much better after that and here are examples of examples of",
    "start": "1652640",
    "end": "1659760"
  },
  {
    "text": "things that are validated in the agnostic this diagnostic tool and i think i've talked about many of",
    "start": "1659760",
    "end": "1665679"
  },
  {
    "text": "them but not all of them and just come down and talk to us if you",
    "start": "1665679",
    "end": "1670720"
  },
  {
    "text": "want to see how overseas only if you want to see it as we have seen best practice",
    "start": "1670720",
    "end": "1677440"
  },
  {
    "text": "recommendations are different for different use cases and some applications require high throughput while other",
    "start": "1677440",
    "end": "1683919"
  },
  {
    "text": "applications are publishing batch jobs that can be delayed for a while and other applications just need to have",
    "start": "1683919",
    "end": "1689760"
  },
  {
    "text": "lots of connections and trade-offs have to be done between performance and guaranteed message delivery etc",
    "start": "1689760",
    "end": "1697360"
  },
  {
    "text": "and our customers are today able to select number of nodes when they are creating a cluster a single node for",
    "start": "1697360",
    "end": "1703360"
  },
  {
    "text": "high performance and two or three nodes mainly for high availability and or consist consistency",
    "start": "1703360",
    "end": "1711840"
  },
  {
    "text": "we also have lots of other features built into the cloud and cubic control panel like the option to configure alarms",
    "start": "1712399",
    "end": "1720799"
  },
  {
    "text": "for queue links or for missing consumers etc and users can view how many messages there has been in",
    "start": "1720799",
    "end": "1728720"
  },
  {
    "text": "the queue over time which helps us a lot when we are troubleshooting",
    "start": "1728720",
    "end": "1734880"
  },
  {
    "text": "our servers since statistics for the queues are available all the time",
    "start": "1734880",
    "end": "1740399"
  },
  {
    "text": "and we also have show metrics for usage like cpu ram and the disk",
    "start": "1740399",
    "end": "1747360"
  },
  {
    "text": "and we have some seen many different use cases and our future plan at cloud amqp is to make it",
    "start": "1748159",
    "end": "1754159"
  },
  {
    "text": "even easier for customers to quickly set up a cluster specified for a selected use case based on",
    "start": "1754159",
    "end": "1760480"
  },
  {
    "text": "best practice recommendations",
    "start": "1760480",
    "end": "1766559"
  },
  {
    "start": "1765000",
    "end": "1811000"
  },
  {
    "text": "this is my final slide and it would be nice if we could have a",
    "start": "1766559",
    "end": "1772080"
  },
  {
    "text": "list like this in a community like a list of recommendations because it makes it makes it so much",
    "start": "1772080",
    "end": "1777440"
  },
  {
    "text": "easier for beginners to start using rabbit mq so if you have any recommendations of things that we",
    "start": "1777440",
    "end": "1783520"
  },
  {
    "text": "need to add or if you have different opinions",
    "start": "1783520",
    "end": "1788880"
  },
  {
    "text": "about something just let me know or send me an email or reach out to me",
    "start": "1788880",
    "end": "1795840"
  },
  {
    "text": "[Applause]",
    "start": "1796590",
    "end": "1802869"
  },
  {
    "text": "thanks you",
    "start": "1806840",
    "end": "1812398"
  }
]
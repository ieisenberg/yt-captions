[
  {
    "text": "[Music] hello thanks for you for all of you who",
    "start": "6990",
    "end": "12639"
  },
  {
    "text": "are here staying with me um even if you're are not so many as I hoped but never mind um so I would like to talk",
    "start": "12639",
    "end": "19880"
  },
  {
    "text": "about uh graph databases especially scaling of graph databases um because that is a pretty",
    "start": "19880",
    "end": "26880"
  },
  {
    "text": "hard problem so title of my talk is handling billions of edges or even more inside one graph",
    "start": "26880",
    "end": "32960"
  },
  {
    "text": "database what are graph databases who is working with them already no one great",
    "start": "32960",
    "end": "39840"
  },
  {
    "text": "okay then I will explain them so the general idea is of a graph database is that they store schema free objects so",
    "start": "39840",
    "end": "47520"
  },
  {
    "text": "documents which can have arbitrary values and arbitrary keys to them and they do not have necessarily be the same",
    "start": "47520",
    "end": "54480"
  },
  {
    "text": "every time and these objects are called vertices and then they store the relations between these vertices which",
    "start": "54480",
    "end": "60879"
  },
  {
    "text": "is the important part of a graph database and these are called edges and",
    "start": "60879",
    "end": "65960"
  },
  {
    "text": "these edges again can be schema free objects and all of these edges have a",
    "start": "65960",
    "end": "71000"
  },
  {
    "text": "Direction so they start at one point and they end at one",
    "start": "71000",
    "end": "75640"
  },
  {
    "text": "point and the query mechanisms that you have for graph database is that you can query alongside these edges in both",
    "start": "76080",
    "end": "83159"
  },
  {
    "text": "directions so either Follow The Edge or go con to the edge or don't care for the",
    "start": "83159",
    "end": "88240"
  },
  {
    "text": "direction and you can easily query ranges of steps so you can say please",
    "start": "88240",
    "end": "93520"
  },
  {
    "text": "start with two edges three edges four edges five edges in a simple statement",
    "start": "93520",
    "end": "98799"
  },
  {
    "text": "which is really really hard if you do it in a relational world because then you have to write three different joint",
    "start": "98799",
    "end": "104040"
  },
  {
    "text": "statements and then join everything together and you can even do something which is not possible at all in",
    "start": "104040",
    "end": "109799"
  },
  {
    "text": "relational database you can say start here and go as long as you need to find the target an undefined number of steps",
    "start": "109799",
    "end": "117399"
  },
  {
    "text": "in between or you can say this is thought this is Target please give me the shortest way between",
    "start": "117399",
    "end": "123320"
  },
  {
    "text": "them let's take a look at some typical graph queries which graph uh graph",
    "start": "123320",
    "end": "129000"
  },
  {
    "text": "databases are very very good at so this is the graph that we have stored in our database vertices which are persons and",
    "start": "129000",
    "end": "135879"
  },
  {
    "text": "the relations between them um in this graph I actually ignore the direction when querying um and the first query I want",
    "start": "135879",
    "end": "142959"
  },
  {
    "text": "to ask is give me all the friends of Ellis so that would be start at Ellis and give me all the direct",
    "start": "142959",
    "end": "148360"
  },
  {
    "text": "neighbors there we go it's Bob Charlie and Dave next query give me all the",
    "start": "148360",
    "end": "154000"
  },
  {
    "text": "friends of friends so I'm now starting again at Ellis go to their friends and I",
    "start": "154000",
    "end": "159040"
  },
  {
    "text": "just want her their friends again but not the ones that are already friends",
    "start": "159040",
    "end": "164200"
  },
  {
    "text": "with Alice so only Eve and Frank are important for this",
    "start": "164200",
    "end": "170080"
  },
  {
    "text": "one and I can also say oh I know now Ellis and I know Eve and I would like to",
    "start": "170080",
    "end": "175640"
  },
  {
    "text": "have the shortest pass between them which could be using Bob or over Charlie",
    "start": "175640",
    "end": "181239"
  },
  {
    "text": "so it's not always um a unique result can have some um",
    "start": "181239",
    "end": "188239"
  },
  {
    "text": "variations and what you can also do is if you're in the tube you have bought a ticket which allows you to go six",
    "start": "188799",
    "end": "194360"
  },
  {
    "text": "stations at most and you can switch lines as often as you want can just start here and go for six",
    "start": "194360",
    "end": "202680"
  },
  {
    "text": "destinations which is really really easy to Define in a graph",
    "start": "202680",
    "end": "207200"
  },
  {
    "text": "database and the other type of queries that you have in a graph database which makes them very very powerful are",
    "start": "208560",
    "end": "214159"
  },
  {
    "text": "so-called pattern matching queries you define a pattern that you're searching for in your entire base uh",
    "start": "214159",
    "end": "220120"
  },
  {
    "text": "graph which you can then match on top of the data that you have so in my pattern I have Ellis and the pattern is I know",
    "start": "220120",
    "end": "227200"
  },
  {
    "text": "that Ellis had has bought at least two product has um at least two hobbies and",
    "start": "227200",
    "end": "232439"
  },
  {
    "text": "I want to find all the friends that have the same Hobbies at least two of them so this is the pattern that I put on top of",
    "start": "232439",
    "end": "238640"
  },
  {
    "text": "my database and I find the and it can make it even more complicated",
    "start": "238640",
    "end": "244799"
  },
  {
    "text": "classical recommendation engine Alis has bought something her friend has bought",
    "start": "244799",
    "end": "249959"
  },
  {
    "text": "something and I want to find everything that this friend has bought which Ellis hasn't and then I can find these",
    "start": "249959",
    "end": "258040"
  },
  {
    "text": "products and those queries are very very good for graph database they optimized for them they are fast and solving them",
    "start": "258040",
    "end": "264479"
  },
  {
    "text": "they are not good in this classical aggregation queries so give me all the users which have an age attribute",
    "start": "264479",
    "end": "271199"
  },
  {
    "text": "between 21 and 35 or give me the overall age distribution of all my",
    "start": "271199",
    "end": "277400"
  },
  {
    "text": "uses or group all the users by their name it is possible to express this in a",
    "start": "277400",
    "end": "282600"
  },
  {
    "text": "graph database but they're not designed for it it is typically very very",
    "start": "282600",
    "end": "287639"
  },
  {
    "text": "slow what is the underlying technology the underlying technique to query a database and this is called a traversal",
    "start": "287639",
    "end": "295680"
  },
  {
    "text": "we first pick one start vertex which I call S we collect all the edges that are",
    "start": "295680",
    "end": "302080"
  },
  {
    "text": "attached to this vertex we apply some filtering and probably slow throw away some of the",
    "start": "302080",
    "end": "308280"
  },
  {
    "text": "results and pick the other vertices that are still connected that match my filter conditions pick one of them and again",
    "start": "308280",
    "end": "315800"
  },
  {
    "text": "get their edges select the vertices filter and then finally I have some",
    "start": "315800",
    "end": "321479"
  },
  {
    "text": "result that I can return then I have to go back okay a",
    "start": "321479",
    "end": "326600"
  },
  {
    "text": "doesn't have any more edges go back to the other one which is B and now get edges of B again apply the",
    "start": "326600",
    "end": "333720"
  },
  {
    "text": "filters return the result and then get back B doesn't have any more edges s doesn't have any more edges so we are",
    "start": "333720",
    "end": "340600"
  },
  {
    "text": "done result would be this path and the other",
    "start": "340600",
    "end": "345680"
  },
  {
    "text": "path let's talk a bit of about complexity because that is one of the strength of graph databases what we have",
    "start": "346800",
    "end": "354000"
  },
  {
    "text": "to do in every traversal is first we have to find the starting point the S",
    "start": "354000",
    "end": "359240"
  },
  {
    "text": "and that depends on the index that we can use for it if you're using an in-memory hash Index this one is cont",
    "start": "359240",
    "end": "365400"
  },
  {
    "text": "constant time if you don't use an index at all this depends on the amount of vertices",
    "start": "365400",
    "end": "371280"
  },
  {
    "text": "very expensive but then for every depths we have to do exactly this schema first of",
    "start": "371280",
    "end": "376919"
  },
  {
    "text": "all we have to find all the connected edges which can be done with an edge",
    "start": "376919",
    "end": "382000"
  },
  {
    "text": "index which is typically hash based constant time or with an index free adjacency pretty much the same thing",
    "start": "382000",
    "end": "388120"
  },
  {
    "text": "just different name then we have to filter all the non-matching edges we have to look at each Edge and throw the",
    "start": "388120",
    "end": "394880"
  },
  {
    "text": "ones away that we don't need find the connected vertices and filter the vertices again",
    "start": "394880",
    "end": "401960"
  },
  {
    "text": "and the last three operations actually need one run over all the edges which is linear and the amount of edges that we",
    "start": "401960",
    "end": "408199"
  },
  {
    "text": "find for each vertex but we can do this in one PA so for every depth uh 3 * n is",
    "start": "408199",
    "end": "415520"
  },
  {
    "text": "the complexity that we need but for the next step we have 3 * n",
    "start": "415520",
    "end": "421400"
  },
  {
    "text": "input vertices time 3 * n so every depth",
    "start": "421400",
    "end": "426680"
  },
  {
    "text": "increases the exponent that we need for a query sounds evil right but it is not",
    "start": "426680",
    "end": "435039"
  },
  {
    "text": "linear in all the edges that we have in a graph database it's just the amount the subset that we really hit with our",
    "start": "435039",
    "end": "442199"
  },
  {
    "text": "query that needs the linear complexity so we can store billions of edges as long as the result is like 120",
    "start": "442199",
    "end": "449639"
  },
  {
    "text": "edges it's fast um yeah but we have to keep in mind",
    "start": "449639",
    "end": "457479"
  },
  {
    "text": "every depth increases the exponent so if you query with a depth of 100 it will be",
    "start": "457479",
    "end": "463240"
  },
  {
    "text": "very very very very very expensive don't do it and there is some Theory out there",
    "start": "463240",
    "end": "469159"
  },
  {
    "text": "which says in a natural born graph so typically social graphs you have the Seven Degrees of Separation which means",
    "start": "469159",
    "end": "475800"
  },
  {
    "text": "in a social graph there are only seven steps between me and for example Barack",
    "start": "475800",
    "end": "480919"
  },
  {
    "text": "Obama so six intermediate friends and I can get to basically everyone in the",
    "start": "480919",
    "end": "486479"
  },
  {
    "text": "world in this six to seven intermediate steps so that means for a natural graph",
    "start": "486479",
    "end": "491879"
  },
  {
    "text": "if you're going more than depth six it will be as expensive as querying all the edges at the same",
    "start": "491879",
    "end": "497240"
  },
  {
    "text": "time if you have some artificial graph this may not be",
    "start": "497240",
    "end": "502280"
  },
  {
    "text": "true now I would like to introduce you to one of the graph databases because I will use that later in my demonstration",
    "start": "503080",
    "end": "510159"
  },
  {
    "text": "a rodb is a soal multimodel database which allows you to store key value",
    "start": "510159",
    "end": "515279"
  },
  {
    "text": "pairs documents and graphs just in one core one quer language on top of that we",
    "start": "515279",
    "end": "522518"
  },
  {
    "text": "just saw the different data formats just in the same technology the query language offers",
    "start": "522519",
    "end": "528480"
  },
  {
    "text": "document queries graph queries and joints and you can combine them in the same statement in arbitrary",
    "start": "528480",
    "end": "535760"
  },
  {
    "text": "order and it has asset support including multicollection transaction which is typically missing in single document",
    "start": "535760",
    "end": "544360"
  },
  {
    "text": "stores to quer rodb we have invented a new query language which is called AQL",
    "start": "544519",
    "end": "550279"
  },
  {
    "text": "and it has some syntax taken from from ex uh xquery so the simplest AQL you can",
    "start": "550279",
    "end": "556560"
  },
  {
    "text": "think of is for user in users iterating over my users collection just return everything you find pretty easy pretty",
    "start": "556560",
    "end": "565600"
  },
  {
    "text": "expensive we can filter these things so B based on for example a name which is",
    "start": "565600",
    "end": "571640"
  },
  {
    "text": "Ellis and then return only the things that we have so now we found our vertex Ellis note here unless uh compared to",
    "start": "571640",
    "end": "579560"
  },
  {
    "text": "other document stores you do not say which index is the best one to use the database will figure it out itself just",
    "start": "579560",
    "end": "585680"
  },
  {
    "text": "you know it from relational databases and now let's start with the graph stuff we would like to find a",
    "start": "585680",
    "end": "593120"
  },
  {
    "text": "product which Ellis has bought so we start again at Ellis follow the has",
    "start": "593120",
    "end": "598640"
  },
  {
    "text": "bought Edge and find she that she has bought TV and now we can make it more complex",
    "start": "598640",
    "end": "604839"
  },
  {
    "text": "and actually put the pattern matching on top of that pattern is Ellis has bought something which was bought by Bob and",
    "start": "604839",
    "end": "612000"
  },
  {
    "text": "Bob has bought something else and then there are some conditions on Bob and on the things that we would like to",
    "start": "612000",
    "end": "620160"
  },
  {
    "text": "recommend what you can see here is that we actually use the same mechanisms to filter on the elements inside the graph",
    "start": "621000",
    "end": "628160"
  },
  {
    "text": "as we use on on the elements inside the document store and we can interchange them as we",
    "start": "628160",
    "end": "635360"
  },
  {
    "text": "like but now let's talk a bit about challenges of graph databases many graphs have so-called",
    "start": "635360",
    "end": "642040"
  },
  {
    "text": "super noes super noes are these ones that have many ingoing or outgoing or",
    "start": "642040",
    "end": "647959"
  },
  {
    "text": "even both relations especially celebrities I don't know how many followers Barack Obama or",
    "start": "647959",
    "end": "655320"
  },
  {
    "text": "whoever has on Twitter compared to me traversing over them is expensive",
    "start": "655320",
    "end": "661120"
  },
  {
    "text": "because you have to take a look at all the edges that you have linear time complexity very expensive and often you",
    "start": "661120",
    "end": "668200"
  },
  {
    "text": "actually know that you only need a subset of these edges so you only KN know you need the newest 10 or with a SE",
    "start": "668200",
    "end": "675760"
  },
  {
    "text": "uh specific type or whatever so a solution to this problem",
    "start": "675760",
    "end": "680959"
  },
  {
    "text": "is so-called vertic Centric indices the idea is that you define an",
    "start": "680959",
    "end": "687120"
  },
  {
    "text": "additional index on the edges where you combine the the vertex plus arbitrary",
    "start": "687120",
    "end": "693320"
  },
  {
    "text": "other attributes so for example you you define an index on the vertex and a type",
    "start": "693320",
    "end": "699880"
  },
  {
    "text": "and then this index allows you to find exactly the set of matches of edges that matches the vertex and type in one go if",
    "start": "699880",
    "end": "708480"
  },
  {
    "text": "it's in hash index constant time so this actually reduces the amount",
    "start": "708480",
    "end": "715839"
  },
  {
    "text": "that we need to post filter because we know the index already did the filtering for us and it significantly decreases",
    "start": "715839",
    "end": "723920"
  },
  {
    "text": "the N so if we just pick the orange arrows here it's five of them compared to whatever 30 or what there",
    "start": "723920",
    "end": "731600"
  },
  {
    "text": "is but this doesn't solve everything this is very good if we have the data on one machine and we just have the problem",
    "start": "731600",
    "end": "739199"
  },
  {
    "text": "of uh these super nodes but it doesn't help if our network is so large that we",
    "start": "739199",
    "end": "744600"
  },
  {
    "text": "cannot put it on one machine anymore so we have the problem of Big Data we just",
    "start": "744600",
    "end": "749880"
  },
  {
    "text": "store everything that we get we store all the relations that we have for example we are Twitter we want to store",
    "start": "749880",
    "end": "756360"
  },
  {
    "text": "every tweet as NCH which would be very expensive but we could",
    "start": "756360",
    "end": "761600"
  },
  {
    "text": "do and then we can easily grow our data set beyond the scale of one",
    "start": "762160",
    "end": "770959"
  },
  {
    "text": "machine vertic Centric indices don't help with that because the boundaries of",
    "start": "771160",
    "end": "776399"
  },
  {
    "text": "a machine is there so what we have have to do now is we have to distribute the graph on several machines which is called",
    "start": "776399",
    "end": "784199"
  },
  {
    "text": "Shing so Distributing the graph is not that complicated in theory but if you",
    "start": "784199",
    "end": "790120"
  },
  {
    "text": "want to query it and you want to query it performant it's really really hard to do first thing you have to know you",
    "start": "790120",
    "end": "797199"
  },
  {
    "text": "cannot get a global overview of the complete graph that doesn't fit on a machine given by",
    "start": "797199",
    "end": "802839"
  },
  {
    "text": "definition and then what is about the edges that actually connect vertices",
    "start": "802839",
    "end": "807959"
  },
  {
    "text": "that are placed on different machines which is really really problem and if you want to query it the",
    "start": "807959",
    "end": "815680"
  },
  {
    "text": "network is typically the botton ne so if you have to uh uh jump between all the",
    "start": "815680",
    "end": "820760"
  },
  {
    "text": "ver all the servers by while querying it it will be very very slow so in the quering mechanism we have to reduce the",
    "start": "820760",
    "end": "826839"
  },
  {
    "text": "number of network hops still we can use verx Centric indices because they help with super",
    "start": "826839",
    "end": "833279"
  },
  {
    "text": "noes but only on one local machine they cannot work across machines",
    "start": "833279",
    "end": "839839"
  },
  {
    "text": "but now let's first start with this cluster thingy and there I would like to introduce you to one technology stack",
    "start": "840040",
    "end": "846240"
  },
  {
    "text": "that I really like um and that is",
    "start": "846240",
    "end": "851440"
  },
  {
    "text": "dcos and the Rango DB is um actually one of the first databases that got a um",
    "start": "851440",
    "end": "858160"
  },
  {
    "text": "fully certified database in dcos um Network because we make use of the um",
    "start": "858160",
    "end": "863959"
  },
  {
    "text": "persistence Primitives that they have which allows us to regain the data if the machine just reboots",
    "start": "863959",
    "end": "870720"
  },
  {
    "text": "um arb's cluster resource resource management is based on apach misos which",
    "start": "870720",
    "end": "876360"
  },
  {
    "text": "is below dcos but we will also include support for kubernetes",
    "start": "876360",
    "end": "882839"
  },
  {
    "text": "soon and you do not have to use the US you can run a rang Tob cluster mode",
    "start": "883320",
    "end": "888519"
  },
  {
    "text": "without it um but you need to do some manual setup so you have to uh configure the IP",
    "start": "888519",
    "end": "895920"
  },
  {
    "text": "tables and all this stuff um not the IP tables but you have to figure out the IPS of all the machines that work and",
    "start": "895920",
    "end": "901399"
  },
  {
    "text": "stuff what you get then is automatic failover uh re rebalancing of the shards",
    "start": "901399",
    "end": "907519"
  },
  {
    "text": "and everything that's working inside a rodb what you do not get which is based on misos and coros is a complete self",
    "start": "907519",
    "end": "914800"
  },
  {
    "text": "healing system which means database dies misos will restart the database",
    "start": "914800",
    "end": "920480"
  },
  {
    "text": "somewhere else so if you don't go with the DC Tech",
    "start": "920480",
    "end": "926199"
  },
  {
    "text": "or kubernetes in the future we suggest that you have some on call that can restart reboot the",
    "start": "926199",
    "end": "933240"
  },
  {
    "text": "processes talking about DCS I would like to show it to you so this is the",
    "start": "934880",
    "end": "941600"
  },
  {
    "text": "dcos dashboard which actually gives you a nice overview of all the things that",
    "start": "941600",
    "end": "946920"
  },
  {
    "text": "are going on in your cluster so I've uh started a cluster with um five machines",
    "start": "946920",
    "end": "953240"
  },
  {
    "text": "uh in total I have um 20 shares of CPU um 68 GBS of RAM",
    "start": "953240",
    "end": "959880"
  },
  {
    "text": "um some main memory and right now there actually 10 tasks running and those 10",
    "start": "959880",
    "end": "966759"
  },
  {
    "text": "tasks are something that dcos needs plus the arangodb instance which is running",
    "start": "966759",
    "end": "973199"
  },
  {
    "text": "right now if I take a look at Services there is this arangodb Enterprise running um",
    "start": "973199",
    "end": "979759"
  },
  {
    "text": "okay you can't read that I hate dark interfaces sorry um yeah and I can just get a nice",
    "start": "979759",
    "end": "988000"
  },
  {
    "text": "overview of what's going going on inside the cluster and cool thing that dcos offers",
    "start": "988000",
    "end": "993480"
  },
  {
    "text": "is a so-called Universe which is some kind of app store where I can just go go to and install technologies that I need",
    "start": "993480",
    "end": "1002079"
  },
  {
    "text": "so for example Jenkins or spark or Marathon which is which is also used by",
    "start": "1002079",
    "end": "1007720"
  },
  {
    "text": "um dcos or even in a Rango DB is just one click I want this at that many",
    "start": "1007720",
    "end": "1013880"
  },
  {
    "text": "processes and then it deploys it somewhere in the cluster you don't have to care it figures it out",
    "start": "1013880",
    "end": "1021079"
  },
  {
    "text": "automatically okay let's continue and now let's distribute the",
    "start": "1023360",
    "end": "1030400"
  },
  {
    "text": "graph across this cluster so assumption only parts of the",
    "start": "1030400",
    "end": "1036880"
  },
  {
    "text": "graph can be stored on every single machine this leads to a couple of",
    "start": "1036880",
    "end": "1043640"
  },
  {
    "text": "problems so first of all the neighboring vertices may be on different machines",
    "start": "1043640",
    "end": "1049520"
  },
  {
    "text": "and for some graph databases even the edges can be on another machine if you",
    "start": "1049520",
    "end": "1054960"
  },
  {
    "text": "don't want to duplicate them queries need to be executed in a",
    "start": "1054960",
    "end": "1061080"
  },
  {
    "text": "distributed way so you have to find something that allows the query across the cluster and then puts together the",
    "start": "1061080",
    "end": "1067880"
  },
  {
    "text": "result because you cannot force the complete graph into one instance to compute it you have to distributedly",
    "start": "1067880",
    "end": "1074840"
  },
  {
    "text": "execute the traversal which is actually quite hard because you you need to know some history of what has going on inside the",
    "start": "1074840",
    "end": "1084080"
  },
  {
    "text": "traversal and then finally the the results have to be merged in one instance",
    "start": "1084080",
    "end": "1091000"
  },
  {
    "text": "locally um and now we can find some distribution techniques on how to store",
    "start": "1091679",
    "end": "1097840"
  },
  {
    "text": "the graph onto the different service so on the bottom I have my graph and I have",
    "start": "1097840",
    "end": "1103000"
  },
  {
    "text": "three machines that I want to distribute it on and the first Native way is a random distribution by constant hashing",
    "start": "1103000",
    "end": "1109760"
  },
  {
    "text": "on the keys of whatever objects I want to store Advantage is there every server",
    "start": "1109760",
    "end": "1115679"
  },
  {
    "text": "takes an equal portion of the data set it's very easy to realize for the database",
    "start": "1115679",
    "end": "1121679"
  },
  {
    "text": "engineer it doesn't require any knowledge of the graph it always",
    "start": "1121679",
    "end": "1126799"
  },
  {
    "text": "works disadvantage most likely the neighbors will be in different machines probably",
    "start": "1126799",
    "end": "1133240"
  },
  {
    "text": "the edges will be in different machines and this means a lot of query overhead is required for for the quering",
    "start": "1133240",
    "end": "1139320"
  },
  {
    "text": "because the graph actually ends up like this inside the cluster cannot make reason anyway inside the graph so yeah",
    "start": "1139320",
    "end": "1148520"
  },
  {
    "text": "has some advantages but in terms of querying it's really really",
    "start": "1148520",
    "end": "1154159"
  },
  {
    "text": "bad and then there's something that a lot of other graph database vendors use",
    "start": "1154159",
    "end": "1159720"
  },
  {
    "text": "which is so-called index free adjacency and they actually say an edge",
    "start": "1159720",
    "end": "1166679"
  },
  {
    "text": "is glued to the vertex so the vertex really knows has exactly a handle to these",
    "start": "1166679",
    "end": "1172840"
  },
  {
    "text": "edges so we can move vertices to one uh machine plus all their",
    "start": "1172840",
    "end": "1179240"
  },
  {
    "text": "edges because the vertex maintains these two L lists of in and outgoing",
    "start": "1179240",
    "end": "1184520"
  },
  {
    "text": "edges then we can just how can we shart this so one part can go here then this machine is full the other part can go",
    "start": "1184520",
    "end": "1192159"
  },
  {
    "text": "there but what is with this Edge is it on the left server is it on the right server because actually we needed in",
    "start": "1192159",
    "end": "1198960"
  },
  {
    "text": "both if you want to maintain index fre adjacency in a rang DB we can use an",
    "start": "1198960",
    "end": "1205640"
  },
  {
    "text": "hash based Edge index which actually makes the vertex and the edge independent from one",
    "start": "1205640",
    "end": "1211640"
  },
  {
    "text": "another and this allows us to actually Store The Edge somewhere else so if",
    "start": "1211640",
    "end": "1216919"
  },
  {
    "text": "required we can store it on a remote machine which actually allows us to do",
    "start": "1216919",
    "end": "1222159"
  },
  {
    "text": "this random distribution if we want to but it can be done way cleverer and",
    "start": "1222159",
    "end": "1228720"
  },
  {
    "text": "this is what I like to call domain-based distribution so many graphs that I've seen out there in the field have a",
    "start": "1228720",
    "end": "1235000"
  },
  {
    "text": "natural distribution that actually cuts it into pieces typically if you have a",
    "start": "1235000",
    "end": "1240159"
  },
  {
    "text": "social network it's the country or the region where the people live in typically have way more friends in",
    "start": "1240159",
    "end": "1246919"
  },
  {
    "text": "London if you're from London than you have from Germany or from the",
    "start": "1246919",
    "end": "1252159"
  },
  {
    "text": "states which doesn't mean that you're not allowed to have any friends abroad but most of them won't be abroad",
    "start": "1252159",
    "end": "1260600"
  },
  {
    "text": "for products typically they are sold in the same category space so also that",
    "start": "1261240",
    "end": "1266720"
  },
  {
    "text": "naturally distributes in some kind of graph and then if we just take and apply",
    "start": "1266720",
    "end": "1273480"
  },
  {
    "text": "this knowledge the graph actually distributes a bit better so we can identify three groups which have the",
    "start": "1273480",
    "end": "1279919"
  },
  {
    "text": "same Tex and then we can at least make parts of the graph on the same",
    "start": "1279919",
    "end": "1285919"
  },
  {
    "text": "machine and a rang DB Enterprise Edition actually uses this domain knowledge to do",
    "start": "1285960",
    "end": "1292120"
  },
  {
    "text": "shortcuts when querying the data which gives an enormous performance boost which I will show you in a",
    "start": "1292120",
    "end": "1298600"
  },
  {
    "text": "second how does it actually work so this is the architecture of a rang be we have",
    "start": "1298600",
    "end": "1304600"
  },
  {
    "text": "coordinator which is the user interface so user talks to a coordinator machine",
    "start": "1304600",
    "end": "1310000"
  },
  {
    "text": "which has a query Optimizer which figures out okay this database server has to do this part of the query this",
    "start": "1310000",
    "end": "1315440"
  },
  {
    "text": "one has to do the other part and this one has to do the third part distributes to database server which are holding the",
    "start": "1315440",
    "end": "1321520"
  },
  {
    "text": "data preing it locally and uh and the result is again merged on the",
    "start": "1321520",
    "end": "1327559"
  },
  {
    "text": "coordinated and if we now do some traversal which follows this orange",
    "start": "1327559",
    "end": "1332960"
  },
  {
    "text": "P we see that at least at these points we need to do some Network hops",
    "start": "1332960",
    "end": "1339400"
  },
  {
    "text": "because the vertices are placed on a different machine which are",
    "start": "1339400",
    "end": "1344880"
  },
  {
    "text": "expensive and if we shot the graph a bit more clever",
    "start": "1344880",
    "end": "1350080"
  },
  {
    "text": "suddenly we only need one network hop in between giving us way more",
    "start": "1350080",
    "end": "1357039"
  },
  {
    "text": "performance and now I would like to see to show you how much that actually",
    "start": "1357200",
    "end": "1363880"
  },
  {
    "text": "brings so this is a rodb web",
    "start": "1366400",
    "end": "1372520"
  },
  {
    "text": "interface in my cluster that I'm show you uh that I showed you in dcus already",
    "start": "1372520",
    "end": "1378640"
  },
  {
    "text": "I have imported the same graph two times one time with a random",
    "start": "1378640",
    "end": "1383960"
  },
  {
    "text": "distribution which I called the Nave way so I have um two collections V",
    "start": "1383960",
    "end": "1389919"
  },
  {
    "text": "naive and V naive which are the vert uh vertices and the edges and I have the",
    "start": "1389919",
    "end": "1395360"
  },
  {
    "text": "Smart Ones essentially the same graph sh differently and if you take a look at",
    "start": "1395360",
    "end": "1402640"
  },
  {
    "text": "this collection we will see below here that we have roughly",
    "start": "1402640",
    "end": "1408840"
  },
  {
    "text": "3.2 million edges distributed across the",
    "start": "1408840",
    "end": "1413960"
  },
  {
    "text": "cluster and for the vertices we have roughly a million vertices it's not that",
    "start": "1414880",
    "end": "1420240"
  },
  {
    "text": "large but it allows to show what I I want to show",
    "start": "1420240",
    "end": "1425600"
  },
  {
    "text": "you in terms of um my notes I've running four",
    "start": "1425880",
    "end": "1432159"
  },
  {
    "text": "coordinator instances and for database server instances that are sharing the data",
    "start": "1432159",
    "end": "1439600"
  },
  {
    "text": "and now let's execute some queries on the graph so first of all I would like to",
    "start": "1439640",
    "end": "1446080"
  },
  {
    "text": "execute a pretty simple query so I start at one vertex which has some generated",
    "start": "1446080",
    "end": "1452440"
  },
  {
    "text": "name um and then I just go three steps outbound in this",
    "start": "1452440",
    "end": "1458400"
  },
  {
    "text": "graph just play and here we go so this is the native",
    "start": "1458400",
    "end": "1465360"
  },
  {
    "text": "approach I can see I got um 38 um vertices connected in this one",
    "start": "1465360",
    "end": "1472039"
  },
  {
    "text": "query and the only thing I do now is I change the names here",
    "start": "1472039",
    "end": "1478399"
  },
  {
    "text": "smart uh no in this section",
    "start": "1478399",
    "end": "1485679"
  },
  {
    "text": "smart smart and execute the same query",
    "start": "1485679",
    "end": "1491480"
  },
  {
    "text": "again and actually the result is identical I still have the 38 elements",
    "start": "1491720",
    "end": "1498000"
  },
  {
    "text": "still get the same graph because it was the same query but now I'll show you the",
    "start": "1498000",
    "end": "1503120"
  },
  {
    "text": "performance boost that you can get so I have prepared a",
    "start": "1503120",
    "end": "1509840"
  },
  {
    "text": "query which actually starts again as this one Vex and goes one to seven steps",
    "start": "1510200",
    "end": "1517720"
  },
  {
    "text": "outbound and simply counts what it finds because if I would return the whole data",
    "start": "1517720",
    "end": "1523440"
  },
  {
    "text": "it would overshadow the performance benefit that you get and now let let's just run this",
    "start": "1523440",
    "end": "1531158"
  },
  {
    "text": "one and you see it's loading it's loading it's loading it's loading",
    "start": "1531760",
    "end": "1538480"
  },
  {
    "text": "because that's the native way random distribution the elements are stored somewhere takes about 10 seconds and I",
    "start": "1538480",
    "end": "1546600"
  },
  {
    "text": "got only 11,000 vertices touched with this one query and if I fix",
    "start": "1546600",
    "end": "1553880"
  },
  {
    "text": "it and just go smart",
    "start": "1553880",
    "end": "1558600"
  },
  {
    "text": "there we go 0.18 seconds it's uh 50 times faster at",
    "start": "1563399",
    "end": "1570080"
  },
  {
    "text": "least just because we use the better distribution we apply some knowledge on",
    "start": "1570080",
    "end": "1575600"
  },
  {
    "text": "the graph we save a lot of network hops in between because the the actual problem",
    "start": "1575600",
    "end": "1582520"
  },
  {
    "text": "is with this query no matter how hard we try at least we would do seven Network pops with this",
    "start": "1582520",
    "end": "1589159"
  },
  {
    "text": "outbound Direction because everything could be stored or is stored actually somewhere",
    "start": "1589159",
    "end": "1596640"
  },
  {
    "text": "else so I think this performance benefit is actually very very good very nice and",
    "start": "1597000",
    "end": "1602039"
  },
  {
    "text": "very useful if you are really scaling and having a scale problem with the graph",
    "start": "1602039",
    "end": "1608399"
  },
  {
    "text": "data what about the other features so we did run an open- Source performance test",
    "start": "1608399",
    "end": "1615240"
  },
  {
    "text": "comparing us to all the other nosql databases that are out there",
    "start": "1615240",
    "end": "1620240"
  },
  {
    "text": "especially comparing us to the more specialized data Stores um and as we started the",
    "start": "1620559",
    "end": "1627679"
  },
  {
    "text": "performance block post we actually expected that we would be like close to them but not faster because the",
    "start": "1627679",
    "end": "1633240"
  },
  {
    "text": "specialized would would be assumed to be faster but then we actually figured out we are not that bad as we thought so",
    "start": "1633240",
    "end": "1641480"
  },
  {
    "text": "single read it's just we have a key and we just want to get the document by key",
    "start": "1641480",
    "end": "1648679"
  },
  {
    "text": "not super smart but something that you really really need very often mongodb is very very fast in terms of",
    "start": "1648679",
    "end": "1656799"
  },
  {
    "text": "singer reads Neo forj which is a graph database is quite slow because they",
    "start": "1656799",
    "end": "1662240"
  },
  {
    "text": "shine when you do the graph features Orient which is another multimodel database is a little bit",
    "start": "1662240",
    "end": "1669120"
  },
  {
    "text": "slower than we are then we have used postgress in two ways either store Json",
    "start": "1669120",
    "end": "1675640"
  },
  {
    "text": "because we need it schema free to make it comparable or we use the tabular layout so we",
    "start": "1675640",
    "end": "1681000"
  },
  {
    "text": "Define what is the schema and stuff and if we do single read the Jason one is way faster than the tabular",
    "start": "1681000",
    "end": "1688760"
  },
  {
    "text": "one for single right uh also the tabular one is a bit faster than um and the",
    "start": "1688760",
    "end": "1695880"
  },
  {
    "text": "adjacent one is a bit faster than the tabular one but all are pretty much in the same area um single right zinc which",
    "start": "1695880",
    "end": "1703240"
  },
  {
    "text": "means we wait until we have fire than fsnc uh postgress is way better than the others but yeah you see the other ones",
    "start": "1703240",
    "end": "1710760"
  },
  {
    "text": "are even slower and then the thing that astonished us the most aggregation just wanted to aggregate all",
    "start": "1710760",
    "end": "1717960"
  },
  {
    "text": "the uses by AG that we have in our database postgress uses the information",
    "start": "1717960",
    "end": "1725240"
  },
  {
    "text": "that the age is an in integer and is small and can get a lot of performance benefit out there so the tbla one is",
    "start": "1725240",
    "end": "1731559"
  },
  {
    "text": "very very fast but we could outperform all the others and then we have shortest path",
    "start": "1731559",
    "end": "1738720"
  },
  {
    "text": "algorithm we go from a to anyb somewhere this is not possible in postgress this",
    "start": "1738720",
    "end": "1744799"
  },
  {
    "text": "is not possible in mongodb those are not graph databases they simply don't have a querium mechanism for",
    "start": "1744799",
    "end": "1751799"
  },
  {
    "text": "it so we only had to do it in Neo forj and Orient DB and actually we we were able to",
    "start": "1751799",
    "end": "1758440"
  },
  {
    "text": "outperform Neo forj in that case by an order of magnitude then we have neighbors",
    "start": "1758440",
    "end": "1764159"
  },
  {
    "text": "computation Neighbors in this case is we start at one point and we go two step",
    "start": "1764159",
    "end": "1769919"
  },
  {
    "text": "neighbors we ignore the first step everyone we have seen in the first step is ignored and we take the second step",
    "start": "1769919",
    "end": "1775480"
  },
  {
    "text": "in mongodb this actually requires that we pick everything in the first step into the client and quer the server",
    "start": "1775480",
    "end": "1781919"
  },
  {
    "text": "again and still they are faster than some of the graph databases out there which really astonished me but that's",
    "start": "1781919",
    "end": "1788840"
  },
  {
    "text": "what we measured if we include the profiles so that means we actually shift away the",
    "start": "1788840",
    "end": "1794880"
  },
  {
    "text": "data to the client we actually see that um there is not much performance gain",
    "start": "1794880",
    "end": "1800679"
  },
  {
    "text": "that you get from mongodb but still we are way faster than them price you pay if you're using a Rango DB is we have a",
    "start": "1800679",
    "end": "1807000"
  },
  {
    "text": "higher memory footprint which will be fixed in one of the upcoming",
    "start": "1807000",
    "end": "1812000"
  },
  {
    "text": "versions speaking of scaling so the other one was a single server test only",
    "start": "1812799",
    "end": "1818080"
  },
  {
    "text": "because NE forj at that time couldn't use more than one server and now we did some scaling test",
    "start": "1818080",
    "end": "1825240"
  },
  {
    "text": "on a Shard um a ranger DB and we wanted to find out how many do",
    "start": "1825240",
    "end": "1830600"
  },
  {
    "text": "right document right transactions per virtual CPU we could achieve and we see",
    "start": "1830600",
    "end": "1836039"
  },
  {
    "text": "that we actually good could get an almost linear scaling adding more CPUs we get linear right scaling latency um",
    "start": "1836039",
    "end": "1844640"
  },
  {
    "text": "pretty much the same level goes up a bit um same holds true for the overall um",
    "start": "1844640",
    "end": "1851519"
  },
  {
    "text": "95% latency check and this is the test that is actually comparable and",
    "start": "1851519",
    "end": "1856639"
  },
  {
    "text": "published by some of the other database vendors which do the same",
    "start": "1856639",
    "end": "1862320"
  },
  {
    "text": "test and I don't think that we are too bad in that case again okay that it",
    "start": "1862480",
    "end": "1868799"
  },
  {
    "text": "that's it thank you very much for your attention I hope you liked the talk and if you like I have a lot of",
    "start": "1868799",
    "end": "1875120"
  },
  {
    "text": "t-shirts that I would like to give away thank you very",
    "start": "1875120",
    "end": "1880759"
  },
  {
    "text": "much thanks",
    "start": "1883159",
    "end": "1887159"
  }
]
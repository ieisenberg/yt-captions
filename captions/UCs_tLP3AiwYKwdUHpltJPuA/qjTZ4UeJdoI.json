[
  {
    "start": "0",
    "end": "48000"
  },
  {
    "text": "[Music]",
    "start": "970",
    "end": "7838"
  },
  {
    "text": "uh my name is robin moffat i'm a developer advocate for conference uh and i'm rather delighted to be here",
    "start": "13120",
    "end": "18640"
  },
  {
    "text": "uh speaking at utopia this morning um i want to talk about apache kafka and we're going to talk",
    "start": "18640",
    "end": "24640"
  },
  {
    "text": "about why you even need apache kafka and the concepts behind it so we can understand exactly what you",
    "start": "24640",
    "end": "31679"
  },
  {
    "text": "can use it for what you perhaps shouldn't be using it for and what it is outside maybe some of the misconceptions",
    "start": "31679",
    "end": "37760"
  },
  {
    "text": "that people have of it so to understand apache kafka we want to",
    "start": "37760",
    "end": "43280"
  },
  {
    "text": "understand the reasoning for why do we even need this thing in the first place and at the very heart of",
    "start": "43280",
    "end": "49039"
  },
  {
    "start": "48000",
    "end": "243000"
  },
  {
    "text": "apache kafka is this concept of these things called events events are the building blocks for",
    "start": "49039",
    "end": "55520"
  },
  {
    "text": "what's the data that we work with day-to-day in our jobs we just don't always realize that they started life as events",
    "start": "55520",
    "end": "62239"
  },
  {
    "text": "we work with databases we work with nosql stores we work with other sources of data a lot of these places",
    "start": "62239",
    "end": "69040"
  },
  {
    "text": "where we keep data that data started life as an event and events",
    "start": "69040",
    "end": "74080"
  },
  {
    "text": "are these magical things that occur unbounded over time connect until the end of the world",
    "start": "74080",
    "end": "79680"
  },
  {
    "text": "and events tell us that something happened and they tell us what happened and if we",
    "start": "79680",
    "end": "86000"
  },
  {
    "text": "think about the kind of data that we work with we can think of plenty of examples of human generated events",
    "start": "86000",
    "end": "91360"
  },
  {
    "text": "someone walks into a shop and buys something or probably nowadays they kind of click online and buy something but you have an event",
    "start": "91360",
    "end": "97680"
  },
  {
    "text": "something was bought what was boss what was its cost price what was the model and so on or we moved some inventory around the",
    "start": "97680",
    "end": "104479"
  },
  {
    "text": "warehouse so you have the notification that something happened those stock movements what happened well",
    "start": "104479",
    "end": "110159"
  },
  {
    "text": "what was the stock item where did it move from where did it move to what was the reason for moving it so we have these events",
    "start": "110159",
    "end": "115840"
  },
  {
    "text": "and these happen continually over time so events actually let us start to model out",
    "start": "115840",
    "end": "121439"
  },
  {
    "text": "what's happening within our businesses events aren't just limited to human generated events though we have",
    "start": "121439",
    "end": "127840"
  },
  {
    "text": "plenty of machine generated events we have events happening across our networks like our firewalls and our",
    "start": "127840",
    "end": "133360"
  },
  {
    "text": "switches and so on are capturing events all the time iot devices are continually giving out readings about the",
    "start": "133360",
    "end": "139200"
  },
  {
    "text": "temperature around us or the light sensors or all this other kind of stuff and the applications that we build also",
    "start": "139200",
    "end": "145520"
  },
  {
    "text": "generate events and the user did something in it through an error well there's your events something that kind of an",
    "start": "145520",
    "end": "151519"
  },
  {
    "text": "error happened is the notification of what was the area what was the stack trace these are also events so we have all of",
    "start": "151519",
    "end": "158000"
  },
  {
    "text": "these events around us and we can use these events to build very very powerful applications",
    "start": "158000",
    "end": "164800"
  },
  {
    "text": "we can use them to drive things in our applications our applications respond to what happens so we can make systems much",
    "start": "164800",
    "end": "171840"
  },
  {
    "text": "more responsive to our users we can use events to build up state and reproduce what happened",
    "start": "171840",
    "end": "177599"
  },
  {
    "text": "at a particular time so we can use them to connect our systems around our businesses",
    "start": "177599",
    "end": "182800"
  },
  {
    "text": "so using these events we can do great things but we need a way of actually being able",
    "start": "182800",
    "end": "187920"
  },
  {
    "text": "to do them we need a kind of a platform on which to do that so let's think about how",
    "start": "187920",
    "end": "193360"
  },
  {
    "text": "we can actually build that platform let's think about an event how are we going to work with this particular event",
    "start": "193360",
    "end": "199200"
  },
  {
    "text": "or as we'll probably have lots of events because these events are happening maybe like",
    "start": "199200",
    "end": "204319"
  },
  {
    "text": "continuing vast streams maybe just like periodically every few seconds every few minutes maybe every",
    "start": "204319",
    "end": "210319"
  },
  {
    "text": "few days but there's still events so we have these events and what is an event well we said it's like it's a",
    "start": "210319",
    "end": "216560"
  },
  {
    "text": "notification and it tells us what happens but for now let's say it's a key value",
    "start": "216560",
    "end": "221920"
  },
  {
    "text": "pair okay it's going to tell us there's your notification that the event actually happens and the value of what",
    "start": "221920",
    "end": "227519"
  },
  {
    "text": "happens and that value could just be like a zero or a one it could be like a hugely complex scheme with a massive payload",
    "start": "227519",
    "end": "234159"
  },
  {
    "text": "within it but it's a key value pair for now where are we going to keep our events how do we actually capture",
    "start": "234159",
    "end": "240959"
  },
  {
    "text": "them and deal with them well here comes the most important kind of like building block",
    "start": "240959",
    "end": "246560"
  },
  {
    "start": "243000",
    "end": "355000"
  },
  {
    "text": "of apache kafka which is the log now when i say a log i don't mean like",
    "start": "246560",
    "end": "252480"
  },
  {
    "text": "you can like log.txt or your log4j or that kind of thing all those those are actually kind of type of event capture things",
    "start": "252480",
    "end": "258400"
  },
  {
    "text": "that we're doing anyway here we're talking about a log a very specific way the log is where we take our events",
    "start": "258400",
    "end": "266639"
  },
  {
    "text": "and we append them over time so as events are happening they're appended to the log",
    "start": "266639",
    "end": "273759"
  },
  {
    "text": "so something happens it gets written to the log something else happens it gets written to the log and this log is immutable so kafka gives",
    "start": "273759",
    "end": "281600"
  },
  {
    "text": "us some very very powerful guarantees of building our systems and here's the first one it is that",
    "start": "281600",
    "end": "287520"
  },
  {
    "text": "guarantees that the data those events will not have changed because it is immutable so you have a",
    "start": "287520",
    "end": "294560"
  },
  {
    "text": "conversation with someone and you're speaking something and they say something and they say something those are events back and forth and",
    "start": "294560",
    "end": "301039"
  },
  {
    "text": "they're happening over time and just as if you have an argument with someone and you say something and heat",
    "start": "301039",
    "end": "306080"
  },
  {
    "text": "and you're like you say something you really didn't mean to and like the next morning you regret it a little bit it's immutable",
    "start": "306080",
    "end": "311840"
  },
  {
    "text": "that has been said those words were uttered you can't go back and unsay those and it's the same with an event log",
    "start": "311840",
    "end": "317759"
  },
  {
    "text": "events happen over time they are append only they are appended to the end of the log it is immutable and if you put something",
    "start": "317759",
    "end": "324400"
  },
  {
    "text": "onto it that you didn't mean to well you can kind of counteract it and put another event in place and",
    "start": "324400",
    "end": "329600"
  },
  {
    "text": "in the kind of the analogy of the conversation go and say sorry but that original event still happened",
    "start": "329600",
    "end": "334880"
  },
  {
    "text": "it is immutable so we can use this when we're building our systems because you have that guarantee",
    "start": "334880",
    "end": "340240"
  },
  {
    "text": "that the data we read from that event log has not changed those events are as they occurred so the events get added",
    "start": "340240",
    "end": "348400"
  },
  {
    "text": "to the end of the log it's immutable it's append only it continues over time and that's the conceptual heart of",
    "start": "348400",
    "end": "355440"
  },
  {
    "start": "355000",
    "end": "387000"
  },
  {
    "text": "apache kafka as an event streaming platform so event streaming platform sounds big and fancy",
    "start": "355440",
    "end": "360639"
  },
  {
    "text": "and kind of like a bit marketing but that's going to describe what we're going to build up around all of this",
    "start": "360639",
    "end": "366479"
  },
  {
    "text": "very fairly simple concept at the very heart of it which is an immutable app and only",
    "start": "366479",
    "end": "371919"
  },
  {
    "text": "commit log and it's also distributed by the way which makes it very scalable and resilient we'll talk about that later",
    "start": "371919",
    "end": "378639"
  },
  {
    "text": "but a log itself is a bit conceptual and we need to actually work with this we need to kind of have apis and we need a",
    "start": "378639",
    "end": "384800"
  },
  {
    "text": "way of structuring the data so we're going to carve up that log into what are called topics",
    "start": "384800",
    "end": "390400"
  },
  {
    "start": "387000",
    "end": "498000"
  },
  {
    "text": "and topics if you were from a database background like i am they're kind of like tables and looks",
    "start": "390400",
    "end": "395919"
  },
  {
    "text": "like it's entities of data so you have a topic which describes click events over time",
    "start": "395919",
    "end": "403280"
  },
  {
    "text": "so people click on your website it gets appended to the individual topic they place an order it gets that event",
    "start": "403280",
    "end": "408560"
  },
  {
    "text": "gets somebody appended to the end of the orders topic there's also a topic here for customers",
    "start": "408560",
    "end": "414319"
  },
  {
    "text": "and whilst streams of facts like clicks or orders are kind of like nice and easy to conceptually understand",
    "start": "414319",
    "end": "421039"
  },
  {
    "text": "like these things can happen continually over time you can also use topics you can also use events to",
    "start": "421039",
    "end": "428160"
  },
  {
    "text": "describe reference information look up data because if you think about that itself it's also created as an event so",
    "start": "428160",
    "end": "436160"
  },
  {
    "text": "a customer joins our organization or they can like they sign up that's a create event and it's got",
    "start": "436160",
    "end": "441759"
  },
  {
    "text": "information about their name and their email address and then they change their email address well that's another event they change",
    "start": "441759",
    "end": "447919"
  },
  {
    "text": "their email address and now have additional information about that customer and if you keep all of that",
    "start": "447919",
    "end": "453039"
  },
  {
    "text": "information about that customer on that particular topic that series of events you can now replay that and build up a",
    "start": "453039",
    "end": "460000"
  },
  {
    "text": "full picture of the state about your customers but you also now have more information than simply the",
    "start": "460000",
    "end": "465599"
  },
  {
    "text": "state alone because you can go back and say well when did they change their email address how many times have they done this",
    "start": "465599",
    "end": "471520"
  },
  {
    "text": "so by capturing events we can roll up so kind of like our normal view of data like we would say in a relational",
    "start": "471520",
    "end": "476720"
  },
  {
    "text": "database but we also have the raw events that created it which are also useful in themselves these topics",
    "start": "476720",
    "end": "484560"
  },
  {
    "text": "are how we're going to organize our data but because kafka is a distributed system",
    "start": "484560",
    "end": "490160"
  },
  {
    "text": "and because we want it to be scalable we're also going to carve up these topics one more time",
    "start": "490160",
    "end": "495280"
  },
  {
    "text": "and we carve these up into partitions partitions exist within a topic",
    "start": "495280",
    "end": "502080"
  },
  {
    "start": "498000",
    "end": "550000"
  },
  {
    "text": "and you can have one and usually more than one partition and partitions there are units of scale",
    "start": "502080",
    "end": "508720"
  },
  {
    "text": "and within a partition we have our seconds really strong guarantee that kafka gives",
    "start": "508720",
    "end": "514159"
  },
  {
    "text": "us which is that messages will be ordered within a partition within a topic so your topic is four",
    "start": "514159",
    "end": "520959"
  },
  {
    "text": "partitions within those four partitions within each partition you're guaranteed",
    "start": "520959",
    "end": "526240"
  },
  {
    "text": "that the date the order in which the data was written to that partition is the order in which it will be read",
    "start": "526240",
    "end": "531600"
  },
  {
    "text": "from that partition so in the example of a customer if you start reading from the partition you're not going to get the",
    "start": "531600",
    "end": "536880"
  },
  {
    "text": "they change their email address before you got there oh they got created event so you got that strong ordering",
    "start": "536880",
    "end": "542800"
  },
  {
    "text": "guarantee within partitions now let's see how we actually get the data",
    "start": "542800",
    "end": "548000"
  },
  {
    "text": "in and out of these topics out of this distributed commit log kafka itself has characteristics of a",
    "start": "548000",
    "end": "555600"
  },
  {
    "start": "550000",
    "end": "1020000"
  },
  {
    "text": "message queue it's not just a message queue as you would think of like any other message queue on the shelf and like oh well any",
    "start": "555600",
    "end": "561680"
  },
  {
    "text": "media might we'll use kafka here it's just a message queue kafka has characteristics",
    "start": "561680",
    "end": "567279"
  },
  {
    "text": "of a message queue it's not just that it's not just transient messaging but it lets us do pub sub let's just put",
    "start": "567279",
    "end": "573839"
  },
  {
    "text": "data onto it and take data off it with one or more different subscribers so to get a data on",
    "start": "573839",
    "end": "579920"
  },
  {
    "text": "to a topic in kafka we use a producer and the producer writes data to the end",
    "start": "579920",
    "end": "586000"
  },
  {
    "text": "of the log just like we said it's an append only log so something happens we write it to the log",
    "start": "586000",
    "end": "591760"
  },
  {
    "text": "the producer will decide which partition are we going to write it to there are producer api libraries to lots",
    "start": "591760",
    "end": "599600"
  },
  {
    "text": "of different languages there's java there's go like you can see here there's python and the c c plus plus any number of languages if",
    "start": "599600",
    "end": "607040"
  },
  {
    "text": "you can't find one for your language your preference there's also a rest proxy so you can just use risk calls to put data",
    "start": "607040",
    "end": "612800"
  },
  {
    "text": "onto topics and kafka we said earlier about our events are going to be key",
    "start": "612800",
    "end": "618240"
  },
  {
    "text": "value pairs and this is where the key comes in if you don't assign a key to your message and you don't have to",
    "start": "618240",
    "end": "624560"
  },
  {
    "text": "kafka will simply round rub and distribute messages as they arrive across the partitions within a topic so",
    "start": "624560",
    "end": "630240"
  },
  {
    "text": "you get a nice even distribution of messages but if you care about the uh",
    "start": "630240",
    "end": "635920"
  },
  {
    "text": "partitions which data is going to get assigned so you want messages for a particular customer or a",
    "start": "635920",
    "end": "640959"
  },
  {
    "text": "particular business unit always to be in a particular partition you're going to want to set a key on",
    "start": "640959",
    "end": "646560"
  },
  {
    "text": "those messages so that then messages for a given key will always end up on the same partition",
    "start": "646560",
    "end": "652959"
  },
  {
    "text": "now you don't need the same number of partitions as the same number of key instances if you have 10 000",
    "start": "652959",
    "end": "658720"
  },
  {
    "text": "customers you don't need ten thousand partitions you could have two partitions and each partition is gonna get five thousand",
    "start": "658720",
    "end": "664800"
  },
  {
    "text": "customers on it but the important point is each customer will be on the same partition",
    "start": "664800",
    "end": "671839"
  },
  {
    "text": "so when we're reading the data from that partition we're guaranteed that the data for the particular customer reading",
    "start": "671839",
    "end": "677519"
  },
  {
    "text": "any more data related to that customer will be on that same partition so producers",
    "start": "677519",
    "end": "684160"
  },
  {
    "text": "send data to topics it's a client application that we write and any number of different languages there's also a",
    "start": "684160",
    "end": "689600"
  },
  {
    "text": "rest proxy the producer api handles like talking to the brokers and working out which passage in the data is going to go on to",
    "start": "689600",
    "end": "697040"
  },
  {
    "text": "and that and as i say there's a rest proxy or lots of different languages we can use as well",
    "start": "697040",
    "end": "703040"
  },
  {
    "text": "to get data out of a topic the kind of the subscribers we're going to use the consumer api so",
    "start": "703040",
    "end": "709360"
  },
  {
    "text": "when we consume data from a topic it's sequential access so you can't look at random access and i",
    "start": "709360",
    "end": "715920"
  },
  {
    "text": "just scan through this whole thing or have uh go through it and look for a particular type of a message or something like that",
    "start": "715920",
    "end": "721680"
  },
  {
    "text": "we say we're going to go to a particular topic we can read data from the beginning of the topic the end of the topic or indeed any point",
    "start": "721680",
    "end": "728560"
  },
  {
    "text": "within a particular offset or a particular timestamp and we go to that point and we read those messages",
    "start": "728560",
    "end": "734720"
  },
  {
    "text": "through now kafka itself doesn't delete messages when they get",
    "start": "734720",
    "end": "740399"
  },
  {
    "text": "read kafka itself will delete messages from a topic when you've told it to so you say to kafka on this particular",
    "start": "740399",
    "end": "747360"
  },
  {
    "text": "topic here i would like to keep the messages based on time i'd like to keep them for seven days for the orders or",
    "start": "747360",
    "end": "753680"
  },
  {
    "text": "seven years for the customer information or indeed you say i would like to keep this data forever",
    "start": "753680",
    "end": "760720"
  },
  {
    "text": "so kafka will delete the messages when you tell it to based on each topic settings when consumers read the",
    "start": "760720",
    "end": "766880"
  },
  {
    "text": "data from a topic the data does not get deleted the two concepts are completely separate so we read data",
    "start": "766880",
    "end": "773519"
  },
  {
    "text": "from its topic the data stays on that topic all that changes is kafka says okay you got to this particular point in the",
    "start": "773519",
    "end": "780000"
  },
  {
    "text": "topic here and you said you've processed those messages kafka keeps a note of that offset so when you come along",
    "start": "780000",
    "end": "786720"
  },
  {
    "text": "again and connect and say i'd like the messages this is well you got to hear from last time so now you get any new messages that",
    "start": "786720",
    "end": "792320"
  },
  {
    "text": "have arrived since then and because messages don't get deleted off the topic when they're being",
    "start": "792320",
    "end": "797600"
  },
  {
    "text": "consumed it means that other consumers can come along and they can say i would like to read messages actually",
    "start": "797600",
    "end": "803120"
  },
  {
    "text": "from earlier on in the log i'd like to repress reprocess us everything that's happened",
    "start": "803120",
    "end": "808800"
  },
  {
    "text": "and this can be really useful because it means that we can write data to a kafka topic based on like a particular requirement",
    "start": "808800",
    "end": "814880"
  },
  {
    "text": "like we need to capture order information into the topic to drive this particular application over here",
    "start": "814880",
    "end": "820480"
  },
  {
    "text": "and then someone else comes along after this initial application is launched and they say oh you've got older information on a topic",
    "start": "820480",
    "end": "826959"
  },
  {
    "text": "that's really useful i would also like to use that so then another consumer can come along without having to be",
    "start": "826959",
    "end": "832639"
  },
  {
    "text": "declared up front or anything like that and they say oh the order's topic brilliant well i've not processed any of them yet",
    "start": "832639",
    "end": "838000"
  },
  {
    "text": "so i'll go back to the beginning of the topic and i'll read all of those and now i'm caught up and i can keep on processing",
    "start": "838000",
    "end": "843040"
  },
  {
    "text": "them and someone else can come along and say well i processed those ones then i made a bit of a mistake so actually",
    "start": "843040",
    "end": "848079"
  },
  {
    "text": "i'm going to rewind my offset back kind of like an hour or so until i make the mistake in my application and i'm going to",
    "start": "848079",
    "end": "854240"
  },
  {
    "text": "reprocess just those particular messages consumers are independent of each other",
    "start": "854240",
    "end": "860560"
  },
  {
    "text": "consumers can seek back and forth in the log to read the messages that they want to and kafka will track where",
    "start": "860560",
    "end": "866480"
  },
  {
    "text": "each consumer has got to again lots of different libraries available",
    "start": "866480",
    "end": "871600"
  },
  {
    "text": "here's an example using go where it'll subscribe to a particular topic and process the messages as they arrive",
    "start": "871600",
    "end": "877839"
  },
  {
    "text": "now consumers if you have a single instance of a consumer will read data from every partition",
    "start": "877839",
    "end": "883519"
  },
  {
    "text": "because you want to make sure you're processing all of the data so without a key the data is distributed",
    "start": "883519",
    "end": "888560"
  },
  {
    "text": "across all partitions the consumer will simply read the data from all of those partitions and process",
    "start": "888560",
    "end": "893760"
  },
  {
    "text": "all of your data you can have a second consumer as we said and that will also read all of the",
    "start": "893760",
    "end": "898800"
  },
  {
    "text": "data from all of the partitions because these are two separate logical applications one",
    "start": "898800",
    "end": "904160"
  },
  {
    "text": "application is processing orders to come out to check for fraud one of them is processing them to check",
    "start": "904160",
    "end": "909199"
  },
  {
    "text": "for like scoring certain characteristics or some other purpose two separate applications now",
    "start": "909199",
    "end": "915600"
  },
  {
    "text": "our first application here c1 the blue box at the top there we say well it's doing fraud processing",
    "start": "915600",
    "end": "920880"
  },
  {
    "text": "and we need to increase the rate which is processing those messages and we've stayed out of the box and",
    "start": "920880",
    "end": "926399"
  },
  {
    "text": "we've put more cpus in and we've done like special dances standing on one leg it still can't process the messages at",
    "start": "926399",
    "end": "932079"
  },
  {
    "text": "the reach which we need to to meet rsla so we say well that's fine we can scale",
    "start": "932079",
    "end": "937519"
  },
  {
    "text": "our particular consumers horizontally we can add in additional instances",
    "start": "937519",
    "end": "942800"
  },
  {
    "text": "of that application so c2 at the bottom there is kind of like out of the picture this is just like it just keeps on doing what",
    "start": "942800",
    "end": "949040"
  },
  {
    "text": "it was doing but c1 the blue one at the top we have now added in additional instances of that application and what",
    "start": "949040",
    "end": "956880"
  },
  {
    "text": "kafka will do is it will say great we've now got what's called a consumer group and it'll say",
    "start": "956880",
    "end": "962639"
  },
  {
    "text": "each of those instances of the application will get data from one or more partitions so if you have",
    "start": "962639",
    "end": "969360"
  },
  {
    "text": "four partitions and four instances of your consumers then each consumer gets one partition",
    "start": "969360",
    "end": "974800"
  },
  {
    "text": "if you had two instances of the application each instance will get two partitions and so on",
    "start": "974800",
    "end": "980880"
  },
  {
    "text": "and kafka keeps track of how many instances you have so you have one and you scale it up or rebalance if you have four and you",
    "start": "980880",
    "end": "988399"
  },
  {
    "text": "lose one it will also rebalance it'll say well that partition four at the bottom there it was getting consumed by that",
    "start": "988399",
    "end": "994959"
  },
  {
    "text": "particular instance but we've lost that one so actually i'll rebalance it now and one of the other instances",
    "start": "994959",
    "end": "1000720"
  },
  {
    "text": "will take over so consumers again client application reads messages",
    "start": "1000720",
    "end": "1006959"
  },
  {
    "text": "from topics we can scale it horizontally as we need to and as before lots of different client libraries",
    "start": "1006959",
    "end": "1013040"
  },
  {
    "text": "available also a rest proxy we need somewhere for all this data to",
    "start": "1013040",
    "end": "1019279"
  },
  {
    "text": "actually reside we need a thing that's going to run these bits and bytes a process that we can lock out and poke and make sure it's",
    "start": "1019279",
    "end": "1025360"
  },
  {
    "start": "1020000",
    "end": "1141000"
  },
  {
    "text": "actually doing what we want it to and this is called the kafka broker we've talked about the events we've",
    "start": "1025360",
    "end": "1030798"
  },
  {
    "text": "built them into a log we've split that up into topics we talked about the apis to getting the data in and out",
    "start": "1030799",
    "end": "1036798"
  },
  {
    "text": "but how do you actually run this thing well what we run is called a broker it's the jvm process and we run one",
    "start": "1036799",
    "end": "1044000"
  },
  {
    "text": "or more of them usually three it's a distributed system we don't have redundancy we want it not to kind of",
    "start": "1044000",
    "end": "1049760"
  },
  {
    "text": "want it to be able to form core and work out who's in charge and stuff like that so we start off usually with three",
    "start": "1049760",
    "end": "1055120"
  },
  {
    "text": "brokers and we can scale it out as we need to for capacity and redundancy requirements",
    "start": "1055120",
    "end": "1061360"
  },
  {
    "text": "because we have partitions these get distributed across those brokers and each broker will be the leader for a",
    "start": "1061360",
    "end": "1067600"
  },
  {
    "text": "particular partition so if you have four partitions and three brokers one of those brokers is going to",
    "start": "1067600",
    "end": "1072640"
  },
  {
    "text": "be the leader for two of the partitions but we also have what are called follower partitions spread out across the other",
    "start": "1072640",
    "end": "1080160"
  },
  {
    "text": "brokers so each topic you can set what's called a replication factor and say i would like to have two",
    "start": "1080160",
    "end": "1087039"
  },
  {
    "text": "replicas or three replicas or how many replicas you need and they'll get spread out across the brokers that you have",
    "start": "1087039",
    "end": "1093360"
  },
  {
    "text": "and because we have redundant copies of the data it means that if we lose a broker so we lose broker three here and",
    "start": "1093360",
    "end": "1099520"
  },
  {
    "text": "a puff of smoke then the other brokers have got that data also and so can take over responsibility for",
    "start": "1099520",
    "end": "1106160"
  },
  {
    "text": "being the leader of that partition",
    "start": "1106160",
    "end": "1109840"
  },
  {
    "text": "so this is kind of neat this is building up the concepts of an event streaming platform this is",
    "start": "1114320",
    "end": "1120400"
  },
  {
    "text": "talking about events that can then be in events streams and unbounded event streams that we can process",
    "start": "1120400",
    "end": "1126000"
  },
  {
    "text": "in a scalable distributed way but we're only actually really getting going this is just the foundations for a",
    "start": "1126000",
    "end": "1133039"
  },
  {
    "text": "platform on which we can build some really powerful applications and what people do with kafka varies",
    "start": "1133039",
    "end": "1139679"
  },
  {
    "text": "sometimes they build out these streaming pipelines sometimes they use them to build event-driven applications or sometimes",
    "start": "1139679",
    "end": "1145200"
  },
  {
    "start": "1141000",
    "end": "1730000"
  },
  {
    "text": "they do both and they can like act as a central nervous system of their organization but let's think about building a",
    "start": "1145200",
    "end": "1151360"
  },
  {
    "text": "streaming pipeline you say i've got data in a database i'd like to use kafka to stream that over to somewhere else let's",
    "start": "1151360",
    "end": "1158000"
  },
  {
    "text": "do analysis stick the data into s3 well we've got the data in kafka so we could also put it into hdfs",
    "start": "1158000",
    "end": "1164799"
  },
  {
    "text": "so you think well we're gonna have to write some code to get that data from the database into kafka we're gonna",
    "start": "1164799",
    "end": "1170080"
  },
  {
    "text": "have to write some code to push it into place three we're gonna have to write some code to put into hdfs looks like a bit of",
    "start": "1170080",
    "end": "1175360"
  },
  {
    "text": "java we need here maybe a little spark maybe something else or we say well let's find pipelines",
    "start": "1175360",
    "end": "1180799"
  },
  {
    "text": "we've got an application that we're going to build and that application is going to be driven by events happening in a database",
    "start": "1180799",
    "end": "1187120"
  },
  {
    "text": "because in that database we can capture what's happening in like an existing application so you can actually link them together",
    "start": "1187120",
    "end": "1192559"
  },
  {
    "text": "using this but again data in the database how we're going to get that into kafka i know i'll write myself some code now as i'd",
    "start": "1192559",
    "end": "1200400"
  },
  {
    "text": "know blackboard tell us this is all a trap because writing code to do integration between systems into",
    "start": "1200400",
    "end": "1207280"
  },
  {
    "text": "kafka and from kafka down to other systems it kind of sounds like fun because we've got databases we've got message queues",
    "start": "1207280",
    "end": "1214080"
  },
  {
    "text": "we've got events stores and all of these different things we want to integrate into kafka so we start off when we write we say",
    "start": "1214080",
    "end": "1220400"
  },
  {
    "text": "well here's the producer api we'll write some code to get the data into kafka and here's the consumer api so we'll",
    "start": "1220400",
    "end": "1226240"
  },
  {
    "text": "write some code to get data from kafka and push it to s3 and then we say well as well as s3 we",
    "start": "1226240",
    "end": "1231520"
  },
  {
    "text": "need to get the data somewhere else so why don't we make it plugable and actually we need it to go kind of like to have high throughput so",
    "start": "1231520",
    "end": "1238080"
  },
  {
    "text": "we'll make it distributed and we need to handle things like schemas and resets and offsets and all this kind of stuff",
    "start": "1238080",
    "end": "1243760"
  },
  {
    "text": "this is great we could like build ourselves a framework we could do all of this stuff well the problem is that's like entry that's",
    "start": "1243760",
    "end": "1250960"
  },
  {
    "text": "kind of like base requirements everyone needs to get data between kafka and a database everyone needs to get data between",
    "start": "1250960",
    "end": "1256720"
  },
  {
    "text": "kafka and s3 so if you spend your time writing code to doing that you're actually differentiating your",
    "start": "1256720",
    "end": "1262559"
  },
  {
    "text": "business you're not solving any real problems that everyone else hasn't done already and this is why kafka provides an",
    "start": "1262559",
    "end": "1268720"
  },
  {
    "text": "integration api for you kafka solve this problem which sounds like a lot of fun to solve but it's been",
    "start": "1268720",
    "end": "1274720"
  },
  {
    "text": "solved already so in terms of wheels to reinvent don't reinvent this one use kafka connect when you need to get",
    "start": "1274720",
    "end": "1281200"
  },
  {
    "text": "data between systems upstream into kafka from kafka downstream to other systems so you can use kafka",
    "start": "1281200",
    "end": "1288400"
  },
  {
    "text": "connect to do this and it's just configuration file based so you say i want to use this connector",
    "start": "1288400",
    "end": "1294240"
  },
  {
    "text": "i'm going to get data from here and i want to write it to here it's a plugable architecture",
    "start": "1294240",
    "end": "1299760"
  },
  {
    "text": "so you say i've got my particular connector for the particular technology i want to integrate with i've got a converter which is like my",
    "start": "1299760",
    "end": "1306159"
  },
  {
    "text": "series for serializing and deserializing is appropriate we can even apply transformations",
    "start": "1306159",
    "end": "1311760"
  },
  {
    "text": "it's an open api it's part of apache kafka so if you're desperate to write some code and you find a system for which there",
    "start": "1311760",
    "end": "1318480"
  },
  {
    "text": "isn't an existing connector you can go and write some code yay rejoice most of the time you don't need",
    "start": "1318480",
    "end": "1324320"
  },
  {
    "text": "to most of the time the connectors will already exist so you head over to confluence hub",
    "start": "1324320",
    "end": "1329600"
  },
  {
    "text": "and type in the particular technology with which you want to integrate and it'll get lists out of different connectors that are available",
    "start": "1329600",
    "end": "1337120"
  },
  {
    "text": "ancient saudis a moment ago i mentioned serializing and deserializing data and it's time now",
    "start": "1337120",
    "end": "1344240"
  },
  {
    "text": "to think about what's within this little box of key value bytes we've talked about how we're going to store",
    "start": "1344240",
    "end": "1350000"
  },
  {
    "text": "them we're going to store them on a log within topics or brokers but what are these bytes and talking",
    "start": "1350000",
    "end": "1356159"
  },
  {
    "text": "about kafka connects and integrating with other systems actually starts us down the road of thought of all how we're going to do",
    "start": "1356159",
    "end": "1362799"
  },
  {
    "text": "this in a way which is going to be resilient to changes which is going to let us evolve rapidly",
    "start": "1362799",
    "end": "1369840"
  },
  {
    "text": "but without tightly coupling things together so within this log of key value bytes",
    "start": "1369840",
    "end": "1376080"
  },
  {
    "text": "what actually is this thing well hopefully it's not this hopefully it's not kind of like well i",
    "start": "1376080",
    "end": "1381600"
  },
  {
    "text": "can eyeball it and i guess it's tab separated maybe color separated maybe white space separated",
    "start": "1381600",
    "end": "1387360"
  },
  {
    "text": "and what are the different field names and what are the data types and are there any fields missing i don't know what are there any defaults i don't know",
    "start": "1387360",
    "end": "1394480"
  },
  {
    "text": "and this is the problem if we don't think about how we're serializing our data because we say well i've got this",
    "start": "1394480",
    "end": "1401039"
  },
  {
    "text": "new application to write so i'm going to use this fancy thing called kafka it's all good i'm going to serialize the data using",
    "start": "1401039",
    "end": "1406400"
  },
  {
    "text": "whichever thing i'm most familiar with or whichever is quickest to get work you know whichever one i found on stack overflow",
    "start": "1406400",
    "end": "1411440"
  },
  {
    "text": "and off we go and then someone gets this payload and they're like well what's this and now this beautiful idea that kafka",
    "start": "1411440",
    "end": "1418480"
  },
  {
    "text": "enables of loosely coupling systems of one team saying i produce data onto a topic",
    "start": "1418480",
    "end": "1424080"
  },
  {
    "text": "and one or more other teams saying i build applications that read data from that topic and a nicely loosely coupled way goes",
    "start": "1424080",
    "end": "1430640"
  },
  {
    "text": "out the window because those people consuming the data have to phone up or email or whatever",
    "start": "1430640",
    "end": "1436159"
  },
  {
    "text": "the people writing the data and say well what on earth is this and what are these fields and then in a",
    "start": "1436159",
    "end": "1441440"
  },
  {
    "text": "couple of weeks well my consumers just stopped working what did you change oh well i changed this thing i didn't realize if anyone was",
    "start": "1441440",
    "end": "1446640"
  },
  {
    "text": "using it so thinking about schemers thinking about serialization is really important",
    "start": "1446640",
    "end": "1452640"
  },
  {
    "text": "because they're completely intertwined so there are different ways to serialize your data if",
    "start": "1452640",
    "end": "1458799"
  },
  {
    "text": "you want to make life easier for yourself in the long run please use something with support for",
    "start": "1458799",
    "end": "1464720"
  },
  {
    "text": "schemas so something like avro something like protobuf something like json schema they let you take the schema from your",
    "start": "1464720",
    "end": "1471360"
  },
  {
    "text": "data and by the way most data has a schema it's just sometimes we choose to ignore the fact because it's",
    "start": "1471360",
    "end": "1476799"
  },
  {
    "text": "easier but it's not easier in the long run it just lets us kind of brush it under the carpets and worry about it later so you've got a schema in",
    "start": "1476799",
    "end": "1484000"
  },
  {
    "text": "your data most of the time if you use avro protobuf json schema you can actually take that schema",
    "start": "1484000",
    "end": "1489600"
  },
  {
    "text": "and it'll get put into the schema registry so confidence scheme registry it's community license partner confluent",
    "start": "1489600",
    "end": "1495039"
  },
  {
    "text": "platform you can then have the schema in there you produce your data into there and then consumers can come along and they",
    "start": "1495039",
    "end": "1500880"
  },
  {
    "text": "can read that data from the schema registry to pull the schema down and deserialize the data when they have the schema",
    "start": "1500880",
    "end": "1507120"
  },
  {
    "text": "available so i'm going to show you a demo at the end time permitting and i'll show you exactly how useful that is the ski registry provides",
    "start": "1507120",
    "end": "1514240"
  },
  {
    "text": "serializers and deserializers those serializers actually let you enforce compatibility",
    "start": "1514240",
    "end": "1519440"
  },
  {
    "text": "guarantees so you can't just decide to change the schema without actually making sure you're not",
    "start": "1519440",
    "end": "1525039"
  },
  {
    "text": "going to break things for other people so it's a hugely good idea",
    "start": "1525039",
    "end": "1530640"
  },
  {
    "text": "let's finish a little tour of the ecosystem by thinking about the kind of",
    "start": "1530640",
    "end": "1536000"
  },
  {
    "text": "applications that we build when we're consuming data now within these particular consumers",
    "start": "1536000",
    "end": "1542480"
  },
  {
    "text": "there's a fairly standard set of patterns that we do when it comes to stream processing we",
    "start": "1542480",
    "end": "1547919"
  },
  {
    "text": "want to read the data and we've got data from like a factory and we're getting information about the widgets being produced",
    "start": "1547919",
    "end": "1554000"
  },
  {
    "text": "and within these widgets as set of data there's only so many things if you boil",
    "start": "1554000",
    "end": "1559840"
  },
  {
    "text": "it down to their basics that you're actually doing with the data one of them like in an example here",
    "start": "1559840",
    "end": "1565200"
  },
  {
    "text": "would be filtering that data so you have a series of events arriving over time unbounded and you say within that",
    "start": "1565200",
    "end": "1572320"
  },
  {
    "text": "stream of data i would like to filter it i would like to say as these events arrive some of",
    "start": "1572320",
    "end": "1577520"
  },
  {
    "text": "the events are about yellow widgets some of them are red widgets when a red widget arrives on this unbounded event stream i would like",
    "start": "1577520",
    "end": "1584159"
  },
  {
    "text": "to write it to a separate stream of data because i've got an application in my business that needs to be driven by",
    "start": "1584159",
    "end": "1590559"
  },
  {
    "text": "red events uh red widgets only so when a red widget occurs my application wants to know about it so",
    "start": "1590559",
    "end": "1596159"
  },
  {
    "text": "i'd like to filter this in downstream and route any red widgets to another stream",
    "start": "1596159",
    "end": "1601760"
  },
  {
    "text": "apache kafka has got a stream processing api it's called kafka streams and it's a",
    "start": "1601760",
    "end": "1607120"
  },
  {
    "text": "java library so if you're writing java applications you pull in this particular library",
    "start": "1607120",
    "end": "1612480"
  },
  {
    "text": "and now you can do stream processing within your applications so the idea here is that instead of",
    "start": "1612480",
    "end": "1618400"
  },
  {
    "text": "building and provisioning and watering and maintaining a separate stack of technology and machines to do your stream processing",
    "start": "1618400",
    "end": "1625279"
  },
  {
    "text": "jobs you actually just build your applications as you did before but now they're stream processing applications",
    "start": "1625279",
    "end": "1631120"
  },
  {
    "text": "so you do your stream processing within your existing applications so you build them you code them you test",
    "start": "1631120",
    "end": "1637039"
  },
  {
    "text": "them you deploy them exactly the same way as your normal applications",
    "start": "1637039",
    "end": "1642720"
  },
  {
    "text": "not everyone codes java not everyone necessarily wants to be doing so so in this case you can",
    "start": "1642720",
    "end": "1649440"
  },
  {
    "text": "use sql using kc equal db to actually declare what you want to do",
    "start": "1649440",
    "end": "1654559"
  },
  {
    "text": "with your stream processing so here we can say i want to create a separate stream and you actually just declare using sql",
    "start": "1654559",
    "end": "1661679"
  },
  {
    "text": "how you want to process that data create a new stream populated by the output of this particular select",
    "start": "1661679",
    "end": "1668000"
  },
  {
    "text": "statement so using key sql db which again is confluent community license it's part of confluent platform it's",
    "start": "1668000",
    "end": "1674080"
  },
  {
    "text": "actually built on top of kafka streams and you can do all of these sorts of different things but using sql",
    "start": "1674080",
    "end": "1680559"
  },
  {
    "text": "so we can say i'd like to filter the data if the data matches this particular condition then write it out to a new stream i'd",
    "start": "1680559",
    "end": "1687679"
  },
  {
    "text": "like to build a stateful aggregation so start counting these things up grouped by this thing",
    "start": "1687679",
    "end": "1693039"
  },
  {
    "text": "or do another stateful aggregation but applying predicates one of the other very common patterns of",
    "start": "1693039",
    "end": "1698480"
  },
  {
    "text": "streaming data is to say well we've got those things or we may be doing one of those particular things what we also want to do is we want to",
    "start": "1698480",
    "end": "1705679"
  },
  {
    "text": "route that data to somewhere else because we're going to do some ad hoc analytics we'll see some machine learning on that",
    "start": "1705679",
    "end": "1711679"
  },
  {
    "text": "data so here we can use kafka connect with key sql db as a wrapper around it say as this data arrives maybe we can",
    "start": "1711679",
    "end": "1719039"
  },
  {
    "text": "like cleanse it or tie these up a little bit but we then take that data and we just write it to",
    "start": "1719039",
    "end": "1724159"
  },
  {
    "text": "somewhere else right let me show you a bit of an example of this",
    "start": "1724159",
    "end": "1730240"
  },
  {
    "start": "1730000",
    "end": "2242000"
  },
  {
    "text": "uh in action and then we'll wrap up and if time allows we'll do some questions if not we'll head over to slack",
    "start": "1730240",
    "end": "1735520"
  },
  {
    "text": "and we can do them over there so the demo i'm going to show you is this one here and it comes from i'll",
    "start": "1735520",
    "end": "1742320"
  },
  {
    "text": "show you this from the confluence demo scene repository",
    "start": "1742320",
    "end": "1748320"
  },
  {
    "text": "so demonstrating repository it's got a ton of different demos and they're all based around docker and docker compose",
    "start": "1750640",
    "end": "1755840"
  },
  {
    "text": "so the cool thing is if you see something that sounds interesting you can say well i've got docker i've got docker compose pull down the code",
    "start": "1755840",
    "end": "1762159"
  },
  {
    "text": "docker goes up and then you can just follow it through and try it out so this is the one i'm showing you here",
    "start": "1762159",
    "end": "1767840"
  },
  {
    "text": "i've got a little cheat sheet because i can never remember all of these things and not fat finger them when i'm typing them live but you can actually take this you can",
    "start": "1767840",
    "end": "1774159"
  },
  {
    "text": "run it for yourself at home and try it out so if i do this and do this we're going",
    "start": "1774159",
    "end": "1780960"
  },
  {
    "text": "to just check that everything's um up first",
    "start": "1780960",
    "end": "1786080"
  },
  {
    "text": "okay so this is case equal db so i'm going to show you an example of k sql db taking some data so if i say",
    "start": "1786159",
    "end": "1794000"
  },
  {
    "text": "show topics we have a look at the topics that we've got on my cluster i've got a topic called trades so what k",
    "start": "1794000",
    "end": "1800159"
  },
  {
    "text": "sql db you can do as well as like all the sql stuff which i'll show you it can also act as simply producer and",
    "start": "1800159",
    "end": "1806159"
  },
  {
    "text": "consumer so if i say print trades it's going to act as a consumer and simply go to the topic and say",
    "start": "1806159",
    "end": "1812159"
  },
  {
    "text": "what's the data in this topic now we've got about a bunch of stock trade data arriving continually",
    "start": "1812159",
    "end": "1817919"
  },
  {
    "text": "if i pause the output you can see we've got it's got a key and it's got a value it's got that was it a buy or sell the quantity the symbol",
    "start": "1817919",
    "end": "1824880"
  },
  {
    "text": "and so on but this is just acting as a consumer dumping it to the console which is kind of useful it's actually",
    "start": "1824880",
    "end": "1830799"
  },
  {
    "text": "worked out how data's been serialized now we're going to say well let's",
    "start": "1830799",
    "end": "1836240"
  },
  {
    "text": "declare ourselves a stream and a stream in case equal db is a kafka topic",
    "start": "1836240",
    "end": "1841600"
  },
  {
    "text": "it's all simply a kafka topic but with a schema i talked about schemas earlier and we see now why thinking about how we",
    "start": "1841600",
    "end": "1848480"
  },
  {
    "text": "serialize data when we write it to kafka is so important because as a user of that data",
    "start": "1848480",
    "end": "1854080"
  },
  {
    "text": "i've come along to the cluster i've been authorized to do so i can access the data now i say i've got a",
    "start": "1854080",
    "end": "1860159"
  },
  {
    "text": "stream of data called trades and i say create stream against it i can say describe",
    "start": "1860159",
    "end": "1865519"
  },
  {
    "text": "that stream that you've just created it says well here's the schema so i've not had to go along to the",
    "start": "1865519",
    "end": "1871039"
  },
  {
    "text": "person who wrote that data and say well okay so you use json i can eyeball it i've guessed that these are the data types is that right",
    "start": "1871039",
    "end": "1877600"
  },
  {
    "text": "i've guessed that there aren't any fields missing because they used avro there's actually an explicit schema being declared so my",
    "start": "1877600",
    "end": "1884640"
  },
  {
    "text": "consuming application which in this case is key sequel db could go to the scheme registry and pull down the teamer but it would also work",
    "start": "1884640",
    "end": "1890880"
  },
  {
    "text": "with just like a native consumer application or kafka connect pulls down the schema and now people can",
    "start": "1890880",
    "end": "1896480"
  },
  {
    "text": "use it and because we have a schema we can actually do projections within that data",
    "start": "1896480",
    "end": "1901919"
  },
  {
    "text": "and apply protocols so you can say select the uh the side and the quantity",
    "start": "1901919",
    "end": "1907279"
  },
  {
    "text": "from trades where symbol is this so now it's processing that stream of data",
    "start": "1907279",
    "end": "1912399"
  },
  {
    "text": "as it arrives and we could also have told it to go back to the beginning of the topic and process all of the data from the topic this is",
    "start": "1912399",
    "end": "1918399"
  },
  {
    "text": "just processing the data in the topic as it arrives now and it's applying that filter it writes out to the screen",
    "start": "1918399",
    "end": "1924559"
  },
  {
    "text": "because this is a select statement if i say create stream test",
    "start": "1924559",
    "end": "1929760"
  },
  {
    "text": "as so create stream is going to actually create a kafka topic and write the results of this select",
    "start": "1929760",
    "end": "1936720"
  },
  {
    "text": "to that topic so we've created that and i can say print actually show topics",
    "start": "1936720",
    "end": "1944000"
  },
  {
    "text": "oh dear that's always fun in live demos when it does that it's not done that usually let's give it",
    "start": "1944000",
    "end": "1950240"
  },
  {
    "text": "a second see if it's going to behave show topics there we go so we've got a",
    "start": "1950240",
    "end": "1956159"
  },
  {
    "text": "topic called test and i can say print test and now it's saying here are the messages arriving on",
    "start": "1956159",
    "end": "1961919"
  },
  {
    "text": "that topic so it was really a consumer against it so we've taken an inbound topic",
    "start": "1961919",
    "end": "1967200"
  },
  {
    "text": "we said pick out these particular fields where it matches this particular condition in the data",
    "start": "1967200",
    "end": "1972320"
  },
  {
    "text": "and write it out to a new topic and it's just a kafka topic so we can have other applications consuming from that data",
    "start": "1972320",
    "end": "1977840"
  },
  {
    "text": "from that topic if they wanted to we could also do other things with this data we can say well we've got all this",
    "start": "1977840",
    "end": "1983679"
  },
  {
    "text": "information about these trades arriving i would like to aggregate that data and write it to a database",
    "start": "1983679",
    "end": "1989200"
  },
  {
    "text": "we're going to do some reporting from the database but we want to pre-aggregate it for performance reasons before we write it to the database so we",
    "start": "1989200",
    "end": "1996320"
  },
  {
    "text": "can do this we can build ourselves so it's called a table in case equal db and a table is much",
    "start": "1996320",
    "end": "2002080"
  },
  {
    "text": "more like a relational database table it's key value state so here we're saying create a table",
    "start": "2002080",
    "end": "2007919"
  },
  {
    "text": "we're going to do uh select the the side so is it a bios cell uh we're going to count up the",
    "start": "2007919",
    "end": "2013279"
  },
  {
    "text": "trades and the total value where the symbol is this",
    "start": "2013279",
    "end": "2018960"
  },
  {
    "text": "let me give you that so now we've created that query first show tables we've now got a table called",
    "start": "2018960",
    "end": "2025679"
  },
  {
    "text": "that and say select star from that table",
    "start": "2025679",
    "end": "2030480"
  },
  {
    "text": "and if we say emit changes we can see what's happening in it and it changes",
    "start": "2030880",
    "end": "2036880"
  },
  {
    "text": "and what i did up here was i said set offset to the earliest so here i said",
    "start": "2037440",
    "end": "2043279"
  },
  {
    "text": "when you build that table go and process all of the data in that topic so you can see here our case equal db is",
    "start": "2043279",
    "end": "2049599"
  },
  {
    "text": "basically acting as a consumer just like a few levels of abstraction up but then the consumer can just go back",
    "start": "2049599",
    "end": "2055358"
  },
  {
    "text": "and forth in the topic as it wants to we can process from the end we can say actually now ours process",
    "start": "2055359",
    "end": "2060960"
  },
  {
    "text": "from the beginning so we've created that table and now we're selecting from that table",
    "start": "2060960",
    "end": "2066960"
  },
  {
    "text": "so you've got your row key here which is the buy and sell we're doing a windowed aggregation so",
    "start": "2066960",
    "end": "2072158"
  },
  {
    "text": "we're saying uh break it down by 15 minutes so every 15 minutes tell me how many trades have",
    "start": "2072159",
    "end": "2077839"
  },
  {
    "text": "there been what's the total value and so on and the time stamp here is the um unix epoch so",
    "start": "2077839",
    "end": "2083280"
  },
  {
    "text": "you have to take my word for it they are 15 minute windows we'll see in a moment a proper proof of that and you can see",
    "start": "2083280",
    "end": "2090240"
  },
  {
    "text": "it's continually updating because as trades arrive that match the predicate the aggregate changes that's",
    "start": "2090240",
    "end": "2095760"
  },
  {
    "text": "where the aggregate re-emits its value but k-sql db is maintaining that aggregates itself in memory",
    "start": "2095760",
    "end": "2102000"
  },
  {
    "text": "it's done in a distributed way so you can scale out k sequel db and it's also persisted down to kafka in",
    "start": "2102000",
    "end": "2107920"
  },
  {
    "text": "the background as well so if you lose a node uh it can rebuild that state it's kind of clever but now let's take that",
    "start": "2107920",
    "end": "2114079"
  },
  {
    "text": "aggregate that we've built and we're maintaining within k sequel db and let's push it down to a database so",
    "start": "2114079",
    "end": "2120240"
  },
  {
    "text": "here is kafka connects using k sql db is a wrap around it create a connector",
    "start": "2120240",
    "end": "2125440"
  },
  {
    "text": "using the jdbc sync connector go push it over to postgres so we're going to do that create",
    "start": "2125440",
    "end": "2131119"
  },
  {
    "text": "connector show connectors make sure it's working and it says it is and if i come out of",
    "start": "2131119",
    "end": "2136720"
  },
  {
    "text": "kc or db and head into postgres okay so another sql command prompt but",
    "start": "2136720",
    "end": "2142480"
  },
  {
    "text": "it's postgres this time if i say select everything from this table",
    "start": "2142480",
    "end": "2147599"
  },
  {
    "text": "you can see we've now got that data in postgres so we're not doing any aggregates here we're just saying select everything from here",
    "start": "2147599",
    "end": "2153359"
  },
  {
    "text": "with an order by clause and you can see here's our time windows so this is uh this must be utc",
    "start": "2153359",
    "end": "2160160"
  },
  {
    "text": "so i'm bst over here this is utc on server that's showing so 8 30 here is the most recent time",
    "start": "2160160",
    "end": "2166960"
  },
  {
    "text": "window and that's 8 30 time window is still open okay it started like six minutes ago and if i re-run this query i'm pretty",
    "start": "2166960",
    "end": "2174079"
  },
  {
    "text": "sure in this source topic new messages will have arrived matching the predicate therefore in case equal db the aggregate would have",
    "start": "2174079",
    "end": "2180480"
  },
  {
    "text": "updated which means it will be pushed over to the database so if i re-query it if we look at these values here we're going to",
    "start": "2180480",
    "end": "2186960"
  },
  {
    "text": "expect them to change when i re-query it if we select that we can see those have changed",
    "start": "2186960",
    "end": "2192240"
  },
  {
    "text": "because the source aggregate has changed so it's updated it in place in the database",
    "start": "2192240",
    "end": "2198800"
  },
  {
    "text": "so what we've built out here is a topic of data being populated from somewhere",
    "start": "2198800",
    "end": "2204640"
  },
  {
    "text": "it could be from kafka connect pulling in from another database or a message queue it could be a producing application",
    "start": "2204640",
    "end": "2211040"
  },
  {
    "text": "streaming it into a kafka topic it could be anywhere like most systems nowadays integrate with kafka data arriving in kafka topic we've",
    "start": "2211040",
    "end": "2218240"
  },
  {
    "text": "written a few lines of sequel to say we'll take this data filter it and aggregate it and then",
    "start": "2218240",
    "end": "2223520"
  },
  {
    "text": "another sql statement say take that aggregate and push it down continually to this particular place",
    "start": "2223520",
    "end": "2229040"
  },
  {
    "text": "which here is a database it could be elasticsearch it could be snowflake could be anywhere else",
    "start": "2229040",
    "end": "2235680"
  },
  {
    "text": "so that is a brief tour of the kafka ecosystem we started off",
    "start": "2238320",
    "end": "2245119"
  },
  {
    "start": "2242000",
    "end": "2356000"
  },
  {
    "text": "with a concept of an event very very abstract these events are happening all around us they",
    "start": "2245119",
    "end": "2250160"
  },
  {
    "text": "muddle what happens in our businesses we say well let's call it a key value pair it's just information and it's got a key we're",
    "start": "2250160",
    "end": "2257040"
  },
  {
    "text": "going to capture it in an append only immutable distributed commit log and that log sits at the",
    "start": "2257040",
    "end": "2264160"
  },
  {
    "text": "heart of apache kafka we've got producer and consumer api so getting data in and out and we've got the kafka connects",
    "start": "2264160",
    "end": "2271359"
  },
  {
    "text": "api to do an integration between systems upstream into kafka and from kafka downstream to",
    "start": "2271359",
    "end": "2277119"
  },
  {
    "text": "other systems and doing so in a streaming fashion that's also distributed and resilient and we can do stream processing using",
    "start": "2277119",
    "end": "2283200"
  },
  {
    "text": "the kafka streams api and this is all part of apache kafka",
    "start": "2283200",
    "end": "2288640"
  },
  {
    "text": "we then talked about some of the other pieces of the puzzle of the broader ecosystem so in confluent platform we add in the",
    "start": "2288640",
    "end": "2294240"
  },
  {
    "text": "community license schema registry the community license key sql db also for doing stream processing",
    "start": "2294240",
    "end": "2301119"
  },
  {
    "text": "so if you want to learn more about kafka and some of the concepts around all of this you can go to that qr",
    "start": "2301119",
    "end": "2307119"
  },
  {
    "text": "code you can go to the url there download these books for free if you're interested in the concept",
    "start": "2307119",
    "end": "2312400"
  },
  {
    "text": "of a distributed commit log the iheart logs book is particularly interesting it goes into like",
    "start": "2312400",
    "end": "2317440"
  },
  {
    "text": "why is this so important it's such a simple concept but it powers so many important things",
    "start": "2317440",
    "end": "2323839"
  },
  {
    "text": "and then to learn more about kafka head over to developer.confluence.io",
    "start": "2323839",
    "end": "2328960"
  },
  {
    "text": "and here you can find a whole bunch of tutorials to take you through lots of different concepts there's podcasts there's videos there's",
    "start": "2328960",
    "end": "2335680"
  },
  {
    "text": "a whole bunch more so with that thank you very much for your time and have a great day",
    "start": "2335680",
    "end": "2354880"
  },
  {
    "text": "you",
    "start": "2354880",
    "end": "2356960"
  }
]
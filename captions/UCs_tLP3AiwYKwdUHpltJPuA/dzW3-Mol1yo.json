[
  {
    "start": "0",
    "end": "52000"
  },
  {
    "text": "I'm duraj mahapatra I'm a principal s specialist ESS I focus on Financial Services customers and this topic has",
    "start": "12599",
    "end": "20880"
  },
  {
    "text": "something that has come up really well when it comes to financial services and then I met Umar working on",
    "start": "20880",
    "end": "28519"
  },
  {
    "text": "the same topic as well so let um introduce hi everyone Umar radas I'm",
    "start": "28519",
    "end": "33600"
  },
  {
    "text": "also a Solutions architect at AWS I focus on serverless nice to meet you all today",
    "start": "33600",
    "end": "39280"
  },
  {
    "text": "thank you Ma so this is something that we both are passionate about talking about how servoless and event driven",
    "start": "39280",
    "end": "45680"
  },
  {
    "text": "patterns can be applied to generative AI uh with that let's look at what our",
    "start": "45680",
    "end": "51280"
  },
  {
    "text": "agenda will be today well well gen or generative AI in general is how many how",
    "start": "51280",
    "end": "59160"
  },
  {
    "start": "52000",
    "end": "100000"
  },
  {
    "text": "many of you have heard about geni almost everybody right it's it's it's not new it is like constantly it's",
    "start": "59160",
    "end": "66159"
  },
  {
    "text": "like if you are walking you'll hear Hey Foundation model generative AI so you'll be listening to those terms more often",
    "start": "66159",
    "end": "73640"
  },
  {
    "text": "so we'll give a brief introduction we'll not dive deeper we'll talk about what generative AI is and how that fits into",
    "start": "73640",
    "end": "80240"
  },
  {
    "text": "industry use cases and then look at where seress and even driven patterns",
    "start": "80240",
    "end": "85520"
  },
  {
    "text": "can help for you to build generative AI applications and then overall we'll see",
    "start": "85520",
    "end": "91799"
  },
  {
    "text": "the bigger picture like spanning out we'll see the bigger picture how all of these things can be stitched together",
    "start": "91799",
    "end": "98159"
  },
  {
    "text": "okay with that okay the most common and the most foundational part of generative",
    "start": "98159",
    "end": "105079"
  },
  {
    "start": "100000",
    "end": "446000"
  },
  {
    "text": "AI no pun intend it's called Foundation models right so what are Foundation",
    "start": "105079",
    "end": "110600"
  },
  {
    "text": "models Foundation models as part of generative AI they have",
    "start": "110600",
    "end": "115920"
  },
  {
    "text": "nothing new but we have done it already using models were built from scratch but",
    "start": "115920",
    "end": "122560"
  },
  {
    "text": "Foundation models has already been trained and built on a vast majority of data so that's what you get when you do",
    "start": "122560",
    "end": "129959"
  },
  {
    "text": "generative AI with Foundation models in general generative AI with Gen AI you",
    "start": "129959",
    "end": "135959"
  },
  {
    "text": "can create and I I'll use the word gen instead of generative AI because I can save some time with geni you can create",
    "start": "135959",
    "end": "142720"
  },
  {
    "text": "new contents you can create new uh images you can create new videos and you",
    "start": "142720",
    "end": "148400"
  },
  {
    "text": "can do a lot of stuff and all of that is powered by large models and the reason it has become so",
    "start": "148400",
    "end": "155760"
  },
  {
    "text": "popular is because it's pre-trained you don't have your data science team go and",
    "start": "155760",
    "end": "161920"
  },
  {
    "text": "train them Based on data they are already trained so you can very well go there and directly use them right for",
    "start": "161920",
    "end": "168879"
  },
  {
    "text": "example it can learn English vocabulary and create a poem for you so you can",
    "start": "168879",
    "end": "174480"
  },
  {
    "text": "just give two texts and say write a poem for step functions and even bridge and",
    "start": "174480",
    "end": "179760"
  },
  {
    "text": "and I will get a poem on step functions in even Bridge so that is what power of generative AI",
    "start": "179760",
    "end": "185519"
  },
  {
    "text": "is the core of generative AI or Foundation models is how you deal with",
    "start": "185519",
    "end": "192840"
  },
  {
    "text": "texts llms are large language models large language models are trained on",
    "start": "192840",
    "end": "198959"
  },
  {
    "text": "text and they are the subset of all Foundation models that we see today so",
    "start": "198959",
    "end": "205159"
  },
  {
    "text": "what llms can be used to produce those text contents",
    "start": "205159",
    "end": "210319"
  },
  {
    "text": "and you can make more use of those text contents you can take that output as",
    "start": "210319",
    "end": "215680"
  },
  {
    "text": "input to a new prompt or new content and you can go keep on working on them and you can build something very new and",
    "start": "215680",
    "end": "222959"
  },
  {
    "text": "very drastic that is totally different from what you had earlier so the core part of using a",
    "start": "222959",
    "end": "228760"
  },
  {
    "text": "generative AI or large language models is something called prompts so think of",
    "start": "228760",
    "end": "234640"
  },
  {
    "text": "a kid so you you have a intelligent kid who knows everything about about the",
    "start": "234640",
    "end": "239959"
  },
  {
    "text": "internet everything about the world but you have to ask the kid the right",
    "start": "239959",
    "end": "245239"
  },
  {
    "text": "question in the right way that's what prompts are when you talk about prompts",
    "start": "245239",
    "end": "252439"
  },
  {
    "text": "we have to engineer prompts to make sure that these prompts are available for llms or large language models and with",
    "start": "252439",
    "end": "259880"
  },
  {
    "text": "those prompts you can go ahead and get your work done some of the examples like",
    "start": "259880",
    "end": "265440"
  },
  {
    "text": "write a poem on music and Nashville you can get get a good poem out of your llms",
    "start": "265440",
    "end": "271880"
  },
  {
    "text": "or any text based models you can even ask llms to create code for you like if",
    "start": "271880",
    "end": "277759"
  },
  {
    "text": "you can ask let give me a python code using boto3 client or just give me a python code which uploads objects to S3",
    "start": "277759",
    "end": "285360"
  },
  {
    "text": "those things are possible now there are other ways as well you can ask uh llms",
    "start": "285360",
    "end": "291479"
  },
  {
    "text": "to provide you text and in that case you have to train them you have to like Hey",
    "start": "291479",
    "end": "296880"
  },
  {
    "text": "kid hold on listen to me this is how it should should work can you give me a new output that looks like this so one",
    "start": "296880",
    "end": "305240"
  },
  {
    "text": "example is you can provide some context and say I have these many tweets and these are the sentiments can you go and",
    "start": "305240",
    "end": "311919"
  },
  {
    "text": "figure out the sentiment for the last tweet which is the new hot chicken restaurant in Nashville was",
    "start": "311919",
    "end": "319080"
  },
  {
    "text": "incredible right so the one we saw earlier is termed as zero short",
    "start": "319080",
    "end": "325919"
  },
  {
    "text": "prompting you did not provide any context to that llm and the llm was able to provide you an answer so you there",
    "start": "325919",
    "end": "333400"
  },
  {
    "text": "was no shot from your side so it's a zero shot but in the next uh category we",
    "start": "333400",
    "end": "339000"
  },
  {
    "text": "had few shots we had to provide some context we have to provide some training uh to to to the LM to provide a expected",
    "start": "339000",
    "end": "347280"
  },
  {
    "text": "outputs that's called few short prompting there are many more we have fine tuning as well but we not going to",
    "start": "347280",
    "end": "353160"
  },
  {
    "text": "touch on fine tuning but keep in mind prompt engineering is something very critical the the more you become very",
    "start": "353160",
    "end": "359960"
  },
  {
    "text": "intuitive and more sophisticated in writing prompts the better you will see outputs coming from",
    "start": "359960",
    "end": "367639"
  },
  {
    "text": "LMS on AWS you can access Foundation models two ways one we recently made",
    "start": "367960",
    "end": "376520"
  },
  {
    "text": "Amazon badrock generally available which is serverless and it's is the most fastest and easiest way for you to build",
    "start": "376520",
    "end": "383160"
  },
  {
    "text": "a gen application right so you can go to Amazon Bedrock console you can",
    "start": "383160",
    "end": "389880"
  },
  {
    "text": "say write a poem on Nashville and music and Bedrock will give you a response on",
    "start": "389880",
    "end": "395080"
  },
  {
    "text": "top of that there is a button in Bedrock console where you can click and see how",
    "start": "395080",
    "end": "400560"
  },
  {
    "text": "the API call would look like what should be my Json data if I have to make the same question why an API call so it's",
    "start": "400560",
    "end": "408520"
  },
  {
    "text": "very intuitive it's fully servoless the other form where you can use Foundation",
    "start": "408520",
    "end": "414080"
  },
  {
    "text": "models and before badrock we have been using this more often was using sagemaker jump start with Amazon",
    "start": "414080",
    "end": "421319"
  },
  {
    "text": "salemaker jump start you can get third party models you can get the models that are already available in Bedrock as well",
    "start": "421319",
    "end": "427599"
  },
  {
    "text": "you have to bring them up in a cluster in an instance and make them available for inference right so there are",
    "start": "427599",
    "end": "434520"
  },
  {
    "text": "dedicated instances or Computing that is available that you can use and you can make it up and running and use the same",
    "start": "434520",
    "end": "441319"
  },
  {
    "text": "way when when you do an inferencing you can use the same way like you did with bedrock let's look at some industry use",
    "start": "441319",
    "end": "448000"
  },
  {
    "start": "446000",
    "end": "696000"
  },
  {
    "text": "cases now that you have known about Foundation models llms what are uh what",
    "start": "448000",
    "end": "453879"
  },
  {
    "text": "is Amazon Bedrock prompts Sage maker jump starts where do we apply this right",
    "start": "453879",
    "end": "459520"
  },
  {
    "text": "that's the most common question you will see some of the use cases include it's",
    "start": "459520",
    "end": "464639"
  },
  {
    "text": "not limited to these months but the major ones which I have seen which Uma and I we have seen is like when you",
    "start": "464639",
    "end": "471120"
  },
  {
    "text": "think about SCS like healthcare Life Sciences we have medical",
    "start": "471120",
    "end": "476360"
  },
  {
    "text": "transcriptions which are scattered across multiple areas multiple documents it can be a recording it can be an audio",
    "start": "476360",
    "end": "483720"
  },
  {
    "text": "it can be a PDF document they're all scattered across and stored somewhere which is not accessible not",
    "start": "483720",
    "end": "490240"
  },
  {
    "text": "searchable with llms or with generative AI you can gather them you can summarize",
    "start": "490240",
    "end": "496560"
  },
  {
    "text": "them and you can make them available in a very comprehensive way to medical professionals like doctors and nurses so",
    "start": "496560",
    "end": "503159"
  },
  {
    "text": "that with few clicks or few minutes they will be able to get the entire Det",
    "start": "503159",
    "end": "509240"
  },
  {
    "text": "details of a case if they're working on if they're training on how should I do this surgery have we seen these cases",
    "start": "509240",
    "end": "515279"
  },
  {
    "text": "earlier you can summarize those kind of data and make them available readily so",
    "start": "515279",
    "end": "520360"
  },
  {
    "text": "it will save valuable time for medical professionals other one which I'm very",
    "start": "520360",
    "end": "526200"
  },
  {
    "text": "closely working with right now is Insurance CA documents so think of a",
    "start": "526200",
    "end": "531959"
  },
  {
    "text": "Property and Casualty Insurance it doesn't limit to property in casualty if you have any insurance or if you are an",
    "start": "531959",
    "end": "538399"
  },
  {
    "text": "any insurance provider provider when any claims that is filed whether it's a car",
    "start": "538399",
    "end": "543600"
  },
  {
    "text": "claim or a life insurance claim or any device Insurance claim whatever claim is filed you can do some as an insurance",
    "start": "543600",
    "end": "551240"
  },
  {
    "text": "provider you can do some additional checks to figure out whether the data that was provided as an image has any",
    "start": "551240",
    "end": "559160"
  },
  {
    "text": "anomalies has any fraud or you can based on that summary of the report you can",
    "start": "559160",
    "end": "564519"
  },
  {
    "text": "move forward and see what based on that context of data contextual data you can see what should be the next step how",
    "start": "564519",
    "end": "571560"
  },
  {
    "text": "should I move forward and deal with this claim process so that's a good benefit of uh generative",
    "start": "571560",
    "end": "577680"
  },
  {
    "text": "AI here's a QR code where which leads you to a Blog which I wrote with the",
    "start": "577680",
    "end": "583480"
  },
  {
    "text": "AIML team at AWS it talks about intelligent document processing using generative",
    "start": "583480",
    "end": "589959"
  },
  {
    "text": "AI the next use case is pretty common you'll see more common because this is",
    "start": "589959",
    "end": "596320"
  },
  {
    "text": "mainly related to one of the major uh gen use cases which is chat Bots or Q",
    "start": "596320",
    "end": "603240"
  },
  {
    "text": "Q&A question and answer think of a case where you have a customer service agent in your organization and they are on",
    "start": "603240",
    "end": "609959"
  },
  {
    "text": "call with your customers right how can you feed actual and valuable data back",
    "start": "609959",
    "end": "617200"
  },
  {
    "text": "to the agent so that the next question the agent asks to the customer can be",
    "start": "617200",
    "end": "622760"
  },
  {
    "text": "much more useful to the customer so if you have uh a customer on call and and",
    "start": "622760",
    "end": "629279"
  },
  {
    "text": "you transcribe that voice and feed that to a foundation model and Foundation model will give back set of questions",
    "start": "629279",
    "end": "635480"
  },
  {
    "text": "hey agent go and ask this question because it makes more sense to ask it right now then the agent picks it up and",
    "start": "635480",
    "end": "641240"
  },
  {
    "text": "asks the question while on call so in this case Foundation models or J acts as",
    "start": "641240",
    "end": "646760"
  },
  {
    "text": "an assistant for the service agent last but not the",
    "start": "646760",
    "end": "652800"
  },
  {
    "text": "least this is one of my favorite because Market content uh generation is going to",
    "start": "652800",
    "end": "658839"
  },
  {
    "text": "be very common with Gen our marketing team or your marketing team in organizations they work a lot to figure",
    "start": "658839",
    "end": "666360"
  },
  {
    "text": "out how content should be like images and videos but now with generative",
    "start": "666360",
    "end": "671680"
  },
  {
    "text": "AI you can tell them you don't have to build images from scratch just provide",
    "start": "671680",
    "end": "678320"
  },
  {
    "text": "the valuable text and we have models like stable diffusion mid journey and",
    "start": "678320",
    "end": "683959"
  },
  {
    "text": "Dolly who can create images for you and we can refine that image if required",
    "start": "683959",
    "end": "689480"
  },
  {
    "text": "so it will save a lot of time and lot of money",
    "start": "689480",
    "end": "695079"
  },
  {
    "text": "okay so one major question why use seress with generative AI right so",
    "start": "695079",
    "end": "701040"
  },
  {
    "start": "696000",
    "end": "901000"
  },
  {
    "text": "Foundation model can coherently respond to prompts on subject that haven't been",
    "start": "701040",
    "end": "706120"
  },
  {
    "text": "explicitly trained on but there are many challenges to using Foundation models",
    "start": "706120",
    "end": "712680"
  },
  {
    "text": "and one of the challenge is how do you build an application that sits behind or",
    "start": "712680",
    "end": "718560"
  },
  {
    "text": "sits in front of the foundation model that actually works as your business logic right so Foundation model are",
    "start": "718560",
    "end": "726440"
  },
  {
    "text": "generally stateless so if you ask a question 2 minutes later if you ask another question related to the previous",
    "start": "726440",
    "end": "732399"
  },
  {
    "text": "one without additional without if you follow a zero shot prompting it won't",
    "start": "732399",
    "end": "737519"
  },
  {
    "text": "understand what you're asking for so what you have to do is build a capability right in front of those",
    "start": "737519",
    "end": "743240"
  },
  {
    "text": "models to make sure that when you ask a question it has a context to reply you",
    "start": "743240",
    "end": "751320"
  },
  {
    "text": "back based on whatever you asked earlier so you have to build some context awareness you have to build some smart",
    "start": "751320",
    "end": "757519"
  },
  {
    "text": "prompting you have to build a lot of other use cases which will need actual application code or orchestration of",
    "start": "757519",
    "end": "764199"
  },
  {
    "text": "some code and some business logic has to live",
    "start": "764199",
    "end": "769360"
  },
  {
    "text": "behind that's where you think about serverless because with serverless you get the power of services like Lambda",
    "start": "769360",
    "end": "777160"
  },
  {
    "text": "functions ECS fogy uh even Bridge API Gateway sqs SNS Etc",
    "start": "777160",
    "end": "783560"
  },
  {
    "text": "and then they can directly work with the power of generative AI that is given by",
    "start": "783560",
    "end": "789000"
  },
  {
    "text": "services like Amazon Bedrock stage maker jump and you can do all of that while",
    "start": "789000",
    "end": "794399"
  },
  {
    "text": "writing code which is being driven by Amazon code Whisperer which are which is",
    "start": "794399",
    "end": "799480"
  },
  {
    "text": "our generative a solution to write code for you so with that combination you",
    "start": "799480",
    "end": "805560"
  },
  {
    "text": "should be able to rapidly deliver smarter applications and innovate",
    "start": "805560",
    "end": "810760"
  },
  {
    "text": "faster so to summarize the benefits of serverless architecture around gen we",
    "start": "810760",
    "end": "816320"
  },
  {
    "text": "know that sess architecture can handle Spike of traffic it can scale up and down in relatively less time so if you",
    "start": "816320",
    "end": "825240"
  },
  {
    "text": "have requirements where it has to scale Up and Down based on generative AI requests so surus would be a good fit",
    "start": "825240",
    "end": "832839"
  },
  {
    "text": "the most important one to look at is generative AI or the foundation models",
    "start": "832839",
    "end": "838440"
  },
  {
    "text": "they are pretty new the market is pretty new so which means it is still evolving it is still shaping up so you cannot go",
    "start": "838440",
    "end": "846040"
  },
  {
    "text": "and uh get one model to run in production for any number of days because the model will keep on growing",
    "start": "846040",
    "end": "853040"
  },
  {
    "text": "the number of parameters of that model will keep on growing and you there will be a requirement for you to shift from",
    "start": "853040",
    "end": "858880"
  },
  {
    "text": "Model A to model B so with seress application you'll have the flexibility to change it change the uh",
    "start": "858880",
    "end": "866480"
  },
  {
    "text": "specifications and move to a new model again with serverless you save on cost",
    "start": "866480",
    "end": "871680"
  },
  {
    "text": "and you enable integration with different services so this is one of the biggest example of a Greenfield",
    "start": "871680",
    "end": "878279"
  },
  {
    "text": "application because jna is Greenfield by itself where serus fits best because",
    "start": "878279",
    "end": "883720"
  },
  {
    "text": "when we think about serverless and you're building something new you would ideally think of going serverless first",
    "start": "883720",
    "end": "890959"
  },
  {
    "text": "and gen is new so it it immediately fits in to become serverless first and at the",
    "start": "890959",
    "end": "897759"
  },
  {
    "text": "result of that is that you can build capabilities faster now I'll go through some of the",
    "start": "897759",
    "end": "903079"
  },
  {
    "start": "901000",
    "end": "1132000"
  },
  {
    "text": "services which you have already heard earlier in the rest of the day before",
    "start": "903079",
    "end": "908199"
  },
  {
    "text": "but at the core of a serverless service in Amazon or in AWS is Lambda",
    "start": "908199",
    "end": "914360"
  },
  {
    "text": "functions I think everybody knows here Lambda functions with the show of hand how it works so it's actually a business",
    "start": "914360",
    "end": "922160"
  },
  {
    "text": "code that you can write as a function any event that comes in can trigger a Lambda function and the most critical",
    "start": "922160",
    "end": "927360"
  },
  {
    "text": "part is you can integrate that with other services be it S3 Dynamo DB or a",
    "start": "927360",
    "end": "932759"
  },
  {
    "text": "foundation model so ECS and then sorry uh Lambda",
    "start": "932759",
    "end": "938240"
  },
  {
    "text": "function and then we have foget on Amazon ECS if you have built container",
    "start": "938240",
    "end": "943839"
  },
  {
    "text": "application and you want to run them on a container orchestrator then you would not get a better combination of AWS fet",
    "start": "943839",
    "end": "951279"
  },
  {
    "text": "running on Amazon ECS you don't have any container host to upgrade you don't have",
    "start": "951279",
    "end": "956800"
  },
  {
    "text": "cluster capacity management and it's fully servoless the the the the beauty of this combination is that you get to",
    "start": "956800",
    "end": "963440"
  },
  {
    "text": "play with spot instances and grabit on so when you are",
    "start": "963440",
    "end": "968759"
  },
  {
    "text": "considering using a compute with ECS fogget and Amazon ECS those are the",
    "start": "968759",
    "end": "974560"
  },
  {
    "text": "options that will help you a lot then as normal you would need an API",
    "start": "974560",
    "end": "980480"
  },
  {
    "text": "Gateway to have any communication with outside world we have Amazon API Gateway that interacts with various services",
    "start": "980480",
    "end": "987000"
  },
  {
    "text": "like Lambda functions Public public HTP endpoints and different other",
    "start": "987000",
    "end": "992440"
  },
  {
    "text": "services I think we heard about even Bridge a lot today but I'll just a recap on this one event Bridge provides you a",
    "start": "992440",
    "end": "999800"
  },
  {
    "text": "mechanism as an event router which decouples producers from consumers and",
    "start": "999800",
    "end": "1005360"
  },
  {
    "text": "basically with event Bridge you have event sources which can be AWS services or your custom events or it can come",
    "start": "1005360",
    "end": "1010519"
  },
  {
    "text": "from any partners and then you have bunch of bus that you can Define that can be a custom event bus or you can use",
    "start": "1010519",
    "end": "1017880"
  },
  {
    "text": "the default event bus or for partner you have partner event bus the the main power of event Bridge",
    "start": "1017880",
    "end": "1024558"
  },
  {
    "text": "comes when you define a rule where you have embedded business logic and that rule defines which Target to hit so that",
    "start": "1024559",
    "end": "1033160"
  },
  {
    "text": "that's there your even bridge sqs is also an important service when you think about running at scale",
    "start": "1033160",
    "end": "1039480"
  },
  {
    "text": "with serverless right when a traffic spikes up you don't want to overwhelm",
    "start": "1039480",
    "end": "1045520"
  },
  {
    "text": "Downstream systems like the Lambda function or the foundation n Point Foundation model and point what you need",
    "start": "1045520",
    "end": "1051440"
  },
  {
    "text": "is a buffering mechanism or even store that acts as a buffer so that you can",
    "start": "1051440",
    "end": "1057360"
  },
  {
    "text": "get all those traffic spikes converted to events and then your Downstream Lambda functions or your Downstream step",
    "start": "1057360",
    "end": "1063880"
  },
  {
    "text": "functions can pull messages at their own pace and start working on them without",
    "start": "1063880",
    "end": "1069520"
  },
  {
    "text": "affecting the foundation model so heavily heavily encouraged to use sqs as",
    "start": "1069520",
    "end": "1075720"
  },
  {
    "text": "a queue when you're are building applications and we you'll learn more from Uma going forward last but not the",
    "start": "1075720",
    "end": "1083559"
  },
  {
    "text": "least sorry this is uma's favorite service s State machines can be built",
    "start": "1083559",
    "end": "1089679"
  },
  {
    "text": "with AWS State step functions uh you can build we learned from different uh",
    "start": "1089679",
    "end": "1095679"
  },
  {
    "text": "sessions today like uh you can build resilient workflow Automation and if you have attended um's previous sessions he",
    "start": "1095679",
    "end": "1102360"
  },
  {
    "text": "talked about Adam and um talked about what how can you do error handling with",
    "start": "1102360",
    "end": "1107559"
  },
  {
    "text": "step functions how can you integrate with other services without writing Lambda functions that's called AWS STK",
    "start": "1107559",
    "end": "1114200"
  },
  {
    "text": "integration and the cool part is you get auditable history of all of your",
    "start": "1114200",
    "end": "1120240"
  },
  {
    "text": "executions the the best part on top of the cool part is that all of this is",
    "start": "1120240",
    "end": "1125559"
  },
  {
    "text": "written as a Json or yl file you don't have to learn a l language so with that I hand it over to",
    "start": "1125559",
    "end": "1133120"
  },
  {
    "start": "1132000",
    "end": "1811000"
  },
  {
    "text": "Uma to dive deeper on some of the patterns thank you d",
    "start": "1133120",
    "end": "1139840"
  },
  {
    "text": "I'm going to cover some of the serol list patterns that you can use in Genera viia Solutions and these patterns for",
    "start": "1139840",
    "end": "1146520"
  },
  {
    "text": "some of you who are familiar with serverless are not going to be new these are foundational components for any",
    "start": "1146520",
    "end": "1151799"
  },
  {
    "text": "serverless applications and so here the QR code",
    "start": "1151799",
    "end": "1157240"
  },
  {
    "text": "there if you scan it you will see some of the sil lless pattern uh for generated VA Solutions we're adding",
    "start": "1157240",
    "end": "1164000"
  },
  {
    "text": "pattern every day so you might want to check out often",
    "start": "1164000",
    "end": "1169840"
  },
  {
    "text": "majority of the use cases that we are seeing around generative a applications is consuming the foundation model so I",
    "start": "1169840",
    "end": "1177000"
  },
  {
    "text": "will first cover the patterns that related to consumption of the foundation",
    "start": "1177000",
    "end": "1182200"
  },
  {
    "text": "model I will use chatbot as an example to illustrate the patterns but the applicability of the patterns goes",
    "start": "1182200",
    "end": "1188919"
  },
  {
    "text": "beyond chat Parts they said anything that you ask of",
    "start": "1188919",
    "end": "1194559"
  },
  {
    "text": "a model is prompt so when you build a chatbot application you ask your user to",
    "start": "1194559",
    "end": "1201440"
  },
  {
    "text": "give an question but most of the time that same question doesn't go to the",
    "start": "1201440",
    "end": "1206880"
  },
  {
    "text": "model as such you add some enhancements few shot prompting so",
    "start": "1206880",
    "end": "1213480"
  },
  {
    "text": "something like that you would do so I asked this chatbot write about music in",
    "start": "1213480",
    "end": "1219400"
  },
  {
    "text": "Nashville and I had I had a simple no",
    "start": "1219400",
    "end": "1226880"
  },
  {
    "text": "back sorry yep",
    "start": "1226880",
    "end": "1230159"
  },
  {
    "text": "so I had a simple prom template I used it for anthropic model human in an input",
    "start": "1232600",
    "end": "1238400"
  },
  {
    "text": "and assistant it gave me a beautiful answer if as a as a backend developer if",
    "start": "1238400",
    "end": "1244520"
  },
  {
    "text": "you go about build an API for it you could use a synchronous pattern",
    "start": "1244520",
    "end": "1250240"
  },
  {
    "text": "very simple pattern we have already um we all used it have an API gave away expose an API and a Lambda function is",
    "start": "1250240",
    "end": "1257039"
  },
  {
    "text": "an intermediary and call a foundation model the foundation model it could be hosted in your you know and it could be",
    "start": "1257039",
    "end": "1263919"
  },
  {
    "text": "Amazon Bedrock or it could be in a in um Amazon Sage maker jump start or it could",
    "start": "1263919",
    "end": "1269080"
  },
  {
    "text": "be something that you have deployed in your own computer like eks most of the time you don't expose",
    "start": "1269080",
    "end": "1274600"
  },
  {
    "text": "your model publicly to everybody so you do need an intermediary like a Lambda function but Lambda is not just an",
    "start": "1274600",
    "end": "1280000"
  },
  {
    "text": "intermediary there are two other important functionalities here one is prompt enhancement that you saw earlier",
    "start": "1280000",
    "end": "1286520"
  },
  {
    "text": "you don't send this input right there right away to the foundation model you enhance that input sometimes you might",
    "start": "1286520",
    "end": "1293320"
  },
  {
    "text": "add instruction like do not send sensitive information in the answer then the next one is the model",
    "start": "1293320",
    "end": "1300880"
  },
  {
    "text": "abstraction you are abstracting the foundation model from your front end models comes and go every other day when",
    "start": "1300880",
    "end": "1308039"
  },
  {
    "text": "you find a more performant model you need a way to quickly swap it out with",
    "start": "1308039",
    "end": "1313360"
  },
  {
    "text": "so with Lambda function you can make little change code change and then swap that one",
    "start": "1313360",
    "end": "1318919"
  },
  {
    "text": "allowed any user interface requires a sophisticated authentication authorization that's why we chose API",
    "start": "1318919",
    "end": "1325720"
  },
  {
    "text": "Gateway and API gway also like offers several other capabilities um two of the",
    "start": "1325720",
    "end": "1331120"
  },
  {
    "text": "capabilities that I would highlight especially useful for um generative a Solutions is caching you don't want your",
    "start": "1331120",
    "end": "1338240"
  },
  {
    "text": "model to be inundated with repeated questions you can enable caching at API gway level and when a repeated question",
    "start": "1338240",
    "end": "1345080"
  },
  {
    "text": "comes up API gway answers with the um with answer from Catching and then AP",
    "start": "1345080",
    "end": "1351440"
  },
  {
    "text": "also offers fine grain rate limiting with um usage plans and API ways sorry",
    "start": "1351440",
    "end": "1358400"
  },
  {
    "text": "usage plans and API keys so let's say your chatbot has",
    "start": "1358400",
    "end": "1364320"
  },
  {
    "text": "increased in pop uh popularity and more users are using and as more users using there's",
    "start": "1364320",
    "end": "1371039"
  },
  {
    "text": "more volume of traffic comes in would you use the same synchronous",
    "start": "1371039",
    "end": "1376000"
  },
  {
    "text": "pattern you can but but it can result in poor performance or poor user",
    "start": "1376200",
    "end": "1383279"
  },
  {
    "text": "experience the main reason is we are right now talking",
    "start": "1383279",
    "end": "1388960"
  },
  {
    "text": "about a highly scalable serverless services",
    "start": "1388960",
    "end": "1394400"
  },
  {
    "text": "and low scaling a foundation endpoint why I'm saying low low low scaling",
    "start": "1394400",
    "end": "1400360"
  },
  {
    "text": "Foundation model sometimes can be hosted in in a in a computer environment where",
    "start": "1400360",
    "end": "1407320"
  },
  {
    "text": "you have lower rate limiting the reason is it could be cost of hosting it or it",
    "start": "1407320",
    "end": "1413480"
  },
  {
    "text": "could be like resource availability so you have like a asymmetric scaling",
    "start": "1413480",
    "end": "1418600"
  },
  {
    "text": "between the serous services and the foundation model you're talking about so how do we send a sustained the traffic",
    "start": "1418600",
    "end": "1425159"
  },
  {
    "text": "to the foundation model that's why we use Amazon sqs so API giveway a sendor",
    "start": "1425159",
    "end": "1430880"
  },
  {
    "text": "request to Amazon sqs Lambda function can directly consume messages from sqs",
    "start": "1430880",
    "end": "1436200"
  },
  {
    "text": "you can also configure how many any Lambda functions you can uh stand up to consume from sqs which can correspond to",
    "start": "1436200",
    "end": "1443880"
  },
  {
    "text": "the rate limiting on the foundation model end point so in that way you send sustained traffic to the foundation",
    "start": "1443880",
    "end": "1450000"
  },
  {
    "text": "model now your request became asynchronous this is an asynchronized pattern user sends a request user sends",
    "start": "1450000",
    "end": "1457200"
  },
  {
    "text": "a question they get an immediate response that the question is accepted but they don't get an answer so how do",
    "start": "1457200",
    "end": "1463440"
  },
  {
    "text": "we get a response asynchronously to the user",
    "start": "1463440",
    "end": "1468480"
  },
  {
    "text": "there are so many techniques available the easiest one is probably sending an email when the response is available but",
    "start": "1468480",
    "end": "1474480"
  },
  {
    "text": "that may not be suitable for many use cases Lambda one technique is polling",
    "start": "1474480",
    "end": "1480919"
  },
  {
    "text": "you can have Lambda function store the information in a database and then have an API available",
    "start": "1480919",
    "end": "1487760"
  },
  {
    "text": "in API Gateway to keep pulling that API until the answer is available it introduces some delays",
    "start": "1487760",
    "end": "1494200"
  },
  {
    "text": "depending on the polling frequency it is also resource was B page another um way",
    "start": "1494200",
    "end": "1500399"
  },
  {
    "text": "you could have like um the send the response uh back to the user is web sockets two-way interactive",
    "start": "1500399",
    "end": "1507320"
  },
  {
    "text": "communication between the client and the server API gway offers websocket AWS um",
    "start": "1507320",
    "end": "1513320"
  },
  {
    "text": "iot code offers websocket and there is also abing sub subscriptions so you can",
    "start": "1513320",
    "end": "1518399"
  },
  {
    "text": "use these mechanisms to send the asynchronous response back to the",
    "start": "1518399",
    "end": "1523520"
  },
  {
    "text": "user all right so we got a question we got an answer",
    "start": "1523520",
    "end": "1528600"
  },
  {
    "text": "I actually did not like the format of the response that my chatbot gave me earlier so I tried to give a another ask",
    "start": "1528600",
    "end": "1538600"
  },
  {
    "text": "it again to change the format into bullet point so I said write the same in bullet points it gave me a random",
    "start": "1538600",
    "end": "1545640"
  },
  {
    "text": "answer the mentioned earlier Foundation models are not inherently",
    "start": "1545640",
    "end": "1552039"
  },
  {
    "text": "stateful so what what can I do to make the foundation model be aware of my",
    "start": "1552039",
    "end": "1557320"
  },
  {
    "text": "convers ation the previous conversation so what I did is I asked that question but in the in",
    "start": "1557320",
    "end": "1564880"
  },
  {
    "text": "my prompt template and I enhanced that question I added my context from my",
    "start": "1564880",
    "end": "1570240"
  },
  {
    "text": "previous question and I asked the model and now it gave me the accurate answer",
    "start": "1570240",
    "end": "1576600"
  },
  {
    "text": "so now we're talking about storing that con conversation context somewhere the total conversation history everything so",
    "start": "1576600",
    "end": "1583279"
  },
  {
    "text": "there's another familiar pattern that we have all used using database API gave Lambda and the database so we use Dynamo",
    "start": "1583279",
    "end": "1590320"
  },
  {
    "text": "DB here you store the conversation history in Dynamo DB now it might be very simple but when",
    "start": "1590320",
    "end": "1597720"
  },
  {
    "text": "you think about it deeper this is not a simple thing it's not straightforward you you were we talking about",
    "start": "1597720",
    "end": "1604720"
  },
  {
    "text": "conversation history we're talking about users sessions tracking them and",
    "start": "1604720",
    "end": "1609760"
  },
  {
    "text": "sometimes conversation history can go really huge in like very short time you",
    "start": "1609760",
    "end": "1615159"
  },
  {
    "text": "our foundation models have request payload limits just like every other services and sometimes some even go can",
    "start": "1615159",
    "end": "1621520"
  },
  {
    "text": "go up to thousand tokens so there's a technical summarization of conversation",
    "start": "1621520",
    "end": "1628360"
  },
  {
    "text": "so instead of sending the whole conversation history I can just summarize that conversation and send a",
    "start": "1628360",
    "end": "1635240"
  },
  {
    "text": "shter information uh as a context and Foundation model still can send give me an accurate response but now I have to",
    "start": "1635240",
    "end": "1642320"
  },
  {
    "text": "summarize so it's not a s it's not a single thing that you know you would write in a Lambda function your Lambda",
    "start": "1642320",
    "end": "1648159"
  },
  {
    "text": "function now grows bigger it's not single responsibility Lambda function anymore so now I have since I have",
    "start": "1648159",
    "end": "1654200"
  },
  {
    "text": "multiple steps I choose to go with a workflow pattern So within workflow",
    "start": "1654200",
    "end": "1659640"
  },
  {
    "text": "pattern like with step functions workflow it's a low code visual service you can have all of those steps defined",
    "start": "1659640",
    "end": "1665519"
  },
  {
    "text": "for example the structure the sample architecture would look something like this the first I will check whether",
    "start": "1665519",
    "end": "1672039"
  },
  {
    "text": "there's a session and if there's a session I grab that conversation his conversation history or summary in this",
    "start": "1672039",
    "end": "1678840"
  },
  {
    "text": "case and then enrich that prompt I don't really need a Lambda function to enrich The Prompt I can use step functions en",
    "start": "1678840",
    "end": "1685559"
  },
  {
    "text": "intrinsic function to enrich that prompt add the conversation summary and ask the",
    "start": "1685559",
    "end": "1690960"
  },
  {
    "text": "llm for for the answer now llm responds with accurate information I will send",
    "start": "1690960",
    "end": "1696880"
  },
  {
    "text": "that response back to the user asynchronously but my workflow doesn't stop there the reason is I've got a new",
    "start": "1696880",
    "end": "1703919"
  },
  {
    "text": "information like the new question and answer I need to add it to the conversation summary so then I create a",
    "start": "1703919",
    "end": "1710000"
  },
  {
    "text": "conversation summary again then I stored it in the database there's multiple things that you need to do and step",
    "start": "1710000",
    "end": "1715600"
  },
  {
    "text": "functions is a great way to connect everything together as a single workflow and also with the less",
    "start": "1715600",
    "end": "1723320"
  },
  {
    "text": "code now so far we talked about invoking a single model how about use cases where",
    "start": "1723559",
    "end": "1730799"
  },
  {
    "text": "I need to invoke multiple models for example I'm generating a a",
    "start": "1730799",
    "end": "1736240"
  },
  {
    "text": "content for a marketing page and that requires a text information as well as",
    "start": "1736240",
    "end": "1741720"
  },
  {
    "text": "some images that corresponds to the text I need to invoke a text model and also uh image",
    "start": "1741720",
    "end": "1748799"
  },
  {
    "text": "model Amazon SNS and Amazon even bridge where the pattern that I have is a very",
    "start": "1748799",
    "end": "1753840"
  },
  {
    "text": "familiar pattern for most of you it's a fan out pattern fan out pattern distributes messages to multiple",
    "start": "1753840",
    "end": "1761080"
  },
  {
    "text": "destinations in parallel so you can use both Amazon SNS and even Rich to Fan out",
    "start": "1761080",
    "end": "1766480"
  },
  {
    "text": "this messages you can add rules and filters to filter um apply the filters",
    "start": "1766480",
    "end": "1772760"
  },
  {
    "text": "and choose which destination you want here right so you can have like one destination two destination or like all",
    "start": "1772760",
    "end": "1779640"
  },
  {
    "text": "the destinations fired up at the same time so with that our architecture now",
    "start": "1779640",
    "end": "1785120"
  },
  {
    "text": "looked like this when you are when you are calling to a text based model you call you can go with AWS Lambda if you",
    "start": "1785120",
    "end": "1791480"
  },
  {
    "text": "need to run a workflow for example use cases like prom chaining we'll talk about prom chaining later you can use",
    "start": "1791480",
    "end": "1798039"
  },
  {
    "text": "AWS step functions if it is an image uh task or you need a task that needs to",
    "start": "1798039",
    "end": "1803240"
  },
  {
    "text": "run for more than 15 minutes you can use AWS fargate connected to",
    "start": "1803240",
    "end": "1808960"
  },
  {
    "text": "it now so far we asked a generic question and the model gave us generic",
    "start": "1809720",
    "end": "1815000"
  },
  {
    "start": "1811000",
    "end": "2228000"
  },
  {
    "text": "answer how about you ask a question that is internal knowledge something domain",
    "start": "1815000",
    "end": "1820679"
  },
  {
    "text": "specific to the chatbot so what I did is I asked this uh this chatbot what is",
    "start": "1820679",
    "end": "1827320"
  },
  {
    "text": "distributed map in AWS step functions and I also gave instructions I",
    "start": "1827320",
    "end": "1832880"
  },
  {
    "text": "do not make up an answer if you don't know and M promptly responded that it doesn't know about",
    "start": "1832880",
    "end": "1840278"
  },
  {
    "text": "it the reason is it doesn't know if so if you ask a foundation model without",
    "start": "1840320",
    "end": "1846480"
  },
  {
    "text": "enabling it for domain specific information it is going to be either Limited in its answer or it's going to",
    "start": "1846480",
    "end": "1853760"
  },
  {
    "text": "give you erroneous answer there are multiple techniques to make the model context aware or the",
    "start": "1853760",
    "end": "1860159"
  },
  {
    "text": "domain aware and one of the popular technique is retrieval augmented generation or knowledge",
    "start": "1860159",
    "end": "1866480"
  },
  {
    "text": "retrieval as a name indicates you're retrieving the knowledge from a knowledge store augment The Prompt with",
    "start": "1866480",
    "end": "1874240"
  },
  {
    "text": "that knowledge so aument the question with that knowledge and then ask the",
    "start": "1874240",
    "end": "1879360"
  },
  {
    "text": "foundation model to generate the answer and so now the prompt will contain just like earlier in the",
    "start": "1879360",
    "end": "1886159"
  },
  {
    "text": "conversation um history The Prompt contains the question as well as the uh",
    "start": "1886159",
    "end": "1893559"
  },
  {
    "text": "knowledge information that knowledge can come from a knowledge store like Amazon Kendra or it can be from Vector database",
    "start": "1893559",
    "end": "1900000"
  },
  {
    "text": "some of the popular Vector database are open search Amazon open search service um chroma DB and pine con Etc Vector",
    "start": "1900000",
    "end": "1907799"
  },
  {
    "text": "databases are specialized databases they store numbers and they also organize this",
    "start": "1907799",
    "end": "1914720"
  },
  {
    "text": "information in a clever way so so similar informations are placed closer",
    "start": "1914720",
    "end": "1919799"
  },
  {
    "text": "to each other so if I ask a question that is domain specific this information in",
    "start": "1919799",
    "end": "1927320"
  },
  {
    "text": "number should exist ahead in time so somebody or somewhere this",
    "start": "1927320",
    "end": "1932760"
  },
  {
    "text": "process of changing this domain specific knowledge or document whatever it is to",
    "start": "1932760",
    "end": "1938480"
  },
  {
    "text": "be converted to a number should have happen and that con the conversion is",
    "start": "1938480",
    "end": "1944720"
  },
  {
    "text": "typically done by a embedding model it's a special kind of a model and so it will",
    "start": "1944720",
    "end": "1951200"
  },
  {
    "text": "go through a series of steps and uh and it will convert the domain specific",
    "start": "1951200",
    "end": "1956840"
  },
  {
    "text": "information to a number based information and store it in a vector",
    "start": "1956840",
    "end": "1962679"
  },
  {
    "text": "database and so here if you scan the QR code there is a GitHub sample um which",
    "start": "1962679",
    "end": "1970960"
  },
  {
    "text": "um is a great one uh to check out this is a llm chatbot with rag",
    "start": "1970960",
    "end": "1979720"
  },
  {
    "text": "capability so the step of converting a text information to a",
    "start": "1981000",
    "end": "1986840"
  },
  {
    "text": "vector embedding it involves multiple steps so I'm going to show another",
    "start": "1986840",
    "end": "1991960"
  },
  {
    "text": "workflow pattern so you've got like list of documents and they have to go through pre-processing chunking this is a very",
    "start": "1991960",
    "end": "1999080"
  },
  {
    "text": "important step because you might be you might be transforming uh a document",
    "start": "1999080",
    "end": "2005080"
  },
  {
    "text": "which is a 100 page document just like the foundation model that we saw earlier embedding models also has request",
    "start": "2005080",
    "end": "2011200"
  },
  {
    "text": "payload limits so you need to chunk them to match that payload limits you create the embeddings and then you store the",
    "start": "2011200",
    "end": "2017799"
  },
  {
    "text": "embeddings and so again as a step functions workflow you could put everything",
    "start": "2017799",
    "end": "2024000"
  },
  {
    "text": "together if you are using Amazon Bedrock this process is actually readily",
    "start": "2024000",
    "end": "2029120"
  },
  {
    "text": "available through um Bedrock agents you don't really have to go through this process now if you look at this whole",
    "start": "2029120",
    "end": "2036240"
  },
  {
    "text": "process of of how this context aware um",
    "start": "2036240",
    "end": "2041279"
  },
  {
    "text": "um invocation will occur it will start with a user uploading a domain specific",
    "start": "2041279",
    "end": "2048200"
  },
  {
    "text": "knowledge document into Amazon S3 you can have an S3 event uh notification to",
    "start": "2048200",
    "end": "2055118"
  },
  {
    "text": "trigger Amazon event bridge and then the event Bridge apply filter and then you",
    "start": "2055119",
    "end": "2060599"
  },
  {
    "text": "can call step functions workflow and then where that's where that previous um Slide the workflow will happen and will",
    "start": "2060599",
    "end": "2067638"
  },
  {
    "text": "store the data in Vector database and then the user can ask a question related to the document that they uploaded and",
    "start": "2067639",
    "end": "2074158"
  },
  {
    "text": "that goes through the familiar path of API gway sqs to Lambda function and this",
    "start": "2074159",
    "end": "2079800"
  },
  {
    "text": "time Lambda function is not going to call the model directly it is going to",
    "start": "2079800",
    "end": "2084878"
  },
  {
    "text": "first ask the vector database to get a similar information so it does a",
    "start": "2084879",
    "end": "2089919"
  },
  {
    "text": "similarity search on the information that is stored in the vector database to the question that is asked from the user",
    "start": "2089919",
    "end": "2097240"
  },
  {
    "text": "then it gets the context arguments The Prompt with that context and then ask",
    "start": "2097240",
    "end": "2103440"
  },
  {
    "text": "the foundation model for an answer and that answer can be sent back asynchronously through the asynchronous",
    "start": "2103440",
    "end": "2110040"
  },
  {
    "text": "mechanism that we talked about earlier this whole process is retrieval",
    "start": "2110040",
    "end": "2117480"
  },
  {
    "text": "augmented generation prom chaining is a way to is",
    "start": "2117480",
    "end": "2124359"
  },
  {
    "text": "a technique to wire multiple proms and responses together in a sequence of",
    "start": "2124359",
    "end": "2130160"
  },
  {
    "text": "workflow pattern to achieve a business process think about use cases like",
    "start": "2130160",
    "end": "2137599"
  },
  {
    "text": "prompt um chaining sorry use cases like trip planner a trip planner um if it's a",
    "start": "2137599",
    "end": "2146119"
  },
  {
    "text": "let's just say if it is a Genera VA enabled agent it can ask the traveler",
    "start": "2146119",
    "end": "2152680"
  },
  {
    "text": "where they want to travel like the location and budget and then it can offer information like where they can stay the",
    "start": "2152680",
    "end": "2159520"
  },
  {
    "text": "hotels they can eat and the activities they can do and this this is a series of",
    "start": "2159520",
    "end": "2164760"
  },
  {
    "text": "Step they need to do I have here I have given here um a an example of how you",
    "start": "2164760",
    "end": "2171280"
  },
  {
    "text": "can generate a story in order to generate a story The workflow first ask ask the LM to generate the",
    "start": "2171280",
    "end": "2179119"
  },
  {
    "text": "characters so every story has characters so it ask generate generate the characters and that response is fed into",
    "start": "2179119",
    "end": "2185319"
  },
  {
    "text": "the next step and in that step every single character is get has got an",
    "start": "2185319",
    "end": "2190839"
  },
  {
    "text": "unique story and everything comes from llm and you've got like characters and",
    "start": "2190839",
    "end": "2195920"
  },
  {
    "text": "the character stories and then you wire them together to create a new story and this whole process can be enhanced by",
    "start": "2195920",
    "end": "2203680"
  },
  {
    "text": "adding a human in the look for example think about an editor who is looking at the story reviewing the story and if he",
    "start": "2203680",
    "end": "2209240"
  },
  {
    "text": "doesn't like it he can just ask the workflow to kick it off and generate regenerate the story step function",
    "start": "2209240",
    "end": "2217040"
  },
  {
    "text": "integrates um really well with human approval workflow so human in the loop can be easily embedded into the prom",
    "start": "2217040",
    "end": "2224839"
  },
  {
    "text": "chaining now with that I'm going to step step aside and uh and the will cover a",
    "start": "2224839",
    "end": "2231000"
  },
  {
    "start": "2228000",
    "end": "2266000"
  },
  {
    "text": "pattern related to hosting a foundation model and also the Better Together story of how SS and Genera VA Solutions work",
    "start": "2231000",
    "end": "2240200"
  },
  {
    "text": "together thank you so as a whole we saw like how if you use Bedrock uh",
    "start": "2240200",
    "end": "2248400"
  },
  {
    "text": "serverless end points then you can focus mainly on writing business logic using",
    "start": "2248400",
    "end": "2253800"
  },
  {
    "text": "serverless now if you want to switch the attention to little bit like towards Sage maker jump start where you have to",
    "start": "2253800",
    "end": "2259560"
  },
  {
    "text": "host a model like if you have a requirement where you need to uh do some",
    "start": "2259560",
    "end": "2265520"
  },
  {
    "text": "documents processing or document summarization at scale on Sage maker right you can do that if you want to do",
    "start": "2265520",
    "end": "2273920"
  },
  {
    "start": "2266000",
    "end": "2592000"
  },
  {
    "text": "that as a real time as in when document comes to an S3 bucket you can hit your sagemaker endpoint and summarize the",
    "start": "2273920",
    "end": "2280280"
  },
  {
    "text": "document however at scale when you run that if you have multiple documents you have to run that stage maker R Point",
    "start": "2280280",
    "end": "2287640"
  },
  {
    "text": "throughout the day and that can incur a cost based on the instance that you have used",
    "start": "2287640",
    "end": "2293000"
  },
  {
    "text": "underneath here is a cost effective technique where you can summarize at scale and you can schedule document",
    "start": "2293000",
    "end": "2300800"
  },
  {
    "text": "summarization with Stage maker end point so think of it as if you have written some tests you can set up in the test",
    "start": "2300800",
    "end": "2307599"
  },
  {
    "text": "you can run your test and then you tear down so think apply the same principle here in this state machine I can",
    "start": "2307599",
    "end": "2315240"
  },
  {
    "text": "schedule the state machine to run nightly and I can gather 5 5,000 or",
    "start": "2315240",
    "end": "2320880"
  },
  {
    "text": "100,000 documents and On Demand I can create a sagemaker endpoint config I can",
    "start": "2320880",
    "end": "2327760"
  },
  {
    "text": "create the sagemaker on endpoint and then figure out if the endpoint is available or not and for 30 seconds or 1",
    "start": "2327760",
    "end": "2334839"
  },
  {
    "text": "minute and I can pull and figure out if if it is available then I can use the distributed map capability if youve",
    "start": "2334839",
    "end": "2341000"
  },
  {
    "text": "attended the previous session uh distributed map is a cool feature and step functions I would highly encourage",
    "start": "2341000",
    "end": "2346520"
  },
  {
    "text": "to check that out and you can call AWS SDK Integrations like calling text tracks directly calling uh stagemaker",
    "start": "2346520",
    "end": "2353920"
  },
  {
    "text": "invoke endpoint directly and other config endpoints uh directly and you can run document processing or document",
    "start": "2353920",
    "end": "2360720"
  },
  {
    "text": "summarization at scale once you're done with that last two steps that you see here is delete stagemaker endpoint and",
    "start": "2360720",
    "end": "2367440"
  },
  {
    "text": "delete sagemaker endpoint config so you tear down the whole setup which means",
    "start": "2367440",
    "end": "2372680"
  },
  {
    "text": "you only run the sagemaker endpoint when you need it in in the night so that will drastically reduce your cost so you can",
    "start": "2372680",
    "end": "2379359"
  },
  {
    "text": "think about those scenarios where if you have to host in sagemaker uh jump start",
    "start": "2379359",
    "end": "2384800"
  },
  {
    "text": "you can build workflow orchestrations like this where you can save on cost now let's step back and look at the",
    "start": "2384800",
    "end": "2391800"
  },
  {
    "text": "bigger picture we talked about apis where you have uploading documents question question and answer with chat",
    "start": "2391800",
    "end": "2397359"
  },
  {
    "text": "board text to Media with uh things like stable diffusion mid journey and then",
    "start": "2397359",
    "end": "2402800"
  },
  {
    "text": "model evaluation like if you have to run a query or if you ask multiple models",
    "start": "2402800",
    "end": "2408040"
  },
  {
    "text": "get back response and check the accuracy of each model all those things are available or you can do that on top of J",
    "start": "2408040",
    "end": "2415560"
  },
  {
    "text": "available in AWS you can do text summarization which we saw right now in the right hand side we have all the",
    "start": "2415560",
    "end": "2421960"
  },
  {
    "text": "models that you can use today on AWS on the top row are all AWS services for",
    "start": "2421960",
    "end": "2428200"
  },
  {
    "text": "AIML where you can use Bedrock uh jump start uh comprehend text track and all",
    "start": "2428200",
    "end": "2434079"
  },
  {
    "text": "those things that will help you enable you to run generative AI applications and then there are tools like Lan chain",
    "start": "2434079",
    "end": "2439800"
  },
  {
    "text": "that you can incorporate in Lambda functions or ACS fargate and then you can work on it what we saw is actually a",
    "start": "2439800",
    "end": "2447040"
  },
  {
    "text": "good story of putting everything together as an event driven architecture right and how is that possible we talked",
    "start": "2447040",
    "end": "2453560"
  },
  {
    "text": "about even Brokers and even Brokers will facilitate at highly extensible architecture with the fan out scenario",
    "start": "2453560",
    "end": "2459800"
  },
  {
    "text": "that umaar talked about is not just three rules you can have five different rules to figure out if you have to call",
    "start": "2459800",
    "end": "2465920"
  },
  {
    "text": "a new uh model as part of the F out process so it is highly extensible you have cues that can handle",
    "start": "2465920",
    "end": "2472880"
  },
  {
    "text": "scale without overwhelming the foundation models or the underlying uh compute and then you have orchestration",
    "start": "2472880",
    "end": "2480400"
  },
  {
    "text": "soic is like step functions where you can run rag or run document at scale then you have those Ever Changing",
    "start": "2480400",
    "end": "2487040"
  },
  {
    "text": "Foundation models that will keep on evolving you have to keep on changing the endpoint you have to make them available to your business logic then we",
    "start": "2487040",
    "end": "2494480"
  },
  {
    "text": "talked about notification systems like how you can send responses back by polling or iot core the most important",
    "start": "2494480",
    "end": "2501520"
  },
  {
    "text": "part that we did not talk about yet is what happens in the future generative AI",
    "start": "2501520",
    "end": "2507119"
  },
  {
    "text": "is new we have not thought about governance auditability we have not thought about",
    "start": "2507119",
    "end": "2513359"
  },
  {
    "text": "analytics Eda even D an architecture will will facilitate to build those system as in when you progress with your",
    "start": "2513359",
    "end": "2519800"
  },
  {
    "text": "evolving your architecture so keep that in mind if you start with even driven architectures you can bring in those",
    "start": "2519800",
    "end": "2525960"
  },
  {
    "text": "capabilities as and when they are asked for or as and when they are required and finally we saw a scheduling mechanism",
    "start": "2525960",
    "end": "2532119"
  },
  {
    "text": "where you can use even bridge schedulers to schedule a lot of documents summarize a lot of documents in in it scale so",
    "start": "2532119",
    "end": "2539480"
  },
  {
    "text": "this is the entire story of how you can think about even driven architecture using serverless services and around",
    "start": "2539480",
    "end": "2548040"
  },
  {
    "text": "AI we talked about couple of services but they are not limited to those Services you can when it comes to API",
    "start": "2548040",
    "end": "2554559"
  },
  {
    "text": "appsync uh web sockets in API Gateway iot core when it comes to compute we",
    "start": "2554559",
    "end": "2559920"
  },
  {
    "text": "have ECS and AWS fate when it comes to router we have Kinesis data streams",
    "start": "2559920",
    "end": "2565280"
  },
  {
    "text": "Amazon msk and Amazon mq and same with event store not just sqs but we have",
    "start": "2565280",
    "end": "2570599"
  },
  {
    "text": "this plora of services with that here is an example",
    "start": "2570599",
    "end": "2575839"
  },
  {
    "text": "which you can scan this QR code this is a Blog that is written by David our most beloved seress da and you can scan this",
    "start": "2575839",
    "end": "2583359"
  },
  {
    "text": "and you can read the blog and see how he has implemented a story generation app using chat GPT and",
    "start": "2583359",
    "end": "2591400"
  },
  {
    "text": "Dolly to summarize in quick few minutes we you are you're enable to uh eliminate",
    "start": "2591400",
    "end": "2598880"
  },
  {
    "start": "2592000",
    "end": "2649000"
  },
  {
    "text": "bottlenecks if you start using Eda we talked about the governance part that is the part of evolutionary",
    "start": "2598880",
    "end": "2605599"
  },
  {
    "text": "architecture so you evolve with Eda and then you get fine grein scaling of",
    "start": "2605599",
    "end": "2610839"
  },
  {
    "text": "components and you can extend all those features to different parts of your businesses most importantly you have",
    "start": "2610839",
    "end": "2617440"
  },
  {
    "text": "reduced the fault impact radius because if you fail on a small component only",
    "start": "2617440",
    "end": "2623200"
  },
  {
    "text": "you fail at that component you are not affecting other areas of your even driven architecture so you fail fast you",
    "start": "2623200",
    "end": "2629720"
  },
  {
    "text": "recover and you go to market faster there are a couple of resources that you can scan and will we'll provide",
    "start": "2629720",
    "end": "2636559"
  },
  {
    "text": "you this resource or reach out to us we can provide you this resources as well blogs and a workshop and the llm chat",
    "start": "2636559",
    "end": "2643119"
  },
  {
    "text": "application that we showed as a QR code that will help you keep on moving and get",
    "start": "2643119",
    "end": "2648800"
  },
  {
    "text": "started with that thank you everyone U happy that everybody is here happy to be",
    "start": "2648800",
    "end": "2655559"
  },
  {
    "start": "2649000",
    "end": "2681000"
  },
  {
    "text": "here and learn more from everybody else in the in this uh go to Ed day and please give your vote for the session",
    "start": "2655559",
    "end": "2662920"
  },
  {
    "text": "using the go to guide app thanks a lot thank you all right [Applause]",
    "start": "2662920",
    "end": "2671869"
  }
]
[
  {
    "start": "0",
    "end": "147000"
  },
  {
    "text": "Hello. Welcome to another episode of \nGOTO Book Club. My name's Phil Winder,   and I'm the CEO of Winder AI. Since 2013, Winder \nAI has been developing AI applications. And if you  ",
    "start": "4080",
    "end": "13120"
  },
  {
    "text": "need AI engineers for your next project, \nthen give me a call. I'm here today with   James Phoenix and Mike Taylor. They are the \nauthors of a brand new-ish book, end of 2024,  ",
    "start": "13120",
    "end": "24680"
  },
  {
    "text": "\"Prompt Engineering for Generative AI.\" \nI'm just laying there, proof. Today,  ",
    "start": "24680",
    "end": "30840"
  },
  {
    "text": "I'm hoping to basically delve through the book and \nask lots of questions, follow-up questions that I   had based upon all of the interesting insight \nthat was provided in the book. Mike, would you  ",
    "start": "30840",
    "end": "41320"
  },
  {
    "text": "like to go first just to introduce yourself, \ntell us about what you do, and what made you  ",
    "start": "41320",
    "end": "46960"
  },
  {
    "text": "interested in prompt engineering, to begin with.\nSure, Phil. Thanks for having us here. I also love  ",
    "start": "46960",
    "end": "54079"
  },
  {
    "text": "that you use the word delve, by the way, because \nthat's one of the words that we had to search for  ",
    "start": "54080",
    "end": "60600"
  },
  {
    "text": "the book and make sure that it wasn't in too often \nbecause it's what ChatGPT uses quite a lot.  I  ",
    "start": "60600",
    "end": "68080"
  },
  {
    "text": "got into prompt engineering in 2020 because I was \nactually just leaving my first company. I founded  ",
    "start": "68080",
    "end": "76680"
  },
  {
    "text": "a marketing agency, grew it to 50 people, and then \nI was looking for something to do during the COVID  ",
    "start": "76680",
    "end": "82520"
  },
  {
    "text": "lockdowns, and got access to GT3. So, the rest is \nhistory. I managed to start replacing all my work  ",
    "start": "82520",
    "end": "90399"
  },
  {
    "text": "with AI and then eventually started to work in AI \nfull-time. We could talk a bit more about that,  ",
    "start": "90400",
    "end": "97640"
  },
  {
    "text": "but that was my journey.\nPerfect. James, over to you. ",
    "start": "97640",
    "end": "101560"
  },
  {
    "text": "Nice to meet everyone. I'm James Phoenix. \nI'm a software engineer, indie hacker,   and predominantly been using GPT and \nOpenAI for a good couple of years now.  ",
    "start": "102800",
    "end": "112920"
  },
  {
    "text": "I really enjoy using it for coding. So, I'm \nreally, really into the whole Cursor stuff  ",
    "start": "112920",
    "end": "119680"
  },
  {
    "text": "and sort of, you know, replacing any part \nof my workflow. I do a range of different  ",
    "start": "120800",
    "end": "126320"
  },
  {
    "text": "projects for clients. I've got one client at the \nmoment who I'm helping build some sort of rank   tracker for LLMs and, yeah, classification \npipelines and that kind of stuff. So, yeah. ",
    "start": "127400",
    "end": "139360"
  },
  {
    "text": "Interesting. Well, thank you again for the book. \nI found it really, really interesting. I think  ",
    "start": "139360",
    "end": "147560"
  },
  {
    "start": "147000",
    "end": "502000"
  },
  {
    "text": "I'd like to start off by asking a few general \nquestions about the use of LLMs and generative AI,  ",
    "start": "147560",
    "end": "154080"
  },
  {
    "text": "in general, just to bring everybody up to \nspeed if they're not fully aware of what it is.",
    "start": "154080",
    "end": "160480"
  },
  {
    "text": "I guess let's get the big one over \nand done with. How would you define   prompt engineering? What is prompt engineering?\nObviously, everyone thinks about it differently.  ",
    "start": "162240",
    "end": "174000"
  },
  {
    "text": "Some people think of it as just kind of adding \nsome magic word on the end of the prompt that  ",
    "start": "174000",
    "end": "180040"
  },
  {
    "text": "tricks the AI into doing a good job, and that's \nwhat it started as, I think, in a lot of cases.  ",
    "start": "180040",
    "end": "185920"
  },
  {
    "text": "But we take a broader view of prompt engineering \nbeing this rigorous process of figuring out, you  ",
    "start": "185920",
    "end": "193080"
  },
  {
    "text": "know, through testing, through evaluation, what \ncombination of inputs lead to the best outputs  ",
    "start": "193080",
    "end": "201880"
  },
  {
    "text": "and the most reliable outputs as well because \nI would say, you know, you don't need prompt  ",
    "start": "201880",
    "end": "208160"
  },
  {
    "text": "engineering that much when you're just using \nChatGPT as a consumer. But if you're building an  ",
    "start": "208160",
    "end": "213360"
  },
  {
    "text": "AI application, it's going to be very important. \nThere's a great source of improvement in accuracy  ",
    "start": "213360",
    "end": "219720"
  },
  {
    "text": "just by getting the context right, by rewriting \nthe prompt in a certain way, it will give you much  ",
    "start": "219720",
    "end": "226560"
  },
  {
    "text": "better results. So, it's that kind of process for \nreally applying the scientific method as much as  ",
    "start": "226560",
    "end": "232400"
  },
  {
    "text": "possible with these LLMs to test and learn, \n\"Okay, when I write it this way with this  ",
    "start": "232400",
    "end": "240000"
  },
  {
    "text": "context, I get this type of response.\"\nSo, it's a lot about rigor there. It's  ",
    "start": "240000",
    "end": "246960"
  },
  {
    "text": "engineering rigor that you're trying to \napply to a slightly non-deterministic  ",
    "start": "246960",
    "end": "252280"
  },
  {
    "text": "system, depending on how you configure it.\nExactly. Yeah. And I come from a marketing  ",
    "start": "252280",
    "end": "257720"
  },
  {
    "text": "background. You know, growth marketing has a \ngreat culture of A-B testing and that kind of  ",
    "start": "257720",
    "end": "263160"
  },
  {
    "text": "came naturally to me. And then, James Phoenix, \nI think you could talk a bit more about this,   but coming from a data science background as well, \nI think that's another rich profile for people  ",
    "start": "263160",
    "end": "272360"
  },
  {
    "text": "getting into AI because it comes natural that you \nstart to really think about what are the inputs,  ",
    "start": "272360",
    "end": "279680"
  },
  {
    "text": "let's look at the raw data, let's look \nat patterns, let's see what opportunities   there are to improve performance.\nAbsolutely. James, what do you think? ",
    "start": "279680",
    "end": "289160"
  },
  {
    "text": "I think definitely, and then there's also some \nother dimensions that you'll often do whilst   you're working in this kind of environment. \nThings like using more powerful models,  ",
    "start": "289720",
    "end": "300120"
  },
  {
    "text": "switching the models quite a lot, and as well \nas that playing around with the parameters like  ",
    "start": "300120",
    "end": "305280"
  },
  {
    "text": "temperature and log probabilities. It's one \nof these things where prompt engineering is  ",
    "start": "305280",
    "end": "310440"
  },
  {
    "text": "definitely part of the stack. But as you know, \nan AI engineer or someone working in that space,  ",
    "start": "310440",
    "end": "316680"
  },
  {
    "text": "you'll often use a mixture of techniques \nalongside prompt engineering. So, you know,  ",
    "start": "316680",
    "end": "322160"
  },
  {
    "text": "changing the models, you might do fine-tuning. \nLike, there's a variety of different techniques  ",
    "start": "322160",
    "end": "327560"
  },
  {
    "text": "that you're kind of trying to apply to maximize \nthat output from a non-deterministic model. ",
    "start": "327560",
    "end": "335080"
  },
  {
    "text": "I guess one of the challenges I always have with \nmy AI projects, data science projects, in general,  ",
    "start": "335600",
    "end": "343800"
  },
  {
    "text": "is the problem definition, is defining the \nthing that you're trying to solve. And so,  ",
    "start": "343800",
    "end": "348879"
  },
  {
    "text": "does that still apply in prompt \nengineering? How important is the goal?  ",
    "start": "348880",
    "end": "354160"
  },
  {
    "text": "I think you mentioned the word goal there, Mike.\nIt's like 80% of the work. I find quite often when  ",
    "start": "354160",
    "end": "360720"
  },
  {
    "text": "I work with clients, they don't have any formal \nprocess for evaluation, and that becomes most of  ",
    "start": "360720",
    "end": "368720"
  },
  {
    "text": "the hard work. But because once you have a way \nto measure whether this is a good response or a  ",
    "start": "368720",
    "end": "376160"
  },
  {
    "text": "bad response that doesn't require the CEO of the \ncompany to come and check each response manually,  ",
    "start": "376160",
    "end": "383640"
  },
  {
    "text": "once you have a programmatic evaluation \nmethod that you can run after every response,  ",
    "start": "383640",
    "end": "389560"
  },
  {
    "text": "that's when it really blooms. You know, it really \nopens up the amount of things you can do in prompt   engineering. You can A-B test, especially if \nyou're not a domain expert in this area. So,  ",
    "start": "390120",
    "end": "400760"
  },
  {
    "text": "say you're working with a team of lawyers, \nlike, James, one of your projects, it's a real  ",
    "start": "400760",
    "end": "407680"
  },
  {
    "text": "bottleneck if you have to go back to the lawyers \nevery time to check whether the response is good   or not. You need to build up a test set, different \ntest cases, you need to know the right answer in  ",
    "start": "407680",
    "end": "417800"
  },
  {
    "text": "those cases, and then you need to set up some \nevaluation metric that you can use to optimize.  ",
    "start": "417800",
    "end": "423759"
  },
  {
    "text": "Once you have that, you can do A-B testing. \nYou can build more interesting architectures   with retries and things like that. So, that tends \nto be the main key. And if you don't have that,  ",
    "start": "423760",
    "end": "434440"
  },
  {
    "text": "you can't really do prompt engineering.\nJust to add onto this, I think the other thing  ",
    "start": "434440",
    "end": "439560"
  },
  {
    "text": "that's really interesting is, for example, it's \nmuch harder to evaluate content generation versus  ",
    "start": "439560",
    "end": "446919"
  },
  {
    "text": "a classification pipeline because you can easily \nsee when a classification has gone wrong. So,  ",
    "start": "446920",
    "end": "454400"
  },
  {
    "text": "depending upon what you're trying to do \nas the goal, if your goal is to produce,   you know, social media posts, the evaluation \nisn't necessarily as important there. I mean,  ",
    "start": "454400",
    "end": "464280"
  },
  {
    "text": "you could make the argument that brand \ntext and guidelines are quite important,   but there's less of an effort on that side. \nWhilst if you've got very wrong classifications,  ",
    "start": "464280",
    "end": "475240"
  },
  {
    "text": "that's going to have a lot more of an impact on \ndownstream data and, you know, the applications   that are consuming that data.There's a risk of \nhow well the evaluations have to work and also  ",
    "start": "475240",
    "end": "487000"
  },
  {
    "text": "how easy it is to tell whether it's good or bad. \nIf it's classification, a binary classification,  ",
    "start": "487000",
    "end": "492200"
  },
  {
    "text": "it's very easy to see if it's wrong. It's a lot \nless easy to see whether it's wrong when you  ",
    "start": "492200",
    "end": "499000"
  },
  {
    "text": "have a human evaluating this piece of marketing \nmaterial versus that part of marketing material  ",
    "start": "499000",
    "end": "504240"
  },
  {
    "start": "502000",
    "end": "621000"
  },
  {
    "text": "because it is a lot more vague. There's a \nlot more nuance to language than, you know,   binary classification as well. Those are all \nthe types of things you also run into as well.",
    "start": "504240",
    "end": "513640"
  },
  {
    "text": "Cracking. I guess before we dive any deeper, \nare there any misconceptions or anything that  ",
    "start": "514800",
    "end": "521440"
  },
  {
    "text": "we'd need to sort of clear up before we dig in?\nOne of them is just that prompt engineering isn't  ",
    "start": "521440",
    "end": "529680"
  },
  {
    "text": "an art as much as it is a science. I would \nsay that prompting is an art and, you know,  ",
    "start": "529680",
    "end": "536360"
  },
  {
    "text": "there's a creative element to coming up with new \nideas for prompts. But I wouldn't call it prompt  ",
    "start": "536360",
    "end": "543480"
  },
  {
    "text": "engineering unless you're doing testing and, \nyou know, trying to work at scale. And that's  ",
    "start": "543480",
    "end": "551040"
  },
  {
    "text": "something I struggle with as well as someone who \nhas a Udemy course with James, and we wrote the  ",
    "start": "551040",
    "end": "557040"
  },
  {
    "text": "book as well. Those are targeted more towards a \ntechnical audience, but initially, a lot of the  ",
    "start": "557040",
    "end": "562399"
  },
  {
    "text": "audience was non-technical. We get a huge demand \nfrom people who don't know how to code, who want   to read the book or, you know, want to get better \nat prompting. And it's just kind of two different  ",
    "start": "562400",
    "end": "572160"
  },
  {
    "text": "things, right? Like, there's only so much testing \nyou can do manually without, like, you know, being  ",
    "start": "572160",
    "end": "577879"
  },
  {
    "text": "able to code and being able to run it 1,000 times \nor 10,000 times and see how often it breaks. So,  ",
    "start": "577880",
    "end": "584360"
  },
  {
    "text": "that's something that we still don't have, \nI think, a good handle on in the industry,  ",
    "start": "584360",
    "end": "590320"
  },
  {
    "text": "whether...you need to know how to code to be a \nprompt engineer because when I deliver training,  ",
    "start": "591040",
    "end": "598399"
  },
  {
    "text": "quite often the non-technical people say, \"This is \ntoo technical.\" And then the technical people say,  ",
    "start": "598400",
    "end": "604200"
  },
  {
    "text": "\"This is too simplistic.\" And so, what I try \nto do is I call it prompt engineering if it's  ",
    "start": "604200",
    "end": "610480"
  },
  {
    "text": "for a technical audience, and then I just call it \nprompting if it's not. But not everyone has that  ",
    "start": "610480",
    "end": "615839"
  },
  {
    "text": "same definition in their head. So, that's the \nthing I would love for more people to clear up.",
    "start": "615840",
    "end": "621000"
  },
  {
    "start": "621000",
    "end": "823000"
  },
  {
    "text": "You're almost saying that it's actually more \nlike programming than it is writing. So,  ",
    "start": "622560",
    "end": "627960"
  },
  {
    "text": "do you consider prompt engineering \nto be a new style of programming? ",
    "start": "627960",
    "end": "633360"
  },
  {
    "text": "It feels that way. I really like Andrej Karpathy, \nhis take on it, that it's basically a new kind of  ",
    "start": "633360",
    "end": "643560"
  },
  {
    "text": "abstraction on top of machine learning, which was \nan abstraction on top of programming initially,  ",
    "start": "643560",
    "end": "650240"
  },
  {
    "text": "right? Rather than building a special-purpose \ncomputer that's the size of a room to do a  ",
    "start": "650240",
    "end": "657480"
  },
  {
    "text": "specific counting task. That was the first \nprogramming, right? It was actually literally  ",
    "start": "657480",
    "end": "663639"
  },
  {
    "text": "building the computer. Then we had general-purpose \ncomputers where you just have to write the program   and run it. Then you have machine learning where \nyou just need to give it the data and it will  ",
    "start": "663640",
    "end": "673520"
  },
  {
    "text": "write the program. We have these pre-trained \nmodels. Now, we just need to kind of write in  ",
    "start": "673520",
    "end": "679120"
  },
  {
    "text": "plain English what you want and then find some \nway of evaluating it. It does feel like a new  ",
    "start": "679120",
    "end": "686320"
  },
  {
    "text": "way of programming. James, I mean, I don't know if \nyou want to talk a bit more about your work with   Cursor. You're very deep into using...\nI think the one thing... ",
    "start": "686320",
    "end": "695198"
  },
  {
    "text": "I don't know how much code you're actually writing \nanymore or if you're going to see yourself more   as an engineering manager of AI agents.\nFor sure. Cursor is definitely like writing  ",
    "start": "695198",
    "end": "706200"
  },
  {
    "text": "probably 60% to 70% of my code. I will say that \nwhen I'm learning something new, I actually   manually type it out by hand. I think that's \na really good way to still learn. Otherwise,  ",
    "start": "706200",
    "end": "715600"
  },
  {
    "text": "you're sort of blindly copying and pasting. But, \nyeah, definitely what I'm starting to find is even  ",
    "start": "715600",
    "end": "722120"
  },
  {
    "text": "in engineering workflows, you can specifically \nhave prompts to just take that piece of work. So,  ",
    "start": "722120",
    "end": "728160"
  },
  {
    "text": "the good one is if you're in composer for the \nwhole day in Cursor, you can have a separate  ",
    "start": "728160",
    "end": "733879"
  },
  {
    "text": "prompt or a separate notepad that will generate \na progress report in a specifically standardized  ",
    "start": "733880",
    "end": "739680"
  },
  {
    "text": "way. Like, what were the key learnings today, \nthe key blockers, the next steps? You just say,   \"Generate a progress report.\" And because Cursor \nhas now got an agent mode, it can also run Linux  ",
    "start": "739680",
    "end": "748800"
  },
  {
    "text": "commands to get the right date and time and \nformat and that kind of stuff. Or you can do   things like have a prompt to generate a git commit \nmessage based on git conventional commits, such as  ",
    "start": "748800",
    "end": "759160"
  },
  {
    "text": "a prefixing with fix or feed or chore.\nYou can kind of automate these smaller routines  ",
    "start": "759160",
    "end": "766079"
  },
  {
    "text": "or subroutines that you're doing as a programmer, \nas well as the code that you're also generating.  ",
    "start": "766080",
    "end": "771760"
  },
  {
    "text": "I definitely find that, yeah, LLMs are speeding us \nall up. I think going back to what Mike was saying  ",
    "start": "772920",
    "end": "779920"
  },
  {
    "text": "about, you know, you've got this non-technical \nversus technical audience, I think with the   technical audience, it's very much more focused \naround scientific rigor and experimentation when  ",
    "start": "779920",
    "end": "788880"
  },
  {
    "text": "it comes to AI engineering and prompt engineering. \nThen I think for the non-technical audience,   what I always recommend is just enriching the \ncontext as much as possible because they're  ",
    "start": "788880",
    "end": "798760"
  },
  {
    "text": "not going to sit down and run O1 Pro 100 times or \nO1 100 times because it's just the latency is too  ",
    "start": "798760",
    "end": "804200"
  },
  {
    "text": "large. But if they get the right context \nin there, then it's probably going to be  ",
    "start": "804200",
    "end": "809240"
  },
  {
    "text": "good enough if they're just using one response \nor two responses. So, I think, yeah, putting an   emphasis on the richness of context is really \ngreat for a non-technical audience, for sure.",
    "start": "809240",
    "end": "821160"
  },
  {
    "text": "Interesting. Let's move on to the book. One \nof the big headline topics that you kind of  ",
    "start": "821160",
    "end": "830920"
  },
  {
    "start": "823000",
    "end": "1587000"
  },
  {
    "text": "go back to throughout the book is these five \nprinciples of prompting. I guess let's have  ",
    "start": "830920",
    "end": "836680"
  },
  {
    "text": "a little bit of a background. So it's a nice \ncatchy title. I can see why you've done it.   But I guess why did you come up with them in \nthe first place? Like, why not six or four? ",
    "start": "837200",
    "end": "846240"
  },
  {
    "text": "Good question. It came from self-preservation \nessentially. When GPT-4 came out, we had a bit  ",
    "start": "847640",
    "end": "856480"
  },
  {
    "text": "of a panic, I think, because a lot of the prompt \nengineering techniques that we used to use GPT-3  ",
    "start": "856480",
    "end": "862639"
  },
  {
    "text": "just weren't really necessary anymore. You \ndidn't have to threaten it to return JSON. They  ",
    "start": "862640",
    "end": "869840"
  },
  {
    "text": "started to follow instructions much better. All \nfrontier models are pretty good at following  ",
    "start": "869840",
    "end": "877640"
  },
  {
    "text": "instructions. You don't need to kind of \nhack the prompt as much as you used to. But,  ",
    "start": "877640",
    "end": "883880"
  },
  {
    "text": "you know, looking ahead, I thought, \"Okay, \nwe're just about to write a book. You know,  ",
    "start": "883880",
    "end": "889200"
  },
  {
    "text": "we're creating a course as well. We don't want to \nhave to update those two assets too often. And so,  ",
    "start": "889200",
    "end": "896200"
  },
  {
    "text": "let's think really deeply about what would \nform the core of these principles. What things,  ",
    "start": "896200",
    "end": "902960"
  },
  {
    "text": "you know, were we doing with GPT-3 that we're \nstill doing today with GPT-4? And looking ahead,   like, what do we think will still \nbe useful with GPT-5 and so on?\" ",
    "start": "902960",
    "end": "911800"
  },
  {
    "text": "That was really just an attempt to make sure we \ndidn't have to do version 2 of the book three  ",
    "start": "913000",
    "end": "921040"
  },
  {
    "text": "weeks after it was released in Britain. We brought \nit down, and we tried to condense the principles  ",
    "start": "921040",
    "end": "929120"
  },
  {
    "text": "as much as possible. Then actually, we were \npretty happy when OpenAI came out with their  ",
    "start": "929120",
    "end": "934400"
  },
  {
    "text": "principles. They have a prompt engineering guide \nnow. It came out after we'd already written most  ",
    "start": "934400",
    "end": "939640"
  },
  {
    "text": "of the book. I quickly checked it, and I was like, \n\"That principle maps to this principle.\" It felt  ",
    "start": "939640",
    "end": "945960"
  },
  {
    "text": "good. But I feel like pretty much anyone who works \nwith these tools will arrive at a similar set of  ",
    "start": "945960",
    "end": "953120"
  },
  {
    "text": "principles. And there's nothing magic to it. \nAnyone who's very experienced will get these  ",
    "start": "953120",
    "end": "959080"
  },
  {
    "text": "straight away and will recognize them. But  \nstarting with those five principles in the  ",
    "start": "959080",
    "end": "964800"
  },
  {
    "text": "first chapter just really helps people ramp up \nif they're not as familiar, if they don't have   as much experience in prompt engineering yet.\nYes. James, what do you think about the five?  ",
    "start": "964800",
    "end": "974080"
  },
  {
    "text": "Like, have you got any ones \nthat you particularly like?  I think division of labor is something that I \nuse quite a lot because when you're combining  ",
    "start": "974080",
    "end": "983360"
  },
  {
    "text": "and composing multiple prompt chains, you are \nessentially breaking down a larger problem into a  ",
    "start": "983360",
    "end": "991720"
  },
  {
    "text": "series of sub-problems that basically once solved \nwill solve the larger problem. And I find that  ",
    "start": "991720",
    "end": "997680"
  },
  {
    "text": "works incredibly well. I think, you know, that it \nalso works quite well with imperative programming  ",
    "start": "997680",
    "end": "1004720"
  },
  {
    "text": "languages. You don't really want to do everything \nup until this point because you don't have certain   data. Maybe you have to go to the database at \nthat point. And just from the nature of things,  ",
    "start": "1004720",
    "end": "1014399"
  },
  {
    "text": "you'll find that when you're doing prompt \nchaining and creating these chains, they   naturally don't all sit together anyway within \nthe code and within the data pipeline flow for  ",
    "start": "1014400",
    "end": "1024880"
  },
  {
    "text": "backend applications. So, yeah, definitely \ndivision of labor, I think that's a really   good one. It's probably my favorite, for sure.\nI think it might help actually if we just give  ",
    "start": "1024880",
    "end": "1036439"
  },
  {
    "text": "a little example there, James. So, if division \nof labor is your favorite, could you just walk  ",
    "start": "1036440",
    "end": "1043199"
  },
  {
    "text": "through how the average person might do that for \na simple task like writing an email or something?  ",
    "start": "1043200",
    "end": "1049159"
  },
  {
    "text": "How would you approach that in terms of dividing?\nSo, if we're thinking about writing an email,   the first thing you might want to do is gather \nsome relevant context about that person or that  ",
    "start": "1049160",
    "end": "1060640"
  },
  {
    "text": "company. The other thing you might want to do is \ngather context about previous emails that have  ",
    "start": "1060640",
    "end": "1066000"
  },
  {
    "text": "been sent because there might be several email \nthreads that are happening, which actually would   be really beneficial to know about. So, those \nare the kinds of things you would do as upstream  ",
    "start": "1066000",
    "end": "1076000"
  },
  {
    "text": "chains. Then the second thing you might do is \nthen generate the email. Then the third thing  ",
    "start": "1076000",
    "end": "1082520"
  },
  {
    "text": "is you might have a human approval loop or a human \napproval stage. And then the fourth thing is you  ",
    "start": "1082520",
    "end": "1088880"
  },
  {
    "text": "might get another LLM to critique the email and \nlook for any spelling mistakes or discrepancies  ",
    "start": "1088880",
    "end": "1094560"
  },
  {
    "text": "or things that are missing. And then you would \nthen have a final step to say, \"Send the email.\" ",
    "start": "1094560",
    "end": "1100240"
  },
  {
    "text": "So, rather than just say, \"Let's create an \nemail from this email,\" there's a step one,   which is gathering the right relevant context. So, \nthat might be doing some additional information,  ",
    "start": "1100240",
    "end": "1110440"
  },
  {
    "text": "or maybe you've got a database full of \nthe people that you're talking with,   or it could just be also gathering relevant emails \nfrom your Gmail or the API. The second stage is  ",
    "start": "1110440",
    "end": "1119520"
  },
  {
    "text": "generate the email, and then you've got maybe some \nhuman approval step or a human in the loop step,   and then you've got a critique step, and then send \nthe email. So, rather than trying to do everything  ",
    "start": "1119520",
    "end": "1128200"
  },
  {
    "text": "in one step, you're kind of breaking that down \ninto about four steps. And the reason why is that   then you can have a deterministic way of doing \nthat while still using LLMs within that workflow. ",
    "start": "1128200",
    "end": "1138720"
  },
  {
    "text": "Yeah. If you find you're having trouble with \none of the steps, you can then continue to break   that down further. So, one of the things \nI found quite good for creative tasks,  ",
    "start": "1139560",
    "end": "1148520"
  },
  {
    "text": "like the actual generation of the email, is \nsplit that into, \"Okay, write the hook first,  ",
    "start": "1148520",
    "end": "1156200"
  },
  {
    "text": "and then based on this hook, write the email.\" \nAnd just by splitting that into two smaller tasks,  ",
    "start": "1156840",
    "end": "1163679"
  },
  {
    "text": "I find that you end up getting much more creative \nresponses. You can test whether this model is  ",
    "start": "1163680",
    "end": "1171920"
  },
  {
    "text": "just not good at writing a hook, like a way to \ndraw people in, or whether this model is just  ",
    "start": "1171920",
    "end": "1178520"
  },
  {
    "text": "not good at taking a hook and writing it out.You \nmight find that you use two different models for   those two things. Like, you might have to use a \nmuch better model for the creative task than you  ",
    "start": "1178520",
    "end": "1188559"
  },
  {
    "text": "need for the actual email writing task itself.\nThe other thing to note here is depending upon  ",
    "start": "1188560",
    "end": "1197000"
  },
  {
    "text": "how cognitively intelligent the models are will \ndepend upon when you need to split tasks into  ",
    "start": "1197000",
    "end": "1203360"
  },
  {
    "text": "multiple sub-tasks. So, when you had GPT-3, it \nwas quite advantageous to have more division of  ",
    "start": "1203360",
    "end": "1209679"
  },
  {
    "text": "labor at smaller and more easy tasks. Now that \nyou've got o1 and O1 Pro, you can essentially  ",
    "start": "1209680",
    "end": "1216960"
  },
  {
    "text": "just one-shot entire scripts or one-shot \nentire processes. Obviously, that retrieval   step might be done separately. But if we're \nviewing very much like editing a coding file,  ",
    "start": "1216960",
    "end": "1226639"
  },
  {
    "text": "you could maybe do all of that in one go. So, your \ndivision of labor now goes up to, \"Okay, now I can  ",
    "start": "1226640",
    "end": "1231920"
  },
  {
    "text": "solve a larger problem and do division of labor \nwith o1 to then maybe analyze, I don't know,  ",
    "start": "1231920",
    "end": "1238560"
  },
  {
    "text": "10 or 15 files and refactor all those files in \ndifferent ways. So, you can still kind of use that  ",
    "start": "1238560",
    "end": "1244400"
  },
  {
    "text": "principle even with a larger model. You're just \nbasically using that to make o1 solve things that  ",
    "start": "1244400",
    "end": "1251600"
  },
  {
    "text": "it can't inherently solve in a one-shot process, \nif that makes sense, because every model has some  ",
    "start": "1251600",
    "end": "1257240"
  },
  {
    "text": "sort of top end capability. You basically have to \ndiscover when does o1 consistently fail at doing  ",
    "start": "1257240",
    "end": "1264520"
  },
  {
    "text": "some type of task. And that's when you would then \nstart breaking that down into a more deterministic  ",
    "start": "1264520",
    "end": "1269680"
  },
  {
    "text": "workflow and using division of labor to then \nmake o1 or O1 Pro do something that it can't  ",
    "start": "1269680",
    "end": "1275360"
  },
  {
    "text": "do without division of labor, if that makes sense.\nThat makes sense. Then two questions sort of pop  ",
    "start": "1275360",
    "end": "1281840"
  },
  {
    "text": "into my mind. The first is, it was really \ninteresting to note that despite the focus  ",
    "start": "1281840",
    "end": "1288679"
  },
  {
    "text": "on prompt engineering and working \nwith language models, in general,   at least half of the steps that you described \nthere, James, were getting data, ingesting  ",
    "start": "1288680",
    "end": "1298240"
  },
  {
    "text": "data from other sources in order to use it in the \ncontext of generation. And it's almost like you're  ",
    "start": "1298240",
    "end": "1303480"
  },
  {
    "text": "still writing software effectively. You're still \nplugging things together, you know, to generate  ",
    "start": "1303480",
    "end": "1308960"
  },
  {
    "text": "the final thing. So, I found that interesting. \nBut the second point is, you mentioned there that  ",
    "start": "1308960",
    "end": "1315799"
  },
  {
    "text": "you're constantly trying to find the capabilities \nof the model that you're using. Have you had any   experience of maintenance of a solution over \nthe lifespan of multiple different models? Like,  ",
    "start": "1315800",
    "end": "1327520"
  },
  {
    "text": "what happens when OpenAI depreciate, you know, \nGPT-4 or something? Does that mean all of your  ",
    "start": "1327520",
    "end": "1335880"
  },
  {
    "text": "stuff is suddenly going to break because suddenly \nthe capabilities of the model have changed? ",
    "start": "1335880",
    "end": "1341200"
  },
  {
    "text": "I think, in general, things get better. \nThere are some nuances to that where,   you know, like, if you're comparing, like, the \nnew reasoning models versus the chat models,  ",
    "start": "1341760",
    "end": "1350800"
  },
  {
    "text": "then they're completely different paradigms. But \nin general, classifications probably get more   accurate. The output of the text feels kind of \nmore human. That being said, you know, there are  ",
    "start": "1350800",
    "end": "1363400"
  },
  {
    "text": "scenarios where you can get regressions because \nthe newer model doesn't work with the old prompt  ",
    "start": "1363400",
    "end": "1368920"
  },
  {
    "text": "in the same way. And we actually did experience \nthat for one of our products called Vexpower when  ",
    "start": "1368920",
    "end": "1374360"
  },
  {
    "text": "we had an automation script that would basically \ngenerate a large part of the course from listening  ",
    "start": "1374360",
    "end": "1380559"
  },
  {
    "text": "to a video transcript and ingesting the course \nmaterials and sort of helping with the FAQ and the  ",
    "start": "1380560",
    "end": "1386800"
  },
  {
    "text": "exercise generation. We found that when we moved \nfrom, I think, GPT-3.5 to GPT-4, and GPT-4 Turbo,  ",
    "start": "1386800",
    "end": "1395440"
  },
  {
    "text": "the original prompt just basically broke, and I \nhad to go in and re-architect and just basically  ",
    "start": "1397640",
    "end": "1403360"
  },
  {
    "text": "go in and... And so, yes, you can get changes.\nI think that is also happening less and less. And  ",
    "start": "1403360",
    "end": "1410600"
  },
  {
    "text": "the reason for that is a lot of developers are now \nusing something called structured output parsing,   which is a native-supported output format for \nOpenAI and Anthropic also offer something similar,  ",
    "start": "1410600",
    "end": "1423040"
  },
  {
    "text": "which basically allow you to define Python, \nPydantic models, or Zod models for data  ",
    "start": "1423040",
    "end": "1428240"
  },
  {
    "text": "validation. And these models that you can use, so, \nfor example, GPT-4o Mini, have been fine-tuned to  ",
    "start": "1428240",
    "end": "1435200"
  },
  {
    "text": "do JSON decoding and generation of JSON characters \nin a very deterministic way so that when it does  ",
    "start": "1435200",
    "end": "1444200"
  },
  {
    "text": "produce JSON, it doesn't run into validation \nerrors when you're parsing that string into a  ",
    "start": "1444200",
    "end": "1450279"
  },
  {
    "text": "JSON type. We are finding that the more that you \nstructure outputs, then potentially the less is  ",
    "start": "1450280",
    "end": "1457640"
  },
  {
    "text": "going to change in terms of the data that's coming \nout. So, the structured outputs API is definitely  ",
    "start": "1457640",
    "end": "1462840"
  },
  {
    "text": "worth looking at. It's something that I use \nactively on most of my projects. And that's been  ",
    "start": "1462840",
    "end": "1469799"
  },
  {
    "text": "a massive improvement versus what we had to do two \nyears ago where you had to specifically put in the  ",
    "start": "1469800",
    "end": "1476360"
  },
  {
    "text": "prompt, \"This is the kind of JSON structure that I \nwant.\" And sometimes it wouldn't conform to that. ",
    "start": "1476360",
    "end": "1483000"
  },
  {
    "text": "With the new capabilities as well, you find that \neven if your old code doesn't break, it's just  ",
    "start": "1483800",
    "end": "1489520"
  },
  {
    "text": "a really inefficient way to do things because the \nolder models tend to cost more and the new models  ",
    "start": "1489520",
    "end": "1495240"
  },
  {
    "text": "tend to be more...they have more capabilities. So, \nI had a recent example where I had a client. They  ",
    "start": "1495240",
    "end": "1504080"
  },
  {
    "text": "were doing video transcription, and they were \nusing a service for the transcription of the  ",
    "start": "1504080",
    "end": "1513799"
  },
  {
    "text": "audio. And then they're taking that transcript \nand then doing some kind of entity extraction  ",
    "start": "1513800",
    "end": "1522040"
  },
  {
    "text": "from that transcript. We found with Google \nGemini, which takes audio as a native input,  ",
    "start": "1522040",
    "end": "1529480"
  },
  {
    "text": "it doesn't need a transcription model on top. \nIt doesn't need Whisper, which is what they were   using before. Now, you can just dump the whole \nthing into Gemini, and they don't need to chunk  ",
    "start": "1529480",
    "end": "1540240"
  },
  {
    "text": "it up into different sections first. They didn't \nneed to transcribe it first. Gemini just does  ",
    "start": "1540240",
    "end": "1547280"
  },
  {
    "text": "it all in one shot. Because they have, I think \nit's like a million or two million token input,  ",
    "start": "1547280",
    "end": "1553040"
  },
  {
    "text": "you can put the whole call transcript in \nthere...oh, actually the whole call audio   in there and then just get back out entities. So, \nit just massively simplified the whole pipeline  ",
    "start": "1553040",
    "end": "1562320"
  },
  {
    "text": "once we got that working. It just took a lot of \neffort to optimize the prompt, but now it's at the  ",
    "start": "1562320",
    "end": "1568679"
  },
  {
    "text": "same sort of 75% accuracy, something like that, \nthat the previous system was, but at a much lower  ",
    "start": "1568680",
    "end": "1576360"
  },
  {
    "text": "cost. I think it's about 60% lower cost.\nMuch lower maintenance burden as well.",
    "start": "1576360",
    "end": "1582679"
  },
  {
    "start": "1587000",
    "end": "1962000"
  },
  {
    "text": "I think we sort of almost highlighted a little \nbit there about talking about task decomposition  ",
    "start": "1587600",
    "end": "1593960"
  },
  {
    "text": "and specifying JSON output structure formats and \nthings, about specificity, about being specific  ",
    "start": "1593960",
    "end": "1602399"
  },
  {
    "text": "about what you want the model to do. But there was \na really interesting quote from your book that I  ",
    "start": "1602400",
    "end": "1608240"
  },
  {
    "text": "found interesting. \"If your prompt is overly \nspecific, there might not be enough samples in   the training data to generate a response that's \nconsistent with all your criteria.\" So, that's  ",
    "start": "1608240",
    "end": "1618440"
  },
  {
    "text": "saying that you can go so deep sometimes that you \nactually end up in a space within the model that  ",
    "start": "1618440",
    "end": "1625639"
  },
  {
    "text": "doesn't have any previous examples. Therefore what \nyou get out might not be appropriate. I guess that  ",
    "start": "1625640",
    "end": "1632800"
  },
  {
    "text": "might be more of a problem for image models, \npossibly, than it is for text because I would  ",
    "start": "1632800",
    "end": "1640320"
  },
  {
    "text": "guess there's maybe more gaps in the training \ndata for image models than there are for texts.  There's a really good example I can give \nof this. I've actually got an example.  ",
    "start": "1640320",
    "end": "1647840"
  },
  {
    "text": "I was doing basically an interview for a job and \nsort of a placement there. And they created a   custom data structure to basically map that kind \nof backend system to the React front end. And you  ",
    "start": "1651960",
    "end": "1665160"
  },
  {
    "text": "can't use prompt engineering if you have a custom \ndata structure because these models don't have  ",
    "start": "1665160",
    "end": "1670520"
  },
  {
    "text": "any data in the pre-training data about that type \nof custom data structure. So, the only thing you   can really do at that point is a few-shot learning \nwith their own custom data structures or building  ",
    "start": "1670520",
    "end": "1680679"
  },
  {
    "text": "a fine-tuning model, which takes a lot more time.\nWhen you're working with coding, if you're  ",
    "start": "1680680",
    "end": "1687640"
  },
  {
    "text": "creating kind of a custom way of doing some type \nof CRUD operation and you're not using standard  ",
    "start": "1687640",
    "end": "1692720"
  },
  {
    "text": "backend, so you're maybe using a JSON file \nas your backend, and you have your own custom  ",
    "start": "1692720",
    "end": "1697799"
  },
  {
    "text": "data structure, and you have your own kind of \nways of manipulating that JSON in an API layer  ",
    "start": "1697800",
    "end": "1704120"
  },
  {
    "text": "that gets exposed to the front end, then all of \nthat is very difficult to actually work with in  ",
    "start": "1704120",
    "end": "1709920"
  },
  {
    "text": "terms of figuring out how does that work? How \ncan we automate parts of that? How can we know   which API endpoints to call because the data \nstructure is specifically custom? Now, if you  ",
    "start": "1709920",
    "end": "1720240"
  },
  {
    "text": "start using Postgres and you give it the Postgres \ntables or, you know, maybe you're using MongoDB,  ",
    "start": "1720240",
    "end": "1724800"
  },
  {
    "text": "there's enough data in the pre-training to know \nwhat types of operations you can do on any type  ",
    "start": "1725960",
    "end": "1731480"
  },
  {
    "text": "of database, in general. That's where, you know, \nthere is a trade-off between if you do start doing  ",
    "start": "1731480",
    "end": "1738160"
  },
  {
    "text": "things in a different way that is off the standard \npath, then you're going to end up where there's   probably less likely to be data in pre-training \nfor that. Another example of this is if a package  ",
    "start": "1738160",
    "end": "1749200"
  },
  {
    "text": "changes tomorrow, there's probably no pre-training \ndata in that foundational model about that package  ",
    "start": "1749200",
    "end": "1755559"
  },
  {
    "text": "at this point in time. Therefore, if you try and \ngenerate code about that newer package, you're  ",
    "start": "1755560",
    "end": "1761520"
  },
  {
    "text": "going to get older package code that's generated. \nSo, you know, you've got to be very careful about  ",
    "start": "1761520",
    "end": "1767120"
  },
  {
    "text": "specifically those types of problems.\nI've seen the same thing. Specifically  ",
    "start": "1767120",
    "end": "1773559"
  },
  {
    "text": "on image models, which is the part of the book \nthat I handled most of, you used to get to these  ",
    "start": "1773560",
    "end": "1780880"
  },
  {
    "text": "really sparse areas in latent space where there \njust...you know, there might be a lot of pictures  ",
    "start": "1780880",
    "end": "1788640"
  },
  {
    "text": "of Ronald McDonald, and there might be a lot of \npictures of astronauts, but there's not that many   pictures of Ronald McDonald as an astronaut, \nright? And then the more variables you layer  ",
    "start": "1788640",
    "end": "1798720"
  },
  {
    "text": "on top of that, the more likely the model \nis to get confused and not know how much of  ",
    "start": "1798720",
    "end": "1804919"
  },
  {
    "text": "Ronald McDonald to put in there versus how much \nof an astronaut to put in there because there's  ",
    "start": "1804920",
    "end": "1810680"
  },
  {
    "text": "some kind of inherent conflict. And that could \nlead to really creative results in some cases,  ",
    "start": "1810680",
    "end": "1818680"
  },
  {
    "text": "but also quite often it leads to poor results when \nyou step too far out of the training material. ",
    "start": "1818680",
    "end": "1826360"
  },
  {
    "text": "The solution there is, you know, you can train \nnew weights for the model. You can use DreamBooth,  ",
    "start": "1827120",
    "end": "1834400"
  },
  {
    "text": "which is a fine-tuning technique, or LoRA, and \ngive it examples. But then when you're training  ",
    "start": "1834400",
    "end": "1842360"
  },
  {
    "text": "the model, fine-tuning the model, then you're \nin some ways kind of constraining the creativity  ",
    "start": "1842360",
    "end": "1848799"
  },
  {
    "text": "of the model as well. So, this is always a \ntrade-off because if you think about the more   examples you give it, and this is true of text \ngeneration as well, the more examples you give  ",
    "start": "1848800",
    "end": "1858200"
  },
  {
    "text": "it, and the more you steer it in one direction, \nthen the less freedom it has to come up with   something that you didn't think of. Usually, what \nI try to avoid getting stuck in this trap is I'll  ",
    "start": "1858200",
    "end": "1872360"
  },
  {
    "text": "try prompt engineering first. I'll try and see \nwhat it comes up with just natively. Then if  ",
    "start": "1872360",
    "end": "1880240"
  },
  {
    "text": "it's too out of bounds, then I'll start to layer \non a few short examples or, you know, step towards  ",
    "start": "1880240",
    "end": "1885920"
  },
  {
    "text": "fine-tuning. But I don't jump straight to a \nfew-shot and fine-tuning for that reason. I  ",
    "start": "1885920",
    "end": "1892320"
  },
  {
    "text": "want to give it an opportunity to surprise me and \ngive me something that I wouldn't have thought of,  ",
    "start": "1892320",
    "end": "1898039"
  },
  {
    "text": "so that then I can adapt my vision accordingly.\nHow do you actually go about finding that middle  ",
    "start": "1898040",
    "end": "1905240"
  },
  {
    "text": "ground, that perfect balance between specificity \nand creativity? Is it an iterative process based  ",
    "start": "1905240",
    "end": "1912160"
  },
  {
    "text": "upon the problem that you're trying to \nsolve, or are there tricks of the trade? ",
    "start": "1912160",
    "end": "1917480"
  },
  {
    "text": "For image generation, in particular, it's \nmuch more iterative. I think image models are  ",
    "start": "1917480",
    "end": "1923400"
  },
  {
    "text": "starting to get smarter, starting to get better at \nadherence to the prompt and character consistency  ",
    "start": "1923400",
    "end": "1932400"
  },
  {
    "text": "as well, especially some of the video models \nwhere character consistency is really important,  ",
    "start": "1932400",
    "end": "1937920"
  },
  {
    "text": "because you can't have your character change \ntheir face halfway through the video. It doesn't   work that way. So, that is something, I think, \nthat's a very strong active development space.  ",
    "start": "1938720",
    "end": "1948040"
  },
  {
    "text": "And the models will just get better natively at \nit. But until it works better out of the box,  ",
    "start": "1948040",
    "end": "1955120"
  },
  {
    "text": "it is very iterative right now. And it \njust takes a lot of trial and error.",
    "start": "1955120",
    "end": "1959480"
  },
  {
    "start": "1962000",
    "end": "2579000"
  },
  {
    "text": "The next sort of bunch of questions I had were \nall sort of starting to dig into the use of RAG,  ",
    "start": "1963080",
    "end": "1969720"
  },
  {
    "text": "really. Actually, I think that was really \ninteresting. So, the quote that I pulled out was,  ",
    "start": "1969720",
    "end": "1977039"
  },
  {
    "text": "\"The real unlock is realizing that every part \nof the system can be broken down to a series of   iterative steps.\" And we talked about that, and \nwe touched upon it earlier with your comment,  ",
    "start": "1977040",
    "end": "1986600"
  },
  {
    "text": "James, where you were talking about task \ndecomposition and how the newer models are   actually able to do that themselves. But what \nstruck me, I think, with one of your examples,  ",
    "start": "1986600",
    "end": "1996600"
  },
  {
    "text": "you mentioned in there, using the words, literally \nthe word \"step by step forces it into this mode of  ",
    "start": "1996600",
    "end": "2003520"
  },
  {
    "text": "planning effectively.\" It made me wonder what \nother words are hidden within the models that  ",
    "start": "2003520",
    "end": "2011760"
  },
  {
    "text": "force certain behaviors? And why are they there?\nI think maybe it's just the way that the model  ",
    "start": "2011760",
    "end": "2019720"
  },
  {
    "text": "learned from the pre-training data, that when \nit has that, then the next bit of information  ",
    "start": "2019720",
    "end": "2025440"
  },
  {
    "text": "that it sees or produces is more based on \na reasoning chain. Thinking step by step,  ",
    "start": "2025440",
    "end": "2032279"
  },
  {
    "text": "or let's explore this, or let's think through \nall the steps, or let's use a chain of thought.  ",
    "start": "2032280",
    "end": "2037920"
  },
  {
    "text": "So, all of those ways, well, are early ways to \ndetermine whether or not you could get some type  ",
    "start": "2037920",
    "end": "2044040"
  },
  {
    "text": "of more reasoning and using the reasoning from \nthat to then hopefully produce a better answer.  ",
    "start": "2044040",
    "end": "2050919"
  },
  {
    "text": "It's interesting because a lot of reasoning models \ndo this now. So, O1 Pro will do reasoning for you.  ",
    "start": "2050920",
    "end": "2059040"
  },
  {
    "text": "I do think chain of thought is becoming less \nof a used technique. It's still used in chat  ",
    "start": "2059040",
    "end": "2064360"
  },
  {
    "text": "models. But specifically for reasoning models, \nthey're already doing that. And they're doing a   turn-based approach where they go through a series \nof steps, and they'll use the reasoning tokens  ",
    "start": "2064360",
    "end": "2073560"
  },
  {
    "text": "within that single step, which then goes into the \ninput of the secondary step. I would actually say  ",
    "start": "2073560",
    "end": "2080080"
  },
  {
    "text": "that we're using those types of things less. I \nthink the principles that are kind of standard  ",
    "start": "2080080",
    "end": "2086639"
  },
  {
    "text": "are things like if we're giving direction, for \nexample, you know, getting that relevant context  ",
    "start": "2086640",
    "end": "2092359"
  },
  {
    "text": "is still very important. Specifying format, \nagain, is also we're using that quite a lot with  ",
    "start": "2092360",
    "end": "2097960"
  },
  {
    "text": "structured outputs. And few-shot learning is \nstill really important. But I would say that   chain-of-thought reasoning is probably going \naway, at least in reasoning models, for sure.  ",
    "start": "2097960",
    "end": "2110119"
  },
  {
    "text": "The new one I've been seeing a lot of and \nsoon to be baked into most models is more   like self-evaluation or backtracking. I don't know \nif you've seen this when using Claude, where it  ",
    "start": "2111360",
    "end": "2122920"
  },
  {
    "text": "will start writing out the answer, and it'll say, \n\"Oh, no, sorry, I made a mistake there,\" and then   it will change its direction. So, it's kind of \nevaluating itself. So, rather than a chain of  ",
    "start": "2122920",
    "end": "2133440"
  },
  {
    "text": "thought, which is like planning ahead, then \nyou have this kind of other concept of like  ",
    "start": "2133440",
    "end": "2140119"
  },
  {
    "text": "after it started to generate, does it backtrack \nor change direction? But I would say, generally,  ",
    "start": "2140120",
    "end": "2146360"
  },
  {
    "text": "the reason why they're there in the training set \nis just that this is what people do, right? When  ",
    "start": "2146360",
    "end": "2153720"
  },
  {
    "text": "I was running my marketing agency, I would tell \npeople to plan what they're going to do for a  ",
    "start": "2153720",
    "end": "2160960"
  },
  {
    "text": "presentation before they create the presentation. \nThey would tell them to write an outline for a  ",
    "start": "2160960",
    "end": "2166400"
  },
  {
    "text": "blog post before they wrote the blog post. And \nthat's because thinking step by step through  ",
    "start": "2166400",
    "end": "2172880"
  },
  {
    "text": "a problem really helps people access high-level \nthinking and make sure they don't forget anything,  ",
    "start": "2172880",
    "end": "2180119"
  },
  {
    "text": "make sure that they are doing things in the right \nway to achieve a goal. If step by step reasoning  ",
    "start": "2180120",
    "end": "2188040"
  },
  {
    "text": "helps humans, then LLMs are kind of like a human \nbrain simulator, if you think about it. They're  ",
    "start": "2188040",
    "end": "2196360"
  },
  {
    "text": "trying to predict what a human would say in that \nsituation. It makes sense that the techniques that  ",
    "start": "2196360",
    "end": "2203240"
  },
  {
    "text": "work for people will just work for LLMs as well. \nThat's what they've seen in the training data.  ",
    "start": "2203240",
    "end": "2210400"
  },
  {
    "text": "And when people think step by step, they tend to \nend up producing better results. So, it's kind of  ",
    "start": "2210400",
    "end": "2216079"
  },
  {
    "text": "a way to steer them towards those better results.\nIt's just specifically the use of that word that  ",
    "start": "2216080",
    "end": "2221760"
  },
  {
    "text": "I find a bit weird. It's not a word that \nI've used in the past and that you haven't  ",
    "start": "2221760",
    "end": "2226840"
  },
  {
    "text": "read in the past. And then all of a \nsudden, it's a word that everybody's   using because it steers the model so much.\nBecause it's the word that they specifically  ",
    "start": "2226840",
    "end": "2237400"
  },
  {
    "text": "used in one of the scientific papers.\nExactly. Then everyone bakes that into   their libraries and blog posts and prompts. And \nthen you might learn from that second order or  ",
    "start": "2237400",
    "end": "2253040"
  },
  {
    "text": "third order by reading our book or whatever. \nBut, yeah, you don't have to specifically use  ",
    "start": "2253040",
    "end": "2258920"
  },
  {
    "text": "that phrase. Actually, it's a big misconception. \nI think a lot of people think that... They think,   \"Oh, you have to use the phrase. Let's \nthink step by step.\" But actually,  ",
    "start": "2258920",
    "end": "2267200"
  },
  {
    "text": "any combination of words for getting it to think \nthrough the problem first is going to work. ",
    "start": "2267200",
    "end": "2273320"
  },
  {
    "text": "I think there's also some emotional prompting \nthat still works with O1 Pro, for example. So,  ",
    "start": "2274120",
    "end": "2280240"
  },
  {
    "text": "if you tell O1 Pro, \"I'm not really bothered about \nthis answer,\" it will give you something pretty   small. But if you say, \"Oh, I have to get this \nright because my livelihood depends on this,\" O1  ",
    "start": "2280240",
    "end": "2289880"
  },
  {
    "text": "Pro is going to think for much longer, and it will \ngive you a much longer output as well. So, even  ",
    "start": "2289880",
    "end": "2295079"
  },
  {
    "text": "emotional prompting still works. We don't have \nthat thought step by step anymore. But emotional  ",
    "start": "2295080",
    "end": "2300560"
  },
  {
    "text": "prompting definitely still works with O1 Pro.\nInteresting. I don't think that was one of your  ",
    "start": "2300560",
    "end": "2306640"
  },
  {
    "text": "recipes in the book there, emotional prompting. \nYour next book should be a self-help book. I  ",
    "start": "2306640",
    "end": "2312760"
  },
  {
    "text": "think it'll be useful there.\nTherapy with LLMs.   Absolutely. There were quite a few \nother strategies that were mentioned.  ",
    "start": "2312760",
    "end": "2321480"
  },
  {
    "text": "I think the one that jumped out to \nme is the query planning prompting,  ",
    "start": "2321480",
    "end": "2328040"
  },
  {
    "text": "attempting to address multiple user intents. Could \nyou talk a little bit more about query planning? ",
    "start": "2328040",
    "end": "2337440"
  },
  {
    "text": "Query planning is basically where you have a user \nquery, and then rather than sending that straight   to an LLM, you can decompose that down into a \nseries of intents, and then you can work out  ",
    "start": "2338120",
    "end": "2348280"
  },
  {
    "text": "the order of those intents and then execute those. \nSo, that can be useful to specifically figure out  ",
    "start": "2348280",
    "end": "2355320"
  },
  {
    "text": "what to do at what point. There's also something \nelse that you should be aware of called routing,  ",
    "start": "2355320",
    "end": "2360920"
  },
  {
    "text": "which is another way of doing query planning, \nwhere you can basically take a user query,  ",
    "start": "2361480",
    "end": "2366560"
  },
  {
    "text": "and you have a bunch of destinations. Let's \nsay you've got three destinations, A, B,   and C. You can take a user query, and you can \nspecifically find what type of route should  ",
    "start": "2366560",
    "end": "2377120"
  },
  {
    "text": "that user query be forwarded to. Let's say you've \ngot three functions, one's generate a summary,  ",
    "start": "2377120",
    "end": "2382720"
  },
  {
    "text": "one's write an email, and one's look for some \norder information, if the user query is like,  ",
    "start": "2382720",
    "end": "2387800"
  },
  {
    "text": "\"I really want to summarize this information,\" \nthe LLM router will basically take that query  ",
    "start": "2387800",
    "end": "2393640"
  },
  {
    "text": "and decide, \"Okay, it needs to go to this generate \nsummary route,\" and it will just forward over the  ",
    "start": "2393640",
    "end": "2399920"
  },
  {
    "text": "user query. So, that's another approach.\nQuery planning is basically where you're  ",
    "start": "2399920",
    "end": "2404960"
  },
  {
    "text": "trying to decompose the query, figure \nout all the individually related intents,  ",
    "start": "2404960",
    "end": "2410160"
  },
  {
    "text": "the nested intents and dependencies there, and \nexecute those. And then you've got routing,   which I've just described. There's also in the \nOpenAI now, natively, they do support something  ",
    "start": "2410160",
    "end": "2421360"
  },
  {
    "text": "called parallel tool execution, or parallel \nfunction calling, which basically means you   can have a query that has mixed intents. So, if \nwe say we have a function that can send an email,  ",
    "start": "2421360",
    "end": "2431240"
  },
  {
    "text": "if I have a user query that says, for example, \n\"I want to send an email to John and Jane,\" and  ",
    "start": "2431240",
    "end": "2439720"
  },
  {
    "text": "you've had like, you know, \"And I want to say this \nto John, and I want to say this to Jane,\" OpenAI's  ",
    "start": "2439720",
    "end": "2444840"
  },
  {
    "text": "function calling or their tool calling natively \nnow supports the ability to recognize multiple  ",
    "start": "2444840",
    "end": "2450280"
  },
  {
    "text": "intents and then execute those in parallel.\nQuery planning is very useful. Routing is useful.  ",
    "start": "2450280",
    "end": "2458720"
  },
  {
    "text": "And we now also have native support for being able \nto handle mixed intent using, you know, standard  ",
    "start": "2458720",
    "end": "2465640"
  },
  {
    "text": "packages with parallel function calling. So, \nyeah, there's a range of things. I think routing  ",
    "start": "2465640",
    "end": "2471119"
  },
  {
    "text": "is a very interesting one. You can obviously use \nthat for forwarding requests. And then we've got   parallel function calling, which is great for \nhandling those kinds of multiple intents within  ",
    "start": "2471120",
    "end": "2480360"
  },
  {
    "text": "the same user query. I would say, though, that if \nyou had maybe 5 or 10 intents in a query, that's  ",
    "start": "2480360",
    "end": "2485640"
  },
  {
    "text": "when, you know, manually breaking that down and \nfiguring out those things is probably going to be   more useful than sending it straight to an agent \nand relying on the agent to specifically find,  ",
    "start": "2485640",
    "end": "2495920"
  },
  {
    "text": "you know, what tool calls to generate and what \ntool calls to execute on your backend because,  ",
    "start": "2495920",
    "end": "2503000"
  },
  {
    "text": "yeah, basically, the more things that could \ngo wrong and the less control you're having.  That's why you've got a lot of these frameworks \nlike LangGraph, which are basically trying to,  ",
    "start": "2503000",
    "end": "2512400"
  },
  {
    "text": "you know, not always generate every single tool \nin the kind of recursive while loop. They are   kind of breaking these things out into DAGs, so \ndirect acyclic graphs, where you have a series  ",
    "start": "2512400",
    "end": "2523960"
  },
  {
    "text": "of functions kind of hop along and then it goes \nback into the agentic loop. And you can do that  ",
    "start": "2523960",
    "end": "2529640"
  },
  {
    "text": "natively in Python. And the way you should \ndo that is let's say you've got a tool call,  ",
    "start": "2529640",
    "end": "2535599"
  },
  {
    "text": "rather than just returning it straight back to the \nagent, you could do three different types of other   Python functions inside that Python function. \nYou've got step one, step two, step three. So,  ",
    "start": "2535600",
    "end": "2545600"
  },
  {
    "text": "you can kind of already just write your own kind \nof LangGraph approaches to this problem where you   don't always want the agent to be responsible for \ngenerating the flow of information. Therefore,  ",
    "start": "2545600",
    "end": "2556400"
  },
  {
    "text": "you know, it can be called tool A, but tool A \nalso does three things inside of that tool. So,   there's a variety of different things that you \nshould be looking at. Routing is important,  ",
    "start": "2556400",
    "end": "2565920"
  },
  {
    "text": "obviously, tool calling is important, but, yeah,   you don't always have to rely on the agent to \ndecide exactly what tools need to be generated  ",
    "start": "2565920",
    "end": "2574240"
  },
  {
    "text": "and what ones need to be called.\nOkay. Makes sense. Thanks. James, you mentioned the word agent, which I think \nis a heavily overloaded term at the moment. It's  ",
    "start": "2574240",
    "end": "2587480"
  },
  {
    "start": "2579000",
    "end": "3116000"
  },
  {
    "text": "like the word AI. I kind of struggle to use \nit because it's so broad. But one thing that  ",
    "start": "2587480",
    "end": "2594480"
  },
  {
    "text": "struck me when you started talking about agents \nin your book was the parallels to reinforcement  ",
    "start": "2594480",
    "end": "2599840"
  },
  {
    "text": "learning. So, as you know, I wrote a book \non reinforcement learning, and that's all   about the idea of learning through trial and \nerror and having actions in an environment and  ",
    "start": "2599840",
    "end": "2610800"
  },
  {
    "text": "feeding those signals back to the agent and \nusing a reward signal to be able to decide  ",
    "start": "2610800",
    "end": "2615920"
  },
  {
    "text": "whether it did well. The parallels here is that \nit's almost sounding like that the agents need a  ",
    "start": "2615920",
    "end": "2621119"
  },
  {
    "text": "similar kind of structure. It's almost like the \nthinking of the prompt as the reward definition.  ",
    "start": "2621120",
    "end": "2626880"
  },
  {
    "text": "That's what decides whether it's rewarding or \nnot. The user context is kind of defining the  ",
    "start": "2626880",
    "end": "2631920"
  },
  {
    "text": "actions and then the environment and the various \ntools that can be used by the agent. So, I guess,  ",
    "start": "2631920",
    "end": "2638559"
  },
  {
    "text": "let me step back a little bit. How do agents \ndiffer from standard prompt based approaches? ",
    "start": "2639480",
    "end": "2648240"
  },
  {
    "text": "With a prompt-based approach, you're basically \nhaving a Python function or some type of code  ",
    "start": "2648880",
    "end": "2654519"
  },
  {
    "text": "that will, you know, call an LLM, it'll produce \nan output, and you're sort of putting that into  ",
    "start": "2654520",
    "end": "2659560"
  },
  {
    "text": "your existing software architecture, your sort \nof software where you've got an AWS Lambda, this  ",
    "start": "2659560",
    "end": "2665320"
  },
  {
    "text": "little bit. Now, you kind of do that as a fuzzy \nfunction and non-deterministic step. And then   you're kind of embedding that into your existing \nworkflows. And how that differs from an agent is  ",
    "start": "2665320",
    "end": "2676160"
  },
  {
    "text": "an agent is basically a different architecture, \nwhich relies very much on...it has a higher amount  ",
    "start": "2676160",
    "end": "2683920"
  },
  {
    "text": "of control. It has a higher amount of autonomy. \nAnd rather than basically you as the programmer  ",
    "start": "2683920",
    "end": "2691640"
  },
  {
    "text": "and imperatively determining what's going to \nhappen when this code is executed at runtime,  ",
    "start": "2691640",
    "end": "2697039"
  },
  {
    "text": "you're basically relying on the agent's prompt, \nits tools, and the tool definitions that it has,  ",
    "start": "2697040",
    "end": "2703480"
  },
  {
    "text": "and the context that that has in the \nprompt to decide what to do given a series   of messages that have already happened before.\nThen once those messages are basically executed,  ",
    "start": "2703480",
    "end": "2715000"
  },
  {
    "text": "those will generate some type of tool calls or \nmaybe not. They'll maybe just reply. And then  ",
    "start": "2715000",
    "end": "2721160"
  },
  {
    "text": "after that, you have to have some type of stopping \ncriteria. So, generally, the easier way of writing  ",
    "start": "2721160",
    "end": "2726680"
  },
  {
    "text": "is something like while there are still tool calls \nto do, then keep going with the agent. When we've  ",
    "start": "2726680",
    "end": "2734280"
  },
  {
    "text": "hit stop, reason, finish, or there's no tool calls \nleft, then the agent tick while loop. That being  ",
    "start": "2734280",
    "end": "2741040"
  },
  {
    "text": "said, you can also create your own objectives. \nSo, if the agent does stop prematurely,   you can also add an additional message saying, \n\"No, we haven't stopped yet. You haven't hit this  ",
    "start": "2741040",
    "end": "2751560"
  },
  {
    "text": "programmatically or non-deterministic goal.\" \nSo, imagine you're trying to get 100 leads,  ",
    "start": "2751560",
    "end": "2757240"
  },
  {
    "text": "and you've got this agent that's using a Google \nsearch tool and maybe a web page reading tool.  ",
    "start": "2757240",
    "end": "2762840"
  },
  {
    "text": "You can also say, you know, if it's finished \nearly, because there are no tool calls left,   you can add an additional message in there and \ntell it, \"No, you actually need to keep going.\" ",
    "start": "2762840",
    "end": "2772400"
  },
  {
    "text": "The thing with agents is they have these tools. \nThe tools give them the ability to execute. You  ",
    "start": "2773480",
    "end": "2781119"
  },
  {
    "text": "know, the more tools that it has, the more useful \nthe agent becomes because it can bundle those  ",
    "start": "2781120",
    "end": "2786600"
  },
  {
    "text": "tools and execute those tools in a variety of \ndifferent ways. So, it is essentially building  ",
    "start": "2786600",
    "end": "2791720"
  },
  {
    "text": "a computation graph at runtime as it executes \nthese tools. Now, the problem with them is,  ",
    "start": "2791720",
    "end": "2798720"
  },
  {
    "text": "obviously, you're giving a lot more autonomy to \nthe agent. And if one of those steps is wrong,  ",
    "start": "2798720",
    "end": "2804640"
  },
  {
    "text": "you're going to get compound error across all the \nrest of the steps. So, having reduced error is  ",
    "start": "2804640",
    "end": "2809839"
  },
  {
    "text": "really, really important. And if it's got too many \ntools, that can be a problem, or if the user query  ",
    "start": "2809840",
    "end": "2817120"
  },
  {
    "text": "isn't specific enough or can't be solved by the \ngiven tool set, that's also a problem. You've also  ",
    "start": "2817120",
    "end": "2822600"
  },
  {
    "text": "got problems with if one of the tools fails, \nwhat does the agent do in that scenario? So,   maybe it couldn't connect to the database, it \ncouldn't get the output. What does the agent do? ",
    "start": "2822600",
    "end": "2832240"
  },
  {
    "text": "There's lots of different problems that happen, \nboth from the DevOps side, from IO issues, from,  ",
    "start": "2832240",
    "end": "2839600"
  },
  {
    "text": "you know, the user issues in terms of the \nuser query. And a lot of people are trying   to figure out how to innovate in that space. So, \nadding humans in the loop steps is one approach.  ",
    "start": "2839600",
    "end": "2850920"
  },
  {
    "text": "People are building robust execution workflows to \nmake sure that steps don't fail so that the agent  ",
    "start": "2850920",
    "end": "2858920"
  },
  {
    "text": "always succeeds. If there's an IO error, it will \nretry for that step. At its heart, an agent has  ",
    "start": "2858920",
    "end": "2866040"
  },
  {
    "text": "tools. It's basically in some type of wild, true \nloop. It's doing all of those tool calls until it  ",
    "start": "2866040",
    "end": "2872880"
  },
  {
    "text": "thinks that it's finished with the result.\nMike, just following on from that then,  ",
    "start": "2872880",
    "end": "2878960"
  },
  {
    "text": "how much of a role does prompting still \nhave in agentic systems then? Does it   make it harder in some sense because you've \ngot disparate agents working independently? ",
    "start": "2879480",
    "end": "2888960"
  },
  {
    "text": "It's a good question. And I would say the system \nprompt for the agent still needs a lot of work  ",
    "start": "2888960",
    "end": "2897760"
  },
  {
    "text": "because you want to protect against those edge \ncases. So, in some respects, it's more important  ",
    "start": "2897760",
    "end": "2904960"
  },
  {
    "text": "because, you know, when the agent runs, it's \ngoing to do a lot of steps itself. And therefore,  ",
    "start": "2904960",
    "end": "2911200"
  },
  {
    "text": "that system prompt needs to be much better than \nit would be if it was just doing one step because,   like James said, those errors compound. If it \nchooses the wrong steps, then that's a bad thing.  ",
    "start": "2911200",
    "end": "2922240"
  },
  {
    "text": "So, all of the traditional prompt engineering \ntechniques still apply. It's just that they   have higher leverage because now the agent is \ngoing out on its own with your instructions.  ",
    "start": "2922240",
    "end": "2933640"
  },
  {
    "text": "You better make sure your instructions are good.\nIn some respects, it also takes away from prompt  ",
    "start": "2933640",
    "end": "2940079"
  },
  {
    "text": "engineering because the big difference actually \nbetween reinforcement learning and agents,  ",
    "start": "2940080",
    "end": "2949000"
  },
  {
    "text": "just to make that link, is that with reinforcement \nlearning, there's some objective truth, typically,  ",
    "start": "2949000",
    "end": "2954960"
  },
  {
    "text": "right? You can calculate it quickly. Whereas \nwith agents, they have to decide whether  ",
    "start": "2954960",
    "end": "2961520"
  },
  {
    "text": "they've done a good job or not based on your \ngoal. It's a much fuzzier reward mechanism  ",
    "start": "2961520",
    "end": "2966720"
  },
  {
    "text": "and self-determined in some ways. So, I think \nthat's why we're not seeing that many true agents  ",
    "start": "2968320",
    "end": "2973960"
  },
  {
    "text": "in production because the current crop of models \njust aren't as reliable in terms of deciding  ",
    "start": "2973960",
    "end": "2983280"
  },
  {
    "text": "whether they've done a good job and also in \ndeciding what to do based on their observations. ",
    "start": "2983280",
    "end": "2990120"
  },
  {
    "text": "As we get better models, then those loops will get \ntighter, and they'll make less mistakes. But it's  ",
    "start": "2990800",
    "end": "2996440"
  },
  {
    "text": "a bit of a trap in that if the AI can't do that \ntask very well, it's also probably not going to  ",
    "start": "2999760",
    "end": "3006240"
  },
  {
    "text": "be very good at judging whether that task has been \ndone well, to some degree. So, I think that's the  ",
    "start": "3006240",
    "end": "3013440"
  },
  {
    "text": "major difference. That's why when people talk \nabout agents from a marketing perspective,  ",
    "start": "3013440",
    "end": "3018520"
  },
  {
    "text": "I know you hear Salesforce or Microsoft talk about \nagents, they're not really talking about agents.  ",
    "start": "3018520",
    "end": "3024120"
  },
  {
    "text": "They're talking about quite a deterministic \nchain of prompts still, and maybe some retrieval  ",
    "start": "3024120",
    "end": "3031600"
  },
  {
    "text": "with RAG. It's very rare that you have a true \nagent in production these days, although that  ",
    "start": "3031600",
    "end": "3038800"
  },
  {
    "text": "should change quite a lot in the next year.\nJust to add on to that, like, the other thing  ",
    "start": "3038800",
    "end": "3044720"
  },
  {
    "text": "for the prompt engineering side is, obviously, you \ncan write the tool definitions more explicitly. If  ",
    "start": "3044720",
    "end": "3052359"
  },
  {
    "text": "the tool definitions are very detailed and tell \nexactly when to use this tool, when to not use  ",
    "start": "3052360",
    "end": "3057560"
  },
  {
    "text": "this tool, all that information is really valuable \nto the agent because it will pick different  ",
    "start": "3057560",
    "end": "3062880"
  },
  {
    "text": "tools based on those tool descriptions and the \narguments of those tool descriptions, etc., which  ",
    "start": "3062880",
    "end": "3067920"
  },
  {
    "text": "is generally in a JSON schema specification. So, \nthat also has an impact. You can also do hybrids,  ",
    "start": "3067920",
    "end": "3076119"
  },
  {
    "text": "by the way. So, you can have like the agent uses \nthe search function and it calls a search function  ",
    "start": "3076120",
    "end": "3081520"
  },
  {
    "text": "and that search function could use something \nlike Q-learning where it has a Google search,   a tabu search, a variety of different searches, \nand then it could use Q-learning inside of that  ",
    "start": "3081520",
    "end": "3091640"
  },
  {
    "text": "tool call. So, it's also possible to have an \nagent that has a mixture of an LLM-based agent  ",
    "start": "3091640",
    "end": "3098599"
  },
  {
    "text": "with a tool call that will use different types \nof searches based on an updated Q-learning table. ",
    "start": "3098600",
    "end": "3105320"
  },
  {
    "text": "I think, obviously, that's where most of \nthe innovation is going on at the moment.  ",
    "start": "3107920",
    "end": "3113160"
  },
  {
    "text": "Be interesting to see where that goes. But I \nthink we've got to the end of our time slot. So,  ",
    "start": "3113160",
    "end": "3120799"
  },
  {
    "start": "3116000",
    "end": "3372000"
  },
  {
    "text": "I think the only thing that remains is to thank \nyou both for joining me today. It's been really  ",
    "start": "3120800",
    "end": "3126360"
  },
  {
    "text": "interesting. To everybody else, the book again, \n\"Prompt Engineering for Generative AI,\" I'll plug  ",
    "start": "3126360",
    "end": "3131800"
  },
  {
    "text": "it for you. There you go. Really great book. \nRead it almost like in a couple of nights,  ",
    "start": "3131800",
    "end": "3137440"
  },
  {
    "text": "really. Just kept going and kept going. It's a \nreally fun book, really interesting, and I really   enjoyed it. So, I definitely recommend it. Any \nfinal closing words? Anything you want to plug? ",
    "start": "3137440",
    "end": "3150840"
  },
  {
    "text": "I appreciate you shouting out the book and \nalso reading it so quickly as well. Yeah,  ",
    "start": "3153040",
    "end": "3159120"
  },
  {
    "text": "I'm glad it's digestible. One thing I would \nlike to end with is just to remind people not  ",
    "start": "3159120",
    "end": "3168600"
  },
  {
    "text": "to get too anxious about how fast everything is \nmoving. Because if you're following everything  ",
    "start": "3168600",
    "end": "3176440"
  },
  {
    "text": "on Twitter or Reddit and you're seeing \nnew things come out every single week,  ",
    "start": "3177360",
    "end": "3183720"
  },
  {
    "text": "it can get anxiety-inducing thinking, \"How am \nI going to keep up with all this?\" But what I  ",
    "start": "3183720",
    "end": "3189960"
  },
  {
    "text": "found is that after a couple of years of being \nin the mix, very few things actually change.  ",
    "start": "3189960",
    "end": "3196640"
  },
  {
    "text": "Even though the models are getting better, \nthey're getting better at a predictable rate.  ",
    "start": "3199240",
    "end": "3204280"
  },
  {
    "text": "Costs are coming down at a predictable rate. So, \nit's just a case of zooming out a little bit,  ",
    "start": "3204280",
    "end": "3209960"
  },
  {
    "text": "thinking ahead and going, \"Okay, well, \nif I start working on this project now,  ",
    "start": "3209960",
    "end": "3215599"
  },
  {
    "text": "where are things going to be in six months?\" I \nwould say that even though things are moving fast,  ",
    "start": "3215600",
    "end": "3221840"
  },
  {
    "text": "if you're in a specific niche or a specific \ndomain, you cannot drive yourself crazy trying to  ",
    "start": "3221840",
    "end": "3230880"
  },
  {
    "text": "keep up with everything. Ultimately, if something \nreally big happens, other people will tell you  ",
    "start": "3230880",
    "end": "3236680"
  },
  {
    "text": "about it. That would be my advice for coping, \nis just kind of pick a niche, learn everything  ",
    "start": "3236680",
    "end": "3242240"
  },
  {
    "text": "about that niche, and then don't worry too much \nabout all the other craziness that's happening. ",
    "start": "3242240",
    "end": "3249720"
  },
  {
    "text": "Nice. I think my plug will be if \nyou haven't checked out Cursor yet,   definitely give it a go. I think the other thing \nas well is this idea of bottom-up coding. You can  ",
    "start": "3249720",
    "end": "3261360"
  },
  {
    "text": "give a very large goal to Claude and then break \nthat down into lots of different smaller tasks,  ",
    "start": "3261360",
    "end": "3266360"
  },
  {
    "text": "which you work through in chat or Composer. But \nthen there's also this bottom or top-down approach  ",
    "start": "3267040",
    "end": "3274440"
  },
  {
    "text": "to coding where you give O1 Pro 10 files and you \nsay, \"Generate me three or five new files,\" which  ",
    "start": "3274440",
    "end": "3282359"
  },
  {
    "text": "is a completely different paradigm. And when do \nyou use either of these? Claude's Sonnet has very  ",
    "start": "3282360",
    "end": "3289120"
  },
  {
    "text": "low latency, but it has more regressions and more \nhallucinations, while O1 Pro has incredibly high  ",
    "start": "3289120",
    "end": "3295520"
  },
  {
    "text": "latency, but very high accuracy. There's something \nto be had with sometimes you should pick Claude  ",
    "start": "3295520",
    "end": "3302600"
  },
  {
    "text": "and sometimes you should pick O1 Pro. There's \nalso scenarios where sometimes you'll use Claude   and it will generate code, and you'll kind of get \nstuck in a loop and it can't really figure it out.  ",
    "start": "3302600",
    "end": "3311799"
  },
  {
    "text": "You jump to O1 Pro, go make a cup of coffee or a \ntea, and then you come back and it's figured out   on the first go. So, have a think about when \nyou should be using these kinds of reasoning  ",
    "start": "3311800",
    "end": "3322760"
  },
  {
    "text": "models for your development work versus when you \nshould be using a lighter chat model to be doing  ",
    "start": "3322760",
    "end": "3329120"
  },
  {
    "text": "quicker edits or doing that bottom-up approach \nto coding rather than the top-down. Have a think   about that and obviously let me know. Yeah.\nOkay, thank you both. See you later. ",
    "start": "3329120",
    "end": "3338949"
  },
  {
    "text": "All right. Thanks, Phil Winder.\nAll right. Thanks, Bye.",
    "start": "3338949",
    "end": "3341359"
  }
]
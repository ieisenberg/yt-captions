[
  {
    "start": "0",
    "end": "85000"
  },
  {
    "text": "[Music]",
    "start": "6990",
    "end": "10118"
  },
  {
    "text": "cool thank you uh I'm Dogo as bit of background I have a very math and",
    "start": "12519",
    "end": "17720"
  },
  {
    "text": "computery background which is very good for deep learning um list of achievements on why you should listen to",
    "start": "17720",
    "end": "24080"
  },
  {
    "text": "me is that I currently work at a super cool company that does uses deep learning to make faster and more accurate Medical diagnoses",
    "start": "24080",
    "end": "30920"
  },
  {
    "text": "and in the past lives I've won a whole lot of like International math competitions and some programming",
    "start": "30920",
    "end": "36280"
  },
  {
    "text": "competitions as well and today I'm going to chat about what deep learning is and what it can do for you feel free to ask",
    "start": "36280",
    "end": "42399"
  },
  {
    "text": "questions at any time if I can ask that they can ask that right Simon cool so",
    "start": "42399",
    "end": "47520"
  },
  {
    "text": "yeah feel free to ask questions anytime just yell them out um especially if you think I'm lying to you",
    "start": "47520",
    "end": "53920"
  },
  {
    "text": "um so what is deep learning um gonna start with a disclaimer this deep learning is actually pretty complicated",
    "start": "53920",
    "end": "61120"
  },
  {
    "text": "it's hard to be very general about everything and be correct so when in doubt I'm going to favor generality so",
    "start": "61120",
    "end": "66960"
  },
  {
    "text": "if you're familiar with deep learning already it's going to sound like I'm lying a lot but in reality like this is just to like kind of give the high",
    "start": "66960",
    "end": "73320"
  },
  {
    "text": "really high level of it and also when whenever possible I'm going to favor some of the shortcuts that might not be",
    "start": "73320",
    "end": "78920"
  },
  {
    "text": "100% correct but should give the correct mental model of how these things work but if you have any questions feel free",
    "start": "78920",
    "end": "84000"
  },
  {
    "text": "to ask so from a super high level there's a",
    "start": "84000",
    "end": "89079"
  },
  {
    "start": "85000",
    "end": "172000"
  },
  {
    "text": "very there's a lot of like different levels of hierarchy here in the uh the ecosystem there's artificial",
    "start": "89079",
    "end": "94759"
  },
  {
    "text": "intelligence which is a super set of like everything um an example would be IBM Watson where it's lots of hand-coded",
    "start": "94759",
    "end": "101200"
  },
  {
    "text": "rules and uses extremely large amounts of expert Manpower built to do a specific task um there's machine",
    "start": "101200",
    "end": "107759"
  },
  {
    "text": "learning which is a subset of that um an example of this would be like Google ad click prediction and how you do this is",
    "start": "107759",
    "end": "114119"
  },
  {
    "text": "rather than using tons and tons of hardcoded rules you start using more examples to figure out how to combine",
    "start": "114119",
    "end": "119600"
  },
  {
    "text": "some hand-coded statistics to predict the probability of for example an ad click at a slightly um deeper level you",
    "start": "119600",
    "end": "126799"
  },
  {
    "text": "have representation learning which is sometimes seen as one layer deep learning so sometimes referred like",
    "start": "126799",
    "end": "134000"
  },
  {
    "text": "these levels are called shallow learning if you're trying to start a fight um and",
    "start": "134000",
    "end": "139360"
  },
  {
    "text": "an example of this would be Netflix movie recommendation where the statistics of what you even know about",
    "start": "139360",
    "end": "145360"
  },
  {
    "text": "each movie is learned from data but you're still learning a simple combination of how these features go together and after a few levels you get",
    "start": "145360",
    "end": "153080"
  },
  {
    "text": "into deep learning so this would be an example of figuring out diseases from images where instead of you know having",
    "start": "153080",
    "end": "159519"
  },
  {
    "text": "a layer of manual statistics that are learned and then combining it together you might learn all of these statistics",
    "start": "159519",
    "end": "165480"
  },
  {
    "text": "at the same time in tens hundreds or even thousands of steps which is what some people use",
    "start": "165480",
    "end": "171440"
  },
  {
    "text": "nowadays um this is probably not a common view of what deep learning is but",
    "start": "171440",
    "end": "176959"
  },
  {
    "start": "172000",
    "end": "246000"
  },
  {
    "text": "I think the easiest view of how to see it is deep learning is just an interface and this interface has roughly two",
    "start": "176959",
    "end": "184080"
  },
  {
    "text": "methods um as the first method you have a forward pass and this is definitely the easy part given arbitrary input make",
    "start": "184080",
    "end": "192000"
  },
  {
    "text": "arbitrary output anyone can do this part this is really easy um the the trick that makes it work is the backwards path",
    "start": "192000",
    "end": "199120"
  },
  {
    "text": "so given a desired change in the output you want to be able to transform this",
    "start": "199120",
    "end": "204319"
  },
  {
    "text": "into a desired change in the input and once you have these you can make arbitrarily complex things by changing",
    "start": "204319",
    "end": "210720"
  },
  {
    "text": "them up changing them up into a directed a cyclic graph and this sounds too good to be true especially with how we",
    "start": "210720",
    "end": "215959"
  },
  {
    "text": "designed the forward path because if you just say arbitrary input and arbitrary output of course you can do anything you",
    "start": "215959",
    "end": "221239"
  },
  {
    "text": "want but the hard part is how you define that backwards pass because as you make",
    "start": "221239",
    "end": "227680"
  },
  {
    "text": "your forward path more and more complicated like if you have like some really crazy function it becomes hard to Define how to map the inputs back into",
    "start": "227680",
    "end": "235439"
  },
  {
    "text": "outputs so by keeping these things simple and combining them together it gives us this almost composable language",
    "start": "235439",
    "end": "241879"
  },
  {
    "text": "of modules that allow us to do the things we want to do so once you have",
    "start": "241879",
    "end": "247120"
  },
  {
    "start": "246000",
    "end": "352000"
  },
  {
    "text": "this interface you just can build up from this once you once you have that you code up a bunch of these modules",
    "start": "247120",
    "end": "253799"
  },
  {
    "text": "that satisfy this interface as a side note um a bunch of these modules will be",
    "start": "253799",
    "end": "260280"
  },
  {
    "text": "parametric which means that they have parameters um which roughly means that",
    "start": "260280",
    "end": "265759"
  },
  {
    "text": "um they're stateful and they're stateful means that once you have the state the",
    "start": "265759",
    "end": "271240"
  },
  {
    "text": "state changes and it's this change in state that allows you to change this function from something that you just",
    "start": "271240",
    "end": "276560"
  },
  {
    "text": "Cobble together to something that that gets closer and closer to what you want to do um and once you have a framework a",
    "start": "276560",
    "end": "283880"
  },
  {
    "text": "language of what you want to do now you can start doing the tasks that you care about you and deep learn you always",
    "start": "283880",
    "end": "289240"
  },
  {
    "text": "Define a loss or a cost depending on how you want to Define this and this is something you want to minimize um for",
    "start": "289240",
    "end": "294960"
  },
  {
    "text": "reasons that I'd happily explain um this has to always be a scaler so it can't be um several costs at the same time you",
    "start": "294960",
    "end": "301199"
  },
  {
    "text": "have to squash it down into a single thing that you care about and once you squish this number like everything you",
    "start": "301199",
    "end": "306840"
  },
  {
    "text": "care about in the world into a single number now you can start using deep learning to optimize this um you create",
    "start": "306840",
    "end": "312320"
  },
  {
    "text": "an architecture which is the function that you want to do and this would be how you compose together these modules",
    "start": "312320",
    "end": "318840"
  },
  {
    "text": "that I talked about so the way you connect them together changes the function that you have and the kind of",
    "start": "318840",
    "end": "323960"
  },
  {
    "text": "representation power it has um and that becomes the hard part after that you initialize the parameters",
    "start": "323960",
    "end": "330280"
  },
  {
    "text": "and you train this architecture by repeatedly updating the parameters to minimize the cost so you go forward",
    "start": "330280",
    "end": "336039"
  },
  {
    "text": "through the network to get the things you care about and you go backwards through the network to change the parameters to be slightly better for",
    "start": "336039",
    "end": "342160"
  },
  {
    "text": "your cost and you repeat this many times until you get a function that you're really really happy with and solves whatever problem you want and at the end",
    "start": "342160",
    "end": "348720"
  },
  {
    "text": "you just use that function just the forward pass um how to implement the backwards",
    "start": "348720",
    "end": "354160"
  },
  {
    "start": "352000",
    "end": "432000"
  },
  {
    "text": "pass is um in general we almost always use the chain rule uh this is really",
    "start": "354160",
    "end": "359680"
  },
  {
    "text": "really nice because it makes implementing the backwards pass easy how this works is if you have your output as",
    "start": "359680",
    "end": "366360"
  },
  {
    "text": "some function of some X um and you have the partial derivative of your output",
    "start": "366360",
    "end": "371440"
  },
  {
    "text": "dld DF you can get dld DX by simply multiplying the partial derivative of DF",
    "start": "371440",
    "end": "377199"
  },
  {
    "text": "DX and the nice part about this is that dldf is gotten from the rest of your",
    "start": "377199",
    "end": "382759"
  },
  {
    "text": "network and DF DX is gotten just from your module so this allows you to chain",
    "start": "382759",
    "end": "387800"
  },
  {
    "text": "these things together in a way that requires local information in order to get this backwards path it's very nice",
    "start": "387800",
    "end": "394319"
  },
  {
    "text": "it um there's theoretical reasons of why this is a good way to do this and perhaps the best part about this is some",
    "start": "394319",
    "end": "401800"
  },
  {
    "text": "Frameworks make this completely Automatic by defining a forward pass um using automatic differentiation you can",
    "start": "401800",
    "end": "407800"
  },
  {
    "text": "figure out how to make a backwards pass automatically so it becomes basically as easy as defining arbitrary functions um",
    "start": "407800",
    "end": "415000"
  },
  {
    "text": "as uh so you actually do get this benefit of just Define arbitrary things",
    "start": "415000",
    "end": "421520"
  },
  {
    "text": "return arbitrary things as long as all the operations you do are differentiable you can just make it work like magic and",
    "start": "421520",
    "end": "427160"
  },
  {
    "text": "optimize it and this is literally how people do this in practice um updating the parameters",
    "start": "427160",
    "end": "433720"
  },
  {
    "start": "432000",
    "end": "452000"
  },
  {
    "text": "these are just Minor Details to like get an understanding of how this works is that once you have your existing",
    "start": "433720",
    "end": "439919"
  },
  {
    "text": "parameters you get your gradient and you take a step in the opposite direction of the gradient uh and the partial",
    "start": "439919",
    "end": "446080"
  },
  {
    "text": "derivative tells us how to change the parameters to increase or decrease the cost that we care",
    "start": "446080",
    "end": "451440"
  },
  {
    "text": "about an important word to know to know though is um that people always use I",
    "start": "451440",
    "end": "457639"
  },
  {
    "start": "452000",
    "end": "520000"
  },
  {
    "text": "think kind of makes it more complicated because it's a big word is back propagation or back prop for short uh",
    "start": "457639",
    "end": "464080"
  },
  {
    "text": "this is has a longer name called reverse mode automatic differentiation um which sounds pretty",
    "start": "464080",
    "end": "471639"
  },
  {
    "text": "complicated but this is just the chain rule plus dynamic programming I assume that I just talked about chain R I",
    "start": "471639",
    "end": "476879"
  },
  {
    "text": "assume people are familiar with dynamic programming but this is just caching and the idea would be when you have a",
    "start": "476879",
    "end": "483120"
  },
  {
    "text": "computation graph this is a very simple computation graph eal C * D Cals a plus b d equal B+ 1 the idea would be um you",
    "start": "483120",
    "end": "492360"
  },
  {
    "text": "Traverse the graph from the top to the bottom and by doing it from the top to the bottom instead of the bottom to the",
    "start": "492360",
    "end": "497800"
  },
  {
    "text": "top you can cache the intermediates that are used many times in the graph and by caching these intermediates you get",
    "start": "497800",
    "end": "503479"
  },
  {
    "text": "something that's much more efficient than if you were going to do a naive solution and this allows you to get",
    "start": "503479",
    "end": "508759"
  },
  {
    "text": "gradients that are computable in linear time in the size of your graph so you basically evaluate each node once and",
    "start": "508759",
    "end": "515680"
  },
  {
    "text": "this is a really nice property um this makes it all really efficient and that's basically it for the basics from a high",
    "start": "515680",
    "end": "522640"
  },
  {
    "start": "520000",
    "end": "578000"
  },
  {
    "text": "level deep learning is just composing optimizable sub components optimizable almost always means differentiable",
    "start": "522640",
    "end": "529200"
  },
  {
    "text": "differentiable means that you can do back propop uh back propop is just the train Rule and dynamic programming uh",
    "start": "529200",
    "end": "535560"
  },
  {
    "text": "when once you get into practical deep learning normally you have to combine this with green descent software and a",
    "start": "535560",
    "end": "541200"
  },
  {
    "text": "data set that you care about um and the space of software is there's a very rich",
    "start": "541200",
    "end": "546959"
  },
  {
    "text": "space of software that I'll talk a little bit about in the future but it this these things are solved for you so",
    "start": "546959",
    "end": "552160"
  },
  {
    "text": "you can do a deep learning without even knowing how to calculate a gradient",
    "start": "552160",
    "end": "557320"
  },
  {
    "text": "yourself so while we can do arbitrarily complicated things there are a few standard modules that are the main",
    "start": "557320",
    "end": "562920"
  },
  {
    "text": "Workhorse of deep learning today and the goal of this section is going to be to get a high level understanding of each",
    "start": "562920",
    "end": "569000"
  },
  {
    "text": "since of them can be very incredibly nuanced um but these standard modules will cover almost all of what's",
    "start": "569000",
    "end": "575279"
  },
  {
    "text": "happening in papers the simplest of them is perhaps the simplest is just matrix",
    "start": "575279",
    "end": "581079"
  },
  {
    "start": "578000",
    "end": "628000"
  },
  {
    "text": "multiplication it has many names the fully connected layer sometimes short to FC sometimes called dense because you",
    "start": "581079",
    "end": "587920"
  },
  {
    "text": "have lots of connections linear layer because it's a linear transformation or apine because sometimes there's a bias",
    "start": "587920",
    "end": "594279"
  },
  {
    "text": "and uh the matrix multiplication is basically every time you have a neural network diagram all of these arrows",
    "start": "594279",
    "end": "599360"
  },
  {
    "text": "correspond to the matrix multiplication so when you have a diagram that looks complicated that's from that's from this",
    "start": "599360",
    "end": "604560"
  },
  {
    "text": "kind of thing and you can interpret this as a weight from every input to every output so if you have M inputs and you",
    "start": "604560",
    "end": "611519"
  },
  {
    "text": "have n outputs you have M byn weights that transform your inputs to your outputs and its implementation is",
    "start": "611519",
    "end": "617120"
  },
  {
    "text": "literally a matrix multiplication um and W in this case is generally a parameter which means you",
    "start": "617120",
    "end": "623680"
  },
  {
    "text": "learn the connections from inputs to outputs this on its own is not powerful",
    "start": "623680",
    "end": "629160"
  },
  {
    "start": "628000",
    "end": "698000"
  },
  {
    "text": "enough enough so you need at least one more thing which is uh nonlinearity uh the original",
    "start": "629160",
    "end": "635880"
  },
  {
    "text": "nonlinearity is called a sigmoid it's just this function it has the nice",
    "start": "635880",
    "end": "641040"
  },
  {
    "text": "property that it Maps reals into the the space 01 and it can be interpreted as a",
    "start": "641040",
    "end": "647160"
  },
  {
    "text": "probability but um that's not as important as just being nonlinear and",
    "start": "647160",
    "end": "652240"
  },
  {
    "text": "the reason the nonlinearity is important is if you have this kind of like neural network when you stack up the layers",
    "start": "652240",
    "end": "658000"
  },
  {
    "text": "back to back if you had no nonlinearity in the middle this would just be two Matrix multiplies back to back and what",
    "start": "658000",
    "end": "664519"
  },
  {
    "text": "would happen is you could just combine this into a single Matrix multiply so if you had a 100 layer purely linear",
    "start": "664519",
    "end": "670160"
  },
  {
    "text": "network of just Matrix multiplications while this thing is pretty complicated and you do all the work of a real neural",
    "start": "670160",
    "end": "675920"
  },
  {
    "text": "network you could actually flatten it into a single weight Matrix because of uh linear composition of linearity so",
    "start": "675920",
    "end": "683320"
  },
  {
    "text": "this was the original one people like it because it's very similar to what people used before they really got how machine",
    "start": "683320",
    "end": "689639"
  },
  {
    "text": "learning worked which was just binary thresholding um which was very brain inspired back in the day and the cool",
    "start": "689639",
    "end": "696880"
  },
  {
    "text": "part is with just those two units you know how to make a neural network you",
    "start": "696880",
    "end": "702279"
  },
  {
    "start": "698000",
    "end": "1067000"
  },
  {
    "text": "can just simply do you get your input you apply the Matrix multiply you apply a sigmoid you apply another Matrix",
    "start": "702279",
    "end": "708000"
  },
  {
    "text": "multiply and you have one and these are called multi-layer perceptrons when you",
    "start": "708000",
    "end": "713200"
  },
  {
    "text": "only have Matrix multiplies and nonlinearities and the cool part is that there's a theorem on this that this",
    "start": "713200",
    "end": "719519"
  },
  {
    "text": "simple architecture like literally three functions can solve can approximate",
    "start": "719519",
    "end": "724959"
  },
  {
    "text": "arbitrary functions which means it can solve any problem that you care about um there's a cool theorem on this um the",
    "start": "724959",
    "end": "731800"
  },
  {
    "text": "idea is that if you make the middle big enough you can calculate basically any function um the downside is that just",
    "start": "731800",
    "end": "739560"
  },
  {
    "text": "because it can it doesn't mean it will and a single layer multi-layer perceptron often causes more problem",
    "start": "739560",
    "end": "745279"
  },
  {
    "text": "than it solves so this is why there was an AI winter in the just because these things are kind of",
    "start": "745279",
    "end": "751920"
  },
  {
    "text": "terrible um but people have gotten a lot better at it so now now neural networks are",
    "start": "751920",
    "end": "758160"
  },
  {
    "text": "cool and as a disclaimer these are these are neural networks um when you have so",
    "start": "758160",
    "end": "764720"
  },
  {
    "text": "this is would be a multi-layer perceptron these are neural networks everything I'm talking about today is still a neural network but these are",
    "start": "764720",
    "end": "771399"
  },
  {
    "text": "specifically when you talk about the multi-layer perceptron that is what this is so um since then people have made",
    "start": "771399",
    "end": "779680"
  },
  {
    "text": "better nonlinearities this is probably majority of the Improvement between 1990",
    "start": "779680",
    "end": "785440"
  },
  {
    "text": "and 2012 unfortunately um which is you have like a kind of a smarter nonlinearity so",
    "start": "785440",
    "end": "791279"
  },
  {
    "text": "instead of taking this weird squiggly function you just uh do a threshold so",
    "start": "791279",
    "end": "796720"
  },
  {
    "text": "anything that's negative you just turn it into zero uh this is actually the most popular nonlinearity nowadays it",
    "start": "796720",
    "end": "803399"
  },
  {
    "text": "does incredibly well um it has some really nice optimization properties um in particular when you have zero um like",
    "start": "803399",
    "end": "812279"
  },
  {
    "text": "this nonline is very linear so it works very well with a chain Rule and this thing is used almost everywhere nowadays",
    "start": "812279",
    "end": "818720"
  },
  {
    "text": "especially in the middle of a neural network there is a softmax which uh you",
    "start": "818720",
    "end": "825560"
  },
  {
    "text": "can think of as converting a bunch of numbers into a discrete probability distribution so uh the math of it is p",
    "start": "825560",
    "end": "833680"
  },
  {
    "text": "equals um you exponentiate your input and then you divide it by the sum of the inputs you can think of the explanation",
    "start": "833680",
    "end": "839160"
  },
  {
    "text": "is turning it all of the numbers into positive and the dividing by the sum is a normalization term there's some very",
    "start": "839160",
    "end": "845040"
  },
  {
    "text": "nice properties about this and it's used as the final layer for classification problems and it's used in almost every",
    "start": "845040",
    "end": "851519"
  },
  {
    "text": "neural network cool that was the easy part um this gets complicated I like",
    "start": "851519",
    "end": "860639"
  },
  {
    "text": "feel free to ask questions during this I normally explain this with a whiteboard and it normally is is complicated even with a whiteboard um but I'll I'll try",
    "start": "860639",
    "end": "868120"
  },
  {
    "text": "to go through this so a convolution is a the main Workhorse for um deep learning",
    "start": "868120",
    "end": "874240"
  },
  {
    "text": "on images and deep learning on images is basic it's kind of where this revolution started um so it's very very important",
    "start": "874240",
    "end": "880279"
  },
  {
    "text": "it's probably the place where deep learning is most advanced so it's a very important primitive and I think it's a very cool primitive to understand um",
    "start": "880279",
    "end": "886920"
  },
  {
    "text": "because you really realize like how beautiful the framework is when you see like wow this thing sounds pretty complicated but it you can just plug it",
    "start": "886920",
    "end": "894040"
  },
  {
    "text": "in and you don't even need to know how it works when someone has coded up for you which is what I do",
    "start": "894040",
    "end": "899560"
  },
  {
    "text": "um so this is a linear operation for 2D images so once you have a multi-layer perceptron you have a mapping from every",
    "start": "899560",
    "end": "906720"
  },
  {
    "text": "input to every output but in the case of images your inputs are structured so you have like this spatial relationship",
    "start": "906720",
    "end": "912880"
  },
  {
    "text": "between your inputs and if you have a mapping from every input to every output you kind of throw away this spatial",
    "start": "912880",
    "end": "918000"
  },
  {
    "text": "relationship so the idea would be what if rather than having a connection from every input to every output what if",
    "start": "918000",
    "end": "924800"
  },
  {
    "text": "every output the output looked like an image as well and every output was only local connected to the things it",
    "start": "924800",
    "end": "930199"
  },
  {
    "text": "corresponds to so that is Insight number one so local connections and insight",
    "start": "930199",
    "end": "936120"
  },
  {
    "text": "number two is every output is a local function of its input What If instead of",
    "start": "936120",
    "end": "942120"
  },
  {
    "text": "having every output be its own function which would be the general case what if every output was the same function of",
    "start": "942120",
    "end": "947199"
  },
  {
    "text": "its input so what this then becomes is equivalent to like a well-known function",
    "start": "947199",
    "end": "952240"
  },
  {
    "text": "in computer vision which is a convolution which is you have a kernel which is um you can think of it like a",
    "start": "952240",
    "end": "959040"
  },
  {
    "text": "local Weight Matrix so it's represented um let me see oh cool my mouse is here",
    "start": "959040",
    "end": "965160"
  },
  {
    "text": "so it's often represented as this Square in an image like thing which means that they're capturing that local input you",
    "start": "965160",
    "end": "972399"
  },
  {
    "text": "just do a matrix multiply between all of the weights of the kernel um which would",
    "start": "972399",
    "end": "977440"
  },
  {
    "text": "be something like this you do that multiply for everything in the local region you sum up the result so this is",
    "start": "977440",
    "end": "982839"
  },
  {
    "text": "just the dot product and then you do that at every single location at the input so it's kind of like tiling your",
    "start": "982839",
    "end": "988199"
  },
  {
    "text": "input with the same function or it can be interpreted extracting the same features at every location which is the",
    "start": "988199",
    "end": "994240"
  },
  {
    "text": "the more common way to interpret it uh this is um it's very powerful it's very",
    "start": "994240",
    "end": "1001160"
  },
  {
    "text": "parameter efficient because you have a lot of weight sharing between the parameters and um you can end up having",
    "start": "1001160",
    "end": "1008399"
  },
  {
    "text": "much larger outputs than you can have with a normal matrix multiplication and you also don't lose spatial information",
    "start": "1008399",
    "end": "1014000"
  },
  {
    "text": "which is a very important structure of images so these are some really nice properties",
    "start": "1014000",
    "end": "1019680"
  },
  {
    "text": "and as a side effect you might think that this thing is really complicated how do I take a gradient of it because I",
    "start": "1019680",
    "end": "1026600"
  },
  {
    "text": "maybe the whole thing is kind of complicated but this is actually equivalent to a very constrained matrix",
    "start": "1026600",
    "end": "1033199"
  },
  {
    "text": "multiplication so if you take your input image and you unroll it because with a matrix multiplication you lose that",
    "start": "1033199",
    "end": "1038760"
  },
  {
    "text": "spatial structure and you unroll your input you basically have a few connection like every input every um",
    "start": "1038760",
    "end": "1045600"
  },
  {
    "text": "sorry every output is connected to maybe like nine of your inputs and that just becomes equivalent to the really like",
    "start": "1045600",
    "end": "1052200"
  },
  {
    "text": "all the diagram with lots of arrows but most of the arrows being zero or missing so this is still completely",
    "start": "1052200",
    "end": "1058120"
  },
  {
    "text": "differentiable and still fits very nicely into this framework that you can plug in with all of the other nonlinearities",
    "start": "1058120",
    "end": "1065240"
  },
  {
    "text": "um cool it's going to get a little bit harder uh another very fundamental",
    "start": "1066039",
    "end": "1072320"
  },
  {
    "start": "1067000",
    "end": "1387000"
  },
  {
    "text": "building block is called the recurrent neural network I don't know why the building block is called a network when everything else is called a layer but um",
    "start": "1072320",
    "end": "1080120"
  },
  {
    "text": "that's just kind of convention and this is solving a a problem that is basically",
    "start": "1080120",
    "end": "1086360"
  },
  {
    "text": "has not been solved in machine learning before which is we want functions to take to take in variable size input but",
    "start": "1086360",
    "end": "1093480"
  },
  {
    "text": "they can only take in fixed size input and this becomes a problem when your uh function is parametric like a fully",
    "start": "1093480",
    "end": "1100080"
  },
  {
    "text": "connected layer is because if you want the connection from every input to every output but your input size changes that",
    "start": "1100080",
    "end": "1105480"
  },
  {
    "text": "means your the number of Weights you have changes and that means that you if you get a longer example um at inference",
    "start": "1105480",
    "end": "1111360"
  },
  {
    "text": "time you now don't know what to do with it and this also might be inefficient because you might have like really really big a really large number of",
    "start": "1111360",
    "end": "1118159"
  },
  {
    "text": "inputs and you might not need all of the Power of having like every connection there so a recurrent neural network is a",
    "start": "1118159",
    "end": "1124760"
  },
  {
    "text": "way to solve this problem and the solution to this problem is recursion so",
    "start": "1124760",
    "end": "1130080"
  },
  {
    "text": "what you have is an initial state which would just be let's just call it h in this example and you have a bunch of",
    "start": "1130080",
    "end": "1135200"
  },
  {
    "text": "these inputs X and there's a variable number of them so you don't really know what like this capital t is and you can",
    "start": "1135200",
    "end": "1142159"
  },
  {
    "text": "make a function that takes in a fixed size and because each X is fixed size you can make that function f take in",
    "start": "1142159",
    "end": "1147760"
  },
  {
    "text": "both H and x and now you can recurse through this list by saying h of T",
    "start": "1147760",
    "end": "1153280"
  },
  {
    "text": "equals the function of the previous state sorry the new state is a function of the previous state and the current input and then you just return the final",
    "start": "1153280",
    "end": "1159840"
  },
  {
    "text": "one and what this allows you to do is it allows you to with a fixed size input um",
    "start": "1159840",
    "end": "1166159"
  },
  {
    "text": "you can have it operate in sorry with a fixed a function that takes fixed size input you can now turn it into a",
    "start": "1166159",
    "end": "1171480"
  },
  {
    "text": "function that takes in a variable siiz input by applying that function a variable number of times this is not",
    "start": "1171480",
    "end": "1177520"
  },
  {
    "text": "the this is like a pretty obvious Insight um and you could do that with any kind of machine learning algorithm",
    "start": "1177520",
    "end": "1183679"
  },
  {
    "text": "you could like apply a random Forest like an arbitrary number of times but the cool part about this is that because",
    "start": "1183679",
    "end": "1189200"
  },
  {
    "text": "this function is differentiable this recursive function is also differentiable so you can take the derivatives of each of the inputs you",
    "start": "1189200",
    "end": "1195320"
  },
  {
    "text": "can take you can take the derivative of the weight matrices you use at each T you can use that F at each St and you",
    "start": "1195320",
    "end": "1202559"
  },
  {
    "text": "get a diagram that looks kind of like this um you can think of it as applying an FC layer for each input that takes",
    "start": "1202559",
    "end": "1209280"
  },
  {
    "text": "the input and the state so far and this diagram might not be very clear but",
    "start": "1209280",
    "end": "1214559"
  },
  {
    "text": "there are many different diagrams for rnns and they're all equally confusing if you're unfamiliar with them so um",
    "start": "1214559",
    "end": "1220760"
  },
  {
    "text": "this is kind of the the one on the left is my favorite one because you can kind of think of it as a stateful function",
    "start": "1220760",
    "end": "1227679"
  },
  {
    "text": "except you the state only lasts for the duration of your input um but the unrolled version is the version you use",
    "start": "1227679",
    "end": "1234720"
  },
  {
    "text": "if you're taking gradients so this is equivalent to just passing the gradients through this very long",
    "start": "1234720",
    "end": "1240679"
  },
  {
    "text": "graph uh last complicated slide long shortterm memory units uh this puts me",
    "start": "1240679",
    "end": "1246280"
  },
  {
    "text": "in a really hard position because I can't not talk about them because they're so autous but they're also",
    "start": "1246280",
    "end": "1251679"
  },
  {
    "text": "extremely complicated and they're they take more building blocks than I've even even explained but there is this great",
    "start": "1251679",
    "end": "1258240"
  },
  {
    "text": "blog post post I think slides will be published so you don't have to worry about that uh this great great blog post",
    "start": "1258240",
    "end": "1263640"
  },
  {
    "text": "tries to explain it but I I'm going to try to give like a high level intuition of them just so like even higher than",
    "start": "1263640",
    "end": "1268799"
  },
  {
    "text": "what I've said so far um just so that you can kind of understand um where",
    "start": "1268799",
    "end": "1275159"
  },
  {
    "text": "where it's coming from when I talk about these things being used and the idea would be it's kind of",
    "start": "1275159",
    "end": "1281679"
  },
  {
    "text": "like an RNN and in practice no one uses the RNN that I've just described it's a",
    "start": "1281679",
    "end": "1287039"
  },
  {
    "text": "very simple function and there's very much more complicated versions it's an RNN where the function is just really",
    "start": "1287039",
    "end": "1292679"
  },
  {
    "text": "complicated so this entire thing here is a representation of that function um I'm",
    "start": "1292679",
    "end": "1299039"
  },
  {
    "text": "not going to get into the details of it but it involves a lot of different um",
    "start": "1299039",
    "end": "1304760"
  },
  {
    "text": "mechanisms in order to make optimization easier and the idea is that if you apply",
    "start": "1304760",
    "end": "1311480"
  },
  {
    "text": "if you design this function well the function that's applied at each time step it can make the problem much much easier to optimize and you can have like",
    "start": "1311480",
    "end": "1317840"
  },
  {
    "text": "a much much more powerful function and the key is that by having a path which",
    "start": "1317840",
    "end": "1322960"
  },
  {
    "text": "is relatively simple so this is what represents with the top path where there's very little operations being done to it it makes it easier to stack",
    "start": "1322960",
    "end": "1329840"
  },
  {
    "text": "these things what back to back and that makes it easier to learn long-term",
    "start": "1329840",
    "end": "1335159"
  },
  {
    "text": "relationships between the functions okay that was that was the",
    "start": "1335159",
    "end": "1342080"
  },
  {
    "text": "complicated part uh you now know 95% of the building blocks that everyone uses",
    "start": "1342080",
    "end": "1347520"
  },
  {
    "text": "for state-of-the-art deep learning with just these billing BLX you could probably do new state-of-the-art things on new domains so congratulations you're",
    "start": "1347520",
    "end": "1355240"
  },
  {
    "text": "ready for the next part um so in this part I want to talk",
    "start": "1355240",
    "end": "1360279"
  },
  {
    "text": "about what deep learning is really good at uh and what you should use it on the answer is a whole lot so um I'm going to",
    "start": "1360279",
    "end": "1366400"
  },
  {
    "text": "cover just the rough themes of where deep learning really shines but there's just much much more to it which I think",
    "start": "1366400",
    "end": "1371760"
  },
  {
    "text": "is part of the awesomeness because it all falls under this extremely simple framework that I've just described I",
    "start": "1371760",
    "end": "1377320"
  },
  {
    "text": "don't think that you could like describe any framework as simple as what I've just done and have it solve this many",
    "start": "1377320",
    "end": "1383000"
  },
  {
    "text": "complicated unsolved tasks before 2012 basically so convolutional neural",
    "start": "1383000",
    "end": "1389760"
  },
  {
    "start": "1387000",
    "end": "2198000"
  },
  {
    "text": "networks this is a general architecture commonly referred to as cnns um this actually means a network in this case",
    "start": "1389760",
    "end": "1396240"
  },
  {
    "text": "and not just a layer the idea is that you take your image you apply a convolution you apply",
    "start": "1396240",
    "end": "1403039"
  },
  {
    "text": "your Ru your rectified linear unit you apply convolution you apply a Ru and you basically repeat this conu until you",
    "start": "1403039",
    "end": "1410080"
  },
  {
    "text": "solve all of the problems in computer vision that isn't quite true since at the end you need to tack on some sort of",
    "start": "1410080",
    "end": "1416480"
  },
  {
    "text": "output layer and the output layer depends on what kind of input you're trying to solve the Canon like the a",
    "start": "1416480",
    "end": "1421600"
  },
  {
    "text": "really old school task um is that you um it's face recognition trying to",
    "start": "1421600",
    "end": "1427559"
  },
  {
    "text": "determine like whose face this is and this is a a really cool task because it makes the representation very Visual and",
    "start": "1427559",
    "end": "1434760"
  },
  {
    "text": "you can see how the network learns over time so at the first first layer you when you start with the pixels at the",
    "start": "1434760",
    "end": "1441000"
  },
  {
    "text": "first layer your filters tend to just match for edges and very simple things",
    "start": "1441000",
    "end": "1446480"
  },
  {
    "text": "so convolutions can match edges and other very simple shapes and as you get deeper and deeper into the network you learn more complicated functions of the",
    "start": "1446480",
    "end": "1452520"
  },
  {
    "text": "input so after that you can start combining edges into corners or blobs so",
    "start": "1452520",
    "end": "1458640"
  },
  {
    "text": "this is still extremely simple but after you get to another layer somehow like combining two corners the right way",
    "start": "1458640",
    "end": "1464120"
  },
  {
    "text": "becomes kind of like an eye like shape or if you have like two corners in a blob that becomes more eye like and you",
    "start": "1464120",
    "end": "1469399"
  },
  {
    "text": "can build up from edges to Corners to object parts and eventually into the objects you care about and as you get",
    "start": "1469399",
    "end": "1476120"
  },
  {
    "text": "really really deep networks you actually have intermediates that are extremely semantic objects for example um people",
    "start": "1476120",
    "end": "1482640"
  },
  {
    "text": "have made a lot of tools for visualization of neural networks where um they visualize what these what the",
    "start": "1482640",
    "end": "1488640"
  },
  {
    "text": "neural networks learn and you have for example if you have neural network that doesn't learn to classify books at all",
    "start": "1488640",
    "end": "1494399"
  },
  {
    "text": "but it learns to classify bookshelves some of the intermediate features actually become book classifiers which",
    "start": "1494399",
    "end": "1499720"
  },
  {
    "text": "is really interesting like it can learn a like a hierarchical representation of your input space such that these are",
    "start": "1499720",
    "end": "1507720"
  },
  {
    "text": "useful things to combine together in order to make a robust classifier and by combining so maybe if you combine like",
    "start": "1507720",
    "end": "1515200"
  },
  {
    "text": "three books together as well as a square this becomes a bookshelf so these are kind of like what the local operations",
    "start": "1515200",
    "end": "1520399"
  },
  {
    "text": "do with each neural network and the beauty of it is that it's all learned automatically for you you don't need to",
    "start": "1520399",
    "end": "1525600"
  },
  {
    "text": "program like I have a bookshelf bookshelves normally have have books they have books uh sorry they have like",
    "start": "1525600",
    "end": "1530919"
  },
  {
    "text": "Square stuff maybe they're often beside flowers this all can like happen in a data set automatically for you and these",
    "start": "1530919",
    "end": "1537880"
  },
  {
    "text": "convolutional neural networks are absolutely amazing they just when I I I wasn't joking when they save basically",
    "start": "1537880",
    "end": "1543679"
  },
  {
    "text": "all of computer vision right now um it all started with IMAP this was in 2012",
    "start": "1543679",
    "end": "1550320"
  },
  {
    "text": "this is when deep learning actually the entire hype train started where um you",
    "start": "1550320",
    "end": "1556240"
  },
  {
    "text": "had traditional machine learning solving this very hard very large computer vision data set and it was kind of",
    "start": "1556240",
    "end": "1561840"
  },
  {
    "text": "plateauing over the years and all of a sudden deep learning comes in and it just blows everything away and ever",
    "start": "1561840",
    "end": "1568440"
  },
  {
    "text": "since then everything's been everything in computer vision has been deep learning like nothing can even compare",
    "start": "1568440",
    "end": "1575159"
  },
  {
    "text": "and recently we've even been able to get super human results which is um pretty",
    "start": "1575159",
    "end": "1580679"
  },
  {
    "text": "impressive because humans are pretty good at seeing things it's kind of what we evolved to do and the same",
    "start": "1580679",
    "end": "1587240"
  },
  {
    "text": "architectures can do all sorts of really interesting structured tasks so using",
    "start": "1587240",
    "end": "1592720"
  },
  {
    "text": "almost the same architecture you can use a conet to determine you know like you",
    "start": "1592720",
    "end": "1598640"
  },
  {
    "text": "can break up your input space into a what's called a semantic segmentation of like all of the relevant parts that you",
    "start": "1598640",
    "end": "1604080"
  },
  {
    "text": "have and using basically the same architecture as well you can do crazy",
    "start": "1604080",
    "end": "1609120"
  },
  {
    "text": "things like super resolution where you take in like a low resolution image and make it you can fill in the details",
    "start": "1609120",
    "end": "1615120"
  },
  {
    "text": "which is pretty that's a pretty not only is it incredible even though it",
    "start": "1615120",
    "end": "1620559"
  },
  {
    "text": "sounds pretty easy um it's incredible that like that you can use the same architecture that takes",
    "start": "1620559",
    "end": "1627440"
  },
  {
    "text": "an image and tells you whether or not there's a dog in it to take an image and return like a new higher resolution",
    "start": "1627440",
    "end": "1633159"
  },
  {
    "text": "image and this is basically the same Library the same component um it's just very very",
    "start": "1633159",
    "end": "1639559"
  },
  {
    "text": "composable and that's really awesome you can also use this to solve really hard medical tasks tasks that people could",
    "start": "1639559",
    "end": "1645760"
  },
  {
    "text": "not solve before here we're detecting classifying lung cancer in CT scans uh",
    "start": "1645760",
    "end": "1651559"
  },
  {
    "text": "these are the kinds of things that I like to work on and it's not only limited to Vision",
    "start": "1651559",
    "end": "1657440"
  },
  {
    "text": "there's been a lot of work in language understanding so uh something that deep learning is really good at is language",
    "start": "1657440",
    "end": "1663880"
  },
  {
    "text": "modeling roughly this means how probable is a how much sense does statement make",
    "start": "1663880",
    "end": "1671399"
  },
  {
    "text": "in a certain language so it might have to do with a question response how are you I am fine it might have other things",
    "start": "1671399",
    "end": "1678440"
  },
  {
    "text": "such as what would be a weird thing um my laptop is squishy might be a very",
    "start": "1678440",
    "end": "1684559"
  },
  {
    "text": "improbable sentence to say so a neural network could probably determine squishy is a very bad adjective for a laptop um",
    "start": "1684559",
    "end": "1691440"
  },
  {
    "text": "this is a very improbable sentence but if I said my laptop is hot that would probably be a much more likely sentence",
    "start": "1691440",
    "end": "1698240"
  },
  {
    "text": "and this already has some human-like feel to it because language was designed for humans and being able to have like",
    "start": "1698240",
    "end": "1706159"
  },
  {
    "text": "if you can do language understanding as in determining the probability of like any sentence given a context you can and",
    "start": "1706159",
    "end": "1712320"
  },
  {
    "text": "if you do this perfectly you can solve basically any task and this is a it's a really interesting domain where it's",
    "start": "1712320",
    "end": "1718840"
  },
  {
    "text": "being applied because previous if you look at what how language understanding was done before deep learning was around",
    "start": "1718840",
    "end": "1724799"
  },
  {
    "text": "it was just incredibly simplistic tons and tons of rules no robustness to data",
    "start": "1724799",
    "end": "1729880"
  },
  {
    "text": "sets you'd have to make custom rules for every language and now you could you can use the same tricks for um English as",
    "start": "1729880",
    "end": "1737760"
  },
  {
    "text": "you can for Chinese characters as you can for bite code um so that is just pretty",
    "start": "1737760",
    "end": "1743480"
  },
  {
    "text": "incredible they've obviously been much more complicated tasks a um pretty",
    "start": "1743480",
    "end": "1749480"
  },
  {
    "text": "popular use for machine for deep learning that this people are really putting a lot of effort in is endtoend",
    "start": "1749480",
    "end": "1756279"
  },
  {
    "text": "language understanding from scratch so the idea is you use an RNN to compress a",
    "start": "1756279",
    "end": "1762600"
  },
  {
    "text": "a sentence in your Source language into um a vector like I described in the RNs",
    "start": "1762600",
    "end": "1768360"
  },
  {
    "text": "section and then you use a different RNN to decode it into a target language and",
    "start": "1768360",
    "end": "1775840"
  },
  {
    "text": "while it's not surprising that you can design a neural network that plausibly can output this it is quite surprising",
    "start": "1775840",
    "end": "1781640"
  },
  {
    "text": "that it works so well and you've been able to have neural networks that um in",
    "start": "1781640",
    "end": "1788360"
  },
  {
    "text": "the a in a span of a few grad student months match the the performance of",
    "start": "1788360",
    "end": "1794360"
  },
  {
    "text": "systems that people have spent decades engineering um and perhap and nowadays I",
    "start": "1794360",
    "end": "1800600"
  },
  {
    "text": "think that deep learning systems are not end to end deep learning systems are not",
    "start": "1800600",
    "end": "1806240"
  },
  {
    "text": "what's used for this right now but they're a very important component so people still use a bit of hard-coded stuff but it's only a matter of time and",
    "start": "1806240",
    "end": "1813240"
  },
  {
    "text": "the beauty is that what if we have a new task or a new language now it can just automatically work like what if we um",
    "start": "1813240",
    "end": "1820399"
  },
  {
    "text": "you know we find some lost language from a thousand years ago and we have like a",
    "start": "1820399",
    "end": "1827279"
  },
  {
    "text": "good amount of their texts can we actually learn um how to translate it or",
    "start": "1827279",
    "end": "1833919"
  },
  {
    "text": "understand it without any knowledge of this and it seems like purely from data we can and that's really cool we don't",
    "start": "1833919",
    "end": "1839080"
  },
  {
    "text": "need an understanding of something in order to we don't need an understanding prior to applying our machine learning",
    "start": "1839080",
    "end": "1845159"
  },
  {
    "text": "models in order to have an understanding afterwards and that is just really really awesome I've actually been",
    "start": "1845159",
    "end": "1850880"
  },
  {
    "text": "chatting with the people at seti the search for extraterrestrial intelligence and one of the tasks that they're doing",
    "start": "1850880",
    "end": "1858120"
  },
  {
    "text": "is um trying to understand Dolphins um the rationale is that if we",
    "start": "1858120",
    "end": "1864320"
  },
  {
    "text": "can't dolphins have language aliens might have language um if we if we see",
    "start": "1864320",
    "end": "1869960"
  },
  {
    "text": "alien communication we probably won't understand it um perhaps we can use Dolphins as a proxy for aliens to try",
    "start": "1869960",
    "end": "1875360"
  },
  {
    "text": "and understand them um so there's some really cool tasks that are happening there it's not limited to that there's",
    "start": "1875360",
    "end": "1882080"
  },
  {
    "text": "some really cool things being done with art in deep learning actually I think that companies have started up that that",
    "start": "1882080",
    "end": "1888880"
  },
  {
    "text": "their entire business model is creating awesome deep learning art and they seem to be doing well from what I've heard um",
    "start": "1888880",
    "end": "1895760"
  },
  {
    "text": "in this case this is a hallucination purely from a convet trained to do image",
    "start": "1895760",
    "end": "1901639"
  },
  {
    "text": "classification so an imet conet you know something that takes an image tells you like what breed of dog it is what",
    "start": "1901639",
    "end": "1907240"
  },
  {
    "text": "objects are in it you can use it um with a few tricks to create this kind of crazy art and this was a pretty big",
    "start": "1907240",
    "end": "1914880"
  },
  {
    "text": "splash it's very unintuitive that a neural Network that isn't even made",
    "start": "1914880",
    "end": "1920360"
  },
  {
    "text": "trained to make art actually can turn out making this kind of thing there've been more popular use",
    "start": "1920360",
    "end": "1926480"
  },
  {
    "text": "cases such as style transfer the idea would be you can take a neural network still train for classification the idea",
    "start": "1926480",
    "end": "1933480"
  },
  {
    "text": "would be classification has some priors about what images um some priors about",
    "start": "1933480",
    "end": "1938919"
  },
  {
    "text": "the natural world so the what you do then is you say I want my image to kind",
    "start": "1938919",
    "end": "1944360"
  },
  {
    "text": "of match the distribution from a different image and then you get this kind of style transfer where you can mix",
    "start": "1944360",
    "end": "1952320"
  },
  {
    "text": "together these kinds of components and while this is this is actually a pretty ugly example there's there's some some",
    "start": "1952320",
    "end": "1958760"
  },
  {
    "text": "good ones I promise um there's some much more complicated things you can do it's not just like taking two images together",
    "start": "1958760",
    "end": "1964840"
  },
  {
    "text": "and merging them together you can do things like transforming a perhaps not",
    "start": "1964840",
    "end": "1971159"
  },
  {
    "text": "super great a drawing something that you could probably do in paint fairly quickly into something that looks like",
    "start": "1971159",
    "end": "1978360"
  },
  {
    "text": "an artist did um or something that's really awesome and the idea would be that you can actually take these",
    "start": "1978360",
    "end": "1984919"
  },
  {
    "text": "arbitrary Doodles and convert them into these things that look like paintings and this kind of stuff is really awesome",
    "start": "1984919",
    "end": "1990799"
  },
  {
    "text": "and I think it's just the beginning of the kind of stuff that we can do with neural network art but after basically less than a year of",
    "start": "1990799",
    "end": "1997720"
  },
  {
    "text": "work on this you're making applications that are already very tangible very awesome",
    "start": "1997720",
    "end": "2003480"
  },
  {
    "text": "um very like this is already something that if I made this I would probably hang up in my living room and this has",
    "start": "2003480",
    "end": "2010519"
  },
  {
    "text": "only been one year of work imagine what happens in 10 years I I saved the The",
    "start": "2010519",
    "end": "2015639"
  },
  {
    "text": "Best For Last in terms of art we can combine our pictures with that of Pokemon so clearly the future is here um",
    "start": "2015639",
    "end": "2022639"
  },
  {
    "text": "this is one of my crowning achievements I think um primarily because I've done this with like dozens of people and only",
    "start": "2022639",
    "end": "2029279"
  },
  {
    "text": "mine turned out well um but yeah I I think this is really awesome um there's",
    "start": "2029279",
    "end": "2035639"
  },
  {
    "text": "like just so many things to do here and so few people are working it on it and that the sky is really the limit so it's",
    "start": "2035639",
    "end": "2042720"
  },
  {
    "text": "just really exciting what on the kinds of stuff that we can be created",
    "start": "2042720",
    "end": "2048158"
  },
  {
    "text": "here um there have been other huge achievements um game playing has been",
    "start": "2048159",
    "end": "2053280"
  },
  {
    "text": "really big if anyone saw uh deep mind's $500 million acquisition in",
    "start": "2053280",
    "end": "2058800"
  },
  {
    "text": "2013 um roughly the only paper that they had at that time was learning to play",
    "start": "2058800",
    "end": "2064679"
  },
  {
    "text": "Atari games from pixels which is might be harder than it sounds because humans",
    "start": "2064679",
    "end": "2070158"
  },
  {
    "text": "have a prior of how to play the game right like they have a prior that this is maybe a ball and that's a paddle and",
    "start": "2070159",
    "end": "2077000"
  },
  {
    "text": "I want to destroy certain things or they have a prior that a key opens doors or that roads are something I want to stay",
    "start": "2077000",
    "end": "2083480"
  },
  {
    "text": "on in a driving game but uh neural network is not given any of these priors it's literally only given the pixels",
    "start": "2083480",
    "end": "2090118"
  },
  {
    "text": "given these images it learns to play at what is um on median a super human level",
    "start": "2090119",
    "end": "2096079"
  },
  {
    "text": "and the techniques have been continuing to get better and this kind of stuff uh very similar tricks have been applied to",
    "start": "2096079",
    "end": "2103079"
  },
  {
    "text": "uh the much more recent result of um Google deep Minds alphao Network",
    "start": "2103079",
    "end": "2109960"
  },
  {
    "text": "which was not that huge of a deal in the west but if you ever talk to people from",
    "start": "2109960",
    "end": "2115000"
  },
  {
    "text": "the more Eastern world you you can talk to them about here are the achievements of deep learning you talk about smart",
    "start": "2115000",
    "end": "2120760"
  },
  {
    "text": "inbox and they're like oh that's pretty okay you talk about um image search yeah",
    "start": "2120760",
    "end": "2126200"
  },
  {
    "text": "that's pretty okay and then talk tell them about like oh yeah it also beat a world champion at go and they're like w",
    "start": "2126200",
    "end": "2132160"
  },
  {
    "text": "it beat it plays go that's amazing um and people predicted that even beating",
    "start": "2132160",
    "end": "2138760"
  },
  {
    "text": "human experts at go would probably be depending on the expert 10 to 100 years off and it happened it just happened",
    "start": "2138760",
    "end": "2146960"
  },
  {
    "text": "it's already done it's already that like humans have lost it Go and as a side",
    "start": "2146960",
    "end": "2152720"
  },
  {
    "text": "effect go has also caused more fear over AI safety than any other neural network",
    "start": "2152720",
    "end": "2158280"
  },
  {
    "text": "I believe and um this is probably a good representation of that I don't know how",
    "start": "2158280",
    "end": "2164400"
  },
  {
    "text": "that's that's medium clear um this is an XKCD of like how hard people used to",
    "start": "2164400",
    "end": "2169680"
  },
  {
    "text": "think these games were and you can see go is basically being the last on the",
    "start": "2169680",
    "end": "2175839"
  },
  {
    "text": "level of computer still loose to top humans and not all of these are solved",
    "start": "2175839",
    "end": "2181720"
  },
  {
    "text": "but that is just pretty incredible that that's now solved people have been trying to ask like if it can do this",
    "start": "2181720",
    "end": "2189160"
  },
  {
    "text": "what can't it do because go is a task that requires a lot of reasoning and these um kinds of",
    "start": "2189160",
    "end": "2196720"
  },
  {
    "text": "achievements have been being transferred into the physical world as well this is a Google has like a farm with like a",
    "start": "2196720",
    "end": "2203800"
  },
  {
    "start": "2198000",
    "end": "2292000"
  },
  {
    "text": "bunch of robots that have learned on their own to grasp um objects and basically um robotics control is usually",
    "start": "2203800",
    "end": "2210839"
  },
  {
    "text": "pretty hard especially when you're trying to make it generalize and they've been able to do that just by you know",
    "start": "2210839",
    "end": "2216359"
  },
  {
    "text": "throwing the robots into a dark Warehouse having it train for a while designing a cute objective function and",
    "start": "2216359",
    "end": "2222680"
  },
  {
    "text": "it just learned to grasp things better than their handd designed controllers did which was pretty awesome and more",
    "start": "2222680",
    "end": "2230400"
  },
  {
    "text": "recently actually I think there was a video like that came out last week of Nvidia using just deep learning for",
    "start": "2230400",
    "end": "2236760"
  },
  {
    "text": "self-driving cars so the idea was like with just a single camera in front of your car now your car can learn to drive",
    "start": "2236760",
    "end": "2242599"
  },
  {
    "text": "can can drive itself from learning from how other people drove and and this is a",
    "start": "2242599",
    "end": "2248680"
  },
  {
    "text": "very interesting result because even Google has been working for I don't know if it's it might have been a decade",
    "start": "2248680",
    "end": "2254319"
  },
  {
    "text": "already that they've been working on self-driving cars using you know liar and slam and all of that stuff and",
    "start": "2254319",
    "end": "2261839"
  },
  {
    "text": "Nvidia um by some measures caught up to them entirely within I think it's been",
    "start": "2261839",
    "end": "2267880"
  },
  {
    "text": "less than a year since they've been investing in this so a lot of things it it seems to be changing a lot of things",
    "start": "2267880",
    "end": "2273280"
  },
  {
    "text": "especially these kinds of perception tasks um because research is moving so fast I",
    "start": "2273280",
    "end": "2280040"
  },
  {
    "text": "also have to spend some time on things that are not yet practical but may very well soon be as a disclaimer I've been",
    "start": "2280040",
    "end": "2286720"
  },
  {
    "text": "traveling this weekend so I'm not sure if some of these things belong in the already solved category um generation is a big one",
    "start": "2286720",
    "end": "2293800"
  },
  {
    "start": "2292000",
    "end": "2438000"
  },
  {
    "text": "there's tons and tons of stuff happening in Generations so I definitely can't give it justice there's really cool stuff in like just generating images",
    "start": "2293800",
    "end": "2299520"
  },
  {
    "text": "from scratch and generating arbitrary other domains from scratch images are just the most visual so I have them here",
    "start": "2299520",
    "end": "2305680"
  },
  {
    "text": "but um some of the coolest and perhaps most practical examples are conditional Generation Um something I'm really",
    "start": "2305680",
    "end": "2312680"
  },
  {
    "text": "excited about is image to text so the idea is you take in an input image and",
    "start": "2312680",
    "end": "2318720"
  },
  {
    "text": "the output is not like yes or no whether or not the dog's into it but you output a description of the image and that's",
    "start": "2318720",
    "end": "2325720"
  },
  {
    "text": "like a extremely human task it could be extremely useful um if you do this task",
    "start": "2325720",
    "end": "2330800"
  },
  {
    "text": "right it seems like there's a a whole ton of possibilities I'm very excited about like taking a medical image and",
    "start": "2330800",
    "end": "2336920"
  },
  {
    "text": "like outputting like a complete report of it which would be really awesome and some people that are really excited",
    "start": "2336920",
    "end": "2342400"
  },
  {
    "text": "about this that has applications in the very short term is um I don't know the right way to say it but like the poor",
    "start": "2342400",
    "end": "2348800"
  },
  {
    "text": "eyesight Community um so web pages nowadays have been pretty bad about",
    "start": "2348800",
    "end": "2354880"
  },
  {
    "text": "stuff for uh people with disabilities and imagine if you had a neural network that can just describe an image for you",
    "start": "2354880",
    "end": "2361240"
  },
  {
    "text": "describe a page for you tell you what's on the page in a very semantic summarized way and there's also really",
    "start": "2361240",
    "end": "2367560"
  },
  {
    "text": "cool opposite problem which is instead of taking an image and outputting a description you taken a description and",
    "start": "2367560",
    "end": "2373720"
  },
  {
    "text": "output an image which uh as a terrible artist I'm probably a bit more excited about because instead of like I I can",
    "start": "2373720",
    "end": "2380520"
  },
  {
    "text": "describe pictures I can't really draw them and like these are much better already than I can draw but that's",
    "start": "2380520",
    "end": "2385720"
  },
  {
    "text": "probably a low bar um but in in this kind of network you actually take in like a sentence as text and all of these",
    "start": "2385720",
    "end": "2392319"
  },
  {
    "text": "images are generated from that Network and that's pretty incredible some of them are not super great",
    "start": "2392319",
    "end": "2397839"
  },
  {
    "text": "but like these birds are actually um I I i' believe they're real um the flowers",
    "start": "2397839",
    "end": "2405240"
  },
  {
    "text": "the not the purple ones um but they they actually seem close like if I if it was",
    "start": "2405240",
    "end": "2411359"
  },
  {
    "text": "zoomed out enough I could see this is being pretty real and can you imagine in",
    "start": "2411359",
    "end": "2416920"
  },
  {
    "text": "a future where instead of having to spend millions of dollars on a movie you just like type it up and then a neural",
    "start": "2416920",
    "end": "2422839"
  },
  {
    "text": "network just generates the movie for you um we're we're quite away from that but perhaps not that far away especially",
    "start": "2422839",
    "end": "2429599"
  },
  {
    "text": "like with some focused work um and this could enable like all sorts of like new forms of creativity",
    "start": "2429599",
    "end": "2435760"
  },
  {
    "text": "that people didn't even know about um while language understanding",
    "start": "2435760",
    "end": "2440800"
  },
  {
    "start": "2438000",
    "end": "2494000"
  },
  {
    "text": "does quite well there's um deeper language understanding which we can kind of solve in toy tasks but it's kind of",
    "start": "2440800",
    "end": "2448079"
  },
  {
    "text": "harder for real tasks so QA so C question answering that requires more",
    "start": "2448079",
    "end": "2453200"
  },
  {
    "text": "complicated reasoning such that if you have like a story here and you ask something question complicated like",
    "start": "2453200",
    "end": "2458560"
  },
  {
    "text": "where is the football and you have to like go back in the story and figure out where that kind of thing happened that",
    "start": "2458560",
    "end": "2463599"
  },
  {
    "text": "thing's kind of complicated um people are very good at this task um models um",
    "start": "2463599",
    "end": "2469000"
  },
  {
    "text": "can solve these simple ones quite well but they can't real do real question answering yet which is unfortunate but",
    "start": "2469000",
    "end": "2475319"
  },
  {
    "text": "it's something people really care about and we're not quite there yet but I also love how awesome this problem sounds is",
    "start": "2475319",
    "end": "2482119"
  },
  {
    "text": "that like our machines that we have like basically spent no work on only",
    "start": "2482119",
    "end": "2487440"
  },
  {
    "text": "automatically learn a shallow level of reasoning like that's like such a first world",
    "start": "2487440",
    "end": "2492839"
  },
  {
    "text": "problem um while there's like language understanding there's also visual understanding that is um kind of",
    "start": "2492839",
    "end": "2499560"
  },
  {
    "start": "2494000",
    "end": "2526000"
  },
  {
    "text": "Unsolved there's um there's there some awesome data set that involves images and questions and the goal is to find an",
    "start": "2499560",
    "end": "2506640"
  },
  {
    "text": "answer and the models that there are models that can do pretty okay at this task but still very not good and still",
    "start": "2506640",
    "end": "2515520"
  },
  {
    "text": "um like very significantly worse than people do so this kind of thing is something that we we um can't do just",
    "start": "2515520",
    "end": "2524480"
  },
  {
    "text": "yet while game playing is solved harder gam playing is still an open problem and",
    "start": "2524480",
    "end": "2530760"
  },
  {
    "start": "2526000",
    "end": "2574000"
  },
  {
    "text": "you might think harder gam playing my 5-year-old brother can play Minecraft and he almost certainly can't beat a",
    "start": "2530760",
    "end": "2537040"
  },
  {
    "text": "world champion at go and harder in this case means stateful it turns out that",
    "start": "2537040",
    "end": "2542839"
  },
  {
    "text": "humans are really good at remembering something while neural networks have some difficulty with it so uh the neural",
    "start": "2542839",
    "end": "2549800"
  },
  {
    "text": "networks that people have been using for playing games have been completely stateless so when you have a partially",
    "start": "2549800",
    "end": "2555000"
  },
  {
    "text": "observed world like Minecraft where you like only have one direction that you're looking at if you like look to the left it forgets what was on the right and",
    "start": "2555000",
    "end": "2561359"
  },
  {
    "text": "this is something that people are still working to solve it's the same thing with doom and um work has been done at",
    "start": "2561359",
    "end": "2567319"
  },
  {
    "text": "that but it's far from being a solved problem and I do believe that they're still subhuman at this",
    "start": "2567319",
    "end": "2573960"
  },
  {
    "text": "task there's some really cool stuff with automatically discovering hierarchical structure so in language the",
    "start": "2573960",
    "end": "2581040"
  },
  {
    "start": "2574000",
    "end": "2627000"
  },
  {
    "text": "hierarchical structure is maybe clear to us because we use language like character words are made of character",
    "start": "2581040",
    "end": "2586400"
  },
  {
    "text": "sentences are made of words paragraphs are made of sentences um this is like there's this semantic hierarchy which",
    "start": "2586400",
    "end": "2591599"
  },
  {
    "text": "makes it easy to break down a problem into simpler problems um but this is not the case in many domains and there have",
    "start": "2591599",
    "end": "2599160"
  },
  {
    "text": "been people who've designed neural networks that can actually automatically discover this hierarchy and this could be really useful for tasks where we",
    "start": "2599160",
    "end": "2605720"
  },
  {
    "text": "don't know how to interpr that so something I've worked a bit on is genomics and we really don't even know",
    "start": "2605720",
    "end": "2611680"
  },
  {
    "text": "how to read genomics right but if a neural network can automatically break it up into like this part goes together with that part um you know there's",
    "start": "2611680",
    "end": "2618119"
  },
  {
    "text": "connections between here and here this could actually help a whole lot with all sorts of different kinds of scientific",
    "start": "2618119",
    "end": "2623960"
  },
  {
    "text": "tasks just purely from data um this is when it gets a little bit computery but these are things that",
    "start": "2623960",
    "end": "2630079"
  },
  {
    "start": "2627000",
    "end": "2646000"
  },
  {
    "text": "I'm excited as as a computer scientist um there's this model called neural turning machines which learns to use",
    "start": "2630079",
    "end": "2636240"
  },
  {
    "text": "like a big memory buffer which is very cool so you can actually see like how the network reads writes and reads in",
    "start": "2636240",
    "end": "2642079"
  },
  {
    "text": "order to copy an input um there's ways to implement",
    "start": "2642079",
    "end": "2647119"
  },
  {
    "start": "2646000",
    "end": "2673000"
  },
  {
    "text": "differentiable data structures so things that you thought were instead of having like this black",
    "start": "2647119",
    "end": "2653680"
  },
  {
    "text": "box of like arbitrary um activations with Matrix multiplies you can actually plug in a data structure into a network",
    "start": "2653680",
    "end": "2660000"
  },
  {
    "text": "and now your network can learn to do things like pushing and popping to a stack you know getting from both ends of a queue and all of these kinds of things",
    "start": "2660000",
    "end": "2667680"
  },
  {
    "text": "um and this could potentially enable all sorts of very cool use cases such as learning to program U people have done",
    "start": "2667680",
    "end": "2674800"
  },
  {
    "start": "2673000",
    "end": "2702000"
  },
  {
    "text": "some work where you can create models that not only can like have simple input",
    "start": "2674800",
    "end": "2680280"
  },
  {
    "text": "output mappings but as an intermediate in this input output mapping they can learn sub routines and play with",
    "start": "2680280",
    "end": "2686079"
  },
  {
    "text": "pointers and this actually makes them a very very general computing um like it",
    "start": "2686079",
    "end": "2691240"
  },
  {
    "text": "potentially could do all of the problems we care about if you can learn sub routines and play with pointers cuz like",
    "start": "2691240",
    "end": "2697079"
  },
  {
    "text": "that could learn abstraction automatically for you and by putting these things together people have been",
    "start": "2697079",
    "end": "2702680"
  },
  {
    "start": "2702000",
    "end": "2737000"
  },
  {
    "text": "able to do things like learning to actually execute code so the idea would be given like code as a string and",
    "start": "2702680",
    "end": "2710359"
  },
  {
    "text": "targets for that code like what the output is you can actually learn an interpreter for that language and this",
    "start": "2710359",
    "end": "2716440"
  },
  {
    "text": "is really exciting to me as a programming language guy like maybe I could design a programming language not by implementing it but by just showing a",
    "start": "2716440",
    "end": "2723640"
  },
  {
    "text": "whole bunch of examples and the implementation automatically happen for me or perhaps I could just write the",
    "start": "2723640",
    "end": "2728760"
  },
  {
    "text": "test cases for the language and inal network can generate an efficient language for",
    "start": "2728760",
    "end": "2734319"
  },
  {
    "text": "me um and something else that is related to all of this stuff is this is really",
    "start": "2734319",
    "end": "2740800"
  },
  {
    "start": "2737000",
    "end": "2789000"
  },
  {
    "text": "early but I think a lot of people are really excited about that um which are neural module networks where instead of",
    "start": "2740800",
    "end": "2746440"
  },
  {
    "text": "having a single architecture that you play with you can have architectures that are you can have a",
    "start": "2746440",
    "end": "2754000"
  },
  {
    "text": "library of components and that for every single example you make a custom architecture and you output it so for",
    "start": "2754000",
    "end": "2760960"
  },
  {
    "text": "example if you have the question answering task and you have an image and you have a question where is the dog",
    "start": "2760960",
    "end": "2766240"
  },
  {
    "text": "instead of using an arbitrary Network that takes in the question and the answer you actually convert this",
    "start": "2766240",
    "end": "2772079"
  },
  {
    "text": "question into a custom neural network which combines a dog module with a wear",
    "start": "2772079",
    "end": "2777280"
  },
  {
    "text": "module and outputs the answer and this kind of thing is very early but really",
    "start": "2777280",
    "end": "2785680"
  },
  {
    "text": "promising so so um that that's it for the future of it I hopefully you guys",
    "start": "2785680",
    "end": "2790720"
  },
  {
    "start": "2789000",
    "end": "3051000"
  },
  {
    "text": "are pumped to deep learning some problems um there's a lot of software to help you um I'm not going to talk about",
    "start": "2790720",
    "end": "2796920"
  },
  {
    "text": "that right now because there's a lot of tutorials out there and I think the high level understanding is much more important um my recommendation is that",
    "start": "2796920",
    "end": "2803760"
  },
  {
    "text": "if you want to customize a lot of things then theano and tensor flow are the best because it allows you to get this",
    "start": "2803760",
    "end": "2809319"
  },
  {
    "text": "automatic differentiation that I was talking about then you never have to worry about the backwards path basically and if you want to just use like the",
    "start": "2809319",
    "end": "2816880"
  },
  {
    "text": "modules that I talked about as well as a few others uh Caris can solve that and you can do a lot of these things with",
    "start": "2816880",
    "end": "2822000"
  },
  {
    "text": "Caris um if you want to do this there's a lot more learning to do and the",
    "start": "2822000",
    "end": "2827480"
  },
  {
    "text": "devil's really in the detail so I was super high level with lots of this stuff um but all like there's so many little",
    "start": "2827480",
    "end": "2833400"
  },
  {
    "text": "things that you need to know such as how do you take how do you perform the updates in a way that doesn't cause your",
    "start": "2833400",
    "end": "2839440"
  },
  {
    "text": "parameters to grow too large um how do you initialize the parameters to not be a trivial function um how do you not",
    "start": "2839440",
    "end": "2846119"
  },
  {
    "text": "overfit your train set so there's a lot of resources out there um my favorite",
    "start": "2846119",
    "end": "2851359"
  },
  {
    "text": "one is the Stanford class by Andre karpathy cs231n it is specifically on conet but",
    "start": "2851359",
    "end": "2859280"
  },
  {
    "text": "it's constantly updated with state-of-the-art stuff and it's generally very high quality so I think",
    "start": "2859280",
    "end": "2864640"
  },
  {
    "text": "it's very approachable for anyone like beginner to very Advanced and if you want to do this you",
    "start": "2864640",
    "end": "2871040"
  },
  {
    "text": "probably need a GPU or 50 uh I think that's it for time so sorry I was",
    "start": "2871040",
    "end": "2877559"
  },
  {
    "text": "rushing at the end but any questions also I have these slides which slide should I leave it on there are some",
    "start": "2877559",
    "end": "2884200"
  },
  {
    "text": "questions here cool um so one is how can we avoid uh that autonomous cars pick up",
    "start": "2884200",
    "end": "2891640"
  },
  {
    "text": "U human bad habits how can we avoid that autonomous cars pick up human bad habits",
    "start": "2891640",
    "end": "2897040"
  },
  {
    "text": "that is a very interesting question it's very dependent on how the cars are trained so if you train a car to copy",
    "start": "2897040",
    "end": "2904079"
  },
  {
    "text": "the human bad habits so if you train a car to copy humans which is by far the easiest thing to do um it's not the most",
    "start": "2904079",
    "end": "2910760"
  },
  {
    "text": "correct thing to do um because the most correct thing to do would be to learn how to drive optimally from scratch that",
    "start": "2910760",
    "end": "2917720"
  },
  {
    "text": "unfortunately involves trial and error but um You probably don't want that in self-driving car so we can skip that or",
    "start": "2917720",
    "end": "2923160"
  },
  {
    "text": "hard-coded rules um so what can tend to happen is if you're training it to learn",
    "start": "2923160",
    "end": "2929160"
  },
  {
    "text": "from humans it'll mimic those humans but the idea is that if humans make mistakes",
    "start": "2929160",
    "end": "2934559"
  },
  {
    "text": "um you like let's hope let's say humans mistakes and let's say humans don't make consistent mistakes if they don't make",
    "start": "2934559",
    "end": "2940839"
  },
  {
    "text": "consistent mistakes and different humans make different kinds of mistakes or the same human like only makes makes the mistakes sometimes and you have a neural",
    "start": "2940839",
    "end": "2947480"
  },
  {
    "text": "network that neural network can predict the expectation of what the human can do rather than the worst case scenario so",
    "start": "2947480",
    "end": "2954640"
  },
  {
    "text": "if you're kind you can think of humans as an ensemble in this case that if you're predicting what the average of a bunch of humans can do you can drive",
    "start": "2954640",
    "end": "2960799"
  },
  {
    "text": "better than a human can but if humans are consistently make if humans consistently make mistakes then there's",
    "start": "2960799",
    "end": "2966799"
  },
  {
    "text": "nothing you can do about that other than get more data okay I think we have time for one",
    "start": "2966799",
    "end": "2972640"
  },
  {
    "text": "more what do you think about chatbots is it possible to build only with deep learning yes there's actually many",
    "start": "2972640",
    "end": "2978960"
  },
  {
    "text": "startups that are doing this right now so this seems to be the um next wave in",
    "start": "2978960",
    "end": "2984960"
  },
  {
    "text": "startups or like the hot thing right now where people are trying to use chatbots",
    "start": "2984960",
    "end": "2990319"
  },
  {
    "text": "to do all sorts of things for like very spe specific domains it has some really nice properties from a business point of",
    "start": "2990319",
    "end": "2997040"
  },
  {
    "text": "view because um your goal is to replace humans who chat so it's very easy to",
    "start": "2997040",
    "end": "3003440"
  },
  {
    "text": "like replace them with an algorithm because the humans when you have if you have a bunch of them they generate a bunch of data so it is very plausible",
    "start": "3003440",
    "end": "3010280"
  },
  {
    "text": "it's still hard for chatbots it's kind of like the gameplaying problem where it's hard for chat Bots to have a memory",
    "start": "3010280",
    "end": "3016880"
  },
  {
    "text": "of what you said so if you talk about like oh try you know opening this menu and you know go here and here and here",
    "start": "3016880",
    "end": "3023640"
  },
  {
    "text": "and you could like might have five sentences later the chat bot might say the same thing because the neurs still",
    "start": "3023640",
    "end": "3029160"
  },
  {
    "text": "have memory issues cool okay I think that's it uh so",
    "start": "3029160",
    "end": "3034520"
  },
  {
    "text": "please remember to vote and uh let's give a big Applause to [Applause]",
    "start": "3034520",
    "end": "3042760"
  },
  {
    "text": "Theo um thank you",
    "start": "3042760",
    "end": "3047160"
  }
]
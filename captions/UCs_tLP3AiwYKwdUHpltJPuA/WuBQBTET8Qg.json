[
  {
    "text": "[Music]",
    "start": "2550",
    "end": "10419"
  },
  {
    "text": "thanks hello is this work okay post lunch talk I know how",
    "start": "11799",
    "end": "17439"
  },
  {
    "text": "that works thanks Katie okay hi everyone I'm Nan AR I'm",
    "start": "17439",
    "end": "23240"
  },
  {
    "text": "the uh co-founder CTO at confluent one of the creators of Kafka and this talk",
    "start": "23240",
    "end": "29160"
  },
  {
    "text": "is about applications or microservices though I specifically avoided using that",
    "start": "29160",
    "end": "34800"
  },
  {
    "text": "word uh in the world of stream processing um this is uh important because um unbounded unordered large",
    "start": "34800",
    "end": "43360"
  },
  {
    "text": "scale data sets are increasingly common today whether it is mobile usage",
    "start": "43360",
    "end": "48680"
  },
  {
    "text": "statistics or sensor networks or merely web blog data stream data is everywhere",
    "start": "48680",
    "end": "55039"
  },
  {
    "text": "and there's a huge push towards getting faster results but for long time would I've",
    "start": "55039",
    "end": "60680"
  },
  {
    "text": "observed is stream processing is um you know sort of construed as something that",
    "start": "60680",
    "end": "66200"
  },
  {
    "text": "is only a faster map produced layer something that is way closer to your hopes and your data warehouses something",
    "start": "66200",
    "end": "73759"
  },
  {
    "text": "that requires a whole cluster to run and um you know specifically for Niche problems like faster machine learning or",
    "start": "73759",
    "end": "81240"
  },
  {
    "text": "faster analytics uh but in my experience of working in this area for the last 5 to six years what I've learned is uh it",
    "start": "81240",
    "end": "88640"
  },
  {
    "text": "actually impacts uh a big area of the company essentially uh the company's business logic and applications that in",
    "start": "88640",
    "end": "95960"
  },
  {
    "text": "fact uh can leverage stream processing and uh that is what this talk is about",
    "start": "95960",
    "end": "101439"
  },
  {
    "text": "and where Kafka and Kafka stream which is uh kafka's newest stream processing",
    "start": "101439",
    "end": "107119"
  },
  {
    "text": "layer comes in okay so um without further Ado let's get started first off uh you know let's",
    "start": "107119",
    "end": "114360"
  },
  {
    "text": "start by answering this question stream processing uh is this buzzword today uh there are many ways of defining it uh",
    "start": "114360",
    "end": "121439"
  },
  {
    "text": "but today I'm going to use a very uh specific way which is that it is merely a a programming Paradigm for processing",
    "start": "121439",
    "end": "129039"
  },
  {
    "text": "uh unbounded data sets now if you look at programming paradigms there are various ways of chopping this pie but",
    "start": "129039",
    "end": "136080"
  },
  {
    "text": "here I'm going to use uh a specific way which is the way an application gets its",
    "start": "136080",
    "end": "141319"
  },
  {
    "text": "input and the way it produces its output and if you look at this input output IO",
    "start": "141319",
    "end": "147480"
  },
  {
    "text": "Dimension then there are three paradigms for programming one is request response uh there are bad systems and then we'll",
    "start": "147480",
    "end": "154319"
  },
  {
    "text": "come to stream processing so request response are are really simple we're used to these systems these are our RPC",
    "start": "154319",
    "end": "160920"
  },
  {
    "text": "applications you send one input in to your service and then you wait for one output back and the only way of scaling",
    "start": "160920",
    "end": "168519"
  },
  {
    "text": "the services by deploying more instances of it uh the properties of request response systems are that um the it's",
    "start": "168519",
    "end": "175760"
  },
  {
    "text": "tightly coupled it's latency sensitive and uh you want to scale It Out by deploying more instances now on the very",
    "start": "175760",
    "end": "183560"
  },
  {
    "text": "end of the other end of the spectrum are bat systems here you send all your input",
    "start": "183560",
    "end": "189840"
  },
  {
    "text": "in you wait for systems to Crunch all that data and then they send all their",
    "start": "189840",
    "end": "194920"
  },
  {
    "text": "output back and the big difference from request response systems is this looser",
    "start": "194920",
    "end": "201080"
  },
  {
    "text": "coupling and expectation around latency uh typically these systems get",
    "start": "201080",
    "end": "206640"
  },
  {
    "text": "maybe hours to run or sometimes days um and the the thing to note about bat",
    "start": "206640",
    "end": "212720"
  },
  {
    "text": "systems is that they assume that data is bounded in nature you know when you know you know how to define what all means",
    "start": "212720",
    "end": "219439"
  },
  {
    "text": "here okay so uh then coming to stream processing systems here you send uh some",
    "start": "219439",
    "end": "225959"
  },
  {
    "text": "input in and uh you get some output back and the definition of some is left to",
    "start": "225959",
    "end": "232920"
  },
  {
    "text": "the program uh it could mean one input or it could mean all your inputs uh the",
    "start": "232920",
    "end": "238799"
  },
  {
    "text": "the output is available at various times too um you might get one output item for",
    "start": "238799",
    "end": "244120"
  },
  {
    "text": "every input item or one output item for every n input items uh it is really a",
    "start": "244120",
    "end": "250760"
  },
  {
    "text": "generalization of the previous two extremes that we saw the thing to note is that stream processing it assumes",
    "start": "250760",
    "end": "257479"
  },
  {
    "text": "that data is unbounded in nature it is never ending and so it's designed around",
    "start": "257479",
    "end": "263320"
  },
  {
    "text": "that now um for a long time you know stream processing um is misconstrued as",
    "start": "263320",
    "end": "268960"
  },
  {
    "text": "something that might be transient or lossy or",
    "start": "268960",
    "end": "274000"
  },
  {
    "text": "approximate uh some systems have been that way but uh my claim is that those are uh essentially drawbacks of the way",
    "start": "274000",
    "end": "281600"
  },
  {
    "text": "those specific systems were designed but it is not uh an inherent property of the",
    "start": "281600",
    "end": "287000"
  },
  {
    "text": "stream processing Paradigm in fact stream processing systems can absolutely be made to uh generate a perfect results",
    "start": "287000",
    "end": "294639"
  },
  {
    "text": "um just like bat systems do as well as do that efficiently uh so the reason there is",
    "start": "294639",
    "end": "300320"
  },
  {
    "text": "this um you know conflation of problems with stream processing is because uh when you process unbounded data sets",
    "start": "300320",
    "end": "307240"
  },
  {
    "text": "there are various uh tricky trade-offs involved and those are around latency",
    "start": "307240",
    "end": "312919"
  },
  {
    "text": "cost and correctness and often times systems are",
    "start": "312919",
    "end": "318440"
  },
  {
    "text": "specifically designed to optimize along some of these Dimensions versus giving the user the flexibility to pick the",
    "start": "318440",
    "end": "326880"
  },
  {
    "text": "trade-offs that are correct or right for their application and this matters a lot because one size",
    "start": "326880",
    "end": "333120"
  },
  {
    "text": "does not fit all here uh some applications might care about correctness like billing while some may",
    "start": "333120",
    "end": "339919"
  },
  {
    "text": "not like log processing some might care about latency like alerts while some may",
    "start": "339919",
    "end": "346639"
  },
  {
    "text": "not like ETL while some applications actually may not be okay with paying the",
    "start": "346639",
    "end": "352360"
  },
  {
    "text": "cost for fully optimizing along the other two Dimensions so this flexibility",
    "start": "352360",
    "end": "357759"
  },
  {
    "text": "is uh is important while designing uh good stream processing systems uh this talk is about you know stream processing",
    "start": "357759",
    "end": "365000"
  },
  {
    "text": "for application development uh what I'm interested in exploring is how the entire company's business logic can be",
    "start": "365000",
    "end": "372759"
  },
  {
    "text": "designed as stream processing applications and what might be required if we were to do that so throughout this",
    "start": "372759",
    "end": "379639"
  },
  {
    "text": "talk I'm going to work through this example this example is from a brick and mortar retail uh you know company or",
    "start": "379639",
    "end": "387800"
  },
  {
    "text": "industry here you know for retail companies there are two inputs that are relevant or important uh at the very",
    "start": "387800",
    "end": "394319"
  },
  {
    "text": "least and these are sales of things and uh shipments of things and for healthy",
    "start": "394319",
    "end": "400319"
  },
  {
    "text": "businesses these two things are never ending hopefully and so these are essentially um streams of inputs they",
    "start": "400319",
    "end": "408080"
  },
  {
    "text": "are unbounded they never end while if you if you see that you know these two inputs are useful for a",
    "start": "408080",
    "end": "415520"
  },
  {
    "text": "whole set of applications Downstream you might send it to your Hadoop or your",
    "start": "415520",
    "end": "421080"
  },
  {
    "text": "warehouse for analytics you might send it to some kind of fraud detection system or you might index it into a",
    "start": "421080",
    "end": "428120"
  },
  {
    "text": "search system that can po the search feature through your inventory and then there are um two",
    "start": "428120",
    "end": "434400"
  },
  {
    "text": "kinds of processing that should happen continuously but for several of these",
    "start": "434400",
    "end": "439479"
  },
  {
    "text": "companies today it might not be designed that way and those are uh price adjustments and inventory adjustments",
    "start": "439479",
    "end": "446639"
  },
  {
    "text": "this is essentially what Amazon does a great job of which is they have a totally real-time view of what is being",
    "start": "446639",
    "end": "452960"
  },
  {
    "text": "sold what is in demand and uh they have this capability of doing both sort of",
    "start": "452960",
    "end": "459039"
  },
  {
    "text": "adjustments and price adjustments to take advantage of that demand and so uh this is essentially what is um what",
    "start": "459039",
    "end": "465720"
  },
  {
    "text": "falls in the Stream processing bucket however may not be designed that way today so we'll take a look at that um if",
    "start": "465720",
    "end": "472240"
  },
  {
    "text": "you look at this uh picture a little differently at the top are things that fall in the you know what happened category these are events that are",
    "start": "472240",
    "end": "479120"
  },
  {
    "text": "interesting to this business and everything else is essentially a response to that event so",
    "start": "479120",
    "end": "486599"
  },
  {
    "text": "as a response you might send it to your Warehouse or or search uh you know index it in a search system or might process",
    "start": "486599",
    "end": "492800"
  },
  {
    "text": "it using some kind of a processor um now taking a step back if",
    "start": "492800",
    "end": "499599"
  },
  {
    "text": "this whole thing was designed as one large uh monolithic application then what I'm going to say is it doesn't",
    "start": "499599",
    "end": "506159"
  },
  {
    "text": "really matter but in reality applications are not designed that way uh you typically have several Services",
    "start": "506159",
    "end": "512399"
  },
  {
    "text": "each service has you know some uh responsibility that it does and so when",
    "start": "512399",
    "end": "517880"
  },
  {
    "text": "you have you know several applications that need to interact with each other you essentially have a couple of choices",
    "start": "517880",
    "end": "523919"
  },
  {
    "text": "right if you don't have a way to buffer these input streams then what you're",
    "start": "523919",
    "end": "528959"
  },
  {
    "text": "left with is you know the need to tightly couple all these Downstream",
    "start": "528959",
    "end": "534000"
  },
  {
    "text": "services with the services that generate these rights and if you do that then it has all the downsides of tight coupling",
    "start": "534000",
    "end": "540959"
  },
  {
    "text": "which is cascading failures or sensitivity to Performance issues if on",
    "start": "540959",
    "end": "546399"
  },
  {
    "text": "the other hand if you had a log or a queue like Kafka at the center which could buffer your streams of inputs then",
    "start": "546399",
    "end": "554600"
  },
  {
    "text": "it allows you the flexibility of decoupling all the downstream services so that they're not tightly coupled you",
    "start": "554600",
    "end": "560839"
  },
  {
    "text": "end up with a much more resilient architecture and more importantly what we're going to look into is it allows",
    "start": "560839",
    "end": "566560"
  },
  {
    "text": "you to do stream processing some of these uh some of these actions that should uh actually be continuous actions",
    "start": "566560",
    "end": "573040"
  },
  {
    "text": "or processing can happen if you have uh kaf buffer all this",
    "start": "573040",
    "end": "578200"
  },
  {
    "text": "data okay so uh stream processing you know tying that back um to uh this",
    "start": "578200",
    "end": "584040"
  },
  {
    "text": "conversation this is it's actually just a bunch of functions or actions uh on top of this what happen sort of event",
    "start": "584040",
    "end": "590760"
  },
  {
    "text": "data and because Kafka has um emerged to be a sort of a def facto system for",
    "start": "590760",
    "end": "596959"
  },
  {
    "text": "storing event data it essentially boils down into writing functions on top of",
    "start": "596959",
    "end": "603120"
  },
  {
    "text": "Kafka topics or Kafka streams so um you know Kafka has been there for a while it",
    "start": "603120",
    "end": "608279"
  },
  {
    "text": "has been around for 5 years it's used across thousands of companies so over the F past five years a couple of stream",
    "start": "608279",
    "end": "615560"
  },
  {
    "text": "processing approaches have emerged over time um the first one is really what I",
    "start": "615560",
    "end": "620640"
  },
  {
    "text": "call uh do- it yourself stream processing here what people do is they use the basic Kafka libraries and they",
    "start": "620640",
    "end": "627600"
  },
  {
    "text": "build stream processing logic and code themselves in their application and if you did that then",
    "start": "627600",
    "end": "633640"
  },
  {
    "text": "there are a couple of problems um related to stream processing that you should know you would have to deal with",
    "start": "633640",
    "end": "640279"
  },
  {
    "text": "those are you know ensuring that your data arrives and gets processed in order uh ensuring that you can do that",
    "start": "640279",
    "end": "647360"
  },
  {
    "text": "while uh you know horizontally scaling your application out uh fault tolerance",
    "start": "647360",
    "end": "653320"
  },
  {
    "text": "so ensuring that you have all the guarantees as machines and processes fail uh State Management some uh",
    "start": "653320",
    "end": "660440"
  },
  {
    "text": "operations in stream processing like joins and windowed Aggregates it requires maintaining state so uh what",
    "start": "660440",
    "end": "666920"
  },
  {
    "text": "happens to State Management uh reprocessing so the ability to you know",
    "start": "666920",
    "end": "672200"
  },
  {
    "text": "upgrade your application or fix bugs in your application that essentially requires you go back in time and",
    "start": "672200",
    "end": "678000"
  },
  {
    "text": "reprocess past results and finally uh last but not the least the idea of time",
    "start": "678000",
    "end": "684519"
  },
  {
    "text": "uh the uh correctness in stream processing is closely tied to correct treat M of time and I'll talk about each",
    "start": "684519",
    "end": "691480"
  },
  {
    "text": "one of these problems and how Kafka stream solves these uh so the other approach is um you know instead of doing",
    "start": "691480",
    "end": "698480"
  },
  {
    "text": "it yourself you use one of the many um stream processing Frameworks that are out there spark has a streaming module",
    "start": "698480",
    "end": "704760"
  },
  {
    "text": "which is quite cool um there is Storm uh samza which some of us built at LinkedIn",
    "start": "704760",
    "end": "710560"
  },
  {
    "text": "there's also an emerging system called Flink which is uh which works really great um the thing to note about these",
    "start": "710560",
    "end": "716639"
  },
  {
    "text": "systems is that um you know they share a certain um sort of map produce Heritage",
    "start": "716639",
    "end": "722680"
  },
  {
    "text": "the idea of making a faster map produce layer uh and this works actually uh",
    "start": "722680",
    "end": "728680"
  },
  {
    "text": "pretty well for some subset of problems uh there is a ton of innovation happening in this space there are you",
    "start": "728680",
    "end": "735560"
  },
  {
    "text": "know because of this map produce Heritage there are some traits that these systems share uh including the one",
    "start": "735560",
    "end": "742240"
  },
  {
    "text": "we built at linkton which is called samza and those traits are that you know typically there is a custom way of",
    "start": "742240",
    "end": "747760"
  },
  {
    "text": "configuring your processing code which is uh the properties of a job that runs",
    "start": "747760",
    "end": "752880"
  },
  {
    "text": "on a cluster uh that that stream processing Frameworks operates then",
    "start": "752880",
    "end": "758040"
  },
  {
    "text": "there is a custom way to package and deploy your code much like a map ruce",
    "start": "758040",
    "end": "763120"
  },
  {
    "text": "job there is the whole uh sort of problem of resource management mapping",
    "start": "763120",
    "end": "768440"
  },
  {
    "text": "processes to machines and there are tons of solutions for that today uh this",
    "start": "768440",
    "end": "773800"
  },
  {
    "text": "works actually pretty well for uh you know things like um you know code that already runs in dup that needs to run",
    "start": "773800",
    "end": "780440"
  },
  {
    "text": "faster uh long running queries uh like you know machine learning or long",
    "start": "780440",
    "end": "786480"
  },
  {
    "text": "running uh analytics kinds of queries that works pretty well on these kind of systems uh what we wanted to do is you",
    "start": "786480",
    "end": "793320"
  },
  {
    "text": "know uh take a step back and look at um stream processing for application development and if you look at that then",
    "start": "793320",
    "end": "799320"
  },
  {
    "text": "there are um a subset of problems when it comes to these traits the first one is that uh for config management and",
    "start": "799320",
    "end": "807000"
  },
  {
    "text": "packaging alone there are a whole Loop of tools right there's Docker and Chef and puppet and salt and that that's a",
    "start": "807000",
    "end": "813800"
  },
  {
    "text": "long list uh for resource management as well there are lots and lots of tools um",
    "start": "813800",
    "end": "818839"
  },
  {
    "text": "mesos which is what the other talk is about uh there's kubernetes and that whole ecosystem is exciting and is",
    "start": "818839",
    "end": "825079"
  },
  {
    "text": "moving along and so uh if you think about what it will take for application",
    "start": "825079",
    "end": "830279"
  },
  {
    "text": "developers to use stream processing Primitives uh a you would have to make sure that it has fewer external",
    "start": "830279",
    "end": "836920"
  },
  {
    "text": "dependencies it is lightweight it can be embedded in applications and the second thing is that uh you want to allow",
    "start": "836920",
    "end": "843320"
  },
  {
    "text": "developers to use the tools of their choice for config management for application uh packaging for deployment",
    "start": "843320",
    "end": "850880"
  },
  {
    "text": "and so we thought that you know uh if you come back and um look at this problem designing this as a library is",
    "start": "850880",
    "end": "856920"
  },
  {
    "text": "essentially the the right way to go if you want to approach uh application development and so that is exactly what",
    "start": "856920",
    "end": "863160"
  },
  {
    "text": "Kafka streams is it is a Java library that is built on top of Kafka and the",
    "start": "863160",
    "end": "868399"
  },
  {
    "text": "reason it is built on top of Kafka is because Kafka provides foundational Primitives which are required for stream",
    "start": "868399",
    "end": "875160"
  },
  {
    "text": "processing and we look uh we look into what that means so cka streams has uh essentially",
    "start": "875160",
    "end": "881680"
  },
  {
    "text": "two interfaces one is a processor call back API and the other is a high level",
    "start": "881680",
    "end": "887240"
  },
  {
    "text": "DSL and both are Java at the moment so looking at the processor API just to",
    "start": "887240",
    "end": "892800"
  },
  {
    "text": "take an example it's pretty simple you get a key and a value which is essent essentially a message in Kafka you",
    "start": "892800",
    "end": "899519"
  },
  {
    "text": "process it that might be your code and while processing it you might update some State uh we're going to talk about",
    "start": "899519",
    "end": "905720"
  },
  {
    "text": "that later and then you might send that message out in some sense this encapsulates the entire you know scope",
    "start": "905720",
    "end": "912440"
  },
  {
    "text": "of stream processing you have input streams you have some processing code and then you have output streams and",
    "start": "912440",
    "end": "919000"
  },
  {
    "text": "this is the code that you write to build one of your processors you you ask um you configure it to tell it where to",
    "start": "919000",
    "end": "925519"
  },
  {
    "text": "connect to Kafka you write your processor class and then you just say start and you can",
    "start": "925519",
    "end": "932120"
  },
  {
    "text": "take this code and either run it on one instance or one process or you can take it and run on multiple processes Kafka",
    "start": "932120",
    "end": "939120"
  },
  {
    "text": "streams manages uh the load balancing uh of the data now the second API is this might be",
    "start": "939120",
    "end": "946720"
  },
  {
    "text": "hard to read is the high Lev DSL this is a simple application that does word count um you know this is essentially",
    "start": "946720",
    "end": "954000"
  },
  {
    "text": "the the set of apis that it provides are the ones that you might expect filter Jo Jo uh window aggregate um and and so on",
    "start": "954000",
    "end": "963120"
  },
  {
    "text": "and so forth now whether you use this explicit processor API or you use the",
    "start": "963120",
    "end": "969839"
  },
  {
    "text": "DSL internally what stream processing operators typically form are",
    "start": "969839",
    "end": "975160"
  },
  {
    "text": "topologies and um you know you you with Kafka streams you don't have to worry about how this topology maps to",
    "start": "975160",
    "end": "982519"
  },
  {
    "text": "processes uh kafa streams takes care of assigning the partitions that your",
    "start": "982519",
    "end": "988079"
  },
  {
    "text": "topology needs evenly amongst all the instances of your application what happens is this topology is just",
    "start": "988079",
    "end": "994519"
  },
  {
    "text": "embedded in your application it's almost some a detail that you uh don't know about so coming back to uh the problems",
    "start": "994519",
    "end": "1002839"
  },
  {
    "text": "of stream processing and how kafa provides Primitives and how Kafka streams leverages those Primitives let's",
    "start": "1002839",
    "end": "1009480"
  },
  {
    "text": "take a look at each one of these and see what it actually means uh first off ordering uh for those of you who might",
    "start": "1009480",
    "end": "1015920"
  },
  {
    "text": "be um familiar with Kafka this abstraction might look familiar this is the key abstraction that Kafka provides",
    "start": "1015920",
    "end": "1022959"
  },
  {
    "text": "which is a log and um it is really nothing but an ordered or a structured",
    "start": "1022959",
    "end": "1028558"
  },
  {
    "text": "array of messages so data is completely ordered um it is immutable so once data",
    "start": "1028559",
    "end": "1034720"
  },
  {
    "text": "is written it never changes and every record can be identified using a unique",
    "start": "1034720",
    "end": "1040880"
  },
  {
    "text": "index or a sequence number in Kafka this is called an offset so essentially this",
    "start": "1040880",
    "end": "1046319"
  },
  {
    "text": "uh you know abstraction it makes sure that data is both written as well as read in order and this is what provides",
    "start": "1046319",
    "end": "1053720"
  },
  {
    "text": "the ordering abstraction in Kafka which is also used by Kafka streams so coming",
    "start": "1053720",
    "end": "1058880"
  },
  {
    "text": "back to you know partitioning and scalability that is The Logical view of the log physically if you wanted to",
    "start": "1058880",
    "end": "1065440"
  },
  {
    "text": "scale this log out you Shard it into multiple partitions and if you did that then that is exactly the back end of",
    "start": "1065440",
    "end": "1072000"
  },
  {
    "text": "aache Kafka where a log is a topic it's a logical thing and physically um the",
    "start": "1072000",
    "end": "1079080"
  },
  {
    "text": "topic lives in partitions that are deployed on Brokers as messages come in they're appended to one of the",
    "start": "1079080",
    "end": "1084919"
  },
  {
    "text": "partitions log and there's some sort of policy for maintaining a fixed window of the logs you don't run out of space it",
    "start": "1084919",
    "end": "1091159"
  },
  {
    "text": "could be based on time or it could be based on size or uh a special compaction",
    "start": "1091159",
    "end": "1096760"
  },
  {
    "text": "policy called law compaction which we're going to talk about later okay so you",
    "start": "1096760",
    "end": "1102120"
  },
  {
    "text": "know part of um the problem with Partition like scalability is you know data parallelism which is what we looked",
    "start": "1102120",
    "end": "1108440"
  },
  {
    "text": "into which is how do you Shard your data but then part of it is processing parallelism which is how do you now",
    "start": "1108440",
    "end": "1114480"
  },
  {
    "text": "process across a distributed set of machines and processes um for that Kafka has a",
    "start": "1114480",
    "end": "1121080"
  },
  {
    "text": "primitive called group management which allows a group of processes essentially your application to subscribe to a",
    "start": "1121080",
    "end": "1127960"
  },
  {
    "text": "partition resource called the topic while kaf transparently handles the load",
    "start": "1127960",
    "end": "1133559"
  },
  {
    "text": "balancing so that you can have multiple processes and it knows how to assign partition amongst those processes",
    "start": "1133559",
    "end": "1140679"
  },
  {
    "text": "essentially consuming large amounts of data across several instances of your application that embeds the ca consumer",
    "start": "1140679",
    "end": "1147679"
  },
  {
    "text": "is pretty simple the same primitive is available in Kafka streams um now if you look at",
    "start": "1147679",
    "end": "1155880"
  },
  {
    "text": "this the consumer is replaced by the streams topology and it leverages the group",
    "start": "1155880",
    "end": "1162760"
  },
  {
    "text": "management feature so it has essentially the same effect you can have your kafa streams topology run on multiple",
    "start": "1162760",
    "end": "1169520"
  },
  {
    "text": "processes that essentially are your application and it handles the load balancing and assignment of partitions",
    "start": "1169520",
    "end": "1176720"
  },
  {
    "text": "evenly amongst those CFA streams instances so fall tolerance um next up",
    "start": "1176720",
    "end": "1183039"
  },
  {
    "text": "you know we we looked at how processing and data can be scaled horizontally but",
    "start": "1183039",
    "end": "1188600"
  },
  {
    "text": "then uh what about fall tolerance what about uh what if you restart part of your application or it simply crashes",
    "start": "1188600",
    "end": "1195840"
  },
  {
    "text": "now the thing is that the same group Management Facility handles uh fall tolerance so if one of your instances of",
    "start": "1195840",
    "end": "1202480"
  },
  {
    "text": "your application uh might die or is restarted uh it uh you know",
    "start": "1202480",
    "end": "1207799"
  },
  {
    "text": "transparently handles the rebalancing of partitions so that the new set of",
    "start": "1207799",
    "end": "1213080"
  },
  {
    "text": "remaining uh alive instances they pick up the load of the failed instances and the same thing is",
    "start": "1213080",
    "end": "1219080"
  },
  {
    "text": "available for kafa Stream So if if one of your processes that run some of your",
    "start": "1219080",
    "end": "1224480"
  },
  {
    "text": "uh Kafka streams tasks die uh Kafka streams automatically move moves those tasks or those topology instances to the",
    "start": "1224480",
    "end": "1232080"
  },
  {
    "text": "remaining alive instances of your application so um coming to State",
    "start": "1232080",
    "end": "1238360"
  },
  {
    "text": "Management uh and why this is important in stream processing if you notice some of the common operations in stream",
    "start": "1238360",
    "end": "1245280"
  },
  {
    "text": "processing uh some operations like uh filter and map they're essentially a",
    "start": "1245280",
    "end": "1250400"
  },
  {
    "text": "record at a time you know a record comes by you either filter it or not a record comes by and you map it and send it",
    "start": "1250400",
    "end": "1257039"
  },
  {
    "text": "across you don't have to to maintain any context of uh you know of a record as it",
    "start": "1257039",
    "end": "1263039"
  },
  {
    "text": "passes your stream processor but then there are some you know operators that",
    "start": "1263039",
    "end": "1268200"
  },
  {
    "text": "require maintaining some State uh when you window data you have to you know",
    "start": "1268200",
    "end": "1273440"
  },
  {
    "text": "remember uh a couple of messages that uh formulate that window and so State",
    "start": "1273440",
    "end": "1279279"
  },
  {
    "text": "Management is important in stream processing you you almost can get rid of it so there are several options when it",
    "start": "1279279",
    "end": "1285720"
  },
  {
    "text": "comes to State Management the first one is POS possibly the more common approach which is uh you take your state and you",
    "start": "1285720",
    "end": "1292559"
  },
  {
    "text": "just stick it in some kind of key value store that you know and trust um that actually works uh however there is a",
    "start": "1292559",
    "end": "1299480"
  },
  {
    "text": "performance impedance mismatch for example Kafka can actually process",
    "start": "1299480",
    "end": "1304559"
  },
  {
    "text": "messages at the rate of hundreds of thousands of messages per second per node while uh an external key Value",
    "start": "1304559",
    "end": "1312320"
  },
  {
    "text": "Store when used in this manner which is for every message or every set of messages you need to make an external",
    "start": "1312320",
    "end": "1317960"
  },
  {
    "text": "RPC to this key value store and either get or uh set some message or data uh it",
    "start": "1317960",
    "end": "1323919"
  },
  {
    "text": "can only handle possibly thousands of messages per second so there's inherently this uh performance uh",
    "start": "1323919",
    "end": "1329919"
  },
  {
    "text": "mismatch the second option is you push your state inside the stream processor",
    "start": "1329919",
    "end": "1335880"
  },
  {
    "text": "so it's available locally if you did that then um that's obviously way faster",
    "start": "1335880",
    "end": "1341159"
  },
  {
    "text": "because all the data that is required for your processing is available within inside your processor um the nice thing",
    "start": "1341159",
    "end": "1348880"
  },
  {
    "text": "is that is that it provides better isolation so one fast processor cannot take down the database that is used by",
    "start": "1348880",
    "end": "1356320"
  },
  {
    "text": "other processors and it is actually uh flexible so this um this state is",
    "start": "1356320",
    "end": "1362120"
  },
  {
    "text": "actually pluggable so it could be uh an inmemory hashmap or it could be a Rox TB",
    "start": "1362120",
    "end": "1367200"
  },
  {
    "text": "store it could be uh your own data structure that could be read or write optimized depending on your",
    "start": "1367200",
    "end": "1372840"
  },
  {
    "text": "application um and so what kka streams does is it provides the option of local",
    "start": "1372840",
    "end": "1378559"
  },
  {
    "text": "durable State this is pluggable at the moment uh in in the current version of",
    "start": "1378559",
    "end": "1383880"
  },
  {
    "text": "kavka streams this is either a Rox DB store or an inmemory hashmap but the",
    "start": "1383880",
    "end": "1389679"
  },
  {
    "text": "nice thing is that it is uh fa tolerant uh and you might think how what it does",
    "start": "1389679",
    "end": "1395279"
  },
  {
    "text": "is that every update that is written to any Shard of your state store is transparently written to a highly",
    "start": "1395279",
    "end": "1401679"
  },
  {
    "text": "available and durable caot topic so even as processors come and go when they",
    "start": "1401679",
    "end": "1407840"
  },
  {
    "text": "restarted on the new machine they can scan this uh compacted log in Kafka and",
    "start": "1407840",
    "end": "1414279"
  },
  {
    "text": "recreate the state store now this is merely an option so if you choose to you can still go back and stick your state",
    "start": "1414279",
    "end": "1420880"
  },
  {
    "text": "in an external database there are other implications of that but this is an option that is provided out of the box",
    "start": "1420880",
    "end": "1427279"
  },
  {
    "text": "uh in KF kashim so um you might think about you know if you log every update",
    "start": "1427279",
    "end": "1433279"
  },
  {
    "text": "made to some kind of uh state store uh how does it work without running out of",
    "start": "1433279",
    "end": "1439159"
  },
  {
    "text": "space and this is actually where uh the third uh garbage collection policy in Kafka uh comes handy which is lock",
    "start": "1439159",
    "end": "1446559"
  },
  {
    "text": "compaction the idea is that you know imagine every update that was made to uh",
    "start": "1446559",
    "end": "1452640"
  },
  {
    "text": "uh a state store is written as a message in Kafka and recall that a message in",
    "start": "1452640",
    "end": "1457720"
  },
  {
    "text": "Kafka is a key and a value so um this is the primary key and this is the value",
    "start": "1457720",
    "end": "1463080"
  },
  {
    "text": "which is essentially the the content of your role what if you did that then you",
    "start": "1463080",
    "end": "1468360"
  },
  {
    "text": "you know every row that exists in your database it exists in this cafco topic in fact as rows are updated you might",
    "start": "1468360",
    "end": "1474760"
  },
  {
    "text": "find multiple messages that belong to the same key if the RO is never updated",
    "start": "1474760",
    "end": "1480440"
  },
  {
    "text": "you might just find one message that never goes away so the implication is that you know everything um that you",
    "start": "1480440",
    "end": "1487799"
  },
  {
    "text": "have in your external state store is available as a message here so if you wanted to recreate the content the",
    "start": "1487799",
    "end": "1495279"
  },
  {
    "text": "current content of your state store all you have to do is is you you scan this Kafka topic from the very beginning and",
    "start": "1495279",
    "end": "1502399"
  },
  {
    "text": "when you reach the end you have your state store uh the compaction policy what it does is periodically it deletes",
    "start": "1502399",
    "end": "1509399"
  },
  {
    "text": "older values for every unique key to only maintain the latest value and this",
    "start": "1509399",
    "end": "1515440"
  },
  {
    "text": "is what you see the the row with key a was written or updated Thrice but what",
    "start": "1515440",
    "end": "1521600"
  },
  {
    "text": "really matters is the latest value and that is what the compacted version of the log looks like this is actually uh",
    "start": "1521600",
    "end": "1528399"
  },
  {
    "text": "exactly what traditional databases do is you have a redo log and um every every",
    "start": "1528399",
    "end": "1535039"
  },
  {
    "text": "update to a row is um logged into that redo log and so uh that is exactly how",
    "start": "1535039",
    "end": "1540399"
  },
  {
    "text": "databases um handle crash recovery okay so this log compaction uh",
    "start": "1540399",
    "end": "1546919"
  },
  {
    "text": "feature is actually really important in solving another hard problem in reprocessing and I'm going to attempt to",
    "start": "1546919",
    "end": "1554080"
  },
  {
    "text": "explain what reprocessing means with the help of an example so assume that you have had some application that uh counts",
    "start": "1554080",
    "end": "1561159"
  },
  {
    "text": "the number of visits to a user website and it updates some kind of dashboard",
    "start": "1561159",
    "end": "1566480"
  },
  {
    "text": "and that might work fine uh Until you realize that you're either fixing the logic of counting uh or you're fixing a",
    "start": "1566480",
    "end": "1573960"
  },
  {
    "text": "bug in your application to essentially maybe you know drop a Geo code altoe so",
    "start": "1573960",
    "end": "1579600"
  },
  {
    "text": "if you did that then you know you know that all the windows from now on have uh",
    "start": "1579600",
    "end": "1586440"
  },
  {
    "text": "totally different Counts from the windows that the previous version of the application handled uh and so you what",
    "start": "1586440",
    "end": "1593080"
  },
  {
    "text": "you end up with are basically incorrect results for a a large percentage of those windows and so what you want to do",
    "start": "1593080",
    "end": "1600200"
  },
  {
    "text": "is uh you want to go back and reprocess the past results the moment you feel",
    "start": "1600200",
    "end": "1605399"
  },
  {
    "text": "like you have to upgrade your application so the way you do that is you know note that every um update or",
    "start": "1605399",
    "end": "1612960"
  },
  {
    "text": "the entire history of stuff is available in Kafka inside this compacted law l so",
    "start": "1612960",
    "end": "1619360"
  },
  {
    "text": "reprocessing merely amounts to uh resetting the offset of your application to zero and rescanning uh from that",
    "start": "1619360",
    "end": "1627320"
  },
  {
    "text": "point onwards so this is how it works um your application might uh update some",
    "start": "1627320",
    "end": "1633039"
  },
  {
    "text": "kind of state and uh this is where it's running which is it's fully caught up",
    "start": "1633039",
    "end": "1638360"
  },
  {
    "text": "you uh now you want to flip the switch and upgrade your application what you end up doing if you",
    "start": "1638360",
    "end": "1644559"
  },
  {
    "text": "want to use this feature is you start a new uh instance of application with uh",
    "start": "1644559",
    "end": "1650320"
  },
  {
    "text": "which sits in a new consumer group and the offset of that consumer group is set to zero and the state that it updates is",
    "start": "1650320",
    "end": "1657640"
  },
  {
    "text": "initially empty as it catches up you know the state fills up until it reaches",
    "start": "1657640",
    "end": "1662960"
  },
  {
    "text": "the end which is when it's fully caught up once it's fully caught up you flip the switch and you have the the",
    "start": "1662960",
    "end": "1669720"
  },
  {
    "text": "dashboard reads move to this new state store you shut down the old instance of",
    "start": "1669720",
    "end": "1675519"
  },
  {
    "text": "your state store and effectively you've now upgraded your application uh completely in a way that all the counts",
    "start": "1675519",
    "end": "1682039"
  },
  {
    "text": "are uh you know consistently reflected across the board now this feature actually really important because if",
    "start": "1682039",
    "end": "1688480"
  },
  {
    "text": "stream processing systems don't support um the idea of reprocessing you have to",
    "start": "1688480",
    "end": "1694679"
  },
  {
    "text": "fall back to a parallel hup based pipeline which essentially makes it pretty complicated as we will see later",
    "start": "1694679",
    "end": "1701679"
  },
  {
    "text": "to maintain uh okay so uh last but not the least uh the idea of time we spent a lot",
    "start": "1701679",
    "end": "1707880"
  },
  {
    "text": "of time time on this um and a lot of our work is inspired by this um you know",
    "start": "1707880",
    "end": "1715120"
  },
  {
    "text": "this idea shared by the data flow team at Google and this uh this Insight is",
    "start": "1715120",
    "end": "1720480"
  },
  {
    "text": "basically that stream data is never complete but in fact can always arrive",
    "start": "1720480",
    "end": "1726559"
  },
  {
    "text": "out of order and what that means for stream processing systems today is that you want to design things in a way that",
    "start": "1726559",
    "end": "1733360"
  },
  {
    "text": "you always expect data to either arrive late or arrive out of order and this has a bunch of applic uh you know um",
    "start": "1733360",
    "end": "1740519"
  },
  {
    "text": "instances on how you handle some of these problems so um the key thing to note about uh time or when it comes to",
    "start": "1740519",
    "end": "1747720"
  },
  {
    "text": "time are that uh there are two concepts worth paying attention to one is event",
    "start": "1747720",
    "end": "1753080"
  },
  {
    "text": "time which is when an event is created and the other is processing time which",
    "start": "1753080",
    "end": "1758880"
  },
  {
    "text": "is when the event gets processed and due to various delays or bottlenecks in your",
    "start": "1758880",
    "end": "1764399"
  },
  {
    "text": "pipeline these two things can actually converge and diverge over time and the source of the loss of",
    "start": "1764399",
    "end": "1771440"
  },
  {
    "text": "correctness in a lot of stream processing systems is because they totally conflate these two ideas uh",
    "start": "1771440",
    "end": "1777440"
  },
  {
    "text": "leading to incorrect results so here's an example from uh window uh to uh",
    "start": "1777440",
    "end": "1784519"
  },
  {
    "text": "convey this idea now let's uh you know assume the same application we have",
    "start": "1784519",
    "end": "1790039"
  },
  {
    "text": "we're counting uh user visits to a website and we're maintaining some kind of dashboard and because we're counting",
    "start": "1790039",
    "end": "1797519"
  },
  {
    "text": "we probably counting in Windows of data and let's just assume that window is a 10-minute window um now if if I'm a",
    "start": "1797519",
    "end": "1804679"
  },
  {
    "text": "mobile user if I visit this website and uh right before that visit event makes it to the application servers I lose",
    "start": "1804679",
    "end": "1811919"
  },
  {
    "text": "network coverage I come back after 12 hours now when this event makes it back",
    "start": "1811919",
    "end": "1817840"
  },
  {
    "text": "to the application servers you essentially have two choices you know you do you want to count this event in",
    "start": "1817840",
    "end": "1824200"
  },
  {
    "text": "the current 10-minute window or do you want to count this event in the 10-minute window 12 hours ago which is",
    "start": "1824200",
    "end": "1831080"
  },
  {
    "text": "when it really happened and uh if you notice if you if you count using the",
    "start": "1831080",
    "end": "1836399"
  },
  {
    "text": "former method that is counting by processing time it's essentially incorrect because of these delays uh",
    "start": "1836399",
    "end": "1842600"
  },
  {
    "text": "because of 10,000 reasons why those delays might happen if you count using event time that is correct because that",
    "start": "1842600",
    "end": "1849159"
  },
  {
    "text": "is that reflects the true state of the world so this applies broadly to you",
    "start": "1849159",
    "end": "1854399"
  },
  {
    "text": "know um a lot of Downstream processing inside your stream process processing topology and uh this is something that",
    "start": "1854399",
    "end": "1861039"
  },
  {
    "text": "Kafka streams as well as Flink as well as data flow a lot of these modern systems um incorporate the idea of event",
    "start": "1861039",
    "end": "1868279"
  },
  {
    "text": "time carefully throughout the system okay so this is um you know we've",
    "start": "1868279",
    "end": "1873960"
  },
  {
    "text": "rounded off sort of all the problems in uh typical problems in stream processing how you might get that in Kafka streams",
    "start": "1873960",
    "end": "1881159"
  },
  {
    "text": "and Kafka itself next up I'm going to talk about a novel idea in Kafka streams",
    "start": "1881159",
    "end": "1887039"
  },
  {
    "text": "that uh helps you model some of these harder stream processing uh problems",
    "start": "1887039",
    "end": "1892080"
  },
  {
    "text": "like Windows and Joints much more effectively and how that enables you to build these Loosely coupled stateful",
    "start": "1892080",
    "end": "1898960"
  },
  {
    "text": "microservices much more easily um I'm going to start by saying that uh streams",
    "start": "1898960",
    "end": "1904480"
  },
  {
    "text": "and tables are dual and Kafka streams fully integrates these two ideas um now",
    "start": "1904480",
    "end": "1911919"
  },
  {
    "text": "this might make a lot more sense with the help of an example so here goes this is uh essentially a c stream it has",
    "start": "1911919",
    "end": "1919279"
  },
  {
    "text": "three messages um every message has a key and a value like any other Kafka",
    "start": "1919279",
    "end": "1924440"
  },
  {
    "text": "message if you notice the stream is a little different the third message",
    "start": "1924440",
    "end": "1929679"
  },
  {
    "text": "updates the value for a key that you observed in the previous message um now",
    "start": "1929679",
    "end": "1936120"
  },
  {
    "text": "as a third exercise let's try converting it to a table where you know with every",
    "start": "1936120",
    "end": "1941960"
  },
  {
    "text": "message we add a row to this table so when you read message one you create the",
    "start": "1941960",
    "end": "1947279"
  },
  {
    "text": "first row when you read message to you create the second row this is a new key and when you read the third message you",
    "start": "1947279",
    "end": "1953399"
  },
  {
    "text": "update the first row so this is um you know essentially what we've done is we we've converted this stream uh into a",
    "start": "1953399",
    "end": "1961440"
  },
  {
    "text": "table now let's go one step further and try to see what a change log stream for",
    "start": "1961440",
    "end": "1966679"
  },
  {
    "text": "this table might look like um you know for those of you not aware change log streams are are streams that have a",
    "start": "1966679",
    "end": "1975039"
  },
  {
    "text": "message for every uh update made made to any row in a table um so if you want to look at what",
    "start": "1975039",
    "end": "1983200"
  },
  {
    "text": "a change log stream for this table might look like this is what you end up with if you try to compare it with the stream",
    "start": "1983200",
    "end": "1989559"
  },
  {
    "text": "we started with um this is essentially the same stream so we've taken a stream we've converted it to a table that gets",
    "start": "1989559",
    "end": "1996440"
  },
  {
    "text": "converted back into a streams uh essentially streams and table are dual",
    "start": "1996440",
    "end": "2001600"
  },
  {
    "text": "um this is um not that new of an idea um you know SQL um database systems or",
    "start": "2001600",
    "end": "2007799"
  },
  {
    "text": "database stream systems have introduced this idea we're merely bringing it to the surface through gafka um okay so uh",
    "start": "2007799",
    "end": "2015240"
  },
  {
    "text": "so what uh this stream table Duality is helpful in modeling uh some heart",
    "start": "2015240",
    "end": "2021320"
  },
  {
    "text": "problems uh specifically joints so we'll we'll go back and take an example to",
    "start": "2021320",
    "end": "2026480"
  },
  {
    "text": "make this a little more um easy to understand so back to this retail example where I said that you know you",
    "start": "2026480",
    "end": "2033279"
  },
  {
    "text": "have a sales stream you have a shipment stream uh if we wanted to join these two stre streams we might get the inventory",
    "start": "2033279",
    "end": "2040120"
  },
  {
    "text": "on hand for this retail company so you have this shipment stream and sales",
    "start": "2040120",
    "end": "2046039"
  },
  {
    "text": "stream and for Simplicity let's assume that the format of a message in both of",
    "start": "2046039",
    "end": "2051240"
  },
  {
    "text": "these streams is exactly the same it has a dual key which is Item ID and store",
    "start": "2051240",
    "end": "2056800"
  },
  {
    "text": "code which identifies an item inside a store and then it has account now this",
    "start": "2056800",
    "end": "2063200"
  },
  {
    "text": "count for a shipment stream it means the number of items that are stocked up in that store and this count in a sales",
    "start": "2063200",
    "end": "2072000"
  },
  {
    "text": "stream means the number of items that are sold from that store so what a joint operation looks like is essentially for",
    "start": "2072000",
    "end": "2078679"
  },
  {
    "text": "a message in this shipment stream you increment the value in this table and",
    "start": "2078679",
    "end": "2084560"
  },
  {
    "text": "this table is essentially um a concept in gfer streams and for a message on the",
    "start": "2084560",
    "end": "2090158"
  },
  {
    "text": "sales stream you decrement the value in the table and now if you look at what this table is it's essentially a",
    "start": "2090159",
    "end": "2096240"
  },
  {
    "text": "realtime view of the invent on hand for this uh particular company now this uh in Kafka streams it",
    "start": "2096240",
    "end": "2104200"
  },
  {
    "text": "isn't just an internal concept um I didn't get a chance to show you an API but uh there this is absolutely a",
    "start": "2104200",
    "end": "2111359"
  },
  {
    "text": "concept that is available to you as a user so you know what the semantics of that uh particular thing is so you have",
    "start": "2111359",
    "end": "2118200"
  },
  {
    "text": "a k table which is a table uh which is exactly the output of this kind of join operation where there are messages that",
    "start": "2118200",
    "end": "2126440"
  },
  {
    "text": "update values of prev messages and then there are case streams where there are just messages that um don't update the",
    "start": "2126440",
    "end": "2134040"
  },
  {
    "text": "values of previous messages in the Stream um now going one step further you",
    "start": "2134040",
    "end": "2139160"
  },
  {
    "text": "know there's an emergent property of some of the things that I shared um that might not be as obvious and that is that",
    "start": "2139160",
    "end": "2145760"
  },
  {
    "text": "this stream table Duality when combined with uh local queriable state I'll explain that shortly it allows you to",
    "start": "2145760",
    "end": "2153000"
  },
  {
    "text": "build stateful applications with e um let's go back to this example if you",
    "start": "2153000",
    "end": "2158520"
  },
  {
    "text": "look at you know this join operation and what the application view of things looks like um let's assume that this was",
    "start": "2158520",
    "end": "2165640"
  },
  {
    "text": "a simple code that you wrote to join um to join these two streams inside your",
    "start": "2165640",
    "end": "2170960"
  },
  {
    "text": "application you have several instances of this application uh every instance",
    "start": "2170960",
    "end": "2176560"
  },
  {
    "text": "has a subset of partitions of the shipment and Sal stream this is handled by Kafka streams under the covers and",
    "start": "2176560",
    "end": "2183880"
  },
  {
    "text": "hence every instance of the application has um you know subset of charts of this",
    "start": "2183880",
    "end": "2189160"
  },
  {
    "text": "inventory on hand table um assume that this table which is exposed to you as",
    "start": "2189160",
    "end": "2195960"
  },
  {
    "text": "the user this was actually queriable if this was queriable then what that gives",
    "start": "2195960",
    "end": "2202000"
  },
  {
    "text": "you a chance to do is expose this sort of a rest API on top of your application that allows you to query the count for",
    "start": "2202000",
    "end": "2209839"
  },
  {
    "text": "this inventory item in every store um this is actually pretty powerful because",
    "start": "2209839",
    "end": "2215160"
  },
  {
    "text": "uh We've not only Built you know this applic as u a realtime view but that view is",
    "start": "2215160",
    "end": "2221240"
  },
  {
    "text": "actually getting updated uh underneath the covers because of this join operation on the same application right",
    "start": "2221240",
    "end": "2227560"
  },
  {
    "text": "um this actually may not make sense in every domain uh often times what you want to do is uh even if you do this",
    "start": "2227560",
    "end": "2234040"
  },
  {
    "text": "join you just want to stick it in some kind of external database you know and trust but if any um operation that you",
    "start": "2234040",
    "end": "2241240"
  },
  {
    "text": "need to do it requires accessing a ton of state or a ton of data then having",
    "start": "2241240",
    "end": "2246560"
  },
  {
    "text": "this uh query able State option is actually super useful it uh essentially the state is fully isolated it never",
    "start": "2246560",
    "end": "2252800"
  },
  {
    "text": "leaves your application and uh it is entirely um isolated and hence",
    "start": "2252800",
    "end": "2259040"
  },
  {
    "text": "resilient okay so um moving one step further if if you try to put TN together",
    "start": "2259040",
    "end": "2264839"
  },
  {
    "text": "Kafka streams is actually helpful for building these asynchronous and Loosely coupled uh however stateful applications",
    "start": "2264839",
    "end": "2273359"
  },
  {
    "text": "um going one step further on our application you know building it out a little bit further to complete that",
    "start": "2273359",
    "end": "2278880"
  },
  {
    "text": "picture I showed earlier um we have this inventory on state application um it has",
    "start": "2278880",
    "end": "2284839"
  },
  {
    "text": "that uh table and recall that uh every state store is uh backed by a change",
    "start": "2284839",
    "end": "2291119"
  },
  {
    "text": "lock Topic in Kafka that's transparent uh it happens automatically and this is",
    "start": "2291119",
    "end": "2296640"
  },
  {
    "text": "what the change log stream looks like right every message is uh it corresponds to some row update that is made on that",
    "start": "2296640",
    "end": "2304720"
  },
  {
    "text": "table and that is like any other CF topic that is available to you if you",
    "start": "2304720",
    "end": "2310480"
  },
  {
    "text": "had that then it actually Powers two Downstream applications that we initially said are uh typically not",
    "start": "2310480",
    "end": "2317359"
  },
  {
    "text": "built that way today and that is uh the reorder inventory application so what",
    "start": "2317359",
    "end": "2322680"
  },
  {
    "text": "that does is it subscribes to this change log stream like any other Kafka topic with every message on this stream",
    "start": "2322680",
    "end": "2330560"
  },
  {
    "text": "it checks if that inventory count has dropped below a certain threshold if it",
    "start": "2330560",
    "end": "2335599"
  },
  {
    "text": "has then it triggers the reorder action uh this um application is",
    "start": "2335599",
    "end": "2341680"
  },
  {
    "text": "entirely um different from this other application which is the price adjustment application what that does is",
    "start": "2341680",
    "end": "2348160"
  },
  {
    "text": "it independently subscribes to this change log stream and it tries to project the demand for this particular",
    "start": "2348160",
    "end": "2354920"
  },
  {
    "text": "item and if the demand is high or it changes then it triggers price changes",
    "start": "2354920",
    "end": "2360280"
  },
  {
    "text": "right and and these two applications are independent they are real time but",
    "start": "2360280",
    "end": "2365400"
  },
  {
    "text": "they're also totally Loosely coupled the failure of the reorder inventory application has got nothing to do with",
    "start": "2365400",
    "end": "2371560"
  },
  {
    "text": "the price adjustment applications so we've not only you know designed these Services as stream processors they're",
    "start": "2371560",
    "end": "2378599"
  },
  {
    "text": "designed as you know stateful services that are Loosely coupled and uh that is",
    "start": "2378599",
    "end": "2384119"
  },
  {
    "text": "what I meant initially when I said that uh it this this whole idea of uh you",
    "start": "2384119",
    "end": "2389760"
  },
  {
    "text": "know using um something like CCO streams it enables you to to push stream",
    "start": "2389760",
    "end": "2395280"
  },
  {
    "text": "processing inside your application and and helps build these Loosely coupled U microservices if you might call it that",
    "start": "2395280",
    "end": "2402800"
  },
  {
    "text": "um an emergent sort of theme across Kafka or Kafka streams is um you know",
    "start": "2402800",
    "end": "2408720"
  },
  {
    "text": "the Simplicity is valued and and the reason is that um the more things you have in distributed systems the more",
    "start": "2408720",
    "end": "2415160"
  },
  {
    "text": "things you have to operate and ongoing operations are absolutely the hardest things um you know much much harder than",
    "start": "2415160",
    "end": "2422319"
  },
  {
    "text": "building the application or even troubleshooting it uh in in the development phase and so uh the",
    "start": "2422319",
    "end": "2428200"
  },
  {
    "text": "implication for this for stream processing is that typically if your stream processing system does not have",
    "start": "2428200",
    "end": "2433960"
  },
  {
    "text": "local durable State then this is what you end up with uh you have Kafka which",
    "start": "2433960",
    "end": "2439400"
  },
  {
    "text": "is still your you know data pipeline uh but you have the stream processing framework uh if it doesn't support State",
    "start": "2439400",
    "end": "2446359"
  },
  {
    "text": "uh you're dependent on some kind of a database so you have to operate that um",
    "start": "2446359",
    "end": "2451440"
  },
  {
    "text": "this is your stream processing code which runs as a job on this framework that really updates your final View um",
    "start": "2451440",
    "end": "2457760"
  },
  {
    "text": "but then if you if you think about it if your stream processing system does not uh support the capability for uh",
    "start": "2457760",
    "end": "2464400"
  },
  {
    "text": "reprocessing or upgrading your code then you're left with this parallel pipeline which is based on hudo so you have the",
    "start": "2464400",
    "end": "2471839"
  },
  {
    "text": "same logic that runs on hudo it updates uh an entirely offline view of the same",
    "start": "2471839",
    "end": "2477800"
  },
  {
    "text": "database and now if you look at your application it's it's pretty complex it queries these two views it merges it on",
    "start": "2477800",
    "end": "2484400"
  },
  {
    "text": "the Fly and uh then gives you some of these results so that is what I meant by",
    "start": "2484400",
    "end": "2489720"
  },
  {
    "text": "uh you know for application developers that is um just too many moving Parts um",
    "start": "2489720",
    "end": "2494880"
  },
  {
    "text": "this might work for a subset of um you know use cases that you might depend on",
    "start": "2494880",
    "end": "2500440"
  },
  {
    "text": "a fully managed cluster for and it might work but for lightweight um you know",
    "start": "2500440",
    "end": "2505560"
  },
  {
    "text": "stream processing inside applications that is just too many moving parts so that is what we've paid attention to in",
    "start": "2505560",
    "end": "2511000"
  },
  {
    "text": "streams which is um you know we've taken those Aggregates we've provided that as",
    "start": "2511000",
    "end": "2516280"
  },
  {
    "text": "local durable state so it is available out of the box you don't have to depend on an external key Value Store uh we've",
    "start": "2516280",
    "end": "2523040"
  },
  {
    "text": "taken the idea of reprocessing and it is actually available as a first class primitive inside of Kafka and Kafka",
    "start": "2523040",
    "end": "2530119"
  },
  {
    "text": "streams so you don't have to depend on a Hadoop based pipeline uh essentially moving away from uh Lambda architecture",
    "start": "2530119",
    "end": "2537079"
  },
  {
    "text": "is uh what it finally enables in this simplified picture um so you might think you know",
    "start": "2537079",
    "end": "2544440"
  },
  {
    "text": "uh kafa streams is great uh but it is only a library on top of Kafka which means that it only works for data which",
    "start": "2544440",
    "end": "2551200"
  },
  {
    "text": "is within Kafka it is done that way for Simplicity for uh ease of operation but",
    "start": "2551200",
    "end": "2557640"
  },
  {
    "text": "then the problem you might think about is well how do you get your data in and out of Kafka um in the 09 release uh",
    "start": "2557640",
    "end": "2564680"
  },
  {
    "text": "which was the previous release of Kafka we uh had released U Kafka connect which is this uh you know a way to build",
    "start": "2564680",
    "end": "2571800"
  },
  {
    "text": "elastic scalable connectors to other systems using kcom uh the idea is that",
    "start": "2571800",
    "end": "2576960"
  },
  {
    "text": "this layer solves all the common problems that connectors need to solve which is scale out and partitioning and",
    "start": "2576960",
    "end": "2583160"
  },
  {
    "text": "load balancing offset management uh since you know this is exactly the layer that allows you to for example ETL your",
    "start": "2583160",
    "end": "2590400"
  },
  {
    "text": "data from a Cassandra or Oracle database into Hadoop using uh Kafka connectors um",
    "start": "2590400",
    "end": "2596920"
  },
  {
    "text": "it's been roughly around four to five months since we've released Kafka connect and the community has developed",
    "start": "2596920",
    "end": "2603000"
  },
  {
    "text": "basically maybe 30 or so connectors already on top of this uh to various systems like elastic search mongod DB",
    "start": "2603000",
    "end": "2610680"
  },
  {
    "text": "Cassandra someone even went ahead and wrote a Bloomberg ticker Source uh so you can you can take a look at uh some",
    "start": "2610680",
    "end": "2617160"
  },
  {
    "text": "of these um connectors or even develop your own um now tying this into the big",
    "start": "2617160",
    "end": "2622599"
  },
  {
    "text": "picture which is what I um wanted to do here which is uh this is what some of us",
    "start": "2622599",
    "end": "2627880"
  },
  {
    "text": "uh achieved while at LinkedIn and have helped some companies move to which is essentially the ability to deploy a",
    "start": "2627880",
    "end": "2634640"
  },
  {
    "text": "Kafka based stream data platform at the heart of your data center um this is the",
    "start": "2634640",
    "end": "2641319"
  },
  {
    "text": "foundation for building Loosely coupled microservices um a building blog for",
    "start": "2641319",
    "end": "2648359"
  },
  {
    "text": "stateful applications or stream processors or uh enabling um other",
    "start": "2648359",
    "end": "2653680"
  },
  {
    "text": "stream processing systems to exist due to the data pipeline uh as well as uh",
    "start": "2653680",
    "end": "2659599"
  },
  {
    "text": "the feed of data that goes into your Warehouse um now if you wanted to try",
    "start": "2659599",
    "end": "2667200"
  },
  {
    "text": "this out uh Kafka streams was released today um in the latest release of Apache",
    "start": "2667200",
    "end": "2672480"
  },
  {
    "text": "Kafka which is the o10 release you can get it through uh Apache kafar the confluent platform uh both connect and",
    "start": "2672480",
    "end": "2679400"
  },
  {
    "text": "streams is uh brand new uh there are a lot of people who are jumping on these uh ideas if you need help we we do a",
    "start": "2679400",
    "end": "2686680"
  },
  {
    "text": "bi-weekly ask me anything call if you wanted to participate or give us ideas uh you can ping me on Twitter um and",
    "start": "2686680",
    "end": "2693960"
  },
  {
    "text": "that is basically it [Applause]",
    "start": "2693960",
    "end": "2706510"
  }
]
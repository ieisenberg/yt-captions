[
  {
    "start": "0",
    "end": "20000"
  },
  {
    "text": "um hi everyone so for the next half an",
    "start": "5640",
    "end": "8240"
  },
  {
    "text": "hour I'll be talking about data",
    "start": "8240",
    "end": "9800"
  },
  {
    "text": "integration and some of the",
    "start": "9800",
    "end": "12000"
  },
  {
    "text": "techniques um which we develop here data",
    "start": "12000",
    "end": "15040"
  },
  {
    "text": "61 to make the process of data",
    "start": "15040",
    "end": "17160"
  },
  {
    "text": "integration as simple as possible so in",
    "start": "17160",
    "end": "20359"
  },
  {
    "start": "20000",
    "end": "58000"
  },
  {
    "text": "its broadest sense data integration is",
    "start": "20359",
    "end": "23000"
  },
  {
    "text": "about combining data from different",
    "start": "23000",
    "end": "24960"
  },
  {
    "text": "sources and providing the user with a",
    "start": "24960",
    "end": "27400"
  },
  {
    "text": "unified view of this data and the",
    "start": "27400",
    "end": "30759"
  },
  {
    "text": "situations actually when uh this problem",
    "start": "30759",
    "end": "33280"
  },
  {
    "text": "arises are plentiful so for example you",
    "start": "33280",
    "end": "36760"
  },
  {
    "text": "have multiple data sets with some common",
    "start": "36760",
    "end": "38920"
  },
  {
    "text": "entities and content but you don't know",
    "start": "38920",
    "end": "41120"
  },
  {
    "text": "the schema of those uh uh data sets or",
    "start": "41120",
    "end": "43840"
  },
  {
    "text": "you have silot systems or Legacy systems",
    "start": "43840",
    "end": "47079"
  },
  {
    "text": "which you need to uh bring together or I",
    "start": "47079",
    "end": "50360"
  },
  {
    "text": "mean in more General sense you need to",
    "start": "50360",
    "end": "51960"
  },
  {
    "text": "share data across systems or schemas and",
    "start": "51960",
    "end": "54600"
  },
  {
    "text": "you have to handle somehow those",
    "start": "54600",
    "end": "56199"
  },
  {
    "text": "different",
    "start": "56199",
    "end": "57320"
  },
  {
    "text": "schemas so here at data 61 um we face",
    "start": "57320",
    "end": "61320"
  },
  {
    "start": "58000",
    "end": "115000"
  },
  {
    "text": "this problem quite often when dealing",
    "start": "61320",
    "end": "63079"
  },
  {
    "text": "with some government projects which we",
    "start": "63079",
    "end": "65198"
  },
  {
    "text": "have and uh especially uh when we need",
    "start": "65199",
    "end": "67960"
  },
  {
    "text": "to do some analytical work uh on data",
    "start": "67960",
    "end": "71000"
  },
  {
    "text": "which comes from different governmental",
    "start": "71000",
    "end": "72960"
  },
  {
    "text": "agencies um this is uh a huge issue",
    "start": "72960",
    "end": "76119"
  },
  {
    "text": "because we basically get a huge M of",
    "start": "76119",
    "end": "79880"
  },
  {
    "text": "different CSV tables SQL dumps Json",
    "start": "79880",
    "end": "83759"
  },
  {
    "text": "sometimes and then before we can do any",
    "start": "83759",
    "end": "86000"
  },
  {
    "text": "analysis we actually need to bring this",
    "start": "86000",
    "end": "88159"
  },
  {
    "text": "data together and a common practice in",
    "start": "88159",
    "end": "91600"
  },
  {
    "text": "Enterprise to handle this data",
    "start": "91600",
    "end": "93799"
  },
  {
    "text": "integration issue is to uh construct",
    "start": "93799",
    "end": "97240"
  },
  {
    "text": "some complex ETL Frameworks and today in",
    "start": "97240",
    "end": "100759"
  },
  {
    "text": "the morning in the first talk you saw",
    "start": "100759",
    "end": "102880"
  },
  {
    "text": "actually how complex those ETL",
    "start": "102880",
    "end": "104799"
  },
  {
    "text": "Frameworks can look and that this is",
    "start": "104799",
    "end": "106880"
  },
  {
    "text": "really a huge headache so our question",
    "start": "106880",
    "end": "109520"
  },
  {
    "text": "now is can we use machine learning to",
    "start": "109520",
    "end": "112200"
  },
  {
    "text": "help us solve this",
    "start": "112200",
    "end": "114399"
  },
  {
    "text": "problem um but before I actually go into",
    "start": "114399",
    "end": "117000"
  },
  {
    "start": "115000",
    "end": "230000"
  },
  {
    "text": "a bit more detail about how exactly we",
    "start": "117000",
    "end": "119079"
  },
  {
    "text": "use machine learning here how we can use",
    "start": "119079",
    "end": "121000"
  },
  {
    "text": "it um there are uh so the data",
    "start": "121000",
    "end": "124159"
  },
  {
    "text": "integration area this is quite a broad",
    "start": "124159",
    "end": "126280"
  },
  {
    "text": "area and there are lots of different",
    "start": "126280",
    "end": "127920"
  },
  {
    "text": "problems which exist within it and in",
    "start": "127920",
    "end": "130599"
  },
  {
    "text": "our team we focus on the following",
    "start": "130599",
    "end": "133080"
  },
  {
    "text": "problems so the first one is schema",
    "start": "133080",
    "end": "135120"
  },
  {
    "text": "matching and mapping this is actually",
    "start": "135120",
    "end": "136840"
  },
  {
    "text": "the core of data integration and this is",
    "start": "136840",
    "end": "139319"
  },
  {
    "text": "exactly where we try to connect data",
    "start": "139319",
    "end": "141400"
  },
  {
    "text": "sets by establishing a global data model",
    "start": "141400",
    "end": "145400"
  },
  {
    "text": "um then there is a problem of entity",
    "start": "145400",
    "end": "146959"
  },
  {
    "text": "resolution which uh is actually really",
    "start": "146959",
    "end": "150040"
  },
  {
    "text": "crucial when integrating the data that's",
    "start": "150040",
    "end": "152319"
  },
  {
    "text": "basically detecting entities across",
    "start": "152319",
    "end": "154640"
  },
  {
    "text": "databases uh the other one which we are",
    "start": "154640",
    "end": "156680"
  },
  {
    "text": "looking at is privacy preserving",
    "start": "156680",
    "end": "158599"
  },
  {
    "text": "analytics and uh this sorry um uh and we",
    "start": "158599",
    "end": "163959"
  },
  {
    "text": "are interested in this uh uh issue um",
    "start": "163959",
    "end": "167480"
  },
  {
    "text": "since we have a projects with multiple",
    "start": "167480",
    "end": "169800"
  },
  {
    "text": "partners and very often those Partners",
    "start": "169800",
    "end": "171959"
  },
  {
    "text": "don't want explicitly to share their",
    "start": "171959",
    "end": "173640"
  },
  {
    "text": "data so and the question here is that",
    "start": "173640",
    "end": "176000"
  },
  {
    "text": "can we actually learn the global data",
    "start": "176000",
    "end": "177720"
  },
  {
    "text": "model without explicitly sharing the",
    "start": "177720",
    "end": "180080"
  },
  {
    "text": "data in this setting and the other issue",
    "start": "180080",
    "end": "183200"
  },
  {
    "text": "which we're looking at is about data",
    "start": "183200",
    "end": "184640"
  },
  {
    "text": "quality and yeah you've heard already",
    "start": "184640",
    "end": "187120"
  },
  {
    "text": "great talks about this issue yesterday",
    "start": "187120",
    "end": "190599"
  },
  {
    "text": "um the last uh talk was especially about",
    "start": "190599",
    "end": "193239"
  },
  {
    "text": "it and today in the morning as well and",
    "start": "193239",
    "end": "196360"
  },
  {
    "text": "uh our main approach is actually to uh",
    "start": "196360",
    "end": "198840"
  },
  {
    "text": "try to come up with techniques which",
    "start": "198840",
    "end": "200599"
  },
  {
    "text": "would actually automate the solutions to",
    "start": "200599",
    "end": "203080"
  },
  {
    "text": "all of these problems and in my talk I",
    "start": "203080",
    "end": "206400"
  },
  {
    "text": "will focus only on one of those problems",
    "start": "206400",
    "end": "208599"
  },
  {
    "text": "and mainly schema matching and mapping",
    "start": "208599",
    "end": "211120"
  },
  {
    "text": "and I will not go too much into detail",
    "start": "211120",
    "end": "213920"
  },
  {
    "text": "um how exactly um we implement the stuff",
    "start": "213920",
    "end": "217319"
  },
  {
    "text": "and some technical details so I will",
    "start": "217319",
    "end": "219480"
  },
  {
    "text": "just try to share with you ideas",
    "start": "219480",
    "end": "221239"
  },
  {
    "text": "actually how we can um automate the",
    "start": "221239",
    "end": "224439"
  },
  {
    "text": "process of finding a global data model",
    "start": "224439",
    "end": "227000"
  },
  {
    "text": "for our very heterogenous data",
    "start": "227000",
    "end": "230200"
  },
  {
    "start": "230000",
    "end": "316000"
  },
  {
    "text": "sets um so let's start with relational",
    "start": "230200",
    "end": "234040"
  },
  {
    "text": "schema matching and I use here the word",
    "start": "234040",
    "end": "236560"
  },
  {
    "text": "relational since we're dealing with uh",
    "start": "236560",
    "end": "239040"
  },
  {
    "text": "relational um schemas so meaning that we",
    "start": "239040",
    "end": "242079"
  },
  {
    "text": "have some um CSV files or we have some",
    "start": "242079",
    "end": "245720"
  },
  {
    "text": "SQL data",
    "start": "245720",
    "end": "247000"
  },
  {
    "text": "tables and uh imagine that we have five",
    "start": "247000",
    "end": "250720"
  },
  {
    "text": "uh uh data tables and each of those data",
    "start": "250720",
    "end": "253640"
  },
  {
    "text": "tables contains a column which cont uh",
    "start": "253640",
    "end": "257639"
  },
  {
    "text": "which is supposedly has some people's",
    "start": "257639",
    "end": "259759"
  },
  {
    "text": "names in it but in each of those data",
    "start": "259759",
    "end": "262079"
  },
  {
    "text": "tables the",
    "start": "262079",
    "end": "263560"
  },
  {
    "text": "column yeah it's called",
    "start": "263560",
    "end": "266479"
  },
  {
    "text": "differently see that so one it's called",
    "start": "266479",
    "end": "269720"
  },
  {
    "text": "usern name in the other one it's called",
    "start": "269720",
    "end": "271240"
  },
  {
    "text": "people um the other one has it like with",
    "start": "271240",
    "end": "273720"
  },
  {
    "text": "underscore users underscore and then if",
    "start": "273720",
    "end": "276120"
  },
  {
    "text": "you look at the content so it's also the",
    "start": "276120",
    "end": "278039"
  },
  {
    "text": "case that the formatting is quite",
    "start": "278039",
    "end": "280479"
  },
  {
    "text": "different um and our goal is now",
    "start": "280479",
    "end": "283320"
  },
  {
    "text": "actually to automatically connect those",
    "start": "283320",
    "end": "285360"
  },
  {
    "text": "data sets across these relational",
    "start": "285360",
    "end": "287440"
  },
  {
    "text": "schemas and uh the problem which we Face",
    "start": "287440",
    "end": "290199"
  },
  {
    "text": "here is actually syntax versus semantics",
    "start": "290199",
    "end": "293080"
  },
  {
    "text": "so we can quite easily identify that",
    "start": "293080",
    "end": "295960"
  },
  {
    "text": "those are people's name right but the",
    "start": "295960",
    "end": "298520"
  },
  {
    "text": "machine get caught on syntax so all",
    "start": "298520",
    "end": "301120"
  },
  {
    "text": "those formating issues naming uh",
    "start": "301120",
    "end": "303199"
  },
  {
    "text": "differences they cause a problem and",
    "start": "303199",
    "end": "305680"
  },
  {
    "text": "what we want actually to say is that all",
    "start": "305680",
    "end": "308199"
  },
  {
    "text": "these columns talk semantically about",
    "start": "308199",
    "end": "311000"
  },
  {
    "text": "the same concept namely name and that's",
    "start": "311000",
    "end": "313560"
  },
  {
    "text": "what we call semantic",
    "start": "313560",
    "end": "315520"
  },
  {
    "text": "type and now the question the way we",
    "start": "315520",
    "end": "317880"
  },
  {
    "start": "316000",
    "end": "658000"
  },
  {
    "text": "phrase the question is can we",
    "start": "317880",
    "end": "319319"
  },
  {
    "text": "automatically label columns with those",
    "start": "319319",
    "end": "321560"
  },
  {
    "text": "semantic types and as input we have some",
    "start": "321560",
    "end": "325759"
  },
  {
    "text": "uh data sets and we have a set of",
    "start": "325759",
    "end": "327880"
  },
  {
    "text": "semantic types for example uh name",
    "start": "327880",
    "end": "330360"
  },
  {
    "text": "address phone in this case and the",
    "start": "330360",
    "end": "333080"
  },
  {
    "text": "question is can we detect all Columns of",
    "start": "333080",
    "end": "335199"
  },
  {
    "text": "the same semantic type where column",
    "start": "335199",
    "end": "337240"
  },
  {
    "text": "names may be different common entries",
    "start": "337240",
    "end": "339199"
  },
  {
    "text": "may not exist and there might be lots of",
    "start": "339199",
    "end": "341960"
  },
  {
    "text": "formating issues and for this purpose we",
    "start": "341960",
    "end": "345400"
  },
  {
    "text": "design the schema matcher so we call it",
    "start": "345400",
    "end": "348800"
  },
  {
    "text": "schema matcher um yeah and uh for those",
    "start": "348800",
    "end": "351960"
  },
  {
    "text": "of you who are familiar with machine",
    "start": "351960",
    "end": "353440"
  },
  {
    "text": "learning so this problem might sound",
    "start": "353440",
    "end": "355840"
  },
  {
    "text": "very much like a multiclass",
    "start": "355840",
    "end": "357440"
  },
  {
    "text": "classification problem so and yeah",
    "start": "357440",
    "end": "360240"
  },
  {
    "text": "exactly that's what it is so uh to solve",
    "start": "360240",
    "end": "363120"
  },
  {
    "text": "it we um need first actually to",
    "start": "363120",
    "end": "365919"
  },
  {
    "text": "represent each column as a feature",
    "start": "365919",
    "end": "367919"
  },
  {
    "text": "Vector uh which can then be supplied to",
    "start": "367919",
    "end": "370680"
  },
  {
    "text": "a machine learning classifier and to",
    "start": "370680",
    "end": "373479"
  },
  {
    "text": "construct the feature Vector for for a",
    "start": "373479",
    "end": "375840"
  },
  {
    "text": "column uh we designed two groups of I",
    "start": "375840",
    "end": "379759"
  },
  {
    "text": "mean roughly two groups of features",
    "start": "379759",
    "end": "381560"
  },
  {
    "text": "which we calculate uh one group actually",
    "start": "381560",
    "end": "384560"
  },
  {
    "text": "uses the column headers and the table",
    "start": "384560",
    "end": "387080"
  },
  {
    "text": "name um and here we actually use some",
    "start": "387080",
    "end": "390080"
  },
  {
    "text": "natural language processing techniques",
    "start": "390080",
    "end": "392400"
  },
  {
    "text": "um to find out how um similar the column",
    "start": "392400",
    "end": "397080"
  },
  {
    "text": "had in the table name for this",
    "start": "397080",
    "end": "398680"
  },
  {
    "text": "particular column uh to the ones which",
    "start": "398680",
    "end": "401199"
  },
  {
    "text": "we have in the training uh data set and",
    "start": "401199",
    "end": "403960"
  },
  {
    "text": "uh in those uh I mean the for the",
    "start": "403960",
    "end": "406440"
  },
  {
    "text": "columns which are actually for which we",
    "start": "406440",
    "end": "407759"
  },
  {
    "text": "know the semantic types and the other",
    "start": "407759",
    "end": "410080"
  },
  {
    "text": "set of features which we develop are",
    "start": "410080",
    "end": "411639"
  },
  {
    "text": "content based so we're looking here at",
    "start": "411639",
    "end": "414039"
  },
  {
    "text": "the exact values which are in the column",
    "start": "414039",
    "end": "416879"
  },
  {
    "text": "and the features which we actually use",
    "start": "416879",
    "end": "419840"
  },
  {
    "text": "um are based on character frequencies so",
    "start": "419840",
    "end": "422720"
  },
  {
    "text": "the amount of missing values in the",
    "start": "422720",
    "end": "424960"
  },
  {
    "text": "column number of repeated values and",
    "start": "424960",
    "end": "427879"
  },
  {
    "text": "entropy overall of the column um yeah",
    "start": "427879",
    "end": "431639"
  },
  {
    "text": "but with machine learning so the crucial",
    "start": "431639",
    "end": "433960"
  },
  {
    "text": "part is that we need training data right",
    "start": "433960",
    "end": "436400"
  },
  {
    "text": "and in our case this training data is",
    "start": "436400",
    "end": "439680"
  },
  {
    "text": "actually uh is based on the columns",
    "start": "439680",
    "end": "443360"
  },
  {
    "text": "which we have so imagine if you have a",
    "start": "443360",
    "end": "446280"
  },
  {
    "text": "um a data table which has 1 million rows",
    "start": "446280",
    "end": "449080"
  },
  {
    "text": "but only 10 columns so your training",
    "start": "449080",
    "end": "451759"
  },
  {
    "text": "data that would be just those 10 columns",
    "start": "451759",
    "end": "454879"
  },
  {
    "text": "so we kind of have this problem of uh",
    "start": "454879",
    "end": "457520"
  },
  {
    "text": "sparse data so you might have really",
    "start": "457520",
    "end": "459440"
  },
  {
    "text": "like tons and lots of uh data row size",
    "start": "459440",
    "end": "463360"
  },
  {
    "text": "but columnwise it will be quite sparse",
    "start": "463360",
    "end": "466199"
  },
  {
    "text": "that's the first issue here and the",
    "start": "466199",
    "end": "468440"
  },
  {
    "text": "other issue is actually uh class",
    "start": "468440",
    "end": "471039"
  },
  {
    "text": "imbalance so think about it like if you",
    "start": "471039",
    "end": "473680"
  },
  {
    "text": "have if the user actually told uh told",
    "start": "473680",
    "end": "475879"
  },
  {
    "text": "you that here there are 10 data tables",
    "start": "475879",
    "end": "479280"
  },
  {
    "text": "and and in each of those data tables the",
    "start": "479280",
    "end": "481560"
  },
  {
    "text": "user identified like for example uh one",
    "start": "481560",
    "end": "484879"
  },
  {
    "text": "column which is phone number and the 10",
    "start": "484879",
    "end": "488400"
  },
  {
    "text": "columns which are people's names so that",
    "start": "488400",
    "end": "490840"
  },
  {
    "text": "causes then a problem when training",
    "start": "490840",
    "end": "493039"
  },
  {
    "text": "their classifier that we have a highly",
    "start": "493039",
    "end": "495520"
  },
  {
    "text": "imbalanced uh distribution between the",
    "start": "495520",
    "end": "498280"
  },
  {
    "text": "classes so these are two major machine",
    "start": "498280",
    "end": "501120"
  },
  {
    "text": "learning issues which exist when solving",
    "start": "501120",
    "end": "503479"
  },
  {
    "text": "this schema matching problem and one of",
    "start": "503479",
    "end": "506000"
  },
  {
    "text": "the approaches actually which we uh",
    "start": "506000",
    "end": "508240"
  },
  {
    "text": "looked at to handle the problem of class",
    "start": "508240",
    "end": "510599"
  },
  {
    "text": "imbalance is yeah so the standard",
    "start": "510599",
    "end": "514200"
  },
  {
    "text": "approach is to use various class",
    "start": "514200",
    "end": "515719"
  },
  {
    "text": "resampling strategies but we found out",
    "start": "515719",
    "end": "518200"
  },
  {
    "text": "that actually using cost sensitive",
    "start": "518200",
    "end": "519880"
  },
  {
    "text": "learning when we introduce asymmetric",
    "start": "519880",
    "end": "522518"
  },
  {
    "text": "cost for misclassifications works much",
    "start": "522519",
    "end": "525240"
  },
  {
    "text": "better in our case so to be a bit more",
    "start": "525240",
    "end": "528600"
  },
  {
    "text": "uh specific so think about it like um",
    "start": "528600",
    "end": "532279"
  },
  {
    "text": "you you have a the user provided you a",
    "start": "532279",
    "end": "534640"
  },
  {
    "text": "data table with 50 columns right and",
    "start": "534640",
    "end": "537959"
  },
  {
    "text": "then the user uh specified on the",
    "start": "537959",
    "end": "540519"
  },
  {
    "text": "semantic types only for 10 columns and",
    "start": "540519",
    "end": "543480"
  },
  {
    "text": "the other 40 I mean the user might have",
    "start": "543480",
    "end": "545800"
  },
  {
    "text": "been just lazy to label them or I don't",
    "start": "545800",
    "end": "548000"
  },
  {
    "text": "know just not really interested in those",
    "start": "548000",
    "end": "550120"
  },
  {
    "text": "other 40 columns so you don't know so",
    "start": "550120",
    "end": "552120"
  },
  {
    "text": "they actually we treat them as the",
    "start": "552120",
    "end": "554360"
  },
  {
    "text": "unknown class in this sense and then we",
    "start": "554360",
    "end": "557120"
  },
  {
    "text": "get this problem that the unknown class",
    "start": "557120",
    "end": "558800"
  },
  {
    "text": "is highly over represented and then",
    "start": "558800",
    "end": "561640"
  },
  {
    "text": "actually we tell our classifier by",
    "start": "561640",
    "end": "563720"
  },
  {
    "text": "introducing the so-called cost Matrix",
    "start": "563720",
    "end": "566320"
  },
  {
    "text": "that actually if the classifier uh puts",
    "start": "566320",
    "end": "570560"
  },
  {
    "text": "the real name column into the unknown",
    "start": "570560",
    "end": "574040"
  },
  {
    "text": "class that the cost of it is much higher",
    "start": "574040",
    "end": "577200"
  },
  {
    "text": "than for example misclassifying the",
    "start": "577200",
    "end": "579200"
  },
  {
    "text": "unknown class as the name",
    "start": "579200",
    "end": "581399"
  },
  {
    "text": "class yeah and in our experience we",
    "start": "581399",
    "end": "583640"
  },
  {
    "text": "found that actually C sensitive learning",
    "start": "583640",
    "end": "585640"
  },
  {
    "text": "performs much better than um class",
    "start": "585640",
    "end": "588720"
  },
  {
    "text": "resembling strategies uh but here",
    "start": "588720",
    "end": "591360"
  },
  {
    "text": "actually the other issue is still not",
    "start": "591360",
    "end": "593160"
  },
  {
    "text": "solved the issue of having um sparse",
    "start": "593160",
    "end": "596880"
  },
  {
    "text": "data right so I mean the problem look",
    "start": "596880",
    "end": "599680"
  },
  {
    "text": "you have 1 million rows but you get just",
    "start": "599680",
    "end": "602120"
  },
  {
    "text": "one feature Vector out of it because it",
    "start": "602120",
    "end": "604320"
  },
  {
    "text": "represents just one column and uh so",
    "start": "604320",
    "end": "607160"
  },
  {
    "text": "we're actually doing something not",
    "start": "607160",
    "end": "609240"
  },
  {
    "text": "really right here so how can we actually",
    "start": "609240",
    "end": "611000"
  },
  {
    "text": "harness this uh this crucial point that",
    "start": "611000",
    "end": "614440"
  },
  {
    "text": "we have actually big data and for this",
    "start": "614440",
    "end": "617880"
  },
  {
    "text": "purpose we found that bagging works",
    "start": "617880",
    "end": "619560"
  },
  {
    "text": "really well so in this sense that we",
    "start": "619560",
    "end": "622200"
  },
  {
    "text": "take this one column which has 1 million",
    "start": "622200",
    "end": "624399"
  },
  {
    "text": "rows and instead of uh uh constructing",
    "start": "624399",
    "end": "627760"
  },
  {
    "text": "just one feature Vector for for it uh so",
    "start": "627760",
    "end": "630560"
  },
  {
    "text": "we use bagging uh to build many smaller",
    "start": "630560",
    "end": "633680"
  },
  {
    "text": "samples by subsampling the big column",
    "start": "633680",
    "end": "636959"
  },
  {
    "text": "and uh we get um a much bigger amount of",
    "start": "636959",
    "end": "640480"
  },
  {
    "text": "feature vectors just from B column and",
    "start": "640480",
    "end": "643680"
  },
  {
    "text": "uh this uh approach also handles the",
    "start": "643680",
    "end": "646639"
  },
  {
    "text": "problem of class imbalance so in our",
    "start": "646639",
    "end": "648959"
  },
  {
    "text": "experiments actually bagging performs",
    "start": "648959",
    "end": "651040"
  },
  {
    "text": "much better than uh using class",
    "start": "651040",
    "end": "652880"
  },
  {
    "text": "resampling or uh cost sensitive",
    "start": "652880",
    "end": "656560"
  },
  {
    "text": "learning um yeah so now actually how",
    "start": "656560",
    "end": "660040"
  },
  {
    "text": "this schema matching process actually",
    "start": "660040",
    "end": "661959"
  },
  {
    "text": "looks like so the point is that the",
    "start": "661959",
    "end": "663839"
  },
  {
    "text": "schema matching is trained on examples",
    "start": "663839",
    "end": "666240"
  },
  {
    "text": "and user feedback and the idea is that",
    "start": "666240",
    "end": "668800"
  },
  {
    "text": "system improves as predictions get",
    "start": "668800",
    "end": "670839"
  },
  {
    "text": "corrected and as the system sees more",
    "start": "670839",
    "end": "673639"
  },
  {
    "text": "data so a bit more specific so at the",
    "start": "673639",
    "end": "676399"
  },
  {
    "text": "beginning the user supplies semantic",
    "start": "676399",
    "end": "678480"
  },
  {
    "text": "types he or she is interested in uh like",
    "start": "678480",
    "end": "682000"
  },
  {
    "text": "for example in this case name address",
    "start": "682000",
    "end": "684000"
  },
  {
    "text": "phone and email and then the user",
    "start": "684000",
    "end": "686120"
  },
  {
    "text": "provides their data set uh and what the",
    "start": "686120",
    "end": "689040"
  },
  {
    "text": "US also has to do is actually to label",
    "start": "689040",
    "end": "691160"
  },
  {
    "text": "some of those example data sets so say",
    "start": "691160",
    "end": "693839"
  },
  {
    "text": "which column is which semantic type and",
    "start": "693839",
    "end": "696639"
  },
  {
    "text": "then the system uh generates",
    "start": "696639",
    "end": "699880"
  },
  {
    "text": "predictions and then the user might just",
    "start": "699880",
    "end": "702760"
  },
  {
    "text": "automatically accept all the predictions",
    "start": "702760",
    "end": "704800"
  },
  {
    "text": "or actually correct the ones so it",
    "start": "704800",
    "end": "706959"
  },
  {
    "text": "depends on the uh system configuration",
    "start": "706959",
    "end": "709800"
  },
  {
    "text": "and then uh um this way we actually add",
    "start": "709800",
    "end": "712440"
  },
  {
    "text": "more data and the whole process",
    "start": "712440",
    "end": "715399"
  },
  {
    "text": "repeats uh so where can we actually use",
    "start": "715399",
    "end": "718399"
  },
  {
    "text": "now this schema match the way it's um",
    "start": "718399",
    "end": "720959"
  },
  {
    "text": "designed so first of all we can link and",
    "start": "720959",
    "end": "723120"
  },
  {
    "text": "connect the data and merge the different",
    "start": "723120",
    "end": "725480"
  },
  {
    "text": "data tables on the um on those semantic",
    "start": "725480",
    "end": "728560"
  },
  {
    "text": "types which we discovered uh then we can",
    "start": "728560",
    "end": "730959"
  },
  {
    "text": "actually uh provide some classwide",
    "start": "730959",
    "end": "733040"
  },
  {
    "text": "transforms so instead of specifying a",
    "start": "733040",
    "end": "735519"
  },
  {
    "text": "transformation per each column right we",
    "start": "735519",
    "end": "737880"
  },
  {
    "text": "can just say for example that we want",
    "start": "737880",
    "end": "739600"
  },
  {
    "text": "one formating um to be one formating",
    "start": "739600",
    "end": "742440"
  },
  {
    "text": "transformation to be applied to all",
    "start": "742440",
    "end": "744079"
  },
  {
    "text": "phone numbers uh the other thing is",
    "start": "744079",
    "end": "746480"
  },
  {
    "text": "actually we can now relabel columns",
    "start": "746480",
    "end": "748760"
  },
  {
    "text": "using the semantic types to some unified",
    "start": "748760",
    "end": "751839"
  },
  {
    "text": "naming and we can also label no header",
    "start": "751839",
    "end": "754560"
  },
  {
    "text": "data set so if you have a data set with",
    "start": "754560",
    "end": "756480"
  },
  {
    "text": "no column uh headers that's not a",
    "start": "756480",
    "end": "758959"
  },
  {
    "text": "problem for the schema matcher since we",
    "start": "758959",
    "end": "760600"
  },
  {
    "text": "still have those features which are",
    "start": "760600",
    "end": "761959"
  },
  {
    "text": "based on the content uh and but the most",
    "start": "761959",
    "end": "764959"
  },
  {
    "text": "interesting part at least for me is",
    "start": "764959",
    "end": "766959"
  },
  {
    "text": "actually that we can use now the schema",
    "start": "766959",
    "end": "768560"
  },
  {
    "text": "match as a component for further",
    "start": "768560",
    "end": "770160"
  },
  {
    "text": "semantic modeling so what do I mean by",
    "start": "770160",
    "end": "773600"
  },
  {
    "text": "semantic modeling so first of all",
    "start": "773600",
    "end": "775199"
  },
  {
    "text": "semantics is a very tricky concept and",
    "start": "775199",
    "end": "778120"
  },
  {
    "text": "it's because it's High subjective so I",
    "start": "778120",
    "end": "780600"
  },
  {
    "text": "will share with you some ideas actually",
    "start": "780600",
    "end": "782399"
  },
  {
    "text": "what I understand by semantic modeling",
    "start": "782399",
    "end": "785040"
  },
  {
    "text": "for the data sets so look we have now a",
    "start": "785040",
    "end": "788120"
  },
  {
    "text": "data table with five columns name birth",
    "start": "788120",
    "end": "791079"
  },
  {
    "text": "date city state and",
    "start": "791079",
    "end": "792680"
  },
  {
    "text": "workplace and our schema magic can tell",
    "start": "792680",
    "end": "795040"
  },
  {
    "text": "us that um the column name is about some",
    "start": "795040",
    "end": "797560"
  },
  {
    "text": "people's name right and City column",
    "start": "797560",
    "end": "800760"
  },
  {
    "text": "represents the names of the Cities but",
    "start": "800760",
    "end": "803199"
  },
  {
    "text": "the thing actually which we can't tell",
    "start": "803199",
    "end": "805560"
  },
  {
    "text": "from this data table what's the",
    "start": "805560",
    "end": "807639"
  },
  {
    "text": "connection between the person and the",
    "start": "807639",
    "end": "809120"
  },
  {
    "text": "the city so is it the city where the",
    "start": "809120",
    "end": "811399"
  },
  {
    "text": "person lives in is it the city where the",
    "start": "811399",
    "end": "813800"
  },
  {
    "text": "person was born in or is it the city",
    "start": "813800",
    "end": "816560"
  },
  {
    "text": "where the person Works in and there",
    "start": "816560",
    "end": "818079"
  },
  {
    "text": "might be maybe some other",
    "start": "818079",
    "end": "819880"
  },
  {
    "text": "variations and uh",
    "start": "819880",
    "end": "824160"
  },
  {
    "text": "so there are some relationships which",
    "start": "824160",
    "end": "826880"
  },
  {
    "text": "are implied between the columns and they",
    "start": "826880",
    "end": "830360"
  },
  {
    "text": "when we use relational schemas they are",
    "start": "830360",
    "end": "832160"
  },
  {
    "text": "implicit so we can't really see them",
    "start": "832160",
    "end": "834320"
  },
  {
    "text": "explicitly and this is then an issue",
    "start": "834320",
    "end": "837199"
  },
  {
    "text": "actually if we want to do some analysis",
    "start": "837199",
    "end": "838839"
  },
  {
    "text": "on the data to understand to better",
    "start": "838839",
    "end": "841360"
  },
  {
    "text": "understand what the data is actually",
    "start": "841360",
    "end": "842600"
  },
  {
    "text": "about we need actually to know about",
    "start": "842600",
    "end": "844519"
  },
  {
    "text": "those relationships between our columns",
    "start": "844519",
    "end": "847160"
  },
  {
    "text": "and this is where actually we need to",
    "start": "847160",
    "end": "848959"
  },
  {
    "text": "introduce something like graph-like",
    "start": "848959",
    "end": "852079"
  },
  {
    "start": "852000",
    "end": "960000"
  },
  {
    "text": "structure and uh we call it a semantic",
    "start": "852079",
    "end": "855399"
  },
  {
    "text": "model and now the idea is that our",
    "start": "855399",
    "end": "858279"
  },
  {
    "text": "schema match actually",
    "start": "858279",
    "end": "861240"
  },
  {
    "text": "um so the schema match it tells us only",
    "start": "861240",
    "end": "864519"
  },
  {
    "text": "how these columns get mapped into the",
    "start": "864519",
    "end": "867079"
  },
  {
    "text": "noes like that this is person's name and",
    "start": "867079",
    "end": "869160"
  },
  {
    "text": "location that City's name and content",
    "start": "869160",
    "end": "871120"
  },
  {
    "text": "that's phone",
    "start": "871120",
    "end": "873639"
  },
  {
    "text": "number but our schema mat has no way to",
    "start": "873759",
    "end": "876600"
  },
  {
    "text": "tell us what are the relationships",
    "start": "876600",
    "end": "878199"
  },
  {
    "text": "actually between these Concepts so and",
    "start": "878199",
    "end": "881199"
  },
  {
    "text": "the standard approach to introduce",
    "start": "881199",
    "end": "882800"
  },
  {
    "text": "semantics and to talk about semantics is",
    "start": "882800",
    "end": "884920"
  },
  {
    "text": "to use an ontology I mean you can also",
    "start": "884920",
    "end": "887519"
  },
  {
    "text": "think about it as a graph schema and uh",
    "start": "887519",
    "end": "890079"
  },
  {
    "text": "there are different ways actually where",
    "start": "890079",
    "end": "891440"
  },
  {
    "text": "this ontology can come from so it can be",
    "start": "891440",
    "end": "894320"
  },
  {
    "text": "either built up iteratively from",
    "start": "894320",
    "end": "896360"
  },
  {
    "text": "definitions so from those semantic types",
    "start": "896360",
    "end": "898920"
  },
  {
    "text": "um um if you have some experts they can",
    "start": "898920",
    "end": "902639"
  },
  {
    "text": "build some domain specific ontologies or",
    "start": "902639",
    "end": "905399"
  },
  {
    "text": "you can download the ontologies from the",
    "start": "905399",
    "end": "907440"
  },
  {
    "text": "semantic web there are really plentyful",
    "start": "907440",
    "end": "909320"
  },
  {
    "text": "of them there but it's a huge mess so um",
    "start": "909320",
    "end": "913160"
  },
  {
    "text": "yeah I wouldn't recommend actually using",
    "start": "913160",
    "end": "915079"
  },
  {
    "text": "maybe semantic but um not really very",
    "start": "915079",
    "end": "917639"
  },
  {
    "text": "practical uh so let's have a look a",
    "start": "917639",
    "end": "919759"
  },
  {
    "text": "closer look actually what an antology is",
    "start": "919759",
    "end": "921800"
  },
  {
    "text": "so overall this is quite a complex",
    "start": "921800",
    "end": "923759"
  },
  {
    "text": "structure but we're not interested like",
    "start": "923759",
    "end": "925880"
  },
  {
    "text": "in everything that exists and can be",
    "start": "925880",
    "end": "928480"
  },
  {
    "text": "specified in the onology there are three",
    "start": "928480",
    "end": "930560"
  },
  {
    "text": "main constructs which we need there and",
    "start": "930560",
    "end": "933399"
  },
  {
    "text": "that's basically what we call class node",
    "start": "933399",
    "end": "935920"
  },
  {
    "text": "and it represents some abstract concept",
    "start": "935920",
    "end": "938319"
  },
  {
    "text": "for example organization person place",
    "start": "938319",
    "end": "942040"
  },
  {
    "text": "then uh data nodes and those are",
    "start": "942040",
    "end": "944279"
  },
  {
    "text": "properties of the classes so like for",
    "start": "944279",
    "end": "946240"
  },
  {
    "text": "example person is described by the name",
    "start": "946240",
    "end": "948600"
  },
  {
    "text": "Age Passport number and so on and the",
    "start": "948600",
    "end": "951920"
  },
  {
    "text": "last bit uh is actually a relationship",
    "start": "951920",
    "end": "954360"
  },
  {
    "text": "between Concepts right so the links",
    "start": "954360",
    "end": "956160"
  },
  {
    "text": "between the class nodes",
    "start": "956160",
    "end": "960319"
  },
  {
    "text": "and now actually how can we build how",
    "start": "960440",
    "end": "963399"
  },
  {
    "text": "can we construct those semantic models",
    "start": "963399",
    "end": "966199"
  },
  {
    "text": "for our data sets so the idea now is",
    "start": "966199",
    "end": "968720"
  },
  {
    "text": "actually as input we have this",
    "start": "968720",
    "end": "970720"
  },
  {
    "text": "ontology and we have a set of uh known",
    "start": "970720",
    "end": "973680"
  },
  {
    "text": "semantic models for some of the data",
    "start": "973680",
    "end": "975920"
  },
  {
    "text": "sets so this is now the work which the",
    "start": "975920",
    "end": "977880"
  },
  {
    "text": "user still has to do and then the",
    "start": "977880",
    "end": "980199"
  },
  {
    "text": "question is can we generate the semantic",
    "start": "980199",
    "end": "981800"
  },
  {
    "text": "model for a new data set um I will not",
    "start": "981800",
    "end": "985560"
  },
  {
    "text": "and this problem actually is known let's",
    "start": "985560",
    "end": "988199"
  },
  {
    "text": "say in the database Theory Community as",
    "start": "988199",
    "end": "990160"
  },
  {
    "text": "rdb to rdf schema matching problem so",
    "start": "990160",
    "end": "992839"
  },
  {
    "text": "the point is that we are now matching",
    "start": "992839",
    "end": "995079"
  },
  {
    "text": "we're mapping actually relational",
    "start": "995079",
    "end": "996920"
  },
  {
    "text": "database to ADF and ADF this is uh a",
    "start": "996920",
    "end": "1000800"
  },
  {
    "text": "standard uh well maybe not standard but",
    "start": "1000800",
    "end": "1004000"
  },
  {
    "text": "yeah a rather common uh language which",
    "start": "1004000",
    "end": "1005920"
  },
  {
    "text": "is used to express ontologies so this is",
    "start": "1005920",
    "end": "1008560"
  },
  {
    "text": "uh I mean there are also ADF based craft",
    "start": "1008560",
    "end": "1011480"
  },
  {
    "text": "databases um yeah so if you want to look",
    "start": "1011480",
    "end": "1014639"
  },
  {
    "text": "up closer to look closer this problem so",
    "start": "1014639",
    "end": "1017399"
  },
  {
    "text": "you can search for ADB to of schema",
    "start": "1017399",
    "end": "1019399"
  },
  {
    "text": "mapping or",
    "start": "1019399",
    "end": "1020880"
  },
  {
    "text": "matching and um I will not go into much",
    "start": "1020880",
    "end": "1024160"
  },
  {
    "start": "1022000",
    "end": "1160000"
  },
  {
    "text": "detail actually how we solve this",
    "start": "1024160",
    "end": "1025678"
  },
  {
    "text": "problem but very roughly just to give",
    "start": "1025679",
    "end": "1028280"
  },
  {
    "text": "you the idea so we use our schema Mech",
    "start": "1028280",
    "end": "1031038"
  },
  {
    "text": "to map all possible semantic types for",
    "start": "1031039",
    "end": "1033438"
  },
  {
    "text": "columns onto the antology so first we",
    "start": "1033439",
    "end": "1036120"
  },
  {
    "text": "use the schema me to identify the",
    "start": "1036120",
    "end": "1037918"
  },
  {
    "text": "semantic types for the columns and then",
    "start": "1037919",
    "end": "1040079"
  },
  {
    "text": "those identified semantic types we map",
    "start": "1040079",
    "end": "1042438"
  },
  {
    "text": "them onto the antology onto the class",
    "start": "1042439",
    "end": "1044199"
  },
  {
    "text": "and data noes and then uh we need to",
    "start": "1044199",
    "end": "1047558"
  },
  {
    "text": "find most likely some semantic model and",
    "start": "1047559",
    "end": "1049960"
  },
  {
    "text": "what actually our semantic model is in",
    "start": "1049960",
    "end": "1051840"
  },
  {
    "text": "this case is a subgraph in this ontology",
    "start": "1051840",
    "end": "1055039"
  },
  {
    "text": "which covers match semantic types and",
    "start": "1055039",
    "end": "1057480"
  },
  {
    "text": "this is a graph problem as you",
    "start": "1057480",
    "end": "1059240"
  },
  {
    "text": "understand and uh in particular we",
    "start": "1059240",
    "end": "1061280"
  },
  {
    "text": "phrase it as a minimum cost time a tree",
    "start": "1061280",
    "end": "1063559"
  },
  {
    "text": "problem so this is a very rough idea and",
    "start": "1063559",
    "end": "1065840"
  },
  {
    "text": "then we do some graph magic and we get a",
    "start": "1065840",
    "end": "1067919"
  },
  {
    "text": "semantic model as an output and yeah so",
    "start": "1067919",
    "end": "1071400"
  },
  {
    "text": "what can you do now with this semantic",
    "start": "1071400",
    "end": "1072880"
  },
  {
    "text": "mod um firstly and most important",
    "start": "1072880",
    "end": "1075799"
  },
  {
    "text": "importantly you will get a better",
    "start": "1075799",
    "end": "1077760"
  },
  {
    "text": "understanding of your data but then",
    "start": "1077760",
    "end": "1079440"
  },
  {
    "text": "actually you can do some other cool",
    "start": "1079440",
    "end": "1081120"
  },
  {
    "text": "stuff with it um so some of the ideas",
    "start": "1081120",
    "end": "1083919"
  },
  {
    "text": "which actually came to our mind is that",
    "start": "1083919",
    "end": "1086080"
  },
  {
    "text": "you can do better entity resolution so",
    "start": "1086080",
    "end": "1089480"
  },
  {
    "text": "uh the thing about now this semantic",
    "start": "1089480",
    "end": "1091640"
  },
  {
    "text": "model is that you actually know what",
    "start": "1091640",
    "end": "1094240"
  },
  {
    "text": "kind of entities exist in your um in",
    "start": "1094240",
    "end": "1096880"
  },
  {
    "text": "your data so actually these class nodes",
    "start": "1096880",
    "end": "1099120"
  },
  {
    "text": "right like person City phone those are",
    "start": "1099120",
    "end": "1100880"
  },
  {
    "text": "your entities and then you also know by",
    "start": "1100880",
    "end": "1104039"
  },
  {
    "text": "which properties those entities are",
    "start": "1104039",
    "end": "1105720"
  },
  {
    "text": "described so you can actually design",
    "start": "1105720",
    "end": "1107760"
  },
  {
    "text": "your entity resolution",
    "start": "1107760",
    "end": "1109280"
  },
  {
    "text": "algorithms uh for those exact class",
    "start": "1109280",
    "end": "1112360"
  },
  {
    "text": "nodes using their properties so um the",
    "start": "1112360",
    "end": "1115840"
  },
  {
    "text": "other thing is that you can actually",
    "start": "1115840",
    "end": "1117159"
  },
  {
    "text": "integrate now your relational data into",
    "start": "1117159",
    "end": "1119080"
  },
  {
    "text": "a graph database or uh you can also uh",
    "start": "1119080",
    "end": "1123000"
  },
  {
    "text": "have much more sophisticated and more",
    "start": "1123000",
    "end": "1125200"
  },
  {
    "text": "accurate merging of your data sets and",
    "start": "1125200",
    "end": "1128480"
  },
  {
    "text": "uh the last thing is um you can do more",
    "start": "1128480",
    "end": "1131200"
  },
  {
    "text": "powerful search and let's have a closer",
    "start": "1131200",
    "end": "1134559"
  },
  {
    "text": "look actually what kind of search I'm in",
    "start": "1134559",
    "end": "1136400"
  },
  {
    "text": "here so uh the bit which I didn't",
    "start": "1136400",
    "end": "1138799"
  },
  {
    "text": "mentioned to you about theologist is",
    "start": "1138799",
    "end": "1140320"
  },
  {
    "text": "that you can actually have additional uh",
    "start": "1140320",
    "end": "1143200"
  },
  {
    "text": "uh so you can specify some uh particular",
    "start": "1143200",
    "end": "1146039"
  },
  {
    "text": "relationships between the class nodes uh",
    "start": "1146039",
    "end": "1148400"
  },
  {
    "text": "which actually uh allow you to build the",
    "start": "1148400",
    "end": "1151720"
  },
  {
    "text": "uh hierarchies of the classes so this is",
    "start": "1151720",
    "end": "1154240"
  },
  {
    "text": "the",
    "start": "1154240",
    "end": "1154919"
  },
  {
    "text": "so-called subclass",
    "start": "1154919",
    "end": "1158799"
  },
  {
    "text": "property and the point here is that if",
    "start": "1159960",
    "end": "1162280"
  },
  {
    "start": "1160000",
    "end": "1235000"
  },
  {
    "text": "you have a hierarchy then of classes",
    "start": "1162280",
    "end": "1164200"
  },
  {
    "text": "like that city is a subass of state and",
    "start": "1164200",
    "end": "1166200"
  },
  {
    "text": "state is a subass of country and then",
    "start": "1166200",
    "end": "1168360"
  },
  {
    "text": "you do the search for some information",
    "start": "1168360",
    "end": "1170520"
  },
  {
    "text": "within the country class so actually the",
    "start": "1170520",
    "end": "1172440"
  },
  {
    "text": "search can be then proceeded to the sub",
    "start": "1172440",
    "end": "1174760"
  },
  {
    "text": "classes and uh this is uh uh yeah this",
    "start": "1174760",
    "end": "1178480"
  },
  {
    "text": "is one particular theme which actually",
    "start": "1178480",
    "end": "1180440"
  },
  {
    "text": "the ontologist and the semantic mods can",
    "start": "1180440",
    "end": "1182240"
  },
  {
    "text": "help you with but then you can also",
    "start": "1182240",
    "end": "1184159"
  },
  {
    "text": "introduce some additional constraints in",
    "start": "1184159",
    "end": "1186280"
  },
  {
    "text": "your ontology uh like for example you",
    "start": "1186280",
    "end": "1188640"
  },
  {
    "text": "could say that a person should have just",
    "start": "1188640",
    "end": "1190600"
  },
  {
    "text": "one birth date I mean makes sense right",
    "start": "1190600",
    "end": "1193520"
  },
  {
    "text": "and uh and in this way you can actually",
    "start": "1193520",
    "end": "1196360"
  },
  {
    "text": "uh check for data consistency",
    "start": "1196360",
    "end": "1199720"
  },
  {
    "text": "so um yeah you can check actually",
    "start": "1199720",
    "end": "1202360"
  },
  {
    "text": "whether your data is consistent with",
    "start": "1202360",
    "end": "1205200"
  },
  {
    "text": "regard to those uh",
    "start": "1205200",
    "end": "1207840"
  },
  {
    "text": "constraints and as for the graph",
    "start": "1207840",
    "end": "1209880"
  },
  {
    "text": "database so yeah now the antology can",
    "start": "1209880",
    "end": "1211960"
  },
  {
    "text": "act as the intermediary between graph",
    "start": "1211960",
    "end": "1213880"
  },
  {
    "text": "database and relational databases so",
    "start": "1213880",
    "end": "1216440"
  },
  {
    "text": "it's not really necessary that you have",
    "start": "1216440",
    "end": "1218240"
  },
  {
    "text": "actually to upload your data to some",
    "start": "1218240",
    "end": "1220120"
  },
  {
    "text": "graph database but you can do now by",
    "start": "1220120",
    "end": "1222640"
  },
  {
    "text": "having this ontology you can now do",
    "start": "1222640",
    "end": "1224880"
  },
  {
    "text": "graph analytics and yeah so it functions",
    "start": "1224880",
    "end": "1228200"
  },
  {
    "text": "as a graph schema and Global schema of",
    "start": "1228200",
    "end": "1230880"
  },
  {
    "text": "your integrated data",
    "start": "1230880",
    "end": "1234120"
  },
  {
    "text": "sets um yeah so now let's just shortly",
    "start": "1234320",
    "end": "1238559"
  },
  {
    "start": "1235000",
    "end": "1362000"
  },
  {
    "text": "summarize what we've talked about so",
    "start": "1238559",
    "end": "1242320"
  },
  {
    "text": "far yeah so I started with the",
    "start": "1244440",
    "end": "1247039"
  },
  {
    "text": "relational schema matching and I",
    "start": "1247039",
    "end": "1249159"
  },
  {
    "text": "presented you how we can use the schema",
    "start": "1249159",
    "end": "1251320"
  },
  {
    "text": "match actually to uh put together",
    "start": "1251320",
    "end": "1254400"
  },
  {
    "text": "relational schemas and find semantically",
    "start": "1254400",
    "end": "1256720"
  },
  {
    "text": "similar columns across data sets",
    "start": "1256720",
    "end": "1259280"
  },
  {
    "text": "and then I went on and talked about uh",
    "start": "1259280",
    "end": "1262280"
  },
  {
    "text": "how we can use the schema match actually",
    "start": "1262280",
    "end": "1264200"
  },
  {
    "text": "to find now graphik stru schemas for",
    "start": "1264200",
    "end": "1267440"
  },
  {
    "text": "your for your data",
    "start": "1267440",
    "end": "1269960"
  },
  {
    "text": "so so the semantic modeling in uh allows",
    "start": "1269960",
    "end": "1273000"
  },
  {
    "text": "us not only to find semantically similar",
    "start": "1273000",
    "end": "1275520"
  },
  {
    "text": "columns but it also allows us to find",
    "start": "1275520",
    "end": "1277559"
  },
  {
    "text": "relationships between those",
    "start": "1277559",
    "end": "1279600"
  },
  {
    "text": "columns and uh yeah so there are really",
    "start": "1279600",
    "end": "1282400"
  },
  {
    "text": "lots of issues still which are open and",
    "start": "1282400",
    "end": "1286120"
  },
  {
    "text": "um if we talk about schema Magic so",
    "start": "1286120",
    "end": "1288880"
  },
  {
    "text": "there are several open questions which",
    "start": "1288880",
    "end": "1290840"
  },
  {
    "text": "are especially interesting for ra team",
    "start": "1290840",
    "end": "1293799"
  },
  {
    "text": "so the first one is actually about",
    "start": "1293799",
    "end": "1296679"
  },
  {
    "text": "Transformations and the complex column",
    "start": "1296679",
    "end": "1299039"
  },
  {
    "text": "matches like imagine you have a data",
    "start": "1299039",
    "end": "1301520"
  },
  {
    "text": "table um which has um a column full name",
    "start": "1301520",
    "end": "1306440"
  },
  {
    "text": "and another table has the column's first",
    "start": "1306440",
    "end": "1310120"
  },
  {
    "text": "name and second name right so you kind",
    "start": "1310120",
    "end": "1312880"
  },
  {
    "text": "of you need to do a transformation or",
    "start": "1312880",
    "end": "1316799"
  },
  {
    "text": "you have actually to match this uh",
    "start": "1316799",
    "end": "1319360"
  },
  {
    "text": "um it's a one to yeah one to two match",
    "start": "1319360",
    "end": "1322520"
  },
  {
    "text": "right so and the question here is",
    "start": "1322520",
    "end": "1324400"
  },
  {
    "text": "actually can we do that also in an",
    "start": "1324400",
    "end": "1326720"
  },
  {
    "text": "automatic way can we use actually",
    "start": "1326720",
    "end": "1328159"
  },
  {
    "text": "machine learning to help us find such uh",
    "start": "1328159",
    "end": "1330760"
  },
  {
    "text": "matches and such Transformations and uh",
    "start": "1330760",
    "end": "1333640"
  },
  {
    "text": "the other two uh questions are about",
    "start": "1333640",
    "end": "1336080"
  },
  {
    "text": "applications of semantic models in",
    "start": "1336080",
    "end": "1337919"
  },
  {
    "text": "entity resolution and in search so we're",
    "start": "1337919",
    "end": "1340640"
  },
  {
    "text": "still looking at some cool um ideas",
    "start": "1340640",
    "end": "1344000"
  },
  {
    "text": "actually how uh we can use semantic",
    "start": "1344000",
    "end": "1346159"
  },
  {
    "text": "models to improve and to make",
    "start": "1346159",
    "end": "1349120"
  },
  {
    "text": "uh entity resolution and search more",
    "start": "1349120",
    "end": "1352960"
  },
  {
    "text": "efficient so yeah that's it for my talk",
    "start": "1353039",
    "end": "1355600"
  },
  {
    "text": "thank you for your attention and you're",
    "start": "1355600",
    "end": "1357440"
  },
  {
    "text": "welcome with your questions",
    "start": "1357440",
    "end": "1361120"
  }
]
[
  {
    "text": "thank you good afternoon everybody uh I'm Anand and I'm today I'm speaking about a topic called Auto feature",
    "start": "7919",
    "end": "13679"
  },
  {
    "text": "engineering uh before we set off I would like to say that uh this is a work in progress so um some if you ask questions",
    "start": "13679",
    "end": "20800"
  },
  {
    "text": "there might be answers which are like we are still exploring so please bear with me from that context so um let's let me",
    "start": "20800",
    "end": "27640"
  },
  {
    "text": "set a context for this talk so essentially when you say feature engineering uh I'm exclusively concentrating on the classical machine",
    "start": "27640",
    "end": "34000"
  },
  {
    "text": "learning uh domain as opposed to something like deep learning wherein there's not strictly feature engineering it's in intrinsic to the model um it's",
    "start": "34000",
    "end": "42600"
  },
  {
    "text": "uh perhaps it comes with its own drawbacks like it's not explainable let's concentrate on the classical",
    "start": "42600",
    "end": "48120"
  },
  {
    "text": "machine learning aspect of feature engineering which is which is more about art of creating features from raw data",
    "start": "48120",
    "end": "54359"
  },
  {
    "text": "uh the good part about it is that it is explainable that means if someone comes and asks why this feature or can explain",
    "start": "54359",
    "end": "59440"
  },
  {
    "text": "this feature someone would be able to do it uh with the reasonable confidence uh there's also a use case for feature",
    "start": "59440",
    "end": "65720"
  },
  {
    "text": "Engineering in the domain of reporting in other words a feature can be used more like a report although the terminology can can be debated but",
    "start": "65720",
    "end": "72560"
  },
  {
    "text": "essentially it is used also in the context of a reporting construct uh and it's expensive uh when",
    "start": "72560",
    "end": "79560"
  },
  {
    "text": "when you have a platform which runs thousands of jobs every day uh uh and these jobs uh require uh this data sets",
    "start": "79560",
    "end": "87360"
  },
  {
    "text": "really big data plat uh data sets that need to be mind for a feature that's when it becomes costly and it's actually",
    "start": "87360",
    "end": "94000"
  },
  {
    "text": "an art to get it right so let's look at the typical life cycle of a feature right first you the",
    "start": "94000",
    "end": "100920"
  },
  {
    "text": "business comes up with requirements and there's a huge process around collecting the data and and cleansing it and making",
    "start": "100920",
    "end": "106119"
  },
  {
    "text": "ready uh wherein we then step into the design phase wherein a person or",
    "start": "106119",
    "end": "111399"
  },
  {
    "text": "business analyst or a data scientist starts exploring and a hypothesis perhaps iteratively uh and does a lot of",
    "start": "111399",
    "end": "117360"
  },
  {
    "text": "other things like pre-processing uh for example imputing the data data sets and there's also a domain driven aspect to",
    "start": "117360",
    "end": "123640"
  },
  {
    "text": "it when I say future engineering uh the domain Specialists spend a lot of their brain cycles and getting the right",
    "start": "123640",
    "end": "130039"
  },
  {
    "text": "features that are highly domain specific um and also they also do things like",
    "start": "130039",
    "end": "135160"
  },
  {
    "text": "turning the feature into something that is more amable to a modeling exercise uh after this step uh apart from that in",
    "start": "135160",
    "end": "143040"
  },
  {
    "text": "the design phase there are also practical issues like you know um uh from a governance perspective people",
    "start": "143040",
    "end": "149120"
  },
  {
    "text": "might want to discusses whether a feature can be used as an input to build other features primarily because it's",
    "start": "149120",
    "end": "154640"
  },
  {
    "text": "ethical or non-ethical kind of use cases there's also this interesting lens wherein pii access to data Securities um",
    "start": "154640",
    "end": "161840"
  },
  {
    "text": "data security forms and angle to it wherein to even get access to the data set a data scientist has to be approved",
    "start": "161840",
    "end": "167680"
  },
  {
    "text": "for data access which takes perhaps a lot of checks and bonds once all these pH uh steps are",
    "start": "167680",
    "end": "173800"
  },
  {
    "text": "cleared in the design phase then we land in the build phase where in typically the engineering ml engineering folks",
    "start": "173800",
    "end": "178840"
  },
  {
    "text": "come in they try try to optimize this from a realtime versus batch perspective uh they try to see if the feature can be",
    "start": "178840",
    "end": "185840"
  },
  {
    "text": "needs to be actually persisted or it's runtime computed or you know how how do we manage the exactly L one semantics of",
    "start": "185840",
    "end": "192000"
  },
  {
    "text": "this feature uh and how how to tame the latencies if it's a fraud system you end you end up uh you know tuning for",
    "start": "192000",
    "end": "199400"
  },
  {
    "text": "latencies in terms of feature engineering and there also a lot of engineering constructs around uh the",
    "start": "199400",
    "end": "204799"
  },
  {
    "text": "sync which is itself used to store this features uh and you uh explicit use cases exist where you're bringing a",
    "start": "204799",
    "end": "210760"
  },
  {
    "text": "feature for the first time you have to backfill your store which is which is which is uh serving as the serving store",
    "start": "210760",
    "end": "216519"
  },
  {
    "text": "for your say for your streaming use cases uh and that also requires some build as well and there's also a",
    "start": "216519",
    "end": "222720"
  },
  {
    "text": "correction cycle sometimes which might come in basing on the use case the fourth lens to this lifetime",
    "start": "222720",
    "end": "228599"
  },
  {
    "text": "feature is the governance aspect of it uh people typically would like uh lineage to be captured as part of the",
    "start": "228599",
    "end": "233760"
  },
  {
    "text": "feature right I mean how did I arrive at this feature what contributed to this feature and uh what is the uh impact",
    "start": "233760",
    "end": "239400"
  },
  {
    "text": "analysis is if I change this feature and how do I monitor the decay of this feature and how do I expire this feature",
    "start": "239400",
    "end": "244599"
  },
  {
    "text": "these are all questions that might be uh that might need you know a governance lens to",
    "start": "244599",
    "end": "250560"
  },
  {
    "text": "it this as as as I was saying this this this cycle is a very costly one and the question here is can we reduce the cost",
    "start": "250560",
    "end": "257560"
  },
  {
    "text": "of this entire cycle uh possibly governing better and also risk cases better and maintain it better that's",
    "start": "257560",
    "end": "263720"
  },
  {
    "text": "that's the central construct of this talk the whole talk I'll try to use a example schema schema just to provide",
    "start": "263720",
    "end": "270759"
  },
  {
    "text": "the context uh here is the simple uh representation of the schema there are four tables there's a customer table a sence table a products table and a",
    "start": "270759",
    "end": "277600"
  },
  {
    "text": "transactions table representing perhaps something like a mini shopping cart it's not very fancy as you can see a few",
    "start": "277600",
    "end": "282840"
  },
  {
    "text": "columns per per entity in fact it's not more than total number of columns do not exist more than uh 15 or 16 and uh the",
    "start": "282840",
    "end": "291960"
  },
  {
    "text": "uh there is a primary key for in key relationship there uh with with this I'll just run a small demo I know demos",
    "start": "291960",
    "end": "298720"
  },
  {
    "text": "are not good for a talk but I I'll I'll see if I can do some justice so that we can uh we can quickly go through this",
    "start": "298720",
    "end": "305600"
  },
  {
    "text": "just to show it in action and then provide a context so here is a customer table with just four entries a products",
    "start": "305600",
    "end": "311000"
  },
  {
    "text": "table with two entries a sessions table with uh say eight entries and a transaction stable with just uh just 12",
    "start": "311000",
    "end": "318160"
  },
  {
    "text": "entries I believe and I the the algorithm kicks in by just when I hit",
    "start": "318160",
    "end": "323319"
  },
  {
    "text": "the last enter keyboard and it mined around 429 features for the customer",
    "start": "323319",
    "end": "328880"
  },
  {
    "text": "table so essentially the algorithm asks what is the entity you want to enhance features for and it spits out a semantic",
    "start": "328880",
    "end": "337600"
  },
  {
    "text": "representation of the feature as you can see these are all column names it's I can't beautify it because it's 429",
    "start": "337600",
    "end": "343520"
  },
  {
    "text": "columns so that's the back maximum I can do but essentially these are names of the columns that represents new features that are mined in in this in this couple",
    "start": "343520",
    "end": "351080"
  },
  {
    "text": "of seconds as as as you can see the there's a little bit of um there might",
    "start": "351080",
    "end": "356160"
  },
  {
    "text": "be too many questions in the mind and this I'll continue in explaining how this how this how this actually happens",
    "start": "356160",
    "end": "361400"
  },
  {
    "text": "under the hood right before we do that I'll I'll step into take a sample sample",
    "start": "361400",
    "end": "367599"
  },
  {
    "text": "features and the semantic meanings which are displayed on the on the console there right I took a sample uh first one",
    "start": "367599",
    "end": "373080"
  },
  {
    "text": "uh is uh representing the maximum of average print across each sessions of a customer that's what the semantic",
    "start": "373080",
    "end": "379639"
  },
  {
    "text": "meaning of one of the 429 features represented just by using those 15 columns and there are 429 such of them",
    "start": "379639",
    "end": "386599"
  },
  {
    "text": "uh the other example is uh the number of unique wig days that the customer shops and that is the lower uh left corner of",
    "start": "386599",
    "end": "392560"
  },
  {
    "text": "of the transactions table if if you run the same algorithm on the transaction table that could be one of the hundreds of uh features that are",
    "start": "392560",
    "end": "399080"
  },
  {
    "text": "emitted the top right talks about a feature that captures the minimum number of unique products that were purchased",
    "start": "399080",
    "end": "405759"
  },
  {
    "text": "in sessions with most frequent number of transactions so as you can see this algorithm is not too simple it's not",
    "start": "405759",
    "end": "413120"
  },
  {
    "text": "just you know uh simple mix and match or a priation model it's actually do it seems to be doing something interesting",
    "start": "413120",
    "end": "419039"
  },
  {
    "text": "under the and so on and so forth we can discuss all the 429 features if you have time but essentially that's a",
    "start": "419039",
    "end": "425360"
  },
  {
    "text": "sampling now I'll walk into the algorithm itself how how does it mine these features right and the the beauty",
    "start": "425360",
    "end": "431759"
  },
  {
    "text": "of this algorithm is it's it's a very simple algorithm very very simplistic um and it's written by an MIT uh uh set of",
    "start": "431759",
    "end": "438919"
  },
  {
    "text": "couple of MIT folks and it works on the concept of uh three types of features a",
    "start": "438919",
    "end": "444639"
  },
  {
    "text": "direct feature uh an aggregation feature and a transform feature okay this this slide talks about a direct feature where",
    "start": "444639",
    "end": "450879"
  },
  {
    "text": "in essentially a new feature is built by looking at relationship wherein it's called a forward relationship where you",
    "start": "450879",
    "end": "456840"
  },
  {
    "text": "can you simply join the two tables and get a new feature by inheriting the feature column from the previous one",
    "start": "456840",
    "end": "464039"
  },
  {
    "text": "right so in this example there's a products table written in blue and an order table which written in yellow and",
    "start": "464039",
    "end": "470000"
  },
  {
    "text": "by applying a simple join the uh the order table has got product a new column called Product and price that's that's",
    "start": "470000",
    "end": "476360"
  },
  {
    "text": "that's that's an example of a direct feature right the second type of feature that we're talking about today is called as an",
    "start": "476360",
    "end": "482840"
  },
  {
    "text": "aggregation feature wherein uh it's a it uses the relational model but in a really bit more complex uh way it tries",
    "start": "482840",
    "end": "489360"
  },
  {
    "text": "to build a new feature by applying aggregation functions using the relational model so here in this example",
    "start": "489360",
    "end": "495440"
  },
  {
    "text": "there's an order table again and uh there's uh from the product price new",
    "start": "495440",
    "end": "500560"
  },
  {
    "text": "column which came in I can apply a sum function sum and group by functions on top of it uh to to",
    "start": "500560",
    "end": "507440"
  },
  {
    "text": "actually to to get a new feature sum of the product price or or or equalent",
    "start": "507440",
    "end": "514880"
  },
  {
    "text": "right the third example feature is wherein you don't do any joints but you just mine the current row and get a new",
    "start": "514880",
    "end": "522279"
  },
  {
    "text": "feature that means if you say for example the order date as a column I can",
    "start": "522279",
    "end": "527800"
  },
  {
    "text": "mine a new feature called month of the order date that basically is looking at the current not doing any joints and",
    "start": "527800",
    "end": "532920"
  },
  {
    "text": "then it's getting that's that's a basic Foundation right so these are the very simplest most basic Foundation definitions of the feature and the",
    "start": "532920",
    "end": "538880"
  },
  {
    "text": "algorithm what it does is it simply Stacks them it it basically works out all the",
    "start": "538880",
    "end": "545240"
  },
  {
    "text": "input it needs is the relational model across these entities and then it builds a relationship by stacking the concept",
    "start": "545240",
    "end": "550959"
  },
  {
    "text": "and that's how it's able to mine 429 features in a short amount of time right",
    "start": "550959",
    "end": "556839"
  },
  {
    "text": "the algorithm might look very very simple right there's nothing data science in here there's there's nothing um fancy it's a very simplistic model",
    "start": "556839",
    "end": "563160"
  },
  {
    "text": "and the beauty seems to be that it's it's it's it's seems to be spitting out some interesting um uh",
    "start": "563160",
    "end": "569760"
  },
  {
    "text": "features now we saw the algorithm we saw a small demo I'll walk into the design phase constructs of what how we can use",
    "start": "569760",
    "end": "576560"
  },
  {
    "text": "this algorithm in a more practical sense right a to example is one thing but how can I take this algorithm and and use it",
    "start": "576560",
    "end": "581839"
  },
  {
    "text": "in a more practical sense uh under the hood the algorithm uses the underlying",
    "start": "581839",
    "end": "588160"
  },
  {
    "text": "metadata to form uh to to mine new features for example if there's a date",
    "start": "588160",
    "end": "593839"
  },
  {
    "text": "time column in in the aut date table what it has done is it knows that it can apply a Time function on the daytime",
    "start": "593839",
    "end": "600000"
  },
  {
    "text": "column and hence the month concept got mined but it does not apply month on for",
    "start": "600000",
    "end": "605399"
  },
  {
    "text": "for example transaction amount though it's a number so essentially the LI the the the library has an intrinsic",
    "start": "605399",
    "end": "611800"
  },
  {
    "text": "understanding of the meta types metadata types provided the metadata comes from an external configuration",
    "start": "611800",
    "end": "616839"
  },
  {
    "text": "element it also knows how to handle categorical values right for example number of unique instances of a",
    "start": "616839",
    "end": "622240"
  },
  {
    "text": "categorical value time Deltas ID lat long zip codes and Country and the list is increasing in fact this this version",
    "start": "622240",
    "end": "627959"
  },
  {
    "text": "of the library is still in it fancy. 7 version uh just recently released and it's the list of metadata types uh is",
    "start": "627959",
    "end": "634560"
  },
  {
    "text": "increasing as a support as we speak uh here is another uh example of",
    "start": "634560",
    "end": "641839"
  },
  {
    "text": "how we can uh enhance this library to to meet practical use cases us as data",
    "start": "641839",
    "end": "647160"
  },
  {
    "text": "scientists might be doing a lot more um uh mining of features based on the",
    "start": "647160",
    "end": "653079"
  },
  {
    "text": "domain for example uh let's say there's a transaction amount column and you guys have decided okay okay I know what an",
    "start": "653079",
    "end": "660040"
  },
  {
    "text": "expensive purchase looks like what is an inexpensive purchase and what is not uh what is what is neither of these two or",
    "start": "660040",
    "end": "666480"
  },
  {
    "text": "maybe something like rounded to the next uh 10 multiple of 10 now this the bare",
    "start": "666480",
    "end": "671560"
  },
  {
    "text": "algorithm that we saw earlier might not mine this domain specific understanding",
    "start": "671560",
    "end": "676839"
  },
  {
    "text": "right but what it allows you is defining a new seed feature which is like a you",
    "start": "676839",
    "end": "682279"
  },
  {
    "text": "know artificial feature that you can introduce into the algorithm itself so that you can use the mining uh concept",
    "start": "682279",
    "end": "689560"
  },
  {
    "text": "actually to use those subdomain constructs in this example there's a transaction ID and the transaction",
    "start": "689560",
    "end": "694600"
  },
  {
    "text": "amount written in blue in the same table you could Define three new columns on",
    "start": "694600",
    "end": "699839"
  },
  {
    "text": "based on the transaction amount like if amount is greater than 25 I as a data scientist will Define it as an expensive",
    "start": "699839",
    "end": "706000"
  },
  {
    "text": "transaction or or a costly product that's being purchased and so on and so forth and here is a uh interesting thing",
    "start": "706000",
    "end": "712920"
  },
  {
    "text": "that comes out of this algorithm right you see number of features as you increase the number of seeds this this",
    "start": "712920",
    "end": "718720"
  },
  {
    "text": "new features are called seed features and as you increase the number of features you'll see that the number of features that are get getting emed also",
    "start": "718720",
    "end": "725160"
  },
  {
    "text": "increases because the base algorithm is taking them them as base inputs right",
    "start": "725160",
    "end": "730200"
  },
  {
    "text": "and there's also the the the depth of the stacking decides the number of features that are generated another",
    "start": "730200",
    "end": "735639"
  },
  {
    "text": "interesting observation here you can see that uh it's basically since it is a seed feature it applied the perc true as",
    "start": "735639",
    "end": "743360"
  },
  {
    "text": "as an additional uh aggregation function on top of it to to get a new new",
    "start": "743360",
    "end": "749279"
  },
  {
    "text": "interpretation to this new column uh while seeding features what we",
    "start": "749279",
    "end": "756079"
  },
  {
    "text": "saw earlier uh tends to apply on the entire transaction amount column that",
    "start": "756079",
    "end": "761320"
  },
  {
    "text": "means whatever definition you define as inxp or inexpensive or expensive it's taking all the values of the column to",
    "start": "761320",
    "end": "768160"
  },
  {
    "text": "to to to to M the new new interpretations but there might be use cases where in you guys might want to um",
    "start": "768160",
    "end": "775560"
  },
  {
    "text": "uh use a subset of the data uh distribution to Define a new feature for example in the previous there's a",
    "start": "775560",
    "end": "781800"
  },
  {
    "text": "session table and I would like to uh uh create a new feature based on a",
    "start": "781800",
    "end": "787760"
  },
  {
    "text": "foundational block building block of based on the concept of a desktop in this construct what you're",
    "start": "787760",
    "end": "793839"
  },
  {
    "text": "doing is you are saying I want to define a new base feature which will be used in stacking and Mining in the core algorithm and you say the new feature",
    "start": "793839",
    "end": "801079"
  },
  {
    "text": "base version definition is on based on the notion of a desktop similarly you can define something else like iPhone or",
    "start": "801079",
    "end": "808079"
  },
  {
    "text": "Galaxy and what the algorithm will do is it will choose a subset of the rows of your column instead of all the all the",
    "start": "808079",
    "end": "813959"
  },
  {
    "text": "all the all the rows in the column in the previous example and then use that as a foundation for your building um",
    "start": "813959",
    "end": "820399"
  },
  {
    "text": "building principle that's how it so essentially the difference is it cuts horizontally and the earlier one um more",
    "start": "820399",
    "end": "825839"
  },
  {
    "text": "like uh does not uh differentiate it acts on all columns and this is I think another very",
    "start": "825839",
    "end": "832839"
  },
  {
    "text": "interesting uh nature of this algorithm which we are um uh looking into right so",
    "start": "832839",
    "end": "838880"
  },
  {
    "text": "you might be wondering hey this is all fine this is a SQL World um but there are many use cases wherein feature",
    "start": "838880",
    "end": "844680"
  },
  {
    "text": "engineering could apply to non-sql or or or or or non um pipeline align principle",
    "start": "844680",
    "end": "852959"
  },
  {
    "text": "for example let's take the case of there's a case data set wherein there's a case ID case type blah blah blah but",
    "start": "852959",
    "end": "859839"
  },
  {
    "text": "interestingly you also have comments on a case and now how can I define new features on a pure textual data right",
    "start": "859839",
    "end": "866959"
  },
  {
    "text": "the previous example some average minimums uniques all these make sense with numbers or some somewhat",
    "start": "866959",
    "end": "872560"
  },
  {
    "text": "categorical or zip codes they make sense but how do I do new mind new features from comments I as a data scientist",
    "start": "872560",
    "end": "879160"
  },
  {
    "text": "might do intelligent things to get a new column for comments but how do I plug in into the algorithm so what the algorithm",
    "start": "879160",
    "end": "885880"
  },
  {
    "text": "provides is it gives you a mechanism to inject new function definitions so I can",
    "start": "885880",
    "end": "891480"
  },
  {
    "text": "to your right you can you can see I plugged in an additional module based on an analytic analytic python library and",
    "start": "891480",
    "end": "898240"
  },
  {
    "text": "hence I I use that as a foundational building block for the algorithm and the algorithm can spit new features using",
    "start": "898240",
    "end": "904880"
  },
  {
    "text": "the textual analysis components for example I can I can make it act on the comments column and then uh do some",
    "start": "904880",
    "end": "910440"
  },
  {
    "text": "interesting things but these these are all the foundational blocks but I see a lot of",
    "start": "910440",
    "end": "916680"
  },
  {
    "text": "issues with this Library as it stands today the major issue I see is um that it it's actually resulting in fature",
    "start": "916680",
    "end": "922759"
  },
  {
    "text": "explosion like 429 features out of 15 columns in 2 seconds is fine but the pro",
    "start": "922759",
    "end": "929639"
  },
  {
    "text": "the reality is it'll actually result in an explosion of features here is a simple uh uh representation of the",
    "start": "929639",
    "end": "935759"
  },
  {
    "text": "numbers which I did experiments on the first example with the Dem example we saw is named mock customers and the",
    "start": "935759",
    "end": "941399"
  },
  {
    "text": "second data set is the flight data set the trip details data set that you typically encounter in most of the you",
    "start": "941399",
    "end": "946759"
  },
  {
    "text": "know mock uh sorry experimental data sets that you get in any machine Line library the third data set is the retail",
    "start": "946759",
    "end": "952199"
  },
  {
    "text": "customer library from UCI and these number of features in these are less than 25 by the way the UCI thing is",
    "start": "952199",
    "end": "959240"
  },
  {
    "text": "uh retail data set on the last the last four entities there represent the ucci data set and they are mostly around um",
    "start": "959240",
    "end": "966720"
  },
  {
    "text": "not more than 25 to 30 columns across the four tables uh the flights data set the number of columns are even lesser 15",
    "start": "966720",
    "end": "973600"
  },
  {
    "text": "but you will see the the the sorry other way around uh you'll see the number of columns the number of new features that",
    "start": "973600",
    "end": "979639"
  },
  {
    "text": "are generated are are pretty pretty high or the order of 4,000 and hence the problem of feature explosion if you use",
    "start": "979639",
    "end": "985480"
  },
  {
    "text": "this Library so assuming that we we we uh we Sol the",
    "start": "985480",
    "end": "992959"
  },
  {
    "text": "feature explosion aspects of the library uh and keep it aside for some moment and and then the other aspect the other",
    "start": "992959",
    "end": "998680"
  },
  {
    "text": "problem that will arise with this um with this library is that given a large",
    "start": "998680",
    "end": "1003880"
  },
  {
    "text": "big data set uh problem space how can I essentially distribute the feature generation as a as a you know",
    "start": "1003880",
    "end": "1010440"
  },
  {
    "text": "distributed uh Computing Paradigm here is an uh example representation of how you can use the library to generate",
    "start": "1010440",
    "end": "1016800"
  },
  {
    "text": "features in parallel when I say generate features I'm talking about creation of the values of the feature in the past",
    "start": "1016800",
    "end": "1023680"
  },
  {
    "text": "few minutes we're talking about the semantic meaning of new feature now I'm talking about generating a value which represents that feature and I want to do",
    "start": "1023680",
    "end": "1030038"
  },
  {
    "text": "it in parallel because it's a very large data set that is the context I'm talking about and the way to do it is you basically make sure you partition your",
    "start": "1030039",
    "end": "1036880"
  },
  {
    "text": "data set obviously that's the way you solve a problem but by when we say partition how do you partition the data set the way the the algorithm can work",
    "start": "1036880",
    "end": "1044480"
  },
  {
    "text": "nicely is if you can choose to partition your data set so so that all related uh",
    "start": "1044480",
    "end": "1050559"
  },
  {
    "text": "tables to the primary entity are in a single partition in this example you have uh blacks and light light Blues in",
    "start": "1050559",
    "end": "1057280"
  },
  {
    "text": "one table uh the lightish blue and the dark blue and purples in one table and the greens",
    "start": "1057280",
    "end": "1063480"
  },
  {
    "text": "and the dark yellows on the third table now assuming that the blacks and purples and dark yellows are one",
    "start": "1063480",
    "end": "1070840"
  },
  {
    "text": "related partition data sets make sure that all of them sit in a one single data set partition or hdfs partition or",
    "start": "1070840",
    "end": "1076919"
  },
  {
    "text": "whatever your distributed store is and then you can run the uh feature generation algorithm in parallel to",
    "start": "1076919",
    "end": "1082280"
  },
  {
    "text": "generate values for in in an accurate way and hence the algorithm itself is",
    "start": "1082280",
    "end": "1088440"
  },
  {
    "text": "distributable um so the main challenge that we have today if if we were to mine this this a ofing use this autof",
    "start": "1088440",
    "end": "1095880"
  },
  {
    "text": "engineering library to to generate new features is uh basically uh it's a computer intensive challenge as I see it",
    "start": "1095880",
    "end": "1102679"
  },
  {
    "text": "and that's because uh the feature generation process itself takes a lot of",
    "start": "1102679",
    "end": "1107960"
  },
  {
    "text": "comput but what it is uh resulting in is a feature selection phase is getting really really uh computer intensive and",
    "start": "1107960",
    "end": "1114960"
  },
  {
    "text": "so uh hence uh we can easily say that this algorithm though it's reducing the cost for a human to develop new features",
    "start": "1114960",
    "end": "1123080"
  },
  {
    "text": "it might introduce additional cost as compared to your old cost models from in terms of selecting the best features",
    "start": "1123080",
    "end": "1129240"
  },
  {
    "text": "because feature selection becomes a really intensive process it's it's it's you know sub selecting thousands uh from",
    "start": "1129240",
    "end": "1134440"
  },
  {
    "text": "from a thousand set of features right but that's not to be worried given the human cost is always higher than compute",
    "start": "1134440",
    "end": "1140880"
  },
  {
    "text": "cost nowadays given all many of you guys must have worked on cloud infrastructures that might be a compelling option and hence the and",
    "start": "1140880",
    "end": "1147640"
  },
  {
    "text": "Hance the you know beauty of this algorithm making practical sense in these days now we'll go the these are all",
    "start": "1147640",
    "end": "1156360"
  },
  {
    "text": "problems that I think we can uh tweaks or or the library patterns that we can use to design new features I'm now",
    "start": "1156360",
    "end": "1163720"
  },
  {
    "text": "moving into how we can how we can solve the build related or engineering related",
    "start": "1163720",
    "end": "1169080"
  },
  {
    "text": "issues when we when we uh you know uh uh implement this this library in into a",
    "start": "1169080",
    "end": "1174880"
  },
  {
    "text": "production phase right the first thing we realized after after exploring this library is that it's it's got so many um",
    "start": "1174880",
    "end": "1182200"
  },
  {
    "text": "uh hard to pass through uh in terms of engineering the first thing that we uh realize is of course the the blackbox",
    "start": "1182200",
    "end": "1189960"
  },
  {
    "text": "nature of the um feature itself right it has it has spit out 429 features but how",
    "start": "1189960",
    "end": "1196400"
  },
  {
    "text": "can you make someone explain any feature that out of the 429 it's it's difficult because it's an",
    "start": "1196400",
    "end": "1202320"
  },
  {
    "text": "algorithm that spit out and it's so it looks so complex even the first slide we saw the depth is four and it I had to",
    "start": "1202320",
    "end": "1208440"
  },
  {
    "text": "write four lines of text or three lines of text to describe the feature that that's me after spending you know a",
    "start": "1208440",
    "end": "1213840"
  },
  {
    "text": "couple of hours or half an hour per feature to understand how it mapped and the crosschecking my interpretation is",
    "start": "1213840",
    "end": "1219000"
  },
  {
    "text": "right right so the first challenge is um how do I interpret the feature and hence",
    "start": "1219000",
    "end": "1224200"
  },
  {
    "text": "we we have the notion of extracting a semantic meaning out of this feature is a first Challenge from a build or or",
    "start": "1224200",
    "end": "1230720"
  },
  {
    "text": "a productionize phase and we have done some experiments in this in this regard and we uh we were able to say",
    "start": "1230720",
    "end": "1236760"
  },
  {
    "text": "confidently that you know we can we can use the data structures that this Library exposes to extract the semantic",
    "start": "1236760",
    "end": "1242480"
  },
  {
    "text": "meaning of what how the algo work to define a new feature for example it exposes that I I use this as a this",
    "start": "1242480",
    "end": "1248679"
  },
  {
    "text": "direct feature as an intermediate step for the next level and Next Level and so forth by using those data structures at run time we're able to uh get the",
    "start": "1248679",
    "end": "1255880"
  },
  {
    "text": "semantic meaning out of this um these features other interesting thing that we",
    "start": "1255880",
    "end": "1260919"
  },
  {
    "text": "could solve for using this feature is um using more related to security and governance right so if you if I were to",
    "start": "1260919",
    "end": "1268600"
  },
  {
    "text": "ask a human to develop a new feature he we could ask him or her to say hey please don't use this feature because",
    "start": "1268600",
    "end": "1274840"
  },
  {
    "text": "it's ethically not right to use this feature in this context but how do I do this when we automate things and hence",
    "start": "1274840",
    "end": "1281400"
  },
  {
    "text": "this Library we can use something like in the algorithm we can say here I don't want you to consider this path or",
    "start": "1281400",
    "end": "1287600"
  },
  {
    "text": "suppress this path when you're building your features and hence I can prevent a feature being used for a certain use",
    "start": "1287600",
    "end": "1293880"
  },
  {
    "text": "case from by means of configuration that means if I hook this algorithm um framework around this algorithm to look",
    "start": "1293880",
    "end": "1299799"
  },
  {
    "text": "into a metadata system to see if a feature is allowed I or not allowed I can make it suppress generation of new",
    "start": "1299799",
    "end": "1306080"
  },
  {
    "text": "features it also can solve things related to Providence and controls um there are talks today around Provence",
    "start": "1306080",
    "end": "1312840"
  },
  {
    "text": "and uh reproducibility kind of constructs um this this this by by",
    "start": "1312840",
    "end": "1318600"
  },
  {
    "text": "codifying the feature engineering generation process we are able to provide a more reliable Providence to",
    "start": "1318600",
    "end": "1325559"
  },
  {
    "text": "the entire uh to the entire Pipeline and data access security might also be a byproduct because once humans are not",
    "start": "1325559",
    "end": "1332240"
  },
  {
    "text": "required to mine features perhaps you don't need to work on pii regulat access control approvals and all these uh",
    "start": "1332240",
    "end": "1339159"
  },
  {
    "text": "strong checkpoints which come against data that's I think is an interesting byproduct of this approach and of course",
    "start": "1339159",
    "end": "1344480"
  },
  {
    "text": "you can do better CCD controls on it in the in the sense that if you if you see a feature being used for a certain use",
    "start": "1344480",
    "end": "1350039"
  },
  {
    "text": "case uh and you can break a build if it is not allowed by means of by means of checking against a metadata",
    "start": "1350039",
    "end": "1356320"
  },
  {
    "text": "system uh what codifying of this feature Engineering Process also results is is",
    "start": "1356320",
    "end": "1364200"
  },
  {
    "text": "better integration with lineage and metadata systems if you work in data pipelines you must have realized that",
    "start": "1364200",
    "end": "1369640"
  },
  {
    "text": "lineage is a big thing nowadays and and uh you know metadata seems to be uh",
    "start": "1369640",
    "end": "1375880"
  },
  {
    "text": "seems to be gaining as the most foundational thing that you would need in a big data Enterprise nowadays and uh",
    "start": "1375880",
    "end": "1381159"
  },
  {
    "text": "by codifying this feature engineering uh approach what we were able to uh do is",
    "start": "1381159",
    "end": "1387120"
  },
  {
    "text": "extract a rich ton of Rich amount of metadata both for lineage and for normal",
    "start": "1387120",
    "end": "1392360"
  },
  {
    "text": "metadata constructs for example you can see on the top I could I could extract that there were 24 nodes in this um uh",
    "start": "1392360",
    "end": "1398600"
  },
  {
    "text": "in this relational model U the the primary columns raw columns but the interesting Pieces come in the later",
    "start": "1398600",
    "end": "1403679"
  },
  {
    "text": "part that means I have able to extract that there's a agre two aggregation feature nodes that there are there's one",
    "start": "1403679",
    "end": "1409600"
  },
  {
    "text": "direct feature node that means uh I mined an aggregation feature node by using a sum or aggregation function on",
    "start": "1409600",
    "end": "1416360"
  },
  {
    "text": "some of the raw columns there at the bottom you'll see that I was also able to M how an aggregation feature came",
    "start": "1416360",
    "end": "1422559"
  },
  {
    "text": "into existence by saying I applied a skew function at depth level one on on a",
    "start": "1422559",
    "end": "1428919"
  },
  {
    "text": "on a dependent column which itself is U taken from some other column which could",
    "start": "1428919",
    "end": "1434080"
  },
  {
    "text": "have been uh mined in an aggregation way and the the display name of this function is sken transaction. amount",
    "start": "1434080",
    "end": "1441520"
  },
  {
    "text": "that's that's the text at the bottom of the slide now we have we have seen a few",
    "start": "1441520",
    "end": "1447799"
  },
  {
    "text": "patterns on how we want to um uh enable this both in terms of controls and risk and governance and all these things",
    "start": "1447799",
    "end": "1454480"
  },
  {
    "text": "coming to the aspect of um generating a feature either because",
    "start": "1454480",
    "end": "1459520"
  },
  {
    "text": "you want to implement this concept in a real-time streaming use case or generate this feature on a batch U patternn use",
    "start": "1459520",
    "end": "1466200"
  },
  {
    "text": "cases there are two parts to production when we talk about feature engineering one is you apply this feature",
    "start": "1466200",
    "end": "1471559"
  },
  {
    "text": "engineering construct to a batch Paradigm wherein you generate features on an onnight basis that gets fed into",
    "start": "1471559",
    "end": "1477880"
  },
  {
    "text": "another uh serving layer or a production system which is then used for front facing uh systems or there are other use",
    "start": "1477880",
    "end": "1484600"
  },
  {
    "text": "cases like fraud fraud platforms wherein they absolutely need this uh their latency wire and you need to build this",
    "start": "1484600",
    "end": "1490720"
  },
  {
    "text": "new features in absolute low time of the of less than 10 milliseconds the feature engineering tool Library allows for both",
    "start": "1490720",
    "end": "1496240"
  },
  {
    "text": "these patterns and the low latency use case is an easier problem to solve with this library because it it provides a",
    "start": "1496240",
    "end": "1502600"
  },
  {
    "text": "serd construct in the sense if you guys are familiar with how say high works there's a you can plug in a serializer",
    "start": "1502600",
    "end": "1509080"
  },
  {
    "text": "and der serializer to your construct same way you can passivate the for",
    "start": "1509080",
    "end": "1514600"
  },
  {
    "text": "example the 429 features that were created in the in the beginning as a definition just like how you would store",
    "start": "1514600",
    "end": "1520320"
  },
  {
    "text": "a Json version of your exus model and then you pick it up at runtime and that runtime can reread the m feature",
    "start": "1520320",
    "end": "1528080"
  },
  {
    "text": "definition and then use that at the time of scoring where in in this world you're not actually translating the feature",
    "start": "1528080",
    "end": "1533399"
  },
  {
    "text": "definition into any other format like a SQL DSL you're actually using the raw version of the format itself and Boot It",
    "start": "1533399",
    "end": "1539760"
  },
  {
    "text": "Up at production time to generate new features we'll concentrate more on the left side because that's a more harder",
    "start": "1539760",
    "end": "1544919"
  },
  {
    "text": "problem to solve here is a simple example we saw one feature the length of",
    "start": "1544919",
    "end": "1550200"
  },
  {
    "text": "the the the size of the features looks very small right it says count of transactions but if I want to take this feature and turn it into a SQL code you",
    "start": "1550200",
    "end": "1557880"
  },
  {
    "text": "look that it's it's not as as small as as the name of the feature definition itself it's joining across perhaps three",
    "start": "1557880",
    "end": "1564720"
  },
  {
    "text": "tables are involved in the toy schema that I showed earlier and the generation of the SQL is not going to be trivial",
    "start": "1564720",
    "end": "1570679"
  },
  {
    "text": "right I have to understand the semantic meaning here is a more a little bit more",
    "start": "1570679",
    "end": "1576399"
  },
  {
    "text": "medium complex example wherein I have to join across um uh three select in there",
    "start": "1576399",
    "end": "1581799"
  },
  {
    "text": "are three select expressions with a group by clause in between and that is just for representing a a aage",
    "start": "1581799",
    "end": "1587960"
  },
  {
    "text": "transaction amounts in per Max of average transaction transaction amounts across",
    "start": "1587960",
    "end": "1594399"
  },
  {
    "text": "sessions that's what that that new feature defines and if I were to take that meaning and generate a SQL of it out of it this is what it is looking",
    "start": "1594399",
    "end": "1600720"
  },
  {
    "text": "like now the problem you're talking about is it's becoming more complex as you as the as the stacking depth of the",
    "start": "1600720",
    "end": "1608520"
  },
  {
    "text": "feature becomes more more longer you'll see that the SQL required to generate that feature is also becoming more",
    "start": "1608520",
    "end": "1614480"
  },
  {
    "text": "complex and the reason why I'm trying to say SQL is required is because typically that's the pattern where batch platforms",
    "start": "1614480",
    "end": "1620279"
  },
  {
    "text": "use there's an SQL expression which just fed into the pipelines data pipelines CH out those features by thousands or",
    "start": "1620279",
    "end": "1626360"
  },
  {
    "text": "Millions every day and that they get shipped shipped to an external uh consumer so this is how we are solving",
    "start": "1626360",
    "end": "1632880"
  },
  {
    "text": "the SQL generation aspect of of things right so what we did was we extended the",
    "start": "1632880",
    "end": "1639360"
  },
  {
    "text": "uh the metadata that we extracted from a feature Library tool and then we started plotting out how to uh cross link",
    "start": "1639360",
    "end": "1646039"
  },
  {
    "text": "entities and hence once we do that for example here we we were able to build an additional node in the previous metadata",
    "start": "1646039",
    "end": "1653120"
  },
  {
    "text": "model which represents aggregate function called skew on the left most side on the lower bottom sorry on the",
    "start": "1653120",
    "end": "1659440"
  },
  {
    "text": "middle section you you see a uh direct feature which which is avoided by the",
    "start": "1659440",
    "end": "1665039"
  },
  {
    "text": "relationship contemporary of that means the yellow one yellow yellow node or a feature is actually a direct feature",
    "start": "1665039",
    "end": "1671679"
  },
  {
    "text": "resolved from the pink that is on to the left uh on the right bottom you will see that it is the final fin feature that is",
    "start": "1671679",
    "end": "1678480"
  },
  {
    "text": "derived so essentially you start from the right on the customer table we talking about a new feature on the",
    "start": "1678480",
    "end": "1683840"
  },
  {
    "text": "customer table which represents the text there and if you walk from the customer's entity you will see that",
    "start": "1683840",
    "end": "1690000"
  },
  {
    "text": "there is a meaning and depth to each of the nodes that you can use as metadata to generate a SQL expression that's the",
    "start": "1690000",
    "end": "1696559"
  },
  {
    "text": "hazy picture wherein I'm able to generate a SQL expression by walking the graph backwards from from from the uh",
    "start": "1696559",
    "end": "1703880"
  },
  {
    "text": "for example in this example I derived a new feature for customer so I go the customer entity walk it backwards and",
    "start": "1703880",
    "end": "1709159"
  },
  {
    "text": "then that's how I'm able to generate a new uh SQL expression and I have as you can see all the metadata required for me",
    "start": "1709159",
    "end": "1715440"
  },
  {
    "text": "to generate a SQL expression the problem is that that is",
    "start": "1715440",
    "end": "1720720"
  },
  {
    "text": "for one column but in batch pipelines you end up generating multiple columns",
    "start": "1720720",
    "end": "1727360"
  },
  {
    "text": "for one table as a as a batch pipeline right so the problem becomes a little bit more uh interesting because now",
    "start": "1727360",
    "end": "1733279"
  },
  {
    "text": "you're asked to generate one single SQL expression for multiple features belonging into one column and here is a",
    "start": "1733279",
    "end": "1739640"
  },
  {
    "text": "very simpler uh not to worry about text it's car build U but essentially you'll see that SQ generation for multiple",
    "start": "1739640",
    "end": "1746600"
  },
  {
    "text": "columns and table becomes even more complex uh and there's another question that came up while we are designing this",
    "start": "1746600",
    "end": "1752679"
  },
  {
    "text": "while we thinking of the design about this is is um humans tend to do a lot of optimization right uh you can't",
    "start": "1752679",
    "end": "1760159"
  },
  {
    "text": "trivialize the human effort when they they Define new features uh there's an optimization that gets into the human's",
    "start": "1760159",
    "end": "1766640"
  },
  {
    "text": "brain that kicks in and tries to optimize a SQL expression for example which represents a Feature Feature uh",
    "start": "1766640",
    "end": "1771679"
  },
  {
    "text": "export process U we are planning to just use a cal site to to take in the raw the",
    "start": "1771679",
    "end": "1778799"
  },
  {
    "text": "raw SQL expression which you do which came out of as a graph walk and then use the optimizer to basically tune the SQL",
    "start": "1778799",
    "end": "1785519"
  },
  {
    "text": "either because the SQL needs to be specific for an engine for example High versus Spark versus any other fancy SQL",
    "start": "1785519",
    "end": "1791240"
  },
  {
    "text": "engine that you might come into context or you can also write rewrite a SQL expression as an optimized version by",
    "start": "1791240",
    "end": "1797120"
  },
  {
    "text": "using using calite um and finally once this SQL is",
    "start": "1797120",
    "end": "1802519"
  },
  {
    "text": "generated you you you can think of then putting them in context with the spark",
    "start": "1802519",
    "end": "1808080"
  },
  {
    "text": "SQL data pipelines many of us are using spark nowadays and if you in the batch world you would typically have uh the",
    "start": "1808080",
    "end": "1814360"
  },
  {
    "text": "SQL used for your uh in your spark spark pipeline which is a spark SQL to",
    "start": "1814360",
    "end": "1819399"
  },
  {
    "text": "generate new data sets this SQL can then be fed into a spark or Flink run times",
    "start": "1819399",
    "end": "1824480"
  },
  {
    "text": "where in Flink may be for low latency use cases and Spark for you know mini batch or or near real time use cases but",
    "start": "1824480",
    "end": "1834159"
  },
  {
    "text": "interesting thing is it it supports a multiple set of patterns wherein you can use a DSL like SQL generator to",
    "start": "1834159",
    "end": "1839640"
  },
  {
    "text": "transcode it into a pipeline that is more compatible with SQL or you can do the other way around which is you take",
    "start": "1839640",
    "end": "1845559"
  },
  {
    "text": "the feature definition persist as a feature definition as a simple text and at runtime things like uh Frameworks",
    "start": "1845559",
    "end": "1852559"
  },
  {
    "text": "like spark or Flink or dask can actually read the definition and uh materialize",
    "start": "1852559",
    "end": "1857799"
  },
  {
    "text": "the the thing so this uh and this concept can be",
    "start": "1857799",
    "end": "1863639"
  },
  {
    "text": "extended across multiple engines the the idea here is that since we captured the semantic meaning of features we can do",
    "start": "1863639",
    "end": "1868840"
  },
  {
    "text": "it at across SQL or no SQL or even um relational Styles right I'd finally like",
    "start": "1868840",
    "end": "1874480"
  },
  {
    "text": "to wrap up uh by bringing this context back so how feature engineering Auto",
    "start": "1874480",
    "end": "1880559"
  },
  {
    "text": "feature engineering is helping in all four phases it helps us for example in the governance phase it helps us to",
    "start": "1880559",
    "end": "1885600"
  },
  {
    "text": "automate from in terms of lineage and uh and security uh from the build phase we",
    "start": "1885600",
    "end": "1891279"
  },
  {
    "text": "are talking about um persisting uh optimizing for persistence or runtime or",
    "start": "1891279",
    "end": "1896720"
  },
  {
    "text": "you know real real time or batch kind of use cases and design phase it has helped",
    "start": "1896720",
    "end": "1901919"
  },
  {
    "text": "us in providing hooks for example Define a new seed feature or uh defining uh new ways of mining new",
    "start": "1901919",
    "end": "1909320"
  },
  {
    "text": "features that's all I have for my",
    "start": "1909320",
    "end": "1913360"
  },
  {
    "text": "today",
    "start": "1916159",
    "end": "1919159"
  }
]
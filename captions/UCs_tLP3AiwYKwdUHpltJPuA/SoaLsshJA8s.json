[
  {
    "text": "[Music]",
    "start": "980",
    "end": "7849"
  },
  {
    "text": "hi everyone thank you so much for coming to my talk I am super excited to be here",
    "start": "13539",
    "end": "20119"
  },
  {
    "text": "and talk to you about distributed data stores and kubernetes and some kubernetes concepts that help make it",
    "start": "20119",
    "end": "26749"
  },
  {
    "text": "easier and about some other pretty new interested distributed things and",
    "start": "26749",
    "end": "31909"
  },
  {
    "text": "kubernetes I am Alina hall I live in Seattle I am a senior cloud developer",
    "start": "31909",
    "end": "37970"
  },
  {
    "text": "advocate at Microsoft working on Azure focusing on big data and distributed",
    "start": "37970",
    "end": "43250"
  },
  {
    "text": "systems I also really enjoy trying out new things and experimenting with stuff",
    "start": "43250",
    "end": "48440"
  },
  {
    "text": "so like in this talk and as a starting point I will assume that you are able to",
    "start": "48440",
    "end": "54710"
  },
  {
    "text": "create a kubernetes cluster there are many ways to do so with different cloud",
    "start": "54710",
    "end": "60050"
  },
  {
    "text": "providers or machine sizes and other settings I have used as your container",
    "start": "60050",
    "end": "66560"
  },
  {
    "text": "service as your community service created with terraform for my setup in",
    "start": "66560",
    "end": "72080"
  },
  {
    "text": "this talk but if you are using something else it should not matter at all it will be equivalent and we're also going to be",
    "start": "72080",
    "end": "78710"
  },
  {
    "text": "using Cassandra in this talk as an example for those who have not worked with Cassandra I will do a brief",
    "start": "78710",
    "end": "85250"
  },
  {
    "text": "overview but I have a more in-depth blog post about it and I'll share it later at",
    "start": "85250",
    "end": "91520"
  },
  {
    "text": "the end of the talk one more thing you will probably need is also courage or a",
    "start": "91520",
    "end": "97670"
  },
  {
    "text": "sense of adventure because combining technology like kubernetes and something like Cassandra",
    "start": "97670",
    "end": "105350"
  },
  {
    "text": "a system that requires stable persistence that might not sound like everybody would be immediately willing",
    "start": "105350",
    "end": "112070"
  },
  {
    "text": "to do this without thinking about consequences so when we talk about data",
    "start": "112070",
    "end": "118190"
  },
  {
    "text": "and databases they are arguably one of the most important parts of any system and we wouldn't want to deal with any",
    "start": "118190",
    "end": "125119"
  },
  {
    "text": "data loss or spend hours recovering from a mistake that can cause significant",
    "start": "125119",
    "end": "130729"
  },
  {
    "text": "amounts of money so I generally wouldn't use the technology in production unless",
    "start": "130729",
    "end": "136550"
  },
  {
    "text": "I'm 100% confident in it well probably not possible to be 100% confident in anything but general",
    "start": "136550",
    "end": "144749"
  },
  {
    "text": "message is that if you don't feel sure enough and if the system like database system that you're using works well when",
    "start": "144749",
    "end": "151739"
  },
  {
    "text": "physical machines or virtual machines or anything else and then that might be a good way to go but this talk is not",
    "start": "151739",
    "end": "158280"
  },
  {
    "text": "about this we're gonna talk about containers and kubernetes and how it can",
    "start": "158280",
    "end": "164280"
  },
  {
    "text": "make it faster and faster basically to get it up and running but it won't",
    "start": "164280",
    "end": "169829"
  },
  {
    "text": "really simplified day-to-day management and operations on your database cluster",
    "start": "169829",
    "end": "175040"
  },
  {
    "text": "so now let's talk about why and when it might be a good idea flexibility and",
    "start": "175040",
    "end": "183419"
  },
  {
    "text": "possibilities that could be native eyes they actually have proven lead to to lead to more frequent kubernetes service",
    "start": "183419",
    "end": "190230"
  },
  {
    "text": "deployments it also reduces some operational efforts that have to be put",
    "start": "190230",
    "end": "195629"
  },
  {
    "text": "in recovering individual services and it automates a lot of common operations to",
    "start": "195629",
    "end": "201959"
  },
  {
    "text": "support healthy lifetime of services and is generally pretty convenient to manage",
    "start": "201959",
    "end": "207180"
  },
  {
    "text": "multiple services altogether so what is the benefit of running a distributed",
    "start": "207180",
    "end": "214319"
  },
  {
    "text": "database on kubernetes well it might take a long time to properly set up your",
    "start": "214319",
    "end": "220620"
  },
  {
    "text": "database system using physical machines or virtual machines and once you get it",
    "start": "220620",
    "end": "226169"
  },
  {
    "text": "up and running you will most likely leave it up and running and wouldn't want to mess with it if we're thinking",
    "start": "226169",
    "end": "233819"
  },
  {
    "text": "about containerized in our database deployment it is very fast and easy to",
    "start": "233819",
    "end": "239129"
  },
  {
    "text": "get it up and running so we won't have to keep it there when it's unused it",
    "start": "239129",
    "end": "245099"
  },
  {
    "text": "takes just a few minutes to deploy it and to destroy it so it's perfect for Devin test clusters but there are",
    "start": "245099",
    "end": "253620"
  },
  {
    "text": "companies who use kubernetes for databases in production today also so",
    "start": "253620",
    "end": "261509"
  },
  {
    "text": "here is a talk plan quite a few things to cover but first first of all I know",
    "start": "261509",
    "end": "268229"
  },
  {
    "text": "that some of you might have some knowledge of Cassandra and especially after Eric's talk but if so",
    "start": "268229",
    "end": "275599"
  },
  {
    "text": "you don't have it I will do a brief and quick refresher so it would go",
    "start": "275599",
    "end": "281360"
  },
  {
    "text": "Cassandra Cassandra is a very powerful distributed database it it's very highly",
    "start": "281360",
    "end": "288620"
  },
  {
    "text": "available it scales really well it is an AP system in terms of cap theorem and to",
    "start": "288620",
    "end": "296569"
  },
  {
    "text": "be more specific it uses a ring topology cluster so when the new data arrives the cluster already",
    "start": "296569",
    "end": "303740"
  },
  {
    "text": "knows what node to put the entry on because each node in the cluster is",
    "start": "303740",
    "end": "310129"
  },
  {
    "text": "responsible for specific limited hash range from the overall hash circle ring",
    "start": "310129",
    "end": "316870"
  },
  {
    "text": "and also based on the partition key of the data we know what node is",
    "start": "316870",
    "end": "322909"
  },
  {
    "text": "responsible for this data but most likely the data entry will be stored on more than one node if the replication",
    "start": "322909",
    "end": "329569"
  },
  {
    "text": "factor is more than one it is also a highly available system which is",
    "start": "329569",
    "end": "334729"
  },
  {
    "text": "masterless and all nodes can act as a coordinator for example if there is some",
    "start": "334729",
    "end": "342229"
  },
  {
    "text": "request for data entry that is stored on node a that came in through node B and",
    "start": "342229",
    "end": "348949"
  },
  {
    "text": "if node egg went down on us unexpectedly then node B would store the request with",
    "start": "348949",
    "end": "356180"
  },
  {
    "text": "changes necessary in its hints table and as soon as node a comes back up the node",
    "start": "356180",
    "end": "362930"
  },
  {
    "text": "B will know to find out a about the request so even though Cassandra is an",
    "start": "362930",
    "end": "368599"
  },
  {
    "text": "AV system it doesn't mean that we always have to sacrifice consistency we can",
    "start": "368599",
    "end": "374240"
  },
  {
    "text": "also tune consistency on the per query level so the general rule we have for",
    "start": "374240",
    "end": "380840"
  },
  {
    "text": "consistent queries is write quorum plus 3 forum should be more than a replication factor and the important",
    "start": "380840",
    "end": "389060"
  },
  {
    "text": "thing is that we can get really fast reads if we query by partition key because all the data is stored on the",
    "start": "389060",
    "end": "395930"
  },
  {
    "text": "same together on the same level physically so",
    "start": "395930",
    "end": "401100"
  },
  {
    "text": "yeah rights are pretty fast because they are written in two immutable append-only",
    "start": "401100",
    "end": "408140"
  },
  {
    "text": "permit log and also to the per common family structure called mem table which",
    "start": "408140",
    "end": "414090"
  },
  {
    "text": "is residing in memory and when it gets full it flashes to disk into a format",
    "start": "414090",
    "end": "420600"
  },
  {
    "text": "called SS table and we're too many SS tables they get compacted into a bigger SS",
    "start": "420600",
    "end": "425820"
  },
  {
    "text": "table so that's a pretty good intuition about what cassandra is now kubernetes",
    "start": "425820",
    "end": "432680"
  },
  {
    "text": "is a distributed system for running more containerized distributed systems I",
    "start": "432680",
    "end": "439590"
  },
  {
    "text": "would say some of the features that it provides our scheduling and resource",
    "start": "439590",
    "end": "444720"
  },
  {
    "text": "management scaling robux self-healing secrets",
    "start": "444720",
    "end": "450990"
  },
  {
    "text": "service discovery jobs execution and more it also has a concept of nodes and",
    "start": "450990",
    "end": "456840"
  },
  {
    "text": "pods node itself is not created by kubernetes it's created externally like",
    "start": "456840",
    "end": "463620"
  },
  {
    "text": "looking use Azure Oracle cloud to provision nodes but it is an object in kubernetes and kubernetes does some",
    "start": "463620",
    "end": "470730"
  },
  {
    "text": "checks to make sure that node is valid and each node has services necessary to",
    "start": "470730",
    "end": "477630"
  },
  {
    "text": "run pods and there is some managed there are some management components so",
    "start": "477630",
    "end": "483240"
  },
  {
    "text": "services unknowns include cubelet that checks that containers are running in",
    "start": "483240",
    "end": "488940"
  },
  {
    "text": "and healthy there is continued runtime like docker and cube proxy for connection forwarding so nodes can have",
    "start": "488940",
    "end": "499920"
  },
  {
    "text": "one or more pods running and pod is a group of one or more containers which is",
    "start": "499920",
    "end": "505380"
  },
  {
    "text": "basically the simplest unit you can deploy on kubernetes it can have an IP",
    "start": "505380",
    "end": "510390"
  },
  {
    "text": "address or volumes attached it's just a simple way to run your container so",
    "start": "510390",
    "end": "518130"
  },
  {
    "text": "nodes can also be master nodes and so when we submit our resource definitions",
    "start": "518130",
    "end": "523530"
  },
  {
    "text": "which is like a yellow file or a JSON file or through home charts basically we",
    "start": "523530",
    "end": "528540"
  },
  {
    "text": "have an API server that waits for read and write requests and control loop that checks looks at",
    "start": "528540",
    "end": "536490"
  },
  {
    "text": "the current state of the cluster in the desired state and brings current state to the desired state and there is a",
    "start": "536490",
    "end": "542940"
  },
  {
    "text": "scheduler that watches pods that don't have no designed and assigns them to the",
    "start": "542940",
    "end": "549089"
  },
  {
    "text": "node and as Eric mentioned there is at CD which is the highly available key",
    "start": "549089",
    "end": "554459"
  },
  {
    "text": "value store for cluster data now a pods by themself are pretty weak however",
    "start": "554459",
    "end": "562589"
  },
  {
    "text": "they're perfectly good for building out other abstractions and kubernetes for",
    "start": "562589",
    "end": "567630"
  },
  {
    "text": "example deployments or replica sets which is an abstraction on pods that will always keep certain number of pods",
    "start": "567630",
    "end": "575010"
  },
  {
    "text": "running at all times if something goes wrong with one pod it will create",
    "start": "575010",
    "end": "580019"
  },
  {
    "text": "another one which is great for services that's cool but aren't containers meant",
    "start": "580019",
    "end": "587130"
  },
  {
    "text": "to be ephemeral and used for stateless services standard containers kind of are",
    "start": "587130",
    "end": "593940"
  },
  {
    "text": "meant to be stateless and ephemeral they will doesn't forget your data in case of restart or an error so it's not a good",
    "start": "593940",
    "end": "600690"
  },
  {
    "text": "idea to save anything for system that needs persistence on them now how does",
    "start": "600690",
    "end": "607110"
  },
  {
    "text": "that do us any good if we want to run distributed databases then because those",
    "start": "607110",
    "end": "612269"
  },
  {
    "text": "are definitely system that needs stable persistence let's look at what else was",
    "start": "612269",
    "end": "617790"
  },
  {
    "text": "out here I mentioned that pods can have volumes attached so a volume can store data but",
    "start": "617790",
    "end": "625260"
  },
  {
    "text": "the lifetime of the volume is limited by the lifetime of the pod who owns it",
    "start": "625260",
    "end": "630829"
  },
  {
    "text": "volume actually outlives the containers within the pods of container restarts",
    "start": "630829",
    "end": "636240"
  },
  {
    "text": "the data would not be lost kubernetes supports many types of volumes and you",
    "start": "636240",
    "end": "642930"
  },
  {
    "text": "can attach many of them to a pod so what if we try deployments or",
    "start": "642930",
    "end": "649670"
  },
  {
    "text": "replicated containers with volumes if we look at it a bit further we notice that",
    "start": "649670",
    "end": "655880"
  },
  {
    "text": "having volumes is not really enough for any distributed databases because there",
    "start": "655880",
    "end": "661770"
  },
  {
    "text": "are certain assumptions that need to be made about the database cluster nodes before",
    "start": "661770",
    "end": "667170"
  },
  {
    "text": "we actually create the cluster so some of the nodes should be should have roles",
    "start": "667170",
    "end": "673200"
  },
  {
    "text": "like leader follower or we might have some nose designated as seed nodes and",
    "start": "673200",
    "end": "678840"
  },
  {
    "text": "we need need them to be discoverable so standard containers are not persistent",
    "start": "678840",
    "end": "684180"
  },
  {
    "text": "even combined with kubernetes volumes there are quite a few issues we noticed",
    "start": "684180",
    "end": "689580"
  },
  {
    "text": "that pods start up with non-deterministic and random names that",
    "start": "689580",
    "end": "695430"
  },
  {
    "text": "are not predictable enough and that they start in random unpredictable order",
    "start": "695430",
    "end": "702060"
  },
  {
    "text": "same with deletion and termination and scaling so we can't really make those distributed system assumptions so",
    "start": "702060",
    "end": "709350"
  },
  {
    "text": "replica sets with volumes won't work for us hmm so before creating the database",
    "start": "709350",
    "end": "717510"
  },
  {
    "text": "cluster we need to have certain guarantees about the database nodes they",
    "start": "717510",
    "end": "723900"
  },
  {
    "text": "should have discoverable names they need to start in predictable order for us and",
    "start": "723900",
    "end": "730460"
  },
  {
    "text": "they need to have persistent storage so let's look at another creeper neatest",
    "start": "730460",
    "end": "737100"
  },
  {
    "text": "concept that helps make it possible it's called stateful sets straight hole",
    "start": "737100",
    "end": "743220"
  },
  {
    "text": "sets are kind of similar to previous deployments in a way that they always keep a certain number of replicas pods",
    "start": "743220",
    "end": "750590"
  },
  {
    "text": "running but they're different because they have an identity so each pod will",
    "start": "750590",
    "end": "757080"
  },
  {
    "text": "start with a unique and stable network identifier it will have stable and",
    "start": "757080",
    "end": "762090"
  },
  {
    "text": "persistent storage attached and there will be a persistent link from pod to",
    "start": "762090",
    "end": "767910"
  },
  {
    "text": "storage and all of the pods in the stateful set also start in the same",
    "start": "767910",
    "end": "774060"
  },
  {
    "text": "order and get terminated in the reverse order and it is preserved so if we look",
    "start": "774060",
    "end": "779820"
  },
  {
    "text": "at the possible architecture of using stateful set with let's say Cassandra",
    "start": "779820",
    "end": "785250"
  },
  {
    "text": "and kubernetes it might look something like this where we have Cooper Natives we have some ascender pods each of them",
    "start": "785250",
    "end": "792480"
  },
  {
    "text": "has ordinal index and each of them have persistent storage",
    "start": "792480",
    "end": "798840"
  },
  {
    "text": "attached now let's actually unpack the definition of a stateful set we know",
    "start": "798840",
    "end": "805560"
  },
  {
    "text": "what it guarantees but what does it what is it really so it starts with a",
    "start": "805560",
    "end": "810840"
  },
  {
    "text": "headless service this is a kind of service that is called headless because",
    "start": "810840",
    "end": "817800"
  },
  {
    "text": "it does not need a cluster IP available and we don't do any load balancing with",
    "start": "817800",
    "end": "823770"
  },
  {
    "text": "it the service definition has a selector and when the service is accessed the dns",
    "start": "823770",
    "end": "832170"
  },
  {
    "text": "is configured basically to return a list of a records or addresses which point",
    "start": "832170",
    "end": "838140"
  },
  {
    "text": "directly to those pods that have the same selector and we needed to manage",
    "start": "838140",
    "end": "844500"
  },
  {
    "text": "the network identity for those stateful pods to create a headless service we",
    "start": "844500",
    "end": "851430"
  },
  {
    "text": "refer Cassandra for example we can use a similar template which defines a kind",
    "start": "851430",
    "end": "859440"
  },
  {
    "text": "service and defines that cluster IP is none labeled to Sandra and the port 1942",
    "start": "859440",
    "end": "868010"
  },
  {
    "text": "so now let's talk about the actual storage for a stateful sense when pods",
    "start": "868010",
    "end": "876150"
  },
  {
    "text": "in stateful said get created each of them request request storage a storage",
    "start": "876150",
    "end": "882480"
  },
  {
    "text": "class is another kubernetes concept that helps users choose between the types of",
    "start": "882480",
    "end": "889920"
  },
  {
    "text": "storage available for the cluster there are they might be different depending on",
    "start": "889920",
    "end": "895320"
  },
  {
    "text": "the environment and infrastructure you're running oil so azure for example provides at your disks and as your files",
    "start": "895320",
    "end": "902570"
  },
  {
    "text": "they might be different from the pricing perspective like standard or premium",
    "start": "902570",
    "end": "908580"
  },
  {
    "text": "managed to run managed you can even create your own storage classes if needed it might look something like this",
    "start": "908580",
    "end": "915800"
  },
  {
    "text": "where we have a template with definition of a storage class and we define the",
    "start": "915800",
    "end": "921960"
  },
  {
    "text": "provision or type account storage type and other parameters",
    "start": "921960",
    "end": "928610"
  },
  {
    "text": "so we know that users can choose storage based on storage classes and when each",
    "start": "928819",
    "end": "936059"
  },
  {
    "text": "pod in the Cassandra stage will set get initialized how does it actually request",
    "start": "936059",
    "end": "941699"
  },
  {
    "text": "that storage so there are persistent volumes and they can be provisioned",
    "start": "941699",
    "end": "946799"
  },
  {
    "text": "either statically or dynamically here we're talking about dynamic provisioning",
    "start": "946799",
    "end": "952079"
  },
  {
    "text": "and with dynamic provisioning state set has a definition of a persistent volume",
    "start": "952079",
    "end": "958860"
  },
  {
    "text": "claim that is a request for storage after the request succeeds the",
    "start": "958860",
    "end": "965879"
  },
  {
    "text": "persistent volume is dynamically provisioned for each pod according to",
    "start": "965879",
    "end": "971279"
  },
  {
    "text": "the storage class that it requested a persistent volume claim is kind of",
    "start": "971279",
    "end": "976439"
  },
  {
    "text": "similar to a pod in context of the pod requests resources of nodes like memory",
    "start": "976439",
    "end": "984569"
  },
  {
    "text": "amount and stuff like this and persistent volume claim requests",
    "start": "984569",
    "end": "990230"
  },
  {
    "text": "persistent volume resources like size or access mode and it creates persistent",
    "start": "990230",
    "end": "999029"
  },
  {
    "text": "volumes that provides an API for users and administrators to actually abstract",
    "start": "999029",
    "end": "1004759"
  },
  {
    "text": "the details the underlying details of the implementation of the storage away from users and from how it is consumed",
    "start": "1004759",
    "end": "1011720"
  },
  {
    "text": "this is very convenient so persistent volumes are like volumes but their",
    "start": "1011720",
    "end": "1017749"
  },
  {
    "text": "lifecycle is independent from a lifecycle of the pod so now let's look",
    "start": "1017749",
    "end": "1024829"
  },
  {
    "text": "at the story of persistent volume and a persistent volume claim so imagine we have a stateful set and there is a first",
    "start": "1024829",
    "end": "1032209"
  },
  {
    "text": "pod that is initialized and this pot has a definition of a persistent volume",
    "start": "1032209",
    "end": "1038058"
  },
  {
    "text": "claim with a certain storage type and it says I'm requesting my storage based on",
    "start": "1038059",
    "end": "1043459"
  },
  {
    "text": "the storage class then there is a dynamic provisioner that monitors for",
    "start": "1043459",
    "end": "1049010"
  },
  {
    "text": "persistent volume claims that are unbound to any persistent volume so then",
    "start": "1049010",
    "end": "1056120"
  },
  {
    "text": "it will create a new persistent volume based on the character sticks and based on the storage class",
    "start": "1056120",
    "end": "1061450"
  },
  {
    "text": "that the pod requested and after that the persistent volume claim will end up",
    "start": "1061450",
    "end": "1066910"
  },
  {
    "text": "in the bound state and the pod will be attached to that volume now let's look",
    "start": "1066910",
    "end": "1073810"
  },
  {
    "text": "at the actual definition of a stateful set it's quite big here but the main",
    "start": "1073810",
    "end": "1081310"
  },
  {
    "text": "part is there is a part volume claim templates which describes the volume",
    "start": "1081310",
    "end": "1086620"
  },
  {
    "text": "claim access mode storage class name resource is requested there are some",
    "start": "1086620",
    "end": "1092590"
  },
  {
    "text": "standard specific parameters number of replicas and also some seed nodes and",
    "start": "1092590",
    "end": "1099630"
  },
  {
    "text": "let's look at an example of how to actually create a stateful set the",
    "start": "1099630",
    "end": "1104830"
  },
  {
    "text": "actual process of deployment so I made it a little faster first we can create a",
    "start": "1104830",
    "end": "1111660"
  },
  {
    "text": "headless service using the cube CTL create command then after it's done we",
    "start": "1111660",
    "end": "1119500"
  },
  {
    "text": "are creating stateful set from that template definition then after it's",
    "start": "1119500",
    "end": "1126100"
  },
  {
    "text": "created we can monitor the status of the stateful set using the get stateful sets",
    "start": "1126100",
    "end": "1132610"
  },
  {
    "text": "command and we see that there is one for Cassandra remember of desired replicas",
    "start": "1132610",
    "end": "1138610"
  },
  {
    "text": "as five current is one which is pending that means we can describe the pod and",
    "start": "1138610",
    "end": "1145360"
  },
  {
    "text": "see what is going on and we see that there is a persistent volume claim that",
    "start": "1145360",
    "end": "1154120"
  },
  {
    "text": "is actually not bound to see what's going on with the persistent volume",
    "start": "1154120",
    "end": "1159910"
  },
  {
    "text": "claim we can use the cube CTL yet PVC",
    "start": "1159910",
    "end": "1165850"
  },
  {
    "text": "command and here is a new persistent volume claim in a pending status we can",
    "start": "1165850",
    "end": "1174880"
  },
  {
    "text": "of course get more details about the resistible and claim that is being created if we describe it",
    "start": "1174880",
    "end": "1183179"
  },
  {
    "text": "and we see that it is using our designated storage class managed premium",
    "start": "1183390",
    "end": "1189950"
  },
  {
    "text": "pending of type Azure disk so if we want to see the details about the storage",
    "start": "1189950",
    "end": "1196679"
  },
  {
    "text": "class that our claim requests will see",
    "start": "1196679",
    "end": "1201840"
  },
  {
    "text": "that our cluster has the following available and we can look even further",
    "start": "1201840",
    "end": "1207000"
  },
  {
    "text": "into the definition of the storage class if we use the described storage class command and basically it has the entire",
    "start": "1207000",
    "end": "1216330"
  },
  {
    "text": "definition of that storage class name space storage account ID provisioner so",
    "start": "1216330",
    "end": "1222870"
  },
  {
    "text": "let's check back on how the pods are doing get pods the container is creating",
    "start": "1222870",
    "end": "1230460"
  },
  {
    "text": "and that means that our persistent volume claim is probably already bound and it is bound that means that there is",
    "start": "1230460",
    "end": "1237540"
  },
  {
    "text": "a persistent volume created and there is",
    "start": "1237540",
    "end": "1242610"
  },
  {
    "text": "a command yet TV where which shows the",
    "start": "1242610",
    "end": "1247919"
  },
  {
    "text": "persistent volumes and it sure is bound and basically what we can do is monitor",
    "start": "1247919",
    "end": "1256370"
  },
  {
    "text": "pods for creation until we have the exact number of replicas that we expect",
    "start": "1256370",
    "end": "1262770"
  },
  {
    "text": "so here is another one pending they're going to be created one by one in the",
    "start": "1262770",
    "end": "1269669"
  },
  {
    "text": "order in order basically and we can also watch how persistent volume claims are",
    "start": "1269669",
    "end": "1276540"
  },
  {
    "text": "created so how it transfers from pending state to bound state now we need",
    "start": "1276540",
    "end": "1285410"
  },
  {
    "text": "basically five of them and I made it a little faster but you can see how long",
    "start": "1285410",
    "end": "1290940"
  },
  {
    "text": "it takes to provision provisioned persistent volumes if they are already",
    "start": "1290940",
    "end": "1297150"
  },
  {
    "text": "created and one of the pods gets removed or something happens with it by accident",
    "start": "1297150",
    "end": "1303110"
  },
  {
    "text": "then it will be quicker because the persistent volumes are already created",
    "start": "1303110",
    "end": "1308669"
  },
  {
    "text": "and it will just need to be attached and finally we should have all the all four",
    "start": "1308669",
    "end": "1313950"
  },
  {
    "text": "of them running just take a second so four of",
    "start": "1313950",
    "end": "1320249"
  },
  {
    "text": "them are running and we can just confirm it by getting the status of the entire",
    "start": "1320249",
    "end": "1325919"
  },
  {
    "text": "state will set desired number five and current is five so one of the options to",
    "start": "1325919",
    "end": "1334950"
  },
  {
    "text": "experiment with Cassandra and kubernetes without submitting any service is to",
    "start": "1334950",
    "end": "1341580"
  },
  {
    "text": "create a service of a type load balancer and that will expose an IP address that",
    "start": "1341580",
    "end": "1347850"
  },
  {
    "text": "we can reach our stage was set by it's good for interacting with experiments",
    "start": "1347850",
    "end": "1353309"
  },
  {
    "text": "but it's not good to leave it open so let's just writing data into Cassandra",
    "start": "1353309",
    "end": "1359789"
  },
  {
    "text": "so I'm going to show you an example with using my own machine to write data to",
    "start": "1359789",
    "end": "1366600"
  },
  {
    "text": "Cassandra and kubernetes so I decided to use some public data and because I live",
    "start": "1366600",
    "end": "1373139"
  },
  {
    "text": "in Seattle I got a data set of open addresses and I'm going to kind of",
    "start": "1373139",
    "end": "1378690"
  },
  {
    "text": "currently write them into Cassandra to just test this dataset so I'm going to use a sharp functional programming",
    "start": "1378690",
    "end": "1385919"
  },
  {
    "text": "language and interactive CLI because it's convenient and why not do that so",
    "start": "1385919",
    "end": "1392460"
  },
  {
    "text": "here I am in my code environment importing some libraries and here I have",
    "start": "1392460",
    "end": "1401730"
  },
  {
    "text": "a definition of the type for the CSV file I'm using four addresses it infers",
    "start": "1401730",
    "end": "1407759"
  },
  {
    "text": "the type from the data and then I'm getting the addresses and initializing",
    "start": "1407759",
    "end": "1414899"
  },
  {
    "text": "function to connect to Cassandra cluster to create two a key space that I'm going",
    "start": "1414899",
    "end": "1421320"
  },
  {
    "text": "to be using for my table and a function to initialize the table and a bunch of",
    "start": "1421320",
    "end": "1428429"
  },
  {
    "text": "other functions that I need for writing data in parallel manner and then I'm",
    "start": "1428429",
    "end": "1434909"
  },
  {
    "text": "using the external IP address to connect to Cassandra and get the session so that",
    "start": "1434909",
    "end": "1440669"
  },
  {
    "text": "I can actually execute those functions I'm you create housing he's faced with this",
    "start": "1440669",
    "end": "1446490"
  },
  {
    "text": "session creating the addresses table in Casandra and then calling the function",
    "start": "1446490",
    "end": "1453690"
  },
  {
    "text": "to persist the addresses in parallel and just taking the first 100 just our test",
    "start": "1453690",
    "end": "1460130"
  },
  {
    "text": "and it should write them all in parallel I hope it works and it's it's working",
    "start": "1460130",
    "end": "1468330"
  },
  {
    "text": "and it's done so now that we can do similar thing with kubernetes jobs which",
    "start": "1468330",
    "end": "1476760"
  },
  {
    "text": "is another concept it allows us to start pods and run them till completion also",
    "start": "1476760",
    "end": "1483990"
  },
  {
    "text": "configure certain parameters like restart policy resource limits and other",
    "start": "1483990",
    "end": "1489450"
  },
  {
    "text": "things and we can create as many kubernetes jobs as we want and as our",
    "start": "1489450",
    "end": "1495870"
  },
  {
    "text": "kubernetes cluster resources allow so let's go back to that addresses example",
    "start": "1495870",
    "end": "1501630"
  },
  {
    "text": "and where we write data into Cassandra and try to make it work with kubernetes jobs so here is a job definition file",
    "start": "1501630",
    "end": "1512210"
  },
  {
    "text": "where I am and this basically packaged my sherab script into a container and",
    "start": "1512210",
    "end": "1518130"
  },
  {
    "text": "made it accept three parameters because we are writing data into Cassandra in",
    "start": "1518130",
    "end": "1525360"
  },
  {
    "text": "parallel we wanted to basically split data and chunks and write and have each job for for one part so I am using the",
    "start": "1525360",
    "end": "1534780"
  },
  {
    "text": "container it's called f-sharp job and I'm indicating the command to run that script with the correct parameters that",
    "start": "1534780",
    "end": "1542610"
  },
  {
    "text": "accepts the offset number of Records to process and increment if we also want to",
    "start": "1542610",
    "end": "1547680"
  },
  {
    "text": "use a sharp concurrency optionally now how do we send different input",
    "start": "1547680",
    "end": "1553830"
  },
  {
    "text": "parameters to each corresponding job well Bash is the answer I am defining",
    "start": "1553830",
    "end": "1561000"
  },
  {
    "text": "some variables to set the job count step",
    "start": "1561000",
    "end": "1566310"
  },
  {
    "text": "and increment and I'm using that sharp job template to populate to create many",
    "start": "1566310",
    "end": "1572070"
  },
  {
    "text": "files but with the correct parameters populated",
    "start": "1572070",
    "end": "1577570"
  },
  {
    "text": "so cool let's see how it works in action",
    "start": "1577570",
    "end": "1583180"
  },
  {
    "text": "let me go to my code here I'm sharp okay",
    "start": "1583180",
    "end": "1593560"
  },
  {
    "text": "so I'm located in the directory of that project and here is a F sharp job yamo",
    "start": "1593560",
    "end": "1601430"
  },
  {
    "text": "file the same as I showed previously and",
    "start": "1601430",
    "end": "1606860"
  },
  {
    "text": "here is the prepared jobs script that performs the creation of job files and",
    "start": "1606860",
    "end": "1614870"
  },
  {
    "text": "what we want to do is want to execute that prepare jobs script that creates lots of files and we",
    "start": "1614870",
    "end": "1623840"
  },
  {
    "text": "can see that there is a jobs directory and if we navigate to it we see that",
    "start": "1623840",
    "end": "1629240"
  },
  {
    "text": "those are the actual job templates that we need to use so let's look at one of",
    "start": "1629240",
    "end": "1636080"
  },
  {
    "text": "them like seven ok so and here we notice",
    "start": "1636080",
    "end": "1641780"
  },
  {
    "text": "that there is there are three parameters populated with the right data that used",
    "start": "1641780",
    "end": "1646850"
  },
  {
    "text": "the container image finally to submit",
    "start": "1646850",
    "end": "1652040"
  },
  {
    "text": "those jobs we can use cubes video create",
    "start": "1652040",
    "end": "1658480"
  },
  {
    "text": "new jobs in this command will create all the",
    "start": "1658480",
    "end": "1666020"
  },
  {
    "text": "other jobs from that jobs directory now we can check the status of jobs by using",
    "start": "1666020",
    "end": "1673670"
  },
  {
    "text": "the get jobs command we see that there are ten of them they're all successful I",
    "start": "1673670",
    "end": "1679340"
  },
  {
    "text": "mean they're all running and they're not successful yet because they're not completed yet but what happens under the",
    "start": "1679340",
    "end": "1687290"
  },
  {
    "text": "hood is that each jobs creates a pod and",
    "start": "1687290",
    "end": "1692840"
  },
  {
    "text": "we see that there are ten pods creators and they are running we can always look",
    "start": "1692840",
    "end": "1698630"
  },
  {
    "text": "into what is happening in the pod and",
    "start": "1698630",
    "end": "1706760"
  },
  {
    "text": "getting it by name and we see that it's created from the image that was indicated in the template file but we",
    "start": "1706760",
    "end": "1713420"
  },
  {
    "text": "can also watch what the pot is doing in real time and monitor the status of our",
    "start": "1713420",
    "end": "1720440"
  },
  {
    "text": "job oh whoops I didn't copy the name correctly let's get some random pod",
    "start": "1720440",
    "end": "1729110"
  },
  {
    "text": "oh it's completed so we still can look at the logs even after the job is",
    "start": "1729110",
    "end": "1735350"
  },
  {
    "text": "completed and here we see the output of the job but finally the status of jobs",
    "start": "1735350",
    "end": "1745880"
  },
  {
    "text": "is visible here and if we don't need them anymore we can always delete all of",
    "start": "1745880",
    "end": "1752390"
  },
  {
    "text": "them and this is how it works so now let's go back to the slides and",
    "start": "1752390",
    "end": "1761020"
  },
  {
    "text": "yeah and by the way the code for this example is on github after our job queue",
    "start": "1763360",
    "end": "1768669"
  },
  {
    "text": "if you would like to try it out on or check things to note about stateful sets",
    "start": "1768669",
    "end": "1777780"
  },
  {
    "text": "persistent volumes are not automatically removed when you remove a stateful set",
    "start": "1777780",
    "end": "1783309"
  },
  {
    "text": "it's done on purpose in case something happens to the stable said you won't",
    "start": "1783309",
    "end": "1788380"
  },
  {
    "text": "lose all of your data and persistent volumes for now and stateful sets were a",
    "start": "1788380",
    "end": "1794110"
  },
  {
    "text": "better resource and before kubernetes 1.9 now they're out and some people use",
    "start": "1794110",
    "end": "1801970"
  },
  {
    "text": "it in production and before considering using it in production please go through github issues that exist and make sure",
    "start": "1801970",
    "end": "1810280"
  },
  {
    "text": "that there are no critical issues there so there's also a concept of node",
    "start": "1810280",
    "end": "1815710"
  },
  {
    "text": "affinity which Eric mentioned during his talk that means that we can tell which",
    "start": "1815710",
    "end": "1822100"
  },
  {
    "text": "pods can run with other pods on the same node and other flexible settings so",
    "start": "1822100",
    "end": "1828070"
  },
  {
    "text": "there's a lot of flexibility in in this way you know let's go to a slightly",
    "start": "1828070",
    "end": "1836080"
  },
  {
    "text": "different topic but it's still very similar we can run spark jobs on",
    "start": "1836080",
    "end": "1842350"
  },
  {
    "text": "kubernetes since release 2.3 and I I",
    "start": "1842350",
    "end": "1848590"
  },
  {
    "text": "decided to try it with Cassandra on kubernetes so anyone heard about spark",
    "start": "1848590",
    "end": "1854740"
  },
  {
    "text": "buddy knows what SPARC is okay quite a few people so SPARC is an open source",
    "start": "1854740",
    "end": "1860500"
  },
  {
    "text": "project for distributed computations it is kind of similar to Duke MapReduce but",
    "start": "1860500",
    "end": "1867370"
  },
  {
    "text": "it is much faster it tries to keep data in memory it forms a directed acyclic",
    "start": "1867370",
    "end": "1872770"
  },
  {
    "text": "graph of the consecutive computation stages and it allows optimizing data",
    "start": "1872770",
    "end": "1881350"
  },
  {
    "text": "operations and like minimizing shuffling data around and other things you can do",
    "start": "1881350",
    "end": "1888070"
  },
  {
    "text": "stream processing machine learning data science ETL tasks and more the way",
    "start": "1888070",
    "end": "1894510"
  },
  {
    "text": "spark jobs usually are submitted is using spark submit command-line command",
    "start": "1894510",
    "end": "1900630"
  },
  {
    "text": "where we can pass a jar file or Python archive and then yeah so previously you",
    "start": "1900630",
    "end": "1910500"
  },
  {
    "text": "can run you could run spark on resource managers like yarn or mezzos but as I",
    "start": "1910500",
    "end": "1918840"
  },
  {
    "text": "mentioned since release 2.0 it is supported on kubernetes as a scheduler",
    "start": "1918840",
    "end": "1924530"
  },
  {
    "text": "so when you actually submit an application to the cluster with spark",
    "start": "1924530",
    "end": "1931050"
  },
  {
    "text": "submit they're going to be a coordinator process that is called spark driver and",
    "start": "1931050",
    "end": "1937050"
  },
  {
    "text": "it is managing the entire job process and it talks to many other processes",
    "start": "1937050",
    "end": "1946650"
  },
  {
    "text": "that are called spark executors that that do the work provided by a job an",
    "start": "1946650",
    "end": "1952800"
  },
  {
    "text": "accordion implementation they are implemented as kubernetes pods so I will",
    "start": "1952800",
    "end": "1959520"
  },
  {
    "text": "show you a cool example of running spark jobs on kubernetes and using Cassandra",
    "start": "1959520",
    "end": "1964530"
  },
  {
    "text": "to write some data and to fetch some data so before I do that there are a few",
    "start": "1964530",
    "end": "1971700"
  },
  {
    "text": "things that I've done before I can actually submit a job using spark on",
    "start": "1971700",
    "end": "1976950"
  },
  {
    "text": "kubernetes so you need a kubernetes cluster but you also need to build a",
    "start": "1976950",
    "end": "1982920"
  },
  {
    "text": "spark image and that is possible to do if you clone a github repo of spark",
    "start": "1982920",
    "end": "1991110"
  },
  {
    "text": "select the 2.3 or later branch and you can build the source using maven or SBT",
    "start": "1991110",
    "end": "1999630"
  },
  {
    "text": "if you pass the kubernetes switch and then there are some helper scripts that",
    "start": "1999630",
    "end": "2005390"
  },
  {
    "text": "help you build out the docker image and push it to the container registry of your choice that we can indicate when we",
    "start": "2005390",
    "end": "2013790"
  },
  {
    "text": "use a spark submit command so that kubernetes knows what container to use",
    "start": "2013790",
    "end": "2018820"
  },
  {
    "text": "when running driver and executor pods for spark so",
    "start": "2018820",
    "end": "2026650"
  },
  {
    "text": "and we also need to indicate dependency like job dependency archives and in the",
    "start": "2026650",
    "end": "2034450"
  },
  {
    "text": "current version of spark on kubernetes it is not possible to include local",
    "start": "2034450",
    "end": "2040000"
  },
  {
    "text": "files with spark submit command so your dependencies have to be remotely",
    "start": "2040000",
    "end": "2046060"
  },
  {
    "text": "accessible or prepackaged into the container image I've tried both in this",
    "start": "2046060",
    "end": "2052090"
  },
  {
    "text": "example I am using pre-built dependencies so the difference is very",
    "start": "2052090",
    "end": "2059500"
  },
  {
    "text": "small you just need to add local colon slash slash prefix to the dependency URL",
    "start": "2059500",
    "end": "2067770"
  },
  {
    "text": "so what what is the demo the demo is like a practical example sometimes you",
    "start": "2067770",
    "end": "2075010"
  },
  {
    "text": "need to determine what TV show episodes to rewatch based on your preference so",
    "start": "2075010",
    "end": "2082960"
  },
  {
    "text": "collected Game of Thrones for example okay so you might have a favorite",
    "start": "2082960",
    "end": "2089710"
  },
  {
    "text": "character or a favorite thing that is discussed and I have an example where",
    "start": "2089710",
    "end": "2094929"
  },
  {
    "text": "you can run a job and indicate the keyword of your preference I would scan through the scripts of Game of Thrones",
    "start": "2094930",
    "end": "2101910"
  },
  {
    "text": "Season one or all of the seasons and build out a recommendation model with",
    "start": "2101910",
    "end": "2107800"
  },
  {
    "text": "ranked episodes of what which of them you might want to watch first and I'm",
    "start": "2107800",
    "end": "2114370"
  },
  {
    "text": "using Cassandra to save the search results if somebody already searched for a keyword of preference then we just",
    "start": "2114370",
    "end": "2121120"
  },
  {
    "text": "fetch it from Cassandra if nobody has searched for the keyword we can do the",
    "start": "2121120",
    "end": "2128140"
  },
  {
    "text": "spark job and compute it so let's go to the code and I will show you what it is",
    "start": "2128140",
    "end": "2138660"
  },
  {
    "text": "so this is a Scala project I have",
    "start": "2140370",
    "end": "2145690"
  },
  {
    "text": "packaged it using SBT assembly into a jar file because I need a jar to submit",
    "start": "2145690",
    "end": "2150790"
  },
  {
    "text": "using spark submit there are some dependencies here is a keyword which is",
    "start": "2150790",
    "end": "2157060"
  },
  {
    "text": "what I mentioned and here is a connection information for Cassandra Cassandra cluster and I'm using just the",
    "start": "2157060",
    "end": "2165250"
  },
  {
    "text": "word Cassandra because this is going to run with link kubernetes cluster and all",
    "start": "2165250",
    "end": "2170410"
  },
  {
    "text": "the Cassandra cluster is available by this name we have a key space that is",
    "start": "2170410",
    "end": "2176860"
  },
  {
    "text": "called sure recommender and the table called recommendations loading out the spark context connecting to Cassandra",
    "start": "2176860",
    "end": "2184240"
  },
  {
    "text": "cluster and checking if there is already information for that keyword if there is",
    "start": "2184240",
    "end": "2189790"
  },
  {
    "text": "nothing there we are basically looking at the scripts of the TV show and",
    "start": "2189790",
    "end": "2196020"
  },
  {
    "text": "removing all the stop words and building a count vectorizer model that would tell",
    "start": "2196020",
    "end": "2202780"
  },
  {
    "text": "us what episodes have the biggest occurrences of the curative reference we",
    "start": "2202780",
    "end": "2209290"
  },
  {
    "text": "indicated and finally we're writing this information back to Cassandra and",
    "start": "2209290",
    "end": "2214660"
  },
  {
    "text": "closing all the connections so to make it work there are a few things here I",
    "start": "2214660",
    "end": "2222580"
  },
  {
    "text": "need to start a Cuban company this proxy so that I can talk to kubernetes using",
    "start": "2222580",
    "end": "2229740"
  },
  {
    "text": "localhost and Here I am going to run the",
    "start": "2229740",
    "end": "2235510"
  },
  {
    "text": "sparks of mid command but first of all I",
    "start": "2235510",
    "end": "2240630"
  },
  {
    "text": "need to define a keyword so what is your",
    "start": "2240630",
    "end": "2248140"
  },
  {
    "text": "favorite game of thrones' character from the first season",
    "start": "2248140",
    "end": "2253109"
  },
  {
    "text": "Tyrian no more favorites okay okay so",
    "start": "2253250",
    "end": "2260070"
  },
  {
    "text": "we're defining a variable here and here is a spark submit command",
    "start": "2260070",
    "end": "2266099"
  },
  {
    "text": "we're indicating the master URL deploy modus cluster indicating our class that",
    "start": "2266099",
    "end": "2273420"
  },
  {
    "text": "is responsible for the functionality and I have my spark container image that I",
    "start": "2273420",
    "end": "2279000"
  },
  {
    "text": "have pre-built and included my jar into it I'm also adding the jar for Sparky",
    "start": "2279000",
    "end": "2287849"
  },
  {
    "text": "Sandra connector and including the keyword now if we start this we can",
    "start": "2287849",
    "end": "2297150"
  },
  {
    "text": "start watching kubernetes pods whoops get pods",
    "start": "2297150",
    "end": "2304550"
  },
  {
    "text": "so here is a container created for the driver and it is initializing now if we",
    "start": "2305820",
    "end": "2311820"
  },
  {
    "text": "look back here it's already running so that means there are here in our case",
    "start": "2311820",
    "end": "2317640"
  },
  {
    "text": "there are two executor pods created for spark that run the spark job and build",
    "start": "2317640",
    "end": "2323520"
  },
  {
    "text": "out the recommendation model so they were initialized but then now they are",
    "start": "2323520",
    "end": "2329160"
  },
  {
    "text": "running and performing the job and finally we see here that the container",
    "start": "2329160",
    "end": "2334770"
  },
  {
    "text": "is terminated in the phases succeeded so we see that executors are terminating",
    "start": "2334770",
    "end": "2341369"
  },
  {
    "text": "and the results are actually going to be gathered on the driver which is in a completed state it won't be removed so",
    "start": "2341369",
    "end": "2349430"
  },
  {
    "text": "we can always check the logs here and",
    "start": "2349430",
    "end": "2356810"
  },
  {
    "text": "here are the results so recommended episodes to watch with Tyrion are this so this this is",
    "start": "2356810",
    "end": "2364530"
  },
  {
    "text": "basically the output and we can see some other spark job information",
    "start": "2364530",
    "end": "2371900"
  },
  {
    "text": "so if eventually there won't be any executor pods but the driver will stay",
    "start": "2373049",
    "end": "2378599"
  },
  {
    "text": "stay here so now let's go back to the slides",
    "start": "2378599",
    "end": "2384260"
  },
  {
    "text": "so is running sparking kubernetes a good idea it may be a good idea for example",
    "start": "2385430",
    "end": "2393180"
  },
  {
    "text": "for a test environment or if you would like to try out a custom version of",
    "start": "2393180",
    "end": "2398599"
  },
  {
    "text": "spark really quickly or if you already have a kubernetes cluster and you have",
    "start": "2398599",
    "end": "2404430"
  },
  {
    "text": "some spare cycles that you might want to use for running spark jobs or in the",
    "start": "2404430",
    "end": "2410250"
  },
  {
    "text": "long term if you don't really want to have too many orchestrators if you already have kubernetes and spark runs",
    "start": "2410250",
    "end": "2416220"
  },
  {
    "text": "well on kubernetes just use it on kubernetes should I run it in production",
    "start": "2416220",
    "end": "2423829"
  },
  {
    "text": "probably not yet because it's very new but it will get better and we can help",
    "start": "2423829",
    "end": "2431700"
  },
  {
    "text": "make it better there is active development happening in this space and",
    "start": "2431700",
    "end": "2436980"
  },
  {
    "text": "you can still have a say about it if you want to change the way spark jobs are",
    "start": "2436980",
    "end": "2442140"
  },
  {
    "text": "going to be implemented on kubernetes and another important note is that it is",
    "start": "2442140",
    "end": "2447779"
  },
  {
    "text": "quite different from running a standalone spark on kubernetes so here",
    "start": "2447779",
    "end": "2454079"
  },
  {
    "text": "we don't really have spark master around all the time these are cloud native spark jobs where we only have driver and",
    "start": "2454079",
    "end": "2462779"
  },
  {
    "text": "executors running while the job is running after the job is completed all",
    "start": "2462779",
    "end": "2469020"
  },
  {
    "text": "of all of those things are completed the driver stays in a completed state and executors are completely terminated and",
    "start": "2469020",
    "end": "2475589"
  },
  {
    "text": "the code for this is here that go to",
    "start": "2475589",
    "end": "2480660"
  },
  {
    "text": "Cassandra spark if you'd like to see how it works and there are some resources",
    "start": "2480660",
    "end": "2487319"
  },
  {
    "text": "that might be useful blog post about Cassandra other was a talk that I gave",
    "start": "2487319",
    "end": "2493380"
  },
  {
    "text": "about distributed system algorithms I have an article about stable sets and",
    "start": "2493380",
    "end": "2498690"
  },
  {
    "text": "all of the demos are on github so I hope you had fun yeah and this is",
    "start": "2498690",
    "end": "2512140"
  },
  {
    "text": "me I am Leyna hall a senior cloud developer advocate working on Azure previously worked at Microsoft Research",
    "start": "2512140",
    "end": "2518500"
  },
  {
    "text": "and before that I lived in Europe and worked at many projects related to big",
    "start": "2518500",
    "end": "2524290"
  },
  {
    "text": "data distributed systems also functional programming and machine learning and",
    "start": "2524290",
    "end": "2529740"
  },
  {
    "text": "that's it thank you very much you can follow me on Twitter my DMS are open for",
    "start": "2529740",
    "end": "2534760"
  },
  {
    "text": "any questions [Applause]",
    "start": "2534760",
    "end": "2544578"
  }
]
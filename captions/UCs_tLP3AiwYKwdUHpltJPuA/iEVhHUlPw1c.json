[
  {
    "text": "today I want to present to you a use case how under why of why we chose a",
    "start": "30",
    "end": "5790"
  },
  {
    "text": "database to fit our data model rather than trying to adapt our data model to our database so with relational stores",
    "start": "5790",
    "end": "12690"
  },
  {
    "text": "you've pretty much taught there's one size fits all for your database so figure out your data model and you'll be fine and we did the opposite so first an",
    "start": "12690",
    "end": "21600"
  },
  {
    "text": "overview of what we do at SoundCloud those sound clouds a social platform you",
    "start": "21600",
    "end": "27480"
  },
  {
    "text": "can think of it like Flickr for sound or YouTube for sound and social sounds are",
    "start": "27480",
    "end": "33840"
  },
  {
    "text": "at our core so these are these are the sounds the little wave forms and social",
    "start": "33840",
    "end": "39000"
  },
  {
    "text": "activity around them like likes and comments and favoriting z' sharings the",
    "start": "39000",
    "end": "44010"
  },
  {
    "text": "this is how the sounds propagate and in this network on our site on our devices and also other social networks like",
    "start": "44010",
    "end": "50489"
  },
  {
    "text": "Facebook and Twitter so when logging into SoundCloud you get this page overview of the sounds inside of the",
    "start": "50489",
    "end": "58739"
  },
  {
    "text": "network sounds that other Creators about bloated and we're working hard on",
    "start": "58739",
    "end": "64710"
  },
  {
    "text": "fine-tuning that listening experience so if you'd like to see our our next next",
    "start": "64710",
    "end": "70470"
  },
  {
    "text": "website you can go to next stop SoundCloud a calm and I get a preview",
    "start": "70470",
    "end": "76009"
  },
  {
    "text": "we've seen some pretty good adoption and some success we serve a lot and we store",
    "start": "76490",
    "end": "82500"
  },
  {
    "text": "a lot and there's a 20 million registered users that are also helping",
    "start": "82500",
    "end": "88680"
  },
  {
    "text": "us on you at the web but this is gonna be a talk about databases and so after",
    "start": "88680",
    "end": "96630"
  },
  {
    "text": "introducing SoundCloud want to introduce this talk so thinking about what to",
    "start": "96630",
    "end": "102390"
  },
  {
    "text": "present I often go back and I say say what should I tell my past self so he",
    "start": "102390",
    "end": "108990"
  },
  {
    "text": "can be smarter and in this talk I wanted to ask myself what was the most",
    "start": "108990",
    "end": "116100"
  },
  {
    "text": "important lesson that we learned at SoundCloud about our database usage and",
    "start": "116100",
    "end": "122100"
  },
  {
    "text": "save you the suspense it's simply understand what your",
    "start": "122100",
    "end": "127140"
  },
  {
    "text": "database is for you so to put that in perspective if this was a",
    "start": "127140",
    "end": "132730"
  },
  {
    "text": "a architecture or if if this conference was for building architects that answer",
    "start": "132730",
    "end": "140140"
  },
  {
    "text": "may come in the form of understand what your building materials do for you and",
    "start": "140140",
    "end": "146170"
  },
  {
    "text": "it's not too far off in the world of structural engineering it's still putting boxes together maybe using",
    "start": "146170",
    "end": "154000"
  },
  {
    "text": "concrete instead of arrows and I wanted to shine a light on a dirty little",
    "start": "154000",
    "end": "160989"
  },
  {
    "text": "secret in our craft it not everything works as expected",
    "start": "160989",
    "end": "166440"
  },
  {
    "text": "so believe it or not much of the books that we read are coming from experience",
    "start": "166440",
    "end": "171970"
  },
  {
    "text": "of things that don't work but there's a definite lack of sharing these stories in the conferences like this and I want",
    "start": "171970",
    "end": "179560"
  },
  {
    "text": "to break out of that trend and and talk about stuff that hasn't worked so well as much as stuff that has worked so I'm",
    "start": "179560",
    "end": "188430"
  },
  {
    "text": "yeah if we're if we're using the metaphor of building materials we also need a metaphor of abstractions we need",
    "start": "188430",
    "end": "194859"
  },
  {
    "text": "these abstractions in our jobs to do our jobs effectively we can't be laying bricks every day and but in our world of",
    "start": "194859",
    "end": "202750"
  },
  {
    "text": "engineering we live under the constraints of physicality so we have",
    "start": "202750",
    "end": "208480"
  },
  {
    "text": "space and time and the laws of physics as our core constraints as engineers so",
    "start": "208480",
    "end": "214060"
  },
  {
    "text": "those constraints from the base of our materials and our abstractions form the",
    "start": "214060",
    "end": "219639"
  },
  {
    "text": "rest they form the art of our craft so as an industry we often put our our",
    "start": "219639",
    "end": "225160"
  },
  {
    "text": "blinders of abstraction on so this means that you may be looking at your problem",
    "start": "225160",
    "end": "230650"
  },
  {
    "text": "or may be looking at your source code through the facade of your IDE you may",
    "start": "230650",
    "end": "236709"
  },
  {
    "text": "be looking at your solutions at the stock imagery of a vendors brochure or",
    "start": "236709",
    "end": "242349"
  },
  {
    "text": "you may even be looking at your architecture with boxes and arrows they're all abstractions that help us do",
    "start": "242349",
    "end": "248079"
  },
  {
    "text": "our jobs effectively but it's too soon that we forget the limitations of the",
    "start": "248079",
    "end": "253959"
  },
  {
    "text": "physical world and how that applies to the abstractions that we use so seen with these eyes I'm going to introduce",
    "start": "253959",
    "end": "260470"
  },
  {
    "text": "the case study but first I'm gonna okay sorry have this",
    "start": "260470",
    "end": "267110"
  },
  {
    "text": "this case studies gonna go into details somewhat in depth but I still consider",
    "start": "267110",
    "end": "272150"
  },
  {
    "text": "them high enough level where I feel that they're important for all of us to know is we're going to talk about MySQL this",
    "start": "272150",
    "end": "280550"
  },
  {
    "text": "was the data store that we used for most of our online data and cassandra and this is the data store that we chose to",
    "start": "280550",
    "end": "287449"
  },
  {
    "text": "replace mysql for specific use case databases are different things to",
    "start": "287449",
    "end": "294320"
  },
  {
    "text": "different people and so i'm gonna limit the scope of this talk to just persistence so i'm not going to talk",
    "start": "294320",
    "end": "300949"
  },
  {
    "text": "about acid atomicity consistency durability or transactionality or base i",
    "start": "300949",
    "end": "308930"
  },
  {
    "text": "can't even remember what base dancefloor I'm just gonna talk about you write it",
    "start": "308930",
    "end": "314389"
  },
  {
    "text": "you read it it doesn't go away and there",
    "start": "314389",
    "end": "319849"
  },
  {
    "text": "may be some some kind of blow level details I have time after the talk to go into more depth I have a little bit of",
    "start": "319849",
    "end": "326180"
  },
  {
    "text": "time before catching a plane so I'm gonna try to leave some time at the end of the talk for questions in the",
    "start": "326180",
    "end": "332240"
  },
  {
    "text": "audience and then a bit at the podium and some of these details may be old hat",
    "start": "332240",
    "end": "338630"
  },
  {
    "text": "for you but whether or not the message is still the same understand your materials I'm gonna use some terminology",
    "start": "338630",
    "end": "347150"
  },
  {
    "text": "called primary storage and secondary storage just to clear that up primary storage is the storage attached to your",
    "start": "347150",
    "end": "354289"
  },
  {
    "text": "CPU secondary storage is the storage attached over your i/o bus primary",
    "start": "354289",
    "end": "360199"
  },
  {
    "text": "storage is your RAM secondary storage are your disks and the materials I'm",
    "start": "360199",
    "end": "366289"
  },
  {
    "text": "gonna be talking about are gonna be spinning disks so sometime during the talk you may think oh just why are you",
    "start": "366289",
    "end": "373039"
  },
  {
    "text": "wasting your life use SSDs and everything will be okay and that's not",
    "start": "373039",
    "end": "379370"
  },
  {
    "text": "the point the point is if you do use SSDs understand them if you don't need",
    "start": "379370",
    "end": "384860"
  },
  {
    "text": "to go to secondary storage understand your primary storage if your solution fits in Ram understand how your DRAM",
    "start": "384860",
    "end": "391490"
  },
  {
    "text": "works understand how your memory bus interacts with your CPU and how your CPU",
    "start": "391490",
    "end": "396889"
  },
  {
    "text": "interacts with it's Cash's and if you have massive storage and the exabyte scale if you're from Google here your materials would be",
    "start": "396889",
    "end": "405270"
  },
  {
    "text": "magnetic tape so you may also think I'm in the cloud I don't have to worry about",
    "start": "405270",
    "end": "411210"
  },
  {
    "text": "storage I'm in the cloud I don't have to worry about hardware it's the cloud does the hardware for me but the clouds also",
    "start": "411210",
    "end": "418530"
  },
  {
    "text": "based on the same first principles that we deal with his engineers based on the same materials and you can't ignore you",
    "start": "418530",
    "end": "425760"
  },
  {
    "text": "can't ignore the hardware that runs the cloud so the lessons learned here apply equally well in the cloud so the data",
    "start": "425760",
    "end": "433950"
  },
  {
    "text": "that we're storing and serving it composes our Activity Feed it's the it's",
    "start": "433950",
    "end": "440880"
  },
  {
    "text": "the dashboard page after you land after you log in and this display changes when",
    "start": "440880",
    "end": "445890"
  },
  {
    "text": "somebody in your social network either contributes or creates a social link",
    "start": "445890",
    "end": "451620"
  },
  {
    "text": "between them and a sound or whether they upload a sound themselves so this is",
    "start": "451620",
    "end": "457710"
  },
  {
    "text": "going to be the scope of the data model that we've taken out of our primary storage sorry with the primary database",
    "start": "457710",
    "end": "465419"
  },
  {
    "text": "and have built a specialized solution for this feed for the sake of the",
    "start": "465419",
    "end": "472350"
  },
  {
    "text": "product needs to be consistent so if you log in once and you see these these tracks and then you log in again and the",
    "start": "472350",
    "end": "478530"
  },
  {
    "text": "third track has disappeared that's an inconsistent experience and so for us as in the product development it",
    "start": "478530",
    "end": "485460"
  },
  {
    "text": "was very important to have that consistent experience and that meant saving off for us the easiest thing that",
    "start": "485460",
    "end": "492450"
  },
  {
    "text": "we could do is save that off beforehand and display it once you log back in as a",
    "start": "492450",
    "end": "503250"
  },
  {
    "text": "graph of our data model we have viewers and creators these are both the users",
    "start": "503250",
    "end": "510140"
  },
  {
    "text": "there's a relation of following there's relations two creations in the site and",
    "start": "510140",
    "end": "515159"
  },
  {
    "text": "then there's a transitive reduction from viewers to sounds over creators and",
    "start": "515159",
    "end": "520950"
  },
  {
    "text": "their creations we chose to materialize",
    "start": "520950",
    "end": "527220"
  },
  {
    "text": "the first degree of this traversal and what we call events there's other options when building an",
    "start": "527220",
    "end": "533050"
  },
  {
    "text": "activity stream you can also materialize that page on read but we chose to",
    "start": "533050",
    "end": "538449"
  },
  {
    "text": "materialize it on right for the goal of maintaining a consistent experience and",
    "start": "538449",
    "end": "543899"
  },
  {
    "text": "having it load quickly so we wanted to pre-compute all of the events so they",
    "start": "543899",
    "end": "551110"
  },
  {
    "text": "would be ready when the next next time that anybody logs in so we wanted our",
    "start": "551110",
    "end": "556420"
  },
  {
    "text": "goals were latency and and a consistent experience as a entity relation diagram",
    "start": "556420",
    "end": "563800"
  },
  {
    "text": "kind of an incomplete diagram but this is how you can model it with this is how",
    "start": "563800",
    "end": "570550"
  },
  {
    "text": "you typically visualize it in a relational store and we just took this mapping to the first degree of creations",
    "start": "570550",
    "end": "577149"
  },
  {
    "text": "and and save that off into its own table",
    "start": "577149",
    "end": "581970"
  },
  {
    "text": "yeah this worked out really well and there's some benefits for for having",
    "start": "582600",
    "end": "589480"
  },
  {
    "text": "this because at any point in time we can go back and reconstruct the dashboard",
    "start": "589480",
    "end": "594720"
  },
  {
    "text": "it's also robust against changes to our algorithm so if we say that we're going",
    "start": "594720",
    "end": "599949"
  },
  {
    "text": "to introduce or remove creations the prior creations don't change and so you",
    "start": "599949",
    "end": "607149"
  },
  {
    "text": "can maintain that consistent experience and the event store in MySQL worked out",
    "start": "607149",
    "end": "613420"
  },
  {
    "text": "pretty well but we've extrapolated some of our growth in the relation of how much we're restoring versus how many",
    "start": "613420",
    "end": "620079"
  },
  {
    "text": "registered accounts we were seeing and we quickly realized that we could be in",
    "start": "620079",
    "end": "627010"
  },
  {
    "text": "trouble but in fact we were actually in trouble and we were seeing up to two seconds of",
    "start": "627010",
    "end": "634209"
  },
  {
    "text": "load times for some of these dashboards and something that we tried to optimize",
    "start": "634209",
    "end": "641110"
  },
  {
    "text": "for up upfront by doing all this work calculating everybody's dashboard before",
    "start": "641110",
    "end": "646449"
  },
  {
    "text": "they even log in and so we were we were baffled like how can we do this we're",
    "start": "646449",
    "end": "651639"
  },
  {
    "text": "writing fine but we're reading slow this is completely opposite to our intuition of what relational databases are good",
    "start": "651639",
    "end": "658000"
  },
  {
    "text": "for and and so we sat down and we tried to",
    "start": "658000",
    "end": "663550"
  },
  {
    "text": "understand a little bit of why this was going on and I'm gonna jump around in time in the",
    "start": "663550",
    "end": "668830"
  },
  {
    "text": "past and actually describe what was going on because it shouldn't have been",
    "start": "668830",
    "end": "675399"
  },
  {
    "text": "this way we were we were writing just fine because of some natural properties",
    "start": "675399",
    "end": "682360"
  },
  {
    "text": "of our dataset so to illustrate that the",
    "start": "682360",
    "end": "688740"
  },
  {
    "text": "the table that we were writing had a surrogate key meaning that this was a sequence and a number sequence that was",
    "start": "688740",
    "end": "696580"
  },
  {
    "text": "managed by the database this sequence created an ordering that closely matched the ordering of events that were coming",
    "start": "696580",
    "end": "702940"
  },
  {
    "text": "in and this acted like a sequential clock and as a result the database could",
    "start": "702940",
    "end": "710050"
  },
  {
    "text": "use that to its advantage now to understand what the database is doing",
    "start": "710050",
    "end": "715810"
  },
  {
    "text": "for you we need to understand how the database is storage engine interacts",
    "start": "715810",
    "end": "721360"
  },
  {
    "text": "with the material and by using an ODB a storage engine the common storage engine",
    "start": "721360",
    "end": "727959"
  },
  {
    "text": "for MySQL actually an awesome storage engine from MySQL it just can throw it",
    "start": "727959",
    "end": "733120"
  },
  {
    "text": "whatever and it's not going to lose your data and it's optimized for a broad class of access patterns it's really",
    "start": "733120",
    "end": "740440"
  },
  {
    "text": "just the go-to general-purpose storage engine for mutable mutable state and the",
    "start": "740440",
    "end": "747399"
  },
  {
    "text": "way it manages this is it carefully balances a b-tree actually a B+ tree on",
    "start": "747399",
    "end": "755680"
  },
  {
    "text": "disk and this data structure has some branches and in its leaves it stores the",
    "start": "755680",
    "end": "761470"
  },
  {
    "text": "records so in an ODB everything's a be",
    "start": "761470",
    "end": "766540"
  },
  {
    "text": "tree even the even the records themselves are stored as a be tree",
    "start": "766540",
    "end": "772149"
  },
  {
    "text": "they're actually stored in an index form and in in ODB this the primary storage",
    "start": "772149",
    "end": "778360"
  },
  {
    "text": "for in ODB is as a clustered index meaning that they're ordered the records",
    "start": "778360",
    "end": "784959"
  },
  {
    "text": "are ordered off of the primary key so with that sequential primary key we get",
    "start": "784959",
    "end": "791140"
  },
  {
    "text": "our leaves which contain our records group the pages which contain the i/o units",
    "start": "791140",
    "end": "797670"
  },
  {
    "text": "nicely laid out sequentially on disk so the on disk format which we weren't",
    "start": "797670",
    "end": "806800"
  },
  {
    "text": "really aware of at the time it turned out to be quite efficient this is why we",
    "start": "806800",
    "end": "812440"
  },
  {
    "text": "were able to accommodate so many rewrites per second because we were just keeping that order and writing right one",
    "start": "812440",
    "end": "818560"
  },
  {
    "text": "after the other adding one page after the other but on Reed we couldn't read",
    "start": "818560",
    "end": "824830"
  },
  {
    "text": "in this order we needed to read off of those viewer IDs that were coming in",
    "start": "824830",
    "end": "831550"
  },
  {
    "text": "each viewer gets a unique index a unique view and as such we needed to index our",
    "start": "831550",
    "end": "837460"
  },
  {
    "text": "data set so that each viewer can pull out those records and we could follow the next degree of the traversals and so",
    "start": "837460",
    "end": "845529"
  },
  {
    "text": "nodb being a super b-tree stores the",
    "start": "845529",
    "end": "850630"
  },
  {
    "text": "index in index order in a b-tree as well and on this this turns out to be have",
    "start": "850630",
    "end": "857290"
  },
  {
    "text": "the exact same format the records traversable to the leaves in two pages",
    "start": "857290",
    "end": "864570"
  },
  {
    "text": "with the values of the leaves being the primary key of the item that the",
    "start": "864570",
    "end": "872080"
  },
  {
    "text": "secondary index is indexing so what this",
    "start": "872080",
    "end": "880529"
  },
  {
    "text": "that what happens when when adding and updating the indexes is that when as",
    "start": "880529",
    "end": "888100"
  },
  {
    "text": "you're as you're adding more and more items to an individual users activities",
    "start": "888100",
    "end": "893529"
  },
  {
    "text": "stream it may actually fill up one of these pages so one of these IR units is",
    "start": "893529",
    "end": "899860"
  },
  {
    "text": "16 kilobytes and if you've storing more than 16 kilobytes of primary keys in",
    "start": "899860",
    "end": "904990"
  },
  {
    "text": "this nodb performs a page split the it'll bump up against the next page so",
    "start": "904990",
    "end": "911230"
  },
  {
    "text": "there's no more room next to each other so I don't need to go off and create a new page typically at the end of the",
    "start": "911230",
    "end": "916839"
  },
  {
    "text": "tree and fill that up with your index so this is one characteristic of b-trees",
    "start": "916839",
    "end": "924420"
  },
  {
    "text": "when you run out of space you need to go somewhere else but once you do get",
    "start": "924420",
    "end": "929779"
  },
  {
    "text": "those primary keys and you go into the clustered index primary index I you may",
    "start": "929779",
    "end": "936020"
  },
  {
    "text": "be loading up different pages just to get a single record out of each page and",
    "start": "936020",
    "end": "941950"
  },
  {
    "text": "each of the pages that you load could potentially cause a seek this may be a",
    "start": "941950",
    "end": "950839"
  },
  {
    "text": "review for a lot of you but I really want to drill it in that that that why Sikhs are important when understanding",
    "start": "950839",
    "end": "957170"
  },
  {
    "text": "your database because this is what this is what got us the database is simply an",
    "start": "957170",
    "end": "963770"
  },
  {
    "text": "API to your storage medium that gives you some abstractions to reason about your data but Sikhs are not something",
    "start": "963770",
    "end": "969380"
  },
  {
    "text": "that we can we can ignore quickly overview the disks are spinning you can",
    "start": "969380",
    "end": "976250"
  },
  {
    "text": "pull data off of it or put data on to it as quickly as they're spinning but you",
    "start": "976250",
    "end": "981410"
  },
  {
    "text": "need to locate to where that is and yeah when the when you locate to where to put",
    "start": "981410",
    "end": "988130"
  },
  {
    "text": "the data on the physical device you may need to move for where you are and that causes a seek it's difficult to",
    "start": "988130",
    "end": "997100"
  },
  {
    "text": "conceptualize how bad these actually are without understanding a little bit or having a mental model of of time and I I",
    "start": "997100",
    "end": "1005440"
  },
  {
    "text": "think it's important for all of us to strengthen our mental model so this is a",
    "start": "1005440",
    "end": "1010450"
  },
  {
    "text": "nanosecond and it's kind of hard to visualize because we have no sense I",
    "start": "1010450",
    "end": "1016540"
  },
  {
    "text": "mean this did you make toast and it pops out in a nanosecond or or what there's",
    "start": "1016540",
    "end": "1022120"
  },
  {
    "text": "nothing that we deal with except our computers that work in this time scale so if we translate this time to distance",
    "start": "1022120",
    "end": "1029230"
  },
  {
    "text": "we can get a little bit more intuition about how long that actually is so every",
    "start": "1029230",
    "end": "1036610"
  },
  {
    "text": "day you can't go faster than the speed of light unless you watch Damien's talk",
    "start": "1036610",
    "end": "1041709"
  },
  {
    "text": "and you're using Perl so if we if we go the speed of light in one nanosecond",
    "start": "1041709",
    "end": "1047260"
  },
  {
    "text": "that equates to the distance of about this much about the long side of a piece",
    "start": "1047260",
    "end": "1052690"
  },
  {
    "text": "of paper about 30 centimeters so that's that's a nanosecond that's that's one",
    "start": "1052690",
    "end": "1058090"
  },
  {
    "text": "nanosecond this is the fundamental unit of our computers this is what we're processing our code at",
    "start": "1058090",
    "end": "1064570"
  },
  {
    "text": "this is what the this is the the unit of measurement that we measure our inner functions this is this these are the",
    "start": "1064570",
    "end": "1072070"
  },
  {
    "text": "fundamental units of our computing universe but yet these are the units for",
    "start": "1072070",
    "end": "1081460"
  },
  {
    "text": "seek it could take up to 10 milliseconds to seek and so how how long is a",
    "start": "1081460",
    "end": "1088750"
  },
  {
    "text": "secretive to a nanosecond how long is going to disk relative to staying in code and how far could an electron",
    "start": "1088750",
    "end": "1095890"
  },
  {
    "text": "travel at the speed of light in 10 milliseconds so to give you an idea 10",
    "start": "1095890",
    "end": "1102370"
  },
  {
    "text": "milliseconds for an electron is like going to Milan from here and coming back",
    "start": "1102370",
    "end": "1108420"
  },
  {
    "text": "so it's like a round trip to Italy to send something to your disk and this is",
    "start": "1108420",
    "end": "1114040"
  },
  {
    "text": "why we started to see those two second response times so once you have a seek",
    "start": "1114040",
    "end": "1120780"
  },
  {
    "text": "you pretty much know where your bottlenecks gonna be next next thing",
    "start": "1120780",
    "end": "1128020"
  },
  {
    "text": "that we saw is that it wasn't just six it was also storage so from our growth",
    "start": "1128020",
    "end": "1135160"
  },
  {
    "text": "we knew that we couldn't keep all of our events on one host and we also knew that",
    "start": "1135160",
    "end": "1142600"
  },
  {
    "text": "we were creating more and more pages for our index and and this was all for what",
    "start": "1142600",
    "end": "1148990"
  },
  {
    "text": "was ultimately mostly cold data mostly data that would never get loaded in the",
    "start": "1148990",
    "end": "1154360"
  },
  {
    "text": "in one day so the more storage we had",
    "start": "1154360",
    "end": "1160210"
  },
  {
    "text": "the more space the more storage that we required the more space between our pages that we were seeing and the more",
    "start": "1160210",
    "end": "1166060"
  },
  {
    "text": "sikhs that we were incurring and yeah",
    "start": "1166060",
    "end": "1171730"
  },
  {
    "text": "and we also knew from extrapolating our growth that we wouldn't be able to fit on one host for very much longer so we",
    "start": "1171730",
    "end": "1179560"
  },
  {
    "text": "took took a 10,000 foot view and as a",
    "start": "1179560",
    "end": "1184660"
  },
  {
    "text": "reminder we didn't know this back then so we didn't know it what I just described and so we only had a 10,000",
    "start": "1184660",
    "end": "1191710"
  },
  {
    "text": "10,000 foot view back then we didn't realize that what we were having was a disc problem what we saw",
    "start": "1191710",
    "end": "1198830"
  },
  {
    "text": "was we were having a database problem the documentation about all this is",
    "start": "1198830",
    "end": "1203869"
  },
  {
    "text": "tucked away on my SQL documentation site so we eventually did learn it but at the",
    "start": "1203869",
    "end": "1210980"
  },
  {
    "text": "time all we saw was outgrowing our storage capacity getting response times",
    "start": "1210980",
    "end": "1217879"
  },
  {
    "text": "that were out of reason and yeah and not having a way of mitigating it with the",
    "start": "1217879",
    "end": "1225139"
  },
  {
    "text": "database that we were running on so we have some tough questions to ask we needed to ask ourselves do we want to",
    "start": "1225139",
    "end": "1231259"
  },
  {
    "text": "keep this materialisation on right strategy did we want to change everything and go with the materialization on read and then we",
    "start": "1231259",
    "end": "1238190"
  },
  {
    "text": "considered the product and we considered the amount of change that it would take to completely change the way that we",
    "start": "1238190",
    "end": "1244700"
  },
  {
    "text": "were displaying the Activity Feed and we said yeah let's stick with the materialization on right and let's look",
    "start": "1244700",
    "end": "1252139"
  },
  {
    "text": "at the databases but before looking at the databases we we spent a little bit",
    "start": "1252139",
    "end": "1257419"
  },
  {
    "text": "of time understanding our data model and yeah some of the yeah some of the",
    "start": "1257419",
    "end": "1266450"
  },
  {
    "text": "properties of our data model were quite beneficial and it's eventually",
    "start": "1266450",
    "end": "1271549"
  },
  {
    "text": "consistent and by this meet I mean eventually consistent in that the rights",
    "start": "1271549",
    "end": "1277779"
  },
  {
    "text": "are observable in the same order by any reader but at different times so if you",
    "start": "1277779",
    "end": "1285379"
  },
  {
    "text": "write if there's rights of a B and C every reader will see a B and C but they",
    "start": "1285379",
    "end": "1291739"
  },
  {
    "text": "may not see a at the same time and they may not see B at the same time but this is fine because we just have one reader",
    "start": "1291739",
    "end": "1297489"
  },
  {
    "text": "so if you only have one reader everything can be eventually consistent as long as the reader is not the writer",
    "start": "1297489",
    "end": "1306070"
  },
  {
    "text": "and on top of that because people don't log in not everybody logs in at the same",
    "start": "1308200",
    "end": "1315679"
  },
  {
    "text": "time it could be multiple days between logins and so a read could have been",
    "start": "1315679",
    "end": "1321649"
  },
  {
    "text": "actually much much later than our right we also knew we had hot writes all the",
    "start": "1321649",
    "end": "1328750"
  },
  {
    "text": "contents being created right now and so if we're going to materialize that first degree of our graph we are writing all",
    "start": "1328750",
    "end": "1338320"
  },
  {
    "text": "at the same place and no matter how fast you can go if you have a hot spot you're",
    "start": "1338320",
    "end": "1345430"
  },
  {
    "text": "likely going to run into a bottleneck eventually so we knew that we needed to",
    "start": "1345430",
    "end": "1351910"
  },
  {
    "text": "have at least some measure to be able to distribute these rights over multiple locations but identifying your hot spots",
    "start": "1351910",
    "end": "1358450"
  },
  {
    "text": "also means that you can use some techniques you can stay in primary",
    "start": "1358450",
    "end": "1363850"
  },
  {
    "text": "storage for a little bit longer before going to secondary storage so you can basically buffer in RAM before writing",
    "start": "1363850",
    "end": "1370480"
  },
  {
    "text": "to disk and this will mean this means that you can accept more at a higher",
    "start": "1370480",
    "end": "1375640"
  },
  {
    "text": "write rate and then flush out we also",
    "start": "1375640",
    "end": "1381370"
  },
  {
    "text": "had cold reads so most of the pages that we were rendering we're going to be",
    "start": "1381370",
    "end": "1387940"
  },
  {
    "text": "rendering from storage there was no way that we could keep everybody's dashboard",
    "start": "1387940",
    "end": "1393040"
  },
  {
    "text": "in RAM this would be totally wasteful a use of RAM and we could count on the",
    "start": "1393040",
    "end": "1402429"
  },
  {
    "text": "viewers once they load their dashboard to only only load the head of the dashboard sequentially ordered by time",
    "start": "1402429",
    "end": "1409780"
  },
  {
    "text": "once they once they find their index we also because we didn't want to stay with",
    "start": "1409780",
    "end": "1415950"
  },
  {
    "text": "we wanted to avoid having hot spots on writes and we wanted to distribute the cold reads and we knew we weren't grown",
    "start": "1415950",
    "end": "1422140"
  },
  {
    "text": "able to fit on one host we knew our data set needed to be partitioned and this",
    "start": "1422140",
    "end": "1428679"
  },
  {
    "text": "was one of the more important things that we identified is that we identified our partition key the thing that we",
    "start": "1428679",
    "end": "1435850"
  },
  {
    "text": "could split on and the nature of the data model is that it's only the viewers",
    "start": "1435850",
    "end": "1441309"
  },
  {
    "text": "that need their data set so we could partition on the viewer key or the viewer identifier and by knowing this a",
    "start": "1441309",
    "end": "1448929"
  },
  {
    "text": "lot of options came up because we only needed to be consistent on a single partition for a single viewer ID",
    "start": "1448929",
    "end": "1458110"
  },
  {
    "text": "so given with that we yeah we stuck with the storage heavy approach and we needed",
    "start": "1458110",
    "end": "1465770"
  },
  {
    "text": "to grow over multiple hosts so there's really only one thing that we could do let's throw hardware at the problem so",
    "start": "1465770",
    "end": "1473990"
  },
  {
    "text": "we knew we had to throw harder at the problem and I thought we needed a new",
    "start": "1473990",
    "end": "1479030"
  },
  {
    "text": "database we thought because we thought that ok with if we have multiple",
    "start": "1479030",
    "end": "1484340"
  },
  {
    "text": "machines we need a database that can live on multiple machines relational",
    "start": "1484340",
    "end": "1489500"
  },
  {
    "text": "databases can live on multiple machines but we saw that there was this was in 2009 we saw a lot of new technology show",
    "start": "1489500",
    "end": "1497840"
  },
  {
    "text": "up on the market that had promises of just making partition making",
    "start": "1497840",
    "end": "1504590"
  },
  {
    "text": "partitioning a non-issue and so we evaluated a little bit of the market but",
    "start": "1504590",
    "end": "1509780"
  },
  {
    "text": "we also evaluated our workflow and how our workflow would integrate with the databases that we were looking at",
    "start": "1509780",
    "end": "1516370"
  },
  {
    "text": "ultimately when you have data in one form and you need to get it to another form you're going to be applying this",
    "start": "1516370",
    "end": "1523400"
  },
  {
    "text": "age-old technique of an ETL this is fine",
    "start": "1523400",
    "end": "1529010"
  },
  {
    "text": "this is eventually consistent in its core because I the extract each of these",
    "start": "1529010",
    "end": "1534830"
  },
  {
    "text": "steps happen in different transactions and or could happen in different transactions and for us the extract was",
    "start": "1534830",
    "end": "1543280"
  },
  {
    "text": "taking the changes as they were happening the transform was finding",
    "start": "1543280",
    "end": "1549050"
  },
  {
    "text": "those edges to materialize first and it was the load part that we were having problems with because we needed to write",
    "start": "1549050",
    "end": "1557120"
  },
  {
    "text": "enough edges so this is in the orders of hundreds of thousands a second to",
    "start": "1557120",
    "end": "1563870"
  },
  {
    "text": "materialize our index and we needed to load them in a way that was reasonable",
    "start": "1563870",
    "end": "1569210"
  },
  {
    "text": "across multiple hosts but what we really wanted was to take advantage of our",
    "start": "1569210",
    "end": "1575180"
  },
  {
    "text": "write hot spots and write everything into memory and then take advantage of our secondary storage and read",
    "start": "1575180",
    "end": "1581210"
  },
  {
    "text": "everything from disk and somewhere in between we didn't want to have to do any work and this is where we had this dream",
    "start": "1581210",
    "end": "1589160"
  },
  {
    "text": "of like what if we could do this so we started to evaluate our databases based off of whether they can fill in",
    "start": "1589160",
    "end": "1596150"
  },
  {
    "text": "the magic happens part and it turns out we found one so Cassandra has this fake",
    "start": "1596150",
    "end": "1602929"
  },
  {
    "text": "ten but it also had a lot of other properties that were quite beneficial so",
    "start": "1602929",
    "end": "1611360"
  },
  {
    "text": "being ignorant that we actually had a disk problem we decided to throw",
    "start": "1611360",
    "end": "1617720"
  },
  {
    "text": "Cassandra at it because it it aligned with our data our data model and it also",
    "start": "1617720",
    "end": "1625039"
  },
  {
    "text": "offered some conveniences to make our ETL simpler so Cassandra is eventually",
    "start": "1625039",
    "end": "1633980"
  },
  {
    "text": "consistent in its core so you've probably heard a lot about a cap theorem and Cassandra is in the AP section of",
    "start": "1633980",
    "end": "1641720"
  },
  {
    "text": "the cap theorem and every every observer every reader on any node will see the",
    "start": "1641720",
    "end": "1648890"
  },
  {
    "text": "writes that happened even on other nodes eventually every node is a master and a",
    "start": "1648890",
    "end": "1654919"
  },
  {
    "text": "slave so you can connect to any node in your database cluster and read and write",
    "start": "1654919",
    "end": "1660919"
  },
  {
    "text": "to it you can think of it as like a distributed hash table where you whether",
    "start": "1660919",
    "end": "1669409"
  },
  {
    "text": "the writes will get routed to the to the right host and there's well understood a",
    "start": "1669409",
    "end": "1674929"
  },
  {
    "text": "multi data center replication so I believe later in the track Adrian will",
    "start": "1674929",
    "end": "1680690"
  },
  {
    "text": "talk about how Netflix achieves this with multi zone replication which is the",
    "start": "1680690",
    "end": "1686900"
  },
  {
    "text": "same thing as multi datacenter replication multi-zone multi region and",
    "start": "1686900",
    "end": "1694150"
  },
  {
    "text": "yeah and this end rights are distributed so as the rights come in we can split",
    "start": "1694570",
    "end": "1701059"
  },
  {
    "text": "out and avoid those hotspots by distributing our rights across different nodes in the cluster because you can",
    "start": "1701059",
    "end": "1706640"
  },
  {
    "text": "write to any any single one cassandra also offers this so the the beautiful",
    "start": "1706640",
    "end": "1715220"
  },
  {
    "text": "nature of our right path with that sequential with the sequential writes a",
    "start": "1715220",
    "end": "1720409"
  },
  {
    "text": "nice ordered data set and then sequential reads as well means",
    "start": "1720409",
    "end": "1726020"
  },
  {
    "text": "that we can actually we could it gives us the promise of no more trips to Milan",
    "start": "1726020",
    "end": "1732670"
  },
  {
    "text": "seeing this I just imagined okay yeah sikhs can get under control but how",
    "start": "1732670",
    "end": "1740390"
  },
  {
    "text": "cassandra does this is an understanding of its data model and it's also and its",
    "start": "1740390",
    "end": "1747440"
  },
  {
    "text": "storage model so first to start with Cassandra's data model which is",
    "start": "1747440",
    "end": "1753200"
  },
  {
    "text": "important to understand so to know how cassandra turns its data model into on",
    "start": "1753200",
    "end": "1758480"
  },
  {
    "text": "disk storage and being in a distraction over the storage layer we first need to",
    "start": "1758480",
    "end": "1764840"
  },
  {
    "text": "understand what what kind of abstractions we have to work with so I've never liked SQL when I started us",
    "start": "1764840",
    "end": "1773360"
  },
  {
    "text": "started writing SQL statements I do this so I imagined okay I have a little bit",
    "start": "1773360",
    "end": "1781430"
  },
  {
    "text": "of data over here a little bit of data over here I make the same schema and then I want to choose which data I'm going to query from and this has always",
    "start": "1781430",
    "end": "1789200"
  },
  {
    "text": "bugged me because conceptually I group my I group my partitions in tables mentally and I want to select which",
    "start": "1789200",
    "end": "1796970"
  },
  {
    "text": "table I'm I'm looking into so I didn't have any theory about why the this",
    "start": "1796970",
    "end": "1802910"
  },
  {
    "text": "language doesn't allow that but I've always found it annoying but if we could do this and we could create 20 million",
    "start": "1802910",
    "end": "1811190"
  },
  {
    "text": "tables then partitioning is a no-brainer we just select the the users out of the user to each of the user IDs tables now",
    "start": "1811190",
    "end": "1818390"
  },
  {
    "text": "would have been great oh yeah and Cassandra yeah Cassandra has",
    "start": "1818390",
    "end": "1825380"
  },
  {
    "text": "this model baked in but I've also wanted",
    "start": "1825380",
    "end": "1830630"
  },
  {
    "text": "to do this so I didn't know about the entity attribute value pattern I guess",
    "start": "1830630",
    "end": "1836380"
  },
  {
    "text": "where you can create a table and then you can with that table you can create",
    "start": "1836380",
    "end": "1842300"
  },
  {
    "text": "arbitrary attributes sets I always wanted to know what attributes I have",
    "start": "1842300",
    "end": "1847940"
  },
  {
    "text": "available and so I make these super wide tables I mean this was a long time ago I",
    "start": "1847940",
    "end": "1853040"
  },
  {
    "text": "make super wide tables and then say I want that call I call him in that column I want to know what columns are there so I'm gonna make",
    "start": "1853040",
    "end": "1859010"
  },
  {
    "text": "a very wide table but again you can't do this with SQL but even if you could do",
    "start": "1859010",
    "end": "1867919"
  },
  {
    "text": "it in consent or you'd there's a there's a trade-off in Cassandra you don't get a",
    "start": "1867919",
    "end": "1873500"
  },
  {
    "text": "flexible order by statement you can only order by your columns so this is okay it",
    "start": "1873500",
    "end": "1881090"
  },
  {
    "text": "just means you have to pick your columns carefully and yeah that's that's about",
    "start": "1881090",
    "end": "1889490"
  },
  {
    "text": "it for this kind of butchering of the SQL metaphor so if we look at the actual",
    "start": "1889490",
    "end": "1898760"
  },
  {
    "text": "terminology you can think of the data model and Concentra like a giant matrix",
    "start": "1898760",
    "end": "1905289"
  },
  {
    "text": "you have row keys column names and then the values and at the intersection of",
    "start": "1905590",
    "end": "1912260"
  },
  {
    "text": "the row key and the column name you can find your value and the important",
    "start": "1912260",
    "end": "1917779"
  },
  {
    "text": "difference when considering this data model versus a relational model is that you can only scan over the columns you",
    "start": "1917779",
    "end": "1926710"
  },
  {
    "text": "you don't scan over the rows and in",
    "start": "1926710",
    "end": "1935149"
  },
  {
    "text": "Cassandra the order in which you scan over the columns is defined in your",
    "start": "1935149",
    "end": "1940639"
  },
  {
    "text": "schema so it's like setting that order by statement but up front it's possible",
    "start": "1940639",
    "end": "1947750"
  },
  {
    "text": "to to model a data set like you would",
    "start": "1947750",
    "end": "1953210"
  },
  {
    "text": "with a relational model like if you were to do a user's table you just pick some column names which are stable so you can",
    "start": "1953210",
    "end": "1961730"
  },
  {
    "text": "have your your name your avatar URL your email and this would be fine but what",
    "start": "1961730",
    "end": "1967549"
  },
  {
    "text": "you sacrifice is that you can't scan give me the all the rows that have a",
    "start": "1967549",
    "end": "1973090"
  },
  {
    "text": "first name of Bob Cassandra does have secondary indexes not going to go into",
    "start": "1973090",
    "end": "1979039"
  },
  {
    "text": "those but this would be a typical entity modeling in Cassandra because Sandra can",
    "start": "1979039",
    "end": "1986330"
  },
  {
    "text": "do a little bit more so if you use the same key as your Oki",
    "start": "1986330",
    "end": "1992159"
  },
  {
    "text": "is as your in your column name you could easily model an adjacency matrix and with this you can model a",
    "start": "1992159",
    "end": "1998429"
  },
  {
    "text": "directed graph and so the columns just grow the rows grow and you can scan over",
    "start": "1998429",
    "end": "2003769"
  },
  {
    "text": "give me all the outbound edges that I have for any given node it's also",
    "start": "2003769",
    "end": "2013909"
  },
  {
    "text": "possible to model our existing activity stream so if we had a globally consistent sequence generator which was",
    "start": "2013909",
    "end": "2021019"
  },
  {
    "text": "generating those sequence IDs we could use the column comparator in and order",
    "start": "2021019",
    "end": "2028309"
  },
  {
    "text": "our columns in the same sequence order that that we had in our relational store but if we didn't have that globally",
    "start": "2028309",
    "end": "2035659"
  },
  {
    "text": "consistent counter we could end up creating duplicates and it's not as",
    "start": "2035659",
    "end": "2042139"
  },
  {
    "text": "important with our dataset but we decided to model it slightly differently to make the duplicates impossible and we",
    "start": "2042139",
    "end": "2050960"
  },
  {
    "text": "did this by using the clock of time but even time can have duplicates because not all clocks are unique so to make",
    "start": "2050960",
    "end": "2058550"
  },
  {
    "text": "them unique we encoded them as uu IDs so it's a variant of version 1 uu IDs where the",
    "start": "2058550",
    "end": "2065599"
  },
  {
    "text": "high bits are where the timestamp lives low bits or where the uniqueness lives",
    "start": "2065599",
    "end": "2072730"
  },
  {
    "text": "so this this is no SQL for me this is no",
    "start": "2072730",
    "end": "2078378"
  },
  {
    "text": "SQL for me is when you model your data how you want to read it this is how",
    "start": "2078379",
    "end": "2086030"
  },
  {
    "text": "we're gonna access it we're gonna access it in the order of time based off of our column comparator and we're gonna create",
    "start": "2086030",
    "end": "2093138"
  },
  {
    "text": "a very sparse matrix of this and we're just gonna find the row find the columns",
    "start": "2093139",
    "end": "2099440"
  },
  {
    "text": "and we'll be done with it and I think most of the know SQL databases provide",
    "start": "2099440",
    "end": "2107690"
  },
  {
    "text": "means to have finer control of your access patterns based off of how you model it your data in the database but",
    "start": "2107690",
    "end": "2114770"
  },
  {
    "text": "for rights we need to understand Cassandra storage",
    "start": "2114770",
    "end": "2120260"
  },
  {
    "text": "model which is unique it's different than then in ODB's at first we get a",
    "start": "2120260",
    "end": "2129950"
  },
  {
    "text": "little bit of the partitioning out of the way I'm not going to go into depth about partitioning it's one of its strengths and it has a lot of coverage",
    "start": "2129950",
    "end": "2136160"
  },
  {
    "text": "so you can read up about it later but the quick overview is that for any given",
    "start": "2136160",
    "end": "2141590"
  },
  {
    "text": "row key it only uses the row key and then finds a host to store and retrieve",
    "start": "2141590",
    "end": "2148430"
  },
  {
    "text": "that row from it can be more than one hosts if you have redundancy and we use",
    "start": "2148430",
    "end": "2155060"
  },
  {
    "text": "the random host partitioning meaning that any given row key could be on any host but is predictable this is why we",
    "start": "2155060",
    "end": "2163340"
  },
  {
    "text": "can't do row scans because the row keys may not be sequential on on each of the nodes so the storage engine in MySQL I'm",
    "start": "2163340",
    "end": "2174500"
  },
  {
    "text": "sorry in Cassandra is based off of section in the Google's BigTable paper",
    "start": "2174500",
    "end": "2181750"
  },
  {
    "text": "which splits the problem exactly where we would like to have it split so for",
    "start": "2181750",
    "end": "2188900"
  },
  {
    "text": "for rights and for hot reads the primary",
    "start": "2188900",
    "end": "2194210"
  },
  {
    "text": "storage is used in a data structure called mem tables or memory tables these",
    "start": "2194210",
    "end": "2199250"
  },
  {
    "text": "are you can think of them as just hash tables and for secondary storage for our",
    "start": "2199250",
    "end": "2204430"
  },
  {
    "text": "rights and also our cold reads cassandra our the BigTable paper introduces the",
    "start": "2204430",
    "end": "2211790"
  },
  {
    "text": "concept of sorted string tables the sort of the string tables are where the magic happens because if you have a sort of",
    "start": "2211790",
    "end": "2219080"
  },
  {
    "text": "data structure you can actually infer quite a bit your searches into it become a whole like a degree simpler in",
    "start": "2219080",
    "end": "2229310"
  },
  {
    "text": "complexity and and this sorted string table allows you to maintain that those",
    "start": "2229310",
    "end": "2236510"
  },
  {
    "text": "sequential reads and the sequential writes so in memory as the writes are",
    "start": "2236510",
    "end": "2242720"
  },
  {
    "text": "coming in they're coming in in any order they could be any row key any column name it doesn't really matter because",
    "start": "2242720",
    "end": "2248840"
  },
  {
    "text": "they're just going to primary stores they're just going to RAM and so if you have a read immediately after a right",
    "start": "2248840",
    "end": "2254549"
  },
  {
    "text": "you don't even hit the disk Cassandra is durable so it'll it'll commit to a",
    "start": "2254549",
    "end": "2259949"
  },
  {
    "text": "commit log before actually committing to the right or the mem table so it's still",
    "start": "2259949",
    "end": "2267150"
  },
  {
    "text": "fast to accept rights but when that table fills up and it will fill up as",
    "start": "2267150",
    "end": "2273809"
  },
  {
    "text": "you're adding stuff for adding changes it periodically needs to flush out of",
    "start": "2273809",
    "end": "2278880"
  },
  {
    "text": "RAM and and this is where Cassandra and also HBase will take take the mem tables",
    "start": "2278880",
    "end": "2288959"
  },
  {
    "text": "sort them off the Roky then sort them off the column names and to create a",
    "start": "2288959",
    "end": "2295229"
  },
  {
    "text": "stable sort in structure and then it'll take that and just sequentially write it to disk and then start with a new mint",
    "start": "2295229",
    "end": "2302189"
  },
  {
    "text": "able it's important to know that that",
    "start": "2302189",
    "end": "2307829"
  },
  {
    "text": "nothing is overwritten on disk so in the B tree you know DB spends a lot of work",
    "start": "2307829",
    "end": "2313549"
  },
  {
    "text": "reusing portions of the page we're using portions of the pages that the leaves",
    "start": "2313549",
    "end": "2319819"
  },
  {
    "text": "make sure that like if you run out of space on the leave it'll leave it'll add a new one and it does a lot of magic in",
    "start": "2319819",
    "end": "2327239"
  },
  {
    "text": "place on this can that keeps it keeps the data set pretty dense here it's just flushed out but what that means is that",
    "start": "2327239",
    "end": "2337079"
  },
  {
    "text": "as you're fleshing memory tables out to SS tables on disk you're going to be",
    "start": "2337079",
    "end": "2342569"
  },
  {
    "text": "generating a lot of SS tables because it's only gonna be with what you were storing in RAM and this could be yeah",
    "start": "2342569",
    "end": "2349439"
  },
  {
    "text": "100 100 Meg's tops no not even that is I think we're at net 2 Meg's so but we",
    "start": "2349439",
    "end": "2357749"
  },
  {
    "text": "actually flush even smaller or smaller sizes so so what you end up with is a",
    "start": "2357749",
    "end": "2363959"
  },
  {
    "text": "directory full of SS tables and when performing a read your columns could be",
    "start": "2363959",
    "end": "2373079"
  },
  {
    "text": "living in more than one table and so Cassandra keeps some bookkeeping around of what what columns are and what rows",
    "start": "2373079",
    "end": "2381329"
  },
  {
    "text": "are in which SS tables and then it needs to consult all of them to satisfy your read so you can see if",
    "start": "2381329",
    "end": "2388500"
  },
  {
    "text": "there's really not much difference if we if we had all these SS tables on disk this would be very similar to having all",
    "start": "2388500",
    "end": "2394230"
  },
  {
    "text": "of our page splits in our be tree and we would be we'd be seeking all over the",
    "start": "2394230",
    "end": "2400770"
  },
  {
    "text": "place to try to satisfy a read so cassandra has a compaction phase which",
    "start": "2400770",
    "end": "2408480"
  },
  {
    "text": "will read these numbers which will read a set of SS tables in since they're already sorted the merge is incredibly",
    "start": "2408480",
    "end": "2414570"
  },
  {
    "text": "efficient and it'll flush that out sequentially and this is a constant",
    "start": "2414570",
    "end": "2419700"
  },
  {
    "text": "background process that happens that converges the SS tables to reduce the",
    "start": "2419700",
    "end": "2424920"
  },
  {
    "text": "number of tables that are needed to be consulted before a read can be satisfied",
    "start": "2424920",
    "end": "2433880"
  },
  {
    "text": "but even so you can't keep everything compacted at the same time so you would",
    "start": "2434360",
    "end": "2439740"
  },
  {
    "text": "think that you would be just trading seeks in the B tree to seeks across the",
    "start": "2439740",
    "end": "2445710"
  },
  {
    "text": "SS tables for us we have a maximum of 20",
    "start": "2445710",
    "end": "2451980"
  },
  {
    "text": "SS tables that we consult for our dashboards so this is this is from a couple days ago a histogram of number of",
    "start": "2451980",
    "end": "2459120"
  },
  {
    "text": "SS tables consulted for all of our reads bucketed by the number of SS tables an",
    "start": "2459120",
    "end": "2466170"
  },
  {
    "text": "important thing to note is that the trend goes left so the trend in cassandra is to reduce",
    "start": "2466170",
    "end": "2473460"
  },
  {
    "text": "the number of seeks reduce the number of tables that needed to be consulted or",
    "start": "2473460",
    "end": "2479040"
  },
  {
    "text": "leaves that need to be consulted we're in the way that we were using the beech",
    "start": "2479040",
    "end": "2484350"
  },
  {
    "text": "tree in MySQL that trend was the other direction so it's - seeks per SS table",
    "start": "2484350",
    "end": "2492720"
  },
  {
    "text": "and at 2020 SS tables as a maximum for satisfying our reads we now know our",
    "start": "2492720",
    "end": "2499590"
  },
  {
    "text": "upper bound our per bounce 46 and with this we we have a great we have a much",
    "start": "2499590",
    "end": "2505920"
  },
  {
    "text": "more confidence but even at 46 one would think consulting all those tables for cold",
    "start": "2505920",
    "end": "2512400"
  },
  {
    "text": "reads would increase latency so even in out in Milan land where we're",
    "start": "2512400",
    "end": "2520800"
  },
  {
    "text": "consulting many of their tables were still much better off than we were with",
    "start": "2520800",
    "end": "2525830"
  },
  {
    "text": "MySQL so we're under under 200 milliseconds in our upper bound for the",
    "start": "2525830",
    "end": "2532770"
  },
  {
    "text": "for satisfying a dashboard read and these are our cold reads these are the reads that for somebody that hasn't",
    "start": "2532770",
    "end": "2538740"
  },
  {
    "text": "logged in for a while that that needs to pull that up into RAM our average is 20",
    "start": "2538740",
    "end": "2544980"
  },
  {
    "text": "milliseconds and that's still a couple trips to Milan but it's much better than",
    "start": "2544980",
    "end": "2550770"
  },
  {
    "text": "we were doing before and writes our whole different unit of measurement so",
    "start": "2550770",
    "end": "2557130"
  },
  {
    "text": "when you see a distribution like this you you know you're doing it right because it's nice and tight you don't",
    "start": "2557130",
    "end": "2562320"
  },
  {
    "text": "have any outliers you can just pretty much ignore the unit's because because",
    "start": "2562320",
    "end": "2568500"
  },
  {
    "text": "you're doing your you have a predictable distribution but for us this isn't",
    "start": "2568500",
    "end": "2573900"
  },
  {
    "text": "microseconds and at this load our cluster can easily take bursts of 75,000",
    "start": "2573900",
    "end": "2581220"
  },
  {
    "text": "writes per second so 75,000 materializations of edges per second so",
    "start": "2581220",
    "end": "2587970"
  },
  {
    "text": "we did it so we've addressed some of the concerns",
    "start": "2587970",
    "end": "2594599"
  },
  {
    "text": "about partitioning with Cassandra we're accepting a lot of our a lot of writes from all of these edges that we're",
    "start": "2594599",
    "end": "2600750"
  },
  {
    "text": "materializing and we've stabilized our load times and with the partitioning",
    "start": "2600750",
    "end": "2605760"
  },
  {
    "text": "techniques that Cassandra gave we were able to actually perform a live",
    "start": "2605760",
    "end": "2611400"
  },
  {
    "text": "datacenter migration so we set this up before we had moved from England to",
    "start": "2611400",
    "end": "2616859"
  },
  {
    "text": "Amsterdam and this this database or this database cluster was the only thing that",
    "start": "2616859",
    "end": "2623280"
  },
  {
    "text": "was online the entire time during the during the transition we also could",
    "start": "2623280",
    "end": "2629339"
  },
  {
    "text": "accept writes from multiple data centers so we were writing an Amsterdam writing and in England and you may find this",
    "start": "2629339",
    "end": "2637650"
  },
  {
    "text": "amazing but those metrics on those Layton sees were from a cluster that's running an ec2 with a notoriously slow",
    "start": "2637650",
    "end": "2644400"
  },
  {
    "text": "IO IO x so both with Cassandra and in",
    "start": "2644400",
    "end": "2651089"
  },
  {
    "text": "the SS tables and you know DB with its B trees they're using the disks",
    "start": "2651089",
    "end": "2656130"
  },
  {
    "text": "effectively but in different ways so cassandra accepts random writes very",
    "start": "2656130",
    "end": "2661410"
  },
  {
    "text": "well much better than in ODB but as in ODB's creating random writes by",
    "start": "2661410",
    "end": "2667530"
  },
  {
    "text": "maintaining the index but once that index is established in ODB does much better for performing reads because it",
    "start": "2667530",
    "end": "2674550"
  },
  {
    "text": "can traverse that that that tree that with fewer hops than the number of SS",
    "start": "2674550",
    "end": "2681750"
  },
  {
    "text": "tables that you need to consult but it hasn't been such a great experience with",
    "start": "2681750",
    "end": "2688770"
  },
  {
    "text": "Cassandra we spend a lot of time on operations of our clusters and we have",
    "start": "2688770",
    "end": "2697140"
  },
  {
    "text": "about like five to ten hours a week of just babysitting it there's alerts that",
    "start": "2697140",
    "end": "2704040"
  },
  {
    "text": "go off that where nodes can't communicate its distributed but and we",
    "start": "2704040",
    "end": "2709290"
  },
  {
    "text": "understand why it's happening but we still have to respond to it and periodically we have to intervene and",
    "start": "2709290",
    "end": "2714960"
  },
  {
    "text": "say yeah you need to go down for a while or you've been down for too long and we're gonna bring up another and nom as",
    "start": "2714960",
    "end": "2722700"
  },
  {
    "text": "a result it we haven't quite worked out those those kinks but if you do go with Cassandra you can expect trading trading",
    "start": "2722700",
    "end": "2730050"
  },
  {
    "text": "at a time for for operation of anything larger than a five node cluster and in",
    "start": "2730050",
    "end": "2740130"
  },
  {
    "text": "in hindsight we know now how exactly we",
    "start": "2740130",
    "end": "2745950"
  },
  {
    "text": "would have built it with MySQL so the problem that we were having of our index",
    "start": "2745950",
    "end": "2752160"
  },
  {
    "text": "splitting it could easily be mitigated by optimizing our table periodically",
    "start": "2752160",
    "end": "2757530"
  },
  {
    "text": "rewriting the entire be tree and splitting that up into smaller chunks so it doesn't create outages or offering up",
    "start": "2757530",
    "end": "2764640"
  },
  {
    "text": "our workflow our ETL and RAM before writing out to MySQL to avoid being down",
    "start": "2764640",
    "end": "2771030"
  },
  {
    "text": "during that time so to wrap this up of how we fit our database to our data",
    "start": "2771030",
    "end": "2776970"
  },
  {
    "text": "model we did a lot of write things a lot of smart things along the way we found our natural partition key we",
    "start": "2776970",
    "end": "2784660"
  },
  {
    "text": "isolated a read path from a right path we identified the volume and the access",
    "start": "2784660",
    "end": "2791510"
  },
  {
    "text": "patterns both for our read and write loads whether they were sequential or random and we developed a sympathy for",
    "start": "2791510",
    "end": "2800270"
  },
  {
    "text": "the materials that were using but most importantly we never forgot our goal of",
    "start": "2800270",
    "end": "2805630"
  },
  {
    "text": "delivering a product that kicked ass so we architected first without fully",
    "start": "2805630",
    "end": "2812210"
  },
  {
    "text": "understanding what our building materials were because we assumed that our database is going to hide that from",
    "start": "2812210",
    "end": "2818480"
  },
  {
    "text": "us so whether you try to fit your data",
    "start": "2818480",
    "end": "2824120"
  },
  {
    "text": "model to your database or whether you choose to fit your database to your data model ultimately the success of your",
    "start": "2824120",
    "end": "2831680"
  },
  {
    "text": "design and the ability to hide your ignorance to the public is really based",
    "start": "2831680",
    "end": "2837590"
  },
  {
    "text": "on how well you understand the materials that you're working with so that's it thank you",
    "start": "2837590",
    "end": "2844990"
  }
]
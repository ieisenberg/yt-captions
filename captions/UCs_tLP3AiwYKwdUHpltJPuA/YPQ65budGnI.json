[
  {
    "start": "0",
    "end": "70000"
  },
  {
    "text": "[Music]",
    "start": "3470",
    "end": "7799"
  },
  {
    "text": "welcome everyone my name is Ricardo Suarez I'm a developer Advocate at AWS I focus on open source and I've been",
    "start": "11639",
    "end": "17279"
  },
  {
    "text": "working with open source for over 20 years and one of the things that I love about working with open source Builders",
    "start": "17279",
    "end": "23580"
  },
  {
    "text": "is the fact that they come together to solve problems they have and create code",
    "start": "23580",
    "end": "29519"
  },
  {
    "text": "to solve those problems and they open source that so this talk really is about one of the problems that a group of",
    "start": "29519",
    "end": "35579"
  },
  {
    "text": "developers found um and so I'm going to talk about that problem and I hope you'll all be able to",
    "start": "35579",
    "end": "41520"
  },
  {
    "text": "kind of walk away with a better understanding of um this open source project called Apache airflow the",
    "start": "41520",
    "end": "47700"
  },
  {
    "text": "problem space that it helps you solve and we're going to do um you know I want to talk about the",
    "start": "47700",
    "end": "53460"
  },
  {
    "text": "concepts the key Concepts you need to know and understand and then I'm going to actually go into a code and actually",
    "start": "53460",
    "end": "58680"
  },
  {
    "text": "show you how to actually build your first workflow so that hopefully you can actually then use some of this stuff if",
    "start": "58680",
    "end": "65280"
  },
  {
    "text": "it helps you solve some of your problems so um that's the talk so if you think",
    "start": "65280",
    "end": "72659"
  },
  {
    "start": "70000",
    "end": "153000"
  },
  {
    "text": "about um organizations and as they start to think about how they use data there's",
    "start": "72659",
    "end": "79140"
  },
  {
    "text": "typically a number of different steps that organizations have to do to get data from where it is",
    "start": "79140",
    "end": "84900"
  },
  {
    "text": "to the people in the organization that can make use of that data to get insights and and provide value for their",
    "start": "84900",
    "end": "91680"
  },
  {
    "text": "customers you typically have to be able to kind of find it retrieve it store it",
    "start": "91680",
    "end": "97740"
  },
  {
    "text": "you then have to clean it you might have to filter it you might have to combine it and then obviously you then have to",
    "start": "97740",
    "end": "104220"
  },
  {
    "text": "potentially put it somewhere in a data warehouse or a data Lake and you need to do that in the context of making sure",
    "start": "104220",
    "end": "111360"
  },
  {
    "text": "that only those people that can have access to it can have access to so security needs to be kind of kind of",
    "start": "111360",
    "end": "117299"
  },
  {
    "text": "core to this and um in kind of in the past organizations",
    "start": "117299",
    "end": "123360"
  },
  {
    "text": "tend to do this very ad hoc they would create cron jobs and do parts of this and and the problem is that",
    "start": "123360",
    "end": "130679"
  },
  {
    "text": "as you um scale your use of data it's very very difficult to actually manage that",
    "start": "130679",
    "end": "137879"
  },
  {
    "text": "um and so what was really needed was a way to orchestrate those different tasks in a way that would allow you to kind of",
    "start": "137879",
    "end": "143700"
  },
  {
    "text": "automate those processes and many organizations turn to",
    "start": "143700",
    "end": "149459"
  },
  {
    "text": "commercial tools and there are a number of commercial tools that can help you do that but in 2014 at Airbnb they were",
    "start": "149459",
    "end": "156000"
  },
  {
    "start": "153000",
    "end": "731000"
  },
  {
    "text": "faced with the same problem they had their data scientists wanting to have data they were managing all these",
    "start": "156000",
    "end": "163080"
  },
  {
    "text": "different silos manually and so they created this open source project called Apache airflow in order to automate and",
    "start": "163080",
    "end": "169980"
  },
  {
    "text": "create those data pipelines so that they could quickly easily reliably and at scale deliver data to those internal",
    "start": "169980",
    "end": "176580"
  },
  {
    "text": "consumers um so that's what I'm going to talk about um today more about this project which",
    "start": "176580",
    "end": "183720"
  },
  {
    "text": "in 2009 19 actually went from an incubating project to a main project in",
    "start": "183720",
    "end": "189840"
  },
  {
    "text": "Apache and has since 2019 been used by",
    "start": "189840",
    "end": "195480"
  },
  {
    "text": "thousands of customers and the community is growing and they're bringing and innovating the project forward",
    "start": "195480",
    "end": "202580"
  },
  {
    "text": "um so um the kind of if you think about um the kind of the workflow",
    "start": "203459",
    "end": "210060"
  },
  {
    "text": "the group the grouping together of these different tasks um is what we call in Apache airflow a",
    "start": "210060",
    "end": "216720"
  },
  {
    "text": "workflow and these workflows really are kind of sometimes called dags directed",
    "start": "216720",
    "end": "222540"
  },
  {
    "text": "acyclic graphs and what a workflow is really is a collection of tasks that you",
    "start": "222540",
    "end": "228420"
  },
  {
    "text": "need in order to achieve your specific data pipeline so get data move data",
    "start": "228420",
    "end": "234540"
  },
  {
    "text": "clean data combine data store data that kind of thing",
    "start": "234540",
    "end": "239879"
  },
  {
    "text": "and in Apache airflow this workflow or dag is represented by some python code",
    "start": "239879",
    "end": "246180"
  },
  {
    "text": "and within the python code we have a number of key characteristics which I've pointed here the first of all is is we",
    "start": "246180",
    "end": "253439"
  },
  {
    "text": "have some libraries okay so there's an airflow object called dag and that's actually how we create our workflow",
    "start": "253439",
    "end": "258959"
  },
  {
    "text": "object um and then we have some properties for our workflow and then we have a unique",
    "start": "258959",
    "end": "265919"
  },
  {
    "text": "name every workflow has to have a unique name and then we actually Define our workflow object itself so it's just a",
    "start": "265919",
    "end": "273419"
  },
  {
    "text": "python file and a unit of task within that workflow",
    "start": "273419",
    "end": "278699"
  },
  {
    "text": "is also python code and like the workflow having a unique workflow ID",
    "start": "278699",
    "end": "285479"
  },
  {
    "text": "each task also has a unique ID now each",
    "start": "285479",
    "end": "290759"
  },
  {
    "text": "task also uses an operator I'm going to come into the next slide actually what operators are but you can think of",
    "start": "290759",
    "end": "296340"
  },
  {
    "text": "operators as a way of templatizing activities that you want to do and simplifying so you know if I want to",
    "start": "296340",
    "end": "303360"
  },
  {
    "text": "interact with the system I can just provide parameters and then the operator will do all the heavy lifting of how to actually work with that system",
    "start": "303360",
    "end": "311880"
  },
  {
    "text": "um and then we Define and then we assign uh this to her to an object uh and so in order for kind of these",
    "start": "311880",
    "end": "318720"
  },
  {
    "text": "tasks and operators to be useful um we have a number of different kinds",
    "start": "318720",
    "end": "324060"
  },
  {
    "text": "of operators we can use um so here are just some of them but there are actually different kinds of",
    "start": "324060",
    "end": "329639"
  },
  {
    "text": "operators so the basic operator actually allows you to easily abstract how you",
    "start": "329639",
    "end": "335460"
  },
  {
    "text": "work with a system and in the next slide I show you all the systems but we also have other kinds of operators such as",
    "start": "335460",
    "end": "340919"
  },
  {
    "text": "sensors which allow you to wait for some information so I'm going to monitor a folder",
    "start": "340919",
    "end": "346919"
  },
  {
    "text": "um until a file drops in it and then I'm going to execute something and we have hooks which allow you to simplify how",
    "start": "346919",
    "end": "352979"
  },
  {
    "text": "you connect to other systems so it makes it easier for you to provide connection",
    "start": "352979",
    "end": "358440"
  },
  {
    "text": "IDs to things so that your data scientists don't need to have usernames passwords or no connection strings you",
    "start": "358440",
    "end": "363539"
  },
  {
    "text": "give them an ID they can use that ID in a workflow and then you separate the tooth activities together",
    "start": "363539",
    "end": "370979"
  },
  {
    "text": "and over the years you know the Apache airflow Community as well as the actual",
    "start": "370979",
    "end": "376860"
  },
  {
    "text": "core team have developed a whole bunch of operators and if you look at this list",
    "start": "376860",
    "end": "382220"
  },
  {
    "text": "the systems that you tend to need to integrate with will probably be on this",
    "start": "382220",
    "end": "387960"
  },
  {
    "text": "list so just to summarize we have this",
    "start": "387960",
    "end": "393419"
  },
  {
    "text": "workflow object it's dag and within this workflow object we have these tasks and",
    "start": "393419",
    "end": "399300"
  },
  {
    "text": "it's all python code but how do you actually know which runs first how do you define you know where",
    "start": "399300",
    "end": "406500"
  },
  {
    "text": "you start how you branch and that's the role of Apache airflow flow control",
    "start": "406500",
    "end": "411660"
  },
  {
    "text": "where you define the actual start and the branching and the relationship",
    "start": "411660",
    "end": "417300"
  },
  {
    "text": "between the nodes in your workflow and you do that you can see on the top right you can do that either using the greater",
    "start": "417300",
    "end": "424800"
  },
  {
    "text": "than sign or less than sign to specify that the the relationship or you can do",
    "start": "424800",
    "end": "430259"
  },
  {
    "text": "set dot set Downstream or dot set underscore Upstream either way depending on on on how you prefer to use Python",
    "start": "430259",
    "end": "437520"
  },
  {
    "text": "and this is how within your um your kind of python code you've now",
    "start": "437520",
    "end": "443280"
  },
  {
    "text": "defined the workflow you'd like you've defined the tasks and you've defined the relationship of those tasks",
    "start": "443280",
    "end": "451400"
  },
  {
    "text": "so we've got our file now we've defined our workflow what next so an Apache",
    "start": "451620",
    "end": "457259"
  },
  {
    "text": "airflow we have this concept of a dags folder and a dags folder is where we",
    "start": "457259",
    "end": "462599"
  },
  {
    "text": "literally copy the file we've created into this folder Apache airflow will read it and then it",
    "start": "462599",
    "end": "469740"
  },
  {
    "text": "will read that as a workflow and display that in the system and I'm going to show you that when we",
    "start": "469740",
    "end": "475440"
  },
  {
    "text": "actually come to do the demo in a minute now once we've got the workflow in",
    "start": "475440",
    "end": "481259"
  },
  {
    "text": "Apache airflow what next how do we actually schedule it how do we actually run how does this workflow actually run",
    "start": "481259",
    "end": "487139"
  },
  {
    "text": "and that's the job of the scheduler within Apache airflow and the scheduling",
    "start": "487139",
    "end": "492660"
  },
  {
    "text": "Apache airflow will look at your workflow and we'll look at how you've",
    "start": "492660",
    "end": "498720"
  },
  {
    "text": "defined to schedule it which I'm going to come to in a second and then it will work out a plan and",
    "start": "498720",
    "end": "504360"
  },
  {
    "text": "then if a task needs to run from within your workflow it will execute that through one of the workers okay so the",
    "start": "504360",
    "end": "512459"
  },
  {
    "text": "key thing to to take away here is that they're stateless if you have a workflow",
    "start": "512459",
    "end": "518339"
  },
  {
    "text": "with five tasks um those five tasks might be run on five",
    "start": "518339",
    "end": "523500"
  },
  {
    "text": "different workers so that you can't assume any state so for example if I write a file",
    "start": "523500",
    "end": "529320"
  },
  {
    "text": "to slash temp my second task can't read the files from slash temp because it might it may be on a different worker",
    "start": "529320",
    "end": "534839"
  },
  {
    "text": "node so that you have to think of them as stateless and how we actually schedule them how",
    "start": "534839",
    "end": "541200"
  },
  {
    "text": "the schedule knows which uh tasks to run is through a property in the schedule",
    "start": "541200",
    "end": "547260"
  },
  {
    "text": "interval now you can specify it equals To None which means that the scheduler will not schedule this and the workflow",
    "start": "547260",
    "end": "554279"
  },
  {
    "text": "you've created will only run on demand or you can use a chrome-like tab at",
    "start": "554279",
    "end": "560040"
  },
  {
    "text": "santax for people who are familiar with cron on the bottom left where it will schedule it based on you know every",
    "start": "560040",
    "end": "565920"
  },
  {
    "text": "minute every hour every day that kind of thing and recently uh in 2.2 they",
    "start": "565920",
    "end": "571399"
  },
  {
    "text": "released a new feature called timetables that allows you to create your own kind",
    "start": "571399",
    "end": "576420"
  },
  {
    "text": "of bespoke organizational timetable so you can actually schedule workflows based on things like key dates in your",
    "start": "576420",
    "end": "583080"
  },
  {
    "text": "business the the example that I use is you know if you're creating like a if FIFA were using this okay they might",
    "start": "583080",
    "end": "589740"
  },
  {
    "text": "create a timetable for the World Cup uh events right and there'll be a custom timetable for them",
    "start": "589740",
    "end": "597540"
  },
  {
    "text": "now one of the things one of the tricky things um when trying to understand how the search scheduler Works in Apache airflow",
    "start": "597540",
    "end": "603300"
  },
  {
    "text": "is the concept of actually kind of the start date the start when you create a workflow you have to specify a start",
    "start": "603300",
    "end": "609779"
  },
  {
    "text": "date and it can be today it can be a date in the past but when you actually enable your workflow the scheduler will",
    "start": "609779",
    "end": "618540"
  },
  {
    "text": "look for that start date so if for example here the 22nd of 2nd the first if I started that today the schedule",
    "start": "618540",
    "end": "626160"
  },
  {
    "text": "would go all the way back to February and if this was this scheduled for every",
    "start": "626160",
    "end": "631459"
  },
  {
    "text": "hour it would then basically schedule 24 slots per day",
    "start": "631459",
    "end": "637019"
  },
  {
    "text": "for the last four months so I have literally hundreds of tasks that will be",
    "start": "637019",
    "end": "642839"
  },
  {
    "text": "scheduled by the scheduler because the way Apache airflow works is it runs through each time it runs based on that",
    "start": "642839",
    "end": "650640"
  },
  {
    "text": "information now you can you can turn that off by changing catch up equals to false so",
    "start": "650640",
    "end": "657180"
  },
  {
    "text": "that it just ignores everything in the past and just starts from today but this is a really useful piece of Apache",
    "start": "657180",
    "end": "664140"
  },
  {
    "text": "airflow functionality because for example if you wanted to rerun some",
    "start": "664140",
    "end": "669920"
  },
  {
    "text": "extracts or some scripts in your workflows all the way back from when you started you can use this feature it will",
    "start": "669920",
    "end": "676680"
  },
  {
    "text": "rerun across all your data you'd have to it makes it really really easy to do that but it's something you have to be aware of because it's not very intuitive",
    "start": "676680",
    "end": "683220"
  },
  {
    "text": "when you first start now as tasks are running as workflows",
    "start": "683220",
    "end": "688380"
  },
  {
    "text": "are running they generate information they generate state so did it run did it execute did it error and this is all",
    "start": "688380",
    "end": "694260"
  },
  {
    "text": "stored in the metadata database that's used by a hatch airflow but this database is also used to encrypt things",
    "start": "694260",
    "end": "701519"
  },
  {
    "text": "like connection strings usernames and passwords and that kind of thing so this is another key component of Apache",
    "start": "701519",
    "end": "708180"
  },
  {
    "text": "airflow and then the last part before I go into the um demo is the",
    "start": "708180",
    "end": "714839"
  },
  {
    "text": "UI which allows you very easily to give your data Engineers a nice graphic user",
    "start": "714839",
    "end": "720540"
  },
  {
    "text": "interface and you as an operator to actually how to see the workflows and also see how they're running how they're performing view the logs view failures",
    "start": "720540",
    "end": "728459"
  },
  {
    "text": "and that kind of thing so enough presentation let's actually",
    "start": "728459",
    "end": "733800"
  },
  {
    "start": "731000",
    "end": "1093000"
  },
  {
    "text": "show you this stuff actually working there's gonna be plenty of time at the end for questions",
    "start": "733800",
    "end": "739800"
  },
  {
    "text": "so what I'm going to do is actually um actually before I do that I'm going",
    "start": "739800",
    "end": "745680"
  },
  {
    "text": "to show you um all the all the code I'm going to show",
    "start": "745680",
    "end": "751260"
  },
  {
    "text": "you is in a repository um here which is going to be shared in the slides which I'm which will be available to everyone",
    "start": "751260",
    "end": "756440"
  },
  {
    "text": "afterwards and it uses a project that we created in",
    "start": "756440",
    "end": "761519"
  },
  {
    "text": "AWS called Moira local Runner and what this um does is it makes it really easy",
    "start": "761519",
    "end": "766700"
  },
  {
    "text": "to run Apache airflow on your own local look so this is all running on my local",
    "start": "766700",
    "end": "772139"
  },
  {
    "text": "my local laptop at the moment and it just uses containers it spins up a couple of containers run running a postgres database and the other running",
    "start": "772139",
    "end": "778200"
  },
  {
    "text": "Apache airflow core components and I can then access this using localhost I've logged in using the",
    "start": "778200",
    "end": "784920"
  },
  {
    "text": "default admin test password and this is the user interface not particularly",
    "start": "784920",
    "end": "790079"
  },
  {
    "text": "interesting at the moment we're going to come back to this as we start doing stuff so",
    "start": "790079",
    "end": "795720"
  },
  {
    "text": "um we're going to look at off creating our first workflow and I'm going to walk you",
    "start": "795720",
    "end": "801180"
  },
  {
    "text": "through what the the code actually does um based on the stuff that we've talked about so first of all we create",
    "start": "801180",
    "end": "808139"
  },
  {
    "text": "um a dag we sorry we import the dag object um from from airflow",
    "start": "808139",
    "end": "813540"
  },
  {
    "text": "we then in this instance we're going to use the bash operator so again operators are how you can do stuff and it takes",
    "start": "813540",
    "end": "820200"
  },
  {
    "text": "all the heavy lifting so each operator is documented and it tells you what parameters it needs and we'll see in a",
    "start": "820200",
    "end": "825300"
  },
  {
    "text": "minute what that what they look like so we import any required python libraries",
    "start": "825300",
    "end": "831360"
  },
  {
    "text": "we then Define the default arguments we want to use for our Apache airflow workflow I've commented out some of the",
    "start": "831360",
    "end": "838860"
  },
  {
    "text": "options you've got but this is effectively to simplify because otherwise you would need to supply these",
    "start": "838860",
    "end": "844800"
  },
  {
    "text": "to every single task but they allow you to do things like you",
    "start": "844800",
    "end": "850440"
  },
  {
    "text": "know Define the the what happens in the event of a failure success which email",
    "start": "850440",
    "end": "855480"
  },
  {
    "text": "to send if there's a problem that kind of thing we then give it a unique ID and then we",
    "start": "855480",
    "end": "861240"
  },
  {
    "text": "actually Define our workflow object so here we've given an ID we've passed in the default arguments we've given that a",
    "start": "861240",
    "end": "867180"
  },
  {
    "text": "description here we've specified the schedule To None which means it's going to be running on demand we've set the",
    "start": "867180",
    "end": "873360"
  },
  {
    "text": "start date two days ago but we've said catch up to false and then we provide some tags and we'll see what that looks",
    "start": "873360",
    "end": "879300"
  },
  {
    "text": "like in the actual UI we then Define some variables so here I've got a worked source file and a",
    "start": "879300",
    "end": "886500"
  },
  {
    "text": "destination and then we've actually got our tasks so you can see we're using the operator we've created three tasks and",
    "start": "886500",
    "end": "894120"
  },
  {
    "text": "we're good at all unique IDs create file move and remove and then we've passed in",
    "start": "894120",
    "end": "899579"
  },
  {
    "text": "a command right and what we've done is we've put a command and then we're using the passing in the variables we've",
    "start": "899579",
    "end": "904620"
  },
  {
    "text": "created up here so that we can create more generic um less hard-coded workflows so this is",
    "start": "904620",
    "end": "912420"
  },
  {
    "text": "this is it this is and what this will allow us to do so this will allow to run Bosch bash commands and then in order to",
    "start": "912420",
    "end": "917519"
  },
  {
    "text": "actually execute this I just copy it into that Dax folder so if I click on",
    "start": "917519",
    "end": "923699"
  },
  {
    "text": "here and what should hopefully happen",
    "start": "923699",
    "end": "928800"
  },
  {
    "text": "if I go to here we should now see our first workflow and you can see that",
    "start": "928800",
    "end": "935279"
  },
  {
    "text": "we've got some tags here and at the moment this is disabled what's called paused I can enable it and it's now",
    "start": "935279",
    "end": "940860"
  },
  {
    "text": "enabled and actually I can go into it and we can actually see what the actual",
    "start": "940860",
    "end": "946500"
  },
  {
    "text": "um workflow looks like we can see that these are different tasks they've got a color around it they're all white at the",
    "start": "946500",
    "end": "951600"
  },
  {
    "text": "moment and these all correspond to a status here so we can always see at",
    "start": "951600",
    "end": "957720"
  },
  {
    "text": "any time the status of our workflows now in order to run this I can trigger it",
    "start": "957720",
    "end": "964920"
  },
  {
    "text": "um allows you to submit parameters if you want to do these for example create um parameterize workflows but I'm not",
    "start": "964920",
    "end": "971579"
  },
  {
    "text": "going to do that in this instance I kick it off and now hopefully",
    "start": "971579",
    "end": "977639"
  },
  {
    "text": "we can see it that was very very quick but it went from bright green to dark green and we can see here that dark",
    "start": "977639",
    "end": "982980"
  },
  {
    "text": "green is success I can now go into each of these tasks and we can see information metadata",
    "start": "982980",
    "end": "990000"
  },
  {
    "text": "about the tasks we've run including we can look at the log and so here because I was just creating",
    "start": "990000",
    "end": "995699"
  },
  {
    "text": "directories and moving them we can see all the information about what my task did now if I was doing something more",
    "start": "995699",
    "end": "1001160"
  },
  {
    "text": "interesting which we'll see in a bit later this information is more useful but this is just really just to give you an idea of how that works",
    "start": "1001160",
    "end": "1008660"
  },
  {
    "text": "um so if I go to the next task so that's quite straightforward the next one okay does something similar",
    "start": "1008660",
    "end": "1015199"
  },
  {
    "text": "um but what this time I've done is I've actually scheduled this one so I'm using a different background I'm just echoing",
    "start": "1015199",
    "end": "1020660"
  },
  {
    "text": "stuff but this one I'm going to schedule it every two minutes so I'm going to copy this one",
    "start": "1020660",
    "end": "1027040"
  },
  {
    "text": "into the dags folder",
    "start": "1027740",
    "end": "1033819"
  },
  {
    "text": "and then hopefully that will appear soon okay so",
    "start": "1037459",
    "end": "1044058"
  },
  {
    "text": "now I'm going to leave this one running because this is scheduled to run every two minutes and I'll come back to it and we should hopefully see that it's run a",
    "start": "1044059",
    "end": "1050299"
  },
  {
    "text": "few few times um one other thing is actually when we look at the UI",
    "start": "1050299",
    "end": "1055840"
  },
  {
    "text": "as you have more complex workflows and as you as you run these you can actually use the information within the UI to do",
    "start": "1055840",
    "end": "1062120"
  },
  {
    "text": "things like how long the tasks took how many tasks retries you can see for",
    "start": "1062120",
    "end": "1067160"
  },
  {
    "text": "example how long each specific task took in in relation to the overall task and",
    "start": "1067160",
    "end": "1073340"
  },
  {
    "text": "you can also view the code to so you can actually view the code for them here as well so the UI is actually very useful",
    "start": "1073340",
    "end": "1079280"
  },
  {
    "text": "to help you understand how your workflows are so now that that's a very kind of your",
    "start": "1079280",
    "end": "1084740"
  },
  {
    "text": "basic one let's actually do a proper um a proper workflow and make sure time wise I'm doing all right",
    "start": "1084740",
    "end": "1092059"
  },
  {
    "text": "um okay so in this in this hypothetical situation okay what we want to do is we're going to get data from the",
    "start": "1092059",
    "end": "1098240"
  },
  {
    "start": "1093000",
    "end": "1223000"
  },
  {
    "text": "internet somewhere and then we want to put it in our data warehouse but the data's in three files and we need to",
    "start": "1098240",
    "end": "1104840"
  },
  {
    "text": "combine the data clean it before we store it so this is what our workflow looks like",
    "start": "1104840",
    "end": "1110600"
  },
  {
    "text": "okay um which is a kind of a very simple simplified scenario of the different",
    "start": "1110600",
    "end": "1115880"
  },
  {
    "text": "steps um and if I take a look at each of those specific steps and how we can use Apache",
    "start": "1115880",
    "end": "1123440"
  },
  {
    "text": "operators to to work on this the first one is actually how to actually store or retrieve and copy the files so here",
    "start": "1123440",
    "end": "1130640"
  },
  {
    "text": "we're going to use Python operators and then the S3 sensor one so the first one is going to copy the file from somewhere",
    "start": "1130640",
    "end": "1136160"
  },
  {
    "text": "on the internet the second one is going to wait for that file to be copied into",
    "start": "1136160",
    "end": "1141740"
  },
  {
    "text": "the S3 folder before it's successful and then triggers the next part of the workflow",
    "start": "1141740",
    "end": "1147260"
  },
  {
    "text": "so once we've actually got that we now want to ingest that file into our data Lake and so here we're going to use the",
    "start": "1147260",
    "end": "1153740"
  },
  {
    "text": "Athena operator which makes it super easy to ingest data into uh S3 using",
    "start": "1153740",
    "end": "1159919"
  },
  {
    "text": "Athena once we've done that we're going to actually",
    "start": "1159919",
    "end": "1165200"
  },
  {
    "text": "um the same thing so once once we've done that we're going",
    "start": "1165200",
    "end": "1171380"
  },
  {
    "text": "to then because we've got three separate files we're going to merge those all again using Athena using a SQL script",
    "start": "1171380",
    "end": "1179299"
  },
  {
    "text": "and then once we've done that we're going to clean that we're going to use python in this instance the data we've got is movie data and our cleaning data",
    "start": "1179299",
    "end": "1186620"
  },
  {
    "text": "is going to strip all all movies um with the letter e and so we should see at the end of it in our data",
    "start": "1186620",
    "end": "1192260"
  },
  {
    "text": "warehouse no movies with the letter e and then finally we actually want to copy this into our data warehouse so",
    "start": "1192260",
    "end": "1198320"
  },
  {
    "text": "we're going to use the S3 to redshift operator again I don't need to know anything about how to interact with",
    "start": "1198320",
    "end": "1203600"
  },
  {
    "text": "Athena or redshift because Apache airflow is going to make this super easy as you can see here I just need to enter some specific information",
    "start": "1203600",
    "end": "1210160"
  },
  {
    "text": "and then we're good to go so this this is what we're going to end up building um and I'm going to show you the code",
    "start": "1210160",
    "end": "1216080"
  },
  {
    "text": "now",
    "start": "1216080",
    "end": "1218320"
  },
  {
    "text": "and hopefully the demo gods are behind right so here is",
    "start": "1222799",
    "end": "1229100"
  },
  {
    "start": "1223000",
    "end": "1852000"
  },
  {
    "text": "the the actual workflow so we can see that we've got a lot more operators imported into our workflow okay we've",
    "start": "1229100",
    "end": "1236240"
  },
  {
    "text": "got the S the all the ones I just showed in the presentation we've got the python operator the athene operator the S3",
    "start": "1236240",
    "end": "1241580"
  },
  {
    "text": "sensor one so this is so that we can actually use these within our workflow uh we have a bunch of other python",
    "start": "1241580",
    "end": "1248240"
  },
  {
    "text": "Imports and again because it's just a all airflow workflows are just python files you can if you need to do anything",
    "start": "1248240",
    "end": "1254720"
  },
  {
    "text": "you can support them and add them to your requirements.txt file and then you can you can use them",
    "start": "1254720",
    "end": "1260840"
  },
  {
    "text": "we submit some default args we provide a dag ID here rather than specifically put",
    "start": "1260840",
    "end": "1265880"
  },
  {
    "text": "a name I'm just basically using the part the file name as the dag ID and then I'm saying a whole bunch of",
    "start": "1265880",
    "end": "1272660"
  },
  {
    "text": "variables now I could do this manually but what I'm going to do is I'm going to",
    "start": "1272660",
    "end": "1279020"
  },
  {
    "text": "use a feature of the Apache airflow that allows me to ingest and create variables",
    "start": "1279020",
    "end": "1284559"
  },
  {
    "text": "within Apache airflow UI so what I'm going to do is I'm going to find the file",
    "start": "1284559",
    "end": "1290539"
  },
  {
    "text": "um if I can find it where is it airflow",
    "start": "1290539",
    "end": "1297100"
  },
  {
    "text": "this is now when uh where is it",
    "start": "1298059",
    "end": "1305860"
  },
  {
    "text": "ah this is not good all right let's have a look where where",
    "start": "1306620",
    "end": "1312140"
  },
  {
    "text": "it is always one thing so project airflow",
    "start": "1312140",
    "end": "1318020"
  },
  {
    "text": "right that's why it's not Cloud Builders it's airflow there we go",
    "start": "1318020",
    "end": "1324799"
  },
  {
    "text": "and we've got Scripts and nope it's not there either",
    "start": "1324799",
    "end": "1331419"
  },
  {
    "text": "ah here we go variables apologies for that so what we what we're",
    "start": "1331580",
    "end": "1336980"
  },
  {
    "text": "going to do is if I look at that file Scripts",
    "start": "1336980",
    "end": "1343179"
  },
  {
    "text": "we can see it's just a Json file okay and this allows you to simplify how you can then automate the the creation of",
    "start": "1343400",
    "end": "1350179"
  },
  {
    "text": "your your variables so now I've imported them these are now",
    "start": "1350179",
    "end": "1355220"
  },
  {
    "text": "within the Apache airflow UI and my workflows could actually use these so",
    "start": "1355220",
    "end": "1360500"
  },
  {
    "text": "I've got that in my code here and I'm using a um a thing here from Apache ethical",
    "start": "1360500",
    "end": "1366980"
  },
  {
    "text": "variable that allows airflow to actually access the metadatabase and access the variables in there",
    "start": "1366980",
    "end": "1372440"
  },
  {
    "text": "so now that I've got my variables I've got less hard-coded workflow I now actually can start defining my workflow",
    "start": "1372440",
    "end": "1380000"
  },
  {
    "text": "now here I'm creating the actual Athena queries so this is actually what the actual here",
    "start": "1380000",
    "end": "1387320"
  },
  {
    "text": "we will run to do things like the merging and data ingestion um and then I Define some python",
    "start": "1387320",
    "end": "1393320"
  },
  {
    "text": "functions which is is what if I look at the actual um if I go down to actually the workflow",
    "start": "1393320",
    "end": "1398480"
  },
  {
    "text": "so we can see here that the workflow starts off where is it here we go",
    "start": "1398480",
    "end": "1404360"
  },
  {
    "text": "um it starts off with the specific operators we're going to use the first one is check to see if there's a file in",
    "start": "1404360",
    "end": "1411080"
  },
  {
    "text": "the folder and if if it if it detects the file in",
    "start": "1411080",
    "end": "1416419"
  },
  {
    "text": "there it will move as success successful and move on to the next task in order to move the file we're using the python",
    "start": "1416419",
    "end": "1422000"
  },
  {
    "text": "operator we can see here that this takes one parameter which is python callable download underscore zip and if we go up",
    "start": "1422000",
    "end": "1429200"
  },
  {
    "text": "and I look at download here we go this is the python code that",
    "start": "1429200",
    "end": "1434419"
  },
  {
    "text": "I'm using to just download the file and I'm using a a sample movie lens database",
    "start": "1434419",
    "end": "1439840"
  },
  {
    "text": "once I've done that I then use the Athena operators and you can see here all I'm doing is passing in the query",
    "start": "1439840",
    "end": "1446500"
  },
  {
    "text": "specifying uh output database in Athena which I've created and then the query",
    "start": "1446500",
    "end": "1452559"
  },
  {
    "text": "folder for the output and that's so that I can then use that in subsequent tasks",
    "start": "1452559",
    "end": "1458780"
  },
  {
    "text": "so I've not had to know about Athena all I've had to do is actually provide the Athena SQL",
    "start": "1458780",
    "end": "1465279"
  },
  {
    "text": "um and then we um create a table in redshift here we're using the python operation we're using boto3 so if I show",
    "start": "1465380",
    "end": "1472460"
  },
  {
    "text": "you the code there here we can see I'm just using bota 3 I'm doing redshift data client and then",
    "start": "1472460",
    "end": "1478700"
  },
  {
    "text": "actually creating a table in redshift and then once I've done that",
    "start": "1478700",
    "end": "1486100"
  },
  {
    "text": "I am doing the cleanup the cleanup scripts if I show you the cleanup Scripts",
    "start": "1486100",
    "end": "1491900"
  },
  {
    "text": "it is this one here so you can see all I'm doing is cycling through all the files in S3 and doing uh finding e and",
    "start": "1491900",
    "end": "1500539"
  },
  {
    "text": "removing it and then at the very end we Define the relationship between all",
    "start": "1500539",
    "end": "1506419"
  },
  {
    "text": "those different tasks so if I move this into",
    "start": "1506419",
    "end": "1513340"
  },
  {
    "text": "oh come on I'll be here",
    "start": "1514820",
    "end": "1521860"
  },
  {
    "text": "well it's not a while I like it Okay so",
    "start": "1522620",
    "end": "1527659"
  },
  {
    "text": "so we're gonna come here hopefully not to take too long right",
    "start": "1527659",
    "end": "1532760"
  },
  {
    "text": "come on where is it oh here we go um if I open it up and we change the",
    "start": "1532760",
    "end": "1539240"
  },
  {
    "text": "graph mode we can see this is like now a little bit more of a complicated um workflow we can enable it",
    "start": "1539240",
    "end": "1546200"
  },
  {
    "text": "and we can run it um and we should start seeing the",
    "start": "1546200",
    "end": "1551419"
  },
  {
    "text": "workflow if the demo gods are kind to us start moving through all the different steps",
    "start": "1551419",
    "end": "1556820"
  },
  {
    "text": "so we can see that it's it's checked to make sure that the S3 bucket is oops",
    "start": "1556820",
    "end": "1563059"
  },
  {
    "text": "it's not it's not good this is not supposed to happen so let's have a look at the log we've got an error",
    "start": "1563059",
    "end": "1570278"
  },
  {
    "text": "and the error says you must specify a region ah yes",
    "start": "1570620",
    "end": "1575659"
  },
  {
    "text": "okay that I do actually I didn't realize that but so okay in um how these",
    "start": "1575659",
    "end": "1582440"
  },
  {
    "text": "operators connect AWS um is through um these uh connection strings and I",
    "start": "1582440",
    "end": "1590000"
  },
  {
    "text": "have to specify a parameter and it's called",
    "start": "1590000",
    "end": "1595220"
  },
  {
    "text": "a region data",
    "start": "1595220",
    "end": "1601539"
  },
  {
    "text": "EU West one I think that's what it's called I've got it actually written some written down somewhere just in case I",
    "start": "1601720",
    "end": "1607820"
  },
  {
    "text": "forgot it I'll read your name there's always something that you forget",
    "start": "1607820",
    "end": "1616480"
  },
  {
    "text": "but it's actually quite good because actually I can show you now how you recover so that should be",
    "start": "1617299",
    "end": "1622520"
  },
  {
    "text": "um all I need to do so if I go back to here this is quite common when you have a workflow that things fail you don't want to rerun the whole workflow so what",
    "start": "1622520",
    "end": "1629480"
  },
  {
    "text": "I can do is I can just actually clear this particular workflow and it's going to retry okay so hopefully this time",
    "start": "1629480",
    "end": "1636140"
  },
  {
    "text": "it's going to work um let's see it looks like it's working it's not red",
    "start": "1636140",
    "end": "1642679"
  },
  {
    "text": "this time yeah I think that's okay so I can clear the other ones now as well",
    "start": "1642679",
    "end": "1648980"
  },
  {
    "text": "and this is what typically happens is when as you're doing this if you get a failure you don't necessarily want to rerun your",
    "start": "1648980",
    "end": "1655520"
  },
  {
    "text": "um your workflows so that wasn't supposed to happen that was a mistake on my part",
    "start": "1655520",
    "end": "1660679"
  },
  {
    "text": "um but it's okay because it actually showed now this is going to take a few seconds so I'm going to go back to see this other task the scheduled tasks that",
    "start": "1660679",
    "end": "1667460"
  },
  {
    "text": "we ran uh we can see now that this has been running every two minutes and we can see that it's run a number of times and as",
    "start": "1667460",
    "end": "1675140"
  },
  {
    "text": "as your workflows are scheduled you'll start to see these appear in different colors across the different",
    "start": "1675140",
    "end": "1681320"
  },
  {
    "text": "um um uh kind of like at the timeline and we can look at for example the",
    "start": "1681320",
    "end": "1687559"
  },
  {
    "text": "information here we can see how long the tasks took and various other information",
    "start": "1687559",
    "end": "1693320"
  },
  {
    "text": "um that we might find useful in order to optimize and troubleshoot our workflows so let's go back to here",
    "start": "1693320",
    "end": "1700340"
  },
  {
    "text": "how are we doing so we're now joining the data",
    "start": "1700340",
    "end": "1706460"
  },
  {
    "text": "and this this is sometimes takes the the longest bit but it's all working hey we can actually",
    "start": "1706460",
    "end": "1711919"
  },
  {
    "text": "look at now the logs in here and we can see that for this particular task we can",
    "start": "1711919",
    "end": "1717799"
  },
  {
    "text": "see uh what queries run the fact is running the fact it was successful and",
    "start": "1717799",
    "end": "1722840"
  },
  {
    "text": "how it's moved on and that's it we've done it's worked",
    "start": "1722840",
    "end": "1729080"
  },
  {
    "text": "we're all good so we can chest we can test this out now by first of all looking at the uh",
    "start": "1729080",
    "end": "1736580"
  },
  {
    "text": "files in our data Lake we can see that we've got all the files that we've copied",
    "start": "1736580",
    "end": "1742880"
  },
  {
    "text": "and we've got the queries as well the Athena queries if we wanted to go",
    "start": "1742880",
    "end": "1749360"
  },
  {
    "text": "and review them but we can actually look at our redshift table",
    "start": "1749360",
    "end": "1754880"
  },
  {
    "text": "and this is the table here we should have a table now that's yeah we've got one table called movies and if I run",
    "start": "1754880",
    "end": "1760640"
  },
  {
    "text": "this query which should hopefully return a list of movies and they should have no letter",
    "start": "1760640",
    "end": "1768260"
  },
  {
    "text": "e's in them that's the idea let's see if this works",
    "start": "1768260",
    "end": "1773799"
  },
  {
    "text": "what's going on please what if I don't let me down I'm sure what's going let me let me just",
    "start": "1774080",
    "end": "1780140"
  },
  {
    "text": "stop that and try something different let's try",
    "start": "1780140",
    "end": "1787059"
  },
  {
    "text": "go to query obviously sometimes it times out I think because I did it a while ago let's try running that",
    "start": "1789980",
    "end": "1797059"
  },
  {
    "text": "foreign oh yeah that's the",
    "start": "1797059",
    "end": "1803919"
  },
  {
    "text": "I don't want to do that Plus it's a slight",
    "start": "1804679",
    "end": "1810980"
  },
  {
    "text": "staff from movie",
    "start": "1810980",
    "end": "1816940"
  },
  {
    "text": "come on what's the table called movie no",
    "start": "1818720",
    "end": "1824779"
  },
  {
    "text": "movie underscore demo and we can see we've got the query so",
    "start": "1824779",
    "end": "1831080"
  },
  {
    "text": "this one is very hard to tell but uh here we go Father of the Bride because there's no ease there uh hat it should",
    "start": "1831080",
    "end": "1837500"
  },
  {
    "text": "be hate um golden eye without the ease so you can see that actually the the thing",
    "start": "1837500",
    "end": "1843740"
  },
  {
    "text": "worked so that's the demo so it worked and that was like basically how to do a very very",
    "start": "1843740",
    "end": "1849020"
  },
  {
    "text": "simple workflow using Apache airflow um so just to finish up",
    "start": "1849020",
    "end": "1856100"
  },
  {
    "start": "1852000",
    "end": "1908000"
  },
  {
    "text": "um that's that was a demo um now Apache airflow as a project is not static okay and the stuff I've",
    "start": "1856100",
    "end": "1863360"
  },
  {
    "text": "showed you today is very kind of level 200 uh it's very uh kind of beginners just so you can grasp the concept but",
    "start": "1863360",
    "end": "1869600"
  },
  {
    "text": "the community as a whole is is doing a lot of work to evolve and accelerate Innovation within the project in things",
    "start": "1869600",
    "end": "1875539"
  },
  {
    "text": "such as improving optimization of how you run schedules uh in parallel how you",
    "start": "1875539",
    "end": "1881480"
  },
  {
    "text": "actually create workflows that are more closely uh appear and look like python code because at the moment the code",
    "start": "1881480",
    "end": "1887960"
  },
  {
    "text": "doesn't necessarily look very python-like and there's some really cool projects they're doing around that",
    "start": "1887960",
    "end": "1893179"
  },
  {
    "text": "there's a whole bunch of work coming out around improving uh the UI",
    "start": "1893179",
    "end": "1898419"
  },
  {
    "text": "and as well as how to better support asynchronous workflows which you can do",
    "start": "1898419",
    "end": "1904100"
  },
  {
    "text": "but you need to think about how you do those as a project they're always looking for",
    "start": "1904100",
    "end": "1910279"
  },
  {
    "start": "1908000",
    "end": "1930000"
  },
  {
    "text": "new contributors and I've written a couple of blog posts about how I can contribute this project",
    "start": "1910279",
    "end": "1915740"
  },
  {
    "text": "and if you're looking for a project to contribute Apache airflow is one of the the best ones I think because it's super",
    "start": "1915740",
    "end": "1922039"
  },
  {
    "text": "welcoming and easy to get started there's some links to the code that I",
    "start": "1922039",
    "end": "1927799"
  },
  {
    "text": "showed as well as the project okay thank you [Applause]",
    "start": "1927799",
    "end": "1936400"
  }
]
[
  {
    "start": "0",
    "end": "54000"
  },
  {
    "text": "[Music]",
    "start": "3510",
    "end": "7529"
  },
  {
    "text": "okay Julie invited me here it was after my 34",
    "start": "12370",
    "end": "18820"
  },
  {
    "text": "c3 talk so I spoke at the Chaos Computer Congress last year and I spoke about",
    "start": "18820",
    "end": "24279"
  },
  {
    "text": "fooling machine learning today we're going to kind of expand upon that theme because I think there's a lot more to",
    "start": "24279",
    "end": "30610"
  },
  {
    "text": "say that perhaps has to do with more than just machine learning but times where we think computers can do",
    "start": "30610",
    "end": "36400"
  },
  {
    "text": "something but they can't because computers are stupid so how can we protect AI or computer systems from",
    "start": "36400",
    "end": "44650"
  },
  {
    "text": "itself and really from ourselves so",
    "start": "44650",
    "end": "52390"
  },
  {
    "text": "[Music] perfect so I first read this headline",
    "start": "52390",
    "end": "59229"
  },
  {
    "start": "54000",
    "end": "183000"
  },
  {
    "text": "last year and I had to read it twice and it's not only because I live in Berlin",
    "start": "59229",
    "end": "64628"
  },
  {
    "text": "and so my joys especially it it's also because I could not believe that",
    "start": "64629",
    "end": "71439"
  },
  {
    "text": "somebody would worship AI right when I read this headline I said they must be",
    "start": "71439",
    "end": "78189"
  },
  {
    "text": "talking about a different a AI than the one that I work on like machine learning they must be talking about something",
    "start": "78189",
    "end": "83950"
  },
  {
    "text": "else that is actually worth worshiping because this is indeed not the AI that I",
    "start": "83950",
    "end": "89590"
  },
  {
    "text": "know and work with on a regular basis but it goes beyond let's say the hyped",
    "start": "89590",
    "end": "94750"
  },
  {
    "text": "headlines are people that assume or think that AI can do much more than it",
    "start": "94750",
    "end": "100300"
  },
  {
    "text": "can do it also goes to folks who are revered members of our machine learning",
    "start": "100300",
    "end": "105820"
  },
  {
    "text": "community right such as Andrew Inc and Andrew n gave a series of talks this",
    "start": "105820",
    "end": "111070"
  },
  {
    "text": "year called AI is the new electricity and also when I saw that headline I was",
    "start": "111070",
    "end": "117220"
  },
  {
    "text": "a little amused does this mean that AI is going to be delivered by the city into my walls does this mean I will pay",
    "start": "117220",
    "end": "124780"
  },
  {
    "text": "taxes on AI does this mean that every machine in my house will likely need some form of AI to operate this is not",
    "start": "124780",
    "end": "132519"
  },
  {
    "text": "what I want at least definitely not wanting my washing machine and my",
    "start": "132519",
    "end": "137560"
  },
  {
    "text": "toaster to need AI in order to properly function and so even though his talk was",
    "start": "137560",
    "end": "144909"
  },
  {
    "text": "much more nuanced if you watched the entire thing the problem that I had with headlines like these is they put a",
    "start": "144909",
    "end": "151750"
  },
  {
    "text": "lot of meaning and a lot of value on something that still by most cases is highly experimental and still by some",
    "start": "151750",
    "end": "159189"
  },
  {
    "text": "cases doesn't work for a lot of generalized problems right and in machine learning and so-called AI we",
    "start": "159189",
    "end": "167049"
  },
  {
    "text": "solve a lot of specific tasks but generalization is is still a really big problem and this is mainly because",
    "start": "167049",
    "end": "174340"
  },
  {
    "text": "computers are stupid right and so they only know how to do things that we have",
    "start": "174340",
    "end": "179530"
  },
  {
    "text": "programmed them or specifically trained them to do example a so here we have",
    "start": "179530",
    "end": "186939"
  },
  {
    "start": "183000",
    "end": "282000"
  },
  {
    "text": "Google Translate Google Translate uses some of the best and most recent research when we think of machine",
    "start": "186939",
    "end": "193419"
  },
  {
    "text": "translation usually using sequence to sequence neural networks that can more",
    "start": "193419",
    "end": "199389"
  },
  {
    "text": "actively encode and decode languages amongst each other this is like cutting-edge research top-of-the-line in",
    "start": "199389",
    "end": "206260"
  },
  {
    "text": "terms of natural language processing and yet even for those of us that are not",
    "start": "206260",
    "end": "211659"
  },
  {
    "text": "fluent in German in the room you can see that precisely the first sentence has",
    "start": "211659",
    "end": "217000"
  },
  {
    "text": "quite a lot of different words they are different words right and we see that Google very helpfully tells us that the",
    "start": "217000",
    "end": "224409"
  },
  {
    "text": "economics of economics is a part of economics with numerous references to economics in between and this is",
    "start": "224409",
    "end": "231819"
  },
  {
    "text": "problematic right that you've probably seen other google translate fails they're quite common on the Internet to",
    "start": "231819",
    "end": "237609"
  },
  {
    "text": "laugh at and I think it's great we should be laughing but I feel a little bit bad for the brain researchers and",
    "start": "237609",
    "end": "245199"
  },
  {
    "text": "engineers working on this because this is really actually a quite a hard problem right this is a hard problem to",
    "start": "245199",
    "end": "250540"
  },
  {
    "text": "solve and it's hard to especially map languages that have very disparate vocabularies German English have some",
    "start": "250540",
    "end": "257829"
  },
  {
    "text": "overlap right but very disparate vocabularies and disparate amounts of words in regular use and to properly map",
    "start": "257829",
    "end": "264550"
  },
  {
    "text": "them to one another this is a tremendously difficult thing to do and again computers are pretty stupid so",
    "start": "264550",
    "end": "270909"
  },
  {
    "text": "unless we can exactly tell it how to solve the problem or exactly show it how to solve the problem it's very unlikely",
    "start": "270909",
    "end": "277270"
  },
  {
    "text": "that it will learn how to recover from an error such as this",
    "start": "277270",
    "end": "282810"
  },
  {
    "text": "and to continue on this how many people here are I phone users and can you keep",
    "start": "282870",
    "end": "290220"
  },
  {
    "text": "your hand up if you use Siri if you have Siri turned on and can you keep your",
    "start": "290220",
    "end": "295680"
  },
  {
    "text": "hand up if you would recommend Siri to others and you like using Siri okay",
    "start": "295680",
    "end": "300930"
  },
  {
    "text": "excellent and so there's lots of Siri fail jokes",
    "start": "300930",
    "end": "306990"
  },
  {
    "text": "on the internet there's entire websites I found this site why Siri why where people like to post their Siri jokes and",
    "start": "306990",
    "end": "314780"
  },
  {
    "text": "we are asking Siri that we don't want to note and we're asking Siri to cancel the",
    "start": "314780",
    "end": "320460"
  },
  {
    "text": "note and Siri doesn't understand right and this is again we often think of Siri",
    "start": "320460",
    "end": "326190"
  },
  {
    "text": "as almost like a human right we talked as serious if we would another human but Siri is just a computer program or a",
    "start": "326190",
    "end": "332790"
  },
  {
    "text": "series of computer programs and a series of machine learning models and it can really not make any type of human",
    "start": "332790",
    "end": "338850"
  },
  {
    "text": "inferences these simple commands it doesn't understand them and it tries to approximate as best possible another",
    "start": "338850",
    "end": "347580"
  },
  {
    "text": "hard problem is disambiguation so in natural language processing we will call",
    "start": "347580",
    "end": "353250"
  },
  {
    "text": "this problem disambiguation and this means that two things are the same thing but theory doesn't know this and hasn't",
    "start": "353250",
    "end": "360990"
  },
  {
    "text": "learned this yet and so we say send an email to my wife which wife right and",
    "start": "360990",
    "end": "366479"
  },
  {
    "text": "we've seen this disambiguation problem probably across a lot of other apps and things where you have numerous contacts",
    "start": "366479",
    "end": "371789"
  },
  {
    "text": "saved in different ways and this becomes problematic for AI right again",
    "start": "371789",
    "end": "377610"
  },
  {
    "text": "artificial intelligence to understand and this is mainly because computers are",
    "start": "377610",
    "end": "385050"
  },
  {
    "start": "381000",
    "end": "479000"
  },
  {
    "text": "stupid right and it's funny and it's great to make jokes at Siri and it's great to laugh about Translate errors",
    "start": "385050",
    "end": "393060"
  },
  {
    "text": "and so forth but my concern is that there's more and more machine learning that is touching our lives in sometimes",
    "start": "393060",
    "end": "399840"
  },
  {
    "text": "obvious ways like self-driving cars and sometimes non-obvious ways like just",
    "start": "399840",
    "end": "405510"
  },
  {
    "text": "using our bank loans and our credit card applications and our school applications and reviewing things for us right so an",
    "start": "405510",
    "end": "413909"
  },
  {
    "text": "obvious example is self-driving cars everybody likes to pick on self-driving cars so I would join in the fun and what we have",
    "start": "413909",
    "end": "420420"
  },
  {
    "text": "here is a page from a research paper that was released I believe about a year",
    "start": "420420",
    "end": "425970"
  },
  {
    "text": "and a half ago and it was on testing the day of two self-driving platform is about testing and anticipating errors",
    "start": "425970",
    "end": "432960"
  },
  {
    "text": "that the self-driving cars may see in the real world we can see the input to",
    "start": "432960",
    "end": "439410"
  },
  {
    "text": "the left where the picture is quite bright and we're just driving smoothly down the road and we see the picture to",
    "start": "439410",
    "end": "445740"
  },
  {
    "text": "the right that has only been changed by the dark the darkness so the brightness of the picture and some of the contrast",
    "start": "445740",
    "end": "451770"
  },
  {
    "text": "elements and we're going to die a fiery death so in these cases we really need",
    "start": "451770",
    "end": "458490"
  },
  {
    "text": "to start thinking of how we can anticipate the fact that computers are stupid and a machine learning can only",
    "start": "458490",
    "end": "465270"
  },
  {
    "text": "know what we've shown it it doesn't still doesn't generalize that well and it still can't always interpret input",
    "start": "465270",
    "end": "472440"
  },
  {
    "text": "that it hasn't seen and for this reason we need to help think for the computers",
    "start": "472440",
    "end": "478640"
  },
  {
    "text": "and I say that computers are stupid but I really don't believe that computers",
    "start": "478640",
    "end": "484140"
  },
  {
    "start": "479000",
    "end": "545000"
  },
  {
    "text": "are stupid right that would mean that computers have brains and intelligence and all these things I think that",
    "start": "484140",
    "end": "490140"
  },
  {
    "text": "computers are really good at a few things computing like calculating numbers running programs right the good",
    "start": "490140",
    "end": "497550"
  },
  {
    "text": "at sometimes parallelization and there's sometimes ok at sending messages to each other not all the time but sometimes we",
    "start": "497550",
    "end": "504930"
  },
  {
    "text": "get a received message right and the reason why we can do amazing things like",
    "start": "504930",
    "end": "510510"
  },
  {
    "text": "machine learning and like numerous of the other programs that we run our systems that we build is because humans",
    "start": "510510",
    "end": "516840"
  },
  {
    "text": "are really smart humans are quite clever we are sometimes dangerously clever I'm",
    "start": "516840",
    "end": "522570"
  },
  {
    "text": "certain for most the people in this room that you've written computer programs and there has been moments where you're",
    "start": "522570",
    "end": "528030"
  },
  {
    "text": "thinking I'm being really clever right now and some of those times it has come back to haunt you write your own",
    "start": "528030",
    "end": "535200"
  },
  {
    "text": "cleverness have come to haunt you so I feel like this can sometimes be a bit of",
    "start": "535200",
    "end": "540360"
  },
  {
    "text": "a dangerous combination so let's explore this dangerous combination one such way",
    "start": "540360",
    "end": "547620"
  },
  {
    "start": "545000",
    "end": "680000"
  },
  {
    "text": "that clever humans can fool stupid computers is adversarial",
    "start": "547620",
    "end": "552750"
  },
  {
    "text": "examples so adversarial examples have flourished let's say in the past few",
    "start": "552750",
    "end": "558960"
  },
  {
    "text": "years but the first adversarial example is used with machine learning date back to 2005 so this is by no means a new",
    "start": "558960",
    "end": "566550"
  },
  {
    "text": "research area and what adversarial examples are is there are essentially ways that we can full neural networks",
    "start": "566550",
    "end": "572730"
  },
  {
    "text": "into seeing or noting that something is in the input space that is not actually",
    "start": "572730",
    "end": "579060"
  },
  {
    "text": "there so here is an adversarial turtle and you might ask what indeed is an",
    "start": "579060",
    "end": "586320"
  },
  {
    "text": "adversarial turtle well this is a turtle that was printed is 3d printed in a lab",
    "start": "586320",
    "end": "591570"
  },
  {
    "text": "and it has what the authors call adversarial textures and so the textures",
    "start": "591570",
    "end": "598320"
  },
  {
    "text": "along its back and sides and belly so to speak all have these adversarial",
    "start": "598320",
    "end": "603960"
  },
  {
    "text": "textures and we humans we just see maybe some funny patterns right some funny",
    "start": "603960",
    "end": "609030"
  },
  {
    "text": "brightness and different spaces but what the computer vision Network sees is a",
    "start": "609030",
    "end": "614100"
  },
  {
    "text": "rifle the computer vision network is very convinced more than 90% which is",
    "start": "614100",
    "end": "619860"
  },
  {
    "text": "quite rare in computer vision tasks more than 90% convinced that this turtle is a",
    "start": "619860",
    "end": "625170"
  },
  {
    "text": "rifle so we've completely fooled to the network right and we humans we still see",
    "start": "625170",
    "end": "630690"
  },
  {
    "text": "the turtle and this is kind of fun right and you might be thinking how does this work so let's describe a little bit how",
    "start": "630690",
    "end": "636690"
  },
  {
    "text": "it works how we train these computer vision models and most machine learning models especially neural networks is we",
    "start": "636690",
    "end": "644250"
  },
  {
    "text": "iterate over epochs and we try to reduce error so we're going from a place perhaps of high error to a place of",
    "start": "644250",
    "end": "650910"
  },
  {
    "text": "lower error and higher confidence and how we're able to then fool these is we",
    "start": "650910",
    "end": "657090"
  },
  {
    "text": "essentially move in the opposite direction we try to increase uncertainty in the model and by increasing",
    "start": "657090",
    "end": "663510"
  },
  {
    "text": "uncertainty towards let's say the direction of the rifle class we can then get it to misclassify this turtle as a",
    "start": "663510",
    "end": "671220"
  },
  {
    "text": "rifle and to essentially see something remember doesn't have eyes so it can't see but see something that isn't there",
    "start": "671220",
    "end": "679310"
  },
  {
    "text": "and this cleverness continues in the that we can also fool biometric systems",
    "start": "679310",
    "end": "686500"
  },
  {
    "start": "680000",
    "end": "818000"
  },
  {
    "text": "and really any type of system that has regular machine learning or what we",
    "start": "686500",
    "end": "691930"
  },
  {
    "text": "might call active learning so repetitive learning over a series of time across",
    "start": "691930",
    "end": "697300"
  },
  {
    "text": "the bottom we have a series of images that represent the person's face and",
    "start": "697300",
    "end": "702870"
  },
  {
    "text": "this is the person's face as seen by the machine learning model this is what we",
    "start": "702870",
    "end": "708580"
  },
  {
    "text": "call the centroid or we can think of it as the maximum activation or maximum",
    "start": "708580",
    "end": "713920"
  },
  {
    "text": "likelihood that it is this person and what we see across the top is the attack",
    "start": "713920",
    "end": "720100"
  },
  {
    "text": "sequence and in this attack sequence very similar to adversarial examples",
    "start": "720100",
    "end": "725290"
  },
  {
    "text": "were essentially trying to push the class towards a different area or a different region of possible input space",
    "start": "725290",
    "end": "732190"
  },
  {
    "text": "and in this case this is worked by Batista Biggio he's done quite a lot of",
    "start": "732190",
    "end": "737380"
  },
  {
    "text": "work on adversarial learning and poisoning examples and in this case the",
    "start": "737380",
    "end": "742570"
  },
  {
    "text": "goal was to make the facial recognition system show the person with glasses and",
    "start": "742570",
    "end": "747670"
  },
  {
    "text": "this might be in a real-world attack this might be that we want to attack their computer we want to put on a pair",
    "start": "747670",
    "end": "753490"
  },
  {
    "text": "of glasses or sunglasses somewhat have similar facial features and then we can either unlock the computer and get into",
    "start": "753490",
    "end": "759910"
  },
  {
    "text": "the system and get into their bank account whatever it is we're trying to do right and via this poisoning attack",
    "start": "759910",
    "end": "765910"
  },
  {
    "text": "this iterative poisoning attack so again it has to be something that learns on a regular basis this iterative a poisoning",
    "start": "765910",
    "end": "772150"
  },
  {
    "text": "attack we can poison the data and we can fool the neural network or the computer vision or the SVM or whatever model",
    "start": "772150",
    "end": "778870"
  },
  {
    "text": "we're trying to fool into seeing something or believing something about the data that's not there now these",
    "start": "778870",
    "end": "785350"
  },
  {
    "text": "poisoning attacks are quite frequent against spam or phishing but we can also use them against any other types of",
    "start": "785350",
    "end": "791950"
  },
  {
    "text": "models so I could essentially do a poisoning attack against computer vision that reads checks and I could rewrite",
    "start": "791950",
    "end": "798970"
  },
  {
    "text": "your check from 1,000 euros to 10,000 euros and so forth right so these are",
    "start": "798970",
    "end": "805510"
  },
  {
    "text": "things that we need to worry about in the way that we deploy systems and the way that we think about training our",
    "start": "805510",
    "end": "810760"
  },
  {
    "text": "data because right now we kind of grab as much data as possible and we retrain as much",
    "start": "810760",
    "end": "815890"
  },
  {
    "text": "as possible and it goes beyond just fooling stupid computers into say seeing",
    "start": "815890",
    "end": "823899"
  },
  {
    "start": "818000",
    "end": "975000"
  },
  {
    "text": "things that aren't there or making errors we can also use computers to fool other humans and when we use computers",
    "start": "823899",
    "end": "832089"
  },
  {
    "text": "to fool other humans what we likely have in mind is some sort of malicious intent",
    "start": "832089",
    "end": "837550"
  },
  {
    "text": "or interest and if we can use machine learning or data mining some of these",
    "start": "837550",
    "end": "842890"
  },
  {
    "text": "things that computers are quite good at that we humans it would take us quite a long time to do by hand or ourselves",
    "start": "842890",
    "end": "849209"
  },
  {
    "text": "then we can create problems not only within our society but within let's say",
    "start": "849209",
    "end": "855430"
  },
  {
    "text": "the social fabric of our world one such example of course is Cambridge analytic",
    "start": "855430",
    "end": "862540"
  },
  {
    "text": "ah which is quite prescient now with upcoming new elections across many",
    "start": "862540",
    "end": "867820"
  },
  {
    "text": "places is this epidemic of being able to target other people using machine",
    "start": "867820",
    "end": "873279"
  },
  {
    "text": "learning or using some sort of data modelling around whether a person may or may not be susceptible to this type of",
    "start": "873279",
    "end": "880089"
  },
  {
    "text": "negative advertisement and here is a screen grab from one of the page that",
    "start": "880089",
    "end": "885579"
  },
  {
    "text": "one of the pages that bought from Cambridge analytical and what Cambridge analytical did was of course use the",
    "start": "885579",
    "end": "891699"
  },
  {
    "text": "Facebook API to extract information they claimed that they used Facebook with in terms Facebook says not with in terms I",
    "start": "891699",
    "end": "898959"
  },
  {
    "text": "don't know when the terms were updated I don't know why they had access if it's against the terms but neither here nor",
    "start": "898959",
    "end": "904149"
  },
  {
    "text": "there right they were able to get this information from Facebook and make models on people that they thought might",
    "start": "904149",
    "end": "911019"
  },
  {
    "text": "be susceptible to this type of advertising and with those models combined with also the location of that",
    "start": "911019",
    "end": "917829"
  },
  {
    "text": "person and if they were in a key voting district for both the UK leave vote and",
    "start": "917829",
    "end": "923250"
  },
  {
    "text": "for the Clinton versus Trump vote they were perhaps able to help sway the",
    "start": "923250",
    "end": "929769"
  },
  {
    "text": "election now is very difficult for us to know whether those people would have voted or not voted the way that they did",
    "start": "929769",
    "end": "936820"
  },
  {
    "text": "after they saw these advertisements but what we do know is that this type of malicious advertising that is getting",
    "start": "936820",
    "end": "943149"
  },
  {
    "text": "easier to do that it's not getting harder that we're making more and more software that allows us to process",
    "start": "943149",
    "end": "949660"
  },
  {
    "text": "data at a massive scale we have quite a lot of useful open-source machine learning libraries and if one were to",
    "start": "949660",
    "end": "955480"
  },
  {
    "text": "try and do it today versus say in the 90s or the early thousands it would",
    "start": "955480",
    "end": "960790"
  },
  {
    "text": "definitely be easier to do so and so we need to think about ways that we fool other humans using our own cleverness",
    "start": "960790",
    "end": "967600"
  },
  {
    "text": "and machines at what they're good at so called parallel processing and",
    "start": "967600",
    "end": "972790"
  },
  {
    "text": "mathematics and so if computers are",
    "start": "972790",
    "end": "979480"
  },
  {
    "start": "975000",
    "end": "1250000"
  },
  {
    "text": "stupid and humans are smart what else as to this equation well unfortunately",
    "start": "979480",
    "end": "985420"
  },
  {
    "text": "humans are also prone to bias and we tend to harbor our own biases our own",
    "start": "985420",
    "end": "990880"
  },
  {
    "text": "preferences right I don't mean statistical bias I mean a human bias a personal bias and some of these are",
    "start": "990880",
    "end": "998770"
  },
  {
    "text": "informed perhaps by our own personal experiences and other of these are informed by our society and they're",
    "start": "998770",
    "end": "1006270"
  },
  {
    "text": "informed by racism sexism homophobia transphobia scared scared of different",
    "start": "1006270",
    "end": "1013560"
  },
  {
    "text": "religions different cultures different languages right this is something that happens all over the world and has",
    "start": "1013560",
    "end": "1020160"
  },
  {
    "text": "happened throughout history and so we know humans are biased we tend to feel closer to people similar to us and we",
    "start": "1020160",
    "end": "1027060"
  },
  {
    "text": "tend to feel further from people that are different from us and unfortunately this plays out in very dangerous ways",
    "start": "1027060",
    "end": "1032459"
  },
  {
    "text": "when we allow this to interact for the fact that computers are stupid but",
    "start": "1032459",
    "end": "1038459"
  },
  {
    "text": "humans are smart and one of the ways that this can interact is been a large",
    "start": "1038459",
    "end": "1045270"
  },
  {
    "text": "area of research and study particularly gaining focus in the machine learning community over the past few years which",
    "start": "1045270",
    "end": "1052470"
  },
  {
    "text": "is ethical or fairness issues within machine learning and this is by no means",
    "start": "1052470",
    "end": "1058200"
  },
  {
    "text": "a new research operation because Latanya Sweeney was writing about this more than",
    "start": "1058200",
    "end": "1065100"
  },
  {
    "text": "10 years ago and Latanya Sweeney was taking a look at this because this was",
    "start": "1065100",
    "end": "1071160"
  },
  {
    "text": "an era in the late 2000s I believe it was where everybody was saying oh you",
    "start": "1071160",
    "end": "1077100"
  },
  {
    "text": "got a Google yourself and you get a Google yourself you got to make a brand you've got a s",
    "start": "1077100",
    "end": "1082650"
  },
  {
    "text": "yo your SEO mojo and stuff there is all this hype around googling yourself and",
    "start": "1082650",
    "end": "1088050"
  },
  {
    "text": "figuring out what people would find out about you and this is cuz when you went for job interviews and when you were up",
    "start": "1088050",
    "end": "1094320"
  },
  {
    "text": "for in her case assistant professor ships at Harvard and now she is a tenured professor there but when you're",
    "start": "1094320",
    "end": "1100200"
  },
  {
    "text": "going up for these things you want to know what other people will find when they search the internet about you and",
    "start": "1100200",
    "end": "1106850"
  },
  {
    "text": "what Latanya Sweeney found was that the top place which of course is always",
    "start": "1106850",
    "end": "1112500"
  },
  {
    "text": "reserved for advertisements the top place had an advertisement asking if she had been arrested do you want to check",
    "start": "1112500",
    "end": "1119580"
  },
  {
    "text": "out Latanya Sweeney 'he's arrest records she thought herself you know I've never been arrested and I feel like my name is",
    "start": "1119580",
    "end": "1126870"
  },
  {
    "text": "pretty unique she has a background in mathematics statistics and computer science and so she actually took it upon",
    "start": "1126870",
    "end": "1133500"
  },
  {
    "text": "herself to run some experiments when she ran these experiments the only",
    "start": "1133500",
    "end": "1139110"
  },
  {
    "text": "correlation that she could find is that she had a black sounding name and that",
    "start": "1139110",
    "end": "1144660"
  },
  {
    "text": "because her name had an representation or a greater representation within the",
    "start": "1144660",
    "end": "1149820"
  },
  {
    "text": "african-american community these black sounding names would and other black sounding names they were massively",
    "start": "1149820",
    "end": "1157160"
  },
  {
    "text": "over-represented in advertisements that displayed arrest records and they were",
    "start": "1157160",
    "end": "1162540"
  },
  {
    "text": "massively over-represented from a random sample of names and they were much more massively over-represented than white or",
    "start": "1162540",
    "end": "1169200"
  },
  {
    "text": "white European sounding names and obviously I don't think that Google said",
    "start": "1169200",
    "end": "1175860"
  },
  {
    "text": "hmm how can we make more money we're gonna sell arrest records against black sounding names this is what we're gonna",
    "start": "1175860",
    "end": "1182220"
  },
  {
    "text": "do no this is a problem of bias that is from society that is four hump from the",
    "start": "1182220",
    "end": "1189990"
  },
  {
    "text": "data that we collect and perhaps some of the features that we extract and perhaps even from some of these advertisers",
    "start": "1189990",
    "end": "1196830"
  },
  {
    "text": "doing their own data mining and their own machine learning on what terms they would like to target right and this then",
    "start": "1196830",
    "end": "1204600"
  },
  {
    "text": "becomes creeps into our models and remains there until somebody's willing to sit there and do the research and do",
    "start": "1204600",
    "end": "1211650"
  },
  {
    "text": "the work to find it and if Latanya Sweeney didn't do this work I am quite certain that this wooden",
    "start": "1211650",
    "end": "1217299"
  },
  {
    "text": "would have gone unnoticed for a much longer time and so one of the things we",
    "start": "1217299",
    "end": "1222730"
  },
  {
    "text": "need to think about if for those of you that do machine learning in the room and even for those of you that work with",
    "start": "1222730",
    "end": "1227980"
  },
  {
    "text": "systems that use machine learning is how can we help better test for these things how can we find a cycle testing and",
    "start": "1227980",
    "end": "1235630"
  },
  {
    "text": "ethical standards that we can use before we hit deploy and before we start affecting people with biases within our",
    "start": "1235630",
    "end": "1242919"
  },
  {
    "text": "datasets we need to figure out good ways of doing this before we affect and potentially ruin other people's lives",
    "start": "1242919",
    "end": "1251669"
  },
  {
    "start": "1250000",
    "end": "1529000"
  },
  {
    "text": "now another issue when we think of these biases is privacy and privacy issues",
    "start": "1252150",
    "end": "1260169"
  },
  {
    "text": "within machine learning are not new by any means but they're becoming greater",
    "start": "1260169",
    "end": "1265360"
  },
  {
    "text": "and the bias I'm speaking of here is essentially confirmation bias or the",
    "start": "1265360",
    "end": "1270669"
  },
  {
    "text": "fact that when everything's working properly we don't ask a lot of questions in machine learning systems we usually",
    "start": "1270669",
    "end": "1279190"
  },
  {
    "text": "are focused on let's say accuracy or precision and recall we're focused on some metrics that we would like to optimize perhaps we also have speed",
    "start": "1279190",
    "end": "1286690"
  },
  {
    "text": "constraints or deployment constraints but we're thinking about optimizing usually for some sort of accuracy metric",
    "start": "1286690",
    "end": "1293260"
  },
  {
    "text": "or approximation of accuracy metric that we'd like to meet and I have had numerous conversations with my fellow",
    "start": "1293260",
    "end": "1299860"
  },
  {
    "text": "machine learning practitioners where they say well you know the more private data I feed into my model the better it",
    "start": "1299860",
    "end": "1305740"
  },
  {
    "text": "gets so why not I mean I need that one last percentage point so if the purse is",
    "start": "1305740",
    "end": "1313240"
  },
  {
    "text": "zip code and they're age and the last three characters of their name if this ends up being really informative then",
    "start": "1313240",
    "end": "1319270"
  },
  {
    "text": "let's do it and we won't talk we're too talked about the ethical issues but you can start to think about perhaps ethical",
    "start": "1319270",
    "end": "1324760"
  },
  {
    "text": "issues within that we won't go into that but there's also privacy issues when we feed all this private data to the models",
    "start": "1324760",
    "end": "1331270"
  },
  {
    "text": "we need to think of the models as perhaps just like we think of other things perhaps the way we think of open",
    "start": "1331270",
    "end": "1337000"
  },
  {
    "text": "databases that are touching the public Internet they can be used to query",
    "start": "1337000",
    "end": "1342309"
  },
  {
    "text": "private data and so here we have again a facial recognition system on the right",
    "start": "1342309",
    "end": "1348580"
  },
  {
    "text": "here we have training image which is from the 80 faces data set which I highly recommend for looking at really awesome hairdos",
    "start": "1348580",
    "end": "1356610"
  },
  {
    "text": "and glasses from like the late 70s early 80s it's super awesome anyways so ATT faces dataset and we have",
    "start": "1356610",
    "end": "1364530"
  },
  {
    "text": "trained the model now to recognize faces and we essentially use you can think of it very similarly to the other attacks",
    "start": "1364530",
    "end": "1371070"
  },
  {
    "text": "we described but in this case we want to maximize confidence so we're looking for the maximum activation again for the",
    "start": "1371070",
    "end": "1377870"
  },
  {
    "text": "input space that achieves the highest confidence for this particular name so",
    "start": "1377870",
    "end": "1384780"
  },
  {
    "text": "in this case the attacker was only given the name of the person and black box",
    "start": "1384780",
    "end": "1390330"
  },
  {
    "text": "access to the API so this means not access to the model itself but just API queries that it can run and they were",
    "start": "1390330",
    "end": "1398130"
  },
  {
    "text": "able to achieve the image that we see on the left so without knowing how the person looked at all was just their name",
    "start": "1398130",
    "end": "1404280"
  },
  {
    "text": "and access to the facial recognition model they were able to extract a fairly good approximation of course quite fuzzy",
    "start": "1404280",
    "end": "1410460"
  },
  {
    "text": "but we can see the face shape we can see the facial hair we can see the glasses and so on and these attacks can also be",
    "start": "1410460",
    "end": "1417750"
  },
  {
    "text": "used to infer other data that's not facial data of course other biometric data as well but these attacks can also",
    "start": "1417750",
    "end": "1424650"
  },
  {
    "text": "reveal membership in a training set so professor Reza chakra who is at the",
    "start": "1424650",
    "end": "1429930"
  },
  {
    "text": "University of Singapore won an award this year on privacy and machine learning and this is because he modeled",
    "start": "1429930",
    "end": "1437340"
  },
  {
    "text": "a new attack called a membership inference attack with his membership inference attack he showed again with",
    "start": "1437340",
    "end": "1443520"
  },
  {
    "text": "limited access to the model limited API queries and with limited information about the person in the data set that he",
    "start": "1443520",
    "end": "1451470"
  },
  {
    "text": "could extract with between 70 to 90 percent confidence whether they were a part of the training data set so this",
    "start": "1451470",
    "end": "1460380"
  },
  {
    "text": "might not seem that scary but if you work in machine learning you know that we're creating ever and ever more",
    "start": "1460380",
    "end": "1465630"
  },
  {
    "text": "specialized models that now ensemble models become quite popular and that we",
    "start": "1465630",
    "end": "1471510"
  },
  {
    "text": "put people through a series of let's say tests may be some initial classification and then we create groupings and",
    "start": "1471510",
    "end": "1477470"
  },
  {
    "text": "particularly within advertising we may create groupings like or woman or person with a black founding",
    "start": "1477470",
    "end": "1486780"
  },
  {
    "text": "name and we may therefore hide essentially private attributes in the",
    "start": "1486780",
    "end": "1492000"
  },
  {
    "text": "fact that we build these supplemental models that help us make a better decision at the end and if those",
    "start": "1492000",
    "end": "1498510"
  },
  {
    "text": "supplemental models are exposed in any way and I can figure out whether or not",
    "start": "1498510",
    "end": "1503580"
  },
  {
    "text": "you're part of the training data set now I know with 70 to 90 percent accuracy",
    "start": "1503580",
    "end": "1508679"
  },
  {
    "text": "your private variable whether you have a black sounding name in cases of disease",
    "start": "1508679",
    "end": "1514470"
  },
  {
    "text": "whether you're HIV positive or negative in cases of other things that I can",
    "start": "1514470",
    "end": "1519690"
  },
  {
    "text": "learn more information that you are specifically chosen to be grouped by or to be sampled by and this is of course",
    "start": "1519690",
    "end": "1526770"
  },
  {
    "text": "very dangerous for privacy and continuing with let's say the cleverness",
    "start": "1526770",
    "end": "1534600"
  },
  {
    "text": "but the prone to bias is we haven't yet figured out a great way of explaining",
    "start": "1534600",
    "end": "1540870"
  },
  {
    "text": "how most of the machine learning models that we deploy work and often the",
    "start": "1540870",
    "end": "1546540"
  },
  {
    "text": "methods that we use circumvent our ability to explain them in a human",
    "start": "1546540",
    "end": "1552030"
  },
  {
    "text": "understandable way very easily you can kind of think of this I don't know how",
    "start": "1552030",
    "end": "1557760"
  },
  {
    "text": "many older hackers we have in the room but has anybody back in the day tried to",
    "start": "1557760",
    "end": "1563910"
  },
  {
    "text": "like say hack an undocumented API like the win32 or something from or other",
    "start": "1563910",
    "end": "1569490"
  },
  {
    "text": "ones like that and so we know that with these problems what happens is you have",
    "start": "1569490",
    "end": "1575760"
  },
  {
    "text": "this undocumented API you don't quite know how it works and one good way of figuring out how it works is to just put",
    "start": "1575760",
    "end": "1581730"
  },
  {
    "text": "some random stuff in and see what happens right and you kind of experiment and you iterate on that well that's",
    "start": "1581730",
    "end": "1588510"
  },
  {
    "text": "actually a pretty great way pretty ingenious way I would say clever clever humans being clever way of trying to",
    "start": "1588510",
    "end": "1596160"
  },
  {
    "text": "discern how these models work and so what we have here is Marco Rubio sorry",
    "start": "1596160",
    "end": "1603950"
  },
  {
    "text": "his work online which is called local interpretable model explanations and",
    "start": "1603950",
    "end": "1609679"
  },
  {
    "text": "what he did with lime he also released a Python package so you can install it and",
    "start": "1609679",
    "end": "1615030"
  },
  {
    "text": "use for machine learning models that you operate with even black box models so even ones or you don't have access to",
    "start": "1615030",
    "end": "1620549"
  },
  {
    "text": "the model in fact that's exactly how it works and what we have here is an example and",
    "start": "1620549",
    "end": "1625589"
  },
  {
    "text": "on the far left we have the input image and that input image had three classes electric guitar acoustic guitar and",
    "start": "1625589",
    "end": "1633059"
  },
  {
    "text": "Labrador those were the classes that the computer vision algorithm or the computer vision model decided to say",
    "start": "1633059",
    "end": "1640499"
  },
  {
    "text": "okay that it sees electric guitar acoustic guitar and Labrador and what lime does is it takes the input space",
    "start": "1640499",
    "end": "1646950"
  },
  {
    "text": "from the original example and it tries to find connected chunks and it submits",
    "start": "1646950",
    "end": "1652739"
  },
  {
    "text": "these connected chunks in different ways in order to find again the maximum confidence for that particular class and",
    "start": "1652739",
    "end": "1659659"
  },
  {
    "text": "so we can see that this chunk here is the electric guitar then we have the chunk for the acoustic guitar which is",
    "start": "1659659",
    "end": "1666059"
  },
  {
    "text": "kind of the body of the guitar and then we have the chunk for the Labrador which somehow connects this to this right but",
    "start": "1666059",
    "end": "1673859"
  },
  {
    "text": "these are the maximum confidence for these different classes and this is pretty neat right so these solved",
    "start": "1673859",
    "end": "1679799"
  },
  {
    "text": "interpretability right we solved do we solve it no unfortunately we did not and",
    "start": "1679799",
    "end": "1685889"
  },
  {
    "text": "this is because as in the name this is only a local explanation so it's only",
    "start": "1685889",
    "end": "1691769"
  },
  {
    "text": "locally interpretable and what it means by this is this by no means tells us anything global about the model it can",
    "start": "1691769",
    "end": "1698999"
  },
  {
    "text": "only explain this one input and in fact what we know with adversarial examples",
    "start": "1698999",
    "end": "1704399"
  },
  {
    "text": "is if we add some adversarial pixels to this it might change the explanation entirely so we can change as few as two",
    "start": "1704399",
    "end": "1711839"
  },
  {
    "text": "or three pixels and have a completely different explanation and so the problem",
    "start": "1711839",
    "end": "1717149"
  },
  {
    "text": "with finding approximations or explanations for these type of complex",
    "start": "1717149",
    "end": "1722159"
  },
  {
    "text": "models particularly neural networks that can have millions of nodes which are essentially millions of little function",
    "start": "1722159",
    "end": "1727889"
  },
  {
    "text": "approximations is that this is only useful for what we've seen before or",
    "start": "1727889",
    "end": "1734759"
  },
  {
    "text": "what we can submit and it cannot tell us anything about what we haven't seen or what might come in the future or what",
    "start": "1734759",
    "end": "1741599"
  },
  {
    "text": "might come in production and so you might be saying yeah but we can explain simpler models right like if we",
    "start": "1741599",
    "end": "1749309"
  },
  {
    "start": "1743000",
    "end": "1867000"
  },
  {
    "text": "have just linear regression let's just have a linear regression we can definitely explain linear regression",
    "start": "1749309",
    "end": "1754440"
  },
  {
    "text": "right well I'm gonna have here is lime or actually this is Li 5 which is",
    "start": "1754440",
    "end": "1760769"
  },
  {
    "text": "another Python library that's used to explain or implements version of lime and here we have explained waits and",
    "start": "1760769",
    "end": "1769110"
  },
  {
    "text": "waits is just going to list the features by their weights now not only must I",
    "start": "1769110",
    "end": "1774269"
  },
  {
    "text": "note that we have 300 more or sorry more than 700 more that we can't see it's",
    "start": "1774269",
    "end": "1782070"
  },
  {
    "text": "just that when we look at this we also can't interpret this right this has been",
    "start": "1782070",
    "end": "1787950"
  },
  {
    "text": "used with feature engineering so these are polynomial features which is quite common to do these are essentially",
    "start": "1787950",
    "end": "1793919"
  },
  {
    "text": "functions of the future input right and then we also have what is point O eight",
    "start": "1793919",
    "end": "1799889"
  },
  {
    "text": "three versus 0.038 versus 0.036 this is not interpreted to us and it also we",
    "start": "1799889",
    "end": "1807149"
  },
  {
    "text": "need to know the possible values of that feature so the value is a large number like say year or second since date of",
    "start": "1807149",
    "end": "1814950"
  },
  {
    "text": "birth versus a small number like month since last payment or something like this this could have very different",
    "start": "1814950",
    "end": "1821460"
  },
  {
    "text": "meaning with these weights right and so even figuring out something like an explanation for linear regression is not",
    "start": "1821460",
    "end": "1828360"
  },
  {
    "text": "obvious can be done by the people that build model and by other statisticians but it's not obvious let's say to",
    "start": "1828360",
    "end": "1836059"
  },
  {
    "text": "everyone how to go about this and it's not obvious to everything given the fact that we might not know the full input",
    "start": "1836059",
    "end": "1842190"
  },
  {
    "text": "space and so essentially model explanations are difficult and they're",
    "start": "1842190",
    "end": "1847619"
  },
  {
    "text": "by no means a solved problem space and if we're going to deploy these stupid machines these stupid AI models into the",
    "start": "1847619",
    "end": "1855749"
  },
  {
    "text": "world and use them then we need to figure out smarter ways to explain them",
    "start": "1855749",
    "end": "1861210"
  },
  {
    "text": "and to potentially find these biases or these privacy issues within them and so",
    "start": "1861210",
    "end": "1869809"
  },
  {
    "start": "1867000",
    "end": "1952000"
  },
  {
    "text": "we need to kind of try to think about how to start to solve this problem right because I don't want to leave you",
    "start": "1869809",
    "end": "1876059"
  },
  {
    "text": "tremendously depressed and also I don't want to leave you just thinking we should never do machine learning right",
    "start": "1876059",
    "end": "1881279"
  },
  {
    "text": "because that's not my goal either and I think perhaps we can figure out ways to protect ourselves and others and",
    "start": "1881279",
    "end": "1889720"
  },
  {
    "text": "the models themselves from these types of errors these biases these privacy issues and so forth and here's one of my",
    "start": "1889720",
    "end": "1897279"
  },
  {
    "text": "favorite xkcd comics I'll give you a moment to read it in case you haven't",
    "start": "1897279",
    "end": "1902470"
  },
  {
    "text": "read it before",
    "start": "1902470",
    "end": "1905099"
  },
  {
    "text": "I will assume that you start laughing when you're done reading anyways so what",
    "start": "1914360",
    "end": "1920930"
  },
  {
    "text": "we'll talk about is a little bit from both camps so of course given my backgrounds I lean more towards the",
    "start": "1920930",
    "end": "1927350"
  },
  {
    "text": "crypto nerds imagination and I think figuring out those solutions are really really fun and that's part of what I",
    "start": "1927350",
    "end": "1933830"
  },
  {
    "text": "work on and do but I also think it's really important to take a step back and say Katherine let's be realistic like",
    "start": "1933830",
    "end": "1940280"
  },
  {
    "text": "what is most likely the case of security issues or privacy and ethical issues",
    "start": "1940280",
    "end": "1945800"
  },
  {
    "text": "with in machine learning which is probably a little bit more like the right side so we'll try and cover a little bit of both the first and",
    "start": "1945800",
    "end": "1954230"
  },
  {
    "start": "1952000",
    "end": "2122000"
  },
  {
    "text": "foremost is you might have noticed and if any of you work or have worked in pen testing or web security that I mentioned",
    "start": "1954230",
    "end": "1961160"
  },
  {
    "text": "access to API is a bunch of times and this is really really key right if we",
    "start": "1961160",
    "end": "1966680"
  },
  {
    "text": "can lock down access to model api's most of these types of attacks go away also",
    "start": "1966680",
    "end": "1972350"
  },
  {
    "text": "our ability to explain things goes away so maybe we should think about explanations internally right and how we",
    "start": "1972350",
    "end": "1978410"
  },
  {
    "text": "can produce meaningful explanations for decisions that we make but we need to",
    "start": "1978410",
    "end": "1984770"
  },
  {
    "text": "protect the model API so we need to think of interfaces to the model API so we need to think about authentication of",
    "start": "1984770",
    "end": "1990500"
  },
  {
    "text": "requests to the model API and we need to not just have them randomly sitting on the public internet free to use",
    "start": "1990500",
    "end": "1996020"
  },
  {
    "text": "completely unauthenticated unless we are okay with them being attacked which might may be we're okay right one",
    "start": "1996020",
    "end": "2004600"
  },
  {
    "text": "of the other things that we can think about that maybe is slightly less obvious is how we can do input",
    "start": "2004600",
    "end": "2010560"
  },
  {
    "text": "sanitization on inputs that we see in production and so what we have across",
    "start": "2010560",
    "end": "2016810"
  },
  {
    "text": "the top here is m-miss this is the emne status set so I'm sorry if you're",
    "start": "2016810",
    "end": "2022780"
  },
  {
    "text": "traumatized and you've seen it a million times before but M missed images and we can see the digits 0",
    "start": "2022780",
    "end": "2028330"
  },
  {
    "text": "through 9 right and we as humans we notice of course the noise the perturbations these are adversarial",
    "start": "2028330",
    "end": "2034990"
  },
  {
    "text": "examples across the top that are often misclassified and we can see them and",
    "start": "2034990",
    "end": "2040090"
  },
  {
    "text": "because our brain works well we can essentially read them through the noise but with the machine learning model what",
    "start": "2040090",
    "end": "2046600"
  },
  {
    "text": "it will is misclassified these quite often and with feature squeezing which is one area",
    "start": "2046600",
    "end": "2054220"
  },
  {
    "text": "of research of a research group that calls themselves evade ml I believe they're based out of the University of",
    "start": "2054220",
    "end": "2059589"
  },
  {
    "text": "Virginia and what they're focused on is defenses against adversarial examples but we can think of this feature",
    "start": "2059589",
    "end": "2065618"
  },
  {
    "text": "squeezing essentially as input sanitization as it's essentially uses",
    "start": "2065619",
    "end": "2071319"
  },
  {
    "text": "dimensionality reduction or if you're familiar with them like a compression algorithm right essentially creating",
    "start": "2071319",
    "end": "2078429"
  },
  {
    "text": "some sort of compression right where we're removing quite a lot of the detail but what we get at the end is a bit of a",
    "start": "2078429",
    "end": "2085868"
  },
  {
    "text": "fuzzier approximation but a much cleaner image the noise and the perturbations",
    "start": "2085869",
    "end": "2092290"
  },
  {
    "text": "they have been mainly removed and this output set after the feature squeezing",
    "start": "2092290",
    "end": "2097869"
  },
  {
    "text": "or after this sanitization step right this compression step is much higher",
    "start": "2097869",
    "end": "2102910"
  },
  {
    "text": "classified and so this is one thing that we can think of is we know that it",
    "start": "2102910",
    "end": "2108970"
  },
  {
    "text": "requires many different requests and we know that when we see very noisy or perhaps unrealistic input that this",
    "start": "2108970",
    "end": "2116380"
  },
  {
    "text": "could either be user error right or this could be something malicious another",
    "start": "2116380",
    "end": "2124869"
  },
  {
    "start": "2122000",
    "end": "2301000"
  },
  {
    "text": "possibility is to actually try and protect the data that goes into our model so essentially to move input",
    "start": "2124869",
    "end": "2131319"
  },
  {
    "text": "sanitization to before we train the model and this is particularly useful in",
    "start": "2131319",
    "end": "2136869"
  },
  {
    "text": "protecting privacy so this is actually what we're building at ki protect is",
    "start": "2136869",
    "end": "2143220"
  },
  {
    "text": "cryptographic methods that allow us for a pseudonym ization and anonymization of",
    "start": "2143220",
    "end": "2148720"
  },
  {
    "text": "data before it goes into a machine learning algorithm and the problem with this is that you want to preserve as",
    "start": "2148720",
    "end": "2155859"
  },
  {
    "text": "much information as as possible so that you can actually learn something and so that you haven't destroyed all of the",
    "start": "2155859",
    "end": "2162099"
  },
  {
    "text": "signal of your data set but the problem is the more signal you leave or the more information you leave the more chance",
    "start": "2162099",
    "end": "2168190"
  },
  {
    "text": "that it's vulnerable to a privacy attack or adian anima zation attack and so what",
    "start": "2168190",
    "end": "2174670"
  },
  {
    "text": "we're currently working on is a strategy that we call homomorphic pseudonym",
    "start": "2174670",
    "end": "2179829"
  },
  {
    "text": "ization has anybody here worked with homomorphic encryption okay I will briefly describe",
    "start": "2179829",
    "end": "2186820"
  },
  {
    "text": "homomorphic encryption so homomorphic encryption allows you to take encrypted",
    "start": "2186820",
    "end": "2191920"
  },
  {
    "text": "numbers and to do simple math with them addition subtraction multiplication and division",
    "start": "2191920",
    "end": "2197200"
  },
  {
    "text": "right that's that's all the math available to you and what happens is you take an encrypted homomorphic encrypted",
    "start": "2197200",
    "end": "2203290"
  },
  {
    "text": "five and you take a hormone morphic li encrypted 2 and you multiply them together and you get a homomorphic li",
    "start": "2203290",
    "end": "2208930"
  },
  {
    "text": "encrypted ten and you can decrypt that and actually see the raw value again see you ten and we're using not a not the",
    "start": "2208930",
    "end": "2217060"
  },
  {
    "text": "same process but a similar process to allow for homomorphic pseudonym ization so you put an in name you encrypt it and",
    "start": "2217060",
    "end": "2224920"
  },
  {
    "text": "you get out a name it's a pseudonym right you can decrypt it back to the original name at any time using the same key but",
    "start": "2224920",
    "end": "2232839"
  },
  {
    "text": "it gets more interesting when you have data that you'd like to retain some sort of relationships in so let's take an IP",
    "start": "2232839",
    "end": "2239290"
  },
  {
    "text": "address you have an IP address you encrypt it you get another IP address but what you can use is prefix",
    "start": "2239290",
    "end": "2247599"
  },
  {
    "text": "preserving which essentially will retain some of the same input space will retain",
    "start": "2247599",
    "end": "2252760"
  },
  {
    "text": "the relationships in the output space so the subnets for IP addresses are preserved in the encrypted state so the",
    "start": "2252760",
    "end": "2261190"
  },
  {
    "text": "outputs face these pseudonyms the subnets between the subnets that were in",
    "start": "2261190",
    "end": "2266380"
  },
  {
    "text": "the input space these are preserved so if you want to do something like anomaly detection or a fraud detection or abuse",
    "start": "2266380",
    "end": "2272290"
  },
  {
    "text": "detection using IP addresses this actually retains quite a lot of information and this is something that",
    "start": "2272290",
    "end": "2278380"
  },
  {
    "text": "we're actively researching and working on and building more tools for if you want to chat about it we also have a",
    "start": "2278380",
    "end": "2284079"
  },
  {
    "text": "technical paper that we can share with you but whether or not you use something",
    "start": "2284079",
    "end": "2289300"
  },
  {
    "text": "like our solution or something this input sanitization for private data before it goes into machine learning",
    "start": "2289300",
    "end": "2295390"
  },
  {
    "text": "models is an essential step if we're going to protect ourselves against privacy attacks finally moving a little",
    "start": "2295390",
    "end": "2304329"
  },
  {
    "start": "2301000",
    "end": "2379000"
  },
  {
    "text": "bit more towards the ways that we can do this outside of technical problems is",
    "start": "2304329",
    "end": "2309510"
  },
  {
    "text": "interdisciplinary work so I've been happy say that interdisciplinary panels and",
    "start": "2309510",
    "end": "2315180"
  },
  {
    "text": "panels between let's say legal experts ethical experts sociologists or other people from cultural aspects as well as",
    "start": "2315180",
    "end": "2322650"
  },
  {
    "text": "AI technologists scientists and ethicists these are all starting to come about and people are starting to work on",
    "start": "2322650",
    "end": "2330180"
  },
  {
    "text": "creating regulations creating recommendations that are going to allow us to let's say move forward with",
    "start": "2330180",
    "end": "2336720"
  },
  {
    "text": "machine learning in a better way and this panel was particularly interesting here we have Joanna Bryson and some",
    "start": "2336720",
    "end": "2343710"
  },
  {
    "text": "folks from AI now and this was a really interesting conversation around AI ethics and robot ethics and also talking",
    "start": "2343710",
    "end": "2351120"
  },
  {
    "text": "about how we move forward and I think in the time of GDP our and other ways that governments are trying to figure out how",
    "start": "2351120",
    "end": "2357570"
  },
  {
    "text": "to regulate some of the privacy and security concerns within the types of systems that we're building now is",
    "start": "2357570",
    "end": "2363810"
  },
  {
    "text": "important for us to have these conversations from a broader aspect and I'm hoping that some of these",
    "start": "2363810",
    "end": "2368850"
  },
  {
    "text": "conversations allow us better insight over a longer period of time and thinking outside the box a little bit",
    "start": "2368850",
    "end": "2375240"
  },
  {
    "text": "when we're thinking of our technical solutions as well and finally this is a",
    "start": "2375240",
    "end": "2383550"
  },
  {
    "start": "2379000",
    "end": "2504000"
  },
  {
    "text": "paper distribution of nips and nips is one of the predominant neural network or",
    "start": "2383550",
    "end": "2391100"
  },
  {
    "text": "machine learning conferences in the world and this is made this graph it's",
    "start": "2391100",
    "end": "2397200"
  },
  {
    "text": "grouped by author employer and so we can see that the author employers on the",
    "start": "2397200",
    "end": "2402240"
  },
  {
    "text": "Left lowest bar is NGOs these are institutes and other types of non-governmental organizations that are",
    "start": "2402240",
    "end": "2408330"
  },
  {
    "text": "not necessarily affiliated with that one any one specific University that we have",
    "start": "2408330",
    "end": "2413400"
  },
  {
    "text": "corporate papers and these are industry papers most often or the highest number is from alphabet by Google brain and",
    "start": "2413400",
    "end": "2420990"
  },
  {
    "text": "deep mind and then we have University which is on the Left which is still the",
    "start": "2420990",
    "end": "2426270"
  },
  {
    "text": "largest proportion and I only have anecdotal evidence I'm writing a scraper to try and collect all of the nips to",
    "start": "2426270",
    "end": "2432960"
  },
  {
    "text": "show this progression over time but I have anecdotal evidence dating back to 2011 and the anecdotal evidence is that",
    "start": "2432960",
    "end": "2441000"
  },
  {
    "text": "the corporate used to be less than 10% and now it's around 20",
    "start": "2441000",
    "end": "2447110"
  },
  {
    "text": "to 25% for nips and ICML and I don't think this is a bad thing I think that",
    "start": "2447110",
    "end": "2453440"
  },
  {
    "text": "industry should be publishing and I'm really happy that they're publishing a helping move the field forward and that",
    "start": "2453440",
    "end": "2458810"
  },
  {
    "text": "they're also sharing the algorithms and the architecture designs that they're working on but it will say that the",
    "start": "2458810",
    "end": "2466130"
  },
  {
    "text": "distribution let's say of different types of persons both at universities",
    "start": "2466130",
    "end": "2471230"
  },
  {
    "text": "and at these corporate entities of the people working on this problem is perhaps not representative of the",
    "start": "2471230",
    "end": "2478550"
  },
  {
    "text": "distribution of people in the world and that we have to put pressure for example",
    "start": "2478550",
    "end": "2484340"
  },
  {
    "text": "like the Google walk out yesterday we have to put pressure on the universities were involved in and the corporations",
    "start": "2484340",
    "end": "2490640"
  },
  {
    "text": "that we work for and so forth into making sure that there's representative voices rather than just some voices in",
    "start": "2490640",
    "end": "2497630"
  },
  {
    "text": "the research that we look at and how we investigate these problems over a longer period of time and so oh and today by",
    "start": "2497630",
    "end": "2509780"
  },
  {
    "text": "saying you know I had a computer and I had a problem and then I wrote a program or I wrote a machine learning model to",
    "start": "2509780",
    "end": "2516950"
  },
  {
    "text": "fix it and then I ended up with two problems right it's not have program that I have to maintain and probably the",
    "start": "2516950",
    "end": "2523550"
  },
  {
    "text": "original problem is still there and I have problems with whatever a computer",
    "start": "2523550",
    "end": "2528710"
  },
  {
    "text": "that I'm working with right and so we often try to think of machine learning as a way to solve a lot of the problems",
    "start": "2528710",
    "end": "2535250"
  },
  {
    "text": "that we work on but sometimes it creates problems that we don't anticipate and this is probably similar to any",
    "start": "2535250",
    "end": "2541280"
  },
  {
    "text": "programming experience right is that we create bugs we create errors and inconsistency and it's difficult to keep",
    "start": "2541280",
    "end": "2548600"
  },
  {
    "text": "on top of this and to continue to keep our eyes on solving the original problem that we had right in the only way that",
    "start": "2548600",
    "end": "2556190"
  },
  {
    "text": "we can do this over time is by helping hold ourselves as a community and one",
    "start": "2556190",
    "end": "2561740"
  },
  {
    "text": "another accountable and this means understanding that computers are really stupid and they're prone to do the wrong",
    "start": "2561740",
    "end": "2569540"
  },
  {
    "text": "thing they don't have inference they can't recover from error right these are all things that we have to take on as",
    "start": "2569540",
    "end": "2576760"
  },
  {
    "text": "intelligent humans and that we have to design and cold into our systems ourselves because",
    "start": "2576760",
    "end": "2582260"
  },
  {
    "text": "it's not going to just happen right and so it's our responsibility so our",
    "start": "2582260",
    "end": "2589550"
  },
  {
    "text": "responsibility as a community and we are the area experts right and so if we",
    "start": "2589550",
    "end": "2595490"
  },
  {
    "text": "don't take this on it likely similar to Latonya sweeties experience it likely won't happen right and so I wrote a",
    "start": "2595490",
    "end": "2603410"
  },
  {
    "text": "haiku this haiku is titled a haiku for from a natural intelligence to an",
    "start": "2603410",
    "end": "2610370"
  },
  {
    "text": "artificial intelligence stupid computer compounding our own",
    "start": "2610370",
    "end": "2616070"
  },
  {
    "text": "problems I thought it would help thank you very much",
    "start": "2616070",
    "end": "2621520"
  },
  {
    "text": "[Applause]",
    "start": "2621520",
    "end": "2630820"
  }
]
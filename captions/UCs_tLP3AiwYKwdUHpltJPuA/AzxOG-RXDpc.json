[
  {
    "start": "0",
    "end": "134000"
  },
  {
    "text": "thank you um good afternoon everyone I hope you uh are having a lively afternoon",
    "start": "12080",
    "end": "18560"
  },
  {
    "text": "session so far um did any of you read the brief for this talk before you",
    "start": "18560",
    "end": "23680"
  },
  {
    "text": "foolishly walked into the room and sat down um a few of you did okay well if you didn't um",
    "start": "23680",
    "end": "30519"
  },
  {
    "text": "I mentioned Taylor Swift quite heavily in the brief for this talk um I don't suppose we have any Taylor Swift fans in",
    "start": "30519",
    "end": "38360"
  },
  {
    "text": "the audience okay we've got a few proud people awesome um okay what about uh I",
    "start": "38360",
    "end": "44760"
  },
  {
    "text": "won't make this all about music what about um Oasis fans then is anybody like",
    "start": "44760",
    "end": "50039"
  },
  {
    "text": "big Oasis fan a couple people at the back wonder wall D back and anger no gallager",
    "start": "50039",
    "end": "55719"
  },
  {
    "text": "brothers okay we've got we've got a few nods a few more a few more people um",
    "start": "55719",
    "end": "61199"
  },
  {
    "text": "this talk is not all about musical tastes or more specifically what the people in this room do not like from a",
    "start": "61199",
    "end": "67240"
  },
  {
    "text": "music perspective it would seem um but what Taylor Swift and Oasis have in",
    "start": "67240",
    "end": "73000"
  },
  {
    "text": "common is that quite recently they have both either announced or been on tour",
    "start": "73000",
    "end": "79400"
  },
  {
    "text": "and these were quite literally events that generated not only a huge amount of",
    "start": "79400",
    "end": "85240"
  },
  {
    "text": "hype and Buzz about the fact that these people were touring and people were very excited about the music but these were",
    "start": "85240",
    "end": "92399"
  },
  {
    "text": "quite literal events that generated traffic and demand on it systems that",
    "start": "92399",
    "end": "98680"
  },
  {
    "text": "supported the ticket purchase process um",
    "start": "98680",
    "end": "104798"
  },
  {
    "text": "soek okay good I'm glad that Taylor Swift brought other countries to a standstill not just not just the UK um I",
    "start": "106119",
    "end": "114560"
  },
  {
    "text": "am not a Taylor Swift fan I will say this now just to set the scene I'm not",
    "start": "114560",
    "end": "120439"
  },
  {
    "text": "particularly passionate about Taylor Swift um but I am passionate about event-driven principles and how we can",
    "start": "120439",
    "end": "127439"
  },
  {
    "text": "use them to challenge some of the traditional scaling models um that we have with",
    "start": "127439",
    "end": "133120"
  },
  {
    "text": "it so a few things that I want to talk about today I do want to talk about Taylor Swift I've not just mentioned her",
    "start": "133120",
    "end": "139440"
  },
  {
    "start": "134000",
    "end": "162000"
  },
  {
    "text": "as a hook to get you in the room although for this crowd I don't think it would have worked by by by the hands up",
    "start": "139440",
    "end": "145080"
  },
  {
    "text": "at the beginning but I want to talk a little bit about Taylor Swift I also want to talk a little bit about event",
    "start": "145080",
    "end": "150720"
  },
  {
    "text": "driven scaling with kubernetes and what that means and different approaches that you might take to scaling workloads that",
    "start": "150720",
    "end": "158000"
  },
  {
    "text": "you deploy to kubernetes so to tailor then um unless",
    "start": "158000",
    "end": "164720"
  },
  {
    "start": "162000",
    "end": "976000"
  },
  {
    "text": "you have been quite literally living under a rock um Taylor Swift has very recently taken the World by storm with",
    "start": "164720",
    "end": "171800"
  },
  {
    "text": "her most recent World Tour um and it is quite literally a record-breaking World",
    "start": "171800",
    "end": "177319"
  },
  {
    "text": "Tour um it's the highest gracing tour ever um it's well over a billion dollars",
    "start": "177319",
    "end": "182599"
  },
  {
    "text": "already and they think it will reach almost 2 billion so it's been bigger than any other musical artist in our",
    "start": "182599",
    "end": "189720"
  },
  {
    "text": "lifetime that's done any sort of tour including Elton John if there's any Elton John fans here uh he did a",
    "start": "189720",
    "end": "196080"
  },
  {
    "text": "farewell tour and he did not make as much uh money as Taylor Swift did um it",
    "start": "196080",
    "end": "201360"
  },
  {
    "text": "shattered attendance record uh globally across the world um it's also resulted",
    "start": "201360",
    "end": "207480"
  },
  {
    "text": "in a 40% increase in the friendship bracelet market so if anybody is into",
    "start": "207480",
    "end": "212920"
  },
  {
    "text": "any sort of arm jewelry uh friendship bracelets are now even more popular than they were before uh solely due to a",
    "start": "212920",
    "end": "219720"
  },
  {
    "text": "lyric in a Taylor Swift song so she's had a huge impact on the friendship bracelet industry um according to the US",
    "start": "219720",
    "end": "226760"
  },
  {
    "text": "tourist board she's also added a significant amount to the economy um and",
    "start": "226760",
    "end": "231879"
  },
  {
    "text": "they estimate that's around 10 billion to the economy and that's purely due to people who have purchased tickets for",
    "start": "231879",
    "end": "238640"
  },
  {
    "text": "Taylor Swift concerts and they traveled either to other cities other countries other states and this is the money",
    "start": "238640",
    "end": "245200"
  },
  {
    "text": "that's attributed to to that so their hotels the taxis transport all of those sorts of uh fun things and uh Taylor",
    "start": "245200",
    "end": "252720"
  },
  {
    "text": "fans or swifties as they're also known I'm going to use this term throughout the talk so it's important we'll",
    "start": "252720",
    "end": "258320"
  },
  {
    "text": "Baseline the term Swifty now um they've also created an earthquake so the uh",
    "start": "258320",
    "end": "265440"
  },
  {
    "text": "jumping and dancing from Taylor Swift fans was with such Force that it actually measured uh on the RoR scale uh",
    "start": "265440",
    "end": "272520"
  },
  {
    "text": "and it actually created what can be classed or classified uh as an earthquake so this tour had a pretty big",
    "start": "272520",
    "end": "280039"
  },
  {
    "text": "impact but we knew it would have a huge impact before Taylor Swift it ever hit",
    "start": "280039",
    "end": "286479"
  },
  {
    "text": "the road um or before she sang a single note so Taylor Swift fans or swifties",
    "start": "286479",
    "end": "292600"
  },
  {
    "text": "are extremely committed and um when Taylor announced her",
    "start": "292600",
    "end": "297960"
  },
  {
    "text": "tour most ticket Merchants decided to have a dedicated fan pre-sale event that",
    "start": "297960",
    "end": "306320"
  },
  {
    "text": "fans would pre-register for um and in the case of the eras tour around three and a half million registered for Early",
    "start": "306320",
    "end": "313360"
  },
  {
    "text": "Access to Taylor Swift tickets so if we think about the it systems that are required to purchase a ticket um we've",
    "start": "313360",
    "end": "321280"
  },
  {
    "text": "got three and a half million people that that really want it so the ticket Merchants thought I don't want to deal",
    "start": "321280",
    "end": "326720"
  },
  {
    "text": "with that much traffic so what we'll do is we'll pop them into two buckets bucket one million and a half uh",
    "start": "326720",
    "end": "332600"
  },
  {
    "text": "swifties bucket two everybody else so about prox 2 million swifties so if we",
    "start": "332600",
    "end": "338160"
  },
  {
    "text": "think about this from an IT systems perspective we've got a view as to how much demand how much traffic we're",
    "start": "338160",
    "end": "343919"
  },
  {
    "text": "expecting to hit those systems so we can we can prepare ourselves now of course on the day if",
    "start": "343919",
    "end": "351560"
  },
  {
    "text": "you'd read any of the headlines um you will know that this is not what happened",
    "start": "351560",
    "end": "357479"
  },
  {
    "text": "it was not smooth sailing at all um now in fact the it systems that",
    "start": "357479",
    "end": "362960"
  },
  {
    "text": "support the ticket purchasing process actually experienced four times the amount of traffic that they ever did",
    "start": "362960",
    "end": "369400"
  },
  {
    "text": "under Peak load previously so there was a significant amount more traffic than",
    "start": "369400",
    "end": "375120"
  },
  {
    "text": "our ticket merchants and our ticket retailers um were expecting and if Taylor Swift was to try and satisfy all",
    "start": "375120",
    "end": "381960"
  },
  {
    "text": "the demand that existed for tickets for her tour she'd have to go on tour another 20 times like that that's how",
    "start": "381960",
    "end": "387520"
  },
  {
    "text": "much demand there actually was so it's unpress ented load on our it systems that support um this",
    "start": "387520",
    "end": "394880"
  },
  {
    "text": "process so could pre-scaling have have helped here so we already knew we had",
    "start": "394880",
    "end": "400080"
  },
  {
    "text": "three and a half million people interested and we'd already agreed we'd have a couple of million that we would look at you know if we'd prescaled in",
    "start": "400080",
    "end": "406919"
  },
  {
    "text": "advance could we have have handled all of this traffic um and there are some considerations to keep in mind here um",
    "start": "406919",
    "end": "413919"
  },
  {
    "text": "and the first one is that it's all it's sometimes really difficult to capture all of the inputs signals that we might",
    "start": "413919",
    "end": "420599"
  },
  {
    "text": "have when it comes to pre-scaling so in the case of toay Swift it might not just",
    "start": "420599",
    "end": "426560"
  },
  {
    "text": "be actually we've got this many people in the fan club there might be other signals there are inputs that drive",
    "start": "426560",
    "end": "435319"
  },
  {
    "text": "demand perhaps there is another event happening in the same city at the same time people are holidaying in a",
    "start": "435319",
    "end": "442280"
  },
  {
    "text": "particular location at that time and that drives demand or extra population in those locations which are going to",
    "start": "442280",
    "end": "448360"
  },
  {
    "text": "drive demand up in those particular cities um sometimes we do get our um",
    "start": "448360",
    "end": "455440"
  },
  {
    "text": "estimates around traffic wildly incorrect so prescaling is great when we",
    "start": "455440",
    "end": "460960"
  },
  {
    "text": "fully understand the demands that are going to be there but where we get them totally wrong uh that it's actually not",
    "start": "460960",
    "end": "467400"
  },
  {
    "text": "useful at all equally where we have our Taylor Swift fans who have decided to",
    "start": "467400",
    "end": "472639"
  },
  {
    "text": "get their pre-sale link and then have that link open on their laptop on their",
    "start": "472639",
    "end": "477840"
  },
  {
    "text": "tablet on their phone they've shared it with Mom and Dad because they also want mom and dad to try and get tickets",
    "start": "477840",
    "end": "483120"
  },
  {
    "text": "they've shared it in their WhatsApp group and all their friends are all going to share that link and everybody's logging on at the same time so actually",
    "start": "483120",
    "end": "490159"
  },
  {
    "text": "very quickly our one and a half million fans turn into millions and millions and",
    "start": "490159",
    "end": "496199"
  },
  {
    "text": "millions of session requests to purchase tickets where we also have it systems in",
    "start": "496199",
    "end": "502800"
  },
  {
    "text": "that Journey that are I don't know slightly monolithic in nature and and",
    "start": "502800",
    "end": "507919"
  },
  {
    "text": "tightly coupled we might be able to scale one part but where we've got one part that doesn't scale so well that",
    "start": "507919",
    "end": "514159"
  },
  {
    "text": "part is going to bring everybody down and it's important to note that there are lots of dependent systems in the",
    "start": "514159",
    "end": "519839"
  },
  {
    "text": "journey from a ticket purchase perspective it's not just our ticket retailer or our ticket Merchant there",
    "start": "519839",
    "end": "525680"
  },
  {
    "text": "are other Downstream systems that also all need to be uh playing ball and all",
    "start": "525680",
    "end": "531360"
  },
  {
    "text": "need to be scaling in line with the amount of demand that's going to hit so pre-scaling is great where it's really",
    "start": "531360",
    "end": "537680"
  },
  {
    "text": "well understood in terms of the demand you're going to have where you've got the architecture to support it and where",
    "start": "537680",
    "end": "543440"
  },
  {
    "text": "your Downstream systems or your dependencies again are also well understood and can scale with",
    "start": "543440",
    "end": "549079"
  },
  {
    "text": "you um but if we think about our Taylor Swift fans and the challenges that they",
    "start": "549079",
    "end": "554200"
  },
  {
    "text": "encountered on the day when they wanted to purchase a ticket so challenge one was even getting into the waiting room",
    "start": "554200",
    "end": "560800"
  },
  {
    "text": "and and getting access um but challenge two once ticket fans had added a ticket",
    "start": "560800",
    "end": "567720"
  },
  {
    "text": "to their basket and they going through the purchase process for those particular tickets what they were seeing",
    "start": "567720",
    "end": "573760"
  },
  {
    "text": "was a little pay now click on it and a little spining icon and then all of a sudden their transaction would time up",
    "start": "573760",
    "end": "580480"
  },
  {
    "text": "so worst thing in the world they were so close but yet they still didn't manage to get their tickets um and this part of",
    "start": "580480",
    "end": "587959"
  },
  {
    "text": "the ticket purchase Journey if you like isn't really something that's solely dependent on our ticket Merchant there",
    "start": "587959",
    "end": "594279"
  },
  {
    "text": "are a load of other Downstream systems that help support this this payment Journey",
    "start": "594279",
    "end": "599480"
  },
  {
    "text": "so if we think about that payment journey and let's break down the people that are in it so we have our ticket purchases or our swifties in this case",
    "start": "599480",
    "end": "606519"
  },
  {
    "text": "um we have the uh the card issuing bank so the bank that the swifties use uh",
    "start": "606519",
    "end": "611640"
  },
  {
    "text": "Bank of Taylor whatever you want to call it these are the people that have given them a credit card or a debit card um we",
    "start": "611640",
    "end": "617800"
  },
  {
    "text": "then have our ticket Merchant the person that's selling our Taylor Swift tickets uh and then we have our our Merchant",
    "start": "617800",
    "end": "623680"
  },
  {
    "text": "acquiring bank now this is a really important entity in the chain um because it's our Merchant AC quiring bank that's",
    "start": "623680",
    "end": "630360"
  },
  {
    "text": "authorized by the likes of visa and MasterCard to actually go and collect",
    "start": "630360",
    "end": "635839"
  },
  {
    "text": "the money on behalf of the ticket Merchant now if we think about demand",
    "start": "635839",
    "end": "641120"
  },
  {
    "text": "for Taylor Swift tickets our ticket Merchants are going to know that there's millions of swifties out there that",
    "start": "641120",
    "end": "647000"
  },
  {
    "text": "really want to buy tickets our Merchant acquiring bank is a separate entity in this chain they're not going to have",
    "start": "647000",
    "end": "652839"
  },
  {
    "text": "visibility of the number of people that have signed up for pre-sale and there are a bank they probably don't care um",
    "start": "652839",
    "end": "660120"
  },
  {
    "text": "they probably don't care about Taylor Swift demand because they're thinking we handle billions and billions of",
    "start": "660120",
    "end": "665240"
  },
  {
    "text": "transactions every day per seconds we are scaled um to to handle this",
    "start": "665240",
    "end": "671240"
  },
  {
    "text": "necessary um necessary demand we have our scaling metrics in",
    "start": "671240",
    "end": "677079"
  },
  {
    "text": "place so if we think about how a uh merchant services architecture might be",
    "start": "677880",
    "end": "684360"
  },
  {
    "text": "deployed um in the cloud um so I'm just going to map out here our different actors in The Chain so we have our",
    "start": "684360",
    "end": "690600"
  },
  {
    "text": "swifties we have our ticket Merchant um we have our card issuer um",
    "start": "690600",
    "end": "695760"
  },
  {
    "text": "sorry this screen's really high so it's really difficult for me to see um we have our card issuer our payment",
    "start": "695760",
    "end": "701000"
  },
  {
    "text": "networks and then our Merchant acquiring bank so our swifties decide they want to",
    "start": "701000",
    "end": "706360"
  },
  {
    "text": "purchase a ticket add to basket enter their credit card de details click pay now um so that request goes to our",
    "start": "706360",
    "end": "714320"
  },
  {
    "text": "ticket Merchant to say I want to pay this amount of money um now if anybody is familiar with the Taylor Swift ticket",
    "start": "714320",
    "end": "720320"
  },
  {
    "text": "Saga they were significantly more expensive than $100 but you know let's just for the sake of argument $100 so",
    "start": "720320",
    "end": "727399"
  },
  {
    "text": "they communicate with our ticket Merchant who then sends a request uh to our Merchant acquiring Bank to say hey",
    "start": "727399",
    "end": "734800"
  },
  {
    "text": "you're authorized on behalf of Visa or MasterCard to go and go and get this money for me so please do so our",
    "start": "734800",
    "end": "740880"
  },
  {
    "text": "Merchant acquiring Bank gets that request from our ticket Merchant um and what they do is um that particular",
    "start": "740880",
    "end": "746920"
  },
  {
    "text": "request generates an event and they keep event in some sort of uh event stream uh",
    "start": "746920",
    "end": "752240"
  },
  {
    "text": "in this case we're implementing this in AWS so we've decided to use some sort of event broker um we might use something",
    "start": "752240",
    "end": "758639"
  },
  {
    "text": "like um Kinesis or we might use something else um but we're storing that event in some sort of event",
    "start": "758639",
    "end": "764399"
  },
  {
    "text": "stream um the acquiring bank will then communicate over the payment networks uh",
    "start": "764399",
    "end": "769720"
  },
  {
    "text": "back to the card issuing Bank to say hey has this Swifty fan got enough money in their bank account for this particular",
    "start": "769720",
    "end": "776279"
  },
  {
    "text": "transaction um they will then send a message back to say yes yes they do uh",
    "start": "776279",
    "end": "783040"
  },
  {
    "text": "that again is another event that's stored in our event stream um our acquiring bank then gets in contact with",
    "start": "783040",
    "end": "789279"
  },
  {
    "text": "our ticket Merchant and says yep all good to go and then lovely jly Taylor",
    "start": "789279",
    "end": "794639"
  },
  {
    "text": "Swift fans get that congratulations screen with their reference payment uh with their reference number for their",
    "start": "794639",
    "end": "800079"
  },
  {
    "text": "ticket transaction brilliant they've got their ticket um and behind the scenes a clearing and settlement process kicks",
    "start": "800079",
    "end": "807040"
  },
  {
    "text": "off between all of the different payment enti to make sure all the necessary Ledges are updated with these amounts um so our",
    "start": "807040",
    "end": "814920"
  },
  {
    "text": "uh ticket Merchant will then get in touch with their acquiring bank again and say great let's let's have the money",
    "start": "814920",
    "end": "820519"
  },
  {
    "text": "please again more events in our event stream um there is then a clearing and settlement um process that goes on where",
    "start": "820519",
    "end": "828399"
  },
  {
    "text": "various messages passed between um the card issuing Bank The Merchant Bank over",
    "start": "828399",
    "end": "834440"
  },
  {
    "text": "the payment networks um to get the amount um you'll notice uh that the",
    "start": "834440",
    "end": "839839"
  },
  {
    "text": "amount that actually goes back to our um um back to our acquiring bank is is not",
    "start": "839839",
    "end": "845040"
  },
  {
    "text": "the $100 uh because it's less uh transaction fees so just trying to map out a real world example here um but all",
    "start": "845040",
    "end": "852000"
  },
  {
    "text": "of these events are stored in our in our event stream um but in this particular",
    "start": "852000",
    "end": "857160"
  },
  {
    "text": "scenario everybody's communicated successfully together and our Swifty fans have got their tickets which is",
    "start": "857160",
    "end": "862759"
  },
  {
    "text": "great news um for them but this particular example um what we're trying to do is trying to break up",
    "start": "862759",
    "end": "870839"
  },
  {
    "text": "the different steps in the journey and have these event responsive or event",
    "start": "870839",
    "end": "876079"
  },
  {
    "text": "driven steps that happen in our payment journey and you'll notice um that we",
    "start": "876079",
    "end": "881199"
  },
  {
    "text": "have a little uh Amazon eks symbol under our Merchant acquiring bank so for these particular payment settlement and",
    "start": "881199",
    "end": "887320"
  },
  {
    "text": "clearing systems we want to containerize them and we want to deploy them onto",
    "start": "887320",
    "end": "893240"
  },
  {
    "text": "kubernetes but before we jump into the kubernetes setup and what that looks like um I just want to discuss a little",
    "start": "893240",
    "end": "898839"
  },
  {
    "text": "bit bit what scaling on kubernetes actually means in the different scaling Dimensions when you have a solution",
    "start": "898839",
    "end": "904839"
  },
  {
    "text": "that's deployed to kubernetes so just to Baseline some of the components um",
    "start": "904839",
    "end": "909880"
  },
  {
    "text": "kubernetes control plane so that's our kubernetes API server our scheduler etcd",
    "start": "909880",
    "end": "916240"
  },
  {
    "text": "um if you're using Amazon eks which is our elastic kubernetes service um we're going to manage this component for you",
    "start": "916240",
    "end": "923000"
  },
  {
    "text": "from a scaling perspective so you don't need to worry about that um our kubernetes data plane these are our",
    "start": "923000",
    "end": "929000"
  },
  {
    "text": "worker nodes or the compute that actually runs your containers so think of this as like uh ec2 instances and",
    "start": "929000",
    "end": "936959"
  },
  {
    "text": "storage volumes and then we have um our cluster services on top so these are all",
    "start": "936959",
    "end": "943519"
  },
  {
    "text": "of those add-ons and extensions that you deploy onto your cluster that extend some sort of capability to your workload",
    "start": "943519",
    "end": "950639"
  },
  {
    "text": "so something like I don't know C CNS something like that for example and then",
    "start": "950639",
    "end": "956040"
  },
  {
    "text": "finally we have your workloads themselves um in our particular scenario",
    "start": "956040",
    "end": "961079"
  },
  {
    "text": "we are particularly interested in how we can scale our workloads so our workloads",
    "start": "961079",
    "end": "966680"
  },
  {
    "text": "being our payment workloads that are going to grab the payment and how can we scale our data plane or our compute",
    "start": "966680",
    "end": "972720"
  },
  {
    "text": "which is going to run those particular workloads um and when it comes to scaling our particular workloads there",
    "start": "972720",
    "end": "979399"
  },
  {
    "start": "976000",
    "end": "1110000"
  },
  {
    "text": "are a few different approaches that that we can take in kubernetes um but they're",
    "start": "979399",
    "end": "984440"
  },
  {
    "text": "really um all I suppose concerned with how we can either a have more instances",
    "start": "984440",
    "end": "991399"
  },
  {
    "text": "of your containerized workload so horizontally scaled with the logic being",
    "start": "991399",
    "end": "996639"
  },
  {
    "text": "the more instances I have of my container the more work it can do or B",
    "start": "996639",
    "end": "1002519"
  },
  {
    "text": "how can I give more resource to my container again the logic being the more compute and resource it's got to access",
    "start": "1002519",
    "end": "1009800"
  },
  {
    "text": "again the more work it can do and there are three scaling approaches there horizontal pod autoscaler vertical pod",
    "start": "1009800",
    "end": "1016519"
  },
  {
    "text": "Auto scaler and then kubernetes EV ENT an autoscaling orca once you've scaled your",
    "start": "1016519",
    "end": "1023440"
  },
  {
    "text": "applications or scaled your containers you need somewhere for them to run so that compute or that data plane um and",
    "start": "1023440",
    "end": "1029438"
  },
  {
    "text": "there are two primary approaches we see customers using when they're using Amazon eks for their kubernetes clusters",
    "start": "1029439",
    "end": "1036480"
  },
  {
    "text": "and that is cluster autoscaler and then Carpenter let's have a look at",
    "start": "1036480",
    "end": "1041640"
  },
  {
    "text": "application scaling first so horizontal P AO scaler so this is entirely",
    "start": "1041640",
    "end": "1046959"
  },
  {
    "text": "concerned with how can I increase inre the number of instances I have of my containerized application so it um Works",
    "start": "1046959",
    "end": "1055400"
  },
  {
    "text": "in conjunction with the kubernetes metric server and it looks at uh Telemetry data such as CPU and memory",
    "start": "1055400",
    "end": "1063480"
  },
  {
    "text": "and based on a deployment definition that you have for your workload it will make a decision uh do you need more",
    "start": "1063480",
    "end": "1069760"
  },
  {
    "text": "instances of that particular workload at that point it makes a request and then the kubernetes scheduler will then",
    "start": "1069760",
    "end": "1076039"
  },
  {
    "text": "schedule more instances of your workload and that essentially it looks like more replicas that run of your workload on",
    "start": "1076039",
    "end": "1082840"
  },
  {
    "text": "your cluster vertical pod autoscaler Works in a very similar way again in conjunction",
    "start": "1082840",
    "end": "1088679"
  },
  {
    "text": "with our kubernetes metric server but rather than having more replicas or more instances of your workload it simply",
    "start": "1088679",
    "end": "1095600"
  },
  {
    "text": "increases the CPU and memory so it gives it gives it more juice if you",
    "start": "1095600",
    "end": "1100640"
  },
  {
    "text": "like kadada or uh kubernetes event driven autoscaling Works ever so",
    "start": "1100640",
    "end": "1106200"
  },
  {
    "text": "slightly um differently",
    "start": "1106200",
    "end": "1110360"
  },
  {
    "start": "1110000",
    "end": "1577000"
  },
  {
    "text": "so kada works as a replacement so to speak for the kubernetes metric server",
    "start": "1111799",
    "end": "1117919"
  },
  {
    "text": "so whereas our kubernetes metric server is feeding Telemetry data like CPU and memory Kor is going to be feed feeding",
    "start": "1117919",
    "end": "1124960"
  },
  {
    "text": "really rich event driven data um so kada has a number of um Integrations or hooks",
    "start": "1124960",
    "end": "1133280"
  },
  {
    "text": "into some of the most popular integration tooling that's out there many of which you would have heard about",
    "start": "1133280",
    "end": "1138360"
  },
  {
    "text": "today things like CFA for example sqs um and what kada will do is it will",
    "start": "1138360",
    "end": "1146360"
  },
  {
    "text": "expose metrics about these different integration services to our kubernetes",
    "start": "1146360",
    "end": "1151440"
  },
  {
    "text": "scalers to allow us to scale our workloads based on some event",
    "start": "1151440",
    "end": "1157158"
  },
  {
    "text": "data and how this works is by using what we call a scaled object think of this as",
    "start": "1158200",
    "end": "1164919"
  },
  {
    "text": "just like a configuration if you like for kadada um and then what we have are these things called scalers and scalers",
    "start": "1164919",
    "end": "1172039"
  },
  {
    "text": "will actually go and look at a given uh event technology so let's say you're",
    "start": "1172039",
    "end": "1177320"
  },
  {
    "text": "using something like sqs or cafer or whatever um your scaler will go and look at that event um look at that um event",
    "start": "1177320",
    "end": "1185400"
  },
  {
    "text": "technology um we then have our metrics adapter and the metrics adapter is going to grab data Telemetry about that",
    "start": "1185400",
    "end": "1193120"
  },
  {
    "text": "particular event implementation and convert it into a format that kubernetes can understand and then our controller",
    "start": "1193120",
    "end": "1199919"
  },
  {
    "text": "will then act upon that and then feed information to our horizontal pod autoscaler and what this means is that",
    "start": "1199919",
    "end": "1206919"
  },
  {
    "text": "kada can pick up information about say a CFA topic or a Q and it can say ah I've",
    "start": "1206919",
    "end": "1214200"
  },
  {
    "text": "got a message in my queue that's a scalable event that I want to do something on and it converts that into a",
    "start": "1214200",
    "end": "1220039"
  },
  {
    "text": "form that horizontal pod autoscaler can act on um I've got some configuration",
    "start": "1220039",
    "end": "1227360"
  },
  {
    "text": "examples now of P just to really demonstrate um I suppose what what it",
    "start": "1227360",
    "end": "1232760"
  },
  {
    "text": "actually what it actually looks like and I hope you can see it this screen's a little high but I I'll sort talk you through what we've got here um so this",
    "start": "1232760",
    "end": "1239159"
  },
  {
    "text": "particular configuration um is for sqs so this is basically saying I want to",
    "start": "1239159",
    "end": "1244640"
  },
  {
    "text": "Scale based on some information about sqs so messages in my q and what we can",
    "start": "1244640",
    "end": "1250760"
  },
  {
    "text": "Define here are polling intervals how often I want to poll my queue to see if",
    "start": "1250760",
    "end": "1256039"
  },
  {
    "text": "there's messages in there we can Define what we want to happen if the queue is empty so for if we think about our um",
    "start": "1256039",
    "end": "1264880"
  },
  {
    "text": "payment architecture for our tail of Swift fans buying some tickets um we really want to scale up the number of uh",
    "start": "1264880",
    "end": "1272279"
  },
  {
    "text": "workloads that can handle clearing and settlement when there's lots of Taylor Swift fans putting pay now messages in",
    "start": "1272279",
    "end": "1277679"
  },
  {
    "text": "the queue but when they've all finished um actually we would quite like to scale that down to zero because otherwise it's",
    "start": "1277679",
    "end": "1283480"
  },
  {
    "text": "workloads that are running that we're paying for that aren't doing anything um I can also Define exactly",
    "start": "1283480",
    "end": "1289200"
  },
  {
    "text": "the URLs of the uh endpoints that I want to use so if you have lots of different cues lots of different q names you can",
    "start": "1289200",
    "end": "1295960"
  },
  {
    "text": "also uh do that here um equally if you do have um an",
    "start": "1295960",
    "end": "1303919"
  },
  {
    "text": "event um that you know in advance um you can pre-scale with kadada it doesn't",
    "start": "1303919",
    "end": "1309480"
  },
  {
    "text": "always have to be responsive based on messages in AQ you can also still scale",
    "start": "1309480",
    "end": "1314880"
  },
  {
    "text": "on schedule so if you know you have Peaks for your systems throughout the day you can still scale on a schedule um",
    "start": "1314880",
    "end": "1322120"
  },
  {
    "text": "using the information that you have about your end users and how they use your it systems you don't just have to",
    "start": "1322120",
    "end": "1327760"
  },
  {
    "text": "be entirely uh responsive the whole time um so that's that's great to scale",
    "start": "1327760",
    "end": "1333480"
  },
  {
    "text": "your workload so rather than scaling based on CPU and memory we now know that",
    "start": "1333480",
    "end": "1338720"
  },
  {
    "text": "we could Scale based on messages in a queue and those messages could be Taylor Swift fans saying pay now pay now pay",
    "start": "1338720",
    "end": "1344720"
  },
  {
    "text": "now pay now and that's what we want to scale under um which is great as I'm scaling my payment workload but not so",
    "start": "1344720",
    "end": "1351480"
  },
  {
    "text": "great if I don't have sufficient compute in my cluster to actually run all of those payment workloads um so that's",
    "start": "1351480",
    "end": "1358760"
  },
  {
    "text": "where we need to look at data plane scaling um and uh as I mentioned there are two approaches that we see customers",
    "start": "1358760",
    "end": "1364880"
  },
  {
    "text": "using for data plane scaling for kubernetes um the first is cluster autoscaler and the second is Carpenter",
    "start": "1364880",
    "end": "1372559"
  },
  {
    "text": "um so Carpenter is relatively new um it was something that uh we developed uh inhouse in AWS",
    "start": "1372559",
    "end": "1378960"
  },
  {
    "text": "um it's fully open source and we contributed it back to the cncf at the end of last year um so it's now a",
    "start": "1378960",
    "end": "1385640"
  },
  {
    "text": "graduated Sig autoscaling project um V1 so all its apis officially baselined um",
    "start": "1385640",
    "end": "1392840"
  },
  {
    "text": "happened about oh about six to eight weeks ago is um Carpenter is what we",
    "start": "1392840",
    "end": "1397919"
  },
  {
    "text": "like to think of as as application Centric scaling um so Carpenter will add",
    "start": "1397919",
    "end": "1402960"
  },
  {
    "text": "compute into your kubernetes cluster based on what your application needs not necessarily based on what you've defined",
    "start": "1402960",
    "end": "1410720"
  },
  {
    "text": "as a compute configuration so it's specifically looking at what your application needs um and I'll explain",
    "start": "1410720",
    "end": "1416480"
  },
  {
    "text": "what that means now um but before I do that I just want to Baseline how cluster",
    "start": "1416480",
    "end": "1421520"
  },
  {
    "text": "autoscaler works because we typically explain Carpenter by comparing it with cluster autoscaler so it's always nice",
    "start": "1421520",
    "end": "1428520"
  },
  {
    "text": "just to just to talk about how that works a little bit so let's imagine we've had um uh something that's either",
    "start": "1428520",
    "end": "1435760"
  },
  {
    "text": "a caused our CPU in memory to increase of our work workload or we've had a cader event um and that's fed into our",
    "start": "1435760",
    "end": "1443200"
  },
  {
    "text": "horizontal pod Auto Scala so we now need more replicas of our",
    "start": "1443200",
    "end": "1448480"
  },
  {
    "text": "workload kubernetes scheduler will attempt to schedule those workloads somewhere in the cluster um and if there",
    "start": "1448480",
    "end": "1455279"
  },
  {
    "text": "is insufficient compute in the cluster those workloads will be unschedulable where we have customers",
    "start": "1455279",
    "end": "1461720"
  },
  {
    "text": "who are using cluster autoscaler um they typically use that alongside uh manage no groups which is kind of",
    "start": "1461720",
    "end": "1468559"
  },
  {
    "text": "configurations for like or similar um compute in AWS um so when you've got your",
    "start": "1468559",
    "end": "1474760"
  },
  {
    "text": "unschedulable pods cluster autoscaler kicks in and it will pick a manage node group um to expand and under the covers",
    "start": "1474760",
    "end": "1482760"
  },
  {
    "text": "of a manage node group is essentially an autoscaling group so it will scale up some ec2 instances super easy where",
    "start": "1482760",
    "end": "1489640"
  },
  {
    "text": "there's only one manage node group if you have many manage node groups which some of our customers do um it's a bit",
    "start": "1489640",
    "end": "1497000"
  },
  {
    "text": "tricky then for cluster autoscaler to know which node group to pick um and",
    "start": "1497000",
    "end": "1502440"
  },
  {
    "text": "there's a concept of expanders where you can give cluster autoscaler some hints and say pick this node group over this",
    "start": "1502440",
    "end": "1508440"
  },
  {
    "text": "one but essentially cluster autoscaler is making that decision some of the limitations that customers have raised",
    "start": "1508440",
    "end": "1514919"
  },
  {
    "text": "to us about managed node groups are that they're very set in terms of the compute that's in there so you have one managed",
    "start": "1514919",
    "end": "1521120"
  },
  {
    "text": "node group per type of ec2 instance compute that you want to use so say you",
    "start": "1521120",
    "end": "1526200"
  },
  {
    "text": "want to use I don't know uh an M5 2XL you'll have one node group for that",
    "start": "1526200",
    "end": "1532480"
  },
  {
    "text": "configuration and then maybe if you want to use um uh a memory optim another",
    "start": "1532480",
    "end": "1537880"
  },
  {
    "text": "memory optimized instance or something else you'll have to have a different node group for that configuration and what customers found is that they just",
    "start": "1537880",
    "end": "1544600"
  },
  {
    "text": "had lots and lots of node groups and this was then doubled when they wanted to use things like a mix of spot and On",
    "start": "1544600",
    "end": "1551159"
  },
  {
    "text": "Demand um so it became a lot of of overhead to manage and it was also a",
    "start": "1551159",
    "end": "1556559"
  },
  {
    "text": "real pain when workloads were deployed to the cluster and they needed something",
    "start": "1556559",
    "end": "1562279"
  },
  {
    "text": "which was not being served by the manage node group so perfect example is you deploy a workload and it needs a GPU and",
    "start": "1562279",
    "end": "1569720"
  },
  {
    "text": "you don't have a manage node group configuration for a GPU that workload is just not going to get scheduled and it's going to fail um so that's kind of where",
    "start": "1569720",
    "end": "1576880"
  },
  {
    "text": "Carpenter really steps in so if we think about our cluster autoscaler workflow um",
    "start": "1576880",
    "end": "1583640"
  },
  {
    "start": "1577000",
    "end": "1967000"
  },
  {
    "text": "we have um our pods which will Auto scale through our horizontal pod Auto aut scaler um we have our pending pods",
    "start": "1583640",
    "end": "1591559"
  },
  {
    "text": "kubernetes attempts to schedule them can't cluster autoscaler kicks in invokes the autoscaling group adds more",
    "start": "1591559",
    "end": "1598559"
  },
  {
    "text": "compute in the carpenter World Carpenter is still listening to events that happen",
    "start": "1598559",
    "end": "1603960"
  },
  {
    "text": "on the cluster so it's it's a deployment to the cluster it's continually listening for those unschedulable pod",
    "start": "1603960",
    "end": "1610720"
  },
  {
    "text": "events and when they crop up Carpenter will then kick in and say great I need",
    "start": "1610720",
    "end": "1615880"
  },
  {
    "text": "to do something I need to scale the compute in this cluster and what it does is it looks at all of the unschedulable",
    "start": "1615880",
    "end": "1623000"
  },
  {
    "text": "pods it bin packs the amount of CPU and memory that those pods need into kind of",
    "start": "1623000",
    "end": "1629600"
  },
  {
    "text": "one two uh metrics and then it makes a decision about the right type of ec2 to",
    "start": "1629600",
    "end": "1637720"
  },
  {
    "text": "pick in order for those workloads to be scheduled um and it does this using two strategies um so if you want to use on",
    "start": "1637720",
    "end": "1645600"
  },
  {
    "text": "demand compute it will pick the cheapest eect instance if you want to use uh",
    "start": "1645600",
    "end": "1650679"
  },
  {
    "text": "Amazon ec2 spot instances it uses something called a price capacity",
    "start": "1650679",
    "end": "1656279"
  },
  {
    "text": "optimized strategy whereby it looks at the spot pole which is biggest and then the one that that's cheapest uh and then",
    "start": "1656279",
    "end": "1663480"
  },
  {
    "text": "what it does is it communicates with our um eect Fleet API um and this is a",
    "start": "1663480",
    "end": "1668799"
  },
  {
    "text": "synchronous call that it makes so it gets an instant response back um our cluster autoscaler using autoscaling",
    "start": "1668799",
    "end": "1675399"
  },
  {
    "text": "groups makes a call just to our regular ec2a and this is an async call um we",
    "start": "1675399",
    "end": "1681519"
  },
  {
    "text": "haven't done any benchmarking on the times in terms of response times um but we do have uh some of our AWS Heroes",
    "start": "1681519",
    "end": "1689279"
  },
  {
    "text": "that have and there is a Blog that exists um definitely go and have a look for it uh but one of our container",
    "start": "1689279",
    "end": "1695919"
  },
  {
    "text": "Heroes uh did a a benchmarking exercise trying to scale to 10,000 pods and",
    "start": "1695919",
    "end": "1702240"
  },
  {
    "text": "comparing all of the different scaling mechanisms and uh and did find that there was a performance Improvement in",
    "start": "1702240",
    "end": "1707880"
  },
  {
    "text": "terms terms of scaling to 10,000 when using Carpenter over cluster autoscaler",
    "start": "1707880",
    "end": "1713039"
  },
  {
    "text": "with manage node groups so if if you're thinking about it definitely a benchmarking that you should uh you should uh be aware of um so Carpenter",
    "start": "1713039",
    "end": "1721440"
  },
  {
    "text": "basically makes that decision of what compute to add into your cluster um but you can still give Carpenter some",
    "start": "1721440",
    "end": "1727640"
  },
  {
    "text": "guidance uh we have a concept of a node provisioner template where you can tell",
    "start": "1727640",
    "end": "1734760"
  },
  {
    "text": "Carpenter um for example don't pick bare metal instances or don't pick T2",
    "start": "1734760",
    "end": "1742000"
  },
  {
    "text": "micros um to give Carpenter some guidance about what to pick equally you can give Carpenter some further guidance",
    "start": "1742000",
    "end": "1748360"
  },
  {
    "text": "that says when you do spin up an ec2 instance make sure it's labeled in this",
    "start": "1748360",
    "end": "1753480"
  },
  {
    "text": "particular way make sure it uses this API uh Ami Etc and you can do that with",
    "start": "1753480",
    "end": "1758559"
  },
  {
    "text": "a node class template um and what this allows you to do is it allows you to move towards um",
    "start": "1758559",
    "end": "1766679"
  },
  {
    "text": "compute that's driven by your workload so you're not going to spin up an ec2 instance that's based on a static ec2",
    "start": "1766679",
    "end": "1773640"
  },
  {
    "text": "config you're now looking at what your workload wants so say you have 10 unschedulable pods you're going to spin",
    "start": "1773640",
    "end": "1779880"
  },
  {
    "text": "up an ec2 that works for those pods maybe not just an ec2 that's defined by",
    "start": "1779880",
    "end": "1785000"
  },
  {
    "text": "your configuration and it means that this means you can be a lot more flexible with the type of compute that",
    "start": "1785000",
    "end": "1790200"
  },
  {
    "text": "you have in your cluster and if cost is really important to you Carpenter uses a",
    "start": "1790200",
    "end": "1795519"
  },
  {
    "text": "bunch of different cost optimization strategies to be able to pick the the cheapest",
    "start": "1795519",
    "end": "1800760"
  },
  {
    "text": "ECT um and there are a couple of different strategies that Carpenter can use in order to to pick the right",
    "start": "1800760",
    "end": "1806640"
  },
  {
    "text": "instance um but I just want to step you through I guess uh the carpenter config and and and what it looks like um so in",
    "start": "1806640",
    "end": "1814880"
  },
  {
    "text": "this particular example um we can tell Carpenter which type of ec2 instances we",
    "start": "1814880",
    "end": "1821600"
  },
  {
    "text": "do and don't want it to select from when it makes a decision because Carpenters considering our whole ec2 um",
    "start": "1821600",
    "end": "1829399"
  },
  {
    "text": "availability what so that's like uh over I think the last count was over 700 different uh options that you have so",
    "start": "1829399",
    "end": "1836679"
  },
  {
    "text": "carpenter has all those 700 to pick from and this is a great way to give it a bit of a steer as to which one um another",
    "start": "1836679",
    "end": "1843159"
  },
  {
    "text": "thing I want to draw your attention to is the config right at the bottom which is a CPU limit so Carpenter no longer",
    "start": "1843159",
    "end": "1850120"
  },
  {
    "text": "wants to think about your kubernetes data plane in terms of the number of",
    "start": "1850120",
    "end": "1855159"
  },
  {
    "text": "nodes it wants to think about it in terms of the number of CPUs that your workloads need so Carpenter doesn't care",
    "start": "1855159",
    "end": "1862720"
  },
  {
    "text": "if you have one node or 10 nodes as long as you have the number of CPUs that your workloads need it's it's happy and it's",
    "start": "1862720",
    "end": "1870120"
  },
  {
    "text": "satisfied and what we're trying to Trend towards here I suppose is is Shifting that mindset from my compute layer is a",
    "start": "1870120",
    "end": "1877240"
  },
  {
    "text": "set number of ec2 instances and we want to shift towards our compute layer is",
    "start": "1877240",
    "end": "1882840"
  },
  {
    "text": "this much CPU and memory for my workload and really be workload driven um when",
    "start": "1882840",
    "end": "1887919"
  },
  {
    "text": "we're thinking about it um we can also tell Carpenter about things like availability zones to make",
    "start": "1887919",
    "end": "1893799"
  },
  {
    "text": "sure you're keeping in mind best practices around architecting for resiliency um equally we can tell",
    "start": "1893799",
    "end": "1900960"
  },
  {
    "text": "Carpenter if we want to do things like use different types of architecture types whether you want to use Intel",
    "start": "1900960",
    "end": "1907080"
  },
  {
    "text": "whether you want to use graviton whether you want to use something else you can tell tell Carpenter to do that um",
    "start": "1907080",
    "end": "1912919"
  },
  {
    "text": "equally you can also specify if you want to use Spot On Demand instances or or",
    "start": "1912919",
    "end": "1917960"
  },
  {
    "text": "both if you're thinking about your different purchase options so it's a super um easy read in terms of the",
    "start": "1917960",
    "end": "1924720"
  },
  {
    "text": "configuration um but it's a different way to think about scaling um your data plane and not necessarily just scaling",
    "start": "1924720",
    "end": "1930919"
  },
  {
    "text": "your kubernetes data plane based on like a a static config so we have a really",
    "start": "1930919",
    "end": "1936039"
  },
  {
    "text": "cool example uh on our GitHub page which uh will allow you to create a kubernetes",
    "start": "1936039",
    "end": "1941799"
  },
  {
    "text": "cluster using Amazon eks with Carpenter and cader set up and configured on it um",
    "start": "1941799",
    "end": "1949559"
  },
  {
    "text": "so there is a link to our GitHub repo there's some a nice readme file it will",
    "start": "1949559",
    "end": "1955200"
  },
  {
    "text": "step you through how to set it up so if you're interested in what that architecture could look like um here's a",
    "start": "1955200",
    "end": "1962159"
  },
  {
    "text": "here's a really good example um but let's bring this now back",
    "start": "1962159",
    "end": "1967799"
  },
  {
    "start": "1967000",
    "end": "2208000"
  },
  {
    "text": "to Taylor Swift so we've had a few minutes now where we haven't mentioned Taylor or our very sad swifties who who",
    "start": "1967799",
    "end": "1974679"
  },
  {
    "text": "weren't able to actually make uh their payment transaction ction when they were buying tickets um so how does any of",
    "start": "1974679",
    "end": "1981000"
  },
  {
    "text": "this actually help our Taylor Swift problem um so let's think about our fans we've got our fans and they really want",
    "start": "1981000",
    "end": "1988440"
  },
  {
    "text": "to um change their lives uh by buying some tickets and the way they want to do",
    "start": "1988440",
    "end": "1994080"
  },
  {
    "text": "that is with a credit card transaction um so really what we want to",
    "start": "1994080",
    "end": "1999279"
  },
  {
    "text": "happen is our credit card transaction systems and all of those dependent systems that we saw in that chain",
    "start": "1999279",
    "end": "2005200"
  },
  {
    "text": "earlier on um we want those systems to actually Scale based on the Taylor Swift",
    "start": "2005200",
    "end": "2011120"
  },
  {
    "text": "demand we don't want those systems really to scale on CPU and memory we want them to Scale based on the number",
    "start": "2011120",
    "end": "2016960"
  },
  {
    "text": "of Taylor Swift lands that have clicked pay now and and given their information in and and we now know that CER is a way",
    "start": "2016960",
    "end": "2024360"
  },
  {
    "text": "to do that we now know that if we have an event stream uh with lots of different events in cader is one way",
    "start": "2024360",
    "end": "2031039"
  },
  {
    "text": "that we can read information from that event stream and Scale based on it so cader is a key part of our solution here",
    "start": "2031039",
    "end": "2039399"
  },
  {
    "text": "um so what does this actually look like in practice now I do apologize this diagram is a little little fiddly um so",
    "start": "2039399",
    "end": "2046799"
  },
  {
    "text": "let's think about our our Taylor Swift fans so our Taylor Swift fan is uh right at the top on the left hand side of this",
    "start": "2046799",
    "end": "2052878"
  },
  {
    "text": "slide making a credit card transaction um so the credit card transaction message uh has gone into the queue and",
    "start": "2052879",
    "end": "2059679"
  },
  {
    "text": "we have our workloads that are deployed to kubernetes that are processing that message and then persisting some data",
    "start": "2059679",
    "end": "2066878"
  },
  {
    "text": "somewhere and communicating with our Merchant Bank um to say you know let's let's make this particular",
    "start": "2066879",
    "end": "2073679"
  },
  {
    "text": "transaction um but let's imagine we don't just have one Tailor Swift fan anymore um we have four or in the case",
    "start": "2073679",
    "end": "2080560"
  },
  {
    "text": "of uh our problem four times the amount of peak traffic um so think of this as",
    "start": "2080560",
    "end": "2086240"
  },
  {
    "text": "actually millions of fans that now suddenly want to purchase a ticket so we now have loads more messages in the",
    "start": "2086240",
    "end": "2092480"
  },
  {
    "text": "queue and we don't have sufficient um instances of our application to actually",
    "start": "2092480",
    "end": "2097720"
  },
  {
    "text": "process this um so really what we want is cada um to look at the queue and recognize that we need more instances of",
    "start": "2097720",
    "end": "2105880"
  },
  {
    "text": "our pod um so we have kada here in the center of our slide recognizing that our",
    "start": "2105880",
    "end": "2111720"
  },
  {
    "text": "Q size is actually increased um so kada communicates with our horizontal pod autoscaler it does",
    "start": "2111720",
    "end": "2118720"
  },
  {
    "text": "that through that metric server and that controller and says hey we need more instances of our of our credit card",
    "start": "2118720",
    "end": "2125240"
  },
  {
    "text": "transaction processing workloads that we've got so we've now got all these pods um that the kubernetes scheduler",
    "start": "2125240",
    "end": "2131040"
  },
  {
    "text": "needs to schedule and then kubernetes realizes oh no we've only got two two",
    "start": "2131040",
    "end": "2136800"
  },
  {
    "text": "ec2 instances that is not enough compute for all of this so at that point what we want is Carpenter to kick in and realize",
    "start": "2136800",
    "end": "2144599"
  },
  {
    "text": "hey we need more compute and not just we need another two ec2 instances we need",
    "start": "2144599",
    "end": "2150200"
  },
  {
    "text": "compute that's big enough to look after all of these five pods that are unschedulable um so Carpenter will then",
    "start": "2150200",
    "end": "2157200"
  },
  {
    "text": "look at what the pods need it will then look at what's cheapest if we're using on demand or um the cheapest with the",
    "start": "2157200",
    "end": "2164480"
  },
  {
    "text": "biggest capacity available if we're using spots and it will then provision the right ec2 instances and in this",
    "start": "2164480",
    "end": "2171079"
  },
  {
    "text": "particular example it's worked out the cheapest thing to do is to provision small ec2s but five of them but perhaps",
    "start": "2171079",
    "end": "2178079"
  },
  {
    "text": "on another point in time the cheapest thing to do could have been to provision a single ec2 instance um but carpenter",
    "start": "2178079",
    "end": "2184640"
  },
  {
    "text": "has now provisioned those new nodes kubernetes Schuler has scheduled those workloads on those nodes and we're now",
    "start": "2184640",
    "end": "2191200"
  },
  {
    "text": "processing all those messages that are in the queue so our Taylor Swift fans now are happy because they're all",
    "start": "2191200",
    "end": "2197640"
  },
  {
    "text": "receiving uh transaction complete messages and they are getting access to their to their particular",
    "start": "2197640",
    "end": "2205800"
  },
  {
    "text": "tickets so we've sort of solved the Taylor Swift problem we've we've we've solved the the bit in the journey",
    "start": "2207319",
    "end": "2213640"
  },
  {
    "start": "2208000",
    "end": "2268000"
  },
  {
    "text": "whereby we have dependent systems that maybe don't know about the demand um of",
    "start": "2213640",
    "end": "2219560"
  },
  {
    "text": "the pre-sale they don't know how many fans have signed up but they want to make sure they can handle it if if that",
    "start": "2219560",
    "end": "2224760"
  },
  {
    "text": "ever happens um now when it comes to scaling based on event driven metrics",
    "start": "2224760",
    "end": "2229960"
  },
  {
    "text": "and scaling uh with Carpenter and with kubernetes there are certainly some best practices um to keep in mind um all of",
    "start": "2229960",
    "end": "2237240"
  },
  {
    "text": "those are detailed on our Amazon eks best practice guide um which is where this QR code uh will link to um but",
    "start": "2237240",
    "end": "2244760"
  },
  {
    "text": "really we want to encourage you to think about the most most optimal uh I guess compute configuration that you need in",
    "start": "2244760",
    "end": "2251920"
  },
  {
    "text": "your cluster um for the workloads that you actually want to run so definitely have a look at the best practice guide",
    "start": "2251920",
    "end": "2258119"
  },
  {
    "text": "there's a really interesting configuration on there check out our GitHub repo which gives a really good code example um of this particular setup",
    "start": "2258119",
    "end": "2266240"
  },
  {
    "text": "and uh all I'll say is thank you for your attention um Good Luck for any future Taylor Swift fans out there that",
    "start": "2266240",
    "end": "2272520"
  },
  {
    "start": "2268000",
    "end": "2291000"
  },
  {
    "text": "want to try and go and see IRAs 2 um thank you very much",
    "start": "2272520",
    "end": "2278838"
  }
]
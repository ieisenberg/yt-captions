[
  {
    "text": "hi I'm Simon Marlow I'm going to tell you about glean our system for indexing and querying code at scale that we've",
    "start": "120",
    "end": "6779"
  },
  {
    "text": "built at meta so let's start with a high level goal I'd like to ask questions about my code",
    "start": "6779",
    "end": "14099"
  },
  {
    "text": "because if we can achieve this in a general way then we'll have a tool that we can use to solve several different",
    "start": "14099",
    "end": "19320"
  },
  {
    "text": "kinds of problems for example what if we could ask what are all the",
    "start": "19320",
    "end": "24900"
  },
  {
    "text": "functions in a file or where is the definition of a particular function or maybe who is using my class",
    "start": "24900",
    "end": "32398"
  },
  {
    "text": "these are the kinds of questions that you could Implement IDE features like jump to definition find all",
    "start": "32399",
    "end": "38760"
  },
  {
    "text": "references or outlines what about some different questions how",
    "start": "38760",
    "end": "43800"
  },
  {
    "text": "about what's all ahead as referenced by my project or is anything from this import being used in this file",
    "start": "43800",
    "end": "49800"
  },
  {
    "text": "or maybe who is calling a function with these you can Implement dead code detection tools and Analysis",
    "start": "49800",
    "end": "57480"
  },
  {
    "text": "how about what are all the methods of a class in their types or what does a class inherit from or what are its",
    "start": "57480",
    "end": "62940"
  },
  {
    "text": "documentation comments with these you can build code documentation tools",
    "start": "62940",
    "end": "68040"
  },
  {
    "text": "well how about finding all the functions that match a particular name or finding all the functions that return a value of",
    "start": "68040",
    "end": "74159"
  },
  {
    "text": "a certain type or that create an object of a class with these you can build code search",
    "start": "74159",
    "end": "79799"
  },
  {
    "text": "tools so of course all of these things do",
    "start": "79799",
    "end": "85020"
  },
  {
    "text": "actually exist in one form or another but mostly they're aimed at one particular problem domain or they don't",
    "start": "85020",
    "end": "91200"
  },
  {
    "text": "scale in one of the axes that we're interested in what if you wanted to ask questions about say all of your company's code or",
    "start": "91200",
    "end": "98460"
  },
  {
    "text": "all of the code on GitHub in all of the different programming languages and you wanted to do that at large scale",
    "start": "98460",
    "end": "104880"
  },
  {
    "text": "so what we'd like to have is a system that scales to large code bases to many",
    "start": "104880",
    "end": "110159"
  },
  {
    "text": "different programming languages to lots of clients at the same time and to complex queries to things that you",
    "start": "110159",
    "end": "115920"
  },
  {
    "text": "haven't thought about asking about your code so far so in the rest of the talk I'm going to",
    "start": "115920",
    "end": "122159"
  },
  {
    "text": "tell you about glean which is the system we built at meta for solving these kinds of problems clean is an open source system you can",
    "start": "122159",
    "end": "129119"
  },
  {
    "text": "find it on GitHub and it's also at the URL glean.software we're using Gleaner meta to solve many",
    "start": "129119",
    "end": "135660"
  },
  {
    "text": "of these problems that I've mentioned already things like IDE features code navigation code analysis and code search",
    "start": "135660",
    "end": "141959"
  },
  {
    "text": "applications just to name a few so let's take a look at how the pieces",
    "start": "141959",
    "end": "147660"
  },
  {
    "text": "of glean fit together first we have indexes so these are the parts of the system that take the source",
    "start": "147660",
    "end": "154020"
  },
  {
    "text": "code and turn it into an abstract syntax tree data structure that we're going to write to clean",
    "start": "154020",
    "end": "159360"
  },
  {
    "text": "so you need one of these indexes for each of the different kinds of language that you're going to store in glean",
    "start": "159360",
    "end": "165360"
  },
  {
    "text": "and typically the indexer is built using the native compiler front end for that language so for example for C plus plus",
    "start": "165360",
    "end": "172019"
  },
  {
    "text": "our indexer is built on top of Cloud so the indexer takes the source code",
    "start": "172019",
    "end": "177720"
  },
  {
    "text": "turns it into an abstract syntax tree and then into glean facts",
    "start": "177720",
    "end": "183500"
  },
  {
    "text": "so gleam Factor stored in a database and gleam uses rocksdb as its storage backend",
    "start": "184200",
    "end": "189720"
  },
  {
    "text": "and each fact each node in the graph that we're going to store is stored exactly what so glean deduplicates the",
    "start": "189720",
    "end": "196560"
  },
  {
    "text": "data as you write it and of course because this is a database the facts are going to be indexed so",
    "start": "196560",
    "end": "202260"
  },
  {
    "text": "that we can retrieve them efficiently so that we can answer those questions that I mentioned earlier not only that but we also derive",
    "start": "202260",
    "end": "209580"
  },
  {
    "text": "additional facts once the data is written and the purpose of that is to be able to answer more questions more",
    "start": "209580",
    "end": "215220"
  },
  {
    "text": "efficiently and then would be provided by the index that you get by default",
    "start": "215220",
    "end": "221459"
  },
  {
    "text": "so finally the last part of the of this picture is the clients so each of these clients the IDE the code browser the",
    "start": "221459",
    "end": "228299"
  },
  {
    "text": "analysis tools and so on each of these work by making queries to glean and",
    "start": "228299",
    "end": "233340"
  },
  {
    "text": "glean provides its own query language that we call angle I'll talk about that a bit later in the talk angles Based on",
    "start": "233340",
    "end": "239459"
  },
  {
    "text": "data log and we also want to query at scale by that I mean many different clients all",
    "start": "239459",
    "end": "246180"
  },
  {
    "text": "querying at the same time doing a mixture of simple and complex queries",
    "start": "246180",
    "end": "251340"
  },
  {
    "text": "and so we can scale this horizontally just by adding more and more servers by replicating the databases across each of",
    "start": "251340",
    "end": "257400"
  },
  {
    "text": "these servers so that gives us a way to scale to as many clients as we want",
    "start": "257400",
    "end": "263780"
  },
  {
    "text": "when you're running this on your on your source code repository you want to have indexing running continuously because",
    "start": "264300",
    "end": "270479"
  },
  {
    "text": "the repository is continuously changing so indexing and replication of that data runs as a continuous process so the",
    "start": "270479",
    "end": "277919"
  },
  {
    "text": "clients at all times have access to the latest version of the code that we can give them",
    "start": "277919",
    "end": "283819"
  },
  {
    "text": "so that's the high level architecture let's talk a bit more about how glean works and how you can use it so first a",
    "start": "283860",
    "end": "291120"
  },
  {
    "text": "few just basic principles and some terminology that we're going to be using clean stores facts",
    "start": "291120",
    "end": "296759"
  },
  {
    "text": "so each factor is like a node in the in the graph of the data that you're going to store and each fact is stored exactly",
    "start": "296759",
    "end": "302280"
  },
  {
    "text": "once as I mentioned and when you store a fact glean assigns a unique fact ID to",
    "start": "302280",
    "end": "307800"
  },
  {
    "text": "each of those facts now the types of these facts are called predicates right glean is a strongly",
    "start": "307800",
    "end": "314280"
  },
  {
    "text": "typed system we have types for everything and we type check everything before it's stored in the database",
    "start": "314280",
    "end": "320639"
  },
  {
    "text": "so before you can store any data in glean you have to tell Glenn about the types that you're going to store this is",
    "start": "320639",
    "end": "325860"
  },
  {
    "text": "called the schema so let's imagine we're going to write the schema for a very simple language",
    "start": "325860",
    "end": "331380"
  },
  {
    "text": "let's start with the names in our language so here's how you define the predicate for a name",
    "start": "331380",
    "end": "337620"
  },
  {
    "text": "we write predicate name and then the type of the data that the factor is predicate they're going to store",
    "start": "337620",
    "end": "344340"
  },
  {
    "text": "now the data that each fact stores we call the key of the fact that's because this is also how you might retrieve that",
    "start": "344340",
    "end": "351180"
  },
  {
    "text": "data later on so this line here I've written on the left says we're defining a predicate",
    "start": "351180",
    "end": "356759"
  },
  {
    "text": "name and the types of the keys of those facts are strings",
    "start": "356759",
    "end": "362000"
  },
  {
    "text": "so here's what an instance of a fact of that predicate might look like I'm using",
    "start": "362160",
    "end": "367860"
  },
  {
    "text": "Json here as the the representation glean actually supports several",
    "start": "367860",
    "end": "373080"
  },
  {
    "text": "different representations and in fact if you're manipulating the data programmatically you would probably be",
    "start": "373080",
    "end": "378120"
  },
  {
    "text": "using native data types and I'll come on to that a bit later and but for the purposes of uh of just",
    "start": "378120",
    "end": "384780"
  },
  {
    "text": "talking generically about facts let's just use Json for the time being",
    "start": "384780",
    "end": "390840"
  },
  {
    "text": "okay so here's a fact it has a fact ID 42 and its key has a value of Foo",
    "start": "390840",
    "end": "398418"
  },
  {
    "text": "I suppose our language has qualified names we're a qualified name is a pair of a name and a module",
    "start": "399180",
    "end": "405960"
  },
  {
    "text": "so here we've defined a predicate qualified name and its value is a record or the type of type of its values is a",
    "start": "405960",
    "end": "412620"
  },
  {
    "text": "record with two Fields name and module and you can see each of these fields",
    "start": "412620",
    "end": "417840"
  },
  {
    "text": "contains a reference to the earlier predicate name so facts can refer to other facts and",
    "start": "417840",
    "end": "424860"
  },
  {
    "text": "that's how we build up tree shaped or rather graph shaped data structures in general the graph of facts is a dag",
    "start": "424860",
    "end": "432900"
  },
  {
    "text": "so here's how we might represent the effect of this qualified name predicate so it has an ID and a key which is a",
    "start": "432900",
    "end": "441120"
  },
  {
    "text": "record and the key has name and module fields and you can see that the facts that these fields are referenced",
    "start": "441120",
    "end": "448160"
  },
  {
    "text": "referencing are expanded in line in the Json so this is one way that you might",
    "start": "448160",
    "end": "453240"
  },
  {
    "text": "see an instance of this fact expanded like this of course we try to retain",
    "start": "453240",
    "end": "458880"
  },
  {
    "text": "sharing as much as possible so in the database the sharing is retained because each fact is stored exactly once",
    "start": "458880",
    "end": "464460"
  },
  {
    "text": "but we also try to retain sharing when you make queries so the data you get back well depending on what format you",
    "start": "464460",
    "end": "471060"
  },
  {
    "text": "ask for the data in we'll hopefully resign sharing",
    "start": "471060",
    "end": "475819"
  },
  {
    "text": "the next stage let's try to Define classes how we might refer to a class in this language so a class is going to",
    "start": "476880",
    "end": "483660"
  },
  {
    "text": "have a qualified name and it's going to have a source location corresponding to where the class is defined",
    "start": "483660",
    "end": "490199"
  },
  {
    "text": "so here we'll Define a type for location a type is not a predicate there's no no facts of a type it's just an alias",
    "start": "490199",
    "end": "496880"
  },
  {
    "text": "giving a name to a type so the type location is a record with two Fields line in column",
    "start": "496880",
    "end": "504620"
  },
  {
    "text": "and the class predicate that is also a record and it has a name which is a qualified name and it has a location",
    "start": "504780",
    "end": "511259"
  },
  {
    "text": "field and here's an instance of that fact and just one thing to note here is that we",
    "start": "511259",
    "end": "516659"
  },
  {
    "text": "can refer to nested facts just by their IDs if you're writing data in this Json format and then you can refer to facts",
    "start": "516659",
    "end": "523919"
  },
  {
    "text": "that you've defined earlier just by their ID to to explicitly Express sharing",
    "start": "523919",
    "end": "532040"
  },
  {
    "text": "so end to end how you do indexing is first of all you define a schema and then you have an indexer which produces",
    "start": "533399",
    "end": "540300"
  },
  {
    "text": "data corresponding to that schema you can write the indexer to either produce Json or you can use a typed DSL",
    "start": "540300",
    "end": "548540"
  },
  {
    "text": "with types generated from the schema I'll talk a bit about that later on in the talk",
    "start": "548540",
    "end": "554519"
  },
  {
    "text": "and then Glenn takes this data encoded into an efficient binary format and then",
    "start": "554519",
    "end": "560339"
  },
  {
    "text": "writes the data into rocksdb and finally once this is all complete then we can",
    "start": "560339",
    "end": "565980"
  },
  {
    "text": "query the data so let's talk a bit about querying glean comes with an interactive shell that you",
    "start": "565980",
    "end": "572519"
  },
  {
    "text": "can use for playing around with queries and for trying things out interactively while you're experimenting",
    "start": "572519",
    "end": "579000"
  },
  {
    "text": "while you're iterating on your on your schema perhaps so we start the glean shell like this and",
    "start": "579000",
    "end": "586620"
  },
  {
    "text": "it gives us a prompt and now we can make queries so here's an example of a query that we",
    "start": "586620",
    "end": "592200"
  },
  {
    "text": "might use to look up a particular class that we've indexed so this is a query and it's going to",
    "start": "592200",
    "end": "598980"
  },
  {
    "text": "return facts that match the pattern that we've written in our query",
    "start": "598980",
    "end": "604560"
  },
  {
    "text": "so on the left of the query we start with the predicate so we're asking to match facts that match this particular",
    "start": "604560",
    "end": "609660"
  },
  {
    "text": "predicate and on the right here we have a pattern so the pattern looks like the",
    "start": "609660",
    "end": "615300"
  },
  {
    "text": "type that we wrote earlier on it's a record it has some fields but we don't have to give all the fields we're just",
    "start": "615300",
    "end": "620339"
  },
  {
    "text": "going to give the fields that we want to match on so here we're matching classes that have a name field",
    "start": "620339",
    "end": "626820"
  },
  {
    "text": "and just for reference here is the schema that we defined earlier on the classes have a name field and the name",
    "start": "626820",
    "end": "632640"
  },
  {
    "text": "is a qualified name and a qualified name also has a name field and the value of that main field is a",
    "start": "632640",
    "end": "639420"
  },
  {
    "text": "string so we have two nested name fields and finally the string is going to be my",
    "start": "639420",
    "end": "645480"
  },
  {
    "text": "class so this will match classes whose uh whose unqualified name so we're not",
    "start": "645480",
    "end": "651360"
  },
  {
    "text": "matching on the module the qualified name whose unqualified name is my class and if you wrote this query you might",
    "start": "651360",
    "end": "657899"
  },
  {
    "text": "see a result like this so the shell will give you back the Json representing the fact that matches that",
    "start": "657899",
    "end": "663720"
  },
  {
    "text": "particular query or more facts if more facts match the query um",
    "start": "663720",
    "end": "670260"
  },
  {
    "text": "okay so I won't go into any more detail about the query language but just to say",
    "start": "670260",
    "end": "675959"
  },
  {
    "text": "it is quite expressive we have some features that you've probably seen in",
    "start": "675959",
    "end": "681240"
  },
  {
    "text": "logic programming languages some features borrowed from data log and some features that we've invented for",
    "start": "681240",
    "end": "686459"
  },
  {
    "text": "ourselves um so you can have things like statements variables there's disjunctions if then else and negation",
    "start": "686459",
    "end": "694800"
  },
  {
    "text": "and all of these things are supported by a query compiler so every time you send a query to clean it's compiling the",
    "start": "694800",
    "end": "700860"
  },
  {
    "text": "query inside the server optimizing it turning it into by code and then executing the bytecode in the database",
    "start": "700860",
    "end": "707220"
  },
  {
    "text": "backend so data log is well known for supporting",
    "start": "707220",
    "end": "713519"
  },
  {
    "text": "recursive queries and this is a very expressive way of of doing interesting queries on your data and but",
    "start": "713519",
    "end": "720839"
  },
  {
    "text": "we found for our purposes recursive queries were not the highest priority",
    "start": "720839",
    "end": "726560"
  },
  {
    "text": "types of queries that we wanted to be able to express at least at first we said we definitely want to be able to",
    "start": "726560",
    "end": "731579"
  },
  {
    "text": "support recursive queries but as as things stand at present because the queries are not supported we plan to do",
    "start": "731579",
    "end": "737760"
  },
  {
    "text": "that in the future so let's talk now about something a bit",
    "start": "737760",
    "end": "744240"
  },
  {
    "text": "philosophical so I've said that when you index a language you have to define a schema for that language",
    "start": "744240",
    "end": "751260"
  },
  {
    "text": "um and that means that glean has a schema for each of the different languages that we support okay so this is part of the",
    "start": "751260",
    "end": "758640"
  },
  {
    "text": "design of of glean we've decided that we want to have a different schema for each of the languages that we support",
    "start": "758640",
    "end": "765839"
  },
  {
    "text": "and that gives us the the ability to do things that are language specific when we need to so some languages well every",
    "start": "765839",
    "end": "774060"
  },
  {
    "text": "language has something that's unique to that particular language and and if we can store a language",
    "start": "774060",
    "end": "779880"
  },
  {
    "text": "specific detail that means we can do things that are and",
    "start": "779880",
    "end": "785180"
  },
  {
    "text": "language specific analysis for example for for that language including the detail that's um",
    "start": "785180",
    "end": "791519"
  },
  {
    "text": "that's specific to that language for example we do redundance include removal in C plus as an analysis",
    "start": "791519",
    "end": "798480"
  },
  {
    "text": "and and this relies on having information in the C plus index that's",
    "start": "798480",
    "end": "804120"
  },
  {
    "text": "very unique to C plus plus particular declarations name spacing rules and so",
    "start": "804120",
    "end": "809880"
  },
  {
    "text": "on um we can only do this because we have a schema that's specific to C plus",
    "start": "809880",
    "end": "816959"
  },
  {
    "text": "and not only that but you probably want to design the schema to be a natural fit for the indexer to be something close to",
    "start": "816959",
    "end": "822839"
  },
  {
    "text": "the abstract syntax tree that the indexer is retrieving from the compiler so that means your indexer is just doing",
    "start": "822839",
    "end": "829440"
  },
  {
    "text": "a very simple translation between the abstract syntax tree and the glean facts in in the schema that you've defined",
    "start": "829440",
    "end": "836339"
  },
  {
    "text": "um so that makes it very convenient to be able to write your indexer",
    "start": "836339",
    "end": "842160"
  },
  {
    "text": "but the downside of having one schema per language is that we somehow have to figure out",
    "start": "842160",
    "end": "848339"
  },
  {
    "text": "how to support the kinds of clients that don't care very much about all of these language specific details",
    "start": "848339",
    "end": "854220"
  },
  {
    "text": "so something for example like a generic code browser which just wants to be able to do click to definition for example",
    "start": "854220",
    "end": "860519"
  },
  {
    "text": "and to navigate your code and it would like to support all of the different languages without having to do something",
    "start": "860519",
    "end": "866880"
  },
  {
    "text": "different for each of those languages so we definitely want to support this use case and how are we going to do that",
    "start": "866880",
    "end": "873660"
  },
  {
    "text": "well one way we might try to do it is to have a multi-language Library",
    "start": "873660",
    "end": "880139"
  },
  {
    "text": "that we write and we provide that as a library that clients can use them to build on top of",
    "start": "880139",
    "end": "885720"
  },
  {
    "text": "so that would certainly work we we would certainly have to only write this once and it could be used by many clients",
    "start": "885720",
    "end": "892680"
  },
  {
    "text": "but one problem here is we have to figure out what language to write that library in and you know",
    "start": "892680",
    "end": "897959"
  },
  {
    "text": "you know that could be uh that could be quite a quite a difficult choice to make",
    "start": "897959",
    "end": "903240"
  },
  {
    "text": "um So to avoid that maybe we could build this Library as a service and a",
    "start": "903240",
    "end": "911279"
  },
  {
    "text": "service with an RPC interface that can be used by many different languages",
    "start": "911279",
    "end": "916920"
  },
  {
    "text": "and that would work in in fact we've done something similar to this but it also has a downside the API to the",
    "start": "916920",
    "end": "924180"
  },
  {
    "text": "service is fixed you know we've had to Define this RPC protocol and it's inflexible so we can't write arbitrary",
    "start": "924180",
    "end": "930899"
  },
  {
    "text": "queries against it so this is where data log comes in and",
    "start": "930899",
    "end": "936660"
  },
  {
    "text": "this gives us the expressivity we need to be able to solve this problem in a more flexible way",
    "start": "936660",
    "end": "942480"
  },
  {
    "text": "so data log is a query language in which you can derive new facts from existing facts so for example right now what we",
    "start": "942480",
    "end": "949680"
  },
  {
    "text": "have is with our language specific schemas we have facts about Java declarations in Java source files we",
    "start": "949680",
    "end": "955380"
  },
  {
    "text": "have facts about C plus plus declarations in C plus plus source files and using data log techniques from all",
    "start": "955380",
    "end": "963300"
  },
  {
    "text": "of these we can derive facts that are generic across languages we can drive",
    "start": "963300",
    "end": "968760"
  },
  {
    "text": "facts about declarations in any source files so that's basically how the technique",
    "start": "968760",
    "end": "974220"
  },
  {
    "text": "works so let me show you a bit of the code associated with how we do this in glean so we can define a type of declarations",
    "start": "974220",
    "end": "981120"
  },
  {
    "text": "and a type of declarations is a disjunction between declarations for",
    "start": "981120",
    "end": "986459"
  },
  {
    "text": "Java and declarations for python all the languages we support so that's the Declaration in any",
    "start": "986459",
    "end": "992519"
  },
  {
    "text": "language and then we can define a predicate file declaration which is going to give us the relationship",
    "start": "992519",
    "end": "998399"
  },
  {
    "text": "between a file and the Declarations it contains and we can Define this just by",
    "start": "998399",
    "end": "1004880"
  },
  {
    "text": "using a disjunction between the file declaration predicates that we've defined for each of the different",
    "start": "1004880",
    "end": "1010759"
  },
  {
    "text": "languages that we support so you would have to define a Java file declaration a python file declaration one of those for",
    "start": "1010759",
    "end": "1016880"
  },
  {
    "text": "each of the languages and now our generic file declaration predicate can support all of those",
    "start": "1016880",
    "end": "1022940"
  },
  {
    "text": "languages that we Define the uh the language specific predicates for",
    "start": "1022940",
    "end": "1028040"
  },
  {
    "text": "so in fact this is exactly what we do and now in our queries we can write a query for",
    "start": "1028040",
    "end": "1034100"
  },
  {
    "text": "file declarations for a particular file and it will return declarations in that",
    "start": "1034100",
    "end": "1039500"
  },
  {
    "text": "file regardless of what language that file is written in",
    "start": "1039500",
    "end": "1044500"
  },
  {
    "text": "so we built the code markup layer for clean and it's called uh well it's called code",
    "start": "1045319",
    "end": "1051740"
  },
  {
    "text": "markup it supports all the languages that we support it's aimed currently at supporting the",
    "start": "1051740",
    "end": "1058039"
  },
  {
    "text": "kinds of operations that you need to do code navigation and code browsing and that's simply because that's the",
    "start": "1058039",
    "end": "1064400"
  },
  {
    "text": "application that we had in mind at the moment when writing this this layer so it supports finding all the Declarations",
    "start": "1064400",
    "end": "1070460"
  },
  {
    "text": "in a file it supports finding all the references within the file that's cross references from the uses of a symbol to",
    "start": "1070460",
    "end": "1078320"
  },
  {
    "text": "its definition and it also supports finding the reverse mapping so going from a declaration to",
    "start": "1078320",
    "end": "1084919"
  },
  {
    "text": "all of the uses of that symbol throughout the code base and all the languages that we support",
    "start": "1084919",
    "end": "1090140"
  },
  {
    "text": "support all of these operations and we can also fetch some declaration metadata so in the future this layer will",
    "start": "1090140",
    "end": "1096200"
  },
  {
    "text": "probably support more more data it will allow us to do code documentation for",
    "start": "1096200",
    "end": "1101240"
  },
  {
    "text": "example code search and other types of applications the languages that this layer supports",
    "start": "1101240",
    "end": "1106460"
  },
  {
    "text": "currently include C plus plus python JavaScript uh you know whole",
    "start": "1106460",
    "end": "1111740"
  },
  {
    "text": "string of languages that we have indexes for",
    "start": "1111740",
    "end": "1115900"
  },
  {
    "text": "so let's just walk through a real world example of indexing some some actual code base",
    "start": "1116780",
    "end": "1123440"
  },
  {
    "text": "and we've used react as the example here so to index the code base we've provided",
    "start": "1123440",
    "end": "1129100"
  },
  {
    "text": "the glean index command which lets you do this from the command line so you can say glean index flow you give the",
    "start": "1129100",
    "end": "1135140"
  },
  {
    "text": "language that you want to use to index it the location of the code and the name of",
    "start": "1135140",
    "end": "1141559"
  },
  {
    "text": "the the database that you want to produce that's what the repo flag is doing here",
    "start": "1141559",
    "end": "1147500"
  },
  {
    "text": "so in a few seconds we're running the flow tool itself which produces a whole lot of Json data and",
    "start": "1147500",
    "end": "1154880"
  },
  {
    "text": "then the Json data is being written to a clean database and a few seconds later we have an index",
    "start": "1154880",
    "end": "1160760"
  },
  {
    "text": "so now we can fire up the glean shell and we can tell our lean channel that we want to use this database that we've",
    "start": "1160760",
    "end": "1166760"
  },
  {
    "text": "just created so that's the colon DB command so now we're making queries against this",
    "start": "1166760",
    "end": "1171860"
  },
  {
    "text": "data and we're inspecting this database that we've just created so we can look at statistics and in this",
    "start": "1171860",
    "end": "1179539"
  },
  {
    "text": "case it tells us that we have 430 000 facts 15 megabytes the data is quite compact",
    "start": "1179539",
    "end": "1185539"
  },
  {
    "text": "because we're using a binary encoding and we can make query so here's an",
    "start": "1185539",
    "end": "1190700"
  },
  {
    "text": "example of a code markup query and we're looking for all of the uh well file",
    "start": "1190700",
    "end": "1196640"
  },
  {
    "text": "entity locations gives us the all of the entities defined in a particular file and we've given the name of a file",
    "start": "1196640",
    "end": "1203360"
  },
  {
    "text": "within the react code base here and this is giving us well I've given you one result here in fact there would be many",
    "start": "1203360",
    "end": "1209000"
  },
  {
    "text": "results and I've set the limit so that it just gave us one result",
    "start": "1209000",
    "end": "1214900"
  },
  {
    "text": "so we've indexed some code we've indexed the react code base using the flow indexer and now we're using the code",
    "start": "1215780",
    "end": "1222679"
  },
  {
    "text": "markup layer to give us language independent results for queries against that data",
    "start": "1222679",
    "end": "1229120"
  },
  {
    "text": "so far so good but you're probably wondering how does this relate to functional programming",
    "start": "1229280",
    "end": "1234860"
  },
  {
    "text": "well there's a couple of ways one way is that well we wrote glean mostly at Haskell as",
    "start": "1234860",
    "end": "1240380"
  },
  {
    "text": "it happens but I want to tell you about a couple of ways in which Haskell really helps not",
    "start": "1240380",
    "end": "1245660"
  },
  {
    "text": "just with writing Glee but also with using it from the client-side perspective so one of the ways is that using Haskell",
    "start": "1245660",
    "end": "1253039"
  },
  {
    "text": "we can define a typesafe query DSL so I showed you some examples of angle queries earlier on just written using",
    "start": "1253039",
    "end": "1259520"
  },
  {
    "text": "text but when you're writing queries programmatically inside your client you",
    "start": "1259520",
    "end": "1265100"
  },
  {
    "text": "don't just want to use text because that doesn't give you any guarantees that the query won't fail the query doesn't have any typos or type errors",
    "start": "1265100",
    "end": "1272480"
  },
  {
    "text": "that would fail the query at runtime so what we'd like to be able to do is to write our queries",
    "start": "1272480",
    "end": "1278440"
  },
  {
    "text": "and type check them at compile time at the compile time of our client so the query DSL that we have in Haskell",
    "start": "1278440",
    "end": "1285980"
  },
  {
    "text": "actually provides that guarantee so here's an example on the left we've got the original angle",
    "start": "1285980",
    "end": "1291980"
  },
  {
    "text": "query which is looking for a file named food.hs and on the right we have the Haskell",
    "start": "1291980",
    "end": "1298340"
  },
  {
    "text": "code that implements the same query so there's a function called predicate",
    "start": "1298340",
    "end": "1304700"
  },
  {
    "text": "and it takes a type argument so the second argument here is a type argument and the type is source.file",
    "start": "1304700",
    "end": "1312020"
  },
  {
    "text": "this is a type that's generated from the schema and it tells our DSL",
    "start": "1312020",
    "end": "1319880"
  },
  {
    "text": "the nature of this type the definition of the type so that the DSL can type check the rest of the query against the",
    "start": "1319880",
    "end": "1326960"
  },
  {
    "text": "definition of source.file so in our DSL we have this type angle P",
    "start": "1326960",
    "end": "1334700"
  },
  {
    "text": "or angle T which is a query that returns a result of type T and in fact when you",
    "start": "1334700",
    "end": "1339799"
  },
  {
    "text": "pretty print an angle T it actually pretty prints as the angle query",
    "start": "1339799",
    "end": "1346580"
  },
  {
    "text": "so here's the type of predicate it's taking a type argument for all P that's",
    "start": "1346580",
    "end": "1351620"
  },
  {
    "text": "the predicate that we're querying it's taking as its first argument an angle",
    "start": "1351620",
    "end": "1357260"
  },
  {
    "text": "query for the key of facts of those of that predicate and it's returning a",
    "start": "1357260",
    "end": "1362720"
  },
  {
    "text": "query for the predicate itself and we have a function string that takes a text and it's a query for things of",
    "start": "1362720",
    "end": "1369200"
  },
  {
    "text": "type text so here's something a bit more complex here's an example of a query for a",
    "start": "1369200",
    "end": "1377059"
  },
  {
    "text": "record type so python.declaration with name and we give it a name it returns declarations with that particular name",
    "start": "1377059",
    "end": "1384080"
  },
  {
    "text": "so on the right we have the Haskell code for that that's the predicate function as it as",
    "start": "1384080",
    "end": "1389120"
  },
  {
    "text": "before with the type argument python.declaration with name and now the",
    "start": "1389120",
    "end": "1394700"
  },
  {
    "text": "the key of this is going to be a record so we have special combinators in our",
    "start": "1394700",
    "end": "1399799"
  },
  {
    "text": "DSL for building record matching so Rec introduces a record and then we have a",
    "start": "1399799",
    "end": "1405860"
  },
  {
    "text": "number of fields and of course the DSL has to match for each field it has to ensure that",
    "start": "1405860",
    "end": "1411679"
  },
  {
    "text": "this is actually a field of the record that we're matching and it has to make sure that the type of",
    "start": "1411679",
    "end": "1417919"
  },
  {
    "text": "that field matches the type of the field in the schema so our field combinator takes a type",
    "start": "1417919",
    "end": "1424280"
  },
  {
    "text": "argument which is a string literal type and here we've used the name",
    "start": "1424280",
    "end": "1430760"
  },
  {
    "text": "stream of course because it's matching the the name field and on the right Foo is the text which is the contents of",
    "start": "1430760",
    "end": "1437960"
  },
  {
    "text": "that main field",
    "start": "1437960",
    "end": "1440559"
  },
  {
    "text": "so having set all this up this gives you a quite a nice experience when you're writing these queries if you're doing it",
    "start": "1445039",
    "end": "1451400"
  },
  {
    "text": "in vs code and you and you have the Haskell extension enabled you can get instant feedback on your your queries",
    "start": "1451400",
    "end": "1457820"
  },
  {
    "text": "that you're writing using the DSL as type errors and the type errors are quite readable in fact so for example if",
    "start": "1457820",
    "end": "1464840"
  },
  {
    "text": "I try to query for a field that doesn't exist here I've queried for a field called No Such field",
    "start": "1464840",
    "end": "1471440"
  },
  {
    "text": "and I've got a tie powder that tells me there's no instance for hasfield of No Such field",
    "start": "1471440",
    "end": "1477080"
  },
  {
    "text": "so it's telling me that this field just doesn't exist in the in the record type that I'm trying to query",
    "start": "1477080",
    "end": "1483760"
  },
  {
    "text": "and if I get the type of the contents of the field rung again I",
    "start": "1483860",
    "end": "1489500"
  },
  {
    "text": "get a type error here it's saying it couldn't match leaned on that with code.location where I've written",
    "start": "1489500",
    "end": "1496100"
  },
  {
    "text": "Nat 42 and I should have written something of of the type location",
    "start": "1496100",
    "end": "1501320"
  },
  {
    "text": "so the instant feedback is really great for just writing queries in the DSL and",
    "start": "1501320",
    "end": "1507380"
  },
  {
    "text": "ensuring that they're type correct at compile time",
    "start": "1507380",
    "end": "1511900"
  },
  {
    "text": "so how does this actually work well you wrote the schema in a file called schema.angle corresponding to the the",
    "start": "1512900",
    "end": "1520280"
  },
  {
    "text": "predicates for your language that you're querying and and there's a Code generation step",
    "start": "1520280",
    "end": "1525679"
  },
  {
    "text": "that takes this schema and produces some Haskell code amongst other languages so",
    "start": "1525679",
    "end": "1531020"
  },
  {
    "text": "we also co-generate code for other languages too but the Haskell code will give you the native data types",
    "start": "1531020",
    "end": "1537799"
  },
  {
    "text": "corresponding to each of the predicates in each of the types in the schema and it also produces type instances so",
    "start": "1537799",
    "end": "1545240"
  },
  {
    "text": "here's a type instance of record fields and this is going to tell the DSL what",
    "start": "1545240",
    "end": "1550460"
  },
  {
    "text": "are all the fields of this record contains and what are the types of those fields and that's enough information for",
    "start": "1550460",
    "end": "1556279"
  },
  {
    "text": "the DSL to be able to type check the queries at compile time so the generated Haskell type and the",
    "start": "1556279",
    "end": "1564260"
  },
  {
    "text": "type instance so the whole process of working on a",
    "start": "1564260",
    "end": "1570559"
  },
  {
    "text": "schema and working on some queries is that you get to iterate on your angle code and use glean to type check it",
    "start": "1570559",
    "end": "1576320"
  },
  {
    "text": "using the Shell that I mentioned earlier on so you you work on the schema code and then you generate the Haskell code",
    "start": "1576320",
    "end": "1582260"
  },
  {
    "text": "and now you can write your your client code using GHC to type check inside vs",
    "start": "1582260",
    "end": "1587659"
  },
  {
    "text": "code so getting instant feedback while you're writing the code so now you have the guarantees that your queries don't fail",
    "start": "1587659",
    "end": "1594020"
  },
  {
    "text": "at runtime and also the queries are returning these native Haskell types that were generated",
    "start": "1594020",
    "end": "1599419"
  },
  {
    "text": "from the schema and so this works very nicely for",
    "start": "1599419",
    "end": "1605419"
  },
  {
    "text": "Haskell but you can also do similar kinds of things in other languages too but typically we'd want to do something",
    "start": "1605419",
    "end": "1611659"
  },
  {
    "text": "that's idiomatic in that language so for example we have a hack based DSL that's",
    "start": "1611659",
    "end": "1617299"
  },
  {
    "text": "not part of the open source repository at the moment um but it's designed to be idiomatic in in",
    "start": "1617299",
    "end": "1624980"
  },
  {
    "text": "hack so it gives you something that's a lot more familiar to hack programmers and it doesn't look very much like the",
    "start": "1624980",
    "end": "1630200"
  },
  {
    "text": "the Haskell DSL that I showed you just down we're also planning a python DSL and I",
    "start": "1630200",
    "end": "1636559"
  },
  {
    "text": "imagine in the future there will be DSL for other languages too if you don't have a DSL for the language",
    "start": "1636559",
    "end": "1642200"
  },
  {
    "text": "you want to use to query glean you can still make raw angle queries and that that works just fine it's just that you",
    "start": "1642200",
    "end": "1647720"
  },
  {
    "text": "don't get the compile time type checking and the IDE feedback and you might you",
    "start": "1647720",
    "end": "1652820"
  },
  {
    "text": "might write queries that fail at runtime and then they'll raise an exception",
    "start": "1652820",
    "end": "1659179"
  },
  {
    "text": "so the second benefit of Haskell that I wanted to talk about is the haxel library so clients with gleam they're",
    "start": "1659179",
    "end": "1664820"
  },
  {
    "text": "often making many queries to retrieve data from clean and we would like those queries to be as concurrent as possible",
    "start": "1664820",
    "end": "1671000"
  },
  {
    "text": "so the hacksaw Library together with the applicative do extension gives you a great experience writing these types of",
    "start": "1671000",
    "end": "1676340"
  },
  {
    "text": "clients so let's recap quickly on applicative two applicative do is an extension that",
    "start": "1676340",
    "end": "1682340"
  },
  {
    "text": "takes a do expression in the source code with a number of statements when the statements don't depend on each other",
    "start": "1682340",
    "end": "1687919"
  },
  {
    "text": "the compiler can translate this automatically into the equivalent applicative expression and this is done",
    "start": "1687919",
    "end": "1694340"
  },
  {
    "text": "by analyzing the dependencies in the compiler the Huntsville Library takes these",
    "start": "1694340",
    "end": "1700580"
  },
  {
    "text": "applicative Expressions produced by applicative Duke and it executes them in parallel",
    "start": "1700580",
    "end": "1705860"
  },
  {
    "text": "so we have an applicative expression like this example here where we have X and Y we can run X and Y if those are",
    "start": "1705860",
    "end": "1712880"
  },
  {
    "text": "computations that make queries we can run those queries in parallel so hacksaw isn't tied to any particular",
    "start": "1712880",
    "end": "1719360"
  },
  {
    "text": "service or any particular data source what you have to do when you use hacksaw you have to provide a data source for",
    "start": "1719360",
    "end": "1725900"
  },
  {
    "text": "your service and glean comes with a haxel data source that makes clean queries",
    "start": "1725900",
    "end": "1732260"
  },
  {
    "text": "so that means if you're writing a glean client and it has a statement like map M",
    "start": "1732260",
    "end": "1737299"
  },
  {
    "text": "query over a list all of those queries would be executed in parallel when you're using haxel",
    "start": "1737299",
    "end": "1743720"
  },
  {
    "text": "and if you're using hacks altogether with applicative do and you have a do expression with a number of statements",
    "start": "1743720",
    "end": "1749299"
  },
  {
    "text": "that might be in queries and they don't depend on each other then most lean queries will happen concurrently",
    "start": "1749299",
    "end": "1754640"
  },
  {
    "text": "automatically as long as you're using the applicative do extension",
    "start": "1754640",
    "end": "1759980"
  },
  {
    "text": "so here's a real world example of something from our code base that's exploiting this ability",
    "start": "1759980",
    "end": "1765620"
  },
  {
    "text": "so this is part of the glass line which is some middleware that we use intermediate and intermediate layer",
    "start": "1765620",
    "end": "1771740"
  },
  {
    "text": "between clients with a simple API and glean queries on the other side",
    "start": "1771740",
    "end": "1777260"
  },
  {
    "text": "so this particular example is some code that wants to find within a source file",
    "start": "1777260",
    "end": "1782539"
  },
  {
    "text": "it wants to find the cross references and also the Declarations in that source file and those are two separate queries",
    "start": "1782539",
    "end": "1788059"
  },
  {
    "text": "that we've entered lean and here are two separate statements making those queries and those",
    "start": "1788059",
    "end": "1793279"
  },
  {
    "text": "statements are going to be executed concurrently just because we're using hacks all together with the applicative do extension",
    "start": "1793279",
    "end": "1800539"
  },
  {
    "text": "so you might be wondering what languages do we support well in the open source release we're currently supporting",
    "start": "1800539",
    "end": "1806059"
  },
  {
    "text": "JavaScript flow hack and a number of languages that we're supporting through a generic lsif translator",
    "start": "1806059",
    "end": "1813320"
  },
  {
    "text": "so these this takes lsif data translates it into lean facts and for these indexes",
    "start": "1813320",
    "end": "1819260"
  },
  {
    "text": "we're not going to get the full Fidelity that you would expect from a language specific indexer with a language specific schema but it does mean that we",
    "start": "1819260",
    "end": "1826279"
  },
  {
    "text": "can use existing lsif indexes that already exist exist for these languages",
    "start": "1826279",
    "end": "1832399"
  },
  {
    "text": "so there's a number of indexes that are in the open source repository but not fully integrated at the present time",
    "start": "1832399",
    "end": "1838880"
  },
  {
    "text": "that includes C plus and Objective C rust and Haskell so these languages we",
    "start": "1838880",
    "end": "1844399"
  },
  {
    "text": "have indexes for them they're in the repository but the necessary glue to be able to integrate them with the rest of",
    "start": "1844399",
    "end": "1850100"
  },
  {
    "text": "the system isn't fully there yet and of course we'll be developing that over time and improving it",
    "start": "1850100",
    "end": "1856880"
  },
  {
    "text": "there are also some indexes that are not in the open source repository yet and we hope to get those open sourced in due",
    "start": "1856880",
    "end": "1862100"
  },
  {
    "text": "course that includes Python and Java are there any actual clients that you",
    "start": "1862100",
    "end": "1868399"
  },
  {
    "text": "can use well this is work in progress we are actively trying to integrate lean",
    "start": "1868399",
    "end": "1874640"
  },
  {
    "text": "with existing systems we're thinking about vs code for example and we hope to have more end-to-end Integrations over",
    "start": "1874640",
    "end": "1881960"
  },
  {
    "text": "time in due course but for right now there are demos and you can write your own clients of course and you can",
    "start": "1881960",
    "end": "1887059"
  },
  {
    "text": "experiment with queries and so on um but but the full Integrations we're still working on",
    "start": "1887059",
    "end": "1893480"
  },
  {
    "text": "as far as the open source release goes we're definitely actively developing it and we want to maintain it and support",
    "start": "1893480",
    "end": "1899000"
  },
  {
    "text": "it over time um so we're if you go look at the repository we're keeping the CI green",
    "start": "1899000",
    "end": "1905059"
  },
  {
    "text": "all the time you can see all the development going on there's lots of lots of commits going in all the commits",
    "start": "1905059",
    "end": "1911779"
  },
  {
    "text": "to our internal version of gleam get automatically propagated into the open source Repository",
    "start": "1911779",
    "end": "1917419"
  },
  {
    "text": "and over time we expect it to be uh to continue to be maintained and developed actively",
    "start": "1917419",
    "end": "1924580"
  },
  {
    "text": "so you can go ahead and go and have a look at Green Dot software where you find all the documentation the download",
    "start": "1924620",
    "end": "1930559"
  },
  {
    "text": "links links to GitHub and you can also find Docker images on GitHub that you",
    "start": "1930559",
    "end": "1935840"
  },
  {
    "text": "can download and just play around with glean and try it out that's all I have to say thank you very",
    "start": "1935840",
    "end": "1941120"
  },
  {
    "text": "much",
    "start": "1941120",
    "end": "1943240"
  }
]
[
  {
    "start": "0",
    "end": "53000"
  },
  {
    "text": "[Music]",
    "start": "970",
    "end": "7838"
  },
  {
    "text": "i'm really excited today to talk to you about streaming with structure and this talk has come about because",
    "start": "11280",
    "end": "17920"
  },
  {
    "text": "i've been doing quite a bit lately around kafka and sort of schemas and how you define your",
    "start": "17920",
    "end": "23760"
  },
  {
    "text": "events and i found that there aren't that many people talking about how to do this generically with kafka so i'm going to",
    "start": "23760",
    "end": "30800"
  },
  {
    "text": "talk a little bit about why you should have structure when you're streaming but also some specifics so that if you want to start using",
    "start": "30800",
    "end": "37680"
  },
  {
    "text": "schemas and adding structure to your kafka streams then you'll be able to do it no matter what schema registry you choose to use",
    "start": "37680",
    "end": "44719"
  },
  {
    "text": "so hopefully this will be useful whether you've come across kafka or not and whether you've picked your schema",
    "start": "44719",
    "end": "50000"
  },
  {
    "text": "registry or not so first let's get some coffee",
    "start": "50000",
    "end": "57360"
  },
  {
    "start": "53000",
    "end": "529000"
  },
  {
    "text": "i know we've got a couple people already drinking coffee this morning i personally don't drink coffee well i",
    "start": "57360",
    "end": "63039"
  },
  {
    "text": "know how much people love coffee and it's a great way to introduce streaming so before i go into the",
    "start": "63039",
    "end": "68479"
  },
  {
    "text": "structure let's talk about streaming so i'm going to start with this coffee demo and i'll keep revisiting this",
    "start": "68479",
    "end": "74640"
  },
  {
    "text": "through the talk but we have a basic coffee demo here where we have a coffee shop and a barista and we have a lot of",
    "start": "74640",
    "end": "81439"
  },
  {
    "text": "coffee lovers that come in they send http requests to the coffee shop to place their orders and that gets forwarded to the barista",
    "start": "81439",
    "end": "88400"
  },
  {
    "text": "barista makes the coffee and then the coffee shop can tell the coffee lovers that their coffee is ready",
    "start": "88400",
    "end": "94320"
  },
  {
    "text": "this works well as a sort of basic setup demo but what you find is the more coffee lovers you have",
    "start": "94320",
    "end": "100159"
  },
  {
    "text": "the more you find that actually this http form of communication perhaps doesn't",
    "start": "100159",
    "end": "105280"
  },
  {
    "text": "work as well as it could do so this is where adventure event architecture comes in",
    "start": "105280",
    "end": "111119"
  },
  {
    "text": "so event driven architecture is adding micro services that are publishing events into this event-driven messaging",
    "start": "111119",
    "end": "118159"
  },
  {
    "text": "backbone so the idea here is making a shift so you have this messaging backbone at the",
    "start": "118159",
    "end": "123200"
  },
  {
    "text": "center of your whole architecture and your flowing events all around the system",
    "start": "123200",
    "end": "128800"
  },
  {
    "text": "so you can have other micro services that are consuming events perhaps publishing new ones into the",
    "start": "128800",
    "end": "134319"
  },
  {
    "text": "backbone and then others consuming again and if we add this to our coffee shop",
    "start": "134319",
    "end": "140319"
  },
  {
    "text": "demo we now have this set up so we've still got http between the coffee lovers and the coffee shop",
    "start": "140319",
    "end": "145680"
  },
  {
    "text": "because they want to know whether their order was accepted but then the copy shop is sending orders",
    "start": "145680",
    "end": "151200"
  },
  {
    "text": "into the event backbone and creating a list of these orders",
    "start": "151200",
    "end": "156560"
  },
  {
    "text": "this leaves the barista available to process the orders in whatever order they want to it allows",
    "start": "156560",
    "end": "163120"
  },
  {
    "text": "us to scale up and add more baristas and it also enables us to have this board where we can post when the coffee is",
    "start": "163120",
    "end": "168840"
  },
  {
    "text": "ready by moving to the right hand side of this diagram it enables the coffee lovers to",
    "start": "168840",
    "end": "174000"
  },
  {
    "text": "go and sit down chat about java or kafka while they're wasting their coffee",
    "start": "174000",
    "end": "179040"
  },
  {
    "text": "and if you actually run this demo so you can see the github link at the top you do find that moving to this",
    "start": "179040",
    "end": "185280"
  },
  {
    "text": "architecture often gives you a lot of advantages so if you run with a lot of copy lovers you'll find that the",
    "start": "185280",
    "end": "191280"
  },
  {
    "text": "processing of the orders is much quicker on the event backbone side",
    "start": "191280",
    "end": "196560"
  },
  {
    "text": "now i'm not going to talk any more in depth about adventure of an architecture but we are seeing a lot of people who",
    "start": "196560",
    "end": "202080"
  },
  {
    "text": "are making this shift and starting to ask when can i introduce an event backbone and will that help me to",
    "start": "202080",
    "end": "208640"
  },
  {
    "text": "decouple my system in some way and allow me to scale different parts independently",
    "start": "208640",
    "end": "214159"
  },
  {
    "text": "and this does bring decoupling but through this talk i'm going to explain where there is still coupling between",
    "start": "214159",
    "end": "220799"
  },
  {
    "text": "these parts and why you might want to consider the structure of what you're throwing into your event backbone",
    "start": "220799",
    "end": "226560"
  },
  {
    "text": "if you've chosen to go to event driven architecture so let's first talk about the event",
    "start": "226560",
    "end": "233200"
  },
  {
    "text": "backbone so in this case talking about kafka kafka is an open source",
    "start": "233200",
    "end": "238560"
  },
  {
    "text": "distributed streaming platform it is becoming very very popular as a source of all your streams going",
    "start": "238560",
    "end": "245120"
  },
  {
    "text": "through your system i've been talking at the kafka summit conferences which are sort of main",
    "start": "245120",
    "end": "251439"
  },
  {
    "text": "community conferences for the last three or four years and the kafka community and the amount",
    "start": "251439",
    "end": "256720"
  },
  {
    "text": "of companies that are using kafka in their systems is just growing exponentially every single year",
    "start": "256720",
    "end": "262400"
  },
  {
    "text": "i'm always impressed with how many more people are at the event how many more companies are talking about the way they've used kafka to",
    "start": "262400",
    "end": "268639"
  },
  {
    "text": "transform what they're doing so if you're using something like kafka",
    "start": "268639",
    "end": "274720"
  },
  {
    "text": "then you need to start thinking about structure but in order to talk about that i just want to give you",
    "start": "274720",
    "end": "280000"
  },
  {
    "text": "a little overview of kafka as a system so it provides stream history which means that you can reprocess",
    "start": "280000",
    "end": "285840"
  },
  {
    "text": "and re-read messages it provides scalable consumption so it's designed to have a lot of",
    "start": "285840",
    "end": "290960"
  },
  {
    "text": "different containers connected it provides immutable data so when you put something into kafka",
    "start": "290960",
    "end": "296880"
  },
  {
    "text": "it's immutable it shouldn't be transformed as it flows through and it's very scalable and highly",
    "start": "296880",
    "end": "302080"
  },
  {
    "text": "available and all these things make kafka a really great choice for streaming but kafka is designed",
    "start": "302080",
    "end": "310639"
  },
  {
    "text": "to fulfill a lot of different use cases so it has a lot of different configuration options but it's also",
    "start": "310639",
    "end": "317840"
  },
  {
    "text": "designed that you can sort of flow any kind of data through it and that's where the need for structure",
    "start": "317840",
    "end": "324320"
  },
  {
    "text": "starts to come in so the first thing you need to know is when you're dealing with kafka i'm going",
    "start": "324320",
    "end": "329919"
  },
  {
    "text": "to talk a lot about producers and consumers so producer is an application that's putting data into kafka a consumer is pulling",
    "start": "329919",
    "end": "335759"
  },
  {
    "text": "out all of the data in kafka is stored in bytes so when the data comes",
    "start": "335759",
    "end": "341039"
  },
  {
    "text": "over the wire into kafka it's in bytes at that point which means when you're producing and",
    "start": "341039",
    "end": "346560"
  },
  {
    "text": "you're consuming you need to make sure that your producers and consumers understand how to interpret those bites",
    "start": "346560",
    "end": "352560"
  },
  {
    "text": "or how to create them now kafka is generally it's built primarily with java",
    "start": "352560",
    "end": "359039"
  },
  {
    "text": "it also has some scala in it there are plenty of other languages you can use with kafka",
    "start": "359039",
    "end": "364080"
  },
  {
    "text": "but i'm going to use like primarily java in all of my talking here because that's the language",
    "start": "364080",
    "end": "369360"
  },
  {
    "text": "that provides the clients and things so it's one of the most popular ones with kafka",
    "start": "369360",
    "end": "374479"
  },
  {
    "text": "so in java we already have this idea of serialization so what the kafka community do is when",
    "start": "374479",
    "end": "380720"
  },
  {
    "text": "you download kafka you get these serializers with it so when you write a producer and a",
    "start": "380720",
    "end": "386080"
  },
  {
    "text": "consumer you can use the string serializer or integer serializer and then the matching d serializer to",
    "start": "386080",
    "end": "392319"
  },
  {
    "text": "serialize and deserialize your messages so that when they flow through kafka they're just bikes but the producer and",
    "start": "392319",
    "end": "397919"
  },
  {
    "text": "consumer understands them so this is really great because you can run all different producers and",
    "start": "397919",
    "end": "403600"
  },
  {
    "text": "consumers and to catch just generic data coming through it",
    "start": "403600",
    "end": "409360"
  },
  {
    "text": "so what does this mean for our coffee shop demo well let's say we're going to use the string serializer and we want to start",
    "start": "409360",
    "end": "415919"
  },
  {
    "text": "sending orders a sort of basic starting point is to say well",
    "start": "415919",
    "end": "421199"
  },
  {
    "text": "i've got a string maybe i can just do a comma separated list of items",
    "start": "421199",
    "end": "426400"
  },
  {
    "text": "so i've got an id a product a customer and a size i'm going to put them in this order and this order only and",
    "start": "426400",
    "end": "432639"
  },
  {
    "text": "as long as the barista understands that then i can send an order that's my id my order of hot chocolate",
    "start": "432639",
    "end": "440400"
  },
  {
    "text": "since i don't drink coffee my name and then small and the barista",
    "start": "440400",
    "end": "445440"
  },
  {
    "text": "will understand as long as it's configured you use the string deserializer and it knows what order to look for the items in",
    "start": "445440",
    "end": "452080"
  },
  {
    "text": "then that's okay i guess well it might work if",
    "start": "452080",
    "end": "458960"
  },
  {
    "text": "you know exactly how long each of these items is going to be or you know splits on the comma but what",
    "start": "458960",
    "end": "464639"
  },
  {
    "text": "happens if the coffee shop decides you know we want to start offering marshmallows as an option if you order a",
    "start": "464639",
    "end": "470479"
  },
  {
    "text": "hot chocolate we're going to add marshmallows if you want in well if i put that into my next order",
    "start": "470479",
    "end": "477280"
  },
  {
    "text": "how does the barista know that that was what i was trying to do how do they know marshmallows is an option how",
    "start": "477280",
    "end": "483919"
  },
  {
    "text": "do they know whether it's even going to be there and it gets worse than this because",
    "start": "483919",
    "end": "489199"
  },
  {
    "text": "the coffee shop could decide they want to send any kind of data so what if they decide they're going to send jason instead of xml",
    "start": "489199",
    "end": "497039"
  },
  {
    "text": "how do you make sure that although you've created this separation and disconnection between your coffee shop",
    "start": "497039",
    "end": "502400"
  },
  {
    "text": "and your barista how do you make sure they're still talking the same language and i think this is something that's",
    "start": "502400",
    "end": "507599"
  },
  {
    "text": "often sort of forgotten about because it's so great having something like kafka that allows you to have multiple",
    "start": "507599",
    "end": "512959"
  },
  {
    "text": "different consumers that are all consuming from this one set of events but actually if all of the",
    "start": "512959",
    "end": "519279"
  },
  {
    "text": "consumers don't understand how to read the messages then adding kafka isn't really helping you",
    "start": "519279",
    "end": "525839"
  },
  {
    "text": "so we can start by adding some structure and a nice way to do that is using json",
    "start": "525839",
    "end": "532000"
  },
  {
    "start": "529000",
    "end": "620000"
  },
  {
    "text": "lots of people are using json to add structure and a lot of the different languages now",
    "start": "532000",
    "end": "537760"
  },
  {
    "text": "provide reasonable support for reading and writing json okay so we've got this sort of good",
    "start": "537760",
    "end": "544080"
  },
  {
    "text": "structure in json we've got an order id a product customer and size now if i put them in a different order",
    "start": "544080",
    "end": "551279"
  },
  {
    "text": "whatever's consuming them can probably find the right entry and this does help us a bit in terms of",
    "start": "551279",
    "end": "557040"
  },
  {
    "text": "adding new data so if i add an extra entry and my consumer doesn't understand it",
    "start": "557040",
    "end": "562399"
  },
  {
    "text": "as long as they're configured to ignore fields they don't understand then yeah this is okay but",
    "start": "562399",
    "end": "569200"
  },
  {
    "text": "it still doesn't give us a lot of information about what's coming into this message so as a",
    "start": "569200",
    "end": "575200"
  },
  {
    "text": "consumer i might understand that there's an entry called marshmallows and then it's a boolean of true or false",
    "start": "575200",
    "end": "581200"
  },
  {
    "text": "but what if the coffee shop decides actually we're done with booleans we're going to send everything as",
    "start": "581200",
    "end": "586560"
  },
  {
    "text": "strings so they change it to a yes or no again the barista wouldn't understand",
    "start": "586560",
    "end": "593040"
  },
  {
    "text": "how to process this message so although json gives you nice structure it lacks metadata",
    "start": "593040",
    "end": "599839"
  },
  {
    "text": "it doesn't give us any additional information about what types are on the right hand side of",
    "start": "599839",
    "end": "606000"
  },
  {
    "text": "these key value pairs but also what are the options we can't tell from this message",
    "start": "606000",
    "end": "611760"
  },
  {
    "text": "whether you can buy a large hot chocolate or just a small and a medium",
    "start": "611760",
    "end": "617680"
  },
  {
    "text": "so this is where schemas come in so a schema is basically a blueprint for",
    "start": "617680",
    "end": "624000"
  },
  {
    "start": "620000",
    "end": "800000"
  },
  {
    "text": "your event it defines what data should be in there and the different types and structures that are available",
    "start": "624000",
    "end": "631200"
  },
  {
    "text": "it's actually bringing in schemas isn't something that's new in terms of microservices and communication",
    "start": "631200",
    "end": "637120"
  },
  {
    "text": "because a lot of rest-based systems do have a sort of schema anyway they use things like open api definition",
    "start": "637120",
    "end": "643440"
  },
  {
    "text": "to define their api and say this is how you consume it these are the end points and this is the information",
    "start": "643440",
    "end": "649920"
  },
  {
    "text": "that you're going to get out so a schema is similar but for events",
    "start": "649920",
    "end": "655920"
  },
  {
    "text": "so you need to define a schema so your producer is producing events with the right",
    "start": "655920",
    "end": "661279"
  },
  {
    "text": "information in it but also so your consumer understands how to consume that",
    "start": "661279",
    "end": "666959"
  },
  {
    "text": "but where do you store your schema first starting point would be well i'll",
    "start": "666959",
    "end": "672320"
  },
  {
    "text": "just deploy the schema with each of my applications and then if it changes i can update it or something",
    "start": "672320",
    "end": "680480"
  },
  {
    "text": "but if you do have an update coming in this isn't like an api definition where you could just",
    "start": "680480",
    "end": "686399"
  },
  {
    "text": "have multiple different paths for the different versions when you're flowing through events there's no way to indicate to the",
    "start": "686399",
    "end": "692720"
  },
  {
    "text": "consumer i'm using this version up to here but this schema comes in at this point in",
    "start": "692720",
    "end": "698880"
  },
  {
    "text": "time in general you wouldn't create a new topic every single time you wanted to",
    "start": "698880",
    "end": "704720"
  },
  {
    "text": "change your schema there needs to be a better way for this to be communicated and to make sure that the consumer doesn't suddenly read the",
    "start": "704720",
    "end": "711279"
  },
  {
    "text": "next message on the topic in kafka and find that they don't understand it so a better way",
    "start": "711279",
    "end": "719920"
  },
  {
    "text": "rather than having them stored with the individual producer and consumer is to send it as part of the message so",
    "start": "719920",
    "end": "727040"
  },
  {
    "text": "we have jason here and we can put a schema inside our json object and then pass the whole thing across",
    "start": "727040",
    "end": "733839"
  },
  {
    "text": "this again works okay it does the job it means that when the consumer receives the message they",
    "start": "733839",
    "end": "740320"
  },
  {
    "text": "can look at the schema to understand how to interpret the data we can tell them some other information",
    "start": "740320",
    "end": "745519"
  },
  {
    "text": "about what might be coming along the problem with this is you are now",
    "start": "745519",
    "end": "750639"
  },
  {
    "text": "adding a schema to every single message that comes through kafka and i talked earlier about kafka being",
    "start": "750639",
    "end": "757360"
  },
  {
    "text": "highly resilient and available the way that kafka does that is through replication so",
    "start": "757360",
    "end": "762560"
  },
  {
    "text": "kafka will actually store multiple copies of your individual events so that if one part of the distributed system",
    "start": "762560",
    "end": "768399"
  },
  {
    "text": "goes down you still have other copies to fall back on so for kafka specifically sending",
    "start": "768399",
    "end": "775279"
  },
  {
    "text": "messages in this way with the schema included you're not just adding that extra bit for every single message you choose",
    "start": "775279",
    "end": "781839"
  },
  {
    "text": "but you also because you're storing the message multiple times you're adding a lot more storage you're",
    "start": "781839",
    "end": "786959"
  },
  {
    "text": "going to have as a requirement in your kafka system so",
    "start": "786959",
    "end": "792079"
  },
  {
    "text": "ideally you want the producer and the consumer to agree on the schema but you don't want to have to send it as",
    "start": "792079",
    "end": "797920"
  },
  {
    "text": "part of the message and this is where a schema registry comes in",
    "start": "797920",
    "end": "804480"
  },
  {
    "start": "800000",
    "end": "847000"
  },
  {
    "text": "so a schema registry is a registry full of schemas you deploy it somewhere separately to",
    "start": "804480",
    "end": "811200"
  },
  {
    "text": "your producers and your consumers and as long as your producers and consumers can access the schema registry",
    "start": "811200",
    "end": "816399"
  },
  {
    "text": "and access all of the schemas you now have a mechanism to be able to update those schemas and make sure that all of",
    "start": "816399",
    "end": "821920"
  },
  {
    "text": "the applications know about it so i would encourage you to use schemas and",
    "start": "821920",
    "end": "828880"
  },
  {
    "text": "schema entries as part of your systems what i found is when i start talking about schemas and schema registries",
    "start": "828880",
    "end": "835360"
  },
  {
    "text": "there are two questions that come to mind one question is one that i get asked a lot the second one is one that i don't",
    "start": "835360",
    "end": "841680"
  },
  {
    "text": "guess but i feel like people should be asking so the first one of those is what format",
    "start": "841680",
    "end": "848560"
  },
  {
    "start": "847000",
    "end": "1173000"
  },
  {
    "text": "to use that's the question i get asked all the time the one that people never seem to ask is",
    "start": "848560",
    "end": "853920"
  },
  {
    "text": "which schema does it do we choose so which schema in the schema registry does my",
    "start": "853920",
    "end": "860639"
  },
  {
    "text": "application choose for that particular event and how does that work under the covers",
    "start": "860639",
    "end": "866560"
  },
  {
    "text": "so i'm going to go into each of these and talk about some common formats that are available and for most",
    "start": "866560",
    "end": "872560"
  },
  {
    "text": "of the schema registries that people use around kafka but also talk about how you can",
    "start": "872560",
    "end": "878079"
  },
  {
    "text": "flow the information about which schema to choose through kafka specifically",
    "start": "878079",
    "end": "884800"
  },
  {
    "text": "so first let's talk about schema formats it's worth noting none of these formats are specific to kafka",
    "start": "884800",
    "end": "891360"
  },
  {
    "text": "if you're using some other event system and you want to look at schemas you can definitely use these formats for others",
    "start": "891360",
    "end": "896639"
  },
  {
    "text": "they are just generic schema formats so the three i'm going to talk about is",
    "start": "896639",
    "end": "902320"
  },
  {
    "text": "json schema the google protocol buffer and apache avro",
    "start": "902320",
    "end": "907839"
  },
  {
    "text": "so let's start with json schema json schema is a vocabulary that allows",
    "start": "907839",
    "end": "913839"
  },
  {
    "text": "you to annotate and validate json documents it's nice for people who are very familiar",
    "start": "913839",
    "end": "919839"
  },
  {
    "text": "with json because if you look at it it sort of feels familiar you don't have to learn a lot of new syntax understand how to write the schema and",
    "start": "919839",
    "end": "926959"
  },
  {
    "text": "it's very good for describing existing data so if you've already got a lot of",
    "start": "926959",
    "end": "932000"
  },
  {
    "text": "json data that you're flowing through events then this might be a really good choice for you it provides clear",
    "start": "932000",
    "end": "938240"
  },
  {
    "text": "human and machine readable documentation so it's easy for a human to pass what's",
    "start": "938240",
    "end": "943440"
  },
  {
    "text": "going on here but also easy for your applications to consume it as well",
    "start": "943440",
    "end": "950160"
  },
  {
    "text": "so this is the first one that i find a lot of people use the next one is protobuf so protobuf is",
    "start": "950160",
    "end": "956959"
  },
  {
    "text": "a mechanism for serializing structured data it was created by google they describe it sort of language neutral",
    "start": "956959",
    "end": "963519"
  },
  {
    "text": "the idea behind protobuf is you provide this proto file which just finds your actual schema",
    "start": "963519",
    "end": "969759"
  },
  {
    "text": "and then they have a lot of code generation that allows you to generate libraries to interact with your schema",
    "start": "969759",
    "end": "975839"
  },
  {
    "text": "for your specific language so the example i've given here is java because that's the one that i use the",
    "start": "975839",
    "end": "980880"
  },
  {
    "text": "most and you can see here we've got the definition of the schema so we've got an order we've got an id which is required",
    "start": "980880",
    "end": "988320"
  },
  {
    "text": "and a product which is required and then we've got our optional billion for marshmallows and i can create an object",
    "start": "988320",
    "end": "995279"
  },
  {
    "text": "so under the covers what protobuf will be doing is generating me my order java class and then i can",
    "start": "995279",
    "end": "1001920"
  },
  {
    "text": "interact with it so this works pretty nicely um one of the disadvantages though",
    "start": "1001920",
    "end": "1007680"
  },
  {
    "text": "is because you are having to do the code generation it means you have to sort of set all of that up",
    "start": "1007680",
    "end": "1013680"
  },
  {
    "text": "before you get started with writing anything um you also do need to understand how to write that proto file",
    "start": "1013680",
    "end": "1021680"
  },
  {
    "text": "the third one is the one that i've seen used the most with kafka and that's apache avery so apache avro",
    "start": "1021839",
    "end": "1029199"
  },
  {
    "text": "is a data serialization system that provides very rich data structures and we'll see what that means in a minute",
    "start": "1029199",
    "end": "1035280"
  },
  {
    "text": "it has a compact fast binary data format so it sort of fits well with kafka and",
    "start": "1035280",
    "end": "1041038"
  },
  {
    "text": "being able to have high throughput and it provides simple integration with dynamic languages",
    "start": "1041039",
    "end": "1046558"
  },
  {
    "text": "so you don't have to use code generation with apache afro but you can if you want to so if we look",
    "start": "1046559",
    "end": "1053919"
  },
  {
    "text": "a little bit more what that means when you define a schema the apache adverse schemas go in a file",
    "start": "1053919",
    "end": "1059360"
  },
  {
    "text": "which has this extension dot absc but it's all structured json inside so",
    "start": "1059360",
    "end": "1064960"
  },
  {
    "text": "again it's quite easy if you've never seen avro before you can look at this jason and sort of guess what the schema means",
    "start": "1064960",
    "end": "1071840"
  },
  {
    "text": "which i think is quite nice there are a few different types that you can define this one is of type record",
    "start": "1071840",
    "end": "1078799"
  },
  {
    "text": "a record has a name and then some fields and you can see here that i've then got",
    "start": "1078799",
    "end": "1084400"
  },
  {
    "text": "some simple types so i've got my product which is just a string but i can also provide quite complex",
    "start": "1084400",
    "end": "1090880"
  },
  {
    "text": "types without frame so you can see here for example i've got a logical type of a uuid",
    "start": "1090880",
    "end": "1096400"
  },
  {
    "text": "the one i actually see use the most is the date time logical type but you can also provide things like",
    "start": "1096400",
    "end": "1101760"
  },
  {
    "text": "enums and stuff so it's very rich in terms of the different structures you can define with it but i",
    "start": "1101760",
    "end": "1109280"
  },
  {
    "text": "find reading the schema files is really straightforward the other thing that i really like about",
    "start": "1109280",
    "end": "1115679"
  },
  {
    "text": "afro which i sort of touched upon a minute ago is that you can actually use it without any",
    "start": "1115679",
    "end": "1122400"
  },
  {
    "text": "code generation so here you can see an example i'm just using the generic data types",
    "start": "1122400",
    "end": "1128080"
  },
  {
    "text": "that avro provides so i've got my schema and then i can basically create",
    "start": "1128080",
    "end": "1133200"
  },
  {
    "text": "generic data objects i can then send in so this is from the producing site constructing my",
    "start": "1133200",
    "end": "1139360"
  },
  {
    "text": "order which i'm going to send up in practice you would potentially often just use the code",
    "start": "1139360",
    "end": "1145120"
  },
  {
    "text": "generation because it means you're not having to sort of write these all out by hand and you wouldn't have for example the",
    "start": "1145120",
    "end": "1150720"
  },
  {
    "text": "fact that i've spelt marshmallows wrong which i only noticed when i presented this yesterday",
    "start": "1150720",
    "end": "1156080"
  },
  {
    "text": "but for getting started this makes it really easy because you aren't having to sort of set up",
    "start": "1156080",
    "end": "1161919"
  },
  {
    "text": "anything to do that code generation and run maven or whatever it is to do the code generation",
    "start": "1161919",
    "end": "1167280"
  },
  {
    "text": "beforehand so for that reason i yeah really like it",
    "start": "1167280",
    "end": "1172799"
  },
  {
    "start": "1173000",
    "end": "1622000"
  },
  {
    "text": "okay so now on to the question that i find people aren't necessarily asking but it's a really interesting one to look at",
    "start": "1173679",
    "end": "1180080"
  },
  {
    "text": "and that's which schema to choose and for this i'll be delving a little bit more into what's happening with kafka under the covers",
    "start": "1180080",
    "end": "1186640"
  },
  {
    "text": "and personally i think this is really interesting to see how you can flow the data through kafka specifically",
    "start": "1186640",
    "end": "1192320"
  },
  {
    "text": "and i think it does apply to other event systems but i'm going to talk specifically about kafka",
    "start": "1192320",
    "end": "1197360"
  },
  {
    "text": "and how they do it so the first thing you have to do when you're thinking about your schemas and your schema",
    "start": "1197360",
    "end": "1203039"
  },
  {
    "text": "registry is you need to work out how you're going to identify a specific schema",
    "start": "1203039",
    "end": "1208320"
  },
  {
    "text": "so it's probably naive to assume that you can create one schema and that will be your schema forevermore",
    "start": "1208320",
    "end": "1214640"
  },
  {
    "text": "if you were going to do that then you wouldn't need a schema registry but chances are you're going to want to add",
    "start": "1214640",
    "end": "1219919"
  },
  {
    "text": "a field change a field and do something that means your schema will evolve over time so for schemas i've found that",
    "start": "1219919",
    "end": "1228080"
  },
  {
    "text": "generally schema registries will store them in one of two ways so the first is that they'll have a",
    "start": "1228080",
    "end": "1233360"
  },
  {
    "text": "unique identifier for every single individual version of a schema so that's what i've got sort of on the",
    "start": "1233360",
    "end": "1238880"
  },
  {
    "text": "left hand side so id1 is the first version of my schema",
    "start": "1238880",
    "end": "1243919"
  },
  {
    "text": "and then i updated it and i got a new id for it which is id2 so although the schema might be the same",
    "start": "1243919",
    "end": "1250559"
  },
  {
    "text": "and they might just have different versions they each have a unique identifier there are some schema registries however that will",
    "start": "1250559",
    "end": "1257840"
  },
  {
    "text": "um go a bit further in terms of like tying together the different versions of the same schema so that's what i've got on the",
    "start": "1257840",
    "end": "1264400"
  },
  {
    "text": "right here so here we have a unique identifier that identifies this schema and then we have the",
    "start": "1264400",
    "end": "1270159"
  },
  {
    "text": "different versions of that schema as it goes through so the first thing you need to understand is how does your schema",
    "start": "1270159",
    "end": "1277039"
  },
  {
    "text": "registry store schemas is there a unique identifier for every single artifact",
    "start": "1277039",
    "end": "1282159"
  },
  {
    "text": "every single like version of that schema or to get a specific version do you have to",
    "start": "1282159",
    "end": "1287440"
  },
  {
    "text": "have a combination of an id and a version and you might find if the schema registry has chosen the one on the right",
    "start": "1287440",
    "end": "1294240"
  },
  {
    "text": "then actually if you just provide id1 it will pick the latest version of that schema",
    "start": "1294240",
    "end": "1299440"
  },
  {
    "text": "but if you want a specific version you have to add that version number so once you've worked this out we need",
    "start": "1299440",
    "end": "1304960"
  },
  {
    "text": "to work out how do i get that id from the producer who knows what schema they used to create the object to",
    "start": "1304960",
    "end": "1312320"
  },
  {
    "text": "the consumer and to do that we need to look a little bit closer at kafka records",
    "start": "1312320",
    "end": "1319039"
  },
  {
    "text": "so in kafka each event that goes through kafka and is stored on a topic is made",
    "start": "1319039",
    "end": "1325200"
  },
  {
    "text": "up of a key value pair so we call this a record the key is optional and is used for some",
    "start": "1325200",
    "end": "1332400"
  },
  {
    "text": "kind of routing within kafka and where the events end up",
    "start": "1332400",
    "end": "1337760"
  },
  {
    "text": "but the value is what contains your main sort of event and it's worth noting that i've seen",
    "start": "1337760",
    "end": "1344159"
  },
  {
    "text": "people using schemas for both the key and the value that's like definitely something you can do",
    "start": "1344159",
    "end": "1349280"
  },
  {
    "text": "but generally most people would stick with just the value because often the key is just a simple id or something",
    "start": "1349280",
    "end": "1355120"
  },
  {
    "text": "that doesn't necessarily need a schema so we've got this key and value pair",
    "start": "1355120",
    "end": "1361840"
  },
  {
    "text": "how do we get the id for a schema and then pass it through as part of these records",
    "start": "1361840",
    "end": "1368799"
  },
  {
    "text": "well in kafka i said that a particular value is a stream of bytes one way to do this and get the",
    "start": "1368799",
    "end": "1376400"
  },
  {
    "text": "schema id across is use using something called a magic byte so if i've got this as my value and i'm",
    "start": "1376400",
    "end": "1384400"
  },
  {
    "text": "using a schema id and i'm using a setup where i'm going to use magic bytes",
    "start": "1384400",
    "end": "1389520"
  },
  {
    "text": "what i would do is basically have this set of bytes is split into three parts so the first is a magic",
    "start": "1389520",
    "end": "1396480"
  },
  {
    "text": "white which indicates that we've got schema id going on here",
    "start": "1396480",
    "end": "1402880"
  },
  {
    "text": "then we have an integer schema id and then we have the serialized data so",
    "start": "1402880",
    "end": "1409039"
  },
  {
    "text": "the idea is that when the consumer receives this information it can spot the magic",
    "start": "1409039",
    "end": "1414240"
  },
  {
    "text": "byte it can grab out the schema id get the schema from the schema registry and then deserialize the data that comes",
    "start": "1414240",
    "end": "1420880"
  },
  {
    "text": "after it i said you can do this for keys and values so you could have",
    "start": "1420880",
    "end": "1426480"
  },
  {
    "text": "records that are coming into your kafka where both the key and the value have the magic lights at the beginning that",
    "start": "1426480",
    "end": "1432159"
  },
  {
    "text": "indicate that they've got a schema this allows you to be more specific about which",
    "start": "1432159",
    "end": "1437679"
  },
  {
    "text": "schema each message comes through without having to include the whole schema the nice thing about this flow is you",
    "start": "1437679",
    "end": "1444400"
  },
  {
    "text": "aren't having to send any other additional data all of the information about how to read the message is part of the message",
    "start": "1444400",
    "end": "1450640"
  },
  {
    "text": "itself the downside of this is you are polluting your value as it goes through",
    "start": "1450640",
    "end": "1457520"
  },
  {
    "text": "so if you don't have an application the other side that understands that there's a magic bite at the beginning you could",
    "start": "1457520",
    "end": "1463279"
  },
  {
    "text": "find you've got some interesting parsing of the data going on because if it was guessing the underlying type it wouldn't necessarily",
    "start": "1463279",
    "end": "1469679"
  },
  {
    "text": "be able to understand that there's a schema id at the beginning but when people started using schemas in",
    "start": "1469679",
    "end": "1476960"
  },
  {
    "text": "kafka this was pretty much the only way to do it but in version 0 11 0 record headers",
    "start": "1476960",
    "end": "1483600"
  },
  {
    "text": "were added to kafka along with the key value pair a record header is an additional piece of",
    "start": "1483600",
    "end": "1489679"
  },
  {
    "text": "information that can be passed along with the record you can have multiple different headers and",
    "start": "1489679",
    "end": "1495520"
  },
  {
    "text": "it's up to the producer to decide what headers they define it's just a key value pair there isn't",
    "start": "1495520",
    "end": "1501600"
  },
  {
    "text": "that many restrictions on it and a lot of steamer registries are starting to look at this",
    "start": "1501600",
    "end": "1507919"
  },
  {
    "text": "as the mechanism to use so here it gives us an opportunity to have",
    "start": "1507919",
    "end": "1513360"
  },
  {
    "text": "both an id and a version for example and i can add into my producer record a specific header that says the schema id",
    "start": "1513360",
    "end": "1520000"
  },
  {
    "text": "is this id and then the schema version is this version the nice thing about this",
    "start": "1520000",
    "end": "1525120"
  },
  {
    "text": "approach is you're not polluting your actual value it's just sentence separate headers and the other thing is it makes it more",
    "start": "1525120",
    "end": "1531840"
  },
  {
    "text": "efficient in terms of reading the schema id and finding the schema so the application that's consuming this",
    "start": "1531840",
    "end": "1539520"
  },
  {
    "text": "value coming across they don't have to actually do any processing of the real value they could check the schema id if it's",
    "start": "1539520",
    "end": "1546559"
  },
  {
    "text": "something they don't understand they could you know put it on a different topic and say someone else is going to process that or just ignore it",
    "start": "1546559",
    "end": "1553679"
  },
  {
    "text": "it's kind of up to you but it makes it a bit more efficient in terms of reading",
    "start": "1553679",
    "end": "1559120"
  },
  {
    "text": "so as i said there are two different approaches here we've got the magic byte approach where the key and the value",
    "start": "1559840",
    "end": "1565200"
  },
  {
    "text": "contain the information about the schema id and then we've got the record header where it's included in the header",
    "start": "1565200",
    "end": "1573039"
  },
  {
    "text": "now there are actually quite a few schema registries that support both of these and then there are some that just support one or the other i found",
    "start": "1573039",
    "end": "1580320"
  },
  {
    "text": "in general if they support one it's normally the magic bytes approach because that's the one that was available first through kafka",
    "start": "1580320",
    "end": "1586159"
  },
  {
    "text": "and then the record header was later but more and more schema registered adding both options but it's worth",
    "start": "1586159",
    "end": "1592559"
  },
  {
    "text": "noting that in a minute i'm going to talk about configuring your applications but your applications the producing and",
    "start": "1592559",
    "end": "1599840"
  },
  {
    "text": "consuming side need to agree which approach they're using obviously if you've got a producer that's putting",
    "start": "1599840",
    "end": "1605679"
  },
  {
    "text": "everything in the actual key in value as a magic bite and the consumer is looking in the header",
    "start": "1605679",
    "end": "1612480"
  },
  {
    "text": "then we're not going to have easy reading of our messages so we need to work out how to get these",
    "start": "1612480",
    "end": "1618159"
  },
  {
    "text": "to agree and read the same information and this is where studies and converters",
    "start": "1618159",
    "end": "1624400"
  },
  {
    "start": "1622000",
    "end": "2081000"
  },
  {
    "text": "come in so in kafka for a kafka cluster there",
    "start": "1624400",
    "end": "1630320"
  },
  {
    "text": "are broadly four types of applications that you can write",
    "start": "1630320",
    "end": "1635919"
  },
  {
    "text": "there are producing and consuming applications connect applications and streams",
    "start": "1635919",
    "end": "1643039"
  },
  {
    "text": "applications and for each of these the way you configure them to",
    "start": "1643039",
    "end": "1648080"
  },
  {
    "text": "do the serialization and talk to the schema registry is subtly different so let's talk about producers first i've",
    "start": "1648080",
    "end": "1654799"
  },
  {
    "text": "already sort of touched on this producers and the consumers because i talked about the serializers",
    "start": "1654799",
    "end": "1659840"
  },
  {
    "text": "and d serializers at the beginning so when you configure a kafka application that's a producer or",
    "start": "1659840",
    "end": "1665360"
  },
  {
    "text": "consumer you can provide a configuration option which is a key serializer and value serializer and",
    "start": "1665360",
    "end": "1670960"
  },
  {
    "text": "then for the consumer you do the d serializer as i said there are some default java classes you can use",
    "start": "1670960",
    "end": "1677120"
  },
  {
    "text": "if you're using language that isn't java you'll find that there's other libraries or dependencies or for their",
    "start": "1677120",
    "end": "1683919"
  },
  {
    "text": "language that do the serializing and deserializing but what you need to do is configure",
    "start": "1683919",
    "end": "1688960"
  },
  {
    "text": "your producer and consumer with a serializer and deserializer that understand",
    "start": "1688960",
    "end": "1694159"
  },
  {
    "text": "how to talk to the schema registry and then how to serialize with that schema and then on the d serialize how to get",
    "start": "1694159",
    "end": "1700880"
  },
  {
    "text": "the ide out of the message whether it's in the header or using magic bytes get it out of the schema and then",
    "start": "1700880",
    "end": "1707679"
  },
  {
    "text": "deserialize the message with it so what you'll find is that different schema industries basically provide",
    "start": "1707679",
    "end": "1714159"
  },
  {
    "text": "serializers and deserializers to use with that schema registry they'll normally be configured so they",
    "start": "1714159",
    "end": "1720880"
  },
  {
    "text": "understand how to authenticate with the schema registry if that's required and they understand where to get the",
    "start": "1720880",
    "end": "1726559"
  },
  {
    "text": "information out but that's why you do need to think about this magic byte versus header",
    "start": "1726559",
    "end": "1731600"
  },
  {
    "text": "because if your schema registry supports both options you obviously need to make sure your producers and consumers are configured",
    "start": "1731600",
    "end": "1738000"
  },
  {
    "text": "so they both know which option they're looking for so this is producers and consumers the",
    "start": "1738000",
    "end": "1744720"
  },
  {
    "text": "next one is kafka connect so cathy connect is a framework within the kafka",
    "start": "1744720",
    "end": "1751440"
  },
  {
    "text": "community it allows you to pull data from an external system into kafka using a source connector",
    "start": "1751440",
    "end": "1757760"
  },
  {
    "text": "and then get the data out of kafka and put it into an external system connect is both a framework to run",
    "start": "1757760",
    "end": "1765760"
  },
  {
    "text": "connectors and also a library to write connectors basically the word connector is",
    "start": "1765760",
    "end": "1772159"
  },
  {
    "text": "completely overloaded in kafka connect but if you're looking at this i would highly recommend that you go and look at",
    "start": "1772159",
    "end": "1778640"
  },
  {
    "text": "what existing source connectors and sync connectors there are out there chances are you won't have to write any",
    "start": "1778640",
    "end": "1784000"
  },
  {
    "text": "code you'll just have to run an existing one but all of the connectors are configured so that they are pluggable when it comes",
    "start": "1784000",
    "end": "1790799"
  },
  {
    "text": "to serializing and deserializing and they are pluggable by configuring the converter",
    "start": "1790799",
    "end": "1796559"
  },
  {
    "text": "so again you have one for a key and one for a value because the source and sync connectors",
    "start": "1796559",
    "end": "1802000"
  },
  {
    "text": "they only go in one direction so either you're running from the external system to kafka you're going from",
    "start": "1802000",
    "end": "1808320"
  },
  {
    "text": "instead of having to know whether you're doing serializing or deserializing you just provide a converter and the",
    "start": "1808320",
    "end": "1814480"
  },
  {
    "text": "connector will basically use the right one so if it's pulling from kafka then it'll",
    "start": "1814480",
    "end": "1820720"
  },
  {
    "text": "have to deserialize it and then put it into the external format there are a few that are provided by",
    "start": "1820720",
    "end": "1827039"
  },
  {
    "text": "default for you to use so if you're not using a schema you can use the json converter the string converter or the byte array converter",
    "start": "1827039",
    "end": "1834159"
  },
  {
    "text": "but again it's the same as producing and consuming you need to go to whoever's providing your schema",
    "start": "1834159",
    "end": "1839279"
  },
  {
    "text": "registry or if you've written it yourself you'll need to write a converter and then you run the converter that",
    "start": "1839279",
    "end": "1845279"
  },
  {
    "text": "understands how to talk to the schema registry and look for the ids in the right place",
    "start": "1845279",
    "end": "1851760"
  },
  {
    "text": "the final one is kafka streams so kafka streams is a library it's a java library that",
    "start": "1851760",
    "end": "1857360"
  },
  {
    "text": "allows you to do stream processing you can basically write a very short amount of code and",
    "start": "1857360",
    "end": "1862480"
  },
  {
    "text": "get really complex interesting stream processing happening",
    "start": "1862480",
    "end": "1867679"
  },
  {
    "text": "with kafka streams again for some reason they picked a different term for how you configure the serializing and",
    "start": "1867679",
    "end": "1873600"
  },
  {
    "text": "deserializing so we have for key and value",
    "start": "1873600",
    "end": "1879200"
  },
  {
    "text": "servies is short for serialized serializer but the configuration option for some reason doesn't have the s on the end",
    "start": "1879200",
    "end": "1886799"
  },
  {
    "text": "when you're configuring your kafka streams applications again there are some default ones you can use",
    "start": "1886799",
    "end": "1892640"
  },
  {
    "text": "there's bite array string and integer the interesting thing about the studies",
    "start": "1892640",
    "end": "1897760"
  },
  {
    "text": "for kafka streams is the way streams works is you can do things like pull from one topic",
    "start": "1897760",
    "end": "1903279"
  },
  {
    "text": "and then aggregate things and often it will create sort of smaller topics in between things like",
    "start": "1903279",
    "end": "1908720"
  },
  {
    "text": "that you can actually be very specific about which studies you're using at different points in time",
    "start": "1908720",
    "end": "1914720"
  },
  {
    "text": "so it might be that if you've got quite a complex streams flow that you pull from something that",
    "start": "1914720",
    "end": "1920559"
  },
  {
    "text": "originally had a schema and use your studies for that and then you can kind of",
    "start": "1920559",
    "end": "1925679"
  },
  {
    "text": "change the format of it through and then sort of put it back at the end if you want to",
    "start": "1925679",
    "end": "1930960"
  },
  {
    "text": "so when you're configuring kafka streams app is worth paying attention to what level have you",
    "start": "1930960",
    "end": "1936320"
  },
  {
    "text": "set the studies is it doing the same thing across the whole process or is it changing at some point lower down",
    "start": "1936320",
    "end": "1942480"
  },
  {
    "text": "and again like the others you need to consider your schema registry so most schema registries will provide a",
    "start": "1942480",
    "end": "1948480"
  },
  {
    "text": "studies that you can use that understands how to talk to the schema industry",
    "start": "1948480",
    "end": "1954000"
  },
  {
    "text": "so let's look at an example flow and consider what this means in terms of the",
    "start": "1954480",
    "end": "1961440"
  },
  {
    "text": "magic bytes the headers and the different config options so if i have an external system that is",
    "start": "1961440",
    "end": "1969039"
  },
  {
    "text": "got lots of data in it already so it's a database and i have a connector that is doing change data capture so it's",
    "start": "1969039",
    "end": "1975919"
  },
  {
    "text": "watching the changing databases pulling that data and then putting it into kafka i then",
    "start": "1975919",
    "end": "1981200"
  },
  {
    "text": "have kafka streams app which is processing that data in some way adding something to it aggregating it",
    "start": "1981200",
    "end": "1986320"
  },
  {
    "text": "whatever and then the consumer consuming it if i want to make sure that the data all",
    "start": "1986320",
    "end": "1992559"
  },
  {
    "text": "flows through and uses a schema all the way i have to configure a converter for kafka connect that",
    "start": "1992559",
    "end": "2000880"
  },
  {
    "text": "sets up the schema registry id puts it in the right place i then have to make sure my servies",
    "start": "2000880",
    "end": "2007440"
  },
  {
    "text": "doesn't change that or you know make sure to put it back at the end of the process then i have to use consumer that is also",
    "start": "2007440",
    "end": "2014559"
  },
  {
    "text": "configured to understand this is the format we're using and this is where my schema id is located",
    "start": "2014559",
    "end": "2021279"
  },
  {
    "text": "so what i've often seen people doing is they set up an app a system where they've got",
    "start": "2021279",
    "end": "2026480"
  },
  {
    "text": "maybe a connector and a consumer and they come and say well i've can i configured a producer",
    "start": "2026480",
    "end": "2032000"
  },
  {
    "text": "consumer and my serialized ad serialized worked fine but then when i configured my connector",
    "start": "2032000",
    "end": "2037279"
  },
  {
    "text": "i added the serializer and it i was getting a different message and it's because they didn't realize that",
    "start": "2037279",
    "end": "2042559"
  },
  {
    "text": "they had to configure a converter not a serializer and it's a different class you can't",
    "start": "2042559",
    "end": "2047679"
  },
  {
    "text": "just provide the same class as a converter you have to actually provide a converter class",
    "start": "2047679",
    "end": "2053919"
  },
  {
    "text": "so it's worth being aware of this flow and understanding where is the id that's",
    "start": "2053919",
    "end": "2060638"
  },
  {
    "text": "flowing through so you can help to debug but also does your schema registry that you've chosen support all the application types",
    "start": "2060639",
    "end": "2067358"
  },
  {
    "text": "that you want because some schema registries don't actually have like a surveys or they don't have a",
    "start": "2067359",
    "end": "2073358"
  },
  {
    "text": "converter so you have to make sure everything's available before you set it all up",
    "start": "2073359",
    "end": "2079520"
  },
  {
    "text": "so hopefully that's given you a bit of an overview of why you might want to use schemas and",
    "start": "2079520",
    "end": "2085118"
  },
  {
    "start": "2081000",
    "end": "2166000"
  },
  {
    "text": "how they work in kafka i just want to give a very quick overview of a couple of",
    "start": "2085119",
    "end": "2090158"
  },
  {
    "text": "options first the epicurea registry so this is an open source schema",
    "start": "2090159",
    "end": "2095200"
  },
  {
    "text": "registry it provides all of the format options that i've talked about today it has two different storage options so",
    "start": "2095200",
    "end": "2101839"
  },
  {
    "text": "it's actually not a dedicated kafka schema registry you can store your schemas",
    "start": "2101839",
    "end": "2107359"
  },
  {
    "text": "in kafka itself as a topic if you want to but it also provides postgres sql as well",
    "start": "2107359",
    "end": "2114240"
  },
  {
    "text": "it also has ibm and confluent compatibility apis which i think is a very interesting",
    "start": "2114240",
    "end": "2120320"
  },
  {
    "text": "setup for it because i talked about earlier this whole like needing a converter and 30s",
    "start": "2120320",
    "end": "2126000"
  },
  {
    "text": "and things like that they actually have set up their schema registry so that pretty much any of the existing",
    "start": "2126000",
    "end": "2132560"
  },
  {
    "text": "converters and serializers you might want to use so the epicurea ones the ones that we provide from event streams that i work",
    "start": "2132560",
    "end": "2139200"
  },
  {
    "text": "on and the console ones they all work against africa so that makes it really flexible in",
    "start": "2139200",
    "end": "2145119"
  },
  {
    "text": "terms of what kind of applications you want to run against it if you want to check out the code i've",
    "start": "2145119",
    "end": "2150480"
  },
  {
    "text": "got the link here and these are the different serializers deserializers converters they provide",
    "start": "2150480",
    "end": "2156960"
  },
  {
    "text": "so if you're starting from scratch and you haven't written anything yet you can just use all of their converters",
    "start": "2156960",
    "end": "2162720"
  },
  {
    "text": "and serializers the second one that i did want to mention is the confluence schema",
    "start": "2162720",
    "end": "2167760"
  },
  {
    "start": "2166000",
    "end": "2211000"
  },
  {
    "text": "registry just because that's the other one that we see a lot of people using in event streams the products that",
    "start": "2167760",
    "end": "2174880"
  },
  {
    "text": "i work on we did have our own schema registry but we actually swapped using epicurea recently so that's why i'm not going to",
    "start": "2174880",
    "end": "2181280"
  },
  {
    "text": "talk about our schema registry because it's just epicurean so the confluence schema registry is",
    "start": "2181280",
    "end": "2187839"
  },
  {
    "text": "available under the console and community license so that's it's not a fully open source license so just be aware of that",
    "start": "2187839",
    "end": "2194160"
  },
  {
    "text": "but it does have all of the format options that i talked about today and you can store the schematic in kafka",
    "start": "2194160",
    "end": "2200320"
  },
  {
    "text": "it's designed primarily for use with kafka so where epicurea registry has sort of kafka as one use case the",
    "start": "2200320",
    "end": "2207119"
  },
  {
    "text": "confluent one is designed primarily just for kafka",
    "start": "2207119",
    "end": "2211920"
  },
  {
    "start": "2211000",
    "end": "2248000"
  },
  {
    "text": "so in summary you should definitely think about using schemas to get structure it means that you won't end up in a",
    "start": "2212400",
    "end": "2218720"
  },
  {
    "text": "situation where your producers don't understand your messages anymore and it also means you don't have to pass",
    "start": "2218720",
    "end": "2224640"
  },
  {
    "text": "your schema every single time you want to send an event through the system the schema registry provides that nice",
    "start": "2224640",
    "end": "2231040"
  },
  {
    "text": "centralized store that you can talk to but you need to have a think about what format you want to use",
    "start": "2231040",
    "end": "2236400"
  },
  {
    "text": "and how you want to do that identification mechanism and making sure that your schema registry you've chosen",
    "start": "2236400",
    "end": "2241839"
  },
  {
    "text": "supports all of the different types of applications that you want to use",
    "start": "2241839",
    "end": "2247440"
  },
  {
    "text": "so that was all i had for you today thank you so much for listening i've put a whole set of links on this page so if",
    "start": "2247760",
    "end": "2253920"
  },
  {
    "start": "2248000",
    "end": "2300000"
  },
  {
    "text": "you want sort of another intro or review of schemas then feel free to check out the",
    "start": "2253920",
    "end": "2259119"
  },
  {
    "text": "event stream stocks we've got links for epicurea and consulate and a few getting started links so",
    "start": "2259119",
    "end": "2264800"
  },
  {
    "text": "there's the quick start for kafka if you've never run kafka before strimzy which is the next link down is a",
    "start": "2264800",
    "end": "2270640"
  },
  {
    "text": "operator for kafka so it's kubernetes operator it's open source it's a great project and then the",
    "start": "2270640",
    "end": "2276560"
  },
  {
    "text": "starter app is just a application that i wrote with vertex that's quite a nice sort of first java",
    "start": "2276560",
    "end": "2282160"
  },
  {
    "text": "app if you're looking for a running kafka for the first time thank you very much",
    "start": "2282160",
    "end": "2299280"
  },
  {
    "text": "you",
    "start": "2299280",
    "end": "2301359"
  }
]
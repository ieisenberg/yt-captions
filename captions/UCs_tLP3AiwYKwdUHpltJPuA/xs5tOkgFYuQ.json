[
  {
    "text": "[Applause] so I'm very very happy to be here today",
    "start": "1910",
    "end": "10280"
  },
  {
    "text": "um when I originally submitted my talk abstract I wrote something incredibly",
    "start": "10280",
    "end": "16760"
  },
  {
    "text": "generic and so I hope you bear with me as I talk about something hopefully significantly more interesting um I know",
    "start": "16760",
    "end": "23359"
  },
  {
    "text": "that the audience here is Gage engaged and interested in data processing and I'm assuming you have a bit of awareness",
    "start": "23359",
    "end": "29759"
  },
  {
    "text": "about spark and so what I'm going to be talking about is about is how spark can",
    "start": "29759",
    "end": "34760"
  },
  {
    "text": "fit into realistic machine learning workflows so there's lots of great material out there on how to use spark",
    "start": "34760",
    "end": "41640"
  },
  {
    "text": "in isolation and what I'm interested in talking about today is how if you're a data scientist who's building machine",
    "start": "41640",
    "end": "48239"
  },
  {
    "text": "learning models how spark can realistically fit into your workflows currently so both in model training",
    "start": "48239",
    "end": "55280"
  },
  {
    "text": "model deployment and hopefully you'll find some powerful",
    "start": "55280",
    "end": "60399"
  },
  {
    "text": "useful things in here or at least some funny jokes about pickles",
    "start": "60399",
    "end": "65680"
  },
  {
    "text": "so um spark is a huge project I would say",
    "start": "65680",
    "end": "72320"
  },
  {
    "text": "spark is in fact an ecosystem much like this rainforest where we have core spark which is an inmemory com distributed",
    "start": "72320",
    "end": "78840"
  },
  {
    "text": "computational engine and other pieces of spark that",
    "start": "78840",
    "end": "85320"
  },
  {
    "text": "work together to support a lot of different use cases we have things like spark sequel which is pretty close to core spark at this point because some of",
    "start": "85320",
    "end": "92560"
  },
  {
    "text": "the most flexible useful uh well written parts of spark",
    "start": "92560",
    "end": "97640"
  },
  {
    "text": "rely on spark SQL there's things like spark ml lib which we'll talk a little bit about today which is a machine",
    "start": "97640",
    "end": "102880"
  },
  {
    "text": "learning library that's built inside of spark with some algorithms that are available to you already which depends",
    "start": "102880",
    "end": "108560"
  },
  {
    "text": "on spark SQL spark streaming Graphics I we've heard these things mentioned at different talks throughout the",
    "start": "108560",
    "end": "114680"
  },
  {
    "text": "conference so far so there's a wide ecosystem of what can",
    "start": "114680",
    "end": "120159"
  },
  {
    "text": "use spark with and different use cases you can use it in I'm going to do a brief description of what the spark",
    "start": "120159",
    "end": "125640"
  },
  {
    "text": "execution model looks like before digging into what a real machine learning workflow is and how spark might",
    "start": "125640",
    "end": "133160"
  },
  {
    "text": "fit into that so the spark execution uh Paradigm is that you write",
    "start": "133160",
    "end": "140040"
  },
  {
    "text": "a spark program that spark program gets executed on a driver a driver is a node",
    "start": "140040",
    "end": "146040"
  },
  {
    "text": "that's near you can be an edge node of a cluster or can be your own laptop that driver program creates a spark",
    "start": "146040",
    "end": "152440"
  },
  {
    "text": "context and the spark context is what is used to interact with and orchestrate",
    "start": "152440",
    "end": "157920"
  },
  {
    "text": "the rest of the worker nodes which are worker nodes that are actually executed on the cluster so the worker nodes spin",
    "start": "157920",
    "end": "163360"
  },
  {
    "text": "up executors which are the processes that are going to do work on the cluster for you and those executors are going to",
    "start": "163360",
    "end": "169400"
  },
  {
    "text": "have parallel threads working which are going to operate on tasks this might be splits of the data so you might have a",
    "start": "169400",
    "end": "175239"
  },
  {
    "text": "huge file inside of hop or S3 and that's partitioned into block blocks and you'll",
    "start": "175239",
    "end": "180400"
  },
  {
    "text": "process those as Tas separately a use case that I'm going to talk about is doing massively parallel",
    "start": "180400",
    "end": "187360"
  },
  {
    "text": "model fitting and in that case you're using the same input data but you have",
    "start": "187360",
    "end": "192720"
  },
  {
    "text": "multiple processes Because the actual process of model training is going to be slightly different between each of those",
    "start": "192720",
    "end": "199519"
  },
  {
    "text": "tasks those executors are performing so that's very briefly the",
    "start": "199519",
    "end": "206680"
  },
  {
    "text": "ecosystem that spark exists in and the spark execution model now what I think is a little more",
    "start": "206680",
    "end": "214040"
  },
  {
    "text": "fun than and this is my bias to having a background in mathematics then I think",
    "start": "214040",
    "end": "219760"
  },
  {
    "text": "it's a bit more fun than just talking about the platform that spark provides is what is the real thing that we're",
    "start": "219760",
    "end": "225080"
  },
  {
    "text": "trying to do what is the real thing we're trying to build so let's say that I'm hypothetically a",
    "start": "225080",
    "end": "232920"
  },
  {
    "text": "data scientist and I want to build some sort of predictive model I usually have some amount of historic data that",
    "start": "232920",
    "end": "239840"
  },
  {
    "text": "historic data exists in a database somewhere I'm going to do some sort of process that then generates a model and",
    "start": "239840",
    "end": "246680"
  },
  {
    "text": "if I want to use that model ever again I'm probably going to need to save it somewhere so in this diagram I've I've",
    "start": "246680",
    "end": "253480"
  },
  {
    "text": "colored blue green the the pieces of it that are data that is written somewhere",
    "start": "253480",
    "end": "260919"
  },
  {
    "text": "and the white blocks are the processes so it's some sort of computational process that happens so model training",
    "start": "260919",
    "end": "268880"
  },
  {
    "text": "is almost vacuous ly defined as the thing that fits historic data together",
    "start": "268880",
    "end": "274840"
  },
  {
    "text": "with your model that you actually write down somewhere and then once we've trained this model we don't just pretend",
    "start": "274840",
    "end": "281160"
  },
  {
    "text": "it never existed and go away right we want to deploy this into production we actually want to use it in the real",
    "start": "281160",
    "end": "287600"
  },
  {
    "text": "world so part of my introduction was that I lead data science for the engineering",
    "start": "287600",
    "end": "294000"
  },
  {
    "text": "team at Cloud era but a previous role that I had at Cloud era was interacting with our customers and",
    "start": "294000",
    "end": "300280"
  },
  {
    "text": "trying to advise and guide them on how to take their current practices and fit",
    "start": "300280",
    "end": "306759"
  },
  {
    "text": "that in with different tools they might be interested in exploring or just generally advise them on how to build",
    "start": "306759",
    "end": "313400"
  },
  {
    "text": "good production systems if they're trying to get their data science team to a certain place and so a fair amount of this talk a fair amount of this advising",
    "start": "313400",
    "end": "320720"
  },
  {
    "text": "was focused on what it means to productionize a model and what I've realized is that when people or",
    "start": "320720",
    "end": "327680"
  },
  {
    "text": "companies talk about productionizing machine learning models they can mean a huge variety of things and so the reason",
    "start": "327680",
    "end": "336120"
  },
  {
    "text": "that I have these like Star call out back boxes for new data and model result is that I've seen a variety of ways that",
    "start": "336120",
    "end": "344520"
  },
  {
    "text": "this shows up so this could be new data could be coming into your model scoring system through a rest like an HTTP",
    "start": "344520",
    "end": "353120"
  },
  {
    "text": "request rest call to the rest server it could be that you have a nightly batched",
    "start": "353120",
    "end": "360400"
  },
  {
    "text": "job that gets executed on a database and you're writing a file out somewhere I've seen both of these use cases called",
    "start": "360400",
    "end": "366000"
  },
  {
    "text": "putting things in a production and so when it comes to fitting spark into this",
    "start": "366000",
    "end": "372720"
  },
  {
    "text": "workflow you have to both think about how you're persisting your model and what two pieces you're trying to connect",
    "start": "372720",
    "end": "379440"
  },
  {
    "text": "what what the new data is and what the result is going to be so this is just a",
    "start": "379440",
    "end": "385479"
  },
  {
    "text": "very generic sort of workflow and I'm going to talk a little more concretely",
    "start": "385479",
    "end": "391120"
  },
  {
    "text": "about what it means when we have more specific pieces that fit in here but first I want to focus on this",
    "start": "391120",
    "end": "397479"
  },
  {
    "text": "model training step did you like how I just sort of pointed at this and I was like model training",
    "start": "397479",
    "end": "402599"
  },
  {
    "text": "simple um I want to zoom in a little bit on the model training step so frequently",
    "start": "402599",
    "end": "409440"
  },
  {
    "text": "when we have historic data the first thing we're going to do is we're going to take our data we're going to take a small percentage of it and set it aside",
    "start": "409440",
    "end": "415879"
  },
  {
    "text": "and not look at it until we think we're done and we're done with our model right so this is going to be our completely",
    "start": "415879",
    "end": "422919"
  },
  {
    "text": "blind to us test set then we're going to have data that is our training data we",
    "start": "422919",
    "end": "428120"
  },
  {
    "text": "take this training data we're going to do some sort of maybe pre-processing",
    "start": "428120",
    "end": "434360"
  },
  {
    "text": "change this raw data into features that get fed into a numerical algorithm that estimates parameters in a machine",
    "start": "434360",
    "end": "440080"
  },
  {
    "text": "learning model and those series of steps combined",
    "start": "440080",
    "end": "445680"
  },
  {
    "text": "together to be this machine learning pipeline or model generation step where",
    "start": "445680",
    "end": "452280"
  },
  {
    "text": "at the end of that we have this model that we can write out somewhere where we say well when I get data in I you know",
    "start": "452280",
    "end": "461440"
  },
  {
    "text": "tokenize the strings and then I do TF IDF and then I do some sort of",
    "start": "461440",
    "end": "468960"
  },
  {
    "text": "classification on this text and from those series of steps you can fully describe what it means to both train the",
    "start": "468960",
    "end": "474680"
  },
  {
    "text": "model and to actually apply that model to new data so we'll",
    "start": "474680",
    "end": "479960"
  },
  {
    "text": "we'll describe those pipelines we'll fit any sort of estimated parameters we need in there and then we'll write out this",
    "start": "479960",
    "end": "486440"
  },
  {
    "text": "persistent model somewhere and we'll want to usually do",
    "start": "486440",
    "end": "491599"
  },
  {
    "text": "this in a both iterative way where we're testing and doing cross validation on that training set that we have until we",
    "start": "491599",
    "end": "498120"
  },
  {
    "text": "get to a point that that we feel pretty good that the evaluation metrics that we're using for our models are",
    "start": "498120",
    "end": "503599"
  },
  {
    "text": "performing well so this could be any number of things it could be the Precision the recall the area under the",
    "start": "503599",
    "end": "508680"
  },
  {
    "text": "Precision recall curve the area under the receiver operator characteristic right um choose your favorite one but",
    "start": "508680",
    "end": "514518"
  },
  {
    "text": "there's some sort of evaluation that you're doing and usually some sort of cross validation beyond that when you're",
    "start": "514519",
    "end": "520880"
  },
  {
    "text": "describing these models you usually also have these hyperparameters that can describe what the model training is and",
    "start": "520880",
    "end": "528560"
  },
  {
    "text": "what it looks like right and so this is not a single step where you say okay",
    "start": "528560",
    "end": "533680"
  },
  {
    "text": "I've fully described the best model I'm going to run it once see what the statistics are and say like yes sure",
    "start": "533680",
    "end": "540120"
  },
  {
    "text": "this this evaluation metric is good enough for me usually you continually refine your model until it's",
    "start": "540120",
    "end": "547200"
  },
  {
    "text": "at a place that you need it to be in terms of precision or accuracy whatever it is you need",
    "start": "547200",
    "end": "554959"
  },
  {
    "text": "so these multiple steps so the featurization the model training and",
    "start": "554959",
    "end": "561079"
  },
  {
    "text": "then being able to take that and do say cross validation or grid search with it requires pipelining and so pipelining",
    "start": "561079",
    "end": "568200"
  },
  {
    "text": "ends up being a really important Concept in various machine learning libraries",
    "start": "568200",
    "end": "574160"
  },
  {
    "text": "and it's one that a lot of API built for machine learning have moved towards and",
    "start": "574160",
    "end": "579320"
  },
  {
    "text": "so that is very very related to being able to do cross validation well so",
    "start": "579320",
    "end": "584560"
  },
  {
    "text": "train your model in one way and then know that you're applying that same trained model on your",
    "start": "584560",
    "end": "589920"
  },
  {
    "text": "new uh test set and that ends up also being",
    "start": "589920",
    "end": "596640"
  },
  {
    "text": "incredibly useful and valuable in production so I have know a huge number of data",
    "start": "596640",
    "end": "603720"
  },
  {
    "text": "scientists and data engineers at various companies that built data products that if there's a split between the data",
    "start": "603720",
    "end": "609560"
  },
  {
    "text": "scientists and the people putting machine learning models in production they run into this issue where a data scientist will make a model and then",
    "start": "609560",
    "end": "616240"
  },
  {
    "text": "they'll put the wrong one into production so being able to validate that the thing that you actually made is",
    "start": "616240",
    "end": "621360"
  },
  {
    "text": "the thing that is getting run is a valuable thing because it's a mistake that you're like oh no no no when I talk",
    "start": "621360",
    "end": "627360"
  },
  {
    "text": "about a model I know it was that model being able to identify to know that the thing that you made is the thing that gets run in every situation is actually",
    "start": "627360",
    "end": "635079"
  },
  {
    "text": "challenging and so that's why a lot of these apis end up trying to focus on",
    "start": "635079",
    "end": "640560"
  },
  {
    "text": "this pipeline concept and making sure that the thing that you fit is the thing you're actually",
    "start": "640560",
    "end": "646560"
  },
  {
    "text": "applying so talking about generics is all well and",
    "start": "647120",
    "end": "652240"
  },
  {
    "text": "good uh I will try not to be super generic and",
    "start": "652240",
    "end": "659519"
  },
  {
    "text": "instead now get a little bit more concrete because I think getting the abstractions",
    "start": "659519",
    "end": "667639"
  },
  {
    "text": "correct for machine learning ends up being a big mouthful and it's a lot more interesting to talk about something",
    "start": "667639",
    "end": "674639"
  },
  {
    "text": "realistic so the realistic thing that I want to talk about is customer turn",
    "start": "677480",
    "end": "683360"
  },
  {
    "text": "prediction so I like this for a few reasons and the primary one is it's",
    "start": "683360",
    "end": "689360"
  },
  {
    "text": "relatively easy for me to explain and I'm a pretty lazy speaker so I'm glad that I just get to briefly explain this",
    "start": "689360",
    "end": "695480"
  },
  {
    "text": "to you and the second one that I think is also",
    "start": "695480",
    "end": "700519"
  },
  {
    "text": "important and valuable is this is a problem that I've done with cl's customers a few times it comes up again",
    "start": "700519",
    "end": "707079"
  },
  {
    "text": "and again it's ubiquitous if you have any kind of subscription model people are interested in turn",
    "start": "707079",
    "end": "713200"
  },
  {
    "text": "prediction so let's say we have three customers we have ex President Barack",
    "start": "713200",
    "end": "718320"
  },
  {
    "text": "Obama we have have a child and we have a baby with a phone and we want to know if",
    "start": "718320",
    "end": "725560"
  },
  {
    "text": "next month these customers of ours are still going to be customers of ours so",
    "start": "725560",
    "end": "731360"
  },
  {
    "text": "the ex president will still be a customer of ours the young girl will still be a customer of ours but that",
    "start": "731360",
    "end": "736680"
  },
  {
    "text": "baby doesn't need a phone line so it's going to stop paying us right and we should be able to predict that and so",
    "start": "736680",
    "end": "742839"
  },
  {
    "text": "the example that I'm going to use is from the UCI machine learning library you can go get this data set if you want",
    "start": "742839",
    "end": "749519"
  },
  {
    "text": "um I have some code examples online which if you ask me after the talk I can",
    "start": "749519",
    "end": "755040"
  },
  {
    "text": "point you to for some of the things I'm going to point out but I haven't I don't have it all implemented",
    "start": "755040",
    "end": "760680"
  },
  {
    "text": "for exactly this problem I have it for some of it so ask me about that later",
    "start": "760680",
    "end": "767040"
  },
  {
    "text": "this data set's pretty simple each line is an individual it's a customer of ours we have information",
    "start": "767040",
    "end": "774079"
  },
  {
    "text": "about what US state they're in their phone number whether or not they subscribe to an international plan how",
    "start": "774079",
    "end": "780519"
  },
  {
    "text": "many minutes they've used uh Day evening night bunch of",
    "start": "780519",
    "end": "786320"
  },
  {
    "text": "numeric values bunch of categorical values and then the very last column is whether or not they churn or not so this",
    "start": "786320",
    "end": "793320"
  },
  {
    "text": "is a very straightforward supervised learning problem we have labels we want to be able to predict these labels and",
    "start": "793320",
    "end": "799399"
  },
  {
    "text": "test that we're doing well in the future so we're going to make some pipelines",
    "start": "799399",
    "end": "804680"
  },
  {
    "text": "this data set is not very large I can download it very easily over the internet from the UCI machine learning",
    "start": "804680",
    "end": "811320"
  },
  {
    "text": "library so the first thing I probably want to do is just use S kit learn this",
    "start": "811320",
    "end": "816360"
  },
  {
    "text": "is realistic right this Mach this data set fits in memory it doesn't take that long to train a single model for it and",
    "start": "816360",
    "end": "823800"
  },
  {
    "text": "so what I'm going to do is I'm going to use a gradient boosting classifier these things tend to perform",
    "start": "823800",
    "end": "829680"
  },
  {
    "text": "really well and psychic learn already has it implemented so that's great I have some magical function called get",
    "start": "829680",
    "end": "836320"
  },
  {
    "text": "data which returns to me X which is all the future vectors and Y which are the",
    "start": "836320",
    "end": "841759"
  },
  {
    "text": "labels that I'm going to try and predict from there to create a gradient boosted classifier split",
    "start": "841759",
    "end": "849079"
  },
  {
    "text": "my uh my data set that I'm training it on into a train and test split for this",
    "start": "849079",
    "end": "854600"
  },
  {
    "text": "particular instance of building a model and then I'm going to fit the model to",
    "start": "854600",
    "end": "860440"
  },
  {
    "text": "the training data apply it to the testing features and eventually get some sort of",
    "start": "860440",
    "end": "867800"
  },
  {
    "text": "evaluation metric of how well my model performed this is all well and good and",
    "start": "867800",
    "end": "872920"
  },
  {
    "text": "you can see two very uh pertinent things about this gradient booted classifier it",
    "start": "872920",
    "end": "878199"
  },
  {
    "text": "has a function called fit and a function called transform and transform doesn't make any",
    "start": "878199",
    "end": "884079"
  },
  {
    "text": "sense to call until you have fit the model so this is exactly what defines a",
    "start": "884079",
    "end": "889639"
  },
  {
    "text": "pipeline or a thing that has a characteristic of a pipeline it has a fit method and a transform",
    "start": "889639",
    "end": "895399"
  },
  {
    "text": "method this almost makes sense except if you you go back and look at the data set",
    "start": "895399",
    "end": "901360"
  },
  {
    "text": "there are categorical variables I haven't really dealt with there are these labels that are true and false",
    "start": "901360",
    "end": "908279"
  },
  {
    "text": "which actually in the gradi btic classifier it's expected that they're zeros or ones and so there's processing",
    "start": "908279",
    "end": "913880"
  },
  {
    "text": "that I need to do in order to actually get it to a stage where I can use this gradient to classifier so instead I'm going to",
    "start": "913880",
    "end": "920199"
  },
  {
    "text": "create a pipeline which has these steps in it so in this pipeline I'm again I'm going to get the data I'm going to do",
    "start": "920199",
    "end": "927120"
  },
  {
    "text": "things like one hot encoding where for categorical variables if I have say 50",
    "start": "927120",
    "end": "933920"
  },
  {
    "text": "different possible values for each of the US states I'm instead going to create a vector that gets appended to",
    "start": "933920",
    "end": "939360"
  },
  {
    "text": "this feature Vector that has that is either zero or one depending on what value it's",
    "start": "939360",
    "end": "946440"
  },
  {
    "text": "taking so it's kind of like a a pivot table but like a binary pivot table and then I create this pipeline",
    "start": "946440",
    "end": "953240"
  },
  {
    "text": "that says okay I'm going to take my input Vector I'm going to transform it in this way going to fit this model and",
    "start": "953240",
    "end": "958600"
  },
  {
    "text": "this line you can see I'm doing exactly the same thing so the where I had just",
    "start": "958600",
    "end": "963880"
  },
  {
    "text": "the machine learning model before that had that fit and transform method this pipeline now has the fit and transform",
    "start": "963880",
    "end": "969360"
  },
  {
    "text": "method and so I can use it uh very easily here great now sparkl lib uh sparkl lib",
    "start": "969360",
    "end": "980880"
  },
  {
    "text": "has had has evolved quite a bit in the last year or two and at this point spark ml lib has taken a huge",
    "start": "980880",
    "end": "988519"
  },
  {
    "text": "amount of inspiration from the pyit learn API spark MLB similarly relies on",
    "start": "988519",
    "end": "994399"
  },
  {
    "text": "pipelines where the thing that you create this pipeline has a series of steps and operations on your data and",
    "start": "994399",
    "end": "1001480"
  },
  {
    "text": "this pipeline has both fit and transform methods so this is just an example that's a screenshot from their",
    "start": "1001480",
    "end": "1007440"
  },
  {
    "text": "documentation where people are trying to create some sort of classifier on text and they have",
    "start": "1007440",
    "end": "1013920"
  },
  {
    "text": "featurization steps like tokenizing so going from a string to a collection of",
    "start": "1013920",
    "end": "1020519"
  },
  {
    "text": "words hashing so going from a collection of words to a feature vector and then",
    "start": "1020519",
    "end": "1027120"
  },
  {
    "text": "going from a feature Vector to a fit model that has parameters in it that can tell you whether or not a certain",
    "start": "1027120",
    "end": "1033400"
  },
  {
    "text": "feature Vector is of one type or another type so an interesting part of ml lib",
    "start": "1033400",
    "end": "1041199"
  },
  {
    "text": "like I mentioned is that ml lib lives in this ecosystem of spark and the newest",
    "start": "1041199",
    "end": "1046640"
  },
  {
    "text": "version of ml lib which is confusingly moved from the ml lib package to the ml package is that it",
    "start": "1046640",
    "end": "1055559"
  },
  {
    "text": "fits in and integrates very closely with spark SQL and so all of your operations",
    "start": "1055559",
    "end": "1061000"
  },
  {
    "text": "in your pipeline are transforming columns in a spark SQL table which is",
    "start": "1061000",
    "end": "1066039"
  },
  {
    "text": "basically a data frame like object that is a distributed data frame that spark is operating",
    "start": "1066039",
    "end": "1072160"
  },
  {
    "text": "with so in this ml pipeline example I create these Transformers which is which",
    "start": "1072160",
    "end": "1078919"
  },
  {
    "text": "is these string indexers so this is again a one hot en coding kind of thing",
    "start": "1078919",
    "end": "1085480"
  },
  {
    "text": "where we're taking you know whether a label of whether or not they're churned or not whether or not they're International",
    "start": "1085480",
    "end": "1091559"
  },
  {
    "text": "they have an international plan or not and then creating a feature Vector with",
    "start": "1091559",
    "end": "1097840"
  },
  {
    "text": "this Vector assembler and then fitting a decision tree classifier so at the very end we",
    "start": "1097840",
    "end": "1104520"
  },
  {
    "text": "create this pipeline that has stages in order where we do some featurization",
    "start": "1104520",
    "end": "1109600"
  },
  {
    "text": "like indexing those categorical variables we assemble them into a feature vector and then we have a",
    "start": "1109600",
    "end": "1115559"
  },
  {
    "text": "classifier and so again we're just Define these pipelines that we can use in a few contexts so I did it very",
    "start": "1115559",
    "end": "1121960"
  },
  {
    "text": "manually in the sense of it doing a test train split in previous examples but you can imagine that this pipeline concept",
    "start": "1121960",
    "end": "1129400"
  },
  {
    "text": "allows you to do cross validation very very easily so now that we've defined these",
    "start": "1129400",
    "end": "1137880"
  },
  {
    "text": "Pipelines train these models we're going to deploy them great but what does it",
    "start": "1137880",
    "end": "1144640"
  },
  {
    "text": "mean to deploy it there's a few things that fit into a discussion about",
    "start": "1144640",
    "end": "1150919"
  },
  {
    "text": "deploying a fit model the first is how you've persisted",
    "start": "1150919",
    "end": "1156000"
  },
  {
    "text": "that model you don't just sort of fit a model have it in memory and feel good about that",
    "start": "1156000",
    "end": "1162440"
  },
  {
    "text": "right it's not an abstract concept where once you've seen the evaluation metrics you're like oh yes this is a thing that",
    "start": "1162440",
    "end": "1168159"
  },
  {
    "text": "exists now all right you actually need to persist and write down that model somewhere and given that you've written",
    "start": "1168159",
    "end": "1174799"
  },
  {
    "text": "down that model somewhere you need to be able to read that model again in your model scoring system and that model",
    "start": "1174799",
    "end": "1180559"
  },
  {
    "text": "scoring system could be a number of things depending on what you expect your input data to be and what you expect your output data to",
    "start": "1180559",
    "end": "1187000"
  },
  {
    "text": "be so let's talk about persistence first question is how did",
    "start": "1187000",
    "end": "1192679"
  },
  {
    "text": "you save your model you have a few options people that are already familiar",
    "start": "1192679",
    "end": "1198360"
  },
  {
    "text": "with p Pyon probably heard of pickle or JB these are ways of just dumping python",
    "start": "1198360",
    "end": "1204720"
  },
  {
    "text": "objects into bites and being able to read those bites back again there's a format called pmml which if you have a",
    "start": "1204720",
    "end": "1212720"
  },
  {
    "text": "visceral reaction to XML it's not going to make you feel good but it's incredibly consistent it's",
    "start": "1212720",
    "end": "1223720"
  },
  {
    "text": "more human readable than a pile of bites and it doesn't have a lot of the flaws that I'll talk about with respect to",
    "start": "1223720",
    "end": "1229600"
  },
  {
    "text": "pickles and uh job lib fourth option is to do something",
    "start": "1229600",
    "end": "1235799"
  },
  {
    "text": "Custom Custom is feasible a lot of people do this it is very challenging",
    "start": "1235799",
    "end": "1243600"
  },
  {
    "text": "and before you go and do something custom for your model serialization I would strongly encourage",
    "start": "1243600",
    "end": "1250039"
  },
  {
    "text": "you to look at the pros and cons of pickling jobb and pmml because these are",
    "start": "1250039",
    "end": "1256320"
  },
  {
    "text": "systems that people have thought about a lot and written about the tradeoffs in",
    "start": "1256320",
    "end": "1262039"
  },
  {
    "text": "them and seriously take those into consideration before you build a custom system because they have listed very",
    "start": "1262039",
    "end": "1269039"
  },
  {
    "text": "well the types of issues people run into",
    "start": "1269039",
    "end": "1274080"
  },
  {
    "text": "so there's this really great talk if you use Python a lot that's called pickles",
    "start": "1274080",
    "end": "1279279"
  },
  {
    "text": "are Fidelis and it's from Pon in 2014 I",
    "start": "1279279",
    "end": "1284760"
  },
  {
    "text": "think where an engineer talks about some of the issues that pickling objects",
    "start": "1284760",
    "end": "1291360"
  },
  {
    "text": "presents so pickling an object basically means you open up a file handle you say",
    "start": "1291360",
    "end": "1297000"
  },
  {
    "text": "hey dump this object out over there and then it does it and later on you can unpickle it by saying like hey here's a",
    "start": "1297000",
    "end": "1303080"
  },
  {
    "text": "file give me that object back there's a lot of issues with pickling",
    "start": "1303080",
    "end": "1308320"
  },
  {
    "text": "whoa there we go there's a lot of issues with pickling first of all it's not secure at all it's very easy for a",
    "start": "1308320",
    "end": "1316080"
  },
  {
    "text": "malicious attack to be put into a pickled object there are very um funny examples of this that have been put",
    "start": "1316080",
    "end": "1321799"
  },
  {
    "text": "online where it's like look if you pickle and unpickle this thing it'll delete all the files in your computer",
    "start": "1321799",
    "end": "1326960"
  },
  {
    "text": "like this example that we put here asks for you to confirm each file that we're going to delete but if you changed one",
    "start": "1326960",
    "end": "1334400"
  },
  {
    "text": "letter so it's not secure it's not portable so pickling an",
    "start": "1334400",
    "end": "1340679"
  },
  {
    "text": "object is very dependent on the CPU architecture you're actually working on and so if you were to take this pickled",
    "start": "1340679",
    "end": "1347279"
  },
  {
    "text": "file and move it to a different computer you don't have a guarantee it would continue to work in the way that you would expect it to which seems like a",
    "start": "1347279",
    "end": "1354120"
  },
  {
    "text": "drawback to me similarly pickling objects can be very big like much larger uh than you",
    "start": "1354120",
    "end": "1362279"
  },
  {
    "text": "would expect the serialized object to be and because of that it can actually also be very slow um this is something that",
    "start": "1362279",
    "end": "1368640"
  },
  {
    "text": "jobb kind of works around the big and slow part but not that well it still has",
    "start": "1368640",
    "end": "1374679"
  },
  {
    "text": "issues with security and portability similarly the portability issue comes up with using two different versions of",
    "start": "1374679",
    "end": "1380919"
  },
  {
    "text": "python or having two different environments of python on different machines you don't really know if these things are going to perform the same",
    "start": "1380919",
    "end": "1388080"
  },
  {
    "text": "way so pickling is problematic I personally would not recommend it for",
    "start": "1388080",
    "end": "1393799"
  },
  {
    "text": "production deployment systems you could do something custom",
    "start": "1393799",
    "end": "1398960"
  },
  {
    "text": "but I want to talk about something concrete so we're going to talk about pmml instead and I actually I don't have",
    "start": "1398960",
    "end": "1405120"
  },
  {
    "text": "the visceral reaction to XML that a lot of people have I think it's fine it's very consistent you can kind of read it",
    "start": "1405120",
    "end": "1410640"
  },
  {
    "text": "it's a little horrifying files are a little long but uh it at least doesn't",
    "start": "1410640",
    "end": "1415720"
  },
  {
    "text": "have issues that pickling does so we can store models as",
    "start": "1415720",
    "end": "1421200"
  },
  {
    "text": "pmml it's relatively easy to do this this is something a lot of people want to do and there are a lot of libraries",
    "start": "1421200",
    "end": "1427320"
  },
  {
    "text": "that either exist out there that are that exist out there and integrate withs kit learn or inside of spark ml lib so",
    "start": "1427320",
    "end": "1435240"
  },
  {
    "text": "there's some functionality for certain types of functions to export them as pmml so at the Top Line in MLB if it's the",
    "start": "1435240",
    "end": "1443720"
  },
  {
    "text": "right you the right combination of types of machine learning models you can just say hey two pmml and give it a file",
    "start": "1443720",
    "end": "1450360"
  },
  {
    "text": "handle and it'll export a pmml file for you similarly there's outside libraries",
    "start": "1450360",
    "end": "1456400"
  },
  {
    "text": "that integrate with spark ml lib and will export more things that are built into spark ml Libs pmml export",
    "start": "1456400",
    "end": "1465720"
  },
  {
    "text": "functionality flip side of this is that there's also outside libraries for pyit learn that",
    "start": "1465720",
    "end": "1471600"
  },
  {
    "text": "will allow you to export pyit learn models as pmml as you might have noticed I was",
    "start": "1471600",
    "end": "1477919"
  },
  {
    "text": "saying if you have the right type of machine learning function in spark ml",
    "start": "1477919",
    "end": "1482960"
  },
  {
    "text": "lib you can export as pmml this is the very long list of available",
    "start": "1482960",
    "end": "1488120"
  },
  {
    "text": "functions and so I think one of the more obvious drawbacks of spark MLB is",
    "start": "1488120",
    "end": "1495960"
  },
  {
    "text": "that in general there's less models available to you than there would be in a lot of other systems and then when it",
    "start": "1495960",
    "end": "1502399"
  },
  {
    "text": "comes to certain functionality of MLB there's even smaller collections so these are the only models you can",
    "start": "1502399",
    "end": "1509360"
  },
  {
    "text": "export so the example that I had where I was using a decision tree which I mean I wouldn't actually use in production",
    "start": "1509440",
    "end": "1514760"
  },
  {
    "text": "anyway but the example I had I wouldn't even be able to export in pmml because it's not supported here though there are",
    "start": "1514760",
    "end": "1520480"
  },
  {
    "text": "some outside libraries which might allow it so great we have an understanding of how",
    "start": "1520480",
    "end": "1529720"
  },
  {
    "text": "a machine learning modeling workflow works and now we want to see how spark might be able to fit into this actually",
    "start": "1529720",
    "end": "1537240"
  },
  {
    "text": "I don't know if you all want to see it but I'm going to talk about it anyway so so the modeling life",
    "start": "1537240",
    "end": "1545320"
  },
  {
    "text": "cycle we're back here again and what we're interested in distributing in this",
    "start": "1545320",
    "end": "1552279"
  },
  {
    "text": "case is going to be model training and so particularly in the model training life cycle the thing we're going to",
    "start": "1552279",
    "end": "1557360"
  },
  {
    "text": "distribute is the model fitting so this is the type of situation that you run into and it's sort of a classic",
    "start": "1557360",
    "end": "1563840"
  },
  {
    "text": "application of ml lip where what we have is our historic data is very large the",
    "start": "1563840",
    "end": "1570279"
  },
  {
    "text": "input data that we want to train our model on is huge it exists as a huge pile of files on S3 or somewhere in our",
    "start": "1570279",
    "end": "1575760"
  },
  {
    "text": "Hadoop cluster and our model pipeline we want to be in MLB and be able to distribute",
    "start": "1575760",
    "end": "1582399"
  },
  {
    "text": "and have all of this uh data used to inform our estimates",
    "start": "1582399",
    "end": "1590240"
  },
  {
    "text": "so what this looks like is what I already showed you it's relatively easy we have pipeline stages we execute these",
    "start": "1590520",
    "end": "1597200"
  },
  {
    "text": "pipeline stages we can do cross validation it'll report metrics to us um",
    "start": "1597200",
    "end": "1602520"
  },
  {
    "text": "this is the example that I have online and it's very uh accessible and you can ask me",
    "start": "1602520",
    "end": "1607720"
  },
  {
    "text": "for a link lator great we can fit a big model there's plenty of people out there that will explain to you in great deal how to",
    "start": "1607720",
    "end": "1613919"
  },
  {
    "text": "use ml to fit a big distributed model what else can we do how how else can spark fit into our machine learning",
    "start": "1613919",
    "end": "1621360"
  },
  {
    "text": "workflows well it can fit into model training again",
    "start": "1621360",
    "end": "1627640"
  },
  {
    "text": "but slightly different way this time when we're doing model training we're",
    "start": "1627640",
    "end": "1632720"
  },
  {
    "text": "really doing that process of fitting in a model and evaluating it and again and",
    "start": "1632720",
    "end": "1638720"
  },
  {
    "text": "again and again but with slightly different parameters each time right as",
    "start": "1638720",
    "end": "1644360"
  },
  {
    "text": "we iterate we're changing some things to see if we're going to produce a better model model",
    "start": "1644360",
    "end": "1650760"
  },
  {
    "text": "so when we change these things like the type of",
    "start": "1650760",
    "end": "1656679"
  },
  {
    "text": "uh like if we want to do lassu or rid regression or use some sort of smaller",
    "start": "1656679",
    "end": "1663039"
  },
  {
    "text": "different hyper parameter we're going to need to to produce a bunch of these models and we can do this",
    "start": "1663039",
    "end": "1669759"
  },
  {
    "text": "serially uh thanks for the light chuckle that's all I expect out of a slide about serial boxes",
    "start": "1670480",
    "end": "1678399"
  },
  {
    "text": "um where one after another going to fit these models and what that ends up",
    "start": "1678399",
    "end": "1685519"
  },
  {
    "text": "looking like is something like this where we have grid search CV which is basically",
    "start": "1685519",
    "end": "1693320"
  },
  {
    "text": "heyit learn I want you to do cross validation and give me some of these evaluation metrics for my model and I'm",
    "start": "1693320",
    "end": "1699640"
  },
  {
    "text": "going to give you a bunch of parameters and you should figure out every combination of parameters and test them",
    "start": "1699640",
    "end": "1705039"
  },
  {
    "text": "all so in this one I just have two different loss functions that I want to compare but you can imagine that as you",
    "start": "1705039",
    "end": "1711120"
  },
  {
    "text": "begin to have uh more parameters that you want to compare in each of these",
    "start": "1711120",
    "end": "1718080"
  },
  {
    "text": "types of parameters you get the cross product of all of these combinations and it ends up being quite a bit of work to",
    "start": "1718080",
    "end": "1724559"
  },
  {
    "text": "do this search but let's start with two and so we need to fit these two models we",
    "start": "1724559",
    "end": "1731760"
  },
  {
    "text": "again Define uh some pipeline that we want and so here I'm just using",
    "start": "1731760",
    "end": "1737200"
  },
  {
    "text": "classifier again to make this slide short but it could be a much longer pipeline that I've described I put in",
    "start": "1737200",
    "end": "1742440"
  },
  {
    "text": "this grid search CV I tell it what it's my parameter grid is it's like hey here's a list of parameters I want to",
    "start": "1742440",
    "end": "1747880"
  },
  {
    "text": "try out um tell me what happens after this I fit it and then after the fitting",
    "start": "1747880",
    "end": "1755440"
  },
  {
    "text": "on this grid search TV there's an attribute called best estimator which will tell you which one of these models",
    "start": "1755440",
    "end": "1762480"
  },
  {
    "text": "actually is the best which collection of parameters combined with your pipeline produces the best results fantastic",
    "start": "1762480",
    "end": "1769120"
  },
  {
    "text": "but kind of slow especially if we have hundreds or thousands of these things that we want to search through so",
    "start": "1769120",
    "end": "1775799"
  },
  {
    "text": "perhaps we can run this in parallel like I'm not even talking about a cluster I mean we just have a single node what if",
    "start": "1775799",
    "end": "1781600"
  },
  {
    "text": "we run these next to each other well in Python it's possible to have",
    "start": "1781600",
    "end": "1787480"
  },
  {
    "text": "parallel execution on a single node and it is somewhat gnarly uh there's this horrible thing",
    "start": "1787480",
    "end": "1794240"
  },
  {
    "text": "that people like to not talk about called the G the global interpreter lock and I shouldn't call it horrible because",
    "start": "1794240",
    "end": "1800320"
  },
  {
    "text": "it prevents a lot of other problems we could run into anyway but there is a way to keep a lock on The",
    "start": "1800320",
    "end": "1810159"
  },
  {
    "text": "Interpreter and trade that between processes and that is what happens you",
    "start": "1810159",
    "end": "1816360"
  },
  {
    "text": "can get pyit learn to do this and what we end up doing in order to actually use",
    "start": "1816360",
    "end": "1822679"
  },
  {
    "text": "it has nothing to do with us having to have any knowledge of the global interpreter lock",
    "start": "1822679",
    "end": "1829960"
  },
  {
    "text": "um but it does require us to know that okay we have these parameters we can set which is end jobs which is basically how",
    "start": "1830440",
    "end": "1838559"
  },
  {
    "text": "many uh how many jobs in general do you want to have",
    "start": "1838559",
    "end": "1844840"
  },
  {
    "text": "running wait about this how many do you want to have running s",
    "start": "1844840",
    "end": "1850480"
  },
  {
    "text": "wait ah how many jobs do you want to spawn overall and then pre- dispatches how how",
    "start": "1850480",
    "end": "1858039"
  },
  {
    "text": "many you want to spawn simultaneously so you'll start two at a time you'll do 10 overall and then within those it'll",
    "start": "1858039",
    "end": "1864480"
  },
  {
    "text": "begin to divvy up the work and maybe do some of them serly so fascinating fine this can be",
    "start": "1864480",
    "end": "1870799"
  },
  {
    "text": "helpful but you can run into other issues so there are actually also ways",
    "start": "1870799",
    "end": "1876399"
  },
  {
    "text": "for us to use our entire cluster to do this grid search and",
    "start": "1876399",
    "end": "1881600"
  },
  {
    "text": "so there comes a time where you're like how am I going to find an image that's distributed model fitting and and that",
    "start": "1881600",
    "end": "1889200"
  },
  {
    "text": "time then takes you to Big data. tumblr.com uh which is one of my",
    "start": "1889200",
    "end": "1897039"
  },
  {
    "text": "favorite image websites everything is blue and in binary it looks like the Space Age",
    "start": "1897039",
    "end": "1902440"
  },
  {
    "text": "future so I uh what we're going to do here is instead of running all the all this grid",
    "start": "1902440",
    "end": "1909720"
  },
  {
    "text": "search model fitting on a single node with a single python interpreter",
    "start": "1909720",
    "end": "1915919"
  },
  {
    "text": "we're going to actually do this with many many nodes many many many processes",
    "start": "1915919",
    "end": "1922679"
  },
  {
    "text": "working simultaneously and relatively recently there was a package called spark sklearn",
    "start": "1922679",
    "end": "1930120"
  },
  {
    "text": "that came out to use spark sklearn you need to install it on your driver node and you need to install it on your",
    "start": "1930120",
    "end": "1936480"
  },
  {
    "text": "cluster and then what it'll allow you to do is not automatically scale up model training from a single node to the",
    "start": "1936480",
    "end": "1944919"
  },
  {
    "text": "entire cluster but instead do this grid search where instead of having to do a",
    "start": "1944919",
    "end": "1952159"
  },
  {
    "text": "thousand model trainings with slightly different parameters to farm this out on your cluster and so what we've done here",
    "start": "1952159",
    "end": "1960200"
  },
  {
    "text": "that's a change from the this one which is the serial model",
    "start": "1960200",
    "end": "1969000"
  },
  {
    "text": "fitting the only thing that we're going to change is the import at the top",
    "start": "1969000",
    "end": "1975200"
  },
  {
    "text": "oh I was like why is this really not going to where I needed to go and I realized I was going the wrong",
    "start": "1986799",
    "end": "1993840"
  },
  {
    "text": "direction so we're going to change the import at the top um from sidekit learn grid search CV to spark sklearn great uh",
    "start": "1993840",
    "end": "2003399"
  },
  {
    "text": "the code doesn't change at all and it will just do all the work we need fantastic I'm actually kind of thrilled",
    "start": "2003399",
    "end": "2009559"
  },
  {
    "text": "by that project I think it's a great idea it's incredibly useful and making the distinction between massively",
    "start": "2009559",
    "end": "2016080"
  },
  {
    "text": "parallel model fitting where you're making one model versus massively parallel model fitting where you're",
    "start": "2016080",
    "end": "2021480"
  },
  {
    "text": "making tons of models with slightly different hyperparameters it's good to be precise",
    "start": "2021480",
    "end": "2026600"
  },
  {
    "text": "about that because I think the value of this grid search parallelism is",
    "start": "2026600",
    "end": "2034880"
  },
  {
    "text": "actually pretty immediate and fits into people's workflows pretty quickly and easily and",
    "start": "2034880",
    "end": "2041600"
  },
  {
    "text": "obviously so we then have distributed model scoring as another way that spark can",
    "start": "2041600",
    "end": "2048440"
  },
  {
    "text": "fit into our machine learning workflows again model scoring model",
    "start": "2048440",
    "end": "2054320"
  },
  {
    "text": "deployment it can mean so many things we're assuming we've written a",
    "start": "2054320",
    "end": "2059440"
  },
  {
    "text": "model somewhere and that we're then going to apply it to some kind of data so let's",
    "start": "2059440",
    "end": "2067760"
  },
  {
    "text": "let's suppose we're going to apply it to some kind of data with a rest server well we can imagine that the data",
    "start": "2067760",
    "end": "2074720"
  },
  {
    "text": "that we're coming in is getting transported with an HTTP request and that we're going to respond with an HTTP",
    "start": "2074720",
    "end": "2082358"
  },
  {
    "text": "response and there is actually a really wonderful Library called open scoring",
    "start": "2082359",
    "end": "2089320"
  },
  {
    "text": "which which uh will allow you to spin up a rest server very easily that has rest",
    "start": "2089320",
    "end": "2095280"
  },
  {
    "text": "end points predefined deploy your pm pmml models to it and then do all of",
    "start": "2095280",
    "end": "2103640"
  },
  {
    "text": "the uh request understanding and response giving that you needed to do",
    "start": "2103640",
    "end": "2109520"
  },
  {
    "text": "and so this is a description of some of the rest end points that exist so you can deploy models using post and put you",
    "start": "2109520",
    "end": "2116880"
  },
  {
    "text": "can do model prediction in batch so you can give it a bunch of Json blobs that",
    "start": "2116880",
    "end": "2123400"
  },
  {
    "text": "represent a bunch of of features and it'll give you a response back awesome",
    "start": "2123400",
    "end": "2130640"
  },
  {
    "text": "fantastic when so that is a type of deployment",
    "start": "2130640",
    "end": "2135960"
  },
  {
    "text": "system when we get to actually wanting to apply this to a huge database",
    "start": "2135960",
    "end": "2141359"
  },
  {
    "text": "sometimes people want to keep this rest server up and send rest send HTTP calls",
    "start": "2141359",
    "end": "2151079"
  },
  {
    "text": "and get responses back and use that to write the output of the result and that's one method of deployment that",
    "start": "2151079",
    "end": "2156920"
  },
  {
    "text": "seems pretty Flex flexible but big data is just another word for dosing your own",
    "start": "2156920",
    "end": "2163040"
  },
  {
    "text": "systems so again this is one of those ones I had a really good time trying to",
    "start": "2163040",
    "end": "2168640"
  },
  {
    "text": "find images for I really don't want a keyboard with my own dos",
    "start": "2168640",
    "end": "2175040"
  },
  {
    "text": "button so if you have a very large table that you're trying to apply model",
    "start": "2175040",
    "end": "2180480"
  },
  {
    "text": "predictions to what you will find is that you'll pretty quickly overwhelm rest servers like this and so any single",
    "start": "2180480",
    "end": "2187800"
  },
  {
    "text": "single point of here like any single point of contention um will become an",
    "start": "2187800",
    "end": "2194680"
  },
  {
    "text": "issue so instead of doing this what should we do with this model",
    "start": "2194680",
    "end": "2199920"
  },
  {
    "text": "that we've stored hopefully in pmml well the lucky thing for us is that there's a system called jpml",
    "start": "2199920",
    "end": "2209000"
  },
  {
    "text": "jpml I don't feel like there's enough acronyms in this talk um there's a system called jpml jpmm",
    "start": "2209319",
    "end": "2218079"
  },
  {
    "text": "L and jpml allows you to load a pmml file and",
    "start": "2218079",
    "end": "2225200"
  },
  {
    "text": "then has all of the corresponding Java classes that knows how to apply it given the parameters that are fit in your file",
    "start": "2225200",
    "end": "2232200"
  },
  {
    "text": "so the way you would use it as something like this or you say hey I'm going to load this PML file let's build this",
    "start": "2232200",
    "end": "2240040"
  },
  {
    "text": "Transformer you have a little factor that builds a transformer for you and then you can call it in your code so",
    "start": "2240040",
    "end": "2245640"
  },
  {
    "text": "this is something that would be relatively easy to use inside of spark because spark is jvm based fundamentally",
    "start": "2245640",
    "end": "2251920"
  },
  {
    "text": "and you can then take a PM file that you've written somewhere and apply it",
    "start": "2251920",
    "end": "2257599"
  },
  {
    "text": "regularly using JP MML perhaps nightly Weekly right as a crown",
    "start": "2257599",
    "end": "2264280"
  },
  {
    "text": "job so hopefully what we've seen here is",
    "start": "2264280",
    "end": "2270520"
  },
  {
    "text": "that there are a variety of machine learning workflows that generally follow this description of you do model",
    "start": "2270520",
    "end": "2278319"
  },
  {
    "text": "training and model training is defined kind of vacuously as the thing that connects data to this model that you",
    "start": "2278319",
    "end": "2283440"
  },
  {
    "text": "output and then once you output that model you need to persist it in some sort of sane way given their form of",
    "start": "2283440",
    "end": "2290160"
  },
  {
    "text": "persistence you might be able to then apply it to new data that's coming in",
    "start": "2290160",
    "end": "2295720"
  },
  {
    "text": "and there are three ways that I've seen that re that spark realistically fit into this workflow the first is with",
    "start": "2295720",
    "end": "2303760"
  },
  {
    "text": "distributed model training the second is with distributed grid search and the",
    "start": "2303760",
    "end": "2310440"
  },
  {
    "text": "third is with distributed model application and so working on a cluster",
    "start": "2310440",
    "end": "2316319"
  },
  {
    "text": "can happen at a few different stages and there's different trade-offs and benefits to both of those so with that",
    "start": "2316319",
    "end": "2322839"
  },
  {
    "text": "thank you very much",
    "start": "2322839",
    "end": "2326760"
  }
]
[
  {
    "text": "so I don't know about you but it's pretty rare that I get an opportunity to do a green field of an app like it's",
    "start": "7319",
    "end": "12960"
  },
  {
    "text": "very rare that any of us get to do this uh maybe like small stuff but any of our",
    "start": "12960",
    "end": "18960"
  },
  {
    "text": "big systems maybe you think it looks like that maybe that's how you think your app looks but probably most of you",
    "start": "18960",
    "end": "25359"
  },
  {
    "text": "your app is more like this it's actually very sophisticated it's very powerful it's doing a lot of things well it's",
    "start": "25359",
    "end": "32040"
  },
  {
    "text": "running business in my case we've got systems built running a multi-billion Dollar business",
    "start": "32040",
    "end": "37760"
  },
  {
    "text": "globally and this is a picture of New York okay so New York has been built up",
    "start": "37760",
    "end": "43039"
  },
  {
    "text": "over decades and the infrastructure of it serves a purpose but as we've as it's grown up around it any major city like",
    "start": "43039",
    "end": "49440"
  },
  {
    "text": "this has the challenge of how do we start to modernize certain aspects of it in a cost effective way without ripping",
    "start": "49440",
    "end": "56039"
  },
  {
    "text": "out the city because that's just not reality now if your app looks like that",
    "start": "56039",
    "end": "61760"
  },
  {
    "text": "you can get up and leave uh you don't need me I've never actually seen an app like",
    "start": "61760",
    "end": "67560"
  },
  {
    "text": "this um if you've seen those those comics of like an engineer an architect",
    "start": "67560",
    "end": "72880"
  },
  {
    "text": "sitting down like this time I'm going to do it right and they got this vision and then like six panels later it's the oh",
    "start": "72880",
    "end": "78280"
  },
  {
    "text": "we've done it again thing my goal is to maybe take a few of the aspects of this and bring it back into New York City",
    "start": "78280",
    "end": "84960"
  },
  {
    "text": "okay so a few years ago we had a very simple use case that we were trying to achieve we wanted to have a single",
    "start": "84960",
    "end": "91000"
  },
  {
    "text": "Network call come in from our devices and then leverage the low latency network of our server side",
    "start": "91000",
    "end": "97240"
  },
  {
    "text": "infrastructure and the concurrency that was available to us on our powerful servers as opposed to letting little",
    "start": "97240",
    "end": "103560"
  },
  {
    "text": "mobile devices or cheap like $30 boxes because Netflix deploys to anything that",
    "start": "103560",
    "end": "108840"
  },
  {
    "text": "attaches a screen to it and so we've got everything down to like the 20 and $30 silicon and all the way up to the multi",
    "start": "108840",
    "end": "116200"
  },
  {
    "text": "hundred or multiple thousands of dollars of equipment we've got everything in between and the cheaper devices they just can't",
    "start": "116200",
    "end": "122799"
  },
  {
    "text": "handle all of the concurrent composition of all the web services so we wanted to push all that server side so along the",
    "start": "122799",
    "end": "129399"
  },
  {
    "text": "way we realized that to do this effectively we wanted to be able to embrace a u async we needed to do that",
    "start": "129399",
    "end": "136400"
  },
  {
    "text": "and the most natural way the obvious way is let's do callbacks uh callbacks effectively is",
    "start": "136400",
    "end": "143280"
  },
  {
    "text": "what everything boils down to at some point you can put lots of abstractions on top of but at some point the work",
    "start": "143280",
    "end": "148760"
  },
  {
    "text": "finishes and it tells you when it's done and it it calls you back in reality though the use cases we were trying to",
    "start": "148760",
    "end": "154720"
  },
  {
    "text": "solve for was service composition so we wanted to compose multiple Services together without giving up on error",
    "start": "154720",
    "end": "161239"
  },
  {
    "text": "handling and developer productivity and in reality most",
    "start": "161239",
    "end": "166360"
  },
  {
    "text": "solutions that that go down the async path end up sacrificing a lot in these two areas and so there was a enough of",
    "start": "166360",
    "end": "174120"
  },
  {
    "text": "us on the team that had experienced that pain that we didn't just quickly move down this uh path path I was lucky",
    "start": "174120",
    "end": "181080"
  },
  {
    "text": "enough that I had lots of different Engineers around me from different backgrounds and one of them was joffer",
    "start": "181080",
    "end": "186319"
  },
  {
    "text": "Hussein who had come from Microsoft who uh spent a couple months uh arguing with",
    "start": "186319",
    "end": "191560"
  },
  {
    "text": "me and beating me down until I admitted that he was right and uh that's how I",
    "start": "191560",
    "end": "196680"
  },
  {
    "text": "was introduced into the reactive programming space so we chose to adopt async but to do it without raw",
    "start": "196680",
    "end": "203560"
  },
  {
    "text": "callbacks so if if I just look at Java as is most of Netflix is running on the",
    "start": "203560",
    "end": "209920"
  },
  {
    "text": "jvm and most of that is still just plain Java and more and more of it is Java 8",
    "start": "209920",
    "end": "215599"
  },
  {
    "text": "thankfully the future and future of list of te's with those two things we could",
    "start": "215599",
    "end": "221439"
  },
  {
    "text": "actually address a lot of our use cases but honestly that list of te in a future is not exactly right because we still",
    "start": "221439",
    "end": "229319"
  },
  {
    "text": "have to wait for the entire thing to complete before it returns and also at the time when we started on this path",
    "start": "229319",
    "end": "234760"
  },
  {
    "text": "Java Futures they just suck um that you actually can't compose them you end up block threads on them I'm not going to",
    "start": "234760",
    "end": "241760"
  },
  {
    "text": "get into that in depth today uh the lists are actually something we deal with this is the",
    "start": "241760",
    "end": "248319"
  },
  {
    "text": "stereotypical example a list of list of movies and this is for making like the Grid on a homepage and so we iterate",
    "start": "248319",
    "end": "255439"
  },
  {
    "text": "over the list of lists and then within that we iterate over all the movies within a list and then within that we go",
    "start": "255439",
    "end": "262600"
  },
  {
    "text": "and fetch a bunch of stuff and so if you do this naively you end up with two things hundreds of network calls and you",
    "start": "262600",
    "end": "269919"
  },
  {
    "text": "also end up with a step function like a waterfall that just keeps on going on forever and so that was exactly what we",
    "start": "269919",
    "end": "277199"
  },
  {
    "text": "didn't want to have happen there's also this case that you would actually never do with a normal future this future list of future of te",
    "start": "277199",
    "end": "284960"
  },
  {
    "text": "but semantically that's actually what we wanted we wanted to kick off this work asynchronously that would be able to",
    "start": "284960",
    "end": "291240"
  },
  {
    "text": "send back to us individual items uh down the pipe as they came and be able to",
    "start": "291240",
    "end": "296479"
  },
  {
    "text": "work on them as they came in so we already knew semantically that what we wanted to do just this wasn't right and",
    "start": "296479",
    "end": "304000"
  },
  {
    "text": "we we ended up there's different ways of handling this but we ended up uh adopting the the RX observable type so",
    "start": "304000",
    "end": "311440"
  },
  {
    "text": "RX stands for reactive extensions it's not a prescription that might be a prescription for Java I don't know but",
    "start": "311440",
    "end": "317320"
  },
  {
    "text": "uh this the reactive extensions for Java gave us this observable type and we ended up treating everything",
    "start": "317320",
    "end": "323680"
  },
  {
    "text": "as a stream so just all data coming into US is just a stream of data whether it's one item many items or an infinite",
    "start": "323680",
    "end": "330639"
  },
  {
    "text": "stream of data we just started treating everything as a stream so what is what did our API look",
    "start": "330639",
    "end": "338319"
  },
  {
    "text": "like at the time everything was blocking API calls like that now we don't really deal with orders products and shipping",
    "start": "338319",
    "end": "343919"
  },
  {
    "text": "status but I decided to use something other than the than the Netflix isms that I typically use and in this case",
    "start": "343919",
    "end": "350360"
  },
  {
    "text": "you fetch all the orders and then for each order you fetch all the products and for each product you fetch the the the shipping status so when I go to my",
    "start": "350360",
    "end": "357160"
  },
  {
    "text": "amazon.com page I see similar things like this okay this is very common like virtually every e-commerce site I've ever used has",
    "start": "357160",
    "end": "363080"
  },
  {
    "text": "some page that is being rendered behind the scenes I can Envision this flow happening and the apis underneath it",
    "start": "363080",
    "end": "371400"
  },
  {
    "text": "that uh we're using these are typical blocking apis that we've all been using forever okay the problem is that if you",
    "start": "371400",
    "end": "379759"
  },
  {
    "text": "just put this together naively you end up with stepping through this in a waterfall style and each shipping stas",
    "start": "379759",
    "end": "386080"
  },
  {
    "text": "CS let's say 100 milliseconds like I did here so you can just visualize it and you step through it and there's",
    "start": "386080",
    "end": "391199"
  },
  {
    "text": "absolutely no concurrency going on whatsoever now I'm all good with the Java concurrency and practice book that",
    "start": "391199",
    "end": "396759"
  },
  {
    "text": "train book is sitting on my desk it's one of only two books I still have in paper form and it's a great book but",
    "start": "396759",
    "end": "403720"
  },
  {
    "text": "honestly most of us shouldn't have to be reading it and even though I've read that thing twice and still refer to it I still screw everything up and we had",
    "start": "403720",
    "end": "412120"
  },
  {
    "text": "dozens of Engineers uh and we even had a user interface engineer stepping into these code bases and we just knew that",
    "start": "412120",
    "end": "418039"
  },
  {
    "text": "we couldn't have semaphor and M xes and like launching threads randomly and all that kind of stuff and expecting it to",
    "start": "418039",
    "end": "423560"
  },
  {
    "text": "work the environment we were working within this is what our stack dealt with",
    "start": "423560",
    "end": "428879"
  },
  {
    "text": "all our interprocess communication was predominantly being done with Apache HTP we have mcash D and here's the sad thing",
    "start": "428879",
    "end": "436639"
  },
  {
    "text": "is even though its client actually is running on an event Loop had a blocking API over it that didn't actually expose",
    "start": "436639",
    "end": "442039"
  },
  {
    "text": "the asynchron be underneath it and so you're still sitting and blocking on an async callback Cassandra was blocking in",
    "start": "442039",
    "end": "449639"
  },
  {
    "text": "tomcat and serlet like that's the world that that uh we were in and most of our",
    "start": "449639",
    "end": "454759"
  },
  {
    "text": "stuff still is it's all blocking so how on Earth do I bring in a reactive model",
    "start": "454759",
    "end": "460479"
  },
  {
    "text": "into a stack like that and so the reality was that we we couldn't go around just rebuilding",
    "start": "460479",
    "end": "466479"
  },
  {
    "text": "everything especially for something that was unproven uh Engineers were still not buying into the idea but we could change",
    "start": "466479",
    "end": "473639"
  },
  {
    "text": "our service layer and so there was a layer within this stack that we were able to go in and and change we had full",
    "start": "473639",
    "end": "480400"
  },
  {
    "text": "freedom to do it it was isolated to just our team and we could iterate on it and",
    "start": "480400",
    "end": "486319"
  },
  {
    "text": "so we created this async facade and we stuck it right in between the parts that we couldn't control at the top is the",
    "start": "486319",
    "end": "492759"
  },
  {
    "text": "seret and Tomcat infrastructure that we weren't about to go change uh that it's a whole different thing I'll talk about",
    "start": "492759",
    "end": "499080"
  },
  {
    "text": "that more at the end of the my presentation and underneath all of the code that runs all the business logic",
    "start": "499080",
    "end": "505599"
  },
  {
    "text": "and all the IPC and all that stuff which we couldn't in anytime soon swap out so what we did is we went from",
    "start": "505599",
    "end": "512479"
  },
  {
    "text": "a blocking model blocking apis to asynchronous apis which we ended up",
    "start": "512479",
    "end": "517719"
  },
  {
    "text": "calling observable apis because they all end up looking like that instead of type T it's an observable of T and so all of",
    "start": "517719",
    "end": "526279"
  },
  {
    "text": "our our entire service layer was switched over to this model where all the method calls were return un",
    "start": "526279",
    "end": "531519"
  },
  {
    "text": "observable of something and what that allows this is a very trivial example but just to show",
    "start": "531519",
    "end": "537720"
  },
  {
    "text": "that the shipping status now that was synchronously being invoked you still have the same nesting so the the",
    "start": "537720",
    "end": "543920"
  },
  {
    "text": "semantics are still there I still see that I'm two levels down uh like I was",
    "start": "543920",
    "end": "549000"
  },
  {
    "text": "in the before but now it's sitting inside an async observable stream which",
    "start": "549000",
    "end": "554079"
  },
  {
    "text": "is inside another async observable stream and the way that this behaves now when I hit play on this it runs and then",
    "start": "554079",
    "end": "561279"
  },
  {
    "text": "it all snaps in because what it does is by uh making it so that it's all async",
    "start": "561279",
    "end": "567000"
  },
  {
    "text": "it allows me to declare what I want it to do and then the runtime can choose",
    "start": "567000",
    "end": "573079"
  },
  {
    "text": "the concurrency that it's going to execute at and so I can start to leverage the the the concurrency",
    "start": "573079",
    "end": "579560"
  },
  {
    "text": "capabilities of my machine and the io that I'm interacting with so that the actual user experience latency now can",
    "start": "579560",
    "end": "586880"
  },
  {
    "text": "be significantly improved so that's all stuff that we all know about but this starts to give me the tooling to get",
    "start": "586880",
    "end": "593120"
  },
  {
    "text": "there so how do I actually get from that get shipping status method which is",
    "start": "593120",
    "end": "598160"
  },
  {
    "text": "blocking to one that is async so RX is a tool that we use to to do this kind of",
    "start": "598160",
    "end": "604760"
  },
  {
    "text": "stuff so a very basic way is we literally just wrap the blocking calls",
    "start": "604760",
    "end": "610720"
  },
  {
    "text": "and so uh there's a mechanism in RX an operator called defer we're literally",
    "start": "610720",
    "end": "616480"
  },
  {
    "text": "saying defer execution of this until I come back to it later just declare the work to be done when you are run execute",
    "start": "616480",
    "end": "624600"
  },
  {
    "text": "this block of code it's sitting here in a Lambda and then when you run it this is",
    "start": "624600",
    "end": "629640"
  },
  {
    "text": "the this is an important part when you actually are subscribed to subscribe on this scheduler in this case we put it",
    "start": "629640",
    "end": "636519"
  },
  {
    "text": "off on an IO scheduler which is going to put it on threads that are that are intended to be blocked with blocking IO",
    "start": "636519",
    "end": "643680"
  },
  {
    "text": "okay so there's no magic going on here we are just adding threads to our system and some of you are going to winse and",
    "start": "643680",
    "end": "649519"
  },
  {
    "text": "cry and I'll get to that later uh yes we have hundreds and hundreds of threads in some of our systems and it's a sad sad",
    "start": "649519",
    "end": "655760"
  },
  {
    "text": "State of Affairs but it's better for the use case that we had where it's almost all IO that we're sitting on when it",
    "start": "655760",
    "end": "662399"
  },
  {
    "text": "runs this it then invokes get shipping status in a blocking way and blocks that IO thread and then when it eventually",
    "start": "662399",
    "end": "668560"
  },
  {
    "text": "returns it says just take that value of T and return it as an",
    "start": "668560",
    "end": "676279"
  },
  {
    "text": "observable so what if I have a list of orders I actually don't want to have um",
    "start": "676279",
    "end": "682440"
  },
  {
    "text": "this turn into an observable of list of order because that would kind of defeat the point of what I was trying to achieve and so that that list of order",
    "start": "682440",
    "end": "688519"
  },
  {
    "text": "can become observable of order and so when I subscribe to this it will emit each item in the list to me now I'm not",
    "start": "688519",
    "end": "694399"
  },
  {
    "text": "actually achieving any streaming yet this is just getting me into an async uh programming",
    "start": "694399",
    "end": "700399"
  },
  {
    "text": "model the way that you can do this is exactly the same the only difference here is I have defer subscribe on and",
    "start": "700399",
    "end": "707000"
  },
  {
    "text": "get orders I just use from instead of just and from just converts an inable to an observable nothing all that special",
    "start": "707000",
    "end": "714040"
  },
  {
    "text": "here so at a basic level we literally just ran around our system wrapping everything in Threads",
    "start": "714040",
    "end": "720760"
  },
  {
    "text": "and we were able to just with that ability improve our user uh latency uh",
    "start": "720760",
    "end": "727200"
  },
  {
    "text": "but in a way that we could actually still reason about because the the tool gave us the ability to compose it let's",
    "start": "727200",
    "end": "732959"
  },
  {
    "text": "go a little bit further if I actually am working with jdbc uh which uh I imagine",
    "start": "732959",
    "end": "738440"
  },
  {
    "text": "at least some of you uh still have to deal with it thankfully I haven't had to deal with jdbc in four years um I'm very",
    "start": "738440",
    "end": "745199"
  },
  {
    "text": "happy about that the jdbc though is still the really the only legitimate way",
    "start": "745199",
    "end": "750600"
  },
  {
    "text": "to get access to a lot of databases and so if your code actually is interacting with jdbc you can start to do uh some",
    "start": "750600",
    "end": "757560"
  },
  {
    "text": "different things so in the blocking one you can actually see that we accumulate",
    "start": "757560",
    "end": "762639"
  },
  {
    "text": "all of the the data into a data structure as it's coming back so we're pulling it back from the database and as",
    "start": "762639",
    "end": "768680"
  },
  {
    "text": "it's coming back we accumulate it and this means that we're allocating memory and we're also holding the user up until",
    "start": "768680",
    "end": "773760"
  },
  {
    "text": "we have finished pulling everything down putting it into a data structure we give them the data structure they iterate",
    "start": "773760",
    "end": "779880"
  },
  {
    "text": "over it again and then they have to throw that away and you garbage collect it instead if you move to the observable",
    "start": "779880",
    "end": "785680"
  },
  {
    "text": "stream model you put that same code inside of create and as you're receiving",
    "start": "785680",
    "end": "791440"
  },
  {
    "text": "the responses back you're actually just unting them out down the stream as you receive them and so we've completely",
    "start": "791440",
    "end": "797600"
  },
  {
    "text": "eliminated the need for that extra layer of uh object allocation and",
    "start": "797600",
    "end": "804079"
  },
  {
    "text": "buffering this alone is a big gain because now I'm just letting the data flow through and I can uh react to it as",
    "start": "804079",
    "end": "812040"
  },
  {
    "text": "it is passed down the pipeline rather than buffering it into steps along the",
    "start": "812040",
    "end": "817600"
  },
  {
    "text": "way the terminal States for both successful and erroneous completion are there and this is showing the bridge",
    "start": "817600",
    "end": "824920"
  },
  {
    "text": "between a blocking and non-blocking world because jdbc is all blocking it will throw exceptions and I have to",
    "start": "824920",
    "end": "830839"
  },
  {
    "text": "catch them it also supports unsubscribed because in my trivial example here I",
    "start": "830839",
    "end": "836079"
  },
  {
    "text": "decided to select star from the entire table and and so I probably actually",
    "start": "836079",
    "end": "841240"
  },
  {
    "text": "don't want to pull the entire table down and so this will allow me to actually unsubscribe gracefully and it will shut it all down so that if I only want to",
    "start": "841240",
    "end": "847959"
  },
  {
    "text": "take five values it will then terminate itself cleanly clean up all the resources instead of sucking the entire",
    "start": "847959",
    "end": "854800"
  },
  {
    "text": "database down and just throwing it all away and of course because JBC is blocking I have to put it off on an IO",
    "start": "854800",
    "end": "861320"
  },
  {
    "text": "scheduler now I'm going to show you a more complicated example and I want to do this so that you can see the the the",
    "start": "861320",
    "end": "867279"
  },
  {
    "text": "power as you that is there and this reactive pull style back pressure um has evolved out of",
    "start": "867279",
    "end": "873560"
  },
  {
    "text": "collaboration in the industry with like typ safe and pivotal and Twitter and others and has resulted in the reactive",
    "start": "873560",
    "end": "878920"
  },
  {
    "text": "streams uh specification which just went 1 recently and the great thing about that",
    "start": "878920",
    "end": "886120"
  },
  {
    "text": "is that we're getting the same semantics for how to do streaming with back pressure across many different companies",
    "start": "886120",
    "end": "892800"
  },
  {
    "text": "and libraries so RX Java has been involved in that right from the beginning and so we support the the",
    "start": "892800",
    "end": "898040"
  },
  {
    "text": "semantics and so um in Java for those of you who are lucky enough to work in C",
    "start": "898040",
    "end": "903399"
  },
  {
    "text": "and other languages with async a we just Shield your eyes we have to do it all by hand so we",
    "start": "903399",
    "end": "909680"
  },
  {
    "text": "have to put a state machine in place to do this like asyn of white style stuff and so I'm going to show you some code",
    "start": "909680",
    "end": "914880"
  },
  {
    "text": "that is like the in between I'm not going to show you the actual State machine but I'm going to show you the",
    "start": "914880",
    "end": "920279"
  },
  {
    "text": "pieces of it so we're going to create an observable and this particular abstraction we use just to to drive the",
    "start": "920279",
    "end": "926639"
  },
  {
    "text": "state machine for us the actual state within it is the result set that we're going to get back from the JBC okay when",
    "start": "926639",
    "end": "933079"
  },
  {
    "text": "this state machine starts the first thing it does is it construct it State and so you'll see that within it we get",
    "start": "933079",
    "end": "938519"
  },
  {
    "text": "the database connection we create the statement with the correct U uh configuration so this configuration is",
    "start": "938519",
    "end": "945240"
  },
  {
    "text": "basically what you do in U uh jdbc to tell to not buffer everything for you so",
    "start": "945240",
    "end": "950519"
  },
  {
    "text": "years ago when I was working with my SQL a lot it's always fun when you ended up like bloating your your memory space to",
    "start": "950519",
    "end": "956440"
  },
  {
    "text": "like 10 gigs cuz you tried to load the whole database in this tells the JBC driver to uh if your",
    "start": "956440",
    "end": "962600"
  },
  {
    "text": "database supports it to stream the data to you instead of uh pulling it all down buffering into memory and then giving it",
    "start": "962600",
    "end": "967839"
  },
  {
    "text": "to you um which is when you're streaming large amounts of data you want to be doing this especially when you're doing",
    "start": "967839",
    "end": "973759"
  },
  {
    "text": "something like that so the state is created then what it does is that it",
    "start": "973759",
    "end": "979639"
  },
  {
    "text": "actually has a bidirectional negotiation between the consumer and the producer and when the consumer expresses uh",
    "start": "979639",
    "end": "986399"
  },
  {
    "text": "ability to receive data it requests data the state machine will then invoke this Lambda as many times as it needs to",
    "start": "986399",
    "end": "992839"
  },
  {
    "text": "fulfill that and so when it steps into that it retrieves the state and then it says if the result set has data and",
    "start": "992839",
    "end": "999959"
  },
  {
    "text": "that's a blocking call because it's jdbc then it emits on next otherwise it onom completes if there's no further data",
    "start": "999959",
    "end": "1005600"
  },
  {
    "text": "because jdbc is blocking it will throw an exception so this is the bridge between the blocking and non-blocking",
    "start": "1005600",
    "end": "1010680"
  },
  {
    "text": "worlds and then I would capture that and admit the error and then the importantly",
    "start": "1010680",
    "end": "1016000"
  },
  {
    "text": "when when the state machine shuts itself down it gives me the opportunity to terminate and clean everything up and that happens whether it's a termin a",
    "start": "1016000",
    "end": "1022279"
  },
  {
    "text": "successful termination uh an error or if I have unsubscribed from and ask it to",
    "start": "1022279",
    "end": "1027558"
  },
  {
    "text": "shut down prematurely it will always go through the cleanup uh step so I share",
    "start": "1027559",
    "end": "1032600"
  },
  {
    "text": "this because this is important for async streaming systems that if you don't have this kind of a a state machine behind",
    "start": "1032600",
    "end": "1038520"
  },
  {
    "text": "the scenes you you end up with buffer bloat um or out of memory data loss",
    "start": "1038520",
    "end": "1044760"
  },
  {
    "text": "different things like that back pressure is important in async systems same way it is in um synchronous it's just a",
    "start": "1044760",
    "end": "1051919"
  },
  {
    "text": "little trickier to get right in an async system and so this is a mechanism for dealing with that and of course because",
    "start": "1051919",
    "end": "1058080"
  },
  {
    "text": "we're bridging between the synchronous and asynchronous worlds here we have to put all this blocking code off on an IO",
    "start": "1058080",
    "end": "1065919"
  },
  {
    "text": "scheduler so the first round of things that we looked at doing effectively and by when we started we didn't have any of",
    "start": "1065919",
    "end": "1072160"
  },
  {
    "text": "that reactive pullback pressure stuff that is only in the last year and a half that that's come about so about 3ish",
    "start": "1072160",
    "end": "1077640"
  },
  {
    "text": "years ago when we started down this pth path we weren't doing any of that these tools are are available to us to easily",
    "start": "1077640",
    "end": "1083520"
  },
  {
    "text": "bridge between the blocking and non-blocking worlds so that was the bottom half of this diagram what about the top half the",
    "start": "1083520",
    "end": "1090400"
  },
  {
    "text": "top half was when the requests are actually coming into the system and it's a thread per request model and this is",
    "start": "1090400",
    "end": "1096400"
  },
  {
    "text": "honestly the hardest part of most infrastructures to get rid of because your entire company is set up to deploy",
    "start": "1096400",
    "end": "1101799"
  },
  {
    "text": "into something and changing that infrastructure is pretty non-trivial in most places and so we aren't going to",
    "start": "1101799",
    "end": "1109200"
  },
  {
    "text": "try and change that up front uh we're starting to explore it and I'll get to that in a little bit but we've had to",
    "start": "1109200",
    "end": "1116159"
  },
  {
    "text": "deal with the servlet model for the last several years and so this is the typical serlet request response Loop well within",
    "start": "1116159",
    "end": "1123480"
  },
  {
    "text": "that I still want to do that async service composition and so I can kick off that work and this is calling that",
    "start": "1123480",
    "end": "1129520"
  },
  {
    "text": "asynchronous method we made earlier with the observable that kicks off the shipping status asynchronously and under",
    "start": "1129520",
    "end": "1135559"
  },
  {
    "text": "the covers is doing everything async it's all the composition we looked at later so this is going to achieve all",
    "start": "1135559",
    "end": "1140760"
  },
  {
    "text": "those goals of of flattening out that waterfall so that now everything is able to happen concurrently and I get the low",
    "start": "1140760",
    "end": "1146960"
  },
  {
    "text": "latency for the users the difference here now is that I",
    "start": "1146960",
    "end": "1152039"
  },
  {
    "text": "need to bridge back from async to sync because otherwise the serlet thread will just run right through and I'll have",
    "start": "1152039",
    "end": "1159000"
  },
  {
    "text": "spawned off the work in in the background and then I'll return some empty response to my user and so I could",
    "start": "1159000",
    "end": "1166039"
  },
  {
    "text": "go and like do countdown latches and all that stuff by myself but that's not fun and so the RX observable offers this",
    "start": "1166039",
    "end": "1172799"
  },
  {
    "text": "very explicitly named method to blocking it is called that so that it is in your",
    "start": "1172799",
    "end": "1178039"
  },
  {
    "text": "face that you know what you're doing U so that you know that you're going to break all the reasons of why you just",
    "start": "1178039",
    "end": "1183080"
  },
  {
    "text": "adopted RX in the first place because otherwise people end up defaulting back into their imperative synchronous mode",
    "start": "1183080",
    "end": "1190000"
  },
  {
    "text": "easily because it's like easier when you're first getting started so this is like in your face if you see two blocking in your code you know that",
    "start": "1190000",
    "end": "1196159"
  },
  {
    "text": "you're stepping out of the async world it then allows you to like for each over",
    "start": "1196159",
    "end": "1201360"
  },
  {
    "text": "it and it's going to block the servlet thread for you and then you can Bridge",
    "start": "1201360",
    "end": "1206799"
  },
  {
    "text": "back into the servlet world and synchronous blocking iio and you write out your output and also because two",
    "start": "1206799",
    "end": "1213320"
  },
  {
    "text": "each uh two blocking and four each have converted back into a blocking World it will then convert the error messages",
    "start": "1213320",
    "end": "1219760"
  },
  {
    "text": "back into Throne exceptions so you can use the tri catch model around the entire block of code and so in this way",
    "start": "1219760",
    "end": "1225880"
  },
  {
    "text": "we've bridged back from async to synchronous so that we can live within the the",
    "start": "1225880",
    "end": "1231360"
  },
  {
    "text": "serlet ecosystem that already existed so two blocking is the mechanism",
    "start": "1231360",
    "end": "1237120"
  },
  {
    "text": "for bridging between asynchronous and synchronous this is another just practicality of the library it uh by",
    "start": "1237120",
    "end": "1245080"
  },
  {
    "text": "definition it's virtually impossible to have anything pure in a platform such as",
    "start": "1245080",
    "end": "1250960"
  },
  {
    "text": "the jvm that was never built to assume 100% asynchrony And so these types of",
    "start": "1250960",
    "end": "1256000"
  },
  {
    "text": "things are there in the library to allow for bridging back and forth between",
    "start": "1256000",
    "end": "1261720"
  },
  {
    "text": "them so I want to get into like how it actually went uh as we did this and the first",
    "start": "1264559",
    "end": "1271400"
  },
  {
    "text": "attempt we actually tackled Apple TV Apple TV was the first device that we we chose and we rewrote it three times and",
    "start": "1271400",
    "end": "1280400"
  },
  {
    "text": "the first two were horrible the third one still was bad but it worked and the",
    "start": "1280400",
    "end": "1285440"
  },
  {
    "text": "experience felt like this okay that that it was myself and one other engineer who were doing most of the work together",
    "start": "1285440",
    "end": "1291880"
  },
  {
    "text": "paired on it and especially the other engineer was just like why the hell are we doing this and I had I had some a bit",
    "start": "1291880",
    "end": "1299600"
  },
  {
    "text": "of a head start on him and learning the model and we honestly had no idea what we were doing what we found is that the tech",
    "start": "1299600",
    "end": "1306520"
  },
  {
    "text": "worked that actually moving to this async model did actually achieve the goals and that the the reactive",
    "start": "1306520",
    "end": "1313000"
  },
  {
    "text": "extensions model uh created by Eric Meer and Microsoft actually did work even in our horribly bad implementation in Java",
    "start": "1313000",
    "end": "1320840"
  },
  {
    "text": "that existed at that time but we learned a few things along the way and these are important for anyone of you to",
    "start": "1320840",
    "end": "1326880"
  },
  {
    "text": "understand if you're going to start going down this path in your own uh environments we had to relearn a lot of",
    "start": "1326880",
    "end": "1332760"
  },
  {
    "text": "idiomatic Solutions things that we take for granted that we just assume that there are the way to do things when",
    "start": "1332760",
    "end": "1339039"
  },
  {
    "text": "you've uh you know spent your entire career with the imperative uh you know",
    "start": "1339039",
    "end": "1345240"
  },
  {
    "text": "standard style of programming things as simple as iterating a loop so a for Loop we just",
    "start": "1345240",
    "end": "1352679"
  },
  {
    "text": "kind of take for granted most of us unless you uh came up in a completely different path than I did and you know",
    "start": "1352679",
    "end": "1357799"
  },
  {
    "text": "came from the functional background most people I talk to have come from backgrounds of c and Java and",
    "start": "1357799",
    "end": "1365320"
  },
  {
    "text": "you know C and uh Python and Ruby Etc and we just assume that you write",
    "start": "1365320",
    "end": "1372080"
  },
  {
    "text": "programs with four Loops thing is that actually doesn't work when you start to move into like async and functional",
    "start": "1372080",
    "end": "1378880"
  },
  {
    "text": "composition and stuff like Loops have to go away they just they're the wrong Tool",
    "start": "1378880",
    "end": "1384880"
  },
  {
    "text": "uh for what we're trying to achieve and so we had to move our our thinking to instead use like map functions and you",
    "start": "1384880",
    "end": "1390400"
  },
  {
    "text": "declare go apply this to everything in this in the sequence in the Stream and so we had to everywhere where we would",
    "start": "1390400",
    "end": "1397279"
  },
  {
    "text": "naturally go to think about a for Loop we had to eliminate that error handling is completely",
    "start": "1397279",
    "end": "1402679"
  },
  {
    "text": "different in an async world too so everywhere that we would have a TR catch it it's funny I've seen code where",
    "start": "1402679",
    "end": "1409480"
  },
  {
    "text": "people would actually write everything async and then they put a tri catch block around it and then they would wonder why their errors never got caught",
    "start": "1409480",
    "end": "1416320"
  },
  {
    "text": "and it's because the code is long gone and off somewhere else and the tri catch is like over there and has no idea the",
    "start": "1416320",
    "end": "1423520"
  },
  {
    "text": "exception was thrown and so we had to completely stop doing any of our error",
    "start": "1423520",
    "end": "1428679"
  },
  {
    "text": "handling like that we had to move to these models of actually having error handlers that are in the pipelines in the streams that took a mental",
    "start": "1428679",
    "end": "1436679"
  },
  {
    "text": "reconditioning we also had to invest in documentation and so we spent enormous",
    "start": "1436679",
    "end": "1442039"
  },
  {
    "text": "amounts of time on getting this right and we actually hired a technical writer David Gross one of the best decisions we did in the project and uh eventually",
    "start": "1442039",
    "end": "1450279"
  },
  {
    "text": "elaborated into documentation like this where we've got it all on the website we started it all internally and it",
    "start": "1450279",
    "end": "1455360"
  },
  {
    "text": "migrated and evolved as we open sourced and I'm telling you it is awesome working with the tech writer where",
    "start": "1455360",
    "end": "1461840"
  },
  {
    "text": "Engineers write their horrible bad description in the Java do or wherever your documentation is and he would then",
    "start": "1461840",
    "end": "1468440"
  },
  {
    "text": "see the commit happen and he would swoop in behind us and like make it actually like make sense and readable and flush",
    "start": "1468440",
    "end": "1475559"
  },
  {
    "text": "it out put it in examples that's been incredibly important as we spread this different model across dozens of",
    "start": "1475559",
    "end": "1482679"
  },
  {
    "text": "Engineers because we actually have to relearn all those things we also had to allow for the the time and mistakes that",
    "start": "1482679",
    "end": "1489640"
  },
  {
    "text": "were guaranteed to happen I found that once an engineer uh was tackling a project like this",
    "start": "1489640",
    "end": "1495840"
  },
  {
    "text": "to you had to assume about 2 months you basically had to to consider that",
    "start": "1495840",
    "end": "1501200"
  },
  {
    "text": "two months of time for them to wrap their head around it and start to feel natural writing this type of code and be",
    "start": "1501200",
    "end": "1507159"
  },
  {
    "text": "willing to sacrifice good chunks of that time once they get over that hump then",
    "start": "1507159",
    "end": "1512840"
  },
  {
    "text": "it's smooth sailing uh for the most part I also need to talk about unit testing and debugging these things always come",
    "start": "1512840",
    "end": "1518600"
  },
  {
    "text": "up and so unit testing actually is pretty good async unit test actually can work quite nicely so I want to show some",
    "start": "1518600",
    "end": "1524679"
  },
  {
    "text": "ways so RX actually supports uh testing right out of the box and with the test subscriber that block of code underneath",
    "start": "1524679",
    "end": "1531399"
  },
  {
    "text": "it 100% async if you run a normal like J unit or or pick your whatever framework",
    "start": "1531399",
    "end": "1537840"
  },
  {
    "text": "you prefer if you notice they're always they always assume synchronous execution because if you were just to run that",
    "start": "1537840",
    "end": "1543960"
  },
  {
    "text": "without blocking something your unit test would pass while the work is actually off happening somewhere else",
    "start": "1543960",
    "end": "1550520"
  },
  {
    "text": "okay and the unit test or or it would fail because it has no none of the work is there it's not going to be right so",
    "start": "1550520",
    "end": "1557000"
  },
  {
    "text": "you subscribe to it with this subscriber and then it just provides uh helpers to be able to say I want to await a",
    "start": "1557000",
    "end": "1563320"
  },
  {
    "text": "terminal event so block the current thread until a terminal event occurs either successfully or erroneously",
    "start": "1563320",
    "end": "1569240"
  },
  {
    "text": "assert that there's no errors and then do the assertions of everything you accumulated so the test subscriber takes",
    "start": "1569240",
    "end": "1574840"
  },
  {
    "text": "care of accumulating the data that's all asynchronously firing the test subscriber also allows you to pass in",
    "start": "1574840",
    "end": "1580840"
  },
  {
    "text": "like mocked observers like if you want to use makito or whatever and so it allows you to combine all those tools",
    "start": "1580840",
    "end": "1587720"
  },
  {
    "text": "together and so you can actually mix and match async and synchronous uh in unit tests gets even better though with uh",
    "start": "1587720",
    "end": "1595720"
  },
  {
    "text": "virtualized time so same test subscriber except I'm going to add this new test",
    "start": "1595720",
    "end": "1600840"
  },
  {
    "text": "scheduler so something interesting that Eric Meer did when he designed reactive extensions is he made it so that all",
    "start": "1600840",
    "end": "1606600"
  },
  {
    "text": "concurrency anytime you add concurrency to the system it's always parameterized and so all time is is virtual it never",
    "start": "1606600",
    "end": "1613799"
  },
  {
    "text": "actually asks the runtime what the time is it always asks a scheduler and the",
    "start": "1613799",
    "end": "1619240"
  },
  {
    "text": "scheduler always can be injected and so what that allows us to do here is that",
    "start": "1619240",
    "end": "1624760"
  },
  {
    "text": "that time the time unit milliseconds that we're incrementing by all of a sudden allows us to take control of time",
    "start": "1624760",
    "end": "1631360"
  },
  {
    "text": "and so we can advance time in a relative manner by 200 milliseconds deterministically we can then assert",
    "start": "1631360",
    "end": "1638080"
  },
  {
    "text": "that it has emitted one item as we would expect when it ticks and then I can also do absolute increase in Time advance",
    "start": "1638080",
    "end": "1645000"
  },
  {
    "text": "time to 1,000 milliseconds and assert that I've received the five values and now by unit test I've got two really",
    "start": "1645000",
    "end": "1651799"
  },
  {
    "text": "strong benefits out of this one I no longer have to have like crazy long unit",
    "start": "1651799",
    "end": "1656880"
  },
  {
    "text": "test where I'm adding like seconds of sleep time just to try and like cater to all the different machines in the world that might WR run my unit test to try",
    "start": "1656880",
    "end": "1663960"
  },
  {
    "text": "and get it so it's not racy um and so that it's deterministic but it's also so",
    "start": "1663960",
    "end": "1670080"
  },
  {
    "text": "so it runs as fast as a CPU can crunch through it and my tests now are always deterministic it will always do exactly",
    "start": "1670080",
    "end": "1676559"
  },
  {
    "text": "the right thing because it's incrementing time in a deterministic manner this is an incredibly powerful",
    "start": "1676559",
    "end": "1682159"
  },
  {
    "text": "tool if you're dealing with asynchrony this same behavior is also what allows us to actually look at",
    "start": "1682159",
    "end": "1687840"
  },
  {
    "text": "historical streams of data and then crunch over them uh in as fast as we can",
    "start": "1687840",
    "end": "1693799"
  },
  {
    "text": "applying the same temporal operators to them as if we would have done in real time on the other hand async debugging",
    "start": "1693799",
    "end": "1700279"
  },
  {
    "text": "it just sucks this is just a reality of where we are in the industry right now let me just show you a few examples of",
    "start": "1700279",
    "end": "1706200"
  },
  {
    "text": "how bad it is so stack traces lambdas just destroy everything they're just",
    "start": "1706200",
    "end": "1711799"
  },
  {
    "text": "completely garbled you have no idea what's going on when you schedule something asynchronously the native",
    "start": "1711799",
    "end": "1717080"
  },
  {
    "text": "thread only knows that it was scheduled it has no idea what scheduled it so you you've completely lost the chain that",
    "start": "1717080",
    "end": "1722799"
  },
  {
    "text": "got you to this point stack pollution everywhere the all you see is the library code for the most part hardly",
    "start": "1722799",
    "end": "1728519"
  },
  {
    "text": "any user code in there so RX tries it tries to tell you here that hey I got an error when on nexting this thing it's",
    "start": "1728519",
    "end": "1735080"
  },
  {
    "text": "the product type so you can like sort of kind of find your your way but this is a just a",
    "start": "1735080",
    "end": "1740200"
  },
  {
    "text": "mess your step uh your debugger stepping through code it probably won't work for",
    "start": "1740200",
    "end": "1745960"
  },
  {
    "text": "you up on the top there if you actually set a debugger and St and follow that you're actually going to step through",
    "start": "1745960",
    "end": "1751320"
  },
  {
    "text": "the outer layer as you declare but it's never going to actually get into your user code so to get into the user code",
    "start": "1751320",
    "end": "1757799"
  },
  {
    "text": "you actually have to put a break point right in the Lambda where you want to be but that's it like you actually can't step up and down the that's just that is",
    "start": "1757799",
    "end": "1765840"
  },
  {
    "text": "the nature of async code today and so we end up doing a lot of uh debugging via logging and this kind of",
    "start": "1765840",
    "end": "1772640"
  },
  {
    "text": "sucks but it's the reality of where we are now this actually isn't that far off from where we were anyways because uh",
    "start": "1772640",
    "end": "1778720"
  },
  {
    "text": "distributed systems that's just we work in distributed systems and so we kind of given up on all the debug tools for the",
    "start": "1778720",
    "end": "1784840"
  },
  {
    "text": "most part anyways but this really does suck when you're doing local development and that's just the reality that I don't",
    "start": "1784840",
    "end": "1791120"
  },
  {
    "text": "hide so we're actually exploring work here like we've actually conceptually built logical call Stacks that are",
    "start": "1791120",
    "end": "1797519"
  },
  {
    "text": "really nice that hop threads they just kill performance by like two orders of magnitude because you generate stack",
    "start": "1797519",
    "end": "1802720"
  },
  {
    "text": "traces everywhere there's a company we're working with that has done some prototyping the space that we're exploring being able to do some things",
    "start": "1802720",
    "end": "1809960"
  },
  {
    "text": "like deep inside the jvm to stitch together uh logical stack traces that flow across thread boundaries if that",
    "start": "1809960",
    "end": "1818000"
  },
  {
    "text": "work um matures and becomes useful we'll definitely let the world know about it",
    "start": "1818000",
    "end": "1823760"
  },
  {
    "text": "um I would really like for the platforms to start to solve this problem uh that's",
    "start": "1823760",
    "end": "1830039"
  },
  {
    "text": "really the place where it needs to be solved so how did this all look once it was done the observable apis worked well",
    "start": "1830039",
    "end": "1836159"
  },
  {
    "text": "in that async facade and we were able to move from calling patterns like the top where we had everything synchronous and",
    "start": "1836159",
    "end": "1841880"
  },
  {
    "text": "it was all the concurrency was really only because our devices were calling us lots we were able to collapse down the",
    "start": "1841880",
    "end": "1848440"
  },
  {
    "text": "amount of uh Network calls and push most of that work to the server side and have it be Saye the error handling was",
    "start": "1848440",
    "end": "1855120"
  },
  {
    "text": "correct developer productivity after that that hurdle of training ourselves was good and we moved from a blocking",
    "start": "1855120",
    "end": "1862559"
  },
  {
    "text": "API to an observable API and all Netflix traffic uh for the control plane goes",
    "start": "1862559",
    "end": "1869799"
  },
  {
    "text": "through uh observable traffic like this absolutely every web service request that powers our uis goes through this",
    "start": "1869799",
    "end": "1875919"
  },
  {
    "text": "this has nothing to do with the actual V video streaming part to cdns that's a whole different beast that's just fetching bites off of a CDN but the",
    "start": "1875919",
    "end": "1883039"
  },
  {
    "text": "control plane all our web service calls all go through these kind of apis there were challenges along along",
    "start": "1883039",
    "end": "1889720"
  },
  {
    "text": "the way though so one of them way too many threads okay like I've got one system that's like over 1400 threads on",
    "start": "1889720",
    "end": "1896760"
  },
  {
    "text": "an eight core box just think about that um now the benefits have outweighed the",
    "start": "1896760",
    "end": "1903240"
  },
  {
    "text": "cons for the based upon the code base that we had okay however it's made it it",
    "start": "1903240",
    "end": "1908880"
  },
  {
    "text": "was already hard to tune the thing in shed load we've made it far harder we're actually pretty good at it but I feel",
    "start": "1908880",
    "end": "1915080"
  },
  {
    "text": "like we're only 80% of the way there and we don't think we can get the last 20% it's like this magic black art to figure",
    "start": "1915080",
    "end": "1922240"
  },
  {
    "text": "out at what point the Box Falls over and dies because it's never 98% CPU it's like",
    "start": "1922240",
    "end": "1927919"
  },
  {
    "text": "73% some days 62 other days 84% other it all just depends upon the way the wind",
    "start": "1927919",
    "end": "1933480"
  },
  {
    "text": "is blowing and which threads are doing something that's a challenge of this model it's also really easy to",
    "start": "1933480",
    "end": "1939559"
  },
  {
    "text": "accidentally block asynchronous code and so in this C example we've got a concurrent model on the top a sequential",
    "start": "1939559",
    "end": "1945639"
  },
  {
    "text": "one on the bottom the one on the bottom will do the step waterfall and it was just a a user error",
    "start": "1945639",
    "end": "1952440"
  },
  {
    "text": "because the difference between flat map and map completely breaks everything because in the bottom one oops in the",
    "start": "1952440",
    "end": "1959039"
  },
  {
    "text": "bottom one I'm invoking a blocking call and so what we actually did is uh we",
    "start": "1959039",
    "end": "1964639"
  },
  {
    "text": "made something we made it so that we just eliminated all the blocking calls in our API so that we made it really",
    "start": "1964639",
    "end": "1971720"
  },
  {
    "text": "hard like you actually have to consciously go out of your way to do it the thing is is it's there's there's no proper modularization in Java developers",
    "start": "1971720",
    "end": "1979519"
  },
  {
    "text": "make mistakes it's really easy to slip into the old uh model just it's just simple blocking call it returns T and",
    "start": "1979519",
    "end": "1986360"
  },
  {
    "text": "we've seen in production code like this get out and all of a sudden we destroy performance on something and our canaries have to find it or if it's a",
    "start": "1986360",
    "end": "1992760"
  },
  {
    "text": "small thing we don't find it till later this is a problem with mixing things in a an environment that is not built for",
    "start": "1992760",
    "end": "1999240"
  },
  {
    "text": "it so along the way we started asking ourselves what if we did make the effort",
    "start": "1999240",
    "end": "2004639"
  },
  {
    "text": "to go like do a green fill rewrite of this player and what I found was myth",
    "start": "2004639",
    "end": "2010360"
  },
  {
    "text": "and Legend everywhere it was like near impossible to get straight answers on",
    "start": "2010360",
    "end": "2015639"
  },
  {
    "text": "anything and I'd go to companies i' ask why did you adopt something like netti or whatever and I get this answer I'm",
    "start": "2015639",
    "end": "2022799"
  },
  {
    "text": "like really because it's better like that's an answer like that that's not helpful or I get it's worse don't do it",
    "start": "2022799",
    "end": "2030320"
  },
  {
    "text": "like absolutely don't do that completely destroys everything or it's the wrong tool for the job all this stuff I'd also",
    "start": "2030320",
    "end": "2036159"
  },
  {
    "text": "get it doesn't matter like just whatever you prefer and so as I researched it more and more and more I",
    "start": "2036159",
    "end": "2043519"
  },
  {
    "text": "I basically found that all these different approaches to dealing with concurrency theoretically they should",
    "start": "2043519",
    "end": "2049919"
  },
  {
    "text": "all do the same thing so if you boil it all down at some point you've got the same CPUs the same memory the same like",
    "start": "2049919",
    "end": "2057480"
  },
  {
    "text": "physical uh resources if you if all the scheduling and whatever abstractions you use were",
    "start": "2057480",
    "end": "2063960"
  },
  {
    "text": "to slice and dice it in the same efficient way your abstractions should theoretically",
    "start": "2063960",
    "end": "2070040"
  },
  {
    "text": "all be equivalent the reality though is not that but this is where a lot of the",
    "start": "2070040",
    "end": "2077000"
  },
  {
    "text": "confusion I face would come in like for example there's a paper about user threads that you know I shouldn't have",
    "start": "2077000",
    "end": "2082358"
  },
  {
    "text": "to use callbacks because my user threads it's the right abstraction it's like that that that'd be great if my runtime",
    "start": "2082359",
    "end": "2088358"
  },
  {
    "text": "actually gave that to me in a way that worked but it doesn't the only agreement",
    "start": "2088359",
    "end": "2093440"
  },
  {
    "text": "that I got from anybody is that if you're trying to solve the c10k problem which is 10,000 concurrent connections on a box and that was a decade ago or",
    "start": "2093440",
    "end": "2099920"
  },
  {
    "text": "like now it's like 100k or a million I've even I know people who are definitely running a million concurrent connections on a box uh in production",
    "start": "2099920",
    "end": "2107280"
  },
  {
    "text": "today they're now starting to tackle 10 million which just baffles me um I have",
    "start": "2107280",
    "end": "2112680"
  },
  {
    "text": "no doubt we'll get there this is about the only place I got agreement that yes go use event loops and like non-blocking IO for those",
    "start": "2112680",
    "end": "2119079"
  },
  {
    "text": "things it's the only place I could get people to like not argue with me and so",
    "start": "2119079",
    "end": "2124560"
  },
  {
    "text": "I had this problem I had to like what am I going to bet the future of a pretty important system at Netflix on and I",
    "start": "2124560",
    "end": "2131000"
  },
  {
    "text": "didn't want it to be based upon myth and legend or gut checks or opinions or like",
    "start": "2131000",
    "end": "2136119"
  },
  {
    "text": "you know all that stuff and so we did what every bad engineer does we wrote A Benchmark",
    "start": "2136119",
    "end": "2142480"
  },
  {
    "text": "um and disastrous of course but I will tell you why in a second why this actually is interesting so we've created",
    "start": "2142480",
    "end": "2149319"
  },
  {
    "text": "this thing where we basically like the stereotypical web service at Netflix where something comes in you kick off",
    "start": "2149319",
    "end": "2155480"
  },
  {
    "text": "some work and then as that work comes back you kick pick off some more and then some more and then you compose it all together into the totally",
    "start": "2155480",
    "end": "2161440"
  },
  {
    "text": "inefficient Json and I purposefully used Json so that I was actually realistic",
    "start": "2161440",
    "end": "2167800"
  },
  {
    "text": "because try as I might we don't actually use a whole lot of efficient binary encoding type stuff I'm very much trying",
    "start": "2167800",
    "end": "2173640"
  },
  {
    "text": "to get some of our systems there but honestly most of it is this kind of stuff it's the reality of it we're not a",
    "start": "2173640",
    "end": "2180400"
  },
  {
    "text": "hyper latency driven company and so most of the time it's like good enough one",
    "start": "2180400",
    "end": "2186440"
  },
  {
    "text": "and so this whole thing thing should take 150 more 154 milliseconds in a",
    "start": "2186440",
    "end": "2191520"
  },
  {
    "text": "perfect execution of it and most of it is just waiting on I/O very little of it is actually computation and honestly",
    "start": "2191520",
    "end": "2198240"
  },
  {
    "text": "very little of any of the services that I see are doing anything computation other than our own inefficient serialization and distalization of swill",
    "start": "2198240",
    "end": "2205800"
  },
  {
    "text": "that we send across the wire and so uh we tested this in the cloud and all that kind of stuff but",
    "start": "2205800",
    "end": "2211960"
  },
  {
    "text": "eventually we B we did just like bare metal so we could actually get some interesting data out of it and the only",
    "start": "2211960",
    "end": "2217760"
  },
  {
    "text": "reason why I have any trust and confidence in these numbers is because I got to work with Brendan Greg on it and Brendan Greg has written a book that",
    "start": "2217760",
    "end": "2224480"
  },
  {
    "text": "thick it's like two inch thick on system performance and I was really lucky to have him at Netflix to work with on",
    "start": "2224480",
    "end": "2230960"
  },
  {
    "text": "this and it took months and months and months what I learned from this is if",
    "start": "2230960",
    "end": "2236760"
  },
  {
    "text": "you're actually going to go and try and answer these kind of questions plan to lose a lot of time uh if you're actually",
    "start": "2236760",
    "end": "2242920"
  },
  {
    "text": "going to go and try to do benchmarking and we used just Tom cat and NY like nothing fancy or interesting",
    "start": "2242920",
    "end": "2250640"
  },
  {
    "text": "really and so here's the first of the slid showing the data we were actually able to push both of them up to almost",
    "start": "2250640",
    "end": "2256640"
  },
  {
    "text": "all CPU utilization now when we first started we couldn't get Tomcat anywhere near that we actually had to spend two",
    "start": "2256640",
    "end": "2263079"
  },
  {
    "text": "weeks just tuning Tomcat to be able to max out the box that's the first sign",
    "start": "2263079",
    "end": "2268720"
  },
  {
    "text": "actually Netty like we had to configure nothing it just works that actually is a good sign but Tom Cat we were able to",
    "start": "2268720",
    "end": "2274319"
  },
  {
    "text": "get them both to that point here's where it starts to get interesting NY has lower CPU consumption per request and it",
    "start": "2274319",
    "end": "2279960"
  },
  {
    "text": "keeps getting faster under load I'll explain that in a little bit so why so netti definitely achieves higher",
    "start": "2279960",
    "end": "2286760"
  },
  {
    "text": "throughput um noticeably and we were able to prove that this is primarily because of lower CPU consumption per",
    "start": "2286760",
    "end": "2293480"
  },
  {
    "text": "request we were able to track that in all the the metrics we were using U flame graphs and stats and different",
    "start": "2293480",
    "end": "2300720"
  },
  {
    "text": "things average latency now average latency sucks it's totally useless don't use it it's just interesting on this",
    "start": "2300720",
    "end": "2306680"
  },
  {
    "text": "graph just to see even how the average works out the average latency here for um uh nety is better than Tomcat but",
    "start": "2306680",
    "end": "2313880"
  },
  {
    "text": "this is where it gets interesting when you start looking at the max latency and like the 999th 99th 90th Etc we so we I",
    "start": "2313880",
    "end": "2320920"
  },
  {
    "text": "don't only have so much time today so I can't show you all those things but when you start out both of them are actually",
    "start": "2320920",
    "end": "2327160"
  },
  {
    "text": "right in line and what the interesting thing here is it actually starts to confirm the premise that",
    "start": "2327160",
    "end": "2334319"
  },
  {
    "text": "theoretically these two should behave and achieve the same thing and when the system is not underload actually it",
    "start": "2334319",
    "end": "2341079"
  },
  {
    "text": "holds out both of them effectively behave the same as far as the user",
    "start": "2341079",
    "end": "2346640"
  },
  {
    "text": "experience latency on them when the system is not underload as you ramp up though Tom Cat Just Falls over and so",
    "start": "2346640",
    "end": "2354800"
  },
  {
    "text": "let's look at what's happening the actual instructions per cycle for netti which is an event Loop model one event Loop per core actually gets more",
    "start": "2354800",
    "end": "2361760"
  },
  {
    "text": "efficient as you put under load this is fascinating to watch nety gets faster as you push it harder",
    "start": "2361760",
    "end": "2368880"
  },
  {
    "text": "okay and the thread migrations was really where it started to pop out what was going on and so at the beginning we",
    "start": "2368880",
    "end": "2375880"
  },
  {
    "text": "chose not to pin threads or anything like that like that's just not the world we live in we're exploring it but we",
    "start": "2375880",
    "end": "2381079"
  },
  {
    "text": "don't optimize to that level so we let the operating system just schedule things and when it's under light load",
    "start": "2381079",
    "end": "2387680"
  },
  {
    "text": "each time an event Loop or a thread per request was invoked it was still doing scheduling stuff and so both of them",
    "start": "2387680",
    "end": "2393119"
  },
  {
    "text": "were migrating threads and all was good when you start to get under though the",
    "start": "2393119",
    "end": "2398640"
  },
  {
    "text": "event Loops start to get hot and they actually start to do the right thing and",
    "start": "2398640",
    "end": "2403720"
  },
  {
    "text": "just start to pipeline everything and so it stopped the the schedulers stopped migrating stopped moving them around",
    "start": "2403720",
    "end": "2409520"
  },
  {
    "text": "whereas the Tomcat model it's all every time it does an event it has to schedule a thread it picks a core puts it on it",
    "start": "2409520",
    "end": "2416359"
  },
  {
    "text": "and so the thread migrations um becomes a major thing with Tom cat so why was",
    "start": "2416359",
    "end": "2422000"
  },
  {
    "text": "Tom Cat faster and more efficient and why did it scale better all those things the first one just Net's better code",
    "start": "2422000",
    "end": "2428920"
  },
  {
    "text": "than Tom cat like we could actually see in our profiling that it was far better optimized for object allocation and",
    "start": "2428920",
    "end": "2435480"
  },
  {
    "text": "those types of things had smaller Stacks they'd went out of their way to not allocate memory those types of things",
    "start": "2435480",
    "end": "2441440"
  },
  {
    "text": "the event Loop architecture though we were able to demonstrate actually did impact things reduced thread migrations",
    "start": "2441440",
    "end": "2447880"
  },
  {
    "text": "which in turn affects the cash warmth memory locality and structures per cycle and ultimately the thing that we were",
    "start": "2447880",
    "end": "2452960"
  },
  {
    "text": "able to track right from the start lower CPU consumption per cycle and then we were able to pinpoint in the threadpool",
    "start": "2452960",
    "end": "2458839"
  },
  {
    "text": "architecture non-trivial amounts of time um that were spent on lock contention",
    "start": "2458839",
    "end": "2463880"
  },
  {
    "text": "and thread migrations there's far far more data behind this and Brendan Greg could talk about this far more",
    "start": "2463880",
    "end": "2470400"
  },
  {
    "text": "interesting than me what we were able to determine from it though is that despite all the theories with current jvm and",
    "start": "2470400",
    "end": "2477240"
  },
  {
    "text": "Linux uh implementations there is a benefit for us to adopt the event Loop",
    "start": "2477240",
    "end": "2483359"
  },
  {
    "text": "architecture and we also found through this all it was interesting to me I found it far simpler to uh write and",
    "start": "2483359",
    "end": "2491319"
  },
  {
    "text": "operate the event Loop model than the thread model not easier though easier",
    "start": "2491319",
    "end": "2496480"
  },
  {
    "text": "it's easier for me to do the toat one because that's where I've got 15 years of History doing it so I have to like actually think more about the event Loop",
    "start": "2496480",
    "end": "2503160"
  },
  {
    "text": "one and also our tools suck at dealing with that like we haven't we don't have 20 years of tooling around event Loops",
    "start": "2503160",
    "end": "2509839"
  },
  {
    "text": "in fact I found that it kind of worked like this exactly the same way as the latency curve is that the effort to get",
    "start": "2509839",
    "end": "2516640"
  },
  {
    "text": "Tomcat going going was pretty easy going and then when you actually tried to scale the thing and get it to tune well and like how to shed load on stuff the",
    "start": "2516640",
    "end": "2523400"
  },
  {
    "text": "the difficulties spiked exactly like its latency curve so we found that a fully async",
    "start": "2523400",
    "end": "2529319"
  },
  {
    "text": "architecture does have benefits sufficient enough that we've kicked off a pretty massive effort to go and",
    "start": "2529319",
    "end": "2534440"
  },
  {
    "text": "rewrite our front end and migrate off of the the Tomcat model over to netti and",
    "start": "2534440",
    "end": "2541040"
  },
  {
    "text": "the interesting thing was it actually wasn't the the the throughput gains that ultimately drove us like that we could",
    "start": "2541040",
    "end": "2546079"
  },
  {
    "text": "throw money at in we can scale horizontally for us the reason that drove us was the operational benefits",
    "start": "2546079",
    "end": "2552599"
  },
  {
    "text": "the fact that I can push that thing up to 98 99% and still trust how my machine",
    "start": "2552599",
    "end": "2557960"
  },
  {
    "text": "was going to run the availability and uh user experience benefits are far more",
    "start": "2557960",
    "end": "2564839"
  },
  {
    "text": "important to us than just we can throw money at machines that's cheaper than the engineers for this but availability",
    "start": "2564839",
    "end": "2572160"
  },
  {
    "text": "in operations is important so reactive programming can be incrementally applied",
    "start": "2572160",
    "end": "2578000"
  },
  {
    "text": "um but it does come with challenges when you do mixed code bases concurrency via async service",
    "start": "2578000",
    "end": "2583480"
  },
  {
    "text": "composition has been in our environment at scale over many years of of running",
    "start": "2583480",
    "end": "2589040"
  },
  {
    "text": "this with dozens of Engineers of varying levels of experience with it it's worked",
    "start": "2589040",
    "end": "2594359"
  },
  {
    "text": "really well for us we're very happy with this RX Java schedules and threads can be leveraged to bridge that Gap in",
    "start": "2594359",
    "end": "2601280"
  },
  {
    "text": "reality though we we just use hisy for that so Hy is our fault uh fault",
    "start": "2601280",
    "end": "2607839"
  },
  {
    "text": "handling layer it basically does bulkheading and all that kind of stuff it actually we leverage it to do all",
    "start": "2607839",
    "end": "2613240"
  },
  {
    "text": "that stuff we wrap around blocking iio it deals with the it adds the threads and concurrency and bulkheading and",
    "start": "2613240",
    "end": "2619359"
  },
  {
    "text": "metrics and all that stuff so we actually don't directly do any of that code that I showed you earlier because we just put it all in one layer in",
    "start": "2619359",
    "end": "2625599"
  },
  {
    "text": "historics rather than everywhere in our code repeating the same thing over and over again in closing concurrency is",
    "start": "2625599",
    "end": "2632079"
  },
  {
    "text": "still it's non-trivial okay that's not going away RX does not try and trivialize it it every attempt I've ever",
    "start": "2632079",
    "end": "2638640"
  },
  {
    "text": "seen to completely abstract that stuff away and make it trivial and easy gets",
    "start": "2638640",
    "end": "2643960"
  },
  {
    "text": "about 80% of the way there and then you have to punch out the side at some point and completely break the system and I",
    "start": "2643960",
    "end": "2649839"
  },
  {
    "text": "have found that thus far I have not seen a solution out there that solves concurrency and asynchrony in a way that",
    "start": "2649839",
    "end": "2657000"
  },
  {
    "text": "you can completely ignore what's going on they are leaky abstractions you have to still understand what's going on RX",
    "start": "2657000",
    "end": "2662599"
  },
  {
    "text": "is a library not a framework so you apply it where it's needed it doesn't take over your ecosystem",
    "start": "2662599",
    "end": "2667960"
  },
  {
    "text": "and that's been important to us we're not there I don't ever expect to actually see a software system like that",
    "start": "2667960",
    "end": "2673319"
  },
  {
    "text": "but I uh we believe that we're on the process of at least being able maybe pull those little spaceships up there",
    "start": "2673319",
    "end": "2678960"
  },
  {
    "text": "and like bring them into New York and maybe it'll look like Avengers um and uh",
    "start": "2678960",
    "end": "2684440"
  },
  {
    "text": "there's a lot more information here uh we've done and it's most of what I've talked about is all open source and uh",
    "start": "2684440",
    "end": "2692280"
  },
  {
    "text": "I'll take questions if you have any",
    "start": "2692280",
    "end": "2699040"
  }
]
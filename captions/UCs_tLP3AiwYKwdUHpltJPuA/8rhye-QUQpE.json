[
  {
    "text": "thank you",
    "start": "2580",
    "end": "4700"
  },
  {
    "text": "um and then we're going to start today with some phrases on this big screen and I want you to read",
    "start": "13259",
    "end": "19800"
  },
  {
    "text": "through some of them privacy is dead could be like only terrorists want privacy that's a very nice one from my",
    "start": "19800",
    "end": "26880"
  },
  {
    "text": "home country of the United States um I don't care they have my data anyways it was already shared maybe",
    "start": "26880",
    "end": "33360"
  },
  {
    "text": "young people don't care about privacy anymore why should we implement it has anybody heard",
    "start": "33360",
    "end": "39300"
  },
  {
    "text": "any of these things has anybody said anything to us okay no shame there's no shaming here we're",
    "start": "39300",
    "end": "46980"
  },
  {
    "text": "talking about privacy and I think these are real experiences of people",
    "start": "46980",
    "end": "52200"
  },
  {
    "text": "because I think the vibe around privacy in a lot of ways is quite cynical there's a massive amount of data that's",
    "start": "52200",
    "end": "58800"
  },
  {
    "text": "available there's programs for example 10 years ago that Snowden brought to light but that were kind of well known",
    "start": "58800",
    "end": "64680"
  },
  {
    "text": "in some parts of the industry beforehand about the amount of privacy offered to individuals and there's a massive amount",
    "start": "64680",
    "end": "72119"
  },
  {
    "text": "of data collection and use in our lives today so I really mean it when I say I don't want to shame these points of view",
    "start": "72119",
    "end": "78600"
  },
  {
    "text": "I think this is a real feeling and I think it can show us a condition that exists in our world today",
    "start": "78600",
    "end": "85860"
  },
  {
    "text": "how many people here are from Amsterdam or the Netherlands as a larger group did",
    "start": "85860",
    "end": "91920"
  },
  {
    "text": "you hear about the fraud algorithm that came up recently in the news or on",
    "start": "91920",
    "end": "97020"
  },
  {
    "text": "Social Services I'm seeing some nodding so there's a fraud algorithm Fraud's",
    "start": "97020",
    "end": "102180"
  },
  {
    "text": "important to track and usually we use machine learning now to do it my background's in machine learning so I've",
    "start": "102180",
    "end": "107460"
  },
  {
    "text": "had a chance to work on and see lots of fraud systems implemented and the fraud system that was",
    "start": "107460",
    "end": "112680"
  },
  {
    "text": "implemented was supposed to track potential Social Security or social services fraud for applicants so you",
    "start": "112680",
    "end": "120960"
  },
  {
    "text": "would apply for social services or some sort of social programs and this algorithm or the model and system that",
    "start": "120960",
    "end": "126840"
  },
  {
    "text": "was used to create and then evaluate these applications which used some level of machine learning would tell you",
    "start": "126840",
    "end": "133379"
  },
  {
    "text": "whether it's fraud or not now this was implemented by a large consultancy not the one I work at this",
    "start": "133379",
    "end": "140520"
  },
  {
    "text": "is implemented by a large consultancy for the the Dutch State and what was",
    "start": "140520",
    "end": "147180"
  },
  {
    "text": "found in the feature set so in some of the variables that were used essentially",
    "start": "147180",
    "end": "152220"
  },
  {
    "text": "to train the algorithm was that Dutch nationality was a key feature flag and",
    "start": "152220",
    "end": "158099"
  },
  {
    "text": "that this feature flag was then a key decider of the rate of fraud for the",
    "start": "158099",
    "end": "166379"
  },
  {
    "text": "people that were applying to these systems so the question is here what does this",
    "start": "166379",
    "end": "174239"
  },
  {
    "text": "have to do with privacy any guesses",
    "start": "174239",
    "end": "178640"
  },
  {
    "text": "what if nationality wasn't shared what if we just didn't train a model using",
    "start": "183540",
    "end": "189300"
  },
  {
    "text": "nationality as a feature what if somebody in the room said you know I think that's private information",
    "start": "189300",
    "end": "194519"
  },
  {
    "text": "I don't necessarily know if it's relevant or not to the outcomes what if somebody said we need to mask this in",
    "start": "194519",
    "end": "200879"
  },
  {
    "text": "some ways so that it's not a one zero what if somebody had said let's ask the users if they'd like to share their",
    "start": "200879",
    "end": "207360"
  },
  {
    "text": "nationality as part of their form and so on and so forth there's any number of things that could have been done that",
    "start": "207360",
    "end": "214140"
  },
  {
    "text": "would probably provide also better outcomes for the algorithm because it's quite a lazy evaluation from an",
    "start": "214140",
    "end": "220200"
  },
  {
    "text": "Information Gain point of view to use nationality as an indicator of fraud",
    "start": "220200",
    "end": "225720"
  },
  {
    "text": "it's just bad data science so maybe now we see ah if data privacy",
    "start": "225720",
    "end": "232319"
  },
  {
    "text": "exists in software and systems maybe we also have more Humane outcomes maybe we",
    "start": "232319",
    "end": "237780"
  },
  {
    "text": "also have better outcomes maybe we have less of this privacy cynicism but first we actually need to Define",
    "start": "237780",
    "end": "243659"
  },
  {
    "text": "data privacy because it's kind of this big amorphous experience and the reason",
    "start": "243659",
    "end": "249299"
  },
  {
    "text": "why it's so big in amorphous is is way bigger than just the technical side it's",
    "start": "249299",
    "end": "254879"
  },
  {
    "text": "way bigger than just the legal side it's also the social and cultural and individual experiences of humans and I",
    "start": "254879",
    "end": "262979"
  },
  {
    "text": "think this is a big reason why in the EU it's defined as a human right and it's",
    "start": "262979",
    "end": "268259"
  },
  {
    "text": "defined as a human right in the conventions that were put together after the end of World War II and that's this",
    "start": "268259",
    "end": "275520"
  },
  {
    "text": "is not very linked to the way that the Nazi regime operated right is data",
    "start": "275520",
    "end": "282300"
  },
  {
    "text": "privacy as a human right so when we think about all of these different definitions we can see I tried",
    "start": "282300",
    "end": "289139"
  },
  {
    "text": "to make the the circles overlapping in the ways that I see them but also",
    "start": "289139",
    "end": "294300"
  },
  {
    "text": "overlapping in their thighs so I think socially culturally historically we have",
    "start": "294300",
    "end": "299520"
  },
  {
    "text": "a lot more ideas about privacy than the legal implications of privacy that's a",
    "start": "299520",
    "end": "304740"
  },
  {
    "text": "lived experience we have ways that we talk to each other and we communicate hey this is just between us or hey can",
    "start": "304740",
    "end": "311820"
  },
  {
    "text": "you go actually tell all these people that I'm saying this if I'm standing here in the center of town and I'm",
    "start": "311820",
    "end": "317340"
  },
  {
    "text": "screaming I obviously have a different idea about the context and the privacy of that information than if I pull you",
    "start": "317340",
    "end": "324300"
  },
  {
    "text": "aside and I'm whispering to you something right so all of these social and cultural experiences and the ways",
    "start": "324300",
    "end": "330419"
  },
  {
    "text": "the cues of how we talk about the context of the information that we share they're really obvious to us in a real",
    "start": "330419",
    "end": "336300"
  },
  {
    "text": "world and where some of the shift that's difficult is how we put it into a technical world",
    "start": "336300",
    "end": "341460"
  },
  {
    "text": "so first we have to put it into a legal world and that's the definition of data protection or the legal definitions",
    "start": "341460",
    "end": "347520"
  },
  {
    "text": "those are obviously then codified into law regulations maybe policies or standards at an organization that you're",
    "start": "347520",
    "end": "353759"
  },
  {
    "text": "working at and they have their own language around data privacy that is also Divergent from maybe the way that",
    "start": "353759",
    "end": "360060"
  },
  {
    "text": "you and I would commonly talk about data privacy and then we have a growing field of",
    "start": "360060",
    "end": "366000"
  },
  {
    "text": "scientific or technical definitions of privacy that tries to figure out how do",
    "start": "366000",
    "end": "371340"
  },
  {
    "text": "we take these legal Concepts how do we take these social Concepts and how do we Define them in code",
    "start": "371340",
    "end": "376979"
  },
  {
    "text": "and that is a lot of what I've spent the past five six years of my career working",
    "start": "376979",
    "end": "382500"
  },
  {
    "text": "on is how do we actually take and use these scientific and Technical definitions of privacy and make sure",
    "start": "382500",
    "end": "389520"
  },
  {
    "text": "that we find this nice overlap between the legal side and also the cultural",
    "start": "389520",
    "end": "395039"
  },
  {
    "text": "social and hopefully individual side of privacy so that might be kind of complicated",
    "start": "395039",
    "end": "402300"
  },
  {
    "text": "right like that's a lot of things I don't know if we can represent society and code yes I agree with you so how do",
    "start": "402300",
    "end": "410819"
  },
  {
    "text": "we actually Implement privacy in code systems and particularly in data",
    "start": "410819",
    "end": "416039"
  },
  {
    "text": "workflows first off here how many people here are from data science machine learning data engineering data",
    "start": "416039",
    "end": "423000"
  },
  {
    "text": "management side of the house how many folks here are like software",
    "start": "423000",
    "end": "429479"
  },
  {
    "text": "systems Architects Ops okay okay that will help",
    "start": "429479",
    "end": "435300"
  },
  {
    "text": "me so if I say machine learning stuff and you're like what is that that's a great question so um you can add it",
    "start": "435300",
    "end": "442280"
  },
  {
    "text": "obviously my background is in machine learning so I would try to make sure that the way that I'm speaking is",
    "start": "442280",
    "end": "447780"
  },
  {
    "text": "friendly to everybody so the start of my book and some of what",
    "start": "447780",
    "end": "453120"
  },
  {
    "text": "we'll go through today is kind of the Whirlwind tour of my book but the start of my book says you can't do any of the",
    "start": "453120",
    "end": "458940"
  },
  {
    "text": "cool data privacy stuff and you probably can't reach any realm of satisfiable",
    "start": "458940",
    "end": "464340"
  },
  {
    "text": "privacy from a user perspective and even from organizational perspective if you",
    "start": "464340",
    "end": "469560"
  },
  {
    "text": "don't first start with the foundations which is data governance so what is data governance is",
    "start": "469560",
    "end": "475560"
  },
  {
    "text": "multi-disciplinary it often has actors from maybe audit compliance if you had a",
    "start": "475560",
    "end": "480960"
  },
  {
    "text": "large enough place or if you're at a bank or other highly regulated industry it also has to do with the different",
    "start": "480960",
    "end": "486660"
  },
  {
    "text": "data owners so data managers data owners data Architects it also has to obviously do with technological governance so this",
    "start": "486660",
    "end": "493979"
  },
  {
    "text": "might be your software this might be your software architecture this might be your operating environment or what cloud you use and so forth and then it also",
    "start": "493979",
    "end": "501180"
  },
  {
    "text": "has to do with privacy team legal team infosec team and so really it's spanning",
    "start": "501180",
    "end": "507840"
  },
  {
    "text": "across a bunch of parts of the organization pretty much anybody that's responsible for making decisions about",
    "start": "507840",
    "end": "513360"
  },
  {
    "text": "data how it's collected how it's used how it's retained and how it's deleted",
    "start": "513360",
    "end": "518700"
  },
  {
    "text": "and data governance spans Way Beyond data privacy and data security Myspace it also can talk about data quality it",
    "start": "518700",
    "end": "525540"
  },
  {
    "text": "can talk about data consistency it can talk about data interoperability and so",
    "start": "525540",
    "end": "530580"
  },
  {
    "text": "on and so forth data modeling also falls under this as well and so uh this is a",
    "start": "530580",
    "end": "535860"
  },
  {
    "text": "graphic that's used by my employer thoughtworks that we use to talk about all of these different overarching and",
    "start": "535860",
    "end": "543000"
  },
  {
    "text": "interchangeable pieces of governance of which of course privacy is a core part",
    "start": "543000",
    "end": "548399"
  },
  {
    "text": "and it's really important that all these people are making decisions because if you don't set policies and standards",
    "start": "548399",
    "end": "554760"
  },
  {
    "text": "that make sense across the entire organization and that fit for example the organization's risk appetite",
    "start": "554760",
    "end": "561140"
  },
  {
    "text": "organizations liability organizations operating regions and the",
    "start": "561140",
    "end": "566640"
  },
  {
    "text": "variety of regulations you end up in a real pickle let's say about figuring out",
    "start": "566640",
    "end": "572399"
  },
  {
    "text": "how you're going to actually Implement privacy so at the end of the day it needs to be a group decision and we'll",
    "start": "572399",
    "end": "579000"
  },
  {
    "text": "talk a little bit more about that later so let's say you've done this data governance you have some people",
    "start": "579000",
    "end": "585540"
  },
  {
    "text": "decisions you have some process decisions and you have some technical decisions and you now have this mandate",
    "start": "585540",
    "end": "591180"
  },
  {
    "text": "okay go implement this new product with these new privacy features",
    "start": "591180",
    "end": "598080"
  },
  {
    "text": "how's that going to work right so at the end of the day you have maybe these very",
    "start": "598080",
    "end": "603180"
  },
  {
    "text": "organizational very process driven very regulatory driven ideas but in the",
    "start": "603180",
    "end": "610019"
  },
  {
    "text": "beginning of my talk I talked about humans and human rights and human choice so we need to kind of build a bridge",
    "start": "610019",
    "end": "616920"
  },
  {
    "text": "here between these organizational demands and requirements and The Human Side of privacy",
    "start": "616920",
    "end": "622920"
  },
  {
    "text": "so one of the things that I talk about in the book that in case you work with",
    "start": "622920",
    "end": "628019"
  },
  {
    "text": "the product side of the house or the UI ux side of the house or even user research side of the house is to think",
    "start": "628019",
    "end": "634320"
  },
  {
    "text": "about new ways that you allow the user to interface and communicate with you",
    "start": "634320",
    "end": "639360"
  },
  {
    "text": "about privacy preferences and it certainly does not look like the",
    "start": "639360",
    "end": "644940"
  },
  {
    "text": "annoying cooking banners that we have experienced for the past five years it certainly looks different than that",
    "start": "644940",
    "end": "651839"
  },
  {
    "text": "and so there are ways where you can talk with your users where you can even run",
    "start": "651839",
    "end": "656880"
  },
  {
    "text": "non-scalable user research or a b c d e f testing where you can start to",
    "start": "656880",
    "end": "664140"
  },
  {
    "text": "actually interface and provide options and the area of product design",
    "start": "664140",
    "end": "670380"
  },
  {
    "text": "com compliant with privacy by Design and the area of user interface design with",
    "start": "670380",
    "end": "676320"
  },
  {
    "text": "focus on privacy it's as old as technology itself some of the landmark papers are still from the 90s and so",
    "start": "676320",
    "end": "683820"
  },
  {
    "text": "there's no dearth of information about how to actively ask and maybe even learn",
    "start": "683820",
    "end": "689880"
  },
  {
    "text": "and infer ways to talk with users about their privacy preferences and nowhere is",
    "start": "689880",
    "end": "695399"
  },
  {
    "text": "this more apparent today in product development than the way that Apple talks to users about privacy we can",
    "start": "695399",
    "end": "702300"
  },
  {
    "text": "argue about why Apple talks to users about privacy and what does it mean but",
    "start": "702300",
    "end": "707399"
  },
  {
    "text": "we definitely see in the Privacy interfaces that Apple says this app",
    "start": "707399",
    "end": "712560"
  },
  {
    "text": "wants to use this do you want to allow them do you want to allow them for a short period of time all of these things",
    "start": "712560",
    "end": "717660"
  },
  {
    "text": "if we built more of these into the applications themselves users might be more willing to share information",
    "start": "717660",
    "end": "723420"
  },
  {
    "text": "because they have choice and they have transparency so that data is kind of I would say at",
    "start": "723420",
    "end": "731160"
  },
  {
    "text": "the edge right it's on the software it's on the device the application is in the web interface and then from a data",
    "start": "731160",
    "end": "737940"
  },
  {
    "text": "Engineering also from just a systems engineering point of view we have to take that data we have to put it",
    "start": "737940",
    "end": "742980"
  },
  {
    "text": "someplace that people are going to use it that's the kind of the whole point and so",
    "start": "742980",
    "end": "748980"
  },
  {
    "text": "um although I'm a big fan of local First Data so if you're at Martin clepman's talk I'm definitely going to expand upon",
    "start": "748980",
    "end": "756120"
  },
  {
    "text": "those ideas in a minute but when we do so so we have some user interface we have some consent interface we can add",
    "start": "756120",
    "end": "763200"
  },
  {
    "text": "additional lineage and governance information as we collect data this shouldn't be throwaway metadata there",
    "start": "763200",
    "end": "769440"
  },
  {
    "text": "should be data that we value that we use to enhance the decisions that we make around governance we can do pipeline",
    "start": "769440",
    "end": "776940"
  },
  {
    "text": "stuff we can transport we can modify and so forth we might want to also assess",
    "start": "776940",
    "end": "782160"
  },
  {
    "text": "quality and make quality decisions before we store and then we're also going to address sensitivity concerns",
    "start": "782160",
    "end": "789540"
  },
  {
    "text": "and so when we address these sensitivity concerns on ingestion or maybe if you have a multi-stage data area you might",
    "start": "789540",
    "end": "796740"
  },
  {
    "text": "do it between different stages of your data zones or your data mesh or your data Fabric or your lake house or",
    "start": "796740",
    "end": "802320"
  },
  {
    "text": "whatever it is that you'd like to call it but you might apply these transformations in different steps and",
    "start": "802320",
    "end": "808980"
  },
  {
    "text": "if you're doing this at a highly regulated industry or even if you're thinking a lot about data privacy and",
    "start": "808980",
    "end": "815040"
  },
  {
    "text": "data security you might actually start zoning certain data that has had very",
    "start": "815040",
    "end": "820440"
  },
  {
    "text": "little sensitivity Protections in separate zones from other data right and",
    "start": "820440",
    "end": "825899"
  },
  {
    "text": "so you need to really actually start thinking about how you architect things and where the most sensitive data is",
    "start": "825899",
    "end": "832500"
  },
  {
    "text": "stored and where data is stored that everybody or more people can access that has more privacy protections applied to",
    "start": "832500",
    "end": "839639"
  },
  {
    "text": "it we'll get to those protections later but then you should be able to access",
    "start": "839639",
    "end": "844740"
  },
  {
    "text": "the data without doing five join jumps to the information about the sensitivity",
    "start": "844740",
    "end": "851040"
  },
  {
    "text": "to the information about the consent to the information about any other governance criteria that you'd like to",
    "start": "851040",
    "end": "857700"
  },
  {
    "text": "attach and this is because technically with gdpr and other regulations that are",
    "start": "857700",
    "end": "863579"
  },
  {
    "text": "coming into effect the consent that is attached to the data when you collect it is exactly the only consent that that",
    "start": "863579",
    "end": "871079"
  },
  {
    "text": "data can be used under we like to talk about there's a concept of legitimate",
    "start": "871079",
    "end": "876120"
  },
  {
    "text": "interest and you might have heard of this but what has been shown by cnil the French data protection authority is",
    "start": "876120",
    "end": "883139"
  },
  {
    "text": "there shrinking the space of legitimate interest so from a basic compliance point of view",
    "start": "883139",
    "end": "889260"
  },
  {
    "text": "it's very important that you know under what consent terms data was collected so",
    "start": "889260",
    "end": "894720"
  },
  {
    "text": "that things like data retention or things like use cases can be properly tracked",
    "start": "894720",
    "end": "900720"
  },
  {
    "text": "so what might be some of these things that you can do so let's get into a little bit more of the technical side of",
    "start": "900720",
    "end": "907680"
  },
  {
    "text": "things the first and the most basic and the thing that probably hopefully you're already all using right now is",
    "start": "907680",
    "end": "913680"
  },
  {
    "text": "pseudonymization so pseudonymization we take sensitive",
    "start": "913680",
    "end": "918899"
  },
  {
    "text": "information usually this is pii or personally identifiable information and we change it slightly we don't",
    "start": "918899",
    "end": "927300"
  },
  {
    "text": "change a lot of it and we use particular methods and the methods that you use will vary in their privacy protections",
    "start": "927300",
    "end": "934560"
  },
  {
    "text": "but that's what we do from a very basic this is the most basic of techniques",
    "start": "934560",
    "end": "940079"
  },
  {
    "text": "that you can do it offers though some protections so we can think about format preserving",
    "start": "940079",
    "end": "945720"
  },
  {
    "text": "encryption where we also increase utility of the data because we keep it in a format that the data user is",
    "start": "945720",
    "end": "952620"
  },
  {
    "text": "expecting and yet we and we also allow for decryption of that so if you use",
    "start": "952620",
    "end": "958380"
  },
  {
    "text": "encryption Basics there um that's the field I used to work in I'm happy to talk about it further but",
    "start": "958380",
    "end": "963959"
  },
  {
    "text": "you can also do things that are non-reversible like hashing you could do table based tokenization which",
    "start": "963959",
    "end": "970139"
  },
  {
    "text": "questionable of scale but to each their own you can do masking or you can even",
    "start": "970139",
    "end": "975360"
  },
  {
    "text": "do redaction so all of these are techniques that are available to you and they offer some baseline support for",
    "start": "975360",
    "end": "982920"
  },
  {
    "text": "saying okay maybe this pii shouldn't end up in this easily accessible bucket or",
    "start": "982920",
    "end": "988500"
  },
  {
    "text": "something like this but they don't offer you a lot of",
    "start": "988500",
    "end": "993779"
  },
  {
    "text": "protection so pseudonymization I would say is like the very base lowest amount",
    "start": "993779",
    "end": "998880"
  },
  {
    "text": "of protection and that's because it's quite easy to take a bunch of pseudonymized information to link it all",
    "start": "998880",
    "end": "1006259"
  },
  {
    "text": "together which is probably why you're pseudonymizing it is you want it to be linkable to link it all together and",
    "start": "1006259",
    "end": "1012620"
  },
  {
    "text": "then to kind of reverse engineer or single out individuals and be able to figure out who they are this is a known",
    "start": "1012620",
    "end": "1019160"
  },
  {
    "text": "attack is happening time and time again this is why every time I say when people say like we anonymize the data and then",
    "start": "1019160",
    "end": "1027020"
  },
  {
    "text": "they release it it's like you really just probably shouldn't say that unless",
    "start": "1027020",
    "end": "1032839"
  },
  {
    "text": "you're ready for a security attack basically or privacy attack",
    "start": "1032839",
    "end": "1038780"
  },
  {
    "text": "so this is well known by the folks that run and release public records every day",
    "start": "1038780",
    "end": "1046100"
  },
  {
    "text": "so the the U.S census uh is a way of tracking information about U.S residents",
    "start": "1046100",
    "end": "1053120"
  },
  {
    "text": "and citizens there's about 330 million of them plus more over time or maybe",
    "start": "1053120",
    "end": "1058760"
  },
  {
    "text": "less depending on the month but for that reason uh they need to release",
    "start": "1058760",
    "end": "1065780"
  },
  {
    "text": "statistics and a lot of these statistics are used to make decisions about funding",
    "start": "1065780",
    "end": "1071480"
  },
  {
    "text": "they're used to make decisions about health care programs about educational programs and so on and so forth",
    "start": "1071480",
    "end": "1078320"
  },
  {
    "text": "and these decisions have real meaning but they're also always publicly released",
    "start": "1078320",
    "end": "1083900"
  },
  {
    "text": "and so I'm from the US I used to work there and there was lots of clever ways",
    "start": "1083900",
    "end": "1089059"
  },
  {
    "text": "let's just say that data scientists would take these statistics and use them to enrich the data and potentially",
    "start": "1089059",
    "end": "1096200"
  },
  {
    "text": "combine it with enough data that they could actually connect individuals in their consumer databases with",
    "start": "1096200",
    "end": "1102559"
  },
  {
    "text": "individuals released in the census data and this was based on some older techniques that the census used in 2010",
    "start": "1102559",
    "end": "1109940"
  },
  {
    "text": "and before the census kind of got wind of this and",
    "start": "1109940",
    "end": "1115100"
  },
  {
    "text": "they actually performed their own database reconstruction attack and they found that half of the people were able",
    "start": "1115100",
    "end": "1120980"
  },
  {
    "text": "to be reconstructed in some of the areas using openly accessible consumer",
    "start": "1120980",
    "end": "1126440"
  },
  {
    "text": "databases you can buy for like 50 bucks because data privacy in America",
    "start": "1126440",
    "end": "1131840"
  },
  {
    "text": "um so because of this the U.S census was like maybe we should do something more",
    "start": "1131840",
    "end": "1137419"
  },
  {
    "text": "rigorous this time and they decided to go with differential privacy now how many people have already",
    "start": "1137419",
    "end": "1143179"
  },
  {
    "text": "heard about differential privacy one sorry zero two three",
    "start": "1143179",
    "end": "1150500"
  },
  {
    "text": "I'm making a differentially private response you get the joke all right um so differential privacy is a way of",
    "start": "1150500",
    "end": "1158240"
  },
  {
    "text": "essentially removing outliers and inserting error why would we want to do that",
    "start": "1158240",
    "end": "1165700"
  },
  {
    "text": "if if we add noise we could never be exactly certain what the actual answer",
    "start": "1174140",
    "end": "1179240"
  },
  {
    "text": "is and unfortunately I'm here to break it to you if anybody ever told you that",
    "start": "1179240",
    "end": "1184520"
  },
  {
    "text": "they could digitize something and it's Anonymous they lied to you they probably didn't mean to lie to you they probably",
    "start": "1184520",
    "end": "1190460"
  },
  {
    "text": "actually thought that was possible but it's mathematically infeasible it's been proven now in research for decades there",
    "start": "1190460",
    "end": "1197960"
  },
  {
    "text": "is no way to collect information release information and guarantee anonymity in",
    "start": "1197960",
    "end": "1203660"
  },
  {
    "text": "any dictionary sense of the word of anonymity it's literally against the principles of information Theory so if",
    "start": "1203660",
    "end": "1210919"
  },
  {
    "text": "you want to argue information Theory good job but essentially there's no such thing as anonymity from a technical",
    "start": "1210919",
    "end": "1217220"
  },
  {
    "text": "point of view and since there's no such thing as anonymity what was suggested as a replacement is the core concept that",
    "start": "1217220",
    "end": "1224419"
  },
  {
    "text": "form differential privacy and exactly based on this is the closest thing we can get to anonymity because it allows",
    "start": "1224419",
    "end": "1232160"
  },
  {
    "text": "us to reason about the amount of information that we're releasing and when we reason about the amount of",
    "start": "1232160",
    "end": "1238100"
  },
  {
    "text": "information we're releasing we can actually decide to lessen the amount of",
    "start": "1238100",
    "end": "1243320"
  },
  {
    "text": "information or abstract the amount of information by doing things like adding Noise by doing things like removing",
    "start": "1243320",
    "end": "1250280"
  },
  {
    "text": "outliers because they have a lot of information compared to the others they have a increased privacy risk if you're",
    "start": "1250280",
    "end": "1256880"
  },
  {
    "text": "an outlier and this is exactly the types of probabilistic and statistical methods",
    "start": "1256880",
    "end": "1263360"
  },
  {
    "text": "that we need if we're going to get anywhere near what any human would think of as anonymity",
    "start": "1263360",
    "end": "1269299"
  },
  {
    "text": "so that's what they did they have the histograms that are based on the real numbers they added a noise barrier they",
    "start": "1269299",
    "end": "1275059"
  },
  {
    "text": "used a library that I talk about in the book called tumult analytics which runs on spark if you're familiar with it and",
    "start": "1275059",
    "end": "1281539"
  },
  {
    "text": "then they did some correction post-processing Corrections so that everything ended up and that's how they",
    "start": "1281539",
    "end": "1287059"
  },
  {
    "text": "released actually the entire 2020 census number so you can read more about it both in the book but also they have a",
    "start": "1287059",
    "end": "1293539"
  },
  {
    "text": "bunch of cool blog posts on the topic and this gets us to the idea that",
    "start": "1293539",
    "end": "1300380"
  },
  {
    "text": "privacy and information are linked right like information Theory tells us a lot",
    "start": "1300380",
    "end": "1306620"
  },
  {
    "text": "about privacy Theory and privacy risk and it is like a mathematical understanding of privacy right and so",
    "start": "1306620",
    "end": "1313580"
  },
  {
    "text": "when we think of privacy and information we can think of an entire Continuum and the more information that we give the",
    "start": "1313580",
    "end": "1320480"
  },
  {
    "text": "less privacy we can guarantee is by no means a zero one or a binary situation",
    "start": "1320480",
    "end": "1326659"
  },
  {
    "text": "this isn't an on off you can't just turn on or off privacy this is instead an",
    "start": "1326659",
    "end": "1332419"
  },
  {
    "text": "entire Continuum where you're constantly making choices about how much privacy you can offer and what's the trade-off",
    "start": "1332419",
    "end": "1339080"
  },
  {
    "text": "with information and this by the way it's not meant to be linear I had to do linear because it's",
    "start": "1339080",
    "end": "1344780"
  },
  {
    "text": "got to go in a book and you can't do non-linear in a book unfortunately but the idea is that different techniques",
    "start": "1344780",
    "end": "1351740"
  },
  {
    "text": "that you can use can offer different amounts of this trade-off and you could",
    "start": "1351740",
    "end": "1357140"
  },
  {
    "text": "tune this trade off over time and it should be driven not only by the privacy of the individuals but also by the",
    "start": "1357140",
    "end": "1363200"
  },
  {
    "text": "context the use case the risk of how you're releasing data obviously if you're dealing with internal data in an",
    "start": "1363200",
    "end": "1369260"
  },
  {
    "text": "internal use case it's a massively different risk than if you're releasing data to the public",
    "start": "1369260",
    "end": "1375980"
  },
  {
    "text": "so you might be like this is complicated I don't want to learn about your math Catherine uh you're making me bored",
    "start": "1375980",
    "end": "1382280"
  },
  {
    "text": "thinking about probability so um what about ways where I don't have to",
    "start": "1382280",
    "end": "1388880"
  },
  {
    "text": "think about these things like differential privacy I don't really want to think about this yes",
    "start": "1388880",
    "end": "1394640"
  },
  {
    "text": "now we connect to Martin slevin's talk so what if we said okay this sounds like",
    "start": "1394640",
    "end": "1401360"
  },
  {
    "text": "a lot of risk we don't want to collect this data what if we just",
    "start": "1401360",
    "end": "1407000"
  },
  {
    "text": "didn't collect the data how many people here have made that",
    "start": "1407000",
    "end": "1412640"
  },
  {
    "text": "argument at their work at some point in time let's just not collect it yes awesome thank you privacy Champions yes",
    "start": "1412640",
    "end": "1419419"
  },
  {
    "text": "keep doing that regardless of what you learn in this talk um but one of the ways that we can think",
    "start": "1419419",
    "end": "1426020"
  },
  {
    "text": "about high-risk data or even just think about optimizing our Data Systems is to",
    "start": "1426020",
    "end": "1431360"
  },
  {
    "text": "leave more data at the edge and to push compute and processing to the edge",
    "start": "1431360",
    "end": "1436520"
  },
  {
    "text": "instead of sucking data to the center this is one of the core theories behind",
    "start": "1436520",
    "end": "1441919"
  },
  {
    "text": "Federated learning which was first built and deployed at scale by Google because they were having a lot of trouble doing",
    "start": "1441919",
    "end": "1448640"
  },
  {
    "text": "machine learning on predictive text on keyboards this was I think in 2016-2017.",
    "start": "1448640",
    "end": "1454940"
  },
  {
    "text": "and they notice that the performance of their predictive keyboard particularly for non-native English",
    "start": "1454940",
    "end": "1462380"
  },
  {
    "text": "speakers so if your native keyboard language is not English that in certain",
    "start": "1462380",
    "end": "1467840"
  },
  {
    "text": "languages in particular they were doing quite poorly and I imagine here we have some speakers who have experienced this",
    "start": "1467840",
    "end": "1475100"
  },
  {
    "text": "lovely problem in real life where the next word that's predicted has literally nothing",
    "start": "1475100",
    "end": "1480679"
  },
  {
    "text": "to do with anything or is spelled wrong or is a totally different conjugation and an end right",
    "start": "1480679",
    "end": "1486980"
  },
  {
    "text": "so what Google said is you know if you're really useful if we had more keyboard data more text data in other",
    "start": "1486980",
    "end": "1492860"
  },
  {
    "text": "languages and I'm certain somebody in the room I wasn't there but somebody in the room was like let's just start",
    "start": "1492860",
    "end": "1498080"
  },
  {
    "text": "collecting all keyboard data thankfully so when he intervened it was like I think that's super creepy and probably",
    "start": "1498080",
    "end": "1503960"
  },
  {
    "text": "illegal so they went this way and the way that they did is they said",
    "start": "1503960",
    "end": "1509299"
  },
  {
    "text": "you know what we're actually devices are getting strong enough we can do machine learning on the device",
    "start": "1509299",
    "end": "1515780"
  },
  {
    "text": "so instead of collecting all the data centrally we're going to push the machine learning to the devices and then",
    "start": "1515780",
    "end": "1522380"
  },
  {
    "text": "we're going to do machine learning there how does that even work so I want to take you through it and I won't get into",
    "start": "1522380",
    "end": "1527840"
  },
  {
    "text": "too much of the boring machine learning details but the idea is you push the model to the devices or parts of the",
    "start": "1527840",
    "end": "1534799"
  },
  {
    "text": "model depending on how your model is architected you then actually run training or sometimes of learning on the",
    "start": "1534799",
    "end": "1541039"
  },
  {
    "text": "device at some point in time you have what we call an update the update is",
    "start": "1541039",
    "end": "1546080"
  },
  {
    "text": "either a gradient or a tensor or it's some collection of Weights representation of weights of the model",
    "start": "1546080",
    "end": "1551840"
  },
  {
    "text": "that gets aggregated at an aggregation step here and then the aggregator makes",
    "start": "1551840",
    "end": "1557720"
  },
  {
    "text": "some sort of algorithm or decision and here we can also think about adding differential privacy we can also do",
    "start": "1557720",
    "end": "1562760"
  },
  {
    "text": "other things at this step and end decision is made and that update is sent not only to the centralized model but",
    "start": "1562760",
    "end": "1569900"
  },
  {
    "text": "then all the end device models and you can repeat this as many times as you want",
    "start": "1569900",
    "end": "1575720"
  },
  {
    "text": "so there's offers a lot of privacy principles because the data is not centralized but I must say and I want to",
    "start": "1575720",
    "end": "1581779"
  },
  {
    "text": "do big asterisk it depends on the implementation how much privacy we can guarantee of this because sometimes the",
    "start": "1581779",
    "end": "1589520"
  },
  {
    "text": "updates that users send particularly if they're outliers they might actually leak information",
    "start": "1589520",
    "end": "1596559"
  },
  {
    "text": "but we can move Beyond just machine learning we can actually do this in any type of data querying data analysis data",
    "start": "1596600",
    "end": "1603380"
  },
  {
    "text": "collection and so forth we can actually push all of that processing to the edge and I have seen and worked on a lot of",
    "start": "1603380",
    "end": "1610760"
  },
  {
    "text": "even sensor data um Factory floor data and so forth where",
    "start": "1610760",
    "end": "1616220"
  },
  {
    "text": "you actually don't want to aggregate all that data especially if you're just going to run three queries or some sort",
    "start": "1616220",
    "end": "1622520"
  },
  {
    "text": "of predictive maintenance if else statement basically and make a decision so I agree in terms of the local first",
    "start": "1622520",
    "end": "1630140"
  },
  {
    "text": "of the data we should probably for some types of data we should be thinking more",
    "start": "1630140",
    "end": "1635600"
  },
  {
    "text": "about aggregating and pushing queries and Analysis to the edge and not assisting in terabytes of data per day",
    "start": "1635600",
    "end": "1643340"
  },
  {
    "text": "that nobody ever uses or looks at not only for the Privacy principles but for Green Computing and so on and so forth",
    "start": "1643340",
    "end": "1652100"
  },
  {
    "text": "so what you might be thinking if you work in data sharing is this sounds like it",
    "start": "1652100",
    "end": "1657260"
  },
  {
    "text": "could apply to that as well and you might be thinking how is that going to work if we need to aggregate across",
    "start": "1657260",
    "end": "1662960"
  },
  {
    "text": "certain types of our data I don't see how this can work and if you get to this",
    "start": "1662960",
    "end": "1668240"
  },
  {
    "text": "stage you start then moving into my favorite part of the field which is cryptography so private set intersection is deployed",
    "start": "1668240",
    "end": "1675860"
  },
  {
    "text": "and actively used by Google ads and has anybody here studied cryptography before or is the",
    "start": "1675860",
    "end": "1682220"
  },
  {
    "text": "cryptographer works closely with cryptographers yeah awesome excellent you also enjoy differential privacy some",
    "start": "1682220",
    "end": "1688340"
  },
  {
    "text": "of the same core principles of pseudorandomness and so private set intersection is a",
    "start": "1688340",
    "end": "1695240"
  },
  {
    "text": "branch of a subfield of cryptography called encrypted computation and what",
    "start": "1695240",
    "end": "1700460"
  },
  {
    "text": "private set intersection does is it creates protocols that allow us to compare two sets of data and to only",
    "start": "1700460",
    "end": "1707840"
  },
  {
    "text": "find the set the intersection and we can do this All in cryptography",
    "start": "1707840",
    "end": "1713059"
  },
  {
    "text": "we can actually use Jiffy Hellman style protocols this is like very old cryptography it's not anything new or",
    "start": "1713059",
    "end": "1719419"
  },
  {
    "text": "super fancy What's new and fancy is that we can do this for imbalanced data sets at scale and we can do this in optimized",
    "start": "1719419",
    "end": "1725779"
  },
  {
    "text": "ways and so on and so forth and so Google already runs this in production for some time and we can look they can",
    "start": "1725779",
    "end": "1733220"
  },
  {
    "text": "look at things like users who clicked an ad and users who bought something they can find this intersection and then they",
    "start": "1733220",
    "end": "1738740"
  },
  {
    "text": "continue Computing on that and release let's say Roi on ads and so on and so forth and they do this without",
    "start": "1738740",
    "end": "1745220"
  },
  {
    "text": "centralizing the data so again it has these Federated principles",
    "start": "1745220",
    "end": "1750559"
  },
  {
    "text": "and part of what they do in the current way that they operate this as far as my",
    "start": "1750559",
    "end": "1755779"
  },
  {
    "text": "understanding as well as their published research on the topic is they also remain in encrypted space to compute so",
    "start": "1755779",
    "end": "1763399"
  },
  {
    "text": "they actually never decrypt the data to perform the computations and then at the",
    "start": "1763399",
    "end": "1769399"
  },
  {
    "text": "end of the computation they can determine who and where gets to decrypt",
    "start": "1769399",
    "end": "1774980"
  },
  {
    "text": "and this isn't necessarily privacy this is actually starts bordering on what cryptographers call privacy which is",
    "start": "1774980",
    "end": "1781940"
  },
  {
    "text": "secrecy and secrecy is the ability to decide when encrypted information and by",
    "start": "1781940",
    "end": "1789320"
  },
  {
    "text": "whom this is allowed to be decrypted and so we can start to build these principles together where cryptography",
    "start": "1789320",
    "end": "1796039"
  },
  {
    "text": "can help increase secrecy and we can use secrecy and clever ways to add privacy",
    "start": "1796039",
    "end": "1801700"
  },
  {
    "text": "and these can support one another in very holistic ways",
    "start": "1801700",
    "end": "1807260"
  },
  {
    "text": "and it goes even beyond that so I used to work in the field of encrypted machine learning",
    "start": "1807260",
    "end": "1813500"
  },
  {
    "text": "um and in encrypted machine learning what we're doing is we're actually sharing encrypted data across multiple organizations we're doing so or at least",
    "start": "1813500",
    "end": "1820880"
  },
  {
    "text": "the place I worked at did multi-party computation and in this case you might have heard of secret sharing or shamir's",
    "start": "1820880",
    "end": "1827419"
  },
  {
    "text": "secret sharing and in this we're able to learn on encrypted data we're able to",
    "start": "1827419",
    "end": "1833360"
  },
  {
    "text": "learn on distributed data we're only ever encrypted tensors are shared and we're also able to do things like secure",
    "start": "1833360",
    "end": "1839899"
  },
  {
    "text": "and private aggregation where these aggregation steps or syncs across the machine learning can do clever things",
    "start": "1839899",
    "end": "1847039"
  },
  {
    "text": "with differential privacy can do clever things with deciding who gets the decrypted updates and so on and so forth",
    "start": "1847039",
    "end": "1853279"
  },
  {
    "text": "so I share this in the sense that you can start to build these concepts with each other and this is why it's so",
    "start": "1853279",
    "end": "1859340"
  },
  {
    "text": "important to understand where do you actually fit on the risk Continuum where",
    "start": "1859340",
    "end": "1864679"
  },
  {
    "text": "do you fit on the privacy and information Continuum and so on so I hope maybe I've taught you a few",
    "start": "1864679",
    "end": "1872240"
  },
  {
    "text": "Concepts that might be new to you um did practical data privacy especially",
    "start": "1872240",
    "end": "1877460"
  },
  {
    "text": "implementing this taking it from Theory and labs and implementing it into working software is it team sport",
    "start": "1877460",
    "end": "1883399"
  },
  {
    "text": "there's no way that any of this can be done by only one team here's just a few of the teams and how",
    "start": "1883399",
    "end": "1889760"
  },
  {
    "text": "they might interact with each other and there's also a growing field called privacy engineering that I have some",
    "start": "1889760",
    "end": "1896600"
  },
  {
    "text": "YouTube videos in a series on um if you're interested in learning more about specializing just in privacy",
    "start": "1896600",
    "end": "1902240"
  },
  {
    "text": "technology but I think that this could be implemented at any scale at any organization and I'd be happy to talk",
    "start": "1902240",
    "end": "1909320"
  },
  {
    "text": "about that further to wrap up today I think I want to share",
    "start": "1909320",
    "end": "1914659"
  },
  {
    "text": "with you that privacy doesn't have to be dead that privacy very much is a privilege and that different people have",
    "start": "1914659",
    "end": "1920480"
  },
  {
    "text": "different access to privacy that privacy is powerful that it allows",
    "start": "1920480",
    "end": "1925640"
  },
  {
    "text": "people to decide who they are who they want to be online it allows people to change their mind it allows people to",
    "start": "1925640",
    "end": "1932659"
  },
  {
    "text": "determine what context they're operating in it can have ethical social cultural",
    "start": "1932659",
    "end": "1938120"
  },
  {
    "text": "benefits and it could also be super fun math lots of cryptography lots of",
    "start": "1938120",
    "end": "1943220"
  },
  {
    "text": "statistical thinking and it could be also implementing those as scale which means",
    "start": "1943220",
    "end": "1948799"
  },
  {
    "text": "a lot a lot lot of software and operations infrastructure and so on and",
    "start": "1948799",
    "end": "1954380"
  },
  {
    "text": "I think is a good way to think about how do we Implement human rights in technology",
    "start": "1954380",
    "end": "1960080"
  },
  {
    "text": "so I want to thank you very much this is my book uh I have my newsletter probably",
    "start": "1960080",
    "end": "1965840"
  },
  {
    "text": "private and you can reach out to me on these I don't know how much longer I'll be on Twitter but for now I'm still",
    "start": "1965840",
    "end": "1971240"
  },
  {
    "text": "there and I want to thank you so much for your time [Applause]",
    "start": "1971240",
    "end": "1979209"
  }
]
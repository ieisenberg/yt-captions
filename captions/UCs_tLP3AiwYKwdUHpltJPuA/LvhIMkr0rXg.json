[
  {
    "start": "0",
    "end": "60000"
  },
  {
    "text": "[Music]",
    "start": "3520",
    "end": "7840"
  },
  {
    "text": "hi everyone how's everybody doing it's kind of late right okay let let's",
    "start": "13309",
    "end": "19949"
  },
  {
    "text": "try not to fall asleep let's see where we can take this so who likes debugging problems in production it's not a trick",
    "start": "19949",
    "end": "28350"
  },
  {
    "text": "question don't worry so you know the slides I could probably ask you like which slide is coming next like rate the",
    "start": "28350",
    "end": "35219"
  },
  {
    "text": "sessions remember to rate this session did you rate the previous session and now we can get going and this is",
    "start": "35219",
    "end": "42839"
  },
  {
    "text": "something that we see every now and then that no matter what the actual question the answer is kubernetes nowadays and",
    "start": "42839",
    "end": "50449"
  },
  {
    "text": "that brings lots of joy to monitoring observability whatever you want to have",
    "start": "50449",
    "end": "55859"
  },
  {
    "text": "so let's see what we can do that there I work for elastic the company behind the elastic stack maybe you're using our",
    "start": "55859",
    "end": "62309"
  },
  {
    "text": "stuff already for logging and monitoring so let's see what we can do here I have",
    "start": "62309",
    "end": "67590"
  },
  {
    "text": "a very simple application so if you're using spring in the Java ecosystem that",
    "start": "67590",
    "end": "72900"
  },
  {
    "text": "the application is not relevant at all like we have this application you can find somebody so for example you can",
    "start": "72900",
    "end": "79050"
  },
  {
    "text": "search for Frank Leland here and you could find a person and then if my",
    "start": "79050",
    "end": "84720"
  },
  {
    "text": "search loads for Internet is connected it should find Franklin maybe or not now",
    "start": "84720",
    "end": "98960"
  },
  {
    "text": "you can see there veterinaries which will load in a second and you could also",
    "start": "98960",
    "end": "104550"
  },
  {
    "text": "cause an error and then something bad happens and that's as much as we care about the application basically it just",
    "start": "104550",
    "end": "110070"
  },
  {
    "text": "sometimes it's it slow sometimes it produces errors and we want to see what is happening here before we dive into",
    "start": "110070",
    "end": "117690"
  },
  {
    "text": "the application right away let's take a quick look at what we have built here and we won't look at too much of the",
    "start": "117690",
    "end": "124920"
  },
  {
    "text": "code or anything basically we have kind of a ingress from kubernetes then we",
    "start": "124920",
    "end": "131459"
  },
  {
    "text": "have the front and side of stuff so we have a reactor plication backed by a node application and we have three of",
    "start": "131459",
    "end": "137939"
  },
  {
    "text": "those running and then we have two back-end services more or less so we have a job application that is talking",
    "start": "137939",
    "end": "144360"
  },
  {
    "text": "to my sequel and we have a flask application that is talking to elasticsearch and maybe remember this",
    "start": "144360",
    "end": "151349"
  },
  {
    "text": "graphics because we kind of like get back to this structure like these applications is are talking to this and",
    "start": "151349",
    "end": "156360"
  },
  {
    "text": "these applications are talking to that but the other stuff that we're kind of most interested in are basically these",
    "start": "156360",
    "end": "162300"
  },
  {
    "text": "little squares here because this is then the monitoring part that we will use and I'll show you as we go along more about",
    "start": "162300",
    "end": "170400"
  },
  {
    "text": "the monitoring part and how we do that stuff there so if you hear elastic stack probably you have something like this in",
    "start": "170400",
    "end": "176519"
  },
  {
    "text": "mind so these are the components that you have so you have the beats which are like lightweight agents of shippers",
    "start": "176519",
    "end": "181680"
  },
  {
    "start": "180000",
    "end": "240000"
  },
  {
    "text": "they're basically shipping information off like could be files metrics Network",
    "start": "181680",
    "end": "186989"
  },
  {
    "text": "data security data any anything like that you could have log stash to do",
    "start": "186989",
    "end": "192120"
  },
  {
    "text": "parsing and enrichment what do I mean when I say parsing just shout you you",
    "start": "192120",
    "end": "200819"
  },
  {
    "text": "could just have for example a log line and then in the log line you have a timestamp and a log level and you might want to",
    "start": "200819",
    "end": "206459"
  },
  {
    "text": "extract those that you can filter down on those what is enrichment for example",
    "start": "206459",
    "end": "212160"
  },
  {
    "text": "you have an IP address and you want to have the geolocation of the IP address so you want to get the geo point this to",
    "start": "212160",
    "end": "217620"
  },
  {
    "text": "say like these are all the users coming from Denmark today and just segment down on those so it could be adding metadata",
    "start": "217620",
    "end": "224070"
  },
  {
    "text": "but metadata could also be stuff like kubernetes or docker metadata that will be much more interesting for us today to",
    "start": "224070",
    "end": "230760"
  },
  {
    "text": "add that because you might be interested in just give me a specific namespace or give me the information for one pod or I",
    "start": "230760",
    "end": "237390"
  },
  {
    "text": "am interested in one specific base image all of that could be metadata that you add to your events so the log itself",
    "start": "237390",
    "end": "243870"
  },
  {
    "start": "240000",
    "end": "300000"
  },
  {
    "text": "doesn't really know or care about that but you could add that as you go along then you can ship everything into",
    "start": "243870",
    "end": "249359"
  },
  {
    "text": "elasticsearch and Cubana can visualize that so let's see what we have here so where do we normally start oftentimes",
    "start": "249359",
    "end": "256200"
  },
  {
    "text": "logs I guess who is using some logs to debug production I guess that's also",
    "start": "256200",
    "end": "261840"
  },
  {
    "text": "pretty much everybody and I hope it's kind of centralized and you're not using SSH and tail anymore right well you",
    "start": "261840",
    "end": "270599"
  },
  {
    "text": "never know because we still see that every now and then and then people yeah maybe this is not the right",
    "start": "270599",
    "end": "276540"
  },
  {
    "text": "approach so if I come to this application here you can see I have a",
    "start": "276540",
    "end": "282120"
  },
  {
    "text": "lot of logs in the last 15 minutes or actually refresh let's refresh that and see what other events we have in that",
    "start": "282120",
    "end": "288540"
  },
  {
    "text": "time frame actually now we've properly refreshed and now it's a proper amount of logs like 200k in the last 15 minutes",
    "start": "288540",
    "end": "294930"
  },
  {
    "text": "or so which is probably too much to find anything in here but just to give you a quick idea what",
    "start": "294930",
    "end": "302100"
  },
  {
    "start": "300000",
    "end": "360000"
  },
  {
    "text": "we have here or before we actually do that let's filter down on that so I spoke about metadata and we could for",
    "start": "302100",
    "end": "309090"
  },
  {
    "text": "example say kubernetes dot labels app and then I could just say like I'm",
    "start": "309090",
    "end": "314970"
  },
  {
    "text": "interested in only one specific application that I have running here and my application could be the server side",
    "start": "314970",
    "end": "320820"
  },
  {
    "text": "of my pet clinic application and my logs generally don't really know about this",
    "start": "320820",
    "end": "325950"
  },
  {
    "text": "but this is just metadata that I have added here when I collected it and when",
    "start": "325950",
    "end": "331380"
  },
  {
    "text": "I filled it down on that rather than having two hundred thousand events now I only have less than a tenth or so which",
    "start": "331380",
    "end": "337950"
  },
  {
    "text": "is still a bit too much but let's look at one of these entries here and what we have here so looking at this one service",
    "start": "337950",
    "end": "348360"
  },
  {
    "text": "status the message is something like this what could this be or you actually",
    "start": "348360",
    "end": "354420"
  },
  {
    "text": "see it down here already this is an engine x-axis log so this is just what nginx is logging but maybe I'm more",
    "start": "354420",
    "end": "361350"
  },
  {
    "start": "360000",
    "end": "420000"
  },
  {
    "text": "interested for example in my java application then my engine x-axis log so we could exclude those as well for",
    "start": "361350",
    "end": "367350"
  },
  {
    "text": "example since we have a lot of structure information in here so you can see this here this is the raw",
    "start": "367350",
    "end": "373950"
  },
  {
    "text": "log that we've collected and we've extracted for example the IP address and we know where it was collected and what",
    "start": "373950",
    "end": "379470"
  },
  {
    "text": "kind of thing it was but we also added a lot of metadata for example the kubernetes metadata here or we have",
    "start": "379470",
    "end": "386910"
  },
  {
    "text": "extracted the Tokra metadata in the container levels labels and here for cloud we could see that this is running",
    "start": "386910",
    "end": "394800"
  },
  {
    "text": "on TCP how do I get all of that metadata but where do we start let's let's start",
    "start": "394800",
    "end": "402390"
  },
  {
    "text": "with the top core email or container information where could my log file get",
    "start": "402390",
    "end": "408210"
  },
  {
    "text": "the metadata to enrich my log files any guesses",
    "start": "408210",
    "end": "413720"
  },
  {
    "text": "probably the Dockers socket so what we generally do is in the log path to the",
    "start": "413720",
    "end": "420449"
  },
  {
    "start": "420000",
    "end": "480000"
  },
  {
    "text": "container we have two container ID and we used ed ID to actually query the docker socket",
    "start": "420449",
    "end": "425460"
  },
  {
    "text": "to get the metadata and then add it in a very similar fashion I get the same thing for kubernetes where when I get",
    "start": "425460",
    "end": "432690"
  },
  {
    "text": "the data then I have the kubernetes api server i just queried that with the right ID and then get the metadata of",
    "start": "432690",
    "end": "438599"
  },
  {
    "text": "that port back for example and to see what I have there for the cloud metadata",
    "start": "438599",
    "end": "444150"
  },
  {
    "text": "where do I get the cloud metadata from",
    "start": "444150",
    "end": "448250"
  },
  {
    "text": "yes there is the metadata endpoint which is I think the same for all at least three big cloud providers it's always",
    "start": "449660",
    "end": "456740"
  },
  {
    "text": "169 to 54 169 to 54 if you query that with curl for example you will basically",
    "start": "456740",
    "end": "463590"
  },
  {
    "text": "get back the metadata for the container itself so it will then tell you hey you're running on this cloud provider in",
    "start": "463590",
    "end": "469889"
  },
  {
    "text": "this availability zone in this region with this instance ID for example and then you could figure out oh just this",
    "start": "469889",
    "end": "475440"
  },
  {
    "text": "specific instance ID is down or my availability zone just went down obviously only add all of the relevant",
    "start": "475440",
    "end": "483030"
  },
  {
    "start": "480000",
    "end": "540000"
  },
  {
    "text": "information and not just random stuff but in our example we'll make pretty heavy use of all of that metadata so",
    "start": "483030",
    "end": "489960"
  },
  {
    "text": "this is how we get that metadata here in general and then for example I could say like I am I want to use some filters and",
    "start": "489960",
    "end": "497090"
  },
  {
    "text": "then I could for example say the way we collect some information is through an",
    "start": "497090",
    "end": "503099"
  },
  {
    "text": "event module and I want to say is not one-off and this will actually suggest",
    "start": "503099",
    "end": "508409"
  },
  {
    "text": "what the options are and I basically want to just exclude the nginx and my sequel locks which will then leave me",
    "start": "508409",
    "end": "514320"
  },
  {
    "text": "with my java application more or less here so if I filter down on that then we'll go from 16,000 events or so down",
    "start": "514320",
    "end": "521399"
  },
  {
    "text": "to 10,000 and if I open one of those here then you can see yeah this looks",
    "start": "521399",
    "end": "530430"
  },
  {
    "text": "like a job a log like debug something something something what we didn't cover",
    "start": "530430",
    "end": "536370"
  },
  {
    "text": "yet is how did I even get that information where do I put the",
    "start": "536370",
    "end": "541590"
  },
  {
    "start": "540000",
    "end": "600000"
  },
  {
    "text": "for word or file bit in our case to forward me the log file from my kubernetes host generally on a daemon",
    "start": "541590",
    "end": "552660"
  },
  {
    "text": "set the daemon set is you have one instance running basically on every host and that can then collect all the log",
    "start": "552660",
    "end": "558840"
  },
  {
    "text": "files from that host just to give you a quick idea of what that looks like so we",
    "start": "558840",
    "end": "564330"
  },
  {
    "text": "have the file bit daemon set here so kind is daemon set where you make sure",
    "start": "564330",
    "end": "570960"
  },
  {
    "text": "there is one instance running on every single host and then basically I say ok this is the docker image I want to run",
    "start": "570960",
    "end": "578160"
  },
  {
    "text": "you can pass in a configuration and some some values that the main things down",
    "start": "578160",
    "end": "584250"
  },
  {
    "text": "here are basically how to mount the data that you want to get for example here",
    "start": "584250",
    "end": "589830"
  },
  {
    "text": "the docker socket we mount that so we can actually query the docker socket to get the metadata for the docker images",
    "start": "589830",
    "end": "596360"
  },
  {
    "text": "that's something yet you define here and then we have the configuration map where",
    "start": "596360",
    "end": "601440"
  },
  {
    "start": "600000",
    "end": "660000"
  },
  {
    "text": "we actually configure how stuff is set up here and here for example you see all we now need to do is we need to say like",
    "start": "601440",
    "end": "607800"
  },
  {
    "text": "this is running on kubernetes and will then automatically collect all the kubernetes logs from that instance and",
    "start": "607800",
    "end": "615030"
  },
  {
    "text": "you don't need to specify any files and specify the path to those you just say like kubernetes and it will",
    "start": "615030",
    "end": "621270"
  },
  {
    "text": "automatically know how to fetch those I have added some sorry metadata our",
    "start": "621270",
    "end": "627570"
  },
  {
    "text": "conditions that if something is for example the container name is nginx then",
    "start": "627570",
    "end": "632850"
  },
  {
    "text": "it should be treated as an engine X log which kind of makes sense so it will",
    "start": "632850",
    "end": "638580"
  },
  {
    "text": "then know how to parse that file for our log let's have a look here what we",
    "start": "638580",
    "end": "645840"
  },
  {
    "text": "actually get from our application is this one here where do I get this from",
    "start": "645840",
    "end": "651030"
  },
  {
    "text": "from my log Upendra so let's have a very quick look at the log appendage just to show you what we're getting here so we",
    "start": "651030",
    "end": "656850"
  },
  {
    "text": "have spring pet clinic source main resources lock bag XML is what we use",
    "start": "656850",
    "end": "663090"
  },
  {
    "start": "660000",
    "end": "720000"
  },
  {
    "text": "here and this is basically the pattern so this is what my application is",
    "start": "663090",
    "end": "668670"
  },
  {
    "text": "basically spitting out I write it to system out so it lands in the default talker and kubernetes locks so",
    "start": "668670",
    "end": "675390"
  },
  {
    "text": "here I have the log level the logger and the message and this is exactly what we have here the log message the locker and",
    "start": "675390",
    "end": "681600"
  },
  {
    "text": "the actual message but here we have 2",
    "start": "681600",
    "end": "687870"
  },
  {
    "text": "log level nicely extracted so we can fill that out on that one for example how do I get from this string that I've",
    "start": "687870",
    "end": "695460"
  },
  {
    "text": "been writing out to this lock level here how do we extract that field has anybody",
    "start": "695460",
    "end": "705420"
  },
  {
    "text": "used our stack already so if you've been using log session in the past for example what was the thing you were",
    "start": "705420",
    "end": "711570"
  },
  {
    "text": "writing to actually parse log files anybody remembers croc the named regular",
    "start": "711570",
    "end": "718260"
  },
  {
    "text": "expressions basically you could just write a regular expression to parse this part here who likes writing regular",
    "start": "718260",
    "end": "725910"
  },
  {
    "start": "720000",
    "end": "780000"
  },
  {
    "text": "expressions anybody one two not so many okay I always say this is the Stockholm",
    "start": "725910",
    "end": "732690"
  },
  {
    "text": "Syndrome where you you get so used to writing or doing that that you start",
    "start": "732690",
    "end": "738300"
  },
  {
    "text": "liking it at some point just to give you a quick idea of what this looks like so what we do is basically and now we tie",
    "start": "738300",
    "end": "745230"
  },
  {
    "text": "together so this is the Log form format that we're writing out and then in the daemon set that I've just shown or sorry",
    "start": "745230",
    "end": "751380"
  },
  {
    "text": "the config map that I've just shown you we have the configuration and what we have is if I find it we have here if we",
    "start": "751380",
    "end": "759690"
  },
  {
    "text": "say pet clinic server this is basically my java application so if it's in that",
    "start": "759690",
    "end": "767100"
  },
  {
    "text": "kind of kubernetes application and it has that name then use this configuration here and this",
    "start": "767100",
    "end": "773610"
  },
  {
    "text": "configuration here basically says like every line needs to start with one of these because otherwise it might be a",
    "start": "773610",
    "end": "779790"
  },
  {
    "text": "Java stack trace and you don't want to break up with Java stack trace and collect that but what you also say is",
    "start": "779790",
    "end": "786830"
  },
  {
    "start": "780000",
    "end": "840000"
  },
  {
    "text": "here I want to use this techniques of our pipeline to actually parse this and",
    "start": "786830",
    "end": "792660"
  },
  {
    "text": "this is where we're putting the croc pattern or the regular expression because if I have here in these",
    "start": "792660",
    "end": "798750"
  },
  {
    "text": "pipelines its pertinax server this is what you basically do to parse this so",
    "start": "798750",
    "end": "804990"
  },
  {
    "text": "we take the message field so this is the message field we take this we apply this rule here to parse all the",
    "start": "804990",
    "end": "813810"
  },
  {
    "text": "different pieces out so you can see here those who set the like writing regular",
    "start": "813810",
    "end": "818820"
  },
  {
    "text": "expressions you know what is going on right so you see the line is starting this here is a croc pattern you can see",
    "start": "818820",
    "end": "825510"
  },
  {
    "text": "it starts with the percentage sign curly brace then this is the croc pattern",
    "start": "825510",
    "end": "830610"
  },
  {
    "text": "basically it's called block-level and we have a regular expression behind that how to know how to parse that you don't",
    "start": "830610",
    "end": "838320"
  },
  {
    "text": "have to write the raw regular expression croc is basically a named regular expression you can reuse existing patterns and what we then do is we parse",
    "start": "838320",
    "end": "845280"
  },
  {
    "start": "840000",
    "end": "900000"
  },
  {
    "text": "the log level and we put it into a field called log level and this is how it's getting parsed out nicely then we have a",
    "start": "845280",
    "end": "852270"
  },
  {
    "text": "space and then we have for example we have some string and we put that into a",
    "start": "852270",
    "end": "857640"
  },
  {
    "text": "field Handler and at the end anything that is left we put into a field reason for example if you look here now",
    "start": "857640",
    "end": "864000"
  },
  {
    "text": "reason this is exactly closing JPA into the manager this is exactly what is left",
    "start": "864000",
    "end": "869700"
  },
  {
    "text": "so this is how we have parsed that and this is how you can do that with parsing",
    "start": "869700",
    "end": "875280"
  },
  {
    "text": "if you don't like writing regular expressions there is by the way another way to do that and the one that we kind",
    "start": "875280",
    "end": "882540"
  },
  {
    "text": "of would recommend no this is the wrong slide no where's my slide this is the",
    "start": "882540",
    "end": "887820"
  },
  {
    "text": "slide I want you can also log structured if you write out jason logs directly you",
    "start": "887820",
    "end": "894330"
  },
  {
    "text": "can just consume jason locks or even if you use csv logs for example it would be much easier to parse so if your",
    "start": "894330",
    "end": "900960"
  },
  {
    "text": "application regardless of the programming language spits out jason logs already you don't have to parse",
    "start": "900960",
    "end": "906780"
  },
  {
    "text": "them again because it's kind of stupid what we're doing my application knows what all the different fields are then i",
    "start": "906780",
    "end": "912480"
  },
  {
    "text": "write out one line to disk then i fetched the file out the line from disk",
    "start": "912480",
    "end": "917520"
  },
  {
    "text": "and then i parse it apart again if you write it out structured i directly you can skip all of that parsing magic",
    "start": "917520",
    "end": "924060"
  },
  {
    "text": "around it so that would make your life easier and there are various libraries one from us but those are from others these are just",
    "start": "924060",
    "end": "930120"
  },
  {
    "text": "job examples but all the other major programming languages have some log upended that can write out proper locks",
    "start": "930120",
    "end": "936750"
  },
  {
    "text": "as well one thing that is also interesting here is let's",
    "start": "936750",
    "end": "943000"
  },
  {
    "text": "back to the conflict map I'm doing one other thing here tax this is basically a",
    "start": "943000",
    "end": "950620"
  },
  {
    "text": "custom field I'm attaching so basically what I could also do rather than saying I want to have the infraorder that the",
    "start": "950620",
    "end": "957610"
  },
  {
    "text": "Potomac server and I want to exclude nginx and my sequel you could just look for the tag pet clinic server because",
    "start": "957610",
    "end": "964750"
  },
  {
    "start": "960000",
    "end": "1020000"
  },
  {
    "text": "this is the tag I'm adding specifically when I know I found a Java log and just",
    "start": "964750",
    "end": "970329"
  },
  {
    "text": "to show you how you can also work with logs we have this other view here this",
    "start": "970329",
    "end": "976389"
  },
  {
    "text": "is called the so-called locks UI those who like tail F will feel right at home because here we basically have a live",
    "start": "976389",
    "end": "983079"
  },
  {
    "text": "streaming mode and this will just keep streaming all the logs but we can also",
    "start": "983079",
    "end": "988480"
  },
  {
    "text": "filter here for example here I can just use these tags the field that we have just seen and I can then say it will",
    "start": "988480",
    "end": "995050"
  },
  {
    "text": "even suggest like all the options we have I can just say I'm only interested in the pet clinic server and that is the",
    "start": "995050",
    "end": "1000180"
  },
  {
    "text": "tag I've added here if I apply that you can see now we only have the Java logs",
    "start": "1000180",
    "end": "1005819"
  },
  {
    "text": "and you can see it just keeps streaming and the nice thing is even though we have thousands of log events happening",
    "start": "1005819",
    "end": "1011910"
  },
  {
    "text": "every minute unless something goes wrong",
    "start": "1011910",
    "end": "1017339"
  },
  {
    "text": "like now this is no good because this is",
    "start": "1017339",
    "end": "1025980"
  },
  {
    "start": "1020000",
    "end": "1080000"
  },
  {
    "text": "a proper online demo let me check yes I guess we yeah we're",
    "start": "1025980",
    "end": "1038220"
  },
  {
    "text": "good again so yeah if you are not online then suddenly your locks are gone I hope",
    "start": "1038220",
    "end": "1043740"
  },
  {
    "text": "they are reappearing now maybe yeah",
    "start": "1043740",
    "end": "1050179"
  },
  {
    "text": "stuff is happening again so now you can see here I can turn on the die screaming",
    "start": "1050179",
    "end": "1055530"
  },
  {
    "text": "again and you can just see streaming the subset of things that you have filtered for here so whatever you have in the",
    "start": "1055530",
    "end": "1062010"
  },
  {
    "text": "metadata or even in the full-text of your locks you could just search for that and then watch it stream by which",
    "start": "1062010",
    "end": "1068070"
  },
  {
    "text": "is very handy if you have some bug and you're trying to debug something in production and you want to see the right locks for that or you could just say for",
    "start": "1068070",
    "end": "1075570"
  },
  {
    "text": "example if you if the log level extracted here you could just look for any debug message",
    "start": "1075570",
    "end": "1081180"
  },
  {
    "start": "1080000",
    "end": "1140000"
  },
  {
    "text": "URLs or error messages or whatever and filter down to those things so this is",
    "start": "1081180",
    "end": "1086580"
  },
  {
    "text": "helpful if you have any errors but sometimes you also have other problems that people say like your application is",
    "start": "1086580",
    "end": "1092970"
  },
  {
    "text": "slow which is one of the worse things because slow can mean a lot of things that is very hard to debug one thing",
    "start": "1092970",
    "end": "1099930"
  },
  {
    "text": "that we have now as well is a PM or tracing is anybody using any APM or",
    "start": "1099930",
    "end": "1105120"
  },
  {
    "text": "tracing tool couple okay how do I get that into my java application",
    "start": "1105120",
    "end": "1111360"
  },
  {
    "text": "so tracing is basically you add something to your application that will watch calls coming in and then it will",
    "start": "1111360",
    "end": "1118710"
  },
  {
    "text": "follow one call along throughout your application can be even be across services it will follow that along and",
    "start": "1118710",
    "end": "1124440"
  },
  {
    "text": "then show you at the end like what called what where did you spend your time it will also extract stuff like",
    "start": "1124440",
    "end": "1129720"
  },
  {
    "text": "maybe HTTP headers when you called it it might show SQL queries it will show a lot of the details or the call stack of",
    "start": "1129720",
    "end": "1136080"
  },
  {
    "text": "what you have gotten in your application so how do I get that tracing into my",
    "start": "1136080",
    "end": "1142290"
  },
  {
    "start": "1140000",
    "end": "1200000"
  },
  {
    "text": "java application for example or who is generally using Java okay a good bunch",
    "start": "1142290",
    "end": "1150150"
  },
  {
    "text": "how do I get an agent into my java application normally we have this",
    "start": "1150150",
    "end": "1156510"
  },
  {
    "text": "concept of - Java agent that you can just add at runtime and so you just attach it it's not a billet dependency",
    "start": "1156510",
    "end": "1162750"
  },
  {
    "text": "it's just something that you add when you run your application and want to instrument it then you can just add that",
    "start": "1162750",
    "end": "1168780"
  },
  {
    "text": "at runtime where do you put that maybe potentially in the docker file so we",
    "start": "1168780",
    "end": "1175050"
  },
  {
    "text": "have a custom docker file if I would see it here we have a Tucker file and this",
    "start": "1175050",
    "end": "1181440"
  },
  {
    "text": "is very hard to see what we want to show",
    "start": "1181440",
    "end": "1187170"
  },
  {
    "text": "here is this is basically the configuration that I have here and what",
    "start": "1187170",
    "end": "1192450"
  },
  {
    "text": "I have is at the very end this is my application and somewhere here even though I don't see there's a Java agent",
    "start": "1192450",
    "end": "1199770"
  },
  {
    "text": "how I basically set it up and then this is all the configuration you need otherwise your application doesn't touch",
    "start": "1199770",
    "end": "1205920"
  },
  {
    "text": "any agent specific things it will just who can to your application and extract the data",
    "start": "1205920",
    "end": "1211380"
  },
  {
    "text": "for other programming languages it might be a built dependency so for example if you use Python or react it would be a",
    "start": "1211380",
    "end": "1218430"
  },
  {
    "text": "built dependency that when you build your application the agent will be added and then it will extract at runtime the",
    "start": "1218430",
    "end": "1224610"
  },
  {
    "text": "metadata and what you basically have is first it figures out what services we have so these are all the services that",
    "start": "1224610",
    "end": "1230310"
  },
  {
    "text": "we have and then we could just look for example at the java application but we can look at the others as well and you",
    "start": "1230310",
    "end": "1235590"
  },
  {
    "text": "can see this seems to be going pretty well like over time you can see where",
    "start": "1235590",
    "end": "1241590"
  },
  {
    "text": "you spend your time it's like 50/50 between application and database there",
    "start": "1241590",
    "end": "1247140"
  },
  {
    "text": "are no major spikes so this looks okay and then further down you can see how long do your calls take like average",
    "start": "1247140",
    "end": "1254660"
  },
  {
    "text": "95th percentile and 99th percentile and you can also see how many requests per minute are you doing on average so here",
    "start": "1254660",
    "end": "1261930"
  },
  {
    "text": "we do it I don't know 20 ish to 30 ish and 201 or two for hundreds for pages",
    "start": "1261930",
    "end": "1270330"
  },
  {
    "text": "that were not found and at the bottom here you can also see this is in Java terms this is the class and this is the",
    "start": "1270330",
    "end": "1276810"
  },
  {
    "text": "method that has been called and you can see a how long does it take to call that and how many times is it being called",
    "start": "1276810",
    "end": "1284070"
  },
  {
    "text": "per minute and here this impact at the end is basically we multiply the transactions per minute times how often",
    "start": "1284070",
    "end": "1290910"
  },
  {
    "text": "it's called and the idea is that this will show you where are you wasting most of your time so if you optimize the",
    "start": "1290910",
    "end": "1297090"
  },
  {
    "text": "things that are being called most often that are slowest this is probably the point or things that where you should",
    "start": "1297090",
    "end": "1302700"
  },
  {
    "text": "start looking into is it fast enough for what I'm trying to do and we could for example look at get honors just to get",
    "start": "1302700",
    "end": "1308730"
  },
  {
    "text": "an idea of what is this is collecting so you can see this is where we're spending our time here so here the database is",
    "start": "1308730",
    "end": "1315870"
  },
  {
    "text": "spending or we're spending two thirds of the time in my database now maybe this is not what we want we can have a look",
    "start": "1315870",
    "end": "1322830"
  },
  {
    "text": "into that you can see how long transactions take here you see basically an aggregation like we had 1,900",
    "start": "1322830",
    "end": "1329820"
  },
  {
    "text": "requests or so that were very fast and took like up to 23 milliseconds but we also had one request here that took",
    "start": "1329820",
    "end": "1336750"
  },
  {
    "text": "around 300 milliseconds but that's still pretty decent for most applications what",
    "start": "1336750",
    "end": "1342450"
  },
  {
    "text": "we can also see is for dispatch of course we have the call stack down here so first you can see",
    "start": "1342450",
    "end": "1349440"
  },
  {
    "text": "this is what is being called for example here you can see the end point you can see it was a two hundred that came back",
    "start": "1349440",
    "end": "1355700"
  },
  {
    "text": "and then you can see for example all the header parameters that came with that but what you can also see is this weird",
    "start": "1355700",
    "end": "1363300"
  },
  {
    "text": "pattern here what do we have here yeah",
    "start": "1363300",
    "end": "1370020"
  },
  {
    "text": "we have this especially if you use some ORM tool you have this n plus 1 pattern",
    "start": "1370020",
    "end": "1375270"
  },
  {
    "text": "like you do one database call and based on the result of that you start calling another database called to fetch more",
    "start": "1375270",
    "end": "1380940"
  },
  {
    "text": "information and then you do another call and then another which is normally not very good for performance because you",
    "start": "1380940",
    "end": "1386550"
  },
  {
    "text": "will have lots on back and forth with the database that's also why suddenly here we're spending way more time in the",
    "start": "1386550",
    "end": "1393480"
  },
  {
    "text": "database basically than in the application and we could even look at one of these here and look like this is",
    "start": "1393480",
    "end": "1400650"
  },
  {
    "text": "the actual query that we are running and then you could check like if it's a slow query should what should I optimize the",
    "start": "1400650",
    "end": "1406050"
  },
  {
    "text": "query or in this case probably we should look into not having this n plus one problem where it's more and more and",
    "start": "1406050",
    "end": "1412440"
  },
  {
    "text": "more database calls as we go further down so this is stuff that you can very easily see but I've also prepared",
    "start": "1412440",
    "end": "1418470"
  },
  {
    "text": "another scenario in a specific time frame here where our application might look something like this so here we see",
    "start": "1418470",
    "end": "1425850"
  },
  {
    "text": "some very weird pattern you can see here my application every now and then has this spike where it's very slow like",
    "start": "1425850",
    "end": "1431160"
  },
  {
    "text": "generally it's fast but every now and then it's slow and ok the requests per",
    "start": "1431160",
    "end": "1436470"
  },
  {
    "text": "minute are pretty stable so that doesn't seem to be the issue we could also swim into this one for example here I could just mark this",
    "start": "1436470",
    "end": "1442590"
  },
  {
    "text": "error area and then it will zoom into this one we could even zoom further in and you can see okay here there is a",
    "start": "1442590",
    "end": "1449310"
  },
  {
    "text": "clear spike where the response times are just very high and it still get honest",
    "start": "1449310",
    "end": "1454740"
  },
  {
    "text": "but overall lots of these are kind of slow because all of them are kind of",
    "start": "1454740",
    "end": "1459750"
  },
  {
    "text": "higher than they used to be so I'm not unless you I'm not really sure what is",
    "start": "1459750",
    "end": "1464790"
  },
  {
    "text": "happening here and those are the calls are pretty stable but this is not like a big like cooking show obviously I have",
    "start": "1464790",
    "end": "1471750"
  },
  {
    "text": "prepared something and I've prepared the right dashboard to show you what is going on here or to get close by",
    "start": "1471750",
    "end": "1477539"
  },
  {
    "text": "basically so what we have here is this is a dashboard that works for my application because I know I have four",
    "start": "1477539",
    "end": "1482879"
  },
  {
    "text": "services I have the Pythian application i have the java application i have the note backend and then I have the",
    "start": "1482879",
    "end": "1488249"
  },
  {
    "text": "reactive front-end so these are basically the four applications that I have you can see how many instances I",
    "start": "1488249",
    "end": "1493379"
  },
  {
    "text": "have running number of users percentage of response times etc and for example",
    "start": "1493379",
    "end": "1499200"
  },
  {
    "text": "now if I look at the 99th percentile you can see we have these continuous spikes",
    "start": "1499200",
    "end": "1504899"
  },
  {
    "start": "1500000",
    "end": "1560000"
  },
  {
    "text": "here which is not what we want and at the bottom here I have basically an",
    "start": "1504899",
    "end": "1509940"
  },
  {
    "text": "aggregation of all the different services together and now you can see here we have these spikes and now I",
    "start": "1509940",
    "end": "1515970"
  },
  {
    "text": "could can look at the applications like is the react application kind of correlating with these spikes not really",
    "start": "1515970",
    "end": "1521909"
  },
  {
    "text": "it's not application correlating with that kind of yes so you can see here",
    "start": "1521909",
    "end": "1527369"
  },
  {
    "text": "this one spike has this bike this bike matches this bike this one here this one the Pythian application has spikes but",
    "start": "1527369",
    "end": "1534749"
  },
  {
    "text": "different ones so this is not the right trace the java application has again the",
    "start": "1534749",
    "end": "1539789"
  },
  {
    "text": "same spikes here if you remember from the very beginning the architecture",
    "start": "1539789",
    "end": "1545489"
  },
  {
    "text": "diagram that I've shown you maybe you remember how is disconnected what did",
    "start": "1545489",
    "end": "1553590"
  },
  {
    "text": "the load application and the spring application have in common what could",
    "start": "1553590",
    "end": "1559049"
  },
  {
    "text": "make both of them slow but not the Python application let me bring that one",
    "start": "1559049",
    "end": "1566580"
  },
  {
    "text": "up what what do the java application and",
    "start": "1566580",
    "end": "1571830"
  },
  {
    "text": "the node application kind of have in common that the pison application doesn't have yes and this is a pure",
    "start": "1571830",
    "end": "1580409"
  },
  {
    "text": "coincidence of course now that my sequel is slow and not elasticsearch but this",
    "start": "1580409",
    "end": "1586919"
  },
  {
    "text": "you will see in a moment why so maybe this is something we might want to look into the first the other thing that we",
    "start": "1586919",
    "end": "1594570"
  },
  {
    "text": "might be interested in as well is we might just look at resource starvation like how are we doing resource wise in",
    "start": "1594570",
    "end": "1599669"
  },
  {
    "text": "our instance so to look at that we have another visualization here that's called them the infrastructure UI basically you",
    "start": "1599669",
    "end": "1606809"
  },
  {
    "text": "can see so this is not running file bit but metric peat and this is pretty much like getting the data that top",
    "start": "1606809",
    "end": "1612480"
  },
  {
    "text": "would get you it can also get application metrics and other metrics but this specific view here is pretty",
    "start": "1612480",
    "end": "1617760"
  },
  {
    "text": "much what the Linux top command would give you and it's just sending that forward to centralized in elasticsearch",
    "start": "1617760",
    "end": "1624060"
  },
  {
    "start": "1620000",
    "end": "1680000"
  },
  {
    "text": "as well so these are all the hosts that we have running and actually this filter",
    "start": "1624060",
    "end": "1629460"
  },
  {
    "text": "should not be applied right now these are all the hosts that we have running so we have six hosts in our kubernetes cluster we can see these are all the",
    "start": "1629460",
    "end": "1637440"
  },
  {
    "text": "pods that we have here so this is 76 and then we have a couple of docker",
    "start": "1637440",
    "end": "1644010"
  },
  {
    "text": "containers as well but this is not all I have for my application this cluster is running multiple applications so I want",
    "start": "1644010",
    "end": "1650070"
  },
  {
    "text": "to dive into my specific cluster again and again we use the metadata to filter",
    "start": "1650070",
    "end": "1655380"
  },
  {
    "text": "down on that so I can say kubernetes if my browser would co-operate label",
    "start": "1655380",
    "end": "1663860"
  },
  {
    "text": "kubernetes app and this one here has the",
    "start": "1663860",
    "end": "1669840"
  },
  {
    "text": "info demo this is basically filtering down on this specific demo so now you can see just the docker containers for",
    "start": "1669840",
    "end": "1675930"
  },
  {
    "text": "this one or just the port and you can see this is the CPU usage and one is",
    "start": "1675930",
    "end": "1681210"
  },
  {
    "text": "sticking out you can already tell from the name what this one is this is data",
    "start": "1681210",
    "end": "1687180"
  },
  {
    "text": "base we could also look for example at the actual metrics of this instance over time once it's loading and you can see",
    "start": "1687180",
    "end": "1696690"
  },
  {
    "text": "here this looks kind of okay I'm I'm not really sure like network traffic looks okay memory usage is pretty stable CPU",
    "start": "1696690",
    "end": "1704880"
  },
  {
    "text": "usage as well but I'm not sure maybe maybe this is misleading and maybe maybe this time frame is too short and maybe",
    "start": "1704880",
    "end": "1711750"
  },
  {
    "text": "we should go to this time frame I don't know let's let's pick this one see if we",
    "start": "1711750",
    "end": "1718260"
  },
  {
    "text": "see more and lo and behold you can see every now and then we have these weird spikes which might correlate with the",
    "start": "1718260",
    "end": "1726180"
  },
  {
    "text": "slowness in our application any guesses already what is up with our database",
    "start": "1726180",
    "end": "1732980"
  },
  {
    "text": "well we'll see because I've prepared another thing here this is basically a",
    "start": "1733700",
    "end": "1740100"
  },
  {
    "start": "1740000",
    "end": "1800000"
  },
  {
    "text": "custom dashboard as well like this view and this view this and this these are all pre built like",
    "start": "1740100",
    "end": "1748169"
  },
  {
    "text": "this service analysis dashboard I've built just for my application and this my sequel dashboard is also custom built",
    "start": "1748169",
    "end": "1754830"
  },
  {
    "text": "but the others pre exist so what I've done here is I've combined multiple beats outputs so you can see",
    "start": "1754830",
    "end": "1761100"
  },
  {
    "text": "metric beat so metric beat can basically query my sequel and get the statistics from my sequel to see where it's",
    "start": "1761100",
    "end": "1767580"
  },
  {
    "text": "spending its time and you can see this is like how many open tables etc I'm also getting from all my instances the",
    "start": "1767580",
    "end": "1774840"
  },
  {
    "text": "CPU and memory usage here and you can see that's a lot of instances maybe more than I I can visually see but I've also",
    "start": "1774840",
    "end": "1782279"
  },
  {
    "text": "included here the my sequel performance and we can basically get that from packet beats OPEC app it is like",
    "start": "1782279",
    "end": "1788730"
  },
  {
    "text": "Wireshark who is using wireshark those are the desperate days right when you",
    "start": "1788730",
    "end": "1794549"
  },
  {
    "text": "have no idea what is going on anymore you look at the output for this Wireshark producing and we're kind of doing the same here so Wireshark",
    "start": "1794549",
    "end": "1800700"
  },
  {
    "start": "1800000",
    "end": "1860000"
  },
  {
    "text": "basically has this timing information and it knows like this the query sent how long does it take to send the answer",
    "start": "1800700",
    "end": "1807090"
  },
  {
    "text": "and you can see spikes here for example here you can see suddenly you have weird spikes that sometimes your my sequel",
    "start": "1807090",
    "end": "1812940"
  },
  {
    "text": "queries are just slower and you can also see processes and network traffic network traffic so it looks pretty ok so",
    "start": "1812940",
    "end": "1820499"
  },
  {
    "text": "I don't see any outliers here processes look pretty okay as well what I'm interested in now is I want to zoom into",
    "start": "1820499",
    "end": "1826889"
  },
  {
    "text": "one of these slowness spikes of my database ok let's zoom in a bit more and now you",
    "start": "1826889",
    "end": "1835440"
  },
  {
    "text": "can already see ok this looks pretty interesting like we have one spike for this instance here like in for a pet",
    "start": "1835440",
    "end": "1842460"
  },
  {
    "text": "clinic my sequel see see something you could either just filter down on this instance here in the filter or for more",
    "start": "1842460",
    "end": "1849779"
  },
  {
    "text": "convenience we can have fact control here and I think this one was called what was it infra in from the sea sea",
    "start": "1849779",
    "end": "1862739"
  },
  {
    "start": "1860000",
    "end": "1920000"
  },
  {
    "text": "yes see see this is the one I want because this is probably slow so we filter down",
    "start": "1862739",
    "end": "1869009"
  },
  {
    "text": "on this instance here now and now it's probably pretty obvious what is happening so we have this one job here",
    "start": "1869009",
    "end": "1875999"
  },
  {
    "text": "running and here you also see where is your sip spending its time and then suddenly you see okay this is where the time is being",
    "start": "1875999",
    "end": "1884730"
  },
  {
    "text": "spent basically so you have a regular snapshot job that is slowing down your entire database that is also going",
    "start": "1884730",
    "end": "1890639"
  },
  {
    "text": "through your entire application and we've basically followed that along here so that's fine but sometimes it's not",
    "start": "1890639",
    "end": "1898019"
  },
  {
    "text": "the beta database sometimes it's something else for example let's say we have users and the user calls support",
    "start": "1898019",
    "end": "1905549"
  },
  {
    "text": "and says like your application has been slow in the last two weeks and you're like I'm not sure maybe where could we",
    "start": "1905549",
    "end": "1913230"
  },
  {
    "text": "start looking we could looking at tracing again so let's for example go to our java application and they set the last two weeks right so let's look at",
    "start": "1913230",
    "end": "1919619"
  },
  {
    "text": "the last two weeks so let's say two weeks ago okay we see lots of ups and",
    "start": "1919619",
    "end": "1930029"
  },
  {
    "start": "1920000",
    "end": "1980000"
  },
  {
    "text": "downs this is a bit hard to tell what you can also do is since classic search",
    "start": "1930029",
    "end": "1935460"
  },
  {
    "text": "kind of the history where it all came from was search the good thing is you can always search on anything here so",
    "start": "1935460",
    "end": "1940559"
  },
  {
    "text": "for example what is even suggested here is you look at the transaction duration that is greater than some number so",
    "start": "1940559",
    "end": "1946590"
  },
  {
    "text": "let's let's do that that's transaction duration microseconds if I want every all the transaction that",
    "start": "1946590",
    "end": "1953460"
  },
  {
    "text": "are slower than two seconds how many zeros do I need six yes one two three",
    "start": "1953460",
    "end": "1961739"
  },
  {
    "text": "one two three then we filter down on that and we don't find anything why yes",
    "start": "1961739",
    "end": "1970950"
  },
  {
    "text": "exactly this should probably be greater than or greater than equals and not just two",
    "start": "1970950",
    "end": "1976649"
  },
  {
    "text": "seconds because two seconds exactly is also interesting but probably not what your users were experiencing it's always",
    "start": "1976649",
    "end": "1983100"
  },
  {
    "text": "nice to see that you're paying attention and then when we look at this one here we see that there is exactly one method",
    "start": "1983100",
    "end": "1988679"
  },
  {
    "text": "that is slow and you can see over time it wasn't called very frequently but when it was called it was really slow",
    "start": "1988679",
    "end": "1994230"
  },
  {
    "text": "and I can look into that one and you can for example see so these are the",
    "start": "1994230",
    "end": "1999299"
  },
  {
    "text": "aggregations so we had some that took 50 seconds and this one here was still 25 seconds so this is still pretty slow and",
    "start": "1999299",
    "end": "2007090"
  },
  {
    "text": "once it finished loading it will call me the",
    "start": "2007090",
    "end": "2012170"
  },
  {
    "text": "call stack down here and the caustic is actually very short you can see this was the overall call you can see it was it",
    "start": "2012170",
    "end": "2019010"
  },
  {
    "text": "got back at 400 which is weird why would it get it 400 we could even look at the error but it's not telling us that much",
    "start": "2019010",
    "end": "2024050"
  },
  {
    "text": "here and we can see where we spent all our time we spent 26 seconds invalidate",
    "start": "2024050",
    "end": "2030170"
  },
  {
    "text": "ZIP code in this one call and basically what we have here is we have Bella dead",
    "start": "2030170",
    "end": "2035180"
  },
  {
    "text": "zip code validator on line 33 and then 12 and by the way you can define your",
    "start": "2035180",
    "end": "2042830"
  },
  {
    "start": "2040000",
    "end": "2100000"
  },
  {
    "text": "own namespace because most of the time you're probably interested in your own namespace for stuff and not the framework you're using and this is",
    "start": "2042830",
    "end": "2049100"
  },
  {
    "text": "exactly what we have done here so it knows because I've annotated my own namespace here this is my namespace and",
    "start": "2049100",
    "end": "2054770"
  },
  {
    "text": "it will only show this by default and then this is the framework that you're using in the background - it will hide",
    "start": "2054770",
    "end": "2060260"
  },
  {
    "text": "that by default and I would be curious what is that one here so let's let's",
    "start": "2060260",
    "end": "2066620"
  },
  {
    "text": "find validate zip code and look at that one and you can see here okay we return",
    "start": "2066620",
    "end": "2071810"
  },
  {
    "text": "and match and we have some regular expression here and actually this is the",
    "start": "2071810",
    "end": "2078200"
  },
  {
    "text": "regular expression those who set the like writing regular expressions maybe you can already see that this is a",
    "start": "2078200",
    "end": "2084110"
  },
  {
    "text": "pretty bad regular expression this is intentionally badly written and to show",
    "start": "2084110",
    "end": "2089810"
  },
  {
    "text": "you what is basically going wrong so you're spending a lot of time in that zip code validation and since we were",
    "start": "2089810",
    "end": "2095840"
  },
  {
    "text": "capturing the actual request here so if you look at the request here you can see",
    "start": "2095840",
    "end": "2102110"
  },
  {
    "start": "2100000",
    "end": "2160000"
  },
  {
    "text": "somewhere here we have a zip code here is zip code and you can see this is a very long zip code and this is exactly",
    "start": "2102110",
    "end": "2108950"
  },
  {
    "text": "the problem that our regular expression for the zip code is very bad and that's why this call is very slow in the end",
    "start": "2108950",
    "end": "2114050"
  },
  {
    "text": "and then you can fix the zip code is it a very made-up example that bad regular",
    "start": "2114050",
    "end": "2119120"
  },
  {
    "text": "expressions might bring down your applications not really maybe you",
    "start": "2119120",
    "end": "2124370"
  },
  {
    "text": "remember the cloud for their outage recently like I think it was this summer where CloudFlare had the big outage",
    "start": "2124370",
    "end": "2131540"
  },
  {
    "text": "where some bad regular expression that they were deploying was taking down their entire service so bad regular",
    "start": "2131540",
    "end": "2137000"
  },
  {
    "text": "expressions are kind of a common thing if you like them nice but be careful to",
    "start": "2137000",
    "end": "2142520"
  },
  {
    "text": "not take down your application here another thing that you could for example",
    "start": "2142520",
    "end": "2147710"
  },
  {
    "text": "look at do we still have time yeah we still have a couple of minutes that's",
    "start": "2147710",
    "end": "2153410"
  },
  {
    "text": "good no this is not the one I want this is the final one I wanted to show so for example here I've picked a special time",
    "start": "2153410",
    "end": "2159080"
  },
  {
    "text": "frame because I have a hard time replicating that here I mean my react application so this is the front-end",
    "start": "2159080",
    "end": "2164630"
  },
  {
    "start": "2160000",
    "end": "2220000"
  },
  {
    "text": "side because every now and then some users complained that for them the application is slow and we do tracing in",
    "start": "2164630",
    "end": "2170600"
  },
  {
    "text": "Python react angular in all kinds of frameworks just to give you a JavaScript example if that is more you thing and",
    "start": "2170600",
    "end": "2177050"
  },
  {
    "text": "we're doing the same thing transaction duration and this time I'll go for",
    "start": "2177050",
    "end": "2182210"
  },
  {
    "text": "greater than five seconds one two three one two three I'll filter down on that",
    "start": "2182210",
    "end": "2189410"
  },
  {
    "text": "one and here for example you can see I'm not sure what is happening like it's",
    "start": "2189410",
    "end": "2195710"
  },
  {
    "text": "lots of pages is not one that is slow they're all slow this is all terrible basically and let's look at one to",
    "start": "2195710",
    "end": "2202430"
  },
  {
    "text": "figure out what is going on so you can see here obviously there are no calls below this one here because we filter",
    "start": "2202430",
    "end": "2209180"
  },
  {
    "text": "those out we've only got the slow calls now and I don't know you see here this",
    "start": "2209180",
    "end": "2214340"
  },
  {
    "text": "one I don't know this is spending a lot of time here but I'm not really sure what is going on or let's look at owner",
    "start": "2214340",
    "end": "2222170"
  },
  {
    "start": "2220000",
    "end": "2280000"
  },
  {
    "text": "editor page now it's loading or aggregating the right traces together",
    "start": "2222170",
    "end": "2228110"
  },
  {
    "text": "for me for this page you can see it was less you only collected a couple of times and once it's done loading come on",
    "start": "2228110",
    "end": "2236390"
  },
  {
    "text": "I think it also wants to go home this one is also interesting but not the one",
    "start": "2236390",
    "end": "2243200"
  },
  {
    "text": "I wanted let's go to back to the original one here you can see there's nothing happening initially and when you",
    "start": "2243200",
    "end": "2250250"
  },
  {
    "text": "see that page is anything sticking out to you here sorry yes the user agent",
    "start": "2250250",
    "end": "2262330"
  },
  {
    "text": "this is somebody's using a terrible browser that was probably not doing so",
    "start": "2262330",
    "end": "2268280"
  },
  {
    "text": "well with react and this is why I have a hard time reproducing that on my laptop",
    "start": "2268280",
    "end": "2273680"
  },
  {
    "text": "because luckily I don't have Internet Explorer but we I think",
    "start": "2273680",
    "end": "2280040"
  },
  {
    "start": "2280000",
    "end": "2340000"
  },
  {
    "text": "set up some virtual machine somewhere to actually create those and here you can",
    "start": "2280040",
    "end": "2285080"
  },
  {
    "text": "then basically see Oh Internet Explorer and then once you have that you could since this is all search you could then",
    "start": "2285080",
    "end": "2291500"
  },
  {
    "text": "say like oh let's filter down on actual user agent and just search for Internet Explorer and then you will find all",
    "start": "2291500",
    "end": "2297020"
  },
  {
    "text": "kinds of slow queries for Internet Explorer so this is kind of how to explore stuff and since this is all based on search user age so this is just",
    "start": "2297020",
    "end": "2315560"
  },
  {
    "text": "this page here but you could probably see let's write it out if we go to the one of the very slow cause I hope I",
    "start": "2315560",
    "end": "2322910"
  },
  {
    "text": "haven't tested this before and this will be another Internet Explorer call and then you would say can or then you can",
    "start": "2322910",
    "end": "2328280"
  },
  {
    "text": "tell people basically please change your browser because we don't want to support this let's see okay this is already",
    "start": "2328280",
    "end": "2336530"
  },
  {
    "text": "Internet Explorer 9 but it's not much better here that actually has another",
    "start": "2336530",
    "end": "2342350"
  },
  {
    "start": "2340000",
    "end": "2460000"
  },
  {
    "text": "error inside so here this was calling some 404 internally as well but you can",
    "start": "2342350",
    "end": "2347870"
  },
  {
    "text": "even see like okay this is from my react application this was calling a 404 and you can even see the code where this",
    "start": "2347870",
    "end": "2353360"
  },
  {
    "text": "happened and then you can figure out who wrote the bad code and who needs to fix",
    "start": "2353360",
    "end": "2358490"
  },
  {
    "text": "the code here to actually see that so that can all be aggregated finally what you probably want to have is some uptime",
    "start": "2358490",
    "end": "2364790"
  },
  {
    "text": "monitoring and you can throw that in here as well so we have it's called heartbeat is just pinning things",
    "start": "2364790",
    "end": "2371270"
  },
  {
    "text": "it supports I simply TCP HTTP and HTTPS it can even do basic auth and it can",
    "start": "2371270",
    "end": "2378050"
  },
  {
    "text": "check to the page as a certain string in it etc and here you can see in the last 15 minutes we have just been pinging",
    "start": "2378050",
    "end": "2384830"
  },
  {
    "text": "these pages but they are both up now but this one has been down for a while and you can also see if I would extend the",
    "start": "2384830",
    "end": "2393590"
  },
  {
    "text": "time frame we would probably have more services here so if I say the last 15 month I'm not even sure what we have",
    "start": "2393590",
    "end": "2400610"
  },
  {
    "text": "been running in the last 15 months but this will now aggregate together all the",
    "start": "2400610",
    "end": "2407030"
  },
  {
    "text": "heartbeat things that we have been doing in the last 15 months and well you can see these were all the services that",
    "start": "2407030",
    "end": "2413210"
  },
  {
    "text": "we've been piñon over time and you hear you can just define one endpoint like a status",
    "start": "2413210",
    "end": "2418950"
  },
  {
    "text": "page and then in the status page you can check is it up or is it down for example where would you run this pinger do you",
    "start": "2418950",
    "end": "2425549"
  },
  {
    "text": "run this as part of your communities cluster as well yeah ideally outside",
    "start": "2425549",
    "end": "2431009"
  },
  {
    "text": "where you can also test something like here this is already questionable because probably you want to have more",
    "start": "2431009",
    "end": "2436079"
  },
  {
    "text": "of an end-to-end test that you also want to test stuff like DNS and maybe a TLS",
    "start": "2436079",
    "end": "2441269"
  },
  {
    "text": "certificate and that's all you can do with the heartbeat as well so if you run that externally you could basically get",
    "start": "2441269",
    "end": "2447299"
  },
  {
    "text": "your end-users view and see like okay DNS is working and the certificate is still good and the service is actually",
    "start": "2447299",
    "end": "2452849"
  },
  {
    "text": "responding and then you could just say like I'm interested in one specific service let's go back to the last 15",
    "start": "2452849",
    "end": "2458940"
  },
  {
    "text": "minutes for example the last 15 hours let's see what has been running here",
    "start": "2458940",
    "end": "2466880"
  },
  {
    "start": "2460000",
    "end": "2520000"
  },
  {
    "text": "hopefully ok these are the services that",
    "start": "2468950",
    "end": "2473970"
  },
  {
    "text": "have been running and then you could for example just look at this one here you can see okay now we're filtering down on",
    "start": "2473970",
    "end": "2480569"
  },
  {
    "text": "that one even though it hasn't been",
    "start": "2480569",
    "end": "2486930"
  },
  {
    "text": "running to a year ago no this is not what I want let's see you should have been running",
    "start": "2486930",
    "end": "2492210"
  },
  {
    "text": "in that time frame somewhere ideally maybe",
    "start": "2492210",
    "end": "2498828"
  },
  {
    "text": "okay for whatever reason it doesn't load the proper time frame but here would tendency like a was it up or down and P",
    "start": "2506410",
    "end": "2513619"
  },
  {
    "text": "also you would see while doing this I",
    "start": "2513619",
    "end": "2520390"
  },
  {
    "start": "2520000",
    "end": "2580000"
  },
  {
    "text": "think it doesn't want to work anymore as well and here would you would see a",
    "start": "2520390",
    "end": "2526300"
  },
  {
    "text": "things over time like in terms of latency and you would also see like has it been green or not green and has it",
    "start": "2526300",
    "end": "2533270"
  },
  {
    "text": "been responding and that's the general idea here so Tomales wrap-up I think",
    "start": "2533270",
    "end": "2542060"
  },
  {
    "text": "we've covered pretty much everything else you'll get the slides afterwards okay basically get an idea of or you can",
    "start": "2542060",
    "end": "2549200"
  },
  {
    "text": "remember all the steps that I've done the general idea that we have a bit here is that you don't want to have X tools",
    "start": "2549200",
    "end": "2555050"
  },
  {
    "text": "for X features that you want to have we want to kind of like bridge these little islands to one bigger map so that's kind",
    "start": "2555050",
    "end": "2561890"
  },
  {
    "text": "of like the appeal that we try to have with our stack here that you have one place where you can go and you can see",
    "start": "2561890",
    "end": "2567800"
  },
  {
    "text": "it's my service up or down what is in the logs how long are the traces is any if it user complains like what is in",
    "start": "2567800",
    "end": "2575089"
  },
  {
    "text": "their logs you can just filter down to the username they provide or you can filter down to just a slow request or",
    "start": "2575089",
    "end": "2580400"
  },
  {
    "start": "2580000",
    "end": "2641000"
  },
  {
    "text": "you could look at the metrics like do you have some resource duration like are you running out of memory or CPU or is",
    "start": "2580400",
    "end": "2586070"
  },
  {
    "text": "your my sequel slow or any of these pieces of information you can combine and then you see kind of more overall",
    "start": "2586070",
    "end": "2593119"
  },
  {
    "text": "rather than having one little thing here and one little thing there that you always need to manually combine and jump",
    "start": "2593119",
    "end": "2598190"
  },
  {
    "text": "around that's the overall idea basically if you want to try it out at home it's a",
    "start": "2598190",
    "end": "2603650"
  },
  {
    "text": "slightly different environment and is a bit lockdown but you can go to demo dot elastic Toshio this basically just locks",
    "start": "2603650",
    "end": "2609380"
  },
  {
    "text": "you into a cube on a dashboard and you can just play around there and see if that makes sense for you this is the",
    "start": "2609380",
    "end": "2615950"
  },
  {
    "text": "easiest way to get started with the entire stack here which will look something like this so you will have",
    "start": "2615950",
    "end": "2621170"
  },
  {
    "text": "lots of kubernetes pots and docker images to play around with so if that is your thing you can use all the metadata",
    "start": "2621170",
    "end": "2626720"
  },
  {
    "text": "and go wild with those now we have pretty much five minutes left for",
    "start": "2626720",
    "end": "2632089"
  },
  {
    "text": "questions do we have any questions you",
    "start": "2632089",
    "end": "2637120"
  }
]
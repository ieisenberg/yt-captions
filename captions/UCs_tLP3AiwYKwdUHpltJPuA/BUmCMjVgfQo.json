[
  {
    "start": "0",
    "end": "35000"
  },
  {
    "text": "[Music]",
    "start": "980",
    "end": "7849"
  },
  {
    "text": "so this is the outline what I will talking about so we have some points",
    "start": "11719",
    "end": "17160"
  },
  {
    "text": "like collecting data we need data to build the models and then I will talk briefly about building the model there",
    "start": "17160",
    "end": "23789"
  },
  {
    "text": "is a magic name H to order I I will touch it later and then of course we I",
    "start": "23789",
    "end": "30000"
  },
  {
    "text": "will talk about serving the model and then checking the candidate so",
    "start": "30000",
    "end": "35460"
  },
  {
    "start": "35000",
    "end": "827000"
  },
  {
    "text": "collecting data so first things first right before we do anything of course we",
    "start": "35460",
    "end": "41160"
  },
  {
    "text": "have to have data and data is somewhere in our system right we have to grab the",
    "start": "41160",
    "end": "47879"
  },
  {
    "text": "data and provide to to model as to to do",
    "start": "47879",
    "end": "53010"
  },
  {
    "text": "data scientist to create to teach the model right and this is this is extremely important which data you",
    "start": "53010",
    "end": "59010"
  },
  {
    "text": "provides or which data you grab from the from the system because how you teach the model this will be how it will work",
    "start": "59010",
    "end": "65970"
  },
  {
    "text": "how will have this whole prediction work right so first we have we have to create",
    "start": "65970",
    "end": "73170"
  },
  {
    "text": "some some events right and events are immutable facts in our system or",
    "start": "73170",
    "end": "78240"
  },
  {
    "text": "subsystems we if we have service architecture of course there is not one",
    "start": "78240",
    "end": "83610"
  },
  {
    "text": "service we have many services and then we produce a lot of lot of events right",
    "start": "83610",
    "end": "89250"
  },
  {
    "text": "and those events usually contains data and contains data about current state",
    "start": "89250",
    "end": "95759"
  },
  {
    "text": "and about some background sometimes right and to give you some some example",
    "start": "95759",
    "end": "101880"
  },
  {
    "text": "of event it could be as in our domain for example creating an ad or updating a",
    "start": "101880",
    "end": "107729"
  },
  {
    "text": "net right it's immutable fact it happens it happens many times so we register many such such events and yes and and",
    "start": "107729",
    "end": "116399"
  },
  {
    "text": "then of course we have to store those even somewhere and then process and",
    "start": "116399",
    "end": "122630"
  },
  {
    "text": "which possibilities do we have normally right so we have as of course we can",
    "start": "122630",
    "end": "129509"
  },
  {
    "text": "create something like like REST API so it's like a gateway for the event where when events are sand and we just",
    "start": "129509",
    "end": "137370"
  },
  {
    "text": "get get the requests and and then we post those even somewhere because what",
    "start": "137370",
    "end": "143970"
  },
  {
    "text": "was here really important we should not block right block is really bad so",
    "start": "143970",
    "end": "148980"
  },
  {
    "text": "because if you if you create an event in some system or subsystem then the last thing what the system expects from you",
    "start": "148980",
    "end": "155790"
  },
  {
    "text": "is when you send that event which is necessary for something else which is not connected with business logic is",
    "start": "155790",
    "end": "162210"
  },
  {
    "text": "simply to block right and then the second the second important part here is",
    "start": "162210",
    "end": "168960"
  },
  {
    "text": "you should process really fast right you you normally therefore we use for",
    "start": "168960",
    "end": "174510"
  },
  {
    "text": "example Kafka in in our case it works really fine because then if we get for example a new request then Kafka is",
    "start": "174510",
    "end": "181770"
  },
  {
    "text": "really really fast so you can really fast or the events and then we can we",
    "start": "181770",
    "end": "188400"
  },
  {
    "text": "can go further then you may ask a question for yourself why we should this",
    "start": "188400",
    "end": "194160"
  },
  {
    "text": "REST API there right we can write directly to Kafka right that's that's the that's the obvious one and it",
    "start": "194160",
    "end": "201420"
  },
  {
    "text": "depends right as usual everything it depends there are some advantages and",
    "start": "201420",
    "end": "207080"
  },
  {
    "text": "disadvantages of both approach right with REST API",
    "start": "207080",
    "end": "212430"
  },
  {
    "text": "the huge advantage is that every programming language can send HTTP",
    "start": "212430",
    "end": "218370"
  },
  {
    "text": "requests right it's it's easy you don't have to import any crazy stuff you just create and request and then BAM it",
    "start": "218370",
    "end": "225450"
  },
  {
    "text": "happens with Kafka it's not the case right you have to already import some",
    "start": "225450",
    "end": "230550"
  },
  {
    "text": "some Kafka specific stuff to create event and and this this is sometimes",
    "start": "230550",
    "end": "236130"
  },
  {
    "text": "problematic when it's a problematic normally if you if you think about the events and subsystems you have many many",
    "start": "236130",
    "end": "243120"
  },
  {
    "text": "services micro services you have plenty of them right so this is not one place",
    "start": "243120",
    "end": "248370"
  },
  {
    "text": "you have many places many services and those many services have dependency to",
    "start": "248370",
    "end": "255090"
  },
  {
    "text": "your Kafka library so then if you want to rise Kafka version it could be",
    "start": "255090",
    "end": "260790"
  },
  {
    "text": "problematic right because it's really too high it's really hard to say hey guys now we have upgrade 300 service",
    "start": "260790",
    "end": "267780"
  },
  {
    "text": "you have to rise the client and please do it on one as in specific time because we are we just update Kafka right so",
    "start": "267780",
    "end": "275270"
  },
  {
    "text": "that's that's that could be problematic but it's it's still an option and below",
    "start": "275270",
    "end": "280980"
  },
  {
    "text": "you see the the last not option I should say don't do that as I do not connect",
    "start": "280980",
    "end": "287490"
  },
  {
    "text": "please do not connect to the database directly it hurts right it has because when you correctly connected data",
    "start": "287490",
    "end": "293820"
  },
  {
    "text": "directly usually it works at the beginning then but then the team who is",
    "start": "293820",
    "end": "299130"
  },
  {
    "text": "responsible for that database for this specific domain simply updates the schema right and how you detect that of",
    "start": "299130",
    "end": "306840"
  },
  {
    "text": "course on production you will get some some events or or even not get any events and you will have some some",
    "start": "306840",
    "end": "314370"
  },
  {
    "text": "problems with query data and and yes actually this is this this is a huge problem right and then you have tight",
    "start": "314370",
    "end": "321030"
  },
  {
    "text": "coupling and you know if we talk now about distributed system so tight",
    "start": "321030",
    "end": "326160"
  },
  {
    "text": "coupling is actually the last what you want to have in your system and here is",
    "start": "326160",
    "end": "332310"
  },
  {
    "text": "an example what we have currently in our system so we have we have Gateway as a",
    "start": "332310",
    "end": "338970"
  },
  {
    "text": "it's it's REST API and then in this in this gateway we just check check the",
    "start": "338970",
    "end": "346050"
  },
  {
    "text": "events by the type and then branch the event to specific Kafka topics right",
    "start": "346050",
    "end": "352100"
  },
  {
    "text": "then you could put actually validator or",
    "start": "352100",
    "end": "357930"
  },
  {
    "text": "enricher afterwards and this afterwards is really important because as I said if",
    "start": "357930",
    "end": "363150"
  },
  {
    "text": "you put that one into even gateway it will take time right if you get an event",
    "start": "363150",
    "end": "369330"
  },
  {
    "text": "and then you have to validate this this even this will take time right normally",
    "start": "369330",
    "end": "375180"
  },
  {
    "text": "we send JSON so passing a JSON so first deserializing JSON and do anything with",
    "start": "375180",
    "end": "382320"
  },
  {
    "text": "that it takes time and of course if you if you think about an richer because",
    "start": "382320",
    "end": "387900"
  },
  {
    "text": "sometimes you have to enrich your events it could be even more expensive right so actually what what we do we put put",
    "start": "387900",
    "end": "396479"
  },
  {
    "text": "events into Kafka topic and then we have additional step which is validator and in richer",
    "start": "396479",
    "end": "401490"
  },
  {
    "text": "it was fully in a synchronous models and this validator or enricher or both",
    "start": "401490",
    "end": "408380"
  },
  {
    "text": "simply do the stuff and then create and next event to next Kafka topic and here",
    "start": "408380",
    "end": "415050"
  },
  {
    "text": "you may may notice that we have two types of Kafka topic is like a success",
    "start": "415050",
    "end": "420539"
  },
  {
    "text": "and failure one why because in in case of validator maybe you can detect that",
    "start": "420539",
    "end": "426300"
  },
  {
    "text": "some subsystems or services start to produce corrupted messages that's that's",
    "start": "426300",
    "end": "431970"
  },
  {
    "text": "possible right you may detect okay we updated something we have changed in the system we have",
    "start": "431970",
    "end": "438539"
  },
  {
    "text": "changed in the event and then at once those event are not valid anymore right",
    "start": "438539",
    "end": "443909"
  },
  {
    "text": "so this this is pretty pretty nice to have this feedback loop and and then have something like Fela topic right you",
    "start": "443909",
    "end": "450659"
  },
  {
    "text": "can consume it you can monitor it as there are plenty plenty strategies how you can deal with that with that kind of",
    "start": "450659",
    "end": "457020"
  },
  {
    "text": "problem when you have events right you",
    "start": "457020",
    "end": "465120"
  },
  {
    "text": "should as you should put some kind of context inside and what what the contact",
    "start": "465120",
    "end": "472409"
  },
  {
    "text": "is it could be for example user ID browser fingerprint or anything what",
    "start": "472409",
    "end": "479520"
  },
  {
    "text": "what can help you to group events right why it's possible why it's important",
    "start": "479520",
    "end": "485699"
  },
  {
    "text": "because you know if you if you will create any model afterwards sometimes you want to have intermediate step and",
    "start": "485699",
    "end": "492060"
  },
  {
    "text": "then connect some some parts on some kind of events to to create a bigger picture of this what happens in the",
    "start": "492060",
    "end": "498810"
  },
  {
    "text": "system right in the distributed system we have many steps you produce many",
    "start": "498810",
    "end": "504030"
  },
  {
    "text": "events and and sometimes you you don't want to deal with one particular kind of",
    "start": "504030",
    "end": "509159"
  },
  {
    "text": "event but you want to group them and then and then deal with with with those",
    "start": "509159",
    "end": "514320"
  },
  {
    "text": "right and here also a small hint if you create if you create context information",
    "start": "514320",
    "end": "521328"
  },
  {
    "text": "then then put it somewhere in a separate separate place right in separate file I",
    "start": "521329",
    "end": "528360"
  },
  {
    "text": "will show you example of JSON schema later on and important is that you share",
    "start": "528360",
    "end": "534000"
  },
  {
    "text": "this information between evens because if you start to to to put that information directly in in",
    "start": "534000",
    "end": "543170"
  },
  {
    "text": "the schema of of you even then of course someone can create another one and then",
    "start": "543170",
    "end": "548780"
  },
  {
    "text": "you have some kind of discrepancy and this is this is really hard to find okay so we have contacts we have event",
    "start": "548780",
    "end": "556340"
  },
  {
    "text": "then ba-bam we have schema right and similar situation like we have with the",
    "start": "556340",
    "end": "563660"
  },
  {
    "text": "databases like no sequel databases everybody says yeah this is something what does not have schema nice I mean",
    "start": "563660",
    "end": "571460"
  },
  {
    "text": "but in real world we need schema schema is like a guard right it's protecting",
    "start": "571460",
    "end": "577010"
  },
  {
    "text": "you from many many problems which will occur when you will not have the schema",
    "start": "577010",
    "end": "582620"
  },
  {
    "text": "right and and and that's normally a good example here is data format right I",
    "start": "582620",
    "end": "588320"
  },
  {
    "text": "don't know how many formats of data exists worldwide and I suppose when you",
    "start": "588320",
    "end": "593480"
  },
  {
    "text": "have teams then they will really go white and choose data data formats as",
    "start": "593480",
    "end": "599030"
  },
  {
    "text": "date formats which which is really exotic yes what's more important is also",
    "start": "599030",
    "end": "604750"
  },
  {
    "text": "even if they use some kind of date format it could be that you you produce",
    "start": "604750",
    "end": "610730"
  },
  {
    "text": "even in different time zones right and then when start processing then you can face really interesting logical problems",
    "start": "610730",
    "end": "618200"
  },
  {
    "text": "because you know this is some events which happens in the system yesterday",
    "start": "618200",
    "end": "623660"
  },
  {
    "text": "will will process as events from today and and this this is not what what you",
    "start": "623660",
    "end": "629540"
  },
  {
    "text": "want to have right and also in the schema as usual we can we can divide",
    "start": "629540",
    "end": "634630"
  },
  {
    "text": "divide properties on mandatory and optional and and this this is what what",
    "start": "634630",
    "end": "640820"
  },
  {
    "text": "gives you a confidence e about quality of of the event right if you say",
    "start": "640820",
    "end": "646700"
  },
  {
    "text": "something is mandatory and then you have validation logic of course you can be sure I have all data which is necessary",
    "start": "646700",
    "end": "653780"
  },
  {
    "text": "for me right in other case this is really hard you have to check somehow if the event is valid and then you have",
    "start": "653780",
    "end": "660140"
  },
  {
    "text": "distributed logic along all of services or some some other places and yes",
    "start": "660140",
    "end": "666980"
  },
  {
    "text": "actually this this is not what what we want to have and here you can see example of of the schema with some",
    "start": "666980",
    "end": "675440"
  },
  {
    "text": "context so we have two types of contexts one is something like yes the general",
    "start": "675440",
    "end": "681680"
  },
  {
    "text": "info so this is like metadata for the event and then we have more more context",
    "start": "681680",
    "end": "689540"
  },
  {
    "text": "dependent even information about head so you can put anything there right this",
    "start": "689540",
    "end": "694670"
  },
  {
    "text": "this this is not limited to one something it's you can put as many",
    "start": "694670",
    "end": "700220"
  },
  {
    "text": "contexts as you need and and that'sthat's open stuff and here as I say this is a JSON schema example",
    "start": "700220",
    "end": "707500"
  },
  {
    "text": "important point to notice I don't know where's the pointer the when you look",
    "start": "707500",
    "end": "715550"
  },
  {
    "text": "for example the properties you have something like a ref and it's it's for",
    "start": "715550",
    "end": "720860"
  },
  {
    "text": "example as in this example hat is not in the file itself it's externalized and then we shared",
    "start": "720860",
    "end": "727280"
  },
  {
    "text": "that information with many others events right ok and last step of course",
    "start": "727280",
    "end": "735650"
  },
  {
    "text": "external data providers what we found especially by building prediction",
    "start": "735650",
    "end": "741080"
  },
  {
    "text": "pipelines it's nice what you have in your system right but it's also nice",
    "start": "741080",
    "end": "746960"
  },
  {
    "text": "sometimes to enrich your event for external data so for something what you",
    "start": "746960",
    "end": "752480"
  },
  {
    "text": "actually do not have but will be nice for the model to to to to be there to to",
    "start": "752480",
    "end": "759740"
  },
  {
    "text": "have right and in our case in in vehicle domain we have something like VIN number",
    "start": "759740",
    "end": "766130"
  },
  {
    "text": "for example this is vehicle identification identified intensification number and with this",
    "start": "766130",
    "end": "773180"
  },
  {
    "text": "number we can go to external third-party provider and then fetch a lot of information which we actually probably",
    "start": "773180",
    "end": "779990"
  },
  {
    "text": "do not have in the system what's more our clients not all of them are",
    "start": "779990",
    "end": "785350"
  },
  {
    "text": "proficient with with you know with vehicle domain right they sometimes they have cars with equipment they do not",
    "start": "785350",
    "end": "792770"
  },
  {
    "text": "know but this equipment has huge influence on the price of the car right so with for example with this kind of",
    "start": "792770",
    "end": "799820"
  },
  {
    "text": "step we can enrich model and then we can a user - to get a better price for the",
    "start": "799820",
    "end": "806570"
  },
  {
    "text": "car because we can say okay user do not know but you know if you have as a sunroof is maybe better example it's",
    "start": "806570",
    "end": "812840"
  },
  {
    "text": "easy to see but if you have some kind of special navigation system and and stuff",
    "start": "812840",
    "end": "818030"
  },
  {
    "text": "like that yes we can we can help the user and then provide some kind of data all right so let's say we have data",
    "start": "818030",
    "end": "825890"
  },
  {
    "text": "right next step building the model and it's pretty interesting yesterday on",
    "start": "825890",
    "end": "832130"
  },
  {
    "start": "827000",
    "end": "1672000"
  },
  {
    "text": "closing keynote Rebecca Parsons a persons on heard talk about where the",
    "start": "832130",
    "end": "839390"
  },
  {
    "text": "world ends gave an example from us when",
    "start": "839390",
    "end": "845560"
  },
  {
    "text": "prediction model judge prisoners and she said that some kind of random right what",
    "start": "845560",
    "end": "853670"
  },
  {
    "text": "I want to say here it's a huge responsibility to build a model yes you",
    "start": "853670",
    "end": "859220"
  },
  {
    "text": "can you can help your business with prediction model but you can also have the business with prediction model if",
    "start": "859220",
    "end": "865160"
  },
  {
    "text": "you really do something bad and from our experience it's something like it's not",
    "start": "865160",
    "end": "872120"
  },
  {
    "text": "for software developers right as if you want to deal with that just higher so",
    "start": "872120",
    "end": "878620"
  },
  {
    "text": "data scientist and they really really know what what they do it's it's like I",
    "start": "878620",
    "end": "884540"
  },
  {
    "text": "you know software engineers deal with the systems and we know how to scale we know how to build services we know which",
    "start": "884540",
    "end": "890990"
  },
  {
    "text": "frameworks are good how to monitor and so on and so on and data scientists are really proficient in predict as in",
    "start": "890990",
    "end": "898580"
  },
  {
    "text": "building and training prediction models they have experience they they you know",
    "start": "898580",
    "end": "903610"
  },
  {
    "text": "deep tech the knowledge and then they really know what they do but nevertheless I will I will show you the",
    "start": "903610",
    "end": "911290"
  },
  {
    "text": "some steps they they follow just do to know what they would they actually do so",
    "start": "911290",
    "end": "918410"
  },
  {
    "text": "first first thing is surprise surprise they have to filter data right we",
    "start": "918410",
    "end": "924110"
  },
  {
    "text": "produce a lot of events and with lot of data and they they have a lot of noise",
    "start": "924110",
    "end": "929510"
  },
  {
    "text": "right so that's that's the opposite and what they do they they see we really fast tried to find which data",
    "start": "929510",
    "end": "939510"
  },
  {
    "text": "is significant right if you have 150 properties of the car or 250 even in our",
    "start": "939510",
    "end": "945360"
  },
  {
    "text": "case 20 is really important right but",
    "start": "945360",
    "end": "950460"
  },
  {
    "text": "the rest is just you know have no influence no huge influence on the price it also vary from from the make and",
    "start": "950460",
    "end": "957570"
  },
  {
    "text": "model and generation and stuff like that but but nevertheless they did they try",
    "start": "957570",
    "end": "963360"
  },
  {
    "text": "to find out what is important what is less important right and then they do some kind of pre-processing yesterday",
    "start": "963360",
    "end": "970050"
  },
  {
    "text": "they they take the data they transform sometimes like for for example mileage",
    "start": "970050",
    "end": "979100"
  },
  {
    "text": "when you when you look at mileage it has a huge influence when when it's small right",
    "start": "979100",
    "end": "984390"
  },
  {
    "text": "but above 200 thousand kilometres doesn't count anymore right you you",
    "start": "984390",
    "end": "989910"
  },
  {
    "text": "reach your plateau and then it has just small influence on the price so with pre-processing they apply some",
    "start": "989910",
    "end": "996600"
  },
  {
    "text": "kind of functions just just due to process such kind of data in in a way",
    "start": "996600",
    "end": "1001760"
  },
  {
    "text": "they want to write the next step is feature engineering sometimes when when",
    "start": "1001760",
    "end": "1009830"
  },
  {
    "text": "you look at the data you may find some connections right and the connections are extremely valuable I mean I mean for",
    "start": "1009830",
    "end": "1019070"
  },
  {
    "text": "example that if you buy a car and then you buy some kind of package then you will get sunroof like LED lamps and",
    "start": "1019070",
    "end": "1027199"
  },
  {
    "text": "stuff like that right so in theory what is possible you can just say hey if you",
    "start": "1027199",
    "end": "1032569"
  },
  {
    "text": "have this three features right then we can reduce those three features to one",
    "start": "1032569",
    "end": "1038839"
  },
  {
    "text": "which is yes or no right and then your whole model which be much much easier",
    "start": "1038839",
    "end": "1044510"
  },
  {
    "text": "because you have to deal with boolean information not with you know some kind",
    "start": "1044510",
    "end": "1050630"
  },
  {
    "text": "of list and check and in connection to this and that so so that's that simplifies a lot of lot of things right",
    "start": "1050630",
    "end": "1056720"
  },
  {
    "text": "and then yeah well no problem I think I talked to that our data saying",
    "start": "1056720",
    "end": "1062840"
  },
  {
    "text": "scientists and they say ok you can write a book about this subject how to sample the data and of course",
    "start": "1062840",
    "end": "1068210"
  },
  {
    "text": "when you go to internet Google says you 80/20 70/30 yes it's I think it's a good point to",
    "start": "1068210",
    "end": "1074240"
  },
  {
    "text": "start but they fight with that really so it's it's really depending what you do",
    "start": "1074240",
    "end": "1079850"
  },
  {
    "text": "which domain do you have how many data do you have and what we want to achieve right because here it's it's just a one",
    "start": "1079850",
    "end": "1087590"
  },
  {
    "text": "word but at the end it's about overall or overfitting or underfitting",
    "start": "1087590",
    "end": "1093049"
  },
  {
    "text": "and both are not not really what you want to have right so yeah that's that's",
    "start": "1093049",
    "end": "1098510"
  },
  {
    "text": "very very important part of this this pipeline and then experiment with",
    "start": "1098510",
    "end": "1105169"
  },
  {
    "text": "algorithm and yes when you look on the",
    "start": "1105169",
    "end": "1110380"
  },
  {
    "text": "algorithm used for prediction models they are plenty right we have random for us we have thousands of other",
    "start": "1110380",
    "end": "1117200"
  },
  {
    "text": "algorithm-- there is nothing what fit everything right which which is like",
    "start": "1117200",
    "end": "1123710"
  },
  {
    "text": "a silver bullet we can say yes okay we take one and it will work for us right",
    "start": "1123710",
    "end": "1129159"
  },
  {
    "text": "unfortunately not so we have many are buried and those many algorithm-- any",
    "start": "1129159",
    "end": "1135080"
  },
  {
    "text": "different requirements right and even data scientists do not take one",
    "start": "1135080",
    "end": "1140779"
  },
  {
    "text": "algorithm and they know already they look on the data say yeah that that's working fantastic and I will take that",
    "start": "1140779",
    "end": "1146210"
  },
  {
    "text": "one what they do they sometimes try two or three which they believe can work and",
    "start": "1146210",
    "end": "1151909"
  },
  {
    "text": "then do some experiments and doing some experiments it's like a mantra check",
    "start": "1151909",
    "end": "1158840"
  },
  {
    "text": "tune and repeat check tune and repeat right and from this point we can jump directly to the to the collecting data",
    "start": "1158840",
    "end": "1166059"
  },
  {
    "text": "because very often they come back to you and say hey you know we train our model",
    "start": "1166059",
    "end": "1172850"
  },
  {
    "text": "and we find some kind of interesting points about that and you know we need different events right and we need",
    "start": "1172850",
    "end": "1180020"
  },
  {
    "text": "events with more in data on this particular subject right and yeah so I",
    "start": "1180020",
    "end": "1188360"
  },
  {
    "text": "mean here you have to be also prepared as a software engineer data engineer",
    "start": "1188360",
    "end": "1193630"
  },
  {
    "text": "that you have to provide that data that's really important and this really this will be changed as we we notice",
    "start": "1193630",
    "end": "1200120"
  },
  {
    "text": "that in during during duration they jump sometimes from one",
    "start": "1200120",
    "end": "1206059"
  },
  {
    "text": "side to another and then they in time they found okay this this branch could",
    "start": "1206059",
    "end": "1211429"
  },
  {
    "text": "be really interesting so so we have to provide them data which are specific for",
    "start": "1211429",
    "end": "1216500"
  },
  {
    "text": "something and then after some time they found okay no this this was like not the best solution then we will we need",
    "start": "1216500",
    "end": "1223309"
  },
  {
    "text": "something else right so so this is this is like a continuous continuous play okay and so by the way I will post the",
    "start": "1223309",
    "end": "1230149"
  },
  {
    "text": "slides afterwards so you don't have to make photos if you want you're welcome but I will post the slides okay and now",
    "start": "1230149",
    "end": "1239480"
  },
  {
    "text": "the magic h2o yes and I don't know if you have familiar of the meters power of bubble",
    "start": "1239480",
    "end": "1247100"
  },
  {
    "text": "like the people spoke one language and",
    "start": "1247100",
    "end": "1252139"
  },
  {
    "text": "they want to build a tower which hits the heaven and the gods and sends them",
    "start": "1252139",
    "end": "1257149"
  },
  {
    "text": "different languages and the project collapsed right and yes that's our world",
    "start": "1257149",
    "end": "1264379"
  },
  {
    "text": "right normally at mobile a we we are heavily using jvm languages like Java Scala",
    "start": "1264379",
    "end": "1271580"
  },
  {
    "text": "Clojure something like that and data scientists I don't know why they start",
    "start": "1271580",
    "end": "1276799"
  },
  {
    "text": "using Python and are right and and yes they did they like them yes and of",
    "start": "1276799",
    "end": "1282230"
  },
  {
    "text": "course the languages as a Python and are are really supportive for data scientists you can program and train the",
    "start": "1282230",
    "end": "1288740"
  },
  {
    "text": "model really fast so they can eat they iterate extremely fast right in Java you",
    "start": "1288740",
    "end": "1294649"
  },
  {
    "text": "have a lot of boilerplate code and and this is not actually what they want to do they want they want really fast do",
    "start": "1294649",
    "end": "1301610"
  },
  {
    "text": "something and Python and are a really good languages for that yes but then when the model is created",
    "start": "1301610",
    "end": "1309080"
  },
  {
    "text": "and then you know everybody's happy which possibilities do we have right and",
    "start": "1309080",
    "end": "1314360"
  },
  {
    "text": "of course one possibility is just take the Python and translate it to Java by",
    "start": "1314360",
    "end": "1320450"
  },
  {
    "text": "the way who has experience with stuff like that ok do you want to repeat yes",
    "start": "1320450",
    "end": "1329559"
  },
  {
    "text": "it's really painful right it's it's it's extremely painful",
    "start": "1329559",
    "end": "1335570"
  },
  {
    "text": "and normally except that it's painful is also error-prone right if you translate",
    "start": "1335570",
    "end": "1341960"
  },
  {
    "text": "one language to another it's not that that you know you will do always perfect",
    "start": "1341960",
    "end": "1347120"
  },
  {
    "text": "matching right you can make mistakes and mistakes are simply there and it's also",
    "start": "1347120",
    "end": "1353510"
  },
  {
    "text": "hard to have to have to check because if even if you want to say okay I will write a unit test for that that's easy",
    "start": "1353510",
    "end": "1359810"
  },
  {
    "text": "right so then you you really slow your process right because you have to ask",
    "start": "1359810",
    "end": "1365750"
  },
  {
    "text": "the guys and say eh in this particular part of the Python code please provide",
    "start": "1365750",
    "end": "1371240"
  },
  {
    "text": "me input and output so I can check my Java code right and then of course when",
    "start": "1371240",
    "end": "1377810"
  },
  {
    "text": "you think about it eration two weeks later they come to you and say you know we change it a little bit right and then",
    "start": "1377810",
    "end": "1384890"
  },
  {
    "text": "I don't know you look a little bit strange and then and after three third",
    "start": "1384890",
    "end": "1390110"
  },
  {
    "text": "time I suppose you're you are not friends anymore right because she because it's simply painful process",
    "start": "1390110",
    "end": "1395930"
  },
  {
    "text": "right so and here here is where the h2o comes to play it's a framework we use",
    "start": "1395930",
    "end": "1403490"
  },
  {
    "text": "and it connects actually both words data",
    "start": "1403490",
    "end": "1408860"
  },
  {
    "text": "scientists can use Python and r2 to train the model and can do all crazy",
    "start": "1408860",
    "end": "1415580"
  },
  {
    "text": "stuff they like to do but at the end they can export everything to Java which",
    "start": "1415580",
    "end": "1421550"
  },
  {
    "text": "is extremely nice for us right we get just a package and that's all right it's",
    "start": "1421550",
    "end": "1427010"
  },
  {
    "text": "it's very comfortable but there is also some kind of trade-offs and some kind of",
    "start": "1427010",
    "end": "1435170"
  },
  {
    "text": "pitfalls right so the one is you know if if you start to train a model it depends",
    "start": "1435170",
    "end": "1441740"
  },
  {
    "text": "of course from the domain in which you are but sometimes the models can be really huge right it's not that you will",
    "start": "1441740",
    "end": "1448550"
  },
  {
    "text": "end up with something like two or five megabytes in our case it was like I think one and half gigabyte of model and",
    "start": "1448550",
    "end": "1455660"
  },
  {
    "text": "I will come back on that later that's that's the optimized version right it's just talking next slides about that and",
    "start": "1455660",
    "end": "1464800"
  },
  {
    "text": "what you can do in this case is simply you can you can you can create as a think about heart",
    "start": "1464800",
    "end": "1470990"
  },
  {
    "text": "branches you have in your domain and then split the model yes example from our from our domain is we",
    "start": "1470990",
    "end": "1478670"
  },
  {
    "text": "can take for example we can take a make and then say okay make like BMW or",
    "start": "1478670",
    "end": "1484810"
  },
  {
    "text": "Renault or anything else it's hard branch and we create a model which which",
    "start": "1484810",
    "end": "1490520"
  },
  {
    "text": "is special for that one and it makes really a lot of sense because it's also",
    "start": "1490520",
    "end": "1496220"
  },
  {
    "text": "depending from your location right as a example of that is in Germany when you",
    "start": "1496220",
    "end": "1502460"
  },
  {
    "text": "think about German manufacturers as a then of course in Germany cars like BMW",
    "start": "1502460",
    "end": "1509300"
  },
  {
    "text": "for swaggins I really really have the really good value even in time right so",
    "start": "1509300",
    "end": "1515120"
  },
  {
    "text": "if you predict a value of the car of course this this this has totally",
    "start": "1515120",
    "end": "1521000"
  },
  {
    "text": "different model than providing a value for something exotic right because the",
    "start": "1521000",
    "end": "1526670"
  },
  {
    "text": "value of exotic cars drops down really fast so that you have really two different differently situation but in",
    "start": "1526670",
    "end": "1533900"
  },
  {
    "text": "the country where the exotic car is produced maybe it's total opposite situation right as in US BMW is not such fancy car",
    "start": "1533900",
    "end": "1542000"
  },
  {
    "text": "it's just a car right they favor I don't know Ford Mustang probably which",
    "start": "1542000",
    "end": "1547100"
  },
  {
    "text": "is not the case in Germany right so then you should provide different models for",
    "start": "1547100",
    "end": "1552290"
  },
  {
    "text": "for different parts of your system then",
    "start": "1552290",
    "end": "1557950"
  },
  {
    "text": "exporting exporting a module the export in the model export this model as some",
    "start": "1557950",
    "end": "1563270"
  },
  {
    "text": "module in h2o you have actually adding three possibilities to export a model and the one is for just a plain old Java",
    "start": "1563270",
    "end": "1570650"
  },
  {
    "text": "object you don't want to do that and why simply because it's huge right if you",
    "start": "1570650",
    "end": "1579650"
  },
  {
    "text": "export POJO the model is 20 to 25 times",
    "start": "1579650",
    "end": "1584930"
  },
  {
    "text": "bigger than the module 1 when we talk about one and half gigabyte you can imagine how big the model is right I",
    "start": "1584930",
    "end": "1592010"
  },
  {
    "text": "don't know if you can load this in memory that's probably yes but you you will need a really huge huge computer",
    "start": "1592010",
    "end": "1598910"
  },
  {
    "text": "behind right huge and then additionally the the models as",
    "start": "1598910",
    "end": "1604950"
  },
  {
    "text": "the de modules are 2 to 3 times faster in the hot phase what I mean hot phase",
    "start": "1604950",
    "end": "1610560"
  },
  {
    "text": "when the model already worse and a bit yes because it's it strains themself and then then then there is a difference for",
    "start": "1610560",
    "end": "1618680"
  },
  {
    "text": "for hot and cold and two to three times makes difference right it's not a small",
    "start": "1618680",
    "end": "1624330"
  },
  {
    "text": "number but what was this even more important in a in a cold face it's 10 to",
    "start": "1624330",
    "end": "1629430"
  },
  {
    "text": "40 times difference right so if you start just you know you new created",
    "start": "1629430",
    "end": "1635760"
  },
  {
    "text": "prediction service and then the speed is 40 times slower I think it's not what do",
    "start": "1635760",
    "end": "1642660"
  },
  {
    "text": "you expect actually and and I wasn't already on a talk when guys from another company says they they create something",
    "start": "1642660",
    "end": "1649380"
  },
  {
    "text": "like like a warm-up phase right but warm-up face first is complicated and",
    "start": "1649380",
    "end": "1655170"
  },
  {
    "text": "second it takes time right you cannot you just deployed the service you have to create some extra steps just say a",
    "start": "1655170",
    "end": "1663440"
  },
  {
    "text": "the service which is still in the warm-up phase is not served to the public it's it's bad but bad thing so go",
    "start": "1663440",
    "end": "1674160"
  },
  {
    "start": "1672000",
    "end": "1987000"
  },
  {
    "text": "to the serving model we have our model we can go and yes we have events we",
    "start": "1674160",
    "end": "1681030"
  },
  {
    "text": "train them we did this long trip and now we are happy to serve right so the first",
    "start": "1681030",
    "end": "1687300"
  },
  {
    "text": "hint here is simply load models and start right when we export the model we can we can export this as a third-party",
    "start": "1687300",
    "end": "1693990"
  },
  {
    "text": "library and include it for example in our in our artifact but having this like",
    "start": "1693990",
    "end": "1700710"
  },
  {
    "text": "one and half gigabyte big right and including this every time when you create a docker I think this this is not",
    "start": "1700710",
    "end": "1707700"
  },
  {
    "text": "what makes you operations have you right at some point they will come say a you consume all our space right and",
    "start": "1707700",
    "end": "1714740"
  },
  {
    "text": "additionally this this is like you know like putting something which which which",
    "start": "1714740",
    "end": "1721050"
  },
  {
    "text": "not belongs to the service per se inside of the service right if we have services",
    "start": "1721050",
    "end": "1726690"
  },
  {
    "text": "like like something which which makes everything possible so you don't actually need that that model inside and",
    "start": "1726690",
    "end": "1732900"
  },
  {
    "text": "and additionally if you to deploy as a modify the service every time we produce that artifact which is",
    "start": "1732900",
    "end": "1739650"
  },
  {
    "text": "huge every time when data scientists change something we will produce artifact with this feels right it's not the way we you",
    "start": "1739650",
    "end": "1746040"
  },
  {
    "text": "want to do the other option with pods oh we excluded that but but anyway you can",
    "start": "1746040",
    "end": "1752190"
  },
  {
    "text": "include the sources I don't know what for it's generated code if if there's",
    "start": "1752190",
    "end": "1758040"
  },
  {
    "text": "some crazy people like to change generated code have a fun normally you",
    "start": "1758040",
    "end": "1763050"
  },
  {
    "text": "should you shouldn't touch it right yeah the probably will do something wrong so with mojo with mod with modules we we",
    "start": "1763050",
    "end": "1770790"
  },
  {
    "text": "simply create our models and then put it in some kind of storage normally cloud storage and and then when the service",
    "start": "1770790",
    "end": "1777780"
  },
  {
    "text": "starts we load the model and then when we then then we proceed another part is",
    "start": "1777780",
    "end": "1784530"
  },
  {
    "text": "anti-corruption layer and yesterday some guys the corruption sounds bad right I",
    "start": "1784530",
    "end": "1790130"
  },
  {
    "text": "like it very much it protects you from many many problems",
    "start": "1790130",
    "end": "1796050"
  },
  {
    "text": "because for example when you train a model and then from any reason the input",
    "start": "1796050",
    "end": "1802020"
  },
  {
    "text": "change you can still provide anti-corruption layer so you can transform the input as a new input to",
    "start": "1802020",
    "end": "1809250"
  },
  {
    "text": "the input which model expects and this will still work in other case in in the worst case you will create something the",
    "start": "1809250",
    "end": "1816480"
  },
  {
    "text": "model say hey I have prediction like this for you and this prediction is not actually the good one because it keeps",
    "start": "1816480",
    "end": "1823530"
  },
  {
    "text": "half of the properties right so with anti-corruption layer what we did is",
    "start": "1823530",
    "end": "1830330"
  },
  {
    "text": "that this part is not also placed in our service but we develop some kind of dsl",
    "start": "1830330",
    "end": "1836970"
  },
  {
    "text": "and data scientists create some kind like a description how they want to",
    "start": "1836970",
    "end": "1842040"
  },
  {
    "text": "transform the data and then in our anti-corruption layer we reread that",
    "start": "1842040",
    "end": "1847140"
  },
  {
    "text": "that part on information that kind of information and then we prepare transformers on fly for them right so in",
    "start": "1847140",
    "end": "1855450"
  },
  {
    "text": "this case we also protect ourselves from situation that they can say you know for",
    "start": "1855450",
    "end": "1860460"
  },
  {
    "text": "this model you have to transform field x and e grow to something like that right they do this description somewhere in",
    "start": "1860460",
    "end": "1867240"
  },
  {
    "text": "DSL and and we know how to transform it right so that's that's that's what we learned we started simple like with",
    "start": "1867240",
    "end": "1874560"
  },
  {
    "text": "direct direct transformation but end up with this kind of abstraction layer",
    "start": "1874560",
    "end": "1879660"
  },
  {
    "text": "because it helps us a lot if you have a model model contains also information how to transform the data it's a part of",
    "start": "1879660",
    "end": "1887040"
  },
  {
    "text": "the model and then you just take it and do it additionally if you have different",
    "start": "1887040",
    "end": "1892500"
  },
  {
    "text": "versions and then you know the service transformation as a Anti Corruption layer is in different version as the",
    "start": "1892500",
    "end": "1897840"
  },
  {
    "text": "model it can also lead to some kind of problems if you had at one place of course it's it's not not that big",
    "start": "1897840",
    "end": "1903660"
  },
  {
    "text": "deal and what we use currently for our services we use scala akka streams and",
    "start": "1903660",
    "end": "1910230"
  },
  {
    "text": "akash DDP but to be honest it makes no difference if you use plain Java right",
    "start": "1910230",
    "end": "1916800"
  },
  {
    "text": "it just are just a tool and why we like it actually the Transformers you can you",
    "start": "1916800",
    "end": "1923370"
  },
  {
    "text": "can write in Scala as you have really really nice support to to write transformers and then with akka iddp you",
    "start": "1923370",
    "end": "1931320"
  },
  {
    "text": "have really thin layer which sells that stuff and everything is a synchronous so we like it but as I said this is",
    "start": "1931320",
    "end": "1938250"
  },
  {
    "text": "actually not not not important to be honest right and here is a picture how",
    "start": "1938250",
    "end": "1945120"
  },
  {
    "text": "it looks like as a from the text to the picture more than thousand words of course so we have h2o we have models and",
    "start": "1945120",
    "end": "1954150"
  },
  {
    "text": "our try for DSL somewhere in the cloud and unload we just fetch that information to our service we prepare",
    "start": "1954150",
    "end": "1961350"
  },
  {
    "text": "transformation we prepared predictor and we are ready to go and then when the when the client calls our service",
    "start": "1961350",
    "end": "1968820"
  },
  {
    "text": "predictor service then first we transform input as a row input to input",
    "start": "1968820",
    "end": "1975330"
  },
  {
    "text": "which our model expects do the prediction and then give response back right that's easy",
    "start": "1975330",
    "end": "1981680"
  },
  {
    "text": "all right so next step yeah change is",
    "start": "1981680",
    "end": "1987690"
  },
  {
    "start": "1987000",
    "end": "2460000"
  },
  {
    "text": "only constant I think everybody knows that so in time after after you create",
    "start": "1987690",
    "end": "1995190"
  },
  {
    "text": "your first prediction model business comes to say a you know we",
    "start": "1995190",
    "end": "2001730"
  },
  {
    "text": "have to adjust this and that right we want to do something else slightly as and of course you then have",
    "start": "2001730",
    "end": "2009260"
  },
  {
    "text": "to create a new model right so you have repeat all that steps and after you repeat it you have to check somehow if",
    "start": "2009260",
    "end": "2017960"
  },
  {
    "text": "the candidate is really working for you right very important step you don't want to just say a we replace the model and",
    "start": "2017960",
    "end": "2025420"
  },
  {
    "text": "yes let's see how it works on production right it's it's maybe not the best idea",
    "start": "2025420",
    "end": "2030910"
  },
  {
    "text": "especially when the user tends to get already some kind of prediction and they",
    "start": "2030910",
    "end": "2036710"
  },
  {
    "text": "didn't know how it works and that once you come with really I would say buggy predictor then it's really bad",
    "start": "2036710",
    "end": "2043670"
  },
  {
    "text": "experience you want you want to protect yourself from from that that's that and what you can do is this is the first one",
    "start": "2043670",
    "end": "2051139"
  },
  {
    "text": "it's dry run so we create that kind of job it's a job on purpose it's it's very",
    "start": "2051140",
    "end": "2058190"
  },
  {
    "text": "similar to service by the way that we we also fetch fetch the model from from the cloud and and then start the prediction",
    "start": "2058190",
    "end": "2066050"
  },
  {
    "text": "and in dry run we just want to check if generally the model works I mean",
    "start": "2066050",
    "end": "2072050"
  },
  {
    "text": "generally it's like you know if it's not explode because if it's plot you can",
    "start": "2072050",
    "end": "2077360"
  },
  {
    "text": "just keep call next steps it's it's buggy right so dry run we limit we have",
    "start": "2077360",
    "end": "2084290"
  },
  {
    "text": "some some kind of parameter so you can say a consume like thousand events or something like that or work for five",
    "start": "2084290",
    "end": "2090139"
  },
  {
    "text": "minutes and then we can check a it should as it makes sense to do next",
    "start": "2090140",
    "end": "2095840"
  },
  {
    "text": "steps or not right then very important part is test with live data why it's",
    "start": "2095840",
    "end": "2103640"
  },
  {
    "text": "important because life data is different to the data you have on test system what",
    "start": "2103640",
    "end": "2109430"
  },
  {
    "text": "we tend to do we tend to copy the data we like to test system and then go to",
    "start": "2109430",
    "end": "2114560"
  },
  {
    "text": "happy path right and actually it it",
    "start": "2114560",
    "end": "2119810"
  },
  {
    "text": "works for the test for unit test but if you want to check your model its it says",
    "start": "2119810",
    "end": "2126110"
  },
  {
    "text": "nothing I mean if you just you know use same same small set of data all the time",
    "start": "2126110",
    "end": "2132620"
  },
  {
    "text": "so you are really really the locked I mean those kinds of data",
    "start": "2132620",
    "end": "2138310"
  },
  {
    "text": "are limited right and what we do is we",
    "start": "2138310",
    "end": "2143320"
  },
  {
    "text": "we produce our events as you may remember to the as we publish to deck to",
    "start": "2143320",
    "end": "2148990"
  },
  {
    "text": "the Kafka topic and then we can easily consume Kafka topic is really in",
    "start": "2148990",
    "end": "2154150"
  },
  {
    "text": "invasive right and if you a little bit familiar with Kafka it's easy to say",
    "start": "2154150",
    "end": "2159940"
  },
  {
    "text": "okay when the when this checker is is finished right it's ready we do not have",
    "start": "2159940",
    "end": "2166859"
  },
  {
    "text": "we do not have commit offset right so next time when the job starts starts from the beginning right really really",
    "start": "2166859",
    "end": "2174099"
  },
  {
    "text": "easy and really powerful what you what",
    "start": "2174099",
    "end": "2179170"
  },
  {
    "text": "you should do is you should at the end of the checker story somewhere right",
    "start": "2179170",
    "end": "2184540"
  },
  {
    "text": "you check the data you make like a prediction you want to store the data because you want to do consistency check",
    "start": "2184540",
    "end": "2191500"
  },
  {
    "text": "yes and consistently consistency track in our case is is something like we go",
    "start": "2191500",
    "end": "2200230"
  },
  {
    "text": "through live stream of ads and then we know what what was predicted before and",
    "start": "2200230",
    "end": "2206550"
  },
  {
    "text": "then we start new predictor and then we store let's say production state and",
    "start": "2206550",
    "end": "2213280"
  },
  {
    "text": "then candidate state right and then we can create some kind of dashboard and",
    "start": "2213280",
    "end": "2218530"
  },
  {
    "text": "check if if everything is fine right of course in prediction when you check",
    "start": "2218530",
    "end": "2223960"
  },
  {
    "text": "prediction model you will have different results but what is important that that you for example that the distribution of",
    "start": "2223960",
    "end": "2230740"
  },
  {
    "text": "the data remains right if you if you make some some kind of mistake you can",
    "start": "2230740",
    "end": "2235780"
  },
  {
    "text": "end up for example with not processing some kind of data right like you do not processing make like golf or something",
    "start": "2235780",
    "end": "2244030"
  },
  {
    "text": "because I don't know mistake and then in the distribution you will see that you",
    "start": "2244030",
    "end": "2249339"
  },
  {
    "text": "know this this kind of this kind of input is not processed also you you may",
    "start": "2249339",
    "end": "2255670"
  },
  {
    "text": "check what is the distribution of your of your prediction right you can create heat maps and then you can see easily",
    "start": "2255670",
    "end": "2261160"
  },
  {
    "text": "where the data is placed right so very very helpful tool for for data",
    "start": "2261160",
    "end": "2267220"
  },
  {
    "text": "scientists and this step is manual yes we thought about optimization but it makes no sense for",
    "start": "2267220",
    "end": "2273570"
  },
  {
    "text": "us because you know you have to be extremely extremely smart to see if the",
    "start": "2273570",
    "end": "2278970"
  },
  {
    "text": "data you you you as if the model you create now is performing better this is what human as a data scientist can can",
    "start": "2278970",
    "end": "2285630"
  },
  {
    "text": "check easily creating nice dashboards and then then see some some kind of connection but for for machine",
    "start": "2285630",
    "end": "2291960"
  },
  {
    "text": "processing it's really hard so for us it made me it made no sense currently so",
    "start": "2291960",
    "end": "2297240"
  },
  {
    "text": "and here's how the model looks currently so I will go from the top left yes its",
    "start": "2297240",
    "end": "2306150"
  },
  {
    "text": "top left on on your side and it's an example of price prediction right and we",
    "start": "2306150",
    "end": "2313080"
  },
  {
    "text": "have at update it could be at create anything then it goes to add processor at processor communicates with predictor",
    "start": "2313080",
    "end": "2320430"
  },
  {
    "text": "and then store this information to to storage and end to the topic right and",
    "start": "2320430",
    "end": "2326820"
  },
  {
    "text": "then from the topic we have of course like consumers we have indexers and and",
    "start": "2326820",
    "end": "2332430"
  },
  {
    "text": "stuff like that so we did you know that the business logic flaws but also we",
    "start": "2332430",
    "end": "2337740"
  },
  {
    "text": "store this data to HDFS and then this data can be used by data scientist as a",
    "start": "2337740",
    "end": "2343350"
  },
  {
    "text": "here's marked as h2 a platform to produce new new models and when new models are produced they are right back",
    "start": "2343350",
    "end": "2350430"
  },
  {
    "text": "to to the h2 all models in the cloud storage right and then on the down we",
    "start": "2350430",
    "end": "2359160"
  },
  {
    "text": "use that models in the pretty in in price predictor and we also use those model in our model checker right so",
    "start": "2359160",
    "end": "2366420"
  },
  {
    "text": "model checker checks the checks as a consumes again at topic is also like a consumer and and then produce",
    "start": "2366420",
    "end": "2374370"
  },
  {
    "text": "information results elasticsearch and then we have Cabana which can visualize that stuff and then then we know",
    "start": "2374370",
    "end": "2381150"
  },
  {
    "text": "everything about about the candidate right what is also what is also new and",
    "start": "2381150",
    "end": "2387390"
  },
  {
    "text": "as of from from my talk here is we have something like trigger recalculate all",
    "start": "2387390",
    "end": "2392460"
  },
  {
    "text": "prices right it's a it's a step we learned we need right because if if we",
    "start": "2392460",
    "end": "2397890"
  },
  {
    "text": "if we have a new model sometimes isness we we need to go through all adds and",
    "start": "2397890",
    "end": "2403910"
  },
  {
    "text": "recalculate the price to be some kind of unified right it's it's not always the",
    "start": "2403910",
    "end": "2410300"
  },
  {
    "text": "case but sometimes if we really change the model in really hard way we say okay",
    "start": "2410300",
    "end": "2415750"
  },
  {
    "text": "recalculate everything and we do in this step then we then we produce all new all",
    "start": "2415750",
    "end": "2422390"
  },
  {
    "text": "new infections to new topic and then add processor in a sync way it starts to",
    "start": "2422390",
    "end": "2429410"
  },
  {
    "text": "consuming so this this is not blocking this is not something where we can say a stop the world we're just producing new",
    "start": "2429410",
    "end": "2435260"
  },
  {
    "text": "predictions unfortunately it's not possible if you have like online business so we just create we just",
    "start": "2435260",
    "end": "2443000"
  },
  {
    "text": "create new new values new new labels in in that case and then ad processor is",
    "start": "2443000",
    "end": "2448610"
  },
  {
    "text": "able to consume that topic and and eventually end up with with updated",
    "start": "2448610",
    "end": "2454400"
  },
  {
    "text": "model so I have last slide it's a",
    "start": "2454400",
    "end": "2461240"
  },
  {
    "start": "2460000",
    "end": "2781000"
  },
  {
    "text": "conclusion and I thought what what to put there honestly and I think these two",
    "start": "2461240",
    "end": "2469070"
  },
  {
    "text": "informations are most important for me and hopefully also for you the first is",
    "start": "2469070",
    "end": "2475400"
  },
  {
    "text": "serving a model is just a part of the pipeline right from the engineering point of view when we started that that",
    "start": "2475400",
    "end": "2481690"
  },
  {
    "text": "project price prediction project then it",
    "start": "2481690",
    "end": "2486830"
  },
  {
    "text": "was like oh we will create a service and that's fine right we just serve the model but but it's just a small part the",
    "start": "2486830",
    "end": "2493730"
  },
  {
    "text": "huge the huge work you have to do is really grabbing the events right like",
    "start": "2493730",
    "end": "2499190"
  },
  {
    "text": "fetching from from the system that'sthat's that's important part serving is I think the simplest one if",
    "start": "2499190",
    "end": "2504440"
  },
  {
    "text": "you use something like h2o you export you have some some anti-corruption layers so you have fun as an engineer to",
    "start": "2504440",
    "end": "2511280"
  },
  {
    "text": "create that one but afterwards it's it's just normal service and also the second",
    "start": "2511280",
    "end": "2517220"
  },
  {
    "text": "point data quality matters this this was actually what we struggled a little bit",
    "start": "2517220",
    "end": "2524840"
  },
  {
    "text": "in the past and really really important that you do some kind of validation",
    "start": "2524840",
    "end": "2532160"
  },
  {
    "text": "right because when you start consuming even's and this evens our pork have also have poor quality then you will create",
    "start": "2532160",
    "end": "2540329"
  },
  {
    "text": "model which has also poor qualities is just you know proportional so that's two",
    "start": "2540329",
    "end": "2547290"
  },
  {
    "text": "points and then I have to put that slide for the credits if you like photos in the background you can check those on on",
    "start": "2547290",
    "end": "2554579"
  },
  {
    "text": "three and yes remember I rate this session and thank you for your attention",
    "start": "2554579",
    "end": "2561300"
  },
  {
    "text": "I'm ready to get some questions if you happen thank you and just to clarify I",
    "start": "2561300",
    "end": "2570960"
  },
  {
    "text": "was taking pictures I was trying to tweet some of the stuff you're talking about no problem but he made a good",
    "start": "2570960",
    "end": "2576000"
  },
  {
    "text": "point all the slides from the sessions unless the speaker just or their company won't let us publish them will be on the",
    "start": "2576000",
    "end": "2582329"
  },
  {
    "text": "go to amsterdam website so we got a few",
    "start": "2582329",
    "end": "2587550"
  },
  {
    "text": "questions and i don't think we're gonna have time to get to all of them so if yours doesn't get answered it will be up here later and you can feel free to come",
    "start": "2587550",
    "end": "2593940"
  },
  {
    "text": "up and ask yes okay so uh your your data",
    "start": "2593940",
    "end": "2600450"
  },
  {
    "text": "science team I guess this side of your brain that was doing the data science",
    "start": "2600450",
    "end": "2607020"
  },
  {
    "text": "you can call it like this yes so were you able to apply deep learning",
    "start": "2607020",
    "end": "2612720"
  },
  {
    "text": "algorithms in real time or nearly real-time in this production environment yes as a we experiment with many",
    "start": "2612720",
    "end": "2618390"
  },
  {
    "text": "algorithms also with deep learning and real-time and we have some progress in",
    "start": "2618390",
    "end": "2624690"
  },
  {
    "text": "this area and we currently have one but as I said this this is this is what the",
    "start": "2624690",
    "end": "2633210"
  },
  {
    "text": "data scientists do I mean the the biggest challenge is simply to do",
    "start": "2633210",
    "end": "2638369"
  },
  {
    "text": "live-streaming there right you have to get the data and you know even if you train your deep learning part it takes",
    "start": "2638369",
    "end": "2646020"
  },
  {
    "text": "time right and then you have different technologies like tensor flow or something else and maybe they are not so",
    "start": "2646020",
    "end": "2653220"
  },
  {
    "text": "Java friendly so you maybe have to even expose like a Python service in some",
    "start": "2653220",
    "end": "2659339"
  },
  {
    "text": "kind of docker we experiment also with that one but in this case you will you",
    "start": "2659339",
    "end": "2665130"
  },
  {
    "text": "will not reach the speed for example we like so for us deep learning is something we do",
    "start": "2665130",
    "end": "2670619"
  },
  {
    "text": "I think in the in the background and are you using Kafka streaming for validation",
    "start": "2670619",
    "end": "2677039"
  },
  {
    "text": "and data enrichment if not how do you deal with this in an industry buted environment as we do data validation and",
    "start": "2677039",
    "end": "2685829"
  },
  {
    "text": "enrichment with with Kafka's and then you have distributed environment per se",
    "start": "2685829",
    "end": "2691890"
  },
  {
    "text": "you have one topic topic has partitions when you connect then your client is",
    "start": "2691890",
    "end": "2696900"
  },
  {
    "text": "always as this is this is specific of Kafka connected to some kind of partitions and then you will it's",
    "start": "2696900",
    "end": "2704579"
  },
  {
    "text": "possible that you will consume something twice at least once they also pro a",
    "start": "2704579",
    "end": "2709859"
  },
  {
    "text": "promise now to deliver exactly other to do exactly once the process exactly was",
    "start": "2709859",
    "end": "2716339"
  },
  {
    "text": "but if you have distributed system I will not I will not fight to do",
    "start": "2716339",
    "end": "2721619"
  },
  {
    "text": "something exactly once I will say at least once right it's in the in",
    "start": "2721619",
    "end": "2727920"
  },
  {
    "text": "distributed systems normal last question how do you store the model to load it on",
    "start": "2727920",
    "end": "2733410"
  },
  {
    "text": "start how do you store the model to load it on start is it with serialize Java",
    "start": "2733410",
    "end": "2739339"
  },
  {
    "text": "yes as a when we export the model from h2 all it's it's this mojo but at the",
    "start": "2739339",
    "end": "2745619"
  },
  {
    "text": "end you have a nice Java package right so this is just a jar file nothing nothing special and and then you can use",
    "start": "2745619",
    "end": "2752489"
  },
  {
    "text": "that one from any storage you like as in our case is internal cloud solution but",
    "start": "2752489",
    "end": "2758039"
  },
  {
    "text": "of course you can store it in filesystem or I don't know AWS as it depends what",
    "start": "2758039",
    "end": "2763079"
  },
  {
    "text": "you use yes super and if you have any questions then just approach me I will",
    "start": "2763079",
    "end": "2769200"
  },
  {
    "text": "be happy to answer them ok thank you very much we do one more round of applause",
    "start": "2769200",
    "end": "2775670"
  },
  {
    "text": "you",
    "start": "2776300",
    "end": "2778360"
  }
]
[
  {
    "text": "right well thank you very much for the",
    "start": "11719",
    "end": "13200"
  },
  {
    "text": "introduction and thank you for coming to",
    "start": "13200",
    "end": "14799"
  },
  {
    "text": "my",
    "start": "14799",
    "end": "15520"
  },
  {
    "text": "talk now I think given the theme of this",
    "start": "15520",
    "end": "17920"
  },
  {
    "text": "conference it would not be an",
    "start": "17920",
    "end": "19600"
  },
  {
    "text": "overstatement if I said that these days",
    "start": "19600",
    "end": "21400"
  },
  {
    "text": "were buried in",
    "start": "21400",
    "end": "22720"
  },
  {
    "text": "data now that's a good thing and it's a",
    "start": "22720",
    "end": "24920"
  },
  {
    "text": "good thing because machine learning and",
    "start": "24920",
    "end": "26439"
  },
  {
    "text": "statistics are provided us with the",
    "start": "26439",
    "end": "28199"
  },
  {
    "text": "theory algorithms and software tools to",
    "start": "28199",
    "end": "31560"
  },
  {
    "text": "analyze this data and to derive",
    "start": "31560",
    "end": "34440"
  },
  {
    "text": "actionable Insight from it now of course",
    "start": "34440",
    "end": "37480"
  },
  {
    "text": "today I'm going to talk about data and",
    "start": "37480",
    "end": "39079"
  },
  {
    "text": "how to analyze it but data come in many",
    "start": "39079",
    "end": "42079"
  },
  {
    "text": "different forms and the kind of data I'm",
    "start": "42079",
    "end": "43879"
  },
  {
    "text": "going to talk about is connected data",
    "start": "43879",
    "end": "46920"
  },
  {
    "text": "now what is connected data connected",
    "start": "46920",
    "end": "49320"
  },
  {
    "text": "data is the kind of data that we can",
    "start": "49320",
    "end": "50760"
  },
  {
    "text": "represent in a graph data structure that",
    "start": "50760",
    "end": "53719"
  },
  {
    "text": "is familiar to us from computer science",
    "start": "53719",
    "end": "56280"
  },
  {
    "text": "now a graph consists of two main",
    "start": "56280",
    "end": "58280"
  },
  {
    "text": "elements we have noes that represent",
    "start": "58280",
    "end": "61039"
  },
  {
    "text": "entities in our data for example the",
    "start": "61039",
    "end": "64198"
  },
  {
    "text": "users of an online social network and",
    "start": "64199",
    "end": "67479"
  },
  {
    "text": "edges that connect nodes in the graph",
    "start": "67479",
    "end": "69880"
  },
  {
    "text": "and the edges represent relationships",
    "start": "69880",
    "end": "72880"
  },
  {
    "text": "between the entities in our data set for",
    "start": "72880",
    "end": "75320"
  },
  {
    "text": "example",
    "start": "75320",
    "end": "77240"
  },
  {
    "text": "friendship now there are many examples",
    "start": "77240",
    "end": "79400"
  },
  {
    "text": "of connected data because we live in a",
    "start": "79400",
    "end": "81200"
  },
  {
    "text": "connected World some examples include",
    "start": "81200",
    "end": "84200"
  },
  {
    "text": "the obvious ones you know social",
    "start": "84200",
    "end": "86200"
  },
  {
    "text": "networks but also Transportation",
    "start": "86200",
    "end": "88240"
  },
  {
    "text": "networks telecommunication Networks",
    "start": "88240",
    "end": "89880"
  },
  {
    "text": "networks biological networks terrorist",
    "start": "89880",
    "end": "93040"
  },
  {
    "text": "networks citation networks and financial",
    "start": "93040",
    "end": "95799"
  },
  {
    "text": "transaction networks such as",
    "start": "95799",
    "end": "98720"
  },
  {
    "text": "Bitcoin so what can we do with connected",
    "start": "98720",
    "end": "101600"
  },
  {
    "text": "data what kind of problems can we solve",
    "start": "101600",
    "end": "104520"
  },
  {
    "text": "we can broadly classify the kinds of",
    "start": "104520",
    "end": "107280"
  },
  {
    "text": "problems we can solve with connected",
    "start": "107280",
    "end": "108719"
  },
  {
    "text": "data into three",
    "start": "108719",
    "end": "110920"
  },
  {
    "text": "categories the first one is what we call",
    "start": "110920",
    "end": "114040"
  },
  {
    "text": "node classification or node attribute",
    "start": "114040",
    "end": "116840"
  },
  {
    "text": "inference in node classification our",
    "start": "116840",
    "end": "119119"
  },
  {
    "text": "goal is to tr train a predictive model",
    "start": "119119",
    "end": "122000"
  },
  {
    "text": "to predict an attribute of the entities",
    "start": "122000",
    "end": "125560"
  },
  {
    "text": "in the graph for example in a social",
    "start": "125560",
    "end": "128360"
  },
  {
    "text": "network given maybe we're interested in",
    "start": "128360",
    "end": "131160"
  },
  {
    "text": "predicting the political affiliation of",
    "start": "131160",
    "end": "133319"
  },
  {
    "text": "the users given that we know the",
    "start": "133319",
    "end": "135200"
  },
  {
    "text": "political affiliation of a subset of the",
    "start": "135200",
    "end": "137000"
  },
  {
    "text": "users the relationships between the",
    "start": "137000",
    "end": "139200"
  },
  {
    "text": "users and possibly additional",
    "start": "139200",
    "end": "140959"
  },
  {
    "text": "information for each user for example",
    "start": "140959",
    "end": "143120"
  },
  {
    "text": "their AIDS their location their um",
    "start": "143120",
    "end": "146800"
  },
  {
    "text": "professional activities and the kind of",
    "start": "146800",
    "end": "148160"
  },
  {
    "text": "stories that they like to read",
    "start": "148160",
    "end": "151599"
  },
  {
    "text": "another kind of problem we want to we",
    "start": "151599",
    "end": "153480"
  },
  {
    "text": "can solve with connected data is called",
    "start": "153480",
    "end": "155920"
  },
  {
    "text": "link prediction and for link prediction",
    "start": "155920",
    "end": "158080"
  },
  {
    "text": "we're trying to predict the",
    "start": "158080",
    "end": "159040"
  },
  {
    "text": "relationships in our data now why do we",
    "start": "159040",
    "end": "161760"
  },
  {
    "text": "want to predict relationships there's a",
    "start": "161760",
    "end": "164080"
  },
  {
    "text": "couple of reasons I can think of for one",
    "start": "164080",
    "end": "166560"
  },
  {
    "text": "it's possible that our data is noisy",
    "start": "166560",
    "end": "168800"
  },
  {
    "text": "maybe due to the process with which we",
    "start": "168800",
    "end": "171200"
  },
  {
    "text": "collected the data some of the",
    "start": "171200",
    "end": "173200"
  },
  {
    "text": "relationships are hidden from us and we",
    "start": "173200",
    "end": "174840"
  },
  {
    "text": "want to predict them another reason",
    "start": "174840",
    "end": "177040"
  },
  {
    "text": "would be that we want to predict predict",
    "start": "177040",
    "end": "180200"
  },
  {
    "text": "how our graph is going to evolve in the",
    "start": "180200",
    "end": "184720"
  },
  {
    "text": "future um link prediction a good",
    "start": "184720",
    "end": "186879"
  },
  {
    "text": "application for link prediction is",
    "start": "186879",
    "end": "188599"
  },
  {
    "text": "product recommendation you can use um uh",
    "start": "188599",
    "end": "192400"
  },
  {
    "text": "link prediction algorithm to recommend",
    "start": "192400",
    "end": "194840"
  },
  {
    "text": "products to users of an e-commerce",
    "start": "194840",
    "end": "197680"
  },
  {
    "text": "website the third category of problems",
    "start": "197680",
    "end": "201280"
  },
  {
    "text": "is a clustering of the entities in our",
    "start": "201280",
    "end": "203440"
  },
  {
    "text": "data set in our",
    "start": "203440",
    "end": "205159"
  },
  {
    "text": "graph uh we call it Community detection",
    "start": "205159",
    "end": "208360"
  },
  {
    "text": "now why do we want to do this uh maybe",
    "start": "208360",
    "end": "210319"
  },
  {
    "text": "we're interested for example in grouping",
    "start": "210319",
    "end": "212799"
  },
  {
    "text": "the users of a social network into",
    "start": "212799",
    "end": "215200"
  },
  {
    "text": "communities based on their Hobbies",
    "start": "215200",
    "end": "217040"
  },
  {
    "text": "without us having to go and explicitly",
    "start": "217040",
    "end": "219040"
  },
  {
    "text": "ask them one at a time do you like sport",
    "start": "219040",
    "end": "221640"
  },
  {
    "text": "do you like watching TV do you like",
    "start": "221640",
    "end": "223519"
  },
  {
    "text": "movies what kind of movies do you like",
    "start": "223519",
    "end": "225239"
  },
  {
    "text": "do you like music and so on and so",
    "start": "225239",
    "end": "227840"
  },
  {
    "text": "forth why do we want to do this for a",
    "start": "227840",
    "end": "230080"
  },
  {
    "text": "social network maybe we want to Target",
    "start": "230080",
    "end": "232760"
  },
  {
    "text": "our advertising a bit better but of",
    "start": "232760",
    "end": "235920"
  },
  {
    "text": "course there are applications of this",
    "start": "235920",
    "end": "237519"
  },
  {
    "text": "outside of selling ads right for example",
    "start": "237519",
    "end": "240599"
  },
  {
    "text": "a law enforcement agency may be",
    "start": "240599",
    "end": "242439"
  },
  {
    "text": "interested in detecting um uh whether um",
    "start": "242439",
    "end": "246120"
  },
  {
    "text": "a group of people in an online Forum",
    "start": "246120",
    "end": "248480"
  },
  {
    "text": "comprise a criminal",
    "start": "248480",
    "end": "250239"
  },
  {
    "text": "Syndicate now for the rest of the day um",
    "start": "250239",
    "end": "253319"
  },
  {
    "text": "I'm going to talk about a node",
    "start": "253319",
    "end": "254799"
  },
  {
    "text": "classification problem obviously we",
    "start": "254799",
    "end": "256160"
  },
  {
    "text": "don't have the time to discuss each each",
    "start": "256160",
    "end": "257919"
  },
  {
    "text": "of these classes of pro",
    "start": "257919",
    "end": "260919"
  },
  {
    "text": "problems uh I'm going to set up a",
    "start": "260919",
    "end": "262960"
  },
  {
    "text": "problem and then I'm going to show you",
    "start": "262960",
    "end": "264840"
  },
  {
    "text": "the methods we use to solve those kind",
    "start": "264840",
    "end": "266919"
  },
  {
    "text": "of problems state-of-the-art methods and",
    "start": "266919",
    "end": "269280"
  },
  {
    "text": "then I'm going to show you how to do",
    "start": "269280",
    "end": "270960"
  },
  {
    "text": "this programmatically using our open",
    "start": "270960",
    "end": "272759"
  },
  {
    "text": "source",
    "start": "272759",
    "end": "274160"
  },
  {
    "text": "Library let's say that I have data this",
    "start": "274160",
    "end": "276680"
  },
  {
    "text": "is data um collected from Twitter and",
    "start": "276680",
    "end": "280039"
  },
  {
    "text": "the individuals are Twitter",
    "start": "280039",
    "end": "282639"
  },
  {
    "text": "users I have about I have data for about",
    "start": "282639",
    "end": "285560"
  },
  {
    "text": "100,000 of these users which you know in",
    "start": "285560",
    "end": "288759"
  },
  {
    "text": "the grand scheme of things is looks like",
    "start": "288759",
    "end": "290680"
  },
  {
    "text": "a big number but you know if you think",
    "start": "290680",
    "end": "291960"
  },
  {
    "text": "of the total number of people using ttor",
    "start": "291960",
    "end": "293639"
  },
  {
    "text": "is just a small sample let's assume that",
    "start": "293639",
    "end": "295680"
  },
  {
    "text": "I've used proper methodology and this is",
    "start": "295680",
    "end": "297320"
  },
  {
    "text": "a proper um sample of the Twitter",
    "start": "297320",
    "end": "300880"
  },
  {
    "text": "Network for each of these users I want",
    "start": "300880",
    "end": "303800"
  },
  {
    "text": "to predict a binary attribute I'm",
    "start": "303800",
    "end": "305639"
  },
  {
    "text": "interested in identifying hate speeds",
    "start": "305639",
    "end": "308080"
  },
  {
    "text": "online so for each user I want to",
    "start": "308080",
    "end": "310000"
  },
  {
    "text": "identify I want to predict if they are",
    "start": "310000",
    "end": "311720"
  },
  {
    "text": "hateful or not for my 100,000 users for",
    "start": "311720",
    "end": "315680"
  },
  {
    "text": "5,000 of them I have annotations as to",
    "start": "315680",
    "end": "318280"
  },
  {
    "text": "whether they're hateful or not it's a",
    "start": "318280",
    "end": "319840"
  },
  {
    "text": "50/50 split now this is manually",
    "start": "319840",
    "end": "322800"
  },
  {
    "text": "annotated data set right so we asked",
    "start": "322800",
    "end": "325039"
  },
  {
    "text": "people the people who collected the data",
    "start": "325039",
    "end": "327280"
  },
  {
    "text": "set asked people to identify whether",
    "start": "327280",
    "end": "329560"
  },
  {
    "text": "particular users are hateful or",
    "start": "329560",
    "end": "332400"
  },
  {
    "text": "not now for each user we also have a",
    "start": "332400",
    "end": "335120"
  },
  {
    "text": "numerical feature Vector that tells us",
    "start": "335120",
    "end": "337240"
  },
  {
    "text": "something about the user now there are",
    "start": "337240",
    "end": "339560"
  },
  {
    "text": "two types of features in this feature",
    "start": "339560",
    "end": "341039"
  },
  {
    "text": "Vector they're all numerical now one",
    "start": "341039",
    "end": "343759"
  },
  {
    "text": "type of features is derived from the",
    "start": "343759",
    "end": "346199"
  },
  {
    "text": "users's activity on Twitter for example",
    "start": "346199",
    "end": "348759"
  },
  {
    "text": "the number of followers they have the",
    "start": "348759",
    "end": "350039"
  },
  {
    "text": "number of Fes the number of hashtags",
    "start": "350039",
    "end": "351840"
  },
  {
    "text": "they use when they tweet and the",
    "start": "351840",
    "end": "354240"
  },
  {
    "text": "frequency at which they tweet the other",
    "start": "354240",
    "end": "357080"
  },
  {
    "text": "type of features is derived from from",
    "start": "357080",
    "end": "360000"
  },
  {
    "text": "the text from the textual analysis the",
    "start": "360000",
    "end": "362120"
  },
  {
    "text": "lexical analysis of the users",
    "start": "362120",
    "end": "365440"
  },
  {
    "text": "tweets and for the lexical analysis our",
    "start": "365440",
    "end": "368199"
  },
  {
    "text": "goal is that um we look at the",
    "start": "368199",
    "end": "370479"
  },
  {
    "text": "vocabulary the you each user uses and",
    "start": "370479",
    "end": "372720"
  },
  {
    "text": "we're trying to determine in a",
    "start": "372720",
    "end": "375120"
  },
  {
    "text": "quantitative way if this user uses",
    "start": "375120",
    "end": "378240"
  },
  {
    "text": "vocabulary that relates to particular",
    "start": "378240",
    "end": "379880"
  },
  {
    "text": "topics for example positive and negative",
    "start": "379880",
    "end": "381720"
  },
  {
    "text": "emotions sadness family love terrorism",
    "start": "381720",
    "end": "385880"
  },
  {
    "text": "politics um and and so on so there's",
    "start": "385880",
    "end": "388599"
  },
  {
    "text": "about 200 f fees that I've selected for",
    "start": "388599",
    "end": "390840"
  },
  {
    "text": "this um for this",
    "start": "390840",
    "end": "394160"
  },
  {
    "text": "talk now like I said we're going to",
    "start": "394280",
    "end": "397080"
  },
  {
    "text": "solve a binary classification problem we",
    "start": "397080",
    "end": "400120"
  },
  {
    "text": "have a subset of the data annotated so I",
    "start": "400120",
    "end": "402840"
  },
  {
    "text": "have a semi-supervised binary",
    "start": "402840",
    "end": "404520"
  },
  {
    "text": "classification problem I going to solve",
    "start": "404520",
    "end": "406039"
  },
  {
    "text": "I can use traditional machine learning",
    "start": "406039",
    "end": "408120"
  },
  {
    "text": "to solve this problem I'm sure many of",
    "start": "408120",
    "end": "409840"
  },
  {
    "text": "you can think of ways to do it here's",
    "start": "409840",
    "end": "412319"
  },
  {
    "text": "here it is I would take my f vectors I'm",
    "start": "412319",
    "end": "415440"
  },
  {
    "text": "going to stuck them into a",
    "start": "415440",
    "end": "416879"
  },
  {
    "text": "two-dimensional array I'm going to make",
    "start": "416879",
    "end": "418840"
  },
  {
    "text": "a f Matrix and of course I'm going to",
    "start": "418840",
    "end": "421520"
  },
  {
    "text": "take the the targets as well I'm going",
    "start": "421520",
    "end": "424280"
  },
  {
    "text": "to pass them to my favorite um machine",
    "start": "424280",
    "end": "427199"
  },
  {
    "text": "learning algorithm could it be logistic",
    "start": "427199",
    "end": "429319"
  },
  {
    "text": "regression or random Forest you can use",
    "start": "429319",
    "end": "430879"
  },
  {
    "text": "a neural network if you want I'm going",
    "start": "430879",
    "end": "432840"
  },
  {
    "text": "to train a model and I'm going to use",
    "start": "432840",
    "end": "434400"
  },
  {
    "text": "the model to make predictions for the",
    "start": "434400",
    "end": "436160"
  },
  {
    "text": "95,000 users I don't have data",
    "start": "436160",
    "end": "438720"
  },
  {
    "text": "for okay this is the way we do things",
    "start": "438720",
    "end": "442240"
  },
  {
    "text": "okay but what's missing from this",
    "start": "442240",
    "end": "444039"
  },
  {
    "text": "picture well this that Twitter uses and",
    "start": "444039",
    "end": "446680"
  },
  {
    "text": "Twitter is an online social network and",
    "start": "446680",
    "end": "449400"
  },
  {
    "text": "so the users are",
    "start": "449400",
    "end": "450840"
  },
  {
    "text": "connected now the connections this data",
    "start": "450840",
    "end": "453319"
  },
  {
    "text": "set was actually collected by Manuel REO",
    "start": "453319",
    "end": "455560"
  },
  {
    "text": "and his colleagues um in their efforts",
    "start": "455560",
    "end": "457840"
  },
  {
    "text": "to understand head speeds online and the",
    "start": "457840",
    "end": "461199"
  },
  {
    "text": "connections the relations between the",
    "start": "461199",
    "end": "462759"
  },
  {
    "text": "users are not the obvious connections",
    "start": "462759",
    "end": "464919"
  },
  {
    "text": "like you know a person follows another",
    "start": "464919",
    "end": "466720"
  },
  {
    "text": "person instead there is an edge between",
    "start": "466720",
    "end": "469039"
  },
  {
    "text": "two users if a person has retweeted",
    "start": "469039",
    "end": "472000"
  },
  {
    "text": "another",
    "start": "472000",
    "end": "473280"
  },
  {
    "text": "person now what is the problem with the",
    "start": "473280",
    "end": "475960"
  },
  {
    "text": "traditional Mel approach in this setting",
    "start": "475960",
    "end": "477639"
  },
  {
    "text": "and why do we care about their",
    "start": "477639",
    "end": "478879"
  },
  {
    "text": "relationship ships now it it is quite",
    "start": "478879",
    "end": "481960"
  },
  {
    "text": "possible and not",
    "start": "481960",
    "end": "484319"
  },
  {
    "text": "inconceivable that a user does not want",
    "start": "484319",
    "end": "486840"
  },
  {
    "text": "to appear hateful right when he's",
    "start": "486840",
    "end": "488919"
  },
  {
    "text": "tweeting so his vocabulary is chosen",
    "start": "488919",
    "end": "491199"
  },
  {
    "text": "very very carefully that means the",
    "start": "491199",
    "end": "493360"
  },
  {
    "text": "feature vectors are not very good at",
    "start": "493360",
    "end": "496639"
  },
  {
    "text": "identifying that property of",
    "start": "496639",
    "end": "499639"
  },
  {
    "text": "his however he might be comfortable in",
    "start": "499639",
    "end": "502199"
  },
  {
    "text": "retweeting other people who are",
    "start": "502199",
    "end": "503520"
  },
  {
    "text": "obviously hateful right so that",
    "start": "503520",
    "end": "506120"
  },
  {
    "text": "information is hidden in the",
    "start": "506120",
    "end": "508240"
  },
  {
    "text": "relationships",
    "start": "508240",
    "end": "509919"
  },
  {
    "text": "so we want to take advantage of that",
    "start": "509919",
    "end": "511960"
  },
  {
    "text": "right because we hope it will make it",
    "start": "511960",
    "end": "513880"
  },
  {
    "text": "easier for us to classify users",
    "start": "513880",
    "end": "515919"
  },
  {
    "text": "correctly you don't want to be going",
    "start": "515919",
    "end": "517599"
  },
  {
    "text": "around blaming people for being hateful",
    "start": "517599",
    "end": "519800"
  },
  {
    "text": "if they're",
    "start": "519800",
    "end": "521800"
  },
  {
    "text": "not now our data set has a few edges has",
    "start": "521800",
    "end": "525320"
  },
  {
    "text": "2.2 million edges so it's it's",
    "start": "525320",
    "end": "527279"
  },
  {
    "text": "relatively sparse given that we have",
    "start": "527279",
    "end": "529200"
  },
  {
    "text": "100,000",
    "start": "529200",
    "end": "531800"
  },
  {
    "text": "users um how can we solve this problem",
    "start": "531800",
    "end": "535080"
  },
  {
    "text": "using traditional ml how can we take",
    "start": "535080",
    "end": "537040"
  },
  {
    "text": "advantage of the relationships if we",
    "start": "537040",
    "end": "539440"
  },
  {
    "text": "using still traditional machine learning",
    "start": "539440",
    "end": "541680"
  },
  {
    "text": "methods okay one way to do it would be",
    "start": "541680",
    "end": "543800"
  },
  {
    "text": "to use manual feature engineering so I",
    "start": "543800",
    "end": "545720"
  },
  {
    "text": "can go back to my graph and I can look",
    "start": "545720",
    "end": "549120"
  },
  {
    "text": "at uh extracting features relating to",
    "start": "549120",
    "end": "551640"
  },
  {
    "text": "the graph structure for example I can",
    "start": "551640",
    "end": "553519"
  },
  {
    "text": "take a user I can look at the number of",
    "start": "553519",
    "end": "555600"
  },
  {
    "text": "people he's connected with the number of",
    "start": "555600",
    "end": "557279"
  },
  {
    "text": "people he's retweeting we call this the",
    "start": "557279",
    "end": "559320"
  },
  {
    "text": "node degree and I can take that number",
    "start": "559320",
    "end": "561320"
  },
  {
    "text": "and augment it with my feature vector",
    "start": "561320",
    "end": "563720"
  },
  {
    "text": "and now I have a longer fure Vector but",
    "start": "563720",
    "end": "565600"
  },
  {
    "text": "I can use it in my mail method to train",
    "start": "565600",
    "end": "568720"
  },
  {
    "text": "a model make predictions there are many",
    "start": "568720",
    "end": "571279"
  },
  {
    "text": "many different ways of creating features",
    "start": "571279",
    "end": "573240"
  },
  {
    "text": "this way right but if there's anything",
    "start": "573240",
    "end": "575640"
  },
  {
    "text": "we've learned from the successes of deep",
    "start": "575640",
    "end": "577959"
  },
  {
    "text": "learning and especially convolutional",
    "start": "577959",
    "end": "580160"
  },
  {
    "text": "neuron networks is that manual feature",
    "start": "580160",
    "end": "582560"
  },
  {
    "text": "engineering is probably not the best way",
    "start": "582560",
    "end": "584640"
  },
  {
    "text": "to do this we should let the machine",
    "start": "584640",
    "end": "586640"
  },
  {
    "text": "learning",
    "start": "586640",
    "end": "588120"
  },
  {
    "text": "algorithm decide what the best features",
    "start": "588120",
    "end": "591399"
  },
  {
    "text": "are for maximizing the performance on",
    "start": "591399",
    "end": "594320"
  },
  {
    "text": "the downstream task and we would like to",
    "start": "594320",
    "end": "596519"
  },
  {
    "text": "be able to do this with craft structured",
    "start": "596519",
    "end": "600320"
  },
  {
    "text": "data unfortunately none of the",
    "start": "600320",
    "end": "602440"
  },
  {
    "text": "traditional machine learning methods can",
    "start": "602440",
    "end": "604200"
  },
  {
    "text": "do this right so we need to invent new",
    "start": "604200",
    "end": "605959"
  },
  {
    "text": "ones well we're not going to invent them",
    "start": "605959",
    "end": "608959"
  },
  {
    "text": "there are other people out there who",
    "start": "608959",
    "end": "610160"
  },
  {
    "text": "have invented those for us so I'm going",
    "start": "610160",
    "end": "613040"
  },
  {
    "text": "to go I'm going to give a quick overview",
    "start": "613040",
    "end": "614720"
  },
  {
    "text": "of two different methods that um in the",
    "start": "614720",
    "end": "617720"
  },
  {
    "text": "class of graph neural network models",
    "start": "617720",
    "end": "620360"
  },
  {
    "text": "that we can use directly on our graph s",
    "start": "620360",
    "end": "623000"
  },
  {
    "text": "data to solve a n classification problem",
    "start": "623000",
    "end": "626839"
  },
  {
    "text": "now the first one was introduced in",
    "start": "626839",
    "end": "628120"
  },
  {
    "text": "early 20 17 by keep fuelling it's called",
    "start": "628120",
    "end": "631560"
  },
  {
    "text": "graph convolution",
    "start": "631560",
    "end": "634000"
  },
  {
    "text": "networks",
    "start": "634000",
    "end": "635800"
  },
  {
    "text": "gcn now um gcn defines a new type of",
    "start": "635800",
    "end": "640480"
  },
  {
    "text": "neural network layer right that's",
    "start": "640480",
    "end": "642320"
  },
  {
    "text": "applicable to graphs the forward model",
    "start": "642320",
    "end": "644839"
  },
  {
    "text": "is straightforward it actually involves",
    "start": "644839",
    "end": "646519"
  },
  {
    "text": "only three",
    "start": "646519",
    "end": "647639"
  },
  {
    "text": "quantities W which are the trainable",
    "start": "647639",
    "end": "650240"
  },
  {
    "text": "parameters for the layer F which is the",
    "start": "650240",
    "end": "652800"
  },
  {
    "text": "same fure Matrix that we used for",
    "start": "652800",
    "end": "655079"
  },
  {
    "text": "training the traditional Ming model I",
    "start": "655079",
    "end": "657040"
  },
  {
    "text": "talked about a couple of minutes ago and",
    "start": "657040",
    "end": "659480"
  },
  {
    "text": "a prime which encodes the structure of",
    "start": "659480",
    "end": "663560"
  },
  {
    "text": "the graph it is actually a function of",
    "start": "663560",
    "end": "665839"
  },
  {
    "text": "the graph adjacent symmetrix it's a",
    "start": "665839",
    "end": "667600"
  },
  {
    "text": "square Matrix and in our case it's",
    "start": "667600",
    "end": "670720"
  },
  {
    "text": "100,000 by 100,000 so it's quite",
    "start": "670720",
    "end": "673240"
  },
  {
    "text": "large I say it's it's not exactly the",
    "start": "673240",
    "end": "676040"
  },
  {
    "text": "graph adjacency Matrix we apply some",
    "start": "676040",
    "end": "678279"
  },
  {
    "text": "normalization to it but it's not very",
    "start": "678279",
    "end": "680480"
  },
  {
    "text": "different than the graph adjacency",
    "start": "680480",
    "end": "682399"
  },
  {
    "text": "Matrix then we multiply these three",
    "start": "682399",
    "end": "684839"
  },
  {
    "text": "matrices we apply an element wise",
    "start": "684839",
    "end": "687480"
  },
  {
    "text": "nonlinear function for example the",
    "start": "687480",
    "end": "690200"
  },
  {
    "text": "um rectified linear unit and that gives",
    "start": "690200",
    "end": "692040"
  },
  {
    "text": "us the output for the layer of course I",
    "start": "692040",
    "end": "693800"
  },
  {
    "text": "can take many of these layers I can Stu",
    "start": "693800",
    "end": "695720"
  },
  {
    "text": "them back to back to make a deer model",
    "start": "695720",
    "end": "697680"
  },
  {
    "text": "and I can train this end to endend using",
    "start": "697680",
    "end": "700519"
  },
  {
    "text": "um grad in",
    "start": "700519",
    "end": "703079"
  },
  {
    "text": "descent okay so this method when it was",
    "start": "703079",
    "end": "705680"
  },
  {
    "text": "introduced it actually pushed the um",
    "start": "705680",
    "end": "709000"
  },
  {
    "text": "state-ofthe-art in nor classification",
    "start": "709000",
    "end": "711240"
  },
  {
    "text": "for graphs uh I head by large margin",
    "start": "711240",
    "end": "714440"
  },
  {
    "text": "like for some of the standard benchmarks",
    "start": "714440",
    "end": "716760"
  },
  {
    "text": "it pushed itead by something like 20 or",
    "start": "716760",
    "end": "719040"
  },
  {
    "text": "more percent that's a big",
    "start": "719040",
    "end": "721399"
  },
  {
    "text": "Improvement the problem with this model",
    "start": "721399",
    "end": "723600"
  },
  {
    "text": "is is that you have to perform this",
    "start": "723600",
    "end": "725680"
  },
  {
    "text": "multiplication between a and F and this",
    "start": "725680",
    "end": "728240"
  },
  {
    "text": "can be very big metries now 100,000",
    "start": "728240",
    "end": "730240"
  },
  {
    "text": "isn't too bad but when you go to",
    "start": "730240",
    "end": "732600"
  },
  {
    "text": "Millions then it becomes intractable and",
    "start": "732600",
    "end": "734920"
  },
  {
    "text": "you won't be able to do it on a even on",
    "start": "734920",
    "end": "737079"
  },
  {
    "text": "a big",
    "start": "737079",
    "end": "739360"
  },
  {
    "text": "computer but it does form a very good",
    "start": "739360",
    "end": "741639"
  },
  {
    "text": "Baseline if you just experimenting with",
    "start": "741639",
    "end": "743760"
  },
  {
    "text": "graph nura networks now later in",
    "start": "743760",
    "end": "747440"
  },
  {
    "text": "2017 um how and his colleagues they",
    "start": "747440",
    "end": "751160"
  },
  {
    "text": "introduced another method that's very",
    "start": "751160",
    "end": "752920"
  },
  {
    "text": "similar in nature to gcn but it is much",
    "start": "752920",
    "end": "755959"
  },
  {
    "text": "more scalable okay it's called graph",
    "start": "755959",
    "end": "758480"
  },
  {
    "text": "States graph sample and aggregate it",
    "start": "758480",
    "end": "761240"
  },
  {
    "text": "also defines a new type of graph neural",
    "start": "761240",
    "end": "763720"
  },
  {
    "text": "network layer the Insight behind graph s",
    "start": "763720",
    "end": "768120"
  },
  {
    "text": "is that to make a good prediction for a",
    "start": "768120",
    "end": "769959"
  },
  {
    "text": "node you should look at its own feure",
    "start": "769959",
    "end": "772320"
  },
  {
    "text": "Vector but you can do better if you also",
    "start": "772320",
    "end": "774920"
  },
  {
    "text": "look at the feure vectors of its",
    "start": "774920",
    "end": "776800"
  },
  {
    "text": "neighbors in the graph but then how do",
    "start": "776800",
    "end": "779240"
  },
  {
    "text": "you do this how do you bring that",
    "start": "779240",
    "end": "780760"
  },
  {
    "text": "information into its node well you apply",
    "start": "780760",
    "end": "783320"
  },
  {
    "text": "an aggregation function you iterate over",
    "start": "783320",
    "end": "785279"
  },
  {
    "text": "the neighborhood of a node you pick out",
    "start": "785279",
    "end": "787920"
  },
  {
    "text": "their fure vectors you aggregate them",
    "start": "787920",
    "end": "790040"
  },
  {
    "text": "you use something like the mean you take",
    "start": "790040",
    "end": "792199"
  },
  {
    "text": "the average of them or you can use a",
    "start": "792199",
    "end": "794040"
  },
  {
    "text": "trainable function it could be just",
    "start": "794040",
    "end": "795360"
  },
  {
    "text": "another neural network but you combine",
    "start": "795360",
    "end": "797040"
  },
  {
    "text": "them into a single feature Vector then",
    "start": "797040",
    "end": "799360"
  },
  {
    "text": "you pass that information to the central",
    "start": "799360",
    "end": "801920"
  },
  {
    "text": "node you combine each own feature Vector",
    "start": "801920",
    "end": "805120"
  },
  {
    "text": "with its neighbors for example this",
    "start": "805120",
    "end": "806639"
  },
  {
    "text": "example shows concatenation you can of",
    "start": "806639",
    "end": "808880"
  },
  {
    "text": "course take the averaging or apply",
    "start": "808880",
    "end": "810079"
  },
  {
    "text": "another function if you want and then",
    "start": "810079",
    "end": "812680"
  },
  {
    "text": "you apply linear transformation you",
    "start": "812680",
    "end": "814120"
  },
  {
    "text": "multiply by W that these are the weights",
    "start": "814120",
    "end": "816440"
  },
  {
    "text": "of the layer and unknown linearity",
    "start": "816440",
    "end": "818600"
  },
  {
    "text": "element wise that we're all very",
    "start": "818600",
    "end": "820519"
  },
  {
    "text": "familiar with from neuron",
    "start": "820519",
    "end": "822639"
  },
  {
    "text": "networks the this looks similar to gcn",
    "start": "822639",
    "end": "826360"
  },
  {
    "text": "the scalability comes from the fact that",
    "start": "826360",
    "end": "829000"
  },
  {
    "text": "instead of actually aggregating",
    "start": "829000",
    "end": "830480"
  },
  {
    "text": "information from every neighbor of a",
    "start": "830480",
    "end": "833759"
  },
  {
    "text": "node we sample a subset of the neighbors",
    "start": "833759",
    "end": "837000"
  },
  {
    "text": "okay and we can cap that numbers for for",
    "start": "837000",
    "end": "838839"
  },
  {
    "text": "example we can sample only 10 neighbors",
    "start": "838839",
    "end": "840680"
  },
  {
    "text": "or 20 neighbors what this means is that",
    "start": "840680",
    "end": "842839"
  },
  {
    "text": "basically at the end of the day the",
    "start": "842839",
    "end": "844759"
  },
  {
    "text": "machine learning model that you're",
    "start": "844759",
    "end": "845880"
  },
  {
    "text": "building is of a fixed size and it",
    "start": "845880",
    "end": "848519"
  },
  {
    "text": "doesn't depend on the size of the graph",
    "start": "848519",
    "end": "851040"
  },
  {
    "text": "which means that you can have a small",
    "start": "851040",
    "end": "852320"
  },
  {
    "text": "graph or you can have a huge graph and",
    "start": "852320",
    "end": "854880"
  },
  {
    "text": "it still works really well one of my",
    "start": "854880",
    "end": "856720"
  },
  {
    "text": "colleagues this morning Kevin he saw how",
    "start": "856720",
    "end": "859160"
  },
  {
    "text": "he can you can use this algorithm to",
    "start": "859160",
    "end": "861959"
  },
  {
    "text": "solve a no classification problem for a",
    "start": "861959",
    "end": "863920"
  },
  {
    "text": "very large network was a Bitcoin data",
    "start": "863920",
    "end": "865920"
  },
  {
    "text": "set with 400 million",
    "start": "865920",
    "end": "867680"
  },
  {
    "text": "nodes",
    "start": "867680",
    "end": "870360"
  },
  {
    "text": "now of course say you have graph data",
    "start": "870360",
    "end": "873839"
  },
  {
    "text": "and you want to try these models on your",
    "start": "873839",
    "end": "876000"
  },
  {
    "text": "data set and you going to going to do",
    "start": "876000",
    "end": "878320"
  },
  {
    "text": "this to see if it if it works for you or",
    "start": "878320",
    "end": "879920"
  },
  {
    "text": "not right fortunately the devil is in",
    "start": "879920",
    "end": "881759"
  },
  {
    "text": "the details when you try to implement",
    "start": "881759",
    "end": "883399"
  },
  {
    "text": "these algorithms it takes time and",
    "start": "883399",
    "end": "885560"
  },
  {
    "text": "effort to implement them correctly and",
    "start": "885560",
    "end": "888440"
  },
  {
    "text": "efficiently especially when you have",
    "start": "888440",
    "end": "890360"
  },
  {
    "text": "like deadlines bearing down in you and",
    "start": "890360",
    "end": "891959"
  },
  {
    "text": "your Bo is breathing down your neck it's",
    "start": "891959",
    "end": "894000"
  },
  {
    "text": "difficult to do it",
    "start": "894000",
    "end": "895600"
  },
  {
    "text": "correctly so at data 61 our team Stell",
    "start": "895600",
    "end": "899959"
  },
  {
    "text": "graph we have developed a python library",
    "start": "899959",
    "end": "902560"
  },
  {
    "text": "for graph machine learning it is also",
    "start": "902560",
    "end": "904759"
  },
  {
    "text": "called Stell graph you can find is in",
    "start": "904759",
    "end": "907079"
  },
  {
    "text": "GitHub it's based on car intensive law",
    "start": "907079",
    "end": "910480"
  },
  {
    "text": "and we use also Network X for graph",
    "start": "910480",
    "end": "913920"
  },
  {
    "text": "iio we're we've published it under the",
    "start": "913920",
    "end": "916480"
  },
  {
    "text": "Apache 2.0 license we've done two major",
    "start": "916480",
    "end": "918800"
  },
  {
    "text": "releases so far one was as recently as a",
    "start": "918800",
    "end": "921240"
  },
  {
    "text": "few weeks ago and we are making another",
    "start": "921240",
    "end": "923720"
  },
  {
    "text": "major release in a few months but we",
    "start": "923720",
    "end": "925920"
  },
  {
    "text": "also do minor releases quite often",
    "start": "925920",
    "end": "929880"
  },
  {
    "text": "um we have lots of documentation uh and",
    "start": "929880",
    "end": "932440"
  },
  {
    "text": "lots of demos on GitHub and we also have",
    "start": "932440",
    "end": "936399"
  },
  {
    "text": "a forum a discourse Forum where you can",
    "start": "936399",
    "end": "938399"
  },
  {
    "text": "go there and you can ask questions if",
    "start": "938399",
    "end": "940440"
  },
  {
    "text": "you need help or if you have feature",
    "start": "940440",
    "end": "942079"
  },
  {
    "text": "requests or if you want to report a bug",
    "start": "942079",
    "end": "944399"
  },
  {
    "text": "or too now our forum is brand new we",
    "start": "944399",
    "end": "946880"
  },
  {
    "text": "just opened it up like a week ago so",
    "start": "946880",
    "end": "948560"
  },
  {
    "text": "there isn't a lot of activity there at",
    "start": "948560",
    "end": "949800"
  },
  {
    "text": "the moment but you're welcome to come",
    "start": "949800",
    "end": "951600"
  },
  {
    "text": "and ask questions if you'd like for the",
    "start": "951600",
    "end": "954440"
  },
  {
    "text": "rest of the talk I'm going to show you",
    "start": "954440",
    "end": "955959"
  },
  {
    "text": "how you can use Telegraph to use to",
    "start": "955959",
    "end": "958880"
  },
  {
    "text": "implement gcn and steg graph and solve",
    "start": "958880",
    "end": "961720"
  },
  {
    "text": "the hateful twitterers problem but",
    "start": "961720",
    "end": "964959"
  },
  {
    "text": "before I do that let's have a look at",
    "start": "964959",
    "end": "966800"
  },
  {
    "text": "the traditional machine learning",
    "start": "966800",
    "end": "968000"
  },
  {
    "text": "workflow what do we do there are three",
    "start": "968000",
    "end": "970279"
  },
  {
    "text": "steps basically right the first step is",
    "start": "970279",
    "end": "972600"
  },
  {
    "text": "we prepare our data we take our feuture",
    "start": "972600",
    "end": "974839"
  },
  {
    "text": "vectors we fill in missing values we",
    "start": "974839",
    "end": "977399"
  },
  {
    "text": "want hard in COD categorical values and",
    "start": "977399",
    "end": "980519"
  },
  {
    "text": "maybe we normalize the range of the",
    "start": "980519",
    "end": "982720"
  },
  {
    "text": "continuous uh",
    "start": "982720",
    "end": "984399"
  },
  {
    "text": "features and then we split it into",
    "start": "984399",
    "end": "986480"
  },
  {
    "text": "training and test data sets maybe valid",
    "start": "986480",
    "end": "988680"
  },
  {
    "text": "ation set as well next we use our",
    "start": "988680",
    "end": "991800"
  },
  {
    "text": "favorite toolkit to specify and train a",
    "start": "991800",
    "end": "994240"
  },
  {
    "text": "model and then we evaluate and visualize",
    "start": "994240",
    "end": "997720"
  },
  {
    "text": "the results of our model predicting on a",
    "start": "997720",
    "end": "1001160"
  },
  {
    "text": "holdout data",
    "start": "1001160",
    "end": "1002600"
  },
  {
    "text": "set how does the graph machine learning",
    "start": "1002600",
    "end": "1005000"
  },
  {
    "text": "workflow differ it doesn't differ by",
    "start": "1005000",
    "end": "1007000"
  },
  {
    "text": "whole lot it still involves the same",
    "start": "1007000",
    "end": "1008920"
  },
  {
    "text": "three steps the only difference is that",
    "start": "1008920",
    "end": "1010839"
  },
  {
    "text": "when you specify in trainer model you",
    "start": "1010839",
    "end": "1012680"
  },
  {
    "text": "will use Telegraph and maybe a bit of",
    "start": "1012680",
    "end": "1016800"
  },
  {
    "text": "Caris so I'm not going to going to talk",
    "start": "1016959",
    "end": "1019480"
  },
  {
    "text": "about everything in detail because we",
    "start": "1019480",
    "end": "1020880"
  },
  {
    "text": "don't have the time I'm going to just",
    "start": "1020880",
    "end": "1022120"
  },
  {
    "text": "show you how to load the data assuming",
    "start": "1022120",
    "end": "1024038"
  },
  {
    "text": "you've prepared it already how to split",
    "start": "1024039",
    "end": "1026438"
  },
  {
    "text": "your data how to specify and train your",
    "start": "1026439",
    "end": "1028678"
  },
  {
    "text": "models and then how to evaluate it so",
    "start": "1028679",
    "end": "1032079"
  },
  {
    "text": "we're going to look at some code now not",
    "start": "1032079",
    "end": "1033880"
  },
  {
    "text": "a lot of it okay first of all we're",
    "start": "1033880",
    "end": "1036640"
  },
  {
    "text": "going to load the data we're going to do",
    "start": "1036640",
    "end": "1038400"
  },
  {
    "text": "it we need to do this in two steps first",
    "start": "1038400",
    "end": "1041038"
  },
  {
    "text": "of all we're going to use Network X and",
    "start": "1041039",
    "end": "1042600"
  },
  {
    "text": "we're going to load the graph structure",
    "start": "1042600",
    "end": "1044438"
  },
  {
    "text": "from an nlist file now n list file is",
    "start": "1044439",
    "end": "1047120"
  },
  {
    "text": "basically a two column CSV",
    "start": "1047120",
    "end": "1049240"
  },
  {
    "text": "every row lists the two node IDs that",
    "start": "1049240",
    "end": "1051919"
  },
  {
    "text": "are connected by",
    "start": "1051919",
    "end": "1053919"
  },
  {
    "text": "Nets next we're going to load our F",
    "start": "1053919",
    "end": "1056440"
  },
  {
    "text": "vectors for our nodes we're going to use",
    "start": "1056440",
    "end": "1058400"
  },
  {
    "text": "pandas for that we store the data again",
    "start": "1058400",
    "end": "1061600"
  },
  {
    "text": "in a CSV file and every row has an index",
    "start": "1061600",
    "end": "1065200"
  },
  {
    "text": "which is the node ID corresponding to",
    "start": "1065200",
    "end": "1066919"
  },
  {
    "text": "that particular feature vector and every",
    "start": "1066919",
    "end": "1069520"
  },
  {
    "text": "column is of course the features for",
    "start": "1069520",
    "end": "1071640"
  },
  {
    "text": "that",
    "start": "1071640",
    "end": "1072559"
  },
  {
    "text": "node this should be a column as well for",
    "start": "1072559",
    "end": "1075000"
  },
  {
    "text": "the Target values right because we know",
    "start": "1075000",
    "end": "1077320"
  },
  {
    "text": "you know 5,000 of the labels for our",
    "start": "1077320",
    "end": "1079159"
  },
  {
    "text": "Twitter data set once we've loaded our",
    "start": "1079159",
    "end": "1081520"
  },
  {
    "text": "data we have the structure and the",
    "start": "1081520",
    "end": "1083320"
  },
  {
    "text": "features we're going to create a Stell",
    "start": "1083320",
    "end": "1085480"
  },
  {
    "text": "graph",
    "start": "1085480",
    "end": "1086880"
  },
  {
    "text": "object what Stell graph object will do",
    "start": "1086880",
    "end": "1089240"
  },
  {
    "text": "is under the wood it's going to prepare",
    "start": "1089240",
    "end": "1091120"
  },
  {
    "text": "the data for graph machine",
    "start": "1091120",
    "end": "1093400"
  },
  {
    "text": "learning and lastly we're going to use",
    "start": "1093400",
    "end": "1095320"
  },
  {
    "text": "pit Len and we're going to split our",
    "start": "1095320",
    "end": "1097080"
  },
  {
    "text": "data into a training and test set",
    "start": "1097080",
    "end": "1099480"
  },
  {
    "text": "normally you would also have a",
    "start": "1099480",
    "end": "1100559"
  },
  {
    "text": "validation set I'm not going to s that",
    "start": "1100559",
    "end": "1102919"
  },
  {
    "text": "today now we've LED our data now we want",
    "start": "1102919",
    "end": "1105480"
  },
  {
    "text": "to specify our graph neural network",
    "start": "1105480",
    "end": "1107320"
  },
  {
    "text": "model",
    "start": "1107320",
    "end": "1109520"
  },
  {
    "text": "first thing let's try gcn with Stell",
    "start": "1109520",
    "end": "1113960"
  },
  {
    "text": "graph we're want to create a gcn object",
    "start": "1113960",
    "end": "1117600"
  },
  {
    "text": "and the first thing I'm going to do is",
    "start": "1117600",
    "end": "1118799"
  },
  {
    "text": "I'm going to specify the number of",
    "start": "1118799",
    "end": "1120200"
  },
  {
    "text": "layers I want I'm going to specify two",
    "start": "1120200",
    "end": "1122799"
  },
  {
    "text": "of them the first one we have 32 units",
    "start": "1122799",
    "end": "1126000"
  },
  {
    "text": "and the second one will have only one",
    "start": "1126000",
    "end": "1127600"
  },
  {
    "text": "unit and the activation functions is the",
    "start": "1127600",
    "end": "1129799"
  },
  {
    "text": "last parameter on that line it's going",
    "start": "1129799",
    "end": "1132880"
  },
  {
    "text": "to be U for the first layer and it's",
    "start": "1132880",
    "end": "1135840"
  },
  {
    "text": "going to be a sigmoid activation for the",
    "start": "1135840",
    "end": "1137400"
  },
  {
    "text": "second layer because that's the the",
    "start": "1137400",
    "end": "1138600"
  },
  {
    "text": "classification layer for us I'm going to",
    "start": "1138600",
    "end": "1141760"
  },
  {
    "text": "pull out the input and output tensors",
    "start": "1141760",
    "end": "1143799"
  },
  {
    "text": "from this object because I'm going to",
    "start": "1143799",
    "end": "1145240"
  },
  {
    "text": "use them later",
    "start": "1145240",
    "end": "1146760"
  },
  {
    "text": "on for graph Sage it looks very similar",
    "start": "1146760",
    "end": "1150039"
  },
  {
    "text": "I'm going to create a graph Sage object",
    "start": "1150039",
    "end": "1151919"
  },
  {
    "text": "I'm going to tell it I need two layers",
    "start": "1151919",
    "end": "1154400"
  },
  {
    "text": "two graph convolutional layers they're",
    "start": "1154400",
    "end": "1156640"
  },
  {
    "text": "going to have 32 units each and the",
    "start": "1156640",
    "end": "1158720"
  },
  {
    "text": "default for graph sage in our case is a",
    "start": "1158720",
    "end": "1161799"
  },
  {
    "text": "rue activation we're changing that so",
    "start": "1161799",
    "end": "1164400"
  },
  {
    "text": "you can specify your own",
    "start": "1164400",
    "end": "1166240"
  },
  {
    "text": "activation I'm going to pull out the",
    "start": "1166240",
    "end": "1168320"
  },
  {
    "text": "input and output potentials but I also",
    "start": "1168320",
    "end": "1169919"
  },
  {
    "text": "want to show you how Stellar graph",
    "start": "1169919",
    "end": "1172080"
  },
  {
    "text": "neural network layers can be combined",
    "start": "1172080",
    "end": "1174640"
  },
  {
    "text": "with caras layers so here I'm going to",
    "start": "1174640",
    "end": "1176799"
  },
  {
    "text": "tag a third layer which is going to be a",
    "start": "1176799",
    "end": "1178960"
  },
  {
    "text": "caras dense layer with one unit in a Sig",
    "start": "1178960",
    "end": "1181240"
  },
  {
    "text": "mode activation because that's going to",
    "start": "1181240",
    "end": "1182520"
  },
  {
    "text": "do the classification for",
    "start": "1182520",
    "end": "1184720"
  },
  {
    "text": "us the next thing I do is I go to kasas",
    "start": "1184720",
    "end": "1188000"
  },
  {
    "text": "I create a caras model I give it the",
    "start": "1188000",
    "end": "1190039"
  },
  {
    "text": "input and output tensors that I pulled",
    "start": "1190039",
    "end": "1191880"
  },
  {
    "text": "out of my gcn and graph stage models I'm",
    "start": "1191880",
    "end": "1194640"
  },
  {
    "text": "almost ready to go I just need to do one",
    "start": "1194640",
    "end": "1197120"
  },
  {
    "text": "more thing I need to",
    "start": "1197120",
    "end": "1200880"
  },
  {
    "text": "tell uh or I need an object that will",
    "start": "1200880",
    "end": "1203200"
  },
  {
    "text": "feed data to Caris when it's training so",
    "start": "1203200",
    "end": "1208320"
  },
  {
    "text": "I'm going to do it as follows gcn is a",
    "start": "1208320",
    "end": "1210120"
  },
  {
    "text": "full Parts method unfortunately and so",
    "start": "1210120",
    "end": "1213039"
  },
  {
    "text": "I'm going to create a stra FB node",
    "start": "1213039",
    "end": "1215120"
  },
  {
    "text": "generator I'm just going to give it my",
    "start": "1215120",
    "end": "1216720"
  },
  {
    "text": "staph object G that I created at the",
    "start": "1216720",
    "end": "1219159"
  },
  {
    "text": "very beginning when I was loading the",
    "start": "1219159",
    "end": "1220760"
  },
  {
    "text": "data because the the the generator needs",
    "start": "1220760",
    "end": "1224320"
  },
  {
    "text": "to know about the",
    "start": "1224320",
    "end": "1226440"
  },
  {
    "text": "graph and then I'm going to call the",
    "start": "1226440",
    "end": "1228559"
  },
  {
    "text": "flow method to tell it to specify what",
    "start": "1228559",
    "end": "1232240"
  },
  {
    "text": "the training data are which note it is I",
    "start": "1232240",
    "end": "1234320"
  },
  {
    "text": "have labels for and what is the the the",
    "start": "1234320",
    "end": "1237360"
  },
  {
    "text": "test",
    "start": "1237360",
    "end": "1238679"
  },
  {
    "text": "set for graph",
    "start": "1238679",
    "end": "1240720"
  },
  {
    "text": "setes which is for which we can use mini",
    "start": "1240720",
    "end": "1244240"
  },
  {
    "text": "grad in",
    "start": "1244240",
    "end": "1245840"
  },
  {
    "text": "descent I'm going to create a graph",
    "start": "1245840",
    "end": "1248039"
  },
  {
    "text": "sides node generator and I'm going going",
    "start": "1248039",
    "end": "1250799"
  },
  {
    "text": "to specify the B sides and I'm going to",
    "start": "1250799",
    "end": "1253440"
  },
  {
    "text": "specify the number of sampol for each",
    "start": "1253440",
    "end": "1256159"
  },
  {
    "text": "layer now the number of sampol is the",
    "start": "1256159",
    "end": "1258799"
  },
  {
    "text": "size of the neighborhood for its layer",
    "start": "1258799",
    "end": "1260640"
  },
  {
    "text": "so in this example I'm saying that for",
    "start": "1260640",
    "end": "1262360"
  },
  {
    "text": "my first layer I'm going to sample 20",
    "start": "1262360",
    "end": "1265200"
  },
  {
    "text": "neighbors for its node and for my second",
    "start": "1265200",
    "end": "1267080"
  },
  {
    "text": "layer because I had a two- layer model",
    "start": "1267080",
    "end": "1268799"
  },
  {
    "text": "I'm going to assemble 10 labels now the",
    "start": "1268799",
    "end": "1270880"
  },
  {
    "text": "assembling is done",
    "start": "1270880",
    "end": "1272520"
  },
  {
    "text": "uniformly um at random with",
    "start": "1272520",
    "end": "1276320"
  },
  {
    "text": "replacement and I'm going to call the",
    "start": "1276320",
    "end": "1278120"
  },
  {
    "text": "flow function to specify what my",
    "start": "1278120",
    "end": "1279760"
  },
  {
    "text": "training data are and now I can go back",
    "start": "1279760",
    "end": "1282480"
  },
  {
    "text": "to Caris I can compile my model I can",
    "start": "1282480",
    "end": "1285600"
  },
  {
    "text": "choose an Optimizer and a loss function",
    "start": "1285600",
    "end": "1288480"
  },
  {
    "text": "and then I can call fit generator to",
    "start": "1288480",
    "end": "1291120"
  },
  {
    "text": "train my motel for 200 epochs in that in",
    "start": "1291120",
    "end": "1294120"
  },
  {
    "text": "this",
    "start": "1294120",
    "end": "1296320"
  },
  {
    "text": "example next I can I can use caras",
    "start": "1296919",
    "end": "1300640"
  },
  {
    "text": "predict generator or evaluate generator",
    "start": "1300640",
    "end": "1303200"
  },
  {
    "text": "or pyit L routines to evaluate my model",
    "start": "1303200",
    "end": "1306720"
  },
  {
    "text": "on my test set and here I'm showing the",
    "start": "1306720",
    "end": "1310120"
  },
  {
    "text": "receiver operating characteristic CES",
    "start": "1310120",
    "end": "1311640"
  },
  {
    "text": "for gcn and graph States and the",
    "start": "1311640",
    "end": "1313320"
  },
  {
    "text": "confusion tables you can see from the RC",
    "start": "1313320",
    "end": "1316279"
  },
  {
    "text": "curves that there isn't much difference",
    "start": "1316279",
    "end": "1317600"
  },
  {
    "text": "between the two algorithms they both get",
    "start": "1317600",
    "end": "1319640"
  },
  {
    "text": "the same area under the curve but if you",
    "start": "1319640",
    "end": "1321480"
  },
  {
    "text": "look closely at the confusion tables you",
    "start": "1321480",
    "end": "1323880"
  },
  {
    "text": "can tell that you can see that for",
    "start": "1323880",
    "end": "1326240"
  },
  {
    "text": "example um gcn has a larger number of uh",
    "start": "1326240",
    "end": "1330840"
  },
  {
    "text": "false positives so if you don't want to",
    "start": "1330840",
    "end": "1333080"
  },
  {
    "text": "go around you know um accusing the wrong",
    "start": "1333080",
    "end": "1335840"
  },
  {
    "text": "people then um it's better to use graph",
    "start": "1335840",
    "end": "1339200"
  },
  {
    "text": "stage but it's not just that graph stage",
    "start": "1339200",
    "end": "1340720"
  },
  {
    "text": "is more scalable right so it's good that",
    "start": "1340720",
    "end": "1343320"
  },
  {
    "text": "it performs just as well as gcn which is",
    "start": "1343320",
    "end": "1345559"
  },
  {
    "text": "a very very strong Baseline for graph",
    "start": "1345559",
    "end": "1347679"
  },
  {
    "text": "neuron Network",
    "start": "1347679",
    "end": "1350399"
  },
  {
    "text": "research right so um I'm coming to the",
    "start": "1352159",
    "end": "1355799"
  },
  {
    "text": "end of my talk I'm just going to talk a",
    "start": "1355799",
    "end": "1357480"
  },
  {
    "text": "little bit about the challenges behind",
    "start": "1357480",
    "end": "1359880"
  },
  {
    "text": "developing this",
    "start": "1359880",
    "end": "1362000"
  },
  {
    "text": "Library one of these challenges have to",
    "start": "1362000",
    "end": "1364159"
  },
  {
    "text": "do with how quickly the um the machine",
    "start": "1364159",
    "end": "1368080"
  },
  {
    "text": "learning discipline craft machine",
    "start": "1368080",
    "end": "1369520"
  },
  {
    "text": "learning is actually moving forward like",
    "start": "1369520",
    "end": "1372279"
  },
  {
    "text": "I said the two main algorithms I",
    "start": "1372279",
    "end": "1373799"
  },
  {
    "text": "presented they're only like 2 years old",
    "start": "1373799",
    "end": "1376080"
  },
  {
    "text": "if not less and the there is new work",
    "start": "1376080",
    "end": "1378880"
  },
  {
    "text": "being published almost on a weekly basis",
    "start": "1378880",
    "end": "1380760"
  },
  {
    "text": "especially these days with the open-",
    "start": "1380760",
    "end": "1382559"
  },
  {
    "text": "source publishing um that's very common",
    "start": "1382559",
    "end": "1384960"
  },
  {
    "text": "in in academic",
    "start": "1384960",
    "end": "1386480"
  },
  {
    "text": "circles so it's very difficult for us",
    "start": "1386480",
    "end": "1388720"
  },
  {
    "text": "because we have to sort through all",
    "start": "1388720",
    "end": "1390080"
  },
  {
    "text": "these papers to figure out what are the",
    "start": "1390080",
    "end": "1392320"
  },
  {
    "text": "good contributions what are good",
    "start": "1392320",
    "end": "1394000"
  },
  {
    "text": "algorithms that we need to add to the",
    "start": "1394000",
    "end": "1395360"
  },
  {
    "text": "library in order to help our users to do",
    "start": "1395360",
    "end": "1397880"
  },
  {
    "text": "the best they can do we're very lucky at",
    "start": "1397880",
    "end": "1400520"
  },
  {
    "text": "data 61 we have access to some of the",
    "start": "1400520",
    "end": "1402919"
  },
  {
    "text": "world's top machine learning researchers",
    "start": "1402919",
    "end": "1405440"
  },
  {
    "text": "and they're all very friendly and we can",
    "start": "1405440",
    "end": "1407000"
  },
  {
    "text": "always go and talk to to them about you",
    "start": "1407000",
    "end": "1408919"
  },
  {
    "text": "know what she will be paying attention",
    "start": "1408919",
    "end": "1411120"
  },
  {
    "text": "to some other",
    "start": "1411120",
    "end": "1413640"
  },
  {
    "text": "challenges uh it's a lot about",
    "start": "1413640",
    "end": "1415440"
  },
  {
    "text": "trade-offs when you built these",
    "start": "1415440",
    "end": "1416559"
  },
  {
    "text": "libraries we",
    "start": "1416559",
    "end": "1418440"
  },
  {
    "text": "found for example we had to make a",
    "start": "1418440",
    "end": "1420960"
  },
  {
    "text": "decision between should we Implement as",
    "start": "1420960",
    "end": "1423480"
  },
  {
    "text": "many algorithms as possible or so we",
    "start": "1423480",
    "end": "1426559"
  },
  {
    "text": "Implement a small subset of good",
    "start": "1426559",
    "end": "1428240"
  },
  {
    "text": "algorithms and make sure that they're",
    "start": "1428240",
    "end": "1430159"
  },
  {
    "text": "implemented correctly so we chose to go",
    "start": "1430159",
    "end": "1432919"
  },
  {
    "text": "with a small number of algorithms",
    "start": "1432919",
    "end": "1434279"
  },
  {
    "text": "implemented",
    "start": "1434279",
    "end": "1436159"
  },
  {
    "text": "correctly another trade of has to do",
    "start": "1436159",
    "end": "1438400"
  },
  {
    "text": "with training speed and memory usage",
    "start": "1438400",
    "end": "1441039"
  },
  {
    "text": "versus consistency of the API so we've",
    "start": "1441039",
    "end": "1443960"
  },
  {
    "text": "decided to go with consistency of the",
    "start": "1443960",
    "end": "1446000"
  },
  {
    "text": "API so we make sure that that you can",
    "start": "1446000",
    "end": "1448799"
  },
  {
    "text": "switch you can replace one model with",
    "start": "1448799",
    "end": "1451039"
  },
  {
    "text": "another you change a few lines of code",
    "start": "1451039",
    "end": "1452559"
  },
  {
    "text": "now you're training gcn now you training",
    "start": "1452559",
    "end": "1454320"
  },
  {
    "text": "graph say now you're training a",
    "start": "1454320",
    "end": "1455840"
  },
  {
    "text": "different model without having to",
    "start": "1455840",
    "end": "1457400"
  },
  {
    "text": "rewrite your",
    "start": "1457400",
    "end": "1460159"
  },
  {
    "text": "scripts um speed of training and memory",
    "start": "1460200",
    "end": "1462480"
  },
  {
    "text": "optimization is actually coming up for",
    "start": "1462480",
    "end": "1464159"
  },
  {
    "text": "our next major release so we haven't",
    "start": "1464159",
    "end": "1465880"
  },
  {
    "text": "forgotten about that we're very much",
    "start": "1465880",
    "end": "1467840"
  },
  {
    "text": "interested in making it the fastest",
    "start": "1467840",
    "end": "1469360"
  },
  {
    "text": "Library out",
    "start": "1469360",
    "end": "1470679"
  },
  {
    "text": "there another challenge is about",
    "start": "1470679",
    "end": "1472720"
  },
  {
    "text": "selecting the audience we had to choose",
    "start": "1472720",
    "end": "1475320"
  },
  {
    "text": "between targeting academic researchers",
    "start": "1475320",
    "end": "1478159"
  },
  {
    "text": "who are very much interested in this or",
    "start": "1478159",
    "end": "1481279"
  },
  {
    "text": "practitioners data scientists and",
    "start": "1481279",
    "end": "1483039"
  },
  {
    "text": "machine learning Engineers so we decided",
    "start": "1483039",
    "end": "1485279"
  },
  {
    "text": "to go to to focus on on you guys the",
    "start": "1485279",
    "end": "1488640"
  },
  {
    "text": "practitioners we want you to want to",
    "start": "1488640",
    "end": "1491799"
  },
  {
    "text": "help you um get insight from your",
    "start": "1491799",
    "end": "1494799"
  },
  {
    "text": "connected data as easily as possible",
    "start": "1494799",
    "end": "1498679"
  },
  {
    "text": "so in conclusion you know Stell graph is",
    "start": "1498679",
    "end": "1501080"
  },
  {
    "text": "a lot more than the two algorithms I",
    "start": "1501080",
    "end": "1502760"
  },
  {
    "text": "mentioned we have many many other graph",
    "start": "1502760",
    "end": "1506039"
  },
  {
    "text": "no network algorithms one's based uh on",
    "start": "1506039",
    "end": "1508799"
  },
  {
    "text": "random walks we have algorithms using",
    "start": "1508799",
    "end": "1511279"
  },
  {
    "text": "attenion mechanisms um we have",
    "start": "1511279",
    "end": "1514600"
  },
  {
    "text": "probabilistic models embl",
    "start": "1514600",
    "end": "1517840"
  },
  {
    "text": "um and uh algorithms for working with",
    "start": "1517840",
    "end": "1520919"
  },
  {
    "text": "heterogeneous networks you can find this",
    "start": "1520919",
    "end": "1523520"
  },
  {
    "text": "on GitHub or on github.com Telegraph",
    "start": "1523520",
    "end": "1526679"
  },
  {
    "text": "Telegraph and our team is expanding so",
    "start": "1526679",
    "end": "1529640"
  },
  {
    "text": "if you're on the job market and if you",
    "start": "1529640",
    "end": "1531120"
  },
  {
    "text": "find any of this interesting we're",
    "start": "1531120",
    "end": "1532360"
  },
  {
    "text": "hiring all across the board from",
    "start": "1532360",
    "end": "1533600"
  },
  {
    "text": "software Engineers data scientists data",
    "start": "1533600",
    "end": "1535559"
  },
  {
    "text": "engineers and machine learning",
    "start": "1535559",
    "end": "1538760"
  },
  {
    "text": "Engineers thank you very much for",
    "start": "1538760",
    "end": "1541000"
  },
  {
    "text": "listening to",
    "start": "1541000",
    "end": "1542530"
  },
  {
    "text": "[Applause]",
    "start": "1542530",
    "end": "1548919"
  },
  {
    "text": "me",
    "start": "1548919",
    "end": "1551919"
  }
]
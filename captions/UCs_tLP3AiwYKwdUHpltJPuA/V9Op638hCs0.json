[
  {
    "start": "0",
    "end": "104000"
  },
  {
    "text": "Hello, and welcome to another GOTO Unscripted \nseries video. It’s weird to say hello to the show  ",
    "start": "14040",
    "end": "22640"
  },
  {
    "text": "that I never hosted before. But here I am. My name \nis Marcia Villalba, developer advocate for AWS  ",
    "start": "22640",
    "end": "29640"
  },
  {
    "text": "at the Serverless team. And I’m joined by...\nHello, I'm Julian Wood. And Marcia and I are  ",
    "start": "29640",
    "end": "35720"
  },
  {
    "text": "actually on the same team, so we sort of do \nthe same things, although we have different   specialties. Marcia, it is always lovely \nto talk to you, and I love that your intro,  ",
    "start": "35720",
    "end": "42720"
  },
  {
    "text": "even for your own podcast and your own \nYouTube channel, transcends over here   to GOTO Unscripted. So it's super cool.\nI cannot avoid, introducing things is my... ",
    "start": "42720",
    "end": "51239"
  },
  {
    "text": "Absolutely.\nI have to say hello   to people. So today we have a really cool topic \nbecause I don't know, maybe people reading the  ",
    "start": "51240",
    "end": "61640"
  },
  {
    "text": "description of this video, like how many buzzwords \nyou can put in a sentence, functions/containers,  ",
    "start": "61640",
    "end": "69560"
  },
  {
    "text": "containers and functions. And it's like, \nhow is that possible? Are they not kind of  ",
    "start": "69560",
    "end": "75399"
  },
  {
    "text": "the same thing? Well, I have heard about these \nopen-source functions that you can run yourself,  ",
    "start": "75400",
    "end": "85480"
  },
  {
    "text": "are we talking about that? What is \nit that we are going to talk today? ",
    "start": "85480",
    "end": "90360"
  },
  {
    "text": "Well, we need to put more buzzwords in just for \nthe title. So we'll say gen AI a few times, and   then we'll do gen AI functions and containers, and \nthen we're covered. So, we have all the buzzwords. ",
    "start": "91480",
    "end": "100160"
  },
  {
    "text": "Cryptocurrency.\nOh, nice one. I like   it. So this is an interesting topic to talk \nabout because, you know, people always think  ",
    "start": "100160",
    "end": "108760"
  },
  {
    "start": "104000",
    "end": "333000"
  },
  {
    "text": "that there's some sort of philosophical, technical \nwhatever, either or debate between whether you can  ",
    "start": "108760",
    "end": "115760"
  },
  {
    "text": "use functions or whether you can use containers.\nAnd obviously, this is complicated because the  ",
    "start": "115760",
    "end": "123040"
  },
  {
    "text": "word containers, let me get my quotes on the \nscreen, is a broad term which encompasses  ",
    "start": "123040",
    "end": "128280"
  },
  {
    "text": "a whole bunch of different things. And \na container can be a packaging format,   so it's a way that you can put a whole bunch of \nfiles together basically. Containers can also  ",
    "start": "128280",
    "end": "138000"
  },
  {
    "text": "be a distribution mechanism because it's a way \nthat you can have something that runs on your   machine and runs on another set of machines in the \ncloud, on-premises, anywhere, that kind of thing. ",
    "start": "138000",
    "end": "147800"
  },
  {
    "text": "Then containerization can also be the sort of \nconcept of, oh, well, we containerizing things.  ",
    "start": "147800",
    "end": "153400"
  },
  {
    "text": "We are making them a little bit smaller, \na little bit more agile maybe. Maybe it's   a similar sort of concept to microservices. So a \nlot of different things that containers are, and  ",
    "start": "153400",
    "end": "162520"
  },
  {
    "text": "sometimes people can come at it from a different \nangle, and so, you know, they may get confused. ",
    "start": "162520",
    "end": "168240"
  },
  {
    "text": "But the big picture is that when we talk about \nserverless, when serverless sort of came on the   scene, about sort of 10-ish years ago, it was \nall about functions as a service. Well, mainly  ",
    "start": "168240",
    "end": "177360"
  },
  {
    "text": "about functions as a service where you just upload \nyour code somewhere and it would just run right at  ",
    "start": "177360",
    "end": "182640"
  },
  {
    "text": "whatever scale, it would just run and somebody \nwould take care of running that for you, scaling   it, and, you know, updating it, and securing \nsome of it and all, all that kind of things. ",
    "start": "182640",
    "end": "191800"
  },
  {
    "text": "Now, obviously, the term serverless has \nevolved since then because it's not just   functions as a service, but it's a whole sort \nof suite of databases, and messaging services,  ",
    "start": "191800",
    "end": "200640"
  },
  {
    "text": "and orchestration systems that can do anything \nthat sort of takes away that undifferentiated   heavy lifting, we talk about it at AWS, \nwhere you just get to run your service  ",
    "start": "200640",
    "end": "210520"
  },
  {
    "text": "over the internet and we'll take care of a \nlot of the sort of grunt work underneath so   you can just focus on your, on your application.\nAnd so we had functions and then we had containers  ",
    "start": "210520",
    "end": "220800"
  },
  {
    "text": "that you could always run. And a lot of companies \nwere doing either lifts and shifts or they were   doing microservices and they were, you know, \ncontainerizing their applications and scheduling…",
    "start": "220800",
    "end": "229100"
  },
  {
    "text": "When we talk about functions, at least in the \nearly beginnings, we always show these graphs that   was, like, physical machines, virtual machines, \ncontainers, functions, and now we are like,  ",
    "start": "229100",
    "end": "239720"
  },
  {
    "text": "how we put these things together?\nI think the sort of idea of that was   possibly good to show how the sort of evolution of \nthings could be, but it's not necessarily that the  ",
    "start": "240560",
    "end": "251480"
  },
  {
    "text": "evolution has to be that you have to migrate from \na container to a function, it's just a different  ",
    "start": "251480",
    "end": "256519"
  },
  {
    "text": "way of running code and, you know, running \nactual containers, whether that's, you know,  ",
    "start": "256520",
    "end": "261759"
  },
  {
    "text": "within AWS unit, that's a way for running a \nfull running container that can run for hours,   forever, in fact. And, yeah, it's a really great \nway to also run applications and functions... ",
    "start": "265240",
    "end": "274672"
  },
  {
    "text": "I think we can go back to the definition of what a \nfunction is and what a container is. I think it's  ",
    "start": "274672",
    "end": "280080"
  },
  {
    "text": "very important what you said at the beginning, \nthe different layers of what a container can be.   Because in this case of functions, what \nwe are talking is about the packaging,  ",
    "start": "280080",
    "end": "288960"
  },
  {
    "text": "the container image, and then we have the \nway of running the container. And that's   what we wanted to graph in that typical graph of \nphysical machines, virtual machines, containers,  ",
    "start": "288960",
    "end": "299400"
  },
  {
    "text": "and functions is where is the responsibility \nand what is the abstraction layer? Now,   what we are going to say, \"Well, now, you can put \nyour container image the same that you put in your  ",
    "start": "299400",
    "end": "308759"
  },
  {
    "text": "ECS or whatever you're using into Lambda.\"\nBasically, the premise is you can build a  ",
    "start": "308760",
    "end": "317200"
  },
  {
    "text": "function from a container image, and the \nworld's like, \"Hang on, hang on, hang on,   what are you talking about?\" That's the confusing \nthing we're trying to tease apart today and sort  ",
    "start": "317200",
    "end": "326960"
  },
  {
    "text": "of help people understand why it can be useful \nand some of the trade-offs that you need to do.",
    "start": "326960",
    "end": "332680"
  },
  {
    "start": "333000",
    "end": "685000"
  },
  {
    "text": "Now we clarify a little bit what we are \ngoing to focus running container images  ",
    "start": "333640",
    "end": "339840"
  },
  {
    "text": "in functions, in serverless functions. \nSo that's the TLDR of this, but why? ",
    "start": "339840",
    "end": "351199"
  },
  {
    "text": "Well, the why is good in a way, because why \nnot? And that may sound a little bit silly,  ",
    "start": "351200",
    "end": "358920"
  },
  {
    "text": "but the whole container ecosystem has gone \nwild over the past 10 years and for really  ",
    "start": "358920",
    "end": "365400"
  },
  {
    "text": "good reasons because containers, when we are \ntalking about the packaging format, the way you  ",
    "start": "365400",
    "end": "370680"
  },
  {
    "text": "can put things together is a standard that so many \ndifferent kind of things use. And so the benefits  ",
    "start": "370680",
    "end": "376199"
  },
  {
    "text": "of using a container image is that there's \nso many tools, and there's so many packaging  ",
    "start": "376200",
    "end": "381280"
  },
  {
    "text": "ways, and there's so many scanning utilities \nand just so many developers know how to package  ",
    "start": "381280",
    "end": "386760"
  },
  {
    "text": "applications in a container. And so let's a...\nAnd you can run it in your local machine. ",
    "start": "386760",
    "end": "391760"
  },
  {
    "text": "That's when we were talking about the portability \nearlier, that is really cool that you can,   you know, test and run something on your Mac \nor your Windows machine. And even on Windows,  ",
    "start": "393760",
    "end": "402880"
  },
  {
    "text": "if it's gonna be deployed on a, you know, Linux \nOS with another chipset in another cloud provider,  ",
    "start": "402880",
    "end": "408320"
  },
  {
    "text": "you know, you can have this sort of confidence \nthat your packaging format can be useful.  And so what Lambda introduced, I \nthink it's about three years ago now,  ",
    "start": "408320",
    "end": "416520"
  },
  {
    "text": "is previously Lambda, you had to take all \nthe files that was your code and you had   to zip it up and you had to upload it to the \ncloud, to the Lambda service. It would store  ",
    "start": "416520",
    "end": "425280"
  },
  {
    "text": "it in S3, some object storage that's a \nbit behind the scenes. And basically,   when the function ran, it would just copy that \ncode down and run your function, pretty simple. ",
    "start": "425280",
    "end": "432960"
  },
  {
    "text": "But people were saying, \"Well, hang on, why do I \nhave to have different tooling for Lambda?\" Or,   \"I'm using containers to build a whole bunch \nof other services, can't I just use containers  ",
    "start": "432960",
    "end": "443240"
  },
  {
    "text": "to build Lambda functions?\" So Lambda came out \nwith what's called sort of OCI image supports,  ",
    "start": "443240",
    "end": "448680"
  },
  {
    "text": "and so an OCI image is the industry \nstandard to build a container image. ",
    "start": "448680",
    "end": "455320"
  },
  {
    "text": "If you've worked in containers at all, \nI'm sure you've done Docker files,   but a Docker file is a way of doing a container \nimage, and that's Docker's implementation,  ",
    "start": "455320",
    "end": "463759"
  },
  {
    "text": "but it's using the OCI spec under the hood, but \nthere are other container runtimes, which also use   the OCI spec. So anyway, what Lambda came out \nwas instead of having to zip your package up,  ",
    "start": "463760",
    "end": "473200"
  },
  {
    "text": "you could just use a Docker file to specify \nwhat is going to be in your Lambda function,   and you could build in Lambda function with that.\nWe're talking about some of the benefits,  ",
    "start": "473200",
    "end": "481440"
  },
  {
    "text": "we're talking about some of the tools using \nyour tooling, using your Docker CLI on your   laptop or wherever to do it. Another one is \nportability. Well, as you mentioned before,  ",
    "start": "481440",
    "end": "491120"
  },
  {
    "text": "if you've got a function that is some code that \nis running somewhere, you can now port that to  ",
    "start": "491120",
    "end": "496479"
  },
  {
    "text": "Lambda or use some of the functionality within \nLambda much easier. And then some other sort of  ",
    "start": "496480",
    "end": "502600"
  },
  {
    "text": "useful use cases was larger artifacts. So one of \nthe constraints with Lambda is you can only have  ",
    "start": "502600",
    "end": "509840"
  },
  {
    "text": "zip files that are 256 meg, with container \nimages that is now up to 10 gig. And there's  ",
    "start": "509840",
    "end": "515159"
  },
  {
    "text": "a whole bunch of cool technology \nwe're gonna get in to make it happen.  We'll get into that because that's very magical.\nMost definitely. Oh, I love it. Love it. That is  ",
    "start": "515160",
    "end": "521360"
  },
  {
    "text": "so cool. So you can build Lambda functions \nup to 10 gig. So that means, you know,   huge binaries that you need to put in, or even \nmachine learning models or, you know, the... ",
    "start": "521360",
    "end": "531519"
  },
  {
    "text": "That was a huge constraint for a lot of our \ncustomers that they were like, \"Well, I have so  ",
    "start": "531520",
    "end": "536600"
  },
  {
    "text": "many dependencies, I have so many things. And even \nif you use Lambda layers, when you are running  ",
    "start": "536600",
    "end": "542600"
  },
  {
    "text": "your functions in traditional where you're still \nlimited to that deployment package size.\" Well,  ",
    "start": "542600",
    "end": "548680"
  },
  {
    "text": "there is many reasons for why the package size is \nsmall but with containers, it seems that we have  ",
    "start": "548680",
    "end": "555480"
  },
  {
    "text": "done some magic and we have broke that in some \nway, we'll talk that later so don't tune out, and  ",
    "start": "555480",
    "end": "564959"
  },
  {
    "text": "we can put 10 gigabytes. So that's, I think, one \nof the biggest things besides we already know how  ",
    "start": "564960",
    "end": "570360"
  },
  {
    "text": "to use containers, now we can put bigger things.\nAnd I think another big one that at least I  ",
    "start": "570360",
    "end": "576120"
  },
  {
    "text": "heard from customers is the immutability and the \ncontrol that they have on their images. Because,  ",
    "start": "576120",
    "end": "583160"
  },
  {
    "text": "well, if you use Lambda the vanilla \nway, the traditional way, let's call it,  ",
    "start": "583160",
    "end": "590160"
  },
  {
    "text": "you are basically using whatever we provide, the \nruntime we provide, but maybe sometimes you need  ",
    "start": "590160",
    "end": "596240"
  },
  {
    "text": "your own images, you need your own run times, \nyou need your own whatever because you have  ",
    "start": "596240",
    "end": "602520"
  },
  {
    "text": "so many constraints in your organization. \nAnd if you use the container image support,  ",
    "start": "602520",
    "end": "608600"
  },
  {
    "text": "then you can bring all that into the play and \nthat's also very important for many organizations. ",
    "start": "608600",
    "end": "615199"
  },
  {
    "text": "So that's when you talk about the \npackaging format and, you know,   the power of a container is a packaging format \nbecause, by default, one of the awesome things  ",
    "start": "615200",
    "end": "623120"
  },
  {
    "text": "about Lambda is it just automatically patches \nitself, the operating system and, you know,   if using Python or Node or Java, you know, the \nminor version of Java, Node, or Python just gets  ",
    "start": "623120",
    "end": "633000"
  },
  {
    "text": "automatically upgraded. Literally every time you \nrun your function, it's making sure it's got the   latest and greatest. And that is fantastic because \nit means you don't have to do that work yourself. ",
    "start": "633000",
    "end": "641399"
  },
  {
    "text": "But for some customers they're like, \"Hang on, \nthis means if I do have a library which suddenly  ",
    "start": "641400",
    "end": "646920"
  },
  {
    "text": "has an incompatibility now, but stuck because \nsomething just broke and I didn't make any code  ",
    "start": "646920",
    "end": "652800"
  },
  {
    "text": "changes,\" or, you know, \"Lambda functions run on \nAmazon Linux, previously Amazon Linux 2, and now  ",
    "start": "652800",
    "end": "658800"
  },
  {
    "text": "Amazon Linux 2023, and my company uses Ubuntu or \nAlpine or some other, you know, Debian, or Red  ",
    "start": "658800",
    "end": "666640"
  },
  {
    "text": "Hat, or anything, some other Linux distro, I don't \nreally wanna have to use something different for   Lambda because all my processes and everything are \nset up to use this other Linux distro.\" And so,  ",
    "start": "666640",
    "end": "677160"
  },
  {
    "text": "as with a Docker file, with a Lambda function \nand container image support, it means you can   actually bring your own runtime and bring your \nown operating system and that is super powerful.",
    "start": "677160",
    "end": "685560"
  },
  {
    "start": "685000",
    "end": "838000"
  },
  {
    "text": "I have heard stories of people running \ncobalt Lambda functions in these type of   scenarios. So when we mean bring your own \nruntime, we mean bring your own runtime ",
    "start": "685560",
    "end": "695640"
  },
  {
    "text": "That's one of the powerful features of Lambda. \nThere's a way that you can use customer runtime.   So, yes, we have no Java, Python, Go, all these \nmanaged runtime. But, yeah, there are the custom  ",
    "start": "697000",
    "end": "706760"
  },
  {
    "text": "run times, which custom run times is also a bit \nof a funny term because custom means, oh, we've  ",
    "start": "706760",
    "end": "711880"
  },
  {
    "text": "customized the runtime. It basically is an OS-only \nruntime. So it's an operating system, and then you   have the flexibility to build whatever you want \non top of it. And so, yeah, that gives a lot of  ",
    "start": "711880",
    "end": "721000"
  },
  {
    "text": "a lot of flexibility that you can do anything.\nBut also in the other hand, it's not that you   can bring your own things, but you can also use \nall the base images that Lambda provides. So if  ",
    "start": "721560",
    "end": "731200"
  },
  {
    "text": "you don't need any custom runtime or anything \nweird, you want to use what Lambda provides,  ",
    "start": "731200",
    "end": "736400"
  },
  {
    "text": "just go grab the base image for \nthe runtime. You'll have like...  All the goodies there.\n...all the goodies. No  ",
    "start": "736400",
    "end": "742920"
  },
  {
    "text": "need to stress because that's also what I love \nfrom Lambda, that is simple and I don't need to  ",
    "start": "742920",
    "end": "749200"
  },
  {
    "text": "reconfigure the word in order to get started. \nSo there is a lot of customization possible,  ",
    "start": "749200",
    "end": "754600"
  },
  {
    "text": "but also the ease for the ones that don't \nneed that much level of customization.  Literally the first line in your Docker file is \nwhen I'm starting my Docker file, or when I'm  ",
    "start": "754600",
    "end": "762920"
  },
  {
    "text": "starting my container image for Lambda, please, \nLambda service can I have the base image, which  ",
    "start": "762920",
    "end": "769040"
  },
  {
    "text": "contains Node or Python or Java, whatever? That \nkind of thing. And so Lambda creates these base   images, which are publicly available on Docker \nHub and Elastic Container Registry. And say,  ",
    "start": "769040",
    "end": "779199"
  },
  {
    "text": "\"You're not starting from scratch,\" you just say, \n\"I want the Lambda image,\" and that's got all the   Lambda-specific code in it as well. So your \ncode as you used before, can run exactly the  ",
    "start": "779200",
    "end": "787600"
  },
  {
    "text": "same as it is, yeah, it makes it really easy \nto get started with building your functions.   You're not just starting from an operating \nsystem and have to craft everything yourself. ",
    "start": "787600",
    "end": "795560"
  },
  {
    "text": "So when we should not use containers \nbecause these are lovely, but... ",
    "start": "795560",
    "end": "802000"
  },
  {
    "text": "Containers are lovely, but I think some of the \nchallenge is people get to, when they think  ",
    "start": "802560",
    "end": "807640"
  },
  {
    "text": "about containers with Lambda, is that original \npoint making about what a container is. Because  ",
    "start": "807640",
    "end": "813080"
  },
  {
    "text": "people think, \"Oh, I'm just running a container \nin Lambda. Any container in Lambda,\" that's not   entirely true. It needs to be a container \nthat Lambda works with or that supports,  ",
    "start": "813080",
    "end": "823600"
  },
  {
    "text": "that can work with Lambda because Lambda \nis an event-driven application construct   and architecture, your container needs to be able \nto support that. An event-driven basically means  ",
    "start": "823600",
    "end": "833200"
  },
  {
    "text": "there's an event that comes in, your code does \nsome processing and then returns the results. So maybe here we can stop for a second and talk \na little bit on how we define this connection  ",
    "start": "833200",
    "end": "844480"
  },
  {
    "start": "838000",
    "end": "1128000"
  },
  {
    "text": "because in the vanilla Lambda scenario, we \nhave our infrastructure and we say, \"Hey,  ",
    "start": "844480",
    "end": "851480"
  },
  {
    "text": "the input, the function that we are going \nto start is in this file, in this method,  ",
    "start": "851480",
    "end": "856600"
  },
  {
    "text": "go from there.\" And then we have our handler file \nthat has that method that will start the whole  ",
    "start": "856600",
    "end": "863600"
  },
  {
    "text": "function and that's the event-driven part that we \nlove from Lambda. How do we do that in containers,  ",
    "start": "863600",
    "end": "870600"
  },
  {
    "text": "so we need to change the code? How will it work?\nYou don't actually need to change your code,   if you are using the manage run times and \nyou're just pulling that image layer down,  ",
    "start": "870600",
    "end": "879080"
  },
  {
    "text": "your code doesn't need to change at all. And \nyou're just setting up basically a configuration   option for your Lambda function, which can \neither be within the Docker file or it's  ",
    "start": "879080",
    "end": "888720"
  },
  {
    "text": "just gonna use the defaults for Lambda.\nSo say you're using a Python function,   if you're using the Python-managed container image \nlayer, you just write your code and you don't have  ",
    "start": "888720",
    "end": "899440"
  },
  {
    "text": "to do anything. But what you can't actually \nalso do is specify, well, actually make sure   that my handler is this file and this function \nwithin that file, and then off you can go. ",
    "start": "899440",
    "end": "909520"
  },
  {
    "text": "And lots of people use that, not just for a \nsingle function, but sometimes they're gonna   have multiple Python functions within a Lambda \nfunction, just to confuse that kind of thing. And  ",
    "start": "909520",
    "end": "916120"
  },
  {
    "text": "so you can have the same file artifact or the same \ncontainer artifact, and then go into different  ",
    "start": "916120",
    "end": "921240"
  },
  {
    "text": "functions depending on your handler set. So, yeah, \ndifferent ways to configure it. You can either   configure it within the configuration of your \nLambda function or set it within your Docker file. ",
    "start": "921240",
    "end": "932040"
  },
  {
    "text": "But is the same idea. So when you have \nyour application in a container image,  ",
    "start": "932040",
    "end": "937639"
  },
  {
    "text": "you still need to tell Lambda what is the input, \nthe starting point of that function. So, well,  ",
    "start": "937640",
    "end": "944280"
  },
  {
    "text": "we do that also for any kind of application \nwe need to tell the server where to start.  ",
    "start": "944280",
    "end": "949360"
  },
  {
    "text": "So similar for Lambda, but that's an important \nthing because sometimes we just, \"Oh, let's put an  ",
    "start": "949360",
    "end": "954720"
  },
  {
    "text": "express application here. We can run containers \non Lambda.\" No. Not that straightforward. ",
    "start": "954720",
    "end": "961319"
  },
  {
    "text": "Going on on the sort of the specifics of how \nLambda works, that when you are function code   runs, it's gonna take an input and that's gonna \nbe the trigger that launched the Lambda function.  ",
    "start": "961320",
    "end": "971200"
  },
  {
    "text": "And that's gonna be if it's behind an API, well, \nit's gonna be that API event, if it's putting a   message off a queue, it's gonna be the format of \nthat message from a queue. If it is, you know,  ",
    "start": "971200",
    "end": "980680"
  },
  {
    "text": "you've uploaded something to S3 and that's gonna \ninvoke the Lambda function, well, it's gonna be   the metadata object that comes from S3.\nAnd so a Lambda function has an event,  ",
    "start": "980680",
    "end": "988440"
  },
  {
    "text": "which is that event we've been talking \nabout. And then some context information,   which is just some metadata about the \ninvoke. And so your code needs to be  ",
    "start": "988440",
    "end": "995760"
  },
  {
    "text": "able to handle that as a container and, you \nknow, so there's no point running, you know,  ",
    "start": "995760",
    "end": "1000920"
  },
  {
    "text": "server full things inside your Lambda function \nsuch as a full Express app or that kind of thing. ",
    "start": "1000920",
    "end": "1007079"
  },
  {
    "text": "So that's sort of one of the differences \nwith running Lambda. And the other is just   one of the constraints with Lambda is Lambda \nfunctions can only run for 15 minutes. And  ",
    "start": "1007080",
    "end": "1015720"
  },
  {
    "text": "that idea is born from the fact that Lambda \nfunctions are there to do a piece of work,   and they're gonna then return their result back. \nAnd, you know, hopefully, it's gonna be within 15,  ",
    "start": "1015720",
    "end": "1025240"
  },
  {
    "text": "well, needs to be within 15 minutes.\nBut, obviously, if you're running a   full sort of more server full workflow within \na container such as a Flask or an Express app,  ",
    "start": "1025240",
    "end": "1033640"
  },
  {
    "text": "or some kind of really long-running process that's \ngonna run over 15 minutes, that's not gonna be   suitable for Lambda. So, you know, you maybe want \nto be thinking about some other solution or maybe  ",
    "start": "1033640",
    "end": "1043279"
  },
  {
    "text": "reducing the size or splitting up that job to \ndo it within 15 minutes so it can be for Lambda. ",
    "start": "1043280",
    "end": "1049277"
  },
  {
    "text": "So a lot of customers are taking applications \nand, you know, lift and shifting into the cloud   and thinking they can just take the container \nthat does a long-running process or users,  ",
    "start": "1049277",
    "end": "1058360"
  },
  {
    "text": "you know, maybe specific hardware features \nor runs an Express app as is, and to just  ",
    "start": "1058360",
    "end": "1063520"
  },
  {
    "text": "port that to Lambda, yeah, that's not gonna \nquite work straight out the box, but it's not   gonna be that easy, that difficult to change.\nSo there's the same limitations that whenever  ",
    "start": "1063520",
    "end": "1071560"
  },
  {
    "text": "we choose, if we use Lambda or we use Fargate, \nwe have to apply here because the long-running  ",
    "start": "1071560",
    "end": "1077480"
  },
  {
    "text": "processes, if it's not event-driven, if like fully \nlifted shift, well, it's a stateless service,  ",
    "start": "1077480",
    "end": "1084840"
  },
  {
    "text": "so well, all these kind of considerations that \nwe have for traditional functions we need to have  ",
    "start": "1084840",
    "end": "1090480"
  },
  {
    "text": "in this case because, at the end of the day, \nit's the same way of running the application. ",
    "start": "1090480",
    "end": "1094960"
  },
  {
    "text": "With addition of that one little thing you \nmentioned earlier about the mutability. One of   the powers of the container images, you have full \ncontrol over it, but then that means Lambda isn't  ",
    "start": "1096960",
    "end": "1104399"
  },
  {
    "text": "going to automatically patch the function for \nyou. So you do need to build something into your,   you know, delivery life cycle, or your CI/CD \nprocess when a new version of Node comes out  ",
    "start": "1104400",
    "end": "1113399"
  },
  {
    "text": "or a new operating system patch comes out, that \nyou can just regenerate that container image.   Hopefully, you've got some good testing, so you \ncan just do some of that automatically. That  ",
    "start": "1113400",
    "end": "1121520"
  },
  {
    "text": "is one of the differences between a container \nimage on Lambda and just the previous zip way.",
    "start": "1121520",
    "end": "1128600"
  },
  {
    "start": "1128000",
    "end": "1487000"
  },
  {
    "text": "Now we cover a little bit the pros, cons, when \nto use it, and we dive a little bit on how we  ",
    "start": "1129440",
    "end": "1136480"
  },
  {
    "text": "develop this. So we said that we need to have \na specification that's kind of something that  ",
    "start": "1136480",
    "end": "1143120"
  },
  {
    "text": "changes. So when we are developing this function \nwe will create a specification file and there you  ",
    "start": "1143120",
    "end": "1150080"
  },
  {
    "text": "mentioned the base, the base image. If we want, \nwe can put the input for our handler or the  ",
    "start": "1150080",
    "end": "1158640"
  },
  {
    "text": "starting of our application. Is there something \nelse that we need to put in this specification? ",
    "start": "1158640",
    "end": "1165680"
  },
  {
    "text": "If you are doing things as simple, not really. \nSo you're gonna create an image and it's just  ",
    "start": "1165680",
    "end": "1170800"
  },
  {
    "text": "gonna be basically a Docker file. So the first \nline of the Docker file is going to be from some  ",
    "start": "1170800",
    "end": "1176840"
  },
  {
    "text": "kind of base image. So you're gonna say from some \nkind of base image, say we are talking a Node. So  ",
    "start": "1176840",
    "end": "1182559"
  },
  {
    "text": "from the Node-base image, your second line in \nthe Docker file maybe to copy your local and to  ",
    "start": "1182560",
    "end": "1188400"
  },
  {
    "text": "copy all your local files into their base image.\nThat's literally the simplest Docker file you're  ",
    "start": "1188400",
    "end": "1194400"
  },
  {
    "text": "gonna have and you may then want to specify what \ntheir hand method is as another file. So that's   gonna be really, really simple. But people who \npackage Docker files know that there's a build  ",
    "start": "1194400",
    "end": "1204560"
  },
  {
    "text": "process that you can also do in that. So that \nmay be running, you know, NPM install or PIP   install if you're in the Python world. And, \nyou know, when you're building applications,  ",
    "start": "1204560",
    "end": "1212760"
  },
  {
    "text": "there's obviously a lot that you can do, and \nthat's fully supported in the Docker file.  So what you can do is, in your Docker file, \nyou can do, you know, pull the base layer,  ",
    "start": "1212760",
    "end": "1220960"
  },
  {
    "text": "you can then say, \"Oh, well, I'm gonna do a \nPIP install for Python, then I'm gonna copy   some files, then I'm gonna do, you know, whatever \nit is in the Docker file, I'm gonna, you know,  ",
    "start": "1220960",
    "end": "1228920"
  },
  {
    "text": "change something, grab something from another \nAPI, pull another image down, which is gonna be   maybe some machine learning. I'm gonna then pull \nsomewhere else and get, you know, some source  ",
    "start": "1228920",
    "end": "1240040"
  },
  {
    "text": "data that I wanna store in my Docker image.\"\nAs you would in a normal Docker file, you can   just go step by step by step and pull all the \ninformation in to create that sort of artifact.  ",
    "start": "1240040",
    "end": "1247840"
  },
  {
    "text": "And at the end, obviously, you would add your \nLambda function code. That handover comment you   would want to do. With a Docker file, Lambda also \nsupports the builds where you can do the...oh,  ",
    "start": "1247840",
    "end": "1261840"
  },
  {
    "text": "my brain has gone fried with the multi-stage \nbuilds. So what you can also do is you can  ",
    "start": "1261840",
    "end": "1267039"
  },
  {
    "text": "separate that sort of process of having the \nbuild part of your Docker file and then the   actual image creation part of your Docker file.\nSo some people need to install a whole bunch of  ",
    "start": "1269160",
    "end": "1278120"
  },
  {
    "text": "tools to be able to build their Docker file. So \nthey can do that with a minimal image. You know,   some people use Alpine or minimal images like \nthat, and then they sort of start from scratch  ",
    "start": "1278120",
    "end": "1286960"
  },
  {
    "text": "again, go, \"Okay, I've got all of that stuff \nI brought in, that's all in parts I need,   let me start building my actual final Docker file \nfrom the actual Node.js say base image. And then  ",
    "start": "1286960",
    "end": "1297000"
  },
  {
    "text": "I'm just gonna copy those pre-compiled or, \nyou know, brought-in files and sort of then  ",
    "start": "1297000",
    "end": "1302800"
  },
  {
    "text": "build up my image.\" So multi-stage builds works \nreally well with with Docker files for Lambda. ",
    "start": "1302800",
    "end": "1308240"
  },
  {
    "text": "When developing, also an important thing \nis testing. Is there some difference on  ",
    "start": "1308240",
    "end": "1313960"
  },
  {
    "text": "how we test these type of applications \nusing Docker images than how we test the  ",
    "start": "1313960",
    "end": "1319840"
  },
  {
    "text": "traditional serverless functions?\nYes, in a good way that, actually,   I think it probably makes it a little bit easier \nto test your Docker files locally because you  ",
    "start": "1319840",
    "end": "1329600"
  },
  {
    "text": "can just use Docker run. So there are lots of \nother solutions for running zip files locally,  ",
    "start": "1329600",
    "end": "1334679"
  },
  {
    "text": "and you can use SAM, or serverless framework, or \nsome CDK functionality to do it. But that's not  ",
    "start": "1334680",
    "end": "1340680"
  },
  {
    "text": "the tools maybe you're normally using. So when \nyou're actually developing Lambda functions,   you can do it literally fully in Docker \nand you can run that Docker image. There's  ",
    "start": "1340680",
    "end": "1350880"
  },
  {
    "text": "a little emulator you add in, which pretends \nto be the sort of Lambda API, and that's also   just another line you put in your Docker file.\nIt means you can do a Docker run locally. Two ways  ",
    "start": "1350880",
    "end": "1361919"
  },
  {
    "text": "I actually like to run it. One is when I'm really \nsort of developing from scratch and I actually   don't quite know what's going on in that function. \nWhat I can actually do is I can sort of live run  ",
    "start": "1361920",
    "end": "1370960"
  },
  {
    "text": "that Docker image and I can just connect into \nthat Docker image and then literally live type,  ",
    "start": "1370960",
    "end": "1376760"
  },
  {
    "text": "you know, line by line, installing kind of things, \ncopying some code, and just sort of iterating sort  ",
    "start": "1376760",
    "end": "1382280"
  },
  {
    "text": "of while I'm into the container. And because it's \nlocally, I'm not limited by any 15-minute timeouts  ",
    "start": "1382280",
    "end": "1388640"
  },
  {
    "text": "or any kind of thing, I'm just running something \nin a container and that's really useful for   testing out your whole build process...\nAnd it's fast... ",
    "start": "1388640",
    "end": "1394520"
  },
  {
    "text": "Yes, really fast.\n...because no need to go to the cloud...  Use everything local.\n...you can do it in a tunnel,   in your subway, or in an airplane.\nThen the second step is, you know,  ",
    "start": "1394520",
    "end": "1404600"
  },
  {
    "text": "once you've got your build process done in your \ncontainer, well, what you can do is just run it   locally in a bit more of an automated fashion \nwhere you create a mock input, for example,  ",
    "start": "1404600",
    "end": "1413720"
  },
  {
    "text": "to Lambda function, and you, you know, send \nthat to the container, it does its processing   and then returns the result. So the container \nruns, spins up, does its work, and then sort  ",
    "start": "1413720",
    "end": "1420920"
  },
  {
    "text": "of spins down afterwards. That sort of emulates \nthe way that Lambda is gonna work in the cloud.  Here is the same caveats that with any Lambda \nfunction or with any application that connects  ",
    "start": "1420920",
    "end": "1430440"
  },
  {
    "text": "to AWS services, if you are connecting in your \nfunction to Dynamo or S3, or SNS, whatever,  ",
    "start": "1430440",
    "end": "1438480"
  },
  {
    "text": "we are local. So either you make that connection \nto the cloud or you mock it. But that happens with  ",
    "start": "1438480",
    "end": "1445440"
  },
  {
    "text": "any application that we are running locally that \nwe need to be aware of that. So that's something,  ",
    "start": "1445440",
    "end": "1450919"
  },
  {
    "text": "it's not like this Docker file it's magical \nand will emulate the whole AWS cloud in your   computer. It just runs the function and \nif the function needs to communicate with  ",
    "start": "1450920",
    "end": "1459840"
  },
  {
    "text": "outside world, well, you need to do that.\nAnd because of the way Docker works,   there are also cool ways that you can sort \nof inject credentials into your Docker image.  ",
    "start": "1459840",
    "end": "1467600"
  },
  {
    "text": "So when it runs, it can, you know, use another \nrole, or use some sort of session credentials,  ",
    "start": "1467600",
    "end": "1474039"
  },
  {
    "text": "that's actually really useful as well that you \ncan have this, you know, one of the packaging   cool things about Docker is it is all isolated and \nseparate from your local machine. You just inject  ",
    "start": "1474040",
    "end": "1482720"
  },
  {
    "text": "your credentials in, do your database connection \nor whatever, and you can prove that it works.",
    "start": "1482720",
    "end": "1487240"
  },
  {
    "start": "1487000",
    "end": "2073000"
  },
  {
    "text": "So now we develop this amazing \napplication, how we put it in the cloud. ",
    "start": "1487840",
    "end": "1492279"
  },
  {
    "text": "The way that your local Docker file gets connected \nto the Lambda service is by uploading the image to  ",
    "start": "1493520",
    "end": "1499760"
  },
  {
    "text": "Amazon Elastic Container Registry. So that's \nan AWS-managed container registry. It's sort  ",
    "start": "1499760",
    "end": "1505080"
  },
  {
    "text": "of like Docker Hub, but it's AWS's. At \nthe moment, Lambda only supports images   from Elastic Container Registry, but as \nyou use your normal command line utility,  ",
    "start": "1505080",
    "end": "1514960"
  },
  {
    "text": "you do a Docker tag, tag your image, Docker \npushes up to the repository you're gonna do,  ",
    "start": "1514960",
    "end": "1520279"
  },
  {
    "text": "and then when you configure your Lambda \nfunction, your configuration of your   Lambda function is actually, you know \nwhat? That Docker image I just created,  ",
    "start": "1520280",
    "end": "1526919"
  },
  {
    "text": "you just pointed to that and you're sort \nof done. So that's the cool part of it.  So when Lambda then deploys that function, Lambda \nservice is gonna pull that image from ECR and is  ",
    "start": "1526920",
    "end": "1537160"
  },
  {
    "text": "then gonna run your Lambda function based on \nthat image. Two-step process, but for people   who are building any kind of container image, \nthat's a normal way you would develop it. You  ",
    "start": "1537160",
    "end": "1545399"
  },
  {
    "text": "don't need any other AWS tuning, you can just use \nyour Docker CLI. And the Docker CLI to create the   image, you then need to use AWS CLI or the Lambda \npart of it to actually build from that image. ",
    "start": "1545400",
    "end": "1555320"
  },
  {
    "text": "Many of the frameworks support that. So if \nyou're using some or CDK or something like that,   it's pretty straightforward to do this deployment.\nAnd often it's behind the scenes,  ",
    "start": "1555320",
    "end": "1563000"
  },
  {
    "text": "you don't even notice that's happening.\nYou don't need to even worry. But I think   now the most interesting part is the running this \nthing because, well, we talk about developing,  ",
    "start": "1563000",
    "end": "1572560"
  },
  {
    "text": "we put it in the cloud, now, it's a function. \nNobody's using it. So, now, Marcia comes  ",
    "start": "1572560",
    "end": "1577680"
  },
  {
    "text": "and do API gateway call to that function and \nwakes it up for the first time, what happens? ",
    "start": "1577680",
    "end": "1586120"
  },
  {
    "text": "Well, this is when we talk back to 10 gig, \nwhen people are going, \"How?\" Obviously,  ",
    "start": "1586120",
    "end": "1592080"
  },
  {
    "text": "the most important thing that a lot of people \nworry about is cold starts with Lambda and   cold starts, are important...\nAnd 10 gig scares you. ",
    "start": "1592080",
    "end": "1600069"
  },
  {
    "text": "Yes, like, \"You must be absolutely crazy. And I \nhave a huge machine learning model, or I have,   you know, the Python-based image or Java or .net. \nLike, are you people crazy? Because that's gonna  ",
    "start": "1600069",
    "end": "1610320"
  },
  {
    "text": "be ridiculously scary for cold starts.\" No. So \nbefore I go into the why not, just to explain  ",
    "start": "1610320",
    "end": "1618000"
  },
  {
    "text": "about cold starts, a cold start is as your code \nstarts up in the Lambda, what we call, execution  ",
    "start": "1618000",
    "end": "1624840"
  },
  {
    "text": "environment and that is just the isolated \nlittle micro VM that runs your Lambda code. ",
    "start": "1624840",
    "end": "1630080"
  },
  {
    "text": "Obviously, Node has got a startup, or Python's \ngot a startup, maybe you've gotta make a database   connection, maybe you've gotta pull some \nsecret from somewhere, and then your code  ",
    "start": "1630080",
    "end": "1638519"
  },
  {
    "text": "is gonna run for each invoke. So those sort \nof first initial steps is gonna happen every   single time that your Lambda function runs.\nThat's gonna take some time. But that's,  ",
    "start": "1638520",
    "end": "1648280"
  },
  {
    "text": "as with all normal coding practices, you \nknow, that's just the way it happens. It   can be a little bit more exacerbated in Lambda \nbecause obviously, you're running more of these  ",
    "start": "1648280",
    "end": "1658040"
  },
  {
    "text": "execution environments. But the cool thing \nis actually is the more of them you run,   the actual fewer cold starts you get because \nonce you do a cold start and Lambda is gonna  ",
    "start": "1658040",
    "end": "1666360"
  },
  {
    "text": "then run your invoke, and next time an invoke \ncomes in, it doesn't need to run that cold   start process. It's just gonna go and run your \nfunction, hand the code. So that's really quick. ",
    "start": "1666360",
    "end": "1673320"
  },
  {
    "text": "If the execution environment is idle, let's say.\nIt's up and running. So this is an issue for some  ",
    "start": "1673320",
    "end": "1679720"
  },
  {
    "text": "developers because some developers are testing \ntheir functions and they deploy a new version of   the function to the cloud, and then they run the \nfunction and they go cold start. Okay. And then  ",
    "start": "1679720",
    "end": "1687960"
  },
  {
    "text": "they do some tweaking, deploy the same function, a \nnew version, get a cold start. They're like, \"This  ",
    "start": "1687960",
    "end": "1693080"
  },
  {
    "text": "is gonna be bad when I'm running production.\" \nBut actually, because Lambda is reusing these  ",
    "start": "1693080",
    "end": "1699200"
  },
  {
    "text": "execution environments for subsequent invokes, \nthe busier application is, the fewer cold   starts you're gonna get. And that is a bit of \ncounterintuitive, and we talk to many customers,  ",
    "start": "1699200",
    "end": "1708120"
  },
  {
    "text": "and customers are running these lambda functions \nat reasonable scale, you know, whether it's high   scale or low scale, reasonable scale, see sort \nof between half 0.5% and 1% of cold starts. ",
    "start": "1708120",
    "end": "1718519"
  },
  {
    "text": "So, you know, less than 1% of your function \ninvokes are going to be cold starts. And really  ",
    "start": "1718520",
    "end": "1724000"
  },
  {
    "text": "that actually only matters if you're running \nsynchronous workloads because then your client   is waiting for a response. If you're doing some \nbatch processing, or stream processing, or some  ",
    "start": "1724000",
    "end": "1733159"
  },
  {
    "text": "asynchronous process where you eventually need to \nupdate a database, you don't really care about the   cold starts. So it's not as big a deal as people \nas people think. So that's the sort of history,  ",
    "start": "1733160",
    "end": "1744520"
  },
  {
    "text": "and sort of why cold starts matter and what it's.\nSo the free cart is like, okay, when I do a zip  ",
    "start": "1744520",
    "end": "1750480"
  },
  {
    "text": "function, when the function runs, it copies up to \nthat 250 meg that's gonna take some time, 10 gig,  ",
    "start": "1750480",
    "end": "1756200"
  },
  {
    "text": "you must be absolutely insane. There's no way I'm \ngonna wait around for that. So as part of this  ",
    "start": "1756200",
    "end": "1761760"
  },
  {
    "text": "release, Lambda came out with, I think, is some \nof the coolest technology that I've seen in Lambda  ",
    "start": "1761760",
    "end": "1767560"
  },
  {
    "text": "and this is one of the cool things with Lambda, is \nthere's just a whole bunch of stuff optimizations   behind the scenes that you don't know about or \nyou don't need to know about, and we just make  ",
    "start": "1767560",
    "end": "1776320"
  },
  {
    "text": "things faster and more efficient for you.\nSo two things, one is container images  ",
    "start": "1776320",
    "end": "1781759"
  },
  {
    "text": "are actually aren't pretty full. So even \nthough you can have up to 10 gig function,  ",
    "start": "1781760",
    "end": "1789160"
  },
  {
    "text": "most container sizes are actually really small. \nAnd actually what's used are that function is  ",
    "start": "1789160",
    "end": "1795400"
  },
  {
    "text": "even tinier. So even if you are, you know, using \nJava or .net or that kind of thing, and you pull  ",
    "start": "1795400",
    "end": "1801680"
  },
  {
    "text": "down that immediate layer, and then your function \ncode, in terms of the actual amount of bytes that  ",
    "start": "1801680",
    "end": "1807480"
  },
  {
    "text": "are gonna be read from that container image is \nreally tiny. And so if you're using, you know,  ",
    "start": "1807480",
    "end": "1812720"
  },
  {
    "text": ".net, Java, whatever runtime it is, even \nNode, you're not using all of Node or, like,   everything that's possible that Python could do.\nSo the first thing Lambda did is understood that,  ",
    "start": "1812720",
    "end": "1822640"
  },
  {
    "text": "well, actually, we don't need to download the \nwhole container image. We only need to pull   the things as you need to use them. So if you're \ngoing to use some library with a Node, well, what  ",
    "start": "1822640",
    "end": "1832640"
  },
  {
    "text": "it's gonna do is it's gonna pull that image as you \nuse it, and that's sort of called...it's like lazy   loading. But instead of having to download the \nwhole image before even running your function,  ",
    "start": "1832640",
    "end": "1842480"
  },
  {
    "text": "Lambda can just say, \"Well, when your function \ncode runs, I'm gonna be able to pull the things   that you need,\" and that can become really \nefficient. And that means that the amounts  ",
    "start": "1842480",
    "end": "1851080"
  },
  {
    "text": "of data that you're pulling down is literally \nprobably 80% to 90% less. And so that's also,  ",
    "start": "1851080",
    "end": "1856600"
  },
  {
    "text": "you know, super useful that you're not pulling the \nwhole 250 meg for a zip power car function. It's  ",
    "start": "1856600",
    "end": "1862840"
  },
  {
    "text": "literally only the data that you're gonna access.\nI don't know if this is something that we have   benchmarked internally, but I have seen some \ntweets of people running container images  ",
    "start": "1862840",
    "end": "1871640"
  },
  {
    "text": "faster than the traditional zip images. And \nit's like, okay, this is the magic on how it  ",
    "start": "1871640",
    "end": "1879480"
  },
  {
    "text": "works because in your traditional vanilla Lambda \nfunctions, you pull everything down. And in here,  ",
    "start": "1879480",
    "end": "1886520"
  },
  {
    "text": "you just pull exactly what you need. So \nyou might be pulling like a few megs and,   boom, you're ready to go. So that's...\nEven gets better because if you think of  ",
    "start": "1886520",
    "end": "1896480"
  },
  {
    "text": "a lot of different functions that if you are using \nthe Node.js manage runtime or Java manage runtime,  ",
    "start": "1896480",
    "end": "1901840"
  },
  {
    "text": "how many different customers and how many \ndifferent functions are actually using the same   manage runtime? So why when your function runs, \ndo you need runs? Do you need to copy all that  ",
    "start": "1901840",
    "end": "1910480"
  },
  {
    "text": "information down? So second cool stage is where \nLambda actually caches a lot of that information. ",
    "start": "1910480",
    "end": "1916160"
  },
  {
    "text": "So, for example, if you were to build a Node.js \n20 runtime today using a container image,  ",
    "start": "1917440",
    "end": "1923120"
  },
  {
    "text": "I'm pretty confident that there are one or \ntwo other customers who are already using   the Node.js 20 image. And so that is probably \ncached all through the Lambda fleet. And so  ",
    "start": "1923120",
    "end": "1932640"
  },
  {
    "text": "when your function first starts and it says, \n\"Oh, I need to pull something from Node.js...\"  I have this one.\nIt's, \"I have this one,\" and  ",
    "start": "1932640",
    "end": "1938680"
  },
  {
    "text": "there are multiple levels of the cache and one of \nthe levels of the cache is literally on the host,   on the actual server that runs your code. So, \nyou know, there's even nothing to download,  ",
    "start": "1938680",
    "end": "1948600"
  },
  {
    "text": "even if Lambda has said, \"Oh, you're gonna \nneed to use that functionality that's in   the cache,\" and so that's gonna be super-fast.\nSo this is in a nutshell, a little bit of the  ",
    "start": "1948600",
    "end": "1958840"
  },
  {
    "text": "magic of how we can run container images on \nfunctions. But before finishing this episode,  ",
    "start": "1958840",
    "end": "1967720"
  },
  {
    "text": "I want to let know the audience that we \nleave a lot of the resources to deep dive  ",
    "start": "1967720",
    "end": "1973559"
  },
  {
    "text": "and go into hands-on with these things in the \ndescription of this episode, because, well,  ",
    "start": "1973560",
    "end": "1979880"
  },
  {
    "text": "this is just a short introduction, but you \nshould try it, you should explore it. It's   not hard. And we are still on this pay-and-use \nmode, so you can have your containers running  ",
    "start": "1979880",
    "end": "1991000"
  },
  {
    "text": "in the free tier of Lambda with no problem.\nThat's so easy to play with it. The speed thing  ",
    "start": "1991000",
    "end": "2001320"
  },
  {
    "text": "is just so cool because we will put the link in \nthe show notes, but there's some public papers  ",
    "start": "2001320",
    "end": "2007000"
  },
  {
    "text": "describing how this all works. So even though it's \nunder the hood in Lambda, you know, we explained   it really well, and there's scientific papers \nshowing how it all puts together. We cache stuff  ",
    "start": "2007000",
    "end": "2017880"
  },
  {
    "text": "in it, and in fact, we've come up with a whole \ncool way that we can actually cache things across   multiple different functions entirely securely \nwithout having to share any information between  ",
    "start": "2017880",
    "end": "2027640"
  },
  {
    "text": "different functions or different customers.\nSo, for example, we talk about the Node 20   manager runtime coming down really quickly, if \nyou've got a Python package or a Node package  ",
    "start": "2027640",
    "end": "2037000"
  },
  {
    "text": "that someone else has used, even though we don't \nhave visibility into different people's functions,   the way we can manage it on the system is we \ncan use some clever caching technologies that  ",
    "start": "2037000",
    "end": "2047760"
  },
  {
    "text": "we can de-dupe across functions without \nfunctions knowing about each other.   That sounds a bit like absolutely impossible.\nIt's a part of it called convergent encryption,  ",
    "start": "2047760",
    "end": "2056919"
  },
  {
    "text": "which always sounds like a cool name. And so, \nyeah, just so many different ways we can cache   this and make it faster. And as Marcia Villalba \nsaid, you know, for many Lambda functions,  ",
    "start": "2056920",
    "end": "2066040"
  },
  {
    "text": "like, it's actually faster on the \ncontainer image than the zip archive   because we take advantage of this caching.\nI think with that, we can close this episode  ",
    "start": "2068400",
    "end": "2077359"
  },
  {
    "start": "2073000",
    "end": "2139000"
  },
  {
    "text": "for today. It was lovely chatting with you, Julian \nWood. I hope the audience enjoyed this and learned  ",
    "start": "2077360",
    "end": "2084080"
  },
  {
    "text": "something new, at least I hope, because this is \na very interesting topic that many organizations  ",
    "start": "2084640",
    "end": "2090879"
  },
  {
    "text": "are taking the benefit of because we all know \ncontainers and we have tooling for it. So why not  ",
    "start": "2090880",
    "end": "2097799"
  },
  {
    "text": "to embrace it with Lambda? So thank you very much.\nNo, thanks, Marcia. Always happy to chat. And,  ",
    "start": "2097800",
    "end": "2103600"
  },
  {
    "text": "yes, try it out. It's really easy if you're a \ncontainer person, and you are thinking Lambda   is gonna be a bit weird because it's all a bit \ndifferent. Well, now the two worlds have merged  ",
    "start": "2103600",
    "end": "2111040"
  },
  {
    "text": "and you can just use your container images \nto build your Lambda functions. Hopefully,   it'll be a really great experience for you. \nAnd, yeah, lots of resources in the notes,  ",
    "start": "2111040",
    "end": "2118520"
  },
  {
    "text": "which you can delve deep into how it all works.\nYes. Thank you. Bye.",
    "start": "2118520",
    "end": "2122920"
  }
]
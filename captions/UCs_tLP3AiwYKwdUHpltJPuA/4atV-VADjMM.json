[
  {
    "text": "[Music] welcome to the go-to podcast each",
    "start": "290",
    "end": "7520"
  },
  {
    "text": "episode covers the brightest and boldest ideas from the world's leading experts in software development tune in for",
    "start": "7520",
    "end": "14120"
  },
  {
    "text": "practical lessons compelling theories and plenty of",
    "start": "14120",
    "end": "19240"
  },
  {
    "text": "inspiration go to gathers the brightest Minds in the software Community to help developers tackle projects today plan",
    "start": "19960",
    "end": "26720"
  },
  {
    "text": "for tomorrow and create a better future stay up to dat with the latest in Tech through go-to's top rated events held",
    "start": "26720",
    "end": "33320"
  },
  {
    "text": "online and in person in cities like Amsterdam London Copenhagen and Chicago",
    "start": "33320",
    "end": "39160"
  },
  {
    "text": "and by subscribing to the goto conferences YouTube channel where you can find thousands more highquality de",
    "start": "39160",
    "end": "44680"
  },
  {
    "text": "talks learn more e [Music]",
    "start": "44680",
    "end": "51530"
  },
  {
    "text": "copia.jpg and he's the creator of the axon project and the co-creator of the inex project as well this is all things",
    "start": "58920",
    "end": "66600"
  },
  {
    "text": "machine learning in Elixir you want to tell the audience about yourself Sean",
    "start": "66600",
    "end": "71720"
  },
  {
    "text": "sure so my name is Shan morard um originally from Philadelphia Pennsylvania um I am the author of",
    "start": "71720",
    "end": "78960"
  },
  {
    "text": "genetic algorithms in Elixir and I also have a new publication out called machine learning in Elixir um worked in",
    "start": "78960",
    "end": "84880"
  },
  {
    "text": "the machine learning ecosystem in Elixir for quite some time now and I'm excited to talk a little bit about new",
    "start": "84880",
    "end": "90840"
  },
  {
    "text": "project yeah and this is an interesting story because as as many of you might",
    "start": "90840",
    "end": "96320"
  },
  {
    "text": "know Elixir has not always been known as a great language for machine learning",
    "start": "96320",
    "end": "101479"
  },
  {
    "text": "and so I I think that you might have knocked Jose the creative Elixir out of his chair when you wrote the first book",
    "start": "101479",
    "end": "108840"
  },
  {
    "text": "about genetic algorithms in in machine learning could you tell us a little bit about that yeah so um I was really",
    "start": "108840",
    "end": "115719"
  },
  {
    "text": "interested in uh genetic algorithms and evolutionary algorithms and in college",
    "start": "115719",
    "end": "120880"
  },
  {
    "text": "mainly for applications in like sports betting in particular because um sports",
    "start": "120880",
    "end": "126320"
  },
  {
    "text": "betting is very similar to uh like Financial Theory investing basically so portfolio Theory um and there's a lot of",
    "start": "126320",
    "end": "132760"
  },
  {
    "text": "tie-ins with uh using genetic algorithms and evolutionary algorithms for optimizing a portfolio for risk and",
    "start": "132760",
    "end": "139120"
  },
  {
    "text": "reward um and so I was really interested in genetic algorithms evolutionary algorithms and I was also really",
    "start": "139120",
    "end": "145400"
  },
  {
    "text": "interested in Elixir but Elixir was not a good language for doing any of this stuff um the the beam the virtual",
    "start": "145400",
    "end": "152280"
  },
  {
    "text": "machine that Elixir runs on the airling virtual machine is not good for",
    "start": "152280",
    "end": "157560"
  },
  {
    "text": "numerical computations it's well suited for like concurrency building fault tolerant applications but numerical",
    "start": "157560",
    "end": "163560"
  },
  {
    "text": "applications were not something that that it was very good for uh but I decided I was just going to write uh",
    "start": "163560",
    "end": "168800"
  },
  {
    "text": "genetic algorithms in Elixir anyway and so I created the project for creating genetic algorithms solving some toy",
    "start": "168800",
    "end": "175280"
  },
  {
    "text": "problems basically with with genetic algorithms and I thought it was something that other people might also be interested in so I kind of threw a",
    "start": "175280",
    "end": "182280"
  },
  {
    "text": "hail Mary over to the pragmatic programmer the pragmatic bookshelf uh who's the publisher behind the pragmatic",
    "start": "182280",
    "end": "188319"
  },
  {
    "text": "programmer um about a book pitch basically for genetic algor Elixir and",
    "start": "188319",
    "end": "193480"
  },
  {
    "text": "uh miraculously they ended up accepting it um the book came out in I think February of 2020 um or maybe it might",
    "start": "193480",
    "end": "201680"
  },
  {
    "text": "have been October of 2020 um and after that uh I got in touch with Jose valim",
    "start": "201680",
    "end": "208040"
  },
  {
    "text": "who's the creator of elixir and he basically was like Hey so I thought this was pretty interesting do you want to start working on machine learning",
    "start": "208040",
    "end": "213840"
  },
  {
    "text": "projects in Elixir and I thought that would be pretty awesome so we we started kicked off that project around the same",
    "start": "213840",
    "end": "219280"
  },
  {
    "text": "time October 2020 and um three years on now we we've got uh everything from Deep",
    "start": "219280",
    "end": "224599"
  },
  {
    "text": "learning to traditional machine learning um you can use you know pre-trained Transformers and a lot of pre-trained",
    "start": "224599",
    "end": "229920"
  },
  {
    "text": "models just directly from from Elixir itself and uh our performance is pretty competitive with uh the python ecosystem",
    "start": "229920",
    "end": "237519"
  },
  {
    "text": "um and we have some pretty good abstractions for deploying machine learning models as well I want to slow you down a little bit because we've GS",
    "start": "237519",
    "end": "244200"
  },
  {
    "text": "over some pretty interesting things here so so I've got to tell you I've got to",
    "start": "244200",
    "end": "250000"
  },
  {
    "text": "make an admission for the first time on this podcast I saw that initial uh book",
    "start": "250000",
    "end": "255640"
  },
  {
    "text": "proposal come through and I didn't I said this is the wrong thing for Elixir I'm I'm the editor or um kind of the",
    "start": "255640",
    "end": "262479"
  },
  {
    "text": "line editor of The Elixir lot of books at the time um I said this is really interesting stuff but um this is more",
    "start": "262479",
    "end": "270639"
  },
  {
    "text": "interesting from an academic perspective so I said you know I don't want to kill this but I don't want to I also don't",
    "start": "270639",
    "end": "277880"
  },
  {
    "text": "want to uh kind of kind of give people false hope right so what I did is I said",
    "start": "277880",
    "end": "283919"
  },
  {
    "text": "okay this is this is interesting academically so does anybody else want to take a shot at this and another",
    "start": "283919",
    "end": "290360"
  },
  {
    "text": "editor stepped up and at you know the rest is history but one thing is",
    "start": "290360",
    "end": "295960"
  },
  {
    "text": "interesting is that there's a there's a pretty pretty blinding moment in time",
    "start": "295960",
    "end": "301400"
  },
  {
    "text": "that that just went very quickly where Elixir was not a good language for for",
    "start": "301400",
    "end": "307039"
  },
  {
    "text": "these kinds of applications to to the the time that Elixir became that and that's what index is about could you",
    "start": "307039",
    "end": "313280"
  },
  {
    "text": "tell us a little bit about what index does before we get into axon and the Machine learning stack yeah so NX stands",
    "start": "313280",
    "end": "321360"
  },
  {
    "text": "for numerical Elixir which is essentially the foundation for The Elixir machine learning ecosystem um the",
    "start": "321360",
    "end": "327680"
  },
  {
    "text": "NX project started out so early on we were trying to make a decision on how we",
    "start": "327680",
    "end": "333759"
  },
  {
    "text": "were going to design the libraries and um Elixir and airling they have this concept of native implemented functions",
    "start": "333759",
    "end": "340800"
  },
  {
    "text": "uh they're essentially just a way you can write C bindings to some you know native library and then get it to work",
    "start": "340800",
    "end": "346000"
  },
  {
    "text": "with the airline virtual machine um and one of the paths we could have taken was say okay well these libraries like",
    "start": "346000",
    "end": "352639"
  },
  {
    "text": "tensorflow and pytorch they offer C and C++ uh libraries we can just essentially",
    "start": "352639",
    "end": "358160"
  },
  {
    "text": "build directly on top of that and it would have been a pretty quick win we C we could have gotten something up and running very quickly the problem with",
    "start": "358160",
    "end": "365479"
  },
  {
    "text": "marrying yourself to another ecosystem is you are uh essentially blocked",
    "start": "365479",
    "end": "371080"
  },
  {
    "text": "anytime they have an issue and you know as a as a smaller consumer of their native libraries you might not",
    "start": "371080",
    "end": "377160"
  },
  {
    "text": "necessarily have the biggest influence over the bugs they're going to fix and the things they're going to prioritize",
    "start": "377160",
    "end": "382479"
  },
  {
    "text": "so um we made a very intentional decision to not build the library dependent on uh other ecosystems",
    "start": "382479",
    "end": "389840"
  },
  {
    "text": "Upstream like that um so NX for those that are familiar with the python ecosystem is very very similar to uh",
    "start": "389840",
    "end": "397360"
  },
  {
    "text": "numpy but NX has the additional abstraction of like pluggable compilers",
    "start": "397360",
    "end": "403639"
  },
  {
    "text": "and backends which means that NX itself just implements a Behavior Uh which is I",
    "start": "403639",
    "end": "410000"
  },
  {
    "text": "guess similar to like an abstract class for those coming from uh object oriented programming um essentially it's just a",
    "start": "410000",
    "end": "416199"
  },
  {
    "text": "contract for people to implement their own uh implementations of some of the numerical routines that we have in NX so",
    "start": "416199",
    "end": "422440"
  },
  {
    "text": "for example um NX has something like nx. coine or nx. Co in this case and Library",
    "start": "422440",
    "end": "429479"
  },
  {
    "text": "uh backend and compiler implementers can Implement their own versions of cosign for you know targeted Hardware um or",
    "start": "429479",
    "end": "437039"
  },
  {
    "text": "specialized routines uh that are that are you know accelerated in some way and the first compiler we implemented was",
    "start": "437039",
    "end": "444199"
  },
  {
    "text": "xlaa which is Google's uh accelerated linear algebra um it's it's basically a machine learning compiler for taking",
    "start": "444199",
    "end": "450840"
  },
  {
    "text": "these numerical programs and uh compiling them to the CPU the GPU and and Google's tpus these accelerators um",
    "start": "450840",
    "end": "458919"
  },
  {
    "text": "so NX really serves as the foundation for our entire ecosystem it also",
    "start": "458919",
    "end": "464159"
  },
  {
    "text": "implements automatic differentiation which is important for implementing some of the uh optimization routines used in",
    "start": "464159",
    "end": "470400"
  },
  {
    "text": "axon which is deep learning library but it sounds like we're going to get to that a little later um so that's pretty",
    "start": "470400",
    "end": "476000"
  },
  {
    "text": "much it about NX yeah know I love theide idea that that since you're snapping out this this",
    "start": "476000",
    "end": "482240"
  },
  {
    "text": "whole numerical model and then then kind of the the whole way that you think about storing tensors right that that",
    "start": "482240",
    "end": "491199"
  },
  {
    "text": "these are Concepts that are just kind of ripped out of the language and snapped in and and to make that serviceable he",
    "start": "491199",
    "end": "498440"
  },
  {
    "text": "did something fairly brilliant in there and that's that's taking a um a traditional function definition and then",
    "start": "498440",
    "end": "505759"
  },
  {
    "text": "offering an alternative implementation can you tell us just just a little bit about defn yeah so um",
    "start": "505759",
    "end": "513120"
  },
  {
    "text": "NX introduces this idea of numerical definitions so in Elixir functions are declared with the defa keyword um in NX",
    "start": "513120",
    "end": "522360"
  },
  {
    "text": "uh you get something called defn so it's just literally like deaf and then an end at the end that's that's a numerical definition and these numerical",
    "start": "522360",
    "end": "529080"
  },
  {
    "text": "definitions support a tiny subset of The Elixir programming language so it's a little more strict one of the things",
    "start": "529080",
    "end": "535200"
  },
  {
    "text": "that we noticed we tried to Model A lot of the library off of jacks which uh you know it's a library it offers the",
    "start": "535200",
    "end": "542160"
  },
  {
    "text": "basically the numpy API jx. numpy um but but it supports just in time compilation",
    "start": "542160",
    "end": "548880"
  },
  {
    "text": "as a part of that just in time compilation um you get some interesting Behavior so Jack's functions uh Jack's",
    "start": "548880",
    "end": "557040"
  },
  {
    "text": "jitted functions they have to be uh completely pure so any side effects that happen uh they only really happen once",
    "start": "557040",
    "end": "563680"
  },
  {
    "text": "in in these these programs and you they have to have some interesting like static shape and type constraint",
    "start": "563680",
    "end": "569920"
  },
  {
    "text": "um and it was difficult for people transitioning to to write Jacks to get",
    "start": "569920",
    "end": "575320"
  },
  {
    "text": "around like hey python has these really flexible uh abstractions like people like writing python because it's",
    "start": "575320",
    "end": "581920"
  },
  {
    "text": "flexible and Jax jit was not flexible uh so we made kind of an intentional decision to have a completely separate",
    "start": "581920",
    "end": "588760"
  },
  {
    "text": "abstraction from traditional Elixir functions because we wanted people to understand that when you write a numerical definition uh it's going to",
    "start": "588760",
    "end": "595240"
  },
  {
    "text": "get jit compiled um you know this anything that's like side of affecting is is not going to not going to work",
    "start": "595240",
    "end": "601120"
  },
  {
    "text": "very well with with what you want to do um and so we wanted to keep that abstraction completely separate from the",
    "start": "601120",
    "end": "607399"
  },
  {
    "text": "core language um so when you write a numerical definition it essentially gets immediately compiled and targeted to",
    "start": "607399",
    "end": "614680"
  },
  {
    "text": "whatever the the compiler you choose is so in this case if you're using something like exla which uses Google's",
    "start": "614680",
    "end": "620640"
  },
  {
    "text": "xlaa um your numerical definition will get just in time compiled to uh the CPU",
    "start": "620640",
    "end": "626320"
  },
  {
    "text": "or the GPU depending on the client that you choose for the the inputs that that you give it um and it's a very",
    "start": "626320",
    "end": "632720"
  },
  {
    "text": "interesting abstraction because it's something that just extends the language like it's not it didn't require any any",
    "start": "632720",
    "end": "638519"
  },
  {
    "text": "changes to Elixir Upstream Elixir itself is just a really really flexible language with uh meta programming and",
    "start": "638519",
    "end": "644200"
  },
  {
    "text": "some of the other things you can do um so we didn't have to make any changes to Elixir Upstream it's just something that we could were able to natively support",
    "start": "644200",
    "end": "650600"
  },
  {
    "text": "given what Elixir has which is really beautiful right it's like you can you can snap these guard",
    "start": "650600",
    "end": "657160"
  },
  {
    "text": "rails right right out to the system system and and everything just worked right so it's so I hope that the",
    "start": "657160",
    "end": "664480"
  },
  {
    "text": "listeners are starting to get a sense that rather than building something quick and dirty and making a library",
    "start": "664480",
    "end": "671639"
  },
  {
    "text": "type decision this is actually something a little bit more related to the infrastructure in building up layer by",
    "start": "671639",
    "end": "679440"
  },
  {
    "text": "layer slowly and then let's talk a little bit about the next layer the axon",
    "start": "679440",
    "end": "684839"
  },
  {
    "text": "layer so what is axon yeah so after the NX project started to show some initial successes we wanted to uh get like real",
    "start": "684839",
    "end": "693240"
  },
  {
    "text": "applications of what we were building and so the first I would say real concrete application was uh neural",
    "start": "693240",
    "end": "698920"
  },
  {
    "text": "networks because uh deep learning and neural networks today are almost synonymous with machine learning people",
    "start": "698920",
    "end": "705200"
  },
  {
    "text": "say machine learning and like 90% of the time people are talking about deep learning just because of the popularity of large language models and some of",
    "start": "705200",
    "end": "712920"
  },
  {
    "text": "these other pre-trained models for computer vision and natural language processing um so while there is like traditional machine learning and we do",
    "start": "712920",
    "end": "719120"
  },
  {
    "text": "support traditional machine learning uh we really targeted neural networks because at the time uh they were very",
    "start": "719120",
    "end": "725040"
  },
  {
    "text": "very popular and that was the first thing we wanted to prove we were able to do that because if we were able to do that then we were essentially able to do",
    "start": "725040",
    "end": "730839"
  },
  {
    "text": "anything we wanted to um so axon is a library for creating and training neural",
    "start": "730839",
    "end": "736800"
  },
  {
    "text": "networks in Elixir uh it has a very similar API to Caris tensorflow Caris uh",
    "start": "736800",
    "end": "742600"
  },
  {
    "text": "as well as some other ideas stolen from the pytorch ecosystem so I am a I would say machine learning framework junkie",
    "start": "742600",
    "end": "749480"
  },
  {
    "text": "and I spend a lot of time just reading about different approaches to solving",
    "start": "749480",
    "end": "754839"
  },
  {
    "text": "machine learning problems and um different like Library design decisions that the creators of pytorch and Caris",
    "start": "754839",
    "end": "760880"
  },
  {
    "text": "and uh some of the other the projects in those ecosystems have made and you know looking at the complaints of people and",
    "start": "760880",
    "end": "766639"
  },
  {
    "text": "trying out different things and seeing what works um and so axon borrows a lot of ideas from these other ecosystems to",
    "start": "766639",
    "end": "773040"
  },
  {
    "text": "make it easy to to create composable neural networks and then and then also train these neural networks and it's a",
    "start": "773040",
    "end": "778920"
  },
  {
    "text": "fundamentally different approach than what you see in the python ecosystem just completely out of necessity so",
    "start": "778920",
    "end": "785760"
  },
  {
    "text": "obviously python supports those object-oriented abstractions and axon being built on top of a functional",
    "start": "785760",
    "end": "791959"
  },
  {
    "text": "programming language has to to build on functional constructs so um it's a little difficult in in terms of like",
    "start": "791959",
    "end": "798959"
  },
  {
    "text": "comparing Apples to Apples you know something that's implemented in caros and something that's implemented in axon",
    "start": "798959",
    "end": "804160"
  },
  {
    "text": "um but it is very similar will feel very similar to someone coming from another another ecosystem system directly into",
    "start": "804160",
    "end": "809519"
  },
  {
    "text": "the Elixir ecosystem yeah and this is this is cool right so one of the things that I've",
    "start": "809519",
    "end": "815320"
  },
  {
    "text": "noticed is that by slowing down we're kind of hitting we're hitting",
    "start": "815320",
    "end": "820680"
  },
  {
    "text": "this point where everything seems to be happening at once it seems Seems like having the Elixir infrastructure",
    "start": "820680",
    "end": "827160"
  },
  {
    "text": "underneath um by slowing down and getting the abstractions right all those things can be brought to bear to the",
    "start": "827160",
    "end": "833480"
  },
  {
    "text": "overall to the overall project so can you talk about the impact of Axon an",
    "start": "833480",
    "end": "838959"
  },
  {
    "text": "index on The Elixir ecosystem yeah so I first I want to hit on the point that like starting out slowly how how",
    "start": "838959",
    "end": "845279"
  },
  {
    "text": "fundamentally important that was to what we wanted to do because um you I think there this is happening a lot in the",
    "start": "845279",
    "end": "850759"
  },
  {
    "text": "python ecosystem now um pytorch pytorch 2.0 has made a huge like effort to",
    "start": "850759",
    "end": "856839"
  },
  {
    "text": "rewrite a lot of their internals in Python and there's a lot of reason for that decision um but you know one of",
    "start": "856839",
    "end": "865240"
  },
  {
    "text": "them is obviously just like from a maintainability perspective um python For Better or Worse is is much more",
    "start": "865240",
    "end": "871440"
  },
  {
    "text": "approachable than C++ as like a you know language for writing compilers um and",
    "start": "871440",
    "end": "876880"
  },
  {
    "text": "and writing for for someone who's you know just coming into uh the pytorch ecosystem it's a lot easier for them to",
    "start": "876880",
    "end": "882560"
  },
  {
    "text": "just look at some python code that maybe implements like their their some of their their backends for for writing",
    "start": "882560",
    "end": "887839"
  },
  {
    "text": "these uh these numerical programs uh then trying to figure out like decipher",
    "start": "887839",
    "end": "893240"
  },
  {
    "text": "C++ and so we had that kind of same inclination from the beginning that",
    "start": "893240",
    "end": "899399"
  },
  {
    "text": "we should keep as much of what we were building in Elixir as possible because",
    "start": "899399",
    "end": "904680"
  },
  {
    "text": "it's more maintainable it's more approachable um and it was going to just be easier for us to to work with and to",
    "start": "904680",
    "end": "910759"
  },
  {
    "text": "work fast and build on top of um because neither myself nor Jose nor any of the",
    "start": "910759",
    "end": "916279"
  },
  {
    "text": "maintainers who have come on after the fact the original project like Paulo and Jonathan um none of none of us are are",
    "start": "916279",
    "end": "923199"
  },
  {
    "text": "C++ people we all are Elixir programmers and so um keeping everything in Elixir allows us to work a lot faster than we",
    "start": "923199",
    "end": "930079"
  },
  {
    "text": "traditionally would have because we're you know we're a very small team of people writing this it's it's basically four five people that are that are",
    "start": "930079",
    "end": "936639"
  },
  {
    "text": "really the core maintainers of the NX project and um we're able to implement features significantly faster just",
    "start": "936639",
    "end": "942240"
  },
  {
    "text": "because we're working in Elixir and you know only reach into C++ and c and rust and whatever uh when it's absolutely",
    "start": "942240",
    "end": "948720"
  },
  {
    "text": "necessary um now the overall impact that NX and axon have had on the Elixir",
    "start": "948720",
    "end": "955160"
  },
  {
    "text": "ecosystem I would say it it's it's been pretty large um especially in the amount of time that the the projects have have",
    "start": "955160",
    "end": "962199"
  },
  {
    "text": "been out there so we really are only around three years into these projects and um there are already some successful",
    "start": "962199",
    "end": "968720"
  },
  {
    "text": "applications of these libraries being used in production um people I think are excited about the prospect of using",
    "start": "968720",
    "end": "975279"
  },
  {
    "text": "machine learning and elixir especially for companies that are using um Elixir for their actual like deployment",
    "start": "975279",
    "end": "980920"
  },
  {
    "text": "environment their uh backend services and stuff uh it's a lot I would say easier for someone like them to maybe",
    "start": "980920",
    "end": "987759"
  },
  {
    "text": "get thrown a model from the python ecosystem from their data science or machine learning team uh and then to",
    "start": "987759",
    "end": "993120"
  },
  {
    "text": "implement you know essentially an inference pipeline um directly in Elixir without having to uh call out to another",
    "start": "993120",
    "end": "1000440"
  },
  {
    "text": "service or or or build some on top of some complex like microservices stack so it has definitely had a pretty large",
    "start": "1000440",
    "end": "1006759"
  },
  {
    "text": "impact um and I'm excited to see where the the ecosystem grows yeah we're starting to see all",
    "start": "1006759",
    "end": "1013240"
  },
  {
    "text": "these little little popup projects right and that's that's all always an indication that that are doing something",
    "start": "1013240",
    "end": "1019120"
  },
  {
    "text": "well on the abstractions end right um so we've talked a little bit about the",
    "start": "1019120",
    "end": "1024280"
  },
  {
    "text": "impact of machine learning on Elixir and the idea that this is unexpected and and pretty exciting and",
    "start": "1024280",
    "end": "1031438"
  },
  {
    "text": "is has definitely hit this critical mass where everything is rolling now but we haven't talked about the impact that we",
    "start": "1031439",
    "end": "1039079"
  },
  {
    "text": "might see of introducing Elixir to machine learning can you talk about why",
    "start": "1039079",
    "end": "1044360"
  },
  {
    "text": "that might be interesting to us yeah so anytime time you try to I guess like",
    "start": "1044360",
    "end": "1051559"
  },
  {
    "text": "penetrate a an additional Market from a programming language perspective you",
    "start": "1051559",
    "end": "1057039"
  },
  {
    "text": "have to I would say like do it carefully and and think hard about why someone would choose to use your language for uh",
    "start": "1057039",
    "end": "1065480"
  },
  {
    "text": "whatever it is that they're doing over what they're used to um and particularly like in machine learning python is so",
    "start": "1065480",
    "end": "1072960"
  },
  {
    "text": "entrenched and it's for good reason there's a lot of really great abstractions and great libraries in the python ecosystem",
    "start": "1072960",
    "end": "1078919"
  },
  {
    "text": "um it's friendly for you know beginner programmers who might have like you know an academic background and they're",
    "start": "1078919",
    "end": "1084559"
  },
  {
    "text": "interested in some aspect of like numerical Computing or machine learning um it's very easy to write you know pick",
    "start": "1084559",
    "end": "1091120"
  },
  {
    "text": "up Python and just and just run with it um so when we first started these",
    "start": "1091120",
    "end": "1096159"
  },
  {
    "text": "projects I think a lot of people thought we were kind of crazy because you know it trying to Target something that is so",
    "start": "1096159",
    "end": "1102559"
  },
  {
    "text": "entrenched like python is in the machine learning ecosystem you know other languages have tried to do this and uh it doesn't always have the best results",
    "start": "1102559",
    "end": "1109799"
  },
  {
    "text": "and so uh we we we're trying to I guess tread carefully from the very beginning that uh you know we we don't necessarily",
    "start": "1109799",
    "end": "1116600"
  },
  {
    "text": "see these projects as overtaking python as the like the primary language for machine learning uh but we wanted to",
    "start": "1116600",
    "end": "1122720"
  },
  {
    "text": "give people who were using Elixir and who were interested also in Elixir kind of an alternative to some of the original workflows and as the projects",
    "start": "1122720",
    "end": "1129679"
  },
  {
    "text": "have matured we're kind of identifying areas where our projects could have a",
    "start": "1129679",
    "end": "1136520"
  },
  {
    "text": "significant advantage over uh some of the same projects in the python ecosystem so I think one of those is in",
    "start": "1136520",
    "end": "1142840"
  },
  {
    "text": "our serving abstraction which is a uh servings in in the world of machine learning are just like an inference uh",
    "start": "1142840",
    "end": "1149840"
  },
  {
    "text": "it's it's essentially just a fancy way to say that we're we're going to get uh inferences from the model in production",
    "start": "1149840",
    "end": "1156360"
  },
  {
    "text": "and in the python ecosystem there are like five or six serving projects and",
    "start": "1156360",
    "end": "1162559"
  },
  {
    "text": "they're all separate services like torch serve tensorflow serving uh K serve which is like a kuber thing um there",
    "start": "1162559",
    "end": "1170320"
  },
  {
    "text": "there's these all these abstractions for essentially overcoming I think some of the shortcomings that python has as a as",
    "start": "1170320",
    "end": "1175360"
  },
  {
    "text": "a language for uh deploying machine learning infrastructure whereas in The Elixir ecosystem we don't necessarily",
    "start": "1175360",
    "end": "1181320"
  },
  {
    "text": "have some of the same shortcomings so uh we have this abstraction which is NX serving it is essentially a a a data",
    "start": "1181320",
    "end": "1189520"
  },
  {
    "text": "structure or a behavior that wraps uh what you would see in a production",
    "start": "1189520",
    "end": "1194840"
  },
  {
    "text": "inference pipeline so it encapsulates pre-processing actual of the model and then post-processing and the NX serving",
    "start": "1194840",
    "end": "1201360"
  },
  {
    "text": "abstraction is very very simple but it supports some pretty insane things like because of the the the way Elixir is",
    "start": "1201360",
    "end": "1208400"
  },
  {
    "text": "built on top of the airlink virtual machine um NX serving supports distribution just natively so if you",
    "start": "1208400",
    "end": "1214840"
  },
  {
    "text": "have a cluster um you can spin up you know multiple servings and they're they're load balanced automatically",
    "start": "1214840",
    "end": "1220480"
  },
  {
    "text": "between the the nodes in your cluster or if you have let's say like multiple gpus you can partition inferences between uh",
    "start": "1220480",
    "end": "1227520"
  },
  {
    "text": "multiple GP use and it's a very scalable uh application it's a very it's a very scalable abstraction and it's also gets",
    "start": "1227520",
    "end": "1235000"
  },
  {
    "text": "you get all of the the goodies that you would get from building on top of the airline virtual machine to begin with like you know fault tolerance and uh",
    "start": "1235000",
    "end": "1242039"
  },
  {
    "text": "good concurrency and and you know the ability to build robust machine learning applications uh on a on a battle tested",
    "start": "1242039",
    "end": "1249400"
  },
  {
    "text": "and production ready uh virtual machine so it sounds kind of like there",
    "start": "1249400",
    "end": "1254640"
  },
  {
    "text": "are reasons to use Elixir and there are reasons to do machine learning and and",
    "start": "1254640",
    "end": "1259760"
  },
  {
    "text": "so the the reasons to to use Elixir don't go away just because you're entering this other space right so in in",
    "start": "1259760",
    "end": "1266919"
  },
  {
    "text": "some ways uh all the things that elixir does are becoming table staks right and",
    "start": "1266919",
    "end": "1272919"
  },
  {
    "text": "all the things that machine learning does are becoming table stakes and so once once we can bring those two things",
    "start": "1272919",
    "end": "1280279"
  },
  {
    "text": "together some pretty exciting things happen exactly yeah and we try as best",
    "start": "1280279",
    "end": "1285559"
  },
  {
    "text": "as we possibly can to make the ecosystem uh you know interrupt well with the python ecosystem so we have this Library",
    "start": "1285559",
    "end": "1293320"
  },
  {
    "text": "called Bumblebee which supports a lot of pre-trained uh machine learning models",
    "start": "1293320",
    "end": "1299159"
  },
  {
    "text": "in the in the python ecosystem so essentially what bumblebee is is it's very similar to the hugging face Transformers Library uh which has a ton",
    "start": "1299159",
    "end": "1306279"
  },
  {
    "text": "of pre-trained Transformer models and some other like computer vision based models like reset and whatnot and um we",
    "start": "1306279",
    "end": "1313159"
  },
  {
    "text": "built Bumblebee as kind of like an intermediary between ourselves and the python ecosystem so we're were able to",
    "start": "1313159",
    "end": "1318480"
  },
  {
    "text": "take uh pre-trained like pie torch models um convert them to what you would",
    "start": "1318480",
    "end": "1323600"
  },
  {
    "text": "need to use in Elixir and then use them directly in your elix applications and we also support a lot of the same uh",
    "start": "1323600",
    "end": "1330520"
  },
  {
    "text": "tasks as you could you would see in the python ecosystem so hugging face has like pipelines is what they call them we",
    "start": "1330520",
    "end": "1335640"
  },
  {
    "text": "call them servings uh these pipelines support anything from the dentity recognition to text classification to",
    "start": "1335640",
    "end": "1342000"
  },
  {
    "text": "image classification to text generation we support all those as well so um if you are working with the data science",
    "start": "1342000",
    "end": "1348360"
  },
  {
    "text": "team that you know they're not going to want to switch right away from using you know Elixir from using python to Elixir",
    "start": "1348360",
    "end": "1354360"
  },
  {
    "text": "so they can still work in in Python they train their models in Python and then uh as long as you have like trained or",
    "start": "1354360",
    "end": "1359880"
  },
  {
    "text": "saved weights uh you can kind of throw them over to your your backin team and they can they can write the inference",
    "start": "1359880",
    "end": "1366159"
  },
  {
    "text": "pipeline in Elixir so we're we're very intentionally I think uh you know friendly or try to be friendly and",
    "start": "1366159",
    "end": "1372360"
  },
  {
    "text": "supportive of the Python ecosystem because you know in some ways it's it's a necessity there's no reason to uh completely",
    "start": "1372360",
    "end": "1378600"
  },
  {
    "text": "uh disregard all of the incredible work that's been done in the python ecosystem because um it's just unrealistic to",
    "start": "1378600",
    "end": "1384360"
  },
  {
    "text": "think that we would be able to uh catch up with 30 plus years of of a head start in the space right um so we we try to",
    "start": "1384360",
    "end": "1391799"
  },
  {
    "text": "try to support interupt we also support um Onyx open neural network exchange so you can transfer or you can uh you can",
    "start": "1391799",
    "end": "1398919"
  },
  {
    "text": "essentially take uh Onyx models that you've trained you know in the python ecosystem and uh run them with some of",
    "start": "1398919",
    "end": "1404760"
  },
  {
    "text": "the NX abstractions so we have what's called like a storage only backend where you use the NX serving abstraction as a",
    "start": "1404760",
    "end": "1412279"
  },
  {
    "text": "way to implement an inference Pipeline and it's backed by the Onyx runtime so um there's there's a lot of reasons to",
    "start": "1412279",
    "end": "1418840"
  },
  {
    "text": "uh you know use Elixir without actually having to switch from using python yeah can we talk about some of",
    "start": "1418840",
    "end": "1426159"
  },
  {
    "text": "the use cases that you might have seen in bubblebee what what can this thing do",
    "start": "1426159",
    "end": "1431200"
  },
  {
    "text": "and where well first let's talk about what it can do yeah so bumblebee can do",
    "start": "1431200",
    "end": "1437400"
  },
  {
    "text": "a lot of the the same things that the hugging face Transformers Library can do so we support um a pretty large I would",
    "start": "1437400",
    "end": "1444320"
  },
  {
    "text": "say relative to to uh the size of the Transformers Library we have a pretty pretty large coverage of of the",
    "start": "1444320",
    "end": "1450640"
  },
  {
    "text": "pre-trained models at least the ones that uh are the most popular so you could take something like a pre-trained",
    "start": "1450640",
    "end": "1455840"
  },
  {
    "text": "Bert and you know do uh do text classification with that you can fine-tune the models and you know",
    "start": "1455840",
    "end": "1461919"
  },
  {
    "text": "pre-trained models from bubblebee for Downstream applications um we also support like I said these servings so um",
    "start": "1461919",
    "end": "1468399"
  },
  {
    "text": "one example that I've seen used is is in entity recognition um taking uh",
    "start": "1468399",
    "end": "1474399"
  },
  {
    "text": "essentially extracting like proper nouns out of some structured or unstructured data like text uh and identifying like",
    "start": "1474399",
    "end": "1481480"
  },
  {
    "text": "hey this is a person this is a place this is uh you know an organization um",
    "start": "1481480",
    "end": "1487320"
  },
  {
    "text": "and then we also support like text generation so we do support some of the uh latest and greatest uh chat models",
    "start": "1487320",
    "end": "1494360"
  },
  {
    "text": "out there so llama for example is one of the ones that we do support um you can build on large language models in Elixir",
    "start": "1494360",
    "end": "1502000"
  },
  {
    "text": "without having to actually you know shell out the python or something else so there are a lot of very powerful applications and one of the strengths of",
    "start": "1502000",
    "end": "1508640"
  },
  {
    "text": "Bumblebee is that it's a very low code I would say library so you know getting up",
    "start": "1508640",
    "end": "1513760"
  },
  {
    "text": "and running with a text generation pipeline is probably like four lines of code and and you're ready to go um and",
    "start": "1513760",
    "end": "1520000"
  },
  {
    "text": "that's pretty powerful especially for us because in the Elixir ecosystem we don't have a ton of people with machine learning experience so bumblebee is able",
    "start": "1520000",
    "end": "1526720"
  },
  {
    "text": "to to give them access to like a quick win you I've talked to a number of people who have started to make some",
    "start": "1526720",
    "end": "1532320"
  },
  {
    "text": "bumblebee contributions they said it's it's really remarkably easy so it seems",
    "start": "1532320",
    "end": "1538039"
  },
  {
    "text": "like once again the abstractions are are good yep and Bumblebee builds it's it's",
    "start": "1538039",
    "end": "1543559"
  },
  {
    "text": "an 100% Elixir Library so really the only libraries we have that touch any",
    "start": "1543559",
    "end": "1549640"
  },
  {
    "text": "sort of native code are are you know compilers for NX um NX itself is a 100%",
    "start": "1549640",
    "end": "1555720"
  },
  {
    "text": "Elixir library and then it's the comp compilers that NX touches that are written in C and C++ and rust and some",
    "start": "1555720",
    "end": "1562399"
  },
  {
    "text": "of the other native languages but uh everything from NX to axon to bumblebee",
    "start": "1562399",
    "end": "1567440"
  },
  {
    "text": "it's 100% Elixir so it's a very approachable Library um the abstractions are are very I think easy to understand",
    "start": "1567440",
    "end": "1574679"
  },
  {
    "text": "once you kind of peel back the layers so it's very powerful so we've spent a little bit of",
    "start": "1574679",
    "end": "1580480"
  },
  {
    "text": "time embracing Python and I'm not going to say take your shot now but what are some of the things that elixir does that",
    "start": "1580480",
    "end": "1587919"
  },
  {
    "text": "may make it maybe even better for machine learning than some of the other machine learning languages yeah I think",
    "start": "1587919",
    "end": "1595080"
  },
  {
    "text": "the obvious one here is concurrency um python with with the uh the the Gill is",
    "start": "1595080",
    "end": "1601039"
  },
  {
    "text": "is it's kind of difficult to achieve the same I would say level of uh concurrency that you you can achieve in Elixir",
    "start": "1601039",
    "end": "1607440"
  },
  {
    "text": "application Elixir is really really good for building like robust uh fault tolerant concurrent highly concurrent",
    "start": "1607440",
    "end": "1614080"
  },
  {
    "text": "applications um one of the things that originally drew me to uh trying to do machine learning in Elixir was uh",
    "start": "1614080",
    "end": "1620919"
  },
  {
    "text": "there's a book from the pragmatic bookshelf as well concurrent data processing in Elixir and it's about",
    "start": "1620919",
    "end": "1626039"
  },
  {
    "text": "building these like robust uh uh data pipelines highly concurrent data",
    "start": "1626039",
    "end": "1631080"
  },
  {
    "text": "pipelines and uh that's something that you see a lot in machine learning workloads and achieving some of the the",
    "start": "1631080",
    "end": "1638840"
  },
  {
    "text": "same I guess throughput that you would you would get in the the python ecosystem the electure ecosystem is just trivial um there's a lot of like",
    "start": "1638840",
    "end": "1645120"
  },
  {
    "text": "abstractions in the python ecosystem that are essentially just like wrappers around C and C++ uh implementations",
    "start": "1645120",
    "end": "1653480"
  },
  {
    "text": "whereas uh you know you don't have to do the same thing in the Electric System so for example like tf. dat is is a data",
    "start": "1653480",
    "end": "1660640"
  },
  {
    "text": "input pipeline uh for for uh tensorflow and the same exact things you can do in",
    "start": "1660640",
    "end": "1667799"
  },
  {
    "text": "tf. data you can just do natively with Elixir because it just supports this you know concurrent data processing out of",
    "start": "1667799",
    "end": "1673679"
  },
  {
    "text": "the box um and then a lot of the the like the you know OTP abstractions in",
    "start": "1673679",
    "end": "1680159"
  },
  {
    "text": "Elixir are I would say very very well suited for building these like robust",
    "start": "1680159",
    "end": "1686200"
  },
  {
    "text": "machine learning applications so I'm just now because I you know I was not getting into the language I liked Elixir",
    "start": "1686200",
    "end": "1692519"
  },
  {
    "text": "aesthetically uh but I didn't necessarily appreciate the OTP abstractions as much and now recently",
    "start": "1692519",
    "end": "1697960"
  },
  {
    "text": "I'm starting to get really into the the uh OTP abstractions and building more on",
    "start": "1697960",
    "end": "1703159"
  },
  {
    "text": "what the language is designed to do and seeing how how it you know connects really well with uh some of the things",
    "start": "1703159",
    "end": "1709080"
  },
  {
    "text": "you want to do in like the ml Ops life cycle which is you know the life cycle for deploying machine learning models and um trying to identify I guess use",
    "start": "1709080",
    "end": "1716039"
  },
  {
    "text": "cases for uh oh this is like you know really powerful and this is how this benefits the machine learning ecosystem",
    "start": "1716039",
    "end": "1721440"
  },
  {
    "text": "so uh there's a lot of things that I think elixir does better than python just out of you know the circumstances",
    "start": "1721440",
    "end": "1727799"
  },
  {
    "text": "of the language the language is designed for Telecom platforms right or build on top of a language designed for Telecom",
    "start": "1727799",
    "end": "1732880"
  },
  {
    "text": "platforms and uh it turns out those abstractions are also really good for building like robust web applications and so um that's one thing or those are",
    "start": "1732880",
    "end": "1740039"
  },
  {
    "text": "some of the things I think that elixir does just better than python as a consequence of of how it's built and",
    "start": "1740039",
    "end": "1745120"
  },
  {
    "text": "what about a mutability does that does that play a role or does the lack of immutability play a role in the way that",
    "start": "1745120",
    "end": "1752200"
  },
  {
    "text": "you've had to to build axon in layers versus the way you might have done it",
    "start": "1752200",
    "end": "1757320"
  },
  {
    "text": "with something like python yeah I think immutability is an interesting one because um for like mathematicians and",
    "start": "1757320",
    "end": "1763679"
  },
  {
    "text": "people who are coming from like an academic machine learning background uh the immutability and like the functional",
    "start": "1763679",
    "end": "1769799"
  },
  {
    "text": "style of writing things in Elixir kind of fits better with what uh you know you would be used to seeing like",
    "start": "1769799",
    "end": "1776120"
  },
  {
    "text": "mathematically um immutability I think helps a lot about you know reasoning about some of these uh more complex uh",
    "start": "1776120",
    "end": "1784080"
  },
  {
    "text": "highly concurrent uh data pipelines but then from like just the the I guess aesthetic perspective uh writing a",
    "start": "1784080",
    "end": "1791760"
  },
  {
    "text": "program a a numerical program functionally I think makes a lot more sense than uh some of the the things you",
    "start": "1791760",
    "end": "1798559"
  },
  {
    "text": "would do in the python ecosystem so like for example like um tensorflow and pytorch both support what are called in",
    "start": "1798559",
    "end": "1804600"
  },
  {
    "text": "place operations where essentially you have a buffer that's uh you have a tensor that's backed by some buffer and",
    "start": "1804600",
    "end": "1812000"
  },
  {
    "text": "you can perform like an inplace sort where that data is is completely changed",
    "start": "1812000",
    "end": "1817640"
  },
  {
    "text": "completely overwritten um and I've had you know experiences in in the python ecosystem where I do something in place",
    "start": "1817640",
    "end": "1823840"
  },
  {
    "text": "and then um you you get some pretty wonky result because you don't realize that you were mutating some data like",
    "start": "1823840",
    "end": "1830200"
  },
  {
    "text": "four or five lines up or you know somewhere at the beginning of the program uh you don't necessarily have that same exact problem in the Elixir",
    "start": "1830200",
    "end": "1836399"
  },
  {
    "text": "ecosystem because everything is immutable by default so um from a performance perspective it's something",
    "start": "1836399",
    "end": "1842679"
  },
  {
    "text": "that kind of hindered Elixir from from from the beginning because uh with immutability that obviously like kind of",
    "start": "1842679",
    "end": "1849519"
  },
  {
    "text": "implies some additional copies but with this comp compiler this jit compilation",
    "start": "1849519",
    "end": "1855960"
  },
  {
    "text": "concept that we introduced with NX uh we kind of completely bypass any of the",
    "start": "1855960",
    "end": "1861639"
  },
  {
    "text": "issues we have with immutability because um NX works on like a multi-staged programming model so when you write a",
    "start": "1861639",
    "end": "1868559"
  },
  {
    "text": "numerical definition uh it gets lowered to an NX expression and then that gets compiled into a program so it's not",
    "start": "1868559",
    "end": "1875279"
  },
  {
    "text": "eager by default it's it's a very you know uh I would say static workflow and",
    "start": "1875279",
    "end": "1880320"
  },
  {
    "text": "so uh you don't necessarily have the same performance hits with immutability that you would if you were just you know",
    "start": "1880320",
    "end": "1887000"
  },
  {
    "text": "uh working natively in Elixir you just kind of carved down how much what what your primitive operations",
    "start": "1887000",
    "end": "1893960"
  },
  {
    "text": "are right you expand those a little bit and and and contract them in other places right that's that's pretty",
    "start": "1893960",
    "end": "1899919"
  },
  {
    "text": "cool so I have a couple more questions for you do you have some favorite moments on um of of when you know this",
    "start": "1899919",
    "end": "1908639"
  },
  {
    "text": "whole roller of where this whole roller coaster ride has taken you uh are there some favorite moments yeah there's",
    "start": "1908639",
    "end": "1914880"
  },
  {
    "text": "definitely a lot of like uh stories related to these projects um early on I don't think we like there was a lot of I",
    "start": "1914880",
    "end": "1921799"
  },
  {
    "text": "would say initial roadblocks to to success and like we we we have come a long way but in the beginning it was",
    "start": "1921799",
    "end": "1927600"
  },
  {
    "text": "there was not like a guarantee that the projects were going to work out it was kind of just more of an experiment so I can distinctly remember some of the",
    "start": "1927600",
    "end": "1933880"
  },
  {
    "text": "initial like trials and tribulations with these projects one for example was uh the first time we got a NX and to",
    "start": "1933880",
    "end": "1942600"
  },
  {
    "text": "like to compile a program to the GPU um that was a little rough so there I have",
    "start": "1942600",
    "end": "1948360"
  },
  {
    "text": "I go into a deep dive on on Twitter about this but uh the the airline virtual machine does some interesting",
    "start": "1948360",
    "end": "1954840"
  },
  {
    "text": "things like intentionally and uh when you're dealing with uh subprocesses",
    "start": "1954840",
    "end": "1960720"
  },
  {
    "text": "external programs um you can run into some problems so I I have a deep dive on Twitter about that but I I I do",
    "start": "1960720",
    "end": "1966360"
  },
  {
    "text": "distinctly remember it took like a few days to track down some issues we were having with you know why could we not compile a programs the GPU and then uh",
    "start": "1966360",
    "end": "1972679"
  },
  {
    "text": "we had kind of a breakthrough moment we're able to and I think it was the program we were compiling was just like one plus one or something simple like it",
    "start": "1972679",
    "end": "1978120"
  },
  {
    "text": "was nothing nothing crazy but that was that was pretty awesome when that first happened and then um I remember we had",
    "start": "1978120",
    "end": "1983960"
  },
  {
    "text": "some initial uh difficulties with um uh uh autograd so tray wrote a lot of the",
    "start": "1983960",
    "end": "1991760"
  },
  {
    "text": "uh autograd like infrastructure I think he honestly has probably Rewritten it like six or seven times uh in you know",
    "start": "1991760",
    "end": "1999000"
  },
  {
    "text": "the life of the project and uh I remember how just how frustrating it was at times to to get some of the things to",
    "start": "1999000",
    "end": "2004279"
  },
  {
    "text": "work because uh autograd is not necessarily automatic differentiation is not necessarily something that's like",
    "start": "2004279",
    "end": "2009519"
  },
  {
    "text": "straightforward to implement uh and straightforward to implement efficiently um so I remember the first nural Network",
    "start": "2009519",
    "end": "2015480"
  },
  {
    "text": "we trained when we finally got uh you know the automatic differentiation system working and we had written a a",
    "start": "2015480",
    "end": "2022279"
  },
  {
    "text": "pure NX neural network uh it was just trained on mest and I remember the I",
    "start": "2022279",
    "end": "2027399"
  },
  {
    "text": "think that was like maybe six or seven months into the project when that that first worked and that was that was pretty awesome um and then we also some",
    "start": "2027399",
    "end": "2035159"
  },
  {
    "text": "of the first benchmarks we had were you know we showed that the GPU compiled program with uh NX and exla were like",
    "start": "2035159",
    "end": "2042360"
  },
  {
    "text": "4,000 times faster than anything you can do uh natively in Elixir and sharing",
    "start": "2042360",
    "end": "2047440"
  },
  {
    "text": "some of those benchmarks and people were like this is crazy that's can't believe this is happening um that was a lot of",
    "start": "2047440",
    "end": "2052720"
  },
  {
    "text": "fun too yeah with the koi messaging you know this thing that we're working on is x%",
    "start": "2052720",
    "end": "2059560"
  },
  {
    "text": "faster that was kind of a lot of fun to watch too yep and and what about what",
    "start": "2059560",
    "end": "2065200"
  },
  {
    "text": "about some some moments that that um that were particularly frustrating for you um what would have been some of the",
    "start": "2065200",
    "end": "2071878"
  },
  {
    "text": "hard ones to break through you mentioned you mentioned the the earlier one with with kind of",
    "start": "2071879",
    "end": "2077638"
  },
  {
    "text": "establishing that that initial compilation but what were some of the other ones that were pretty difficult",
    "start": "2077639",
    "end": "2083079"
  },
  {
    "text": "yeah so um the GPU one in particular I just remember being incredibly frustrating so I guess like high level",
    "start": "2083079",
    "end": "2088800"
  },
  {
    "text": "essentially what was going on there is that to compile a a program to uh the",
    "start": "2088800",
    "end": "2094919"
  },
  {
    "text": "GPU specifically Nvidia GP gpus uh tensorflow and xlaa were using something called PTX which is like a Nvidia",
    "start": "2094919",
    "end": "2102800"
  },
  {
    "text": "assembler essentially um and they were calling it out from a subprocess using I",
    "start": "2102800",
    "end": "2108000"
  },
  {
    "text": "think like uh weight PID or something something particular um and there's like",
    "start": "2108000",
    "end": "2113880"
  },
  {
    "text": "something where on Linux systems the uh Airline virtual machine sets Sig child",
    "start": "2113880",
    "end": "2119800"
  },
  {
    "text": "to uh I think Sig ignore or something specific which essentially just results",
    "start": "2119800",
    "end": "2125680"
  },
  {
    "text": "in in uh the the calling process of of weight pit to completely like ignore the",
    "start": "2125680",
    "end": "2130839"
  },
  {
    "text": "result of the program and return negative one or something insane and like tracking that down took forever",
    "start": "2130839",
    "end": "2137000"
  },
  {
    "text": "like that and that's something that's that's pretty obscure about the the airling you know virtual machine that like only a few people would know off",
    "start": "2137000",
    "end": "2143560"
  },
  {
    "text": "the bat right um there was another very frustrating uh segmentation fault we",
    "start": "2143560",
    "end": "2149200"
  },
  {
    "text": "were getting with uh convolutions on Nvidia gpus and I remember just how",
    "start": "2149200",
    "end": "2154839"
  },
  {
    "text": "frustrating it was kind of working with Nvidia trying to figure out what the deal was and it turned out actually the the reason for the segmentation fault",
    "start": "2154839",
    "end": "2160800"
  },
  {
    "text": "was the default stack size for uh uh the the dirty nifs that we were using which",
    "start": "2160800",
    "end": "2166680"
  },
  {
    "text": "is kind of an A or an Elixir specific thing that the uh the dirty niffs we were using the default stack size was",
    "start": "2166680",
    "end": "2172119"
  },
  {
    "text": "too small um and I had talked to some of the core team uh for airling a few times",
    "start": "2172119",
    "end": "2178200"
  },
  {
    "text": "about this and they kept saying well if you just set the stack size a little bigger does it work and I was like yeah I've tried that it doesn't work but I",
    "start": "2178200",
    "end": "2183599"
  },
  {
    "text": "was setting the flag wrong or something so it took me like four or five months realized that I was setting the flag wrong and I think Nvidia had been",
    "start": "2183599",
    "end": "2189839"
  },
  {
    "text": "telling me the same thing too they were like well what's the stack size like is the stack size too small um so that was frustrating but that was probably more",
    "start": "2189839",
    "end": "2195920"
  },
  {
    "text": "frustrating for me to realize you know that I was making a silly mistake it was like a typo or something that that uh",
    "start": "2195920",
    "end": "2201319"
  },
  {
    "text": "and you know how frustrating it can be when you realize that you know and you have a typo in your code that's been contributing to a bug for like four or",
    "start": "2201319",
    "end": "2207760"
  },
  {
    "text": "five months now um that was frustrating and there's been some I guess difficult moments in in uh implementing like axon",
    "start": "2207760",
    "end": "2215560"
  },
  {
    "text": "so um I think we have the benefit of of being able to test against correct",
    "start": "2215560",
    "end": "2221440"
  },
  {
    "text": "implementations in pytorch and tensor flow but when you're implementing like numerical algorithms uh getting exact",
    "start": "2221440",
    "end": "2230480"
  },
  {
    "text": "like correctness numerical correctness is very very difficult like it very there's can be very subtle bugs that",
    "start": "2230480",
    "end": "2237000"
  },
  {
    "text": "just pop up and uh they have a drastic impact on the stability of like training",
    "start": "2237000",
    "end": "2243160"
  },
  {
    "text": "different models and the predictions you get with different models and so uh that can be very frustrating as well um I",
    "start": "2243160",
    "end": "2248800"
  },
  {
    "text": "remember we implemented so one of the things you can do with bumblebee is stable diffusion you can do image generation and I just remember working",
    "start": "2248800",
    "end": "2255880"
  },
  {
    "text": "for like two weeks straight trying to get uh the outputs we were getting from stable diffusion to match match like",
    "start": "2255880",
    "end": "2262200"
  },
  {
    "text": "within a very small Precision of of what you get in Python and I I also remember",
    "start": "2262200",
    "end": "2267960"
  },
  {
    "text": "like thinking how it insane or how you know how how how much admiration I have",
    "start": "2267960",
    "end": "2273800"
  },
  {
    "text": "for people that are Implement these algorithms from scratch without any reference implementation and without any uh any any reference tests or anything",
    "start": "2273800",
    "end": "2280760"
  },
  {
    "text": "to say like you know this is the correct implementation of whatever this uh algorithm is so uh those are always very",
    "start": "2280760",
    "end": "2286720"
  },
  {
    "text": "frustrating to try to track down those small bugs and numerical correctness so I have two two more",
    "start": "2286720",
    "end": "2294079"
  },
  {
    "text": "questions they basically wrapup questions one of them is uh make your",
    "start": "2294079",
    "end": "2299160"
  },
  {
    "text": "last pitch for machine learning with Elixir yeah so for I think those that",
    "start": "2299160",
    "end": "2305880"
  },
  {
    "text": "are uh deploying um well first I I honestly think that Elixir for machine",
    "start": "2305880",
    "end": "2311960"
  },
  {
    "text": "learning startups is probably the best language that you can have because you can do everything in Elixir um and not",
    "start": "2311960",
    "end": "2319079"
  },
  {
    "text": "just everything from like a machine learning perspective but also like from a like application development",
    "start": "2319079",
    "end": "2324119"
  },
  {
    "text": "perspective so um with live view you can you know write your front end in elixir with uh Phoenix you can write really",
    "start": "2324119",
    "end": "2330720"
  },
  {
    "text": "scalable backends with Elixir um you can have your entire you know inference pipeline written in Elixir and it's it's",
    "start": "2330720",
    "end": "2336720"
  },
  {
    "text": "fall tolerant and scalable uh you can train your models in Elixir you can deploy your models in Elixir and I think",
    "start": "2336720",
    "end": "2343400"
  },
  {
    "text": "for a startup that's you know underman or or you know not necessarily doesn't necessarily have large teams you can",
    "start": "2343400",
    "end": "2349640"
  },
  {
    "text": "build at a a very high velocity I think that's something that you just don't necessarily get from another ecosystem",
    "start": "2349640",
    "end": "2354920"
  },
  {
    "text": "so if I was a small team that that is obvious I think that would that would be the first language I would I would reach",
    "start": "2354920",
    "end": "2361240"
  },
  {
    "text": "for would be you know building an application in The Elixir because you can punch above your weight",
    "start": "2361240",
    "end": "2367000"
  },
  {
    "text": "I like that so you take JavaScript off the table you take python off the table and you you centralize everything on one",
    "start": "2367000",
    "end": "2373800"
  },
  {
    "text": "language that's that's wonderful and I have one last question is there anything else that you want your listeners to",
    "start": "2373800",
    "end": "2379640"
  },
  {
    "text": "know what's coming up what's happening yeah so um I guess on on we've kind of",
    "start": "2379640",
    "end": "2386280"
  },
  {
    "text": "ranted a little bit about machine learning Elixir but I definitely want my my uh the listeners to know if you're if you're not familiar with the machine",
    "start": "2386280",
    "end": "2391960"
  },
  {
    "text": "learning in lir ecosystem we have I think the perfect uh treat for you so I just recently released a book machine",
    "start": "2391960",
    "end": "2397800"
  },
  {
    "text": "learning in Elixir uh it's out in beta now where you can learn the fundamentals of the machine learning ecosystem uh in",
    "start": "2397800",
    "end": "2406119"
  },
  {
    "text": "Elixir from the ground up so if you're not familiar with Elixir you can it's a great way to learn the language and then",
    "start": "2406119",
    "end": "2412040"
  },
  {
    "text": "if you are familiar with Elixir and you're not familiar with machine learning then it's a great way to learn machine learning um machine learning in",
    "start": "2412040",
    "end": "2417119"
  },
  {
    "text": "Elixir is I would say designed to be the authoritative Source on everything you can do with machine learning and elixir",
    "start": "2417119",
    "end": "2423880"
  },
  {
    "text": "um and it's got a lot of inspiration from some of my favorite machine learning books such as uh you know France Wash's deep learning in Python",
    "start": "2423880",
    "end": "2430440"
  },
  {
    "text": "was kind of the the first book I ever read in machine learning and then um some of the other really popular machine",
    "start": "2430440",
    "end": "2436000"
  },
  {
    "text": "learning textbooks out there like deep learning uh by Ian Goodfellow and yosua Benjo and uh the other co-authors they",
    "start": "2436000",
    "end": "2441800"
  },
  {
    "text": "have there so um I would highly recommend any listeners of these to go check out that book um send me any Arata",
    "start": "2441800",
    "end": "2448800"
  },
  {
    "text": "you find because it is in beta so obviously there's going to be some issues as we upgrade the libraries and",
    "start": "2448800",
    "end": "2453839"
  },
  {
    "text": "and things change but um yeah that's I think that's that's really the one of my key focuses now is just building out",
    "start": "2453839",
    "end": "2460200"
  },
  {
    "text": "some of the educational material for uh people in the ecosystem to to kind of you know cut their teeth",
    "start": "2460200",
    "end": "2465760"
  },
  {
    "text": "on wonderful that's a beautiful cap going from genetic algorithms all the way to machine learning and elixir and",
    "start": "2465760",
    "end": "2473079"
  },
  {
    "text": "uh so for Bruce and Sean we've been talking for the go-to book club and",
    "start": "2473079",
    "end": "2479319"
  },
  {
    "text": "we're signing off thank you thank you everyone thanks for listening to this episode of the go-to podcast head over",
    "start": "2479319",
    "end": "2486040"
  },
  {
    "text": "to cop. Tech to discover lots more content from the brightest minds and software",
    "start": "2486040",
    "end": "2492280"
  },
  {
    "text": "[Music]",
    "start": "2493910",
    "end": "2501920"
  },
  {
    "text": "development",
    "start": "2501920",
    "end": "2504920"
  }
]
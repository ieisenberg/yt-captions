[
  {
    "start": "0",
    "end": "181000"
  },
  {
    "text": "thank you for the absolutely lovely introduction um so I did give a version",
    "start": "12759",
    "end": "17920"
  },
  {
    "text": "of this talk um it's changed quite a bit between then and now in Porto last year",
    "start": "17920",
    "end": "23640"
  },
  {
    "text": "um so thank you so much for coming to this talk slot um as Adele said my name",
    "start": "23640",
    "end": "28679"
  },
  {
    "text": "is Jody Burell and I'm currently working as a developer advocate in jet brains all nicely branded today I've been a",
    "start": "28679",
    "end": "35280"
  },
  {
    "text": "data scientist for almost 10 years and a big chunk of my career I actually spent in NLP kind of a funny story about that",
    "start": "35280",
    "end": "42840"
  },
  {
    "text": "one of the jobs that I worked at in NLP when I left we were starting to work with early large language models like",
    "start": "42840",
    "end": "49640"
  },
  {
    "text": "Bert and I have friends who are still working there and one of them reached out to me a couple of months ago and",
    "start": "49640",
    "end": "54920"
  },
  {
    "text": "said the CEO has been in contact with our team and he wanted to know what we're doing about working with a",
    "start": "54920",
    "end": "60559"
  },
  {
    "text": "I and he's like dude we've been doing that for the last like seven years so",
    "start": "60559",
    "end": "66439"
  },
  {
    "text": "confusion abounds so prior to my career as a data scientist I actually did my",
    "start": "66439",
    "end": "71640"
  },
  {
    "text": "PhD in Psychology so you can imagine that I've been watching this space with",
    "start": "71640",
    "end": "77200"
  },
  {
    "text": "a lot of interest but I've also been watching it with a lot of concern and",
    "start": "77200",
    "end": "83159"
  },
  {
    "text": "one of the biggest areas where I've sort of been having concern is about the",
    "start": "83159",
    "end": "88799"
  },
  {
    "text": "messaging around large language models so what I want to do in this talk is take a much more measured look at this",
    "start": "88799",
    "end": "95560"
  },
  {
    "text": "talk uh sorry at this area and cut through the hype a bit so for the past two years no big",
    "start": "95560",
    "end": "102560"
  },
  {
    "text": "surprise we've been in a full-on AI hype cycle I'm actually surprised you came to my talk about llms because I'm quite",
    "start": "102560",
    "end": "109719"
  },
  {
    "text": "sure everyone's sick of hearing about them at this point so we've had claims that range from Models like Lambda",
    "start": "109719",
    "end": "116399"
  },
  {
    "text": "showing sentience to speculation that huge s of the white collar job market",
    "start": "116399",
    "end": "121600"
  },
  {
    "text": "are going to be replaced by generative models to even doomsday claims that we",
    "start": "121600",
    "end": "127600"
  },
  {
    "text": "have an AI apocalypse on the horizon so it's been an absolutely overwhelming flood of opinions idea and speculation",
    "start": "127600",
    "end": "136360"
  },
  {
    "text": "so naturally for most people it's really hard to know what to think about these models are they actually useful or are",
    "start": "136360",
    "end": "142160"
  },
  {
    "text": "they just fun toys are they just a gimmick what can we realistically use them for and are they really going to",
    "start": "142160",
    "end": "148800"
  },
  {
    "text": "replace or destroy us so what we're going to be doing over the next 40 minutes is cutting through the",
    "start": "148800",
    "end": "154599"
  },
  {
    "text": "hype and looking at the actual applications and limitations of these models we're going to see the context",
    "start": "154599",
    "end": "159959"
  },
  {
    "text": "and the science behind these models and we're going to challenge some of the more outrageous claims such as we're on",
    "start": "159959",
    "end": "165640"
  },
  {
    "text": "the path to artificial general intelligence or AGI with these models and obviously with a 40 to 50 minute",
    "start": "165640",
    "end": "172000"
  },
  {
    "text": "time slot I've had to leave out a lot um I think we should have a few minutes for questions at the end so please do send",
    "start": "172000",
    "end": "177720"
  },
  {
    "text": "them through the app or come and find me after afterwards so for a lot of people models",
    "start": "177720",
    "end": "184000"
  },
  {
    "start": "181000",
    "end": "815000"
  },
  {
    "text": "like chat GPT 3.5 and 4 felt like they came out of nowhere but naturally",
    "start": "184000",
    "end": "189720"
  },
  {
    "text": "they're part of a long history of research in this field specifically in the area that I mentioned of natural",
    "start": "189720",
    "end": "194920"
  },
  {
    "text": "language processing so the interesting thing about these models is that the generation of text was not the original",
    "start": "194920",
    "end": "201840"
  },
  {
    "text": "aim of earlier models in this field it was to build models that could automate tasks with text that require huge",
    "start": "201840",
    "end": "209040"
  },
  {
    "text": "amounts of man labor things like text classification or summarization so let's have a look at how this journey",
    "start": "209040",
    "end": "216519"
  },
  {
    "text": "evolved so large language models all belong to a type of model called neural",
    "start": "216519",
    "end": "222159"
  },
  {
    "text": "Nets and these were originally proposed of as a way of artificially mimicking",
    "start": "222159",
    "end": "227439"
  },
  {
    "text": "the human brain so research in this area started in the 1940s and when in stops",
    "start": "227439",
    "end": "233200"
  },
  {
    "text": "and starts up until sort of the 1980s where a number of important technological limitations were",
    "start": "233200",
    "end": "240439"
  },
  {
    "text": "overcome however the practical application of neural Nets was limited",
    "start": "240439",
    "end": "245560"
  },
  {
    "text": "even up to the start of the 21st century and this is because these models have really intense computing power",
    "start": "245560",
    "end": "251879"
  },
  {
    "text": "requirements so researchers found the larger they made these models the more they can learn about their input data",
    "start": "251879",
    "end": "258720"
  },
  {
    "text": "and the more accurate or sophisticated their predictions can be but this requires the use of processing units",
    "start": "258720",
    "end": "264479"
  },
  {
    "text": "that are really efficient at doing huge amounts of matrix multiplication hence you hear all these mentioned of linear",
    "start": "264479",
    "end": "270240"
  },
  {
    "text": "algebra in this area so this leads us to our first breakthrough on the path to large language models which was the",
    "start": "270240",
    "end": "276639"
  },
  {
    "text": "development of Cuda so Cuda allowed us to transform gpus into allpurpose matrix",
    "start": "276639",
    "end": "283400"
  },
  {
    "text": "multiplication machines and therefore make the training of large neural Nets much more",
    "start": "283400",
    "end": "289800"
  },
  {
    "text": "feasible as you increase the size of neural Nets they also become unsurprisingly much more data hungry so",
    "start": "289800",
    "end": "296400"
  },
  {
    "text": "therefore the next big advancement was the development of a data set called common crawl this is a huge dump of",
    "start": "296400",
    "end": "303360"
  },
  {
    "text": "frequently linked pages on the internet and the development of common crawl meant that researchers now had",
    "start": "303360",
    "end": "309400"
  },
  {
    "text": "sufficient Text data to start training more and more complex language models and the final step was",
    "start": "309400",
    "end": "316000"
  },
  {
    "text": "Innovations on the modeling side so despite early predictions that this would be an easy problem working with",
    "start": "316000",
    "end": "322319"
  },
  {
    "text": "text turned out to be quite complicated even with all of this nice computing power and all of this data that we now",
    "start": "322319",
    "end": "328479"
  },
  {
    "text": "had so language is really complex and it's highly context dependent so it took",
    "start": "328479",
    "end": "333639"
  },
  {
    "text": "some time to develop a type of neural net that could actually capture these sort of relationships between words and",
    "start": "333639",
    "end": "339639"
  },
  {
    "text": "this also happened in 2007 the same year that common CW was developed with the development of a type of neural net",
    "start": "339639",
    "end": "345440"
  },
  {
    "text": "called long short-term memory networks or lstms we're not amazing at naming things in this area you may have noticed",
    "start": "345440",
    "end": "351800"
  },
  {
    "text": "that not a very catchy name so these models were one of the first to really",
    "start": "351800",
    "end": "357120"
  },
  {
    "text": "understand words in their context sentences and therefore they were able to vastly outperform previous models on",
    "start": "357120",
    "end": "363440"
  },
  {
    "text": "a range of tasks so of course they were better at uh text generation than previous models but they were also one",
    "start": "363440",
    "end": "370199"
  },
  {
    "text": "of the first general purpose natural language processing models they were capable of doing a range of tasks like",
    "start": "370199",
    "end": "377319"
  },
  {
    "text": "text classification summarization and translation and in fact you may have noticed that Google translate suddenly",
    "start": "377319",
    "end": "383479"
  },
  {
    "text": "got a lot better in 2016 this is because we started using lstms under the hood",
    "start": "383479",
    "end": "389759"
  },
  {
    "text": "however a major limitation of lstms is that they're forced to process words in a piece of text sequentially so what",
    "start": "389759",
    "end": "396160"
  },
  {
    "text": "they do is they process the first word they remember something about it they process the second word they add that",
    "start": "396160",
    "end": "402160"
  },
  {
    "text": "information to this memory and so on and so forth so this caused a number of problems but the biggest of these is it",
    "start": "402160",
    "end": "408400"
  },
  {
    "text": "led to problems with scaling these models limiting how big researchers could feasibly make them so the models",
    "start": "408400",
    "end": "414479"
  },
  {
    "text": "that solve this are of course Transformer models you would have heard this term everywhere this type of model",
    "start": "414479",
    "end": "420479"
  },
  {
    "text": "avoids this sequentially Pro sequential processing and therefore allows models to get really huge and a really cool",
    "start": "420479",
    "end": "427560"
  },
  {
    "text": "thing about Transformer models is as part of their training they learn really rich internal representations of how",
    "start": "427560",
    "end": "433720"
  },
  {
    "text": "language works and therefore they're of course generalist models they're able to do a range of NLP tasks that they were",
    "start": "433720",
    "end": "439919"
  },
  {
    "text": "not explicitly trained to do so this has kicked off the current generation of text processing models and this is why",
    "start": "439919",
    "end": "446800"
  },
  {
    "text": "we can have the large in large language models so the branch of Transformer models that evolved into generative or",
    "start": "446800",
    "end": "453039"
  },
  {
    "text": "Auto regressive models are the generative pre-trained Transformers or gpts and the first of these came out in",
    "start": "453039",
    "end": "460440"
  },
  {
    "text": "2018 so gpts have been a very successful type of model and pretty much every",
    "start": "460440",
    "end": "465720"
  },
  {
    "text": "single one of the many many many many large language models released in the last three years have a GPT based",
    "start": "465720",
    "end": "472599"
  },
  {
    "text": "architecture including Heavy Hitters that you would have heard of like chat GPT GPT 4 Falcon mistal 7B",
    "start": "472599",
    "end": "480120"
  },
  {
    "text": "Gemini and Claude so now that we have an understanding of the recent history of",
    "start": "480120",
    "end": "485720"
  },
  {
    "text": "large language models and some of the foundations that they're built on let's have a closer look at the GPT models so",
    "start": "485720",
    "end": "492159"
  },
  {
    "text": "we're obviously not going to look at every variant I just showed you we'd be here for the rest of the talk doing that but what we're going to do is have a",
    "start": "492159",
    "end": "498240"
  },
  {
    "text": "look at the group of models developed by open AI because they were the ones who came up with the first GPT",
    "start": "498240",
    "end": "504000"
  },
  {
    "text": "model so one of the most interesting problems for natural language processing is machine translation and this was the",
    "start": "504000",
    "end": "511800"
  },
  {
    "text": "first major use case for Transformer models so in order to do translation between two languages Transformer based",
    "start": "511800",
    "end": "519440"
  },
  {
    "text": "model needs two components an encoder and a decoder so the role of the encoder",
    "start": "519440",
    "end": "525440"
  },
  {
    "text": "is to learn everything it can about the source language and send that information over to the decoder now",
    "start": "525440",
    "end": "532440"
  },
  {
    "text": "decoder's job is a bit more complex it needs to learn everything it can about how the target language functions but",
    "start": "532440",
    "end": "538920"
  },
  {
    "text": "then it also needs to use that information sent over by the encoder and try to predict word by word the most",
    "start": "538920",
    "end": "545880"
  },
  {
    "text": "likely matching sequence in the target language so you can see that in this example here let's say we have the",
    "start": "545880",
    "end": "552240"
  },
  {
    "text": "sentence I have visited Italy in English and we want to translate it to German so",
    "start": "552240",
    "end": "557760"
  },
  {
    "text": "encoder will have learned a whole bunch about how the English language functions now decoder will have learned a whole bunch about how German functions so our",
    "start": "557760",
    "end": "565120"
  },
  {
    "text": "sentence is first processed by the encoder and then word by word the Dakota will generate the most likely matching",
    "start": "565120",
    "end": "572000"
  },
  {
    "text": "sequence in German however something that researchers quickly realized is that",
    "start": "572000",
    "end": "578040"
  },
  {
    "text": "Dakota units all on their own are pretty useful so as we discussed a Dakota's whole job is to learn the ins and outs",
    "start": "578040",
    "end": "584399"
  },
  {
    "text": "of how a target language works and use that knowledge to predict the next word in a sequence based on an input so",
    "start": "584399",
    "end": "592160"
  },
  {
    "text": "researcher started to think well what if we cut out this Source language we cut out the encoder and we just Train",
    "start": "592160",
    "end": "597240"
  },
  {
    "text": "encoders by asking them to predict the next word in the same language what we can do is train these models by showing",
    "start": "597240",
    "end": "604120"
  },
  {
    "text": "the millions of words in the same language and get them to adjust their predictions based on whether they can",
    "start": "604120",
    "end": "609680"
  },
  {
    "text": "successfully predict the next word or not and we then end up with as a result with a model that has a pretty good idea",
    "start": "609680",
    "end": "616240"
  },
  {
    "text": "of the next most likely words to come in based on a given text input so we can",
    "start": "616240",
    "end": "621959"
  },
  {
    "text": "see that with this example here we have the two words as an input I have and the",
    "start": "621959",
    "end": "627120"
  },
  {
    "text": "model has learned the probability of the next word and the next word after that and so on and so",
    "start": "627120",
    "end": "633279"
  },
  {
    "text": "forth now interestingly this was initially not a huge break for through because of its ability to generate text",
    "start": "633279",
    "end": "640240"
  },
  {
    "text": "but because it's solved the problem of where to get enough data to train these really huge models as I said the bigger",
    "start": "640240",
    "end": "646240"
  },
  {
    "text": "you make neural Nets the more data hungry they get so the problem with training most models this is machine",
    "start": "646240",
    "end": "651639"
  },
  {
    "text": "learning models across the board it's not uh unique to llms is you often need to manually prepare the data in some way",
    "start": "651639",
    "end": "658040"
  },
  {
    "text": "it might be labeling data or pairing things up for example and obviously if you want to make really really really",
    "start": "658040",
    "end": "664000"
  },
  {
    "text": "huge data sets this gets really costly or potentially unfeasible but this problem is solved if",
    "start": "664000",
    "end": "670079"
  },
  {
    "text": "you're basically using a sentence as both the input and the output you just need to cut the sentence at a point use",
    "start": "670079",
    "end": "676160"
  },
  {
    "text": "the beginning of the sentence as your input and you use the next word as your Target and this gives you a ready-made",
    "start": "676160",
    "end": "681959"
  },
  {
    "text": "training set which scales very easily so this was the basis of the GPT",
    "start": "681959",
    "end": "687360"
  },
  {
    "text": "models and along with that beautiful scalable Transformer architecture is the secret of how these models have been",
    "start": "687360",
    "end": "693360"
  },
  {
    "text": "able to grow so big so the way these models work is they roughly increase their size by stacking decoda units it's",
    "start": "693360",
    "end": "700560"
  },
  {
    "text": "not exactly how they work but this is the general idea and what this does is it increases the number of model",
    "start": "700560",
    "end": "705920"
  },
  {
    "text": "parameters so this is the size of the models so the first GPT was 120 million",
    "start": "705920",
    "end": "712000"
  },
  {
    "text": "parameters which seems quaint at this point the second was 13 times that size",
    "start": "712000",
    "end": "717720"
  },
  {
    "text": "at 1.5 billion parameters and you can see the models have just kept growing and growing up to gp4 which",
    "start": "717720",
    "end": "724040"
  },
  {
    "text": "is estimated to be at around a trillion parameters and I left GPT 4 out o out I",
    "start": "724040",
    "end": "729399"
  },
  {
    "text": "just can't keep up with all this stuff so I was like you're staying off this slide so the models have grown over",
    "start": "729399",
    "end": "735680"
  },
  {
    "text": "successive generations to be better and better at a range of natural language tasks and we can get a sense of how the",
    "start": "735680",
    "end": "741760"
  },
  {
    "text": "models have evolved by seeing how they each respond to the same prompt complete this sentence Belgium is apologies to",
    "start": "741760",
    "end": "748959"
  },
  {
    "text": "any belgians in the audience I'm not taking the piss but uh you know this is just the one I've been using for for",
    "start": "748959",
    "end": "755639"
  },
  {
    "text": "about a year so okay so gpt1 is really good at generating text which is",
    "start": "755639",
    "end": "761959"
  },
  {
    "text": "grammatically correct but there's no real sense of context so this is what gpt1 came up with for our prompt which",
    "start": "761959",
    "end": "768920"
  },
  {
    "text": "the best you can say about it is it's grammatically correct now gpt2 is a bit more polished",
    "start": "768920",
    "end": "776800"
  },
  {
    "text": "than gpt1 but it still tends to come up with really output so here is gpt2",
    "start": "776800",
    "end": "783440"
  },
  {
    "text": "attempt so gpt3 is where the models start learning not only grammar but they",
    "start": "785199",
    "end": "790360"
  },
  {
    "text": "start encoding some information about the words that they're trained on so here's gpt3 is attempt it's gives us a",
    "start": "790360",
    "end": "796720"
  },
  {
    "text": "nice little sentence which not only makes sense but it actually gives us on context uh on topic information and then",
    "start": "796720",
    "end": "803199"
  },
  {
    "text": "finally when I put this into chat GPT 3.5 it wrote a whole bloody essay I had",
    "start": "803199",
    "end": "808600"
  },
  {
    "text": "to cut it off but it kept going on about multilingualism and comic books would have gone on",
    "start": "808600",
    "end": "814760"
  },
  {
    "text": "forever so now we know where llms have come from and we've explored how they work under the hood a bit let's turn to",
    "start": "814760",
    "end": "822000"
  },
  {
    "start": "815000",
    "end": "1649000"
  },
  {
    "text": "how these models are being perceived in both the tech world and Beyond so as we've discussed these models now exist",
    "start": "822000",
    "end": "829040"
  },
  {
    "text": "in a hype cycle which makes claims about them that goes far beyond their original purpose as generalist natural language",
    "start": "829040",
    "end": "836600"
  },
  {
    "text": "processing models and the most sensationalized of these claims as I said at the beginning is that llms are",
    "start": "836600",
    "end": "841880"
  },
  {
    "text": "showing signs of artificial general intelligence or AGI so these claims of AGI have run the",
    "start": "841880",
    "end": "848519"
  },
  {
    "text": "gamut and they've been backed up actually by some of the most respected researchers in the field like Jeffrey",
    "start": "848519",
    "end": "854160"
  },
  {
    "text": "Hinton one of the so-called three Godfathers of AI or backed up by papers",
    "start": "854160",
    "end": "859279"
  },
  {
    "text": "from Microsoft research so with all these people throwing their weight behind the idea of lm's showing AGI how",
    "start": "859279",
    "end": "867800"
  },
  {
    "text": "can we be sure that these model haven't developed intelligence so let's go back to May of",
    "start": "867800",
    "end": "873920"
  },
  {
    "text": "1997 when then World chess champion Gary Kasparov was playing deep blue IBM's uh",
    "start": "873920",
    "end": "880680"
  },
  {
    "text": "chess playing Ai and this was the second time that they' faced each other so in the second game of the match deep blue",
    "start": "880680",
    "end": "887759"
  },
  {
    "text": "made an unexpected move and this rattled Casper of and it made him believe that the model was far more sophisticated or",
    "start": "887759",
    "end": "894800"
  },
  {
    "text": "advanced than it actually was so thrown off his game he actually ended up losing this game then he lost the third then he lost the",
    "start": "894800",
    "end": "901720"
  },
  {
    "text": "fourth he lost the whole match and the Press went crazy speculating that if we",
    "start": "901720",
    "end": "907160"
  },
  {
    "text": "could solve chess with artificial systems then surely AGI was just around the corner but as you can see from this",
    "start": "907160",
    "end": "914480"
  },
  {
    "text": "incredible you know quality of this screen capture uh that was almost 30 years ago and we can see how those",
    "start": "914480",
    "end": "920720"
  },
  {
    "text": "predictions panned out the problem with trying to assess intelligent in this manner is that it",
    "start": "920720",
    "end": "926639"
  },
  {
    "text": "confuses the output of an AI syst system with the mechanism that the system took",
    "start": "926639",
    "end": "931800"
  },
  {
    "text": "to get there so we can use these skill-based Assessments in humans",
    "start": "931800",
    "end": "937440"
  },
  {
    "text": "because we know that in humans the ability to demonstrate significant skill in an area is reflective of an",
    "start": "937440",
    "end": "943800"
  },
  {
    "text": "underlying Raw General ability machine learning or AI models they don't work",
    "start": "943800",
    "end": "949319"
  },
  {
    "text": "this way they try to optimize for their training goals and if they can take shortcuts to get to good performance on",
    "start": "949319",
    "end": "955319"
  },
  {
    "text": "those goals they absolutely will the mistake is thinking that the pathway required to learn some skill for a",
    "start": "955319",
    "end": "962480"
  },
  {
    "text": "machine learning model including llms requires the development of an underlying",
    "start": "962480",
    "end": "968399"
  },
  {
    "text": "intelligence this illusion of skill-based intelligence is so well known it actually has a name the kaggle",
    "start": "968399",
    "end": "973920"
  },
  {
    "text": "effect after the well-known machine learning competition website so on this website people compete to create an",
    "start": "973920",
    "end": "980839"
  },
  {
    "text": "algorithm that can best complete some sort of task and the winning Solutions are so good at doing this specific task",
    "start": "980839",
    "end": "987560"
  },
  {
    "text": "that while they're doing it they seem to show a sort of intelligence but as soon as you try to get them to predict on",
    "start": "987560",
    "end": "994120"
  },
  {
    "text": "some sort of example that's too far outside of what they were trained on they fail they show",
    "start": "994120",
    "end": "999399"
  },
  {
    "text": "brittleness and this is a problem plaguing the current assessment of intelligence in llms they focus very",
    "start": "999399",
    "end": "1005920"
  },
  {
    "text": "strongly on how these models perform in specific tasks ignoring how intelligence is actually defined and measured in",
    "start": "1005920",
    "end": "1012040"
  },
  {
    "text": "humans and this is because while researchers in these areas are very very well established in their fields their",
    "start": "1012040",
    "end": "1018040"
  },
  {
    "text": "fields are things like Computer Sciences physics mathematics or engineering not",
    "start": "1018040",
    "end": "1024199"
  },
  {
    "text": "psychology so let's have a look at an example that shows why these skill-based assessments are a problem so if you",
    "start": "1024199",
    "end": "1030959"
  },
  {
    "text": "remember back to the beginning of last year one of the biggest hype topics especially after GPT 4 came out was that",
    "start": "1030959",
    "end": "1036678"
  },
  {
    "text": "this model was able to solve medical and law exams and there was all these claims that this model was going to replace",
    "start": "1036679",
    "end": "1042959"
  },
  {
    "text": "doctors and lawyers and then they came for us the model started solving leak code problems and then they started",
    "start": "1042959",
    "end": "1049160"
  },
  {
    "text": "saying these models are going to replace programmers so let's take a closer look at this last claim so there's really",
    "start": "1049160",
    "end": "1056400"
  },
  {
    "text": "great example circulating on Twitter around the time that GPT 4 came out so there this guy called Horus Haye and he",
    "start": "1056400",
    "end": "1063200"
  },
  {
    "text": "tested out GPT 4 with some coding problems from a website called code forces and what made code forces really",
    "start": "1063200",
    "end": "1070200"
  },
  {
    "text": "good for this particular little experiment is the date that each coding problem um was released is actually",
    "start": "1070200",
    "end": "1077640"
  },
  {
    "text": "timestamped so so what he did is he collected 10 puzzles that were released at the time that gp4 was being trained",
    "start": "1077640",
    "end": "1084120"
  },
  {
    "text": "so potentially it could have been in their training data he ran them through GPT 4 and well' you know gp4 got all of",
    "start": "1084120",
    "end": "1091480"
  },
  {
    "text": "them right congrats it's coming for our jobs but then what he did is he collected another 10 puzzles that were",
    "start": "1091480",
    "end": "1098039"
  },
  {
    "text": "released after gp4 was trained these were of an equivalent level of difficulty but this time GPT 4 got every",
    "start": "1098039",
    "end": "1106600"
  },
  {
    "text": "single one of them wrong so what happened well this raised a lot of",
    "start": "1106600",
    "end": "1111840"
  },
  {
    "text": "suspicions that GPT 4 was only able to solve these puzzles because they're in the training data and he just memorized",
    "start": "1111840",
    "end": "1118679"
  },
  {
    "text": "them so another researcher Sayes kapore tested this explicitly by asking gp4",
    "start": "1118679",
    "end": "1124240"
  },
  {
    "text": "about a code Force's puzzle that was available at the time it was trained and obligingly gbt 4 vomited up the complete",
    "start": "1124240",
    "end": "1131840"
  },
  {
    "text": "Source confirming that it did indeed have code Force's puzzles in the training data so I think this is a",
    "start": "1131840",
    "end": "1137960"
  },
  {
    "text": "really neat example that these skill-based assessments of intelligence in llms can be wildly misleading instead",
    "start": "1137960",
    "end": "1144559"
  },
  {
    "text": "we need to look to how well these systems can solve tasks they've never seen before that is how well can these",
    "start": "1144559",
    "end": "1150679"
  },
  {
    "text": "systems generalize so the way this was approached by franois chol he's a very",
    "start": "1150679",
    "end": "1156360"
  },
  {
    "text": "well-known AI researcher he works at Google he defines this in a hierarchy of",
    "start": "1156360",
    "end": "1161760"
  },
  {
    "text": "generalization so what we do is we start at an absence of generalization this includes systems",
    "start": "1161760",
    "end": "1167120"
  },
  {
    "text": "that know all of the Poss possible outcomes in advance such as if you've got an algorithm that can play tic tac",
    "start": "1167120",
    "end": "1172919"
  },
  {
    "text": "toe it will be able to play it by knowing all the possible configurations that it can play with in advance we then",
    "start": "1172919",
    "end": "1179320"
  },
  {
    "text": "move to local generalization this is where a system can make inferences on examples it",
    "start": "1179320",
    "end": "1184520"
  },
  {
    "text": "hasn't seen before but only if those examples are similar enough to things it was trained on and machine learning",
    "start": "1184520",
    "end": "1190559"
  },
  {
    "text": "models fall under this and this is an illustration of the kaggle effect broad generalization reflects a",
    "start": "1190559",
    "end": "1197960"
  },
  {
    "text": "human level of in a single broad activity domain so a famous example of this is the wnc coffee test this was",
    "start": "1197960",
    "end": "1204520"
  },
  {
    "text": "proposed by unsurprisingly Steve wnc of Apple Fame and he proposed that if you can have a system that can go into a",
    "start": "1204520",
    "end": "1210880"
  },
  {
    "text": "kitchen and can complete all the steps required to make a cup of coffee without human intervention that would show broad",
    "start": "1210880",
    "end": "1217480"
  },
  {
    "text": "generalization and full self-driving cars would also fall under this C",
    "start": "1217480",
    "end": "1222600"
  },
  {
    "text": "categorization we then have extreme generalization this is essentially human level intelligence and this is basically",
    "start": "1222600",
    "end": "1230080"
  },
  {
    "text": "where you have a system that can solve problems it hasn't seen before even those that only share some abstract",
    "start": "1230080",
    "end": "1235559"
  },
  {
    "text": "commonalities with things it has seen before and it can solve problems across the scope of what you'd expect humans to",
    "start": "1235559",
    "end": "1241919"
  },
  {
    "text": "be able to solve so you might be thinking at this point I'm focusing a lot on human level",
    "start": "1241919",
    "end": "1247600"
  },
  {
    "text": "abilities but we're talking about artificialist systems don't we want them to go beyond what we can do to be better",
    "start": "1247600",
    "end": "1252880"
  },
  {
    "text": "than us and this leads to the final level which is universality this is the ability of a system to solve any problem",
    "start": "1252880",
    "end": "1259720"
  },
  {
    "text": "in the universe beyond even problems that have any relevance to us the thing",
    "start": "1259720",
    "end": "1264799"
  },
  {
    "text": "with universality is it shouldn't really be considered as an initial goal for an artificial system for a couple of",
    "start": "1264799",
    "end": "1270600"
  },
  {
    "text": "reasons the first is as developers we know that all problems need a scope in",
    "start": "1270600",
    "end": "1275799"
  },
  {
    "text": "order to be useful and the current scope we have is being able to automate tasks that we ourselves do",
    "start": "1275799",
    "end": "1282200"
  },
  {
    "text": "manually for artificial systems the second is we haven't really even been",
    "start": "1282200",
    "end": "1287440"
  },
  {
    "text": "able to solve up to Broad generalization so should maybe focus on these lower levels before we aim quite so",
    "start": "1287440",
    "end": "1293600"
  },
  {
    "text": "high so if we come back to intelligence we can actually line up Chet's",
    "start": "1293600",
    "end": "1298960"
  },
  {
    "text": "conceptualization of generalization with the actual effect uh sorry accepted",
    "start": "1298960",
    "end": "1304279"
  },
  {
    "text": "definition of intelligence in humans so this conceptualization says that human",
    "start": "1304279",
    "end": "1309880"
  },
  {
    "text": "int is that humans have a general ability to learn called G or general intelligence and we use our general",
    "start": "1309880",
    "end": "1316279"
  },
  {
    "text": "intelligence to learn broad activities such as how to cook or drive a car and",
    "start": "1316279",
    "end": "1321360"
  },
  {
    "text": "within those broad activities are tasks that we can complete such as whisking eggs or using an indicator and you can",
    "start": "1321360",
    "end": "1327640"
  },
  {
    "text": "see that an artificial system's extreme generalization aligns with G in humans",
    "start": "1327640",
    "end": "1333559"
  },
  {
    "text": "broad abilities align with broad generalization and specific skills align with no generalization or local",
    "start": "1333559",
    "end": "1340520"
  },
  {
    "text": "generalization so given this overlap it seems fair that we can derive lessons from measuring intelligence in humans",
    "start": "1340520",
    "end": "1347520"
  },
  {
    "text": "which is an established field and apply them to measuring intelligence in artificial systems so as an aside before",
    "start": "1347520",
    "end": "1354760"
  },
  {
    "text": "I go on I want to say I am a psychologist I am aware that intelligence is a controversial field",
    "start": "1354760",
    "end": "1360880"
  },
  {
    "text": "this is not being proposed as a silver bullet it's more giving us a framework to move Beyond these skill focused",
    "start": "1360880",
    "end": "1367440"
  },
  {
    "text": "assessments of intelligence in these systems and try to get a sense of how well a system can truly",
    "start": "1367440",
    "end": "1373640"
  },
  {
    "text": "generalize so Chalet also promoted a method of maybe designing or building a",
    "start": "1373640",
    "end": "1379279"
  },
  {
    "text": "system with artificial general intelligence so he defines it as follows an artificial system should be able to",
    "start": "1379279",
    "end": "1385720"
  },
  {
    "text": "demonstrate the ability to solve a task so far so familiar but it does this by",
    "start": "1385720",
    "end": "1391760"
  },
  {
    "text": "using knowledge encoded in a skill program relevant to that task and the skill program is generated by a",
    "start": "1391760",
    "end": "1397880"
  },
  {
    "text": "humanlike intelligent system so these skill programs are refined on input",
    "start": "1397880",
    "end": "1403480"
  },
  {
    "text": "about both the situations they encounter and how effective the response has been and the intelligence system itself",
    "start": "1403480",
    "end": "1410120"
  },
  {
    "text": "learns over time through exposure to more and more tasks so Chalet also",
    "start": "1410120",
    "end": "1415440"
  },
  {
    "text": "argues that if we're talking about a humanlike intelligence system we should also presume that such a system is",
    "start": "1415440",
    "end": "1421840"
  },
  {
    "text": "designed with the same priors or skills that humans are innately born with and",
    "start": "1421840",
    "end": "1427200"
  },
  {
    "text": "this is Elementary geometry and physics arithmetic and an understanding of the agency of others so skill programs will",
    "start": "1427200",
    "end": "1434520"
  },
  {
    "text": "be able to encode their experience with tasks and remember how they solve such problems in the past and tasks",
    "start": "1434520",
    "end": "1440960"
  },
  {
    "text": "themselves can vary based on generalization difficulty so the generalization difficulty of task is",
    "start": "1440960",
    "end": "1446400"
  },
  {
    "text": "quite Central to this system design it's basically how different tasks are from",
    "start": "1446400",
    "end": "1451919"
  },
  {
    "text": "things that the system has already seen so obviously tasks that are much more different or much more different are",
    "start": "1451919",
    "end": "1457679"
  },
  {
    "text": "quite different to things that the system has seen before are going to be much harder for the system to solve and",
    "start": "1457679",
    "end": "1462840"
  },
  {
    "text": "it will need to be able to generalize more in order to successfully solve them so this gives us is a starting point a",
    "start": "1462840",
    "end": "1470799"
  },
  {
    "text": "conceptualization of how we might build a system with artificial general intelligence so chal's work has been",
    "start": "1470799",
    "end": "1477399"
  },
  {
    "text": "followed up with researchers from Deep mine these are actually the precursor to open Ai and were then acquired by Google",
    "start": "1477399",
    "end": "1483559"
  },
  {
    "text": "so they again start from the idea that an intelligent artificial system must be able to generalize but they simplify",
    "start": "1483559",
    "end": "1490559"
  },
  {
    "text": "this Dimension by breaking it into narrow and general systems and to this they add a second dimension performance",
    "start": "1490559",
    "end": "1498120"
  },
  {
    "text": "and they measure this by the percent of people that it can outperform on a particular task or range of tasks and",
    "start": "1498120",
    "end": "1504720"
  },
  {
    "text": "the way that they kind of break it up is they have a range from no people or outperformed to people unskilled in that",
    "start": "1504720",
    "end": "1511720"
  },
  {
    "text": "task to 50% of people 90% 99 and then finally all people are outperformed by",
    "start": "1511720",
    "end": "1518320"
  },
  {
    "text": "that system so let's first have a look at systems they classify as having narrow",
    "start": "1518320",
    "end": "1525919"
  },
  {
    "text": "generalization so in terms of systems that can out perform no one they put calculators and other systems that need",
    "start": "1525919",
    "end": "1531720"
  },
  {
    "text": "to be entirely manually operated under emerging narrow AI they put GOI or good oldfashioned AI these",
    "start": "1531720",
    "end": "1539480"
  },
  {
    "text": "are these old school I know I love that term um these are systems those kind of old school ones that needed to be",
    "start": "1539480",
    "end": "1545640"
  },
  {
    "text": "encoded specifically with rules and then at the higher ends they have systems like grammar that can outperform 90% of",
    "start": "1545640",
    "end": "1552480"
  },
  {
    "text": "people in terms of spelling spell checking and grammar tasks they have our old friend deep blue that can out form",
    "start": "1552480",
    "end": "1558640"
  },
  {
    "text": "99% of people at chess and then they have a system called Alpha fold that can",
    "start": "1558640",
    "end": "1564520"
  },
  {
    "text": "predict a protein's 3D structure better than 100% of people even skilled",
    "start": "1564520",
    "end": "1570279"
  },
  {
    "text": "scientists but as impressive as these are these are narrow systems as we know",
    "start": "1570279",
    "end": "1575360"
  },
  {
    "text": "the true path to AGI is in systems that can generalize so let's see what the",
    "start": "1575360",
    "end": "1580520"
  },
  {
    "text": "Deep mine team puts here well so far they only have two systems and interestingly they classify",
    "start": "1580520",
    "end": "1588720"
  },
  {
    "text": "chat GPT as emerging AGI I strongly disagree with this as",
    "start": "1588720",
    "end": "1594000"
  },
  {
    "text": "I've just shown you Chet's definition which is different from what these authors have put together is that the",
    "start": "1594000",
    "end": "1599399"
  },
  {
    "text": "scope of generality includes all tasks that a human would be reasonably en uh",
    "start": "1599399",
    "end": "1604480"
  },
  {
    "text": "expected to encounter and even chat GPT 4",
    "start": "1604480",
    "end": "1609640"
  },
  {
    "text": "40 um is still Limited in what it can do the other interesting thing is is",
    "start": "1609640",
    "end": "1616120"
  },
  {
    "text": "that the Deep M team were unable to find other examples on the higher ends of",
    "start": "1616120",
    "end": "1621240"
  },
  {
    "text": "generalization so what this shows is this these researchers really believe",
    "start": "1621240",
    "end": "1626360"
  },
  {
    "text": "that we have quite a long way to go before we get to AGI or as they're",
    "start": "1626360",
    "end": "1632000"
  },
  {
    "text": "calling it for some reason artificial super intelligence I guess AGI got you know not sexy enough and they had to change the",
    "start": "1632000",
    "end": "1638279"
  },
  {
    "text": "branding so coupling this with Chet's definition of how we might build such a system I think there's really enough",
    "start": "1638279",
    "end": "1644520"
  },
  {
    "text": "evidence here that we are quite a long way off this goal so what does this mean does it mean that",
    "start": "1644520",
    "end": "1651480"
  },
  {
    "start": "1649000",
    "end": "2549000"
  },
  {
    "text": "llms are not useful well of course they are but only when they're applied to the",
    "start": "1651480",
    "end": "1657240"
  },
  {
    "text": "problem domain that they were designed to solve which as I've been saying all throughout this talk is natural language",
    "start": "1657240",
    "end": "1664120"
  },
  {
    "text": "problems so we've touched a bit on what natural language tasks are throughout this talk but let's take a step back and",
    "start": "1664120",
    "end": "1670720"
  },
  {
    "text": "Define what they really are so this problem area is pretty borrowed and it encompasses anything that you might want",
    "start": "1670720",
    "end": "1677399"
  },
  {
    "text": "to do with natural languages natural languages are languages like Dutch English Mandarin ones that evolve",
    "start": "1677399",
    "end": "1684039"
  },
  {
    "text": "naturally so as I mentioned at the beginning of this presentation these are problems we've been trying to solve for",
    "start": "1684039",
    "end": "1690039"
  },
  {
    "text": "decades and llms are simply the latest and so far most sophisticated tool we've",
    "start": "1690039",
    "end": "1696200"
  },
  {
    "text": "had to solve these problems so let's have a look at some examples of natural language problems this is just a taster",
    "start": "1696200",
    "end": "1702760"
  },
  {
    "text": "but it will give you an indication of what this problem domain looks like so llms are good at doing the following",
    "start": "1702760",
    "end": "1710240"
  },
  {
    "text": "they're good at translating between one language and another but only if the",
    "start": "1710240",
    "end": "1715600"
  },
  {
    "text": "model has being trained on sufficient examples of both language they're good at text",
    "start": "1715600",
    "end": "1720880"
  },
  {
    "text": "classification where they can infer the topic of a piece of text and assign it to a category they're good at",
    "start": "1720880",
    "end": "1727880"
  },
  {
    "text": "summarizing longer pieces of text into shorter ones and they're good at answering questions or question",
    "start": "1727880",
    "end": "1733960"
  },
  {
    "text": "answering as it's called where a model can provide an answer BAS B on a question passed in as an input so we're",
    "start": "1733960",
    "end": "1741000"
  },
  {
    "text": "going to focus on this application for the rest of the talk so llms can answer questions in a",
    "start": "1741000",
    "end": "1747559"
  },
  {
    "text": "few ways they can of course answer it during during using their parametric knowledge as we saw with the slide About",
    "start": "1747559",
    "end": "1754440"
  },
  {
    "text": "Belgium so during training sufficiently large llms will be able to encode",
    "start": "1754440",
    "end": "1760679"
  },
  {
    "text": "knowledge that's trained sorry that's contained in their training data so",
    "start": "1760679",
    "end": "1767000"
  },
  {
    "text": "depending on the model depending on the training data llms may be able to answer",
    "start": "1767000",
    "end": "1772279"
  },
  {
    "text": "questions accurately based on this parametric knowledge alone llms can also be further trained",
    "start": "1772279",
    "end": "1779000"
  },
  {
    "text": "to better answer questions in a specific domain and this is a technique known as fine-tuning so the idea is you create a",
    "start": "1779000",
    "end": "1786600"
  },
  {
    "text": "data set which is comprised of high quality inputs questions and the",
    "start": "1786600",
    "end": "1792000"
  },
  {
    "text": "expected output and you further train the model so that it returns outputs",
    "start": "1792000",
    "end": "1797519"
  },
  {
    "text": "that are more more in line with this data set and after further training on this data set the llm will be better",
    "start": "1797519",
    "end": "1803640"
  },
  {
    "text": "equipped to answer questions in this specific domain and then finally there's one of the most talked about Methods at the",
    "start": "1803640",
    "end": "1809720"
  },
  {
    "text": "moment which is retrieval augmented generation or rag so this is where additional context relevant to the inut",
    "start": "1809720",
    "end": "1817279"
  },
  {
    "text": "input prompt is pulled in from some Source external to the llm and this is then incorporated into the prompt and",
    "start": "1817279",
    "end": "1824120"
  },
  {
    "text": "helps the llm more accurately answer the question so let's focus on rag a bit",
    "start": "1824120",
    "end": "1829399"
  },
  {
    "text": "more deeply and see how a rag pipeline might be used to answer a question who won the American Super Bowl this year so",
    "start": "1829399",
    "end": "1837200"
  },
  {
    "text": "I pick this question deliberately not because I'm a huge fan of American Sports but because it's a relatively",
    "start": "1837200",
    "end": "1842960"
  },
  {
    "text": "recent event so most models are not going to be able to answer this question based on their parametric knowledge",
    "start": "1842960",
    "end": "1848440"
  },
  {
    "text": "alone so instead they're going to have to rely on pulling in this information from somewhere",
    "start": "1848440",
    "end": "1854200"
  },
  {
    "text": "else so how can we answer this question using a rag pipeline well just like when we use an llm",
    "start": "1854200",
    "end": "1860880"
  },
  {
    "text": "normally we create our prompt you know in this case a question about the Super Bowl however rather than passing this",
    "start": "1860880",
    "end": "1867519"
  },
  {
    "text": "directly into the llm we can first gather some additional information so this information can come",
    "start": "1867519",
    "end": "1873679"
  },
  {
    "text": "from a variety of places it could actually come from a web search engine and if you've used chat GPT 4 that's",
    "start": "1873679",
    "end": "1879679"
  },
  {
    "text": "actually what it's doing sometimes under the hood it's actually pinging Bing and pulling in information but if you're dealing with",
    "start": "1879679",
    "end": "1886559"
  },
  {
    "text": "sensitive documents you're going to want to store that internally some way in some sort of database so how do we then retrieve",
    "start": "1886559",
    "end": "1894799"
  },
  {
    "text": "information from our database at question time at the time we want to get our llm to answer our question and do",
    "start": "1894799",
    "end": "1901519"
  },
  {
    "text": "this in a way that's efficient well the first thing we need to do is divide our documents into chunks we then feed these",
    "start": "1901519",
    "end": "1909080"
  },
  {
    "text": "chunks into a second what's called an encoder model and as a result we convert",
    "start": "1909080",
    "end": "1914159"
  },
  {
    "text": "these chunks into document embeddings and these are then stored in Vector database so if you've heard things like",
    "start": "1914159",
    "end": "1919760"
  },
  {
    "text": "web8 or pine cone all these deor databases people are talking about this is why people are using",
    "start": "1919760",
    "end": "1925279"
  },
  {
    "text": "them at retrieval time the prompt is also converted into a document embedding",
    "start": "1925279",
    "end": "1930679"
  },
  {
    "text": "using that same model and the most similar document trunks are retrieved from your vector database so we can see",
    "start": "1930679",
    "end": "1937159"
  },
  {
    "text": "from for the Super Bowl query we have two chunks one telling us that the cansas City Chiefs one against the San",
    "start": "1937159",
    "end": "1943760"
  },
  {
    "text": "Francisco 49ers and a second telling us the score we can now build our augmented",
    "start": "1943760",
    "end": "1949480"
  },
  {
    "text": "prompt we instruct the llm to ignore its parametric knowledge and only use this",
    "start": "1949480",
    "end": "1954679"
  },
  {
    "text": "additional information we retrieve from our Vector datab uh yeah do document database when answering the question and",
    "start": "1954679",
    "end": "1961120"
  },
  {
    "text": "then voila the llm is now able to accurately answer our",
    "start": "1961120",
    "end": "1966600"
  },
  {
    "text": "question so let's now jump over to pie charm and see how we might actually be able to build our own simple rag",
    "start": "1966600",
    "end": "1972399"
  },
  {
    "text": "pipeline for question answering",
    "start": "1972399",
    "end": "1977000"
  },
  {
    "text": "okay sorry it's going to be slightly awkward all right so what we're going to be dealing with in this demo if I can",
    "start": "1978159",
    "end": "1985039"
  },
  {
    "text": "find my mouse can you see my mouse there we are",
    "start": "1985039",
    "end": "1991880"
  },
  {
    "text": "okay so we're going to be dealing with is a really large PDF which basically",
    "start": "1991880",
    "end": "1997159"
  },
  {
    "text": "contains all of the pie charm documentation I thought this was very clever I was doing a demo of pie charm",
    "start": "1997159",
    "end": "2002559"
  },
  {
    "text": "using pie charm documentation so you know patting myself on the back for that so this is a really huge PDF it has",
    "start": "2002559",
    "end": "2010360"
  },
  {
    "text": "almost 2,000 pages and because it's not indexed in any way it's just a plain PDF we're actually going to have a lot of",
    "start": "2010360",
    "end": "2016559"
  },
  {
    "text": "trouble actually searching through that if we want to answer questions so we can build a question",
    "start": "2016559",
    "end": "2022880"
  },
  {
    "text": "answering rag application by ingesting this documentation and searching over it using our llm so how are we going to do",
    "start": "2022880",
    "end": "2030080"
  },
  {
    "text": "this we're going going to do this using an open source package called Lang chain",
    "start": "2030080",
    "end": "2035840"
  },
  {
    "text": "now Lang chain is a really really powerful application for extending the functionality of llms Beyond just sort",
    "start": "2035840",
    "end": "2042159"
  },
  {
    "text": "of simple input output systems and at the moment it's only officially supported in Python and JavaScript but",
    "start": "2042159",
    "end": "2049878"
  },
  {
    "text": "because it's been such a popular package it's been ported actually to a lot of languages in uh Community projects so",
    "start": "2049879",
    "end": "2056599"
  },
  {
    "text": "I've seen Java I've seen C so if you're interested in using this and you're not working in python or JavaScript you may",
    "start": "2056599",
    "end": "2063599"
  },
  {
    "text": "want to have a look around for one of those Community projects okay so let's now go through our",
    "start": "2063599",
    "end": "2069158"
  },
  {
    "text": "application so obviously the first thing that we need to do is choose an llm that we're going to use so that's what we do",
    "start": "2069159",
    "end": "2076040"
  },
  {
    "text": "here I'm going to be using an open AI model so we have the Syntax for doing that there then of course we need to",
    "start": "2076040",
    "end": "2083200"
  },
  {
    "text": "load in our gigantic documentation that we're going to search over in my case I'm using a PDF but you don't need to",
    "start": "2083200",
    "end": "2090000"
  },
  {
    "text": "use a PDF Lang chain supports a lot of different formats so if you want to use some other type of text format you can",
    "start": "2090000",
    "end": "2096398"
  },
  {
    "text": "have a look through their documentation and see what they support so now we have read in our",
    "start": "2096399",
    "end": "2101480"
  },
  {
    "text": "documentation we need to split it into chunks just like I showed you in the previous slide so we split that based on",
    "start": "2101480",
    "end": "2108000"
  },
  {
    "text": "character and then we have our chunks and then we need to convert them into document embeddings and store them in",
    "start": "2108000",
    "end": "2114160"
  },
  {
    "text": "the vector database in this case we're using a chroma database and we use a particular embedding model that we want",
    "start": "2114160",
    "end": "2120359"
  },
  {
    "text": "to use for that so once it's in the vector database we need to retrieve it when we want to ask a question so this",
    "start": "2120359",
    "end": "2127079"
  },
  {
    "text": "is what we do here in this method we would create create our retriever use that on our database and",
    "start": "2127079",
    "end": "2133800"
  },
  {
    "text": "we can set different parameters like potentially the number of chunks that we want to retrieve each time we ask a",
    "start": "2133800",
    "end": "2140000"
  },
  {
    "text": "question from the vector database and then having put together all those components it's actually really simple",
    "start": "2140000",
    "end": "2145359"
  },
  {
    "text": "as you can see all we need to do is bundle it together in a little application so this is called a chain in",
    "start": "2145359",
    "end": "2151440"
  },
  {
    "text": "Lang chain and you can see we're building a retrieval QA chain don't worry if you didn't get all of this I'm",
    "start": "2151440",
    "end": "2157319"
  },
  {
    "text": "going to be providing the code at the end of this talk so you'll be able to play around with that yourself so now that we've created our",
    "start": "2157319",
    "end": "2164079"
  },
  {
    "text": "app we need to be able to instantiate it with different parameters and there are as you can see a lot of different levers",
    "start": "2164079",
    "end": "2171000"
  },
  {
    "text": "that you can pull when creating rag pipelines so I'm not going to go through all of these The Talk would go 20 minute",
    "start": "2171000",
    "end": "2176720"
  },
  {
    "text": "over and Adele would be very angry with me but again you can go through this notebook at your own Leisure and see the",
    "start": "2176720",
    "end": "2182480"
  },
  {
    "text": "different parameters you might be able to tweak in order to optimize your own pipeline",
    "start": "2182480",
    "end": "2188000"
  },
  {
    "text": "however the most important things I want to point out to you is the model that I've chosen to use to answer the questions I've used chat GPT 3.5 so I've",
    "start": "2188000",
    "end": "2196400"
  },
  {
    "text": "already shown you how powerful this model is it's going to help us get good performance on a range of natural language tasks including question",
    "start": "2196400",
    "end": "2203319"
  },
  {
    "text": "answering and I'm also retrieving five chunks per question in order to answer",
    "start": "2203319",
    "end": "2208880"
  },
  {
    "text": "my question okay great so we built our application that was easy so now we can",
    "start": "2208880",
    "end": "2214119"
  },
  {
    "text": "start asking questions so the first question I'm going to ask is is what are the options for debugging with py charm",
    "start": "2214119",
    "end": "2221640"
  },
  {
    "text": "and you can actually see that it gives us a really nice answer this is the summary given by the llm tells us about",
    "start": "2221640",
    "end": "2228280"
  },
  {
    "text": "creating break points tells us about stepping through code tells us about evaluating expressions etc etc so if we",
    "start": "2228280",
    "end": "2235800"
  },
  {
    "text": "go down here we can actually see the chunks that our application has used to answer this question so we can see this",
    "start": "2235800",
    "end": "2242839"
  },
  {
    "text": "first one is very relevant this second one very relevant but if we scroll down the last two chunks are actually not",
    "start": "2242839",
    "end": "2249280"
  },
  {
    "text": "that relevant they more seem to be from overview pages that just mentioned debugging and this is where you can see",
    "start": "2249280",
    "end": "2254560"
  },
  {
    "text": "that trade-off you have to do with your hyper parameters it might be that five chunks is too many and there are",
    "start": "2254560",
    "end": "2260240"
  },
  {
    "text": "different kind of levers you can pull in terms of that so now that we have been able to",
    "start": "2260240",
    "end": "2266040"
  },
  {
    "text": "ask one question we might want to ask a follow-up question we have a chat after all so maybe we want to ask have you",
    "start": "2266040",
    "end": "2272040"
  },
  {
    "text": "left out any other types of debugging but we need the application to",
    "start": "2272040",
    "end": "2277160"
  },
  {
    "text": "understand what it's already been asked so we can do that in a really simple way here we can basically pass in the first",
    "start": "2277160",
    "end": "2283560"
  },
  {
    "text": "question that we asked and also pass in the result that it gave us that little",
    "start": "2283560",
    "end": "2288599"
  },
  {
    "text": "answer that it talked about break points and the following and then we assign that as one of the parameters when we",
    "start": "2288599",
    "end": "2296760"
  },
  {
    "text": "invoke the application and you can see it's given us a follow-up answer it's now telling us about debugging in",
    "start": "2296760",
    "end": "2303359"
  },
  {
    "text": "specific use cases like JavaScript or specific python frame Frameworks so to finish the demo I want",
    "start": "2303359",
    "end": "2310359"
  },
  {
    "text": "to show you something kind of wild I was so excited when I put this together so like I talked about llms are generalist",
    "start": "2310359",
    "end": "2318079"
  },
  {
    "text": "natural language models so this means that the same model can often do multiple tasks and one of those tasks is",
    "start": "2318079",
    "end": "2324760"
  },
  {
    "text": "translation so because I'm using a sufficiently powerful model I can actually do queries in different",
    "start": "2324760",
    "end": "2332960"
  },
  {
    "text": "languages so German to English translation is supported by this model so I can ask how can you install py",
    "start": "2332960",
    "end": "2339680"
  },
  {
    "text": "charm in German what my application then does is it goes away and it finds me English",
    "start": "2339680",
    "end": "2345960"
  },
  {
    "text": "language document chunks that are relevant to this sorry I'm so excited and so you can see this is relevant",
    "start": "2345960",
    "end": "2352040"
  },
  {
    "text": "installation guide you can install pycharm doing the following and then what it gives me is a relevant summary",
    "start": "2352040",
    "end": "2359800"
  },
  {
    "text": "in the original language so I just think this is so cool um like I said I'm going to give you the code please go away and",
    "start": "2359800",
    "end": "2366119"
  },
  {
    "text": "play with it yourself but for now I'm going to end with a boring cautionary tale just for a couple",
    "start": "2366119",
    "end": "2373760"
  },
  {
    "text": "of slides I'm sorry where is my mouse there we are okay so this is the point where I",
    "start": "2373760",
    "end": "2382200"
  },
  {
    "text": "tell you like a boring data scientist that after showing you this really cute little neat rag act that app that um",
    "start": "2382200",
    "end": "2389680"
  },
  {
    "text": "working with rag in fact working with llms in deployment is not really simple and comes with a lot of gotches and",
    "start": "2389680",
    "end": "2396359"
  },
  {
    "text": "pitfalls so let's start with problems you might have with rag so do you remember all those levers I was talking",
    "start": "2396359",
    "end": "2402839"
  },
  {
    "text": "about that you can pull like the you know number of chunks that you return per query well all of these can",
    "start": "2402839",
    "end": "2409000"
  },
  {
    "text": "massively impact the performance of your rag app so this can include important things like the size of the chunks how",
    "start": "2409000",
    "end": "2416560"
  },
  {
    "text": "many how you create the document embeddings what model you use how you retrieve from the database and how you",
    "start": "2416560",
    "end": "2423480"
  },
  {
    "text": "create your prompt how you integrate that information into the prompt and then with llms",
    "start": "2423480",
    "end": "2430040"
  },
  {
    "text": "generally not all llms are suitable for all tasks so while they are generalist",
    "start": "2430040",
    "end": "2437000"
  },
  {
    "text": "models different models may have specializations in different things they may be trained on specific data sets so",
    "start": "2437000",
    "end": "2443960"
  },
  {
    "text": "like a really simple example is let's say you want to use a model for some reason for translating fan to Dutch",
    "start": "2443960",
    "end": "2450160"
  },
  {
    "text": "because fan is quite a small language if you if your model has never actually been trained on Fran text then your llm",
    "start": "2450160",
    "end": "2456839"
  },
  {
    "text": "is just not going to be able to do this translation it still needs the underlying data it's not magic it doesn't just create that information",
    "start": "2456839",
    "end": "2462520"
  },
  {
    "text": "from nowhere and if it does it's a hallucination so if you don't pick the",
    "start": "2462520",
    "end": "2468599"
  },
  {
    "text": "right model for the task or if you don't tune your applications correctly this can lead to poor performance it can lead",
    "start": "2468599",
    "end": "2475200"
  },
  {
    "text": "to poor quality anwers and as I said it can lead to hallucinations and I guess this leads",
    "start": "2475200",
    "end": "2481599"
  },
  {
    "text": "you with the final question how do you know whether the llm that you want to use is going to appropriate for your use",
    "start": "2481599",
    "end": "2488520"
  },
  {
    "text": "case well this gets into a really huge and complex topic which I'm not going to have time to get into I'm just going to",
    "start": "2488520",
    "end": "2494440"
  },
  {
    "text": "touch on which is llm measurement so a number of benchmarks exist for measuring",
    "start": "2494440",
    "end": "2500920"
  },
  {
    "text": "how well llms can perform on natural language tasks generally and you can see the",
    "start": "2500920",
    "end": "2507119"
  },
  {
    "text": "performance of various models on leaderboards like this one created by hugging face for open source",
    "start": "2507119",
    "end": "2512400"
  },
  {
    "text": "llms however how a model will perform on your specific task is is really going to",
    "start": "2512400",
    "end": "2518079"
  },
  {
    "text": "depend on the domain and the use case and potentially you may need to go and seek domain specific benchmarks or even",
    "start": "2518079",
    "end": "2524079"
  },
  {
    "text": "create your own benchmarking data set so in conclusion llms are powerful but",
    "start": "2524079",
    "end": "2531160"
  },
  {
    "text": "still limited models they're not on the brink of developing AGI but nor are they",
    "start": "2531160",
    "end": "2536240"
  },
  {
    "text": "without application and only part of an empty hype cycle the trick is picking",
    "start": "2536240",
    "end": "2541760"
  },
  {
    "text": "The Right Use case carefully tuning and building your deployment and making sure you measure your performance carefully",
    "start": "2541760",
    "end": "2548760"
  },
  {
    "text": "and if this sounds familiar it's the same boring problems we've been dealing with in software development and machine",
    "start": "2548760",
    "end": "2554400"
  },
  {
    "start": "2549000",
    "end": "2572000"
  },
  {
    "text": "learning for decades thank you very much",
    "start": "2554400",
    "end": "2559440"
  }
]
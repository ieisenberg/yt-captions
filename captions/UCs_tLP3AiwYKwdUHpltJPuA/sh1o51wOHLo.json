[
  {
    "start": "0",
    "end": "173000"
  },
  {
    "text": "[Music]",
    "start": "970",
    "end": "7838"
  },
  {
    "text": "all right hello everyone my name is phil winder and i run a business in the uk",
    "start": "13360",
    "end": "19359"
  },
  {
    "text": "that specializes in doing um production data science so we fingers in quite a few pies but one",
    "start": "19359",
    "end": "26320"
  },
  {
    "text": "of the pies we've got our fingers in is something called reinforcement learning and reinforcement learning is",
    "start": "26320",
    "end": "32398"
  },
  {
    "text": "a a tool or a technique um that kind of derives from machine",
    "start": "32399",
    "end": "37440"
  },
  {
    "text": "learning and it's a really new and interesting way of solving um a certain kind of machine learning",
    "start": "37440",
    "end": "44800"
  },
  {
    "text": "problem so this presentation is all about uh providing an introduction to that in a",
    "start": "44800",
    "end": "52640"
  },
  {
    "text": "code oriented way so this this presentation is primarily for for engineers",
    "start": "52640",
    "end": "58000"
  },
  {
    "text": "for people that like looking at code that like tinkering with things um it's it's it's you know it's it's",
    "start": "58000",
    "end": "63920"
  },
  {
    "text": "it's very specific and not very abstract so it's very uh in depth basically um and",
    "start": "63920",
    "end": "70960"
  },
  {
    "text": "uh what i'd like to do is i'll i'm gonna give you a very quick introduction and then we're",
    "start": "70960",
    "end": "76000"
  },
  {
    "text": "gonna dive into a jupiter notebook and at the same time you can load that notebook and follow",
    "start": "76000",
    "end": "81200"
  },
  {
    "text": "along if you if you like or you can follow the screen as i as i walk you through it we have about 30-ish minutes",
    "start": "81200",
    "end": "88880"
  },
  {
    "text": "so i have to be quite brief and quick going through that document unfortunately",
    "start": "88880",
    "end": "94079"
  },
  {
    "text": "but hopefully it'll be enough for you to to get an understanding if you could type any of your questions",
    "start": "94079",
    "end": "101520"
  },
  {
    "text": "into the chat window that would be great or if you just leave the questions till the end that's all",
    "start": "101520",
    "end": "106560"
  },
  {
    "text": "that's also good just so we don't sort of break the the thread of the talk um",
    "start": "106560",
    "end": "112720"
  },
  {
    "text": "yeah and with that i'll i'll get cracking so the main reason why i have written this presentation",
    "start": "112720",
    "end": "119439"
  },
  {
    "text": "is that it is an accompaniment for my new book on reinforcement",
    "start": "119439",
    "end": "125200"
  },
  {
    "text": "learning it's being published by o'reilly and it's being released in about three weeks time hopefully it's just gone to",
    "start": "125200",
    "end": "131840"
  },
  {
    "text": "the printers a couple of days ago so so now it's it's uh going through all of the",
    "start": "131840",
    "end": "137920"
  },
  {
    "text": "the processes that that need to happen in order for it to get released and printed",
    "start": "137920",
    "end": "143280"
  },
  {
    "text": "there's an accompanying website rlbook.comrldashbook.com",
    "start": "143280",
    "end": "148560"
  },
  {
    "text": "and on this website you'll find all of the the extra materials that didn't make it into the book in all of the examples",
    "start": "148560",
    "end": "155599"
  },
  {
    "text": "and things like that um what i recommend is that you you go there and sign up and i'll uh you know send you details of",
    "start": "155599",
    "end": "163360"
  },
  {
    "text": "when the book is released and free chapters and and things like that so yeah you can find more details about",
    "start": "163360",
    "end": "169280"
  },
  {
    "text": "the book on there uh so yeah this presentation is it comes from that book it it delves",
    "start": "169280",
    "end": "176560"
  },
  {
    "start": "173000",
    "end": "188000"
  },
  {
    "text": "into a very small part of that book there's far more details in the book as you can imagine",
    "start": "176560",
    "end": "181840"
  },
  {
    "text": "um but yeah hopefully it's still going to be interesting so let's let's try and uh explain what what reinforcement learning",
    "start": "181840",
    "end": "187840"
  },
  {
    "text": "is for those that don't know so far so i like to find good examples of",
    "start": "187840",
    "end": "193440"
  },
  {
    "start": "188000",
    "end": "532000"
  },
  {
    "text": "reinforcement learning and they usually they usually come back to the way in",
    "start": "193440",
    "end": "198879"
  },
  {
    "text": "which we learn humans learn because it's a really good it's a really good representation of what we're trying to solve here",
    "start": "198879",
    "end": "204720"
  },
  {
    "text": "so reinforcement learning is learning by reinforcement the name is actually really good for once",
    "start": "204720",
    "end": "210959"
  },
  {
    "text": "which doesn't doesn't happen very often in data science but the name fits and um one example of learning by",
    "start": "210959",
    "end": "218640"
  },
  {
    "text": "reinforcement is learning how to ride a bike and a couple of years ago i think at one of the go-to conferences",
    "start": "218640",
    "end": "224319"
  },
  {
    "text": "i i saw uh destin uh sandlin give a presentation about a bike that his friend had made",
    "start": "224319",
    "end": "232080"
  },
  {
    "text": "him which inverted the steering on a bicycle so if you steered left it turned right",
    "start": "232080",
    "end": "238959"
  },
  {
    "text": "if you steered right it turned left um just with a couple of gears on the on the post of the",
    "start": "238959",
    "end": "244879"
  },
  {
    "text": "of the bike there as you can see and when he tried to uh go ahead and ride this bike",
    "start": "244879",
    "end": "252640"
  },
  {
    "text": "then you can imagine that it's incredibly difficult because it's not",
    "start": "252640",
    "end": "257919"
  },
  {
    "text": "what you're used to you've learned you've spent your entire life learning how to ride a bike and then this bike comes along and it does the",
    "start": "257919",
    "end": "264080"
  },
  {
    "text": "opposite of what you expect so as soon as you try and sort of counter falling off a bike it instantly",
    "start": "264080",
    "end": "269520"
  },
  {
    "text": "goes the wrong way and throws you off so there's a funny video of of him falling off his bike many times",
    "start": "269520",
    "end": "275199"
  },
  {
    "text": "um and the interesting aspect of this is is when he when he played the same trick on his son",
    "start": "275199",
    "end": "280560"
  },
  {
    "text": "his son was able to learn much quicker than than he was how to ride this inverted bike",
    "start": "280560",
    "end": "285600"
  },
  {
    "text": "and this is uh just a you know a screenshot from the video with his head chopped off but um his his son was was able to to learn",
    "start": "285600",
    "end": "293440"
  },
  {
    "text": "how to ride the bike really quickly um so this is a sort of an example really",
    "start": "293440",
    "end": "299919"
  },
  {
    "text": "of of how you learn in in the first place and how it's hard to learn new tasks once you've",
    "start": "299919",
    "end": "305520"
  },
  {
    "text": "you've learned the optimal strategy for for doing that thing but it all boils down to this um",
    "start": "305520",
    "end": "311919"
  },
  {
    "text": "when you when you see a bike for the first time you have to experiment to learn how to ride it you",
    "start": "311919",
    "end": "318800"
  },
  {
    "text": "can't somebody can't just tell you how to ride a bike you actually need to try and do it in order to learn",
    "start": "318800",
    "end": "324240"
  },
  {
    "text": "and what you're doing there is when you sit on that bike you can see and sense and feel",
    "start": "324240",
    "end": "330880"
  },
  {
    "text": "um you know many things around you you can you can see the grass you can feel the",
    "start": "330880",
    "end": "336720"
  },
  {
    "text": "pain when you fall off you can hear the sound of the gears grinding things like that",
    "start": "336720",
    "end": "341840"
  },
  {
    "text": "and that that is um the that represents the state of the environment",
    "start": "341840",
    "end": "346960"
  },
  {
    "text": "so all of that all of that information is the state of the environment you're currently operating in okay so",
    "start": "346960",
    "end": "352800"
  },
  {
    "text": "that's this arrow coming here um here at the bottom we've got this box called",
    "start": "352800",
    "end": "358160"
  },
  {
    "text": "agent an agent in this sense is you it's the person the person is the agent because they are",
    "start": "358160",
    "end": "363600"
  },
  {
    "text": "the one that's responsible for for taking in this state for absorbing all of this information",
    "start": "363600",
    "end": "369520"
  },
  {
    "text": "and then suggesting new things to try and you do that by suggesting actions so",
    "start": "369520",
    "end": "376880"
  },
  {
    "text": "for example steer left steer right brake pedal things like that and those actions get",
    "start": "376880",
    "end": "382080"
  },
  {
    "text": "fed back to the environment again so when you steer left for example um that will",
    "start": "382080",
    "end": "389120"
  },
  {
    "text": "change the state of the environment because you might have fallen off your bike so previously you were looking at the",
    "start": "389120",
    "end": "395600"
  },
  {
    "text": "horizon and now you're looking at the grass okay so the state of the environment has changed and",
    "start": "395600",
    "end": "401440"
  },
  {
    "text": "over time when we repeat this loop again and again and again again we also obtain some kind of",
    "start": "401440",
    "end": "407759"
  },
  {
    "text": "feedback some kind of reward that represents the well represents how well we are doing at",
    "start": "407759",
    "end": "413759"
  },
  {
    "text": "that task so in in terms of riding a bike the reward could be negative",
    "start": "413759",
    "end": "419280"
  },
  {
    "text": "it could be that you've fallen off and you've you've hurt yourself or it could be positive and you're getting a clap from your",
    "start": "419280",
    "end": "424560"
  },
  {
    "text": "parents um and and over time you learn to maximize",
    "start": "424560",
    "end": "430240"
  },
  {
    "text": "this reward you learn to avoid all of the negative things and um you know try and obtain all of",
    "start": "430240",
    "end": "437120"
  },
  {
    "text": "the positive things and uh this loop goes round round and round you never stop learning you never",
    "start": "437120",
    "end": "442880"
  },
  {
    "text": "you never stop learning and and ultimately the the agent this thing at the bottom it",
    "start": "442880",
    "end": "448960"
  },
  {
    "text": "it is able to um you know store or memorize some kind of strategy for",
    "start": "448960",
    "end": "454800"
  },
  {
    "text": "dealing with that particular situation and when we see similar situations again we can pull out that",
    "start": "454800",
    "end": "460400"
  },
  {
    "text": "same strategy and try it again and in most cases it works you know if you get on a different bike",
    "start": "460400",
    "end": "465840"
  },
  {
    "text": "it generally works the same way um you know unless you uh unless you go to",
    "start": "465840",
    "end": "472319"
  },
  {
    "text": "to amsterdam or somewhere and have like these hub uh these these bikes with the hub brakes in the back wheel where",
    "start": "472319",
    "end": "479120"
  },
  {
    "text": "you have to pedal backwards in order to brake there's no there's no handlebar brakes so it's like",
    "start": "479120",
    "end": "484160"
  },
  {
    "text": "the first time you have to do an emergency stop and you do this and there's no brakes",
    "start": "484160",
    "end": "490160"
  },
  {
    "text": "so in general it works quite well but when you turn the steering around then obviously that strategy doesn't work",
    "start": "490160",
    "end": "495520"
  },
  {
    "text": "anymore and you've got to restart this process again you've got to train yourself and and form a new",
    "start": "495520",
    "end": "500960"
  },
  {
    "text": "strategy um so that was just a description of how we we",
    "start": "500960",
    "end": "506319"
  },
  {
    "text": "learn on a bike but this has been generalized and formalized into something that mathematicians",
    "start": "506319",
    "end": "511599"
  },
  {
    "text": "called a uh a markov decision process an mdp and this presentation is about",
    "start": "511599",
    "end": "517839"
  },
  {
    "text": "encoding this mdp in some python code and rather than",
    "start": "517839",
    "end": "524159"
  },
  {
    "text": "learning to ride a bike we can teach an agent to do different and interesting things",
    "start": "524159",
    "end": "530720"
  },
  {
    "text": "okay so let's move on to taking a look at the code now because uh we've got about 20 minutes left so",
    "start": "531120",
    "end": "537360"
  },
  {
    "start": "532000",
    "end": "635000"
  },
  {
    "text": "that's that's great um what we've got here is a link to a github repo so if you browse to",
    "start": "537360",
    "end": "545160"
  },
  {
    "text": "tinyurl.com forward slash rl code notebook that should redirect you to a github",
    "start": "545160",
    "end": "552959"
  },
  {
    "text": "repository in the readme there there's two buttons and what i'd like you to do is to click",
    "start": "552959",
    "end": "558080"
  },
  {
    "text": "one of those it doesn't matter which but this will open the notebook inside a notebook hosting service",
    "start": "558080",
    "end": "565920"
  },
  {
    "text": "um it's pure python there's no libraries so it pretty much should work anywhere um and i'm going to go ahead",
    "start": "565920",
    "end": "573839"
  },
  {
    "text": "and open up that notebook now and see everyone can see it why have you",
    "start": "573839",
    "end": "580959"
  },
  {
    "text": "reappeared go away all right i'm gonna open the collab",
    "start": "580959",
    "end": "588640"
  },
  {
    "text": "version oh solve that that wasn't neat there we go",
    "start": "588640",
    "end": "596480"
  },
  {
    "text": "and in a few seconds time we will see a full-on",
    "start": "596480",
    "end": "603440"
  },
  {
    "text": "jupiter notebook so i've written this notebook so that you can use it and read it",
    "start": "603440",
    "end": "609040"
  },
  {
    "text": "without watching this presentation so there's a lot of text in there there's a lot of explanatory notes of course there isn't",
    "start": "609040",
    "end": "616399"
  },
  {
    "text": "as much detail as there is in the book but hopefully there's enough to get you going i'm going to skip",
    "start": "616399",
    "end": "622160"
  },
  {
    "text": "over all this text and get straight to the code because we haven't got too much time so",
    "start": "622160",
    "end": "628640"
  },
  {
    "text": "what we're going to do is we're going to code up this markov decision process let me go back to that image",
    "start": "628640",
    "end": "635200"
  },
  {
    "start": "635000",
    "end": "1790000"
  },
  {
    "text": "before and we're going to simulate our own environment so ideally",
    "start": "635200",
    "end": "641040"
  },
  {
    "text": "you want to do this in the real world ideally we want to be able to control a bike we want to you know sense all of the",
    "start": "641040",
    "end": "648000"
  },
  {
    "text": "things around that bike but it's it's it's actually it's quite hard to do that in practice um it's quite expensive to do",
    "start": "648000",
    "end": "654720"
  },
  {
    "text": "um and it's it's hard to iterate it it's quite yeah slow work so typically what",
    "start": "654720",
    "end": "660240"
  },
  {
    "text": "engineers do when attacking these kinds of problems is they they build a simulation either",
    "start": "660240",
    "end": "665279"
  },
  {
    "text": "from past data from log data or from first principles so what we're going to",
    "start": "665279",
    "end": "671200"
  },
  {
    "text": "do is build a very simple environment which consists of a 2d",
    "start": "671200",
    "end": "676800"
  },
  {
    "text": "square and within that square we're splitting the environment up into cells and",
    "start": "676800",
    "end": "683839"
  },
  {
    "text": "we're going to have an agent inside there which is allowed to move around the the 2d space so basically it can",
    "start": "683839",
    "end": "690800"
  },
  {
    "text": "move like a like a piece on the chess board it can move around these different cells inside that that square",
    "start": "690800",
    "end": "698000"
  },
  {
    "text": "and in the literature that's typically called a grid world",
    "start": "698000",
    "end": "703680"
  },
  {
    "text": "environment um i start off by defining some core types",
    "start": "703680",
    "end": "708959"
  },
  {
    "text": "we have two chord types here one called a point which is a just an x y coordinate of that 2d space",
    "start": "708959",
    "end": "716720"
  },
  {
    "text": "so 0 0 represents the bottom left-hand corner of that chessboard if",
    "start": "716720",
    "end": "722720"
  },
  {
    "text": "you're thinking of a chessboard and then we have some directions in which the agent can move",
    "start": "722720",
    "end": "727760"
  },
  {
    "text": "they can either go north east south or west up down left or right okay nice and simple next we're going to",
    "start": "727760",
    "end": "735120"
  },
  {
    "text": "start encoding the environment and we're going to do that by creating a class",
    "start": "735120",
    "end": "740720"
  },
  {
    "text": "called simple grid world we can specify the width and height of the grid world and we're setting the",
    "start": "740720",
    "end": "748320"
  },
  {
    "text": "actions that the agent can take within that space and we're just saying that the agent can move in all directions",
    "start": "748320",
    "end": "755200"
  },
  {
    "text": "basically next we've got this reset function and this is required because",
    "start": "755200",
    "end": "761440"
  },
  {
    "text": "mdps come in two forms basic mdbs can come in a continuous form",
    "start": "761440",
    "end": "768000"
  },
  {
    "text": "where this loop never ends it just goes on forever it's an infinite loop okay but there is",
    "start": "768000",
    "end": "774639"
  },
  {
    "text": "another type of ndp which is called an episodic mdp which means that one of these states",
    "start": "774639",
    "end": "781200"
  },
  {
    "text": "is a terminating state so basically you go around in that loop until you find the terminating state and",
    "start": "781200",
    "end": "787440"
  },
  {
    "text": "then it stops and then we need to reset it back to some starting position again typically episodic mdps are easier",
    "start": "787440",
    "end": "796000"
  },
  {
    "text": "to work with because there's there's a finite amount of time in which uh an episode",
    "start": "796000",
    "end": "803200"
  },
  {
    "text": "can run um but but some problems are necessarily",
    "start": "803200",
    "end": "808399"
  },
  {
    "text": "uh continuous for for reasons that um depend on the on the problem okay but",
    "start": "808399",
    "end": "815200"
  },
  {
    "text": "in this case we're going to work with an episodic mdp um because it's easier to visualize it's",
    "start": "815200",
    "end": "820639"
  },
  {
    "text": "easier easier to to conceptualize what's going on so this reset function is resetting the",
    "start": "820639",
    "end": "826240"
  },
  {
    "text": "agent back to the starting position and here i'm defining the starting position as",
    "start": "826240",
    "end": "831680"
  },
  {
    "text": "uh x equals zero which starts the left hand side y equals the height so basically the top",
    "start": "831680",
    "end": "837600"
  },
  {
    "text": "left hand corner i'm fixing that starting position every time in a real problem",
    "start": "837600",
    "end": "843040"
  },
  {
    "text": "you might want to consider randomizing that start position to explore more of the the state",
    "start": "843040",
    "end": "849680"
  },
  {
    "text": "then i'm setting the goal and the goal i'm setting to the x equals the the width so the right",
    "start": "849680",
    "end": "856320"
  },
  {
    "text": "hand side and y equals zero so this is the bottom right hand corner so the goal of this environment is",
    "start": "856320",
    "end": "863519"
  },
  {
    "text": "basically to go from the top left hand corner to the bottom right hand corner nice and",
    "start": "863519",
    "end": "868839"
  },
  {
    "text": "simple then we've got a function called step and this step",
    "start": "868839",
    "end": "874560"
  },
  {
    "text": "function actually implements this interface it it uh it implements this interface of",
    "start": "874560",
    "end": "879920"
  },
  {
    "text": "providing an action to the environment and returning a state and a reward",
    "start": "879920",
    "end": "885839"
  },
  {
    "text": "so you can see here in the the parameters we're passing in an action and all of this code",
    "start": "886240",
    "end": "893760"
  },
  {
    "text": "is basically just controlling the transition from one state to another",
    "start": "893760",
    "end": "898880"
  },
  {
    "text": "um yeah it's you know for example if we if we pass an action um of direction north if we tell the",
    "start": "898880",
    "end": "906079"
  },
  {
    "text": "agent to go up then we're we're basically just incrementing the y counter for that uh for for the current",
    "start": "906079",
    "end": "913760"
  },
  {
    "text": "state okay so that's just a quite a bit it's just yeah it's probably cleaner or simpler ways of",
    "start": "913760",
    "end": "920000"
  },
  {
    "text": "doing that but it's just controlling the internal state then we're checking to see if the agent is out of bounds",
    "start": "920000",
    "end": "926079"
  },
  {
    "text": "if it's out of bounds so if it's moved off the board we just move it back on we just put it back to its previous",
    "start": "926079",
    "end": "931360"
  },
  {
    "text": "position so from the outside what the agent will what it will look like is that the agent",
    "start": "931360",
    "end": "936399"
  },
  {
    "text": "tries to you know move off the board but it can't",
    "start": "936399",
    "end": "942480"
  },
  {
    "text": "then we have a flag here to check to see whether the current position is",
    "start": "942480",
    "end": "948800"
  },
  {
    "text": "actually the goal so to see if the agent has reached the terminating state",
    "start": "948800",
    "end": "954399"
  },
  {
    "text": "and finally we we are specifying the the reward and this is actually a really crucial",
    "start": "954399",
    "end": "960320"
  },
  {
    "text": "part of the design process so the reward encodes the goal",
    "start": "960320",
    "end": "965440"
  },
  {
    "text": "of the optimization here we're setting it to -1 which means that we're",
    "start": "965440",
    "end": "970639"
  },
  {
    "text": "negatively rewarding for every single movement for every movement that it makes we're saying no bad bad agent like",
    "start": "970639",
    "end": "978560"
  },
  {
    "text": "try not to move um and what that will do over time is that encourages the agent",
    "start": "978560",
    "end": "984639"
  },
  {
    "text": "to take fewer steps to get to the goal if we just set this to zero we're",
    "start": "984639",
    "end": "990160"
  },
  {
    "text": "effectively saying you can move freely you can you can do what you want if we set this to a positive value then we're actually encouraging it to move",
    "start": "990160",
    "end": "996959"
  },
  {
    "text": "more so yeah this is really important and in more complex problems it can",
    "start": "996959",
    "end": "1004320"
  },
  {
    "text": "a lot of time is spent tuning and designing this reward to suit the problem that you're trying",
    "start": "1004320",
    "end": "1010000"
  },
  {
    "text": "to solve okay and then we're passing back the current position the reward",
    "start": "1010000",
    "end": "1016000"
  },
  {
    "text": "and this is terminal flag so it's really important in any data",
    "start": "1016000",
    "end": "1022839"
  },
  {
    "text": "science discipline to visualize your data to visualize what is going on",
    "start": "1022839",
    "end": "1030079"
  },
  {
    "text": "and no different here so what i've done is coded up a function to present a visualization of",
    "start": "1030079",
    "end": "1037280"
  },
  {
    "text": "that environment and it's quite simple it's just a a big print statement it's just outputting some text and i'll",
    "start": "1037280",
    "end": "1044798"
  },
  {
    "text": "show you that in a second so now let's just test all of this code so i'm instantiating the class here",
    "start": "1044799",
    "end": "1050960"
  },
  {
    "text": "this is our environment class and then i'm passing an action",
    "start": "1050960",
    "end": "1057360"
  },
  {
    "text": "to the step function repeatedly so i'm ascending south south south east east east so when we run that",
    "start": "1057360",
    "end": "1065120"
  },
  {
    "text": "what we'll do is because we turn this deep debug flag on we'll get this printout of the environment state",
    "start": "1065120",
    "end": "1072160"
  },
  {
    "text": "and here you can see a single character for every single square on that board we've got a five by five",
    "start": "1072160",
    "end": "1078240"
  },
  {
    "text": "square so we've got you know yep five by five five lines five five characters",
    "start": "1078240",
    "end": "1083760"
  },
  {
    "text": "the x represents the agent the zero the o represents the goal and when we pass in",
    "start": "1083760",
    "end": "1091600"
  },
  {
    "text": "the action and call the step function you'll see that the agent has moved down it's moved",
    "start": "1091600",
    "end": "1097120"
  },
  {
    "text": "south and it's moved south again and each time it's returning this",
    "start": "1097120",
    "end": "1102559"
  },
  {
    "text": "from the step function it's returning the the new position the new state it's returning the reward for that",
    "start": "1102559",
    "end": "1109280"
  },
  {
    "text": "action and whether this is terminal so we're going to keep moving south we're going to keep moving south now",
    "start": "1109280",
    "end": "1115840"
  },
  {
    "text": "we're at the bottom can't move anymore if it tries to move south again it'll just stay exactly where it is but it will still uh it will still",
    "start": "1115840",
    "end": "1123440"
  },
  {
    "text": "receive a reward of minus one for trying to move out of bounds um then we move east east east east and",
    "start": "1123440",
    "end": "1130640"
  },
  {
    "text": "eventually we get to the terminating state and that's represented by an at symbol when the the agent is on a terminating",
    "start": "1130640",
    "end": "1136960"
  },
  {
    "text": "state and now our flag is is set to true all right so we've got an environment",
    "start": "1136960",
    "end": "1143200"
  },
  {
    "text": "now what do we do next well the next part of the problem is",
    "start": "1143200",
    "end": "1149280"
  },
  {
    "text": "what we'll think about what we're trying to do we're trying to",
    "start": "1149280",
    "end": "1154400"
  },
  {
    "text": "um typically we're trying to find a way of uh getting to the goal we want to try",
    "start": "1154400",
    "end": "1160400"
  },
  {
    "text": "and achieve some goal and we want to do that in the best way possible the definition of",
    "start": "1160400",
    "end": "1165679"
  },
  {
    "text": "best and and optimal is entirely dependent on that reward function so in this particular occasion what",
    "start": "1165679",
    "end": "1172000"
  },
  {
    "text": "we're saying is that we want to try and get to the goal in as few steps as possible so what we",
    "start": "1172000",
    "end": "1177520"
  },
  {
    "text": "need to do is try and write an algorithm that um that achieves that",
    "start": "1177520",
    "end": "1183520"
  },
  {
    "text": "one of the simplest algorithms that you can write is something called uh the cross-entropy method",
    "start": "1183520",
    "end": "1190799"
  },
  {
    "text": "and that's a bit of a bit of a fancy name but it's quite a simple algorithm and it it",
    "start": "1190799",
    "end": "1196240"
  },
  {
    "text": "can work quite well and even in complex scenarios the idea is is that you randomly explore",
    "start": "1196240",
    "end": "1202480"
  },
  {
    "text": "an environment until you reach a terminating state and you do that many many many many many",
    "start": "1202480",
    "end": "1208159"
  },
  {
    "text": "times over a long period of time eventually you happen to",
    "start": "1208159",
    "end": "1213760"
  },
  {
    "text": "randomly stumble across a strategy or a trajectory to a goal",
    "start": "1213760",
    "end": "1219360"
  },
  {
    "text": "that is actually quite good so in this algorithm what you do is you repeat that many times and then you look",
    "start": "1219360",
    "end": "1226000"
  },
  {
    "text": "at the final reward and you pick the set of actions that produced the best reward",
    "start": "1226000",
    "end": "1232400"
  },
  {
    "text": "and then you just repeat those set of actions and that is then your optimal strategy um so that's all well",
    "start": "1232400",
    "end": "1240320"
  },
  {
    "text": "and good and it's very simple and it's simple to code and it's a really good baseline because it does tend to work quite well",
    "start": "1240320",
    "end": "1247440"
  },
  {
    "text": "in in many situations but it's not particularly intelligent it's not really using any knowledge or um it's it's not it's not",
    "start": "1247440",
    "end": "1255919"
  },
  {
    "text": "using the information provided by the environment to further optimize those trajectories so",
    "start": "1255919",
    "end": "1262000"
  },
  {
    "text": "one of the earliest and most fundamental algorithms is something",
    "start": "1262000",
    "end": "1269120"
  },
  {
    "text": "called a monte carlo algorithm and monte carlo is a statistics technique which is very",
    "start": "1269120",
    "end": "1275520"
  },
  {
    "text": "similar to what i just explained where you are randomly sampling you're randomly asking the environment to provide you with a",
    "start": "1275520",
    "end": "1281520"
  },
  {
    "text": "sample and over time you can build a really good picture of the of of how that environment",
    "start": "1281520",
    "end": "1289200"
  },
  {
    "text": "actually how that environment works basically so",
    "start": "1289200",
    "end": "1294480"
  },
  {
    "text": "monte carlo techniques are trying to sample many times and build a picture so that we can then guide the direction",
    "start": "1294480",
    "end": "1300320"
  },
  {
    "text": "in the future and one way of doing that is to quantify the value of being in a",
    "start": "1300320",
    "end": "1307120"
  },
  {
    "text": "particular state so if we just go back to this picture here for a second",
    "start": "1307120",
    "end": "1312559"
  },
  {
    "text": "and um here's our chess board think of this as a chess board and think of that bottom right hand corner as being",
    "start": "1312559",
    "end": "1318000"
  },
  {
    "text": "a goal we know that it takes a reward of minus one to to move a",
    "start": "1318000",
    "end": "1324000"
  },
  {
    "text": "single square so if we are in any of these states that are in that bottom right hand corner",
    "start": "1324000",
    "end": "1331120"
  },
  {
    "text": "then we know that we can actually sorry not yeah we've only said north south east or west actually so we",
    "start": "1331120",
    "end": "1337600"
  },
  {
    "text": "have to move to the left or down in order to get there so actually it's only two states if we're in any of these two states that are next",
    "start": "1337600",
    "end": "1344480"
  },
  {
    "text": "to the the terminating state then it only takes one step to get there so that means that",
    "start": "1344480",
    "end": "1351679"
  },
  {
    "text": "there is a a an optimal action that we can choose in order to get to the terminating state",
    "start": "1351679",
    "end": "1358320"
  },
  {
    "text": "and it will reward us with -1 and so in in this state it will be south and in",
    "start": "1358320",
    "end": "1364159"
  },
  {
    "text": "this state it'll be east",
    "start": "1364159",
    "end": "1368240"
  },
  {
    "text": "and for those two states then we know that if we just pick the action",
    "start": "1369520",
    "end": "1375919"
  },
  {
    "text": "with the highest reward or the highest expected reward then that's going to lead us to the",
    "start": "1375919",
    "end": "1382000"
  },
  {
    "text": "terminating state so what what the monte carlo algorithm does is it tries to visit all of these",
    "start": "1382000",
    "end": "1387440"
  },
  {
    "text": "states and it tries to see the value of moving in every single direction because",
    "start": "1387440",
    "end": "1392720"
  },
  {
    "text": "obviously if you're in this if you're in this state here and you move to the left then actually that's not very good at all because",
    "start": "1392720",
    "end": "1398880"
  },
  {
    "text": "you're going to have to loop around and take many more steps to get to the terminating state so the value of going to the left to",
    "start": "1398880",
    "end": "1406240"
  },
  {
    "text": "going west is is very low but the value of going to the right going east",
    "start": "1406240",
    "end": "1411760"
  },
  {
    "text": "is very high all right hopefully that makes sense so the first thing that we need to do is code up an",
    "start": "1411760",
    "end": "1418799"
  },
  {
    "text": "um a piece of code that allows us to generate these trajectories",
    "start": "1418799",
    "end": "1423919"
  },
  {
    "text": "so this this class and this method here is um a bit of code to",
    "start": "1423919",
    "end": "1430400"
  },
  {
    "text": "choose a random you see the the random library there right choose a random action",
    "start": "1430400",
    "end": "1437279"
  },
  {
    "text": "um whilst it's not terminal so it's just repeatedly picking random actions",
    "start": "1437279",
    "end": "1442320"
  },
  {
    "text": "and it keeps doing so until it reaches a terminating state and when it does that it results in an",
    "start": "1442320",
    "end": "1449760"
  },
  {
    "text": "array of action choices and also states as",
    "start": "1449760",
    "end": "1454880"
  },
  {
    "text": "well and you can see in this particular run this will be different because it's random every time",
    "start": "1454880",
    "end": "1460159"
  },
  {
    "text": "but in this particular run it chose to go down and up and up and left and left and down and so on",
    "start": "1460159",
    "end": "1466080"
  },
  {
    "text": "and this represents a single trajectory for a single episode so each each item in here is one step",
    "start": "1466080",
    "end": "1472880"
  },
  {
    "text": "this is a full trajectory and uh this is a trajectory for one episode and the total reward for this",
    "start": "1472880",
    "end": "1479440"
  },
  {
    "text": "episode was -10 so that's actually pretty good um because it's moving randomly can take a very long time sometimes to",
    "start": "1479440",
    "end": "1486559"
  },
  {
    "text": "actually reach the terminating state so that's actually a pretty good run and",
    "start": "1486559",
    "end": "1492400"
  },
  {
    "text": "then once we do that i'm just going to skip over that that section just for a second what we then want to do is we want to",
    "start": "1492400",
    "end": "1498400"
  },
  {
    "text": "try and quantify the value of each of those states so",
    "start": "1498400",
    "end": "1503600"
  },
  {
    "text": "one way of doing that is calculating the average reward observed for each action",
    "start": "1503600",
    "end": "1512840"
  },
  {
    "text": "um uh well back from the terminating state so",
    "start": "1512840",
    "end": "1518240"
  },
  {
    "text": "um what we're doing here is we're taking a trajectory so just like the array you saw earlier we're reversing it so we're starting",
    "start": "1518240",
    "end": "1525039"
  },
  {
    "text": "from the end we're starting from the terminal state and then we're working backwards to see",
    "start": "1525039",
    "end": "1530080"
  },
  {
    "text": "how many more steps it takes to get to the to the uh to the goal and then over time",
    "start": "1530080",
    "end": "1537840"
  },
  {
    "text": "we can average out those average um rewards",
    "start": "1537840",
    "end": "1543279"
  },
  {
    "text": "and hopefully build a picture of on average how many steps does it take to get to the terminal",
    "start": "1543279",
    "end": "1548880"
  },
  {
    "text": "terminating state from this particular state all right and obviously to do that we",
    "start": "1548880",
    "end": "1554320"
  },
  {
    "text": "just need a couple of dictionaries to store the raw the raw values the raw um uh the yeah the the role",
    "start": "1554320",
    "end": "1562559"
  },
  {
    "text": "rewards and uh how many times we've actually visited that state so we just keep track of that and then",
    "start": "1562559",
    "end": "1568080"
  },
  {
    "text": "calculate the average here right so when we run that then we end up",
    "start": "1568080",
    "end": "1574799"
  },
  {
    "text": "with this you know quite giant 2d grid where for every single square",
    "start": "1574799",
    "end": "1579840"
  },
  {
    "text": "we have an array of four things that represents the value of each action so remember let's just go back to",
    "start": "1579840",
    "end": "1587760"
  },
  {
    "text": "let me just find yeah let's just use this square for a second um so if this is the terminating state",
    "start": "1587760",
    "end": "1593520"
  },
  {
    "text": "then the estate that's just to the left of it will have four elements in there it'll",
    "start": "1593520",
    "end": "1600080"
  },
  {
    "text": "have four actions with four values and the action that is saying go east",
    "start": "1600080",
    "end": "1606400"
  },
  {
    "text": "should have a value of minus one okay and so that's what i'm printing out here",
    "start": "1606400",
    "end": "1611440"
  },
  {
    "text": "i'm printing out the um the raw action values for",
    "start": "1611440",
    "end": "1616960"
  },
  {
    "text": "that particular state and you can see that we've got north and then east and then",
    "start": "1616960",
    "end": "1622640"
  },
  {
    "text": "south and then west for the east we've got a reward of minus one perfect um so that's what you'd expect after",
    "start": "1622640",
    "end": "1629440"
  },
  {
    "text": "many many many runs so obviously again we're still we're still dependent on random sampling here",
    "start": "1629440",
    "end": "1634640"
  },
  {
    "text": "so it may not actually visit that action or it may not even visit this entire state for quite a while",
    "start": "1634640",
    "end": "1641440"
  },
  {
    "text": "so what we need to do is run that for many iterations i ran it for a thousand iterations and it ended up with this",
    "start": "1641440",
    "end": "1648559"
  },
  {
    "text": "this is a plot of the average expected return the average expected",
    "start": "1648559",
    "end": "1654640"
  },
  {
    "text": "reward for all actions so this is saying and and yeah so basically this is",
    "start": "1654640",
    "end": "1662240"
  },
  {
    "text": "answering the question what is the value of being in in a particular state and you can see that the values",
    "start": "1662240",
    "end": "1668159"
  },
  {
    "text": "tend to be lower the closer they are to the uh to the terminating state and they",
    "start": "1668159",
    "end": "1674240"
  },
  {
    "text": "tend to be higher further away so now what we can do is we can generate an",
    "start": "1674240",
    "end": "1681360"
  },
  {
    "text": "optimal strategy by looking at all of those actions and saying which is the best action",
    "start": "1681360",
    "end": "1687120"
  },
  {
    "text": "so that's what this bit of code is doing here it's trying to find the best action and you end up with a plot that looks",
    "start": "1687120",
    "end": "1693360"
  },
  {
    "text": "like this every single square now has a best action attributed to it and all",
    "start": "1693360",
    "end": "1698799"
  },
  {
    "text": "of the actions are generally pointing towards the um terminating states they're all",
    "start": "1698799",
    "end": "1705279"
  },
  {
    "text": "generally kind of guiding you no matter where you go in the right direction but remember this",
    "start": "1705279",
    "end": "1710399"
  },
  {
    "text": "is still due to random sampling and it's quite noisy especially far away from the terminating state",
    "start": "1710399",
    "end": "1716559"
  },
  {
    "text": "and so if you look here look at those two states you've got one that says go down but then the next one says go up so this",
    "start": "1716559",
    "end": "1723279"
  },
  {
    "text": "is just going to end up in some kind of infinite loop going up and down up and down up and down and up and down",
    "start": "1723279",
    "end": "1728480"
  },
  {
    "text": "um but if we ran this for longer you would hope that it would average out and the policy would get better",
    "start": "1728480",
    "end": "1735200"
  },
  {
    "text": "but there are far more sophisticated algorithms that avoid this problem entirely um but this is a yeah a simple way of",
    "start": "1735200",
    "end": "1742320"
  },
  {
    "text": "kind of introducing what an optimal strategy or an optimal policy actually is all right",
    "start": "1742320",
    "end": "1750159"
  },
  {
    "text": "so i encourage you to go through that and play with it and tinker with the code and and ideally if you really want to get a",
    "start": "1750159",
    "end": "1756080"
  },
  {
    "text": "good intuition actually code it yourself so start from scratch um and you can do",
    "start": "1756080",
    "end": "1761679"
  },
  {
    "text": "all sorts of things you could try increasing the size of the grid you could uh you could add holes in the",
    "start": "1761679",
    "end": "1767120"
  },
  {
    "text": "middle see what happens if the agent falls down a big hole add some walls add a cliff at one side",
    "start": "1767120",
    "end": "1773520"
  },
  {
    "text": "change the reward value things like that see what happens um",
    "start": "1773520",
    "end": "1778880"
  },
  {
    "text": "and i'm just going to go back to the presentation now just to finish this off and i wanted to sort of bring this back",
    "start": "1778880",
    "end": "1784720"
  },
  {
    "text": "to the real world a little bit let's skip through all this",
    "start": "1784720",
    "end": "1790480"
  },
  {
    "start": "1790000",
    "end": "1913000"
  },
  {
    "text": "yeah i wanted to bring this back to the real world because this seems really really simplistic and in in some ways it is um",
    "start": "1790480",
    "end": "1798080"
  },
  {
    "text": "but there are applications that kind of fit very well to this to this idea of simulating this 2d space",
    "start": "1798080",
    "end": "1804799"
  },
  {
    "text": "so one example that is quite common is when you're working with geospatial domains um there's there's one paper on",
    "start": "1804799",
    "end": "1812000"
  },
  {
    "text": "there on the website uh so on the website sorry just to recap there is a whole section dedicated to",
    "start": "1812000",
    "end": "1818080"
  },
  {
    "text": "industrial applications of reinforcement learning one application on there is it talks about",
    "start": "1818080",
    "end": "1824559"
  },
  {
    "text": "optimizing um taxi routes according to a geospatial grid in in new",
    "start": "1824559",
    "end": "1830399"
  },
  {
    "text": "york and the idea is is that if you can tell the taxes to go to the right square at",
    "start": "1830399",
    "end": "1835760"
  },
  {
    "text": "the right time then people are able to get a taxi whenever they want less traffic less congestion",
    "start": "1835760",
    "end": "1841440"
  },
  {
    "text": "more earnings more efficiency this is another example which could use a a a discrete state and i think this",
    "start": "1841440",
    "end": "1849520"
  },
  {
    "text": "example is really cool this is an example of a html styled",
    "start": "1849520",
    "end": "1855200"
  },
  {
    "text": "inbox there's there's lots of other html style things that you could you could do as well and the state is",
    "start": "1855200",
    "end": "1861600"
  },
  {
    "text": "the actual html code the action is a css selector",
    "start": "1861600",
    "end": "1867279"
  },
  {
    "text": "and the goal is represented by a text string so the the idea here is that you will",
    "start": "1867279",
    "end": "1873840"
  },
  {
    "text": "say a command say forward the email from kyle to anna and the agent over time by randomly",
    "start": "1873840",
    "end": "1881679"
  },
  {
    "text": "sampling all of these actions in these states will learn how to you know forward an email to anna by using the right",
    "start": "1881679",
    "end": "1888080"
  },
  {
    "text": "css css selector and this is just a quick gif so showing that in action we've got the",
    "start": "1888080",
    "end": "1893760"
  },
  {
    "text": "goal at the top we've got the the actions that the agent is choosing and it's writing some text and it's",
    "start": "1893760",
    "end": "1899120"
  },
  {
    "text": "sporting emails um and stuff like that so it's a really good sort of tech example from the tech industry um that",
    "start": "1899120",
    "end": "1906960"
  },
  {
    "text": "uses a discrete state so it's not that unrealistic what we've been doing",
    "start": "1906960",
    "end": "1912880"
  },
  {
    "text": "all right just a reminder that this has touched the surface and you can find a lot more in my new",
    "start": "1912880",
    "end": "1918480"
  },
  {
    "start": "1913000",
    "end": "1957000"
  },
  {
    "text": "book on reinforcement learning um if you are attempting or wanting or thinking about using reinforcement",
    "start": "1918480",
    "end": "1925200"
  },
  {
    "text": "learning in industry in in your job for your company then i'd really really like to talk to",
    "start": "1925200",
    "end": "1930960"
  },
  {
    "text": "you uh about that more so please do get in touch windowresearch.com or",
    "start": "1930960",
    "end": "1936159"
  },
  {
    "text": "just you know any any way you can search for me and you should be able to find me",
    "start": "1936159",
    "end": "1941200"
  },
  {
    "text": "and with that i've run out of time and i'll hand it over to questions thank you very much",
    "start": "1941200",
    "end": "1949840"
  },
  {
    "text": "you",
    "start": "1956640",
    "end": "1958720"
  }
]
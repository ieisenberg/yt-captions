[
  {
    "text": "Apache spark an open- Source data",
    "start": "320",
    "end": "2480"
  },
  {
    "text": "analytics engine that can process",
    "start": "2480",
    "end": "4400"
  },
  {
    "text": "massive streams of data from multiple",
    "start": "4400",
    "end": "6319"
  },
  {
    "text": "sources like an octopus juggling",
    "start": "6319",
    "end": "8200"
  },
  {
    "text": "chainsaws it was created in 2009 by mate",
    "start": "8200",
    "end": "11160"
  },
  {
    "text": "zaharia at UC Berkeley's amp lab around",
    "start": "11160",
    "end": "13920"
  },
  {
    "text": "this time the amount of data being",
    "start": "13920",
    "end": "15559"
  },
  {
    "text": "collected on the internet was exploding",
    "start": "15559",
    "end": "17400"
  },
  {
    "text": "from megabytes to pedabytes making it",
    "start": "17400",
    "end": "19439"
  },
  {
    "text": "impossible to analyze on a single",
    "start": "19439",
    "end": "21160"
  },
  {
    "text": "machine but there was already a clever",
    "start": "21160",
    "end": "22800"
  },
  {
    "text": "programming model called map reduce you",
    "start": "22800",
    "end": "24760"
  },
  {
    "text": "map data into key value pairs Shuffle",
    "start": "24760",
    "end": "26920"
  },
  {
    "text": "and sort them into groups by key then",
    "start": "26920",
    "end": "28960"
  },
  {
    "text": "reduce each group to to compute a final",
    "start": "28960",
    "end": "30800"
  },
  {
    "text": "result this allowed large data sets to",
    "start": "30800",
    "end": "32758"
  },
  {
    "text": "be distributed across multiple machines",
    "start": "32759",
    "end": "35040"
  },
  {
    "text": "but there was still a huge bottleneck",
    "start": "35040",
    "end": "36520"
  },
  {
    "text": "caused by dis iio aache spark fixed this",
    "start": "36520",
    "end": "39160"
  },
  {
    "text": "by doing most of its work in memory",
    "start": "39160",
    "end": "40960"
  },
  {
    "text": "instead of reading from disk which can",
    "start": "40960",
    "end": "42559"
  },
  {
    "text": "be up to 100 times faster and that's a",
    "start": "42559",
    "end": "44559"
  },
  {
    "text": "game Cher for big data analytics and",
    "start": "44559",
    "end": "46600"
  },
  {
    "text": "machine learning it's used by Amazon to",
    "start": "46600",
    "end": "48680"
  },
  {
    "text": "analyze e-commerce data by NASA's jet",
    "start": "48680",
    "end": "51120"
  },
  {
    "text": "propulsion lab to analyze deep space",
    "start": "51120",
    "end": "53399"
  },
  {
    "text": "along with 80% of Fortune 500 companies",
    "start": "53399",
    "end": "55680"
  },
  {
    "text": "to process all their data despite its",
    "start": "55680",
    "end": "57600"
  },
  {
    "text": "reputation for distributed big data",
    "start": "57600",
    "end": "59519"
  },
  {
    "text": "processing you can easily run Apache",
    "start": "59519",
    "end": "61519"
  },
  {
    "text": "spark locally on your own machine it's",
    "start": "61519",
    "end": "63280"
  },
  {
    "text": "written in Java and runs on the jvm but",
    "start": "63280",
    "end": "65640"
  },
  {
    "text": "its apis can be used with wrappers for",
    "start": "65640",
    "end": "67720"
  },
  {
    "text": "python SQL and many other languages to",
    "start": "67720",
    "end": "70320"
  },
  {
    "text": "get started install it then let's",
    "start": "70320",
    "end": "72159"
  },
  {
    "text": "imagine we have a CSV file with four",
    "start": "72159",
    "end": "74240"
  },
  {
    "text": "columns for City population latitude and",
    "start": "74240",
    "end": "77080"
  },
  {
    "text": "longitude and our boss wants us to find",
    "start": "77080",
    "end": "78960"
  },
  {
    "text": "the city with the biggest population",
    "start": "78960",
    "end": "80520"
  },
  {
    "text": "between the tropics the first step is to",
    "start": "80520",
    "end": "82600"
  },
  {
    "text": "initialize a session and then load the",
    "start": "82600",
    "end": "84360"
  },
  {
    "text": "data into memory the spark will take the",
    "start": "84360",
    "end": "86119"
  },
  {
    "text": "spreadsheet and create a data frame",
    "start": "86119",
    "end": "88119"
  },
  {
    "text": "which turns the columns and rows into a",
    "start": "88119",
    "end": "89920"
  },
  {
    "text": "collection of objects they can be",
    "start": "89920",
    "end": "91479"
  },
  {
    "text": "processed across distributed nodes from",
    "start": "91479",
    "end": "93600"
  },
  {
    "text": "here we can apply transformations to the",
    "start": "93600",
    "end": "95280"
  },
  {
    "text": "data frame by chaining method calls like",
    "start": "95280",
    "end": "97680"
  },
  {
    "text": "in this case we want to filter the data",
    "start": "97680",
    "end": "99479"
  },
  {
    "text": "frame to exclude cities outside of the",
    "start": "99479",
    "end": "101479"
  },
  {
    "text": "tropics that transformation will happen",
    "start": "101479",
    "end": "103439"
  },
  {
    "text": "in memory then we can order the results",
    "start": "103439",
    "end": "105399"
  },
  {
    "text": "by population and finally use first to",
    "start": "105399",
    "end": "107880"
  },
  {
    "text": "grab the largest tropical City to the",
    "start": "107880",
    "end": "109719"
  },
  {
    "text": "city of Mexico City pretty cool and if",
    "start": "109719",
    "end": "112079"
  },
  {
    "text": "you're working with a SQL database you",
    "start": "112079",
    "end": "113920"
  },
  {
    "text": "can easily use that data directly",
    "start": "113920",
    "end": "115680"
  },
  {
    "text": "instead of the data frame API and when",
    "start": "115680",
    "end": "117680"
  },
  {
    "text": "working with massive data sets it Sparks",
    "start": "117680",
    "end": "119880"
  },
  {
    "text": "cluster manager or tools like kubernetes",
    "start": "119880",
    "end": "122000"
  },
  {
    "text": "can scale this workload horizontally",
    "start": "122000",
    "end": "123840"
  },
  {
    "text": "across an unlimited number of machines",
    "start": "123840",
    "end": "125719"
  },
  {
    "text": "but when it comes to machine learning",
    "start": "125719",
    "end": "127200"
  },
  {
    "text": "spark also has a secret weapon called",
    "start": "127200",
    "end": "129239"
  },
  {
    "text": "MLB let's build a predictive model by",
    "start": "129239",
    "end": "131440"
  },
  {
    "text": "first bringing in Vector assembler to",
    "start": "131440",
    "end": "133200"
  },
  {
    "text": "merge multiple columns into a vector",
    "start": "133200",
    "end": "134959"
  },
  {
    "text": "column then we can split it up into",
    "start": "134959",
    "end": "136760"
  },
  {
    "text": "training and testing data frames from",
    "start": "136760",
    "end": "138760"
  },
  {
    "text": "there spark has a wide variety of",
    "start": "138760",
    "end": "140480"
  },
  {
    "text": "different algorithms to handle",
    "start": "140480",
    "end": "141959"
  },
  {
    "text": "classification regression clustering and",
    "start": "141959",
    "end": "144519"
  },
  {
    "text": "so on all of which can be trained in a",
    "start": "144519",
    "end": "146360"
  },
  {
    "text": "distributed system congratulations you",
    "start": "146360",
    "end": "148400"
  },
  {
    "text": "can now train large scale Ma machine",
    "start": "148400",
    "end": "150080"
  },
  {
    "text": "learning models this has been a patchy",
    "start": "150080",
    "end": "151720"
  },
  {
    "text": "spark in 100 seconds but before one can",
    "start": "151720",
    "end": "154239"
  },
  {
    "text": "truly harness the full potential of",
    "start": "154239",
    "end": "155720"
  },
  {
    "text": "spark one must have a solid foundation",
    "start": "155720",
    "end": "157720"
  },
  {
    "text": "and math and problem solving and you can",
    "start": "157720",
    "end": "159440"
  },
  {
    "text": "start building that foundation for free",
    "start": "159440",
    "end": "161280"
  },
  {
    "text": "right now thanks to this video sponsor",
    "start": "161280",
    "end": "163280"
  },
  {
    "text": "brilliant brilliant's platform will",
    "start": "163280",
    "end": "164920"
  },
  {
    "text": "introduce you to essential programming",
    "start": "164920",
    "end": "166599"
  },
  {
    "text": "Concepts but most importantly the",
    "start": "166599",
    "end": "168599"
  },
  {
    "text": "Hands-On exercises will develop your",
    "start": "168599",
    "end": "170519"
  },
  {
    "text": "brain to recognize and solve complex",
    "start": "170519",
    "end": "173080"
  },
  {
    "text": "problems that developers need to",
    "start": "173080",
    "end": "174599"
  },
  {
    "text": "overcome on a daily basis best of all",
    "start": "174599",
    "end": "176879"
  },
  {
    "text": "every lesson is concise and rewarding",
    "start": "176879",
    "end": "178800"
  },
  {
    "text": "but by investing just a few minutes each",
    "start": "178800",
    "end": "180480"
  },
  {
    "text": "day you'll develop habits that can level",
    "start": "180480",
    "end": "182280"
  },
  {
    "text": "up your programming skills for the rest",
    "start": "182280",
    "end": "183920"
  },
  {
    "text": "of your life and you can do it anywhere",
    "start": "183920",
    "end": "185959"
  },
  {
    "text": "even from your phone to try everything",
    "start": "185959",
    "end": "187799"
  },
  {
    "text": "brilliant has to offer for free for 30",
    "start": "187799",
    "end": "189920"
  },
  {
    "text": "days visit brilliant.org fireship or",
    "start": "189920",
    "end": "192879"
  },
  {
    "text": "scan this QR code for 20% off their",
    "start": "192879",
    "end": "195280"
  },
  {
    "text": "premium annual subscription thanks for",
    "start": "195280",
    "end": "197159"
  },
  {
    "text": "watching and I will see you in the next",
    "start": "197159",
    "end": "198760"
  },
  {
    "text": "one",
    "start": "198760",
    "end": "201159"
  }
]
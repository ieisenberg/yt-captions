[
  {
    "text": "recently somehow I got access to an",
    "start": "120",
    "end": "2240"
  },
  {
    "text": "overpowered h100 GPU and on it I was",
    "start": "2240",
    "end": "5120"
  },
  {
    "text": "able to self-host and scale my own Army",
    "start": "5120",
    "end": "7319"
  },
  {
    "text": "of AI agents thanks to a new tool called",
    "start": "7319",
    "end": "9559"
  },
  {
    "text": "Nim 10 years from now the workforce will",
    "start": "9559",
    "end": "11639"
  },
  {
    "text": "look nothing like it does today Bill",
    "start": "11639",
    "end": "13440"
  },
  {
    "text": "Gates once said most people overestimate",
    "start": "13440",
    "end": "15799"
  },
  {
    "text": "what they can do in one year and",
    "start": "15799",
    "end": "17359"
  },
  {
    "text": "underestimate what they can do in 10",
    "start": "17359",
    "end": "18960"
  },
  {
    "text": "years AI models like llama 3 mistal and",
    "start": "18960",
    "end": "21720"
  },
  {
    "text": "stable diffusion have already changed",
    "start": "21720",
    "end": "23519"
  },
  {
    "text": "the world but they've barely even",
    "start": "23519",
    "end": "25240"
  },
  {
    "text": "penetrated the mainstream Consciousness",
    "start": "25240",
    "end": "26920"
  },
  {
    "text": "over the last year in today's video",
    "start": "26920",
    "end": "28679"
  },
  {
    "text": "we'll fast forward 10 years into the",
    "start": "28679",
    "end": "30279"
  },
  {
    "text": "future to a magical time when any job",
    "start": "30279",
    "end": "32719"
  },
  {
    "text": "that can be done by a robot will be done",
    "start": "32719",
    "end": "34680"
  },
  {
    "text": "by a robot some experts think that we'll",
    "start": "34680",
    "end": "36520"
  },
  {
    "text": "create a Sci-Fi AGI an all-in-one jack",
    "start": "36520",
    "end": "39280"
  },
  {
    "text": "of all trades in a black box that can do",
    "start": "39280",
    "end": "41320"
  },
  {
    "text": "every intellectual job better than we",
    "start": "41320",
    "end": "43039"
  },
  {
    "text": "humans do but that's highly speculative",
    "start": "43039",
    "end": "45320"
  },
  {
    "text": "perhaps a far more realistic vision is a",
    "start": "45320",
    "end": "47480"
  },
  {
    "text": "network of Highly specialized AI agents",
    "start": "47480",
    "end": "49800"
  },
  {
    "text": "running on kubernetes if you're an indie",
    "start": "49800",
    "end": "51879"
  },
  {
    "text": "hacker entrepreneur or even a massive",
    "start": "51879",
    "end": "53879"
  },
  {
    "text": "Enterprise and you want to build an AI",
    "start": "53879",
    "end": "55600"
  },
  {
    "text": "Workforce that includes a doctor a",
    "start": "55600",
    "end": "57359"
  },
  {
    "text": "lawyer and a programmer you'll quickly",
    "start": "57359",
    "end": "59000"
  },
  {
    "text": "run into a massive technical challenge",
    "start": "59000",
    "end": "61000"
  },
  {
    "text": "even if your AI models are smart enough",
    "start": "61000",
    "end": "62879"
  },
  {
    "text": "to do these jobs a model is quite",
    "start": "62879",
    "end": "64799"
  },
  {
    "text": "literally just a file with weights and",
    "start": "64799",
    "end": "66520"
  },
  {
    "text": "biases AKA numbers but in order to run",
    "start": "66520",
    "end": "69360"
  },
  {
    "text": "inference with it like generate text and",
    "start": "69360",
    "end": "71400"
  },
  {
    "text": "images you'll need a massive amount of",
    "start": "71400",
    "end": "73159"
  },
  {
    "text": "RAM and the parallel Computing magic of",
    "start": "73159",
    "end": "75080"
  },
  {
    "text": "a GPU to do all that linear algebra and",
    "start": "75080",
    "end": "77479"
  },
  {
    "text": "if your app ever goes viral it'll",
    "start": "77479",
    "end": "79080"
  },
  {
    "text": "quickly grind to a halt because scaling",
    "start": "79080",
    "end": "80880"
  },
  {
    "text": "up this technology is extremely",
    "start": "80880",
    "end": "82840"
  },
  {
    "text": "difficult well not anymore thanks to",
    "start": "82840",
    "end": "84680"
  },
  {
    "text": "Nvidia Nim the sponsor of today's video",
    "start": "84680",
    "end": "87320"
  },
  {
    "text": "Nvidia was kind enough to give me access",
    "start": "87320",
    "end": "89159"
  },
  {
    "text": "to an H1 100 GPU to try out their Nvidia",
    "start": "89159",
    "end": "92200"
  },
  {
    "text": "Nims which are inference microservices",
    "start": "92200",
    "end": "94520"
  },
  {
    "text": "what they do is package up popular AI",
    "start": "94520",
    "end": "96720"
  },
  {
    "text": "models along with all the apis that you",
    "start": "96720",
    "end": "98680"
  },
  {
    "text": "need to run them at scale including",
    "start": "98680",
    "end": "100320"
  },
  {
    "text": "inference engines like tensor RT llm as",
    "start": "100320",
    "end": "103280"
  },
  {
    "text": "well as data management tools for",
    "start": "103280",
    "end": "105079"
  },
  {
    "text": "authentication health checks monitoring",
    "start": "105079",
    "end": "107479"
  },
  {
    "text": "and so on all these apis along with the",
    "start": "107479",
    "end": "109719"
  },
  {
    "text": "model itself are containerized and run",
    "start": "109719",
    "end": "111680"
  },
  {
    "text": "on kubernetes that means you can deploy",
    "start": "111680",
    "end": "113399"
  },
  {
    "text": "it to the cloud on Prem or even on your",
    "start": "113399",
    "end": "115560"
  },
  {
    "text": "local PC and that's going to save you",
    "start": "115560",
    "end": "117399"
  },
  {
    "text": "weeks if not months of painful",
    "start": "117399",
    "end": "118920"
  },
  {
    "text": "development time well at a real example",
    "start": "118920",
    "end": "120759"
  },
  {
    "text": "in just a minute but what's cool about",
    "start": "120759",
    "end": "122320"
  },
  {
    "text": "this platform is that there's a",
    "start": "122320",
    "end": "123560"
  },
  {
    "text": "playground where you can play around",
    "start": "123560",
    "end": "125039"
  },
  {
    "text": "with these Nims right now it has all the",
    "start": "125039",
    "end": "126920"
  },
  {
    "text": "popular large language models like llama",
    "start": "126920",
    "end": "129239"
  },
  {
    "text": "mistal Gemma and so on it can do image",
    "start": "129239",
    "end": "131560"
  },
  {
    "text": "and video with stable diffusion and",
    "start": "131560",
    "end": "133440"
  },
  {
    "text": "others along with a bunch of other",
    "start": "133440",
    "end": "135160"
  },
  {
    "text": "specialized models for healthcare",
    "start": "135160",
    "end": "137040"
  },
  {
    "text": "climate simulation and more these models",
    "start": "137040",
    "end": "139319"
  },
  {
    "text": "are hosted by Nvidia and you can use",
    "start": "139319",
    "end": "141200"
  },
  {
    "text": "them right now in the browser or you can",
    "start": "141200",
    "end": "143080"
  },
  {
    "text": "access them via the API and they've been",
    "start": "143080",
    "end": "145040"
  },
  {
    "text": "standardized to work with the open AI",
    "start": "145040",
    "end": "146800"
  },
  {
    "text": "SDK in addition because it's",
    "start": "146800",
    "end": "148560"
  },
  {
    "text": "containerized you can also pull it with",
    "start": "148560",
    "end": "150360"
  },
  {
    "text": "Docker and run it in your local",
    "start": "150360",
    "end": "151879"
  },
  {
    "text": "environment or configure it in the cloud",
    "start": "151879",
    "end": "153560"
  },
  {
    "text": "to scale to any workload and now we can",
    "start": "153560",
    "end": "155519"
  },
  {
    "text": "start to see what the future Workforce",
    "start": "155519",
    "end": "157080"
  },
  {
    "text": "might look like imagine you work for",
    "start": "157080",
    "end": "158800"
  },
  {
    "text": "dinosaur Enterprises and your CEO",
    "start": "158800",
    "end": "161239"
  },
  {
    "text": "chainsaw Jeff wants to cut down the",
    "start": "161239",
    "end": "163080"
  },
  {
    "text": "human-based headcount by 90% is so it",
    "start": "163080",
    "end": "165440"
  },
  {
    "text": "can increase his bonus by 4% how is he",
    "start": "165440",
    "end": "167599"
  },
  {
    "text": "going to do that for shareholders so",
    "start": "167599",
    "end": "169120"
  },
  {
    "text": "first let's get rid of customer service",
    "start": "169120",
    "end": "170680"
  },
  {
    "text": "agents by deploying one Nim that can",
    "start": "170680",
    "end": "172480"
  },
  {
    "text": "recognize speech along with a large",
    "start": "172480",
    "end": "174280"
  },
  {
    "text": "language model to generate text we might",
    "start": "174280",
    "end": "176319"
  },
  {
    "text": "also want to replace warehouse workers",
    "start": "176319",
    "end": "178159"
  },
  {
    "text": "with Superior autonomous forlift drivers",
    "start": "178159",
    "end": "180480"
  },
  {
    "text": "and a custom trained Nim hosted on Prem",
    "start": "180480",
    "end": "182480"
  },
  {
    "text": "is perfect for that we also have",
    "start": "182480",
    "end": "183959"
  },
  {
    "text": "hundreds of worthless product managers",
    "start": "183959",
    "end": "185640"
  },
  {
    "text": "who do nothing but post Day in the Life",
    "start": "185640",
    "end": "187080"
  },
  {
    "text": "Tik toks so let's add a stable diffusion",
    "start": "187080",
    "end": "188959"
  },
  {
    "text": "Nim to generate product mockups and",
    "start": "188959",
    "end": "190959"
  },
  {
    "text": "website designs to get rid of them now",
    "start": "190959",
    "end": "192840"
  },
  {
    "text": "these websites aren't going to build",
    "start": "192840",
    "end": "194200"
  },
  {
    "text": "themselves well no actually they are if",
    "start": "194200",
    "end": "196120"
  },
  {
    "text": "we deploy a Nim that can code and then",
    "start": "196120",
    "end": "197959"
  },
  {
    "text": "finally for the last 10% of humans",
    "start": "197959",
    "end": "199640"
  },
  {
    "text": "working here we can deploy a mental",
    "start": "199640",
    "end": "201519"
  },
  {
    "text": "health Nim to ensure their continued",
    "start": "201519",
    "end": "203080"
  },
  {
    "text": "well-being now obviously I'm joking here",
    "start": "203080",
    "end": "205159"
  },
  {
    "text": "and humans will continue to thrive",
    "start": "205159",
    "end": "206720"
  },
  {
    "text": "thrive in the artificial intelligence",
    "start": "206720",
    "end": "208159"
  },
  {
    "text": "age but the main takeaway here is that",
    "start": "208159",
    "end": "210040"
  },
  {
    "text": "Nims allow anyone to scale AI in any",
    "start": "210040",
    "end": "212599"
  },
  {
    "text": "environment and it's all about",
    "start": "212599",
    "end": "213799"
  },
  {
    "text": "augmenting human work as opposed to",
    "start": "213799",
    "end": "215519"
  },
  {
    "text": "replacing it my personal goal is to",
    "start": "215519",
    "end": "217439"
  },
  {
    "text": "someday create a billion- Dollar",
    "start": "217439",
    "end": "218840"
  },
  {
    "text": "business as a single solo developer and",
    "start": "218840",
    "end": "220879"
  },
  {
    "text": "Nims are the perfect tool to make that",
    "start": "220879",
    "end": "222480"
  },
  {
    "text": "dream a little more realistic they",
    "start": "222480",
    "end": "224159"
  },
  {
    "text": "simultaneously reduce development time",
    "start": "224159",
    "end": "226080"
  },
  {
    "text": "while facilitating the deployment of",
    "start": "226080",
    "end": "227480"
  },
  {
    "text": "tools that augment my own limited human",
    "start": "227480",
    "end": "229680"
  },
  {
    "text": "capabilities but now let's take a look",
    "start": "229680",
    "end": "231360"
  },
  {
    "text": "at how it works from a programming",
    "start": "231360",
    "end": "232879"
  },
  {
    "text": "perspective like I mentioned before",
    "start": "232879",
    "end": "234480"
  },
  {
    "text": "Nvidia gave me access to an h100 for a",
    "start": "234480",
    "end": "236840"
  },
  {
    "text": "few days which is their 80 gb GPU used",
    "start": "236840",
    "end": "239200"
  },
  {
    "text": "in data C these things go for about 30",
    "start": "239200",
    "end": "241319"
  },
  {
    "text": "grand on the street if you can even get",
    "start": "241319",
    "end": "242799"
  },
  {
    "text": "your hands on one and it was just way",
    "start": "242799",
    "end": "244400"
  },
  {
    "text": "more horsepower than I even knew what to",
    "start": "244400",
    "end": "245879"
  },
  {
    "text": "do with as you can see here I have sshed",
    "start": "245879",
    "end": "247920"
  },
  {
    "text": "into a server which is also conveniently",
    "start": "247920",
    "end": "250040"
  },
  {
    "text": "running vs code in the terminal you'll",
    "start": "250040",
    "end": "251879"
  },
  {
    "text": "notice we've pulled a Docker image and",
    "start": "251879",
    "end": "253480"
  },
  {
    "text": "I'm also running Nvidia SMI to check the",
    "start": "253480",
    "end": "255760"
  },
  {
    "text": "status of the GPU there's also a running",
    "start": "255760",
    "end": "257919"
  },
  {
    "text": "process for kubernetes that will allow",
    "start": "257919",
    "end": "259799"
  },
  {
    "text": "this microservice to automatically scale",
    "start": "259799",
    "end": "261799"
  },
  {
    "text": "when traffic increases and automatically",
    "start": "261799",
    "end": "263880"
  },
  {
    "text": "heal when things break most importantly",
    "start": "263880",
    "end": "266000"
  },
  {
    "text": "though everything is configured to work",
    "start": "266000",
    "end": "267560"
  },
  {
    "text": "out of the box you don't actually have",
    "start": "267560",
    "end": "269199"
  },
  {
    "text": "to touch kubernetes yourself all we have",
    "start": "269199",
    "end": "271039"
  },
  {
    "text": "to do is write a little bit of python to",
    "start": "271039",
    "end": "272680"
  },
  {
    "text": "run the model you could do this in a",
    "start": "272680",
    "end": "274199"
  },
  {
    "text": "python notebook but I'm just going to",
    "start": "274199",
    "end": "276000"
  },
  {
    "text": "write a python script here in this",
    "start": "276000",
    "end": "277720"
  },
  {
    "text": "app.py file the actual API to access the",
    "start": "277720",
    "end": "280600"
  },
  {
    "text": "model is running on Local Host 8000 we",
    "start": "280600",
    "end": "283160"
  },
  {
    "text": "can use the request library and python",
    "start": "283160",
    "end": "285160"
  },
  {
    "text": "to send HTTP request to it like the",
    "start": "285160",
    "end": "287520"
  },
  {
    "text": "first thing we might want to do is see",
    "start": "287520",
    "end": "289039"
  },
  {
    "text": "which models are available in this",
    "start": "289039",
    "end": "290800"
  },
  {
    "text": "environment we currently have access to",
    "start": "290800",
    "end": "292560"
  },
  {
    "text": "llama 3 now that we have that piece of",
    "start": "292560",
    "end": "294560"
  },
  {
    "text": "information we can make a post request",
    "start": "294560",
    "end": "296759"
  },
  {
    "text": "to the chat completions endpoint and",
    "start": "296759",
    "end": "299039"
  },
  {
    "text": "most importantly we have an array of",
    "start": "299039",
    "end": "300759"
  },
  {
    "text": "messages here which provide the llm with",
    "start": "300759",
    "end": "303160"
  },
  {
    "text": "context for the conversation in my case",
    "start": "303160",
    "end": "305639"
  },
  {
    "text": "I want to ask it the question of what is",
    "start": "305639",
    "end": "307720"
  },
  {
    "text": "the best JavaScript framework of all",
    "start": "307720",
    "end": "309240"
  },
  {
    "text": "time then from there we can Define some",
    "start": "309240",
    "end": "311000"
  },
  {
    "text": "configuration options like the model",
    "start": "311000",
    "end": "313000"
  },
  {
    "text": "name max number of tokens temperature",
    "start": "313000",
    "end": "315280"
  },
  {
    "text": "Etc and then finally to get a response",
    "start": "315280",
    "end": "317520"
  },
  {
    "text": "all we have to do is make a post request",
    "start": "317520",
    "end": "319319"
  },
  {
    "text": "with this data now let's go ahead and",
    "start": "319319",
    "end": "321000"
  },
  {
    "text": "run this code by pulling up the terminal",
    "start": "321000",
    "end": "323039"
  },
  {
    "text": "and entering python app.py you'll notice",
    "start": "323039",
    "end": "325919"
  },
  {
    "text": "we get a full response almost",
    "start": "325919",
    "end": "327520"
  },
  {
    "text": "instantaneously under the hood these n",
    "start": "327520",
    "end": "329759"
  },
  {
    "text": "use tools you would expect like pytorch",
    "start": "329759",
    "end": "331960"
  },
  {
    "text": "but also other tools you may not know",
    "start": "331960",
    "end": "333560"
  },
  {
    "text": "about like Triton to maximize",
    "start": "333560",
    "end": "335479"
  },
  {
    "text": "performance on inference which is",
    "start": "335479",
    "end": "337039"
  },
  {
    "text": "awesome because that means you don't",
    "start": "337039",
    "end": "338280"
  },
  {
    "text": "need to figure out how to make things",
    "start": "338280",
    "end": "339680"
  },
  {
    "text": "fast on your own and I would say latency",
    "start": "339680",
    "end": "341560"
  },
  {
    "text": "is probably the number one killer for",
    "start": "341560",
    "end": "343080"
  },
  {
    "text": "people starting their own AI SAS",
    "start": "343080",
    "end": "344880"
  },
  {
    "text": "products oh and in addition we can also",
    "start": "344880",
    "end": "347120"
  },
  {
    "text": "monitor the hardware like here I can see",
    "start": "347120",
    "end": "348919"
  },
  {
    "text": "the GPU temperature jumped after I asked",
    "start": "348919",
    "end": "350759"
  },
  {
    "text": "it that question and we can also keep an",
    "start": "350759",
    "end": "352520"
  },
  {
    "text": "eye on the CPU and memory usage now of",
    "start": "352520",
    "end": "354759"
  },
  {
    "text": "course when I ask llama 3 for the best",
    "start": "354759",
    "end": "356400"
  },
  {
    "text": "JavaScript framework it's going to",
    "start": "356400",
    "end": "357800"
  },
  {
    "text": "respond with react even though that's",
    "start": "357800",
    "end": "359400"
  },
  {
    "text": "clear clearly a lie so I changed my",
    "start": "359400",
    "end": "361160"
  },
  {
    "text": "prompt to ask it what the worst",
    "start": "361160",
    "end": "362440"
  },
  {
    "text": "JavaScript framework is and of course it",
    "start": "362440",
    "end": "364280"
  },
  {
    "text": "threw shade at its arch nemesis angular",
    "start": "364280",
    "end": "366520"
  },
  {
    "text": "which is the real best JavaScript",
    "start": "366520",
    "end": "367880"
  },
  {
    "text": "framework ever invented but one other",
    "start": "367880",
    "end": "369639"
  },
  {
    "text": "thing I'll mention in the code here is",
    "start": "369639",
    "end": "371080"
  },
  {
    "text": "that instead of request we could also",
    "start": "371080",
    "end": "372759"
  },
  {
    "text": "use the open AI SDK which is extremely",
    "start": "372759",
    "end": "375400"
  },
  {
    "text": "popular and has become somewhat of an",
    "start": "375400",
    "end": "377160"
  },
  {
    "text": "industry standard the bottom line though",
    "start": "377160",
    "end": "379080"
  },
  {
    "text": "is that we now have an API that can",
    "start": "379080",
    "end": "380880"
  },
  {
    "text": "scale up to an infinite number of gpus",
    "start": "380880",
    "end": "383160"
  },
  {
    "text": "those gpus could live on AWS they could",
    "start": "383160",
    "end": "385440"
  },
  {
    "text": "live in your own data center or it could",
    "start": "385440",
    "end": "387039"
  },
  {
    "text": "be the one in your PC right now but",
    "start": "387039",
    "end": "388720"
  },
  {
    "text": "pretty awesome and if you want to try",
    "start": "388720",
    "end": "390039"
  },
  {
    "text": "out Nims for yourself I'd recommend",
    "start": "390039",
    "end": "391680"
  },
  {
    "text": "going directly to the API catalog at",
    "start": "391680",
    "end": "393880"
  },
  {
    "text": "build. nvidia.com where you can easily",
    "start": "393880",
    "end": "396080"
  },
  {
    "text": "try them out or check out Nvidia AI",
    "start": "396080",
    "end": "398000"
  },
  {
    "text": "Enterprise if your goal is to operate at",
    "start": "398000",
    "end": "399919"
  },
  {
    "text": "a massive scale thanks for watching and",
    "start": "399919",
    "end": "401800"
  },
  {
    "text": "I will see you in the next one",
    "start": "401800",
    "end": "405039"
  }
]
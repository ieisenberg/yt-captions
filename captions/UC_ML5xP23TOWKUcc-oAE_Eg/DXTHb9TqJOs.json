[
  {
    "start": "0",
    "end": "30000"
  },
  {
    "text": "what is going on guys this video is actually a compilation of all my",
    "start": "640",
    "end": "6560"
  },
  {
    "text": "cues and publish subscribe specific videos so i took those old",
    "start": "6560",
    "end": "12080"
  },
  {
    "text": "videos and fixed the audio because some of them are had like a bad quality of an audio",
    "start": "12080",
    "end": "17199"
  },
  {
    "text": "and then recompile them into one massive video i hope you enjoy it",
    "start": "17199",
    "end": "25359"
  },
  {
    "text": "the message queue is a very useful backend infrastructure piece that allows for asynchronous and",
    "start": "28800",
    "end": "36320"
  },
  {
    "start": "30000",
    "end": "84000"
  },
  {
    "text": "distributed processing and many other use cases as well it is designed so that a publisher",
    "start": "36320",
    "end": "43200"
  },
  {
    "text": "can publish a message to the centralized piece so this is the software the message queue",
    "start": "43200",
    "end": "48320"
  },
  {
    "text": "and a consumer can consume that message in a first and first",
    "start": "48320",
    "end": "54480"
  },
  {
    "text": "out manner the goal here is every consumer once that message is popped",
    "start": "54480",
    "end": "60640"
  },
  {
    "text": "that's it it's gone from the queue no other consumer can consume the same message right that's the",
    "start": "60640",
    "end": "66720"
  },
  {
    "text": "trick here as a result building a message queue is very very difficult and very very challenging because how do you",
    "start": "66720",
    "end": "72159"
  },
  {
    "text": "guarantee that that message has been consumed once and only once by a given consumer it's very",
    "start": "72159",
    "end": "78720"
  },
  {
    "text": "challenging kafka rabbit mq active mq and others does things",
    "start": "78720",
    "end": "84840"
  },
  {
    "start": "84000",
    "end": "873000"
  },
  {
    "text": "differently what is going on guys my name is hussain",
    "start": "84840",
    "end": "91520"
  },
  {
    "text": "and this video i want to discuss cues and when to use the cues message cues to be specific",
    "start": "91520",
    "end": "97439"
  },
  {
    "text": "like there are other type of queues but i don't i'm not sure what are they so i'm talking about rabbitmq 0mq",
    "start": "97439",
    "end": "104479"
  },
  {
    "text": "kafka when do you want to use this in your architecture and do you really need it right and that's the question",
    "start": "104479",
    "end": "110720"
  },
  {
    "text": "here you always have a question that hey do i really need to implement this in my system design or not",
    "start": "110720",
    "end": "117200"
  },
  {
    "text": "and i'm just trying to kind of assess that and help you with that if possible",
    "start": "117200",
    "end": "124159"
  },
  {
    "text": "so how about we jump into it and if you're new here guys i discuss all sorts of back in engineering this channel so",
    "start": "124159",
    "end": "129679"
  },
  {
    "text": "if you're interested subscribe and like this video and share with your friends that's it let's just jump into it",
    "start": "129679",
    "end": "135680"
  },
  {
    "text": "all right so what is a queue and when do we need to use it and",
    "start": "135680",
    "end": "140840"
  },
  {
    "text": "guys if you if you already uh subscribe to my channel you would see",
    "start": "140840",
    "end": "146160"
  },
  {
    "text": "me repeat this over and over again any technology out there any back-end technology out there",
    "start": "146160",
    "end": "151519"
  },
  {
    "text": "it exists for a reason and it exists to solve a problem",
    "start": "151519",
    "end": "156720"
  },
  {
    "text": "so yeah i know that might sound cliche and makes just perfect sense right just yeah of",
    "start": "156720",
    "end": "162480"
  },
  {
    "text": "course it exists for reason and that also means that there's no technology just exists for a",
    "start": "162480",
    "end": "167760"
  },
  {
    "text": "fun of it or because it's cool right you need to use it if that problem exists for you",
    "start": "167760",
    "end": "174879"
  },
  {
    "text": "you cannot just use grpc because it's hip and cool right no you should use it when",
    "start": "174879",
    "end": "181840"
  },
  {
    "text": "you absolutely the problems that grpc addresses solves your problem right addresses your",
    "start": "181840",
    "end": "189040"
  },
  {
    "text": "problem same thing with a queue so how about we talk about the actual problems with the queue solved",
    "start": "189040",
    "end": "196159"
  },
  {
    "text": "back to the request response architecture when i make a request to a backend",
    "start": "196159",
    "end": "203200"
  },
  {
    "text": "and regardless of the communication protocol that i use whether it's tcp stateful tcp",
    "start": "203200",
    "end": "210480"
  },
  {
    "text": "raw or whether i'm using grpc again stateful or with mm whether i'm",
    "start": "210480",
    "end": "217599"
  },
  {
    "text": "using a stateless wrist architecture that request requires some resources at the back end",
    "start": "217599",
    "end": "225440"
  },
  {
    "text": "to be served right to be consumed and executed that request",
    "start": "225440",
    "end": "233360"
  },
  {
    "text": "what does that mean it means that request might be less to get all the employees right or",
    "start": "233360",
    "end": "241360"
  },
  {
    "text": "an update to do a booking system right it's like hey i'm on a book this seat that's that's a",
    "start": "241360",
    "end": "247680"
  },
  {
    "text": "that's same thing right and this requires a finite amount of time",
    "start": "247680",
    "end": "252959"
  },
  {
    "text": "of your server to actually process this and we talked about the ways you can",
    "start": "252959",
    "end": "260160"
  },
  {
    "text": "serve your request and one way to solve this problem is asynchronous",
    "start": "260160",
    "end": "267919"
  },
  {
    "text": "execution with a single thread like your server has one thread and that thread just keeps",
    "start": "267919",
    "end": "275520"
  },
  {
    "text": "working the problems that it have right it's all server and request this is now it's listening to tcp connection this is now",
    "start": "275520",
    "end": "281759"
  },
  {
    "text": "doing that that's how node.js does it right other other web servers",
    "start": "281759",
    "end": "286800"
  },
  {
    "text": "uh does it differently multi-threading multi-processing right regardless right so apache does",
    "start": "286800",
    "end": "291840"
  },
  {
    "text": "multi-threading node.js does a single thread but it's asynchronous and we talked about that i'm going to reference the video here i think it's",
    "start": "291840",
    "end": "297840"
  },
  {
    "text": "here go check it out but sometimes a single thread in a node.js",
    "start": "297840",
    "end": "305360"
  },
  {
    "text": "or multi-processing or multi-threading in a web server",
    "start": "305360",
    "end": "311759"
  },
  {
    "text": "could not cut it because you will quickly overwhelm that single server to execute",
    "start": "311759",
    "end": "318639"
  },
  {
    "text": "all these requests right it really depends if that request is taking a long time to process",
    "start": "318639",
    "end": "326240"
  },
  {
    "text": "and if it does that if that equals taking a huge amount of time an unpredictable amount of time to",
    "start": "326240",
    "end": "332320"
  },
  {
    "text": "process then there are flood of other requests",
    "start": "332320",
    "end": "337840"
  },
  {
    "text": "that is coming i'm not talking about cues yet guys right just normal request response there are flood",
    "start": "337840",
    "end": "343919"
  },
  {
    "text": "of requests coming and they are waiting and when i say waiting they the client",
    "start": "343919",
    "end": "350639"
  },
  {
    "text": "is actually just blocked because that access to the tcp connection didn't",
    "start": "350639",
    "end": "357039"
  },
  {
    "text": "even get a response back okay and that could be harmful for the user experience",
    "start": "357039",
    "end": "363919"
  },
  {
    "text": "right the user will feel it so what is going on i clicked and nothing happened and users hate that when they click and",
    "start": "363919",
    "end": "371120"
  },
  {
    "text": "nothing happens you show me something that happens or tell me that something is happening but don't tell me that i'm",
    "start": "371120",
    "end": "380000"
  },
  {
    "text": "doing something and i did something and i don't see any results they hate that you're a user you probably seen that",
    "start": "380000",
    "end": "389039"
  },
  {
    "text": "so how do we trick that a normal request response architecture",
    "start": "389039",
    "end": "394639"
  },
  {
    "text": "doesn't cut it in this case if your response time is unpredictable",
    "start": "394639",
    "end": "400080"
  },
  {
    "text": "right because you have a lot of requests coming and you might say hey who's saying i'm",
    "start": "400080",
    "end": "406479"
  },
  {
    "text": "going to scale horizontally and that's absolutely fine you can do that you can put a reverse proxy",
    "start": "406479",
    "end": "412400"
  },
  {
    "text": "have it configured to be a load balancer and swizzle the request to all the other",
    "start": "412400",
    "end": "419039"
  },
  {
    "text": "services and if you have if you start waiting if you've started seeing",
    "start": "419039",
    "end": "424880"
  },
  {
    "text": "requests taking a long time to process right then you start spinning up more",
    "start": "424880",
    "end": "431759"
  },
  {
    "text": "services or containers if you're in a micro services architecture and then start serving that and people",
    "start": "431759",
    "end": "437280"
  },
  {
    "text": "do this to this day without a cue without the idea of a queue right and as i said this doesn't really",
    "start": "437280",
    "end": "443120"
  },
  {
    "text": "scale well if your processing at the back end is is very hungry processing hungary or cpu hungry",
    "start": "443120",
    "end": "450080"
  },
  {
    "text": "or even ram hungry right because you cannot spend a lot of time",
    "start": "450080",
    "end": "455520"
  },
  {
    "text": "just uh having this process take time so if you're",
    "start": "455520",
    "end": "460720"
  },
  {
    "text": "predicting that responses will always take a long time probably spinning up multiple services will not",
    "start": "460720",
    "end": "467840"
  },
  {
    "text": "help you right because the request will be the same whether it's going",
    "start": "467840",
    "end": "473280"
  },
  {
    "text": "uh it's sending to another server which are which is free or a service that is",
    "start": "473280",
    "end": "478960"
  },
  {
    "text": "server doing other things as well yeah you're going to see some mindless school",
    "start": "478960",
    "end": "485360"
  },
  {
    "text": "minus school is that the right word minor school difference but still it's going to take",
    "start": "485360",
    "end": "491280"
  },
  {
    "text": "a long time so here's where a queue is useful if you",
    "start": "491280",
    "end": "497680"
  },
  {
    "text": "really think that request will always exponentially go large yeah maybe if",
    "start": "497680",
    "end": "504800"
  },
  {
    "text": "your database is uh doesn't have any rows but as you grow large that request will go slower and slower",
    "start": "504800",
    "end": "510800"
  },
  {
    "text": "or slower what is that exponentially not necessary exponentially just uh polynomially",
    "start": "510800",
    "end": "516240"
  },
  {
    "text": "with your number of rows so here's where q really beneficial so what you would do",
    "start": "516240",
    "end": "522640"
  },
  {
    "text": "in this case is what is what i'm gonna do i'm gonna employ a queue",
    "start": "522640",
    "end": "528240"
  },
  {
    "text": "in my system a message queue and that means if i am receiving our quest a server",
    "start": "528240",
    "end": "534800"
  },
  {
    "text": "i will do a very quick operation that is constant",
    "start": "534800",
    "end": "541760"
  },
  {
    "text": "that is a big o of one it's a very fast operation and i'm gonna respond to",
    "start": "541760",
    "end": "548160"
  },
  {
    "text": "the user with that with some sort of an identifier right and here's that's that's how a",
    "start": "548160",
    "end": "556160"
  },
  {
    "text": "queue works so if i send me a request i'm gonna put it in a queue",
    "start": "556160",
    "end": "561360"
  },
  {
    "text": "that's a big off one because writing is always fast especially if you're in a lsm3 kind of a",
    "start": "561360",
    "end": "567680"
  },
  {
    "text": "database right and most databases now especially write only just right to the end lsm right log structure",
    "start": "567680",
    "end": "575040"
  },
  {
    "text": "mercy you write it and then you respond back to the user hey i committed to you user",
    "start": "575040",
    "end": "582640"
  },
  {
    "text": "that i have received your request and it's now processing or it's now it's in the queue",
    "start": "582640",
    "end": "589600"
  },
  {
    "text": "it i can't promise anything else but hey i received it better than having a request",
    "start": "589600",
    "end": "597040"
  },
  {
    "text": "that is not served right that is not just waiting so check",
    "start": "597040",
    "end": "603200"
  },
  {
    "text": "user experience better right okay i'm willing to wait as a user yeah at least i see they received it and",
    "start": "603200",
    "end": "610160"
  },
  {
    "text": "now really up to you as an architect you can have a client come back and",
    "start": "610160",
    "end": "618160"
  },
  {
    "text": "ask and paul p-o-l-l this task id that we're given",
    "start": "618160",
    "end": "626399"
  },
  {
    "text": "he's like hey how's how's this job down we're doing how's this job doing how's just just jump down and",
    "start": "626399",
    "end": "634560"
  },
  {
    "text": "once that response actually complete the response will come back hey that job is done okay you can now do",
    "start": "634560",
    "end": "641279"
  },
  {
    "text": "whatever you want to do that's one way of solving the problem rabbit in the queue doesn't do it this",
    "start": "641279",
    "end": "647040"
  },
  {
    "text": "way uh rabbit mq does it the push way",
    "start": "647040",
    "end": "652800"
  },
  {
    "text": "right where it's just like a stateful connection i forgot with the the",
    "start": "652800",
    "end": "657920"
  },
  {
    "text": "protocol that rabbitmq's but it's a it's a it's a very elegant way of using channels it's awesome",
    "start": "657920",
    "end": "663519"
  },
  {
    "text": "i love it and i'm going to make another video about this compared to http 2 the idea of rabbitmq using channels",
    "start": "663519",
    "end": "670480"
  },
  {
    "text": "it's very similar to streams and i don't know who came up with this idea before regardless get back to the point",
    "start": "670480",
    "end": "676880"
  },
  {
    "text": "if i response back if that job is dequeued right or executed",
    "start": "676880",
    "end": "685120"
  },
  {
    "text": "that could push results back to the client immediately as they are received right",
    "start": "685120",
    "end": "693600"
  },
  {
    "text": "so this way you eliminated the latency of waiting client is still",
    "start": "693600",
    "end": "701279"
  },
  {
    "text": "technically didn't receive the result right because you don't receive that result but i can unblock the user",
    "start": "701279",
    "end": "708399"
  },
  {
    "text": "experience i can show some sort of progress bar i can i can give a better user experience and i",
    "start": "708399",
    "end": "715440"
  },
  {
    "text": "elevated the flood of request on my server now i'm gonna have a nice",
    "start": "715440",
    "end": "721040"
  },
  {
    "text": "queue yes it's a centralized system still but it's an ice cube and people people services can listen to",
    "start": "721040",
    "end": "729200"
  },
  {
    "text": "the skew and start pulling jobs pulling tasks and execute and write it back to the queue",
    "start": "729200",
    "end": "735519"
  },
  {
    "text": "right very very similar to a pub sub system except the only difference",
    "start": "735519",
    "end": "741360"
  },
  {
    "text": "between a queue and a pub up a q is whenever you remove an item from the queue it is gone",
    "start": "741360",
    "end": "749360"
  },
  {
    "text": "right that service owns it it is dq'd",
    "start": "749360",
    "end": "754560"
  },
  {
    "text": "versus the pub sub system you have a topic or very similarly right",
    "start": "754560",
    "end": "761200"
  },
  {
    "text": "the brokers have these topics and the service can as infinitely",
    "start": "761200",
    "end": "766959"
  },
  {
    "text": "consume the same item many services can consume the same item right but now each service have",
    "start": "766959",
    "end": "774800"
  },
  {
    "text": "some sort of a position that remembers oh i consumed this yes i consumed this i consumed this and the",
    "start": "774800",
    "end": "780240"
  },
  {
    "text": "service optionally can have a way to go back and forth in the queue and then the pop sub system so that's a",
    "start": "780240",
    "end": "787040"
  },
  {
    "text": "very cool very quick way of knowing how do you actually when do you want to use a queue versus",
    "start": "787040",
    "end": "794800"
  },
  {
    "text": "just a normal request process circuit system and load balancing and all that stuff",
    "start": "794800",
    "end": "800079"
  },
  {
    "text": "right so very quick if your request is indeterministic you don't know how long it's going to take",
    "start": "800079",
    "end": "806880"
  },
  {
    "text": "a queue is probably a good idea for you if your process is by nature long running a queue is good for you i",
    "start": "806880",
    "end": "814480"
  },
  {
    "text": "just queue it and let other process pick up the work and write it back to the queue or if it's a",
    "start": "814480",
    "end": "822000"
  },
  {
    "text": "resource hungry if you're by default your process back in processing is a resource hungry it's a bad idea to",
    "start": "822000",
    "end": "828000"
  },
  {
    "text": "have the web server itself do the work for you the web server should do one job and one",
    "start": "828000",
    "end": "834160"
  },
  {
    "text": "job only shouldn't process your stinking request it should just response back",
    "start": "834160",
    "end": "839600"
  },
  {
    "text": "to web traffic a service web is it is a web server it serves web traffic",
    "start": "839600",
    "end": "845360"
  },
  {
    "text": "and that's it don't let it process your prime numbers or do a very complex operations in the web",
    "start": "845360",
    "end": "852160"
  },
  {
    "text": "servers stuff try to separate concerns as much as possible all right guys there's a quick video just to let you",
    "start": "852160",
    "end": "858320"
  },
  {
    "text": "know the difference between when to use a queue when do not use a queue hope you enjoyed this video",
    "start": "858320",
    "end": "863839"
  },
  {
    "text": "uh subscribe if you like this content like this video if you like it i'm gonna see in the next one you say guys stay",
    "start": "863839",
    "end": "870720"
  },
  {
    "text": "awesome",
    "start": "870720",
    "end": "873199"
  },
  {
    "start": "873000",
    "end": "1200000"
  },
  {
    "text": "let's start with request response model it's a very elegant and simple",
    "start": "876320",
    "end": "882000"
  },
  {
    "text": "design i have been designed in the 90s and the whole internet is running on this thing",
    "start": "882000",
    "end": "887839"
  },
  {
    "text": "it's very very simple design that's why it's popular so you're a client you're a web server",
    "start": "887839",
    "end": "895839"
  },
  {
    "text": "and the client makes a request let's say this is a get request over http",
    "start": "895839",
    "end": "901920"
  },
  {
    "text": "the client waits the client is blocked now you can argue with that whether it's",
    "start": "901920",
    "end": "907519"
  },
  {
    "text": "blocked and cannot do anything else right which is no longer true because we have asynchronous requests",
    "start": "907519",
    "end": "914800"
  },
  {
    "text": "right you can make a request and you can do other stuff in the background that's okay right",
    "start": "914800",
    "end": "920639"
  },
  {
    "text": "because it's just you make a request you wait and you don't actively wait you don't spend any",
    "start": "920639",
    "end": "928320"
  },
  {
    "text": "processing power waiting right just break a request and forget about it right and then once the request comes back you",
    "start": "928320",
    "end": "935279"
  },
  {
    "text": "get back a content and then you do something with this content right so that's the request response model",
    "start": "935279",
    "end": "940959"
  },
  {
    "text": "it's always the client initiating the request there is no other way coming from the",
    "start": "940959",
    "end": "946320"
  },
  {
    "text": "web server okay and i'm gonna reference a video here for the asynchronous versus asynchronous so there are a lot",
    "start": "946320",
    "end": "953519"
  },
  {
    "text": "of playlists that you can go and watch that if you're interested to know more all right and where does this break is this",
    "start": "953519",
    "end": "960240"
  },
  {
    "text": "perfect obviously nothing is perfect let's assume you have this system",
    "start": "960240",
    "end": "965440"
  },
  {
    "text": "where you want to upload a video let's say this is youtube and obviously when you upload a video to",
    "start": "965440",
    "end": "971040"
  },
  {
    "text": "youtube you don't just upload a video there are a lot of stuff happening in the background so you want to upload the whole video",
    "start": "971040",
    "end": "977440"
  },
  {
    "text": "you wanna youtube want to compress the video because usually it's that raw mp4 file is",
    "start": "977440",
    "end": "983600"
  },
  {
    "text": "very huge right you want to compress it and after compress is done you want to pick that up by the format",
    "start": "983600",
    "end": "990639"
  },
  {
    "text": "service you want to format and what does that mean you want to produce different video ties for",
    "start": "990639",
    "end": "996000"
  },
  {
    "text": "the appropriate devices so you want to provide a video for mobile phones so that's up maybe 480 or 720 or 1080 or",
    "start": "996000",
    "end": "1004160"
  },
  {
    "text": "4k i want to produce different kind of content right based on the viewing platform and",
    "start": "1004160",
    "end": "1009600"
  },
  {
    "text": "provide that and you want to also once this is done you want to notify subscribers so how do",
    "start": "1009600",
    "end": "1015199"
  },
  {
    "text": "you do that with just request response well it's still simple but it really breaks",
    "start": "1015199",
    "end": "1020639"
  },
  {
    "text": "down if you think about it so client makes a request uploads that beautiful raw mp4 video right and it waits",
    "start": "1020639",
    "end": "1028959"
  },
  {
    "text": "right it can do other stuff in the background but still waiting right and then upload service processing that",
    "start": "1028959",
    "end": "1035360"
  },
  {
    "text": "stuff and then once it's done it now it is waiting and it's making it",
    "start": "1035360",
    "end": "1042240"
  },
  {
    "text": "a quest to the compressed service to compress the uploaded video all right",
    "start": "1042240",
    "end": "1047520"
  },
  {
    "text": "okay that make our code now the compressed video is processing and what is it is done it",
    "start": "1047520",
    "end": "1054320"
  },
  {
    "text": "is waiting and make a request to the format service and waits right so a lot of people are",
    "start": "1054320",
    "end": "1059840"
  },
  {
    "text": "waiting there's a chain of people waiting for this thing to get done format service",
    "start": "1059840",
    "end": "1066160"
  },
  {
    "text": "is processing producing all these 418 720 and 1080 and 4k",
    "start": "1066160",
    "end": "1071280"
  },
  {
    "text": "and 8k there's no 8k right it's a fad all right i don't know if that's true",
    "start": "1071280",
    "end": "1078799"
  },
  {
    "text": "okay format services just processing that stuff and then once it's done it will make the",
    "start": "1078799",
    "end": "1085600"
  },
  {
    "text": "request to the notification so it's like okay i'm done let's make a request to the notification service which will notify all the",
    "start": "1085600",
    "end": "1092080"
  },
  {
    "text": "subscribers obviously that hey we're done this video is uploaded go and",
    "start": "1092080",
    "end": "1097679"
  },
  {
    "text": "and that and then the for myself is waiting for the notification service and you guys can't argue with this like",
    "start": "1097679",
    "end": "1103200"
  },
  {
    "text": "oh go no really we can notify people once it's uploaded right no really you want to notify",
    "start": "1103200",
    "end": "1109039"
  },
  {
    "text": "people when it's ready to be consumed when it's here it's not ready to be consumed right",
    "start": "1109039",
    "end": "1114640"
  },
  {
    "text": "so and that even get more complicated as we talk about it all right notification servers that okay i'm done",
    "start": "1114640",
    "end": "1120960"
  },
  {
    "text": "the first response format server says i'm done compressor i'm done so people start unblocking services start",
    "start": "1120960",
    "end": "1128880"
  },
  {
    "text": "unblocking the request as they come in and finally the client would say who done uploaded all right obviously",
    "start": "1128880",
    "end": "1136240"
  },
  {
    "text": "guys put anything that breaks in the middle the whole thing is broken i'm sorry",
    "start": "1136240",
    "end": "1142880"
  },
  {
    "text": "about that okay okay so the whole thing is essentially",
    "start": "1142880",
    "end": "1148720"
  },
  {
    "text": "broken right once you put any obstacle and network error the whole",
    "start": "1148720",
    "end": "1154720"
  },
  {
    "text": "chain is broken and you don't know if this thing is finished or not that's the problem we're facing with",
    "start": "1154720",
    "end": "1160320"
  },
  {
    "text": "request response if you're training multiple services especially in a microservices architecture",
    "start": "1160320",
    "end": "1165440"
  },
  {
    "text": "that breaks down let's say we i want to add another copyrighted service",
    "start": "1165440",
    "end": "1170799"
  },
  {
    "text": "and we want this to the copyright service like to check the contents for content ids",
    "start": "1170799",
    "end": "1177440"
  },
  {
    "text": "and check if there is like a copyright infringement right so you want to consume the compressed",
    "start": "1177440",
    "end": "1183600"
  },
  {
    "text": "service need to send the compressed file to both format and copyrighted oh my god right this",
    "start": "1183600",
    "end": "1191280"
  },
  {
    "text": "topology gets really complicated real quick son right all right what's good what's bad",
    "start": "1191280",
    "end": "1198720"
  },
  {
    "text": "about these pros it's very elegant and simple yes if you have only two pieces of",
    "start": "1198720",
    "end": "1207120"
  },
  {
    "start": "1200000",
    "end": "1451000"
  },
  {
    "text": "software talking to each other that's beautiful and i still love that but once you get into",
    "start": "1207120",
    "end": "1213360"
  },
  {
    "text": "complicated scenarios not really right it's elegant and simple i love that",
    "start": "1213360",
    "end": "1218640"
  },
  {
    "text": "it's stateless especially when you use http that's not really true for like uh request response like a database",
    "start": "1218640",
    "end": "1225840"
  },
  {
    "text": "like database you make a sequel that's still a request response you make update table where blah equal blah",
    "start": "1225840",
    "end": "1234960"
  },
  {
    "text": "that's a request and then when you get a better result like hey 70 year old updated that's a",
    "start": "1234960",
    "end": "1240320"
  },
  {
    "text": "response right that's still request response but that's that's nowhere stateless this is the stateflies gets",
    "start": "1240320",
    "end": "1246240"
  },
  {
    "text": "right http another is stateless but yes you can argue with that but but it is if",
    "start": "1246240",
    "end": "1252159"
  },
  {
    "text": "it's stateless it's good because it's scalable right you can scale it horizontally and that's a very",
    "start": "1252159",
    "end": "1258159"
  },
  {
    "text": "overloaded word i hate putting it there but i have to put something in the pros section scalable here means that it is",
    "start": "1258159",
    "end": "1264880"
  },
  {
    "text": "scalable at that receiver end where you can duplicate the receiver if it's the same",
    "start": "1264880",
    "end": "1272240"
  },
  {
    "text": "content right if it's the same has the same functionality you can duplicate it easily",
    "start": "1272240",
    "end": "1277600"
  },
  {
    "text": "and you can scale it easily right because it just makes the same request you can put it behind load balance and",
    "start": "1277600",
    "end": "1283600"
  },
  {
    "text": "beautiful idea right load balancer can just route request to any service and",
    "start": "1283600",
    "end": "1289039"
  },
  {
    "text": "just scales very nicely right but not really scalable in other terms right so scalable here is a very overloaded",
    "start": "1289039",
    "end": "1296320"
  },
  {
    "text": "word and i'm really mean about horizontal scalability of the same",
    "start": "1296320",
    "end": "1301760"
  },
  {
    "text": "duplicated service oh my god that's getting complicated okay what was that cons what's bad about",
    "start": "1301760",
    "end": "1308400"
  },
  {
    "text": "this obviously as we said it's very bad for multiple receivers the moment you start seeing a lot of raseivas",
    "start": "1308400",
    "end": "1314480"
  },
  {
    "text": "a lot of consumers you start really wearing yourself down and and and yeah things can go really long",
    "start": "1314480",
    "end": "1322400"
  },
  {
    "text": "at the moment you insert any thing in the middle right you your architecture falls apart okay",
    "start": "1322400",
    "end": "1329360"
  },
  {
    "text": "that's why you have to start hacking things on how do you hack things around right you basically introduce high coupling",
    "start": "1329360",
    "end": "1337360"
  },
  {
    "text": "so people a lot of services start talking to each other which produces a lot of high coupled services",
    "start": "1337360",
    "end": "1343679"
  },
  {
    "text": "so services start knowing each other and that's bad we want software to have social anxiety",
    "start": "1343679",
    "end": "1350159"
  },
  {
    "text": "we do not want software to talk to each other that's bad in software high coupling is bad we want",
    "start": "1350159",
    "end": "1356400"
  },
  {
    "text": "software to be as oblivious as possible about the whole system hi",
    "start": "1356400",
    "end": "1362799"
  },
  {
    "text": "coupling yeah we talked about that client and server have to be running you won't say hussein that's just weird",
    "start": "1362799",
    "end": "1370000"
  },
  {
    "text": "of course i'm gonna send a request of the servers down yeah of course the client have and",
    "start": "1370000",
    "end": "1375200"
  },
  {
    "text": "server has to be running to communicate are you telling me there's something better than that where the client can go",
    "start": "1375200",
    "end": "1381120"
  },
  {
    "text": "offline and or the server can go fly and still they can communicate oh we're gonna see about that all right",
    "start": "1381120",
    "end": "1388159"
  },
  {
    "text": "yeah so that's kind of a disadvantage pops up has this advantage still have my concerns about that but",
    "start": "1388159",
    "end": "1396000"
  },
  {
    "text": "we're going to talk about that all right so chaining circuit breaking retries all that stuff that we",
    "start": "1396000",
    "end": "1403360"
  },
  {
    "text": "introduced just to solve the problem of of how can we guarantee that these",
    "start": "1403360",
    "end": "1409440"
  },
  {
    "text": "topology of systems connect together right the highly coupled system can correctly",
    "start": "1409440",
    "end": "1415120"
  },
  {
    "text": "talk to each other right we need to time out correctly we need to retry if that didn't work",
    "start": "1415120",
    "end": "1420880"
  },
  {
    "text": "and that just put a lot of pressure on the service and complicate things even worse right and that is a problem",
    "start": "1420880",
    "end": "1428080"
  },
  {
    "text": "by itself it's not an easy problem to solve yes service missions take care of that stuff",
    "start": "1428080",
    "end": "1435200"
  },
  {
    "text": "clients like finagle on twitter that open source to finagle can take care of",
    "start": "1435200",
    "end": "1440480"
  },
  {
    "text": "that stuff for you right if you make a request but to me still",
    "start": "1440480",
    "end": "1445520"
  },
  {
    "text": "sounds like we have a very complex system so i don't know about that right yeah",
    "start": "1445520",
    "end": "1453278"
  },
  {
    "start": "1451000",
    "end": "1513000"
  },
  {
    "text": "a pops up is a back-end infrastructure piece that allows a publisher to publish a",
    "start": "1455360",
    "end": "1461440"
  },
  {
    "text": "message to the system and multiple consumers to consume the same message",
    "start": "1461440",
    "end": "1467120"
  },
  {
    "text": "over and over again example is let's say you upload a video to youtube",
    "start": "1467120",
    "end": "1472720"
  },
  {
    "text": "this video need to be processed need to be compressed it needs to be checked for copyright",
    "start": "1472720",
    "end": "1477840"
  },
  {
    "text": "violation and other stuff as well so these are consumers right and they all gonna",
    "start": "1477840",
    "end": "1483919"
  },
  {
    "text": "consume the same message the video right unlike a queue where once that message is popped",
    "start": "1483919",
    "end": "1490240"
  },
  {
    "text": "nobody should ever see it right for job processing or asynchronous processing",
    "start": "1490240",
    "end": "1496080"
  },
  {
    "text": "pop sub systems are very critical and very difficult to build because how do you guarantee that",
    "start": "1496080",
    "end": "1501440"
  },
  {
    "text": "every consumer have read the message at least once it depends on your guarantees kafka does",
    "start": "1501440",
    "end": "1506960"
  },
  {
    "text": "it differently robin mcq does it differently",
    "start": "1506960",
    "end": "1510960"
  },
  {
    "text": "all right pops up to the rescue it's the best thing ever not really all right so let's talk",
    "start": "1512960",
    "end": "1520080"
  },
  {
    "start": "1513000",
    "end": "1909000"
  },
  {
    "text": "about pabst up publish subscribe model all right we'll take the same example the youtube uploading service",
    "start": "1520080",
    "end": "1526240"
  },
  {
    "text": "and we're gonna upload a video and we're going to compress the video we're going to format the video we're",
    "start": "1526240",
    "end": "1531919"
  },
  {
    "text": "going to notify people how about that so there's as you can see here that you can see still the services here the",
    "start": "1531919",
    "end": "1537679"
  },
  {
    "text": "client here the notification services all that jazz but there's some box here this box is",
    "start": "1537679",
    "end": "1544559"
  },
  {
    "text": "the middle middle layer that everybody's communicating to and this is called multiple names people call it broker",
    "start": "1544559",
    "end": "1551919"
  },
  {
    "text": "people call it message queue people call it streaming processing a lot of names but it's a middleware",
    "start": "1551919",
    "end": "1559679"
  },
  {
    "text": "layer where you can push and publish content to it and it will take care of",
    "start": "1559679",
    "end": "1567840"
  },
  {
    "text": "delivering that content to someone else okay based on the subscription model so these",
    "start": "1567840",
    "end": "1575120"
  },
  {
    "text": "guys subscribe these guys publish everybody can publish and subscribe at the same time and you",
    "start": "1575120",
    "end": "1580960"
  },
  {
    "text": "publish and you subscribe and publish to what is called a queue or sometimes called topic like kafka",
    "start": "1580960",
    "end": "1587919"
  },
  {
    "text": "call it topic uh rabbit mq call it q",
    "start": "1587919",
    "end": "1592960"
  },
  {
    "text": "channels is called i think red is called channels right so by the way reduce and kafka and",
    "start": "1592960",
    "end": "1598640"
  },
  {
    "text": "rabbit mq 0mq all of that stuff are just this message queue that supports pops up",
    "start": "1598640",
    "end": "1603679"
  },
  {
    "text": "right all right let's go through an example and see if this thing is good or not all right so here's the thing here's what we're",
    "start": "1603679",
    "end": "1608960"
  },
  {
    "text": "going to do i'm going to i'm making a client i'm gonna upload the service still this is to add to an",
    "start": "1608960",
    "end": "1616000"
  },
  {
    "text": "extent this is still a request response right you can still mission mash what does",
    "start": "1616000",
    "end": "1621760"
  },
  {
    "text": "that mean mission match i don't think it's a word but yeah you can do a hybrid between request response and pops up so that's",
    "start": "1621760",
    "end": "1628080"
  },
  {
    "text": "okay right so you make a request and upload service stop processing",
    "start": "1628080",
    "end": "1633200"
  },
  {
    "text": "waiting for all your stuff so the client is blocked now right and again guys when i say block doesn't mean he cannot do anything or",
    "start": "1633200",
    "end": "1639760"
  },
  {
    "text": "she cannot do anything why am i referring to computers as gender okay i don't know all right so you make",
    "start": "1639760",
    "end": "1646880"
  },
  {
    "text": "a request and it waits right it still can't do other stuff in the background obviously",
    "start": "1646880",
    "end": "1652480"
  },
  {
    "text": "but it is asynchronous nevertheless so upload service processing once it's done the upload",
    "start": "1652480",
    "end": "1659279"
  },
  {
    "text": "service will say you know what just give me a second give me a second give me a second i'm gonna",
    "start": "1659279",
    "end": "1664640"
  },
  {
    "text": "publish this really quick to this topic and once i get the result and which is usually this quick because",
    "start": "1664640",
    "end": "1672080"
  },
  {
    "text": "these guys are in the same network interface i'm assuming this is another network interface",
    "start": "1672080",
    "end": "1678080"
  },
  {
    "text": "and this is another network interface so they communicate with this i am hoping this is in the same hopefully a",
    "start": "1678080",
    "end": "1684799"
  },
  {
    "text": "lan area and they will communicate whether like in a 10 gigabit uh ethernet network or",
    "start": "1684799",
    "end": "1691840"
  },
  {
    "text": "whatever and that will become fast right so you make a request and then we'll get response real quick upload",
    "start": "1691840",
    "end": "1697840"
  },
  {
    "text": "that five gig video once it's done that's it your job is",
    "start": "1697840",
    "end": "1702960"
  },
  {
    "text": "done as upload service so your client you can notify the client that it's done let's repeat that right all right so",
    "start": "1702960",
    "end": "1708159"
  },
  {
    "text": "upload once it's done publish it to a topic or a channel and get back a result and then sure upload",
    "start": "1708159",
    "end": "1714880"
  },
  {
    "text": "it done that's it the client now done its job you can disconnect the",
    "start": "1714880",
    "end": "1720720"
  },
  {
    "text": "client you can just move on with your life the video is in the system",
    "start": "1720720",
    "end": "1726320"
  },
  {
    "text": "and leave right obviously that means this guy has to be up all the time that's what she said but what we have",
    "start": "1726320",
    "end": "1732640"
  },
  {
    "text": "here is essentially a topic and that topic or the channel has the content it's sometimes called a cue",
    "start": "1732640",
    "end": "1739120"
  },
  {
    "text": "a topic a channel and that has the raw mp4 videos now how do people consume it these guys",
    "start": "1739120",
    "end": "1746240"
  },
  {
    "text": "would have been subscribed already to a topic that already exists i just",
    "start": "1746240",
    "end": "1751600"
  },
  {
    "text": "hide it i did some animation but compressed service in this case is subscribing to this topic now we're",
    "start": "1751600",
    "end": "1758480"
  },
  {
    "text": "gonna talk in details like how this is actually done is it",
    "start": "1758480",
    "end": "1763919"
  },
  {
    "text": "what does it mean to subscribe right it's very weird abstract word right is it",
    "start": "1763919",
    "end": "1770399"
  },
  {
    "text": "are you pushing the result to compress service the moment you have a raw mp4 video or is the",
    "start": "1770399",
    "end": "1777520"
  },
  {
    "text": "compressed service actually pulling information or is is it like pinging what's",
    "start": "1777520",
    "end": "1782799"
  },
  {
    "text": "happening here right so you gotta tell me more right so the compressed service there are multiple implementations we're",
    "start": "1782799",
    "end": "1788720"
  },
  {
    "text": "gonna talk about them but posh and long polling and then polling just",
    "start": "1788720",
    "end": "1793919"
  },
  {
    "text": "pulling is just useless i don't know why would you do that it's just same as a request response but all right",
    "start": "1793919",
    "end": "1800399"
  },
  {
    "text": "so the compressed service will receive now the raw mp4 value let's imagine that it",
    "start": "1800399",
    "end": "1805679"
  },
  {
    "text": "just got it like immediately pushed to it right that has this limitation obviously but we're",
    "start": "1805679",
    "end": "1811120"
  },
  {
    "text": "going to talk about that the compressed service receive this raw mp4 video start processing it and guess what it",
    "start": "1811120",
    "end": "1818080"
  },
  {
    "text": "will publish its own compressed video to another topic that says hey",
    "start": "1818080",
    "end": "1823120"
  },
  {
    "text": "compass video here is it all right it's a topic so it doesn't really know who's going to",
    "start": "1823120",
    "end": "1828880"
  },
  {
    "text": "consume it the upload service didn't know that the compressed server is going to consume it and that's the decoupling that we talked",
    "start": "1828880",
    "end": "1834960"
  },
  {
    "text": "about just decouple that everybody from each other the format services now",
    "start": "1834960",
    "end": "1840320"
  },
  {
    "text": "subscribe to the compressed video topic and it will get it immediately let's",
    "start": "1840320",
    "end": "1846000"
  },
  {
    "text": "this is a little bit okay yeah you get it whether it's push or long polling whatever you get it format",
    "start": "1846000",
    "end": "1853200"
  },
  {
    "text": "service it's just like publishing content look at that 480p 1080p this is garyvee man format",
    "start": "1853200",
    "end": "1860480"
  },
  {
    "text": "services garyvee just just producing content like there's no tomorrow format service publishes all",
    "start": "1860480",
    "end": "1865679"
  },
  {
    "text": "our stuff so that it's done now the notification service let's say you're notification you want",
    "start": "1865679",
    "end": "1871600"
  },
  {
    "text": "to identify people when the 4k video is ready i know this is a little bit harsh",
    "start": "1871600",
    "end": "1876720"
  },
  {
    "text": "you want to notify people the moment the 480p videos is ready so it's up to you you want for",
    "start": "1876720",
    "end": "1883039"
  },
  {
    "text": "example to notify people when the highest quality videos available that's gonna take long",
    "start": "1883039",
    "end": "1888880"
  },
  {
    "text": "time to notify people obviously but nevertheless right you got it all right and then you can easily fit",
    "start": "1888880",
    "end": "1894960"
  },
  {
    "text": "the copyright service right we talked about them just slam it there and subscribe to the",
    "start": "1894960",
    "end": "1900559"
  },
  {
    "text": "i don't know the compressed video and i will just immediately find any content id and then",
    "start": "1900559",
    "end": "1906480"
  },
  {
    "text": "there right so it's a beautiful design is it perfect though i don't know let's find out pros what's",
    "start": "1906480",
    "end": "1914240"
  },
  {
    "start": "1909000",
    "end": "2644000"
  },
  {
    "text": "good about this let's find out obviously scales with multiple subscribers",
    "start": "1914240",
    "end": "1919679"
  },
  {
    "text": "right multiple receivers multiple consumers is great for multiple receivers because they can you can add as many",
    "start": "1919679",
    "end": "1926240"
  },
  {
    "text": "receivers and unique receivers here we're talking about unique different distinct",
    "start": "1926240",
    "end": "1932480"
  },
  {
    "text": "receivers right they are different from each other they have different needs they have different",
    "start": "1932480",
    "end": "1939360"
  },
  {
    "text": "wants and they want to be scaled you can scale them beautifully right unlike very cost",
    "start": "1939360",
    "end": "1945760"
  },
  {
    "text": "response where they have to be aware of each other and that's bad all right so this thing is",
    "start": "1945760",
    "end": "1950960"
  },
  {
    "text": "great for micro services all right it's amazing right because the moment you have",
    "start": "1950960",
    "end": "1957600"
  },
  {
    "text": "multiple services in order to avoid the spaghetti uh",
    "start": "1957600",
    "end": "1963519"
  },
  {
    "text": "mesh topology of everything is connected to everything you can you can just have this one place",
    "start": "1963519",
    "end": "1970320"
  },
  {
    "text": "and everything is connected to this place now you have a center almost like a center single point of",
    "start": "1970320",
    "end": "1975440"
  },
  {
    "text": "failure but that can be dealt with differently right we're gonna talk about the pros and cons",
    "start": "1975440",
    "end": "1983360"
  },
  {
    "text": "loose coupling you just decoupled things now the services are not aware of each other",
    "start": "1983360",
    "end": "1988640"
  },
  {
    "text": "that's good we like that stuff right the moment the the the the less things are coupled to each other the",
    "start": "1988640",
    "end": "1994960"
  },
  {
    "text": "more they can essentially scale and be added and the the system can be",
    "start": "1994960",
    "end": "2000399"
  },
  {
    "text": "modified easily right because you cannot you can smartly change one thing",
    "start": "2000399",
    "end": "2008640"
  },
  {
    "text": "without breaking the entire system because low coupling are bad because the moment you",
    "start": "2008640",
    "end": "2014240"
  },
  {
    "text": "have a service that depends on 700 services any small",
    "start": "2014240",
    "end": "2019600"
  },
  {
    "text": "change can break any of these 700 clients right so if you have if you're sure that your",
    "start": "2019600",
    "end": "2024880"
  },
  {
    "text": "only client is the pub sub system you're golden right works while clients",
    "start": "2024880",
    "end": "2030640"
  },
  {
    "text": "not running well yeah but right so if if we go back to the example",
    "start": "2030640",
    "end": "2039760"
  },
  {
    "text": "there and we select the notification service if if any of these services are offline",
    "start": "2039760",
    "end": "2045360"
  },
  {
    "text": "we don't really care the moment they come back online they will subscribe and they will",
    "start": "2045360",
    "end": "2051200"
  },
  {
    "text": "say hey we have a new message we have a new topic let's consume it",
    "start": "2051200",
    "end": "2056398"
  },
  {
    "text": "right so that's okay because the messages are already stored in the queue and the",
    "start": "2056399",
    "end": "2061520"
  },
  {
    "text": "topic in the channel right so that's how but that also means there's problems let's talk",
    "start": "2061520",
    "end": "2069280"
  },
  {
    "text": "about the problems cones all right there are obviously message delivery",
    "start": "2069280",
    "end": "2077200"
  },
  {
    "text": "issues all right so the message delivery issues about when when we have a subscriber",
    "start": "2077200",
    "end": "2083200"
  },
  {
    "text": "and we have a message queue or we have a publisher and we have this message queue and you're publishing something",
    "start": "2083200",
    "end": "2088320"
  },
  {
    "text": "how do you know that the the queue the message has been published that's",
    "start": "2088320",
    "end": "2094320"
  },
  {
    "text": "first thing okay well you can say that well just saying message queue will will will send me a notification i",
    "start": "2094320",
    "end": "2100560"
  },
  {
    "text": "cannot even hey you're done good stuff we're good all right",
    "start": "2100560",
    "end": "2106240"
  },
  {
    "text": "and that you don't care about anything else for the publisher that's good okay if you don't receive that",
    "start": "2106240",
    "end": "2111359"
  },
  {
    "text": "acknowledgement you might try again and that's a problem okay like how do you know that if if i",
    "start": "2111359",
    "end": "2117440"
  },
  {
    "text": "actually if i published again how do i know i didn't publish that same content twice right we have ways of solving this with",
    "start": "2117440",
    "end": "2124640"
  },
  {
    "text": "item potency but still can it still complicate complication going on",
    "start": "2124640",
    "end": "2130000"
  },
  {
    "text": "there right and who's taking care of this complication should it be me as a publisher or should it be the",
    "start": "2130000",
    "end": "2135440"
  },
  {
    "text": "message queue i don't know right the other problem is the subscriber now the subscriber",
    "start": "2135440",
    "end": "2141760"
  },
  {
    "text": "that's that's that's the challenging part how do you know as a subscriber that",
    "start": "2141760",
    "end": "2148000"
  },
  {
    "text": "that's a this subscriber this consumer this compressed service actually got the",
    "start": "2148000",
    "end": "2154000"
  },
  {
    "text": "content first how do you know that it actually processed the content because it has to tell the service hey",
    "start": "2154000",
    "end": "2159760"
  },
  {
    "text": "by the way i read that i read this message just the fact that this acknowledgement",
    "start": "2159760",
    "end": "2165119"
  },
  {
    "text": "that hey i read the message people are taking phds in this because it's so hard",
    "start": "2165119",
    "end": "2173359"
  },
  {
    "text": "right it is so hard to know that a message has been consumed or not how do you know right you can send an",
    "start": "2173359",
    "end": "2180560"
  },
  {
    "text": "economy but what if the economy didn't you didn't get it all right so we talked about the message delivery issues obviously",
    "start": "2180560",
    "end": "2186160"
  },
  {
    "text": "and now let's talk about the complexity it is very complex system because of the",
    "start": "2186160",
    "end": "2193440"
  },
  {
    "text": "message delivery issue we try to find ways around it okay and to find ways around it we add",
    "start": "2193440",
    "end": "2200320"
  },
  {
    "text": "complexity okay so it's first very simple here let's talk about the posh",
    "start": "2200320",
    "end": "2205440"
  },
  {
    "text": "and the pull and the long pulling model how do you deliver a message",
    "start": "2205440",
    "end": "2213359"
  },
  {
    "text": "from the topic right how do the broker deliver a message from the topic to the",
    "start": "2213359",
    "end": "2219520"
  },
  {
    "text": "subscriber or to the consumer okay how does that happen right you can you can",
    "start": "2219520",
    "end": "2224880"
  },
  {
    "text": "imagine like rabbitmq already and we made a rabbit mq video here i'm gonna reference it here so you",
    "start": "2224880",
    "end": "2231119"
  },
  {
    "text": "can you guys check it out but it's very interesting and what you want to do essentially is",
    "start": "2231119",
    "end": "2238079"
  },
  {
    "text": "first thing is you wanted to establish a two-way communication like a tcp channel right and then rapid mq has its own protocol i",
    "start": "2238079",
    "end": "2246000"
  },
  {
    "text": "think it's called it's not really its own but it's a standard so advanced message queue protocol and they're using that it's a two-way",
    "start": "2246000",
    "end": "2251839"
  },
  {
    "text": "communication it's a two-way binary protocol and they talk about it redis have its own rest protocol",
    "start": "2251839",
    "end": "2257839"
  },
  {
    "text": "i don't know what's stands for what but i forgot so they again it's a byway",
    "start": "2257839",
    "end": "2264800"
  },
  {
    "text": "two-way communication where it's like you communicate on both directions and then now you can",
    "start": "2264800",
    "end": "2270640"
  },
  {
    "text": "start sending push messages as a result because it's a two-way communication right and push messages",
    "start": "2270640",
    "end": "2277440"
  },
  {
    "text": "push notification or push models very complicated you might it might sound nice hey the",
    "start": "2277440",
    "end": "2283520"
  },
  {
    "text": "moment i get a topic immediately pushed to the subscriber that sounds beautiful because it's almost real time",
    "start": "2283520",
    "end": "2290960"
  },
  {
    "text": "but what happened if the client is offline whatever if the consumer's offline you",
    "start": "2290960",
    "end": "2296640"
  },
  {
    "text": "okay you can say they let's hold the message until they are online and then when they are online push it",
    "start": "2296640",
    "end": "2301839"
  },
  {
    "text": "okay that seems reasonable all right but how do you know that they are offline and then that that that status right you're",
    "start": "2301839",
    "end": "2309680"
  },
  {
    "text": "almost keeping track of the subscriber in your message queue and that might be okay",
    "start": "2309680",
    "end": "2314720"
  },
  {
    "text": "if you think about it but that adds additional complexity another complexity is the back pressure",
    "start": "2314720",
    "end": "2321119"
  },
  {
    "text": "where you the publisher is so fast in producing content let's say a",
    "start": "2321119",
    "end": "2328320"
  },
  {
    "text": "publisher is garyvee it's just like grinding content daily right not daily every second just",
    "start": "2328320",
    "end": "2335040"
  },
  {
    "text": "publishing stuff all the time and then the poor consumer",
    "start": "2335040",
    "end": "2340079"
  },
  {
    "text": "can barely consume these messages they're right this is just the flood of push",
    "start": "2340079",
    "end": "2346480"
  },
  {
    "text": "messages the little tiny device for example that consumes that",
    "start": "2346480",
    "end": "2352839"
  },
  {
    "text": "stuff cannot handle that load it just cannot it cannot handle",
    "start": "2352839",
    "end": "2357920"
  },
  {
    "text": "something that shoved down their throat obviously it's gonna wait right and this what do you do with these",
    "start": "2357920",
    "end": "2364960"
  },
  {
    "text": "awaited messages do you just put them back and do you do you time out do you put them do you",
    "start": "2364960",
    "end": "2374320"
  },
  {
    "text": "and do you now keep track oh this client is is slow so i'm gonna slow down this kind of fast",
    "start": "2374320",
    "end": "2379760"
  },
  {
    "text": "i'm gonna speed up that's a very complex problem to solve by itself right that's itself that's a",
    "start": "2379760",
    "end": "2386800"
  },
  {
    "text": "problem right and then another problem is okay so you might say that's the rabbitmq and redis uses that",
    "start": "2386800",
    "end": "2393760"
  },
  {
    "text": "okay that has its own limitation so the other approach is to do like the polling method right where",
    "start": "2393760",
    "end": "2399119"
  },
  {
    "text": "do i have a message do i have a message do i have a message as a client you say do i have a message do i have a message do i have a message do i have a message",
    "start": "2399119",
    "end": "2404960"
  },
  {
    "text": "do i have a message do i have a message well if you don't then you just",
    "start": "2404960",
    "end": "2410160"
  },
  {
    "text": "kind of saturated the network with empty requests which kind of business right right that's a problem okay that's it",
    "start": "2410160",
    "end": "2417839"
  },
  {
    "text": "that's that's a lot of processing wasted cycles for requesting empty responses",
    "start": "2417839",
    "end": "2425200"
  },
  {
    "text": "right there's nothing for you so why you keep requesting so the so the solution the part solution is use",
    "start": "2425200",
    "end": "2431839"
  },
  {
    "text": "long polling with which kafka uses right which is like hey you make a request",
    "start": "2431839",
    "end": "2437119"
  },
  {
    "text": "and you block yourself right we're going to block you essentially as if you made a request and we're",
    "start": "2437119",
    "end": "2444640"
  },
  {
    "text": "taking a long time processing it but there is there is really nothing to process nobody is busy",
    "start": "2444640",
    "end": "2450480"
  },
  {
    "text": "and because it's a beautiful of asynchronous in this age it's fine you can wait but you can do",
    "start": "2450480",
    "end": "2458560"
  },
  {
    "text": "other stuff in the meantime you the only thing that's spent is memory here",
    "start": "2458560",
    "end": "2463599"
  },
  {
    "text": "that's the only thing i spent maybe a little bit of an event main loop",
    "start": "2463599",
    "end": "2468720"
  },
  {
    "text": "just checking if there's something came back or not but that you're doing that anyway right",
    "start": "2468720",
    "end": "2473760"
  },
  {
    "text": "so it's it's not much so the long pulling that's what kafka uses",
    "start": "2473760",
    "end": "2479040"
  },
  {
    "text": "right and then that has it's also limitation obviously because like you might not get best",
    "start": "2479040",
    "end": "2486400"
  },
  {
    "text": "real time but you solve the problem of uh essentially the the back pressure of",
    "start": "2486400",
    "end": "2493440"
  },
  {
    "text": "shoving a lot of messages for clients who cannot be ready to consume messages right",
    "start": "2493440",
    "end": "2499040"
  },
  {
    "text": "obviously it's a very complex system and network saturation in case of posh",
    "start": "2499040",
    "end": "2504400"
  },
  {
    "text": "you're pushing a lot of messages you're shoving the network with a huge amount of notifications and content",
    "start": "2504400",
    "end": "2511680"
  },
  {
    "text": "right that that's a lot of content going at the network sometimes unnecessarily because the",
    "start": "2511680",
    "end": "2517599"
  },
  {
    "text": "client doesn't really necessarily can process these messages which which might lead to failure which may",
    "start": "2517599",
    "end": "2523680"
  },
  {
    "text": "which may lead to you retrying the broker can have to retry these requests which is",
    "start": "2523680",
    "end": "2531040"
  },
  {
    "text": "also bad right and the network restoration on the other hand is like the other way under utilization which i didn't write here",
    "start": "2531040",
    "end": "2537440"
  },
  {
    "text": "it's just okay i make a request but i don't see anything i make a request i don't see anything so",
    "start": "2537440",
    "end": "2542960"
  },
  {
    "text": "summary what did we discuss in this video we talked about where the request",
    "start": "2542960",
    "end": "2549520"
  },
  {
    "text": "response model breaks right it's a beautiful design but it has",
    "start": "2549520",
    "end": "2554800"
  },
  {
    "text": "its limitation right we talked about the pros and cons of this christmas bones we talked about",
    "start": "2554800",
    "end": "2559839"
  },
  {
    "text": "the publish subscribe pattern or architecture i don't know what you call it right",
    "start": "2559839",
    "end": "2564960"
  },
  {
    "text": "publish subscribe architecture or pattern whatever rocks your boat and we talked",
    "start": "2564960",
    "end": "2570400"
  },
  {
    "text": "about the pros and cons of that thing okay the example of this is kafka rabbit",
    "start": "2570400",
    "end": "2575680"
  },
  {
    "text": "mq and so we made a video about redis we made a video about rabbit mcu i am making",
    "start": "2575680",
    "end": "2583359"
  },
  {
    "text": "a video about kafka still in the process i'm going to let you guys know if you",
    "start": "2583359",
    "end": "2590400"
  },
  {
    "text": "want to know if you want to really see the video about the kafka write down in the comment section right now",
    "start": "2590400",
    "end": "2596800"
  },
  {
    "text": "write kafka so we can actually i see if there's a lot of interest in",
    "start": "2596800",
    "end": "2602240"
  },
  {
    "text": "that you guys give me a lot of great suggestion i love those videos suggestion i'm making them i'm enjoying",
    "start": "2602240",
    "end": "2609040"
  },
  {
    "text": "making all these content it's a long form content i know it's a lecture this is not a three minute video they",
    "start": "2609040",
    "end": "2615680"
  },
  {
    "text": "will watch right and then you move on it's if you this is videos that you watch for your series to learn obviously",
    "start": "2615680",
    "end": "2622720"
  },
  {
    "text": "and no like no 10 minute video can give you any value really or five minutes video",
    "start": "2622720",
    "end": "2629520"
  },
  {
    "text": "you're gonna watch and learn about a lot of stuff okay that's the kind of content we make in this channel so if you're",
    "start": "2629520",
    "end": "2635200"
  },
  {
    "text": "interested consider subscribing like this video like it and share it with your friend i'm gonna see you on the next one",
    "start": "2635200",
    "end": "2641680"
  },
  {
    "text": "you guys stay awesome",
    "start": "2641680",
    "end": "2644960"
  }
]
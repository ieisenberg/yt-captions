[
  {
    "start": "0",
    "end": "60000"
  },
  {
    "text": "we now know the reason of the outage that happened on november 25th for the us east one aws",
    "start": "80",
    "end": "7759"
  },
  {
    "text": "amazon kinesis event amazon responded with a nice summary it's a very long summary",
    "start": "7759",
    "end": "14320"
  },
  {
    "text": "discussing detailing what happened exactly what was the codes and there are lessons",
    "start": "14320",
    "end": "20640"
  },
  {
    "text": "for us back in engineer that we can extract from this summary how about we jump into it so",
    "start": "20640",
    "end": "27119"
  },
  {
    "text": "what i'm gonna do in this article is that i'm gonna do a tl dr for those who are just interested to know what happened exactly",
    "start": "27119",
    "end": "33200"
  },
  {
    "text": "so i i drew a little bit of a nice nifty diagram because this is a very dry article to read um",
    "start": "33200",
    "end": "40320"
  },
  {
    "text": "so i'm gonna do a field and then i'm gonna dive into the deep analysis so you see you're going to see the youtube",
    "start": "40320",
    "end": "45920"
  },
  {
    "text": "chapters where you can jump into the interesting part of the video if you want to stay for the detailed analysis of the of the",
    "start": "45920",
    "end": "52160"
  },
  {
    "text": "article that i'm going to explain and go through and kind of ask some unanswered questions",
    "start": "52160",
    "end": "59760"
  },
  {
    "text": "that i don't have yet and uh stay alone so let's just jump into it so guys tldr",
    "start": "59760",
    "end": "65680"
  },
  {
    "start": "60000",
    "end": "450000"
  },
  {
    "text": "let's go through the amazon kinesis architecture as described",
    "start": "65680",
    "end": "70880"
  },
  {
    "text": "by this article amazon kinesis have a bunch of back end servers",
    "start": "70880",
    "end": "77280"
  },
  {
    "text": "and these are called backing clusters and each cluster is basically the core processing unit of those streams right",
    "start": "77280",
    "end": "84400"
  },
  {
    "text": "those click-throughs these these videos these voice any stream that you created in kinesis",
    "start": "84400",
    "end": "91680"
  },
  {
    "text": "lives on the back end essentially and to scale naturally we need to do sharding and",
    "start": "91680",
    "end": "97920"
  },
  {
    "text": "most companies do right so we have essentially many shorts in a single back end",
    "start": "97920",
    "end": "103040"
  },
  {
    "text": "for a single stream data stream right so that's the idea here so now all of a",
    "start": "103040",
    "end": "108799"
  },
  {
    "text": "sudden we have many shards over many clusters so we need some sort of a mapping right so",
    "start": "108799",
    "end": "114159"
  },
  {
    "text": "okay back-end one which is think of this as an ip address has two short chart one and short two",
    "start": "114159",
    "end": "119680"
  },
  {
    "text": "and back in two has charts three on chart four so now the consuming part of this which is",
    "start": "119680",
    "end": "124960"
  },
  {
    "text": "their front end fleet so that was the back end fleet that's where the front and fleet that's was by the way",
    "start": "124960",
    "end": "130720"
  },
  {
    "text": "what broke things down the front and fleet which accepts uh the traffic from",
    "start": "130720",
    "end": "136319"
  },
  {
    "text": "outside whether it's customers or just another aws services so these front-end servers communicate",
    "start": "136319",
    "end": "142480"
  },
  {
    "text": "with the back-end in order to write or read from a different chart based on what data stream you're reading",
    "start": "142480",
    "end": "148400"
  },
  {
    "text": "so they have this map this is okay back-end one has shard one back-end one has chart two",
    "start": "148400",
    "end": "154959"
  },
  {
    "text": "right and same thing this machine has this front-end machine has back in two has shard three and back in two has also shadow four so",
    "start": "154959",
    "end": "162879"
  },
  {
    "text": "those guys in this case i have only two those communicate with with each other",
    "start": "162879",
    "end": "169840"
  },
  {
    "text": "very interesting and and very very interesting choice of design",
    "start": "169840",
    "end": "175280"
  },
  {
    "text": "right so all by all front-end machines or servers actually communicate with you with each other to in order",
    "start": "175280",
    "end": "182640"
  },
  {
    "text": "to say okay are you healthy are you alive and here by the way we're gonna exchange",
    "start": "182640",
    "end": "188800"
  },
  {
    "text": "some of our this sharding information they call this the shard map so the shard map is the most",
    "start": "188800",
    "end": "195920"
  },
  {
    "text": "important piece that we need to understand here and those machines exchange those shard map as",
    "start": "195920",
    "end": "202959"
  },
  {
    "text": "they change as as the shard map changes like let's say you as a customer added a new chart or",
    "start": "202959",
    "end": "208720"
  },
  {
    "text": "remove the new shard these front end need to be updated right so they communicate with each other and exchange",
    "start": "208720",
    "end": "215120"
  },
  {
    "text": "these short map information so now they are in sync essentially right so",
    "start": "215120",
    "end": "222080"
  },
  {
    "text": "what happened when i add a new machine right let's add a new front-end machine",
    "start": "222080",
    "end": "227360"
  },
  {
    "text": "just increase the capacity all of a sudden now this new machine needs to communicate with this this",
    "start": "227360",
    "end": "232959"
  },
  {
    "text": "needs to come out of this and this needs coming in so so you effectively it's very similar to a peer-to-peer",
    "start": "232959",
    "end": "238480"
  },
  {
    "text": "architecture right so this communication now this each machine has two so essentially n minus one right so",
    "start": "238480",
    "end": "246159"
  },
  {
    "text": "if you have in front and machines you have n minus one connections and each connection it's it's the apache",
    "start": "246159",
    "end": "253599"
  },
  {
    "text": "model where each connection is a thread in the operating system and this is very important it's a very",
    "start": "253599",
    "end": "259519"
  },
  {
    "text": "important point so each connection is a thread so now we have two threads here two connections",
    "start": "259519",
    "end": "264639"
  },
  {
    "text": "two threads two connections two threads so just so we can parallelize the information as they come right",
    "start": "264639",
    "end": "269919"
  },
  {
    "text": "and so as a result we can sync all of them together and that's not so bad if we have three",
    "start": "269919",
    "end": "275280"
  },
  {
    "text": "machines but amazon have they didn't specify the number but they say",
    "start": "275280",
    "end": "280560"
  },
  {
    "text": "thousands my guess it's my guess it's it's 10 000 right because that's",
    "start": "280560",
    "end": "287919"
  },
  {
    "text": "the default thread size that after the watch the operating system just dies",
    "start": "287919",
    "end": "293360"
  },
  {
    "text": "right so here's what happened right what happened is amazon at 5 a.m in the",
    "start": "293360",
    "end": "299600"
  },
  {
    "text": "morning they added a new capacity just just regular thing they do they just",
    "start": "299600",
    "end": "305199"
  },
  {
    "text": "they keep doing this they increase the front-end servers the back-end is happy they just want to increase the",
    "start": "305199",
    "end": "310960"
  },
  {
    "text": "front end so they can accept more requests and essentially decrease their latency right so now",
    "start": "310960",
    "end": "318720"
  },
  {
    "text": "when they added that extra machine right they have thousands of machines",
    "start": "318720",
    "end": "325120"
  },
  {
    "text": "all of a sudden they started getting all sorts of errors failures everywhere and long story short so here's what",
    "start": "325120",
    "end": "332720"
  },
  {
    "text": "happened the addition of the new capacity the new front and servers increased by a threshold that",
    "start": "332720",
    "end": "340400"
  },
  {
    "text": "exceeded the number of maximum threads that any operating system can",
    "start": "340400",
    "end": "346240"
  },
  {
    "text": "handle that that configuration for the operating system whatever the operating system here they didn't specify the number my guess",
    "start": "346240",
    "end": "353280"
  },
  {
    "text": "is it's 10 000. so if you go beyond 10 000 all of a",
    "start": "353280",
    "end": "358720"
  },
  {
    "text": "sudden you cannot spend more threads guess what if you don't spend more threads you cannot create new connections",
    "start": "358720",
    "end": "364400"
  },
  {
    "text": "right to that new machine that just just joined so god knows what will",
    "start": "364400",
    "end": "370880"
  },
  {
    "text": "happen maybe it will create a new connection and we'll destroy another one from another machine so all of a sudden",
    "start": "370880",
    "end": "376720"
  },
  {
    "text": "you have a corrupted shard map right because what's going on here it's",
    "start": "376720",
    "end": "382960"
  },
  {
    "text": "like what is the source of truth we don't have a consistent view anymore these connections are severed so we",
    "start": "382960",
    "end": "390000"
  },
  {
    "text": "there there are information that we need to propagate but we can't so we get errors and we get",
    "start": "390000",
    "end": "395440"
  },
  {
    "text": "throttles as a result and we get also for earth and that wasn't easy to determine it took them a",
    "start": "395440",
    "end": "400960"
  },
  {
    "text": "long time to to get to that uh reason so what they did is they actually said okay",
    "start": "400960",
    "end": "407199"
  },
  {
    "text": "let's remove the the new capacitor that we added and they restarted each machine in order",
    "start": "407199",
    "end": "414319"
  },
  {
    "text": "for all of these to re-communicate slowly and they stopped the outside traffic",
    "start": "414319",
    "end": "420240"
  },
  {
    "text": "so that essentially they don't get overwhelmed because these machines accept requests from the",
    "start": "420240",
    "end": "426720"
  },
  {
    "text": "outside from other aws services and customers and they also accept requests from",
    "start": "426720",
    "end": "433759"
  },
  {
    "text": "they their neighbors right whatever that means right my guess is that everyone is",
    "start": "433759",
    "end": "439039"
  },
  {
    "text": "connected to everyone and we have a specific passage paragraph saying that in in in the summary it's like",
    "start": "439039",
    "end": "446639"
  },
  {
    "text": "every machine is connected to every other machine so now i have many questions and we're going to dive deep into the details on like what",
    "start": "446639",
    "end": "453440"
  },
  {
    "start": "450000",
    "end": "1500000"
  },
  {
    "text": "exactly happened and i'll probably jump into it let's go back so that was the summary so let's go",
    "start": "453440",
    "end": "459360"
  },
  {
    "text": "let's go and start reading this article and then kind of break it apart amazon kinesis enables",
    "start": "459360",
    "end": "466560"
  },
  {
    "text": "real-time processing of streaming data in addition to its direct use by customer kinesis is used by other aws services",
    "start": "466560",
    "end": "474080"
  },
  {
    "text": "okay as we described the services also so impact during the event right any outside words which",
    "start": "474080",
    "end": "481440"
  },
  {
    "text": "is aws and customers that's to me that's a big mistake you're sharing",
    "start": "481440",
    "end": "488160"
  },
  {
    "text": "you're sharing resources between your internal services and external",
    "start": "488160",
    "end": "493759"
  },
  {
    "text": "customers these should be separated and that's one of the solutions they did in the end of the article they say okay",
    "start": "493759",
    "end": "499599"
  },
  {
    "text": "that was a mistake we should not do that let's separate those two",
    "start": "499599",
    "end": "504800"
  },
  {
    "text": "i mean if you have confidence on the architecture which they did initially but it did not scale well",
    "start": "505039",
    "end": "512479"
  },
  {
    "text": "the trigger though not the root cause for the event was a relatively small addition of capacity that began",
    "start": "512479",
    "end": "519200"
  },
  {
    "text": "to be added to the service at 2 4 a.m also i was wrong so it was in the morning they added in",
    "start": "519200",
    "end": "525040"
  },
  {
    "text": "the morning and they saw they finished and 3 45 a.m so it took an hour to add this so",
    "start": "525040",
    "end": "532160"
  },
  {
    "text": "here's here's the details now kinesis has a large number of back and cell clusters that process streams",
    "start": "532160",
    "end": "538240"
  },
  {
    "text": "that's the backend architecture that we explain in the diagram these are the workhorses in kinesis provide",
    "start": "538240",
    "end": "543760"
  },
  {
    "text": "distribution access and scalability for stream processing streams are spread across the back end",
    "start": "543760",
    "end": "549440"
  },
  {
    "text": "through a shorting mechanism owned by a front-end fleet of service that's the friend that we explain",
    "start": "549440",
    "end": "555200"
  },
  {
    "text": "a back-end cluster owns many shards and provide consistent scaling unit",
    "start": "555200",
    "end": "563440"
  },
  {
    "text": "and fault isolation yeah of course you need they they probably they are they are replicated they're",
    "start": "563440",
    "end": "568880"
  },
  {
    "text": "everywhere they're not just uh they're just not unique right you have to duplicate it",
    "start": "568880",
    "end": "574480"
  },
  {
    "text": "because in case of a fall let's say what if a backend server or cluster",
    "start": "574480",
    "end": "579519"
  },
  {
    "text": "fall fail right you need to kind of do a load balancing on that the front end job is small but important",
    "start": "579519",
    "end": "586480"
  },
  {
    "text": "hand is authentication that's something i didn't explain so it authenticates in throttles which they",
    "start": "586480",
    "end": "591760"
  },
  {
    "text": "have actually implemented during the outage and they throttle everyone and request routing to the correct stream",
    "start": "591760",
    "end": "597120"
  },
  {
    "text": "shard that's the most important one the capacity addition was being made to the front end fleet",
    "start": "597120",
    "end": "602880"
  },
  {
    "text": "each server in the front and fleet maintains a cache of information including membership details",
    "start": "602880",
    "end": "608880"
  },
  {
    "text": "shard ownership for the backend cluster called the shard map that's that's the word we talked",
    "start": "608880",
    "end": "614480"
  },
  {
    "text": "about this information is obtained through calls to a microservice vending the membership information so",
    "start": "614480",
    "end": "621040"
  },
  {
    "text": "the membership information i don't know what's exactly the membership here uh are we talking about the actual",
    "start": "621040",
    "end": "626959"
  },
  {
    "text": "amazon memberships like hey are you authenticated or not i guess the authentication part of it",
    "start": "626959",
    "end": "633120"
  },
  {
    "text": "retrieval of configuration information from dynamodb and contune continuous processing",
    "start": "633120",
    "end": "639120"
  },
  {
    "text": "messages from other kinesis front-end servers that's that's",
    "start": "639120",
    "end": "644399"
  },
  {
    "text": "the peer-to-peer communication that we whether we should for later communication",
    "start": "644399",
    "end": "649920"
  },
  {
    "text": "each front-end server creates operating system threads",
    "start": "649920",
    "end": "656480"
  },
  {
    "text": "and there is a threads with an s for each of the other that's what made me",
    "start": "656480",
    "end": "663440"
  },
  {
    "text": "realize that it's a peer-to-peer almost like everyone is committed to another one",
    "start": "663440",
    "end": "668480"
  },
  {
    "text": "that's just very bizarre architecture in my opinion i still don't",
    "start": "668480",
    "end": "675040"
  },
  {
    "text": "know what kind of information being exchanged between all these machines and do can",
    "start": "675040",
    "end": "681680"
  },
  {
    "text": "you just have a centralized system to store the cash that's the first thing that i was",
    "start": "681680",
    "end": "687120"
  },
  {
    "text": "like whoa why are you guys communicating between each other it's just very inefficient we",
    "start": "687120",
    "end": "693120"
  },
  {
    "text": "tell people hey peer-to-peer is great for a few people for a few machines for a few participants but the moment you exchange",
    "start": "693120",
    "end": "700800"
  },
  {
    "text": "and and and explode to multi multi hundreds",
    "start": "700800",
    "end": "706000"
  },
  {
    "text": "it just doesn't scale right we know this the mesh architecture right by any addition of capacity the servers that",
    "start": "706000",
    "end": "711760"
  },
  {
    "text": "are already operating members of the fleet will learn of new servers joining and establish the",
    "start": "711760",
    "end": "718079"
  },
  {
    "text": "appropriate threads it takes up to an hour for an existing fleet",
    "start": "718079",
    "end": "723279"
  },
  {
    "text": "member fleet member to learn of a new partisan that exactly that's the time it took them right",
    "start": "723279",
    "end": "731360"
  },
  {
    "text": "they added their machines at 2 4 a.m they finished 344 exactly an hour right",
    "start": "731360",
    "end": "738480"
  },
  {
    "text": "so it tells you that is extremely inefficient why would an adding of a single machine takes an",
    "start": "738480",
    "end": "744880"
  },
  {
    "text": "hour to update can we make it better again guys we don't know a lot about the background of the",
    "start": "744880",
    "end": "751920"
  },
  {
    "text": "architecture before we judge right there must be a reason for everything",
    "start": "751920",
    "end": "757200"
  },
  {
    "text": "i'd i'd like to always uh before i search in any asserting anything i like to know the reasons and to us we don't know",
    "start": "757200",
    "end": "763920"
  },
  {
    "text": "so there must be a good reason for everything those companies do right we just don't know it yet in this paragraph they",
    "start": "763920",
    "end": "769600"
  },
  {
    "text": "explained that exactly when they started to see the error at 5 am so it took around one hour one hour and",
    "start": "769600",
    "end": "777120"
  },
  {
    "text": "a half to start seeing the first alarms again the teams started uh reading the",
    "start": "777120",
    "end": "782320"
  },
  {
    "text": "logs and see what exactly what happened or what what did we do we added a capacity",
    "start": "782320",
    "end": "787680"
  },
  {
    "text": "what's wrong we add capacity all the time why now so they they immediately started",
    "start": "787680",
    "end": "793600"
  },
  {
    "text": "removing the capacity even removing the capacity is slow they the diagnosis work was slowly by very",
    "start": "793600",
    "end": "800480"
  },
  {
    "text": "was slowed by a variety of errors observed because it's all the wild wall risk now",
    "start": "800480",
    "end": "806480"
  },
  {
    "text": "right because yeah if i can't communicate with the other server and you get cascading errors",
    "start": "806480",
    "end": "814639"
  },
  {
    "text": "and you get some weird errors that oh i don't know i i can't access a server maybe you just try to",
    "start": "814639",
    "end": "822000"
  },
  {
    "text": "access a server that a back end that has been removed but you just didn't get the updated",
    "start": "822000",
    "end": "830639"
  },
  {
    "text": "short map to know that it has been removed or a new short that has been removed and you're connecting to a show that doesn't",
    "start": "830639",
    "end": "836320"
  },
  {
    "text": "exist so you start getting these errors but you have to put two and two together and that's absolutely difficult so i can",
    "start": "836320",
    "end": "842079"
  },
  {
    "text": "totally relate to that because in my career i've seen so many errors and just the",
    "start": "842079",
    "end": "847519"
  },
  {
    "text": "other day i've seen an error that took us a lot of i don't know what it took us like three",
    "start": "847519",
    "end": "854320"
  },
  {
    "text": "hours to find out the root cause of and has the the the error has nothing to do with the root",
    "start": "854320",
    "end": "862000"
  },
  {
    "text": "when you first is like what what why and i'm sure a lot of you guys",
    "start": "862000",
    "end": "867279"
  },
  {
    "text": "if you if a lot of you guys can relate to that can you in the comment section just write what is the most interesting",
    "start": "867279",
    "end": "873839"
  },
  {
    "text": "diagnostic and troubleshooting experience if you can share that is right of course so here's they say like",
    "start": "873839",
    "end": "880240"
  },
  {
    "text": "we just want to go back we just want to go back we just want to go back so they're starting to go back and",
    "start": "880240",
    "end": "885680"
  },
  {
    "text": "remove the extra capacity they added so they can just restart the system and go back but",
    "start": "885680",
    "end": "890720"
  },
  {
    "text": "again if you do that again remember every machine you introduce takes an hour according to them right so",
    "start": "890720",
    "end": "898240"
  },
  {
    "text": "if you removed everything you have to remove everything because guess what all the front ends now have corrupted shard maps",
    "start": "898240",
    "end": "905120"
  },
  {
    "text": "there's no solution you have to destroy all the restart every single front end and every",
    "start": "905120",
    "end": "911680"
  },
  {
    "text": "front that you introduce and you add another one takes an hour hour hour hour hour so that that's why",
    "start": "911680",
    "end": "917920"
  },
  {
    "text": "it took a long time to actually retrieve that so they need to work on a better uh their cold start problem",
    "start": "917920",
    "end": "925440"
  },
  {
    "text": "apparently because they have a slow cold start here there you go there is where they actually find out at",
    "start": "925440",
    "end": "931920"
  },
  {
    "text": "9 39 we were able to confirm the root cause and it turns out this wasn't",
    "start": "931920",
    "end": "937519"
  },
  {
    "text": "brilliant by memory pressure rather than a new capacity had caused all the servers in their fleet",
    "start": "937519",
    "end": "943440"
  },
  {
    "text": "to exceed the number of maximum number of threads allowed by an operating system configuration",
    "start": "943440",
    "end": "948959"
  },
  {
    "text": "they didn't say what that number is or was as the limit was being exceeded cash",
    "start": "948959",
    "end": "955199"
  },
  {
    "text": "construction was failing to complete and front-end servers were ending up",
    "start": "955199",
    "end": "960399"
  },
  {
    "text": "with the useless shard maps and left them unable to route request to back-end cluster that's",
    "start": "960399",
    "end": "966880"
  },
  {
    "text": "exactly what we talked about right or they they try to connect it with with",
    "start": "966880",
    "end": "972399"
  },
  {
    "text": "back and cluster that just doesn't exist anymore or don't exist we didn't want to increase the operating system limit",
    "start": "972399",
    "end": "978959"
  },
  {
    "text": "without further testing because that's the first oh oh since we know let's just increase",
    "start": "978959",
    "end": "984240"
  },
  {
    "text": "it it's not tested you have not tested that so and that's just if you're",
    "start": "984240",
    "end": "989360"
  },
  {
    "text": "if you if you're adept in software engineering you know you don't try something you never tried before in",
    "start": "989360",
    "end": "995120"
  },
  {
    "text": "production that's just a recipe for disaster and we had just completed the removal of",
    "start": "995120",
    "end": "1001519"
  },
  {
    "text": "additional capacity that's regarding we determined that the thread count would no longer exceed the operating",
    "start": "1001519",
    "end": "1006560"
  },
  {
    "text": "system because they know that it worked before so let's just stay as let's just remove the capacity",
    "start": "1006560",
    "end": "1014079"
  },
  {
    "text": "that we added so we go back to the existing number of threads which didn't exceed right",
    "start": "1014079",
    "end": "1019759"
  },
  {
    "text": "we begin bringing back the front-end servers with the first group of servers taking kinesis traffic",
    "start": "1019759",
    "end": "1025678"
  },
  {
    "text": "at 10 am the the front end so they started rolling back starting",
    "start": "1025679",
    "end": "1033360"
  },
  {
    "text": "everything at 10 am in the morning that's the morning of 25 i guess the",
    "start": "1033360",
    "end": "1038480"
  },
  {
    "text": "front and fleet is composed of many thousands of servers",
    "start": "1038480",
    "end": "1044240"
  },
  {
    "text": "many thousands they didn't say how much and for the reasons described earlier we",
    "start": "1044240",
    "end": "1050240"
  },
  {
    "text": "could only add servers at a rate of a few hundred per hour so they can add few hundred per hour oh",
    "start": "1050240",
    "end": "1056160"
  },
  {
    "text": "all right it's not just one server but yeah okay that may kind of make better sense",
    "start": "1056160",
    "end": "1061360"
  },
  {
    "text": "we continued to slowly add traffic to the front end fleet with the kinesis error rate steadily",
    "start": "1061360",
    "end": "1066960"
  },
  {
    "text": "dropping from the noon onward kinesis fully returned to normal at 10 23 p.m",
    "start": "1066960",
    "end": "1075039"
  },
  {
    "text": "pacific standard time that was a long outage i'm glad i'm glad they actually wrote",
    "start": "1075039",
    "end": "1080559"
  },
  {
    "text": "this this is good this is really good it does leave me thirsty for more answers though and",
    "start": "1080559",
    "end": "1086240"
  },
  {
    "text": "i have more questions for kinesis we have a number of learning that we",
    "start": "1086240",
    "end": "1092080"
  },
  {
    "text": "will be implemented immediately so they they learned from this outage like any software engineer should",
    "start": "1092080",
    "end": "1097840"
  },
  {
    "text": "you have a disaster and you learn from it like how can i prevent this and this big company that's the first thing they",
    "start": "1097840",
    "end": "1104320"
  },
  {
    "text": "they tell each other so hey all right no big deal you guys did this",
    "start": "1104320",
    "end": "1110559"
  },
  {
    "text": "what could you do to to prevent this that's the cto will immediately say this what can we do to prevent this in the",
    "start": "1110559",
    "end": "1116320"
  },
  {
    "text": "future in the very short term we'll be moving to a larger cpu memory reducing the",
    "start": "1116320",
    "end": "1121760"
  },
  {
    "text": "total number of servers that's a hack in my opinion let me explain what happened and why i",
    "start": "1121760",
    "end": "1127760"
  },
  {
    "text": "think it's a hack because they have smaller servers with small cpus so they have",
    "start": "1127760",
    "end": "1133760"
  },
  {
    "text": "ma they need more more front ends in order uh in order to kind of accept that x",
    "start": "1133760",
    "end": "1140799"
  },
  {
    "text": "amount of load or requests right so they said okay and we can't really have a lot of front end",
    "start": "1140799",
    "end": "1147200"
  },
  {
    "text": "because our architecture doesn't scale as a peer-to-peer system right because these machines are communicated with",
    "start": "1147200",
    "end": "1153120"
  },
  {
    "text": "each other so let's minimize the number of of servers that we need yeah that might",
    "start": "1153120",
    "end": "1158320"
  },
  {
    "text": "work but you still have a lot of servers that communicate with each other and we",
    "start": "1158320",
    "end": "1164080"
  },
  {
    "text": "still don't know what are they communicating right are they communicating just the",
    "start": "1164080",
    "end": "1171039"
  },
  {
    "text": "cash map you they're gonna say they say hey we move the cache into a centralized cluster",
    "start": "1171039",
    "end": "1176559"
  },
  {
    "text": "and all the front end will just read from the cache that makes sense right yeah it's a",
    "start": "1176559",
    "end": "1182240"
  },
  {
    "text": "centralized server but still the centralized server cluster is still on many machines but",
    "start": "1182240",
    "end": "1188400"
  },
  {
    "text": "they're not going to be at more than 10 machines and that's enough right because and those",
    "start": "1188400",
    "end": "1194480"
  },
  {
    "text": "can share the the cash and they propagate the cash nicely but and then all the",
    "start": "1194480",
    "end": "1199600"
  },
  {
    "text": "fleets can just read from this centralized cache but regardless they say okay we'll just minimize the number of server make them",
    "start": "1199600",
    "end": "1206400"
  },
  {
    "text": "vertically scalable instead of horizontally hence the threads required by server across the fleet will be minimum",
    "start": "1206400",
    "end": "1212799"
  },
  {
    "text": "essentially yeah i don't know about this one i think they have to revise their architecture",
    "start": "1212799",
    "end": "1218320"
  },
  {
    "text": "in my opinion this will provide significant hit room in the thread count used as the total thread each server",
    "start": "1218320",
    "end": "1225760"
  },
  {
    "text": "must maintain is directly proportional to the number of servers in the fleet well we know that having fewer server",
    "start": "1225760",
    "end": "1234080"
  },
  {
    "text": "means that each server maintains fewer thread because now because it's if the thread",
    "start": "1234080",
    "end": "1239440"
  },
  {
    "text": "is one to one to the front-end server almost right so we know that if you have n",
    "start": "1239440",
    "end": "1244559"
  },
  {
    "text": "front-end it's n minus one according to our graphic but that might that calculation might not be",
    "start": "1244559",
    "end": "1250240"
  },
  {
    "text": "accurate i've just made it up because they say threads so it could be actually more than one thread",
    "start": "1250240",
    "end": "1256640"
  },
  {
    "text": "for each server so it could be double who knows and as a result it could be",
    "start": "1256640",
    "end": "1261919"
  },
  {
    "text": "just expanding and we still don't know why front ends",
    "start": "1261919",
    "end": "1267120"
  },
  {
    "text": "these front and are talking to each other are they heartbeats can we just do neighbors maybe they're",
    "start": "1267120",
    "end": "1273919"
  },
  {
    "text": "just they talk to each other i'm just again i'm just making some assertions here i'm",
    "start": "1273919",
    "end": "1278960"
  },
  {
    "text": "not necessarily correct um my guess is that these are heartbeats to detect if a front-end machine",
    "start": "1278960",
    "end": "1285760"
  },
  {
    "text": "has went down in order to remove it from the fleet that's just an uh i guess but even",
    "start": "1285760",
    "end": "1293520"
  },
  {
    "text": "though can we have a better approach without communicating with each other",
    "start": "1293520",
    "end": "1299120"
  },
  {
    "text": "because you you need to communicate with each other i mean cassandra does that right cassandra and they're shard right",
    "start": "1299120",
    "end": "1306720"
  },
  {
    "text": "in their shorted starting system they have a shard ring and if you add a new",
    "start": "1306720",
    "end": "1312159"
  },
  {
    "text": "system it just talks to the neighbor because it's a sharp drink it's not a short p",
    "start": "1312159",
    "end": "1317280"
  },
  {
    "text": "or mesh it's not a sharp mesh it's a short ring so if you add a new sharp it's just like",
    "start": "1317280",
    "end": "1322720"
  },
  {
    "text": "hey i'm a new shard can i have three uh can i have uh i don't know half a gig from you and half a gig from",
    "start": "1322720",
    "end": "1329200"
  },
  {
    "text": "you and i'm going to saturate you a little bit let me get my traffic's from new so so",
    "start": "1329200",
    "end": "1334320"
  },
  {
    "text": "yeah there are some communication but it's just very minimum right instead of taking from the all fleet",
    "start": "1334320",
    "end": "1339679"
  },
  {
    "text": "that's something cassandra again i'm buying me wrong but i believe cassandra fixes that",
    "start": "1339679",
    "end": "1346240"
  },
  {
    "text": "that limitation in dynamo dynamo was taking from everyone right uh so when shard entered the ring",
    "start": "1346240",
    "end": "1353919"
  },
  {
    "text": "it was taking from everyone so saturating the network of whether if a shard leaves or enters",
    "start": "1353919",
    "end": "1360240"
  },
  {
    "text": "okay while cassandra they just took from the sides there is there is there is a slight",
    "start": "1360240",
    "end": "1368640"
  },
  {
    "text": "again i'm making all this stuff up guys don't don't take my word for grand but it's just analysis that's what we do",
    "start": "1368640",
    "end": "1374880"
  },
  {
    "text": "we analyze back and if you don't have answers we analyze why we could be wrong of course we could be wrong",
    "start": "1374880",
    "end": "1380240"
  },
  {
    "text": "who cares i'm not saying this is the truth i'm just saying i'm analysis and you guys",
    "start": "1380240",
    "end": "1385280"
  },
  {
    "text": "are gonna have hundreds of comments that you guys analyze and i love those analysis that's what we do we analyze we",
    "start": "1385280",
    "end": "1392159"
  },
  {
    "text": "are back engineers we make assertions let's continue so that's my guess",
    "start": "1392159",
    "end": "1398559"
  },
  {
    "text": "right so yeah peer-to-peer and this mish architecture i don't think it's working",
    "start": "1398559",
    "end": "1404400"
  },
  {
    "text": "my opinion is just unless they're doing something that cannot justify that communication but",
    "start": "1404400",
    "end": "1410799"
  },
  {
    "text": "i don't know we are moving front-end cache to a dedicated fleet there you go that's what when i first read the",
    "start": "1410799",
    "end": "1417200"
  },
  {
    "text": "articles like why don't you move the cash in a dedicated cluster as a result they just did right so the",
    "start": "1417200",
    "end": "1423919"
  },
  {
    "text": "cash is now a dedicated fleet so maybe it's a smaller fleet so but they still",
    "start": "1423919",
    "end": "1429279"
  },
  {
    "text": "yet they are still uh insisting on the communication between",
    "start": "1429279",
    "end": "1435120"
  },
  {
    "text": "all the front-end servers and i don't know why i'm so curious to",
    "start": "1435120",
    "end": "1440559"
  },
  {
    "text": "know if you move the cache then those front-end stinking servers don't need to talk to",
    "start": "1440559",
    "end": "1446960"
  },
  {
    "text": "each other right you just moved it to a fleet right so you communicate to that fleet and that's it we will also move a few",
    "start": "1446960",
    "end": "1452799"
  },
  {
    "text": "large aws services like aws to a separate partitioned front-end fleet okay so",
    "start": "1452799",
    "end": "1458240"
  },
  {
    "text": "they're also moving these the g series so it is not depending on kinesis as much in the",
    "start": "1458240",
    "end": "1465600"
  },
  {
    "text": "medium term we will greatly accelerate ciliarization of front-end fleet to",
    "start": "1465600",
    "end": "1471279"
  },
  {
    "text": "match what we've done with the back end all right so they they're going to shard the front into",
    "start": "1471279",
    "end": "1478000"
  },
  {
    "text": "cellularized i'm not familiar with that one guys if you know what i don't know what that was silly realization is an approach we use",
    "start": "1478000",
    "end": "1485600"
  },
  {
    "text": "to isolate the effect of failure within a service okay and to keep the components of the",
    "start": "1485600",
    "end": "1491200"
  },
  {
    "text": "service in case of the sharp map cache operating within a previously tested and",
    "start": "1491200",
    "end": "1496799"
  },
  {
    "text": "operating range okay are they sharding the cash this had been underway for the front end fleet in kinesis but",
    "start": "1496799",
    "end": "1504080"
  },
  {
    "start": "1500000",
    "end": "1880000"
  },
  {
    "text": "unfortunately the work had not been completed now they explain like why other services went down as well so",
    "start": "1504080",
    "end": "1511120"
  },
  {
    "text": "there are a number of services that users kinesis that impacted amazon cognito a lot of you guys in the previous video",
    "start": "1511120",
    "end": "1516880"
  },
  {
    "text": "that i made uh mentioned that cognito went down right so amazon cognito uses kinesis",
    "start": "1516880",
    "end": "1524000"
  },
  {
    "text": "data stream to collect analysis analyze api access pattern so amazon cognito uses kinesis data stream",
    "start": "1524000",
    "end": "1531120"
  },
  {
    "text": "to collect and analyze api access pattern can you guys opt out of this as a",
    "start": "1531120",
    "end": "1537679"
  },
  {
    "text": "customer for for people who uses kennedys let me know in the comment section can you guys opt out of this",
    "start": "1537679",
    "end": "1543440"
  },
  {
    "text": "analysis of the api pattern because i don't know do you even know",
    "start": "1543440",
    "end": "1549520"
  },
  {
    "text": "that they are doing this the analyzer of the api access panel i don't think you can opt out they just",
    "start": "1549520",
    "end": "1556000"
  },
  {
    "text": "want to optimize so they analyze these patterns api access while this",
    "start": "1556000",
    "end": "1561039"
  },
  {
    "text": "information is extremely useful for operating the cognito service this information streaming is designed",
    "start": "1561039",
    "end": "1567200"
  },
  {
    "text": "to be best effort data is buffered locally allowing the service to cope with",
    "start": "1567200",
    "end": "1573760"
  },
  {
    "text": "latency or short period of unavailability of the kinesis data system so there is",
    "start": "1573760",
    "end": "1579279"
  },
  {
    "text": "some buffering going on right unfortunately the prolonged issue with kenya's data stream triggered a latent",
    "start": "1579279",
    "end": "1584720"
  },
  {
    "text": "bug in the buffering code that caused cognitive oh my god that is genius okay",
    "start": "1584720",
    "end": "1592159"
  },
  {
    "text": "a latent bug in the buffering code that caused the cognito observer to begin to block",
    "start": "1592159",
    "end": "1597520"
  },
  {
    "text": "on the back logged kinesis data stream buffer so i guess the buffer you cannot just",
    "start": "1597520",
    "end": "1603520"
  },
  {
    "text": "because the kinesis was known you still uh cognito started buffering buffering buffering",
    "start": "1603520",
    "end": "1608960"
  },
  {
    "text": "and i guess it ran out of buffer or triggered a a bug with the buffering",
    "start": "1608960",
    "end": "1614000"
  },
  {
    "text": "code as a result cognitive has extended elevated api failure and increased latencies for cognito user",
    "start": "1614000",
    "end": "1620880"
  },
  {
    "text": "pool and identity which prevented external user from authenticated or opening up obtaining temporary aws",
    "start": "1620880",
    "end": "1628880"
  },
  {
    "text": "credential my god look at it analyzing an api which is",
    "start": "1628880",
    "end": "1636960"
  },
  {
    "text": "something you don't want to do right it's just collects an analog api this is as a side effect",
    "start": "1636960",
    "end": "1642080"
  },
  {
    "text": "it's it's it's not something that has to do with cognito yet it",
    "start": "1642080",
    "end": "1649600"
  },
  {
    "text": "brought down the cognito observers there is a big lesson for us to learn",
    "start": "1649600",
    "end": "1655520"
  },
  {
    "text": "here guys you ain't gonna need it if you not gonna need it don't add it to the feature right",
    "start": "1655520",
    "end": "1662159"
  },
  {
    "text": "because yeah look at this this is oh my god so in the early stages of the event the",
    "start": "1662159",
    "end": "1668799"
  },
  {
    "text": "cognito team worked to make mitigate the impact of the kinesis error by adding",
    "start": "1668799",
    "end": "1674000"
  },
  {
    "text": "additional capacity and therefore increasing their capacity to buffer calls um to buffer calls to kinesis okay so",
    "start": "1674000",
    "end": "1680480"
  },
  {
    "text": "they just increase the buffer capacity so that they buffer more instead of failing right",
    "start": "1680480",
    "end": "1686880"
  },
  {
    "text": "i'm glad that amazon is doing that by the way it takes it takes guts to write this telling you that guys by the way we're",
    "start": "1686880",
    "end": "1693440"
  },
  {
    "text": "doing this we're collecting this api stuff i know that has nothing to do with cognito",
    "start": "1693440",
    "end": "1699200"
  },
  {
    "text": "but yeah it actually brought your server down although the cognito did literally",
    "start": "1699200",
    "end": "1704399"
  },
  {
    "text": "didn't do anything right their service is up and running they have just a bad code so that when i try to buffer",
    "start": "1704399",
    "end": "1712320"
  },
  {
    "text": "these analog analysis api for kinesis they can't send it anymore right there",
    "start": "1712320",
    "end": "1717600"
  },
  {
    "text": "so it started buffering buffering buffering collecting all these apis to be analyzed but they i i guess",
    "start": "1717600",
    "end": "1723440"
  },
  {
    "text": "crash the server okay can't can't take more this should be like stored somewhere but",
    "start": "1723440",
    "end": "1729440"
  },
  {
    "text": "they fixed that i'm glad they actually fixed that very quickly all right while this reduced the impacts",
    "start": "1729440",
    "end": "1736159"
  },
  {
    "text": "by 7 am pst error rates increased significantly the team",
    "start": "1736159",
    "end": "1742159"
  },
  {
    "text": "was working in parallel on a change to cognito to reduce the dependency on kinesis there you go",
    "start": "1742159",
    "end": "1749600"
  },
  {
    "text": "that's the that's what they should do there should not be a dependency between cognito and kinesis",
    "start": "1749600",
    "end": "1755120"
  },
  {
    "text": "because nito's what it's going to mean let's search about that oh so it's an identity system essentially you can log",
    "start": "1755120",
    "end": "1760960"
  },
  {
    "text": "in with facebook amazon google using cognito essentially okay let me know guys if i get that right but yeah",
    "start": "1760960",
    "end": "1767360"
  },
  {
    "text": "that's what it is to reduce dependency on kinesis so they started working on that and 10",
    "start": "1767360",
    "end": "1773600"
  },
  {
    "text": "am deployment of this change began and error rate began falling",
    "start": "1773600",
    "end": "1778960"
  },
  {
    "text": "right okay that's that's wow guys those are badass they implemented reducing the dependency",
    "start": "1778960",
    "end": "1786080"
  },
  {
    "text": "in few hours some engineers man there's a badass engineers guys",
    "start": "1786080",
    "end": "1791919"
  },
  {
    "text": "i i want to give a shout out for all the amazon aws engineers",
    "start": "1791919",
    "end": "1798399"
  },
  {
    "text": "that worked on this and managed to fix this you guys are the real hero in my opinion",
    "start": "1798399",
    "end": "1805279"
  },
  {
    "text": "because that must have been very stressful right i should have started with this",
    "start": "1805279",
    "end": "1810399"
  },
  {
    "text": "guys kudos and uh great job like from all the teams look at this the",
    "start": "1810399",
    "end": "1816080"
  },
  {
    "text": "cognito team has nothing to do with kenya's but it went down and they immediately",
    "start": "1816080",
    "end": "1821360"
  },
  {
    "text": "started implementing a fix to reduce the dependence on kinesis that tells me there's there's a fluidity",
    "start": "1821360",
    "end": "1828399"
  },
  {
    "text": "when it comes to amazon and there's like ev every team is like reactive which is great",
    "start": "1828399",
    "end": "1833760"
  },
  {
    "text": "i like this it's not like a centralized entity that makes the order they just",
    "start": "1833760",
    "end": "1839600"
  },
  {
    "text": "otherwise it's going to slow down all right let's continue in 10 a.m uh 10 a.m the morning deployed of this chain",
    "start": "1839600",
    "end": "1845919"
  },
  {
    "text": "began and error began failing by 12 pm error rates were significantly",
    "start": "1845919",
    "end": "1852640"
  },
  {
    "text": "reduced and 2 pm cognito was operating normally the prevent to prevent a recurrence of this issue we",
    "start": "1852640",
    "end": "1858960"
  },
  {
    "text": "have modified the cognito observers so that they can sustain kinesis errors without exhausting their buffers",
    "start": "1858960",
    "end": "1865200"
  },
  {
    "text": "okay so they fix that bug so that it's like okay even if kinesis failed we still can continue normally",
    "start": "1865200",
    "end": "1872720"
  },
  {
    "text": "which is awesome this is what yeah because that extra server that we're doing has nothing to do with the",
    "start": "1872720",
    "end": "1879200"
  },
  {
    "text": "main job of cognito right this should be independent list coupling cloudwatch uses kinesis",
    "start": "1879200",
    "end": "1887200"
  },
  {
    "start": "1880000",
    "end": "2000000"
  },
  {
    "text": "data stream for processing metrics and logs data starting at 5 am",
    "start": "1887200",
    "end": "1892640"
  },
  {
    "text": "psd cloud watch experience increasing error rate and latencies for the put metric data and put look api",
    "start": "1892640",
    "end": "1901519"
  },
  {
    "text": "and that makes it like cloud watch has to go down because it is depended on kinesis unlike cognito which is like",
    "start": "1901519",
    "end": "1908880"
  },
  {
    "text": "a side thing hey we're going to analyze the logs let's just any api call that we make we're going to analyze let's put it in kinesis",
    "start": "1908880",
    "end": "1915039"
  },
  {
    "text": "so we can stream it and analyze it later right so as we do that that",
    "start": "1915039",
    "end": "1921120"
  },
  {
    "text": "should not affect it but cloud watch yeah it is it is its main dependency so of course it's going to go",
    "start": "1921120",
    "end": "1927279"
  },
  {
    "text": "down cloud watch experience increased errors and we said alarms transition to",
    "start": "1927279",
    "end": "1932640"
  },
  {
    "text": "insufficient data state why while some cloud watch metric",
    "start": "1932640",
    "end": "1937760"
  },
  {
    "text": "continued to be processed throughout the event the increased error rate on latencies prevented the vast",
    "start": "1937760",
    "end": "1945039"
  },
  {
    "text": "majority of metric while some cloud watch metric continued to be processed throughout the",
    "start": "1945039",
    "end": "1950320"
  },
  {
    "text": "event increased error rate and latencies prevented the vast majority of metrics",
    "start": "1950320",
    "end": "1955840"
  },
  {
    "text": "from being successfully processed at 7 30 7 47 p.m",
    "start": "1955840",
    "end": "1962159"
  },
  {
    "text": "cloud watch began to see early signs of recovery as kinesis data stream availability",
    "start": "1962159",
    "end": "1967679"
  },
  {
    "text": "improved right because uh i think that their front end started i think they",
    "start": "1967679",
    "end": "1973039"
  },
  {
    "text": "they they give the priorities to to cloud watch so they they can spin up",
    "start": "1973039",
    "end": "1979679"
  },
  {
    "text": "all these services and get it up and running and by 10 30 pm cloud watch",
    "start": "1979679",
    "end": "1986159"
  },
  {
    "text": "metric and alarm fully recover delayed metrics and log uh subsequence all right",
    "start": "1986159",
    "end": "1991200"
  },
  {
    "text": "so we we know that okay this is dependent this services depend and that's good though cognito one was really interesting",
    "start": "1991200",
    "end": "1997200"
  },
  {
    "text": "in my opinion two services were impacted as a result of the issues with cloud",
    "start": "1997200",
    "end": "2002840"
  },
  {
    "start": "2000000",
    "end": "2150000"
  },
  {
    "text": "metrics my god look at this it's a chain it's a cascading chain",
    "start": "2002840",
    "end": "2009600"
  },
  {
    "text": "so cloudflag metrics first reactive auto scaling policies that rely on cloud",
    "start": "2009600",
    "end": "2014799"
  },
  {
    "text": "watch metrics experience delays until cloud watch metrics begin to recover so",
    "start": "2014799",
    "end": "2021600"
  },
  {
    "text": "these things that's called auto scaling policies depending on cloud watch which depend on kinesis which depends on their",
    "start": "2021600",
    "end": "2027200"
  },
  {
    "text": "internal architecture the front end and and once something fail all the other cascading just cascades and fail",
    "start": "2027200",
    "end": "2034399"
  },
  {
    "text": "oh this one is interesting let's see as and second lambda so impact lambda functions are the this",
    "start": "2034399",
    "end": "2040000"
  },
  {
    "text": "the serverless functions lambda function invocations currently require publishing metric data to cloud",
    "start": "2040000",
    "end": "2047679"
  },
  {
    "text": "uh to cloud watch as part of the invocation lambda metrics agents are designed to",
    "start": "2047679",
    "end": "2054960"
  },
  {
    "text": "buffer metrics data locally for a period of time if",
    "start": "2054960",
    "end": "2060079"
  },
  {
    "text": "cloudwatch is unavailable all right that same thing we saw with cognito it's buffering stuff",
    "start": "2060079",
    "end": "2066158"
  },
  {
    "text": "starting is buffering stuff locally so that it can send it at a later time starting",
    "start": "2066159",
    "end": "2071919"
  },
  {
    "text": "6 15 am this buffering metric data grew to the point that it caused memory contention",
    "start": "2071919",
    "end": "2077679"
  },
  {
    "text": "on the services of the host of lambda information that makes perfect sense like if you have like a lambda services",
    "start": "2077679",
    "end": "2083919"
  },
  {
    "text": "right you execute a server servers like function that serverless",
    "start": "2083919",
    "end": "2089200"
  },
  {
    "text": "lambda talks to cloudwatch which talks to kinesis which is down right",
    "start": "2089200",
    "end": "2094240"
  },
  {
    "text": "so that service decided to buffer things in memory and as request comes in so the buffer",
    "start": "2094240",
    "end": "2101440"
  },
  {
    "text": "the buffer causes the the memory to grow and as the memory grows your node.js serverless function",
    "start": "2101440",
    "end": "2109359"
  },
  {
    "text": "cannot no longer execute resulting in errors it feels so good when you actually understand what's going on man",
    "start": "2109359",
    "end": "2115119"
  },
  {
    "text": "that's really good i was like just understand like oh this is because of this this is because of this everything has a cause and effect at 10",
    "start": "2115119",
    "end": "2121440"
  },
  {
    "text": "36 a.m engineers took the action to my to mitigate the memory contextual which",
    "start": "2121440",
    "end": "2126880"
  },
  {
    "text": "resolved the increase so so lambda was fixed very early right those the lambda engineers they just",
    "start": "2126880",
    "end": "2133440"
  },
  {
    "text": "said hey wait a second why are we buffering this thing let's just maybe flush it to disk or something like that they didn't say that",
    "start": "2133440",
    "end": "2139599"
  },
  {
    "text": "but i'm just assuming they flush the disk and why would you keep it in the member this is useless useless information right i'd rather",
    "start": "2139599",
    "end": "2147680"
  },
  {
    "text": "execute the user's data function rather than keep in memory some metrics cloudwatch events and",
    "start": "2147680",
    "end": "2155280"
  },
  {
    "start": "2150000",
    "end": "2280000"
  },
  {
    "text": "eventbridge experienced increased api errors and delays in event processing starting",
    "start": "2155280",
    "end": "2161920"
  },
  {
    "text": "at 5 00 15 a.m as kinesis availability improved",
    "start": "2161920",
    "end": "2167599"
  },
  {
    "text": "event bridge began to deliver new events and slowly process the backlog of older",
    "start": "2167599",
    "end": "2173599"
  },
  {
    "text": "events elastic container service sheesh and elastic",
    "start": "2173599",
    "end": "2178880"
  },
  {
    "text": "kubernetes service both make use of eventbridge to drive internal workflows",
    "start": "2178880",
    "end": "2185680"
  },
  {
    "text": "used to manage customers clusters this impact provisioning of new cluster delayed scaling of existing clustered and",
    "start": "2185680",
    "end": "2194320"
  },
  {
    "text": "man this one is serious guys i couldn't i didn't realize how serious this thing is",
    "start": "2194320",
    "end": "2200480"
  },
  {
    "text": "so amazon kinesis is the heart of the entire aws system looks like it",
    "start": "2200480",
    "end": "2208400"
  },
  {
    "text": "man that wasn't a fun day for aws i wonder if the aws",
    "start": "2208400",
    "end": "2216480"
  },
  {
    "text": "amazon stocks will go down after this because that that kind of",
    "start": "2216480",
    "end": "2223280"
  },
  {
    "text": "because now as they start revealing their architecture people will have second thoughts like quality",
    "start": "2224079",
    "end": "2229760"
  },
  {
    "text": "this thing is first it's proprietary second they have a centralized system",
    "start": "2229760",
    "end": "2235200"
  },
  {
    "text": "everything is relying on this kinesis thing and if this kinesis went down again in the future i don't know",
    "start": "2235200",
    "end": "2244000"
  },
  {
    "text": "people might lose trust in amazon what do you guys think let me know it's",
    "start": "2244000",
    "end": "2250480"
  },
  {
    "text": "just nuts that everything you really rely on kenny's i haven't i did not know that",
    "start": "2250480",
    "end": "2256320"
  },
  {
    "text": "outside of the service issue we experienced some delays in communicating service status yeah i saw that",
    "start": "2256320",
    "end": "2262560"
  },
  {
    "text": "like even we cannot even tell you that the service is down",
    "start": "2262560",
    "end": "2267680"
  },
  {
    "text": "because our service i'm gonna kill myself if this the service status page depends",
    "start": "2267680",
    "end": "2273520"
  },
  {
    "text": "on kenya's let's read this out by the way i i didn't read this bottom but i only read",
    "start": "2273520",
    "end": "2278800"
  },
  {
    "text": "the interesting part in the beginning so i'm reading this for the first time with you we have two ways of communication",
    "start": "2278800",
    "end": "2286720"
  },
  {
    "start": "2280000",
    "end": "2400000"
  },
  {
    "text": "during the operation event the service health dashboard which is our public dashboard to alert",
    "start": "2286720",
    "end": "2293040"
  },
  {
    "text": "customers of board operational issues and personal health dashboard which we use to",
    "start": "2293040",
    "end": "2300560"
  },
  {
    "text": "communicate directly with impacted customers with an event such as",
    "start": "2300560",
    "end": "2305920"
  },
  {
    "text": "this one we typically post to the service health dashboard during the early part of this event we were not",
    "start": "2305920",
    "end": "2314320"
  },
  {
    "text": "we were unable to update the service because the tool we use to post these updates itself uses",
    "start": "2314320",
    "end": "2323200"
  },
  {
    "text": "cognitive which was impacted by the event i didn't mean to laugh it's just it's",
    "start": "2324839",
    "end": "2331760"
  },
  {
    "text": "just funny the dependency tree it's like this tells",
    "start": "2331760",
    "end": "2336800"
  },
  {
    "text": "me that amazon better gets their ducks in their own mech kinesis",
    "start": "2336800",
    "end": "2343119"
  },
  {
    "text": "really scalable it's not scalable today they have to solve the cold star problem",
    "start": "2343119",
    "end": "2349680"
  },
  {
    "text": "they have to stop this peer-to-peer mesh architecture that they have the service the front end services",
    "start": "2349680",
    "end": "2355520"
  },
  {
    "text": "should not talk to each other if they don't have to again we don't know the story behind it maybe there is a good reason that for",
    "start": "2355520",
    "end": "2362160"
  },
  {
    "text": "them to have to talk to because nobody no i've never seen an architecture where",
    "start": "2362160",
    "end": "2367440"
  },
  {
    "text": "machines talk to each other in this verbose manner it's just i don't know i don't think",
    "start": "2367440",
    "end": "2373920"
  },
  {
    "text": "that's a good idea because it's not scalable but yet amazon is the biggest cloud provider so what do",
    "start": "2373920",
    "end": "2380079"
  },
  {
    "text": "i know so yeah so the the the cognito is this identity provider it looks like it's",
    "start": "2380079",
    "end": "2386400"
  },
  {
    "text": "so observer so it depends on the service health dashboard which uses cognito which uses",
    "start": "2386400",
    "end": "2394079"
  },
  {
    "text": "which which fires up this analytics um uh api metrics",
    "start": "2394079",
    "end": "2400320"
  },
  {
    "start": "2400000",
    "end": "2732000"
  },
  {
    "text": "to kinesis which was down and before because of the buffering bug incognito that was impacted for a few",
    "start": "2400320",
    "end": "2406640"
  },
  {
    "text": "so they fixed cognito which fixed any upstream services or downstream man this this is",
    "start": "2406640",
    "end": "2414319"
  },
  {
    "text": "overloaded i guess it's downstream which was impacted by this event",
    "start": "2414319",
    "end": "2420720"
  },
  {
    "text": "we have backup means we have backup okay english we have we have a backup",
    "start": "2420720",
    "end": "2428079"
  },
  {
    "text": "means of updating the service health that has minimum service dependencies yes while this worked as expected we",
    "start": "2428079",
    "end": "2435599"
  },
  {
    "text": "encountered several delays during the earlier part of the event and posting to the service health as",
    "start": "2435599",
    "end": "2442319"
  },
  {
    "text": "it is it is more manual and less familiar for uh support operators",
    "start": "2442319",
    "end": "2449280"
  },
  {
    "text": "okay so because it's a manual process they weren't updating as much so they were relying on the automated i mean",
    "start": "2449280",
    "end": "2456319"
  },
  {
    "text": "as they should they should rely on automation i mean who knew this will happen this is this is a great lesson for all engineers",
    "start": "2456319",
    "end": "2463200"
  },
  {
    "text": "thank you amazon for being so generous and writing this summary we love you for this",
    "start": "2463200",
    "end": "2469040"
  },
  {
    "text": "to ensure customers were getting timely update their support team use the personal health dashboard to",
    "start": "2469040",
    "end": "2475359"
  },
  {
    "text": "notify impacted customers if they were impacted by the service issues",
    "start": "2475359",
    "end": "2481760"
  },
  {
    "text": "we also posted a global banner summary on the service dashboard to ensure customer during the reminder",
    "start": "2481760",
    "end": "2488319"
  },
  {
    "text": "of the event a remainder of the event we continue using a combination of the service health dashboard with the",
    "start": "2488319",
    "end": "2494960"
  },
  {
    "text": "global banner summaries and service details while also continuing to update",
    "start": "2494960",
    "end": "2500800"
  },
  {
    "text": "impacted customers via personal health dashboard going forward we have changed",
    "start": "2500800",
    "end": "2507839"
  },
  {
    "text": "our support training to ensure that our support engineers are regularly trained on the backup tools for posting services",
    "start": "2507839",
    "end": "2514640"
  },
  {
    "text": "okay so they're they saying they had the service health don't rely on the automated",
    "start": "2514640",
    "end": "2519839"
  },
  {
    "text": "do the manual thing where you just literally type it in and then just or use like their their",
    "start": "2519839",
    "end": "2526400"
  },
  {
    "text": "service all right that's that makes this this uh these measures are great finally",
    "start": "2526400",
    "end": "2534400"
  },
  {
    "text": "we want to apologize for the impact this event caused for our customers while we are proud for",
    "start": "2534400",
    "end": "2540640"
  },
  {
    "text": "long track record of ability and he says yeah you guys nailed it i mean",
    "start": "2540640",
    "end": "2546000"
  },
  {
    "text": "i did not hear of it of uh dow an off an outage like this before on",
    "start": "2546000",
    "end": "2551520"
  },
  {
    "text": "amazon like because i keep up to date with the outages and amazon is a barely goes into arnold if it does",
    "start": "2551520",
    "end": "2558000"
  },
  {
    "text": "it's a few minutes and goes back up so this one when it happened when it happened it happened",
    "start": "2558000",
    "end": "2563680"
  },
  {
    "text": "hard so it is scary we now know how critical the",
    "start": "2563680",
    "end": "2569520"
  },
  {
    "text": "service and other iws servers that were impacted are to our customers their application end users and their",
    "start": "2569520",
    "end": "2576319"
  },
  {
    "text": "businesses we will do everything we can to learn from this event and use to improve our availability",
    "start": "2576319",
    "end": "2584560"
  },
  {
    "text": "even further guys we saw two patterns here the first pattern is",
    "start": "2584560",
    "end": "2591040"
  },
  {
    "text": "the amazon kinesis architecture which is i still do not fully understand why it is a mesh at in",
    "start": "2591040",
    "end": "2598240"
  },
  {
    "text": "the front end at least where all these servers are talking to each other right",
    "start": "2598240",
    "end": "2603440"
  },
  {
    "text": "they they fix that they they claim to they want to move the cash map of the",
    "start": "2603440",
    "end": "2609920"
  },
  {
    "text": "shard to a serve to a different fleet from the front customer and have all these front end just talk",
    "start": "2609920",
    "end": "2616480"
  },
  {
    "text": "to the fleet to obtain the cash because that's what we usually do",
    "start": "2616480",
    "end": "2621839"
  },
  {
    "text": "right but they still are keeping the the one-to-one peer-to-peer",
    "start": "2621839",
    "end": "2627440"
  },
  {
    "text": "communication between this one and i do not know the answer to this and this article does not explain that",
    "start": "2627440",
    "end": "2633760"
  },
  {
    "text": "all right i am speculating it's a health it's like hey by the way i'm alarm i'm alive i'm alive",
    "start": "2633760",
    "end": "2639119"
  },
  {
    "text": "but do you really need to communicate to all surf just that you're alive doesn't make sense just their neighboring is enough",
    "start": "2639119",
    "end": "2646640"
  },
  {
    "text": "again what uh the second thing is just the dependency on kenny says i knew if case is so powerful",
    "start": "2646839",
    "end": "2655359"
  },
  {
    "text": "that then yeah sure you can depend on on this cascade and",
    "start": "2655359",
    "end": "2661680"
  },
  {
    "text": "it's it's very very simple for us to use a service but once this service starts depending on",
    "start": "2661680",
    "end": "2667280"
  },
  {
    "text": "other servers like that we sell with with cloud watch right cloudwork depending on kinesis and then",
    "start": "2667280",
    "end": "2674160"
  },
  {
    "text": "some elastic i don't know what depends on cloud watch it depends on kinesis and and their their health service depend",
    "start": "2674160",
    "end": "2681119"
  },
  {
    "text": "their health status depends on cognito which kind of not really depends on on kenesis",
    "start": "2681119",
    "end": "2687040"
  },
  {
    "text": "but has this this metrics logging system that does in the background which",
    "start": "2687040",
    "end": "2692240"
  },
  {
    "text": "creates a buffer which has a memory contention lambda all this stuff they have fixes",
    "start": "2692240",
    "end": "2698400"
  },
  {
    "text": "for it but it's just i'm a little bit still worried about the architecture in",
    "start": "2698400",
    "end": "2704480"
  },
  {
    "text": "the front and it's like the cold start of those front end and just adding and",
    "start": "2704480",
    "end": "2710720"
  },
  {
    "text": "removing service is so slow they i think they need to do something about it",
    "start": "2710720",
    "end": "2717119"
  },
  {
    "text": "that's the article guys that's my analysis that's to my two cents what do you guys think let me know in",
    "start": "2717119",
    "end": "2722640"
  },
  {
    "text": "the comment section below were you affected by this outage and what do you think about this architecture let me know in the comment",
    "start": "2722640",
    "end": "2728240"
  },
  {
    "text": "section below i'm gonna see on the next one you guys stay awesome goodbye",
    "start": "2728240",
    "end": "2732960"
  }
]
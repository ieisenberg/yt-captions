[
  {
    "start": "0",
    "end": "120000"
  },
  {
    "text": "the engineering team behind Amazon Prime Video has released a Blog detailing how",
    "start": "0",
    "end": "6600"
  },
  {
    "text": "they moved one monitoring service that detects you know freezing frames and",
    "start": "6600",
    "end": "13679"
  },
  {
    "text": "clicks and audio in their live streaming portion in the Prime video app",
    "start": "13679",
    "end": "20160"
  },
  {
    "text": "and they moved that piece of the architecture from serverless and microservices to a",
    "start": "20160",
    "end": "29039"
  },
  {
    "text": "monolith and they saved 90 of the cost and they were able to scale better",
    "start": "29039",
    "end": "35340"
  },
  {
    "text": "how about we read this article and then discuss so this comes from Prime video tech right written by Marcin colney",
    "start": "35340",
    "end": "43579"
  },
  {
    "text": "scaling up the Prime video audio video monitoring service and reducing cost by",
    "start": "43579",
    "end": "49680"
  },
  {
    "text": "90 the move from distributed microservices architecture to a monolith",
    "start": "49680",
    "end": "54840"
  },
  {
    "text": "application helped achieve higher scale resilience and reduce costs so yeah so",
    "start": "54840",
    "end": "61199"
  },
  {
    "text": "how did they actually move from microservices to monolithan how did that happen let's discuss this uh I gotta warn you",
    "start": "61199",
    "end": "68880"
  },
  {
    "text": "guys this article is not very detailed unfortunately right there is a lot of",
    "start": "68880",
    "end": "74640"
  },
  {
    "text": "missing things here uh this article could have been great it it's just okay to be honest right that's",
    "start": "74640",
    "end": "81600"
  },
  {
    "text": "that's one one thing out of the way and and the reason is because there's so much background information that we have",
    "start": "81600",
    "end": "88140"
  },
  {
    "text": "no idea about the diagrams is is not already well designed in my opinion and",
    "start": "88140",
    "end": "94799"
  },
  {
    "text": "the the the the text doesn't explain the architecture well it's just it's just a",
    "start": "94799",
    "end": "100680"
  },
  {
    "text": "bunch of boxes and they talk to each other and we have no idea what the use case is what's the workflow like what is",
    "start": "100680",
    "end": "107159"
  },
  {
    "text": "what am I doing here as a customer all of these things are missing right maybe they are explaining in other places I",
    "start": "107159",
    "end": "114360"
  },
  {
    "text": "looked in other articles it's not there but I'll try based on my understanding",
    "start": "114360",
    "end": "120420"
  },
  {
    "start": "120000",
    "end": "635000"
  },
  {
    "text": "to actually explain what I think is happening right of course I might be wrong okay but let's",
    "start": "120420",
    "end": "127439"
  },
  {
    "text": "get it Prime video a prime Amazon Prime if you don't know this is a service you pay what 120 a dollar a year you get so",
    "start": "127439",
    "end": "135480"
  },
  {
    "text": "many stuff like two-day delivery from Amazon Prime video Prime music",
    "start": "135480",
    "end": "141120"
  },
  {
    "text": "so much Services right so you can also subscribe with twitch you know to",
    "start": "141120",
    "end": "146160"
  },
  {
    "text": "support your creators Prime something almost all you know people in the US",
    "start": "146160",
    "end": "151860"
  },
  {
    "text": "have like even even outside as well so Prime's a very popular concept right so",
    "start": "151860",
    "end": "157500"
  },
  {
    "text": "a Prime video we offer thousands of live streams to our customers live streams",
    "start": "157500",
    "end": "163379"
  },
  {
    "text": "here has nothing to do with twitch by the way this is their own new thing apparently that you know to live stream",
    "start": "163379",
    "end": "170580"
  },
  {
    "text": "sporting events you know and having you watch it on this app",
    "start": "170580",
    "end": "176819"
  },
  {
    "text": "that's called Prime video so don't confuse that with twitch that I don't think it has anything to do with twitch",
    "start": "176819",
    "end": "182400"
  },
  {
    "text": "because at first like live streaming isn't that twitch because Twitches are owned by Amazon so that's why it first",
    "start": "182400",
    "end": "188340"
  },
  {
    "text": "went but nothing to do with twitch they're they're apparently working and from them these articles that you see on",
    "start": "188340",
    "end": "195239"
  },
  {
    "text": "the side it's like always like the streaming how you're trying to pop promote it because that's their you know",
    "start": "195239",
    "end": "201480"
  },
  {
    "text": "the better version of twitch if you will the actual high quality streaming and",
    "start": "201480",
    "end": "207840"
  },
  {
    "text": "they are spending good money when it comes to here right that's all you notice so to ensure that",
    "start": "207840",
    "end": "215040"
  },
  {
    "text": "customers seemingly seeming seamlessly receive content so if I'm a prime paying",
    "start": "215040",
    "end": "220920"
  },
  {
    "text": "customer unlike twitch which is free anyone can go go and watch it you know this is actually payment so if you're",
    "start": "220920",
    "end": "228180"
  },
  {
    "text": "paying something you better be good so they are spending they have an architecture to detect right so just to",
    "start": "228180",
    "end": "234900"
  },
  {
    "text": "summarize this article uh maybe let's do that like yeah they haven't they have an",
    "start": "234900",
    "end": "240659"
  },
  {
    "text": "architecture to Monitor and detect the experience of the user so because if the",
    "start": "240659",
    "end": "246840"
  },
  {
    "text": "experience of the user on a on a PS5 watching a live stream versus on an",
    "start": "246840",
    "end": "252000"
  },
  {
    "text": "iPhone versus on an Xbox versus on an Android phone it's all different and the reason is because the device does the",
    "start": "252000",
    "end": "258720"
  },
  {
    "text": "decoding I suppose of the video and the audio and and it takes these packets and there's a client-side logic that",
    "start": "258720",
    "end": "266100"
  },
  {
    "text": "executes and does more work and it could be there is there is a bug",
    "start": "266100",
    "end": "271560"
  },
  {
    "text": "in the decoder or the encoder that that shows you this uh freeze you know frames",
    "start": "271560",
    "end": "279360"
  },
  {
    "text": "or or something it clicks in the audio so there's a bug there in The Client app and Amazon wants to detect those bugs in",
    "start": "279360",
    "end": "287280"
  },
  {
    "text": "the client apps that's my understanding there's also of course it could be the encoder that the data you receive based",
    "start": "287280",
    "end": "295380"
  },
  {
    "text": "on what whatever streaming platform you are in whether it's good better quality",
    "start": "295380",
    "end": "300419"
  },
  {
    "text": "like the load I think that's how they categorize it good better or best something like that that's how they",
    "start": "300419",
    "end": "306720"
  },
  {
    "text": "categorize it so based on those streaming qualities and bitrates they",
    "start": "306720",
    "end": "313199"
  },
  {
    "text": "they could have problems in those as well in the source themselves so I don't",
    "start": "313199",
    "end": "318300"
  },
  {
    "text": "know if that is being detected by this okay but in general",
    "start": "318300",
    "end": "324600"
  },
  {
    "text": "maybe both actually so if if I am actually monitoring my device",
    "start": "324600",
    "end": "330000"
  },
  {
    "text": "what what I think this tool does well I think because they don't say that",
    "start": "330000",
    "end": "335580"
  },
  {
    "text": "the client application actually once it decodes that and I see it right",
    "start": "335580",
    "end": "342979"
  },
  {
    "text": "there is an option where you can set up monitoring I didn't see it in my app",
    "start": "342979",
    "end": "348900"
  },
  {
    "text": "here but maybe there is a place that I didn't see look when you enable this",
    "start": "348900",
    "end": "354120"
  },
  {
    "text": "monitoring thing it will re-upload the stream or part of the",
    "start": "354120",
    "end": "361020"
  },
  {
    "text": "stream that you just watched back to Amazon as as it is",
    "start": "361020",
    "end": "367020"
  },
  {
    "text": "as you decoded it so it's as how you watched it is Amazon will see it that's",
    "start": "367020",
    "end": "373740"
  },
  {
    "text": "the only way that you can actually ensure that whatever the user's seen is",
    "start": "373740",
    "end": "379080"
  },
  {
    "text": "uploaded back right because the client's doing more work so this uploading thing back to this",
    "start": "379080",
    "end": "386479"
  },
  {
    "text": "architecture that we're going to discuss then goes into the steps that we're",
    "start": "386479",
    "end": "393000"
  },
  {
    "text": "gonna that they're optimizing it goes into a microservice architecture there's a media conversion it converts the",
    "start": "393000",
    "end": "399180"
  },
  {
    "text": "stream that the user just uploaded then the application I just uploaded to",
    "start": "399180",
    "end": "404400"
  },
  {
    "text": "a bunch of frames right which is images and the audio is converted into certain buffers certain you know uh uh bytes and",
    "start": "404400",
    "end": "414180"
  },
  {
    "text": "those are fed into something called the Detector service another micro service how we're going to talk about that and",
    "start": "414180",
    "end": "421020"
  },
  {
    "text": "then once the detector will use machine learning based on training data let's say okay oh I detect these these frames",
    "start": "421020",
    "end": "427500"
  },
  {
    "text": "actually Frozen and these audios are actually clicking so it will once it detects something it will issue a",
    "start": "427500",
    "end": "435120"
  },
  {
    "text": "notification to a service and it will write down that okay this portion this",
    "start": "435120",
    "end": "440220"
  },
  {
    "text": "Frame is bad this Fortune This the frame is is not good right and will detect",
    "start": "440220",
    "end": "445259"
  },
  {
    "text": "those so that's how monitoring works and so now that we understand that let's",
    "start": "445259",
    "end": "450300"
  },
  {
    "text": "continue on reading and discussing the distributed architecture of that that I want to just explained versus the",
    "start": "450300",
    "end": "456539"
  },
  {
    "text": "monolith version right let's go ahead our video quality team at a Prime video",
    "start": "456539",
    "end": "462599"
  },
  {
    "text": "already on the tool for audio video Quality Inspection so a Quality",
    "start": "462599",
    "end": "467940"
  },
  {
    "text": "Inspection we're inspection the quality but we never intended it nor designed it to run at higher scale which is",
    "start": "467940",
    "end": "473699"
  },
  {
    "text": "understandable when you first design something they never thought about it you know it's to actually serve",
    "start": "473699",
    "end": "479780"
  },
  {
    "text": "thousands of concurrent streams right 1000 concurrency and we're talking about",
    "start": "479780",
    "end": "484979"
  },
  {
    "text": "are we and here's what what another thing I didn't understand what is concurrent streams right",
    "start": "484979",
    "end": "491460"
  },
  {
    "text": "we're monitoring concurrent streams back from the customers right the customers",
    "start": "491460",
    "end": "496500"
  },
  {
    "text": "watching something right and it's downloading it then it turns around and",
    "start": "496500",
    "end": "502379"
  },
  {
    "text": "upload that part of the Stream to the",
    "start": "502379",
    "end": "508080"
  },
  {
    "text": "to the service and the reason I'm saying this is because that's exactly what the diagram is showing right their diagram",
    "start": "508080",
    "end": "515399"
  },
  {
    "text": "is actually showing the user the custom is actually uploading something it's not a direct and the reason is because you",
    "start": "515399",
    "end": "522959"
  },
  {
    "text": "want the customer to upload which makes also more sense is because the the",
    "start": "522959",
    "end": "528560"
  },
  {
    "text": "decoding happening in the device and and if there's a bug in the client",
    "start": "528560",
    "end": "534120"
  },
  {
    "text": "application you want to detect that after the decoding so whatever so I have",
    "start": "534120",
    "end": "539519"
  },
  {
    "text": "no idea how much bandwidth that takes when it comes to the upload again guys I",
    "start": "539519",
    "end": "544800"
  },
  {
    "text": "might be way off here but again this article is not details enough so I have no idea like the from what I'm saying is",
    "start": "544800",
    "end": "552899"
  },
  {
    "text": "actually correct or not but yeah so these concur Cinemas are being monitored while onboarding more",
    "start": "552899",
    "end": "558480"
  },
  {
    "text": "streams of the service we notice they're running the infrastructure was high scale was very expensive so the the more",
    "start": "558480",
    "end": "564959"
  },
  {
    "text": "streams they start to onboard I suppose the more customers they're starting to monitor their experience that's my guess",
    "start": "564959",
    "end": "571620"
  },
  {
    "text": "at least that's where they saw the bottlenecks the initial version they did",
    "start": "571620",
    "end": "576779"
  },
  {
    "text": "was a service consisted of distributed components that were orchestrated by",
    "start": "576779",
    "end": "582120"
  },
  {
    "text": "step functions AWS step function which is I think this is their Lambda the two expensive operations were the",
    "start": "582120",
    "end": "587700"
  },
  {
    "text": "orchestration workflow and the data passed between and when the data pass",
    "start": "587700",
    "end": "593640"
  },
  {
    "text": "between distributor component because now you're having this decoded frames and you're passing around between",
    "start": "593640",
    "end": "599700"
  },
  {
    "text": "microservices of course it's going to be slow right to address this we moved all components to a single process",
    "start": "599700",
    "end": "607200"
  },
  {
    "text": "to keep the data transfer within the process memory right which also simplify",
    "start": "607200",
    "end": "612959"
  },
  {
    "text": "the orchestration logic because we compiled all operations into a single process so that's why they did they",
    "start": "612959",
    "end": "618600"
  },
  {
    "text": "moved everything from microservices down to a single process and once you do that",
    "start": "618600",
    "end": "624480"
  },
  {
    "text": "all the single process have is the Heap memory right so you can store these frames into the hip and",
    "start": "624480",
    "end": "632160"
  },
  {
    "text": "uh just access them doesn't get any faster right distribute",
    "start": "632160",
    "end": "637740"
  },
  {
    "start": "635000",
    "end": "1290000"
  },
  {
    "text": "to the system over it so here's where we're going to go into details once our service consists of three major",
    "start": "637740",
    "end": "643380"
  },
  {
    "text": "components three major components the media converter converts input audio video streams to",
    "start": "643380",
    "end": "652079"
  },
  {
    "text": "frames or decrypted audio buffers that are sent to detectors that's the",
    "start": "652079",
    "end": "658440"
  },
  {
    "text": "first thing media converter how the media converter got the data they don't explain but they're but they're but",
    "start": "658440",
    "end": "665820"
  },
  {
    "text": "their diagram does their diagram has this customer which is a very bad name",
    "start": "665820",
    "end": "672060"
  },
  {
    "text": "to to label something why did you call it it should be called the client application right",
    "start": "672060",
    "end": "678839"
  },
  {
    "text": "it's just to me the cost if you say customer I don't know it's not clear to me like",
    "start": "678839",
    "end": "685740"
  },
  {
    "text": "what is this you have to be the client app the Prime video Client app right I know it might be I might be like over",
    "start": "685740",
    "end": "694380"
  },
  {
    "text": "exaggerating here but but see do you see the narrow audio video stream where is the auto going arrows going from the",
    "start": "694380",
    "end": "700800"
  },
  {
    "text": "customer to the media conversion service like if you're watching something you're",
    "start": "700800",
    "end": "706800"
  },
  {
    "text": "gonna watch it from The Source down right so the the customer is actually",
    "start": "706800",
    "end": "712260"
  },
  {
    "text": "consuming this stream but here the customer is actually uploading something and that's where they something they",
    "start": "712260",
    "end": "718440"
  },
  {
    "text": "never mention here there is a monitoring concept here and I think the app itself have this feature where you can opt in",
    "start": "718440",
    "end": "725519"
  },
  {
    "text": "maybe in the app on any platform to monitor your stream",
    "start": "725519",
    "end": "731940"
  },
  {
    "text": "the quality of your stream and if that happens you the app will periodically",
    "start": "731940",
    "end": "737279"
  },
  {
    "text": "probably sample your stream and upload of course not gonna upload everything hope not right back to the media",
    "start": "737279",
    "end": "745079"
  },
  {
    "text": "conversion service that we just talked about this media conversion service will take that raw stream it's not really raw",
    "start": "745079",
    "end": "752579"
  },
  {
    "text": "it's the converted stream on your app it's as if it's whatever you saw and",
    "start": "752579",
    "end": "758100"
  },
  {
    "text": "again anything I say here is just my assumption because it's not it's not it's not stated in the article and so",
    "start": "758100",
    "end": "765360"
  },
  {
    "text": "anything I say here is just my assumption and I could be wrong so now the stream is received by the",
    "start": "765360",
    "end": "770639"
  },
  {
    "text": "Miss media service it's being converted into the frames and the audio decrypted audio buffers now what they said is like",
    "start": "770639",
    "end": "778440"
  },
  {
    "text": "now they are sent to the detectors how do they they are sent to the detectors",
    "start": "778440",
    "end": "784200"
  },
  {
    "text": "to send to the detectors they are actually writing it to an S3 bucket",
    "start": "784200",
    "end": "790519"
  },
  {
    "text": "why and the reason is because there's another process that the",
    "start": "790680",
    "end": "797519"
  },
  {
    "text": "customer effect essentially triggered to say okay start monitoring now there's",
    "start": "797519",
    "end": "803279"
  },
  {
    "text": "this arrow that is not labeled here but I think from the other from the other",
    "start": "803279",
    "end": "808380"
  },
  {
    "text": "diagram I kind of deduce is called start analysis I think that's what it is so the there is a thing that's called okay",
    "start": "808380",
    "end": "814500"
  },
  {
    "text": "start analysis which calls this Lambda function which then starts the conversion because when when you upload",
    "start": "814500",
    "end": "821459"
  },
  {
    "text": "when the customer uploads this it doesn't really start the conversion just",
    "start": "821459",
    "end": "826620"
  },
  {
    "text": "stores it locally apparently here and then this Arrow this explicit",
    "start": "826620",
    "end": "834000"
  },
  {
    "text": "Client app actually says okay now let's convert",
    "start": "834000",
    "end": "839420"
  },
  {
    "text": "I don't know why it's like that right now it's gonna convert this and then",
    "start": "840120",
    "end": "845700"
  },
  {
    "text": "we'll store it the moment to restore this this is not that's the orchestration okay now you go go ahead",
    "start": "845700",
    "end": "851639"
  },
  {
    "text": "and convert now let's wait oh did you did you convert like it has to be you the media conversion has to send back",
    "start": "851639",
    "end": "858600"
  },
  {
    "text": "something and it's not it's not in the diagram of course right so it's like okay I'm acknowledging I just did the",
    "start": "858600",
    "end": "865079"
  },
  {
    "text": "conversion maybe this is done asynchronously right once it's done the Lambda will now code the answers okay",
    "start": "865079",
    "end": "871740"
  },
  {
    "text": "hey detector go read from the S3 bucket uh whatever the media conversion wrote",
    "start": "871740",
    "end": "877800"
  },
  {
    "text": "those frames and these uh decrypted buffers the audio buffers and then run",
    "start": "877800",
    "end": "883560"
  },
  {
    "text": "your beautiful machine AI thingy right and let's just do the thing and once you",
    "start": "883560",
    "end": "889440"
  },
  {
    "text": "have the results go and write it to the notification service now who's gonna read the notification service probably",
    "start": "889440",
    "end": "894660"
  },
  {
    "text": "the customer but as a customer why do I care to see the that my f",
    "start": "894660",
    "end": "901160"
  },
  {
    "text": "my frame froze it's like I want you guys to fix it not like this so This",
    "start": "901160",
    "end": "907560"
  },
  {
    "text": "notifications like for for Amazon not for me as a customer so I don't I don't",
    "start": "907560",
    "end": "912839"
  },
  {
    "text": "understand why it's called Amazon isn't its customers real time notification topic I don't care if your frame froze",
    "start": "912839",
    "end": "919500"
  },
  {
    "text": "right I saw it freezing I know it's freezing so why would you tell me I don't know the whole thing is just I",
    "start": "919500",
    "end": "926760"
  },
  {
    "text": "don't know there is so much missing thing and maybe I'm missing one component that it will make everything",
    "start": "926760",
    "end": "932399"
  },
  {
    "text": "make sense but part of this doesn't of course there is another result",
    "start": "932399",
    "end": "937800"
  },
  {
    "text": "aggregation function that collects this user and write this aggregation to",
    "start": "937800",
    "end": "943980"
  },
  {
    "text": "another S3 bucket and if you want to learn more uh there's another article describing",
    "start": "943980",
    "end": "950220"
  },
  {
    "text": "this machine learning thing is right here so now they they talk about the problems we design our initials this uh",
    "start": "950220",
    "end": "956699"
  },
  {
    "text": "solution as a distributed system using serverless right and the whole thing is almost all of this serverless except",
    "start": "956699",
    "end": "963839"
  },
  {
    "text": "this media service conversion they didn't say what that is",
    "start": "963839",
    "end": "969180"
  },
  {
    "text": "however the way we use the some components causes to hit a hard scaling limit at five percent of the expected",
    "start": "969180",
    "end": "976079"
  },
  {
    "text": "load so you couldn't scale past that they just hit that",
    "start": "976079",
    "end": "981180"
  },
  {
    "text": "so of course there is a there is a bottleneck here right the main scaling bottleneck in this",
    "start": "981180",
    "end": "987899"
  },
  {
    "text": "architecture was the orchestration management that was implemented using AWS function because this this thing",
    "start": "987899",
    "end": "993899"
  },
  {
    "text": "like okay stock conversion and then customers trigger this and then now you go read this and now you do that and now",
    "start": "993899",
    "end": "1001279"
  },
  {
    "text": "you aggregate that's orchestration that's the expensive part because there's always a delay like when do you",
    "start": "1001279",
    "end": "1007459"
  },
  {
    "text": "know when to actually orchestrate like do you do asynchronously do do you have a timer do you do it asynchronously",
    "start": "1007459",
    "end": "1014240"
  },
  {
    "text": "it's just interesting our service performed multiple State transitions for every second of stream that I that I",
    "start": "1014240",
    "end": "1021800"
  },
  {
    "text": "didn't understand exactly what like what is the state transitions maybe it's an AWS thing that I don't know about so we",
    "start": "1021800",
    "end": "1029298"
  },
  {
    "text": "um we quickly reached our account limit beside that AWS function charges users",
    "start": "1029299",
    "end": "1035240"
  },
  {
    "text": "per state transitions it's like here's the third thing why are you",
    "start": "1035240",
    "end": "1041058"
  },
  {
    "text": "charging me for something you're responsible for with I don't know guys I still don't know",
    "start": "1041059",
    "end": "1048919"
  },
  {
    "text": "what the heck is this it's like what why would I care it's like it's like you're",
    "start": "1048919",
    "end": "1055160"
  },
  {
    "text": "responsible for Prime video not me why are you charging me for your serverless like charges user I think it's just the",
    "start": "1055160",
    "end": "1062360"
  },
  {
    "text": "way it's written is just it is it's it's weird it's just the way it's written",
    "start": "1062360",
    "end": "1068539"
  },
  {
    "text": "it's like it's like an engineer actually writing and and we're treating us like users you know it's not it's not written",
    "start": "1068539",
    "end": "1075080"
  },
  {
    "text": "as a as a product that makes sense it's written as an actual engineer",
    "start": "1075080",
    "end": "1080860"
  },
  {
    "text": "trying to explain the problem although their the engineering piece is actually",
    "start": "1080860",
    "end": "1086840"
  },
  {
    "text": "belong to them does that make sense the code the second course problem what we discovered was about the way we were",
    "start": "1086840",
    "end": "1095419"
  },
  {
    "text": "passing video frames images around the different components to reduce computationally expensive",
    "start": "1095419",
    "end": "1102080"
  },
  {
    "text": "video conversion jobs we built a micro server that splits videos into frame and",
    "start": "1102080",
    "end": "1107660"
  },
  {
    "text": "temporarily upload images to this S3 right that's the way they did and the reason is uh they don't they want to",
    "start": "1107660",
    "end": "1114799"
  },
  {
    "text": "reduce the conversion jobs so they they convert it once and then",
    "start": "1114799",
    "end": "1120160"
  },
  {
    "text": "distribute images and instead of having and that's that's this service the media",
    "start": "1120160",
    "end": "1126200"
  },
  {
    "text": "conversion instead of passing the audio stream directly to those because it's going to be expensive for the compute",
    "start": "1126200",
    "end": "1131960"
  },
  {
    "text": "unit to actually convert and analyze as opposed so that kind of makes sense I'm",
    "start": "1131960",
    "end": "1137780"
  },
  {
    "text": "with them on this it's a good idea to convert it it's not a good idea to put the output in an S3 bucket to my in my",
    "start": "1137780",
    "end": "1145820"
  },
  {
    "text": "opinion they could have at least instead of writing that to us it's three bucket",
    "start": "1145820",
    "end": "1152240"
  },
  {
    "text": "and then reading it it's like you're incurring the cost of a right you're in terms of cost of a network right",
    "start": "1152240",
    "end": "1158780"
  },
  {
    "text": "bandwidth because that's not the same machine right then you are incurring another cost to a ride and that's",
    "start": "1158780",
    "end": "1165200"
  },
  {
    "text": "another i o and then there is another cost of the network so why all this stuff and there is these are these",
    "start": "1165200",
    "end": "1172039"
  },
  {
    "text": "frames are all small they are huge right so even if you like have say this is HTTP and you can have HTTP 2 compression",
    "start": "1172039",
    "end": "1179840"
  },
  {
    "text": "right so gzip or whatever then then then then still these are really large thing",
    "start": "1179840",
    "end": "1186200"
  },
  {
    "text": "you're downloading and uploading and downloading uploading there so they have their limit even in this three",
    "start": "1186200",
    "end": "1191840"
  },
  {
    "text": "it's always like this is odd the way they're talking about this like they own the product but they're talking about S3",
    "start": "1191840",
    "end": "1198799"
  },
  {
    "text": "and Amazon as if it's something else does that make sense it's just odd I",
    "start": "1198799",
    "end": "1204380"
  },
  {
    "text": "know I know yeah so uh what what else what else so one thing just just look at this diagram",
    "start": "1204380",
    "end": "1211640"
  },
  {
    "text": "like forget about the monitors you could have eliminated this by just",
    "start": "1211640",
    "end": "1217280"
  },
  {
    "text": "having the media conversion talk directly to the S3 to the to the",
    "start": "1217280",
    "end": "1223100"
  },
  {
    "text": "detector like have a serverless function that takes the frames as an input so",
    "start": "1223100",
    "end": "1228919"
  },
  {
    "text": "have the media conversion once it's upload both immediately uh go ahead and",
    "start": "1228919",
    "end": "1234740"
  },
  {
    "text": "upload this way you can kill technically you can kill the starting version and",
    "start": "1234740",
    "end": "1239780"
  },
  {
    "text": "you can kill this orchestration altogether you don't need orchestration because once the video is uploaded the",
    "start": "1239780",
    "end": "1245780"
  },
  {
    "text": "media conversion will have the result and it will buffer it in memory and then once it",
    "start": "1245780",
    "end": "1251900"
  },
  {
    "text": "have it it will upload it to the to call this serverless",
    "start": "1251900",
    "end": "1257500"
  },
  {
    "text": "Lambda function as I say here's a frame go and detect them right and this will",
    "start": "1257500",
    "end": "1262580"
  },
  {
    "text": "just scale right because it's just a scalable function so this way you don't even need the S3 so I don't know why",
    "start": "1262580",
    "end": "1269120"
  },
  {
    "text": "they didn't do it this way for example that's just one way to do it I suppose it's always expensive to write to S3",
    "start": "1269120",
    "end": "1275419"
  },
  {
    "text": "right again I speak here now like an armchair",
    "start": "1275419",
    "end": "1280520"
  },
  {
    "text": "architect of course right but I I'm not in the in the midst of this there is so",
    "start": "1280520",
    "end": "1286160"
  },
  {
    "text": "much missing things here so you we have no idea what's behind this it could be a way more complex process that doesn't",
    "start": "1286160",
    "end": "1293960"
  },
  {
    "start": "1290000",
    "end": "1740000"
  },
  {
    "text": "allow what I just mentioned here but okay okay they said okay uh microservice",
    "start": "1293960",
    "end": "1299480"
  },
  {
    "text": "is bad uh just just Mom give me more or less please give me beautiful models so",
    "start": "1299480",
    "end": "1307159"
  },
  {
    "text": "whether it's okay to address the bottleneck they said all right let's fix everything let's put everything they",
    "start": "1307159",
    "end": "1312200"
  },
  {
    "text": "made the Bold decision to to re-architect what they did",
    "start": "1312200",
    "end": "1317419"
  },
  {
    "text": "they basically everything is the same right it's just they put everything in a single process",
    "start": "1317419",
    "end": "1323600"
  },
  {
    "text": "so they're still talking to this orchestration layer which I still think is unnecessary to be honest right but",
    "start": "1323600",
    "end": "1330380"
  },
  {
    "text": "they have this orchestration says okay now let's go ahead and start analysis but still see the user still uploads the",
    "start": "1330380",
    "end": "1336919"
  },
  {
    "text": "stream from their client app to this media converter like there's so there is an end point here that allows you to",
    "start": "1336919",
    "end": "1343220"
  },
  {
    "text": "upload stuff and this ECS task what's the difference between an ECS VM and an",
    "start": "1343220",
    "end": "1348980"
  },
  {
    "text": "ECS tags those two different thing I don't know maybe they are but that that",
    "start": "1348980",
    "end": "1354260"
  },
  {
    "text": "whole thing is just one beautiful process right and these are the components so",
    "start": "1354260",
    "end": "1362000"
  },
  {
    "text": "they put everything in the same thing so now when when you call start analysis it",
    "start": "1362000",
    "end": "1367580"
  },
  {
    "text": "will call start conversion and then it will convert everything that has been uploaded by the user so start conversion",
    "start": "1367580",
    "end": "1373760"
  },
  {
    "text": "and then upload the new buffers uploading it somewhere here new audio buffer why is it going back to the",
    "start": "1373760",
    "end": "1381200"
  },
  {
    "text": "orchestration I think that's oh I know so that what is the dotted",
    "start": "1381200",
    "end": "1387260"
  },
  {
    "text": "line I suppose the dotting line is the content",
    "start": "1387260",
    "end": "1392780"
  },
  {
    "text": "that's what I understand seems like and this solid lines are the response",
    "start": "1392780",
    "end": "1399200"
  },
  {
    "text": "and requests it's okay hey I have a new buffer see for example why you guys you didn't do this why is it not here",
    "start": "1399200",
    "end": "1406580"
  },
  {
    "text": "why is it not complete that is so slobby I'm sorry it's so",
    "start": "1406580",
    "end": "1412280"
  },
  {
    "text": "sloppy it's like yeah this is Amazon Tech we're talking about this Amazon you gotta",
    "start": "1412280",
    "end": "1418820"
  },
  {
    "text": "produce some good piece of content guys this is not acceptable right so yeah if you did then there's",
    "start": "1418820",
    "end": "1425419"
  },
  {
    "text": "like so I called it I saw it's like there must be something coming back here as an acknowledgment here they show it",
    "start": "1425419",
    "end": "1431600"
  },
  {
    "text": "right okay let's go now new audio video boom good and now the orchestration here",
    "start": "1431600",
    "end": "1438860"
  },
  {
    "text": "The Next Step kicks in says all right now let's analyze what we have but but what did the media conversion did they",
    "start": "1438860",
    "end": "1445340"
  },
  {
    "text": "also write in memory it wrote these frames and they decrypted audio in memory beautiful because in memory it's",
    "start": "1445340",
    "end": "1452179"
  },
  {
    "text": "a it's in this process Heap right so this is assuming this is just a single process",
    "start": "1452179",
    "end": "1457820"
  },
  {
    "text": "even it has it can be different process that's fine but then this instant memory",
    "start": "1457820",
    "end": "1463460"
  },
  {
    "text": "could be a shared memory pool right and then multiple processors can access that",
    "start": "1463460",
    "end": "1468500"
  },
  {
    "text": "that's fine it still is fast right so in that case the whether the detection is a",
    "start": "1468500",
    "end": "1475039"
  },
  {
    "text": "different process or not it doesn't matter it's still the whole thing is in the single machine so",
    "start": "1475039",
    "end": "1482360"
  },
  {
    "text": "we still have access to the memory direct hot memory access right and we don't care about persistent so if we",
    "start": "1482360",
    "end": "1488179"
  },
  {
    "text": "lose this if we crash who cares we don't care about durability right like this is",
    "start": "1488179",
    "end": "1493820"
  },
  {
    "text": "there this is not one of their goals to like okay oh I crashed sure we lose it",
    "start": "1493820",
    "end": "1499100"
  },
  {
    "text": "and that's fine I think right because it's fine to lose the work for it's a",
    "start": "1499100",
    "end": "1504740"
  },
  {
    "text": "monitoring service it's not like a serious thing that you need to persist right so that's fine if you do it in uh",
    "start": "1504740",
    "end": "1512659"
  },
  {
    "text": "generally so yeah we have this director one director two right and then detecting goes off and",
    "start": "1512659",
    "end": "1520400"
  },
  {
    "text": "then we write the detection results and then notify people and then still we're writing the aggregation",
    "start": "1520400",
    "end": "1527179"
  },
  {
    "text": "final output to ns3 bucket cool",
    "start": "1527179",
    "end": "1532299"
  },
  {
    "text": "so conceptually the high level architecture remain the same",
    "start": "1532340",
    "end": "1537380"
  },
  {
    "text": "they didn't change that's why they they wanted to keep the orchestration just because they do they want to",
    "start": "1537380",
    "end": "1543820"
  },
  {
    "text": "they don't want to change that code a lot because the orchestation is still there they just change the how the",
    "start": "1543820",
    "end": "1549980"
  },
  {
    "text": "orchestration is talking to each other by making it local calls effectively right and then uh so all the components",
    "start": "1549980",
    "end": "1558860"
  },
  {
    "text": "are still there the initial design we could scale several detectors horizontally right why because it's just",
    "start": "1558860",
    "end": "1565159"
  },
  {
    "text": "it's another serverless function right as each of them are in separate microservice right",
    "start": "1565159",
    "end": "1571159"
  },
  {
    "text": "and they can just spin up here they cannot right because well I can argue",
    "start": "1571159",
    "end": "1576860"
  },
  {
    "text": "that you still can if you do the detection as a different process you can",
    "start": "1576860",
    "end": "1581900"
  },
  {
    "text": "but the problems that you're limited by the compute power on that thing right",
    "start": "1581900",
    "end": "1587000"
  },
  {
    "text": "which is still I guess that's fine also all right like then they they the",
    "start": "1587000",
    "end": "1592700"
  },
  {
    "text": "problem is that now they that box is reaching its limit right let's say",
    "start": "1592700",
    "end": "1598820"
  },
  {
    "text": "you spin up even one or multiple products I think that's what they don't they're spending on multiple processes",
    "start": "1598820",
    "end": "1603980"
  },
  {
    "text": "which is each detector is a process or a thread whatever but then the",
    "start": "1603980",
    "end": "1610640"
  },
  {
    "text": "so yeah that's what they're doing right so so each detector I think is its own process that I wish they talked about",
    "start": "1610640",
    "end": "1615980"
  },
  {
    "text": "this I really I wish I wish I wish I wish these details are explained this this",
    "start": "1615980",
    "end": "1623900"
  },
  {
    "text": "block could have been great but it's just okay I'm sorry I'm sorry I'm sorry",
    "start": "1623900",
    "end": "1629419"
  },
  {
    "text": "it's like why don't you explain that oh we now every detector is now a process",
    "start": "1629419",
    "end": "1634880"
  },
  {
    "text": "or the video director is a thread why not why not okay whatever",
    "start": "1634880",
    "end": "1642080"
  },
  {
    "text": "okay I I apologize but sometimes like these things it hurts my heart because this is",
    "start": "1642080",
    "end": "1650179"
  },
  {
    "text": "a really good piece of work they put there but the block doesn't do it is Justice I think",
    "start": "1650179",
    "end": "1656360"
  },
  {
    "text": "it really doesn't do it as Justice I'm anyway in the initial this is we could scale",
    "start": "1656360",
    "end": "1662960"
  },
  {
    "text": "several detectors horizontally as each of them has said okay we talked about that so what did you guys do",
    "start": "1662960",
    "end": "1668840"
  },
  {
    "text": "um however in our approach the number of detectors only scale vertically because",
    "start": "1668840",
    "end": "1674120"
  },
  {
    "text": "they all run on the same instance vertically because that's just the same as I suppose these detectors are",
    "start": "1674120",
    "end": "1680840"
  },
  {
    "text": "processes in this case our team regular regularly add more detectors to the",
    "start": "1680840",
    "end": "1686059"
  },
  {
    "text": "service and we already exceeded the capacity of the single instance again they don't explain what the detectors is",
    "start": "1686059",
    "end": "1692120"
  },
  {
    "text": "I'm assuming it's a processes to overcome this problem we cloned the service multiple times parameterizing",
    "start": "1692120",
    "end": "1698419"
  },
  {
    "text": "each copy with a different subset of detectors so it's a very simple thing the whole ECS cluster now its own thing",
    "start": "1698419",
    "end": "1705440"
  },
  {
    "text": "so there is an escs machine with everything right I think so right at",
    "start": "1705440",
    "end": "1712520"
  },
  {
    "text": "least right part of the things has been cloned right as a group so it's still everything is",
    "start": "1712520",
    "end": "1719059"
  },
  {
    "text": "talking to each other it's just they added another layer on top uh to to orchestrate to for to load balance the",
    "start": "1719059",
    "end": "1726380"
  },
  {
    "text": "forward request to to forward the request so think of this box these",
    "start": "1726380",
    "end": "1732140"
  },
  {
    "text": "clusters is this whole thing right this is that that Orange Box everything now",
    "start": "1732140",
    "end": "1737600"
  },
  {
    "text": "become there and now if you you just horizontally scale that so now this here",
    "start": "1737600",
    "end": "1743179"
  },
  {
    "start": "1740000",
    "end": "1950000"
  },
  {
    "text": "is where microservices when in that particular case uh they they effectively",
    "start": "1743179",
    "end": "1749480"
  },
  {
    "text": "did macro Services if you will macro not micro macro Services just",
    "start": "1749480",
    "end": "1755419"
  },
  {
    "text": "grouped everything and that's the perfect solution for this right in that particular case because all of these",
    "start": "1755419",
    "end": "1761779"
  },
  {
    "text": "things that tightly talk to each other let's put them in one monolith all right that makes sense because these",
    "start": "1761779",
    "end": "1769520"
  },
  {
    "text": "guys talk to each other there's no point to separate them right if they are if they are very",
    "start": "1769520",
    "end": "1776899"
  },
  {
    "text": "coupled you need to put put them together or somehow destroy the coupling if you",
    "start": "1776899",
    "end": "1782240"
  },
  {
    "text": "can so there's a two detectors here there's three detectors in this case right and then uh they just you load",
    "start": "1782240",
    "end": "1789260"
  },
  {
    "text": "balance the whole thing okay before I forget and go go through the final piece uh I think",
    "start": "1789260",
    "end": "1796720"
  },
  {
    "text": "here's what I think will break in the future",
    "start": "1797419",
    "end": "1804620"
  },
  {
    "text": "currently there is only one consumer if you will for this converted frames and",
    "start": "1804620",
    "end": "1811520"
  },
  {
    "text": "these are the these detectors right uh I think if there's another set of",
    "start": "1811520",
    "end": "1818899"
  },
  {
    "text": "detectors that need to be added it's going to be interesting I don't",
    "start": "1818899",
    "end": "1824539"
  },
  {
    "text": "know how they're going to do that right the only place where this detector should live is in this big monolith",
    "start": "1824539",
    "end": "1833419"
  },
  {
    "text": "and that's the cost that they will have to incur right that's where Kafka and",
    "start": "1833419",
    "end": "1838460"
  },
  {
    "text": "and and other you know pop subsystems come in handy",
    "start": "1838460",
    "end": "1843980"
  },
  {
    "text": "right unfortunately that's that's what will happen in that particular case where",
    "start": "1843980",
    "end": "1850580"
  },
  {
    "text": "that media conversion if there will be more consumers for this",
    "start": "1850580",
    "end": "1857320"
  },
  {
    "text": "decrypted audio and these frame images other than the detector then",
    "start": "1857320",
    "end": "1865100"
  },
  {
    "text": "it will it will be interesting because they have to put these detectors this new detector types will have tests to be",
    "start": "1865100",
    "end": "1872960"
  },
  {
    "text": "left in this whole cluster and the only way to scale is to the scale the whole",
    "start": "1872960",
    "end": "1879260"
  },
  {
    "text": "old thing right although the media conversion doesn't need it to be scale",
    "start": "1879260",
    "end": "1884600"
  },
  {
    "text": "you had to scale it you had to incur the cost of putting it in a cluster putting",
    "start": "1884600",
    "end": "1891860"
  },
  {
    "text": "in that process that is the selling point of microservices in that particular case",
    "start": "1891860",
    "end": "1898419"
  },
  {
    "text": "where where see these these two components right what they did is like initially",
    "start": "1898419",
    "end": "1904640"
  },
  {
    "text": "that's what they thought about it's like a media conversion uh put in a its own Microsoft this thing put it in another",
    "start": "1904640",
    "end": "1910520"
  },
  {
    "text": "microservice but then if one scales more than the other let's say the media",
    "start": "1910520",
    "end": "1915679"
  },
  {
    "text": "conversion is not much right or I want to scale the media conversion service more versus the",
    "start": "1915679",
    "end": "1922460"
  },
  {
    "text": "detection service you don't get a choice you have to scale them both and that might be fine and",
    "start": "1922460",
    "end": "1928039"
  },
  {
    "text": "that might be fine it's just in the future if you want to add more uh it's gonna become interesting to see",
    "start": "1928039",
    "end": "1933679"
  },
  {
    "text": "like what will happen the only way is just to add another type of detector",
    "start": "1933679",
    "end": "1939860"
  },
  {
    "text": "in this instances so that's something I actually uh I'm interested in to think",
    "start": "1939860",
    "end": "1945200"
  },
  {
    "text": "more about results and take away microservices and serverless components are tools that do",
    "start": "1945200",
    "end": "1950779"
  },
  {
    "start": "1950000",
    "end": "2110000"
  },
  {
    "text": "work at high scale but whether to use them over month has to be made on a",
    "start": "1950779",
    "end": "1956240"
  },
  {
    "text": "case-by-case basis I have to agree with that statement 100 It's All Case by case basis all depends on what you're trying",
    "start": "1956240",
    "end": "1962179"
  },
  {
    "text": "to do moving at our services to our model to reduce our infrastructure cost by 90 percent",
    "start": "1962179",
    "end": "1967580"
  },
  {
    "text": "okay and that because uh everything is now simpler now there is no more these",
    "start": "1967580",
    "end": "1975080"
  },
  {
    "text": "uh the the S3s is was killing them to be honest right and the bandwidth",
    "start": "1975080",
    "end": "1981740"
  },
  {
    "text": "here and the and the orchestration cost right all of the thing is now a single",
    "start": "1981740",
    "end": "1989419"
  },
  {
    "text": "process or maybe a multiple processes right depends on what whatever that is",
    "start": "1989419",
    "end": "1994519"
  },
  {
    "text": "so it also increases our scaling capabilities today we're able to handle thousands of streams and we're still we",
    "start": "1994519",
    "end": "2002679"
  },
  {
    "text": "we still have capacity to scale the service even further moving the solution",
    "start": "2002679",
    "end": "2008620"
  },
  {
    "text": "to Amazon ec2 allows us to use the compute saving plans that will help",
    "start": "2008620",
    "end": "2015399"
  },
  {
    "text": "reduce costs down even further some decisions with uh we've taken are not obvious but they resulted in significant",
    "start": "2015399",
    "end": "2023620"
  },
  {
    "text": "improvements for example we've replicated a computationally expensive media conversion process and placed it",
    "start": "2023620",
    "end": "2030100"
  },
  {
    "text": "closer to the detectors whereas running media conversion once and caching it",
    "start": "2030100",
    "end": "2035940"
  },
  {
    "text": "outcome caching its outcome might be considered to be a cheaper option we",
    "start": "2035940",
    "end": "2041559"
  },
  {
    "text": "found that this is not cost effective because that's what I just said right it's very interesting because they they",
    "start": "2041559",
    "end": "2048040"
  },
  {
    "text": "rather recompute the because they were thinking about like let's let's make a media conversion and let's cache it but",
    "start": "2048040",
    "end": "2053800"
  },
  {
    "text": "apparently that didn't work for them it's just interesting that it's an interesting use case in indeed the",
    "start": "2053800",
    "end": "2059440"
  },
  {
    "text": "changes we've made allow Prime to monitor all streams viewed by our",
    "start": "2059440",
    "end": "2065500"
  },
  {
    "text": "customers not just the ones with the highest number of viewers this approach",
    "start": "2065500",
    "end": "2071618"
  },
  {
    "text": "results in even higher quality okay so that's interesting right so this actually proves that they're actually",
    "start": "2071619",
    "end": "2077138"
  },
  {
    "text": "monitoring the streams viewed by our customers",
    "start": "2077139",
    "end": "2083940"
  },
  {
    "text": "again that statement is still I'm not clear about right are we monitoring the",
    "start": "2084760",
    "end": "2089800"
  },
  {
    "text": "raw stream that is that is being produced or are we",
    "start": "2089800",
    "end": "2094839"
  },
  {
    "text": "monitoring how the stream is being consumed by the by the customer that that's that's a step that I'm not clear",
    "start": "2094839",
    "end": "2101320"
  },
  {
    "text": "about yet all right guys that's it for me today hope you enjoyed this video and what do you think about this let me know",
    "start": "2101320",
    "end": "2107140"
  },
  {
    "text": "in the comment section below see you in the next one goodbye",
    "start": "2107140",
    "end": "2111119"
  }
]
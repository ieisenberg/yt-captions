[
  {
    "start": "0",
    "end": "167000"
  },
  {
    "text": "okay welcome to uh ee 380 the stanford uh double the",
    "start": "11440",
    "end": "16480"
  },
  {
    "text": "computer systems colloquium uh for march uh uh",
    "start": "16480",
    "end": "22560"
  },
  {
    "text": "march 2nd 2022. um the speaker today is dave ditzel",
    "start": "22560",
    "end": "30240"
  },
  {
    "text": "from esperanto technologies and he's going to tell us about the new",
    "start": "30240",
    "end": "36320"
  },
  {
    "text": "machine that they have in progress with thousands of cores and performance",
    "start": "36320",
    "end": "42160"
  },
  {
    "text": "that's amazing um i think uh it should be very interesting",
    "start": "42160",
    "end": "47600"
  },
  {
    "text": "um in any case dave um i'm not going to tell anybody about you though i i will",
    "start": "47600",
    "end": "53039"
  },
  {
    "text": "say that you started out at bell labs uh made a number of machines",
    "start": "53039",
    "end": "59199"
  },
  {
    "text": "there went on to uh to berkeley uh made stuff there went to",
    "start": "59199",
    "end": "65600"
  },
  {
    "text": "sun made stuff there went to well on and on and on uh",
    "start": "65600",
    "end": "70720"
  },
  {
    "text": "someone i mentioned that they thought that you just seem to be making machines on a",
    "start": "70720",
    "end": "75840"
  },
  {
    "text": "great on a regular basis and it's going to be boring to hear about your new stuff i don't think so",
    "start": "75840",
    "end": "82720"
  },
  {
    "text": "i think i think it's the sixth talk i've given for the doubly 380 series for whatever incarnation it's been i went",
    "start": "82720",
    "end": "89119"
  },
  {
    "text": "back and counted just a little bit so 35 years of presenting the w380",
    "start": "89119",
    "end": "94320"
  },
  {
    "text": "i think i think it's it's marvelous but the fact is she was never going to bad talk so i'm looking forward to this",
    "start": "94320",
    "end": "102240"
  },
  {
    "text": "okay you're on great well uh thanks everybody i see a lot of familiar names here we're gonna",
    "start": "102240",
    "end": "107920"
  },
  {
    "text": "have some fun today i hope uh and that we'll be able to go into a little bit more depth and i can",
    "start": "107920",
    "end": "113200"
  },
  {
    "text": "typically do into a squeeze conference presentation here and i'm excited to tell you all about",
    "start": "113200",
    "end": "118799"
  },
  {
    "text": "esperanto's first main chip there's many more to come we're going to talk more about hardware",
    "start": "118799",
    "end": "125119"
  },
  {
    "text": "today than software accelerating ai is just a giant topic here",
    "start": "125119",
    "end": "130160"
  },
  {
    "text": "and you know for the software so we can just get some context i'm going to talk more about accelerating recommendation",
    "start": "130160",
    "end": "136400"
  },
  {
    "text": "because there's lots of kinds of things to accelerate machine learning",
    "start": "136400",
    "end": "142560"
  },
  {
    "text": "uh and we're gonna do that uh in a kind of interesting way rather than kind of a special purpose chip that's oriented",
    "start": "142560",
    "end": "148640"
  },
  {
    "text": "exactly towards machine learning we're gonna do it by accelerating uh programs with over a thousand risk five",
    "start": "148640",
    "end": "155280"
  },
  {
    "text": "processors on a chip and",
    "start": "155280",
    "end": "160480"
  },
  {
    "text": "with some special enhanced hardware and architecture so we'll go through that today we'll take some questions at the",
    "start": "160480",
    "end": "166239"
  },
  {
    "text": "end here so one of the interesting things is of all the chips being built today uh we",
    "start": "166239",
    "end": "172480"
  },
  {
    "start": "167000",
    "end": "403000"
  },
  {
    "text": "think we've got the world's highest performance risk 5 chip uh in in the sense of putting the most",
    "start": "172480",
    "end": "178800"
  },
  {
    "text": "risk five instructions per second on a single processor here we have over a thousand risk five processors on a",
    "start": "178800",
    "end": "185440"
  },
  {
    "text": "single seven nanometer chip and for those who who follow processors think about how many processor cores you have",
    "start": "185440",
    "end": "192080"
  },
  {
    "text": "in your in your notebook computer or pad or even in a server and it's a number a",
    "start": "192080",
    "end": "198000"
  },
  {
    "text": "lot smaller than a thousand typically maybe less than 30 or something than that today would be typical",
    "start": "198000",
    "end": "204239"
  },
  {
    "text": "of those we have actually three different processor types we have a 1088",
    "start": "204239",
    "end": "210080"
  },
  {
    "text": "and you'll see why that number comes about later of our energy efficient we call our et minion processors those are",
    "start": "210080",
    "end": "216400"
  },
  {
    "text": "full 64-bit wrist-5 processor cores uh they're fairly simple in-order cores",
    "start": "216400",
    "end": "222959"
  },
  {
    "text": "uh because we're going for energy efficiency with these cores and each of those has its own dedicated",
    "start": "222959",
    "end": "229040"
  },
  {
    "text": "vector tensor unit and i'll go through a lot of detail on those course today uh",
    "start": "229040",
    "end": "234159"
  },
  {
    "text": "in addition to those energy efficient cores there are times where we want to operate standalone and you'd like a very",
    "start": "234159",
    "end": "239840"
  },
  {
    "text": "fairly high performance uh single thread execution uh and so we have a processor",
    "start": "239840",
    "end": "245599"
  },
  {
    "text": "we've designed at esperanto called their maxion processor and and those are again full 64-bit risk five cores but using an",
    "start": "245599",
    "end": "252720"
  },
  {
    "text": "out-of-order pipeline i've only got one slide on that today but we'll go over it a little bit uh and",
    "start": "252720",
    "end": "258479"
  },
  {
    "text": "then there's one other core we have which is this a risc-v processor we use as a service processor which is a little",
    "start": "258479",
    "end": "264240"
  },
  {
    "text": "bit different but in addition to cores you you have to keep the course fed",
    "start": "264240",
    "end": "269360"
  },
  {
    "text": "and so um given how fast these cores are you want a lot of on-chip bandwidth we have",
    "start": "269360",
    "end": "274560"
  },
  {
    "text": "over 160 million bytes of on-chip sram we'll show you how we've architected",
    "start": "274560",
    "end": "279600"
  },
  {
    "text": "that uh this is a full system on chip as well and we have interfaces for large",
    "start": "279600",
    "end": "285280"
  },
  {
    "text": "external memory uh again because we're very power conscious we've used low power ddr4 xdram",
    "start": "285280",
    "end": "292479"
  },
  {
    "text": "we also have interfaces for flash because for certain kinds of machine learning storing stuff in flash turns",
    "start": "292479",
    "end": "298000"
  },
  {
    "text": "out to be very helpful uh we typically operate",
    "start": "298000",
    "end": "303759"
  },
  {
    "text": "in a mode where we're an accelerator to a host in a data center and to talk to that host cpu whether it be it uh",
    "start": "303759",
    "end": "310560"
  },
  {
    "text": "usually intel or amd we talked to it over eight lanes of pcie gen4",
    "start": "310560",
    "end": "317759"
  },
  {
    "text": "and you know when we put all this on a chip it allows a single chip to generate peak rates of 100 to 200 uh",
    "start": "318400",
    "end": "326240"
  },
  {
    "text": "terra ops per second now again the trick is not so much to get peak rates which is what everybody likes to quote but",
    "start": "326240",
    "end": "332240"
  },
  {
    "text": "it's how to get high sustainable rates of computation and that's what a lot of this talk will be about today",
    "start": "332240",
    "end": "338560"
  },
  {
    "text": "now you may have seen people put a lot of cores on a chip uh but typically when people try and cram a lot of cores on a",
    "start": "338560",
    "end": "345120"
  },
  {
    "text": "chip you know that chip might be uh two or three or even 400 watts i think",
    "start": "345120",
    "end": "350479"
  },
  {
    "text": "what's really interesting here is that we come from a background of low power techniques and we're able to do this",
    "start": "350479",
    "end": "357280"
  },
  {
    "text": "particularly for running machine learning recommendation where we expect to be able to operate the chip using",
    "start": "357280",
    "end": "362960"
  },
  {
    "text": "typically under 20 watts of power so that's one of the keys to what we're doing here now with a thousand risk five",
    "start": "362960",
    "end": "370080"
  },
  {
    "text": "processors on a chip you can do a lot of different things almost any workload that's parallelizable you could think",
    "start": "370080",
    "end": "376479"
  },
  {
    "text": "about distributing amongst these risk five cores but that again is a giant topic to talk",
    "start": "376479",
    "end": "382000"
  },
  {
    "text": "about what we could do here so today i'm really going to focus on machine learning recommendation and more",
    "start": "382000",
    "end": "387440"
  },
  {
    "text": "particularly inference with recommendation there and part of the reason we focused on that is one of the",
    "start": "387440",
    "end": "394560"
  },
  {
    "text": "the most important problems for a lot of hyperscale data center uh customers here in addition to being a fairly hard",
    "start": "394560",
    "end": "401120"
  },
  {
    "text": "problem in its own right so let's talk about how we deal with that so what's first of all what's challenging about",
    "start": "401120",
    "end": "406960"
  },
  {
    "start": "403000",
    "end": "780000"
  },
  {
    "text": "recommendation how is it maybe different than other kinds of of workloads and why go after data centers well data centers",
    "start": "406960",
    "end": "414000"
  },
  {
    "text": "is where people buy lots of chips and as a startup company you want to find customers who want to buy lots of chips",
    "start": "414000",
    "end": "420080"
  },
  {
    "text": "at once and rather than selling to you know ten thousand customers each of whom buy three chips",
    "start": "420080",
    "end": "427120"
  },
  {
    "text": "we thought it'd be a lot easier to start off with you know targeting just a small number of data center customers each of",
    "start": "427120",
    "end": "432720"
  },
  {
    "text": "whom could buy a large number of chips now a lot of these servers that are",
    "start": "432720",
    "end": "438800"
  },
  {
    "text": "running ml workloads that you all use today and recommendation just so you know is that when you're in a web",
    "start": "438800",
    "end": "445360"
  },
  {
    "text": "browser and you're visiting somebody's website you'll see advertising come up and recommendation is where they may",
    "start": "445360",
    "end": "451520"
  },
  {
    "text": "recommend you want to buy bicycles or red shoes or a certain shirt they're basing",
    "start": "451520",
    "end": "459120"
  },
  {
    "text": "that across your personal history and they will try and recommend particular",
    "start": "459120",
    "end": "464160"
  },
  {
    "text": "advertising to you so this is how they make a lot of money now uh a lot of this",
    "start": "464160",
    "end": "469680"
  },
  {
    "text": "workload today is run on just standard x86 processors and those servers tend to",
    "start": "469680",
    "end": "476479"
  },
  {
    "text": "have an empty slot a lot of the time in in in our case there was a particular",
    "start": "476479",
    "end": "481599"
  },
  {
    "text": "customer they had one empty slot available with each x86 cpu",
    "start": "481599",
    "end": "486800"
  },
  {
    "text": "but in order to serve as an accelerator chip we had to meet a couple key requirements",
    "start": "486800",
    "end": "492479"
  },
  {
    "text": "first of all you need to be faster than the host cpu that they already have right if you want to plug in an",
    "start": "492479",
    "end": "498319"
  },
  {
    "text": "accelerator to that existing system so that meant we needed to deliver on the order of a hundred",
    "start": "498319",
    "end": "503840"
  },
  {
    "text": "tera ops to a thousand tera ops peak rates in order to provide sufficiently",
    "start": "503840",
    "end": "509280"
  },
  {
    "text": "better performance than the x86 cpu already had they also had a limited power budget",
    "start": "509280",
    "end": "515440"
  },
  {
    "text": "in this particular case it was less than about 120 watts there are other pcie cards and other",
    "start": "515440",
    "end": "521440"
  },
  {
    "text": "systems that have 75 watts and in particular when you have",
    "start": "521440",
    "end": "528000"
  },
  {
    "text": "thousands of these servers and data centers i think one of the more interesting lessons is that they really",
    "start": "528000",
    "end": "533839"
  },
  {
    "text": "wanted these to be air-cooled and there's a little you'll see a little uh kind of a footnote here to a",
    "start": "533839",
    "end": "539839"
  },
  {
    "text": "reference for a paper this is to uh a google paper that talks about how they had mistakenly tried to do water cooling",
    "start": "539839",
    "end": "547519"
  },
  {
    "text": "in their inference and really regretted it later and so those references all be available at the end of the presentation",
    "start": "547519",
    "end": "553600"
  },
  {
    "text": "we can go over those i'll try and reference those um and again in looking for data types",
    "start": "553600",
    "end": "559279"
  },
  {
    "text": "people have done all kinds of clever things you know you know five-bit integers or specialized",
    "start": "559279",
    "end": "565920"
  },
  {
    "text": "floating point format but really we had a lot of feedback when we interviewed the our potential customers they said",
    "start": "565920",
    "end": "571920"
  },
  {
    "text": "look just just focus on three data types in eight uh which is really great fp16 and fb32",
    "start": "571920",
    "end": "580480"
  },
  {
    "text": "if you invent some other specialized data type realize you are not the only company who's going to be selling chips",
    "start": "580480",
    "end": "586240"
  },
  {
    "text": "to us to accelerate machine learning this is going to be a heterogeneous environment we have to live with intel",
    "start": "586240",
    "end": "591360"
  },
  {
    "text": "amd nvidia various other people we're not going to be transcoding data between",
    "start": "591360",
    "end": "596880"
  },
  {
    "text": "one or the other just because you have some fancy data type he said look spend all your effort there",
    "start": "596880",
    "end": "602720"
  },
  {
    "text": "don't waste any logic gates on doing anything else because you'll just be wasting power for something we're not",
    "start": "602720",
    "end": "609040"
  },
  {
    "text": "likely to use and that's pretty consistent there's a second paper i reference here from facebook which says pretty much the the same thing",
    "start": "609040",
    "end": "616720"
  },
  {
    "text": "how much memory capacity uh the customer said look um you need to hold on the accelerator card",
    "start": "616720",
    "end": "623279"
  },
  {
    "text": "on the order of 100 gigabytes if you do that for most of the inference work we do you can hold what we need on the",
    "start": "623279",
    "end": "629920"
  },
  {
    "text": "accelerator card at least the most important part for holding embeddings weights and",
    "start": "629920",
    "end": "634959"
  },
  {
    "text": "activations and that's good but you can't fit 100",
    "start": "634959",
    "end": "640399"
  },
  {
    "text": "gigabytes on a chip per se and so you can while you put that on the board it's still important to",
    "start": "640399",
    "end": "646079"
  },
  {
    "text": "have memory on die because that can still be very frequently used and have much higher bandwidth and they",
    "start": "646079",
    "end": "652000"
  },
  {
    "text": "recommended about 100 megabytes and in fact at the beginning when we went out with a proposal from esperanto we were",
    "start": "652000",
    "end": "657680"
  },
  {
    "text": "proposing i think graphcore had 256 megabytes we said oh that's a good idea",
    "start": "657680",
    "end": "662720"
  },
  {
    "text": "and we got pretty consistent advice saying hey don't waste more than about 100 megabytes with online memory if it",
    "start": "662720",
    "end": "668959"
  },
  {
    "text": "doesn't fit in 100 it's not going to fit in 256. so that's why we went with just a little",
    "start": "668959",
    "end": "674720"
  },
  {
    "text": "over 100 megabytes it was very important to handle both dense and sparse workloads",
    "start": "674720",
    "end": "682160"
  },
  {
    "text": "so dense workloads you might imagine all the data fits in a little cache and you can compute all the time but a lot of",
    "start": "682160",
    "end": "688160"
  },
  {
    "text": "these things are fetching data that's kind of random in memory uh and embedding in particular is a lookup of",
    "start": "688160",
    "end": "695200"
  },
  {
    "text": "you know a sparse matrix by dense matrix multiplication here so you have to be able to randomly access this hundred",
    "start": "695200",
    "end": "701760"
  },
  {
    "text": "gigabytes and do pretty well with that it's very easy to build very high performance machine learning uh and have",
    "start": "701760",
    "end": "709519"
  },
  {
    "text": "very impressive you know terra ops per watt if you can keep everything on die",
    "start": "709519",
    "end": "715519"
  },
  {
    "text": "but again for the applications we were going after uh these large commercial applications they said look that just",
    "start": "715519",
    "end": "721440"
  },
  {
    "text": "that just isn't possible you've got a reference 100 gigabyte so how do you deal with these sparse",
    "start": "721440",
    "end": "726560"
  },
  {
    "text": "workloads and in particular they were really looking for a programmability there was a lot of view that a lot of",
    "start": "726560",
    "end": "732880"
  },
  {
    "text": "the hardware they had seen was what they tended to call overly specialized hardware okay that's really great",
    "start": "732880",
    "end": "738720"
  },
  {
    "text": "you build hardware that does the inner loop of resin at 50 but you know nobody really runs resnet50 as an actual",
    "start": "738720",
    "end": "745279"
  },
  {
    "text": "workload uh the workloads are changing all the time and they were really looking for more programmability so if",
    "start": "745279",
    "end": "752639"
  },
  {
    "text": "there's anything to come out of this talk that i'd like you to uh to think about uh it's um you know can you you",
    "start": "752639",
    "end": "760560"
  },
  {
    "text": "compete in doing machine learning acceleration with a general purpose processor or do you really need",
    "start": "760560",
    "end": "767279"
  },
  {
    "text": "specialized hardware to do it and one of the challenges esperanto took on is to prove that you could in fact use general",
    "start": "767279",
    "end": "773600"
  },
  {
    "text": "purpose hardware if you had the right kind of general purpose hardware and you built it to be very energy efficient",
    "start": "773600",
    "end": "780480"
  },
  {
    "start": "780000",
    "end": "1064000"
  },
  {
    "text": "so we'll visit that at the end so let me see if i can contrast esperanto's approach versus",
    "start": "780480",
    "end": "787279"
  },
  {
    "text": "there's so many different ai accelerator chips so let me over generalize a little bit here to the ones that tend to be",
    "start": "787279",
    "end": "792800"
  },
  {
    "text": "closer to our space but we see a lot of approaches that build what i call the",
    "start": "792800",
    "end": "797920"
  },
  {
    "text": "one giant hot chip right and on that they'll tend to put a lot of array",
    "start": "797920",
    "end": "803200"
  },
  {
    "text": "multipliers whether they're systolic array multipliers or some other kind that tends to",
    "start": "803200",
    "end": "808720"
  },
  {
    "text": "be very effective and then they'll put maybe 10 to 20 more general purpose cpu",
    "start": "808720",
    "end": "813920"
  },
  {
    "text": "cores there and then connected up over a very high speed interface uh i mean",
    "start": "813920",
    "end": "820639"
  },
  {
    "text": "something like hbi memory because you have a limited number of pins to uh to",
    "start": "820639",
    "end": "825920"
  },
  {
    "text": "talk to the dram and so you use all your power budget there and you'll see a lot of three or four hundred watt chips uh",
    "start": "825920",
    "end": "832720"
  },
  {
    "text": "or things that are even hotter than that so our approach was a little bit different rather than building the",
    "start": "832720",
    "end": "837839"
  },
  {
    "text": "largest chip we built a moderate size chip and use multiple of those chips that",
    "start": "837839",
    "end": "843760"
  },
  {
    "text": "still try to fit within the same power budget so why do we do that well if you",
    "start": "843760",
    "end": "849040"
  },
  {
    "text": "have just one chip with one package you have a limited number of i o pins you have a limited amount of memory and a",
    "start": "849040",
    "end": "855360"
  },
  {
    "text": "limited amount of memory bandwidth so if you use multiple chips",
    "start": "855360",
    "end": "861440"
  },
  {
    "text": "your performance the number of pins you have the amount of memory and the bandwidth will all scale up with the",
    "start": "861680",
    "end": "867440"
  },
  {
    "text": "number of chips if you use array multipliers yeah that",
    "start": "867440",
    "end": "873199"
  },
  {
    "text": "can give you a great resonate 50 score but it's not really very good with large sparse memory and you'll find as you go",
    "start": "873199",
    "end": "879680"
  },
  {
    "text": "through multiple layers that the matrix stops being a nice square shape which",
    "start": "879680",
    "end": "885360"
  },
  {
    "text": "fits on an array multiplier but maybe your data will get tall and thin and it doesn't fit so well on the array",
    "start": "885360",
    "end": "890560"
  },
  {
    "text": "multiplier again on by contrast by using thousands of general purpose risk 5",
    "start": "890560",
    "end": "897680"
  },
  {
    "text": "cores with tensor accelerators we ended up with the far more programmable solution",
    "start": "897680",
    "end": "902800"
  },
  {
    "text": "and to deal with the large memory latency when going to that 100 gigabytes we used",
    "start": "902800",
    "end": "908880"
  },
  {
    "text": "a similar technique to what a lot of the gpus use thousands of threads help with",
    "start": "908880",
    "end": "914000"
  },
  {
    "text": "that large sparse memory latency if you have a case where you only have",
    "start": "914000",
    "end": "919600"
  },
  {
    "text": "10 to 20 general purpose cores that really limits the amount of total parallelism you have so anytime your",
    "start": "919600",
    "end": "925839"
  },
  {
    "text": "problem doesn't fit perfectly onto that array multiplier you can only fall back to say a parallelism of 10 cores in",
    "start": "925839",
    "end": "933279"
  },
  {
    "text": "parallel whereas with the esperanto approach we have the full parallelism of thousands of cores always available so",
    "start": "933279",
    "end": "941360"
  },
  {
    "text": "so long as your program is parallelizable and most ai programs are you can get take advantage of that full",
    "start": "941360",
    "end": "947440"
  },
  {
    "text": "parallelism and then you know in terms of physical implementation and circuit techniques uh",
    "start": "947440",
    "end": "953360"
  },
  {
    "text": "most everybody else tend to operate their chips at standard voltages and as i'll show you uh coming up we believe",
    "start": "953360",
    "end": "960399"
  },
  {
    "text": "that was not the most energy efficient place to operate uh instead what we do at esperanto is we operate the power",
    "start": "960399",
    "end": "967680"
  },
  {
    "text": "hungry portions of the chip at very low relative voltages and that's",
    "start": "967680",
    "end": "973680"
  },
  {
    "text": "because when you operate transistors at much lower voltages they actually are more energy efficient",
    "start": "973680",
    "end": "979759"
  },
  {
    "text": "think of my analogy often uses you know a car going down the highway yeah you can have a car that goes 100 miles per hour but",
    "start": "979759",
    "end": "987360"
  },
  {
    "text": "you're probably using your gasoline more efficiently if you drive at 30 miles per hour same kind of thing happens with",
    "start": "987360",
    "end": "993120"
  },
  {
    "text": "transistors you know most of the semiconductor fabs you know put a a",
    "start": "993120",
    "end": "998320"
  },
  {
    "text": "nominal standard voltage for a chip that gives the best performance but that's not always the most energy efficient",
    "start": "998320",
    "end": "1004639"
  },
  {
    "text": "place but why doesn't everybody operate at a lower voltage then well it turns out you that's not so easy uh while",
    "start": "1004639",
    "end": "1012320"
  },
  {
    "text": "lower voltage operation reduces power you've got to have specialized circuit techniques and we actually change the",
    "start": "1012320",
    "end": "1019600"
  },
  {
    "text": "actual architecture of the cpu so that it would better match what happens at",
    "start": "1019600",
    "end": "1025918"
  },
  {
    "text": "low voltage in fact a number of the accelerators out there use approaches that just aren't amenable to low power",
    "start": "1025919",
    "end": "1031918"
  },
  {
    "text": "for example they put fairly large uh caches or memory uh at the first",
    "start": "1031919",
    "end": "1037280"
  },
  {
    "text": "level and you just can't scale those down and voltage very well so given this particular approach we",
    "start": "1037280",
    "end": "1043600"
  },
  {
    "text": "were going after a certain set of customers that said look how much performance can",
    "start": "1043600",
    "end": "1049280"
  },
  {
    "text": "you put on a single accelerator card with 120 watt limit and i'm going to use",
    "start": "1049280",
    "end": "1054480"
  },
  {
    "text": "that as an example today uh to show you how how our particular solution approaches that particular problem",
    "start": "1054480",
    "end": "1061200"
  },
  {
    "text": "although it can be used for other other problems as well so if you're gonna we had a physical",
    "start": "1061200",
    "end": "1066960"
  },
  {
    "start": "1064000",
    "end": "1275000"
  },
  {
    "text": "limitation with one card we could only mount six chips and all the dram and power supplies everything else",
    "start": "1066960",
    "end": "1073919"
  },
  {
    "text": "on a card so we start off with that constraint so therefore if you take your 120 watts available divide by six it",
    "start": "1073919",
    "end": "1080720"
  },
  {
    "text": "means each chip complex has to take less than 20 watts",
    "start": "1080720",
    "end": "1085840"
  },
  {
    "text": "so for purposes of this example you know we assume that about half of the 20 watt",
    "start": "1085840",
    "end": "1090880"
  },
  {
    "text": "power we have available would be available for a thousand cores because we don't get all that 20 watts for our",
    "start": "1090880",
    "end": "1096799"
  },
  {
    "text": "thousand floors we only got half of that so that only leaves you about 10 milliwatts per core",
    "start": "1096799",
    "end": "1102880"
  },
  {
    "text": "so let's compare that and see how much of a challenge this kind of a problem is now here's what we typically call the",
    "start": "1102880",
    "end": "1109120"
  },
  {
    "text": "iron rule of power here your power is cb squared f plus leakage here and",
    "start": "1109120",
    "end": "1115600"
  },
  {
    "text": "the c there is the dynamic switching capacitance it's the capacitance that inherently a wire has or it's the",
    "start": "1115600",
    "end": "1122799"
  },
  {
    "text": "capacitance you get by touching typically most capacitors is the gate of a transistor although there's a little",
    "start": "1122799",
    "end": "1128960"
  },
  {
    "text": "bit from uh touching the grain or source of a transistor as well the voltage that's just the normal",
    "start": "1128960",
    "end": "1134480"
  },
  {
    "text": "supply voltage but that's times the voltage squared uh and times the say the",
    "start": "1134480",
    "end": "1139760"
  },
  {
    "text": "frequency in megahertz plus leakage and the leakage it will depend a little on how you want to operate but uh you know",
    "start": "1139760",
    "end": "1147120"
  },
  {
    "text": "typically on a modern processor that will be maybe 30 to 40 most of the time here",
    "start": "1147120",
    "end": "1152799"
  },
  {
    "text": "so let's take a look at how hard a problem this is by looking at say a generic x86 server cpu you might be",
    "start": "1152799",
    "end": "1158960"
  },
  {
    "text": "familiar with so we just went to a typical part and looked at the data sheet and that was 165 watts",
    "start": "1158960",
    "end": "1166480"
  },
  {
    "text": "and they were able to support 24 x86 cores so what that means is you have about",
    "start": "1166480",
    "end": "1172320"
  },
  {
    "text": "seven watts per core and if you're running it three gigahertz uh and voltage we guessed there they",
    "start": "1172320",
    "end": "1179360"
  },
  {
    "text": "vary a little bit about .85 volts and you can just back engineer and say well that means the switching capacitance",
    "start": "1179360",
    "end": "1185440"
  },
  {
    "text": "would be 2.2 nanofarads so what was our challenge well we needed",
    "start": "1185440",
    "end": "1190480"
  },
  {
    "text": "to operate with 10 milliwatts per core we wanted to run about one gigahertz",
    "start": "1190480",
    "end": "1196320"
  },
  {
    "text": "we can improve energy efficiency by operating at roughly half of that voltage",
    "start": "1196320",
    "end": "1202240"
  },
  {
    "text": "and what that meant is our switching capacitance could only be 0.04 nanofarads per core",
    "start": "1202240",
    "end": "1208960"
  },
  {
    "text": "so that meant we had in order to hit our goals here to use a general purpose processor we needed a solution that",
    "start": "1208960",
    "end": "1215360"
  },
  {
    "text": "could be 700 times better than the traditional x86 cpu you might be",
    "start": "1215360",
    "end": "1220559"
  },
  {
    "text": "familiar with now by operating at a lower frequency the power consumed is linear with frequency",
    "start": "1220559",
    "end": "1227039"
  },
  {
    "text": "so we could pick up a factor of three there we pick up a factor of four by operating at half the voltage but powers related",
    "start": "1227039",
    "end": "1233520"
  },
  {
    "text": "to the voltage square but what that meant is that the bulk of the problem of how to fit into the power",
    "start": "1233520",
    "end": "1239919"
  },
  {
    "text": "envelope had to come from reducing the dynamic switching capacitance by almost a factor of 60.",
    "start": "1239919",
    "end": "1246159"
  },
  {
    "text": "okay so reducing the frequency was pretty easy reducing the voltage that's a lot",
    "start": "1246159",
    "end": "1251440"
  },
  {
    "text": "more work because you have to use specialized design techniques and particularly how you deal with both the",
    "start": "1251440",
    "end": "1256640"
  },
  {
    "text": "circuits that burn power and your storage uh if you want s-rams that operate at",
    "start": "1256640",
    "end": "1262080"
  },
  {
    "text": "this low voltage those are very special design technique um and the hardest part",
    "start": "1262080",
    "end": "1267600"
  },
  {
    "text": "here again was reducing the dynamic switching capacitance and that really has has to do with",
    "start": "1267600",
    "end": "1273440"
  },
  {
    "text": "getting a just a simple design now let's let's go talk about energy efficiency for a second here so we've got this 120",
    "start": "1273440",
    "end": "1280640"
  },
  {
    "start": "1275000",
    "end": "1464000"
  },
  {
    "text": "watt problem here uh what could we do um um so on the the y-axis here i've got the",
    "start": "1280640",
    "end": "1288559"
  },
  {
    "text": "kind of the energy efficiency in terms of in in inferences per second per watt and if we",
    "start": "1288559",
    "end": "1294400"
  },
  {
    "text": "simply took our our risk 5 000 cpus and we we stuck our",
    "start": "1294400",
    "end": "1300000"
  },
  {
    "text": "simplified design and ran it to say the typically way a graphics vendor might do which is you",
    "start": "1300000",
    "end": "1305919"
  },
  {
    "text": "over voltage a little bit if we ran them at 0.9 volts in seven nanometer",
    "start": "1305919",
    "end": "1311600"
  },
  {
    "text": "the chip that i'm going to talk to you about today would have taken about uh 275 watts so clearly over the power",
    "start": "1311600",
    "end": "1318640"
  },
  {
    "text": "budget if we reduce the voltage to the nominal voltage in seven nanometer 0.75 watts you can see it still doesn't fit",
    "start": "1318640",
    "end": "1325679"
  },
  {
    "text": "not one single chip that is too much we can start reducing the voltage until we just",
    "start": "1325679",
    "end": "1332000"
  },
  {
    "text": "barely fit and that would have been about 0.65 volts and you can see we're",
    "start": "1332000",
    "end": "1337039"
  },
  {
    "text": "operating a little more energy efficiency there there but if you operate at the most energy",
    "start": "1337039",
    "end": "1342159"
  },
  {
    "text": "efficient point four seven nanometer transistors from tsmc",
    "start": "1342159",
    "end": "1347600"
  },
  {
    "text": "they you get your peak energy efficiency when operating between 300 and maybe 350",
    "start": "1347600",
    "end": "1353520"
  },
  {
    "text": "millivolts and that entire chip with a thousand processors would then only take about",
    "start": "1353520",
    "end": "1359440"
  },
  {
    "text": "eight and a half watts so that when you multiply by six would in fact have fit within the power budget",
    "start": "1359440",
    "end": "1366559"
  },
  {
    "text": "and in fact that would have been 20 times more energy efficient by operating at that low voltage point rather than",
    "start": "1366559",
    "end": "1373600"
  },
  {
    "text": "the high voltage point for the machine learning recommendation benchmark that we're that we're using",
    "start": "1373600",
    "end": "1380960"
  },
  {
    "text": "now notice also that it's two and a half times more performance by using those six chips rather than",
    "start": "1380960",
    "end": "1387679"
  },
  {
    "text": "using one very hot chip and so that sounds pretty good however we're not",
    "start": "1387679",
    "end": "1393360"
  },
  {
    "text": "using up the full 120 watt limit and so for the server power guys they say look don't exceed this number",
    "start": "1393360",
    "end": "1399840"
  },
  {
    "text": "but certainly go ahead and use up the full power budget and so if we use 20 watts per chip",
    "start": "1399840",
    "end": "1405600"
  },
  {
    "text": "we'd end up actually having four times more performance than the single chip performance would have been",
    "start": "1405600",
    "end": "1412240"
  },
  {
    "text": "um and and been still a pretty good energy efficiency here",
    "start": "1412240",
    "end": "1417919"
  },
  {
    "text": "so this is why for esperanto we kind of targeted our sweet spot to be around 0.4",
    "start": "1417919",
    "end": "1423600"
  },
  {
    "text": "volts and again our chip is capable of operating at a variety of operating points anywhere we're just we're",
    "start": "1423600",
    "end": "1430799"
  },
  {
    "text": "we believe will be robust all the way down to about 0.3 volts but you might want to operate as much as maybe a 0.5",
    "start": "1430799",
    "end": "1436720"
  },
  {
    "text": "volts but again you're going down the energy efficiency point there are some customers that really care about energy",
    "start": "1436720",
    "end": "1443279"
  },
  {
    "text": "efficiency as i said the primary customer going after is the one that simply wants the most inferences per",
    "start": "1443279",
    "end": "1449279"
  },
  {
    "text": "second that fit in that power limit of 120 watts but there'll be other customers simply say hey i don't",
    "start": "1449279",
    "end": "1455440"
  },
  {
    "text": "care what the power is put on the biggest heat sink run it up at 300 watts and so we could choose to do that as",
    "start": "1455440",
    "end": "1461760"
  },
  {
    "text": "well with our part so uh how did we build the simplest",
    "start": "1461760",
    "end": "1467200"
  },
  {
    "text": "possible risk 5 to get that switching capacitance down so that's what we call our et minion part um it's a custom",
    "start": "1467200",
    "end": "1475440"
  },
  {
    "text": "64-bit risk 5 processor again in order pipelines tend to be more energy efficient",
    "start": "1475440",
    "end": "1482799"
  },
  {
    "text": "but to run with a decent speed at low voltage we had to work very hard to reduce the number of gates per clock so",
    "start": "1482799",
    "end": "1489600"
  },
  {
    "text": "we could still get to roughly that gigahertz level at roughly that 0.4 volt",
    "start": "1489600",
    "end": "1495360"
  },
  {
    "text": "of operation so we did a lot of",
    "start": "1495360",
    "end": "1500720"
  },
  {
    "text": "of cross optimization across the design domains between architecture",
    "start": "1500720",
    "end": "1506559"
  },
  {
    "text": "and circuits and physical design in order to enable this low voltage operation",
    "start": "1506559",
    "end": "1512080"
  },
  {
    "text": "the the cpu implements the full risk 5 integer 64-bit instruction set uh",
    "start": "1512080",
    "end": "1518480"
  },
  {
    "text": "including compressed instructions uh we have two hardware threads of execution",
    "start": "1518480",
    "end": "1523760"
  },
  {
    "text": "uh and one of the tricks we've done is we've made our level one data cache be able to operate as a scratch pad as well",
    "start": "1523760",
    "end": "1531360"
  },
  {
    "text": "as a data cache and i'll explain how we utilize that in the future",
    "start": "1531360",
    "end": "1536559"
  },
  {
    "text": "you can see on the right hand side here roughly to scale how much area each of the particular",
    "start": "1536559",
    "end": "1543120"
  },
  {
    "text": "units take and again the common wisdom is oh if you use the general purpose instruction set",
    "start": "1543120",
    "end": "1548960"
  },
  {
    "text": "that would take too much area you couldn't use that but what you see is in yellow where the integer pipeline is",
    "start": "1548960",
    "end": "1554960"
  },
  {
    "text": "that's really not a very large part of the total area of one individual processor",
    "start": "1554960",
    "end": "1562720"
  },
  {
    "text": "most of the areas taken up by the vector and tensor unit and in fact the hardest thing in that",
    "start": "1562720",
    "end": "1568400"
  },
  {
    "text": "vector tensor unit are the 32-bit and 16-bit floating point multiply and accumulates you can see in purple here",
    "start": "1568400",
    "end": "1575039"
  },
  {
    "text": "there's a unit here called the tema that's the tensor integer multiply and accumulate and again integers much",
    "start": "1575039",
    "end": "1581120"
  },
  {
    "text": "simpler to do you'll see a lot of acceleration chips that just do integer only because floating point is is fairly",
    "start": "1581120",
    "end": "1587039"
  },
  {
    "text": "hard here uh and on the vpu register file we support both threads",
    "start": "1587039",
    "end": "1592240"
  },
  {
    "text": "something that's a little bit unusual one of the extensions we did is we actually do support certain transient",
    "start": "1592240",
    "end": "1597279"
  },
  {
    "text": "instructions because that was important for machine learning so we can do vector transcendentals as well",
    "start": "1597279",
    "end": "1603600"
  },
  {
    "text": "the floating point operates 5 12 bits wide for the integer side but a little bit unusual as we operate",
    "start": "1603600",
    "end": "1610480"
  },
  {
    "text": "only 256 bits wide for the floating point and that's because the customer directly requested kind of a ratio of",
    "start": "1610480",
    "end": "1617600"
  },
  {
    "text": "float to int here and so that ended up with a slightly unusual design uh here where you have a",
    "start": "1617600",
    "end": "1624240"
  },
  {
    "text": "lot more processing event we can do 128 8-bit integer operations per cycle",
    "start": "1624240",
    "end": "1631200"
  },
  {
    "text": "in the vector unit and those 8-bit ops accumulate to 32-bit integers for floating point",
    "start": "1631200",
    "end": "1638159"
  },
  {
    "text": "we operate 256 bits wide per cycle and you can use either 32-bit uh double",
    "start": "1638159",
    "end": "1644080"
  },
  {
    "text": "single precision or 16-bit half-precision operations you get twice as many uh",
    "start": "1644080",
    "end": "1650960"
  },
  {
    "text": "half precision operations per cycle and then you can you'll be accumulating those uh",
    "start": "1650960",
    "end": "1656399"
  },
  {
    "text": "for the half precision you can accumulate either in half precision or into a 32-bit single position per cycle",
    "start": "1656399",
    "end": "1663840"
  },
  {
    "text": "uh one of the things that's a little bit different in the extension we've done as well is we've added multi-cycle tensor",
    "start": "1663840",
    "end": "1669679"
  },
  {
    "text": "instructions so a tensor is when you're multiplying say a matrix times another matrix here",
    "start": "1669679",
    "end": "1676159"
  },
  {
    "text": "and that occurs very frequently in machine learning so what we can do is operate at the full width of 512 bits",
    "start": "1676159",
    "end": "1684080"
  },
  {
    "text": "and we can run for up to 512 cycles with one of these tensor instructions so",
    "start": "1684080",
    "end": "1689679"
  },
  {
    "text": "you might do as many as 32 000",
    "start": "1689679",
    "end": "1694480"
  },
  {
    "text": "arithmetic operations with one single tensor instruction well why did we do that well it reduces",
    "start": "1694799",
    "end": "1701679"
  },
  {
    "text": "the instruction fetch bandwidth tremendously and that also helps reduce power so when you think of multiplying",
    "start": "1701679",
    "end": "1709039"
  },
  {
    "text": "you know two matrices by each other rather than it being in a general purpose program loop that might take a",
    "start": "1709039",
    "end": "1715360"
  },
  {
    "text": "lot of power fetching instructions running the integer pipeline we have a very tiny finite state machine that",
    "start": "1715360",
    "end": "1722000"
  },
  {
    "text": "operates the tensor and we actually put the risk 5 integer pipeline to sleep",
    "start": "1722000",
    "end": "1727279"
  },
  {
    "text": "during tensor operations and what you'll see when you're running very high performance machine learning",
    "start": "1727279",
    "end": "1732880"
  },
  {
    "text": "workloads you might be spending 99 95 of your time in tensor instructions so",
    "start": "1732880",
    "end": "1738559"
  },
  {
    "text": "again we reduce the overhead or the cost for using general purpose programming to",
    "start": "1738559",
    "end": "1744159"
  },
  {
    "text": "a negligible amount so we can provide a very nice programming environment but we get the",
    "start": "1744159",
    "end": "1750080"
  },
  {
    "text": "kind of efficiencies you would get by a a very highly optimized hardwired",
    "start": "1750080",
    "end": "1756720"
  },
  {
    "text": "vector unit because that's where you're spending almost all your time",
    "start": "1756720",
    "end": "1762559"
  },
  {
    "text": "we can operate our our minion anywhere from around 300 megahertz to perhaps up to uh to two",
    "start": "1762559",
    "end": "1769039"
  },
  {
    "text": "gigahertz um and so uh each individual minion cpu can",
    "start": "1769039",
    "end": "1774880"
  },
  {
    "text": "deliver a peak performance of 128 giga ops per gigahertz",
    "start": "1774880",
    "end": "1781520"
  },
  {
    "text": "uh now the the way we've optimized the design is is with a core that's really designed",
    "start": "1781520",
    "end": "1788559"
  },
  {
    "start": "1782000",
    "end": "1954000"
  },
  {
    "text": "for parallel programming and so what we realize is in the physical design",
    "start": "1788559",
    "end": "1794799"
  },
  {
    "text": "limitation in seven nanometer you can only go a certain distance in your clock cycle and so we found that we could pack",
    "start": "1794799",
    "end": "1801840"
  },
  {
    "text": "about eight cpus together um uh in this proximity and so we call that a",
    "start": "1801840",
    "end": "1808880"
  },
  {
    "text": "computing neighborhood and we're able to capitalize on that physical proximity for running parallel",
    "start": "1808880",
    "end": "1816559"
  },
  {
    "text": "code so for example um when you're running code on a thousand",
    "start": "1816559",
    "end": "1821760"
  },
  {
    "text": "processors you'll tend to find that they're almost always running the same code there's you have a highly parallel",
    "start": "1821760",
    "end": "1827919"
  },
  {
    "text": "problem you're multiplying giant matrices you give each processor a piece of that matrix to go off and work on",
    "start": "1827919",
    "end": "1835360"
  },
  {
    "text": "right so rather than having many separate instruction caches that each had redundant code in them",
    "start": "1835360",
    "end": "1842559"
  },
  {
    "text": "we in groups of eight have a common shared instruction cache so that",
    "start": "1842559",
    "end": "1847679"
  },
  {
    "text": "tremendously increased the capacity we can have in the instruction cache and because we have tensor instructions that",
    "start": "1847679",
    "end": "1854559"
  },
  {
    "text": "are used very frequently the fetch bandwidth is actually not very high so we can share that one instruction cache",
    "start": "1854559",
    "end": "1860960"
  },
  {
    "text": "amongst eight minions uh and and not have any uh",
    "start": "1860960",
    "end": "1866720"
  },
  {
    "text": "large performance hit we do a similar trick with the uh on the data cache side",
    "start": "1866720",
    "end": "1872799"
  },
  {
    "text": "what you'll tend to find is a lot of the time the processors are all loading something from the same address",
    "start": "1872799",
    "end": "1880000"
  },
  {
    "text": "from the l2 cache into the l1 cache and that's a very power intensive",
    "start": "1880000",
    "end": "1885200"
  },
  {
    "text": "operation so if you were to do eight individual loads one for each",
    "start": "1885200",
    "end": "1890320"
  },
  {
    "text": "uh risk 5 minion you'd have eight times that amount of power but with the feature we call a",
    "start": "1890320",
    "end": "1896159"
  },
  {
    "text": "cooperative load when all of the loads are there pending when the first processor goes out and fetches it the",
    "start": "1896159",
    "end": "1901919"
  },
  {
    "text": "other seven processors are waiting and they simply capture the data that's come back off the l2 bus back to this group",
    "start": "1901919",
    "end": "1910000"
  },
  {
    "text": "of uh eight cpus in a neighborhood and and that was just a dramatic savings in",
    "start": "1910000",
    "end": "1916000"
  },
  {
    "text": "power um um you know compared to not having that",
    "start": "1916000",
    "end": "1921919"
  },
  {
    "text": "type of instruction so that's an example where you can't just go and pick an",
    "start": "1921919",
    "end": "1927200"
  },
  {
    "text": "off-the-shelf risk five processor and put it down and expect to get the levels of energy efficiency",
    "start": "1927200",
    "end": "1933440"
  },
  {
    "text": "sorry okay so cooperative loads were very helpful and there are a number of kinds of",
    "start": "1933440",
    "end": "1939919"
  },
  {
    "text": "instructions we do to make cooperation uh more efficient here we have instructions for fast synchronization",
    "start": "1939919",
    "end": "1946000"
  },
  {
    "text": "we have instructions to send to a neighbor receive from neighbor and i'll go through some of those extensions a little bit later in the talk",
    "start": "1946000",
    "end": "1952399"
  },
  {
    "text": "okay um so uh how do we then group these so now",
    "start": "1952399",
    "end": "1957919"
  },
  {
    "start": "1954000",
    "end": "2144000"
  },
  {
    "text": "we have a group of eight in the prior slide what we do is we take four of those eight core neighborhoods and we",
    "start": "1957919",
    "end": "1964320"
  },
  {
    "text": "pack them into what we call a minion shire we uh we wanted a little grouping of large what's larger than a",
    "start": "1964320",
    "end": "1970399"
  },
  {
    "text": "neighborhood but smaller than a city and we tried various groupings here so when shire we have a lord of the rings fan uh",
    "start": "1970399",
    "end": "1977760"
  },
  {
    "text": "shires what we ended up with here uh and so we have we next we build groups of 32",
    "start": "1977760",
    "end": "1983760"
  },
  {
    "text": "cpus together now with the group of 32 we put a much larger amount of memory we",
    "start": "1983760",
    "end": "1989039"
  },
  {
    "text": "put four megabytes of memory together with four banks interconnected with a four by four crossbar",
    "start": "1989039",
    "end": "1996880"
  },
  {
    "text": "and that will let us load enough data that we can keep these cpus busy crunching on that particular data and",
    "start": "1997039",
    "end": "2003519"
  },
  {
    "text": "keep them fed so again they can get higher sustained rates of performance and we're able to feed them at that rate",
    "start": "2003519",
    "end": "2011200"
  },
  {
    "text": "the the these srams can be configured uh as a level two cache",
    "start": "2011200",
    "end": "2018480"
  },
  {
    "text": "or as a level three cache or as a scratch pad there are certain times",
    "start": "2018480",
    "end": "2023760"
  },
  {
    "text": "where your workloads are very deterministic and you do not want to have cache",
    "start": "2023760",
    "end": "2029200"
  },
  {
    "text": "thrashing or other things going on so if you configure them as a scratch pad you can pretty much guarantee that the data",
    "start": "2029200",
    "end": "2035200"
  },
  {
    "text": "will be there waiting for you when you're ready and somebody else some other processor will not have thrown it",
    "start": "2035200",
    "end": "2041200"
  },
  {
    "text": "out of the cache these groups of 32 are interconnected with an on-chip network we just call it",
    "start": "2041200",
    "end": "2047519"
  },
  {
    "text": "a mesh stop i'll show you how that's interconnected next uh",
    "start": "2047519",
    "end": "2052878"
  },
  {
    "text": "again within a shire you can use some of these new synchronization primitives we've added to the risk 5 instruction",
    "start": "2052879",
    "end": "2059599"
  },
  {
    "text": "set atomic operations barrier instructions",
    "start": "2059599",
    "end": "2065599"
  },
  {
    "text": "credit counters and inter processor interrupt support so here's maybe a good place for you to",
    "start": "2065599",
    "end": "2071760"
  },
  {
    "text": "understand how we've worked in our power saving through operating at different voltages so you can see these groups of",
    "start": "2071760",
    "end": "2078720"
  },
  {
    "text": "32 et minions they all operate on a single low voltage plane",
    "start": "2078720",
    "end": "2084320"
  },
  {
    "text": "even the data caches are built out of special memory cells we use instead of a typical",
    "start": "2084320",
    "end": "2090720"
  },
  {
    "text": "6t cell a 12t transistor cell so those can operate down to 300",
    "start": "2090720",
    "end": "2096240"
  },
  {
    "text": "millivolts but when you want very dense amounts of memory",
    "start": "2096240",
    "end": "2101440"
  },
  {
    "text": "the rule in designing velocity chips is you always want to use the densest cell from your memory bender they have",
    "start": "2101440",
    "end": "2107680"
  },
  {
    "text": "optimized that many ways they do lots of special tricks and you you really want to operate that",
    "start": "2107680",
    "end": "2114480"
  },
  {
    "text": "and pretty much the nominal voltage and so again you'll see we have two different voltage domains in this",
    "start": "2114480",
    "end": "2121040"
  },
  {
    "text": "particular unit and we have many different voltage domains across our chip and that lets us go in and tweak",
    "start": "2121040",
    "end": "2126400"
  },
  {
    "text": "each voltage domain particularly for the neighborhoods the lowest voltage for best energy efficiency",
    "start": "2126400",
    "end": "2132240"
  },
  {
    "text": "and then you adjust your your um large des end srams to kind of meet the",
    "start": "2132240",
    "end": "2138079"
  },
  {
    "text": "speed that you need to to match that and a voltage that's very close to the nominal voltages",
    "start": "2138079",
    "end": "2145200"
  },
  {
    "start": "2144000",
    "end": "2193000"
  },
  {
    "text": "okay so now we have to make these shires talk to each other and that's done over a mess stop with um",
    "start": "2145200",
    "end": "2152880"
  },
  {
    "text": "i say large amounts of parallelism we use lots of wires and those wires run at the low voltages uh and so what you'll",
    "start": "2152880",
    "end": "2160880"
  },
  {
    "text": "find is is uh there are for example from one mesh top uh say on the left to a",
    "start": "2160880",
    "end": "2165920"
  },
  {
    "text": "neighbor on its right there will be several thousand wires in a unidirectional bus going from one mesh",
    "start": "2165920",
    "end": "2172240"
  },
  {
    "text": "top to the other and several thousand wires coming back the other direction and this is one of the beauties of using",
    "start": "2172240",
    "end": "2178720"
  },
  {
    "text": "a technology like seven nanometers the wires are very small and you can put",
    "start": "2178720",
    "end": "2183920"
  },
  {
    "text": "many hundreds of thousands of wires for getting high on-chip bandwidth on a chip",
    "start": "2183920",
    "end": "2189760"
  },
  {
    "text": "for interconnectivity um so then let's put everything together",
    "start": "2189760",
    "end": "2194880"
  },
  {
    "text": "here so we have our shires with groups of 32 you can see kind of in the center here we have an array of a six by six",
    "start": "2194880",
    "end": "2200960"
  },
  {
    "text": "array we use 34 of those shire positions to put groups of 32 processors and that's",
    "start": "2200960",
    "end": "2208400"
  },
  {
    "text": "how we end up with our 1088 we needed to use kind of two of those groupings at the top right for some",
    "start": "2208400",
    "end": "2215119"
  },
  {
    "text": "other things we put four of our maxion cpus in the shire at the upper right",
    "start": "2215119",
    "end": "2220960"
  },
  {
    "text": "along with a risk 5 service processor and then we have to have logic for our pcie bus interface",
    "start": "2220960",
    "end": "2227680"
  },
  {
    "text": "for dft fuses and those are what we call a pcie shire",
    "start": "2227680",
    "end": "2233520"
  },
  {
    "text": "on the in this block diagram roughly corresponds to the physical layout on",
    "start": "2233520",
    "end": "2239280"
  },
  {
    "text": "the chip on the that we call the east and the west sides we have dram controllers here and in order to provide",
    "start": "2239280",
    "end": "2246560"
  },
  {
    "text": "the uh the bandwidth we want but with very low power for low power we use the low",
    "start": "2246560",
    "end": "2252880"
  },
  {
    "text": "voltage swing lpddr 4x vram but we go 256 bits wide",
    "start": "2252880",
    "end": "2259520"
  },
  {
    "text": "so on the east side for example we do 128 bits wide that's by using 16-bit wide",
    "start": "2259520",
    "end": "2266720"
  },
  {
    "text": "controllers and just using multiple of those that connect upon the chip okay so that gives you then a picture of how the",
    "start": "2266720",
    "end": "2273680"
  },
  {
    "text": "memory is distributed across the chip how the processes are distributed across the chip and how they connect to memory",
    "start": "2273680",
    "end": "2281839"
  },
  {
    "text": "okay and so the the processors on a chip are all sharing a single global address",
    "start": "2281839",
    "end": "2288160"
  },
  {
    "text": "space so when a processor let's say in the lower left wants to request a piece of",
    "start": "2288160",
    "end": "2293359"
  },
  {
    "text": "data it'll first ask and see if it's in its local l1 data cache it's not there it goes out to the l2 cache and it's",
    "start": "2293359",
    "end": "2299920"
  },
  {
    "text": "memory shire and that's kind of the l2s are kind of private to the shire if it's not there it queries the l3 cache",
    "start": "2299920",
    "end": "2307040"
  },
  {
    "text": "subsystem the l3 subsystem operates across the entire die and so that piece",
    "start": "2307040",
    "end": "2312720"
  },
  {
    "text": "of data may be in any shires l3 cache if it's in your own shire you get it a little bit quicker if",
    "start": "2312720",
    "end": "2319760"
  },
  {
    "text": "not you make hops out to put the request out and the shire that has the data on die we'll send it back to you",
    "start": "2319760",
    "end": "2326960"
  },
  {
    "text": "and it may seem like it's a lot of hops if you're in the if your data was in the top right shire and you want to consume",
    "start": "2326960",
    "end": "2332400"
  },
  {
    "text": "it in the lower left shirt but let me tell you that's still a lot faster than going off chip to uh off off-chip dram",
    "start": "2332400",
    "end": "2341280"
  },
  {
    "text": "so overall it's what you might think of as almost a fairly conventional memory system with l1 l2 l3 caches and main memory",
    "start": "2341280",
    "end": "2350160"
  },
  {
    "text": "so people who are used to programming super computers take a look at this design and go oh i",
    "start": "2350160",
    "end": "2355280"
  },
  {
    "text": "understand how to use that fairly easy to map problems onto this kind of a structure",
    "start": "2355280",
    "end": "2361520"
  },
  {
    "text": "and again while we've done a six by six array here because of this fairly",
    "start": "2361520",
    "end": "2366560"
  },
  {
    "text": "modular design think of this first chip as the prototype it's going to be fairly easy for us to scale this down if we",
    "start": "2366560",
    "end": "2373040"
  },
  {
    "text": "want to go to edge devices or to scale it up in the future to much larger",
    "start": "2373040",
    "end": "2378640"
  },
  {
    "text": "arrays and at the end of the talk we'll speculate a little bit on what those larger things might look like in in",
    "start": "2378640",
    "end": "2385359"
  },
  {
    "text": "future products without making any actual product announcement here's just a little bit",
    "start": "2385359",
    "end": "2391359"
  },
  {
    "start": "2389000",
    "end": "2474000"
  },
  {
    "text": "more detail to show you that this really is a system on a chip we have all kinds of other interfaces uarts flash",
    "start": "2391359",
    "end": "2398320"
  },
  {
    "text": "interfaces gpios timers um",
    "start": "2398320",
    "end": "2404079"
  },
  {
    "text": "interfaces for debuggers usb and so this can operate as a stand-alone",
    "start": "2405119",
    "end": "2411200"
  },
  {
    "text": "chip at times uh but you know quite often in our first customer uses uh",
    "start": "2411200",
    "end": "2416640"
  },
  {
    "text": "we'll be talking across the pcie bus um to a a host uh host processor",
    "start": "2416640",
    "end": "2423920"
  },
  {
    "text": "for data center customers they very much care about security so we have a route of trust",
    "start": "2423920",
    "end": "2430319"
  },
  {
    "text": "for providing secure boot um and there's a lot of redundancy built in",
    "start": "2430319",
    "end": "2436800"
  },
  {
    "text": "here typically for example we have enough compute shires here that we can use one",
    "start": "2436800",
    "end": "2443520"
  },
  {
    "text": "as a fully redundant one uh one to control the other shires and have a nice round number of a thousand for the",
    "start": "2443520",
    "end": "2449839"
  },
  {
    "text": "software to use uh so there's a lot of redundancy and uh",
    "start": "2449839",
    "end": "2455760"
  },
  {
    "text": "opportunities to very have fine grain control over",
    "start": "2455760",
    "end": "2462000"
  },
  {
    "text": "individual positions on the chip and i'll talk a little bit more about that we do have full ecc support both in the",
    "start": "2462000",
    "end": "2468240"
  },
  {
    "text": "dram and in the internal memory system as well",
    "start": "2468240",
    "end": "2473920"
  },
  {
    "start": "2474000",
    "end": "2555000"
  },
  {
    "text": "so how do we use this in practice well again if you can get the power per chip down that means when the customer wants",
    "start": "2474240",
    "end": "2481760"
  },
  {
    "text": "to say how much performance do you get on a board it really we need to compare the performance on a board here not just",
    "start": "2481760",
    "end": "2488720"
  },
  {
    "text": "an individual chip so what you can see here is if we think about having six chips mounted on the board our memory",
    "start": "2488720",
    "end": "2494880"
  },
  {
    "text": "system is really a 1500 bit wide memory system here we can put up to 192",
    "start": "2494880",
    "end": "2500800"
  },
  {
    "text": "gigabytes of accelerator memory using 24 uh dram packages each 64 bits wide um",
    "start": "2500800",
    "end": "2509599"
  },
  {
    "text": "those 64-bit wide packages actually tend to have two 32-bit wide drams in a single package here",
    "start": "2509599",
    "end": "2515839"
  },
  {
    "text": "uh so you see we can get a lot of memory here to get a lot going and what you want to do is have a lot of channels",
    "start": "2515839",
    "end": "2522000"
  },
  {
    "text": "each one of those 64-bit wide drams is actually made up of four 16-bit channels",
    "start": "2522000",
    "end": "2528240"
  },
  {
    "text": "so we end up having 96 of these 16-bit channels able to operate in parallel",
    "start": "2528240",
    "end": "2533920"
  },
  {
    "text": "here and remember we have two threads per core so with all over a thousand",
    "start": "2533920",
    "end": "2540960"
  },
  {
    "text": "threads per chip on one board we get over 12 000 threads of execution going",
    "start": "2540960",
    "end": "2548000"
  },
  {
    "text": "at one time with this memory system and then those will connect through a pci switch to the host",
    "start": "2548000",
    "end": "2555040"
  },
  {
    "text": "so let's take a picture of what a look at one of those cars might be like",
    "start": "2555040",
    "end": "2560480"
  },
  {
    "text": "here are six chips in a mock-up module here that fit on an uh",
    "start": "2560480",
    "end": "2566640"
  },
  {
    "text": "ocp glacier point v2 card and it can handle um you'll see there are what's called a",
    "start": "2566640",
    "end": "2573280"
  },
  {
    "text": "dual mdot ii module on the top uh you can handle three on the top and three on",
    "start": "2573280",
    "end": "2578319"
  },
  {
    "text": "the bottom so this card you see in the background in red is just kind of a standard card and you could plug",
    "start": "2578319",
    "end": "2584480"
  },
  {
    "text": "for example you can turn this into a solid-state disk i believe facebook has some parts they've",
    "start": "2584480",
    "end": "2590319"
  },
  {
    "text": "worked with qualcomm on that do uh video decoding uh or if you use our chip you",
    "start": "2590319",
    "end": "2596480"
  },
  {
    "text": "could plug it in and be accelerating uh ai applications here",
    "start": "2596480",
    "end": "2601680"
  },
  {
    "text": "um and so one card here in that power limit we believe can provide over 800 tera ops uh when all",
    "start": "2601680",
    "end": "2610480"
  },
  {
    "text": "six chips are are operating at a gigahertz so how do you use that card well",
    "start": "2610480",
    "end": "2617839"
  },
  {
    "text": "think of think of that in our customers this way so we put six chips on a standard pcie",
    "start": "2617839",
    "end": "2623680"
  },
  {
    "text": "interface card that can drop into what's called the yosemite v2 sled",
    "start": "2623680",
    "end": "2629280"
  },
  {
    "text": "and that yosemite system has it's actually a dual x86 cpu system so it has",
    "start": "2629280",
    "end": "2634720"
  },
  {
    "text": "two pcie slots available as well so we'd be putting 12 chips in that you then put",
    "start": "2634720",
    "end": "2641599"
  },
  {
    "text": "four of those yosemite systems in what they call a cubby right so now we're up to putting 48 chips in the cubby and",
    "start": "2641599",
    "end": "2647839"
  },
  {
    "text": "then those go into a rack and you can hold eight of these yosemite cubbies in",
    "start": "2647839",
    "end": "2654079"
  },
  {
    "text": "a rack so we get 384 chips in a rack",
    "start": "2654079",
    "end": "2659200"
  },
  {
    "text": "and then some of these large data centers have as many as 20 000 racks in",
    "start": "2659200",
    "end": "2665520"
  },
  {
    "text": "a single hyperscale data center so our customer opportunity here is to sell",
    "start": "2665520",
    "end": "2671359"
  },
  {
    "text": "millions of chips to just one particular data center and some of our customers operate many of",
    "start": "2671359",
    "end": "2677920"
  },
  {
    "text": "these large-scale data centers and of course there's many customers that have this so that's kind of the business",
    "start": "2677920",
    "end": "2683040"
  },
  {
    "text": "model we had to get started for why we decided to pick going after data centers",
    "start": "2683040",
    "end": "2688800"
  },
  {
    "text": "there are other places you want to uh go into as well and so we do have other form factors so for example uh",
    "start": "2688800",
    "end": "2696160"
  },
  {
    "start": "2689000",
    "end": "2704000"
  },
  {
    "text": "we can put you know one or several of our chips on standard pcie express cards",
    "start": "2696160",
    "end": "2702480"
  },
  {
    "text": "as well okay let's talk just a little bit about software and then the instruction sets",
    "start": "2702480",
    "end": "2709119"
  },
  {
    "start": "2704000",
    "end": "2781000"
  },
  {
    "text": "here um so most of our customers we think will program a recommendation models uh using",
    "start": "2709119",
    "end": "2715839"
  },
  {
    "text": "something like pie torch you may use some machine learning framework and we can",
    "start": "2715839",
    "end": "2721520"
  },
  {
    "text": "get to most of the frameworks here through onyx models we started off",
    "start": "2721520",
    "end": "2727680"
  },
  {
    "text": "our initial software was based on the glow system that facebook initially started and then has open sourced that",
    "start": "2727680",
    "end": "2734240"
  },
  {
    "text": "was nice because it it provided for partitioning of models across multiple chips",
    "start": "2734240",
    "end": "2741359"
  },
  {
    "text": "and had a fairly clean separation of the machine dependent",
    "start": "2741359",
    "end": "2746400"
  },
  {
    "text": "versus the machine independent parts so on the machine dependent part we went in and were able",
    "start": "2746400",
    "end": "2752240"
  },
  {
    "text": "to change the back end to generate code for our particular cpu then we provided our own run time and",
    "start": "2752240",
    "end": "2758640"
  },
  {
    "text": "our own etpcie driver for the host and that lets us again you know bring in any",
    "start": "2758640",
    "end": "2764079"
  },
  {
    "text": "of these particular sources run it through glow and run it on our hardware we're also doing a tv import that seems",
    "start": "2764079",
    "end": "2771520"
  },
  {
    "text": "to be gaining in popularity uh and again we expect we'll have other software uh in the future here",
    "start": "2771520",
    "end": "2777440"
  },
  {
    "text": "so that's kind of a simple view of the software um i know people are kind of curious about",
    "start": "2777440",
    "end": "2783119"
  },
  {
    "start": "2781000",
    "end": "2859000"
  },
  {
    "text": "what we've done to extend risk five uh we have added a number of vector and tensor instructions uh",
    "start": "2783119",
    "end": "2789760"
  },
  {
    "text": "uh i'll give some examples in these these little blue squares here for different vector ops we can you know not only have",
    "start": "2789760",
    "end": "2797119"
  },
  {
    "text": "computation but there's conversion we do uh scatter gather again for people are",
    "start": "2797119",
    "end": "2802160"
  },
  {
    "text": "used to programming super computers that's kind of a natural people understand how to do that we have transcendental vector operations",
    "start": "2802160",
    "end": "2809920"
  },
  {
    "text": "uh not just computation but also communication so we can broadcast",
    "start": "2809920",
    "end": "2816960"
  },
  {
    "text": "do special kinds of loads and stores with inner leaves trans poses reduces transformations",
    "start": "2816960",
    "end": "2824000"
  },
  {
    "text": "and again controlling the memory system is key for keeping high sustained rates we have some special cash control",
    "start": "2824000",
    "end": "2830480"
  },
  {
    "text": "operations we put in these barrier credits atomic operations cash",
    "start": "2830480",
    "end": "2836960"
  },
  {
    "text": "trigger cash control operations and how you reserve space in the scratch pad these were all things we did when we",
    "start": "2836960",
    "end": "2843599"
  },
  {
    "text": "kind of started on risk five and said look we have to think about this in kind of a super computer mentality we're",
    "start": "2843599",
    "end": "2849040"
  },
  {
    "text": "starting with a thousand processors on a chip this is kind of like a lot of data centers that use small number of",
    "start": "2849040",
    "end": "2854960"
  },
  {
    "text": "cores but they have a thousand cores in their whole data center here um",
    "start": "2854960",
    "end": "2860079"
  },
  {
    "start": "2859000",
    "end": "2871000"
  },
  {
    "text": "and so with the tensor multiply operations we can uh multiply you know two-dimensional matrices or",
    "start": "2860079",
    "end": "2866160"
  },
  {
    "text": "three-dimensional matrices here for what we're doing i won't spend a lot of time on the detail here but let me just show",
    "start": "2866160",
    "end": "2872559"
  },
  {
    "start": "2871000",
    "end": "3034000"
  },
  {
    "text": "you an example of how we use these new instructions so if you think of starting",
    "start": "2872559",
    "end": "2877680"
  },
  {
    "text": "off with our little block diagram here we have a thousand cores one of the first things you might do is a tensor",
    "start": "2877680",
    "end": "2884240"
  },
  {
    "text": "load the l2 scratch pad and so what this will do is it'll take uh data that's",
    "start": "2884240",
    "end": "2889520"
  },
  {
    "text": "maybe out in dram or it might possibly be in some of the l3s or a mixture of",
    "start": "2889520",
    "end": "2895440"
  },
  {
    "text": "the two and it will it will bring it into a particular shires into those four",
    "start": "2895440",
    "end": "2901119"
  },
  {
    "text": "megabytes of memory into the amount you've allocated for scratch pad and those you can",
    "start": "2901119",
    "end": "2907119"
  },
  {
    "text": "allocate those in different size partitions kind of at will here once it's in that",
    "start": "2907119",
    "end": "2913440"
  },
  {
    "text": "l2 scratch pad then what you'll do is to do a tensor load instruction and that will load from",
    "start": "2913440",
    "end": "2920480"
  },
  {
    "text": "the scratch pad memory the large four megabyte capacity into the individual e.t minions into their local",
    "start": "2920480",
    "end": "2928000"
  },
  {
    "text": "data caches once you have the data in the data caches you want to operate on",
    "start": "2928000",
    "end": "2933359"
  },
  {
    "text": "then you can go and you execute the actual floating point multiply accumulate tensor instruction and so",
    "start": "2933359",
    "end": "2940240"
  },
  {
    "text": "that'll move data into the vector register files and the floating point units directly",
    "start": "2940240",
    "end": "2946480"
  },
  {
    "text": "and then store the results back in the vector register file and then we have instructions which do the reverse to get",
    "start": "2946480",
    "end": "2952160"
  },
  {
    "text": "things back out to memory as well why so many instructions why didn't we just have one instruction and stream all this",
    "start": "2952160",
    "end": "2958319"
  },
  {
    "text": "in like everybody else well programmers are have gotten very clever",
    "start": "2958319",
    "end": "2963520"
  },
  {
    "text": "over the last 20 years in figuring out how to",
    "start": "2963520",
    "end": "2968559"
  },
  {
    "text": "overlap the data movement so you can keep high sustainable rates of",
    "start": "2968559",
    "end": "2974000"
  },
  {
    "text": "computation again although everybody quotes peak rates the goal really is to get high",
    "start": "2974000",
    "end": "2979920"
  },
  {
    "text": "sustainable rates of computation and so again there's there's sort of there's a wealth of expertise here on how to keep",
    "start": "2979920",
    "end": "2986880"
  },
  {
    "text": "high sustainable rates if you're using a more traditional programming model here and that's what we've done and we're",
    "start": "2986880",
    "end": "2992880"
  },
  {
    "text": "very happy with how that works out so uh with what we've done our tensor fma operation we are keeping this near a",
    "start": "2992880",
    "end": "3000480"
  },
  {
    "text": "hundred percent utilization over the 512 cycles that it runs we can keep the",
    "start": "3000480",
    "end": "3005599"
  },
  {
    "text": "machine you know it's how do you keep the beast fed how do you keep all these anal use fed on the machine here",
    "start": "3005599",
    "end": "3012400"
  },
  {
    "text": "so we're able to uh to do that and again each tensor instruction in this particular example might do 16 000",
    "start": "3012400",
    "end": "3019680"
  },
  {
    "text": "floating point operations all from one one risk 5 extended instruction issue",
    "start": "3019680",
    "end": "3026400"
  },
  {
    "text": "here and again the risk 5 integer core gets put to sleep during these long tensor operations so that saves on on",
    "start": "3026400",
    "end": "3033359"
  },
  {
    "text": "power overall the integer uh 8-bit integer uh tensor operations are a",
    "start": "3033359",
    "end": "3041760"
  },
  {
    "start": "3034000",
    "end": "3076000"
  },
  {
    "text": "little bit different um in that we have a separate integer register file uh that assists the",
    "start": "3041760",
    "end": "3049760"
  },
  {
    "text": "generic uh vector register file in these operations here uh so that we get uh",
    "start": "3049760",
    "end": "3057200"
  },
  {
    "text": "four times the throughput that we get from fv16 when we're doing integer operations and of course we do standard",
    "start": "3057200",
    "end": "3064000"
  },
  {
    "text": "tricks like you know if you're going to do a multiply check to make sure if you're multiplying by zero",
    "start": "3064000",
    "end": "3069119"
  },
  {
    "text": "don't toggle your gates you know the answer is going to be zero just pass the zero on and go through and do that",
    "start": "3069119",
    "end": "3076480"
  },
  {
    "start": "3076000",
    "end": "3092000"
  },
  {
    "text": "we have a number of instructions here for coordination special barrier instructions credit",
    "start": "3076480",
    "end": "3082480"
  },
  {
    "text": "counters uh and there's a little again a lot of little programming tricks the the",
    "start": "3082480",
    "end": "3087760"
  },
  {
    "text": "programmers can can utilize to keep high throughput in the machine here so let's get to some benchmarks here so how do we",
    "start": "3087760",
    "end": "3094240"
  },
  {
    "start": "3092000",
    "end": "3322000"
  },
  {
    "text": "do so we're trying to figure out a way to you know",
    "start": "3094240",
    "end": "3099839"
  },
  {
    "text": "give a fair comparison between what we thought we would do since most of the",
    "start": "3099839",
    "end": "3106480"
  },
  {
    "text": "recommendation work was going on on intel cpus today we decided to use the intel cpu as a",
    "start": "3106480",
    "end": "3113440"
  },
  {
    "text": "reference um and for benchmarkings we're very much fans of the ml perf consortium here and",
    "start": "3113440",
    "end": "3121520"
  },
  {
    "text": "they have a deep learning recommendation benchmark that they put in so we're using that",
    "start": "3121520",
    "end": "3127680"
  },
  {
    "text": "why because as we've learned in benchmarking it's more fair if you let that vendor cite their own performance",
    "start": "3127680",
    "end": "3134559"
  },
  {
    "text": "on their best configuration rather than you running it and not getting the parameters right",
    "start": "3134559",
    "end": "3140079"
  },
  {
    "text": "so the performance numbers i'm getting here let's say for the you know the on the xeon 3000 samples per second per die",
    "start": "3140079",
    "end": "3148160"
  },
  {
    "text": "this comes directly out of going to the perf website taking the absolute best performance",
    "start": "3148160",
    "end": "3154720"
  },
  {
    "text": "chip they can utilize and the best system they have with the best amount of memory and we just use those numbers",
    "start": "3154720",
    "end": "3160960"
  },
  {
    "text": "right so you can see that intel has picked a fairly high performance chip for just",
    "start": "3160960",
    "end": "3166960"
  },
  {
    "text": "eight chips they're burning two kilowatts just for the cpus alone so that's they're operating at roughly 250",
    "start": "3166960",
    "end": "3174079"
  },
  {
    "text": "watts per die uh and they get reasonable performance with that",
    "start": "3174079",
    "end": "3179680"
  },
  {
    "text": "nvidia would say hey our gpus are better and in fact they are in terms of relative",
    "start": "3179680",
    "end": "3187760"
  },
  {
    "text": "performance they're 11 times better in absolute performance",
    "start": "3187760",
    "end": "3193520"
  },
  {
    "text": "and if you look at the amount of power they're taking there they don't need two kilowatts they can use just 70 watts",
    "start": "3193520",
    "end": "3199839"
  },
  {
    "text": "per p4 card uh and so they're actually 39 times better in energy efficiency",
    "start": "3199839",
    "end": "3205200"
  },
  {
    "text": "which is shown in the darker green bar chart here how do different chips compare you say",
    "start": "3205200",
    "end": "3210960"
  },
  {
    "text": "oh the t4 is a little bit old you see yeah but everybody wants to hear about the t4 because they're used to that the",
    "start": "3210960",
    "end": "3216800"
  },
  {
    "text": "newer chip would be the a10 uh and so that does a little bit better in absolute performance about three times",
    "start": "3216800",
    "end": "3223599"
  },
  {
    "text": "better but it doesn't do as much better in terms of of energy efficiency in terms of",
    "start": "3223599",
    "end": "3229359"
  },
  {
    "text": "performance per watt okay if you look at what esperanto can do with this recommendation benchmark",
    "start": "3229359",
    "end": "3236559"
  },
  {
    "text": "we believe with our sick chips on our card we'll get to roughly a factor of a hundred times better",
    "start": "3236559",
    "end": "3242880"
  },
  {
    "text": "than those those eight intel cpus would do in the system so we're a great case where the customer",
    "start": "3242880",
    "end": "3249200"
  },
  {
    "text": "can still use the intel cpu on the host to run the operating system to deal with the i o but we're a good partner in",
    "start": "3249200",
    "end": "3256000"
  },
  {
    "text": "terms of being able to accelerate that cpu by another factor of a hundred",
    "start": "3256000",
    "end": "3261599"
  },
  {
    "text": "so we're particularly good at deep learning recommendation now at this point in the presentation if we were",
    "start": "3261599",
    "end": "3267920"
  },
  {
    "text": "sitting in a in a consortium room somebody would be raising their hand and say yeah but i don't have this number in",
    "start": "3267920",
    "end": "3273920"
  },
  {
    "text": "my performance charts what do you do on resnet50 so okay yes we'll go we'll give that one",
    "start": "3273920",
    "end": "3279599"
  },
  {
    "text": "next because you all want to compare that so we do uh again uh very well but",
    "start": "3279599",
    "end": "3285200"
  },
  {
    "text": "not 100x better we're about 25 times better and that's probably because intel spent a lot of time making resin",
    "start": "3285200",
    "end": "3290880"
  },
  {
    "text": "resonance 50 run well on their on their advanced cpus as well but overall and we we here were able to",
    "start": "3290880",
    "end": "3298079"
  },
  {
    "text": "we had a habanagoya comparison for resnet50 whereas we didn't have that for dlrm",
    "start": "3298079",
    "end": "3304720"
  },
  {
    "text": "uh and we still do very very well with a general purpose wrist five processor as",
    "start": "3304720",
    "end": "3310720"
  },
  {
    "text": "the the core of our acceleration here okay uh it's a little bit on performance",
    "start": "3310720",
    "end": "3317760"
  },
  {
    "text": "now let's got stuck there a little bit um",
    "start": "3317760",
    "end": "3322799"
  },
  {
    "start": "3322000",
    "end": "3372000"
  },
  {
    "text": "just talk about you know we have a whole other class of processor here our maxion processor here i'm not",
    "start": "3322799",
    "end": "3328400"
  },
  {
    "text": "going to spend a lot of time on this uh it's an out of order processor we had designed uh initially we started off",
    "start": "3328400",
    "end": "3335280"
  },
  {
    "text": "with the boom processor we more than doubled its performance uh",
    "start": "3335280",
    "end": "3340799"
  },
  {
    "text": "uh and we have a number of other talks that are out there just go look at one of",
    "start": "3340799",
    "end": "3345839"
  },
  {
    "text": "those other talks if you're interested in the the maxion processor uh again we think there will be",
    "start": "3345839",
    "end": "3352240"
  },
  {
    "text": "applications in the future that'll want to run standalone and uh so uh the maxions",
    "start": "3352240",
    "end": "3358400"
  },
  {
    "text": "it can run say uh i think we have them running at about 1.5 gigahertz now in the lab uh they can run a",
    "start": "3358400",
    "end": "3366000"
  },
  {
    "text": "linux operating system or something else to to help drive the uh the array of minions",
    "start": "3366000",
    "end": "3372079"
  },
  {
    "start": "3372000",
    "end": "3535000"
  },
  {
    "text": "uh so just some summary stats here um uh it's found a tsmc 7 nanometer about",
    "start": "3372079",
    "end": "3377839"
  },
  {
    "text": "24 billion devices on a single die uh it's only a moderate size die 570",
    "start": "3377839",
    "end": "3384240"
  },
  {
    "text": "millimeters squared uh we're not going to the full reticle size which is what or even wafer scale",
    "start": "3384240",
    "end": "3390400"
  },
  {
    "text": "size which is what other people are doing is uh there are different approaches that are appropriate for",
    "start": "3390400",
    "end": "3396000"
  },
  {
    "text": "different usage cases here again three different types of",
    "start": "3396000",
    "end": "3401280"
  },
  {
    "text": "processors here and typically for dlrm we're expecting to operate these kind of around the 20",
    "start": "3401280",
    "end": "3407520"
  },
  {
    "text": "watt level or below the the package sorry the package here has got",
    "start": "3407520",
    "end": "3415040"
  },
  {
    "text": "about 2500 balls on the back of the package but there are many more bumps on the die",
    "start": "3415040",
    "end": "3421760"
  },
  {
    "text": "when you flip chip it over onto the package we over 30 000 bumps what are we doing with all those bumps well in",
    "start": "3421760",
    "end": "3427920"
  },
  {
    "text": "addition to lots of power and ground one of the things we've done is to",
    "start": "3427920",
    "end": "3433040"
  },
  {
    "text": "realize that with a thousand processors there is threshold voltage variation across the die",
    "start": "3433040",
    "end": "3439200"
  },
  {
    "text": "or if you get unlucky enough that you have a mass defect that you know maybe",
    "start": "3439200",
    "end": "3444400"
  },
  {
    "text": "the the processors in the lower left-hand side of the die uh they're all running a little bit slow",
    "start": "3444400",
    "end": "3451280"
  },
  {
    "text": "in order to get to the megahertz you want you may have to turn up the voltage",
    "start": "3451280",
    "end": "3456720"
  },
  {
    "text": "uh to get there but all the rest of the processors 90 we didn't need so much voltage",
    "start": "3456720",
    "end": "3462720"
  },
  {
    "text": "so each you can see in kind of the blue squares here we have each group of 32",
    "start": "3462720",
    "end": "3468480"
  },
  {
    "text": "each of those group of 32 cpus has its own independent",
    "start": "3468480",
    "end": "3473599"
  },
  {
    "text": "low voltage control so we can finely tune the power supplies",
    "start": "3473599",
    "end": "3480480"
  },
  {
    "text": "to this and we think that can offer you know tremendous power savings if you get",
    "start": "3480480",
    "end": "3485839"
  },
  {
    "text": "into issues where you have vte variation again as the manufacturing proceeds and",
    "start": "3485839",
    "end": "3490960"
  },
  {
    "text": "matures over time maybe that's not quite as critical but we have that flexibility on dye",
    "start": "3490960",
    "end": "3497200"
  },
  {
    "text": "and we can also use those to you know again run different sections of the chip at different frequencies there",
    "start": "3497200",
    "end": "3503760"
  },
  {
    "text": "are independent plls in each of those groupings uh so you can run different frequencies",
    "start": "3503760",
    "end": "3509839"
  },
  {
    "text": "different voltages you can have the bottom half of the chip running",
    "start": "3509839",
    "end": "3514720"
  },
  {
    "text": "a recommendation half and maybe the top half running a vision task again they're just a thousand general purpose",
    "start": "3514880",
    "end": "3521520"
  },
  {
    "text": "processors programmers will figure out what clever things they want to do with these we've got a few uh",
    "start": "3521520",
    "end": "3527839"
  },
  {
    "text": "suggestions for machine learning but we expect over time we're going to find all kinds of clever uses for using a",
    "start": "3527839",
    "end": "3534000"
  },
  {
    "text": "thousand processors okay so where are we at yeah well yes we have real silicon here's a picture of the wafer we have",
    "start": "3534000",
    "end": "3540480"
  },
  {
    "start": "3535000",
    "end": "3562000"
  },
  {
    "text": "chips up and running in the lab we have a remote access for customers uh",
    "start": "3540480",
    "end": "3548240"
  },
  {
    "text": "for what we're doing here we're not in general availability quite yet it takes quite a long time to go through the",
    "start": "3548240",
    "end": "3554640"
  },
  {
    "text": "whole qualification process on chips uh and get everything finely tuned up but",
    "start": "3554640",
    "end": "3562319"
  },
  {
    "start": "3562000",
    "end": "3599000"
  },
  {
    "text": "everything is pretty much running on our very first silicon here we are still not seeing anything would",
    "start": "3562319",
    "end": "3568799"
  },
  {
    "text": "require not even a metal mass change on the chip we're running uh substantial ai",
    "start": "3568799",
    "end": "3574799"
  },
  {
    "text": "inference workloads on all thousand plus processors we're running nightly continuous integration tests on those",
    "start": "3574799",
    "end": "3582240"
  },
  {
    "text": "the maxions are up and running our pcie and ddr interfaces are up and",
    "start": "3582240",
    "end": "3587680"
  },
  {
    "text": "running at speed uh we have already done a public demo uh",
    "start": "3587680",
    "end": "3593680"
  },
  {
    "text": "i think samsung had a what they call a tech day they were very impressed with what we were doing and we showed how if you couple a",
    "start": "3593680",
    "end": "3602319"
  },
  {
    "text": "processor with an ssd that we can dramatically reduce bandwidth requirements in the system",
    "start": "3602319",
    "end": "3608559"
  },
  {
    "text": "uh so that's out and that's public um and we're talking to individual large",
    "start": "3608559",
    "end": "3615440"
  },
  {
    "text": "customers at this point and we have an early access program for those people to get on and start testing our chip",
    "start": "3615440",
    "end": "3621760"
  },
  {
    "text": "if you're very very eager you can contact us now and ask to be in the early access program or later on this",
    "start": "3621760",
    "end": "3627839"
  },
  {
    "text": "year hopefully we'll have much more widespread spread availability you can get your own pcie card and play with it",
    "start": "3627839",
    "end": "3634480"
  },
  {
    "text": "so what's what's coming up next here so that's let me just one slide there's a lot of interesting things going on there",
    "start": "3634480",
    "end": "3640400"
  },
  {
    "text": "have been some announcements uh recently here so um",
    "start": "3640400",
    "end": "3645520"
  },
  {
    "text": "uh uh last month less than a month ago on february 7th uh esperanto announced that",
    "start": "3645520",
    "end": "3652720"
  },
  {
    "text": "we were partnering with intel uh to get access to their advanced technology",
    "start": "3652720",
    "end": "3658000"
  },
  {
    "text": "nodes on their fab to their three nanometer and uh 1.8 nanometer actually they call it 18a generation",
    "start": "3658000",
    "end": "3664960"
  },
  {
    "text": "um and they also announced in addition that esperanto was going to be one of the risk five ecosystem partners",
    "start": "3664960",
    "end": "3671680"
  },
  {
    "text": "uh risk five is growing and intel has just decided to go big into risk five they've joined the risk five consortium",
    "start": "3671680",
    "end": "3680000"
  },
  {
    "text": "and they announced four different ecosystem partners esperanto andes and sci-fi who both offer",
    "start": "3680000",
    "end": "3688000"
  },
  {
    "text": "ip if you want to build your own uh embedded chip and ventana microsystems",
    "start": "3688000",
    "end": "3693440"
  },
  {
    "text": "who is offering what they call a data class center chip you'll have to talk to them to see what they're doing and esperanto is really focused more on",
    "start": "3693440",
    "end": "3700720"
  },
  {
    "text": "the ai side with over a thousand ai optimized risk five cores we by far",
    "start": "3700720",
    "end": "3706480"
  },
  {
    "text": "have the highest uh performing risk five system out there but that's just the",
    "start": "3706480",
    "end": "3711520"
  },
  {
    "text": "beginning uh today march 2nd there was an announcement some",
    "start": "3711520",
    "end": "3716640"
  },
  {
    "text": "of you may not have seen yet the follow-on to the pcie bus in some ways it's called the ucie bus",
    "start": "3716640",
    "end": "3724079"
  },
  {
    "text": "the universal chiplet interconnect express was announced i think there were about 20 different companies uh",
    "start": "3724079",
    "end": "3730880"
  },
  {
    "text": "announced so far here they've announced basically a bus that lets you connect uh chiplets together",
    "start": "3730880",
    "end": "3737760"
  },
  {
    "text": "um and so if you think of what we've done in seven nanometer rather than shrinking to five if you shrink directly",
    "start": "3737760",
    "end": "3745039"
  },
  {
    "text": "to three uh what we have is a thousand processors and a moderate size chip becomes a thousand processors and a",
    "start": "3745039",
    "end": "3751839"
  },
  {
    "text": "little tiny chiplet right and with little tiny chiplets you might assemble you know let's say 10 of those",
    "start": "3751839",
    "end": "3759200"
  },
  {
    "text": "on a package maybe with even a zeon host cpu who knows right and with a thousand each you",
    "start": "3759200",
    "end": "3765839"
  },
  {
    "text": "could put 10 thousand risk five pours in in a fairly small package",
    "start": "3765839",
    "end": "3772079"
  },
  {
    "text": "uh with giblet technology here and so the world is going to advance to where you're not having hundred hundreds or",
    "start": "3772079",
    "end": "3778799"
  },
  {
    "text": "even just a thousand but tens of thousands of cores able to operate together",
    "start": "3778799",
    "end": "3784880"
  },
  {
    "text": "how do you program tens of thousands of cores well we believe the general purpose programming model is a really",
    "start": "3784880",
    "end": "3791280"
  },
  {
    "text": "good one and one that will scale because the world has been scaling data centers and other things to those kinds of",
    "start": "3791280",
    "end": "3797200"
  },
  {
    "text": "numbers of cpus in the past so again i'm not trying to announce any particular product here but just to say",
    "start": "3797200",
    "end": "3805039"
  },
  {
    "text": "esperanto very much likes the chiplet methodology and we like this special",
    "start": "3805039",
    "end": "3810720"
  },
  {
    "text": "packaging technology that intel has that will help package chiplets",
    "start": "3810720",
    "end": "3815920"
  },
  {
    "text": "and so you should expect to see very interesting things coming in the future",
    "start": "3815920",
    "end": "3821280"
  },
  {
    "text": "so i think i've kind of gone over most of the details here we have this nice scalable design",
    "start": "3821280",
    "end": "3826559"
  },
  {
    "text": "we're the stage we're at we're doing early access for early customers right now and yes we are hiring and growing go",
    "start": "3826559",
    "end": "3833440"
  },
  {
    "text": "ahead and see our website for details or send me a personal email if you don't see a slot there that that's made for",
    "start": "3833440",
    "end": "3840559"
  },
  {
    "text": "you and you want to do something else tell us why you can contribute uh just write that as a note along with your",
    "start": "3840559",
    "end": "3846079"
  },
  {
    "text": "resume we'd be happy to talk to you i just want to say quick thanks to a number of our different partners here",
    "start": "3846079",
    "end": "3851599"
  },
  {
    "text": "we've gotten ip from who've helped us with the lab with packaging uh with input on the design for what",
    "start": "3851599",
    "end": "3858000"
  },
  {
    "text": "they wanted as a large data scale data center customers for debugging hardware for uh for help particularly to",
    "start": "3858000",
    "end": "3864799"
  },
  {
    "text": "semi dynamics who's helped us with the architecture and other implementations we got going",
    "start": "3864799",
    "end": "3871359"
  },
  {
    "text": "to mobilize for the plls more tick for some of the on-chip sensors lots of different customers and a lot of",
    "start": "3871359",
    "end": "3877839"
  },
  {
    "text": "people have helped again we see different companies and risk five not as our competitors but as",
    "start": "3877839",
    "end": "3883839"
  },
  {
    "text": "members of a common ecosystem so thanks also to sci-fi and andy's and other companies there who we work together",
    "start": "3883839",
    "end": "3890880"
  },
  {
    "text": "with regularly in the ris5 consortia out there uh again if you're interested",
    "start": "3890880",
    "end": "3896880"
  },
  {
    "text": "in some of the details here are the uh the papers cited in the footnotes along with a few more details here on how we",
    "start": "3896880",
    "end": "3903119"
  },
  {
    "text": "did the benchmarking and at this point if dennis allows and we can work out the logistics i'll take",
    "start": "3903119",
    "end": "3909280"
  },
  {
    "text": "a few questions i'm blown away i think you did a great job with this thing i'm really curious who the other who the",
    "start": "3909280",
    "end": "3916000"
  },
  {
    "text": "other architects were this is a significant departure from what",
    "start": "3916000",
    "end": "3922480"
  },
  {
    "text": "people have been doing and i think you didn't done an exceptional job",
    "start": "3922480",
    "end": "3928079"
  },
  {
    "text": "there were a lot of architects here and a lot of people with a lot of industry experience here we have some of the",
    "start": "3928079",
    "end": "3933520"
  },
  {
    "text": "original people just a personal thanks to people like tom riordan who helped",
    "start": "3933520",
    "end": "3938559"
  },
  {
    "text": "found nips technologies um uh alan baum very involved in the instruction set and",
    "start": "3938559",
    "end": "3944880"
  },
  {
    "text": "helping us on risk five um you know various other people brian you know well",
    "start": "3944880",
    "end": "3949920"
  },
  {
    "text": "brian case peter gloskowski others have been helping uh",
    "start": "3949920",
    "end": "3955119"
  },
  {
    "text": "uh people who've uh started the spark architecture started the mips architecture we have a number of alpha",
    "start": "3955119",
    "end": "3961039"
  },
  {
    "text": "architects i think allen work bomb worked on the alpha sri masala who's one of the the top",
    "start": "3961039",
    "end": "3966720"
  },
  {
    "text": "floating point gurus in the world he did the floating point on all the boxes he did the floating point on the atonium he",
    "start": "3966720",
    "end": "3973440"
  },
  {
    "text": "worked for me on my secret project at intel that i wish i could give you a seminar about but we never got clearance",
    "start": "3973440",
    "end": "3979520"
  },
  {
    "text": "for that um uh and just a variety of different people here we",
    "start": "3979520",
    "end": "3985359"
  },
  {
    "text": "we kind of bit off a very large problem here and so we used a lot of people with a lot of industry experience who came in",
    "start": "3985359",
    "end": "3992160"
  },
  {
    "text": "at the beginning and helped us out and just want to say thanks to all of",
    "start": "3992160",
    "end": "3997280"
  },
  {
    "text": "those there are a lot of fairly well-known names here and a lot of newer people were training for the next",
    "start": "3997280",
    "end": "4003520"
  },
  {
    "text": "generation here we've got well over 100 people probably 150 to almost 200 people",
    "start": "4003520",
    "end": "4009359"
  },
  {
    "text": "contributed to this design in various ways directly working with esperanto okay so",
    "start": "4009359",
    "end": "4016960"
  },
  {
    "text": "we're giving out gold stars you've got one uh no we can take some questions and uh if you raise your hand and so forth",
    "start": "4016960",
    "end": "4024319"
  },
  {
    "text": "uh you should be able to do it got a question yeah the the uh of course the other big",
    "start": "4024319",
    "end": "4030079"
  },
  {
    "text": "problem in this space is training any estimates on how you do on that or is this purely inference",
    "start": "4030079",
    "end": "4036880"
  },
  {
    "text": "um we we are certainly capable with the risk five instruction set to do some training and we expect to do some",
    "start": "4036880",
    "end": "4042400"
  },
  {
    "text": "incremental training but training is a really really hard problem and so when",
    "start": "4042400",
    "end": "4047680"
  },
  {
    "text": "we first went to the large data center companies and said hey we can build you a really good chip for",
    "start": "4047680",
    "end": "4053760"
  },
  {
    "text": "training they literally told us please don't do that",
    "start": "4053760",
    "end": "4059599"
  },
  {
    "text": "look we have over a million cpus in our data center they have to be ready for handling peak loads so what that means",
    "start": "4059599",
    "end": "4066559"
  },
  {
    "text": "is most of the time they're 50 idle we don't care how long it takes to do training we have plenty of cpu cycles",
    "start": "4066559",
    "end": "4073039"
  },
  {
    "text": "for training but we don't have is the millisecond level response we need for",
    "start": "4073039",
    "end": "4078720"
  },
  {
    "text": "inference and so we were really guided into doing more of an inference solution to begin with again",
    "start": "4078720",
    "end": "4085839"
  },
  {
    "text": "i think training needs huge amounts of memory you need to get to there are just all kinds of very",
    "start": "4085839",
    "end": "4092640"
  },
  {
    "text": "challenging systems issues there so my hat's off to the companies that are going after training first",
    "start": "4092640",
    "end": "4098960"
  },
  {
    "text": "we decided to start with inference and i think we'll grow into training as a company more over time as i say we have",
    "start": "4098960",
    "end": "4105758"
  },
  {
    "text": "general purpose risk five processors there's no reason why we can't do some training the question will be do we have",
    "start": "4105759",
    "end": "4111920"
  },
  {
    "text": "enough memory for what you want to do for your particular training if it fits in 200 gigabytes and you can split the",
    "start": "4111920",
    "end": "4118000"
  },
  {
    "text": "work across six cores yeah it's pretty easy to do and in fact uh if you have a pcie bus system that",
    "start": "4118000",
    "end": "4124080"
  },
  {
    "text": "takes more than six slots we can kind of add numbers of pcie cards and get the collective memory up higher",
    "start": "4124080",
    "end": "4131679"
  },
  {
    "text": "or if you can just partition your problem in a way yeah we could do training that way but",
    "start": "4131679",
    "end": "4136798"
  },
  {
    "text": "one of the things they said is look if you bring us a training chip it will take well over a year",
    "start": "4136799",
    "end": "4142000"
  },
  {
    "text": "for us to go from buying you know a dozen of your cpus to play with to where we would understand how to uh deploy",
    "start": "4142000",
    "end": "4149199"
  },
  {
    "text": "this um so and then how about more general high",
    "start": "4149199",
    "end": "4155920"
  },
  {
    "text": "performance computing problems yes i think the big thing you'll notice that's different at the moment at least",
    "start": "4155920",
    "end": "4162000"
  },
  {
    "text": "is the minions don't do double precision floating point but if your problem fits in single",
    "start": "4162000",
    "end": "4167520"
  },
  {
    "text": "precision or half precision or ant eight go for it but uh it's great uh great seeing so many people here just to email",
    "start": "4167520",
    "end": "4174159"
  },
  {
    "text": "me dave at esperanto.ai will get me and would be happy to be in communication but thanks everybody for coming it's",
    "start": "4174159",
    "end": "4180238"
  },
  {
    "text": "been a pleasure to be able to present thank you dave it was really outstanding to have you here",
    "start": "4180239",
    "end": "4186000"
  },
  {
    "text": "and we look forward to seeing you in person at some point",
    "start": "4186000",
    "end": "4193239"
  }
]
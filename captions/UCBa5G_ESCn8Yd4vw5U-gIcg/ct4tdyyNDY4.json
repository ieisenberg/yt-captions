[
  {
    "start": "0",
    "end": "5290"
  },
  {
    "text": "Hey, guys. Oh, yeah, thanks for waiting. I'm really happy to be here. I guess to shortly\nintroduce myself.",
    "start": "5290",
    "end": "11870"
  },
  {
    "text": "My name is Ted Xiao. I'm a Senior Research Engineer\nat the Google Brain team.",
    "start": "11870",
    "end": "17140"
  },
  {
    "text": "I've been on working on robotics\nnow for the past five years. I've touched upon a few topics\nincluding multi-task learning,",
    "start": "17140",
    "end": "23890"
  },
  {
    "text": "reinforcement learning. And then lately,\njust broadly thinking about how we can scale\nrobots to make sure",
    "start": "23890",
    "end": "29109"
  },
  {
    "text": "that they can actually work\nin the wild in the real world. I guess today I'll be\ntalking about quite",
    "start": "29110",
    "end": "34420"
  },
  {
    "text": "a few different topics. But as a first preface, I\nguess the first thing to know",
    "start": "34420",
    "end": "39610"
  },
  {
    "text": "is that our team is\npretty massive now. All of these projects are\nhuge collaborations with--",
    "start": "39610",
    "end": "44890"
  },
  {
    "text": "some projects have more\nthan 40 people working on these for many years. So these are large efforts. And I'm just very fortunate\nto call myself to be",
    "start": "44890",
    "end": "52000"
  },
  {
    "text": "on teams of very smart people. And secondly, some of my\ntakes are spicier and more",
    "start": "52000",
    "end": "57730"
  },
  {
    "text": "controversial than others. And so all of those opinions\nare definitely only my own and don't reflect\nthose of Google",
    "start": "57730",
    "end": "63940"
  },
  {
    "text": "or anyone else on the team. So with that out of the way,\nyeah, welcome to my TEDx talk.",
    "start": "63940",
    "end": "69640"
  },
  {
    "start": "69640",
    "end": "75820"
  },
  {
    "text": "So I think maybe\nsome of you have seen a lot of the cool robot videos. A lot learning videos out\nin the wild these days.",
    "start": "75820",
    "end": "82930"
  },
  {
    "text": "But I am more excited than\never, and it's not just hype, I think. I think there's been a\nfundamental shift in how",
    "start": "82930",
    "end": "89440"
  },
  {
    "text": "researcher and robotics view\nlearning over the past two years. And I think the\nshift has a lot to do",
    "start": "89440",
    "end": "95410"
  },
  {
    "text": "with all of the trends happening\nmore broadly in foundation modeling, in large\nscale internet",
    "start": "95410",
    "end": "101260"
  },
  {
    "text": "models across different\nfields like language, audio, and so on. But I think my goal today\nis to convey to you why",
    "start": "101260",
    "end": "109210"
  },
  {
    "text": "I am particularly excited about\nthis time today right and now. And why there's been a very\nfundamental 180 degree paradigm",
    "start": "109210",
    "end": "117010"
  },
  {
    "text": "shift, I think, across\nthe robot learning field. And if you walk away from\nthis talk with just one thing",
    "start": "117010",
    "end": "122680"
  },
  {
    "text": "and that's you're slightly a\nbit more excited about robotics than you were before or\nbelieve that the time is now",
    "start": "122680",
    "end": "128919"
  },
  {
    "text": "for these robots to really\nstart scaling exponentially and doing something\nreally cool, I think then my talk\nwill have succeeded.",
    "start": "128919",
    "end": "135040"
  },
  {
    "text": " Let's see.",
    "start": "135040",
    "end": "141900"
  },
  {
    "text": "The talk we'll have a few parts. We're going to start\nat a very high level and just talk about why a\nfoundation model for robotics",
    "start": "141900",
    "end": "149850"
  },
  {
    "text": "at all, what that\nmight look like. And the ingredients and recipe\nfor how we might get there. Then we'll dive into\na few different works",
    "start": "149850",
    "end": "157769"
  },
  {
    "text": "pretty deeply that my\nteam has been very proud of over the past year or two. And finally, we'll go\nback to the high level",
    "start": "157770",
    "end": "164159"
  },
  {
    "text": "and then zoom out and think\nabout what's next for robot learning.",
    "start": "164160",
    "end": "169560"
  },
  {
    "text": "So why a foundation\nmodel for robotics? One sec, let me try\nto hide this thing.",
    "start": "169560",
    "end": "176190"
  },
  {
    "text": " Oh, that's fine. I will keep that\nbar there for now.",
    "start": "176190",
    "end": "181730"
  },
  {
    "text": "But the top bar says why\nfoundation model for robotics? Being coined here\nat Stanford and I'll",
    "start": "181730",
    "end": "187400"
  },
  {
    "text": "use the phrases internet\nscale model, foundation model, and large language model, pretty\ninterchangeably throughout,",
    "start": "187400",
    "end": "193250"
  },
  {
    "text": "and I hope it's pretty clear. But generally, when I'm talking\nabout these big monolithic beasts that are training\non tons of data,",
    "start": "193250",
    "end": "200330"
  },
  {
    "text": "they have two very\nimportant properties that I think are quite nice. One is emergence.",
    "start": "200330",
    "end": "206150"
  },
  {
    "text": "When very simple things, kind\nof, work at a small scale, they get a ton better when\nyou just scale things up.",
    "start": "206150",
    "end": "212960"
  },
  {
    "text": "More data, more\ncompute larger models. And what we see here is\nthat when these models even",
    "start": "212960",
    "end": "218960"
  },
  {
    "text": "become good enough,\nthe domain space of what they're good\nat and able to do starts to go\ncombinatorial even larger.",
    "start": "218960",
    "end": "226200"
  },
  {
    "text": "And here for these\ntwo points, I would like to suggest two blog\npost I highly recommend.",
    "start": "226200",
    "end": "231420"
  },
  {
    "text": "One is from Jacob\nSteinhardt called \"More is Different for AI\"\nand this kind of links the phenomenon that we see\nin other fields like physics",
    "start": "231420",
    "end": "238459"
  },
  {
    "text": "or biology. For example, individual\nwater molecules will behave very\ndifferently and have",
    "start": "238460",
    "end": "244099"
  },
  {
    "text": "very different say\nelectrostatic forces, then they start to clump up,\nclump up and start behaving as a liquid altogether.",
    "start": "244100",
    "end": "250280"
  },
  {
    "text": "We see this in herds of\nanimal, flocking patterns. We see this in\nhumans in economies. We see this all across different\nfields and now even in AI,",
    "start": "250280",
    "end": "257930"
  },
  {
    "text": "we see models that are\ndoing stuff that would not be even possible where\nthey at a smaller scale but when they reach some\ncritical scale in size,",
    "start": "257930",
    "end": "265889"
  },
  {
    "text": "they start to work\nreally, really well. This is documented by Jason\nin his blog post, \"Emergence",
    "start": "265890",
    "end": "271759"
  },
  {
    "text": "in LLMs\", which you see this\nplot on the bottom left. Success rate across a\nbunch of different tasks,",
    "start": "271760",
    "end": "277500"
  },
  {
    "text": "whether it's modular arithmetic\nor purging question answering, the success rate\nis basically flat",
    "start": "277500",
    "end": "282590"
  },
  {
    "text": "until these models get big\nenough good enough and then the success rate just,\nkind of, skyrocket.",
    "start": "282590",
    "end": "287780"
  },
  {
    "text": "And that's why I think these\nare particularly exciting. Sorry, you have a question?",
    "start": "287780",
    "end": "293330"
  },
  {
    "text": "[INAUDIBLE] I'm curious to know, do\nrobotic foundation models",
    "start": "293330",
    "end": "298340"
  },
  {
    "text": "display [INAUDIBLE]? Great question. And I'm really glad you asked.",
    "start": "298340",
    "end": "303389"
  },
  {
    "text": "We have-- I'm pretty excited\nto present some directions we have along that. I hope we'll answer\na question and maybe",
    "start": "303390",
    "end": "308630"
  },
  {
    "text": "about 10 minutes or so. OK. Yeah. But I think that's a\nquestion on all of our minds, including myself.",
    "start": "308630",
    "end": "315720"
  },
  {
    "text": "So I think before we even\nget to the feasibility or the existence of any\nrobotics foundation models like is this even needed.",
    "start": "315720",
    "end": "322078"
  },
  {
    "text": "And I think the argument\nthat I don't think is obvious is that\nI think emerging capabilities and\nrelying on these",
    "start": "322078",
    "end": "328430"
  },
  {
    "text": "might be actually indispensable\nfor robotics to actually work. A lot of the research over\nthe past decades in robotics",
    "start": "328430",
    "end": "334430"
  },
  {
    "text": "has been in one bin, one\nroom, one table, one robot, one building even.",
    "start": "334430",
    "end": "339590"
  },
  {
    "text": "But these are so vastly\ndifferent from the orders of magnitude more complex\nwhile real world situations",
    "start": "339590",
    "end": "346190"
  },
  {
    "text": "that humans operate\nin every single day. And I think to make\nthat gigantic leap, we're going to have to rely\non this emerging capability",
    "start": "346190",
    "end": "353330"
  },
  {
    "text": "scaling curve where\nthings, kind of, work you have very kind demos. Maybe you have a\nhumanoid robot programmed",
    "start": "353330",
    "end": "359840"
  },
  {
    "text": "to backflip after\nhundreds of trials, but going from that to\nthe chaotic real world, I think we're going to have\nto rely on this emergence",
    "start": "359840",
    "end": "366830"
  },
  {
    "text": "phenomenon for that. And I think maybe\neven intellectually",
    "start": "366830",
    "end": "372400"
  },
  {
    "text": "or academically it's\nalso interesting to think about why or why not a\nfoundation model for robotics",
    "start": "372400",
    "end": "378789"
  },
  {
    "text": "might even work. It's worked in so\nmany other domains. There's existence proofs in\naudio, music, coding language,",
    "start": "378790",
    "end": "385090"
  },
  {
    "text": "another domain every single\nday it seems with 3D models and beyond. But if there is something\nvery special about robotics,",
    "start": "385090",
    "end": "392620"
  },
  {
    "text": "whether it's embodiment\nor causality or physical grounding, and that is\nthe barrier to making",
    "start": "392620",
    "end": "397780"
  },
  {
    "text": "this very simple\nrecipe that's work in all these other domains. If there is something\nspecial about robotics",
    "start": "397780",
    "end": "403360"
  },
  {
    "text": "that causes this\nrecipe to fail, I think that's quite interesting\nto study why that is. I'm personally an optimist.",
    "start": "403360",
    "end": "409010"
  },
  {
    "text": "I don't think there is some\nmagical secret sauce that's going to keep robotics\nfrom being tackled with the same formulas\nand recipes that's",
    "start": "409010",
    "end": "416080"
  },
  {
    "text": "worked elsewhere. But I think this\nis a question I'd like to find out the answer to. ",
    "start": "416080",
    "end": "423380"
  },
  {
    "text": "And so maybe then,\ninstead of just motivating this philosophically, OK,\nwe need foundation models. Foundation models are great.",
    "start": "423380",
    "end": "428980"
  },
  {
    "text": "Let's try to build\none for robotics. How do we actually do that? Well, I think we can\nleverage a few ingredients",
    "start": "428980",
    "end": "436480"
  },
  {
    "text": "by standing on the\nshoulders of giants and looking at other domains. The first one is looking at\ndifferent design principles",
    "start": "436480",
    "end": "442449"
  },
  {
    "text": "of ML scaling from\nother domains. Let's look first at high\ncapacity architectures,",
    "start": "442450",
    "end": "448300"
  },
  {
    "text": "the topic of this class today. Ideas such as self-attention.",
    "start": "448300",
    "end": "453370"
  },
  {
    "text": "As all the different ideas\nencompassed in the transformer, as Andre Karpathy\nfamously said, it's like a magical universal\ndifferentiable computer",
    "start": "453370",
    "end": "460599"
  },
  {
    "text": "that's very general, very\nrobust, and very remarkably scalable on many\ndifferent dimensions.",
    "start": "460600",
    "end": "465610"
  },
  {
    "text": "Let's use those. We should also leverage\nthe more guiding principles that have been seen the scaling\nlaws, the trends this year--",
    "start": "465610",
    "end": "473380"
  },
  {
    "text": "Chinchilla. We not only have to\nscale the model size. We also have to scale\ncompute and we also",
    "start": "473380",
    "end": "478600"
  },
  {
    "text": "have to scale the\nnumber of unique tokens in the corpus of the vast\ndata sets that we train on.",
    "start": "478600",
    "end": "483920"
  },
  {
    "text": "But if we do all\nthree together, this has been shown to reliably\nhave a pretty good chance",
    "start": "483920",
    "end": "489190"
  },
  {
    "text": "of succeeding no matter what\ndomain you're looking at. And finally, what\nthat kind of means--",
    "start": "489190",
    "end": "495293"
  },
  {
    "text": "and I think this is actually\ngoing to come up later. --is that data set size\nseems to matter these days a lot more than quality.",
    "start": "495293",
    "end": "500970"
  },
  {
    "text": "Even if you have some\nsentences on Wikipedia that are misspelled, or\nsome falsehoods,",
    "start": "500970",
    "end": "506430"
  },
  {
    "text": "or some things that\naren't so desirable if in aggregate your data\nset is diverse enough and interesting\nenough, these things",
    "start": "506430",
    "end": "512820"
  },
  {
    "text": "will hopefully wash\nit out in the mix. Ingredient number\ntwo, the proliferation",
    "start": "512820",
    "end": "519159"
  },
  {
    "text": "of the internet scale\nmodels themselves, not just the principles. What's exciting and I'm\nsure it's definitely",
    "start": "519159",
    "end": "526450"
  },
  {
    "text": "been very shocking for both\nexperts and laypeople alike, is that a lot of these\ngenerative models",
    "start": "526450",
    "end": "531640"
  },
  {
    "text": "across many different modalities\nhave been experiencing emergent capabilities\nand have been surpassing all of our wildest\nexpectations time and time",
    "start": "531640",
    "end": "539530"
  },
  {
    "text": "and again. But even when we think\nthat we're exhausted. All this stuff is too much. That's not going to work. Something will come\nout and completely",
    "start": "539530",
    "end": "545769"
  },
  {
    "text": "blow me out of the water. And I think this trend will\ndefinitely keep continuing. And I think in addition to\nthat, they not only will",
    "start": "545770",
    "end": "551890"
  },
  {
    "text": "continue coming on and\naccelerate more rapidly, they're going to happen with it\nwhether or not we do anything",
    "start": "551890",
    "end": "557530"
  },
  {
    "text": "in the grand scale of speaking. Me as a robotics\nresearcher or you and whatever subfield\nyou're on, there",
    "start": "557530",
    "end": "564558"
  },
  {
    "text": "are parts of machine learning\nthat likely you'll probably not ever touch in at\nleast the near future.",
    "start": "564558",
    "end": "569649"
  },
  {
    "text": "And those parts will be seeing\ntremendous breakthroughs and scaling and new\ncapabilities coming online every single week.",
    "start": "569650",
    "end": "576650"
  },
  {
    "text": "And you can look\nat this not only in the impressiveness\nof the models but also the acceleration of progress.",
    "start": "576650",
    "end": "582860"
  },
  {
    "text": "The time scales in\nwhich new models are being released where large\ncollaborations are being worked",
    "start": "582860",
    "end": "587870"
  },
  {
    "text": "on by many groups and then\nbeing available to access for all to use and build upon.",
    "start": "587870",
    "end": "594910"
  },
  {
    "text": "And the final\ningredient in this trend is more of a robotic\nspecific one. But it is a vast shift from\nonline robotic learning, where",
    "start": "594910",
    "end": "604330"
  },
  {
    "text": "robots collect experience\nonline make actions and learn through trial and error\nto an offline setting,",
    "start": "604330",
    "end": "610510"
  },
  {
    "text": "where we decouple\nthe data generation process from the data\nconsumption process.",
    "start": "610510",
    "end": "615850"
  },
  {
    "text": "As we've seen in all these other\nfoundation modeling domains, these big internet scale\ndata sets are so diverse.",
    "start": "615850",
    "end": "622210"
  },
  {
    "text": "And they're static. We just scrape them once or\nscrape them multiple times continuously but we\naggregate a continuous pile",
    "start": "622210",
    "end": "628960"
  },
  {
    "text": "that's just growing. Here we see either the\npile data set from Eleuther or a LAION-5B for\npaired image text.",
    "start": "628960",
    "end": "636740"
  },
  {
    "text": "And these are pretty big. And they're orders\nof magnitude more than what we've seen before. And they are definitely\na key ingredient",
    "start": "636740",
    "end": "642037"
  },
  {
    "text": "to why other domains have\nbeen doing so well by training these big foundation models. ",
    "start": "642037",
    "end": "649899"
  },
  {
    "text": "Coming back to\nrobotics then, I'd like to take a brief detour\ninto how the shift came to be.",
    "start": "649900",
    "end": "655060"
  },
  {
    "text": "Because it's very easy\nto say in a sentence, yeah, robotics is\noffline more than online. And this is coming as, kind of,\na no brainer to many folks who",
    "start": "655060",
    "end": "662170"
  },
  {
    "text": "are coming from other\ndomains like this is the way things are done. But in robotics, this has\nbeen a very big shift.",
    "start": "662170",
    "end": "668510"
  },
  {
    "text": "And I think robotics\nhas also been synonymous with\nRL, reinforcement learning for a lot of people. And I think increasingly,\nthis is becoming less true.",
    "start": "668510",
    "end": "676459"
  },
  {
    "text": "And so I'd like to take\nyou down a brief trip down the history of my team. The other slide of the\ntalk is brief history",
    "start": "676460",
    "end": "683290"
  },
  {
    "text": "of robotics at Google. Yeah, of course, thanks. And I think this is not just\nfor dramatic exposition.",
    "start": "683290",
    "end": "690040"
  },
  {
    "text": "It's really to try to guide\nyou through how drastically our team's thinking has, kind\nof, evolved over the years",
    "start": "690040",
    "end": "697150"
  },
  {
    "text": "and how that's going\nto inform the design decisions and the kind of\nrisks and research directions",
    "start": "697150",
    "end": "703149"
  },
  {
    "text": "that we take in this\nspecific project. So I'm going to show coming up. Thank you. So in 2016, some of\nyou may have seen this,",
    "start": "703150",
    "end": "710170"
  },
  {
    "text": "we had what we\ncall the arm farm. Seven Kuka robots in a room,\ncollecting picking data 24/7.",
    "start": "710170",
    "end": "716259"
  },
  {
    "text": "And this was doing on-policy RL. In the real world, we were the\nfirst team to kind of say, hey,",
    "start": "716260",
    "end": "721500"
  },
  {
    "text": "can we even do this? With the goal of saying, can\nwe do end-to-end robot learning with results in the real world?",
    "start": "721500",
    "end": "727360"
  },
  {
    "text": "This was, kind of,\nrisky at the time. It was not a common take. And from that we developed\nseveral interesting research",
    "start": "727360",
    "end": "732850"
  },
  {
    "text": "directions that we\nstarted exploring. We looked into\nstuff like QT-Opt, which is a cue-learning method\nworking on continuous control",
    "start": "732850",
    "end": "741670"
  },
  {
    "text": "actions while taking\nvision inputs. We worked on\nCycleGAN to transform",
    "start": "741670",
    "end": "747220"
  },
  {
    "text": "simulation-based images\ninto real-looking images for [INAUDIBLE]. We looked at\nconcurrent role, how",
    "start": "747220",
    "end": "752890"
  },
  {
    "text": "we get robots moving\nfaster and more efficiently in the real world. I'm sorry, do you\nhave a question? Yeah, [INAUDIBLE] 24/7 data\ncollection [INAUDIBLE]..",
    "start": "752890",
    "end": "760774"
  },
  {
    "text": "Curious to know, how\ndid you read seven? Yeah, great question. And that one, I\nthink, was basically",
    "start": "760774",
    "end": "767410"
  },
  {
    "text": "the arms would pick\nstuff up from the bin. If they messed up\nand it fell out, well, we'd come back\nthe next morning,",
    "start": "767410",
    "end": "772625"
  },
  {
    "text": "and there'd be objects scattered\nall throughout the room. So there was no reset. But if they missed a\nlittle bit, the objects",
    "start": "772625",
    "end": "778657"
  },
  {
    "text": "would fall back into\nthe bin and, hopefully, be in a position where they\ncould pick them up again. I wanted to ask you\nif you can repeat",
    "start": "778657",
    "end": "784630"
  },
  {
    "text": "the question they've asked. Oh, yeah, of course. Thanks. I'll do that in the future. This specific question was,\nfor this 24/7 arm farm,",
    "start": "784630",
    "end": "791560"
  },
  {
    "text": "how did we do resets? And the answer is,\nwell, we didn't. We designed the bin\nso that they were",
    "start": "791560",
    "end": "797140"
  },
  {
    "text": "banked so that if an\nobject slightly missed, they would fall back in the bin,\nreorient themselves, maybe add more diversity with\nthe training data.",
    "start": "797140",
    "end": "803440"
  },
  {
    "text": "But this was doing\noff-policy online RL row with cue learning. And we mixed it with same\ndata, deploy it again.",
    "start": "803440",
    "end": "809950"
  },
  {
    "text": " Next, we went through this\nconsolidation phase around 2020",
    "start": "809950",
    "end": "816552"
  },
  {
    "text": "when we were like, all right. This is pretty cool. But we want to get\nout of the bin. How do we do more complex tasks\nin a more practical setting",
    "start": "816552",
    "end": "824545"
  },
  {
    "text": "that could be\ncloser to something that humans would want to use,\nthat's more general every day? There, we settled on this office\nmicro kitchen environment,",
    "start": "824545",
    "end": "831890"
  },
  {
    "text": "if you've heard of the\nfamous Google micro-kitchens. And I think this was the setting\nwe decided to operate in.",
    "start": "831890",
    "end": "838700"
  },
  {
    "text": "And there, we started\ncollecting data. We scaled our operations. And there we scaled approaches\nto some different things.",
    "start": "838700",
    "end": "844830"
  },
  {
    "text": "And I think, in the\nbottom right here, is the more mechanized\nreset version, I would say, of the arm farm.",
    "start": "844830",
    "end": "850670"
  },
  {
    "text": "Here, we had a bin\nthat folded in half. And this was doing multitask\nRL in the real world. And the bin would flipping\nin half, dumping objects",
    "start": "850670",
    "end": "857270"
  },
  {
    "text": "from one side to the other. So you could do more\ninteresting tasks, whereas the arm farm\nwas, pick anything up. Now we could say, hey,\npick up the carrot",
    "start": "857270",
    "end": "863300"
  },
  {
    "text": "and place the tomato\nonto the plate. And then the bin would\nflip, and you'd reset.",
    "start": "863300",
    "end": "868490"
  },
  {
    "text": "Some other works we\nlook at multitasking imitation learning. This is BC-zero. And then, we also look at stuff\nlike combining reinforcement",
    "start": "868490",
    "end": "874940"
  },
  {
    "text": "learning with imitation learning\nbootstrapping [INAUDIBLE].. But in 2020, once\nagain, we realized",
    "start": "874940",
    "end": "882630"
  },
  {
    "text": "we were working in a ton\nof different directions, and we wanted to consolidate. And I think the two main things\nthat were really bothering us",
    "start": "882630",
    "end": "889290"
  },
  {
    "text": "at the point, at the time, were\nwe are hitting two main walls across all these methods. Some of them were plateauing\nat this 50% to 70%",
    "start": "889290",
    "end": "897690"
  },
  {
    "text": "rough range in the real world. And other methods were\nrequiring very specific data distributions.",
    "start": "897690",
    "end": "903540"
  },
  {
    "text": "They had to be on policy,\nor they could only use demonstrations, or\nthey blah, blah, blah. There were so many different\nnuances and gotchas",
    "start": "903540",
    "end": "910055"
  },
  {
    "text": "to all of these\ndifferent methods and all of these\ndifferent drawbacks. And so the question\nwe posed was,",
    "start": "910055",
    "end": "915060"
  },
  {
    "text": "we're open to any\nmethod, any strategy that will enable us to solve tasks\nin a very performant matter",
    "start": "915060",
    "end": "921105"
  },
  {
    "text": "manner, more than 90%\nin the real world, and, also, that can scale\nwith some kind of data",
    "start": "921105",
    "end": "926850"
  },
  {
    "text": "that we can collect. And maybe this is a bit\nmore lax than, let's say, an academic setting where you're\nmuch more resource-constrained.",
    "start": "926850",
    "end": "934200"
  },
  {
    "text": "But at the end of the day,\neven our team does not have infinite money, we\nstill have a certain number of robots, a certain\nnumber of operators,",
    "start": "934200",
    "end": "940380"
  },
  {
    "text": "and we're constrained\nby the laws of physics. So we need some way\nto acquire more data that we can then learn from. And so we're all\nscratching our heads",
    "start": "940380",
    "end": "946732"
  },
  {
    "text": "thinking about this for a\nfew months in spring 2022. We decided on going with\nmulti-task imitation learning.",
    "start": "946732",
    "end": "953290"
  },
  {
    "text": "So this was a vast departure\nfrom the 24/7 arm farm. This was a vast evolution of\nhow we approach the problem.",
    "start": "953290",
    "end": "959860"
  },
  {
    "text": "We found that with enough,\nno gentle care and love, multi-task imitation\nlearning was able to hit these 90% numbers.",
    "start": "959860",
    "end": "966420"
  },
  {
    "text": "And it was able to get better\nwith more demonstrations. These aren't the\ncheapest thing, but it was able to scale with\nadditional demonstrations,",
    "start": "966420",
    "end": "973560"
  },
  {
    "text": "which was a sign of life\nthat we were looking for. So that brings us to\nless than a year ago,",
    "start": "973560",
    "end": "979050"
  },
  {
    "text": "our team was deciding\nthis is the path forward, at least in the\nnear-term future, but maybe, we could\njust think about how",
    "start": "979050",
    "end": "987540"
  },
  {
    "text": "the approach we were\ntaking here might also spread out in the future. And we might be able to bring\nback these other threads.",
    "start": "987540",
    "end": "994140"
  },
  {
    "text": "For example, if now that we're\ndecoupling this data collection of demonstrations, or\net cetera, from how",
    "start": "994140",
    "end": "1000529"
  },
  {
    "text": "we learn from them with a\nmultitask imitation learning policy, maybe we\ncan, in the future, then do something\nlike offline RL.",
    "start": "1000530",
    "end": "1006710"
  },
  {
    "text": "But I think at a\nhigh level now-- I've just, in a\nfew short minutes, just compressed six years\nof very bitter lessons",
    "start": "1006710",
    "end": "1013957"
  },
  {
    "text": "that our team has been learning. And I think, from\nwhere we are today, and looking back even\njust two years ago, if you told me that the\nstrategies we're deploying",
    "start": "1013957",
    "end": "1020870"
  },
  {
    "text": "today could just scale\nthe way they are, I probably would not\nhave believed you. You have a question?",
    "start": "1020870",
    "end": "1026089"
  },
  {
    "text": "[INAUDIBLE] instead of\ntrying to figure out",
    "start": "1026089",
    "end": "1034099"
  },
  {
    "text": "how [INAUDIBLE] data sets. Great question. So I think task conditioning\nis definitely still-- was",
    "start": "1034099",
    "end": "1039470"
  },
  {
    "text": "an open question at the time. But I think with\nthis work, BC-zero, we found that language\nwas able, at least",
    "start": "1039470",
    "end": "1047180"
  },
  {
    "text": "in a templated language\nrepresentation, was good enough where\nwe could direct. I think BC-zero\nis over 80 tasks.",
    "start": "1047180",
    "end": "1053570"
  },
  {
    "text": "So they were very templated,\nlike pick grapes, or move grapes onto a plate,\nor drag this across--",
    "start": "1053570",
    "end": "1061530"
  },
  {
    "text": "drag a cloth across a table. And I think this\nrepresentation was still enough where you're learning a\ngood number of skills.",
    "start": "1061530",
    "end": "1067708"
  },
  {
    "text": "You're passing in, essentially,\na one-hot ID into your policy network. And it will learn\nto imitate that. And for each one\nof those 80 tasks,",
    "start": "1067708",
    "end": "1073728"
  },
  {
    "text": "it'd collect hundreds or\nthousands of the imitations. And we'll touch upon the\nspecifics of that a bit later,",
    "start": "1073728",
    "end": "1079440"
  },
  {
    "text": "too.  So yeah, today, or at least in\n2022, let's do offline methods.",
    "start": "1079440",
    "end": "1088910"
  },
  {
    "text": "Let's decouple data generation\nfrom data consumption. And let's take these\nthree lessons now",
    "start": "1088910",
    "end": "1094030"
  },
  {
    "text": "that we've touched upon. Let's take the design\nprinciples of ML scaling, and then figure out what\nlessons can actually be applied when you go--\nlook into the future",
    "start": "1094030",
    "end": "1101300"
  },
  {
    "text": "for a recipe for robot\nlearning and foundation models. The first lesson I think\nis very important is",
    "start": "1101300",
    "end": "1108020"
  },
  {
    "text": "this high-capacity\narchitecture, is like attention. The second, I'll\ntouch upon later, is data interoperability,\ntokenization, discretization.",
    "start": "1108020",
    "end": "1116300"
  },
  {
    "text": "And the second ingredient\nis the proliferation of these models themselves. Can we leverage them because\nthey will get better over time?",
    "start": "1116300",
    "end": "1123630"
  },
  {
    "text": "And I think here, I\nwould like to plug my colleague Karol\nHausman's bitter lesson 2.0, which is the bitter lesson.",
    "start": "1123630",
    "end": "1129660"
  },
  {
    "text": "The first one from\nRichard Sutton was, you should leverage methods\nthat scale with more compute. And maybe in\ntoday's day and age,",
    "start": "1129660",
    "end": "1136850"
  },
  {
    "text": "the lesson is that we\nshould leverage methods that are able to\nutilize improvements in foundation models because\nthey're going to get better.",
    "start": "1136850",
    "end": "1143600"
  },
  {
    "text": "Yeah. So both in the bitter\nlesson 1.0 and 2.0, one thing that's\nalways unclear to me is suppose I have\na set of methods,",
    "start": "1143600",
    "end": "1150748"
  },
  {
    "text": "and I want to choose\nthe methods that are going to scale with more\ncompute or, in this case, scale with better\nfoundation models.",
    "start": "1150748",
    "end": "1156400"
  },
  {
    "text": "The question is,\nhow do I actually decide which of those\nmethods meets those criteria?",
    "start": "1156400",
    "end": "1162610"
  },
  {
    "text": "Yeah, a great question. I think, and maybe it's--\nand I think that's a very-- I don't have a good\nanswer for that.",
    "start": "1162610",
    "end": "1168430"
  },
  {
    "text": "Could you repeat the question? Oh, sorry, yeah. The question was in bitter\nlesson 1.0 and bitter lesson 2.0, the question is,\nwell, that's great.",
    "start": "1168430",
    "end": "1174669"
  },
  {
    "text": "That's the lesson. But how do we\nactually decide which methods meet these criteria? And I think my answer is\nit's not always obvious.",
    "start": "1174670",
    "end": "1182630"
  },
  {
    "text": "And it's actually\nquite tricky sometimes. But maybe, sometimes what-- you\ncan be very confident that, Oh,",
    "start": "1182630",
    "end": "1188320"
  },
  {
    "text": "yeah, this will definitely scale\nwith more data and compute. And some that are the same-- basically, the more\nhard-coded you are,",
    "start": "1188320",
    "end": "1193610"
  },
  {
    "text": "the more assumptions, the more\nheuristics you make bake in, the more you-- in\nour day and age, the more you rely on a\nspecific implementation",
    "start": "1193610",
    "end": "1200230"
  },
  {
    "text": "of a specific foundation\nmodel of a specific class of algorithm maybe that will be\nless robust than a method that",
    "start": "1200230",
    "end": "1206860"
  },
  {
    "text": "just assumes some very abstract\ninput and output and assumes that how you get from\nthat input and output",
    "start": "1206860",
    "end": "1212080"
  },
  {
    "text": "can improve over time. And maybe the algorithm itself\neven changes altogether. So I think that would be my\ntake on the bitter lesson 2.0.",
    "start": "1212080",
    "end": "1218950"
  },
  {
    "text": "But this is definitely still-- I think the jury's\nstill out on this.",
    "start": "1218950",
    "end": "1225200"
  },
  {
    "text": "And my basic-- one of the\nthings I like to propose is that language\nis the way that we",
    "start": "1225200",
    "end": "1231080"
  },
  {
    "text": "can leverage bitter lesson 2.0. If you have language as the\nuniversal representation through which all\nof these foundations",
    "start": "1231080",
    "end": "1236840"
  },
  {
    "text": "communicate to each other,\nwhether it's captioning, or generation, or\nwhatnot, I think that's one way that we could\nleverage bitter lessons 2.0.",
    "start": "1236840",
    "end": "1247030"
  },
  {
    "text": "And finally, the\nthird ingredient, offline robot learning,\ndecoupling data generation from data consumption.",
    "start": "1247030",
    "end": "1253350"
  },
  {
    "text": "Putting these all\ntogether, my recipe for how one takes\nat a modern attempt",
    "start": "1253350",
    "end": "1258612"
  },
  {
    "text": "at embodied\nintelligence would look like would be to combine\nthese large offline data sets with high-capacity\narchitectures",
    "start": "1258612",
    "end": "1265380"
  },
  {
    "text": "by using language as\nthe universal glue. And in the works I'm\ngoing to present shortly,",
    "start": "1265380",
    "end": "1270510"
  },
  {
    "text": "all of our different projects,\nI think, in some way or another, are inspired by this philosophy.",
    "start": "1270510",
    "end": "1276269"
  },
  {
    "text": " And now, that we've understood\nthe motivations and potentially",
    "start": "1276270",
    "end": "1284440"
  },
  {
    "text": "one possible approach-- Sorry. Can you go back one slide? Of course. The bottom, the recipe-- \"large diverse offline data\nsets with high-capacity",
    "start": "1284440",
    "end": "1290880"
  },
  {
    "text": "architectures using language\nas a universal glue\"-- I'm curious to know which, if\nany, of these are currently--",
    "start": "1290880",
    "end": "1297483"
  },
  {
    "text": "[INAUDIBLE] is not\nthe right word. Which of these are limited? Got it. Because it seems to me like we\nalready have large offline data",
    "start": "1297483",
    "end": "1303160"
  },
  {
    "text": "sets. We have high-capacity\narchitectures. Those architectures\n[INAUDIBLE] language. It seems like we already have\nall the components necessary.",
    "start": "1303160",
    "end": "1309740"
  },
  {
    "text": "So why is this then\nnot a solved problem? The question was, it\nseems like we have",
    "start": "1309740",
    "end": "1315970"
  },
  {
    "text": "a lot of these ingredients. And so, why hasn't\nrobotics been solved yet? So I would argue that actually,\nthis take here, and maybe I'm--",
    "start": "1315970",
    "end": "1323767"
  },
  {
    "text": "this is to the wrong\naudience at the moment. But I think this is\nnot very non-obvious across the robotics field.",
    "start": "1323767",
    "end": "1328929"
  },
  {
    "text": "Many people do\nnot agree with all of these, much less two of these\nor even any of these points.",
    "start": "1328930",
    "end": "1334940"
  },
  {
    "text": "And so I think-- and\nalso the existence of the scale of how mature\neach of these components",
    "start": "1334940",
    "end": "1340600"
  },
  {
    "text": "are within robotics is\nthat very different stages. And I would say-- and we\ncan talk a bit later about, for example, data scale\nor the architectures that",
    "start": "1340600",
    "end": "1347920"
  },
  {
    "text": "have diffused through\nosmosis from other ML domains into robotics, but\nI think we're still",
    "start": "1347920",
    "end": "1354070"
  },
  {
    "text": "at very different\nstages on how much people have actually\nbought into these lessons and invested in them.",
    "start": "1354070",
    "end": "1359537"
  },
  {
    "text": "Can I have a follow-up question? Yeah. [INAUDIBLE] I'm curious to know-- I'm not asking you to name\nnames, but the people who",
    "start": "1359537",
    "end": "1366520"
  },
  {
    "text": "might not be buying into all\nthese pieces [INAUDIBLE]..",
    "start": "1366520",
    "end": "1372180"
  },
  {
    "text": "Yeah, I can probably-- I also don't want to get\ninto too much trouble here.",
    "start": "1372180",
    "end": "1377429"
  },
  {
    "text": "I'll probably get\nmyself in a bit of hot water in a few slides. So I'll expand\nupon it a bit then. Sounds good.",
    "start": "1377430",
    "end": "1382915"
  },
  {
    "text": "Yeah. I'm just curious to know\nwhat their opinion is and why you think they're\nwrong on the subject. [INAUDIBLE] Yeah. And I would say that\nme, personally, and--",
    "start": "1382915",
    "end": "1391770"
  },
  {
    "text": "I'm not speaking for my team,\nbut a lot of people on my team are probably at the very extreme\nend of learning, scaling,",
    "start": "1391770",
    "end": "1398230"
  },
  {
    "text": "data-driven, foundation\nmodel-based, let's go big. And I think a lot of\npeople don't believe that,",
    "start": "1398230",
    "end": "1404890"
  },
  {
    "text": "and, yeah, happy to discuss\nwhy later, maybe after the Zoom as well. [LAUGHTER]",
    "start": "1404890",
    "end": "1411085"
  },
  {
    "text": "So yeah, well, OK, then\nlet's go ahead and dive in and see how this recipe\nmight actually percolate",
    "start": "1411085",
    "end": "1417250"
  },
  {
    "text": "into specific domains. And the first one is RT-1.",
    "start": "1417250",
    "end": "1422470"
  },
  {
    "text": "This is a recent\nwork from our group that works on how we can\nscale imitation learning. And let's look at\nhow we can actually",
    "start": "1422470",
    "end": "1428830"
  },
  {
    "text": "apply these first principles. So the first one is to\nconsider what we actually--",
    "start": "1428830",
    "end": "1434470"
  },
  {
    "text": "let's put ourselves into\nthe spring 2020 mindset. We've been collecting\ndemonstrations for a while. This is a ton of\ndemos, like 100,000.",
    "start": "1434470",
    "end": "1442000"
  },
  {
    "text": "Data was collected\nover a year and a half on many, many robots\non many, many tasks.",
    "start": "1442000",
    "end": "1447220"
  },
  {
    "text": "That exists. It was expensive. And over time, this\nwill actually not trickle up at insane amounts.",
    "start": "1447220",
    "end": "1453580"
  },
  {
    "text": "We won't just get 100,000 new\nhigh-quality demos every day. This will grow over\ntime, but it's not going to grow for free.",
    "start": "1453580",
    "end": "1460720"
  },
  {
    "text": "And autonomous\nways of doing this is very hard, as you\nsaw earlier with ntop with the bin reset\nmechanism, or DeepMind",
    "start": "1460720",
    "end": "1466138"
  },
  {
    "text": "has a record\nRGB-stacking, where they try to do autonomous resets. And the way that we're doing\nit right now, or at least",
    "start": "1466138",
    "end": "1472120"
  },
  {
    "text": "for this paper, was\nhuman teleoperation pioneered by BC-zero. And that was very\nexpensive as well.",
    "start": "1472120",
    "end": "1478380"
  },
  {
    "text": "So there's going to\nbe limited throughput. And finally, BC-zero used\na ResNet base backbone. And it was pretty\ngood, but they found",
    "start": "1478380",
    "end": "1484600"
  },
  {
    "text": "that it was very sensitive\nto training distributions. For example, when they remove\ndata from some teleoperators",
    "start": "1484600",
    "end": "1489760"
  },
  {
    "text": "to make the data\nmore homogeneous, performance got better. And that's not really\na property we like. We want more data, even if\nit's not exactly the same.",
    "start": "1489760",
    "end": "1497870"
  },
  {
    "text": "So the lesson here,\nmodels need to be robust, and they need to generalize. Cool.",
    "start": "1497870",
    "end": "1503050"
  },
  {
    "text": "So we have, models need to\nbe robust and generalized. What else do we have? Well, off-the-shelf\nmodels are pretty slow.",
    "start": "1503050",
    "end": "1508270"
  },
  {
    "text": "If we take in these\nhuge vision transformers from other domains, they're not\ngoing to run on the real robot.",
    "start": "1508270",
    "end": "1513880"
  },
  {
    "text": "We need to be able to run\nat a pretty high frequency. They need to be reactive. Inference time needs to be\nslow because all our models are",
    "start": "1513880",
    "end": "1520299"
  },
  {
    "text": "vision-based. And finally, we want our data to\nbe able to understand language.",
    "start": "1520300",
    "end": "1525900"
  },
  {
    "text": "As I mentioned, if language\nis the universal glue, our data set already\nhas some language. And we want eventual models\nto be very multi-modal.",
    "start": "1525900",
    "end": "1532740"
  },
  {
    "text": "This is first principle\nthat we need to bake in. What does this mean? We can't just take\nsomething existing.",
    "start": "1532740",
    "end": "1538153"
  },
  {
    "text": "We probably need to design\nor at least modify something from the ground up. And let's take the best\npractices that we've",
    "start": "1538153",
    "end": "1543880"
  },
  {
    "text": "seen work in other fields. And so we worked for a bit.",
    "start": "1543880",
    "end": "1548929"
  },
  {
    "text": "And we came up with this\narchitecture for RT-1. Again, once again,\nthis is a large team",
    "start": "1548930",
    "end": "1554120"
  },
  {
    "text": "with a bunch of\ndifferent contributions. And I'll just go through\na few of them here. At a high level, RT-1\nis robotics transformer.",
    "start": "1554120",
    "end": "1562429"
  },
  {
    "text": "It operates at three hertz. It takes in visual\ninput from the robot, or RGB camera, as well as\nnatural language instruction.",
    "start": "1562430",
    "end": "1570409"
  },
  {
    "text": "There the image is\npetrified and fed into a film-EfficientNet\ntokenizer.",
    "start": "1570410",
    "end": "1576320"
  },
  {
    "text": "It's then passed\ninto token learning, which I'll talk about soon. And then also the language\ninstructions are tokenized.",
    "start": "1576320",
    "end": "1582830"
  },
  {
    "text": "And then, they are put\ninto the same transformer. And then, finally, we output the\ndiscretized actions as tokens",
    "start": "1582830",
    "end": "1589580"
  },
  {
    "text": "and send that to the real world\nin three hertz in a closed loop. ",
    "start": "1589580",
    "end": "1595100"
  },
  {
    "text": "This transformer\nis a decoder one. We use a sparse categorical\nentropy objective for action prediction by\napplying a causal mask.",
    "start": "1595100",
    "end": "1603230"
  },
  {
    "text": "We use the pre-trained\nEfficientNet backbone. And we also use token\nlearner for very-- for faster inference.",
    "start": "1603230",
    "end": "1609680"
  },
  {
    "text": "Diving a little bit deeper-- Oh, sorry. Yeah, a question? [INAUDIBLE]? ",
    "start": "1609680",
    "end": "1618440"
  },
  {
    "text": "Great question. So the image token, when it\ngoes in from-- so each image",
    "start": "1618440",
    "end": "1623630"
  },
  {
    "text": "is the high-fidelity RGB\nimage from the camera. We split that up into\n81 separate patches.",
    "start": "1623630",
    "end": "1630080"
  },
  {
    "text": "And so each patch is-- it's spatially just\nlike the square there. But the cool thing is that\nwhat TokenLearner does here,",
    "start": "1630080",
    "end": "1637789"
  },
  {
    "text": "this thing here, is-- it's a\nprevious work from our group that takes in a bunch of\npossible image patches",
    "start": "1637790",
    "end": "1645950"
  },
  {
    "text": "and dynamically selects\nwhich of those image patch tokens are more\nrelevant for the task at hand",
    "start": "1645950",
    "end": "1651950"
  },
  {
    "text": "given the existing context. So from those 81\nimage patch tokens, we sub-sample eight of\nthem to use for inference.",
    "start": "1651950",
    "end": "1659570"
  },
  {
    "text": "And this happens at\nevery time stamp. And that process has learned,\nwhich of the eight patches",
    "start": "1659570",
    "end": "1664600"
  },
  {
    "text": "are relevant at\nany given moment. And otherwise, we're sending\nin way too many tokens.",
    "start": "1664600",
    "end": "1670707"
  },
  {
    "text": "And the context\nlength would explode. And we wouldn't be able\nto do inference on robots. We are also passing in a single\nsequence length of six images.",
    "start": "1670708",
    "end": "1678137"
  },
  {
    "text": "History is quite\nimportant when you're doing temporally coherent\ntasks in the real world where things like physics and exactly\nthis nuanced detail of what",
    "start": "1678137",
    "end": "1686680"
  },
  {
    "text": "the objects are doing in\nrelation to each other and to your robot those\ndetails really matter.",
    "start": "1686680",
    "end": "1692180"
  },
  {
    "text": "And in total, the model size\nis 35 million parameters, which is quite a bit\nsmaller than a lot",
    "start": "1692180",
    "end": "1698770"
  },
  {
    "text": "of these other huge\ninternet-scale models. And finally, one main difference\nhere is action democratization.",
    "start": "1698770",
    "end": "1706360"
  },
  {
    "text": "Before a lot of the products,\nwe are doing continuous control. And if you think about\nit, our robot does have--",
    "start": "1706360",
    "end": "1712480"
  },
  {
    "text": "We do end effector post\ncontrol or position control. And they are-- the real world\nis a continuous state space.",
    "start": "1712480",
    "end": "1718960"
  },
  {
    "text": "And to do that,\nwe had to come up with many algorithmic novelties,\nfor example, a CEM actor that",
    "start": "1718960",
    "end": "1725529"
  },
  {
    "text": "did basically sampling of\nthese continuous action spaces to propose the highest\nones that would get rated by the Q function.",
    "start": "1725530",
    "end": "1731440"
  },
  {
    "text": "And we do this twice,\nblah, blah, blah. But that's so sensitive. But we needed to do that\nto get things to work.",
    "start": "1731440",
    "end": "1736840"
  },
  {
    "text": "But now, we just decided,\nlet's just bin our actions. It's only 256 discrete actions.",
    "start": "1736840",
    "end": "1743230"
  },
  {
    "text": "And let's just predict\nthose as tokens. Any questions? Yeah, what I was\ngoing to ask is-- so I heard you mentioning\nthat you have this design",
    "start": "1743230",
    "end": "1751200"
  },
  {
    "text": "requirement or engineering\nrequirement about speed, latency reaction. I think we say that\nthat necessitates",
    "start": "1751200",
    "end": "1756809"
  },
  {
    "text": "having a relatively small\nmodel, which makes sense. But one of the\nlessons of scaling, when we're talking\nabout foundation models,",
    "start": "1756810",
    "end": "1762442"
  },
  {
    "text": "is that [INAUDIBLE] bottleneck\nby either data or parameters. So I guess what\nI'm curious to know is how do you balance\nthese off in the sense",
    "start": "1762442",
    "end": "1769020"
  },
  {
    "text": "that you want to have lots of\nparameters that have a really powerful model, but\non the other hand, you want to have\nvery [INAUDIBLE]??",
    "start": "1769020",
    "end": "1775100"
  },
  {
    "text": "Yeah, great question. And to repeat it,\nthe question is, we set a pretty hard\nconstraint with 100 millisecond",
    "start": "1775100",
    "end": "1781010"
  },
  {
    "text": "inference time, yet,\na lot of the lessons in foundation modeling is that\nyou shouldn't be constraining yourself against any dimension,\nwhether it's data set size,",
    "start": "1781010",
    "end": "1788270"
  },
  {
    "text": "compute or model capacity. And I think my\ninitial answer to that is that's a very great\npoint and something",
    "start": "1788270",
    "end": "1793730"
  },
  {
    "text": "I think that's going\nto be coming up as a severe bottleneck\nin the future. But for our initial\ncase, I think",
    "start": "1793730",
    "end": "1799789"
  },
  {
    "text": "this is more of an exploration\nof whether these principles and even scaling,\nwell, beyond what we were looking at now to work.",
    "start": "1799790",
    "end": "1805850"
  },
  {
    "text": "Already, this 35\nmillion is gigantic compared to a lot of prior work\nusing, for example, a ResNet",
    "start": "1805850",
    "end": "1812059"
  },
  {
    "text": "34 or whatnot. So this is already much bigger\nthan a lot of other options. And maybe, for now, at\nleast, it's the easiest.",
    "start": "1812060",
    "end": "1819620"
  },
  {
    "text": "It's the largest scale\nwe could go to, roughly, in the short term without\nhaving to think of more tricks.",
    "start": "1819620",
    "end": "1825616"
  },
  {
    "text": "[INAUDIBLE] I guess that's more\njust an [INAUDIBLE].. Got it. Yeah, we can talk\nabout it a bit later.",
    "start": "1825616",
    "end": "1831080"
  },
  {
    "text": "Maybe I think I'd also love\nto hear your thoughts, too, because it's very\nnon-obvious how we can get past some of these bottlenecks.",
    "start": "1831080",
    "end": "1838340"
  },
  {
    "text": "So what [INAUDIBLE] this. Say I give you [INAUDIBLE],, but\neverything else is the same.",
    "start": "1838340",
    "end": "1845015"
  },
  {
    "text": "The data is the same. Requirements are the same. Do you think we see\nsignificant improvements, even",
    "start": "1845015",
    "end": "1850190"
  },
  {
    "text": "some emergent behavior\n[INAUDIBLE] pipeline for these bigger models? Or do you think\nthere's more to this",
    "start": "1850190",
    "end": "1855860"
  },
  {
    "text": "than just scaling down and\nreliability [INAUDIBLE]?? Yeah, a great question.",
    "start": "1855860",
    "end": "1861169"
  },
  {
    "text": "We ran some ablations\non model size. I might have that\nin a few slides.",
    "start": "1861170",
    "end": "1866610"
  },
  {
    "text": "But maybe we can\nreturn to that then. And if not, we-- I can-- [INAUDIBLE] Yeah, but a great question.",
    "start": "1866610",
    "end": "1874890"
  },
  {
    "text": "So yeah, that's\nthe architecture. And I'll discuss some of\nthe ablations to the trends later on. But maybe this is\na robotics lecture.",
    "start": "1874890",
    "end": "1881760"
  },
  {
    "text": "I should show you\nsome pretty visuals. So let's look at some\nevaluations we did.",
    "start": "1881760",
    "end": "1887252"
  },
  {
    "text": "We compared against\nsome baselines. One is GATO, which you\nmight be familiar with. And then other--\nthe other one is",
    "start": "1887252",
    "end": "1893929"
  },
  {
    "text": "BC-zero, the ResNet baseline. And we find that we evaluate on\nseen tasks versus unseen tasks.",
    "start": "1893930",
    "end": "1899240"
  },
  {
    "text": "And we also add in various\ndistractor objects. Our normal data collection looks\nlike this top-left picture,",
    "start": "1899240",
    "end": "1904940"
  },
  {
    "text": "three cans on a gray desk. That's basically it. But then we push it further by\nbringing in a lot more objects",
    "start": "1904940",
    "end": "1911488"
  },
  {
    "text": "so that the table is\nso cluttered that even as a human, sometimes it's hard\nto find the object that you're actually looking for.",
    "start": "1911488",
    "end": "1917090"
  },
  {
    "text": "We add in tablecloths to make\nthe textures very different. We bring it to new micro\nkitchens, with new surfaces",
    "start": "1917090",
    "end": "1923210"
  },
  {
    "text": "altogether. And we find that RT-1\nis more robust than these other different methods.",
    "start": "1923210",
    "end": "1928962"
  },
  {
    "text": "[INAUDIBLE] this\nmodel on this layout?",
    "start": "1928962",
    "end": "1935000"
  },
  {
    "text": "Or would the GATO be only\ntrained by this specific robot hardware? Good question. The question was from the GATO.",
    "start": "1935000",
    "end": "1941300"
  },
  {
    "text": "Was the GATO model\ntrained on our data, or was it just already\nincluded in GATO?",
    "start": "1941300",
    "end": "1946490"
  },
  {
    "text": "The answer is this data\nwas not included in GATO. And so, we retrained the\nGATO model only on our data.",
    "start": "1946490",
    "end": "1951559"
  },
  {
    "text": " So here's just a\ndifferent visualization of the robot going out\nin our micro kitchen",
    "start": "1951560",
    "end": "1957582"
  },
  {
    "text": "and doing different\ninteresting things. You can see here that it's\ntrained on one setting, but then it goes into\na brand new kitchen,",
    "start": "1957582",
    "end": "1964190"
  },
  {
    "text": "brand new countertops,\nnew objects, and it's able to do all\nof them pretty robustly. We also put it into a\nlong-horizon setting",
    "start": "1964190",
    "end": "1973160"
  },
  {
    "text": "using the SayCan framework\nthat we'll talk about next. But in these settings,\na lot of them",
    "start": "1973160",
    "end": "1978320"
  },
  {
    "text": "are mixing all of these\ngeneralization capabilities. And on the plot-- on\nthe left here, we're using what we call\ngeneralization levels inspired",
    "start": "1978320",
    "end": "1984679"
  },
  {
    "text": "by the VIMA paper that\nwould basically increasingly change more factors of\nvariation simultaneously.",
    "start": "1984680",
    "end": "1991010"
  },
  {
    "text": "And here, we found RT-1\nis the most robust. [INAUDIBLE] How do you [INAUDIBLE]?",
    "start": "1991010",
    "end": "1996993"
  },
  {
    "text": " Yeah, a good question.",
    "start": "1996994",
    "end": "2002087"
  },
  {
    "text": "We'll go into a bit\nmore detail later. But I think at a high\nlevel, teleoperators get a structured\ntemplate command",
    "start": "2002087",
    "end": "2007810"
  },
  {
    "text": "of like, verb, noun, verb, or\nsomething, like \"pick coke can\" or \"move apple near sponge.\"",
    "start": "2007810",
    "end": "2015910"
  },
  {
    "text": "We have around 700\ntasks set up this way. And they go ahead and collect\nthat data, press Done. And then later we\nhave-- we make sure",
    "start": "2015910",
    "end": "2023350"
  },
  {
    "text": "that successes are\nactually successes, and we discard stuff\nthat's unsafe, for example. [INAUDIBLE]",
    "start": "2023350",
    "end": "2030580"
  },
  {
    "text": "Oh, yeah, I got\nit for this paper. We utilized 130,000\ndemonstrations for this, yeah.",
    "start": "2030580",
    "end": "2036466"
  },
  {
    "text": "[INAUDIBLE] ",
    "start": "2036466",
    "end": "2042580"
  },
  {
    "text": "Is there any [INAUDIBLE]? ",
    "start": "2042580",
    "end": "2050590"
  },
  {
    "text": "Yeah, a great question. I think a lot of\nprior work has also noted that when you have, for\nexample-- oh, the question was,",
    "start": "2050590",
    "end": "2057250"
  },
  {
    "text": "did you find that the\ntrajectories in your data set were very multi-modal? And I think what you mean by\nthat is that to go from point A",
    "start": "2057250",
    "end": "2064810"
  },
  {
    "text": "to point B, I can go\nleft, or I can go right, or I can go straight. And I think this kind of\ndiversity in, basically,",
    "start": "2064810",
    "end": "2072309"
  },
  {
    "text": "for a single image\nstate, but yet, my data has three possible\nlabels, that can have",
    "start": "2072310",
    "end": "2077379"
  },
  {
    "text": "very bad effects sometimes. For us, I think, because\nwe are using teleoperator demonstrations, the data was\nmore homogeneous than perhaps",
    "start": "2077380",
    "end": "2085570"
  },
  {
    "text": "in the wild. For example, there's a type of\ndata collection called PlayData where operators just\ndo whatever they want, and we label in hindsight.",
    "start": "2085570",
    "end": "2091669"
  },
  {
    "text": "And I think our data is\nmore homogeneous than that. But we did not find\na lot of the issues that we've seen\nin prior projects.",
    "start": "2091670",
    "end": "2097420"
  },
  {
    "text": "One potential answer is maybe\nit's the architecture itself. But we can talk\nabout that later too.",
    "start": "2097420",
    "end": "2104302"
  },
  {
    "text": "Yeah, a question? [INAUDIBLE] when it comes to\nterminating actions, how do we determine [INAUDIBLE]?",
    "start": "2104302",
    "end": "2111080"
  },
  {
    "text": " That is great question. We actually do have\na termination action.",
    "start": "2111080",
    "end": "2117240"
  },
  {
    "text": "So the policy itself,\nthe-- so the question was, how do you determine when\nan episode is complete? And the policy is able\nto predict-terminate",
    "start": "2117240",
    "end": "2124940"
  },
  {
    "text": "because at the end of each\nteleoperation session, the operator can click\na button, and it's smart as the episode's done.",
    "start": "2124940",
    "end": "2130600"
  },
  {
    "text": "[INAUDIBLE] ",
    "start": "2130600",
    "end": "2138980"
  },
  {
    "text": "Yeah, I think for\nthese evaluations, we were quite strict. But definitely, I\nthink in some cases--",
    "start": "2138980",
    "end": "2144560"
  },
  {
    "text": "maybe if we're just doing\nan experiment for ourselves, we'll have a dense\nreward scale of grasp",
    "start": "2144560",
    "end": "2150890"
  },
  {
    "text": "the object and move\ncloser, grasp the object and almost got there\nbut mess up at the end. And we'll have a grading\ncurve, basically.",
    "start": "2150890",
    "end": "2156950"
  },
  {
    "text": "But for all of these\nstats I'm showing here, it was zero or one. One, fully complete.",
    "start": "2156950",
    "end": "2162440"
  },
  {
    "text": "Zero was not fully complete. ",
    "start": "2162440",
    "end": "2168330"
  },
  {
    "text": "And I think what\nwas exciting, maybe talking about the\nmulti-modality aspect is then we pushed the\nlimit even further.",
    "start": "2168330",
    "end": "2174300"
  },
  {
    "text": "We decided to train on very\ndiverse data distributions. Your math background, yeah.",
    "start": "2174300",
    "end": "2180440"
  },
  {
    "text": "OK. So right now, you saw\n130,000 demonstrations train on this everyday-robot or\npreparatory mobile manipulator.",
    "start": "2180440",
    "end": "2189540"
  },
  {
    "text": "But we were also looking to\ntrain on very different data distributions with very\ndifferent action distributions,",
    "start": "2189540",
    "end": "2195059"
  },
  {
    "text": "very different trajectories,\neven very different visuals, objects, tasks. And to do that, we included\ntwo other data sources.",
    "start": "2195060",
    "end": "2201580"
  },
  {
    "text": "One was simulation data, which\nwas our robot but [INAUDIBLE],, but it looked quite different. And also, this\ndata was collected",
    "start": "2201580",
    "end": "2208590"
  },
  {
    "text": "with reinforcement\nlearning and not with teleoperator\ndemonstrations. In the past, with all the IO\nplus RL work that I mentioned,",
    "start": "2208590",
    "end": "2215610"
  },
  {
    "text": "we found that combining\nthese two types of data was going to be very\ndifficult because RL data has",
    "start": "2215610",
    "end": "2221760"
  },
  {
    "text": "very short actions. It's very quick. That's very optimized for\nthe specific reward function",
    "start": "2221760",
    "end": "2226799"
  },
  {
    "text": "versus human-collected\nteleoperation data is a lot more\nhuman-like, so to speak.",
    "start": "2226800",
    "end": "2232080"
  },
  {
    "text": "And finally, we revived a\ndata set from many years ago, in 2018. If you remember\nthe KUKA Project,",
    "start": "2232080",
    "end": "2237953"
  },
  {
    "text": "that arm farm has now been\noperational in that state for many years now. But we had that data still. And so, we were hoping to\nsee if a different robot",
    "start": "2237953",
    "end": "2245610"
  },
  {
    "text": "with a different action\nspace on different objects with different visuals\nin a different building could still be combined with\ndata from this macro kitchen",
    "start": "2245610",
    "end": "2254845"
  },
  {
    "text": "data set that we\ntrained on originally. And what was very\nsurprising to me is that RT-1 was able to\nlearn from all of these very",
    "start": "2254845",
    "end": "2261270"
  },
  {
    "text": "diverse data distributions. I had never seen a result like\nthis or any other architecture, for example, a ResNet or\neven another learning method,",
    "start": "2261270",
    "end": "2269520"
  },
  {
    "text": "like reinforcement\nlearning, could successfully learn on such different data\ndistributions so robustly.",
    "start": "2269520",
    "end": "2275400"
  },
  {
    "text": "And we evaluated, for example,\non combining concepts. So we would have the original\neveryday-robot robot pick up",
    "start": "2275400",
    "end": "2282750"
  },
  {
    "text": "objects that were only\nseen in the KUKA Project, or we would put objects\nonly seen in simulation",
    "start": "2282750",
    "end": "2287817"
  },
  {
    "text": "and see if our policy\ncould understand that. So it did seem like it could\ngeneralize between objects that's seen in other\ndata sets and concepts",
    "start": "2287817",
    "end": "2293891"
  },
  {
    "text": "that it had seen\nin other data sets into the setting it was in\nnow in the real micro kitchen. And that was a very fun result.",
    "start": "2293892",
    "end": "2301365"
  },
  {
    "text": "[INAUDIBLE] has a question. How did we combine the action\nspaces of the everyday robot with the KUKA?",
    "start": "2301365",
    "end": "2307020"
  },
  {
    "text": "Great question. Yeah, we just\ntokenized the image so that the tokenization\nscheme was interoperable.",
    "start": "2307020",
    "end": "2313470"
  },
  {
    "text": "But I think that was the-- yeah, I can dive into\nthat in a bit later too. OK. Yeah.",
    "start": "2313470",
    "end": "2319720"
  },
  {
    "text": "And note that does\nnot mean we can't send the exact actions\nfor one robot to another and have it execute. It was more just like--",
    "start": "2319720",
    "end": "2325545"
  },
  {
    "text": "in the data set, I think,\neven by human inspection, you can tell that\nthese are coming from two different robots.",
    "start": "2325545",
    "end": "2331460"
  },
  {
    "text": "So yeah, let's look at some\nablations for the scaling loss that we're all here for now. We found that reducing data\nsite size reduces performance,",
    "start": "2331460",
    "end": "2339560"
  },
  {
    "text": "but more interesting,\nmaybe, is tasks diversity was quite important. Here, we have two\ndifferent trends.",
    "start": "2339560",
    "end": "2346579"
  },
  {
    "text": "The green line is\nwhat happens when you reduce the total amount\nof episodes per a task.",
    "start": "2346580",
    "end": "2351859"
  },
  {
    "text": "And then gray here--\nthe purple curve is for what happens\nwhen you reduce the total number of tasks.",
    "start": "2351860",
    "end": "2358160"
  },
  {
    "text": "And we found that\nhaving more tasks is relatively more\nimportant than having more data for each task.",
    "start": "2358160",
    "end": "2365270"
  },
  {
    "text": "And I think this was a lesson\nthat I think is probably going to suggest ways that\nwe should scale robotics",
    "start": "2365270",
    "end": "2371720"
  },
  {
    "text": "even further. It's not to just collect\nmore data of the same task in the same settings but\nto go out into the wild",
    "start": "2371720",
    "end": "2377510"
  },
  {
    "text": "and get more diverse behavior. Quick question. How do you define\ndiversity in the data?",
    "start": "2377510",
    "end": "2383775"
  },
  {
    "text": "Great question. The question is, how do\nyou define data diversity? In this case, it's\njust a number of",
    "start": "2383775",
    "end": "2389670"
  },
  {
    "text": "unique structure-templated\ncommands that teleoperators receive. So those 700 templated commands,\nwhen we start reducing them",
    "start": "2389670",
    "end": "2396990"
  },
  {
    "text": "and only train on 500 or\nonly trained on 300 of them, performance drops much\nquicker than if we",
    "start": "2396990",
    "end": "2402190"
  },
  {
    "text": "had taken the same proportional\ncuts to the total number. Yeah. OK.",
    "start": "2402190",
    "end": "2407210"
  },
  {
    "text": "So I guess I'm very [INAUDIBLE]. ",
    "start": "2407210",
    "end": "2414300"
  },
  {
    "text": "It seems almost [INAUDIBLE]\ntipping point [INAUDIBLE].. ",
    "start": "2414300",
    "end": "2422430"
  },
  {
    "text": "Yeah, I don't think we-- the question was\nthere seems to be almost a linear correlation\nbetween a data size and success",
    "start": "2422430",
    "end": "2428510"
  },
  {
    "text": "rate. And I think we could\napply some fancy scaling law, trying to curve fitting.",
    "start": "2428510",
    "end": "2434069"
  },
  {
    "text": "But we didn't look\ntoo much into that because this is a\ntrend that we expected. We just weren't sure\nabout the magnitude",
    "start": "2434070",
    "end": "2440910"
  },
  {
    "text": "of how much it would affect us. And I think I don't have\nany really good insights",
    "start": "2440910",
    "end": "2447119"
  },
  {
    "text": "on this besides that we see\nthis phenomenon empirically. Yeah. [INAUDIBLE]",
    "start": "2447120",
    "end": "2452589"
  },
  {
    "text": "It would seem that [INAUDIBLE]\nthere should be less [INAUDIBLE] make this\n100% or [INAUDIBLE]??",
    "start": "2452590",
    "end": "2466830"
  },
  {
    "text": "Great question. So the question\nis, Oh, maybe this will just go on indefinitely,\nor is there something magical about January 2023?",
    "start": "2466830",
    "end": "2473100"
  },
  {
    "text": "But I think this is maybe also-- This is when we\nstart to conflate",
    "start": "2473100",
    "end": "2478440"
  },
  {
    "text": "the algorithmic exploration with\nthe practical considerations of scaling real-world\noperations, which was,",
    "start": "2478440",
    "end": "2483990"
  },
  {
    "text": "we got enough data, our\npolicies were hitting, saturating on these\nhitting close to 100%. We're like, all right, let's\ncollect another data set.",
    "start": "2483990",
    "end": "2490810"
  },
  {
    "text": "So we basically collect\nuntil it's at 100 and then we switch\nto something else. But at this point\nwhat was interesting",
    "start": "2490810",
    "end": "2496740"
  },
  {
    "text": "is that we bet really big\non this RT-1 architecture. We'd already been collecting\ndemos for a while.",
    "start": "2496740",
    "end": "2502109"
  },
  {
    "text": "So it was possible that we had\ncollected more than we needed. And in some cases, actually,\nyou could cut tasks",
    "start": "2502110",
    "end": "2507480"
  },
  {
    "text": "without losing too\nmuch performance, which was quite interesting. [INAUDIBLE]",
    "start": "2507480",
    "end": "2513192"
  },
  {
    "text": "It says it needs\n[INAUDIBLE] data",
    "start": "2513192",
    "end": "2519855"
  },
  {
    "text": "that might be more diverse among\nthe different tasks [INAUDIBLE]",
    "start": "2519855",
    "end": "2524913"
  },
  {
    "text": "the same task? Yeah. If you just use the same\nobject for all the tasks",
    "start": "2524913",
    "end": "2530490"
  },
  {
    "text": "or the same [INAUDIBLE]. ",
    "start": "2530490",
    "end": "2538500"
  },
  {
    "text": "Great question. And the question\nis whether or not all tasks are created equal\nin terms of their capacity and entropy for\ndifferent behaviors you",
    "start": "2538500",
    "end": "2544260"
  },
  {
    "text": "can learn from them. And yeah, that's\ndefinitely true. Some tasks are much easier. We have a task that's just\n\"pick up this object.\"",
    "start": "2544260",
    "end": "2549690"
  },
  {
    "text": "That's going to have much\nless interesting stuff you can squeeze out of it\nthan removing something into a drawer and then\nclosing the drawer.",
    "start": "2549690",
    "end": "2556408"
  },
  {
    "text": "That's, yeah, a great question.  Great. Now, ablations, we also trained\nwithout the big model size.",
    "start": "2556408",
    "end": "2564800"
  },
  {
    "text": "We did it without\npre-training, without-- with continuous instead\nof discrete actions, with autoregressive\nactions, without history,",
    "start": "2564800",
    "end": "2571870"
  },
  {
    "text": "without the transformer. And I think all of\nthese design choices did seem to be required\nfor robust performance.",
    "start": "2571870",
    "end": "2580414"
  },
  {
    "text": "[INAUDIBLE] Oh, yeah, of course. [INAUDIBLE] ",
    "start": "2580414",
    "end": "2590430"
  },
  {
    "text": "[INAUDIBLE] Yeah, I think all the-- and, again, for\npaper writing, it's",
    "start": "2590430",
    "end": "2597910"
  },
  {
    "text": "the best thing that we\ncan empirically find. That's the method. And then, we'll figure out why\neach of these are important.",
    "start": "2597910",
    "end": "2603938"
  },
  {
    "text": "And so, yeah. I think one surprising\nthing here, perhaps, was that autoregressive\nactions hurt. You might think that\npassing in more information",
    "start": "2603938",
    "end": "2610540"
  },
  {
    "text": "is always better than\npassing in fewer information. But in this case,\nmaybe conditioning",
    "start": "2610540",
    "end": "2615760"
  },
  {
    "text": "on your previous actions was\ndoing in-context learning. It was doing online\nsystems identification",
    "start": "2615760",
    "end": "2622000"
  },
  {
    "text": "to figure out what teleoperator\nthis data came from and how you can overfit that\nspecific set of action history.",
    "start": "2622000",
    "end": "2629680"
  },
  {
    "text": "And so removing that\nwas actually better, one interesting tidbit there.",
    "start": "2629680",
    "end": "2636590"
  },
  {
    "text": "Cool then. And maybe in the\ninterest of time, I'll try to get through the\nother ones a bit more quicker.",
    "start": "2636590",
    "end": "2643250"
  },
  {
    "text": "And then we can\nmaybe just do a few, or I'll just do the\nquestions at the end if that's possible,\njust so we have",
    "start": "2643250",
    "end": "2648500"
  },
  {
    "text": "time to get through everything. The next work here, moving a bit\naway from skill learning then, and actually on to\nthe planning level,",
    "start": "2648500",
    "end": "2655000"
  },
  {
    "text": "I think the first project\ntook a lot of the design principles of other fields\nand all this offline robot",
    "start": "2655000",
    "end": "2660130"
  },
  {
    "text": "learning paradigm and put\nit into the skill learning. So it actually bring\nthat out to other parts of the robotic system.",
    "start": "2660130",
    "end": "2665960"
  },
  {
    "text": "And the first work\nhere is SayCan. If you remember here, back\nin this timeline, in 2022, we started thinking\nabout, Oh, yeah, how do we",
    "start": "2665960",
    "end": "2672550"
  },
  {
    "text": "scale this multi-task imitation\nlearning, but at the same time, large language models and other\ntypes of foundation models",
    "start": "2672550",
    "end": "2680320"
  },
  {
    "text": "are really picking\nup steam, whether it was imaging or DALL-E 2. And we definitely\nwanted to figure out",
    "start": "2680320",
    "end": "2685660"
  },
  {
    "text": "how we could use those as well. We had come up with\nthis [INAUDIBLE] design that we're betting big on. But from here, we\nstarted to explore how",
    "start": "2685660",
    "end": "2693430"
  },
  {
    "text": "all of the bitter lessons 2.0-- we could start utilizing\nfoundation models within the context of\nour full stack system.",
    "start": "2693430",
    "end": "2701599"
  },
  {
    "text": "The problem of\ndoing this naively is that language models\nare not completely a very natural fit for robotics.",
    "start": "2701600",
    "end": "2707440"
  },
  {
    "text": "For example, if you're\na robot in a kitchen, you ask the language\nmodel, \"I spilled my drink. What can you do?\" Language model will give you\nstuff that's not very relevant.",
    "start": "2707440",
    "end": "2714610"
  },
  {
    "text": "It's going to ask\nyou to vacuum it, it's going to ask you\nto call a cleaner, or it's going to apologize. And these are not\nthings that the robot",
    "start": "2714610",
    "end": "2720550"
  },
  {
    "text": "can do in your kitchen with\nyour spilled drink to help you. And so there are two\nparts of this then.",
    "start": "2720550",
    "end": "2726830"
  },
  {
    "text": "The one issue is that\nour robots are limited. They are very constrained\nwith what they can do.",
    "start": "2726830",
    "end": "2732267"
  },
  {
    "text": "They cannot do everything. But they can do certain things. And then the second problem\nis that the language models",
    "start": "2732267",
    "end": "2738980"
  },
  {
    "text": "are also constrained. They don't know\nwhat the robot sees. They don't understand that\nthey are in a robot body in a micro kitchen,\nneeding to do real stuff",
    "start": "2738980",
    "end": "2746210"
  },
  {
    "text": "in the physical world. And so, we need to get the\nrobots to speak language model language and then the language\nmodel to speak robot language.",
    "start": "2746210",
    "end": "2754970"
  },
  {
    "text": "To do this, we present SayCan. In the same setting, \"please\nput an apple on the table.\"",
    "start": "2754970",
    "end": "2760520"
  },
  {
    "text": "We score the predictions\nof the language model on a constrained\nset of tasks that we",
    "start": "2760520",
    "end": "2765530"
  },
  {
    "text": "know the robot has\nbeen trained to do. And then, we also take\nthe affordance function from the robot. And the affordance function\nis an estimation of,",
    "start": "2765530",
    "end": "2773300"
  },
  {
    "text": "given some kind of state,\nwhat the robot is able to do, how confident it is that it\ncan successfully accomplish",
    "start": "2773300",
    "end": "2779240"
  },
  {
    "text": "that task in the given state. In our case, we use something\nlike a value function for reinforcement learning\nwhich accomplishes this quality.",
    "start": "2779240",
    "end": "2785780"
  },
  {
    "text": "Given these two values,\nthese two scores, we have the confidence\nfrom a language model and then the confidence\nfrom the robot.",
    "start": "2785780",
    "end": "2791820"
  },
  {
    "text": "We can combine these. And then, hopefully,\nthe combined prediction is both something that's\ngoing to be very semantically",
    "start": "2791820",
    "end": "2797090"
  },
  {
    "text": "relevant for the\nhigh-level instruction. Finding an apple\nis the first step and, \"please put an\napple on the table.\"",
    "start": "2797090",
    "end": "2802372"
  },
  {
    "text": "But it's also something\nthat the robot can do. There's no robot in\nthe frame, but it knows that it's been\ntrained to find an apple.",
    "start": "2802373",
    "end": "2807980"
  },
  {
    "text": "So it can navigate\naround to find it. And so, hopefully, we can do\nthis then in a closed loop and then keep on\ngoing and predicting",
    "start": "2807980",
    "end": "2813829"
  },
  {
    "text": "a high-level plan from\nthe language model that's grounded with the\naffordance function of what the robot understands.",
    "start": "2813830",
    "end": "2821410"
  },
  {
    "text": "There's a video here of the\nSayCan doing different stuff, but happy to share\nit later offline.",
    "start": "2821410",
    "end": "2827260"
  },
  {
    "text": "It's very cool, trust me. It's the greatest thing\nsince sliced bread. ",
    "start": "2827260",
    "end": "2836010"
  },
  {
    "text": "And, yeah, some numbers, then. We tested this out on very\nlong-horizon instructions,",
    "start": "2836010",
    "end": "2841470"
  },
  {
    "text": "encompassing more than\n10 separate navigation and manipulation skills\nin the micro kitchen",
    "start": "2841470",
    "end": "2846660"
  },
  {
    "text": "that you see on\nthe bottom right. We evaluated hundreds of\ndifferent evaluations on this.",
    "start": "2846660",
    "end": "2853050"
  },
  {
    "text": "And we tested out very-- a\nlot of different concepts, including things like rephrasing\nby using single primitives",
    "start": "2853050",
    "end": "2858809"
  },
  {
    "text": "by drawing instructions that\njust came from colleagues and friends. And then we found that\nwhile they were failures",
    "start": "2858810",
    "end": "2867030"
  },
  {
    "text": "in both the language model\nplanning stuff side, where it would predict the wrong\npath for the current situation,",
    "start": "2867030",
    "end": "2872190"
  },
  {
    "text": "as well as on a policy execution\nside, even when it gets a good plan, the robot\nwill mess up sometimes, overall, it was still\ndoing quite well.",
    "start": "2872190",
    "end": "2881410"
  },
  {
    "text": "And now, let's kick\nthis back to the lesson. I think this is a very\ngreat example of how",
    "start": "2881410",
    "end": "2887940"
  },
  {
    "text": "we can leverage internet\nscale foundation models as they get better. When we started the project, we\nstarted with a language model",
    "start": "2887940",
    "end": "2894810"
  },
  {
    "text": "called FLAN from Google. Throughout our\nimplementation, our PaLM came online, Pathways\nLanguage Model.",
    "start": "2894810",
    "end": "2900810"
  },
  {
    "text": "And when that happened, we were\nable to just hot-swap it in. And performance just\ngot better for free",
    "start": "2900810",
    "end": "2907020"
  },
  {
    "text": "without us having\nto do anything. By just assuming that\nlanguage was the API, the plan just has\nto be any string.",
    "start": "2907020",
    "end": "2912843"
  },
  {
    "text": "It can come from any source. It can come from a human. It can come from\na language model. When we improve\nthat language model,",
    "start": "2912843",
    "end": "2917940"
  },
  {
    "text": "the system gets better overall. And here you see,\nwith a scaling size, as the model LLM\nincreased in size,",
    "start": "2917940",
    "end": "2924360"
  },
  {
    "text": "our planning performance\ngot even better. ",
    "start": "2924360",
    "end": "2930440"
  },
  {
    "text": "And some cool tricks here\nto get it working, well, how do we actually\nproduce this plan? Well, while just by prompting\nas is the rage these days,",
    "start": "2930440",
    "end": "2938390"
  },
  {
    "text": "with chain-of-thought and\nwith better prompting, of just giving it examples of, here\nare some great robot plans,",
    "start": "2938390",
    "end": "2943940"
  },
  {
    "text": "now give me a new\nplan starting with this high-level instruction. We saw that the robot\ncould do all things,",
    "start": "2943940",
    "end": "2949370"
  },
  {
    "text": "from understanding different\nlanguages to asking them to do very complex\nreasoning, like hey,",
    "start": "2949370",
    "end": "2955577"
  },
  {
    "text": "give me something caffeinated\nor \"I don't do caffeine anymore. Get me something better.\" Or bring me a healthy\nsnack versus bring me",
    "start": "2955577",
    "end": "2962480"
  },
  {
    "text": "an unhealthy snack. So they can was able to\nreason through all of these.",
    "start": "2962480",
    "end": "2968110"
  },
  {
    "text": "But I think that was our kind\nof the first contact of robotics with language\nmodels on our team.",
    "start": "2968110",
    "end": "2974260"
  },
  {
    "text": "And it was the first\nexploration into how these two worlds could overlap. There were definitely\nstill improvements, though.",
    "start": "2974260",
    "end": "2980130"
  },
  {
    "text": "And in Inner Monologue, we\ntry to improve those further by bringing in vision\nlanguage models.",
    "start": "2980130",
    "end": "2985400"
  },
  {
    "text": "The idea here is that we\nhad a very high planned rate success with SayCan,\nbut unfortunately, it",
    "start": "2985400",
    "end": "2992839"
  },
  {
    "text": "wasn't really able to\nrecover from failures. What I mean by that is that the\nlanguage model would not really get updates of what was\ngoing on in the world.",
    "start": "2992840",
    "end": "2999930"
  },
  {
    "text": "So that if this was the plan\nit proposed, go to the table, pick up a coke, bring it\nto you, but you messed up picking the coke can,\nyou drop it on the floor,",
    "start": "2999930",
    "end": "3006950"
  },
  {
    "text": "it would still continue\ntrying to bring it to you. Put it aside. But all of that does not\nreally matter anymore because you drop the coke can.",
    "start": "3006950",
    "end": "3012650"
  },
  {
    "text": "And so, in this work,\nInner Monologue, we are really\nhoping to figure out how we could add\nclosed-loop dynamic feedback",
    "start": "3012650",
    "end": "3020260"
  },
  {
    "text": "from the environment into\nthis planning process. Let's take that\nexact same example.",
    "start": "3020260",
    "end": "3026490"
  },
  {
    "text": "Now, instead of just directly\ncorrecting every instruction, maybe we add back some\nfeedback from the scene",
    "start": "3026490",
    "end": "3031859"
  },
  {
    "text": "also conveyed using language\nas the universal API here. The scene can tell you\nwhat's actually in there.",
    "start": "3031860",
    "end": "3037650"
  },
  {
    "text": "Maybe the robot asks a\nquestion now in the robot. This is the language model\nasking the clarification question.",
    "start": "3037650",
    "end": "3043200"
  },
  {
    "text": "Maybe hear a human response\nor another language model, then you can predict the\naction or the next task",
    "start": "3043200",
    "end": "3048600"
  },
  {
    "text": "to do once the language\nmodel has enough context. And maybe you even add in\nstuff like success detection,",
    "start": "3048600",
    "end": "3054210"
  },
  {
    "text": "and so on and so forth. How do we do this, then? Well, the first thing\nthat we implement",
    "start": "3054210",
    "end": "3060120"
  },
  {
    "text": "is what we call passive\nscene description. Just using either an\noff-the-shelf engineer",
    "start": "3060120",
    "end": "3065250"
  },
  {
    "text": "heuristic, using object\ndetection models, something like ViLD, you can\ndescribe the scene in text",
    "start": "3065250",
    "end": "3070920"
  },
  {
    "text": "and just convey all of that\ncontext to the language model. For active scene\ndescription, this",
    "start": "3070920",
    "end": "3076750"
  },
  {
    "text": "is maybe similar to\nvisual question answering if you're familiar\nwith that field. The language model can\nactually propose active queries",
    "start": "3076750",
    "end": "3083980"
  },
  {
    "text": "that it's curious\nabout in the scene, maybe to make sure that it\nhas enough context to move on. And here, either a human\ncan provide the answer,",
    "start": "3083980",
    "end": "3091120"
  },
  {
    "text": "or in the future, a VQA\nmodel, as they improve, can provide that.",
    "start": "3091120",
    "end": "3096390"
  },
  {
    "text": "And finally, for\nsuccess detection, this is very important to allow\nthe language model planner to know when to try\nto retry something.",
    "start": "3096390",
    "end": "3103790"
  },
  {
    "text": "Here, we take in the first\nand last image, fine-tune a [INAUDIBLE] success\ndetector, and use that to provide binary\nsuccess/failure information",
    "start": "3103790",
    "end": "3111680"
  },
  {
    "text": "back to our language model.  And for the--",
    "start": "3111680",
    "end": "3117320"
  },
  {
    "text": "Results wise, we can see a very\nsimilar SayCan long-horizon evaluation, but\nhere we actually--",
    "start": "3117320",
    "end": "3123380"
  },
  {
    "text": "what's interesting is\nthat we're able to-- and basically implement all\nof these different automated",
    "start": "3123380",
    "end": "3129260"
  },
  {
    "text": "feedback mechanisms\non the robot, and so that it's able to reason\nand recover from things.",
    "start": "3129260",
    "end": "3134390"
  },
  {
    "text": "Here, you see, it's going\nto try to go to the table. But the humans actually\nhave been saying, hey,",
    "start": "3134390",
    "end": "3141210"
  },
  {
    "text": "I changed my mind. And then it changes-- the\nhuman change its mind again, asking it to go back and forth. And the robot's able to-- maybe\nwe're torturing the language",
    "start": "3141210",
    "end": "3148527"
  },
  {
    "text": "model at this point. But the language is able\nto replan and make sure that the human\nintent is satisfied.",
    "start": "3148527",
    "end": "3154130"
  },
  {
    "text": " We also tried.",
    "start": "3154130",
    "end": "3159180"
  },
  {
    "text": "I'm not sure if\nthis video shows it. But situations where we did\nadversarial inputs where I walked around and just--",
    "start": "3159180",
    "end": "3165422"
  },
  {
    "text": "knocking objects out\nof the robot's hands and forcing the success detector\nto tell it, hey, you messed up.",
    "start": "3165422",
    "end": "3170785"
  },
  {
    "text": "Try again. ",
    "start": "3170785",
    "end": "3177130"
  },
  {
    "text": "And we also tried\nthis out on a couple of different domains, a\nsimulated tabletop manipulation domain as well as a real-world\nmanipulation domain.",
    "start": "3177130",
    "end": "3184359"
  },
  {
    "text": "And we found that\nthis was much better than SayCan or, let's\nsay, just only using",
    "start": "3184360",
    "end": "3189910"
  },
  {
    "text": "visual features themselves,\nwith something like CLIPort. And I think here, it really\nspeaks towards a trend",
    "start": "3189910",
    "end": "3198339"
  },
  {
    "text": "that I really come\nto appreciate. In 2018, a robotics\nprofessor once said that when they looked at\nall of the different things",
    "start": "3198340",
    "end": "3204670"
  },
  {
    "text": "preventing robot learning\nfrom scaling tremendously, they thought the bottleneck was\nhigh-level semantic planning, about reasoning,\nabout common sense.",
    "start": "3204670",
    "end": "3211130"
  },
  {
    "text": "And I think in 2022 and\n2023, language models can provide one path of\nhow this can be offloaded,",
    "start": "3211130",
    "end": "3219400"
  },
  {
    "text": "at least in the interim. And I think if language\nmodels are the API, then you can just bring in\nthese vision language models.",
    "start": "3219400",
    "end": "3226510"
  },
  {
    "text": "As object detectors get\nbetter, as success detectors, as VQA, as language\nmodels get better, you can bring them\nall into the fold.",
    "start": "3226510",
    "end": "3232600"
  },
  {
    "text": "And the act is a life vest. If your robot currently does\nnot have common sense reasoning,",
    "start": "3232600",
    "end": "3238089"
  },
  {
    "text": "these other models can act\nas a scaffold in a life vest to bring you up to par with\nwhat they currently love.",
    "start": "3238090",
    "end": "3243160"
  },
  {
    "text": "And maybe then, in\nthe future, you'll get beyond what the\nlanguage models know. But in the short\nterm, it does seem that we can leverage\nthem to accelerate what",
    "start": "3243160",
    "end": "3249943"
  },
  {
    "text": "we can do in the real world. Moving on now from-- we saw now how language\nmodels could do planning.",
    "start": "3249943",
    "end": "3257040"
  },
  {
    "text": "We saw how vision language\nmodels could help planning. And now, we're going\nto switch gears a bit and think about how\nvision language models can",
    "start": "3257040",
    "end": "3263220"
  },
  {
    "text": "help other aspects\nof the bottlenecks that robot learning faces. One of these is that data\ncollection is very expensive.",
    "start": "3263220",
    "end": "3272099"
  },
  {
    "text": "As we mentioned before, we\ndid have this 130,000-episode demonstration data set, but\nit was collected over a year",
    "start": "3272100",
    "end": "3279599"
  },
  {
    "text": "and a half at significant cost,\nboth in resources and time, and money and with\nmany, many robots.",
    "start": "3279600",
    "end": "3287460"
  },
  {
    "text": "And, of course, these tasks,\ntoo, we're also a bit limited. We use 700\nvery-templated commands,",
    "start": "3287460",
    "end": "3294510"
  },
  {
    "text": "instructions that we would give\nto teleoperators because we knew that this would scale. If we collected enough data for\neach of these templated tasks,",
    "start": "3294510",
    "end": "3302550"
  },
  {
    "text": "we could do that specific task. And here's the flow that someone\nwas asking about earlier. We give this \"pick\ncoke can\" instruction.",
    "start": "3302550",
    "end": "3309359"
  },
  {
    "text": "The operator controls the\nrobot in the real world, finished the task, marked\nsteps that it has terminated, and then, stage that out to\nthis big orange data set.",
    "start": "3309360",
    "end": "3317220"
  },
  {
    "text": "And that big orange\ndata set is what we trained on and all\nof the previous projects for the control policies.",
    "start": "3317220",
    "end": "3322859"
  },
  {
    "text": "What we additionally\nconsidered was adding a bit of crowdsourced\nhindsight annotation. If you're familiar with\nHindsight Experience Replay",
    "start": "3322860",
    "end": "3330270"
  },
  {
    "text": "in reinforcement learning\nwith goal-conditioning with-- maybe the robot did\nsomething that wasn't just",
    "start": "3330270",
    "end": "3335850"
  },
  {
    "text": "this high-level\ntemplate instruction. We could ask a human to\ndescribe more verbosely what",
    "start": "3335850",
    "end": "3341069"
  },
  {
    "text": "the robot did. Maybe it picked up\nthe coke can that was on the right side of the table. Maybe it picked it up\nand then knocked it over.",
    "start": "3341070",
    "end": "3346350"
  },
  {
    "text": "Maybe it moved it very\nslowly to the middle. There's a lot of semantic\ndiversity encompassed in this demonstration\nthat is not totally",
    "start": "3346350",
    "end": "3355589"
  },
  {
    "text": "caught by this\nhigh-level templated \"pick coke can\" instruction. So we labeled 3% of this big\norange data set with these very",
    "start": "3355590",
    "end": "3363420"
  },
  {
    "text": "verbose descriptions. And next, we applied the\npseudo-label strategy",
    "start": "3363420",
    "end": "3370440"
  },
  {
    "text": "that's been seen in other\nfields, such as video pretraining with their\ninverse dynamics model. But instead, we apply\nthat to the instructions,",
    "start": "3370440",
    "end": "3377190"
  },
  {
    "text": "to the semantics of what's\ncontained in your data set. So step one, we be\npre-train a clip model",
    "start": "3377190",
    "end": "3383609"
  },
  {
    "text": "on your small labeled data\nset of 3% of your main data.",
    "start": "3383610",
    "end": "3388700"
  },
  {
    "text": "Then, you go ahead and use that\ntrained-VLM data to label all of the templated instruction\ndemonstrations that you had",
    "start": "3388700",
    "end": "3395900"
  },
  {
    "text": "before that\n130,000-episode data set. And now you have a\nrelabeled data set which has a large diversity\nof interesting semantic",
    "start": "3395900",
    "end": "3404000"
  },
  {
    "text": "constructions. And then, we plug in all of\nthese data sets into RT-1",
    "start": "3404000",
    "end": "3409549"
  },
  {
    "text": "and just train a\nlanguage condition behavior cloning policy similar\nto how we would normally.",
    "start": "3409550",
    "end": "3415550"
  },
  {
    "text": "Even though normally we just use\ndata set B, the orange one, now we use all three data sets.",
    "start": "3415550",
    "end": "3421460"
  },
  {
    "text": "And then, finally, we evaluate\non entirely new unseen instructions. In the prior works, we were\nevaluating mainly on these 700",
    "start": "3421460",
    "end": "3430910"
  },
  {
    "text": "templated instructions. But in this work, we\nactually go beyond that. We can type in almost\nanything you want",
    "start": "3430910",
    "end": "3436670"
  },
  {
    "text": "that you think might succeed. And you can phrase\nit how you can. You can add typos. You can even do it by\nreferring to semantic concepts.",
    "start": "3436670",
    "end": "3444200"
  },
  {
    "text": "You can add spatial concepts. And we see how it does-- ",
    "start": "3444200",
    "end": "3449630"
  },
  {
    "text": "The reason that this\nmight work, maybe visually to represent\nthis, is here are the [INAUDIBLE] embeddings\non the left and the right.",
    "start": "3449630",
    "end": "3456740"
  },
  {
    "text": "It's the same embeddings,\nbut on the left, they're colored by the original\ntemplated instruction that was",
    "start": "3456740",
    "end": "3463250"
  },
  {
    "text": "used to collect that episode. And on the right is what\nthe vision language model",
    "start": "3463250",
    "end": "3468410"
  },
  {
    "text": "thinks if it's allowed to put\na free-form natural language caption and assign\nit to that episode.",
    "start": "3468410",
    "end": "3474062"
  },
  {
    "text": "You see that on the left,\nyou have these big clusters of \"pick coke can.\" It's like hundreds or\nthousands of episodes.",
    "start": "3474062",
    "end": "3479769"
  },
  {
    "text": "But we all just call\nthem \"pick coke can.\" On the right, then we can then\nexpand those concepts and say, actually, this episode is\npicking up the red coke can.",
    "start": "3479770",
    "end": "3487370"
  },
  {
    "text": "This episode is picking\nup the clumped coke can. This is picking up the coke can\nthat's next to the chip bag.",
    "start": "3487370",
    "end": "3492859"
  },
  {
    "text": "And so you can get\na lot more mileage out of the same underlying\ndata set by just using language",
    "start": "3492860",
    "end": "3498170"
  },
  {
    "text": "as the diversity mechanism\nthrough which you expand the concepts\nthat you're considering. And, for example,\nin the middle, you",
    "start": "3498170",
    "end": "3504470"
  },
  {
    "text": "see \"open top drawer\" can\nbecome \"hold and pull out the top drawer.\" We have stuff like\n\"the center-left\"",
    "start": "3504470",
    "end": "3510380"
  },
  {
    "text": "for the middle episode. For the bottom one,\n\"pick green rice chips from white bowl\" becomes,\n\"lift up the grape chip bag",
    "start": "3510380",
    "end": "3517010"
  },
  {
    "text": "from the bowl bow and\ndrop it at the bottom left corner of the table.\" So you get a lot of these\nsemantic, spatial concepts that",
    "start": "3517010",
    "end": "3522890"
  },
  {
    "text": "are now going to be in your\ntarget supervised labels. Yeah, a question. Yes.",
    "start": "3522890",
    "end": "3528213"
  },
  {
    "text": "So using [INAUDIBLE] this\nis expected [INAUDIBLE]..",
    "start": "3528213",
    "end": "3536480"
  },
  {
    "text": "You have your [INAUDIBLE]. ",
    "start": "3536480",
    "end": "3550640"
  },
  {
    "text": "Yeah, great question. So I guess, if I\ncan rephrase a bit, the problem is\nthat it's actually",
    "start": "3550640",
    "end": "3557180"
  },
  {
    "text": "a very difficult and\nperhaps even intractable problem of how you map all the\nlinguistic concepts you see out",
    "start": "3557180",
    "end": "3562430"
  },
  {
    "text": "in the wild down\nto maybe embodied specific types of episodes. And here, maybe I would say\nis that we are definitely",
    "start": "3562430",
    "end": "3570290"
  },
  {
    "text": "introducing a lot of our\npriors and our biases onto maybe what we call as left,\nyou mean left 10 centimeters,",
    "start": "3570290",
    "end": "3577130"
  },
  {
    "text": "left two centimeters. What do words mean? And these definitions,\nwhat do they",
    "start": "3577130",
    "end": "3582590"
  },
  {
    "text": "mean to us, to the\ncrowd compute raters that generated these captions? What do they mean to the robot? What do they mean to\nthe language models?",
    "start": "3582590",
    "end": "3588620"
  },
  {
    "text": "Maybe these are all\nslightly different. But the hope is at least\nif they're roughly similar.",
    "start": "3588620",
    "end": "3594020"
  },
  {
    "text": "We'll get directionally\ncorrect improvements. So I would say the nuances\nof these specific hard lines",
    "start": "3594020",
    "end": "3600650"
  },
  {
    "text": "of definitions and\nactual semantic meaning of these words, I think that's\nmaybe out of scope right now,",
    "start": "3600650",
    "end": "3608390"
  },
  {
    "text": "but maybe something\nwe'll dive into further. At a higher level,\nthough, I think, basically, the bar\nis just so low.",
    "start": "3608390",
    "end": "3613430"
  },
  {
    "text": "We have these 700\ntemplate instructions that are basically one-hot IDs. And we just want to make those\ncloser to natural language,",
    "start": "3613430",
    "end": "3621060"
  },
  {
    "text": "even if by a little. And I think, at\nleast, we're trying to get towards that with these\nvisual language models that",
    "start": "3621060",
    "end": "3627890"
  },
  {
    "text": "are captioning automatically. I hope that answers\nyour question.",
    "start": "3627890",
    "end": "3633110"
  },
  {
    "text": "And we also compare\nit to a few baselines. On the top left,\nhere, we look at what",
    "start": "3633110",
    "end": "3638900"
  },
  {
    "text": "if we only train on this 3% of\nthese fancy human-rated labels. What if we only train on\nthe original RT-1 data sets?",
    "start": "3638900",
    "end": "3646440"
  },
  {
    "text": "What if we train\non both of these? And what if we train\non both of these, plus all of the predictions\ngiven by our VLM?",
    "start": "3646440",
    "end": "3653360"
  },
  {
    "text": "And what's interesting\nhere is that relabeling seems to universally help.",
    "start": "3653360",
    "end": "3658910"
  },
  {
    "text": "We evaluated only on\nnovel instructions that was new for this project. It's the first time on a\nrobotics project where we only",
    "start": "3658910",
    "end": "3665540"
  },
  {
    "text": "tested it on something-- I could type whatever I thought. I'd type it in, and that\nbecame the test set. And we just have to make sure\nthat it was never contained",
    "start": "3665540",
    "end": "3672859"
  },
  {
    "text": "in the training coverage. And you see all these\ninteresting examples on the right here of stuff\nlike \"move the lonely object",
    "start": "3672860",
    "end": "3679820"
  },
  {
    "text": "to the others.\" I have no idea how this worked. Stuff like lifting\nthe yellow rectangle,",
    "start": "3679820",
    "end": "3685400"
  },
  {
    "text": "talking about colors,\ntalking about \"move the right apple to the left.\" Here, we actually had\ntwo apples in the scene.",
    "start": "3685400",
    "end": "3690650"
  },
  {
    "text": "And actually, in our\ntraining demonstration data, we never collected scenes\nwith duplicate objects.",
    "start": "3690650",
    "end": "3696428"
  },
  {
    "text": "Just because we thought of\nthis multi-modality problem, if you just say, \"pick coke\ncans and these two coke cans.\" It's going to be very difficult\nto figure out which one to do.",
    "start": "3696428",
    "end": "3703493"
  },
  {
    "text": "But with language labeling,\nit seems like maybe we could do that now. So even though we never trained\non scenes with two apples,",
    "start": "3703493",
    "end": "3708887"
  },
  {
    "text": "now you could evaluate on them\nand just specify with language which apple you want to go for. And it was working\npretty reasonably.",
    "start": "3708887",
    "end": "3716830"
  },
  {
    "text": "And finally, for\nthe last example, here, I thought it\nwas interesting, a coke can-- we try to\ndo a novel behavior.",
    "start": "3716830",
    "end": "3722859"
  },
  {
    "text": "A push towards the left was\nnot a templated instruction. We only had \"move coke can near\nY,\" where Y is another object,",
    "start": "3722860",
    "end": "3731677"
  },
  {
    "text": "\"move coke can near apple. Move coke can near your sponge.\" So pushing this motion, of\njust pushing the coke can",
    "start": "3731677",
    "end": "3738160"
  },
  {
    "text": "into the air essentially\nwas not something that we ever encompassed. But maybe it was in\none of the labels. Maybe if you've seen like\n\"move coke near apple\"",
    "start": "3738160",
    "end": "3745678"
  },
  {
    "text": "and the apple is on\nthe left, and you saw \"move coke can near sponge,\"\nand the sponge is on the left, you would generate the model,\ncould generalize and be like,",
    "start": "3745678",
    "end": "3752628"
  },
  {
    "text": "oh, left means this side of the\ntable, not a specific object. So maybe that's\nwhat's happening. But it's very unclear.",
    "start": "3752628",
    "end": "3758470"
  },
  {
    "text": "This is, as I\nsaid, just I type-- I thought of something, I typed\nit, and just saw what happened.",
    "start": "3758470",
    "end": "3764328"
  },
  {
    "text": "And we definitely hope\nto explore this more quantitatively in the future. Bottom left, of\ncourse, is, I think,",
    "start": "3764328",
    "end": "3769720"
  },
  {
    "text": "comparing against\nnon-visual augmentation. So maybe you can also get\nthese interesting concepts just from language alone.",
    "start": "3769720",
    "end": "3776140"
  },
  {
    "text": "Here, we had adding random\nnoise, or we do Matlab style, just swapping out\nwords, or we even",
    "start": "3776140",
    "end": "3781330"
  },
  {
    "text": "use LLM GPT-3, in this\ncase, to propose rephrasing of existing instructions. But I think my takeaway\nthere is that you really",
    "start": "3781330",
    "end": "3789165"
  },
  {
    "text": "need visual grounding for\nthe visual language model to say, actually, yeah,\nthis caption is factually",
    "start": "3789165",
    "end": "3794440"
  },
  {
    "text": "accurate at this\ngiven point in time, and that it's something\nperhaps that would",
    "start": "3794440",
    "end": "3799450"
  },
  {
    "text": "be interesting for a robot. That fine-tuning process\nprovides both of those. Yeah. [INAUDIBLE]",
    "start": "3799450",
    "end": "3813100"
  },
  {
    "text": "Yeah, definitely. These are just some subsets\nof type of these evaluation instructions, but we\nhad over 60 of them.",
    "start": "3813100",
    "end": "3820300"
  },
  {
    "text": "We didn't do a full quantitative\nablation, for example, as we did in RT-1. We had this seen\nand unseen task set,",
    "start": "3820300",
    "end": "3827110"
  },
  {
    "text": "and that was compositional. You'd see, \"move\ncoke near apple,\" and you would see, \"move\napple in your sponge.\"",
    "start": "3827110",
    "end": "3833230"
  },
  {
    "text": "But we'd hold out \"move\ncoke near sponge,\" and we'd test that out. But in this case, I think we\ncan go much more beyond that.",
    "start": "3833230",
    "end": "3838494"
  },
  {
    "text": "Because our language is\ncompletely free-form. The compositional space\nof what you can combine",
    "start": "3838495",
    "end": "3844000"
  },
  {
    "text": "is just going to be much larger. So we did try a little bit. To answer your\nquestion, we tried some combinatorial evaluations,\nbut there's definitely",
    "start": "3844000",
    "end": "3851140"
  },
  {
    "text": "a lot more thoroughness\nthat we could do there too. How am I doing on time?",
    "start": "3851140",
    "end": "3856530"
  },
  {
    "text": "OK, 10 minutes. Maybe I'll try to wrap\nup pretty soon, then. The DIAL Takeaway then is\nthat two parts, lesson 2,",
    "start": "3856530",
    "end": "3864045"
  },
  {
    "text": "leverage foundation models. Let's use VLMs as\ndata augmentation. And lesson 3, let's make sure\nthat our offline data set",
    "start": "3864045",
    "end": "3870240"
  },
  {
    "text": "is robust enough where these\ndifferent behaviors exist. And you can describe\nthem in language.",
    "start": "3870240",
    "end": "3875378"
  },
  {
    "text": "If you don't have enough\ndiverse behaviors, no matter how good\nyour labeling is, you probably can't elicit all\nof the interesting concepts",
    "start": "3875378",
    "end": "3881160"
  },
  {
    "text": "that you want to learn from. And maybe most exciting for\nme here was that, actually, some label noise is OK.",
    "start": "3881160",
    "end": "3887400"
  },
  {
    "text": "Notoriously in supervised\nlearning and imitation learning, you need\nvery clean labels that are always 100% true.",
    "start": "3887400",
    "end": "3893339"
  },
  {
    "text": "You don't want to be learning\nfrom noisy data where some-- a large percentage\nis just not accurate.",
    "start": "3893340",
    "end": "3898900"
  },
  {
    "text": "But in our case, it seems\nthat some label noise was OK. The vision language\nmodel was not",
    "start": "3898900",
    "end": "3904710"
  },
  {
    "text": "always predicting factually\naccurate descriptions of the scene.",
    "start": "3904710",
    "end": "3909940"
  },
  {
    "text": "And I think this\ndefinitely hurt when it got too high, the noise. But at smaller\nlevels, it definitely",
    "start": "3909940",
    "end": "3915299"
  },
  {
    "text": "still seemed to be OK and\nrobust enough to handle that.",
    "start": "3915300",
    "end": "3920470"
  },
  {
    "text": "So that was a deep dive then\non some individual works that use this big recipe of language,\nfoundation models, offline data",
    "start": "3920470",
    "end": "3928300"
  },
  {
    "text": "sets in different parts\nof the robot system. And this was the pitch\nat the beginning.",
    "start": "3928300",
    "end": "3934190"
  },
  {
    "text": "And I hope you at least see a\nlittle bit of how our team has tried to take these\nprinciples and apply them",
    "start": "3934190",
    "end": "3940040"
  },
  {
    "text": "to accelerating robot\nlearning in the real world. As we see, these different\ntypes of ingredients and lessons",
    "start": "3940040",
    "end": "3946519"
  },
  {
    "text": "map onto different parts of\nthe robot system altogether. But it's still learning. That was RT-1 that\nwe talked about.",
    "start": "3946520",
    "end": "3952670"
  },
  {
    "text": "For planning, that was SayCan. And then adding the\nclose of feedback with vision language models,\nthat was inner monologue.",
    "start": "3952670",
    "end": "3958370"
  },
  {
    "text": "For low-level control, we\ndidn't talk about this today, but exciting work from\nour team is actually using language models\nto predict code",
    "start": "3958370",
    "end": "3964819"
  },
  {
    "text": "that's executed on the\nrobot directly, perhaps as low-level controls. Language models,\nthey read textbooks,",
    "start": "3964820",
    "end": "3970369"
  },
  {
    "text": "they read-- they've\nread raw ROSS docs. They've read UR5\ndocumentation code. And they can write\ncode for these robots,",
    "start": "3970370",
    "end": "3976369"
  },
  {
    "text": "and we can execute that. For data augmentation,\nwe saw DIAL with vision language models.",
    "start": "3976370",
    "end": "3981650"
  },
  {
    "text": "And also, I didn't\ntalk about this here, but for object-centric\nrepresentations for things like feature activation\nmaps for specific objects,",
    "start": "3981650",
    "end": "3989060"
  },
  {
    "text": "we can use those as\ntask representations for mapping a scene. And in NLMap, they did that\nfor object-centric navigation",
    "start": "3989060",
    "end": "3997339"
  },
  {
    "text": "around the micro kitchen\nthat we looked at. And I think, hopefully, in the\nnext coming weeks and months,",
    "start": "3997340",
    "end": "4003520"
  },
  {
    "text": "we have a few more rows and\nentries to add here as well. But I think this kind of mindset\nis a very exciting research",
    "start": "4003520",
    "end": "4010990"
  },
  {
    "text": "direction of how you can apply\nthese big high-level concepts about foundation models\nand offline data sets.",
    "start": "4010990",
    "end": "4016240"
  },
  {
    "text": "And you look at what exists\nin the robot systems of today. And you find many gaps in\nopportunities still available,",
    "start": "4016240",
    "end": "4022329"
  },
  {
    "text": "where we can do everything\nfrom exploratory pilots on how this might look\nall the way to more",
    "start": "4022330",
    "end": "4027940"
  },
  {
    "text": "extensive evaluations and really\nbuilding out robust systems. I think both of\nthese have value.",
    "start": "4027940",
    "end": "4033480"
  },
  {
    "text": "So I'll conclude\nwith just saying that it was very\nfun exploring all",
    "start": "4033480",
    "end": "4038720"
  },
  {
    "text": "of these complementary\ndirections. But there are still\nsome major questions of how we can take these\nconcepts even further",
    "start": "4038720",
    "end": "4044720"
  },
  {
    "text": "in how these trends\nand ideas might even evolve moving forward as\nfoundation models get better, as more data set becomes\navailable online,",
    "start": "4044720",
    "end": "4052130"
  },
  {
    "text": "as more data becomes\nhomogenized and tokenized, and interoperable. And I think a lot\nof the concepts",
    "start": "4052130",
    "end": "4057230"
  },
  {
    "text": "from other fields like\nlinguistics and vision, and from all of the big\nscaling level questions",
    "start": "4057230",
    "end": "4064220"
  },
  {
    "text": "that are being pioneered in\nlanguage-based foundation models. Hopefully, those ideas can\ntrickle down to robotics.",
    "start": "4064220",
    "end": "4070490"
  },
  {
    "text": "Maybe even robotics can\nprovide something back by providing embodied action\ncausal data sets that maybe",
    "start": "4070490",
    "end": "4075890"
  },
  {
    "text": "might improve the\nquality of reasoning of some of these large language\nmodels that are not embodied.",
    "start": "4075890",
    "end": "4081710"
  },
  {
    "text": "With that, though, I guess\nI'd like to thank everyone for your time and for--",
    "start": "4081710",
    "end": "4086720"
  },
  {
    "text": "Dave and [INAUDIBLE]\nfor inviting me and open to any questions about\nthe papers or just at a high",
    "start": "4086720",
    "end": "4091940"
  },
  {
    "text": "level as well. Thanks so much. ",
    "start": "4091940",
    "end": "4101568"
  },
  {
    "text": "A question? [INAUDIBLE] ",
    "start": "4101569",
    "end": "4115532"
  },
  {
    "text": "Yeah, a great question. So the question,\nI guess, is what about tasks that require\nmore semantic reasoning, like operating at a certain\nspeed or with maybe,",
    "start": "4115532",
    "end": "4124049"
  },
  {
    "text": "I don't know, numerical\nreasoning within the question, the prompt itself? I would say, so for a lot of\nthe more common sense reasoning,",
    "start": "4124050",
    "end": "4131670"
  },
  {
    "text": "like \"throw away three\ncoke cans after another,\" I think the language model is\nvery good at that right now.",
    "start": "4131670",
    "end": "4139899"
  },
  {
    "text": "So for, the second\nplanner, it will predict \"throw away the coke\ncan\" three separate times.\"",
    "start": "4139899",
    "end": "4145109"
  },
  {
    "text": "For the low-level\nskill policy learning, though, I think that's more of\na high variance, I would say.",
    "start": "4145109",
    "end": "4152285"
  },
  {
    "text": "And definitely,\nfor right now, we don't really condition on\nspeed or how you do it exactly.",
    "start": "4152285",
    "end": "4158850"
  },
  {
    "text": "But that's definitely--\nmaybe something like that we could do. If you could relabel with like\n\"pick up the coke cans slowly\"",
    "start": "4158850",
    "end": "4164609"
  },
  {
    "text": "versus \"pick up the\ncoke can quickly,\" maybe that is something a visual\nlanguage model could recognize. Yeah.",
    "start": "4164609",
    "end": "4170567"
  },
  {
    "text": "There is [INAUDIBLE]\ncombinatorial generalization.",
    "start": "4170567",
    "end": "4176960"
  },
  {
    "text": "So if you have data\n[INAUDIBLE] something, if you hvae something [INAUDIBLE].",
    "start": "4176960",
    "end": "4183259"
  },
  {
    "start": "4183260",
    "end": "4195050"
  },
  {
    "text": "A great question. The question was,\nwhat scale do we see combinatorial\ngeneralizations start",
    "start": "4195050",
    "end": "4200670"
  },
  {
    "text": "to occur, maybe between--\nyou've seen colors of one block, and then you want to\nevaluate on a new color.",
    "start": "4200670",
    "end": "4206200"
  },
  {
    "text": "And I think that's\na great question. And unfortunately, my answer\nis going to be very vague. And it depends. It depends on how you\ndefine your tasks.",
    "start": "4206200",
    "end": "4212642"
  },
  {
    "text": "It depends on the\nscale of your data set. And it depends on the\nconcept that you're trying to generalize across. I think there have been numerous\nattempts to basically formalize",
    "start": "4212642",
    "end": "4222599"
  },
  {
    "text": "what it means to\ngeneralize within learning and within robotics, even\nwithin the specific settings we",
    "start": "4222600",
    "end": "4228150"
  },
  {
    "text": "consider. And I don't think there are\nany clear trends of where you can say, Oh, yeah,\nthis is the number",
    "start": "4228150",
    "end": "4234030"
  },
  {
    "text": "I need to hit where I can\ngeneralize across X, Y, Z dimensions. You could evaluate\nall of those, but I",
    "start": "4234030",
    "end": "4239760"
  },
  {
    "text": "don't think it will help you\npredict new trends, at least right now. I think we're probably--\nthis is just me talking.",
    "start": "4239760",
    "end": "4244960"
  },
  {
    "text": "I would say where one order\nof magnitude off before we can start to make very broadly\ngeneralizing statements",
    "start": "4244960",
    "end": "4250950"
  },
  {
    "text": "about generalization\ncapabilities. But I think add one or two more\nzeros to our data set size.",
    "start": "4250950",
    "end": "4256740"
  },
  {
    "text": "And we can start to\ntalk about that in terms of tasks and object skills. ",
    "start": "4256740",
    "end": "4263370"
  },
  {
    "text": "[INAUDIBLE] Yeah. So say [INAUDIBLE]. ",
    "start": "4263370",
    "end": "4278040"
  },
  {
    "text": "So we thought of an [INAUDIBLE]. ",
    "start": "4278040",
    "end": "4288370"
  },
  {
    "text": "Yeah, a very astute observation. So the question was that in\nSayCan, the value functions",
    "start": "4288370",
    "end": "4294760"
  },
  {
    "text": "that predict these\nscholars on the right here for the\naffordances are only scoring a certain\nlimited number of tasks.",
    "start": "4294760",
    "end": "4300790"
  },
  {
    "text": "So is that the bottleneck? And I would say, yes, 100%. Scaling the number of tasks\nthat your system is able to do,",
    "start": "4300790",
    "end": "4307060"
  },
  {
    "text": "that you can then\ngive to the planner as its buffet of options to\nchoose that is the bottleneck. No matter how good your\nplanner is, if you can only",
    "start": "4307060",
    "end": "4314679"
  },
  {
    "text": "do three tasks, there's\nonly certain combinations of those three tasks\nthat it can do to map",
    "start": "4314680",
    "end": "4321250"
  },
  {
    "text": "onto a high-level instruction. So as you add more tasks, as\nthe low-level skill capabilities",
    "start": "4321250",
    "end": "4326680"
  },
  {
    "text": "of your robot increase,\nyou're adding precision to the coverage of the\nhigh-level instructions",
    "start": "4326680",
    "end": "4333100"
  },
  {
    "text": "that your robot can try to do. And that's one of the main\nbottlenecks I see today.",
    "start": "4333100",
    "end": "4339004"
  },
  {
    "text": "[INAUDIBLE] ",
    "start": "4339004",
    "end": "4351880"
  },
  {
    "text": "Great question. So have we tried RT-1\nwith ROHF or with RL.",
    "start": "4351880",
    "end": "4357700"
  },
  {
    "text": "I think the short\nanswer is I think we have some stuff in the\nworks that is doing that.",
    "start": "4357700",
    "end": "4362800"
  },
  {
    "text": "But right now, for\nall of our projects, currently, we're just using\nthis imitation learning loss.",
    "start": "4362800",
    "end": "4368710"
  },
  {
    "text": "Again, I think I view\nthis multi-task imitation that we're making as kind\nof an existence proof. It works.",
    "start": "4368710",
    "end": "4373929"
  },
  {
    "text": "It's not cheap. But it does work. And it does scale. And that, at least, is\na good starting point.",
    "start": "4373930",
    "end": "4379840"
  },
  {
    "text": "And our main hope over\nthe next months and years is, can we improve beyond that?",
    "start": "4379840",
    "end": "4384850"
  },
  {
    "text": "Can we add back in\noffline improvement? Can we add in RL back\nto the equation somehow? I'm an RL person at heart,\nso I really hope so.",
    "start": "4384850",
    "end": "4392369"
  },
  {
    "text": "[INAUDIBLE] ",
    "start": "4392370",
    "end": "4405950"
  },
  {
    "text": "Sorry, could you repeat that? [INAUDIBLE]? ",
    "start": "4405950",
    "end": "4428540"
  },
  {
    "text": "Yeah, a good question. So regarding task balance\nand whether text-only data is",
    "start": "4428540",
    "end": "4433760"
  },
  {
    "text": "sufficient for helping\nmodel controlled learning, I think my hope is\nthat when models--",
    "start": "4433760",
    "end": "4440960"
  },
  {
    "text": "when we experience the emergence\nin both the robotic space, and we've already seen\nemergence in the language space,",
    "start": "4440960",
    "end": "4446360"
  },
  {
    "text": "at some point maybe\nthese reasoning concepts will start to transfer\nbetween the two. I would point them to one\ninteresting paper, which",
    "start": "4446360",
    "end": "4452990"
  },
  {
    "text": "is, I think, \"Can Wikipedia\nHelp Reinforcement Learning,\" from Shane\nand some other folks.",
    "start": "4452990",
    "end": "4458449"
  },
  {
    "text": "They pre-trained a\nlarge policy network on autoregressive\ntoken prediction on Wikipedia, just text only.",
    "start": "4458450",
    "end": "4465469"
  },
  {
    "text": "And they use that to initialize\ncontrol for Atari Games with RL. And this actually helped.",
    "start": "4465470",
    "end": "4471230"
  },
  {
    "text": "So maybe this is philosophical,\nbut maybe there's something about\ndecision-making reasoning that transfers between\ntext and action data.",
    "start": "4471230",
    "end": "4480056"
  },
  {
    "text": "[INAUDIBLE]",
    "start": "4480056",
    "end": "4493598"
  },
  {
    "text": "Great question. I definitely agree. Passing in six\nimages is not going to be enough when\nyou're executing tasks",
    "start": "4493598",
    "end": "4500120"
  },
  {
    "text": "for minutes at a time. Like \"clean my whole\nhouse,\" and then you can only pass in\nthe last two seconds.",
    "start": "4500120",
    "end": "4505280"
  },
  {
    "text": "Come on. So I think that's\ndefinitely going to be a limitation\nas our tasks get more complex and long horizon.",
    "start": "4505280",
    "end": "4512060"
  },
  {
    "text": "And I think here, it's\nanother open question, too, is context when we have high\ndimensional images, even",
    "start": "4512060",
    "end": "4517880"
  },
  {
    "text": "with token learning for\nreducing the number of patches that we pass through. It's still very\nhigh dimensional.",
    "start": "4517880",
    "end": "4524010"
  },
  {
    "text": "And we quickly hit the\ncontext length cap. Can we do-- how do we\nimprove it beyond this? Maybe it's like retrieval\ntransformers or some other kind",
    "start": "4524010",
    "end": "4532190"
  },
  {
    "text": "of mechanism. [INAUDIBLE]? ",
    "start": "4532190",
    "end": "4538540"
  },
  {
    "text": "Great question. I think we are hoping to\nexplore that in the future. But with this context\nlength limitation,",
    "start": "4538540",
    "end": "4544270"
  },
  {
    "text": "we are already near the context\nlength capacity with just the six images alone, much less\npassing in whole trajectories",
    "start": "4544270",
    "end": "4551710"
  },
  {
    "text": "of zero-shot behaviour--\nfew-shot behavior we wish to see. So TBD.",
    "start": "4551710",
    "end": "4556980"
  },
  {
    "text": "Yeah. [INAUDIBLE] Cool. Thank you, guys. Thank you.",
    "start": "4556980",
    "end": "4563110"
  },
  {
    "start": "4563110",
    "end": "4567000"
  }
]
[
  {
    "text": "thanks everybody for making time on a Friday afternoon i'm super happy to be here uh like Mark said I'm faculty in",
    "start": "10000",
    "end": "16320"
  },
  {
    "text": "electrical and computer engineering at WCE so to start with the ideas the",
    "start": "16320",
    "end": "21439"
  },
  {
    "text": "motivation for my work is the observation that the way we interact with the physical world is increasingly",
    "start": "21439",
    "end": "26720"
  },
  {
    "text": "mediated by machines and this can take the form of teaoperated robots where we're at a haptic console stereo vision",
    "start": "26720",
    "end": "34239"
  },
  {
    "text": "etc to do robot assisted surgeries that can improve surgical outcomes it could",
    "start": "34239",
    "end": "39440"
  },
  {
    "text": "be um an invasive brain machine neural implanted interface to control a robot",
    "start": "39440",
    "end": "46399"
  },
  {
    "text": "you know if I'm paralyzed from the neck down like Jan and I want to be able to feed myself again and have that autonomy",
    "start": "46399",
    "end": "51760"
  },
  {
    "text": "and that kind of sense of identity and self um these machines can restore that for me",
    "start": "51760",
    "end": "57360"
  },
  {
    "text": "and it could be in um augmenting or amplifying human ability so the final example Steve Collins um uh one of your",
    "start": "57360",
    "end": "65360"
  },
  {
    "text": "folks here um created this in this case a purely passive device that reduce the metabolic cost of walking which is a",
    "start": "65360",
    "end": "71280"
  },
  {
    "text": "really extraordinary accomplishment but then they have active devices that even decrease it even further and I think",
    "start": "71280",
    "end": "76720"
  },
  {
    "text": "just is just hinting at the possibilities uh that we have for um",
    "start": "76720",
    "end": "82720"
  },
  {
    "text": "either mitigating disability or just amplifying innate abilities in people",
    "start": "82720",
    "end": "88720"
  },
  {
    "text": "and so the goal of my research the kind of fundamental questions that drive me are how to predict the outcomes when",
    "start": "88720",
    "end": "93840"
  },
  {
    "text": "humans and machines interact in these ways and then how to shape those outcomes toward you know better um",
    "start": "93840",
    "end": "100079"
  },
  {
    "text": "devices that work perform better or that are more usable or preferable for the",
    "start": "100079",
    "end": "105560"
  },
  {
    "text": "users so that kind of sets up the structure for today's talk i'm going to talk about kind of a constellation of",
    "start": "105560",
    "end": "112079"
  },
  {
    "text": "results that build toward trying to uh predict and shape outcomes of these",
    "start": "112079",
    "end": "117240"
  },
  {
    "text": "interactions we're going to take it step by step and kind of piece by piece not kind of tackle it all at once but um",
    "start": "117240",
    "end": "122960"
  },
  {
    "text": "have kind of a sequence of results that culminate in that and so there sort of two parts of the talk first part is",
    "start": "122960",
    "end": "129119"
  },
  {
    "text": "about a third of it and then the second part is about twothirds of it so first we're going to talk about um the kinds",
    "start": "129119",
    "end": "134480"
  },
  {
    "text": "of models that people learn when they're controlling machines and then subsequently we're going to leverage our",
    "start": "134480",
    "end": "140160"
  },
  {
    "text": "knowledge about those models to um synthesize how machines should learn from and interact with",
    "start": "140160",
    "end": "146680"
  },
  {
    "text": "people so the way that we try to study the kinds of models people build when",
    "start": "146680",
    "end": "151840"
  },
  {
    "text": "they're controlling machines is a paradigm we use a paradigm that goes back decades so like the um folks",
    "start": "151840",
    "end": "158000"
  },
  {
    "text": "interested in fighter pilots in the 50s were already developing some of the kinds of techniques and paradigms that we use so we have the human we have the",
    "start": "158000",
    "end": "165360"
  },
  {
    "text": "robot the remote robot that they're controlling through some interface and um just to acclimate us to",
    "start": "165360",
    "end": "171519"
  },
  {
    "text": "the notation and the kind of terminology and stuff um there's going to be some input that the human provides to the",
    "start": "171519",
    "end": "178160"
  },
  {
    "text": "machine so it's the human's output but it's the input to the machine and then there's going to be some output from the",
    "start": "178160",
    "end": "183599"
  },
  {
    "text": "machine that's displayed back to the human and in um some of the experiments I'll talk about that human input is",
    "start": "183599",
    "end": "190319"
  },
  {
    "text": "manual it's like a joystick in another set of experiments it's going to be my electric muscle activity based and then",
    "start": "190319",
    "end": "197360"
  },
  {
    "text": "I'm only going to be talking about visuals there could be other display modalities like haptics but I'm not going to talk about that",
    "start": "197360",
    "end": "204200"
  },
  {
    "text": "today and then in addition there's going to be these extra signals that we think about there's going to be a reference R",
    "start": "204200",
    "end": "209519"
  },
  {
    "text": "that the um users are tasked with tracking so they're trying to make their output or not their output um they're",
    "start": "209519",
    "end": "216400"
  },
  {
    "text": "trying to make the machine's output track some specified reference signal and then there's going to be some",
    "start": "216400",
    "end": "221440"
  },
  {
    "text": "disturbances that are coming in and kind of jostling things around and making the task harder um and also as it turns out",
    "start": "221440",
    "end": "227680"
  },
  {
    "text": "revealing some information about um the human transformations that we can only get by",
    "start": "227680",
    "end": "233840"
  },
  {
    "text": "applying that disturbance and so the way that I like to think about these systems I'm a control",
    "start": "233840",
    "end": "239920"
  },
  {
    "text": "theorist by training and so everything to me is a block diagram and a dynamical system model and the interconnection",
    "start": "239920",
    "end": "245439"
  },
  {
    "text": "between those things and so here this is just kind of a a schematic representation of the",
    "start": "245439",
    "end": "252080"
  },
  {
    "text": "picture the cartoon that I had in the previous slide but we're going to be able to kind of cache out this picture",
    "start": "252080",
    "end": "258079"
  },
  {
    "text": "into math and into learning methods that we can apply to the system",
    "start": "258079",
    "end": "263520"
  },
  {
    "text": "and the kind of fun first fundamental question I have is what's in the box right what exactly is happening inside",
    "start": "263520",
    "end": "269520"
  },
  {
    "text": "this human transformation the human is looking at the reference they want to track they're looking at the error with respect to that reference and then",
    "start": "269520",
    "end": "276160"
  },
  {
    "text": "they're producing their um control signal U that's um feeding into the",
    "start": "276160",
    "end": "281960"
  },
  {
    "text": "machine and there are a lot of hypotheses about what's inside the box",
    "start": "281960",
    "end": "287680"
  },
  {
    "text": "ideas going back decades are that there are um forward models and inverse models",
    "start": "287680",
    "end": "292800"
  },
  {
    "text": "so the human's learning if it's uh if they're controlling their own body they're learning the kinematics and dynamics of their arm for instance and",
    "start": "292800",
    "end": "300400"
  },
  {
    "text": "then an inverse model where that lets the human compute if I want my arm or the cursor on the screen to do something",
    "start": "300400",
    "end": "306960"
  },
  {
    "text": "go through some squiggle on the screen then what is the input I should supply to get it to do that and this is the",
    "start": "306960",
    "end": "313039"
  },
  {
    "text": "terminology that's common in the motor control literature um to be kind of more consistent with um the controls",
    "start": "313039",
    "end": "319520"
  },
  {
    "text": "literature again the school of thought I come from we're going to talk about feed forward controllers and feed forward",
    "start": "319520",
    "end": "325759"
  },
  {
    "text": "controllers are supposed to approximate the inverse of forward models or machine dynamics that are being",
    "start": "325759",
    "end": "331240"
  },
  {
    "text": "controlled and another reason we like thinking about things this way is that they're really this came from the motor",
    "start": "331240",
    "end": "336639"
  },
  {
    "text": "control world but there are really strong parallels in the fields that uh engineers role in you know control theory AI machine learning",
    "start": "336639",
    "end": "345280"
  },
  {
    "text": "So now if I return to this picture uh and I want to understand what's inside that box we have a hypothesis that there",
    "start": "346320",
    "end": "352800"
  },
  {
    "text": "are two principal mechanisms please enter the meeting password solely on the reference that",
    "start": "352800",
    "end": "359360"
  },
  {
    "text": "the human's trying to track and then a feedback mechanism that operates solely on the um error that they're currently",
    "start": "359360",
    "end": "366560"
  },
  {
    "text": "observing between the where they are and where they want to be you are in the meeting like I said these",
    "start": "366560",
    "end": "372319"
  },
  {
    "text": "diagrams aren't just pretty pictures we can actually use them cache them out computationally so we can take the block",
    "start": "372319",
    "end": "378080"
  },
  {
    "text": "diagram we can transcribe it into a system of equations that's kind of an equivalent representation the block diagram just happens to be a graphical",
    "start": "378080",
    "end": "384639"
  },
  {
    "text": "representation of some algebraic identities but we can actually cache those out and then we can manipulate",
    "start": "384639",
    "end": "390639"
  },
  {
    "text": "these in order to estimate quantities of interest so what's important about the equations in step two are that the um",
    "start": "390639",
    "end": "398560"
  },
  {
    "text": "the transformations of interest F and B the feed forward and feedback transformations we can't directly measure those are inside the box like I",
    "start": "398560",
    "end": "405840"
  },
  {
    "text": "don't get to go in and carve into the human's brain uh maybe some people you know some neuroscientists can come up",
    "start": "405840",
    "end": "411199"
  },
  {
    "text": "with methods to do that I don't think that way but what we can do is measure the input output behavior for the human",
    "start": "411199",
    "end": "418080"
  },
  {
    "text": "transformations HUR and HUD the way that they respond to these exogenous signals",
    "start": "418080",
    "end": "423280"
  },
  {
    "text": "we're plugging into the system and then through these algebraic manipulations we can get estimates unbiased estimates of",
    "start": "423280",
    "end": "429759"
  },
  {
    "text": "um the transformations of interest so we apply this in an",
    "start": "429759",
    "end": "435440"
  },
  {
    "text": "experimental paradigm where somebody's sitting at a computer and they're seeing a reference squiggle on the screen and",
    "start": "435440",
    "end": "440960"
  },
  {
    "text": "then they're controlling the cursor the purple cursor through a man for instance a manual interface to try to track it",
    "start": "440960",
    "end": "447520"
  },
  {
    "text": "and the kind of results we get for the feed forward and feedback controllers look like this what I'm showing are the bodde plots which if you come from a",
    "start": "447520",
    "end": "454160"
  },
  {
    "text": "controls or signals background is probably very familiar if you don't come from those backgrounds these are basically the way that s different",
    "start": "454160",
    "end": "460960"
  },
  {
    "text": "frequencies of syosoidal inputs are transformed through the system the dynamics turn out to be surprisingly",
    "start": "460960",
    "end": "466840"
  },
  {
    "text": "linear the dynamics of the human their transformations turn out to be surprisingly linear and so the way a",
    "start": "466840",
    "end": "472240"
  },
  {
    "text": "sinosoid gets transformed is it gets scaled the magnitude changes and it gets phase shifted um by some amount and so",
    "start": "472240",
    "end": "480720"
  },
  {
    "text": "overlaid on this plot are um the inverse of the dynamics the machine or sorry the",
    "start": "480720",
    "end": "485840"
  },
  {
    "text": "machine dynamics the human is trying to control in this case it was a first order velocity based interface and so",
    "start": "485840",
    "end": "491280"
  },
  {
    "text": "the um inverse model is shown in the dash line and you can see that the feedback feed forward sorry",
    "start": "491280",
    "end": "496639"
  },
  {
    "text": "transformation f actually does a pretty good job of approximating it gets the kind of general trends it gets the right",
    "start": "496639",
    "end": "502400"
  },
  {
    "text": "phase lead um of about pi over two uh in the phase compon component and then in",
    "start": "502400",
    "end": "509039"
  },
  {
    "text": "the magnitude component it gets the right trend you know there's kind of this linear increase interestingly it's",
    "start": "509039",
    "end": "514399"
  },
  {
    "text": "sort of scaled down there's sort of the systematic bias so the human doesn't exactly invert it does a good",
    "start": "514399",
    "end": "520800"
  },
  {
    "text": "approximation but there's some bias in it and we'll return to that idea that the human isn't purely trying to",
    "start": "520800",
    "end": "526880"
  },
  {
    "text": "maximize or minimize error um they might be trading off some with some other pri priority um for instance the amount of",
    "start": "526880",
    "end": "533760"
  },
  {
    "text": "effort it takes to solve the to perform the task so this these are results with a",
    "start": "533760",
    "end": "539680"
  },
  {
    "text": "first order model we can do the same thing with a second order model um the main reason I'm showing this is to uh",
    "start": "539680",
    "end": "544959"
  },
  {
    "text": "the main take reasons that I'm showing this are um it's nice to know that these same general trends hold when I change",
    "start": "544959",
    "end": "551200"
  },
  {
    "text": "the system dynamics but then also maybe more importantly um the model that gets",
    "start": "551200",
    "end": "556880"
  },
  {
    "text": "learned here is just categorically different from the model in the first order system so people adapt well to the",
    "start": "556880",
    "end": "563440"
  },
  {
    "text": "systems they're controlling and therefore if the systems they're controlling are different then the human controllers end up very",
    "start": "563440",
    "end": "570839"
  },
  {
    "text": "different we've done a similar thing as I alluded to at the beginning with um Oh",
    "start": "570839",
    "end": "576720"
  },
  {
    "text": "yeah do we have any questions yeah oh okay never mind um we've done the",
    "start": "576720",
    "end": "582560"
  },
  {
    "text": "same thing with um myoelectric muscle interfaces this one was a very simple I'll show a highdensity version later",
    "start": "582560",
    "end": "588880"
  },
  {
    "text": "but this one's very simple there's just electrodes on biceps and triceps two electrodes and then it's just the",
    "start": "588880",
    "end": "594000"
  },
  {
    "text": "difference in the activation of your biceps and triceps that acts as that one-dimensional um cursor",
    "start": "594000",
    "end": "599880"
  },
  {
    "text": "input and so we wanted to compare these two and the idea was you know these probably have different dynamical",
    "start": "599880",
    "end": "605519"
  },
  {
    "text": "properties is one strictly better than another u how do they compare",
    "start": "605519",
    "end": "611279"
  },
  {
    "text": "and so we can look at two metrics of performance one is the actual tracking error which is the task that we that",
    "start": "611279",
    "end": "617040"
  },
  {
    "text": "what we assign as the task is to minimize tracking error of course the human might have other priorities as",
    "start": "617040",
    "end": "622560"
  },
  {
    "text": "well but this is at least what we have prescribed to them and then we could look at another metric which is how well",
    "start": "622560",
    "end": "627600"
  },
  {
    "text": "have they learned to invert the model so that's in the right column and what we find that's kind of interesting is that",
    "start": "627600",
    "end": "633920"
  },
  {
    "text": "when it comes to the tracking error and when it comes to the inversion error for the first order system these two",
    "start": "633920",
    "end": "639360"
  },
  {
    "text": "interfaces are pretty comparable they're not you're not seeing significant differences between them but then when",
    "start": "639360",
    "end": "645040"
  },
  {
    "text": "we look at the inversion error so how well the human has learned to invert the",
    "start": "645040",
    "end": "650240"
  },
  {
    "text": "system dynamics we see a big difference for the second order system and lower error is better and so the muscle",
    "start": "650240",
    "end": "656079"
  },
  {
    "text": "interface they're able to better internalize that second order those second order dynamics um we don't have a good I don't have a",
    "start": "656079",
    "end": "662320"
  },
  {
    "text": "question that I get almost every time I give this talk is so I'll just preempt it is why what's the mechanistic",
    "start": "662320",
    "end": "669040"
  },
  {
    "text": "explanation for this difference I don't have a good answer to that um but one plausible hypothesis is uh based on the",
    "start": "669040",
    "end": "676800"
  },
  {
    "text": "observation that you know before my hand can move my muscles had to have",
    "start": "676800",
    "end": "681880"
  },
  {
    "text": "activated and so there's going to be some difference in delay for a muscle modality is going to be have less delay",
    "start": "681880",
    "end": "689680"
  },
  {
    "text": "gener I would expect than a manual modality and so it could be that difference in delay that's helping them",
    "start": "689680",
    "end": "694720"
  },
  {
    "text": "to better implement those feed forward signals so this is wrapping up that",
    "start": "694720",
    "end": "701120"
  },
  {
    "text": "first segment of the talk um what we've shown is that humans adapt to the",
    "start": "701120",
    "end": "706320"
  },
  {
    "text": "dynamical systems they're interacting with it's not a surprising or a controversial point but it's all part of",
    "start": "706320",
    "end": "712399"
  },
  {
    "text": "the story it's all part of the journey we're going on right now together um building up these blocks u one at a time",
    "start": "712399",
    "end": "719200"
  },
  {
    "text": "and in particular what I want you to take away from it as I was saying before is that humans learn different models",
    "start": "719200",
    "end": "724560"
  },
  {
    "text": "depending on the system they're interacting with so that in the second part of the talk I'm going to start",
    "start": "724560",
    "end": "729600"
  },
  {
    "text": "dynamically varying or adapting the machine uh in in some with some learning",
    "start": "729600",
    "end": "735600"
  },
  {
    "text": "algorithm and so that's going then the human is going to respond by doing its own learning and now all of a sudden",
    "start": "735600",
    "end": "741040"
  },
  {
    "text": "we're uh in a complicated situation",
    "start": "741040",
    "end": "746519"
  },
  {
    "text": "so the key observation here other than um humans learn well the key observation",
    "start": "746800",
    "end": "752000"
  },
  {
    "text": "is that humans learn to approximately invert machine dynamics so if you're present with different machine dynamics you get different human",
    "start": "752000",
    "end": "758279"
  },
  {
    "text": "models and so now I want to kind of flip the script and look at what happens when the machine is learning its own model or",
    "start": "758279",
    "end": "765360"
  },
  {
    "text": "doing its own uh learning or adaptation and so we return to this picture and",
    "start": "765360",
    "end": "771519"
  },
  {
    "text": "what I want to do now h is already a function of m but I want to make m a function of h and I want m to be as a function to be",
    "start": "771519",
    "end": "779920"
  },
  {
    "text": "changing in time or as h changes and so fundamentally what happens",
    "start": "779920",
    "end": "785120"
  },
  {
    "text": "mathematically what happens is we get a game mathematical game um distinct from when I referred earlier",
    "start": "785120",
    "end": "791440"
  },
  {
    "text": "to my experiments as being video games that the users are playing this is a mathematical game where I have two decision-making agents that have",
    "start": "791440",
    "end": "798320"
  },
  {
    "text": "potentially differing or conflicting priorities um they're not perfectly sharing information with each other",
    "start": "798320",
    "end": "804000"
  },
  {
    "text": "they're not perfectly coordinating or colluding and so we're in this kind of mess that we need to figure out what's",
    "start": "804000",
    "end": "809120"
  },
  {
    "text": "going to happen so one hypothesis a hypothesis we base",
    "start": "809120",
    "end": "816639"
  },
  {
    "text": "our approach on is the idea that well both of them the way they're making decisions is by minimizing some cost",
    "start": "816639",
    "end": "822680"
  },
  {
    "text": "function right and there's a ton of this this idea has recurred many times in the",
    "start": "822680",
    "end": "829440"
  },
  {
    "text": "human like motor control literature BCI literature uh hri literature it's kind",
    "start": "829440",
    "end": "834880"
  },
  {
    "text": "of a fundamental touchstone for um modeling what people do you know it's a",
    "start": "834880",
    "end": "840399"
  },
  {
    "text": "it's a fiction People have a lot of different priorities and a lot of different motivations for making the decisions they make but you know in",
    "start": "840399",
    "end": "848079"
  },
  {
    "text": "certain circumstances if we prepare the environment properly if we're kind of restricted to you know some favorable",
    "start": "848079",
    "end": "855519"
  },
  {
    "text": "circumstances um they will approximately solve optimization problems so we can leverage that in analyzing and trying to",
    "start": "855519",
    "end": "863360"
  },
  {
    "text": "um make predictions and shape outcomes in these kinds of systems",
    "start": "863360",
    "end": "868880"
  },
  {
    "text": "on the machine side very common that machines adapt and learn by solving",
    "start": "868880",
    "end": "874079"
  },
  {
    "text": "optimization problems what's the loss and then I would just run with it right um of course there are other ways that I",
    "start": "874079",
    "end": "879519"
  },
  {
    "text": "could program my robot but minim minimizing a cost is extremely common another kind of principle we",
    "start": "879519",
    "end": "886800"
  },
  {
    "text": "bring when we look at this problem is we don't assume that the agents can exactly globally solve this optimization problem",
    "start": "886800",
    "end": "892639"
  },
  {
    "text": "so we assume that they have some form of bounded rationality and so um rather than you know perfectly globally",
    "start": "892639",
    "end": "899279"
  },
  {
    "text": "optimizing a problem they might have to do some kind of local search method something gradient- like and so I might",
    "start": "899279",
    "end": "905120"
  },
  {
    "text": "have my machine literally running gradient descent and then I might hypothesize that the human is maybe doing something analogous you know at",
    "start": "905120",
    "end": "911680"
  },
  {
    "text": "least using local information making small changes in their strategy observing the consequences and then trying to you know descend a cost",
    "start": "911680",
    "end": "917839"
  },
  {
    "text": "landscape roughly in that way but that's an open hypothesis um I'll present some",
    "start": "917839",
    "end": "923760"
  },
  {
    "text": "indirect evidence um that uh humans are doing something like this something that's consistent with this um in a few",
    "start": "923760",
    "end": "930560"
  },
  {
    "text": "slides but that's kind of an open you know question of what people actually",
    "start": "930560",
    "end": "935720"
  },
  {
    "text": "do so to study this we created what I think of as the simplest possible human",
    "start": "935720",
    "end": "941199"
  },
  {
    "text": "machine interaction game so we literally scalarized the problem so the human has",
    "start": "941199",
    "end": "947199"
  },
  {
    "text": "one-dimensional kind of like in the first part of the talk a one-dimensional decision variable it gets to choose um",
    "start": "947199",
    "end": "952639"
  },
  {
    "text": "it's a continuous decision variable we're not playing finite games we're playing continuous games and they get to",
    "start": "952639",
    "end": "958399"
  },
  {
    "text": "they get to it's continuous in decision variable and it's also continuous in time they get to uh continually change",
    "start": "958399",
    "end": "964320"
  },
  {
    "text": "this and update this over time and then similarly the machine has its own scalar variable it gets to vary over time",
    "start": "964320",
    "end": "970079"
  },
  {
    "text": "according to one or another of learning algorithms and then we're looking at the interaction between the two so we assume",
    "start": "970079",
    "end": "976160"
  },
  {
    "text": "that they both have their own cost functions in our experiments we prescribe the cost function to the user",
    "start": "976160",
    "end": "982160"
  },
  {
    "text": "and we do that for the purpose of doing the basic science science of what happens when we have these differing cost functions and these differing",
    "start": "982160",
    "end": "988639"
  },
  {
    "text": "adaptation algorithms and how do we you know change um the outcome here um so",
    "start": "988639",
    "end": "993759"
  },
  {
    "text": "for initial experiments we prescribe it but then in the last experiment I'll talk about um we actually leave it up to",
    "start": "993759",
    "end": "1001199"
  },
  {
    "text": "um the user and then we're able uh we're able to predict how they're going to change their strategy based on just some",
    "start": "1001199",
    "end": "1007440"
  },
  {
    "text": "rough approximation or idea about what their cost function probably looks like what some dominant terms in their cost function probably",
    "start": "1007440",
    "end": "1014360"
  },
  {
    "text": "are so when I have these two cost functions there are a number of um well",
    "start": "1014360",
    "end": "1020000"
  },
  {
    "text": "let me put it let me start here when I have a single uh cost function I'm trying to optimize there's really only",
    "start": "1020000",
    "end": "1027120"
  },
  {
    "text": "one prediction of an outcome and that's minimizer local minimizer global minimizer there's really only one",
    "start": "1027120",
    "end": "1033360"
  },
  {
    "text": "candidate for the outcome of an of a good optimization algorithm an optimization algorithm that's working",
    "start": "1033360",
    "end": "1038520"
  },
  {
    "text": "correctly when I have two cost functions and they're not exactly aligned or exactly opposed in the case of like a",
    "start": "1038520",
    "end": "1044079"
  },
  {
    "text": "zero sum game if they're in general sum is a term that's used then there's a lot",
    "start": "1044079",
    "end": "1050080"
  },
  {
    "text": "of different candidate outcomes it could be that we end up at either the human or",
    "start": "1050080",
    "end": "1055520"
  },
  {
    "text": "the machine's global optimum it could be so it could be that either the human or the machine just wins the game right not",
    "start": "1055520",
    "end": "1063280"
  },
  {
    "text": "super likely not generally what we want as the outcome but it's a possibility",
    "start": "1063280",
    "end": "1068880"
  },
  {
    "text": "but there are many other possibilities so if I look at the best response functions which say let me fix one of",
    "start": "1068880",
    "end": "1074960"
  },
  {
    "text": "the decision variables the humans say and then let me find the optimal response to that for the other agent the",
    "start": "1074960",
    "end": "1080320"
  },
  {
    "text": "machine say and then look at that parametrically as a function of that first variable I get these best response",
    "start": "1080320",
    "end": "1085600"
  },
  {
    "text": "curves if the costs are quadratic then the best responses are lines and so this this is a cartoon but it's actually kind",
    "start": "1085600",
    "end": "1091520"
  },
  {
    "text": "of a faithful cartoon accurate representation of what happens where those response curves intersect is",
    "start": "1091520",
    "end": "1097440"
  },
  {
    "text": "called a Nash equilibrium if people are familiar with game theory they're often familiar with this equilibrium",
    "start": "1097440",
    "end": "1106240"
  },
  {
    "text": "concept one way to define it is by the intersection of best response curves as I just did another way to define it is",
    "start": "1107400",
    "end": "1114400"
  },
  {
    "text": "it's a point in this joint action space where neither agent has an incentive to",
    "start": "1114400",
    "end": "1120280"
  },
  {
    "text": "deviate on their own so and I are playing the game and we're at a puditive",
    "start": "1120280",
    "end": "1127200"
  },
  {
    "text": "Nash equilibrium and if it keeps her action the same and I change my action my cost increases and I'm disincclined",
    "start": "1127200",
    "end": "1134000"
  },
  {
    "text": "to make that change and then symmetrically for as well so that's another possible outcome",
    "start": "1134000",
    "end": "1140240"
  },
  {
    "text": "it's not inevitable some people think that the Nash have the mistaken impression that a Nash equilibrium is",
    "start": "1140240",
    "end": "1145760"
  },
  {
    "text": "the inevitable and the and the only kind of ultimate outcome of a game but that's not true there are other possibilities",
    "start": "1145760",
    "end": "1151760"
  },
  {
    "text": "that arise in different circumstances and arrangements another one is a stackleberg equilibrium we're going to",
    "start": "1151760",
    "end": "1157520"
  },
  {
    "text": "specifically focus on a humanled but these show these show up when there's an order of play that's where this idea",
    "start": "1157520",
    "end": "1162960"
  },
  {
    "text": "comes from and so in particular with a humanled the human is going to choose its action and the machine is going to",
    "start": "1162960",
    "end": "1168080"
  },
  {
    "text": "quickly adapt and so in that way the human is leading and the machine is following what the human is showing",
    "start": "1168080",
    "end": "1174520"
  },
  {
    "text": "them and then a final equilibrium concept um we're going to talk about is called a conjectural equilibrium",
    "start": "1174520",
    "end": "1180720"
  },
  {
    "text": "formally it's a consistent conjectural variations equilibrium CCVE but I'm not",
    "start": "1180720",
    "end": "1185760"
  },
  {
    "text": "going to punish you with those four words and that horrible acronym so I'm just going to call it conjectural for",
    "start": "1185760",
    "end": "1192160"
  },
  {
    "text": "the purpose of this talk and the way this arises is um kind of very naturally",
    "start": "1192160",
    "end": "1198000"
  },
  {
    "text": "from stackleberg right so in stackleberg uh human is playing an action and",
    "start": "1198000",
    "end": "1204960"
  },
  {
    "text": "machine is kind of best responding that means that things are going to turn out the stackleberg equilibrium is is almost",
    "start": "1204960",
    "end": "1213120"
  },
  {
    "text": "certainly worse for the machine because the human gets to kind of control the",
    "start": "1213120",
    "end": "1218240"
  },
  {
    "text": "show right they get to run the show um suppose now that the machine decid",
    "start": "1218240",
    "end": "1223280"
  },
  {
    "text": "decides I'm not going to adapt so fast anymore so that I'm the follower i'm going to I'm going to slow down and",
    "start": "1223280",
    "end": "1229200"
  },
  {
    "text": "maybe play a policy and kind of disrupt to this leader follower game that's happening here if the machine is",
    "start": "1229200",
    "end": "1235200"
  },
  {
    "text": "building a model of what the human is doing and then responding to that that's where we can get into this conjectural world it's where internal models are",
    "start": "1235200",
    "end": "1241520"
  },
  {
    "text": "being formed by both the human and the machine both players in the game",
    "start": "1241520",
    "end": "1247840"
  },
  {
    "text": "so then we instantiate this and it's kind of similar uh in terms of human sitting at a you know computer screen um",
    "start": "1247840",
    "end": "1254960"
  },
  {
    "text": "what they're doing is they're using their mouse or touch screen to just move horizontally a cursor horizontally and",
    "start": "1254960",
    "end": "1260080"
  },
  {
    "text": "then their uh vertical bar on the screen is getting larger or smaller and they're told keep this bar as small as possible",
    "start": "1260080",
    "end": "1266799"
  },
  {
    "text": "and so their um manual input their one-dimensional manual input is",
    "start": "1266799",
    "end": "1272400"
  },
  {
    "text": "influencing the height of that bar but behind the scenes invisible to them a machine action machine decision variable",
    "start": "1272400",
    "end": "1278880"
  },
  {
    "text": "m is also influencing the height of that bar so it's this is the cost function we prescribe to the user and we run these",
    "start": "1278880",
    "end": "1285919"
  },
  {
    "text": "experiments on a crowd source platform called prolific um so we can collect lots of data very quickly very cheaply",
    "start": "1285919",
    "end": "1292880"
  },
  {
    "text": "um people play this game you know it takes 10 minutes for them to play it and they get a couple bucks",
    "start": "1292880",
    "end": "1299799"
  },
  {
    "text": "basically uh but it makes it very nice to scale up you know we run we've in my",
    "start": "1299799",
    "end": "1305360"
  },
  {
    "text": "group we run a lot of human subjects experiments in person and like n of 10 is reasonable for a paper and it takes",
    "start": "1305360",
    "end": "1312320"
  },
  {
    "text": "you know the it takes couple hours per subject and so we're talking about you know with setup and breakdown and blah",
    "start": "1312320",
    "end": "1318400"
  },
  {
    "text": "blah blah it's a week of somebody's time in contrast to collect N of 20 or N of a 100 on this platform takes you you push",
    "start": "1318400",
    "end": "1326080"
  },
  {
    "text": "play and you go to launch and you come back and you have your data essentially just to throw that out there it's kind",
    "start": "1326080",
    "end": "1331280"
  },
  {
    "text": "of like it's kind of the the scientific mechanical Turk",
    "start": "1331280",
    "end": "1336320"
  },
  {
    "text": "basically okay so in the I have three results from three experiments to present in the first experiment the",
    "start": "1336440",
    "end": "1341760"
  },
  {
    "text": "machine adapts using gradient descent kind of the most obvious algorithm like let's just run with that and there's a",
    "start": "1341760",
    "end": "1347760"
  },
  {
    "text": "hyperparameter in this algorithm which is the adaptation rate or the learning rate alpha and so we varied that alpha",
    "start": "1347760",
    "end": "1354000"
  },
  {
    "text": "from very slow to very fast and then we looked at the outcomes and what we find is that as learning rate increases we",
    "start": "1354000",
    "end": "1361360"
  },
  {
    "text": "systematically shift from Nash equilibrium at the slowest learning rate to Stackleberg equilibrium at the",
    "start": "1361360",
    "end": "1367120"
  },
  {
    "text": "fastest learning rate and intuitively this makes sense if we think of um Stackleberg as emerging from",
    "start": "1367120",
    "end": "1374080"
  },
  {
    "text": "an order of play because if the human is kind of you know moving their mouse",
    "start": "1374080",
    "end": "1379440"
  },
  {
    "text": "cursor at whatever rate they're moving it you know human speed if the machine is adapting very very quickly it's",
    "start": "1379440",
    "end": "1385760"
  },
  {
    "text": "descending its gradient the gradient of its cost landscape super fast then um",
    "start": "1385760",
    "end": "1391360"
  },
  {
    "text": "it's going to essentially solve its best response function um online and you know",
    "start": "1391360",
    "end": "1396720"
  },
  {
    "text": "continuously in time while the human's moving around so it's not surprising these outcomes aren't surprising but it was nice to see and it's nice to see so",
    "start": "1396720",
    "end": "1403039"
  },
  {
    "text": "clearly you know if we look in the action space we start at the Nash equilibrium which are the bottom dash lines and we um kind of continuously",
    "start": "1403039",
    "end": "1410000"
  },
  {
    "text": "converge to the stackleberg equilibrium which are the top",
    "start": "1410000",
    "end": "1415200"
  },
  {
    "text": "lines in the second experiment oh yeah sorry and an important an interesting takeaway here is um these results are",
    "start": "1416200",
    "end": "1423440"
  },
  {
    "text": "consistent with the human doing something like gradient descent on its own cost uh I I want to make it clear",
    "start": "1423440",
    "end": "1429840"
  },
  {
    "text": "this is not direct evidence of that so I'm being a little I'm overreaching a little bit in making this statement or",
    "start": "1429840",
    "end": "1435280"
  },
  {
    "text": "conclusion um but it's at least human human actions are consistent with using gradient descent um and we have very",
    "start": "1435280",
    "end": "1441919"
  },
  {
    "text": "simple simulation models uh for what the human's algorithm could be that recapitulate these results um but",
    "start": "1441919",
    "end": "1448159"
  },
  {
    "text": "basically if they're doing approximate gradient descent then this is what you would expect",
    "start": "1448159",
    "end": "1454159"
  },
  {
    "text": "so in experiment two we're doing we're looking after uh we're targeting this conjectural equilibrium and like I said this arises",
    "start": "1454159",
    "end": "1461120"
  },
  {
    "text": "from the following kind of thought experiment that I remember I remember distinctly uh I don't know if you",
    "start": "1461120",
    "end": "1467279"
  },
  {
    "text": "remember this Dorso we read these Bayian games papers by Zamir uh right at the",
    "start": "1467279",
    "end": "1472960"
  },
  {
    "text": "end of your or end of my time at Berkeley um and it always stuck with me the following iteration where I have",
    "start": "1472960",
    "end": "1478880"
  },
  {
    "text": "these two agents and the human as we saw in the first part of the talk builds a model of the machine that it interacts",
    "start": "1478880",
    "end": "1484159"
  },
  {
    "text": "with right so it's kind of natural for the machine to build its own model of the human which we also did in the first",
    "start": "1484159",
    "end": "1490240"
  },
  {
    "text": "part of the talk we estimated models of the human feed forward feedback transformations but then if they're playing a game",
    "start": "1490240",
    "end": "1496799"
  },
  {
    "text": "they're strategic decision-making agents and they want to um minimize their respective costs you know potentially at",
    "start": "1496799",
    "end": "1503360"
  },
  {
    "text": "the expense of their opponent or the other player then it's in the human's best interest to build a model of the",
    "start": "1503360",
    "end": "1510240"
  },
  {
    "text": "machine's model of the human and then symmetrically and so on and so on right",
    "start": "1510240",
    "end": "1515520"
  },
  {
    "text": "and then you get this infinite regress and there is this theory this tide theory and different kinds of ideas um",
    "start": "1515520",
    "end": "1523279"
  },
  {
    "text": "uh that I'm citing here um from economic game theory that try to actually",
    "start": "1523279",
    "end": "1529440"
  },
  {
    "text": "computationally or actually analytically handle this infinite regress and then come up with um models for for the",
    "start": "1529440",
    "end": "1536240"
  },
  {
    "text": "limiting process we adopted a kind of different perspective where we directly um model and measure the um the models",
    "start": "1536240",
    "end": "1545279"
  },
  {
    "text": "that the users are building of each other and then analyze as this regress is happening kind of in real time and",
    "start": "1545279",
    "end": "1550960"
  },
  {
    "text": "rolling out over time and so this this is the idea of conjectural variations um it's been around for a long time it's",
    "start": "1550960",
    "end": "1557440"
  },
  {
    "text": "funny i you know I like to get the old citations for stuff in addition to the new citations like the old the initial",
    "start": "1557440",
    "end": "1563440"
  },
  {
    "text": "idea as well as like the good reference for the grad students um nowadays and what's kind of funny is that um the the",
    "start": "1563440",
    "end": "1570240"
  },
  {
    "text": "reference for the Nash equilibrium concept which is kind of the simplest is the latest and then the reference for",
    "start": "1570240",
    "end": "1575600"
  },
  {
    "text": "the conjectural one 1924 most complicated concept is the earliest it's kind of a funny um funny little e",
    "start": "1575600",
    "end": "1582320"
  },
  {
    "text": "version here n version um so the way that we actually cach this out I said before or observed",
    "start": "1582320",
    "end": "1588240"
  },
  {
    "text": "before that since costs are quadratic in our game we prescribe quadratic costs then the machine's best response to the",
    "start": "1588240",
    "end": "1594320"
  },
  {
    "text": "human is a linear fun an aphine function but linear because of the coordinates we",
    "start": "1594320",
    "end": "1599640"
  },
  {
    "text": "chose similarly it's kind of natural to hypothesize that the human's response function is going to be",
    "start": "1599640",
    "end": "1605960"
  },
  {
    "text": "linear and so then the what we do in the experiments is the machine kind of jostles around its policy parameters to",
    "start": "1605960",
    "end": "1613679"
  },
  {
    "text": "estimate the parameters of this human model and Josel is basically the offset in its",
    "start": "1613679",
    "end": "1621440"
  },
  {
    "text": "um policy and then it takes that model and then it solves its optimization problem to decide how to play the",
    "start": "1621440",
    "end": "1628520"
  },
  {
    "text": "game and you could imagine the human may be doing the symmetric thing building an",
    "start": "1628520",
    "end": "1634480"
  },
  {
    "text": "estimate of the machine's policy and then best responding to that policy and",
    "start": "1634480",
    "end": "1639600"
  },
  {
    "text": "so if we run that iteration in our game like just computationally we run the iteration then that converges to this",
    "start": "1639600",
    "end": "1645520"
  },
  {
    "text": "conjectural equilibrium type consistent conjectural variations equilibrium and so we run that",
    "start": "1645520",
    "end": "1651200"
  },
  {
    "text": "experiment and we find that's the result um we get we get exactly that result",
    "start": "1651200",
    "end": "1658360"
  },
  {
    "text": "um we see that we we started at stackleberg equilibrium like I said it's kind of natural this is kind of a",
    "start": "1658360",
    "end": "1663840"
  },
  {
    "text": "natural extension to Stackleberg where initially the machine has no model of the human but the human has a model of",
    "start": "1663840",
    "end": "1670159"
  },
  {
    "text": "the machine's policy and then the machine begins by building a model of the human and then the human builds a",
    "start": "1670159",
    "end": "1676080"
  },
  {
    "text": "model of the machine and we iterate basically and where we're going to converge is a place where um the",
    "start": "1676080",
    "end": "1683520"
  },
  {
    "text": "policies that the individual agents are playing are in fact the policies that",
    "start": "1683520",
    "end": "1688640"
  },
  {
    "text": "their opponents are estimating that's the consistency in the definition of this um equilibrium",
    "start": "1688640",
    "end": "1695159"
  },
  {
    "text": "concept and uh yeah we we see exactly that",
    "start": "1695159",
    "end": "1700559"
  },
  {
    "text": "shift then yeah and I forget that I have these takeaways and so the takeaway is",
    "start": "1700679",
    "end": "1706480"
  },
  {
    "text": "that the human here this is another instance where the human is learning this is strong evidence the human is learning an internal model for the",
    "start": "1706480",
    "end": "1712720"
  },
  {
    "text": "machine if they weren't if they were just playing a fixed policy or if they were continuing to just naively run",
    "start": "1712720",
    "end": "1718480"
  },
  {
    "text": "gradient descent like in the first experiment um we would not expect to observe this outcome but this outcome arises when",
    "start": "1718480",
    "end": "1724559"
  },
  {
    "text": "both agents are iteratively building and updating these models yeah",
    "start": "1724559",
    "end": "1730640"
  },
  {
    "text": "so you talk about bounded rationality and I was wondering if bounded rationality shows up anywhere like in some of these experiments that uh you",
    "start": "1730640",
    "end": "1737520"
  },
  {
    "text": "guys looked at and what would be the formal bounded rationality like the reason I'm thinking about this is we kind of like have this infinite regress",
    "start": "1737520",
    "end": "1743520"
  },
  {
    "text": "and remember like back like a couple years back when we were looking at driving uh you could argue when you're driving right next to another car you",
    "start": "1743520",
    "end": "1750000"
  },
  {
    "text": "could have this infinite regress but in practice that doesn't happen because you have limited time and because you have limited time like like there are these",
    "start": "1750000",
    "end": "1756880"
  },
  {
    "text": "user studies that say well you at most do two levels a fury of mind you don't actually like to do the infinite regress",
    "start": "1756880",
    "end": "1762000"
  },
  {
    "text": "because you have so little time to decide what to do and like what how did and machine here is like the other car",
    "start": "1762000",
    "end": "1767520"
  },
  {
    "text": "and like you're like the driver of like your your own car so so you start seeing like some of these boundary rationalities kicking in in terms of",
    "start": "1767520",
    "end": "1774000"
  },
  {
    "text": "like the interactions and I was wondering if you have various forms of bounded memory bounded time uh and if",
    "start": "1774000",
    "end": "1780399"
  },
  {
    "text": "they show up in some of the experiments you guys were looking at yeah that's a great question um I guess it kind of to",
    "start": "1780399",
    "end": "1787039"
  },
  {
    "text": "me it sort of shows up differently in I'm gonna I'm gonna present one more experiment from this paradigm um and it",
    "start": "1787039",
    "end": "1793919"
  },
  {
    "text": "sort of shows up differently in each of them where uh we have a sort of naive model of what the human's going to or",
    "start": "1793919",
    "end": "1800159"
  },
  {
    "text": "like maybe not naive model we have a mathematical model for what the human's going to do you know we say machine does",
    "start": "1800159",
    "end": "1805760"
  },
  {
    "text": "X we predict human does Y and um if machine does X and human does Y then we",
    "start": "1805760",
    "end": "1813200"
  },
  {
    "text": "should arrive at this equilibrium outcome and if the human wasn't doing Y we should not arrive at that equilibrium outcome and so in each of these cases we",
    "start": "1813200",
    "end": "1820240"
  },
  {
    "text": "are observing convergence to the predicted equilibrium and so to me that's a form of um this is the",
    "start": "1820240",
    "end": "1825760"
  },
  {
    "text": "limitation on the the human's rationality they are playing the game at this level they are not going another",
    "start": "1825760",
    "end": "1831520"
  },
  {
    "text": "layer deep more deeply said that and categorize like what are the different",
    "start": "1831520",
    "end": "1836880"
  },
  {
    "text": "equilibria that they're reaching under yeah exactly like the the equilibrium concept uh is the thing that",
    "start": "1836880",
    "end": "1844320"
  },
  {
    "text": "characterizes how deeply the human is reasoning in that particular game",
    "start": "1844320",
    "end": "1849520"
  },
  {
    "text": "or in their response to that machine algorithm and maybe one follow so um like when we",
    "start": "1849520",
    "end": "1857679"
  },
  {
    "text": "think about like valid rationality um you could capture like how many layers deep you're going but it could",
    "start": "1857679",
    "end": "1864200"
  },
  {
    "text": "capture other things too um like another example that comes to mind is um like",
    "start": "1864200",
    "end": "1871039"
  },
  {
    "text": "there's this game of lunar lander right and and it's motor control like kind of like a game and I remember there was a",
    "start": "1871039",
    "end": "1876399"
  },
  {
    "text": "paper from like this group a couple years back uh where they were saying well humans are not bounded rational",
    "start": "1876399",
    "end": "1882080"
  },
  {
    "text": "when it comes to playing this game the reason they're bad at like the reason we are bad at like playing at playing a",
    "start": "1882080",
    "end": "1887840"
  },
  {
    "text": "game of polar lander is we think we are doing cartisian control but in practice like you're controlling like the",
    "start": "1887840",
    "end": "1893360"
  },
  {
    "text": "acceleration and motors but we think like like we as humans we think in cartian control and that is the reason",
    "start": "1893360",
    "end": "1898960"
  },
  {
    "text": "the model is off so it feels like there are these different forms of boundedness or like how he is making decisions and",
    "start": "1898960",
    "end": "1905120"
  },
  {
    "text": "so in reality if you have seen any forms of various forms of bound rationality or",
    "start": "1905120",
    "end": "1910159"
  },
  {
    "text": "mostly like you're looking at like how many layers of thinking you're going down the tree yeah yeah that's really",
    "start": "1910159",
    "end": "1915840"
  },
  {
    "text": "interesting um I guess uh one observation is from the first part of",
    "start": "1915840",
    "end": "1920960"
  },
  {
    "text": "the talk is there are bounds that show up in sort of the sensor motor transforms people learn and implement um",
    "start": "1920960",
    "end": "1929120"
  },
  {
    "text": "whether they're those are bounds on rationality or just bounds on neurohysiology or something i'm not sure",
    "start": "1929120",
    "end": "1935519"
  },
  {
    "text": "how to tease those apart but um yeah it's it's I hadn't thought of it",
    "start": "1935519",
    "end": "1941120"
  },
  {
    "text": "that way before but I think like one way to think about my talk is it's kind of a sequence of vignettes about the",
    "start": "1941120",
    "end": "1947200"
  },
  {
    "text": "limitations on humans human abilities while interacting with machines whether it's kind of at the sensory motor skill",
    "start": "1947200",
    "end": "1954159"
  },
  {
    "text": "level or it's kind of more cognitive",
    "start": "1954159",
    "end": "1958519"
  },
  {
    "text": "cool any other",
    "start": "1960600",
    "end": "1964158"
  },
  {
    "text": "questions okay I'm going to go into um experiment three and um here we were",
    "start": "1969000",
    "end": "1976000"
  },
  {
    "text": "interested in trying to steer the system outcome to where the machine wants it to go to the machine's global minimizer",
    "start": "1976000",
    "end": "1984399"
  },
  {
    "text": "um and so here the machine does kind of the so I'd say that like straight up",
    "start": "1984399",
    "end": "1990320"
  },
  {
    "text": "gradient descent on actions probably the simplest most obvious algorithm policy gradient probably the next simplest most",
    "start": "1990320",
    "end": "1996399"
  },
  {
    "text": "obvious algorithm and so here machine implements a policy it varies the slope",
    "start": "1996399",
    "end": "2001440"
  },
  {
    "text": "a policy as a line uh an aphine um subspace and then it ver it manipulates",
    "start": "2001440",
    "end": "2007600"
  },
  {
    "text": "the slope of that policy observes the outcomes you know through how the human responds like through that whole closed",
    "start": "2007600",
    "end": "2013519"
  },
  {
    "text": "loop and then um descends that cost that noisy cost landscape and we see that",
    "start": "2013519",
    "end": "2019200"
  },
  {
    "text": "just running this very simple-minded algorithm converges to the machine's global minimum in the game theory",
    "start": "2019200",
    "end": "2024640"
  },
  {
    "text": "literature doing this kind of thing is referred to as designing an incentive um for the other for the human uh to vary",
    "start": "2024640",
    "end": "2032240"
  },
  {
    "text": "to change how they behave and in that case the point that you converge to is called a reverse stackleberg equilibrium",
    "start": "2032240",
    "end": "2038240"
  },
  {
    "text": "or RSE doesn't I just did that mention that as an aside to anybody that does um",
    "start": "2038240",
    "end": "2044799"
  },
  {
    "text": "this kind of work and is interested in those results but um the point being that we can literally coersse the",
    "start": "2044799",
    "end": "2052320"
  },
  {
    "text": "outcome to anything we want just by doing an incredibly simple algorithm and",
    "start": "2052320",
    "end": "2057440"
  },
  {
    "text": "so here is another demonstration of the limitations on rationality for the human because if the human realized this is",
    "start": "2057440",
    "end": "2064398"
  },
  {
    "text": "what was happening um because keep in mind that the machine's minimum is far from the human's minimum so in terms of",
    "start": "2064399",
    "end": "2070878"
  },
  {
    "text": "the prescribed cost this is a much worse outcome for the human if the human could get wise to what the machine was doing",
    "start": "2070879",
    "end": "2077358"
  },
  {
    "text": "then they could play their own policy and then start iterating at at the level of their own policy in the game um but",
    "start": "2077359",
    "end": "2083679"
  },
  {
    "text": "here it appears that they just do the kind of naive gradient descent thing they were doing in the first experiment",
    "start": "2083679",
    "end": "2089440"
  },
  {
    "text": "um and so then we get this outcome and in essence the machine is",
    "start": "2089440",
    "end": "2094480"
  },
  {
    "text": "outsmarting the human in this game it's manipulating the interaction to achieve",
    "start": "2094480",
    "end": "2099599"
  },
  {
    "text": "whatever outcome it wants which I think is is a um if not wholly surprising it",
    "start": "2099599",
    "end": "2106720"
  },
  {
    "text": "could be a potentially a sobering observation that you know in the m the learning algorithms we interact with",
    "start": "2106720",
    "end": "2113359"
  },
  {
    "text": "with machines in our physical environment um could actually strongly",
    "start": "2113359",
    "end": "2119599"
  },
  {
    "text": "uh determine or constrain our behavior actually influence our behavior in a really strong way even with very simple",
    "start": "2119599",
    "end": "2124960"
  },
  {
    "text": "algorithms so returning to this um kind of",
    "start": "2124960",
    "end": "2130400"
  },
  {
    "text": "constellation we had originally um we're able to achieve um a wide variety of",
    "start": "2130400",
    "end": "2136720"
  },
  {
    "text": "game theory equilibria and importantly the way we select them is by the machine choosing a learning algorithm and it's",
    "start": "2136720",
    "end": "2143839"
  },
  {
    "text": "the choice of machine learning algorithm that determines the outcome in this interaction you know human is continually adapting and learning uh on",
    "start": "2143839",
    "end": "2150880"
  },
  {
    "text": "its own and they're intelligent and um can reason in various ways um but the",
    "start": "2150880",
    "end": "2156720"
  },
  {
    "text": "machine is essentially able to steer where the outcome to wherever we want it to",
    "start": "2156720",
    "end": "2162480"
  },
  {
    "text": "go so then the final experiment I want to talk about is taking these ideas away",
    "start": "2163640",
    "end": "2169119"
  },
  {
    "text": "from that these kind of like scalar um little inputs um for the previous",
    "start": "2169119",
    "end": "2174320"
  },
  {
    "text": "paradigms that I talked about and into a um higher dimensional um non-invasive we",
    "start": "2174320",
    "end": "2181040"
  },
  {
    "text": "call it a brain machine interface my collaborator is a legitimate you know neuroscience brain computer interface researcher so she gives me permission to",
    "start": "2181040",
    "end": "2187520"
  },
  {
    "text": "call it a brain machine interface it's going to be a myio surface myiography that we're measuring uh but it's nervous",
    "start": "2187520",
    "end": "2192800"
  },
  {
    "text": "system right it's electrical signals and so we have this high uh density",
    "start": "2192800",
    "end": "2198640"
  },
  {
    "text": "electrode array 64 channels that we put over a patch on the forearm",
    "start": "2198640",
    "end": "2203760"
  },
  {
    "text": "those um signals get integrated um and then they get um uh multiplied by a",
    "start": "2203760",
    "end": "2212560"
  },
  {
    "text": "matrix that kind of decodes and down uh down selects them so we start with 64",
    "start": "2212560",
    "end": "2218400"
  },
  {
    "text": "EMG electrodes and then we end up with two dimensions of um cursor velocity and",
    "start": "2218400",
    "end": "2224240"
  },
  {
    "text": "then we just integrate that um cursor velocity to display a target on a screen and then we have this reference so it's",
    "start": "2224240",
    "end": "2229760"
  },
  {
    "text": "the same kind of paradigm from the first part of the talk um not the bar on the screen but now the squiggle on the",
    "start": "2229760",
    "end": "2235359"
  },
  {
    "text": "screen that we're trying to track but now the input is provided by this um electromyioraphic interface",
    "start": "2235359",
    "end": "2243960"
  },
  {
    "text": "forward to detect the tendons that control the fingers um this is a super fancy EMG so it definitely can we're",
    "start": "2244640",
    "end": "2252000"
  },
  {
    "text": "only using it for very gross we're using it for two dimensions of input so it's just very gross kind of wrist movements",
    "start": "2252000",
    "end": "2259440"
  },
  {
    "text": "well this is a quattrochento uh highdensity um",
    "start": "2259440",
    "end": "2266320"
  },
  {
    "text": "device oh thanks so so here we are doing a function of M but could we do the",
    "start": "2266599",
    "end": "2275200"
  },
  {
    "text": "other way around with with the same setup where you're able to like make",
    "start": "2275200",
    "end": "2280400"
  },
  {
    "text": "human learn from your machine do you mean are you meaning in just the pre previous part of the talk uh no oh in",
    "start": "2280400",
    "end": "2286800"
  },
  {
    "text": "this one okay so here is the sensor uh we're using a sensor to uh you give the",
    "start": "2286800",
    "end": "2292720"
  },
  {
    "text": "instructions to the machine could you do the other way around with the um M uh",
    "start": "2292720",
    "end": "2298320"
  },
  {
    "text": "M2H interface yeah so um terms of the sensory display",
    "start": "2298320",
    "end": "2304160"
  },
  {
    "text": "yeah absolutely let's say someone is like video game and you're able to like uh let them know on their skin whether",
    "start": "2304160",
    "end": "2311760"
  },
  {
    "text": "they like an obstacle yeah absolutely yeah my sort of um you know high level",
    "start": "2311760",
    "end": "2316800"
  },
  {
    "text": "vision in my group is you have the user like in in terms of a block diagram is you have the user um you have the",
    "start": "2316800",
    "end": "2322720"
  },
  {
    "text": "machine you're trying to control the robot or whatever it is and then in in the middle you have the interface and",
    "start": "2322720",
    "end": "2328320"
  },
  {
    "text": "the interface is processing both the motor pathway the motor commands from the person and the sensory feedback to",
    "start": "2328320",
    "end": "2335119"
  },
  {
    "text": "the person um but we haven't done it yet yeah yeah but I'm very interested in you",
    "start": "2335119",
    "end": "2340720"
  },
  {
    "text": "know what does this look like for haptics um with a kind of sci-fi vision that um Amy Osborne who's pictured there",
    "start": "2340720",
    "end": "2347920"
  },
  {
    "text": "and I had um for a um kind of high-risk grant that NSF funded was um uh for",
    "start": "2347920",
    "end": "2356320"
  },
  {
    "text": "invasive neural interfaces you can put electrode arrays in sensory cortex and you can actually render new sense",
    "start": "2356320",
    "end": "2362720"
  },
  {
    "text": "sensory data and so you could make an artificial like one-dimensional",
    "start": "2362720",
    "end": "2369040"
  },
  {
    "text": "uh one dimension of continuous feedback so that they could play the tracking game or something",
    "start": "2369040",
    "end": "2375640"
  },
  {
    "text": "so in our block diagram what we're doing here is hypothesizing or sorry we're",
    "start": "2378160",
    "end": "2383760"
  },
  {
    "text": "deciding that our machine is going to have a cost function and it's going to um be a combination of the tracking",
    "start": "2383760",
    "end": "2391359"
  },
  {
    "text": "error and um the decoder effort so as as a gain matrix how big is this um decoder",
    "start": "2391359",
    "end": "2397520"
  },
  {
    "text": "matrix and then kind of symmetrically we're going to hypothesize that the brain has the same cost this is a common",
    "start": "2397520",
    "end": "2403680"
  },
  {
    "text": "hypothesis that's been proposed by a bunch of other people over you know the last 20 or so years um and for",
    "start": "2403680",
    "end": "2411760"
  },
  {
    "text": "importantly for this part of the talk we don't need to know exactly quantitatively um what this cost function is we just",
    "start": "2411760",
    "end": "2418960"
  },
  {
    "text": "work from the the general structure of the cost function and then make predictions and shape outcomes",
    "start": "2418960",
    "end": "2426519"
  },
  {
    "text": "and so the structure of these costs are that they have this linear convex combination of um or this weighted",
    "start": "2426560",
    "end": "2432640"
  },
  {
    "text": "combination of error and effort um and then we have this hyperparameter um multiplying the effort term and why do",
    "start": "2432640",
    "end": "2439920"
  },
  {
    "text": "we even have these effort terms if they aren't there then um the trivial",
    "start": "2439920",
    "end": "2445119"
  },
  {
    "text": "solution to the game is that we should crank up the gains as high as possible to attenuate error as fast as possible",
    "start": "2445119",
    "end": "2450640"
  },
  {
    "text": "and it's just not realistic it's not plausible that the person can implement that and it'd be you'd just be",
    "start": "2450640",
    "end": "2455680"
  },
  {
    "text": "amplifying noise if you tried to implement um the decoder to do that and so it's kind of a regularization that",
    "start": "2455680",
    "end": "2461520"
  },
  {
    "text": "trades off um between these two things this is very common in control theory if I'm solving an optimal control problem",
    "start": "2461520",
    "end": "2467920"
  },
  {
    "text": "for a linear system i have like an LQR problem i have a Q term and an R term i have a state penalty and an in penalty",
    "start": "2467920",
    "end": "2474400"
  },
  {
    "text": "on the input same idea and we got predict you know we can use",
    "start": "2474400",
    "end": "2480240"
  },
  {
    "text": "this analytically to make predictions about the outcomes in this game and the prediction is very intuitive that the",
    "start": "2480240",
    "end": "2487599"
  },
  {
    "text": "decoder and brain together are going to learn to approximately invert one",
    "start": "2487599",
    "end": "2492640"
  },
  {
    "text": "another so this goes back all the way to the first part of the talk where what people are learning when they're interacting with machines is how to",
    "start": "2492640",
    "end": "2500480"
  },
  {
    "text": "model and then invert their forward dynamics and so these turn out to be the predicted equilibrium outcomes um and",
    "start": "2500480",
    "end": "2507119"
  },
  {
    "text": "they're scaled by this penalty parameter basically the introduction of the penalty parameter means you're not going to get zero tracking error you're going",
    "start": "2507119",
    "end": "2513920"
  },
  {
    "text": "to get some amount of tracking error and it's proportion the amount of error is proportional to that parameter",
    "start": "2513920",
    "end": "2521640"
  },
  {
    "text": "and so the predictions we make are that um if we look at this in this exploded",
    "start": "2521839",
    "end": "2527599"
  },
  {
    "text": "kind of feed forward feedback diagram um we predict that the um the encoder is",
    "start": "2527599",
    "end": "2533839"
  },
  {
    "text": "going to be matched to the de the um matched to the decoder so the decoder is",
    "start": "2533839",
    "end": "2540000"
  },
  {
    "text": "just this first order velocity interface and so then we think that the controller is going to have zeroth order terms and",
    "start": "2540000",
    "end": "2547040"
  },
  {
    "text": "first order terms so terms of control theorist feedback proportional terms that are proportional to error and terms",
    "start": "2547040",
    "end": "2553359"
  },
  {
    "text": "that are proportional to the time derivative of error P and D terms and",
    "start": "2553359",
    "end": "2558800"
  },
  {
    "text": "then um then we make this prediction about the approximate inversion and then also that it's a stable closed loop",
    "start": "2558800",
    "end": "2565200"
  },
  {
    "text": "system and so then what we're able to do experimentally is um measure these Fs and these B's and then test these",
    "start": "2565200",
    "end": "2572240"
  },
  {
    "text": "various predictions so basically these predictions bear out if I look at um the terms in the kind of",
    "start": "2572240",
    "end": "2579040"
  },
  {
    "text": "zeroth order term they're approximately zero if I look at the terms in the first order term they're almost an identity",
    "start": "2579040",
    "end": "2584400"
  },
  {
    "text": "matrix um this gap along these diagonal terms kind of goes all the way back to",
    "start": "2584400",
    "end": "2591599"
  },
  {
    "text": "the first part of the talk where I had the bodde plots and I showed what m inverse would look like in magnitude and",
    "start": "2591599",
    "end": "2597280"
  },
  {
    "text": "then um what the feed forward controller actually looks like sort of it's an attenuated version of the um of the uh",
    "start": "2597280",
    "end": "2605520"
  },
  {
    "text": "actually exactly inverting controller and then we get stability of the closed loop system we already knew",
    "start": "2605520",
    "end": "2611359"
  },
  {
    "text": "the closed loop system was stable because the cursor didn't fly off the screen but this is just a this is more a",
    "start": "2611359",
    "end": "2616400"
  },
  {
    "text": "validation that our estimation methods make sense and give kind of consistent",
    "start": "2616400",
    "end": "2622000"
  },
  {
    "text": "predictions so we get consistency with our control theory predictions for the system and then we're going to vary that",
    "start": "2622280",
    "end": "2629839"
  },
  {
    "text": "penalty parameter and see how that shifts things and um what we observe is that by cranking",
    "start": "2629839",
    "end": "2638880"
  },
  {
    "text": "up that penalty parameter in our so we don't get to change the human's cost function that one might have penalties",
    "start": "2638880",
    "end": "2644400"
  },
  {
    "text": "it might not we don't have control over it but we do have control over the decoder the machine's penalty parameter",
    "start": "2644400",
    "end": "2651119"
  },
  {
    "text": "and so if we crank that up then for high lambda the decoder effort term gets",
    "start": "2651119",
    "end": "2658040"
  },
  {
    "text": "smaller very in intuitive outcome not surprising but it was good to see it",
    "start": "2658040",
    "end": "2664079"
  },
  {
    "text": "bear out in practice and then the opposite happens um for the encoder the encoder has to crank up its gain to",
    "start": "2664079",
    "end": "2670520"
  },
  {
    "text": "compensate and so then at high lambda we get a larger um encoder",
    "start": "2670520",
    "end": "2676200"
  },
  {
    "text": "effort so this is consistent with our game theory predictions",
    "start": "2676200",
    "end": "2682240"
  },
  {
    "text": "and so the takeaway here is that we were able to not only predict the outcomes we were going to get by going in and",
    "start": "2682240",
    "end": "2688960"
  },
  {
    "text": "tweaking the machine learning algorithm uh the machine's cost function but we're also able to shape it in the sense of",
    "start": "2688960",
    "end": "2695520"
  },
  {
    "text": "manipulating uh user effort while they're using this system so you could imagine in like a rehabilitation cont",
    "start": "2695520",
    "end": "2702079"
  },
  {
    "text": "context you might want to be uh the clinician might want to be able to systematically change the amount of user",
    "start": "2702079",
    "end": "2708480"
  },
  {
    "text": "you know muscle activity or effort they're exerting in a particular treatment um and so this gives a kind of",
    "start": "2708480",
    "end": "2714480"
  },
  {
    "text": "principled systematic way to achieve that kind of",
    "start": "2714480",
    "end": "2719119"
  },
  {
    "text": "manipulation so that concludes the second part um the big takeaway is that",
    "start": "2719800",
    "end": "2725200"
  },
  {
    "text": "these machine learning algorithms can shape outcomes we can you know in one class of experiments select from a whole",
    "start": "2725200",
    "end": "2730640"
  },
  {
    "text": "constellation of game theory equilibria and then in another um experiment we're able to nudge the user in a desired um",
    "start": "2730640",
    "end": "2740240"
  },
  {
    "text": "direction and so I just want to advocate for this idea of bringing game theory into these human machine interactions",
    "start": "2740680",
    "end": "2747119"
  },
  {
    "text": "it's something that I've been really excited about for years um and that I think I think needs more recognition has",
    "start": "2747119",
    "end": "2753599"
  },
  {
    "text": "more potential uh to grow so with that I'd love to thank you for your time um",
    "start": "2753599",
    "end": "2759680"
  },
  {
    "text": "and uh love to take any questions [Applause]",
    "start": "2759680",
    "end": "2769380"
  },
  {
    "text": "so so you talked about like the gay theory ideas and I was wondering and you talked in the context of what control but um how do you think like things",
    "start": "2770800",
    "end": "2778240"
  },
  {
    "text": "would change if you go outside of what talk about other types of human robot interactions this morning you were talking about these diatic interactions",
    "start": "2778240",
    "end": "2784800"
  },
  {
    "text": "where there's a robot arm and there's a human and they're trying to extend here so like like do you think similar type",
    "start": "2784800",
    "end": "2791040"
  },
  {
    "text": "of ideas there or like have you been looking at multi motor control tasks or",
    "start": "2791040",
    "end": "2796800"
  },
  {
    "text": "how should you think about your scope yeah it's a great question um I'd say my my particular interest and focus is on",
    "start": "2796800",
    "end": "2804640"
  },
  {
    "text": "um situations where the the machine is really attached to or tightly integrated",
    "start": "2804640",
    "end": "2810640"
  },
  {
    "text": "with the person and either um you know restoring or like adding or augmenting",
    "start": "2810640",
    "end": "2816960"
  },
  {
    "text": "like you said motor control in one variety or another so I can I can foresee um really obvious generalization",
    "start": "2816960",
    "end": "2824319"
  },
  {
    "text": "of these kinds of results into like invasive neural interfaces because we're already did non-invasive or um wearables",
    "start": "2824319",
    "end": "2831880"
  },
  {
    "text": "exoskeletons things like that um for the co-roobots I have if I had a good idea I",
    "start": "2831880",
    "end": "2838640"
  },
  {
    "text": "would be doing it I think is my bit answer um so yeah",
    "start": "2838640",
    "end": "2845040"
  },
  {
    "text": "I'm not I'm not sure what the um what the right way to do it is um I guess",
    "start": "2845040",
    "end": "2851280"
  },
  {
    "text": "there's kind of a I mean maybe I shouldn't end by being controversial but there's sort of an issue which is um",
    "start": "2851280",
    "end": "2857680"
  },
  {
    "text": "should robots and people be in the same spaces doing stuff it's kind of kind of this general question but",
    "start": "2857680",
    "end": "2866280"
  },
  {
    "text": "yeah so it's more of a question so we had like tools to uh let's say for",
    "start": "2866400",
    "end": "2872640"
  },
  {
    "text": "humans to learn about the machines but we are we are doing it both ways uh so",
    "start": "2872640",
    "end": "2877920"
  },
  {
    "text": "even machines are like learning about humans in in full model but now that we",
    "start": "2877920",
    "end": "2883760"
  },
  {
    "text": "have um the semantic models so it it might be like a different new paradigm",
    "start": "2883760",
    "end": "2889119"
  },
  {
    "text": "where we can like enable machines to learn more about the human interaction so what do you think about that future",
    "start": "2889119",
    "end": "2898680"
  },
  {
    "text": "um I might need you to restate or rephrase your question okay so just like",
    "start": "2899000",
    "end": "2907520"
  },
  {
    "text": "humans are learning about machines machines are running through this model but machines did not have let's say LLMs",
    "start": "2907520",
    "end": "2914720"
  },
  {
    "text": "before okay and now we have LLM so maybe machines have better tools to learn",
    "start": "2914720",
    "end": "2920480"
  },
  {
    "text": "about human behavior so in that way how do you see the future i see",
    "start": "2920480",
    "end": "2928078"
  },
  {
    "text": "um I think I might have really dissatisfying answers for two questions in a row",
    "start": "2929960",
    "end": "2937200"
  },
  {
    "text": "um I would love to I would love to see and test whether any of these ideas show",
    "start": "2937640",
    "end": "2945079"
  },
  {
    "text": "up in that complex of an interaction um you know I think",
    "start": "2945079",
    "end": "2952359"
  },
  {
    "text": "there's there are possibly hints that it might",
    "start": "2952359",
    "end": "2957480"
  },
  {
    "text": "um my collaborator Lillian Ratliff um who's the game theory expert um has",
    "start": "2957480",
    "end": "2965359"
  },
  {
    "text": "taken some of these basic ideas and then um shown how they how the different",
    "start": "2965359",
    "end": "2971440"
  },
  {
    "text": "outcomes can show up when you have two like largecale learning algorithms",
    "start": "2971440",
    "end": "2977280"
  },
  {
    "text": "interacting with one other um and so that's a that's kind of more broadly",
    "start": "2977280",
    "end": "2983119"
  },
  {
    "text": "that's one direction this kind of work could go in is not even human machine anymore but just machine machine you",
    "start": "2983119",
    "end": "2989760"
  },
  {
    "text": "know two AI algorithms um but yeah it would be yeah it would be",
    "start": "2989760",
    "end": "2996000"
  },
  {
    "text": "beautiful to see a Nash equilibrium uh between an LLM and a human um I think we",
    "start": "2996000",
    "end": "3002079"
  },
  {
    "text": "need to you know what is it's kind of similar with the human robot space like what is what What is the problem what is",
    "start": "3002079",
    "end": "3008800"
  },
  {
    "text": "the cost function that we we think the human might be minimizing and that we",
    "start": "3008800",
    "end": "3014319"
  },
  {
    "text": "would want to design a machine to be minimizing so what is the task what is the problem",
    "start": "3014319",
    "end": "3020000"
  },
  {
    "text": "that's my very dissatisfying i'm dissatisfied with my answer to your question but that's what I've got",
    "start": "3020000",
    "end": "3028280"
  },
  {
    "text": "yeah um earlier you mentioned that you use the gradient descent method for",
    "start": "3028960",
    "end": "3034000"
  },
  {
    "text": "finding the optimization and I was wondering if you use um in using a direct method like the",
    "start": "3034000",
    "end": "3041680"
  },
  {
    "text": "hook he method I was wondering if using a direct algorithm that wouldn't require",
    "start": "3041680",
    "end": "3047760"
  },
  {
    "text": "you finding the gradient how would that impact the result",
    "start": "3047760",
    "end": "3053359"
  },
  {
    "text": "that's that's really interesting I'm not familiar with the particular scheme you're talking about can you describe",
    "start": "3053359",
    "end": "3058720"
  },
  {
    "text": "like is it a zeroth order method well it's a second order method that requires",
    "start": "3058720",
    "end": "3064720"
  },
  {
    "text": "no gradient a second order method that requires no gradient",
    "start": "3064720",
    "end": "3070319"
  },
  {
    "text": "wow it doesn't require you just finding the gradient to find the optimiz but so",
    "start": "3070319",
    "end": "3075359"
  },
  {
    "text": "is it estimating the gradient from function evaluations or um",
    "start": "3075359",
    "end": "3081400"
  },
  {
    "text": "well I'm trying to recollect how that works so basically it kind of goes",
    "start": "3081400",
    "end": "3088119"
  },
  {
    "text": "over the searching different minimizers and",
    "start": "3088119",
    "end": "3093680"
  },
  {
    "text": "just like optimizing as it goes along but it requires no gradient so I was",
    "start": "3093680",
    "end": "3098960"
  },
  {
    "text": "wondering if using a direct method would impact the whole",
    "start": "3098960",
    "end": "3104599"
  },
  {
    "text": "result that's really interesting um uh I think my so again not knowing not",
    "start": "3104599",
    "end": "3112480"
  },
  {
    "text": "knowing any details about that particular method I think my general answer would be um that you know based",
    "start": "3112480",
    "end": "3118559"
  },
  {
    "text": "on what we've observed different algorithms give rise to different outcomes and so you might imagine that",
    "start": "3118559",
    "end": "3124160"
  },
  {
    "text": "you end up at a completely different equilibrium concept um yeah",
    "start": "3124160",
    "end": "3132359"
  },
  {
    "text": "yeah um I'm curious to hear what are your thoughts on um maybe using some of",
    "start": "3132640",
    "end": "3138240"
  },
  {
    "text": "the conclusions from your work um and applying that to for example a case like",
    "start": "3138240",
    "end": "3143440"
  },
  {
    "text": "sports because in my head I'm thinking about how um for example in a tennis",
    "start": "3143440",
    "end": "3148960"
  },
  {
    "text": "match two players are like really trying like ultimately as a as a player you're you're not just learning reacting to",
    "start": "3148960",
    "end": "3155359"
  },
  {
    "text": "what's happening in front of you but also trying to figure out how your opponent plays and in a way I I feel",
    "start": "3155359",
    "end": "3161040"
  },
  {
    "text": "like that's very similar to the human learning about the machine and the machine learning about the human and I",
    "start": "3161040",
    "end": "3167040"
  },
  {
    "text": "wonder if there this this kind of framework could be applied um in those s",
    "start": "3167040",
    "end": "3172800"
  },
  {
    "text": "sort of circumstances where like a human's ability to do a certain task could improve u could be in sports could",
    "start": "3172800",
    "end": "3181040"
  },
  {
    "text": "be in something else as well like in a particular game yeah no that's super",
    "start": "3181040",
    "end": "3186559"
  },
  {
    "text": "interesting um you know maybe tennis might be hard because we don't have robots that are that athletic but maybe",
    "start": "3186559",
    "end": "3192480"
  },
  {
    "text": "table tennis you know I just saw um uh demo of that",
    "start": "3192480",
    "end": "3199960"
  },
  {
    "text": "um I I really think that these ideas uh I really think that people are as",
    "start": "3199960",
    "end": "3206000"
  },
  {
    "text": "they're playing games like that competitive games um building models in real time and updating them in real time",
    "start": "3206000",
    "end": "3212720"
  },
  {
    "text": "and then um you know any weakness in the opponent's strategy is being you know",
    "start": "3212720",
    "end": "3218319"
  },
  {
    "text": "instantly exploited basically so it would be super cool to see um to endow",
    "start": "3218319",
    "end": "3223680"
  },
  {
    "text": "machines with that same level um you know I have a seven-year-old and so playing some games with her um either",
    "start": "3223680",
    "end": "3231280"
  },
  {
    "text": "you know board games or sports kind of games um it's it's interesting to kind",
    "start": "3231280",
    "end": "3236720"
  },
  {
    "text": "of probe her level of reason and you know the bounds on her rationality and things like that um yeah I think that'd",
    "start": "3236720",
    "end": "3244160"
  },
  {
    "text": "be",
    "start": "3244160",
    "end": "3246318"
  },
  {
    "text": "[Music] fascinating great thanks everybody for your time have a great weekend",
    "start": "3251340",
    "end": "3260280"
  }
]
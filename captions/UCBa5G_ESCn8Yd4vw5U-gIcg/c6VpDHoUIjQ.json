[
  {
    "text": "So today, we'll be talking about lifelong learning. Um, and all- it's first logistics,",
    "start": "4310",
    "end": "11460"
  },
  {
    "text": "uh, the project milestones are due on Wednesday, uh, and next week we have two guest lectures, uh,",
    "start": "11460",
    "end": "16945"
  },
  {
    "text": "by Jeff Clune and Sergey Levine and I, uh, highly encourage you to inten- attend in person.",
    "start": "16945",
    "end": "22529"
  },
  {
    "text": "I think that their talks will be, uh, pretty neat talking about, uh, probably talking- like I don't know the parti- particular topic of just the",
    "start": "22530",
    "end": "30190"
  },
  {
    "text": "lecture yet but it'll probably be covering things like evolutionary methods, um, more advanced topics in",
    "start": "30190",
    "end": "35380"
  },
  {
    "text": "lifelong learning than the things that we'll be covering today, uh, as well as other, uh,",
    "start": "35380",
    "end": "40405"
  },
  {
    "text": "kind of interesting topics in the context of control, animation, evolution, those sorts of things.",
    "start": "40405",
    "end": "46055"
  },
  {
    "text": "Uh, and then Sergey Levine will be talking about information theoretic exploration and unsupervised reinforcement learning and how that can",
    "start": "46055",
    "end": "52310"
  },
  {
    "text": "be pertained to a form of task-agnostic reinforcement learning where you want to pre-train before knowing what task you're going to be doing.",
    "start": "52310",
    "end": "60235"
  },
  {
    "text": "All right, so, um, the plan for today is, uh, we'll be talking about lifelong learning,",
    "start": "60235",
    "end": "65495"
  },
  {
    "text": "and before I go over the outline, I guess I'd like to preface this, preface this lecture by",
    "start": "65495",
    "end": "72590"
  },
  {
    "text": "saying that in many ways lifelong learning I think is, uh, a very active area of research and a very open area of research,",
    "start": "72590",
    "end": "80290"
  },
  {
    "text": "and I don't think that, um, as with a couple of the other lectures in this course I think there may be more questions than answers.",
    "start": "80290",
    "end": "86510"
  },
  {
    "text": "Uh, and so, uh, I'm going to try to have some, some interactions and some engagement with regard to, uh,",
    "start": "86510",
    "end": "92655"
  },
  {
    "text": "some of those questions so that we can, um, think about them in the lecture as well.",
    "start": "92655",
    "end": "97835"
  },
  {
    "text": "So, um, first, we'll be talking about the lifelong learning problem statement, uh, then we'd be talking about some basic approaches to lifelong learning, uh,",
    "start": "97835",
    "end": "106865"
  },
  {
    "text": "and then we'll think about can we do better than these basics and we'll see two examples of ways that we can do better,",
    "start": "106865",
    "end": "111899"
  },
  {
    "text": "uh, and then revisit the problem statement of lifelong learning from the perspective of meta-learning.",
    "start": "111900",
    "end": "117590"
  },
  {
    "text": "Okay. So let's first start by talking about the problem statement. Uh, and this is actually probably one of the biggest topics of the lecture,",
    "start": "117590",
    "end": "125350"
  },
  {
    "text": "uh, which is how do you actually formulate the problem of lifelong learning? Uh, and to review the,",
    "start": "125350",
    "end": "130940"
  },
  {
    "text": "the two main problem statements that we focused on in this course have been multitask learning and meta-learning which may be in",
    "start": "130940",
    "end": "136450"
  },
  {
    "text": "the context of supervised learning or reinforcement learning, um, and in multi-task learning the goal is to solve some set of tasks and then",
    "start": "136450",
    "end": "142390"
  },
  {
    "text": "perform those tasks and in meta-learning the goal is to use, uh, experience from a set of tasks to be able to quickly learn a new task.",
    "start": "142390",
    "end": "149605"
  },
  {
    "text": "And so, uh, the motivation behind things like lifelong learning is that,",
    "start": "149605",
    "end": "155334"
  },
  {
    "text": "uh, in practice, unlike these problem statements, um, are kind of the real world may look something like this where we",
    "start": "155335",
    "end": "162760"
  },
  {
    "text": "don't have access to a set of tasks right off the bat, and instead we need to be learning, uh,",
    "start": "162760",
    "end": "169180"
  },
  {
    "text": "in a more incremental or online fashion where we are given objectives one at a time and we save T data,",
    "start": "169180",
    "end": "175310"
  },
  {
    "text": "uh, in a stream rather than in, a batch. And so this is kind of a general temporal view of multitask learning or meta-learning.",
    "start": "175310",
    "end": "187069"
  },
  {
    "text": "Uh, is, is kind of what underpins the, um, kind of idea behind things like life-long learning.",
    "start": "187070",
    "end": "193810"
  },
  {
    "text": "So, um, some examples of these, uh, that I came up with, there are many other examples, uh,",
    "start": "193810",
    "end": "200880"
  },
  {
    "text": "of lifelong learning systems, in, uh, that we may want to be able to create. So one example is a student, uh,",
    "start": "200880",
    "end": "207650"
  },
  {
    "text": "learning concepts in school, learning, uh, for example math concepts ranging from, um, simple addition to long division to, um,",
    "start": "207650",
    "end": "216260"
  },
  {
    "text": "to, uh, algebra and calculus, etc. Um, another example might be,",
    "start": "216260",
    "end": "223880"
  },
  {
    "text": "uh, say you are, uh, you have some image classification system and you want to deploy it to help, uh,",
    "start": "223880",
    "end": "229190"
  },
  {
    "text": "classify people's images, uh, for different users, and if it's deployed in the world,",
    "start": "229190",
    "end": "234780"
  },
  {
    "text": "it will be seeing a stream of images and it will be given different, uh, tasks over time.",
    "start": "234780",
    "end": "240319"
  },
  {
    "text": "And that may- may be a stationary distribution, may be a non-stationary distribution, uh, because the world is, is changing and also the, the kinds of pictures that people take change over time.",
    "start": "240320",
    "end": "249275"
  },
  {
    "text": "Um, another example is, uh, something like a robot acquiring an increasingly large set of skills, uh, in different environments.",
    "start": "249275",
    "end": "255080"
  },
  {
    "text": "So in practice we, uh, we may want robots to do many different things that we might not know right off the bat everything that we may want the robot to do.",
    "start": "255080",
    "end": "262090"
  },
  {
    "text": "Uh, so instead you wanna kinda have this sequential setting. Um, also in the cut of in the context of language,",
    "start": "262090",
    "end": "268650"
  },
  {
    "text": "you can imagine a virtual assistant helping different users with different, uh, different tasks at different points of time, um,",
    "start": "268650",
    "end": "273965"
  },
  {
    "text": "or something like a doctor's assistant aiding in medical decision making decisions. Um, in each of these cases,",
    "start": "273965",
    "end": "279920"
  },
  {
    "text": "I guess one of the key ideas behind lifelong learning is that when you deploy a machine learning system,",
    "start": "279920",
    "end": "285185"
  },
  {
    "text": "it shouldn't be fixed. Uh, you shouldn't just kind of keep its weights the same and deploy it and run it.",
    "start": "285185",
    "end": "291280"
  },
  {
    "text": "Uh, instead it should be continuing to learn based off of the data that it sees. Uh, and that will allow it to handle, um,",
    "start": "291280",
    "end": "298510"
  },
  {
    "text": "challenges related to non-stationarity, and challenges relating to, uh, it seeing tasks that it wasn't trained to do in the past.",
    "start": "298510",
    "end": "306050"
  },
  {
    "text": "Okay, so with that in mind, uh, first some terminology.",
    "start": "306050",
    "end": "312669"
  },
  {
    "text": "So, uh, you could broadly view this class of problems as a form of sequential learning problem where you're given data,",
    "start": "312670",
    "end": "320270"
  },
  {
    "text": "or you're given tasks in sequence, but there are a lot of different terms that have been used to",
    "start": "320270",
    "end": "325550"
  },
  {
    "text": "describe these kinds of sequential learning settings, ranging from things like online learning, lifelong learning, continual learning,",
    "start": "325550",
    "end": "331925"
  },
  {
    "text": "incremental learning, streaming machine learning, or streaming model or streaming data.",
    "start": "331925",
    "end": "337140"
  },
  {
    "text": "Um, I think all of these fall into the category of sequential learning.",
    "start": "337140",
    "end": "342170"
  },
  {
    "text": "Uh, in general, the community doesn't use consistent terminology for many of these terms, unfortunately.",
    "start": "342170",
    "end": "349350"
  },
  {
    "text": "Uh, so I think that the- all, all of you, I'll define a couple of these terms, uh,",
    "start": "349350",
    "end": "355310"
  },
  {
    "text": "throughout the lecture but otherwise I think that, uh, when reading the literature I wouldn't necessarily assume that these mean different things, they may all just mean the same thing.",
    "start": "355310",
    "end": "363470"
  },
  {
    "text": "Whether, and it's a bit dissatisfying I know, uh, but and then maybe in the future we can try to actually assign different names to",
    "start": "363470",
    "end": "370430"
  },
  {
    "text": "these terms or better define the types of things that we're talking about. Um, and it's also worth mentioning that this is distinct from sequence data.",
    "start": "370430",
    "end": "377600"
  },
  {
    "text": "Uh, for example if it's something like language is a sequential form of data but that doesn't mean that you're learning from it in sequence,",
    "start": "377600",
    "end": "384910"
  },
  {
    "text": "you might- you could still have a batch of sequential data that you're learning from. Um, and likewise, this is also different from sequential decision-making,",
    "start": "384910",
    "end": "392225"
  },
  {
    "text": "things like reinforcement learning are a form of a sequential decision-making problem where the actions that you take at your current time affect the next action.",
    "start": "392225",
    "end": "400100"
  },
  {
    "text": "Um but you could also do sequential decision-making in a batch learning setting where you're just given one environment and",
    "start": "400100",
    "end": "406580"
  },
  {
    "text": "one batch of data from that environment and you want to learn a policy. Uh, and so these kind of, there's like three different forms of viewing, uh,",
    "start": "406580",
    "end": "414960"
  },
  {
    "text": "sequential data, sequence decision-making and sequential learning, and in this lecture will be focusing on sequential learning.",
    "start": "414960",
    "end": "421625"
  },
  {
    "text": "Okay, any questions? All right,",
    "start": "421625",
    "end": "429060"
  },
  {
    "text": "so I want to do a little exercise. Um, so I don't think that there's really, as I kind of",
    "start": "429060",
    "end": "435500"
  },
  {
    "text": "alluded to you before I don't think there is necessarily any consensus to what the lifelong learning problem statement is. Uh, and I think that actually in many different contexts,",
    "start": "435500",
    "end": "442160"
  },
  {
    "text": "it will vary based off of the things that you care about in that application. Uh, and so what I'd like to do in the next",
    "start": "442160",
    "end": "450060"
  },
  {
    "text": "like I don't know 5-10 minutes is I'll have each of you, uh, pick an example problem setting, uh,",
    "start": "450060",
    "end": "456670"
  },
  {
    "text": "from the example problem settings that I showed on the previous slide and I'll bring them back up again. Uh, and then- or maybe also pair up, uh,",
    "start": "456670",
    "end": "463735"
  },
  {
    "text": "with someone or form a group of two or three and discuss the problem statement corresponding to that problem setting with,",
    "start": "463735",
    "end": "469909"
  },
  {
    "text": "uh, with your partner. Uh, and in particular try to answer the questions such as, uh,",
    "start": "469910",
    "end": "475580"
  },
  {
    "text": "how do you set up an experiment in order to develop and test your algorithm, and this will kind of help you identify the sort",
    "start": "475580",
    "end": "481820"
  },
  {
    "text": "of actual underlying problem statement underlying that example. Um, what are desirable, desirable or required properties of the algorithm,",
    "start": "481820",
    "end": "489500"
  },
  {
    "text": "uh, as they pertain to different things like memory, privacy, uh, data, uh, those sorts of things,",
    "start": "489500",
    "end": "495960"
  },
  {
    "text": "what things do you want out of your algorithm and that problem setting and then also how do you evaluate a system.",
    "start": "495960",
    "end": "501335"
  },
  {
    "text": "So if you have an algorithm that can solve the lifelong learning problem, uh, how would you actually go about evaluating whether or not",
    "start": "501335",
    "end": "507650"
  },
  {
    "text": "it's doing a good job or doing a bad job. Okay, so, uh, here are the examples that I showed on the previous slide.",
    "start": "507650",
    "end": "517115"
  },
  {
    "text": "If you want, you can also come up with a new example setting if, uh, if you're, uh, feeling creative and I'll give you a few minutes to chat with, uh,",
    "start": "517115",
    "end": "526759"
  },
  {
    "text": "chat with someone else in the room about these problem statements. Ready, go.",
    "start": "526760",
    "end": "533430"
  },
  {
    "text": "Oh, and then afterwards I'm going to ask you guys to say what you discussed and what was",
    "start": "543920",
    "end": "550079"
  },
  {
    "text": "specific to that problem-solving. [BACKGROUND].",
    "start": "661070",
    "end": "820000"
  },
  {
    "text": "Okay. Are you ready to regroup or do you need another minute?",
    "start": "820000",
    "end": "825500"
  },
  {
    "text": "Raise your hand if you think you'll need another minute. Yeah. I should. [LAUGHTER]",
    "start": "825890",
    "end": "833410"
  },
  {
    "text": "Okay. Let's regroup and you guys- you guys can pick all-I'll, go visit you guys last. Okay, um, so let's start with this group right here.",
    "start": "833410",
    "end": "842079"
  },
  {
    "text": "So what- which example did you pick, uh, and what were your considerations for A, B, and C?",
    "start": "842080",
    "end": "847300"
  },
  {
    "text": "Uh, so we picked the students learning concepts in school. And then in terms of an experiment,",
    "start": "847300",
    "end": "853509"
  },
  {
    "text": "we kind of divided it into two sections. So one, the student would be able- would each be able to learn new concepts without forgetting old ones.",
    "start": "853510",
    "end": "860620"
  },
  {
    "text": "So kind of eliminate or reduce negative transfer. Okay. So like ne- negative backward transfer?",
    "start": "860620",
    "end": "868600"
  },
  {
    "text": "Yeah. All right. So this is for A? You can keep on talking.",
    "start": "868600",
    "end": "874750"
  },
  {
    "text": "[inaudible] And then another property",
    "start": "874750",
    "end": "880810"
  },
  {
    "text": "would be to take in [inaudible] increasing complexity, so sort of challenge themselves to kind of, um,",
    "start": "880810",
    "end": "888175"
  },
  {
    "text": "like push themselves and learn something new based on  [inaudible]. Cool. So like they have the ability to generate new tasks.",
    "start": "888175",
    "end": "895410"
  },
  {
    "text": "Yeah. And how- how would you evaluate that ability? So in terms of the experiment and test- testing",
    "start": "895410",
    "end": "903025"
  },
  {
    "text": "we were thinking about- so we have a sequence of tasks, uh, with increasing complexity.",
    "start": "903025",
    "end": "908080"
  },
  {
    "text": "All right. Cool. Yeah. So the experimental setup would have like increasingly difficult tasks.",
    "start": "908080",
    "end": "914095"
  },
  {
    "text": "We weren't sure exactly how you were going to evaluate it, but we were considering the decoding like the task generation,",
    "start": "914095",
    "end": "922450"
  },
  {
    "text": "with some latent distribution and then maybe measuring the entropy of the distribution and try to kind of like increase that from task to task.",
    "start": "922450",
    "end": "930190"
  },
  {
    "text": "Okay. So- yeah. Seeing if they can generate a broader range of tasks. And you probably want something in addition to just entropy of that test distribution,",
    "start": "930190",
    "end": "937840"
  },
  {
    "text": "maybe you have something relating to, uh, whether or not they're solvable tasks or something.",
    "start": "937840",
    "end": "943089"
  },
  {
    "text": "Okay. Cool, anything else to add? Well, maybe the [inaudible].",
    "start": "943090",
    "end": "951820"
  },
  {
    "text": "Right so you're saying that maybe you don't need to- maybe it's okay to forget some things? Yeah. Okay. Cool. Okay. Uh, next group.",
    "start": "951820",
    "end": "960850"
  },
  {
    "text": "[inaudible].",
    "start": "960850",
    "end": "991300"
  },
  {
    "text": "Okay. So you're saying that basically, you want to maintain a distribution over all of your previous tasks, and evaluate it on all of the previous tasks?",
    "start": "991300",
    "end": "998610"
  },
  {
    "text": "Yeah. Okay. Cool. Um, I'll put that under evaluation.",
    "start": "998610",
    "end": "1004389"
  },
  {
    "text": "And then just- the second point was maybe, uh- maybe you don't care about all of the past tasks,",
    "start": "1005870",
    "end": "1011880"
  },
  {
    "text": "but just a subset of them, or a certain distribution over them? Yeah. Yeah. Okay. Cool. Anything that was different",
    "start": "1011880",
    "end": "1017459"
  },
  {
    "text": "from the first group that you felt like wasn't important? [inaudible].",
    "start": "1017460",
    "end": "1029640"
  },
  {
    "text": "Yeah. So like where does the curriculum of tasks come from? Right. Yeah. Yeah. That's a good question.",
    "start": "1029640",
    "end": "1035324"
  },
  {
    "text": "Uh, I- I don't- I guess I don't really have a box for that, but yeah, that's good. Okay, next group.",
    "start": "1035325",
    "end": "1042569"
  },
  {
    "text": "Yeah. Okay. [inaudible] At the same time,",
    "start": "1042570",
    "end": "1052890"
  },
  {
    "text": "[inaudible] sort of an abstract is possible thing [inaudible] transfer that",
    "start": "1052890",
    "end": "1063060"
  },
  {
    "text": "you're also thinking about how this might potentially have to be evaluated [inaudible] in terms of",
    "start": "1063060",
    "end": "1070755"
  },
  {
    "text": "which sort of problems are presented to the robot as [inaudible] really influence which kind of skills get acquired.",
    "start": "1070755",
    "end": "1078600"
  },
  {
    "text": "I see. So you're thinking about both- like how the evaluations kind of intermixed into the learning process itself. Yeah.",
    "start": "1078600",
    "end": "1085035"
  },
  {
    "text": "Yeah. Okay, cool. I feel like that's mostly covered all the things up here more or less. Okay.",
    "start": "1085035",
    "end": "1094320"
  },
  {
    "text": "Yeah. Was there anything else? . So maybe like- I guess",
    "start": "1094320",
    "end": "1099644"
  },
  {
    "text": "the desirable or required properties of the algorithm is like you don't want to have a negative transfer if you want to be able to [inaudible].",
    "start": "1099645",
    "end": "1104670"
  },
  {
    "text": "But maybe like- in terms of like maybe the training scheme that you",
    "start": "1104670",
    "end": "1110100"
  },
  {
    "text": "use like when the desired property from that would be related to this tricked up thing,",
    "start": "1110100",
    "end": "1116370"
  },
  {
    "text": "is that you need to be is- like if you were to try to have like a lists sort of- like a discreet set of like properties that you want,",
    "start": "1116370",
    "end": "1124304"
  },
  {
    "text": "that are- like- like properties for the tasks, and then properties related to like the environment that you want to be able to like take",
    "start": "1124305",
    "end": "1130830"
  },
  {
    "text": "sort of combinatorial combinations of like all the different possible tasks that you can get out in different environments.",
    "start": "1130830",
    "end": "1135840"
  },
  {
    "text": "And then that can be used to kind of construct your evaluation set, and you want to be kind of- you want to assume that maybe like when you're evaluating,",
    "start": "1135840",
    "end": "1142770"
  },
  {
    "text": "that you can take any combination of these tasks and environments and be able to like generate a new task that makes sense that you can work on.",
    "start": "1142770",
    "end": "1149309"
  },
  {
    "text": "So it's kind of like robust to all possible combinations of [inaudible].",
    "start": "1149310",
    "end": "1158910"
  },
  {
    "text": "So you are evaluating on how that combinations of, uh, like tasks, environments, variations on the tasks?",
    "start": "1158910",
    "end": "1166410"
  },
  {
    "text": "Yeah. Okay. Yeah.",
    "start": "1166410",
    "end": "1172230"
  },
  {
    "text": "[inaudible] increasingly large set of skills [inaudible] probably is important that the skills be around present and continuous [inaudible].",
    "start": "1172230",
    "end": "1179710"
  },
  {
    "text": "Yeah. It's like a continuous parameterization of tasks.",
    "start": "1185960",
    "end": "1192340"
  },
  {
    "text": "Okay. Um, the group in the middle. Uh, we talked about, uh, [inaudible].",
    "start": "1193040",
    "end": "1198690"
  },
  {
    "text": "Okay. So we talked about a couple of things in general,",
    "start": "1198690",
    "end": "1204039"
  },
  {
    "text": "but one like, uh, more specific example is like diagnosing like [inaudible] For example,",
    "start": "1204040",
    "end": "1210804"
  },
  {
    "text": "if you had a string of patients coming into your office and you wanted to do an evaluation based on",
    "start": "1210805",
    "end": "1216050"
  },
  {
    "text": "their symptoms [inaudible] seasonal trends every year.",
    "start": "1216050",
    "end": "1223655"
  },
  {
    "text": "But you still want the algorithm to perform well no matter what time of the year it is. And you also want it to be able to remember,",
    "start": "1223655",
    "end": "1232110"
  },
  {
    "text": "uh, information for many years past, so maybe flu strains [inaudible] And you wanted to do well,",
    "start": "1232110",
    "end": "1239730"
  },
  {
    "text": "uh, on implications that you did, um, as opposed to maybe the [inaudible].",
    "start": "1239730",
    "end": "1251160"
  },
  {
    "text": "Yeah. So you want some sort of kind of memory of the past, and also, uh,",
    "start": "1251160",
    "end": "1257850"
  },
  {
    "text": "you may have, uh, like periodic signals, like seasons for example, and you want to be able to take that into account in",
    "start": "1257850",
    "end": "1263430"
  },
  {
    "text": "your decision making to do pe- to perform well. I guess in addition to transfer the- and generating new tasks,",
    "start": "1263430",
    "end": "1269159"
  },
  {
    "text": "there's also just generally like good performance is something that we care about.",
    "start": "1269160",
    "end": "1274060"
  },
  {
    "text": "Yeah. Yeah. [inaudible] performance, I think [inaudible] was mentioning maybe, uh,",
    "start": "1274560",
    "end": "1279885"
  },
  {
    "text": "after learning could be a good feature to have because oftentimes, my system will recommend [inaudible]",
    "start": "1279885",
    "end": "1296580"
  },
  {
    "text": "Yeah. And that's particularly relevant if you're seeing like",
    "start": "1296580",
    "end": "1303165"
  },
  {
    "text": "our distribution data for example. Yeah. [inaudible].",
    "start": "1303165",
    "end": "1317399"
  },
  {
    "text": "Yeah. So considering like different sequences of tasks and you want it to be potentially robust to those different types of sequences.",
    "start": "1317400",
    "end": "1327330"
  },
  {
    "text": "If you're in a, like a medical decision-making situations because you don't know if you're gonna be seeing, the easier cases, or the harder cases or if you",
    "start": "1327330",
    "end": "1333389"
  },
  {
    "text": "may see some intermixing of hard cases and easy cases. Great, okay. Um, the group in the back.",
    "start": "1333390",
    "end": "1341010"
  },
  {
    "text": "Yeah, uh, so we talked about the- the social system and I guess we were talking about uh,",
    "start": "1343490",
    "end": "1350250"
  },
  {
    "text": "kind of like two different spectrums here like the one spectrum was like on the one side, we don't want to bias like,",
    "start": "1350250",
    "end": "1355559"
  },
  {
    "text": "towards a single set of users, or a single set of classes for a single set of time. But then on the other hand er, maybe for example,",
    "start": "1355560",
    "end": "1363060"
  },
  {
    "text": "if you're seeing this single task a lot more frequently at voice like [inaudible] highest maybe a virtual assistant",
    "start": "1363060",
    "end": "1369960"
  },
  {
    "text": "should focus on learning that task over others. So we are like, kinda of like asking about how we should balance those two er,",
    "start": "1369960",
    "end": "1377115"
  },
  {
    "text": "between like passing chords or set of rules and um, may- maybe not do.",
    "start": "1377115",
    "end": "1382304"
  },
  {
    "text": "And in terms of evaluation, we also talked about how the performance on",
    "start": "1382305",
    "end": "1387360"
  },
  {
    "text": "the different tasks could be different depending on which training you look at. And that is also an interesting question because at the [inaudible] checkpoints with",
    "start": "1387360",
    "end": "1394920"
  },
  {
    "text": "that training period we might wanna focus on different tasks er, we might wanna invite [inaudible].",
    "start": "1394920",
    "end": "1402659"
  },
  {
    "text": "Yeah- yeah, that's a good point. Like if you have- if there's one user that you've been repeatedly seeing a lot and- and- and very recently,",
    "start": "1402660",
    "end": "1409380"
  },
  {
    "text": "then you may want to- like, focus some of your representational capacity on that user because it's likely that in the near future,",
    "start": "1409380",
    "end": "1414450"
  },
  {
    "text": "you'll see them again and you wanna be able to make good decisions then. Great. Um, group in the middle.",
    "start": "1414450",
    "end": "1421230"
  },
  {
    "text": "[inaudible] You know young children's this needs to grow up.",
    "start": "1421230",
    "end": "1431040"
  },
  {
    "text": "They have like very broad but like very few categories of God's finding so they can classify birds and they [inaudible].",
    "start": "1431040",
    "end": "1441360"
  },
  {
    "text": "And as they grow up, they acquire more and more categories that are finer and finer manipulate levels.",
    "start": "1441360",
    "end": "1449044"
  },
  {
    "text": "And we thought about potentially lifelong learning system around that and it would give their,",
    "start": "1449045",
    "end": "1454804"
  },
  {
    "text": "neighbors neuroscience showing that this here can break the character dataset into several therapies.",
    "start": "1454805",
    "end": "1461820"
  },
  {
    "text": "There has been a learning process involves didn't make represented the delayed activation of",
    "start": "1461820",
    "end": "1467760"
  },
  {
    "text": "the classes and overall along the hierarchical tree. [OVERLAPPING] Like of coarse-to-fine type approach?",
    "start": "1467760",
    "end": "1473385"
  },
  {
    "text": "Yeah. And then we talk about how you best work a system like that could [inaudible] as a professor,",
    "start": "1473385",
    "end": "1483030"
  },
  {
    "text": "you want to be able to learn this final grade classes [inaudible] based on er,",
    "start": "1483030",
    "end": "1489360"
  },
  {
    "text": "you know, the previous classification [OVERLAPPING]. Right. So you might have a kind of coarse to",
    "start": "1489360",
    "end": "1495990"
  },
  {
    "text": "fine type of tasks and may also you care about er, like learning efficiency like be able to learn more",
    "start": "1495990",
    "end": "1501179"
  },
  {
    "text": "quickly as you see new concepts in sequence.",
    "start": "1501180",
    "end": "1506020"
  },
  {
    "text": "I'm not sure if course defined falls under evaluation or properties but uh,",
    "start": "1510200",
    "end": "1515760"
  },
  {
    "text": "I think that- this kind of gray area is what makes life- these sorts of problems interesting. Um, this group.",
    "start": "1515760",
    "end": "1523240"
  },
  {
    "text": "So I think we receive about B. Uh, we are considering a sequential learning for image cast.",
    "start": "1523430",
    "end": "1530279"
  },
  {
    "text": "[inaudible] image cast within distance. Uh, for example, at the first page, user provide a data set of handwritten digits.",
    "start": "1530280",
    "end": "1537255"
  },
  {
    "text": "So say well, this is going to be able to identify an even digits. And that's second stage you know,",
    "start": "1537255",
    "end": "1542399"
  },
  {
    "text": "different time this, you know, the user may provide the dataset of ImageNet. So obviously, you want to assist him to be able to do",
    "start": "1542400",
    "end": "1549690"
  },
  {
    "text": "classification on ImageNet of all the natural images. So this would be my care, uh,",
    "start": "1549690",
    "end": "1556140"
  },
  {
    "text": "sequential learning of different uh, classification datasets. Um, in terms of poverty,",
    "start": "1556140",
    "end": "1563100"
  },
  {
    "text": "I think we discussed, uh, first of all, we would want the system to be able to adapt to the new dataset faster than training from scratch,",
    "start": "1563100",
    "end": "1570465"
  },
  {
    "text": "and also, things more likely, the training will be sequential, in a sequential way.",
    "start": "1570465",
    "end": "1575870"
  },
  {
    "text": "So uh, uh, which probably can lead to like some catastrophic forgetting for them.",
    "start": "1575870",
    "end": "1581525"
  },
  {
    "text": "So this does not mean forget what- what the levers rigorously.",
    "start": "1581525",
    "end": "1586555"
  },
  {
    "text": "Um, so it wouldn't allow that to happen so well, you know, the system can be continually learning and building up your knowledge across the tasks.",
    "start": "1586555",
    "end": "1598440"
  },
  {
    "text": "All tasks in addition freshly tests. Yeah. So yeah, like evaluation on like yeah- like yeah- I'm extra classes.",
    "start": "1598440",
    "end": "1605670"
  },
  {
    "text": "One tiny thing that we talked about is the idea of maybe having it classify things that we don't specify at all.",
    "start": "1605670",
    "end": "1612889"
  },
  {
    "text": "[inaudible] Having it like if we were to show it images of cats,",
    "start": "1612890",
    "end": "1620130"
  },
  {
    "text": "like even having some sub classify those cats and create classifications that we specify that it is just kind of cancels these [inaudible].",
    "start": "1620130",
    "end": "1629370"
  },
  {
    "text": "Yeah. So kind of like maybe a generation of new tasks but from unlabeled data. Yeah. [OVERLAPPING] Another thing is that being",
    "start": "1629370",
    "end": "1637289"
  },
  {
    "text": "estimated we basically need to keep all that data from previous tasks uh, during the evaluation stage,",
    "start": "1637290",
    "end": "1643230"
  },
  {
    "text": "I think it will be- ideally, you need to remove keeping increasing the data as we uh,",
    "start": "1643230",
    "end": "1651450"
  },
  {
    "text": "[inaudible] become very different task over time. So we don't want to keep all of the previous tasks. So like O of N memory.",
    "start": "1651450",
    "end": "1659430"
  },
  {
    "text": "Like little o of n memory. Yeah. Ideally, yes. Yeah. Okay. And then, last group.",
    "start": "1659430",
    "end": "1671160"
  },
  {
    "text": "So one I gave the students learning in school is say",
    "start": "1671160",
    "end": "1676920"
  },
  {
    "text": "this had such that we want the students to have some introspective capabilities.",
    "start": "1676920",
    "end": "1682245"
  },
  {
    "text": "Like they should know who I'm not good at this pass. Not only so that you focus on that task but also sort of they don't go on American Idol and start singing.",
    "start": "1682245",
    "end": "1692800"
  },
  {
    "text": "That's very useful. All right. I'm gonna put this next to active learning because it relates",
    "start": "1694220",
    "end": "1700590"
  },
  {
    "text": "pretty closely to like understanding when you should ask for more information. Yeah. Yea- yeah.",
    "start": "1700590",
    "end": "1705840"
  },
  {
    "text": "It looks like there's two aspects: One is, yeah, what are you good at and what you do for example.",
    "start": "1705840",
    "end": "1712350"
  },
  {
    "text": "And the other one was uh, I think this was said sort of what are actually if you're a student in school,",
    "start": "1712350",
    "end": "1720660"
  },
  {
    "text": "they can't learn everything focused on things that will be useful later perhaps indicates the students.",
    "start": "1720660",
    "end": "1727860"
  },
  {
    "text": "You could imagine money, how much will you make or like that that could be a signal of one of the things you're going to actually useful.",
    "start": "1727860",
    "end": "1735540"
  },
  {
    "text": "You actually get paid later on when you use them. Great.",
    "start": "1735540",
    "end": "1740820"
  },
  {
    "text": "Just something else when we were talking about there was thinking about is um, wouldn't it be good for the model to be able to  expand its parameters so",
    "start": "1740820",
    "end": "1749520"
  },
  {
    "text": "that its architecture so know how to fix it?",
    "start": "1749520",
    "end": "1754860"
  },
  {
    "text": "[NOISE] You're getting increasingly complicated tasks. So like a dynamic architecture capacity.",
    "start": "1754860",
    "end": "1760950"
  },
  {
    "text": "[NOISE]",
    "start": "1760950",
    "end": "1768330"
  },
  {
    "text": "Okay um, did you have a comment? Yeah. Um, I guess this is kind of like related to some of the things that",
    "start": "1768330",
    "end": "1773940"
  },
  {
    "text": "are being done but in the evaluation side of things, it would be useful to, I think, have, uh, a,",
    "start": "1773940",
    "end": "1780450"
  },
  {
    "text": "a good understanding of, like, what the tradeoff is between generalization and specialization for this algorithm where like on one hand,",
    "start": "1780450",
    "end": "1788040"
  },
  {
    "text": "like if you're trying to get it to work better on like increasingly difficult tasks and you want it to kind of get specialized,",
    "start": "1788040",
    "end": "1794580"
  },
  {
    "text": "and maybe your weight is more heavily on that- on that like component of like evaluat- like",
    "start": "1794580",
    "end": "1799710"
  },
  {
    "text": "that evaluation metric and then at the same time, if you wanted to be able to like, like the robot to be [NOISE] able to adopt to like cleaning a bunch of different houses,",
    "start": "1799710",
    "end": "1808110"
  },
  {
    "text": "and it's okay if initially it doesn't perform that well, uh, at cleaning that new house because it- it's just kind of like [inaudible] cleaning house,",
    "start": "1808110",
    "end": "1815340"
  },
  {
    "text": "then you kind of wanna be more general with it. You want it to be focused on like the variety of like",
    "start": "1815340",
    "end": "1822120"
  },
  {
    "text": "different houses as opposed to how perfectly they're able to clean one specific house. So like- yeah. I know I think that trade off might be its",
    "start": "1822120",
    "end": "1829290"
  },
  {
    "text": "own metric or its own certain evaluation criteria. Yeah. And I also suspect that something like generalization",
    "start": "1829290",
    "end": "1834420"
  },
  {
    "text": "versus specialization is gonna be something application dependent. Like, uh, in many situ- situations, you may care about,",
    "start": "1834420",
    "end": "1840075"
  },
  {
    "text": "uh, like, it being, like, very consistently performing very well in this sit- situations where you really need it to perform well,",
    "start": "1840075",
    "end": "1847230"
  },
  {
    "text": "versus be able to do, uh, something, like, do more things but slightly at a lower degree of performance.",
    "start": "1847230",
    "end": "1853380"
  },
  {
    "text": "It's like a robot doing things with, like, a lower success rate or a, um, or, uh, like,",
    "start": "1853380",
    "end": "1859050"
  },
  {
    "text": "more slowly than if it were a specialist that was specifically tuned for doing one particular task. Yep.",
    "start": "1859050",
    "end": "1865605"
  },
  {
    "text": "Yeah. One thought I also had was, in fact, this is more than one but two. One, perhaps you want to make sure that they don't,",
    "start": "1865605",
    "end": "1873270"
  },
  {
    "text": "like, the agent doesn't learn dangerous things. Like in the case of students, we don't want the student going",
    "start": "1873270",
    "end": "1878490"
  },
  {
    "text": "on the wild side to build weapons and things like that. They could imagine, like, if they had a group which is a large pool of tasks,",
    "start": "1878490",
    "end": "1885165"
  },
  {
    "text": "that they end up learning things that we don't want them to learn. Right. So when they propose their own tasks they should-",
    "start": "1885165",
    "end": "1891810"
  },
  {
    "text": "Propose things- Propose things that are useful and ethical. Yeah. [LAUGHTER]. Okay. Great. Um, I think that was a great discussion.",
    "start": "1891810",
    "end": "1902255"
  },
  {
    "text": "Uh, and I think that I guess one takeaway from this, is I think that in different applications, you care about different things.",
    "start": "1902255",
    "end": "1907850"
  },
  {
    "text": "Like, in some applications, you really, uh, want it to, uh, kind of, remember everything and be able to perform well on",
    "start": "1907850",
    "end": "1913050"
  },
  {
    "text": "a wide variety of situations whereas in other applications, you care a lot more about just the, the recent thing, uh,",
    "start": "1913050",
    "end": "1918240"
  },
  {
    "text": "uh, and the things that it, it needs to do now. Um, so for example, in decision-making situation,",
    "start": "1918240",
    "end": "1925170"
  },
  {
    "text": "you don't want to forget past events, you wa- you want to be able to, uh, recognize new trends when they're happening whereas in,",
    "start": "1925170",
    "end": "1932159"
  },
  {
    "text": "um, a student learning concepts in school, maybe, uh, maybe they don't need to - uh, maybe if they're not using, uh,",
    "start": "1932160",
    "end": "1938520"
  },
  {
    "text": "very basic long division skills, uh, maybe they don't need to remember those long division skills because they're not actually useful for their, uh,",
    "start": "1938520",
    "end": "1945360"
  },
  {
    "text": "current position, um, to- I don't know, if, if- I don't per- I- I personally don't use long division a lot.",
    "start": "1945360",
    "end": "1950820"
  },
  {
    "text": "So, uh, I think it's okay if I forget that particular skill, for example. Okay. [NOISE] Okay.",
    "start": "1950820",
    "end": "1958995"
  },
  {
    "text": "So let's, let's- um, I wrote out some problem variations and, um, and evaluation considerations, uh,",
    "start": "1958995",
    "end": "1967320"
  },
  {
    "text": "on the slide just to, kind of- and I think that we probably covered most of the things here. But we can go over some of these things. So, um, one variation is how the tasks come, uh, to the agent.",
    "start": "1967320",
    "end": "1977730"
  },
  {
    "text": "So we talked about this a little bit. They may come in the curriculum from easy to hard or they may be more something like IID where you see a both a range of difficult tasks and hard- and,",
    "start": "1977730",
    "end": "1986520"
  },
  {
    "text": "and easy tasks, uh, in some, sort of, stream. Uh, there's also a setting,",
    "start": "1986520",
    "end": "1992640"
  },
  {
    "text": "uh, called predictable which is a general. It's, um, it's, uh, less strong, uh, notion of, of ideas similar to the seasons, for example.",
    "start": "1992640",
    "end": "2001520"
  },
  {
    "text": "If you know it's, kind of, the end of, uh, summer you know that it, fall's likely to come. So you can see that sort of trend in your stream of data.",
    "start": "2001520",
    "end": "2009110"
  },
  {
    "text": "Uh, and then there's also- I don't think it was covered in any of these settings, but there's also settings where you have adversarial tasks coming in.",
    "start": "2009110",
    "end": "2016370"
  },
  {
    "text": "Uh, that might be if you have a competitive environment and you're trying to learn how to, um, I don't know, compete against another agent,",
    "start": "2016370",
    "end": "2023075"
  },
  {
    "text": "then the types of tasks that may be coming in are gonna be tasks that are particularly, uh, targeted towards the types of tasks that you do poorly at.",
    "start": "2023075",
    "end": "2031580"
  },
  {
    "text": "Um, and so that's also, uh, a variation of the lifelong learning problem statement. Uh, and the type of algorithm that you develop may be very,",
    "start": "2031580",
    "end": "2039985"
  },
  {
    "text": "like, very much influenced by these different types of categories. Uh, another variation of the problems is",
    "start": "2039985",
    "end": "2048784"
  },
  {
    "text": "whether or not you have very discrete task boundaries or more continuous task boundaries. This came up, um, when we were talking about having,",
    "start": "2048785",
    "end": "2055054"
  },
  {
    "text": "kind of ah your task be continuously parameterized versus, um, having ah, more discrete tasks.",
    "start": "2055055",
    "end": "2064129"
  },
  {
    "text": "Uh, and then there's also situations where you know where the task boundaries are and where you don't know the task boundaries are.",
    "start": "2064130",
    "end": "2069350"
  },
  {
    "text": "Um, so for example, if, um, if you're in grade school, if you're going from first grade to second grade",
    "start": "2069350",
    "end": "2074419"
  },
  {
    "text": "or you're given one problem versus another problem, there's pretty, uh, clear shifts. But if you are,",
    "start": "2074420",
    "end": "2081740"
  },
  {
    "text": "are, are, um, diagnosing flu symptoms or, uh, making diagnosis for the flu, you may not know, uh,",
    "start": "2081740",
    "end": "2087215"
  },
  {
    "text": "shifts in the data distribution that you're seeing. Do you have a question? No.",
    "start": "2087215",
    "end": "2092665"
  },
  {
    "text": "Uh, cool. Uh, some considerations in terms of, uh, like, the desirable properties that we care about, um,",
    "start": "2092665",
    "end": "2100730"
  },
  {
    "text": "model performance as we discussed, data efficiency, uh, the ability to learn new things quickly, uh,",
    "start": "2100730",
    "end": "2106325"
  },
  {
    "text": "we didn't really talk about this but computational resources. And this is actually gonna come up, uh, a fair amount in thinking about the algorithms that we develop.",
    "start": "2106325",
    "end": "2113585"
  },
  {
    "text": "Uh, and it's related to, uh, this, uh, me - memory but in terms of computation.",
    "start": "2113585",
    "end": "2120050"
  },
  {
    "text": "You don't want the computation to grow, uh, with- uh, grow linearly and, and for example, as you see more tasks.",
    "start": "2120050",
    "end": "2127415"
  },
  {
    "text": "Um, and then there's other considerations such as privacy, interpretability, fairness, uh, and the amount of compute memory you use at task time.",
    "start": "2127415",
    "end": "2135545"
  },
  {
    "text": "Um, a lot of the- some of these things are things that you care about in standard machine learning settings and aren't specific to lifelong learning.",
    "start": "2135545",
    "end": "2141529"
  },
  {
    "text": "Um, although one thing that comes up that we'll touch on, [NOISE] uh, in a couple of slides is privacy.",
    "start": "2141530",
    "end": "2146720"
  },
  {
    "text": "Uh, if you're in the medical decision-making setting, for example, it may not be- um, you may not be allowed to actually store all of the data",
    "start": "2146720",
    "end": "2153920"
  },
  {
    "text": "perpetually and so that may motivate, um, settings where you have to, uh,",
    "start": "2153920",
    "end": "2160490"
  },
  {
    "text": "store things in the memory of the neural network rather than storing them in, uh, in plain texts.",
    "start": "2160490",
    "end": "2165710"
  },
  {
    "text": "Although in that setting, it's, it's unclear if you're storing things on the weights of a neural network, uh, maybe you're still storing them and maybe that's also violating,",
    "start": "2165710",
    "end": "2174214"
  },
  {
    "text": "uh, privacy- patient privacy. Uh, so some pe- kind of, interesting,",
    "start": "2174215",
    "end": "2179240"
  },
  {
    "text": "philosophical questions there. Um, yeah. So in general, substantial writing of a problem statement and unfortunately all of",
    "start": "2179240",
    "end": "2186800"
  },
  {
    "text": "these generally fall under the umbrella of lifelong learning or online learning. And so it makes it, uh, rather difficult,",
    "start": "2186800",
    "end": "2193099"
  },
  {
    "text": "uh, a bit to tease apart some of, um, the different advances in this area.",
    "start": "2193100",
    "end": "2198320"
  },
  {
    "text": "Okay. So, uh, now let's look at one very concrete instantiation of,",
    "start": "2198320",
    "end": "2205535"
  },
  {
    "text": "uh, the lifelong learning problem statement. And this typically falls under what's called online learning. Uh, and it's very simple.",
    "start": "2205535",
    "end": "2211070"
  },
  {
    "text": "So you have, uh, time that's passing and you observe an input.",
    "start": "2211070",
    "end": "2217895"
  },
  {
    "text": "You make a prediction about the label corresponding to that input and then you observe the label for that input.",
    "start": "2217895",
    "end": "2225530"
  },
  {
    "text": "And then the loop, uh, iterates. This is basically vanilla",
    "start": "2225530",
    "end": "2231312"
  },
  {
    "text": "uh, online learning um, and in the very general case,",
    "start": "2231312",
    "end": "2236990"
  },
  {
    "text": "you could make no assumptions about what x is and what y is. Um, and also, uh,",
    "start": "2236990",
    "end": "2242810"
  },
  {
    "text": "in the general case, you could just, you um, you could p- not place any restrictions on memory or computation,",
    "start": "2242810",
    "end": "2248420"
  },
  {
    "text": "uh, and just want to be able to solve this problem, in the general case. So that's the most general,",
    "start": "2248420",
    "end": "2254525"
  },
  {
    "text": "uh, formulation of the problem. Uh, you may make some certain assumptions. So one assumption that you can make is that the data is coming in IID.",
    "start": "2254525",
    "end": "2261950"
  },
  {
    "text": "So the x_t is drawn from p of x, and y_t is drawn from p of y given x.",
    "start": "2261950",
    "end": "2267410"
  },
  {
    "text": "Uh, and note that p is not a function of t. So it's a stationary distribution.",
    "start": "2267410",
    "end": "2273155"
  },
  {
    "text": "This is, uh, one example of online learning and, and this assumption can make it easier to think about algorithms, uh,",
    "start": "2273155",
    "end": "2280580"
  },
  {
    "text": "even if the data distri- density doesn't necessarily follow these assumptions.",
    "start": "2280580",
    "end": "2285680"
  },
  {
    "text": "Um, otherwise, if you assume that you're not in the IID setting, then you assume some sort of time-varying,",
    "start": "2285680",
    "end": "2291575"
  },
  {
    "text": "uh, distribution over x and y given x. Uh, and there's other- as I alluded to you before,",
    "start": "2291575",
    "end": "2297230"
  },
  {
    "text": "there's also a setting, uh, called the predictable setting that I don't have, uh, texts for but that's the setting where you can",
    "start": "2297230",
    "end": "2302720"
  },
  {
    "text": "actually predict something about the next distribution based off of the trends you've seen in the past. Okay.",
    "start": "2302720",
    "end": "2309724"
  },
  {
    "text": "Um, so another assumption or another, uh, consideration or restriction that you can put on this is what I'm going to call the streaming setting.",
    "start": "2309725",
    "end": "2316759"
  },
  {
    "text": "Uh, and in this setting, you can't store xt and yt.",
    "start": "2316760",
    "end": "2322220"
  },
  {
    "text": "You could only look at them once, uh, and then you're kind of given the next thing.",
    "start": "2322220",
    "end": "2328460"
  },
  {
    "text": "You're not allowed to have any memory. Uh, and so this could be very useful if you're in settings where you have- don't have any memory,",
    "start": "2328460",
    "end": "2336230"
  },
  {
    "text": "or just the amount of data, the quantity of data is so enormous that it's impractical to think about storing it.",
    "start": "2336230",
    "end": "2342725"
  },
  {
    "text": "Um, due to memory or due to computational resources. If you are streaming video for example, uh,",
    "start": "2342725",
    "end": "2348140"
  },
  {
    "text": "every single second, uh, it may be impractical to store that. It could also relate to privacy considerations as I mentioned before.",
    "start": "2348140",
    "end": "2354950"
  },
  {
    "text": "Um, and it could also relate to, uh, wanting to study neural memory mechanisms.",
    "start": "2354950",
    "end": "2360289"
  },
  {
    "text": "So there's a- a kind of a sub-field of lifelong learning that really cares about how humans remember things,",
    "start": "2360290",
    "end": "2366170"
  },
  {
    "text": "uh, when they're given a stream of data, and so if you care about kind of this biologically plausible, uh,",
    "start": "2366170",
    "end": "2371510"
  },
  {
    "text": "form of memory that is more biologically plausible than, like, a hard drive,",
    "start": "2371510",
    "end": "2376895"
  },
  {
    "text": "then you could, uh, consider this setting. Uh, and it's worth mentioning that",
    "start": "2376895",
    "end": "2383015"
  },
  {
    "text": "this is certainly true in some cases that you cannot store x and y, but in many cases,",
    "start": "2383015",
    "end": "2388549"
  },
  {
    "text": "it is actually practical to store the data that you're seeing. Uh, we have very large data sets like ImageNet. We have pretty big hard drives,",
    "start": "2388550",
    "end": "2395270"
  },
  {
    "text": "uh, and so from a practical point of view, it can be actually, uh, very sensible to store the data that you're seeing for random problem settings.",
    "start": "2395270",
    "end": "2403115"
  },
  {
    "text": "Um, so for example, in reinforcement learning settings, we store our data in replay buffers and we, uh,",
    "start": "2403115",
    "end": "2408140"
  },
  {
    "text": "typically replay our da- uh, that data to the agent, uh, in order to allow it to continuously learn from that data.",
    "start": "2408140",
    "end": "2414780"
  },
  {
    "text": "Okay. And then the last, uh, variation on this problem statement that I had written down is",
    "start": "2414790",
    "end": "2421849"
  },
  {
    "text": "that if you know where the task boundaries are, you may also be observing, um,",
    "start": "2421850",
    "end": "2427130"
  },
  {
    "text": "some task descriptor zt that could correspond to a one-hot vector or some other more descriptive,",
    "start": "2427130",
    "end": "2432784"
  },
  {
    "text": "um, description of the task. Uh, and in that case, you would observe both xt as well as the task descriptor.",
    "start": "2432784",
    "end": "2440119"
  },
  {
    "text": "Although you could also put this into the general case of online learning where xt contains both the in- the input and the task descriptor.",
    "start": "2440120",
    "end": "2448200"
  },
  {
    "text": "Okay. Um, so this is the problem statement, uh, or several different variations on a general problem statement.",
    "start": "2448960",
    "end": "2458270"
  },
  {
    "text": "Now, what do you want from your lifelong learning algorithm? Uh, and in particular, how do you go about evaluating lifelong learning algorithms?",
    "start": "2458270",
    "end": "2464705"
  },
  {
    "text": "Um, there are two metrics that I- or- or two classes of metrics that I think are useful for thinking about this.",
    "start": "2464705",
    "end": "2470900"
  },
  {
    "text": "Uh, and I- actually I don't think that anyone really gave a concrete metric when we were discussing this before.",
    "start": "2470900",
    "end": "2478970"
  },
  {
    "text": "So let's talk about that now. Um, one of the most, uh, classic metrics and online learning is what's called regret,",
    "start": "2478970",
    "end": "2487700"
  },
  {
    "text": "uh, and you want to have minimal regret and you want your regret to grow slowly with, uh, the time.",
    "start": "2487700",
    "end": "2495934"
  },
  {
    "text": "And in particular, what regret refers to is the cumulative loss of the learner.",
    "start": "2495935",
    "end": "2502565"
  },
  {
    "text": "So essentially the integral of the loss for each of the data points that you see subtracted by the cumulative loss of the best learner in hindsight.",
    "start": "2502565",
    "end": "2514625"
  },
  {
    "text": "Um, so this is basically a comparison between, uh, your cumulative loss and what you could have done in the best case.",
    "start": "2514625",
    "end": "2521510"
  },
  {
    "text": "And mathematically what this looks like is the following. So, say Theta t is the parameters that you choose at each timestep",
    "start": "2521510",
    "end": "2526910"
  },
  {
    "text": "to make predictions. Um, the cumulative regret of a- the cumulative loss of yourself is the left term.",
    "start": "2526910",
    "end": "2533870"
  },
  {
    "text": "Where you're just adding up the loss for the set of parameters that you use at each time step. And the right term is referring to in hindsight.",
    "start": "2533870",
    "end": "2541670"
  },
  {
    "text": "Uh, if you had some model,uh, that, that minimized the loss for those time steps,",
    "start": "2541670",
    "end": "2548030"
  },
  {
    "text": "basically kind of the best set of parameters that you could have done or they- you could have used to perform that sequence of tasks.",
    "start": "2548030",
    "end": "2555240"
  },
  {
    "text": "Okay. Yeah. [inaudible]. Yeah. So this cannot be evaluated in practice,",
    "start": "2555700",
    "end": "2562940"
  },
  {
    "text": "uh, typically but it's very useful for analysis. And, uh, and in particular we're thinking about in,",
    "start": "2562940",
    "end": "2570889"
  },
  {
    "text": "uh, in simplified settings, usually in complex settings. Can we study how the regret grows for these algorithms?",
    "start": "2570889",
    "end": "2577920"
  },
  {
    "text": "Um, so one thing worth noting is that regret that grows linearly in t is trivial to obtain.",
    "start": "2578950",
    "end": "2588680"
  },
  {
    "text": "Uh, can anyone tell me why that is the case?",
    "start": "2588680",
    "end": "2593099"
  },
  {
    "text": "[inaudible]",
    "start": "2593930",
    "end": "2605290"
  },
  {
    "text": "Um, let's see. So if you- right.",
    "start": "2605290",
    "end": "2611890"
  },
  {
    "text": "So if you output kind of a random parameter vector, it would grow linearly in t. You could actually do slightly better than that.",
    "start": "2611890",
    "end": "2618400"
  },
  {
    "text": "Um, and still have it be linear. Are there any other? So that- that's, that's a good example.",
    "start": "2618400",
    "end": "2625280"
  },
  {
    "text": "Uh, are there any other examples of where you could get, uh, a learner that is linear in t? Yeah.",
    "start": "2625280",
    "end": "2636020"
  },
  {
    "text": "Uh, you can just keep Theta fix. Uh-huh. So if you keep Theta fixed at like a random initialization?",
    "start": "2636020",
    "end": "2643625"
  },
  {
    "text": "Yeah, or even like at any performance. At any performance. What do you mean?",
    "start": "2643625",
    "end": "2649415"
  },
  {
    "text": "Like Theta key for any t. Then, [inaudible] same loss, it will always be linear.",
    "start": "2649415",
    "end": "2654650"
  },
  {
    "text": "Um, right. So you don't get to choose the loss. You only get to choose Theta.",
    "start": "2654650",
    "end": "2660275"
  },
  {
    "text": "Right [inaudible]. Um, if you keep the Theta fixed,",
    "start": "2660275",
    "end": "2666410"
  },
  {
    "text": "you won't necessarily have the same loss for all of the tasks. Does that make sense? Yeah.",
    "start": "2666410",
    "end": "2672250"
  },
  {
    "text": "Although if you have a random Theta you would- you could- you would guess that you would probably have, uh, the sim- a similar loss for all the tasks.",
    "start": "2673720",
    "end": "2680510"
  },
  {
    "text": "I guess the same thing for fixed. Any other thoughts?",
    "start": "2680510",
    "end": "2686240"
  },
  {
    "text": "Yeah. [inaudible] every t have a Theta that just minimizes the loss of that t?",
    "start": "2686240",
    "end": "2694370"
  },
  {
    "text": "Yeah. Yeah. So if you just train from scratch on each of the t tasks, uh,",
    "start": "2694370",
    "end": "2701540"
  },
  {
    "text": "and disregard any previous experience, then you would get linear regret, uh, because the loss, uh,",
    "start": "2701540",
    "end": "2707930"
  },
  {
    "text": "or assuming that the loss- that the tasks are similar difficulty. If you just train on each of those tasks from scratch, um, yeah,",
    "start": "2707930",
    "end": "2716270"
  },
  {
    "text": "you would get linear regret, uh, and because the, the loss for- the loss value would be constant.",
    "start": "2716270",
    "end": "2723485"
  },
  {
    "text": "Uh, and so the loss would, would increase. Uh, and so in practice,",
    "start": "2723485",
    "end": "2728570"
  },
  {
    "text": "what we typically want is, uh, sub-linear growth in your regret so that you can",
    "start": "2728570",
    "end": "2734854"
  },
  {
    "text": "actually use your previous experience to do better on the future tasks.",
    "start": "2734854",
    "end": "2740610"
  },
  {
    "text": "Okay. Um, cool. So that's one metric, uh, that's used typically in the online learning literature.",
    "start": "2741460",
    "end": "2749000"
  },
  {
    "text": "And in practice, as I mentioned, it's something that's very difficult to evaluate. So let's think about some, some metrics that we could actually evaluate in practice.",
    "start": "2749000",
    "end": "2755030"
  },
  {
    "text": "Uh, and so I think the most common, uh, metric that people use in",
    "start": "2755030",
    "end": "2761285"
  },
  {
    "text": "lifelong learning is thinking about positive and negative transfer. So I guess first you can look at performance, uh, on, on your set of tasks.",
    "start": "2761285",
    "end": "2768380"
  },
  {
    "text": "But in addition to performance, you can look at how well your tasks are allowing you to perform other tasks.",
    "start": "2768380",
    "end": "2773795"
  },
  {
    "text": "Uh, and so, so particular positive forward transfer refers to a setting where previous tasks can cause you to do better on future tasks,",
    "start": "2773795",
    "end": "2782135"
  },
  {
    "text": "uh, compared to learning the future task from scratch. So if you basically compare how well you do on",
    "start": "2782135",
    "end": "2788570"
  },
  {
    "text": "future tasks after learning the previous task compared to, uh, learning future tasks from scratch,",
    "start": "2788570",
    "end": "2794240"
  },
  {
    "text": "that can give you a measure of positive transfer, uh, and positive backward transfer would be if",
    "start": "2794240",
    "end": "2800330"
  },
  {
    "text": "a current task allows you to do better on previous tasks, uh, and this would be compared to learning those past tasks",
    "start": "2800330",
    "end": "2806329"
  },
  {
    "text": "from scratch before seeing, uh, your current task. Uh, and then if you want to find negative transfer,",
    "start": "2806330",
    "end": "2813380"
  },
  {
    "text": "just replace the word better with the word worse, uh, and you'll get negative transfer.",
    "start": "2813380",
    "end": "2818795"
  },
  {
    "text": "If you're doing- if basically previous tasks cause you to do worse on future tasks, and if the current task, uh, allow you to do or cause you to do worse on previous tasks.",
    "start": "2818795",
    "end": "2828080"
  },
  {
    "text": "Okay. So this is a metric that can allow us to study whether or not lifelong learning is allowing us to,",
    "start": "2828080",
    "end": "2834350"
  },
  {
    "text": "to learn well. Yup.",
    "start": "2834350",
    "end": "2837150"
  },
  {
    "text": "Is this symmetrical? So let's say I have two tasks; A and B. [inaudible].",
    "start": "2842800",
    "end": "2848010"
  },
  {
    "text": "Right. So typically it's not a symmetric metric. Uh, so, uh, for example,",
    "start": "2848010",
    "end": "2853455"
  },
  {
    "text": "if you learn how to, um, what is an example of this? [NOISE] If you- if you learn how to grasp objects,",
    "start": "2853455",
    "end": "2864945"
  },
  {
    "text": "uh, and then you learn how to, um, grasp an object and put it into a container,",
    "start": "2864945",
    "end": "2871530"
  },
  {
    "text": "uh, if you learn the grasping thing first and then, then the container thing, uh, then you'll be faster at learning the,",
    "start": "2871530",
    "end": "2878145"
  },
  {
    "text": "the, the task of picking and placing if you have a, a good learner. Uh, whereas if you reverse the order you",
    "start": "2878145",
    "end": "2884880"
  },
  {
    "text": "learn how to kind of pick and place and then you learn how to grasp. Um, the time it will take to learn how to",
    "start": "2884880",
    "end": "2891180"
  },
  {
    "text": "grasp should be trivial after learning how to pick and place. And so basically if you flip the order of those two tasks,",
    "start": "2891180",
    "end": "2896670"
  },
  {
    "text": "uh, for one of them you get, uh, you get positive forward transfer,",
    "start": "2896670",
    "end": "2903165"
  },
  {
    "text": "uh, to some degree and the other order you get positive forward transfer to a much greater degree.",
    "start": "2903165",
    "end": "2908474"
  },
  {
    "text": "If you have a good learner. Does that answer your question? Right. And that's something that's interesting and worth keeping in mind,",
    "start": "2908475",
    "end": "2917660"
  },
  {
    "text": "uh, as you think about- and it can be useful for thinking about how do you actually order the tasks. Okay. So now that we've spent a [NOISE] long time on",
    "start": "2917660",
    "end": "2926150"
  },
  {
    "text": "the problem statement, let's actually talk about some [NOISE] approaches for solving it. Uh, and we can start with the very basic approaches.",
    "start": "2926150",
    "end": "2932085"
  },
  {
    "text": "So, uh, a- and by basic I mean really the most naive thing as you could imagine doing.",
    "start": "2932085",
    "end": "2938775"
  },
  {
    "text": "So, uh, the first approach you could imagine doing, uh, under settings where you don't have a lot of constraints on",
    "start": "2938775",
    "end": "2946365"
  },
  {
    "text": "what you're allowed to do with the data is just store all the data that you've seen so far, and train on it,",
    "start": "2946365",
    "end": "2952035"
  },
  {
    "text": "uh, until you, uh, achieve the optimal loss function for all the data that you've seen.",
    "start": "2952035",
    "end": "2959010"
  },
  {
    "text": "[NOISE] Uh, and this is- this actually has a name, uh, to it. So it's called the follow the leader algorithm.",
    "start": "2959010",
    "end": "2965340"
  },
  {
    "text": "Uh, and it's actually if, if you have the ability to do this,",
    "start": "2965340",
    "end": "2971235"
  },
  {
    "text": "then this is an extremely strong approach. I basically saying given all the data that you've seen so",
    "start": "2971235",
    "end": "2976619"
  },
  {
    "text": "far train on it and minimize the loss of all that data. Uh, and we will achieve",
    "start": "2976620",
    "end": "2982530"
  },
  {
    "text": "very strong performance because you won't necessarily over-fit to the most recent data because you'll be, uh, continuously training on everything.",
    "start": "2982530",
    "end": "2989520"
  },
  {
    "text": "Uh, yeah. Downsides is that, uh, it's very [NOISE] computationally intensive.",
    "start": "2989520",
    "end": "2995190"
  },
  {
    "text": "So if at every single time you see a new data point you now train on everything you've seen. Then, uh, the- your train time is",
    "start": "2995190",
    "end": "3002930"
  },
  {
    "text": "actually worse than o(n) because as you see more data you'll presumably be- uh,",
    "start": "3002930",
    "end": "3008140"
  },
  {
    "text": "have to do more computation. Uh, with that said if you kind of continuously fine tune",
    "start": "3008140",
    "end": "3014079"
  },
  {
    "text": "instead of trying to train from scratch on- at every ti- time step, you instead can fine tune from what you learned",
    "start": "3014080",
    "end": "3019670"
  },
  {
    "text": "before then it may actually be more practical to do this. Um, it can also be memory intensive.",
    "start": "3019670",
    "end": "3025160"
  },
  {
    "text": "Uh, so if you're in applications where you can't store all the data you've seen that this is a problem. If you're in applications where you can't store all the data this is fine.",
    "start": "3025160",
    "end": "3032000"
  },
  {
    "text": "Uh, so this depends on the application. Okay. Uh, second naive approach that you could imagine doing, uh,",
    "start": "3032000",
    "end": "3042605"
  },
  {
    "text": "is- particularly if you're in a setting where you can't store data, you just imagine taking a gradient step on the data point that you observe.",
    "start": "3042605",
    "end": "3051095"
  },
  {
    "text": "Uh, and this corresponds to [NOISE] stochastic gradient descent [NOISE] as, uh,",
    "start": "3051095",
    "end": "3057320"
  },
  {
    "text": "many of [NOISE] us should all know, and, and what you've been using in your, uh, homework.",
    "start": "3057320",
    "end": "3064640"
  },
  {
    "text": "This is very computationally cheap. It requires no memory. Uh, and the downside is that it's",
    "start": "3064640",
    "end": "3073340"
  },
  {
    "text": "subject to negative backward transfer if you- if the data points that it sees, uh, do not, uh,",
    "start": "3073340",
    "end": "3079130"
  },
  {
    "text": "kind of cover the things that you saw previously. Uh, and this is what is known as forgetting.",
    "start": "3079130",
    "end": "3086195"
  },
  {
    "text": "Uh, sometimes also referred to as catastrophic forgetting. Uh, how catastrophic it is depends on the application that you're in.",
    "start": "3086195",
    "end": "3094190"
  },
  {
    "text": "Uh, so maybe it's fine that you, uh, forgot how to do long division for example, it just not really a,",
    "start": "3094190",
    "end": "3100910"
  },
  {
    "text": "a catastrophe but maybe, uh, in other settings if you forget how to, uh, make decisions based on a current season,",
    "start": "3100910",
    "end": "3108470"
  },
  {
    "text": "uh, then there is potentially more catastrophic. Yeah. So to avoid catastrophic forgetting in the first setting,",
    "start": "3108470",
    "end": "3115400"
  },
  {
    "text": "you have to always be randomizing on how you sample the next batch? Yeah. So the way that the first setting avoids",
    "start": "3115400",
    "end": "3122720"
  },
  {
    "text": "forgetting is that it just stores all the data that it's seen, and continuously replays that data,",
    "start": "3122720",
    "end": "3127775"
  },
  {
    "text": "and continuously trains on that data. So now they are mechanically stored? [NOISE]",
    "start": "3127775",
    "end": "3133340"
  },
  {
    "text": "Right. Yeah. So this- the top ver- the top version will- um, in principle to follow the leader algorithm will actually train to",
    "start": "3133340",
    "end": "3140990"
  },
  {
    "text": "convergence on all of the data that you've seen so far. Uh, where you store the data and you sample it IID from your buffer of data. Yeah.",
    "start": "3140990",
    "end": "3151795"
  },
  {
    "text": "You wanna talk about a strong performance is this with respect to our regret or something else?",
    "start": "3151795",
    "end": "3157365"
  },
  {
    "text": "It's, uh, yeah. It's, it's with respect to something like regret, uh, and in convex settings under certain, uh,",
    "start": "3157365",
    "end": "3165109"
  },
  {
    "text": "I think smoothness assumptions, uh, and, and convexity assumptions or maybe actually be strong convexity,",
    "start": "3165110",
    "end": "3170570"
  },
  {
    "text": "uh, you can show that it gets o of log n regret. Uh, and log n is, uh,",
    "start": "3170570",
    "end": "3175744"
  },
  {
    "text": "pretty good. [LAUGHTER] Yeah. And so, does this not work so well if you assume like,",
    "start": "3175745",
    "end": "3183109"
  },
  {
    "text": "that here is your local minima that you can converge to when you're training the sort of leader and all of the data number one.",
    "start": "3183110",
    "end": "3190924"
  },
  {
    "text": "And are there any cases where like, training on less data can actually give you a better- like,",
    "start": "3190925",
    "end": "3198230"
  },
  {
    "text": "like, ge- get you a better reader performance? Um, so for the first question if you are continuously fine tuning then like,",
    "start": "3198230",
    "end": "3206405"
  },
  {
    "text": "it could certainly be the case that at the beginning you get to a certain place in",
    "start": "3206405",
    "end": "3211415"
  },
  {
    "text": "that your optimization landscape from training on a very small amount of data that is very hard to get out of.",
    "start": "3211415",
    "end": "3216815"
  },
  {
    "text": "Uh, and there's actually some interesting work by, um, Stefano Soatto that looks at these sorts of critical periods in neural network training,",
    "start": "3216815",
    "end": "3223940"
  },
  {
    "text": "and how that affects training in later parts of, uh, later parts of training. And that's actually, uh, that will hurt potentially both of these two approaches,",
    "start": "3223940",
    "end": "3232880"
  },
  {
    "text": "uh, because you could over fit to small amounts of data or get to a bad part of the optimization landscape. Um, and so one way to do that is just to restart, like",
    "start": "3232880",
    "end": "3240095"
  },
  {
    "text": "randomly initialize your network at different points during training. Um, and in principle,",
    "start": "3240095",
    "end": "3245990"
  },
  {
    "text": "like on paper the follow the leader algorithm would, would do that- would at every single time step will reinitialize your neural network.",
    "start": "3245990",
    "end": "3252860"
  },
  {
    "text": "If you want to implement in practice you would probably want to do some sort of continuous fine tuning or, or periodic, uh, random initializations.",
    "start": "3252860",
    "end": "3258935"
  },
  {
    "text": "Uh, what was your second question? Um, I guess it was just about like if sometimes using like,",
    "start": "3258935",
    "end": "3266030"
  },
  {
    "text": "a smaller subset of the data as opposed to all of the data up until the point that you like train is in some ways like better to train the leader.",
    "start": "3266030",
    "end": "3275855"
  },
  {
    "text": "Like if you- for example, if you selectively choose examples that are more instructive,",
    "start": "3275855",
    "end": "3281644"
  },
  {
    "text": "and leave out examples that are either redundant or actually [NOISE] might affect their performance,",
    "start": "3281645",
    "end": "3286970"
  },
  {
    "text": "because [NOISE] let's say you collect way to many negative examples, and you wanna somehow balance like,",
    "start": "3286970",
    "end": "3292220"
  },
  {
    "text": "positive and negative examples while training their leaders. Yeah, so in general I think- yeah,",
    "start": "3292220",
    "end": "3298760"
  },
  {
    "text": "in general in machine learning not just in lifelong learning that that like the distribution of the data that you're training on matters.",
    "start": "3298760",
    "end": "3304205"
  },
  {
    "text": "And so for example if you have a highly imbalanced classification task where you have, uh, maybe you're actually, like, uh,",
    "start": "3304205",
    "end": "3311295"
  },
  {
    "text": "making- doing medical diagnoses and like 99% of your people, uh, of your patients don't have the condition and 1% do,",
    "start": "3311295",
    "end": "3317890"
  },
  {
    "text": "then, uh, re-balancing that a little bit can actually help you get better performance,",
    "start": "3317890",
    "end": "3323535"
  },
  {
    "text": "um, and then also in reinforcement learning contexts. For example, if- if- if the data that you're seeing, um,",
    "start": "3323535",
    "end": "3330005"
  },
  {
    "text": "is- is highly imbalanced then it could be that you could do better by re-balancing it in different ways.",
    "start": "3330005",
    "end": "3336265"
  },
  {
    "text": "Typically, you don't re-balance by using less data. Typically, you re-balance by just sampling the data in a different manner.",
    "start": "3336265",
    "end": "3342090"
  },
  {
    "text": "Uh, in general, I don't think there is that much that is known about how best to optimally balance your data.",
    "start": "3342090",
    "end": "3348170"
  },
  {
    "text": "And I think that typically it depends on the types of data that you're seeing at test time. I mean in practice you want that the-",
    "start": "3348170",
    "end": "3353660"
  },
  {
    "text": "the balance to be the same as what you would be seeing at test time. Okay. Oh, the other thing,",
    "start": "3353660",
    "end": "3362255"
  },
  {
    "text": "um, the other note or other downside as SGD is that, uh, it is a somewhat slow learning process.",
    "start": "3362255",
    "end": "3368750"
  },
  {
    "text": "And so, uh, and that's why we typically replay our data multiple times. I do multiple epochs of training.",
    "start": "3368750",
    "end": "3374795"
  },
  {
    "text": "Uh, and that's because SGD, uh, doesn't update as quickly, uh, as possible.",
    "start": "3374795",
    "end": "3380150"
  },
  {
    "text": "If you just give it one pass through the data. Um, and so we may want algorithms that can learn faster.",
    "start": "3380150",
    "end": "3387359"
  },
  {
    "text": "Okay. So the next question is can we do better?",
    "start": "3387460",
    "end": "3393020"
  },
  {
    "text": "Uh, so these are the two basics, uh, to I think two most basic algorithms in online learning and continual learning.",
    "start": "3393020",
    "end": "3400055"
  },
  {
    "text": "Uh, and so I'll cover a couple- a couple of algorithms that allow us to do better,",
    "start": "3400055",
    "end": "3405694"
  },
  {
    "text": "uh, than these algorithms in different problems settings. Uh, so the first, ah, case study that we'll look at is if SGD is slow,",
    "start": "3405695",
    "end": "3415325"
  },
  {
    "text": "can we use meta learning to make it faster in online learning problem settings.",
    "start": "3415325",
    "end": "3421685"
  },
  {
    "text": "And so in particular what we're gonna do is we will revisit the example that we saw in the last lecture where we have,",
    "start": "3421685",
    "end": "3427684"
  },
  {
    "text": "uh, some agent that is learning to traverse different terrains.",
    "start": "3427685",
    "end": "3433035"
  },
  {
    "text": "And at different points in time it sees different terrains. Uh, and we know- remember that we talked about how",
    "start": "3433035",
    "end": "3439945"
  },
  {
    "text": "this form of like online adaptation can be viewed as a form of few-shot learning where the tasks are different temporal slices of your experience.",
    "start": "3439945",
    "end": "3447685"
  },
  {
    "text": "But now what's gonna be different this time is we're going to consider a setting where, ah, we see a new terrain,",
    "start": "3447685",
    "end": "3453970"
  },
  {
    "text": "ah, and we see data from that new terrain. Uh, and that setting might be extrapolated from the kinds of things that we learned before.",
    "start": "3453970",
    "end": "3461880"
  },
  {
    "text": "Uh, and so this can be an example of an online learning program where we continuously see data from that terrain and we wanna be able to eventually learn how to,",
    "start": "3461880",
    "end": "3469415"
  },
  {
    "text": "uh, handle that terrain. And so because it's extrapolated from what we saw before,",
    "start": "3469415",
    "end": "3474665"
  },
  {
    "text": "if you just take the last k time steps of experience that isn't going to be sufficient to learn, to adapt, to an entirely new terrain.",
    "start": "3474665",
    "end": "3481984"
  },
  {
    "text": "So how do we solve this problem? Um, one option would be to continually- just continuously run SGD.",
    "start": "3481985",
    "end": "3488855"
  },
  {
    "text": "So basically, uh, take the algorithm- take the SGD algorithm I talked about before. And just for each window of k time steps you take another gradient step.",
    "start": "3488855",
    "end": "3497090"
  },
  {
    "text": "Uh, and this will do better than taking one gradient step on the last k. Ur,",
    "start": "3497090",
    "end": "3502140"
  },
  {
    "text": "and it will be pretty fast with a MAML initialization. Um, the downside is though that if you see ice for a while,",
    "start": "3502150",
    "end": "3509795"
  },
  {
    "text": "you- you adapt to that by running SGD. Uh, and then you go back to one of your other terrains,",
    "start": "3509795",
    "end": "3515810"
  },
  {
    "text": "uh, if you've adapted your parameter vector and specialized it for ice, uh, then you may not be able to do well on other terrains and you",
    "start": "3515810",
    "end": "3524630"
  },
  {
    "text": "may also forget the- that meta learned initialization that allowed you to adapt very quickly in the first place.",
    "start": "3524630",
    "end": "3530099"
  },
  {
    "text": "Okay. So how could we do better than SGD in this setting? Um, the first thing we notice that we can do better by",
    "start": "3530350",
    "end": "3538160"
  },
  {
    "text": "meta-training with it like a MAML initialization that will allow us to adapt more quickly. Um, but we can also do better than that and try to solve this second problem.",
    "start": "3538160",
    "end": "3545855"
  },
  {
    "text": "So, uh, we can view this as a form of online inference. So at each point in time we wanna be able to identify,",
    "start": "3545855",
    "end": "3553204"
  },
  {
    "text": "uh, the task that we're in. Uh, and we may not be able to observe that task.",
    "start": "3553205",
    "end": "3558305"
  },
  {
    "text": "Uh, so for example when we're on ice you may not be able to observe that we're on ice and when we move back to another terrain you need to be able to infer from the data that we're on a new terrain.",
    "start": "3558305",
    "end": "3567589"
  },
  {
    "text": "Um, so what we'll do, uh, in- in this case task is corresponding to the terrain that were on or the model- the dynamics model that we're under.",
    "start": "3567660",
    "end": "3575195"
  },
  {
    "text": "Uh, and it may not correspond to that like a semantic task that you're trying to accomplish. Okay. So we wanna be able to infer,",
    "start": "3575195",
    "end": "3582635"
  },
  {
    "text": "uh, the terrain or the task in each time step, and once we do that, uh, what we're going to do is,",
    "start": "3582635",
    "end": "3588260"
  },
  {
    "text": "we're going to have a mixture of- a mixture model of parameters. One for each of the tasks that we have.",
    "start": "3588260",
    "end": "3594695"
  },
  {
    "text": "And once we infer the task that we're in we can then just run the parameters corresponding to that task for, uh, planning.",
    "start": "3594695",
    "end": "3602225"
  },
  {
    "text": "So in particular we'll have, ah, a mixture of neural network parameters over, uh, your task variable.",
    "start": "3602225",
    "end": "3608765"
  },
  {
    "text": "And for each of those mixture components, we'll take an SGD step on that component.",
    "start": "3608765",
    "end": "3616595"
  },
  {
    "text": "When we think that we're in that data regime. [NOISE] So you can actually formulate this as,",
    "start": "3616595",
    "end": "3623765"
  },
  {
    "text": "uh, an expectation maximization problem, uh, where the E-step is gonna correspond to estimating which terrain you're on or which task you're in,",
    "start": "3623765",
    "end": "3631895"
  },
  {
    "text": "uh, given your data. So let's say that the , um, you're- you're, let's just kind of simplify the notation and say that the last k time steps of",
    "start": "3631895",
    "end": "3640850"
  },
  {
    "text": "data s and a is just gonna correspond to x_t and y_t for a given time step. Uh, and the way that we can estimate which task we're in will look like this.",
    "start": "3640850",
    "end": "3650780"
  },
  {
    "text": "So, uh, we want to be able to estimate the probability that we're in task i given the data at the current time step and so what we'll do is we'll multiply the,",
    "start": "3650780",
    "end": "3659885"
  },
  {
    "text": "uh, likelihood of the data under each of the tasks. So say we'll imagine that we're under task i,",
    "start": "3659885",
    "end": "3666665"
  },
  {
    "text": "look at the likelihood of being under task i. And then we'll multiply that by the prior that we're in task i.",
    "start": "3666665",
    "end": "3674450"
  },
  {
    "text": "Obviously this can tell us the probability that the current terrain correspond to a particular task.",
    "start": "3674450",
    "end": "3681300"
  },
  {
    "text": "Okay. So once we have a set of parameters, once we've identified which task we're in, uh, we can then update the parameters corresponding to that task.",
    "start": "3682240",
    "end": "3692540"
  },
  {
    "text": "Uh, by just taking the SGD step. Uh, and [NOISE] we can do that actually in a soft way. So we could, uh,",
    "start": "3692540",
    "end": "3698810"
  },
  {
    "text": "we can have these probabilities be continuous probabilities and then we'll take a gradient step. Uh, so we'll have a great- uh,",
    "start": "3698810",
    "end": "3704900"
  },
  {
    "text": "a parameter, uh, vector for each task. And then we'll take, uh, a gradient descent step, uh,",
    "start": "3704900",
    "end": "3710960"
  },
  {
    "text": "that is on each mixture element weighted by the probability of the task. So this is just the probability of the task right here.",
    "start": "3710960",
    "end": "3718955"
  },
  {
    "text": "And we'll take a gradient step on the data that we, uh, observed for that task.",
    "start": "3718955",
    "end": "3724174"
  },
  {
    "text": "So if this probability is zero, if we're not in that terrain, we won't update the parameters for that task or that terrain.",
    "start": "3724175",
    "end": "3730355"
  },
  {
    "text": "And if we are in that terrain, for example, the probability is one or very high, then we'll take a gradient step using that data.",
    "start": "3730355",
    "end": "3737190"
  },
  {
    "text": "Any questions on how this works? Yeah. [inaudible]",
    "start": "3737910",
    "end": "3745870"
  },
  {
    "text": "Yeah. So this is a good question. So what we did for that is uh,",
    "start": "3745870",
    "end": "3751450"
  },
  {
    "text": "you can basically allow it to instantiate new tasks.",
    "start": "3751450",
    "end": "3757075"
  },
  {
    "text": "And so- and basically allow it to incrementally grow the number of tasks that's used. In particular what you can use,",
    "start": "3757075",
    "end": "3764620"
  },
  {
    "text": "is you can use something called a Chinese restaurant process prior, that corresponds the prior probability that you're in a new situation,",
    "start": "3764620",
    "end": "3771910"
  },
  {
    "text": "or in a new task or a new terrain. Uh, and then, if you think that",
    "start": "3771910",
    "end": "3777490"
  },
  {
    "text": "you- the probability- so they'll be probability of being under a, the terrains that you've seen previously and it will also be a probability of being in",
    "start": "3777490",
    "end": "3785110"
  },
  {
    "text": "a new terrain and to evaluate that probability will have the prior term, uh,",
    "start": "3785110",
    "end": "3790705"
  },
  {
    "text": "corresponding to the Chinese restaurant process prior and then we'll also have, um, likelihood of the data,",
    "start": "3790705",
    "end": "3796225"
  },
  {
    "text": "if you reinitialize to the middle of the initialization to the prior, take one gradient stuff on that terrain and see, um,",
    "start": "3796225",
    "end": "3803430"
  },
  {
    "text": "the likelihood of how well that explains the data versus all the other tasks.",
    "start": "3803430",
    "end": "3808474"
  },
  {
    "text": "Uh, one downside is that you may add a lot of tasks and so at",
    "start": "3808475",
    "end": "3814480"
  },
  {
    "text": "some point you may need to refresh the tasks or kind of remove the tasks that you haven't seen recently. Yeah.",
    "start": "3814480",
    "end": "3819820"
  },
  {
    "text": "It's kind of like a follow-up question. So it sounds like very similar to the type of modeling that you don't know,",
    "start": "3819820",
    "end": "3826720"
  },
  {
    "text": "how many topics of the head like then we decided whatever [inaudible] prior or some transfers were all processed.",
    "start": "3826720",
    "end": "3834520"
  },
  {
    "text": "But the likelihood that you maximize doesn't necessarily serve, uh, the potential probability that you adapt with new terrain that you going to see",
    "start": "3834520",
    "end": "3844089"
  },
  {
    "text": "is higher for anything or evaluated or this successful, this for successfulness of, uh,",
    "start": "3844090",
    "end": "3851275"
  },
  {
    "text": "like entering into the right trace, or right cap for your up role model, in this case.",
    "start": "3851275",
    "end": "3859375"
  },
  {
    "text": "So you're asking me how do you evaluate, so it's definitely similar to topic modeling, um, like Dirichlet processes,  the- you're asking,",
    "start": "3859375",
    "end": "3867280"
  },
  {
    "text": "how do you evaluate whether or not you are in, uh, like whether or not a task corresponds to a terrain.",
    "start": "3867280",
    "end": "3875185"
  },
  {
    "text": "Yeah, or how can you tell this passes to successful.",
    "start": "3875185",
    "end": "3880330"
  },
  {
    "text": "If you don't train or see this topic, uh, in your training set and then you like arbitrarily",
    "start": "3880330",
    "end": "3888085"
  },
  {
    "text": "assign this new topic to the new data that you can process, and how straight people tell this new topic you",
    "start": "3888085",
    "end": "3895630"
  },
  {
    "text": "haven't- you've got across before the right new topic for your context in this terrain setting like the- the- the notations are still mysterious.",
    "start": "3895630",
    "end": "3907750"
  },
  {
    "text": "Yeah, so we are given both like at each time step we are given we're doing model-based reinforcement learning.",
    "start": "3907750",
    "end": "3915760"
  },
  {
    "text": "So we're learning a dynamic model. And so we have actually the labels, uh, which is basically the next state.",
    "start": "3915760",
    "end": "3921160"
  },
  {
    "text": "And so that can tell us the- that can allow us to explain whether or not, uh,",
    "start": "3921160",
    "end": "3926289"
  },
  {
    "text": "to identify whether or not a, a given point in our data stream, corresponds to a certain model by looking at the likelihood of that data under our model.",
    "start": "3926290",
    "end": "3934510"
  },
  {
    "text": "Um, in terms of identifying whether or not you're in a- kind of one of the tasks that you've seen previously versus a new task.",
    "start": "3934510",
    "end": "3940930"
  },
  {
    "text": "You can basically, uh, for a new task you can just reset to your middle of an initialization and take one gradient step, and see if that explains the data better,",
    "start": "3940930",
    "end": "3947710"
  },
  {
    "text": "if that gives them a higher likelihood on the data, compared to the, uh, the other parameter vectors that you have.",
    "start": "3947710",
    "end": "3954895"
  },
  {
    "text": "Does that answer your question? Yep. So and I think the question that was like a couple weeks ago but once you're up there and",
    "start": "3954895",
    "end": "3964360"
  },
  {
    "text": "this what is the benefit of maintaining models versus online system.",
    "start": "3964360",
    "end": "3969640"
  },
  {
    "text": "Yeah so, in this setting- so this is maintaining multiple models is maintaining like a mixture model of- of -of models.",
    "start": "3969640",
    "end": "3978714"
  },
  {
    "text": "One of the benefits that you get is that, uh, you couldn't- with multiple models you can potentially adopted in zero shot,",
    "start": "3978715",
    "end": "3986200"
  },
  {
    "text": "or in like one shot like once you've- once you basically see the- see a data point.",
    "start": "3986200",
    "end": "3991450"
  },
  {
    "text": "You can use that to identify which model you should use, whereas a form of- kind of online system identification needs to",
    "start": "3991450",
    "end": "3997000"
  },
  {
    "text": "actually adapt using that data from a prior. And it may be that you need more than one data point to adapt.",
    "start": "3997000",
    "end": "4004244"
  },
  {
    "text": "Um, so this recall is essentially can be faster, if you're maintaining multiple models com- compared to having a single prior.",
    "start": "4004245",
    "end": "4012480"
  },
  {
    "text": "Uh, the benefit of using a prior is that you don't have to maintain multiple sets of parameters.",
    "start": "4012480",
    "end": "4020970"
  },
  {
    "text": "Uh, and so that can also be- be, um, nice. Does that answer your question?",
    "start": "4020970",
    "end": "4026385"
  },
  {
    "text": "Yeah. So when you're evaluating and, um, you're giving it like, so let's say a completely new terrain, and you're not allowed to find that new terrain,",
    "start": "4026385",
    "end": "4037080"
  },
  {
    "text": "does it- basically learned to like mix the models that's it's learned for over the distributions of the terrains that it's lined up to that point,",
    "start": "4037080",
    "end": "4045375"
  },
  {
    "text": "it's kind of like adding the average like its behavior on the new terrain,",
    "start": "4045375",
    "end": "4051750"
  },
  {
    "text": "so that kind of what it does or? Um, so we do allow it to continuously fine-tune, on- as it sees data,",
    "start": "4051750",
    "end": "4057540"
  },
  {
    "text": "and so if it sees it as a terrain that was like, um, that is very different from anything that it saw before that it will",
    "start": "4057540",
    "end": "4063240"
  },
  {
    "text": "instantiate a new task or a new model for that. Uh, if it seems to be like a mixture of two terrains and- in that",
    "start": "4063240",
    "end": "4069030"
  },
  {
    "text": "explains- those two terrains explain- like a mixture of those two terrains basic- a linear mixture,",
    "start": "4069030",
    "end": "4074040"
  },
  {
    "text": "uh, explains the data well, then it will use both of those. It will use a linear combination of those parameters and then it will",
    "start": "4074040",
    "end": "4080565"
  },
  {
    "text": "update both of them with a gradient step that's weighted, uh, by one half, update each model by one half of the string.",
    "start": "4080565",
    "end": "4088815"
  },
  {
    "text": "Yep. [inaudible] initialization, did you do that before",
    "start": "4088815",
    "end": "4096299"
  },
  {
    "text": "starting this or did you do it also update it concurrently? Yeah, that's a good question.",
    "start": "4096300",
    "end": "4101580"
  },
  {
    "text": "So in this case, uh, we- the initialization is, is pre-trained and then we- and the next one is just like ahead of time, and then you,",
    "start": "4101580",
    "end": "4109650"
  },
  {
    "text": "run this form of online learning, uh, from that initialization. One really important thing to think about is can you then take",
    "start": "4109650",
    "end": "4116699"
  },
  {
    "text": "that data and use that to improve your initialization. For example, if you start seeing ice you should then kind of incorporate that into your priors such that,",
    "start": "4116700",
    "end": "4124154"
  },
  {
    "text": "uh, you improve your prior. Uh, and maybe you can kind of discard the Ice model, uh,",
    "start": "4124155",
    "end": "4129315"
  },
  {
    "text": "as was all-, alluded to you before and just adapt to that from your prior. But you can't do that until you actually start incorporating data into it.",
    "start": "4129315",
    "end": "4136469"
  },
  {
    "text": "Um, this work didn't study that setting and it's- I guess one of the challenges that's worth",
    "start": "4136470",
    "end": "4143190"
  },
  {
    "text": "thinking about is can you- instead like- adaptation is very fast because it's meta- meta-trained for fast adaptation.",
    "start": "4143190",
    "end": "4149775"
  },
  {
    "text": "But if you do an update to the meta learn parameters, that update won't necessarily be fast. That will be a slow update and so it may not be able to actually incorporate that data,",
    "start": "4149775",
    "end": "4158865"
  },
  {
    "text": "or a small amount of that data, to change the meta-learning or the prior very quickly. Um, you could imagine a form of like meta- meta",
    "start": "4158865",
    "end": "4165659"
  },
  {
    "text": "learning such that you train it also such that, the update- the updates to the meta learn model are also fast.",
    "start": "4165660",
    "end": "4171420"
  },
  {
    "text": "Uh, but that would be tricky.",
    "start": "4171420",
    "end": "4176170"
  },
  {
    "text": "Okay, along these lines, one thing is worth noting is that if",
    "start": "4178400",
    "end": "4183750"
  },
  {
    "text": "your neural network is randomly initialized and you do this procedure, it wouldn't work that well because the adaptation steps won't be very fast, er,",
    "start": "4183750",
    "end": "4192359"
  },
  {
    "text": "and you won't be able to adapt very far to your, um, to those new trains or those new situations that you're in.",
    "start": "4192360",
    "end": "4199290"
  },
  {
    "text": "So, um, having some sort of meta learn initialization is very important for successful online learning.",
    "start": "4199290",
    "end": "4205210"
  },
  {
    "text": "Okay, um, so this is one approach for using meta-learning to make online learning faster,",
    "start": "4205490",
    "end": "4211980"
  },
  {
    "text": "uh, and also being able to alleviate the forgetting problem. Uh, I'll quickly run through a couple of",
    "start": "4211980",
    "end": "4217785"
  },
  {
    "text": "the experiments that actually looked at how this works in practice. So, uh, in this case, the experiments, uh,",
    "start": "4217785",
    "end": "4224250"
  },
  {
    "text": "looked at two different settings at test time, one setting where, uh, the legs or the, um,",
    "start": "4224250",
    "end": "4231480"
  },
  {
    "text": "the- the creature, I think it was called a crawler, uh, it was in a constant crippled setting,",
    "start": "4231480",
    "end": "4238260"
  },
  {
    "text": "uh, versus, uh, the second setting was one where there was regions of flipping between the legs being crippled or,",
    "start": "4238260",
    "end": "4245970"
  },
  {
    "text": "or being disabled and legs being fixed. Uh, and then the y-axis to show the reward that's",
    "start": "4245970",
    "end": "4253650"
  },
  {
    "text": "normalized based off of the performance of all the methods in each of the two situations.",
    "start": "4253650",
    "end": "4258975"
  },
  {
    "text": "And then there are different methods that we can compare. So the first thing that we can do is online learning with the MAML initialization,",
    "start": "4258975",
    "end": "4265649"
  },
  {
    "text": "as we described on the previous slide. Uh, you could also do MAML initialization but just run SGD. Uh, and this will do well at continuously adapting but may forget,",
    "start": "4265649",
    "end": "4274385"
  },
  {
    "text": "uh, and they've kind of specialized too much. Uh, you could also do the original, uh,",
    "start": "4274385",
    "end": "4280190"
  },
  {
    "text": "approach of just always resetting to your prior and taking one gradient step, at every single timestep. This will, uh,",
    "start": "4280190",
    "end": "4286440"
  },
  {
    "text": "allow you to adapt quickly but won't necessarily allow you to accumulate data,",
    "start": "4286440",
    "end": "4291675"
  },
  {
    "text": "if you're in a setting that's extrapolated. Uh, and then last two examples are, uh, non-meta learning approaches that, uh,",
    "start": "4291675",
    "end": "4298740"
  },
  {
    "text": "either don't do adaptation, um, and just try to learn a single model or learn a model and fine-tune that model with gradient descent steps.",
    "start": "4298740",
    "end": "4305864"
  },
  {
    "text": "But those gradient descent steps may not be, uh, very fast. Um, so a lot of different methods.",
    "start": "4305865",
    "end": "4312330"
  },
  {
    "text": "Uh, in the constant crippled setting, we don't, um, we don't really expect to see much difference between these, uh,",
    "start": "4312330",
    "end": "4317820"
  },
  {
    "text": "these kinds of approaches because you can fit a single model to, uh, to that setting and, um,",
    "start": "4317820",
    "end": "4325280"
  },
  {
    "text": "you don't really need to, uh, you, um, it's- it's okay to count continuously just,",
    "start": "4325280",
    "end": "4332210"
  },
  {
    "text": "uh, keep on running SGD steps, and so we see, um, the methods do uh, somewhat similarly.",
    "start": "4332210",
    "end": "4338670"
  },
  {
    "text": "Whereas if we have these regions of the legs being crippled versus the legs not being crippled. Um, first, uh, meta-learning is",
    "start": "4338670",
    "end": "4345570"
  },
  {
    "text": "very important to actually be able to adapt to these different settings. So we see a big difference between the first two approaches and the second two.",
    "start": "4345570",
    "end": "4351855"
  },
  {
    "text": "And also we see that, uh, using always resetting and running SGD continuously,",
    "start": "4351855",
    "end": "4358695"
  },
  {
    "text": "don't perform well because they aren't able to, uh, accumulate data and also very quickly switch between these modes.",
    "start": "4358695",
    "end": "4364965"
  },
  {
    "text": "And so that's why we see the green doing better than the red and the blue. And the only thing that you can look at is the task distribution that's learned,",
    "start": "4364965",
    "end": "4374620"
  },
  {
    "text": "uh, and it's, it's, it's kind of identifying which uh, which mixture elements to use at which points in",
    "start": "4374620",
    "end": "4381820"
  },
  {
    "text": "time and so what you can see is that, uh, in this case the- the tasks are switching every 500 steps and it learns,",
    "start": "4381820",
    "end": "4388390"
  },
  {
    "text": "um, it learns that, uh, in, uh, these increments it learns to use these tasks. So, ah, from 500-1,000 and",
    "start": "4388390",
    "end": "4395710"
  },
  {
    "text": "from 1500-2,000 it always identifies it very clearly as Task one or, or Model number one and in the other increments it seems to prefer using the task with,",
    "start": "4395710",
    "end": "4406239"
  },
  {
    "text": "uh, ID of one ah. Sorry, the first case it was ta- task ID",
    "start": "4406240",
    "end": "4412599"
  },
  {
    "text": "two and then second one it seems to prefer task ID one and it ends up specializing that model to the terrain as it",
    "start": "4412600",
    "end": "4417610"
  },
  {
    "text": "sees more data on that terrain or in that situation. Okay, any questions? Yeah.",
    "start": "4417610",
    "end": "4427600"
  },
  {
    "text": "We are doing experiments where it is needed to like use three in at once, like we, we can make sure three [inaudible] environment.",
    "start": "4427600",
    "end": "4437965"
  },
  {
    "text": "Um, so in- in this I guess it's, it's choosing which, like how many models it wants to use, uh.",
    "start": "4437965",
    "end": "4446280"
  },
  {
    "text": "Actually yeah, between 1000 and 1500 there's like green, red- There's a little bit of green, yeah.",
    "start": "4446280",
    "end": "4452070"
  },
  {
    "text": "So it- it's, it is choosing in some of these to use three models. I think it's mostly dominated by, uh,",
    "start": "4452070",
    "end": "4460030"
  },
  {
    "text": "one and three though rather than two. Okay. Uh, so now let's talk about a second case study which is,",
    "start": "4460030",
    "end": "4470395"
  },
  {
    "text": "what if we're in the meta- we're not in the meta-learning setting, we don't have a way to pre-train for initialization that's very fast.",
    "start": "4470395",
    "end": "4475825"
  },
  {
    "text": "Uh, can we modify vanilla SGD to avoid negative backward transfer um, when we're learning from scratch?",
    "start": "4475825",
    "end": "4485350"
  },
  {
    "text": "Uh, and there has been actually a fairly large amount of work in this area, um and I'm going to highlight one work that I think,",
    "start": "4485350",
    "end": "4492670"
  },
  {
    "text": "uh, considers a fairly principled approach to this problem. Uh, and that was some work by, uh,",
    "start": "4492670",
    "end": "4498595"
  },
  {
    "text": "David Lopez-Paz and ah Marc'Aurelio Ranzato called gradient episodic memory for continual learning.",
    "start": "4498595",
    "end": "4505660"
  },
  {
    "text": "Uh, and the key idea behind this approach is that you can first store, uh,",
    "start": "4505660",
    "end": "4511900"
  },
  {
    "text": "some amount of data per task in memory but only store a small amount of data, uh, in contrast to storing everything, uh,",
    "start": "4511900",
    "end": "4518680"
  },
  {
    "text": "and you have actually a fixed memory size and then with making updates for new tasks,",
    "start": "4518680",
    "end": "4524650"
  },
  {
    "text": "ensure that the updates that you make don't unlearn your previous tasks.",
    "start": "4524650",
    "end": "4530320"
  },
  {
    "text": "Uh, and I guess- the second idea is or the second, uh, second concept is what most methods are trying to doing at- at,",
    "start": "4530320",
    "end": "4539920"
  },
  {
    "text": "what- what both methods in continue learning are trying to do. [NOISE] Uh, and so the key lies in how we actually try to accomplish 2.",
    "start": "4539920",
    "end": "4547449"
  },
  {
    "text": "Uh, and what this approach is gonna do is it's going to try to leverage the- the small amount of data that's stored in memory to ah, ensure that future updates don't,",
    "start": "4547450",
    "end": "4556990"
  },
  {
    "text": "uh, don't hurt the previous tasks that are stored um, and by using the, the data that's stored in memory.",
    "start": "4556990",
    "end": "4563829"
  },
  {
    "text": "Okay. So let's say that our predictor is parameterized by our or is f theta um and it knows the input and the task,",
    "start": "4563830",
    "end": "4571990"
  },
  {
    "text": "uh, and the task corresponds to ZT. And then we'll have some memory, uh,",
    "start": "4571990",
    "end": "4577735"
  },
  {
    "text": "corresponding to MK for task k or for task zk. What this approach will do, um,",
    "start": "4577735",
    "end": "4584290"
  },
  {
    "text": "is for every time step it's going to take an update step on the data point xt, yt, uh,",
    "start": "4584290",
    "end": "4591560"
  },
  {
    "text": "with respect to the predictor, subject to the constraint that the loss on the, uh,",
    "start": "4591750",
    "end": "4600880"
  },
  {
    "text": "on the stored data points in memory doesn't get worse than it was for the previous model.",
    "start": "4600880",
    "end": "4607855"
  },
  {
    "text": "Uh, and it's going to do this for all of the tasks stored, all of the tasks that were previously seen.",
    "start": "4607855",
    "end": "4613675"
  },
  {
    "text": "This seems pretty reasonable. I guess I just want to ensure that the, the loss function doesn't go down for, uh, for those tasks,",
    "start": "4613675",
    "end": "4620409"
  },
  {
    "text": "and we're gonna be using the data points in a more, in a, at a more weak way than if we're going to try to directly train on them.",
    "start": "4620410",
    "end": "4627680"
  },
  {
    "text": "Uh, the challenge with this is that it's, it's hard to think about how you would actually solve this constraint optimization problem.",
    "start": "4628080",
    "end": "4635570"
  },
  {
    "text": "And so, one of the things that was neat in this paper is they showed that ah,",
    "start": "4635850",
    "end": "4641530"
  },
  {
    "text": "kind of they came up with the idea that if you assume local linearity, uh, of the optimization landscape,",
    "start": "4641530",
    "end": "4647844"
  },
  {
    "text": "then you can basically use the, the gradient of the task [NOISE] to ah, rephrase this constraint. Yeah.",
    "start": "4647845",
    "end": "4657190"
  },
  {
    "text": "Do you update memory or it's just static distribution? Right, sorry, I guess I didn't put this in here but yeah,",
    "start": "4657190",
    "end": "4664620"
  },
  {
    "text": "you also update the memory at each time step um, and store ah, a,",
    "start": "4664620",
    "end": "4670980"
  },
  {
    "text": "a set of data points for each task that you see. And the memory storing mechanism that they used in this paper is quite simple,",
    "start": "4670980",
    "end": "4680940"
  },
  {
    "text": "they just took the total size of the memory divided by the total number of tasks and then for each task they saw they just added that number of data points to the memory,",
    "start": "4680940",
    "end": "4688375"
  },
  {
    "text": "um, such that, ah, it kind of fillled to max capacity ah, but",
    "start": "4688375",
    "end": "4693385"
  },
  {
    "text": "I think the more sophisticated approaches would also probably do better. Okay. So if you assume linearity of,",
    "start": "4693385",
    "end": "4701365"
  },
  {
    "text": "or local linearity of the optimization landscape, then you can actually rephrase this second constraint as saying that you want the, uh,",
    "start": "4701365",
    "end": "4708775"
  },
  {
    "text": "the inner products between the gradient of, the gradient that you take with respect to your current data point and",
    "start": "4708775",
    "end": "4717879"
  },
  {
    "text": "the gradient of the data points in your memory to be non-negative.",
    "start": "4717879",
    "end": "4723415"
  },
  {
    "text": "And this is basically saying that when you apply the gradient on your current timestamp or basically apply,",
    "start": "4723415",
    "end": "4729280"
  },
  {
    "text": "uh, GT, you want GT to not, uh, go in the opposite direction as the gradients for all of your other tasks",
    "start": "4729280",
    "end": "4737034"
  },
  {
    "text": "and if ends- if it points in the same direction as the task then it will, well, if it is orthogonal then, and if the space is locally",
    "start": "4737035",
    "end": "4743890"
  },
  {
    "text": "linear then it won't- it will keep the loss the same for all these previous tasks and if it actually points in the same direction it has",
    "start": "4743890",
    "end": "4750594"
  },
  {
    "text": "a positive inner product then- and the space is locally linear, then, uh, you actually get positive backward transfer.",
    "start": "4750595",
    "end": "4759505"
  },
  {
    "text": "It will actually improve those previous tasks. Uh, the other assumption that this",
    "start": "4759505",
    "end": "4765190"
  },
  {
    "text": "makes is that the small amount of data stored in your memory, is representative of those previous tasks.",
    "start": "4765190",
    "end": "4771260"
  },
  {
    "text": "Okay. Um, and then what you can do, uh, is you can replace this, ah, the constraint there with the constraint there, uh,",
    "start": "4772080",
    "end": "4780400"
  },
  {
    "text": "and you can then formulate this as a quadratic program, uh, and use, ah,",
    "start": "4780400",
    "end": "4786070"
  },
  {
    "text": "QP solvers to, um, to figure out how to modify your gradient such that the constraints are satisfied.",
    "start": "4786070",
    "end": "4794659"
  },
  {
    "text": "Great. Uh, so in our experiments they looked at a few different problems.",
    "start": "4796020",
    "end": "4801490"
  },
  {
    "text": "Ah, they looked at permutations of MNIST, uh, where the pixels were permuted and you saw a sequence of",
    "start": "4801490",
    "end": "4806860"
  },
  {
    "text": "tasks corresponding to different permutations of those pixels. They also looked at, uh, rotated MNIST digits,",
    "start": "4806860",
    "end": "4812200"
  },
  {
    "text": "same thing but rotating the pixels, uh, and also CIFAR-100 where it introduces five classes of CIFAR, for each task.",
    "start": "4812200",
    "end": "4820300"
  },
  {
    "text": "Um, and the evaluated backward transfer as well as forward transfer as well as the accuracy on each of the tasks in sequence,",
    "start": "4820300",
    "end": "4826750"
  },
  {
    "text": "uh, and the total memory size that they used was 5,000 examples across all of the tasks.",
    "start": "4826750",
    "end": "4833305"
  },
  {
    "text": "All right. So here are what the results look like. Um, so you can see that the,",
    "start": "4833305",
    "end": "4838810"
  },
  {
    "text": "uh, in general so GEM is what this method is called, it was able to achieve higher accuracy than training",
    "start": "4838810",
    "end": "4845530"
  },
  {
    "text": "a single model on everything and in comparative training, ah, independent models on each of the tasks,",
    "start": "4845530",
    "end": "4851304"
  },
  {
    "text": "uh, and if you look at the, uh, what the red plot is showing, is it showing the performance,",
    "start": "4851305",
    "end": "4857260"
  },
  {
    "text": "um, of the models, uh, as you add more and more tasks, uh,",
    "start": "4857260",
    "end": "4863605"
  },
  {
    "text": "and it's showing, I think the performance of the first task after seeing each sequence of tasks.",
    "start": "4863605",
    "end": "4869110"
  },
  {
    "text": "You can see that it doesn't, uh, for many of the methods it starts to decline due to negative, uh, backward transfer, uh, whereas for this approach it's able to,",
    "start": "4869110",
    "end": "4876940"
  },
  {
    "text": "uh, maintain a high accuracy even as you see more data. Uh, and you can see fairly consistent trends for",
    "start": "4876940",
    "end": "4883975"
  },
  {
    "text": "the other approaches as well or the other, uh, the other benchmarks.",
    "start": "4883975",
    "end": "4890695"
  },
  {
    "text": "Um, one thing that I'd like to know, here, uh, if you take a step back and think about this experimental setup, uh, you may think well,",
    "start": "4890695",
    "end": "4898045"
  },
  {
    "text": "do these experimental domains make sense for studying problems in backward transfer and- and forgetting?",
    "start": "4898045",
    "end": "4903159"
  },
  {
    "text": "Uh, and if you're in a setting where you have, uh, 20 MNIST tasks or,",
    "start": "4903160",
    "end": "4909400"
  },
  {
    "text": "uh, 23 CIFAR-100 tasks, those are both settings where it's actually very easy to store the entire dataset in your replay buffer or,",
    "start": "4909400",
    "end": "4916210"
  },
  {
    "text": "ah, on your hard drive and so, uh, they aren't necessarily reflective of the kinds of problems that we care",
    "start": "4916210",
    "end": "4921849"
  },
  {
    "text": "about in lifelong learning where we can't store data, uh, and so an approach where you, just store everything and train on it would actually probably do much better than,",
    "start": "4921850",
    "end": "4930430"
  },
  {
    "text": "uh, all the approaches pictured. So something to keep in mind when you're, uh, developing, uh algorithms.",
    "start": "4930430",
    "end": "4937929"
  },
  {
    "text": "Uh, there's also some algorithms that kind of combine the ideas of these two, two approaches where we actually try to meta-learn",
    "start": "4937930",
    "end": "4943210"
  },
  {
    "text": "how to avoid negative backward transfer. There's a paper at NeurIPS that is covering that. Ah and because we're out of time,",
    "start": "4943210",
    "end": "4950319"
  },
  {
    "text": "I'll jump ahead to, [NOISE] I'll skip. The last part was about [NOISE] um, online meta-learning which we don't have time to cover.",
    "start": "4950319",
    "end": "4958060"
  },
  {
    "text": "Uh, the main takeaways that I want to get across is that there are many flavors of lifelong learning that are all under the same name.",
    "start": "4958060",
    "end": "4963969"
  },
  {
    "text": "Defining the problem statement is often the hardest part. It, it varies based off of what you care about in your particular application and, uh,",
    "start": "4963970",
    "end": "4971350"
  },
  {
    "text": "also in many ways meta-learning where you try to actually optimize for fast learning, uh, can be viewed as a slice of the lifelong learning problem, uh, where you want,",
    "start": "4971350",
    "end": "4979495"
  },
  {
    "text": "if you really care about ah, positive forward transfer and data efficiency. Uh, and lastly it's a very open and active area of research.",
    "start": "4979495",
    "end": "4988435"
  },
  {
    "text": "Okay. Um, a couple of reminders again, project milestones are due on Wednesday and two guest lectures next week,",
    "start": "4988435",
    "end": "4994750"
  },
  {
    "text": "Jeff Clune and Sergey Levine. I'll see you next week or on Wednesday.",
    "start": "4994750",
    "end": "5000489"
  }
]
[
  {
    "start": "0",
    "end": "5090"
  },
  {
    "text": "So first I want to recap\nthe meta-learning problem and black-box meta-learning\njust to provide a little bit",
    "start": "5090",
    "end": "11420"
  },
  {
    "text": "of review and refresher. And today, we'll talk primarily\nabout optimization-based meta-learning.",
    "start": "11420",
    "end": "18620"
  },
  {
    "text": "We'll cover the\noverall approach. We'll compare optimization-based\nand black-box meta-learning.",
    "start": "18620",
    "end": "25250"
  },
  {
    "text": "Conceptually, we'll talk\nabout some of the challenges with optimization-based\nmeta-learning and some solutions.",
    "start": "25250",
    "end": "30900"
  },
  {
    "text": "I also notice that\nthere's a typo here that I'll fix with\na pen, so it should",
    "start": "30900",
    "end": "38270"
  },
  {
    "text": "be optimization-based\nmeta-learning. And then we'll also talk\nabout a case study that applies meta-learning to\nthe problem of land cover",
    "start": "38270",
    "end": "45020"
  },
  {
    "text": "classification. And the goals for the\nend of the lecture",
    "start": "45020",
    "end": "50910"
  },
  {
    "text": "are; hopefully, you'll\nbe able to understand the basics of\noptimization-based meta-learning",
    "start": "50910",
    "end": "56160"
  },
  {
    "text": "as well as generally how to\ngo about implementing them and also understand\nthe trade-offs between black-box and\noptimization-based",
    "start": "56160",
    "end": "62730"
  },
  {
    "text": "meta-learning approaches. Great.",
    "start": "62730",
    "end": "68300"
  },
  {
    "text": "Let's get started. To recap what we talked\na bit about last time,",
    "start": "68300",
    "end": "74840"
  },
  {
    "text": "we talked about transfer\nlearning and also the meta-learning problem. And we talked about how\nthese different problem",
    "start": "74840",
    "end": "80630"
  },
  {
    "text": "settings relate also\nwith multi-task learning. So in multi-task\nlearning, the goal is to solve multiple\ntasks all at once.",
    "start": "80630",
    "end": "87320"
  },
  {
    "text": "In meta-learning, the goal is to\ngiven data from multiple tasks be able to leverage that\nto quickly solve a new task",
    "start": "87320",
    "end": "94010"
  },
  {
    "text": "with a small amount of data. And in transfer\nlearning, the goal is to solve a new task after\nsolving some previous source",
    "start": "94010",
    "end": "101420"
  },
  {
    "text": "tasks by transferring knowledge. Although the lines\nbetween transfer learning",
    "start": "101420",
    "end": "106490"
  },
  {
    "text": "and meta-learning may\nbe blurred a little bit.  Meta-learning can be viewed as\nan instantiation of transfer",
    "start": "106490",
    "end": "113570"
  },
  {
    "text": "learning if you view the\nsource task as the set of n meta-training tasks.",
    "start": "113570",
    "end": "121337"
  },
  {
    "text": "In both transfer learning\nand meta-learning, it's generally impractical\nto access the previous tasks.",
    "start": "121337",
    "end": "127259"
  },
  {
    "text": "And in all of these\nsettings the tasks must share some\namount of structure in order to actually\nsee a benefit",
    "start": "127260",
    "end": "133190"
  },
  {
    "text": "from these methods in comparison\nto independently training on each of the tasks. ",
    "start": "133190",
    "end": "139920"
  },
  {
    "text": "We also talked about what an\nexample meta-learning problem might look like.",
    "start": "139920",
    "end": "144950"
  },
  {
    "text": "For example, if you look at\nfew-shot image classification from the MiniImagenet\ndata set, at test time",
    "start": "144950",
    "end": "152180"
  },
  {
    "text": "your goal is to\nclassify new examples after seeing a tiny training\ndata set of only five examples.",
    "start": "152180",
    "end": "159800"
  },
  {
    "text": "And the way that\nyou go about trying to solve this few-shot\nlearning problem is to structure image data\nfrom other image classes",
    "start": "159800",
    "end": "166370"
  },
  {
    "text": "into different mini\ntrain sets and test sets and learn how to learn\neach of these tasks",
    "start": "166370",
    "end": "174270"
  },
  {
    "text": "so that you're\nwell-prepared to solve the meta-test task at the top\nwithout the image classes.",
    "start": "174270",
    "end": "180860"
  },
  {
    "text": "And of course this is an example\nin the image classification domain but you can replace\neach of these tasks",
    "start": "180860",
    "end": "187010"
  },
  {
    "text": "with regression problems,\nlanguage generation problems, skill learning problems,\nreally a wide range of machine",
    "start": "187010",
    "end": "192845"
  },
  {
    "text": "learning problems.  And then after we talked about\nthe meta-learning problem",
    "start": "192845",
    "end": "199110"
  },
  {
    "text": "statement, we also talked\nabout black-box adaptation. And this is a class of\nmeta-learning algorithms",
    "start": "199110",
    "end": "204510"
  },
  {
    "text": "that basically take your\ntraining data set for each of these tasks pass this through\na neural network that produces",
    "start": "204510",
    "end": "210420"
  },
  {
    "text": "the weights of another\nneural network phi i and then you take\nnew examples that you",
    "start": "210420",
    "end": "215670"
  },
  {
    "text": "want to be able to classify and\npass that through your network with phi i to get the\ncorresponding prediction.",
    "start": "215670",
    "end": "221849"
  },
  {
    "text": "And this whole process is\ntrained end-to-end with respect to your performance\non these test",
    "start": "221850",
    "end": "229440"
  },
  {
    "text": "examples for each of your tasks.  And this could be viewed as a\ngeneral form of neural network",
    "start": "229440",
    "end": "237690"
  },
  {
    "text": "that takes some of the training\ndata set and a new input and is trained to be able\nto make a correct prediction",
    "start": "237690",
    "end": "244050"
  },
  {
    "text": "about new input.  And then one of the main\nbenefits of this approach",
    "start": "244050",
    "end": "250360"
  },
  {
    "text": "is it's very expressive and\none of the main downside is that it's a pretty\nchallenging optimization problem because you need to\nactually learn to process data",
    "start": "250360",
    "end": "258088"
  },
  {
    "text": "and learn from data completely\nfrom scratch, from a randomly initialized neural\nnetwork of theta.",
    "start": "258089",
    "end": "266160"
  },
  {
    "text": "So that's a brief recap of\nwhat we covered last time. Now one question\nthat may come up",
    "start": "266160",
    "end": "273700"
  },
  {
    "text": "is well, right now we have this\nblack-box neural network that's",
    "start": "273700",
    "end": "279790"
  },
  {
    "text": "representing this\nlearning process, that's taking a train data\nset and outputting the weights of another\nneural network.",
    "start": "279790",
    "end": "287610"
  },
  {
    "text": "And there may be other ways that\nwe can represent this process. Instead of treating it as\nthis black-black inference",
    "start": "287610",
    "end": "294780"
  },
  {
    "text": "procedure, we could\ninstead treat it as an optimization procedure.",
    "start": "294780",
    "end": "300210"
  },
  {
    "text": "In many ways, this\nis the main idea behind optimization-based\nmeta-learning. So if you take the black-box\nadaptation approach",
    "start": "300210",
    "end": "309870"
  },
  {
    "text": "if you want to make\nit optimization-based, what you can simply do is\nreplace the neural network",
    "start": "309870",
    "end": "315120"
  },
  {
    "text": "that produces phi\ni with something that looks more like\nan optimization process and then meta-learn all the free\nparameters of that optimization",
    "start": "315120",
    "end": "323939"
  },
  {
    "text": "process, such as the\ninitialization, the learning rate or other ways that you\nmight tweak this optimization.",
    "start": "323940",
    "end": "333920"
  },
  {
    "text": "The idea is to embed\nan optimization inside this inner\nlearning process. ",
    "start": "333920",
    "end": "340560"
  },
  {
    "text": "Now why might this make\nsense in comparison to a black-box\nadaptation approach?",
    "start": "340560",
    "end": "346870"
  },
  {
    "text": "Well, one way to look\nat this is actually from the perspective of\nfine-tuning and transfer",
    "start": "346870",
    "end": "353925"
  },
  {
    "text": "learning. One thing that we saw\nbefore with fine-tuning was that if you start with a\nset of pre-trained parameters",
    "start": "353925",
    "end": "361290"
  },
  {
    "text": "and fine-tune, this is\nquite effective especially when you have a fairly sizable\nnumber of training examples",
    "start": "361290",
    "end": "369420"
  },
  {
    "text": "that you're fine-tuning on. But this is less effective\nwith very small data sets.",
    "start": "369420",
    "end": "374930"
  },
  {
    "text": "And so essentially\nthe question that optimization-based\nmeta-learning algorithms",
    "start": "374930",
    "end": "380930"
  },
  {
    "text": "seek to answer is,\nwell, what if instead of initializing from a set\nof pre-trained parameters",
    "start": "380930",
    "end": "388759"
  },
  {
    "text": "initialized on the\nimage net, for example, what if we explicitly\noptimized for a set of pre-trained\nparameters and maybe also",
    "start": "388760",
    "end": "395780"
  },
  {
    "text": "the learning rate or other\naspects of this fine-tuning process so that we can\ngeneralize effectively",
    "start": "395780",
    "end": "401240"
  },
  {
    "text": "with a small number of examples?  And so in particular one\ninstantiation of this, which is",
    "start": "401240",
    "end": "410550"
  },
  {
    "text": "called the model-agnostic\nmeta-learning algorithm. It tries to be able to do\nfine-tuning at test time",
    "start": "410550",
    "end": "415763"
  },
  {
    "text": "and it tries to find a set\nof pre-trained parameters such that fine-tuning\ngeneralizes well with a small\namount of data.",
    "start": "415763",
    "end": "423470"
  },
  {
    "text": "And the way this\noptimization looks like is we take the\nfine-tuning process, we say,",
    "start": "423470",
    "end": "429320"
  },
  {
    "text": "hey we want this fine-tuning\nprocess to generalize well with a small training data set.",
    "start": "429320",
    "end": "434580"
  },
  {
    "text": "So we'll feed in a\nsmall training data set and then evaluate fine-tuning\non new held out data",
    "start": "434580",
    "end": "440389"
  },
  {
    "text": "points in our task test set. And then we'll optimize\nfor the initialization",
    "start": "440390",
    "end": "447630"
  },
  {
    "text": "for theta such that this one\nor a few steps of fine-tuning",
    "start": "447630",
    "end": "452940"
  },
  {
    "text": "generalizes well to\nthese new data points. And then of course, we\ndo this optimization",
    "start": "452940",
    "end": "458460"
  },
  {
    "text": "across all of the tasks\nin our meta-training set. ",
    "start": "458460",
    "end": "464472"
  },
  {
    "text": "So the key idea here\nis we're essentially going to be trying to learn\na parameter vector theta that can transfer to all of the tasks\nin our meta-training data set",
    "start": "464472",
    "end": "472840"
  },
  {
    "text": "with a few steps of fine-tuning. This equation shows\none gradient step.",
    "start": "472840",
    "end": "478060"
  },
  {
    "text": "In practice, it\ncould just be one or it could be a\nfew or a handful. Although, as you increase\nthe number of gradient steps,",
    "start": "478060",
    "end": "486550"
  },
  {
    "text": "this optimization problem gets\na little bit more unwieldy. ",
    "start": "486550",
    "end": "493060"
  },
  {
    "text": "So this is the gist of an\noptimization-based meta-learner",
    "start": "493060",
    "end": "501700"
  },
  {
    "text": "in the sense that it's\nembedding this optimization inside the process\nin order to get,",
    "start": "501700",
    "end": "509530"
  },
  {
    "text": "this will give you something\nthat looks like phi i. Basically, fine-tuning\nwill get you phi i",
    "start": "509530",
    "end": "514530"
  },
  {
    "text": "and then you're\noptimizing for phi i such that it generalizes\non the test set.",
    "start": "514530",
    "end": "519641"
  },
  {
    "text": " And then one way that you could\nview this process more visually",
    "start": "519642",
    "end": "526990"
  },
  {
    "text": "is say theta is the\nparameter vector that you're meta-learning and phi i*\nis the optimal parameter vector",
    "start": "526990",
    "end": "533410"
  },
  {
    "text": "for all of your meta-training\ntasks then in some sense, you could view the meta-learning\nprocess as this thick black",
    "start": "533410",
    "end": "540940"
  },
  {
    "text": "line here where when\nyou're at this point during the meta-training process if\nyou take a gradient step with",
    "start": "540940",
    "end": "546430"
  },
  {
    "text": "respect to test 3, you're quite\nfar from the optimum for test 3.",
    "start": "546430",
    "end": "552052"
  },
  {
    "text": "Likewise for the other tasks,\nif you take a single gradient after task 2, you're\nquite far from the optimum and likewise for task 1.",
    "start": "552052",
    "end": "558100"
  },
  {
    "text": "Whereas by the time\nyou get to the end of the meta-training\nprocess, if you take a gradient step\nwith this vector task 3,",
    "start": "558100",
    "end": "563560"
  },
  {
    "text": "you're much closer and likewise\nfor all of the other tasks.",
    "start": "563560",
    "end": "568960"
  },
  {
    "text": "So this is a cartoon\ndiagram to give some intuition for what this\nmeta-training algorithm might",
    "start": "568960",
    "end": "575410"
  },
  {
    "text": "be doing.  So there's a question\nfrom the chat.",
    "start": "575410",
    "end": "582420"
  },
  {
    "text": "Won't we need to calculate the\ndouble derivatives of the loss for the optimization? Does this slow\ndown the algorithm?",
    "start": "582420",
    "end": "589690"
  },
  {
    "text": "Yes. We will have to compute\nthe second derivatives and we'll get to this on\nthe next slide basically.",
    "start": "589690",
    "end": "597225"
  },
  {
    "text": " Yeah. And then [AUDIO OUT]\nis asking, why do we only do one step\nof gradient descent",
    "start": "597225",
    "end": "603560"
  },
  {
    "text": "rather than multiple steps?  You can absolutely implement\nthis with multiple steps",
    "start": "603560",
    "end": "610062"
  },
  {
    "text": "and it's actually pretty\ncommon to implement it with multiple gradient steps. I'm writing it only is a\nsingle step here for now",
    "start": "610062",
    "end": "616310"
  },
  {
    "text": "because that's\nsimpler notationally. It takes a little\nbit more screen space to write down multiple steps.",
    "start": "616310",
    "end": "622490"
  },
  {
    "text": "If you want to do a very\nlarge number of gradient steps then, as I mentioned before,\nit gets very computationally",
    "start": "622490",
    "end": "627650"
  },
  {
    "text": "expensive and so typically\nyou will do around like five gradient steps or\nfewer than that, maybe 10.",
    "start": "627650",
    "end": "635810"
  },
  {
    "text": "There are some works that\ngo beyond that as well. But in practice you can\nget actually pretty far",
    "start": "635810",
    "end": "641060"
  },
  {
    "text": "with only a few gradient steps. ",
    "start": "641060",
    "end": "646280"
  },
  {
    "text": "Do you have a question? Yeah. So are you basically the\nway your train works are you",
    "start": "646280",
    "end": "653027"
  },
  {
    "text": "training to get\na set [INAUDIBLE] initialize or\ndirectly [INAUDIBLE] parameters given test task.",
    "start": "653027",
    "end": "659626"
  },
  {
    "text": " And then what do is you\nwant those parameters to be",
    "start": "659626",
    "end": "665450"
  },
  {
    "text": "so good that when\ninitializing them you can do-- they're just too\nshort optimization",
    "start": "665450",
    "end": "671780"
  },
  {
    "text": "and then get\n[INAUDIBLE] of theta? Yeah. Exactly.",
    "start": "671780",
    "end": "676880"
  },
  {
    "text": "The goal of theta\nis to basically find these other pre-trained\nparameters that are so good that even with\na few steps of gradient",
    "start": "676880",
    "end": "683120"
  },
  {
    "text": "descent on a small data\nset you can generalize well from those examples. ",
    "start": "683120",
    "end": "691141"
  },
  {
    "text": "[AUDIO OUT] is asking, do\nyou compute the gradient on batch or sample many batches?",
    "start": "691141",
    "end": "697260"
  },
  {
    "text": "Let's actually go to the\nnext slide to answer this.",
    "start": "697260",
    "end": "702810"
  },
  {
    "text": "This is what's called the\nmodel-agnostic meta-learning algorithm or MAML for short in\nthe sense that it's agnostic.",
    "start": "702810",
    "end": "710295"
  },
  {
    "text": "The model architecture\ndoesn't really play a role anywhere in here\nand so really any architecture",
    "start": "710295",
    "end": "715530"
  },
  {
    "text": "should be able to work for\nthis or any loss function as long as the architecture\nand the loss function",
    "start": "715530",
    "end": "720720"
  },
  {
    "text": "are amenable to this form of\ngradient-based optimization. So in terms of what this\nlooks like as an algorithm,",
    "start": "720720",
    "end": "728220"
  },
  {
    "text": "I talk to just\nabout the objective on the previous slides, how\ndo you actually optimize this subjective in an algorithm.",
    "start": "728220",
    "end": "734250"
  },
  {
    "text": "We can take the same algorithm\nfrom the black-box approach and there's just a few\nthings that we'll change. So first of all sample\nor mini batch of tasks.",
    "start": "734250",
    "end": "741779"
  },
  {
    "text": "We'll sample disjoint data\nsets, D train and D test. And then instead of\ncomputing the parameters",
    "start": "741780",
    "end": "749790"
  },
  {
    "text": "with this neural\nnetwork, we're instead going to compute these\nparameters by fine-tuning from our current\nmeta parameters.",
    "start": "749790",
    "end": "758070"
  },
  {
    "text": "And then when we\nupdate the model, we're going to use basically\nthe same update as before where",
    "start": "758070",
    "end": "766170"
  },
  {
    "text": "we're going to back-propagate\nthrough this fine-tuning process to the\ninitialization in order",
    "start": "766170",
    "end": "771899"
  },
  {
    "text": "to update our meta parameters. As was mentioned by\n[INAUDIBLE],, this actually",
    "start": "771900",
    "end": "778050"
  },
  {
    "text": "does bring up second\norder derivatives. And, I guess, I'll talk\nabout that in a second.",
    "start": "778050",
    "end": "787839"
  },
  {
    "text": "First, I want to\nanswer questions. What's your question?",
    "start": "787840",
    "end": "793080"
  },
  {
    "text": "Yeah. I think I'm still struggling\nto understand the intuition because what we are doing here\nis that we're taking the D",
    "start": "793080",
    "end": "801339"
  },
  {
    "text": "train for a task and even though\nwe take just small gradient steps, we are updating\nthe entirety, which",
    "start": "801340",
    "end": "809730"
  },
  {
    "text": "means like all the parameters. So why does it work like\nalways or in all cases,",
    "start": "809730",
    "end": "817230"
  },
  {
    "text": "isn't there a potential for\nsome large perturbations or because of some task?",
    "start": "817230",
    "end": "824630"
  },
  {
    "text": "Yeah. So I guess a few thoughts here. One is that this alpha\nparameter you could either",
    "start": "824630",
    "end": "832300"
  },
  {
    "text": "have it be a hyper,\nthis is a learning rate of the fine-tuning\nprocess you can either have it be a hyper-parameter\nor have it be learned.",
    "start": "832300",
    "end": "839410"
  },
  {
    "text": "Although in many cases,\nit's just a hyper-parameter and you can actually set this\nto be pretty large so that it's",
    "start": "839410",
    "end": "844720"
  },
  {
    "text": "actually taking pretty\nlarge gradient steps on your few-shot data set. Now, one thing you\nmight be worried about",
    "start": "844720",
    "end": "850720"
  },
  {
    "text": "is you might overfit to\nthis really small data set especially if you're\ntaking very large steps.",
    "start": "850720",
    "end": "856750"
  },
  {
    "text": "However, with this\noptimization, you're explicitly optimizing for\na point in the parameter",
    "start": "856750",
    "end": "862269"
  },
  {
    "text": "space that won't\nlead to overfitting when you take a few gradient\nsteps on a small data set.",
    "start": "862270",
    "end": "870589"
  },
  {
    "text": "So by nature of actually\noptimizing explicitly for the regional parameter\nspace that you're",
    "start": "870590",
    "end": "876920"
  },
  {
    "text": "in and for these\ninitial features you can avoid these\nproblems in principle.",
    "start": "876920",
    "end": "885820"
  },
  {
    "text": "Does that answer your question? Oh, yeah, I think that\nmakes sense to an extent.",
    "start": "885820",
    "end": "891250"
  },
  {
    "text": "But I'm just wondering that will\nthis not, like the prior task,",
    "start": "891250",
    "end": "897250"
  },
  {
    "text": "would we not lose\naccuracy on them as we start to do\nthis on future task?",
    "start": "897250",
    "end": "902485"
  },
  {
    "text": " Right. So when we do this on\nnew tasks at test time,",
    "start": "902485",
    "end": "909660"
  },
  {
    "text": "we need to assume that\nthose tasks are still somewhat similar to\nthe tasks that we saw during meta-training\nand specifically, they",
    "start": "909660",
    "end": "916200"
  },
  {
    "text": "need to be from the same\ndistribution as the tasks that we saw during\nmeta-training. And if we have enough\ntasks and the tasks",
    "start": "916200",
    "end": "923998"
  },
  {
    "text": "that we see at test time are\nin that same distribution, then we can expect it to\nwork well for those tasks. If you give it a completely\nunrelated to task that",
    "start": "923998",
    "end": "931020"
  },
  {
    "text": "isn't from that\ndistribution, then you may not expect it to\ngeneralize as well.",
    "start": "931020",
    "end": "937060"
  },
  {
    "text": "OK. Thanks. Great and then I\nalso saw that there was a question in the chat\nabout what is phi i again.",
    "start": "937060",
    "end": "944680"
  },
  {
    "text": "In this case, I'm\nusing phi i to denote just the fine-tuned parameters\nas a result of fine-tuning",
    "start": "944680",
    "end": "952870"
  },
  {
    "text": "from theta on the few-shot\ndata set Di train. On the previous side, I also had\na notation for phi i* and this",
    "start": "952870",
    "end": "963370"
  },
  {
    "text": "was the optimal parameter\nvectors for that task just",
    "start": "963370",
    "end": "969339"
  },
  {
    "text": "as an illustrative diagram. OK. Do you have a question?",
    "start": "969340",
    "end": "975510"
  },
  {
    "text": "Yes. I'm also having a bit of\ntrouble understanding phi i.",
    "start": "975510",
    "end": "981540"
  },
  {
    "text": "So phi i within step\n3 is a copy of theta and then we try to\noptimize that using test",
    "start": "981540",
    "end": "988590"
  },
  {
    "text": "and then optimize\nthe actual theta? Phi i is the result of running\ngradient descent on theta.",
    "start": "988590",
    "end": "997030"
  },
  {
    "start": "997030",
    "end": "1002630"
  },
  {
    "text": "Theta is your meta-parameter. It's the initial\nparameters that you're",
    "start": "1002630",
    "end": "1007850"
  },
  {
    "text": "learning throughout the\nmeta-training process and then phi i is the result of\ntaking multiple gradient steps",
    "start": "1007850",
    "end": "1015980"
  },
  {
    "text": "on theta starting from\ntheta on your training data set for that task. ",
    "start": "1015980",
    "end": "1023250"
  },
  {
    "text": "But we're updating\ntheta in step 4, right? So in step 3 we're\noptimizing a copy of theta?",
    "start": "1023250",
    "end": "1029510"
  },
  {
    "text": "Is that how to interpret that? Yeah. In step 3, you're\noptimizing a copy of theta and a question that was\nalso asked in the chat",
    "start": "1029510",
    "end": "1036750"
  },
  {
    "text": "is, do you reinitialize data\nfor each i, and that's correct. So we're always going to\nbe starting fine-tuning",
    "start": "1036750",
    "end": "1043170"
  },
  {
    "text": "from this set of initial\nparameters theta. We're not going to be\nstarting it from where we had fine-tuned to last.",
    "start": "1043170",
    "end": "1049574"
  },
  {
    "text": "OK. Makes sense. Great. ",
    "start": "1049574",
    "end": "1055429"
  },
  {
    "text": "Yes. The training data\nhere refers to samples from multiple tasks\nand not a single task?",
    "start": "1055430",
    "end": "1064530"
  },
  {
    "text": "So D train i corresponds\nto the training data for a single task. So you sample a\ntask here, then you",
    "start": "1064530",
    "end": "1073430"
  },
  {
    "text": "split the data for that task\nand do a train set and the test set. These are both\nfrom the same task.",
    "start": "1073430",
    "end": "1080990"
  },
  {
    "text": "Then you run fine-tuning on\ndata from that task and measure how well the fine-tuned\nparameters generalize",
    "start": "1080990",
    "end": "1088280"
  },
  {
    "text": "to new data from\nthat task and then you update your meta-parameters. [INTERPOSING VOICES]",
    "start": "1088280",
    "end": "1094130"
  },
  {
    "text": "Mini batch of tasks as well.  I'm just trying\nto understand how",
    "start": "1094130",
    "end": "1099490"
  },
  {
    "text": "is this different from\nlet's say transfer learning where you\nwould train, you",
    "start": "1099490",
    "end": "1104790"
  },
  {
    "text": "taken model grade on\nimage net and fine-tune it for some other task?",
    "start": "1104790",
    "end": "1110910"
  },
  {
    "text": "Yeah. The way that this is\ndifferent from transferring and fine-tuning is that\nin transfer learning",
    "start": "1110910",
    "end": "1118200"
  },
  {
    "text": "and fine-tuning, you\noptimize your data, your initial parameters\nby training directly",
    "start": "1118200",
    "end": "1124620"
  },
  {
    "text": "on a previous task or\nprevious set of tasks, basically trying to, let's see,\nso what transfer learning would",
    "start": "1124620",
    "end": "1139650"
  },
  {
    "text": "try to do is it would say\ntheta init equals basically",
    "start": "1139650",
    "end": "1148110"
  },
  {
    "text": "min of theta of L of theta Di.",
    "start": "1148110",
    "end": "1155960"
  },
  {
    "start": "1155960",
    "end": "1161309"
  },
  {
    "text": "This is what transfer learning. I'll call it TL. Basically, it's going to try\nto find initial parameters such",
    "start": "1161310",
    "end": "1167010"
  },
  {
    "text": "that you minimize your loss\non your set of training tasks and then at test time, you\nfine-tune this theta init",
    "start": "1167010",
    "end": "1174640"
  },
  {
    "text": "on other things. And then what this is doing,\nwhich is a bit different,",
    "start": "1174640",
    "end": "1180750"
  },
  {
    "text": "is it's learning a set\nof initial parameters such that optimize over tasks.",
    "start": "1180750",
    "end": "1191210"
  },
  {
    "text": "Basically, you just\nreplace theta with phi i.",
    "start": "1191210",
    "end": "1198059"
  },
  {
    "text": "And this is on the\ntest set for test i where phi i equals the\nfine-tuned version of this.",
    "start": "1198060",
    "end": "1214250"
  },
  {
    "text": "So the key difference\nis that in transferring, you basically be optimizing just\nso that theta does well and all",
    "start": "1214250",
    "end": "1221509"
  },
  {
    "text": "of your tasks and what this\nis doing it is optimizing such that when you\nfine-tune from theta",
    "start": "1221510",
    "end": "1227420"
  },
  {
    "text": "you do well on your tasks. Does that answer your question?",
    "start": "1227420",
    "end": "1233544"
  },
  {
    "text": "Yeah, it does. Thanks. Great. ",
    "start": "1233544",
    "end": "1239870"
  },
  {
    "text": "Hi, yeah. This might be something\nyou're going to address later in the lecture,\nbut I was wondering if there were any theoretical\nguarantees of, I guess,",
    "start": "1239870",
    "end": "1248600"
  },
  {
    "text": "optimization or this\napproach in general. Yeah. We'll talk a bit\nabout theoretically",
    "start": "1248600",
    "end": "1254290"
  },
  {
    "text": "what the expressive power\nof this meta-learning is. There is also some\nwork saying basically",
    "start": "1254290",
    "end": "1260980"
  },
  {
    "text": "the theoretical\nguarantees of whether this meta-learning process will\nactually give you the optimum.",
    "start": "1260980",
    "end": "1270009"
  },
  {
    "text": "And I won't actually\ncover that in the lecture, but if you're interested in\nthat maybe make a post on Piazza",
    "start": "1270010",
    "end": "1275380"
  },
  {
    "text": "and I can send some\nfiner references. OK. Thank you. ",
    "start": "1275380",
    "end": "1283820"
  },
  {
    "text": "So my question is\nlike, in step three, we are learning this\ntask-specific parameter.",
    "start": "1283820",
    "end": "1288860"
  },
  {
    "text": "But if [INAUDIBLE] all tasks.",
    "start": "1288860",
    "end": "1294250"
  },
  {
    "text": "So when we're doing step\nfour, the gradient loss, again, with the\n[INAUDIBLE] task phi i,",
    "start": "1294250",
    "end": "1301300"
  },
  {
    "text": "how many gradient steps\nwould lead to [INAUDIBLE] one gradient step, right? So when we do the [INAUDIBLE]--",
    "start": "1301300",
    "end": "1307550"
  },
  {
    "text": "Yeah. So when we update it using it-- in this fourth step, when we're\nupdating the meta-parameters,",
    "start": "1307550",
    "end": "1314020"
  },
  {
    "text": "typically you just run one\ngradient step on theta. And in order to compute\nthis gradient right here,",
    "start": "1314020",
    "end": "1322570"
  },
  {
    "text": "you need a kind\nof a prerequisite. You'd need to compute phi i. So you basically alternate\nbetween computing phi i",
    "start": "1322570",
    "end": "1328680"
  },
  {
    "text": "and then computing the gradient\nof your meta-parameters. Basically, most definitely\nwe need one gradient step.",
    "start": "1328680",
    "end": "1334170"
  },
  {
    "text": "One is for this\n[INAUDIBLE] without a loss in the step four?",
    "start": "1334170",
    "end": "1340790"
  },
  {
    "text": "Yes. Although, here you\ncould also run-- it's pretty common to also\nrun more than one gradient",
    "start": "1340790",
    "end": "1346870"
  },
  {
    "text": "step for this one. This can be a few\ngradient steps. Here, you really want this to\nbe just a single gradient step,",
    "start": "1346870",
    "end": "1353770"
  },
  {
    "text": "because it's only pertinent\nto this value of phi i.",
    "start": "1353770",
    "end": "1358790"
  },
  {
    "text": "Thank you. ",
    "start": "1358790",
    "end": "1364438"
  },
  {
    "text": "I just want to check that\ndetails between these three algorithms.",
    "start": "1364438",
    "end": "1369510"
  },
  {
    "text": "So in black box\napproach, you have to initialize your [INAUDIBLE]\nwith your learned [INAUDIBLE]",
    "start": "1369510",
    "end": "1377766"
  },
  {
    "text": "without doing any\nof the [INAUDIBLE]",
    "start": "1377766",
    "end": "1382830"
  },
  {
    "text": "to compute the loss\nof a task [INAUDIBLE]??",
    "start": "1382830",
    "end": "1388100"
  },
  {
    "text": "And so after the [INAUDIBLE]\nafter you [INAUDIBLE]..",
    "start": "1388100",
    "end": "1393730"
  },
  {
    "text": "And in the\noptimization-based approach, you add additional\nfreedom [INAUDIBLE]",
    "start": "1393730",
    "end": "1400270"
  },
  {
    "text": "to the initialized [INAUDIBLE].",
    "start": "1400270",
    "end": "1405380"
  },
  {
    "text": "So-- [INAUDIBLE] That's close. So the black box model\nthat's shown right here,",
    "start": "1405380",
    "end": "1416340"
  },
  {
    "text": "this is kind of having a neural\nnetwork basically represent",
    "start": "1416340",
    "end": "1421350"
  },
  {
    "text": "the organization itself. It's outputting phi i directly. Whereas in the\noptimization-based approach,",
    "start": "1421350",
    "end": "1428790"
  },
  {
    "text": "the meta-parameters correspond\nto the initialization. And to get phi i, the\ntask-specific parameters,",
    "start": "1428790",
    "end": "1434880"
  },
  {
    "text": "you are running an optimization. Oh, so the-- So there's kind of no\noptimization that happens,",
    "start": "1434880",
    "end": "1441780"
  },
  {
    "text": "you just run-- you just take your neural\nnetwork and run it forward. Whereas in the\noptimization-based meta-learner",
    "start": "1441780",
    "end": "1447690"
  },
  {
    "text": "you're running\nthis optimization. Thank you. [INAUDIBLE] in the black box\napproach, [INAUDIBLE] MAML",
    "start": "1447690",
    "end": "1455559"
  },
  {
    "text": "[INAUDIBLE] the parameter\nof your actual network. And in the optimization-based\napproach, it [INAUDIBLE]",
    "start": "1455560",
    "end": "1461315"
  },
  {
    "text": "gradients you want\nto [INAUDIBLE] in your actual network. Basically yes.",
    "start": "1461315",
    "end": "1467070"
  },
  {
    "text": "Although, in the\noptimization-based approach, basically you're-- in\nthis case, you're just-- you're optimizing the\ninitial parameters.",
    "start": "1467070",
    "end": "1472920"
  },
  {
    "text": "And then the way that\nyou get the gradients are by taking the actual gradient. ",
    "start": "1472920",
    "end": "1482584"
  },
  {
    "text": "[INAUDIBLE] more about this. Yeah, but thank you. Cool. ",
    "start": "1482584",
    "end": "1489252"
  },
  {
    "text": "Yeah, I had a question\nlike, how is it different from [INAUDIBLE]\nbased approach, since the [INAUDIBLE]\nwe are setting",
    "start": "1489252",
    "end": "1495670"
  },
  {
    "text": "phi i, as a function of theta\nand d theta, [INAUDIBLE] also like phi i is a function of\ntheta and d theta in some way,",
    "start": "1495670",
    "end": "1504184"
  },
  {
    "text": "right? Yeah. So they're both-- they're both\nkind of a function of theta and the training data.",
    "start": "1504184",
    "end": "1510620"
  },
  {
    "text": "One is that one of them is using\na neural network to produce phi i, and one of them\nis using an optimization",
    "start": "1510620",
    "end": "1516039"
  },
  {
    "text": "to produce phi i.  OK.",
    "start": "1516040",
    "end": "1521157"
  },
  {
    "text": "Thanks.  Yeah, I was\nwondering [INAUDIBLE]",
    "start": "1521157",
    "end": "1527424"
  },
  {
    "text": "the second-order derivatives,\nI was trying to think through if you have multiple\ngradient steps on step three,",
    "start": "1527424",
    "end": "1533769"
  },
  {
    "text": "would that keep nesting and get\nlike higher and higher order derivatives? Or I might be picturing\nsomething wrong with that.",
    "start": "1533770",
    "end": "1540409"
  },
  {
    "text": "Yeah, that's a great question. And I was actually paid\nto talk about that next. So let's actually\ntalk about that.",
    "start": "1540410",
    "end": "1545909"
  },
  {
    "text": "So there's two questions\nthat come up here. One is, we have\nsecond-order derivatives, does that mean that we need\nto compute the full Hessian?",
    "start": "1545910",
    "end": "1554389"
  },
  {
    "text": "And if we did, that would\nbe a pretty big problem, because if we have a really\nhuge vector of parameters, then",
    "start": "1554390",
    "end": "1560029"
  },
  {
    "text": "the Hessian is going\nto be a matrix that has a dimensionality of\nthe size of your parameters",
    "start": "1560030",
    "end": "1566060"
  },
  {
    "text": "by the size your parameters. And the second is\nthat if we take more than one inner\ngradient step here,",
    "start": "1566060",
    "end": "1572630"
  },
  {
    "text": "do we actually have third- and\nfourth-order derivatives when you take more inner\ngradient steps.",
    "start": "1572630",
    "end": "1579000"
  },
  {
    "text": "Does anyone have any\nguesses as to the answer to these questions before I kind\nof go through some of the math?",
    "start": "1579000",
    "end": "1586310"
  },
  {
    "start": "1586310",
    "end": "1599807"
  },
  {
    "text": "So there's one guess,\nwhich is that maybe we only need the diagonal\nof the Hessian, which isn't quite correct.",
    "start": "1599807",
    "end": "1606390"
  },
  {
    "text": "Yeah. So [AUDIO OUT]\nsays maybe we only have to compute the Hessian\nvector products, which will turn out to be correct.",
    "start": "1606390",
    "end": "1611577"
  },
  {
    "text": "And we'll go through\nwhy that's the case. So as we talked about before,\nwe can basically view--",
    "start": "1611577",
    "end": "1622020"
  },
  {
    "text": " we have this kind\nof update procedure",
    "start": "1622020",
    "end": "1627549"
  },
  {
    "text": "that takes as input a set of\nparameters and a training data",
    "start": "1627550",
    "end": "1633150"
  },
  {
    "text": "set. And in the MAML case,\nthis update procedure might be something like\none gradient descent",
    "start": "1633150",
    "end": "1640440"
  },
  {
    "text": "step on your\ntraining law starting from your meta-trained\nparameters.",
    "start": "1640440",
    "end": "1647070"
  },
  {
    "text": "And it can also be multiple\ninner gradient steps. But we'll start with\nthe case where it's just",
    "start": "1647070",
    "end": "1653110"
  },
  {
    "text": "one inner gradient step. And then our meta-objective\nis something like--",
    "start": "1653110",
    "end": "1664500"
  },
  {
    "text": "sorry, I'm going to\nwrite this in my lap.",
    "start": "1664500",
    "end": "1670040"
  },
  {
    "text": "So the meta-objective is\nsomething like min over theta of L of phi i comma D--",
    "start": "1670040",
    "end": "1679100"
  },
  {
    "text": "or sorry, this is D test i. So this is our kind of\nthe objective with regard",
    "start": "1679100",
    "end": "1685730"
  },
  {
    "text": "to our meta-parameters theta. And this is equal to the min\nover theta of L of f theta D",
    "start": "1685730",
    "end": "1698450"
  },
  {
    "text": "trained i comma D test i.",
    "start": "1698450",
    "end": "1704029"
  },
  {
    "text": "And I'm just using\nf here as shorthand for the gradient step.",
    "start": "1704030",
    "end": "1709280"
  },
  {
    "text": "It's going to be helpful\nto have that shorthand for the next step.",
    "start": "1709280",
    "end": "1715480"
  },
  {
    "text": "So in order to optimize\nthis meta-objective,",
    "start": "1715480",
    "end": "1720919"
  },
  {
    "text": "what does our\nmeta-optimization look like? So you want to compute\nthe gradient with regard to our parameters theta in order\nto optimize this objective.",
    "start": "1720920",
    "end": "1730440"
  },
  {
    "text": "One side note is\nthat I'm going to use d dx or whatever as to\nbe the total derivative",
    "start": "1730440",
    "end": "1741320"
  },
  {
    "text": "and the gradient with regard\nto x as the partial derivative,",
    "start": "1741320",
    "end": "1747649"
  },
  {
    "text": "just so it's kind of-- to be able to split\napart the notation. So in order to do this\nmeta-optimization,",
    "start": "1747650",
    "end": "1754549"
  },
  {
    "text": "we need to compute the\nderivative of our objective.",
    "start": "1754550",
    "end": "1760670"
  },
  {
    "text": " And so the first\nquestion is, do we",
    "start": "1760670",
    "end": "1765840"
  },
  {
    "text": "have to compute the\nfull Hessian in order to compute this derivative? Do we have to actually\nconstruct the entire Hessian?",
    "start": "1765840",
    "end": "1772650"
  },
  {
    "text": "Or do we only need\nHessian vector products? So to do that, we'll\nexpand out what",
    "start": "1772650",
    "end": "1778140"
  },
  {
    "text": "this derivative looks like. So to do that, we can\nfirst take the chain rule",
    "start": "1778140",
    "end": "1783960"
  },
  {
    "text": "and say this derivative\nis equal to the gradient",
    "start": "1783960",
    "end": "1790440"
  },
  {
    "text": "of this loss with respect to phi\ni times the derivative of phi i",
    "start": "1790440",
    "end": "1797940"
  },
  {
    "text": "with respect to theta. So this is equal to first\nthe partial derivative",
    "start": "1797940",
    "end": "1812950"
  },
  {
    "text": "of phi bar evaluated at\nphi bar equals phi i,",
    "start": "1812950",
    "end": "1821380"
  },
  {
    "text": "where this equals f of\ntheta comma D trained.",
    "start": "1821380",
    "end": "1826963"
  },
  {
    "text": "So this is the derivative of the\nfirst term, which is the vector phi i, and then we also\nwill have a term that",
    "start": "1826963",
    "end": "1832270"
  },
  {
    "text": "looks like d phi i d theta. ",
    "start": "1832270",
    "end": "1839730"
  },
  {
    "text": "Cool? So this is the first kind of\nexpansion of the gradient. Now, if we want to consider\nwhat these two terms look like,",
    "start": "1839730",
    "end": "1847460"
  },
  {
    "text": "this first term is going\nto be a row vector, because L is a scalar function.",
    "start": "1847460",
    "end": "1855690"
  },
  {
    "text": "And then the second term\nis going to be a matrix.",
    "start": "1855690",
    "end": "1860745"
  },
  {
    "text": " And basically, the way that\nyou get this row vector is,",
    "start": "1860745",
    "end": "1865990"
  },
  {
    "text": "you can get this row\nvector just by taking a single backward pass\nthrough the network. So you just evaluate\nthe loss at phi i,",
    "start": "1865990",
    "end": "1873370"
  },
  {
    "text": "and then run a backward pass\nto get the gradient at phi i. So this is basically just\nlike one backward pass.",
    "start": "1873370",
    "end": "1881310"
  },
  {
    "text": "Now, what about the second term? So maybe we'll just separately\nlooking at this second term.",
    "start": "1881310",
    "end": "1888809"
  },
  {
    "text": " So the second term is--",
    "start": "1888810",
    "end": "1895600"
  },
  {
    "text": "so we know that phi i is\nequal to one gradient step.",
    "start": "1895600",
    "end": "1902539"
  },
  {
    "text": " And so if we want to compute the\nderivative of the second term",
    "start": "1902540",
    "end": "1909150"
  },
  {
    "text": "with respect to theta, what\nwe're going to get is d phi i d theta equals\nthe identity--",
    "start": "1909150",
    "end": "1918810"
  },
  {
    "text": "oh, sorry. I should have-- this\nshould actually technically",
    "start": "1918810",
    "end": "1924880"
  },
  {
    "text": "be a total derivative. What we'll get is something like\nthe identity minus alpha times",
    "start": "1924880",
    "end": "1933030"
  },
  {
    "text": "d squared d theta squared\nof L of theta D trained.",
    "start": "1933030",
    "end": "1939460"
  },
  {
    "text": "So this term right here,\nthis is the Hessian, right? ",
    "start": "1939460",
    "end": "1944960"
  },
  {
    "text": "Let's call this H. And let's\ncall this row vector r.",
    "start": "1944960",
    "end": "1952740"
  },
  {
    "text": "Then what we get is that this,\nthe gradient with respect to theta, is equal to r\ntimes identity minus alpha",
    "start": "1952740",
    "end": "1967679"
  },
  {
    "text": "r times the Hessian. And so the way that\nwe got that is we just",
    "start": "1967680",
    "end": "1972750"
  },
  {
    "text": "basically plugged in this term\nin for the matrix right here.",
    "start": "1972750",
    "end": "1979450"
  },
  {
    "text": "And we get this. And the result of this is\nthat this means that we only have to do the Hessian vector\nproduct between the row",
    "start": "1979450",
    "end": "1986310"
  },
  {
    "text": "vector and the\nHessian, and we don't need to worry about actually\ncomputing the full Hessian. ",
    "start": "1986310",
    "end": "1994600"
  },
  {
    "text": "OK. Any questions on that? ",
    "start": "1994600",
    "end": "2001400"
  },
  {
    "text": "Do you have a question on this? [INAUDIBLE] ",
    "start": "2001400",
    "end": "2010050"
  },
  {
    "text": "Hi, so why is it the case that-- why do you [INAUDIBLE]\nyou just have",
    "start": "2010050",
    "end": "2015606"
  },
  {
    "text": "to [INAUDIBLE] the product? Because don't you\n[INAUDIBLE] isn't the way to get the product by\nfirst finding the matrix",
    "start": "2015606",
    "end": "2022343"
  },
  {
    "text": "and then doing the\n[INAUDIBLE] multiplication? Like, how would you\navoid [INAUDIBLE]??",
    "start": "2022343",
    "end": "2028049"
  },
  {
    "text": "Yeah. So there are efficient ways to\ncompute Hessian vector products without having to\nconstruct the full Hessian.",
    "start": "2028050",
    "end": "2036890"
  },
  {
    "text": "I guess I don't want to\nget into that too much. But to kind of--",
    "start": "2036890",
    "end": "2041920"
  },
  {
    "text": "the main takeaway is\nthat there are basically ways to compute this Hessian\nvector product without actually",
    "start": "2041920",
    "end": "2048440"
  },
  {
    "text": "having to construct the\nfull Hessian in memory.",
    "start": "2048440",
    "end": "2053449"
  },
  {
    "text": "Yeah. And if you're interested\nin kind of learning more about some of those\ntechniques, then we could also post some\nresources on [INAUDIBLE]..",
    "start": "2053449",
    "end": "2060329"
  },
  {
    "text": "It's also possible\nthat Matt Johnson will go into some\nof those techniques",
    "start": "2060330",
    "end": "2065629"
  },
  {
    "text": "in the lecture on Monday.  OK. And then there's one\nmore thing that we",
    "start": "2065630",
    "end": "2071804"
  },
  {
    "text": "talked about before, which\nis, you're wondering, if we take more than\none inner gradient step,",
    "start": "2071804",
    "end": "2081800"
  },
  {
    "text": "do we get third-order derivative\nand fourth-order derivatives? So this is kind of\na simple extension",
    "start": "2081800",
    "end": "2088029"
  },
  {
    "text": "on top of what we just showed. So instead of saying that phi i\nequals one gradient step, if we",
    "start": "2088030",
    "end": "2096860"
  },
  {
    "text": "say that phi i equals\ntwo gradient steps, then equals theta minus alpha\ngrad theta L of D trained.",
    "start": "2096860",
    "end": "2106542"
  },
  {
    "text": "And then when we take\nthe second gradient step, we're going to take\nthat second gradient step starting from the result\nof this first gradient step.",
    "start": "2106542",
    "end": "2113340"
  },
  {
    "text": "So we'll call this theta prime. And then the next\ngradient step will be at theta prime L of\ntheta prime D trained.",
    "start": "2113340",
    "end": "2125640"
  },
  {
    "text": "So this is what phi i\nequals to if we have--",
    "start": "2125640",
    "end": "2132732"
  },
  {
    "text": "if we run two gradient steps. And what we get, if we want\nto compute, basically--",
    "start": "2132732",
    "end": "2143150"
  },
  {
    "text": "so the place where the Hessian\ncomes into, again, here is this matrix right here.",
    "start": "2143150",
    "end": "2148710"
  },
  {
    "text": "And so what we're\ninterested in is if you compute d phi d theta,\ndoes this give us the Hessian,",
    "start": "2148710",
    "end": "2156000"
  },
  {
    "text": "or does this give us\nhigher order terms? So what you get is if you\ntake this phi i on the left",
    "start": "2156000",
    "end": "2162900"
  },
  {
    "text": "and we compute the derivative\nwith respect to theta, then you get something\nlike the identity matrix",
    "start": "2162900",
    "end": "2169800"
  },
  {
    "text": "for theta minus alpha times the\nHessian, what you had before,",
    "start": "2169800",
    "end": "2181100"
  },
  {
    "text": "L theta D trained. And then we-- for the second\nterm, we get minus alpha.",
    "start": "2181100",
    "end": "2187715"
  },
  {
    "text": " And then we actually\nget-- so we're-- in this case, we're taking\nthe derivative of this term",
    "start": "2187715",
    "end": "2195559"
  },
  {
    "text": "evaluated at theta. And so we're going to need to\napply the chain rule again.",
    "start": "2195560",
    "end": "2201110"
  },
  {
    "text": "And what you get\nif you do this is you get another\nsecond derivative,",
    "start": "2201110",
    "end": "2208010"
  },
  {
    "text": "this time actually at theta\nprime of L of theta prime D",
    "start": "2208010",
    "end": "2218090"
  },
  {
    "text": "trained evaluated at theta prime\ntimes d theta prime d theta.",
    "start": "2218090",
    "end": "2228290"
  },
  {
    "text": "So the main takeaway\nhere is that basically, even if you have two inner\ngradient steps, the highest",
    "start": "2228290",
    "end": "2235329"
  },
  {
    "text": "order term that you\nget is still only going to be second derivatives. And the key idea is that the--",
    "start": "2235330",
    "end": "2244345"
  },
  {
    "text": "the key idea is, the\nreason why this is the case is that when you take the\nsecond inner gradient step,",
    "start": "2244345",
    "end": "2249430"
  },
  {
    "text": "you take it at theta\nprime, not at theta. If you were taking it at\ntheta, then you would go--",
    "start": "2249430",
    "end": "2256869"
  },
  {
    "text": "then, basically, these\nterms would combine. But because we're taking\nit at theta prime,",
    "start": "2256870",
    "end": "2262790"
  },
  {
    "text": "we basically we will not\nget higher-order gradients.",
    "start": "2262790",
    "end": "2269300"
  },
  {
    "text": "Yeah, and [AUDIO OUT]\nasking, is it typical to take multiple\ngradient steps on the D trained?",
    "start": "2269300",
    "end": "2275113"
  },
  {
    "text": "So one thing you\ncould do here is, instead of running basically\nbatch gradient descent on your small training\nset, you could",
    "start": "2275113",
    "end": "2280232"
  },
  {
    "text": "run SGD, where you\nbasically run one gradient stuff on the first data\npoint, one gradient",
    "start": "2280232",
    "end": "2285255"
  },
  {
    "text": "step on the second data\npoint, and so forth. When we're in the\nfew-shot learning setting, you typically will--",
    "start": "2285255",
    "end": "2292730"
  },
  {
    "text": "typically breaking up the data-- this small data set that you\nhave into even finer data sets",
    "start": "2292730",
    "end": "2297830"
  },
  {
    "text": "will lead to fairly\nhigh variance gradients. And so typically, at\nleast in my experience,",
    "start": "2297830",
    "end": "2304010"
  },
  {
    "text": "I found it most helpful to\nrun multiple gradient steps on the same training data\nset so that you get the least",
    "start": "2304010",
    "end": "2311060"
  },
  {
    "text": "noise in your gradient. ",
    "start": "2311060",
    "end": "2317819"
  },
  {
    "text": "OK. Any questions on that? There's actually one more\nquestion from [AUDIO OUT]",
    "start": "2317820",
    "end": "2324420"
  },
  {
    "text": "about how do we get d\ntheta prime d theta? That's basically the\ncomputation that we did up here.",
    "start": "2324420",
    "end": "2334500"
  },
  {
    "text": "It's, yeah, the same\nas that computation. ",
    "start": "2334500",
    "end": "2340651"
  },
  {
    "text": "[AUDIO OUT] is asking, are these\nhigher order differentiation supported by deep\nlearning frameworks?",
    "start": "2340652",
    "end": "2345880"
  },
  {
    "text": "Yes. So both TensorFlow\nand PyTorch and DAX",
    "start": "2345880",
    "end": "2351450"
  },
  {
    "text": "support these\nsecond-order, taking basically second derivatives\nwith regard to your network.",
    "start": "2351450",
    "end": "2357089"
  },
  {
    "text": " Yeah. Some-- especially\nTensorFlow, especially",
    "start": "2357090",
    "end": "2362450"
  },
  {
    "text": "the more developed ones. In the past, some of them\nhave been a little bit",
    "start": "2362450",
    "end": "2367792"
  },
  {
    "text": "shakier with regard\nto second derivative. But I think that both of those--\nboth TensorFlow and PyTorch are developed enough to support\nthese and basically compute",
    "start": "2367792",
    "end": "2376100"
  },
  {
    "text": "all these derivatives for you. This is mostly just an exercise\nto understand exactly what's happening under the hood.",
    "start": "2376100",
    "end": "2381895"
  },
  {
    "text": "When you actually go about\nimplementing these algorithms, you don't actually have to\nunderstand these calculations,",
    "start": "2381895",
    "end": "2387980"
  },
  {
    "text": "for better or for worse. I still think it's helpful\nto understand them, to know that you don't have\nto compute this full Hessian,",
    "start": "2387980",
    "end": "2393680"
  },
  {
    "text": "and to know that you don't\nget third-order derivatives. But in practice, it's\nactually fairly convenient",
    "start": "2393680",
    "end": "2399890"
  },
  {
    "text": "that you don't have to worry\nabout actually computing these manually if you're\nimplementing them. ",
    "start": "2399890",
    "end": "2408710"
  },
  {
    "text": "OK. So that's the gist\nof optimization-based",
    "start": "2408710",
    "end": "2414619"
  },
  {
    "text": "meta-learning. So now let's talk a bit\nabout how optimization-based",
    "start": "2414620",
    "end": "2422350"
  },
  {
    "text": "meta-learners and black\nbox meta-learners are-- how they kind of\ncompare conceptually,",
    "start": "2422350",
    "end": "2428010"
  },
  {
    "text": "what are the benefits\nof one versus the other. So in black box\nadaptation, there's",
    "start": "2428010",
    "end": "2435280"
  },
  {
    "text": "this general form of basically\nhaving a neural network, take as input a training set,\nand maybe also a test input,",
    "start": "2435280",
    "end": "2442780"
  },
  {
    "text": "and produce an output. And maybe somewhere\nin the middle here, you may also have some phi i.",
    "start": "2442780",
    "end": "2451990"
  },
  {
    "text": "Or you can abstract that away. Now, in model-agnostic\nmeta-learning,",
    "start": "2451990",
    "end": "2458405"
  },
  {
    "text": "you can actually also view\nthe same kind of general form,",
    "start": "2458405",
    "end": "2463550"
  },
  {
    "text": "but where you have\nthis phi i that is computed with\ngradient descent,",
    "start": "2463550",
    "end": "2470620"
  },
  {
    "text": "and then you process your\ntest input with that network. So in some ways,\nactually, MAML can",
    "start": "2470620",
    "end": "2476630"
  },
  {
    "text": "be viewed as the same sort\nof computation graph, where you're taking as input a trained\ndata set and a test input.",
    "start": "2476630",
    "end": "2484599"
  },
  {
    "text": "But there's this\ngradient operator that's embedded inside\nthat computation graph.",
    "start": "2484600",
    "end": "2490410"
  },
  {
    "text": "And I think that the view is\nuseful for thinking about how these two methods compare.",
    "start": "2490410",
    "end": "2495560"
  },
  {
    "text": "In many ways, they're\nboth optimized for doing the same exact thing. It's just that MAML has the\nstructure of an optimization",
    "start": "2495560",
    "end": "2502430"
  },
  {
    "text": "built inside of it,\nso that you can expect it to essentially still\ndescend on the objective",
    "start": "2502430",
    "end": "2510200"
  },
  {
    "text": "that you care about, at least\non the trained data set. Now, it's worth noting that you\ncan mix and match components",
    "start": "2510200",
    "end": "2516400"
  },
  {
    "text": "of this computation graph. And this view of things is\nhelpful for understanding",
    "start": "2516400",
    "end": "2522520"
  },
  {
    "text": "how you might do that. So one thing that you\ncould do, for example, is you could learn\nthe initialization,",
    "start": "2522520",
    "end": "2529300"
  },
  {
    "text": "and you could also, instead\nof using the actual gradient, you could replace the gradient\nupdate with a large network.",
    "start": "2529300",
    "end": "2536349"
  },
  {
    "text": "That looks something like\nthis, where you learn theta, and you also learn\nthis network that",
    "start": "2536350",
    "end": "2541480"
  },
  {
    "text": "takes as input the gradient\nand modifies it in some way. This is done in this paper by\nSachin Ravi and Hugo Larochelle",
    "start": "2541480",
    "end": "2548380"
  },
  {
    "text": "in 2017. It actually precedes the MAML\nalgorithm that we covered.",
    "start": "2548380",
    "end": "2555829"
  },
  {
    "text": "And also, this computation\ngraph view of meta-learning will come back again in\na couple of lectures,",
    "start": "2555830",
    "end": "2561380"
  },
  {
    "text": "when we are also\ncomparing and thinking about a third kind of\nmeta-learning algorithm. ",
    "start": "2561380",
    "end": "2569260"
  },
  {
    "text": "Now, one thing\nthat's maybe worth thinking about in terms of\nmeta-learning algorithms, is how these methods\nmight do if you're",
    "start": "2569260",
    "end": "2577150"
  },
  {
    "text": "on tasks that are a\nbit different from what you saw during training.",
    "start": "2577150",
    "end": "2582359"
  },
  {
    "text": "So if you're given a task that's\nkind of out of distribution from what you saw during\nthe meta-training process,",
    "start": "2582360",
    "end": "2590730"
  },
  {
    "text": "MAML will still be\nrunning fine tuning or be running gradient\ndescent on that held-out task.",
    "start": "2590730",
    "end": "2597220"
  },
  {
    "text": "And so we can expect these\nto be something reasonable when provided this\nout-of-distribution data.",
    "start": "2597220",
    "end": "2603870"
  },
  {
    "text": "Whereas if you feed that\nout-of-distribution data into the black box neural\nnetwork, you can't really--",
    "start": "2603870",
    "end": "2609277"
  },
  {
    "text": "you don't really know exactly\nwhat it will do with that data. It might not generalize well. We can actually\nempirically consider",
    "start": "2609278",
    "end": "2617370"
  },
  {
    "text": "this exercise of looking\nat how these methods do on extrapolating tasks.",
    "start": "2617370",
    "end": "2622770"
  },
  {
    "text": "And what we'll do is\nwe'll compare MAML to two forms of black\nbox meta-learners. One is called SNAIL and\none is called MetaNetworks.",
    "start": "2622770",
    "end": "2631117"
  },
  {
    "text": "They're basically\njust different kinds of memory-based neural\nnetworks that process data with a single network.",
    "start": "2631117",
    "end": "2636930"
  },
  {
    "text": " And if you look at the omniglot\ntask, and we'll construct the--",
    "start": "2636930",
    "end": "2643500"
  },
  {
    "text": "we'll construct different\ntasks, and we'll construct actually\nout-of-distribution tasks by skewing the digits, and\nalso by scaling the digits.",
    "start": "2643500",
    "end": "2653750"
  },
  {
    "text": "And what we find is on\neach of these cases, we're looking at the\nperformance as you move away",
    "start": "2653750",
    "end": "2658970"
  },
  {
    "text": "from the distribution\nthat these are trained on. Of course, as you move from--",
    "start": "2658970",
    "end": "2664345"
  },
  {
    "text": "all these algorithms\nwere kind of trained on this distribution. And they all do pretty\nwell when you are testing",
    "start": "2664345",
    "end": "2671660"
  },
  {
    "text": "on what they're trained on. But when you move away\nfrom the manifold of tasks",
    "start": "2671660",
    "end": "2677180"
  },
  {
    "text": "than what they were trained\non, you see that all of them degree. But we see that MAML degrades\nthe least out of the three",
    "start": "2677180",
    "end": "2686780"
  },
  {
    "text": "methods. And this is kind of\nwhat we'd expect, because we're fine-tuning\non these out-of-distribution",
    "start": "2686780",
    "end": "2692300"
  },
  {
    "text": "tasks, you can still expect\nthem to do something reasonable when you're\nfine-tuning, in contrast with passing these\nout-of-distribution data",
    "start": "2692300",
    "end": "2698869"
  },
  {
    "text": "points into a black\nbox neural network. ",
    "start": "2698870",
    "end": "2705300"
  },
  {
    "text": "OK. Any questions on\nthis experiment? ",
    "start": "2705300",
    "end": "2718060"
  },
  {
    "text": "To clarify one-shot, do\nyou mean that you're just doing one gradient step\nupdate to get phi from theta?",
    "start": "2718060",
    "end": "2724260"
  },
  {
    "text": " I actually can't remember how\nmany gradient steps were used.",
    "start": "2724260",
    "end": "2730150"
  },
  {
    "text": "By one-shot learning, I mean\nthat there's one example for-- ",
    "start": "2730150",
    "end": "2735810"
  },
  {
    "text": "sorry, yeah, one example per\nclass in the classification process. Got it. Cool. Thanks. ",
    "start": "2735810",
    "end": "2743526"
  },
  {
    "text": "I was wondering where\n[INAUDIBLE] process, we pass in the\n[INAUDIBLE] process",
    "start": "2743526",
    "end": "2751049"
  },
  {
    "text": "and pass in the data [INAUDIBLE]\nis it [INAUDIBLE] the test set, or is it in the\nmeta-test set as well?",
    "start": "2751050",
    "end": "2758390"
  },
  {
    "text": "Right. So the way this\nexperiment was done is that it was meta-trained\non standard omniglot. And then at meta-test\ntime, we either",
    "start": "2758390",
    "end": "2765270"
  },
  {
    "text": "gave it a training\ndata set that had digits that were kind\nof normal, or we gave it",
    "start": "2765270",
    "end": "2772900"
  },
  {
    "text": "a task and a meta-training\ndata set that had few digits or scaled digits.",
    "start": "2772900",
    "end": "2779080"
  },
  {
    "text": "So the out-of-distribution\ntasks are only happening at meta-test time. And it's reflected both in the\ntraining set and the test set",
    "start": "2779080",
    "end": "2786180"
  },
  {
    "text": "of that meta-test [INAUDIBLE].  Yeah, so during\nthis meta-test time,",
    "start": "2786180",
    "end": "2794460"
  },
  {
    "text": "so we are optimizing it, right? So how many steps will\n[INAUDIBLE] just one step of [INAUDIBLE] multiple\ntimes to do [INAUDIBLE]??",
    "start": "2794460",
    "end": "2804381"
  },
  {
    "text": "Yeah, that's a good question. So with MAML-based\nalgorithms, you want to--",
    "start": "2804382",
    "end": "2810098"
  },
  {
    "text": "the number of gradients,\nfine-tuning steps, that you run at\nmeta-test time, you want to be at least\nas large as the number of gradients--\ninner gradient steps",
    "start": "2810098",
    "end": "2816318"
  },
  {
    "text": "that you used during\nmeta-training. But in practice, you could\nalso run more gradient steps if you find that you\nhaven't converged on the--",
    "start": "2816318",
    "end": "2824310"
  },
  {
    "text": "if you find that you're\ntraining accuracy hasn't converged\nat meta-test time. [INAUDIBLE] similar\nlike [INAUDIBLE]",
    "start": "2824310",
    "end": "2830700"
  },
  {
    "text": "of a hundred of black box. So we will do meta-test\n[INAUDIBLE] similar start [INAUDIBLE] when we\nfind the [INAUDIBLE]..",
    "start": "2830700",
    "end": "2838235"
  },
  {
    "text": "So meta-test time, I guess\ntypically you don't here run that much. So you'll kind of typically\nmeta-train with one",
    "start": "2838235",
    "end": "2844530"
  },
  {
    "text": "or a few gradient steps. And then at meta-test\ntime, you might run-- you might run like up\nto 20 gradient steps.",
    "start": "2844530",
    "end": "2850829"
  },
  {
    "text": "But typically, because these-- in few-shot learning, because\nyour training data sets are so small, you\nconverge very quickly.",
    "start": "2850830",
    "end": "2856820"
  },
  {
    "start": "2856820",
    "end": "2864596"
  },
  {
    "text": "I just had a question. Is there any insight to why\n[INAUDIBLE] skew in the data",
    "start": "2864596",
    "end": "2869850"
  },
  {
    "text": "fit that drop in performance\nis very [INAUDIBLE],, but-- or the scaling, the drop\nis quite early [INAUDIBLE]",
    "start": "2869850",
    "end": "2877908"
  },
  {
    "text": "or something. Yeah. So I wouldn't\nnecessarily think that. But I wouldn't necessarily\nsay that like this skew",
    "start": "2877908",
    "end": "2884950"
  },
  {
    "text": "is comparable to the scale. You could skew the\ndata even more, and you would probably expect\nto see an even larger drop",
    "start": "2884950",
    "end": "2893050"
  },
  {
    "text": "in performance. I think that just the scale\nthat's considered here is probably a bit more\ndrastic than the [INAUDIBLE]",
    "start": "2893050",
    "end": "2898265"
  },
  {
    "text": "that's considered. OK. Thank you. Yeah, during meta-testing, we\nwon't be changing theta, right?",
    "start": "2898265",
    "end": "2906990"
  },
  {
    "text": "Theta is fixed. Yeah. So at meta-test time, we start\nfrom our theta parameters.",
    "start": "2906990",
    "end": "2913380"
  },
  {
    "text": "And then we run fine-tuning\non our training data set from there. And then at the\nend of fine-tuning,",
    "start": "2913380",
    "end": "2918869"
  },
  {
    "text": "we get a set of parameters that\nwe evaluate accuracy algorithm.",
    "start": "2918870",
    "end": "2924860"
  },
  {
    "text": "So this is to get\nthe [INAUDIBLE].. Yeah. OK, got it.",
    "start": "2924860",
    "end": "2930160"
  },
  {
    "text": "OK. Sounds good. [AUDIO OUT] is asking, in\nMAML does the initialization",
    "start": "2930160",
    "end": "2936329"
  },
  {
    "text": "of theta matter a lot? If so, what was the\ninitialization for MAML here? So the-- let's go back to\nthe algorithm real quick.",
    "start": "2936330",
    "end": "2946140"
  },
  {
    "text": "So I guess there's kind\nof a step zero here, which is to take an\ninitialization for theta,",
    "start": "2946140",
    "end": "2955110"
  },
  {
    "text": "and then at the\nend of this you'll get some kind of set of initial\nparameters theta that are good.",
    "start": "2955110",
    "end": "2962789"
  },
  {
    "text": "And in general,\nthis initialization here isn't super important. Typically we just use like\nrandom initialization.",
    "start": "2962790",
    "end": "2969440"
  },
  {
    "text": "It's about as important\nas initial parameters are in general with deep learning.",
    "start": "2969440",
    "end": "2975500"
  },
  {
    "text": "And then of course, the\nfinal initialization that you get for meta-test\ntime is very important,",
    "start": "2975500",
    "end": "2981170"
  },
  {
    "text": "and that's exactly what\nMAML is optimizing for. [AUDIO OUT] is\nasking, how much worse",
    "start": "2981170",
    "end": "2988360"
  },
  {
    "text": "does multitasked learning\nplus fine-tuning do on these\nout-of-distribution tasks? So we didn't actually\nevaluate that here,",
    "start": "2988360",
    "end": "2996789"
  },
  {
    "text": "but we would also expect\nmultitask learning and fine-tuning\nto be more robust",
    "start": "2996790",
    "end": "3005890"
  },
  {
    "text": "to these out-of-distribution\ntasks in comparison to things like SNAIL\nand MetaNetworks.",
    "start": "3005890",
    "end": "3013780"
  },
  {
    "text": "Yeah. But we don't have-- I don't have any results on\nthis specific evaluation.",
    "start": "3013780",
    "end": "3018790"
  },
  {
    "text": " OK. Now, we get this nice structure\nof building an organization",
    "start": "3018790",
    "end": "3026170"
  },
  {
    "text": "into our meta-learner. And the structure allows us to\npotentially generalize better to extrapolate a task.",
    "start": "3026170",
    "end": "3032920"
  },
  {
    "text": "But one downside is,\nwell, maybe the structure means that we can't express\nas many learning procedures.",
    "start": "3032920",
    "end": "3039609"
  },
  {
    "text": "So we know that a black\nbox adaptation procedure, if this neural network\nis large enough,",
    "start": "3039610",
    "end": "3046820"
  },
  {
    "text": "then you can represent\nany learning procedure, in the sense that neural\nnetworks are universal function",
    "start": "3046820",
    "end": "3052070"
  },
  {
    "text": "approximators. But we don't know if that same\nstatement is true for MAML. We don't know that if our\nnetwork is big enough,",
    "start": "3052070",
    "end": "3060130"
  },
  {
    "text": "whether it will be able\nto represent any learning procedure, when it has\nthis gradient operator",
    "start": "3060130",
    "end": "3066040"
  },
  {
    "text": "inside the computation graph. And so we actually\nstudied this question. And it turns out that\nyou can theoretically",
    "start": "3066040",
    "end": "3072130"
  },
  {
    "text": "show that if you have a\nsufficiently deep network, then this MAML function can\napproximate any function",
    "start": "3072130",
    "end": "3078819"
  },
  {
    "text": "of the training data set\nand the test data point,",
    "start": "3078820",
    "end": "3084460"
  },
  {
    "text": "under a few assumptions. And the assumptions\nare fairly mild. The first is that you have to\nhave a non-zero learning rate.",
    "start": "3084460",
    "end": "3092019"
  },
  {
    "text": "This makes sense. The second assumption\nis pretty important. This says that the loss\n[INAUDIBLE] gradient cannot",
    "start": "3092020",
    "end": "3098905"
  },
  {
    "text": "lose information\nabout the label. And then the third\nassumption is that the data points in your training data\nset that have to be unique.",
    "start": "3098905",
    "end": "3106270"
  },
  {
    "text": "And this is also often\ntrue in practice. And the intuition\nbehind this result is that if you view MAML\nas the computation graph",
    "start": "3106270",
    "end": "3113342"
  },
  {
    "text": "that we talked about\nbefore where there's a gradient operator in\nthe middle, as long as that gradient operator doesn't\nkind of discard information",
    "start": "3113342",
    "end": "3121410"
  },
  {
    "text": "about your data points in your\ntraining data set, then you--",
    "start": "3121410",
    "end": "3127099"
  },
  {
    "text": "then you can also\nstill represent-- that computation graph can\nstill represent any learning",
    "start": "3127100",
    "end": "3132470"
  },
  {
    "text": "procedure. And why is this\nimportant or interesting?",
    "start": "3132470",
    "end": "3138880"
  },
  {
    "text": "This means that MAML has the\nbenefit of inductive bias without losing the\nexpressive power that you",
    "start": "3138880",
    "end": "3144880"
  },
  {
    "text": "get from black box\nadaptation [INAUDIBLE].. ",
    "start": "3144880",
    "end": "3151520"
  },
  {
    "text": "OK, cool. So now I want to talk a bit\nabout challenges, and some",
    "start": "3151520",
    "end": "3157220"
  },
  {
    "text": "of the challenges that come up\nwith this class of approaches, and some of the solutions\nthat people have come up with.",
    "start": "3157220",
    "end": "3164150"
  },
  {
    "text": "So one challenge is that we\nhave this bi-level organization,",
    "start": "3164150",
    "end": "3170145"
  },
  {
    "text": "in the sense that\nwe're embedding gradient descent inside another\ngradient descent optimization.",
    "start": "3170145",
    "end": "3175540"
  },
  {
    "text": "And this can exhibit\nsome instabilities. And so there are a few\nideas that you could do to try to mitigate this.",
    "start": "3175540",
    "end": "3183460"
  },
  {
    "text": "One is to try to automatically\nlearn your inner learning rate alpha or tune your\nouter learning rate",
    "start": "3183460",
    "end": "3191950"
  },
  {
    "text": "in order to not have\nto worry too much about tuning either\nof these manually.",
    "start": "3191950",
    "end": "3198070"
  },
  {
    "text": "In practice, I do-- I have found that\ninner learning it is really important for\ngetting things to work well.",
    "start": "3198070",
    "end": "3203440"
  },
  {
    "text": "And the outer learning\nrate, in practice, I found that\n[INAUDIBLE] works well, and that can tune the outer\nlearning rate for you.",
    "start": "3203440",
    "end": "3208950"
  },
  {
    "text": "But there are also\nsome prior works that I've looked at\ntuning that outer learning rate automatically.",
    "start": "3208950",
    "end": "3214900"
  },
  {
    "text": "Another idea is to only optimize\na subset of the parameters in the inner loop. And this can be a\nlittle bit lighter",
    "start": "3214900",
    "end": "3221590"
  },
  {
    "text": "of an optimization\nin the inner loop and reduce some of\nthe instabilities.",
    "start": "3221590",
    "end": "3226620"
  },
  {
    "text": "The third idea is to\ndecouple the inner learning rate and the batch\nnormal statistics for each gradient\ndescent step, so",
    "start": "3226620",
    "end": "3233468"
  },
  {
    "text": "that if you're running\none gradient descent step and another\ngradient descent step, and the third one,\ndifferent learning",
    "start": "3233468",
    "end": "3239550"
  },
  {
    "text": "rates and different\nbatch statistics for each step of that\ninner optimization,",
    "start": "3239550",
    "end": "3245220"
  },
  {
    "text": "this can also make\nthe optimization a bit more flexible. ",
    "start": "3245220",
    "end": "3251775"
  },
  {
    "text": "You can also introduce some\ncontext variables to increase the expressive power.",
    "start": "3251775",
    "end": "3257098"
  },
  {
    "text": "I guess the general\ntakeaway that I'd like to get across\nhere is that there's a range of fairly\nsimple tricks that can help the optimization\nfairly significantly.",
    "start": "3257098",
    "end": "3265210"
  },
  {
    "text": "Even the vanilla algorithm\nworks pretty well, but there are various number of\ntricks that could be helpful.",
    "start": "3265210",
    "end": "3270360"
  },
  {
    "text": " OK.",
    "start": "3270360",
    "end": "3275690"
  },
  {
    "text": "It looks like there's the\nquestion from [AUDIO OUT].. Yes, I have a question on\nthe slide on the assumptions.",
    "start": "3275690",
    "end": "3282930"
  },
  {
    "text": "Yeah. OK, can you explain,\nwhat do you mean by loss function [INAUDIBLE]\nnot lose information but",
    "start": "3282930",
    "end": "3290100"
  },
  {
    "text": "[INAUDIBLE]. Or does it exactly mean-- Yeah. So what this means\nis that, basically",
    "start": "3290100",
    "end": "3295730"
  },
  {
    "text": "when you take the gradient\nof a loss function, we--",
    "start": "3295730",
    "end": "3302727"
  },
  {
    "text": "we're passing in the\ntraining data set here. And depending on your\nchoice of loss function,",
    "start": "3302727",
    "end": "3310650"
  },
  {
    "text": "we want to be able to recover\nthe labels of the training data set from the gradient.",
    "start": "3310650",
    "end": "3316520"
  },
  {
    "text": "And there are some-- I guess examples of this is, if\nyou have an L1 loss function,",
    "start": "3316520",
    "end": "3321690"
  },
  {
    "text": "then the gradient is just-- it's like 1 or negative\n1, essentially.",
    "start": "3321690",
    "end": "3329240"
  },
  {
    "text": "And this will lose information,\nbecause depending-- basically, how incorrect you\nare doesn't really affect--",
    "start": "3329240",
    "end": "3338530"
  },
  {
    "text": "if you're incorrect but you\ndon't know how incorrect you are, that doesn't really\naffect the gradient",
    "start": "3338530",
    "end": "3345620"
  },
  {
    "text": "of like an L1 loss function. Whereas if you have something\nmore like mean squared error or cross entropy, the gradient\nis actually much more--",
    "start": "3345620",
    "end": "3353750"
  },
  {
    "text": "much more informative\nabout the label. And you can-- if you actually\nwrite out the gradient, it's possible to\nrecover the full label",
    "start": "3353750",
    "end": "3361310"
  },
  {
    "text": "information from\nthat gradient if you know the model's prediction. Does that answer your question?",
    "start": "3361310",
    "end": "3366770"
  },
  {
    "text": "Oh, I guess margin loss\nis also losing information about the data. Sorry, what did you say?",
    "start": "3366770",
    "end": "3372802"
  },
  {
    "text": "So basically, margin\nloss [INAUDIBLE] will also be losing information. Yeah. So the L1 loss and\nthe margin loss",
    "start": "3372802",
    "end": "3377830"
  },
  {
    "text": "will also be losing information. Things like L2 and cross entropy\nloss will not lose information.",
    "start": "3377830",
    "end": "3386119"
  },
  {
    "text": "That isn't to say that you can\nuse all these loss functions in practice with MAML. And people who have been\nsuccessful using these loss",
    "start": "3386120",
    "end": "3392327"
  },
  {
    "text": "functions. It's just a kind of a criterion\nfor proving this result.",
    "start": "3392327",
    "end": "3399148"
  },
  {
    "text": "And you don't really\nneed this result to hold true for most\nlearning procedures",
    "start": "3399148",
    "end": "3404890"
  },
  {
    "text": "that you care about in practice. Thank you. ",
    "start": "3404890",
    "end": "3411340"
  },
  {
    "text": "OK. So let's talk about\ntwo more challenges. So one challenge--\none more challenging--",
    "start": "3411340",
    "end": "3418060"
  },
  {
    "text": "and this is actually perhaps\none of the most important challenges-- is that if you have\na lot of inner gradient steps,",
    "start": "3418060",
    "end": "3424620"
  },
  {
    "text": "then back-propagating through\nthose inner gradient steps can actually be pretty\ncompute-intensive and pretty",
    "start": "3424620",
    "end": "3430230"
  },
  {
    "text": "memory-intensive,\nbecause you typically have to store all the iterates\nof the inner optimization,",
    "start": "3430230",
    "end": "3435810"
  },
  {
    "text": "and then back-propagate\nall the way through it. There have been a few\napproaches for trying",
    "start": "3435810",
    "end": "3441810"
  },
  {
    "text": "to tackle this challenge. And I'll highlight\nthree of them. So the first is that,\ninstead of trying",
    "start": "3441810",
    "end": "3448290"
  },
  {
    "text": "to propagate through\nthat optimization path from theta to phi\ni, you can crudely",
    "start": "3448290",
    "end": "3453510"
  },
  {
    "text": "approximate this Jacobian\nas the identity function, and basically assume\nthat things at phi i",
    "start": "3453510",
    "end": "3462150"
  },
  {
    "text": "look like things at theta. ",
    "start": "3462150",
    "end": "3467960"
  },
  {
    "text": "This is a very\ncrude approximation. In practice, this\nJacobean is actually",
    "start": "3467960",
    "end": "3473480"
  },
  {
    "text": "nowhere near identity\nfrom what I've found. Although, somewhat\nsurprisingly, this actually does",
    "start": "3473480",
    "end": "3479119"
  },
  {
    "text": "work for simple few-shot\nlearning problems. Anecdotally, I've found\nthat this doesn't work well",
    "start": "3479120",
    "end": "3485390"
  },
  {
    "text": "for more complex\nlearning problems. So your mileage may vary.",
    "start": "3485390",
    "end": "3491300"
  },
  {
    "text": "This is kind of known\nas first-order MAML. And then there's also\nthe Reptile algorithm that does something fairly\nsimilar to this approximation",
    "start": "3491300",
    "end": "3498800"
  },
  {
    "text": "as well. It's called first-order\nMAML in the sense that you don't actually\nneed second-order gradients",
    "start": "3498800",
    "end": "3504350"
  },
  {
    "text": "if you make this approximation. And this kind of relates\nto the calculations that we were doing\nearlier as well.",
    "start": "3504350",
    "end": "3510740"
  },
  {
    "text": " OK.",
    "start": "3510740",
    "end": "3516240"
  },
  {
    "text": "Another idea is to only optimize\nthe last layer of the weights in your inner optimization.",
    "start": "3516240",
    "end": "3523565"
  },
  {
    "text": "So before, we were\nsaying that we were going to fine-tune all\nof the weights in the network. But one thing you could do is\njust fine-tune the last layer.",
    "start": "3523565",
    "end": "3530970"
  },
  {
    "text": "And there are a\nnumber of approaches that have done this, where they\nbasically optimize both for-- for a set of features such\nthat when you optimize",
    "start": "3530970",
    "end": "3538620"
  },
  {
    "text": "on top of that with logistic\nregression, ridge regression, or support vector machine,\nyou generalize well",
    "start": "3538620",
    "end": "3544230"
  },
  {
    "text": "with a small amount of data. And one thing that's pretty cool\nabout these kinds of approaches is that it can actually be--",
    "start": "3544230",
    "end": "3554160"
  },
  {
    "text": "when you do this kind\nof ridge regression and logistic regression, as well\nas a support vector machine, this leads to either a\nclosed-form optimization",
    "start": "3554160",
    "end": "3561780"
  },
  {
    "text": "or a convex optimization\nin the inner loop. And there are kind of various\nother techniques for actually",
    "start": "3561780",
    "end": "3568067"
  },
  {
    "text": "differentiating through\nthese close-form or convex optimizations that make it a\nlot more efficient in practice.",
    "start": "3568067",
    "end": "3577630"
  },
  {
    "text": "So if you're in a\nsetting where kind of optimizing just\nthe last layer will kind of be\nexpected to work well,",
    "start": "3577630",
    "end": "3584770"
  },
  {
    "text": "then this is a very\nreasonable approach. If you think that you may\nneed to fine-tune much deeper than that,\nthen of course,",
    "start": "3584770",
    "end": "3590600"
  },
  {
    "text": "this won't be quite as helpful. ",
    "start": "3590600",
    "end": "3595930"
  },
  {
    "text": "Now, the last idea\nis, there's also a way to derive the\nmeta-gradient using",
    "start": "3595930",
    "end": "3602200"
  },
  {
    "text": "what's called the\nimplicit function theorem. And it basically\nallows you to compute",
    "start": "3602200",
    "end": "3607480"
  },
  {
    "text": "d phi i d theta\nwithout actually having to back-propagate through\nthe optimization path, which",
    "start": "3607480",
    "end": "3616330"
  },
  {
    "text": "is pretty cool. For time, I'm not going to go\nthrough the details of this. But if you want to see a\nderivation of how this works,",
    "start": "3616330",
    "end": "3623690"
  },
  {
    "text": "you can check out the\nlecture from last year. ",
    "start": "3623690",
    "end": "3629890"
  },
  {
    "text": "OK. And this kind of leads to some\nnice memory and computation trade-offs, where\nbasically, as you increase",
    "start": "3629890",
    "end": "3636069"
  },
  {
    "text": "the number of inner gradient\ndescent steps, basically the memory cost is\ncompletely constant",
    "start": "3636070",
    "end": "3642502"
  },
  {
    "text": "as you increase the number\nof gradient descent steps. And the computation cost is--",
    "start": "3642502",
    "end": "3647920"
  },
  {
    "text": "increases more slowly if\nyou do this in comparison to back-propagating through\nthe optimization path.",
    "start": "3647920",
    "end": "3653776"
  },
  {
    "text": " Cool. So [AUDIO OUT] is\nasking in the chat,",
    "start": "3653776",
    "end": "3660060"
  },
  {
    "text": "what's the difference\nbetween phi and theta? So basically, in the context\nof optimization-based",
    "start": "3660060",
    "end": "3668480"
  },
  {
    "text": "meta-learning, we're saying\nthat phi i is basically the result of running\nfine-tuning, starting--",
    "start": "3668480",
    "end": "3677990"
  },
  {
    "text": "initialized at theta. So theta is the initialization\nof fine-tuning and phi i is the result of fine-tuning.",
    "start": "3677990",
    "end": "3684200"
  },
  {
    "text": "I'm using a subscript i to\ndenote that this fine-tuning process takes as input a\ndata set D trained that's",
    "start": "3684200",
    "end": "3693290"
  },
  {
    "text": "specific to task i. So in some ways, theta\nis the meta-parameters, and phi i is the\ntask-specific parameters",
    "start": "3693290",
    "end": "3700863"
  },
  {
    "text": "that have been\nfine-tuned for that task. ",
    "start": "3700863",
    "end": "3706870"
  },
  {
    "text": "OK. Yeah. And then one other\ncool thing about this is this also allows for\nsecond-order optimizers",
    "start": "3706870",
    "end": "3712240"
  },
  {
    "text": "in the inner loop, because you\ndon't have to back-propagate through the second-order\noptimizers, which would lead to third-order optimization.",
    "start": "3712240",
    "end": "3718180"
  },
  {
    "text": "And this has led to\nsome good performance. ",
    "start": "3718180",
    "end": "3723589"
  },
  {
    "text": "OK, cool. And then the last challenge\nI would like to mention is that some of the\narchitecture that works well",
    "start": "3723590",
    "end": "3730220"
  },
  {
    "text": "for optimization-based\nmeta-learning isn't always the same as\narchitectures that work, for deep learning.",
    "start": "3730220",
    "end": "3737119"
  },
  {
    "text": "And one work has actually\ncombined neural architecture search with MAML to try to find\nan architecture that works well",
    "start": "3737120",
    "end": "3744560"
  },
  {
    "text": "with MAML. And they found that fairly\nnonstandard architectures that are very deep and\nnarrow actually",
    "start": "3744560",
    "end": "3753080"
  },
  {
    "text": "led to pretty large\ngains in performance on something like\nmini image set,",
    "start": "3753080",
    "end": "3759350"
  },
  {
    "text": "in comparison to using a\nmore standard architecture. ",
    "start": "3759350",
    "end": "3766520"
  },
  {
    "text": "OK. Cool. So to summarize\noptimization-based adaptation",
    "start": "3766520",
    "end": "3773480"
  },
  {
    "text": "and meta-learning,\nkind of the key idea is to acquire phi i\nthrough an organization rather than through a\nneural network directly.",
    "start": "3773480",
    "end": "3780769"
  },
  {
    "text": "And this involves constructing\na bi-level optimization problem. There are a number of\nbenefits to this approach.",
    "start": "3780770",
    "end": "3786930"
  },
  {
    "text": "So you get kind of as\npositive inductive bias at the start of meta-learning,\nbecause you're already going to be fine-tuning, which\nis already a reasonable way",
    "start": "3786930",
    "end": "3794809"
  },
  {
    "text": "to transfer to a new task. And then from there,\nyou're just going to be improving upon the\ninitialization or the learning",
    "start": "3794810",
    "end": "3801440"
  },
  {
    "text": "rate, or other aspects\nof the optimization. As we saw, it tends\nto extrapolate better",
    "start": "3801440",
    "end": "3807200"
  },
  {
    "text": "than black box meta-learners. It's also maximally\nexpressive if you have",
    "start": "3807200",
    "end": "3812780"
  },
  {
    "text": "a sufficiently large network. And it's model-agnostic\nin the sense that it should be fairly\nstraightforward to combine",
    "start": "3812780",
    "end": "3819430"
  },
  {
    "text": "with different architectures. The downside is that\nit typically requires a second-order optimization.",
    "start": "3819430",
    "end": "3826740"
  },
  {
    "text": "And it's usually more\ncompute- and memory-intensive than black box\nmeta-learning approaches.",
    "start": "3826740",
    "end": "3834700"
  },
  {
    "text": "Questions? Can you illustrate again what\ndoes this positive inductive",
    "start": "3834700",
    "end": "3840940"
  },
  {
    "text": "bias mean? Yeah. So what I mean by\npositive inductive bias is just the sense that you're\nbuilding an optimization",
    "start": "3840940",
    "end": "3848099"
  },
  {
    "text": "into the meta-learner. So you already have-- you're already kind of starting\nfrom this optimization that",
    "start": "3848100",
    "end": "3854910"
  },
  {
    "text": "will do somewhat reasonably. And this says that fine-tuning\ndoes somewhat reasonably when",
    "start": "3854910",
    "end": "3860160"
  },
  {
    "text": "you have data from a new task. Whereas if you just\nhave a black box neural network that doesn't know\nanything about optimization,",
    "start": "3860160",
    "end": "3867119"
  },
  {
    "text": "then it doesn't have that-- what I'm calling inductive bias. [INAUDIBLE]",
    "start": "3867120",
    "end": "3875110"
  },
  {
    "text": "I was sort of curious about\nthe second-order [INAUDIBLE].. So in conventional SGD\nyou have an update,",
    "start": "3875110",
    "end": "3883960"
  },
  {
    "text": "and then you have a [INAUDIBLE]\ngradient of your most recent updated parameter with respect\nto the parameter [INAUDIBLE]",
    "start": "3883960",
    "end": "3892059"
  },
  {
    "text": "of-- so that parameter itself\ncontains its history, and so it contains [INAUDIBLE].",
    "start": "3892060",
    "end": "3898750"
  },
  {
    "text": "How is optimization\n[INAUDIBLE] different from the conventional\nSGD when you just",
    "start": "3898750",
    "end": "3903820"
  },
  {
    "text": "obtain [INAUDIBLE] gradient\ndrop of parameter [INAUDIBLE] usually affected?",
    "start": "3903820",
    "end": "3909700"
  },
  {
    "text": "Yeah. So I guess in some ways,\nthis is similar to what I was mentioning with regard\nto transfer learning, where--",
    "start": "3909700",
    "end": "3917310"
  },
  {
    "text": "whoops-- where transfer\nlearning is doing something like basically min over theta\nof L of theta D trained.",
    "start": "3917310",
    "end": "3928730"
  },
  {
    "text": "Whereas something like\nthis meta-learning approach is doing min of L of theta\nminus alpha theta D trained.",
    "start": "3928730",
    "end": "3940010"
  },
  {
    "text": "In some ways, you can-- this optimization,\nyou're still going to be doing this optimization\nwith an SGD approach.",
    "start": "3940010",
    "end": "3947579"
  },
  {
    "text": "So that kind of\nouter optimization is just the same as vanilla SGD. What's just a\nlittle bit different",
    "start": "3947580",
    "end": "3952970"
  },
  {
    "text": "is that you have this\ngradient operator inside of your objective. And so you need to be\nthinking about actually",
    "start": "3952970",
    "end": "3959289"
  },
  {
    "text": "the second-order\noptimization, because you need to back-propagate through\na gradient step itself.",
    "start": "3959290",
    "end": "3965795"
  },
  {
    "text": "But if you take kind of\nthe computation graph view of things and just\nview this gradient operator as being part of your\ncomputation graph,",
    "start": "3965795",
    "end": "3971960"
  },
  {
    "text": "then there are a\nlot of similarities. OK. That's how I [INAUDIBLE]\nbecause in reality, [INAUDIBLE]",
    "start": "3971960",
    "end": "3978010"
  },
  {
    "text": "learning theta is nothing\nbut theta [INAUDIBLE] minus alpha of\ndelta [INAUDIBLE]..",
    "start": "3978010",
    "end": "3984546"
  },
  {
    "text": " Can you repeat that? Yeah. So in the [INAUDIBLE]\nlearning approach,",
    "start": "3984546",
    "end": "3990537"
  },
  {
    "text": "in the equation of [INAUDIBLE],,\nthe equation is actually [INAUDIBLE] theta\n[INAUDIBLE] theta,",
    "start": "3990537",
    "end": "3997430"
  },
  {
    "text": "but theta is nothing but\n[INAUDIBLE] of the [INAUDIBLE] theta previous\nminus alpha times--",
    "start": "3997430",
    "end": "4002630"
  },
  {
    "text": "Yeah. So OK, one thing that's\ndifferent is that-- so I see what you're-- so basically, this is\nlike theta at iteration i.",
    "start": "4002630",
    "end": "4009110"
  },
  {
    "text": "And theta at iteration i\nis equal to, basically, theta at iteration i minus\n1 minus the gradient step,",
    "start": "4009110",
    "end": "4016910"
  },
  {
    "text": "basically. Exactly, yeah. One thing that's different\nhere is that it's-- so in SGD, you don't\nreally keep track--",
    "start": "4016910",
    "end": "4025190"
  },
  {
    "text": "you're taking kind of the\npartial derivative of theta i. You're not kind\nof really keeping",
    "start": "4025190",
    "end": "4030289"
  },
  {
    "text": "track of how that is a\nfunction of theta i minus 1, whereas here, when\nyou do this, you",
    "start": "4030290",
    "end": "4036050"
  },
  {
    "text": "need to actually back-propagate\nthrough this gradient step",
    "start": "4036050",
    "end": "4041540"
  },
  {
    "text": "right here into your\nprevious value of theta, and optimize kind of your\nprevious value of theta,",
    "start": "4041540",
    "end": "4048380"
  },
  {
    "text": "[INAUDIBLE] initialization such\nthat a gradient step gives you good performance. And so this affects the way that\nyou implement these algorithms,",
    "start": "4048380",
    "end": "4057085"
  },
  {
    "text": "because you can't\njust say, we're going to take a gradient\nstep and then optimize-- and then actually kind of do\nlike assign your parameters",
    "start": "4057085",
    "end": "4063170"
  },
  {
    "text": "to have that value and then\ndo gradient step again. In many ways, that's\nkind of the difference between a total derivative\nand a partial derivative.",
    "start": "4063170",
    "end": "4072260"
  },
  {
    "text": "I have a second question. you got [INAUDIBLE] step,\nbut these outer [INAUDIBLE]",
    "start": "4072260",
    "end": "4077790"
  },
  {
    "text": "appearing on different\ntasks, and the inner step is [INAUDIBLE] varying\nparameters theta for each task",
    "start": "4077790",
    "end": "4083000"
  },
  {
    "text": "or phi. So why are the inner\nand outer [INAUDIBLE]??",
    "start": "4083000",
    "end": "4088130"
  },
  {
    "text": " So this-- so there's\na sum over i here.",
    "start": "4088130",
    "end": "4094490"
  },
  {
    "text": "And this is what I\ncall the inner step. And then the kind\nof things that are",
    "start": "4094490",
    "end": "4100189"
  },
  {
    "text": "used to optimize this is\ncalled the outer step. You need to compute\nthe inner step for multiple different tasks.",
    "start": "4100189",
    "end": "4105620"
  },
  {
    "text": "And then once you\ndo that, you'll need to compute the outer step\non each of those tasks as well,",
    "start": "4105620",
    "end": "4110849"
  },
  {
    "text": "and then average. The outer step is computed-- like, when you compute\nthe gradient here,",
    "start": "4110850",
    "end": "4118040"
  },
  {
    "text": "that gradient will kind of--\ncan go inside the sum here. And you will be computing\nkind of the meta-gradient",
    "start": "4118040",
    "end": "4123920"
  },
  {
    "text": "for each of your tasks,\nand then averaging. Got it. Thank you.",
    "start": "4123920",
    "end": "4128934"
  },
  {
    "text": " Hi. Can you explain why the\nMAML is easy to combine",
    "start": "4128935",
    "end": "4138339"
  },
  {
    "text": "with different\nmodels [INAUDIBLE],, because [INAUDIBLE]\ntheta, we still",
    "start": "4138340",
    "end": "4143589"
  },
  {
    "text": "need an architecture\nto do [INAUDIBLE].. Yeah. I guess when I say that, I\njust mean that basically,",
    "start": "4143590",
    "end": "4149469"
  },
  {
    "text": "all of these equations\nare only having to do with the\nparameters of your model and don't really\nprescribe anything",
    "start": "4149470",
    "end": "4154828"
  },
  {
    "text": "about the architecture\nof that model. Whereas with a\nblack box approach, you need to figure out how to\ncombine whatever architecture",
    "start": "4154828",
    "end": "4162850"
  },
  {
    "text": "you like to process data with\nan architecture that can process like multiple data points.",
    "start": "4162850",
    "end": "4168649"
  },
  {
    "text": "That said, this\noptimization will become more difficult\nif computing gradients for that architecture\nare more difficult.",
    "start": "4168649",
    "end": "4175180"
  },
  {
    "text": "Like, if you have a\nrecurrent neural network, then MAML can be a bit\nmore tricky to combine",
    "start": "4175180",
    "end": "4180939"
  },
  {
    "text": "with a recurrent neural\nnetwork, because you have to kind of\nback-propagate gradients through time through\nthat recurrent network.",
    "start": "4180939",
    "end": "4187548"
  },
  {
    "text": "OK, thank you. OK. For the sake of time, I'm going\nto go through this case study,",
    "start": "4187549",
    "end": "4193339"
  },
  {
    "text": "and then I'll try to\nanswer additional questions at the end at 2:20. ",
    "start": "4193340",
    "end": "4198880"
  },
  {
    "text": "So this case study\nwas looking at how we could use meta-learning\nfor few-shot land cover",
    "start": "4198880",
    "end": "4204360"
  },
  {
    "text": "classification, which is\na pretty cool application. And this is actually\na pretty recent paper",
    "start": "4204360",
    "end": "4210840"
  },
  {
    "text": "that was at the Earth Vision\nWorkshop at CVPR this year. And if you're interested,\nthe link to the paper",
    "start": "4210840",
    "end": "4216480"
  },
  {
    "text": "is also right here, which\nyou can find in the slides. So the problem that\nthey're looking at is trying to map land covering\nfrom satellite images.",
    "start": "4216480",
    "end": "4225510"
  },
  {
    "text": "And they looked at a\nfew different data sets. And this is basically what\nthe problem looks like.",
    "start": "4225510",
    "end": "4232080"
  },
  {
    "text": "You have some satellite imagery\nthat looks like these images here.",
    "start": "4232080",
    "end": "4237420"
  },
  {
    "text": "And your goal is\nto output something like these segmentation images.",
    "start": "4237420",
    "end": "4244620"
  },
  {
    "text": "The first data set is a\nlower resolution data set, where you basically say like,\nwithin a certain region, what",
    "start": "4244620",
    "end": "4250020"
  },
  {
    "text": "is kind of the predominant\nuse of that land. Whereas this data set is\nmuch more fine-grained.",
    "start": "4250020",
    "end": "4258320"
  },
  {
    "text": "And different categories\nof land covering include urban, agricultural,\nrangeland, forest, water,",
    "start": "4258320",
    "end": "4264220"
  },
  {
    "text": "barren, and unknown.  And if we can successfully\nclassify land covering,",
    "start": "4264220",
    "end": "4272480"
  },
  {
    "text": "then this may have applications\nin global urban planning, where you're figuring out\nactually how to use land",
    "start": "4272480",
    "end": "4278840"
  },
  {
    "text": "in different ways,\nclimate change research, and potentially other\nEarth science applications.",
    "start": "4278840",
    "end": "4287720"
  },
  {
    "text": "Now, what are some of the\nchallenges that come up here? So first, labeling data\nis really expensive.",
    "start": "4287720",
    "end": "4294330"
  },
  {
    "text": "You have to label kind\nof individual pixels, or in this case label\nsomething that's a little bit lower resolution.",
    "start": "4294330",
    "end": "4300308"
  },
  {
    "text": "But you still have\nto go through maps and hand-label these things. And also, different\nregions look very different",
    "start": "4300308",
    "end": "4306530"
  },
  {
    "text": "and have different\nland use proportions. So we have kind of a lot\nof distribution shift,",
    "start": "4306530",
    "end": "4312170"
  },
  {
    "text": "both in like p of x, both\nin the image distribution, as well as in p of y,\nwhich is the kind of use",
    "start": "4312170",
    "end": "4319700"
  },
  {
    "text": "of those different\npieces of land. So for example, if you\nlook at of croplands",
    "start": "4319700",
    "end": "4326060"
  },
  {
    "text": "from four different countries,\nfrom Mali, Brazil, Poland, and Angola, we see pretty\nsubstantial differences between the images\nfrom these countries.",
    "start": "4326060",
    "end": "4336080"
  },
  {
    "text": "So the way they frame this as\na meta-learning problem was different tasks corresponded\nto different regions",
    "start": "4336080",
    "end": "4341200"
  },
  {
    "text": "of the world, such as these\nfour regions, for example. And their goal is to\nbe able to segment",
    "start": "4341200",
    "end": "4347110"
  },
  {
    "text": "or classify images\nfrom a new region with a small amount of\ndata from that region,",
    "start": "4347110",
    "end": "4352150"
  },
  {
    "text": "by leveraging the data\nfrom the other regions. So essentially, they took\nkind of the MAML algorithm",
    "start": "4352150",
    "end": "4358730"
  },
  {
    "text": "and were trying to learn\ninitialization such that you can quickly fine-tune that\nmodel to accurately classify",
    "start": "4358730",
    "end": "4366470"
  },
  {
    "text": "the satellite images in\ndifferent regions of the world. ",
    "start": "4366470",
    "end": "4372730"
  },
  {
    "text": "OK. And then more\nspecifically how they framed this as a\nmeta-learning problem, so they did this a little bit\ndifferently for the two data",
    "start": "4372730",
    "end": "4379477"
  },
  {
    "text": "sets, because the data sets\nhad different characteristics. For the first data set,\nthere was geographic metadata",
    "start": "4379477",
    "end": "4386950"
  },
  {
    "text": "that was provided as\npart of the data set. And so they split it\ninto meta-training, meta-val, and\nmeta-test sets, shown",
    "start": "4386950",
    "end": "4393489"
  },
  {
    "text": "in these different colors. And so they're holding out\ndifferent geographic regions in the meta-val set\nand the meta-test set.",
    "start": "4393490",
    "end": "4401548"
  },
  {
    "text": "And then they constructed\na meta-learning problem by trying to be able to\nclassify between different kinds",
    "start": "4401548",
    "end": "4406679"
  },
  {
    "text": "of lands such as\nforest or croplands, given a small number of patches\nfrom that region of the world.",
    "start": "4406680",
    "end": "4420973"
  },
  {
    "text": "So this is an example of a\ntwo-way two-shot classification task. And then for the\nsecond data set,",
    "start": "4420973",
    "end": "4427718"
  },
  {
    "text": "they didn't actually have\nany geographic metadata in the data set unfortunately. So they used clustering to try\nto guess different regions.",
    "start": "4427718",
    "end": "4434412"
  },
  {
    "text": "And then they held\nout different clusters for the meta-validation\nset and the meta-test set.",
    "start": "4434412",
    "end": "4439990"
  },
  {
    "text": "And then they framed a\none-shot learning problem for the segmentation\ntask as the following,",
    "start": "4439990",
    "end": "4445090"
  },
  {
    "text": "where they took a very small\npatch of a much larger region. They labeled this\nas the support site.",
    "start": "4445090",
    "end": "4452800"
  },
  {
    "text": "And they evaluated the\nmodel on the query set of other patches of the data.",
    "start": "4452800",
    "end": "4458140"
  },
  {
    "text": "And like as an example,\nthis kind of large region is an image that's like\n2,400 pixels by 2,400 pixels.",
    "start": "4458140",
    "end": "4466105"
  },
  {
    "text": "And the label would look\nsomething like this.  And what they found\nin their evaluation is",
    "start": "4466105",
    "end": "4473119"
  },
  {
    "text": "they compared, basically,\ntraining on your new data",
    "start": "4473120",
    "end": "4479340"
  },
  {
    "text": "at meta-test time\njust from scratch, they compared to pre-training on\nall of your metadata combined,",
    "start": "4479340",
    "end": "4485280"
  },
  {
    "text": "and then fine-tuning on this. And they also\ncompared to running MAML on the\nmeta-trained data set",
    "start": "4485280",
    "end": "4490290"
  },
  {
    "text": "and adapting to the test data. And what they found is\non the first data set,",
    "start": "4490290",
    "end": "4495840"
  },
  {
    "text": "they were able to first, do\nsignificantly better with MAML than with a pre-trained\nmodel and a random model",
    "start": "4495840",
    "end": "4503280"
  },
  {
    "text": "in the case where you have\nbetween 1 and 10 shots, 10 data points.",
    "start": "4503280",
    "end": "4508780"
  },
  {
    "text": "And when you had\nzero data points, the pre-trained\nmodel did the best. And this is also\nwhat we would expect, because MAML needs\ndata to fine-tune.",
    "start": "4508780",
    "end": "4515752"
  },
  {
    "text": "And of course, the randomly\ninitialized network also needs data to fine-tune.",
    "start": "4515752",
    "end": "4521010"
  },
  {
    "text": "Also, on the DeepGlobe data\nset, they saw similar results on the clustered\nsplit, where they",
    "start": "4521010",
    "end": "4527580"
  },
  {
    "text": "were kind of adapting to a\nnew region that was held out, whereas when they did\na more random split,",
    "start": "4527580",
    "end": "4533460"
  },
  {
    "text": "they found that the pre-trained\nnetwork and MAML performed somewhat similarly when\nyou have a few shots.",
    "start": "4533460",
    "end": "4539010"
  },
  {
    "text": " OK. So this is pretty cool. It's kind of a more\nreal-world application",
    "start": "4539010",
    "end": "4546390"
  },
  {
    "text": "of where meta-learning\nmight be useful when you want to adapt to\ndifferent regions of the world. ",
    "start": "4546390",
    "end": "4554215"
  },
  {
    "text": "And if you're\ninterested, there's more visualizations and\nmore analysis in the paper. And also, both of\nthese data sets",
    "start": "4554215",
    "end": "4559700"
  },
  {
    "text": "are publicly available if\nyou're interested in studying them yourself, for example,\nfor your final project. ",
    "start": "4559700",
    "end": "4567600"
  },
  {
    "text": "OK. So that's it for today. We talked about\noptimization-based meta-learning, and the\nbasics of the techniques,",
    "start": "4567600",
    "end": "4575250"
  },
  {
    "text": "and how the trade-off--\nkind of some of the trade-offs\nbetween black box and optimization-based\ntechniques.",
    "start": "4575250",
    "end": "4581639"
  },
  {
    "text": "And the roadmap for\nthe upcoming lectures is that next week\non Monday, we'll have a guest lecturer from\nMatt Johnson, where he'll",
    "start": "4581640",
    "end": "4587647"
  },
  {
    "text": "talk about automotive\ndifferentiation, and how our deep learning\nsoftwares actually compute the derivatives for things\nthat we talked about today,",
    "start": "4587647",
    "end": "4595990"
  },
  {
    "text": "and for just neural\nnetworks in general. And on Wednesday,\nwe'll start talking about the last class\nof meta-learners, which",
    "start": "4595990",
    "end": "4602250"
  },
  {
    "text": "is nonparametric learners. And we'll also cover kind\nof a general comparison",
    "start": "4602250",
    "end": "4607380"
  },
  {
    "text": "of all of the three approaches\nthat we've discussed. And then the\nfollowing week, we'll talk about more advanced\nmeta-learning topics, topics",
    "start": "4607380",
    "end": "4614746"
  },
  {
    "text": "that are also still\nquite important, though, especially if you want\nto use meta-learning in your final project.",
    "start": "4614747",
    "end": "4620719"
  },
  {
    "text": "And in week five, we'll\nstart reinforcement learning. ",
    "start": "4620720",
    "end": "4629000"
  }
]
[
  {
    "start": "0",
    "end": "180000"
  },
  {
    "text": "thanks for that great introduction um yeah so funny story I was here basically a year ago and so a lot of what I'm",
    "start": "11180",
    "end": "17450"
  },
  {
    "text": "gonna be talking about today has to do with work that I started actually as a postdoc here in the vision and learning",
    "start": "17450",
    "end": "23360"
  },
  {
    "text": "lab um so to modify my talk I wanted to sort of transport you to what I hope is",
    "start": "23360",
    "end": "29509"
  },
  {
    "text": "a familiar situation for you say that you're in a city in this case New York City and you're going just from one",
    "start": "29509",
    "end": "35390"
  },
  {
    "text": "place to another okay and as you're basically walking by I want you to think about all the things",
    "start": "35390",
    "end": "41540"
  },
  {
    "text": "that you're doing to actually get to that place isn't it amazing how we reason about space how we you know",
    "start": "41540",
    "end": "48649"
  },
  {
    "text": "figure out the general direction we want to go we take advantage of our visual",
    "start": "48649",
    "end": "53809"
  },
  {
    "text": "stimuli in particular to avoid obstacles both dynamic and static and even more we",
    "start": "53809",
    "end": "59449"
  },
  {
    "text": "reason about interactions that are happening nearby and obviously we're not just taking this early the shortest path",
    "start": "59449",
    "end": "64489"
  },
  {
    "text": "unless we're really in a hurry we're actually becoming part of the social fabric of that particular",
    "start": "64489",
    "end": "69800"
  },
  {
    "text": "environment and so this sort of set of problems that I just described that we",
    "start": "69800",
    "end": "75770"
  },
  {
    "text": "pretty much solve without thinking about it is something that has happened has fascinated for a while the robotics and",
    "start": "75770",
    "end": "82640"
  },
  {
    "text": "the human robot interaction community and the good news is that well we've come very very far along in terms of",
    "start": "82640",
    "end": "89480"
  },
  {
    "text": "creating systems that we can deploy in particular applications maybe in the case of manufacturing or delivery or",
    "start": "89480",
    "end": "95870"
  },
  {
    "text": "even in the case of transportation and so for many of you today especially here in the Bay Area it might seem like",
    "start": "95870",
    "end": "102370"
  },
  {
    "text": "navigation may be a salt problem but the reality that if you keep reading the",
    "start": "102370",
    "end": "107630"
  },
  {
    "text": "news well they're still very important challenges that remain and I argue that a lot of these challenges come because",
    "start": "107630",
    "end": "114560"
  },
  {
    "text": "of the complexity of unstructured environments as soon as you put this machine somewhere where you haven't",
    "start": "114560",
    "end": "119780"
  },
  {
    "text": "really done a lot of testing where you don't know exactly how people will behave then things start to break down and so today what I'm going to do is I'm",
    "start": "119780",
    "end": "127160"
  },
  {
    "text": "going to present to you a couple of different projects all of them sort of surrounding surrounding the idea that",
    "start": "127160",
    "end": "133580"
  },
  {
    "text": "structure approaches approaches the sort of like in a classical systems engineering even in a classical robotics",
    "start": "133580",
    "end": "139670"
  },
  {
    "text": "way decompose a big challenge into smaller simpler subproblems they can help us Rison about space and",
    "start": "139670",
    "end": "146370"
  },
  {
    "text": "in particular the the sort of commonality among these these methods I'm going to be describing is that they",
    "start": "146370",
    "end": "151840"
  },
  {
    "text": "only use data-driven methods in particularly deep learning in order to do complex function approximation and",
    "start": "151840",
    "end": "158160"
  },
  {
    "text": "what do I mean by this what do you mean by complex function approximation so in the world there's lots of physical and",
    "start": "158160",
    "end": "164260"
  },
  {
    "text": "social things that are happening around us we can use deep learning as a mechanism to approximate this phenomenon",
    "start": "164260",
    "end": "170290"
  },
  {
    "text": "and then hopefully take advantage of that both for perception and decision-making in the case of human",
    "start": "170290",
    "end": "175300"
  },
  {
    "text": "robot interaction and even more broadly in the case of HCI and so what I'm going",
    "start": "175300",
    "end": "180400"
  },
  {
    "start": "180000",
    "end": "223000"
  },
  {
    "text": "to be talking about exactly today so those three projects on the Left I'm",
    "start": "180400",
    "end": "185860"
  },
  {
    "text": "going to start with what I consider to be one of the simplest and more important challenges which is",
    "start": "185860",
    "end": "192580"
  },
  {
    "text": "reversibility estimation especially for avoiding getting your robot into troublesome situations and then I'll",
    "start": "192580",
    "end": "198940"
  },
  {
    "text": "start talking about traumas are in a way a higher-level reasoning more related to interaction including navigation and",
    "start": "198940",
    "end": "205260"
  },
  {
    "text": "reasoning about spatial behavior that might happen during social conversations",
    "start": "205260",
    "end": "211090"
  },
  {
    "text": "and then finally I'll talk about some future directions both things that I think are important that we need to",
    "start": "211090",
    "end": "217150"
  },
  {
    "text": "solve but also some exciting questions in relation to social influence all",
    "start": "217150",
    "end": "222760"
  },
  {
    "text": "right so how many of you have heard about reversibility estimation before one all right so for those of you who",
    "start": "222760",
    "end": "230290"
  },
  {
    "start": "223000",
    "end": "260000"
  },
  {
    "text": "have never heard about this the question here is is this place in front of the robot safe for it to traverse or not",
    "start": "230290",
    "end": "236500"
  },
  {
    "text": "right very simple binary question and you know when you can think about it as a software solution to an emergency stop",
    "start": "236500",
    "end": "244030"
  },
  {
    "text": "right whenever you might see say the jackrabbit project that I was working on before here at Stanford you might see",
    "start": "244030",
    "end": "249310"
  },
  {
    "text": "someone behind the robot with ready to press a button right that looks like whoo I'm gonna stop the robot this is basically an alternative or a",
    "start": "249310",
    "end": "255730"
  },
  {
    "text": "complementary solution to do that through software and so in this particular project what we were trying",
    "start": "255730",
    "end": "261789"
  },
  {
    "start": "260000",
    "end": "359000"
  },
  {
    "text": "to do was answer this question based on an image in particular an image capture",
    "start": "261789",
    "end": "267640"
  },
  {
    "text": "from a camera with a fisheye lens that has a wide view of the environment and based on that image then we wanted to",
    "start": "267640",
    "end": "273880"
  },
  {
    "text": "say okay what is the probability that the environment scene that image is safe for the robot to",
    "start": "273880",
    "end": "278949"
  },
  {
    "text": "traverse here the assumption is that that camera is on the robot and that's basically what's going to come up in front of the robot the next time now",
    "start": "278949",
    "end": "286870"
  },
  {
    "text": "from this image this might seem like a very simple problem right we just have to look for kind of empty hallways but",
    "start": "286870",
    "end": "294220"
  },
  {
    "text": "even if you go and collect data for this problem here at Stanford then you still realize there are lots of different",
    "start": "294220",
    "end": "300099"
  },
  {
    "text": "scenarios that might come up that may pose challenges and so what makes it",
    "start": "300099",
    "end": "305530"
  },
  {
    "text": "this even harder is that this challenging is scenarios are the ones that you actually don't want to expose",
    "start": "305530",
    "end": "310870"
  },
  {
    "text": "your robot to because probably is gonna be in trouble very soon after it since",
    "start": "310870",
    "end": "315909"
  },
  {
    "text": "these images right and so because of that what you end up having when you try",
    "start": "315909",
    "end": "321039"
  },
  {
    "text": "to apply machine learning to this problem is an uneven distribution of lots of positive examples things that",
    "start": "321039",
    "end": "327340"
  },
  {
    "text": "are safe for the robot to see which you can easily collect and just a few negative examples of things that you",
    "start": "327340",
    "end": "333520"
  },
  {
    "text": "were willing to expose your robot to to get at least some negative data of what might be trouble sourcing circumstances",
    "start": "333520",
    "end": "340090"
  },
  {
    "text": "and so this is an even distribution naturally is a problem for standard supervised learning methods and what we",
    "start": "340090",
    "end": "345909"
  },
  {
    "text": "do in this case is treated as an anomaly detection problem or go here for Traverse ability estimation is estimate",
    "start": "345909",
    "end": "351550"
  },
  {
    "text": "detect these images whenever they come in the view of the robot so that it doesn't hopefully collide or fall down",
    "start": "351550",
    "end": "356979"
  },
  {
    "text": "the stairs whatever that is now how do we implement this so the method that we",
    "start": "356979",
    "end": "362770"
  },
  {
    "start": "359000",
    "end": "513000"
  },
  {
    "text": "propose is called Gonet it takes us input an image of the environment as you saw before and then internally is going",
    "start": "362770",
    "end": "369250"
  },
  {
    "text": "to generate an image that looks like the input but that also is constrained to look traversable okay how do we do this",
    "start": "369250",
    "end": "377800"
  },
  {
    "text": "so have you ever heard about generative adversarial networks before raise your",
    "start": "377800",
    "end": "382930"
  },
  {
    "text": "hand yeah so I don't even have to explain this so what's happening here is we have lots of positive examples right",
    "start": "382930",
    "end": "390099"
  },
  {
    "text": "we can use a gun to train a generator function that given some noise input",
    "start": "390099",
    "end": "396699"
  },
  {
    "text": "will give us an image that looks like a positive example right but then in order to make this image that is being",
    "start": "396699",
    "end": "403360"
  },
  {
    "text": "generated similar to the input then we also train an inverse generator function once the generator is fixed in order to",
    "start": "403360",
    "end": "410440"
  },
  {
    "text": "find what should be the noise that we pass to the generator so that we get something that looks similar to the input okay what",
    "start": "410440",
    "end": "418150"
  },
  {
    "text": "does this mean in practice well if your input is actually traversable then the two images will look similar but if your",
    "start": "418150",
    "end": "424630"
  },
  {
    "text": "input is not then the two images will look more different because the images are clones trying to look as if they",
    "start": "424630",
    "end": "430990"
  },
  {
    "text": "were traversable and so based on that we can use very simple features even like the difference between the images pixel",
    "start": "430990",
    "end": "437500"
  },
  {
    "text": "wise in order to finally classify whether the input image is traversable or not here using a small set of",
    "start": "437500",
    "end": "443800"
  },
  {
    "text": "positive and negative examples and so why does this work well this process in",
    "start": "443800",
    "end": "449620"
  },
  {
    "text": "a way is sort of rejecting the input space into space that hopefully is easier to classify based on these",
    "start": "449620",
    "end": "456100"
  },
  {
    "text": "features okay you can think about it that way now here's an example of how this looks in a video so what you're",
    "start": "456100",
    "end": "462940"
  },
  {
    "text": "gonna see on the left is the input image captured from a robot on the right you have the predicted image and then in the",
    "start": "462940",
    "end": "468340"
  },
  {
    "text": "bottom you have the probability that that space is traversable as the robot starts is in front of an open hallway so",
    "start": "468340",
    "end": "474340"
  },
  {
    "text": "the two images look more similar what's gonna happen next is that the Robo is gonna turn towards the elevator pay",
    "start": "474340",
    "end": "479560"
  },
  {
    "text": "attention there because then the images will change a lot okay so now something",
    "start": "479560",
    "end": "486340"
  },
  {
    "text": "boom the elevator disappears it looks like a hallway again and even the person that you're gonna see here also becomes",
    "start": "486340",
    "end": "492670"
  },
  {
    "text": "sort of static element and it's not until the robot goes back into the hallway that images look more similar",
    "start": "492670",
    "end": "498360"
  },
  {
    "text": "that's one actually helps detect reversibility okay you can see even the",
    "start": "498360",
    "end": "505870"
  },
  {
    "text": "paintings in the walls disappear because they're not coming across the data set right paintings might be specific to",
    "start": "505870",
    "end": "510880"
  },
  {
    "text": "specific places now um the original method that we designed here it assumed",
    "start": "510880",
    "end": "517270"
  },
  {
    "text": "that all the images are independent you know every time you get an image you run your your particular method and you get",
    "start": "517270",
    "end": "523060"
  },
  {
    "text": "a prediction but this is of course not true for images captured by a robot because well the images are going to be",
    "start": "523060",
    "end": "529960"
  },
  {
    "text": "correlated across time and you actually have video and so in order to account for this what we did was we added a",
    "start": "529960",
    "end": "535630"
  },
  {
    "text": "recurring neural network to the method in order to enforce temporal consistency of predictions the other thing that we",
    "start": "535630",
    "end": "542830"
  },
  {
    "text": "tried was actually adding too cameras to the robot and here the hypothesis was well we have two views",
    "start": "542830",
    "end": "548770"
  },
  {
    "text": "hopefully we can detect the differences between the views and this will give us a hint as to whether things that",
    "start": "548770",
    "end": "554280"
  },
  {
    "text": "perceptually look as if it was reversible but actually look differently two cameras are at a given distance from",
    "start": "554280",
    "end": "560530"
  },
  {
    "text": "the robot so this is basically trying to use implicitly disparity among the images to try to predict reversibility",
    "start": "560530",
    "end": "567220"
  },
  {
    "text": "and so here you have some quantitative results on a data set that was collected",
    "start": "567220",
    "end": "572530"
  },
  {
    "start": "568000",
    "end": "656000"
  },
  {
    "text": "at Stanford Business any future is actually available online so if you google Bonett you'll get access to all",
    "start": "572530",
    "end": "578020"
  },
  {
    "text": "of the data if you want to play with it what we're comparing against here is having a Kinect on the robot which is",
    "start": "578020",
    "end": "584650"
  },
  {
    "text": "sort of the standard approach that you might use if you have the type of robot that we had before the Kinect is nice",
    "start": "584650",
    "end": "589930"
  },
  {
    "text": "because it has a depth image that already tells you an information about how far things are then the second",
    "start": "589930",
    "end": "598000"
  },
  {
    "text": "method here this time is network is basically state-of-the-art features for object detection and now assemble for",
    "start": "598000",
    "end": "604660"
  },
  {
    "text": "the two images together in order to predict reversibility and then you have the basic version of Gonet the one with",
    "start": "604660",
    "end": "611170"
  },
  {
    "text": "temporal consistency and then the one that uses the the two views and so in general going it to perform really well",
    "start": "611170",
    "end": "617820"
  },
  {
    "text": "what was surprising to me though is that here the Kinect did not perform better and I think this has a lot to do with",
    "start": "617820",
    "end": "623140"
  },
  {
    "text": "the type of images that we were using which have a very wild field of view versus the Kinect which has also a way",
    "start": "623140",
    "end": "629050"
  },
  {
    "text": "narrow field of view and as well sometimes the noise in the depth of that sensor is pretty noisy yeah and yes they",
    "start": "629050",
    "end": "642010"
  },
  {
    "text": "probably complement each other so I would not say you know you should remove all of your lighters and depth sensors",
    "start": "642010",
    "end": "648310"
  },
  {
    "text": "from your robots and then put this on I would not recommend that at all I would say probably you want to have this as an additional source of information all",
    "start": "648310",
    "end": "657220"
  },
  {
    "start": "656000",
    "end": "745000"
  },
  {
    "text": "right so let me show you some examples here actually in this building so this is the robot that in this case an",
    "start": "657220",
    "end": "664150"
  },
  {
    "text": "operator is controlling and what the operator is doing is basically sending velocity commands to the robot and",
    "start": "664150",
    "end": "669900"
  },
  {
    "text": "internally we're using Gonet to stop linear velocity commands that will keep moving the robot forward whenever the",
    "start": "669900",
    "end": "676690"
  },
  {
    "text": "probability of traverse ability goes and so in this particular case the operator is kind of telling the robot to",
    "start": "676690",
    "end": "683080"
  },
  {
    "text": "go against the glass wall and if you see that red tape here this is because we're using only one camera sometimes you'll",
    "start": "683080",
    "end": "688900"
  },
  {
    "text": "see a video with the two cameras and those those are actually the fish our view is that then you saw before so that",
    "start": "688900",
    "end": "700810"
  },
  {
    "text": "stop was actually going now you might wonder well how can this do this if this is actually glass right sometimes we",
    "start": "700810",
    "end": "707560"
  },
  {
    "text": "even bump into glass and so my my hint here is that actually this line on the ground is is very informative for what's",
    "start": "707560",
    "end": "714190"
  },
  {
    "text": "happening here's another example now here we're using the two cameras you can see the operator on the right so we did",
    "start": "714190",
    "end": "722080"
  },
  {
    "text": "a bunch of experiments where we just threw things in front of the robot trying to see would stop not everything is perfect though for instance in this",
    "start": "722080",
    "end": "729640"
  },
  {
    "text": "case it stops there is that piece of cable under the road which you could claim it's a problem so anything that is",
    "start": "729640",
    "end": "735400"
  },
  {
    "text": "really small anything that looks very similar to the ground of course because of visual features can be an issue so",
    "start": "735400",
    "end": "740530"
  },
  {
    "text": "that's why I was saying probably it's good that you complement this with other approaches now the fun experiment here",
    "start": "740530",
    "end": "746830"
  },
  {
    "start": "745000",
    "end": "816000"
  },
  {
    "text": "is that all the data we use to train this method was collected indoors and at some point the the first authors of this",
    "start": "746830",
    "end": "754390"
  },
  {
    "text": "paper they decided to try out well what happens if we actually run it outdoors um and so what happened here was we have",
    "start": "754390",
    "end": "761500"
  },
  {
    "text": "a person this is noriaki first author of the paper he is holding now the fisheye",
    "start": "761500",
    "end": "766720"
  },
  {
    "text": "camera as if he was a robot he is also blindfolded and holding the laptop in a",
    "start": "766720",
    "end": "772630"
  },
  {
    "text": "backpack and then what we did was we connected the output of gonna to a voice",
    "start": "772630",
    "end": "777880"
  },
  {
    "text": "alert so that whenever the Traverse ability estimation went down the probability went down then the system",
    "start": "777880",
    "end": "784450"
  },
  {
    "text": "you know and advised the user so let me show you how this looked in this case",
    "start": "784450",
    "end": "791070"
  },
  {
    "text": "now this is surprising that it works at all we've ever worked in in deep learning because there were no images",
    "start": "798749",
    "end": "805509"
  },
  {
    "text": "outdoors in the data set that we were using and so in a way this was actually very very telling for us that this",
    "start": "805509",
    "end": "810759"
  },
  {
    "text": "method has potential to generalize to new situations than what he has seen before all right so that's my story",
    "start": "810759",
    "end": "818470"
  },
  {
    "start": "816000",
    "end": "867000"
  },
  {
    "text": "about reversibility estimation I'm now going to switch gears to say now that",
    "start": "818470",
    "end": "823899"
  },
  {
    "text": "you can stop moving and start thinking about how to get to a place this is what we normally called a be navigation and I'm saying here this",
    "start": "823899",
    "end": "832269"
  },
  {
    "text": "is social because we not only care about getting to that destination but we care about getting there in a way that",
    "start": "832269",
    "end": "838329"
  },
  {
    "text": "hopefully feels appropriate for the people nearby in a way that you know we considered to be socially acceptable and",
    "start": "838329",
    "end": "844230"
  },
  {
    "text": "so for this work the main assumptions are that one we have a map of the environment okay so we",
    "start": "844230",
    "end": "850660"
  },
  {
    "text": "don't have to solve mapping we also can localize the robot so that we know given that map where it is at any given time",
    "start": "850660",
    "end": "857230"
  },
  {
    "text": "and we can also detect people and track them and that tells us relative to the",
    "start": "857230",
    "end": "862779"
  },
  {
    "text": "robot where individuals that might matter for the navigation task now if",
    "start": "862779",
    "end": "868089"
  },
  {
    "start": "867000",
    "end": "1043000"
  },
  {
    "text": "you were to implement this with sort of a regular system this is what it might look like this is a hierarchical",
    "start": "868089",
    "end": "874089"
  },
  {
    "text": "controller where you would have a global planner that takes that map the goal where you want to go and your current",
    "start": "874089",
    "end": "880269"
  },
  {
    "text": "location and say okay this is general direction that you want to follow and then you will have a reactive controller that would take sensor data and then",
    "start": "880269",
    "end": "887019"
  },
  {
    "text": "predict velocities both linear and angular velocity to adapt to the things that were not in your map to the things",
    "start": "887019",
    "end": "893169"
  },
  {
    "text": "are dynamic in the environment and so in practice this looks something like this",
    "start": "893169",
    "end": "899379"
  },
  {
    "text": "so say this is your robot and then here all the green lines are lighter returns",
    "start": "899379",
    "end": "904720"
  },
  {
    "text": "so you have a sensor that measures distance and based on where the robot is and whatever this sensor says then you",
    "start": "904720",
    "end": "910869"
  },
  {
    "text": "can start computing costs for your environment that allows that reactive controller to basically figure out how",
    "start": "910869",
    "end": "917980"
  },
  {
    "text": "you should move around the environment to not collide with all of these different elements if you have something",
    "start": "917980",
    "end": "923379"
  },
  {
    "text": "like in person you might assign special class to it to for instance model personal space even model interactions",
    "start": "923379",
    "end": "929589"
  },
  {
    "text": "if you know that people are coming together and so on now what is the challenge of",
    "start": "929589",
    "end": "935440"
  },
  {
    "text": "these approaches well it turns out that depending where you want to run your robot depending on the type of social",
    "start": "935440",
    "end": "942040"
  },
  {
    "text": "context you might want to set different costs for the things in your environment and there might be a lot of hyper",
    "start": "942040",
    "end": "948850"
  },
  {
    "text": "parameter tuning that you have to do in order to find what is the right set of costs that will give you the behavior",
    "start": "948850",
    "end": "953950"
  },
  {
    "text": "that you actually want at the end of the day and so because of all that tuning that has to go on recent methods have",
    "start": "953950",
    "end": "960280"
  },
  {
    "text": "started to look at implementing that reactive controller now using machine learning right the hope is that well we",
    "start": "960280",
    "end": "967000"
  },
  {
    "text": "can now optimize for what those parameters should be as a function of where the robot wants to go and sensor",
    "start": "967000",
    "end": "972880"
  },
  {
    "text": "data and in general if you do this would say imitation learning the other assumption is that the example data that",
    "start": "972880",
    "end": "979420"
  },
  {
    "text": "you have it encodes what it means for the robot to navigate appropriately and that also saves us from actually having",
    "start": "979420",
    "end": "985900"
  },
  {
    "text": "to explicitly write down what it means for the robot to navigate in a good way based on on people's opinions now",
    "start": "985900",
    "end": "993160"
  },
  {
    "text": "remember this is a big assumption so ultimately we always want to test after the fact with people to check if what is",
    "start": "993160",
    "end": "999190"
  },
  {
    "text": "happening kind of makes sense and so what we're doing is work is take a similar approach to this but we add a",
    "start": "999190",
    "end": "1005670"
  },
  {
    "text": "structure to this problem such then one we can have a little bit more interpretability as to what's happening",
    "start": "1005670",
    "end": "1011670"
  },
  {
    "text": "under the hood and second hopefully we get to a better behavior than you would get with just a black box um and so in",
    "start": "1011670",
    "end": "1017790"
  },
  {
    "text": "this case what we have is a local planner that will predict a modification",
    "start": "1017790",
    "end": "1023070"
  },
  {
    "text": "to the global plan this is what we call the local plan and that's going to adapt again to the dynamics of the environment",
    "start": "1023070",
    "end": "1028770"
  },
  {
    "text": "and then we're going to have a velocity controller that takes that local plan information F G here is features from",
    "start": "1028770",
    "end": "1035100"
  },
  {
    "text": "the global plan and information from the sensors here this is lighter information to then output velocity commands for the",
    "start": "1035100",
    "end": "1041370"
  },
  {
    "text": "robot and so how does that look in practice here is a video of a simulation",
    "start": "1041370",
    "end": "1046850"
  },
  {
    "start": "1043000",
    "end": "1212000"
  },
  {
    "text": "we have pedestrian simulated pedestrians moving around we have static obstacles",
    "start": "1046850",
    "end": "1052110"
  },
  {
    "text": "we have a role that we want the robot to reach and a global plan that was computed based on the map of the",
    "start": "1052110",
    "end": "1057150"
  },
  {
    "text": "environment now that this global plan is not ideal because it's actually coming very close to a person in that point but",
    "start": "1057150",
    "end": "1062490"
  },
  {
    "text": "that person is not in the map so there's no way the high-level planner knows that and then what the robot has to do is predict",
    "start": "1062490",
    "end": "1070020"
  },
  {
    "text": "based on all that information what velocities it should actually execute in order to get to the destination now our",
    "start": "1070020",
    "end": "1076620"
  },
  {
    "text": "approach also outputs this predicted local plan which is a visualization in a way of how the robot is going to be",
    "start": "1076620",
    "end": "1081840"
  },
  {
    "text": "moving in the environment it doesn't have to follow it perfectly but it kind of hints to you how the robot is going",
    "start": "1081840",
    "end": "1087090"
  },
  {
    "text": "to go about what's seeing at that point so if things are going well you should see that local plan sort of adapting to",
    "start": "1087090",
    "end": "1093840"
  },
  {
    "text": "the dynamic elements and eventually when the robot that reaches to go police stops stops and and it reach the",
    "start": "1093840",
    "end": "1100710"
  },
  {
    "text": "destination now one of the challenges when we were working on this problem that came about I think this is a common",
    "start": "1100710",
    "end": "1106950"
  },
  {
    "text": "challenge in general in HCI as soon as you start working with many different types of sensor data is how should we",
    "start": "1106950",
    "end": "1112980"
  },
  {
    "text": "combine all the information that is coming in into our modules here about the local planner and the velocity",
    "start": "1112980",
    "end": "1118470"
  },
  {
    "text": "controller and sort of the standard thing that you might do is just concatenate all the features together into a bigger feature vector and then",
    "start": "1118470",
    "end": "1124680"
  },
  {
    "text": "process that along now what happened in our case is that we just did this the robot would pay attention to one thing",
    "start": "1124680",
    "end": "1130950"
  },
  {
    "text": "more than the other and so we said ah let's be smart let's add more features for the things that is not paying",
    "start": "1130950",
    "end": "1136230"
  },
  {
    "text": "attention to and they would actually pay a lot of attention to those things and not the other things that it was paying attention to originally and so because",
    "start": "1136230",
    "end": "1143730"
  },
  {
    "text": "of that we decided to go with sort of a dynamic set of combination for these",
    "start": "1143730",
    "end": "1149790"
  },
  {
    "text": "features what we're doing is computing attention coefficients for each of them",
    "start": "1149790",
    "end": "1154800"
  },
  {
    "text": "as a function of what their values are and in this way based on whatever the context is where the robot is navigating",
    "start": "1154800",
    "end": "1161190"
  },
  {
    "text": "it would basically scale some features more than the others to pay more attention to that particular source",
    "start": "1161190",
    "end": "1166680"
  },
  {
    "text": "information so let me show you here how this looks so this is a plot for the",
    "start": "1166680",
    "end": "1172590"
  },
  {
    "text": "inputs to the velocity controller and then on the y-axis you have that attention coefficient for each of them",
    "start": "1172590",
    "end": "1177980"
  },
  {
    "text": "when the robot starts moving when it's close to a dynamic element the ladder becomes more important as the robot",
    "start": "1177980",
    "end": "1184980"
  },
  {
    "text": "starts basically moving around free space than the local plan what it has to follow becomes more relevant and then at",
    "start": "1184980",
    "end": "1191640"
  },
  {
    "text": "the end when it starts approaching the global plan then the global plan the the",
    "start": "1191640",
    "end": "1197160"
  },
  {
    "text": "end destination in the global plan comes more relevant as it was nice to see right even though we were not supervising these attention coefficients",
    "start": "1197160",
    "end": "1204180"
  },
  {
    "text": "this is something that could be learned from data based on how the example trajectories that we had to train this",
    "start": "1204180",
    "end": "1210000"
  },
  {
    "text": "model look like now we compare this method against other approaches in",
    "start": "1210000",
    "end": "1216840"
  },
  {
    "start": "1212000",
    "end": "1367000"
  },
  {
    "text": "particular sort of a classical approach like the one that I described before where you Huntoon the costs for things in your environment and also to deep",
    "start": "1216840",
    "end": "1224070"
  },
  {
    "text": "learning methods that kind of work as a black box the first one here just takes one point along the high-level plan that",
    "start": "1224070",
    "end": "1233100"
  },
  {
    "text": "robot has and this point is at a fixed trajectory at a fixed distance from the robot and then the one over here",
    "start": "1233100",
    "end": "1238470"
  },
  {
    "text": "actually takes a sequence of points from where the robot is up to a given distance and then we compare that with",
    "start": "1238470",
    "end": "1244740"
  },
  {
    "text": "our proposed approach here's an example um video of all of these methods running",
    "start": "1244740",
    "end": "1250830"
  },
  {
    "text": "in practice what you see is that in general our approach is not necessarily",
    "start": "1250830",
    "end": "1255990"
  },
  {
    "text": "the most efficient but it definitely can handle sort of variations in the",
    "start": "1255990",
    "end": "1261060"
  },
  {
    "text": "locality of the robot and it can adjust the things that are happening by that we're not this is not really part of the",
    "start": "1261060",
    "end": "1266100"
  },
  {
    "text": "plan in this particular case these two other deep learning methods kind of got stuck this doesn't happen all the time",
    "start": "1266100",
    "end": "1271890"
  },
  {
    "text": "this is just one example but what you can see is for instance here even even",
    "start": "1271890",
    "end": "1277380"
  },
  {
    "text": "this was troublesome because the robot came very close to a person there what you can see is that in general this is a",
    "start": "1277380",
    "end": "1283020"
  },
  {
    "text": "very complex problem and part of what makes it successful for a robot to to do",
    "start": "1283020",
    "end": "1288300"
  },
  {
    "text": "a good job here has to do with that spatial reasoning that we normally do without even thinking about it so quantitatively how did this method do",
    "start": "1288300",
    "end": "1297270"
  },
  {
    "text": "so what we have here are four different environments where we tested how I was",
    "start": "1297270",
    "end": "1302580"
  },
  {
    "text": "doing this is an environment that was very similar to the training data and so we would expect if we're doing things right that these numbers will all be",
    "start": "1302580",
    "end": "1308820"
  },
  {
    "text": "high even the parameters that we set for the navigation stack were chosen based on this particular environment now if",
    "start": "1308820",
    "end": "1315780"
  },
  {
    "text": "you go to a simpler environment where you have fewer obstacles fewer people same layout then most methods perform",
    "start": "1315780",
    "end": "1322710"
  },
  {
    "text": "better are a little bit down but when you keep increasing the complexity of",
    "start": "1322710",
    "end": "1327900"
  },
  {
    "text": "the environments you either add more people or you move to a new layout that's where actually benefits I think of machine learning",
    "start": "1327900",
    "end": "1333580"
  },
  {
    "text": "start showing up and the particular structure that we gave to this problem this I must say this is in terms of how",
    "start": "1333580",
    "end": "1340210"
  },
  {
    "text": "often the the robot reach tickle on a number of trials that's what this plot is showing now in this case we were",
    "start": "1340210",
    "end": "1346840"
  },
  {
    "text": "looking at how after me the robot come close to almost or near by a collision including collisions I'm here the",
    "start": "1346840",
    "end": "1353320"
  },
  {
    "text": "threshold for concern in near collision was 0.3 meters and what you can see is",
    "start": "1353320",
    "end": "1358420"
  },
  {
    "text": "that in general the navigation stack is sort of the most conservative of all with our method being the most conservative out of the ones that are",
    "start": "1358420",
    "end": "1364840"
  },
  {
    "text": "used in deep learning in this case now as I said before it's important that we understand if the end resolver if the",
    "start": "1364840",
    "end": "1372310"
  },
  {
    "start": "1367000",
    "end": "1486000"
  },
  {
    "text": "behaviors that were rendering kind of makes sense to people so the first time that we did here was actually evaluate",
    "start": "1372310",
    "end": "1378160"
  },
  {
    "text": "this perception using mechanical trick and for that we showed 12 different scenarios with these four methods two",
    "start": "1378160",
    "end": "1384340"
  },
  {
    "text": "people in particular we had 30 by 35 people evaluated all of these methods what we found in this case was that in",
    "start": "1384340",
    "end": "1392380"
  },
  {
    "text": "general the approaches were considered to be natural with the one of the black box the learning methods mean the most",
    "start": "1392380",
    "end": "1399460"
  },
  {
    "text": "unnatural system one actually had a trajectory as input we also found that",
    "start": "1399460",
    "end": "1404500"
  },
  {
    "text": "methods tend to not be considered an aggressive note that this is evaluating videos right so it's not 100% telling",
    "start": "1404500",
    "end": "1410110"
  },
  {
    "text": "you the full story but at least it was good to see that is these numbers were low and also we found that our",
    "start": "1410110",
    "end": "1416860"
  },
  {
    "text": "particular approach was considered to be efficient more efficient in comparison to other methods these two differences",
    "start": "1416860",
    "end": "1423310"
  },
  {
    "text": "were marginally significant and this to me actually was surprising because when you look at the method is really not",
    "start": "1423310",
    "end": "1428830"
  },
  {
    "text": "rendering sort of the the minimum path but it seems like the way that is adapting to the environment people",
    "start": "1428830",
    "end": "1434890"
  },
  {
    "text": "consider it to be more efficient than the other approaches now how long does",
    "start": "1434890",
    "end": "1440170"
  },
  {
    "text": "this transfer to the real world well we don't know yet we're trying to answer that question this is a very very",
    "start": "1440170",
    "end": "1446020"
  },
  {
    "text": "early video of the robot executing the policy that we train his simulation it's",
    "start": "1446020",
    "end": "1451300"
  },
  {
    "text": "not perfect but at least we're starting to see cases where hopefully we can run this on the real robot which is in",
    "start": "1451300",
    "end": "1456820"
  },
  {
    "text": "general a hard thing to do in robotics because transferring from simulation to to real world is difficult because of",
    "start": "1456820",
    "end": "1463000"
  },
  {
    "text": "the differences in the input distributions one biggest challenges here I must say is actually people tracking which is not as",
    "start": "1463000",
    "end": "1469910"
  },
  {
    "text": "consistent as it obviously happened in simulation and so now you see this robot around be careful because we might be",
    "start": "1469910",
    "end": "1477050"
  },
  {
    "text": "testing you know the new approaches that we're implementing on it don't assume that the robot works perfectly which",
    "start": "1477050",
    "end": "1482720"
  },
  {
    "text": "many people sort of do all right now I'm moving on I want to talk about an even",
    "start": "1482720",
    "end": "1489740"
  },
  {
    "start": "1486000",
    "end": "1598000"
  },
  {
    "text": "higher level sort of sort of reasoning problems which have to do with understanding human spatial behavior for",
    "start": "1489740",
    "end": "1496790"
  },
  {
    "text": "the purposes of of interacting and this problem this is something that I started working on while I was a PhD student I",
    "start": "1496790",
    "end": "1503750"
  },
  {
    "text": "was working here with Disney and we had made this furniture robot that we wanted to show two groups of kids that came to",
    "start": "1503750",
    "end": "1509840"
  },
  {
    "text": "to the laboratory and so the whole setup was as follows so people came to the laboratory they start interacting with",
    "start": "1509840",
    "end": "1516370"
  },
  {
    "text": "the robot they didn't know I was gonna be there and sort of the storyline of the interaction build up to a point",
    "start": "1516370",
    "end": "1522440"
  },
  {
    "text": "where the robot gave them a set of souvenirs for having come to the lab and then soon after after they got this",
    "start": "1522440",
    "end": "1528980"
  },
  {
    "text": "piece of paper that you see here crazy things happen people did not pay attention to the robot anymore you know",
    "start": "1528980",
    "end": "1535610"
  },
  {
    "text": "the members of the conversations change even more new conversations started right in front of the robot even though",
    "start": "1535610",
    "end": "1540830"
  },
  {
    "text": "it was still speaking and trying to engage the children in that environment and so when this happened we kept",
    "start": "1540830",
    "end": "1549110"
  },
  {
    "text": "wondering right why can't we do in order to enable robots to understand that these interacting groups are actually",
    "start": "1549110",
    "end": "1555170"
  },
  {
    "text": "changing right in front of it and you know it might be that the environment is noisy but it's very clear for us even",
    "start": "1555170",
    "end": "1560960"
  },
  {
    "text": "from these pictures that these groups are changing right and so now the the interesting bit here is that as we were",
    "start": "1560960",
    "end": "1568250"
  },
  {
    "text": "watching videos special arrangements kept emerging like very regular special",
    "start": "1568250",
    "end": "1573320"
  },
  {
    "text": "arrangements like side-to-side or face-to-face or circular arrangements whenever these conversations were",
    "start": "1573320",
    "end": "1579170"
  },
  {
    "text": "happening and turns out this should not be a surprise there's lots of work in social psychology that described the way",
    "start": "1579170",
    "end": "1584900"
  },
  {
    "text": "that we position ourselves relative to one another during these social interactions what we try to do in",
    "start": "1584900",
    "end": "1589940"
  },
  {
    "text": "general is maximize our opportunities to monitor one another mutual perceptions and this naturally results in these",
    "start": "1589940",
    "end": "1596630"
  },
  {
    "text": "types of formations how does this work in practice so we all",
    "start": "1596630",
    "end": "1602240"
  },
  {
    "start": "1598000",
    "end": "1710000"
  },
  {
    "text": "have what is known as a transactional segment that is used these space that extends forward from our body that",
    "start": "1602240",
    "end": "1608090"
  },
  {
    "text": "includes whatever we're engaged with and whenever we hold conversations we naturally position energy orient",
    "start": "1608090",
    "end": "1614510"
  },
  {
    "text": "ourselves so that we intersect our transactional segments with one another and that way we have equal direct and",
    "start": "1614510",
    "end": "1620450"
  },
  {
    "text": "exclusive access to the space between us and that's what leads to all these different kinds of formations that I",
    "start": "1620450",
    "end": "1626720"
  },
  {
    "text": "assume you're very familiar with now a lot of my work in my PhD focus on very",
    "start": "1626720",
    "end": "1632480"
  },
  {
    "text": "very finely hypothesis that this also happens in human robot interaction and in fact we try this basically in the",
    "start": "1632480",
    "end": "1639200"
  },
  {
    "text": "experiment that I showed you originally also in a case where the robot was playing mafia with groups of people and",
    "start": "1639200",
    "end": "1644720"
  },
  {
    "text": "also in another experiment where people were brainstorming ideas with the robot in all these cases these types of",
    "start": "1644720",
    "end": "1649760"
  },
  {
    "text": "formations tended to emerge and so then the question became how can we recognize",
    "start": "1649760",
    "end": "1654980"
  },
  {
    "text": "these formations automatically using computational methods and at the time the way that we propose to do that is as",
    "start": "1654980",
    "end": "1661610"
  },
  {
    "text": "follows we had information about the position of people in the scene information about their lower body",
    "start": "1661610",
    "end": "1667550"
  },
  {
    "text": "orientation which is sort of the main feature that matters for transactional segments and then we modeled those",
    "start": "1667550",
    "end": "1673490"
  },
  {
    "text": "spaces we try to find whatever the transactional segments of people intersected and then we say ah-ha there is a no space there's probably a group",
    "start": "1673490",
    "end": "1679970"
  },
  {
    "text": "going on now the twist here is that you can also use information about the groups that are happening at any point",
    "start": "1679970",
    "end": "1686120"
  },
  {
    "text": "in time in order to better estimate people's orientation and the reason why this happens is because interactions are",
    "start": "1686120",
    "end": "1692300"
  },
  {
    "text": "naturally a forest that biases the way that people stand in human environments",
    "start": "1692300",
    "end": "1697520"
  },
  {
    "text": "right if I were standing here all the time giving my back to you probably you wouldn't feel so comfortable with all",
    "start": "1697520",
    "end": "1703970"
  },
  {
    "text": "the information that I'm saying because it would not be clear if I'm actually talking to you at this time and so we",
    "start": "1703970",
    "end": "1711050"
  },
  {
    "start": "1710000",
    "end": "1828000"
  },
  {
    "text": "use this particular method in order to study body orientation and gaze here in",
    "start": "1711050",
    "end": "1716360"
  },
  {
    "text": "this particular case we had the robot basically orient in two different ways this is a between subject experiment in",
    "start": "1716360",
    "end": "1723260"
  },
  {
    "text": "one case the robot oriented towards the middle of its conversational group as computer automatically by the method and",
    "start": "1723260",
    "end": "1730410"
  },
  {
    "text": "in our case it turned towards the person who was the speaker or the addressee at that given time and then we also had the",
    "start": "1730410",
    "end": "1737010"
  },
  {
    "text": "robot change its gaze during the interaction and basically we have here four conditions combining each of these",
    "start": "1737010",
    "end": "1744150"
  },
  {
    "text": "variables what we found in this case is that in general when things went wrong",
    "start": "1744150",
    "end": "1749640"
  },
  {
    "text": "this completely disrupted the interaction right people wouldn't know what what is going on and so it's",
    "start": "1749640",
    "end": "1755370"
  },
  {
    "text": "actually very important for robots to conform to the way that people expect them to be positioning themselves in",
    "start": "1755370",
    "end": "1760950"
  },
  {
    "text": "these environments the other thing that was interesting was that the particular gage behavior that we tried influenced",
    "start": "1760950",
    "end": "1767760"
  },
  {
    "text": "the perception of the robot's motion and vice versa and the motion that the robot was executing whether it was orienting",
    "start": "1767760",
    "end": "1774360"
  },
  {
    "text": "towards the middle or it was the attentive orientation behavior it influenced the perception that people",
    "start": "1774360",
    "end": "1779640"
  },
  {
    "text": "had of the gaze of the robot and because of this even though often we designed this behaviour independently of each",
    "start": "1779640",
    "end": "1785880"
  },
  {
    "text": "other I think that we should rather try to do it gently in order to account for these potential effects of one into the",
    "start": "1785880",
    "end": "1792780"
  },
  {
    "text": "other now at the time a lot of the experiments that I did were were simple",
    "start": "1792780",
    "end": "1798330"
  },
  {
    "text": "open spaces and if you look around right there's many environments where the the type of formations that you see they're",
    "start": "1798330",
    "end": "1805050"
  },
  {
    "text": "actually malleable to to that context right if you enter for instance an elevator people might be okay kind of",
    "start": "1805050",
    "end": "1811020"
  },
  {
    "text": "coming closer to one another because well obviously the space is more constrained similarly if you're in a",
    "start": "1811020",
    "end": "1816030"
  },
  {
    "text": "party where there's lots of people around you might actually change the distance is in your proxemics behavior",
    "start": "1816030",
    "end": "1821340"
  },
  {
    "text": "based on what's going on and so because of that then we decided to try in this",
    "start": "1821340",
    "end": "1826830"
  },
  {
    "text": "case again there are driven methods and now reframe the problem as a clustering problem from a certain more classical",
    "start": "1826830",
    "end": "1833700"
  },
  {
    "start": "1828000",
    "end": "1868000"
  },
  {
    "text": "perspective so here say that you have a scene right of people interacting then",
    "start": "1833700",
    "end": "1839520"
  },
  {
    "text": "you can build a graph where every node corresponds to a person and then the engines if they have a weight that way",
    "start": "1839520",
    "end": "1846240"
  },
  {
    "text": "corresponds to how likely it is that people are actually part of the same conversation and so provided you have",
    "start": "1846240",
    "end": "1852450"
  },
  {
    "text": "some algorithm to do graph clustering which which exists for the case of conversational groups then the question",
    "start": "1852450",
    "end": "1858180"
  },
  {
    "text": "that remains is what should be the weights Nia finish then you assign to those edges in the graph so then you end up having a good result when you try to",
    "start": "1858180",
    "end": "1864720"
  },
  {
    "text": "cluster people out right and so for that what we did was we proposed to use a",
    "start": "1864720",
    "end": "1870330"
  },
  {
    "start": "1868000",
    "end": "1967000"
  },
  {
    "text": "neural network again because he has great approximation capabilities in this case for this type of social phenomena",
    "start": "1870330",
    "end": "1876059"
  },
  {
    "text": "and so the way the system works is we haven't seen put a social scene for which we have position and orientation",
    "start": "1876059",
    "end": "1882720"
  },
  {
    "text": "for everybody in that scene then we build a graph that I mentioned before and then for every edge we're going to",
    "start": "1882720",
    "end": "1890909"
  },
  {
    "text": "compute an affinity value that depends on features of the diet that we care",
    "start": "1890909",
    "end": "1896280"
  },
  {
    "text": "about which are just the nodes related to that edge but also on features of all the other",
    "start": "1896280",
    "end": "1901679"
  },
  {
    "text": "people in this scene if this scene was very big then you would just pick the people nearby the edge that you care",
    "start": "1901679",
    "end": "1907440"
  },
  {
    "text": "about and so how does this two transforms look like they actually look very similar and what we have as input",
    "start": "1907440",
    "end": "1913770"
  },
  {
    "text": "is information about the position and the orientation of people here this is for numbers just because we are encoding",
    "start": "1913770",
    "end": "1919799"
  },
  {
    "text": "the orientation with cosine and sine and then the other two numbers are just X and y and then we pass this through a",
    "start": "1919799",
    "end": "1927059"
  },
  {
    "text": "transformation it gives us features in a higher dimensional space and then we use a symmetric function here in the same",
    "start": "1927059",
    "end": "1933480"
  },
  {
    "text": "spirit of Poynette and which was used to reason about point clouds in order to",
    "start": "1933480",
    "end": "1939270"
  },
  {
    "text": "get one feature that is the relevant of the order of the inputs so in this particular case is a magical operation",
    "start": "1939270",
    "end": "1945570"
  },
  {
    "text": "you can use another symmetric operation potentially ok any questions about this",
    "start": "1945570",
    "end": "1951510"
  },
  {
    "text": "now right now once we have all those Affinia is what we can do is we run our",
    "start": "1951510",
    "end": "1958289"
  },
  {
    "text": "clustering algorithm here in particular we use an algorithm called dominant sets which is actually a generalization of",
    "start": "1958289",
    "end": "1965039"
  },
  {
    "text": "maximal cliques for weighted graphs now what kind of results do we get in this",
    "start": "1965039",
    "end": "1970140"
  },
  {
    "start": "1967000",
    "end": "2042000"
  },
  {
    "text": "case so these are two data sets for group detection within the computer vision community the first graph here",
    "start": "1970140",
    "end": "1978030"
  },
  {
    "text": "the first blue bar corresponds to a deep learning method that was proposed very",
    "start": "1978030",
    "end": "1983730"
  },
  {
    "text": "recently this green bar actually corresponds to another algorithm that is similarly reasoning about graphs clustering and then the yellow one is",
    "start": "1983730",
    "end": "1991980"
  },
  {
    "text": "actually state-of-the-art in this particular two data sets now for two",
    "start": "1991980",
    "end": "1997169"
  },
  {
    "text": "years or so and so for the coffee break data set we do as well as state of the art the",
    "start": "1997169",
    "end": "2002800"
  },
  {
    "text": "challenge here is that this dataset has orientations for people that are bent into four possible numbers and that",
    "start": "2002800",
    "end": "2009730"
  },
  {
    "text": "makes it actually really hard to notice small variations in people orientation now in the cocktail party data set where",
    "start": "2009730",
    "end": "2016330"
  },
  {
    "text": "the orientation is actually way way more fine-grained then in this case we",
    "start": "2016330",
    "end": "2022210"
  },
  {
    "text": "actually outperform the state of the art and the nice thing I think of this approach which which makes it very very",
    "start": "2022210",
    "end": "2028570"
  },
  {
    "text": "straightforward to implement is that again we're not finding all the parameters of what exactly should be the",
    "start": "2028570",
    "end": "2034210"
  },
  {
    "text": "transactional segment for every people in the scene which is some of the things that you have to care about for graph",
    "start": "2034210",
    "end": "2040090"
  },
  {
    "text": "codes approach all right so for the remaining time that I have ten minutes",
    "start": "2040090",
    "end": "2046120"
  },
  {
    "start": "2042000",
    "end": "2367000"
  },
  {
    "text": "or so I want to talk about some future research directions which I think we're now going to be able to avoid and others",
    "start": "2046120",
    "end": "2053110"
  },
  {
    "text": "that I just think are interesting and fun to think about so one question that often people ask",
    "start": "2053110",
    "end": "2059950"
  },
  {
    "text": "especially within human robot interaction and I think it's yeah as well is why are we using neural networks",
    "start": "2059950",
    "end": "2066580"
  },
  {
    "text": "and I my answer to this is that well if you look at how well they perform",
    "start": "2066580",
    "end": "2071679"
  },
  {
    "text": "against other learning algorithms there has been a clear advantage and we want to take advantage of that sort of",
    "start": "2071680",
    "end": "2078490"
  },
  {
    "text": "powerful capabilities of these methods the challenge here though is that for most problems that have to do with",
    "start": "2078490",
    "end": "2084460"
  },
  {
    "text": "interaction you're actually in this space where you don't have that much data and so a natural question arises of",
    "start": "2084460",
    "end": "2090639"
  },
  {
    "text": "how do we get more data right so that we can actually take advantage of these methods for for what we want to do for",
    "start": "2090640",
    "end": "2097360"
  },
  {
    "text": "the case of navigation and and in particular for the case of robotics I'm a big advocate for just getting data",
    "start": "2097360",
    "end": "2103780"
  },
  {
    "text": "from the real world I know this is very expensive but I think it's going to be",
    "start": "2103780",
    "end": "2108790"
  },
  {
    "text": "very fruitful in the long term so that's one of the things that we're exploring in particular in the jackrabbit project here at Stanford another thing that you",
    "start": "2108790",
    "end": "2116290"
  },
  {
    "text": "might want to do is actually take advantage of simulations simulations of",
    "start": "2116290",
    "end": "2121420"
  },
  {
    "text": "course are not gonna be perfect even when you think about simulating a person that's very challenging on itself but it",
    "start": "2121420",
    "end": "2127390"
  },
  {
    "text": "might actually allow you to make progress faster and prototype algorithm in a way that hopefully doesn't take",
    "start": "2127390",
    "end": "2133420"
  },
  {
    "text": "forever for you to get an answer of how well things are working this particular type of simulation environments here",
    "start": "2133420",
    "end": "2139900"
  },
  {
    "text": "we're using unity I think there's lots of potential for using all of the different game engines that are coming along that are becoming available now",
    "start": "2139900",
    "end": "2145930"
  },
  {
    "text": "for this kind of work one of the also interesting positive things of these",
    "start": "2145930",
    "end": "2151330"
  },
  {
    "text": "environments is that you can very easily export your games into online form which",
    "start": "2151330",
    "end": "2157120"
  },
  {
    "text": "means that you can potentially engage a bigger amount of people than if you had to bring everybody to your lab to try",
    "start": "2157120",
    "end": "2162250"
  },
  {
    "text": "out your environment and then basically use it in person now in terms of sample",
    "start": "2162250",
    "end": "2168970"
  },
  {
    "text": "efficient methods I think there's also very interesting potential for revisiting ideas from topological",
    "start": "2168970",
    "end": "2175180"
  },
  {
    "text": "navigation for the case of enabling robots to move around human environments",
    "start": "2175180",
    "end": "2181210"
  },
  {
    "text": "and so when I when I'm saying here topological navigation this is what I mean so say the robot wants to go from",
    "start": "2181210",
    "end": "2188110"
  },
  {
    "text": "one place to another sort of us as we want it before but now instead of modeling the environment precisely with",
    "start": "2188110",
    "end": "2194800"
  },
  {
    "text": "a metric map that's kind of what we were assuming we had in the in the prior example we're gonna have a graph and",
    "start": "2194800",
    "end": "2201190"
  },
  {
    "text": "this graph is going to now be a more compact representation of that space here the nodes correspond to places",
    "start": "2201190",
    "end": "2209290"
  },
  {
    "text": "where it's sort of a critical situation where you want to make potentially a change in decision in terms of where",
    "start": "2209290",
    "end": "2214780"
  },
  {
    "text": "you're going so think about it like entry ways or exit ways from from other",
    "start": "2214780",
    "end": "2220210"
  },
  {
    "text": "places even points along a corridor whenever you can change the direction one way or another and then the engines",
    "start": "2220210",
    "end": "2227170"
  },
  {
    "text": "in this particular case encode connectivity that's sort of the classical view of topological navigation",
    "start": "2227170",
    "end": "2232710"
  },
  {
    "text": "now in this particular case the twist of how we're thinking about this taken advantage of data-driven methods is that",
    "start": "2232710",
    "end": "2239380"
  },
  {
    "text": "each of these edges can also correspond to a particular behavior that the robot can execute to go from the source node",
    "start": "2239380",
    "end": "2245770"
  },
  {
    "text": "to the target node and if you think about in their environments there's often lots of things that you do that",
    "start": "2245770",
    "end": "2252640"
  },
  {
    "text": "look very very similar to each other right and so you can potentially have just a small set of behaviors like the",
    "start": "2252640",
    "end": "2258340"
  },
  {
    "text": "ones that you see here that you can then compose with one another in order to get basically a complex now",
    "start": "2258340",
    "end": "2264820"
  },
  {
    "text": "en route and so here for instance we have we're considering turning left behaviors turning right",
    "start": "2264820",
    "end": "2270580"
  },
  {
    "text": "following a corridor finding a door and moving straight now with this five said",
    "start": "2270580",
    "end": "2276460"
  },
  {
    "text": "five behaviors that you see here we can now enable a robot to go from that upper",
    "start": "2276460",
    "end": "2282490"
  },
  {
    "text": "room over there all the way to this room simply by localizing relative to the graph in this",
    "start": "2282490",
    "end": "2288250"
  },
  {
    "text": "particular case using graph neural networks and then executing depending on the edge that you're in the graph that",
    "start": "2288250",
    "end": "2293440"
  },
  {
    "text": "particular visual motor behavior that is a deep learning policy for the robot now",
    "start": "2293440",
    "end": "2298570"
  },
  {
    "text": "note here that the robot is not using this map it's just taken as input this depth image from the environment and the",
    "start": "2298570",
    "end": "2305770"
  },
  {
    "text": "particular behavior that it has to execute and that allows the robot to navigate all the way around to the",
    "start": "2305770",
    "end": "2311980"
  },
  {
    "text": "destination now this word gear does not consider dynamic elements this is all in a static environment but I think if we",
    "start": "2311980",
    "end": "2318670"
  },
  {
    "text": "start thinking about how are we gonna make robots really operating human environments where everybody's going around every time I go to New York City",
    "start": "2318670",
    "end": "2324700"
  },
  {
    "text": "I go to the subway and I see how crazy it is how people are moving I think this type of approaches have slightly better",
    "start": "2324700",
    "end": "2329980"
  },
  {
    "text": "chance than if we assume we're going to have a perfect map metric map of the environment where we're always gonna",
    "start": "2329980",
    "end": "2335050"
  },
  {
    "text": "know precisely where we are because often right all the people around you will look good could you now another",
    "start": "2335050",
    "end": "2341380"
  },
  {
    "text": "sort of positive aspect of this type of work is that the semantics of this",
    "start": "2341380",
    "end": "2346390"
  },
  {
    "text": "behaviour can make an easy connection to natural language directions and so we've",
    "start": "2346390",
    "end": "2352000"
  },
  {
    "text": "also explore taking natural language directions and then translating them to",
    "start": "2352000",
    "end": "2357250"
  },
  {
    "text": "a sequence of behaviors using in this case the topological graph basically as as a database or a knowledge base for",
    "start": "2357250",
    "end": "2365050"
  },
  {
    "text": "this translation task all right now in terms of thinking more about kind of",
    "start": "2365050",
    "end": "2373030"
  },
  {
    "start": "2367000",
    "end": "2629000"
  },
  {
    "text": "classical human robot interaction problems one issue that arises very",
    "start": "2373030",
    "end": "2378370"
  },
  {
    "text": "often when you put a robot in a public space is the following so this is a",
    "start": "2378370",
    "end": "2384250"
  },
  {
    "text": "robot in Japan this is super Bobby and the robot is in a mall and when kids",
    "start": "2384250",
    "end": "2390430"
  },
  {
    "text": "find it they start doing all sorts of crazy things to the robot and so one of",
    "start": "2390430",
    "end": "2396730"
  },
  {
    "text": "the strategies in this work to help the robot was to actually have it move whenever you can move towards",
    "start": "2396730",
    "end": "2402280"
  },
  {
    "text": "the parents of the kids because then you know the the kids will behave a little bit better and so this line of work is",
    "start": "2402280",
    "end": "2409720"
  },
  {
    "text": "actually very interesting right because it poses the question of how can robots take advantage of their social context",
    "start": "2409720",
    "end": "2415750"
  },
  {
    "text": "in order to help themselves in these these kinds of settings and so to explore this question we decided to run",
    "start": "2415750",
    "end": "2422950"
  },
  {
    "text": "a lab experiment where we had a Confederate here the person on the Left",
    "start": "2422950",
    "end": "2428140"
  },
  {
    "text": "interact with the participant which is see on the right and these two people they were said to complete a distraction",
    "start": "2428140",
    "end": "2434619"
  },
  {
    "text": "test mainly a memorization test here on the tablet and while they were doing that there was a robot nearby that",
    "start": "2434619",
    "end": "2441550"
  },
  {
    "text": "happened to be there because they were using him before for something else and the Confederate would fail at the task",
    "start": "2441550",
    "end": "2447550"
  },
  {
    "text": "and then basically release its anger with the robot and then the question was how should the robot behave in order to",
    "start": "2447550",
    "end": "2454480"
  },
  {
    "text": "motivate this person to help you out even a little bit okay so let me show you an example of what what this abuse",
    "start": "2454480",
    "end": "2461470"
  },
  {
    "text": "looked like this was both verbal and physical abuse starting with verbal abuse and then combining verbal and physical this is",
    "start": "2461470",
    "end": "2467080"
  },
  {
    "text": "sort of like the worst case scenario at the end of this session so this is the",
    "start": "2467080",
    "end": "2472089"
  },
  {
    "text": "robot that you see there and so a lot of",
    "start": "2472089",
    "end": "2482560"
  },
  {
    "text": "people were in shock no surprise in terms of what the robot tried to do so",
    "start": "2482560",
    "end": "2488260"
  },
  {
    "text": "in one case this is one of the variables we manipulator which was the response from the robot in West Gaines the robot",
    "start": "2488260",
    "end": "2494500"
  },
  {
    "text": "did absolutely nothing right it was abuse and it just kept doing whatever he was supposed to do in another case in",
    "start": "2494500",
    "end": "2499839"
  },
  {
    "text": "the shutdown response condition it just kind of showed a sad face for a little bit and then he shut down for 10 seconds",
    "start": "2499839",
    "end": "2506200"
  },
  {
    "text": "and then went back up and then kept doing whatever he was doing and then in the emotional response condition the",
    "start": "2506200",
    "end": "2511660"
  },
  {
    "text": "robot first became sad and then angry and the Confederate now the other thing that we manipulated was empathy whether",
    "start": "2511660",
    "end": "2518050"
  },
  {
    "text": "the robot was empathetic to the task that people were doing how well they were doing in it and whether it was just",
    "start": "2518050",
    "end": "2524349"
  },
  {
    "text": "indifferent right he didn't care what was happening well we found in this case was that even though respect any",
    "start": "2524349",
    "end": "2531010"
  },
  {
    "text": "empathetic - in general induce more helping behavior there was no difference across",
    "start": "2531010",
    "end": "2536020"
  },
  {
    "text": "conditions and the majority of the people ended up helping the robot and so this is actually good news for Humanity",
    "start": "2536020",
    "end": "2541990"
  },
  {
    "text": "I think I'm not for experiment necessarily because the results were not as significant but I think it's good",
    "start": "2541990",
    "end": "2547390"
  },
  {
    "text": "that people were actually at the end at least flipping up the robot or even sometimes moving away from the",
    "start": "2547390",
    "end": "2553120"
  },
  {
    "text": "Confederates that hopefully would not abuse it again now in terms of the responses that the robot had in general",
    "start": "2553120",
    "end": "2559480"
  },
  {
    "text": "the shutdown response was the one that led to higher ratings of the perception of the verbal abuse and also higher",
    "start": "2559480",
    "end": "2567520"
  },
  {
    "text": "distress from the participants and so in a way it seemed like they this shutdown response ended up being sort of the more",
    "start": "2567520",
    "end": "2574210"
  },
  {
    "text": "effective out of the ones that we tried now this is just a very small baby step I think it's important to for us to",
    "start": "2574210",
    "end": "2581650"
  },
  {
    "text": "think about this question right how can robots motivate pro-social human behavior and potentially right if they",
    "start": "2581650",
    "end": "2588310"
  },
  {
    "text": "could do this then you can imagine that robots could leverage their social context for practical problems like the",
    "start": "2588310",
    "end": "2593560"
  },
  {
    "text": "one that I that I showed before but maybe they could also potentially just positively impact interactions more than",
    "start": "2593560",
    "end": "2600160"
  },
  {
    "text": "that we could ever imagine from the beginning and so with that I'm going to end thanking everybody that has helped",
    "start": "2600160",
    "end": "2606160"
  },
  {
    "text": "on on the many projects that I showed before especially this time for vision and learning lab there was a lot of a friend bridge that I showed from the lab",
    "start": "2606160",
    "end": "2612460"
  },
  {
    "text": "and also our funding sources to your NSF and Disney and I'll open up for",
    "start": "2612460",
    "end": "2617830"
  },
  {
    "text": "questions thank you [Applause]",
    "start": "2617830",
    "end": "2625819"
  }
]
[
  {
    "start": "0",
    "end": "5630"
  },
  {
    "text": "So today, we will discuss\nabout Huffman codes, which are one of the prefix codes that\nI promised we will talk about",
    "start": "5630",
    "end": "14719"
  },
  {
    "text": "in the lectures. And we will do some examples,\nlook at some real life",
    "start": "14720",
    "end": "21110"
  },
  {
    "text": "applications. So let's get started.",
    "start": "21110",
    "end": "26380"
  },
  {
    "text": "So again, you go\nto the website-- again, remember don't go\nto the last year's website. Go to this year's\nwebsite, fall 2023-2024.",
    "start": "26380",
    "end": "34420"
  },
  {
    "text": "Once you are here,\nclick on Lectures.",
    "start": "34420",
    "end": "39730"
  },
  {
    "text": "And then here you see, we\nhave also released a tutorial. So click on the tutorial. ",
    "start": "39730",
    "end": "46820"
  },
  {
    "text": "So it gives a broad overview\nof SCL, how to install, how to use it.",
    "start": "46820",
    "end": "52220"
  },
  {
    "text": "And then there are sub pages. So there is SCL\nbasic section that",
    "start": "52220",
    "end": "57860"
  },
  {
    "text": "shows you the structure\nof the library, what you can find in the structure. Some of the\ninterfaces, so we try",
    "start": "57860",
    "end": "64550"
  },
  {
    "text": "to have some interfaces that\nare common across a bunch of compressors so that\nlife becomes easy.",
    "start": "64550",
    "end": "69800"
  },
  {
    "text": "We'll see actually for Huffman\ncode today how some of that makes our implementations\nvery easy.",
    "start": "69800",
    "end": "75200"
  },
  {
    "text": "You just need to\nfocus on the logic, not on the all the\nstuff around it.",
    "start": "75200",
    "end": "81080"
  },
  {
    "text": "So data blocks, data\nencoder decoder, probability distribution\nrelated stuff",
    "start": "81080",
    "end": "86240"
  },
  {
    "text": "like getting empirical\ndistributions, computing entropy\nthat sort of thing,",
    "start": "86240",
    "end": "91520"
  },
  {
    "text": "some standard compressors that\nwe implement, some of which-- some others we will implement\nas part of your project",
    "start": "91520",
    "end": "97490"
  },
  {
    "text": "or as your homework. Some utility stuff like\nworking with bits versus bytes",
    "start": "97490",
    "end": "102530"
  },
  {
    "text": "and working with\ntrees and so on. And then there is an exercise.",
    "start": "102530",
    "end": "109460"
  },
  {
    "text": "The exercise is\nactually a question from last year's homework 0,\nwhich we this year decided",
    "start": "109460",
    "end": "116837"
  },
  {
    "text": "to provide as an exercise. So you can just go through\nit with the solution and just see how you\ncan use the library.",
    "start": "116837",
    "end": "125160"
  },
  {
    "text": "So this has questions\nand answers. And there is a Colab\nnotebook linked here, which you can look at, which\njust shows the working example",
    "start": "125160",
    "end": "136299"
  },
  {
    "text": "and the test passing here. You can see. ",
    "start": "136300",
    "end": "144700"
  },
  {
    "text": "OK. Any questions so far\non the announcements on SCL on the homework?",
    "start": "144700",
    "end": "151640"
  },
  {
    "text": "I just add one part,\nso the Colab notebook is also for you\nguys to just see how you can use SCL with Colab\nwhich might be useful for some",
    "start": "151640",
    "end": "159410"
  },
  {
    "text": "of your project stuff even\ngoing ahead, just trying out things on Google Colab. So it's just one\nset of unique code,",
    "start": "159410",
    "end": "166680"
  },
  {
    "text": "and so you can have\na look at that. Yeah. So Pulkit just announced that\nthe Google Colab notebook,",
    "start": "166680",
    "end": "172530"
  },
  {
    "text": "you can-- it has the steps to install\nSCL into a Colab notebook which will be useful for\nyou in your projects.",
    "start": "172530",
    "end": "178890"
  },
  {
    "text": "It was useful for me for\ntoday's lecture actually as I was trying to do a demo. So, yeah, take a look.",
    "start": "178890",
    "end": "184815"
  },
  {
    "text": " OK. Let's move on.",
    "start": "184815",
    "end": "191070"
  },
  {
    "text": "So let's recap very quickly. And in the recap, I\nwon't dwell on things that you don't need\nas much going forward,",
    "start": "191070",
    "end": "197610"
  },
  {
    "text": "more on the things\nthat we'll focus on, so more on the results,\nless on the proofs.",
    "start": "197610",
    "end": "202860"
  },
  {
    "text": "We learnt about\nKraft's inequality. Kraft's inequality was an\nif and only if condition for prefix codes.",
    "start": "202860",
    "end": "208110"
  },
  {
    "text": "So you are a prefix code if\nand only if your lengths-- no not really if and only if.",
    "start": "208110",
    "end": "213160"
  },
  {
    "text": "If you're a prefix\ncode, then your lengths satisfy a certain inequality. And if the lengths satisfies\ncertain inequality,",
    "start": "213160",
    "end": "219090"
  },
  {
    "text": "then you can create a\nprefix code out of it. So that was Kraft's inequality. We won't need it really.",
    "start": "219090",
    "end": "225030"
  },
  {
    "text": "You have a question in\nhomework about proving it for uniquely decodable codes. So good luck with that one.",
    "start": "225030",
    "end": "233700"
  },
  {
    "text": "Entropy. We defined entropy. Entropy is the\nfundamental quantity for lossless compression.",
    "start": "233700",
    "end": "238770"
  },
  {
    "text": "It's the lower bound on the\nbest compression possible.",
    "start": "238770",
    "end": "244920"
  },
  {
    "text": "And it's defined\nas this formula. And you had some quiz\nquestions to help you get more familiar with it.",
    "start": "244920",
    "end": "250409"
  },
  {
    "text": "We talked about joint\nentropy for IID variables where if you have n IID\nvariables x1 through xn, then",
    "start": "250410",
    "end": "256838"
  },
  {
    "text": "their joint entropy, you\ncan do it in two steps. So the first step is that\nthe joint entropy is the sum",
    "start": "256839",
    "end": "262930"
  },
  {
    "text": "of the individual entropies. This step uses independence\nof the random variables. And the second\nstep uses the fact",
    "start": "262930",
    "end": "268840"
  },
  {
    "text": "that they are\nidentically distributed so that the entropy\nof the sum is the n times the entropy\nof a single one.",
    "start": "268840",
    "end": "275080"
  },
  {
    "text": "All of them have\nthe same entropy. And then we define\nKL divergence. I'm very quickly recapping.",
    "start": "275080",
    "end": "281140"
  },
  {
    "text": "If you have questions,\nplease let me know. So KL divergence was\nthis other quantity.",
    "start": "281140",
    "end": "287660"
  },
  {
    "text": "There's two\nvariables p and q, so two probability distributions. It's sort of a distance measure.",
    "start": "287660",
    "end": "294490"
  },
  {
    "text": "So it is greater than or\nequal to 0 with equality",
    "start": "294490",
    "end": "305710"
  },
  {
    "text": "if and only if p is equal to q. And you, again, had some\nquestions in your homework",
    "start": "305710",
    "end": "312850"
  },
  {
    "text": "about this. Then the other big thing\nwe did last lecture was the main result, the real\nmain theorem of compression",
    "start": "312850",
    "end": "322150"
  },
  {
    "text": "that for any prefix code-- in the homework, you will see\nfor any uniquely decodable code--",
    "start": "322150",
    "end": "328310"
  },
  {
    "text": "the expected code length is\nlower bounded by the entropy. So you cannot do better\nthan the entropy.",
    "start": "328310",
    "end": "335120"
  },
  {
    "text": "And the other part was\nthat you can actually achieve entropy\nor get arbitrarily close to entropy if\nyou work with blocks.",
    "start": "335120",
    "end": "341630"
  },
  {
    "text": " Any questions so\nfar on last lecture? ",
    "start": "341630",
    "end": "350300"
  },
  {
    "text": "Let's move on.  Towards the very end\nof the last lecture,",
    "start": "350300",
    "end": "355669"
  },
  {
    "text": "we talked about the\nachievability part, how do you actually\nachieve this.",
    "start": "355670",
    "end": "360680"
  },
  {
    "text": "So the first thing we did was\nwe took the Shannon codes. We know their lengths. We did this calculation with\nthe ceiling function and so on.",
    "start": "360680",
    "end": "367729"
  },
  {
    "text": "And what we got was that the\nexpected length for the Shannon code is sandwiched\nbetween entropy of x",
    "start": "367730",
    "end": "374330"
  },
  {
    "text": "and the entropy of x plus 1.  And we saw some\nexamples and you saw one",
    "start": "374330",
    "end": "382000"
  },
  {
    "text": "in quiz, which we'll see\nshortly, where Shannon codes didn't do as well. You clearly could see that\nShannon codes were very, very",
    "start": "382000",
    "end": "387430"
  },
  {
    "text": "bad. And Shannon codes are\nnot the optimal codes, and we'll look at the optimal\ncode today, the Huffman codes.",
    "start": "387430",
    "end": "395320"
  },
  {
    "text": "The other thing we saw\ntowards the very end was that if you\ncode in blocks of n, then the average code\nlength per symbol",
    "start": "395320",
    "end": "404349"
  },
  {
    "text": "you can achieve using this\nformula we saw just now, this one, that the entropy\nof xn is equal to n",
    "start": "404350",
    "end": "411390"
  },
  {
    "text": "times the entropy of x.  You can get basically\nwithin 1 by n of entropy.",
    "start": "411390",
    "end": "419240"
  },
  {
    "text": "So working with blocks is really\nthe way you get arbitrarily close to entropy.",
    "start": "419240",
    "end": "424460"
  },
  {
    "text": "And it's very important\nworking with blocks. You will see as we go\nthrough the lectures",
    "start": "424460",
    "end": "430100"
  },
  {
    "text": "that there was a\nprogression in compressors. The very early days\ncompressors like Gzip,",
    "start": "430100",
    "end": "435530"
  },
  {
    "text": "they used to do Huffman\ncoding which doesn't work with blocks really. And they didn't get\nvery good results.",
    "start": "435530",
    "end": "442430"
  },
  {
    "text": "And all of the compressors\ntoday, the modern compressors, all of them work with blocks.",
    "start": "442430",
    "end": "447979"
  },
  {
    "text": "But they don't work\nin blocks like the way you worked in blocks when you\ndid your homework question. There are better ways to\nwork with blocks, which",
    "start": "447980",
    "end": "455240"
  },
  {
    "text": "we'll learn about next week. So topic for next week\nwe'll come back to this.",
    "start": "455240",
    "end": "461600"
  },
  {
    "text": "Let's keep going. Let's look at the quiz\nwhich will also help motivate some of\ntoday's questions.",
    "start": "461600",
    "end": "470669"
  },
  {
    "text": "So you have a Bernoulli\np random variable. Bernoulli is like one of\nthe most-- the simplest distributions. So you have 0 and 1.",
    "start": "470670",
    "end": "476820"
  },
  {
    "text": "And probability of 1 is p. Probability of 0 is 1 minus p.",
    "start": "476820",
    "end": "482250"
  },
  {
    "text": "So the first question\nwas, what is the entropy of x as a function of p?",
    "start": "482250",
    "end": "487770"
  },
  {
    "text": "Anybody? ",
    "start": "487770",
    "end": "498600"
  },
  {
    "text": "Anyone wants to-- I assume all of you did it.",
    "start": "498600",
    "end": "504390"
  },
  {
    "text": "OK. Let me write it down. So it is p log-- it's just as a formula,\nnothing very clever.",
    "start": "504390",
    "end": "511740"
  },
  {
    "text": " So this function,\nthis is in literature,",
    "start": "511740",
    "end": "520229"
  },
  {
    "text": "it's sometimes written as h2p. Sometimes it's written as hbp,\nso binary entropy function.",
    "start": "520230",
    "end": "526020"
  },
  {
    "text": "That's what it's often called. And you can even plot\nit as a function of p.",
    "start": "526020",
    "end": "532019"
  },
  {
    "text": "Let's call it as hbp. So what is the value at 0? What is the entropy\nof Bernoulli 0?",
    "start": "532020",
    "end": "538190"
  },
  {
    "start": "538190",
    "end": "546160"
  },
  {
    "text": "Zero. Yeah. I see some people saying\nzero, which is correct. We learnt last lecture\nthat the entropy,",
    "start": "546160",
    "end": "553450"
  },
  {
    "text": "if you have a random variable\nwhich is deterministic, its entropy is 0. There is no randomness.",
    "start": "553450",
    "end": "559210"
  },
  {
    "text": "Bernoulli 0 means that\nit's always equal to 0. It's never 1. So the entropy is 0 at 0.",
    "start": "559210",
    "end": "566440"
  },
  {
    "text": "How about the entropy at 1? When p equal to\n1, so p equal to 1",
    "start": "566440",
    "end": "571810"
  },
  {
    "text": "means that it's always equal\nto 1, never equal to 0. Also zero. Yeah.",
    "start": "571810",
    "end": "577250"
  },
  {
    "text": "A few people said also zero. You can put it in the formula. Remember that p log 1\nby p is defined as 0",
    "start": "577250",
    "end": "583010"
  },
  {
    "text": "when p is equal to 0. So it's also 0 at 1. How about at 1/2? ",
    "start": "583010",
    "end": "591210"
  },
  {
    "text": "Yeah. For 1/2, I hear 1. So 1/2 means that it's\nequally likely to be 0 or 1.",
    "start": "591210",
    "end": "598670"
  },
  {
    "text": "So then the information\ncontent is one bit. It's either 0 or 1\nwith equal probability.",
    "start": "598670",
    "end": "604760"
  },
  {
    "text": "So it's 1 at 1/2. And you can prove in your\ninformation theory course",
    "start": "604760",
    "end": "612750"
  },
  {
    "text": "that it's a concave function. So it looks something like this.",
    "start": "612750",
    "end": "618390"
  },
  {
    "text": "It's symmetric around 1/2 as\nyou can see in the expression as well.",
    "start": "618390",
    "end": "623640"
  },
  {
    "text": "And yeah not much\nto say other than-- you will see this\nfunction a few times.",
    "start": "623640",
    "end": "629280"
  },
  {
    "text": "If you do information theory,\nyou will see it a bit more. It's very flattish\naround 1/2 you will see.",
    "start": "629280",
    "end": "635530"
  },
  {
    "text": "So whether you have a\nBernoulli 1/2 variable or you have a Bernoulli\n0.4 or Bernoulli 0.6, you will see it hardly\nmakes a difference in how",
    "start": "635530",
    "end": "642899"
  },
  {
    "text": "compressible your file becomes. So there are some practical\nobservations around entropies concavity that\nyou might encounter.",
    "start": "642900",
    "end": "650640"
  },
  {
    "text": " OK. Please stop me if any questions.",
    "start": "650640",
    "end": "657520"
  },
  {
    "text": "Then we asked you to do the KL\ndivergence between Bernoulli",
    "start": "657520",
    "end": "664045"
  },
  {
    "text": "p and Bernoulli q. I will just write\ndown the expression.",
    "start": "664045",
    "end": "670589"
  },
  {
    "text": "Please talk to me later if\nyou had any trouble, again",
    "start": "670590",
    "end": "676220"
  },
  {
    "text": "just following the formula. ",
    "start": "676220",
    "end": "683470"
  },
  {
    "text": "OK. Is this correct? OK. I see some nods. Good. OK.",
    "start": "683470",
    "end": "689680"
  },
  {
    "text": "And then we asked you to\ncompute this Bernoulli 0.3 0.7. I assume you computed it.",
    "start": "689680",
    "end": "695230"
  },
  {
    "text": "Just plug it in the formula. So you will see the quiz\nquestions are mostly",
    "start": "695230",
    "end": "700540"
  },
  {
    "text": "meant to make sure\nyou're following what's happening in class. They're not-- most\nof the time, it's",
    "start": "700540",
    "end": "706390"
  },
  {
    "text": "not supposed to require\nvery advanced thinking. ",
    "start": "706390",
    "end": "713300"
  },
  {
    "text": "OK. This one, so what we asked\nfor is, what is the maximum KL divergence between\nBernoulli p and Bernoulli",
    "start": "713300",
    "end": "719750"
  },
  {
    "text": "q if you are allowed to vary\np and q in their entire range of 0 to 1?",
    "start": "719750",
    "end": "726110"
  },
  {
    "text": "What was the answer\nthat people got? ",
    "start": "726110",
    "end": "737740"
  },
  {
    "text": "Now I hear infinity. Yes. Yes. So the KL divergence\ncan be unbounded.",
    "start": "737740",
    "end": "744540"
  },
  {
    "text": "It can be infinity. And in this expression\non the last page,",
    "start": "744540",
    "end": "750600"
  },
  {
    "text": "if you set q to 0 and p to 1,\nthen you get 1 log infinity.",
    "start": "750600",
    "end": "763990"
  },
  {
    "text": " Yeah. So this is infinity.",
    "start": "763990",
    "end": "769780"
  },
  {
    "text": " Not much to say. It's like it goes from 0.",
    "start": "769780",
    "end": "775510"
  },
  {
    "text": "Minimum is 0. When p equal to q, it's 0. And when one of them is 0,\nthen it becomes infinity.",
    "start": "775510",
    "end": "781569"
  },
  {
    "text": " Yeah. You will see that between\nprobability distributions,",
    "start": "781570",
    "end": "787589"
  },
  {
    "text": "there are two very common\nways to measure the distance. One of them is KL divergence.",
    "start": "787590",
    "end": "792959"
  },
  {
    "text": "The other one is something\ncalled total variation distance or L1 distance.",
    "start": "792960",
    "end": "798360"
  },
  {
    "text": "So depending on what\napplication you're working with, you either prefer\none or the other. The total variation\nthing is symmetric.",
    "start": "798360",
    "end": "805177"
  },
  {
    "text": "It's never infinite. It's bounded. It's much nicer in\nterms of its properties,",
    "start": "805177",
    "end": "810600"
  },
  {
    "text": "but this one often works better\nin many of the machine learning applications.",
    "start": "810600",
    "end": "817040"
  },
  {
    "text": "And this one is no. It is not symmetric. You can try out any example. Even if you take p equal\nto 0.3, q equal to 0.7,",
    "start": "817040",
    "end": "826460"
  },
  {
    "text": "you will see that it\nwill be symmetric. But if you take this thing,\nthen it won't be symmetric.",
    "start": "826460",
    "end": "833800"
  },
  {
    "text": " OK. Any questions on\nquestion 1 in the quiz?",
    "start": "833800",
    "end": "839110"
  },
  {
    "text": " Let's move on.",
    "start": "839110",
    "end": "845078"
  },
  {
    "text": "This one, this one will be more\ninteresting for this lecture. ",
    "start": "845078",
    "end": "851140"
  },
  {
    "text": "So you have a Bernoulli 0.001. So it's very high probability,\nit's a 0 and very low",
    "start": "851140",
    "end": "859150"
  },
  {
    "text": "probability that it's a 1. We asked you to make a\nShannon code for this thing.",
    "start": "859150",
    "end": "865150"
  },
  {
    "text": "So you can do this calculation. You have probability of x.",
    "start": "865150",
    "end": "871690"
  },
  {
    "text": "And you can\ncalculate the length, which is log 1 over probability\nof x, the ceiling function.",
    "start": "871690",
    "end": "879430"
  },
  {
    "text": "And you get 1 for\n0 and 10 for 1. So you can now\nassign the codewords. Maybe you call it 1 0 and\nyou call it 100000000.",
    "start": "879430",
    "end": "895180"
  },
  {
    "text": "And then you can calculate\nthe expected code length, which is just 0.999\nmultiplied by 1 plus 0.001",
    "start": "895180",
    "end": "902860"
  },
  {
    "text": "multiplied by 10.  I hope all of you got this.",
    "start": "902860",
    "end": "909600"
  },
  {
    "text": "This is just-- we have been\ndoing this for a few lectures. ",
    "start": "909601",
    "end": "916580"
  },
  {
    "text": "Then we asked you to\ncompute the entropy. Again, the entropy, we\nalready did in question 1. You know how to\ncompute the entropy.",
    "start": "916580",
    "end": "922490"
  },
  {
    "text": "And then we asked you\nto compute expectation of the length\ndivided by entropy. And I got around 88.",
    "start": "922490",
    "end": "930890"
  },
  {
    "text": "I saw some students, I\nthink, we asked, Pulkit, in the question, this\none, the second one,",
    "start": "930890",
    "end": "937130"
  },
  {
    "text": "to give your answer\nto two decimal places. And then if you take both the\nexpected length and the entropy",
    "start": "937130",
    "end": "944930"
  },
  {
    "text": "to two decimal and then you\ndivide them, you don't get it. You get 100 or\nsomething like that. So we can, I guess,\nmake a regret request.",
    "start": "944930",
    "end": "951710"
  },
  {
    "text": "And we will look at it\non an individual basis. ",
    "start": "951710",
    "end": "959420"
  },
  {
    "text": "So the takeaway really is\nthat for this very skewed distribution, Shannon codes are\nnot doing particularly well.",
    "start": "959420",
    "end": "964910"
  },
  {
    "text": "You should be spending\n0.01 bits per symbol. You should be spending\nvery few bits per symbol, but you are spending more\nthan one bit per symbol.",
    "start": "964910",
    "end": "973100"
  },
  {
    "text": "It's like a huge\noverhead, not great. ",
    "start": "973100",
    "end": "978760"
  },
  {
    "text": "OK. So any suggestions? What is the first thing we\ncan do to improve this code? ",
    "start": "978760",
    "end": "986090"
  },
  {
    "text": "We can cut down the code\n[INAUDIBLE] 1 just after 1.",
    "start": "986090",
    "end": "991320"
  },
  {
    "text": "Yeah. So the first suggestion is that\nthis clearly seems suboptimal. Why do we have this huge thing?",
    "start": "991320",
    "end": "997640"
  },
  {
    "text": "So Shannon codes are good. They helped us prove something,\nbut they are not optimal as we have been seeing\nfor a while now.",
    "start": "997640",
    "end": "1004750"
  },
  {
    "text": "So you can cut this down. What will be the expected\nlength after you cut this down?",
    "start": "1004750",
    "end": "1010510"
  },
  {
    "text": " One. The expected will be one because\nboth of the things are one.",
    "start": "1010510",
    "end": "1018020"
  },
  {
    "text": "So it doesn't really\nsolve our problem. Our entropy is 0.011, and we are\nstill using one bit per symbol.",
    "start": "1018020",
    "end": "1023884"
  },
  {
    "text": " So this is the thing I just--\nthis is the optimal code.",
    "start": "1023884",
    "end": "1030157"
  },
  {
    "text": "This is the optimal code. You can't do better than this. If you have two\nsymbols, you have to spend at least\none bit per symbol.",
    "start": "1030158",
    "end": "1035520"
  },
  {
    "text": "So the optimal code here\nis not particularly good. It's one bit per symbol,\nmuch, much bigger",
    "start": "1035520",
    "end": "1043410"
  },
  {
    "text": "than the 0.011 of the entropy.",
    "start": "1043410",
    "end": "1050795"
  },
  {
    "text": "So the other thing we have\nbeen seeing for a few lectures is to do block coding. So let's write it down.",
    "start": "1050795",
    "end": "1057250"
  },
  {
    "text": "What does block\ncoding really mean? So you create this joint\nsymbol, take x1 and x2,",
    "start": "1057250",
    "end": "1065180"
  },
  {
    "text": "two symbols at a time. So you have four\npossibilities 00 01 10 11.",
    "start": "1065180",
    "end": "1070970"
  },
  {
    "text": "Then you compute the\nprobability of these pairs. ",
    "start": "1070970",
    "end": "1076093"
  },
  {
    "text": "How do you compute\nthe probability of a pair from the probability\nof the individual-- from the original distribution?",
    "start": "1076093",
    "end": "1084320"
  },
  {
    "text": "How do you get like p is\n01 in terms of p0 and p1?",
    "start": "1084320",
    "end": "1090990"
  },
  {
    "text": "I'm hearing product. Can anybody explain why product\nis the correct way to do it?",
    "start": "1090990",
    "end": "1097190"
  },
  {
    "text": "Can I always assume that\nproduct of two things is the joint thing?",
    "start": "1097190",
    "end": "1103400"
  },
  {
    "text": "What is the assumption, the\nunderlying assumption here? They're independent. Yeah.",
    "start": "1103400",
    "end": "1108700"
  },
  {
    "text": "So then set is\nthey're independent. So this thing, so px1,x2 is\nequal to px1 times px2 due",
    "start": "1108700",
    "end": "1120850"
  },
  {
    "text": "to independence. So we'll assume independence\nfor the next couple of weeks, and then we'll move on.",
    "start": "1120850",
    "end": "1128200"
  },
  {
    "text": "Independence.  So I did that calculation\nat home, got these numbers.",
    "start": "1128200",
    "end": "1136230"
  },
  {
    "text": "I made the code. This is not a Shannon code. This is actually the optimal\ncode for this distribution,",
    "start": "1136230",
    "end": "1141990"
  },
  {
    "text": "and we'll learn how\nto make this later on. But you can see it makes sense. You give short codewords to\nthe high probability stuff,",
    "start": "1141990",
    "end": "1148710"
  },
  {
    "text": "and you give longer codewords\nto the low probability stuff, hopefully intuitive.",
    "start": "1148710",
    "end": "1154260"
  },
  {
    "text": "And then you can compute\nthe expected length. And when you compute\nit always remember",
    "start": "1154260",
    "end": "1160150"
  },
  {
    "text": "to divide it at the end\nby 2 because now you're doing two symbols at a time. You're doing a block\nof two symbols.",
    "start": "1160150",
    "end": "1166930"
  },
  {
    "text": "So I did this calculation again.  And now you see it's actually\ncloser to the entropy.",
    "start": "1166930",
    "end": "1175180"
  },
  {
    "text": "It's 0.5 instead of\none we had before. Still very far away.",
    "start": "1175180",
    "end": "1181460"
  },
  {
    "text": "0.5 is still roughly 50\ntimes worse than the entropy. Long ways to go.",
    "start": "1181460",
    "end": "1187809"
  },
  {
    "text": "And really you can keep\nincreasing the block size, but it gets unwieldy very soon. The real solution is to\nuse streaming codes, which",
    "start": "1187810",
    "end": "1195010"
  },
  {
    "text": "we'll learn about next week. But for now, let's try\nto understand how did",
    "start": "1195010",
    "end": "1200529"
  },
  {
    "text": "we even get this optimal code. It's not trivial. I give you any\nrandom distribution.",
    "start": "1200530",
    "end": "1205630"
  },
  {
    "text": "We saw Shannon codes\noften do very badly. How do I get the optimal code? And that's the topic\nfor this lecture.",
    "start": "1205630",
    "end": "1213669"
  },
  {
    "text": "So we'll start with some\nconditions for optimal prefix codes, then we'll look\nat the actual code.",
    "start": "1213670",
    "end": "1221529"
  },
  {
    "text": "Then we'll talk about\nHuffman coding in practice. And you will hear some\ninteresting things",
    "start": "1221530",
    "end": "1229019"
  },
  {
    "text": "which you might have heard\nin your algorithms class. So hopefully, this is fun.",
    "start": "1229020",
    "end": "1235590"
  },
  {
    "text": "Any questions so far\nbefore we get started? OK. Let's get started.",
    "start": "1235590",
    "end": "1241220"
  },
  {
    "start": "1241220",
    "end": "1250669"
  },
  {
    "text": "So optimal prefix codes. ",
    "start": "1250670",
    "end": "1257400"
  },
  {
    "text": "So when we talk about optimal\nthings, first thing to define is, what do we mean? What does it mean to be optimal?",
    "start": "1257400",
    "end": "1263640"
  },
  {
    "text": "So in our case,\noptimal means we want to find the minimum lengths\nsuch that you want to minimize--",
    "start": "1263640",
    "end": "1273610"
  },
  {
    "text": "you want to find the\nlength such that this sum, the expected code\nlength is minimized,",
    "start": "1273610",
    "end": "1278650"
  },
  {
    "text": "subject to the prefix free\ncondition or equivalently",
    "start": "1278650",
    "end": "1288400"
  },
  {
    "text": "satisfying Kraft's inequality,\nwhich we saw are equivalent. ",
    "start": "1288400",
    "end": "1295559"
  },
  {
    "text": "So this is the definition\nof optimal prefix codes. And those of you who have done\nconvex optimization or just",
    "start": "1295560",
    "end": "1304920"
  },
  {
    "text": "generally optimization, you\nmight want to go that way. And actually if you do\nthat, you will actually",
    "start": "1304920",
    "end": "1311519"
  },
  {
    "text": "start getting some\nof the thumb rules that we have been looking at. The length should\nbe log 1 over p.",
    "start": "1311520",
    "end": "1316980"
  },
  {
    "text": "In the notes, you will see\nthat if you do the Lagrange multiplier stuff for\nthis one and you proceed,",
    "start": "1316980",
    "end": "1322590"
  },
  {
    "text": "you will actually get the thumb\nrule that we know and love. But today, we will look at\na different way of doing it.",
    "start": "1322590",
    "end": "1329790"
  },
  {
    "text": "So we will define\nsome conditions",
    "start": "1329790",
    "end": "1343960"
  },
  {
    "text": "for optimality after\nwhich it is story time.",
    "start": "1343960",
    "end": "1359169"
  },
  {
    "text": "So there are two\nconditions for optimality. One, this one you\nhave already seen,",
    "start": "1359170",
    "end": "1371340"
  },
  {
    "text": "if the probability\nof a symbol is bigger than the probability\nof another symbol. You should give it a shorter\nor equal length codeword.",
    "start": "1371340",
    "end": "1377480"
  },
  {
    "text": " Otherwise, what\nyou can do is swap.",
    "start": "1377480",
    "end": "1386507"
  },
  {
    "text": "Basically, you can\nswap the codewords and get a better\nexpected length.",
    "start": "1386508",
    "end": "1393260"
  },
  {
    "text": "So this one we\nhave already seen. Let's look at the other one. ",
    "start": "1393260",
    "end": "1399740"
  },
  {
    "text": "The two longest codewords\nhas the same length.",
    "start": "1399740",
    "end": "1416679"
  },
  {
    "text": "This one we have\nnot seen before. Can anybody-- let\nme draw a chord,",
    "start": "1416680",
    "end": "1426129"
  },
  {
    "text": "and then we'll see\nwhat I mean here. ",
    "start": "1426130",
    "end": "1434710"
  },
  {
    "text": "So basically it's\nthis guy and this guy. These are the two longest\ncodewords for this small code",
    "start": "1434710",
    "end": "1442560"
  },
  {
    "text": "that I've drawn. They do not have\nthe same length. One of them has length 2.",
    "start": "1442560",
    "end": "1447900"
  },
  {
    "text": "One of them has length 3. And that means this\ncannot be an optimal code.",
    "start": "1447900",
    "end": "1453210"
  },
  {
    "text": "Why is that? Can anybody explain? ",
    "start": "1453210",
    "end": "1460860"
  },
  {
    "text": "You can move the\nlongest one leg up. ",
    "start": "1460860",
    "end": "1466539"
  },
  {
    "text": "OK. So the one suggestion is\nthat it is not optimal because you can take the\nlongest one and make it shorter.",
    "start": "1466540",
    "end": "1471915"
  },
  {
    "text": " And I guess in the\ndiagram, it's clear.",
    "start": "1471915",
    "end": "1477610"
  },
  {
    "text": "But in general, can you\nargue why that will still leave the code as prefix free? ",
    "start": "1477610",
    "end": "1487060"
  },
  {
    "text": "Because the longest two, the\ndifference between one bit. The last bit would\nallow you to create",
    "start": "1487060",
    "end": "1494020"
  },
  {
    "text": "two codewords of the same\nlength, so the length is same. Yeah. So basically the answer\nis that if you have one",
    "start": "1494020",
    "end": "1501190"
  },
  {
    "text": "codeword-- the longest two\ncodewords are not equal. So the longest codeword,\nyou can basically shorten it to the length of\nthe second longest codeword.",
    "start": "1501190",
    "end": "1510310"
  },
  {
    "text": "And do the math at home\nin peace basically. You will see that it cannot\nviolate the prefix code",
    "start": "1510310",
    "end": "1517539"
  },
  {
    "text": "condition. Why? Because if the longest code was\na suffix of some other code,",
    "start": "1517540",
    "end": "1528110"
  },
  {
    "text": "then-- Basically, let's say after\nshortening the longest code,",
    "start": "1528110",
    "end": "1533509"
  },
  {
    "text": "it becomes a suffix\nof some other code. You can argue that\nit has to be already a suffix in the original code.",
    "start": "1533510",
    "end": "1539360"
  },
  {
    "text": "So it's like-- let\nme write it down, and then I guess you\ncan think about it more.",
    "start": "1539360",
    "end": "1546800"
  },
  {
    "text": "Why still-- so basically, the\nsolution is to cut this part.",
    "start": "1546800",
    "end": "1552140"
  },
  {
    "text": "Why still prefix free? Can you see it? Yeah.",
    "start": "1552140",
    "end": "1557320"
  },
  {
    "text": " If shortening violates\nprefix property,",
    "start": "1557320",
    "end": "1575669"
  },
  {
    "text": "you can argue that original\ncode also violates.",
    "start": "1575670",
    "end": "1585200"
  },
  {
    "text": " If you shorten it and then\nit starts violating suddenly",
    "start": "1585200",
    "end": "1590690"
  },
  {
    "text": "the prefix quality, you can\nargue that the original code must have been already\nviolating it, otherwise, it's not possible that the\nshortening violates it.",
    "start": "1590690",
    "end": "1598730"
  },
  {
    "text": "Think about it it's\nnot very crucial, but really these\nobservations, you will see that Shannon code, the\none we saw a few slides ago,",
    "start": "1598730",
    "end": "1609500"
  },
  {
    "text": "extra dividend, but\nthe Shannon code often doesn't have this condition.",
    "start": "1609500",
    "end": "1615230"
  },
  {
    "text": "Therefore, it is\nnot always optimal. Any questions so far?",
    "start": "1615230",
    "end": "1621200"
  },
  {
    "text": "I guess you understand. Just understand the\nconditions, and the proofs are in the book plus you\ncan think about this.",
    "start": "1621200",
    "end": "1627230"
  },
  {
    "text": "This is relatively\neasy to reason about. ",
    "start": "1627230",
    "end": "1633630"
  },
  {
    "text": "Story time. Huffman codes. So David Huffman was,\nI think, a PhD student.",
    "start": "1633630",
    "end": "1642904"
  },
  {
    "text": " And he was taking a class\non information theory--",
    "start": "1642905",
    "end": "1648000"
  },
  {
    "text": "this was very early days. This was a few years after\nShannon had done his 1948 paper",
    "start": "1648000",
    "end": "1654420"
  },
  {
    "text": "and Robert Fano, another very\nfamous information theorist was the person teaching that\ninformation theory class.",
    "start": "1654420",
    "end": "1661060"
  },
  {
    "text": "So he gave students an option,\neither you do a final exam or you do a project.",
    "start": "1661060",
    "end": "1667169"
  },
  {
    "text": "And true story, it's not a tale. It's a true story. So Huffman thought\nwhy do the final--",
    "start": "1667170",
    "end": "1675600"
  },
  {
    "text": "why do the exam? I will do the project. It will be more fun\nand easier, he thought. And the question was\nbasically [INAUDIBLE]",
    "start": "1675600",
    "end": "1683880"
  },
  {
    "text": "find the optimal prefix code. And Huffman worked very hard.",
    "start": "1683880",
    "end": "1688928"
  },
  {
    "text": "At some point he thought\nit's not possible, but then he cracked it. He solved the problem.",
    "start": "1688928",
    "end": "1695370"
  },
  {
    "text": "And then the Professor\nFano told the students that this was actually\nan open problem. He had just given an open\nproblem as a project problem.",
    "start": "1695370",
    "end": "1705120"
  },
  {
    "text": "So yeah, Huffman\nat some point later said that if he had known\nthat it was an open problem,",
    "start": "1705120",
    "end": "1710309"
  },
  {
    "text": "he probably wouldn't\nhave even tried it. He would have just given up. So sometimes not knowing\nthat it's a tough problem--",
    "start": "1710310",
    "end": "1717990"
  },
  {
    "text": "sometimes we underestimate\nour abilities. And the construction\nis very easy.",
    "start": "1717990",
    "end": "1724050"
  },
  {
    "text": "It's a greedy construction,\nwhich we'll see in a minute. And Fano also had a\ngreedy construction,",
    "start": "1724050",
    "end": "1730710"
  },
  {
    "text": "but that was not\noptimal in many cases. But Huffman's\ngreedy construction, which we will learn about\nis actually optimal.",
    "start": "1730710",
    "end": "1736770"
  },
  {
    "text": "So let's look at the final\nproject of a student. ",
    "start": "1736770",
    "end": "1749770"
  },
  {
    "text": "So what I'm going to\ndo is I will write down the construction for\nyour future reference,",
    "start": "1749770",
    "end": "1756100"
  },
  {
    "text": "then we'll do one\nexample, which I will do. And then we'll do\nanother example, which you will help me with.",
    "start": "1756100",
    "end": "1761380"
  },
  {
    "text": "And then we'll look at\nsome real life examples. So first step is\nto create a list",
    "start": "1761380",
    "end": "1769810"
  },
  {
    "text": "of nodes which is equal to--",
    "start": "1769810",
    "end": "1775550"
  },
  {
    "text": "you have each symbol\nand its probability.",
    "start": "1775550",
    "end": "1780900"
  },
  {
    "text": "So you make a list like this. Then while more\nthan one node left--",
    "start": "1780900",
    "end": "1794715"
  },
  {
    "text": " we'll post the slides as you\nmight have observed, no need",
    "start": "1794715",
    "end": "1802870"
  },
  {
    "text": "to write if you don't want to-- you pick two nodes\nwith least probability,",
    "start": "1802870",
    "end": "1819660"
  },
  {
    "text": "merge the two nodes. And what does merge mean? And we'll look at an example.",
    "start": "1819660",
    "end": "1825305"
  },
  {
    "text": " Create new node.",
    "start": "1825305",
    "end": "1831570"
  },
  {
    "text": " Actually, how many of you\nhave seen a Huffman code",
    "start": "1831570",
    "end": "1836800"
  },
  {
    "text": "in the past? May I ask, where\nhave you seen it?",
    "start": "1836800",
    "end": "1843172"
  },
  {
    "text": "In 106b, our final\nproject, one of the final homeworks we're going\nto do [INAUDIBLE]..",
    "start": "1843172",
    "end": "1848649"
  },
  {
    "text": "I see. I see. How about you?",
    "start": "1848650",
    "end": "1854540"
  },
  {
    "text": "Where I saw-- Huffman code. In my undergrad\ncourse at Berkeley.",
    "start": "1854540",
    "end": "1862600"
  },
  {
    "text": "Right. Yeah. So we'll see that\nHuffman code is one of the classic examples\nof greedy algorithms, which",
    "start": "1862600",
    "end": "1868380"
  },
  {
    "text": "you study in many\ncomputer science classes. So yeah, for those\nwho have not seen,",
    "start": "1868380",
    "end": "1874110"
  },
  {
    "text": "this is a good introduction. So we create a new node with\nthe two nodes as children.",
    "start": "1874110",
    "end": "1885640"
  },
  {
    "text": " Probability equal to sum\nof probability of children.",
    "start": "1885640",
    "end": "1898380"
  },
  {
    "start": "1898380",
    "end": "1904330"
  },
  {
    "text": "And you keep on doing this. It's like a loop. ",
    "start": "1904330",
    "end": "1913390"
  },
  {
    "text": "And the last remaining\nnode is the root.",
    "start": "1913390",
    "end": "1925950"
  },
  {
    "start": "1925950",
    "end": "1931500"
  },
  {
    "text": "And one asterisk, you\nbreak ties arbitrarily.",
    "start": "1931500",
    "end": "1941360"
  },
  {
    "text": " So basically, you\nstart with a list.",
    "start": "1941360",
    "end": "1948030"
  },
  {
    "text": "You keep merging the two lowest\nprobability nodes and you end",
    "start": "1948030",
    "end": "1953280"
  },
  {
    "text": "up with a tree where all\nof your initial symbols are at the leaf of the tree. ",
    "start": "1953280",
    "end": "1961101"
  },
  {
    "text": "Let's do some examples. I think that's the most\nuseful thing to do. ",
    "start": "1961102",
    "end": "1970679"
  },
  {
    "text": "Huffman 1.",
    "start": "1970680",
    "end": "1976510"
  },
  {
    "start": "1976510",
    "end": "1999640"
  },
  {
    "text": "So the first step here is you\ntake the two lowest probability nodes. So right now, there\nare four nodes.",
    "start": "1999640",
    "end": "2005340"
  },
  {
    "text": "The initial nodes\nare just the symbols. You take the two lowest\nones, you merge them.",
    "start": "2005340",
    "end": "2012000"
  },
  {
    "text": "What does merging mean? You basically take these\ntwo nodes, you merge them,",
    "start": "2012000",
    "end": "2019720"
  },
  {
    "text": "and that creates a new node. Call it N1, let's say. And the new node has the\nold two nodes as children.",
    "start": "2019720",
    "end": "2026920"
  },
  {
    "text": " The sum of the probabilities\nof the two nodes,",
    "start": "2026920",
    "end": "2035968"
  },
  {
    "text": "so 0.2 in this case. Now you have three\nnodes left in the tree.",
    "start": "2035968",
    "end": "2042500"
  },
  {
    "text": "You have A, B, and N1. You again take the\ntwo lowest nodes.",
    "start": "2042500",
    "end": "2047870"
  },
  {
    "text": "So now the two\nlowest nodes are B, which is 0.25 and N1, which is\n0.2, you merge those two nodes.",
    "start": "2047870",
    "end": "2055579"
  },
  {
    "text": "So you merge them like this. You get another node\ncalled N2, which has probability which is the sum\nof 0.25 and 0.2, which is 0.45.",
    "start": "2055580",
    "end": "2066379"
  },
  {
    "text": "Now you are just\nleft with two nodes, so they are the\ntwo you will merge. You take A and N2,\nyou merge them.",
    "start": "2066380",
    "end": "2073429"
  },
  {
    "text": "You get the root\nnode, let's call it N3, which has probability 1. ",
    "start": "2073429",
    "end": "2079429"
  },
  {
    "text": "And that's it basically. That that's the Huffman tree.",
    "start": "2079429",
    "end": "2084899"
  },
  {
    "text": "And then you can-- more of a afterthought,\nbut you can do it. You can just label these guys 1\n0, and that gives you the code.",
    "start": "2084900",
    "end": "2092115"
  },
  {
    "text": " So very simple construction.",
    "start": "2092115",
    "end": "2098369"
  },
  {
    "text": "Any questions? Otherwise, we'll\ndo another example where you will help me out. ",
    "start": "2098370",
    "end": "2108370"
  },
  {
    "text": "Looks like we have [INAUDIBLE]. Sorry. ",
    "start": "2108370",
    "end": "2117290"
  },
  {
    "text": "Huffman, this one will\nbe more interesting.",
    "start": "2117290",
    "end": "2122820"
  },
  {
    "start": "2122820",
    "end": "2134720"
  },
  {
    "text": "Again, A, B, C,\nD. This time there are five symbols, 0.3,\n0.25, 0.2, 0.12, 0.08.",
    "start": "2134720",
    "end": "2154250"
  },
  {
    "text": "So initially we have five nodes\nin the tree, A, B, C, D, E.",
    "start": "2154250",
    "end": "2161150"
  },
  {
    "text": "Somebody, which are the\nfirst two nodes we merge, and what is the probability\nof the merged node?",
    "start": "2161150",
    "end": "2167060"
  },
  {
    "text": " So the answer is D and E.\nAnd so let's merge D and E.",
    "start": "2167060",
    "end": "2173270"
  },
  {
    "text": "And what is the probability of\nthis new node, let's call it N1? 0.2.",
    "start": "2173270",
    "end": "2179240"
  },
  {
    "text": "0.12 plus 0.08 is 0.2. Good. ",
    "start": "2179240",
    "end": "2185670"
  },
  {
    "text": "Now what are the next\ntwo nodes we merge? ",
    "start": "2185670",
    "end": "2196130"
  },
  {
    "text": "Some people are whispering\nvery low voice please. ",
    "start": "2196130",
    "end": "2202040"
  },
  {
    "text": "Am I hearing C and N1? ",
    "start": "2202040",
    "end": "2208940"
  },
  {
    "text": "Let's merge C and N1.  Let's call it N2. What is the probability of N2?",
    "start": "2208940",
    "end": "2215545"
  },
  {
    "text": " 0.4 because 0.2 plus 0.2 is 0.4.",
    "start": "2215545",
    "end": "2222690"
  },
  {
    "text": "Next one. N2 and B. I heard N2 and B.\nAnybody disagrees?",
    "start": "2222690",
    "end": "2228680"
  },
  {
    "start": "2228680",
    "end": "2234710"
  },
  {
    "text": "Yeah. So now you have\nthree nodes left. You have N2, which is 0.4.",
    "start": "2234710",
    "end": "2240760"
  },
  {
    "text": "You have B, which is 0.25. You have A, which is 0.35. The two lowest ones are\nactually A and B at this point.",
    "start": "2240760",
    "end": "2246730"
  },
  {
    "text": "So you merge A\nand B. You get N3,",
    "start": "2246730",
    "end": "2252270"
  },
  {
    "text": "which has probability 0.6\nbecause 0.35 plus 0.25 is 0.6.",
    "start": "2252270",
    "end": "2258540"
  },
  {
    "text": "And now you can just\nmerge these two guys, get the last root node.",
    "start": "2258540",
    "end": "2263849"
  },
  {
    "text": "You get 1.0 and then\nassign like this. ",
    "start": "2263850",
    "end": "2273160"
  },
  {
    "text": "Let's actually write\ndown the code words so that there is no\nconfusion at all. ABCDE. ",
    "start": "2273160",
    "end": "2282520"
  },
  {
    "text": "Codeword for A? ",
    "start": "2282520",
    "end": "2287700"
  },
  {
    "text": "00. Codeword for B?  01 because we drew it\nin a different way.",
    "start": "2287700",
    "end": "2295303"
  },
  {
    "text": "The root is actually\non the right, so you need to go\nfrom right to left. So B is 01. C? ",
    "start": "2295303",
    "end": "2305260"
  },
  {
    "text": "C is 10. D? ",
    "start": "2305260",
    "end": "2310990"
  },
  {
    "text": "Yeah, 110. And E is 111.",
    "start": "2310990",
    "end": "2317170"
  },
  {
    "text": "We see it has the usual the\nproperties, the optimality properties we discussed\njust now that the two",
    "start": "2317170",
    "end": "2322930"
  },
  {
    "text": "longest codewords are D and E,\nand they have the same length. That's good. And you can verify that if\none guy has higher probability",
    "start": "2322930",
    "end": "2330070"
  },
  {
    "text": "than the other one, then\nit has a equal to a smaller length than the other one. So it satisfies the\noptimality properties.",
    "start": "2330070",
    "end": "2337059"
  },
  {
    "start": "2337060",
    "end": "2343410"
  },
  {
    "text": "OK. Any questions about\nthe construction? Very simple construction,\nreally not that much to say.",
    "start": "2343410",
    "end": "2353560"
  },
  {
    "text": " Try to implement it if you\nwant to do coding practice",
    "start": "2353560",
    "end": "2360610"
  },
  {
    "text": "for some interviews or so on. It's a very classic\ngreedy algorithm. See what data structures you\nuse, do you use recursion,",
    "start": "2360610",
    "end": "2367270"
  },
  {
    "text": "or do you use\niterative and so on. ",
    "start": "2367270",
    "end": "2381170"
  },
  {
    "text": "So why is it optimal? Just satisfying\nthose two conditions doesn't make the code optimal. You need to prove that\nit is actually optimal.",
    "start": "2381170",
    "end": "2389030"
  },
  {
    "text": "We will not prove it in class. So we will see\nthe lecture notes.",
    "start": "2389030",
    "end": "2394370"
  },
  {
    "text": "Actually, it's not\nin the lecture notes. You need to see the book. So you see Cover\nand Thomas chapter 5",
    "start": "2394370",
    "end": "2404780"
  },
  {
    "text": "for the proof of optimality. It's based on an argument\nwhich is roughly that--",
    "start": "2404780",
    "end": "2413405"
  },
  {
    "text": " let's see, ABCDE.",
    "start": "2413405",
    "end": "2427540"
  },
  {
    "start": "2427540",
    "end": "2432650"
  },
  {
    "text": "So it's like an\ninductive argument that optimality of this\nguy is equivalent to--",
    "start": "2432650",
    "end": "2442474"
  },
  {
    "start": "2442475",
    "end": "2455110"
  },
  {
    "text": "so it's a step by\nstep proof where you say that if my final code\nis optimal, that's if and only",
    "start": "2455110",
    "end": "2461440"
  },
  {
    "text": "if the code at my second-- the second step is optimal,\nwhich is optimal if",
    "start": "2461440",
    "end": "2467590"
  },
  {
    "text": "and only if my code at\nthe third step is optimal. And at the very end you're\njust left with two nodes",
    "start": "2467590",
    "end": "2473410"
  },
  {
    "text": "because the last two\nnodes are just 0 and 1. So that is definitely optimal. So it's that sort of inductive\nproof where every step",
    "start": "2473410",
    "end": "2479890"
  },
  {
    "text": "you show that this\nstep is optimal. And at the end, you get to the\nbase case which is optimal.",
    "start": "2479890",
    "end": "2486640"
  },
  {
    "text": "We'll not do it. You don't need it\nfor the homeworks.",
    "start": "2486640",
    "end": "2491680"
  },
  {
    "text": "It's interesting. Read about it. Greedy algorithms,\nyou will often see the proofs are\nsometimes a bit tricky.",
    "start": "2491680",
    "end": "2498520"
  },
  {
    "text": "This is one of them where-- you need some amount of\nmath writing to prove it. But fundamentally,\nthis is the idea.",
    "start": "2498520",
    "end": "2505015"
  },
  {
    "start": "2505015",
    "end": "2516151"
  },
  {
    "text": "So the first thing, as\nyou might have observed, it's a greedy algorithm. We don't try to do some\nsort of global optimization.",
    "start": "2516152",
    "end": "2522456"
  },
  {
    "text": "At every step, we just take the\ntwo smallest things, merge two smallest things, merge so on.",
    "start": "2522457",
    "end": "2527960"
  },
  {
    "text": "So that's something. Works for general Wi is\ngreater than or equal to 0",
    "start": "2527960",
    "end": "2541960"
  },
  {
    "text": "to solve this sort of problem. If you have any weighted\noptimization problem,",
    "start": "2541960",
    "end": "2551060"
  },
  {
    "text": "then it not be probabilities\nis what I'm saying. You can take any W's, and\nit's the same algorithm.",
    "start": "2551060",
    "end": "2558160"
  },
  {
    "text": "It doesn't matter. So sometimes you will see\napplications of Huffman codes beyond just coding. In some other areas, you\nmight see some of them",
    "start": "2558160",
    "end": "2566260"
  },
  {
    "text": "in either this or\nthe next homework. ",
    "start": "2566260",
    "end": "2573200"
  },
  {
    "text": "And one last point is,\nthis will be very important",
    "start": "2573200",
    "end": "2582619"
  },
  {
    "text": "for this homework, so just be\nvery careful, the tie breaking. We said that if you have\ntwo possibilities then--",
    "start": "2582620",
    "end": "2590570"
  },
  {
    "text": "if you have three\nnodes, each of them have 0.2, 0.2,\n0.2, you can either merge the first two\nor the second two",
    "start": "2590570",
    "end": "2595970"
  },
  {
    "text": "or the first and the third. So there is a\nnon-determinism built in. The construction is\nnot deterministic.",
    "start": "2595970",
    "end": "2602780"
  },
  {
    "text": "In many cases, you can have\nmore than one possible optimal Huffman code. So when you do the homework\nproblem 5, be very careful.",
    "start": "2602780",
    "end": "2610970"
  },
  {
    "text": "Last year lots of students\nhave a lot of issues. So just be careful that the\ntie breaking step in particular",
    "start": "2610970",
    "end": "2619160"
  },
  {
    "text": "means that you have multiple\npossible Huffman codes.",
    "start": "2619160",
    "end": "2629349"
  },
  {
    "text": "All of them will have the\nsame expected code length. All of them are optimal,\nbut they are different.",
    "start": "2629350",
    "end": "2637270"
  },
  {
    "start": "2637270",
    "end": "2649020"
  },
  {
    "text": "Let me go back actually here. No. ",
    "start": "2649020",
    "end": "2655580"
  },
  {
    "text": "Last thing is that\nfor Shannon codes we saw that expected code length\nis between Hx and Hx plus 1.",
    "start": "2655580",
    "end": "2662150"
  },
  {
    "text": "For Huffman codes, that's\nbasically what we have. We know-- maybe let\nme write it like this.",
    "start": "2662150",
    "end": "2669710"
  },
  {
    "text": "So we know that Hx greater than\nor equal to expected length",
    "start": "2669710",
    "end": "2674740"
  },
  {
    "text": "of Huffman codes,\nwhich is less than or equal to expected length\nof Shannon codes, which",
    "start": "2674740",
    "end": "2687600"
  },
  {
    "text": "is less than Hx plus 1. So this is the chain\nof inequalities.",
    "start": "2687600",
    "end": "2692619"
  },
  {
    "text": "So Huffman codes are somewhere\nbetween Shannon codes and entropy.",
    "start": "2692620",
    "end": "2698099"
  },
  {
    "text": "For certain types\nof distributions, you can prove stronger\nresults but really this is what you have.",
    "start": "2698100",
    "end": "2703305"
  },
  {
    "start": "2703305",
    "end": "2713200"
  },
  {
    "text": "Coming back to the\nconstruction, can somebody",
    "start": "2713200",
    "end": "2724180"
  },
  {
    "text": "suggest how do I do this step? How do I always\npick the two nodes with the least probability?",
    "start": "2724180",
    "end": "2730570"
  },
  {
    "text": "Can I do it in an\nefficient way, maybe even in an efficient\nway, just any ideas",
    "start": "2730570",
    "end": "2735730"
  },
  {
    "text": "on how we can pick the two nodes\nwith the least probability? How would you do it if\nyou were implementing it",
    "start": "2735730",
    "end": "2741370"
  },
  {
    "text": "in Python, let's say? ",
    "start": "2741370",
    "end": "2750880"
  },
  {
    "text": "We could do the heaps or\npriority queues to do this. Yeah. Correctly suggests that you\ncould use a heap or a priority",
    "start": "2750880",
    "end": "2758970"
  },
  {
    "text": "queue, which is a data structure\nwhere you can always pull out the lowest thing or\nthe highest thing",
    "start": "2758970",
    "end": "2765600"
  },
  {
    "text": "depending on the type of heap\nor priority queue you're using. If you're not seeing\nthose, it's fine.",
    "start": "2765600",
    "end": "2771540"
  },
  {
    "text": "Just you should be aware. There is an inefficient way. You take the list of nodes.",
    "start": "2771540",
    "end": "2778230"
  },
  {
    "text": "You sort it. You take the two lowest ones. Then you add the new\nnode, the N1 node.",
    "start": "2778230",
    "end": "2783990"
  },
  {
    "text": "And then you again\nsort it, and then you again take the two lowest. That also works. It's less efficient,\nbut it works.",
    "start": "2783990",
    "end": "2791369"
  },
  {
    "text": "Heaps or priority queues\nare, I guess, easier. Another thing to note is\nthat in many situations,",
    "start": "2791370",
    "end": "2797730"
  },
  {
    "text": "you will construct the\nHuffman code once and use it multiple times. So it's fine if the\nconstruction is a bit slow",
    "start": "2797730",
    "end": "2804390"
  },
  {
    "text": "because ultimately, you're\ngoing to construct it once for a distribution and then keep\nusing it for lots of symbols.",
    "start": "2804390",
    "end": "2809640"
  },
  {
    "start": "2809640",
    "end": "2816250"
  },
  {
    "text": "Let's actually look at\na code for constructing this in the library.",
    "start": "2816250",
    "end": "2824380"
  },
  {
    "text": " Let me know if I need\nto zoom at some point.",
    "start": "2824380",
    "end": "2833329"
  },
  {
    "text": "So we go to SCL. We go to compressors. We go to Huffman_coder. ",
    "start": "2833330",
    "end": "2843378"
  },
  {
    "text": "I'll walk you through it. The file is this one,\nstanford_compression_library, scl, compressors,\nhuffman_coder.py.",
    "start": "2843378",
    "end": "2850750"
  },
  {
    "text": "That's the file if you\nwant to later look.  So what we do is we define\nthis thing called a HuffmanNode",
    "start": "2850750",
    "end": "2859000"
  },
  {
    "text": "where the HuffmanNode has\na less than or equal to implementation, which just\nsays self.prob less than",
    "start": "2859000",
    "end": "2866740"
  },
  {
    "text": "or equal to other.prob. So basically, what\nwe are saying is you are creating this\nclass in Python, which",
    "start": "2866740",
    "end": "2875349"
  },
  {
    "text": "has this ordering property. You can define which node is\nbigger than the other node based on their probabilities.",
    "start": "2875350",
    "end": "2882040"
  },
  {
    "text": "So then there is a function\ncalled build_huffman_tree, which is what we\nwere just doing.",
    "start": "2882040",
    "end": "2888259"
  },
  {
    "text": "So let's see what\nthe function does. If the length of\nthe alphabet is 1,",
    "start": "2888260",
    "end": "2893349"
  },
  {
    "text": "so if you are at the last node\nor there is just one node, there is nothing to do.",
    "start": "2893350",
    "end": "2899119"
  },
  {
    "text": "You just-- that's the base\ncase, I guess, of the recursion.",
    "start": "2899120",
    "end": "2904370"
  },
  {
    "text": "What else? You start with a node_list equal\nto the empty list, so I'm here.",
    "start": "2904370",
    "end": "2911500"
  },
  {
    "text": "Yeah. Then for a in self.alphabet,\nyou create these nodes",
    "start": "2911500",
    "end": "2919650"
  },
  {
    "text": "and you append them\nto the node_list. And then you use this function\ncalled heapify, which converts",
    "start": "2919650",
    "end": "2926640"
  },
  {
    "text": "this thing into a heap.  And then you have a loop where\nwhile the number of nodes",
    "start": "2926640",
    "end": "2934680"
  },
  {
    "text": "in your heap is more than 1,\nyou first heapify the thing, then you take the two\nsmallest symbols, very easy.",
    "start": "2934680",
    "end": "2942069"
  },
  {
    "text": "You pop from the heap. And then you create\nthis combined symbol",
    "start": "2942070",
    "end": "2948670"
  },
  {
    "text": "which we were just\ntalking about, so the last1.pro and last2.prob. You create a combined node, and\nyou push it back into the heap.",
    "start": "2948670",
    "end": "2958150"
  },
  {
    "text": "And at the end, you're left\nwith a single node, which is the root node of the thing. ",
    "start": "2958150",
    "end": "2964983"
  },
  {
    "text": "So basically the construction we\nsaw you can very easily code it up in like less than-- if you remove the comments,\nit's less than 10,",
    "start": "2964983",
    "end": "2971700"
  },
  {
    "text": "15 lines of Python\nreally, so very simple.",
    "start": "2971700",
    "end": "2976890"
  },
  {
    "text": "And any questions on this? ",
    "start": "2976890",
    "end": "2991570"
  },
  {
    "text": "Yeah. So depending on\nwhether you find-- you learn easily with code\nor with the pseudo code,",
    "start": "2991570",
    "end": "2999550"
  },
  {
    "text": "you have both options available. ",
    "start": "2999550",
    "end": "3016040"
  },
  {
    "text": "So one topic which again\nconnects to the homework question 4 is decoding.",
    "start": "3016040",
    "end": "3023240"
  },
  {
    "start": "3023240",
    "end": "3028369"
  },
  {
    "text": "So if you remember\nwe, in lecture 2, actually we talked about you\nhave this prefix codes that",
    "start": "3028370",
    "end": "3033619"
  },
  {
    "text": "can be represented with trees. So the decoding is so easy. You just walk down the tree. You decode a symbol.",
    "start": "3033620",
    "end": "3040940"
  },
  {
    "text": "We were very happy. So we talked about this\ntree-based decoding where the idea was\nvery simple really.",
    "start": "3040940",
    "end": "3049750"
  },
  {
    "text": "You have this tree,\nlike this, 0110.",
    "start": "3049750",
    "end": "3056050"
  },
  {
    "text": "And then you had a stream which\nwas like 01011 sort of thing.",
    "start": "3056050",
    "end": "3062440"
  },
  {
    "text": "And then you would go here,\nthen you would go like this, then you would go like this,\nand then you would decode it.",
    "start": "3062440",
    "end": "3069670"
  },
  {
    "text": " Sadly, nobody uses this.",
    "start": "3069670",
    "end": "3076165"
  },
  {
    "text": "This is not a good\nidea in practice. Two reasons.",
    "start": "3076165",
    "end": "3081730"
  },
  {
    "text": "One is, there are\ntoo many branches.",
    "start": "3081730",
    "end": "3086869"
  },
  {
    "text": "Branches in the\nsense that if you write the Python code for this,\nthere is if-else statements. If this is 1, go left.",
    "start": "3086870",
    "end": "3092390"
  },
  {
    "text": "If this is 0, go\nright, that branches. So this sort of thing.",
    "start": "3092390",
    "end": "3097760"
  },
  {
    "text": "If 0, left. If 1, right.",
    "start": "3097760",
    "end": "3103730"
  },
  {
    "text": "And branches are\nreally, really bad for modern computers, modern\ncomputer architectures.",
    "start": "3103730",
    "end": "3114860"
  },
  {
    "text": " We won't do a computer\narchitecture course right now",
    "start": "3114860",
    "end": "3121630"
  },
  {
    "text": "but in short the reason is they\ndo something called pipelining where they collect a\nbunch of instructions",
    "start": "3121630",
    "end": "3129280"
  },
  {
    "text": "and try to execute them\nin a pipelined way. And if you take\nthe wrong branch, then you have to flush\nthe whole pipeline.",
    "start": "3129280",
    "end": "3135100"
  },
  {
    "text": "A lot of work goes to waste. So it's just bad. Branches are bad. Even though you have\ngood branch predictors,",
    "start": "3135100",
    "end": "3141490"
  },
  {
    "text": "still branches make\nyour code really slow. And you might wonder\nlike, why do we care?",
    "start": "3141490",
    "end": "3147760"
  },
  {
    "text": "Do we really decode so\nmuch data with Huffman? Actually, we do. Gzip, one of the most\npopular compression formats,",
    "start": "3147760",
    "end": "3155170"
  },
  {
    "text": "uses Huffman as\nits entropy coder. And every time you download\na file from the internet,",
    "start": "3155170",
    "end": "3161080"
  },
  {
    "text": "there is probably a\nHuffman coder running. The older video codecs\nused to use Huffman. The new ones I don't know.",
    "start": "3161080",
    "end": "3169210"
  },
  {
    "text": "Every time you're streaming\na video over YouTube, either this or something\nsimilar is actually running. You're always decoding\na prefix code.",
    "start": "3169210",
    "end": "3175875"
  },
  {
    "text": "Anytime your\ncomputer is running, you're probably decoding\na prefix code somewhere. So this is not\njust about Huffman.",
    "start": "3175875",
    "end": "3183230"
  },
  {
    "text": "This is about any [INAUDIBLE]\njust this tree-based decoding is a really, really bad idea\nbecause of these branches.",
    "start": "3183230",
    "end": "3191150"
  },
  {
    "text": "You will never get the\nsame video throughput that you get today. So let's look at\nan alternate way.",
    "start": "3191150",
    "end": "3199880"
  },
  {
    "text": "We'll look at it briefly now\nand then later in the homework, you will actually\nimplement the decoding.",
    "start": "3199880",
    "end": "3207849"
  },
  {
    "text": "And this is question\n4 of the homework.",
    "start": "3207850",
    "end": "3213570"
  },
  {
    "text": " Yeah. You implement it in the\ncontext of Shannon codes,",
    "start": "3213570",
    "end": "3220232"
  },
  {
    "text": "but the idea is the same. So I will briefly\ndescribe it so that you",
    "start": "3220232",
    "end": "3229800"
  },
  {
    "text": "have some context when you\nstart the homework question. So there is a decoder\nstate table, which is 000--",
    "start": "3229800",
    "end": "3237840"
  },
  {
    "text": "actually, let me draw code here. So we draw this code A is 0.",
    "start": "3237840",
    "end": "3243970"
  },
  {
    "text": "B is 10. C is 110. D is 111.",
    "start": "3243970",
    "end": "3278750"
  },
  {
    "text": "so this is the code state table. And then you have\nanother table which",
    "start": "3278750",
    "end": "3284550"
  },
  {
    "text": "is called encode-len,\nwhich is ABCD, 1, 2, 3, 3.",
    "start": "3284550",
    "end": "3294475"
  },
  {
    "start": "3294475",
    "end": "3300400"
  },
  {
    "text": "Anybody wants to guess what the\ndecode stage table is doing?",
    "start": "3300400",
    "end": "3305980"
  },
  {
    "start": "3305980",
    "end": "3311670"
  },
  {
    "text": "This is all\ncorresponding to the code I made on the right, the\nA, 0, B, 10, that one.",
    "start": "3311670",
    "end": "3318575"
  },
  {
    "text": "We basically just grab three\nbits at a time of a sequence and then check which\nsymbol it corresponds to",
    "start": "3318575",
    "end": "3325420"
  },
  {
    "text": "in the decode_state_table. From there, we can advance\nforward based on code lengths.",
    "start": "3325420",
    "end": "3331980"
  },
  {
    "text": "Not all of our symbols\nare being decoded. Yeah. So this was basically\nthe full answer.",
    "start": "3331980",
    "end": "3338080"
  },
  {
    "text": "So let's start step by step. So what does it mean that-- somebody else, what does it\nmean that 011 is decoded to A,",
    "start": "3338080",
    "end": "3346600"
  },
  {
    "text": "what does that mean? ",
    "start": "3346600",
    "end": "3352320"
  },
  {
    "text": "Why are there like four\nthings, 000 is recorded to A, 001 decoded to A, 010011?",
    "start": "3352320",
    "end": "3357540"
  },
  {
    "text": "Why are all four decoded to A? Just try to guess. I haven't obviously told\nyou what we are doing,",
    "start": "3357540",
    "end": "3363570"
  },
  {
    "text": "but if you had to guess. ",
    "start": "3363570",
    "end": "3368710"
  },
  {
    "text": "[INAUDIBLE] is A, like 0,\nthat can be encoded to A.",
    "start": "3368710",
    "end": "3376530"
  },
  {
    "text": "Yeah. So then you look at the prefix. Just the way we were\ndoing the prefix coding--",
    "start": "3376530",
    "end": "3382110"
  },
  {
    "text": "prefix decoding in the\npast, you look at a sequence and you try to find\nthe first symbol",
    "start": "3382110",
    "end": "3388437"
  },
  {
    "text": "that you decode out of it. So if you see a 000, the first\nsymbol you would decode out of it is A. It starts with zero.",
    "start": "3388437",
    "end": "3394799"
  },
  {
    "text": "The only codeword\nthat starts with zero. If you see a 100--",
    "start": "3394800",
    "end": "3399940"
  },
  {
    "text": "if you see a 100 or a 101, the\nfirst symbol you would decode is a B because the B is the\nonly one that starts with 10.",
    "start": "3399940",
    "end": "3407859"
  },
  {
    "text": "If you see a 110, then you would\ndecode a C. If you see a 111, you would decode a D. So with\nthis in mind, you can define--",
    "start": "3407860",
    "end": "3422140"
  },
  {
    "text": "you can implement this function. ",
    "start": "3422140",
    "end": "3427329"
  },
  {
    "text": "I think this is\nactually not what you're asked to do in the homework. You are asked to construct these\nstate tables in the homework.",
    "start": "3427330",
    "end": "3433690"
  },
  {
    "text": "So I'm not infringing\nupon your homework here. So we call it\ndecode_symbol_fast,",
    "start": "3433690",
    "end": "3442330"
  },
  {
    "text": "fast in the sense that it's\nfaster than doing it in a tree. So you define this\nstate, which is,",
    "start": "3442330",
    "end": "3450170"
  },
  {
    "text": "you take the three bits\nfrom the bit array-- the next three bits\nfrom the bit array.",
    "start": "3450170",
    "end": "3456500"
  },
  {
    "text": "You look at the\ndecode state table,",
    "start": "3456500",
    "end": "3465180"
  },
  {
    "text": "and you can decode\na symbol already. You can decode that. Based on the three bits,\nyou can decode the symbol.",
    "start": "3465180",
    "end": "3470984"
  },
  {
    "text": " And then you look at the\nencode_len table, which tells",
    "start": "3470985",
    "end": "3476993"
  },
  {
    "text": "you the length of the encoding. ",
    "start": "3476993",
    "end": "3489130"
  },
  {
    "text": "And then you can\nbasically return S and the number of bits. ",
    "start": "3489130",
    "end": "3498510"
  },
  {
    "text": "So it's a few steps\nof things to do. First thing is you take the next\nthree bits from the bit area.",
    "start": "3498510",
    "end": "3507470"
  },
  {
    "text": "Based on those three bits,\nyou decode one symbol, only one symbol. So you can decode any\nof these ABCD symbols.",
    "start": "3507470",
    "end": "3515319"
  },
  {
    "text": "Then based on the symbol\nyou decode you check, how many bits do I actually\nneed, how many bits I have actually read?",
    "start": "3515320",
    "end": "3522320"
  },
  {
    "text": "And then you basically advance. So that's the process. And you will get\nmuch more practice",
    "start": "3522320",
    "end": "3528410"
  },
  {
    "text": "with this in the homework. But here I just wanted\nto give you a flavor. Any questions on this?",
    "start": "3528410",
    "end": "3535018"
  },
  {
    "text": "And if there are no\nquestions, can somebody tell me what this three is? Why three? What's so special about three?",
    "start": "3535018",
    "end": "3541760"
  },
  {
    "text": "It's the longest. Yeah, I hear that three is\nthe longest codeword here.",
    "start": "3541760",
    "end": "3548869"
  },
  {
    "text": "Yeah. I have a question. Yep. What situation would\nwe have this bit array",
    "start": "3548870",
    "end": "3554230"
  },
  {
    "text": "with symbols of three when we're\ndealing with the prefix code? It just seems--",
    "start": "3554230",
    "end": "3559900"
  },
  {
    "text": "Yeah. So the way to think\nabout it is that you are given a long, long sequence.",
    "start": "3559900",
    "end": "3565420"
  },
  {
    "text": "It's just a stream coming in\nor a big block or something. You have encoded a\nbunch of ABCDs together.",
    "start": "3565420",
    "end": "3571329"
  },
  {
    "text": "You got a long bit array. And then you take\nthe first three bits.",
    "start": "3571330",
    "end": "3576940"
  },
  {
    "text": "Based on that, you\ndecode one symbol, and you know that you\nhave read maybe one bit. Maybe it was an A, so\nyou only read one bit.",
    "start": "3576940",
    "end": "3584380"
  },
  {
    "text": "So next time, you will look at-- if the first time you\nlook at bit 1, 2, 3, next time you look\nat bit 2, 3, 4.",
    "start": "3584380",
    "end": "3591609"
  },
  {
    "text": "And then maybe you\nread two symbols. So now you have consumed\nbits 2 and bits 3.",
    "start": "3591610",
    "end": "3596829"
  },
  {
    "text": "So now you look at 4, 5, 6. So that's the progression. It's just not clear to me\nwhy that array would even",
    "start": "3596830",
    "end": "3602950"
  },
  {
    "text": "exist in first place. What is the-- Yeah. ",
    "start": "3602950",
    "end": "3612430"
  },
  {
    "text": "Yeah. I think we talked about\nit a little bit earlier. I think as you do the homework,\nyou will get more experience.",
    "start": "3612430",
    "end": "3617880"
  },
  {
    "text": "But the whole reason\nwhy we talk about all this prefix free codes, why\ndo we need prefix free codes,",
    "start": "3617880",
    "end": "3624300"
  },
  {
    "text": "why is it not sufficient that\nABCD just have different code words, why the prefix free\nproperty is because almost all",
    "start": "3624300",
    "end": "3631080"
  },
  {
    "text": "the time, you don't want\nto encode just one symbol. You want to encode a\nlong string of symbols.",
    "start": "3631080",
    "end": "3637530"
  },
  {
    "text": "So the thing you encode\nis like ACDBBDD-something. And that whole big thing will be\nconverted to a long bit array,",
    "start": "3637530",
    "end": "3645870"
  },
  {
    "text": "like 0011010 whatever. So you get this long thing. And then that long\nthing, you should",
    "start": "3645870",
    "end": "3651780"
  },
  {
    "text": "be able to decode back\nto the original sequence. Yeah. Look at the lecture\n2 slides where",
    "start": "3651780",
    "end": "3658180"
  },
  {
    "text": "we talked about-- there\nis an alternate approach in a Morse code\nor something where you put a comma or a separator\nbetween every symbol,",
    "start": "3658180",
    "end": "3663900"
  },
  {
    "text": "but that's not how\nwe do it typically. It's not optimal. So it's better to do--",
    "start": "3663900",
    "end": "3669090"
  },
  {
    "text": "have it prefix-free so that\nyou can encode a long sequence into a long bit array.",
    "start": "3669090",
    "end": "3675630"
  },
  {
    "text": "So that's how you get\nthe three basically. At the very end, you might\nreach the very end of the thing",
    "start": "3675630",
    "end": "3681835"
  },
  {
    "text": "where maybe you don't have--\nit's not a multiple of three or there is some\nboundary conditions. So you can pad it with zeros\njust to make sure it works out.",
    "start": "3681835",
    "end": "3690630"
  },
  {
    "text": "Pulkit, yeah. I wanted to just\nclarify the last point that sure there may be some\nedge cases boundary condition.",
    "start": "3690630",
    "end": "3697260"
  },
  {
    "text": "So suppose you are encoding\nAB010 in that case, you read three,\nyou decode it say,",
    "start": "3697260",
    "end": "3702930"
  },
  {
    "text": "you can only decode one symbol. You are still left\nwith one zero. But that's just a corner case.",
    "start": "3702930",
    "end": "3708090"
  },
  {
    "text": "You can just always\nappend last bit as zero if it's not a multiple of three,\nread 100 and that's B again.",
    "start": "3708090",
    "end": "3715930"
  },
  {
    "text": "That's where you stop decode. Yeah. So Pulkit just\ntalking about padding basically that at the\nend, you might not",
    "start": "3715930",
    "end": "3722620"
  },
  {
    "text": "be left with three symbols when\nyou decode a long sequence. You just pad it with zeros. It's fine. ",
    "start": "3722620",
    "end": "3729820"
  },
  {
    "text": "Any other questions? ",
    "start": "3729820",
    "end": "3737180"
  },
  {
    "text": "Sorry. ",
    "start": "3737180",
    "end": "3743880"
  },
  {
    "text": "So one more thing about-- a couple more things about\ntable-based decoding,",
    "start": "3743880",
    "end": "3753220"
  },
  {
    "text": "so the size of the\ntable is exponential in",
    "start": "3753220",
    "end": "3758680"
  },
  {
    "text": "the maximum depth of the tree. We saw that in the last one\nthe table size was eight",
    "start": "3758680",
    "end": "3764710"
  },
  {
    "text": "because 2 power 3 is 8. And what you want\nis in practice,",
    "start": "3764710",
    "end": "3770340"
  },
  {
    "text": "you want it to\nfit in your cache. So it should be very small\nso that your decoding",
    "start": "3770340",
    "end": "3775830"
  },
  {
    "text": "can work very fast. So therefore, you want\nto limit max depth.",
    "start": "3775830",
    "end": "3784270"
  },
  {
    "start": "3784270",
    "end": "3789760"
  },
  {
    "text": "So this is something we\nwill not do in class. Last year, a couple students\ndid it actually as a project.",
    "start": "3789760",
    "end": "3794890"
  },
  {
    "text": "But there is something\ncalled a constrained Huffman",
    "start": "3794890",
    "end": "3800890"
  },
  {
    "text": "code where the idea is best\ncode with max depth constraint.",
    "start": "3800890",
    "end": "3815619"
  },
  {
    "start": "3815620",
    "end": "3821855"
  },
  {
    "text": "The construction is\nslightly more complicated than your usual Huffman\ncodes, but these are the version of Huffman\ncodes that you will often",
    "start": "3821855",
    "end": "3828260"
  },
  {
    "text": "see being used in practice. You want to constrain\nthe max length. And often you want\nto constrain it",
    "start": "3828260",
    "end": "3834080"
  },
  {
    "text": "to 16 or 24 or a\nbyte multiple thing",
    "start": "3834080",
    "end": "3839570"
  },
  {
    "text": "so that it works nicely\nwith how computers work. ",
    "start": "3839570",
    "end": "3846380"
  },
  {
    "text": "Any questions on this?  Yeah. So this is really\nlow level stuff.",
    "start": "3846380",
    "end": "3855260"
  },
  {
    "text": "But you will see a lot\nof action and compression is often in the very\nlow level stuff. You need to be-- you\nhave a good algorithm.",
    "start": "3855260",
    "end": "3861080"
  },
  {
    "text": "That's good. But if it uses all these\ncomplicated trees and so on, you can't use it for the\nlarge volumes of data.",
    "start": "3861080",
    "end": "3867950"
  },
  {
    "text": "Videos are huge. Logs are huge. Text is not that big. So if you're just\ncompressing text, go all in.",
    "start": "3867950",
    "end": "3876109"
  },
  {
    "text": "But for practical\ntypes of data, it's often so big that\nyou can't afford suboptimal types of things.",
    "start": "3876110",
    "end": "3882545"
  },
  {
    "text": " Last thing-- on table-based\ncoding the last thing--",
    "start": "3882545",
    "end": "3889329"
  },
  {
    "text": " table-based decoding,\nmore of a homework really,",
    "start": "3889330",
    "end": "3897730"
  },
  {
    "text": "does anybody recognize\nthis sequence? ",
    "start": "3897730",
    "end": "3911200"
  },
  {
    "text": "Yeah, some people are\ncorrectly answering. It's the Fibonacci sequence. ",
    "start": "3911200",
    "end": "3917849"
  },
  {
    "text": "What is the sum of 1 plus 1, 2. 2 plus 2, 4. 4 plus 3 is 7.",
    "start": "3917850",
    "end": "3923670"
  },
  {
    "text": "12. 20, 33.",
    "start": "3923670",
    "end": "3928840"
  },
  {
    "text": "So we make this\nprobability distribution. ",
    "start": "3928840",
    "end": "3935662"
  },
  {
    "text": "We make this probability\ndistribution. Just make the Huffman\ncode for this at home.",
    "start": "3935662",
    "end": "3943545"
  },
  {
    "start": "3943545",
    "end": "3948970"
  },
  {
    "text": "What you will\nobserve is that this is an adversarial case where\nyou will get really, really long codewords.",
    "start": "3948970",
    "end": "3955390"
  },
  {
    "text": "You might think that why\nworry about this max depth? In practice, you will never\nhave a very long code word. All the code words will\nbe short and so on.",
    "start": "3955390",
    "end": "3961990"
  },
  {
    "text": "But there are these\nspecial distributions where you will see that\nthe max depth in this case",
    "start": "3961990",
    "end": "3968829"
  },
  {
    "text": "will be basically equal to\nthe number of symbols, that",
    "start": "3968830",
    "end": "3974140"
  },
  {
    "text": "minus 1, something like that. So the max depth will be roughly\nequal to the number of symbols.",
    "start": "3974140",
    "end": "3979300"
  },
  {
    "text": "So you will get a really, really\nlong codeword, like 111111111 so on.",
    "start": "3979300",
    "end": "3984590"
  },
  {
    "text": "So solve it at home. Hopefully, you enjoyed. ",
    "start": "3984590",
    "end": "3993170"
  },
  {
    "text": "Moving on to some practical\nHuffman codes, so first thing,",
    "start": "3993170",
    "end": "3999220"
  },
  {
    "text": "this is like somebody\ndid a nice experiment where they took a\nkeyboard and the height",
    "start": "3999220",
    "end": "4005490"
  },
  {
    "text": "of the letters on\nthe keyboard are the frequency of that symbol. So E is very, very high.",
    "start": "4005490",
    "end": "4011580"
  },
  {
    "text": "T is the second highest. A is the third highest,\nso just in English.",
    "start": "4011580",
    "end": "4017130"
  },
  {
    "text": "And then they also\nmade this Huffman code for this distribution. And you can see at the top\npart for example that--",
    "start": "4017130",
    "end": "4027138"
  },
  {
    "text": "sorry. ",
    "start": "4027138",
    "end": "4041440"
  },
  {
    "text": "Yeah. So E you see-- E is very short codeword. Z, Q, X, J, the less commonly\nused letters in English",
    "start": "4041440",
    "end": "4050260"
  },
  {
    "text": "are much longer. But it's non-trivial, if you\ndidn't know the algorithm,",
    "start": "4050260",
    "end": "4056590"
  },
  {
    "text": "this is the optimal code for\nthis distribution, so just something. ",
    "start": "4056590",
    "end": "4065339"
  },
  {
    "text": "At home, I did a\nfew more using SCL.",
    "start": "4065340",
    "end": "4071960"
  },
  {
    "text": " So I followed basically\nPulkit's tutorial of SCL.",
    "start": "4071960",
    "end": "4080670"
  },
  {
    "text": "I installed SCL. I downloaded this\nvery famous book,",
    "start": "4080670",
    "end": "4086580"
  },
  {
    "text": "which I guess you know,\nHuckleberry Finn by Mark Twain.",
    "start": "4086580",
    "end": "4092797"
  },
  {
    "text": "Can you make the size big. Oh, yeah, let me\nmake it a bit bigger. Yeah. So we're saying this\nbook, normal English text",
    "start": "4092797",
    "end": "4100020"
  },
  {
    "text": "about treasures and so on.  And then I used SCL to\ncreate the Huffman tree",
    "start": "4100020",
    "end": "4108930"
  },
  {
    "text": "for this distribution. ",
    "start": "4108930",
    "end": "4117200"
  },
  {
    "text": "We will post this. Take a look. But you see the letter small\ne is very short codeword.",
    "start": "4117200",
    "end": "4124130"
  },
  {
    "text": "Letter capital E, uppercase\nE, is much less common because E is very common,\nbut E doesn't often",
    "start": "4124130",
    "end": "4131630"
  },
  {
    "text": "come at the start of\na sentence actually. ",
    "start": "4131630",
    "end": "4140739"
  },
  {
    "text": "OK. We'll try to scroll down. Then what I did was\nI actually used-- ",
    "start": "4140740",
    "end": "4148589"
  },
  {
    "text": "sorry. This is just hard to do-- is it visible?",
    "start": "4148590",
    "end": "4154084"
  },
  {
    "text": "No. ",
    "start": "4154084",
    "end": "4162149"
  },
  {
    "text": "Yeah. So I actually compressed\nit with the Huffman code. So I started with a 622\nkilobyte file, 622,542.",
    "start": "4162149",
    "end": "4170430"
  },
  {
    "text": "It got compressed to 348,142. So nice with Huffman\ncodes now you",
    "start": "4170430",
    "end": "4175680"
  },
  {
    "text": "can compress this\none book to about--",
    "start": "4175680",
    "end": "4180898"
  },
  {
    "text": "you can reduce it by 44%. So that's good.",
    "start": "4180898",
    "end": "4186380"
  },
  {
    "text": "Then I thought maybe let's\ncompress another file. So I took this Apache Camel,\nwhich is a Java library,",
    "start": "4186380",
    "end": "4201440"
  },
  {
    "text": "and which looks\nsomething like this. You have these function calls\nand semicolons and symbols that",
    "start": "4201440",
    "end": "4207530"
  },
  {
    "text": "don't occur as\ncommonly in English, but they occur more\ncommonly in code. And when we get\nthere, we'll see.",
    "start": "4207530",
    "end": "4222830"
  },
  {
    "text": "So one thing you see here is\nthat see this parentheses, these parentheses get a\nmuch shorter code word",
    "start": "4222830",
    "end": "4228469"
  },
  {
    "text": "than they would have\ngotten in normal English because a code has many more\nparentheses than English.",
    "start": "4228470",
    "end": "4235070"
  },
  {
    "text": "And similarly semicolon\nis much shorter code word. Semicolon you see right\nbelow the parentheses.",
    "start": "4235070",
    "end": "4240795"
  },
  {
    "text": "So depending on your\ndata distribution, your Huffman code will\nlook very, very different. And that's the beauty of it.",
    "start": "4240795",
    "end": "4245867"
  },
  {
    "text": "Any distribution you\ncreate the optimal code for that distribution\nand then use that one. ",
    "start": "4245867",
    "end": "4254280"
  },
  {
    "text": "Last one, here also I\ntried to compress it. This one compressed\nby about 40%.",
    "start": "4254280",
    "end": "4259500"
  },
  {
    "text": "The last thing I did was\nI took an encrypted file. So the encrypted file was not--",
    "start": "4259500",
    "end": "4266280"
  },
  {
    "text": "it's bytes. It's not human readable English. So I made the Huffman\ncode on the bytes.",
    "start": "4266280",
    "end": "4271680"
  },
  {
    "text": "Look at this Huffman code. Anybody tell me, what do you\nsee in this Huffman code?",
    "start": "4271680",
    "end": "4277080"
  },
  {
    "start": "4277080",
    "end": "4282560"
  },
  {
    "text": "Yeah. You see that all of the\nsymbols have same depth. They seem to have\nall the same depth.",
    "start": "4282560",
    "end": "4289270"
  },
  {
    "text": "Can anybody explain why\nthe encrypted file gives me this strange looking\nHuffman code?",
    "start": "4289270",
    "end": "4294325"
  },
  {
    "text": " Why did all codewords\nget the same length?",
    "start": "4294325",
    "end": "4300369"
  },
  {
    "text": "This is basically\nthe fixed length code that we saw in\nthe first lecture. ",
    "start": "4300370",
    "end": "4306909"
  },
  {
    "text": "If it's not like this, then\nyou can basically [INAUDIBLE].. ",
    "start": "4306910",
    "end": "4313290"
  },
  {
    "text": "Yeah. So typically, most\nencryption algorithms, you will see that their\noutput is IID uniform--",
    "start": "4313290",
    "end": "4320860"
  },
  {
    "text": "it's uniformly spread\nacross the bytes. And the reason is something\nlike it should not",
    "start": "4320860",
    "end": "4326710"
  },
  {
    "text": "leak any information about\nthe original distribution. So that's why all inputs go\nto the uniform distribution",
    "start": "4326710",
    "end": "4332680"
  },
  {
    "text": "for a good encryption algorithm. Here I think we used AES, which\nis one of the state-of-the-art",
    "start": "4332680",
    "end": "4338740"
  },
  {
    "text": "encryption algorithms. So you see all of these. The whole tree everything\nis of the same length.",
    "start": "4338740",
    "end": "4345235"
  },
  {
    "text": " So one lesson here is that you\ncan't compress encrypted data.",
    "start": "4345235",
    "end": "4352630"
  },
  {
    "text": "You have this-- there's\njust some fundamental incompatibility. After encryption if you\nwant to compress something,",
    "start": "4352630",
    "end": "4359260"
  },
  {
    "text": "do it before encryption,\nnot after encryption because encryption\nwill basically destroy",
    "start": "4359260",
    "end": "4364630"
  },
  {
    "text": "all structure in your data. The data will look completely\nrandom to any compressor. It will not get any\ncompression at all.",
    "start": "4364630",
    "end": "4370760"
  },
  {
    "text": "So if somebody comes to\nyou with a startup idea, I can compress every\nfile you give me by 50%,",
    "start": "4370760",
    "end": "4377079"
  },
  {
    "text": "give them encrypted file. See what they do. And I guess if they're\nable to compress",
    "start": "4377080",
    "end": "4382510"
  },
  {
    "text": "an encrypted file, that\nmeans they have broken AES. So that's a good thing.",
    "start": "4382510",
    "end": "4387760"
  },
  {
    "text": "Most likely they won't.  Is that clear that the\nencrypted data is random?",
    "start": "4387760",
    "end": "4394869"
  },
  {
    "text": "It's IID uniform. It's not exactly IID, but\nit's close to IID uniform.",
    "start": "4394870",
    "end": "4400510"
  },
  {
    "text": "Over all the bytes, 0 to 256, so\nyou will spend basically eight bits per symbol there\nbecause each of the byte",
    "start": "4400510",
    "end": "4407330"
  },
  {
    "text": "is equally likely. ",
    "start": "4407330",
    "end": "4413640"
  },
  {
    "text": "And then I actually ran\nthe compression right here. I think you can see.",
    "start": "4413640",
    "end": "4419220"
  },
  {
    "text": "Let me try to zoom in. Basically, you get\ncompression rate of one, which means that\nthere is no compression at all",
    "start": "4419220",
    "end": "4425909"
  },
  {
    "text": "for the encrypted file. ",
    "start": "4425910",
    "end": "4435309"
  },
  {
    "text": "So this is available. We'll post the slides. ",
    "start": "4435310",
    "end": "4442920"
  },
  {
    "text": "Let's see. ",
    "start": "4442920",
    "end": "4448072"
  },
  {
    "text": "So there are a couple more\nthings about Huffman codes that I will not\ntry to cover today. We will wrap them up\nin the next lecture.",
    "start": "4448072",
    "end": "4456910"
  },
  {
    "text": "But after we cover\nthose very small topics, the next lecture will mostly\nbe about theoretical intuition",
    "start": "4456910",
    "end": "4464619"
  },
  {
    "text": "behind entropy and\nblock coding, why entropy, what is the\nimportance of entropy,",
    "start": "4464620",
    "end": "4470140"
  },
  {
    "text": "why does block coding\nworks, how does it interact with laws of\nlarge numbers, probability,",
    "start": "4470140",
    "end": "4476380"
  },
  {
    "text": "and so on. So Professor Saki will\nbe taking that lecture.",
    "start": "4476380",
    "end": "4481780"
  },
  {
    "text": "And next week, we will start\ntalking about practical block codes or stream\ncodes, which actually",
    "start": "4481780",
    "end": "4488230"
  },
  {
    "text": "get very close to entropy. And they are the ones that are\nused for the state-of-the-art",
    "start": "4488230",
    "end": "4493300"
  },
  {
    "text": "basically compressors. So with that, thank you.",
    "start": "4493300",
    "end": "4499810"
  },
  {
    "text": "Let me know if you\nhave any questions. ",
    "start": "4499810",
    "end": "4508000"
  }
]